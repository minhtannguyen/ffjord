{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3,4,5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_conditional_gate.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.odenvp_conditional_gate as odenvp\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=True, choices=[True, False])\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"./data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"./data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"./data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"./data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"./data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"./data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            './data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            './data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, 'scale': args.scale, 'gate': args.gate},)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    if args.conditional: best_error_score = float(\"inf\")\n",
      "    \n",
      "    itr = 0\n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol = compute_bits_per_dim_conditional(x, y, model)\n",
      "                loss =  loss_nll + args.weight_y * loss_xent\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits/dim', {'train': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                                \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                        \n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'validation': time.time() - start}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits/dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}, Xent {:.4f}, Loss {:.4f}, Error {:.4f}\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, loss_xent, loss, error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, conditional=True, conv=True, data='mnist', dims='64,64,64', divergence_fn='approximate', dl2int=None, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume=None, rtol=1e-05, save='experiments/cnf_bs900_gate_dev_scale_1e_4_cond', scale=0.0001, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=900, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.0)\n",
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(4, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(4, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(2, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(2, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(8, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(8, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(4, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(4, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=1568, bias=True)\n",
      "  (project_class): LinearZeros(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 841930\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 0000 | Time 38.8070(38.8070) | Bit/dim 23.0852(23.0852) | Xent 2.3026(2.3026) | Loss 23.0852(23.0852) | Error 0.9178(0.9178) Steps 0(0.00) | Grad Norm 183.3802(183.3802) | Total Time 0.00(0.00)\n",
      "Iter 0010 | Time 12.9757(32.0134) | Bit/dim 20.9928(22.8446) | Xent 2.3026(2.3026) | Loss 20.9928(22.8446) | Error 0.8978(0.9135) Steps 0(0.00) | Grad Norm 163.4110(181.1429) | Total Time 0.00(0.00)\n",
      "Iter 0020 | Time 12.1812(26.8811) | Bit/dim 16.4922(21.6933) | Xent 2.3026(2.3026) | Loss 16.4922(21.6933) | Error 0.8989(0.9102) Steps 0(0.00) | Grad Norm 116.1406(169.8126) | Total Time 0.00(0.00)\n",
      "Iter 0030 | Time 12.4431(23.0672) | Bit/dim 12.5337(19.7017) | Xent 2.3026(2.3026) | Loss 12.5337(19.7017) | Error 0.9033(0.9080) Steps 0(0.00) | Grad Norm 60.3555(147.1095) | Total Time 0.00(0.00)\n",
      "Iter 0040 | Time 12.7502(20.3260) | Bit/dim 10.6240(17.5045) | Xent 2.3026(2.3026) | Loss 10.6240(17.5045) | Error 0.8833(0.9052) Steps 0(0.00) | Grad Norm 23.2605(117.8280) | Total Time 0.00(0.00)\n",
      "Iter 0050 | Time 12.7938(18.3316) | Bit/dim 9.1750(15.4654) | Xent 2.3026(2.3026) | Loss 9.1750(15.4654) | Error 0.9089(0.9041) Steps 0(0.00) | Grad Norm 15.3495(91.5948) | Total Time 0.00(0.00)\n",
      "Iter 0060 | Time 12.7874(16.8720) | Bit/dim 7.7166(13.5883) | Xent 2.3026(2.3026) | Loss 7.7166(13.5883) | Error 0.9056(0.9030) Steps 0(0.00) | Grad Norm 13.9038(71.1834) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 48.3227, Epoch Time 923.8718(923.8718), Bit/dim 7.0560, Xent 2.3026, Loss 7.0560, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0070 | Time 12.8447(15.8136) | Bit/dim 6.5382(11.8629) | Xent 2.3026(2.3026) | Loss 6.5382(11.8629) | Error 0.9100(0.9034) Steps 0(0.00) | Grad Norm 14.3661(56.3029) | Total Time 0.00(0.00)\n",
      "Iter 0080 | Time 13.1902(15.0312) | Bit/dim 5.2437(10.2685) | Xent 2.3026(2.3026) | Loss 5.2437(10.2685) | Error 0.9200(0.9031) Steps 0(0.00) | Grad Norm 11.7298(44.9201) | Total Time 0.00(0.00)\n",
      "Iter 0090 | Time 13.2633(14.5440) | Bit/dim 4.2480(8.8049) | Xent 2.3026(2.3026) | Loss 4.2480(8.8049) | Error 0.8989(0.9013) Steps 0(0.00) | Grad Norm 9.6682(35.8908) | Total Time 0.00(0.00)\n",
      "Iter 0100 | Time 13.0515(14.1651) | Bit/dim 3.4770(7.4884) | Xent 2.3026(2.3026) | Loss 3.4770(7.4884) | Error 0.9067(0.9011) Steps 0(0.00) | Grad Norm 7.8543(28.7373) | Total Time 0.00(0.00)\n",
      "Iter 0110 | Time 13.2820(13.9094) | Bit/dim 2.9537(6.3506) | Xent 2.3026(2.3026) | Loss 2.9537(6.3506) | Error 0.8844(0.9018) Steps 0(0.00) | Grad Norm 5.5407(22.9161) | Total Time 0.00(0.00)\n",
      "Iter 0120 | Time 13.0485(13.6920) | Bit/dim 2.6527(5.4074) | Xent 2.3026(2.3026) | Loss 2.6527(5.4074) | Error 0.9033(0.9017) Steps 0(0.00) | Grad Norm 3.5795(18.0373) | Total Time 0.00(0.00)\n",
      "Iter 0130 | Time 13.1276(13.5448) | Bit/dim 2.4732(4.6532) | Xent 2.3026(2.3026) | Loss 2.4732(4.6532) | Error 0.9100(0.9015) Steps 0(0.00) | Grad Norm 2.2018(14.0193) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 51.3038, Epoch Time 928.3906(924.0074), Bit/dim 2.4315, Xent 2.3026, Loss 2.4315, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0140 | Time 13.2503(13.4706) | Bit/dim 2.3628(4.0606) | Xent 2.3026(2.3026) | Loss 2.3628(4.0606) | Error 0.8967(0.9019) Steps 0(0.00) | Grad Norm 1.4704(10.7956) | Total Time 0.00(0.00)\n",
      "Iter 0150 | Time 13.3981(13.4258) | Bit/dim 2.2988(3.6052) | Xent 2.3026(2.3026) | Loss 2.2988(3.6052) | Error 0.9011(0.9016) Steps 0(0.00) | Grad Norm 1.0664(8.2816) | Total Time 0.00(0.00)\n",
      "Iter 0160 | Time 13.5581(13.4211) | Bit/dim 2.2564(3.2570) | Xent 2.3026(2.3026) | Loss 2.2564(3.2570) | Error 0.9189(0.9007) Steps 0(0.00) | Grad Norm 0.8637(6.3557) | Total Time 0.00(0.00)\n",
      "Iter 0170 | Time 13.2521(13.4343) | Bit/dim 2.2425(2.9918) | Xent 2.3026(2.3026) | Loss 2.2425(2.9918) | Error 0.9022(0.9013) Steps 0(0.00) | Grad Norm 0.7448(4.8968) | Total Time 0.00(0.00)\n",
      "Iter 0180 | Time 13.2272(13.4124) | Bit/dim 2.2083(2.7894) | Xent 2.3026(2.3026) | Loss 2.2083(2.7894) | Error 0.9167(0.9021) Steps 0(0.00) | Grad Norm 0.6506(3.7909) | Total Time 0.00(0.00)\n",
      "Iter 0190 | Time 13.2885(13.3679) | Bit/dim 2.1870(2.6346) | Xent 2.3026(2.3026) | Loss 2.1870(2.6346) | Error 0.9044(0.9016) Steps 0(0.00) | Grad Norm 0.5828(2.9530) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 51.6685, Epoch Time 945.9183(924.6647), Bit/dim 2.1701, Xent 2.3026, Loss 2.1701, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0200 | Time 13.1920(13.3501) | Bit/dim 2.1663(2.5152) | Xent 2.3026(2.3026) | Loss 2.1663(2.5152) | Error 0.9078(0.9013) Steps 0(0.00) | Grad Norm 0.5542(2.3235) | Total Time 0.00(0.00)\n",
      "Iter 0210 | Time 13.2220(13.3489) | Bit/dim 2.1604(2.4232) | Xent 2.3026(2.3026) | Loss 2.1604(2.4232) | Error 0.8911(0.9011) Steps 0(0.00) | Grad Norm 0.5049(1.8502) | Total Time 0.00(0.00)\n",
      "Iter 0220 | Time 13.1561(13.3073) | Bit/dim 2.1477(2.3523) | Xent 2.3026(2.3026) | Loss 2.1477(2.3523) | Error 0.8933(0.8999) Steps 0(0.00) | Grad Norm 0.4869(1.4953) | Total Time 0.00(0.00)\n",
      "Iter 0230 | Time 13.0750(13.2956) | Bit/dim 2.1096(2.2942) | Xent 2.3026(2.3026) | Loss 2.1096(2.2942) | Error 0.9044(0.9000) Steps 0(0.00) | Grad Norm 0.4697(1.2282) | Total Time 0.00(0.00)\n",
      "Iter 0240 | Time 13.3131(13.2834) | Bit/dim 2.1299(2.2483) | Xent 2.3026(2.3026) | Loss 2.1299(2.2483) | Error 0.9022(0.9023) Steps 0(0.00) | Grad Norm 0.4356(1.0241) | Total Time 0.00(0.00)\n",
      "Iter 0250 | Time 13.2067(13.2874) | Bit/dim 2.1043(2.2114) | Xent 2.3026(2.3026) | Loss 2.1043(2.2114) | Error 0.8867(0.9016) Steps 0(0.00) | Grad Norm 0.4550(0.8679) | Total Time 0.00(0.00)\n",
      "Iter 0260 | Time 12.9002(13.2438) | Bit/dim 2.0596(2.1783) | Xent 2.3026(2.3026) | Loss 2.0596(2.1783) | Error 0.9289(0.9016) Steps 0(0.00) | Grad Norm 0.4219(0.7524) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 49.9561, Epoch Time 938.3204(925.0744), Bit/dim 2.0729, Xent 2.3026, Loss 2.0729, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0270 | Time 12.9806(13.2015) | Bit/dim 2.0660(2.1508) | Xent 2.3026(2.3026) | Loss 2.0660(2.1508) | Error 0.8822(0.9006) Steps 0(0.00) | Grad Norm 0.3907(0.6613) | Total Time 0.00(0.00)\n",
      "Iter 0280 | Time 13.3199(13.2120) | Bit/dim 2.0366(2.1281) | Xent 2.3026(2.3026) | Loss 2.0366(2.1281) | Error 0.9000(0.9008) Steps 0(0.00) | Grad Norm 0.4021(0.5886) | Total Time 0.00(0.00)\n",
      "Iter 0290 | Time 13.1976(13.1963) | Bit/dim 2.0361(2.1063) | Xent 2.3026(2.3026) | Loss 2.0361(2.1063) | Error 0.9011(0.9014) Steps 0(0.00) | Grad Norm 0.3968(0.5369) | Total Time 0.00(0.00)\n",
      "Iter 0300 | Time 13.2284(13.2034) | Bit/dim 2.0148(2.0865) | Xent 2.3026(2.3026) | Loss 2.0148(2.0865) | Error 0.8967(0.9020) Steps 0(0.00) | Grad Norm 0.4661(0.5090) | Total Time 0.00(0.00)\n",
      "Iter 0310 | Time 13.2940(13.2260) | Bit/dim 2.0204(2.0683) | Xent 2.3026(2.3026) | Loss 2.0204(2.0683) | Error 0.8967(0.9021) Steps 0(0.00) | Grad Norm 0.3837(0.4806) | Total Time 0.00(0.00)\n",
      "Iter 0320 | Time 13.3761(13.2571) | Bit/dim 2.0023(2.0511) | Xent 2.3026(2.3026) | Loss 2.0023(2.0511) | Error 0.9000(0.9015) Steps 0(0.00) | Grad Norm 0.4113(0.4590) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 52.2805, Epoch Time 942.0820(925.5846), Bit/dim 1.9786, Xent 2.3026, Loss 1.9786, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0330 | Time 13.4800(13.3386) | Bit/dim 1.9822(2.0343) | Xent 2.3026(2.3026) | Loss 1.9822(2.0343) | Error 0.8956(0.9014) Steps 0(0.00) | Grad Norm 0.3721(0.4331) | Total Time 0.00(0.00)\n",
      "Iter 0340 | Time 13.5887(13.4090) | Bit/dim 1.9771(2.0189) | Xent 2.3026(2.3026) | Loss 1.9771(2.0189) | Error 0.9022(0.9019) Steps 0(0.00) | Grad Norm 0.3540(0.4129) | Total Time 0.00(0.00)\n",
      "Iter 0350 | Time 13.5578(13.4940) | Bit/dim 1.9736(2.0022) | Xent 2.3026(2.3026) | Loss 1.9736(2.0022) | Error 0.8911(0.9026) Steps 0(0.00) | Grad Norm 0.3350(0.3938) | Total Time 0.00(0.00)\n",
      "Iter 0360 | Time 13.7072(13.5677) | Bit/dim 1.9449(1.9889) | Xent 2.3026(2.3026) | Loss 1.9449(1.9889) | Error 0.9111(0.9024) Steps 0(0.00) | Grad Norm 0.3371(0.3799) | Total Time 0.00(0.00)\n",
      "Iter 0370 | Time 13.7859(13.6023) | Bit/dim 1.9619(1.9761) | Xent 2.3026(2.3026) | Loss 1.9619(1.9761) | Error 0.8889(0.9026) Steps 0(0.00) | Grad Norm 0.4686(0.3715) | Total Time 0.00(0.00)\n",
      "Iter 0380 | Time 13.4818(13.5812) | Bit/dim 1.9257(1.9641) | Xent 2.3026(2.3026) | Loss 1.9257(1.9641) | Error 0.8822(0.9008) Steps 0(0.00) | Grad Norm 0.3075(0.3525) | Total Time 0.00(0.00)\n",
      "Iter 0390 | Time 13.5731(13.5560) | Bit/dim 1.9264(1.9533) | Xent 2.3026(2.3026) | Loss 1.9264(1.9533) | Error 0.9089(0.9010) Steps 0(0.00) | Grad Norm 0.2788(0.3330) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 50.0561, Epoch Time 963.4814(926.7215), Bit/dim 1.9094, Xent 2.3026, Loss 1.9094, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0400 | Time 13.3467(13.5259) | Bit/dim 1.9189(1.9437) | Xent 2.3026(2.3026) | Loss 1.9189(1.9437) | Error 0.9078(0.9008) Steps 0(0.00) | Grad Norm 0.2379(0.3204) | Total Time 0.00(0.00)\n",
      "Iter 0410 | Time 13.6300(13.5127) | Bit/dim 1.9020(1.9331) | Xent 2.3026(2.3026) | Loss 1.9020(1.9331) | Error 0.8989(0.9010) Steps 0(0.00) | Grad Norm 0.2319(0.3119) | Total Time 0.00(0.00)\n",
      "Iter 0420 | Time 13.9454(13.5691) | Bit/dim 1.9083(1.9231) | Xent 2.3026(2.3026) | Loss 1.9083(1.9231) | Error 0.9044(0.9007) Steps 0(0.00) | Grad Norm 0.2803(0.3019) | Total Time 0.00(0.00)\n",
      "Iter 0430 | Time 13.7081(13.6289) | Bit/dim 1.8888(1.9151) | Xent 2.3026(2.3026) | Loss 1.8888(1.9151) | Error 0.9089(0.9018) Steps 0(0.00) | Grad Norm 0.2410(0.2840) | Total Time 0.00(0.00)\n",
      "Iter 0440 | Time 13.7894(13.6723) | Bit/dim 1.8836(1.9074) | Xent 2.3026(2.3026) | Loss 1.8836(1.9074) | Error 0.8911(0.9004) Steps 0(0.00) | Grad Norm 0.2115(0.2759) | Total Time 0.00(0.00)\n",
      "Iter 0450 | Time 13.7100(13.6973) | Bit/dim 1.8725(1.8987) | Xent 2.3026(2.3026) | Loss 1.8725(1.8987) | Error 0.9078(0.9000) Steps 0(0.00) | Grad Norm 0.1948(0.2654) | Total Time 0.00(0.00)\n",
      "Iter 0460 | Time 13.8840(13.7244) | Bit/dim 1.8618(1.8911) | Xent 2.3026(2.3026) | Loss 1.8618(1.8911) | Error 0.9111(0.9011) Steps 0(0.00) | Grad Norm 0.3755(0.2701) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 55.1225, Epoch Time 973.2795(928.1183), Bit/dim 1.8582, Xent 2.3026, Loss 1.8582, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0470 | Time 13.5683(13.7253) | Bit/dim 1.8445(1.8827) | Xent 2.3026(2.3026) | Loss 1.8445(1.8827) | Error 0.9078(0.9019) Steps 0(0.00) | Grad Norm 0.2357(0.2763) | Total Time 0.00(0.00)\n",
      "Iter 0480 | Time 13.8643(13.7666) | Bit/dim 1.8582(1.8749) | Xent 2.3026(2.3026) | Loss 1.8582(1.8749) | Error 0.8911(0.9019) Steps 0(0.00) | Grad Norm 0.5744(0.3038) | Total Time 0.00(0.00)\n",
      "Iter 0490 | Time 13.8985(13.7938) | Bit/dim 1.8377(1.8668) | Xent 2.3026(2.3026) | Loss 1.8377(1.8668) | Error 0.9044(0.9017) Steps 0(0.00) | Grad Norm 0.3398(0.3275) | Total Time 0.00(0.00)\n",
      "Iter 0500 | Time 13.8240(13.8319) | Bit/dim 1.8331(1.8589) | Xent 2.3026(2.3026) | Loss 1.8331(1.8589) | Error 0.9044(0.9011) Steps 0(0.00) | Grad Norm 0.4398(0.3381) | Total Time 0.00(0.00)\n",
      "Iter 0510 | Time 13.9251(13.8277) | Bit/dim 1.8361(1.8506) | Xent 2.3026(2.3026) | Loss 1.8361(1.8506) | Error 0.9144(0.9020) Steps 0(0.00) | Grad Norm 0.5289(0.3680) | Total Time 0.00(0.00)\n",
      "Iter 0520 | Time 13.9576(13.8754) | Bit/dim 1.8275(1.8432) | Xent 2.3026(2.3026) | Loss 1.8275(1.8432) | Error 0.8867(0.9014) Steps 0(0.00) | Grad Norm 0.2586(0.3725) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 55.6459, Epoch Time 985.4050(929.8369), Bit/dim 1.8024, Xent 2.3026, Loss 1.8024, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0530 | Time 14.1773(13.9014) | Bit/dim 1.8117(1.8342) | Xent 2.3026(2.3026) | Loss 1.8117(1.8342) | Error 0.9000(0.9005) Steps 0(0.00) | Grad Norm 0.4543(0.3715) | Total Time 0.00(0.00)\n",
      "Iter 0540 | Time 14.0519(13.9325) | Bit/dim 1.8012(1.8256) | Xent 2.3026(2.3026) | Loss 1.8012(1.8256) | Error 0.8956(0.9018) Steps 0(0.00) | Grad Norm 0.3677(0.3847) | Total Time 0.00(0.00)\n",
      "Iter 0550 | Time 13.9931(13.9404) | Bit/dim 1.7819(1.8174) | Xent 2.3026(2.3026) | Loss 1.7819(1.8174) | Error 0.8978(0.9003) Steps 0(0.00) | Grad Norm 0.4958(0.3823) | Total Time 0.00(0.00)\n",
      "Iter 0560 | Time 13.6361(13.9582) | Bit/dim 1.7828(1.8088) | Xent 2.3026(2.3026) | Loss 1.7828(1.8088) | Error 0.9056(0.8993) Steps 0(0.00) | Grad Norm 0.8626(0.4261) | Total Time 0.00(0.00)\n",
      "Iter 0570 | Time 13.8325(13.9773) | Bit/dim 1.7606(1.7982) | Xent 2.3026(2.3026) | Loss 1.7606(1.7982) | Error 0.8967(0.9013) Steps 0(0.00) | Grad Norm 0.4058(0.4628) | Total Time 0.00(0.00)\n",
      "Iter 0580 | Time 13.9925(14.0208) | Bit/dim 1.7504(1.7895) | Xent 2.3026(2.3026) | Loss 1.7504(1.7895) | Error 0.9011(0.9016) Steps 0(0.00) | Grad Norm 2.0501(0.6280) | Total Time 0.00(0.00)\n",
      "Iter 0590 | Time 14.6228(14.1074) | Bit/dim 1.7262(1.7826) | Xent 2.3026(2.3026) | Loss 1.7262(1.7826) | Error 0.9044(0.9017) Steps 0(0.00) | Grad Norm 0.5902(2.0046) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 56.2116, Epoch Time 1000.7769(931.9651), Bit/dim 1.7434, Xent 2.3026, Loss 1.7434, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0600 | Time 14.4196(14.1728) | Bit/dim 1.7293(1.7722) | Xent 2.3026(2.3026) | Loss 1.7293(1.7722) | Error 0.9122(0.9018) Steps 0(0.00) | Grad Norm 3.9722(2.5930) | Total Time 0.00(0.00)\n",
      "Iter 0610 | Time 14.1575(14.1792) | Bit/dim 1.7277(1.7634) | Xent 2.3026(2.3026) | Loss 1.7277(1.7634) | Error 0.9000(0.9013) Steps 0(0.00) | Grad Norm 0.5947(2.5444) | Total Time 0.00(0.00)\n",
      "Iter 0620 | Time 14.2475(14.2396) | Bit/dim 1.7141(1.7514) | Xent 2.3026(2.3026) | Loss 1.7141(1.7514) | Error 0.9011(0.9021) Steps 0(0.00) | Grad Norm 1.2321(2.6321) | Total Time 0.00(0.00)\n",
      "Iter 0630 | Time 14.3075(14.2892) | Bit/dim 1.7405(1.7461) | Xent 2.3026(2.3026) | Loss 1.7405(1.7461) | Error 0.8978(0.9018) Steps 0(0.00) | Grad Norm 13.2464(4.1172) | Total Time 0.00(0.00)\n",
      "Iter 0640 | Time 14.4870(14.3246) | Bit/dim 1.7234(1.7369) | Xent 2.3026(2.3026) | Loss 1.7234(1.7369) | Error 0.9000(0.9005) Steps 0(0.00) | Grad Norm 11.6786(5.2555) | Total Time 0.00(0.00)\n",
      "Iter 0650 | Time 14.3580(14.3484) | Bit/dim 1.6895(1.7277) | Xent 2.3026(2.3026) | Loss 1.6895(1.7277) | Error 0.8933(0.9011) Steps 0(0.00) | Grad Norm 8.6244(6.3861) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 58.5413, Epoch Time 1021.0345(934.6371), Bit/dim 1.6538, Xent 2.3026, Loss 1.6538, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0660 | Time 14.1972(14.3502) | Bit/dim 1.6620(1.7140) | Xent 2.3026(2.3026) | Loss 1.6620(1.7140) | Error 0.9078(0.9013) Steps 0(0.00) | Grad Norm 5.0157(6.3971) | Total Time 0.00(0.00)\n",
      "Iter 0670 | Time 14.2142(14.3440) | Bit/dim 1.6309(1.6966) | Xent 2.3026(2.3026) | Loss 1.6309(1.6966) | Error 0.9111(0.9020) Steps 0(0.00) | Grad Norm 3.4843(5.8624) | Total Time 0.00(0.00)\n",
      "Iter 0680 | Time 14.5371(14.3576) | Bit/dim 1.6272(1.6779) | Xent 2.3026(2.3026) | Loss 1.6272(1.6779) | Error 0.9000(0.9010) Steps 0(0.00) | Grad Norm 2.5366(5.1133) | Total Time 0.00(0.00)\n",
      "Iter 0690 | Time 14.5888(14.4035) | Bit/dim 1.5943(1.6585) | Xent 2.3026(2.3026) | Loss 1.5943(1.6585) | Error 0.9033(0.9015) Steps 0(0.00) | Grad Norm 9.7673(6.1621) | Total Time 0.00(0.00)\n",
      "Iter 0700 | Time 14.3598(14.4073) | Bit/dim 1.5696(1.6358) | Xent 2.3026(2.3026) | Loss 1.5696(1.6358) | Error 0.8944(0.9000) Steps 0(0.00) | Grad Norm 9.6649(6.5268) | Total Time 0.00(0.00)\n",
      "Iter 0710 | Time 14.4898(14.4208) | Bit/dim 1.5491(1.6158) | Xent 2.3026(2.3026) | Loss 1.5491(1.6158) | Error 0.8833(0.9012) Steps 0(0.00) | Grad Norm 5.1753(8.1651) | Total Time 0.00(0.00)\n",
      "Iter 0720 | Time 14.3444(14.4260) | Bit/dim 1.5375(1.5941) | Xent 2.3026(2.3026) | Loss 1.5375(1.5941) | Error 0.9144(0.9021) Steps 0(0.00) | Grad Norm 9.7851(7.7815) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 56.0991, Epoch Time 1022.2081(937.2643), Bit/dim 1.5111, Xent 2.3026, Loss 1.5111, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0730 | Time 14.3135(14.4208) | Bit/dim 1.5197(1.5753) | Xent 2.3026(2.3026) | Loss 1.5197(1.5753) | Error 0.8867(0.9010) Steps 0(0.00) | Grad Norm 16.4359(8.5299) | Total Time 0.00(0.00)\n",
      "Iter 0740 | Time 14.3792(14.4318) | Bit/dim 1.4948(1.5546) | Xent 2.3026(2.3026) | Loss 1.4948(1.5546) | Error 0.8878(0.9000) Steps 0(0.00) | Grad Norm 1.6294(7.9735) | Total Time 0.00(0.00)\n",
      "Iter 0750 | Time 14.6157(14.4431) | Bit/dim 1.4812(1.5409) | Xent 2.3026(2.3026) | Loss 1.4812(1.5409) | Error 0.9100(0.9018) Steps 0(0.00) | Grad Norm 11.8261(9.2551) | Total Time 0.00(0.00)\n",
      "Iter 0760 | Time 14.2868(14.4130) | Bit/dim 1.4617(1.5248) | Xent 2.3026(2.3026) | Loss 1.4617(1.5248) | Error 0.8989(0.9011) Steps 0(0.00) | Grad Norm 3.0490(9.0945) | Total Time 0.00(0.00)\n",
      "Iter 0770 | Time 14.2684(14.4181) | Bit/dim 1.4532(1.5066) | Xent 2.3026(2.3026) | Loss 1.4532(1.5066) | Error 0.9056(0.9013) Steps 0(0.00) | Grad Norm 7.7935(8.3545) | Total Time 0.00(0.00)\n",
      "Iter 0780 | Time 14.9043(14.4412) | Bit/dim 1.4371(1.4952) | Xent 2.3026(2.3026) | Loss 1.4371(1.4952) | Error 0.9233(0.9023) Steps 0(0.00) | Grad Norm 14.9668(9.8455) | Total Time 0.00(0.00)\n",
      "Iter 0790 | Time 14.6889(14.4662) | Bit/dim 1.4448(1.4807) | Xent 2.3026(2.3026) | Loss 1.4448(1.4807) | Error 0.8711(0.9010) Steps 0(0.00) | Grad Norm 8.6473(9.1119) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 58.1249, Epoch Time 1025.3413(939.9066), Bit/dim 1.4241, Xent 2.3026, Loss 1.4241, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0800 | Time 14.7761(14.4913) | Bit/dim 1.5443(1.4712) | Xent 2.3026(2.3026) | Loss 1.5443(1.4712) | Error 0.9011(0.9003) Steps 0(0.00) | Grad Norm 30.6600(9.3089) | Total Time 0.00(0.00)\n",
      "Iter 0810 | Time 14.3232(14.4658) | Bit/dim 1.4147(1.4661) | Xent 2.3026(2.3026) | Loss 1.4147(1.4661) | Error 0.9178(0.9009) Steps 0(0.00) | Grad Norm 6.7447(10.3689) | Total Time 0.00(0.00)\n",
      "Iter 0820 | Time 14.6935(14.4656) | Bit/dim 1.4409(1.4562) | Xent 2.3026(2.3026) | Loss 1.4409(1.4562) | Error 0.8956(0.9011) Steps 0(0.00) | Grad Norm 8.0266(9.4603) | Total Time 0.00(0.00)\n",
      "Iter 0830 | Time 14.3639(14.4814) | Bit/dim 1.4175(1.4448) | Xent 2.3026(2.3026) | Loss 1.4175(1.4448) | Error 0.8811(0.9009) Steps 0(0.00) | Grad Norm 9.3379(9.4316) | Total Time 0.00(0.00)\n",
      "Iter 0840 | Time 14.5290(14.5123) | Bit/dim 1.4730(1.4357) | Xent 2.3026(2.3026) | Loss 1.4730(1.4357) | Error 0.8989(0.9018) Steps 0(0.00) | Grad Norm 25.2145(9.0844) | Total Time 0.00(0.00)\n",
      "Iter 0850 | Time 14.5516(14.5014) | Bit/dim 1.3978(1.4344) | Xent 2.3026(2.3026) | Loss 1.3978(1.4344) | Error 0.9167(0.9013) Steps 0(0.00) | Grad Norm 1.9554(10.4673) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 55.7628, Epoch Time 1026.2586(942.4971), Bit/dim 1.4010, Xent 2.3026, Loss 1.4010, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0860 | Time 14.5326(14.4546) | Bit/dim 1.4144(1.4336) | Xent 2.3026(2.3026) | Loss 1.4144(1.4336) | Error 0.9033(0.9017) Steps 0(0.00) | Grad Norm 13.8165(11.6174) | Total Time 0.00(0.00)\n",
      "Iter 0870 | Time 14.3198(14.4331) | Bit/dim 1.4083(1.4258) | Xent 2.3026(2.3026) | Loss 1.4083(1.4258) | Error 0.9022(0.9024) Steps 0(0.00) | Grad Norm 11.6498(10.7635) | Total Time 0.00(0.00)\n",
      "Iter 0880 | Time 14.6821(14.4763) | Bit/dim 1.3880(1.4161) | Xent 2.3026(2.3026) | Loss 1.3880(1.4161) | Error 0.9178(0.9027) Steps 0(0.00) | Grad Norm 9.0248(9.6366) | Total Time 0.00(0.00)\n",
      "Iter 0890 | Time 14.5744(14.5195) | Bit/dim 1.3829(1.4065) | Xent 2.3026(2.3026) | Loss 1.3829(1.4065) | Error 0.9211(0.9021) Steps 0(0.00) | Grad Norm 5.8950(8.6387) | Total Time 0.00(0.00)\n",
      "Iter 0900 | Time 14.0695(14.4917) | Bit/dim 1.4115(1.4036) | Xent 2.3026(2.3026) | Loss 1.4115(1.4036) | Error 0.8889(0.8999) Steps 0(0.00) | Grad Norm 13.8138(9.9415) | Total Time 0.00(0.00)\n",
      "Iter 0910 | Time 14.5172(14.5039) | Bit/dim 1.3678(1.3979) | Xent 2.3026(2.3026) | Loss 1.3678(1.3979) | Error 0.8978(0.8995) Steps 0(0.00) | Grad Norm 7.8748(9.6864) | Total Time 0.00(0.00)\n",
      "Iter 0920 | Time 14.6582(14.5596) | Bit/dim 1.3881(1.3912) | Xent 2.3026(2.3026) | Loss 1.3881(1.3912) | Error 0.9044(0.9005) Steps 0(0.00) | Grad Norm 16.3755(9.5467) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 57.4925, Epoch Time 1030.5801(945.1396), Bit/dim 1.3662, Xent 2.3026, Loss 1.3662, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0930 | Time 14.6738(14.5419) | Bit/dim 1.3615(1.3888) | Xent 2.3026(2.3026) | Loss 1.3615(1.3888) | Error 0.8933(0.9009) Steps 0(0.00) | Grad Norm 7.7642(10.3314) | Total Time 0.00(0.00)\n",
      "Iter 0940 | Time 14.6803(14.5642) | Bit/dim 1.3766(1.3835) | Xent 2.3026(2.3026) | Loss 1.3766(1.3835) | Error 0.8956(0.9023) Steps 0(0.00) | Grad Norm 5.9870(9.9016) | Total Time 0.00(0.00)\n",
      "Iter 0950 | Time 14.8679(14.5719) | Bit/dim 1.3562(1.3792) | Xent 2.3026(2.3026) | Loss 1.3562(1.3792) | Error 0.9044(0.9004) Steps 0(0.00) | Grad Norm 12.5926(9.9880) | Total Time 0.00(0.00)\n",
      "Iter 0960 | Time 14.6756(14.5858) | Bit/dim 1.3424(1.3747) | Xent 2.3026(2.3026) | Loss 1.3424(1.3747) | Error 0.9133(0.8992) Steps 0(0.00) | Grad Norm 13.3600(10.3947) | Total Time 0.00(0.00)\n",
      "Iter 0970 | Time 14.1799(14.5478) | Bit/dim 1.3778(1.3722) | Xent 2.3026(2.3026) | Loss 1.3778(1.3722) | Error 0.9111(0.9002) Steps 0(0.00) | Grad Norm 17.0961(11.0163) | Total Time 0.00(0.00)\n",
      "Iter 0980 | Time 14.7711(14.5623) | Bit/dim 1.3334(1.3679) | Xent 2.3026(2.3026) | Loss 1.3334(1.3679) | Error 0.9100(0.9019) Steps 0(0.00) | Grad Norm 7.0352(11.0436) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 57.4859, Epoch Time 1033.3031(947.7845), Bit/dim 1.3331, Xent 2.3026, Loss 1.3331, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 0990 | Time 14.4583(14.5707) | Bit/dim 1.3385(1.3639) | Xent 2.3026(2.3026) | Loss 1.3385(1.3639) | Error 0.8956(0.9023) Steps 0(0.00) | Grad Norm 1.7376(10.7704) | Total Time 0.00(0.00)\n",
      "Iter 1000 | Time 14.7897(14.5609) | Bit/dim 1.3304(1.3607) | Xent 2.3026(2.3026) | Loss 1.3304(1.3607) | Error 0.9111(0.9018) Steps 0(0.00) | Grad Norm 6.8835(11.0954) | Total Time 0.00(0.00)\n",
      "Iter 1010 | Time 14.4534(14.5642) | Bit/dim 1.3383(1.3589) | Xent 2.3026(2.3026) | Loss 1.3383(1.3589) | Error 0.8878(0.9017) Steps 0(0.00) | Grad Norm 12.9845(11.3533) | Total Time 0.00(0.00)\n",
      "Iter 1020 | Time 14.2498(14.5539) | Bit/dim 1.3711(1.3742) | Xent 2.3026(2.3026) | Loss 1.3711(1.3742) | Error 0.9033(0.9023) Steps 0(0.00) | Grad Norm 11.6879(13.6385) | Total Time 0.00(0.00)\n",
      "Iter 1030 | Time 14.4595(14.5158) | Bit/dim 1.3437(1.3790) | Xent 2.3026(2.3026) | Loss 1.3437(1.3790) | Error 0.9078(0.9021) Steps 0(0.00) | Grad Norm 2.6963(13.3511) | Total Time 0.00(0.00)\n",
      "Iter 1040 | Time 14.4169(14.5356) | Bit/dim 1.3485(1.3754) | Xent 2.3026(2.3026) | Loss 1.3485(1.3754) | Error 0.8922(0.9013) Steps 0(0.00) | Grad Norm 8.1491(12.3220) | Total Time 0.00(0.00)\n",
      "Iter 1050 | Time 14.8041(14.5469) | Bit/dim 1.3427(1.3657) | Xent 2.3026(2.3026) | Loss 1.3427(1.3657) | Error 0.9067(0.9020) Steps 0(0.00) | Grad Norm 3.3813(10.6855) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 57.4957, Epoch Time 1030.8778(950.2773), Bit/dim 1.3203, Xent 2.3026, Loss 1.3203, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1060 | Time 14.5776(14.5692) | Bit/dim 1.3096(1.3559) | Xent 2.3026(2.3026) | Loss 1.3096(1.3559) | Error 0.9111(0.9006) Steps 0(0.00) | Grad Norm 2.1157(9.1133) | Total Time 0.00(0.00)\n",
      "Iter 1070 | Time 14.5829(14.5771) | Bit/dim 1.3151(1.3463) | Xent 2.3026(2.3026) | Loss 1.3151(1.3463) | Error 0.9067(0.9007) Steps 0(0.00) | Grad Norm 0.7760(7.7327) | Total Time 0.00(0.00)\n",
      "Iter 1080 | Time 14.6420(14.6123) | Bit/dim 1.3316(1.3403) | Xent 2.3026(2.3026) | Loss 1.3316(1.3403) | Error 0.9133(0.9017) Steps 0(0.00) | Grad Norm 10.3143(7.2215) | Total Time 0.00(0.00)\n",
      "Iter 1090 | Time 14.8867(14.5991) | Bit/dim 1.3045(1.3356) | Xent 2.3026(2.3026) | Loss 1.3045(1.3356) | Error 0.9156(0.9025) Steps 0(0.00) | Grad Norm 3.5337(7.5413) | Total Time 0.00(0.00)\n",
      "Iter 1100 | Time 14.7110(14.6119) | Bit/dim 1.3047(1.3311) | Xent 2.3026(2.3026) | Loss 1.3047(1.3311) | Error 0.8900(0.9013) Steps 0(0.00) | Grad Norm 4.9386(8.1947) | Total Time 0.00(0.00)\n",
      "Iter 1110 | Time 14.5986(14.5865) | Bit/dim 1.3237(1.3266) | Xent 2.3026(2.3026) | Loss 1.3237(1.3266) | Error 0.8944(0.9016) Steps 0(0.00) | Grad Norm 15.2368(8.6319) | Total Time 0.00(0.00)\n",
      "Iter 1120 | Time 14.7974(14.6138) | Bit/dim 1.3094(1.3226) | Xent 2.3026(2.3026) | Loss 1.3094(1.3226) | Error 0.8867(0.9007) Steps 0(0.00) | Grad Norm 5.2124(8.4116) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 57.7848, Epoch Time 1037.1389(952.8832), Bit/dim 1.3088, Xent 2.3026, Loss 1.3088, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1130 | Time 14.1392(14.5842) | Bit/dim 1.3591(1.3228) | Xent 2.3026(2.3026) | Loss 1.3591(1.3228) | Error 0.8933(0.9016) Steps 0(0.00) | Grad Norm 19.7835(9.6754) | Total Time 0.00(0.00)\n",
      "Iter 1140 | Time 15.2453(14.5759) | Bit/dim 1.5398(1.3335) | Xent 2.3026(2.3026) | Loss 1.5398(1.3335) | Error 0.9089(0.9019) Steps 0(0.00) | Grad Norm 45.8152(11.9378) | Total Time 0.00(0.00)\n",
      "Iter 1150 | Time 14.1974(14.5679) | Bit/dim 1.3916(1.3550) | Xent 2.3026(2.3026) | Loss 1.3916(1.3550) | Error 0.8867(0.9004) Steps 0(0.00) | Grad Norm 11.3079(12.8499) | Total Time 0.00(0.00)\n",
      "Iter 1160 | Time 14.6536(14.5785) | Bit/dim 1.3306(1.3514) | Xent 2.3026(2.3026) | Loss 1.3306(1.3514) | Error 0.9189(0.9006) Steps 0(0.00) | Grad Norm 10.5428(12.0983) | Total Time 0.00(0.00)\n",
      "Iter 1170 | Time 14.7461(14.5880) | Bit/dim 1.3052(1.3419) | Xent 2.3026(2.3026) | Loss 1.3052(1.3419) | Error 0.8989(0.9010) Steps 0(0.00) | Grad Norm 2.0167(10.4842) | Total Time 0.00(0.00)\n",
      "Iter 1180 | Time 14.6632(14.6123) | Bit/dim 1.3084(1.3319) | Xent 2.3026(2.3026) | Loss 1.3084(1.3319) | Error 0.8978(0.9003) Steps 0(0.00) | Grad Norm 9.4562(9.4304) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 57.6266, Epoch Time 1033.8392(955.3119), Bit/dim 1.2869, Xent 2.3026, Loss 1.2869, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1190 | Time 14.3209(14.6094) | Bit/dim 1.3082(1.3232) | Xent 2.3026(2.3026) | Loss 1.3082(1.3232) | Error 0.8989(0.9016) Steps 0(0.00) | Grad Norm 14.4922(9.1050) | Total Time 0.00(0.00)\n",
      "Iter 1200 | Time 14.2437(14.5808) | Bit/dim 1.3619(1.3285) | Xent 2.3026(2.3026) | Loss 1.3619(1.3285) | Error 0.9000(0.9012) Steps 0(0.00) | Grad Norm 16.1170(10.8937) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 14.6856(14.5810) | Bit/dim 1.3086(1.3233) | Xent 2.3026(2.3026) | Loss 1.3086(1.3233) | Error 0.8833(0.9006) Steps 0(0.00) | Grad Norm 12.5215(11.0696) | Total Time 0.00(0.00)\n",
      "Iter 1220 | Time 14.7149(14.5873) | Bit/dim 1.3030(1.3172) | Xent 2.3026(2.3026) | Loss 1.3030(1.3172) | Error 0.9067(0.9021) Steps 0(0.00) | Grad Norm 8.5108(10.2933) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 14.6818(14.5970) | Bit/dim 1.2699(1.3109) | Xent 2.3026(2.3026) | Loss 1.2699(1.3109) | Error 0.9033(0.9020) Steps 0(0.00) | Grad Norm 5.5850(9.9890) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 14.5903(14.5787) | Bit/dim 1.3281(1.3100) | Xent 2.3026(2.3026) | Loss 1.3281(1.3100) | Error 0.8922(0.9015) Steps 0(0.00) | Grad Norm 18.6759(10.7269) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 14.6783(14.5974) | Bit/dim 1.2973(1.3051) | Xent 2.3026(2.3026) | Loss 1.2973(1.3051) | Error 0.8944(0.9015) Steps 0(0.00) | Grad Norm 7.7291(10.5931) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 57.5366, Epoch Time 1034.7715(957.6957), Bit/dim 1.2743, Xent 2.3026, Loss 1.2743, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1260 | Time 14.7879(14.6198) | Bit/dim 1.2974(1.3009) | Xent 2.3026(2.3026) | Loss 1.2974(1.3009) | Error 0.8978(0.9010) Steps 0(0.00) | Grad Norm 3.3896(10.0608) | Total Time 0.00(0.00)\n",
      "Iter 1270 | Time 14.4428(14.6041) | Bit/dim 1.2951(1.3022) | Xent 2.3026(2.3026) | Loss 1.2951(1.3022) | Error 0.9033(0.9017) Steps 0(0.00) | Grad Norm 14.4853(11.4212) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 14.6159(14.6306) | Bit/dim 1.3014(1.2984) | Xent 2.3026(2.3026) | Loss 1.3014(1.2984) | Error 0.9022(0.9009) Steps 0(0.00) | Grad Norm 15.5021(10.8155) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 14.6928(14.6276) | Bit/dim 1.2656(1.2942) | Xent 2.3026(2.3026) | Loss 1.2656(1.2942) | Error 0.9122(0.9027) Steps 0(0.00) | Grad Norm 8.2640(10.4672) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 14.7664(14.6024) | Bit/dim 1.2755(1.2918) | Xent 2.3026(2.3026) | Loss 1.2755(1.2918) | Error 0.9056(0.9024) Steps 0(0.00) | Grad Norm 6.6470(10.5235) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 14.4011(14.5802) | Bit/dim 1.2857(1.2906) | Xent 2.3026(2.3026) | Loss 1.2857(1.2906) | Error 0.8878(0.9022) Steps 0(0.00) | Grad Norm 8.6840(11.0750) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 57.4533, Epoch Time 1033.9647(959.9837), Bit/dim 1.2645, Xent 2.3026, Loss 1.2645, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1320 | Time 14.7085(14.5791) | Bit/dim 1.2779(1.2862) | Xent 2.3026(2.3026) | Loss 1.2779(1.2862) | Error 0.9000(0.9004) Steps 0(0.00) | Grad Norm 7.1667(9.5900) | Total Time 0.00(0.00)\n",
      "Iter 1330 | Time 14.6552(14.6066) | Bit/dim 1.2636(1.2813) | Xent 2.3026(2.3026) | Loss 1.2636(1.2813) | Error 0.9078(0.9000) Steps 0(0.00) | Grad Norm 6.4895(8.5041) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 14.4848(14.6139) | Bit/dim 1.2731(1.2765) | Xent 2.3026(2.3026) | Loss 1.2731(1.2765) | Error 0.9144(0.9006) Steps 0(0.00) | Grad Norm 6.5328(7.4868) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 14.7661(14.6500) | Bit/dim 1.2386(1.2709) | Xent 2.3026(2.3026) | Loss 1.2386(1.2709) | Error 0.9100(0.9009) Steps 0(0.00) | Grad Norm 1.4039(6.2874) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 14.2957(14.6702) | Bit/dim 1.2598(1.2681) | Xent 2.3026(2.3026) | Loss 1.2598(1.2681) | Error 0.9178(0.9024) Steps 0(0.00) | Grad Norm 10.8405(6.4439) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 14.6334(14.6473) | Bit/dim 1.2666(1.2637) | Xent 2.3026(2.3026) | Loss 1.2666(1.2637) | Error 0.8822(0.9007) Steps 0(0.00) | Grad Norm 2.7909(5.6905) | Total Time 0.00(0.00)\n",
      "Iter 1380 | Time 14.9517(14.6585) | Bit/dim 1.3374(1.2693) | Xent 2.3026(2.3026) | Loss 1.3374(1.2693) | Error 0.9067(0.9015) Steps 0(0.00) | Grad Norm 34.5642(8.4232) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 55.8217, Epoch Time 1038.2374(962.3313), Bit/dim 1.3732, Xent 2.3026, Loss 1.3732, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1390 | Time 14.4293(14.6528) | Bit/dim 1.3623(1.2962) | Xent 2.3026(2.3026) | Loss 1.3623(1.2962) | Error 0.9089(0.9019) Steps 0(0.00) | Grad Norm 16.9837(10.9140) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 14.4268(14.6219) | Bit/dim 1.2876(1.2965) | Xent 2.3026(2.3026) | Loss 1.2876(1.2965) | Error 0.8956(0.9011) Steps 0(0.00) | Grad Norm 12.2520(10.8908) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 14.7018(14.5939) | Bit/dim 1.2545(1.2899) | Xent 2.3026(2.3026) | Loss 1.2545(1.2899) | Error 0.8978(0.9010) Steps 0(0.00) | Grad Norm 9.3410(10.2684) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 14.6810(14.6232) | Bit/dim 1.2483(1.2811) | Xent 2.3026(2.3026) | Loss 1.2483(1.2811) | Error 0.8922(0.8998) Steps 0(0.00) | Grad Norm 7.9752(8.8995) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 14.2342(14.6305) | Bit/dim 1.2770(1.2741) | Xent 2.3026(2.3026) | Loss 1.2770(1.2741) | Error 0.9144(0.9021) Steps 0(0.00) | Grad Norm 13.2206(8.5698) | Total Time 0.00(0.00)\n",
      "Iter 1440 | Time 14.5951(14.6389) | Bit/dim 1.3165(1.2764) | Xent 2.3026(2.3026) | Loss 1.3165(1.2764) | Error 0.9033(0.9016) Steps 0(0.00) | Grad Norm 16.0630(10.1480) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 14.4615(14.6489) | Bit/dim 1.2826(1.2755) | Xent 2.3026(2.3026) | Loss 1.2826(1.2755) | Error 0.9000(0.9011) Steps 0(0.00) | Grad Norm 13.9028(10.8194) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 57.3576, Epoch Time 1037.2315(964.5783), Bit/dim 1.2825, Xent 2.3026, Loss 1.2825, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1460 | Time 14.6343(14.6324) | Bit/dim 1.2496(1.2706) | Xent 2.3026(2.3026) | Loss 1.2496(1.2706) | Error 0.8944(0.9015) Steps 0(0.00) | Grad Norm 8.6706(10.5059) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 14.6876(14.6258) | Bit/dim 1.2478(1.2653) | Xent 2.3026(2.3026) | Loss 1.2478(1.2653) | Error 0.8878(0.9015) Steps 0(0.00) | Grad Norm 5.8776(9.4721) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 14.8347(14.6272) | Bit/dim 1.2176(1.2582) | Xent 2.3026(2.3026) | Loss 1.2176(1.2582) | Error 0.8978(0.9019) Steps 0(0.00) | Grad Norm 3.5398(7.8926) | Total Time 0.00(0.00)\n",
      "Iter 1490 | Time 14.5314(14.6145) | Bit/dim 1.2311(1.2520) | Xent 2.3026(2.3026) | Loss 1.2311(1.2520) | Error 0.9022(0.9031) Steps 0(0.00) | Grad Norm 2.1622(6.3232) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 14.6501(14.6175) | Bit/dim 1.2295(1.2463) | Xent 2.3026(2.3026) | Loss 1.2295(1.2463) | Error 0.8978(0.9023) Steps 0(0.00) | Grad Norm 1.9365(5.2989) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 14.7957(14.6385) | Bit/dim 1.2410(1.2425) | Xent 2.3026(2.3026) | Loss 1.2410(1.2425) | Error 0.8922(0.9009) Steps 0(0.00) | Grad Norm 0.7310(4.1089) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 55.6612, Epoch Time 1035.7932(966.7148), Bit/dim 1.2474, Xent 2.3026, Loss 1.2474, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1520 | Time 14.7435(14.6824) | Bit/dim 1.2290(1.2398) | Xent 2.3026(2.3026) | Loss 1.2290(1.2398) | Error 0.9044(0.9015) Steps 0(0.00) | Grad Norm 11.7125(5.3098) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 14.6895(14.6780) | Bit/dim 1.2373(1.2379) | Xent 2.3026(2.3026) | Loss 1.2373(1.2379) | Error 0.9078(0.9024) Steps 0(0.00) | Grad Norm 4.7661(5.9634) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 14.5118(14.6735) | Bit/dim 1.2370(1.2371) | Xent 2.3026(2.3026) | Loss 1.2370(1.2371) | Error 0.8978(0.9021) Steps 0(0.00) | Grad Norm 10.6435(6.7192) | Total Time 0.00(0.00)\n",
      "Iter 1550 | Time 14.7758(14.6595) | Bit/dim 1.2601(1.2490) | Xent 2.3026(2.3026) | Loss 1.2601(1.2490) | Error 0.9067(0.9017) Steps 0(0.00) | Grad Norm 6.8346(9.1855) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 15.1063(14.6679) | Bit/dim 1.2984(1.2577) | Xent 2.3026(2.3026) | Loss 1.2984(1.2577) | Error 0.9122(0.9011) Steps 0(0.00) | Grad Norm 25.9462(11.0099) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 14.1680(14.6391) | Bit/dim 1.2908(1.2657) | Xent 2.3026(2.3026) | Loss 1.2908(1.2657) | Error 0.9011(0.9013) Steps 0(0.00) | Grad Norm 13.4839(11.5782) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 14.5955(14.6257) | Bit/dim 1.2546(1.2631) | Xent 2.3026(2.3026) | Loss 1.2546(1.2631) | Error 0.9033(0.9001) Steps 0(0.00) | Grad Norm 11.7906(10.9883) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 57.5420, Epoch Time 1037.8069(968.8476), Bit/dim 1.2256, Xent 2.3026, Loss 1.2256, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1590 | Time 14.6147(14.6420) | Bit/dim 1.2500(1.2567) | Xent 2.3026(2.3026) | Loss 1.2500(1.2567) | Error 0.8989(0.9011) Steps 0(0.00) | Grad Norm 7.3578(9.6603) | Total Time 0.00(0.00)\n",
      "Iter 1600 | Time 14.6386(14.6474) | Bit/dim 1.2229(1.2473) | Xent 2.3026(2.3026) | Loss 1.2229(1.2473) | Error 0.9044(0.9004) Steps 0(0.00) | Grad Norm 8.9764(8.7150) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 14.6634(14.6376) | Bit/dim 1.2186(1.2409) | Xent 2.3026(2.3026) | Loss 1.2186(1.2409) | Error 0.8956(0.9013) Steps 0(0.00) | Grad Norm 5.5896(8.1662) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 14.6152(14.6441) | Bit/dim 1.2370(1.2359) | Xent 2.3026(2.3026) | Loss 1.2370(1.2359) | Error 0.8967(0.9013) Steps 0(0.00) | Grad Norm 1.6309(7.4155) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 14.4798(14.6303) | Bit/dim 1.2071(1.2318) | Xent 2.3026(2.3026) | Loss 1.2071(1.2318) | Error 0.9033(0.9008) Steps 0(0.00) | Grad Norm 2.0444(7.1798) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 14.8669(14.6435) | Bit/dim 1.2032(1.2300) | Xent 2.3026(2.3026) | Loss 1.2032(1.2300) | Error 0.9011(0.9012) Steps 0(0.00) | Grad Norm 2.5849(7.7209) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 58.6938, Epoch Time 1039.0835(970.9546), Bit/dim 1.2697, Xent 2.3026, Loss 1.2697, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1650 | Time 14.7780(14.6428) | Bit/dim 1.2811(1.2413) | Xent 2.3026(2.3026) | Loss 1.2811(1.2413) | Error 0.8922(0.9009) Steps 0(0.00) | Grad Norm 13.2509(10.0706) | Total Time 0.00(0.00)\n",
      "Iter 1660 | Time 14.8287(14.6481) | Bit/dim 1.2286(1.2548) | Xent 2.3026(2.3026) | Loss 1.2286(1.2548) | Error 0.8978(0.9021) Steps 0(0.00) | Grad Norm 2.8903(11.5735) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 14.7274(14.6492) | Bit/dim 1.2233(1.2522) | Xent 2.3026(2.3026) | Loss 1.2233(1.2522) | Error 0.9111(0.9021) Steps 0(0.00) | Grad Norm 2.7557(10.9501) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 14.7919(14.6683) | Bit/dim 1.2259(1.2454) | Xent 2.3026(2.3026) | Loss 1.2259(1.2454) | Error 0.9156(0.9012) Steps 0(0.00) | Grad Norm 2.9554(9.7428) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 14.6786(14.6759) | Bit/dim 1.2312(1.2388) | Xent 2.3026(2.3026) | Loss 1.2312(1.2388) | Error 0.8944(0.9015) Steps 0(0.00) | Grad Norm 13.3900(9.2788) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 14.7941(14.6899) | Bit/dim 1.2155(1.2372) | Xent 2.3026(2.3026) | Loss 1.2155(1.2372) | Error 0.8933(0.9020) Steps 0(0.00) | Grad Norm 4.2820(10.2137) | Total Time 0.00(0.00)\n",
      "Iter 1710 | Time 14.6464(14.6748) | Bit/dim 1.2245(1.2336) | Xent 2.3026(2.3026) | Loss 1.2245(1.2336) | Error 0.9044(0.9007) Steps 0(0.00) | Grad Norm 12.3992(9.8310) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 56.5496, Epoch Time 1039.7401(973.0182), Bit/dim 1.2221, Xent 2.3026, Loss 1.2221, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1720 | Time 14.2990(14.6551) | Bit/dim 1.2224(1.2321) | Xent 2.3026(2.3026) | Loss 1.2224(1.2321) | Error 0.9078(0.9019) Steps 0(0.00) | Grad Norm 10.2565(10.2222) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 14.8127(14.6657) | Bit/dim 1.2088(1.2277) | Xent 2.3026(2.3026) | Loss 1.2088(1.2277) | Error 0.8989(0.9018) Steps 0(0.00) | Grad Norm 3.1527(9.2932) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 14.9309(14.6733) | Bit/dim 1.2331(1.2288) | Xent 2.3026(2.3026) | Loss 1.2331(1.2288) | Error 0.9089(0.9023) Steps 0(0.00) | Grad Norm 17.5979(10.3363) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 14.6515(14.6775) | Bit/dim 1.2007(1.2252) | Xent 2.3026(2.3026) | Loss 1.2007(1.2252) | Error 0.9011(0.9002) Steps 0(0.00) | Grad Norm 4.4369(9.2153) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 14.7179(14.6688) | Bit/dim 1.1974(1.2194) | Xent 2.3026(2.3026) | Loss 1.1974(1.2194) | Error 0.8978(0.8998) Steps 0(0.00) | Grad Norm 5.3411(8.2206) | Total Time 0.00(0.00)\n",
      "Iter 1770 | Time 14.5814(14.6559) | Bit/dim 1.2037(1.2151) | Xent 2.3026(2.3026) | Loss 1.2037(1.2151) | Error 0.9000(0.9009) Steps 0(0.00) | Grad Norm 5.4994(7.5405) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 14.5827(14.6741) | Bit/dim 1.1977(1.2117) | Xent 2.3026(2.3026) | Loss 1.1977(1.2117) | Error 0.9122(0.9016) Steps 0(0.00) | Grad Norm 4.6763(6.9570) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 57.2277, Epoch Time 1039.1515(975.0022), Bit/dim 1.1923, Xent 2.3026, Loss 1.1923, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1790 | Time 14.5541(14.6604) | Bit/dim 1.1988(1.2098) | Xent 2.3026(2.3026) | Loss 1.1988(1.2098) | Error 0.8978(0.9015) Steps 0(0.00) | Grad Norm 2.7102(6.1672) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 14.4794(14.6785) | Bit/dim 1.2244(1.2091) | Xent 2.3026(2.3026) | Loss 1.2244(1.2091) | Error 0.9122(0.9025) Steps 0(0.00) | Grad Norm 15.7874(6.3627) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 15.2436(14.6906) | Bit/dim 1.2734(1.2200) | Xent 2.3026(2.3026) | Loss 1.2734(1.2200) | Error 0.8922(0.9009) Steps 0(0.00) | Grad Norm 16.9250(8.8770) | Total Time 0.00(0.00)\n",
      "Iter 1820 | Time 14.9427(14.7343) | Bit/dim 1.2230(1.2262) | Xent 2.3026(2.3026) | Loss 1.2230(1.2262) | Error 0.9089(0.9016) Steps 0(0.00) | Grad Norm 8.0939(10.3806) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 14.7095(14.7580) | Bit/dim 1.2484(1.2280) | Xent 2.3026(2.3026) | Loss 1.2484(1.2280) | Error 0.8822(0.9019) Steps 0(0.00) | Grad Norm 13.8975(10.7438) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 15.1943(14.7901) | Bit/dim 1.2016(1.2260) | Xent 2.3026(2.3026) | Loss 1.2016(1.2260) | Error 0.9167(0.9014) Steps 0(0.00) | Grad Norm 5.1205(10.3697) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 57.1093, Epoch Time 1046.4353(977.1452), Bit/dim 1.2048, Xent 2.3026, Loss 1.2048, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1850 | Time 14.7526(14.7951) | Bit/dim 1.2054(1.2213) | Xent 2.3026(2.3026) | Loss 1.2054(1.2213) | Error 0.9011(0.9005) Steps 0(0.00) | Grad Norm 3.9289(9.7146) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 14.9678(14.8085) | Bit/dim 1.1848(1.2156) | Xent 2.3026(2.3026) | Loss 1.1848(1.2156) | Error 0.8933(0.9008) Steps 0(0.00) | Grad Norm 1.7238(8.2357) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 14.7404(14.8065) | Bit/dim 1.2019(1.2117) | Xent 2.3026(2.3026) | Loss 1.2019(1.2117) | Error 0.9189(0.9020) Steps 0(0.00) | Grad Norm 3.2326(6.6914) | Total Time 0.00(0.00)\n",
      "Iter 1880 | Time 14.7343(14.7843) | Bit/dim 1.1810(1.2062) | Xent 2.3026(2.3026) | Loss 1.1810(1.2062) | Error 0.9111(0.9023) Steps 0(0.00) | Grad Norm 2.4848(5.5732) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 15.0093(14.7925) | Bit/dim 1.1943(1.2021) | Xent 2.3026(2.3026) | Loss 1.1943(1.2021) | Error 0.9022(0.9025) Steps 0(0.00) | Grad Norm 5.3373(4.7086) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 15.3081(14.8428) | Bit/dim 1.2330(1.2020) | Xent 2.3026(2.3026) | Loss 1.2330(1.2020) | Error 0.8900(0.9021) Steps 0(0.00) | Grad Norm 16.1685(6.1152) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 15.1580(14.8643) | Bit/dim 1.2664(1.2166) | Xent 2.3026(2.3026) | Loss 1.2664(1.2166) | Error 0.8922(0.9009) Steps 0(0.00) | Grad Norm 27.5246(8.9838) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 59.1418, Epoch Time 1052.5932(979.4086), Bit/dim 1.2852, Xent 2.3026, Loss 1.2852, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1920 | Time 14.9207(14.8788) | Bit/dim 1.2394(1.2275) | Xent 2.3026(2.3026) | Loss 1.2394(1.2275) | Error 0.9089(0.9009) Steps 0(0.00) | Grad Norm 15.9287(10.6934) | Total Time 0.00(0.00)\n",
      "Iter 1930 | Time 14.8947(14.8848) | Bit/dim 1.2099(1.2238) | Xent 2.3026(2.3026) | Loss 1.2099(1.2238) | Error 0.9156(0.9016) Steps 0(0.00) | Grad Norm 5.0129(9.7213) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 15.0567(14.8999) | Bit/dim 1.2114(1.2177) | Xent 2.3026(2.3026) | Loss 1.2114(1.2177) | Error 0.9044(0.9027) Steps 0(0.00) | Grad Norm 2.3917(8.4495) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 14.9997(14.9089) | Bit/dim 1.1960(1.2102) | Xent 2.3026(2.3026) | Loss 1.1960(1.2102) | Error 0.9022(0.9034) Steps 0(0.00) | Grad Norm 2.6400(7.1401) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 14.7132(14.8663) | Bit/dim 1.1787(1.2049) | Xent 2.3026(2.3026) | Loss 1.1787(1.2049) | Error 0.9078(0.9028) Steps 0(0.00) | Grad Norm 3.9009(6.0616) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 15.0137(14.8742) | Bit/dim 1.1815(1.2004) | Xent 2.3026(2.3026) | Loss 1.1815(1.2004) | Error 0.9000(0.9013) Steps 0(0.00) | Grad Norm 6.7445(5.3460) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 58.0326, Epoch Time 1054.9819(981.6758), Bit/dim 1.1798, Xent 2.3026, Loss 1.1798, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1980 | Time 14.8224(14.8788) | Bit/dim 1.1893(1.1980) | Xent 2.3026(2.3026) | Loss 1.1893(1.1980) | Error 0.8989(0.9000) Steps 0(0.00) | Grad Norm 4.9245(5.6088) | Total Time 0.00(0.00)\n",
      "Iter 1990 | Time 14.7178(14.8759) | Bit/dim 1.1960(1.1954) | Xent 2.3026(2.3026) | Loss 1.1960(1.1954) | Error 0.8889(0.9015) Steps 0(0.00) | Grad Norm 6.2142(6.3783) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 14.8664(14.8715) | Bit/dim 1.1845(1.1916) | Xent 2.3026(2.3026) | Loss 1.1845(1.1916) | Error 0.8956(0.9022) Steps 0(0.00) | Grad Norm 5.2888(6.6876) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 14.8341(14.8842) | Bit/dim 1.2626(1.1945) | Xent 2.3026(2.3026) | Loss 1.2626(1.1945) | Error 0.8900(0.9027) Steps 0(0.00) | Grad Norm 22.0452(7.7598) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 14.9862(14.9045) | Bit/dim 1.2480(1.2145) | Xent 2.3026(2.3026) | Loss 1.2480(1.2145) | Error 0.9111(0.9016) Steps 0(0.00) | Grad Norm 9.8296(10.0146) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 14.9384(14.9530) | Bit/dim 1.2061(1.2221) | Xent 2.3026(2.3026) | Loss 1.2061(1.2221) | Error 0.9044(0.9018) Steps 0(0.00) | Grad Norm 3.9971(10.0979) | Total Time 0.00(0.00)\n",
      "Iter 2040 | Time 15.3057(14.9686) | Bit/dim 1.1933(1.2193) | Xent 2.3026(2.3026) | Loss 1.1933(1.2193) | Error 0.9011(0.9012) Steps 0(0.00) | Grad Norm 7.0273(9.6333) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 57.8356, Epoch Time 1057.9716(983.9647), Bit/dim 1.1828, Xent 2.3026, Loss 1.1828, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2050 | Time 15.0107(14.9438) | Bit/dim 1.1820(1.2122) | Xent 2.3026(2.3026) | Loss 1.1820(1.2122) | Error 0.9122(0.9009) Steps 0(0.00) | Grad Norm 2.1559(8.0470) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 14.9786(14.9121) | Bit/dim 1.1946(1.2040) | Xent 2.3026(2.3026) | Loss 1.1946(1.2040) | Error 0.9011(0.9017) Steps 0(0.00) | Grad Norm 2.1773(6.7085) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 15.0885(14.9220) | Bit/dim 1.1711(1.1984) | Xent 2.3026(2.3026) | Loss 1.1711(1.1984) | Error 0.9056(0.9012) Steps 0(0.00) | Grad Norm 7.0156(6.1160) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 14.9666(14.9207) | Bit/dim 1.1948(1.1945) | Xent 2.3026(2.3026) | Loss 1.1948(1.1945) | Error 0.9022(0.9006) Steps 0(0.00) | Grad Norm 9.6805(6.4951) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 14.8070(14.8989) | Bit/dim 1.2047(1.1913) | Xent 2.3026(2.3026) | Loss 1.2047(1.1913) | Error 0.8956(0.9014) Steps 0(0.00) | Grad Norm 13.7353(6.5020) | Total Time 0.00(0.00)\n",
      "Iter 2100 | Time 14.4916(14.8844) | Bit/dim 1.2723(1.2086) | Xent 2.3026(2.3026) | Loss 1.2723(1.2086) | Error 0.9000(0.9011) Steps 0(0.00) | Grad Norm 10.5448(9.0797) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 15.6283(14.9423) | Bit/dim 1.2423(1.2200) | Xent 2.3026(2.3026) | Loss 1.2423(1.2200) | Error 0.8889(0.9002) Steps 0(0.00) | Grad Norm 20.0510(9.9908) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 57.0308, Epoch Time 1055.0636(986.0977), Bit/dim 1.2245, Xent 2.3026, Loss 1.2245, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2120 | Time 15.1060(14.9367) | Bit/dim 1.1844(1.2200) | Xent 2.3026(2.3026) | Loss 1.1844(1.2200) | Error 0.9111(0.9007) Steps 0(0.00) | Grad Norm 3.1213(10.2992) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 15.0819(14.9028) | Bit/dim 1.2105(1.2180) | Xent 2.3026(2.3026) | Loss 1.2105(1.2180) | Error 0.8778(0.9002) Steps 0(0.00) | Grad Norm 8.3133(10.2681) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 14.7851(14.9108) | Bit/dim 1.1981(1.2110) | Xent 2.3026(2.3026) | Loss 1.1981(1.2110) | Error 0.8944(0.9007) Steps 0(0.00) | Grad Norm 5.3514(9.4180) | Total Time 0.00(0.00)\n",
      "Iter 2150 | Time 14.8474(14.8912) | Bit/dim 1.2038(1.2036) | Xent 2.3026(2.3026) | Loss 1.2038(1.2036) | Error 0.8856(0.9003) Steps 0(0.00) | Grad Norm 3.5624(7.7895) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 14.9420(14.8994) | Bit/dim 1.1697(1.1962) | Xent 2.3026(2.3026) | Loss 1.1697(1.1962) | Error 0.8967(0.9008) Steps 0(0.00) | Grad Norm 2.3947(6.3190) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 14.8592(14.8953) | Bit/dim 1.1771(1.1901) | Xent 2.3026(2.3026) | Loss 1.1771(1.1901) | Error 0.8989(0.9018) Steps 0(0.00) | Grad Norm 0.9613(5.0236) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 58.2827, Epoch Time 1055.3433(988.1750), Bit/dim 1.1746, Xent 2.3026, Loss 1.1746, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2180 | Time 14.7223(14.8984) | Bit/dim 1.1803(1.1876) | Xent 2.3026(2.3026) | Loss 1.1803(1.1876) | Error 0.8889(0.9012) Steps 0(0.00) | Grad Norm 6.6670(5.2577) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 14.8134(14.9027) | Bit/dim 1.1728(1.1851) | Xent 2.3026(2.3026) | Loss 1.1728(1.1851) | Error 0.9056(0.9024) Steps 0(0.00) | Grad Norm 12.0485(5.5473) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 15.0245(14.9082) | Bit/dim 1.1786(1.1838) | Xent 2.3026(2.3026) | Loss 1.1786(1.1838) | Error 0.9033(0.9018) Steps 0(0.00) | Grad Norm 8.5275(6.0676) | Total Time 0.00(0.00)\n",
      "Iter 2210 | Time 14.7537(14.8816) | Bit/dim 1.1754(1.1823) | Xent 2.3026(2.3026) | Loss 1.1754(1.1823) | Error 0.9044(0.9008) Steps 0(0.00) | Grad Norm 3.8066(6.3036) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 14.9744(14.8844) | Bit/dim 1.1947(1.1819) | Xent 2.3026(2.3026) | Loss 1.1947(1.1819) | Error 0.8967(0.9005) Steps 0(0.00) | Grad Norm 18.4440(7.2348) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 14.8881(14.8889) | Bit/dim 1.2428(1.2050) | Xent 2.3026(2.3026) | Loss 1.2428(1.2050) | Error 0.9089(0.9002) Steps 0(0.00) | Grad Norm 10.9533(9.4607) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 14.6730(14.9510) | Bit/dim 1.2170(1.2097) | Xent 2.3026(2.3026) | Loss 1.2170(1.2097) | Error 0.9022(0.9018) Steps 0(0.00) | Grad Norm 11.7402(10.1381) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 58.3490, Epoch Time 1057.1526(990.2444), Bit/dim 1.1898, Xent 2.3026, Loss 1.1898, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2250 | Time 14.9149(14.9748) | Bit/dim 1.1804(1.2050) | Xent 2.3026(2.3026) | Loss 1.1804(1.2050) | Error 0.9000(0.9015) Steps 0(0.00) | Grad Norm 2.8416(9.0571) | Total Time 0.00(0.00)\n",
      "Iter 2260 | Time 14.9596(14.9844) | Bit/dim 1.1857(1.1991) | Xent 2.3026(2.3026) | Loss 1.1857(1.1991) | Error 0.9156(0.9017) Steps 0(0.00) | Grad Norm 3.2228(7.9818) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 14.8649(14.9611) | Bit/dim 1.1825(1.1926) | Xent 2.3026(2.3026) | Loss 1.1825(1.1926) | Error 0.9156(0.9018) Steps 0(0.00) | Grad Norm 7.9613(7.1055) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 14.9874(14.9379) | Bit/dim 1.1837(1.1873) | Xent 2.3026(2.3026) | Loss 1.1837(1.1873) | Error 0.8856(0.9019) Steps 0(0.00) | Grad Norm 16.8758(7.3400) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 15.1675(14.9523) | Bit/dim 1.1909(1.1949) | Xent 2.3026(2.3026) | Loss 1.1909(1.1949) | Error 0.8933(0.9010) Steps 0(0.00) | Grad Norm 8.6608(9.1517) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 15.8438(15.0022) | Bit/dim 1.2865(1.2037) | Xent 2.3026(2.3026) | Loss 1.2865(1.2037) | Error 0.8978(0.9007) Steps 0(0.00) | Grad Norm 31.4873(10.9036) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 58.2037, Epoch Time 1064.7050(992.4782), Bit/dim 1.1872, Xent 2.3026, Loss 1.1872, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2310 | Time 15.2100(15.0898) | Bit/dim 1.2048(1.2088) | Xent 2.3026(2.3026) | Loss 1.2048(1.2088) | Error 0.8967(0.9010) Steps 0(0.00) | Grad Norm 5.7577(10.6641) | Total Time 0.00(0.00)\n",
      "Iter 2320 | Time 15.1357(15.0581) | Bit/dim 1.1832(1.2054) | Xent 2.3026(2.3026) | Loss 1.1832(1.2054) | Error 0.9211(0.9012) Steps 0(0.00) | Grad Norm 12.1659(10.3849) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 15.2582(15.0566) | Bit/dim 1.1913(1.2000) | Xent 2.3026(2.3026) | Loss 1.1913(1.2000) | Error 0.8989(0.9019) Steps 0(0.00) | Grad Norm 9.5455(9.5482) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 15.2029(15.0472) | Bit/dim 1.1872(1.1925) | Xent 2.3026(2.3026) | Loss 1.1872(1.1925) | Error 0.8944(0.9022) Steps 0(0.00) | Grad Norm 5.0927(8.2282) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 14.8087(15.0213) | Bit/dim 1.1747(1.1863) | Xent 2.3026(2.3026) | Loss 1.1747(1.1863) | Error 0.9000(0.9015) Steps 0(0.00) | Grad Norm 2.1094(6.9708) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 15.0027(15.0176) | Bit/dim 1.1573(1.1822) | Xent 2.3026(2.3026) | Loss 1.1573(1.1822) | Error 0.9011(0.9017) Steps 0(0.00) | Grad Norm 2.7948(6.0874) | Total Time 0.00(0.00)\n",
      "Iter 2370 | Time 15.3386(15.0414) | Bit/dim 1.1752(1.1785) | Xent 2.3026(2.3026) | Loss 1.1752(1.1785) | Error 0.9122(0.9003) Steps 0(0.00) | Grad Norm 4.4533(5.6206) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 57.4167, Epoch Time 1063.0779(994.5962), Bit/dim 1.1649, Xent 2.3026, Loss 1.1649, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2380 | Time 14.9316(15.0623) | Bit/dim 1.1600(1.1773) | Xent 2.3026(2.3026) | Loss 1.1600(1.1773) | Error 0.8978(0.9000) Steps 0(0.00) | Grad Norm 5.3572(6.0094) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 14.8103(15.0620) | Bit/dim 1.1675(1.1757) | Xent 2.3026(2.3026) | Loss 1.1675(1.1757) | Error 0.9256(0.9006) Steps 0(0.00) | Grad Norm 10.3844(6.3446) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 14.9756(15.0791) | Bit/dim 1.1685(1.1729) | Xent 2.3026(2.3026) | Loss 1.1685(1.1729) | Error 0.9122(0.9010) Steps 0(0.00) | Grad Norm 3.7596(5.5056) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 15.1523(15.1085) | Bit/dim 1.1771(1.1729) | Xent 2.3026(2.3026) | Loss 1.1771(1.1729) | Error 0.8978(0.9011) Steps 0(0.00) | Grad Norm 14.7406(6.6594) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 15.7628(15.1364) | Bit/dim 1.3332(1.1923) | Xent 2.3026(2.3026) | Loss 1.3332(1.1923) | Error 0.9111(0.9011) Steps 0(0.00) | Grad Norm 37.1134(9.7484) | Total Time 0.00(0.00)\n",
      "Iter 2430 | Time 15.4510(15.1737) | Bit/dim 1.2156(1.2125) | Xent 2.3026(2.3026) | Loss 1.2156(1.2125) | Error 0.9122(0.9012) Steps 0(0.00) | Grad Norm 6.9347(9.7764) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 15.4322(15.2183) | Bit/dim 1.1886(1.2104) | Xent 2.3026(2.3026) | Loss 1.1886(1.2104) | Error 0.8856(0.9017) Steps 0(0.00) | Grad Norm 4.7107(9.0871) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 58.0265, Epoch Time 1074.7270(997.0001), Bit/dim 1.1799, Xent 2.3026, Loss 1.1799, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2450 | Time 14.8682(15.2113) | Bit/dim 1.1747(1.2029) | Xent 2.3026(2.3026) | Loss 1.1747(1.2029) | Error 0.9000(0.9021) Steps 0(0.00) | Grad Norm 1.4540(7.5608) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 15.4105(15.2127) | Bit/dim 1.1656(1.1948) | Xent 2.3026(2.3026) | Loss 1.1656(1.1948) | Error 0.9056(0.9020) Steps 0(0.00) | Grad Norm 2.2312(6.1818) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 15.1398(15.2248) | Bit/dim 1.1713(1.1880) | Xent 2.3026(2.3026) | Loss 1.1713(1.1880) | Error 0.8933(0.9015) Steps 0(0.00) | Grad Norm 2.4462(5.0360) | Total Time 0.00(0.00)\n",
      "Iter 2480 | Time 15.1798(15.2146) | Bit/dim 1.1593(1.1807) | Xent 2.3026(2.3026) | Loss 1.1593(1.1807) | Error 0.8867(0.9018) Steps 0(0.00) | Grad Norm 3.2833(4.9899) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 15.1699(15.2074) | Bit/dim 1.1503(1.1759) | Xent 2.3026(2.3026) | Loss 1.1503(1.1759) | Error 0.8956(0.9016) Steps 0(0.00) | Grad Norm 2.2631(5.4390) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 15.9813(15.2286) | Bit/dim 1.2849(1.1818) | Xent 2.3026(2.3026) | Loss 1.2849(1.1818) | Error 0.8833(0.9005) Steps 0(0.00) | Grad Norm 33.7804(7.6811) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 60.5294, Epoch Time 1078.7915(999.4538), Bit/dim 1.2171, Xent 2.3026, Loss 1.2171, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2510 | Time 15.4362(15.2598) | Bit/dim 1.2192(1.1966) | Xent 2.3026(2.3026) | Loss 1.2192(1.1966) | Error 0.9122(0.9004) Steps 0(0.00) | Grad Norm 13.6720(9.4157) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 15.5089(15.3052) | Bit/dim 1.1780(1.1967) | Xent 2.3026(2.3026) | Loss 1.1780(1.1967) | Error 0.9022(0.9018) Steps 0(0.00) | Grad Norm 11.1472(10.0954) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 15.1188(15.3166) | Bit/dim 1.1478(1.1903) | Xent 2.3026(2.3026) | Loss 1.1478(1.1903) | Error 0.9011(0.9027) Steps 0(0.00) | Grad Norm 6.0104(9.5181) | Total Time 0.00(0.00)\n",
      "Iter 2540 | Time 15.4516(15.3044) | Bit/dim 1.1668(1.1856) | Xent 2.3026(2.3026) | Loss 1.1668(1.1856) | Error 0.9022(0.9008) Steps 0(0.00) | Grad Norm 15.1426(9.2959) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 15.5317(15.3013) | Bit/dim 1.1679(1.1845) | Xent 2.3026(2.3026) | Loss 1.1679(1.1845) | Error 0.9011(0.9004) Steps 0(0.00) | Grad Norm 2.4775(9.7134) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 14.8938(15.2654) | Bit/dim 1.1716(1.1808) | Xent 2.3026(2.3026) | Loss 1.1716(1.1808) | Error 0.8933(0.9006) Steps 0(0.00) | Grad Norm 10.9151(8.9574) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 15.2432(15.2676) | Bit/dim 1.1716(1.1806) | Xent 2.3026(2.3026) | Loss 1.1716(1.1806) | Error 0.9156(0.9007) Steps 0(0.00) | Grad Norm 8.0745(9.1019) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 59.5084, Epoch Time 1083.7009(1001.9813), Bit/dim 1.1762, Xent 2.3026, Loss 1.1762, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2580 | Time 15.0330(15.2284) | Bit/dim 1.2109(1.1869) | Xent 2.3026(2.3026) | Loss 1.2109(1.1869) | Error 0.8967(0.9012) Steps 0(0.00) | Grad Norm 15.2554(10.7619) | Total Time 0.00(0.00)\n",
      "Iter 2590 | Time 15.2936(15.2134) | Bit/dim 1.1713(1.1859) | Xent 2.3026(2.3026) | Loss 1.1713(1.1859) | Error 0.9089(0.9020) Steps 0(0.00) | Grad Norm 6.3403(10.4830) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 15.1614(15.2314) | Bit/dim 1.1484(1.1814) | Xent 2.3026(2.3026) | Loss 1.1484(1.1814) | Error 0.9144(0.9013) Steps 0(0.00) | Grad Norm 1.7166(9.5306) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 15.4254(15.2850) | Bit/dim 1.1806(1.1781) | Xent 2.3026(2.3026) | Loss 1.1806(1.1781) | Error 0.8878(0.9006) Steps 0(0.00) | Grad Norm 3.7742(7.9830) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 15.6304(15.3349) | Bit/dim 1.1643(1.1735) | Xent 2.3026(2.3026) | Loss 1.1643(1.1735) | Error 0.9022(0.9008) Steps 0(0.00) | Grad Norm 1.9684(6.5375) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 15.5583(15.3989) | Bit/dim 1.1543(1.1685) | Xent 2.3026(2.3026) | Loss 1.1543(1.1685) | Error 0.9133(0.9010) Steps 0(0.00) | Grad Norm 1.3327(5.2236) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 60.8533, Epoch Time 1089.4597(1004.6056), Bit/dim 1.1541, Xent 2.3026, Loss 1.1541, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2640 | Time 15.3103(15.4204) | Bit/dim 1.1449(1.1643) | Xent 2.3026(2.3026) | Loss 1.1449(1.1643) | Error 0.8911(0.9010) Steps 0(0.00) | Grad Norm 8.9121(4.7379) | Total Time 0.00(0.00)\n",
      "Iter 2650 | Time 15.2447(15.4162) | Bit/dim 1.1878(1.1642) | Xent 2.3026(2.3026) | Loss 1.1878(1.1642) | Error 0.8822(0.9006) Steps 0(0.00) | Grad Norm 11.3861(5.6280) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 15.7977(15.4041) | Bit/dim 1.2414(1.1725) | Xent 2.3026(2.3026) | Loss 1.2414(1.1725) | Error 0.9033(0.9000) Steps 0(0.00) | Grad Norm 22.7986(7.6622) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 16.1420(15.4297) | Bit/dim 1.2349(1.1769) | Xent 2.3026(2.3026) | Loss 1.2349(1.1769) | Error 0.9056(0.9010) Steps 0(0.00) | Grad Norm 30.6447(9.2918) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 15.4551(15.4159) | Bit/dim 1.1806(1.1864) | Xent 2.3026(2.3026) | Loss 1.1806(1.1864) | Error 0.9100(0.9007) Steps 0(0.00) | Grad Norm 9.5561(9.5095) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 15.1879(15.4300) | Bit/dim 1.1733(1.1843) | Xent 2.3026(2.3026) | Loss 1.1733(1.1843) | Error 0.9144(0.9018) Steps 0(0.00) | Grad Norm 5.6680(9.0600) | Total Time 0.00(0.00)\n",
      "Iter 2700 | Time 15.5300(15.4136) | Bit/dim 1.1793(1.1809) | Xent 2.3026(2.3026) | Loss 1.1793(1.1809) | Error 0.9111(0.9011) Steps 0(0.00) | Grad Norm 5.7624(8.7650) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 56.4402, Epoch Time 1088.0959(1007.1103), Bit/dim 1.1826, Xent 2.3026, Loss 1.1826, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2710 | Time 15.5160(15.4093) | Bit/dim 1.1636(1.1818) | Xent 2.3026(2.3026) | Loss 1.1636(1.1818) | Error 0.9078(0.9021) Steps 0(0.00) | Grad Norm 1.9845(9.5822) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 15.6992(15.4048) | Bit/dim 1.1808(1.1779) | Xent 2.3026(2.3026) | Loss 1.1808(1.1779) | Error 0.8967(0.9010) Steps 0(0.00) | Grad Norm 0.7124(9.3150) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 15.7574(15.4011) | Bit/dim 1.1866(1.1781) | Xent 2.3026(2.3026) | Loss 1.1866(1.1781) | Error 0.8933(0.9006) Steps 0(0.00) | Grad Norm 17.0504(9.9375) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 15.7734(15.4206) | Bit/dim 1.1652(1.1723) | Xent 2.3026(2.3026) | Loss 1.1652(1.1723) | Error 0.8978(0.9023) Steps 0(0.00) | Grad Norm 10.4535(8.9960) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 15.4929(15.4241) | Bit/dim 1.1591(1.1747) | Xent 2.3026(2.3026) | Loss 1.1591(1.1747) | Error 0.8978(0.9027) Steps 0(0.00) | Grad Norm 2.3615(9.8661) | Total Time 0.00(0.00)\n",
      "Iter 2760 | Time 15.3140(15.4111) | Bit/dim 1.1653(1.1728) | Xent 2.3026(2.3026) | Loss 1.1653(1.1728) | Error 0.9033(0.9009) Steps 0(0.00) | Grad Norm 7.6172(9.8277) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 15.6605(15.4169) | Bit/dim 1.1615(1.1701) | Xent 2.3026(2.3026) | Loss 1.1615(1.1701) | Error 0.9033(0.9018) Steps 0(0.00) | Grad Norm 2.9422(8.9819) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 58.2163, Epoch Time 1089.5779(1009.5843), Bit/dim 1.1555, Xent 2.3026, Loss 1.1555, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2780 | Time 15.9394(15.4150) | Bit/dim 1.2008(1.1703) | Xent 2.3026(2.3026) | Loss 1.2008(1.1703) | Error 0.9044(0.9012) Steps 0(0.00) | Grad Norm 24.9420(9.5005) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 15.4280(15.4204) | Bit/dim 1.1670(1.1754) | Xent 2.3026(2.3026) | Loss 1.1670(1.1754) | Error 0.8944(0.9017) Steps 0(0.00) | Grad Norm 5.5108(10.0857) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 15.3120(15.4711) | Bit/dim 1.1626(1.1760) | Xent 2.3026(2.3026) | Loss 1.1626(1.1760) | Error 0.9011(0.9024) Steps 0(0.00) | Grad Norm 12.1742(10.3943) | Total Time 0.00(0.00)\n",
      "Iter 2810 | Time 15.4761(15.4844) | Bit/dim 1.1588(1.1728) | Xent 2.3026(2.3026) | Loss 1.1588(1.1728) | Error 0.9022(0.9016) Steps 0(0.00) | Grad Norm 4.7802(9.3770) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 15.4543(15.4628) | Bit/dim 1.1986(1.1716) | Xent 2.3026(2.3026) | Loss 1.1986(1.1716) | Error 0.9033(0.9010) Steps 0(0.00) | Grad Norm 16.6832(9.7335) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 15.3633(15.4549) | Bit/dim 1.1602(1.1686) | Xent 2.3026(2.3026) | Loss 1.1602(1.1686) | Error 0.8878(0.9005) Steps 0(0.00) | Grad Norm 4.8741(9.1316) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 60.2165, Epoch Time 1094.9879(1012.1464), Bit/dim 1.1567, Xent 2.3026, Loss 1.1567, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2840 | Time 15.0998(15.4296) | Bit/dim 1.1428(1.1651) | Xent 2.3026(2.3026) | Loss 1.1428(1.1651) | Error 0.8867(0.9018) Steps 0(0.00) | Grad Norm 3.1320(8.8377) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 15.4568(15.3997) | Bit/dim 1.1431(1.1679) | Xent 2.3026(2.3026) | Loss 1.1431(1.1679) | Error 0.8978(0.9019) Steps 0(0.00) | Grad Norm 2.8934(9.6009) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 15.5855(15.3919) | Bit/dim 1.1473(1.1673) | Xent 2.3026(2.3026) | Loss 1.1473(1.1673) | Error 0.9100(0.9017) Steps 0(0.00) | Grad Norm 11.8326(10.0801) | Total Time 0.00(0.00)\n",
      "Iter 2870 | Time 15.5538(15.4242) | Bit/dim 1.1455(1.1632) | Xent 2.3026(2.3026) | Loss 1.1455(1.1632) | Error 0.9089(0.9019) Steps 0(0.00) | Grad Norm 3.4139(8.4849) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 15.6097(15.4217) | Bit/dim 1.1510(1.1599) | Xent 2.3026(2.3026) | Loss 1.1510(1.1599) | Error 0.8867(0.9014) Steps 0(0.00) | Grad Norm 4.5581(7.1769) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 15.7346(15.4452) | Bit/dim 1.1322(1.1557) | Xent 2.3026(2.3026) | Loss 1.1322(1.1557) | Error 0.8989(0.9015) Steps 0(0.00) | Grad Norm 2.5083(5.9354) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 15.5006(15.4725) | Bit/dim 1.1493(1.1541) | Xent 2.3026(2.3026) | Loss 1.1493(1.1541) | Error 0.9000(0.9011) Steps 0(0.00) | Grad Norm 6.1197(5.1038) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 60.4201, Epoch Time 1093.8574(1014.5978), Bit/dim 1.1465, Xent 2.3026, Loss 1.1465, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2910 | Time 15.3711(15.4856) | Bit/dim 1.1483(1.1550) | Xent 2.3026(2.3026) | Loss 1.1483(1.1550) | Error 0.9167(0.9004) Steps 0(0.00) | Grad Norm 8.2504(5.7251) | Total Time 0.00(0.00)\n",
      "Iter 2920 | Time 15.4595(15.4914) | Bit/dim 1.1566(1.1523) | Xent 2.3026(2.3026) | Loss 1.1566(1.1523) | Error 0.8844(0.9003) Steps 0(0.00) | Grad Norm 7.7849(5.4745) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 15.0287(15.4778) | Bit/dim 1.2225(1.1575) | Xent 2.3026(2.3026) | Loss 1.2225(1.1575) | Error 0.8889(0.9000) Steps 0(0.00) | Grad Norm 19.8345(7.5104) | Total Time 0.00(0.00)\n",
      "Iter 2940 | Time 15.8725(15.4734) | Bit/dim 1.1933(1.1758) | Xent 2.3026(2.3026) | Loss 1.1933(1.1758) | Error 0.9089(0.9008) Steps 0(0.00) | Grad Norm 5.1016(9.2389) | Total Time 0.00(0.00)\n",
      "Iter 2950 | Time 15.7914(15.5016) | Bit/dim 1.1864(1.1846) | Xent 2.3026(2.3026) | Loss 1.1864(1.1846) | Error 0.9133(0.9022) Steps 0(0.00) | Grad Norm 13.1678(9.6651) | Total Time 0.00(0.00)\n",
      "Iter 2960 | Time 15.5678(15.5077) | Bit/dim 1.1670(1.1809) | Xent 2.3026(2.3026) | Loss 1.1670(1.1809) | Error 0.8922(0.9015) Steps 0(0.00) | Grad Norm 6.0422(8.9173) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 60.9047, Epoch Time 1098.5698(1017.1169), Bit/dim 1.1455, Xent 2.3026, Loss 1.1455, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2970 | Time 15.4618(15.5093) | Bit/dim 1.1618(1.1735) | Xent 2.3026(2.3026) | Loss 1.1618(1.1735) | Error 0.8933(0.9015) Steps 0(0.00) | Grad Norm 6.2206(7.6536) | Total Time 0.00(0.00)\n",
      "Iter 2980 | Time 15.3793(15.4572) | Bit/dim 1.1488(1.1680) | Xent 2.3026(2.3026) | Loss 1.1488(1.1680) | Error 0.9222(0.9010) Steps 0(0.00) | Grad Norm 5.5147(6.9537) | Total Time 0.00(0.00)\n",
      "Iter 2990 | Time 15.1461(15.4021) | Bit/dim 1.1431(1.1619) | Xent 2.3026(2.3026) | Loss 1.1431(1.1619) | Error 0.9167(0.9003) Steps 0(0.00) | Grad Norm 8.5586(6.7261) | Total Time 0.00(0.00)\n",
      "Iter 3000 | Time 15.3321(15.3839) | Bit/dim 1.1642(1.1580) | Xent 2.3026(2.3026) | Loss 1.1642(1.1580) | Error 0.9078(0.8996) Steps 0(0.00) | Grad Norm 11.1773(6.6210) | Total Time 0.00(0.00)\n",
      "Iter 3010 | Time 15.6988(15.3427) | Bit/dim 1.2308(1.1629) | Xent 2.3026(2.3026) | Loss 1.2308(1.1629) | Error 0.9000(0.9012) Steps 0(0.00) | Grad Norm 23.9356(8.4796) | Total Time 0.00(0.00)\n",
      "Iter 3020 | Time 15.5208(15.3347) | Bit/dim 1.1882(1.1657) | Xent 2.3026(2.3026) | Loss 1.1882(1.1657) | Error 0.8967(0.9012) Steps 0(0.00) | Grad Norm 19.4920(9.3634) | Total Time 0.00(0.00)\n",
      "Iter 3030 | Time 15.4267(15.3086) | Bit/dim 1.1439(1.1635) | Xent 2.3026(2.3026) | Loss 1.1439(1.1635) | Error 0.9178(0.9022) Steps 0(0.00) | Grad Norm 1.8895(9.2786) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 57.2682, Epoch Time 1081.3719(1019.0446), Bit/dim 1.1405, Xent 2.3026, Loss 1.1405, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3040 | Time 14.7809(15.3229) | Bit/dim 1.1429(1.1600) | Xent 2.3026(2.3026) | Loss 1.1429(1.1600) | Error 0.9056(0.9021) Steps 0(0.00) | Grad Norm 4.6327(8.1652) | Total Time 0.00(0.00)\n",
      "Iter 3050 | Time 15.4527(15.3180) | Bit/dim 1.1434(1.1561) | Xent 2.3026(2.3026) | Loss 1.1434(1.1561) | Error 0.8822(0.9013) Steps 0(0.00) | Grad Norm 5.5121(7.1243) | Total Time 0.00(0.00)\n",
      "Iter 3060 | Time 15.5939(15.3249) | Bit/dim 1.1464(1.1530) | Xent 2.3026(2.3026) | Loss 1.1464(1.1530) | Error 0.8900(0.9007) Steps 0(0.00) | Grad Norm 3.7755(6.7962) | Total Time 0.00(0.00)\n",
      "Iter 3070 | Time 15.0722(15.3527) | Bit/dim 1.1522(1.1504) | Xent 2.3026(2.3026) | Loss 1.1522(1.1504) | Error 0.9078(0.9007) Steps 0(0.00) | Grad Norm 6.0252(6.2985) | Total Time 0.00(0.00)\n",
      "Iter 3080 | Time 15.2033(15.3565) | Bit/dim 1.1292(1.1489) | Xent 2.3026(2.3026) | Loss 1.1292(1.1489) | Error 0.9089(0.9004) Steps 0(0.00) | Grad Norm 3.5895(6.0796) | Total Time 0.00(0.00)\n",
      "Iter 3090 | Time 15.2892(15.3349) | Bit/dim 1.1783(1.1494) | Xent 2.3026(2.3026) | Loss 1.1783(1.1494) | Error 0.9044(0.9013) Steps 0(0.00) | Grad Norm 13.7749(7.3665) | Total Time 0.00(0.00)\n",
      "Iter 3100 | Time 16.0539(15.3565) | Bit/dim 1.2895(1.1783) | Xent 2.3026(2.3026) | Loss 1.2895(1.1783) | Error 0.9167(0.9022) Steps 0(0.00) | Grad Norm 11.5134(9.4329) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 59.4128, Epoch Time 1087.6128(1021.1016), Bit/dim 1.1985, Xent 2.3026, Loss 1.1985, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3110 | Time 15.6637(15.4153) | Bit/dim 1.1937(1.1902) | Xent 2.3026(2.3026) | Loss 1.1937(1.1902) | Error 0.8900(0.9032) Steps 0(0.00) | Grad Norm 3.6273(8.9841) | Total Time 0.00(0.00)\n",
      "Iter 3120 | Time 15.2035(15.4254) | Bit/dim 1.1677(1.1857) | Xent 2.3026(2.3026) | Loss 1.1677(1.1857) | Error 0.8944(0.9028) Steps 0(0.00) | Grad Norm 7.8823(7.9509) | Total Time 0.00(0.00)\n",
      "Iter 3130 | Time 14.9697(15.2608) | Bit/dim 1.1500(1.1772) | Xent 2.3026(2.3026) | Loss 1.1500(1.1772) | Error 0.8956(0.9031) Steps 0(0.00) | Grad Norm 8.2057(7.3217) | Total Time 0.00(0.00)\n",
      "Iter 3140 | Time 15.2005(15.1539) | Bit/dim 1.1413(1.1688) | Xent 2.3026(2.3026) | Loss 1.1413(1.1688) | Error 0.9033(0.9028) Steps 0(0.00) | Grad Norm 1.6609(6.3811) | Total Time 0.00(0.00)\n",
      "Iter 3150 | Time 14.7575(15.0562) | Bit/dim 1.1490(1.1623) | Xent 2.3026(2.3026) | Loss 1.1490(1.1623) | Error 0.8967(0.9014) Steps 0(0.00) | Grad Norm 6.1428(5.6572) | Total Time 0.00(0.00)\n",
      "Iter 3160 | Time 14.5307(14.9469) | Bit/dim 1.1374(1.1573) | Xent 2.3026(2.3026) | Loss 1.1374(1.1573) | Error 0.9089(0.8999) Steps 0(0.00) | Grad Norm 8.3726(5.6117) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 54.9274, Epoch Time 1057.1271(1022.1824), Bit/dim 1.1414, Xent 2.3026, Loss 1.1414, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3170 | Time 14.8653(14.8845) | Bit/dim 1.1533(1.1543) | Xent 2.3026(2.3026) | Loss 1.1533(1.1543) | Error 0.9033(0.9002) Steps 0(0.00) | Grad Norm 11.9681(6.2364) | Total Time 0.00(0.00)\n",
      "Iter 3180 | Time 14.4557(14.8576) | Bit/dim 1.2937(1.1706) | Xent 2.3026(2.3026) | Loss 1.2937(1.1706) | Error 0.9044(0.8999) Steps 0(0.00) | Grad Norm 9.0487(8.1984) | Total Time 0.00(0.00)\n",
      "Iter 3190 | Time 14.9601(14.8267) | Bit/dim 1.2274(1.1845) | Xent 2.3026(2.3026) | Loss 1.2274(1.1845) | Error 0.9000(0.9004) Steps 0(0.00) | Grad Norm 21.1891(8.8211) | Total Time 0.00(0.00)\n",
      "Iter 3200 | Time 14.3222(14.7415) | Bit/dim 1.1575(1.1845) | Xent 2.3026(2.3026) | Loss 1.1575(1.1845) | Error 0.9144(0.9014) Steps 0(0.00) | Grad Norm 2.3729(9.2572) | Total Time 0.00(0.00)\n",
      "Iter 3210 | Time 14.7195(14.6856) | Bit/dim 1.1640(1.1775) | Xent 2.3026(2.3026) | Loss 1.1640(1.1775) | Error 0.8978(0.9016) Steps 0(0.00) | Grad Norm 6.9500(8.5953) | Total Time 0.00(0.00)\n",
      "Iter 3220 | Time 14.1683(14.5820) | Bit/dim 1.1721(1.1728) | Xent 2.3026(2.3026) | Loss 1.1721(1.1728) | Error 0.8989(0.9017) Steps 0(0.00) | Grad Norm 9.9359(8.8765) | Total Time 0.00(0.00)\n",
      "Iter 3230 | Time 14.2712(14.5402) | Bit/dim 1.1402(1.1695) | Xent 2.3026(2.3026) | Loss 1.1402(1.1695) | Error 0.9056(0.9011) Steps 0(0.00) | Grad Norm 0.8408(8.7188) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 56.6526, Epoch Time 1031.5412(1022.4632), Bit/dim 1.1603, Xent 2.3026, Loss 1.1603, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3240 | Time 14.3435(14.4860) | Bit/dim 1.1550(1.1691) | Xent 2.3026(2.3026) | Loss 1.1550(1.1691) | Error 0.8878(0.9005) Steps 0(0.00) | Grad Norm 11.7399(9.8123) | Total Time 0.00(0.00)\n",
      "Iter 3250 | Time 14.6521(14.4377) | Bit/dim 1.1381(1.1662) | Xent 2.3026(2.3026) | Loss 1.1381(1.1662) | Error 0.9056(0.8993) Steps 0(0.00) | Grad Norm 7.0053(9.6696) | Total Time 0.00(0.00)\n",
      "Iter 3260 | Time 14.5704(14.3988) | Bit/dim 1.1383(1.1609) | Xent 2.3026(2.3026) | Loss 1.1383(1.1609) | Error 0.9122(0.8994) Steps 0(0.00) | Grad Norm 13.6174(8.7442) | Total Time 0.00(0.00)\n",
      "Iter 3270 | Time 14.4044(14.3591) | Bit/dim 1.1917(1.1637) | Xent 2.3026(2.3026) | Loss 1.1917(1.1637) | Error 0.9011(0.9014) Steps 0(0.00) | Grad Norm 23.1826(10.2384) | Total Time 0.00(0.00)\n",
      "Iter 3280 | Time 14.0267(14.3597) | Bit/dim 1.1892(1.1666) | Xent 2.3026(2.3026) | Loss 1.1892(1.1666) | Error 0.9022(0.9019) Steps 0(0.00) | Grad Norm 12.4475(10.9646) | Total Time 0.00(0.00)\n",
      "Iter 3290 | Time 14.2124(14.3631) | Bit/dim 1.1327(1.1623) | Xent 2.3026(2.3026) | Loss 1.1327(1.1623) | Error 0.9011(0.9017) Steps 0(0.00) | Grad Norm 6.7139(10.1319) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 54.6497, Epoch Time 1014.0788(1022.2116), Bit/dim 1.1345, Xent 2.3026, Loss 1.1345, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3300 | Time 14.3668(14.3569) | Bit/dim 1.1554(1.1577) | Xent 2.3026(2.3026) | Loss 1.1554(1.1577) | Error 0.9044(0.9018) Steps 0(0.00) | Grad Norm 4.7963(9.2730) | Total Time 0.00(0.00)\n",
      "Iter 3310 | Time 14.6749(14.3507) | Bit/dim 1.1616(1.1568) | Xent 2.3026(2.3026) | Loss 1.1616(1.1568) | Error 0.9033(0.9011) Steps 0(0.00) | Grad Norm 16.5428(9.8480) | Total Time 0.00(0.00)\n",
      "Iter 3320 | Time 14.1419(14.3373) | Bit/dim 1.1507(1.1534) | Xent 2.3026(2.3026) | Loss 1.1507(1.1534) | Error 0.9000(0.9013) Steps 0(0.00) | Grad Norm 3.5585(8.7805) | Total Time 0.00(0.00)\n",
      "Iter 3330 | Time 14.4314(14.3166) | Bit/dim 1.1304(1.1491) | Xent 2.3026(2.3026) | Loss 1.1304(1.1491) | Error 0.9100(0.9019) Steps 0(0.00) | Grad Norm 4.9302(7.7235) | Total Time 0.00(0.00)\n",
      "Iter 3340 | Time 14.4376(14.2992) | Bit/dim 1.1271(1.1439) | Xent 2.3026(2.3026) | Loss 1.1271(1.1439) | Error 0.8978(0.9015) Steps 0(0.00) | Grad Norm 2.8459(6.4508) | Total Time 0.00(0.00)\n",
      "Iter 3350 | Time 14.3128(14.3086) | Bit/dim 1.1236(1.1409) | Xent 2.3026(2.3026) | Loss 1.1236(1.1409) | Error 0.9078(0.9010) Steps 0(0.00) | Grad Norm 2.4480(5.4109) | Total Time 0.00(0.00)\n",
      "Iter 3360 | Time 14.4598(14.3198) | Bit/dim 1.1470(1.1399) | Xent 2.3026(2.3026) | Loss 1.1470(1.1399) | Error 0.9022(0.9014) Steps 0(0.00) | Grad Norm 10.6481(5.1875) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 53.2592, Epoch Time 1011.8153(1021.8997), Bit/dim 1.1268, Xent 2.3026, Loss 1.1268, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3370 | Time 14.2745(14.3101) | Bit/dim 1.1396(1.1389) | Xent 2.3026(2.3026) | Loss 1.1396(1.1389) | Error 0.9000(0.9017) Steps 0(0.00) | Grad Norm 8.9384(5.6054) | Total Time 0.00(0.00)\n",
      "Iter 3380 | Time 14.8404(14.3560) | Bit/dim 1.1541(1.1382) | Xent 2.3026(2.3026) | Loss 1.1541(1.1382) | Error 0.9089(0.9026) Steps 0(0.00) | Grad Norm 13.8786(5.7181) | Total Time 0.00(0.00)\n",
      "Iter 3390 | Time 14.0595(14.3586) | Bit/dim 1.2084(1.1520) | Xent 2.3026(2.3026) | Loss 1.2084(1.1520) | Error 0.8956(0.9023) Steps 0(0.00) | Grad Norm 8.4203(7.7624) | Total Time 0.00(0.00)\n",
      "Iter 3400 | Time 14.8971(14.4448) | Bit/dim 1.2268(1.1620) | Xent 2.3026(2.3026) | Loss 1.2268(1.1620) | Error 0.8911(0.9022) Steps 0(0.00) | Grad Norm 18.0933(9.1052) | Total Time 0.00(0.00)\n",
      "Iter 3410 | Time 14.3485(14.4826) | Bit/dim 1.1771(1.1718) | Xent 2.3026(2.3026) | Loss 1.1771(1.1718) | Error 0.9000(0.9001) Steps 0(0.00) | Grad Norm 5.6082(9.8965) | Total Time 0.00(0.00)\n",
      "Iter 3420 | Time 14.5408(14.5500) | Bit/dim 1.1682(1.1734) | Xent 2.3026(2.3026) | Loss 1.1682(1.1734) | Error 0.9189(0.9021) Steps 0(0.00) | Grad Norm 6.5060(10.5655) | Total Time 0.00(0.00)\n",
      "Iter 3430 | Time 14.4638(14.5125) | Bit/dim 1.1440(1.1679) | Xent 2.3026(2.3026) | Loss 1.1440(1.1679) | Error 0.9089(0.9008) Steps 0(0.00) | Grad Norm 3.1943(9.4888) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 55.2557, Epoch Time 1028.2967(1022.0916), Bit/dim 1.1332, Xent 2.3026, Loss 1.1332, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3440 | Time 14.2285(14.4919) | Bit/dim 1.1357(1.1609) | Xent 2.3026(2.3026) | Loss 1.1357(1.1609) | Error 0.9033(0.9008) Steps 0(0.00) | Grad Norm 9.1400(8.6485) | Total Time 0.00(0.00)\n",
      "Iter 3450 | Time 13.9097(14.4674) | Bit/dim 1.1741(1.1600) | Xent 2.3026(2.3026) | Loss 1.1741(1.1600) | Error 0.9067(0.9018) Steps 0(0.00) | Grad Norm 13.7223(9.4300) | Total Time 0.00(0.00)\n",
      "Iter 3460 | Time 14.8596(14.4942) | Bit/dim 1.2094(1.1656) | Xent 2.3026(2.3026) | Loss 1.2094(1.1656) | Error 0.8900(0.9006) Steps 0(0.00) | Grad Norm 23.2958(10.6432) | Total Time 0.00(0.00)\n",
      "Iter 3470 | Time 14.3576(14.4923) | Bit/dim 1.1561(1.1663) | Xent 2.3026(2.3026) | Loss 1.1561(1.1663) | Error 0.9100(0.9001) Steps 0(0.00) | Grad Norm 9.2176(10.6223) | Total Time 0.00(0.00)\n",
      "Iter 3480 | Time 14.5465(14.4686) | Bit/dim 1.1386(1.1606) | Xent 2.3026(2.3026) | Loss 1.1386(1.1606) | Error 0.8989(0.9010) Steps 0(0.00) | Grad Norm 1.7812(9.5076) | Total Time 0.00(0.00)\n",
      "Iter 3490 | Time 14.3727(14.4409) | Bit/dim 1.1352(1.1555) | Xent 2.3026(2.3026) | Loss 1.1352(1.1555) | Error 0.9122(0.9024) Steps 0(0.00) | Grad Norm 5.9903(8.3478) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 58.3090, Epoch Time 1025.8244(1022.2036), Bit/dim 1.1479, Xent 2.3026, Loss 1.1479, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3500 | Time 14.3558(14.4359) | Bit/dim 1.1474(1.1515) | Xent 2.3026(2.3026) | Loss 1.1474(1.1515) | Error 0.9056(0.9010) Steps 0(0.00) | Grad Norm 8.9902(8.4877) | Total Time 0.00(0.00)\n",
      "Iter 3510 | Time 14.6751(14.4558) | Bit/dim 1.1574(1.1510) | Xent 2.3026(2.3026) | Loss 1.1574(1.1510) | Error 0.8900(0.9017) Steps 0(0.00) | Grad Norm 4.7512(8.6860) | Total Time 0.00(0.00)\n",
      "Iter 3520 | Time 14.6615(14.4881) | Bit/dim 1.1410(1.1502) | Xent 2.3026(2.3026) | Loss 1.1410(1.1502) | Error 0.8978(0.9013) Steps 0(0.00) | Grad Norm 9.1508(9.4179) | Total Time 0.00(0.00)\n",
      "Iter 3530 | Time 14.4896(14.4790) | Bit/dim 1.1295(1.1454) | Xent 2.3026(2.3026) | Loss 1.1295(1.1454) | Error 0.9044(0.8998) Steps 0(0.00) | Grad Norm 11.6317(8.4027) | Total Time 0.00(0.00)\n",
      "Iter 3540 | Time 14.7308(14.4760) | Bit/dim 1.1316(1.1449) | Xent 2.3026(2.3026) | Loss 1.1316(1.1449) | Error 0.9089(0.9021) Steps 0(0.00) | Grad Norm 5.3373(9.1093) | Total Time 0.00(0.00)\n",
      "Iter 3550 | Time 14.3108(14.4941) | Bit/dim 1.1484(1.1469) | Xent 2.3026(2.3026) | Loss 1.1484(1.1469) | Error 0.9100(0.9022) Steps 0(0.00) | Grad Norm 9.1956(9.6994) | Total Time 0.00(0.00)\n",
      "Iter 3560 | Time 14.2467(14.5001) | Bit/dim 1.1451(1.1448) | Xent 2.3026(2.3026) | Loss 1.1451(1.1448) | Error 0.8844(0.9009) Steps 0(0.00) | Grad Norm 10.7002(9.0627) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 54.8218, Epoch Time 1026.9922(1022.3473), Bit/dim 1.1326, Xent 2.3026, Loss 1.1326, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3570 | Time 13.8383(14.4628) | Bit/dim 1.1630(1.1461) | Xent 2.3026(2.3026) | Loss 1.1630(1.1461) | Error 0.9000(0.9005) Steps 0(0.00) | Grad Norm 13.3772(9.8576) | Total Time 0.00(0.00)\n",
      "Iter 3580 | Time 14.7295(14.5450) | Bit/dim 1.1424(1.1468) | Xent 2.3026(2.3026) | Loss 1.1424(1.1468) | Error 0.9067(0.9013) Steps 0(0.00) | Grad Norm 8.4842(10.0396) | Total Time 0.00(0.00)\n",
      "Iter 3590 | Time 14.3088(14.5524) | Bit/dim 1.1350(1.1440) | Xent 2.3026(2.3026) | Loss 1.1350(1.1440) | Error 0.9189(0.9021) Steps 0(0.00) | Grad Norm 8.1025(9.2148) | Total Time 0.00(0.00)\n",
      "Iter 3600 | Time 14.0346(14.5313) | Bit/dim 1.1752(1.1450) | Xent 2.3026(2.3026) | Loss 1.1752(1.1450) | Error 0.8911(0.9014) Steps 0(0.00) | Grad Norm 11.4811(9.7108) | Total Time 0.00(0.00)\n",
      "Iter 3610 | Time 14.4951(14.5295) | Bit/dim 1.1431(1.1456) | Xent 2.3026(2.3026) | Loss 1.1431(1.1456) | Error 0.9122(0.9019) Steps 0(0.00) | Grad Norm 10.6792(9.8010) | Total Time 0.00(0.00)\n",
      "Iter 3620 | Time 14.4717(14.5806) | Bit/dim 1.1238(1.1454) | Xent 2.3026(2.3026) | Loss 1.1238(1.1454) | Error 0.8978(0.9012) Steps 0(0.00) | Grad Norm 8.3402(10.0266) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 55.5944, Epoch Time 1032.2913(1022.6456), Bit/dim 1.1255, Xent 2.3026, Loss 1.1255, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3630 | Time 14.7681(14.5979) | Bit/dim 1.1247(1.1417) | Xent 2.3026(2.3026) | Loss 1.1247(1.1417) | Error 0.8989(0.9013) Steps 0(0.00) | Grad Norm 4.2226(8.7034) | Total Time 0.00(0.00)\n",
      "Iter 3640 | Time 14.6594(14.6250) | Bit/dim 1.1295(1.1379) | Xent 2.3026(2.3026) | Loss 1.1295(1.1379) | Error 0.9011(0.9025) Steps 0(0.00) | Grad Norm 5.3010(7.5419) | Total Time 0.00(0.00)\n",
      "Iter 3650 | Time 14.7548(14.6399) | Bit/dim 1.1368(1.1357) | Xent 2.3026(2.3026) | Loss 1.1368(1.1357) | Error 0.8911(0.9020) Steps 0(0.00) | Grad Norm 2.8688(6.5206) | Total Time 0.00(0.00)\n",
      "Iter 3660 | Time 14.5626(14.6373) | Bit/dim 1.1207(1.1326) | Xent 2.3026(2.3026) | Loss 1.1207(1.1326) | Error 0.8978(0.9009) Steps 0(0.00) | Grad Norm 5.6440(5.7761) | Total Time 0.00(0.00)\n",
      "Iter 3670 | Time 14.5405(14.6421) | Bit/dim 1.1243(1.1303) | Xent 2.3026(2.3026) | Loss 1.1243(1.1303) | Error 0.9044(0.9016) Steps 0(0.00) | Grad Norm 1.0083(4.8691) | Total Time 0.00(0.00)\n",
      "Iter 3680 | Time 14.7822(14.6311) | Bit/dim 1.1205(1.1291) | Xent 2.3026(2.3026) | Loss 1.1205(1.1291) | Error 0.8978(0.8997) Steps 0(0.00) | Grad Norm 6.1387(5.1004) | Total Time 0.00(0.00)\n",
      "Iter 3690 | Time 15.1675(14.6699) | Bit/dim 1.1787(1.1338) | Xent 2.3026(2.3026) | Loss 1.1787(1.1338) | Error 0.8922(0.9009) Steps 0(0.00) | Grad Norm 9.8906(6.3390) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 55.6821, Epoch Time 1040.0919(1023.1690), Bit/dim 1.2469, Xent 2.3026, Loss 1.2469, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3700 | Time 14.2377(14.6792) | Bit/dim 1.2530(1.1497) | Xent 2.3026(2.3026) | Loss 1.2530(1.1497) | Error 0.8978(0.9011) Steps 0(0.00) | Grad Norm 21.1548(8.5172) | Total Time 0.00(0.00)\n",
      "Iter 3710 | Time 15.1965(14.7471) | Bit/dim 1.2283(1.1668) | Xent 2.3026(2.3026) | Loss 1.2283(1.1668) | Error 0.9067(0.9008) Steps 0(0.00) | Grad Norm 24.9985(9.7729) | Total Time 0.00(0.00)\n",
      "Iter 3720 | Time 14.6865(14.7785) | Bit/dim 1.1492(1.1665) | Xent 2.3026(2.3026) | Loss 1.1492(1.1665) | Error 0.9122(0.9010) Steps 0(0.00) | Grad Norm 7.5066(9.6540) | Total Time 0.00(0.00)\n",
      "Iter 3730 | Time 14.4508(14.7350) | Bit/dim 1.1354(1.1595) | Xent 2.3026(2.3026) | Loss 1.1354(1.1595) | Error 0.9067(0.9015) Steps 0(0.00) | Grad Norm 2.4279(8.4902) | Total Time 0.00(0.00)\n",
      "Iter 3740 | Time 14.7328(14.6892) | Bit/dim 1.1349(1.1517) | Xent 2.3026(2.3026) | Loss 1.1349(1.1517) | Error 0.9100(0.9021) Steps 0(0.00) | Grad Norm 4.7519(7.4347) | Total Time 0.00(0.00)\n",
      "Iter 3750 | Time 14.7402(14.7105) | Bit/dim 1.1042(1.1437) | Xent 2.3026(2.3026) | Loss 1.1042(1.1437) | Error 0.9056(0.9021) Steps 0(0.00) | Grad Norm 2.3669(6.4675) | Total Time 0.00(0.00)\n",
      "Iter 3760 | Time 14.5591(14.7143) | Bit/dim 1.1357(1.1393) | Xent 2.3026(2.3026) | Loss 1.1357(1.1393) | Error 0.8978(0.9015) Steps 0(0.00) | Grad Norm 7.6468(5.9734) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 55.8048, Epoch Time 1042.2530(1023.7415), Bit/dim 1.1172, Xent 2.3026, Loss 1.1172, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3770 | Time 14.5673(14.6995) | Bit/dim 1.1220(1.1361) | Xent 2.3026(2.3026) | Loss 1.1220(1.1361) | Error 0.9144(0.9016) Steps 0(0.00) | Grad Norm 8.9566(5.8630) | Total Time 0.00(0.00)\n",
      "Iter 3780 | Time 14.4879(14.6887) | Bit/dim 1.1297(1.1339) | Xent 2.3026(2.3026) | Loss 1.1297(1.1339) | Error 0.9022(0.9017) Steps 0(0.00) | Grad Norm 12.5460(6.4788) | Total Time 0.00(0.00)\n",
      "Iter 3790 | Time 14.4968(14.6884) | Bit/dim 1.1369(1.1332) | Xent 2.3026(2.3026) | Loss 1.1369(1.1332) | Error 0.8978(0.9017) Steps 0(0.00) | Grad Norm 8.9692(6.8537) | Total Time 0.00(0.00)\n",
      "Iter 3800 | Time 14.5402(14.6773) | Bit/dim 1.1059(1.1318) | Xent 2.3026(2.3026) | Loss 1.1059(1.1318) | Error 0.8989(0.9013) Steps 0(0.00) | Grad Norm 2.2748(6.9988) | Total Time 0.00(0.00)\n",
      "Iter 3810 | Time 14.5446(14.6744) | Bit/dim 1.1219(1.1302) | Xent 2.3026(2.3026) | Loss 1.1219(1.1302) | Error 0.9000(0.9008) Steps 0(0.00) | Grad Norm 9.8185(6.7548) | Total Time 0.00(0.00)\n",
      "Iter 3820 | Time 14.6490(14.6451) | Bit/dim 1.1904(1.1316) | Xent 2.3026(2.3026) | Loss 1.1904(1.1316) | Error 0.9156(0.9017) Steps 0(0.00) | Grad Norm 36.2959(7.9945) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 54.7145, Epoch Time 1035.2313(1024.0862), Bit/dim 1.1774, Xent 2.3026, Loss 1.1774, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3830 | Time 15.2999(14.6690) | Bit/dim 1.1821(1.1594) | Xent 2.3026(2.3026) | Loss 1.1821(1.1594) | Error 0.9000(0.9024) Steps 0(0.00) | Grad Norm 5.8724(8.5017) | Total Time 0.00(0.00)\n",
      "Iter 3840 | Time 14.4840(14.6727) | Bit/dim 1.1396(1.1577) | Xent 2.3026(2.3026) | Loss 1.1396(1.1577) | Error 0.9067(0.9020) Steps 0(0.00) | Grad Norm 3.6283(8.3431) | Total Time 0.00(0.00)\n",
      "Iter 3850 | Time 14.0360(14.6403) | Bit/dim 1.1862(1.1638) | Xent 2.3026(2.3026) | Loss 1.1862(1.1638) | Error 0.8856(0.9001) Steps 0(0.00) | Grad Norm 12.0071(10.0245) | Total Time 0.00(0.00)\n",
      "Iter 3860 | Time 14.4857(14.5698) | Bit/dim 1.1673(1.1675) | Xent 2.3026(2.3026) | Loss 1.1673(1.1675) | Error 0.9100(0.9007) Steps 0(0.00) | Grad Norm 14.2179(10.5960) | Total Time 0.00(0.00)\n",
      "Iter 3870 | Time 14.3843(14.5176) | Bit/dim 1.1344(1.1601) | Xent 2.3026(2.3026) | Loss 1.1344(1.1601) | Error 0.9022(0.9027) Steps 0(0.00) | Grad Norm 4.2444(9.4287) | Total Time 0.00(0.00)\n",
      "Iter 3880 | Time 14.0515(14.4469) | Bit/dim 1.1320(1.1528) | Xent 2.3026(2.3026) | Loss 1.1320(1.1528) | Error 0.8922(0.9024) Steps 0(0.00) | Grad Norm 6.5103(8.3109) | Total Time 0.00(0.00)\n",
      "Iter 3890 | Time 14.3183(14.4100) | Bit/dim 1.1051(1.1446) | Xent 2.3026(2.3026) | Loss 1.1051(1.1446) | Error 0.9100(0.9015) Steps 0(0.00) | Grad Norm 7.3853(7.3771) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 53.3972, Epoch Time 1021.1911(1023.9993), Bit/dim 1.1162, Xent 2.3026, Loss 1.1162, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3900 | Time 13.8549(14.3711) | Bit/dim 1.2017(1.1467) | Xent 2.3026(2.3026) | Loss 1.2017(1.1467) | Error 0.9144(0.9009) Steps 0(0.00) | Grad Norm 13.2231(8.6858) | Total Time 0.00(0.00)\n",
      "Iter 3910 | Time 14.6607(14.3763) | Bit/dim 1.1595(1.1557) | Xent 2.3026(2.3026) | Loss 1.1595(1.1557) | Error 0.9000(0.9003) Steps 0(0.00) | Grad Norm 14.8446(9.9309) | Total Time 0.00(0.00)\n",
      "Iter 3920 | Time 14.5275(14.3857) | Bit/dim 1.1373(1.1514) | Xent 2.3026(2.3026) | Loss 1.1373(1.1514) | Error 0.9033(0.9014) Steps 0(0.00) | Grad Norm 4.1550(9.1123) | Total Time 0.00(0.00)\n",
      "Iter 3930 | Time 14.5820(14.3932) | Bit/dim 1.1319(1.1451) | Xent 2.3026(2.3026) | Loss 1.1319(1.1451) | Error 0.9144(0.9018) Steps 0(0.00) | Grad Norm 7.4802(7.9196) | Total Time 0.00(0.00)\n",
      "Iter 3940 | Time 13.8814(14.4107) | Bit/dim 1.1689(1.1425) | Xent 2.3026(2.3026) | Loss 1.1689(1.1425) | Error 0.8944(0.9010) Steps 0(0.00) | Grad Norm 14.6579(8.2857) | Total Time 0.00(0.00)\n",
      "Iter 3950 | Time 14.9945(14.4627) | Bit/dim 1.1544(1.1435) | Xent 2.3026(2.3026) | Loss 1.1544(1.1435) | Error 0.9089(0.9024) Steps 0(0.00) | Grad Norm 23.6712(9.4298) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 53.4379, Epoch Time 1023.2648(1023.9773), Bit/dim 1.1517, Xent 2.3026, Loss 1.1517, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3960 | Time 14.2054(14.5198) | Bit/dim 1.1565(1.1532) | Xent 2.3026(2.3026) | Loss 1.1565(1.1532) | Error 0.9178(0.9018) Steps 0(0.00) | Grad Norm 8.9090(10.3806) | Total Time 0.00(0.00)\n",
      "Iter 3970 | Time 14.6227(14.4812) | Bit/dim 1.1394(1.1502) | Xent 2.3026(2.3026) | Loss 1.1394(1.1502) | Error 0.9000(0.9034) Steps 0(0.00) | Grad Norm 12.4946(10.0319) | Total Time 0.00(0.00)\n",
      "Iter 3980 | Time 14.2408(14.4308) | Bit/dim 1.1307(1.1446) | Xent 2.3026(2.3026) | Loss 1.1307(1.1446) | Error 0.9000(0.9025) Steps 0(0.00) | Grad Norm 7.5741(8.9645) | Total Time 0.00(0.00)\n",
      "Iter 3990 | Time 14.5607(14.4249) | Bit/dim 1.1401(1.1390) | Xent 2.3026(2.3026) | Loss 1.1401(1.1390) | Error 0.8833(0.9004) Steps 0(0.00) | Grad Norm 4.0477(7.6953) | Total Time 0.00(0.00)\n",
      "Iter 4000 | Time 14.3605(14.4213) | Bit/dim 1.1199(1.1343) | Xent 2.3026(2.3026) | Loss 1.1199(1.1343) | Error 0.8867(0.9003) Steps 0(0.00) | Grad Norm 4.1508(6.6869) | Total Time 0.00(0.00)\n",
      "Iter 4010 | Time 14.4716(14.4155) | Bit/dim 1.1213(1.1310) | Xent 2.3026(2.3026) | Loss 1.1213(1.1310) | Error 0.8944(0.9005) Steps 0(0.00) | Grad Norm 0.7842(5.7603) | Total Time 0.00(0.00)\n",
      "Iter 4020 | Time 14.5061(14.4488) | Bit/dim 1.1310(1.1288) | Xent 2.3026(2.3026) | Loss 1.1310(1.1288) | Error 0.8833(0.9008) Steps 0(0.00) | Grad Norm 2.1297(5.4943) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 55.4488, Epoch Time 1020.8491(1023.8835), Bit/dim 1.1134, Xent 2.3026, Loss 1.1134, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4030 | Time 14.4705(14.4619) | Bit/dim 1.1130(1.1267) | Xent 2.3026(2.3026) | Loss 1.1130(1.1267) | Error 0.8967(0.9004) Steps 0(0.00) | Grad Norm 3.4717(5.6937) | Total Time 0.00(0.00)\n",
      "Iter 4040 | Time 14.5628(14.4917) | Bit/dim 1.1144(1.1246) | Xent 2.3026(2.3026) | Loss 1.1144(1.1246) | Error 0.8933(0.8998) Steps 0(0.00) | Grad Norm 1.4258(5.9619) | Total Time 0.00(0.00)\n",
      "Iter 4050 | Time 14.8099(14.5243) | Bit/dim 1.2452(1.1426) | Xent 2.3026(2.3026) | Loss 1.2452(1.1426) | Error 0.8878(0.9007) Steps 0(0.00) | Grad Norm 16.7130(8.2926) | Total Time 0.00(0.00)\n",
      "Iter 4060 | Time 14.7256(14.5954) | Bit/dim 1.1823(1.1559) | Xent 2.3026(2.3026) | Loss 1.1823(1.1559) | Error 0.9122(0.9005) Steps 0(0.00) | Grad Norm 8.8325(9.4384) | Total Time 0.00(0.00)\n",
      "Iter 4070 | Time 14.9053(14.5838) | Bit/dim 1.1732(1.1589) | Xent 2.3026(2.3026) | Loss 1.1732(1.1589) | Error 0.9000(0.9007) Steps 0(0.00) | Grad Norm 14.9613(9.6127) | Total Time 0.00(0.00)\n",
      "Iter 4080 | Time 14.5225(14.5759) | Bit/dim 1.1408(1.1548) | Xent 2.3026(2.3026) | Loss 1.1408(1.1548) | Error 0.9044(0.9004) Steps 0(0.00) | Grad Norm 7.7551(8.9221) | Total Time 0.00(0.00)\n",
      "Iter 4090 | Time 14.5604(14.5235) | Bit/dim 1.1363(1.1477) | Xent 2.3026(2.3026) | Loss 1.1363(1.1477) | Error 0.8811(0.9015) Steps 0(0.00) | Grad Norm 8.7015(7.8197) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 52.7479, Epoch Time 1028.6909(1024.0277), Bit/dim 1.1157, Xent 2.3026, Loss 1.1157, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4100 | Time 13.8097(14.4413) | Bit/dim 1.1528(1.1448) | Xent 2.3026(2.3026) | Loss 1.1528(1.1448) | Error 0.8911(0.9013) Steps 0(0.00) | Grad Norm 12.9816(8.6816) | Total Time 0.00(0.00)\n",
      "Iter 4110 | Time 14.5941(14.4220) | Bit/dim 1.1431(1.1449) | Xent 2.3026(2.3026) | Loss 1.1431(1.1449) | Error 0.9067(0.9013) Steps 0(0.00) | Grad Norm 17.3517(9.4230) | Total Time 0.00(0.00)\n",
      "Iter 4120 | Time 14.5301(14.4294) | Bit/dim 1.1324(1.1437) | Xent 2.3026(2.3026) | Loss 1.1324(1.1437) | Error 0.8956(0.9018) Steps 0(0.00) | Grad Norm 4.9075(9.7153) | Total Time 0.00(0.00)\n",
      "Iter 4130 | Time 14.5295(14.3765) | Bit/dim 1.1292(1.1475) | Xent 2.3026(2.3026) | Loss 1.1292(1.1475) | Error 0.9089(0.9035) Steps 0(0.00) | Grad Norm 4.1016(10.4893) | Total Time 0.00(0.00)\n",
      "Iter 4140 | Time 14.4482(14.3556) | Bit/dim 1.1280(1.1459) | Xent 2.3026(2.3026) | Loss 1.1280(1.1459) | Error 0.9056(0.9023) Steps 0(0.00) | Grad Norm 6.0666(9.7418) | Total Time 0.00(0.00)\n",
      "Iter 4150 | Time 14.0421(14.3555) | Bit/dim 1.1177(1.1409) | Xent 2.3026(2.3026) | Loss 1.1177(1.1409) | Error 0.8989(0.9004) Steps 0(0.00) | Grad Norm 4.0167(8.5323) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 52.2342, Epoch Time 1011.1960(1023.6427), Bit/dim 1.1189, Xent 2.3026, Loss 1.1189, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4160 | Time 14.4662(14.3442) | Bit/dim 1.1340(1.1363) | Xent 2.3026(2.3026) | Loss 1.1340(1.1363) | Error 0.9000(0.9005) Steps 0(0.00) | Grad Norm 12.1393(8.1437) | Total Time 0.00(0.00)\n",
      "Iter 4170 | Time 14.6150(14.3241) | Bit/dim 1.1307(1.1350) | Xent 2.3026(2.3026) | Loss 1.1307(1.1350) | Error 0.8922(0.9022) Steps 0(0.00) | Grad Norm 1.4579(8.7394) | Total Time 0.00(0.00)\n",
      "Iter 4180 | Time 14.2081(14.3649) | Bit/dim 1.1467(1.1335) | Xent 2.3026(2.3026) | Loss 1.1467(1.1335) | Error 0.8944(0.9023) Steps 0(0.00) | Grad Norm 13.6282(9.0349) | Total Time 0.00(0.00)\n",
      "Iter 4190 | Time 14.4428(14.4064) | Bit/dim 1.1038(1.1331) | Xent 2.3026(2.3026) | Loss 1.1038(1.1331) | Error 0.9044(0.9029) Steps 0(0.00) | Grad Norm 4.2491(9.2337) | Total Time 0.00(0.00)\n",
      "Iter 4200 | Time 14.6524(14.4752) | Bit/dim 1.1081(1.1321) | Xent 2.3026(2.3026) | Loss 1.1081(1.1321) | Error 0.9056(0.9016) Steps 0(0.00) | Grad Norm 2.0495(9.3236) | Total Time 0.00(0.00)\n",
      "Iter 4210 | Time 14.2506(14.5115) | Bit/dim 1.1519(1.1296) | Xent 2.3026(2.3026) | Loss 1.1519(1.1296) | Error 0.9011(0.9011) Steps 0(0.00) | Grad Norm 12.6909(8.8308) | Total Time 0.00(0.00)\n",
      "Iter 4220 | Time 14.4243(14.5450) | Bit/dim 1.1404(1.1313) | Xent 2.3026(2.3026) | Loss 1.1404(1.1313) | Error 0.9067(0.9005) Steps 0(0.00) | Grad Norm 10.3526(9.3337) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 53.8559, Epoch Time 1027.9443(1023.7718), Bit/dim 1.1225, Xent 2.3026, Loss 1.1225, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4230 | Time 14.3890(14.5991) | Bit/dim 1.1010(1.1287) | Xent 2.3026(2.3026) | Loss 1.1010(1.1287) | Error 0.9011(0.9005) Steps 0(0.00) | Grad Norm 9.4635(8.7960) | Total Time 0.00(0.00)\n",
      "Iter 4240 | Time 14.1868(14.5826) | Bit/dim 1.1308(1.1297) | Xent 2.3026(2.3026) | Loss 1.1308(1.1297) | Error 0.9111(0.9006) Steps 0(0.00) | Grad Norm 10.8599(9.3913) | Total Time 0.00(0.00)\n",
      "Iter 4250 | Time 14.8819(14.6554) | Bit/dim 1.1205(1.1297) | Xent 2.3026(2.3026) | Loss 1.1205(1.1297) | Error 0.8978(0.9002) Steps 0(0.00) | Grad Norm 5.1031(9.0859) | Total Time 0.00(0.00)\n",
      "Iter 4260 | Time 14.8070(14.7058) | Bit/dim 1.1031(1.1249) | Xent 2.3026(2.3026) | Loss 1.1031(1.1249) | Error 0.9011(0.8998) Steps 0(0.00) | Grad Norm 8.2752(8.0074) | Total Time 0.00(0.00)\n",
      "Iter 4270 | Time 15.5323(14.7439) | Bit/dim 1.2222(1.1319) | Xent 2.3026(2.3026) | Loss 1.2222(1.1319) | Error 0.9022(0.9004) Steps 0(0.00) | Grad Norm 29.9916(9.4700) | Total Time 0.00(0.00)\n",
      "Iter 4280 | Time 14.7058(14.7513) | Bit/dim 1.1425(1.1395) | Xent 2.3026(2.3026) | Loss 1.1425(1.1395) | Error 0.9089(0.9019) Steps 0(0.00) | Grad Norm 7.7050(9.6821) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 55.2289, Epoch Time 1041.8707(1024.3148), Bit/dim 1.1152, Xent 2.3026, Loss 1.1152, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4290 | Time 14.5161(14.6974) | Bit/dim 1.1122(1.1361) | Xent 2.3026(2.3026) | Loss 1.1122(1.1361) | Error 0.9044(0.9021) Steps 0(0.00) | Grad Norm 4.1815(9.0314) | Total Time 0.00(0.00)\n",
      "Iter 4300 | Time 14.3797(14.6551) | Bit/dim 1.1208(1.1317) | Xent 2.3026(2.3026) | Loss 1.1208(1.1317) | Error 0.9111(0.9026) Steps 0(0.00) | Grad Norm 7.7342(8.4672) | Total Time 0.00(0.00)\n",
      "Iter 4310 | Time 14.6836(14.6555) | Bit/dim 1.1258(1.1309) | Xent 2.3026(2.3026) | Loss 1.1258(1.1309) | Error 0.8833(0.9014) Steps 0(0.00) | Grad Norm 5.1015(8.5748) | Total Time 0.00(0.00)\n",
      "Iter 4320 | Time 14.9261(14.7047) | Bit/dim 1.1211(1.1278) | Xent 2.3026(2.3026) | Loss 1.1211(1.1278) | Error 0.8900(0.9001) Steps 0(0.00) | Grad Norm 14.5207(8.1217) | Total Time 0.00(0.00)\n",
      "Iter 4330 | Time 14.9626(14.6958) | Bit/dim 1.1428(1.1359) | Xent 2.3026(2.3026) | Loss 1.1428(1.1359) | Error 0.8911(0.9009) Steps 0(0.00) | Grad Norm 5.8450(9.5178) | Total Time 0.00(0.00)\n",
      "Iter 4340 | Time 14.5753(14.6849) | Bit/dim 1.1313(1.1390) | Xent 2.3026(2.3026) | Loss 1.1313(1.1390) | Error 0.9189(0.9027) Steps 0(0.00) | Grad Norm 9.8185(9.9836) | Total Time 0.00(0.00)\n",
      "Iter 4350 | Time 14.5685(14.7018) | Bit/dim 1.1216(1.1370) | Xent 2.3026(2.3026) | Loss 1.1216(1.1370) | Error 0.9100(0.9015) Steps 0(0.00) | Grad Norm 7.7530(9.6347) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 55.2082, Epoch Time 1039.4126(1024.7677), Bit/dim 1.1191, Xent 2.3026, Loss 1.1191, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4360 | Time 14.4222(14.6775) | Bit/dim 1.1036(1.1327) | Xent 2.3026(2.3026) | Loss 1.1036(1.1327) | Error 0.8944(0.9005) Steps 0(0.00) | Grad Norm 2.0154(8.6895) | Total Time 0.00(0.00)\n",
      "Iter 4370 | Time 14.5287(14.6331) | Bit/dim 1.1251(1.1270) | Xent 2.3026(2.3026) | Loss 1.1251(1.1270) | Error 0.9033(0.9011) Steps 0(0.00) | Grad Norm 1.8480(7.1220) | Total Time 0.00(0.00)\n",
      "Iter 4380 | Time 14.3139(14.6311) | Bit/dim 1.1092(1.1223) | Xent 2.3026(2.3026) | Loss 1.1092(1.1223) | Error 0.8922(0.9011) Steps 0(0.00) | Grad Norm 1.2965(5.6024) | Total Time 0.00(0.00)\n",
      "Iter 4390 | Time 14.8397(14.6754) | Bit/dim 1.1023(1.1196) | Xent 2.3026(2.3026) | Loss 1.1023(1.1196) | Error 0.8944(0.9008) Steps 0(0.00) | Grad Norm 0.8439(4.4585) | Total Time 0.00(0.00)\n",
      "Iter 4400 | Time 14.8405(14.7303) | Bit/dim 1.1104(1.1167) | Xent 2.3026(2.3026) | Loss 1.1104(1.1167) | Error 0.8911(0.9014) Steps 0(0.00) | Grad Norm 1.2208(3.5784) | Total Time 0.00(0.00)\n",
      "Iter 4410 | Time 14.6815(14.7531) | Bit/dim 1.1194(1.1149) | Xent 2.3026(2.3026) | Loss 1.1194(1.1149) | Error 0.8989(0.9012) Steps 0(0.00) | Grad Norm 8.9601(3.5501) | Total Time 0.00(0.00)\n",
      "Iter 4420 | Time 14.8116(14.7734) | Bit/dim 1.1120(1.1147) | Xent 2.3026(2.3026) | Loss 1.1120(1.1147) | Error 0.8967(0.9014) Steps 0(0.00) | Grad Norm 5.7273(4.4459) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 54.3446, Epoch Time 1040.0979(1025.2276), Bit/dim 1.1009, Xent 2.3026, Loss 1.1009, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4430 | Time 14.8664(14.8025) | Bit/dim 1.1176(1.1141) | Xent 2.3026(2.3026) | Loss 1.1176(1.1141) | Error 0.8956(0.9005) Steps 0(0.00) | Grad Norm 16.0105(5.4040) | Total Time 0.00(0.00)\n",
      "Iter 4440 | Time 14.7074(14.8176) | Bit/dim 1.1871(1.1386) | Xent 2.3026(2.3026) | Loss 1.1871(1.1386) | Error 0.9033(0.9011) Steps 0(0.00) | Grad Norm 7.1363(7.1960) | Total Time 0.00(0.00)\n",
      "Iter 4450 | Time 14.3895(14.8105) | Bit/dim 1.1645(1.1449) | Xent 2.3026(2.3026) | Loss 1.1645(1.1449) | Error 0.8967(0.9015) Steps 0(0.00) | Grad Norm 7.4797(7.6399) | Total Time 0.00(0.00)\n",
      "Iter 4460 | Time 14.9482(14.7408) | Bit/dim 1.1987(1.1601) | Xent 2.3026(2.3026) | Loss 1.1987(1.1601) | Error 0.8933(0.9013) Steps 0(0.00) | Grad Norm 16.7147(9.1466) | Total Time 0.00(0.00)\n",
      "Iter 4470 | Time 14.5143(14.6986) | Bit/dim 1.1203(1.1558) | Xent 2.3026(2.3026) | Loss 1.1203(1.1558) | Error 0.8956(0.9027) Steps 0(0.00) | Grad Norm 4.3239(8.6308) | Total Time 0.00(0.00)\n",
      "Iter 4480 | Time 14.2298(14.6080) | Bit/dim 1.1153(1.1484) | Xent 2.3026(2.3026) | Loss 1.1153(1.1484) | Error 0.9033(0.9005) Steps 0(0.00) | Grad Norm 5.0386(8.2534) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 53.5389, Epoch Time 1032.5160(1025.4462), Bit/dim 1.1071, Xent 2.3026, Loss 1.1071, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4490 | Time 14.0116(14.4845) | Bit/dim 1.1190(1.1413) | Xent 2.3026(2.3026) | Loss 1.1190(1.1413) | Error 0.9000(0.9009) Steps 0(0.00) | Grad Norm 1.7350(7.2420) | Total Time 0.00(0.00)\n",
      "Iter 4500 | Time 14.2766(14.3640) | Bit/dim 1.1240(1.1339) | Xent 2.3026(2.3026) | Loss 1.1240(1.1339) | Error 0.8989(0.9010) Steps 0(0.00) | Grad Norm 2.2914(5.9344) | Total Time 0.00(0.00)\n",
      "Iter 4510 | Time 14.2548(14.3259) | Bit/dim 1.1135(1.1280) | Xent 2.3026(2.3026) | Loss 1.1135(1.1280) | Error 0.8844(0.9002) Steps 0(0.00) | Grad Norm 0.6089(4.9191) | Total Time 0.00(0.00)\n",
      "Iter 4520 | Time 14.2835(14.3558) | Bit/dim 1.0938(1.1227) | Xent 2.3026(2.3026) | Loss 1.0938(1.1227) | Error 0.9100(0.9004) Steps 0(0.00) | Grad Norm 4.5365(4.4166) | Total Time 0.00(0.00)\n",
      "Iter 4530 | Time 14.6526(14.3842) | Bit/dim 1.1079(1.1181) | Xent 2.3026(2.3026) | Loss 1.1079(1.1181) | Error 0.9078(0.9003) Steps 0(0.00) | Grad Norm 3.0545(4.0113) | Total Time 0.00(0.00)\n",
      "Iter 4540 | Time 14.7957(14.4054) | Bit/dim 1.1152(1.1152) | Xent 2.3026(2.3026) | Loss 1.1152(1.1152) | Error 0.9000(0.9013) Steps 0(0.00) | Grad Norm 8.4842(4.4521) | Total Time 0.00(0.00)\n",
      "Iter 4550 | Time 14.6107(14.4575) | Bit/dim 1.0997(1.1133) | Xent 2.3026(2.3026) | Loss 1.0997(1.1133) | Error 0.9033(0.9018) Steps 0(0.00) | Grad Norm 2.7285(4.7633) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 55.7903, Epoch Time 1017.9960(1025.2227), Bit/dim 1.1077, Xent 2.3026, Loss 1.1077, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4560 | Time 14.8669(14.5358) | Bit/dim 1.2181(1.1389) | Xent 2.3026(2.3026) | Loss 1.2181(1.1389) | Error 0.9044(0.9015) Steps 0(0.00) | Grad Norm 6.0416(6.9971) | Total Time 0.00(0.00)\n",
      "Iter 4570 | Time 14.5906(14.5395) | Bit/dim 1.1515(1.1506) | Xent 2.3026(2.3026) | Loss 1.1515(1.1506) | Error 0.8956(0.9016) Steps 0(0.00) | Grad Norm 3.8075(6.8959) | Total Time 0.00(0.00)\n",
      "Iter 4580 | Time 14.2249(14.4963) | Bit/dim 1.2208(1.1608) | Xent 2.3026(2.3026) | Loss 1.2208(1.1608) | Error 0.9056(0.9023) Steps 0(0.00) | Grad Norm 12.8962(8.9327) | Total Time 0.00(0.00)\n",
      "Iter 4590 | Time 14.8335(14.4593) | Bit/dim 1.1282(1.1593) | Xent 2.3026(2.3026) | Loss 1.1282(1.1593) | Error 0.9033(0.9026) Steps 0(0.00) | Grad Norm 4.7326(8.8609) | Total Time 0.00(0.00)\n",
      "Iter 4600 | Time 14.1883(14.4147) | Bit/dim 1.1097(1.1516) | Xent 2.3026(2.3026) | Loss 1.1097(1.1516) | Error 0.8978(0.9012) Steps 0(0.00) | Grad Norm 6.8549(8.9218) | Total Time 0.00(0.00)\n",
      "Iter 4610 | Time 14.3351(14.3713) | Bit/dim 1.1090(1.1438) | Xent 2.3026(2.3026) | Loss 1.1090(1.1438) | Error 0.8967(0.9009) Steps 0(0.00) | Grad Norm 1.7076(7.7694) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 55.4512, Epoch Time 1020.0152(1025.0665), Bit/dim 1.1178, Xent 2.3026, Loss 1.1178, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4620 | Time 14.0651(14.3264) | Bit/dim 1.1234(1.1362) | Xent 2.3026(2.3026) | Loss 1.1234(1.1362) | Error 0.9011(0.9016) Steps 0(0.00) | Grad Norm 14.1889(7.4857) | Total Time 0.00(0.00)\n",
      "Iter 4630 | Time 14.8518(14.3832) | Bit/dim 1.1275(1.1344) | Xent 2.3026(2.3026) | Loss 1.1275(1.1344) | Error 0.9011(0.9022) Steps 0(0.00) | Grad Norm 6.6671(8.3008) | Total Time 0.00(0.00)\n",
      "Iter 4640 | Time 14.0297(14.4361) | Bit/dim 1.1154(1.1311) | Xent 2.3026(2.3026) | Loss 1.1154(1.1311) | Error 0.8989(0.9021) Steps 0(0.00) | Grad Norm 6.3203(8.9647) | Total Time 0.00(0.00)\n",
      "Iter 4650 | Time 14.4914(14.4521) | Bit/dim 1.1074(1.1259) | Xent 2.3026(2.3026) | Loss 1.1074(1.1259) | Error 0.8956(0.9008) Steps 0(0.00) | Grad Norm 2.3317(7.8741) | Total Time 0.00(0.00)\n",
      "Iter 4660 | Time 14.1336(14.4371) | Bit/dim 1.1043(1.1205) | Xent 2.3026(2.3026) | Loss 1.1043(1.1205) | Error 0.9167(0.9016) Steps 0(0.00) | Grad Norm 3.4396(6.6960) | Total Time 0.00(0.00)\n",
      "Iter 4670 | Time 14.6362(14.4505) | Bit/dim 1.1097(1.1171) | Xent 2.3026(2.3026) | Loss 1.1097(1.1171) | Error 0.9100(0.9016) Steps 0(0.00) | Grad Norm 2.5522(5.6798) | Total Time 0.00(0.00)\n",
      "Iter 4680 | Time 14.8342(14.5236) | Bit/dim 1.0888(1.1140) | Xent 2.3026(2.3026) | Loss 1.0888(1.1140) | Error 0.9056(0.9010) Steps 0(0.00) | Grad Norm 3.4829(4.9196) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 54.4571, Epoch Time 1030.5908(1025.2322), Bit/dim 1.0966, Xent 2.3026, Loss 1.0966, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4690 | Time 14.6269(14.6209) | Bit/dim 1.1051(1.1109) | Xent 2.3026(2.3026) | Loss 1.1051(1.1109) | Error 0.9022(0.9009) Steps 0(0.00) | Grad Norm 7.6430(4.4682) | Total Time 0.00(0.00)\n",
      "Iter 4700 | Time 14.9845(14.6809) | Bit/dim 1.1066(1.1110) | Xent 2.3026(2.3026) | Loss 1.1066(1.1110) | Error 0.8989(0.9015) Steps 0(0.00) | Grad Norm 4.4511(5.1173) | Total Time 0.00(0.00)\n",
      "Iter 4710 | Time 14.5076(14.6634) | Bit/dim 1.1168(1.1099) | Xent 2.3026(2.3026) | Loss 1.1168(1.1099) | Error 0.9078(0.9023) Steps 0(0.00) | Grad Norm 13.3844(6.0410) | Total Time 0.00(0.00)\n",
      "Iter 4720 | Time 14.7976(14.6946) | Bit/dim 1.1786(1.1277) | Xent 2.3026(2.3026) | Loss 1.1786(1.1277) | Error 0.8922(0.9014) Steps 0(0.00) | Grad Norm 5.8977(7.9446) | Total Time 0.00(0.00)\n",
      "Iter 4730 | Time 14.5300(14.6521) | Bit/dim 1.1387(1.1407) | Xent 2.3026(2.3026) | Loss 1.1387(1.1407) | Error 0.9122(0.9022) Steps 0(0.00) | Grad Norm 9.4433(8.9999) | Total Time 0.00(0.00)\n",
      "Iter 4740 | Time 14.0258(14.5340) | Bit/dim 1.1225(1.1375) | Xent 2.3026(2.3026) | Loss 1.1225(1.1375) | Error 0.8978(0.9007) Steps 0(0.00) | Grad Norm 10.2638(8.5150) | Total Time 0.00(0.00)\n",
      "Iter 4750 | Time 14.0424(14.4648) | Bit/dim 1.1324(1.1350) | Xent 2.3026(2.3026) | Loss 1.1324(1.1350) | Error 0.8956(0.9008) Steps 0(0.00) | Grad Norm 16.6172(9.2886) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 53.1148, Epoch Time 1028.5429(1025.3316), Bit/dim 1.1379, Xent 2.3026, Loss 1.1379, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4760 | Time 14.4254(14.4679) | Bit/dim 1.1225(1.1348) | Xent 2.3026(2.3026) | Loss 1.1225(1.1348) | Error 0.8911(0.9011) Steps 0(0.00) | Grad Norm 4.1907(9.3266) | Total Time 0.00(0.00)\n",
      "Iter 4770 | Time 14.5296(14.5213) | Bit/dim 1.1166(1.1332) | Xent 2.3026(2.3026) | Loss 1.1166(1.1332) | Error 0.9044(0.9008) Steps 0(0.00) | Grad Norm 11.6603(9.8383) | Total Time 0.00(0.00)\n",
      "Iter 4790 | Time 14.5934(14.5000) | Bit/dim 1.1370(1.1250) | Xent 2.3026(2.3026) | Loss 1.1370(1.1250) | Error 0.9156(0.9021) Steps 0(0.00) | Grad Norm 20.3733(9.1313) | Total Time 0.00(0.00)\n",
      "Iter 4800 | Time 14.5886(14.4964) | Bit/dim 1.1196(1.1245) | Xent 2.3026(2.3026) | Loss 1.1196(1.1245) | Error 0.9200(0.9026) Steps 0(0.00) | Grad Norm 16.7624(9.4558) | Total Time 0.00(0.00)\n",
      "Iter 4810 | Time 14.5795(14.4784) | Bit/dim 1.1221(1.1205) | Xent 2.3026(2.3026) | Loss 1.1221(1.1205) | Error 0.8822(0.9011) Steps 0(0.00) | Grad Norm 3.4864(8.3918) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 53.5651, Epoch Time 1024.1511(1025.2961), Bit/dim 1.0964, Xent 2.3026, Loss 1.0964, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4820 | Time 14.6388(14.4721) | Bit/dim 1.1061(1.1165) | Xent 2.3026(2.3026) | Loss 1.1061(1.1165) | Error 0.8867(0.9006) Steps 0(0.00) | Grad Norm 3.8932(7.1388) | Total Time 0.00(0.00)\n",
      "Iter 4830 | Time 14.5200(14.5037) | Bit/dim 1.0987(1.1121) | Xent 2.3026(2.3026) | Loss 1.0987(1.1121) | Error 0.8922(0.9016) Steps 0(0.00) | Grad Norm 2.8938(5.8481) | Total Time 0.00(0.00)\n",
      "Iter 4840 | Time 14.7813(14.5610) | Bit/dim 1.1024(1.1096) | Xent 2.3026(2.3026) | Loss 1.1024(1.1096) | Error 0.9011(0.9011) Steps 0(0.00) | Grad Norm 4.7761(4.9959) | Total Time 0.00(0.00)\n",
      "Iter 4850 | Time 14.7063(14.6167) | Bit/dim 1.1063(1.1081) | Xent 2.3026(2.3026) | Loss 1.1063(1.1081) | Error 0.8978(0.9013) Steps 0(0.00) | Grad Norm 3.5565(5.0741) | Total Time 0.00(0.00)\n",
      "Iter 4860 | Time 14.5938(14.6609) | Bit/dim 1.0920(1.1060) | Xent 2.3026(2.3026) | Loss 1.0920(1.1060) | Error 0.9111(0.9016) Steps 0(0.00) | Grad Norm 3.1465(5.3237) | Total Time 0.00(0.00)\n",
      "Iter 4870 | Time 14.5685(14.6776) | Bit/dim 1.0961(1.1045) | Xent 2.3026(2.3026) | Loss 1.0961(1.1045) | Error 0.9111(0.9011) Steps 0(0.00) | Grad Norm 5.8998(5.4801) | Total Time 0.00(0.00)\n",
      "Iter 4880 | Time 14.5524(14.6920) | Bit/dim 1.1111(1.1057) | Xent 2.3026(2.3026) | Loss 1.1111(1.1057) | Error 0.8900(0.9008) Steps 0(0.00) | Grad Norm 3.3105(6.1523) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 57.8213, Epoch Time 1043.0029(1025.8274), Bit/dim 1.3030, Xent 2.3026, Loss 1.3030, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4890 | Time 14.5378(14.7212) | Bit/dim 1.1868(1.1417) | Xent 2.3026(2.3026) | Loss 1.1868(1.1417) | Error 0.9044(0.9007) Steps 0(0.00) | Grad Norm 3.7514(7.4614) | Total Time 0.00(0.00)\n",
      "Iter 4900 | Time 14.3549(14.7131) | Bit/dim 1.1088(1.1433) | Xent 2.3026(2.3026) | Loss 1.1088(1.1433) | Error 0.9056(0.9011) Steps 0(0.00) | Grad Norm 2.2113(7.0683) | Total Time 0.00(0.00)\n",
      "Iter 4910 | Time 14.0333(14.5473) | Bit/dim 1.1177(1.1373) | Xent 2.3026(2.3026) | Loss 1.1177(1.1373) | Error 0.8989(0.9002) Steps 0(0.00) | Grad Norm 4.3240(6.1712) | Total Time 0.00(0.00)\n",
      "Iter 4920 | Time 14.1201(14.4554) | Bit/dim 1.0956(1.1291) | Xent 2.3026(2.3026) | Loss 1.0956(1.1291) | Error 0.9067(0.8997) Steps 0(0.00) | Grad Norm 2.7086(5.3090) | Total Time 0.00(0.00)\n",
      "Iter 4930 | Time 14.1675(14.3679) | Bit/dim 1.1003(1.1235) | Xent 2.3026(2.3026) | Loss 1.1003(1.1235) | Error 0.9033(0.9003) Steps 0(0.00) | Grad Norm 1.0953(4.7208) | Total Time 0.00(0.00)\n",
      "Iter 4940 | Time 14.1955(14.3161) | Bit/dim 1.0885(1.1172) | Xent 2.3026(2.3026) | Loss 1.0885(1.1172) | Error 0.9144(0.9021) Steps 0(0.00) | Grad Norm 5.7097(4.9610) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 53.4526, Epoch Time 1013.0477(1025.4440), Bit/dim 1.0932, Xent 2.3026, Loss 1.0932, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4950 | Time 14.3167(14.3117) | Bit/dim 1.0914(1.1130) | Xent 2.3026(2.3026) | Loss 1.0914(1.1130) | Error 0.8944(0.9016) Steps 0(0.00) | Grad Norm 1.9929(5.3937) | Total Time 0.00(0.00)\n",
      "Iter 4960 | Time 14.9449(14.3653) | Bit/dim 1.1240(1.1120) | Xent 2.3026(2.3026) | Loss 1.1240(1.1120) | Error 0.8900(0.9014) Steps 0(0.00) | Grad Norm 18.8453(5.9565) | Total Time 0.00(0.00)\n",
      "Iter 4970 | Time 14.6314(14.4833) | Bit/dim 1.2496(1.1352) | Xent 2.3026(2.3026) | Loss 1.2496(1.1352) | Error 0.8967(0.9025) Steps 0(0.00) | Grad Norm 13.3377(8.5587) | Total Time 0.00(0.00)\n",
      "Iter 4980 | Time 13.9900(14.4818) | Bit/dim 1.1792(1.1456) | Xent 2.3026(2.3026) | Loss 1.1792(1.1456) | Error 0.9078(0.9023) Steps 0(0.00) | Grad Norm 8.6399(9.1552) | Total Time 0.00(0.00)\n",
      "Iter 4990 | Time 14.7032(14.4235) | Bit/dim 1.1396(1.1533) | Xent 2.3026(2.3026) | Loss 1.1396(1.1533) | Error 0.8933(0.9007) Steps 0(0.00) | Grad Norm 4.4943(9.7192) | Total Time 0.00(0.00)\n",
      "Iter 5000 | Time 14.1129(14.3435) | Bit/dim 1.1466(1.1522) | Xent 2.3026(2.3026) | Loss 1.1466(1.1522) | Error 0.9100(0.9010) Steps 0(0.00) | Grad Norm 14.6198(9.7729) | Total Time 0.00(0.00)\n",
      "Iter 5010 | Time 14.2394(14.2965) | Bit/dim 1.1081(1.1449) | Xent 2.3026(2.3026) | Loss 1.1081(1.1449) | Error 0.9033(0.9019) Steps 0(0.00) | Grad Norm 3.3900(9.1918) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 53.7029, Epoch Time 1018.8138(1025.2451), Bit/dim 1.1064, Xent 2.3026, Loss 1.1064, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5020 | Time 14.5805(14.3383) | Bit/dim 1.1063(1.1357) | Xent 2.3026(2.3026) | Loss 1.1063(1.1357) | Error 0.9078(0.9023) Steps 0(0.00) | Grad Norm 1.7771(8.3276) | Total Time 0.00(0.00)\n",
      "Iter 5030 | Time 14.3771(14.3245) | Bit/dim 1.1030(1.1275) | Xent 2.3026(2.3026) | Loss 1.1030(1.1275) | Error 0.9111(0.9011) Steps 0(0.00) | Grad Norm 15.2001(8.0133) | Total Time 0.00(0.00)\n",
      "Iter 5040 | Time 14.7954(14.4191) | Bit/dim 1.1185(1.1250) | Xent 2.3026(2.3026) | Loss 1.1185(1.1250) | Error 0.9033(0.9009) Steps 0(0.00) | Grad Norm 15.2380(8.7097) | Total Time 0.00(0.00)\n",
      "Iter 5050 | Time 14.5693(14.4746) | Bit/dim 1.1095(1.1223) | Xent 2.3026(2.3026) | Loss 1.1095(1.1223) | Error 0.9100(0.9011) Steps 0(0.00) | Grad Norm 4.1556(8.4596) | Total Time 0.00(0.00)\n",
      "Iter 5060 | Time 14.2222(14.4576) | Bit/dim 1.1638(1.1222) | Xent 2.3026(2.3026) | Loss 1.1638(1.1222) | Error 0.8922(0.8999) Steps 0(0.00) | Grad Norm 14.9407(8.8385) | Total Time 0.00(0.00)\n",
      "Iter 5070 | Time 14.9661(14.5277) | Bit/dim 1.1476(1.1307) | Xent 2.3026(2.3026) | Loss 1.1476(1.1307) | Error 0.8844(0.9002) Steps 0(0.00) | Grad Norm 9.8692(9.7216) | Total Time 0.00(0.00)\n",
      "Iter 5080 | Time 14.3579(14.5233) | Bit/dim 1.1613(1.1335) | Xent 2.3026(2.3026) | Loss 1.1613(1.1335) | Error 0.8967(0.9021) Steps 0(0.00) | Grad Norm 24.3158(10.2978) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 53.0371, Epoch Time 1026.2494(1025.2752), Bit/dim 1.1469, Xent 2.3026, Loss 1.1469, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5090 | Time 14.6057(14.5174) | Bit/dim 1.1185(1.1341) | Xent 2.3026(2.3026) | Loss 1.1185(1.1341) | Error 0.9122(0.9026) Steps 0(0.00) | Grad Norm 8.7688(10.1035) | Total Time 0.00(0.00)\n",
      "Iter 5100 | Time 14.6233(14.5254) | Bit/dim 1.1021(1.1284) | Xent 2.3026(2.3026) | Loss 1.1021(1.1284) | Error 0.8933(0.9011) Steps 0(0.00) | Grad Norm 6.5561(9.2517) | Total Time 0.00(0.00)\n",
      "Iter 5110 | Time 14.6895(14.4949) | Bit/dim 1.1056(1.1219) | Xent 2.3026(2.3026) | Loss 1.1056(1.1219) | Error 0.9000(0.9013) Steps 0(0.00) | Grad Norm 2.7977(7.9881) | Total Time 0.00(0.00)\n",
      "Iter 5120 | Time 14.1935(14.4645) | Bit/dim 1.0974(1.1160) | Xent 2.3026(2.3026) | Loss 1.0974(1.1160) | Error 0.8967(0.9007) Steps 0(0.00) | Grad Norm 2.8814(6.5325) | Total Time 0.00(0.00)\n",
      "Iter 5130 | Time 14.8343(14.4997) | Bit/dim 1.1094(1.1118) | Xent 2.3026(2.3026) | Loss 1.1094(1.1118) | Error 0.9111(0.9017) Steps 0(0.00) | Grad Norm 1.3484(5.4129) | Total Time 0.00(0.00)\n",
      "Iter 5140 | Time 14.4289(14.5238) | Bit/dim 1.1010(1.1086) | Xent 2.3026(2.3026) | Loss 1.1010(1.1086) | Error 0.9033(0.9006) Steps 0(0.00) | Grad Norm 1.0826(4.4262) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 53.3432, Epoch Time 1025.3483(1025.2774), Bit/dim 1.0940, Xent 2.3026, Loss 1.0940, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5150 | Time 14.5952(14.5417) | Bit/dim 1.1024(1.1044) | Xent 2.3026(2.3026) | Loss 1.1024(1.1044) | Error 0.9078(0.9016) Steps 0(0.00) | Grad Norm 3.8760(4.3945) | Total Time 0.00(0.00)\n",
      "Iter 5160 | Time 14.5276(14.5558) | Bit/dim 1.0887(1.1022) | Xent 2.3026(2.3026) | Loss 1.0887(1.1022) | Error 0.8989(0.9028) Steps 0(0.00) | Grad Norm 2.7371(4.4159) | Total Time 0.00(0.00)\n",
      "Iter 5170 | Time 14.6426(14.5452) | Bit/dim 1.0950(1.1009) | Xent 2.3026(2.3026) | Loss 1.0950(1.1009) | Error 0.9078(0.9026) Steps 0(0.00) | Grad Norm 7.6890(4.8635) | Total Time 0.00(0.00)\n",
      "Iter 5180 | Time 14.5547(14.6016) | Bit/dim 1.2027(1.1297) | Xent 2.3026(2.3026) | Loss 1.2027(1.1297) | Error 0.8911(0.9009) Steps 0(0.00) | Grad Norm 13.1960(7.1583) | Total Time 0.00(0.00)\n",
      "Iter 5190 | Time 14.7001(14.5973) | Bit/dim 1.1477(1.1365) | Xent 2.3026(2.3026) | Loss 1.1477(1.1365) | Error 0.9011(0.9008) Steps 0(0.00) | Grad Norm 15.8722(7.5241) | Total Time 0.00(0.00)\n",
      "Iter 5200 | Time 14.4197(14.5911) | Bit/dim 1.1666(1.1464) | Xent 2.3026(2.3026) | Loss 1.1666(1.1464) | Error 0.8800(0.9007) Steps 0(0.00) | Grad Norm 8.2760(9.2720) | Total Time 0.00(0.00)\n",
      "Iter 5210 | Time 14.3036(14.5390) | Bit/dim 1.1361(1.1474) | Xent 2.3026(2.3026) | Loss 1.1361(1.1474) | Error 0.8956(0.9007) Steps 0(0.00) | Grad Norm 14.3712(9.6519) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 53.0792, Epoch Time 1028.4444(1025.3724), Bit/dim 1.1145, Xent 2.3026, Loss 1.1145, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5220 | Time 14.5407(14.4899) | Bit/dim 1.1049(1.1383) | Xent 2.3026(2.3026) | Loss 1.1049(1.1383) | Error 0.9011(0.9011) Steps 0(0.00) | Grad Norm 1.4074(8.5557) | Total Time 0.00(0.00)\n",
      "Iter 5230 | Time 14.0469(14.4699) | Bit/dim 1.1310(1.1305) | Xent 2.3026(2.3026) | Loss 1.1310(1.1305) | Error 0.9044(0.9019) Steps 0(0.00) | Grad Norm 9.7063(8.1315) | Total Time 0.00(0.00)\n",
      "Iter 5240 | Time 14.7942(14.4625) | Bit/dim 1.0937(1.1242) | Xent 2.3026(2.3026) | Loss 1.0937(1.1242) | Error 0.9133(0.9021) Steps 0(0.00) | Grad Norm 8.6264(7.9116) | Total Time 0.00(0.00)\n",
      "Iter 5250 | Time 14.6252(14.4992) | Bit/dim 1.1518(1.1238) | Xent 2.3026(2.3026) | Loss 1.1518(1.1238) | Error 0.9078(0.9006) Steps 0(0.00) | Grad Norm 15.0018(9.2203) | Total Time 0.00(0.00)\n",
      "Iter 5260 | Time 14.0440(14.4900) | Bit/dim 1.1205(1.1290) | Xent 2.3026(2.3026) | Loss 1.1205(1.1290) | Error 0.9000(0.8998) Steps 0(0.00) | Grad Norm 7.0317(9.9712) | Total Time 0.00(0.00)\n",
      "Iter 5270 | Time 14.7255(14.4589) | Bit/dim 1.1121(1.1244) | Xent 2.3026(2.3026) | Loss 1.1121(1.1244) | Error 0.8967(0.9002) Steps 0(0.00) | Grad Norm 6.9229(9.2600) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 54.5804, Epoch Time 1023.5921(1025.3190), Bit/dim 1.0952, Xent 2.3026, Loss 1.0952, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5280 | Time 14.3710(14.4940) | Bit/dim 1.0873(1.1190) | Xent 2.3026(2.3026) | Loss 1.0873(1.1190) | Error 0.9122(0.9013) Steps 0(0.00) | Grad Norm 4.1978(8.6141) | Total Time 0.00(0.00)\n",
      "Iter 5290 | Time 14.4767(14.4877) | Bit/dim 1.1348(1.1166) | Xent 2.3026(2.3026) | Loss 1.1348(1.1166) | Error 0.9100(0.9006) Steps 0(0.00) | Grad Norm 14.8756(8.5521) | Total Time 0.00(0.00)\n",
      "Iter 5300 | Time 14.4119(14.5068) | Bit/dim 1.0913(1.1140) | Xent 2.3026(2.3026) | Loss 1.0913(1.1140) | Error 0.9033(0.9004) Steps 0(0.00) | Grad Norm 1.6681(8.8569) | Total Time 0.00(0.00)\n",
      "Iter 5320 | Time 14.8372(14.5182) | Bit/dim 1.1715(1.1167) | Xent 2.3026(2.3026) | Loss 1.1715(1.1167) | Error 0.9100(0.9023) Steps 0(0.00) | Grad Norm 27.9666(9.7158) | Total Time 0.00(0.00)\n",
      "Iter 5330 | Time 14.1395(14.4721) | Bit/dim 1.1193(1.1225) | Xent 2.3026(2.3026) | Loss 1.1193(1.1225) | Error 0.9122(0.9024) Steps 0(0.00) | Grad Norm 7.8559(9.8708) | Total Time 0.00(0.00)\n",
      "Iter 5340 | Time 14.4810(14.4524) | Bit/dim 1.1251(1.1241) | Xent 2.3026(2.3026) | Loss 1.1251(1.1241) | Error 0.8967(0.9014) Steps 0(0.00) | Grad Norm 5.7094(10.0736) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 54.2033, Epoch Time 1023.9549(1025.2781), Bit/dim 1.1062, Xent 2.3026, Loss 1.1062, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5350 | Time 14.4871(14.4723) | Bit/dim 1.0924(1.1227) | Xent 2.3026(2.3026) | Loss 1.0924(1.1227) | Error 0.9011(0.9016) Steps 0(0.00) | Grad Norm 7.4234(9.9377) | Total Time 0.00(0.00)\n",
      "Iter 5360 | Time 14.6598(14.4552) | Bit/dim 1.1161(1.1194) | Xent 2.3026(2.3026) | Loss 1.1161(1.1194) | Error 0.8889(0.9016) Steps 0(0.00) | Grad Norm 9.2483(9.1593) | Total Time 0.00(0.00)\n",
      "Iter 5370 | Time 14.8536(14.4793) | Bit/dim 1.0988(1.1145) | Xent 2.3026(2.3026) | Loss 1.0988(1.1145) | Error 0.9122(0.9009) Steps 0(0.00) | Grad Norm 3.8136(7.9357) | Total Time 0.00(0.00)\n",
      "Iter 5380 | Time 15.0834(14.5216) | Bit/dim 1.1070(1.1099) | Xent 2.3026(2.3026) | Loss 1.1070(1.1099) | Error 0.9022(0.9022) Steps 0(0.00) | Grad Norm 7.0727(6.9192) | Total Time 0.00(0.00)\n",
      "Iter 5390 | Time 14.7126(14.5551) | Bit/dim 1.1500(1.1116) | Xent 2.3026(2.3026) | Loss 1.1500(1.1116) | Error 0.9089(0.9023) Steps 0(0.00) | Grad Norm 11.9296(7.8077) | Total Time 0.00(0.00)\n",
      "Iter 5400 | Time 14.6717(14.5753) | Bit/dim 1.1622(1.1275) | Xent 2.3026(2.3026) | Loss 1.1622(1.1275) | Error 0.9111(0.9020) Steps 0(0.00) | Grad Norm 8.0179(9.2291) | Total Time 0.00(0.00)\n",
      "Iter 5410 | Time 14.1348(14.5462) | Bit/dim 1.1353(1.1329) | Xent 2.3026(2.3026) | Loss 1.1353(1.1329) | Error 0.8878(0.9009) Steps 0(0.00) | Grad Norm 8.0320(9.5061) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 54.2519, Epoch Time 1028.8302(1025.3846), Bit/dim 1.1354, Xent 2.3026, Loss 1.1354, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5420 | Time 14.7448(14.5170) | Bit/dim 1.1160(1.1305) | Xent 2.3026(2.3026) | Loss 1.1160(1.1305) | Error 0.8856(0.9005) Steps 0(0.00) | Grad Norm 9.4000(9.2166) | Total Time 0.00(0.00)\n",
      "Iter 5430 | Time 14.3583(14.4830) | Bit/dim 1.1108(1.1235) | Xent 2.3026(2.3026) | Loss 1.1108(1.1235) | Error 0.9011(0.9008) Steps 0(0.00) | Grad Norm 3.0111(7.9142) | Total Time 0.00(0.00)\n",
      "Iter 5440 | Time 14.5796(14.4784) | Bit/dim 1.0935(1.1173) | Xent 2.3026(2.3026) | Loss 1.0935(1.1173) | Error 0.8822(0.9010) Steps 0(0.00) | Grad Norm 1.5781(6.5967) | Total Time 0.00(0.00)\n",
      "Iter 5450 | Time 14.6729(14.5081) | Bit/dim 1.1112(1.1128) | Xent 2.3026(2.3026) | Loss 1.1112(1.1128) | Error 0.8867(0.9010) Steps 0(0.00) | Grad Norm 2.5056(5.4909) | Total Time 0.00(0.00)\n",
      "Iter 5460 | Time 14.4571(14.5255) | Bit/dim 1.0770(1.1088) | Xent 2.3026(2.3026) | Loss 1.0770(1.1088) | Error 0.9111(0.9001) Steps 0(0.00) | Grad Norm 0.9715(4.6661) | Total Time 0.00(0.00)\n",
      "Iter 5470 | Time 14.4657(14.5354) | Bit/dim 1.0984(1.1036) | Xent 2.3026(2.3026) | Loss 1.0984(1.1036) | Error 0.9100(0.9009) Steps 0(0.00) | Grad Norm 0.9165(3.9901) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 53.2386, Epoch Time 1024.5164(1025.3586), Bit/dim 1.0850, Xent 2.3026, Loss 1.0850, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5480 | Time 14.4182(14.5136) | Bit/dim 1.0962(1.1006) | Xent 2.3026(2.3026) | Loss 1.0962(1.1006) | Error 0.8900(0.9011) Steps 0(0.00) | Grad Norm 1.4457(3.3810) | Total Time 0.00(0.00)\n",
      "Iter 5490 | Time 14.7607(14.5229) | Bit/dim 1.1047(1.0993) | Xent 2.3026(2.3026) | Loss 1.1047(1.0993) | Error 0.8956(0.9004) Steps 0(0.00) | Grad Norm 7.5562(3.4787) | Total Time 0.00(0.00)\n",
      "Iter 5500 | Time 14.5861(14.5354) | Bit/dim 1.0883(1.0967) | Xent 2.3026(2.3026) | Loss 1.0883(1.0967) | Error 0.9022(0.9003) Steps 0(0.00) | Grad Norm 3.6027(3.2647) | Total Time 0.00(0.00)\n",
      "Iter 5510 | Time 14.7869(14.5606) | Bit/dim 1.0975(1.0963) | Xent 2.3026(2.3026) | Loss 1.0975(1.0963) | Error 0.9122(0.9015) Steps 0(0.00) | Grad Norm 13.3574(4.5542) | Total Time 0.00(0.00)\n",
      "Iter 5520 | Time 14.6185(14.6269) | Bit/dim 1.2129(1.1298) | Xent 2.3026(2.3026) | Loss 1.2129(1.1298) | Error 0.9144(0.9011) Steps 0(0.00) | Grad Norm 5.7210(6.4755) | Total Time 0.00(0.00)\n",
      "Iter 5530 | Time 14.5282(14.6063) | Bit/dim 1.1183(1.1363) | Xent 2.3026(2.3026) | Loss 1.1183(1.1363) | Error 0.9211(0.9005) Steps 0(0.00) | Grad Norm 5.7985(6.0395) | Total Time 0.00(0.00)\n",
      "Iter 5540 | Time 14.6461(14.5697) | Bit/dim 1.0999(1.1299) | Xent 2.3026(2.3026) | Loss 1.0999(1.1299) | Error 0.9089(0.9026) Steps 0(0.00) | Grad Norm 5.3789(5.8069) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 54.2750, Epoch Time 1029.9837(1025.4973), Bit/dim 1.0956, Xent 2.3026, Loss 1.0956, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5550 | Time 14.4285(14.4948) | Bit/dim 1.0868(1.1218) | Xent 2.3026(2.3026) | Loss 1.0868(1.1218) | Error 0.9189(0.9025) Steps 0(0.00) | Grad Norm 3.1703(4.9975) | Total Time 0.00(0.00)\n",
      "Iter 5560 | Time 14.2235(14.4615) | Bit/dim 1.0937(1.1150) | Xent 2.3026(2.3026) | Loss 1.0937(1.1150) | Error 0.9089(0.9013) Steps 0(0.00) | Grad Norm 5.4753(4.5597) | Total Time 0.00(0.00)\n",
      "Iter 5570 | Time 14.5612(14.4981) | Bit/dim 1.0939(1.1089) | Xent 2.3026(2.3026) | Loss 1.0939(1.1089) | Error 0.9111(0.9015) Steps 0(0.00) | Grad Norm 1.2097(4.2045) | Total Time 0.00(0.00)\n",
      "Iter 5580 | Time 14.8675(14.5396) | Bit/dim 1.0961(1.1045) | Xent 2.3026(2.3026) | Loss 1.0961(1.1045) | Error 0.9056(0.9019) Steps 0(0.00) | Grad Norm 8.8323(4.0421) | Total Time 0.00(0.00)\n",
      "Iter 5590 | Time 14.8676(14.5620) | Bit/dim 1.1013(1.1010) | Xent 2.3026(2.3026) | Loss 1.1013(1.1010) | Error 0.8922(0.9021) Steps 0(0.00) | Grad Norm 10.5737(4.7330) | Total Time 0.00(0.00)\n",
      "Iter 5600 | Time 14.5008(14.5847) | Bit/dim 1.1312(1.1147) | Xent 2.3026(2.3026) | Loss 1.1312(1.1147) | Error 0.9133(0.9017) Steps 0(0.00) | Grad Norm 15.6294(6.8189) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 54.4617, Epoch Time 1029.1799(1025.6078), Bit/dim 1.1879, Xent 2.3026, Loss 1.1879, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5610 | Time 14.5449(14.5904) | Bit/dim 1.1859(1.1288) | Xent 2.3026(2.3026) | Loss 1.1859(1.1288) | Error 0.8967(0.9012) Steps 0(0.00) | Grad Norm 10.3600(8.3240) | Total Time 0.00(0.00)\n",
      "Iter 5620 | Time 14.6485(14.5659) | Bit/dim 1.1122(1.1298) | Xent 2.3026(2.3026) | Loss 1.1122(1.1298) | Error 0.9122(0.9010) Steps 0(0.00) | Grad Norm 8.0146(8.3041) | Total Time 0.00(0.00)\n",
      "Iter 5630 | Time 14.3392(14.5390) | Bit/dim 1.1157(1.1278) | Xent 2.3026(2.3026) | Loss 1.1157(1.1278) | Error 0.9033(0.9015) Steps 0(0.00) | Grad Norm 7.4762(8.8864) | Total Time 0.00(0.00)\n",
      "Iter 5640 | Time 14.5699(14.5483) | Bit/dim 1.0965(1.1221) | Xent 2.3026(2.3026) | Loss 1.0965(1.1221) | Error 0.9044(0.9012) Steps 0(0.00) | Grad Norm 7.2461(8.3566) | Total Time 0.00(0.00)\n",
      "Iter 5650 | Time 14.3582(14.5076) | Bit/dim 1.0996(1.1184) | Xent 2.3026(2.3026) | Loss 1.0996(1.1184) | Error 0.9133(0.9016) Steps 0(0.00) | Grad Norm 1.6999(8.4969) | Total Time 0.00(0.00)\n",
      "Iter 5660 | Time 14.7565(14.5377) | Bit/dim 1.1049(1.1167) | Xent 2.3026(2.3026) | Loss 1.1049(1.1167) | Error 0.8989(0.9012) Steps 0(0.00) | Grad Norm 5.6057(9.0363) | Total Time 0.00(0.00)\n",
      "Iter 5670 | Time 14.8468(14.5938) | Bit/dim 1.1281(1.1286) | Xent 2.3026(2.3026) | Loss 1.1281(1.1286) | Error 0.9078(0.9017) Steps 0(0.00) | Grad Norm 4.3923(10.0544) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 55.6230, Epoch Time 1030.0884(1025.7422), Bit/dim 1.1708, Xent 2.3026, Loss 1.1708, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5680 | Time 14.2822(14.5348) | Bit/dim 1.1088(1.1329) | Xent 2.3026(2.3026) | Loss 1.1088(1.1329) | Error 0.9044(0.9023) Steps 0(0.00) | Grad Norm 2.6032(9.9198) | Total Time 0.00(0.00)\n",
      "Iter 5690 | Time 14.5694(14.5025) | Bit/dim 1.0975(1.1262) | Xent 2.3026(2.3026) | Loss 1.0975(1.1262) | Error 0.8911(0.9013) Steps 0(0.00) | Grad Norm 3.2943(8.9863) | Total Time 0.00(0.00)\n",
      "Iter 5700 | Time 14.4847(14.5233) | Bit/dim 1.0987(1.1184) | Xent 2.3026(2.3026) | Loss 1.0987(1.1184) | Error 0.9078(0.9018) Steps 0(0.00) | Grad Norm 2.9118(7.6604) | Total Time 0.00(0.00)\n",
      "Iter 5710 | Time 14.5293(14.5326) | Bit/dim 1.0860(1.1117) | Xent 2.3026(2.3026) | Loss 1.0860(1.1117) | Error 0.8889(0.9020) Steps 0(0.00) | Grad Norm 1.6660(6.2721) | Total Time 0.00(0.00)\n",
      "Iter 5720 | Time 14.6302(14.5492) | Bit/dim 1.0941(1.1060) | Xent 2.3026(2.3026) | Loss 1.0941(1.1060) | Error 0.9000(0.9010) Steps 0(0.00) | Grad Norm 0.9476(4.9642) | Total Time 0.00(0.00)\n",
      "Iter 5730 | Time 14.4297(14.5381) | Bit/dim 1.0832(1.1014) | Xent 2.3026(2.3026) | Loss 1.0832(1.1014) | Error 0.9122(0.9009) Steps 0(0.00) | Grad Norm 0.7002(3.8663) | Total Time 0.00(0.00)\n",
      "Iter 5740 | Time 14.6111(14.5439) | Bit/dim 1.0749(1.0993) | Xent 2.3026(2.3026) | Loss 1.0749(1.0993) | Error 0.9000(0.9009) Steps 0(0.00) | Grad Norm 1.9701(3.2863) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 53.6392, Epoch Time 1025.5843(1025.7375), Bit/dim 1.0828, Xent 2.3026, Loss 1.0828, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5750 | Time 14.3370(14.5354) | Bit/dim 1.1088(1.0964) | Xent 2.3026(2.3026) | Loss 1.1088(1.0964) | Error 0.8978(0.9012) Steps 0(0.00) | Grad Norm 6.5979(3.3903) | Total Time 0.00(0.00)\n",
      "Iter 5760 | Time 14.3777(14.5351) | Bit/dim 1.0809(1.0939) | Xent 2.3026(2.3026) | Loss 1.0809(1.0939) | Error 0.9044(0.9008) Steps 0(0.00) | Grad Norm 6.0943(3.8680) | Total Time 0.00(0.00)\n",
      "Iter 5770 | Time 13.9473(14.4974) | Bit/dim 1.0983(1.0929) | Xent 2.3026(2.3026) | Loss 1.0983(1.0929) | Error 0.8878(0.9004) Steps 0(0.00) | Grad Norm 11.5870(4.9795) | Total Time 0.00(0.00)\n",
      "Iter 5780 | Time 15.3219(14.5072) | Bit/dim 1.1632(1.0975) | Xent 2.3026(2.3026) | Loss 1.1632(1.0975) | Error 0.9178(0.9006) Steps 0(0.00) | Grad Norm 38.1812(6.7889) | Total Time 0.00(0.00)\n",
      "Iter 5790 | Time 14.4230(14.5118) | Bit/dim 1.1687(1.1303) | Xent 2.3026(2.3026) | Loss 1.1687(1.1303) | Error 0.9178(0.9009) Steps 0(0.00) | Grad Norm 4.1654(7.0810) | Total Time 0.00(0.00)\n",
      "Iter 5800 | Time 14.2495(14.4919) | Bit/dim 1.1139(1.1347) | Xent 2.3026(2.3026) | Loss 1.1139(1.1347) | Error 0.9078(0.9013) Steps 0(0.00) | Grad Norm 5.1440(7.8692) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 53.3097, Epoch Time 1024.9100(1025.7127), Bit/dim 1.1551, Xent 2.3026, Loss 1.1551, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5810 | Time 14.1237(14.4811) | Bit/dim 1.1375(1.1462) | Xent 2.3026(2.3026) | Loss 1.1375(1.1462) | Error 0.9011(0.9005) Steps 0(0.00) | Grad Norm 12.2391(9.0294) | Total Time 0.00(0.00)\n",
      "Iter 5820 | Time 14.7268(14.4640) | Bit/dim 1.1221(1.1398) | Xent 2.3026(2.3026) | Loss 1.1221(1.1398) | Error 0.9078(0.9011) Steps 0(0.00) | Grad Norm 6.0612(8.1216) | Total Time 0.00(0.00)\n",
      "Iter 5830 | Time 14.8447(14.5040) | Bit/dim 1.1026(1.1293) | Xent 2.3026(2.3026) | Loss 1.1026(1.1293) | Error 0.9067(0.9018) Steps 0(0.00) | Grad Norm 1.6173(7.0009) | Total Time 0.00(0.00)\n",
      "Iter 5840 | Time 14.6641(14.5463) | Bit/dim 1.1170(1.1214) | Xent 2.3026(2.3026) | Loss 1.1170(1.1214) | Error 0.8844(0.9023) Steps 0(0.00) | Grad Norm 16.6779(7.1846) | Total Time 0.00(0.00)\n",
      "Iter 5850 | Time 14.4914(14.5574) | Bit/dim 1.0857(1.1158) | Xent 2.3026(2.3026) | Loss 1.0857(1.1158) | Error 0.9056(0.9034) Steps 0(0.00) | Grad Norm 6.4029(8.0020) | Total Time 0.00(0.00)\n",
      "Iter 5860 | Time 14.4886(14.5443) | Bit/dim 1.1158(1.1132) | Xent 2.3026(2.3026) | Loss 1.1158(1.1132) | Error 0.9022(0.9023) Steps 0(0.00) | Grad Norm 10.9961(8.6705) | Total Time 0.00(0.00)\n",
      "Iter 5870 | Time 14.1355(14.5497) | Bit/dim 1.1340(1.1136) | Xent 2.3026(2.3026) | Loss 1.1340(1.1136) | Error 0.8944(0.9010) Steps 0(0.00) | Grad Norm 12.8061(9.2452) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 53.6587, Epoch Time 1027.7917(1025.7750), Bit/dim 1.1465, Xent 2.3026, Loss 1.1465, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5880 | Time 14.1120(14.5290) | Bit/dim 1.1440(1.1249) | Xent 2.3026(2.3026) | Loss 1.1440(1.1249) | Error 0.9144(0.9002) Steps 0(0.00) | Grad Norm 9.9817(9.9643) | Total Time 0.00(0.00)\n",
      "Iter 5890 | Time 14.4262(14.4903) | Bit/dim 1.1024(1.1222) | Xent 2.3026(2.3026) | Loss 1.1024(1.1222) | Error 0.9056(0.9006) Steps 0(0.00) | Grad Norm 5.5949(9.1508) | Total Time 0.00(0.00)\n",
      "Iter 5900 | Time 14.5187(14.4876) | Bit/dim 1.1031(1.1167) | Xent 2.3026(2.3026) | Loss 1.1031(1.1167) | Error 0.9022(0.9010) Steps 0(0.00) | Grad Norm 5.5773(8.0219) | Total Time 0.00(0.00)\n",
      "Iter 5910 | Time 14.5238(14.4872) | Bit/dim 1.0901(1.1095) | Xent 2.3026(2.3026) | Loss 1.0901(1.1095) | Error 0.8856(0.9013) Steps 0(0.00) | Grad Norm 3.0969(6.6871) | Total Time 0.00(0.00)\n",
      "Iter 5920 | Time 14.4961(14.4986) | Bit/dim 1.0814(1.1025) | Xent 2.3026(2.3026) | Loss 1.0814(1.1025) | Error 0.8967(0.9021) Steps 0(0.00) | Grad Norm 3.2703(5.7662) | Total Time 0.00(0.00)\n",
      "Iter 5930 | Time 14.6436(14.5102) | Bit/dim 1.0861(1.0977) | Xent 2.3026(2.3026) | Loss 1.0861(1.0977) | Error 0.8889(0.9018) Steps 0(0.00) | Grad Norm 2.0709(4.7971) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 54.2637, Epoch Time 1024.6375(1025.7409), Bit/dim 1.0780, Xent 2.3026, Loss 1.0780, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5940 | Time 14.6018(14.5170) | Bit/dim 1.0774(1.0943) | Xent 2.3026(2.3026) | Loss 1.0774(1.0943) | Error 0.8922(0.9003) Steps 0(0.00) | Grad Norm 1.6787(3.9997) | Total Time 0.00(0.00)\n",
      "Iter 5950 | Time 14.6338(14.4972) | Bit/dim 1.0835(1.0919) | Xent 2.3026(2.3026) | Loss 1.0835(1.0919) | Error 0.9122(0.9014) Steps 0(0.00) | Grad Norm 7.6294(4.1987) | Total Time 0.00(0.00)\n",
      "Iter 5960 | Time 14.6882(14.5055) | Bit/dim 1.0949(1.0899) | Xent 2.3026(2.3026) | Loss 1.0949(1.0899) | Error 0.8978(0.9017) Steps 0(0.00) | Grad Norm 10.0493(4.1066) | Total Time 0.00(0.00)\n",
      "Iter 5970 | Time 14.3699(14.4879) | Bit/dim 1.2798(1.1035) | Xent 2.3026(2.3026) | Loss 1.2798(1.1035) | Error 0.8900(0.9008) Steps 0(0.00) | Grad Norm 10.4065(6.5792) | Total Time 0.00(0.00)\n",
      "Iter 5980 | Time 14.3014(14.4896) | Bit/dim 1.1564(1.1250) | Xent 2.3026(2.3026) | Loss 1.1564(1.1250) | Error 0.8811(0.9003) Steps 0(0.00) | Grad Norm 8.1450(6.8684) | Total Time 0.00(0.00)\n",
      "Iter 5990 | Time 14.3480(14.4490) | Bit/dim 1.1060(1.1270) | Xent 2.3026(2.3026) | Loss 1.1060(1.1270) | Error 0.9178(0.9003) Steps 0(0.00) | Grad Norm 8.1019(7.8592) | Total Time 0.00(0.00)\n",
      "Iter 6000 | Time 14.5161(14.4371) | Bit/dim 1.0897(1.1200) | Xent 2.3026(2.3026) | Loss 1.0897(1.1200) | Error 0.9089(0.9004) Steps 0(0.00) | Grad Norm 2.3182(7.5446) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 54.6446, Epoch Time 1022.0240(1025.6294), Bit/dim 1.0833, Xent 2.3026, Loss 1.0833, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6010 | Time 14.4720(14.4274) | Bit/dim 1.0876(1.1126) | Xent 2.3026(2.3026) | Loss 1.0876(1.1126) | Error 0.9089(0.9009) Steps 0(0.00) | Grad Norm 0.8598(6.2543) | Total Time 0.00(0.00)\n",
      "Iter 6020 | Time 14.4161(14.4142) | Bit/dim 1.0806(1.1053) | Xent 2.3026(2.3026) | Loss 1.0806(1.1053) | Error 0.9056(0.9019) Steps 0(0.00) | Grad Norm 1.5346(5.2486) | Total Time 0.00(0.00)\n",
      "Iter 6030 | Time 14.2812(14.4166) | Bit/dim 1.0801(1.1000) | Xent 2.3026(2.3026) | Loss 1.0801(1.1000) | Error 0.9022(0.9025) Steps 0(0.00) | Grad Norm 7.3689(4.9110) | Total Time 0.00(0.00)\n",
      "Iter 6040 | Time 14.4976(14.4039) | Bit/dim 1.0762(1.0959) | Xent 2.3026(2.3026) | Loss 1.0762(1.0959) | Error 0.9022(0.9014) Steps 0(0.00) | Grad Norm 3.3703(5.0367) | Total Time 0.00(0.00)\n",
      "Iter 6050 | Time 14.2680(14.3832) | Bit/dim 1.0619(1.0936) | Xent 2.3026(2.3026) | Loss 1.0619(1.0936) | Error 0.8989(0.9016) Steps 0(0.00) | Grad Norm 1.4298(5.4688) | Total Time 0.00(0.00)\n",
      "Iter 6060 | Time 14.2102(14.3922) | Bit/dim 1.2017(1.0969) | Xent 2.3026(2.3026) | Loss 1.2017(1.0969) | Error 0.8900(0.9008) Steps 0(0.00) | Grad Norm 16.2145(6.9673) | Total Time 0.00(0.00)\n",
      "Iter 6070 | Time 14.6060(14.4315) | Bit/dim 1.2545(1.1204) | Xent 2.3026(2.3026) | Loss 1.2545(1.1204) | Error 0.9189(0.9011) Steps 0(0.00) | Grad Norm 7.3601(8.5018) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 54.2566, Epoch Time 1019.2661(1025.4385), Bit/dim 1.2058, Xent 2.3026, Loss 1.2058, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6080 | Time 14.2629(14.4039) | Bit/dim 1.1291(1.1343) | Xent 2.3026(2.3026) | Loss 1.1291(1.1343) | Error 0.9044(0.9022) Steps 0(0.00) | Grad Norm 3.0799(7.7607) | Total Time 0.00(0.00)\n",
      "Iter 6090 | Time 14.4899(14.4337) | Bit/dim 1.1000(1.1286) | Xent 2.3026(2.3026) | Loss 1.1000(1.1286) | Error 0.8922(0.9013) Steps 0(0.00) | Grad Norm 5.3531(6.9298) | Total Time 0.00(0.00)\n",
      "Iter 6100 | Time 14.4907(14.5026) | Bit/dim 1.1030(1.1218) | Xent 2.3026(2.3026) | Loss 1.1030(1.1218) | Error 0.9144(0.9013) Steps 0(0.00) | Grad Norm 12.2126(7.1464) | Total Time 0.00(0.00)\n",
      "Iter 6110 | Time 14.4632(14.5588) | Bit/dim 1.0749(1.1148) | Xent 2.3026(2.3026) | Loss 1.0749(1.1148) | Error 0.9044(0.9017) Steps 0(0.00) | Grad Norm 2.6836(7.1573) | Total Time 0.00(0.00)\n",
      "Iter 6120 | Time 14.5796(14.5695) | Bit/dim 1.1024(1.1140) | Xent 2.3026(2.3026) | Loss 1.1024(1.1140) | Error 0.8967(0.9018) Steps 0(0.00) | Grad Norm 5.6128(7.8491) | Total Time 0.00(0.00)\n",
      "Iter 6130 | Time 14.5054(14.5679) | Bit/dim 1.1324(1.1273) | Xent 2.3026(2.3026) | Loss 1.1324(1.1273) | Error 0.8878(0.9002) Steps 0(0.00) | Grad Norm 5.6609(9.0899) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 53.5557, Epoch Time 1028.0232(1025.5160), Bit/dim 1.1040, Xent 2.3026, Loss 1.1040, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6140 | Time 14.3946(14.4887) | Bit/dim 1.1131(1.1256) | Xent 2.3026(2.3026) | Loss 1.1131(1.1256) | Error 0.9000(0.9002) Steps 0(0.00) | Grad Norm 2.8552(8.7167) | Total Time 0.00(0.00)\n",
      "Iter 6150 | Time 14.4020(14.4995) | Bit/dim 1.0802(1.1172) | Xent 2.3026(2.3026) | Loss 1.0802(1.1172) | Error 0.9144(0.9014) Steps 0(0.00) | Grad Norm 3.4378(7.9265) | Total Time 0.00(0.00)\n",
      "Iter 6160 | Time 14.4880(14.4821) | Bit/dim 1.0815(1.1091) | Xent 2.3026(2.3026) | Loss 1.0815(1.1091) | Error 0.9178(0.9015) Steps 0(0.00) | Grad Norm 2.4666(6.7352) | Total Time 0.00(0.00)\n",
      "Iter 6170 | Time 14.4260(14.4870) | Bit/dim 1.0835(1.1031) | Xent 2.3026(2.3026) | Loss 1.0835(1.1031) | Error 0.8989(0.9007) Steps 0(0.00) | Grad Norm 2.2760(5.8486) | Total Time 0.00(0.00)\n",
      "Iter 6180 | Time 14.5166(14.4761) | Bit/dim 1.0703(1.0974) | Xent 2.3026(2.3026) | Loss 1.0703(1.0974) | Error 0.9133(0.9015) Steps 0(0.00) | Grad Norm 3.2711(5.0401) | Total Time 0.00(0.00)\n",
      "Iter 6190 | Time 14.3235(14.4373) | Bit/dim 1.0775(1.0937) | Xent 2.3026(2.3026) | Loss 1.0775(1.0937) | Error 0.8867(0.9009) Steps 0(0.00) | Grad Norm 2.4083(4.2988) | Total Time 0.00(0.00)\n",
      "Iter 6200 | Time 14.3294(14.4284) | Bit/dim 1.0914(1.0914) | Xent 2.3026(2.3026) | Loss 1.0914(1.0914) | Error 0.8744(0.9004) Steps 0(0.00) | Grad Norm 9.1804(4.6356) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 54.7428, Epoch Time 1020.9691(1025.3796), Bit/dim 1.0794, Xent 2.3026, Loss 1.0794, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6210 | Time 14.5580(14.4044) | Bit/dim 1.1852(1.0966) | Xent 2.3026(2.3026) | Loss 1.1852(1.0966) | Error 0.9100(0.9014) Steps 0(0.00) | Grad Norm 11.3373(6.2386) | Total Time 0.00(0.00)\n",
      "Iter 6220 | Time 14.6534(14.4907) | Bit/dim 1.2370(1.1228) | Xent 2.3026(2.3026) | Loss 1.2370(1.1228) | Error 0.9111(0.9013) Steps 0(0.00) | Grad Norm 10.1808(8.2694) | Total Time 0.00(0.00)\n",
      "Iter 6230 | Time 14.2097(14.4247) | Bit/dim 1.1321(1.1321) | Xent 2.3026(2.3026) | Loss 1.1321(1.1321) | Error 0.9178(0.9016) Steps 0(0.00) | Grad Norm 7.7340(8.4011) | Total Time 0.00(0.00)\n",
      "Iter 6240 | Time 14.3794(14.4525) | Bit/dim 1.0897(1.1275) | Xent 2.3026(2.3026) | Loss 1.0897(1.1275) | Error 0.9067(0.9010) Steps 0(0.00) | Grad Norm 7.5417(7.8151) | Total Time 0.00(0.00)\n",
      "Iter 6250 | Time 14.0524(14.4471) | Bit/dim 1.1018(1.1194) | Xent 2.3026(2.3026) | Loss 1.1018(1.1194) | Error 0.8911(0.9010) Steps 0(0.00) | Grad Norm 2.3929(6.5078) | Total Time 0.00(0.00)\n",
      "Iter 6260 | Time 14.3577(14.4278) | Bit/dim 1.0805(1.1115) | Xent 2.3026(2.3026) | Loss 1.0805(1.1115) | Error 0.9156(0.9015) Steps 0(0.00) | Grad Norm 3.8439(5.5290) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 54.8927, Epoch Time 1022.5234(1025.2940), Bit/dim 1.0763, Xent 2.3026, Loss 1.0763, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6270 | Time 14.2304(14.4252) | Bit/dim 1.0792(1.1024) | Xent 2.3026(2.3026) | Loss 1.0792(1.1024) | Error 0.9022(0.9013) Steps 0(0.00) | Grad Norm 3.4707(4.7238) | Total Time 0.00(0.00)\n",
      "Iter 6280 | Time 14.2906(14.4276) | Bit/dim 1.0687(1.0965) | Xent 2.3026(2.3026) | Loss 1.0687(1.0965) | Error 0.8989(0.9022) Steps 0(0.00) | Grad Norm 0.5510(4.0069) | Total Time 0.00(0.00)\n",
      "Iter 6290 | Time 14.7226(14.4467) | Bit/dim 1.0698(1.0930) | Xent 2.3026(2.3026) | Loss 1.0698(1.0930) | Error 0.9144(0.9018) Steps 0(0.00) | Grad Norm 1.6871(3.2141) | Total Time 0.00(0.00)\n",
      "Iter 6300 | Time 14.8600(14.4272) | Bit/dim 1.1645(1.0952) | Xent 2.3026(2.3026) | Loss 1.1645(1.0952) | Error 0.8867(0.9008) Steps 0(0.00) | Grad Norm 34.9441(5.7111) | Total Time 0.00(0.00)\n",
      "Iter 6310 | Time 14.3662(14.4606) | Bit/dim 1.1481(1.1134) | Xent 2.3026(2.3026) | Loss 1.1481(1.1134) | Error 0.8989(0.9012) Steps 0(0.00) | Grad Norm 7.8403(7.4279) | Total Time 0.00(0.00)\n",
      "Iter 6320 | Time 14.1131(14.4355) | Bit/dim 1.0883(1.1151) | Xent 2.3026(2.3026) | Loss 1.0883(1.1151) | Error 0.9067(0.9010) Steps 0(0.00) | Grad Norm 6.6658(7.7503) | Total Time 0.00(0.00)\n",
      "Iter 6330 | Time 14.2655(14.4710) | Bit/dim 1.1244(1.1185) | Xent 2.3026(2.3026) | Loss 1.1244(1.1185) | Error 0.8978(0.9006) Steps 0(0.00) | Grad Norm 10.5394(9.1483) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 53.5983, Epoch Time 1021.7699(1025.1882), Bit/dim 1.1267, Xent 2.3026, Loss 1.1267, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6340 | Time 13.9663(14.4172) | Bit/dim 1.1144(1.1219) | Xent 2.3026(2.3026) | Loss 1.1144(1.1219) | Error 0.8989(0.9010) Steps 0(0.00) | Grad Norm 7.1716(9.1224) | Total Time 0.00(0.00)\n",
      "Iter 6350 | Time 14.5896(14.4264) | Bit/dim 1.0959(1.1159) | Xent 2.3026(2.3026) | Loss 1.0959(1.1159) | Error 0.8956(0.9020) Steps 0(0.00) | Grad Norm 8.9427(8.3280) | Total Time 0.00(0.00)\n",
      "Iter 6360 | Time 14.3392(14.4551) | Bit/dim 1.0906(1.1085) | Xent 2.3026(2.3026) | Loss 1.0906(1.1085) | Error 0.9144(0.9018) Steps 0(0.00) | Grad Norm 1.0414(7.3006) | Total Time 0.00(0.00)\n",
      "Iter 6370 | Time 14.2482(14.4073) | Bit/dim 1.0794(1.1016) | Xent 2.3026(2.3026) | Loss 1.0794(1.1016) | Error 0.8978(0.9008) Steps 0(0.00) | Grad Norm 1.1315(5.8245) | Total Time 0.00(0.00)\n",
      "Iter 6380 | Time 14.2055(14.3996) | Bit/dim 1.0843(1.0960) | Xent 2.3026(2.3026) | Loss 1.0843(1.0960) | Error 0.8800(0.9011) Steps 0(0.00) | Grad Norm 2.0554(4.7230) | Total Time 0.00(0.00)\n",
      "Iter 6390 | Time 14.2131(14.3894) | Bit/dim 1.0802(1.0900) | Xent 2.3026(2.3026) | Loss 1.0802(1.0900) | Error 0.8944(0.9019) Steps 0(0.00) | Grad Norm 2.0190(3.8778) | Total Time 0.00(0.00)\n",
      "Iter 6400 | Time 14.2865(14.3991) | Bit/dim 1.0702(1.0873) | Xent 2.3026(2.3026) | Loss 1.0702(1.0873) | Error 0.9033(0.9016) Steps 0(0.00) | Grad Norm 7.6180(3.9302) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 56.0857, Epoch Time 1020.3570(1025.0433), Bit/dim 1.0750, Xent 2.3026, Loss 1.0750, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6410 | Time 14.2742(14.4028) | Bit/dim 1.0798(1.0841) | Xent 2.3026(2.3026) | Loss 1.0798(1.0841) | Error 0.9078(0.9012) Steps 0(0.00) | Grad Norm 5.1436(3.8389) | Total Time 0.00(0.00)\n",
      "Iter 6420 | Time 14.1970(14.3632) | Bit/dim 1.1830(1.0946) | Xent 2.3026(2.3026) | Loss 1.1830(1.0946) | Error 0.8978(0.9021) Steps 0(0.00) | Grad Norm 13.1595(6.4460) | Total Time 0.00(0.00)\n",
      "Iter 6430 | Time 14.2721(14.4269) | Bit/dim 1.1718(1.1142) | Xent 2.3026(2.3026) | Loss 1.1718(1.1142) | Error 0.8867(0.9008) Steps 0(0.00) | Grad Norm 11.0702(8.1252) | Total Time 0.00(0.00)\n",
      "Iter 6440 | Time 14.6348(14.4164) | Bit/dim 1.0947(1.1158) | Xent 2.3026(2.3026) | Loss 1.0947(1.1158) | Error 0.9056(0.9021) Steps 0(0.00) | Grad Norm 2.6590(8.1576) | Total Time 0.00(0.00)\n",
      "Iter 6450 | Time 14.2565(14.4570) | Bit/dim 1.1077(1.1146) | Xent 2.3026(2.3026) | Loss 1.1077(1.1146) | Error 0.9111(0.9022) Steps 0(0.00) | Grad Norm 8.6567(8.5266) | Total Time 0.00(0.00)\n",
      "Iter 6460 | Time 14.2070(14.4915) | Bit/dim 1.0911(1.1086) | Xent 2.3026(2.3026) | Loss 1.0911(1.1086) | Error 0.9067(0.9011) Steps 0(0.00) | Grad Norm 7.9211(8.3963) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 54.9095, Epoch Time 1025.2195(1025.0486), Bit/dim 1.1038, Xent 2.3026, Loss 1.1038, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6470 | Time 14.8518(14.5227) | Bit/dim 1.0933(1.1050) | Xent 2.3026(2.3026) | Loss 1.0933(1.1050) | Error 0.9089(0.9010) Steps 0(0.00) | Grad Norm 13.5237(8.6536) | Total Time 0.00(0.00)\n",
      "Iter 6480 | Time 14.7522(14.4935) | Bit/dim 1.0856(1.1023) | Xent 2.3026(2.3026) | Loss 1.0856(1.1023) | Error 0.9022(0.9009) Steps 0(0.00) | Grad Norm 8.7084(8.7651) | Total Time 0.00(0.00)\n",
      "Iter 6490 | Time 14.7235(14.4772) | Bit/dim 1.0878(1.1003) | Xent 2.3026(2.3026) | Loss 1.0878(1.1003) | Error 0.9011(0.8995) Steps 0(0.00) | Grad Norm 13.4276(8.7766) | Total Time 0.00(0.00)\n",
      "Iter 6500 | Time 14.6797(14.4941) | Bit/dim 1.0846(1.0942) | Xent 2.3026(2.3026) | Loss 1.0846(1.0942) | Error 0.9089(0.9017) Steps 0(0.00) | Grad Norm 3.0088(7.4563) | Total Time 0.00(0.00)\n",
      "Iter 6510 | Time 14.3858(14.4883) | Bit/dim 1.0662(1.0900) | Xent 2.3026(2.3026) | Loss 1.0662(1.0900) | Error 0.9089(0.9016) Steps 0(0.00) | Grad Norm 1.7698(6.3615) | Total Time 0.00(0.00)\n",
      "Iter 6520 | Time 14.4594(14.4943) | Bit/dim 1.0833(1.0868) | Xent 2.3026(2.3026) | Loss 1.0833(1.0868) | Error 0.9022(0.9019) Steps 0(0.00) | Grad Norm 1.6438(5.2214) | Total Time 0.00(0.00)\n",
      "Iter 6530 | Time 14.6836(14.4737) | Bit/dim 1.0714(1.0845) | Xent 2.3026(2.3026) | Loss 1.0714(1.0845) | Error 0.9000(0.9013) Steps 0(0.00) | Grad Norm 3.0915(4.2361) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 55.4651, Epoch Time 1025.1984(1025.0531), Bit/dim 1.0812, Xent 2.3026, Loss 1.0812, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6540 | Time 14.6649(14.4519) | Bit/dim 1.0997(1.0844) | Xent 2.3026(2.3026) | Loss 1.0997(1.0844) | Error 0.9078(0.9011) Steps 0(0.00) | Grad Norm 8.6617(4.9140) | Total Time 0.00(0.00)\n",
      "Iter 6550 | Time 14.2885(14.4306) | Bit/dim 1.1996(1.0907) | Xent 2.3026(2.3026) | Loss 1.1996(1.0907) | Error 0.8844(0.8997) Steps 0(0.00) | Grad Norm 10.9688(6.2716) | Total Time 0.00(0.00)\n",
      "Iter 6560 | Time 14.5438(14.4686) | Bit/dim 1.1645(1.1091) | Xent 2.3026(2.3026) | Loss 1.1645(1.1091) | Error 0.8900(0.8998) Steps 0(0.00) | Grad Norm 6.2713(7.6652) | Total Time 0.00(0.00)\n",
      "Iter 6570 | Time 14.5191(14.4478) | Bit/dim 1.1298(1.1196) | Xent 2.3026(2.3026) | Loss 1.1298(1.1196) | Error 0.9111(0.9001) Steps 0(0.00) | Grad Norm 16.7035(8.5404) | Total Time 0.00(0.00)\n",
      "Iter 6580 | Time 14.8918(14.4662) | Bit/dim 1.0815(1.1166) | Xent 2.3026(2.3026) | Loss 1.0815(1.1166) | Error 0.9056(0.9005) Steps 0(0.00) | Grad Norm 3.2869(8.0737) | Total Time 0.00(0.00)\n",
      "Iter 6590 | Time 14.7269(14.5013) | Bit/dim 1.0888(1.1102) | Xent 2.3026(2.3026) | Loss 1.0888(1.1102) | Error 0.8989(0.9018) Steps 0(0.00) | Grad Norm 13.1327(8.0251) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 55.1756, Epoch Time 1024.9244(1025.0492), Bit/dim 1.0842, Xent 2.3026, Loss 1.0842, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6600 | Time 14.2979(14.4946) | Bit/dim 1.0788(1.1044) | Xent 2.3026(2.3026) | Loss 1.0788(1.1044) | Error 0.9133(0.9032) Steps 0(0.00) | Grad Norm 8.1541(8.3953) | Total Time 0.00(0.00)\n",
      "Iter 6610 | Time 14.3972(14.4705) | Bit/dim 1.0850(1.0997) | Xent 2.3026(2.3026) | Loss 1.0850(1.0997) | Error 0.8822(0.9024) Steps 0(0.00) | Grad Norm 5.2499(8.4387) | Total Time 0.00(0.00)\n",
      "Iter 6620 | Time 14.4455(14.4232) | Bit/dim 1.1035(1.0975) | Xent 2.3026(2.3026) | Loss 1.1035(1.0975) | Error 0.9089(0.9031) Steps 0(0.00) | Grad Norm 11.6821(8.9798) | Total Time 0.00(0.00)\n",
      "Iter 6630 | Time 14.5774(14.4430) | Bit/dim 1.0610(1.0929) | Xent 2.3026(2.3026) | Loss 1.0610(1.0929) | Error 0.9033(0.9021) Steps 0(0.00) | Grad Norm 6.3400(7.8344) | Total Time 0.00(0.00)\n",
      "Iter 6640 | Time 13.9241(14.4015) | Bit/dim 1.0854(1.0925) | Xent 2.3026(2.3026) | Loss 1.0854(1.0925) | Error 0.9033(0.9017) Steps 0(0.00) | Grad Norm 8.5444(8.2070) | Total Time 0.00(0.00)\n",
      "Iter 6650 | Time 14.4467(14.4118) | Bit/dim 1.0872(1.0882) | Xent 2.3026(2.3026) | Loss 1.0872(1.0882) | Error 0.8944(0.9018) Steps 0(0.00) | Grad Norm 5.3850(7.1182) | Total Time 0.00(0.00)\n",
      "Iter 6660 | Time 14.1829(14.3968) | Bit/dim 1.0835(1.0859) | Xent 2.3026(2.3026) | Loss 1.0835(1.0859) | Error 0.9167(0.9017) Steps 0(0.00) | Grad Norm 4.6585(6.2486) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 56.5766, Epoch Time 1020.1397(1024.9019), Bit/dim 1.0703, Xent 2.3026, Loss 1.0703, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6670 | Time 14.5549(14.3960) | Bit/dim 1.0756(1.0835) | Xent 2.3026(2.3026) | Loss 1.0756(1.0835) | Error 0.8967(0.9017) Steps 0(0.00) | Grad Norm 1.7082(5.4919) | Total Time 0.00(0.00)\n",
      "Iter 6680 | Time 14.4874(14.3943) | Bit/dim 1.0844(1.0816) | Xent 2.3026(2.3026) | Loss 1.0844(1.0816) | Error 0.9044(0.9020) Steps 0(0.00) | Grad Norm 8.9350(5.8815) | Total Time 0.00(0.00)\n",
      "Iter 6690 | Time 14.7332(14.4422) | Bit/dim 1.1341(1.0826) | Xent 2.3026(2.3026) | Loss 1.1341(1.0826) | Error 0.8856(0.9013) Steps 0(0.00) | Grad Norm 34.0368(7.0161) | Total Time 0.00(0.00)\n",
      "Iter 6700 | Time 14.1697(14.4699) | Bit/dim 1.1286(1.1088) | Xent 2.3026(2.3026) | Loss 1.1286(1.1088) | Error 0.9044(0.9008) Steps 0(0.00) | Grad Norm 3.8318(7.5209) | Total Time 0.00(0.00)\n",
      "Iter 6710 | Time 14.5357(14.4769) | Bit/dim 1.0989(1.1099) | Xent 2.3026(2.3026) | Loss 1.0989(1.1099) | Error 0.9011(0.9010) Steps 0(0.00) | Grad Norm 6.9452(7.3326) | Total Time 0.00(0.00)\n",
      "Iter 6720 | Time 14.6425(14.5172) | Bit/dim 1.1648(1.1156) | Xent 2.3026(2.3026) | Loss 1.1648(1.1156) | Error 0.9211(0.9022) Steps 0(0.00) | Grad Norm 13.9433(8.9114) | Total Time 0.00(0.00)\n",
      "Iter 6730 | Time 14.7032(14.5560) | Bit/dim 1.1100(1.1236) | Xent 2.3026(2.3026) | Loss 1.1100(1.1236) | Error 0.8889(0.9008) Steps 0(0.00) | Grad Norm 3.0514(8.8988) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 54.0063, Epoch Time 1027.5880(1024.9825), Bit/dim 1.1048, Xent 2.3026, Loss 1.1048, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6740 | Time 14.6289(14.5440) | Bit/dim 1.0877(1.1191) | Xent 2.3026(2.3026) | Loss 1.0877(1.1191) | Error 0.9167(0.9021) Steps 0(0.00) | Grad Norm 7.2488(8.1092) | Total Time 0.00(0.00)\n",
      "Iter 6750 | Time 14.7208(14.5226) | Bit/dim 1.0851(1.1104) | Xent 2.3026(2.3026) | Loss 1.0851(1.1104) | Error 0.9056(0.9017) Steps 0(0.00) | Grad Norm 3.3180(6.7339) | Total Time 0.00(0.00)\n",
      "Iter 6760 | Time 14.3761(14.5137) | Bit/dim 1.0698(1.1027) | Xent 2.3026(2.3026) | Loss 1.0698(1.1027) | Error 0.8989(0.9015) Steps 0(0.00) | Grad Norm 4.7878(5.7867) | Total Time 0.00(0.00)\n",
      "Iter 6770 | Time 14.3589(14.5251) | Bit/dim 1.0694(1.0933) | Xent 2.3026(2.3026) | Loss 1.0694(1.0933) | Error 0.9000(0.9018) Steps 0(0.00) | Grad Norm 3.2674(4.9673) | Total Time 0.00(0.00)\n",
      "Iter 6780 | Time 14.7272(14.5395) | Bit/dim 1.0658(1.0885) | Xent 2.3026(2.3026) | Loss 1.0658(1.0885) | Error 0.9089(0.9004) Steps 0(0.00) | Grad Norm 1.7295(4.0054) | Total Time 0.00(0.00)\n",
      "Iter 6790 | Time 14.4830(14.5198) | Bit/dim 1.0609(1.0842) | Xent 2.3026(2.3026) | Loss 1.0609(1.0842) | Error 0.8978(0.9014) Steps 0(0.00) | Grad Norm 1.0193(3.9536) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 55.9208, Epoch Time 1027.3007(1025.0521), Bit/dim 1.0660, Xent 2.3026, Loss 1.0660, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6800 | Time 14.3079(14.5048) | Bit/dim 1.1330(1.0837) | Xent 2.3026(2.3026) | Loss 1.1330(1.0837) | Error 0.9111(0.9018) Steps 0(0.00) | Grad Norm 15.9387(5.1792) | Total Time 0.00(0.00)\n",
      "Iter 6810 | Time 14.5889(14.5043) | Bit/dim 1.1457(1.0922) | Xent 2.3026(2.3026) | Loss 1.1457(1.0922) | Error 0.9022(0.9025) Steps 0(0.00) | Grad Norm 10.8224(7.5570) | Total Time 0.00(0.00)\n",
      "Iter 6820 | Time 14.0365(14.4838) | Bit/dim 1.1734(1.1065) | Xent 2.3026(2.3026) | Loss 1.1734(1.1065) | Error 0.9211(0.9028) Steps 0(0.00) | Grad Norm 8.8261(8.8365) | Total Time 0.00(0.00)\n",
      "Iter 6830 | Time 14.2365(14.4635) | Bit/dim 1.1261(1.1117) | Xent 2.3026(2.3026) | Loss 1.1261(1.1117) | Error 0.9078(0.9023) Steps 0(0.00) | Grad Norm 8.8826(8.8611) | Total Time 0.00(0.00)\n",
      "Iter 6840 | Time 14.6806(14.4802) | Bit/dim 1.0829(1.1071) | Xent 2.3026(2.3026) | Loss 1.0829(1.1071) | Error 0.9144(0.9020) Steps 0(0.00) | Grad Norm 5.9416(8.2836) | Total Time 0.00(0.00)\n",
      "Iter 6850 | Time 14.3537(14.4985) | Bit/dim 1.0818(1.1009) | Xent 2.3026(2.3026) | Loss 1.0818(1.1009) | Error 0.8978(0.9019) Steps 0(0.00) | Grad Norm 3.3212(7.6621) | Total Time 0.00(0.00)\n",
      "Iter 6860 | Time 14.5140(14.5058) | Bit/dim 1.0689(1.0949) | Xent 2.3026(2.3026) | Loss 1.0689(1.0949) | Error 0.9078(0.8994) Steps 0(0.00) | Grad Norm 2.0405(6.8633) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 57.0185, Epoch Time 1027.7470(1025.1329), Bit/dim 1.1058, Xent 2.3026, Loss 1.1058, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6870 | Time 14.1164(14.4755) | Bit/dim 1.1886(1.1003) | Xent 2.3026(2.3026) | Loss 1.1886(1.1003) | Error 0.9078(0.8994) Steps 0(0.00) | Grad Norm 11.7533(8.5854) | Total Time 0.00(0.00)\n",
      "Iter 6880 | Time 14.4874(14.4963) | Bit/dim 1.1123(1.1096) | Xent 2.3026(2.3026) | Loss 1.1123(1.1096) | Error 0.8944(0.9010) Steps 0(0.00) | Grad Norm 6.7545(9.0052) | Total Time 0.00(0.00)\n",
      "Iter 6890 | Time 14.3117(14.4856) | Bit/dim 1.1041(1.1079) | Xent 2.3026(2.3026) | Loss 1.1041(1.1079) | Error 0.8822(0.8998) Steps 0(0.00) | Grad Norm 5.7673(8.3946) | Total Time 0.00(0.00)\n",
      "Iter 6900 | Time 14.4587(14.4965) | Bit/dim 1.0979(1.1019) | Xent 2.3026(2.3026) | Loss 1.0979(1.1019) | Error 0.8989(0.9007) Steps 0(0.00) | Grad Norm 4.5125(7.4294) | Total Time 0.00(0.00)\n",
      "Iter 6910 | Time 14.6940(14.5180) | Bit/dim 1.0861(1.0956) | Xent 2.3026(2.3026) | Loss 1.0861(1.0956) | Error 0.8967(0.9007) Steps 0(0.00) | Grad Norm 1.3634(6.3764) | Total Time 0.00(0.00)\n",
      "Iter 6920 | Time 14.9373(14.5058) | Bit/dim 1.1221(1.0942) | Xent 2.3026(2.3026) | Loss 1.1221(1.0942) | Error 0.9022(0.9009) Steps 0(0.00) | Grad Norm 23.4161(7.1491) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 54.6613, Epoch Time 1025.3833(1025.1404), Bit/dim 1.1121, Xent 2.3026, Loss 1.1121, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6930 | Time 14.3113(14.4911) | Bit/dim 1.1111(1.1000) | Xent 2.3026(2.3026) | Loss 1.1111(1.1000) | Error 0.8922(0.9012) Steps 0(0.00) | Grad Norm 10.5130(8.5021) | Total Time 0.00(0.00)\n",
      "Iter 6940 | Time 14.4781(14.4739) | Bit/dim 1.0894(1.1006) | Xent 2.3026(2.3026) | Loss 1.0894(1.1006) | Error 0.8978(0.9003) Steps 0(0.00) | Grad Norm 3.8353(8.1096) | Total Time 0.00(0.00)\n",
      "Iter 6950 | Time 14.5925(14.4968) | Bit/dim 1.0794(1.0953) | Xent 2.3026(2.3026) | Loss 1.0794(1.0953) | Error 0.9178(0.9023) Steps 0(0.00) | Grad Norm 2.2705(7.1088) | Total Time 0.00(0.00)\n",
      "Iter 6960 | Time 14.6054(14.5402) | Bit/dim 1.0773(1.0915) | Xent 2.3026(2.3026) | Loss 1.0773(1.0915) | Error 0.9067(0.9025) Steps 0(0.00) | Grad Norm 15.1845(7.2277) | Total Time 0.00(0.00)\n",
      "Iter 6970 | Time 14.5498(14.5244) | Bit/dim 1.0735(1.0888) | Xent 2.3026(2.3026) | Loss 1.0735(1.0888) | Error 0.8956(0.9012) Steps 0(0.00) | Grad Norm 5.2968(7.4297) | Total Time 0.00(0.00)\n",
      "Iter 6980 | Time 14.4252(14.5162) | Bit/dim 1.0947(1.0888) | Xent 2.3026(2.3026) | Loss 1.0947(1.0888) | Error 0.9000(0.9015) Steps 0(0.00) | Grad Norm 9.4383(8.1492) | Total Time 0.00(0.00)\n",
      "Iter 6990 | Time 14.3730(14.5130) | Bit/dim 1.0812(1.0877) | Xent 2.3026(2.3026) | Loss 1.0812(1.0877) | Error 0.9044(0.9017) Steps 0(0.00) | Grad Norm 7.3899(8.1333) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 56.0294, Epoch Time 1028.4906(1025.2409), Bit/dim 1.0679, Xent 2.3026, Loss 1.0679, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7000 | Time 14.5997(14.5136) | Bit/dim 1.0771(1.0835) | Xent 2.3026(2.3026) | Loss 1.0771(1.0835) | Error 0.9000(0.9011) Steps 0(0.00) | Grad Norm 2.0641(7.0266) | Total Time 0.00(0.00)\n",
      "Iter 7010 | Time 14.3761(14.5175) | Bit/dim 1.0918(1.0827) | Xent 2.3026(2.3026) | Loss 1.0918(1.0827) | Error 0.8933(0.8996) Steps 0(0.00) | Grad Norm 15.5647(7.6753) | Total Time 0.00(0.00)\n",
      "Iter 7020 | Time 14.3859(14.5057) | Bit/dim 1.1062(1.0839) | Xent 2.3026(2.3026) | Loss 1.1062(1.0839) | Error 0.9011(0.8998) Steps 0(0.00) | Grad Norm 16.4536(7.7893) | Total Time 0.00(0.00)\n",
      "Iter 7030 | Time 14.7814(14.5159) | Bit/dim 1.1326(1.0927) | Xent 2.3026(2.3026) | Loss 1.1326(1.0927) | Error 0.9189(0.9012) Steps 0(0.00) | Grad Norm 8.3773(9.0540) | Total Time 0.00(0.00)\n",
      "Iter 7040 | Time 14.3738(14.5141) | Bit/dim 1.1137(1.1019) | Xent 2.3026(2.3026) | Loss 1.1137(1.1019) | Error 0.9033(0.9009) Steps 0(0.00) | Grad Norm 6.9881(9.3938) | Total Time 0.00(0.00)\n",
      "Iter 7050 | Time 14.3625(14.4408) | Bit/dim 1.0816(1.1006) | Xent 2.3026(2.3026) | Loss 1.0816(1.1006) | Error 0.9033(0.9021) Steps 0(0.00) | Grad Norm 5.5397(8.7376) | Total Time 0.00(0.00)\n",
      "Iter 7060 | Time 14.2491(14.3970) | Bit/dim 1.0839(1.0970) | Xent 2.3026(2.3026) | Loss 1.0839(1.0970) | Error 0.9078(0.9021) Steps 0(0.00) | Grad Norm 1.4206(7.4571) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 55.3922, Epoch Time 1022.2484(1025.1511), Bit/dim 1.0699, Xent 2.3026, Loss 1.0699, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7070 | Time 14.5830(14.3885) | Bit/dim 1.0758(1.0909) | Xent 2.3026(2.3026) | Loss 1.0758(1.0909) | Error 0.8911(0.9021) Steps 0(0.00) | Grad Norm 5.7746(6.5155) | Total Time 0.00(0.00)\n",
      "Iter 7080 | Time 14.5601(14.4110) | Bit/dim 1.0691(1.0850) | Xent 2.3026(2.3026) | Loss 1.0691(1.0850) | Error 0.9100(0.9023) Steps 0(0.00) | Grad Norm 6.0838(5.8612) | Total Time 0.00(0.00)\n",
      "Iter 7090 | Time 14.5952(14.4185) | Bit/dim 1.0628(1.0806) | Xent 2.3026(2.3026) | Loss 1.0628(1.0806) | Error 0.9044(0.9012) Steps 0(0.00) | Grad Norm 4.7308(5.2565) | Total Time 0.00(0.00)\n",
      "Iter 7100 | Time 14.6077(14.4470) | Bit/dim 1.0794(1.0783) | Xent 2.3026(2.3026) | Loss 1.0794(1.0783) | Error 0.8900(0.9002) Steps 0(0.00) | Grad Norm 4.5100(4.9027) | Total Time 0.00(0.00)\n",
      "Iter 7110 | Time 14.6439(14.4608) | Bit/dim 1.0729(1.0752) | Xent 2.3026(2.3026) | Loss 1.0729(1.0752) | Error 0.8956(0.9010) Steps 0(0.00) | Grad Norm 7.8474(4.9505) | Total Time 0.00(0.00)\n",
      "Iter 7120 | Time 14.8750(14.5222) | Bit/dim 1.0609(1.0743) | Xent 2.3026(2.3026) | Loss 1.0609(1.0743) | Error 0.9044(0.9009) Steps 0(0.00) | Grad Norm 2.3220(4.9755) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 55.6399, Epoch Time 1027.3312(1025.2165), Bit/dim 1.0731, Xent 2.3026, Loss 1.0731, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7130 | Time 14.1095(14.5298) | Bit/dim 1.1987(1.0815) | Xent 2.3026(2.3026) | Loss 1.1987(1.0815) | Error 0.8844(0.9018) Steps 0(0.00) | Grad Norm 15.5813(7.0282) | Total Time 0.00(0.00)\n",
      "Iter 7140 | Time 14.3741(14.5157) | Bit/dim 1.1299(1.1070) | Xent 2.3026(2.3026) | Loss 1.1299(1.1070) | Error 0.9011(0.9022) Steps 0(0.00) | Grad Norm 3.8726(6.8010) | Total Time 0.00(0.00)\n",
      "Iter 7150 | Time 14.6115(14.5055) | Bit/dim 1.0963(1.1064) | Xent 2.3026(2.3026) | Loss 1.0963(1.1064) | Error 0.8822(0.9014) Steps 0(0.00) | Grad Norm 2.2637(6.0010) | Total Time 0.00(0.00)\n",
      "Iter 7160 | Time 14.7240(14.5196) | Bit/dim 1.0793(1.0990) | Xent 2.3026(2.3026) | Loss 1.0793(1.0990) | Error 0.9078(0.9011) Steps 0(0.00) | Grad Norm 0.9279(5.0252) | Total Time 0.00(0.00)\n",
      "Iter 7170 | Time 14.5748(14.5416) | Bit/dim 1.0883(1.0924) | Xent 2.3026(2.3026) | Loss 1.0883(1.0924) | Error 0.8922(0.9008) Steps 0(0.00) | Grad Norm 1.7078(4.0783) | Total Time 0.00(0.00)\n",
      "Iter 7180 | Time 14.7130(14.5713) | Bit/dim 1.0522(1.0878) | Xent 2.3026(2.3026) | Loss 1.0522(1.0878) | Error 0.9011(0.9012) Steps 0(0.00) | Grad Norm 4.1561(4.2188) | Total Time 0.00(0.00)\n",
      "Iter 7190 | Time 14.8104(14.6145) | Bit/dim 1.0503(1.0824) | Xent 2.3026(2.3026) | Loss 1.0503(1.0824) | Error 0.9178(0.9019) Steps 0(0.00) | Grad Norm 2.4727(4.1586) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 55.4756, Epoch Time 1032.5775(1025.4374), Bit/dim 1.0612, Xent 2.3026, Loss 1.0612, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7200 | Time 14.8180(14.6021) | Bit/dim 1.0598(1.0789) | Xent 2.3026(2.3026) | Loss 1.0598(1.0789) | Error 0.9011(0.9021) Steps 0(0.00) | Grad Norm 1.4749(4.4902) | Total Time 0.00(0.00)\n",
      "Iter 7210 | Time 15.2839(14.6210) | Bit/dim 1.1810(1.0820) | Xent 2.3026(2.3026) | Loss 1.1810(1.0820) | Error 0.9000(0.9021) Steps 0(0.00) | Grad Norm 42.3527(6.6472) | Total Time 0.00(0.00)\n",
      "Iter 7220 | Time 14.1488(14.5592) | Bit/dim 1.1613(1.1132) | Xent 2.3026(2.3026) | Loss 1.1613(1.1132) | Error 0.9067(0.9024) Steps 0(0.00) | Grad Norm 3.4440(6.6742) | Total Time 0.00(0.00)\n",
      "Iter 7230 | Time 14.9086(14.5347) | Bit/dim 1.0983(1.1132) | Xent 2.3026(2.3026) | Loss 1.0983(1.1132) | Error 0.8944(0.9014) Steps 0(0.00) | Grad Norm 2.6110(5.7446) | Total Time 0.00(0.00)\n",
      "Iter 7240 | Time 14.6410(14.5333) | Bit/dim 1.0823(1.1057) | Xent 2.3026(2.3026) | Loss 1.0823(1.1057) | Error 0.8944(0.9016) Steps 0(0.00) | Grad Norm 3.6833(5.0069) | Total Time 0.00(0.00)\n",
      "Iter 7250 | Time 15.0165(14.5797) | Bit/dim 1.0684(1.0973) | Xent 2.3026(2.3026) | Loss 1.0684(1.0973) | Error 0.8944(0.9016) Steps 0(0.00) | Grad Norm 1.5114(4.1451) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 55.5019, Epoch Time 1031.5219(1025.6199), Bit/dim 1.0637, Xent 2.3026, Loss 1.0637, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7260 | Time 14.7489(14.6224) | Bit/dim 1.0695(1.0905) | Xent 2.3026(2.3026) | Loss 1.0695(1.0905) | Error 0.9067(0.9007) Steps 0(0.00) | Grad Norm 5.9054(4.1678) | Total Time 0.00(0.00)\n",
      "Iter 7270 | Time 14.3412(14.6487) | Bit/dim 1.0704(1.0839) | Xent 2.3026(2.3026) | Loss 1.0704(1.0839) | Error 0.9144(0.9028) Steps 0(0.00) | Grad Norm 9.3088(4.3584) | Total Time 0.00(0.00)\n",
      "Iter 7280 | Time 14.4130(14.6086) | Bit/dim 1.0963(1.0854) | Xent 2.3026(2.3026) | Loss 1.0963(1.0854) | Error 0.8978(0.9030) Steps 0(0.00) | Grad Norm 7.3601(5.5758) | Total Time 0.00(0.00)\n",
      "Iter 7290 | Time 14.1573(14.5947) | Bit/dim 1.1868(1.1140) | Xent 2.3026(2.3026) | Loss 1.1868(1.1140) | Error 0.9044(0.9018) Steps 0(0.00) | Grad Norm 10.1212(7.4170) | Total Time 0.00(0.00)\n",
      "Iter 7300 | Time 14.3430(14.5649) | Bit/dim 1.1408(1.1200) | Xent 2.3026(2.3026) | Loss 1.1408(1.1200) | Error 0.8922(0.9006) Steps 0(0.00) | Grad Norm 5.0255(7.4604) | Total Time 0.00(0.00)\n",
      "Iter 7310 | Time 14.6014(14.5743) | Bit/dim 1.1019(1.1132) | Xent 2.3026(2.3026) | Loss 1.1019(1.1132) | Error 0.8933(0.8997) Steps 0(0.00) | Grad Norm 10.3940(6.9459) | Total Time 0.00(0.00)\n",
      "Iter 7320 | Time 14.3676(14.5642) | Bit/dim 1.0812(1.1066) | Xent 2.3026(2.3026) | Loss 1.0812(1.1066) | Error 0.9044(0.9003) Steps 0(0.00) | Grad Norm 1.3120(7.1864) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 54.5945, Epoch Time 1030.7227(1025.7730), Bit/dim 1.0655, Xent 2.3026, Loss 1.0655, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7330 | Time 14.5296(14.5548) | Bit/dim 1.0768(1.0977) | Xent 2.3026(2.3026) | Loss 1.0768(1.0977) | Error 0.8900(0.8997) Steps 0(0.00) | Grad Norm 2.1574(5.9091) | Total Time 0.00(0.00)\n",
      "Iter 7340 | Time 14.5241(14.5972) | Bit/dim 1.0662(1.0904) | Xent 2.3026(2.3026) | Loss 1.0662(1.0904) | Error 0.9056(0.9001) Steps 0(0.00) | Grad Norm 3.4146(4.9254) | Total Time 0.00(0.00)\n",
      "Iter 7350 | Time 14.4663(14.5886) | Bit/dim 1.0804(1.0845) | Xent 2.3026(2.3026) | Loss 1.0804(1.0845) | Error 0.9078(0.9001) Steps 0(0.00) | Grad Norm 6.9181(4.3540) | Total Time 0.00(0.00)\n",
      "Iter 7360 | Time 14.7041(14.5742) | Bit/dim 1.0735(1.0798) | Xent 2.3026(2.3026) | Loss 1.0735(1.0798) | Error 0.8967(0.9005) Steps 0(0.00) | Grad Norm 6.5066(4.7464) | Total Time 0.00(0.00)\n",
      "Iter 7370 | Time 14.2065(14.5835) | Bit/dim 1.1074(1.0781) | Xent 2.3026(2.3026) | Loss 1.1074(1.0781) | Error 0.9189(0.9014) Steps 0(0.00) | Grad Norm 13.2236(5.5840) | Total Time 0.00(0.00)\n",
      "Iter 7380 | Time 14.3029(14.5872) | Bit/dim 1.1694(1.1115) | Xent 2.3026(2.3026) | Loss 1.1694(1.1115) | Error 0.9256(0.9014) Steps 0(0.00) | Grad Norm 4.9306(6.7680) | Total Time 0.00(0.00)\n",
      "Iter 7390 | Time 14.6572(14.5455) | Bit/dim 1.1083(1.1155) | Xent 2.3026(2.3026) | Loss 1.1083(1.1155) | Error 0.8744(0.9014) Steps 0(0.00) | Grad Norm 3.9614(6.0495) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 55.6717, Epoch Time 1032.0848(1025.9624), Bit/dim 1.0940, Xent 2.3026, Loss 1.0940, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7400 | Time 14.4510(14.5482) | Bit/dim 1.0777(1.1088) | Xent 2.3026(2.3026) | Loss 1.0777(1.1088) | Error 0.9000(0.9027) Steps 0(0.00) | Grad Norm 2.5330(5.1713) | Total Time 0.00(0.00)\n",
      "Iter 7410 | Time 14.3580(14.5486) | Bit/dim 1.0757(1.0985) | Xent 2.3026(2.3026) | Loss 1.0757(1.0985) | Error 0.8933(0.9028) Steps 0(0.00) | Grad Norm 3.2309(4.6060) | Total Time 0.00(0.00)\n",
      "Iter 7420 | Time 14.7390(14.5979) | Bit/dim 1.0666(1.0912) | Xent 2.3026(2.3026) | Loss 1.0666(1.0912) | Error 0.8856(0.9022) Steps 0(0.00) | Grad Norm 2.8029(4.5221) | Total Time 0.00(0.00)\n",
      "Iter 7430 | Time 14.5343(14.6113) | Bit/dim 1.0764(1.0842) | Xent 2.3026(2.3026) | Loss 1.0764(1.0842) | Error 0.8867(0.9016) Steps 0(0.00) | Grad Norm 8.2821(4.6936) | Total Time 0.00(0.00)\n",
      "Iter 7440 | Time 14.4211(14.6280) | Bit/dim 1.0805(1.0797) | Xent 2.3026(2.3026) | Loss 1.0805(1.0797) | Error 0.9044(0.9019) Steps 0(0.00) | Grad Norm 24.6828(5.5759) | Total Time 0.00(0.00)\n",
      "Iter 7450 | Time 15.6774(14.6865) | Bit/dim 1.2226(1.1053) | Xent 2.3026(2.3026) | Loss 1.2226(1.1053) | Error 0.8956(0.9001) Steps 0(0.00) | Grad Norm 33.8276(7.8558) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 54.9173, Epoch Time 1035.6126(1026.2519), Bit/dim 1.1204, Xent 2.3026, Loss 1.1204, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7460 | Time 14.2932(14.6200) | Bit/dim 1.1423(1.1195) | Xent 2.3026(2.3026) | Loss 1.1423(1.1195) | Error 0.9167(0.9008) Steps 0(0.00) | Grad Norm 6.1731(7.9827) | Total Time 0.00(0.00)\n",
      "Iter 7470 | Time 14.5831(14.5945) | Bit/dim 1.0877(1.1165) | Xent 2.3026(2.3026) | Loss 1.0877(1.1165) | Error 0.9100(0.9001) Steps 0(0.00) | Grad Norm 8.2679(7.5024) | Total Time 0.00(0.00)\n",
      "Iter 7480 | Time 14.4747(14.5751) | Bit/dim 1.0753(1.1071) | Xent 2.3026(2.3026) | Loss 1.0753(1.1071) | Error 0.8844(0.9002) Steps 0(0.00) | Grad Norm 9.2471(6.8182) | Total Time 0.00(0.00)\n",
      "Iter 7490 | Time 14.6157(14.5302) | Bit/dim 1.1052(1.1017) | Xent 2.3026(2.3026) | Loss 1.1052(1.1017) | Error 0.8767(0.8987) Steps 0(0.00) | Grad Norm 9.7646(7.4911) | Total Time 0.00(0.00)\n",
      "Iter 7500 | Time 14.4117(14.5098) | Bit/dim 1.0994(1.0961) | Xent 2.3026(2.3026) | Loss 1.0994(1.0961) | Error 0.8933(0.8998) Steps 0(0.00) | Grad Norm 10.8284(7.5290) | Total Time 0.00(0.00)\n",
      "Iter 7510 | Time 14.8135(14.5243) | Bit/dim 1.0741(1.0908) | Xent 2.3026(2.3026) | Loss 1.0741(1.0908) | Error 0.8956(0.9005) Steps 0(0.00) | Grad Norm 5.4211(7.0412) | Total Time 0.00(0.00)\n",
      "Iter 7520 | Time 14.2132(14.5249) | Bit/dim 1.0739(1.0885) | Xent 2.3026(2.3026) | Loss 1.0739(1.0885) | Error 0.8967(0.9019) Steps 0(0.00) | Grad Norm 8.5465(7.4663) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 55.8746, Epoch Time 1027.1063(1026.2775), Bit/dim 1.0658, Xent 2.3026, Loss 1.0658, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7530 | Time 14.4757(14.5342) | Bit/dim 1.0644(1.0819) | Xent 2.3026(2.3026) | Loss 1.0644(1.0819) | Error 0.8933(0.9011) Steps 0(0.00) | Grad Norm 7.0502(6.7037) | Total Time 0.00(0.00)\n",
      "Iter 7540 | Time 15.3078(14.5561) | Bit/dim 1.1583(1.0860) | Xent 2.3026(2.3026) | Loss 1.1583(1.0860) | Error 0.9178(0.9013) Steps 0(0.00) | Grad Norm 30.3492(8.0202) | Total Time 0.00(0.00)\n",
      "Iter 7550 | Time 14.8571(14.5862) | Bit/dim 1.1163(1.1005) | Xent 2.3026(2.3026) | Loss 1.1163(1.1005) | Error 0.9056(0.9014) Steps 0(0.00) | Grad Norm 10.8333(8.8289) | Total Time 0.00(0.00)\n",
      "Iter 7560 | Time 14.7841(14.5971) | Bit/dim 1.0897(1.1013) | Xent 2.3026(2.3026) | Loss 1.0897(1.1013) | Error 0.9022(0.9015) Steps 0(0.00) | Grad Norm 3.9942(8.1802) | Total Time 0.00(0.00)\n",
      "Iter 7570 | Time 14.4721(14.5716) | Bit/dim 1.0743(1.0955) | Xent 2.3026(2.3026) | Loss 1.0743(1.0955) | Error 0.9089(0.9018) Steps 0(0.00) | Grad Norm 1.2494(7.1432) | Total Time 0.00(0.00)\n",
      "Iter 7580 | Time 14.6008(14.5631) | Bit/dim 1.0744(1.0893) | Xent 2.3026(2.3026) | Loss 1.0744(1.0893) | Error 0.8911(0.9014) Steps 0(0.00) | Grad Norm 0.9505(5.8443) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 55.3310, Epoch Time 1032.2972(1026.4581), Bit/dim 1.0577, Xent 2.3026, Loss 1.0577, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7590 | Time 14.7042(14.5862) | Bit/dim 1.0523(1.0825) | Xent 2.3026(2.3026) | Loss 1.0523(1.0825) | Error 0.9078(0.9020) Steps 0(0.00) | Grad Norm 0.7763(4.9100) | Total Time 0.00(0.00)\n",
      "Iter 7600 | Time 15.1996(14.6300) | Bit/dim 1.0525(1.0767) | Xent 2.3026(2.3026) | Loss 1.0525(1.0767) | Error 0.9189(0.9016) Steps 0(0.00) | Grad Norm 1.0863(4.2156) | Total Time 0.00(0.00)\n",
      "Iter 7610 | Time 14.7633(14.6894) | Bit/dim 1.0697(1.0734) | Xent 2.3026(2.3026) | Loss 1.0697(1.0734) | Error 0.9000(0.9016) Steps 0(0.00) | Grad Norm 7.6693(4.2414) | Total Time 0.00(0.00)\n",
      "Iter 7620 | Time 14.4885(14.7063) | Bit/dim 1.0838(1.0709) | Xent 2.3026(2.3026) | Loss 1.0838(1.0709) | Error 0.8911(0.9001) Steps 0(0.00) | Grad Norm 15.7870(4.8133) | Total Time 0.00(0.00)\n",
      "Iter 7630 | Time 14.8473(14.7168) | Bit/dim 1.0991(1.0771) | Xent 2.3026(2.3026) | Loss 1.0991(1.0771) | Error 0.9033(0.9006) Steps 0(0.00) | Grad Norm 10.1893(6.9573) | Total Time 0.00(0.00)\n",
      "Iter 7640 | Time 15.1276(14.7428) | Bit/dim 1.1464(1.0811) | Xent 2.3026(2.3026) | Loss 1.1464(1.0811) | Error 0.9156(0.9025) Steps 0(0.00) | Grad Norm 30.0279(8.1078) | Total Time 0.00(0.00)\n",
      "Iter 7650 | Time 14.8262(14.7497) | Bit/dim 1.1409(1.1035) | Xent 2.3026(2.3026) | Loss 1.1409(1.1035) | Error 0.8922(0.9021) Steps 0(0.00) | Grad Norm 5.5062(8.6776) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 56.5039, Epoch Time 1045.9558(1027.0430), Bit/dim 1.1032, Xent 2.3026, Loss 1.1032, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7660 | Time 14.4792(14.7365) | Bit/dim 1.0959(1.1069) | Xent 2.3026(2.3026) | Loss 1.0959(1.1069) | Error 0.8978(0.9009) Steps 0(0.00) | Grad Norm 5.4796(8.3337) | Total Time 0.00(0.00)\n",
      "Iter 7670 | Time 14.5766(14.7456) | Bit/dim 1.0843(1.1018) | Xent 2.3026(2.3026) | Loss 1.0843(1.1018) | Error 0.8878(0.9003) Steps 0(0.00) | Grad Norm 4.3490(7.3904) | Total Time 0.00(0.00)\n",
      "Iter 7680 | Time 14.6859(14.6493) | Bit/dim 1.0793(1.0948) | Xent 2.3026(2.3026) | Loss 1.0793(1.0948) | Error 0.8989(0.9000) Steps 0(0.00) | Grad Norm 3.1214(6.6064) | Total Time 0.00(0.00)\n",
      "Iter 7690 | Time 14.2519(14.5889) | Bit/dim 1.0598(1.0866) | Xent 2.3026(2.3026) | Loss 1.0598(1.0866) | Error 0.9033(0.9020) Steps 0(0.00) | Grad Norm 4.9579(6.0053) | Total Time 0.00(0.00)\n",
      "Iter 7700 | Time 14.3900(14.5776) | Bit/dim 1.0588(1.0800) | Xent 2.3026(2.3026) | Loss 1.0588(1.0800) | Error 0.9033(0.9011) Steps 0(0.00) | Grad Norm 4.1940(5.5994) | Total Time 0.00(0.00)\n",
      "Iter 7710 | Time 14.8898(14.5839) | Bit/dim 1.0655(1.0753) | Xent 2.3026(2.3026) | Loss 1.0655(1.0753) | Error 0.8978(0.9007) Steps 0(0.00) | Grad Norm 0.9693(4.6692) | Total Time 0.00(0.00)\n",
      "Iter 7720 | Time 14.5226(14.5920) | Bit/dim 1.0650(1.0706) | Xent 2.3026(2.3026) | Loss 1.0650(1.0706) | Error 0.8944(0.9015) Steps 0(0.00) | Grad Norm 9.1884(4.2327) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 56.1649, Epoch Time 1031.8140(1027.1861), Bit/dim 1.0564, Xent 2.3026, Loss 1.0564, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7730 | Time 14.8133(14.6272) | Bit/dim 1.1047(1.0725) | Xent 2.3026(2.3026) | Loss 1.1047(1.0725) | Error 0.9022(0.9017) Steps 0(0.00) | Grad Norm 10.0567(5.6044) | Total Time 0.00(0.00)\n",
      "Iter 7740 | Time 14.3415(14.6659) | Bit/dim 1.1802(1.0834) | Xent 2.3026(2.3026) | Loss 1.1802(1.0834) | Error 0.8989(0.9016) Steps 0(0.00) | Grad Norm 10.9748(7.7620) | Total Time 0.00(0.00)\n",
      "Iter 7750 | Time 14.3978(14.6980) | Bit/dim 1.1138(1.0949) | Xent 2.3026(2.3026) | Loss 1.1138(1.0949) | Error 0.9111(0.9024) Steps 0(0.00) | Grad Norm 6.9559(8.3910) | Total Time 0.00(0.00)\n",
      "Iter 7760 | Time 14.8635(14.6847) | Bit/dim 1.0838(1.0935) | Xent 2.3026(2.3026) | Loss 1.0838(1.0935) | Error 0.9033(0.9023) Steps 0(0.00) | Grad Norm 4.4431(7.9105) | Total Time 0.00(0.00)\n",
      "Iter 7770 | Time 14.6530(14.6638) | Bit/dim 1.0836(1.0914) | Xent 2.3026(2.3026) | Loss 1.0836(1.0914) | Error 0.8956(0.9014) Steps 0(0.00) | Grad Norm 7.4137(7.9967) | Total Time 0.00(0.00)\n",
      "Iter 7780 | Time 14.4927(14.6424) | Bit/dim 1.0635(1.0868) | Xent 2.3026(2.3026) | Loss 1.0635(1.0868) | Error 0.9067(0.9017) Steps 0(0.00) | Grad Norm 5.8202(7.7033) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 58.6932, Epoch Time 1042.2248(1027.6373), Bit/dim 1.0846, Xent 2.3026, Loss 1.0846, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7790 | Time 14.8605(14.6529) | Bit/dim 1.0885(1.0835) | Xent 2.3026(2.3026) | Loss 1.0885(1.0835) | Error 0.9078(0.9010) Steps 0(0.00) | Grad Norm 9.3527(7.9759) | Total Time 0.00(0.00)\n",
      "Iter 7800 | Time 15.4740(14.7088) | Bit/dim 1.1292(1.0873) | Xent 2.3026(2.3026) | Loss 1.1292(1.0873) | Error 0.8822(0.8999) Steps 0(0.00) | Grad Norm 25.2339(9.0554) | Total Time 0.00(0.00)\n",
      "Iter 7810 | Time 14.3301(14.6980) | Bit/dim 1.0735(1.0869) | Xent 2.3026(2.3026) | Loss 1.0735(1.0869) | Error 0.9078(0.9024) Steps 0(0.00) | Grad Norm 7.0048(9.0483) | Total Time 0.00(0.00)\n",
      "Iter 7820 | Time 14.6810(14.6529) | Bit/dim 1.0683(1.0839) | Xent 2.3026(2.3026) | Loss 1.0683(1.0839) | Error 0.8989(0.9023) Steps 0(0.00) | Grad Norm 1.4475(8.3468) | Total Time 0.00(0.00)\n",
      "Iter 7830 | Time 14.3827(14.6267) | Bit/dim 1.0668(1.0792) | Xent 2.3026(2.3026) | Loss 1.0668(1.0792) | Error 0.8989(0.9015) Steps 0(0.00) | Grad Norm 5.3633(7.7114) | Total Time 0.00(0.00)\n",
      "Iter 7840 | Time 14.8612(14.6597) | Bit/dim 1.0653(1.0756) | Xent 2.3026(2.3026) | Loss 1.0653(1.0756) | Error 0.9033(0.9011) Steps 0(0.00) | Grad Norm 3.4745(6.7098) | Total Time 0.00(0.00)\n",
      "Iter 7850 | Time 15.1798(14.7434) | Bit/dim 1.0606(1.0719) | Xent 2.3026(2.3026) | Loss 1.0606(1.0719) | Error 0.8900(0.9004) Steps 0(0.00) | Grad Norm 0.7564(5.4880) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 56.7905, Epoch Time 1043.8297(1028.1231), Bit/dim 1.0528, Xent 2.3026, Loss 1.0528, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7860 | Time 15.1702(14.8327) | Bit/dim 1.0425(1.0691) | Xent 2.3026(2.3026) | Loss 1.0425(1.0691) | Error 0.8967(0.9001) Steps 0(0.00) | Grad Norm 2.8969(4.7607) | Total Time 0.00(0.00)\n",
      "Iter 7870 | Time 15.0758(14.8976) | Bit/dim 1.0369(1.0661) | Xent 2.3026(2.3026) | Loss 1.0369(1.0661) | Error 0.9222(0.9007) Steps 0(0.00) | Grad Norm 5.4597(4.5370) | Total Time 0.00(0.00)\n",
      "Iter 7880 | Time 15.1311(14.9288) | Bit/dim 1.0724(1.0652) | Xent 2.3026(2.3026) | Loss 1.0724(1.0652) | Error 0.8844(0.8995) Steps 0(0.00) | Grad Norm 8.2351(4.3208) | Total Time 0.00(0.00)\n",
      "Iter 7890 | Time 15.0614(14.9148) | Bit/dim 1.0491(1.0645) | Xent 2.3026(2.3026) | Loss 1.0491(1.0645) | Error 0.9056(0.9012) Steps 0(0.00) | Grad Norm 2.3698(4.9977) | Total Time 0.00(0.00)\n",
      "Iter 7900 | Time 15.3374(14.9256) | Bit/dim 1.1661(1.0909) | Xent 2.3026(2.3026) | Loss 1.1661(1.0909) | Error 0.8933(0.9003) Steps 0(0.00) | Grad Norm 7.2170(7.0154) | Total Time 0.00(0.00)\n",
      "Iter 7910 | Time 14.8382(14.9085) | Bit/dim 1.0975(1.0995) | Xent 2.3026(2.3026) | Loss 1.0975(1.0995) | Error 0.9122(0.9013) Steps 0(0.00) | Grad Norm 4.8834(7.1438) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 55.6146, Epoch Time 1057.8794(1029.0158), Bit/dim 1.0715, Xent 2.3026, Loss 1.0715, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7920 | Time 14.9373(14.9257) | Bit/dim 1.0742(1.0951) | Xent 2.3026(2.3026) | Loss 1.0742(1.0951) | Error 0.9144(0.9024) Steps 0(0.00) | Grad Norm 5.3660(6.7206) | Total Time 0.00(0.00)\n",
      "Iter 7930 | Time 15.1465(14.9115) | Bit/dim 1.0749(1.0885) | Xent 2.3026(2.3026) | Loss 1.0749(1.0885) | Error 0.8956(0.9015) Steps 0(0.00) | Grad Norm 2.4256(5.5742) | Total Time 0.00(0.00)\n",
      "Iter 7940 | Time 15.0067(14.9380) | Bit/dim 1.0709(1.0817) | Xent 2.3026(2.3026) | Loss 1.0709(1.0817) | Error 0.8933(0.9000) Steps 0(0.00) | Grad Norm 3.5432(4.7286) | Total Time 0.00(0.00)\n",
      "Iter 7950 | Time 14.9876(14.9642) | Bit/dim 1.0547(1.0755) | Xent 2.3026(2.3026) | Loss 1.0547(1.0755) | Error 0.9089(0.9010) Steps 0(0.00) | Grad Norm 3.4811(4.3176) | Total Time 0.00(0.00)\n",
      "Iter 7960 | Time 15.0496(14.9751) | Bit/dim 1.0515(1.0703) | Xent 2.3026(2.3026) | Loss 1.0515(1.0703) | Error 0.9144(0.9030) Steps 0(0.00) | Grad Norm 7.1217(4.6404) | Total Time 0.00(0.00)\n",
      "Iter 7970 | Time 15.5206(15.0030) | Bit/dim 1.1626(1.0730) | Xent 2.3026(2.3026) | Loss 1.1626(1.0730) | Error 0.8800(0.9018) Steps 0(0.00) | Grad Norm 38.5960(6.4044) | Total Time 0.00(0.00)\n",
      "Iter 7980 | Time 15.2849(15.0097) | Bit/dim 1.1539(1.1039) | Xent 2.3026(2.3026) | Loss 1.1539(1.1039) | Error 0.8778(0.9021) Steps 0(0.00) | Grad Norm 4.3894(6.7111) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 55.8453, Epoch Time 1061.0908(1029.9780), Bit/dim 1.0983, Xent 2.3026, Loss 1.0983, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7990 | Time 14.9209(15.0269) | Bit/dim 1.1011(1.1030) | Xent 2.3026(2.3026) | Loss 1.1011(1.1030) | Error 0.8922(0.8996) Steps 0(0.00) | Grad Norm 4.3401(6.0259) | Total Time 0.00(0.00)\n",
      "Iter 8000 | Time 14.7452(14.9956) | Bit/dim 1.0756(1.0966) | Xent 2.3026(2.3026) | Loss 1.0756(1.0966) | Error 0.8944(0.8990) Steps 0(0.00) | Grad Norm 1.8999(5.1131) | Total Time 0.00(0.00)\n",
      "Iter 8010 | Time 14.9393(14.9815) | Bit/dim 1.0637(1.0870) | Xent 2.3026(2.3026) | Loss 1.0637(1.0870) | Error 0.9000(0.9000) Steps 0(0.00) | Grad Norm 0.7163(4.2280) | Total Time 0.00(0.00)\n",
      "Iter 8020 | Time 14.8698(14.9735) | Bit/dim 1.0580(1.0803) | Xent 2.3026(2.3026) | Loss 1.0580(1.0803) | Error 0.8911(0.9000) Steps 0(0.00) | Grad Norm 5.0497(4.3937) | Total Time 0.00(0.00)\n",
      "Iter 8030 | Time 15.0784(14.9584) | Bit/dim 1.0689(1.0754) | Xent 2.3026(2.3026) | Loss 1.0689(1.0754) | Error 0.8978(0.9006) Steps 0(0.00) | Grad Norm 1.1702(4.7988) | Total Time 0.00(0.00)\n",
      "Iter 8040 | Time 14.8864(14.9575) | Bit/dim 1.0966(1.0765) | Xent 2.3026(2.3026) | Loss 1.0966(1.0765) | Error 0.9044(0.9016) Steps 0(0.00) | Grad Norm 10.7315(6.3791) | Total Time 0.00(0.00)\n",
      "Iter 8050 | Time 14.5036(14.9604) | Bit/dim 1.1167(1.0793) | Xent 2.3026(2.3026) | Loss 1.1167(1.0793) | Error 0.9133(0.9023) Steps 0(0.00) | Grad Norm 12.1152(7.8998) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 57.3044, Epoch Time 1058.3318(1030.8286), Bit/dim 1.1040, Xent 2.3026, Loss 1.1040, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8060 | Time 15.0761(14.9924) | Bit/dim 1.1599(1.0898) | Xent 2.3026(2.3026) | Loss 1.1599(1.0898) | Error 0.9011(0.9022) Steps 0(0.00) | Grad Norm 8.2179(8.8220) | Total Time 0.00(0.00)\n",
      "Iter 8070 | Time 14.9968(15.0067) | Bit/dim 1.0892(1.0986) | Xent 2.3026(2.3026) | Loss 1.0892(1.0986) | Error 0.8989(0.9019) Steps 0(0.00) | Grad Norm 8.7303(8.8344) | Total Time 0.00(0.00)\n",
      "Iter 8080 | Time 15.0109(14.9558) | Bit/dim 1.0718(1.0958) | Xent 2.3026(2.3026) | Loss 1.0718(1.0958) | Error 0.9078(0.9013) Steps 0(0.00) | Grad Norm 3.7834(7.7955) | Total Time 0.00(0.00)\n",
      "Iter 8090 | Time 15.1324(14.9708) | Bit/dim 1.0532(1.0889) | Xent 2.3026(2.3026) | Loss 1.0532(1.0889) | Error 0.8956(0.9011) Steps 0(0.00) | Grad Norm 3.0856(6.8119) | Total Time 0.00(0.00)\n",
      "Iter 8100 | Time 14.9110(14.9334) | Bit/dim 1.0496(1.0840) | Xent 2.3026(2.3026) | Loss 1.0496(1.0840) | Error 0.9100(0.9019) Steps 0(0.00) | Grad Norm 4.8638(7.2015) | Total Time 0.00(0.00)\n",
      "Iter 8110 | Time 15.1440(14.9608) | Bit/dim 1.0987(1.0816) | Xent 2.3026(2.3026) | Loss 1.0987(1.0816) | Error 0.9144(0.9015) Steps 0(0.00) | Grad Norm 20.3499(7.5230) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 62.5181, Epoch Time 1063.9046(1031.8209), Bit/dim 1.1204, Xent 2.3026, Loss 1.1204, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8120 | Time 14.7566(14.9334) | Bit/dim 1.1346(1.0858) | Xent 2.3026(2.3026) | Loss 1.1346(1.0858) | Error 0.9144(0.9021) Steps 0(0.00) | Grad Norm 10.1460(8.5807) | Total Time 0.00(0.00)\n",
      "Iter 8130 | Time 14.9658(14.9680) | Bit/dim 1.1092(1.0910) | Xent 2.3026(2.3026) | Loss 1.1092(1.0910) | Error 0.9033(0.9010) Steps 0(0.00) | Grad Norm 8.0993(8.9380) | Total Time 0.00(0.00)\n",
      "Iter 8140 | Time 15.0462(14.9641) | Bit/dim 1.0648(1.0891) | Xent 2.3026(2.3026) | Loss 1.0648(1.0891) | Error 0.9078(0.9002) Steps 0(0.00) | Grad Norm 3.7963(8.4483) | Total Time 0.00(0.00)\n",
      "Iter 8150 | Time 14.6822(14.9405) | Bit/dim 1.0693(1.0824) | Xent 2.3026(2.3026) | Loss 1.0693(1.0824) | Error 0.8956(0.9010) Steps 0(0.00) | Grad Norm 4.5369(7.3179) | Total Time 0.00(0.00)\n",
      "Iter 8160 | Time 15.0912(14.9163) | Bit/dim 1.0709(1.0782) | Xent 2.3026(2.3026) | Loss 1.0709(1.0782) | Error 0.8956(0.9013) Steps 0(0.00) | Grad Norm 2.4661(6.3213) | Total Time 0.00(0.00)\n",
      "Iter 8170 | Time 15.2698(14.9714) | Bit/dim 1.0737(1.0772) | Xent 2.3026(2.3026) | Loss 1.0737(1.0772) | Error 0.8978(0.9023) Steps 0(0.00) | Grad Norm 4.4969(6.9983) | Total Time 0.00(0.00)\n",
      "Iter 8180 | Time 15.1400(15.0039) | Bit/dim 1.0877(1.0868) | Xent 2.3026(2.3026) | Loss 1.0877(1.0868) | Error 0.9078(0.9021) Steps 0(0.00) | Grad Norm 4.3735(8.1389) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 57.6390, Epoch Time 1061.5155(1032.7118), Bit/dim 1.0979, Xent 2.3026, Loss 1.0979, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8190 | Time 15.1667(15.0600) | Bit/dim 1.0722(1.0882) | Xent 2.3026(2.3026) | Loss 1.0722(1.0882) | Error 0.9178(0.9031) Steps 0(0.00) | Grad Norm 4.1333(7.8255) | Total Time 0.00(0.00)\n",
      "Iter 8200 | Time 14.9736(15.0844) | Bit/dim 1.0402(1.0830) | Xent 2.3026(2.3026) | Loss 1.0402(1.0830) | Error 0.9156(0.9016) Steps 0(0.00) | Grad Norm 3.9222(6.8568) | Total Time 0.00(0.00)\n",
      "Iter 8210 | Time 15.2268(15.0688) | Bit/dim 1.0669(1.0777) | Xent 2.3026(2.3026) | Loss 1.0669(1.0777) | Error 0.8922(0.9003) Steps 0(0.00) | Grad Norm 1.3018(5.8285) | Total Time 0.00(0.00)\n",
      "Iter 8220 | Time 15.9396(15.1898) | Bit/dim 1.0774(1.0727) | Xent 2.3026(2.3026) | Loss 1.0774(1.0727) | Error 0.8989(0.8995) Steps 0(0.00) | Grad Norm 18.5877(6.1072) | Total Time 0.00(0.00)\n",
      "Iter 8230 | Time 14.6305(15.2642) | Bit/dim 1.0988(1.0836) | Xent 2.3026(2.3026) | Loss 1.0988(1.0836) | Error 0.9067(0.9011) Steps 0(0.00) | Grad Norm 10.4875(7.7709) | Total Time 0.00(0.00)\n",
      "Iter 8240 | Time 15.9791(15.2980) | Bit/dim 1.1022(1.0900) | Xent 2.3026(2.3026) | Loss 1.1022(1.0900) | Error 0.9056(0.9009) Steps 0(0.00) | Grad Norm 14.1675(7.8763) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 56.8903, Epoch Time 1081.6135(1034.1788), Bit/dim 1.0669, Xent 2.3026, Loss 1.0669, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8250 | Time 14.7757(15.3057) | Bit/dim 1.0711(1.0859) | Xent 2.3026(2.3026) | Loss 1.0711(1.0859) | Error 0.9267(0.9028) Steps 0(0.00) | Grad Norm 4.7613(7.1245) | Total Time 0.00(0.00)\n",
      "Iter 8260 | Time 15.2891(15.2927) | Bit/dim 1.0553(1.0796) | Xent 2.3026(2.3026) | Loss 1.0553(1.0796) | Error 0.9111(0.9033) Steps 0(0.00) | Grad Norm 3.6462(6.1761) | Total Time 0.00(0.00)\n",
      "Iter 8270 | Time 15.2207(15.2993) | Bit/dim 1.0560(1.0748) | Xent 2.3026(2.3026) | Loss 1.0560(1.0748) | Error 0.9044(0.9022) Steps 0(0.00) | Grad Norm 1.9913(5.2815) | Total Time 0.00(0.00)\n",
      "Iter 8280 | Time 15.4311(15.3526) | Bit/dim 1.0454(1.0694) | Xent 2.3026(2.3026) | Loss 1.0454(1.0694) | Error 0.8978(0.9014) Steps 0(0.00) | Grad Norm 2.3003(4.3793) | Total Time 0.00(0.00)\n",
      "Iter 8290 | Time 15.4783(15.3756) | Bit/dim 1.0584(1.0650) | Xent 2.3026(2.3026) | Loss 1.0584(1.0650) | Error 0.9133(0.9019) Steps 0(0.00) | Grad Norm 3.5693(3.8402) | Total Time 0.00(0.00)\n",
      "Iter 8300 | Time 15.4338(15.4096) | Bit/dim 1.0635(1.0630) | Xent 2.3026(2.3026) | Loss 1.0635(1.0630) | Error 0.9089(0.9005) Steps 0(0.00) | Grad Norm 7.9107(3.8140) | Total Time 0.00(0.00)\n",
      "Iter 8310 | Time 15.5320(15.4429) | Bit/dim 1.0567(1.0607) | Xent 2.3026(2.3026) | Loss 1.0567(1.0607) | Error 0.9222(0.9008) Steps 0(0.00) | Grad Norm 3.6115(4.0697) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 56.9365, Epoch Time 1088.9601(1035.8222), Bit/dim 1.1527, Xent 2.3026, Loss 1.1527, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8320 | Time 15.7494(15.4425) | Bit/dim 1.1699(1.0738) | Xent 2.3026(2.3026) | Loss 1.1699(1.0738) | Error 0.8956(0.9017) Steps 0(0.00) | Grad Norm 29.4342(6.3078) | Total Time 0.00(0.00)\n",
      "Iter 8330 | Time 14.6459(15.3789) | Bit/dim 1.0985(1.0907) | Xent 2.3026(2.3026) | Loss 1.0985(1.0907) | Error 0.9022(0.9018) Steps 0(0.00) | Grad Norm 4.5291(6.9697) | Total Time 0.00(0.00)\n",
      "Iter 8340 | Time 15.0214(15.3317) | Bit/dim 1.0905(1.0911) | Xent 2.3026(2.3026) | Loss 1.0905(1.0911) | Error 0.9000(0.9025) Steps 0(0.00) | Grad Norm 4.3589(6.6430) | Total Time 0.00(0.00)\n",
      "Iter 8350 | Time 14.9963(15.2810) | Bit/dim 1.0644(1.0848) | Xent 2.3026(2.3026) | Loss 1.0644(1.0848) | Error 0.8978(0.9008) Steps 0(0.00) | Grad Norm 2.4990(5.8924) | Total Time 0.00(0.00)\n",
      "Iter 8360 | Time 15.5258(15.2823) | Bit/dim 1.0768(1.0812) | Xent 2.3026(2.3026) | Loss 1.0768(1.0812) | Error 0.9011(0.9011) Steps 0(0.00) | Grad Norm 7.8053(6.7261) | Total Time 0.00(0.00)\n",
      "Iter 8370 | Time 16.7093(15.3779) | Bit/dim 1.0797(1.0771) | Xent 2.3026(2.3026) | Loss 1.0797(1.0771) | Error 0.9078(0.9010) Steps 0(0.00) | Grad Norm 22.3310(6.8450) | Total Time 0.00(0.00)\n",
      "Iter 8380 | Time 14.9556(15.3680) | Bit/dim 1.0583(1.0854) | Xent 2.3026(2.3026) | Loss 1.0583(1.0854) | Error 0.8978(0.9012) Steps 0(0.00) | Grad Norm 7.6279(8.2884) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 57.0905, Epoch Time 1081.6567(1037.1973), Bit/dim 1.1035, Xent 2.3026, Loss 1.1035, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8390 | Time 15.1062(15.3528) | Bit/dim 1.0843(1.0860) | Xent 2.3026(2.3026) | Loss 1.0843(1.0860) | Error 0.9033(0.9010) Steps 0(0.00) | Grad Norm 2.8781(7.9632) | Total Time 0.00(0.00)\n",
      "Iter 8400 | Time 15.2635(15.3329) | Bit/dim 1.0686(1.0815) | Xent 2.3026(2.3026) | Loss 1.0686(1.0815) | Error 0.9022(0.9013) Steps 0(0.00) | Grad Norm 2.9782(7.0738) | Total Time 0.00(0.00)\n",
      "Iter 8410 | Time 15.1729(15.2924) | Bit/dim 1.0663(1.0769) | Xent 2.3026(2.3026) | Loss 1.0663(1.0769) | Error 0.8856(0.9009) Steps 0(0.00) | Grad Norm 1.3278(6.0836) | Total Time 0.00(0.00)\n",
      "Iter 8420 | Time 16.1306(15.3171) | Bit/dim 1.0611(1.0710) | Xent 2.3026(2.3026) | Loss 1.0611(1.0710) | Error 0.9000(0.9005) Steps 0(0.00) | Grad Norm 14.7713(5.9579) | Total Time 0.00(0.00)\n",
      "Iter 8430 | Time 15.3054(15.3272) | Bit/dim 1.0405(1.0697) | Xent 2.3026(2.3026) | Loss 1.0405(1.0697) | Error 0.9056(0.9006) Steps 0(0.00) | Grad Norm 2.8585(6.2445) | Total Time 0.00(0.00)\n",
      "Iter 8440 | Time 15.3823(15.3389) | Bit/dim 1.0479(1.0656) | Xent 2.3026(2.3026) | Loss 1.0479(1.0656) | Error 0.9200(0.9010) Steps 0(0.00) | Grad Norm 4.5480(6.0106) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 56.4892, Epoch Time 1082.1770(1038.5467), Bit/dim 1.1252, Xent 2.3026, Loss 1.1252, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8450 | Time 15.7909(15.3543) | Bit/dim 1.1449(1.0777) | Xent 2.3026(2.3026) | Loss 1.1449(1.0777) | Error 0.8967(0.9013) Steps 0(0.00) | Grad Norm 21.1362(7.9325) | Total Time 0.00(0.00)\n",
      "Iter 8460 | Time 15.3369(15.3346) | Bit/dim 1.0756(1.0797) | Xent 2.3026(2.3026) | Loss 1.0756(1.0797) | Error 0.9022(0.9012) Steps 0(0.00) | Grad Norm 6.5067(7.6521) | Total Time 0.00(0.00)\n",
      "Iter 8470 | Time 16.0228(15.4261) | Bit/dim 1.0558(1.0765) | Xent 2.3026(2.3026) | Loss 1.0558(1.0765) | Error 0.9133(0.9009) Steps 0(0.00) | Grad Norm 3.2642(6.4964) | Total Time 0.00(0.00)\n",
      "Iter 8480 | Time 14.9801(15.4067) | Bit/dim 1.0660(1.0713) | Xent 2.3026(2.3026) | Loss 1.0660(1.0713) | Error 0.8978(0.9012) Steps 0(0.00) | Grad Norm 1.2460(5.2108) | Total Time 0.00(0.00)\n",
      "Iter 8490 | Time 15.6521(15.4598) | Bit/dim 1.0452(1.0662) | Xent 2.3026(2.3026) | Loss 1.0452(1.0662) | Error 0.9056(0.9017) Steps 0(0.00) | Grad Norm 0.9597(4.0958) | Total Time 0.00(0.00)\n",
      "Iter 8500 | Time 15.7991(15.5103) | Bit/dim 1.0399(1.0617) | Xent 2.3026(2.3026) | Loss 1.0399(1.0617) | Error 0.9178(0.9018) Steps 0(0.00) | Grad Norm 2.7777(3.4803) | Total Time 0.00(0.00)\n",
      "Iter 8510 | Time 15.8744(15.5687) | Bit/dim 1.0553(1.0587) | Xent 2.3026(2.3026) | Loss 1.0553(1.0587) | Error 0.9022(0.9015) Steps 0(0.00) | Grad Norm 6.6628(3.2462) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 58.9638, Epoch Time 1099.5836(1040.3778), Bit/dim 1.0535, Xent 2.3026, Loss 1.0535, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8520 | Time 14.8172(15.5449) | Bit/dim 1.1820(1.0728) | Xent 2.3026(2.3026) | Loss 1.1820(1.0728) | Error 0.9078(0.8997) Steps 0(0.00) | Grad Norm 7.2089(5.5562) | Total Time 0.00(0.00)\n",
      "Iter 8530 | Time 15.2183(15.5187) | Bit/dim 1.0932(1.0833) | Xent 2.3026(2.3026) | Loss 1.0932(1.0833) | Error 0.8889(0.8995) Steps 0(0.00) | Grad Norm 2.5788(5.7598) | Total Time 0.00(0.00)\n",
      "Iter 8540 | Time 15.6389(15.5400) | Bit/dim 1.0586(1.0795) | Xent 2.3026(2.3026) | Loss 1.0586(1.0795) | Error 0.8967(0.9012) Steps 0(0.00) | Grad Norm 10.3478(5.9331) | Total Time 0.00(0.00)\n",
      "Iter 8550 | Time 15.7099(15.6068) | Bit/dim 1.0561(1.0767) | Xent 2.3026(2.3026) | Loss 1.0561(1.0767) | Error 0.8989(0.9011) Steps 0(0.00) | Grad Norm 4.0354(6.5893) | Total Time 0.00(0.00)\n",
      "Iter 8560 | Time 15.8990(15.6516) | Bit/dim 1.0517(1.0734) | Xent 2.3026(2.3026) | Loss 1.0517(1.0734) | Error 0.9156(0.9014) Steps 0(0.00) | Grad Norm 6.9213(6.7544) | Total Time 0.00(0.00)\n",
      "Iter 8570 | Time 15.6991(15.6734) | Bit/dim 1.0409(1.0698) | Xent 2.3026(2.3026) | Loss 1.0409(1.0698) | Error 0.9078(0.9025) Steps 0(0.00) | Grad Norm 3.1071(6.8567) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 57.3346, Epoch Time 1104.4261(1042.2992), Bit/dim 1.0808, Xent 2.3026, Loss 1.0808, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8580 | Time 15.4499(15.6853) | Bit/dim 1.0986(1.0684) | Xent 2.3026(2.3026) | Loss 1.0986(1.0684) | Error 0.9056(0.9022) Steps 0(0.00) | Grad Norm 11.0953(6.8603) | Total Time 0.00(0.00)\n",
      "Iter 8590 | Time 15.7883(15.6816) | Bit/dim 1.0577(1.0688) | Xent 2.3026(2.3026) | Loss 1.0577(1.0688) | Error 0.8889(0.9006) Steps 0(0.00) | Grad Norm 4.2776(7.4336) | Total Time 0.00(0.00)\n",
      "Iter 8600 | Time 15.8821(15.7208) | Bit/dim 1.0524(1.0668) | Xent 2.3026(2.3026) | Loss 1.0524(1.0668) | Error 0.8844(0.9006) Steps 0(0.00) | Grad Norm 1.7427(7.3034) | Total Time 0.00(0.00)\n",
      "Iter 8610 | Time 15.7787(15.7275) | Bit/dim 1.0499(1.0614) | Xent 2.3026(2.3026) | Loss 1.0499(1.0614) | Error 0.8978(0.9021) Steps 0(0.00) | Grad Norm 2.1520(5.9174) | Total Time 0.00(0.00)\n",
      "Iter 8620 | Time 15.6984(15.7258) | Bit/dim 1.0512(1.0590) | Xent 2.3026(2.3026) | Loss 1.0512(1.0590) | Error 0.9133(0.9031) Steps 0(0.00) | Grad Norm 1.9431(4.7526) | Total Time 0.00(0.00)\n",
      "Iter 8630 | Time 16.1721(15.7436) | Bit/dim 1.0508(1.0563) | Xent 2.3026(2.3026) | Loss 1.0508(1.0563) | Error 0.9000(0.9018) Steps 0(0.00) | Grad Norm 5.5173(4.7340) | Total Time 0.00(0.00)\n",
      "Iter 8640 | Time 15.2441(15.7544) | Bit/dim 1.0863(1.0562) | Xent 2.3026(2.3026) | Loss 1.0863(1.0562) | Error 0.8867(0.9013) Steps 0(0.00) | Grad Norm 13.1464(5.4239) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 57.8182, Epoch Time 1111.2082(1044.3665), Bit/dim 1.1623, Xent 2.3026, Loss 1.1623, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8650 | Time 15.5317(15.7214) | Bit/dim 1.1238(1.0777) | Xent 2.3026(2.3026) | Loss 1.1238(1.0777) | Error 0.9100(0.9012) Steps 0(0.00) | Grad Norm 9.4376(6.8926) | Total Time 0.00(0.00)\n",
      "Iter 8660 | Time 16.0053(15.7152) | Bit/dim 1.0924(1.0813) | Xent 2.3026(2.3026) | Loss 1.0924(1.0813) | Error 0.9044(0.9008) Steps 0(0.00) | Grad Norm 9.6531(6.9560) | Total Time 0.00(0.00)\n",
      "Iter 8670 | Time 16.1706(15.7386) | Bit/dim 1.0747(1.0775) | Xent 2.3026(2.3026) | Loss 1.0747(1.0775) | Error 0.9011(0.9011) Steps 0(0.00) | Grad Norm 5.7746(6.3999) | Total Time 0.00(0.00)\n",
      "Iter 8680 | Time 15.2197(15.7013) | Bit/dim 1.1151(1.0785) | Xent 2.3026(2.3026) | Loss 1.1151(1.0785) | Error 0.9200(0.9021) Steps 0(0.00) | Grad Norm 11.5409(7.5128) | Total Time 0.00(0.00)\n",
      "Iter 8690 | Time 15.5423(15.6425) | Bit/dim 1.0947(1.0876) | Xent 2.3026(2.3026) | Loss 1.0947(1.0876) | Error 0.8944(0.9017) Steps 0(0.00) | Grad Norm 7.1965(8.1107) | Total Time 0.00(0.00)\n",
      "Iter 8700 | Time 15.1965(15.6382) | Bit/dim 1.0780(1.0857) | Xent 2.3026(2.3026) | Loss 1.0780(1.0857) | Error 0.8989(0.9011) Steps 0(0.00) | Grad Norm 3.5934(7.2879) | Total Time 0.00(0.00)\n",
      "Iter 8710 | Time 15.5209(15.5959) | Bit/dim 1.0564(1.0798) | Xent 2.3026(2.3026) | Loss 1.0564(1.0798) | Error 0.9000(0.9012) Steps 0(0.00) | Grad Norm 1.9040(6.0066) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 57.5810, Epoch Time 1102.0760(1046.0978), Bit/dim 1.0483, Xent 2.3026, Loss 1.0483, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8720 | Time 15.7975(15.6041) | Bit/dim 1.0436(1.0717) | Xent 2.3026(2.3026) | Loss 1.0436(1.0717) | Error 0.8911(0.9014) Steps 0(0.00) | Grad Norm 2.3311(4.8471) | Total Time 0.00(0.00)\n",
      "Iter 8730 | Time 15.7613(15.6287) | Bit/dim 1.0520(1.0659) | Xent 2.3026(2.3026) | Loss 1.0520(1.0659) | Error 0.9122(0.9018) Steps 0(0.00) | Grad Norm 0.5897(4.2015) | Total Time 0.00(0.00)\n",
      "Iter 8740 | Time 15.9123(15.6705) | Bit/dim 1.0413(1.0618) | Xent 2.3026(2.3026) | Loss 1.0413(1.0618) | Error 0.9144(0.9016) Steps 0(0.00) | Grad Norm 3.7505(4.0750) | Total Time 0.00(0.00)\n",
      "Iter 8750 | Time 16.4021(15.7569) | Bit/dim 1.0458(1.0572) | Xent 2.3026(2.3026) | Loss 1.0458(1.0572) | Error 0.9000(0.9024) Steps 0(0.00) | Grad Norm 6.7280(4.3372) | Total Time 0.00(0.00)\n",
      "Iter 8760 | Time 15.3748(15.7542) | Bit/dim 1.0834(1.0565) | Xent 2.3026(2.3026) | Loss 1.0834(1.0565) | Error 0.9211(0.9021) Steps 0(0.00) | Grad Norm 13.9429(5.1274) | Total Time 0.00(0.00)\n",
      "Iter 8770 | Time 15.5642(15.7317) | Bit/dim 1.1040(1.0737) | Xent 2.3026(2.3026) | Loss 1.1040(1.0737) | Error 0.9011(0.9010) Steps 0(0.00) | Grad Norm 7.0938(7.1620) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 58.5114, Epoch Time 1112.0779(1048.0772), Bit/dim 1.0679, Xent 2.3026, Loss 1.0679, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8780 | Time 15.4159(15.6959) | Bit/dim 1.0853(1.0817) | Xent 2.3026(2.3026) | Loss 1.0853(1.0817) | Error 0.9022(0.9003) Steps 0(0.00) | Grad Norm 5.6451(7.5042) | Total Time 0.00(0.00)\n",
      "Iter 8790 | Time 15.7150(15.6656) | Bit/dim 1.0639(1.0781) | Xent 2.3026(2.3026) | Loss 1.0639(1.0781) | Error 0.9056(0.9010) Steps 0(0.00) | Grad Norm 4.5620(6.6425) | Total Time 0.00(0.00)\n",
      "Iter 8800 | Time 15.7074(15.6709) | Bit/dim 1.0634(1.0727) | Xent 2.3026(2.3026) | Loss 1.0634(1.0727) | Error 0.9000(0.9009) Steps 0(0.00) | Grad Norm 1.5967(5.9905) | Total Time 0.00(0.00)\n",
      "Iter 8810 | Time 15.9701(15.6845) | Bit/dim 1.0665(1.0693) | Xent 2.3026(2.3026) | Loss 1.0665(1.0693) | Error 0.9022(0.9009) Steps 0(0.00) | Grad Norm 11.2422(6.8838) | Total Time 0.00(0.00)\n",
      "Iter 8820 | Time 15.6595(15.7166) | Bit/dim 1.0540(1.0666) | Xent 2.3026(2.3026) | Loss 1.0540(1.0666) | Error 0.9067(0.9014) Steps 0(0.00) | Grad Norm 5.4120(7.4109) | Total Time 0.00(0.00)\n",
      "Iter 8830 | Time 15.5373(15.7337) | Bit/dim 1.0552(1.0632) | Xent 2.3026(2.3026) | Loss 1.0552(1.0632) | Error 0.8933(0.9016) Steps 0(0.00) | Grad Norm 6.9856(7.5194) | Total Time 0.00(0.00)\n",
      "Iter 8840 | Time 15.9075(15.7444) | Bit/dim 1.0545(1.0612) | Xent 2.3026(2.3026) | Loss 1.0545(1.0612) | Error 0.9056(0.9020) Steps 0(0.00) | Grad Norm 4.5802(7.1415) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 57.9367, Epoch Time 1109.9319(1049.9328), Bit/dim 1.0449, Xent 2.3026, Loss 1.0449, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8850 | Time 15.8974(15.7546) | Bit/dim 1.0369(1.0580) | Xent 2.3026(2.3026) | Loss 1.0369(1.0580) | Error 0.9111(0.9011) Steps 0(0.00) | Grad Norm 2.7108(6.0992) | Total Time 0.00(0.00)\n",
      "Iter 8860 | Time 15.7324(15.7636) | Bit/dim 1.0588(1.0553) | Xent 2.3026(2.3026) | Loss 1.0588(1.0553) | Error 0.8989(0.9025) Steps 0(0.00) | Grad Norm 1.0308(5.4796) | Total Time 0.00(0.00)\n",
      "Iter 8870 | Time 15.6440(15.7687) | Bit/dim 1.0445(1.0526) | Xent 2.3026(2.3026) | Loss 1.0445(1.0526) | Error 0.9078(0.9016) Steps 0(0.00) | Grad Norm 6.3007(5.2742) | Total Time 0.00(0.00)\n",
      "Iter 8880 | Time 16.0153(15.8247) | Bit/dim 1.0689(1.0501) | Xent 2.3026(2.3026) | Loss 1.0689(1.0501) | Error 0.8956(0.9018) Steps 0(0.00) | Grad Norm 7.0500(5.6524) | Total Time 0.00(0.00)\n",
      "Iter 8890 | Time 15.5311(15.8464) | Bit/dim 1.1678(1.0556) | Xent 2.3026(2.3026) | Loss 1.1678(1.0556) | Error 0.9089(0.9017) Steps 0(0.00) | Grad Norm 14.5901(7.2262) | Total Time 0.00(0.00)\n",
      "Iter 8900 | Time 15.6630(15.8216) | Bit/dim 1.0967(1.0766) | Xent 2.3026(2.3026) | Loss 1.0967(1.0766) | Error 0.9078(0.9012) Steps 0(0.00) | Grad Norm 5.8159(7.3158) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 56.9375, Epoch Time 1115.5002(1051.8998), Bit/dim 1.0692, Xent 2.3026, Loss 1.0692, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8910 | Time 15.3183(15.8029) | Bit/dim 1.0765(1.0766) | Xent 2.3026(2.3026) | Loss 1.0765(1.0766) | Error 0.8989(0.9008) Steps 0(0.00) | Grad Norm 8.5259(7.4604) | Total Time 0.00(0.00)\n",
      "Iter 8920 | Time 15.7851(15.7845) | Bit/dim 1.0494(1.0726) | Xent 2.3026(2.3026) | Loss 1.0494(1.0726) | Error 0.9022(0.9017) Steps 0(0.00) | Grad Norm 3.1116(7.2157) | Total Time 0.00(0.00)\n",
      "Iter 8930 | Time 15.9515(15.7875) | Bit/dim 1.0614(1.0708) | Xent 2.3026(2.3026) | Loss 1.0614(1.0708) | Error 0.8933(0.9007) Steps 0(0.00) | Grad Norm 3.7372(7.8579) | Total Time 0.00(0.00)\n",
      "Iter 8940 | Time 16.1424(15.7603) | Bit/dim 1.0935(1.0758) | Xent 2.3026(2.3026) | Loss 1.0935(1.0758) | Error 0.8867(0.9012) Steps 0(0.00) | Grad Norm 13.8713(8.7258) | Total Time 0.00(0.00)\n",
      "Iter 8950 | Time 15.6655(15.7425) | Bit/dim 1.0627(1.0723) | Xent 2.3026(2.3026) | Loss 1.0627(1.0723) | Error 0.9089(0.9014) Steps 0(0.00) | Grad Norm 3.8454(7.6565) | Total Time 0.00(0.00)\n",
      "Iter 8960 | Time 15.7695(15.7169) | Bit/dim 1.0456(1.0675) | Xent 2.3026(2.3026) | Loss 1.0456(1.0675) | Error 0.8989(0.9014) Steps 0(0.00) | Grad Norm 1.3393(6.2711) | Total Time 0.00(0.00)\n",
      "Iter 8970 | Time 15.7401(15.7261) | Bit/dim 1.0499(1.0633) | Xent 2.3026(2.3026) | Loss 1.0499(1.0633) | Error 0.9033(0.9003) Steps 0(0.00) | Grad Norm 5.1967(5.4500) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 59.9197, Epoch Time 1110.5307(1053.6588), Bit/dim 1.0410, Xent 2.3026, Loss 1.0410, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 8980 | Time 15.7130(15.7291) | Bit/dim 1.0503(1.0581) | Xent 2.3026(2.3026) | Loss 1.0503(1.0581) | Error 0.9056(0.9012) Steps 0(0.00) | Grad Norm 1.5453(4.8526) | Total Time 0.00(0.00)\n",
      "Iter 8990 | Time 15.7165(15.7262) | Bit/dim 1.0506(1.0550) | Xent 2.3026(2.3026) | Loss 1.0506(1.0550) | Error 0.9100(0.9005) Steps 0(0.00) | Grad Norm 7.0638(4.1565) | Total Time 0.00(0.00)\n",
      "Iter 9000 | Time 15.5394(15.7158) | Bit/dim 1.1448(1.0701) | Xent 2.3026(2.3026) | Loss 1.1448(1.0701) | Error 0.9022(0.9010) Steps 0(0.00) | Grad Norm 12.0429(6.4733) | Total Time 0.00(0.00)\n",
      "Iter 9010 | Time 16.5683(15.7297) | Bit/dim 1.1000(1.0844) | Xent 2.3026(2.3026) | Loss 1.1000(1.0844) | Error 0.9189(0.9015) Steps 0(0.00) | Grad Norm 14.3903(7.0671) | Total Time 0.00(0.00)\n",
      "Iter 9020 | Time 15.6939(15.6736) | Bit/dim 1.0592(1.0810) | Xent 2.3026(2.3026) | Loss 1.0592(1.0810) | Error 0.9044(0.9026) Steps 0(0.00) | Grad Norm 2.5439(6.4644) | Total Time 0.00(0.00)\n",
      "Iter 9030 | Time 15.8251(15.6827) | Bit/dim 1.0766(1.0753) | Xent 2.3026(2.3026) | Loss 1.0766(1.0753) | Error 0.8933(0.9016) Steps 0(0.00) | Grad Norm 9.4626(5.8844) | Total Time 0.00(0.00)\n",
      "Iter 9040 | Time 15.6557(15.6771) | Bit/dim 1.1047(1.0793) | Xent 2.3026(2.3026) | Loss 1.1047(1.0793) | Error 0.8967(0.9014) Steps 0(0.00) | Grad Norm 7.7609(7.2162) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 63.9127, Epoch Time 1114.8717(1055.4952), Bit/dim 1.1101, Xent 2.3026, Loss 1.1101, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 9050 | Time 15.0362(15.6563) | Bit/dim 1.0933(1.0861) | Xent 2.3026(2.3026) | Loss 1.0933(1.0861) | Error 0.9089(0.9013) Steps 0(0.00) | Grad Norm 6.1682(7.7589) | Total Time 0.00(0.00)\n",
      "Iter 9060 | Time 15.8117(15.6669) | Bit/dim 1.0724(1.0822) | Xent 2.3026(2.3026) | Loss 1.0724(1.0822) | Error 0.9133(0.9016) Steps 0(0.00) | Grad Norm 8.1480(7.2192) | Total Time 0.00(0.00)\n",
      "Iter 9070 | Time 16.1942(15.6875) | Bit/dim 1.0524(1.0739) | Xent 2.3026(2.3026) | Loss 1.0524(1.0739) | Error 0.9056(0.9022) Steps 0(0.00) | Grad Norm 4.5316(6.2450) | Total Time 0.00(0.00)\n",
      "Iter 9080 | Time 15.7300(15.7310) | Bit/dim 1.0377(1.0671) | Xent 2.3026(2.3026) | Loss 1.0377(1.0671) | Error 0.8978(0.9015) Steps 0(0.00) | Grad Norm 3.4853(5.3280) | Total Time 0.00(0.00)\n",
      "Iter 9090 | Time 15.8911(15.7838) | Bit/dim 1.0465(1.0613) | Xent 2.3026(2.3026) | Loss 1.0465(1.0613) | Error 0.9056(0.9019) Steps 0(0.00) | Grad Norm 2.2559(4.5470) | Total Time 0.00(0.00)\n",
      "Iter 9100 | Time 16.3053(15.8114) | Bit/dim 1.0340(1.0561) | Xent 2.3026(2.3026) | Loss 1.0340(1.0561) | Error 0.8922(0.9014) Steps 0(0.00) | Grad Norm 0.9889(4.0227) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 58.1914, Epoch Time 1115.0096(1057.2806), Bit/dim 1.0430, Xent 2.3026, Loss 1.0430, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 9110 | Time 15.7716(15.8518) | Bit/dim 1.0508(1.0532) | Xent 2.3026(2.3026) | Loss 1.0508(1.0532) | Error 0.8967(0.8999) Steps 0(0.00) | Grad Norm 2.0343(4.0992) | Total Time 0.00(0.00)\n",
      "Iter 9120 | Time 15.7832(15.8684) | Bit/dim 1.1512(1.0549) | Xent 2.3026(2.3026) | Loss 1.1512(1.0549) | Error 0.9156(0.9010) Steps 0(0.00) | Grad Norm 14.3292(5.1828) | Total Time 0.00(0.00)\n",
      "Iter 9130 | Time 15.6572(15.8244) | Bit/dim 1.0671(1.0672) | Xent 2.3026(2.3026) | Loss 1.0671(1.0672) | Error 0.8889(0.8994) Steps 0(0.00) | Grad Norm 6.3985(5.7596) | Total Time 0.00(0.00)\n",
      "Iter 9140 | Time 16.3399(15.8677) | Bit/dim 1.0545(1.0668) | Xent 2.3026(2.3026) | Loss 1.0545(1.0668) | Error 0.9067(0.8992) Steps 0(0.00) | Grad Norm 5.4782(5.8602) | Total Time 0.00(0.00)\n",
      "Iter 9150 | Time 16.1657(15.8936) | Bit/dim 1.0587(1.0641) | Xent 2.3026(2.3026) | Loss 1.0587(1.0641) | Error 0.9189(0.9005) Steps 0(0.00) | Grad Norm 6.5170(5.6750) | Total Time 0.00(0.00)\n",
      "Iter 9160 | Time 15.8369(15.9528) | Bit/dim 1.0328(1.0595) | Xent 2.3026(2.3026) | Loss 1.0328(1.0595) | Error 0.9200(0.9018) Steps 0(0.00) | Grad Norm 7.8581(5.5584) | Total Time 0.00(0.00)\n",
      "Iter 9170 | Time 15.5431(15.9682) | Bit/dim 1.0684(1.0568) | Xent 2.3026(2.3026) | Loss 1.0684(1.0568) | Error 0.9022(0.9020) Steps 0(0.00) | Grad Norm 10.5902(5.8129) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 57.5816, Epoch Time 1124.7685(1059.3052), Bit/dim 1.1684, Xent 2.3026, Loss 1.1684, Error 0.9031\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 9180 | Time 15.8199(15.8933) | Bit/dim 1.0872(1.0705) | Xent 2.3026(2.3026) | Loss 1.0872(1.0705) | Error 0.8800(0.9020) Steps 0(0.00) | Grad Norm 4.6220(6.8315) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p train_cnf_conditional_gate.py --data mnist --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 900 --save experiments/cnf_bs900_gate_dev_scale_1e_4_cond --conditional True --log_freq 10 --weight_y 0. --scale 0.0001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
