{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=0.0001, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, conditional=False, controlled_tol=True, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_cifar10_published_bs8K_errcontrol_3/epoch_400_checkpt.pth', rtol=0.0001, save='../experiments_published/cnf_cifar10_published_bs8K_errcontrol_3', seed=3, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000.0, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=6144, bias=True)\n",
      "  (project_class): LinearZeros(in_features=3072, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1469494\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 2401 | Time 103.6061(53.4067) | Bit/dim 3.4941(3.4938) | Xent 0.0000(0.0000) | Loss 3.4941(3.4938) | Error 0.0000(0.0000) Steps 586(586.77) | Grad Norm 0.4238(0.5380) | Total Time 14.00(14.00)\n",
      "Iter 2402 | Time 54.1522(53.4290) | Bit/dim 3.5014(3.4940) | Xent 0.0000(0.0000) | Loss 3.5014(3.4940) | Error 0.0000(0.0000) Steps 580(586.56) | Grad Norm 0.3754(0.5331) | Total Time 14.00(14.00)\n",
      "Iter 2403 | Time 54.8331(53.4712) | Bit/dim 3.4854(3.4937) | Xent 0.0000(0.0000) | Loss 3.4854(3.4937) | Error 0.0000(0.0000) Steps 586(586.55) | Grad Norm 0.1793(0.5225) | Total Time 14.00(14.00)\n",
      "Iter 2404 | Time 54.5142(53.5025) | Bit/dim 3.4910(3.4937) | Xent 0.0000(0.0000) | Loss 3.4910(3.4937) | Error 0.0000(0.0000) Steps 586(586.53) | Grad Norm 0.1288(0.5107) | Total Time 14.00(14.00)\n",
      "Iter 2405 | Time 50.9002(53.4244) | Bit/dim 3.4925(3.4936) | Xent 0.0000(0.0000) | Loss 3.4925(3.4936) | Error 0.0000(0.0000) Steps 586(586.51) | Grad Norm 0.3268(0.5052) | Total Time 14.00(14.00)\n",
      "Iter 2406 | Time 50.4396(53.3348) | Bit/dim 3.4860(3.4934) | Xent 0.0000(0.0000) | Loss 3.4860(3.4934) | Error 0.0000(0.0000) Steps 592(586.68) | Grad Norm 0.3652(0.5010) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 38.7874, Epoch Time 423.1535(352.5170), Bit/dim 3.4943(best: inf), Xent 0.0000, Loss 3.4943, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2407 | Time 63.4963(53.6397) | Bit/dim 3.4908(3.4933) | Xent 0.0000(0.0000) | Loss 3.4908(3.4933) | Error 0.0000(0.0000) Steps 586(586.66) | Grad Norm 0.2557(0.4936) | Total Time 14.00(14.00)\n",
      "Iter 2408 | Time 53.5394(53.6367) | Bit/dim 3.4906(3.4932) | Xent 0.0000(0.0000) | Loss 3.4906(3.4932) | Error 0.0000(0.0000) Steps 586(586.64) | Grad Norm 0.1136(0.4822) | Total Time 14.00(14.00)\n",
      "Iter 2409 | Time 50.6888(53.5482) | Bit/dim 3.4929(3.4932) | Xent 0.0000(0.0000) | Loss 3.4929(3.4932) | Error 0.0000(0.0000) Steps 586(586.62) | Grad Norm 0.1394(0.4719) | Total Time 14.00(14.00)\n",
      "Iter 2410 | Time 52.7902(53.5255) | Bit/dim 3.4947(3.4933) | Xent 0.0000(0.0000) | Loss 3.4947(3.4933) | Error 0.0000(0.0000) Steps 586(586.60) | Grad Norm 0.2545(0.4654) | Total Time 14.00(14.00)\n",
      "Iter 2411 | Time 53.0735(53.5119) | Bit/dim 3.4987(3.4934) | Xent 0.0000(0.0000) | Loss 3.4987(3.4934) | Error 0.0000(0.0000) Steps 586(586.58) | Grad Norm 0.2564(0.4592) | Total Time 14.00(14.00)\n",
      "Iter 2412 | Time 53.3318(53.5065) | Bit/dim 3.4858(3.4932) | Xent 0.0000(0.0000) | Loss 3.4858(3.4932) | Error 0.0000(0.0000) Steps 580(586.39) | Grad Norm 0.2006(0.4514) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 23.0602, Epoch Time 366.0214(352.9221), Bit/dim 3.4944(best: 3.4943), Xent 0.0000, Loss 3.4944, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2413 | Time 51.2603(53.4391) | Bit/dim 3.4896(3.4931) | Xent 0.0000(0.0000) | Loss 3.4896(3.4931) | Error 0.0000(0.0000) Steps 580(586.19) | Grad Norm 0.0996(0.4408) | Total Time 14.00(14.00)\n",
      "Iter 2414 | Time 52.6626(53.4158) | Bit/dim 3.4868(3.4929) | Xent 0.0000(0.0000) | Loss 3.4868(3.4929) | Error 0.0000(0.0000) Steps 592(586.37) | Grad Norm 0.1373(0.4317) | Total Time 14.00(14.00)\n",
      "Iter 2415 | Time 55.1627(53.4683) | Bit/dim 3.4841(3.4926) | Xent 0.0000(0.0000) | Loss 3.4841(3.4926) | Error 0.0000(0.0000) Steps 586(586.36) | Grad Norm 0.1927(0.4246) | Total Time 14.00(14.00)\n",
      "Iter 2416 | Time 51.4699(53.4083) | Bit/dim 3.4988(3.4928) | Xent 0.0000(0.0000) | Loss 3.4988(3.4928) | Error 0.0000(0.0000) Steps 586(586.35) | Grad Norm 0.2117(0.4182) | Total Time 14.00(14.00)\n",
      "Iter 2417 | Time 49.2729(53.2842) | Bit/dim 3.4887(3.4927) | Xent 0.0000(0.0000) | Loss 3.4887(3.4927) | Error 0.0000(0.0000) Steps 586(586.34) | Grad Norm 0.1439(0.4099) | Total Time 14.00(14.00)\n",
      "Iter 2418 | Time 51.5587(53.2325) | Bit/dim 3.4971(3.4928) | Xent 0.0000(0.0000) | Loss 3.4971(3.4928) | Error 0.0000(0.0000) Steps 592(586.51) | Grad Norm 0.0728(0.3998) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 22.6844, Epoch Time 349.9661(352.8334), Bit/dim 3.4942(best: 3.4943), Xent 0.0000, Loss 3.4942, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2419 | Time 51.9385(53.1937) | Bit/dim 3.4860(3.4926) | Xent 0.0000(0.0000) | Loss 3.4860(3.4926) | Error 0.0000(0.0000) Steps 586(586.49) | Grad Norm 0.1306(0.3918) | Total Time 14.00(14.00)\n",
      "Iter 2420 | Time 51.7615(53.1507) | Bit/dim 3.4984(3.4928) | Xent 0.0000(0.0000) | Loss 3.4984(3.4928) | Error 0.0000(0.0000) Steps 586(586.48) | Grad Norm 0.1702(0.3851) | Total Time 14.00(14.00)\n",
      "Iter 2421 | Time 53.5284(53.1620) | Bit/dim 3.4926(3.4928) | Xent 0.0000(0.0000) | Loss 3.4926(3.4928) | Error 0.0000(0.0000) Steps 592(586.64) | Grad Norm 0.1507(0.3781) | Total Time 14.00(14.00)\n",
      "Iter 2422 | Time 52.6977(53.1481) | Bit/dim 3.4934(3.4928) | Xent 0.0000(0.0000) | Loss 3.4934(3.4928) | Error 0.0000(0.0000) Steps 586(586.62) | Grad Norm 0.0865(0.3693) | Total Time 14.00(14.00)\n",
      "Iter 2423 | Time 53.3851(53.1552) | Bit/dim 3.4888(3.4927) | Xent 0.0000(0.0000) | Loss 3.4888(3.4927) | Error 0.0000(0.0000) Steps 586(586.60) | Grad Norm 0.0623(0.3601) | Total Time 14.00(14.00)\n",
      "Iter 2424 | Time 51.7784(53.1139) | Bit/dim 3.4920(3.4927) | Xent 0.0000(0.0000) | Loss 3.4920(3.4927) | Error 0.0000(0.0000) Steps 586(586.59) | Grad Norm 0.1096(0.3526) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 22.6723, Epoch Time 353.7091(352.8597), Bit/dim 3.4947(best: 3.4942), Xent 0.0000, Loss 3.4947, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2425 | Time 49.2285(52.9973) | Bit/dim 3.4993(3.4929) | Xent 0.0000(0.0000) | Loss 3.4993(3.4929) | Error 0.0000(0.0000) Steps 586(586.57) | Grad Norm 0.1280(0.3459) | Total Time 14.00(14.00)\n",
      "Iter 2426 | Time 49.7352(52.8995) | Bit/dim 3.4909(3.4928) | Xent 0.0000(0.0000) | Loss 3.4909(3.4928) | Error 0.0000(0.0000) Steps 586(586.55) | Grad Norm 0.1251(0.3392) | Total Time 14.00(14.00)\n",
      "Iter 2427 | Time 53.1788(52.9079) | Bit/dim 3.4923(3.4928) | Xent 0.0000(0.0000) | Loss 3.4923(3.4928) | Error 0.0000(0.0000) Steps 586(586.53) | Grad Norm 0.0687(0.3311) | Total Time 14.00(14.00)\n",
      "Iter 2428 | Time 53.9297(52.9385) | Bit/dim 3.4955(3.4929) | Xent 0.0000(0.0000) | Loss 3.4955(3.4929) | Error 0.0000(0.0000) Steps 586(586.52) | Grad Norm 0.0743(0.3234) | Total Time 14.00(14.00)\n",
      "Iter 2429 | Time 51.8380(52.9055) | Bit/dim 3.4860(3.4927) | Xent 0.0000(0.0000) | Loss 3.4860(3.4927) | Error 0.0000(0.0000) Steps 586(586.50) | Grad Norm 0.1024(0.3168) | Total Time 14.00(14.00)\n",
      "Iter 2430 | Time 49.9618(52.8172) | Bit/dim 3.4896(3.4926) | Xent 0.0000(0.0000) | Loss 3.4896(3.4926) | Error 0.0000(0.0000) Steps 586(586.49) | Grad Norm 0.1258(0.3111) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 22.7211, Epoch Time 346.5969(352.6718), Bit/dim 3.4940(best: 3.4942), Xent 0.0000, Loss 3.4940, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2431 | Time 52.2741(52.8009) | Bit/dim 3.5058(3.4930) | Xent 0.0000(0.0000) | Loss 3.5058(3.4930) | Error 0.0000(0.0000) Steps 598(586.83) | Grad Norm 0.0838(0.3042) | Total Time 14.00(14.00)\n",
      "Iter 2432 | Time 51.0299(52.7478) | Bit/dim 3.4812(3.4926) | Xent 0.0000(0.0000) | Loss 3.4812(3.4926) | Error 0.0000(0.0000) Steps 586(586.81) | Grad Norm 0.0452(0.2965) | Total Time 14.00(14.00)\n",
      "Iter 2433 | Time 50.4449(52.6787) | Bit/dim 3.4958(3.4927) | Xent 0.0000(0.0000) | Loss 3.4958(3.4927) | Error 0.0000(0.0000) Steps 586(586.78) | Grad Norm 0.0591(0.2894) | Total Time 14.00(14.00)\n",
      "Iter 2434 | Time 49.3810(52.5797) | Bit/dim 3.4845(3.4925) | Xent 0.0000(0.0000) | Loss 3.4845(3.4925) | Error 0.0000(0.0000) Steps 586(586.76) | Grad Norm 0.0821(0.2831) | Total Time 14.00(14.00)\n",
      "Iter 2435 | Time 52.4911(52.5771) | Bit/dim 3.4934(3.4925) | Xent 0.0000(0.0000) | Loss 3.4934(3.4925) | Error 0.0000(0.0000) Steps 592(586.92) | Grad Norm 0.0945(0.2775) | Total Time 14.00(14.00)\n",
      "Iter 2436 | Time 51.9091(52.5570) | Bit/dim 3.4945(3.4926) | Xent 0.0000(0.0000) | Loss 3.4945(3.4926) | Error 0.0000(0.0000) Steps 586(586.89) | Grad Norm 0.0698(0.2712) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 22.8202, Epoch Time 345.8851(352.4682), Bit/dim 3.4938(best: 3.4940), Xent 0.0000, Loss 3.4938, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2437 | Time 52.6195(52.5589) | Bit/dim 3.4897(3.4925) | Xent 0.0000(0.0000) | Loss 3.4897(3.4925) | Error 0.0000(0.0000) Steps 586(586.86) | Grad Norm 0.0512(0.2646) | Total Time 14.00(14.00)\n",
      "Iter 2438 | Time 54.6999(52.6231) | Bit/dim 3.4911(3.4924) | Xent 0.0000(0.0000) | Loss 3.4911(3.4924) | Error 0.0000(0.0000) Steps 586(586.84) | Grad Norm 0.0510(0.2582) | Total Time 14.00(14.00)\n",
      "Iter 2439 | Time 52.6625(52.6243) | Bit/dim 3.5027(3.4927) | Xent 0.0000(0.0000) | Loss 3.5027(3.4927) | Error 0.0000(0.0000) Steps 592(586.99) | Grad Norm 0.1063(0.2537) | Total Time 14.00(14.00)\n",
      "Iter 2440 | Time 50.9990(52.5756) | Bit/dim 3.4815(3.4924) | Xent 0.0000(0.0000) | Loss 3.4815(3.4924) | Error 0.0000(0.0000) Steps 586(586.96) | Grad Norm 0.1156(0.2495) | Total Time 14.00(14.00)\n",
      "Iter 2441 | Time 52.3496(52.5688) | Bit/dim 3.4892(3.4923) | Xent 0.0000(0.0000) | Loss 3.4892(3.4923) | Error 0.0000(0.0000) Steps 586(586.93) | Grad Norm 0.0624(0.2439) | Total Time 14.00(14.00)\n",
      "Iter 2442 | Time 51.4195(52.5343) | Bit/dim 3.5005(3.4926) | Xent 0.0000(0.0000) | Loss 3.5005(3.4926) | Error 0.0000(0.0000) Steps 586(586.91) | Grad Norm 0.0491(0.2381) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 22.8786, Epoch Time 353.9094(352.5114), Bit/dim 3.4941(best: 3.4938), Xent 0.0000, Loss 3.4941, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2443 | Time 51.4404(52.5015) | Bit/dim 3.4828(3.4923) | Xent 0.0000(0.0000) | Loss 3.4828(3.4923) | Error 0.0000(0.0000) Steps 586(586.88) | Grad Norm 0.0957(0.2338) | Total Time 14.00(14.00)\n",
      "Iter 2444 | Time 50.8577(52.4522) | Bit/dim 3.5024(3.4926) | Xent 0.0000(0.0000) | Loss 3.5024(3.4926) | Error 0.0000(0.0000) Steps 586(586.85) | Grad Norm 0.0848(0.2293) | Total Time 14.00(14.00)\n",
      "Iter 2445 | Time 49.4745(52.3629) | Bit/dim 3.4816(3.4922) | Xent 0.0000(0.0000) | Loss 3.4816(3.4922) | Error 0.0000(0.0000) Steps 586(586.83) | Grad Norm 0.0808(0.2249) | Total Time 14.00(14.00)\n",
      "Iter 2446 | Time 51.4310(52.3349) | Bit/dim 3.4985(3.4924) | Xent 0.0000(0.0000) | Loss 3.4985(3.4924) | Error 0.0000(0.0000) Steps 586(586.80) | Grad Norm 0.0428(0.2194) | Total Time 14.00(14.00)\n",
      "Iter 2447 | Time 52.2325(52.3318) | Bit/dim 3.4888(3.4923) | Xent 0.0000(0.0000) | Loss 3.4888(3.4923) | Error 0.0000(0.0000) Steps 586(586.78) | Grad Norm 0.0577(0.2146) | Total Time 14.00(14.00)\n",
      "Iter 2448 | Time 51.7431(52.3142) | Bit/dim 3.4980(3.4925) | Xent 0.0000(0.0000) | Loss 3.4980(3.4925) | Error 0.0000(0.0000) Steps 592(586.93) | Grad Norm 0.0749(0.2104) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 22.8225, Epoch Time 345.7716(352.3092), Bit/dim 3.4944(best: 3.4938), Xent 0.0000, Loss 3.4944, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2449 | Time 52.2672(52.3128) | Bit/dim 3.4925(3.4925) | Xent 0.0000(0.0000) | Loss 3.4925(3.4925) | Error 0.0000(0.0000) Steps 586(586.91) | Grad Norm 0.0739(0.2063) | Total Time 14.00(14.00)\n",
      "Iter 2450 | Time 53.2895(52.3421) | Bit/dim 3.4920(3.4925) | Xent 0.0000(0.0000) | Loss 3.4920(3.4925) | Error 0.0000(0.0000) Steps 586(586.88) | Grad Norm 0.0480(0.2015) | Total Time 14.00(14.00)\n",
      "Iter 2451 | Time 51.3297(52.3117) | Bit/dim 3.4983(3.4926) | Xent 0.0000(0.0000) | Loss 3.4983(3.4926) | Error 0.0000(0.0000) Steps 592(587.03) | Grad Norm 0.0414(0.1967) | Total Time 14.00(14.00)\n",
      "Iter 2452 | Time 54.1070(52.3655) | Bit/dim 3.4899(3.4926) | Xent 0.0000(0.0000) | Loss 3.4899(3.4926) | Error 0.0000(0.0000) Steps 586(587.00) | Grad Norm 0.0537(0.1924) | Total Time 14.00(14.00)\n",
      "Iter 2453 | Time 49.0816(52.2670) | Bit/dim 3.4962(3.4927) | Xent 0.0000(0.0000) | Loss 3.4962(3.4927) | Error 0.0000(0.0000) Steps 586(586.97) | Grad Norm 0.0593(0.1884) | Total Time 14.00(14.00)\n",
      "Iter 2454 | Time 49.5990(52.1870) | Bit/dim 3.4853(3.4925) | Xent 0.0000(0.0000) | Loss 3.4853(3.4925) | Error 0.0000(0.0000) Steps 586(586.94) | Grad Norm 0.0638(0.1847) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 22.4455, Epoch Time 347.8758(352.1762), Bit/dim 3.4944(best: 3.4938), Xent 0.0000, Loss 3.4944, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2455 | Time 52.4448(52.1947) | Bit/dim 3.4932(3.4925) | Xent 0.0000(0.0000) | Loss 3.4932(3.4925) | Error 0.0000(0.0000) Steps 586(586.91) | Grad Norm 0.0563(0.1809) | Total Time 14.00(14.00)\n",
      "Iter 2456 | Time 50.8151(52.1533) | Bit/dim 3.4852(3.4923) | Xent 0.0000(0.0000) | Loss 3.4852(3.4923) | Error 0.0000(0.0000) Steps 586(586.89) | Grad Norm 0.0508(0.1769) | Total Time 14.00(14.00)\n",
      "Iter 2457 | Time 49.5715(52.0759) | Bit/dim 3.4975(3.4924) | Xent 0.0000(0.0000) | Loss 3.4975(3.4924) | Error 0.0000(0.0000) Steps 586(586.86) | Grad Norm 0.0511(0.1732) | Total Time 14.00(14.00)\n",
      "Iter 2458 | Time 51.0986(52.0466) | Bit/dim 3.4837(3.4922) | Xent 0.0000(0.0000) | Loss 3.4837(3.4922) | Error 0.0000(0.0000) Steps 586(586.83) | Grad Norm 0.0646(0.1699) | Total Time 14.00(14.00)\n",
      "Iter 2459 | Time 52.6350(52.0642) | Bit/dim 3.4968(3.4923) | Xent 0.0000(0.0000) | Loss 3.4968(3.4923) | Error 0.0000(0.0000) Steps 586(586.81) | Grad Norm 0.0461(0.1662) | Total Time 14.00(14.00)\n",
      "Iter 2460 | Time 52.0627(52.0642) | Bit/dim 3.4915(3.4923) | Xent 0.0000(0.0000) | Loss 3.4915(3.4923) | Error 0.0000(0.0000) Steps 586(586.79) | Grad Norm 0.0512(0.1628) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 23.1084, Epoch Time 347.6840(352.0415), Bit/dim 3.4935(best: 3.4938), Xent 0.0000, Loss 3.4935, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2461 | Time 52.7026(52.0833) | Bit/dim 3.4881(3.4921) | Xent 0.0000(0.0000) | Loss 3.4881(3.4921) | Error 0.0000(0.0000) Steps 592(586.94) | Grad Norm 0.0528(0.1595) | Total Time 14.00(14.00)\n",
      "Iter 2462 | Time 49.1966(51.9967) | Bit/dim 3.4930(3.4922) | Xent 0.0000(0.0000) | Loss 3.4930(3.4922) | Error 0.0000(0.0000) Steps 586(586.91) | Grad Norm 0.0564(0.1564) | Total Time 14.00(14.00)\n",
      "Iter 2463 | Time 48.9811(51.9062) | Bit/dim 3.5024(3.4925) | Xent 0.0000(0.0000) | Loss 3.5024(3.4925) | Error 0.0000(0.0000) Steps 586(586.89) | Grad Norm 0.0571(0.1534) | Total Time 14.00(14.00)\n",
      "Iter 2464 | Time 52.4319(51.9220) | Bit/dim 3.4956(3.4926) | Xent 0.0000(0.0000) | Loss 3.4956(3.4926) | Error 0.0000(0.0000) Steps 586(586.86) | Grad Norm 0.0477(0.1502) | Total Time 14.00(14.00)\n",
      "Iter 2465 | Time 54.4272(51.9972) | Bit/dim 3.4851(3.4923) | Xent 0.0000(0.0000) | Loss 3.4851(3.4923) | Error 0.0000(0.0000) Steps 598(587.19) | Grad Norm 0.0491(0.1472) | Total Time 14.00(14.00)\n",
      "Iter 2466 | Time 50.1911(51.9430) | Bit/dim 3.4877(3.4922) | Xent 0.0000(0.0000) | Loss 3.4877(3.4922) | Error 0.0000(0.0000) Steps 592(587.34) | Grad Norm 0.0625(0.1446) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 22.9389, Epoch Time 346.8869(351.8868), Bit/dim 3.4938(best: 3.4935), Xent 0.0000, Loss 3.4938, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2467 | Time 51.5617(51.9316) | Bit/dim 3.4870(3.4921) | Xent 0.0000(0.0000) | Loss 3.4870(3.4921) | Error 0.0000(0.0000) Steps 586(587.30) | Grad Norm 0.0538(0.1419) | Total Time 14.00(14.00)\n",
      "Iter 2468 | Time 53.5833(51.9811) | Bit/dim 3.4828(3.4918) | Xent 0.0000(0.0000) | Loss 3.4828(3.4918) | Error 0.0000(0.0000) Steps 586(587.26) | Grad Norm 0.0362(0.1387) | Total Time 14.00(14.00)\n",
      "Iter 2469 | Time 51.0928(51.9545) | Bit/dim 3.4933(3.4918) | Xent 0.0000(0.0000) | Loss 3.4933(3.4918) | Error 0.0000(0.0000) Steps 592(587.40) | Grad Norm 0.0486(0.1360) | Total Time 14.00(14.00)\n",
      "Iter 2470 | Time 52.5970(51.9737) | Bit/dim 3.4907(3.4918) | Xent 0.0000(0.0000) | Loss 3.4907(3.4918) | Error 0.0000(0.0000) Steps 586(587.36) | Grad Norm 0.0555(0.1336) | Total Time 14.00(14.00)\n",
      "Iter 2471 | Time 51.6122(51.9629) | Bit/dim 3.4972(3.4920) | Xent 0.0000(0.0000) | Loss 3.4972(3.4920) | Error 0.0000(0.0000) Steps 586(587.32) | Grad Norm 0.0452(0.1310) | Total Time 14.00(14.00)\n",
      "Iter 2472 | Time 51.3583(51.9447) | Bit/dim 3.4976(3.4921) | Xent 0.0000(0.0000) | Loss 3.4976(3.4921) | Error 0.0000(0.0000) Steps 586(587.28) | Grad Norm 0.0415(0.1283) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 22.7449, Epoch Time 350.4769(351.8445), Bit/dim 3.4934(best: 3.4935), Xent 0.0000, Loss 3.4934, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2473 | Time 51.6423(51.9357) | Bit/dim 3.4885(3.4920) | Xent 0.0000(0.0000) | Loss 3.4885(3.4920) | Error 0.0000(0.0000) Steps 586(587.24) | Grad Norm 0.0442(0.1258) | Total Time 14.00(14.00)\n",
      "Iter 2474 | Time 53.1373(51.9717) | Bit/dim 3.4838(3.4918) | Xent 0.0000(0.0000) | Loss 3.4838(3.4918) | Error 0.0000(0.0000) Steps 586(587.20) | Grad Norm 0.0527(0.1236) | Total Time 14.00(14.00)\n",
      "Iter 2475 | Time 54.6732(52.0528) | Bit/dim 3.4856(3.4916) | Xent 0.0000(0.0000) | Loss 3.4856(3.4916) | Error 0.0000(0.0000) Steps 586(587.17) | Grad Norm 0.0530(0.1215) | Total Time 14.00(14.00)\n",
      "Iter 2476 | Time 53.6484(52.1006) | Bit/dim 3.4871(3.4914) | Xent 0.0000(0.0000) | Loss 3.4871(3.4914) | Error 0.0000(0.0000) Steps 586(587.13) | Grad Norm 0.0420(0.1191) | Total Time 14.00(14.00)\n",
      "Iter 2477 | Time 49.3502(52.0181) | Bit/dim 3.5046(3.4918) | Xent 0.0000(0.0000) | Loss 3.5046(3.4918) | Error 0.0000(0.0000) Steps 586(587.10) | Grad Norm 0.0471(0.1169) | Total Time 14.00(14.00)\n",
      "Iter 2478 | Time 51.6691(52.0077) | Bit/dim 3.5003(3.4921) | Xent 0.0000(0.0000) | Loss 3.5003(3.4921) | Error 0.0000(0.0000) Steps 598(587.43) | Grad Norm 0.0542(0.1150) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 23.1229, Epoch Time 353.3644(351.8901), Bit/dim 3.4944(best: 3.4934), Xent 0.0000, Loss 3.4944, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2479 | Time 53.3637(52.0483) | Bit/dim 3.4937(3.4921) | Xent 0.0000(0.0000) | Loss 3.4937(3.4921) | Error 0.0000(0.0000) Steps 586(587.38) | Grad Norm 0.0472(0.1130) | Total Time 14.00(14.00)\n",
      "Iter 2480 | Time 50.6951(52.0077) | Bit/dim 3.4959(3.4923) | Xent 0.0000(0.0000) | Loss 3.4959(3.4923) | Error 0.0000(0.0000) Steps 586(587.34) | Grad Norm 0.0426(0.1109) | Total Time 14.00(14.00)\n",
      "Iter 2481 | Time 50.6049(51.9657) | Bit/dim 3.4893(3.4922) | Xent 0.0000(0.0000) | Loss 3.4893(3.4922) | Error 0.0000(0.0000) Steps 598(587.66) | Grad Norm 0.0453(0.1089) | Total Time 14.00(14.00)\n",
      "Iter 2482 | Time 50.4925(51.9215) | Bit/dim 3.4856(3.4920) | Xent 0.0000(0.0000) | Loss 3.4856(3.4920) | Error 0.0000(0.0000) Steps 598(587.97) | Grad Norm 0.0415(0.1069) | Total Time 14.00(14.00)\n",
      "Iter 2483 | Time 52.5109(51.9391) | Bit/dim 3.4931(3.4920) | Xent 0.0000(0.0000) | Loss 3.4931(3.4920) | Error 0.0000(0.0000) Steps 586(587.91) | Grad Norm 0.0456(0.1051) | Total Time 14.00(14.00)\n",
      "Iter 2484 | Time 52.3649(51.9519) | Bit/dim 3.4910(3.4920) | Xent 0.0000(0.0000) | Loss 3.4910(3.4920) | Error 0.0000(0.0000) Steps 586(587.85) | Grad Norm 0.0529(0.1035) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 22.8402, Epoch Time 348.7359(351.7955), Bit/dim 3.4941(best: 3.4934), Xent 0.0000, Loss 3.4941, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2485 | Time 52.0063(51.9535) | Bit/dim 3.4874(3.4918) | Xent 0.0000(0.0000) | Loss 3.4874(3.4918) | Error 0.0000(0.0000) Steps 586(587.80) | Grad Norm 0.0554(0.1020) | Total Time 14.00(14.00)\n",
      "Iter 2486 | Time 51.3004(51.9339) | Bit/dim 3.4887(3.4917) | Xent 0.0000(0.0000) | Loss 3.4887(3.4917) | Error 0.0000(0.0000) Steps 586(587.74) | Grad Norm 0.0470(0.1004) | Total Time 14.00(14.00)\n",
      "Iter 2487 | Time 51.7822(51.9294) | Bit/dim 3.4900(3.4917) | Xent 0.0000(0.0000) | Loss 3.4900(3.4917) | Error 0.0000(0.0000) Steps 586(587.69) | Grad Norm 0.0441(0.0987) | Total Time 14.00(14.00)\n",
      "Iter 2488 | Time 53.5977(51.9794) | Bit/dim 3.4918(3.4917) | Xent 0.0000(0.0000) | Loss 3.4918(3.4917) | Error 0.0000(0.0000) Steps 586(587.64) | Grad Norm 0.0713(0.0979) | Total Time 14.00(14.00)\n",
      "Iter 2489 | Time 55.9161(52.0975) | Bit/dim 3.4870(3.4916) | Xent 0.0000(0.0000) | Loss 3.4870(3.4916) | Error 0.0000(0.0000) Steps 598(587.95) | Grad Norm 0.0492(0.0964) | Total Time 14.00(14.00)\n",
      "Iter 2490 | Time 51.5012(52.0797) | Bit/dim 3.5052(3.4920) | Xent 0.0000(0.0000) | Loss 3.5052(3.4920) | Error 0.0000(0.0000) Steps 586(587.89) | Grad Norm 0.0448(0.0949) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 22.8675, Epoch Time 354.8676(351.8877), Bit/dim 3.4945(best: 3.4934), Xent 0.0000, Loss 3.4945, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2491 | Time 51.6770(52.0676) | Bit/dim 3.4826(3.4917) | Xent 0.0000(0.0000) | Loss 3.4826(3.4917) | Error 0.0000(0.0000) Steps 592(588.02) | Grad Norm 0.0417(0.0933) | Total Time 14.00(14.00)\n",
      "Iter 2492 | Time 52.9614(52.0944) | Bit/dim 3.4846(3.4915) | Xent 0.0000(0.0000) | Loss 3.4846(3.4915) | Error 0.0000(0.0000) Steps 586(587.96) | Grad Norm 0.0622(0.0923) | Total Time 14.00(14.00)\n",
      "Iter 2493 | Time 51.4153(52.0740) | Bit/dim 3.5055(3.4919) | Xent 0.0000(0.0000) | Loss 3.5055(3.4919) | Error 0.0000(0.0000) Steps 586(587.90) | Grad Norm 0.0585(0.0913) | Total Time 14.00(14.00)\n",
      "Iter 2494 | Time 50.9173(52.0393) | Bit/dim 3.4942(3.4920) | Xent 0.0000(0.0000) | Loss 3.4942(3.4920) | Error 0.0000(0.0000) Steps 586(587.84) | Grad Norm 0.0439(0.0899) | Total Time 14.00(14.00)\n",
      "Iter 2495 | Time 51.8145(52.0326) | Bit/dim 3.4982(3.4921) | Xent 0.0000(0.0000) | Loss 3.4982(3.4921) | Error 0.0000(0.0000) Steps 586(587.79) | Grad Norm 0.0378(0.0883) | Total Time 14.00(14.00)\n",
      "Iter 2496 | Time 52.0905(52.0343) | Bit/dim 3.4886(3.4920) | Xent 0.0000(0.0000) | Loss 3.4886(3.4920) | Error 0.0000(0.0000) Steps 586(587.73) | Grad Norm 0.0599(0.0875) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 22.6256, Epoch Time 349.2459(351.8084), Bit/dim 3.4938(best: 3.4934), Xent 0.0000, Loss 3.4938, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2497 | Time 52.2655(52.0412) | Bit/dim 3.4886(3.4919) | Xent 0.0000(0.0000) | Loss 3.4886(3.4919) | Error 0.0000(0.0000) Steps 586(587.68) | Grad Norm 0.0477(0.0863) | Total Time 14.00(14.00)\n",
      "Iter 2498 | Time 50.5839(51.9975) | Bit/dim 3.4942(3.4920) | Xent 0.0000(0.0000) | Loss 3.4942(3.4920) | Error 0.0000(0.0000) Steps 586(587.63) | Grad Norm 0.0436(0.0850) | Total Time 14.00(14.00)\n",
      "Iter 2499 | Time 50.5170(51.9531) | Bit/dim 3.4921(3.4920) | Xent 0.0000(0.0000) | Loss 3.4921(3.4920) | Error 0.0000(0.0000) Steps 586(587.58) | Grad Norm 0.0460(0.0838) | Total Time 14.00(14.00)\n",
      "Iter 2500 | Time 52.8779(51.9809) | Bit/dim 3.4984(3.4922) | Xent 0.0000(0.0000) | Loss 3.4984(3.4922) | Error 0.0000(0.0000) Steps 586(587.53) | Grad Norm 0.0580(0.0831) | Total Time 14.00(14.00)\n",
      "Iter 2501 | Time 50.3786(51.9328) | Bit/dim 3.4905(3.4922) | Xent 0.0000(0.0000) | Loss 3.4905(3.4922) | Error 0.0000(0.0000) Steps 592(587.67) | Grad Norm 0.0558(0.0823) | Total Time 14.00(14.00)\n",
      "Iter 2502 | Time 51.9561(51.9335) | Bit/dim 3.4883(3.4920) | Xent 0.0000(0.0000) | Loss 3.4883(3.4920) | Error 0.0000(0.0000) Steps 592(587.80) | Grad Norm 0.0431(0.0811) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 22.7700, Epoch Time 347.1135(351.6676), Bit/dim 3.4937(best: 3.4934), Xent 0.0000, Loss 3.4937, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2503 | Time 51.0954(51.9083) | Bit/dim 3.4930(3.4921) | Xent 0.0000(0.0000) | Loss 3.4930(3.4921) | Error 0.0000(0.0000) Steps 586(587.74) | Grad Norm 0.0439(0.0800) | Total Time 14.00(14.00)\n",
      "Iter 2504 | Time 54.5627(51.9880) | Bit/dim 3.4910(3.4920) | Xent 0.0000(0.0000) | Loss 3.4910(3.4920) | Error 0.0000(0.0000) Steps 586(587.69) | Grad Norm 0.0366(0.0787) | Total Time 14.00(14.00)\n",
      "Iter 2505 | Time 51.5396(51.9745) | Bit/dim 3.4963(3.4922) | Xent 0.0000(0.0000) | Loss 3.4963(3.4922) | Error 0.0000(0.0000) Steps 598(588.00) | Grad Norm 0.0562(0.0780) | Total Time 14.00(14.00)\n",
      "Iter 2506 | Time 53.2132(52.0117) | Bit/dim 3.4910(3.4921) | Xent 0.0000(0.0000) | Loss 3.4910(3.4921) | Error 0.0000(0.0000) Steps 592(588.12) | Grad Norm 0.0469(0.0771) | Total Time 14.00(14.00)\n",
      "Iter 2507 | Time 54.6898(52.0920) | Bit/dim 3.4992(3.4923) | Xent 0.0000(0.0000) | Loss 3.4992(3.4923) | Error 0.0000(0.0000) Steps 592(588.24) | Grad Norm 0.0464(0.0761) | Total Time 14.00(14.00)\n",
      "Iter 2508 | Time 51.4633(52.0732) | Bit/dim 3.4815(3.4920) | Xent 0.0000(0.0000) | Loss 3.4815(3.4920) | Error 0.0000(0.0000) Steps 586(588.17) | Grad Norm 0.0389(0.0750) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 22.6839, Epoch Time 355.7159(351.7890), Bit/dim 3.4941(best: 3.4934), Xent 0.0000, Loss 3.4941, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2509 | Time 52.3942(52.0828) | Bit/dim 3.4828(3.4917) | Xent 0.0000(0.0000) | Loss 3.4828(3.4917) | Error 0.0000(0.0000) Steps 586(588.10) | Grad Norm 0.0458(0.0741) | Total Time 14.00(14.00)\n",
      "Iter 2510 | Time 51.6157(52.0688) | Bit/dim 3.5041(3.4921) | Xent 0.0000(0.0000) | Loss 3.5041(3.4921) | Error 0.0000(0.0000) Steps 586(588.04) | Grad Norm 0.0458(0.0733) | Total Time 14.00(14.00)\n",
      "Iter 2511 | Time 49.7458(51.9991) | Bit/dim 3.4865(3.4919) | Xent 0.0000(0.0000) | Loss 3.4865(3.4919) | Error 0.0000(0.0000) Steps 592(588.16) | Grad Norm 0.0442(0.0724) | Total Time 14.00(14.00)\n",
      "Iter 2512 | Time 52.7630(52.0220) | Bit/dim 3.4957(3.4920) | Xent 0.0000(0.0000) | Loss 3.4957(3.4920) | Error 0.0000(0.0000) Steps 586(588.10) | Grad Norm 0.0453(0.0716) | Total Time 14.00(14.00)\n",
      "Iter 2513 | Time 53.2084(52.0576) | Bit/dim 3.5025(3.4924) | Xent 0.0000(0.0000) | Loss 3.5025(3.4924) | Error 0.0000(0.0000) Steps 586(588.03) | Grad Norm 0.0413(0.0707) | Total Time 14.00(14.00)\n",
      "Iter 2514 | Time 50.0562(51.9976) | Bit/dim 3.4855(3.4922) | Xent 0.0000(0.0000) | Loss 3.4855(3.4922) | Error 0.0000(0.0000) Steps 586(587.97) | Grad Norm 0.0464(0.0700) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 22.8509, Epoch Time 348.3046(351.6845), Bit/dim 3.4940(best: 3.4934), Xent 0.0000, Loss 3.4940, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2515 | Time 48.4295(51.8905) | Bit/dim 3.4927(3.4922) | Xent 0.0000(0.0000) | Loss 3.4927(3.4922) | Error 0.0000(0.0000) Steps 586(587.91) | Grad Norm 0.0438(0.0692) | Total Time 14.00(14.00)\n",
      "Iter 2516 | Time 52.9473(51.9222) | Bit/dim 3.4927(3.4922) | Xent 0.0000(0.0000) | Loss 3.4927(3.4922) | Error 0.0000(0.0000) Steps 586(587.86) | Grad Norm 0.0481(0.0686) | Total Time 14.00(14.00)\n",
      "Iter 2517 | Time 53.7347(51.9766) | Bit/dim 3.4905(3.4921) | Xent 0.0000(0.0000) | Loss 3.4905(3.4921) | Error 0.0000(0.0000) Steps 586(587.80) | Grad Norm 0.0429(0.0678) | Total Time 14.00(14.00)\n",
      "Iter 2518 | Time 51.4211(51.9599) | Bit/dim 3.5029(3.4925) | Xent 0.0000(0.0000) | Loss 3.5029(3.4925) | Error 0.0000(0.0000) Steps 586(587.75) | Grad Norm 0.0404(0.0670) | Total Time 14.00(14.00)\n",
      "Iter 2519 | Time 51.1689(51.9362) | Bit/dim 3.4924(3.4925) | Xent 0.0000(0.0000) | Loss 3.4924(3.4925) | Error 0.0000(0.0000) Steps 586(587.69) | Grad Norm 0.0457(0.0663) | Total Time 14.00(14.00)\n",
      "Iter 2520 | Time 53.6022(51.9862) | Bit/dim 3.4810(3.4921) | Xent 0.0000(0.0000) | Loss 3.4810(3.4921) | Error 0.0000(0.0000) Steps 592(587.82) | Grad Norm 0.0488(0.0658) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 23.0445, Epoch Time 349.8614(351.6298), Bit/dim 3.4942(best: 3.4934), Xent 0.0000, Loss 3.4942, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2521 | Time 53.2597(52.0244) | Bit/dim 3.4851(3.4919) | Xent 0.0000(0.0000) | Loss 3.4851(3.4919) | Error 0.0000(0.0000) Steps 586(587.77) | Grad Norm 0.0420(0.0651) | Total Time 14.00(14.00)\n",
      "Iter 2522 | Time 52.6240(52.0424) | Bit/dim 3.4940(3.4920) | Xent 0.0000(0.0000) | Loss 3.4940(3.4920) | Error 0.0000(0.0000) Steps 586(587.71) | Grad Norm 0.0474(0.0646) | Total Time 14.00(14.00)\n",
      "Iter 2523 | Time 49.2294(51.9580) | Bit/dim 3.4857(3.4918) | Xent 0.0000(0.0000) | Loss 3.4857(3.4918) | Error 0.0000(0.0000) Steps 586(587.66) | Grad Norm 0.0451(0.0640) | Total Time 14.00(14.00)\n",
      "Iter 2524 | Time 51.7225(51.9509) | Bit/dim 3.5008(3.4921) | Xent 0.0000(0.0000) | Loss 3.5008(3.4921) | Error 0.0000(0.0000) Steps 586(587.61) | Grad Norm 0.0493(0.0635) | Total Time 14.00(14.00)\n",
      "Iter 2525 | Time 54.0939(52.0152) | Bit/dim 3.5015(3.4923) | Xent 0.0000(0.0000) | Loss 3.5015(3.4923) | Error 0.0000(0.0000) Steps 586(587.56) | Grad Norm 0.0371(0.0627) | Total Time 14.00(14.00)\n",
      "Iter 2526 | Time 50.7625(51.9776) | Bit/dim 3.4857(3.4921) | Xent 0.0000(0.0000) | Loss 3.4857(3.4921) | Error 0.0000(0.0000) Steps 586(587.52) | Grad Norm 0.0471(0.0623) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 22.7005, Epoch Time 349.8815(351.5773), Bit/dim 3.4940(best: 3.4934), Xent 0.0000, Loss 3.4940, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2527 | Time 48.9811(51.8877) | Bit/dim 3.5012(3.4924) | Xent 0.0000(0.0000) | Loss 3.5012(3.4924) | Error 0.0000(0.0000) Steps 586(587.47) | Grad Norm 0.0459(0.0618) | Total Time 14.00(14.00)\n",
      "Iter 2528 | Time 52.1733(51.8963) | Bit/dim 3.4913(3.4924) | Xent 0.0000(0.0000) | Loss 3.4913(3.4924) | Error 0.0000(0.0000) Steps 586(587.43) | Grad Norm 0.0431(0.0612) | Total Time 14.00(14.00)\n",
      "Iter 2529 | Time 50.0063(51.8396) | Bit/dim 3.4870(3.4922) | Xent 0.0000(0.0000) | Loss 3.4870(3.4922) | Error 0.0000(0.0000) Steps 586(587.39) | Grad Norm 0.0507(0.0609) | Total Time 14.00(14.00)\n",
      "Iter 2530 | Time 52.0248(51.8452) | Bit/dim 3.4877(3.4921) | Xent 0.0000(0.0000) | Loss 3.4877(3.4921) | Error 0.0000(0.0000) Steps 586(587.34) | Grad Norm 0.0535(0.0607) | Total Time 14.00(14.00)\n",
      "Iter 2531 | Time 53.2890(51.8885) | Bit/dim 3.4950(3.4922) | Xent 0.0000(0.0000) | Loss 3.4950(3.4922) | Error 0.0000(0.0000) Steps 586(587.30) | Grad Norm 0.0469(0.0603) | Total Time 14.00(14.00)\n",
      "Iter 2532 | Time 50.1814(51.8373) | Bit/dim 3.4886(3.4921) | Xent 0.0000(0.0000) | Loss 3.4886(3.4921) | Error 0.0000(0.0000) Steps 586(587.26) | Grad Norm 0.0420(0.0597) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 22.9680, Epoch Time 345.5672(351.3970), Bit/dim 3.4938(best: 3.4934), Xent 0.0000, Loss 3.4938, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2533 | Time 50.9735(51.8114) | Bit/dim 3.4926(3.4921) | Xent 0.0000(0.0000) | Loss 3.4926(3.4921) | Error 0.0000(0.0000) Steps 586(587.23) | Grad Norm 0.0540(0.0595) | Total Time 14.00(14.00)\n",
      "Iter 2534 | Time 49.0487(51.7285) | Bit/dim 3.4994(3.4923) | Xent 0.0000(0.0000) | Loss 3.4994(3.4923) | Error 0.0000(0.0000) Steps 586(587.19) | Grad Norm 0.0496(0.0593) | Total Time 14.00(14.00)\n",
      "Iter 2535 | Time 51.3610(51.7174) | Bit/dim 3.4956(3.4924) | Xent 0.0000(0.0000) | Loss 3.4956(3.4924) | Error 0.0000(0.0000) Steps 586(587.15) | Grad Norm 0.0445(0.0588) | Total Time 14.00(14.00)\n",
      "Iter 2536 | Time 52.3806(51.7373) | Bit/dim 3.4882(3.4923) | Xent 0.0000(0.0000) | Loss 3.4882(3.4923) | Error 0.0000(0.0000) Steps 586(587.12) | Grad Norm 0.0420(0.0583) | Total Time 14.00(14.00)\n",
      "Iter 2537 | Time 50.0555(51.6869) | Bit/dim 3.4799(3.4919) | Xent 0.0000(0.0000) | Loss 3.4799(3.4919) | Error 0.0000(0.0000) Steps 586(587.09) | Grad Norm 0.0492(0.0580) | Total Time 14.00(14.00)\n",
      "Iter 2538 | Time 51.0025(51.6664) | Bit/dim 3.4991(3.4921) | Xent 0.0000(0.0000) | Loss 3.4991(3.4921) | Error 0.0000(0.0000) Steps 586(587.05) | Grad Norm 0.0433(0.0576) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 22.9368, Epoch Time 343.7558(351.1678), Bit/dim 3.4937(best: 3.4934), Xent 0.0000, Loss 3.4937, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2539 | Time 50.1201(51.6200) | Bit/dim 3.4881(3.4920) | Xent 0.0000(0.0000) | Loss 3.4881(3.4920) | Error 0.0000(0.0000) Steps 586(587.02) | Grad Norm 0.0480(0.0573) | Total Time 14.00(14.00)\n",
      "Iter 2540 | Time 52.4017(51.6434) | Bit/dim 3.4940(3.4921) | Xent 0.0000(0.0000) | Loss 3.4940(3.4921) | Error 0.0000(0.0000) Steps 586(586.99) | Grad Norm 0.0468(0.0570) | Total Time 14.00(14.00)\n",
      "Iter 2541 | Time 52.1575(51.6588) | Bit/dim 3.5045(3.4924) | Xent 0.0000(0.0000) | Loss 3.5045(3.4924) | Error 0.0000(0.0000) Steps 586(586.96) | Grad Norm 0.0565(0.0570) | Total Time 14.00(14.00)\n",
      "Iter 2542 | Time 49.8433(51.6044) | Bit/dim 3.4832(3.4921) | Xent 0.0000(0.0000) | Loss 3.4832(3.4921) | Error 0.0000(0.0000) Steps 586(586.93) | Grad Norm 0.0481(0.0567) | Total Time 14.00(14.00)\n",
      "Iter 2543 | Time 51.6010(51.6043) | Bit/dim 3.4910(3.4921) | Xent 0.0000(0.0000) | Loss 3.4910(3.4921) | Error 0.0000(0.0000) Steps 592(587.08) | Grad Norm 0.0410(0.0562) | Total Time 14.00(14.00)\n",
      "Iter 2544 | Time 52.7767(51.6394) | Bit/dim 3.4984(3.4923) | Xent 0.0000(0.0000) | Loss 3.4984(3.4923) | Error 0.0000(0.0000) Steps 586(587.05) | Grad Norm 0.0390(0.0557) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 22.9418, Epoch Time 347.3499(351.0533), Bit/dim 3.4943(best: 3.4934), Xent 0.0000, Loss 3.4943, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2545 | Time 51.9760(51.6495) | Bit/dim 3.4743(3.4918) | Xent 0.0000(0.0000) | Loss 3.4743(3.4918) | Error 0.0000(0.0000) Steps 586(587.02) | Grad Norm 0.0481(0.0555) | Total Time 14.00(14.00)\n",
      "Iter 2546 | Time 50.9592(51.6288) | Bit/dim 3.4911(3.4917) | Xent 0.0000(0.0000) | Loss 3.4911(3.4917) | Error 0.0000(0.0000) Steps 586(586.99) | Grad Norm 0.0406(0.0550) | Total Time 14.00(14.00)\n",
      "Iter 2547 | Time 49.0231(51.5507) | Bit/dim 3.4980(3.4919) | Xent 0.0000(0.0000) | Loss 3.4980(3.4919) | Error 0.0000(0.0000) Steps 586(586.96) | Grad Norm 0.0429(0.0547) | Total Time 14.00(14.00)\n",
      "Iter 2548 | Time 55.1701(51.6592) | Bit/dim 3.4887(3.4918) | Xent 0.0000(0.0000) | Loss 3.4887(3.4918) | Error 0.0000(0.0000) Steps 598(587.29) | Grad Norm 0.0499(0.0545) | Total Time 14.00(14.00)\n",
      "Iter 2549 | Time 53.7741(51.7227) | Bit/dim 3.4972(3.4920) | Xent 0.0000(0.0000) | Loss 3.4972(3.4920) | Error 0.0000(0.0000) Steps 586(587.25) | Grad Norm 0.0434(0.0542) | Total Time 14.00(14.00)\n",
      "Iter 2550 | Time 51.0627(51.7029) | Bit/dim 3.5011(3.4923) | Xent 0.0000(0.0000) | Loss 3.5011(3.4923) | Error 0.0000(0.0000) Steps 586(587.21) | Grad Norm 0.0441(0.0539) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 22.6702, Epoch Time 350.3332(351.0317), Bit/dim 3.4945(best: 3.4934), Xent 0.0000, Loss 3.4945, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2551 | Time 49.6069(51.6400) | Bit/dim 3.4861(3.4921) | Xent 0.0000(0.0000) | Loss 3.4861(3.4921) | Error 0.0000(0.0000) Steps 592(587.36) | Grad Norm 0.0479(0.0537) | Total Time 14.00(14.00)\n",
      "Iter 2552 | Time 52.7757(51.6741) | Bit/dim 3.4997(3.4923) | Xent 0.0000(0.0000) | Loss 3.4997(3.4923) | Error 0.0000(0.0000) Steps 586(587.32) | Grad Norm 0.0456(0.0535) | Total Time 14.00(14.00)\n",
      "Iter 2553 | Time 54.7309(51.7658) | Bit/dim 3.4959(3.4924) | Xent 0.0000(0.0000) | Loss 3.4959(3.4924) | Error 0.0000(0.0000) Steps 586(587.28) | Grad Norm 0.0421(0.0531) | Total Time 14.00(14.00)\n",
      "Iter 2554 | Time 51.8869(51.7694) | Bit/dim 3.4925(3.4924) | Xent 0.0000(0.0000) | Loss 3.4925(3.4924) | Error 0.0000(0.0000) Steps 586(587.24) | Grad Norm 0.0435(0.0528) | Total Time 14.00(14.00)\n",
      "Iter 2555 | Time 49.4416(51.6996) | Bit/dim 3.4908(3.4924) | Xent 0.0000(0.0000) | Loss 3.4908(3.4924) | Error 0.0000(0.0000) Steps 586(587.20) | Grad Norm 0.0491(0.0527) | Total Time 14.00(14.00)\n",
      "Iter 2556 | Time 52.2213(51.7152) | Bit/dim 3.4875(3.4922) | Xent 0.0000(0.0000) | Loss 3.4875(3.4922) | Error 0.0000(0.0000) Steps 586(587.17) | Grad Norm 0.0536(0.0528) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 22.9180, Epoch Time 349.5178(350.9862), Bit/dim 3.4940(best: 3.4934), Xent 0.0000, Loss 3.4940, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2557 | Time 53.0536(51.7554) | Bit/dim 3.4810(3.4919) | Xent 0.0000(0.0000) | Loss 3.4810(3.4919) | Error 0.0000(0.0000) Steps 592(587.31) | Grad Norm 0.0440(0.0525) | Total Time 14.00(14.00)\n",
      "Iter 2558 | Time 52.3605(51.7735) | Bit/dim 3.4967(3.4920) | Xent 0.0000(0.0000) | Loss 3.4967(3.4920) | Error 0.0000(0.0000) Steps 586(587.27) | Grad Norm 0.0396(0.0521) | Total Time 14.00(14.00)\n",
      "Iter 2559 | Time 50.6237(51.7390) | Bit/dim 3.4967(3.4922) | Xent 0.0000(0.0000) | Loss 3.4967(3.4922) | Error 0.0000(0.0000) Steps 586(587.23) | Grad Norm 0.0426(0.0518) | Total Time 14.00(14.00)\n",
      "Iter 2560 | Time 52.2376(51.7540) | Bit/dim 3.4914(3.4921) | Xent 0.0000(0.0000) | Loss 3.4914(3.4921) | Error 0.0000(0.0000) Steps 586(587.20) | Grad Norm 0.0453(0.0516) | Total Time 14.00(14.00)\n",
      "Iter 2561 | Time 51.4531(51.7450) | Bit/dim 3.4868(3.4920) | Xent 0.0000(0.0000) | Loss 3.4868(3.4920) | Error 0.0000(0.0000) Steps 586(587.16) | Grad Norm 0.0405(0.0513) | Total Time 14.00(14.00)\n",
      "Iter 2562 | Time 52.6514(51.7722) | Bit/dim 3.4958(3.4921) | Xent 0.0000(0.0000) | Loss 3.4958(3.4921) | Error 0.0000(0.0000) Steps 586(587.13) | Grad Norm 0.0427(0.0510) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 22.8321, Epoch Time 350.6393(350.9758), Bit/dim 3.4934(best: 3.4934), Xent 0.0000, Loss 3.4934, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2563 | Time 52.2401(51.7862) | Bit/dim 3.5028(3.4924) | Xent 0.0000(0.0000) | Loss 3.5028(3.4924) | Error 0.0000(0.0000) Steps 586(587.09) | Grad Norm 0.0399(0.0507) | Total Time 14.00(14.00)\n",
      "Iter 2564 | Time 51.8599(51.7884) | Bit/dim 3.4893(3.4923) | Xent 0.0000(0.0000) | Loss 3.4893(3.4923) | Error 0.0000(0.0000) Steps 586(587.06) | Grad Norm 0.0413(0.0504) | Total Time 14.00(14.00)\n",
      "Iter 2565 | Time 51.7641(51.7877) | Bit/dim 3.4876(3.4922) | Xent 0.0000(0.0000) | Loss 3.4876(3.4922) | Error 0.0000(0.0000) Steps 586(587.03) | Grad Norm 0.0523(0.0505) | Total Time 14.00(14.00)\n",
      "Iter 2566 | Time 51.7876(51.7877) | Bit/dim 3.4925(3.4922) | Xent 0.0000(0.0000) | Loss 3.4925(3.4922) | Error 0.0000(0.0000) Steps 586(587.00) | Grad Norm 0.0418(0.0502) | Total Time 14.00(14.00)\n",
      "Iter 2567 | Time 50.1068(51.7373) | Bit/dim 3.4922(3.4922) | Xent 0.0000(0.0000) | Loss 3.4922(3.4922) | Error 0.0000(0.0000) Steps 592(587.15) | Grad Norm 0.0459(0.0501) | Total Time 14.00(14.00)\n",
      "Iter 2568 | Time 53.1363(51.7792) | Bit/dim 3.4869(3.4920) | Xent 0.0000(0.0000) | Loss 3.4869(3.4920) | Error 0.0000(0.0000) Steps 592(587.29) | Grad Norm 0.0450(0.0499) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 23.1688, Epoch Time 349.9955(350.9464), Bit/dim 3.4947(best: 3.4934), Xent 0.0000, Loss 3.4947, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2569 | Time 52.0414(51.7871) | Bit/dim 3.4972(3.4922) | Xent 0.0000(0.0000) | Loss 3.4972(3.4922) | Error 0.0000(0.0000) Steps 592(587.43) | Grad Norm 0.0488(0.0499) | Total Time 14.00(14.00)\n",
      "Iter 2570 | Time 52.4364(51.8066) | Bit/dim 3.4979(3.4924) | Xent 0.0000(0.0000) | Loss 3.4979(3.4924) | Error 0.0000(0.0000) Steps 586(587.39) | Grad Norm 0.0459(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 2571 | Time 49.2094(51.7287) | Bit/dim 3.4991(3.4926) | Xent 0.0000(0.0000) | Loss 3.4991(3.4926) | Error 0.0000(0.0000) Steps 586(587.35) | Grad Norm 0.0597(0.0501) | Total Time 14.00(14.00)\n",
      "Iter 2572 | Time 52.4431(51.7501) | Bit/dim 3.4915(3.4925) | Xent 0.0000(0.0000) | Loss 3.4915(3.4925) | Error 0.0000(0.0000) Steps 586(587.31) | Grad Norm 0.0475(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 2573 | Time 52.9772(51.7869) | Bit/dim 3.4759(3.4920) | Xent 0.0000(0.0000) | Loss 3.4759(3.4920) | Error 0.0000(0.0000) Steps 598(587.63) | Grad Norm 0.0377(0.0496) | Total Time 14.00(14.00)\n",
      "Iter 2574 | Time 52.0188(51.7939) | Bit/dim 3.4896(3.4920) | Xent 0.0000(0.0000) | Loss 3.4896(3.4920) | Error 0.0000(0.0000) Steps 586(587.58) | Grad Norm 0.0541(0.0498) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 22.8489, Epoch Time 349.7795(350.9114), Bit/dim 3.4928(best: 3.4934), Xent 0.0000, Loss 3.4928, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2575 | Time 52.3153(51.8095) | Bit/dim 3.4812(3.4916) | Xent 0.0000(0.0000) | Loss 3.4812(3.4916) | Error 0.0000(0.0000) Steps 586(587.53) | Grad Norm 0.0571(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 2576 | Time 53.7252(51.8670) | Bit/dim 3.4870(3.4915) | Xent 0.0000(0.0000) | Loss 3.4870(3.4915) | Error 0.0000(0.0000) Steps 592(587.67) | Grad Norm 0.0492(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 2577 | Time 54.8955(51.9578) | Bit/dim 3.5015(3.4918) | Xent 0.0000(0.0000) | Loss 3.5015(3.4918) | Error 0.0000(0.0000) Steps 586(587.62) | Grad Norm 0.0411(0.0497) | Total Time 14.00(14.00)\n",
      "Iter 2578 | Time 52.2634(51.9670) | Bit/dim 3.4926(3.4918) | Xent 0.0000(0.0000) | Loss 3.4926(3.4918) | Error 0.0000(0.0000) Steps 586(587.57) | Grad Norm 0.0435(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2579 | Time 50.1036(51.9111) | Bit/dim 3.4930(3.4919) | Xent 0.0000(0.0000) | Loss 3.4930(3.4919) | Error 0.0000(0.0000) Steps 586(587.52) | Grad Norm 0.0453(0.0494) | Total Time 14.00(14.00)\n",
      "Iter 2580 | Time 54.2344(51.9808) | Bit/dim 3.4922(3.4919) | Xent 0.0000(0.0000) | Loss 3.4922(3.4919) | Error 0.0000(0.0000) Steps 586(587.48) | Grad Norm 0.0467(0.0493) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 22.9511, Epoch Time 356.5206(351.0797), Bit/dim 3.4940(best: 3.4928), Xent 0.0000, Loss 3.4940, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2581 | Time 52.8991(52.0083) | Bit/dim 3.4974(3.4920) | Xent 0.0000(0.0000) | Loss 3.4974(3.4920) | Error 0.0000(0.0000) Steps 586(587.43) | Grad Norm 0.0400(0.0490) | Total Time 14.00(14.00)\n",
      "Iter 2582 | Time 52.3028(52.0172) | Bit/dim 3.4900(3.4920) | Xent 0.0000(0.0000) | Loss 3.4900(3.4920) | Error 0.0000(0.0000) Steps 586(587.39) | Grad Norm 0.0444(0.0489) | Total Time 14.00(14.00)\n",
      "Iter 2583 | Time 51.1011(51.9897) | Bit/dim 3.4928(3.4920) | Xent 0.0000(0.0000) | Loss 3.4928(3.4920) | Error 0.0000(0.0000) Steps 586(587.35) | Grad Norm 0.0488(0.0489) | Total Time 14.00(14.00)\n",
      "Iter 2584 | Time 49.1435(51.9043) | Bit/dim 3.4922(3.4920) | Xent 0.0000(0.0000) | Loss 3.4922(3.4920) | Error 0.0000(0.0000) Steps 586(587.31) | Grad Norm 0.0493(0.0489) | Total Time 14.00(14.00)\n",
      "Iter 2585 | Time 52.7257(51.9289) | Bit/dim 3.4905(3.4920) | Xent 0.0000(0.0000) | Loss 3.4905(3.4920) | Error 0.0000(0.0000) Steps 592(587.45) | Grad Norm 0.0377(0.0486) | Total Time 14.00(14.00)\n",
      "Iter 2586 | Time 53.0473(51.9625) | Bit/dim 3.4904(3.4919) | Xent 0.0000(0.0000) | Loss 3.4904(3.4919) | Error 0.0000(0.0000) Steps 592(587.58) | Grad Norm 0.0499(0.0486) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 23.0662, Epoch Time 350.3717(351.0585), Bit/dim 3.4933(best: 3.4928), Xent 0.0000, Loss 3.4933, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2587 | Time 52.0475(51.9651) | Bit/dim 3.4930(3.4919) | Xent 0.0000(0.0000) | Loss 3.4930(3.4919) | Error 0.0000(0.0000) Steps 586(587.54) | Grad Norm 0.0412(0.0484) | Total Time 14.00(14.00)\n",
      "Iter 2588 | Time 52.1676(51.9711) | Bit/dim 3.5020(3.4922) | Xent 0.0000(0.0000) | Loss 3.5020(3.4922) | Error 0.0000(0.0000) Steps 586(587.49) | Grad Norm 0.0464(0.0483) | Total Time 14.00(14.00)\n",
      "Iter 2589 | Time 54.1309(52.0359) | Bit/dim 3.4990(3.4924) | Xent 0.0000(0.0000) | Loss 3.4990(3.4924) | Error 0.0000(0.0000) Steps 586(587.45) | Grad Norm 0.0391(0.0480) | Total Time 14.00(14.00)\n",
      "Iter 2590 | Time 52.7735(52.0580) | Bit/dim 3.4913(3.4924) | Xent 0.0000(0.0000) | Loss 3.4913(3.4924) | Error 0.0000(0.0000) Steps 592(587.58) | Grad Norm 0.0377(0.0477) | Total Time 14.00(14.00)\n",
      "Iter 2591 | Time 50.1580(52.0010) | Bit/dim 3.4820(3.4921) | Xent 0.0000(0.0000) | Loss 3.4820(3.4921) | Error 0.0000(0.0000) Steps 586(587.53) | Grad Norm 0.0436(0.0476) | Total Time 14.00(14.00)\n",
      "Iter 2592 | Time 53.0967(52.0339) | Bit/dim 3.4853(3.4919) | Xent 0.0000(0.0000) | Loss 3.4853(3.4919) | Error 0.0000(0.0000) Steps 592(587.67) | Grad Norm 0.0435(0.0475) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 22.2483, Epoch Time 352.4039(351.0988), Bit/dim 3.4930(best: 3.4928), Xent 0.0000, Loss 3.4930, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2593 | Time 52.4487(52.0464) | Bit/dim 3.4883(3.4918) | Xent 0.0000(0.0000) | Loss 3.4883(3.4918) | Error 0.0000(0.0000) Steps 586(587.62) | Grad Norm 0.0430(0.0474) | Total Time 14.00(14.00)\n",
      "Iter 2594 | Time 49.0659(51.9569) | Bit/dim 3.4833(3.4915) | Xent 0.0000(0.0000) | Loss 3.4833(3.4915) | Error 0.0000(0.0000) Steps 586(587.57) | Grad Norm 0.0428(0.0472) | Total Time 14.00(14.00)\n",
      "Iter 2595 | Time 52.0248(51.9590) | Bit/dim 3.4933(3.4916) | Xent 0.0000(0.0000) | Loss 3.4933(3.4916) | Error 0.0000(0.0000) Steps 586(587.52) | Grad Norm 0.0447(0.0471) | Total Time 14.00(14.00)\n",
      "Iter 2596 | Time 51.1781(51.9356) | Bit/dim 3.4951(3.4917) | Xent 0.0000(0.0000) | Loss 3.4951(3.4917) | Error 0.0000(0.0000) Steps 598(587.84) | Grad Norm 0.0362(0.0468) | Total Time 14.00(14.00)\n",
      "Iter 2597 | Time 51.4036(51.9196) | Bit/dim 3.5028(3.4920) | Xent 0.0000(0.0000) | Loss 3.5028(3.4920) | Error 0.0000(0.0000) Steps 592(587.96) | Grad Norm 0.0458(0.0468) | Total Time 14.00(14.00)\n",
      "Iter 2598 | Time 51.7883(51.9157) | Bit/dim 3.4861(3.4918) | Xent 0.0000(0.0000) | Loss 3.4861(3.4918) | Error 0.0000(0.0000) Steps 586(587.90) | Grad Norm 0.0426(0.0467) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 22.7659, Epoch Time 346.0997(350.9488), Bit/dim 3.4941(best: 3.4928), Xent 0.0000, Loss 3.4941, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2599 | Time 51.7176(51.9097) | Bit/dim 3.4971(3.4920) | Xent 0.0000(0.0000) | Loss 3.4971(3.4920) | Error 0.0000(0.0000) Steps 586(587.85) | Grad Norm 0.0438(0.0466) | Total Time 14.00(14.00)\n",
      "Iter 2600 | Time 51.0449(51.8838) | Bit/dim 3.4933(3.4920) | Xent 0.0000(0.0000) | Loss 3.4933(3.4920) | Error 0.0000(0.0000) Steps 586(587.79) | Grad Norm 0.0471(0.0466) | Total Time 14.00(14.00)\n",
      "Iter 2601 | Time 50.9015(51.8543) | Bit/dim 3.4856(3.4918) | Xent 0.0000(0.0000) | Loss 3.4856(3.4918) | Error 0.0000(0.0000) Steps 598(588.10) | Grad Norm 0.0489(0.0467) | Total Time 14.00(14.00)\n",
      "Iter 2602 | Time 51.5561(51.8454) | Bit/dim 3.4858(3.4917) | Xent 0.0000(0.0000) | Loss 3.4858(3.4917) | Error 0.0000(0.0000) Steps 586(588.03) | Grad Norm 0.0430(0.0465) | Total Time 14.00(14.00)\n",
      "Iter 2603 | Time 50.7556(51.8127) | Bit/dim 3.5000(3.4919) | Xent 0.0000(0.0000) | Loss 3.5000(3.4919) | Error 0.0000(0.0000) Steps 586(587.97) | Grad Norm 0.0467(0.0466) | Total Time 14.00(14.00)\n",
      "Iter 2604 | Time 49.3339(51.7383) | Bit/dim 3.4896(3.4918) | Xent 0.0000(0.0000) | Loss 3.4896(3.4918) | Error 0.0000(0.0000) Steps 586(587.91) | Grad Norm 0.0406(0.0464) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 22.7829, Epoch Time 343.6120(350.7287), Bit/dim 3.4938(best: 3.4928), Xent 0.0000, Loss 3.4938, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2605 | Time 51.6753(51.7364) | Bit/dim 3.4872(3.4917) | Xent 0.0000(0.0000) | Loss 3.4872(3.4917) | Error 0.0000(0.0000) Steps 586(587.86) | Grad Norm 0.0413(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2606 | Time 50.7917(51.7081) | Bit/dim 3.4941(3.4918) | Xent 0.0000(0.0000) | Loss 3.4941(3.4918) | Error 0.0000(0.0000) Steps 586(587.80) | Grad Norm 0.0473(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2607 | Time 50.9520(51.6854) | Bit/dim 3.4768(3.4913) | Xent 0.0000(0.0000) | Loss 3.4768(3.4913) | Error 0.0000(0.0000) Steps 586(587.75) | Grad Norm 0.0528(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2608 | Time 50.9183(51.6624) | Bit/dim 3.4930(3.4914) | Xent 0.0000(0.0000) | Loss 3.4930(3.4914) | Error 0.0000(0.0000) Steps 586(587.69) | Grad Norm 0.0403(0.0463) | Total Time 14.00(14.00)\n",
      "Iter 2609 | Time 53.2031(51.7086) | Bit/dim 3.4970(3.4915) | Xent 0.0000(0.0000) | Loss 3.4970(3.4915) | Error 0.0000(0.0000) Steps 592(587.82) | Grad Norm 0.0394(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2610 | Time 50.6058(51.6755) | Bit/dim 3.4961(3.4917) | Xent 0.0000(0.0000) | Loss 3.4961(3.4917) | Error 0.0000(0.0000) Steps 586(587.77) | Grad Norm 0.0419(0.0459) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 22.9746, Epoch Time 347.0688(350.6189), Bit/dim 3.4937(best: 3.4928), Xent 0.0000, Loss 3.4937, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2611 | Time 50.6417(51.6445) | Bit/dim 3.4978(3.4919) | Xent 0.0000(0.0000) | Loss 3.4978(3.4919) | Error 0.0000(0.0000) Steps 586(587.72) | Grad Norm 0.0508(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2612 | Time 54.1954(51.7210) | Bit/dim 3.4961(3.4920) | Xent 0.0000(0.0000) | Loss 3.4961(3.4920) | Error 0.0000(0.0000) Steps 586(587.66) | Grad Norm 0.0553(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2613 | Time 51.7727(51.7226) | Bit/dim 3.5013(3.4923) | Xent 0.0000(0.0000) | Loss 3.5013(3.4923) | Error 0.0000(0.0000) Steps 586(587.61) | Grad Norm 0.0443(0.0463) | Total Time 14.00(14.00)\n",
      "Iter 2614 | Time 54.4478(51.8043) | Bit/dim 3.4794(3.4919) | Xent 0.0000(0.0000) | Loss 3.4794(3.4919) | Error 0.0000(0.0000) Steps 586(587.57) | Grad Norm 0.0524(0.0465) | Total Time 14.00(14.00)\n",
      "Iter 2615 | Time 52.3832(51.8217) | Bit/dim 3.4854(3.4917) | Xent 0.0000(0.0000) | Loss 3.4854(3.4917) | Error 0.0000(0.0000) Steps 592(587.70) | Grad Norm 0.0583(0.0468) | Total Time 14.00(14.00)\n",
      "Iter 2616 | Time 51.3176(51.8066) | Bit/dim 3.4884(3.4916) | Xent 0.0000(0.0000) | Loss 3.4884(3.4916) | Error 0.0000(0.0000) Steps 586(587.65) | Grad Norm 0.0390(0.0466) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 22.8117, Epoch Time 353.7779(350.7137), Bit/dim 3.4937(best: 3.4928), Xent 0.0000, Loss 3.4937, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2617 | Time 52.5574(51.8291) | Bit/dim 3.4886(3.4915) | Xent 0.0000(0.0000) | Loss 3.4886(3.4915) | Error 0.0000(0.0000) Steps 592(587.78) | Grad Norm 0.0428(0.0465) | Total Time 14.00(14.00)\n",
      "Iter 2618 | Time 53.1279(51.8681) | Bit/dim 3.4887(3.4914) | Xent 0.0000(0.0000) | Loss 3.4887(3.4914) | Error 0.0000(0.0000) Steps 586(587.73) | Grad Norm 0.0406(0.0463) | Total Time 14.00(14.00)\n",
      "Iter 2619 | Time 50.9726(51.8412) | Bit/dim 3.4943(3.4915) | Xent 0.0000(0.0000) | Loss 3.4943(3.4915) | Error 0.0000(0.0000) Steps 598(588.03) | Grad Norm 0.0499(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2620 | Time 51.8098(51.8403) | Bit/dim 3.4988(3.4917) | Xent 0.0000(0.0000) | Loss 3.4988(3.4917) | Error 0.0000(0.0000) Steps 592(588.15) | Grad Norm 0.0413(0.0463) | Total Time 14.00(14.00)\n",
      "Iter 2621 | Time 53.0367(51.8761) | Bit/dim 3.4851(3.4915) | Xent 0.0000(0.0000) | Loss 3.4851(3.4915) | Error 0.0000(0.0000) Steps 586(588.09) | Grad Norm 0.0445(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2622 | Time 52.4267(51.8927) | Bit/dim 3.4900(3.4915) | Xent 0.0000(0.0000) | Loss 3.4900(3.4915) | Error 0.0000(0.0000) Steps 586(588.03) | Grad Norm 0.0446(0.0462) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 22.7452, Epoch Time 352.3436(350.7626), Bit/dim 3.4929(best: 3.4928), Xent 0.0000, Loss 3.4929, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2623 | Time 50.4017(51.8479) | Bit/dim 3.4959(3.4916) | Xent 0.0000(0.0000) | Loss 3.4959(3.4916) | Error 0.0000(0.0000) Steps 586(587.96) | Grad Norm 0.0513(0.0463) | Total Time 14.00(14.00)\n",
      "Iter 2624 | Time 52.2190(51.8591) | Bit/dim 3.4862(3.4915) | Xent 0.0000(0.0000) | Loss 3.4862(3.4915) | Error 0.0000(0.0000) Steps 586(587.91) | Grad Norm 0.0428(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2625 | Time 51.6247(51.8520) | Bit/dim 3.4945(3.4915) | Xent 0.0000(0.0000) | Loss 3.4945(3.4915) | Error 0.0000(0.0000) Steps 586(587.85) | Grad Norm 0.0436(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2626 | Time 52.7609(51.8793) | Bit/dim 3.5004(3.4918) | Xent 0.0000(0.0000) | Loss 3.5004(3.4918) | Error 0.0000(0.0000) Steps 586(587.79) | Grad Norm 0.0444(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2627 | Time 52.8722(51.9091) | Bit/dim 3.4924(3.4918) | Xent 0.0000(0.0000) | Loss 3.4924(3.4918) | Error 0.0000(0.0000) Steps 586(587.74) | Grad Norm 0.0459(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2628 | Time 52.3394(51.9220) | Bit/dim 3.4827(3.4916) | Xent 0.0000(0.0000) | Loss 3.4827(3.4916) | Error 0.0000(0.0000) Steps 598(588.05) | Grad Norm 0.0458(0.0461) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 22.8951, Epoch Time 350.8772(350.7660), Bit/dim 3.4928(best: 3.4928), Xent 0.0000, Loss 3.4928, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2629 | Time 51.2566(51.9020) | Bit/dim 3.4874(3.4914) | Xent 0.0000(0.0000) | Loss 3.4874(3.4914) | Error 0.0000(0.0000) Steps 586(587.99) | Grad Norm 0.0384(0.0458) | Total Time 14.00(14.00)\n",
      "Iter 2630 | Time 50.3135(51.8544) | Bit/dim 3.4931(3.4915) | Xent 0.0000(0.0000) | Loss 3.4931(3.4915) | Error 0.0000(0.0000) Steps 586(587.93) | Grad Norm 0.0540(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2631 | Time 53.7730(51.9119) | Bit/dim 3.4956(3.4916) | Xent 0.0000(0.0000) | Loss 3.4956(3.4916) | Error 0.0000(0.0000) Steps 592(588.05) | Grad Norm 0.0455(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2632 | Time 54.2969(51.9835) | Bit/dim 3.4832(3.4913) | Xent 0.0000(0.0000) | Loss 3.4832(3.4913) | Error 0.0000(0.0000) Steps 586(587.99) | Grad Norm 0.0498(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2633 | Time 52.2263(51.9908) | Bit/dim 3.4919(3.4914) | Xent 0.0000(0.0000) | Loss 3.4919(3.4914) | Error 0.0000(0.0000) Steps 586(587.93) | Grad Norm 0.0413(0.0460) | Total Time 14.00(14.00)\n",
      "Iter 2634 | Time 50.5702(51.9482) | Bit/dim 3.4881(3.4913) | Xent 0.0000(0.0000) | Loss 3.4881(3.4913) | Error 0.0000(0.0000) Steps 598(588.23) | Grad Norm 0.0492(0.0461) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 22.6311, Epoch Time 350.9582(350.7718), Bit/dim 3.4935(best: 3.4928), Xent 0.0000, Loss 3.4935, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2635 | Time 53.0527(51.9813) | Bit/dim 3.4881(3.4912) | Xent 0.0000(0.0000) | Loss 3.4881(3.4912) | Error 0.0000(0.0000) Steps 586(588.16) | Grad Norm 0.0423(0.0460) | Total Time 14.00(14.00)\n",
      "Iter 2636 | Time 51.2591(51.9596) | Bit/dim 3.4950(3.4913) | Xent 0.0000(0.0000) | Loss 3.4950(3.4913) | Error 0.0000(0.0000) Steps 598(588.46) | Grad Norm 0.0366(0.0457) | Total Time 14.00(14.00)\n",
      "Iter 2637 | Time 55.1528(52.0554) | Bit/dim 3.4894(3.4912) | Xent 0.0000(0.0000) | Loss 3.4894(3.4912) | Error 0.0000(0.0000) Steps 586(588.38) | Grad Norm 0.0407(0.0456) | Total Time 14.00(14.00)\n",
      "Iter 2638 | Time 50.3600(52.0046) | Bit/dim 3.4956(3.4914) | Xent 0.0000(0.0000) | Loss 3.4956(3.4914) | Error 0.0000(0.0000) Steps 598(588.67) | Grad Norm 0.0443(0.0455) | Total Time 14.00(14.00)\n",
      "Iter 2639 | Time 51.1621(51.9793) | Bit/dim 3.4899(3.4913) | Xent 0.0000(0.0000) | Loss 3.4899(3.4913) | Error 0.0000(0.0000) Steps 586(588.59) | Grad Norm 0.0561(0.0459) | Total Time 14.00(14.00)\n",
      "Iter 2640 | Time 49.4312(51.9028) | Bit/dim 3.4911(3.4913) | Xent 0.0000(0.0000) | Loss 3.4911(3.4913) | Error 0.0000(0.0000) Steps 586(588.51) | Grad Norm 0.0387(0.0456) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 22.7074, Epoch Time 348.9213(350.7163), Bit/dim 3.4928(best: 3.4928), Xent 0.0000, Loss 3.4928, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2641 | Time 52.3092(51.9150) | Bit/dim 3.4811(3.4910) | Xent 0.0000(0.0000) | Loss 3.4811(3.4910) | Error 0.0000(0.0000) Steps 592(588.62) | Grad Norm 0.0495(0.0458) | Total Time 14.00(14.00)\n",
      "Iter 2642 | Time 50.9939(51.8874) | Bit/dim 3.4946(3.4911) | Xent 0.0000(0.0000) | Loss 3.4946(3.4911) | Error 0.0000(0.0000) Steps 586(588.54) | Grad Norm 0.0500(0.0459) | Total Time 14.00(14.00)\n",
      "Iter 2643 | Time 54.5615(51.9676) | Bit/dim 3.4962(3.4913) | Xent 0.0000(0.0000) | Loss 3.4962(3.4913) | Error 0.0000(0.0000) Steps 604(589.00) | Grad Norm 0.0537(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2644 | Time 53.9111(52.0259) | Bit/dim 3.4861(3.4911) | Xent 0.0000(0.0000) | Loss 3.4861(3.4911) | Error 0.0000(0.0000) Steps 586(588.91) | Grad Norm 0.0442(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2645 | Time 52.3512(52.0357) | Bit/dim 3.4923(3.4911) | Xent 0.0000(0.0000) | Loss 3.4923(3.4911) | Error 0.0000(0.0000) Steps 586(588.83) | Grad Norm 0.0556(0.0463) | Total Time 14.00(14.00)\n",
      "Iter 2646 | Time 49.4914(51.9594) | Bit/dim 3.4971(3.4913) | Xent 0.0000(0.0000) | Loss 3.4971(3.4913) | Error 0.0000(0.0000) Steps 586(588.74) | Grad Norm 0.0425(0.0462) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 22.6644, Epoch Time 352.0602(350.7566), Bit/dim 3.4935(best: 3.4928), Xent 0.0000, Loss 3.4935, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2647 | Time 52.4129(51.9730) | Bit/dim 3.4903(3.4913) | Xent 0.0000(0.0000) | Loss 3.4903(3.4913) | Error 0.0000(0.0000) Steps 598(589.02) | Grad Norm 0.0440(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2648 | Time 53.3585(52.0145) | Bit/dim 3.4906(3.4913) | Xent 0.0000(0.0000) | Loss 3.4906(3.4913) | Error 0.0000(0.0000) Steps 592(589.11) | Grad Norm 0.0492(0.0463) | Total Time 14.00(14.00)\n",
      "Iter 2649 | Time 53.2303(52.0510) | Bit/dim 3.4976(3.4915) | Xent 0.0000(0.0000) | Loss 3.4976(3.4915) | Error 0.0000(0.0000) Steps 586(589.02) | Grad Norm 0.0507(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2650 | Time 52.8344(52.0745) | Bit/dim 3.5029(3.4918) | Xent 0.0000(0.0000) | Loss 3.5029(3.4918) | Error 0.0000(0.0000) Steps 586(588.93) | Grad Norm 0.0397(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2651 | Time 52.1010(52.0753) | Bit/dim 3.4893(3.4917) | Xent 0.0000(0.0000) | Loss 3.4893(3.4917) | Error 0.0000(0.0000) Steps 586(588.84) | Grad Norm 0.0427(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2652 | Time 52.0385(52.0742) | Bit/dim 3.4817(3.4914) | Xent 0.0000(0.0000) | Loss 3.4817(3.4914) | Error 0.0000(0.0000) Steps 586(588.75) | Grad Norm 0.0432(0.0460) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 22.5863, Epoch Time 354.2209(350.8605), Bit/dim 3.4936(best: 3.4928), Xent 0.0000, Loss 3.4936, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2653 | Time 52.9395(52.1002) | Bit/dim 3.4978(3.4916) | Xent 0.0000(0.0000) | Loss 3.4978(3.4916) | Error 0.0000(0.0000) Steps 598(589.03) | Grad Norm 0.0491(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2654 | Time 51.7240(52.0889) | Bit/dim 3.4887(3.4915) | Xent 0.0000(0.0000) | Loss 3.4887(3.4915) | Error 0.0000(0.0000) Steps 586(588.94) | Grad Norm 0.0484(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2655 | Time 50.8948(52.0530) | Bit/dim 3.4865(3.4914) | Xent 0.0000(0.0000) | Loss 3.4865(3.4914) | Error 0.0000(0.0000) Steps 592(589.03) | Grad Norm 0.0402(0.0460) | Total Time 14.00(14.00)\n",
      "Iter 2656 | Time 52.1686(52.0565) | Bit/dim 3.4953(3.4915) | Xent 0.0000(0.0000) | Loss 3.4953(3.4915) | Error 0.0000(0.0000) Steps 586(588.94) | Grad Norm 0.0448(0.0459) | Total Time 14.00(14.00)\n",
      "Iter 2657 | Time 53.6920(52.1056) | Bit/dim 3.4881(3.4914) | Xent 0.0000(0.0000) | Loss 3.4881(3.4914) | Error 0.0000(0.0000) Steps 586(588.85) | Grad Norm 0.0425(0.0458) | Total Time 14.00(14.00)\n",
      "Iter 2658 | Time 54.8320(52.1874) | Bit/dim 3.4976(3.4916) | Xent 0.0000(0.0000) | Loss 3.4976(3.4916) | Error 0.0000(0.0000) Steps 598(589.13) | Grad Norm 0.0423(0.0457) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 22.9958, Epoch Time 355.1647(350.9897), Bit/dim 3.4924(best: 3.4928), Xent 0.0000, Loss 3.4924, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2659 | Time 52.1097(52.1850) | Bit/dim 3.4975(3.4918) | Xent 0.0000(0.0000) | Loss 3.4975(3.4918) | Error 0.0000(0.0000) Steps 586(589.03) | Grad Norm 0.0417(0.0456) | Total Time 14.00(14.00)\n",
      "Iter 2660 | Time 51.1720(52.1547) | Bit/dim 3.4924(3.4918) | Xent 0.0000(0.0000) | Loss 3.4924(3.4918) | Error 0.0000(0.0000) Steps 586(588.94) | Grad Norm 0.0410(0.0455) | Total Time 14.00(14.00)\n",
      "Iter 2661 | Time 48.7332(52.0520) | Bit/dim 3.4894(3.4917) | Xent 0.0000(0.0000) | Loss 3.4894(3.4917) | Error 0.0000(0.0000) Steps 586(588.85) | Grad Norm 0.0463(0.0455) | Total Time 14.00(14.00)\n",
      "Iter 2662 | Time 55.3001(52.1494) | Bit/dim 3.4821(3.4914) | Xent 0.0000(0.0000) | Loss 3.4821(3.4914) | Error 0.0000(0.0000) Steps 586(588.77) | Grad Norm 0.0389(0.0453) | Total Time 14.00(14.00)\n",
      "Iter 2663 | Time 53.5155(52.1904) | Bit/dim 3.4911(3.4914) | Xent 0.0000(0.0000) | Loss 3.4911(3.4914) | Error 0.0000(0.0000) Steps 586(588.68) | Grad Norm 0.0450(0.0453) | Total Time 14.00(14.00)\n",
      "Iter 2664 | Time 54.4340(52.2577) | Bit/dim 3.4899(3.4914) | Xent 0.0000(0.0000) | Loss 3.4899(3.4914) | Error 0.0000(0.0000) Steps 586(588.60) | Grad Norm 0.0483(0.0454) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 23.0364, Epoch Time 354.0837(351.0825), Bit/dim 3.4933(best: 3.4924), Xent 0.0000, Loss 3.4933, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2665 | Time 54.2327(52.3170) | Bit/dim 3.4915(3.4914) | Xent 0.0000(0.0000) | Loss 3.4915(3.4914) | Error 0.0000(0.0000) Steps 586(588.53) | Grad Norm 0.0508(0.0455) | Total Time 14.00(14.00)\n",
      "Iter 2666 | Time 53.2341(52.3445) | Bit/dim 3.5000(3.4916) | Xent 0.0000(0.0000) | Loss 3.5000(3.4916) | Error 0.0000(0.0000) Steps 586(588.45) | Grad Norm 0.0416(0.0454) | Total Time 14.00(14.00)\n",
      "Iter 2667 | Time 51.8184(52.3287) | Bit/dim 3.4974(3.4918) | Xent 0.0000(0.0000) | Loss 3.4974(3.4918) | Error 0.0000(0.0000) Steps 586(588.38) | Grad Norm 0.0402(0.0453) | Total Time 14.00(14.00)\n",
      "Iter 2668 | Time 54.2561(52.3865) | Bit/dim 3.4783(3.4914) | Xent 0.0000(0.0000) | Loss 3.4783(3.4914) | Error 0.0000(0.0000) Steps 586(588.31) | Grad Norm 0.0421(0.0452) | Total Time 14.00(14.00)\n",
      "Iter 2669 | Time 55.0572(52.4667) | Bit/dim 3.4985(3.4916) | Xent 0.0000(0.0000) | Loss 3.4985(3.4916) | Error 0.0000(0.0000) Steps 598(588.60) | Grad Norm 0.0374(0.0449) | Total Time 14.00(14.00)\n",
      "Iter 2670 | Time 53.3513(52.4932) | Bit/dim 3.4786(3.4912) | Xent 0.0000(0.0000) | Loss 3.4786(3.4912) | Error 0.0000(0.0000) Steps 586(588.52) | Grad Norm 0.0442(0.0449) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 22.8586, Epoch Time 360.3728(351.3612), Bit/dim 3.4937(best: 3.4924), Xent 0.0000, Loss 3.4937, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2671 | Time 55.6764(52.5887) | Bit/dim 3.4958(3.4914) | Xent 0.0000(0.0000) | Loss 3.4958(3.4914) | Error 0.0000(0.0000) Steps 586(588.44) | Grad Norm 0.0393(0.0448) | Total Time 14.00(14.00)\n",
      "Iter 2672 | Time 52.0501(52.5725) | Bit/dim 3.4993(3.4916) | Xent 0.0000(0.0000) | Loss 3.4993(3.4916) | Error 0.0000(0.0000) Steps 604(588.91) | Grad Norm 0.0403(0.0446) | Total Time 14.00(14.00)\n",
      "Iter 2673 | Time 55.1583(52.6501) | Bit/dim 3.4868(3.4915) | Xent 0.0000(0.0000) | Loss 3.4868(3.4915) | Error 0.0000(0.0000) Steps 586(588.82) | Grad Norm 0.0476(0.0447) | Total Time 14.00(14.00)\n",
      "Iter 2674 | Time 52.0790(52.6330) | Bit/dim 3.4860(3.4913) | Xent 0.0000(0.0000) | Loss 3.4860(3.4913) | Error 0.0000(0.0000) Steps 586(588.74) | Grad Norm 0.0485(0.0448) | Total Time 14.00(14.00)\n",
      "Iter 2675 | Time 51.4899(52.5987) | Bit/dim 3.4839(3.4911) | Xent 0.0000(0.0000) | Loss 3.4839(3.4911) | Error 0.0000(0.0000) Steps 586(588.66) | Grad Norm 0.0524(0.0451) | Total Time 14.00(14.00)\n",
      "Iter 2676 | Time 52.2668(52.5887) | Bit/dim 3.4933(3.4911) | Xent 0.0000(0.0000) | Loss 3.4933(3.4911) | Error 0.0000(0.0000) Steps 586(588.58) | Grad Norm 0.0514(0.0452) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 22.8264, Epoch Time 357.5325(351.5463), Bit/dim 3.4923(best: 3.4924), Xent 0.0000, Loss 3.4923, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2677 | Time 51.0462(52.5424) | Bit/dim 3.4920(3.4912) | Xent 0.0000(0.0000) | Loss 3.4920(3.4912) | Error 0.0000(0.0000) Steps 598(588.86) | Grad Norm 0.0514(0.0454) | Total Time 14.00(14.00)\n",
      "Iter 2678 | Time 52.6725(52.5463) | Bit/dim 3.4901(3.4911) | Xent 0.0000(0.0000) | Loss 3.4901(3.4911) | Error 0.0000(0.0000) Steps 586(588.77) | Grad Norm 0.0399(0.0453) | Total Time 14.00(14.00)\n",
      "Iter 2679 | Time 51.2354(52.5070) | Bit/dim 3.4854(3.4910) | Xent 0.0000(0.0000) | Loss 3.4854(3.4910) | Error 0.0000(0.0000) Steps 598(589.05) | Grad Norm 0.0399(0.0451) | Total Time 14.00(14.00)\n",
      "Iter 2680 | Time 53.9475(52.5502) | Bit/dim 3.4787(3.4906) | Xent 0.0000(0.0000) | Loss 3.4787(3.4906) | Error 0.0000(0.0000) Steps 598(589.32) | Grad Norm 0.0464(0.0451) | Total Time 14.00(14.00)\n",
      "Iter 2681 | Time 53.7796(52.5871) | Bit/dim 3.4994(3.4909) | Xent 0.0000(0.0000) | Loss 3.4994(3.4909) | Error 0.0000(0.0000) Steps 604(589.76) | Grad Norm 0.0572(0.0455) | Total Time 14.00(14.00)\n",
      "Iter 2682 | Time 51.8911(52.5662) | Bit/dim 3.5010(3.4912) | Xent 0.0000(0.0000) | Loss 3.5010(3.4912) | Error 0.0000(0.0000) Steps 586(589.65) | Grad Norm 0.0386(0.0453) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 22.8682, Epoch Time 353.2144(351.5964), Bit/dim 3.4931(best: 3.4923), Xent 0.0000, Loss 3.4931, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2683 | Time 53.4228(52.5919) | Bit/dim 3.4976(3.4914) | Xent 0.0000(0.0000) | Loss 3.4976(3.4914) | Error 0.0000(0.0000) Steps 586(589.54) | Grad Norm 0.0433(0.0452) | Total Time 14.00(14.00)\n",
      "Iter 2684 | Time 52.1385(52.5783) | Bit/dim 3.4925(3.4914) | Xent 0.0000(0.0000) | Loss 3.4925(3.4914) | Error 0.0000(0.0000) Steps 586(589.43) | Grad Norm 0.0522(0.0454) | Total Time 14.00(14.00)\n",
      "Iter 2685 | Time 51.0441(52.5323) | Bit/dim 3.4843(3.4912) | Xent 0.0000(0.0000) | Loss 3.4843(3.4912) | Error 0.0000(0.0000) Steps 598(589.69) | Grad Norm 0.0420(0.0453) | Total Time 14.00(14.00)\n",
      "Iter 2686 | Time 54.4669(52.5903) | Bit/dim 3.5023(3.4915) | Xent 0.0000(0.0000) | Loss 3.5023(3.4915) | Error 0.0000(0.0000) Steps 592(589.76) | Grad Norm 0.0480(0.0454) | Total Time 14.00(14.00)\n",
      "Iter 2687 | Time 54.0451(52.6340) | Bit/dim 3.4848(3.4913) | Xent 0.0000(0.0000) | Loss 3.4848(3.4913) | Error 0.0000(0.0000) Steps 592(589.82) | Grad Norm 0.0500(0.0456) | Total Time 14.00(14.00)\n",
      "Iter 2688 | Time 51.9075(52.6122) | Bit/dim 3.4830(3.4911) | Xent 0.0000(0.0000) | Loss 3.4830(3.4911) | Error 0.0000(0.0000) Steps 598(590.07) | Grad Norm 0.0530(0.0458) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 22.7907, Epoch Time 355.3926(351.7103), Bit/dim 3.4932(best: 3.4923), Xent 0.0000, Loss 3.4932, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2689 | Time 51.4526(52.5774) | Bit/dim 3.4949(3.4912) | Xent 0.0000(0.0000) | Loss 3.4949(3.4912) | Error 0.0000(0.0000) Steps 586(589.95) | Grad Norm 0.0555(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2690 | Time 49.9265(52.4979) | Bit/dim 3.4804(3.4909) | Xent 0.0000(0.0000) | Loss 3.4804(3.4909) | Error 0.0000(0.0000) Steps 586(589.83) | Grad Norm 0.0437(0.0460) | Total Time 14.00(14.00)\n",
      "Iter 2691 | Time 50.6166(52.4414) | Bit/dim 3.4914(3.4909) | Xent 0.0000(0.0000) | Loss 3.4914(3.4909) | Error 0.0000(0.0000) Steps 586(589.71) | Grad Norm 0.0628(0.0465) | Total Time 14.00(14.00)\n",
      "Iter 2692 | Time 53.6626(52.4781) | Bit/dim 3.5051(3.4913) | Xent 0.0000(0.0000) | Loss 3.5051(3.4913) | Error 0.0000(0.0000) Steps 598(589.96) | Grad Norm 0.0737(0.0473) | Total Time 14.00(14.00)\n",
      "Iter 2693 | Time 51.5547(52.4504) | Bit/dim 3.4925(3.4913) | Xent 0.0000(0.0000) | Loss 3.4925(3.4913) | Error 0.0000(0.0000) Steps 598(590.20) | Grad Norm 0.0479(0.0473) | Total Time 14.00(14.00)\n",
      "Iter 2694 | Time 52.0769(52.4392) | Bit/dim 3.4815(3.4910) | Xent 0.0000(0.0000) | Loss 3.4815(3.4910) | Error 0.0000(0.0000) Steps 592(590.26) | Grad Norm 0.0505(0.0474) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 23.0252, Epoch Time 347.7038(351.5901), Bit/dim 3.4931(best: 3.4923), Xent 0.0000, Loss 3.4931, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2695 | Time 53.2716(52.4641) | Bit/dim 3.4974(3.4912) | Xent 0.0000(0.0000) | Loss 3.4974(3.4912) | Error 0.0000(0.0000) Steps 592(590.31) | Grad Norm 0.0636(0.0479) | Total Time 14.00(14.00)\n",
      "Iter 2696 | Time 52.3353(52.4603) | Bit/dim 3.4957(3.4914) | Xent 0.0000(0.0000) | Loss 3.4957(3.4914) | Error 0.0000(0.0000) Steps 592(590.36) | Grad Norm 0.0519(0.0480) | Total Time 14.00(14.00)\n",
      "Iter 2697 | Time 51.8322(52.4414) | Bit/dim 3.4842(3.4911) | Xent 0.0000(0.0000) | Loss 3.4842(3.4911) | Error 0.0000(0.0000) Steps 586(590.23) | Grad Norm 0.0399(0.0478) | Total Time 14.00(14.00)\n",
      "Iter 2698 | Time 49.4905(52.3529) | Bit/dim 3.4932(3.4912) | Xent 0.0000(0.0000) | Loss 3.4932(3.4912) | Error 0.0000(0.0000) Steps 586(590.10) | Grad Norm 0.0464(0.0478) | Total Time 14.00(14.00)\n",
      "Iter 2699 | Time 50.7497(52.3048) | Bit/dim 3.4802(3.4909) | Xent 0.0000(0.0000) | Loss 3.4802(3.4909) | Error 0.0000(0.0000) Steps 586(589.98) | Grad Norm 0.0533(0.0479) | Total Time 14.00(14.00)\n",
      "Iter 2700 | Time 52.1788(52.3010) | Bit/dim 3.4933(3.4909) | Xent 0.0000(0.0000) | Loss 3.4933(3.4909) | Error 0.0000(0.0000) Steps 598(590.22) | Grad Norm 0.0594(0.0483) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 22.9391, Epoch Time 348.4250(351.4951), Bit/dim 3.4936(best: 3.4923), Xent 0.0000, Loss 3.4936, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2701 | Time 49.7677(52.2250) | Bit/dim 3.5000(3.4912) | Xent 0.0000(0.0000) | Loss 3.5000(3.4912) | Error 0.0000(0.0000) Steps 586(590.09) | Grad Norm 0.0519(0.0484) | Total Time 14.00(14.00)\n",
      "Iter 2702 | Time 53.8756(52.2745) | Bit/dim 3.4793(3.4909) | Xent 0.0000(0.0000) | Loss 3.4793(3.4909) | Error 0.0000(0.0000) Steps 598(590.33) | Grad Norm 0.0566(0.0486) | Total Time 14.00(14.00)\n",
      "Iter 2703 | Time 50.9614(52.2351) | Bit/dim 3.4904(3.4908) | Xent 0.0000(0.0000) | Loss 3.4904(3.4908) | Error 0.0000(0.0000) Steps 586(590.20) | Grad Norm 0.0557(0.0488) | Total Time 14.00(14.00)\n",
      "Iter 2704 | Time 50.2927(52.1769) | Bit/dim 3.4964(3.4910) | Xent 0.0000(0.0000) | Loss 3.4964(3.4910) | Error 0.0000(0.0000) Steps 598(590.43) | Grad Norm 0.0568(0.0491) | Total Time 14.00(14.00)\n",
      "Iter 2705 | Time 55.6123(52.2799) | Bit/dim 3.4914(3.4910) | Xent 0.0000(0.0000) | Loss 3.4914(3.4910) | Error 0.0000(0.0000) Steps 586(590.30) | Grad Norm 0.0574(0.0493) | Total Time 14.00(14.00)\n",
      "Iter 2706 | Time 52.4025(52.2836) | Bit/dim 3.4826(3.4908) | Xent 0.0000(0.0000) | Loss 3.4826(3.4908) | Error 0.0000(0.0000) Steps 586(590.17) | Grad Norm 0.0499(0.0493) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 22.6806, Epoch Time 351.3881(351.4919), Bit/dim 3.4935(best: 3.4923), Xent 0.0000, Loss 3.4935, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2707 | Time 53.4650(52.3191) | Bit/dim 3.4863(3.4906) | Xent 0.0000(0.0000) | Loss 3.4863(3.4906) | Error 0.0000(0.0000) Steps 586(590.05) | Grad Norm 0.0506(0.0494) | Total Time 14.00(14.00)\n",
      "Iter 2708 | Time 52.7478(52.3319) | Bit/dim 3.4950(3.4908) | Xent 0.0000(0.0000) | Loss 3.4950(3.4908) | Error 0.0000(0.0000) Steps 604(590.47) | Grad Norm 0.0579(0.0496) | Total Time 14.00(14.00)\n",
      "Iter 2709 | Time 52.3341(52.3320) | Bit/dim 3.5038(3.4912) | Xent 0.0000(0.0000) | Loss 3.5038(3.4912) | Error 0.0000(0.0000) Steps 598(590.69) | Grad Norm 0.0514(0.0497) | Total Time 14.00(14.00)\n",
      "Iter 2710 | Time 53.3966(52.3639) | Bit/dim 3.4912(3.4912) | Xent 0.0000(0.0000) | Loss 3.4912(3.4912) | Error 0.0000(0.0000) Steps 592(590.73) | Grad Norm 0.0557(0.0499) | Total Time 14.00(14.00)\n",
      "Iter 2711 | Time 52.0073(52.3532) | Bit/dim 3.4800(3.4908) | Xent 0.0000(0.0000) | Loss 3.4800(3.4908) | Error 0.0000(0.0000) Steps 598(590.95) | Grad Norm 0.0490(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 2712 | Time 51.2179(52.3192) | Bit/dim 3.4901(3.4908) | Xent 0.0000(0.0000) | Loss 3.4901(3.4908) | Error 0.0000(0.0000) Steps 586(590.80) | Grad Norm 0.0491(0.0498) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 22.6467, Epoch Time 353.8315(351.5621), Bit/dim 3.4931(best: 3.4923), Xent 0.0000, Loss 3.4931, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2713 | Time 54.8006(52.3936) | Bit/dim 3.4862(3.4907) | Xent 0.0000(0.0000) | Loss 3.4862(3.4907) | Error 0.0000(0.0000) Steps 604(591.20) | Grad Norm 0.0434(0.0496) | Total Time 14.00(14.00)\n",
      "Iter 2714 | Time 51.8454(52.3772) | Bit/dim 3.4873(3.4906) | Xent 0.0000(0.0000) | Loss 3.4873(3.4906) | Error 0.0000(0.0000) Steps 586(591.04) | Grad Norm 0.0431(0.0494) | Total Time 14.00(14.00)\n",
      "Iter 2715 | Time 53.2152(52.4023) | Bit/dim 3.4814(3.4903) | Xent 0.0000(0.0000) | Loss 3.4814(3.4903) | Error 0.0000(0.0000) Steps 598(591.25) | Grad Norm 0.0463(0.0493) | Total Time 14.00(14.00)\n",
      "Iter 2716 | Time 52.6817(52.4107) | Bit/dim 3.4952(3.4904) | Xent 0.0000(0.0000) | Loss 3.4952(3.4904) | Error 0.0000(0.0000) Steps 598(591.45) | Grad Norm 0.0512(0.0494) | Total Time 14.00(14.00)\n",
      "Iter 2717 | Time 52.3739(52.4096) | Bit/dim 3.4885(3.4904) | Xent 0.0000(0.0000) | Loss 3.4885(3.4904) | Error 0.0000(0.0000) Steps 586(591.29) | Grad Norm 0.0461(0.0493) | Total Time 14.00(14.00)\n",
      "Iter 2718 | Time 53.4230(52.4400) | Bit/dim 3.5052(3.4908) | Xent 0.0000(0.0000) | Loss 3.5052(3.4908) | Error 0.0000(0.0000) Steps 598(591.49) | Grad Norm 0.0475(0.0492) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 22.9000, Epoch Time 357.4285(351.7381), Bit/dim 3.4936(best: 3.4923), Xent 0.0000, Loss 3.4936, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2719 | Time 53.0265(52.4576) | Bit/dim 3.4924(3.4909) | Xent 0.0000(0.0000) | Loss 3.4924(3.4909) | Error 0.0000(0.0000) Steps 604(591.87) | Grad Norm 0.0578(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2720 | Time 54.0183(52.5044) | Bit/dim 3.4986(3.4911) | Xent 0.0000(0.0000) | Loss 3.4986(3.4911) | Error 0.0000(0.0000) Steps 586(591.69) | Grad Norm 0.0625(0.0499) | Total Time 14.00(14.00)\n",
      "Iter 2721 | Time 51.7977(52.4832) | Bit/dim 3.4817(3.4908) | Xent 0.0000(0.0000) | Loss 3.4817(3.4908) | Error 0.0000(0.0000) Steps 586(591.52) | Grad Norm 0.0442(0.0497) | Total Time 14.00(14.00)\n",
      "Iter 2722 | Time 52.2159(52.4752) | Bit/dim 3.4909(3.4908) | Xent 0.0000(0.0000) | Loss 3.4909(3.4908) | Error 0.0000(0.0000) Steps 592(591.53) | Grad Norm 0.0427(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2723 | Time 52.7516(52.4835) | Bit/dim 3.4912(3.4908) | Xent 0.0000(0.0000) | Loss 3.4912(3.4908) | Error 0.0000(0.0000) Steps 598(591.73) | Grad Norm 0.0446(0.0494) | Total Time 14.00(14.00)\n",
      "Iter 2724 | Time 52.6942(52.4898) | Bit/dim 3.4928(3.4909) | Xent 0.0000(0.0000) | Loss 3.4928(3.4909) | Error 0.0000(0.0000) Steps 586(591.56) | Grad Norm 0.0578(0.0496) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 22.7885, Epoch Time 355.2308(351.8429), Bit/dim 3.4925(best: 3.4923), Xent 0.0000, Loss 3.4925, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2725 | Time 54.9224(52.5628) | Bit/dim 3.4878(3.4908) | Xent 0.0000(0.0000) | Loss 3.4878(3.4908) | Error 0.0000(0.0000) Steps 586(591.39) | Grad Norm 0.0597(0.0499) | Total Time 14.00(14.00)\n",
      "Iter 2726 | Time 50.5159(52.5014) | Bit/dim 3.4950(3.4909) | Xent 0.0000(0.0000) | Loss 3.4950(3.4909) | Error 0.0000(0.0000) Steps 586(591.23) | Grad Norm 0.0540(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 2727 | Time 50.8936(52.4531) | Bit/dim 3.4949(3.4910) | Xent 0.0000(0.0000) | Loss 3.4949(3.4910) | Error 0.0000(0.0000) Steps 598(591.43) | Grad Norm 0.0558(0.0502) | Total Time 14.00(14.00)\n",
      "Iter 2728 | Time 51.7911(52.4333) | Bit/dim 3.4843(3.4908) | Xent 0.0000(0.0000) | Loss 3.4843(3.4908) | Error 0.0000(0.0000) Steps 592(591.45) | Grad Norm 0.1018(0.0518) | Total Time 14.00(14.00)\n",
      "Iter 2729 | Time 51.9473(52.4187) | Bit/dim 3.4958(3.4910) | Xent 0.0000(0.0000) | Loss 3.4958(3.4910) | Error 0.0000(0.0000) Steps 586(591.28) | Grad Norm 0.0407(0.0514) | Total Time 14.00(14.00)\n",
      "Iter 2730 | Time 52.5666(52.4231) | Bit/dim 3.4901(3.4910) | Xent 0.0000(0.0000) | Loss 3.4901(3.4910) | Error 0.0000(0.0000) Steps 598(591.49) | Grad Norm 0.0452(0.0512) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 23.1004, Epoch Time 351.5983(351.8355), Bit/dim 3.4925(best: 3.4923), Xent 0.0000, Loss 3.4925, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2731 | Time 51.7328(52.4024) | Bit/dim 3.4964(3.4911) | Xent 0.0000(0.0000) | Loss 3.4964(3.4911) | Error 0.0000(0.0000) Steps 586(591.32) | Grad Norm 0.0743(0.0519) | Total Time 14.00(14.00)\n",
      "Iter 2732 | Time 54.5645(52.4673) | Bit/dim 3.4919(3.4912) | Xent 0.0000(0.0000) | Loss 3.4919(3.4912) | Error 0.0000(0.0000) Steps 586(591.16) | Grad Norm 0.0486(0.0518) | Total Time 14.00(14.00)\n",
      "Iter 2733 | Time 52.3751(52.4645) | Bit/dim 3.4940(3.4912) | Xent 0.0000(0.0000) | Loss 3.4940(3.4912) | Error 0.0000(0.0000) Steps 598(591.37) | Grad Norm 0.0499(0.0518) | Total Time 14.00(14.00)\n",
      "Iter 2734 | Time 53.7770(52.5039) | Bit/dim 3.4946(3.4913) | Xent 0.0000(0.0000) | Loss 3.4946(3.4913) | Error 0.0000(0.0000) Steps 586(591.21) | Grad Norm 0.0494(0.0517) | Total Time 14.00(14.00)\n",
      "Iter 2735 | Time 51.2387(52.4659) | Bit/dim 3.4877(3.4912) | Xent 0.0000(0.0000) | Loss 3.4877(3.4912) | Error 0.0000(0.0000) Steps 586(591.05) | Grad Norm 0.0484(0.0516) | Total Time 14.00(14.00)\n",
      "Iter 2736 | Time 53.6592(52.5017) | Bit/dim 3.4866(3.4911) | Xent 0.0000(0.0000) | Loss 3.4866(3.4911) | Error 0.0000(0.0000) Steps 598(591.26) | Grad Norm 0.0655(0.0520) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 23.0224, Epoch Time 356.2526(351.9680), Bit/dim 3.4934(best: 3.4923), Xent 0.0000, Loss 3.4934, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2737 | Time 50.6291(52.4456) | Bit/dim 3.4833(3.4909) | Xent 0.0000(0.0000) | Loss 3.4833(3.4909) | Error 0.0000(0.0000) Steps 598(591.46) | Grad Norm 0.0466(0.0519) | Total Time 14.00(14.00)\n",
      "Iter 2738 | Time 52.5358(52.4483) | Bit/dim 3.4956(3.4910) | Xent 0.0000(0.0000) | Loss 3.4956(3.4910) | Error 0.0000(0.0000) Steps 598(591.66) | Grad Norm 0.0499(0.0518) | Total Time 14.00(14.00)\n",
      "Iter 2739 | Time 49.6834(52.3653) | Bit/dim 3.4845(3.4908) | Xent 0.0000(0.0000) | Loss 3.4845(3.4908) | Error 0.0000(0.0000) Steps 586(591.49) | Grad Norm 0.0486(0.0517) | Total Time 14.00(14.00)\n",
      "Iter 2740 | Time 52.5288(52.3702) | Bit/dim 3.5027(3.4912) | Xent 0.0000(0.0000) | Loss 3.5027(3.4912) | Error 0.0000(0.0000) Steps 586(591.32) | Grad Norm 0.0497(0.0516) | Total Time 14.00(14.00)\n",
      "Iter 2741 | Time 52.5031(52.3742) | Bit/dim 3.4930(3.4912) | Xent 0.0000(0.0000) | Loss 3.4930(3.4912) | Error 0.0000(0.0000) Steps 598(591.52) | Grad Norm 0.0561(0.0518) | Total Time 14.00(14.00)\n",
      "Iter 2742 | Time 52.4559(52.3767) | Bit/dim 3.4862(3.4911) | Xent 0.0000(0.0000) | Loss 3.4862(3.4911) | Error 0.0000(0.0000) Steps 604(591.90) | Grad Norm 0.0426(0.0515) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 22.9249, Epoch Time 349.1004(351.8820), Bit/dim 3.4924(best: 3.4923), Xent 0.0000, Loss 3.4924, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2743 | Time 52.2475(52.3728) | Bit/dim 3.4931(3.4911) | Xent 0.0000(0.0000) | Loss 3.4931(3.4911) | Error 0.0000(0.0000) Steps 604(592.26) | Grad Norm 0.0460(0.0513) | Total Time 14.00(14.00)\n",
      "Iter 2744 | Time 50.3756(52.3129) | Bit/dim 3.4959(3.4913) | Xent 0.0000(0.0000) | Loss 3.4959(3.4913) | Error 0.0000(0.0000) Steps 586(592.07) | Grad Norm 0.0450(0.0511) | Total Time 14.00(14.00)\n",
      "Iter 2745 | Time 54.4573(52.3772) | Bit/dim 3.4880(3.4912) | Xent 0.0000(0.0000) | Loss 3.4880(3.4912) | Error 0.0000(0.0000) Steps 604(592.43) | Grad Norm 0.0479(0.0511) | Total Time 14.00(14.00)\n",
      "Iter 2746 | Time 50.7099(52.3272) | Bit/dim 3.4897(3.4911) | Xent 0.0000(0.0000) | Loss 3.4897(3.4911) | Error 0.0000(0.0000) Steps 598(592.60) | Grad Norm 0.0424(0.0508) | Total Time 14.00(14.00)\n",
      "Iter 2747 | Time 51.5047(52.3025) | Bit/dim 3.4904(3.4911) | Xent 0.0000(0.0000) | Loss 3.4904(3.4911) | Error 0.0000(0.0000) Steps 604(592.94) | Grad Norm 0.0401(0.0505) | Total Time 14.00(14.00)\n",
      "Iter 2748 | Time 51.5318(52.2794) | Bit/dim 3.4950(3.4912) | Xent 0.0000(0.0000) | Loss 3.4950(3.4912) | Error 0.0000(0.0000) Steps 586(592.73) | Grad Norm 0.0433(0.0503) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 22.4863, Epoch Time 348.9683(351.7946), Bit/dim 3.4938(best: 3.4923), Xent 0.0000, Loss 3.4938, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2749 | Time 51.7645(52.2639) | Bit/dim 3.4871(3.4911) | Xent 0.0000(0.0000) | Loss 3.4871(3.4911) | Error 0.0000(0.0000) Steps 598(592.89) | Grad Norm 0.0405(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 2750 | Time 52.6296(52.2749) | Bit/dim 3.4952(3.4912) | Xent 0.0000(0.0000) | Loss 3.4952(3.4912) | Error 0.0000(0.0000) Steps 598(593.04) | Grad Norm 0.0498(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 2751 | Time 48.7687(52.1697) | Bit/dim 3.4873(3.4911) | Xent 0.0000(0.0000) | Loss 3.4873(3.4911) | Error 0.0000(0.0000) Steps 586(592.83) | Grad Norm 0.0425(0.0497) | Total Time 14.00(14.00)\n",
      "Iter 2752 | Time 50.8098(52.1289) | Bit/dim 3.4917(3.4911) | Xent 0.0000(0.0000) | Loss 3.4917(3.4911) | Error 0.0000(0.0000) Steps 592(592.81) | Grad Norm 0.0461(0.0496) | Total Time 14.00(14.00)\n",
      "Iter 2753 | Time 53.6131(52.1734) | Bit/dim 3.4953(3.4912) | Xent 0.0000(0.0000) | Loss 3.4953(3.4912) | Error 0.0000(0.0000) Steps 586(592.60) | Grad Norm 0.0607(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 2754 | Time 53.5193(52.2138) | Bit/dim 3.4877(3.4911) | Xent 0.0000(0.0000) | Loss 3.4877(3.4911) | Error 0.0000(0.0000) Steps 598(592.76) | Grad Norm 0.0475(0.0499) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 22.6818, Epoch Time 349.7267(351.7326), Bit/dim 3.4934(best: 3.4923), Xent 0.0000, Loss 3.4934, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2755 | Time 53.9261(52.2652) | Bit/dim 3.4924(3.4912) | Xent 0.0000(0.0000) | Loss 3.4924(3.4912) | Error 0.0000(0.0000) Steps 598(592.92) | Grad Norm 0.0392(0.0496) | Total Time 14.00(14.00)\n",
      "Iter 2756 | Time 54.5749(52.3345) | Bit/dim 3.4779(3.4908) | Xent 0.0000(0.0000) | Loss 3.4779(3.4908) | Error 0.0000(0.0000) Steps 598(593.07) | Grad Norm 0.0451(0.0494) | Total Time 14.00(14.00)\n",
      "Iter 2757 | Time 50.6298(52.2833) | Bit/dim 3.4919(3.4908) | Xent 0.0000(0.0000) | Loss 3.4919(3.4908) | Error 0.0000(0.0000) Steps 586(592.86) | Grad Norm 0.0507(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2758 | Time 53.3129(52.3142) | Bit/dim 3.4910(3.4908) | Xent 0.0000(0.0000) | Loss 3.4910(3.4908) | Error 0.0000(0.0000) Steps 598(593.02) | Grad Norm 0.0517(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2759 | Time 51.6094(52.2931) | Bit/dim 3.4906(3.4908) | Xent 0.0000(0.0000) | Loss 3.4906(3.4908) | Error 0.0000(0.0000) Steps 586(592.80) | Grad Norm 0.0544(0.0497) | Total Time 14.00(14.00)\n",
      "Iter 2760 | Time 54.3686(52.3553) | Bit/dim 3.4982(3.4910) | Xent 0.0000(0.0000) | Loss 3.4982(3.4910) | Error 0.0000(0.0000) Steps 598(592.96) | Grad Norm 0.0489(0.0497) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 22.6410, Epoch Time 356.7061(351.8818), Bit/dim 3.4938(best: 3.4923), Xent 0.0000, Loss 3.4938, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2761 | Time 54.6184(52.4232) | Bit/dim 3.4914(3.4910) | Xent 0.0000(0.0000) | Loss 3.4914(3.4910) | Error 0.0000(0.0000) Steps 598(593.11) | Grad Norm 0.0489(0.0496) | Total Time 14.00(14.00)\n",
      "Iter 2762 | Time 54.6137(52.4890) | Bit/dim 3.4787(3.4907) | Xent 0.0000(0.0000) | Loss 3.4787(3.4907) | Error 0.0000(0.0000) Steps 604(593.44) | Grad Norm 0.0453(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2763 | Time 53.2356(52.5114) | Bit/dim 3.4829(3.4904) | Xent 0.0000(0.0000) | Loss 3.4829(3.4904) | Error 0.0000(0.0000) Steps 586(593.22) | Grad Norm 0.0498(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2764 | Time 54.7748(52.5793) | Bit/dim 3.5020(3.4908) | Xent 0.0000(0.0000) | Loss 3.5020(3.4908) | Error 0.0000(0.0000) Steps 586(593.00) | Grad Norm 0.0491(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2765 | Time 54.6169(52.6404) | Bit/dim 3.4876(3.4907) | Xent 0.0000(0.0000) | Loss 3.4876(3.4907) | Error 0.0000(0.0000) Steps 586(592.79) | Grad Norm 0.0583(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 2766 | Time 52.8021(52.6452) | Bit/dim 3.4910(3.4907) | Xent 0.0000(0.0000) | Loss 3.4910(3.4907) | Error 0.0000(0.0000) Steps 592(592.77) | Grad Norm 0.0572(0.0500) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 22.7365, Epoch Time 362.9079(352.2126), Bit/dim 3.4930(best: 3.4923), Xent 0.0000, Loss 3.4930, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2767 | Time 52.4258(52.6387) | Bit/dim 3.4884(3.4906) | Xent 0.0000(0.0000) | Loss 3.4884(3.4906) | Error 0.0000(0.0000) Steps 604(593.10) | Grad Norm 0.0441(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 2768 | Time 53.1030(52.6526) | Bit/dim 3.4954(3.4908) | Xent 0.0000(0.0000) | Loss 3.4954(3.4908) | Error 0.0000(0.0000) Steps 598(593.25) | Grad Norm 0.0506(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 2769 | Time 50.5917(52.5908) | Bit/dim 3.4906(3.4908) | Xent 0.0000(0.0000) | Loss 3.4906(3.4908) | Error 0.0000(0.0000) Steps 598(593.39) | Grad Norm 0.0640(0.0503) | Total Time 14.00(14.00)\n",
      "Iter 2770 | Time 53.0961(52.6059) | Bit/dim 3.4880(3.4907) | Xent 0.0000(0.0000) | Loss 3.4880(3.4907) | Error 0.0000(0.0000) Steps 598(593.53) | Grad Norm 0.0494(0.0502) | Total Time 14.00(14.00)\n",
      "Iter 2771 | Time 56.1813(52.7132) | Bit/dim 3.4919(3.4907) | Xent 0.0000(0.0000) | Loss 3.4919(3.4907) | Error 0.0000(0.0000) Steps 598(593.66) | Grad Norm 0.0456(0.0501) | Total Time 14.00(14.00)\n",
      "Iter 2772 | Time 51.3660(52.6728) | Bit/dim 3.4854(3.4906) | Xent 0.0000(0.0000) | Loss 3.4854(3.4906) | Error 0.0000(0.0000) Steps 586(593.43) | Grad Norm 0.0505(0.0501) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 22.8386, Epoch Time 355.0213(352.2968), Bit/dim 3.4936(best: 3.4923), Xent 0.0000, Loss 3.4936, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2773 | Time 53.0645(52.6845) | Bit/dim 3.4813(3.4903) | Xent 0.0000(0.0000) | Loss 3.4813(3.4903) | Error 0.0000(0.0000) Steps 598(593.57) | Grad Norm 0.0593(0.0504) | Total Time 14.00(14.00)\n",
      "Iter 2774 | Time 53.2955(52.7028) | Bit/dim 3.4821(3.4900) | Xent 0.0000(0.0000) | Loss 3.4821(3.4900) | Error 0.0000(0.0000) Steps 586(593.34) | Grad Norm 0.0500(0.0504) | Total Time 14.00(14.00)\n",
      "Iter 2775 | Time 53.8180(52.7363) | Bit/dim 3.4992(3.4903) | Xent 0.0000(0.0000) | Loss 3.4992(3.4903) | Error 0.0000(0.0000) Steps 586(593.12) | Grad Norm 0.0446(0.0502) | Total Time 14.00(14.00)\n",
      "Iter 2776 | Time 53.4541(52.7578) | Bit/dim 3.4816(3.4901) | Xent 0.0000(0.0000) | Loss 3.4816(3.4901) | Error 0.0000(0.0000) Steps 604(593.45) | Grad Norm 0.0470(0.0501) | Total Time 14.00(14.00)\n",
      "Iter 2777 | Time 53.4350(52.7781) | Bit/dim 3.4931(3.4901) | Xent 0.0000(0.0000) | Loss 3.4931(3.4901) | Error 0.0000(0.0000) Steps 598(593.59) | Grad Norm 0.0570(0.0503) | Total Time 14.00(14.00)\n",
      "Iter 2778 | Time 53.8900(52.8115) | Bit/dim 3.5009(3.4905) | Xent 0.0000(0.0000) | Loss 3.5009(3.4905) | Error 0.0000(0.0000) Steps 598(593.72) | Grad Norm 0.0496(0.0503) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 22.5266, Epoch Time 359.2293(352.5048), Bit/dim 3.4931(best: 3.4923), Xent 0.0000, Loss 3.4931, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2779 | Time 53.0379(52.8183) | Bit/dim 3.4922(3.4905) | Xent 0.0000(0.0000) | Loss 3.4922(3.4905) | Error 0.0000(0.0000) Steps 592(593.67) | Grad Norm 0.0456(0.0502) | Total Time 14.00(14.00)\n",
      "Iter 2780 | Time 50.9283(52.7616) | Bit/dim 3.4921(3.4906) | Xent 0.0000(0.0000) | Loss 3.4921(3.4906) | Error 0.0000(0.0000) Steps 586(593.44) | Grad Norm 0.0520(0.0502) | Total Time 14.00(14.00)\n",
      "Iter 2781 | Time 53.2076(52.7750) | Bit/dim 3.4935(3.4907) | Xent 0.0000(0.0000) | Loss 3.4935(3.4907) | Error 0.0000(0.0000) Steps 598(593.57) | Grad Norm 0.0599(0.0505) | Total Time 14.00(14.00)\n",
      "Iter 2782 | Time 50.6687(52.7118) | Bit/dim 3.4907(3.4907) | Xent 0.0000(0.0000) | Loss 3.4907(3.4907) | Error 0.0000(0.0000) Steps 598(593.71) | Grad Norm 0.0440(0.0503) | Total Time 14.00(14.00)\n",
      "Iter 2783 | Time 52.8099(52.7147) | Bit/dim 3.4921(3.4907) | Xent 0.0000(0.0000) | Loss 3.4921(3.4907) | Error 0.0000(0.0000) Steps 586(593.48) | Grad Norm 0.0521(0.0504) | Total Time 14.00(14.00)\n",
      "Iter 2784 | Time 52.4230(52.7060) | Bit/dim 3.4927(3.4908) | Xent 0.0000(0.0000) | Loss 3.4927(3.4908) | Error 0.0000(0.0000) Steps 586(593.25) | Grad Norm 0.0687(0.0509) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 22.8793, Epoch Time 351.7685(352.4827), Bit/dim 3.4927(best: 3.4923), Xent 0.0000, Loss 3.4927, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2785 | Time 49.8093(52.6191) | Bit/dim 3.4932(3.4908) | Xent 0.0000(0.0000) | Loss 3.4932(3.4908) | Error 0.0000(0.0000) Steps 598(593.39) | Grad Norm 0.0605(0.0512) | Total Time 14.00(14.00)\n",
      "Iter 2786 | Time 51.8033(52.5946) | Bit/dim 3.4874(3.4907) | Xent 0.0000(0.0000) | Loss 3.4874(3.4907) | Error 0.0000(0.0000) Steps 586(593.17) | Grad Norm 0.0536(0.0513) | Total Time 14.00(14.00)\n",
      "Iter 2787 | Time 49.3243(52.4965) | Bit/dim 3.4899(3.4907) | Xent 0.0000(0.0000) | Loss 3.4899(3.4907) | Error 0.0000(0.0000) Steps 598(593.32) | Grad Norm 0.0643(0.0517) | Total Time 14.00(14.00)\n",
      "Iter 2788 | Time 49.7143(52.4130) | Bit/dim 3.4921(3.4907) | Xent 0.0000(0.0000) | Loss 3.4921(3.4907) | Error 0.0000(0.0000) Steps 586(593.10) | Grad Norm 0.0700(0.0522) | Total Time 14.00(14.00)\n",
      "Iter 2789 | Time 51.3934(52.3824) | Bit/dim 3.4884(3.4907) | Xent 0.0000(0.0000) | Loss 3.4884(3.4907) | Error 0.0000(0.0000) Steps 586(592.88) | Grad Norm 0.0586(0.0524) | Total Time 14.00(14.00)\n",
      "Iter 2790 | Time 51.6002(52.3590) | Bit/dim 3.4929(3.4907) | Xent 0.0000(0.0000) | Loss 3.4929(3.4907) | Error 0.0000(0.0000) Steps 598(593.04) | Grad Norm 0.0395(0.0520) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 22.8145, Epoch Time 341.8742(352.1645), Bit/dim 3.4924(best: 3.4923), Xent 0.0000, Loss 3.4924, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2791 | Time 52.0670(52.3502) | Bit/dim 3.5031(3.4911) | Xent 0.0000(0.0000) | Loss 3.5031(3.4911) | Error 0.0000(0.0000) Steps 586(592.83) | Grad Norm 0.0588(0.0522) | Total Time 14.00(14.00)\n",
      "Iter 2792 | Time 53.3621(52.3806) | Bit/dim 3.4880(3.4910) | Xent 0.0000(0.0000) | Loss 3.4880(3.4910) | Error 0.0000(0.0000) Steps 604(593.16) | Grad Norm 0.0739(0.0529) | Total Time 14.00(14.00)\n",
      "Iter 2793 | Time 51.4073(52.3514) | Bit/dim 3.4767(3.4906) | Xent 0.0000(0.0000) | Loss 3.4767(3.4906) | Error 0.0000(0.0000) Steps 598(593.31) | Grad Norm 0.0453(0.0526) | Total Time 14.00(14.00)\n",
      "Iter 2794 | Time 53.3066(52.3800) | Bit/dim 3.5022(3.4909) | Xent 0.0000(0.0000) | Loss 3.5022(3.4909) | Error 0.0000(0.0000) Steps 592(593.27) | Grad Norm 0.0444(0.0524) | Total Time 14.00(14.00)\n",
      "Iter 2795 | Time 50.6420(52.3279) | Bit/dim 3.4956(3.4911) | Xent 0.0000(0.0000) | Loss 3.4956(3.4911) | Error 0.0000(0.0000) Steps 598(593.41) | Grad Norm 0.0584(0.0526) | Total Time 14.00(14.00)\n",
      "Iter 2796 | Time 53.7526(52.3706) | Bit/dim 3.4773(3.4907) | Xent 0.0000(0.0000) | Loss 3.4773(3.4907) | Error 0.0000(0.0000) Steps 586(593.19) | Grad Norm 0.0721(0.0532) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 22.9457, Epoch Time 353.4488(352.2030), Bit/dim 3.4926(best: 3.4923), Xent 0.0000, Loss 3.4926, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2797 | Time 51.5185(52.3451) | Bit/dim 3.4961(3.4908) | Xent 0.0000(0.0000) | Loss 3.4961(3.4908) | Error 0.0000(0.0000) Steps 598(593.33) | Grad Norm 0.0571(0.0533) | Total Time 14.00(14.00)\n",
      "Iter 2798 | Time 50.7920(52.2985) | Bit/dim 3.4888(3.4908) | Xent 0.0000(0.0000) | Loss 3.4888(3.4908) | Error 0.0000(0.0000) Steps 592(593.29) | Grad Norm 0.0447(0.0530) | Total Time 14.00(14.00)\n",
      "Iter 2799 | Time 51.0891(52.2622) | Bit/dim 3.4892(3.4907) | Xent 0.0000(0.0000) | Loss 3.4892(3.4907) | Error 0.0000(0.0000) Steps 604(593.61) | Grad Norm 0.0544(0.0531) | Total Time 14.00(14.00)\n",
      "Iter 2800 | Time 52.5274(52.2702) | Bit/dim 3.4889(3.4907) | Xent 0.0000(0.0000) | Loss 3.4889(3.4907) | Error 0.0000(0.0000) Steps 586(593.38) | Grad Norm 0.0492(0.0529) | Total Time 14.00(14.00)\n",
      "Iter 2801 | Time 54.5281(52.3379) | Bit/dim 3.4875(3.4906) | Xent 0.0000(0.0000) | Loss 3.4875(3.4906) | Error 0.0000(0.0000) Steps 586(593.16) | Grad Norm 0.0550(0.0530) | Total Time 14.00(14.00)\n",
      "Iter 2802 | Time 51.4022(52.3098) | Bit/dim 3.4920(3.4906) | Xent 0.0000(0.0000) | Loss 3.4920(3.4906) | Error 0.0000(0.0000) Steps 598(593.31) | Grad Norm 0.0495(0.0529) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 22.8191, Epoch Time 350.4694(352.1510), Bit/dim 3.4929(best: 3.4923), Xent 0.0000, Loss 3.4929, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2803 | Time 51.9410(52.2988) | Bit/dim 3.4766(3.4902) | Xent 0.0000(0.0000) | Loss 3.4766(3.4902) | Error 0.0000(0.0000) Steps 604(593.63) | Grad Norm 0.0508(0.0528) | Total Time 14.00(14.00)\n",
      "Iter 2804 | Time 53.9814(52.3492) | Bit/dim 3.4990(3.4905) | Xent 0.0000(0.0000) | Loss 3.4990(3.4905) | Error 0.0000(0.0000) Steps 586(593.40) | Grad Norm 0.0555(0.0529) | Total Time 14.00(14.00)\n",
      "Iter 2805 | Time 50.6824(52.2992) | Bit/dim 3.4883(3.4904) | Xent 0.0000(0.0000) | Loss 3.4883(3.4904) | Error 0.0000(0.0000) Steps 586(593.18) | Grad Norm 0.0490(0.0528) | Total Time 14.00(14.00)\n",
      "Iter 2806 | Time 51.2182(52.2668) | Bit/dim 3.4963(3.4906) | Xent 0.0000(0.0000) | Loss 3.4963(3.4906) | Error 0.0000(0.0000) Steps 604(593.50) | Grad Norm 0.0396(0.0524) | Total Time 14.00(14.00)\n",
      "Iter 2807 | Time 49.6134(52.1872) | Bit/dim 3.4994(3.4908) | Xent 0.0000(0.0000) | Loss 3.4994(3.4908) | Error 0.0000(0.0000) Steps 586(593.28) | Grad Norm 0.0539(0.0525) | Total Time 14.00(14.00)\n",
      "Iter 2810 | Time 53.1196(52.1476) | Bit/dim 3.4895(3.4910) | Xent 0.0000(0.0000) | Loss 3.4895(3.4910) | Error 0.0000(0.0000) Steps 586(592.99) | Grad Norm 0.0413(0.0517) | Total Time 14.00(14.00)\n",
      "Iter 2811 | Time 52.6500(52.1626) | Bit/dim 3.4708(3.4904) | Xent 0.0000(0.0000) | Loss 3.4708(3.4904) | Error 0.0000(0.0000) Steps 604(593.32) | Grad Norm 0.0433(0.0515) | Total Time 14.00(14.00)\n",
      "Iter 2812 | Time 54.3134(52.2272) | Bit/dim 3.4918(3.4904) | Xent 0.0000(0.0000) | Loss 3.4918(3.4904) | Error 0.0000(0.0000) Steps 586(593.10) | Grad Norm 0.0547(0.0516) | Total Time 14.00(14.00)\n",
      "Iter 2813 | Time 51.1373(52.1945) | Bit/dim 3.5013(3.4908) | Xent 0.0000(0.0000) | Loss 3.5013(3.4908) | Error 0.0000(0.0000) Steps 598(593.25) | Grad Norm 0.0517(0.0516) | Total Time 14.00(14.00)\n",
      "Iter 2814 | Time 52.6533(52.2082) | Bit/dim 3.4917(3.4908) | Xent 0.0000(0.0000) | Loss 3.4917(3.4908) | Error 0.0000(0.0000) Steps 598(593.39) | Grad Norm 0.0426(0.0513) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 23.0044, Epoch Time 352.7818(352.0371), Bit/dim 3.4924(best: 3.4923), Xent 0.0000, Loss 3.4924, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2815 | Time 53.1744(52.2372) | Bit/dim 3.4786(3.4904) | Xent 0.0000(0.0000) | Loss 3.4786(3.4904) | Error 0.0000(0.0000) Steps 598(593.53) | Grad Norm 0.0459(0.0511) | Total Time 14.00(14.00)\n",
      "Iter 2816 | Time 53.5348(52.2761) | Bit/dim 3.5027(3.4908) | Xent 0.0000(0.0000) | Loss 3.5027(3.4908) | Error 0.0000(0.0000) Steps 586(593.30) | Grad Norm 0.0402(0.0508) | Total Time 14.00(14.00)\n",
      "Iter 2817 | Time 53.0934(52.3007) | Bit/dim 3.4884(3.4907) | Xent 0.0000(0.0000) | Loss 3.4884(3.4907) | Error 0.0000(0.0000) Steps 592(593.26) | Grad Norm 0.0562(0.0510) | Total Time 14.00(14.00)\n",
      "Iter 2818 | Time 52.5141(52.3071) | Bit/dim 3.4929(3.4908) | Xent 0.0000(0.0000) | Loss 3.4929(3.4908) | Error 0.0000(0.0000) Steps 598(593.41) | Grad Norm 0.0507(0.0510) | Total Time 14.00(14.00)\n",
      "Iter 2819 | Time 51.8402(52.2931) | Bit/dim 3.4857(3.4906) | Xent 0.0000(0.0000) | Loss 3.4857(3.4906) | Error 0.0000(0.0000) Steps 586(593.18) | Grad Norm 0.0453(0.0508) | Total Time 14.00(14.00)\n",
      "Iter 2820 | Time 55.4193(52.3869) | Bit/dim 3.4925(3.4907) | Xent 0.0000(0.0000) | Loss 3.4925(3.4907) | Error 0.0000(0.0000) Steps 598(593.33) | Grad Norm 0.0548(0.0509) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 22.8109, Epoch Time 358.2509(352.2235), Bit/dim 3.4928(best: 3.4923), Xent 0.0000, Loss 3.4928, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2821 | Time 53.9370(52.4334) | Bit/dim 3.5014(3.4910) | Xent 0.0000(0.0000) | Loss 3.5014(3.4910) | Error 0.0000(0.0000) Steps 604(593.65) | Grad Norm 0.0461(0.0508) | Total Time 14.00(14.00)\n",
      "Iter 2822 | Time 51.7417(52.4126) | Bit/dim 3.5051(3.4914) | Xent 0.0000(0.0000) | Loss 3.5051(3.4914) | Error 0.0000(0.0000) Steps 586(593.42) | Grad Norm 0.0705(0.0514) | Total Time 14.00(14.00)\n",
      "Iter 2823 | Time 50.9202(52.3678) | Bit/dim 3.4700(3.4908) | Xent 0.0000(0.0000) | Loss 3.4700(3.4908) | Error 0.0000(0.0000) Steps 586(593.20) | Grad Norm 0.0488(0.0513) | Total Time 14.00(14.00)\n",
      "Iter 2824 | Time 51.8285(52.3517) | Bit/dim 3.4840(3.4906) | Xent 0.0000(0.0000) | Loss 3.4840(3.4906) | Error 0.0000(0.0000) Steps 586(592.98) | Grad Norm 0.0573(0.0515) | Total Time 14.00(14.00)\n",
      "Iter 2825 | Time 51.8670(52.3371) | Bit/dim 3.4903(3.4906) | Xent 0.0000(0.0000) | Loss 3.4903(3.4906) | Error 0.0000(0.0000) Steps 598(593.13) | Grad Norm 0.0524(0.0515) | Total Time 14.00(14.00)\n",
      "Iter 2826 | Time 52.1035(52.3301) | Bit/dim 3.4877(3.4905) | Xent 0.0000(0.0000) | Loss 3.4877(3.4905) | Error 0.0000(0.0000) Steps 586(592.92) | Grad Norm 0.0547(0.0516) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 22.8114, Epoch Time 350.9491(352.1852), Bit/dim 3.4935(best: 3.4923), Xent 0.0000, Loss 3.4935, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2827 | Time 50.8550(52.2859) | Bit/dim 3.4887(3.4904) | Xent 0.0000(0.0000) | Loss 3.4887(3.4904) | Error 0.0000(0.0000) Steps 604(593.25) | Grad Norm 0.0458(0.0514) | Total Time 14.00(14.00)\n",
      "Iter 2828 | Time 49.7190(52.2088) | Bit/dim 3.4960(3.4906) | Xent 0.0000(0.0000) | Loss 3.4960(3.4906) | Error 0.0000(0.0000) Steps 586(593.03) | Grad Norm 0.0392(0.0511) | Total Time 14.00(14.00)\n",
      "Iter 2829 | Time 53.7423(52.2549) | Bit/dim 3.4884(3.4905) | Xent 0.0000(0.0000) | Loss 3.4884(3.4905) | Error 0.0000(0.0000) Steps 586(592.82) | Grad Norm 0.0493(0.0510) | Total Time 14.00(14.00)\n",
      "Iter 2830 | Time 52.2596(52.2550) | Bit/dim 3.4837(3.4903) | Xent 0.0000(0.0000) | Loss 3.4837(3.4903) | Error 0.0000(0.0000) Steps 598(592.98) | Grad Norm 0.0465(0.0509) | Total Time 14.00(14.00)\n",
      "Iter 2831 | Time 55.4128(52.3497) | Bit/dim 3.4923(3.4904) | Xent 0.0000(0.0000) | Loss 3.4923(3.4904) | Error 0.0000(0.0000) Steps 598(593.13) | Grad Norm 0.0440(0.0507) | Total Time 14.00(14.00)\n",
      "Iter 2832 | Time 51.7184(52.3308) | Bit/dim 3.4982(3.4906) | Xent 0.0000(0.0000) | Loss 3.4982(3.4906) | Error 0.0000(0.0000) Steps 598(593.27) | Grad Norm 0.0412(0.0504) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 22.7857, Epoch Time 352.4765(352.1940), Bit/dim 3.4939(best: 3.4923), Xent 0.0000, Loss 3.4939, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2833 | Time 53.0932(52.3537) | Bit/dim 3.4903(3.4906) | Xent 0.0000(0.0000) | Loss 3.4903(3.4906) | Error 0.0000(0.0000) Steps 586(593.06) | Grad Norm 0.0481(0.0503) | Total Time 14.00(14.00)\n",
      "Iter 2834 | Time 52.5807(52.3605) | Bit/dim 3.4947(3.4907) | Xent 0.0000(0.0000) | Loss 3.4947(3.4907) | Error 0.0000(0.0000) Steps 586(592.84) | Grad Norm 0.0401(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 2835 | Time 55.0784(52.4420) | Bit/dim 3.4866(3.4906) | Xent 0.0000(0.0000) | Loss 3.4866(3.4906) | Error 0.0000(0.0000) Steps 586(592.64) | Grad Norm 0.0563(0.0502) | Total Time 14.00(14.00)\n",
      "Iter 2836 | Time 50.1459(52.3731) | Bit/dim 3.4942(3.4907) | Xent 0.0000(0.0000) | Loss 3.4942(3.4907) | Error 0.0000(0.0000) Steps 586(592.44) | Grad Norm 0.0435(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 2837 | Time 52.7914(52.3857) | Bit/dim 3.4894(3.4907) | Xent 0.0000(0.0000) | Loss 3.4894(3.4907) | Error 0.0000(0.0000) Steps 604(592.79) | Grad Norm 0.0455(0.0499) | Total Time 14.00(14.00)\n",
      "Iter 2838 | Time 50.8976(52.3410) | Bit/dim 3.4938(3.4908) | Xent 0.0000(0.0000) | Loss 3.4938(3.4908) | Error 0.0000(0.0000) Steps 598(592.94) | Grad Norm 0.0476(0.0498) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 22.5504, Epoch Time 352.7268(352.2100), Bit/dim 3.4922(best: 3.4923), Xent 0.0000, Loss 3.4922, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2839 | Time 53.6927(52.3816) | Bit/dim 3.4811(3.4905) | Xent 0.0000(0.0000) | Loss 3.4811(3.4905) | Error 0.0000(0.0000) Steps 598(593.09) | Grad Norm 0.0493(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 2840 | Time 53.3409(52.4104) | Bit/dim 3.4954(3.4906) | Xent 0.0000(0.0000) | Loss 3.4954(3.4906) | Error 0.0000(0.0000) Steps 604(593.42) | Grad Norm 0.0483(0.0497) | Total Time 14.00(14.00)\n",
      "Iter 2841 | Time 55.1778(52.4934) | Bit/dim 3.4942(3.4907) | Xent 0.0000(0.0000) | Loss 3.4942(3.4907) | Error 0.0000(0.0000) Steps 586(593.20) | Grad Norm 0.0539(0.0499) | Total Time 14.00(14.00)\n",
      "Iter 2842 | Time 57.3053(52.6377) | Bit/dim 3.5000(3.4910) | Xent 0.0000(0.0000) | Loss 3.5000(3.4910) | Error 0.0000(0.0000) Steps 598(593.34) | Grad Norm 0.0488(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 2843 | Time 52.5451(52.6350) | Bit/dim 3.4861(3.4909) | Xent 0.0000(0.0000) | Loss 3.4861(3.4909) | Error 0.0000(0.0000) Steps 598(593.48) | Grad Norm 0.0484(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 2844 | Time 51.4334(52.5989) | Bit/dim 3.4836(3.4906) | Xent 0.0000(0.0000) | Loss 3.4836(3.4906) | Error 0.0000(0.0000) Steps 598(593.62) | Grad Norm 0.0485(0.0497) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 22.8838, Epoch Time 361.9522(352.5022), Bit/dim 3.4923(best: 3.4922), Xent 0.0000, Loss 3.4923, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2845 | Time 50.5209(52.5366) | Bit/dim 3.4877(3.4906) | Xent 0.0000(0.0000) | Loss 3.4877(3.4906) | Error 0.0000(0.0000) Steps 598(593.75) | Grad Norm 0.0434(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2846 | Time 50.7025(52.4816) | Bit/dim 3.4987(3.4908) | Xent 0.0000(0.0000) | Loss 3.4987(3.4908) | Error 0.0000(0.0000) Steps 586(593.52) | Grad Norm 0.0519(0.0496) | Total Time 14.00(14.00)\n",
      "Iter 2847 | Time 50.8053(52.4313) | Bit/dim 3.4870(3.4907) | Xent 0.0000(0.0000) | Loss 3.4870(3.4907) | Error 0.0000(0.0000) Steps 598(593.65) | Grad Norm 0.0566(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 2848 | Time 50.6912(52.3791) | Bit/dim 3.4837(3.4905) | Xent 0.0000(0.0000) | Loss 3.4837(3.4905) | Error 0.0000(0.0000) Steps 598(593.78) | Grad Norm 0.0622(0.0502) | Total Time 14.00(14.00)\n",
      "Iter 2849 | Time 54.2095(52.4340) | Bit/dim 3.4913(3.4905) | Xent 0.0000(0.0000) | Loss 3.4913(3.4905) | Error 0.0000(0.0000) Steps 592(593.73) | Grad Norm 0.0468(0.0501) | Total Time 14.00(14.00)\n",
      "Iter 2850 | Time 52.8988(52.4479) | Bit/dim 3.4995(3.4908) | Xent 0.0000(0.0000) | Loss 3.4995(3.4908) | Error 0.0000(0.0000) Steps 598(593.86) | Grad Norm 0.0422(0.0499) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 22.8314, Epoch Time 348.4772(352.3815), Bit/dim 3.4924(best: 3.4922), Xent 0.0000, Loss 3.4924, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2851 | Time 52.9885(52.4641) | Bit/dim 3.4914(3.4908) | Xent 0.0000(0.0000) | Loss 3.4914(3.4908) | Error 0.0000(0.0000) Steps 598(593.98) | Grad Norm 0.0496(0.0499) | Total Time 14.00(14.00)\n",
      "Iter 2852 | Time 53.8309(52.5051) | Bit/dim 3.4865(3.4907) | Xent 0.0000(0.0000) | Loss 3.4865(3.4907) | Error 0.0000(0.0000) Steps 598(594.10) | Grad Norm 0.0559(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 2853 | Time 52.1229(52.4937) | Bit/dim 3.4894(3.4906) | Xent 0.0000(0.0000) | Loss 3.4894(3.4906) | Error 0.0000(0.0000) Steps 598(594.22) | Grad Norm 0.0481(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 2854 | Time 53.8409(52.5341) | Bit/dim 3.4807(3.4903) | Xent 0.0000(0.0000) | Loss 3.4807(3.4903) | Error 0.0000(0.0000) Steps 586(593.97) | Grad Norm 0.0443(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 2855 | Time 52.9323(52.5460) | Bit/dim 3.4970(3.4905) | Xent 0.0000(0.0000) | Loss 3.4970(3.4905) | Error 0.0000(0.0000) Steps 598(594.09) | Grad Norm 0.0471(0.0497) | Total Time 14.00(14.00)\n",
      "Iter 2856 | Time 50.0192(52.4702) | Bit/dim 3.4944(3.4906) | Xent 0.0000(0.0000) | Loss 3.4944(3.4906) | Error 0.0000(0.0000) Steps 598(594.21) | Grad Norm 0.0448(0.0496) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 22.8444, Epoch Time 354.6021(352.4481), Bit/dim 3.4923(best: 3.4922), Xent 0.0000, Loss 3.4923, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2857 | Time 54.8842(52.5427) | Bit/dim 3.4913(3.4907) | Xent 0.0000(0.0000) | Loss 3.4913(3.4907) | Error 0.0000(0.0000) Steps 598(594.32) | Grad Norm 0.0467(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2858 | Time 52.9328(52.5544) | Bit/dim 3.4914(3.4907) | Xent 0.0000(0.0000) | Loss 3.4914(3.4907) | Error 0.0000(0.0000) Steps 598(594.43) | Grad Norm 0.0512(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2859 | Time 52.2369(52.5448) | Bit/dim 3.4943(3.4908) | Xent 0.0000(0.0000) | Loss 3.4943(3.4908) | Error 0.0000(0.0000) Steps 604(594.72) | Grad Norm 0.0429(0.0493) | Total Time 14.00(14.00)\n",
      "Iter 2860 | Time 49.1619(52.4433) | Bit/dim 3.4777(3.4904) | Xent 0.0000(0.0000) | Loss 3.4777(3.4904) | Error 0.0000(0.0000) Steps 598(594.82) | Grad Norm 0.0547(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 2861 | Time 52.3734(52.4412) | Bit/dim 3.4927(3.4905) | Xent 0.0000(0.0000) | Loss 3.4927(3.4905) | Error 0.0000(0.0000) Steps 598(594.91) | Grad Norm 0.0458(0.0494) | Total Time 14.00(14.00)\n",
      "Iter 2862 | Time 50.2158(52.3745) | Bit/dim 3.4955(3.4906) | Xent 0.0000(0.0000) | Loss 3.4955(3.4906) | Error 0.0000(0.0000) Steps 604(595.19) | Grad Norm 0.0482(0.0494) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 22.9927, Epoch Time 350.5104(352.3900), Bit/dim 3.4927(best: 3.4922), Xent 0.0000, Loss 3.4927, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2863 | Time 51.0587(52.3350) | Bit/dim 3.4896(3.4906) | Xent 0.0000(0.0000) | Loss 3.4896(3.4906) | Error 0.0000(0.0000) Steps 598(595.27) | Grad Norm 0.0447(0.0492) | Total Time 14.00(14.00)\n",
      "Iter 2864 | Time 52.4201(52.3376) | Bit/dim 3.4910(3.4906) | Xent 0.0000(0.0000) | Loss 3.4910(3.4906) | Error 0.0000(0.0000) Steps 598(595.35) | Grad Norm 0.0391(0.0489) | Total Time 14.00(14.00)\n",
      "Iter 2865 | Time 51.5087(52.3127) | Bit/dim 3.4951(3.4907) | Xent 0.0000(0.0000) | Loss 3.4951(3.4907) | Error 0.0000(0.0000) Steps 598(595.43) | Grad Norm 0.0430(0.0487) | Total Time 14.00(14.00)\n",
      "Iter 2866 | Time 52.9387(52.3315) | Bit/dim 3.4868(3.4906) | Xent 0.0000(0.0000) | Loss 3.4868(3.4906) | Error 0.0000(0.0000) Steps 598(595.51) | Grad Norm 0.0421(0.0485) | Total Time 14.00(14.00)\n",
      "Iter 2867 | Time 51.2582(52.2993) | Bit/dim 3.4821(3.4904) | Xent 0.0000(0.0000) | Loss 3.4821(3.4904) | Error 0.0000(0.0000) Steps 598(595.58) | Grad Norm 0.0474(0.0485) | Total Time 14.00(14.00)\n",
      "Iter 2868 | Time 52.2669(52.2983) | Bit/dim 3.4935(3.4905) | Xent 0.0000(0.0000) | Loss 3.4935(3.4905) | Error 0.0000(0.0000) Steps 598(595.66) | Grad Norm 0.0414(0.0483) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 22.8676, Epoch Time 350.0158(352.3187), Bit/dim 3.4923(best: 3.4922), Xent 0.0000, Loss 3.4923, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2869 | Time 54.5585(52.3661) | Bit/dim 3.4888(3.4904) | Xent 0.0000(0.0000) | Loss 3.4888(3.4904) | Error 0.0000(0.0000) Steps 598(595.73) | Grad Norm 0.0390(0.0480) | Total Time 14.00(14.00)\n",
      "Iter 2870 | Time 55.3156(52.4546) | Bit/dim 3.4909(3.4904) | Xent 0.0000(0.0000) | Loss 3.4909(3.4904) | Error 0.0000(0.0000) Steps 598(595.80) | Grad Norm 0.0423(0.0478) | Total Time 14.00(14.00)\n",
      "Iter 2871 | Time 54.2899(52.5097) | Bit/dim 3.4777(3.4900) | Xent 0.0000(0.0000) | Loss 3.4777(3.4900) | Error 0.0000(0.0000) Steps 604(596.04) | Grad Norm 0.0437(0.0477) | Total Time 14.00(14.00)\n",
      "Iter 2872 | Time 53.6864(52.5450) | Bit/dim 3.4885(3.4900) | Xent 0.0000(0.0000) | Loss 3.4885(3.4900) | Error 0.0000(0.0000) Steps 598(596.10) | Grad Norm 0.0467(0.0477) | Total Time 14.00(14.00)\n",
      "Iter 2873 | Time 53.3183(52.5682) | Bit/dim 3.4990(3.4903) | Xent 0.0000(0.0000) | Loss 3.4990(3.4903) | Error 0.0000(0.0000) Steps 598(596.16) | Grad Norm 0.0611(0.0481) | Total Time 14.00(14.00)\n",
      "Iter 2874 | Time 50.3618(52.5020) | Bit/dim 3.4888(3.4902) | Xent 0.0000(0.0000) | Loss 3.4888(3.4902) | Error 0.0000(0.0000) Steps 592(596.03) | Grad Norm 0.0451(0.0480) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 22.5100, Epoch Time 359.5216(352.5348), Bit/dim 3.4925(best: 3.4922), Xent 0.0000, Loss 3.4925, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2875 | Time 50.7166(52.4484) | Bit/dim 3.4911(3.4902) | Xent 0.0000(0.0000) | Loss 3.4911(3.4902) | Error 0.0000(0.0000) Steps 604(596.27) | Grad Norm 0.0441(0.0479) | Total Time 14.00(14.00)\n",
      "Iter 2876 | Time 54.7263(52.5167) | Bit/dim 3.4941(3.4904) | Xent 0.0000(0.0000) | Loss 3.4941(3.4904) | Error 0.0000(0.0000) Steps 604(596.50) | Grad Norm 0.0462(0.0478) | Total Time 14.00(14.00)\n",
      "Iter 2877 | Time 53.1583(52.5360) | Bit/dim 3.4922(3.4904) | Xent 0.0000(0.0000) | Loss 3.4922(3.4904) | Error 0.0000(0.0000) Steps 598(596.55) | Grad Norm 0.0501(0.0479) | Total Time 14.00(14.00)\n",
      "Iter 2878 | Time 51.1421(52.4942) | Bit/dim 3.4865(3.4903) | Xent 0.0000(0.0000) | Loss 3.4865(3.4903) | Error 0.0000(0.0000) Steps 598(596.59) | Grad Norm 0.0431(0.0478) | Total Time 14.00(14.00)\n",
      "Iter 2879 | Time 54.1055(52.5425) | Bit/dim 3.4827(3.4901) | Xent 0.0000(0.0000) | Loss 3.4827(3.4901) | Error 0.0000(0.0000) Steps 598(596.63) | Grad Norm 0.0487(0.0478) | Total Time 14.00(14.00)\n",
      "Iter 2880 | Time 49.9659(52.4652) | Bit/dim 3.4999(3.4904) | Xent 0.0000(0.0000) | Loss 3.4999(3.4904) | Error 0.0000(0.0000) Steps 598(596.68) | Grad Norm 0.0541(0.0480) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 22.8757, Epoch Time 352.3180(352.5283), Bit/dim 3.4926(best: 3.4922), Xent 0.0000, Loss 3.4926, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2881 | Time 54.3274(52.5211) | Bit/dim 3.4917(3.4904) | Xent 0.0000(0.0000) | Loss 3.4917(3.4904) | Error 0.0000(0.0000) Steps 598(596.72) | Grad Norm 0.0413(0.0478) | Total Time 14.00(14.00)\n",
      "Iter 2882 | Time 52.2292(52.5123) | Bit/dim 3.5000(3.4907) | Xent 0.0000(0.0000) | Loss 3.5000(3.4907) | Error 0.0000(0.0000) Steps 598(596.75) | Grad Norm 0.0458(0.0477) | Total Time 14.00(14.00)\n",
      "Iter 2883 | Time 50.3381(52.4471) | Bit/dim 3.4828(3.4905) | Xent 0.0000(0.0000) | Loss 3.4828(3.4905) | Error 0.0000(0.0000) Steps 598(596.79) | Grad Norm 0.0445(0.0476) | Total Time 14.00(14.00)\n",
      "Iter 2884 | Time 52.6589(52.4535) | Bit/dim 3.4872(3.4904) | Xent 0.0000(0.0000) | Loss 3.4872(3.4904) | Error 0.0000(0.0000) Steps 604(597.01) | Grad Norm 0.0462(0.0476) | Total Time 14.00(14.00)\n",
      "Iter 2885 | Time 52.6427(52.4591) | Bit/dim 3.4927(3.4904) | Xent 0.0000(0.0000) | Loss 3.4927(3.4904) | Error 0.0000(0.0000) Steps 598(597.04) | Grad Norm 0.0488(0.0476) | Total Time 14.00(14.00)\n",
      "Iter 2886 | Time 51.8605(52.4412) | Bit/dim 3.4889(3.4904) | Xent 0.0000(0.0000) | Loss 3.4889(3.4904) | Error 0.0000(0.0000) Steps 598(597.07) | Grad Norm 0.0518(0.0477) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 22.6839, Epoch Time 352.4063(352.5247), Bit/dim 3.4915(best: 3.4922), Xent 0.0000, Loss 3.4915, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2887 | Time 54.0289(52.4888) | Bit/dim 3.4997(3.4907) | Xent 0.0000(0.0000) | Loss 3.4997(3.4907) | Error 0.0000(0.0000) Steps 598(597.09) | Grad Norm 0.0477(0.0477) | Total Time 14.00(14.00)\n",
      "Iter 2888 | Time 50.7061(52.4353) | Bit/dim 3.4863(3.4905) | Xent 0.0000(0.0000) | Loss 3.4863(3.4905) | Error 0.0000(0.0000) Steps 598(597.12) | Grad Norm 0.0435(0.0476) | Total Time 14.00(14.00)\n",
      "Iter 2889 | Time 54.2291(52.4891) | Bit/dim 3.4880(3.4905) | Xent 0.0000(0.0000) | Loss 3.4880(3.4905) | Error 0.0000(0.0000) Steps 604(597.33) | Grad Norm 0.0518(0.0477) | Total Time 14.00(14.00)\n",
      "Iter 2890 | Time 54.1140(52.5379) | Bit/dim 3.4925(3.4905) | Xent 0.0000(0.0000) | Loss 3.4925(3.4905) | Error 0.0000(0.0000) Steps 598(597.35) | Grad Norm 0.0394(0.0475) | Total Time 14.00(14.00)\n",
      "Iter 2891 | Time 55.4204(52.6244) | Bit/dim 3.4901(3.4905) | Xent 0.0000(0.0000) | Loss 3.4901(3.4905) | Error 0.0000(0.0000) Steps 598(597.37) | Grad Norm 0.0450(0.0474) | Total Time 14.00(14.00)\n",
      "Iter 2892 | Time 53.5254(52.6514) | Bit/dim 3.4894(3.4905) | Xent 0.0000(0.0000) | Loss 3.4894(3.4905) | Error 0.0000(0.0000) Steps 604(597.57) | Grad Norm 0.0487(0.0475) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 22.9225, Epoch Time 360.8409(352.7741), Bit/dim 3.4932(best: 3.4915), Xent 0.0000, Loss 3.4932, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2893 | Time 51.6870(52.6225) | Bit/dim 3.5049(3.4909) | Xent 0.0000(0.0000) | Loss 3.5049(3.4909) | Error 0.0000(0.0000) Steps 598(597.58) | Grad Norm 0.0453(0.0474) | Total Time 14.00(14.00)\n",
      "Iter 2894 | Time 52.7101(52.6251) | Bit/dim 3.4990(3.4911) | Xent 0.0000(0.0000) | Loss 3.4990(3.4911) | Error 0.0000(0.0000) Steps 598(597.59) | Grad Norm 0.0406(0.0472) | Total Time 14.00(14.00)\n",
      "Iter 2895 | Time 51.3136(52.5857) | Bit/dim 3.4895(3.4911) | Xent 0.0000(0.0000) | Loss 3.4895(3.4911) | Error 0.0000(0.0000) Steps 598(597.60) | Grad Norm 0.0455(0.0471) | Total Time 14.00(14.00)\n",
      "Iter 2896 | Time 50.9245(52.5359) | Bit/dim 3.4831(3.4909) | Xent 0.0000(0.0000) | Loss 3.4831(3.4909) | Error 0.0000(0.0000) Steps 598(597.62) | Grad Norm 0.0405(0.0469) | Total Time 14.00(14.00)\n",
      "Iter 2897 | Time 53.4329(52.5628) | Bit/dim 3.4788(3.4905) | Xent 0.0000(0.0000) | Loss 3.4788(3.4905) | Error 0.0000(0.0000) Steps 604(597.81) | Grad Norm 0.0447(0.0469) | Total Time 14.00(14.00)\n",
      "Iter 2898 | Time 52.1398(52.5501) | Bit/dim 3.4824(3.4902) | Xent 0.0000(0.0000) | Loss 3.4824(3.4902) | Error 0.0000(0.0000) Steps 598(597.81) | Grad Norm 0.0416(0.0467) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 23.1102, Epoch Time 351.1789(352.7263), Bit/dim 3.4932(best: 3.4915), Xent 0.0000, Loss 3.4932, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2899 | Time 53.7913(52.5874) | Bit/dim 3.4984(3.4905) | Xent 0.0000(0.0000) | Loss 3.4984(3.4905) | Error 0.0000(0.0000) Steps 598(597.82) | Grad Norm 0.0503(0.0468) | Total Time 14.00(14.00)\n",
      "Iter 2900 | Time 51.8189(52.5643) | Bit/dim 3.4999(3.4908) | Xent 0.0000(0.0000) | Loss 3.4999(3.4908) | Error 0.0000(0.0000) Steps 586(597.46) | Grad Norm 0.0405(0.0466) | Total Time 14.00(14.00)\n",
      "Iter 2901 | Time 52.8509(52.5729) | Bit/dim 3.4867(3.4907) | Xent 0.0000(0.0000) | Loss 3.4867(3.4907) | Error 0.0000(0.0000) Steps 592(597.30) | Grad Norm 0.0450(0.0466) | Total Time 14.00(14.00)\n",
      "Iter 2902 | Time 51.3298(52.5356) | Bit/dim 3.4948(3.4908) | Xent 0.0000(0.0000) | Loss 3.4948(3.4908) | Error 0.0000(0.0000) Steps 598(597.32) | Grad Norm 0.0435(0.0465) | Total Time 14.00(14.00)\n",
      "Iter 2903 | Time 53.0468(52.5509) | Bit/dim 3.4837(3.4906) | Xent 0.0000(0.0000) | Loss 3.4837(3.4906) | Error 0.0000(0.0000) Steps 586(596.98) | Grad Norm 0.0441(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2904 | Time 50.4183(52.4870) | Bit/dim 3.4813(3.4903) | Xent 0.0000(0.0000) | Loss 3.4813(3.4903) | Error 0.0000(0.0000) Steps 598(597.01) | Grad Norm 0.0475(0.0464) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 23.1286, Epoch Time 352.2610(352.7123), Bit/dim 3.4924(best: 3.4915), Xent 0.0000, Loss 3.4924, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2905 | Time 53.1259(52.5061) | Bit/dim 3.4889(3.4902) | Xent 0.0000(0.0000) | Loss 3.4889(3.4902) | Error 0.0000(0.0000) Steps 598(597.04) | Grad Norm 0.0413(0.0463) | Total Time 14.00(14.00)\n",
      "Iter 2906 | Time 53.2677(52.5290) | Bit/dim 3.4932(3.4903) | Xent 0.0000(0.0000) | Loss 3.4932(3.4903) | Error 0.0000(0.0000) Steps 586(596.71) | Grad Norm 0.0493(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2907 | Time 54.2799(52.5815) | Bit/dim 3.4978(3.4906) | Xent 0.0000(0.0000) | Loss 3.4978(3.4906) | Error 0.0000(0.0000) Steps 598(596.75) | Grad Norm 0.0461(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2908 | Time 50.5060(52.5192) | Bit/dim 3.4856(3.4904) | Xent 0.0000(0.0000) | Loss 3.4856(3.4904) | Error 0.0000(0.0000) Steps 586(596.43) | Grad Norm 0.0486(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2909 | Time 54.0005(52.5637) | Bit/dim 3.4899(3.4904) | Xent 0.0000(0.0000) | Loss 3.4899(3.4904) | Error 0.0000(0.0000) Steps 598(596.47) | Grad Norm 0.0417(0.0463) | Total Time 14.00(14.00)\n",
      "Iter 2910 | Time 53.3829(52.5883) | Bit/dim 3.4848(3.4902) | Xent 0.0000(0.0000) | Loss 3.4848(3.4902) | Error 0.0000(0.0000) Steps 598(596.52) | Grad Norm 0.0456(0.0463) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 22.7978, Epoch Time 357.0273(352.8418), Bit/dim 3.4921(best: 3.4915), Xent 0.0000, Loss 3.4921, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2911 | Time 51.2638(52.5485) | Bit/dim 3.4925(3.4903) | Xent 0.0000(0.0000) | Loss 3.4925(3.4903) | Error 0.0000(0.0000) Steps 598(596.56) | Grad Norm 0.0525(0.0465) | Total Time 14.00(14.00)\n",
      "Iter 2912 | Time 53.6021(52.5801) | Bit/dim 3.4818(3.4900) | Xent 0.0000(0.0000) | Loss 3.4818(3.4900) | Error 0.0000(0.0000) Steps 598(596.61) | Grad Norm 0.0437(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2913 | Time 53.3378(52.6029) | Bit/dim 3.4913(3.4901) | Xent 0.0000(0.0000) | Loss 3.4913(3.4901) | Error 0.0000(0.0000) Steps 598(596.65) | Grad Norm 0.0381(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2914 | Time 53.1195(52.6184) | Bit/dim 3.4956(3.4902) | Xent 0.0000(0.0000) | Loss 3.4956(3.4902) | Error 0.0000(0.0000) Steps 598(596.69) | Grad Norm 0.0665(0.0467) | Total Time 14.00(14.00)\n",
      "Iter 2915 | Time 49.6519(52.5294) | Bit/dim 3.4886(3.4902) | Xent 0.0000(0.0000) | Loss 3.4886(3.4902) | Error 0.0000(0.0000) Steps 598(596.73) | Grad Norm 0.0524(0.0469) | Total Time 14.00(14.00)\n",
      "Iter 2916 | Time 55.1500(52.6080) | Bit/dim 3.4913(3.4902) | Xent 0.0000(0.0000) | Loss 3.4913(3.4902) | Error 0.0000(0.0000) Steps 598(596.77) | Grad Norm 0.0432(0.0468) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 22.8845, Epoch Time 354.8249(352.9013), Bit/dim 3.4926(best: 3.4915), Xent 0.0000, Loss 3.4926, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2917 | Time 52.9823(52.6192) | Bit/dim 3.4848(3.4901) | Xent 0.0000(0.0000) | Loss 3.4848(3.4901) | Error 0.0000(0.0000) Steps 586(596.44) | Grad Norm 0.0439(0.0467) | Total Time 14.00(14.00)\n",
      "Iter 2918 | Time 51.3576(52.5814) | Bit/dim 3.4900(3.4901) | Xent 0.0000(0.0000) | Loss 3.4900(3.4901) | Error 0.0000(0.0000) Steps 604(596.67) | Grad Norm 0.0432(0.0466) | Total Time 14.00(14.00)\n",
      "Iter 2919 | Time 53.1275(52.5978) | Bit/dim 3.4864(3.4900) | Xent 0.0000(0.0000) | Loss 3.4864(3.4900) | Error 0.0000(0.0000) Steps 598(596.71) | Grad Norm 0.0465(0.0466) | Total Time 14.00(14.00)\n",
      "Iter 2920 | Time 53.6187(52.6284) | Bit/dim 3.4965(3.4901) | Xent 0.0000(0.0000) | Loss 3.4965(3.4901) | Error 0.0000(0.0000) Steps 598(596.75) | Grad Norm 0.0395(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2921 | Time 52.7103(52.6308) | Bit/dim 3.4930(3.4902) | Xent 0.0000(0.0000) | Loss 3.4930(3.4902) | Error 0.0000(0.0000) Steps 598(596.79) | Grad Norm 0.0498(0.0465) | Total Time 14.00(14.00)\n",
      "Iter 2922 | Time 51.1300(52.5858) | Bit/dim 3.4901(3.4902) | Xent 0.0000(0.0000) | Loss 3.4901(3.4902) | Error 0.0000(0.0000) Steps 598(596.82) | Grad Norm 0.0438(0.0464) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 22.9393, Epoch Time 353.7005(352.9253), Bit/dim 3.4925(best: 3.4915), Xent 0.0000, Loss 3.4925, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2923 | Time 50.2205(52.5149) | Bit/dim 3.4866(3.4901) | Xent 0.0000(0.0000) | Loss 3.4866(3.4901) | Error 0.0000(0.0000) Steps 598(596.86) | Grad Norm 0.0452(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2924 | Time 52.6410(52.5186) | Bit/dim 3.4882(3.4901) | Xent 0.0000(0.0000) | Loss 3.4882(3.4901) | Error 0.0000(0.0000) Steps 598(596.89) | Grad Norm 0.0401(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2925 | Time 54.1597(52.5679) | Bit/dim 3.4962(3.4903) | Xent 0.0000(0.0000) | Loss 3.4962(3.4903) | Error 0.0000(0.0000) Steps 604(597.11) | Grad Norm 0.0468(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2926 | Time 53.3445(52.5912) | Bit/dim 3.4882(3.4902) | Xent 0.0000(0.0000) | Loss 3.4882(3.4902) | Error 0.0000(0.0000) Steps 598(597.13) | Grad Norm 0.0453(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2927 | Time 53.1684(52.6085) | Bit/dim 3.4926(3.4903) | Xent 0.0000(0.0000) | Loss 3.4926(3.4903) | Error 0.0000(0.0000) Steps 598(597.16) | Grad Norm 0.0495(0.0463) | Total Time 14.00(14.00)\n",
      "Iter 2928 | Time 50.7550(52.5529) | Bit/dim 3.4893(3.4902) | Xent 0.0000(0.0000) | Loss 3.4893(3.4902) | Error 0.0000(0.0000) Steps 598(597.18) | Grad Norm 0.0406(0.0461) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 22.8903, Epoch Time 352.6704(352.9176), Bit/dim 3.4929(best: 3.4915), Xent 0.0000, Loss 3.4929, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2929 | Time 49.9286(52.4742) | Bit/dim 3.4956(3.4904) | Xent 0.0000(0.0000) | Loss 3.4956(3.4904) | Error 0.0000(0.0000) Steps 598(597.21) | Grad Norm 0.0358(0.0458) | Total Time 14.00(14.00)\n",
      "Iter 2930 | Time 54.5779(52.5373) | Bit/dim 3.4922(3.4904) | Xent 0.0000(0.0000) | Loss 3.4922(3.4904) | Error 0.0000(0.0000) Steps 598(597.23) | Grad Norm 0.0399(0.0456) | Total Time 14.00(14.00)\n",
      "Iter 2931 | Time 51.0225(52.4918) | Bit/dim 3.4849(3.4903) | Xent 0.0000(0.0000) | Loss 3.4849(3.4903) | Error 0.0000(0.0000) Steps 598(597.26) | Grad Norm 0.0446(0.0456) | Total Time 14.00(14.00)\n",
      "Iter 2932 | Time 52.8344(52.5021) | Bit/dim 3.4876(3.4902) | Xent 0.0000(0.0000) | Loss 3.4876(3.4902) | Error 0.0000(0.0000) Steps 598(597.28) | Grad Norm 0.0455(0.0456) | Total Time 14.00(14.00)\n",
      "Iter 2933 | Time 52.0256(52.4878) | Bit/dim 3.4893(3.4902) | Xent 0.0000(0.0000) | Loss 3.4893(3.4902) | Error 0.0000(0.0000) Steps 598(597.30) | Grad Norm 0.0473(0.0456) | Total Time 14.00(14.00)\n",
      "Iter 2934 | Time 50.0689(52.4152) | Bit/dim 3.4886(3.4901) | Xent 0.0000(0.0000) | Loss 3.4886(3.4901) | Error 0.0000(0.0000) Steps 598(597.32) | Grad Norm 0.0473(0.0457) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0489 | Time 22.7616, Epoch Time 349.0324(352.8011), Bit/dim 3.4923(best: 3.4915), Xent 0.0000, Loss 3.4923, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2935 | Time 52.3109(52.4121) | Bit/dim 3.4971(3.4903) | Xent 0.0000(0.0000) | Loss 3.4971(3.4903) | Error 0.0000(0.0000) Steps 598(597.34) | Grad Norm 0.0444(0.0457) | Total Time 14.00(14.00)\n",
      "Iter 2936 | Time 54.0360(52.4608) | Bit/dim 3.4966(3.4905) | Xent 0.0000(0.0000) | Loss 3.4966(3.4905) | Error 0.0000(0.0000) Steps 604(597.54) | Grad Norm 0.0454(0.0456) | Total Time 14.00(14.00)\n",
      "Iter 2937 | Time 51.7851(52.4406) | Bit/dim 3.4780(3.4902) | Xent 0.0000(0.0000) | Loss 3.4780(3.4902) | Error 0.0000(0.0000) Steps 586(597.19) | Grad Norm 0.0539(0.0459) | Total Time 14.00(14.00)\n",
      "Iter 2938 | Time 54.5459(52.5037) | Bit/dim 3.4911(3.4902) | Xent 0.0000(0.0000) | Loss 3.4911(3.4902) | Error 0.0000(0.0000) Steps 598(597.22) | Grad Norm 0.0480(0.0460) | Total Time 14.00(14.00)\n",
      "Iter 2939 | Time 52.4352(52.5017) | Bit/dim 3.4904(3.4902) | Xent 0.0000(0.0000) | Loss 3.4904(3.4902) | Error 0.0000(0.0000) Steps 598(597.24) | Grad Norm 0.0530(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2940 | Time 53.8764(52.5429) | Bit/dim 3.4900(3.4902) | Xent 0.0000(0.0000) | Loss 3.4900(3.4902) | Error 0.0000(0.0000) Steps 598(597.26) | Grad Norm 0.0437(0.0461) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0490 | Time 23.1955, Epoch Time 358.2034(352.9631), Bit/dim 3.4927(best: 3.4915), Xent 0.0000, Loss 3.4927, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2941 | Time 51.7892(52.5203) | Bit/dim 3.4986(3.4904) | Xent 0.0000(0.0000) | Loss 3.4986(3.4904) | Error 0.0000(0.0000) Steps 586(596.93) | Grad Norm 0.0492(0.0462) | Total Time 14.00(14.00)\n",
      "Iter 2942 | Time 51.1813(52.4801) | Bit/dim 3.4919(3.4905) | Xent 0.0000(0.0000) | Loss 3.4919(3.4905) | Error 0.0000(0.0000) Steps 598(596.96) | Grad Norm 0.0434(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2943 | Time 51.4880(52.4504) | Bit/dim 3.4911(3.4905) | Xent 0.0000(0.0000) | Loss 3.4911(3.4905) | Error 0.0000(0.0000) Steps 598(596.99) | Grad Norm 0.0448(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2944 | Time 52.4295(52.4497) | Bit/dim 3.4954(3.4906) | Xent 0.0000(0.0000) | Loss 3.4954(3.4906) | Error 0.0000(0.0000) Steps 598(597.02) | Grad Norm 0.0446(0.0460) | Total Time 14.00(14.00)\n",
      "Iter 2945 | Time 52.4834(52.4507) | Bit/dim 3.4848(3.4905) | Xent 0.0000(0.0000) | Loss 3.4848(3.4905) | Error 0.0000(0.0000) Steps 604(597.23) | Grad Norm 0.0464(0.0460) | Total Time 14.00(14.00)\n",
      "Iter 2946 | Time 51.4583(52.4210) | Bit/dim 3.4819(3.4902) | Xent 0.0000(0.0000) | Loss 3.4819(3.4902) | Error 0.0000(0.0000) Steps 598(597.25) | Grad Norm 0.0519(0.0462) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0491 | Time 22.8591, Epoch Time 349.8792(352.8706), Bit/dim 3.4931(best: 3.4915), Xent 0.0000, Loss 3.4931, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2947 | Time 53.1523(52.4429) | Bit/dim 3.4939(3.4903) | Xent 0.0000(0.0000) | Loss 3.4939(3.4903) | Error 0.0000(0.0000) Steps 598(597.28) | Grad Norm 0.0402(0.0460) | Total Time 14.00(14.00)\n",
      "Iter 2948 | Time 51.1491(52.4041) | Bit/dim 3.4914(3.4904) | Xent 0.0000(0.0000) | Loss 3.4914(3.4904) | Error 0.0000(0.0000) Steps 598(597.30) | Grad Norm 0.0400(0.0458) | Total Time 14.00(14.00)\n",
      "Iter 2949 | Time 50.1400(52.3362) | Bit/dim 3.4892(3.4903) | Xent 0.0000(0.0000) | Loss 3.4892(3.4903) | Error 0.0000(0.0000) Steps 598(597.32) | Grad Norm 0.0421(0.0457) | Total Time 14.00(14.00)\n",
      "Iter 2950 | Time 52.5417(52.3423) | Bit/dim 3.4891(3.4903) | Xent 0.0000(0.0000) | Loss 3.4891(3.4903) | Error 0.0000(0.0000) Steps 598(597.34) | Grad Norm 0.0466(0.0458) | Total Time 14.00(14.00)\n",
      "Iter 2951 | Time 54.6165(52.4106) | Bit/dim 3.4931(3.4904) | Xent 0.0000(0.0000) | Loss 3.4931(3.4904) | Error 0.0000(0.0000) Steps 604(597.54) | Grad Norm 0.0434(0.0457) | Total Time 14.00(14.00)\n",
      "Iter 2952 | Time 50.2466(52.3456) | Bit/dim 3.4840(3.4902) | Xent 0.0000(0.0000) | Loss 3.4840(3.4902) | Error 0.0000(0.0000) Steps 598(597.55) | Grad Norm 0.0433(0.0456) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0492 | Time 23.0676, Epoch Time 350.5609(352.8013), Bit/dim 3.4927(best: 3.4915), Xent 0.0000, Loss 3.4927, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2953 | Time 51.4016(52.3173) | Bit/dim 3.4873(3.4901) | Xent 0.0000(0.0000) | Loss 3.4873(3.4901) | Error 0.0000(0.0000) Steps 604(597.75) | Grad Norm 0.0423(0.0455) | Total Time 14.00(14.00)\n",
      "Iter 2954 | Time 51.2612(52.2856) | Bit/dim 3.4863(3.4900) | Xent 0.0000(0.0000) | Loss 3.4863(3.4900) | Error 0.0000(0.0000) Steps 598(597.75) | Grad Norm 0.0416(0.0454) | Total Time 14.00(14.00)\n",
      "Iter 2955 | Time 54.9492(52.3655) | Bit/dim 3.4840(3.4898) | Xent 0.0000(0.0000) | Loss 3.4840(3.4898) | Error 0.0000(0.0000) Steps 604(597.94) | Grad Norm 0.0449(0.0454) | Total Time 14.00(14.00)\n",
      "Iter 2956 | Time 53.4896(52.3993) | Bit/dim 3.5032(3.4902) | Xent 0.0000(0.0000) | Loss 3.5032(3.4902) | Error 0.0000(0.0000) Steps 598(597.94) | Grad Norm 0.0405(0.0452) | Total Time 14.00(14.00)\n",
      "Iter 2957 | Time 49.8405(52.3225) | Bit/dim 3.4873(3.4901) | Xent 0.0000(0.0000) | Loss 3.4873(3.4901) | Error 0.0000(0.0000) Steps 598(597.94) | Grad Norm 0.0491(0.0454) | Total Time 14.00(14.00)\n",
      "Iter 2958 | Time 52.4768(52.3271) | Bit/dim 3.4886(3.4901) | Xent 0.0000(0.0000) | Loss 3.4886(3.4901) | Error 0.0000(0.0000) Steps 598(597.95) | Grad Norm 0.0385(0.0451) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0493 | Time 22.9912, Epoch Time 353.2585(352.8150), Bit/dim 3.4921(best: 3.4915), Xent 0.0000, Loss 3.4921, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2959 | Time 53.2975(52.3562) | Bit/dim 3.4847(3.4899) | Xent 0.0000(0.0000) | Loss 3.4847(3.4899) | Error 0.0000(0.0000) Steps 586(597.59) | Grad Norm 0.0492(0.0453) | Total Time 14.00(14.00)\n",
      "Iter 2960 | Time 54.2491(52.4130) | Bit/dim 3.4825(3.4897) | Xent 0.0000(0.0000) | Loss 3.4825(3.4897) | Error 0.0000(0.0000) Steps 598(597.60) | Grad Norm 0.0473(0.0453) | Total Time 14.00(14.00)\n",
      "Iter 2961 | Time 50.7014(52.3617) | Bit/dim 3.4863(3.4896) | Xent 0.0000(0.0000) | Loss 3.4863(3.4896) | Error 0.0000(0.0000) Steps 604(597.79) | Grad Norm 0.0497(0.0455) | Total Time 14.00(14.00)\n",
      "Iter 2962 | Time 51.7051(52.3420) | Bit/dim 3.4932(3.4897) | Xent 0.0000(0.0000) | Loss 3.4932(3.4897) | Error 0.0000(0.0000) Steps 598(597.80) | Grad Norm 0.0439(0.0454) | Total Time 14.00(14.00)\n",
      "Iter 2963 | Time 50.4742(52.2859) | Bit/dim 3.4940(3.4898) | Xent 0.0000(0.0000) | Loss 3.4940(3.4898) | Error 0.0000(0.0000) Steps 598(597.80) | Grad Norm 0.0633(0.0459) | Total Time 14.00(14.00)\n",
      "Iter 2964 | Time 54.5222(52.3530) | Bit/dim 3.5004(3.4901) | Xent 0.0000(0.0000) | Loss 3.5004(3.4901) | Error 0.0000(0.0000) Steps 598(597.81) | Grad Norm 0.0499(0.0461) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0494 | Time 22.8249, Epoch Time 353.4362(352.8337), Bit/dim 3.4917(best: 3.4915), Xent 0.0000, Loss 3.4917, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2965 | Time 53.6382(52.3916) | Bit/dim 3.4880(3.4901) | Xent 0.0000(0.0000) | Loss 3.4880(3.4901) | Error 0.0000(0.0000) Steps 598(597.82) | Grad Norm 0.0389(0.0459) | Total Time 14.00(14.00)\n",
      "Iter 2966 | Time 52.8310(52.4048) | Bit/dim 3.4897(3.4901) | Xent 0.0000(0.0000) | Loss 3.4897(3.4901) | Error 0.0000(0.0000) Steps 598(597.82) | Grad Norm 0.0444(0.0458) | Total Time 14.00(14.00)\n",
      "Iter 2967 | Time 50.8450(52.3580) | Bit/dim 3.4837(3.4899) | Xent 0.0000(0.0000) | Loss 3.4837(3.4899) | Error 0.0000(0.0000) Steps 598(597.83) | Grad Norm 0.0480(0.0459) | Total Time 14.00(14.00)\n",
      "Iter 2968 | Time 54.2277(52.4141) | Bit/dim 3.4777(3.4895) | Xent 0.0000(0.0000) | Loss 3.4777(3.4895) | Error 0.0000(0.0000) Steps 604(598.01) | Grad Norm 0.0445(0.0458) | Total Time 14.00(14.00)\n",
      "Iter 2969 | Time 51.7286(52.3935) | Bit/dim 3.5063(3.4900) | Xent 0.0000(0.0000) | Loss 3.5063(3.4900) | Error 0.0000(0.0000) Steps 604(598.19) | Grad Norm 0.0433(0.0458) | Total Time 14.00(14.00)\n",
      "Iter 2970 | Time 54.3518(52.4523) | Bit/dim 3.4934(3.4901) | Xent 0.0000(0.0000) | Loss 3.4934(3.4901) | Error 0.0000(0.0000) Steps 598(598.19) | Grad Norm 0.0422(0.0456) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0495 | Time 23.0294, Epoch Time 356.1902(352.9344), Bit/dim 3.4920(best: 3.4915), Xent 0.0000, Loss 3.4920, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2971 | Time 49.6140(52.3671) | Bit/dim 3.4891(3.4901) | Xent 0.0000(0.0000) | Loss 3.4891(3.4901) | Error 0.0000(0.0000) Steps 598(598.18) | Grad Norm 0.0440(0.0456) | Total Time 14.00(14.00)\n",
      "Iter 2972 | Time 51.4384(52.3392) | Bit/dim 3.4935(3.4902) | Xent 0.0000(0.0000) | Loss 3.4935(3.4902) | Error 0.0000(0.0000) Steps 604(598.35) | Grad Norm 0.0351(0.0453) | Total Time 14.00(14.00)\n",
      "Iter 2973 | Time 50.5305(52.2850) | Bit/dim 3.4897(3.4902) | Xent 0.0000(0.0000) | Loss 3.4897(3.4902) | Error 0.0000(0.0000) Steps 598(598.34) | Grad Norm 0.0418(0.0452) | Total Time 14.00(14.00)\n",
      "Iter 2974 | Time 53.2903(52.3151) | Bit/dim 3.4990(3.4904) | Xent 0.0000(0.0000) | Loss 3.4990(3.4904) | Error 0.0000(0.0000) Steps 598(598.33) | Grad Norm 0.0500(0.0453) | Total Time 14.00(14.00)\n",
      "Iter 2975 | Time 54.5521(52.3823) | Bit/dim 3.4896(3.4904) | Xent 0.0000(0.0000) | Loss 3.4896(3.4904) | Error 0.0000(0.0000) Steps 598(598.32) | Grad Norm 0.0442(0.0453) | Total Time 14.00(14.00)\n",
      "Iter 2976 | Time 53.0475(52.4022) | Bit/dim 3.4801(3.4901) | Xent 0.0000(0.0000) | Loss 3.4801(3.4901) | Error 0.0000(0.0000) Steps 598(598.31) | Grad Norm 0.0422(0.0452) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0496 | Time 22.9559, Epoch Time 351.1549(352.8810), Bit/dim 3.4924(best: 3.4915), Xent 0.0000, Loss 3.4924, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2977 | Time 51.8272(52.3850) | Bit/dim 3.4994(3.4904) | Xent 0.0000(0.0000) | Loss 3.4994(3.4904) | Error 0.0000(0.0000) Steps 598(598.30) | Grad Norm 0.0387(0.0450) | Total Time 14.00(14.00)\n",
      "Iter 2978 | Time 52.5602(52.3902) | Bit/dim 3.4810(3.4901) | Xent 0.0000(0.0000) | Loss 3.4810(3.4901) | Error 0.0000(0.0000) Steps 598(598.30) | Grad Norm 0.0535(0.0453) | Total Time 14.00(14.00)\n",
      "Iter 2979 | Time 53.8658(52.4345) | Bit/dim 3.5053(3.4906) | Xent 0.0000(0.0000) | Loss 3.5053(3.4906) | Error 0.0000(0.0000) Steps 610(598.65) | Grad Norm 0.0569(0.0456) | Total Time 14.00(14.00)\n",
      "Iter 2980 | Time 52.7445(52.4438) | Bit/dim 3.4843(3.4904) | Xent 0.0000(0.0000) | Loss 3.4843(3.4904) | Error 0.0000(0.0000) Steps 598(598.63) | Grad Norm 0.0454(0.0456) | Total Time 14.00(14.00)\n",
      "Iter 2981 | Time 53.2601(52.4683) | Bit/dim 3.4786(3.4900) | Xent 0.0000(0.0000) | Loss 3.4786(3.4900) | Error 0.0000(0.0000) Steps 598(598.61) | Grad Norm 0.0497(0.0457) | Total Time 14.00(14.00)\n",
      "Iter 2982 | Time 51.8997(52.4512) | Bit/dim 3.4985(3.4903) | Xent 0.0000(0.0000) | Loss 3.4985(3.4903) | Error 0.0000(0.0000) Steps 598(598.59) | Grad Norm 0.0558(0.0460) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0497 | Time 22.6665, Epoch Time 354.9867(352.9441), Bit/dim 3.4924(best: 3.4915), Xent 0.0000, Loss 3.4924, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2983 | Time 51.0525(52.4093) | Bit/dim 3.4817(3.4900) | Xent 0.0000(0.0000) | Loss 3.4817(3.4900) | Error 0.0000(0.0000) Steps 598(598.57) | Grad Norm 0.0501(0.0461) | Total Time 14.00(14.00)\n",
      "Iter 2984 | Time 52.2904(52.4057) | Bit/dim 3.4993(3.4903) | Xent 0.0000(0.0000) | Loss 3.4993(3.4903) | Error 0.0000(0.0000) Steps 598(598.56) | Grad Norm 0.0588(0.0465) | Total Time 14.00(14.00)\n",
      "Iter 2985 | Time 52.6431(52.4128) | Bit/dim 3.4873(3.4902) | Xent 0.0000(0.0000) | Loss 3.4873(3.4902) | Error 0.0000(0.0000) Steps 598(598.54) | Grad Norm 0.0421(0.0464) | Total Time 14.00(14.00)\n",
      "Iter 2986 | Time 53.2800(52.4388) | Bit/dim 3.4928(3.4903) | Xent 0.0000(0.0000) | Loss 3.4928(3.4903) | Error 0.0000(0.0000) Steps 598(598.52) | Grad Norm 0.0483(0.0465) | Total Time 14.00(14.00)\n",
      "Iter 2987 | Time 50.4022(52.3777) | Bit/dim 3.4914(3.4903) | Xent 0.0000(0.0000) | Loss 3.4914(3.4903) | Error 0.0000(0.0000) Steps 598(598.51) | Grad Norm 0.0493(0.0465) | Total Time 14.00(14.00)\n",
      "Iter 2988 | Time 53.2743(52.4046) | Bit/dim 3.4886(3.4903) | Xent 0.0000(0.0000) | Loss 3.4886(3.4903) | Error 0.0000(0.0000) Steps 598(598.49) | Grad Norm 0.0611(0.0470) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0498 | Time 22.6374, Epoch Time 351.2567(352.8935), Bit/dim 3.4926(best: 3.4915), Xent 0.0000, Loss 3.4926, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2989 | Time 54.9306(52.4804) | Bit/dim 3.4950(3.4904) | Xent 0.0000(0.0000) | Loss 3.4950(3.4904) | Error 0.0000(0.0000) Steps 598(598.48) | Grad Norm 0.0385(0.0467) | Total Time 14.00(14.00)\n",
      "Iter 2990 | Time 54.8077(52.5502) | Bit/dim 3.4842(3.4902) | Xent 0.0000(0.0000) | Loss 3.4842(3.4902) | Error 0.0000(0.0000) Steps 598(598.46) | Grad Norm 0.0514(0.0469) | Total Time 14.00(14.00)\n",
      "Iter 2991 | Time 53.0024(52.5638) | Bit/dim 3.4938(3.4903) | Xent 0.0000(0.0000) | Loss 3.4938(3.4903) | Error 0.0000(0.0000) Steps 598(598.45) | Grad Norm 0.0487(0.0469) | Total Time 14.00(14.00)\n",
      "Iter 2992 | Time 54.6921(52.6276) | Bit/dim 3.4917(3.4904) | Xent 0.0000(0.0000) | Loss 3.4917(3.4904) | Error 0.0000(0.0000) Steps 598(598.44) | Grad Norm 0.0506(0.0470) | Total Time 14.00(14.00)\n",
      "Iter 2993 | Time 52.5235(52.6245) | Bit/dim 3.4890(3.4903) | Xent 0.0000(0.0000) | Loss 3.4890(3.4903) | Error 0.0000(0.0000) Steps 598(598.42) | Grad Norm 0.0454(0.0470) | Total Time 14.00(14.00)\n",
      "Iter 2994 | Time 53.9905(52.6655) | Bit/dim 3.4845(3.4901) | Xent 0.0000(0.0000) | Loss 3.4845(3.4901) | Error 0.0000(0.0000) Steps 604(598.59) | Grad Norm 0.0445(0.0469) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0499 | Time 22.9622, Epoch Time 362.5010(353.1817), Bit/dim 3.4923(best: 3.4915), Xent 0.0000, Loss 3.4923, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2997 | Time 53.0010(52.5830) | Bit/dim 3.4961(3.4902) | Xent 0.0000(0.0000) | Loss 3.4961(3.4902) | Error 0.0000(0.0000) Steps 598(598.71) | Grad Norm 0.0454(0.0470) | Total Time 14.00(14.00)\n",
      "Iter 2998 | Time 52.3446(52.5758) | Bit/dim 3.4892(3.4902) | Xent 0.0000(0.0000) | Loss 3.4892(3.4902) | Error 0.0000(0.0000) Steps 598(598.69) | Grad Norm 0.0409(0.0469) | Total Time 14.00(14.00)\n",
      "Iter 2999 | Time 53.1686(52.5936) | Bit/dim 3.4931(3.4903) | Xent 0.0000(0.0000) | Loss 3.4931(3.4903) | Error 0.0000(0.0000) Steps 598(598.67) | Grad Norm 0.0586(0.0472) | Total Time 14.00(14.00)\n",
      "Iter 3000 | Time 50.0314(52.5168) | Bit/dim 3.4892(3.4902) | Xent 0.0000(0.0000) | Loss 3.4892(3.4902) | Error 0.0000(0.0000) Steps 598(598.65) | Grad Norm 0.0582(0.0475) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0500 | Time 22.7985, Epoch Time 348.9017(353.0533), Bit/dim 3.4921(best: 3.4915), Xent 0.0000, Loss 3.4921, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3001 | Time 54.1787(52.5666) | Bit/dim 3.4956(3.4904) | Xent 0.0000(0.0000) | Loss 3.4956(3.4904) | Error 0.0000(0.0000) Steps 598(598.63) | Grad Norm 0.0420(0.0474) | Total Time 14.00(14.00)\n",
      "Iter 3002 | Time 51.5994(52.5376) | Bit/dim 3.4873(3.4903) | Xent 0.0000(0.0000) | Loss 3.4873(3.4903) | Error 0.0000(0.0000) Steps 598(598.61) | Grad Norm 0.0402(0.0472) | Total Time 14.00(14.00)\n",
      "Iter 3003 | Time 51.0168(52.4920) | Bit/dim 3.4938(3.4904) | Xent 0.0000(0.0000) | Loss 3.4938(3.4904) | Error 0.0000(0.0000) Steps 598(598.59) | Grad Norm 0.0525(0.0473) | Total Time 14.00(14.00)\n",
      "Iter 3004 | Time 50.3463(52.4276) | Bit/dim 3.5005(3.4907) | Xent 0.0000(0.0000) | Loss 3.5005(3.4907) | Error 0.0000(0.0000) Steps 598(598.58) | Grad Norm 0.0524(0.0475) | Total Time 14.00(14.00)\n",
      "Iter 3005 | Time 53.4258(52.4576) | Bit/dim 3.4780(3.4903) | Xent 0.0000(0.0000) | Loss 3.4780(3.4903) | Error 0.0000(0.0000) Steps 586(598.20) | Grad Norm 0.0462(0.0474) | Total Time 14.00(14.00)\n",
      "Iter 3006 | Time 52.6017(52.4619) | Bit/dim 3.4844(3.4901) | Xent 0.0000(0.0000) | Loss 3.4844(3.4901) | Error 0.0000(0.0000) Steps 598(598.19) | Grad Norm 0.0422(0.0473) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0501 | Time 22.7352, Epoch Time 351.6728(353.0119), Bit/dim 3.4913(best: 3.4915), Xent 0.0000, Loss 3.4913, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3007 | Time 51.8303(52.4429) | Bit/dim 3.4851(3.4900) | Xent 0.0000(0.0000) | Loss 3.4851(3.4900) | Error 0.0000(0.0000) Steps 598(598.19) | Grad Norm 0.0513(0.0474) | Total Time 14.00(14.00)\n",
      "Iter 3008 | Time 54.4887(52.5043) | Bit/dim 3.4989(3.4903) | Xent 0.0000(0.0000) | Loss 3.4989(3.4903) | Error 0.0000(0.0000) Steps 598(598.18) | Grad Norm 0.0500(0.0475) | Total Time 14.00(14.00)\n",
      "Iter 3009 | Time 49.2532(52.4068) | Bit/dim 3.4967(3.4905) | Xent 0.0000(0.0000) | Loss 3.4967(3.4905) | Error 0.0000(0.0000) Steps 598(598.18) | Grad Norm 0.0480(0.0475) | Total Time 14.00(14.00)\n",
      "Iter 3010 | Time 52.9334(52.4226) | Bit/dim 3.4831(3.4902) | Xent 0.0000(0.0000) | Loss 3.4831(3.4902) | Error 0.0000(0.0000) Steps 604(598.35) | Grad Norm 0.0448(0.0474) | Total Time 14.00(14.00)\n",
      "Iter 3011 | Time 52.3756(52.4212) | Bit/dim 3.4894(3.4902) | Xent 0.0000(0.0000) | Loss 3.4894(3.4902) | Error 0.0000(0.0000) Steps 598(598.34) | Grad Norm 0.0505(0.0475) | Total Time 14.00(14.00)\n",
      "Iter 3012 | Time 55.9132(52.5259) | Bit/dim 3.4840(3.4900) | Xent 0.0000(0.0000) | Loss 3.4840(3.4900) | Error 0.0000(0.0000) Steps 604(598.51) | Grad Norm 0.0520(0.0476) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0502 | Time 22.7254, Epoch Time 354.9496(353.0701), Bit/dim 3.4915(best: 3.4913), Xent 0.0000, Loss 3.4915, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3013 | Time 50.6139(52.4686) | Bit/dim 3.4834(3.4898) | Xent 0.0000(0.0000) | Loss 3.4834(3.4898) | Error 0.0000(0.0000) Steps 598(598.49) | Grad Norm 0.0432(0.0475) | Total Time 14.00(14.00)\n",
      "Iter 3014 | Time 53.0720(52.4867) | Bit/dim 3.5020(3.4902) | Xent 0.0000(0.0000) | Loss 3.5020(3.4902) | Error 0.0000(0.0000) Steps 598(598.48) | Grad Norm 0.0487(0.0475) | Total Time 14.00(14.00)\n",
      "Iter 3015 | Time 50.2043(52.4182) | Bit/dim 3.4919(3.4902) | Xent 0.0000(0.0000) | Loss 3.4919(3.4902) | Error 0.0000(0.0000) Steps 598(598.47) | Grad Norm 0.0456(0.0475) | Total Time 14.00(14.00)\n",
      "Iter 3016 | Time 52.2739(52.4139) | Bit/dim 3.4832(3.4900) | Xent 0.0000(0.0000) | Loss 3.4832(3.4900) | Error 0.0000(0.0000) Steps 598(598.45) | Grad Norm 0.0423(0.0473) | Total Time 14.00(14.00)\n",
      "Iter 3017 | Time 53.7099(52.4527) | Bit/dim 3.4845(3.4899) | Xent 0.0000(0.0000) | Loss 3.4845(3.4899) | Error 0.0000(0.0000) Steps 598(598.44) | Grad Norm 0.0429(0.0472) | Total Time 14.00(14.00)\n",
      "Iter 3018 | Time 52.2078(52.4454) | Bit/dim 3.4952(3.4900) | Xent 0.0000(0.0000) | Loss 3.4952(3.4900) | Error 0.0000(0.0000) Steps 598(598.42) | Grad Norm 0.0451(0.0471) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0503 | Time 22.7963, Epoch Time 350.4532(352.9916), Bit/dim 3.4917(best: 3.4913), Xent 0.0000, Loss 3.4917, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3019 | Time 51.9516(52.4306) | Bit/dim 3.4856(3.4899) | Xent 0.0000(0.0000) | Loss 3.4856(3.4899) | Error 0.0000(0.0000) Steps 598(598.41) | Grad Norm 0.0515(0.0473) | Total Time 14.00(14.00)\n",
      "Iter 3020 | Time 50.9798(52.3871) | Bit/dim 3.4814(3.4896) | Xent 0.0000(0.0000) | Loss 3.4814(3.4896) | Error 0.0000(0.0000) Steps 598(598.40) | Grad Norm 0.0478(0.0473) | Total Time 14.00(14.00)\n",
      "Iter 3021 | Time 52.7762(52.3987) | Bit/dim 3.4833(3.4894) | Xent 0.0000(0.0000) | Loss 3.4833(3.4894) | Error 0.0000(0.0000) Steps 598(598.39) | Grad Norm 0.0511(0.0474) | Total Time 14.00(14.00)\n",
      "Iter 3022 | Time 51.4525(52.3703) | Bit/dim 3.4961(3.4896) | Xent 0.0000(0.0000) | Loss 3.4961(3.4896) | Error 0.0000(0.0000) Steps 598(598.38) | Grad Norm 0.0465(0.0474) | Total Time 14.00(14.00)\n",
      "Iter 3023 | Time 50.1420(52.3035) | Bit/dim 3.4873(3.4896) | Xent 0.0000(0.0000) | Loss 3.4873(3.4896) | Error 0.0000(0.0000) Steps 598(598.36) | Grad Norm 0.0497(0.0474) | Total Time 14.00(14.00)\n",
      "Iter 3024 | Time 52.4736(52.3086) | Bit/dim 3.5001(3.4899) | Xent 0.0000(0.0000) | Loss 3.5001(3.4899) | Error 0.0000(0.0000) Steps 604(598.53) | Grad Norm 0.0491(0.0475) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0504 | Time 23.0397, Epoch Time 348.4990(352.8568), Bit/dim 3.4915(best: 3.4913), Xent 0.0000, Loss 3.4915, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3025 | Time 52.0152(52.2998) | Bit/dim 3.4861(3.4898) | Xent 0.0000(0.0000) | Loss 3.4861(3.4898) | Error 0.0000(0.0000) Steps 604(598.70) | Grad Norm 0.0508(0.0476) | Total Time 14.00(14.00)\n",
      "Iter 3026 | Time 53.4977(52.3357) | Bit/dim 3.4952(3.4899) | Xent 0.0000(0.0000) | Loss 3.4952(3.4899) | Error 0.0000(0.0000) Steps 598(598.68) | Grad Norm 0.0518(0.0477) | Total Time 14.00(14.00)\n",
      "Iter 3027 | Time 51.2421(52.3029) | Bit/dim 3.4753(3.4895) | Xent 0.0000(0.0000) | Loss 3.4753(3.4895) | Error 0.0000(0.0000) Steps 598(598.66) | Grad Norm 0.0527(0.0479) | Total Time 14.00(14.00)\n",
      "Iter 3028 | Time 54.4915(52.3686) | Bit/dim 3.4920(3.4896) | Xent 0.0000(0.0000) | Loss 3.4920(3.4896) | Error 0.0000(0.0000) Steps 598(598.64) | Grad Norm 0.0502(0.0479) | Total Time 14.00(14.00)\n",
      "Iter 3029 | Time 51.7142(52.3489) | Bit/dim 3.4907(3.4896) | Xent 0.0000(0.0000) | Loss 3.4907(3.4896) | Error 0.0000(0.0000) Steps 598(598.62) | Grad Norm 0.0565(0.0482) | Total Time 14.00(14.00)\n",
      "Iter 3030 | Time 52.2571(52.3462) | Bit/dim 3.4961(3.4898) | Xent 0.0000(0.0000) | Loss 3.4961(3.4898) | Error 0.0000(0.0000) Steps 598(598.60) | Grad Norm 0.0587(0.0485) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0505 | Time 22.9631, Epoch Time 353.8581(352.8868), Bit/dim 3.4918(best: 3.4913), Xent 0.0000, Loss 3.4918, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3031 | Time 50.9446(52.3041) | Bit/dim 3.4891(3.4898) | Xent 0.0000(0.0000) | Loss 3.4891(3.4898) | Error 0.0000(0.0000) Steps 598(598.58) | Grad Norm 0.0462(0.0484) | Total Time 14.00(14.00)\n",
      "Iter 3032 | Time 50.7190(52.2566) | Bit/dim 3.4945(3.4899) | Xent 0.0000(0.0000) | Loss 3.4945(3.4899) | Error 0.0000(0.0000) Steps 598(598.56) | Grad Norm 0.0465(0.0484) | Total Time 14.00(14.00)\n",
      "Iter 3033 | Time 53.7740(52.3021) | Bit/dim 3.4881(3.4899) | Xent 0.0000(0.0000) | Loss 3.4881(3.4899) | Error 0.0000(0.0000) Steps 598(598.55) | Grad Norm 0.0623(0.0488) | Total Time 14.00(14.00)\n",
      "Iter 3034 | Time 50.6043(52.2512) | Bit/dim 3.4902(3.4899) | Xent 0.0000(0.0000) | Loss 3.4902(3.4899) | Error 0.0000(0.0000) Steps 598(598.53) | Grad Norm 0.0446(0.0487) | Total Time 14.00(14.00)\n",
      "Iter 3035 | Time 52.5907(52.2614) | Bit/dim 3.4863(3.4898) | Xent 0.0000(0.0000) | Loss 3.4863(3.4898) | Error 0.0000(0.0000) Steps 598(598.51) | Grad Norm 0.0430(0.0485) | Total Time 14.00(14.00)\n",
      "Iter 3036 | Time 52.9040(52.2806) | Bit/dim 3.4870(3.4897) | Xent 0.0000(0.0000) | Loss 3.4870(3.4897) | Error 0.0000(0.0000) Steps 598(598.50) | Grad Norm 0.0541(0.0487) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0506 | Time 22.9968, Epoch Time 350.2914(352.8090), Bit/dim 3.4917(best: 3.4913), Xent 0.0000, Loss 3.4917, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3037 | Time 53.3582(52.3130) | Bit/dim 3.4954(3.4899) | Xent 0.0000(0.0000) | Loss 3.4954(3.4899) | Error 0.0000(0.0000) Steps 604(598.66) | Grad Norm 0.0489(0.0487) | Total Time 14.00(14.00)\n",
      "Iter 3038 | Time 49.2591(52.2214) | Bit/dim 3.4929(3.4900) | Xent 0.0000(0.0000) | Loss 3.4929(3.4900) | Error 0.0000(0.0000) Steps 598(598.64) | Grad Norm 0.0453(0.0486) | Total Time 14.00(14.00)\n",
      "Iter 3039 | Time 54.8061(52.2989) | Bit/dim 3.4884(3.4899) | Xent 0.0000(0.0000) | Loss 3.4884(3.4899) | Error 0.0000(0.0000) Steps 598(598.62) | Grad Norm 0.0466(0.0485) | Total Time 14.00(14.00)\n",
      "Iter 3040 | Time 52.5780(52.3073) | Bit/dim 3.4822(3.4897) | Xent 0.0000(0.0000) | Loss 3.4822(3.4897) | Error 0.0000(0.0000) Steps 598(598.61) | Grad Norm 0.0653(0.0490) | Total Time 14.00(14.00)\n",
      "Iter 3041 | Time 50.5236(52.2538) | Bit/dim 3.4936(3.4898) | Xent 0.0000(0.0000) | Loss 3.4936(3.4898) | Error 0.0000(0.0000) Steps 598(598.59) | Grad Norm 0.0484(0.0490) | Total Time 14.00(14.00)\n",
      "Iter 3042 | Time 51.0694(52.2182) | Bit/dim 3.4860(3.4897) | Xent 0.0000(0.0000) | Loss 3.4860(3.4897) | Error 0.0000(0.0000) Steps 598(598.57) | Grad Norm 0.0608(0.0494) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0507 | Time 22.8648, Epoch Time 350.0023(352.7248), Bit/dim 3.4920(best: 3.4913), Xent 0.0000, Loss 3.4920, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3043 | Time 52.5883(52.2293) | Bit/dim 3.4871(3.4896) | Xent 0.0000(0.0000) | Loss 3.4871(3.4896) | Error 0.0000(0.0000) Steps 598(598.55) | Grad Norm 0.0468(0.0493) | Total Time 14.00(14.00)\n",
      "Iter 3044 | Time 54.3528(52.2930) | Bit/dim 3.4890(3.4896) | Xent 0.0000(0.0000) | Loss 3.4890(3.4896) | Error 0.0000(0.0000) Steps 604(598.72) | Grad Norm 0.0432(0.0491) | Total Time 14.00(14.00)\n",
      "Iter 3045 | Time 50.8599(52.2500) | Bit/dim 3.4969(3.4898) | Xent 0.0000(0.0000) | Loss 3.4969(3.4898) | Error 0.0000(0.0000) Steps 598(598.70) | Grad Norm 0.0528(0.0492) | Total Time 14.00(14.00)\n",
      "Iter 3046 | Time 51.9941(52.2424) | Bit/dim 3.4928(3.4899) | Xent 0.0000(0.0000) | Loss 3.4928(3.4899) | Error 0.0000(0.0000) Steps 598(598.67) | Grad Norm 0.0543(0.0494) | Total Time 14.00(14.00)\n",
      "Iter 3047 | Time 50.1530(52.1797) | Bit/dim 3.4853(3.4898) | Xent 0.0000(0.0000) | Loss 3.4853(3.4898) | Error 0.0000(0.0000) Steps 598(598.65) | Grad Norm 0.0500(0.0494) | Total Time 14.00(14.00)\n",
      "Iter 3048 | Time 53.5154(52.2198) | Bit/dim 3.4853(3.4896) | Xent 0.0000(0.0000) | Loss 3.4853(3.4896) | Error 0.0000(0.0000) Steps 598(598.63) | Grad Norm 0.0502(0.0494) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0508 | Time 22.8100, Epoch Time 352.1651(352.7080), Bit/dim 3.4924(best: 3.4913), Xent 0.0000, Loss 3.4924, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3049 | Time 50.8374(52.1783) | Bit/dim 3.4918(3.4897) | Xent 0.0000(0.0000) | Loss 3.4918(3.4897) | Error 0.0000(0.0000) Steps 598(598.62) | Grad Norm 0.0461(0.0493) | Total Time 14.00(14.00)\n",
      "Iter 3050 | Time 52.0054(52.1731) | Bit/dim 3.4904(3.4897) | Xent 0.0000(0.0000) | Loss 3.4904(3.4897) | Error 0.0000(0.0000) Steps 598(598.60) | Grad Norm 0.0553(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 3051 | Time 53.6676(52.2179) | Bit/dim 3.4901(3.4897) | Xent 0.0000(0.0000) | Loss 3.4901(3.4897) | Error 0.0000(0.0000) Steps 598(598.58) | Grad Norm 0.0625(0.0499) | Total Time 14.00(14.00)\n",
      "Iter 3052 | Time 50.2391(52.1586) | Bit/dim 3.4856(3.4896) | Xent 0.0000(0.0000) | Loss 3.4856(3.4896) | Error 0.0000(0.0000) Steps 598(598.56) | Grad Norm 0.0468(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 3053 | Time 51.5858(52.1414) | Bit/dim 3.4819(3.4894) | Xent 0.0000(0.0000) | Loss 3.4819(3.4894) | Error 0.0000(0.0000) Steps 598(598.54) | Grad Norm 0.0480(0.0497) | Total Time 14.00(14.00)\n",
      "Iter 3054 | Time 52.9584(52.1659) | Bit/dim 3.5007(3.4897) | Xent 0.0000(0.0000) | Loss 3.5007(3.4897) | Error 0.0000(0.0000) Steps 604(598.71) | Grad Norm 0.0532(0.0498) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0509 | Time 22.6717, Epoch Time 349.5525(352.6133), Bit/dim 3.4924(best: 3.4913), Xent 0.0000, Loss 3.4924, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3055 | Time 51.6833(52.1514) | Bit/dim 3.4941(3.4898) | Xent 0.0000(0.0000) | Loss 3.4941(3.4898) | Error 0.0000(0.0000) Steps 598(598.69) | Grad Norm 0.0539(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 3056 | Time 53.6949(52.1977) | Bit/dim 3.4901(3.4898) | Xent 0.0000(0.0000) | Loss 3.4901(3.4898) | Error 0.0000(0.0000) Steps 598(598.67) | Grad Norm 0.0459(0.0498) | Total Time 14.00(14.00)\n",
      "Iter 3057 | Time 52.8969(52.2187) | Bit/dim 3.4805(3.4896) | Xent 0.0000(0.0000) | Loss 3.4805(3.4896) | Error 0.0000(0.0000) Steps 604(598.83) | Grad Norm 0.0456(0.0497) | Total Time 14.00(14.00)\n",
      "Iter 3058 | Time 51.2501(52.1896) | Bit/dim 3.4908(3.4896) | Xent 0.0000(0.0000) | Loss 3.4908(3.4896) | Error 0.0000(0.0000) Steps 598(598.80) | Grad Norm 0.0431(0.0495) | Total Time 14.00(14.00)\n",
      "Iter 3059 | Time 50.0696(52.1260) | Bit/dim 3.4875(3.4895) | Xent 0.0000(0.0000) | Loss 3.4875(3.4895) | Error 0.0000(0.0000) Steps 598(598.78) | Grad Norm 0.0518(0.0496) | Total Time 14.00(14.00)\n",
      "Iter 3060 | Time 52.8016(52.1463) | Bit/dim 3.4905(3.4896) | Xent 0.0000(0.0000) | Loss 3.4905(3.4896) | Error 0.0000(0.0000) Steps 598(598.75) | Grad Norm 0.0508(0.0496) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0510 | Time 23.1697, Epoch Time 350.8525(352.5605), Bit/dim 3.4913(best: 3.4913), Xent 0.0000, Loss 3.4913, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3061 | Time 52.6299(52.1608) | Bit/dim 3.4995(3.4899) | Xent 0.0000(0.0000) | Loss 3.4995(3.4899) | Error 0.0000(0.0000) Steps 598(598.73) | Grad Norm 0.0424(0.0494) | Total Time 14.00(14.00)\n",
      "Iter 3062 | Time 52.6830(52.1765) | Bit/dim 3.4780(3.4895) | Xent 0.0000(0.0000) | Loss 3.4780(3.4895) | Error 0.0000(0.0000) Steps 598(598.71) | Grad Norm 0.0498(0.0494) | Total Time 14.00(14.00)\n",
      "Iter 3063 | Time 51.0089(52.1414) | Bit/dim 3.4976(3.4898) | Xent 0.0000(0.0000) | Loss 3.4976(3.4898) | Error 0.0000(0.0000) Steps 598(598.69) | Grad Norm 0.0693(0.0500) | Total Time 14.00(14.00)\n",
      "Iter 3064 | Time 52.3182(52.1468) | Bit/dim 3.4897(3.4898) | Xent 0.0000(0.0000) | Loss 3.4897(3.4898) | Error 0.0000(0.0000) Steps 598(598.67) | Grad Norm 0.0535(0.0501) | Total Time 14.00(14.00)\n",
      "Iter 3065 | Time 52.6779(52.1627) | Bit/dim 3.4876(3.4897) | Xent 0.0000(0.0000) | Loss 3.4876(3.4897) | Error 0.0000(0.0000) Steps 604(598.83) | Grad Norm 0.0506(0.0501) | Total Time 14.00(14.00)\n",
      "Iter 3066 | Time 49.4772(52.0821) | Bit/dim 3.4861(3.4896) | Xent 0.0000(0.0000) | Loss 3.4861(3.4896) | Error 0.0000(0.0000) Steps 598(598.80) | Grad Norm 0.0578(0.0504) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0511 | Time 22.9558, Epoch Time 349.1952(352.4595), Bit/dim 3.4928(best: 3.4913), Xent 0.0000, Loss 3.4928, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3067 | Time 54.1993(52.1456) | Bit/dim 3.4886(3.4896) | Xent 0.0000(0.0000) | Loss 3.4886(3.4896) | Error 0.0000(0.0000) Steps 598(598.78) | Grad Norm 0.0638(0.0508) | Total Time 14.00(14.00)\n",
      "Iter 3068 | Time 52.8897(52.1680) | Bit/dim 3.4842(3.4894) | Xent 0.0000(0.0000) | Loss 3.4842(3.4894) | Error 0.0000(0.0000) Steps 604(598.94) | Grad Norm 0.0468(0.0506) | Total Time 14.00(14.00)\n",
      "Iter 3069 | Time 53.0223(52.1936) | Bit/dim 3.4912(3.4894) | Xent 0.0000(0.0000) | Loss 3.4912(3.4894) | Error 0.0000(0.0000) Steps 598(598.91) | Grad Norm 0.0437(0.0504) | Total Time 14.00(14.00)\n",
      "Iter 3070 | Time 50.7416(52.1500) | Bit/dim 3.4992(3.4897) | Xent 0.0000(0.0000) | Loss 3.4992(3.4897) | Error 0.0000(0.0000) Steps 598(598.88) | Grad Norm 0.0535(0.0505) | Total Time 14.00(14.00)\n",
      "Iter 3071 | Time 51.8817(52.1420) | Bit/dim 3.4882(3.4897) | Xent 0.0000(0.0000) | Loss 3.4882(3.4897) | Error 0.0000(0.0000) Steps 598(598.85) | Grad Norm 0.0640(0.0509) | Total Time 14.00(14.00)\n",
      "Iter 3072 | Time 53.3911(52.1795) | Bit/dim 3.4855(3.4896) | Xent 0.0000(0.0000) | Loss 3.4855(3.4896) | Error 0.0000(0.0000) Steps 598(598.83) | Grad Norm 0.0498(0.0509) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0512 | Time 22.8508, Epoch Time 354.6145(352.5242), Bit/dim 3.4918(best: 3.4913), Xent 0.0000, Loss 3.4918, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3073 | Time 53.6471(52.2235) | Bit/dim 3.4947(3.4897) | Xent 0.0000(0.0000) | Loss 3.4947(3.4897) | Error 0.0000(0.0000) Steps 598(598.80) | Grad Norm 0.0409(0.0506) | Total Time 14.00(14.00)\n",
      "Iter 3074 | Time 53.2795(52.2552) | Bit/dim 3.4979(3.4900) | Xent 0.0000(0.0000) | Loss 3.4979(3.4900) | Error 0.0000(0.0000) Steps 598(598.78) | Grad Norm 0.0555(0.0507) | Total Time 14.00(14.00)\n",
      "Iter 3075 | Time 52.2651(52.2555) | Bit/dim 3.4783(3.4896) | Xent 0.0000(0.0000) | Loss 3.4783(3.4896) | Error 0.0000(0.0000) Steps 598(598.76) | Grad Norm 0.0480(0.0507) | Total Time 14.00(14.00)\n",
      "Iter 3076 | Time 51.1810(52.2232) | Bit/dim 3.4928(3.4897) | Xent 0.0000(0.0000) | Loss 3.4928(3.4897) | Error 0.0000(0.0000) Steps 598(598.73) | Grad Norm 0.0501(0.0506) | Total Time 14.00(14.00)\n",
      "Iter 3077 | Time 53.5118(52.2619) | Bit/dim 3.4916(3.4898) | Xent 0.0000(0.0000) | Loss 3.4916(3.4898) | Error 0.0000(0.0000) Steps 598(598.71) | Grad Norm 0.0403(0.0503) | Total Time 14.00(14.00)\n",
      "Iter 3078 | Time 52.2707(52.2621) | Bit/dim 3.4817(3.4895) | Xent 0.0000(0.0000) | Loss 3.4817(3.4895) | Error 0.0000(0.0000) Steps 598(598.69) | Grad Norm 0.0489(0.0503) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0513 | Time 22.6258, Epoch Time 354.5366(352.5845), Bit/dim 3.4913(best: 3.4913), Xent 0.0000, Loss 3.4913, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3079 | Time 52.4644(52.2682) | Bit/dim 3.4922(3.4896) | Xent 0.0000(0.0000) | Loss 3.4922(3.4896) | Error 0.0000(0.0000) Steps 604(598.85) | Grad Norm 0.0514(0.0503) | Total Time 14.00(14.00)\n",
      "Iter 3080 | Time 52.3916(52.2719) | Bit/dim 3.4887(3.4896) | Xent 0.0000(0.0000) | Loss 3.4887(3.4896) | Error 0.0000(0.0000) Steps 598(598.82) | Grad Norm 0.0465(0.0502) | Total Time 14.00(14.00)\n",
      "Iter 3081 | Time 50.3909(52.2155) | Bit/dim 3.4956(3.4898) | Xent 0.0000(0.0000) | Loss 3.4956(3.4898) | Error 0.0000(0.0000) Steps 598(598.80) | Grad Norm 0.0523(0.0503) | Total Time 14.00(14.00)\n",
      "Iter 3082 | Time 51.4877(52.1937) | Bit/dim 3.4865(3.4897) | Xent 0.0000(0.0000) | Loss 3.4865(3.4897) | Error 0.0000(0.0000) Steps 598(598.78) | Grad Norm 0.0457(0.0501) | Total Time 14.00(14.00)\n",
      "Iter 3083 | Time 50.9861(52.1574) | Bit/dim 3.4919(3.4897) | Xent 0.0000(0.0000) | Loss 3.4919(3.4897) | Error 0.0000(0.0000) Steps 598(598.75) | Grad Norm 0.0493(0.0501) | Total Time 14.00(14.00)\n",
      "Iter 3084 | Time 51.1151(52.1262) | Bit/dim 3.4851(3.4896) | Xent 0.0000(0.0000) | Loss 3.4851(3.4896) | Error 0.0000(0.0000) Steps 598(598.73) | Grad Norm 0.0560(0.0503) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0514 | Time 23.0402, Epoch Time 347.4230(352.4297), Bit/dim 3.4919(best: 3.4913), Xent 0.0000, Loss 3.4919, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3085 | Time 49.9701(52.0615) | Bit/dim 3.4907(3.4896) | Xent 0.0000(0.0000) | Loss 3.4907(3.4896) | Error 0.0000(0.0000) Steps 598(598.71) | Grad Norm 0.0481(0.0502) | Total Time 14.00(14.00)\n",
      "Iter 3086 | Time 53.0658(52.0916) | Bit/dim 3.5008(3.4900) | Xent 0.0000(0.0000) | Loss 3.5008(3.4900) | Error 0.0000(0.0000) Steps 598(598.69) | Grad Norm 0.0477(0.0501) | Total Time 14.00(14.00)\n",
      "Iter 3087 | Time 52.9506(52.1174) | Bit/dim 3.4889(3.4899) | Xent 0.0000(0.0000) | Loss 3.4889(3.4899) | Error 0.0000(0.0000) Steps 598(598.67) | Grad Norm 0.0601(0.0504) | Total Time 14.00(14.00)\n",
      "Iter 3088 | Time 52.9086(52.1411) | Bit/dim 3.4898(3.4899) | Xent 0.0000(0.0000) | Loss 3.4898(3.4899) | Error 0.0000(0.0000) Steps 598(598.65) | Grad Norm 0.0702(0.0510) | Total Time 14.00(14.00)\n",
      "Iter 3089 | Time 53.6254(52.1856) | Bit/dim 3.4794(3.4896) | Xent 0.0000(0.0000) | Loss 3.4794(3.4896) | Error 0.0000(0.0000) Steps 598(598.63) | Grad Norm 0.0481(0.0509) | Total Time 14.00(14.00)\n",
      "Iter 3090 | Time 52.7433(52.2024) | Bit/dim 3.4871(3.4895) | Xent 0.0000(0.0000) | Loss 3.4871(3.4895) | Error 0.0000(0.0000) Steps 598(598.61) | Grad Norm 0.0577(0.0511) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0515 | Time 22.7568, Epoch Time 354.0821(352.4793), Bit/dim 3.4920(best: 3.4913), Xent 0.0000, Loss 3.4920, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3091 | Time 55.1515(52.2908) | Bit/dim 3.4944(3.4897) | Xent 0.0000(0.0000) | Loss 3.4944(3.4897) | Error 0.0000(0.0000) Steps 604(598.77) | Grad Norm 0.0624(0.0515) | Total Time 14.00(14.00)\n",
      "Iter 3092 | Time 51.6811(52.2725) | Bit/dim 3.4879(3.4896) | Xent 0.0000(0.0000) | Loss 3.4879(3.4896) | Error 0.0000(0.0000) Steps 598(598.75) | Grad Norm 0.0449(0.0513) | Total Time 14.00(14.00)\n",
      "Iter 3093 | Time 50.0948(52.2072) | Bit/dim 3.4912(3.4897) | Xent 0.0000(0.0000) | Loss 3.4912(3.4897) | Error 0.0000(0.0000) Steps 598(598.72) | Grad Norm 0.0459(0.0511) | Total Time 14.00(14.00)\n",
      "Iter 3094 | Time 52.9570(52.2297) | Bit/dim 3.4901(3.4897) | Xent 0.0000(0.0000) | Loss 3.4901(3.4897) | Error 0.0000(0.0000) Steps 598(598.70) | Grad Norm 0.0532(0.0512) | Total Time 14.00(14.00)\n",
      "Iter 3095 | Time 55.3810(52.3242) | Bit/dim 3.4835(3.4895) | Xent 0.0000(0.0000) | Loss 3.4835(3.4895) | Error 0.0000(0.0000) Steps 586(598.32) | Grad Norm 0.0827(0.0521) | Total Time 14.00(14.00)\n",
      "Iter 3096 | Time 51.4274(52.2973) | Bit/dim 3.4880(3.4895) | Xent 0.0000(0.0000) | Loss 3.4880(3.4895) | Error 0.0000(0.0000) Steps 598(598.31) | Grad Norm 0.0417(0.0518) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0516 | Time 22.8447, Epoch Time 355.2215(352.5615), Bit/dim 3.4914(best: 3.4913), Xent 0.0000, Loss 3.4914, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3097 | Time 54.3458(52.3588) | Bit/dim 3.4898(3.4895) | Xent 0.0000(0.0000) | Loss 3.4898(3.4895) | Error 0.0000(0.0000) Steps 598(598.30) | Grad Norm 0.0635(0.0522) | Total Time 14.00(14.00)\n",
      "Iter 3098 | Time 53.4018(52.3901) | Bit/dim 3.4963(3.4897) | Xent 0.0000(0.0000) | Loss 3.4963(3.4897) | Error 0.0000(0.0000) Steps 598(598.29) | Grad Norm 0.0571(0.0523) | Total Time 14.00(14.00)\n",
      "Iter 3099 | Time 51.9021(52.3754) | Bit/dim 3.4845(3.4895) | Xent 0.0000(0.0000) | Loss 3.4845(3.4895) | Error 0.0000(0.0000) Steps 598(598.28) | Grad Norm 0.0515(0.0523) | Total Time 14.00(14.00)\n",
      "Iter 3100 | Time 50.6341(52.3232) | Bit/dim 3.4969(3.4897) | Xent 0.0000(0.0000) | Loss 3.4969(3.4897) | Error 0.0000(0.0000) Steps 598(598.28) | Grad Norm 0.0483(0.0522) | Total Time 14.00(14.00)\n",
      "Iter 3101 | Time 54.1924(52.3793) | Bit/dim 3.4859(3.4896) | Xent 0.0000(0.0000) | Loss 3.4859(3.4896) | Error 0.0000(0.0000) Steps 598(598.27) | Grad Norm 0.0613(0.0525) | Total Time 14.00(14.00)\n",
      "Iter 3102 | Time 49.9972(52.3078) | Bit/dim 3.4824(3.4894) | Xent 0.0000(0.0000) | Loss 3.4824(3.4894) | Error 0.0000(0.0000) Steps 598(598.26) | Grad Norm 0.0688(0.0529) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0517 | Time 23.0653, Epoch Time 353.3168(352.5842), Bit/dim 3.4920(best: 3.4913), Xent 0.0000, Loss 3.4920, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3103 | Time 55.1291(52.3925) | Bit/dim 3.5036(3.4898) | Xent 0.0000(0.0000) | Loss 3.5036(3.4898) | Error 0.0000(0.0000) Steps 598(598.25) | Grad Norm 0.0547(0.0530) | Total Time 14.00(14.00)\n",
      "Iter 3104 | Time 53.2298(52.4176) | Bit/dim 3.4796(3.4895) | Xent 0.0000(0.0000) | Loss 3.4796(3.4895) | Error 0.0000(0.0000) Steps 604(598.42) | Grad Norm 0.0524(0.0530) | Total Time 14.00(14.00)\n",
      "Iter 3105 | Time 50.0932(52.3478) | Bit/dim 3.4992(3.4898) | Xent 0.0000(0.0000) | Loss 3.4992(3.4898) | Error 0.0000(0.0000) Steps 598(598.41) | Grad Norm 0.0595(0.0532) | Total Time 14.00(14.00)\n",
      "Iter 3106 | Time 51.9628(52.3363) | Bit/dim 3.4866(3.4897) | Xent 0.0000(0.0000) | Loss 3.4866(3.4897) | Error 0.0000(0.0000) Steps 598(598.40) | Grad Norm 0.0610(0.0534) | Total Time 14.00(14.00)\n",
      "Iter 3107 | Time 54.6651(52.4062) | Bit/dim 3.4846(3.4896) | Xent 0.0000(0.0000) | Loss 3.4846(3.4896) | Error 0.0000(0.0000) Steps 598(598.39) | Grad Norm 0.0565(0.0535) | Total Time 14.00(14.00)\n",
      "Iter 3108 | Time 56.0382(52.5151) | Bit/dim 3.4826(3.4894) | Xent 0.0000(0.0000) | Loss 3.4826(3.4894) | Error 0.0000(0.0000) Steps 598(598.38) | Grad Norm 0.0652(0.0539) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0518 | Time 22.8457, Epoch Time 359.2392(352.7838), Bit/dim 3.4914(best: 3.4913), Xent 0.0000, Loss 3.4914, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3109 | Time 53.2656(52.5376) | Bit/dim 3.4863(3.4893) | Xent 0.0000(0.0000) | Loss 3.4863(3.4893) | Error 0.0000(0.0000) Steps 598(598.36) | Grad Norm 0.0713(0.0544) | Total Time 14.00(14.00)\n",
      "Iter 3110 | Time 49.9752(52.4608) | Bit/dim 3.4895(3.4893) | Xent 0.0000(0.0000) | Loss 3.4895(3.4893) | Error 0.0000(0.0000) Steps 598(598.35) | Grad Norm 0.0523(0.0543) | Total Time 14.00(14.00)\n",
      "Iter 3111 | Time 52.4405(52.4602) | Bit/dim 3.5011(3.4896) | Xent 0.0000(0.0000) | Loss 3.5011(3.4896) | Error 0.0000(0.0000) Steps 598(598.34) | Grad Norm 0.0465(0.0541) | Total Time 14.00(14.00)\n",
      "Iter 3112 | Time 51.9304(52.4443) | Bit/dim 3.4815(3.4894) | Xent 0.0000(0.0000) | Loss 3.4815(3.4894) | Error 0.0000(0.0000) Steps 598(598.33) | Grad Norm 0.0797(0.0548) | Total Time 14.00(14.00)\n",
      "Iter 3113 | Time 51.6415(52.4202) | Bit/dim 3.4927(3.4895) | Xent 0.0000(0.0000) | Loss 3.4927(3.4895) | Error 0.0000(0.0000) Steps 598(598.32) | Grad Norm 0.0554(0.0549) | Total Time 14.00(14.00)\n",
      "Iter 3114 | Time 50.2706(52.3557) | Bit/dim 3.4872(3.4894) | Xent 0.0000(0.0000) | Loss 3.4872(3.4894) | Error 0.0000(0.0000) Steps 604(598.49) | Grad Norm 0.0473(0.0546) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0519 | Time 23.0546, Epoch Time 348.4021(352.6524), Bit/dim 3.4918(best: 3.4913), Xent 0.0000, Loss 3.4918, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3115 | Time 52.2907(52.3537) | Bit/dim 3.4983(3.4897) | Xent 0.0000(0.0000) | Loss 3.4983(3.4897) | Error 0.0000(0.0000) Steps 598(598.48) | Grad Norm 0.0536(0.0546) | Total Time 14.00(14.00)\n",
      "Iter 3116 | Time 50.8625(52.3090) | Bit/dim 3.4823(3.4895) | Xent 0.0000(0.0000) | Loss 3.4823(3.4895) | Error 0.0000(0.0000) Steps 598(598.46) | Grad Norm 0.0538(0.0546) | Total Time 14.00(14.00)\n",
      "Iter 3117 | Time 53.7273(52.3516) | Bit/dim 3.4897(3.4895) | Xent 0.0000(0.0000) | Loss 3.4897(3.4895) | Error 0.0000(0.0000) Steps 604(598.63) | Grad Norm 0.0489(0.0544) | Total Time 14.00(14.00)\n",
      "Iter 3118 | Time 52.0733(52.3432) | Bit/dim 3.4949(3.4896) | Xent 0.0000(0.0000) | Loss 3.4949(3.4896) | Error 0.0000(0.0000) Steps 604(598.79) | Grad Norm 0.0531(0.0544) | Total Time 14.00(14.00)\n",
      "Iter 3119 | Time 53.0672(52.3649) | Bit/dim 3.4871(3.4895) | Xent 0.0000(0.0000) | Loss 3.4871(3.4895) | Error 0.0000(0.0000) Steps 598(598.77) | Grad Norm 0.0573(0.0545) | Total Time 14.00(14.00)\n",
      "Iter 3120 | Time 52.8474(52.3794) | Bit/dim 3.4899(3.4896) | Xent 0.0000(0.0000) | Loss 3.4899(3.4896) | Error 0.0000(0.0000) Steps 598(598.74) | Grad Norm 0.0466(0.0542) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0520 | Time 22.5703, Epoch Time 353.3637(352.6737), Bit/dim 3.4913(best: 3.4913), Xent 0.0000, Loss 3.4913, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3121 | Time 50.0602(52.3098) | Bit/dim 3.4925(3.4896) | Xent 0.0000(0.0000) | Loss 3.4925(3.4896) | Error 0.0000(0.0000) Steps 598(598.72) | Grad Norm 0.0424(0.0539) | Total Time 14.00(14.00)\n",
      "Iter 3122 | Time 54.4941(52.3754) | Bit/dim 3.4816(3.4894) | Xent 0.0000(0.0000) | Loss 3.4816(3.4894) | Error 0.0000(0.0000) Steps 598(598.70) | Grad Norm 0.0460(0.0536) | Total Time 14.00(14.00)\n",
      "Iter 3123 | Time 52.4272(52.3769) | Bit/dim 3.4814(3.4892) | Xent 0.0000(0.0000) | Loss 3.4814(3.4892) | Error 0.0000(0.0000) Steps 598(598.68) | Grad Norm 0.0512(0.0536) | Total Time 14.00(14.00)\n",
      "Iter 3124 | Time 51.4342(52.3486) | Bit/dim 3.5017(3.4895) | Xent 0.0000(0.0000) | Loss 3.5017(3.4895) | Error 0.0000(0.0000) Steps 598(598.66) | Grad Norm 0.0442(0.0533) | Total Time 14.00(14.00)\n",
      "Iter 3125 | Time 50.7005(52.2992) | Bit/dim 3.4906(3.4896) | Xent 0.0000(0.0000) | Loss 3.4906(3.4896) | Error 0.0000(0.0000) Steps 598(598.64) | Grad Norm 0.0447(0.0530) | Total Time 14.00(14.00)\n",
      "Iter 3126 | Time 49.7538(52.2228) | Bit/dim 3.4873(3.4895) | Xent 0.0000(0.0000) | Loss 3.4873(3.4895) | Error 0.0000(0.0000) Steps 598(598.62) | Grad Norm 0.0459(0.0528) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0521 | Time 22.6656, Epoch Time 347.2947(352.5124), Bit/dim 3.4913(best: 3.4913), Xent 0.0000, Loss 3.4913, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3127 | Time 52.0521(52.2177) | Bit/dim 3.4861(3.4894) | Xent 0.0000(0.0000) | Loss 3.4861(3.4894) | Error 0.0000(0.0000) Steps 598(598.60) | Grad Norm 0.0509(0.0528) | Total Time 14.00(14.00)\n",
      "Iter 3128 | Time 50.4896(52.1659) | Bit/dim 3.4906(3.4894) | Xent 0.0000(0.0000) | Loss 3.4906(3.4894) | Error 0.0000(0.0000) Steps 598(598.58) | Grad Norm 0.0429(0.0525) | Total Time 14.00(14.00)\n",
      "Iter 3129 | Time 52.9657(52.1899) | Bit/dim 3.4897(3.4894) | Xent 0.0000(0.0000) | Loss 3.4897(3.4894) | Error 0.0000(0.0000) Steps 604(598.75) | Grad Norm 0.0458(0.0523) | Total Time 14.00(14.00)\n",
      "Iter 3130 | Time 48.9961(52.0940) | Bit/dim 3.4910(3.4895) | Xent 0.0000(0.0000) | Loss 3.4910(3.4895) | Error 0.0000(0.0000) Steps 598(598.72) | Grad Norm 0.0566(0.0524) | Total Time 14.00(14.00)\n",
      "Iter 3131 | Time 50.0446(52.0326) | Bit/dim 3.4906(3.4895) | Xent 0.0000(0.0000) | Loss 3.4906(3.4895) | Error 0.0000(0.0000) Steps 598(598.70) | Grad Norm 0.0553(0.0525) | Total Time 14.00(14.00)\n",
      "Iter 3132 | Time 52.5741(52.0488) | Bit/dim 3.4866(3.4894) | Xent 0.0000(0.0000) | Loss 3.4866(3.4894) | Error 0.0000(0.0000) Steps 598(598.68) | Grad Norm 0.0580(0.0526) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0522 | Time 22.7821, Epoch Time 345.5446(352.3033), Bit/dim 3.4914(best: 3.4913), Xent 0.0000, Loss 3.4914, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3133 | Time 51.5137(52.0327) | Bit/dim 3.4902(3.4895) | Xent 0.0000(0.0000) | Loss 3.4902(3.4895) | Error 0.0000(0.0000) Steps 598(598.66) | Grad Norm 0.0516(0.0526) | Total Time 14.00(14.00)\n",
      "Iter 3134 | Time 51.7232(52.0235) | Bit/dim 3.4932(3.4896) | Xent 0.0000(0.0000) | Loss 3.4932(3.4896) | Error 0.0000(0.0000) Steps 604(598.82) | Grad Norm 0.0660(0.0530) | Total Time 14.00(14.00)\n",
      "Iter 3135 | Time 50.9295(51.9906) | Bit/dim 3.4819(3.4893) | Xent 0.0000(0.0000) | Loss 3.4819(3.4893) | Error 0.0000(0.0000) Steps 598(598.80) | Grad Norm 0.0549(0.0531) | Total Time 14.00(14.00)\n",
      "Iter 3136 | Time 50.1998(51.9369) | Bit/dim 3.4976(3.4896) | Xent 0.0000(0.0000) | Loss 3.4976(3.4896) | Error 0.0000(0.0000) Steps 598(598.77) | Grad Norm 0.0597(0.0533) | Total Time 14.00(14.00)\n",
      "Iter 3137 | Time 51.3635(51.9197) | Bit/dim 3.4890(3.4896) | Xent 0.0000(0.0000) | Loss 3.4890(3.4896) | Error 0.0000(0.0000) Steps 598(598.75) | Grad Norm 0.0524(0.0532) | Total Time 14.00(14.00)\n",
      "Iter 3138 | Time 49.7450(51.8545) | Bit/dim 3.4864(3.4895) | Xent 0.0000(0.0000) | Loss 3.4864(3.4895) | Error 0.0000(0.0000) Steps 598(598.73) | Grad Norm 0.0435(0.0529) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0523 | Time 22.9880, Epoch Time 344.0224(352.0549), Bit/dim 3.4919(best: 3.4913), Xent 0.0000, Loss 3.4919, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3139 | Time 49.8305(51.7938) | Bit/dim 3.4859(3.4894) | Xent 0.0000(0.0000) | Loss 3.4859(3.4894) | Error 0.0000(0.0000) Steps 598(598.70) | Grad Norm 0.0443(0.0527) | Total Time 14.00(14.00)\n",
      "Iter 3140 | Time 51.7914(51.7937) | Bit/dim 3.4926(3.4895) | Xent 0.0000(0.0000) | Loss 3.4926(3.4895) | Error 0.0000(0.0000) Steps 598(598.68) | Grad Norm 0.0679(0.0531) | Total Time 14.00(14.00)\n",
      "Iter 3141 | Time 49.9628(51.7388) | Bit/dim 3.4823(3.4892) | Xent 0.0000(0.0000) | Loss 3.4823(3.4892) | Error 0.0000(0.0000) Steps 598(598.66) | Grad Norm 0.0672(0.0536) | Total Time 14.00(14.00)\n",
      "Iter 3142 | Time 52.7990(51.7706) | Bit/dim 3.4876(3.4892) | Xent 0.0000(0.0000) | Loss 3.4876(3.4892) | Error 0.0000(0.0000) Steps 598(598.64) | Grad Norm 0.0449(0.0533) | Total Time 14.00(14.00)\n",
      "Iter 3143 | Time 53.0717(51.8096) | Bit/dim 3.4924(3.4893) | Xent 0.0000(0.0000) | Loss 3.4924(3.4893) | Error 0.0000(0.0000) Steps 598(598.62) | Grad Norm 0.0663(0.0537) | Total Time 14.00(14.00)\n",
      "Iter 3144 | Time 52.7666(51.8383) | Bit/dim 3.4979(3.4895) | Xent 0.0000(0.0000) | Loss 3.4979(3.4895) | Error 0.0000(0.0000) Steps 598(598.60) | Grad Norm 0.0863(0.0547) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0524 | Time 22.6475, Epoch Time 348.7124(351.9546), Bit/dim 3.4918(best: 3.4913), Xent 0.0000, Loss 3.4918, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3145 | Time 53.0061(51.8733) | Bit/dim 3.4923(3.4896) | Xent 0.0000(0.0000) | Loss 3.4923(3.4896) | Error 0.0000(0.0000) Steps 598(598.59) | Grad Norm 0.0540(0.0547) | Total Time 14.00(14.00)\n",
      "Iter 3146 | Time 50.3147(51.8266) | Bit/dim 3.4956(3.4898) | Xent 0.0000(0.0000) | Loss 3.4956(3.4898) | Error 0.0000(0.0000) Steps 598(598.57) | Grad Norm 0.0481(0.0545) | Total Time 14.00(14.00)\n",
      "Iter 3147 | Time 52.5962(51.8497) | Bit/dim 3.4816(3.4896) | Xent 0.0000(0.0000) | Loss 3.4816(3.4896) | Error 0.0000(0.0000) Steps 598(598.55) | Grad Norm 0.0752(0.0551) | Total Time 14.00(14.00)\n",
      "Iter 3148 | Time 52.6498(51.8737) | Bit/dim 3.4900(3.4896) | Xent 0.0000(0.0000) | Loss 3.4900(3.4896) | Error 0.0000(0.0000) Steps 604(598.72) | Grad Norm 0.0903(0.0561) | Total Time 14.00(14.00)\n",
      "Iter 3149 | Time 50.3694(51.8285) | Bit/dim 3.4941(3.4897) | Xent 0.0000(0.0000) | Loss 3.4941(3.4897) | Error 0.0000(0.0000) Steps 598(598.69) | Grad Norm 0.0545(0.0561) | Total Time 14.00(14.00)\n",
      "Iter 3150 | Time 49.9140(51.7711) | Bit/dim 3.4841(3.4895) | Xent 0.0000(0.0000) | Loss 3.4841(3.4895) | Error 0.0000(0.0000) Steps 598(598.67) | Grad Norm 0.1031(0.0575) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0525 | Time 23.0330, Epoch Time 347.6000(351.8240), Bit/dim 3.4912(best: 3.4913), Xent 0.0000, Loss 3.4912, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3151 | Time 53.7158(51.8294) | Bit/dim 3.4882(3.4895) | Xent 0.0000(0.0000) | Loss 3.4882(3.4895) | Error 0.0000(0.0000) Steps 598(598.65) | Grad Norm 0.0876(0.0584) | Total Time 14.00(14.00)\n",
      "Iter 3152 | Time 52.4992(51.8495) | Bit/dim 3.4883(3.4895) | Xent 0.0000(0.0000) | Loss 3.4883(3.4895) | Error 0.0000(0.0000) Steps 598(598.63) | Grad Norm 0.0613(0.0585) | Total Time 14.00(14.00)\n",
      "Iter 3153 | Time 51.9369(51.8522) | Bit/dim 3.4976(3.4897) | Xent 0.0000(0.0000) | Loss 3.4976(3.4897) | Error 0.0000(0.0000) Steps 598(598.61) | Grad Norm 0.0857(0.0593) | Total Time 14.00(14.00)\n",
      "Iter 3154 | Time 50.4764(51.8109) | Bit/dim 3.4930(3.4898) | Xent 0.0000(0.0000) | Loss 3.4930(3.4898) | Error 0.0000(0.0000) Steps 604(598.78) | Grad Norm 0.0971(0.0604) | Total Time 14.00(14.00)\n",
      "Iter 3155 | Time 53.7856(51.8701) | Bit/dim 3.4803(3.4895) | Xent 0.0000(0.0000) | Loss 3.4803(3.4895) | Error 0.0000(0.0000) Steps 604(598.93) | Grad Norm 0.0613(0.0605) | Total Time 14.00(14.00)\n",
      "Iter 3156 | Time 52.3990(51.8860) | Bit/dim 3.4910(3.4896) | Xent 0.0000(0.0000) | Loss 3.4910(3.4896) | Error 0.0000(0.0000) Steps 598(598.90) | Grad Norm 0.0642(0.0606) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0526 | Time 23.0771, Epoch Time 353.3738(351.8705), Bit/dim 3.4911(best: 3.4912), Xent 0.0000, Loss 3.4911, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3157 | Time 51.8083(51.8837) | Bit/dim 3.4840(3.4894) | Xent 0.0000(0.0000) | Loss 3.4840(3.4894) | Error 0.0000(0.0000) Steps 598(598.88) | Grad Norm 0.0751(0.0610) | Total Time 14.00(14.00)\n",
      "Iter 3158 | Time 50.6106(51.8455) | Bit/dim 3.4931(3.4895) | Xent 0.0000(0.0000) | Loss 3.4931(3.4895) | Error 0.0000(0.0000) Steps 598(598.85) | Grad Norm 0.0468(0.0606) | Total Time 14.00(14.00)\n",
      "Iter 3159 | Time 49.6806(51.7805) | Bit/dim 3.4893(3.4895) | Xent 0.0000(0.0000) | Loss 3.4893(3.4895) | Error 0.0000(0.0000) Steps 598(598.83) | Grad Norm 0.0661(0.0608) | Total Time 14.00(14.00)\n",
      "Iter 3160 | Time 53.1124(51.8205) | Bit/dim 3.4845(3.4894) | Xent 0.0000(0.0000) | Loss 3.4845(3.4894) | Error 0.0000(0.0000) Steps 598(598.80) | Grad Norm 0.0551(0.0606) | Total Time 14.00(14.00)\n",
      "Iter 3161 | Time 53.6926(51.8767) | Bit/dim 3.4895(3.4894) | Xent 0.0000(0.0000) | Loss 3.4895(3.4894) | Error 0.0000(0.0000) Steps 598(598.78) | Grad Norm 0.0478(0.0602) | Total Time 14.00(14.00)\n",
      "Iter 3162 | Time 49.9744(51.8196) | Bit/dim 3.4947(3.4895) | Xent 0.0000(0.0000) | Loss 3.4947(3.4895) | Error 0.0000(0.0000) Steps 598(598.75) | Grad Norm 0.0503(0.0599) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0527 | Time 22.9337, Epoch Time 347.7758(351.7476), Bit/dim 3.4910(best: 3.4911), Xent 0.0000, Loss 3.4910, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3163 | Time 51.7734(51.8182) | Bit/dim 3.4922(3.4896) | Xent 0.0000(0.0000) | Loss 3.4922(3.4896) | Error 0.0000(0.0000) Steps 598(598.73) | Grad Norm 0.0461(0.0595) | Total Time 14.00(14.00)\n",
      "Iter 3164 | Time 51.6591(51.8134) | Bit/dim 3.4953(3.4898) | Xent 0.0000(0.0000) | Loss 3.4953(3.4898) | Error 0.0000(0.0000) Steps 604(598.89) | Grad Norm 0.0528(0.0593) | Total Time 14.00(14.00)\n",
      "Iter 3165 | Time 55.5866(51.9266) | Bit/dim 3.4821(3.4895) | Xent 0.0000(0.0000) | Loss 3.4821(3.4895) | Error 0.0000(0.0000) Steps 604(599.04) | Grad Norm 0.0432(0.0588) | Total Time 14.00(14.00)\n",
      "Iter 3166 | Time 52.5351(51.9449) | Bit/dim 3.4786(3.4892) | Xent 0.0000(0.0000) | Loss 3.4786(3.4892) | Error 0.0000(0.0000) Steps 598(599.01) | Grad Norm 0.0455(0.0584) | Total Time 14.00(14.00)\n",
      "Iter 3167 | Time 53.3939(51.9883) | Bit/dim 3.4836(3.4890) | Xent 0.0000(0.0000) | Loss 3.4836(3.4890) | Error 0.0000(0.0000) Steps 598(598.98) | Grad Norm 0.0518(0.0582) | Total Time 14.00(14.00)\n",
      "Iter 3168 | Time 51.3511(51.9692) | Bit/dim 3.5018(3.4894) | Xent 0.0000(0.0000) | Loss 3.5018(3.4894) | Error 0.0000(0.0000) Steps 598(598.95) | Grad Norm 0.0483(0.0579) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Iter 3170 | Time 51.6331(52.0179) | Bit/dim 3.5035(3.4896) | Xent 0.0000(0.0000) | Loss 3.5035(3.4896) | Error 0.0000(0.0000) Steps 598(599.24) | Grad Norm 0.0631(0.0577) | Total Time 14.00(14.00)\n",
      "Iter 3171 | Time 50.9010(51.9844) | Bit/dim 3.4961(3.4898) | Xent 0.0000(0.0000) | Loss 3.4961(3.4898) | Error 0.0000(0.0000) Steps 598(599.21) | Grad Norm 0.0616(0.0578) | Total Time 14.00(14.00)\n",
      "Iter 3172 | Time 49.8925(51.9217) | Bit/dim 3.4892(3.4897) | Xent 0.0000(0.0000) | Loss 3.4892(3.4897) | Error 0.0000(0.0000) Steps 598(599.17) | Grad Norm 0.0531(0.0577) | Total Time 14.00(14.00)\n",
      "Iter 3173 | Time 52.1379(51.9282) | Bit/dim 3.4708(3.4892) | Xent 0.0000(0.0000) | Loss 3.4708(3.4892) | Error 0.0000(0.0000) Steps 598(599.14) | Grad Norm 0.0674(0.0580) | Total Time 14.00(14.00)\n",
      "Iter 3174 | Time 50.3615(51.8812) | Bit/dim 3.4969(3.4894) | Xent 0.0000(0.0000) | Loss 3.4969(3.4894) | Error 0.0000(0.0000) Steps 598(599.10) | Grad Norm 0.0701(0.0583) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0529 | Time 23.0475, Epoch Time 347.7811(351.7284), Bit/dim 3.4917(best: 3.4910), Xent 0.0000, Loss 3.4917, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3175 | Time 53.6461(51.9341) | Bit/dim 3.4889(3.4894) | Xent 0.0000(0.0000) | Loss 3.4889(3.4894) | Error 0.0000(0.0000) Steps 604(599.25) | Grad Norm 0.0610(0.0584) | Total Time 14.00(14.00)\n",
      "Iter 3176 | Time 55.5925(52.0439) | Bit/dim 3.4860(3.4893) | Xent 0.0000(0.0000) | Loss 3.4860(3.4893) | Error 0.0000(0.0000) Steps 598(599.21) | Grad Norm 0.0467(0.0581) | Total Time 14.00(14.00)\n",
      "Iter 3177 | Time 50.7737(52.0057) | Bit/dim 3.4875(3.4892) | Xent 0.0000(0.0000) | Loss 3.4875(3.4892) | Error 0.0000(0.0000) Steps 598(599.17) | Grad Norm 0.0741(0.0585) | Total Time 14.00(14.00)\n",
      "Iter 3178 | Time 49.4113(51.9279) | Bit/dim 3.4891(3.4892) | Xent 0.0000(0.0000) | Loss 3.4891(3.4892) | Error 0.0000(0.0000) Steps 598(599.14) | Grad Norm 0.0858(0.0593) | Total Time 14.00(14.00)\n",
      "Iter 3179 | Time 52.8696(51.9562) | Bit/dim 3.4901(3.4893) | Xent 0.0000(0.0000) | Loss 3.4901(3.4893) | Error 0.0000(0.0000) Steps 598(599.11) | Grad Norm 0.0560(0.0592) | Total Time 14.00(14.00)\n",
      "Iter 3180 | Time 52.5153(51.9729) | Bit/dim 3.4894(3.4893) | Xent 0.0000(0.0000) | Loss 3.4894(3.4893) | Error 0.0000(0.0000) Steps 598(599.07) | Grad Norm 0.0575(0.0592) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0530 | Time 23.1859, Epoch Time 353.5976(351.7845), Bit/dim 3.4917(best: 3.4910), Xent 0.0000, Loss 3.4917, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3181 | Time 49.4063(51.8959) | Bit/dim 3.4803(3.4890) | Xent 0.0000(0.0000) | Loss 3.4803(3.4890) | Error 0.0000(0.0000) Steps 598(599.04) | Grad Norm 0.0548(0.0591) | Total Time 14.00(14.00)\n",
      "Iter 3182 | Time 52.5641(51.9160) | Bit/dim 3.4917(3.4891) | Xent 0.0000(0.0000) | Loss 3.4917(3.4891) | Error 0.0000(0.0000) Steps 598(599.01) | Grad Norm 0.0623(0.0592) | Total Time 14.00(14.00)\n",
      "Iter 3183 | Time 52.7077(51.9397) | Bit/dim 3.4912(3.4891) | Xent 0.0000(0.0000) | Loss 3.4912(3.4891) | Error 0.0000(0.0000) Steps 598(598.98) | Grad Norm 0.0643(0.0593) | Total Time 14.00(14.00)\n",
      "Iter 3184 | Time 52.5255(51.9573) | Bit/dim 3.4870(3.4891) | Xent 0.0000(0.0000) | Loss 3.4870(3.4891) | Error 0.0000(0.0000) Steps 598(598.95) | Grad Norm 0.0561(0.0592) | Total Time 14.00(14.00)\n",
      "Iter 3185 | Time 51.6315(51.9475) | Bit/dim 3.4891(3.4891) | Xent 0.0000(0.0000) | Loss 3.4891(3.4891) | Error 0.0000(0.0000) Steps 598(598.92) | Grad Norm 0.0500(0.0589) | Total Time 14.00(14.00)\n",
      "Iter 3186 | Time 53.1403(51.9833) | Bit/dim 3.4911(3.4891) | Xent 0.0000(0.0000) | Loss 3.4911(3.4891) | Error 0.0000(0.0000) Steps 598(598.89) | Grad Norm 0.0480(0.0586) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0531 | Time 22.7451, Epoch Time 350.5761(351.7483), Bit/dim 3.4911(best: 3.4910), Xent 0.0000, Loss 3.4911, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3187 | Time 52.5082(51.9991) | Bit/dim 3.4879(3.4891) | Xent 0.0000(0.0000) | Loss 3.4879(3.4891) | Error 0.0000(0.0000) Steps 604(599.05) | Grad Norm 0.0537(0.0585) | Total Time 14.00(14.00)\n",
      "Iter 3188 | Time 50.3206(51.9487) | Bit/dim 3.4935(3.4892) | Xent 0.0000(0.0000) | Loss 3.4935(3.4892) | Error 0.0000(0.0000) Steps 598(599.01) | Grad Norm 0.0567(0.0584) | Total Time 14.00(14.00)\n",
      "Iter 3189 | Time 53.8942(52.0071) | Bit/dim 3.4738(3.4888) | Xent 0.0000(0.0000) | Loss 3.4738(3.4888) | Error 0.0000(0.0000) Steps 610(599.34) | Grad Norm 0.0518(0.0582) | Total Time 14.00(14.00)\n",
      "Iter 3190 | Time 51.2921(51.9856) | Bit/dim 3.4825(3.4886) | Xent 0.0000(0.0000) | Loss 3.4825(3.4886) | Error 0.0000(0.0000) Steps 598(599.30) | Grad Norm 0.0409(0.0577) | Total Time 14.00(14.00)\n",
      "Iter 3191 | Time 52.6433(52.0054) | Bit/dim 3.4926(3.4887) | Xent 0.0000(0.0000) | Loss 3.4926(3.4887) | Error 0.0000(0.0000) Steps 598(599.27) | Grad Norm 0.0551(0.0576) | Total Time 14.00(14.00)\n",
      "Iter 3192 | Time 51.2617(51.9830) | Bit/dim 3.5038(3.4892) | Xent 0.0000(0.0000) | Loss 3.5038(3.4892) | Error 0.0000(0.0000) Steps 598(599.23) | Grad Norm 0.0506(0.0574) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0532 | Time 23.1759, Epoch Time 350.9824(351.7253), Bit/dim 3.4903(best: 3.4910), Xent 0.0000, Loss 3.4903, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3193 | Time 53.6042(52.0317) | Bit/dim 3.4853(3.4890) | Xent 0.0000(0.0000) | Loss 3.4853(3.4890) | Error 0.0000(0.0000) Steps 598(599.19) | Grad Norm 0.0455(0.0570) | Total Time 14.00(14.00)\n",
      "Iter 3194 | Time 52.0656(52.0327) | Bit/dim 3.4954(3.4892) | Xent 0.0000(0.0000) | Loss 3.4954(3.4892) | Error 0.0000(0.0000) Steps 598(599.15) | Grad Norm 0.0487(0.0568) | Total Time 14.00(14.00)\n",
      "Iter 3195 | Time 52.3519(52.0423) | Bit/dim 3.4918(3.4893) | Xent 0.0000(0.0000) | Loss 3.4918(3.4893) | Error 0.0000(0.0000) Steps 598(599.12) | Grad Norm 0.0517(0.0566) | Total Time 14.00(14.00)\n",
      "Iter 3196 | Time 52.0452(52.0424) | Bit/dim 3.4849(3.4892) | Xent 0.0000(0.0000) | Loss 3.4849(3.4892) | Error 0.0000(0.0000) Steps 598(599.09) | Grad Norm 0.0451(0.0563) | Total Time 14.00(14.00)\n",
      "Iter 3197 | Time 51.6832(52.0316) | Bit/dim 3.4842(3.4890) | Xent 0.0000(0.0000) | Loss 3.4842(3.4890) | Error 0.0000(0.0000) Steps 598(599.05) | Grad Norm 0.0474(0.0560) | Total Time 14.00(14.00)\n",
      "Iter 3198 | Time 51.9716(52.0298) | Bit/dim 3.4909(3.4891) | Xent 0.0000(0.0000) | Loss 3.4909(3.4891) | Error 0.0000(0.0000) Steps 598(599.02) | Grad Norm 0.0462(0.0557) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0533 | Time 22.9907, Epoch Time 352.4494(351.7470), Bit/dim 3.4909(best: 3.4903), Xent 0.0000, Loss 3.4909, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3199 | Time 52.2711(52.0370) | Bit/dim 3.4825(3.4889) | Xent 0.0000(0.0000) | Loss 3.4825(3.4889) | Error 0.0000(0.0000) Steps 598(598.99) | Grad Norm 0.0558(0.0557) | Total Time 14.00(14.00)\n",
      "Iter 3200 | Time 51.4804(52.0203) | Bit/dim 3.4982(3.4892) | Xent 0.0000(0.0000) | Loss 3.4982(3.4892) | Error 0.0000(0.0000) Steps 598(598.96) | Grad Norm 0.0436(0.0554) | Total Time 14.00(14.00)\n",
      "Iter 3201 | Time 53.7215(52.0714) | Bit/dim 3.4819(3.4889) | Xent 0.0000(0.0000) | Loss 3.4819(3.4889) | Error 0.0000(0.0000) Steps 598(598.93) | Grad Norm 0.0563(0.0554) | Total Time 14.00(14.00)\n",
      "Iter 3202 | Time 53.1484(52.1037) | Bit/dim 3.5029(3.4894) | Xent 0.0000(0.0000) | Loss 3.5029(3.4894) | Error 0.0000(0.0000) Steps 598(598.90) | Grad Norm 0.0629(0.0556) | Total Time 14.00(14.00)\n",
      "Iter 3203 | Time 50.6697(52.0607) | Bit/dim 3.4882(3.4893) | Xent 0.0000(0.0000) | Loss 3.4882(3.4893) | Error 0.0000(0.0000) Steps 598(598.88) | Grad Norm 0.0581(0.0557) | Total Time 14.00(14.00)\n",
      "Iter 3204 | Time 50.2446(52.0062) | Bit/dim 3.4822(3.4891) | Xent 0.0000(0.0000) | Loss 3.4822(3.4891) | Error 0.0000(0.0000) Steps 604(599.03) | Grad Norm 0.0628(0.0559) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0534 | Time 23.0548, Epoch Time 350.5865(351.7122), Bit/dim 3.4918(best: 3.4903), Xent 0.0000, Loss 3.4918, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3205 | Time 50.3574(51.9567) | Bit/dim 3.4878(3.4891) | Xent 0.0000(0.0000) | Loss 3.4878(3.4891) | Error 0.0000(0.0000) Steps 598(599.00) | Grad Norm 0.0509(0.0558) | Total Time 14.00(14.00)\n",
      "Iter 3206 | Time 54.6047(52.0361) | Bit/dim 3.4885(3.4891) | Xent 0.0000(0.0000) | Loss 3.4885(3.4891) | Error 0.0000(0.0000) Steps 598(598.97) | Grad Norm 0.0522(0.0557) | Total Time 14.00(14.00)\n",
      "Iter 3207 | Time 49.7521(51.9676) | Bit/dim 3.4912(3.4891) | Xent 0.0000(0.0000) | Loss 3.4912(3.4891) | Error 0.0000(0.0000) Steps 604(599.12) | Grad Norm 0.0539(0.0556) | Total Time 14.00(14.00)\n",
      "Iter 3208 | Time 50.8066(51.9328) | Bit/dim 3.4908(3.4892) | Xent 0.0000(0.0000) | Loss 3.4908(3.4892) | Error 0.0000(0.0000) Steps 598(599.09) | Grad Norm 0.0485(0.0554) | Total Time 14.00(14.00)\n",
      "Iter 3209 | Time 51.6743(51.9250) | Bit/dim 3.4958(3.4894) | Xent 0.0000(0.0000) | Loss 3.4958(3.4894) | Error 0.0000(0.0000) Steps 598(599.06) | Grad Norm 0.0588(0.0555) | Total Time 14.00(14.00)\n",
      "Iter 3210 | Time 51.7319(51.9192) | Bit/dim 3.4841(3.4892) | Xent 0.0000(0.0000) | Loss 3.4841(3.4892) | Error 0.0000(0.0000) Steps 598(599.02) | Grad Norm 0.0505(0.0553) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0535 | Time 22.9726, Epoch Time 347.9003(351.5978), Bit/dim 3.4922(best: 3.4903), Xent 0.0000, Loss 3.4922, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3211 | Time 53.1999(51.9577) | Bit/dim 3.4872(3.4892) | Xent 0.0000(0.0000) | Loss 3.4872(3.4892) | Error 0.0000(0.0000) Steps 604(599.17) | Grad Norm 0.0599(0.0555) | Total Time 14.00(14.00)\n",
      "Iter 3212 | Time 52.6038(51.9770) | Bit/dim 3.4875(3.4891) | Xent 0.0000(0.0000) | Loss 3.4875(3.4891) | Error 0.0000(0.0000) Steps 598(599.14) | Grad Norm 0.0529(0.0554) | Total Time 14.00(14.00)\n",
      "Iter 3213 | Time 50.5325(51.9337) | Bit/dim 3.4767(3.4887) | Xent 0.0000(0.0000) | Loss 3.4767(3.4887) | Error 0.0000(0.0000) Steps 598(599.10) | Grad Norm 0.0485(0.0552) | Total Time 14.00(14.00)\n",
      "Iter 3214 | Time 54.3344(52.0057) | Bit/dim 3.4951(3.4889) | Xent 0.0000(0.0000) | Loss 3.4951(3.4889) | Error 0.0000(0.0000) Steps 598(599.07) | Grad Norm 0.0447(0.0549) | Total Time 14.00(14.00)\n",
      "Iter 3215 | Time 52.8797(52.0319) | Bit/dim 3.4979(3.4892) | Xent 0.0000(0.0000) | Loss 3.4979(3.4892) | Error 0.0000(0.0000) Steps 598(599.04) | Grad Norm 0.0482(0.0547) | Total Time 14.00(14.00)\n",
      "Iter 3216 | Time 52.7280(52.0528) | Bit/dim 3.4922(3.4893) | Xent 0.0000(0.0000) | Loss 3.4922(3.4893) | Error 0.0000(0.0000) Steps 598(599.01) | Grad Norm 0.0679(0.0551) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0536 | Time 23.2322, Epoch Time 355.0979(351.7028), Bit/dim 3.4915(best: 3.4903), Xent 0.0000, Loss 3.4915, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3217 | Time 53.6831(52.1017) | Bit/dim 3.4859(3.4892) | Xent 0.0000(0.0000) | Loss 3.4859(3.4892) | Error 0.0000(0.0000) Steps 598(598.98) | Grad Norm 0.0514(0.0550) | Total Time 14.00(14.00)\n",
      "Iter 3218 | Time 51.8165(52.0932) | Bit/dim 3.4847(3.4890) | Xent 0.0000(0.0000) | Loss 3.4847(3.4890) | Error 0.0000(0.0000) Steps 598(598.95) | Grad Norm 0.0650(0.0553) | Total Time 14.00(14.00)\n",
      "Iter 3219 | Time 49.8736(52.0266) | Bit/dim 3.4958(3.4892) | Xent 0.0000(0.0000) | Loss 3.4958(3.4892) | Error 0.0000(0.0000) Steps 598(598.92) | Grad Norm 0.0650(0.0556) | Total Time 14.00(14.00)\n",
      "Iter 3220 | Time 51.5123(52.0112) | Bit/dim 3.4787(3.4889) | Xent 0.0000(0.0000) | Loss 3.4787(3.4889) | Error 0.0000(0.0000) Steps 598(598.89) | Grad Norm 0.0467(0.0553) | Total Time 14.00(14.00)\n",
      "Iter 3221 | Time 52.5333(52.0268) | Bit/dim 3.4919(3.4890) | Xent 0.0000(0.0000) | Loss 3.4919(3.4890) | Error 0.0000(0.0000) Steps 598(598.86) | Grad Norm 0.0575(0.0554) | Total Time 14.00(14.00)\n",
      "Iter 3222 | Time 49.1259(51.9398) | Bit/dim 3.4938(3.4892) | Xent 0.0000(0.0000) | Loss 3.4938(3.4892) | Error 0.0000(0.0000) Steps 598(598.84) | Grad Norm 0.0478(0.0551) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0537 | Time 22.8815, Epoch Time 347.0751(351.5640), Bit/dim 3.4910(best: 3.4903), Xent 0.0000, Loss 3.4910, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3223 | Time 51.8442(51.9369) | Bit/dim 3.4817(3.4889) | Xent 0.0000(0.0000) | Loss 3.4817(3.4889) | Error 0.0000(0.0000) Steps 598(598.81) | Grad Norm 0.0421(0.0547) | Total Time 14.00(14.00)\n",
      "Iter 3224 | Time 51.7029(51.9299) | Bit/dim 3.4823(3.4887) | Xent 0.0000(0.0000) | Loss 3.4823(3.4887) | Error 0.0000(0.0000) Steps 598(598.79) | Grad Norm 0.0489(0.0546) | Total Time 14.00(14.00)\n",
      "Iter 3225 | Time 52.5942(51.9498) | Bit/dim 3.5017(3.4891) | Xent 0.0000(0.0000) | Loss 3.5017(3.4891) | Error 0.0000(0.0000) Steps 598(598.77) | Grad Norm 0.0468(0.0543) | Total Time 14.00(14.00)\n",
      "Iter 3226 | Time 52.7033(51.9724) | Bit/dim 3.4875(3.4891) | Xent 0.0000(0.0000) | Loss 3.4875(3.4891) | Error 0.0000(0.0000) Steps 598(598.74) | Grad Norm 0.0431(0.0540) | Total Time 14.00(14.00)\n",
      "Iter 3227 | Time 53.6296(52.0222) | Bit/dim 3.4906(3.4891) | Xent 0.0000(0.0000) | Loss 3.4906(3.4891) | Error 0.0000(0.0000) Steps 598(598.72) | Grad Norm 0.0438(0.0537) | Total Time 14.00(14.00)\n",
      "Iter 3228 | Time 52.3983(52.0334) | Bit/dim 3.4870(3.4891) | Xent 0.0000(0.0000) | Loss 3.4870(3.4891) | Error 0.0000(0.0000) Steps 604(598.88) | Grad Norm 0.0442(0.0534) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0538 | Time 22.6593, Epoch Time 353.3612(351.6179), Bit/dim 3.4912(best: 3.4903), Xent 0.0000, Loss 3.4912, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3229 | Time 50.3387(51.9826) | Bit/dim 3.4878(3.4890) | Xent 0.0000(0.0000) | Loss 3.4878(3.4890) | Error 0.0000(0.0000) Steps 604(599.03) | Grad Norm 0.0498(0.0533) | Total Time 14.00(14.00)\n",
      "Iter 3230 | Time 51.0711(51.9553) | Bit/dim 3.4883(3.4890) | Xent 0.0000(0.0000) | Loss 3.4883(3.4890) | Error 0.0000(0.0000) Steps 604(599.18) | Grad Norm 0.0467(0.0531) | Total Time 14.00(14.00)\n",
      "Iter 3231 | Time 50.6612(51.9164) | Bit/dim 3.4853(3.4889) | Xent 0.0000(0.0000) | Loss 3.4853(3.4889) | Error 0.0000(0.0000) Steps 598(599.15) | Grad Norm 0.0407(0.0527) | Total Time 14.00(14.00)\n",
      "Iter 3232 | Time 51.0854(51.8915) | Bit/dim 3.4892(3.4889) | Xent 0.0000(0.0000) | Loss 3.4892(3.4889) | Error 0.0000(0.0000) Steps 598(599.11) | Grad Norm 0.0449(0.0525) | Total Time 14.00(14.00)\n",
      "Iter 3233 | Time 50.9590(51.8635) | Bit/dim 3.4881(3.4889) | Xent 0.0000(0.0000) | Loss 3.4881(3.4889) | Error 0.0000(0.0000) Steps 598(599.08) | Grad Norm 0.0454(0.0523) | Total Time 14.00(14.00)\n",
      "Iter 3234 | Time 54.0385(51.9288) | Bit/dim 3.4932(3.4890) | Xent 0.0000(0.0000) | Loss 3.4932(3.4890) | Error 0.0000(0.0000) Steps 598(599.05) | Grad Norm 0.0695(0.0528) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0539 | Time 22.9033, Epoch Time 346.6504(351.4689), Bit/dim 3.4915(best: 3.4903), Xent 0.0000, Loss 3.4915, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3235 | Time 49.9334(51.8689) | Bit/dim 3.4837(3.4888) | Xent 0.0000(0.0000) | Loss 3.4837(3.4888) | Error 0.0000(0.0000) Steps 598(599.01) | Grad Norm 0.0614(0.0531) | Total Time 14.00(14.00)\n",
      "Iter 3236 | Time 51.9109(51.8702) | Bit/dim 3.4969(3.4891) | Xent 0.0000(0.0000) | Loss 3.4969(3.4891) | Error 0.0000(0.0000) Steps 598(598.98) | Grad Norm 0.0518(0.0530) | Total Time 14.00(14.00)\n",
      "Iter 3237 | Time 49.7523(51.8066) | Bit/dim 3.4842(3.4889) | Xent 0.0000(0.0000) | Loss 3.4842(3.4889) | Error 0.0000(0.0000) Steps 598(598.95) | Grad Norm 0.0487(0.0529) | Total Time 14.00(14.00)\n",
      "Iter 3238 | Time 53.8818(51.8689) | Bit/dim 3.4829(3.4888) | Xent 0.0000(0.0000) | Loss 3.4829(3.4888) | Error 0.0000(0.0000) Steps 604(599.11) | Grad Norm 0.0491(0.0528) | Total Time 14.00(14.00)\n",
      "Iter 3239 | Time 53.4976(51.9178) | Bit/dim 3.4910(3.4888) | Xent 0.0000(0.0000) | Loss 3.4910(3.4888) | Error 0.0000(0.0000) Steps 598(599.07) | Grad Norm 0.0488(0.0526) | Total Time 14.00(14.00)\n",
      "Iter 3240 | Time 52.7424(51.9425) | Bit/dim 3.4978(3.4891) | Xent 0.0000(0.0000) | Loss 3.4978(3.4891) | Error 0.0000(0.0000) Steps 598(599.04) | Grad Norm 0.0438(0.0524) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0540 | Time 23.0303, Epoch Time 350.8025(351.4489), Bit/dim 3.4912(best: 3.4903), Xent 0.0000, Loss 3.4912, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3241 | Time 54.4664(52.0182) | Bit/dim 3.4887(3.4891) | Xent 0.0000(0.0000) | Loss 3.4887(3.4891) | Error 0.0000(0.0000) Steps 598(599.01) | Grad Norm 0.0414(0.0521) | Total Time 14.00(14.00)\n",
      "Iter 3242 | Time 50.4253(51.9704) | Bit/dim 3.4866(3.4890) | Xent 0.0000(0.0000) | Loss 3.4866(3.4890) | Error 0.0000(0.0000) Steps 604(599.16) | Grad Norm 0.0489(0.0520) | Total Time 14.00(14.00)\n",
      "Iter 3243 | Time 53.4458(52.0147) | Bit/dim 3.4856(3.4889) | Xent 0.0000(0.0000) | Loss 3.4856(3.4889) | Error 0.0000(0.0000) Steps 598(599.12) | Grad Norm 0.0447(0.0517) | Total Time 14.00(14.00)\n",
      "Iter 3244 | Time 53.8011(52.0683) | Bit/dim 3.4923(3.4890) | Xent 0.0000(0.0000) | Loss 3.4923(3.4890) | Error 0.0000(0.0000) Steps 604(599.27) | Grad Norm 0.0568(0.0519) | Total Time 14.00(14.00)\n",
      "Iter 3245 | Time 53.2418(52.1035) | Bit/dim 3.5000(3.4893) | Xent 0.0000(0.0000) | Loss 3.5000(3.4893) | Error 0.0000(0.0000) Steps 598(599.23) | Grad Norm 0.0509(0.0519) | Total Time 14.00(14.00)\n",
      "Iter 3246 | Time 50.6448(52.0597) | Bit/dim 3.4813(3.4891) | Xent 0.0000(0.0000) | Loss 3.4813(3.4891) | Error 0.0000(0.0000) Steps 598(599.20) | Grad Norm 0.0572(0.0520) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0541 | Time 22.8622, Epoch Time 354.3063(351.5346), Bit/dim 3.4914(best: 3.4903), Xent 0.0000, Loss 3.4914, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3247 | Time 52.5099(52.0732) | Bit/dim 3.4860(3.4890) | Xent 0.0000(0.0000) | Loss 3.4860(3.4890) | Error 0.0000(0.0000) Steps 598(599.16) | Grad Norm 0.0395(0.0516) | Total Time 14.00(14.00)\n",
      "Iter 3248 | Time 51.7263(52.0628) | Bit/dim 3.4854(3.4889) | Xent 0.0000(0.0000) | Loss 3.4854(3.4889) | Error 0.0000(0.0000) Steps 598(599.12) | Grad Norm 0.0432(0.0514) | Total Time 14.00(14.00)\n",
      "Iter 3249 | Time 54.2658(52.1289) | Bit/dim 3.4856(3.4888) | Xent 0.0000(0.0000) | Loss 3.4856(3.4888) | Error 0.0000(0.0000) Steps 598(599.09) | Grad Norm 0.0575(0.0516) | Total Time 14.00(14.00)\n",
      "Iter 3250 | Time 52.2682(52.1331) | Bit/dim 3.5027(3.4892) | Xent 0.0000(0.0000) | Loss 3.5027(3.4892) | Error 0.0000(0.0000) Steps 598(599.06) | Grad Norm 0.0390(0.0512) | Total Time 14.00(14.00)\n",
      "Iter 3251 | Time 52.4461(52.1425) | Bit/dim 3.4902(3.4892) | Xent 0.0000(0.0000) | Loss 3.4902(3.4892) | Error 0.0000(0.0000) Steps 604(599.21) | Grad Norm 0.0811(0.0521) | Total Time 14.00(14.00)\n",
      "Iter 3252 | Time 50.8977(52.1051) | Bit/dim 3.4823(3.4890) | Xent 0.0000(0.0000) | Loss 3.4823(3.4890) | Error 0.0000(0.0000) Steps 598(599.17) | Grad Norm 0.0557(0.0522) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0542 | Time 22.7488, Epoch Time 352.7618(351.5714), Bit/dim 3.4902(best: 3.4903), Xent 0.0000, Loss 3.4902, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3253 | Time 54.8079(52.1862) | Bit/dim 3.4842(3.4889) | Xent 0.0000(0.0000) | Loss 3.4842(3.4889) | Error 0.0000(0.0000) Steps 604(599.32) | Grad Norm 0.0446(0.0520) | Total Time 14.00(14.00)\n",
      "Iter 3254 | Time 51.7733(52.1738) | Bit/dim 3.4936(3.4890) | Xent 0.0000(0.0000) | Loss 3.4936(3.4890) | Error 0.0000(0.0000) Steps 598(599.28) | Grad Norm 0.0583(0.0522) | Total Time 14.00(14.00)\n",
      "Iter 3255 | Time 53.0882(52.2013) | Bit/dim 3.4963(3.4893) | Xent 0.0000(0.0000) | Loss 3.4963(3.4893) | Error 0.0000(0.0000) Steps 598(599.24) | Grad Norm 0.0690(0.0527) | Total Time 14.00(14.00)\n",
      "Iter 3256 | Time 52.9501(52.2237) | Bit/dim 3.4927(3.4894) | Xent 0.0000(0.0000) | Loss 3.4927(3.4894) | Error 0.0000(0.0000) Steps 598(599.20) | Grad Norm 0.0444(0.0524) | Total Time 14.00(14.00)\n",
      "Iter 3257 | Time 50.4015(52.1691) | Bit/dim 3.4851(3.4892) | Xent 0.0000(0.0000) | Loss 3.4851(3.4892) | Error 0.0000(0.0000) Steps 598(599.16) | Grad Norm 0.0536(0.0525) | Total Time 14.00(14.00)\n",
      "Iter 3258 | Time 51.7618(52.1568) | Bit/dim 3.4809(3.4890) | Xent 0.0000(0.0000) | Loss 3.4809(3.4890) | Error 0.0000(0.0000) Steps 604(599.31) | Grad Norm 0.0589(0.0526) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0543 | Time 23.2310, Epoch Time 353.9562(351.6430), Bit/dim 3.4916(best: 3.4902), Xent 0.0000, Loss 3.4916, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3259 | Time 50.1763(52.0974) | Bit/dim 3.4904(3.4890) | Xent 0.0000(0.0000) | Loss 3.4904(3.4890) | Error 0.0000(0.0000) Steps 598(599.27) | Grad Norm 0.0417(0.0523) | Total Time 14.00(14.00)\n",
      "Iter 3260 | Time 53.3213(52.1341) | Bit/dim 3.4833(3.4888) | Xent 0.0000(0.0000) | Loss 3.4833(3.4888) | Error 0.0000(0.0000) Steps 598(599.23) | Grad Norm 0.0410(0.0520) | Total Time 14.00(14.00)\n",
      "Iter 3261 | Time 53.0090(52.1604) | Bit/dim 3.4837(3.4887) | Xent 0.0000(0.0000) | Loss 3.4837(3.4887) | Error 0.0000(0.0000) Steps 604(599.38) | Grad Norm 0.0682(0.0525) | Total Time 14.00(14.00)\n",
      "Iter 3262 | Time 50.0419(52.0968) | Bit/dim 3.4955(3.4889) | Xent 0.0000(0.0000) | Loss 3.4955(3.4889) | Error 0.0000(0.0000) Steps 598(599.33) | Grad Norm 0.0472(0.0523) | Total Time 14.00(14.00)\n",
      "Iter 3263 | Time 50.0675(52.0360) | Bit/dim 3.4830(3.4887) | Xent 0.0000(0.0000) | Loss 3.4830(3.4887) | Error 0.0000(0.0000) Steps 598(599.29) | Grad Norm 0.0460(0.0521) | Total Time 14.00(14.00)\n",
      "Iter 3264 | Time 53.1180(52.0684) | Bit/dim 3.4980(3.4890) | Xent 0.0000(0.0000) | Loss 3.4980(3.4890) | Error 0.0000(0.0000) Steps 604(599.44) | Grad Norm 0.0701(0.0527) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0544 | Time 23.0498, Epoch Time 348.5473(351.5501), Bit/dim 3.4908(best: 3.4902), Xent 0.0000, Loss 3.4908, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3265 | Time 52.2543(52.0740) | Bit/dim 3.4912(3.4891) | Xent 0.0000(0.0000) | Loss 3.4912(3.4891) | Error 0.0000(0.0000) Steps 604(599.57) | Grad Norm 0.0467(0.0525) | Total Time 14.00(14.00)\n",
      "Iter 3266 | Time 53.3140(52.1112) | Bit/dim 3.4896(3.4891) | Xent 0.0000(0.0000) | Loss 3.4896(3.4891) | Error 0.0000(0.0000) Steps 604(599.70) | Grad Norm 0.0528(0.0525) | Total Time 14.00(14.00)\n",
      "Iter 3267 | Time 49.9990(52.0478) | Bit/dim 3.4879(3.4890) | Xent 0.0000(0.0000) | Loss 3.4879(3.4890) | Error 0.0000(0.0000) Steps 598(599.65) | Grad Norm 0.0604(0.0527) | Total Time 14.00(14.00)\n",
      "Iter 3268 | Time 52.7383(52.0685) | Bit/dim 3.4917(3.4891) | Xent 0.0000(0.0000) | Loss 3.4917(3.4891) | Error 0.0000(0.0000) Steps 598(599.60) | Grad Norm 0.0753(0.0534) | Total Time 14.00(14.00)\n",
      "Iter 3269 | Time 53.3240(52.1062) | Bit/dim 3.4843(3.4890) | Xent 0.0000(0.0000) | Loss 3.4843(3.4890) | Error 0.0000(0.0000) Steps 604(599.74) | Grad Norm 0.0506(0.0533) | Total Time 14.00(14.00)\n",
      "Iter 3270 | Time 52.0614(52.1049) | Bit/dim 3.4872(3.4889) | Xent 0.0000(0.0000) | Loss 3.4872(3.4889) | Error 0.0000(0.0000) Steps 598(599.68) | Grad Norm 0.0766(0.0540) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0545 | Time 22.9433, Epoch Time 352.2296(351.5705), Bit/dim 3.4904(best: 3.4902), Xent 0.0000, Loss 3.4904, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3271 | Time 51.0338(52.0727) | Bit/dim 3.4969(3.4892) | Xent 0.0000(0.0000) | Loss 3.4969(3.4892) | Error 0.0000(0.0000) Steps 598(599.63) | Grad Norm 0.0787(0.0548) | Total Time 14.00(14.00)\n",
      "Iter 3272 | Time 51.5228(52.0562) | Bit/dim 3.4902(3.4892) | Xent 0.0000(0.0000) | Loss 3.4902(3.4892) | Error 0.0000(0.0000) Steps 604(599.76) | Grad Norm 0.0477(0.0546) | Total Time 14.00(14.00)\n",
      "Iter 3273 | Time 53.7843(52.1081) | Bit/dim 3.4911(3.4893) | Xent 0.0000(0.0000) | Loss 3.4911(3.4893) | Error 0.0000(0.0000) Steps 598(599.71) | Grad Norm 0.0909(0.0556) | Total Time 14.00(14.00)\n",
      "Iter 3274 | Time 50.1550(52.0495) | Bit/dim 3.4816(3.4890) | Xent 0.0000(0.0000) | Loss 3.4816(3.4890) | Error 0.0000(0.0000) Steps 598(599.66) | Grad Norm 0.0845(0.0565) | Total Time 14.00(14.00)\n",
      "Iter 3275 | Time 50.1873(51.9936) | Bit/dim 3.4894(3.4890) | Xent 0.0000(0.0000) | Loss 3.4894(3.4890) | Error 0.0000(0.0000) Steps 604(599.79) | Grad Norm 0.0520(0.0564) | Total Time 14.00(14.00)\n",
      "Iter 3276 | Time 53.2128(52.0302) | Bit/dim 3.4833(3.4889) | Xent 0.0000(0.0000) | Loss 3.4833(3.4889) | Error 0.0000(0.0000) Steps 598(599.74) | Grad Norm 0.0547(0.0563) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0546 | Time 23.0095, Epoch Time 348.7951(351.4872), Bit/dim 3.4913(best: 3.4902), Xent 0.0000, Loss 3.4913, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3277 | Time 51.2351(52.0063) | Bit/dim 3.4903(3.4889) | Xent 0.0000(0.0000) | Loss 3.4903(3.4889) | Error 0.0000(0.0000) Steps 598(599.68) | Grad Norm 0.0675(0.0567) | Total Time 14.00(14.00)\n",
      "Iter 3278 | Time 50.5097(51.9614) | Bit/dim 3.4837(3.4887) | Xent 0.0000(0.0000) | Loss 3.4837(3.4887) | Error 0.0000(0.0000) Steps 598(599.63) | Grad Norm 0.0512(0.0565) | Total Time 14.00(14.00)\n",
      "Iter 3279 | Time 52.8606(51.9884) | Bit/dim 3.4924(3.4889) | Xent 0.0000(0.0000) | Loss 3.4924(3.4889) | Error 0.0000(0.0000) Steps 598(599.58) | Grad Norm 0.0504(0.0563) | Total Time 14.00(14.00)\n",
      "Iter 3280 | Time 52.7788(52.0121) | Bit/dim 3.4900(3.4889) | Xent 0.0000(0.0000) | Loss 3.4900(3.4889) | Error 0.0000(0.0000) Steps 604(599.72) | Grad Norm 0.0635(0.0565) | Total Time 14.00(14.00)\n",
      "Iter 3281 | Time 50.6109(51.9701) | Bit/dim 3.4849(3.4888) | Xent 0.0000(0.0000) | Loss 3.4849(3.4888) | Error 0.0000(0.0000) Steps 598(599.67) | Grad Norm 0.0677(0.0569) | Total Time 14.00(14.00)\n",
      "Iter 3283 | Time 54.6125(52.0031) | Bit/dim 3.4893(3.4888) | Xent 0.0000(0.0000) | Loss 3.4893(3.4888) | Error 0.0000(0.0000) Steps 598(599.57) | Grad Norm 0.0601(0.0565) | Total Time 14.00(14.00)\n",
      "Iter 3284 | Time 50.8670(51.9690) | Bit/dim 3.4844(3.4887) | Xent 0.0000(0.0000) | Loss 3.4844(3.4887) | Error 0.0000(0.0000) Steps 598(599.52) | Grad Norm 0.0485(0.0563) | Total Time 14.00(14.00)\n",
      "Iter 3285 | Time 53.9355(52.0280) | Bit/dim 3.4907(3.4887) | Xent 0.0000(0.0000) | Loss 3.4907(3.4887) | Error 0.0000(0.0000) Steps 598(599.47) | Grad Norm 0.0608(0.0564) | Total Time 14.00(14.00)\n",
      "Iter 3286 | Time 49.9328(51.9652) | Bit/dim 3.4867(3.4887) | Xent 0.0000(0.0000) | Loss 3.4867(3.4887) | Error 0.0000(0.0000) Steps 598(599.43) | Grad Norm 0.0508(0.0562) | Total Time 14.00(14.00)\n",
      "Iter 3287 | Time 51.8649(51.9622) | Bit/dim 3.4760(3.4883) | Xent 0.0000(0.0000) | Loss 3.4760(3.4883) | Error 0.0000(0.0000) Steps 598(599.39) | Grad Norm 0.0611(0.0564) | Total Time 14.00(14.00)\n",
      "Iter 3288 | Time 52.5829(51.9808) | Bit/dim 3.5030(3.4887) | Xent 0.0000(0.0000) | Loss 3.5030(3.4887) | Error 0.0000(0.0000) Steps 598(599.35) | Grad Norm 0.0523(0.0562) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0548 | Time 22.6018, Epoch Time 352.0780(351.3870), Bit/dim 3.4905(best: 3.4902), Xent 0.0000, Loss 3.4905, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3289 | Time 52.1073(51.9846) | Bit/dim 3.4844(3.4886) | Xent 0.0000(0.0000) | Loss 3.4844(3.4886) | Error 0.0000(0.0000) Steps 598(599.31) | Grad Norm 0.0453(0.0559) | Total Time 14.00(14.00)\n",
      "Iter 3290 | Time 52.9501(52.0136) | Bit/dim 3.4853(3.4885) | Xent 0.0000(0.0000) | Loss 3.4853(3.4885) | Error 0.0000(0.0000) Steps 598(599.27) | Grad Norm 0.0585(0.0560) | Total Time 14.00(14.00)\n",
      "Iter 3291 | Time 50.3129(51.9625) | Bit/dim 3.4867(3.4885) | Xent 0.0000(0.0000) | Loss 3.4867(3.4885) | Error 0.0000(0.0000) Steps 604(599.41) | Grad Norm 0.0509(0.0558) | Total Time 14.00(14.00)\n",
      "Iter 3292 | Time 49.5639(51.8906) | Bit/dim 3.4961(3.4887) | Xent 0.0000(0.0000) | Loss 3.4961(3.4887) | Error 0.0000(0.0000) Steps 598(599.37) | Grad Norm 0.0649(0.0561) | Total Time 14.00(14.00)\n",
      "Iter 3293 | Time 50.8575(51.8596) | Bit/dim 3.4912(3.4888) | Xent 0.0000(0.0000) | Loss 3.4912(3.4888) | Error 0.0000(0.0000) Steps 598(599.33) | Grad Norm 0.0567(0.0561) | Total Time 14.00(14.00)\n",
      "Iter 3294 | Time 51.5733(51.8510) | Bit/dim 3.4861(3.4887) | Xent 0.0000(0.0000) | Loss 3.4861(3.4887) | Error 0.0000(0.0000) Steps 598(599.29) | Grad Norm 0.0547(0.0561) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0549 | Time 22.9923, Epoch Time 346.0515(351.2270), Bit/dim 3.4909(best: 3.4902), Xent 0.0000, Loss 3.4909, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3295 | Time 50.0814(51.7979) | Bit/dim 3.4818(3.4885) | Xent 0.0000(0.0000) | Loss 3.4818(3.4885) | Error 0.0000(0.0000) Steps 598(599.25) | Grad Norm 0.0498(0.0559) | Total Time 14.00(14.00)\n",
      "Iter 3296 | Time 52.5450(51.8203) | Bit/dim 3.4960(3.4887) | Xent 0.0000(0.0000) | Loss 3.4960(3.4887) | Error 0.0000(0.0000) Steps 598(599.21) | Grad Norm 0.0520(0.0558) | Total Time 14.00(14.00)\n",
      "Iter 3297 | Time 50.9277(51.7935) | Bit/dim 3.4883(3.4887) | Xent 0.0000(0.0000) | Loss 3.4883(3.4887) | Error 0.0000(0.0000) Steps 598(599.17) | Grad Norm 0.0614(0.0560) | Total Time 14.00(14.00)\n",
      "Iter 3298 | Time 53.3918(51.8415) | Bit/dim 3.4864(3.4886) | Xent 0.0000(0.0000) | Loss 3.4864(3.4886) | Error 0.0000(0.0000) Steps 598(599.14) | Grad Norm 0.0569(0.0560) | Total Time 14.00(14.00)\n",
      "Iter 3299 | Time 52.8058(51.8704) | Bit/dim 3.4812(3.4884) | Xent 0.0000(0.0000) | Loss 3.4812(3.4884) | Error 0.0000(0.0000) Steps 598(599.10) | Grad Norm 0.0526(0.0559) | Total Time 14.00(14.00)\n",
      "Iter 3300 | Time 51.4570(51.8580) | Bit/dim 3.4916(3.4885) | Xent 0.0000(0.0000) | Loss 3.4916(3.4885) | Error 0.0000(0.0000) Steps 598(599.07) | Grad Norm 0.0797(0.0566) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0550 | Time 22.9143, Epoch Time 349.6632(351.1801), Bit/dim 3.4908(best: 3.4902), Xent 0.0000, Loss 3.4908, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3301 | Time 52.7457(51.8846) | Bit/dim 3.4861(3.4884) | Xent 0.0000(0.0000) | Loss 3.4861(3.4884) | Error 0.0000(0.0000) Steps 598(599.04) | Grad Norm 0.0673(0.0569) | Total Time 14.00(14.00)\n",
      "Iter 3302 | Time 50.9260(51.8559) | Bit/dim 3.5000(3.4888) | Xent 0.0000(0.0000) | Loss 3.5000(3.4888) | Error 0.0000(0.0000) Steps 598(599.01) | Grad Norm 0.0542(0.0568) | Total Time 14.00(14.00)\n",
      "Iter 3303 | Time 51.5938(51.8480) | Bit/dim 3.4886(3.4888) | Xent 0.0000(0.0000) | Loss 3.4886(3.4888) | Error 0.0000(0.0000) Steps 598(598.98) | Grad Norm 0.0752(0.0574) | Total Time 14.00(14.00)\n",
      "Iter 3304 | Time 51.9531(51.8512) | Bit/dim 3.4801(3.4885) | Xent 0.0000(0.0000) | Loss 3.4801(3.4885) | Error 0.0000(0.0000) Steps 592(598.77) | Grad Norm 0.0618(0.0575) | Total Time 14.00(14.00)\n",
      "Iter 3305 | Time 52.1139(51.8591) | Bit/dim 3.4778(3.4882) | Xent 0.0000(0.0000) | Loss 3.4778(3.4882) | Error 0.0000(0.0000) Steps 604(598.92) | Grad Norm 0.0460(0.0572) | Total Time 14.00(14.00)\n",
      "Iter 3306 | Time 49.9111(51.8006) | Bit/dim 3.4963(3.4884) | Xent 0.0000(0.0000) | Loss 3.4963(3.4884) | Error 0.0000(0.0000) Steps 598(598.90) | Grad Norm 0.0657(0.0574) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0551 | Time 22.9549, Epoch Time 347.7606(351.0775), Bit/dim 3.4905(best: 3.4902), Xent 0.0000, Loss 3.4905, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3307 | Time 52.8627(51.8325) | Bit/dim 3.4778(3.4881) | Xent 0.0000(0.0000) | Loss 3.4778(3.4881) | Error 0.0000(0.0000) Steps 604(599.05) | Grad Norm 0.0638(0.0576) | Total Time 14.00(14.00)\n",
      "Iter 3308 | Time 53.2294(51.8744) | Bit/dim 3.4876(3.4881) | Xent 0.0000(0.0000) | Loss 3.4876(3.4881) | Error 0.0000(0.0000) Steps 598(599.02) | Grad Norm 0.0470(0.0573) | Total Time 14.00(14.00)\n",
      "Iter 3309 | Time 50.8575(51.8439) | Bit/dim 3.4987(3.4884) | Xent 0.0000(0.0000) | Loss 3.4987(3.4884) | Error 0.0000(0.0000) Steps 598(598.99) | Grad Norm 0.0535(0.0572) | Total Time 14.00(14.00)\n",
      "Iter 3310 | Time 51.8435(51.8439) | Bit/dim 3.4871(3.4884) | Xent 0.0000(0.0000) | Loss 3.4871(3.4884) | Error 0.0000(0.0000) Steps 598(598.96) | Grad Norm 0.0501(0.0570) | Total Time 14.00(14.00)\n",
      "Iter 3311 | Time 53.0498(51.8801) | Bit/dim 3.4848(3.4883) | Xent 0.0000(0.0000) | Loss 3.4848(3.4883) | Error 0.0000(0.0000) Steps 604(599.11) | Grad Norm 0.0441(0.0566) | Total Time 14.00(14.00)\n",
      "Iter 3312 | Time 51.9176(51.8812) | Bit/dim 3.4968(3.4885) | Xent 0.0000(0.0000) | Loss 3.4968(3.4885) | Error 0.0000(0.0000) Steps 598(599.08) | Grad Norm 0.0462(0.0563) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0552 | Time 23.1491, Epoch Time 352.4580(351.1189), Bit/dim 3.4912(best: 3.4902), Xent 0.0000, Loss 3.4912, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3313 | Time 52.3816(51.8962) | Bit/dim 3.4945(3.4887) | Xent 0.0000(0.0000) | Loss 3.4945(3.4887) | Error 0.0000(0.0000) Steps 598(599.04) | Grad Norm 0.0524(0.0562) | Total Time 14.00(14.00)\n",
      "Iter 3314 | Time 52.8763(51.9256) | Bit/dim 3.4786(3.4884) | Xent 0.0000(0.0000) | Loss 3.4786(3.4884) | Error 0.0000(0.0000) Steps 598(599.01) | Grad Norm 0.0417(0.0557) | Total Time 14.00(14.00)\n",
      "Iter 3315 | Time 50.6052(51.8860) | Bit/dim 3.4906(3.4885) | Xent 0.0000(0.0000) | Loss 3.4906(3.4885) | Error 0.0000(0.0000) Steps 598(598.98) | Grad Norm 0.0483(0.0555) | Total Time 14.00(14.00)\n",
      "Iter 3316 | Time 49.4682(51.8134) | Bit/dim 3.4819(3.4883) | Xent 0.0000(0.0000) | Loss 3.4819(3.4883) | Error 0.0000(0.0000) Steps 604(599.13) | Grad Norm 0.0415(0.0551) | Total Time 14.00(14.00)\n",
      "Iter 3317 | Time 50.2122(51.7654) | Bit/dim 3.4841(3.4881) | Xent 0.0000(0.0000) | Loss 3.4841(3.4881) | Error 0.0000(0.0000) Steps 598(599.10) | Grad Norm 0.0537(0.0550) | Total Time 14.00(14.00)\n",
      "Iter 3318 | Time 53.8282(51.8273) | Bit/dim 3.4992(3.4885) | Xent 0.0000(0.0000) | Loss 3.4992(3.4885) | Error 0.0000(0.0000) Steps 604(599.25) | Grad Norm 0.0420(0.0547) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0553 | Time 22.7890, Epoch Time 348.4450(351.0387), Bit/dim 3.4906(best: 3.4902), Xent 0.0000, Loss 3.4906, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3319 | Time 53.8234(51.8872) | Bit/dim 3.4905(3.4885) | Xent 0.0000(0.0000) | Loss 3.4905(3.4885) | Error 0.0000(0.0000) Steps 604(599.39) | Grad Norm 0.0450(0.0544) | Total Time 14.00(14.00)\n",
      "Iter 3320 | Time 54.0937(51.9534) | Bit/dim 3.4898(3.4886) | Xent 0.0000(0.0000) | Loss 3.4898(3.4886) | Error 0.0000(0.0000) Steps 598(599.35) | Grad Norm 0.0658(0.0547) | Total Time 14.00(14.00)\n",
      "Iter 3321 | Time 50.9540(51.9234) | Bit/dim 3.4816(3.4884) | Xent 0.0000(0.0000) | Loss 3.4816(3.4884) | Error 0.0000(0.0000) Steps 598(599.31) | Grad Norm 0.0570(0.0548) | Total Time 14.00(14.00)\n",
      "Iter 3322 | Time 52.5016(51.9407) | Bit/dim 3.4897(3.4884) | Xent 0.0000(0.0000) | Loss 3.4897(3.4884) | Error 0.0000(0.0000) Steps 604(599.45) | Grad Norm 0.0792(0.0555) | Total Time 14.00(14.00)\n",
      "Iter 3323 | Time 50.1160(51.8860) | Bit/dim 3.4864(3.4883) | Xent 0.0000(0.0000) | Loss 3.4864(3.4883) | Error 0.0000(0.0000) Steps 598(599.40) | Grad Norm 0.0827(0.0563) | Total Time 14.00(14.00)\n",
      "Iter 3324 | Time 52.0215(51.8901) | Bit/dim 3.4855(3.4883) | Xent 0.0000(0.0000) | Loss 3.4855(3.4883) | Error 0.0000(0.0000) Steps 598(599.36) | Grad Norm 0.0469(0.0560) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0554 | Time 22.9130, Epoch Time 352.0368(351.0686), Bit/dim 3.4908(best: 3.4902), Xent 0.0000, Loss 3.4908, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3325 | Time 49.2635(51.8113) | Bit/dim 3.4952(3.4885) | Xent 0.0000(0.0000) | Loss 3.4952(3.4885) | Error 0.0000(0.0000) Steps 598(599.32) | Grad Norm 0.0824(0.0568) | Total Time 14.00(14.00)\n",
      "Iter 3326 | Time 52.5403(51.8331) | Bit/dim 3.4837(3.4883) | Xent 0.0000(0.0000) | Loss 3.4837(3.4883) | Error 0.0000(0.0000) Steps 598(599.28) | Grad Norm 0.0954(0.0580) | Total Time 14.00(14.00)\n",
      "Iter 3327 | Time 52.9903(51.8679) | Bit/dim 3.4934(3.4885) | Xent 0.0000(0.0000) | Loss 3.4934(3.4885) | Error 0.0000(0.0000) Steps 604(599.42) | Grad Norm 0.0598(0.0580) | Total Time 14.00(14.00)\n",
      "Iter 3328 | Time 54.5489(51.9483) | Bit/dim 3.4828(3.4883) | Xent 0.0000(0.0000) | Loss 3.4828(3.4883) | Error 0.0000(0.0000) Steps 598(599.38) | Grad Norm 0.0752(0.0586) | Total Time 14.00(14.00)\n",
      "Iter 3329 | Time 50.5130(51.9052) | Bit/dim 3.4838(3.4882) | Xent 0.0000(0.0000) | Loss 3.4838(3.4882) | Error 0.0000(0.0000) Steps 598(599.34) | Grad Norm 0.1213(0.0604) | Total Time 14.00(14.00)\n",
      "Iter 3330 | Time 52.4702(51.9222) | Bit/dim 3.4912(3.4883) | Xent 0.0000(0.0000) | Loss 3.4912(3.4883) | Error 0.0000(0.0000) Steps 598(599.30) | Grad Norm 0.0536(0.0602) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0555 | Time 23.0313, Epoch Time 351.1413(351.0708), Bit/dim 3.4906(best: 3.4902), Xent 0.0000, Loss 3.4906, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3331 | Time 53.1346(51.9585) | Bit/dim 3.4772(3.4879) | Xent 0.0000(0.0000) | Loss 3.4772(3.4879) | Error 0.0000(0.0000) Steps 598(599.26) | Grad Norm 0.0575(0.0602) | Total Time 14.00(14.00)\n",
      "Iter 3332 | Time 52.5099(51.9751) | Bit/dim 3.4920(3.4881) | Xent 0.0000(0.0000) | Loss 3.4920(3.4881) | Error 0.0000(0.0000) Steps 598(599.22) | Grad Norm 0.0814(0.0608) | Total Time 14.00(14.00)\n",
      "Iter 3333 | Time 50.1890(51.9215) | Bit/dim 3.4845(3.4879) | Xent 0.0000(0.0000) | Loss 3.4845(3.4879) | Error 0.0000(0.0000) Steps 598(599.19) | Grad Norm 0.0783(0.0613) | Total Time 14.00(14.00)\n",
      "Iter 3334 | Time 53.3357(51.9639) | Bit/dim 3.5002(3.4883) | Xent 0.0000(0.0000) | Loss 3.5002(3.4883) | Error 0.0000(0.0000) Steps 598(599.15) | Grad Norm 0.0524(0.0610) | Total Time 14.00(14.00)\n",
      "Iter 3335 | Time 52.6004(51.9830) | Bit/dim 3.4817(3.4881) | Xent 0.0000(0.0000) | Loss 3.4817(3.4881) | Error 0.0000(0.0000) Steps 598(599.12) | Grad Norm 0.0657(0.0612) | Total Time 14.00(14.00)\n",
      "Iter 3336 | Time 52.1916(51.9893) | Bit/dim 3.4900(3.4882) | Xent 0.0000(0.0000) | Loss 3.4900(3.4882) | Error 0.0000(0.0000) Steps 604(599.26) | Grad Norm 0.0814(0.0618) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0556 | Time 22.8662, Epoch Time 352.5071(351.1139), Bit/dim 3.4906(best: 3.4902), Xent 0.0000, Loss 3.4906, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3337 | Time 52.1179(51.9931) | Bit/dim 3.4851(3.4881) | Xent 0.0000(0.0000) | Loss 3.4851(3.4881) | Error 0.0000(0.0000) Steps 598(599.22) | Grad Norm 0.0477(0.0614) | Total Time 14.00(14.00)\n",
      "Iter 3338 | Time 52.4243(52.0061) | Bit/dim 3.4838(3.4880) | Xent 0.0000(0.0000) | Loss 3.4838(3.4880) | Error 0.0000(0.0000) Steps 598(599.19) | Grad Norm 0.0582(0.0613) | Total Time 14.00(14.00)\n",
      "Iter 3339 | Time 53.1498(52.0404) | Bit/dim 3.5000(3.4883) | Xent 0.0000(0.0000) | Loss 3.5000(3.4883) | Error 0.0000(0.0000) Steps 604(599.33) | Grad Norm 0.0682(0.0615) | Total Time 14.00(14.00)\n",
      "Iter 3340 | Time 51.9362(52.0373) | Bit/dim 3.4935(3.4885) | Xent 0.0000(0.0000) | Loss 3.4935(3.4885) | Error 0.0000(0.0000) Steps 598(599.29) | Grad Norm 0.0711(0.0618) | Total Time 14.00(14.00)\n",
      "Iter 3341 | Time 52.0949(52.0390) | Bit/dim 3.4758(3.4881) | Xent 0.0000(0.0000) | Loss 3.4758(3.4881) | Error 0.0000(0.0000) Steps 598(599.25) | Grad Norm 0.0527(0.0615) | Total Time 14.00(14.00)\n",
      "Iter 3342 | Time 53.0922(52.0706) | Bit/dim 3.4921(3.4882) | Xent 0.0000(0.0000) | Loss 3.4921(3.4882) | Error 0.0000(0.0000) Steps 598(599.22) | Grad Norm 0.0424(0.0609) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0557 | Time 22.9388, Epoch Time 353.7338(351.1925), Bit/dim 3.4897(best: 3.4902), Xent 0.0000, Loss 3.4897, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3343 | Time 52.6869(52.0891) | Bit/dim 3.4934(3.4884) | Xent 0.0000(0.0000) | Loss 3.4934(3.4884) | Error 0.0000(0.0000) Steps 604(599.36) | Grad Norm 0.0569(0.0608) | Total Time 14.00(14.00)\n",
      "Iter 3344 | Time 53.5715(52.1335) | Bit/dim 3.4858(3.4883) | Xent 0.0000(0.0000) | Loss 3.4858(3.4883) | Error 0.0000(0.0000) Steps 598(599.32) | Grad Norm 0.0572(0.0607) | Total Time 14.00(14.00)\n",
      "Iter 3345 | Time 53.3477(52.1700) | Bit/dim 3.4898(3.4883) | Xent 0.0000(0.0000) | Loss 3.4898(3.4883) | Error 0.0000(0.0000) Steps 598(599.28) | Grad Norm 0.0579(0.0606) | Total Time 14.00(14.00)\n",
      "Iter 3346 | Time 51.4014(52.1469) | Bit/dim 3.4919(3.4884) | Xent 0.0000(0.0000) | Loss 3.4919(3.4884) | Error 0.0000(0.0000) Steps 598(599.24) | Grad Norm 0.0466(0.0602) | Total Time 14.00(14.00)\n",
      "Iter 3347 | Time 52.3662(52.1535) | Bit/dim 3.4867(3.4884) | Xent 0.0000(0.0000) | Loss 3.4867(3.4884) | Error 0.0000(0.0000) Steps 598(599.20) | Grad Norm 0.0549(0.0600) | Total Time 14.00(14.00)\n",
      "Iter 3348 | Time 53.2815(52.1873) | Bit/dim 3.4881(3.4884) | Xent 0.0000(0.0000) | Loss 3.4881(3.4884) | Error 0.0000(0.0000) Steps 598(599.17) | Grad Norm 0.0653(0.0602) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0558 | Time 23.0341, Epoch Time 355.7550(351.3294), Bit/dim 3.4905(best: 3.4897), Xent 0.0000, Loss 3.4905, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3349 | Time 52.7319(52.2037) | Bit/dim 3.4960(3.4886) | Xent 0.0000(0.0000) | Loss 3.4960(3.4886) | Error 0.0000(0.0000) Steps 604(599.31) | Grad Norm 0.0496(0.0599) | Total Time 14.00(14.00)\n",
      "Iter 3350 | Time 53.1743(52.2328) | Bit/dim 3.4838(3.4885) | Xent 0.0000(0.0000) | Loss 3.4838(3.4885) | Error 0.0000(0.0000) Steps 598(599.27) | Grad Norm 0.0447(0.0594) | Total Time 14.00(14.00)\n",
      "Iter 3351 | Time 52.6830(52.2463) | Bit/dim 3.4915(3.4886) | Xent 0.0000(0.0000) | Loss 3.4915(3.4886) | Error 0.0000(0.0000) Steps 598(599.23) | Grad Norm 0.0635(0.0595) | Total Time 14.00(14.00)\n",
      "Iter 3352 | Time 52.6360(52.2580) | Bit/dim 3.4923(3.4887) | Xent 0.0000(0.0000) | Loss 3.4923(3.4887) | Error 0.0000(0.0000) Steps 598(599.20) | Grad Norm 0.0538(0.0594) | Total Time 14.00(14.00)\n",
      "Iter 3353 | Time 51.6478(52.2397) | Bit/dim 3.4907(3.4887) | Xent 0.0000(0.0000) | Loss 3.4907(3.4887) | Error 0.0000(0.0000) Steps 598(599.16) | Grad Norm 0.0519(0.0591) | Total Time 14.00(14.00)\n",
      "Iter 3354 | Time 53.2952(52.2714) | Bit/dim 3.4765(3.4884) | Xent 0.0000(0.0000) | Loss 3.4765(3.4884) | Error 0.0000(0.0000) Steps 598(599.13) | Grad Norm 0.0518(0.0589) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0559 | Time 22.9597, Epoch Time 354.6507(351.4290), Bit/dim 3.4902(best: 3.4897), Xent 0.0000, Loss 3.4902, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3355 | Time 49.3945(52.1850) | Bit/dim 3.4739(3.4879) | Xent 0.0000(0.0000) | Loss 3.4739(3.4879) | Error 0.0000(0.0000) Steps 592(598.91) | Grad Norm 0.0620(0.0590) | Total Time 14.00(14.00)\n",
      "Iter 3356 | Time 52.6884(52.2001) | Bit/dim 3.4947(3.4881) | Xent 0.0000(0.0000) | Loss 3.4947(3.4881) | Error 0.0000(0.0000) Steps 598(598.89) | Grad Norm 0.0620(0.0591) | Total Time 14.00(14.00)\n",
      "Iter 3357 | Time 49.7223(52.1258) | Bit/dim 3.4855(3.4881) | Xent 0.0000(0.0000) | Loss 3.4855(3.4881) | Error 0.0000(0.0000) Steps 598(598.86) | Grad Norm 0.0543(0.0590) | Total Time 14.00(14.00)\n",
      "Iter 3358 | Time 52.0087(52.1223) | Bit/dim 3.4895(3.4881) | Xent 0.0000(0.0000) | Loss 3.4895(3.4881) | Error 0.0000(0.0000) Steps 598(598.83) | Grad Norm 0.0480(0.0586) | Total Time 14.00(14.00)\n",
      "Iter 3359 | Time 53.4208(52.1613) | Bit/dim 3.4953(3.4883) | Xent 0.0000(0.0000) | Loss 3.4953(3.4883) | Error 0.0000(0.0000) Steps 598(598.81) | Grad Norm 0.0592(0.0587) | Total Time 14.00(14.00)\n",
      "Iter 3360 | Time 50.3001(52.1054) | Bit/dim 3.4884(3.4883) | Xent 0.0000(0.0000) | Loss 3.4884(3.4883) | Error 0.0000(0.0000) Steps 598(598.78) | Grad Norm 0.0622(0.0588) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0560 | Time 22.7416, Epoch Time 345.7311(351.2581), Bit/dim 3.4906(best: 3.4897), Xent 0.0000, Loss 3.4906, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3361 | Time 51.4430(52.0855) | Bit/dim 3.4881(3.4883) | Xent 0.0000(0.0000) | Loss 3.4881(3.4883) | Error 0.0000(0.0000) Steps 598(598.76) | Grad Norm 0.0622(0.0589) | Total Time 14.00(14.00)\n",
      "Iter 3362 | Time 49.4871(52.0076) | Bit/dim 3.4995(3.4886) | Xent 0.0000(0.0000) | Loss 3.4995(3.4886) | Error 0.0000(0.0000) Steps 598(598.74) | Grad Norm 0.0540(0.0587) | Total Time 14.00(14.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_cifar10_published_bs8K_errcontrol_3 --resume ../experiments_published/cnf_cifar10_published_bs8K_errcontrol_3/epoch_400_checkpt.pth --seed 3 --conditional False --controlled_tol True --lr 0.0001 --warmup_iters 1000 --atol 1e-4  --rtol 1e-4\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
