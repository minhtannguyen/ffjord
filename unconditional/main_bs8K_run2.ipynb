{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, conditional=False, controlled_tol=False, conv=True, data='mnist', dims='64,64,64', divergence_fn='approximate', dl2int=None, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_published_bs8K_2/epoch_400_checkpt.pth', rtol=1e-05, save='../experiments_published/cnf_published_bs8K_2', seed=2, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=113.0, weight_decay=0.0, weight_y=0.5)\n",
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=1568, bias=True)\n",
      "  (project_class): LinearZeros(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 828890\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 2801 | Time 78.4837(40.9074) | Bit/dim 1.0874(1.0974) | Xent 0.0000(0.0000) | Loss 1.0874(1.0974) | Error 0.0000(0.0000) Steps 548(550.82) | Grad Norm 2.0884(4.0992) | Total Time 10.00(10.00)\n",
      "Iter 2802 | Time 39.5129(40.8655) | Bit/dim 1.0882(1.0971) | Xent 0.0000(0.0000) | Loss 1.0882(1.0971) | Error 0.0000(0.0000) Steps 548(550.74) | Grad Norm 2.1478(4.0406) | Total Time 10.00(10.00)\n",
      "Iter 2803 | Time 39.7478(40.8320) | Bit/dim 1.0809(1.0967) | Xent 0.0000(0.0000) | Loss 1.0809(1.0967) | Error 0.0000(0.0000) Steps 554(550.83) | Grad Norm 1.7498(3.9719) | Total Time 10.00(10.00)\n",
      "Iter 2804 | Time 38.4645(40.7610) | Bit/dim 1.0866(1.0964) | Xent 0.0000(0.0000) | Loss 1.0866(1.0964) | Error 0.0000(0.0000) Steps 542(550.57) | Grad Norm 0.9318(3.8807) | Total Time 10.00(10.00)\n",
      "Iter 2805 | Time 39.6236(40.7269) | Bit/dim 1.0814(1.0959) | Xent 0.0000(0.0000) | Loss 1.0814(1.0959) | Error 0.0000(0.0000) Steps 542(550.31) | Grad Norm 0.1471(3.7687) | Total Time 10.00(10.00)\n",
      "Iter 2806 | Time 39.7702(40.6982) | Bit/dim 1.0806(1.0955) | Xent 0.0000(0.0000) | Loss 1.0806(1.0955) | Error 0.0000(0.0000) Steps 548(550.24) | Grad Norm 1.0463(3.6870) | Total Time 10.00(10.00)\n",
      "Iter 2807 | Time 40.2185(40.6838) | Bit/dim 1.0815(1.0950) | Xent 0.0000(0.0000) | Loss 1.0815(1.0950) | Error 0.0000(0.0000) Steps 548(550.18) | Grad Norm 1.6132(3.6248) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 30.7263, Epoch Time 359.1397(317.4884), Bit/dim 1.0782(best: inf), Xent 0.0000, Loss 1.0782, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2808 | Time 41.0438(40.6946) | Bit/dim 1.0836(1.0947) | Xent 0.0000(0.0000) | Loss 1.0836(1.0947) | Error 0.0000(0.0000) Steps 548(550.11) | Grad Norm 1.7462(3.5684) | Total Time 10.00(10.00)\n",
      "Iter 2809 | Time 39.7933(40.6675) | Bit/dim 1.0850(1.0944) | Xent 0.0000(0.0000) | Loss 1.0850(1.0944) | Error 0.0000(0.0000) Steps 554(550.23) | Grad Norm 1.3460(3.5018) | Total Time 10.00(10.00)\n",
      "Iter 2810 | Time 39.3264(40.6273) | Bit/dim 1.0819(1.0940) | Xent 0.0000(0.0000) | Loss 1.0819(1.0940) | Error 0.0000(0.0000) Steps 554(550.34) | Grad Norm 0.6813(3.4172) | Total Time 10.00(10.00)\n",
      "Iter 2811 | Time 39.9812(40.6079) | Bit/dim 1.0821(1.0937) | Xent 0.0000(0.0000) | Loss 1.0821(1.0937) | Error 0.0000(0.0000) Steps 554(550.45) | Grad Norm 0.1396(3.3188) | Total Time 10.00(10.00)\n",
      "Iter 2812 | Time 39.4351(40.5727) | Bit/dim 1.0806(1.0933) | Xent 0.0000(0.0000) | Loss 1.0806(1.0933) | Error 0.0000(0.0000) Steps 554(550.56) | Grad Norm 0.7002(3.2403) | Total Time 10.00(10.00)\n",
      "Iter 2813 | Time 39.0166(40.5260) | Bit/dim 1.0794(1.0929) | Xent 0.0000(0.0000) | Loss 1.0794(1.0929) | Error 0.0000(0.0000) Steps 554(550.66) | Grad Norm 1.1531(3.1777) | Total Time 10.00(10.00)\n",
      "Iter 2814 | Time 39.3602(40.4911) | Bit/dim 1.0861(1.0927) | Xent 0.0000(0.0000) | Loss 1.0861(1.0927) | Error 0.0000(0.0000) Steps 548(550.58) | Grad Norm 1.2006(3.1183) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 20.8400, Epoch Time 311.4064(317.3060), Bit/dim 1.0781(best: 1.0782), Xent 0.0000, Loss 1.0781, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2815 | Time 40.5399(40.4925) | Bit/dim 1.0813(1.0923) | Xent 0.0000(0.0000) | Loss 1.0813(1.0923) | Error 0.0000(0.0000) Steps 548(550.50) | Grad Norm 0.9817(3.0542) | Total Time 10.00(10.00)\n",
      "Iter 2816 | Time 39.5348(40.4638) | Bit/dim 1.0861(1.0921) | Xent 0.0000(0.0000) | Loss 1.0861(1.0921) | Error 0.0000(0.0000) Steps 548(550.43) | Grad Norm 0.5505(2.9791) | Total Time 10.00(10.00)\n",
      "Iter 2817 | Time 40.3355(40.4600) | Bit/dim 1.0812(1.0918) | Xent 0.0000(0.0000) | Loss 1.0812(1.0918) | Error 0.0000(0.0000) Steps 554(550.53) | Grad Norm 0.0854(2.8923) | Total Time 10.00(10.00)\n",
      "Iter 2818 | Time 39.2380(40.4233) | Bit/dim 1.0853(1.0916) | Xent 0.0000(0.0000) | Loss 1.0853(1.0916) | Error 0.0000(0.0000) Steps 548(550.46) | Grad Norm 0.5013(2.8206) | Total Time 10.00(10.00)\n",
      "Iter 2819 | Time 40.8016(40.4346) | Bit/dim 1.0796(1.0912) | Xent 0.0000(0.0000) | Loss 1.0796(1.0912) | Error 0.0000(0.0000) Steps 554(550.56) | Grad Norm 0.7664(2.7590) | Total Time 10.00(10.00)\n",
      "Iter 2820 | Time 40.5798(40.4390) | Bit/dim 1.0830(1.0910) | Xent 0.0000(0.0000) | Loss 1.0830(1.0910) | Error 0.0000(0.0000) Steps 554(550.67) | Grad Norm 0.9555(2.7049) | Total Time 10.00(10.00)\n",
      "Iter 2821 | Time 39.7307(40.4177) | Bit/dim 1.0815(1.0907) | Xent 0.0000(0.0000) | Loss 1.0815(1.0907) | Error 0.0000(0.0000) Steps 548(550.59) | Grad Norm 0.7833(2.6472) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 20.7701, Epoch Time 314.0670(317.2088), Bit/dim 1.0772(best: 1.0781), Xent 0.0000, Loss 1.0772, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2822 | Time 39.8607(40.4010) | Bit/dim 1.0893(1.0907) | Xent 0.0000(0.0000) | Loss 1.0893(1.0907) | Error 0.0000(0.0000) Steps 548(550.51) | Grad Norm 0.4144(2.5802) | Total Time 10.00(10.00)\n",
      "Iter 2823 | Time 39.5438(40.3753) | Bit/dim 1.0860(1.0905) | Xent 0.0000(0.0000) | Loss 1.0860(1.0905) | Error 0.0000(0.0000) Steps 548(550.43) | Grad Norm 0.0683(2.5049) | Total Time 10.00(10.00)\n",
      "Iter 2824 | Time 38.3881(40.3157) | Bit/dim 1.0790(1.0902) | Xent 0.0000(0.0000) | Loss 1.0790(1.0902) | Error 0.0000(0.0000) Steps 548(550.36) | Grad Norm 0.3736(2.4409) | Total Time 10.00(10.00)\n",
      "Iter 2825 | Time 39.2138(40.2826) | Bit/dim 1.0813(1.0899) | Xent 0.0000(0.0000) | Loss 1.0813(1.0899) | Error 0.0000(0.0000) Steps 542(550.11) | Grad Norm 0.5944(2.3855) | Total Time 10.00(10.00)\n",
      "Iter 2826 | Time 38.2530(40.2218) | Bit/dim 1.0809(1.0896) | Xent 0.0000(0.0000) | Loss 1.0809(1.0896) | Error 0.0000(0.0000) Steps 542(549.87) | Grad Norm 0.6839(2.3345) | Total Time 10.00(10.00)\n",
      "Iter 2827 | Time 41.3815(40.2565) | Bit/dim 1.0815(1.0894) | Xent 0.0000(0.0000) | Loss 1.0815(1.0894) | Error 0.0000(0.0000) Steps 542(549.63) | Grad Norm 0.5261(2.2802) | Total Time 10.00(10.00)\n",
      "Iter 2828 | Time 38.4724(40.2030) | Bit/dim 1.0798(1.0891) | Xent 0.0000(0.0000) | Loss 1.0798(1.0891) | Error 0.0000(0.0000) Steps 548(549.58) | Grad Norm 0.3261(2.2216) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 21.0130, Epoch Time 308.4543(316.9462), Bit/dim 1.0770(best: 1.0772), Xent 0.0000, Loss 1.0770, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2829 | Time 40.2110(40.2033) | Bit/dim 1.0773(1.0888) | Xent 0.0000(0.0000) | Loss 1.0773(1.0888) | Error 0.0000(0.0000) Steps 548(549.54) | Grad Norm 0.0890(2.1576) | Total Time 10.00(10.00)\n",
      "Iter 2830 | Time 38.9897(40.1669) | Bit/dim 1.0823(1.0886) | Xent 0.0000(0.0000) | Loss 1.0823(1.0886) | Error 0.0000(0.0000) Steps 548(549.49) | Grad Norm 0.3059(2.1021) | Total Time 10.00(10.00)\n",
      "Iter 2831 | Time 39.1118(40.1352) | Bit/dim 1.0841(1.0884) | Xent 0.0000(0.0000) | Loss 1.0841(1.0884) | Error 0.0000(0.0000) Steps 554(549.62) | Grad Norm 0.4638(2.0529) | Total Time 10.00(10.00)\n",
      "Iter 2832 | Time 39.8775(40.1275) | Bit/dim 1.0835(1.0883) | Xent 0.0000(0.0000) | Loss 1.0835(1.0883) | Error 0.0000(0.0000) Steps 554(549.76) | Grad Norm 0.4902(2.0061) | Total Time 10.00(10.00)\n",
      "Iter 2833 | Time 39.9968(40.1236) | Bit/dim 1.0833(1.0881) | Xent 0.0000(0.0000) | Loss 1.0833(1.0881) | Error 0.0000(0.0000) Steps 554(549.88) | Grad Norm 0.3484(1.9563) | Total Time 10.00(10.00)\n",
      "Iter 2834 | Time 40.0381(40.1210) | Bit/dim 1.0826(1.0880) | Xent 0.0000(0.0000) | Loss 1.0826(1.0880) | Error 0.0000(0.0000) Steps 548(549.83) | Grad Norm 0.2126(1.9040) | Total Time 10.00(10.00)\n",
      "Iter 2835 | Time 40.2875(40.1260) | Bit/dim 1.0850(1.0879) | Xent 0.0000(0.0000) | Loss 1.0850(1.0879) | Error 0.0000(0.0000) Steps 554(549.95) | Grad Norm 0.0673(1.8489) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 21.0889, Epoch Time 312.1360(316.8019), Bit/dim 1.0771(best: 1.0770), Xent 0.0000, Loss 1.0771, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2836 | Time 39.4016(40.1043) | Bit/dim 1.0868(1.0878) | Xent 0.0000(0.0000) | Loss 1.0868(1.0878) | Error 0.0000(0.0000) Steps 548(549.89) | Grad Norm 0.2194(1.8000) | Total Time 10.00(10.00)\n",
      "Iter 2837 | Time 39.7034(40.0922) | Bit/dim 1.0783(1.0876) | Xent 0.0000(0.0000) | Loss 1.0783(1.0876) | Error 0.0000(0.0000) Steps 548(549.84) | Grad Norm 0.2720(1.7542) | Total Time 10.00(10.00)\n",
      "Iter 2838 | Time 38.9516(40.0580) | Bit/dim 1.0843(1.0875) | Xent 0.0000(0.0000) | Loss 1.0843(1.0875) | Error 0.0000(0.0000) Steps 548(549.78) | Grad Norm 0.3592(1.7123) | Total Time 10.00(10.00)\n",
      "Iter 2839 | Time 38.5250(40.0120) | Bit/dim 1.0797(1.0872) | Xent 0.0000(0.0000) | Loss 1.0797(1.0872) | Error 0.0000(0.0000) Steps 548(549.73) | Grad Norm 0.2510(1.6685) | Total Time 10.00(10.00)\n",
      "Iter 2840 | Time 39.6745(40.0019) | Bit/dim 1.0872(1.0872) | Xent 0.0000(0.0000) | Loss 1.0872(1.0872) | Error 0.0000(0.0000) Steps 548(549.68) | Grad Norm 0.1622(1.6233) | Total Time 10.00(10.00)\n",
      "Iter 2841 | Time 39.2618(39.9797) | Bit/dim 1.0825(1.0871) | Xent 0.0000(0.0000) | Loss 1.0825(1.0871) | Error 0.0000(0.0000) Steps 554(549.81) | Grad Norm 0.0647(1.5765) | Total Time 10.00(10.00)\n",
      "Iter 2842 | Time 39.9996(39.9803) | Bit/dim 1.0830(1.0870) | Xent 0.0000(0.0000) | Loss 1.0830(1.0870) | Error 0.0000(0.0000) Steps 548(549.75) | Grad Norm 0.1494(1.5337) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 20.7108, Epoch Time 308.6588(316.5576), Bit/dim 1.0775(best: 1.0770), Xent 0.0000, Loss 1.0775, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2843 | Time 39.6952(39.9717) | Bit/dim 1.0827(1.0868) | Xent 0.0000(0.0000) | Loss 1.0827(1.0868) | Error 0.0000(0.0000) Steps 560(550.06) | Grad Norm 0.2440(1.4950) | Total Time 10.00(10.00)\n",
      "Iter 2844 | Time 41.1459(40.0070) | Bit/dim 1.0826(1.0867) | Xent 0.0000(0.0000) | Loss 1.0826(1.0867) | Error 0.0000(0.0000) Steps 554(550.18) | Grad Norm 0.2415(1.4574) | Total Time 10.00(10.00)\n",
      "Iter 2845 | Time 39.3203(39.9864) | Bit/dim 1.0803(1.0865) | Xent 0.0000(0.0000) | Loss 1.0803(1.0865) | Error 0.0000(0.0000) Steps 554(550.29) | Grad Norm 0.2166(1.4202) | Total Time 10.00(10.00)\n",
      "Iter 2846 | Time 41.8952(40.0436) | Bit/dim 1.0838(1.0864) | Xent 0.0000(0.0000) | Loss 1.0838(1.0864) | Error 0.0000(0.0000) Steps 542(550.04) | Grad Norm 0.0999(1.3806) | Total Time 10.00(10.00)\n",
      "Iter 2847 | Time 39.3226(40.0220) | Bit/dim 1.0820(1.0863) | Xent 0.0000(0.0000) | Loss 1.0820(1.0863) | Error 0.0000(0.0000) Steps 548(549.98) | Grad Norm 0.0640(1.3411) | Total Time 10.00(10.00)\n",
      "Iter 2848 | Time 39.8479(40.0168) | Bit/dim 1.0823(1.0862) | Xent 0.0000(0.0000) | Loss 1.0823(1.0862) | Error 0.0000(0.0000) Steps 548(549.92) | Grad Norm 0.1464(1.3053) | Total Time 10.00(10.00)\n",
      "Iter 2849 | Time 39.3592(39.9970) | Bit/dim 1.0835(1.0861) | Xent 0.0000(0.0000) | Loss 1.0835(1.0861) | Error 0.0000(0.0000) Steps 554(550.04) | Grad Norm 0.1658(1.2711) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 21.1221, Epoch Time 314.2299(316.4877), Bit/dim 1.0768(best: 1.0770), Xent 0.0000, Loss 1.0768, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2850 | Time 40.2195(40.0037) | Bit/dim 1.0787(1.0859) | Xent 0.0000(0.0000) | Loss 1.0787(1.0859) | Error 0.0000(0.0000) Steps 548(549.98) | Grad Norm 0.1369(1.2371) | Total Time 10.00(10.00)\n",
      "Iter 2851 | Time 39.5311(39.9895) | Bit/dim 1.0829(1.0858) | Xent 0.0000(0.0000) | Loss 1.0829(1.0858) | Error 0.0000(0.0000) Steps 548(549.92) | Grad Norm 0.1364(1.2040) | Total Time 10.00(10.00)\n",
      "Iter 2852 | Time 40.4792(40.0042) | Bit/dim 1.0823(1.0857) | Xent 0.0000(0.0000) | Loss 1.0823(1.0857) | Error 0.0000(0.0000) Steps 548(549.87) | Grad Norm 0.0667(1.1699) | Total Time 10.00(10.00)\n",
      "Iter 2853 | Time 41.1632(40.0390) | Bit/dim 1.0820(1.0856) | Xent 0.0000(0.0000) | Loss 1.0820(1.0856) | Error 0.0000(0.0000) Steps 554(549.99) | Grad Norm 0.0578(1.1365) | Total Time 10.00(10.00)\n",
      "Iter 2854 | Time 39.7872(40.0314) | Bit/dim 1.0807(1.0854) | Xent 0.0000(0.0000) | Loss 1.0807(1.0854) | Error 0.0000(0.0000) Steps 554(550.11) | Grad Norm 0.1316(1.1064) | Total Time 10.00(10.00)\n",
      "Iter 2855 | Time 40.0352(40.0316) | Bit/dim 1.0835(1.0854) | Xent 0.0000(0.0000) | Loss 1.0835(1.0854) | Error 0.0000(0.0000) Steps 554(550.23) | Grad Norm 0.0870(1.0758) | Total Time 10.00(10.00)\n",
      "Iter 2856 | Time 40.7377(40.0527) | Bit/dim 1.0806(1.0852) | Xent 0.0000(0.0000) | Loss 1.0806(1.0852) | Error 0.0000(0.0000) Steps 542(549.98) | Grad Norm 0.1466(1.0479) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 21.1649, Epoch Time 315.8916(316.4699), Bit/dim 1.0767(best: 1.0768), Xent 0.0000, Loss 1.0767, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2857 | Time 40.7046(40.0723) | Bit/dim 1.0783(1.0850) | Xent 0.0000(0.0000) | Loss 1.0783(1.0850) | Error 0.0000(0.0000) Steps 548(549.92) | Grad Norm 0.1011(1.0195) | Total Time 10.00(10.00)\n",
      "Iter 2858 | Time 38.9604(40.0389) | Bit/dim 1.0810(1.0849) | Xent 0.0000(0.0000) | Loss 1.0810(1.0849) | Error 0.0000(0.0000) Steps 548(549.86) | Grad Norm 0.0770(0.9913) | Total Time 10.00(10.00)\n",
      "Iter 2859 | Time 40.4538(40.0514) | Bit/dim 1.0862(1.0849) | Xent 0.0000(0.0000) | Loss 1.0862(1.0849) | Error 0.0000(0.0000) Steps 554(549.99) | Grad Norm 0.0759(0.9638) | Total Time 10.00(10.00)\n",
      "Iter 2860 | Time 40.6156(40.0683) | Bit/dim 1.0824(1.0849) | Xent 0.0000(0.0000) | Loss 1.0824(1.0849) | Error 0.0000(0.0000) Steps 548(549.93) | Grad Norm 0.1234(0.9386) | Total Time 10.00(10.00)\n",
      "Iter 2861 | Time 39.8302(40.0612) | Bit/dim 1.0831(1.0848) | Xent 0.0000(0.0000) | Loss 1.0831(1.0848) | Error 0.0000(0.0000) Steps 548(549.87) | Grad Norm 0.0918(0.9132) | Total Time 10.00(10.00)\n",
      "Iter 2862 | Time 39.0492(40.0308) | Bit/dim 1.0841(1.0848) | Xent 0.0000(0.0000) | Loss 1.0841(1.0848) | Error 0.0000(0.0000) Steps 554(549.99) | Grad Norm 0.0797(0.8882) | Total Time 10.00(10.00)\n",
      "Iter 2863 | Time 38.9092(39.9972) | Bit/dim 1.0804(1.0847) | Xent 0.0000(0.0000) | Loss 1.0804(1.0847) | Error 0.0000(0.0000) Steps 548(549.93) | Grad Norm 0.0598(0.8633) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 20.7986, Epoch Time 312.1466(316.3402), Bit/dim 1.0769(best: 1.0767), Xent 0.0000, Loss 1.0769, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2864 | Time 39.8223(39.9919) | Bit/dim 1.0771(1.0844) | Xent 0.0000(0.0000) | Loss 1.0771(1.0844) | Error 0.0000(0.0000) Steps 548(549.88) | Grad Norm 0.0751(0.8397) | Total Time 10.00(10.00)\n",
      "Iter 2865 | Time 40.9093(40.0194) | Bit/dim 1.0822(1.0844) | Xent 0.0000(0.0000) | Loss 1.0822(1.0844) | Error 0.0000(0.0000) Steps 554(550.00) | Grad Norm 0.0552(0.8161) | Total Time 10.00(10.00)\n",
      "Iter 2866 | Time 41.2958(40.0577) | Bit/dim 1.0796(1.0842) | Xent 0.0000(0.0000) | Loss 1.0796(1.0842) | Error 0.0000(0.0000) Steps 554(550.12) | Grad Norm 0.0705(0.7938) | Total Time 10.00(10.00)\n",
      "Iter 2867 | Time 40.5461(40.0724) | Bit/dim 1.0888(1.0844) | Xent 0.0000(0.0000) | Loss 1.0888(1.0844) | Error 0.0000(0.0000) Steps 554(550.24) | Grad Norm 0.0641(0.7719) | Total Time 10.00(10.00)\n",
      "Iter 2868 | Time 39.4534(40.0538) | Bit/dim 1.0823(1.0843) | Xent 0.0000(0.0000) | Loss 1.0823(1.0843) | Error 0.0000(0.0000) Steps 548(550.17) | Grad Norm 0.0793(0.7511) | Total Time 10.00(10.00)\n",
      "Iter 2869 | Time 39.4700(40.0363) | Bit/dim 1.0845(1.0843) | Xent 0.0000(0.0000) | Loss 1.0845(1.0843) | Error 0.0000(0.0000) Steps 554(550.28) | Grad Norm 0.0652(0.7305) | Total Time 10.00(10.00)\n",
      "Iter 2870 | Time 40.6659(40.0552) | Bit/dim 1.0804(1.0842) | Xent 0.0000(0.0000) | Loss 1.0804(1.0842) | Error 0.0000(0.0000) Steps 548(550.22) | Grad Norm 0.0652(0.7106) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 20.9094, Epoch Time 315.5104(316.3153), Bit/dim 1.0766(best: 1.0767), Xent 0.0000, Loss 1.0766, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2871 | Time 39.9140(40.0509) | Bit/dim 1.0809(1.0841) | Xent 0.0000(0.0000) | Loss 1.0809(1.0841) | Error 0.0000(0.0000) Steps 548(550.15) | Grad Norm 0.0759(0.6915) | Total Time 10.00(10.00)\n",
      "Iter 2872 | Time 39.6531(40.0390) | Bit/dim 1.0816(1.0840) | Xent 0.0000(0.0000) | Loss 1.0816(1.0840) | Error 0.0000(0.0000) Steps 554(550.26) | Grad Norm 0.0791(0.6732) | Total Time 10.00(10.00)\n",
      "Iter 2873 | Time 40.4109(40.0502) | Bit/dim 1.0802(1.0839) | Xent 0.0000(0.0000) | Loss 1.0802(1.0839) | Error 0.0000(0.0000) Steps 548(550.20) | Grad Norm 0.0583(0.6547) | Total Time 10.00(10.00)\n",
      "Iter 2874 | Time 40.5994(40.0666) | Bit/dim 1.0799(1.0838) | Xent 0.0000(0.0000) | Loss 1.0799(1.0838) | Error 0.0000(0.0000) Steps 560(550.49) | Grad Norm 0.0622(0.6369) | Total Time 10.00(10.00)\n",
      "Iter 2875 | Time 41.6724(40.1148) | Bit/dim 1.0838(1.0838) | Xent 0.0000(0.0000) | Loss 1.0838(1.0838) | Error 0.0000(0.0000) Steps 548(550.42) | Grad Norm 0.0556(0.6195) | Total Time 10.00(10.00)\n",
      "Iter 2876 | Time 41.0145(40.1418) | Bit/dim 1.0836(1.0838) | Xent 0.0000(0.0000) | Loss 1.0836(1.0838) | Error 0.0000(0.0000) Steps 554(550.52) | Grad Norm 0.0625(0.6028) | Total Time 10.00(10.00)\n",
      "Iter 2877 | Time 39.4797(40.1219) | Bit/dim 1.0805(1.0837) | Xent 0.0000(0.0000) | Loss 1.0805(1.0837) | Error 0.0000(0.0000) Steps 554(550.63) | Grad Norm 0.0581(0.5864) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 20.9375, Epoch Time 316.0216(316.3065), Bit/dim 1.0763(best: 1.0766), Xent 0.0000, Loss 1.0763, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2878 | Time 39.6785(40.1086) | Bit/dim 1.0796(1.0836) | Xent 0.0000(0.0000) | Loss 1.0796(1.0836) | Error 0.0000(0.0000) Steps 554(550.73) | Grad Norm 0.0742(0.5711) | Total Time 10.00(10.00)\n",
      "Iter 2879 | Time 40.7692(40.1285) | Bit/dim 1.0843(1.0836) | Xent 0.0000(0.0000) | Loss 1.0843(1.0836) | Error 0.0000(0.0000) Steps 554(550.83) | Grad Norm 0.0622(0.5558) | Total Time 10.00(10.00)\n",
      "Iter 2880 | Time 40.0414(40.1258) | Bit/dim 1.0831(1.0836) | Xent 0.0000(0.0000) | Loss 1.0831(1.0836) | Error 0.0000(0.0000) Steps 554(550.92) | Grad Norm 0.0812(0.5416) | Total Time 10.00(10.00)\n",
      "Iter 2881 | Time 39.7715(40.1152) | Bit/dim 1.0834(1.0836) | Xent 0.0000(0.0000) | Loss 1.0834(1.0836) | Error 0.0000(0.0000) Steps 560(551.19) | Grad Norm 0.0650(0.5273) | Total Time 10.00(10.00)\n",
      "Iter 2882 | Time 42.0099(40.1721) | Bit/dim 1.0789(1.0834) | Xent 0.0000(0.0000) | Loss 1.0789(1.0834) | Error 0.0000(0.0000) Steps 554(551.28) | Grad Norm 0.0599(0.5133) | Total Time 10.00(10.00)\n",
      "Iter 2883 | Time 41.4609(40.2107) | Bit/dim 1.0808(1.0833) | Xent 0.0000(0.0000) | Loss 1.0808(1.0833) | Error 0.0000(0.0000) Steps 548(551.18) | Grad Norm 0.0574(0.4996) | Total Time 10.00(10.00)\n",
      "Iter 2884 | Time 40.2897(40.2131) | Bit/dim 1.0809(1.0833) | Xent 0.0000(0.0000) | Loss 1.0809(1.0833) | Error 0.0000(0.0000) Steps 548(551.08) | Grad Norm 0.0673(0.4866) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 21.0499, Epoch Time 317.7556(316.3499), Bit/dim 1.0762(best: 1.0763), Xent 0.0000, Loss 1.0762, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2885 | Time 41.0295(40.2376) | Bit/dim 1.0843(1.0833) | Xent 0.0000(0.0000) | Loss 1.0843(1.0833) | Error 0.0000(0.0000) Steps 548(550.99) | Grad Norm 0.0728(0.4742) | Total Time 10.00(10.00)\n",
      "Iter 2886 | Time 39.7692(40.2235) | Bit/dim 1.0803(1.0832) | Xent 0.0000(0.0000) | Loss 1.0803(1.0832) | Error 0.0000(0.0000) Steps 554(551.08) | Grad Norm 0.0513(0.4615) | Total Time 10.00(10.00)\n",
      "Iter 2887 | Time 42.6079(40.2951) | Bit/dim 1.0848(1.0833) | Xent 0.0000(0.0000) | Loss 1.0848(1.0833) | Error 0.0000(0.0000) Steps 554(551.17) | Grad Norm 0.0550(0.4493) | Total Time 10.00(10.00)\n",
      "Iter 2888 | Time 39.8181(40.2808) | Bit/dim 1.0789(1.0831) | Xent 0.0000(0.0000) | Loss 1.0789(1.0831) | Error 0.0000(0.0000) Steps 554(551.26) | Grad Norm 0.0685(0.4379) | Total Time 10.00(10.00)\n",
      "Iter 2889 | Time 39.4836(40.2568) | Bit/dim 1.0806(1.0831) | Xent 0.0000(0.0000) | Loss 1.0806(1.0831) | Error 0.0000(0.0000) Steps 554(551.34) | Grad Norm 0.0625(0.4266) | Total Time 10.00(10.00)\n",
      "Iter 2890 | Time 41.0446(40.2805) | Bit/dim 1.0830(1.0830) | Xent 0.0000(0.0000) | Loss 1.0830(1.0830) | Error 0.0000(0.0000) Steps 554(551.42) | Grad Norm 0.0613(0.4157) | Total Time 10.00(10.00)\n",
      "Iter 2891 | Time 41.5377(40.3182) | Bit/dim 1.0805(1.0830) | Xent 0.0000(0.0000) | Loss 1.0805(1.0830) | Error 0.0000(0.0000) Steps 560(551.67) | Grad Norm 0.0629(0.4051) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 21.1753, Epoch Time 319.1831(316.4349), Bit/dim 1.0766(best: 1.0762), Xent 0.0000, Loss 1.0766, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2892 | Time 39.6235(40.2974) | Bit/dim 1.0826(1.0830) | Xent 0.0000(0.0000) | Loss 1.0826(1.0830) | Error 0.0000(0.0000) Steps 548(551.56) | Grad Norm 0.0807(0.3954) | Total Time 10.00(10.00)\n",
      "Iter 2893 | Time 40.9352(40.3165) | Bit/dim 1.0817(1.0829) | Xent 0.0000(0.0000) | Loss 1.0817(1.0829) | Error 0.0000(0.0000) Steps 548(551.46) | Grad Norm 0.0676(0.3855) | Total Time 10.00(10.00)\n",
      "Iter 2894 | Time 39.4641(40.2909) | Bit/dim 1.0784(1.0828) | Xent 0.0000(0.0000) | Loss 1.0784(1.0828) | Error 0.0000(0.0000) Steps 554(551.53) | Grad Norm 0.0554(0.3756) | Total Time 10.00(10.00)\n",
      "Iter 2895 | Time 39.7131(40.2736) | Bit/dim 1.0819(1.0828) | Xent 0.0000(0.0000) | Loss 1.0819(1.0828) | Error 0.0000(0.0000) Steps 560(551.79) | Grad Norm 0.0648(0.3663) | Total Time 10.00(10.00)\n",
      "Iter 2896 | Time 39.5955(40.2532) | Bit/dim 1.0804(1.0827) | Xent 0.0000(0.0000) | Loss 1.0804(1.0827) | Error 0.0000(0.0000) Steps 560(552.03) | Grad Norm 0.0564(0.3570) | Total Time 10.00(10.00)\n",
      "Iter 2897 | Time 40.4002(40.2576) | Bit/dim 1.0834(1.0827) | Xent 0.0000(0.0000) | Loss 1.0834(1.0827) | Error 0.0000(0.0000) Steps 554(552.09) | Grad Norm 0.0558(0.3480) | Total Time 10.00(10.00)\n",
      "Iter 2898 | Time 41.1422(40.2842) | Bit/dim 1.0809(1.0827) | Xent 0.0000(0.0000) | Loss 1.0809(1.0827) | Error 0.0000(0.0000) Steps 560(552.33) | Grad Norm 0.0577(0.3393) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 21.3143, Epoch Time 314.9735(316.3911), Bit/dim 1.0766(best: 1.0762), Xent 0.0000, Loss 1.0766, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2899 | Time 41.1750(40.3109) | Bit/dim 1.0807(1.0826) | Xent 0.0000(0.0000) | Loss 1.0807(1.0826) | Error 0.0000(0.0000) Steps 560(552.56) | Grad Norm 0.0726(0.3313) | Total Time 10.00(10.00)\n",
      "Iter 2900 | Time 39.9945(40.3014) | Bit/dim 1.0831(1.0826) | Xent 0.0000(0.0000) | Loss 1.0831(1.0826) | Error 0.0000(0.0000) Steps 554(552.60) | Grad Norm 0.0504(0.3228) | Total Time 10.00(10.00)\n",
      "Iter 2901 | Time 41.3664(40.3334) | Bit/dim 1.0838(1.0827) | Xent 0.0000(0.0000) | Loss 1.0838(1.0827) | Error 0.0000(0.0000) Steps 554(552.65) | Grad Norm 0.0496(0.3146) | Total Time 10.00(10.00)\n",
      "Iter 2902 | Time 40.4790(40.3377) | Bit/dim 1.0809(1.0826) | Xent 0.0000(0.0000) | Loss 1.0809(1.0826) | Error 0.0000(0.0000) Steps 554(552.69) | Grad Norm 0.0496(0.3067) | Total Time 10.00(10.00)\n",
      "Iter 2903 | Time 41.5496(40.3741) | Bit/dim 1.0798(1.0825) | Xent 0.0000(0.0000) | Loss 1.0798(1.0825) | Error 0.0000(0.0000) Steps 554(552.73) | Grad Norm 0.0836(0.3000) | Total Time 10.00(10.00)\n",
      "Iter 2904 | Time 40.0979(40.3658) | Bit/dim 1.0783(1.0824) | Xent 0.0000(0.0000) | Loss 1.0783(1.0824) | Error 0.0000(0.0000) Steps 554(552.76) | Grad Norm 0.0797(0.2934) | Total Time 10.00(10.00)\n",
      "Iter 2905 | Time 39.6663(40.3448) | Bit/dim 1.0835(1.0824) | Xent 0.0000(0.0000) | Loss 1.0835(1.0824) | Error 0.0000(0.0000) Steps 554(552.80) | Grad Norm 0.0672(0.2866) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 21.1231, Epoch Time 317.9274(316.4372), Bit/dim 1.0769(best: 1.0762), Xent 0.0000, Loss 1.0769, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2906 | Time 41.0851(40.3670) | Bit/dim 1.0809(1.0824) | Xent 0.0000(0.0000) | Loss 1.0809(1.0824) | Error 0.0000(0.0000) Steps 560(553.02) | Grad Norm 0.0712(0.2801) | Total Time 10.00(10.00)\n",
      "Iter 2907 | Time 40.6400(40.3752) | Bit/dim 1.0806(1.0823) | Xent 0.0000(0.0000) | Loss 1.0806(1.0823) | Error 0.0000(0.0000) Steps 554(553.05) | Grad Norm 0.0584(0.2735) | Total Time 10.00(10.00)\n",
      "Iter 2908 | Time 41.6397(40.4132) | Bit/dim 1.0826(1.0823) | Xent 0.0000(0.0000) | Loss 1.0826(1.0823) | Error 0.0000(0.0000) Steps 554(553.08) | Grad Norm 0.0519(0.2668) | Total Time 10.00(10.00)\n",
      "Iter 2909 | Time 40.2584(40.4085) | Bit/dim 1.0803(1.0823) | Xent 0.0000(0.0000) | Loss 1.0803(1.0823) | Error 0.0000(0.0000) Steps 548(552.92) | Grad Norm 0.0527(0.2604) | Total Time 10.00(10.00)\n",
      "Iter 2910 | Time 39.5942(40.3841) | Bit/dim 1.0823(1.0823) | Xent 0.0000(0.0000) | Loss 1.0823(1.0823) | Error 0.0000(0.0000) Steps 548(552.78) | Grad Norm 0.0574(0.2543) | Total Time 10.00(10.00)\n",
      "Iter 2911 | Time 41.7934(40.4264) | Bit/dim 1.0834(1.0823) | Xent 0.0000(0.0000) | Loss 1.0834(1.0823) | Error 0.0000(0.0000) Steps 554(552.81) | Grad Norm 0.0828(0.2492) | Total Time 10.00(10.00)\n",
      "Iter 2912 | Time 40.7597(40.4364) | Bit/dim 1.0798(1.0822) | Xent 0.0000(0.0000) | Loss 1.0798(1.0822) | Error 0.0000(0.0000) Steps 560(553.03) | Grad Norm 0.0514(0.2432) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 21.0158, Epoch Time 319.2434(316.5214), Bit/dim 1.0766(best: 1.0762), Xent 0.0000, Loss 1.0766, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2913 | Time 41.2908(40.4620) | Bit/dim 1.0823(1.0822) | Xent 0.0000(0.0000) | Loss 1.0823(1.0822) | Error 0.0000(0.0000) Steps 560(553.24) | Grad Norm 0.0673(0.2380) | Total Time 10.00(10.00)\n",
      "Iter 2914 | Time 39.2507(40.4257) | Bit/dim 1.0810(1.0822) | Xent 0.0000(0.0000) | Loss 1.0810(1.0822) | Error 0.0000(0.0000) Steps 554(553.26) | Grad Norm 0.0627(0.2327) | Total Time 10.00(10.00)\n",
      "Iter 2915 | Time 41.7925(40.4667) | Bit/dim 1.0833(1.0822) | Xent 0.0000(0.0000) | Loss 1.0833(1.0822) | Error 0.0000(0.0000) Steps 554(553.28) | Grad Norm 0.0547(0.2274) | Total Time 10.00(10.00)\n",
      "Iter 2916 | Time 39.0757(40.4249) | Bit/dim 1.0816(1.0822) | Xent 0.0000(0.0000) | Loss 1.0816(1.0822) | Error 0.0000(0.0000) Steps 554(553.30) | Grad Norm 0.1255(0.2243) | Total Time 10.00(10.00)\n",
      "Iter 2917 | Time 39.6857(40.4027) | Bit/dim 1.0762(1.0820) | Xent 0.0000(0.0000) | Loss 1.0762(1.0820) | Error 0.0000(0.0000) Steps 560(553.50) | Grad Norm 0.0499(0.2191) | Total Time 10.00(10.00)\n",
      "Iter 2918 | Time 40.2001(40.3967) | Bit/dim 1.0812(1.0820) | Xent 0.0000(0.0000) | Loss 1.0812(1.0820) | Error 0.0000(0.0000) Steps 554(553.52) | Grad Norm 0.0712(0.2146) | Total Time 10.00(10.00)\n",
      "Iter 2919 | Time 40.9783(40.4141) | Bit/dim 1.0803(1.0820) | Xent 0.0000(0.0000) | Loss 1.0803(1.0820) | Error 0.0000(0.0000) Steps 554(553.53) | Grad Norm 0.0594(0.2100) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 21.1139, Epoch Time 315.8208(316.5003), Bit/dim 1.0764(best: 1.0762), Xent 0.0000, Loss 1.0764, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2920 | Time 41.3244(40.4414) | Bit/dim 1.0850(1.0820) | Xent 0.0000(0.0000) | Loss 1.0850(1.0820) | Error 0.0000(0.0000) Steps 554(553.55) | Grad Norm 0.0648(0.2056) | Total Time 10.00(10.00)\n",
      "Iter 2921 | Time 40.9689(40.4573) | Bit/dim 1.0813(1.0820) | Xent 0.0000(0.0000) | Loss 1.0813(1.0820) | Error 0.0000(0.0000) Steps 554(553.56) | Grad Norm 0.0854(0.2020) | Total Time 10.00(10.00)\n",
      "Iter 2922 | Time 39.9614(40.4424) | Bit/dim 1.0798(1.0820) | Xent 0.0000(0.0000) | Loss 1.0798(1.0820) | Error 0.0000(0.0000) Steps 554(553.57) | Grad Norm 0.0597(0.1977) | Total Time 10.00(10.00)\n",
      "Iter 2923 | Time 42.5190(40.5047) | Bit/dim 1.0815(1.0819) | Xent 0.0000(0.0000) | Loss 1.0815(1.0819) | Error 0.0000(0.0000) Steps 554(553.59) | Grad Norm 0.0512(0.1934) | Total Time 10.00(10.00)\n",
      "Iter 2924 | Time 42.2231(40.5562) | Bit/dim 1.0792(1.0819) | Xent 0.0000(0.0000) | Loss 1.0792(1.0819) | Error 0.0000(0.0000) Steps 554(553.60) | Grad Norm 0.0691(0.1896) | Total Time 10.00(10.00)\n",
      "Iter 2925 | Time 40.2556(40.5472) | Bit/dim 1.0847(1.0820) | Xent 0.0000(0.0000) | Loss 1.0847(1.0820) | Error 0.0000(0.0000) Steps 560(553.79) | Grad Norm 0.0538(0.1856) | Total Time 10.00(10.00)\n",
      "Iter 2926 | Time 39.3890(40.5125) | Bit/dim 1.0776(1.0818) | Xent 0.0000(0.0000) | Loss 1.0776(1.0818) | Error 0.0000(0.0000) Steps 560(553.98) | Grad Norm 0.0517(0.1815) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 20.8453, Epoch Time 319.8447(316.6007), Bit/dim 1.0755(best: 1.0762), Xent 0.0000, Loss 1.0755, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2927 | Time 40.1349(40.5011) | Bit/dim 1.0771(1.0817) | Xent 0.0000(0.0000) | Loss 1.0771(1.0817) | Error 0.0000(0.0000) Steps 554(553.98) | Grad Norm 0.0940(0.1789) | Total Time 10.00(10.00)\n",
      "Iter 2928 | Time 41.7375(40.5382) | Bit/dim 1.0838(1.0817) | Xent 0.0000(0.0000) | Loss 1.0838(1.0817) | Error 0.0000(0.0000) Steps 554(553.98) | Grad Norm 0.1087(0.1768) | Total Time 10.00(10.00)\n",
      "Iter 2929 | Time 41.7477(40.5745) | Bit/dim 1.0822(1.0818) | Xent 0.0000(0.0000) | Loss 1.0822(1.0818) | Error 0.0000(0.0000) Steps 554(553.98) | Grad Norm 0.0775(0.1738) | Total Time 10.00(10.00)\n",
      "Iter 2930 | Time 42.7308(40.6392) | Bit/dim 1.0791(1.0817) | Xent 0.0000(0.0000) | Loss 1.0791(1.0817) | Error 0.0000(0.0000) Steps 554(553.98) | Grad Norm 0.0658(0.1706) | Total Time 10.00(10.00)\n",
      "Iter 2931 | Time 40.4894(40.6347) | Bit/dim 1.0838(1.0817) | Xent 0.0000(0.0000) | Loss 1.0838(1.0817) | Error 0.0000(0.0000) Steps 554(553.98) | Grad Norm 0.0479(0.1669) | Total Time 10.00(10.00)\n",
      "Iter 2932 | Time 40.2633(40.6236) | Bit/dim 1.0822(1.0818) | Xent 0.0000(0.0000) | Loss 1.0822(1.0818) | Error 0.0000(0.0000) Steps 554(553.98) | Grad Norm 0.0965(0.1648) | Total Time 10.00(10.00)\n",
      "Iter 2933 | Time 42.3816(40.6763) | Bit/dim 1.0822(1.0818) | Xent 0.0000(0.0000) | Loss 1.0822(1.0818) | Error 0.0000(0.0000) Steps 572(554.52) | Grad Norm 0.1054(0.1630) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 21.2635, Epoch Time 323.2415(316.7999), Bit/dim 1.0760(best: 1.0755), Xent 0.0000, Loss 1.0760, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2934 | Time 41.0099(40.6863) | Bit/dim 1.0796(1.0817) | Xent 0.0000(0.0000) | Loss 1.0796(1.0817) | Error 0.0000(0.0000) Steps 548(554.33) | Grad Norm 0.1304(0.1620) | Total Time 10.00(10.00)\n",
      "Iter 2935 | Time 41.8956(40.7226) | Bit/dim 1.0808(1.0817) | Xent 0.0000(0.0000) | Loss 1.0808(1.0817) | Error 0.0000(0.0000) Steps 560(554.50) | Grad Norm 0.0603(0.1590) | Total Time 10.00(10.00)\n",
      "Iter 2936 | Time 39.6965(40.6918) | Bit/dim 1.0824(1.0817) | Xent 0.0000(0.0000) | Loss 1.0824(1.0817) | Error 0.0000(0.0000) Steps 554(554.48) | Grad Norm 0.0526(0.1558) | Total Time 10.00(10.00)\n",
      "Iter 2937 | Time 41.7623(40.7239) | Bit/dim 1.0794(1.0816) | Xent 0.0000(0.0000) | Loss 1.0794(1.0816) | Error 0.0000(0.0000) Steps 572(555.01) | Grad Norm 0.0598(0.1529) | Total Time 10.00(10.00)\n",
      "Iter 2938 | Time 41.5365(40.7483) | Bit/dim 1.0833(1.0817) | Xent 0.0000(0.0000) | Loss 1.0833(1.0817) | Error 0.0000(0.0000) Steps 554(554.98) | Grad Norm 0.1398(0.1525) | Total Time 10.00(10.00)\n",
      "Iter 2939 | Time 40.4908(40.7406) | Bit/dim 1.0813(1.0817) | Xent 0.0000(0.0000) | Loss 1.0813(1.0817) | Error 0.0000(0.0000) Steps 554(554.95) | Grad Norm 0.1399(0.1521) | Total Time 10.00(10.00)\n",
      "Iter 2940 | Time 41.5393(40.7645) | Bit/dim 1.0834(1.0817) | Xent 0.0000(0.0000) | Loss 1.0834(1.0817) | Error 0.0000(0.0000) Steps 554(554.92) | Grad Norm 0.0711(0.1497) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 21.2709, Epoch Time 321.8767(316.9522), Bit/dim 1.0761(best: 1.0755), Xent 0.0000, Loss 1.0761, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2941 | Time 40.4082(40.7538) | Bit/dim 1.0849(1.0818) | Xent 0.0000(0.0000) | Loss 1.0849(1.0818) | Error 0.0000(0.0000) Steps 554(554.89) | Grad Norm 0.0532(0.1468) | Total Time 10.00(10.00)\n",
      "Iter 2942 | Time 40.5414(40.7475) | Bit/dim 1.0771(1.0817) | Xent 0.0000(0.0000) | Loss 1.0771(1.0817) | Error 0.0000(0.0000) Steps 560(555.04) | Grad Norm 0.0700(0.1445) | Total Time 10.00(10.00)\n",
      "Iter 2943 | Time 42.3188(40.7946) | Bit/dim 1.0800(1.0816) | Xent 0.0000(0.0000) | Loss 1.0800(1.0816) | Error 0.0000(0.0000) Steps 572(555.55) | Grad Norm 0.0794(0.1425) | Total Time 10.00(10.00)\n",
      "Iter 2944 | Time 40.4790(40.7851) | Bit/dim 1.0828(1.0817) | Xent 0.0000(0.0000) | Loss 1.0828(1.0817) | Error 0.0000(0.0000) Steps 554(555.51) | Grad Norm 0.0682(0.1403) | Total Time 10.00(10.00)\n",
      "Iter 2945 | Time 39.4803(40.7460) | Bit/dim 1.0800(1.0816) | Xent 0.0000(0.0000) | Loss 1.0800(1.0816) | Error 0.0000(0.0000) Steps 554(555.46) | Grad Norm 0.0562(0.1378) | Total Time 10.00(10.00)\n",
      "Iter 2946 | Time 41.7972(40.7775) | Bit/dim 1.0847(1.0817) | Xent 0.0000(0.0000) | Loss 1.0847(1.0817) | Error 0.0000(0.0000) Steps 554(555.42) | Grad Norm 0.0634(0.1356) | Total Time 10.00(10.00)\n",
      "Iter 2947 | Time 40.2368(40.7613) | Bit/dim 1.0784(1.0816) | Xent 0.0000(0.0000) | Loss 1.0784(1.0816) | Error 0.0000(0.0000) Steps 554(555.38) | Grad Norm 0.0509(0.1330) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 21.3325, Epoch Time 319.3277(317.0235), Bit/dim 1.0764(best: 1.0755), Xent 0.0000, Loss 1.0764, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2948 | Time 39.6060(40.7266) | Bit/dim 1.0798(1.0816) | Xent 0.0000(0.0000) | Loss 1.0798(1.0816) | Error 0.0000(0.0000) Steps 560(555.51) | Grad Norm 0.0721(0.1312) | Total Time 10.00(10.00)\n",
      "Iter 2949 | Time 40.5807(40.7223) | Bit/dim 1.0799(1.0815) | Xent 0.0000(0.0000) | Loss 1.0799(1.0815) | Error 0.0000(0.0000) Steps 554(555.47) | Grad Norm 0.0658(0.1292) | Total Time 10.00(10.00)\n",
      "Iter 2950 | Time 40.7751(40.7239) | Bit/dim 1.0800(1.0815) | Xent 0.0000(0.0000) | Loss 1.0800(1.0815) | Error 0.0000(0.0000) Steps 572(555.96) | Grad Norm 0.0772(0.1277) | Total Time 10.00(10.00)\n",
      "Iter 2951 | Time 41.4259(40.7449) | Bit/dim 1.0831(1.0815) | Xent 0.0000(0.0000) | Loss 1.0831(1.0815) | Error 0.0000(0.0000) Steps 572(556.45) | Grad Norm 0.0827(0.1263) | Total Time 10.00(10.00)\n",
      "Iter 2952 | Time 40.4162(40.7351) | Bit/dim 1.0784(1.0814) | Xent 0.0000(0.0000) | Loss 1.0784(1.0814) | Error 0.0000(0.0000) Steps 554(556.37) | Grad Norm 0.0648(0.1245) | Total Time 10.00(10.00)\n",
      "Iter 2953 | Time 42.2986(40.7820) | Bit/dim 1.0826(1.0814) | Xent 0.0000(0.0000) | Loss 1.0826(1.0814) | Error 0.0000(0.0000) Steps 560(556.48) | Grad Norm 0.0780(0.1231) | Total Time 10.00(10.00)\n",
      "Iter 2954 | Time 41.2121(40.7949) | Bit/dim 1.0808(1.0814) | Xent 0.0000(0.0000) | Loss 1.0808(1.0814) | Error 0.0000(0.0000) Steps 554(556.41) | Grad Norm 0.0613(0.1212) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 21.3872, Epoch Time 320.1622(317.1176), Bit/dim 1.0758(best: 1.0755), Xent 0.0000, Loss 1.0758, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2955 | Time 42.5220(40.8467) | Bit/dim 1.0809(1.0814) | Xent 0.0000(0.0000) | Loss 1.0809(1.0814) | Error 0.0000(0.0000) Steps 572(556.87) | Grad Norm 0.0568(0.1193) | Total Time 10.00(10.00)\n",
      "Iter 2956 | Time 41.0410(40.8525) | Bit/dim 1.0803(1.0814) | Xent 0.0000(0.0000) | Loss 1.0803(1.0814) | Error 0.0000(0.0000) Steps 554(556.79) | Grad Norm 0.0579(0.1175) | Total Time 10.00(10.00)\n",
      "Iter 2957 | Time 41.1015(40.8600) | Bit/dim 1.0796(1.0813) | Xent 0.0000(0.0000) | Loss 1.0796(1.0813) | Error 0.0000(0.0000) Steps 554(556.70) | Grad Norm 0.0727(0.1161) | Total Time 10.00(10.00)\n",
      "Iter 2958 | Time 40.1300(40.8381) | Bit/dim 1.0853(1.0814) | Xent 0.0000(0.0000) | Loss 1.0853(1.0814) | Error 0.0000(0.0000) Steps 554(556.62) | Grad Norm 0.0466(0.1140) | Total Time 10.00(10.00)\n",
      "Iter 2959 | Time 39.7296(40.8048) | Bit/dim 1.0779(1.0813) | Xent 0.0000(0.0000) | Loss 1.0779(1.0813) | Error 0.0000(0.0000) Steps 554(556.54) | Grad Norm 0.0597(0.1124) | Total Time 10.00(10.00)\n",
      "Iter 2960 | Time 42.6025(40.8588) | Bit/dim 1.0828(1.0814) | Xent 0.0000(0.0000) | Loss 1.0828(1.0814) | Error 0.0000(0.0000) Steps 554(556.47) | Grad Norm 0.0492(0.1105) | Total Time 10.00(10.00)\n",
      "Iter 2961 | Time 40.2243(40.8397) | Bit/dim 1.0781(1.0813) | Xent 0.0000(0.0000) | Loss 1.0781(1.0813) | Error 0.0000(0.0000) Steps 560(556.57) | Grad Norm 0.0609(0.1090) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 21.2684, Epoch Time 321.0577(317.2358), Bit/dim 1.0758(best: 1.0755), Xent 0.0000, Loss 1.0758, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2962 | Time 41.6186(40.8631) | Bit/dim 1.0829(1.0813) | Xent 0.0000(0.0000) | Loss 1.0829(1.0813) | Error 0.0000(0.0000) Steps 554(556.50) | Grad Norm 0.0689(0.1078) | Total Time 10.00(10.00)\n",
      "Iter 2963 | Time 40.7454(40.8596) | Bit/dim 1.0794(1.0813) | Xent 0.0000(0.0000) | Loss 1.0794(1.0813) | Error 0.0000(0.0000) Steps 554(556.42) | Grad Norm 0.0527(0.1062) | Total Time 10.00(10.00)\n",
      "Iter 2964 | Time 41.6212(40.8824) | Bit/dim 1.0796(1.0812) | Xent 0.0000(0.0000) | Loss 1.0796(1.0812) | Error 0.0000(0.0000) Steps 560(556.53) | Grad Norm 0.0611(0.1048) | Total Time 10.00(10.00)\n",
      "Iter 2965 | Time 41.4785(40.9003) | Bit/dim 1.0845(1.0813) | Xent 0.0000(0.0000) | Loss 1.0845(1.0813) | Error 0.0000(0.0000) Steps 572(556.99) | Grad Norm 0.0510(0.1032) | Total Time 10.00(10.00)\n",
      "Iter 2966 | Time 40.5751(40.8905) | Bit/dim 1.0853(1.0814) | Xent 0.0000(0.0000) | Loss 1.0853(1.0814) | Error 0.0000(0.0000) Steps 560(557.08) | Grad Norm 0.1082(0.1033) | Total Time 10.00(10.00)\n",
      "Iter 2967 | Time 42.2476(40.9312) | Bit/dim 1.0813(1.0814) | Xent 0.0000(0.0000) | Loss 1.0813(1.0814) | Error 0.0000(0.0000) Steps 554(556.99) | Grad Norm 0.0726(0.1024) | Total Time 10.00(10.00)\n",
      "Iter 2968 | Time 41.9370(40.9614) | Bit/dim 1.0760(1.0813) | Xent 0.0000(0.0000) | Loss 1.0760(1.0813) | Error 0.0000(0.0000) Steps 554(556.90) | Grad Norm 0.0566(0.1010) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 21.1632, Epoch Time 323.7838(317.4323), Bit/dim 1.0757(best: 1.0755), Xent 0.0000, Loss 1.0757, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2969 | Time 41.5918(40.9803) | Bit/dim 1.0828(1.0813) | Xent 0.0000(0.0000) | Loss 1.0828(1.0813) | Error 0.0000(0.0000) Steps 554(556.81) | Grad Norm 0.0490(0.0995) | Total Time 10.00(10.00)\n",
      "Iter 2970 | Time 41.5609(40.9977) | Bit/dim 1.0818(1.0813) | Xent 0.0000(0.0000) | Loss 1.0818(1.0813) | Error 0.0000(0.0000) Steps 554(556.73) | Grad Norm 0.0493(0.0980) | Total Time 10.00(10.00)\n",
      "Iter 2971 | Time 42.0574(41.0295) | Bit/dim 1.0878(1.0815) | Xent 0.0000(0.0000) | Loss 1.0878(1.0815) | Error 0.0000(0.0000) Steps 560(556.83) | Grad Norm 0.0635(0.0969) | Total Time 10.00(10.00)\n",
      "Iter 2972 | Time 42.3844(41.0702) | Bit/dim 1.0797(1.0815) | Xent 0.0000(0.0000) | Loss 1.0797(1.0815) | Error 0.0000(0.0000) Steps 560(556.92) | Grad Norm 0.0509(0.0956) | Total Time 10.00(10.00)\n",
      "Iter 2973 | Time 41.8416(41.0933) | Bit/dim 1.0760(1.0813) | Xent 0.0000(0.0000) | Loss 1.0760(1.0813) | Error 0.0000(0.0000) Steps 560(557.02) | Grad Norm 0.0510(0.0942) | Total Time 10.00(10.00)\n",
      "Iter 2974 | Time 42.6930(41.1413) | Bit/dim 1.0786(1.0812) | Xent 0.0000(0.0000) | Loss 1.0786(1.0812) | Error 0.0000(0.0000) Steps 572(557.47) | Grad Norm 0.0732(0.0936) | Total Time 10.00(10.00)\n",
      "Iter 2975 | Time 41.7046(41.1582) | Bit/dim 1.0788(1.0812) | Xent 0.0000(0.0000) | Loss 1.0788(1.0812) | Error 0.0000(0.0000) Steps 566(557.72) | Grad Norm 0.0702(0.0929) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 21.1495, Epoch Time 327.8780(317.7456), Bit/dim 1.0762(best: 1.0755), Xent 0.0000, Loss 1.0762, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2976 | Time 42.8254(41.2082) | Bit/dim 1.0825(1.0812) | Xent 0.0000(0.0000) | Loss 1.0825(1.0812) | Error 0.0000(0.0000) Steps 554(557.61) | Grad Norm 0.0528(0.0917) | Total Time 10.00(10.00)\n",
      "Iter 2977 | Time 43.1268(41.2658) | Bit/dim 1.0822(1.0812) | Xent 0.0000(0.0000) | Loss 1.0822(1.0812) | Error 0.0000(0.0000) Steps 578(558.22) | Grad Norm 0.0784(0.0913) | Total Time 10.00(10.00)\n",
      "Iter 2978 | Time 41.2713(41.2660) | Bit/dim 1.0816(1.0812) | Xent 0.0000(0.0000) | Loss 1.0816(1.0812) | Error 0.0000(0.0000) Steps 560(558.27) | Grad Norm 0.0502(0.0901) | Total Time 10.00(10.00)\n",
      "Iter 2979 | Time 41.9163(41.2855) | Bit/dim 1.0855(1.0814) | Xent 0.0000(0.0000) | Loss 1.0855(1.0814) | Error 0.0000(0.0000) Steps 560(558.33) | Grad Norm 0.0567(0.0891) | Total Time 10.00(10.00)\n",
      "Iter 2980 | Time 40.8419(41.2722) | Bit/dim 1.0808(1.0813) | Xent 0.0000(0.0000) | Loss 1.0808(1.0813) | Error 0.0000(0.0000) Steps 554(558.20) | Grad Norm 0.0552(0.0880) | Total Time 10.00(10.00)\n",
      "Iter 2981 | Time 41.9636(41.2929) | Bit/dim 1.0790(1.0813) | Xent 0.0000(0.0000) | Loss 1.0790(1.0813) | Error 0.0000(0.0000) Steps 566(558.43) | Grad Norm 0.0721(0.0876) | Total Time 10.00(10.00)\n",
      "Iter 2982 | Time 41.4945(41.2989) | Bit/dim 1.0765(1.0811) | Xent 0.0000(0.0000) | Loss 1.0765(1.0811) | Error 0.0000(0.0000) Steps 554(558.30) | Grad Norm 0.0536(0.0865) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 21.1806, Epoch Time 327.0926(318.0260), Bit/dim 1.0758(best: 1.0755), Xent 0.0000, Loss 1.0758, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2983 | Time 40.5762(41.2773) | Bit/dim 1.0837(1.0812) | Xent 0.0000(0.0000) | Loss 1.0837(1.0812) | Error 0.0000(0.0000) Steps 560(558.35) | Grad Norm 0.0700(0.0861) | Total Time 10.00(10.00)\n",
      "Iter 2984 | Time 42.6500(41.3184) | Bit/dim 1.0806(1.0812) | Xent 0.0000(0.0000) | Loss 1.0806(1.0812) | Error 0.0000(0.0000) Steps 554(558.22) | Grad Norm 0.0695(0.0856) | Total Time 10.00(10.00)\n",
      "Iter 2985 | Time 42.7215(41.3605) | Bit/dim 1.0800(1.0812) | Xent 0.0000(0.0000) | Loss 1.0800(1.0812) | Error 0.0000(0.0000) Steps 554(558.09) | Grad Norm 0.0534(0.0846) | Total Time 10.00(10.00)\n",
      "Iter 2986 | Time 42.0477(41.3812) | Bit/dim 1.0851(1.0813) | Xent 0.0000(0.0000) | Loss 1.0851(1.0813) | Error 0.0000(0.0000) Steps 560(558.15) | Grad Norm 0.0562(0.0837) | Total Time 10.00(10.00)\n",
      "Iter 2987 | Time 42.8663(41.4257) | Bit/dim 1.0802(1.0812) | Xent 0.0000(0.0000) | Loss 1.0802(1.0812) | Error 0.0000(0.0000) Steps 572(558.56) | Grad Norm 0.0695(0.0833) | Total Time 10.00(10.00)\n",
      "Iter 2988 | Time 42.1939(41.4488) | Bit/dim 1.0783(1.0812) | Xent 0.0000(0.0000) | Loss 1.0783(1.0812) | Error 0.0000(0.0000) Steps 560(558.61) | Grad Norm 0.0794(0.0832) | Total Time 10.00(10.00)\n",
      "Iter 2989 | Time 43.2525(41.5029) | Bit/dim 1.0799(1.0811) | Xent 0.0000(0.0000) | Loss 1.0799(1.0811) | Error 0.0000(0.0000) Steps 554(558.47) | Grad Norm 0.0925(0.0835) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 21.2463, Epoch Time 330.2625(318.3931), Bit/dim 1.0767(best: 1.0755), Xent 0.0000, Loss 1.0767, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2990 | Time 42.2229(41.5245) | Bit/dim 1.0817(1.0811) | Xent 0.0000(0.0000) | Loss 1.0817(1.0811) | Error 0.0000(0.0000) Steps 560(558.52) | Grad Norm 0.0453(0.0823) | Total Time 10.00(10.00)\n",
      "Iter 2991 | Time 42.0457(41.5401) | Bit/dim 1.0820(1.0812) | Xent 0.0000(0.0000) | Loss 1.0820(1.0812) | Error 0.0000(0.0000) Steps 578(559.10) | Grad Norm 0.0590(0.0816) | Total Time 10.00(10.00)\n",
      "Iter 2992 | Time 42.1530(41.5585) | Bit/dim 1.0836(1.0812) | Xent 0.0000(0.0000) | Loss 1.0836(1.0812) | Error 0.0000(0.0000) Steps 578(559.67) | Grad Norm 0.0767(0.0815) | Total Time 10.00(10.00)\n",
      "Iter 2993 | Time 41.4781(41.5561) | Bit/dim 1.0772(1.0811) | Xent 0.0000(0.0000) | Loss 1.0772(1.0811) | Error 0.0000(0.0000) Steps 560(559.68) | Grad Norm 0.0989(0.0820) | Total Time 10.00(10.00)\n",
      "Iter 2994 | Time 41.5136(41.5548) | Bit/dim 1.0818(1.0811) | Xent 0.0000(0.0000) | Loss 1.0818(1.0811) | Error 0.0000(0.0000) Steps 566(559.87) | Grad Norm 0.0921(0.0823) | Total Time 10.00(10.00)\n",
      "Iter 2995 | Time 41.6426(41.5574) | Bit/dim 1.0823(1.0812) | Xent 0.0000(0.0000) | Loss 1.0823(1.0812) | Error 0.0000(0.0000) Steps 560(559.87) | Grad Norm 0.0522(0.0814) | Total Time 10.00(10.00)\n",
      "Iter 2996 | Time 42.2977(41.5796) | Bit/dim 1.0773(1.0811) | Xent 0.0000(0.0000) | Loss 1.0773(1.0811) | Error 0.0000(0.0000) Steps 554(559.69) | Grad Norm 0.0527(0.0805) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 21.1560, Epoch Time 326.8808(318.6478), Bit/dim 1.0756(best: 1.0755), Xent 0.0000, Loss 1.0756, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2997 | Time 41.6505(41.5818) | Bit/dim 1.0866(1.0812) | Xent 0.0000(0.0000) | Loss 1.0866(1.0812) | Error 0.0000(0.0000) Steps 578(560.24) | Grad Norm 0.0891(0.0808) | Total Time 10.00(10.00)\n",
      "Iter 2998 | Time 41.6993(41.5853) | Bit/dim 1.0783(1.0811) | Xent 0.0000(0.0000) | Loss 1.0783(1.0811) | Error 0.0000(0.0000) Steps 554(560.06) | Grad Norm 0.1024(0.0814) | Total Time 10.00(10.00)\n",
      "Iter 2999 | Time 42.4909(41.6125) | Bit/dim 1.0816(1.0811) | Xent 0.0000(0.0000) | Loss 1.0816(1.0811) | Error 0.0000(0.0000) Steps 578(560.59) | Grad Norm 0.0552(0.0807) | Total Time 10.00(10.00)\n",
      "Iter 3000 | Time 42.0032(41.6242) | Bit/dim 1.0769(1.0810) | Xent 0.0000(0.0000) | Loss 1.0769(1.0810) | Error 0.0000(0.0000) Steps 560(560.58) | Grad Norm 0.0516(0.0798) | Total Time 10.00(10.00)\n",
      "Iter 3001 | Time 41.8140(41.6299) | Bit/dim 1.0800(1.0810) | Xent 0.0000(0.0000) | Loss 1.0800(1.0810) | Error 0.0000(0.0000) Steps 578(561.10) | Grad Norm 0.0601(0.0792) | Total Time 10.00(10.00)\n",
      "Iter 3002 | Time 42.5444(41.6573) | Bit/dim 1.0791(1.0809) | Xent 0.0000(0.0000) | Loss 1.0791(1.0809) | Error 0.0000(0.0000) Steps 578(561.61) | Grad Norm 0.0580(0.0786) | Total Time 10.00(10.00)\n",
      "Iter 3003 | Time 41.1272(41.6414) | Bit/dim 1.0802(1.0809) | Xent 0.0000(0.0000) | Loss 1.0802(1.0809) | Error 0.0000(0.0000) Steps 560(561.56) | Grad Norm 0.0602(0.0780) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 21.2764, Epoch Time 326.9475(318.8968), Bit/dim 1.0760(best: 1.0755), Xent 0.0000, Loss 1.0760, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3004 | Time 42.1569(41.6569) | Bit/dim 1.0807(1.0809) | Xent 0.0000(0.0000) | Loss 1.0807(1.0809) | Error 0.0000(0.0000) Steps 560(561.51) | Grad Norm 0.0613(0.0775) | Total Time 10.00(10.00)\n",
      "Iter 3005 | Time 44.0387(41.7283) | Bit/dim 1.0776(1.0808) | Xent 0.0000(0.0000) | Loss 1.0776(1.0808) | Error 0.0000(0.0000) Steps 554(561.29) | Grad Norm 0.0850(0.0777) | Total Time 10.00(10.00)\n",
      "Iter 3006 | Time 41.6186(41.7250) | Bit/dim 1.0811(1.0808) | Xent 0.0000(0.0000) | Loss 1.0811(1.0808) | Error 0.0000(0.0000) Steps 560(561.25) | Grad Norm 0.0469(0.0768) | Total Time 10.00(10.00)\n",
      "Iter 3007 | Time 43.4198(41.7759) | Bit/dim 1.0779(1.0807) | Xent 0.0000(0.0000) | Loss 1.0779(1.0807) | Error 0.0000(0.0000) Steps 560(561.21) | Grad Norm 0.0431(0.0758) | Total Time 10.00(10.00)\n",
      "Iter 3008 | Time 43.6159(41.8311) | Bit/dim 1.0827(1.0808) | Xent 0.0000(0.0000) | Loss 1.0827(1.0808) | Error 0.0000(0.0000) Steps 572(561.53) | Grad Norm 0.0839(0.0760) | Total Time 10.00(10.00)\n",
      "Iter 3009 | Time 41.4588(41.8199) | Bit/dim 1.0806(1.0808) | Xent 0.0000(0.0000) | Loss 1.0806(1.0808) | Error 0.0000(0.0000) Steps 578(562.03) | Grad Norm 0.0848(0.0763) | Total Time 10.00(10.00)\n",
      "Iter 3010 | Time 41.8639(41.8212) | Bit/dim 1.0826(1.0808) | Xent 0.0000(0.0000) | Loss 1.0826(1.0808) | Error 0.0000(0.0000) Steps 560(561.97) | Grad Norm 0.0529(0.0756) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 21.1635, Epoch Time 331.7053(319.2810), Bit/dim 1.0760(best: 1.0755), Xent 0.0000, Loss 1.0760, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3011 | Time 41.9059(41.8238) | Bit/dim 1.0790(1.0808) | Xent 0.0000(0.0000) | Loss 1.0790(1.0808) | Error 0.0000(0.0000) Steps 554(561.73) | Grad Norm 0.0545(0.0750) | Total Time 10.00(10.00)\n",
      "Iter 3012 | Time 41.7503(41.8216) | Bit/dim 1.0784(1.0807) | Xent 0.0000(0.0000) | Loss 1.0784(1.0807) | Error 0.0000(0.0000) Steps 578(562.22) | Grad Norm 0.0470(0.0741) | Total Time 10.00(10.00)\n",
      "Iter 3013 | Time 41.7725(41.8201) | Bit/dim 1.0858(1.0809) | Xent 0.0000(0.0000) | Loss 1.0858(1.0809) | Error 0.0000(0.0000) Steps 560(562.15) | Grad Norm 0.0684(0.0740) | Total Time 10.00(10.00)\n",
      "Iter 3014 | Time 43.1554(41.8602) | Bit/dim 1.0766(1.0807) | Xent 0.0000(0.0000) | Loss 1.0766(1.0807) | Error 0.0000(0.0000) Steps 560(562.09) | Grad Norm 0.0659(0.0737) | Total Time 10.00(10.00)\n",
      "Iter 3015 | Time 41.9785(41.8637) | Bit/dim 1.0853(1.0809) | Xent 0.0000(0.0000) | Loss 1.0853(1.0809) | Error 0.0000(0.0000) Steps 560(562.02) | Grad Norm 0.0459(0.0729) | Total Time 10.00(10.00)\n",
      "Iter 3016 | Time 42.4822(41.8823) | Bit/dim 1.0804(1.0809) | Xent 0.0000(0.0000) | Loss 1.0804(1.0809) | Error 0.0000(0.0000) Steps 560(561.96) | Grad Norm 0.0515(0.0722) | Total Time 10.00(10.00)\n",
      "Iter 3017 | Time 42.3841(41.8973) | Bit/dim 1.0796(1.0808) | Xent 0.0000(0.0000) | Loss 1.0796(1.0808) | Error 0.0000(0.0000) Steps 566(562.08) | Grad Norm 0.0464(0.0715) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 21.0692, Epoch Time 329.1780(319.5779), Bit/dim 1.0756(best: 1.0755), Xent 0.0000, Loss 1.0756, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3018 | Time 41.0227(41.8711) | Bit/dim 1.0815(1.0808) | Xent 0.0000(0.0000) | Loss 1.0815(1.0808) | Error 0.0000(0.0000) Steps 560(562.02) | Grad Norm 0.0648(0.0713) | Total Time 10.00(10.00)\n",
      "Iter 3019 | Time 41.4982(41.8599) | Bit/dim 1.0786(1.0808) | Xent 0.0000(0.0000) | Loss 1.0786(1.0808) | Error 0.0000(0.0000) Steps 560(561.96) | Grad Norm 0.0645(0.0711) | Total Time 10.00(10.00)\n",
      "Iter 3020 | Time 43.0616(41.8959) | Bit/dim 1.0826(1.0808) | Xent 0.0000(0.0000) | Loss 1.0826(1.0808) | Error 0.0000(0.0000) Steps 578(562.44) | Grad Norm 0.0598(0.0707) | Total Time 10.00(10.00)\n",
      "Iter 3021 | Time 41.8673(41.8951) | Bit/dim 1.0818(1.0809) | Xent 0.0000(0.0000) | Loss 1.0818(1.0809) | Error 0.0000(0.0000) Steps 560(562.37) | Grad Norm 0.0600(0.0704) | Total Time 10.00(10.00)\n",
      "Iter 3022 | Time 41.3142(41.8777) | Bit/dim 1.0784(1.0808) | Xent 0.0000(0.0000) | Loss 1.0784(1.0808) | Error 0.0000(0.0000) Steps 566(562.48) | Grad Norm 0.0671(0.0703) | Total Time 10.00(10.00)\n",
      "Iter 3023 | Time 41.7675(41.8744) | Bit/dim 1.0813(1.0808) | Xent 0.0000(0.0000) | Loss 1.0813(1.0808) | Error 0.0000(0.0000) Steps 560(562.40) | Grad Norm 0.0697(0.0703) | Total Time 10.00(10.00)\n",
      "Iter 3024 | Time 40.8462(41.8435) | Bit/dim 1.0824(1.0808) | Xent 0.0000(0.0000) | Loss 1.0824(1.0808) | Error 0.0000(0.0000) Steps 560(562.33) | Grad Norm 0.0438(0.0695) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 21.4442, Epoch Time 325.3751(319.7518), Bit/dim 1.0753(best: 1.0755), Xent 0.0000, Loss 1.0753, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3025 | Time 40.8387(41.8134) | Bit/dim 1.0826(1.0809) | Xent 0.0000(0.0000) | Loss 1.0826(1.0809) | Error 0.0000(0.0000) Steps 560(562.26) | Grad Norm 0.0539(0.0690) | Total Time 10.00(10.00)\n",
      "Iter 3026 | Time 42.8788(41.8453) | Bit/dim 1.0832(1.0810) | Xent 0.0000(0.0000) | Loss 1.0832(1.0810) | Error 0.0000(0.0000) Steps 578(562.73) | Grad Norm 0.0886(0.0696) | Total Time 10.00(10.00)\n",
      "Iter 3027 | Time 41.5855(41.8375) | Bit/dim 1.0804(1.0810) | Xent 0.0000(0.0000) | Loss 1.0804(1.0810) | Error 0.0000(0.0000) Steps 578(563.19) | Grad Norm 0.0527(0.0691) | Total Time 10.00(10.00)\n",
      "Iter 3028 | Time 42.4150(41.8549) | Bit/dim 1.0805(1.0809) | Xent 0.0000(0.0000) | Loss 1.0805(1.0809) | Error 0.0000(0.0000) Steps 578(563.64) | Grad Norm 0.0476(0.0685) | Total Time 10.00(10.00)\n",
      "Iter 3029 | Time 42.7611(41.8820) | Bit/dim 1.0764(1.0808) | Xent 0.0000(0.0000) | Loss 1.0764(1.0808) | Error 0.0000(0.0000) Steps 560(563.53) | Grad Norm 0.0621(0.0683) | Total Time 10.00(10.00)\n",
      "Iter 3030 | Time 42.6051(41.9037) | Bit/dim 1.0802(1.0808) | Xent 0.0000(0.0000) | Loss 1.0802(1.0808) | Error 0.0000(0.0000) Steps 560(563.42) | Grad Norm 0.0479(0.0677) | Total Time 10.00(10.00)\n",
      "Iter 3031 | Time 41.3296(41.8865) | Bit/dim 1.0813(1.0808) | Xent 0.0000(0.0000) | Loss 1.0813(1.0808) | Error 0.0000(0.0000) Steps 578(563.86) | Grad Norm 0.0689(0.0677) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 21.3273, Epoch Time 328.2529(320.0069), Bit/dim 1.0752(best: 1.0753), Xent 0.0000, Loss 1.0752, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3032 | Time 42.0811(41.8923) | Bit/dim 1.0830(1.0809) | Xent 0.0000(0.0000) | Loss 1.0830(1.0809) | Error 0.0000(0.0000) Steps 560(563.74) | Grad Norm 0.0514(0.0672) | Total Time 10.00(10.00)\n",
      "Iter 3033 | Time 40.3702(41.8467) | Bit/dim 1.0761(1.0807) | Xent 0.0000(0.0000) | Loss 1.0761(1.0807) | Error 0.0000(0.0000) Steps 560(563.63) | Grad Norm 0.0556(0.0669) | Total Time 10.00(10.00)\n",
      "Iter 3034 | Time 40.9573(41.8200) | Bit/dim 1.0763(1.0806) | Xent 0.0000(0.0000) | Loss 1.0763(1.0806) | Error 0.0000(0.0000) Steps 560(563.52) | Grad Norm 0.0488(0.0663) | Total Time 10.00(10.00)\n",
      "Iter 3035 | Time 42.1218(41.8291) | Bit/dim 1.0870(1.0808) | Xent 0.0000(0.0000) | Loss 1.0870(1.0808) | Error 0.0000(0.0000) Steps 560(563.42) | Grad Norm 0.0705(0.0664) | Total Time 10.00(10.00)\n",
      "Iter 3036 | Time 42.7642(41.8571) | Bit/dim 1.0860(1.0809) | Xent 0.0000(0.0000) | Loss 1.0860(1.0809) | Error 0.0000(0.0000) Steps 578(563.85) | Grad Norm 0.0513(0.0660) | Total Time 10.00(10.00)\n",
      "Iter 3037 | Time 40.9176(41.8289) | Bit/dim 1.0817(1.0810) | Xent 0.0000(0.0000) | Loss 1.0817(1.0810) | Error 0.0000(0.0000) Steps 560(563.74) | Grad Norm 0.0488(0.0655) | Total Time 10.00(10.00)\n",
      "Iter 3038 | Time 42.6330(41.8531) | Bit/dim 1.0765(1.0808) | Xent 0.0000(0.0000) | Loss 1.0765(1.0808) | Error 0.0000(0.0000) Steps 560(563.63) | Grad Norm 0.0457(0.0649) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 21.4682, Epoch Time 325.9940(320.1865), Bit/dim 1.0754(best: 1.0752), Xent 0.0000, Loss 1.0754, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3039 | Time 42.0664(41.8595) | Bit/dim 1.0750(1.0807) | Xent 0.0000(0.0000) | Loss 1.0750(1.0807) | Error 0.0000(0.0000) Steps 578(564.06) | Grad Norm 0.0450(0.0643) | Total Time 10.00(10.00)\n",
      "Iter 3040 | Time 41.7623(41.8565) | Bit/dim 1.0831(1.0807) | Xent 0.0000(0.0000) | Loss 1.0831(1.0807) | Error 0.0000(0.0000) Steps 560(563.93) | Grad Norm 0.0650(0.0643) | Total Time 10.00(10.00)\n",
      "Iter 3041 | Time 43.4351(41.9039) | Bit/dim 1.0832(1.0808) | Xent 0.0000(0.0000) | Loss 1.0832(1.0808) | Error 0.0000(0.0000) Steps 560(563.82) | Grad Norm 0.0446(0.0637) | Total Time 10.00(10.00)\n",
      "Iter 3042 | Time 41.8008(41.9008) | Bit/dim 1.0783(1.0807) | Xent 0.0000(0.0000) | Loss 1.0783(1.0807) | Error 0.0000(0.0000) Steps 578(564.24) | Grad Norm 0.0450(0.0632) | Total Time 10.00(10.00)\n",
      "Iter 3043 | Time 40.1390(41.8479) | Bit/dim 1.0833(1.0808) | Xent 0.0000(0.0000) | Loss 1.0833(1.0808) | Error 0.0000(0.0000) Steps 566(564.29) | Grad Norm 0.0449(0.0626) | Total Time 10.00(10.00)\n",
      "Iter 3044 | Time 41.2737(41.8307) | Bit/dim 1.0829(1.0809) | Xent 0.0000(0.0000) | Loss 1.0829(1.0809) | Error 0.0000(0.0000) Steps 560(564.17) | Grad Norm 0.0424(0.0620) | Total Time 10.00(10.00)\n",
      "Iter 3045 | Time 40.5135(41.7912) | Bit/dim 1.0802(1.0808) | Xent 0.0000(0.0000) | Loss 1.0802(1.0808) | Error 0.0000(0.0000) Steps 560(564.04) | Grad Norm 0.0580(0.0619) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 21.6445, Epoch Time 325.1139(320.3343), Bit/dim 1.0757(best: 1.0752), Xent 0.0000, Loss 1.0757, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3046 | Time 41.3390(41.7776) | Bit/dim 1.0816(1.0809) | Xent 0.0000(0.0000) | Loss 1.0816(1.0809) | Error 0.0000(0.0000) Steps 560(563.92) | Grad Norm 0.0543(0.0617) | Total Time 10.00(10.00)\n",
      "Iter 3047 | Time 41.5055(41.7695) | Bit/dim 1.0809(1.0809) | Xent 0.0000(0.0000) | Loss 1.0809(1.0809) | Error 0.0000(0.0000) Steps 560(563.80) | Grad Norm 0.0490(0.0613) | Total Time 10.00(10.00)\n",
      "Iter 3048 | Time 41.0468(41.7478) | Bit/dim 1.0787(1.0808) | Xent 0.0000(0.0000) | Loss 1.0787(1.0808) | Error 0.0000(0.0000) Steps 578(564.23) | Grad Norm 0.0458(0.0608) | Total Time 10.00(10.00)\n",
      "Iter 3049 | Time 41.6961(41.7462) | Bit/dim 1.0843(1.0809) | Xent 0.0000(0.0000) | Loss 1.0843(1.0809) | Error 0.0000(0.0000) Steps 560(564.10) | Grad Norm 0.0648(0.0609) | Total Time 10.00(10.00)\n",
      "Iter 3050 | Time 41.8703(41.7500) | Bit/dim 1.0761(1.0808) | Xent 0.0000(0.0000) | Loss 1.0761(1.0808) | Error 0.0000(0.0000) Steps 560(563.98) | Grad Norm 0.0571(0.0608) | Total Time 10.00(10.00)\n",
      "Iter 3051 | Time 40.7207(41.7191) | Bit/dim 1.0802(1.0808) | Xent 0.0000(0.0000) | Loss 1.0802(1.0808) | Error 0.0000(0.0000) Steps 578(564.40) | Grad Norm 0.0495(0.0605) | Total Time 10.00(10.00)\n",
      "Iter 3052 | Time 41.4989(41.7125) | Bit/dim 1.0821(1.0808) | Xent 0.0000(0.0000) | Loss 1.0821(1.0808) | Error 0.0000(0.0000) Steps 560(564.27) | Grad Norm 0.0472(0.0601) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 21.2273, Epoch Time 323.5484(320.4307), Bit/dim 1.0752(best: 1.0752), Xent 0.0000, Loss 1.0752, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3053 | Time 41.9002(41.7181) | Bit/dim 1.0805(1.0808) | Xent 0.0000(0.0000) | Loss 1.0805(1.0808) | Error 0.0000(0.0000) Steps 578(564.68) | Grad Norm 0.0593(0.0601) | Total Time 10.00(10.00)\n",
      "Iter 3054 | Time 42.6643(41.7465) | Bit/dim 1.0820(1.0808) | Xent 0.0000(0.0000) | Loss 1.0820(1.0808) | Error 0.0000(0.0000) Steps 560(564.54) | Grad Norm 0.0532(0.0598) | Total Time 10.00(10.00)\n",
      "Iter 3055 | Time 41.1584(41.7289) | Bit/dim 1.0788(1.0808) | Xent 0.0000(0.0000) | Loss 1.0788(1.0808) | Error 0.0000(0.0000) Steps 560(564.40) | Grad Norm 0.0838(0.0606) | Total Time 10.00(10.00)\n",
      "Iter 3056 | Time 42.1064(41.7402) | Bit/dim 1.0797(1.0807) | Xent 0.0000(0.0000) | Loss 1.0797(1.0807) | Error 0.0000(0.0000) Steps 560(564.27) | Grad Norm 0.0583(0.0605) | Total Time 10.00(10.00)\n",
      "Iter 3057 | Time 42.6674(41.7680) | Bit/dim 1.0845(1.0808) | Xent 0.0000(0.0000) | Loss 1.0845(1.0808) | Error 0.0000(0.0000) Steps 578(564.68) | Grad Norm 0.0530(0.0603) | Total Time 10.00(10.00)\n",
      "Iter 3058 | Time 41.5750(41.7622) | Bit/dim 1.0765(1.0807) | Xent 0.0000(0.0000) | Loss 1.0765(1.0807) | Error 0.0000(0.0000) Steps 560(564.54) | Grad Norm 0.0597(0.0603) | Total Time 10.00(10.00)\n",
      "Iter 3059 | Time 42.8023(41.7934) | Bit/dim 1.0788(1.0807) | Xent 0.0000(0.0000) | Loss 1.0788(1.0807) | Error 0.0000(0.0000) Steps 560(564.41) | Grad Norm 0.1185(0.0620) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 21.2646, Epoch Time 328.4364(320.6709), Bit/dim 1.0751(best: 1.0752), Xent 0.0000, Loss 1.0751, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3060 | Time 40.7962(41.7635) | Bit/dim 1.0807(1.0807) | Xent 0.0000(0.0000) | Loss 1.0807(1.0807) | Error 0.0000(0.0000) Steps 560(564.27) | Grad Norm 0.0479(0.0616) | Total Time 10.00(10.00)\n",
      "Iter 3061 | Time 41.3304(41.7505) | Bit/dim 1.0794(1.0806) | Xent 0.0000(0.0000) | Loss 1.0794(1.0806) | Error 0.0000(0.0000) Steps 560(564.15) | Grad Norm 0.0583(0.0615) | Total Time 10.00(10.00)\n",
      "Iter 3062 | Time 42.2067(41.7642) | Bit/dim 1.0771(1.0805) | Xent 0.0000(0.0000) | Loss 1.0771(1.0805) | Error 0.0000(0.0000) Steps 578(564.56) | Grad Norm 0.0630(0.0615) | Total Time 10.00(10.00)\n",
      "Iter 3063 | Time 42.0821(41.7737) | Bit/dim 1.0824(1.0806) | Xent 0.0000(0.0000) | Loss 1.0824(1.0806) | Error 0.0000(0.0000) Steps 560(564.42) | Grad Norm 0.0743(0.0619) | Total Time 10.00(10.00)\n",
      "Iter 3064 | Time 42.3028(41.7896) | Bit/dim 1.0768(1.0805) | Xent 0.0000(0.0000) | Loss 1.0768(1.0805) | Error 0.0000(0.0000) Steps 560(564.29) | Grad Norm 0.0815(0.0625) | Total Time 10.00(10.00)\n",
      "Iter 3065 | Time 41.6525(41.7855) | Bit/dim 1.0829(1.0805) | Xent 0.0000(0.0000) | Loss 1.0829(1.0805) | Error 0.0000(0.0000) Steps 560(564.16) | Grad Norm 0.0724(0.0628) | Total Time 10.00(10.00)\n",
      "Iter 3066 | Time 41.6951(41.7828) | Bit/dim 1.0830(1.0806) | Xent 0.0000(0.0000) | Loss 1.0830(1.0806) | Error 0.0000(0.0000) Steps 578(564.58) | Grad Norm 0.0757(0.0632) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 21.4273, Epoch Time 325.8110(320.8251), Bit/dim 1.0753(best: 1.0751), Xent 0.0000, Loss 1.0753, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3067 | Time 42.0388(41.7905) | Bit/dim 1.0802(1.0806) | Xent 0.0000(0.0000) | Loss 1.0802(1.0806) | Error 0.0000(0.0000) Steps 560(564.44) | Grad Norm 0.0515(0.0628) | Total Time 10.00(10.00)\n",
      "Iter 3068 | Time 42.2259(41.8035) | Bit/dim 1.0794(1.0806) | Xent 0.0000(0.0000) | Loss 1.0794(1.0806) | Error 0.0000(0.0000) Steps 560(564.31) | Grad Norm 0.0809(0.0634) | Total Time 10.00(10.00)\n",
      "Iter 3069 | Time 43.3856(41.8510) | Bit/dim 1.0819(1.0806) | Xent 0.0000(0.0000) | Loss 1.0819(1.0806) | Error 0.0000(0.0000) Steps 560(564.18) | Grad Norm 0.1043(0.0646) | Total Time 10.00(10.00)\n",
      "Iter 3070 | Time 41.6652(41.8454) | Bit/dim 1.0761(1.0805) | Xent 0.0000(0.0000) | Loss 1.0761(1.0805) | Error 0.0000(0.0000) Steps 560(564.05) | Grad Norm 0.0455(0.0640) | Total Time 10.00(10.00)\n",
      "Iter 3071 | Time 41.4175(41.8326) | Bit/dim 1.0819(1.0805) | Xent 0.0000(0.0000) | Loss 1.0819(1.0805) | Error 0.0000(0.0000) Steps 578(564.47) | Grad Norm 0.0713(0.0642) | Total Time 10.00(10.00)\n",
      "Iter 3072 | Time 43.3380(41.8777) | Bit/dim 1.0810(1.0805) | Xent 0.0000(0.0000) | Loss 1.0810(1.0805) | Error 0.0000(0.0000) Steps 560(564.34) | Grad Norm 0.0997(0.0653) | Total Time 10.00(10.00)\n",
      "Iter 3073 | Time 41.9677(41.8804) | Bit/dim 1.0789(1.0805) | Xent 0.0000(0.0000) | Loss 1.0789(1.0805) | Error 0.0000(0.0000) Steps 560(564.21) | Grad Norm 0.0702(0.0655) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 21.1779, Epoch Time 329.7099(321.0917), Bit/dim 1.0753(best: 1.0751), Xent 0.0000, Loss 1.0753, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3074 | Time 42.0710(41.8861) | Bit/dim 1.0813(1.0805) | Xent 0.0000(0.0000) | Loss 1.0813(1.0805) | Error 0.0000(0.0000) Steps 578(564.62) | Grad Norm 0.0678(0.0655) | Total Time 10.00(10.00)\n",
      "Iter 3075 | Time 41.8730(41.8858) | Bit/dim 1.0782(1.0804) | Xent 0.0000(0.0000) | Loss 1.0782(1.0804) | Error 0.0000(0.0000) Steps 578(565.02) | Grad Norm 0.0736(0.0658) | Total Time 10.00(10.00)\n",
      "Iter 3076 | Time 42.5633(41.9061) | Bit/dim 1.0787(1.0804) | Xent 0.0000(0.0000) | Loss 1.0787(1.0804) | Error 0.0000(0.0000) Steps 560(564.87) | Grad Norm 0.0855(0.0664) | Total Time 10.00(10.00)\n",
      "Iter 3077 | Time 41.7324(41.9009) | Bit/dim 1.0796(1.0803) | Xent 0.0000(0.0000) | Loss 1.0796(1.0803) | Error 0.0000(0.0000) Steps 578(565.27) | Grad Norm 0.0636(0.0663) | Total Time 10.00(10.00)\n",
      "Iter 3078 | Time 41.4438(41.8872) | Bit/dim 1.0819(1.0804) | Xent 0.0000(0.0000) | Loss 1.0819(1.0804) | Error 0.0000(0.0000) Steps 560(565.11) | Grad Norm 0.0462(0.0657) | Total Time 10.00(10.00)\n",
      "Iter 3079 | Time 41.9708(41.8897) | Bit/dim 1.0813(1.0804) | Xent 0.0000(0.0000) | Loss 1.0813(1.0804) | Error 0.0000(0.0000) Steps 560(564.95) | Grad Norm 0.0433(0.0650) | Total Time 10.00(10.00)\n",
      "Iter 3080 | Time 41.4430(41.8763) | Bit/dim 1.0796(1.0804) | Xent 0.0000(0.0000) | Loss 1.0796(1.0804) | Error 0.0000(0.0000) Steps 560(564.81) | Grad Norm 0.0507(0.0646) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 21.2194, Epoch Time 326.8553(321.2646), Bit/dim 1.0751(best: 1.0751), Xent 0.0000, Loss 1.0751, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3081 | Time 42.8023(41.9040) | Bit/dim 1.0799(1.0804) | Xent 0.0000(0.0000) | Loss 1.0799(1.0804) | Error 0.0000(0.0000) Steps 578(565.20) | Grad Norm 0.0482(0.0641) | Total Time 10.00(10.00)\n",
      "Iter 3082 | Time 42.2667(41.9149) | Bit/dim 1.0767(1.0803) | Xent 0.0000(0.0000) | Loss 1.0767(1.0803) | Error 0.0000(0.0000) Steps 578(565.59) | Grad Norm 0.0477(0.0636) | Total Time 10.00(10.00)\n",
      "Iter 3083 | Time 42.0571(41.9192) | Bit/dim 1.0808(1.0803) | Xent 0.0000(0.0000) | Loss 1.0808(1.0803) | Error 0.0000(0.0000) Steps 578(565.96) | Grad Norm 0.0486(0.0631) | Total Time 10.00(10.00)\n",
      "Iter 3084 | Time 40.6078(41.8798) | Bit/dim 1.0842(1.0804) | Xent 0.0000(0.0000) | Loss 1.0842(1.0804) | Error 0.0000(0.0000) Steps 560(565.78) | Grad Norm 0.0633(0.0632) | Total Time 10.00(10.00)\n",
      "Iter 3085 | Time 44.2474(41.9509) | Bit/dim 1.0810(1.0804) | Xent 0.0000(0.0000) | Loss 1.0810(1.0804) | Error 0.0000(0.0000) Steps 560(565.61) | Grad Norm 0.0567(0.0630) | Total Time 10.00(10.00)\n",
      "Iter 3086 | Time 42.4726(41.9665) | Bit/dim 1.0814(1.0805) | Xent 0.0000(0.0000) | Loss 1.0814(1.0805) | Error 0.0000(0.0000) Steps 560(565.44) | Grad Norm 0.0455(0.0624) | Total Time 10.00(10.00)\n",
      "Iter 3087 | Time 41.9168(41.9650) | Bit/dim 1.0782(1.0804) | Xent 0.0000(0.0000) | Loss 1.0782(1.0804) | Error 0.0000(0.0000) Steps 560(565.27) | Grad Norm 0.0622(0.0624) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 21.5455, Epoch Time 330.4228(321.5393), Bit/dim 1.0749(best: 1.0751), Xent 0.0000, Loss 1.0749, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3088 | Time 41.8619(41.9619) | Bit/dim 1.0790(1.0803) | Xent 0.0000(0.0000) | Loss 1.0790(1.0803) | Error 0.0000(0.0000) Steps 560(565.12) | Grad Norm 0.0414(0.0618) | Total Time 10.00(10.00)\n",
      "Iter 3089 | Time 41.4638(41.9470) | Bit/dim 1.0817(1.0804) | Xent 0.0000(0.0000) | Loss 1.0817(1.0804) | Error 0.0000(0.0000) Steps 560(564.96) | Grad Norm 0.0488(0.0614) | Total Time 10.00(10.00)\n",
      "Iter 3090 | Time 40.8886(41.9152) | Bit/dim 1.0799(1.0804) | Xent 0.0000(0.0000) | Loss 1.0799(1.0804) | Error 0.0000(0.0000) Steps 578(565.35) | Grad Norm 0.0603(0.0614) | Total Time 10.00(10.00)\n",
      "Iter 3091 | Time 41.8908(41.9145) | Bit/dim 1.0807(1.0804) | Xent 0.0000(0.0000) | Loss 1.0807(1.0804) | Error 0.0000(0.0000) Steps 560(565.19) | Grad Norm 0.0550(0.0612) | Total Time 10.00(10.00)\n",
      "Iter 3092 | Time 41.8417(41.9123) | Bit/dim 1.0814(1.0804) | Xent 0.0000(0.0000) | Loss 1.0814(1.0804) | Error 0.0000(0.0000) Steps 560(565.04) | Grad Norm 0.0549(0.0610) | Total Time 10.00(10.00)\n",
      "Iter 3093 | Time 42.0497(41.9164) | Bit/dim 1.0823(1.0805) | Xent 0.0000(0.0000) | Loss 1.0823(1.0805) | Error 0.0000(0.0000) Steps 578(565.43) | Grad Norm 0.0446(0.0605) | Total Time 10.00(10.00)\n",
      "Iter 3094 | Time 41.4743(41.9032) | Bit/dim 1.0819(1.0805) | Xent 0.0000(0.0000) | Loss 1.0819(1.0805) | Error 0.0000(0.0000) Steps 560(565.26) | Grad Norm 0.0569(0.0604) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 21.2914, Epoch Time 325.4666(321.6571), Bit/dim 1.0751(best: 1.0749), Xent 0.0000, Loss 1.0751, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3095 | Time 41.7651(41.8990) | Bit/dim 1.0781(1.0804) | Xent 0.0000(0.0000) | Loss 1.0781(1.0804) | Error 0.0000(0.0000) Steps 560(565.11) | Grad Norm 0.0482(0.0600) | Total Time 10.00(10.00)\n",
      "Iter 3096 | Time 42.3711(41.9132) | Bit/dim 1.0742(1.0803) | Xent 0.0000(0.0000) | Loss 1.0742(1.0803) | Error 0.0000(0.0000) Steps 560(564.95) | Grad Norm 0.0393(0.0594) | Total Time 10.00(10.00)\n",
      "Iter 3097 | Time 41.2028(41.8919) | Bit/dim 1.0802(1.0803) | Xent 0.0000(0.0000) | Loss 1.0802(1.0803) | Error 0.0000(0.0000) Steps 560(564.80) | Grad Norm 0.0455(0.0590) | Total Time 10.00(10.00)\n",
      "Iter 3098 | Time 42.1324(41.8991) | Bit/dim 1.0823(1.0803) | Xent 0.0000(0.0000) | Loss 1.0823(1.0803) | Error 0.0000(0.0000) Steps 578(565.20) | Grad Norm 0.0541(0.0588) | Total Time 10.00(10.00)\n",
      "Iter 3099 | Time 42.9366(41.9302) | Bit/dim 1.0797(1.0803) | Xent 0.0000(0.0000) | Loss 1.0797(1.0803) | Error 0.0000(0.0000) Steps 560(565.04) | Grad Norm 0.0423(0.0584) | Total Time 10.00(10.00)\n",
      "Iter 3100 | Time 42.9813(41.9618) | Bit/dim 1.0861(1.0805) | Xent 0.0000(0.0000) | Loss 1.0861(1.0805) | Error 0.0000(0.0000) Steps 578(565.43) | Grad Norm 0.0586(0.0584) | Total Time 10.00(10.00)\n",
      "Iter 3101 | Time 42.6068(41.9811) | Bit/dim 1.0810(1.0805) | Xent 0.0000(0.0000) | Loss 1.0810(1.0805) | Error 0.0000(0.0000) Steps 560(565.27) | Grad Norm 0.0392(0.0578) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 21.0024, Epoch Time 329.3475(321.8878), Bit/dim 1.0750(best: 1.0749), Xent 0.0000, Loss 1.0750, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3102 | Time 41.9442(41.9800) | Bit/dim 1.0800(1.0805) | Xent 0.0000(0.0000) | Loss 1.0800(1.0805) | Error 0.0000(0.0000) Steps 560(565.11) | Grad Norm 0.0477(0.0575) | Total Time 10.00(10.00)\n",
      "Iter 3103 | Time 40.9981(41.9505) | Bit/dim 1.0804(1.0805) | Xent 0.0000(0.0000) | Loss 1.0804(1.0805) | Error 0.0000(0.0000) Steps 560(564.96) | Grad Norm 0.0524(0.0573) | Total Time 10.00(10.00)\n",
      "Iter 3104 | Time 42.8474(41.9775) | Bit/dim 1.0780(1.0804) | Xent 0.0000(0.0000) | Loss 1.0780(1.0804) | Error 0.0000(0.0000) Steps 572(565.17) | Grad Norm 0.0684(0.0577) | Total Time 10.00(10.00)\n",
      "Iter 3105 | Time 40.8286(41.9430) | Bit/dim 1.0817(1.0804) | Xent 0.0000(0.0000) | Loss 1.0817(1.0804) | Error 0.0000(0.0000) Steps 560(565.01) | Grad Norm 0.0532(0.0575) | Total Time 10.00(10.00)\n",
      "Iter 3106 | Time 42.1113(41.9480) | Bit/dim 1.0799(1.0804) | Xent 0.0000(0.0000) | Loss 1.0799(1.0804) | Error 0.0000(0.0000) Steps 560(564.86) | Grad Norm 0.0463(0.0572) | Total Time 10.00(10.00)\n",
      "Iter 3107 | Time 42.9272(41.9774) | Bit/dim 1.0837(1.0805) | Xent 0.0000(0.0000) | Loss 1.0837(1.0805) | Error 0.0000(0.0000) Steps 578(565.26) | Grad Norm 0.0591(0.0572) | Total Time 10.00(10.00)\n",
      "Iter 3108 | Time 41.6171(41.9666) | Bit/dim 1.0826(1.0806) | Xent 0.0000(0.0000) | Loss 1.0826(1.0806) | Error 0.0000(0.0000) Steps 560(565.10) | Grad Norm 0.0534(0.0571) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 21.2130, Epoch Time 327.0268(322.0420), Bit/dim 1.0748(best: 1.0749), Xent 0.0000, Loss 1.0748, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3109 | Time 41.9851(41.9672) | Bit/dim 1.0826(1.0806) | Xent 0.0000(0.0000) | Loss 1.0826(1.0806) | Error 0.0000(0.0000) Steps 578(565.49) | Grad Norm 0.0438(0.0567) | Total Time 10.00(10.00)\n",
      "Iter 3110 | Time 41.1530(41.9427) | Bit/dim 1.0814(1.0807) | Xent 0.0000(0.0000) | Loss 1.0814(1.0807) | Error 0.0000(0.0000) Steps 560(565.32) | Grad Norm 0.0638(0.0569) | Total Time 10.00(10.00)\n",
      "Iter 3111 | Time 41.8264(41.9392) | Bit/dim 1.0776(1.0806) | Xent 0.0000(0.0000) | Loss 1.0776(1.0806) | Error 0.0000(0.0000) Steps 560(565.16) | Grad Norm 0.0525(0.0568) | Total Time 10.00(10.00)\n",
      "Iter 3112 | Time 42.4073(41.9533) | Bit/dim 1.0784(1.0805) | Xent 0.0000(0.0000) | Loss 1.0784(1.0805) | Error 0.0000(0.0000) Steps 560(565.01) | Grad Norm 0.0605(0.0569) | Total Time 10.00(10.00)\n",
      "Iter 3113 | Time 41.7452(41.9470) | Bit/dim 1.0806(1.0805) | Xent 0.0000(0.0000) | Loss 1.0806(1.0805) | Error 0.0000(0.0000) Steps 578(565.40) | Grad Norm 0.0553(0.0569) | Total Time 10.00(10.00)\n",
      "Iter 3114 | Time 41.4511(41.9322) | Bit/dim 1.0808(1.0805) | Xent 0.0000(0.0000) | Loss 1.0808(1.0805) | Error 0.0000(0.0000) Steps 578(565.78) | Grad Norm 0.0541(0.0568) | Total Time 10.00(10.00)\n",
      "Iter 3115 | Time 40.6023(41.8923) | Bit/dim 1.0816(1.0805) | Xent 0.0000(0.0000) | Loss 1.0816(1.0805) | Error 0.0000(0.0000) Steps 560(565.60) | Grad Norm 0.0527(0.0567) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 20.9067, Epoch Time 324.7209(322.1224), Bit/dim 1.0756(best: 1.0748), Xent 0.0000, Loss 1.0756, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3116 | Time 40.8329(41.8605) | Bit/dim 1.0789(1.0805) | Xent 0.0000(0.0000) | Loss 1.0789(1.0805) | Error 0.0000(0.0000) Steps 560(565.43) | Grad Norm 0.0533(0.0566) | Total Time 10.00(10.00)\n",
      "Iter 3117 | Time 42.8965(41.8916) | Bit/dim 1.0807(1.0805) | Xent 0.0000(0.0000) | Loss 1.0807(1.0805) | Error 0.0000(0.0000) Steps 560(565.27) | Grad Norm 0.0458(0.0562) | Total Time 10.00(10.00)\n",
      "Iter 3118 | Time 40.9322(41.8628) | Bit/dim 1.0806(1.0805) | Xent 0.0000(0.0000) | Loss 1.0806(1.0805) | Error 0.0000(0.0000) Steps 572(565.47) | Grad Norm 0.0500(0.0561) | Total Time 10.00(10.00)\n",
      "Iter 3119 | Time 42.7722(41.8901) | Bit/dim 1.0796(1.0805) | Xent 0.0000(0.0000) | Loss 1.0796(1.0805) | Error 0.0000(0.0000) Steps 560(565.31) | Grad Norm 0.0443(0.0557) | Total Time 10.00(10.00)\n",
      "Iter 3120 | Time 42.0279(41.8942) | Bit/dim 1.0812(1.0805) | Xent 0.0000(0.0000) | Loss 1.0812(1.0805) | Error 0.0000(0.0000) Steps 560(565.15) | Grad Norm 0.0633(0.0559) | Total Time 10.00(10.00)\n",
      "Iter 3121 | Time 42.4343(41.9104) | Bit/dim 1.0793(1.0805) | Xent 0.0000(0.0000) | Loss 1.0793(1.0805) | Error 0.0000(0.0000) Steps 560(565.00) | Grad Norm 0.0794(0.0566) | Total Time 10.00(10.00)\n",
      "Iter 3122 | Time 40.7476(41.8755) | Bit/dim 1.0826(1.0805) | Xent 0.0000(0.0000) | Loss 1.0826(1.0805) | Error 0.0000(0.0000) Steps 560(564.85) | Grad Norm 0.0464(0.0563) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 20.9523, Epoch Time 326.3254(322.2485), Bit/dim 1.0751(best: 1.0748), Xent 0.0000, Loss 1.0751, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3123 | Time 41.4597(41.8631) | Bit/dim 1.0841(1.0806) | Xent 0.0000(0.0000) | Loss 1.0841(1.0806) | Error 0.0000(0.0000) Steps 560(564.70) | Grad Norm 0.0449(0.0560) | Total Time 10.00(10.00)\n",
      "Iter 3124 | Time 39.6825(41.7976) | Bit/dim 1.0788(1.0806) | Xent 0.0000(0.0000) | Loss 1.0788(1.0806) | Error 0.0000(0.0000) Steps 560(564.56) | Grad Norm 0.0491(0.0558) | Total Time 10.00(10.00)\n",
      "Iter 3125 | Time 42.0201(41.8043) | Bit/dim 1.0774(1.0805) | Xent 0.0000(0.0000) | Loss 1.0774(1.0805) | Error 0.0000(0.0000) Steps 578(564.96) | Grad Norm 0.0404(0.0553) | Total Time 10.00(10.00)\n",
      "Iter 3126 | Time 39.8101(41.7445) | Bit/dim 1.0789(1.0804) | Xent 0.0000(0.0000) | Loss 1.0789(1.0804) | Error 0.0000(0.0000) Steps 560(564.81) | Grad Norm 0.1225(0.0573) | Total Time 10.00(10.00)\n",
      "Iter 3127 | Time 41.4810(41.7366) | Bit/dim 1.0790(1.0804) | Xent 0.0000(0.0000) | Loss 1.0790(1.0804) | Error 0.0000(0.0000) Steps 560(564.67) | Grad Norm 0.0668(0.0576) | Total Time 10.00(10.00)\n",
      "Iter 3128 | Time 42.2321(41.7514) | Bit/dim 1.0831(1.0805) | Xent 0.0000(0.0000) | Loss 1.0831(1.0805) | Error 0.0000(0.0000) Steps 560(564.53) | Grad Norm 0.0935(0.0587) | Total Time 10.00(10.00)\n",
      "Iter 3129 | Time 41.5107(41.7442) | Bit/dim 1.0820(1.0805) | Xent 0.0000(0.0000) | Loss 1.0820(1.0805) | Error 0.0000(0.0000) Steps 560(564.39) | Grad Norm 0.0508(0.0585) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 21.3175, Epoch Time 322.0111(322.2413), Bit/dim 1.0752(best: 1.0748), Xent 0.0000, Loss 1.0752, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3130 | Time 40.9178(41.7194) | Bit/dim 1.0749(1.0804) | Xent 0.0000(0.0000) | Loss 1.0749(1.0804) | Error 0.0000(0.0000) Steps 560(564.26) | Grad Norm 0.0488(0.0582) | Total Time 10.00(10.00)\n",
      "Iter 3131 | Time 42.1063(41.7310) | Bit/dim 1.0786(1.0803) | Xent 0.0000(0.0000) | Loss 1.0786(1.0803) | Error 0.0000(0.0000) Steps 560(564.13) | Grad Norm 0.0701(0.0585) | Total Time 10.00(10.00)\n",
      "Iter 3132 | Time 40.7893(41.7028) | Bit/dim 1.0820(1.0804) | Xent 0.0000(0.0000) | Loss 1.0820(1.0804) | Error 0.0000(0.0000) Steps 578(564.55) | Grad Norm 0.0595(0.0586) | Total Time 10.00(10.00)\n",
      "Iter 3133 | Time 42.1334(41.7157) | Bit/dim 1.0817(1.0804) | Xent 0.0000(0.0000) | Loss 1.0817(1.0804) | Error 0.0000(0.0000) Steps 560(564.41) | Grad Norm 0.0630(0.0587) | Total Time 10.00(10.00)\n",
      "Iter 3134 | Time 42.2865(41.7328) | Bit/dim 1.0840(1.0805) | Xent 0.0000(0.0000) | Loss 1.0840(1.0805) | Error 0.0000(0.0000) Steps 560(564.28) | Grad Norm 0.0435(0.0582) | Total Time 10.00(10.00)\n",
      "Iter 3135 | Time 42.9234(41.7685) | Bit/dim 1.0786(1.0804) | Xent 0.0000(0.0000) | Loss 1.0786(1.0804) | Error 0.0000(0.0000) Steps 560(564.15) | Grad Norm 0.0454(0.0578) | Total Time 10.00(10.00)\n",
      "Iter 3136 | Time 41.0375(41.7466) | Bit/dim 1.0806(1.0804) | Xent 0.0000(0.0000) | Loss 1.0806(1.0804) | Error 0.0000(0.0000) Steps 560(564.03) | Grad Norm 0.0499(0.0576) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 21.3797, Epoch Time 326.1658(322.3591), Bit/dim 1.0755(best: 1.0748), Xent 0.0000, Loss 1.0755, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3137 | Time 41.1101(41.7275) | Bit/dim 1.0799(1.0804) | Xent 0.0000(0.0000) | Loss 1.0799(1.0804) | Error 0.0000(0.0000) Steps 560(563.91) | Grad Norm 0.0490(0.0574) | Total Time 10.00(10.00)\n",
      "Iter 3138 | Time 42.1727(41.7409) | Bit/dim 1.0804(1.0804) | Xent 0.0000(0.0000) | Loss 1.0804(1.0804) | Error 0.0000(0.0000) Steps 560(563.79) | Grad Norm 0.0658(0.0576) | Total Time 10.00(10.00)\n",
      "Iter 3139 | Time 41.5880(41.7363) | Bit/dim 1.0755(1.0803) | Xent 0.0000(0.0000) | Loss 1.0755(1.0803) | Error 0.0000(0.0000) Steps 560(563.68) | Grad Norm 0.0630(0.0578) | Total Time 10.00(10.00)\n",
      "Iter 3140 | Time 42.8994(41.7712) | Bit/dim 1.0824(1.0803) | Xent 0.0000(0.0000) | Loss 1.0824(1.0803) | Error 0.0000(0.0000) Steps 560(563.57) | Grad Norm 0.0405(0.0573) | Total Time 10.00(10.00)\n",
      "Iter 3141 | Time 43.3547(41.8187) | Bit/dim 1.0809(1.0804) | Xent 0.0000(0.0000) | Loss 1.0809(1.0804) | Error 0.0000(0.0000) Steps 560(563.46) | Grad Norm 0.0417(0.0568) | Total Time 10.00(10.00)\n",
      "Iter 3142 | Time 42.3773(41.8354) | Bit/dim 1.0830(1.0804) | Xent 0.0000(0.0000) | Loss 1.0830(1.0804) | Error 0.0000(0.0000) Steps 578(563.89) | Grad Norm 0.0440(0.0564) | Total Time 10.00(10.00)\n",
      "Iter 3143 | Time 42.1479(41.8448) | Bit/dim 1.0815(1.0805) | Xent 0.0000(0.0000) | Loss 1.0815(1.0805) | Error 0.0000(0.0000) Steps 560(563.78) | Grad Norm 0.0437(0.0560) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 20.8899, Epoch Time 328.9472(322.5567), Bit/dim 1.0751(best: 1.0748), Xent 0.0000, Loss 1.0751, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3144 | Time 41.6719(41.8396) | Bit/dim 1.0795(1.0804) | Xent 0.0000(0.0000) | Loss 1.0795(1.0804) | Error 0.0000(0.0000) Steps 578(564.20) | Grad Norm 0.1054(0.0575) | Total Time 10.00(10.00)\n",
      "Iter 3145 | Time 42.7424(41.8667) | Bit/dim 1.0787(1.0804) | Xent 0.0000(0.0000) | Loss 1.0787(1.0804) | Error 0.0000(0.0000) Steps 560(564.08) | Grad Norm 0.0590(0.0575) | Total Time 10.00(10.00)\n",
      "Iter 3146 | Time 42.0582(41.8725) | Bit/dim 1.0778(1.0803) | Xent 0.0000(0.0000) | Loss 1.0778(1.0803) | Error 0.0000(0.0000) Steps 560(563.96) | Grad Norm 0.0674(0.0578) | Total Time 10.00(10.00)\n",
      "Iter 3147 | Time 42.5813(41.8937) | Bit/dim 1.0794(1.0803) | Xent 0.0000(0.0000) | Loss 1.0794(1.0803) | Error 0.0000(0.0000) Steps 560(563.84) | Grad Norm 0.0427(0.0574) | Total Time 10.00(10.00)\n",
      "Iter 3148 | Time 41.0863(41.8695) | Bit/dim 1.0809(1.0803) | Xent 0.0000(0.0000) | Loss 1.0809(1.0803) | Error 0.0000(0.0000) Steps 578(564.26) | Grad Norm 0.0897(0.0584) | Total Time 10.00(10.00)\n",
      "Iter 3149 | Time 42.0831(41.8759) | Bit/dim 1.0783(1.0802) | Xent 0.0000(0.0000) | Loss 1.0783(1.0802) | Error 0.0000(0.0000) Steps 578(564.67) | Grad Norm 0.0718(0.0588) | Total Time 10.00(10.00)\n",
      "Iter 3150 | Time 41.9932(41.8794) | Bit/dim 1.0798(1.0802) | Xent 0.0000(0.0000) | Loss 1.0798(1.0802) | Error 0.0000(0.0000) Steps 560(564.53) | Grad Norm 0.0972(0.0599) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 21.4990, Epoch Time 328.2397(322.7272), Bit/dim 1.0752(best: 1.0748), Xent 0.0000, Loss 1.0752, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3151 | Time 41.7530(41.8756) | Bit/dim 1.0765(1.0801) | Xent 0.0000(0.0000) | Loss 1.0765(1.0801) | Error 0.0000(0.0000) Steps 560(564.40) | Grad Norm 0.0469(0.0595) | Total Time 10.00(10.00)\n",
      "Iter 3152 | Time 42.1296(41.8832) | Bit/dim 1.0778(1.0800) | Xent 0.0000(0.0000) | Loss 1.0778(1.0800) | Error 0.0000(0.0000) Steps 560(564.27) | Grad Norm 0.1017(0.0608) | Total Time 10.00(10.00)\n",
      "Iter 3153 | Time 42.5447(41.9031) | Bit/dim 1.0823(1.0801) | Xent 0.0000(0.0000) | Loss 1.0823(1.0801) | Error 0.0000(0.0000) Steps 560(564.14) | Grad Norm 0.1212(0.0626) | Total Time 10.00(10.00)\n",
      "Iter 3154 | Time 42.1624(41.9109) | Bit/dim 1.0760(1.0800) | Xent 0.0000(0.0000) | Loss 1.0760(1.0800) | Error 0.0000(0.0000) Steps 578(564.55) | Grad Norm 0.0820(0.0632) | Total Time 10.00(10.00)\n",
      "Iter 3155 | Time 41.0261(41.8843) | Bit/dim 1.0855(1.0802) | Xent 0.0000(0.0000) | Loss 1.0855(1.0802) | Error 0.0000(0.0000) Steps 560(564.42) | Grad Norm 0.0467(0.0627) | Total Time 10.00(10.00)\n",
      "Iter 3156 | Time 41.1396(41.8620) | Bit/dim 1.0842(1.0803) | Xent 0.0000(0.0000) | Loss 1.0842(1.0803) | Error 0.0000(0.0000) Steps 560(564.28) | Grad Norm 0.0790(0.0632) | Total Time 10.00(10.00)\n",
      "Iter 3157 | Time 43.4970(41.9110) | Bit/dim 1.0791(1.0802) | Xent 0.0000(0.0000) | Loss 1.0791(1.0802) | Error 0.0000(0.0000) Steps 560(564.16) | Grad Norm 0.1177(0.0648) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 21.2435, Epoch Time 327.9298(322.8833), Bit/dim 1.0748(best: 1.0748), Xent 0.0000, Loss 1.0748, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3158 | Time 43.1510(41.9482) | Bit/dim 1.0817(1.0803) | Xent 0.0000(0.0000) | Loss 1.0817(1.0803) | Error 0.0000(0.0000) Steps 560(564.03) | Grad Norm 0.0439(0.0642) | Total Time 10.00(10.00)\n",
      "Iter 3159 | Time 41.3657(41.9308) | Bit/dim 1.0793(1.0803) | Xent 0.0000(0.0000) | Loss 1.0793(1.0803) | Error 0.0000(0.0000) Steps 560(563.91) | Grad Norm 0.0650(0.0642) | Total Time 10.00(10.00)\n",
      "Iter 3160 | Time 42.9317(41.9608) | Bit/dim 1.0766(1.0801) | Xent 0.0000(0.0000) | Loss 1.0766(1.0801) | Error 0.0000(0.0000) Steps 578(564.33) | Grad Norm 0.0478(0.0637) | Total Time 10.00(10.00)\n",
      "Iter 3161 | Time 41.0571(41.9337) | Bit/dim 1.0805(1.0802) | Xent 0.0000(0.0000) | Loss 1.0805(1.0802) | Error 0.0000(0.0000) Steps 578(564.74) | Grad Norm 0.0433(0.0631) | Total Time 10.00(10.00)\n",
      "Iter 3162 | Time 42.5461(41.9521) | Bit/dim 1.0812(1.0802) | Xent 0.0000(0.0000) | Loss 1.0812(1.0802) | Error 0.0000(0.0000) Steps 578(565.14) | Grad Norm 0.0835(0.0637) | Total Time 10.00(10.00)\n",
      "Iter 3163 | Time 41.2374(41.9306) | Bit/dim 1.0804(1.0802) | Xent 0.0000(0.0000) | Loss 1.0804(1.0802) | Error 0.0000(0.0000) Steps 560(564.99) | Grad Norm 0.0573(0.0635) | Total Time 10.00(10.00)\n",
      "Iter 3164 | Time 41.6228(41.9214) | Bit/dim 1.0832(1.0803) | Xent 0.0000(0.0000) | Loss 1.0832(1.0803) | Error 0.0000(0.0000) Steps 560(564.84) | Grad Norm 0.0767(0.0639) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 21.1816, Epoch Time 327.7257(323.0286), Bit/dim 1.0744(best: 1.0748), Xent 0.0000, Loss 1.0744, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3165 | Time 41.8289(41.9186) | Bit/dim 1.0792(1.0802) | Xent 0.0000(0.0000) | Loss 1.0792(1.0802) | Error 0.0000(0.0000) Steps 578(565.23) | Grad Norm 0.0558(0.0637) | Total Time 10.00(10.00)\n",
      "Iter 3166 | Time 41.0081(41.8913) | Bit/dim 1.0762(1.0801) | Xent 0.0000(0.0000) | Loss 1.0762(1.0801) | Error 0.0000(0.0000) Steps 578(565.62) | Grad Norm 0.0654(0.0637) | Total Time 10.00(10.00)\n",
      "Iter 3167 | Time 40.0202(41.8352) | Bit/dim 1.0813(1.0802) | Xent 0.0000(0.0000) | Loss 1.0813(1.0802) | Error 0.0000(0.0000) Steps 560(565.45) | Grad Norm 0.0536(0.0634) | Total Time 10.00(10.00)\n",
      "Iter 3168 | Time 42.7532(41.8627) | Bit/dim 1.0745(1.0800) | Xent 0.0000(0.0000) | Loss 1.0745(1.0800) | Error 0.0000(0.0000) Steps 578(565.82) | Grad Norm 0.0407(0.0627) | Total Time 10.00(10.00)\n",
      "Iter 3169 | Time 41.9313(41.8648) | Bit/dim 1.0768(1.0799) | Xent 0.0000(0.0000) | Loss 1.0768(1.0799) | Error 0.0000(0.0000) Steps 560(565.65) | Grad Norm 0.0427(0.0621) | Total Time 10.00(10.00)\n",
      "Iter 3170 | Time 42.2240(41.8755) | Bit/dim 1.0856(1.0801) | Xent 0.0000(0.0000) | Loss 1.0856(1.0801) | Error 0.0000(0.0000) Steps 560(565.48) | Grad Norm 0.0414(0.0615) | Total Time 10.00(10.00)\n",
      "Iter 3171 | Time 41.6229(41.8680) | Bit/dim 1.0849(1.0802) | Xent 0.0000(0.0000) | Loss 1.0849(1.0802) | Error 0.0000(0.0000) Steps 560(565.31) | Grad Norm 0.0831(0.0622) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 21.2295, Epoch Time 325.0473(323.0891), Bit/dim 1.0751(best: 1.0744), Xent 0.0000, Loss 1.0751, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3172 | Time 41.2979(41.8509) | Bit/dim 1.0811(1.0802) | Xent 0.0000(0.0000) | Loss 1.0811(1.0802) | Error 0.0000(0.0000) Steps 578(565.70) | Grad Norm 0.0561(0.0620) | Total Time 10.00(10.00)\n",
      "Iter 3173 | Time 41.4495(41.8388) | Bit/dim 1.0775(1.0802) | Xent 0.0000(0.0000) | Loss 1.0775(1.0802) | Error 0.0000(0.0000) Steps 578(566.06) | Grad Norm 0.0569(0.0618) | Total Time 10.00(10.00)\n",
      "Iter 3174 | Time 42.2738(41.8519) | Bit/dim 1.0795(1.0801) | Xent 0.0000(0.0000) | Loss 1.0795(1.0801) | Error 0.0000(0.0000) Steps 578(566.42) | Grad Norm 0.0438(0.0613) | Total Time 10.00(10.00)\n",
      "Iter 3175 | Time 41.6768(41.8466) | Bit/dim 1.0806(1.0802) | Xent 0.0000(0.0000) | Loss 1.0806(1.0802) | Error 0.0000(0.0000) Steps 560(566.23) | Grad Norm 0.0480(0.0609) | Total Time 10.00(10.00)\n",
      "Iter 3176 | Time 43.0282(41.8821) | Bit/dim 1.0796(1.0801) | Xent 0.0000(0.0000) | Loss 1.0796(1.0801) | Error 0.0000(0.0000) Steps 560(566.04) | Grad Norm 0.0406(0.0603) | Total Time 10.00(10.00)\n",
      "Iter 3177 | Time 40.8145(41.8500) | Bit/dim 1.0785(1.0801) | Xent 0.0000(0.0000) | Loss 1.0785(1.0801) | Error 0.0000(0.0000) Steps 560(565.86) | Grad Norm 0.0572(0.0602) | Total Time 10.00(10.00)\n",
      "Iter 3178 | Time 40.8105(41.8188) | Bit/dim 1.0828(1.0802) | Xent 0.0000(0.0000) | Loss 1.0828(1.0802) | Error 0.0000(0.0000) Steps 560(565.69) | Grad Norm 0.0488(0.0599) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 21.0991, Epoch Time 325.0819(323.1489), Bit/dim 1.0750(best: 1.0744), Xent 0.0000, Loss 1.0750, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3179 | Time 41.1892(41.8000) | Bit/dim 1.0721(1.0799) | Xent 0.0000(0.0000) | Loss 1.0721(1.0799) | Error 0.0000(0.0000) Steps 560(565.52) | Grad Norm 0.0483(0.0595) | Total Time 10.00(10.00)\n",
      "Iter 3180 | Time 41.0569(41.7777) | Bit/dim 1.0881(1.0802) | Xent 0.0000(0.0000) | Loss 1.0881(1.0802) | Error 0.0000(0.0000) Steps 578(565.89) | Grad Norm 0.0424(0.0590) | Total Time 10.00(10.00)\n",
      "Iter 3181 | Time 42.2585(41.7921) | Bit/dim 1.0784(1.0801) | Xent 0.0000(0.0000) | Loss 1.0784(1.0801) | Error 0.0000(0.0000) Steps 560(565.71) | Grad Norm 0.0397(0.0584) | Total Time 10.00(10.00)\n",
      "Iter 3182 | Time 41.2419(41.7756) | Bit/dim 1.0795(1.0801) | Xent 0.0000(0.0000) | Loss 1.0795(1.0801) | Error 0.0000(0.0000) Steps 560(565.54) | Grad Norm 0.0448(0.0580) | Total Time 10.00(10.00)\n",
      "Iter 3183 | Time 41.3194(41.7619) | Bit/dim 1.0825(1.0802) | Xent 0.0000(0.0000) | Loss 1.0825(1.0802) | Error 0.0000(0.0000) Steps 578(565.92) | Grad Norm 0.0449(0.0576) | Total Time 10.00(10.00)\n",
      "Iter 3184 | Time 42.5468(41.7854) | Bit/dim 1.0801(1.0802) | Xent 0.0000(0.0000) | Loss 1.0801(1.0802) | Error 0.0000(0.0000) Steps 578(566.28) | Grad Norm 0.0461(0.0573) | Total Time 10.00(10.00)\n",
      "Iter 3185 | Time 41.6349(41.7809) | Bit/dim 1.0812(1.0802) | Xent 0.0000(0.0000) | Loss 1.0812(1.0802) | Error 0.0000(0.0000) Steps 560(566.09) | Grad Norm 0.0392(0.0567) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 21.3556, Epoch Time 325.0982(323.2074), Bit/dim 1.0752(best: 1.0744), Xent 0.0000, Loss 1.0752, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3186 | Time 41.8764(41.7838) | Bit/dim 1.0808(1.0802) | Xent 0.0000(0.0000) | Loss 1.0808(1.0802) | Error 0.0000(0.0000) Steps 560(565.91) | Grad Norm 0.0516(0.0566) | Total Time 10.00(10.00)\n",
      "Iter 3187 | Time 41.3399(41.7705) | Bit/dim 1.0730(1.0800) | Xent 0.0000(0.0000) | Loss 1.0730(1.0800) | Error 0.0000(0.0000) Steps 560(565.73) | Grad Norm 0.0565(0.0566) | Total Time 10.00(10.00)\n",
      "Iter 3188 | Time 41.9878(41.7770) | Bit/dim 1.0832(1.0801) | Xent 0.0000(0.0000) | Loss 1.0832(1.0801) | Error 0.0000(0.0000) Steps 560(565.56) | Grad Norm 0.0481(0.0563) | Total Time 10.00(10.00)\n",
      "Iter 3189 | Time 42.9865(41.8133) | Bit/dim 1.0843(1.0802) | Xent 0.0000(0.0000) | Loss 1.0843(1.0802) | Error 0.0000(0.0000) Steps 560(565.39) | Grad Norm 0.0644(0.0566) | Total Time 10.00(10.00)\n",
      "Iter 3190 | Time 42.0857(41.8215) | Bit/dim 1.0783(1.0802) | Xent 0.0000(0.0000) | Loss 1.0783(1.0802) | Error 0.0000(0.0000) Steps 560(565.23) | Grad Norm 0.0504(0.0564) | Total Time 10.00(10.00)\n",
      "Iter 3191 | Time 41.3926(41.8086) | Bit/dim 1.0806(1.0802) | Xent 0.0000(0.0000) | Loss 1.0806(1.0802) | Error 0.0000(0.0000) Steps 578(565.61) | Grad Norm 0.0428(0.0560) | Total Time 10.00(10.00)\n",
      "Iter 3192 | Time 41.7145(41.8058) | Bit/dim 1.0782(1.0801) | Xent 0.0000(0.0000) | Loss 1.0782(1.0801) | Error 0.0000(0.0000) Steps 560(565.44) | Grad Norm 0.0438(0.0556) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 21.5198, Epoch Time 327.4492(323.3346), Bit/dim 1.0747(best: 1.0744), Xent 0.0000, Loss 1.0747, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3193 | Time 42.2957(41.8205) | Bit/dim 1.0822(1.0802) | Xent 0.0000(0.0000) | Loss 1.0822(1.0802) | Error 0.0000(0.0000) Steps 578(565.82) | Grad Norm 0.0815(0.0564) | Total Time 10.00(10.00)\n",
      "Iter 3194 | Time 41.0913(41.7986) | Bit/dim 1.0810(1.0802) | Xent 0.0000(0.0000) | Loss 1.0810(1.0802) | Error 0.0000(0.0000) Steps 560(565.65) | Grad Norm 0.0458(0.0561) | Total Time 10.00(10.00)\n",
      "Iter 3195 | Time 42.6418(41.8239) | Bit/dim 1.0789(1.0802) | Xent 0.0000(0.0000) | Loss 1.0789(1.0802) | Error 0.0000(0.0000) Steps 560(565.48) | Grad Norm 0.0402(0.0556) | Total Time 10.00(10.00)\n",
      "Iter 3196 | Time 41.0782(41.8015) | Bit/dim 1.0752(1.0800) | Xent 0.0000(0.0000) | Loss 1.0752(1.0800) | Error 0.0000(0.0000) Steps 578(565.85) | Grad Norm 0.0525(0.0555) | Total Time 10.00(10.00)\n",
      "Iter 3197 | Time 42.2164(41.8140) | Bit/dim 1.0809(1.0800) | Xent 0.0000(0.0000) | Loss 1.0809(1.0800) | Error 0.0000(0.0000) Steps 560(565.68) | Grad Norm 0.0410(0.0551) | Total Time 10.00(10.00)\n",
      "Iter 3198 | Time 41.7170(41.8111) | Bit/dim 1.0757(1.0799) | Xent 0.0000(0.0000) | Loss 1.0757(1.0799) | Error 0.0000(0.0000) Steps 566(565.69) | Grad Norm 0.0604(0.0552) | Total Time 10.00(10.00)\n",
      "Iter 3199 | Time 42.6431(41.8360) | Bit/dim 1.0799(1.0799) | Xent 0.0000(0.0000) | Loss 1.0799(1.0799) | Error 0.0000(0.0000) Steps 560(565.52) | Grad Norm 0.0517(0.0551) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 21.3178, Epoch Time 327.5446(323.4609), Bit/dim 1.0744(best: 1.0744), Xent 0.0000, Loss 1.0744, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3200 | Time 42.2377(41.8481) | Bit/dim 1.0760(1.0798) | Xent 0.0000(0.0000) | Loss 1.0760(1.0798) | Error 0.0000(0.0000) Steps 578(565.89) | Grad Norm 0.0660(0.0554) | Total Time 10.00(10.00)\n",
      "Iter 3201 | Time 40.8367(41.8177) | Bit/dim 1.0771(1.0797) | Xent 0.0000(0.0000) | Loss 1.0771(1.0797) | Error 0.0000(0.0000) Steps 560(565.71) | Grad Norm 0.0358(0.0549) | Total Time 10.00(10.00)\n",
      "Iter 3202 | Time 43.8500(41.8787) | Bit/dim 1.0832(1.0798) | Xent 0.0000(0.0000) | Loss 1.0832(1.0798) | Error 0.0000(0.0000) Steps 560(565.54) | Grad Norm 0.0372(0.0543) | Total Time 10.00(10.00)\n",
      "Iter 3203 | Time 41.9835(41.8818) | Bit/dim 1.0800(1.0798) | Xent 0.0000(0.0000) | Loss 1.0800(1.0798) | Error 0.0000(0.0000) Steps 560(565.38) | Grad Norm 0.0698(0.0548) | Total Time 10.00(10.00)\n",
      "Iter 3204 | Time 41.4570(41.8691) | Bit/dim 1.0808(1.0799) | Xent 0.0000(0.0000) | Loss 1.0808(1.0799) | Error 0.0000(0.0000) Steps 578(565.75) | Grad Norm 0.0976(0.0561) | Total Time 10.00(10.00)\n",
      "Iter 3205 | Time 41.6458(41.8624) | Bit/dim 1.0795(1.0798) | Xent 0.0000(0.0000) | Loss 1.0795(1.0798) | Error 0.0000(0.0000) Steps 560(565.58) | Grad Norm 0.0523(0.0560) | Total Time 10.00(10.00)\n",
      "Iter 3206 | Time 42.1383(41.8707) | Bit/dim 1.0803(1.0799) | Xent 0.0000(0.0000) | Loss 1.0803(1.0799) | Error 0.0000(0.0000) Steps 560(565.41) | Grad Norm 0.0545(0.0559) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 21.2113, Epoch Time 327.6830(323.5876), Bit/dim 1.0748(best: 1.0744), Xent 0.0000, Loss 1.0748, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3207 | Time 43.0304(41.9055) | Bit/dim 1.0798(1.0799) | Xent 0.0000(0.0000) | Loss 1.0798(1.0799) | Error 0.0000(0.0000) Steps 578(565.79) | Grad Norm 0.0485(0.0557) | Total Time 10.00(10.00)\n",
      "Iter 3208 | Time 41.4897(41.8930) | Bit/dim 1.0764(1.0798) | Xent 0.0000(0.0000) | Loss 1.0764(1.0798) | Error 0.0000(0.0000) Steps 578(566.16) | Grad Norm 0.0647(0.0560) | Total Time 10.00(10.00)\n",
      "Iter 3209 | Time 43.2074(41.9324) | Bit/dim 1.0757(1.0796) | Xent 0.0000(0.0000) | Loss 1.0757(1.0796) | Error 0.0000(0.0000) Steps 578(566.51) | Grad Norm 0.0579(0.0560) | Total Time 10.00(10.00)\n",
      "Iter 3210 | Time 40.9635(41.9034) | Bit/dim 1.0829(1.0797) | Xent 0.0000(0.0000) | Loss 1.0829(1.0797) | Error 0.0000(0.0000) Steps 560(566.32) | Grad Norm 0.0495(0.0558) | Total Time 10.00(10.00)\n",
      "Iter 3211 | Time 42.0722(41.9084) | Bit/dim 1.0808(1.0798) | Xent 0.0000(0.0000) | Loss 1.0808(1.0798) | Error 0.0000(0.0000) Steps 560(566.13) | Grad Norm 0.0478(0.0556) | Total Time 10.00(10.00)\n",
      "Iter 3212 | Time 40.7982(41.8751) | Bit/dim 1.0850(1.0799) | Xent 0.0000(0.0000) | Loss 1.0850(1.0799) | Error 0.0000(0.0000) Steps 560(565.94) | Grad Norm 0.0492(0.0554) | Total Time 10.00(10.00)\n",
      "Iter 3213 | Time 42.0672(41.8809) | Bit/dim 1.0746(1.0798) | Xent 0.0000(0.0000) | Loss 1.0746(1.0798) | Error 0.0000(0.0000) Steps 560(565.77) | Grad Norm 0.0464(0.0551) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 21.2457, Epoch Time 327.5175(323.7055), Bit/dim 1.0749(best: 1.0744), Xent 0.0000, Loss 1.0749, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3214 | Time 43.4897(41.9291) | Bit/dim 1.0786(1.0797) | Xent 0.0000(0.0000) | Loss 1.0786(1.0797) | Error 0.0000(0.0000) Steps 560(565.59) | Grad Norm 0.0510(0.0550) | Total Time 10.00(10.00)\n",
      "Iter 3215 | Time 41.6442(41.9206) | Bit/dim 1.0795(1.0797) | Xent 0.0000(0.0000) | Loss 1.0795(1.0797) | Error 0.0000(0.0000) Steps 578(565.97) | Grad Norm 0.0617(0.0552) | Total Time 10.00(10.00)\n",
      "Iter 3216 | Time 41.0793(41.8954) | Bit/dim 1.0781(1.0797) | Xent 0.0000(0.0000) | Loss 1.0781(1.0797) | Error 0.0000(0.0000) Steps 560(565.79) | Grad Norm 0.0505(0.0551) | Total Time 10.00(10.00)\n",
      "Iter 3217 | Time 43.8624(41.9544) | Bit/dim 1.0807(1.0797) | Xent 0.0000(0.0000) | Loss 1.0807(1.0797) | Error 0.0000(0.0000) Steps 578(566.15) | Grad Norm 0.0912(0.0561) | Total Time 10.00(10.00)\n",
      "Iter 3218 | Time 42.6722(41.9759) | Bit/dim 1.0779(1.0797) | Xent 0.0000(0.0000) | Loss 1.0779(1.0797) | Error 0.0000(0.0000) Steps 560(565.97) | Grad Norm 0.0462(0.0558) | Total Time 10.00(10.00)\n",
      "Iter 3219 | Time 41.1863(41.9522) | Bit/dim 1.0781(1.0796) | Xent 0.0000(0.0000) | Loss 1.0781(1.0796) | Error 0.0000(0.0000) Steps 560(565.79) | Grad Norm 0.0529(0.0558) | Total Time 10.00(10.00)\n",
      "Iter 3220 | Time 42.6639(41.9736) | Bit/dim 1.0809(1.0796) | Xent 0.0000(0.0000) | Loss 1.0809(1.0796) | Error 0.0000(0.0000) Steps 560(565.62) | Grad Norm 0.0700(0.0562) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 21.1690, Epoch Time 330.6708(323.9145), Bit/dim 1.0748(best: 1.0744), Xent 0.0000, Loss 1.0748, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3221 | Time 41.8508(41.9699) | Bit/dim 1.0795(1.0796) | Xent 0.0000(0.0000) | Loss 1.0795(1.0796) | Error 0.0000(0.0000) Steps 578(565.99) | Grad Norm 0.0428(0.0558) | Total Time 10.00(10.00)\n",
      "Iter 3222 | Time 41.8201(41.9654) | Bit/dim 1.0817(1.0797) | Xent 0.0000(0.0000) | Loss 1.0817(1.0797) | Error 0.0000(0.0000) Steps 560(565.81) | Grad Norm 0.0465(0.0555) | Total Time 10.00(10.00)\n",
      "Iter 3223 | Time 40.7440(41.9287) | Bit/dim 1.0789(1.0797) | Xent 0.0000(0.0000) | Loss 1.0789(1.0797) | Error 0.0000(0.0000) Steps 560(565.63) | Grad Norm 0.0699(0.0559) | Total Time 10.00(10.00)\n",
      "Iter 3224 | Time 41.2751(41.9091) | Bit/dim 1.0804(1.0797) | Xent 0.0000(0.0000) | Loss 1.0804(1.0797) | Error 0.0000(0.0000) Steps 560(565.46) | Grad Norm 0.0396(0.0554) | Total Time 10.00(10.00)\n",
      "Iter 3225 | Time 42.7985(41.9358) | Bit/dim 1.0761(1.0796) | Xent 0.0000(0.0000) | Loss 1.0761(1.0796) | Error 0.0000(0.0000) Steps 560(565.30) | Grad Norm 0.0474(0.0552) | Total Time 10.00(10.00)\n",
      "Iter 3226 | Time 41.8492(41.9332) | Bit/dim 1.0793(1.0796) | Xent 0.0000(0.0000) | Loss 1.0793(1.0796) | Error 0.0000(0.0000) Steps 578(565.68) | Grad Norm 0.0531(0.0551) | Total Time 10.00(10.00)\n",
      "Iter 3227 | Time 40.4610(41.8891) | Bit/dim 1.0817(1.0796) | Xent 0.0000(0.0000) | Loss 1.0817(1.0796) | Error 0.0000(0.0000) Steps 560(565.51) | Grad Norm 0.0470(0.0549) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 21.1172, Epoch Time 324.3585(323.9278), Bit/dim 1.0749(best: 1.0744), Xent 0.0000, Loss 1.0749, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3228 | Time 41.2535(41.8700) | Bit/dim 1.0832(1.0797) | Xent 0.0000(0.0000) | Loss 1.0832(1.0797) | Error 0.0000(0.0000) Steps 560(565.35) | Grad Norm 0.0555(0.0549) | Total Time 10.00(10.00)\n",
      "Iter 3229 | Time 41.3345(41.8539) | Bit/dim 1.0790(1.0797) | Xent 0.0000(0.0000) | Loss 1.0790(1.0797) | Error 0.0000(0.0000) Steps 578(565.73) | Grad Norm 0.0498(0.0548) | Total Time 10.00(10.00)\n",
      "Iter 3230 | Time 41.1586(41.8331) | Bit/dim 1.0792(1.0797) | Xent 0.0000(0.0000) | Loss 1.0792(1.0797) | Error 0.0000(0.0000) Steps 578(566.09) | Grad Norm 0.0509(0.0546) | Total Time 10.00(10.00)\n",
      "Iter 3231 | Time 41.9600(41.8369) | Bit/dim 1.0810(1.0797) | Xent 0.0000(0.0000) | Loss 1.0810(1.0797) | Error 0.0000(0.0000) Steps 560(565.91) | Grad Norm 0.1001(0.0560) | Total Time 10.00(10.00)\n",
      "Iter 3232 | Time 41.8299(41.8367) | Bit/dim 1.0809(1.0798) | Xent 0.0000(0.0000) | Loss 1.0809(1.0798) | Error 0.0000(0.0000) Steps 578(566.27) | Grad Norm 0.0637(0.0562) | Total Time 10.00(10.00)\n",
      "Iter 3233 | Time 41.5688(41.8286) | Bit/dim 1.0767(1.0797) | Xent 0.0000(0.0000) | Loss 1.0767(1.0797) | Error 0.0000(0.0000) Steps 560(566.09) | Grad Norm 0.0784(0.0569) | Total Time 10.00(10.00)\n",
      "Iter 3234 | Time 42.8096(41.8581) | Bit/dim 1.0767(1.0796) | Xent 0.0000(0.0000) | Loss 1.0767(1.0796) | Error 0.0000(0.0000) Steps 578(566.44) | Grad Norm 0.0406(0.0564) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 21.3242, Epoch Time 325.6632(323.9798), Bit/dim 1.0746(best: 1.0744), Xent 0.0000, Loss 1.0746, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3235 | Time 41.7490(41.8548) | Bit/dim 1.0784(1.0796) | Xent 0.0000(0.0000) | Loss 1.0784(1.0796) | Error 0.0000(0.0000) Steps 578(566.79) | Grad Norm 0.0869(0.0573) | Total Time 10.00(10.00)\n",
      "Iter 3236 | Time 42.1460(41.8635) | Bit/dim 1.0805(1.0796) | Xent 0.0000(0.0000) | Loss 1.0805(1.0796) | Error 0.0000(0.0000) Steps 560(566.59) | Grad Norm 0.0742(0.0578) | Total Time 10.00(10.00)\n",
      "Iter 3237 | Time 41.5255(41.8534) | Bit/dim 1.0870(1.0798) | Xent 0.0000(0.0000) | Loss 1.0870(1.0798) | Error 0.0000(0.0000) Steps 560(566.39) | Grad Norm 0.0676(0.0581) | Total Time 10.00(10.00)\n",
      "Iter 3238 | Time 42.5602(41.8746) | Bit/dim 1.0813(1.0799) | Xent 0.0000(0.0000) | Loss 1.0813(1.0799) | Error 0.0000(0.0000) Steps 578(566.74) | Grad Norm 0.0433(0.0577) | Total Time 10.00(10.00)\n",
      "Iter 3239 | Time 42.4105(41.8907) | Bit/dim 1.0760(1.0797) | Xent 0.0000(0.0000) | Loss 1.0760(1.0797) | Error 0.0000(0.0000) Steps 560(566.53) | Grad Norm 0.1120(0.0593) | Total Time 10.00(10.00)\n",
      "Iter 3240 | Time 41.4217(41.8766) | Bit/dim 1.0794(1.0797) | Xent 0.0000(0.0000) | Loss 1.0794(1.0797) | Error 0.0000(0.0000) Steps 560(566.34) | Grad Norm 0.0575(0.0593) | Total Time 10.00(10.00)\n",
      "Iter 3241 | Time 41.9408(41.8785) | Bit/dim 1.0766(1.0796) | Xent 0.0000(0.0000) | Loss 1.0766(1.0796) | Error 0.0000(0.0000) Steps 560(566.15) | Grad Norm 0.0592(0.0593) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 21.1509, Epoch Time 327.3441(324.0808), Bit/dim 1.0750(best: 1.0744), Xent 0.0000, Loss 1.0750, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3242 | Time 41.9647(41.8811) | Bit/dim 1.0840(1.0798) | Xent 0.0000(0.0000) | Loss 1.0840(1.0798) | Error 0.0000(0.0000) Steps 560(565.96) | Grad Norm 0.0433(0.0588) | Total Time 10.00(10.00)\n",
      "Iter 3243 | Time 40.6208(41.8433) | Bit/dim 1.0790(1.0797) | Xent 0.0000(0.0000) | Loss 1.0790(1.0797) | Error 0.0000(0.0000) Steps 560(565.78) | Grad Norm 0.0563(0.0587) | Total Time 10.00(10.00)\n",
      "Iter 3244 | Time 42.8819(41.8745) | Bit/dim 1.0765(1.0796) | Xent 0.0000(0.0000) | Loss 1.0765(1.0796) | Error 0.0000(0.0000) Steps 560(565.61) | Grad Norm 0.0572(0.0587) | Total Time 10.00(10.00)\n",
      "Iter 3245 | Time 41.2405(41.8554) | Bit/dim 1.0798(1.0797) | Xent 0.0000(0.0000) | Loss 1.0798(1.0797) | Error 0.0000(0.0000) Steps 578(565.98) | Grad Norm 0.0604(0.0587) | Total Time 10.00(10.00)\n",
      "Iter 3246 | Time 42.2082(41.8660) | Bit/dim 1.0794(1.0796) | Xent 0.0000(0.0000) | Loss 1.0794(1.0796) | Error 0.0000(0.0000) Steps 578(566.34) | Grad Norm 0.0526(0.0585) | Total Time 10.00(10.00)\n",
      "Iter 3247 | Time 41.8397(41.8652) | Bit/dim 1.0825(1.0797) | Xent 0.0000(0.0000) | Loss 1.0825(1.0797) | Error 0.0000(0.0000) Steps 578(566.69) | Grad Norm 0.0631(0.0587) | Total Time 10.00(10.00)\n",
      "Iter 3248 | Time 40.8367(41.8344) | Bit/dim 1.0782(1.0797) | Xent 0.0000(0.0000) | Loss 1.0782(1.0797) | Error 0.0000(0.0000) Steps 560(566.49) | Grad Norm 0.0448(0.0582) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 21.2880, Epoch Time 325.2719(324.1165), Bit/dim 1.0747(best: 1.0744), Xent 0.0000, Loss 1.0747, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3249 | Time 40.6966(41.8002) | Bit/dim 1.0792(1.0797) | Xent 0.0000(0.0000) | Loss 1.0792(1.0797) | Error 0.0000(0.0000) Steps 560(566.30) | Grad Norm 0.0512(0.0580) | Total Time 10.00(10.00)\n",
      "Iter 3250 | Time 41.9035(41.8033) | Bit/dim 1.0812(1.0797) | Xent 0.0000(0.0000) | Loss 1.0812(1.0797) | Error 0.0000(0.0000) Steps 578(566.65) | Grad Norm 0.0431(0.0576) | Total Time 10.00(10.00)\n",
      "Iter 3251 | Time 42.0968(41.8121) | Bit/dim 1.0772(1.0796) | Xent 0.0000(0.0000) | Loss 1.0772(1.0796) | Error 0.0000(0.0000) Steps 578(566.99) | Grad Norm 0.0409(0.0571) | Total Time 10.00(10.00)\n",
      "Iter 3252 | Time 43.7302(41.8697) | Bit/dim 1.0807(1.0797) | Xent 0.0000(0.0000) | Loss 1.0807(1.0797) | Error 0.0000(0.0000) Steps 560(566.78) | Grad Norm 0.0776(0.0577) | Total Time 10.00(10.00)\n",
      "Iter 3253 | Time 42.3831(41.8851) | Bit/dim 1.0815(1.0797) | Xent 0.0000(0.0000) | Loss 1.0815(1.0797) | Error 0.0000(0.0000) Steps 560(566.58) | Grad Norm 0.0528(0.0576) | Total Time 10.00(10.00)\n",
      "Iter 3254 | Time 42.1209(41.8922) | Bit/dim 1.0817(1.0798) | Xent 0.0000(0.0000) | Loss 1.0817(1.0798) | Error 0.0000(0.0000) Steps 560(566.38) | Grad Norm 0.0499(0.0573) | Total Time 10.00(10.00)\n",
      "Iter 3255 | Time 42.0138(41.8958) | Bit/dim 1.0786(1.0797) | Xent 0.0000(0.0000) | Loss 1.0786(1.0797) | Error 0.0000(0.0000) Steps 560(566.19) | Grad Norm 0.0530(0.0572) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 21.5632, Epoch Time 328.9814(324.2624), Bit/dim 1.0753(best: 1.0744), Xent 0.0000, Loss 1.0753, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3256 | Time 41.9068(41.8961) | Bit/dim 1.0780(1.0797) | Xent 0.0000(0.0000) | Loss 1.0780(1.0797) | Error 0.0000(0.0000) Steps 560(566.00) | Grad Norm 0.0423(0.0567) | Total Time 10.00(10.00)\n",
      "Iter 3257 | Time 42.1539(41.9039) | Bit/dim 1.0831(1.0798) | Xent 0.0000(0.0000) | Loss 1.0831(1.0798) | Error 0.0000(0.0000) Steps 560(565.82) | Grad Norm 0.0861(0.0576) | Total Time 10.00(10.00)\n",
      "Iter 3258 | Time 42.6970(41.9277) | Bit/dim 1.0817(1.0799) | Xent 0.0000(0.0000) | Loss 1.0817(1.0799) | Error 0.0000(0.0000) Steps 560(565.65) | Grad Norm 0.0772(0.0582) | Total Time 10.00(10.00)\n",
      "Iter 3259 | Time 41.5916(41.9176) | Bit/dim 1.0798(1.0799) | Xent 0.0000(0.0000) | Loss 1.0798(1.0799) | Error 0.0000(0.0000) Steps 560(565.48) | Grad Norm 0.0599(0.0583) | Total Time 10.00(10.00)\n",
      "Iter 3260 | Time 44.0459(41.9814) | Bit/dim 1.0792(1.0798) | Xent 0.0000(0.0000) | Loss 1.0792(1.0798) | Error 0.0000(0.0000) Steps 578(565.85) | Grad Norm 0.0845(0.0591) | Total Time 10.00(10.00)\n",
      "Iter 3261 | Time 42.6659(42.0020) | Bit/dim 1.0806(1.0799) | Xent 0.0000(0.0000) | Loss 1.0806(1.0799) | Error 0.0000(0.0000) Steps 560(565.68) | Grad Norm 0.0737(0.0595) | Total Time 10.00(10.00)\n",
      "Iter 3262 | Time 40.5076(41.9571) | Bit/dim 1.0777(1.0798) | Xent 0.0000(0.0000) | Loss 1.0777(1.0798) | Error 0.0000(0.0000) Steps 560(565.51) | Grad Norm 0.0480(0.0591) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 21.3578, Epoch Time 329.2411(324.4118), Bit/dim 1.0751(best: 1.0744), Xent 0.0000, Loss 1.0751, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3263 | Time 43.1156(41.9919) | Bit/dim 1.0807(1.0798) | Xent 0.0000(0.0000) | Loss 1.0807(1.0798) | Error 0.0000(0.0000) Steps 560(565.34) | Grad Norm 0.0522(0.0589) | Total Time 10.00(10.00)\n",
      "Iter 3264 | Time 42.5996(42.0101) | Bit/dim 1.0826(1.0799) | Xent 0.0000(0.0000) | Loss 1.0826(1.0799) | Error 0.0000(0.0000) Steps 560(565.18) | Grad Norm 0.0475(0.0586) | Total Time 10.00(10.00)\n",
      "Iter 3265 | Time 42.6411(42.0290) | Bit/dim 1.0816(1.0800) | Xent 0.0000(0.0000) | Loss 1.0816(1.0800) | Error 0.0000(0.0000) Steps 560(565.03) | Grad Norm 0.1146(0.0603) | Total Time 10.00(10.00)\n",
      "Iter 3266 | Time 43.7035(42.0793) | Bit/dim 1.0794(1.0799) | Xent 0.0000(0.0000) | Loss 1.0794(1.0799) | Error 0.0000(0.0000) Steps 560(564.88) | Grad Norm 0.0929(0.0613) | Total Time 10.00(10.00)\n",
      "Iter 3267 | Time 42.9754(42.1062) | Bit/dim 1.0792(1.0799) | Xent 0.0000(0.0000) | Loss 1.0792(1.0799) | Error 0.0000(0.0000) Steps 578(565.27) | Grad Norm 0.0415(0.0607) | Total Time 10.00(10.00)\n",
      "Iter 3268 | Time 41.9055(42.1001) | Bit/dim 1.0777(1.0798) | Xent 0.0000(0.0000) | Loss 1.0777(1.0798) | Error 0.0000(0.0000) Steps 578(565.65) | Grad Norm 0.0816(0.0613) | Total Time 10.00(10.00)\n",
      "Iter 3269 | Time 41.4730(42.0813) | Bit/dim 1.0760(1.0797) | Xent 0.0000(0.0000) | Loss 1.0760(1.0797) | Error 0.0000(0.0000) Steps 578(566.02) | Grad Norm 0.0460(0.0608) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 21.5226, Epoch Time 332.4760(324.6537), Bit/dim 1.0747(best: 1.0744), Xent 0.0000, Loss 1.0747, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3270 | Time 40.9008(42.0459) | Bit/dim 1.0794(1.0797) | Xent 0.0000(0.0000) | Loss 1.0794(1.0797) | Error 0.0000(0.0000) Steps 560(565.84) | Grad Norm 0.0592(0.0608) | Total Time 10.00(10.00)\n",
      "Iter 3271 | Time 43.9608(42.1034) | Bit/dim 1.0782(1.0797) | Xent 0.0000(0.0000) | Loss 1.0782(1.0797) | Error 0.0000(0.0000) Steps 560(565.67) | Grad Norm 0.0572(0.0607) | Total Time 10.00(10.00)\n",
      "Iter 3272 | Time 41.2672(42.0783) | Bit/dim 1.0784(1.0796) | Xent 0.0000(0.0000) | Loss 1.0784(1.0796) | Error 0.0000(0.0000) Steps 578(566.04) | Grad Norm 0.0549(0.0605) | Total Time 10.00(10.00)\n",
      "Iter 3273 | Time 41.9265(42.0737) | Bit/dim 1.0797(1.0796) | Xent 0.0000(0.0000) | Loss 1.0797(1.0796) | Error 0.0000(0.0000) Steps 560(565.85) | Grad Norm 0.0486(0.0601) | Total Time 10.00(10.00)\n",
      "Iter 3274 | Time 43.3788(42.1129) | Bit/dim 1.0805(1.0797) | Xent 0.0000(0.0000) | Loss 1.0805(1.0797) | Error 0.0000(0.0000) Steps 560(565.68) | Grad Norm 0.0400(0.0595) | Total Time 10.00(10.00)\n",
      "Iter 3275 | Time 41.8250(42.1042) | Bit/dim 1.0831(1.0798) | Xent 0.0000(0.0000) | Loss 1.0831(1.0798) | Error 0.0000(0.0000) Steps 578(566.05) | Grad Norm 0.0481(0.0592) | Total Time 10.00(10.00)\n",
      "Iter 3276 | Time 41.2767(42.0794) | Bit/dim 1.0787(1.0797) | Xent 0.0000(0.0000) | Loss 1.0787(1.0797) | Error 0.0000(0.0000) Steps 560(565.87) | Grad Norm 0.0460(0.0588) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 21.4824, Epoch Time 328.6518(324.7737), Bit/dim 1.0741(best: 1.0744), Xent 0.0000, Loss 1.0741, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3277 | Time 43.1876(42.1127) | Bit/dim 1.0800(1.0797) | Xent 0.0000(0.0000) | Loss 1.0800(1.0797) | Error 0.0000(0.0000) Steps 578(566.23) | Grad Norm 0.0706(0.0592) | Total Time 10.00(10.00)\n",
      "Iter 3278 | Time 41.9904(42.1090) | Bit/dim 1.0803(1.0798) | Xent 0.0000(0.0000) | Loss 1.0803(1.0798) | Error 0.0000(0.0000) Steps 578(566.58) | Grad Norm 0.0532(0.0590) | Total Time 10.00(10.00)\n",
      "Iter 3279 | Time 42.5389(42.1219) | Bit/dim 1.0742(1.0796) | Xent 0.0000(0.0000) | Loss 1.0742(1.0796) | Error 0.0000(0.0000) Steps 578(566.93) | Grad Norm 0.0511(0.0587) | Total Time 10.00(10.00)\n",
      "Iter 3280 | Time 42.2811(42.1267) | Bit/dim 1.0844(1.0797) | Xent 0.0000(0.0000) | Loss 1.0844(1.0797) | Error 0.0000(0.0000) Steps 560(566.72) | Grad Norm 0.0625(0.0589) | Total Time 10.00(10.00)\n",
      "Iter 3281 | Time 40.9584(42.0916) | Bit/dim 1.0768(1.0797) | Xent 0.0000(0.0000) | Loss 1.0768(1.0797) | Error 0.0000(0.0000) Steps 578(567.06) | Grad Norm 0.0700(0.0592) | Total Time 10.00(10.00)\n",
      "Iter 3282 | Time 41.8933(42.0857) | Bit/dim 1.0825(1.0797) | Xent 0.0000(0.0000) | Loss 1.0825(1.0797) | Error 0.0000(0.0000) Steps 560(566.85) | Grad Norm 0.0617(0.0593) | Total Time 10.00(10.00)\n",
      "Iter 3283 | Time 41.4744(42.0673) | Bit/dim 1.0782(1.0797) | Xent 0.0000(0.0000) | Loss 1.0782(1.0797) | Error 0.0000(0.0000) Steps 578(567.18) | Grad Norm 0.0780(0.0598) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 21.3095, Epoch Time 328.1282(324.8743), Bit/dim 1.0746(best: 1.0741), Xent 0.0000, Loss 1.0746, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3284 | Time 42.4882(42.0800) | Bit/dim 1.0840(1.0798) | Xent 0.0000(0.0000) | Loss 1.0840(1.0798) | Error 0.0000(0.0000) Steps 560(566.97) | Grad Norm 0.0610(0.0599) | Total Time 10.00(10.00)\n",
      "Iter 3285 | Time 40.9293(42.0454) | Bit/dim 1.0800(1.0798) | Xent 0.0000(0.0000) | Loss 1.0800(1.0798) | Error 0.0000(0.0000) Steps 560(566.76) | Grad Norm 0.0763(0.0604) | Total Time 10.00(10.00)\n",
      "Iter 3286 | Time 42.1412(42.0483) | Bit/dim 1.0768(1.0797) | Xent 0.0000(0.0000) | Loss 1.0768(1.0797) | Error 0.0000(0.0000) Steps 560(566.55) | Grad Norm 0.0987(0.0615) | Total Time 10.00(10.00)\n",
      "Iter 3287 | Time 43.0239(42.0776) | Bit/dim 1.0799(1.0797) | Xent 0.0000(0.0000) | Loss 1.0799(1.0797) | Error 0.0000(0.0000) Steps 578(566.90) | Grad Norm 0.0915(0.0624) | Total Time 10.00(10.00)\n",
      "Iter 3288 | Time 41.6325(42.0642) | Bit/dim 1.0771(1.0797) | Xent 0.0000(0.0000) | Loss 1.0771(1.0797) | Error 0.0000(0.0000) Steps 560(566.69) | Grad Norm 0.0493(0.0620) | Total Time 10.00(10.00)\n",
      "Iter 3289 | Time 41.0158(42.0328) | Bit/dim 1.0766(1.0796) | Xent 0.0000(0.0000) | Loss 1.0766(1.0796) | Error 0.0000(0.0000) Steps 560(566.49) | Grad Norm 0.0447(0.0615) | Total Time 10.00(10.00)\n",
      "Iter 3290 | Time 43.2794(42.0702) | Bit/dim 1.0805(1.0796) | Xent 0.0000(0.0000) | Loss 1.0805(1.0796) | Error 0.0000(0.0000) Steps 560(566.29) | Grad Norm 0.1061(0.0628) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 21.1121, Epoch Time 328.0671(324.9701), Bit/dim 1.0747(best: 1.0741), Xent 0.0000, Loss 1.0747, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3291 | Time 40.7611(42.0309) | Bit/dim 1.0765(1.0795) | Xent 0.0000(0.0000) | Loss 1.0765(1.0795) | Error 0.0000(0.0000) Steps 560(566.11) | Grad Norm 0.1370(0.0651) | Total Time 10.00(10.00)\n",
      "Iter 3292 | Time 41.1987(42.0059) | Bit/dim 1.0831(1.0796) | Xent 0.0000(0.0000) | Loss 1.0831(1.0796) | Error 0.0000(0.0000) Steps 578(566.46) | Grad Norm 0.0525(0.0647) | Total Time 10.00(10.00)\n",
      "Iter 3293 | Time 41.4513(41.9893) | Bit/dim 1.0781(1.0796) | Xent 0.0000(0.0000) | Loss 1.0781(1.0796) | Error 0.0000(0.0000) Steps 560(566.27) | Grad Norm 0.0666(0.0647) | Total Time 10.00(10.00)\n",
      "Iter 3294 | Time 41.8767(41.9859) | Bit/dim 1.0812(1.0796) | Xent 0.0000(0.0000) | Loss 1.0812(1.0796) | Error 0.0000(0.0000) Steps 578(566.62) | Grad Norm 0.0862(0.0654) | Total Time 10.00(10.00)\n",
      "Iter 3295 | Time 40.7955(41.9502) | Bit/dim 1.0775(1.0796) | Xent 0.0000(0.0000) | Loss 1.0775(1.0796) | Error 0.0000(0.0000) Steps 560(566.42) | Grad Norm 0.1054(0.0666) | Total Time 10.00(10.00)\n",
      "Iter 3296 | Time 41.7189(41.9433) | Bit/dim 1.0758(1.0794) | Xent 0.0000(0.0000) | Loss 1.0758(1.0794) | Error 0.0000(0.0000) Steps 560(566.23) | Grad Norm 0.0580(0.0663) | Total Time 10.00(10.00)\n",
      "Iter 3297 | Time 42.8794(41.9714) | Bit/dim 1.0836(1.0796) | Xent 0.0000(0.0000) | Loss 1.0836(1.0796) | Error 0.0000(0.0000) Steps 560(566.04) | Grad Norm 0.0475(0.0658) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 20.7767, Epoch Time 323.9259(324.9388), Bit/dim 1.0743(best: 1.0741), Xent 0.0000, Loss 1.0743, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3298 | Time 41.5441(41.9585) | Bit/dim 1.0808(1.0796) | Xent 0.0000(0.0000) | Loss 1.0808(1.0796) | Error 0.0000(0.0000) Steps 578(566.40) | Grad Norm 0.0456(0.0652) | Total Time 10.00(10.00)\n",
      "Iter 3299 | Time 41.9137(41.9572) | Bit/dim 1.0772(1.0795) | Xent 0.0000(0.0000) | Loss 1.0772(1.0795) | Error 0.0000(0.0000) Steps 560(566.21) | Grad Norm 0.0824(0.0657) | Total Time 10.00(10.00)\n",
      "Iter 3300 | Time 42.1531(41.9631) | Bit/dim 1.0748(1.0794) | Xent 0.0000(0.0000) | Loss 1.0748(1.0794) | Error 0.0000(0.0000) Steps 560(566.02) | Grad Norm 0.1572(0.0684) | Total Time 10.00(10.00)\n",
      "Iter 3301 | Time 41.5469(41.9506) | Bit/dim 1.0789(1.0794) | Xent 0.0000(0.0000) | Loss 1.0789(1.0794) | Error 0.0000(0.0000) Steps 560(565.84) | Grad Norm 0.0471(0.0678) | Total Time 10.00(10.00)\n",
      "Iter 3302 | Time 42.3531(41.9627) | Bit/dim 1.0834(1.0795) | Xent 0.0000(0.0000) | Loss 1.0834(1.0795) | Error 0.0000(0.0000) Steps 560(565.67) | Grad Norm 0.0427(0.0670) | Total Time 10.00(10.00)\n",
      "Iter 3303 | Time 41.4130(41.9462) | Bit/dim 1.0812(1.0795) | Xent 0.0000(0.0000) | Loss 1.0812(1.0795) | Error 0.0000(0.0000) Steps 560(565.50) | Grad Norm 0.1060(0.0682) | Total Time 10.00(10.00)\n",
      "Iter 3304 | Time 41.5110(41.9331) | Bit/dim 1.0828(1.0796) | Xent 0.0000(0.0000) | Loss 1.0828(1.0796) | Error 0.0000(0.0000) Steps 578(565.87) | Grad Norm 0.1670(0.0712) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 21.3218, Epoch Time 326.5785(324.9880), Bit/dim 1.0746(best: 1.0741), Xent 0.0000, Loss 1.0746, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3305 | Time 42.9861(41.9647) | Bit/dim 1.0806(1.0797) | Xent 0.0000(0.0000) | Loss 1.0806(1.0797) | Error 0.0000(0.0000) Steps 578(566.24) | Grad Norm 0.0546(0.0707) | Total Time 10.00(10.00)\n",
      "Iter 3306 | Time 41.6446(41.9551) | Bit/dim 1.0849(1.0798) | Xent 0.0000(0.0000) | Loss 1.0849(1.0798) | Error 0.0000(0.0000) Steps 560(566.05) | Grad Norm 0.0455(0.0699) | Total Time 10.00(10.00)\n",
      "Iter 3307 | Time 41.7146(41.9479) | Bit/dim 1.0782(1.0798) | Xent 0.0000(0.0000) | Loss 1.0782(1.0798) | Error 0.0000(0.0000) Steps 560(565.87) | Grad Norm 0.0831(0.0703) | Total Time 10.00(10.00)\n",
      "Iter 3308 | Time 40.9273(41.9173) | Bit/dim 1.0769(1.0797) | Xent 0.0000(0.0000) | Loss 1.0769(1.0797) | Error 0.0000(0.0000) Steps 560(565.69) | Grad Norm 0.0796(0.0706) | Total Time 10.00(10.00)\n",
      "Iter 3309 | Time 43.2437(41.9571) | Bit/dim 1.0752(1.0796) | Xent 0.0000(0.0000) | Loss 1.0752(1.0796) | Error 0.0000(0.0000) Steps 578(566.06) | Grad Norm 0.0560(0.0701) | Total Time 10.00(10.00)\n",
      "Iter 3310 | Time 43.2455(41.9957) | Bit/dim 1.0810(1.0796) | Xent 0.0000(0.0000) | Loss 1.0810(1.0796) | Error 0.0000(0.0000) Steps 560(565.88) | Grad Norm 0.0572(0.0698) | Total Time 10.00(10.00)\n",
      "Iter 3311 | Time 44.0161(42.0563) | Bit/dim 1.0787(1.0796) | Xent 0.0000(0.0000) | Loss 1.0787(1.0796) | Error 0.0000(0.0000) Steps 560(565.70) | Grad Norm 0.0602(0.0695) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 21.7276, Epoch Time 331.9288(325.1962), Bit/dim 1.0739(best: 1.0741), Xent 0.0000, Loss 1.0739, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3312 | Time 42.7322(42.0766) | Bit/dim 1.0743(1.0794) | Xent 0.0000(0.0000) | Loss 1.0743(1.0794) | Error 0.0000(0.0000) Steps 578(566.07) | Grad Norm 0.0583(0.0691) | Total Time 10.00(10.00)\n",
      "Iter 3313 | Time 41.6829(42.0648) | Bit/dim 1.0781(1.0794) | Xent 0.0000(0.0000) | Loss 1.0781(1.0794) | Error 0.0000(0.0000) Steps 578(566.43) | Grad Norm 0.0516(0.0686) | Total Time 10.00(10.00)\n",
      "Iter 3314 | Time 40.7844(42.0264) | Bit/dim 1.0828(1.0795) | Xent 0.0000(0.0000) | Loss 1.0828(1.0795) | Error 0.0000(0.0000) Steps 578(566.78) | Grad Norm 0.0797(0.0689) | Total Time 10.00(10.00)\n",
      "Iter 3315 | Time 41.2599(42.0034) | Bit/dim 1.0795(1.0795) | Xent 0.0000(0.0000) | Loss 1.0795(1.0795) | Error 0.0000(0.0000) Steps 560(566.57) | Grad Norm 0.0785(0.0692) | Total Time 10.00(10.00)\n",
      "Iter 3316 | Time 42.0246(42.0040) | Bit/dim 1.0801(1.0795) | Xent 0.0000(0.0000) | Loss 1.0801(1.0795) | Error 0.0000(0.0000) Steps 560(566.38) | Grad Norm 0.0594(0.0689) | Total Time 10.00(10.00)\n",
      "Iter 3317 | Time 42.3249(42.0136) | Bit/dim 1.0803(1.0795) | Xent 0.0000(0.0000) | Loss 1.0803(1.0795) | Error 0.0000(0.0000) Steps 578(566.72) | Grad Norm 0.0641(0.0688) | Total Time 10.00(10.00)\n",
      "Iter 3318 | Time 42.6222(42.0319) | Bit/dim 1.0765(1.0794) | Xent 0.0000(0.0000) | Loss 1.0765(1.0794) | Error 0.0000(0.0000) Steps 578(567.06) | Grad Norm 0.1069(0.0699) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 21.4067, Epoch Time 327.4661(325.2643), Bit/dim 1.0741(best: 1.0739), Xent 0.0000, Loss 1.0741, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3319 | Time 41.5422(42.0172) | Bit/dim 1.0775(1.0794) | Xent 0.0000(0.0000) | Loss 1.0775(1.0794) | Error 0.0000(0.0000) Steps 560(566.85) | Grad Norm 0.1455(0.0722) | Total Time 10.00(10.00)\n",
      "Iter 3320 | Time 42.1238(42.0204) | Bit/dim 1.0824(1.0795) | Xent 0.0000(0.0000) | Loss 1.0824(1.0795) | Error 0.0000(0.0000) Steps 560(566.65) | Grad Norm 0.0733(0.0722) | Total Time 10.00(10.00)\n",
      "Iter 3321 | Time 41.2751(41.9981) | Bit/dim 1.0724(1.0793) | Xent 0.0000(0.0000) | Loss 1.0724(1.0793) | Error 0.0000(0.0000) Steps 560(566.45) | Grad Norm 0.0724(0.0722) | Total Time 10.00(10.00)\n",
      "Iter 3322 | Time 39.9190(41.9357) | Bit/dim 1.0783(1.0792) | Xent 0.0000(0.0000) | Loss 1.0783(1.0792) | Error 0.0000(0.0000) Steps 560(566.25) | Grad Norm 0.1188(0.0736) | Total Time 10.00(10.00)\n",
      "Iter 3323 | Time 43.0372(41.9687) | Bit/dim 1.0764(1.0791) | Xent 0.0000(0.0000) | Loss 1.0764(1.0791) | Error 0.0000(0.0000) Steps 560(566.07) | Grad Norm 0.1579(0.0762) | Total Time 10.00(10.00)\n",
      "Iter 3324 | Time 42.5382(41.9858) | Bit/dim 1.0809(1.0792) | Xent 0.0000(0.0000) | Loss 1.0809(1.0792) | Error 0.0000(0.0000) Steps 578(566.42) | Grad Norm 0.0663(0.0759) | Total Time 10.00(10.00)\n",
      "Iter 3325 | Time 42.1137(41.9896) | Bit/dim 1.0826(1.0793) | Xent 0.0000(0.0000) | Loss 1.0826(1.0793) | Error 0.0000(0.0000) Steps 578(566.77) | Grad Norm 0.0918(0.0763) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 21.1155, Epoch Time 326.0379(325.2875), Bit/dim 1.0745(best: 1.0739), Xent 0.0000, Loss 1.0745, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3326 | Time 42.0841(41.9925) | Bit/dim 1.0818(1.0794) | Xent 0.0000(0.0000) | Loss 1.0818(1.0794) | Error 0.0000(0.0000) Steps 560(566.57) | Grad Norm 0.0994(0.0770) | Total Time 10.00(10.00)\n",
      "Iter 3327 | Time 43.1198(42.0263) | Bit/dim 1.0806(1.0794) | Xent 0.0000(0.0000) | Loss 1.0806(1.0794) | Error 0.0000(0.0000) Steps 560(566.37) | Grad Norm 0.1241(0.0784) | Total Time 10.00(10.00)\n",
      "Iter 3328 | Time 42.1814(42.0310) | Bit/dim 1.0811(1.0795) | Xent 0.0000(0.0000) | Loss 1.0811(1.0795) | Error 0.0000(0.0000) Steps 560(566.18) | Grad Norm 0.0548(0.0777) | Total Time 10.00(10.00)\n",
      "Iter 3329 | Time 40.1594(41.9748) | Bit/dim 1.0738(1.0793) | Xent 0.0000(0.0000) | Loss 1.0738(1.0793) | Error 0.0000(0.0000) Steps 560(565.99) | Grad Norm 0.0506(0.0769) | Total Time 10.00(10.00)\n",
      "Iter 3330 | Time 42.5815(41.9930) | Bit/dim 1.0797(1.0793) | Xent 0.0000(0.0000) | Loss 1.0797(1.0793) | Error 0.0000(0.0000) Steps 560(565.81) | Grad Norm 0.0980(0.0776) | Total Time 10.00(10.00)\n",
      "Iter 3331 | Time 41.5165(41.9787) | Bit/dim 1.0747(1.0792) | Xent 0.0000(0.0000) | Loss 1.0747(1.0792) | Error 0.0000(0.0000) Steps 560(565.64) | Grad Norm 0.0738(0.0774) | Total Time 10.00(10.00)\n",
      "Iter 3332 | Time 41.3734(41.9606) | Bit/dim 1.0808(1.0792) | Xent 0.0000(0.0000) | Loss 1.0808(1.0792) | Error 0.0000(0.0000) Steps 578(566.01) | Grad Norm 0.1087(0.0784) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 21.1861, Epoch Time 326.7298(325.3308), Bit/dim 1.0744(best: 1.0739), Xent 0.0000, Loss 1.0744, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3333 | Time 42.1261(41.9655) | Bit/dim 1.0801(1.0792) | Xent 0.0000(0.0000) | Loss 1.0801(1.0792) | Error 0.0000(0.0000) Steps 578(566.37) | Grad Norm 0.0433(0.0773) | Total Time 10.00(10.00)\n",
      "Iter 3334 | Time 43.7188(42.0181) | Bit/dim 1.0729(1.0790) | Xent 0.0000(0.0000) | Loss 1.0729(1.0790) | Error 0.0000(0.0000) Steps 560(566.18) | Grad Norm 0.0737(0.0772) | Total Time 10.00(10.00)\n",
      "Iter 3335 | Time 41.3483(41.9980) | Bit/dim 1.0831(1.0792) | Xent 0.0000(0.0000) | Loss 1.0831(1.0792) | Error 0.0000(0.0000) Steps 560(565.99) | Grad Norm 0.1107(0.0782) | Total Time 10.00(10.00)\n",
      "Iter 3336 | Time 41.7009(41.9891) | Bit/dim 1.0798(1.0792) | Xent 0.0000(0.0000) | Loss 1.0798(1.0792) | Error 0.0000(0.0000) Steps 560(565.81) | Grad Norm 0.0868(0.0785) | Total Time 10.00(10.00)\n",
      "Iter 3337 | Time 40.9971(41.9593) | Bit/dim 1.0833(1.0793) | Xent 0.0000(0.0000) | Loss 1.0833(1.0793) | Error 0.0000(0.0000) Steps 560(565.64) | Grad Norm 0.0430(0.0774) | Total Time 10.00(10.00)\n",
      "Iter 3338 | Time 41.6942(41.9514) | Bit/dim 1.0787(1.0793) | Xent 0.0000(0.0000) | Loss 1.0787(1.0793) | Error 0.0000(0.0000) Steps 560(565.47) | Grad Norm 0.0532(0.0767) | Total Time 10.00(10.00)\n",
      "Iter 3339 | Time 42.9740(41.9821) | Bit/dim 1.0764(1.0792) | Xent 0.0000(0.0000) | Loss 1.0764(1.0792) | Error 0.0000(0.0000) Steps 560(565.31) | Grad Norm 0.0627(0.0763) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 21.0479, Epoch Time 328.1086(325.4141), Bit/dim 1.0738(best: 1.0739), Xent 0.0000, Loss 1.0738, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3340 | Time 41.7064(41.9738) | Bit/dim 1.0777(1.0792) | Xent 0.0000(0.0000) | Loss 1.0777(1.0792) | Error 0.0000(0.0000) Steps 560(565.15) | Grad Norm 0.0516(0.0755) | Total Time 10.00(10.00)\n",
      "Iter 3341 | Time 42.2656(41.9826) | Bit/dim 1.0815(1.0792) | Xent 0.0000(0.0000) | Loss 1.0815(1.0792) | Error 0.0000(0.0000) Steps 560(564.99) | Grad Norm 0.0669(0.0753) | Total Time 10.00(10.00)\n",
      "Iter 3342 | Time 41.3322(41.9630) | Bit/dim 1.0706(1.0790) | Xent 0.0000(0.0000) | Loss 1.0706(1.0790) | Error 0.0000(0.0000) Steps 560(564.84) | Grad Norm 0.0485(0.0745) | Total Time 10.00(10.00)\n",
      "Iter 3343 | Time 42.5442(41.9805) | Bit/dim 1.0829(1.0791) | Xent 0.0000(0.0000) | Loss 1.0829(1.0791) | Error 0.0000(0.0000) Steps 560(564.70) | Grad Norm 0.0764(0.0745) | Total Time 10.00(10.00)\n",
      "Iter 3344 | Time 42.8686(42.0071) | Bit/dim 1.0781(1.0791) | Xent 0.0000(0.0000) | Loss 1.0781(1.0791) | Error 0.0000(0.0000) Steps 560(564.56) | Grad Norm 0.0431(0.0736) | Total Time 10.00(10.00)\n",
      "Iter 3345 | Time 41.3500(41.9874) | Bit/dim 1.0787(1.0791) | Xent 0.0000(0.0000) | Loss 1.0787(1.0791) | Error 0.0000(0.0000) Steps 560(564.42) | Grad Norm 0.0572(0.0731) | Total Time 10.00(10.00)\n",
      "Iter 3346 | Time 41.5650(41.9747) | Bit/dim 1.0796(1.0791) | Xent 0.0000(0.0000) | Loss 1.0796(1.0791) | Error 0.0000(0.0000) Steps 560(564.29) | Grad Norm 0.0453(0.0723) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 21.3258, Epoch Time 327.3471(325.4721), Bit/dim 1.0744(best: 1.0738), Xent 0.0000, Loss 1.0744, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3347 | Time 40.9810(41.9449) | Bit/dim 1.0835(1.0792) | Xent 0.0000(0.0000) | Loss 1.0835(1.0792) | Error 0.0000(0.0000) Steps 560(564.16) | Grad Norm 0.0444(0.0714) | Total Time 10.00(10.00)\n",
      "Iter 3348 | Time 41.6760(41.9369) | Bit/dim 1.0790(1.0792) | Xent 0.0000(0.0000) | Loss 1.0790(1.0792) | Error 0.0000(0.0000) Steps 578(564.57) | Grad Norm 0.0404(0.0705) | Total Time 10.00(10.00)\n",
      "Iter 3349 | Time 41.1690(41.9138) | Bit/dim 1.0764(1.0791) | Xent 0.0000(0.0000) | Loss 1.0764(1.0791) | Error 0.0000(0.0000) Steps 560(564.44) | Grad Norm 0.0547(0.0700) | Total Time 10.00(10.00)\n",
      "Iter 3350 | Time 42.6260(41.9352) | Bit/dim 1.0820(1.0792) | Xent 0.0000(0.0000) | Loss 1.0820(1.0792) | Error 0.0000(0.0000) Steps 578(564.84) | Grad Norm 0.0755(0.0702) | Total Time 10.00(10.00)\n",
      "Iter 3351 | Time 41.5564(41.9238) | Bit/dim 1.0802(1.0792) | Xent 0.0000(0.0000) | Loss 1.0802(1.0792) | Error 0.0000(0.0000) Steps 560(564.70) | Grad Norm 0.0451(0.0694) | Total Time 10.00(10.00)\n",
      "Iter 3352 | Time 42.2448(41.9335) | Bit/dim 1.0770(1.0792) | Xent 0.0000(0.0000) | Loss 1.0770(1.0792) | Error 0.0000(0.0000) Steps 560(564.56) | Grad Norm 0.0642(0.0693) | Total Time 10.00(10.00)\n",
      "Iter 3353 | Time 42.2943(41.9443) | Bit/dim 1.0792(1.0792) | Xent 0.0000(0.0000) | Loss 1.0792(1.0792) | Error 0.0000(0.0000) Steps 578(564.96) | Grad Norm 0.0798(0.0696) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 21.1966, Epoch Time 326.2992(325.4969), Bit/dim 1.0747(best: 1.0738), Xent 0.0000, Loss 1.0747, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3354 | Time 41.6897(41.9366) | Bit/dim 1.0782(1.0791) | Xent 0.0000(0.0000) | Loss 1.0782(1.0791) | Error 0.0000(0.0000) Steps 560(564.81) | Grad Norm 0.0393(0.0687) | Total Time 10.00(10.00)\n",
      "Iter 3355 | Time 42.0382(41.9397) | Bit/dim 1.0770(1.0791) | Xent 0.0000(0.0000) | Loss 1.0770(1.0791) | Error 0.0000(0.0000) Steps 560(564.67) | Grad Norm 0.0431(0.0679) | Total Time 10.00(10.00)\n",
      "Iter 3356 | Time 41.8404(41.9367) | Bit/dim 1.0789(1.0791) | Xent 0.0000(0.0000) | Loss 1.0789(1.0791) | Error 0.0000(0.0000) Steps 578(565.07) | Grad Norm 0.0472(0.0673) | Total Time 10.00(10.00)\n",
      "Iter 3357 | Time 43.3184(41.9782) | Bit/dim 1.0766(1.0790) | Xent 0.0000(0.0000) | Loss 1.0766(1.0790) | Error 0.0000(0.0000) Steps 560(564.92) | Grad Norm 0.0715(0.0674) | Total Time 10.00(10.00)\n",
      "Iter 3358 | Time 42.4567(41.9925) | Bit/dim 1.0775(1.0790) | Xent 0.0000(0.0000) | Loss 1.0775(1.0790) | Error 0.0000(0.0000) Steps 560(564.77) | Grad Norm 0.0501(0.0669) | Total Time 10.00(10.00)\n",
      "Iter 3359 | Time 43.2942(42.0316) | Bit/dim 1.0835(1.0791) | Xent 0.0000(0.0000) | Loss 1.0835(1.0791) | Error 0.0000(0.0000) Steps 578(565.16) | Grad Norm 0.0473(0.0663) | Total Time 10.00(10.00)\n",
      "Iter 3360 | Time 41.9287(42.0285) | Bit/dim 1.0831(1.0792) | Xent 0.0000(0.0000) | Loss 1.0831(1.0792) | Error 0.0000(0.0000) Steps 578(565.55) | Grad Norm 0.0511(0.0659) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 21.1027, Epoch Time 330.3424(325.6423), Bit/dim 1.0739(best: 1.0738), Xent 0.0000, Loss 1.0739, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3361 | Time 43.2776(42.0660) | Bit/dim 1.0809(1.0793) | Xent 0.0000(0.0000) | Loss 1.0809(1.0793) | Error 0.0000(0.0000) Steps 578(565.92) | Grad Norm 0.0388(0.0650) | Total Time 10.00(10.00)\n",
      "Iter 3362 | Time 41.9064(42.0612) | Bit/dim 1.0779(1.0792) | Xent 0.0000(0.0000) | Loss 1.0779(1.0792) | Error 0.0000(0.0000) Steps 560(565.75) | Grad Norm 0.0576(0.0648) | Total Time 10.00(10.00)\n",
      "Iter 3363 | Time 42.6337(42.0783) | Bit/dim 1.0784(1.0792) | Xent 0.0000(0.0000) | Loss 1.0784(1.0792) | Error 0.0000(0.0000) Steps 560(565.57) | Grad Norm 0.0545(0.0645) | Total Time 10.00(10.00)\n",
      "Iter 3364 | Time 42.0208(42.0766) | Bit/dim 1.0794(1.0792) | Xent 0.0000(0.0000) | Loss 1.0794(1.0792) | Error 0.0000(0.0000) Steps 560(565.41) | Grad Norm 0.0850(0.0651) | Total Time 10.00(10.00)\n",
      "Iter 3365 | Time 42.6142(42.0927) | Bit/dim 1.0811(1.0793) | Xent 0.0000(0.0000) | Loss 1.0811(1.0793) | Error 0.0000(0.0000) Steps 578(565.78) | Grad Norm 0.0652(0.0651) | Total Time 10.00(10.00)\n",
      "Iter 3366 | Time 42.0984(42.0929) | Bit/dim 1.0776(1.0792) | Xent 0.0000(0.0000) | Loss 1.0776(1.0792) | Error 0.0000(0.0000) Steps 578(566.15) | Grad Norm 0.0451(0.0645) | Total Time 10.00(10.00)\n",
      "Iter 3367 | Time 43.4671(42.1341) | Bit/dim 1.0788(1.0792) | Xent 0.0000(0.0000) | Loss 1.0788(1.0792) | Error 0.0000(0.0000) Steps 560(565.97) | Grad Norm 0.0594(0.0644) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 21.4286, Epoch Time 331.9053(325.8302), Bit/dim 1.0738(best: 1.0738), Xent 0.0000, Loss 1.0738, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3368 | Time 40.2325(42.0771) | Bit/dim 1.0814(1.0793) | Xent 0.0000(0.0000) | Loss 1.0814(1.0793) | Error 0.0000(0.0000) Steps 560(565.79) | Grad Norm 0.0458(0.0638) | Total Time 10.00(10.00)\n",
      "Iter 3369 | Time 42.1214(42.0784) | Bit/dim 1.0781(1.0792) | Xent 0.0000(0.0000) | Loss 1.0781(1.0792) | Error 0.0000(0.0000) Steps 560(565.61) | Grad Norm 0.0515(0.0634) | Total Time 10.00(10.00)\n",
      "Iter 3370 | Time 42.3926(42.0878) | Bit/dim 1.0747(1.0791) | Xent 0.0000(0.0000) | Loss 1.0747(1.0791) | Error 0.0000(0.0000) Steps 560(565.44) | Grad Norm 0.0597(0.0633) | Total Time 10.00(10.00)\n",
      "Iter 3371 | Time 41.4840(42.0697) | Bit/dim 1.0798(1.0791) | Xent 0.0000(0.0000) | Loss 1.0798(1.0791) | Error 0.0000(0.0000) Steps 560(565.28) | Grad Norm 0.0563(0.0631) | Total Time 10.00(10.00)\n",
      "Iter 3372 | Time 42.3551(42.0783) | Bit/dim 1.0819(1.0792) | Xent 0.0000(0.0000) | Loss 1.0819(1.0792) | Error 0.0000(0.0000) Steps 560(565.12) | Grad Norm 0.0415(0.0625) | Total Time 10.00(10.00)\n",
      "Iter 3373 | Time 42.5311(42.0919) | Bit/dim 1.0802(1.0792) | Xent 0.0000(0.0000) | Loss 1.0802(1.0792) | Error 0.0000(0.0000) Steps 578(565.51) | Grad Norm 0.0445(0.0619) | Total Time 10.00(10.00)\n",
      "Iter 3374 | Time 41.9060(42.0863) | Bit/dim 1.0803(1.0793) | Xent 0.0000(0.0000) | Loss 1.0803(1.0793) | Error 0.0000(0.0000) Steps 578(565.88) | Grad Norm 0.0447(0.0614) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 21.2987, Epoch Time 326.7411(325.8575), Bit/dim 1.0741(best: 1.0738), Xent 0.0000, Loss 1.0741, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3375 | Time 41.9853(42.0833) | Bit/dim 1.0759(1.0792) | Xent 0.0000(0.0000) | Loss 1.0759(1.0792) | Error 0.0000(0.0000) Steps 560(565.71) | Grad Norm 0.0503(0.0611) | Total Time 10.00(10.00)\n",
      "Iter 3376 | Time 41.2115(42.0571) | Bit/dim 1.0828(1.0793) | Xent 0.0000(0.0000) | Loss 1.0828(1.0793) | Error 0.0000(0.0000) Steps 578(566.08) | Grad Norm 0.0408(0.0605) | Total Time 10.00(10.00)\n",
      "Iter 3377 | Time 41.7242(42.0471) | Bit/dim 1.0818(1.0793) | Xent 0.0000(0.0000) | Loss 1.0818(1.0793) | Error 0.0000(0.0000) Steps 560(565.89) | Grad Norm 0.0844(0.0612) | Total Time 10.00(10.00)\n",
      "Iter 3378 | Time 41.0998(42.0187) | Bit/dim 1.0773(1.0793) | Xent 0.0000(0.0000) | Loss 1.0773(1.0793) | Error 0.0000(0.0000) Steps 560(565.72) | Grad Norm 0.0498(0.0609) | Total Time 10.00(10.00)\n",
      "Iter 3379 | Time 40.9418(41.9864) | Bit/dim 1.0803(1.0793) | Xent 0.0000(0.0000) | Loss 1.0803(1.0793) | Error 0.0000(0.0000) Steps 578(566.09) | Grad Norm 0.0794(0.0614) | Total Time 10.00(10.00)\n",
      "Iter 3380 | Time 41.7170(41.9783) | Bit/dim 1.0797(1.0793) | Xent 0.0000(0.0000) | Loss 1.0797(1.0793) | Error 0.0000(0.0000) Steps 560(565.90) | Grad Norm 0.0708(0.0617) | Total Time 10.00(10.00)\n",
      "Iter 3381 | Time 42.8490(42.0044) | Bit/dim 1.0791(1.0793) | Xent 0.0000(0.0000) | Loss 1.0791(1.0793) | Error 0.0000(0.0000) Steps 578(566.27) | Grad Norm 0.0534(0.0614) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 21.6332, Epoch Time 325.9111(325.8591), Bit/dim 1.0735(best: 1.0738), Xent 0.0000, Loss 1.0735, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3382 | Time 41.9855(42.0039) | Bit/dim 1.0807(1.0794) | Xent 0.0000(0.0000) | Loss 1.0807(1.0794) | Error 0.0000(0.0000) Steps 560(566.08) | Grad Norm 0.0460(0.0610) | Total Time 10.00(10.00)\n",
      "Iter 3383 | Time 41.7935(41.9976) | Bit/dim 1.0791(1.0793) | Xent 0.0000(0.0000) | Loss 1.0791(1.0793) | Error 0.0000(0.0000) Steps 578(566.44) | Grad Norm 0.0439(0.0605) | Total Time 10.00(10.00)\n",
      "Iter 3384 | Time 42.4224(42.0103) | Bit/dim 1.0761(1.0793) | Xent 0.0000(0.0000) | Loss 1.0761(1.0793) | Error 0.0000(0.0000) Steps 560(566.24) | Grad Norm 0.0369(0.0598) | Total Time 10.00(10.00)\n",
      "Iter 3385 | Time 42.5577(42.0267) | Bit/dim 1.0771(1.0792) | Xent 0.0000(0.0000) | Loss 1.0771(1.0792) | Error 0.0000(0.0000) Steps 560(566.06) | Grad Norm 0.0768(0.0603) | Total Time 10.00(10.00)\n",
      "Iter 3386 | Time 42.6210(42.0446) | Bit/dim 1.0800(1.0792) | Xent 0.0000(0.0000) | Loss 1.0800(1.0792) | Error 0.0000(0.0000) Steps 578(566.41) | Grad Norm 0.0707(0.0606) | Total Time 10.00(10.00)\n",
      "Iter 3387 | Time 44.0991(42.1062) | Bit/dim 1.0754(1.0791) | Xent 0.0000(0.0000) | Loss 1.0754(1.0791) | Error 0.0000(0.0000) Steps 578(566.76) | Grad Norm 0.0516(0.0603) | Total Time 10.00(10.00)\n",
      "Iter 3388 | Time 41.0093(42.0733) | Bit/dim 1.0809(1.0792) | Xent 0.0000(0.0000) | Loss 1.0809(1.0792) | Error 0.0000(0.0000) Steps 578(567.10) | Grad Norm 0.0618(0.0604) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 21.4410, Epoch Time 330.2732(325.9915), Bit/dim 1.0736(best: 1.0735), Xent 0.0000, Loss 1.0736, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3389 | Time 42.0517(42.0726) | Bit/dim 1.0827(1.0793) | Xent 0.0000(0.0000) | Loss 1.0827(1.0793) | Error 0.0000(0.0000) Steps 560(566.89) | Grad Norm 0.0785(0.0609) | Total Time 10.00(10.00)\n",
      "Iter 3390 | Time 43.4606(42.1143) | Bit/dim 1.0814(1.0793) | Xent 0.0000(0.0000) | Loss 1.0814(1.0793) | Error 0.0000(0.0000) Steps 560(566.68) | Grad Norm 0.0695(0.0612) | Total Time 10.00(10.00)\n",
      "Iter 3391 | Time 42.2031(42.1169) | Bit/dim 1.0758(1.0792) | Xent 0.0000(0.0000) | Loss 1.0758(1.0792) | Error 0.0000(0.0000) Steps 560(566.48) | Grad Norm 0.0638(0.0612) | Total Time 10.00(10.00)\n",
      "Iter 3392 | Time 42.9833(42.1429) | Bit/dim 1.0818(1.0793) | Xent 0.0000(0.0000) | Loss 1.0818(1.0793) | Error 0.0000(0.0000) Steps 560(566.28) | Grad Norm 0.0502(0.0609) | Total Time 10.00(10.00)\n",
      "Iter 3393 | Time 41.3545(42.1193) | Bit/dim 1.0809(1.0793) | Xent 0.0000(0.0000) | Loss 1.0809(1.0793) | Error 0.0000(0.0000) Steps 560(566.10) | Grad Norm 0.0391(0.0603) | Total Time 10.00(10.00)\n",
      "Iter 3394 | Time 40.9385(42.0839) | Bit/dim 1.0756(1.0792) | Xent 0.0000(0.0000) | Loss 1.0756(1.0792) | Error 0.0000(0.0000) Steps 560(565.91) | Grad Norm 0.0803(0.0609) | Total Time 10.00(10.00)\n",
      "Iter 3395 | Time 41.9863(42.0809) | Bit/dim 1.0778(1.0792) | Xent 0.0000(0.0000) | Loss 1.0778(1.0792) | Error 0.0000(0.0000) Steps 578(566.28) | Grad Norm 0.0442(0.0604) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 21.1994, Epoch Time 328.7461(326.0742), Bit/dim 1.0736(best: 1.0735), Xent 0.0000, Loss 1.0736, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3396 | Time 42.1763(42.0838) | Bit/dim 1.0806(1.0792) | Xent 0.0000(0.0000) | Loss 1.0806(1.0792) | Error 0.0000(0.0000) Steps 560(566.09) | Grad Norm 0.0959(0.0614) | Total Time 10.00(10.00)\n",
      "Iter 3397 | Time 43.3177(42.1208) | Bit/dim 1.0816(1.0793) | Xent 0.0000(0.0000) | Loss 1.0816(1.0793) | Error 0.0000(0.0000) Steps 560(565.90) | Grad Norm 0.0607(0.0614) | Total Time 10.00(10.00)\n",
      "Iter 3398 | Time 42.3952(42.1290) | Bit/dim 1.0793(1.0793) | Xent 0.0000(0.0000) | Loss 1.0793(1.0793) | Error 0.0000(0.0000) Steps 560(565.73) | Grad Norm 0.0708(0.0617) | Total Time 10.00(10.00)\n",
      "Iter 3399 | Time 43.1823(42.1606) | Bit/dim 1.0771(1.0792) | Xent 0.0000(0.0000) | Loss 1.0771(1.0792) | Error 0.0000(0.0000) Steps 578(566.10) | Grad Norm 0.1282(0.0637) | Total Time 10.00(10.00)\n",
      "Iter 3400 | Time 43.2905(42.1945) | Bit/dim 1.0822(1.0793) | Xent 0.0000(0.0000) | Loss 1.0822(1.0793) | Error 0.0000(0.0000) Steps 578(566.45) | Grad Norm 0.0489(0.0632) | Total Time 10.00(10.00)\n",
      "Iter 3401 | Time 42.9386(42.2169) | Bit/dim 1.0782(1.0793) | Xent 0.0000(0.0000) | Loss 1.0782(1.0793) | Error 0.0000(0.0000) Steps 560(566.26) | Grad Norm 0.0433(0.0626) | Total Time 10.00(10.00)\n",
      "Iter 3402 | Time 41.0246(42.1811) | Bit/dim 1.0762(1.0792) | Xent 0.0000(0.0000) | Loss 1.0762(1.0792) | Error 0.0000(0.0000) Steps 560(566.07) | Grad Norm 0.0547(0.0624) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 21.5436, Epoch Time 332.4819(326.2664), Bit/dim 1.0735(best: 1.0735), Xent 0.0000, Loss 1.0735, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3403 | Time 39.2008(42.0917) | Bit/dim 1.0748(1.0791) | Xent 0.0000(0.0000) | Loss 1.0748(1.0791) | Error 0.0000(0.0000) Steps 560(565.89) | Grad Norm 0.0668(0.0625) | Total Time 10.00(10.00)\n",
      "Iter 3404 | Time 42.1640(42.0939) | Bit/dim 1.0833(1.0792) | Xent 0.0000(0.0000) | Loss 1.0833(1.0792) | Error 0.0000(0.0000) Steps 560(565.71) | Grad Norm 0.0760(0.0629) | Total Time 10.00(10.00)\n",
      "Iter 3405 | Time 42.2417(42.0983) | Bit/dim 1.0772(1.0791) | Xent 0.0000(0.0000) | Loss 1.0772(1.0791) | Error 0.0000(0.0000) Steps 578(566.08) | Grad Norm 0.0692(0.0631) | Total Time 10.00(10.00)\n",
      "Iter 3406 | Time 42.2908(42.1041) | Bit/dim 1.0761(1.0790) | Xent 0.0000(0.0000) | Loss 1.0761(1.0790) | Error 0.0000(0.0000) Steps 560(565.90) | Grad Norm 0.0826(0.0637) | Total Time 10.00(10.00)\n",
      "Iter 3407 | Time 44.2434(42.1682) | Bit/dim 1.0786(1.0790) | Xent 0.0000(0.0000) | Loss 1.0786(1.0790) | Error 0.0000(0.0000) Steps 578(566.26) | Grad Norm 0.1366(0.0659) | Total Time 10.00(10.00)\n",
      "Iter 3408 | Time 41.2157(42.1397) | Bit/dim 1.0807(1.0791) | Xent 0.0000(0.0000) | Loss 1.0807(1.0791) | Error 0.0000(0.0000) Steps 560(566.07) | Grad Norm 0.1088(0.0672) | Total Time 10.00(10.00)\n",
      "Iter 3409 | Time 42.0883(42.1381) | Bit/dim 1.0796(1.0791) | Xent 0.0000(0.0000) | Loss 1.0796(1.0791) | Error 0.0000(0.0000) Steps 560(565.89) | Grad Norm 0.0848(0.0677) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 21.3519, Epoch Time 327.2037(326.2945), Bit/dim 1.0740(best: 1.0735), Xent 0.0000, Loss 1.0740, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3410 | Time 42.4783(42.1483) | Bit/dim 1.0795(1.0791) | Xent 0.0000(0.0000) | Loss 1.0795(1.0791) | Error 0.0000(0.0000) Steps 560(565.71) | Grad Norm 0.0641(0.0676) | Total Time 10.00(10.00)\n",
      "Iter 3411 | Time 42.3644(42.1548) | Bit/dim 1.0799(1.0791) | Xent 0.0000(0.0000) | Loss 1.0799(1.0791) | Error 0.0000(0.0000) Steps 560(565.54) | Grad Norm 0.1224(0.0692) | Total Time 10.00(10.00)\n",
      "Iter 3412 | Time 41.3179(42.1297) | Bit/dim 1.0793(1.0791) | Xent 0.0000(0.0000) | Loss 1.0793(1.0791) | Error 0.0000(0.0000) Steps 560(565.38) | Grad Norm 0.1116(0.0705) | Total Time 10.00(10.00)\n",
      "Iter 3413 | Time 41.4620(42.1097) | Bit/dim 1.0763(1.0791) | Xent 0.0000(0.0000) | Loss 1.0763(1.0791) | Error 0.0000(0.0000) Steps 578(565.76) | Grad Norm 0.1467(0.0728) | Total Time 10.00(10.00)\n",
      "Iter 3414 | Time 43.2773(42.1447) | Bit/dim 1.0800(1.0791) | Xent 0.0000(0.0000) | Loss 1.0800(1.0791) | Error 0.0000(0.0000) Steps 560(565.58) | Grad Norm 0.0675(0.0726) | Total Time 10.00(10.00)\n",
      "Iter 3415 | Time 42.3523(42.1509) | Bit/dim 1.0807(1.0791) | Xent 0.0000(0.0000) | Loss 1.0807(1.0791) | Error 0.0000(0.0000) Steps 578(565.96) | Grad Norm 0.0605(0.0723) | Total Time 10.00(10.00)\n",
      "Iter 3416 | Time 42.1308(42.1503) | Bit/dim 1.0801(1.0792) | Xent 0.0000(0.0000) | Loss 1.0801(1.0792) | Error 0.0000(0.0000) Steps 560(565.78) | Grad Norm 0.2284(0.0770) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 21.3501, Epoch Time 329.3408(326.3859), Bit/dim 1.0739(best: 1.0735), Xent 0.0000, Loss 1.0739, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3417 | Time 43.1799(42.1812) | Bit/dim 1.0805(1.0792) | Xent 0.0000(0.0000) | Loss 1.0805(1.0792) | Error 0.0000(0.0000) Steps 560(565.60) | Grad Norm 0.1286(0.0785) | Total Time 10.00(10.00)\n",
      "Iter 3418 | Time 42.1461(42.1802) | Bit/dim 1.0761(1.0791) | Xent 0.0000(0.0000) | Loss 1.0761(1.0791) | Error 0.0000(0.0000) Steps 560(565.44) | Grad Norm 0.0407(0.0774) | Total Time 10.00(10.00)\n",
      "Iter 3419 | Time 42.5660(42.1917) | Bit/dim 1.0793(1.0791) | Xent 0.0000(0.0000) | Loss 1.0793(1.0791) | Error 0.0000(0.0000) Steps 560(565.27) | Grad Norm 0.0929(0.0778) | Total Time 10.00(10.00)\n",
      "Iter 3420 | Time 41.5552(42.1726) | Bit/dim 1.0759(1.0790) | Xent 0.0000(0.0000) | Loss 1.0759(1.0790) | Error 0.0000(0.0000) Steps 578(565.65) | Grad Norm 0.1586(0.0803) | Total Time 10.00(10.00)\n",
      "Iter 3421 | Time 40.6743(42.1277) | Bit/dim 1.0816(1.0791) | Xent 0.0000(0.0000) | Loss 1.0816(1.0791) | Error 0.0000(0.0000) Steps 560(565.48) | Grad Norm 0.0728(0.0800) | Total Time 10.00(10.00)\n",
      "Iter 3422 | Time 42.5589(42.1406) | Bit/dim 1.0811(1.0792) | Xent 0.0000(0.0000) | Loss 1.0811(1.0792) | Error 0.0000(0.0000) Steps 578(565.86) | Grad Norm 0.0407(0.0789) | Total Time 10.00(10.00)\n",
      "Iter 3423 | Time 42.4492(42.1499) | Bit/dim 1.0752(1.0790) | Xent 0.0000(0.0000) | Loss 1.0752(1.0790) | Error 0.0000(0.0000) Steps 560(565.68) | Grad Norm 0.1204(0.0801) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0489 | Time 21.3463, Epoch Time 328.9153(326.4618), Bit/dim 1.0738(best: 1.0735), Xent 0.0000, Loss 1.0738, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3424 | Time 42.6145(42.1638) | Bit/dim 1.0802(1.0791) | Xent 0.0000(0.0000) | Loss 1.0802(1.0791) | Error 0.0000(0.0000) Steps 560(565.51) | Grad Norm 0.1211(0.0813) | Total Time 10.00(10.00)\n",
      "Iter 3425 | Time 41.5953(42.1468) | Bit/dim 1.0807(1.0791) | Xent 0.0000(0.0000) | Loss 1.0807(1.0791) | Error 0.0000(0.0000) Steps 560(565.35) | Grad Norm 0.0858(0.0815) | Total Time 10.00(10.00)\n",
      "Iter 3426 | Time 41.5452(42.1287) | Bit/dim 1.0803(1.0792) | Xent 0.0000(0.0000) | Loss 1.0803(1.0792) | Error 0.0000(0.0000) Steps 560(565.19) | Grad Norm 0.0809(0.0815) | Total Time 10.00(10.00)\n",
      "Iter 3427 | Time 40.4393(42.0780) | Bit/dim 1.0776(1.0791) | Xent 0.0000(0.0000) | Loss 1.0776(1.0791) | Error 0.0000(0.0000) Steps 560(565.03) | Grad Norm 0.0840(0.0815) | Total Time 10.00(10.00)\n",
      "Iter 3428 | Time 41.3460(42.0561) | Bit/dim 1.0800(1.0791) | Xent 0.0000(0.0000) | Loss 1.0800(1.0791) | Error 0.0000(0.0000) Steps 560(564.88) | Grad Norm 0.1307(0.0830) | Total Time 10.00(10.00)\n",
      "Iter 3429 | Time 42.3464(42.0648) | Bit/dim 1.0767(1.0791) | Xent 0.0000(0.0000) | Loss 1.0767(1.0791) | Error 0.0000(0.0000) Steps 578(565.27) | Grad Norm 0.0682(0.0826) | Total Time 10.00(10.00)\n",
      "Iter 3430 | Time 41.8247(42.0576) | Bit/dim 1.0759(1.0790) | Xent 0.0000(0.0000) | Loss 1.0759(1.0790) | Error 0.0000(0.0000) Steps 560(565.12) | Grad Norm 0.0445(0.0814) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0490 | Time 21.4075, Epoch Time 325.4980(326.4329), Bit/dim 1.0733(best: 1.0735), Xent 0.0000, Loss 1.0733, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3431 | Time 40.4254(42.0086) | Bit/dim 1.0755(1.0789) | Xent 0.0000(0.0000) | Loss 1.0755(1.0789) | Error 0.0000(0.0000) Steps 560(564.96) | Grad Norm 0.1282(0.0828) | Total Time 10.00(10.00)\n",
      "Iter 3432 | Time 41.8417(42.0036) | Bit/dim 1.0753(1.0788) | Xent 0.0000(0.0000) | Loss 1.0753(1.0788) | Error 0.0000(0.0000) Steps 578(565.35) | Grad Norm 0.1007(0.0834) | Total Time 10.00(10.00)\n",
      "Iter 3433 | Time 42.7010(42.0245) | Bit/dim 1.0839(1.0789) | Xent 0.0000(0.0000) | Loss 1.0839(1.0789) | Error 0.0000(0.0000) Steps 578(565.73) | Grad Norm 0.0640(0.0828) | Total Time 10.00(10.00)\n",
      "Iter 3434 | Time 41.8213(42.0184) | Bit/dim 1.0768(1.0788) | Xent 0.0000(0.0000) | Loss 1.0768(1.0788) | Error 0.0000(0.0000) Steps 560(565.56) | Grad Norm 0.0444(0.0816) | Total Time 10.00(10.00)\n",
      "Iter 3435 | Time 41.7927(42.0117) | Bit/dim 1.0822(1.0789) | Xent 0.0000(0.0000) | Loss 1.0822(1.0789) | Error 0.0000(0.0000) Steps 560(565.39) | Grad Norm 0.0560(0.0809) | Total Time 10.00(10.00)\n",
      "Iter 3436 | Time 41.6262(42.0001) | Bit/dim 1.0801(1.0790) | Xent 0.0000(0.0000) | Loss 1.0801(1.0790) | Error 0.0000(0.0000) Steps 560(565.23) | Grad Norm 0.0777(0.0808) | Total Time 10.00(10.00)\n",
      "Iter 3437 | Time 41.2935(41.9789) | Bit/dim 1.0771(1.0789) | Xent 0.0000(0.0000) | Loss 1.0771(1.0789) | Error 0.0000(0.0000) Steps 578(565.62) | Grad Norm 0.1227(0.0820) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0491 | Time 21.2866, Epoch Time 325.1335(326.3939), Bit/dim 1.0736(best: 1.0733), Xent 0.0000, Loss 1.0736, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3438 | Time 41.7822(41.9730) | Bit/dim 1.0744(1.0788) | Xent 0.0000(0.0000) | Loss 1.0744(1.0788) | Error 0.0000(0.0000) Steps 560(565.45) | Grad Norm 0.0583(0.0813) | Total Time 10.00(10.00)\n",
      "Iter 3439 | Time 41.8912(41.9705) | Bit/dim 1.0799(1.0788) | Xent 0.0000(0.0000) | Loss 1.0799(1.0788) | Error 0.0000(0.0000) Steps 560(565.28) | Grad Norm 0.0748(0.0811) | Total Time 10.00(10.00)\n",
      "Iter 3440 | Time 42.1210(41.9751) | Bit/dim 1.0808(1.0789) | Xent 0.0000(0.0000) | Loss 1.0808(1.0789) | Error 0.0000(0.0000) Steps 578(565.67) | Grad Norm 0.1230(0.0824) | Total Time 10.00(10.00)\n",
      "Iter 3441 | Time 41.8925(41.9726) | Bit/dim 1.0811(1.0790) | Xent 0.0000(0.0000) | Loss 1.0811(1.0790) | Error 0.0000(0.0000) Steps 560(565.50) | Grad Norm 0.0590(0.0817) | Total Time 10.00(10.00)\n",
      "Iter 3442 | Time 42.9065(42.0006) | Bit/dim 1.0788(1.0789) | Xent 0.0000(0.0000) | Loss 1.0788(1.0789) | Error 0.0000(0.0000) Steps 560(565.33) | Grad Norm 0.0426(0.0805) | Total Time 10.00(10.00)\n",
      "Iter 3443 | Time 43.2595(42.0384) | Bit/dim 1.0783(1.0789) | Xent 0.0000(0.0000) | Loss 1.0783(1.0789) | Error 0.0000(0.0000) Steps 578(565.71) | Grad Norm 0.0628(0.0800) | Total Time 10.00(10.00)\n",
      "Iter 3444 | Time 41.6245(42.0260) | Bit/dim 1.0823(1.0790) | Xent 0.0000(0.0000) | Loss 1.0823(1.0790) | Error 0.0000(0.0000) Steps 578(566.08) | Grad Norm 0.0720(0.0797) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0492 | Time 21.3197, Epoch Time 329.1755(326.4773), Bit/dim 1.0736(best: 1.0733), Xent 0.0000, Loss 1.0736, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3445 | Time 42.9195(42.0528) | Bit/dim 1.0789(1.0790) | Xent 0.0000(0.0000) | Loss 1.0789(1.0790) | Error 0.0000(0.0000) Steps 560(565.90) | Grad Norm 0.0490(0.0788) | Total Time 10.00(10.00)\n",
      "Iter 3446 | Time 40.8314(42.0161) | Bit/dim 1.0788(1.0790) | Xent 0.0000(0.0000) | Loss 1.0788(1.0790) | Error 0.0000(0.0000) Steps 578(566.26) | Grad Norm 0.0420(0.0777) | Total Time 10.00(10.00)\n",
      "Iter 3447 | Time 41.3148(41.9951) | Bit/dim 1.0754(1.0789) | Xent 0.0000(0.0000) | Loss 1.0754(1.0789) | Error 0.0000(0.0000) Steps 560(566.07) | Grad Norm 0.0406(0.0766) | Total Time 10.00(10.00)\n",
      "Iter 3448 | Time 40.9511(41.9638) | Bit/dim 1.0768(1.0788) | Xent 0.0000(0.0000) | Loss 1.0768(1.0788) | Error 0.0000(0.0000) Steps 578(566.43) | Grad Norm 0.0484(0.0757) | Total Time 10.00(10.00)\n",
      "Iter 3449 | Time 42.5646(41.9818) | Bit/dim 1.0848(1.0790) | Xent 0.0000(0.0000) | Loss 1.0848(1.0790) | Error 0.0000(0.0000) Steps 560(566.24) | Grad Norm 0.0743(0.0757) | Total Time 10.00(10.00)\n",
      "Iter 3450 | Time 41.3200(41.9619) | Bit/dim 1.0791(1.0790) | Xent 0.0000(0.0000) | Loss 1.0791(1.0790) | Error 0.0000(0.0000) Steps 560(566.05) | Grad Norm 0.0576(0.0752) | Total Time 10.00(10.00)\n",
      "Iter 3451 | Time 43.1463(41.9975) | Bit/dim 1.0796(1.0790) | Xent 0.0000(0.0000) | Loss 1.0796(1.0790) | Error 0.0000(0.0000) Steps 560(565.87) | Grad Norm 0.1039(0.0760) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0493 | Time 21.4958, Epoch Time 326.8164(326.4875), Bit/dim 1.0737(best: 1.0733), Xent 0.0000, Loss 1.0737, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3452 | Time 41.9718(41.9967) | Bit/dim 1.0799(1.0791) | Xent 0.0000(0.0000) | Loss 1.0799(1.0791) | Error 0.0000(0.0000) Steps 560(565.69) | Grad Norm 0.0483(0.0752) | Total Time 10.00(10.00)\n",
      "Iter 3453 | Time 42.7708(42.0199) | Bit/dim 1.0759(1.0790) | Xent 0.0000(0.0000) | Loss 1.0759(1.0790) | Error 0.0000(0.0000) Steps 560(565.52) | Grad Norm 0.0493(0.0744) | Total Time 10.00(10.00)\n",
      "Iter 3454 | Time 42.1485(42.0238) | Bit/dim 1.0814(1.0790) | Xent 0.0000(0.0000) | Loss 1.0814(1.0790) | Error 0.0000(0.0000) Steps 560(565.36) | Grad Norm 0.0415(0.0734) | Total Time 10.00(10.00)\n",
      "Iter 3455 | Time 40.9146(41.9905) | Bit/dim 1.0750(1.0789) | Xent 0.0000(0.0000) | Loss 1.0750(1.0789) | Error 0.0000(0.0000) Steps 578(565.74) | Grad Norm 0.0391(0.0724) | Total Time 10.00(10.00)\n",
      "Iter 3456 | Time 42.1356(41.9948) | Bit/dim 1.0816(1.0790) | Xent 0.0000(0.0000) | Loss 1.0816(1.0790) | Error 0.0000(0.0000) Steps 560(565.56) | Grad Norm 0.0979(0.0732) | Total Time 10.00(10.00)\n",
      "Iter 3457 | Time 40.6065(41.9532) | Bit/dim 1.0764(1.0789) | Xent 0.0000(0.0000) | Loss 1.0764(1.0789) | Error 0.0000(0.0000) Steps 578(565.94) | Grad Norm 0.0734(0.0732) | Total Time 10.00(10.00)\n",
      "Iter 3458 | Time 41.8944(41.9514) | Bit/dim 1.0787(1.0789) | Xent 0.0000(0.0000) | Loss 1.0787(1.0789) | Error 0.0000(0.0000) Steps 560(565.76) | Grad Norm 0.0467(0.0724) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0494 | Time 21.4849, Epoch Time 326.4440(326.4862), Bit/dim 1.0741(best: 1.0733), Xent 0.0000, Loss 1.0741, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3459 | Time 41.0874(41.9255) | Bit/dim 1.0801(1.0790) | Xent 0.0000(0.0000) | Loss 1.0801(1.0790) | Error 0.0000(0.0000) Steps 560(565.59) | Grad Norm 0.0533(0.0718) | Total Time 10.00(10.00)\n",
      "Iter 3460 | Time 41.5751(41.9150) | Bit/dim 1.0815(1.0790) | Xent 0.0000(0.0000) | Loss 1.0815(1.0790) | Error 0.0000(0.0000) Steps 578(565.96) | Grad Norm 0.1119(0.0730) | Total Time 10.00(10.00)\n",
      "Iter 3461 | Time 41.6999(41.9085) | Bit/dim 1.0787(1.0790) | Xent 0.0000(0.0000) | Loss 1.0787(1.0790) | Error 0.0000(0.0000) Steps 560(565.78) | Grad Norm 0.0908(0.0735) | Total Time 10.00(10.00)\n",
      "Iter 3462 | Time 41.9671(41.9103) | Bit/dim 1.0839(1.0792) | Xent 0.0000(0.0000) | Loss 1.0839(1.0792) | Error 0.0000(0.0000) Steps 560(565.61) | Grad Norm 0.0527(0.0729) | Total Time 10.00(10.00)\n",
      "Iter 3463 | Time 40.4882(41.8676) | Bit/dim 1.0775(1.0791) | Xent 0.0000(0.0000) | Loss 1.0775(1.0791) | Error 0.0000(0.0000) Steps 560(565.44) | Grad Norm 0.1059(0.0739) | Total Time 10.00(10.00)\n",
      "Iter 3464 | Time 42.4656(41.8856) | Bit/dim 1.0762(1.0790) | Xent 0.0000(0.0000) | Loss 1.0762(1.0790) | Error 0.0000(0.0000) Steps 560(565.27) | Grad Norm 0.1475(0.0761) | Total Time 10.00(10.00)\n",
      "Iter 3465 | Time 42.4066(41.9012) | Bit/dim 1.0785(1.0790) | Xent 0.0000(0.0000) | Loss 1.0785(1.0790) | Error 0.0000(0.0000) Steps 560(565.12) | Grad Norm 0.0462(0.0752) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0495 | Time 21.4071, Epoch Time 325.5567(326.4583), Bit/dim 1.0738(best: 1.0733), Xent 0.0000, Loss 1.0738, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3466 | Time 40.9387(41.8723) | Bit/dim 1.0801(1.0790) | Xent 0.0000(0.0000) | Loss 1.0801(1.0790) | Error 0.0000(0.0000) Steps 560(564.96) | Grad Norm 0.0448(0.0743) | Total Time 10.00(10.00)\n",
      "Iter 3467 | Time 42.9615(41.9050) | Bit/dim 1.0794(1.0791) | Xent 0.0000(0.0000) | Loss 1.0794(1.0791) | Error 0.0000(0.0000) Steps 578(565.35) | Grad Norm 0.1079(0.0753) | Total Time 10.00(10.00)\n",
      "Iter 3468 | Time 42.3078(41.9171) | Bit/dim 1.0782(1.0790) | Xent 0.0000(0.0000) | Loss 1.0782(1.0790) | Error 0.0000(0.0000) Steps 560(565.19) | Grad Norm 0.0828(0.0755) | Total Time 10.00(10.00)\n",
      "Iter 3469 | Time 40.9359(41.8877) | Bit/dim 1.0778(1.0790) | Xent 0.0000(0.0000) | Loss 1.0778(1.0790) | Error 0.0000(0.0000) Steps 560(565.04) | Grad Norm 0.0367(0.0744) | Total Time 10.00(10.00)\n",
      "Iter 3470 | Time 40.8451(41.8564) | Bit/dim 1.0822(1.0791) | Xent 0.0000(0.0000) | Loss 1.0822(1.0791) | Error 0.0000(0.0000) Steps 560(564.89) | Grad Norm 0.0668(0.0741) | Total Time 10.00(10.00)\n",
      "Iter 3471 | Time 42.4326(41.8737) | Bit/dim 1.0781(1.0791) | Xent 0.0000(0.0000) | Loss 1.0781(1.0791) | Error 0.0000(0.0000) Steps 578(565.28) | Grad Norm 0.0628(0.0738) | Total Time 10.00(10.00)\n",
      "Iter 3472 | Time 41.9536(41.8761) | Bit/dim 1.0764(1.0790) | Xent 0.0000(0.0000) | Loss 1.0764(1.0790) | Error 0.0000(0.0000) Steps 560(565.12) | Grad Norm 0.0389(0.0728) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0496 | Time 21.3590, Epoch Time 326.0379(326.4457), Bit/dim 1.0736(best: 1.0733), Xent 0.0000, Loss 1.0736, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3473 | Time 42.6136(41.8982) | Bit/dim 1.0761(1.0789) | Xent 0.0000(0.0000) | Loss 1.0761(1.0789) | Error 0.0000(0.0000) Steps 578(565.51) | Grad Norm 0.0432(0.0719) | Total Time 10.00(10.00)\n",
      "Iter 3474 | Time 42.8321(41.9262) | Bit/dim 1.0785(1.0789) | Xent 0.0000(0.0000) | Loss 1.0785(1.0789) | Error 0.0000(0.0000) Steps 560(565.34) | Grad Norm 0.0492(0.0712) | Total Time 10.00(10.00)\n",
      "Iter 3475 | Time 41.5195(41.9140) | Bit/dim 1.0805(1.0789) | Xent 0.0000(0.0000) | Loss 1.0805(1.0789) | Error 0.0000(0.0000) Steps 560(565.18) | Grad Norm 0.0420(0.0703) | Total Time 10.00(10.00)\n",
      "Iter 3476 | Time 42.2198(41.9232) | Bit/dim 1.0838(1.0791) | Xent 0.0000(0.0000) | Loss 1.0838(1.0791) | Error 0.0000(0.0000) Steps 578(565.57) | Grad Norm 0.0733(0.0704) | Total Time 10.00(10.00)\n",
      "Iter 3477 | Time 42.0697(41.9276) | Bit/dim 1.0726(1.0789) | Xent 0.0000(0.0000) | Loss 1.0726(1.0789) | Error 0.0000(0.0000) Steps 578(565.94) | Grad Norm 0.0512(0.0698) | Total Time 10.00(10.00)\n",
      "Iter 3478 | Time 43.3859(41.9713) | Bit/dim 1.0791(1.0789) | Xent 0.0000(0.0000) | Loss 1.0791(1.0789) | Error 0.0000(0.0000) Steps 560(565.76) | Grad Norm 0.0626(0.0696) | Total Time 10.00(10.00)\n",
      "Iter 3479 | Time 42.9201(41.9998) | Bit/dim 1.0810(1.0790) | Xent 0.0000(0.0000) | Loss 1.0810(1.0790) | Error 0.0000(0.0000) Steps 578(566.13) | Grad Norm 0.1067(0.0707) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0497 | Time 21.0362, Epoch Time 331.1317(326.5863), Bit/dim 1.0737(best: 1.0733), Xent 0.0000, Loss 1.0737, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3480 | Time 42.6998(42.0208) | Bit/dim 1.0805(1.0790) | Xent 0.0000(0.0000) | Loss 1.0805(1.0790) | Error 0.0000(0.0000) Steps 560(565.94) | Grad Norm 0.0575(0.0703) | Total Time 10.00(10.00)\n",
      "Iter 3481 | Time 42.0352(42.0212) | Bit/dim 1.0780(1.0790) | Xent 0.0000(0.0000) | Loss 1.0780(1.0790) | Error 0.0000(0.0000) Steps 560(565.77) | Grad Norm 0.0418(0.0695) | Total Time 10.00(10.00)\n",
      "Iter 3482 | Time 41.2228(41.9973) | Bit/dim 1.0803(1.0790) | Xent 0.0000(0.0000) | Loss 1.0803(1.0790) | Error 0.0000(0.0000) Steps 560(565.59) | Grad Norm 0.0664(0.0694) | Total Time 10.00(10.00)\n",
      "Iter 3483 | Time 40.8806(41.9638) | Bit/dim 1.0770(1.0790) | Xent 0.0000(0.0000) | Loss 1.0770(1.0790) | Error 0.0000(0.0000) Steps 578(565.97) | Grad Norm 0.0374(0.0684) | Total Time 10.00(10.00)\n",
      "Iter 3484 | Time 41.8076(41.9591) | Bit/dim 1.0764(1.0789) | Xent 0.0000(0.0000) | Loss 1.0764(1.0789) | Error 0.0000(0.0000) Steps 578(566.33) | Grad Norm 0.0542(0.0680) | Total Time 10.00(10.00)\n",
      "Iter 3485 | Time 40.8399(41.9255) | Bit/dim 1.0807(1.0789) | Xent 0.0000(0.0000) | Loss 1.0807(1.0789) | Error 0.0000(0.0000) Steps 560(566.14) | Grad Norm 0.0612(0.0678) | Total Time 10.00(10.00)\n",
      "Iter 3486 | Time 41.8994(41.9247) | Bit/dim 1.0783(1.0789) | Xent 0.0000(0.0000) | Loss 1.0783(1.0789) | Error 0.0000(0.0000) Steps 560(565.95) | Grad Norm 0.0411(0.0670) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0498 | Time 21.1530, Epoch Time 325.1181(326.5422), Bit/dim 1.0741(best: 1.0733), Xent 0.0000, Loss 1.0741, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3487 | Time 41.0641(41.8989) | Bit/dim 1.0766(1.0788) | Xent 0.0000(0.0000) | Loss 1.0766(1.0788) | Error 0.0000(0.0000) Steps 560(565.77) | Grad Norm 0.0489(0.0664) | Total Time 10.00(10.00)\n",
      "Iter 3488 | Time 41.9894(41.9016) | Bit/dim 1.0811(1.0789) | Xent 0.0000(0.0000) | Loss 1.0811(1.0789) | Error 0.0000(0.0000) Steps 578(566.14) | Grad Norm 0.0833(0.0669) | Total Time 10.00(10.00)\n",
      "Iter 3489 | Time 42.3207(41.9142) | Bit/dim 1.0787(1.0789) | Xent 0.0000(0.0000) | Loss 1.0787(1.0789) | Error 0.0000(0.0000) Steps 578(566.50) | Grad Norm 0.0965(0.0678) | Total Time 10.00(10.00)\n",
      "Iter 3490 | Time 41.7138(41.9082) | Bit/dim 1.0827(1.0790) | Xent 0.0000(0.0000) | Loss 1.0827(1.0790) | Error 0.0000(0.0000) Steps 560(566.30) | Grad Norm 0.0719(0.0680) | Total Time 10.00(10.00)\n",
      "Iter 3491 | Time 41.2415(41.8882) | Bit/dim 1.0746(1.0789) | Xent 0.0000(0.0000) | Loss 1.0746(1.0789) | Error 0.0000(0.0000) Steps 560(566.11) | Grad Norm 0.0591(0.0677) | Total Time 10.00(10.00)\n",
      "Iter 3492 | Time 41.4475(41.8750) | Bit/dim 1.0764(1.0788) | Xent 0.0000(0.0000) | Loss 1.0764(1.0788) | Error 0.0000(0.0000) Steps 578(566.47) | Grad Norm 0.0912(0.0684) | Total Time 10.00(10.00)\n",
      "Iter 3493 | Time 41.0280(41.8496) | Bit/dim 1.0812(1.0789) | Xent 0.0000(0.0000) | Loss 1.0812(1.0789) | Error 0.0000(0.0000) Steps 560(566.28) | Grad Norm 0.0876(0.0690) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0499 | Time 21.3883, Epoch Time 324.7866(326.4896), Bit/dim 1.0737(best: 1.0733), Xent 0.0000, Loss 1.0737, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3494 | Time 41.3491(41.8345) | Bit/dim 1.0800(1.0789) | Xent 0.0000(0.0000) | Loss 1.0800(1.0789) | Error 0.0000(0.0000) Steps 578(566.63) | Grad Norm 0.0473(0.0683) | Total Time 10.00(10.00)\n",
      "Iter 3495 | Time 40.8750(41.8057) | Bit/dim 1.0779(1.0789) | Xent 0.0000(0.0000) | Loss 1.0779(1.0789) | Error 0.0000(0.0000) Steps 578(566.97) | Grad Norm 0.1175(0.0698) | Total Time 10.00(10.00)\n",
      "Iter 3496 | Time 43.0905(41.8443) | Bit/dim 1.0786(1.0789) | Xent 0.0000(0.0000) | Loss 1.0786(1.0789) | Error 0.0000(0.0000) Steps 560(566.76) | Grad Norm 0.1345(0.0717) | Total Time 10.00(10.00)\n",
      "Iter 3497 | Time 41.3988(41.8309) | Bit/dim 1.0814(1.0790) | Xent 0.0000(0.0000) | Loss 1.0814(1.0790) | Error 0.0000(0.0000) Steps 560(566.56) | Grad Norm 0.0485(0.0710) | Total Time 10.00(10.00)\n",
      "Iter 3498 | Time 39.6469(41.7654) | Bit/dim 1.0752(1.0788) | Xent 0.0000(0.0000) | Loss 1.0752(1.0788) | Error 0.0000(0.0000) Steps 560(566.36) | Grad Norm 0.0588(0.0707) | Total Time 10.00(10.00)\n",
      "Iter 3499 | Time 42.6164(41.7909) | Bit/dim 1.0786(1.0788) | Xent 0.0000(0.0000) | Loss 1.0786(1.0788) | Error 0.0000(0.0000) Steps 578(566.71) | Grad Norm 0.1512(0.0731) | Total Time 10.00(10.00)\n",
      "Iter 3500 | Time 40.0303(41.7381) | Bit/dim 1.0770(1.0788) | Xent 0.0000(0.0000) | Loss 1.0770(1.0788) | Error 0.0000(0.0000) Steps 560(566.51) | Grad Norm 0.0694(0.0730) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0500 | Time 21.1676, Epoch Time 322.5850(326.3724), Bit/dim 1.0735(best: 1.0733), Xent 0.0000, Loss 1.0735, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3501 | Time 42.4877(41.7606) | Bit/dim 1.0768(1.0787) | Xent 0.0000(0.0000) | Loss 1.0768(1.0787) | Error 0.0000(0.0000) Steps 560(566.31) | Grad Norm 0.0485(0.0722) | Total Time 10.00(10.00)\n",
      "Iter 3502 | Time 41.9935(41.7676) | Bit/dim 1.0811(1.0788) | Xent 0.0000(0.0000) | Loss 1.0811(1.0788) | Error 0.0000(0.0000) Steps 578(566.66) | Grad Norm 0.0731(0.0723) | Total Time 10.00(10.00)\n",
      "Iter 3503 | Time 42.0651(41.7765) | Bit/dim 1.0840(1.0789) | Xent 0.0000(0.0000) | Loss 1.0840(1.0789) | Error 0.0000(0.0000) Steps 560(566.46) | Grad Norm 0.0427(0.0714) | Total Time 10.00(10.00)\n",
      "Iter 3504 | Time 41.6228(41.7719) | Bit/dim 1.0765(1.0789) | Xent 0.0000(0.0000) | Loss 1.0765(1.0789) | Error 0.0000(0.0000) Steps 560(566.27) | Grad Norm 0.0613(0.0711) | Total Time 10.00(10.00)\n",
      "Iter 3505 | Time 40.9962(41.7486) | Bit/dim 1.0788(1.0789) | Xent 0.0000(0.0000) | Loss 1.0788(1.0789) | Error 0.0000(0.0000) Steps 560(566.08) | Grad Norm 0.0550(0.0706) | Total Time 10.00(10.00)\n",
      "Iter 3506 | Time 42.4338(41.7692) | Bit/dim 1.0738(1.0787) | Xent 0.0000(0.0000) | Loss 1.0738(1.0787) | Error 0.0000(0.0000) Steps 560(565.90) | Grad Norm 0.0856(0.0711) | Total Time 10.00(10.00)\n",
      "Iter 3507 | Time 41.1708(41.7512) | Bit/dim 1.0792(1.0787) | Xent 0.0000(0.0000) | Loss 1.0792(1.0787) | Error 0.0000(0.0000) Steps 560(565.72) | Grad Norm 0.0426(0.0702) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0501 | Time 21.1985, Epoch Time 326.4446(326.3746), Bit/dim 1.0738(best: 1.0733), Xent 0.0000, Loss 1.0738, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3508 | Time 41.9042(41.7558) | Bit/dim 1.0801(1.0788) | Xent 0.0000(0.0000) | Loss 1.0801(1.0788) | Error 0.0000(0.0000) Steps 560(565.55) | Grad Norm 0.0523(0.0697) | Total Time 10.00(10.00)\n",
      "Iter 3509 | Time 42.7438(41.7855) | Bit/dim 1.0788(1.0788) | Xent 0.0000(0.0000) | Loss 1.0788(1.0788) | Error 0.0000(0.0000) Steps 578(565.92) | Grad Norm 0.0492(0.0690) | Total Time 10.00(10.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf.py --data mnist --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_published_bs8K_2 --resume ../experiments_published/cnf_published_bs8K_2/epoch_400_checkpt.pth --seed 2 --conditional False --controlled_tol False --lr 0.0001 --warmup_iters 113 --atol 1e-5  --rtol 1e-5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
