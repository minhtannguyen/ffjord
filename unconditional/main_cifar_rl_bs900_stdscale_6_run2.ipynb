{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import torch.utils.data as data\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "plt.rcParams['figure.dpi'] = 300\n",
      "\n",
      "from PIL import Image\n",
      "import os.path\n",
      "import errno\n",
      "import codecs\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"colormnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--y_class\", type=int, default=10)\n",
      "parser.add_argument(\"--y_color\", type=int, default=10)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "class ColorMNIST(data.Dataset):\n",
      "    \"\"\"\n",
      "    ColorMNIST\n",
      "    \"\"\"\n",
      "    urls = [\n",
      "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
      "    ]\n",
      "    raw_folder = 'raw'\n",
      "    processed_folder = 'processed'\n",
      "    training_file = 'training.pt'\n",
      "    test_file = 'test.pt'\n",
      "\n",
      "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
      "        self.root = os.path.expanduser(root)\n",
      "        self.transform = transform\n",
      "        self.target_transform = target_transform\n",
      "        self.train = train  # training set or test set\n",
      "\n",
      "        if download:\n",
      "            self.download()\n",
      "\n",
      "        if not self._check_exists():\n",
      "            raise RuntimeError('Dataset not found.' +\n",
      "                               ' You can use download=True to download it')\n",
      "\n",
      "        if self.train:\n",
      "            self.train_data, self.train_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
      "            \n",
      "            self.train_data = np.tile(self.train_data[:, :, :, np.newaxis], 3)\n",
      "        else:\n",
      "            self.test_data, self.test_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "            \n",
      "            self.test_data = np.tile(self.test_data[:, :, :, np.newaxis], 3)\n",
      "        \n",
      "        self.pallette = [[31, 119, 180],\n",
      "                         [255, 127, 14],\n",
      "                         [44, 160, 44],\n",
      "                         [214, 39, 40],\n",
      "                         [148, 103, 189],\n",
      "                         [140, 86, 75],\n",
      "                         [227, 119, 194],\n",
      "                         [127, 127, 127],\n",
      "                         [188, 189, 34],\n",
      "                         [23, 190, 207]]\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            index (int): Index\n",
      "\n",
      "        Returns:\n",
      "            tuple: (image, target) where target is index of the target class.\n",
      "        \"\"\"\n",
      "        if self.train:\n",
      "            img, target = self.train_data[index].copy(), self.train_labels[index]\n",
      "        else:\n",
      "            img, target = self.test_data[index].copy(), self.test_labels[index]\n",
      "        \n",
      "        # doing this so that it is consistent with all other datasets\n",
      "        # to return a PIL Image\n",
      "        y_color_digit = np.random.randint(0, args.y_color)\n",
      "        c_digit = self.pallette[y_color_digit]\n",
      "        \n",
      "        img[:, :, 0] = img[:, :, 0] / 255 * c_digit[0]\n",
      "        img[:, :, 1] = img[:, :, 1] / 255 * c_digit[1]\n",
      "        img[:, :, 2] = img[:, :, 2] / 255 * c_digit[2]\n",
      "        \n",
      "        img = Image.fromarray(img)\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "\n",
      "        return img, [target,torch.from_numpy(np.array(y_color_digit))]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.train:\n",
      "            return len(self.train_data)\n",
      "        else:\n",
      "            return len(self.test_data)\n",
      "\n",
      "    def _check_exists(self):\n",
      "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
      "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "\n",
      "    def download(self):\n",
      "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
      "        from six.moves import urllib\n",
      "        import gzip\n",
      "\n",
      "        if self._check_exists():\n",
      "            return\n",
      "\n",
      "        # download files\n",
      "        try:\n",
      "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
      "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
      "        except OSError as e:\n",
      "            if e.errno == errno.EEXIST:\n",
      "                pass\n",
      "            else:\n",
      "                raise\n",
      "\n",
      "        for url in self.urls:\n",
      "            print('Downloading ' + url)\n",
      "            data = urllib.request.urlopen(url)\n",
      "            filename = url.rpartition('/')[2]\n",
      "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
      "            with open(file_path, 'wb') as f:\n",
      "                f.write(data.read())\n",
      "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
      "                    gzip.GzipFile(file_path) as zip_f:\n",
      "                out_f.write(zip_f.read())\n",
      "            os.unlink(file_path)\n",
      "\n",
      "        # process and save as torch files\n",
      "        print('Processing...')\n",
      "\n",
      "        training_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
      "        )\n",
      "        test_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
      "        )\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
      "            torch.save(training_set, f)\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
      "            torch.save(test_set, f)\n",
      "\n",
      "        print('Done!')\n",
      "\n",
      "    def __repr__(self):\n",
      "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
      "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
      "        tmp = 'train' if self.train is True else 'test'\n",
      "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
      "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
      "        tmp = '    Transforms (if any): '\n",
      "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        tmp = '    Target Transforms (if any): '\n",
      "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        return fmt_str\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"colormnist\":\n",
      "        im_dim = 3\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = ColorMNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = ColorMNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,\n",
      "            y_class = args.y_class)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            if args.data == \"colormnist\":\n",
      "                y = y[0]\n",
      "            \n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        if args.data == \"colormnist\":\n",
      "            # print train images\n",
      "            xall = []\n",
      "            ximg = x[0:40].cpu().numpy().transpose((0,2,3,1))\n",
      "            for i in range(ximg.shape[0]):\n",
      "                xall.append(ximg[i])\n",
      "        \n",
      "            xall = np.hstack(xall)\n",
      "\n",
      "            plt.imshow(xall)\n",
      "            plt.axis('off')\n",
      "            plt.show()\n",
      "            \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if args.data == \"colormnist\":\n",
      "                        y = y[0]\n",
      "                        \n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                if args.data == \"colormnist\":\n",
      "                    # print test images\n",
      "                    xall = []\n",
      "                    ximg = x[0:40].cpu().numpy().transpose((0,2,3,1))\n",
      "                    for i in range(ximg.shape[0]):\n",
      "                        xall.append(ximg[i])\n",
      "\n",
      "                    xall = np.hstack(xall)\n",
      "\n",
      "                    plt.imshow(xall)\n",
      "                    plt.axis('off')\n",
      "                    plt.show()\n",
      "                    \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=False, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=False, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.0, eta=0.1, gamma=0.99, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_cifar10_bs900_rl_stdscale_6_run2/epoch_250_checkpt.pth', rl_weight=0.01, rtol=1e-05, save='../experiments_published/cnf_cifar10_bs900_rl_stdscale_6_run2', scale=1.0, scale_fac=1.0, scale_std=6.0, seed=2, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5, y_class=10, y_color=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1450732\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 13760 | Time 23.4400(23.0856) | Bit/dim 3.3640(3.3729) | Xent 0.0000(0.0000) | Loss 8.6574(9.7329) | Error 0.0000(0.0000) Steps 886(913.34) | Grad Norm 4.2497(4.5819) | Total Time 0.00(0.00)\n",
      "Iter 13770 | Time 23.7339(23.1349) | Bit/dim 3.3259(3.3734) | Xent 0.0000(0.0000) | Loss 8.5849(9.4868) | Error 0.0000(0.0000) Steps 904(914.56) | Grad Norm 2.9095(4.0839) | Total Time 0.00(0.00)\n",
      "Iter 13780 | Time 23.3364(23.3197) | Bit/dim 3.3797(3.3706) | Xent 0.0000(0.0000) | Loss 8.6349(9.3020) | Error 0.0000(0.0000) Steps 928(915.79) | Grad Norm 1.8420(3.4686) | Total Time 0.00(0.00)\n",
      "Iter 13790 | Time 23.0751(23.4380) | Bit/dim 3.3636(3.3695) | Xent 0.0000(0.0000) | Loss 8.6837(9.1662) | Error 0.0000(0.0000) Steps 910(919.92) | Grad Norm 1.0226(2.8634) | Total Time 0.00(0.00)\n",
      "Iter 13800 | Time 24.7077(23.5085) | Bit/dim 3.3741(3.3693) | Xent 0.0000(0.0000) | Loss 8.7585(9.0702) | Error 0.0000(0.0000) Steps 880(923.04) | Grad Norm 0.4704(2.3095) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 114.6757, Epoch Time 1455.1349(1282.1429), Bit/dim 3.3743(best: inf), Xent 0.0000, Loss 3.3743, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13810 | Time 23.3885(23.5918) | Bit/dim 3.3602(3.3671) | Xent 0.0000(0.0000) | Loss 8.7293(9.9134) | Error 0.0000(0.0000) Steps 910(924.51) | Grad Norm 0.3851(1.8517) | Total Time 0.00(0.00)\n",
      "Iter 13820 | Time 24.0108(23.5054) | Bit/dim 3.3361(3.3652) | Xent 0.0000(0.0000) | Loss 8.6935(9.6248) | Error 0.0000(0.0000) Steps 880(925.99) | Grad Norm 0.6270(1.5180) | Total Time 0.00(0.00)\n",
      "Iter 13830 | Time 24.0739(23.5037) | Bit/dim 3.4283(3.3645) | Xent 0.0000(0.0000) | Loss 8.8517(9.4098) | Error 0.0000(0.0000) Steps 910(924.18) | Grad Norm 0.6776(1.2566) | Total Time 0.00(0.00)\n",
      "Iter 13840 | Time 25.2252(23.5852) | Bit/dim 3.4000(3.3688) | Xent 0.0000(0.0000) | Loss 8.9168(9.2441) | Error 0.0000(0.0000) Steps 940(923.49) | Grad Norm 0.4405(1.0525) | Total Time 0.00(0.00)\n",
      "Iter 13850 | Time 23.9382(23.7021) | Bit/dim 3.3738(3.3682) | Xent 0.0000(0.0000) | Loss 8.9683(9.1434) | Error 0.0000(0.0000) Steps 940(922.03) | Grad Norm 0.4930(0.9047) | Total Time 0.00(0.00)\n",
      "Iter 13860 | Time 22.3780(23.7282) | Bit/dim 3.3680(3.3664) | Xent 0.0000(0.0000) | Loss 8.5908(9.0392) | Error 0.0000(0.0000) Steps 892(917.96) | Grad Norm 0.4860(0.7876) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 114.1184, Epoch Time 1436.8160(1286.7831), Bit/dim 3.3689(best: 3.3743), Xent 0.0000, Loss 3.3689, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13870 | Time 22.1842(23.6817) | Bit/dim 3.3687(3.3646) | Xent 0.0000(0.0000) | Loss 8.8168(9.7942) | Error 0.0000(0.0000) Steps 928(921.25) | Grad Norm 0.5759(0.7116) | Total Time 0.00(0.00)\n",
      "Iter 13880 | Time 23.1399(23.5948) | Bit/dim 3.3419(3.3660) | Xent 0.0000(0.0000) | Loss 8.7665(9.5385) | Error 0.0000(0.0000) Steps 904(918.34) | Grad Norm 0.4786(0.6457) | Total Time 0.00(0.00)\n",
      "Iter 13890 | Time 24.4438(23.7260) | Bit/dim 3.3715(3.3666) | Xent 0.0000(0.0000) | Loss 8.8591(9.3575) | Error 0.0000(0.0000) Steps 904(919.60) | Grad Norm 0.4549(0.5951) | Total Time 0.00(0.00)\n",
      "Iter 13900 | Time 23.1333(23.6595) | Bit/dim 3.3580(3.3639) | Xent 0.0000(0.0000) | Loss 8.9488(9.2090) | Error 0.0000(0.0000) Steps 898(916.53) | Grad Norm 0.4520(0.5590) | Total Time 0.00(0.00)\n",
      "Iter 13910 | Time 23.1315(23.6219) | Bit/dim 3.3944(3.3630) | Xent 0.0000(0.0000) | Loss 8.8959(9.1051) | Error 0.0000(0.0000) Steps 928(916.84) | Grad Norm 0.4370(0.5404) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 112.8886, Epoch Time 1428.7408(1291.0418), Bit/dim 3.3697(best: 3.3689), Xent 0.0000, Loss 3.3697, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13920 | Time 24.0123(23.5570) | Bit/dim 3.3586(3.3646) | Xent 0.0000(0.0000) | Loss 8.8202(9.9756) | Error 0.0000(0.0000) Steps 940(914.03) | Grad Norm 0.4574(0.5291) | Total Time 0.00(0.00)\n",
      "Iter 13930 | Time 23.7003(23.5525) | Bit/dim 3.3402(3.3642) | Xent 0.0000(0.0000) | Loss 8.8511(9.6721) | Error 0.0000(0.0000) Steps 922(912.93) | Grad Norm 0.6106(0.5108) | Total Time 0.00(0.00)\n",
      "Iter 13940 | Time 24.0076(23.6083) | Bit/dim 3.3894(3.3662) | Xent 0.0000(0.0000) | Loss 8.9360(9.4498) | Error 0.0000(0.0000) Steps 910(917.58) | Grad Norm 0.4576(0.5149) | Total Time 0.00(0.00)\n",
      "Iter 13950 | Time 23.7408(23.7316) | Bit/dim 3.3760(3.3668) | Xent 0.0000(0.0000) | Loss 8.8295(9.2901) | Error 0.0000(0.0000) Steps 940(919.66) | Grad Norm 0.5380(0.5147) | Total Time 0.00(0.00)\n",
      "Iter 13960 | Time 22.9505(23.7509) | Bit/dim 3.3179(3.3662) | Xent 0.0000(0.0000) | Loss 8.6936(9.1528) | Error 0.0000(0.0000) Steps 922(917.93) | Grad Norm 0.4127(0.5061) | Total Time 0.00(0.00)\n",
      "Iter 13970 | Time 23.5809(23.7409) | Bit/dim 3.3613(3.3664) | Xent 0.0000(0.0000) | Loss 8.7462(9.0567) | Error 0.0000(0.0000) Steps 934(918.84) | Grad Norm 0.5449(0.4911) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 113.4662, Epoch Time 1438.1752(1295.4558), Bit/dim 3.3707(best: 3.3689), Xent 0.0000, Loss 3.3707, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13980 | Time 23.1345(23.7271) | Bit/dim 3.3877(3.3688) | Xent 0.0000(0.0000) | Loss 8.7374(9.8050) | Error 0.0000(0.0000) Steps 892(921.28) | Grad Norm 0.4768(0.4839) | Total Time 0.00(0.00)\n",
      "Iter 13990 | Time 24.1546(23.6876) | Bit/dim 3.3557(3.3691) | Xent 0.0000(0.0000) | Loss 8.7764(9.5438) | Error 0.0000(0.0000) Steps 928(922.50) | Grad Norm 0.4756(0.4795) | Total Time 0.00(0.00)\n",
      "Iter 14000 | Time 23.8335(23.7026) | Bit/dim 3.3420(3.3680) | Xent 0.0000(0.0000) | Loss 8.7036(9.3532) | Error 0.0000(0.0000) Steps 886(921.72) | Grad Norm 0.4482(0.4867) | Total Time 0.00(0.00)\n",
      "Iter 14010 | Time 23.8159(23.7379) | Bit/dim 3.3863(3.3696) | Xent 0.0000(0.0000) | Loss 8.9424(9.2305) | Error 0.0000(0.0000) Steps 946(921.05) | Grad Norm 0.4456(0.4889) | Total Time 0.00(0.00)\n",
      "Iter 14020 | Time 23.9515(23.7700) | Bit/dim 3.3792(3.3656) | Xent 0.0000(0.0000) | Loss 8.7915(9.1239) | Error 0.0000(0.0000) Steps 886(921.64) | Grad Norm 0.5078(0.4888) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 113.4684, Epoch Time 1437.8137(1299.7266), Bit/dim 3.3728(best: 3.3689), Xent 0.0000, Loss 3.3728, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14030 | Time 23.3297(23.7834) | Bit/dim 3.3779(3.3643) | Xent 0.0000(0.0000) | Loss 8.8219(10.0132) | Error 0.0000(0.0000) Steps 922(919.94) | Grad Norm 0.6267(0.4912) | Total Time 0.00(0.00)\n",
      "Iter 14040 | Time 24.1651(23.8467) | Bit/dim 3.3455(3.3654) | Xent 0.0000(0.0000) | Loss 8.8066(9.6992) | Error 0.0000(0.0000) Steps 904(918.14) | Grad Norm 0.5254(0.5042) | Total Time 0.00(0.00)\n",
      "Iter 14050 | Time 23.3435(23.7545) | Bit/dim 3.3803(3.3654) | Xent 0.0000(0.0000) | Loss 8.7378(9.4675) | Error 0.0000(0.0000) Steps 910(920.30) | Grad Norm 0.5847(0.5152) | Total Time 0.00(0.00)\n",
      "Iter 14060 | Time 24.4765(23.8191) | Bit/dim 3.3735(3.3651) | Xent 0.0000(0.0000) | Loss 8.7925(9.2933) | Error 0.0000(0.0000) Steps 874(921.55) | Grad Norm 0.5137(0.5320) | Total Time 0.00(0.00)\n",
      "Iter 14070 | Time 24.2199(23.8807) | Bit/dim 3.3646(3.3647) | Xent 0.0000(0.0000) | Loss 8.8942(9.1591) | Error 0.0000(0.0000) Steps 928(918.09) | Grad Norm 0.5530(0.5456) | Total Time 0.00(0.00)\n",
      "Iter 14080 | Time 23.3510(23.8604) | Bit/dim 3.3431(3.3658) | Xent 0.0000(0.0000) | Loss 8.7551(9.0693) | Error 0.0000(0.0000) Steps 940(923.01) | Grad Norm 0.4597(0.5553) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 114.4581, Epoch Time 1446.3683(1304.1258), Bit/dim 3.3706(best: 3.3689), Xent 0.0000, Loss 3.3706, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14090 | Time 23.4439(23.9201) | Bit/dim 3.3745(3.3650) | Xent 0.0000(0.0000) | Loss 8.6259(9.8180) | Error 0.0000(0.0000) Steps 916(925.72) | Grad Norm 0.5957(0.5842) | Total Time 0.00(0.00)\n",
      "Iter 14100 | Time 23.3874(23.9381) | Bit/dim 3.3585(3.3637) | Xent 0.0000(0.0000) | Loss 8.8962(9.5421) | Error 0.0000(0.0000) Steps 940(923.92) | Grad Norm 0.5509(0.5797) | Total Time 0.00(0.00)\n",
      "Iter 14110 | Time 23.6361(24.2251) | Bit/dim 3.3992(3.3647) | Xent 0.0000(0.0000) | Loss 8.7260(9.3498) | Error 0.0000(0.0000) Steps 898(926.13) | Grad Norm 0.5771(0.5696) | Total Time 0.00(0.00)\n",
      "Iter 14120 | Time 26.9770(24.7642) | Bit/dim 3.3510(3.3627) | Xent 0.0000(0.0000) | Loss 8.7460(9.2077) | Error 0.0000(0.0000) Steps 976(931.80) | Grad Norm 0.6717(0.5906) | Total Time 0.00(0.00)\n",
      "Iter 14130 | Time 27.8595(25.3356) | Bit/dim 3.3745(3.3641) | Xent 0.0000(0.0000) | Loss 8.8298(9.1108) | Error 0.0000(0.0000) Steps 934(938.26) | Grad Norm 0.5760(0.6000) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 115.0246, Epoch Time 1521.6919(1310.6528), Bit/dim 3.3682(best: 3.3689), Xent 0.0000, Loss 3.3682, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14140 | Time 26.5764(25.3790) | Bit/dim 3.3683(3.3634) | Xent 0.0000(0.0000) | Loss 8.7971(9.9943) | Error 0.0000(0.0000) Steps 1012(940.11) | Grad Norm 0.5783(0.5902) | Total Time 0.00(0.00)\n",
      "Iter 14150 | Time 26.0899(25.6928) | Bit/dim 3.3510(3.3651) | Xent 0.0000(0.0000) | Loss 8.9258(9.7037) | Error 0.0000(0.0000) Steps 994(948.72) | Grad Norm 0.5740(0.5827) | Total Time 0.00(0.00)\n",
      "Iter 14160 | Time 24.3324(25.7702) | Bit/dim 3.4099(3.3679) | Xent 0.0000(0.0000) | Loss 8.7636(9.4608) | Error 0.0000(0.0000) Steps 982(949.96) | Grad Norm 0.5926(0.5990) | Total Time 0.00(0.00)\n",
      "Iter 14170 | Time 23.7680(25.6155) | Bit/dim 3.3336(3.3669) | Xent 0.0000(0.0000) | Loss 8.8181(9.2881) | Error 0.0000(0.0000) Steps 904(941.32) | Grad Norm 0.4534(0.5838) | Total Time 0.00(0.00)\n",
      "Iter 14180 | Time 26.6734(25.5551) | Bit/dim 3.3282(3.3648) | Xent 0.0000(0.0000) | Loss 8.5924(9.1558) | Error 0.0000(0.0000) Steps 910(936.96) | Grad Norm 0.4928(0.5757) | Total Time 0.00(0.00)\n",
      "Iter 14190 | Time 26.1090(25.3790) | Bit/dim 3.3359(3.3627) | Xent 0.0000(0.0000) | Loss 8.8539(9.0607) | Error 0.0000(0.0000) Steps 946(937.29) | Grad Norm 0.6370(0.5718) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 116.3726, Epoch Time 1544.9921(1317.6830), Bit/dim 3.3730(best: 3.3682), Xent 0.0000, Loss 3.3730, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14200 | Time 25.3099(25.3031) | Bit/dim 3.3126(3.3602) | Xent 0.0000(0.0000) | Loss 8.7553(9.8071) | Error 0.0000(0.0000) Steps 958(938.98) | Grad Norm 0.4702(0.5767) | Total Time 0.00(0.00)\n",
      "Iter 14210 | Time 26.2575(25.1793) | Bit/dim 3.3829(3.3653) | Xent 0.0000(0.0000) | Loss 8.8345(9.5574) | Error 0.0000(0.0000) Steps 994(940.68) | Grad Norm 0.4768(0.5594) | Total Time 0.00(0.00)\n",
      "Iter 14220 | Time 25.0869(25.3557) | Bit/dim 3.3607(3.3651) | Xent 0.0000(0.0000) | Loss 8.6270(9.3557) | Error 0.0000(0.0000) Steps 940(948.09) | Grad Norm 0.6746(0.6591) | Total Time 0.00(0.00)\n",
      "Iter 14230 | Time 27.8779(26.2492) | Bit/dim 3.3890(3.3664) | Xent 0.0000(0.0000) | Loss 9.0313(9.2324) | Error 0.0000(0.0000) Steps 1054(969.54) | Grad Norm 1.1092(0.6874) | Total Time 0.00(0.00)\n",
      "Iter 14240 | Time 28.0251(26.8504) | Bit/dim 3.3784(3.3662) | Xent 0.0000(0.0000) | Loss 8.9313(9.1320) | Error 0.0000(0.0000) Steps 1018(977.50) | Grad Norm 0.6323(0.6912) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 122.2526, Epoch Time 1607.0059(1326.3627), Bit/dim 3.3729(best: 3.3682), Xent 0.0000, Loss 3.3729, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14250 | Time 29.0806(27.4117) | Bit/dim 3.3998(3.3664) | Xent 0.0000(0.0000) | Loss 8.9207(10.0211) | Error 0.0000(0.0000) Steps 1018(985.37) | Grad Norm 1.5181(1.0219) | Total Time 0.00(0.00)\n",
      "Iter 14260 | Time 29.6379(28.3612) | Bit/dim 3.3571(3.3691) | Xent 0.0000(0.0000) | Loss 8.8606(9.7285) | Error 0.0000(0.0000) Steps 994(1008.04) | Grad Norm 1.0696(1.0550) | Total Time 0.00(0.00)\n",
      "Iter 14270 | Time 28.1476(28.8250) | Bit/dim 3.3243(3.3661) | Xent 0.0000(0.0000) | Loss 8.6479(9.4950) | Error 0.0000(0.0000) Steps 898(1010.04) | Grad Norm 0.9996(1.0854) | Total Time 0.00(0.00)\n",
      "Iter 14280 | Time 30.3441(28.9615) | Bit/dim 3.3681(3.3652) | Xent 0.0000(0.0000) | Loss 8.9939(9.3364) | Error 0.0000(0.0000) Steps 1036(1010.70) | Grad Norm 0.8351(1.0484) | Total Time 0.00(0.00)\n",
      "Iter 14290 | Time 23.2583(28.0223) | Bit/dim 3.3513(3.3665) | Xent 0.0000(0.0000) | Loss 8.8229(9.1967) | Error 0.0000(0.0000) Steps 958(992.63) | Grad Norm 2.1498(1.7087) | Total Time 0.00(0.00)\n",
      "Iter 14300 | Time 23.7069(26.8764) | Bit/dim 3.3474(3.3663) | Xent 0.0000(0.0000) | Loss 8.7497(9.0893) | Error 0.0000(0.0000) Steps 928(970.34) | Grad Norm 2.2888(1.7927) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 113.9768, Epoch Time 1682.5303(1337.0477), Bit/dim 3.3702(best: 3.3682), Xent 0.0000, Loss 3.3702, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14310 | Time 23.3646(26.1150) | Bit/dim 3.3583(3.3652) | Xent 0.0000(0.0000) | Loss 8.7132(9.8612) | Error 0.0000(0.0000) Steps 880(961.15) | Grad Norm 1.5413(1.6728) | Total Time 0.00(0.00)\n",
      "Iter 14320 | Time 23.9167(25.5227) | Bit/dim 3.3692(3.3637) | Xent 0.0000(0.0000) | Loss 8.8684(9.5973) | Error 0.0000(0.0000) Steps 958(955.21) | Grad Norm 0.6822(1.4352) | Total Time 0.00(0.00)\n",
      "Iter 14330 | Time 23.0172(25.0529) | Bit/dim 3.3999(3.3628) | Xent 0.0000(0.0000) | Loss 8.8412(9.3921) | Error 0.0000(0.0000) Steps 916(945.34) | Grad Norm 0.5794(1.2241) | Total Time 0.00(0.00)\n",
      "Iter 14340 | Time 24.8030(24.7792) | Bit/dim 3.3646(3.3654) | Xent 0.0000(0.0000) | Loss 8.4952(9.2267) | Error 0.0000(0.0000) Steps 904(935.81) | Grad Norm 1.4086(1.0737) | Total Time 0.00(0.00)\n",
      "Iter 14350 | Time 23.6869(24.5430) | Bit/dim 3.3336(3.3663) | Xent 0.0000(0.0000) | Loss 8.5596(9.1089) | Error 0.0000(0.0000) Steps 892(933.90) | Grad Norm 0.5577(0.9632) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 115.6332, Epoch Time 1447.4117(1340.3586), Bit/dim 3.3730(best: 3.3682), Xent 0.0000, Loss 3.3730, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14360 | Time 26.7914(24.4080) | Bit/dim 3.3648(3.3680) | Xent 0.0000(0.0000) | Loss 8.7750(9.9882) | Error 0.0000(0.0000) Steps 916(931.24) | Grad Norm 0.5933(0.8673) | Total Time 0.00(0.00)\n",
      "Iter 14370 | Time 22.5347(24.3328) | Bit/dim 3.3824(3.3677) | Xent 0.0000(0.0000) | Loss 8.8625(9.6915) | Error 0.0000(0.0000) Steps 910(930.13) | Grad Norm 0.7849(0.7908) | Total Time 0.00(0.00)\n",
      "Iter 14380 | Time 23.7787(24.2073) | Bit/dim 3.3541(3.3642) | Xent 0.0000(0.0000) | Loss 8.7382(9.4535) | Error 0.0000(0.0000) Steps 898(928.52) | Grad Norm 0.6516(0.7448) | Total Time 0.00(0.00)\n",
      "Iter 14390 | Time 24.1144(24.1816) | Bit/dim 3.3653(3.3641) | Xent 0.0000(0.0000) | Loss 8.8426(9.2829) | Error 0.0000(0.0000) Steps 946(929.42) | Grad Norm 0.5344(0.7182) | Total Time 0.00(0.00)\n",
      "Iter 14400 | Time 23.4253(24.1016) | Bit/dim 3.3536(3.3631) | Xent 0.0000(0.0000) | Loss 8.6957(9.1594) | Error 0.0000(0.0000) Steps 922(927.53) | Grad Norm 0.7071(0.7014) | Total Time 0.00(0.00)\n",
      "Iter 14410 | Time 25.5053(24.1502) | Bit/dim 3.3900(3.3648) | Xent 0.0000(0.0000) | Loss 8.9858(9.0742) | Error 0.0000(0.0000) Steps 952(926.42) | Grad Norm 0.5173(0.6669) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 113.3399, Epoch Time 1456.1082(1343.8311), Bit/dim 3.3706(best: 3.3682), Xent 0.0000, Loss 3.3706, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14420 | Time 24.0263(24.1515) | Bit/dim 3.3638(3.3659) | Xent 0.0000(0.0000) | Loss 8.6866(9.8124) | Error 0.0000(0.0000) Steps 898(925.19) | Grad Norm 0.5557(0.6348) | Total Time 0.00(0.00)\n",
      "Iter 14430 | Time 23.9041(24.1380) | Bit/dim 3.4046(3.3673) | Xent 0.0000(0.0000) | Loss 8.9689(9.5484) | Error 0.0000(0.0000) Steps 940(923.90) | Grad Norm 0.5687(0.6156) | Total Time 0.00(0.00)\n",
      "Iter 14440 | Time 24.3552(24.0918) | Bit/dim 3.3562(3.3659) | Xent 0.0000(0.0000) | Loss 8.8188(9.3551) | Error 0.0000(0.0000) Steps 868(921.38) | Grad Norm 0.4648(0.5943) | Total Time 0.00(0.00)\n",
      "Iter 14450 | Time 24.8867(24.1976) | Bit/dim 3.3693(3.3653) | Xent 0.0000(0.0000) | Loss 8.7751(9.2075) | Error 0.0000(0.0000) Steps 898(921.06) | Grad Norm 0.5394(0.6089) | Total Time 0.00(0.00)\n",
      "Iter 14460 | Time 23.7969(24.2121) | Bit/dim 3.3382(3.3652) | Xent 0.0000(0.0000) | Loss 8.6040(9.1032) | Error 0.0000(0.0000) Steps 934(927.56) | Grad Norm 0.5910(0.6145) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 114.6606, Epoch Time 1466.0738(1347.4984), Bit/dim 3.3725(best: 3.3682), Xent 0.0000, Loss 3.3725, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14470 | Time 24.6662(24.2791) | Bit/dim 3.3795(3.3673) | Xent 0.0000(0.0000) | Loss 8.8393(10.0032) | Error 0.0000(0.0000) Steps 958(929.21) | Grad Norm 0.5829(0.6138) | Total Time 0.00(0.00)\n",
      "Iter 14480 | Time 24.8928(24.3819) | Bit/dim 3.3617(3.3650) | Xent 0.0000(0.0000) | Loss 8.8366(9.6821) | Error 0.0000(0.0000) Steps 964(930.58) | Grad Norm 5.6277(0.7505) | Total Time 0.00(0.00)\n",
      "Iter 14490 | Time 24.0910(24.3590) | Bit/dim 3.3454(3.3627) | Xent 0.0000(0.0000) | Loss 8.8812(9.4511) | Error 0.0000(0.0000) Steps 928(931.97) | Grad Norm 0.6657(0.7644) | Total Time 0.00(0.00)\n",
      "Iter 14500 | Time 24.1699(24.5060) | Bit/dim 3.3419(3.3631) | Xent 0.0000(0.0000) | Loss 8.7328(9.2834) | Error 0.0000(0.0000) Steps 898(930.89) | Grad Norm 0.6890(0.7379) | Total Time 0.00(0.00)\n",
      "Iter 14510 | Time 24.3830(24.4325) | Bit/dim 3.3396(3.3632) | Xent 0.0000(0.0000) | Loss 8.7786(9.1603) | Error 0.0000(0.0000) Steps 952(931.02) | Grad Norm 0.6837(0.7180) | Total Time 0.00(0.00)\n",
      "Iter 14520 | Time 29.2395(25.1238) | Bit/dim 3.3497(3.3640) | Xent 0.0000(0.0000) | Loss 8.8379(9.0792) | Error 0.0000(0.0000) Steps 928(941.80) | Grad Norm 0.9627(0.9453) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 116.8135, Epoch Time 1508.6787(1352.3338), Bit/dim 3.3734(best: 3.3682), Xent 0.0000, Loss 3.3734, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14530 | Time 27.7226(25.8853) | Bit/dim 3.3571(3.3657) | Xent 0.0000(0.0000) | Loss 8.9099(9.8714) | Error 0.0000(0.0000) Steps 970(952.91) | Grad Norm 1.0426(1.2156) | Total Time 0.00(0.00)\n",
      "Iter 14540 | Time 23.2976(25.6103) | Bit/dim 3.3585(3.3644) | Xent 0.0000(0.0000) | Loss 8.7900(9.5930) | Error 0.0000(0.0000) Steps 916(944.39) | Grad Norm 0.9066(1.2128) | Total Time 0.00(0.00)\n",
      "Iter 14550 | Time 23.7426(25.2458) | Bit/dim 3.3492(3.3662) | Xent 0.0000(0.0000) | Loss 8.7866(9.3992) | Error 0.0000(0.0000) Steps 958(944.92) | Grad Norm 0.7775(1.0834) | Total Time 0.00(0.00)\n",
      "Iter 14560 | Time 25.7233(25.2929) | Bit/dim 3.3908(3.3680) | Xent 0.0000(0.0000) | Loss 8.7804(9.2391) | Error 0.0000(0.0000) Steps 940(941.01) | Grad Norm 0.7280(0.9625) | Total Time 0.00(0.00)\n",
      "Iter 14570 | Time 23.9424(25.1863) | Bit/dim 3.3517(3.3666) | Xent 0.0000(0.0000) | Loss 8.8855(9.1254) | Error 0.0000(0.0000) Steps 946(940.31) | Grad Norm 0.5516(0.8529) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 115.4704, Epoch Time 1533.2852(1357.7623), Bit/dim 3.3738(best: 3.3682), Xent 0.0000, Loss 3.3738, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14580 | Time 23.7112(25.0754) | Bit/dim 3.3709(3.3654) | Xent 0.0000(0.0000) | Loss 8.8807(10.0230) | Error 0.0000(0.0000) Steps 928(939.21) | Grad Norm 0.6363(0.7892) | Total Time 0.00(0.00)\n",
      "Iter 14590 | Time 24.5540(24.9339) | Bit/dim 3.3724(3.3673) | Xent 0.0000(0.0000) | Loss 8.8832(9.7078) | Error 0.0000(0.0000) Steps 928(941.09) | Grad Norm 0.5269(0.7362) | Total Time 0.00(0.00)\n",
      "Iter 14600 | Time 24.4465(24.9034) | Bit/dim 3.3577(3.3680) | Xent 0.0000(0.0000) | Loss 8.9992(9.4806) | Error 0.0000(0.0000) Steps 970(942.43) | Grad Norm 0.6142(0.7837) | Total Time 0.00(0.00)\n",
      "Iter 14610 | Time 29.7166(25.2895) | Bit/dim 3.3728(3.3657) | Xent 0.0000(0.0000) | Loss 8.7833(9.3015) | Error 0.0000(0.0000) Steps 1084(951.83) | Grad Norm 0.5983(0.7304) | Total Time 0.00(0.00)\n",
      "Iter 14620 | Time 29.5977(25.6826) | Bit/dim 3.3247(3.3645) | Xent 0.0000(0.0000) | Loss 8.8497(9.1878) | Error 0.0000(0.0000) Steps 1108(962.57) | Grad Norm 0.7039(0.7298) | Total Time 0.00(0.00)\n",
      "Iter 14630 | Time 29.7555(25.8463) | Bit/dim 3.3754(3.3640) | Xent 0.0000(0.0000) | Loss 8.8627(9.0898) | Error 0.0000(0.0000) Steps 1126(963.48) | Grad Norm 0.5362(0.7150) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 115.1199, Epoch Time 1544.9353(1363.3775), Bit/dim 3.3689(best: 3.3682), Xent 0.0000, Loss 3.3689, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14640 | Time 29.1104(25.9647) | Bit/dim 3.3945(3.3633) | Xent 0.0000(0.0000) | Loss 8.9450(9.8289) | Error 0.0000(0.0000) Steps 1078(962.62) | Grad Norm 0.7192(0.6940) | Total Time 0.00(0.00)\n",
      "Iter 14650 | Time 23.3323(25.7081) | Bit/dim 3.3823(3.3645) | Xent 0.0000(0.0000) | Loss 8.9407(9.5686) | Error 0.0000(0.0000) Steps 946(958.49) | Grad Norm 0.8208(0.7359) | Total Time 0.00(0.00)\n",
      "Iter 14660 | Time 24.2352(25.4375) | Bit/dim 3.3883(3.3667) | Xent 0.0000(0.0000) | Loss 8.7753(9.3740) | Error 0.0000(0.0000) Steps 964(948.87) | Grad Norm 0.6502(0.7157) | Total Time 0.00(0.00)\n",
      "Iter 14670 | Time 24.4825(25.1136) | Bit/dim 3.4018(3.3687) | Xent 0.0000(0.0000) | Loss 9.0719(9.2425) | Error 0.0000(0.0000) Steps 928(950.04) | Grad Norm 0.5902(0.6875) | Total Time 0.00(0.00)\n",
      "Iter 14680 | Time 27.8684(25.0430) | Bit/dim 3.3904(3.3658) | Xent 0.0000(0.0000) | Loss 8.8971(9.1272) | Error 0.0000(0.0000) Steps 910(944.81) | Grad Norm 5.0925(0.7975) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0267 | Time 114.5402, Epoch Time 1510.6906(1367.7969), Bit/dim 3.3683(best: 3.3682), Xent 0.0000, Loss 3.3683, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14690 | Time 23.3371(24.9382) | Bit/dim 3.3580(3.3636) | Xent 0.0000(0.0000) | Loss 8.7208(9.9896) | Error 0.0000(0.0000) Steps 928(940.20) | Grad Norm 0.9539(0.8875) | Total Time 0.00(0.00)\n",
      "Iter 14700 | Time 24.8417(24.8058) | Bit/dim 3.3561(3.3661) | Xent 0.0000(0.0000) | Loss 8.8617(9.6965) | Error 0.0000(0.0000) Steps 904(936.02) | Grad Norm 0.8807(0.8520) | Total Time 0.00(0.00)\n",
      "Iter 14710 | Time 25.0994(24.6571) | Bit/dim 3.3770(3.3677) | Xent 0.0000(0.0000) | Loss 8.9233(9.4764) | Error 0.0000(0.0000) Steps 982(939.70) | Grad Norm 0.6884(0.7849) | Total Time 0.00(0.00)\n",
      "Iter 14720 | Time 24.2046(24.5266) | Bit/dim 3.3783(3.3665) | Xent 0.0000(0.0000) | Loss 8.8177(9.3029) | Error 0.0000(0.0000) Steps 904(934.85) | Grad Norm 0.4999(0.7577) | Total Time 0.00(0.00)\n",
      "Iter 14730 | Time 23.0408(24.3015) | Bit/dim 3.3327(3.3635) | Xent 0.0000(0.0000) | Loss 8.5770(9.1653) | Error 0.0000(0.0000) Steps 934(935.45) | Grad Norm 0.7040(0.7196) | Total Time 0.00(0.00)\n",
      "Iter 14740 | Time 23.1705(24.2435) | Bit/dim 3.3604(3.3633) | Xent 0.0000(0.0000) | Loss 8.8335(9.0717) | Error 0.0000(0.0000) Steps 946(935.12) | Grad Norm 0.6737(0.6905) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0268 | Time 116.4858, Epoch Time 1460.4611(1370.5768), Bit/dim 3.3678(best: 3.3682), Xent 0.0000, Loss 3.3678, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14750 | Time 24.4573(24.1588) | Bit/dim 3.3905(3.3644) | Xent 0.0000(0.0000) | Loss 8.8195(9.8359) | Error 0.0000(0.0000) Steps 928(934.50) | Grad Norm 0.9345(0.7140) | Total Time 0.00(0.00)\n",
      "Iter 14760 | Time 23.6609(24.1205) | Bit/dim 3.3649(3.3627) | Xent 0.0000(0.0000) | Loss 8.5794(9.5525) | Error 0.0000(0.0000) Steps 916(931.10) | Grad Norm 0.7092(0.7055) | Total Time 0.00(0.00)\n",
      "Iter 14770 | Time 23.3596(24.1681) | Bit/dim 3.3659(3.3634) | Xent 0.0000(0.0000) | Loss 8.7472(9.3662) | Error 0.0000(0.0000) Steps 946(932.28) | Grad Norm 0.5734(0.6787) | Total Time 0.00(0.00)\n",
      "Iter 14780 | Time 24.2191(24.1208) | Bit/dim 3.3613(3.3652) | Xent 0.0000(0.0000) | Loss 8.6483(9.2217) | Error 0.0000(0.0000) Steps 892(931.11) | Grad Norm 0.6369(0.6641) | Total Time 0.00(0.00)\n",
      "Iter 14790 | Time 23.5962(24.1745) | Bit/dim 3.3254(3.3648) | Xent 0.0000(0.0000) | Loss 8.6671(9.1104) | Error 0.0000(0.0000) Steps 922(930.34) | Grad Norm 0.5461(0.6726) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0269 | Time 115.3630, Epoch Time 1461.0485(1373.2910), Bit/dim 3.3705(best: 3.3678), Xent 0.0000, Loss 3.3705, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14800 | Time 24.2891(24.1880) | Bit/dim 3.3613(3.3625) | Xent 0.0000(0.0000) | Loss 8.7661(9.9910) | Error 0.0000(0.0000) Steps 904(928.78) | Grad Norm 0.8248(0.6618) | Total Time 0.00(0.00)\n",
      "Iter 14810 | Time 25.0704(24.2048) | Bit/dim 3.3326(3.3632) | Xent 0.0000(0.0000) | Loss 8.9064(9.7008) | Error 0.0000(0.0000) Steps 964(932.82) | Grad Norm 0.5208(0.6421) | Total Time 0.00(0.00)\n",
      "Iter 14820 | Time 24.4496(24.1878) | Bit/dim 3.3608(3.3667) | Xent 0.0000(0.0000) | Loss 8.7252(9.4728) | Error 0.0000(0.0000) Steps 904(929.02) | Grad Norm 0.6850(0.6340) | Total Time 0.00(0.00)\n",
      "Iter 14830 | Time 23.6441(24.2199) | Bit/dim 3.3634(3.3665) | Xent 0.0000(0.0000) | Loss 8.8210(9.3061) | Error 0.0000(0.0000) Steps 940(930.82) | Grad Norm 0.8243(0.6409) | Total Time 0.00(0.00)\n",
      "Iter 14840 | Time 24.2607(24.1843) | Bit/dim 3.3733(3.3652) | Xent 0.0000(0.0000) | Loss 8.8927(9.1808) | Error 0.0000(0.0000) Steps 964(933.25) | Grad Norm 0.6988(0.6458) | Total Time 0.00(0.00)\n",
      "Iter 14850 | Time 24.3180(24.2407) | Bit/dim 3.3659(3.3641) | Xent 0.0000(0.0000) | Loss 8.7653(9.0791) | Error 0.0000(0.0000) Steps 934(934.04) | Grad Norm 1.0506(0.6788) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0270 | Time 116.2629, Epoch Time 1467.7265(1376.1240), Bit/dim 3.3711(best: 3.3678), Xent 0.0000, Loss 3.3711, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14860 | Time 24.5355(24.2554) | Bit/dim 3.3552(3.3611) | Xent 0.0000(0.0000) | Loss 8.8739(9.8732) | Error 0.0000(0.0000) Steps 898(933.38) | Grad Norm 0.8203(0.7313) | Total Time 0.00(0.00)\n",
      "Iter 14870 | Time 24.2352(24.2078) | Bit/dim 3.3712(3.3627) | Xent 0.0000(0.0000) | Loss 8.8939(9.5945) | Error 0.0000(0.0000) Steps 898(930.99) | Grad Norm 0.7676(0.7353) | Total Time 0.00(0.00)\n",
      "Iter 14880 | Time 24.5285(24.1566) | Bit/dim 3.3615(3.3629) | Xent 0.0000(0.0000) | Loss 8.9451(9.3823) | Error 0.0000(0.0000) Steps 934(930.41) | Grad Norm 0.5688(0.7361) | Total Time 0.00(0.00)\n",
      "Iter 14890 | Time 25.0995(24.1479) | Bit/dim 3.3517(3.3637) | Xent 0.0000(0.0000) | Loss 8.7669(9.2340) | Error 0.0000(0.0000) Steps 964(931.79) | Grad Norm 0.6501(0.7189) | Total Time 0.00(0.00)\n",
      "Iter 14900 | Time 23.6256(24.0193) | Bit/dim 3.3454(3.3626) | Xent 0.0000(0.0000) | Loss 8.7937(9.1137) | Error 0.0000(0.0000) Steps 892(927.44) | Grad Norm 0.7995(0.7312) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0271 | Time 115.7884, Epoch Time 1454.6250(1378.4791), Bit/dim 3.3683(best: 3.3678), Xent 0.0000, Loss 3.3683, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14910 | Time 23.8388(23.9304) | Bit/dim 3.3543(3.3640) | Xent 0.0000(0.0000) | Loss 8.8015(10.0090) | Error 0.0000(0.0000) Steps 940(927.50) | Grad Norm 0.6580(0.7245) | Total Time 0.00(0.00)\n",
      "Iter 14920 | Time 23.6130(24.0601) | Bit/dim 3.3825(3.3640) | Xent 0.0000(0.0000) | Loss 8.7552(9.6957) | Error 0.0000(0.0000) Steps 946(929.77) | Grad Norm 0.7635(0.7058) | Total Time 0.00(0.00)\n",
      "Iter 14930 | Time 24.1989(24.0317) | Bit/dim 3.3891(3.3658) | Xent 0.0000(0.0000) | Loss 8.9084(9.4759) | Error 0.0000(0.0000) Steps 958(934.44) | Grad Norm 0.7820(0.7037) | Total Time 0.00(0.00)\n",
      "Iter 14940 | Time 25.0652(24.1706) | Bit/dim 3.3775(3.3647) | Xent 0.0000(0.0000) | Loss 8.8455(9.3068) | Error 0.0000(0.0000) Steps 964(937.31) | Grad Norm 0.5773(0.6852) | Total Time 0.00(0.00)\n",
      "Iter 14950 | Time 24.5248(24.1710) | Bit/dim 3.3216(3.3644) | Xent 0.0000(0.0000) | Loss 8.7861(9.1792) | Error 0.0000(0.0000) Steps 946(935.77) | Grad Norm 0.7772(0.6792) | Total Time 0.00(0.00)\n",
      "Iter 14960 | Time 23.7530(24.1959) | Bit/dim 3.3483(3.3619) | Xent 0.0000(0.0000) | Loss 8.7509(9.0841) | Error 0.0000(0.0000) Steps 958(936.23) | Grad Norm 0.6872(0.6803) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0272 | Time 115.9762, Epoch Time 1466.9211(1381.1323), Bit/dim 3.3700(best: 3.3678), Xent 0.0000, Loss 3.3700, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14970 | Time 24.1603(24.2281) | Bit/dim 3.3532(3.3616) | Xent 0.0000(0.0000) | Loss 8.8036(9.8553) | Error 0.0000(0.0000) Steps 916(934.21) | Grad Norm 0.6189(0.6707) | Total Time 0.00(0.00)\n",
      "Iter 14980 | Time 25.3819(24.2457) | Bit/dim 3.3876(3.3627) | Xent 0.0000(0.0000) | Loss 8.8875(9.5958) | Error 0.0000(0.0000) Steps 940(933.56) | Grad Norm 0.7508(0.6808) | Total Time 0.00(0.00)\n",
      "Iter 14990 | Time 25.9147(24.1589) | Bit/dim 3.3436(3.3629) | Xent 0.0000(0.0000) | Loss 8.8540(9.3965) | Error 0.0000(0.0000) Steps 946(933.99) | Grad Norm 0.6714(0.6829) | Total Time 0.00(0.00)\n",
      "Iter 15000 | Time 24.4081(24.2491) | Bit/dim 3.3787(3.3651) | Xent 0.0000(0.0000) | Loss 8.7715(9.2418) | Error 0.0000(0.0000) Steps 892(932.50) | Grad Norm 0.7795(0.6726) | Total Time 0.00(0.00)\n",
      "Iter 15010 | Time 23.9337(24.1943) | Bit/dim 3.3626(3.3643) | Xent 0.0000(0.0000) | Loss 8.7527(9.1218) | Error 0.0000(0.0000) Steps 940(931.47) | Grad Norm 0.8301(0.6952) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0273 | Time 116.1471, Epoch Time 1467.2606(1383.7162), Bit/dim 3.3686(best: 3.3678), Xent 0.0000, Loss 3.3686, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15020 | Time 23.4556(24.1736) | Bit/dim 3.3418(3.3639) | Xent 0.0000(0.0000) | Loss 8.6949(9.9932) | Error 0.0000(0.0000) Steps 934(931.27) | Grad Norm 0.7382(0.7013) | Total Time 0.00(0.00)\n",
      "Iter 15030 | Time 24.1098(24.1857) | Bit/dim 3.3671(3.3632) | Xent 0.0000(0.0000) | Loss 8.9072(9.6819) | Error 0.0000(0.0000) Steps 970(931.86) | Grad Norm 0.7919(0.7153) | Total Time 0.00(0.00)\n",
      "Iter 15040 | Time 24.9187(24.2070) | Bit/dim 3.3645(3.3662) | Xent 0.0000(0.0000) | Loss 8.8497(9.4530) | Error 0.0000(0.0000) Steps 928(928.95) | Grad Norm 0.6882(0.7017) | Total Time 0.00(0.00)\n",
      "Iter 15050 | Time 23.7196(24.1553) | Bit/dim 3.3832(3.3659) | Xent 0.0000(0.0000) | Loss 8.7146(9.2647) | Error 0.0000(0.0000) Steps 928(926.70) | Grad Norm 0.5269(0.6931) | Total Time 0.00(0.00)\n",
      "Iter 15060 | Time 22.9825(24.0890) | Bit/dim 3.3279(3.3627) | Xent 0.0000(0.0000) | Loss 8.5622(9.1302) | Error 0.0000(0.0000) Steps 898(927.17) | Grad Norm 0.8120(0.7187) | Total Time 0.00(0.00)\n",
      "Iter 15070 | Time 24.2752(24.0339) | Bit/dim 3.3832(3.3625) | Xent 0.0000(0.0000) | Loss 8.8040(9.0424) | Error 0.0000(0.0000) Steps 928(926.74) | Grad Norm 0.5336(0.7411) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0274 | Time 116.0574, Epoch Time 1457.4240(1385.9274), Bit/dim 3.3681(best: 3.3678), Xent 0.0000, Loss 3.3681, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15080 | Time 22.6835(24.0340) | Bit/dim 3.3651(3.3622) | Xent 0.0000(0.0000) | Loss 8.8155(9.8240) | Error 0.0000(0.0000) Steps 892(929.35) | Grad Norm 0.6725(0.7368) | Total Time 0.00(0.00)\n",
      "Iter 15090 | Time 24.6029(24.0769) | Bit/dim 3.3648(3.3615) | Xent 0.0000(0.0000) | Loss 8.8332(9.5586) | Error 0.0000(0.0000) Steps 934(929.03) | Grad Norm 0.6388(0.7226) | Total Time 0.00(0.00)\n",
      "Iter 15100 | Time 27.2386(24.1657) | Bit/dim 3.3755(3.3648) | Xent 0.0000(0.0000) | Loss 8.6921(9.3653) | Error 0.0000(0.0000) Steps 934(929.40) | Grad Norm 1.8142(0.7421) | Total Time 0.00(0.00)\n",
      "Iter 15110 | Time 27.5545(24.2171) | Bit/dim 3.3558(3.3653) | Xent 0.0000(0.0000) | Loss 8.7405(9.2207) | Error 0.0000(0.0000) Steps 1012(929.69) | Grad Norm 0.7157(0.7401) | Total Time 0.00(0.00)\n",
      "Iter 15120 | Time 23.1490(24.2978) | Bit/dim 3.3382(3.3633) | Xent 0.0000(0.0000) | Loss 8.7153(9.1122) | Error 0.0000(0.0000) Steps 910(930.42) | Grad Norm 0.6962(0.7324) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0275 | Time 116.4647, Epoch Time 1468.6694(1388.4097), Bit/dim 3.3682(best: 3.3678), Xent 0.0000, Loss 3.3682, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15130 | Time 23.8233(24.2422) | Bit/dim 3.3551(3.3638) | Xent 0.0000(0.0000) | Loss 8.8084(10.0023) | Error 0.0000(0.0000) Steps 916(926.35) | Grad Norm 0.7189(0.7309) | Total Time 0.00(0.00)\n",
      "Iter 15140 | Time 23.5449(24.2123) | Bit/dim 3.3882(3.3643) | Xent 0.0000(0.0000) | Loss 8.7276(9.6840) | Error 0.0000(0.0000) Steps 904(925.24) | Grad Norm 0.6123(0.7173) | Total Time 0.00(0.00)\n",
      "Iter 15150 | Time 24.6403(24.1962) | Bit/dim 3.3394(3.3674) | Xent 0.0000(0.0000) | Loss 8.7922(9.4639) | Error 0.0000(0.0000) Steps 940(925.88) | Grad Norm 0.5886(0.7108) | Total Time 0.00(0.00)\n",
      "Iter 15160 | Time 23.2574(24.1747) | Bit/dim 3.3208(3.3644) | Xent 0.0000(0.0000) | Loss 8.7314(9.2944) | Error 0.0000(0.0000) Steps 934(927.98) | Grad Norm 0.6572(0.7172) | Total Time 0.00(0.00)\n",
      "Iter 15170 | Time 25.1776(24.2430) | Bit/dim 3.3612(3.3639) | Xent 0.0000(0.0000) | Loss 8.8289(9.1729) | Error 0.0000(0.0000) Steps 928(930.47) | Grad Norm 0.9254(0.7190) | Total Time 0.00(0.00)\n",
      "Iter 15180 | Time 23.7949(24.2201) | Bit/dim 3.3151(3.3614) | Xent 0.0000(0.0000) | Loss 8.7387(9.0812) | Error 0.0000(0.0000) Steps 922(930.32) | Grad Norm 1.1342(0.7544) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0276 | Time 115.0938, Epoch Time 1465.7490(1390.7299), Bit/dim 3.3691(best: 3.3678), Xent 0.0000, Loss 3.3691, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15190 | Time 23.7624(24.2251) | Bit/dim 3.3408(3.3636) | Xent 0.0000(0.0000) | Loss 8.8312(9.8580) | Error 0.0000(0.0000) Steps 964(934.03) | Grad Norm 0.7840(0.7902) | Total Time 0.00(0.00)\n",
      "Iter 15200 | Time 25.2146(24.2927) | Bit/dim 3.3618(3.3617) | Xent 0.0000(0.0000) | Loss 8.8143(9.5875) | Error 0.0000(0.0000) Steps 892(934.23) | Grad Norm 0.7690(0.7738) | Total Time 0.00(0.00)\n",
      "Iter 15210 | Time 23.9024(24.2753) | Bit/dim 3.3980(3.3622) | Xent 0.0000(0.0000) | Loss 8.8329(9.3900) | Error 0.0000(0.0000) Steps 934(932.74) | Grad Norm 0.7855(0.7779) | Total Time 0.00(0.00)\n",
      "Iter 15220 | Time 23.4912(24.2054) | Bit/dim 3.3859(3.3617) | Xent 0.0000(0.0000) | Loss 8.8212(9.2297) | Error 0.0000(0.0000) Steps 928(930.37) | Grad Norm 0.6209(0.7442) | Total Time 0.00(0.00)\n",
      "Iter 15230 | Time 23.9934(24.1990) | Bit/dim 3.3582(3.3638) | Xent 0.0000(0.0000) | Loss 8.7290(9.1077) | Error 0.0000(0.0000) Steps 904(926.39) | Grad Norm 0.6452(0.7136) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0277 | Time 113.9213, Epoch Time 1464.0632(1392.9299), Bit/dim 3.3735(best: 3.3678), Xent 0.0000, Loss 3.3735, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15240 | Time 25.5196(24.2577) | Bit/dim 3.3905(3.3628) | Xent 0.0000(0.0000) | Loss 8.9763(10.0090) | Error 0.0000(0.0000) Steps 988(931.24) | Grad Norm 0.6534(0.6941) | Total Time 0.00(0.00)\n",
      "Iter 15250 | Time 24.6076(24.2459) | Bit/dim 3.3833(3.3630) | Xent 0.0000(0.0000) | Loss 8.9009(9.6843) | Error 0.0000(0.0000) Steps 952(931.19) | Grad Norm 0.5954(0.6779) | Total Time 0.00(0.00)\n",
      "Iter 15260 | Time 24.8689(24.3291) | Bit/dim 3.3668(3.3648) | Xent 0.0000(0.0000) | Loss 8.9113(9.4607) | Error 0.0000(0.0000) Steps 970(933.59) | Grad Norm 0.6422(0.6809) | Total Time 0.00(0.00)\n",
      "Iter 15270 | Time 24.2056(24.3970) | Bit/dim 3.3441(3.3630) | Xent 0.0000(0.0000) | Loss 8.7951(9.2864) | Error 0.0000(0.0000) Steps 904(936.21) | Grad Norm 0.7257(0.6891) | Total Time 0.00(0.00)\n",
      "Iter 15280 | Time 25.1062(24.4043) | Bit/dim 3.3515(3.3616) | Xent 0.0000(0.0000) | Loss 8.8153(9.1546) | Error 0.0000(0.0000) Steps 916(933.87) | Grad Norm 0.7104(0.7401) | Total Time 0.00(0.00)\n",
      "Iter 15290 | Time 24.3818(24.3188) | Bit/dim 3.3856(3.3633) | Xent 0.0000(0.0000) | Loss 8.8299(9.0674) | Error 0.0000(0.0000) Steps 946(934.40) | Grad Norm 0.7079(0.7599) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0278 | Time 115.4294, Epoch Time 1477.0800(1395.4544), Bit/dim 3.3664(best: 3.3678), Xent 0.0000, Loss 3.3664, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15300 | Time 23.8779(24.3193) | Bit/dim 3.3490(3.3659) | Xent 0.0000(0.0000) | Loss 8.8015(9.8398) | Error 0.0000(0.0000) Steps 910(937.08) | Grad Norm 0.6952(0.7341) | Total Time 0.00(0.00)\n",
      "Iter 15310 | Time 24.6735(24.3721) | Bit/dim 3.3785(3.3654) | Xent 0.0000(0.0000) | Loss 8.9978(9.5813) | Error 0.0000(0.0000) Steps 964(937.70) | Grad Norm 0.6712(0.7181) | Total Time 0.00(0.00)\n",
      "Iter 15320 | Time 25.2397(24.3165) | Bit/dim 3.4089(3.3660) | Xent 0.0000(0.0000) | Loss 8.9010(9.3765) | Error 0.0000(0.0000) Steps 952(939.11) | Grad Norm 0.6939(0.7371) | Total Time 0.00(0.00)\n",
      "Iter 15330 | Time 24.8399(24.2835) | Bit/dim 3.3626(3.3641) | Xent 0.0000(0.0000) | Loss 8.8414(9.2212) | Error 0.0000(0.0000) Steps 934(935.49) | Grad Norm 1.2221(0.7609) | Total Time 0.00(0.00)\n",
      "Iter 15340 | Time 23.9733(24.3096) | Bit/dim 3.4010(3.3633) | Xent 0.0000(0.0000) | Loss 8.7201(9.1059) | Error 0.0000(0.0000) Steps 892(934.41) | Grad Norm 0.6260(0.7608) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0279 | Time 114.7246, Epoch Time 1470.4539(1397.7043), Bit/dim 3.3658(best: 3.3664), Xent 0.0000, Loss 3.3658, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15350 | Time 24.7435(24.2785) | Bit/dim 3.3699(3.3619) | Xent 0.0000(0.0000) | Loss 8.7805(9.9769) | Error 0.0000(0.0000) Steps 904(936.28) | Grad Norm 0.6154(0.7716) | Total Time 0.00(0.00)\n",
      "Iter 15360 | Time 24.2849(24.2947) | Bit/dim 3.3455(3.3637) | Xent 0.0000(0.0000) | Loss 8.7719(9.6839) | Error 0.0000(0.0000) Steps 946(935.47) | Grad Norm 0.8365(0.7841) | Total Time 0.00(0.00)\n",
      "Iter 15370 | Time 23.1970(24.3132) | Bit/dim 3.3370(3.3644) | Xent 0.0000(0.0000) | Loss 8.7156(9.4632) | Error 0.0000(0.0000) Steps 910(937.51) | Grad Norm 0.7787(0.7970) | Total Time 0.00(0.00)\n",
      "Iter 15380 | Time 24.1936(24.2511) | Bit/dim 3.3952(3.3643) | Xent 0.0000(0.0000) | Loss 8.9532(9.2932) | Error 0.0000(0.0000) Steps 958(938.64) | Grad Norm 0.8013(0.8226) | Total Time 0.00(0.00)\n",
      "Iter 15390 | Time 23.7740(24.2741) | Bit/dim 3.3479(3.3616) | Xent 0.0000(0.0000) | Loss 8.7798(9.1687) | Error 0.0000(0.0000) Steps 934(934.59) | Grad Norm 0.9102(0.8296) | Total Time 0.00(0.00)\n",
      "Iter 15400 | Time 24.6514(24.3213) | Bit/dim 3.3323(3.3612) | Xent 0.0000(0.0000) | Loss 8.8312(9.0797) | Error 0.0000(0.0000) Steps 940(937.64) | Grad Norm 0.7020(0.8172) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0280 | Time 115.4175, Epoch Time 1471.2007(1399.9092), Bit/dim 3.3659(best: 3.3658), Xent 0.0000, Loss 3.3659, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15410 | Time 25.2365(24.3156) | Bit/dim 3.3625(3.3639) | Xent 0.0000(0.0000) | Loss 8.9184(9.8112) | Error 0.0000(0.0000) Steps 964(934.35) | Grad Norm 0.7338(0.7920) | Total Time 0.00(0.00)\n",
      "Iter 15420 | Time 24.6205(24.3815) | Bit/dim 3.3598(3.3615) | Xent 0.0000(0.0000) | Loss 8.9065(9.5450) | Error 0.0000(0.0000) Steps 958(932.27) | Grad Norm 0.9276(0.8209) | Total Time 0.00(0.00)\n",
      "Iter 15430 | Time 23.6635(24.5830) | Bit/dim 3.3832(3.3618) | Xent 0.0000(0.0000) | Loss 8.7614(9.3576) | Error 0.0000(0.0000) Steps 922(930.79) | Grad Norm 0.8560(0.8505) | Total Time 0.00(0.00)\n",
      "Iter 15440 | Time 25.6406(24.5135) | Bit/dim 3.3553(3.3630) | Xent 0.0000(0.0000) | Loss 8.8564(9.2082) | Error 0.0000(0.0000) Steps 916(928.86) | Grad Norm 0.9913(0.8636) | Total Time 0.00(0.00)\n",
      "Iter 15450 | Time 23.8762(24.4652) | Bit/dim 3.3495(3.3623) | Xent 0.0000(0.0000) | Loss 8.6347(9.0910) | Error 0.0000(0.0000) Steps 916(927.85) | Grad Norm 0.7672(0.8381) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0281 | Time 115.2641, Epoch Time 1480.6299(1402.3309), Bit/dim 3.3653(best: 3.3658), Xent 0.0000, Loss 3.3653, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15460 | Time 24.1856(24.3989) | Bit/dim 3.3178(3.3602) | Xent 0.0000(0.0000) | Loss 8.7817(9.9516) | Error 0.0000(0.0000) Steps 916(929.10) | Grad Norm 0.8154(0.8244) | Total Time 0.00(0.00)\n",
      "Iter 15470 | Time 24.0855(24.3294) | Bit/dim 3.3898(3.3619) | Xent 0.0000(0.0000) | Loss 8.8182(9.6576) | Error 0.0000(0.0000) Steps 928(929.45) | Grad Norm 1.0421(0.8430) | Total Time 0.00(0.00)\n",
      "Iter 15480 | Time 24.5364(24.2454) | Bit/dim 3.3808(3.3635) | Xent 0.0000(0.0000) | Loss 8.8845(9.4322) | Error 0.0000(0.0000) Steps 958(929.80) | Grad Norm 0.8813(0.8587) | Total Time 0.00(0.00)\n",
      "Iter 15490 | Time 24.3373(24.2606) | Bit/dim 3.3550(3.3619) | Xent 0.0000(0.0000) | Loss 8.8183(9.2630) | Error 0.0000(0.0000) Steps 970(930.43) | Grad Norm 0.5956(0.8668) | Total Time 0.00(0.00)\n",
      "Iter 15500 | Time 23.4789(24.3243) | Bit/dim 3.3644(3.3633) | Xent 0.0000(0.0000) | Loss 8.8988(9.1435) | Error 0.0000(0.0000) Steps 940(932.50) | Grad Norm 0.9774(0.8892) | Total Time 0.00(0.00)\n",
      "Iter 15510 | Time 23.7556(24.3023) | Bit/dim 3.3784(3.3644) | Xent 0.0000(0.0000) | Loss 8.7946(9.0538) | Error 0.0000(0.0000) Steps 916(933.53) | Grad Norm 0.7607(0.8470) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0282 | Time 116.4882, Epoch Time 1469.4234(1404.3436), Bit/dim 3.3638(best: 3.3653), Xent 0.0000, Loss 3.3638, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15520 | Time 24.0325(24.3467) | Bit/dim 3.3596(3.3641) | Xent 0.0000(0.0000) | Loss 8.7559(9.8287) | Error 0.0000(0.0000) Steps 940(935.86) | Grad Norm 0.8382(0.8284) | Total Time 0.00(0.00)\n",
      "Iter 15530 | Time 22.8262(24.2411) | Bit/dim 3.3393(3.3640) | Xent 0.0000(0.0000) | Loss 8.7212(9.5603) | Error 0.0000(0.0000) Steps 946(937.59) | Grad Norm 0.6584(0.8948) | Total Time 0.00(0.00)\n",
      "Iter 15540 | Time 24.8087(24.3812) | Bit/dim 3.3878(3.3617) | Xent 0.0000(0.0000) | Loss 8.7782(9.3699) | Error 0.0000(0.0000) Steps 922(937.78) | Grad Norm 0.7418(0.9150) | Total Time 0.00(0.00)\n",
      "Iter 15550 | Time 24.3752(24.3986) | Bit/dim 3.3308(3.3618) | Xent 0.0000(0.0000) | Loss 8.8376(9.2387) | Error 0.0000(0.0000) Steps 934(941.07) | Grad Norm 1.1812(0.9308) | Total Time 0.00(0.00)\n",
      "Iter 15560 | Time 24.1677(24.3161) | Bit/dim 3.3883(3.3644) | Xent 0.0000(0.0000) | Loss 8.9302(9.1348) | Error 0.0000(0.0000) Steps 970(941.62) | Grad Norm 0.6333(0.9221) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0283 | Time 115.2424, Epoch Time 1472.6788(1406.3937), Bit/dim 3.3713(best: 3.3638), Xent 0.0000, Loss 3.3713, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15570 | Time 25.3027(24.3259) | Bit/dim 3.3518(3.3642) | Xent 0.0000(0.0000) | Loss 8.8089(10.0536) | Error 0.0000(0.0000) Steps 976(941.80) | Grad Norm 1.0065(0.9181) | Total Time 0.00(0.00)\n",
      "Iter 15580 | Time 25.2237(24.4374) | Bit/dim 3.3523(3.3631) | Xent 0.0000(0.0000) | Loss 8.8826(9.7284) | Error 0.0000(0.0000) Steps 922(940.32) | Grad Norm 0.8121(0.9026) | Total Time 0.00(0.00)\n",
      "Iter 15590 | Time 23.7387(24.4486) | Bit/dim 3.3805(3.3625) | Xent 0.0000(0.0000) | Loss 8.9248(9.4905) | Error 0.0000(0.0000) Steps 928(938.30) | Grad Norm 0.7711(0.8861) | Total Time 0.00(0.00)\n",
      "Iter 15600 | Time 24.3276(24.5015) | Bit/dim 3.3964(3.3639) | Xent 0.0000(0.0000) | Loss 8.9277(9.3266) | Error 0.0000(0.0000) Steps 886(935.79) | Grad Norm 0.9170(0.9014) | Total Time 0.00(0.00)\n",
      "Iter 15610 | Time 24.6834(24.5049) | Bit/dim 3.3810(3.3628) | Xent 0.0000(0.0000) | Loss 8.9074(9.1916) | Error 0.0000(0.0000) Steps 952(938.53) | Grad Norm 0.8133(0.9107) | Total Time 0.00(0.00)\n",
      "Iter 15620 | Time 23.8806(24.5095) | Bit/dim 3.3772(3.3648) | Xent 0.0000(0.0000) | Loss 8.9152(9.0932) | Error 0.0000(0.0000) Steps 952(939.35) | Grad Norm 1.0428(0.9619) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0284 | Time 115.8174, Epoch Time 1486.0859(1408.7845), Bit/dim 3.3673(best: 3.3638), Xent 0.0000, Loss 3.3673, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15630 | Time 24.8726(24.5197) | Bit/dim 3.3676(3.3633) | Xent 0.0000(0.0000) | Loss 8.9075(9.8296) | Error 0.0000(0.0000) Steps 934(941.76) | Grad Norm 1.1567(0.9573) | Total Time 0.00(0.00)\n",
      "Iter 15640 | Time 23.6542(24.5099) | Bit/dim 3.3708(3.3672) | Xent 0.0000(0.0000) | Loss 8.8892(9.5794) | Error 0.0000(0.0000) Steps 928(939.12) | Grad Norm 0.6954(0.9502) | Total Time 0.00(0.00)\n",
      "Iter 15650 | Time 24.9602(24.4864) | Bit/dim 3.3620(3.3668) | Xent 0.0000(0.0000) | Loss 8.7855(9.3794) | Error 0.0000(0.0000) Steps 946(936.71) | Grad Norm 0.5995(0.9168) | Total Time 0.00(0.00)\n",
      "Iter 15660 | Time 23.2302(24.3802) | Bit/dim 3.3541(3.3665) | Xent 0.0000(0.0000) | Loss 8.6630(9.2226) | Error 0.0000(0.0000) Steps 940(935.95) | Grad Norm 0.8317(0.8775) | Total Time 0.00(0.00)\n",
      "Iter 15670 | Time 25.0039(24.3638) | Bit/dim 3.3309(3.3647) | Xent 0.0000(0.0000) | Loss 8.7949(9.1267) | Error 0.0000(0.0000) Steps 976(938.38) | Grad Norm 1.1574(0.8885) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0285 | Time 115.6969, Epoch Time 1475.9048(1410.7981), Bit/dim 3.3693(best: 3.3638), Xent 0.0000, Loss 3.3693, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15680 | Time 23.6966(24.3730) | Bit/dim 3.3716(3.3617) | Xent 0.0000(0.0000) | Loss 8.9248(10.0011) | Error 0.0000(0.0000) Steps 928(937.61) | Grad Norm 1.0188(0.8956) | Total Time 0.00(0.00)\n",
      "Iter 15690 | Time 23.2288(24.4069) | Bit/dim 3.3890(3.3629) | Xent 0.0000(0.0000) | Loss 8.9290(9.6948) | Error 0.0000(0.0000) Steps 916(938.15) | Grad Norm 1.2066(0.9296) | Total Time 0.00(0.00)\n",
      "Iter 15700 | Time 24.5304(24.4354) | Bit/dim 3.3584(3.3606) | Xent 0.0000(0.0000) | Loss 8.7418(9.4624) | Error 0.0000(0.0000) Steps 976(943.89) | Grad Norm 1.2431(0.9491) | Total Time 0.00(0.00)\n",
      "Iter 15710 | Time 25.3909(24.5008) | Bit/dim 3.4098(3.3594) | Xent 0.0000(0.0000) | Loss 9.0269(9.2930) | Error 0.0000(0.0000) Steps 964(943.21) | Grad Norm 0.8140(0.9516) | Total Time 0.00(0.00)\n",
      "Iter 15720 | Time 23.9705(24.4876) | Bit/dim 3.3720(3.3616) | Xent 0.0000(0.0000) | Loss 8.7152(9.1754) | Error 0.0000(0.0000) Steps 934(939.30) | Grad Norm 0.7615(0.9697) | Total Time 0.00(0.00)\n",
      "Iter 15730 | Time 24.4507(24.4331) | Bit/dim 3.3661(3.3632) | Xent 0.0000(0.0000) | Loss 8.8883(9.0877) | Error 0.0000(0.0000) Steps 928(938.35) | Grad Norm 0.9726(0.9900) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0286 | Time 115.1198, Epoch Time 1479.5254(1412.8599), Bit/dim 3.3652(best: 3.3638), Xent 0.0000, Loss 3.3652, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15740 | Time 25.0641(24.4117) | Bit/dim 3.3587(3.3644) | Xent 0.0000(0.0000) | Loss 8.8727(9.8407) | Error 0.0000(0.0000) Steps 976(940.77) | Grad Norm 0.9030(0.9771) | Total Time 0.00(0.00)\n",
      "Iter 15750 | Time 24.9461(24.4118) | Bit/dim 3.3514(3.3650) | Xent 0.0000(0.0000) | Loss 8.6411(9.5707) | Error 0.0000(0.0000) Steps 916(940.56) | Grad Norm 0.9543(0.9808) | Total Time 0.00(0.00)\n",
      "Iter 15760 | Time 24.3846(24.3875) | Bit/dim 3.3797(3.3639) | Xent 0.0000(0.0000) | Loss 8.8072(9.3770) | Error 0.0000(0.0000) Steps 916(938.91) | Grad Norm 0.8824(0.9554) | Total Time 0.00(0.00)\n",
      "Iter 15770 | Time 23.4865(24.3951) | Bit/dim 3.3724(3.3629) | Xent 0.0000(0.0000) | Loss 8.7570(9.2283) | Error 0.0000(0.0000) Steps 940(940.88) | Grad Norm 1.0413(0.9500) | Total Time 0.00(0.00)\n",
      "Iter 15780 | Time 25.3568(24.3393) | Bit/dim 3.3580(3.3624) | Xent 0.0000(0.0000) | Loss 8.7752(9.1189) | Error 0.0000(0.0000) Steps 982(939.38) | Grad Norm 1.2975(0.9567) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0287 | Time 115.0187, Epoch Time 1468.5975(1414.5320), Bit/dim 3.3712(best: 3.3638), Xent 0.0000, Loss 3.3712, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15790 | Time 24.5681(24.2241) | Bit/dim 3.3922(3.3642) | Xent 0.0000(0.0000) | Loss 8.9211(10.0101) | Error 0.0000(0.0000) Steps 964(937.31) | Grad Norm 0.8964(0.9550) | Total Time 0.00(0.00)\n",
      "Iter 15800 | Time 24.3883(24.1845) | Bit/dim 3.3759(3.3628) | Xent 0.0000(0.0000) | Loss 8.8007(9.6968) | Error 0.0000(0.0000) Steps 964(938.13) | Grad Norm 0.7533(0.9558) | Total Time 0.00(0.00)\n",
      "Iter 15810 | Time 24.9889(24.2450) | Bit/dim 3.3450(3.3650) | Xent 0.0000(0.0000) | Loss 8.8867(9.4878) | Error 0.0000(0.0000) Steps 964(944.09) | Grad Norm 0.9606(0.9666) | Total Time 0.00(0.00)\n",
      "Iter 15820 | Time 24.1423(24.2173) | Bit/dim 3.3535(3.3590) | Xent 0.0000(0.0000) | Loss 8.8815(9.3043) | Error 0.0000(0.0000) Steps 952(939.71) | Grad Norm 0.8500(0.9585) | Total Time 0.00(0.00)\n",
      "Iter 15830 | Time 24.6837(24.2954) | Bit/dim 3.3770(3.3607) | Xent 0.0000(0.0000) | Loss 8.8248(9.1693) | Error 0.0000(0.0000) Steps 904(935.55) | Grad Norm 1.3317(0.9875) | Total Time 0.00(0.00)\n",
      "Iter 15840 | Time 24.1694(24.3171) | Bit/dim 3.3513(3.3632) | Xent 0.0000(0.0000) | Loss 8.8209(9.0815) | Error 0.0000(0.0000) Steps 916(934.08) | Grad Norm 0.7148(0.9714) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0288 | Time 114.0345, Epoch Time 1468.1184(1416.1396), Bit/dim 3.3705(best: 3.3638), Xent 0.0000, Loss 3.3705, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15850 | Time 25.6918(24.3331) | Bit/dim 3.3648(3.3624) | Xent 0.0000(0.0000) | Loss 8.8094(9.8230) | Error 0.0000(0.0000) Steps 904(935.35) | Grad Norm 0.9641(0.9906) | Total Time 0.00(0.00)\n",
      "Iter 15860 | Time 23.7247(24.3674) | Bit/dim 3.3604(3.3647) | Xent 0.0000(0.0000) | Loss 8.9433(9.5684) | Error 0.0000(0.0000) Steps 958(934.14) | Grad Norm 0.9916(1.0749) | Total Time 0.00(0.00)\n",
      "Iter 15870 | Time 24.5107(24.3877) | Bit/dim 3.3441(3.3655) | Xent 0.0000(0.0000) | Loss 8.8608(9.3726) | Error 0.0000(0.0000) Steps 958(935.77) | Grad Norm 0.9391(1.0873) | Total Time 0.00(0.00)\n",
      "Iter 15880 | Time 24.2029(24.3700) | Bit/dim 3.3549(3.3625) | Xent 0.0000(0.0000) | Loss 8.7941(9.2238) | Error 0.0000(0.0000) Steps 970(938.70) | Grad Norm 0.9137(1.0433) | Total Time 0.00(0.00)\n",
      "Iter 15890 | Time 23.9681(24.4028) | Bit/dim 3.3745(3.3653) | Xent 0.0000(0.0000) | Loss 8.8897(9.1258) | Error 0.0000(0.0000) Steps 958(939.47) | Grad Norm 1.2638(1.0350) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0289 | Time 116.2868, Epoch Time 1478.5096(1418.0107), Bit/dim 3.3685(best: 3.3638), Xent 0.0000, Loss 3.3685, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15900 | Time 23.9638(24.3848) | Bit/dim 3.3692(3.3636) | Xent 0.0000(0.0000) | Loss 8.7226(10.0075) | Error 0.0000(0.0000) Steps 940(935.71) | Grad Norm 1.0689(1.0210) | Total Time 0.00(0.00)\n",
      "Iter 15910 | Time 24.8884(24.5476) | Bit/dim 3.3882(3.3647) | Xent 0.0000(0.0000) | Loss 8.9113(9.7025) | Error 0.0000(0.0000) Steps 988(942.63) | Grad Norm 1.1262(1.0069) | Total Time 0.00(0.00)\n",
      "Iter 15920 | Time 23.7800(24.5141) | Bit/dim 3.3479(3.3665) | Xent 0.0000(0.0000) | Loss 8.8522(9.4755) | Error 0.0000(0.0000) Steps 952(943.31) | Grad Norm 1.0032(1.0532) | Total Time 0.00(0.00)\n",
      "Iter 15930 | Time 24.1824(24.4773) | Bit/dim 3.3482(3.3627) | Xent 0.0000(0.0000) | Loss 8.7341(9.2878) | Error 0.0000(0.0000) Steps 946(941.91) | Grad Norm 1.0585(1.0178) | Total Time 0.00(0.00)\n",
      "Iter 15940 | Time 25.5289(24.5328) | Bit/dim 3.3377(3.3631) | Xent 0.0000(0.0000) | Loss 8.8626(9.1628) | Error 0.0000(0.0000) Steps 988(942.20) | Grad Norm 1.4940(1.0591) | Total Time 0.00(0.00)\n",
      "Iter 15950 | Time 23.9552(24.4646) | Bit/dim 3.3626(3.3627) | Xent 0.0000(0.0000) | Loss 8.6956(9.0654) | Error 0.0000(0.0000) Steps 934(940.22) | Grad Norm 0.7424(1.1019) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0290 | Time 114.1238, Epoch Time 1481.2613(1419.9082), Bit/dim 3.3677(best: 3.3638), Xent 0.0000, Loss 3.3677, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15960 | Time 24.4630(24.4081) | Bit/dim 3.3930(3.3634) | Xent 0.0000(0.0000) | Loss 8.8684(9.8236) | Error 0.0000(0.0000) Steps 904(937.49) | Grad Norm 1.4768(1.1144) | Total Time 0.00(0.00)\n",
      "Iter 15970 | Time 24.7823(24.4843) | Bit/dim 3.3552(3.3637) | Xent 0.0000(0.0000) | Loss 8.6870(9.5577) | Error 0.0000(0.0000) Steps 922(937.75) | Grad Norm 1.2532(1.1536) | Total Time 0.00(0.00)\n",
      "Iter 15980 | Time 24.0543(24.5164) | Bit/dim 3.3878(3.3635) | Xent 0.0000(0.0000) | Loss 8.9100(9.3636) | Error 0.0000(0.0000) Steps 934(937.55) | Grad Norm 0.8687(1.0859) | Total Time 0.00(0.00)\n",
      "Iter 15990 | Time 23.8528(24.3909) | Bit/dim 3.3579(3.3630) | Xent 0.0000(0.0000) | Loss 8.7953(9.2129) | Error 0.0000(0.0000) Steps 970(936.45) | Grad Norm 0.7911(1.0751) | Total Time 0.00(0.00)\n",
      "Iter 16000 | Time 23.4422(24.3596) | Bit/dim 3.3379(3.3616) | Xent 0.0000(0.0000) | Loss 8.7219(9.1044) | Error 0.0000(0.0000) Steps 940(936.45) | Grad Norm 0.7651(0.9885) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0291 | Time 115.2567, Epoch Time 1474.6433(1421.5503), Bit/dim 3.3666(best: 3.3638), Xent 0.0000, Loss 3.3666, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16010 | Time 24.0170(24.3323) | Bit/dim 3.3534(3.3624) | Xent 0.0000(0.0000) | Loss 8.8236(9.9931) | Error 0.0000(0.0000) Steps 958(939.08) | Grad Norm 0.8048(0.9601) | Total Time 0.00(0.00)\n",
      "Iter 16020 | Time 24.8730(24.4129) | Bit/dim 3.3382(3.3614) | Xent 0.0000(0.0000) | Loss 8.7109(9.6801) | Error 0.0000(0.0000) Steps 982(939.89) | Grad Norm 1.3349(0.9842) | Total Time 0.00(0.00)\n",
      "Iter 16030 | Time 25.1730(24.4474) | Bit/dim 3.3420(3.3636) | Xent 0.0000(0.0000) | Loss 8.9064(9.4631) | Error 0.0000(0.0000) Steps 922(937.84) | Grad Norm 1.3441(0.9995) | Total Time 0.00(0.00)\n",
      "Iter 16040 | Time 23.6004(24.5201) | Bit/dim 3.3255(3.3605) | Xent 0.0000(0.0000) | Loss 8.7687(9.2874) | Error 0.0000(0.0000) Steps 934(939.82) | Grad Norm 0.9255(1.1080) | Total Time 0.00(0.00)\n",
      "Iter 16050 | Time 24.1856(24.4519) | Bit/dim 3.3641(3.3605) | Xent 0.0000(0.0000) | Loss 8.7262(9.1509) | Error 0.0000(0.0000) Steps 940(940.77) | Grad Norm 1.0509(1.1173) | Total Time 0.00(0.00)\n",
      "Iter 16060 | Time 25.2306(24.4493) | Bit/dim 3.3399(3.3618) | Xent 0.0000(0.0000) | Loss 8.7915(9.0557) | Error 0.0000(0.0000) Steps 904(937.38) | Grad Norm 0.9008(1.0774) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0292 | Time 116.7085, Epoch Time 1482.4794(1423.3782), Bit/dim 3.3695(best: 3.3638), Xent 0.0000, Loss 3.3695, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16070 | Time 23.7699(24.3532) | Bit/dim 3.3674(3.3624) | Xent 0.0000(0.0000) | Loss 8.8453(9.8341) | Error 0.0000(0.0000) Steps 964(942.78) | Grad Norm 1.1490(1.0739) | Total Time 0.00(0.00)\n",
      "Iter 16080 | Time 24.5475(24.4095) | Bit/dim 3.3765(3.3657) | Xent 0.0000(0.0000) | Loss 8.7147(9.5720) | Error 0.0000(0.0000) Steps 934(945.38) | Grad Norm 1.0344(1.0812) | Total Time 0.00(0.00)\n",
      "Iter 16090 | Time 24.2934(24.3855) | Bit/dim 3.3652(3.3650) | Xent 0.0000(0.0000) | Loss 8.8749(9.3803) | Error 0.0000(0.0000) Steps 946(942.82) | Grad Norm 1.3954(1.1127) | Total Time 0.00(0.00)\n",
      "Iter 16100 | Time 24.4311(24.3462) | Bit/dim 3.3590(3.3636) | Xent 0.0000(0.0000) | Loss 8.8467(9.2296) | Error 0.0000(0.0000) Steps 952(941.30) | Grad Norm 1.7333(1.2477) | Total Time 0.00(0.00)\n",
      "Iter 16110 | Time 23.9760(24.3832) | Bit/dim 3.3780(3.3603) | Xent 0.0000(0.0000) | Loss 8.8289(9.1157) | Error 0.0000(0.0000) Steps 940(943.18) | Grad Norm 1.0411(1.2932) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0293 | Time 115.4459, Epoch Time 1474.0415(1424.8981), Bit/dim 3.3692(best: 3.3638), Xent 0.0000, Loss 3.3692, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16120 | Time 24.4885(24.4664) | Bit/dim 3.3767(3.3628) | Xent 0.0000(0.0000) | Loss 8.8287(10.0146) | Error 0.0000(0.0000) Steps 934(941.38) | Grad Norm 1.2368(1.2628) | Total Time 0.00(0.00)\n",
      "Iter 16130 | Time 23.9983(24.4704) | Bit/dim 3.3423(3.3607) | Xent 0.0000(0.0000) | Loss 8.8771(9.7003) | Error 0.0000(0.0000) Steps 946(942.47) | Grad Norm 0.7828(1.2189) | Total Time 0.00(0.00)\n",
      "Iter 16140 | Time 24.6034(24.4781) | Bit/dim 3.3859(3.3641) | Xent 0.0000(0.0000) | Loss 9.0263(9.4880) | Error 0.0000(0.0000) Steps 958(946.07) | Grad Norm 0.8943(1.1711) | Total Time 0.00(0.00)\n",
      "Iter 16150 | Time 25.4369(24.5880) | Bit/dim 3.3582(3.3633) | Xent 0.0000(0.0000) | Loss 8.8552(9.3118) | Error 0.0000(0.0000) Steps 958(948.32) | Grad Norm 1.3887(1.1906) | Total Time 0.00(0.00)\n",
      "Iter 16160 | Time 24.7267(24.7648) | Bit/dim 3.3747(3.3626) | Xent 0.0000(0.0000) | Loss 8.9280(9.1821) | Error 0.0000(0.0000) Steps 928(950.74) | Grad Norm 1.0558(1.1589) | Total Time 0.00(0.00)\n",
      "Iter 16170 | Time 23.4359(24.7938) | Bit/dim 3.3445(3.3619) | Xent 0.0000(0.0000) | Loss 8.6816(9.0808) | Error 0.0000(0.0000) Steps 922(948.17) | Grad Norm 1.4634(1.1519) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0294 | Time 115.6575, Epoch Time 1499.0100(1427.1214), Bit/dim 3.3671(best: 3.3638), Xent 0.0000, Loss 3.3671, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16180 | Time 25.4134(24.8145) | Bit/dim 3.3894(3.3614) | Xent 0.0000(0.0000) | Loss 8.8174(9.8475) | Error 0.0000(0.0000) Steps 976(947.70) | Grad Norm 1.1148(1.1569) | Total Time 0.00(0.00)\n",
      "Iter 16190 | Time 25.8446(24.7779) | Bit/dim 3.3634(3.3626) | Xent 0.0000(0.0000) | Loss 8.8770(9.5803) | Error 0.0000(0.0000) Steps 946(947.54) | Grad Norm 1.0884(1.1115) | Total Time 0.00(0.00)\n",
      "Iter 16200 | Time 23.5462(24.6065) | Bit/dim 3.3781(3.3642) | Xent 0.0000(0.0000) | Loss 8.7135(9.3784) | Error 0.0000(0.0000) Steps 922(944.06) | Grad Norm 0.8637(1.0578) | Total Time 0.00(0.00)\n",
      "Iter 16210 | Time 25.0351(24.5929) | Bit/dim 3.3625(3.3627) | Xent 0.0000(0.0000) | Loss 8.8138(9.2341) | Error 0.0000(0.0000) Steps 934(944.02) | Grad Norm 0.6753(1.0059) | Total Time 0.00(0.00)\n",
      "Iter 16220 | Time 24.1890(24.6341) | Bit/dim 3.3546(3.3605) | Xent 0.0000(0.0000) | Loss 8.8124(9.1257) | Error 0.0000(0.0000) Steps 940(944.32) | Grad Norm 1.2777(1.0052) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0295 | Time 116.9583, Epoch Time 1492.0717(1429.0699), Bit/dim 3.3673(best: 3.3638), Xent 0.0000, Loss 3.3673, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16230 | Time 24.3962(24.7095) | Bit/dim 3.3409(3.3604) | Xent 0.0000(0.0000) | Loss 8.8663(10.0006) | Error 0.0000(0.0000) Steps 940(942.41) | Grad Norm 1.5180(1.0253) | Total Time 0.00(0.00)\n",
      "Iter 16240 | Time 25.8523(24.8983) | Bit/dim 3.3960(3.3663) | Xent 0.0000(0.0000) | Loss 9.0754(9.6944) | Error 0.0000(0.0000) Steps 994(943.74) | Grad Norm 1.1516(1.0396) | Total Time 0.00(0.00)\n",
      "Iter 16250 | Time 24.5173(24.8111) | Bit/dim 3.3541(3.3653) | Xent 0.0000(0.0000) | Loss 8.8808(9.4685) | Error 0.0000(0.0000) Steps 964(945.68) | Grad Norm 1.0553(1.0434) | Total Time 0.00(0.00)\n",
      "Iter 16260 | Time 23.6690(24.7339) | Bit/dim 3.3288(3.3616) | Xent 0.0000(0.0000) | Loss 8.7328(9.2883) | Error 0.0000(0.0000) Steps 904(944.10) | Grad Norm 1.4564(1.0666) | Total Time 0.00(0.00)\n",
      "Iter 16270 | Time 26.3578(24.7451) | Bit/dim 3.3699(3.3611) | Xent 0.0000(0.0000) | Loss 8.8559(9.1671) | Error 0.0000(0.0000) Steps 994(947.17) | Grad Norm 1.2931(1.0530) | Total Time 0.00(0.00)\n",
      "Iter 16280 | Time 24.8813(24.7816) | Bit/dim 3.3479(3.3590) | Xent 0.0000(0.0000) | Loss 8.7967(9.0642) | Error 0.0000(0.0000) Steps 958(944.37) | Grad Norm 1.1887(1.0649) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0296 | Time 117.1689, Epoch Time 1500.2279(1431.2047), Bit/dim 3.3687(best: 3.3638), Xent 0.0000, Loss 3.3687, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16290 | Time 25.6353(24.7795) | Bit/dim 3.3694(3.3606) | Xent 0.0000(0.0000) | Loss 8.7212(9.8088) | Error 0.0000(0.0000) Steps 970(944.30) | Grad Norm 2.0830(1.1970) | Total Time 0.00(0.00)\n",
      "Iter 16300 | Time 23.8926(24.7040) | Bit/dim 3.3542(3.3601) | Xent 0.0000(0.0000) | Loss 8.8657(9.5454) | Error 0.0000(0.0000) Steps 940(941.55) | Grad Norm 1.4265(1.2727) | Total Time 0.00(0.00)\n",
      "Iter 16310 | Time 28.1762(24.8366) | Bit/dim 3.3809(3.3621) | Xent 0.0000(0.0000) | Loss 8.7590(9.3580) | Error 0.0000(0.0000) Steps 922(941.40) | Grad Norm 0.9902(1.2701) | Total Time 0.00(0.00)\n",
      "Iter 16320 | Time 24.3662(24.8328) | Bit/dim 3.3627(3.3625) | Xent 0.0000(0.0000) | Loss 8.8038(9.2205) | Error 0.0000(0.0000) Steps 898(937.81) | Grad Norm 0.8977(1.1897) | Total Time 0.00(0.00)\n",
      "Iter 16330 | Time 25.4530(24.8018) | Bit/dim 3.3846(3.3626) | Xent 0.0000(0.0000) | Loss 8.9063(9.1181) | Error 0.0000(0.0000) Steps 910(938.33) | Grad Norm 1.1311(1.1552) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0297 | Time 115.6598, Epoch Time 1498.7586(1433.2313), Bit/dim 3.3674(best: 3.3638), Xent 0.0000, Loss 3.3674, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16340 | Time 24.0023(24.8381) | Bit/dim 3.3806(3.3609) | Xent 0.0000(0.0000) | Loss 8.8284(9.9963) | Error 0.0000(0.0000) Steps 922(939.58) | Grad Norm 0.8520(1.1163) | Total Time 0.00(0.00)\n",
      "Iter 16350 | Time 25.0442(24.8693) | Bit/dim 3.3654(3.3625) | Xent 0.0000(0.0000) | Loss 8.8498(9.6895) | Error 0.0000(0.0000) Steps 928(939.36) | Grad Norm 0.9509(1.0865) | Total Time 0.00(0.00)\n",
      "Iter 16360 | Time 24.5097(24.7466) | Bit/dim 3.3656(3.3620) | Xent 0.0000(0.0000) | Loss 8.8128(9.4626) | Error 0.0000(0.0000) Steps 910(939.46) | Grad Norm 1.2640(1.0996) | Total Time 0.00(0.00)\n",
      "Iter 16370 | Time 23.9932(24.7632) | Bit/dim 3.3634(3.3626) | Xent 0.0000(0.0000) | Loss 8.7967(9.2857) | Error 0.0000(0.0000) Steps 946(939.59) | Grad Norm 1.2570(1.0988) | Total Time 0.00(0.00)\n",
      "Iter 16380 | Time 25.1154(24.8489) | Bit/dim 3.3686(3.3647) | Xent 0.0000(0.0000) | Loss 8.8261(9.1724) | Error 0.0000(0.0000) Steps 922(940.97) | Grad Norm 0.8803(1.1227) | Total Time 0.00(0.00)\n",
      "Iter 16390 | Time 24.7211(24.8188) | Bit/dim 3.3908(3.3611) | Xent 0.0000(0.0000) | Loss 8.9141(9.0764) | Error 0.0000(0.0000) Steps 970(943.44) | Grad Norm 0.9557(1.1029) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0298 | Time 116.0744, Epoch Time 1499.4685(1435.2184), Bit/dim 3.3693(best: 3.3638), Xent 0.0000, Loss 3.3693, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16400 | Time 24.6946(24.8590) | Bit/dim 3.3540(3.3634) | Xent 0.0000(0.0000) | Loss 8.6753(9.8566) | Error 0.0000(0.0000) Steps 940(942.68) | Grad Norm 1.0266(1.0489) | Total Time 0.00(0.00)\n",
      "Iter 16410 | Time 25.6278(24.9128) | Bit/dim 3.3679(3.3609) | Xent 0.0000(0.0000) | Loss 8.9136(9.5892) | Error 0.0000(0.0000) Steps 1000(945.99) | Grad Norm 1.2834(1.1395) | Total Time 0.00(0.00)\n",
      "Iter 16420 | Time 24.9079(24.8648) | Bit/dim 3.4063(3.3630) | Xent 0.0000(0.0000) | Loss 8.9272(9.4034) | Error 0.0000(0.0000) Steps 964(949.14) | Grad Norm 1.3546(1.1710) | Total Time 0.00(0.00)\n",
      "Iter 16430 | Time 24.9500(24.8519) | Bit/dim 3.3497(3.3646) | Xent 0.0000(0.0000) | Loss 8.8599(9.2455) | Error 0.0000(0.0000) Steps 970(946.57) | Grad Norm 1.3128(1.2022) | Total Time 0.00(0.00)\n",
      "Iter 16440 | Time 25.6689(24.7426) | Bit/dim 3.3624(3.3626) | Xent 0.0000(0.0000) | Loss 8.8961(9.1310) | Error 0.0000(0.0000) Steps 934(946.30) | Grad Norm 1.9579(1.2826) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0299 | Time 117.2489, Epoch Time 1499.7502(1437.1543), Bit/dim 3.3655(best: 3.3638), Xent 0.0000, Loss 3.3655, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16450 | Time 27.2340(24.8015) | Bit/dim 3.3751(3.3612) | Xent 0.0000(0.0000) | Loss 8.8039(10.0212) | Error 0.0000(0.0000) Steps 928(946.34) | Grad Norm 1.0455(1.2427) | Total Time 0.00(0.00)\n",
      "Iter 16460 | Time 24.6095(24.7881) | Bit/dim 3.3853(3.3631) | Xent 0.0000(0.0000) | Loss 8.7925(9.7034) | Error 0.0000(0.0000) Steps 922(941.90) | Grad Norm 1.3394(1.2301) | Total Time 0.00(0.00)\n",
      "Iter 16470 | Time 24.0971(24.9283) | Bit/dim 3.3596(3.3632) | Xent 0.0000(0.0000) | Loss 8.8483(9.4911) | Error 0.0000(0.0000) Steps 946(943.11) | Grad Norm 1.1291(1.2759) | Total Time 0.00(0.00)\n",
      "Iter 16480 | Time 25.2667(24.9046) | Bit/dim 3.3762(3.3607) | Xent 0.0000(0.0000) | Loss 8.9214(9.3082) | Error 0.0000(0.0000) Steps 1000(941.53) | Grad Norm 1.0952(1.3137) | Total Time 0.00(0.00)\n",
      "Iter 16490 | Time 24.1511(24.8422) | Bit/dim 3.3793(3.3607) | Xent 0.0000(0.0000) | Loss 8.9238(9.1754) | Error 0.0000(0.0000) Steps 898(938.06) | Grad Norm 1.1796(1.2954) | Total Time 0.00(0.00)\n",
      "Iter 16500 | Time 24.3035(24.8292) | Bit/dim 3.3691(3.3640) | Xent 0.0000(0.0000) | Loss 8.7452(9.0824) | Error 0.0000(0.0000) Steps 952(938.86) | Grad Norm 1.0819(1.2348) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0300 | Time 117.2667, Epoch Time 1505.5120(1439.2051), Bit/dim 3.3730(best: 3.3638), Xent 0.0000, Loss 3.3730, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16510 | Time 25.4427(24.8813) | Bit/dim 3.3847(3.3637) | Xent 0.0000(0.0000) | Loss 8.9749(9.8492) | Error 0.0000(0.0000) Steps 982(941.24) | Grad Norm 1.5196(1.2388) | Total Time 0.00(0.00)\n",
      "Iter 16520 | Time 25.2201(24.8337) | Bit/dim 3.3346(3.3629) | Xent 0.0000(0.0000) | Loss 8.7731(9.5762) | Error 0.0000(0.0000) Steps 928(940.91) | Grad Norm 1.2925(1.3512) | Total Time 0.00(0.00)\n",
      "Iter 16530 | Time 25.7214(24.9350) | Bit/dim 3.3870(3.3638) | Xent 0.0000(0.0000) | Loss 8.7838(9.3862) | Error 0.0000(0.0000) Steps 964(943.23) | Grad Norm 1.2261(1.3543) | Total Time 0.00(0.00)\n",
      "Iter 16540 | Time 24.8457(25.0596) | Bit/dim 3.3719(3.3638) | Xent 0.0000(0.0000) | Loss 8.8964(9.2491) | Error 0.0000(0.0000) Steps 946(942.97) | Grad Norm 1.2671(1.3377) | Total Time 0.00(0.00)\n",
      "Iter 16550 | Time 25.1302(24.9255) | Bit/dim 3.3540(3.3645) | Xent 0.0000(0.0000) | Loss 8.7171(9.1370) | Error 0.0000(0.0000) Steps 970(943.94) | Grad Norm 1.2773(1.2659) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0301 | Time 115.6299, Epoch Time 1511.9350(1441.3870), Bit/dim 3.3677(best: 3.3638), Xent 0.0000, Loss 3.3677, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16560 | Time 24.6115(25.1060) | Bit/dim 3.3990(3.3641) | Xent 0.0000(0.0000) | Loss 8.9514(10.0477) | Error 0.0000(0.0000) Steps 982(949.87) | Grad Norm 1.1030(1.2351) | Total Time 0.00(0.00)\n",
      "Iter 16570 | Time 24.5523(25.0876) | Bit/dim 3.3974(3.3635) | Xent 0.0000(0.0000) | Loss 8.6946(9.7163) | Error 0.0000(0.0000) Steps 910(946.21) | Grad Norm 1.9340(1.2344) | Total Time 0.00(0.00)\n",
      "Iter 16580 | Time 24.9008(25.1564) | Bit/dim 3.3298(3.3605) | Xent 0.0000(0.0000) | Loss 8.6570(9.4774) | Error 0.0000(0.0000) Steps 976(949.81) | Grad Norm 1.6765(1.2787) | Total Time 0.00(0.00)\n",
      "Iter 16590 | Time 24.1184(25.0466) | Bit/dim 3.3711(3.3633) | Xent 0.0000(0.0000) | Loss 8.8532(9.3196) | Error 0.0000(0.0000) Steps 928(950.00) | Grad Norm 1.5747(1.2384) | Total Time 0.00(0.00)\n",
      "Iter 16600 | Time 24.7598(25.0299) | Bit/dim 3.3171(3.3594) | Xent 0.0000(0.0000) | Loss 8.8612(9.1907) | Error 0.0000(0.0000) Steps 964(950.07) | Grad Norm 1.1865(1.2459) | Total Time 0.00(0.00)\n",
      "Iter 16610 | Time 23.6111(25.0011) | Bit/dim 3.3832(3.3605) | Xent 0.0000(0.0000) | Loss 8.7990(9.0783) | Error 0.0000(0.0000) Steps 952(950.93) | Grad Norm 1.2239(1.3582) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0302 | Time 116.5713, Epoch Time 1514.3841(1443.5769), Bit/dim 3.3655(best: 3.3638), Xent 0.0000, Loss 3.3655, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16620 | Time 24.8730(25.0383) | Bit/dim 3.3147(3.3580) | Xent 0.0000(0.0000) | Loss 8.7977(9.8133) | Error 0.0000(0.0000) Steps 952(947.91) | Grad Norm 1.6550(1.3966) | Total Time 0.00(0.00)\n",
      "Iter 16630 | Time 24.7101(25.0073) | Bit/dim 3.3486(3.3604) | Xent 0.0000(0.0000) | Loss 8.8707(9.5543) | Error 0.0000(0.0000) Steps 958(949.61) | Grad Norm 1.6860(1.3630) | Total Time 0.00(0.00)\n",
      "Iter 16640 | Time 25.5696(25.1065) | Bit/dim 3.3379(3.3604) | Xent 0.0000(0.0000) | Loss 8.8568(9.3728) | Error 0.0000(0.0000) Steps 952(953.60) | Grad Norm 1.3809(1.3562) | Total Time 0.00(0.00)\n",
      "Iter 16650 | Time 25.3733(25.1342) | Bit/dim 3.3762(3.3599) | Xent 0.0000(0.0000) | Loss 8.7822(9.2189) | Error 0.0000(0.0000) Steps 910(950.02) | Grad Norm 1.6170(1.4425) | Total Time 0.00(0.00)\n",
      "Iter 16660 | Time 24.2070(25.0656) | Bit/dim 3.3485(3.3615) | Xent 0.0000(0.0000) | Loss 8.6561(9.1052) | Error 0.0000(0.0000) Steps 970(950.44) | Grad Norm 1.4158(1.4274) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0303 | Time 116.5292, Epoch Time 1518.2746(1445.8178), Bit/dim 3.3648(best: 3.3638), Xent 0.0000, Loss 3.3648, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16670 | Time 24.7041(25.1390) | Bit/dim 3.3768(3.3621) | Xent 0.0000(0.0000) | Loss 8.9629(10.0276) | Error 0.0000(0.0000) Steps 976(951.12) | Grad Norm 1.6124(1.4723) | Total Time 0.00(0.00)\n",
      "Iter 16680 | Time 24.7807(25.1271) | Bit/dim 3.3915(3.3653) | Xent 0.0000(0.0000) | Loss 8.9473(9.7146) | Error 0.0000(0.0000) Steps 958(951.82) | Grad Norm 1.5065(1.4516) | Total Time 0.00(0.00)\n",
      "Iter 16690 | Time 25.8381(25.1830) | Bit/dim 3.3337(3.3638) | Xent 0.0000(0.0000) | Loss 8.6677(9.4795) | Error 0.0000(0.0000) Steps 940(951.01) | Grad Norm 1.5514(1.4127) | Total Time 0.00(0.00)\n",
      "Iter 16700 | Time 25.2155(25.2180) | Bit/dim 3.3729(3.3635) | Xent 0.0000(0.0000) | Loss 8.9138(9.3171) | Error 0.0000(0.0000) Steps 976(952.08) | Grad Norm 1.0081(1.3453) | Total Time 0.00(0.00)\n",
      "Iter 16710 | Time 24.9959(25.1562) | Bit/dim 3.3410(3.3624) | Xent 0.0000(0.0000) | Loss 8.7922(9.1923) | Error 0.0000(0.0000) Steps 964(951.97) | Grad Norm 1.5720(1.3604) | Total Time 0.00(0.00)\n",
      "Iter 16720 | Time 25.4012(25.3087) | Bit/dim 3.3398(3.3621) | Xent 0.0000(0.0000) | Loss 8.7404(9.0916) | Error 0.0000(0.0000) Steps 922(952.77) | Grad Norm 1.3377(1.3510) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0304 | Time 118.0198, Epoch Time 1527.2739(1448.2615), Bit/dim 3.3668(best: 3.3638), Xent 0.0000, Loss 3.3668, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16730 | Time 24.8164(25.3678) | Bit/dim 3.3666(3.3650) | Xent 0.0000(0.0000) | Loss 8.8473(9.8258) | Error 0.0000(0.0000) Steps 952(954.04) | Grad Norm 0.9940(1.2968) | Total Time 0.00(0.00)\n",
      "Iter 16740 | Time 25.2262(25.3453) | Bit/dim 3.3607(3.3620) | Xent 0.0000(0.0000) | Loss 8.8893(9.5620) | Error 0.0000(0.0000) Steps 958(953.69) | Grad Norm 1.3489(1.3995) | Total Time 0.00(0.00)\n",
      "Iter 16750 | Time 25.1466(25.4475) | Bit/dim 3.3348(3.3597) | Xent 0.0000(0.0000) | Loss 8.7472(9.3602) | Error 0.0000(0.0000) Steps 898(951.91) | Grad Norm 1.4513(1.5122) | Total Time 0.00(0.00)\n",
      "Iter 16760 | Time 25.0333(25.4313) | Bit/dim 3.3816(3.3613) | Xent 0.0000(0.0000) | Loss 8.8311(9.2175) | Error 0.0000(0.0000) Steps 946(952.98) | Grad Norm 1.4453(1.5603) | Total Time 0.00(0.00)\n",
      "Iter 16770 | Time 25.1121(25.4557) | Bit/dim 3.3467(3.3618) | Xent 0.0000(0.0000) | Loss 8.7295(9.1100) | Error 0.0000(0.0000) Steps 934(953.19) | Grad Norm 1.5073(1.6429) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0305 | Time 118.2608, Epoch Time 1541.7227(1451.0653), Bit/dim 3.3665(best: 3.3638), Xent 0.0000, Loss 3.3665, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16780 | Time 24.6703(25.5035) | Bit/dim 3.3725(3.3595) | Xent 0.0000(0.0000) | Loss 8.8049(10.0042) | Error 0.0000(0.0000) Steps 916(953.88) | Grad Norm 2.7835(1.8740) | Total Time 0.00(0.00)\n",
      "Iter 16790 | Time 24.6181(25.5203) | Bit/dim 3.3359(3.3623) | Xent 0.0000(0.0000) | Loss 8.7707(9.6921) | Error 0.0000(0.0000) Steps 964(956.47) | Grad Norm 1.7339(1.8119) | Total Time 0.00(0.00)\n",
      "Iter 16800 | Time 25.0014(25.4611) | Bit/dim 3.3559(3.3596) | Xent 0.0000(0.0000) | Loss 8.8801(9.4662) | Error 0.0000(0.0000) Steps 940(956.37) | Grad Norm 1.0490(1.6874) | Total Time 0.00(0.00)\n",
      "Iter 16810 | Time 25.7214(25.5225) | Bit/dim 3.3260(3.3602) | Xent 0.0000(0.0000) | Loss 8.8179(9.3054) | Error 0.0000(0.0000) Steps 964(957.19) | Grad Norm 0.9404(1.5415) | Total Time 0.00(0.00)\n",
      "Iter 16820 | Time 25.6453(25.5664) | Bit/dim 3.3640(3.3600) | Xent 0.0000(0.0000) | Loss 8.8419(9.1640) | Error 0.0000(0.0000) Steps 976(955.79) | Grad Norm 0.9261(1.4140) | Total Time 0.00(0.00)\n",
      "Iter 16830 | Time 26.1066(25.6194) | Bit/dim 3.3801(3.3618) | Xent 0.0000(0.0000) | Loss 8.8664(9.0834) | Error 0.0000(0.0000) Steps 952(956.74) | Grad Norm 1.2496(1.3210) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0306 | Time 116.4606, Epoch Time 1542.5978(1453.8113), Bit/dim 3.3701(best: 3.3638), Xent 0.0000, Loss 3.3701, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16840 | Time 27.6807(25.5738) | Bit/dim 3.3618(3.3618) | Xent 0.0000(0.0000) | Loss 8.8839(9.8647) | Error 0.0000(0.0000) Steps 964(956.68) | Grad Norm 0.9051(1.3162) | Total Time 0.00(0.00)\n",
      "Iter 16850 | Time 25.0391(25.5378) | Bit/dim 3.3533(3.3613) | Xent 0.0000(0.0000) | Loss 8.8224(9.5940) | Error 0.0000(0.0000) Steps 976(958.86) | Grad Norm 1.4220(1.3621) | Total Time 0.00(0.00)\n",
      "Iter 16860 | Time 25.2719(25.5397) | Bit/dim 3.3721(3.3587) | Xent 0.0000(0.0000) | Loss 8.8518(9.3793) | Error 0.0000(0.0000) Steps 982(954.70) | Grad Norm 1.0028(1.5742) | Total Time 0.00(0.00)\n",
      "Iter 16870 | Time 24.6713(25.5039) | Bit/dim 3.3402(3.3611) | Xent 0.0000(0.0000) | Loss 8.6912(9.2232) | Error 0.0000(0.0000) Steps 946(953.71) | Grad Norm 2.9303(2.0719) | Total Time 0.00(0.00)\n",
      "Iter 16880 | Time 25.5055(25.4268) | Bit/dim 3.3474(3.3619) | Xent 0.0000(0.0000) | Loss 8.8416(9.1297) | Error 0.0000(0.0000) Steps 946(954.13) | Grad Norm 1.3182(2.0169) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0307 | Time 117.3416, Epoch Time 1534.2379(1456.2241), Bit/dim 3.3681(best: 3.3638), Xent 0.0000, Loss 3.3681, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16890 | Time 25.6886(25.4339) | Bit/dim 3.3229(3.3610) | Xent 0.0000(0.0000) | Loss 8.7647(10.0673) | Error 0.0000(0.0000) Steps 964(955.71) | Grad Norm 1.4018(1.8498) | Total Time 0.00(0.00)\n",
      "Iter 16900 | Time 27.0522(25.4999) | Bit/dim 3.3683(3.3613) | Xent 0.0000(0.0000) | Loss 8.9921(9.7437) | Error 0.0000(0.0000) Steps 946(958.01) | Grad Norm 1.1969(1.7144) | Total Time 0.00(0.00)\n",
      "Iter 16910 | Time 24.2627(25.4414) | Bit/dim 3.3927(3.3635) | Xent 0.0000(0.0000) | Loss 8.8756(9.5020) | Error 0.0000(0.0000) Steps 940(959.51) | Grad Norm 1.0826(1.5837) | Total Time 0.00(0.00)\n",
      "Iter 16920 | Time 25.9079(25.4555) | Bit/dim 3.3722(3.3625) | Xent 0.0000(0.0000) | Loss 8.9083(9.3259) | Error 0.0000(0.0000) Steps 988(960.92) | Grad Norm 1.2600(1.4790) | Total Time 0.00(0.00)\n",
      "Iter 16930 | Time 25.3019(25.4383) | Bit/dim 3.3727(3.3631) | Xent 0.0000(0.0000) | Loss 8.8422(9.2012) | Error 0.0000(0.0000) Steps 964(963.09) | Grad Norm 1.0224(1.4147) | Total Time 0.00(0.00)\n",
      "Iter 16940 | Time 25.3751(25.4851) | Bit/dim 3.3774(3.3658) | Xent 0.0000(0.0000) | Loss 8.9210(9.1103) | Error 0.0000(0.0000) Steps 952(964.20) | Grad Norm 1.3750(1.4373) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0308 | Time 116.3487, Epoch Time 1537.1965(1458.6533), Bit/dim 3.3661(best: 3.3638), Xent 0.0000, Loss 3.3661, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16950 | Time 29.0644(25.5011) | Bit/dim 3.3589(3.3664) | Xent 0.0000(0.0000) | Loss 8.7714(9.8744) | Error 0.0000(0.0000) Steps 970(961.05) | Grad Norm 1.1375(1.4285) | Total Time 0.00(0.00)\n",
      "Iter 16960 | Time 24.1340(25.4442) | Bit/dim 3.3555(3.3648) | Xent 0.0000(0.0000) | Loss 8.7302(9.6024) | Error 0.0000(0.0000) Steps 964(960.11) | Grad Norm 1.2952(1.4156) | Total Time 0.00(0.00)\n",
      "Iter 16970 | Time 25.3153(25.3836) | Bit/dim 3.3448(3.3612) | Xent 0.0000(0.0000) | Loss 8.8407(9.3910) | Error 0.0000(0.0000) Steps 946(954.74) | Grad Norm 1.0888(1.3536) | Total Time 0.00(0.00)\n",
      "Iter 16980 | Time 25.9339(25.3921) | Bit/dim 3.3407(3.3644) | Xent 0.0000(0.0000) | Loss 8.7613(9.2512) | Error 0.0000(0.0000) Steps 970(956.28) | Grad Norm 1.2437(1.3428) | Total Time 0.00(0.00)\n",
      "Iter 16990 | Time 25.8483(25.4277) | Bit/dim 3.3640(3.3642) | Xent 0.0000(0.0000) | Loss 8.8784(9.1399) | Error 0.0000(0.0000) Steps 952(956.37) | Grad Norm 1.2478(1.3814) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0309 | Time 117.0881, Epoch Time 1535.4746(1460.9579), Bit/dim 3.3703(best: 3.3638), Xent 0.0000, Loss 3.3703, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17000 | Time 25.7166(25.5509) | Bit/dim 3.3815(3.3659) | Xent 0.0000(0.0000) | Loss 9.0002(10.0451) | Error 0.0000(0.0000) Steps 958(961.85) | Grad Norm 0.9335(1.3149) | Total Time 0.00(0.00)\n",
      "Iter 17010 | Time 26.2909(25.5538) | Bit/dim 3.3261(3.3664) | Xent 0.0000(0.0000) | Loss 8.8907(9.7224) | Error 0.0000(0.0000) Steps 970(959.44) | Grad Norm 1.0105(1.2420) | Total Time 0.00(0.00)\n",
      "Iter 17020 | Time 25.5927(25.4738) | Bit/dim 3.4048(3.3675) | Xent 0.0000(0.0000) | Loss 8.8649(9.4856) | Error 0.0000(0.0000) Steps 904(960.08) | Grad Norm 1.9265(1.2636) | Total Time 0.00(0.00)\n",
      "Iter 17030 | Time 25.0481(25.5154) | Bit/dim 3.3587(3.3656) | Xent 0.0000(0.0000) | Loss 8.7472(9.3143) | Error 0.0000(0.0000) Steps 934(960.36) | Grad Norm 1.5004(1.4361) | Total Time 0.00(0.00)\n",
      "Iter 17040 | Time 24.5304(25.4359) | Bit/dim 3.3293(3.3608) | Xent 0.0000(0.0000) | Loss 8.5861(9.1735) | Error 0.0000(0.0000) Steps 922(955.86) | Grad Norm 2.0118(1.4328) | Total Time 0.00(0.00)\n",
      "Iter 17050 | Time 25.6520(25.4739) | Bit/dim 3.3830(3.3610) | Xent 0.0000(0.0000) | Loss 8.8494(9.0827) | Error 0.0000(0.0000) Steps 958(955.71) | Grad Norm 2.5462(1.4990) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0310 | Time 116.4943, Epoch Time 1536.0275(1463.2100), Bit/dim 3.3708(best: 3.3638), Xent 0.0000, Loss 3.3708, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17060 | Time 24.7059(25.4716) | Bit/dim 3.3613(3.3623) | Xent 0.0000(0.0000) | Loss 8.7487(9.8422) | Error 0.0000(0.0000) Steps 946(956.23) | Grad Norm 2.9069(1.7379) | Total Time 0.00(0.00)\n",
      "Iter 17070 | Time 25.4744(25.4187) | Bit/dim 3.3514(3.3600) | Xent 0.0000(0.0000) | Loss 8.8616(9.5738) | Error 0.0000(0.0000) Steps 952(955.61) | Grad Norm 1.9178(1.8608) | Total Time 0.00(0.00)\n",
      "Iter 17080 | Time 25.1349(25.3918) | Bit/dim 3.3932(3.3622) | Xent 0.0000(0.0000) | Loss 8.8550(9.3796) | Error 0.0000(0.0000) Steps 958(954.56) | Grad Norm 3.3928(2.1041) | Total Time 0.00(0.00)\n",
      "Iter 17090 | Time 24.5303(25.3616) | Bit/dim 3.3442(3.3625) | Xent 0.0000(0.0000) | Loss 8.8268(9.2332) | Error 0.0000(0.0000) Steps 916(953.86) | Grad Norm 1.6659(2.2232) | Total Time 0.00(0.00)\n",
      "Iter 17100 | Time 25.7739(25.3689) | Bit/dim 3.3563(3.3637) | Xent 0.0000(0.0000) | Loss 8.8798(9.1250) | Error 0.0000(0.0000) Steps 934(953.42) | Grad Norm 2.1596(2.0730) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0311 | Time 117.0482, Epoch Time 1529.0818(1465.1862), Bit/dim 3.3695(best: 3.3638), Xent 0.0000, Loss 3.3695, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17110 | Time 26.0991(25.3582) | Bit/dim 3.3593(3.3624) | Xent 0.0000(0.0000) | Loss 8.7958(10.0185) | Error 0.0000(0.0000) Steps 958(951.91) | Grad Norm 1.7115(2.0268) | Total Time 0.00(0.00)\n",
      "Iter 17120 | Time 26.0078(25.4968) | Bit/dim 3.3568(3.3611) | Xent 0.0000(0.0000) | Loss 8.8762(9.6973) | Error 0.0000(0.0000) Steps 976(952.67) | Grad Norm 1.1122(1.8514) | Total Time 0.00(0.00)\n",
      "Iter 17130 | Time 25.3308(25.5519) | Bit/dim 3.3463(3.3624) | Xent 0.0000(0.0000) | Loss 8.8061(9.4708) | Error 0.0000(0.0000) Steps 988(954.63) | Grad Norm 1.4875(1.7687) | Total Time 0.00(0.00)\n",
      "Iter 17140 | Time 26.0298(25.4806) | Bit/dim 3.3717(3.3647) | Xent 0.0000(0.0000) | Loss 8.9081(9.3114) | Error 0.0000(0.0000) Steps 928(956.90) | Grad Norm 2.2488(1.7373) | Total Time 0.00(0.00)\n",
      "Iter 17150 | Time 26.6053(25.4970) | Bit/dim 3.3540(3.3623) | Xent 0.0000(0.0000) | Loss 8.8772(9.1769) | Error 0.0000(0.0000) Steps 964(956.70) | Grad Norm 1.3374(1.7309) | Total Time 0.00(0.00)\n",
      "Iter 17160 | Time 24.6750(25.4230) | Bit/dim 3.3725(3.3637) | Xent 0.0000(0.0000) | Loss 8.8882(9.0973) | Error 0.0000(0.0000) Steps 940(956.90) | Grad Norm 1.3246(1.7036) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0312 | Time 116.6700, Epoch Time 1538.2943(1467.3794), Bit/dim 3.3718(best: 3.3638), Xent 0.0000, Loss 3.3718, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17170 | Time 25.5550(25.5213) | Bit/dim 3.3537(3.3644) | Xent 0.0000(0.0000) | Loss 8.7914(9.8335) | Error 0.0000(0.0000) Steps 964(958.10) | Grad Norm 1.9675(1.7901) | Total Time 0.00(0.00)\n",
      "Iter 17180 | Time 25.8779(25.5698) | Bit/dim 3.3510(3.3622) | Xent 0.0000(0.0000) | Loss 8.7437(9.5682) | Error 0.0000(0.0000) Steps 934(958.54) | Grad Norm 1.4192(1.9275) | Total Time 0.00(0.00)\n",
      "Iter 17190 | Time 25.4917(25.4940) | Bit/dim 3.3642(3.3655) | Xent 0.0000(0.0000) | Loss 8.9057(9.3757) | Error 0.0000(0.0000) Steps 970(958.46) | Grad Norm 1.4799(2.0807) | Total Time 0.00(0.00)\n",
      "Iter 17200 | Time 25.1777(25.6591) | Bit/dim 3.3834(3.3658) | Xent 0.0000(0.0000) | Loss 8.8112(9.2345) | Error 0.0000(0.0000) Steps 958(962.71) | Grad Norm 1.9337(2.0024) | Total Time 0.00(0.00)\n",
      "Iter 17210 | Time 25.7746(25.8539) | Bit/dim 3.3589(3.3634) | Xent 0.0000(0.0000) | Loss 8.7315(9.1285) | Error 0.0000(0.0000) Steps 928(960.25) | Grad Norm 1.1183(1.9042) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0313 | Time 117.5970, Epoch Time 1563.1503(1470.2525), Bit/dim 3.3731(best: 3.3638), Xent 0.0000, Loss 3.3731, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17220 | Time 26.4969(25.9947) | Bit/dim 3.3581(3.3642) | Xent 0.0000(0.0000) | Loss 8.6923(10.0356) | Error 0.0000(0.0000) Steps 1000(967.46) | Grad Norm 2.5164(1.9294) | Total Time 0.00(0.00)\n",
      "Iter 17230 | Time 26.8278(26.0406) | Bit/dim 3.3601(3.3658) | Xent 0.0000(0.0000) | Loss 8.7237(9.7109) | Error 0.0000(0.0000) Steps 958(964.89) | Grad Norm 2.4766(1.8629) | Total Time 0.00(0.00)\n",
      "Iter 17240 | Time 26.3064(26.0515) | Bit/dim 3.3937(3.3676) | Xent 0.0000(0.0000) | Loss 8.8907(9.4756) | Error 0.0000(0.0000) Steps 934(959.74) | Grad Norm 1.5005(1.7844) | Total Time 0.00(0.00)\n",
      "Iter 17250 | Time 27.0815(26.0604) | Bit/dim 3.4116(3.3764) | Xent 0.0000(0.0000) | Loss 8.9724(9.3213) | Error 0.0000(0.0000) Steps 964(958.10) | Grad Norm 2.9911(2.3712) | Total Time 0.00(0.00)\n",
      "Iter 17260 | Time 26.6430(26.1520) | Bit/dim 3.4193(3.3859) | Xent 0.0000(0.0000) | Loss 8.9846(9.2215) | Error 0.0000(0.0000) Steps 1000(961.14) | Grad Norm 3.3898(2.7919) | Total Time 0.00(0.00)\n",
      "Iter 17270 | Time 26.0187(26.3426) | Bit/dim 3.4553(3.3960) | Xent 0.0000(0.0000) | Loss 9.0905(9.1383) | Error 0.0000(0.0000) Steps 994(966.23) | Grad Norm 2.1736(2.9222) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0314 | Time 119.9624, Epoch Time 1584.4291(1473.6778), Bit/dim 3.4180(best: 3.3638), Xent 0.0000, Loss 3.4180, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17280 | Time 29.6029(26.6866) | Bit/dim 3.4312(3.4017) | Xent 0.0000(0.0000) | Loss 9.0440(9.8879) | Error 0.0000(0.0000) Steps 1024(975.75) | Grad Norm 2.3865(2.8598) | Total Time 0.00(0.00)\n",
      "Iter 17290 | Time 28.1306(27.0121) | Bit/dim 3.4153(3.4025) | Xent 0.0000(0.0000) | Loss 8.8648(9.6317) | Error 0.0000(0.0000) Steps 1030(983.33) | Grad Norm 1.5584(2.6904) | Total Time 0.00(0.00)\n",
      "Iter 17300 | Time 28.1494(27.3431) | Bit/dim 3.4206(3.4088) | Xent 0.0000(0.0000) | Loss 8.9972(9.4498) | Error 0.0000(0.0000) Steps 1000(992.26) | Grad Norm 1.6971(2.4318) | Total Time 0.00(0.00)\n",
      "Iter 17310 | Time 27.7426(27.4377) | Bit/dim 3.4163(3.4117) | Xent 0.0000(0.0000) | Loss 8.8108(9.3076) | Error 0.0000(0.0000) Steps 976(994.78) | Grad Norm 2.4673(2.2980) | Total Time 0.00(0.00)\n",
      "Iter 17320 | Time 27.3472(27.5388) | Bit/dim 3.4335(3.4138) | Xent 0.0000(0.0000) | Loss 8.8714(9.2013) | Error 0.0000(0.0000) Steps 1030(995.55) | Grad Norm 1.8467(2.1625) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0315 | Time 119.1793, Epoch Time 1674.8149(1479.7119), Bit/dim 3.4145(best: 3.3638), Xent 0.0000, Loss 3.4145, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17330 | Time 26.7127(27.7111) | Bit/dim 3.4093(3.4124) | Xent 0.0000(0.0000) | Loss 8.7847(10.1017) | Error 0.0000(0.0000) Steps 1000(996.92) | Grad Norm 2.6798(2.0902) | Total Time 0.00(0.00)\n",
      "Iter 17340 | Time 28.2633(27.7354) | Bit/dim 3.4216(3.4116) | Xent 0.0000(0.0000) | Loss 8.9639(9.7951) | Error 0.0000(0.0000) Steps 970(997.80) | Grad Norm 1.9653(1.9500) | Total Time 0.00(0.00)\n",
      "Iter 17350 | Time 27.7278(27.7395) | Bit/dim 3.4075(3.4110) | Xent 0.0000(0.0000) | Loss 9.0200(9.5764) | Error 0.0000(0.0000) Steps 1006(994.46) | Grad Norm 2.1222(1.8520) | Total Time 0.00(0.00)\n",
      "Iter 17360 | Time 27.6917(27.7398) | Bit/dim 3.3893(3.4080) | Xent 0.0000(0.0000) | Loss 8.7429(9.3989) | Error 0.0000(0.0000) Steps 982(994.62) | Grad Norm 2.6810(1.9494) | Total Time 0.00(0.00)\n",
      "Iter 17370 | Time 28.3536(27.7900) | Bit/dim 3.4018(3.4058) | Xent 0.0000(0.0000) | Loss 8.9127(9.2612) | Error 0.0000(0.0000) Steps 982(994.01) | Grad Norm 1.4787(1.8715) | Total Time 0.00(0.00)\n",
      "Iter 17380 | Time 28.2240(27.7351) | Bit/dim 3.4114(3.4017) | Xent 0.0000(0.0000) | Loss 8.9768(9.1622) | Error 0.0000(0.0000) Steps 1024(996.56) | Grad Norm 2.3146(1.8962) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0316 | Time 118.7019, Epoch Time 1664.3352(1485.2506), Bit/dim 3.4005(best: 3.3638), Xent 0.0000, Loss 3.4005, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17390 | Time 26.4800(27.6714) | Bit/dim 3.3716(3.3993) | Xent 0.0000(0.0000) | Loss 8.8204(9.8991) | Error 0.0000(0.0000) Steps 970(993.02) | Grad Norm 1.8754(1.8862) | Total Time 0.00(0.00)\n",
      "Iter 17400 | Time 26.9433(27.7067) | Bit/dim 3.3860(3.3988) | Xent 0.0000(0.0000) | Loss 8.8319(9.6206) | Error 0.0000(0.0000) Steps 994(992.41) | Grad Norm 1.0910(1.8369) | Total Time 0.00(0.00)\n",
      "Iter 17410 | Time 27.8015(27.6308) | Bit/dim 3.3630(3.3950) | Xent 0.0000(0.0000) | Loss 8.8081(9.4171) | Error 0.0000(0.0000) Steps 976(989.77) | Grad Norm 1.5310(1.7521) | Total Time 0.00(0.00)\n",
      "Iter 17420 | Time 28.5251(27.6093) | Bit/dim 3.3852(3.3921) | Xent 0.0000(0.0000) | Loss 8.7929(9.2639) | Error 0.0000(0.0000) Steps 994(992.17) | Grad Norm 1.5557(1.6652) | Total Time 0.00(0.00)\n",
      "Iter 17430 | Time 27.9421(27.5608) | Bit/dim 3.4387(3.3922) | Xent 0.0000(0.0000) | Loss 9.0105(9.1604) | Error 0.0000(0.0000) Steps 970(992.30) | Grad Norm 1.5377(1.6599) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0317 | Time 116.8093, Epoch Time 1650.8583(1490.2189), Bit/dim 3.3931(best: 3.3638), Xent 0.0000, Loss 3.3931, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17440 | Time 27.9155(27.5995) | Bit/dim 3.4212(3.3923) | Xent 0.0000(0.0000) | Loss 9.0224(10.0359) | Error 0.0000(0.0000) Steps 1006(996.58) | Grad Norm 2.1228(1.7271) | Total Time 0.00(0.00)\n",
      "Iter 17450 | Time 28.2404(27.6064) | Bit/dim 3.4319(3.3906) | Xent 0.0000(0.0000) | Loss 8.9998(9.7271) | Error 0.0000(0.0000) Steps 1048(996.65) | Grad Norm 1.5777(1.6994) | Total Time 0.00(0.00)\n",
      "Iter 17460 | Time 26.7783(27.4417) | Bit/dim 3.3663(3.3884) | Xent 0.0000(0.0000) | Loss 8.8068(9.4928) | Error 0.0000(0.0000) Steps 976(990.99) | Grad Norm 2.7234(1.7272) | Total Time 0.00(0.00)\n",
      "Iter 17470 | Time 26.6493(27.2100) | Bit/dim 3.3924(3.3878) | Xent 0.0000(0.0000) | Loss 8.8251(9.3217) | Error 0.0000(0.0000) Steps 970(986.82) | Grad Norm 1.0357(1.8254) | Total Time 0.00(0.00)\n",
      "Iter 17480 | Time 25.9481(27.1841) | Bit/dim 3.3666(3.3853) | Xent 0.0000(0.0000) | Loss 8.8286(9.2011) | Error 0.0000(0.0000) Steps 982(989.60) | Grad Norm 2.2886(1.7804) | Total Time 0.00(0.00)\n",
      "Iter 17490 | Time 26.0830(27.0970) | Bit/dim 3.3337(3.3813) | Xent 0.0000(0.0000) | Loss 8.7568(9.1103) | Error 0.0000(0.0000) Steps 976(988.35) | Grad Norm 1.3426(1.7964) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0318 | Time 116.7906, Epoch Time 1626.7373(1494.3144), Bit/dim 3.3792(best: 3.3638), Xent 0.0000, Loss 3.3792, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17500 | Time 26.3526(26.9700) | Bit/dim 3.3863(3.3797) | Xent 0.0000(0.0000) | Loss 8.8445(9.8831) | Error 0.0000(0.0000) Steps 970(983.92) | Grad Norm 2.0164(1.8439) | Total Time 0.00(0.00)\n",
      "Iter 17510 | Time 26.4857(26.8681) | Bit/dim 3.3882(3.3807) | Xent 0.0000(0.0000) | Loss 8.8983(9.6209) | Error 0.0000(0.0000) Steps 970(981.26) | Grad Norm 1.1935(1.7117) | Total Time 0.00(0.00)\n",
      "Iter 17520 | Time 26.8552(26.8013) | Bit/dim 3.3400(3.3781) | Xent 0.0000(0.0000) | Loss 8.8054(9.4096) | Error 0.0000(0.0000) Steps 988(975.78) | Grad Norm 1.3164(1.6638) | Total Time 0.00(0.00)\n",
      "Iter 17530 | Time 25.7227(26.6660) | Bit/dim 3.3769(3.3793) | Xent 0.0000(0.0000) | Loss 8.8633(9.2630) | Error 0.0000(0.0000) Steps 970(972.61) | Grad Norm 1.3379(1.7086) | Total Time 0.00(0.00)\n",
      "Iter 17540 | Time 25.8277(26.5483) | Bit/dim 3.3929(3.3769) | Xent 0.0000(0.0000) | Loss 8.6602(9.1603) | Error 0.0000(0.0000) Steps 976(972.91) | Grad Norm 2.4419(1.7116) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0319 | Time 115.7270, Epoch Time 1590.7355(1497.2071), Bit/dim 3.3773(best: 3.3638), Xent 0.0000, Loss 3.3773, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17550 | Time 26.6639(26.5276) | Bit/dim 3.3519(3.3748) | Xent 0.0000(0.0000) | Loss 8.7118(10.0381) | Error 0.0000(0.0000) Steps 1006(973.55) | Grad Norm 1.2569(1.7039) | Total Time 0.00(0.00)\n",
      "Iter 17560 | Time 25.3532(26.4245) | Bit/dim 3.3404(3.3709) | Xent 0.0000(0.0000) | Loss 8.9151(9.7207) | Error 0.0000(0.0000) Steps 970(973.09) | Grad Norm 2.1722(1.8190) | Total Time 0.00(0.00)\n",
      "Iter 17570 | Time 25.8514(26.2776) | Bit/dim 3.3973(3.3714) | Xent 0.0000(0.0000) | Loss 8.7209(9.4880) | Error 0.0000(0.0000) Steps 946(972.94) | Grad Norm 1.0662(1.9742) | Total Time 0.00(0.00)\n",
      "Iter 17580 | Time 25.7820(26.1887) | Bit/dim 3.3807(3.3710) | Xent 0.0000(0.0000) | Loss 8.8056(9.3120) | Error 0.0000(0.0000) Steps 976(966.27) | Grad Norm 1.7297(1.9008) | Total Time 0.00(0.00)\n",
      "Iter 17590 | Time 26.1377(26.2148) | Bit/dim 3.4141(3.3730) | Xent 0.0000(0.0000) | Loss 8.8156(9.1836) | Error 0.0000(0.0000) Steps 970(967.04) | Grad Norm 1.5264(1.8195) | Total Time 0.00(0.00)\n",
      "Iter 17600 | Time 25.4874(26.1223) | Bit/dim 3.3991(3.3740) | Xent 0.0000(0.0000) | Loss 8.7444(9.0979) | Error 0.0000(0.0000) Steps 976(966.60) | Grad Norm 1.1067(1.6895) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0320 | Time 116.4970, Epoch Time 1567.8239(1499.3256), Bit/dim 3.3762(best: 3.3638), Xent 0.0000, Loss 3.3762, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17610 | Time 26.9050(26.1642) | Bit/dim 3.3469(3.3730) | Xent 0.0000(0.0000) | Loss 8.9458(9.8567) | Error 0.0000(0.0000) Steps 1018(967.94) | Grad Norm 0.9479(1.6035) | Total Time 0.00(0.00)\n",
      "Iter 17620 | Time 25.3841(26.1154) | Bit/dim 3.3780(3.3710) | Xent 0.0000(0.0000) | Loss 8.7589(9.5806) | Error 0.0000(0.0000) Steps 964(967.28) | Grad Norm 1.5577(1.5577) | Total Time 0.00(0.00)\n",
      "Iter 17630 | Time 27.0392(26.1097) | Bit/dim 3.3785(3.3683) | Xent 0.0000(0.0000) | Loss 8.9356(9.3786) | Error 0.0000(0.0000) Steps 940(965.73) | Grad Norm 1.2242(1.4914) | Total Time 0.00(0.00)\n",
      "Iter 17640 | Time 24.8830(26.0168) | Bit/dim 3.3402(3.3673) | Xent 0.0000(0.0000) | Loss 8.8489(9.2466) | Error 0.0000(0.0000) Steps 970(966.35) | Grad Norm 2.5581(1.5320) | Total Time 0.00(0.00)\n",
      "Iter 17650 | Time 25.5150(25.8831) | Bit/dim 3.3601(3.3681) | Xent 0.0000(0.0000) | Loss 8.7879(9.1476) | Error 0.0000(0.0000) Steps 946(966.75) | Grad Norm 1.3194(1.5941) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0321 | Time 116.8200, Epoch Time 1562.3633(1501.2167), Bit/dim 3.3746(best: 3.3638), Xent 0.0000, Loss 3.3746, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17660 | Time 25.4088(25.8490) | Bit/dim 3.4141(3.3703) | Xent 0.0000(0.0000) | Loss 8.9094(10.0580) | Error 0.0000(0.0000) Steps 946(960.82) | Grad Norm 1.6785(1.6258) | Total Time 0.00(0.00)\n",
      "Iter 17670 | Time 25.8663(25.8472) | Bit/dim 3.3653(3.3708) | Xent 0.0000(0.0000) | Loss 8.8817(9.7366) | Error 0.0000(0.0000) Steps 988(962.27) | Grad Norm 1.2657(1.5442) | Total Time 0.00(0.00)\n",
      "Iter 17680 | Time 25.1349(25.7056) | Bit/dim 3.3835(3.3691) | Xent 0.0000(0.0000) | Loss 8.9194(9.5069) | Error 0.0000(0.0000) Steps 994(962.82) | Grad Norm 3.0150(1.6794) | Total Time 0.00(0.00)\n",
      "Iter 17690 | Time 24.3953(25.7488) | Bit/dim 3.3628(3.3738) | Xent 0.0000(0.0000) | Loss 8.8257(9.3436) | Error 0.0000(0.0000) Steps 946(962.16) | Grad Norm 1.3086(1.6150) | Total Time 0.00(0.00)\n",
      "Iter 17700 | Time 25.8454(25.7095) | Bit/dim 3.3941(3.3708) | Xent 0.0000(0.0000) | Loss 8.9194(9.2137) | Error 0.0000(0.0000) Steps 970(960.09) | Grad Norm 1.0735(1.5235) | Total Time 0.00(0.00)\n",
      "Iter 17710 | Time 25.3923(25.7058) | Bit/dim 3.3271(3.3656) | Xent 0.0000(0.0000) | Loss 8.7979(9.1011) | Error 0.0000(0.0000) Steps 946(958.49) | Grad Norm 2.5362(1.5719) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0322 | Time 115.1192, Epoch Time 1544.6062(1502.5184), Bit/dim 3.3747(best: 3.3638), Xent 0.0000, Loss 3.3747, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17720 | Time 25.2148(25.5858) | Bit/dim 3.3336(3.3667) | Xent 0.0000(0.0000) | Loss 8.8262(9.8468) | Error 0.0000(0.0000) Steps 982(956.68) | Grad Norm 3.1270(1.7379) | Total Time 0.00(0.00)\n",
      "Iter 17730 | Time 25.6180(25.4604) | Bit/dim 3.3572(3.3628) | Xent 0.0000(0.0000) | Loss 8.7036(9.5654) | Error 0.0000(0.0000) Steps 928(954.79) | Grad Norm 2.2924(1.8227) | Total Time 0.00(0.00)\n",
      "Iter 17740 | Time 25.0280(25.4518) | Bit/dim 3.3438(3.3635) | Xent 0.0000(0.0000) | Loss 8.7722(9.3800) | Error 0.0000(0.0000) Steps 970(955.88) | Grad Norm 2.4086(1.8850) | Total Time 0.00(0.00)\n",
      "Iter 17750 | Time 24.5946(25.4666) | Bit/dim 3.3666(3.3642) | Xent 0.0000(0.0000) | Loss 8.7648(9.2339) | Error 0.0000(0.0000) Steps 922(953.97) | Grad Norm 1.9693(1.9804) | Total Time 0.00(0.00)\n",
      "Iter 17760 | Time 26.4481(25.5476) | Bit/dim 3.3852(3.3658) | Xent 0.0000(0.0000) | Loss 8.9358(9.1298) | Error 0.0000(0.0000) Steps 1000(953.87) | Grad Norm 0.8353(1.9657) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0323 | Time 115.0359, Epoch Time 1533.3353(1503.4429), Bit/dim 3.3687(best: 3.3638), Xent 0.0000, Loss 3.3687, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17770 | Time 25.9883(25.5657) | Bit/dim 3.3978(3.3679) | Xent 0.0000(0.0000) | Loss 8.9380(10.0253) | Error 0.0000(0.0000) Steps 982(955.05) | Grad Norm 2.0591(1.9577) | Total Time 0.00(0.00)\n",
      "Iter 17780 | Time 25.7194(25.5183) | Bit/dim 3.3969(3.3652) | Xent 0.0000(0.0000) | Loss 8.9276(9.7157) | Error 0.0000(0.0000) Steps 958(955.47) | Grad Norm 1.3623(1.9889) | Total Time 0.00(0.00)\n",
      "Iter 17790 | Time 25.1311(25.6034) | Bit/dim 3.3331(3.3647) | Xent 0.0000(0.0000) | Loss 8.9031(9.4897) | Error 0.0000(0.0000) Steps 952(957.05) | Grad Norm 1.1033(1.8552) | Total Time 0.00(0.00)\n",
      "Iter 17800 | Time 26.0303(25.6231) | Bit/dim 3.3585(3.3661) | Xent 0.0000(0.0000) | Loss 8.8329(9.3179) | Error 0.0000(0.0000) Steps 946(954.45) | Grad Norm 1.4402(1.6848) | Total Time 0.00(0.00)\n",
      "Iter 17810 | Time 25.1669(25.5278) | Bit/dim 3.3608(3.3684) | Xent 0.0000(0.0000) | Loss 8.7563(9.1824) | Error 0.0000(0.0000) Steps 982(953.80) | Grad Norm 1.0477(1.5936) | Total Time 0.00(0.00)\n",
      "Iter 17820 | Time 24.3151(25.5608) | Bit/dim 3.3684(3.3661) | Xent 0.0000(0.0000) | Loss 8.7028(9.0872) | Error 0.0000(0.0000) Steps 940(954.64) | Grad Norm 2.4462(1.5808) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0324 | Time 116.1811, Epoch Time 1541.5934(1504.5874), Bit/dim 3.3696(best: 3.3638), Xent 0.0000, Loss 3.3696, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17830 | Time 26.0374(25.4973) | Bit/dim 3.3489(3.3676) | Xent 0.0000(0.0000) | Loss 8.8566(9.8860) | Error 0.0000(0.0000) Steps 994(953.14) | Grad Norm 0.9729(1.6290) | Total Time 0.00(0.00)\n",
      "Iter 17840 | Time 24.9375(25.3957) | Bit/dim 3.3611(3.3660) | Xent 0.0000(0.0000) | Loss 8.8469(9.5960) | Error 0.0000(0.0000) Steps 976(952.60) | Grad Norm 0.8749(1.5208) | Total Time 0.00(0.00)\n",
      "Iter 17850 | Time 26.5372(25.4325) | Bit/dim 3.3282(3.3627) | Xent 0.0000(0.0000) | Loss 8.8237(9.3899) | Error 0.0000(0.0000) Steps 1006(954.17) | Grad Norm 1.2593(1.4541) | Total Time 0.00(0.00)\n",
      "Iter 17860 | Time 25.5880(25.4237) | Bit/dim 3.3583(3.3627) | Xent 0.0000(0.0000) | Loss 8.7075(9.2337) | Error 0.0000(0.0000) Steps 916(953.74) | Grad Norm 1.2354(1.4075) | Total Time 0.00(0.00)\n",
      "Iter 17870 | Time 24.3321(25.3535) | Bit/dim 3.3889(3.3657) | Xent 0.0000(0.0000) | Loss 8.7340(9.1277) | Error 0.0000(0.0000) Steps 928(948.99) | Grad Norm 1.7439(1.5039) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0325 | Time 114.8659, Epoch Time 1525.3759(1505.2111), Bit/dim 3.3692(best: 3.3638), Xent 0.0000, Loss 3.3692, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17880 | Time 25.8254(25.3788) | Bit/dim 3.3571(3.3647) | Xent 0.0000(0.0000) | Loss 8.7801(10.0050) | Error 0.0000(0.0000) Steps 928(950.24) | Grad Norm 1.1160(1.4952) | Total Time 0.00(0.00)\n",
      "Iter 17890 | Time 25.1908(25.2999) | Bit/dim 3.3636(3.3637) | Xent 0.0000(0.0000) | Loss 8.7990(9.6907) | Error 0.0000(0.0000) Steps 964(953.10) | Grad Norm 1.3366(1.4406) | Total Time 0.00(0.00)\n",
      "Iter 17900 | Time 26.1737(25.3409) | Bit/dim 3.3338(3.3624) | Xent 0.0000(0.0000) | Loss 8.7688(9.4613) | Error 0.0000(0.0000) Steps 982(957.57) | Grad Norm 1.1890(1.4439) | Total Time 0.00(0.00)\n",
      "Iter 17910 | Time 25.7331(25.3988) | Bit/dim 3.3727(3.3635) | Xent 0.0000(0.0000) | Loss 8.8167(9.3122) | Error 0.0000(0.0000) Steps 928(957.16) | Grad Norm 1.4174(1.4471) | Total Time 0.00(0.00)\n",
      "Iter 17920 | Time 24.3373(25.3280) | Bit/dim 3.3570(3.3653) | Xent 0.0000(0.0000) | Loss 8.7309(9.1847) | Error 0.0000(0.0000) Steps 958(957.37) | Grad Norm 3.3397(1.6593) | Total Time 0.00(0.00)\n",
      "Iter 17930 | Time 24.7480(25.3285) | Bit/dim 3.3766(3.3650) | Xent 0.0000(0.0000) | Loss 8.9060(9.1014) | Error 0.0000(0.0000) Steps 970(958.47) | Grad Norm 1.1766(1.6249) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0326 | Time 116.4939, Epoch Time 1528.5119(1505.9101), Bit/dim 3.3674(best: 3.3638), Xent 0.0000, Loss 3.3674, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17940 | Time 24.1038(25.1764) | Bit/dim 3.3594(3.3617) | Xent 0.0000(0.0000) | Loss 8.7198(9.8644) | Error 0.0000(0.0000) Steps 910(954.92) | Grad Norm 2.7050(1.6712) | Total Time 0.00(0.00)\n",
      "Iter 17950 | Time 24.6440(25.1755) | Bit/dim 3.3360(3.3633) | Xent 0.0000(0.0000) | Loss 8.7969(9.5930) | Error 0.0000(0.0000) Steps 934(953.87) | Grad Norm 2.1747(1.7384) | Total Time 0.00(0.00)\n",
      "Iter 17960 | Time 24.9650(25.1183) | Bit/dim 3.3637(3.3624) | Xent 0.0000(0.0000) | Loss 8.8593(9.3847) | Error 0.0000(0.0000) Steps 958(954.42) | Grad Norm 1.1669(1.6830) | Total Time 0.00(0.00)\n",
      "Iter 17970 | Time 24.4109(25.0346) | Bit/dim 3.3526(3.3612) | Xent 0.0000(0.0000) | Loss 8.8252(9.2422) | Error 0.0000(0.0000) Steps 934(950.98) | Grad Norm 2.0048(1.6696) | Total Time 0.00(0.00)\n",
      "Iter 17980 | Time 24.2831(25.0894) | Bit/dim 3.3704(3.3663) | Xent 0.0000(0.0000) | Loss 8.8797(9.1452) | Error 0.0000(0.0000) Steps 976(950.62) | Grad Norm 2.3847(1.7799) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0327 | Time 114.6018, Epoch Time 1508.3859(1505.9844), Bit/dim 3.3675(best: 3.3638), Xent 0.0000, Loss 3.3675, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17990 | Time 25.2916(25.1431) | Bit/dim 3.3691(3.3651) | Xent 0.0000(0.0000) | Loss 8.7716(10.0087) | Error 0.0000(0.0000) Steps 898(944.60) | Grad Norm 1.9494(1.7985) | Total Time 0.00(0.00)\n",
      "Iter 18000 | Time 25.2356(25.1367) | Bit/dim 3.3648(3.3601) | Xent 0.0000(0.0000) | Loss 8.8386(9.6916) | Error 0.0000(0.0000) Steps 946(944.69) | Grad Norm 2.1451(1.8589) | Total Time 0.00(0.00)\n",
      "Iter 18010 | Time 24.5138(25.0596) | Bit/dim 3.3682(3.3604) | Xent 0.0000(0.0000) | Loss 8.7669(9.4685) | Error 0.0000(0.0000) Steps 946(947.42) | Grad Norm 2.1813(1.9302) | Total Time 0.00(0.00)\n",
      "Iter 18020 | Time 25.9919(25.0337) | Bit/dim 3.3673(3.3604) | Xent 0.0000(0.0000) | Loss 8.9486(9.3068) | Error 0.0000(0.0000) Steps 994(951.35) | Grad Norm 1.1099(1.9091) | Total Time 0.00(0.00)\n",
      "Iter 18030 | Time 24.3473(24.9801) | Bit/dim 3.3720(3.3651) | Xent 0.0000(0.0000) | Loss 8.8283(9.1898) | Error 0.0000(0.0000) Steps 952(952.13) | Grad Norm 1.6458(1.8200) | Total Time 0.00(0.00)\n",
      "Iter 18040 | Time 26.0198(25.0017) | Bit/dim 3.3656(3.3648) | Xent 0.0000(0.0000) | Loss 8.9399(9.0930) | Error 0.0000(0.0000) Steps 988(954.14) | Grad Norm 1.3346(1.6980) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0328 | Time 114.9812, Epoch Time 1509.1815(1506.0803), Bit/dim 3.3659(best: 3.3638), Xent 0.0000, Loss 3.3659, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18050 | Time 25.5300(25.0350) | Bit/dim 3.3427(3.3622) | Xent 0.0000(0.0000) | Loss 8.7808(9.8383) | Error 0.0000(0.0000) Steps 946(954.76) | Grad Norm 1.0479(1.6277) | Total Time 0.00(0.00)\n",
      "Iter 18060 | Time 25.7895(25.0663) | Bit/dim 3.4009(3.3586) | Xent 0.0000(0.0000) | Loss 8.8929(9.5613) | Error 0.0000(0.0000) Steps 982(955.51) | Grad Norm 1.3838(1.5303) | Total Time 0.00(0.00)\n",
      "Iter 18070 | Time 23.9359(25.1570) | Bit/dim 3.3830(3.3632) | Xent 0.0000(0.0000) | Loss 8.8630(9.3810) | Error 0.0000(0.0000) Steps 916(951.24) | Grad Norm 1.0028(1.4787) | Total Time 0.00(0.00)\n",
      "Iter 18080 | Time 24.4363(25.1084) | Bit/dim 3.3835(3.3640) | Xent 0.0000(0.0000) | Loss 8.9073(9.2399) | Error 0.0000(0.0000) Steps 898(947.92) | Grad Norm 1.4701(1.4599) | Total Time 0.00(0.00)\n",
      "Iter 18090 | Time 23.8971(25.0780) | Bit/dim 3.3683(3.3638) | Xent 0.0000(0.0000) | Loss 8.7593(9.1354) | Error 0.0000(0.0000) Steps 940(947.66) | Grad Norm 1.6435(1.4471) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0329 | Time 116.5824, Epoch Time 1516.9847(1506.4074), Bit/dim 3.3696(best: 3.3638), Xent 0.0000, Loss 3.3696, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18100 | Time 25.4751(25.0323) | Bit/dim 3.3674(3.3653) | Xent 0.0000(0.0000) | Loss 8.7773(10.0265) | Error 0.0000(0.0000) Steps 952(950.03) | Grad Norm 1.3337(1.4715) | Total Time 0.00(0.00)\n",
      "Iter 18110 | Time 25.1289(25.0231) | Bit/dim 3.3539(3.3639) | Xent 0.0000(0.0000) | Loss 8.7348(9.7251) | Error 0.0000(0.0000) Steps 922(949.38) | Grad Norm 1.4676(1.4262) | Total Time 0.00(0.00)\n",
      "Iter 18120 | Time 25.4936(25.0065) | Bit/dim 3.3251(3.3656) | Xent 0.0000(0.0000) | Loss 8.8027(9.5042) | Error 0.0000(0.0000) Steps 952(952.00) | Grad Norm 2.4436(1.5162) | Total Time 0.00(0.00)\n",
      "Iter 18130 | Time 25.4527(24.9485) | Bit/dim 3.3945(3.3614) | Xent 0.0000(0.0000) | Loss 8.8942(9.3183) | Error 0.0000(0.0000) Steps 994(953.24) | Grad Norm 1.4515(1.7635) | Total Time 0.00(0.00)\n",
      "Iter 18140 | Time 25.3254(25.0163) | Bit/dim 3.3536(3.3610) | Xent 0.0000(0.0000) | Loss 8.7489(9.1888) | Error 0.0000(0.0000) Steps 970(957.68) | Grad Norm 1.6936(1.7452) | Total Time 0.00(0.00)\n",
      "Iter 18150 | Time 26.0213(25.0466) | Bit/dim 3.4003(3.3636) | Xent 0.0000(0.0000) | Loss 8.9432(9.1087) | Error 0.0000(0.0000) Steps 988(957.63) | Grad Norm 1.4509(1.7167) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0330 | Time 115.9399, Epoch Time 1509.3136(1506.4946), Bit/dim 3.3672(best: 3.3638), Xent 0.0000, Loss 3.3672, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18160 | Time 25.4701(25.2043) | Bit/dim 3.3303(3.3629) | Xent 0.0000(0.0000) | Loss 8.7932(9.8707) | Error 0.0000(0.0000) Steps 988(960.77) | Grad Norm 1.5793(1.7045) | Total Time 0.00(0.00)\n",
      "Iter 18170 | Time 25.5358(25.2103) | Bit/dim 3.3571(3.3623) | Xent 0.0000(0.0000) | Loss 8.7202(9.5948) | Error 0.0000(0.0000) Steps 904(959.45) | Grad Norm 1.9260(1.6441) | Total Time 0.00(0.00)\n",
      "Iter 18180 | Time 25.7404(25.2713) | Bit/dim 3.4016(3.3611) | Xent 0.0000(0.0000) | Loss 8.7544(9.3909) | Error 0.0000(0.0000) Steps 952(959.44) | Grad Norm 0.8548(1.6049) | Total Time 0.00(0.00)\n",
      "Iter 18190 | Time 25.2746(25.2111) | Bit/dim 3.3691(3.3611) | Xent 0.0000(0.0000) | Loss 8.8672(9.2302) | Error 0.0000(0.0000) Steps 958(956.17) | Grad Norm 0.7923(1.4885) | Total Time 0.00(0.00)\n",
      "Iter 18200 | Time 25.1336(25.2459) | Bit/dim 3.3751(3.3626) | Xent 0.0000(0.0000) | Loss 8.8822(9.1265) | Error 0.0000(0.0000) Steps 964(957.41) | Grad Norm 2.7719(1.4763) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0331 | Time 117.0157, Epoch Time 1529.3179(1507.1793), Bit/dim 3.3681(best: 3.3638), Xent 0.0000, Loss 3.3681, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18210 | Time 24.9219(25.1825) | Bit/dim 3.3757(3.3624) | Xent 0.0000(0.0000) | Loss 8.7846(10.0152) | Error 0.0000(0.0000) Steps 964(957.36) | Grad Norm 2.5678(1.6403) | Total Time 0.00(0.00)\n",
      "Iter 18220 | Time 25.7677(25.2061) | Bit/dim 3.3369(3.3613) | Xent 0.0000(0.0000) | Loss 8.7455(9.7047) | Error 0.0000(0.0000) Steps 958(959.55) | Grad Norm 1.3893(1.6249) | Total Time 0.00(0.00)\n",
      "Iter 18230 | Time 24.7977(25.1471) | Bit/dim 3.3385(3.3601) | Xent 0.0000(0.0000) | Loss 8.6623(9.4746) | Error 0.0000(0.0000) Steps 904(955.93) | Grad Norm 0.8448(1.6458) | Total Time 0.00(0.00)\n",
      "Iter 18240 | Time 24.9878(25.1130) | Bit/dim 3.3744(3.3608) | Xent 0.0000(0.0000) | Loss 8.8726(9.3051) | Error 0.0000(0.0000) Steps 916(953.69) | Grad Norm 1.4381(1.6212) | Total Time 0.00(0.00)\n",
      "Iter 18250 | Time 24.8483(25.1233) | Bit/dim 3.3625(3.3601) | Xent 0.0000(0.0000) | Loss 8.8517(9.1896) | Error 0.0000(0.0000) Steps 934(958.01) | Grad Norm 1.2261(1.5495) | Total Time 0.00(0.00)\n",
      "Iter 18260 | Time 24.4553(25.0646) | Bit/dim 3.3526(3.3625) | Xent 0.0000(0.0000) | Loss 8.8120(9.0890) | Error 0.0000(0.0000) Steps 940(954.90) | Grad Norm 1.1965(1.4259) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0332 | Time 116.9254, Epoch Time 1513.1983(1507.3599), Bit/dim 3.3654(best: 3.3638), Xent 0.0000, Loss 3.3654, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18270 | Time 25.7564(25.0640) | Bit/dim 3.3492(3.3640) | Xent 0.0000(0.0000) | Loss 8.9039(9.8434) | Error 0.0000(0.0000) Steps 1006(953.24) | Grad Norm 1.2575(1.3973) | Total Time 0.00(0.00)\n",
      "Iter 18280 | Time 24.9555(25.0538) | Bit/dim 3.3144(3.3612) | Xent 0.0000(0.0000) | Loss 8.7456(9.5689) | Error 0.0000(0.0000) Steps 976(959.55) | Grad Norm 1.2179(1.3741) | Total Time 0.00(0.00)\n",
      "Iter 18290 | Time 25.2733(25.1051) | Bit/dim 3.3399(3.3608) | Xent 0.0000(0.0000) | Loss 8.7018(9.3760) | Error 0.0000(0.0000) Steps 922(958.42) | Grad Norm 1.4431(1.3553) | Total Time 0.00(0.00)\n",
      "Iter 18300 | Time 25.4741(25.1667) | Bit/dim 3.3628(3.3625) | Xent 0.0000(0.0000) | Loss 8.9627(9.2305) | Error 0.0000(0.0000) Steps 970(956.17) | Grad Norm 1.5584(1.3909) | Total Time 0.00(0.00)\n",
      "Iter 18310 | Time 25.6372(25.2894) | Bit/dim 3.3146(3.3609) | Xent 0.0000(0.0000) | Loss 8.7883(9.1192) | Error 0.0000(0.0000) Steps 988(958.26) | Grad Norm 1.7388(1.3788) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 115.8654, Epoch Time 1523.2008(1507.8351), Bit/dim 3.3650(best: 3.3638), Xent 0.0000, Loss 3.3650, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18320 | Time 24.4982(25.2458) | Bit/dim 3.3784(3.3599) | Xent 0.0000(0.0000) | Loss 8.6438(10.0258) | Error 0.0000(0.0000) Steps 982(955.83) | Grad Norm 1.4663(1.9656) | Total Time 0.00(0.00)\n",
      "Iter 18330 | Time 25.5862(25.1024) | Bit/dim 3.3668(3.3595) | Xent 0.0000(0.0000) | Loss 8.8628(9.7086) | Error 0.0000(0.0000) Steps 946(951.20) | Grad Norm 3.5744(2.3051) | Total Time 0.00(0.00)\n",
      "Iter 18340 | Time 24.4641(24.9942) | Bit/dim 3.3203(3.3580) | Xent 0.0000(0.0000) | Loss 8.6769(9.4667) | Error 0.0000(0.0000) Steps 940(951.79) | Grad Norm 2.0488(2.2451) | Total Time 0.00(0.00)\n",
      "Iter 18350 | Time 24.2889(25.0453) | Bit/dim 3.3720(3.3597) | Xent 0.0000(0.0000) | Loss 8.7527(9.2818) | Error 0.0000(0.0000) Steps 946(949.92) | Grad Norm 2.1398(2.1541) | Total Time 0.00(0.00)\n",
      "Iter 18360 | Time 26.3012(24.9568) | Bit/dim 3.3761(3.3592) | Xent 0.0000(0.0000) | Loss 8.6776(9.1487) | Error 0.0000(0.0000) Steps 976(952.97) | Grad Norm 1.2824(1.9619) | Total Time 0.00(0.00)\n",
      "Iter 18370 | Time 24.8352(24.9810) | Bit/dim 3.3667(3.3599) | Xent 0.0000(0.0000) | Loss 9.0094(9.0830) | Error 0.0000(0.0000) Steps 970(951.65) | Grad Norm 1.5458(1.8355) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 115.7021, Epoch Time 1502.8980(1507.6870), Bit/dim 3.3686(best: 3.3638), Xent 0.0000, Loss 3.3686, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18380 | Time 25.3965(24.9830) | Bit/dim 3.3678(3.3587) | Xent 0.0000(0.0000) | Loss 9.0195(9.8823) | Error 0.0000(0.0000) Steps 946(952.20) | Grad Norm 1.5826(1.7765) | Total Time 0.00(0.00)\n",
      "Iter 18390 | Time 25.2084(24.9203) | Bit/dim 3.3958(3.3597) | Xent 0.0000(0.0000) | Loss 8.9698(9.5967) | Error 0.0000(0.0000) Steps 892(949.40) | Grad Norm 1.6286(1.7300) | Total Time 0.00(0.00)\n",
      "Iter 18400 | Time 25.3830(25.0116) | Bit/dim 3.3273(3.3614) | Xent 0.0000(0.0000) | Loss 8.8601(9.3949) | Error 0.0000(0.0000) Steps 952(949.34) | Grad Norm 1.0783(1.6306) | Total Time 0.00(0.00)\n",
      "Iter 18410 | Time 24.4326(24.9633) | Bit/dim 3.3859(3.3607) | Xent 0.0000(0.0000) | Loss 8.8452(9.2539) | Error 0.0000(0.0000) Steps 940(948.32) | Grad Norm 1.3394(1.5090) | Total Time 0.00(0.00)\n",
      "Iter 18420 | Time 25.8248(25.0651) | Bit/dim 3.3793(3.3595) | Xent 0.0000(0.0000) | Loss 8.8671(9.1407) | Error 0.0000(0.0000) Steps 928(946.60) | Grad Norm 2.0010(1.4783) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 115.8172, Epoch Time 1512.0490(1507.8178), Bit/dim 3.3671(best: 3.3638), Xent 0.0000, Loss 3.3671, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18430 | Time 24.7925(25.0636) | Bit/dim 3.4016(3.3625) | Xent 0.0000(0.0000) | Loss 8.9713(10.0360) | Error 0.0000(0.0000) Steps 958(949.24) | Grad Norm 2.5141(1.6631) | Total Time 0.00(0.00)\n",
      "Iter 18440 | Time 25.2043(25.0437) | Bit/dim 3.3242(3.3622) | Xent 0.0000(0.0000) | Loss 8.8596(9.7313) | Error 0.0000(0.0000) Steps 988(951.41) | Grad Norm 2.3878(1.8293) | Total Time 0.00(0.00)\n",
      "Iter 18450 | Time 24.2484(24.9716) | Bit/dim 3.3475(3.3601) | Xent 0.0000(0.0000) | Loss 8.6297(9.4785) | Error 0.0000(0.0000) Steps 946(946.78) | Grad Norm 2.4537(2.0028) | Total Time 0.00(0.00)\n",
      "Iter 18460 | Time 24.1949(24.9817) | Bit/dim 3.3847(3.3605) | Xent 0.0000(0.0000) | Loss 8.8165(9.3148) | Error 0.0000(0.0000) Steps 922(946.57) | Grad Norm 1.1306(1.8604) | Total Time 0.00(0.00)\n",
      "Iter 18470 | Time 25.7669(25.0968) | Bit/dim 3.3746(3.3602) | Xent 0.0000(0.0000) | Loss 8.9315(9.1778) | Error 0.0000(0.0000) Steps 970(950.51) | Grad Norm 1.0955(1.6728) | Total Time 0.00(0.00)\n",
      "Iter 18480 | Time 24.3222(25.0754) | Bit/dim 3.3695(3.3605) | Xent 0.0000(0.0000) | Loss 8.8532(9.0902) | Error 0.0000(0.0000) Steps 910(949.82) | Grad Norm 1.1515(1.5561) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 115.7159, Epoch Time 1512.0207(1507.9439), Bit/dim 3.3687(best: 3.3638), Xent 0.0000, Loss 3.3687, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18490 | Time 25.8452(25.1147) | Bit/dim 3.3690(3.3612) | Xent 0.0000(0.0000) | Loss 8.7652(9.8636) | Error 0.0000(0.0000) Steps 964(952.34) | Grad Norm 2.7574(1.6520) | Total Time 0.00(0.00)\n",
      "Iter 18500 | Time 25.7792(25.1110) | Bit/dim 3.3429(3.3604) | Xent 0.0000(0.0000) | Loss 8.8335(9.5956) | Error 0.0000(0.0000) Steps 940(951.71) | Grad Norm 1.7670(1.8702) | Total Time 0.00(0.00)\n",
      "Iter 18510 | Time 23.7315(25.0552) | Bit/dim 3.3681(3.3630) | Xent 0.0000(0.0000) | Loss 8.8735(9.4021) | Error 0.0000(0.0000) Steps 964(952.75) | Grad Norm 2.1538(2.0552) | Total Time 0.00(0.00)\n",
      "Iter 18520 | Time 25.1522(25.1079) | Bit/dim 3.3713(3.3619) | Xent 0.0000(0.0000) | Loss 8.8787(9.2482) | Error 0.0000(0.0000) Steps 892(952.02) | Grad Norm 3.2739(2.1961) | Total Time 0.00(0.00)\n",
      "Iter 18530 | Time 24.8065(25.0781) | Bit/dim 3.3257(3.3606) | Xent 0.0000(0.0000) | Loss 8.7945(9.1298) | Error 0.0000(0.0000) Steps 958(951.24) | Grad Norm 1.1525(2.0900) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 114.9135, Epoch Time 1511.4628(1508.0495), Bit/dim 3.3668(best: 3.3638), Xent 0.0000, Loss 3.3668, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18540 | Time 24.5617(24.9672) | Bit/dim 3.3424(3.3579) | Xent 0.0000(0.0000) | Loss 8.8601(9.9982) | Error 0.0000(0.0000) Steps 940(947.42) | Grad Norm 1.1013(1.8374) | Total Time 0.00(0.00)\n",
      "Iter 18550 | Time 25.6981(25.0234) | Bit/dim 3.3632(3.3569) | Xent 0.0000(0.0000) | Loss 8.8341(9.6829) | Error 0.0000(0.0000) Steps 916(945.86) | Grad Norm 1.7138(1.7052) | Total Time 0.00(0.00)\n",
      "Iter 18560 | Time 24.1260(25.0494) | Bit/dim 3.3839(3.3583) | Xent 0.0000(0.0000) | Loss 8.9098(9.4657) | Error 0.0000(0.0000) Steps 940(945.14) | Grad Norm 1.0004(1.7331) | Total Time 0.00(0.00)\n",
      "Iter 18570 | Time 24.3785(25.0460) | Bit/dim 3.3514(3.3594) | Xent 0.0000(0.0000) | Loss 8.6664(9.3094) | Error 0.0000(0.0000) Steps 940(948.59) | Grad Norm 2.1265(1.8892) | Total Time 0.00(0.00)\n",
      "Iter 18580 | Time 24.4060(24.9972) | Bit/dim 3.3737(3.3588) | Xent 0.0000(0.0000) | Loss 8.9652(9.1817) | Error 0.0000(0.0000) Steps 964(951.55) | Grad Norm 1.6329(1.8140) | Total Time 0.00(0.00)\n",
      "Iter 18590 | Time 24.1749(24.8989) | Bit/dim 3.3676(3.3591) | Xent 0.0000(0.0000) | Loss 8.8557(9.0873) | Error 0.0000(0.0000) Steps 916(950.81) | Grad Norm 1.3368(1.7424) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 116.6522, Epoch Time 1507.2207(1508.0246), Bit/dim 3.3666(best: 3.3638), Xent 0.0000, Loss 3.3666, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18600 | Time 25.0113(25.0009) | Bit/dim 3.3813(3.3597) | Xent 0.0000(0.0000) | Loss 8.8076(9.8508) | Error 0.0000(0.0000) Steps 946(949.29) | Grad Norm 1.8815(1.6927) | Total Time 0.00(0.00)\n",
      "Iter 18610 | Time 24.8084(24.9409) | Bit/dim 3.3638(3.3562) | Xent 0.0000(0.0000) | Loss 8.5920(9.5697) | Error 0.0000(0.0000) Steps 886(951.40) | Grad Norm 2.6040(1.7520) | Total Time 0.00(0.00)\n",
      "Iter 18620 | Time 25.2037(24.9894) | Bit/dim 3.3957(3.3580) | Xent 0.0000(0.0000) | Loss 8.9180(9.3796) | Error 0.0000(0.0000) Steps 934(950.64) | Grad Norm 1.8517(1.7150) | Total Time 0.00(0.00)\n",
      "Iter 18630 | Time 24.8925(25.0267) | Bit/dim 3.3637(3.3578) | Xent 0.0000(0.0000) | Loss 8.8449(9.2449) | Error 0.0000(0.0000) Steps 958(951.73) | Grad Norm 1.6574(1.6824) | Total Time 0.00(0.00)\n",
      "Iter 18640 | Time 25.0307(25.0132) | Bit/dim 3.3557(3.3600) | Xent 0.0000(0.0000) | Loss 8.9305(9.1390) | Error 0.0000(0.0000) Steps 934(951.99) | Grad Norm 1.4302(1.7136) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 115.7752, Epoch Time 1513.8892(1508.2006), Bit/dim 3.3670(best: 3.3638), Xent 0.0000, Loss 3.3670, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18650 | Time 23.9898(25.0273) | Bit/dim 3.3870(3.3606) | Xent 0.0000(0.0000) | Loss 8.9778(10.0399) | Error 0.0000(0.0000) Steps 934(954.55) | Grad Norm 2.1289(1.7669) | Total Time 0.00(0.00)\n",
      "Iter 18660 | Time 25.8137(25.0073) | Bit/dim 3.3152(3.3595) | Xent 0.0000(0.0000) | Loss 8.8781(9.7245) | Error 0.0000(0.0000) Steps 1006(956.57) | Grad Norm 2.7909(1.8845) | Total Time 0.00(0.00)\n",
      "Iter 18670 | Time 25.5631(25.1286) | Bit/dim 3.3850(3.3598) | Xent 0.0000(0.0000) | Loss 8.7798(9.4839) | Error 0.0000(0.0000) Steps 958(955.17) | Grad Norm 1.6044(1.8900) | Total Time 0.00(0.00)\n",
      "Iter 18680 | Time 25.1681(25.1288) | Bit/dim 3.3427(3.3592) | Xent 0.0000(0.0000) | Loss 8.6651(9.3068) | Error 0.0000(0.0000) Steps 940(954.99) | Grad Norm 1.7273(1.8203) | Total Time 0.00(0.00)\n",
      "Iter 18690 | Time 24.8767(25.1837) | Bit/dim 3.3089(3.3586) | Xent 0.0000(0.0000) | Loss 8.6494(9.1771) | Error 0.0000(0.0000) Steps 946(954.29) | Grad Norm 1.3613(1.7505) | Total Time 0.00(0.00)\n",
      "Iter 18700 | Time 25.7151(25.1593) | Bit/dim 3.3946(3.3596) | Xent 0.0000(0.0000) | Loss 9.0057(9.0872) | Error 0.0000(0.0000) Steps 952(953.48) | Grad Norm 1.0691(1.6451) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 114.9625, Epoch Time 1517.1115(1508.4679), Bit/dim 3.3620(best: 3.3638), Xent 0.0000, Loss 3.3620, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18710 | Time 26.3267(25.1366) | Bit/dim 3.3859(3.3591) | Xent 0.0000(0.0000) | Loss 8.8258(9.8502) | Error 0.0000(0.0000) Steps 952(953.31) | Grad Norm 2.5412(1.6965) | Total Time 0.00(0.00)\n",
      "Iter 18720 | Time 26.0884(25.2960) | Bit/dim 3.3449(3.3578) | Xent 0.0000(0.0000) | Loss 8.9717(9.5846) | Error 0.0000(0.0000) Steps 946(955.37) | Grad Norm 2.0711(1.7641) | Total Time 0.00(0.00)\n",
      "Iter 18730 | Time 28.4079(26.0898) | Bit/dim 3.2881(3.3570) | Xent 0.0000(0.0000) | Loss 8.7237(9.3944) | Error 0.0000(0.0000) Steps 1012(960.78) | Grad Norm 1.7841(1.9583) | Total Time 0.00(0.00)\n",
      "Iter 18740 | Time 29.0836(26.6714) | Bit/dim 3.4040(3.3607) | Xent 0.0000(0.0000) | Loss 8.9826(9.2523) | Error 0.0000(0.0000) Steps 946(963.23) | Grad Norm 1.6777(1.9699) | Total Time 0.00(0.00)\n",
      "Iter 18750 | Time 26.7908(26.3026) | Bit/dim 3.3581(3.3598) | Xent 0.0000(0.0000) | Loss 9.0031(9.1416) | Error 0.0000(0.0000) Steps 1000(962.40) | Grad Norm 1.1327(1.9350) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 117.3378, Epoch Time 1590.3874(1510.9255), Bit/dim 3.3660(best: 3.3620), Xent 0.0000, Loss 3.3660, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18760 | Time 29.6109(26.2293) | Bit/dim 3.3469(3.3582) | Xent 0.0000(0.0000) | Loss 8.8828(10.0712) | Error 0.0000(0.0000) Steps 1054(962.03) | Grad Norm 2.8357(2.0918) | Total Time 0.00(0.00)\n",
      "Iter 18770 | Time 26.5301(26.1185) | Bit/dim 3.3684(3.3603) | Xent 0.0000(0.0000) | Loss 8.9084(9.7568) | Error 0.0000(0.0000) Steps 1000(965.01) | Grad Norm 1.1090(2.0058) | Total Time 0.00(0.00)\n",
      "Iter 18780 | Time 25.3274(26.0400) | Bit/dim 3.3477(3.3603) | Xent 0.0000(0.0000) | Loss 8.8444(9.5252) | Error 0.0000(0.0000) Steps 958(964.51) | Grad Norm 2.3747(2.0691) | Total Time 0.00(0.00)\n",
      "Iter 18790 | Time 25.7767(26.0984) | Bit/dim 3.3870(3.3635) | Xent 0.0000(0.0000) | Loss 8.8998(9.3565) | Error 0.0000(0.0000) Steps 952(962.12) | Grad Norm 2.3121(2.3088) | Total Time 0.00(0.00)\n",
      "Iter 18800 | Time 26.9838(25.8948) | Bit/dim 3.3305(3.3612) | Xent 0.0000(0.0000) | Loss 8.6286(9.2022) | Error 0.0000(0.0000) Steps 952(959.46) | Grad Norm 1.6055(2.2219) | Total Time 0.00(0.00)\n",
      "Iter 18810 | Time 26.8102(25.8271) | Bit/dim 3.3336(3.3586) | Xent 0.0000(0.0000) | Loss 8.8783(9.1000) | Error 0.0000(0.0000) Steps 958(957.21) | Grad Norm 1.2331(2.1348) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 117.5827, Epoch Time 1555.1114(1512.2510), Bit/dim 3.3633(best: 3.3620), Xent 0.0000, Loss 3.3633, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18820 | Time 24.7778(25.6777) | Bit/dim 3.3509(3.3568) | Xent 0.0000(0.0000) | Loss 8.9000(9.8843) | Error 0.0000(0.0000) Steps 982(955.72) | Grad Norm 1.5833(2.0738) | Total Time 0.00(0.00)\n",
      "Iter 18830 | Time 26.7300(25.5135) | Bit/dim 3.3514(3.3589) | Xent 0.0000(0.0000) | Loss 8.7923(9.6004) | Error 0.0000(0.0000) Steps 940(950.68) | Grad Norm 2.5529(2.0976) | Total Time 0.00(0.00)\n",
      "Iter 18840 | Time 25.3207(25.4527) | Bit/dim 3.3648(3.3611) | Xent 0.0000(0.0000) | Loss 8.8600(9.4051) | Error 0.0000(0.0000) Steps 928(952.45) | Grad Norm 1.6204(2.1574) | Total Time 0.00(0.00)\n",
      "Iter 18850 | Time 25.2562(25.3659) | Bit/dim 3.3549(3.3607) | Xent 0.0000(0.0000) | Loss 8.9633(9.2702) | Error 0.0000(0.0000) Steps 952(952.92) | Grad Norm 1.8524(2.0749) | Total Time 0.00(0.00)\n",
      "Iter 18860 | Time 25.0580(25.3185) | Bit/dim 3.3261(3.3570) | Xent 0.0000(0.0000) | Loss 8.6353(9.1393) | Error 0.0000(0.0000) Steps 940(949.90) | Grad Norm 1.5988(2.0491) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 116.8841, Epoch Time 1518.6812(1512.4440), Bit/dim 3.3659(best: 3.3620), Xent 0.0000, Loss 3.3659, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18870 | Time 23.6498(25.2795) | Bit/dim 3.3384(3.3577) | Xent 0.0000(0.0000) | Loss 8.6148(10.0590) | Error 0.0000(0.0000) Steps 958(952.58) | Grad Norm 1.0891(1.9230) | Total Time 0.00(0.00)\n",
      "Iter 18880 | Time 24.2420(25.1898) | Bit/dim 3.3439(3.3552) | Xent 0.0000(0.0000) | Loss 8.8198(9.7262) | Error 0.0000(0.0000) Steps 934(950.33) | Grad Norm 1.4696(1.9153) | Total Time 0.00(0.00)\n",
      "Iter 18890 | Time 24.5889(25.0934) | Bit/dim 3.3417(3.3590) | Xent 0.0000(0.0000) | Loss 8.7706(9.4905) | Error 0.0000(0.0000) Steps 928(948.36) | Grad Norm 1.4745(1.7428) | Total Time 0.00(0.00)\n",
      "Iter 18900 | Time 25.5419(25.1817) | Bit/dim 3.3378(3.3611) | Xent 0.0000(0.0000) | Loss 8.7907(9.3245) | Error 0.0000(0.0000) Steps 958(948.09) | Grad Norm 1.6598(1.6462) | Total Time 0.00(0.00)\n",
      "Iter 18910 | Time 25.1590(25.2148) | Bit/dim 3.3797(3.3591) | Xent 0.0000(0.0000) | Loss 8.9684(9.1950) | Error 0.0000(0.0000) Steps 958(952.32) | Grad Norm 1.7240(1.5786) | Total Time 0.00(0.00)\n",
      "Iter 18920 | Time 25.7783(25.1401) | Bit/dim 3.3538(3.3591) | Xent 0.0000(0.0000) | Loss 8.7918(9.0942) | Error 0.0000(0.0000) Steps 994(956.43) | Grad Norm 2.0448(1.6580) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 116.4680, Epoch Time 1517.6186(1512.5992), Bit/dim 3.3632(best: 3.3620), Xent 0.0000, Loss 3.3632, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18930 | Time 25.2499(25.1619) | Bit/dim 3.3527(3.3599) | Xent 0.0000(0.0000) | Loss 8.8321(9.8725) | Error 0.0000(0.0000) Steps 922(959.10) | Grad Norm 1.5271(1.6810) | Total Time 0.00(0.00)\n",
      "Iter 18940 | Time 25.7314(25.1336) | Bit/dim 3.3376(3.3591) | Xent 0.0000(0.0000) | Loss 8.6368(9.5781) | Error 0.0000(0.0000) Steps 988(958.87) | Grad Norm 1.7339(1.7736) | Total Time 0.00(0.00)\n",
      "Iter 18950 | Time 25.0050(25.1514) | Bit/dim 3.3850(3.3610) | Xent 0.0000(0.0000) | Loss 8.8570(9.3947) | Error 0.0000(0.0000) Steps 934(954.95) | Grad Norm 2.1215(1.7839) | Total Time 0.00(0.00)\n",
      "Iter 18960 | Time 25.7092(25.3334) | Bit/dim 3.3544(3.3585) | Xent 0.0000(0.0000) | Loss 8.8712(9.2432) | Error 0.0000(0.0000) Steps 946(955.00) | Grad Norm 2.0785(1.8098) | Total Time 0.00(0.00)\n",
      "Iter 18970 | Time 24.9192(25.3348) | Bit/dim 3.3683(3.3584) | Xent 0.0000(0.0000) | Loss 8.7217(9.1349) | Error 0.0000(0.0000) Steps 958(955.31) | Grad Norm 1.0544(1.8432) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 116.7644, Epoch Time 1530.3703(1513.1323), Bit/dim 3.3614(best: 3.3620), Xent 0.0000, Loss 3.3614, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18980 | Time 24.8084(25.4954) | Bit/dim 3.3696(3.3586) | Xent 0.0000(0.0000) | Loss 9.0118(10.0330) | Error 0.0000(0.0000) Steps 994(955.05) | Grad Norm 1.0044(1.7709) | Total Time 0.00(0.00)\n",
      "Iter 18990 | Time 24.5817(25.5224) | Bit/dim 3.3423(3.3556) | Xent 0.0000(0.0000) | Loss 8.7439(9.7103) | Error 0.0000(0.0000) Steps 976(956.95) | Grad Norm 1.4129(1.6689) | Total Time 0.00(0.00)\n",
      "Iter 19000 | Time 25.1793(25.3670) | Bit/dim 3.3860(3.3586) | Xent 0.0000(0.0000) | Loss 8.8418(9.4828) | Error 0.0000(0.0000) Steps 994(958.02) | Grad Norm 0.9492(1.5974) | Total Time 0.00(0.00)\n",
      "Iter 19010 | Time 24.5228(25.3263) | Bit/dim 3.3218(3.3586) | Xent 0.0000(0.0000) | Loss 8.8181(9.3193) | Error 0.0000(0.0000) Steps 982(959.38) | Grad Norm 1.9625(1.6053) | Total Time 0.00(0.00)\n",
      "Iter 19020 | Time 25.7427(25.3238) | Bit/dim 3.3852(3.3623) | Xent 0.0000(0.0000) | Loss 8.9224(9.2015) | Error 0.0000(0.0000) Steps 958(959.40) | Grad Norm 1.2578(1.6203) | Total Time 0.00(0.00)\n",
      "Iter 19030 | Time 26.3902(25.3163) | Bit/dim 3.3614(3.3603) | Xent 0.0000(0.0000) | Loss 8.7005(9.0896) | Error 0.0000(0.0000) Steps 994(960.78) | Grad Norm 1.8144(1.5975) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 116.5935, Epoch Time 1529.5526(1513.6249), Bit/dim 3.3634(best: 3.3614), Xent 0.0000, Loss 3.3634, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19040 | Time 24.5415(25.2738) | Bit/dim 3.3539(3.3584) | Xent 0.0000(0.0000) | Loss 8.7739(9.8484) | Error 0.0000(0.0000) Steps 964(957.64) | Grad Norm 1.6836(1.6454) | Total Time 0.00(0.00)\n",
      "Iter 19050 | Time 25.5759(25.3624) | Bit/dim 3.3611(3.3597) | Xent 0.0000(0.0000) | Loss 8.9679(9.5932) | Error 0.0000(0.0000) Steps 940(955.74) | Grad Norm 2.8533(1.8785) | Total Time 0.00(0.00)\n",
      "Iter 19060 | Time 24.3679(25.2227) | Bit/dim 3.3315(3.3610) | Xent 0.0000(0.0000) | Loss 8.7213(9.4027) | Error 0.0000(0.0000) Steps 946(952.95) | Grad Norm 1.3282(1.8719) | Total Time 0.00(0.00)\n",
      "Iter 19070 | Time 26.0066(25.2815) | Bit/dim 3.3277(3.3593) | Xent 0.0000(0.0000) | Loss 8.6206(9.2301) | Error 0.0000(0.0000) Steps 904(948.98) | Grad Norm 2.3834(1.9911) | Total Time 0.00(0.00)\n",
      "Iter 19080 | Time 23.6173(25.0664) | Bit/dim 3.3386(3.3582) | Xent 0.0000(0.0000) | Loss 8.6094(9.1085) | Error 0.0000(0.0000) Steps 970(948.39) | Grad Norm 1.8029(1.9594) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 117.5822, Epoch Time 1518.2519(1513.7637), Bit/dim 3.3643(best: 3.3614), Xent 0.0000, Loss 3.3643, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19090 | Time 25.0025(25.0923) | Bit/dim 3.3491(3.3561) | Xent 0.0000(0.0000) | Loss 8.8552(9.9811) | Error 0.0000(0.0000) Steps 922(944.17) | Grad Norm 1.4614(1.7462) | Total Time 0.00(0.00)\n",
      "Iter 19100 | Time 25.7842(25.1794) | Bit/dim 3.3225(3.3576) | Xent 0.0000(0.0000) | Loss 8.6874(9.6732) | Error 0.0000(0.0000) Steps 970(944.57) | Grad Norm 1.7862(1.7010) | Total Time 0.00(0.00)\n",
      "Iter 19110 | Time 24.5019(25.1517) | Bit/dim 3.3734(3.3560) | Xent 0.0000(0.0000) | Loss 8.9564(9.4376) | Error 0.0000(0.0000) Steps 946(947.61) | Grad Norm 2.5749(1.8453) | Total Time 0.00(0.00)\n",
      "Iter 19120 | Time 24.7567(25.1639) | Bit/dim 3.3542(3.3593) | Xent 0.0000(0.0000) | Loss 8.9344(9.2844) | Error 0.0000(0.0000) Steps 982(949.87) | Grad Norm 1.8593(2.0038) | Total Time 0.00(0.00)\n",
      "Iter 19130 | Time 25.7156(25.1606) | Bit/dim 3.3610(3.3600) | Xent 0.0000(0.0000) | Loss 8.8030(9.1571) | Error 0.0000(0.0000) Steps 982(952.79) | Grad Norm 2.1056(1.9322) | Total Time 0.00(0.00)\n",
      "Iter 19140 | Time 25.2104(25.0636) | Bit/dim 3.3569(3.3582) | Xent 0.0000(0.0000) | Loss 8.8509(9.0716) | Error 0.0000(0.0000) Steps 946(950.93) | Grad Norm 1.4725(1.8671) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 115.6563, Epoch Time 1515.8490(1513.8263), Bit/dim 3.3625(best: 3.3614), Xent 0.0000, Loss 3.3625, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19150 | Time 24.3132(25.0452) | Bit/dim 3.3659(3.3588) | Xent 0.0000(0.0000) | Loss 8.7685(9.8551) | Error 0.0000(0.0000) Steps 934(948.58) | Grad Norm 1.6333(1.6967) | Total Time 0.00(0.00)\n",
      "Iter 19160 | Time 24.8197(25.0022) | Bit/dim 3.3655(3.3603) | Xent 0.0000(0.0000) | Loss 8.7459(9.5817) | Error 0.0000(0.0000) Steps 952(949.16) | Grad Norm 1.1138(1.7152) | Total Time 0.00(0.00)\n",
      "Iter 19170 | Time 26.0091(25.1157) | Bit/dim 3.3646(3.3578) | Xent 0.0000(0.0000) | Loss 8.7020(9.3700) | Error 0.0000(0.0000) Steps 928(946.18) | Grad Norm 1.8058(1.7101) | Total Time 0.00(0.00)\n",
      "Iter 19180 | Time 24.0268(25.1168) | Bit/dim 3.3571(3.3576) | Xent 0.0000(0.0000) | Loss 8.7917(9.2330) | Error 0.0000(0.0000) Steps 928(947.44) | Grad Norm 1.2350(1.6507) | Total Time 0.00(0.00)\n",
      "Iter 19190 | Time 26.2724(25.2376) | Bit/dim 3.3642(3.3574) | Xent 0.0000(0.0000) | Loss 8.8611(9.1324) | Error 0.0000(0.0000) Steps 940(948.45) | Grad Norm 1.0987(1.5883) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 115.3881, Epoch Time 1519.9847(1514.0111), Bit/dim 3.3602(best: 3.3614), Xent 0.0000, Loss 3.3602, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19200 | Time 24.7292(25.1714) | Bit/dim 3.3781(3.3581) | Xent 0.0000(0.0000) | Loss 8.8995(10.0371) | Error 0.0000(0.0000) Steps 922(950.00) | Grad Norm 1.6556(1.5355) | Total Time 0.00(0.00)\n",
      "Iter 19210 | Time 25.6223(25.2934) | Bit/dim 3.3731(3.3547) | Xent 0.0000(0.0000) | Loss 8.8143(9.7181) | Error 0.0000(0.0000) Steps 940(952.91) | Grad Norm 4.0676(1.7728) | Total Time 0.00(0.00)\n",
      "Iter 19220 | Time 27.5426(25.2516) | Bit/dim 3.3521(3.3566) | Xent 0.0000(0.0000) | Loss 8.8315(9.4878) | Error 0.0000(0.0000) Steps 976(950.50) | Grad Norm 1.4445(1.9787) | Total Time 0.00(0.00)\n",
      "Iter 19230 | Time 25.5854(25.1853) | Bit/dim 3.3357(3.3602) | Xent 0.0000(0.0000) | Loss 8.7936(9.3198) | Error 0.0000(0.0000) Steps 976(952.41) | Grad Norm 1.7501(1.8951) | Total Time 0.00(0.00)\n",
      "Iter 19240 | Time 24.7674(25.1305) | Bit/dim 3.3501(3.3585) | Xent 0.0000(0.0000) | Loss 8.8441(9.1911) | Error 0.0000(0.0000) Steps 940(951.41) | Grad Norm 1.1539(1.7588) | Total Time 0.00(0.00)\n",
      "Iter 19250 | Time 24.9074(25.1416) | Bit/dim 3.3745(3.3579) | Xent 0.0000(0.0000) | Loss 8.8904(9.1028) | Error 0.0000(0.0000) Steps 934(955.53) | Grad Norm 1.8821(1.6701) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 115.5464, Epoch Time 1517.7704(1514.1238), Bit/dim 3.3673(best: 3.3602), Xent 0.0000, Loss 3.3673, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19260 | Time 25.5720(25.1218) | Bit/dim 3.3485(3.3582) | Xent 0.0000(0.0000) | Loss 8.7572(9.8756) | Error 0.0000(0.0000) Steps 970(953.63) | Grad Norm 0.8509(1.5828) | Total Time 0.00(0.00)\n",
      "Iter 19270 | Time 25.0411(25.0925) | Bit/dim 3.3519(3.3591) | Xent 0.0000(0.0000) | Loss 8.7973(9.5937) | Error 0.0000(0.0000) Steps 970(951.71) | Grad Norm 1.4525(1.5394) | Total Time 0.00(0.00)\n",
      "Iter 19280 | Time 25.1832(25.0930) | Bit/dim 3.4009(3.3605) | Xent 0.0000(0.0000) | Loss 8.7972(9.4040) | Error 0.0000(0.0000) Steps 982(953.36) | Grad Norm 3.1385(1.6225) | Total Time 0.00(0.00)\n",
      "Iter 19290 | Time 24.6359(25.2552) | Bit/dim 3.3540(3.3590) | Xent 0.0000(0.0000) | Loss 8.8064(9.2433) | Error 0.0000(0.0000) Steps 970(953.18) | Grad Norm 2.5749(1.8506) | Total Time 0.00(0.00)\n",
      "Iter 19300 | Time 24.2405(25.1670) | Bit/dim 3.3683(3.3593) | Xent 0.0000(0.0000) | Loss 8.7303(9.1315) | Error 0.0000(0.0000) Steps 964(951.94) | Grad Norm 1.5809(1.9882) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 115.3277, Epoch Time 1515.7241(1514.1718), Bit/dim 3.3627(best: 3.3602), Xent 0.0000, Loss 3.3627, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19310 | Time 24.5865(25.1211) | Bit/dim 3.3497(3.3571) | Xent 0.0000(0.0000) | Loss 8.8848(10.0289) | Error 0.0000(0.0000) Steps 940(954.16) | Grad Norm 1.0163(1.9625) | Total Time 0.00(0.00)\n",
      "Iter 19320 | Time 25.1518(25.0972) | Bit/dim 3.3726(3.3599) | Xent 0.0000(0.0000) | Loss 8.7923(9.7258) | Error 0.0000(0.0000) Steps 934(951.76) | Grad Norm 2.3731(1.9818) | Total Time 0.00(0.00)\n",
      "Iter 19330 | Time 24.9359(25.2291) | Bit/dim 3.3591(3.3599) | Xent 0.0000(0.0000) | Loss 8.6645(9.4975) | Error 0.0000(0.0000) Steps 958(955.00) | Grad Norm 2.8930(2.0231) | Total Time 0.00(0.00)\n",
      "Iter 19340 | Time 24.4909(25.2550) | Bit/dim 3.3516(3.3592) | Xent 0.0000(0.0000) | Loss 8.7360(9.3056) | Error 0.0000(0.0000) Steps 934(952.41) | Grad Norm 4.5852(2.4411) | Total Time 0.00(0.00)\n",
      "Iter 19350 | Time 26.7107(25.2289) | Bit/dim 3.3712(3.3602) | Xent 0.0000(0.0000) | Loss 8.9864(9.1842) | Error 0.0000(0.0000) Steps 1000(954.70) | Grad Norm 3.0770(2.5137) | Total Time 0.00(0.00)\n",
      "Iter 19360 | Time 25.3263(25.1603) | Bit/dim 3.3375(3.3570) | Xent 0.0000(0.0000) | Loss 8.8345(9.0843) | Error 0.0000(0.0000) Steps 940(953.93) | Grad Norm 2.9253(2.4938) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 116.0584, Epoch Time 1520.8583(1514.3724), Bit/dim 3.3636(best: 3.3602), Xent 0.0000, Loss 3.3636, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19370 | Time 25.2715(25.1070) | Bit/dim 3.3391(3.3573) | Xent 0.0000(0.0000) | Loss 8.8371(9.8579) | Error 0.0000(0.0000) Steps 922(955.19) | Grad Norm 1.7158(2.3075) | Total Time 0.00(0.00)\n",
      "Iter 19380 | Time 23.5407(25.1195) | Bit/dim 3.3694(3.3580) | Xent 0.0000(0.0000) | Loss 8.7661(9.5863) | Error 0.0000(0.0000) Steps 904(950.29) | Grad Norm 1.9545(2.2359) | Total Time 0.00(0.00)\n",
      "Iter 19390 | Time 24.9002(25.1695) | Bit/dim 3.3453(3.3562) | Xent 0.0000(0.0000) | Loss 8.7121(9.3774) | Error 0.0000(0.0000) Steps 946(950.65) | Grad Norm 1.4695(2.0650) | Total Time 0.00(0.00)\n",
      "Iter 19400 | Time 24.0998(25.1609) | Bit/dim 3.3444(3.3563) | Xent 0.0000(0.0000) | Loss 8.6579(9.2320) | Error 0.0000(0.0000) Steps 958(952.79) | Grad Norm 0.9860(1.8722) | Total Time 0.00(0.00)\n",
      "Iter 19410 | Time 26.1946(25.1347) | Bit/dim 3.3646(3.3583) | Xent 0.0000(0.0000) | Loss 8.9014(9.1427) | Error 0.0000(0.0000) Steps 952(952.31) | Grad Norm 1.1615(1.7300) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 115.9840, Epoch Time 1519.5519(1514.5278), Bit/dim 3.3645(best: 3.3602), Xent 0.0000, Loss 3.3645, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19420 | Time 25.6644(25.3218) | Bit/dim 3.3300(3.3599) | Xent 0.0000(0.0000) | Loss 8.7188(10.0353) | Error 0.0000(0.0000) Steps 928(955.03) | Grad Norm 2.0882(1.6513) | Total Time 0.00(0.00)\n",
      "Iter 19430 | Time 24.7137(25.1796) | Bit/dim 3.3636(3.3572) | Xent 0.0000(0.0000) | Loss 8.7991(9.7145) | Error 0.0000(0.0000) Steps 940(953.91) | Grad Norm 1.7837(1.7590) | Total Time 0.00(0.00)\n",
      "Iter 19440 | Time 24.7427(25.1270) | Bit/dim 3.3837(3.3576) | Xent 0.0000(0.0000) | Loss 8.7429(9.4741) | Error 0.0000(0.0000) Steps 940(949.74) | Grad Norm 1.5321(1.7525) | Total Time 0.00(0.00)\n",
      "Iter 19450 | Time 24.5898(25.0833) | Bit/dim 3.3651(3.3600) | Xent 0.0000(0.0000) | Loss 8.7286(9.3027) | Error 0.0000(0.0000) Steps 934(948.56) | Grad Norm 1.9092(1.7067) | Total Time 0.00(0.00)\n",
      "Iter 19460 | Time 24.9855(25.1249) | Bit/dim 3.3378(3.3588) | Xent 0.0000(0.0000) | Loss 8.6944(9.1673) | Error 0.0000(0.0000) Steps 922(946.84) | Grad Norm 1.9430(1.9604) | Total Time 0.00(0.00)\n",
      "Iter 19470 | Time 25.8855(25.2848) | Bit/dim 3.3446(3.3571) | Xent 0.0000(0.0000) | Loss 8.7722(9.0603) | Error 0.0000(0.0000) Steps 970(951.50) | Grad Norm 1.2616(1.8450) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 118.7836, Epoch Time 1524.9041(1514.8391), Bit/dim 3.3661(best: 3.3602), Xent 0.0000, Loss 3.3661, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19480 | Time 24.0294(25.2034) | Bit/dim 3.3317(3.3579) | Xent 0.0000(0.0000) | Loss 8.6645(9.8434) | Error 0.0000(0.0000) Steps 952(954.68) | Grad Norm 3.9413(3.4997) | Total Time 0.00(0.00)\n",
      "Iter 19490 | Time 25.0951(25.0784) | Bit/dim 3.3565(3.3607) | Xent 0.0000(0.0000) | Loss 8.7146(9.5789) | Error 0.0000(0.0000) Steps 958(950.62) | Grad Norm 1.7378(3.3113) | Total Time 0.00(0.00)\n",
      "Iter 19500 | Time 25.1228(25.0571) | Bit/dim 3.3772(3.3603) | Xent 0.0000(0.0000) | Loss 8.9293(9.3837) | Error 0.0000(0.0000) Steps 958(952.01) | Grad Norm 1.7723(2.9199) | Total Time 0.00(0.00)\n",
      "Iter 19510 | Time 25.7633(25.1188) | Bit/dim 3.3374(3.3575) | Xent 0.0000(0.0000) | Loss 8.7243(9.2316) | Error 0.0000(0.0000) Steps 910(951.34) | Grad Norm 1.6112(2.5171) | Total Time 0.00(0.00)\n",
      "Iter 19520 | Time 24.3605(25.0920) | Bit/dim 3.3527(3.3586) | Xent 0.0000(0.0000) | Loss 8.8838(9.1323) | Error 0.0000(0.0000) Steps 952(949.94) | Grad Norm 1.5049(2.2048) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 117.0820, Epoch Time 1512.9180(1514.7815), Bit/dim 3.3656(best: 3.3602), Xent 0.0000, Loss 3.3656, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19530 | Time 24.9970(25.1633) | Bit/dim 3.3333(3.3576) | Xent 0.0000(0.0000) | Loss 8.8674(10.0349) | Error 0.0000(0.0000) Steps 976(952.92) | Grad Norm 0.9745(1.9716) | Total Time 0.00(0.00)\n",
      "Iter 19540 | Time 24.1572(25.1027) | Bit/dim 3.3425(3.3548) | Xent 0.0000(0.0000) | Loss 8.8650(9.7207) | Error 0.0000(0.0000) Steps 970(954.40) | Grad Norm 1.0216(1.7459) | Total Time 0.00(0.00)\n",
      "Iter 19550 | Time 24.3837(25.1101) | Bit/dim 3.3372(3.3560) | Xent 0.0000(0.0000) | Loss 8.7133(9.4829) | Error 0.0000(0.0000) Steps 958(957.18) | Grad Norm 1.0874(1.6657) | Total Time 0.00(0.00)\n",
      "Iter 19560 | Time 24.5757(25.0148) | Bit/dim 3.3513(3.3583) | Xent 0.0000(0.0000) | Loss 8.8376(9.3049) | Error 0.0000(0.0000) Steps 916(956.49) | Grad Norm 1.2711(1.6151) | Total Time 0.00(0.00)\n",
      "Iter 19570 | Time 24.2852(24.9363) | Bit/dim 3.3607(3.3609) | Xent 0.0000(0.0000) | Loss 8.6755(9.1865) | Error 0.0000(0.0000) Steps 916(954.02) | Grad Norm 1.2765(1.4884) | Total Time 0.00(0.00)\n",
      "Iter 19580 | Time 24.3356(24.9270) | Bit/dim 3.3492(3.3595) | Xent 0.0000(0.0000) | Loss 8.7224(9.0800) | Error 0.0000(0.0000) Steps 928(953.47) | Grad Norm 0.8255(1.3685) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 115.8933, Epoch Time 1505.6129(1514.5064), Bit/dim 3.3620(best: 3.3602), Xent 0.0000, Loss 3.3620, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19590 | Time 24.8943(25.0734) | Bit/dim 3.3933(3.3597) | Xent 0.0000(0.0000) | Loss 8.9256(9.8558) | Error 0.0000(0.0000) Steps 952(954.04) | Grad Norm 1.5689(1.3472) | Total Time 0.00(0.00)\n",
      "Iter 19600 | Time 26.0558(25.0091) | Bit/dim 3.3365(3.3573) | Xent 0.0000(0.0000) | Loss 8.9513(9.5859) | Error 0.0000(0.0000) Steps 1000(952.52) | Grad Norm 1.3055(1.3191) | Total Time 0.00(0.00)\n",
      "Iter 19610 | Time 24.4837(24.9570) | Bit/dim 3.4121(3.3577) | Xent 0.0000(0.0000) | Loss 8.9233(9.3864) | Error 0.0000(0.0000) Steps 946(950.33) | Grad Norm 1.6914(1.4878) | Total Time 0.00(0.00)\n",
      "Iter 19620 | Time 25.4040(24.9300) | Bit/dim 3.3796(3.3575) | Xent 0.0000(0.0000) | Loss 8.9157(9.2297) | Error 0.0000(0.0000) Steps 994(954.56) | Grad Norm 1.3792(1.5435) | Total Time 0.00(0.00)\n",
      "Iter 19630 | Time 25.3784(25.0280) | Bit/dim 3.3738(3.3577) | Xent 0.0000(0.0000) | Loss 8.8667(9.1168) | Error 0.0000(0.0000) Steps 934(951.05) | Grad Norm 1.6720(1.5956) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 115.5141, Epoch Time 1509.9584(1514.3700), Bit/dim 3.3634(best: 3.3602), Xent 0.0000, Loss 3.3634, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19640 | Time 26.5483(25.0302) | Bit/dim 3.3531(3.3592) | Xent 0.0000(0.0000) | Loss 8.7754(10.0049) | Error 0.0000(0.0000) Steps 952(948.94) | Grad Norm 2.2870(1.6263) | Total Time 0.00(0.00)\n",
      "Iter 19650 | Time 24.8420(24.9221) | Bit/dim 3.3561(3.3587) | Xent 0.0000(0.0000) | Loss 8.8727(9.6994) | Error 0.0000(0.0000) Steps 952(949.93) | Grad Norm 1.6210(1.6231) | Total Time 0.00(0.00)\n",
      "Iter 19660 | Time 24.3132(24.8991) | Bit/dim 3.3818(3.3606) | Xent 0.0000(0.0000) | Loss 8.9094(9.4815) | Error 0.0000(0.0000) Steps 946(950.48) | Grad Norm 1.4669(1.6129) | Total Time 0.00(0.00)\n",
      "Iter 19670 | Time 24.8255(24.8554) | Bit/dim 3.3318(3.3591) | Xent 0.0000(0.0000) | Loss 8.8246(9.3030) | Error 0.0000(0.0000) Steps 934(948.29) | Grad Norm 0.8167(1.5889) | Total Time 0.00(0.00)\n",
      "Iter 19680 | Time 24.3967(24.9138) | Bit/dim 3.3364(3.3580) | Xent 0.0000(0.0000) | Loss 8.8565(9.1805) | Error 0.0000(0.0000) Steps 934(944.36) | Grad Norm 1.7273(1.6066) | Total Time 0.00(0.00)\n",
      "Iter 19690 | Time 26.1778(24.8711) | Bit/dim 3.3639(3.3563) | Xent 0.0000(0.0000) | Loss 8.9072(9.0868) | Error 0.0000(0.0000) Steps 934(944.21) | Grad Norm 1.7125(1.5435) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 117.4446, Epoch Time 1503.4714(1514.0430), Bit/dim 3.3614(best: 3.3602), Xent 0.0000, Loss 3.3614, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19700 | Time 25.5967(24.9089) | Bit/dim 3.3256(3.3571) | Xent 0.0000(0.0000) | Loss 8.8338(9.8498) | Error 0.0000(0.0000) Steps 994(945.88) | Grad Norm 2.0435(1.5619) | Total Time 0.00(0.00)\n",
      "Iter 19710 | Time 25.1482(25.1203) | Bit/dim 3.3749(3.3564) | Xent 0.0000(0.0000) | Loss 8.9110(9.5880) | Error 0.0000(0.0000) Steps 946(950.06) | Grad Norm 1.1759(1.4699) | Total Time 0.00(0.00)\n",
      "Iter 19720 | Time 25.3799(25.1102) | Bit/dim 3.3184(3.3523) | Xent 0.0000(0.0000) | Loss 8.7751(9.3835) | Error 0.0000(0.0000) Steps 952(952.90) | Grad Norm 1.2063(1.5183) | Total Time 0.00(0.00)\n",
      "Iter 19730 | Time 24.5237(25.0397) | Bit/dim 3.3866(3.3550) | Xent 0.0000(0.0000) | Loss 8.9273(9.2476) | Error 0.0000(0.0000) Steps 964(956.99) | Grad Norm 1.0669(1.4529) | Total Time 0.00(0.00)\n",
      "Iter 19740 | Time 24.5998(25.0304) | Bit/dim 3.3544(3.3555) | Xent 0.0000(0.0000) | Loss 8.8126(9.1312) | Error 0.0000(0.0000) Steps 958(953.06) | Grad Norm 3.2449(1.5824) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 115.6803, Epoch Time 1517.6946(1514.1526), Bit/dim 3.3617(best: 3.3602), Xent 0.0000, Loss 3.3617, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19750 | Time 23.7504(24.9979) | Bit/dim 3.3238(3.3551) | Xent 0.0000(0.0000) | Loss 8.7117(10.0287) | Error 0.0000(0.0000) Steps 952(951.49) | Grad Norm 1.4688(1.6614) | Total Time 0.00(0.00)\n",
      "Iter 19760 | Time 24.5568(25.0014) | Bit/dim 3.3613(3.3572) | Xent 0.0000(0.0000) | Loss 8.8753(9.7098) | Error 0.0000(0.0000) Steps 940(949.93) | Grad Norm 1.3761(1.6115) | Total Time 0.00(0.00)\n",
      "Iter 19770 | Time 24.5850(25.0265) | Bit/dim 3.3163(3.3573) | Xent 0.0000(0.0000) | Loss 8.8043(9.4760) | Error 0.0000(0.0000) Steps 928(948.86) | Grad Norm 1.1320(1.4825) | Total Time 0.00(0.00)\n",
      "Iter 19780 | Time 25.8063(24.9462) | Bit/dim 3.3682(3.3575) | Xent 0.0000(0.0000) | Loss 8.8774(9.3113) | Error 0.0000(0.0000) Steps 934(950.82) | Grad Norm 1.2411(1.3913) | Total Time 0.00(0.00)\n",
      "Iter 19790 | Time 25.2665(24.9979) | Bit/dim 3.3639(3.3556) | Xent 0.0000(0.0000) | Loss 8.9507(9.1822) | Error 0.0000(0.0000) Steps 964(951.60) | Grad Norm 2.0140(1.3625) | Total Time 0.00(0.00)\n",
      "Iter 19800 | Time 26.9875(24.9958) | Bit/dim 3.3584(3.3553) | Xent 0.0000(0.0000) | Loss 8.8325(9.0811) | Error 0.0000(0.0000) Steps 976(949.12) | Grad Norm 1.9120(1.4222) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 115.7647, Epoch Time 1507.7362(1513.9601), Bit/dim 3.3664(best: 3.3602), Xent 0.0000, Loss 3.3664, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19810 | Time 25.5354(24.9493) | Bit/dim 3.3371(3.3574) | Xent 0.0000(0.0000) | Loss 8.7527(9.8451) | Error 0.0000(0.0000) Steps 916(948.80) | Grad Norm 1.4602(1.5288) | Total Time 0.00(0.00)\n",
      "Iter 19820 | Time 25.8976(24.9708) | Bit/dim 3.3316(3.3576) | Xent 0.0000(0.0000) | Loss 8.6537(9.5768) | Error 0.0000(0.0000) Steps 940(949.61) | Grad Norm 1.5304(1.5571) | Total Time 0.00(0.00)\n",
      "Iter 19830 | Time 24.9193(24.9021) | Bit/dim 3.3693(3.3573) | Xent 0.0000(0.0000) | Loss 8.8251(9.3666) | Error 0.0000(0.0000) Steps 970(947.55) | Grad Norm 2.0130(1.5968) | Total Time 0.00(0.00)\n",
      "Iter 19840 | Time 25.8620(24.8854) | Bit/dim 3.3329(3.3569) | Xent 0.0000(0.0000) | Loss 8.7335(9.2157) | Error 0.0000(0.0000) Steps 982(949.44) | Grad Norm 1.4467(1.7305) | Total Time 0.00(0.00)\n",
      "Iter 19850 | Time 24.2660(24.8715) | Bit/dim 3.3370(3.3561) | Xent 0.0000(0.0000) | Loss 8.7622(9.1095) | Error 0.0000(0.0000) Steps 982(949.04) | Grad Norm 1.6853(1.6867) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 117.9081, Epoch Time 1503.9955(1513.6611), Bit/dim 3.3622(best: 3.3602), Xent 0.0000, Loss 3.3622, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19860 | Time 24.1474(24.7870) | Bit/dim 3.3573(3.3570) | Xent 0.0000(0.0000) | Loss 8.6637(10.0087) | Error 0.0000(0.0000) Steps 934(949.93) | Grad Norm 0.9320(1.6992) | Total Time 0.00(0.00)\n",
      "Iter 19870 | Time 24.5909(24.9250) | Bit/dim 3.3558(3.3577) | Xent 0.0000(0.0000) | Loss 8.8660(9.7018) | Error 0.0000(0.0000) Steps 934(948.71) | Grad Norm 1.1118(1.7751) | Total Time 0.00(0.00)\n",
      "Iter 19880 | Time 25.1278(24.8743) | Bit/dim 3.3631(3.3584) | Xent 0.0000(0.0000) | Loss 8.7773(9.4590) | Error 0.0000(0.0000) Steps 928(945.19) | Grad Norm 1.8704(1.7584) | Total Time 0.00(0.00)\n",
      "Iter 19890 | Time 24.1323(24.8440) | Bit/dim 3.3335(3.3583) | Xent 0.0000(0.0000) | Loss 8.7604(9.2936) | Error 0.0000(0.0000) Steps 946(945.22) | Grad Norm 1.2808(1.7751) | Total Time 0.00(0.00)\n",
      "Iter 19900 | Time 24.2404(24.9523) | Bit/dim 3.3098(3.3555) | Xent 0.0000(0.0000) | Loss 8.6136(9.1662) | Error 0.0000(0.0000) Steps 904(942.57) | Grad Norm 1.2923(1.7005) | Total Time 0.00(0.00)\n",
      "Iter 19910 | Time 24.5399(24.9651) | Bit/dim 3.3783(3.3554) | Xent 0.0000(0.0000) | Loss 8.9077(9.0746) | Error 0.0000(0.0000) Steps 928(941.02) | Grad Norm 2.0102(1.7282) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 116.3962, Epoch Time 1505.7736(1513.4245), Bit/dim 3.3621(best: 3.3602), Xent 0.0000, Loss 3.3621, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19920 | Time 25.4845(24.9075) | Bit/dim 3.3965(3.3564) | Xent 0.0000(0.0000) | Loss 8.8663(9.8757) | Error 0.0000(0.0000) Steps 958(941.90) | Grad Norm 1.8071(1.7319) | Total Time 0.00(0.00)\n",
      "Iter 19930 | Time 26.8363(24.9543) | Bit/dim 3.3892(3.3559) | Xent 0.0000(0.0000) | Loss 8.8831(9.5900) | Error 0.0000(0.0000) Steps 1000(944.50) | Grad Norm 1.1020(1.6451) | Total Time 0.00(0.00)\n",
      "Iter 19940 | Time 26.4815(25.0267) | Bit/dim 3.3298(3.3549) | Xent 0.0000(0.0000) | Loss 8.8562(9.3873) | Error 0.0000(0.0000) Steps 976(947.46) | Grad Norm 0.9289(1.5118) | Total Time 0.00(0.00)\n",
      "Iter 19950 | Time 24.5981(25.0670) | Bit/dim 3.3824(3.3541) | Xent 0.0000(0.0000) | Loss 8.6308(9.2207) | Error 0.0000(0.0000) Steps 910(945.35) | Grad Norm 1.6487(1.4815) | Total Time 0.00(0.00)\n",
      "Iter 19960 | Time 24.2846(24.9739) | Bit/dim 3.3652(3.3564) | Xent 0.0000(0.0000) | Loss 8.8283(9.1171) | Error 0.0000(0.0000) Steps 946(948.02) | Grad Norm 1.0989(1.4076) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 115.7576, Epoch Time 1506.9614(1513.2306), Bit/dim 3.3631(best: 3.3602), Xent 0.0000, Loss 3.3631, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19970 | Time 24.7867(24.9366) | Bit/dim 3.3731(3.3581) | Xent 0.0000(0.0000) | Loss 8.8107(10.0165) | Error 0.0000(0.0000) Steps 910(946.96) | Grad Norm 1.9046(1.4593) | Total Time 0.00(0.00)\n",
      "Iter 19980 | Time 25.0138(25.0921) | Bit/dim 3.3694(3.3598) | Xent 0.0000(0.0000) | Loss 8.8668(9.7146) | Error 0.0000(0.0000) Steps 958(950.60) | Grad Norm 2.0198(1.5201) | Total Time 0.00(0.00)\n",
      "Iter 19990 | Time 24.8362(25.0873) | Bit/dim 3.3570(3.3584) | Xent 0.0000(0.0000) | Loss 8.8603(9.4843) | Error 0.0000(0.0000) Steps 946(949.42) | Grad Norm 2.0781(1.5981) | Total Time 0.00(0.00)\n",
      "Iter 20000 | Time 24.3971(25.1467) | Bit/dim 3.3269(3.3556) | Xent 0.0000(0.0000) | Loss 8.9375(9.3131) | Error 0.0000(0.0000) Steps 970(953.56) | Grad Norm 1.3921(1.6324) | Total Time 0.00(0.00)\n",
      "Iter 20010 | Time 24.1367(25.0869) | Bit/dim 3.3675(3.3536) | Xent 0.0000(0.0000) | Loss 8.8779(9.1848) | Error 0.0000(0.0000) Steps 940(953.14) | Grad Norm 1.4059(1.5941) | Total Time 0.00(0.00)\n",
      "Iter 20020 | Time 24.4219(25.1640) | Bit/dim 3.3386(3.3565) | Xent 0.0000(0.0000) | Loss 8.8867(9.0940) | Error 0.0000(0.0000) Steps 928(949.07) | Grad Norm 1.8272(1.7498) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 115.8649, Epoch Time 1521.6051(1513.4819), Bit/dim 3.3625(best: 3.3602), Xent 0.0000, Loss 3.3625, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20030 | Time 27.6957(25.3657) | Bit/dim 3.3610(3.3564) | Xent 0.0000(0.0000) | Loss 8.8624(9.8639) | Error 0.0000(0.0000) Steps 1012(953.18) | Grad Norm 0.9625(1.7807) | Total Time 0.00(0.00)\n",
      "Iter 20040 | Time 24.0206(25.2675) | Bit/dim 3.2864(3.3521) | Xent 0.0000(0.0000) | Loss 8.7145(9.5789) | Error 0.0000(0.0000) Steps 940(948.05) | Grad Norm 1.3217(1.6464) | Total Time 0.00(0.00)\n",
      "Iter 20050 | Time 24.1381(25.1330) | Bit/dim 3.3722(3.3522) | Xent 0.0000(0.0000) | Loss 8.8180(9.3793) | Error 0.0000(0.0000) Steps 976(951.69) | Grad Norm 0.9184(1.5384) | Total Time 0.00(0.00)\n",
      "Iter 20060 | Time 25.2788(25.0976) | Bit/dim 3.3343(3.3548) | Xent 0.0000(0.0000) | Loss 8.7843(9.2261) | Error 0.0000(0.0000) Steps 934(950.60) | Grad Norm 1.5015(1.5481) | Total Time 0.00(0.00)\n",
      "Iter 20070 | Time 26.2481(24.9761) | Bit/dim 3.3274(3.3609) | Xent 0.0000(0.0000) | Loss 8.7721(9.1233) | Error 0.0000(0.0000) Steps 964(947.56) | Grad Norm 1.5252(1.5156) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 115.6923, Epoch Time 1511.6233(1513.4261), Bit/dim 3.3668(best: 3.3602), Xent 0.0000, Loss 3.3668, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20080 | Time 25.4638(24.9338) | Bit/dim 3.3513(3.3582) | Xent 0.0000(0.0000) | Loss 8.9026(10.0312) | Error 0.0000(0.0000) Steps 946(948.13) | Grad Norm 1.3484(1.4947) | Total Time 0.00(0.00)\n",
      "Iter 20090 | Time 25.0447(24.9155) | Bit/dim 3.3594(3.3602) | Xent 0.0000(0.0000) | Loss 8.9701(9.7294) | Error 0.0000(0.0000) Steps 988(952.28) | Grad Norm 2.3157(1.5911) | Total Time 0.00(0.00)\n",
      "Iter 20100 | Time 24.4847(24.9504) | Bit/dim 3.3575(3.3603) | Xent 0.0000(0.0000) | Loss 8.8375(9.4997) | Error 0.0000(0.0000) Steps 958(954.93) | Grad Norm 1.7554(1.5424) | Total Time 0.00(0.00)\n",
      "Iter 20110 | Time 24.6739(25.0011) | Bit/dim 3.3630(3.3593) | Xent 0.0000(0.0000) | Loss 8.8853(9.3335) | Error 0.0000(0.0000) Steps 952(956.52) | Grad Norm 2.1339(1.6824) | Total Time 0.00(0.00)\n",
      "Iter 20120 | Time 24.5248(24.9182) | Bit/dim 3.3561(3.3582) | Xent 0.0000(0.0000) | Loss 8.7961(9.2025) | Error 0.0000(0.0000) Steps 964(956.72) | Grad Norm 1.4024(1.6981) | Total Time 0.00(0.00)\n",
      "Iter 20130 | Time 24.9286(24.9639) | Bit/dim 3.3558(3.3551) | Xent 0.0000(0.0000) | Loss 8.7680(9.0847) | Error 0.0000(0.0000) Steps 952(955.20) | Grad Norm 1.4568(1.7139) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 115.2692, Epoch Time 1505.6599(1513.1931), Bit/dim 3.3601(best: 3.3602), Xent 0.0000, Loss 3.3601, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20140 | Time 24.3689(24.9314) | Bit/dim 3.3479(3.3565) | Xent 0.0000(0.0000) | Loss 8.8682(9.8373) | Error 0.0000(0.0000) Steps 946(953.39) | Grad Norm 1.6029(1.6299) | Total Time 0.00(0.00)\n",
      "Iter 20150 | Time 25.4209(25.0312) | Bit/dim 3.3481(3.3563) | Xent 0.0000(0.0000) | Loss 8.9841(9.5808) | Error 0.0000(0.0000) Steps 994(951.51) | Grad Norm 1.2742(1.6224) | Total Time 0.00(0.00)\n",
      "Iter 20160 | Time 24.8550(25.0531) | Bit/dim 3.3463(3.3551) | Xent 0.0000(0.0000) | Loss 8.7567(9.3718) | Error 0.0000(0.0000) Steps 970(954.44) | Grad Norm 1.0864(1.6930) | Total Time 0.00(0.00)\n",
      "Iter 20170 | Time 25.0947(25.1066) | Bit/dim 3.3533(3.3555) | Xent 0.0000(0.0000) | Loss 8.8664(9.2186) | Error 0.0000(0.0000) Steps 970(952.18) | Grad Norm 1.8193(1.7164) | Total Time 0.00(0.00)\n",
      "Iter 20180 | Time 25.6539(25.0485) | Bit/dim 3.3503(3.3544) | Xent 0.0000(0.0000) | Loss 8.7429(9.1127) | Error 0.0000(0.0000) Steps 958(949.51) | Grad Norm 2.2498(1.7167) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 115.9425, Epoch Time 1515.3913(1513.2591), Bit/dim 3.3611(best: 3.3601), Xent 0.0000, Loss 3.3611, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20190 | Time 25.0686(25.0222) | Bit/dim 3.3615(3.3529) | Xent 0.0000(0.0000) | Loss 8.9270(10.0082) | Error 0.0000(0.0000) Steps 964(952.35) | Grad Norm 1.4229(1.6255) | Total Time 0.00(0.00)\n",
      "Iter 20200 | Time 26.7838(25.0026) | Bit/dim 3.4149(3.3553) | Xent 0.0000(0.0000) | Loss 8.9179(9.7012) | Error 0.0000(0.0000) Steps 910(949.90) | Grad Norm 2.0891(1.6849) | Total Time 0.00(0.00)\n",
      "Iter 20210 | Time 24.2933(24.9262) | Bit/dim 3.3503(3.3554) | Xent 0.0000(0.0000) | Loss 8.7783(9.4657) | Error 0.0000(0.0000) Steps 976(951.59) | Grad Norm 1.1321(1.6788) | Total Time 0.00(0.00)\n",
      "Iter 20220 | Time 24.0240(24.8132) | Bit/dim 3.3565(3.3568) | Xent 0.0000(0.0000) | Loss 8.7802(9.2912) | Error 0.0000(0.0000) Steps 964(951.43) | Grad Norm 1.6734(1.7249) | Total Time 0.00(0.00)\n",
      "Iter 20230 | Time 25.9047(24.8438) | Bit/dim 3.3325(3.3546) | Xent 0.0000(0.0000) | Loss 8.7709(9.1702) | Error 0.0000(0.0000) Steps 922(949.97) | Grad Norm 2.8416(1.8312) | Total Time 0.00(0.00)\n",
      "Iter 20240 | Time 24.3332(24.7990) | Bit/dim 3.3822(3.3557) | Xent 0.0000(0.0000) | Loss 8.8793(9.0790) | Error 0.0000(0.0000) Steps 976(950.05) | Grad Norm 2.3670(1.9613) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 115.1043, Epoch Time 1494.1190(1512.6849), Bit/dim 3.3592(best: 3.3601), Xent 0.0000, Loss 3.3592, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20250 | Time 25.6785(24.8551) | Bit/dim 3.3369(3.3526) | Xent 0.0000(0.0000) | Loss 8.6786(9.8274) | Error 0.0000(0.0000) Steps 988(951.07) | Grad Norm 1.7305(1.8424) | Total Time 0.00(0.00)\n",
      "Iter 20260 | Time 25.2262(24.8385) | Bit/dim 3.3510(3.3544) | Xent 0.0000(0.0000) | Loss 8.8907(9.5624) | Error 0.0000(0.0000) Steps 982(952.95) | Grad Norm 1.9671(1.8312) | Total Time 0.00(0.00)\n",
      "Iter 20270 | Time 24.7699(25.0129) | Bit/dim 3.3522(3.3547) | Xent 0.0000(0.0000) | Loss 8.8293(9.3754) | Error 0.0000(0.0000) Steps 928(953.93) | Grad Norm 2.4001(1.9619) | Total Time 0.00(0.00)\n",
      "Iter 20280 | Time 24.8905(24.9992) | Bit/dim 3.3609(3.3536) | Xent 0.0000(0.0000) | Loss 8.8332(9.2284) | Error 0.0000(0.0000) Steps 964(952.97) | Grad Norm 1.3053(1.8375) | Total Time 0.00(0.00)\n",
      "Iter 20290 | Time 23.9567(24.8005) | Bit/dim 3.3421(3.3544) | Xent 0.0000(0.0000) | Loss 8.8874(9.1193) | Error 0.0000(0.0000) Steps 946(952.02) | Grad Norm 1.9773(1.7455) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 116.0362, Epoch Time 1505.4994(1512.4693), Bit/dim 3.3605(best: 3.3592), Xent 0.0000, Loss 3.3605, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20300 | Time 24.5309(24.8867) | Bit/dim 3.3697(3.3553) | Xent 0.0000(0.0000) | Loss 8.9434(9.9954) | Error 0.0000(0.0000) Steps 994(948.44) | Grad Norm 2.7532(1.7830) | Total Time 0.00(0.00)\n",
      "Iter 20310 | Time 24.0247(24.8346) | Bit/dim 3.3883(3.3575) | Xent 0.0000(0.0000) | Loss 8.9061(9.7003) | Error 0.0000(0.0000) Steps 940(950.50) | Grad Norm 2.4738(1.8336) | Total Time 0.00(0.00)\n",
      "Iter 20320 | Time 23.7726(24.8226) | Bit/dim 3.3304(3.3566) | Xent 0.0000(0.0000) | Loss 8.6736(9.4653) | Error 0.0000(0.0000) Steps 946(950.65) | Grad Norm 1.7928(1.8780) | Total Time 0.00(0.00)\n",
      "Iter 20330 | Time 24.8455(24.8546) | Bit/dim 3.3372(3.3531) | Xent 0.0000(0.0000) | Loss 8.6539(9.2980) | Error 0.0000(0.0000) Steps 916(950.63) | Grad Norm 1.4975(1.9208) | Total Time 0.00(0.00)\n",
      "Iter 20340 | Time 24.3335(24.8453) | Bit/dim 3.3239(3.3559) | Xent 0.0000(0.0000) | Loss 8.6530(9.1643) | Error 0.0000(0.0000) Steps 934(948.86) | Grad Norm 1.0526(1.8042) | Total Time 0.00(0.00)\n",
      "Iter 20350 | Time 25.3301(24.8783) | Bit/dim 3.3190(3.3570) | Xent 0.0000(0.0000) | Loss 8.6217(9.0635) | Error 0.0000(0.0000) Steps 916(947.24) | Grad Norm 1.2947(1.6975) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 115.4493, Epoch Time 1501.6793(1512.1456), Bit/dim 3.3612(best: 3.3592), Xent 0.0000, Loss 3.3612, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20360 | Time 24.1775(24.8090) | Bit/dim 3.3716(3.3553) | Xent 0.0000(0.0000) | Loss 8.7700(9.8558) | Error 0.0000(0.0000) Steps 946(947.81) | Grad Norm 1.2546(1.6124) | Total Time 0.00(0.00)\n",
      "Iter 20370 | Time 24.7811(24.8734) | Bit/dim 3.3493(3.3567) | Xent 0.0000(0.0000) | Loss 8.7891(9.5937) | Error 0.0000(0.0000) Steps 910(947.95) | Grad Norm 1.0178(1.5698) | Total Time 0.00(0.00)\n",
      "Iter 20380 | Time 24.7590(24.7760) | Bit/dim 3.3625(3.3550) | Xent 0.0000(0.0000) | Loss 8.9430(9.3995) | Error 0.0000(0.0000) Steps 940(950.08) | Grad Norm 1.8023(1.5419) | Total Time 0.00(0.00)\n",
      "Iter 20390 | Time 25.5003(24.7695) | Bit/dim 3.3706(3.3561) | Xent 0.0000(0.0000) | Loss 9.0336(9.2463) | Error 0.0000(0.0000) Steps 970(950.77) | Grad Norm 1.3105(1.5208) | Total Time 0.00(0.00)\n",
      "Iter 20400 | Time 24.9901(24.6392) | Bit/dim 3.3614(3.3576) | Xent 0.0000(0.0000) | Loss 8.7803(9.1384) | Error 0.0000(0.0000) Steps 940(948.85) | Grad Norm 1.9586(1.6519) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 116.1994, Epoch Time 1487.2329(1511.3982), Bit/dim 3.3660(best: 3.3592), Xent 0.0000, Loss 3.3660, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20410 | Time 25.2234(24.6027) | Bit/dim 3.3499(3.3590) | Xent 0.0000(0.0000) | Loss 8.8900(10.0518) | Error 0.0000(0.0000) Steps 922(947.14) | Grad Norm 2.7835(1.6912) | Total Time 0.00(0.00)\n",
      "Iter 20420 | Time 24.0454(24.5503) | Bit/dim 3.3528(3.3539) | Xent 0.0000(0.0000) | Loss 8.8391(9.7070) | Error 0.0000(0.0000) Steps 958(949.42) | Grad Norm 2.8750(1.8263) | Total Time 0.00(0.00)\n",
      "Iter 20430 | Time 24.0133(24.6400) | Bit/dim 3.3179(3.3537) | Xent 0.0000(0.0000) | Loss 8.6912(9.4709) | Error 0.0000(0.0000) Steps 952(948.39) | Grad Norm 1.9508(1.9712) | Total Time 0.00(0.00)\n",
      "Iter 20440 | Time 24.0922(24.6377) | Bit/dim 3.3472(3.3541) | Xent 0.0000(0.0000) | Loss 8.8234(9.3019) | Error 0.0000(0.0000) Steps 946(951.59) | Grad Norm 2.2720(2.1365) | Total Time 0.00(0.00)\n",
      "Iter 20450 | Time 24.5573(24.7320) | Bit/dim 3.3356(3.3556) | Xent 0.0000(0.0000) | Loss 8.8940(9.1809) | Error 0.0000(0.0000) Steps 916(950.95) | Grad Norm 3.0298(2.1653) | Total Time 0.00(0.00)\n",
      "Iter 20460 | Time 25.3018(24.7942) | Bit/dim 3.3454(3.3556) | Xent 0.0000(0.0000) | Loss 8.7824(9.0842) | Error 0.0000(0.0000) Steps 946(953.14) | Grad Norm 1.0689(2.0827) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 115.6582, Epoch Time 1497.4695(1510.9803), Bit/dim 3.3578(best: 3.3592), Xent 0.0000, Loss 3.3578, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20470 | Time 23.7801(24.8755) | Bit/dim 3.3450(3.3540) | Xent 0.0000(0.0000) | Loss 8.8590(9.8733) | Error 0.0000(0.0000) Steps 934(950.41) | Grad Norm 3.1214(2.1573) | Total Time 0.00(0.00)\n",
      "Iter 20480 | Time 24.3700(24.9466) | Bit/dim 3.3287(3.3561) | Xent 0.0000(0.0000) | Loss 8.8381(9.6085) | Error 0.0000(0.0000) Steps 922(948.92) | Grad Norm 1.1195(2.0123) | Total Time 0.00(0.00)\n",
      "Iter 20490 | Time 25.7269(24.9608) | Bit/dim 3.3778(3.3584) | Xent 0.0000(0.0000) | Loss 8.8398(9.3947) | Error 0.0000(0.0000) Steps 946(947.39) | Grad Norm 1.6296(1.8195) | Total Time 0.00(0.00)\n",
      "Iter 20500 | Time 25.0495(24.9621) | Bit/dim 3.3365(3.3557) | Xent 0.0000(0.0000) | Loss 8.8593(9.2468) | Error 0.0000(0.0000) Steps 988(948.94) | Grad Norm 1.2090(1.6678) | Total Time 0.00(0.00)\n",
      "Iter 20510 | Time 24.2279(24.8699) | Bit/dim 3.3397(3.3549) | Xent 0.0000(0.0000) | Loss 8.7963(9.1326) | Error 0.0000(0.0000) Steps 958(948.64) | Grad Norm 1.2862(1.5830) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 116.4897, Epoch Time 1505.6339(1510.8200), Bit/dim 3.3593(best: 3.3578), Xent 0.0000, Loss 3.3593, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20520 | Time 24.6856(24.8450) | Bit/dim 3.3291(3.3560) | Xent 0.0000(0.0000) | Loss 8.7190(10.0072) | Error 0.0000(0.0000) Steps 964(951.47) | Grad Norm 1.4739(1.5973) | Total Time 0.00(0.00)\n",
      "Iter 20530 | Time 23.7065(24.7799) | Bit/dim 3.3462(3.3578) | Xent 0.0000(0.0000) | Loss 8.8226(9.7090) | Error 0.0000(0.0000) Steps 922(950.54) | Grad Norm 1.3473(1.5823) | Total Time 0.00(0.00)\n",
      "Iter 20540 | Time 25.2578(24.7862) | Bit/dim 3.3030(3.3554) | Xent 0.0000(0.0000) | Loss 8.6525(9.4743) | Error 0.0000(0.0000) Steps 898(954.43) | Grad Norm 1.1683(1.5706) | Total Time 0.00(0.00)\n",
      "Iter 20550 | Time 24.7574(24.8527) | Bit/dim 3.3423(3.3543) | Xent 0.0000(0.0000) | Loss 8.8492(9.2978) | Error 0.0000(0.0000) Steps 946(956.22) | Grad Norm 2.0192(1.5510) | Total Time 0.00(0.00)\n",
      "Iter 20560 | Time 24.5672(24.9779) | Bit/dim 3.3751(3.3539) | Xent 0.0000(0.0000) | Loss 8.8446(9.1734) | Error 0.0000(0.0000) Steps 946(953.31) | Grad Norm 4.4944(2.4905) | Total Time 0.00(0.00)\n",
      "Iter 20570 | Time 24.0997(24.9356) | Bit/dim 3.3308(3.3561) | Xent 0.0000(0.0000) | Loss 8.5393(9.0766) | Error 0.0000(0.0000) Steps 934(949.25) | Grad Norm 2.7479(2.5762) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 116.2351, Epoch Time 1506.4361(1510.6884), Bit/dim 3.3644(best: 3.3578), Xent 0.0000, Loss 3.3644, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20580 | Time 27.4638(25.3195) | Bit/dim 3.3634(3.3541) | Xent 0.0000(0.0000) | Loss 8.8819(9.8415) | Error 0.0000(0.0000) Steps 988(951.19) | Grad Norm 0.9936(2.5677) | Total Time 0.00(0.00)\n",
      "Iter 20590 | Time 24.8742(25.1557) | Bit/dim 3.3318(3.3547) | Xent 0.0000(0.0000) | Loss 8.6603(9.5732) | Error 0.0000(0.0000) Steps 1006(950.68) | Grad Norm 0.9208(2.2111) | Total Time 0.00(0.00)\n",
      "Iter 20600 | Time 23.8993(25.0196) | Bit/dim 3.3069(3.3544) | Xent 0.0000(0.0000) | Loss 8.7750(9.3708) | Error 0.0000(0.0000) Steps 928(947.59) | Grad Norm 1.0815(2.0589) | Total Time 0.00(0.00)\n",
      "Iter 20610 | Time 24.2078(24.9755) | Bit/dim 3.3246(3.3562) | Xent 0.0000(0.0000) | Loss 8.6955(9.2222) | Error 0.0000(0.0000) Steps 940(948.24) | Grad Norm 1.3264(1.8442) | Total Time 0.00(0.00)\n",
      "Iter 20620 | Time 26.1685(25.0194) | Bit/dim 3.3489(3.3571) | Xent 0.0000(0.0000) | Loss 8.8407(9.1158) | Error 0.0000(0.0000) Steps 1006(954.44) | Grad Norm 2.7585(1.8905) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 114.9386, Epoch Time 1515.7861(1510.8414), Bit/dim 3.3585(best: 3.3578), Xent 0.0000, Loss 3.3585, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20630 | Time 24.7701(24.9952) | Bit/dim 3.3608(3.3598) | Xent 0.0000(0.0000) | Loss 8.7578(10.0330) | Error 0.0000(0.0000) Steps 922(952.43) | Grad Norm 1.4249(1.7708) | Total Time 0.00(0.00)\n",
      "Iter 20640 | Time 24.1705(24.8170) | Bit/dim 3.3598(3.3564) | Xent 0.0000(0.0000) | Loss 8.6944(9.6972) | Error 0.0000(0.0000) Steps 916(948.65) | Grad Norm 2.3663(1.6802) | Total Time 0.00(0.00)\n",
      "Iter 20650 | Time 24.9206(24.8413) | Bit/dim 3.3694(3.3572) | Xent 0.0000(0.0000) | Loss 8.7846(9.4674) | Error 0.0000(0.0000) Steps 922(945.90) | Grad Norm 2.1804(1.7997) | Total Time 0.00(0.00)\n",
      "Iter 20660 | Time 25.4602(24.8564) | Bit/dim 3.3698(3.3564) | Xent 0.0000(0.0000) | Loss 8.8523(9.2940) | Error 0.0000(0.0000) Steps 976(948.98) | Grad Norm 1.0544(1.9111) | Total Time 0.00(0.00)\n",
      "Iter 20670 | Time 24.1309(24.8080) | Bit/dim 3.3649(3.3561) | Xent 0.0000(0.0000) | Loss 8.7167(9.1579) | Error 0.0000(0.0000) Steps 940(945.44) | Grad Norm 0.9164(1.7874) | Total Time 0.00(0.00)\n",
      "Iter 20680 | Time 24.7010(24.7540) | Bit/dim 3.3497(3.3541) | Xent 0.0000(0.0000) | Loss 8.7192(9.0587) | Error 0.0000(0.0000) Steps 946(945.74) | Grad Norm 2.1647(1.7295) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 115.6422, Epoch Time 1493.3270(1510.3159), Bit/dim 3.3642(best: 3.3578), Xent 0.0000, Loss 3.3642, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20690 | Time 25.1371(24.7509) | Bit/dim 3.3797(3.3543) | Xent 0.0000(0.0000) | Loss 8.7968(9.8400) | Error 0.0000(0.0000) Steps 946(945.76) | Grad Norm 1.3330(1.8529) | Total Time 0.00(0.00)\n",
      "Iter 20700 | Time 23.7795(24.7752) | Bit/dim 3.3605(3.3573) | Xent 0.0000(0.0000) | Loss 8.7315(9.5780) | Error 0.0000(0.0000) Steps 964(946.58) | Grad Norm 2.4374(1.9383) | Total Time 0.00(0.00)\n",
      "Iter 20710 | Time 23.7332(24.7014) | Bit/dim 3.3353(3.3539) | Xent 0.0000(0.0000) | Loss 8.7749(9.3769) | Error 0.0000(0.0000) Steps 976(944.66) | Grad Norm 2.2387(1.9388) | Total Time 0.00(0.00)\n",
      "Iter 20720 | Time 25.2715(24.7656) | Bit/dim 3.3549(3.3516) | Xent 0.0000(0.0000) | Loss 8.7211(9.2218) | Error 0.0000(0.0000) Steps 892(944.87) | Grad Norm 2.7649(1.9806) | Total Time 0.00(0.00)\n",
      "Iter 20730 | Time 24.8511(24.7164) | Bit/dim 3.3627(3.3538) | Xent 0.0000(0.0000) | Loss 8.8612(9.1141) | Error 0.0000(0.0000) Steps 982(945.63) | Grad Norm 1.4125(1.8739) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 114.9885, Epoch Time 1494.1877(1509.8321), Bit/dim 3.3654(best: 3.3578), Xent 0.0000, Loss 3.3654, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20740 | Time 24.4047(24.6908) | Bit/dim 3.3214(3.3531) | Xent 0.0000(0.0000) | Loss 8.8128(9.9882) | Error 0.0000(0.0000) Steps 934(947.40) | Grad Norm 0.9872(1.7653) | Total Time 0.00(0.00)\n",
      "Iter 20750 | Time 24.4034(24.6502) | Bit/dim 3.2929(3.3519) | Xent 0.0000(0.0000) | Loss 8.7506(9.6840) | Error 0.0000(0.0000) Steps 940(951.14) | Grad Norm 1.4464(1.6549) | Total Time 0.00(0.00)\n",
      "Iter 20760 | Time 24.4547(24.6545) | Bit/dim 3.3538(3.3523) | Xent 0.0000(0.0000) | Loss 8.7827(9.4540) | Error 0.0000(0.0000) Steps 928(951.15) | Grad Norm 1.5706(1.6237) | Total Time 0.00(0.00)\n",
      "Iter 20770 | Time 24.6503(24.5852) | Bit/dim 3.3313(3.3533) | Xent 0.0000(0.0000) | Loss 8.8060(9.2847) | Error 0.0000(0.0000) Steps 922(949.89) | Grad Norm 1.5908(1.5947) | Total Time 0.00(0.00)\n",
      "Iter 20780 | Time 25.6336(24.7724) | Bit/dim 3.3884(3.3549) | Xent 0.0000(0.0000) | Loss 8.8660(9.1567) | Error 0.0000(0.0000) Steps 982(950.30) | Grad Norm 1.4826(1.9691) | Total Time 0.00(0.00)\n",
      "Iter 20790 | Time 24.0256(24.8352) | Bit/dim 3.3347(3.3543) | Xent 0.0000(0.0000) | Loss 8.7144(9.0715) | Error 0.0000(0.0000) Steps 970(951.11) | Grad Norm 1.7022(1.8645) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 114.5930, Epoch Time 1494.0549(1509.3588), Bit/dim 3.3609(best: 3.3578), Xent 0.0000, Loss 3.3609, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20800 | Time 25.6360(24.8017) | Bit/dim 3.3809(3.3565) | Xent 0.0000(0.0000) | Loss 8.8073(9.8554) | Error 0.0000(0.0000) Steps 928(949.14) | Grad Norm 1.6916(1.7996) | Total Time 0.00(0.00)\n",
      "Iter 20810 | Time 23.9065(24.7653) | Bit/dim 3.3815(3.3538) | Xent 0.0000(0.0000) | Loss 8.8132(9.5736) | Error 0.0000(0.0000) Steps 910(948.38) | Grad Norm 1.1043(1.7429) | Total Time 0.00(0.00)\n",
      "Iter 20820 | Time 23.9404(24.6866) | Bit/dim 3.3758(3.3544) | Xent 0.0000(0.0000) | Loss 8.9182(9.3640) | Error 0.0000(0.0000) Steps 916(944.87) | Grad Norm 1.5764(1.7450) | Total Time 0.00(0.00)\n",
      "Iter 20830 | Time 23.9167(24.7053) | Bit/dim 3.3654(3.3546) | Xent 0.0000(0.0000) | Loss 8.7143(9.2128) | Error 0.0000(0.0000) Steps 922(948.14) | Grad Norm 2.4104(1.9046) | Total Time 0.00(0.00)\n",
      "Iter 20840 | Time 27.8486(24.7634) | Bit/dim 3.3742(3.3545) | Xent 0.0000(0.0000) | Loss 8.8255(9.1061) | Error 0.0000(0.0000) Steps 928(946.33) | Grad Norm 1.4356(1.8801) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 114.7081, Epoch Time 1494.6228(1508.9167), Bit/dim 3.3610(best: 3.3578), Xent 0.0000, Loss 3.3610, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20850 | Time 24.7451(24.8841) | Bit/dim 3.3365(3.3543) | Xent 0.0000(0.0000) | Loss 8.9053(10.0036) | Error 0.0000(0.0000) Steps 958(950.09) | Grad Norm 2.4545(2.0871) | Total Time 0.00(0.00)\n",
      "Iter 20860 | Time 24.5183(24.9092) | Bit/dim 3.3557(3.3534) | Xent 0.0000(0.0000) | Loss 8.8218(9.6911) | Error 0.0000(0.0000) Steps 970(948.96) | Grad Norm 3.1345(2.1350) | Total Time 0.00(0.00)\n",
      "Iter 20870 | Time 24.9486(24.9104) | Bit/dim 3.3449(3.3540) | Xent 0.0000(0.0000) | Loss 8.9172(9.4765) | Error 0.0000(0.0000) Steps 970(951.59) | Grad Norm 1.7529(2.1662) | Total Time 0.00(0.00)\n",
      "Iter 20880 | Time 25.1311(24.9793) | Bit/dim 3.3950(3.3578) | Xent 0.0000(0.0000) | Loss 8.9670(9.3212) | Error 0.0000(0.0000) Steps 970(950.20) | Grad Norm 1.1441(2.0890) | Total Time 0.00(0.00)\n",
      "Iter 20890 | Time 25.3386(24.8419) | Bit/dim 3.3334(3.3555) | Xent 0.0000(0.0000) | Loss 8.7978(9.1811) | Error 0.0000(0.0000) Steps 970(946.74) | Grad Norm 1.2619(1.8869) | Total Time 0.00(0.00)\n",
      "Iter 20900 | Time 23.9998(24.8073) | Bit/dim 3.3674(3.3560) | Xent 0.0000(0.0000) | Loss 8.8792(9.0874) | Error 0.0000(0.0000) Steps 946(947.54) | Grad Norm 1.5863(1.8419) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 116.7176, Epoch Time 1503.1344(1508.7432), Bit/dim 3.3599(best: 3.3578), Xent 0.0000, Loss 3.3599, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20910 | Time 24.2170(24.7698) | Bit/dim 3.3630(3.3545) | Xent 0.0000(0.0000) | Loss 8.8724(9.8761) | Error 0.0000(0.0000) Steps 916(945.14) | Grad Norm 1.2195(1.7138) | Total Time 0.00(0.00)\n",
      "Iter 20920 | Time 24.3840(24.7608) | Bit/dim 3.3521(3.3547) | Xent 0.0000(0.0000) | Loss 8.8492(9.6072) | Error 0.0000(0.0000) Steps 934(949.43) | Grad Norm 1.1259(1.6558) | Total Time 0.00(0.00)\n",
      "Iter 20930 | Time 25.8101(24.9667) | Bit/dim 3.3796(3.3556) | Xent 0.0000(0.0000) | Loss 8.9573(9.3933) | Error 0.0000(0.0000) Steps 970(946.49) | Grad Norm 1.7659(1.6705) | Total Time 0.00(0.00)\n",
      "Iter 20940 | Time 24.0557(24.8717) | Bit/dim 3.3316(3.3543) | Xent 0.0000(0.0000) | Loss 8.7706(9.2357) | Error 0.0000(0.0000) Steps 928(943.93) | Grad Norm 1.7010(1.8386) | Total Time 0.00(0.00)\n",
      "Iter 20950 | Time 24.9914(24.8439) | Bit/dim 3.3559(3.3561) | Xent 0.0000(0.0000) | Loss 8.9103(9.1288) | Error 0.0000(0.0000) Steps 958(943.88) | Grad Norm 2.9577(2.0768) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 115.4771, Epoch Time 1501.4458(1508.5243), Bit/dim 3.3607(best: 3.3578), Xent 0.0000, Loss 3.3607, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20960 | Time 23.8373(24.7699) | Bit/dim 3.3752(3.3548) | Xent 0.0000(0.0000) | Loss 8.8637(10.0354) | Error 0.0000(0.0000) Steps 922(944.31) | Grad Norm 1.7763(2.0319) | Total Time 0.00(0.00)\n",
      "Iter 20970 | Time 24.6489(24.7195) | Bit/dim 3.3460(3.3536) | Xent 0.0000(0.0000) | Loss 8.8294(9.7195) | Error 0.0000(0.0000) Steps 970(943.44) | Grad Norm 2.0124(1.9710) | Total Time 0.00(0.00)\n",
      "Iter 20980 | Time 24.9664(24.7245) | Bit/dim 3.3449(3.3538) | Xent 0.0000(0.0000) | Loss 8.6915(9.4824) | Error 0.0000(0.0000) Steps 934(947.37) | Grad Norm 1.8461(2.0886) | Total Time 0.00(0.00)\n",
      "Iter 20990 | Time 25.9203(24.7264) | Bit/dim 3.3329(3.3551) | Xent 0.0000(0.0000) | Loss 8.8196(9.3105) | Error 0.0000(0.0000) Steps 964(947.86) | Grad Norm 1.4733(2.0278) | Total Time 0.00(0.00)\n",
      "Iter 21000 | Time 24.8873(24.7573) | Bit/dim 3.3763(3.3556) | Xent 0.0000(0.0000) | Loss 8.8666(9.1843) | Error 0.0000(0.0000) Steps 946(947.25) | Grad Norm 2.2774(1.9542) | Total Time 0.00(0.00)\n",
      "Iter 21010 | Time 25.0216(24.6751) | Bit/dim 3.3490(3.3568) | Xent 0.0000(0.0000) | Loss 8.7024(9.0816) | Error 0.0000(0.0000) Steps 952(946.11) | Grad Norm 2.2710(1.9177) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 116.3779, Epoch Time 1489.8269(1507.9634), Bit/dim 3.3608(best: 3.3578), Xent 0.0000, Loss 3.3608, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21020 | Time 24.0437(24.6497) | Bit/dim 3.3543(3.3543) | Xent 0.0000(0.0000) | Loss 8.7048(9.8497) | Error 0.0000(0.0000) Steps 952(947.05) | Grad Norm 1.3181(1.7869) | Total Time 0.00(0.00)\n",
      "Iter 21030 | Time 23.8488(24.7148) | Bit/dim 3.3267(3.3498) | Xent 0.0000(0.0000) | Loss 8.6665(9.5653) | Error 0.0000(0.0000) Steps 886(943.81) | Grad Norm 1.2272(1.6984) | Total Time 0.00(0.00)\n",
      "Iter 21040 | Time 23.4959(24.9437) | Bit/dim 3.3379(3.3540) | Xent 0.0000(0.0000) | Loss 8.7987(9.3694) | Error 0.0000(0.0000) Steps 934(947.06) | Grad Norm 2.1873(3.2352) | Total Time 0.00(0.00)\n",
      "Iter 21050 | Time 24.2543(24.7641) | Bit/dim 3.3540(3.3542) | Xent 0.0000(0.0000) | Loss 8.8124(9.2259) | Error 0.0000(0.0000) Steps 964(947.07) | Grad Norm 2.3908(2.9160) | Total Time 0.00(0.00)\n",
      "Iter 21060 | Time 23.4992(24.6580) | Bit/dim 3.3338(3.3548) | Xent 0.0000(0.0000) | Loss 8.9146(9.1231) | Error 0.0000(0.0000) Steps 928(944.73) | Grad Norm 2.3043(2.6206) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 116.4785, Epoch Time 1499.1044(1507.6976), Bit/dim 3.3605(best: 3.3578), Xent 0.0000, Loss 3.3605, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21070 | Time 24.6560(24.7321) | Bit/dim 3.3497(3.3547) | Xent 0.0000(0.0000) | Loss 8.7577(10.0092) | Error 0.0000(0.0000) Steps 940(942.33) | Grad Norm 2.5912(2.3978) | Total Time 0.00(0.00)\n",
      "Iter 21080 | Time 24.5479(24.8804) | Bit/dim 3.3633(3.3560) | Xent 0.0000(0.0000) | Loss 8.9851(9.7130) | Error 0.0000(0.0000) Steps 976(942.42) | Grad Norm 1.4897(2.2487) | Total Time 0.00(0.00)\n",
      "Iter 21090 | Time 25.2270(24.9106) | Bit/dim 3.3651(3.3527) | Xent 0.0000(0.0000) | Loss 8.9385(9.4776) | Error 0.0000(0.0000) Steps 940(944.36) | Grad Norm 1.2810(2.0098) | Total Time 0.00(0.00)\n",
      "Iter 21100 | Time 24.1845(24.8695) | Bit/dim 3.3535(3.3567) | Xent 0.0000(0.0000) | Loss 8.6390(9.3061) | Error 0.0000(0.0000) Steps 916(944.53) | Grad Norm 1.5304(1.8335) | Total Time 0.00(0.00)\n",
      "Iter 21110 | Time 23.9959(24.8688) | Bit/dim 3.3691(3.3583) | Xent 0.0000(0.0000) | Loss 8.8828(9.1833) | Error 0.0000(0.0000) Steps 964(948.31) | Grad Norm 1.2721(1.7880) | Total Time 0.00(0.00)\n",
      "Iter 21120 | Time 24.8006(24.7041) | Bit/dim 3.3587(3.3557) | Xent 0.0000(0.0000) | Loss 8.8170(9.0908) | Error 0.0000(0.0000) Steps 940(944.21) | Grad Norm 1.4640(1.6811) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 116.4134, Epoch Time 1500.1592(1507.4715), Bit/dim 3.3590(best: 3.3578), Xent 0.0000, Loss 3.3590, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21130 | Time 24.3062(24.6451) | Bit/dim 3.3466(3.3548) | Xent 0.0000(0.0000) | Loss 8.9563(9.8777) | Error 0.0000(0.0000) Steps 958(948.28) | Grad Norm 1.3760(1.6562) | Total Time 0.00(0.00)\n",
      "Iter 21140 | Time 23.9450(24.7103) | Bit/dim 3.3729(3.3560) | Xent 0.0000(0.0000) | Loss 8.8319(9.6025) | Error 0.0000(0.0000) Steps 910(944.71) | Grad Norm 1.1354(1.5829) | Total Time 0.00(0.00)\n",
      "Iter 21150 | Time 24.8296(24.7109) | Bit/dim 3.3781(3.3554) | Xent 0.0000(0.0000) | Loss 8.7651(9.3929) | Error 0.0000(0.0000) Steps 976(947.58) | Grad Norm 1.1638(1.5579) | Total Time 0.00(0.00)\n",
      "Iter 21160 | Time 24.0771(24.7690) | Bit/dim 3.3595(3.3545) | Xent 0.0000(0.0000) | Loss 8.7949(9.2562) | Error 0.0000(0.0000) Steps 934(947.71) | Grad Norm 1.3953(1.4860) | Total Time 0.00(0.00)\n",
      "Iter 21170 | Time 25.8289(24.7125) | Bit/dim 3.3652(3.3550) | Xent 0.0000(0.0000) | Loss 8.9479(9.1406) | Error 0.0000(0.0000) Steps 946(944.93) | Grad Norm 1.3681(1.4123) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 115.4326, Epoch Time 1493.6823(1507.0578), Bit/dim 3.3621(best: 3.3578), Xent 0.0000, Loss 3.3621, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21180 | Time 23.1591(24.7185) | Bit/dim 3.3315(3.3563) | Xent 0.0000(0.0000) | Loss 8.7027(10.0666) | Error 0.0000(0.0000) Steps 916(948.27) | Grad Norm 2.2677(1.4190) | Total Time 0.00(0.00)\n",
      "Iter 21190 | Time 23.3599(24.6285) | Bit/dim 3.3692(3.3555) | Xent 0.0000(0.0000) | Loss 8.7141(9.7370) | Error 0.0000(0.0000) Steps 940(947.06) | Grad Norm 1.6813(1.5181) | Total Time 0.00(0.00)\n",
      "Iter 21200 | Time 25.0311(24.5567) | Bit/dim 3.3500(3.3556) | Xent 0.0000(0.0000) | Loss 8.8481(9.5014) | Error 0.0000(0.0000) Steps 970(946.68) | Grad Norm 1.3789(1.4953) | Total Time 0.00(0.00)\n",
      "Iter 21210 | Time 24.7484(24.6000) | Bit/dim 3.3203(3.3574) | Xent 0.0000(0.0000) | Loss 8.8883(9.3300) | Error 0.0000(0.0000) Steps 952(948.13) | Grad Norm 2.2950(1.5108) | Total Time 0.00(0.00)\n",
      "Iter 21220 | Time 24.6186(24.6619) | Bit/dim 3.3230(3.3550) | Xent 0.0000(0.0000) | Loss 8.7682(9.1916) | Error 0.0000(0.0000) Steps 910(947.52) | Grad Norm 1.3179(1.4525) | Total Time 0.00(0.00)\n",
      "Iter 21230 | Time 25.9220(24.5799) | Bit/dim 3.3691(3.3535) | Xent 0.0000(0.0000) | Loss 8.6984(9.0900) | Error 0.0000(0.0000) Steps 898(945.93) | Grad Norm 1.0198(1.4552) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 115.8302, Epoch Time 1484.7006(1506.3871), Bit/dim 3.3602(best: 3.3578), Xent 0.0000, Loss 3.3602, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21240 | Time 24.4702(24.7085) | Bit/dim 3.3915(3.3541) | Xent 0.0000(0.0000) | Loss 8.9357(9.8471) | Error 0.0000(0.0000) Steps 1000(945.60) | Grad Norm 2.2828(1.4735) | Total Time 0.00(0.00)\n",
      "Iter 21250 | Time 24.3747(24.6030) | Bit/dim 3.3744(3.3554) | Xent 0.0000(0.0000) | Loss 8.8982(9.5812) | Error 0.0000(0.0000) Steps 964(949.91) | Grad Norm 1.0549(1.5619) | Total Time 0.00(0.00)\n",
      "Iter 21260 | Time 24.5511(24.7771) | Bit/dim 3.3762(3.3550) | Xent 0.0000(0.0000) | Loss 8.8363(9.3950) | Error 0.0000(0.0000) Steps 928(947.08) | Grad Norm 1.5811(1.6601) | Total Time 0.00(0.00)\n",
      "Iter 21270 | Time 23.5583(24.6341) | Bit/dim 3.3295(3.3533) | Xent 0.0000(0.0000) | Loss 8.8666(9.2457) | Error 0.0000(0.0000) Steps 958(947.30) | Grad Norm 1.4524(1.6416) | Total Time 0.00(0.00)\n",
      "Iter 21280 | Time 24.6883(24.5794) | Bit/dim 3.3413(3.3539) | Xent 0.0000(0.0000) | Loss 8.7454(9.1317) | Error 0.0000(0.0000) Steps 904(944.37) | Grad Norm 1.5865(1.6858) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 115.6105, Epoch Time 1490.4644(1505.9094), Bit/dim 3.3604(best: 3.3578), Xent 0.0000, Loss 3.3604, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21290 | Time 24.2706(24.5346) | Bit/dim 3.3713(3.3524) | Xent 0.0000(0.0000) | Loss 8.9986(10.0468) | Error 0.0000(0.0000) Steps 922(942.07) | Grad Norm 1.1935(1.6353) | Total Time 0.00(0.00)\n",
      "Iter 21300 | Time 25.0170(24.5217) | Bit/dim 3.3538(3.3539) | Xent 0.0000(0.0000) | Loss 8.8165(9.7351) | Error 0.0000(0.0000) Steps 928(942.40) | Grad Norm 1.7691(1.6703) | Total Time 0.00(0.00)\n",
      "Iter 21310 | Time 25.2438(24.6542) | Bit/dim 3.3483(3.3530) | Xent 0.0000(0.0000) | Loss 8.8296(9.5009) | Error 0.0000(0.0000) Steps 922(944.21) | Grad Norm 1.5312(1.7025) | Total Time 0.00(0.00)\n",
      "Iter 21320 | Time 23.8066(24.5958) | Bit/dim 3.3454(3.3540) | Xent 0.0000(0.0000) | Loss 8.9274(9.3385) | Error 0.0000(0.0000) Steps 952(947.18) | Grad Norm 2.5795(1.7097) | Total Time 0.00(0.00)\n",
      "Iter 21330 | Time 24.8662(24.5883) | Bit/dim 3.3619(3.3527) | Xent 0.0000(0.0000) | Loss 8.7352(9.1926) | Error 0.0000(0.0000) Steps 928(946.76) | Grad Norm 1.0986(1.6839) | Total Time 0.00(0.00)\n",
      "Iter 21340 | Time 24.8241(24.6202) | Bit/dim 3.3418(3.3531) | Xent 0.0000(0.0000) | Loss 8.9216(9.1069) | Error 0.0000(0.0000) Steps 988(947.03) | Grad Norm 1.7352(1.6013) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 115.2863, Epoch Time 1488.4245(1505.3848), Bit/dim 3.3585(best: 3.3578), Xent 0.0000, Loss 3.3585, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21350 | Time 24.0664(24.5547) | Bit/dim 3.3711(3.3531) | Xent 0.0000(0.0000) | Loss 8.9312(9.8853) | Error 0.0000(0.0000) Steps 922(943.33) | Grad Norm 1.6367(1.6424) | Total Time 0.00(0.00)\n",
      "Iter 21360 | Time 24.4412(24.5748) | Bit/dim 3.3565(3.3547) | Xent 0.0000(0.0000) | Loss 8.9636(9.6226) | Error 0.0000(0.0000) Steps 976(948.17) | Grad Norm 1.2127(1.6239) | Total Time 0.00(0.00)\n",
      "Iter 21370 | Time 24.4192(24.6833) | Bit/dim 3.3323(3.3558) | Xent 0.0000(0.0000) | Loss 8.8633(9.4277) | Error 0.0000(0.0000) Steps 928(951.04) | Grad Norm 1.2343(1.5789) | Total Time 0.00(0.00)\n",
      "Iter 21380 | Time 24.5422(24.6053) | Bit/dim 3.3338(3.3547) | Xent 0.0000(0.0000) | Loss 8.9070(9.2731) | Error 0.0000(0.0000) Steps 946(949.69) | Grad Norm 2.1042(1.6083) | Total Time 0.00(0.00)\n",
      "Iter 21390 | Time 24.2794(24.6428) | Bit/dim 3.3322(3.3537) | Xent 0.0000(0.0000) | Loss 8.7367(9.1495) | Error 0.0000(0.0000) Steps 946(947.94) | Grad Norm 2.4335(1.9793) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 115.4903, Epoch Time 1484.2617(1504.7511), Bit/dim 3.3615(best: 3.3578), Xent 0.0000, Loss 3.3615, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21400 | Time 24.5545(24.5212) | Bit/dim 3.3436(3.3531) | Xent 0.0000(0.0000) | Loss 8.8471(10.0436) | Error 0.0000(0.0000) Steps 940(946.16) | Grad Norm 1.9825(1.8963) | Total Time 0.00(0.00)\n",
      "Iter 21410 | Time 26.8738(24.5691) | Bit/dim 3.3622(3.3535) | Xent 0.0000(0.0000) | Loss 8.8727(9.7253) | Error 0.0000(0.0000) Steps 910(942.88) | Grad Norm 4.5496(1.9745) | Total Time 0.00(0.00)\n",
      "Iter 21420 | Time 25.8665(24.8925) | Bit/dim 3.3789(3.3555) | Xent 0.0000(0.0000) | Loss 8.9114(9.4884) | Error 0.0000(0.0000) Steps 976(949.63) | Grad Norm 1.4827(1.9519) | Total Time 0.00(0.00)\n",
      "Iter 21430 | Time 23.5588(24.8548) | Bit/dim 3.3864(3.3562) | Xent 0.0000(0.0000) | Loss 8.7941(9.3135) | Error 0.0000(0.0000) Steps 940(950.55) | Grad Norm 1.0115(1.8148) | Total Time 0.00(0.00)\n",
      "Iter 21440 | Time 24.5175(24.8260) | Bit/dim 3.3314(3.3546) | Xent 0.0000(0.0000) | Loss 8.7654(9.1831) | Error 0.0000(0.0000) Steps 934(947.72) | Grad Norm 1.1600(1.7222) | Total Time 0.00(0.00)\n",
      "Iter 21450 | Time 22.6535(24.7762) | Bit/dim 3.3456(3.3530) | Xent 0.0000(0.0000) | Loss 8.8089(9.1003) | Error 0.0000(0.0000) Steps 916(947.68) | Grad Norm 1.5868(1.5786) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 115.7046, Epoch Time 1503.3547(1504.7093), Bit/dim 3.3580(best: 3.3578), Xent 0.0000, Loss 3.3580, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21460 | Time 23.9258(24.7741) | Bit/dim 3.3694(3.3524) | Xent 0.0000(0.0000) | Loss 8.8601(9.8666) | Error 0.0000(0.0000) Steps 928(951.23) | Grad Norm 1.5443(1.6452) | Total Time 0.00(0.00)\n",
      "Iter 21470 | Time 24.6047(24.8574) | Bit/dim 3.3688(3.3550) | Xent 0.0000(0.0000) | Loss 8.7614(9.5915) | Error 0.0000(0.0000) Steps 916(953.07) | Grad Norm 2.3222(1.8848) | Total Time 0.00(0.00)\n",
      "Iter 21480 | Time 27.0765(24.8211) | Bit/dim 3.3141(3.3537) | Xent 0.0000(0.0000) | Loss 8.5910(9.3759) | Error 0.0000(0.0000) Steps 964(952.07) | Grad Norm 2.1350(1.9499) | Total Time 0.00(0.00)\n",
      "Iter 21490 | Time 24.7313(24.9124) | Bit/dim 3.3588(3.3514) | Xent 0.0000(0.0000) | Loss 8.8888(9.2389) | Error 0.0000(0.0000) Steps 946(956.73) | Grad Norm 3.0113(2.1739) | Total Time 0.00(0.00)\n",
      "Iter 21500 | Time 25.1205(24.9424) | Bit/dim 3.3893(3.3542) | Xent 0.0000(0.0000) | Loss 8.9306(9.1407) | Error 0.0000(0.0000) Steps 904(952.66) | Grad Norm 1.9362(2.3730) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 116.0608, Epoch Time 1507.4763(1504.7923), Bit/dim 3.3608(best: 3.3578), Xent 0.0000, Loss 3.3608, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21510 | Time 24.4834(24.8128) | Bit/dim 3.3794(3.3546) | Xent 0.0000(0.0000) | Loss 8.8704(10.0434) | Error 0.0000(0.0000) Steps 904(949.32) | Grad Norm 1.0853(2.1539) | Total Time 0.00(0.00)\n",
      "Iter 21520 | Time 23.9256(24.7143) | Bit/dim 3.3225(3.3536) | Xent 0.0000(0.0000) | Loss 8.7430(9.7228) | Error 0.0000(0.0000) Steps 970(948.40) | Grad Norm 1.7295(1.9214) | Total Time 0.00(0.00)\n",
      "Iter 21530 | Time 24.1143(24.7479) | Bit/dim 3.3213(3.3541) | Xent 0.0000(0.0000) | Loss 8.8218(9.4889) | Error 0.0000(0.0000) Steps 964(951.04) | Grad Norm 2.1698(1.9244) | Total Time 0.00(0.00)\n",
      "Iter 21540 | Time 24.8437(24.7853) | Bit/dim 3.3663(3.3546) | Xent 0.0000(0.0000) | Loss 8.8122(9.3046) | Error 0.0000(0.0000) Steps 886(947.12) | Grad Norm 1.6466(2.0122) | Total Time 0.00(0.00)\n",
      "Iter 21550 | Time 24.3761(24.7737) | Bit/dim 3.3405(3.3539) | Xent 0.0000(0.0000) | Loss 8.7548(9.1802) | Error 0.0000(0.0000) Steps 964(947.93) | Grad Norm 1.7482(1.8773) | Total Time 0.00(0.00)\n",
      "Iter 21560 | Time 24.1290(24.8057) | Bit/dim 3.3582(3.3541) | Xent 0.0000(0.0000) | Loss 8.9187(9.0857) | Error 0.0000(0.0000) Steps 952(948.52) | Grad Norm 2.1378(1.8288) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 117.6462, Epoch Time 1495.6431(1504.5178), Bit/dim 3.3597(best: 3.3578), Xent 0.0000, Loss 3.3597, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21570 | Time 24.6645(24.6959) | Bit/dim 3.3563(3.3524) | Xent 0.0000(0.0000) | Loss 8.8789(9.8629) | Error 0.0000(0.0000) Steps 952(949.98) | Grad Norm 1.6269(1.7863) | Total Time 0.00(0.00)\n",
      "Iter 21580 | Time 27.3190(24.7448) | Bit/dim 3.3717(3.3509) | Xent 0.0000(0.0000) | Loss 8.8820(9.5896) | Error 0.0000(0.0000) Steps 982(951.57) | Grad Norm 1.7751(1.9619) | Total Time 0.00(0.00)\n",
      "Iter 21590 | Time 23.8187(24.6644) | Bit/dim 3.3744(3.3513) | Xent 0.0000(0.0000) | Loss 8.8631(9.3827) | Error 0.0000(0.0000) Steps 946(949.15) | Grad Norm 2.0418(2.1022) | Total Time 0.00(0.00)\n",
      "Iter 21600 | Time 24.1804(24.6624) | Bit/dim 3.3414(3.3537) | Xent 0.0000(0.0000) | Loss 8.8512(9.2382) | Error 0.0000(0.0000) Steps 946(948.96) | Grad Norm 1.8594(2.0720) | Total Time 0.00(0.00)\n",
      "Iter 21610 | Time 26.7173(24.7420) | Bit/dim 3.4081(3.3552) | Xent 0.0000(0.0000) | Loss 8.9541(9.1354) | Error 0.0000(0.0000) Steps 922(947.63) | Grad Norm 1.4873(1.9890) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 115.8670, Epoch Time 1490.0650(1504.0842), Bit/dim 3.3627(best: 3.3578), Xent 0.0000, Loss 3.3627, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21620 | Time 27.7132(24.7697) | Bit/dim 3.3900(3.3582) | Xent 0.0000(0.0000) | Loss 8.9048(10.0411) | Error 0.0000(0.0000) Steps 1000(946.81) | Grad Norm 1.5024(1.8093) | Total Time 0.00(0.00)\n",
      "Iter 21630 | Time 24.1177(24.7831) | Bit/dim 3.3668(3.3568) | Xent 0.0000(0.0000) | Loss 8.8537(9.7196) | Error 0.0000(0.0000) Steps 946(948.89) | Grad Norm 1.7464(1.6840) | Total Time 0.00(0.00)\n",
      "Iter 21640 | Time 23.9790(24.8085) | Bit/dim 3.3605(3.3559) | Xent 0.0000(0.0000) | Loss 8.6944(9.4743) | Error 0.0000(0.0000) Steps 970(950.15) | Grad Norm 1.2186(1.6073) | Total Time 0.00(0.00)\n",
      "Iter 21650 | Time 24.2987(24.7922) | Bit/dim 3.3295(3.3537) | Xent 0.0000(0.0000) | Loss 8.8827(9.2970) | Error 0.0000(0.0000) Steps 940(951.12) | Grad Norm 2.1679(1.6347) | Total Time 0.00(0.00)\n",
      "Iter 21660 | Time 23.7200(24.6950) | Bit/dim 3.3617(3.3527) | Xent 0.0000(0.0000) | Loss 8.9086(9.1694) | Error 0.0000(0.0000) Steps 958(946.92) | Grad Norm 1.4186(1.6451) | Total Time 0.00(0.00)\n",
      "Iter 21670 | Time 23.8037(24.7737) | Bit/dim 3.3559(3.3550) | Xent 0.0000(0.0000) | Loss 8.6537(9.0821) | Error 0.0000(0.0000) Steps 892(944.13) | Grad Norm 1.3224(1.5522) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 115.9370, Epoch Time 1499.1942(1503.9375), Bit/dim 3.3603(best: 3.3578), Xent 0.0000, Loss 3.3603, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21680 | Time 24.8574(24.6400) | Bit/dim 3.3691(3.3538) | Xent 0.0000(0.0000) | Loss 8.9080(9.8687) | Error 0.0000(0.0000) Steps 958(945.20) | Grad Norm 1.5819(1.5832) | Total Time 0.00(0.00)\n",
      "Iter 21690 | Time 25.1231(24.6692) | Bit/dim 3.3429(3.3521) | Xent 0.0000(0.0000) | Loss 8.9516(9.5957) | Error 0.0000(0.0000) Steps 970(944.25) | Grad Norm 1.6219(1.5577) | Total Time 0.00(0.00)\n",
      "Iter 21700 | Time 23.6457(24.6482) | Bit/dim 3.3589(3.3532) | Xent 0.0000(0.0000) | Loss 8.6869(9.3942) | Error 0.0000(0.0000) Steps 952(945.06) | Grad Norm 1.1018(1.5646) | Total Time 0.00(0.00)\n",
      "Iter 21710 | Time 24.2858(24.6043) | Bit/dim 3.3226(3.3542) | Xent 0.0000(0.0000) | Loss 8.7627(9.2495) | Error 0.0000(0.0000) Steps 952(944.15) | Grad Norm 1.7510(1.6113) | Total Time 0.00(0.00)\n",
      "Iter 21720 | Time 25.3773(24.6393) | Bit/dim 3.3946(3.3546) | Xent 0.0000(0.0000) | Loss 9.0225(9.1340) | Error 0.0000(0.0000) Steps 904(941.91) | Grad Norm 1.1988(1.6138) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 116.3460, Epoch Time 1488.8376(1503.4845), Bit/dim 3.3614(best: 3.3578), Xent 0.0000, Loss 3.3614, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21730 | Time 24.5829(24.6818) | Bit/dim 3.3459(3.3556) | Xent 0.0000(0.0000) | Loss 8.8450(10.0259) | Error 0.0000(0.0000) Steps 928(941.65) | Grad Norm 1.2507(1.7687) | Total Time 0.00(0.00)\n",
      "Iter 21740 | Time 24.9082(24.6764) | Bit/dim 3.3744(3.3561) | Xent 0.0000(0.0000) | Loss 8.8178(9.7132) | Error 0.0000(0.0000) Steps 934(942.40) | Grad Norm 2.0949(1.9283) | Total Time 0.00(0.00)\n",
      "Iter 21750 | Time 27.2452(24.7525) | Bit/dim 3.3749(3.3547) | Xent 0.0000(0.0000) | Loss 8.8476(9.4736) | Error 0.0000(0.0000) Steps 958(940.88) | Grad Norm 2.4523(1.8997) | Total Time 0.00(0.00)\n",
      "Iter 21760 | Time 24.3087(24.6110) | Bit/dim 3.3153(3.3541) | Xent 0.0000(0.0000) | Loss 8.7170(9.3050) | Error 0.0000(0.0000) Steps 880(939.54) | Grad Norm 1.4593(1.8073) | Total Time 0.00(0.00)\n",
      "Iter 21770 | Time 23.7942(24.5554) | Bit/dim 3.3298(3.3547) | Xent 0.0000(0.0000) | Loss 8.9083(9.1791) | Error 0.0000(0.0000) Steps 940(943.46) | Grad Norm 1.6341(1.7358) | Total Time 0.00(0.00)\n",
      "Iter 21780 | Time 25.5572(24.5430) | Bit/dim 3.3260(3.3523) | Xent 0.0000(0.0000) | Loss 8.7408(9.0621) | Error 0.0000(0.0000) Steps 952(942.72) | Grad Norm 2.5626(1.9154) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 114.3952, Epoch Time 1482.3697(1502.8511), Bit/dim 3.3593(best: 3.3578), Xent 0.0000, Loss 3.3593, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21790 | Time 23.6764(24.4108) | Bit/dim 3.3580(3.3505) | Xent 0.0000(0.0000) | Loss 8.8256(9.8508) | Error 0.0000(0.0000) Steps 946(945.34) | Grad Norm 2.6613(2.0117) | Total Time 0.00(0.00)\n",
      "Iter 21800 | Time 24.7330(24.4748) | Bit/dim 3.3135(3.3499) | Xent 0.0000(0.0000) | Loss 8.7125(9.5774) | Error 0.0000(0.0000) Steps 934(944.22) | Grad Norm 2.7725(2.0546) | Total Time 0.00(0.00)\n",
      "Iter 21810 | Time 25.0159(24.5414) | Bit/dim 3.3183(3.3521) | Xent 0.0000(0.0000) | Loss 8.7236(9.3865) | Error 0.0000(0.0000) Steps 970(947.36) | Grad Norm 2.2075(1.9513) | Total Time 0.00(0.00)\n",
      "Iter 21820 | Time 24.7570(24.5042) | Bit/dim 3.3778(3.3535) | Xent 0.0000(0.0000) | Loss 8.9897(9.2333) | Error 0.0000(0.0000) Steps 946(947.14) | Grad Norm 1.8992(1.9865) | Total Time 0.00(0.00)\n",
      "Iter 21830 | Time 23.5037(24.5710) | Bit/dim 3.3676(3.3537) | Xent 0.0000(0.0000) | Loss 8.8802(9.1189) | Error 0.0000(0.0000) Steps 934(947.18) | Grad Norm 1.3254(1.9119) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 114.3438, Epoch Time 1479.2174(1502.1421), Bit/dim 3.3602(best: 3.3578), Xent 0.0000, Loss 3.3602, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21840 | Time 26.8054(24.5415) | Bit/dim 3.3429(3.3538) | Xent 0.0000(0.0000) | Loss 8.8169(10.0281) | Error 0.0000(0.0000) Steps 1000(948.01) | Grad Norm 2.4547(1.8182) | Total Time 0.00(0.00)\n",
      "Iter 21850 | Time 23.6996(24.4536) | Bit/dim 3.3744(3.3537) | Xent 0.0000(0.0000) | Loss 8.8601(9.7053) | Error 0.0000(0.0000) Steps 934(949.14) | Grad Norm 1.1167(1.7229) | Total Time 0.00(0.00)\n",
      "Iter 21860 | Time 23.9730(24.4836) | Bit/dim 3.3502(3.3512) | Xent 0.0000(0.0000) | Loss 8.8042(9.4636) | Error 0.0000(0.0000) Steps 964(950.31) | Grad Norm 2.4591(1.9211) | Total Time 0.00(0.00)\n",
      "Iter 21870 | Time 25.1422(24.5264) | Bit/dim 3.3845(3.3534) | Xent 0.0000(0.0000) | Loss 8.8630(9.3006) | Error 0.0000(0.0000) Steps 976(949.15) | Grad Norm 2.6648(2.0922) | Total Time 0.00(0.00)\n",
      "Iter 21880 | Time 24.1446(24.4993) | Bit/dim 3.3582(3.3509) | Xent 0.0000(0.0000) | Loss 8.9682(9.1662) | Error 0.0000(0.0000) Steps 958(949.03) | Grad Norm 1.6748(2.0413) | Total Time 0.00(0.00)\n",
      "Iter 21890 | Time 24.5003(24.5395) | Bit/dim 3.3583(3.3533) | Xent 0.0000(0.0000) | Loss 8.8937(9.0801) | Error 0.0000(0.0000) Steps 946(945.84) | Grad Norm 1.3666(1.8332) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 116.3403, Epoch Time 1484.0616(1501.5996), Bit/dim 3.3562(best: 3.3578), Xent 0.0000, Loss 3.3562, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21900 | Time 27.2701(24.6275) | Bit/dim 3.3281(3.3521) | Xent 0.0000(0.0000) | Loss 8.8393(9.8816) | Error 0.0000(0.0000) Steps 1006(949.79) | Grad Norm 1.4341(1.7061) | Total Time 0.00(0.00)\n",
      "Iter 21910 | Time 23.4322(24.5569) | Bit/dim 3.3364(3.3514) | Xent 0.0000(0.0000) | Loss 8.7739(9.6006) | Error 0.0000(0.0000) Steps 940(949.69) | Grad Norm 1.6821(1.6395) | Total Time 0.00(0.00)\n",
      "Iter 21920 | Time 24.4833(24.4806) | Bit/dim 3.3463(3.3525) | Xent 0.0000(0.0000) | Loss 8.8289(9.3837) | Error 0.0000(0.0000) Steps 928(948.32) | Grad Norm 0.8662(1.5766) | Total Time 0.00(0.00)\n",
      "Iter 21930 | Time 23.9739(24.5155) | Bit/dim 3.3738(3.3517) | Xent 0.0000(0.0000) | Loss 8.9344(9.2382) | Error 0.0000(0.0000) Steps 904(945.64) | Grad Norm 1.2737(1.4884) | Total Time 0.00(0.00)\n",
      "Iter 21940 | Time 25.4509(24.5592) | Bit/dim 3.3268(3.3519) | Xent 0.0000(0.0000) | Loss 8.9196(9.1260) | Error 0.0000(0.0000) Steps 988(949.34) | Grad Norm 2.0382(1.5076) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 114.9739, Epoch Time 1485.7628(1501.1245), Bit/dim 3.3594(best: 3.3562), Xent 0.0000, Loss 3.3594, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21950 | Time 24.0461(24.5335) | Bit/dim 3.3374(3.3522) | Xent 0.0000(0.0000) | Loss 8.7358(10.0256) | Error 0.0000(0.0000) Steps 964(948.14) | Grad Norm 1.4801(1.6089) | Total Time 0.00(0.00)\n",
      "Iter 21960 | Time 24.1833(24.6300) | Bit/dim 3.3431(3.3540) | Xent 0.0000(0.0000) | Loss 8.7364(9.7105) | Error 0.0000(0.0000) Steps 952(947.58) | Grad Norm 1.5505(1.5816) | Total Time 0.00(0.00)\n",
      "Iter 21970 | Time 28.2848(24.7173) | Bit/dim 3.3457(3.3535) | Xent 0.0000(0.0000) | Loss 8.7586(9.4830) | Error 0.0000(0.0000) Steps 1000(952.00) | Grad Norm 2.0751(1.5920) | Total Time 0.00(0.00)\n",
      "Iter 21980 | Time 24.9582(24.5886) | Bit/dim 3.3488(3.3527) | Xent 0.0000(0.0000) | Loss 8.7921(9.3071) | Error 0.0000(0.0000) Steps 946(949.65) | Grad Norm 1.2842(1.6742) | Total Time 0.00(0.00)\n",
      "Iter 21990 | Time 24.0197(24.5664) | Bit/dim 3.3112(3.3530) | Xent 0.0000(0.0000) | Loss 8.8632(9.1873) | Error 0.0000(0.0000) Steps 982(950.08) | Grad Norm 1.2036(1.6285) | Total Time 0.00(0.00)\n",
      "Iter 22000 | Time 24.1557(24.5611) | Bit/dim 3.3406(3.3516) | Xent 0.0000(0.0000) | Loss 8.8189(9.0842) | Error 0.0000(0.0000) Steps 946(946.94) | Grad Norm 0.7881(1.6339) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 114.4839, Epoch Time 1484.3989(1500.6228), Bit/dim 3.3598(best: 3.3562), Xent 0.0000, Loss 3.3598, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22010 | Time 23.8673(24.4255) | Bit/dim 3.3600(3.3545) | Xent 0.0000(0.0000) | Loss 8.7370(9.8645) | Error 0.0000(0.0000) Steps 904(939.64) | Grad Norm 2.6805(1.6734) | Total Time 0.00(0.00)\n",
      "Iter 22020 | Time 24.0541(24.3822) | Bit/dim 3.3572(3.3546) | Xent 0.0000(0.0000) | Loss 8.9116(9.5942) | Error 0.0000(0.0000) Steps 964(941.35) | Grad Norm 1.4957(1.7088) | Total Time 0.00(0.00)\n",
      "Iter 22030 | Time 23.9804(24.4325) | Bit/dim 3.3344(3.3545) | Xent 0.0000(0.0000) | Loss 8.7127(9.3908) | Error 0.0000(0.0000) Steps 934(942.26) | Grad Norm 1.4585(1.7326) | Total Time 0.00(0.00)\n",
      "Iter 22040 | Time 24.2561(24.4808) | Bit/dim 3.2869(3.3534) | Xent 0.0000(0.0000) | Loss 8.7169(9.2502) | Error 0.0000(0.0000) Steps 988(945.50) | Grad Norm 1.7446(1.7731) | Total Time 0.00(0.00)\n",
      "Iter 22050 | Time 24.9538(24.4377) | Bit/dim 3.3173(3.3516) | Xent 0.0000(0.0000) | Loss 8.7670(9.1287) | Error 0.0000(0.0000) Steps 976(945.03) | Grad Norm 1.8694(1.8954) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 116.3089, Epoch Time 1475.0650(1499.8560), Bit/dim 3.3577(best: 3.3562), Xent 0.0000, Loss 3.3577, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22060 | Time 25.6001(24.5245) | Bit/dim 3.3560(3.3539) | Xent 0.0000(0.0000) | Loss 8.8548(10.0335) | Error 0.0000(0.0000) Steps 982(945.82) | Grad Norm 4.8824(2.0235) | Total Time 0.00(0.00)\n",
      "Iter 22070 | Time 24.5958(24.4992) | Bit/dim 3.3323(3.3546) | Xent 0.0000(0.0000) | Loss 8.8811(9.7194) | Error 0.0000(0.0000) Steps 958(945.60) | Grad Norm 3.9805(2.2311) | Total Time 0.00(0.00)\n",
      "Iter 22080 | Time 24.2765(24.6941) | Bit/dim 3.2920(3.3512) | Xent 0.0000(0.0000) | Loss 8.7156(9.4904) | Error 0.0000(0.0000) Steps 952(946.42) | Grad Norm 4.3169(2.4777) | Total Time 0.00(0.00)\n",
      "Iter 22090 | Time 26.1335(24.7334) | Bit/dim 3.3786(3.3521) | Xent 0.0000(0.0000) | Loss 9.0185(9.3211) | Error 0.0000(0.0000) Steps 898(946.87) | Grad Norm 1.2793(2.3059) | Total Time 0.00(0.00)\n",
      "Iter 22100 | Time 24.7387(24.7629) | Bit/dim 3.3247(3.3499) | Xent 0.0000(0.0000) | Loss 8.7122(9.1753) | Error 0.0000(0.0000) Steps 982(949.00) | Grad Norm 1.8078(2.1121) | Total Time 0.00(0.00)\n",
      "Iter 22110 | Time 24.4012(24.6871) | Bit/dim 3.3939(3.3527) | Xent 0.0000(0.0000) | Loss 8.8109(9.0861) | Error 0.0000(0.0000) Steps 916(949.38) | Grad Norm 1.4495(1.9516) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 115.7214, Epoch Time 1499.2581(1499.8381), Bit/dim 3.3594(best: 3.3562), Xent 0.0000, Loss 3.3594, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22120 | Time 23.8388(24.6715) | Bit/dim 3.3601(3.3530) | Xent 0.0000(0.0000) | Loss 8.7962(9.8756) | Error 0.0000(0.0000) Steps 940(950.34) | Grad Norm 1.4076(1.8546) | Total Time 0.00(0.00)\n",
      "Iter 22130 | Time 24.7511(24.7172) | Bit/dim 3.3390(3.3519) | Xent 0.0000(0.0000) | Loss 8.8523(9.6017) | Error 0.0000(0.0000) Steps 934(953.32) | Grad Norm 1.2223(1.7587) | Total Time 0.00(0.00)\n",
      "Iter 22140 | Time 25.0072(24.9472) | Bit/dim 3.3611(3.3523) | Xent 0.0000(0.0000) | Loss 8.8691(9.4068) | Error 0.0000(0.0000) Steps 958(953.27) | Grad Norm 1.2094(1.6945) | Total Time 0.00(0.00)\n",
      "Iter 22150 | Time 25.5725(24.8220) | Bit/dim 3.3588(3.3516) | Xent 0.0000(0.0000) | Loss 8.7679(9.2501) | Error 0.0000(0.0000) Steps 970(954.56) | Grad Norm 1.0511(1.5762) | Total Time 0.00(0.00)\n",
      "Iter 22160 | Time 25.0429(24.7798) | Bit/dim 3.3714(3.3539) | Xent 0.0000(0.0000) | Loss 9.0863(9.1429) | Error 0.0000(0.0000) Steps 964(951.99) | Grad Norm 1.2821(1.4614) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 117.0112, Epoch Time 1502.8855(1499.9295), Bit/dim 3.3540(best: 3.3562), Xent 0.0000, Loss 3.3540, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22170 | Time 24.7284(24.8550) | Bit/dim 3.3405(3.3545) | Xent 0.0000(0.0000) | Loss 8.8434(10.0405) | Error 0.0000(0.0000) Steps 994(955.49) | Grad Norm 2.0097(1.4481) | Total Time 0.00(0.00)\n",
      "Iter 22180 | Time 24.0837(24.8736) | Bit/dim 3.3762(3.3534) | Xent 0.0000(0.0000) | Loss 8.7251(9.7163) | Error 0.0000(0.0000) Steps 946(955.41) | Grad Norm 1.4569(1.6102) | Total Time 0.00(0.00)\n",
      "Iter 22190 | Time 25.8545(24.7573) | Bit/dim 3.3700(3.3511) | Xent 0.0000(0.0000) | Loss 8.8165(9.4642) | Error 0.0000(0.0000) Steps 928(950.40) | Grad Norm 1.4332(1.6886) | Total Time 0.00(0.00)\n",
      "Iter 22200 | Time 26.1600(24.7966) | Bit/dim 3.3520(3.3523) | Xent 0.0000(0.0000) | Loss 8.7240(9.3047) | Error 0.0000(0.0000) Steps 922(951.13) | Grad Norm 1.1759(1.6433) | Total Time 0.00(0.00)\n",
      "Iter 22210 | Time 24.9687(24.7494) | Bit/dim 3.3236(3.3521) | Xent 0.0000(0.0000) | Loss 8.8010(9.1788) | Error 0.0000(0.0000) Steps 976(947.25) | Grad Norm 1.6632(1.6483) | Total Time 0.00(0.00)\n",
      "Iter 22220 | Time 25.2616(24.7959) | Bit/dim 3.3727(3.3547) | Xent 0.0000(0.0000) | Loss 8.8993(9.0899) | Error 0.0000(0.0000) Steps 958(948.22) | Grad Norm 1.9055(1.6824) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 115.8443, Epoch Time 1497.1796(1499.8470), Bit/dim 3.3568(best: 3.3540), Xent 0.0000, Loss 3.3568, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22230 | Time 24.6800(24.7988) | Bit/dim 3.3553(3.3555) | Xent 0.0000(0.0000) | Loss 8.9102(9.8853) | Error 0.0000(0.0000) Steps 994(953.17) | Grad Norm 1.7709(1.6954) | Total Time 0.00(0.00)\n",
      "Iter 22240 | Time 25.1453(24.8143) | Bit/dim 3.3219(3.3532) | Xent 0.0000(0.0000) | Loss 8.8776(9.6179) | Error 0.0000(0.0000) Steps 928(952.22) | Grad Norm 1.5134(1.5626) | Total Time 0.00(0.00)\n",
      "Iter 22250 | Time 25.0226(24.6581) | Bit/dim 3.3577(3.3545) | Xent 0.0000(0.0000) | Loss 8.8594(9.4060) | Error 0.0000(0.0000) Steps 970(953.10) | Grad Norm 1.9506(1.5775) | Total Time 0.00(0.00)\n",
      "Iter 22260 | Time 25.2399(24.6187) | Bit/dim 3.3334(3.3514) | Xent 0.0000(0.0000) | Loss 8.7564(9.2506) | Error 0.0000(0.0000) Steps 976(954.22) | Grad Norm 1.4806(1.6078) | Total Time 0.00(0.00)\n",
      "Iter 22270 | Time 24.3846(24.7027) | Bit/dim 3.3431(3.3538) | Xent 0.0000(0.0000) | Loss 8.9112(9.1454) | Error 0.0000(0.0000) Steps 958(954.43) | Grad Norm 2.7919(1.6987) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 115.1266, Epoch Time 1494.5403(1499.6878), Bit/dim 3.3593(best: 3.3540), Xent 0.0000, Loss 3.3593, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22280 | Time 24.9308(24.7934) | Bit/dim 3.3235(3.3533) | Xent 0.0000(0.0000) | Loss 8.9252(10.0470) | Error 0.0000(0.0000) Steps 952(952.64) | Grad Norm 1.6929(1.7554) | Total Time 0.00(0.00)\n",
      "Iter 22290 | Time 25.4971(24.8357) | Bit/dim 3.3253(3.3529) | Xent 0.0000(0.0000) | Loss 8.8208(9.7304) | Error 0.0000(0.0000) Steps 952(952.15) | Grad Norm 1.8438(1.6856) | Total Time 0.00(0.00)\n",
      "Iter 22300 | Time 24.7290(24.9184) | Bit/dim 3.3499(3.3516) | Xent 0.0000(0.0000) | Loss 8.9058(9.4900) | Error 0.0000(0.0000) Steps 934(952.34) | Grad Norm 1.9515(1.6136) | Total Time 0.00(0.00)\n",
      "Iter 22310 | Time 25.2021(24.9326) | Bit/dim 3.3480(3.3518) | Xent 0.0000(0.0000) | Loss 8.8367(9.3096) | Error 0.0000(0.0000) Steps 928(950.57) | Grad Norm 1.1443(1.6832) | Total Time 0.00(0.00)\n",
      "Iter 22320 | Time 24.0267(24.8931) | Bit/dim 3.3257(3.3514) | Xent 0.0000(0.0000) | Loss 8.7431(9.1704) | Error 0.0000(0.0000) Steps 952(948.75) | Grad Norm 1.8470(1.8153) | Total Time 0.00(0.00)\n",
      "Iter 22330 | Time 25.2566(25.0372) | Bit/dim 3.3356(3.3528) | Xent 0.0000(0.0000) | Loss 8.8010(9.0757) | Error 0.0000(0.0000) Steps 928(948.79) | Grad Norm 1.6177(1.7270) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 115.5053, Epoch Time 1510.5482(1500.0136), Bit/dim 3.3577(best: 3.3540), Xent 0.0000, Loss 3.3577, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22340 | Time 24.7044(24.8749) | Bit/dim 3.3693(3.3542) | Xent 0.0000(0.0000) | Loss 8.7976(9.9078) | Error 0.0000(0.0000) Steps 934(950.83) | Grad Norm 1.5871(1.7396) | Total Time 0.00(0.00)\n",
      "Iter 22350 | Time 24.3533(24.9152) | Bit/dim 3.3311(3.3512) | Xent 0.0000(0.0000) | Loss 8.7741(9.6035) | Error 0.0000(0.0000) Steps 952(948.27) | Grad Norm 1.8641(1.6672) | Total Time 0.00(0.00)\n",
      "Iter 22360 | Time 24.6847(24.8984) | Bit/dim 3.3561(3.3532) | Xent 0.0000(0.0000) | Loss 8.7703(9.3937) | Error 0.0000(0.0000) Steps 958(951.19) | Grad Norm 2.1099(1.6712) | Total Time 0.00(0.00)\n",
      "Iter 22370 | Time 23.9290(24.8553) | Bit/dim 3.3277(3.3509) | Xent 0.0000(0.0000) | Loss 8.8183(9.2388) | Error 0.0000(0.0000) Steps 934(950.90) | Grad Norm 1.1091(1.7256) | Total Time 0.00(0.00)\n",
      "Iter 22380 | Time 24.8298(24.9057) | Bit/dim 3.3708(3.3510) | Xent 0.0000(0.0000) | Loss 8.8105(9.1280) | Error 0.0000(0.0000) Steps 982(951.77) | Grad Norm 1.8398(1.6946) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 116.4119, Epoch Time 1502.7148(1500.0947), Bit/dim 3.3588(best: 3.3540), Xent 0.0000, Loss 3.3588, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22390 | Time 24.0068(24.8534) | Bit/dim 3.3666(3.3532) | Xent 0.0000(0.0000) | Loss 8.7346(10.0380) | Error 0.0000(0.0000) Steps 922(947.05) | Grad Norm 2.3734(1.7528) | Total Time 0.00(0.00)\n",
      "Iter 22400 | Time 23.5709(24.7972) | Bit/dim 3.3358(3.3525) | Xent 0.0000(0.0000) | Loss 8.7897(9.7072) | Error 0.0000(0.0000) Steps 916(942.10) | Grad Norm 1.6812(1.6444) | Total Time 0.00(0.00)\n",
      "Iter 22410 | Time 24.0270(24.9225) | Bit/dim 3.3639(3.3538) | Xent 0.0000(0.0000) | Loss 8.9531(9.4763) | Error 0.0000(0.0000) Steps 952(945.52) | Grad Norm 1.2382(1.5744) | Total Time 0.00(0.00)\n",
      "Iter 22420 | Time 24.6666(24.7559) | Bit/dim 3.3310(3.3512) | Xent 0.0000(0.0000) | Loss 8.6627(9.2970) | Error 0.0000(0.0000) Steps 916(946.59) | Grad Norm 2.2427(1.5881) | Total Time 0.00(0.00)\n",
      "Iter 22430 | Time 25.7076(24.7622) | Bit/dim 3.3380(3.3515) | Xent 0.0000(0.0000) | Loss 8.8033(9.1760) | Error 0.0000(0.0000) Steps 976(948.32) | Grad Norm 2.1415(1.8615) | Total Time 0.00(0.00)\n",
      "Iter 22440 | Time 23.6875(24.7201) | Bit/dim 3.3560(3.3505) | Xent 0.0000(0.0000) | Loss 8.8374(9.0886) | Error 0.0000(0.0000) Steps 898(947.65) | Grad Norm 2.7672(2.0343) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 115.5849, Epoch Time 1492.0368(1499.8529), Bit/dim 3.3603(best: 3.3540), Xent 0.0000, Loss 3.3603, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22450 | Time 25.0816(24.6791) | Bit/dim 3.3663(3.3507) | Xent 0.0000(0.0000) | Loss 8.8573(9.8603) | Error 0.0000(0.0000) Steps 988(946.07) | Grad Norm 2.0577(2.0850) | Total Time 0.00(0.00)\n",
      "Iter 22460 | Time 25.4047(24.7687) | Bit/dim 3.2994(3.3507) | Xent 0.0000(0.0000) | Loss 8.6445(9.5913) | Error 0.0000(0.0000) Steps 964(949.33) | Grad Norm 2.4431(1.9962) | Total Time 0.00(0.00)\n",
      "Iter 22470 | Time 24.1056(24.6764) | Bit/dim 3.3274(3.3505) | Xent 0.0000(0.0000) | Loss 8.8352(9.3818) | Error 0.0000(0.0000) Steps 952(950.28) | Grad Norm 2.1357(1.9662) | Total Time 0.00(0.00)\n",
      "Iter 22480 | Time 24.1624(24.6120) | Bit/dim 3.3443(3.3525) | Xent 0.0000(0.0000) | Loss 8.9111(9.2358) | Error 0.0000(0.0000) Steps 976(949.65) | Grad Norm 2.5354(1.9309) | Total Time 0.00(0.00)\n",
      "Iter 22490 | Time 24.8633(24.6392) | Bit/dim 3.3606(3.3536) | Xent 0.0000(0.0000) | Loss 8.9439(9.1390) | Error 0.0000(0.0000) Steps 964(950.27) | Grad Norm 2.2588(1.9465) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 115.4641, Epoch Time 1494.2023(1499.6834), Bit/dim 3.3554(best: 3.3540), Xent 0.0000, Loss 3.3554, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22500 | Time 24.3941(24.7005) | Bit/dim 3.3106(3.3512) | Xent 0.0000(0.0000) | Loss 8.6923(10.0305) | Error 0.0000(0.0000) Steps 958(951.39) | Grad Norm 1.9823(1.8924) | Total Time 0.00(0.00)\n",
      "Iter 22510 | Time 24.1524(24.7552) | Bit/dim 3.3200(3.3508) | Xent 0.0000(0.0000) | Loss 8.7490(9.7225) | Error 0.0000(0.0000) Steps 958(950.20) | Grad Norm 1.4787(1.8895) | Total Time 0.00(0.00)\n",
      "Iter 22520 | Time 24.7145(24.8582) | Bit/dim 3.3669(3.3506) | Xent 0.0000(0.0000) | Loss 8.8098(9.4926) | Error 0.0000(0.0000) Steps 904(948.76) | Grad Norm 1.9029(1.8478) | Total Time 0.00(0.00)\n",
      "Iter 22530 | Time 23.7809(24.8184) | Bit/dim 3.3311(3.3521) | Xent 0.0000(0.0000) | Loss 8.7316(9.3247) | Error 0.0000(0.0000) Steps 940(951.05) | Grad Norm 1.1292(1.8941) | Total Time 0.00(0.00)\n",
      "Iter 22540 | Time 23.8782(24.6688) | Bit/dim 3.3229(3.3531) | Xent 0.0000(0.0000) | Loss 8.7983(9.2040) | Error 0.0000(0.0000) Steps 946(951.93) | Grad Norm 1.7153(1.8985) | Total Time 0.00(0.00)\n",
      "Iter 22550 | Time 26.0991(24.7020) | Bit/dim 3.3420(3.3540) | Xent 0.0000(0.0000) | Loss 8.8815(9.0999) | Error 0.0000(0.0000) Steps 1000(953.17) | Grad Norm 1.2155(1.8388) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 116.9415, Epoch Time 1494.3051(1499.5221), Bit/dim 3.3562(best: 3.3540), Xent 0.0000, Loss 3.3562, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22560 | Time 24.9553(24.6984) | Bit/dim 3.3719(3.3553) | Xent 0.0000(0.0000) | Loss 8.8809(9.8884) | Error 0.0000(0.0000) Steps 904(950.23) | Grad Norm 1.0130(1.7604) | Total Time 0.00(0.00)\n",
      "Iter 22570 | Time 23.9080(24.7841) | Bit/dim 3.3659(3.3544) | Xent 0.0000(0.0000) | Loss 8.7884(9.6045) | Error 0.0000(0.0000) Steps 940(954.63) | Grad Norm 1.2824(1.6739) | Total Time 0.00(0.00)\n",
      "Iter 22580 | Time 26.4587(24.9531) | Bit/dim 3.3774(3.3561) | Xent 0.0000(0.0000) | Loss 8.9671(9.4047) | Error 0.0000(0.0000) Steps 946(955.99) | Grad Norm 1.4679(1.6188) | Total Time 0.00(0.00)\n",
      "Iter 22590 | Time 24.0664(24.8346) | Bit/dim 3.3580(3.3520) | Xent 0.0000(0.0000) | Loss 8.7888(9.2419) | Error 0.0000(0.0000) Steps 964(955.06) | Grad Norm 2.6738(1.5697) | Total Time 0.00(0.00)\n",
      "Iter 22600 | Time 24.3878(24.7442) | Bit/dim 3.3499(3.3504) | Xent 0.0000(0.0000) | Loss 8.8722(9.1371) | Error 0.0000(0.0000) Steps 988(955.73) | Grad Norm 1.1227(1.5277) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 116.7170, Epoch Time 1503.4668(1499.6404), Bit/dim 3.3585(best: 3.3540), Xent 0.0000, Loss 3.3585, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22610 | Time 23.9656(24.7875) | Bit/dim 3.3379(3.3475) | Xent 0.0000(0.0000) | Loss 8.7685(10.0299) | Error 0.0000(0.0000) Steps 958(952.56) | Grad Norm 2.1501(1.6929) | Total Time 0.00(0.00)\n",
      "Iter 22620 | Time 24.1024(24.8250) | Bit/dim 3.3512(3.3472) | Xent 0.0000(0.0000) | Loss 8.8167(9.7175) | Error 0.0000(0.0000) Steps 952(955.25) | Grad Norm 1.7748(1.7026) | Total Time 0.00(0.00)\n",
      "Iter 22630 | Time 23.5739(24.9445) | Bit/dim 3.3144(3.3465) | Xent 0.0000(0.0000) | Loss 8.6522(9.4742) | Error 0.0000(0.0000) Steps 898(957.76) | Grad Norm 2.5859(1.9236) | Total Time 0.00(0.00)\n",
      "Iter 22640 | Time 25.0775(24.9741) | Bit/dim 3.3713(3.3491) | Xent 0.0000(0.0000) | Loss 8.7106(9.3102) | Error 0.0000(0.0000) Steps 910(958.68) | Grad Norm 1.4831(1.9006) | Total Time 0.00(0.00)\n",
      "Iter 22650 | Time 24.5114(24.8832) | Bit/dim 3.3327(3.3503) | Xent 0.0000(0.0000) | Loss 8.9550(9.1828) | Error 0.0000(0.0000) Steps 958(953.66) | Grad Norm 1.6886(1.8887) | Total Time 0.00(0.00)\n",
      "Iter 22660 | Time 24.2973(24.7863) | Bit/dim 3.3607(3.3525) | Xent 0.0000(0.0000) | Loss 8.6875(9.0974) | Error 0.0000(0.0000) Steps 976(956.27) | Grad Norm 1.0941(1.9146) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 116.8314, Epoch Time 1503.2498(1499.7487), Bit/dim 3.3585(best: 3.3540), Xent 0.0000, Loss 3.3585, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22670 | Time 24.7555(24.7951) | Bit/dim 3.3481(3.3526) | Xent 0.0000(0.0000) | Loss 8.8557(9.8774) | Error 0.0000(0.0000) Steps 940(954.41) | Grad Norm 1.2781(1.8910) | Total Time 0.00(0.00)\n",
      "Iter 22680 | Time 25.5282(24.8389) | Bit/dim 3.3666(3.3499) | Xent 0.0000(0.0000) | Loss 8.9002(9.5981) | Error 0.0000(0.0000) Steps 952(953.95) | Grad Norm 2.3250(1.9866) | Total Time 0.00(0.00)\n",
      "Iter 22690 | Time 28.7091(24.9460) | Bit/dim 3.3611(3.3511) | Xent 0.0000(0.0000) | Loss 8.8072(9.3981) | Error 0.0000(0.0000) Steps 982(952.86) | Grad Norm 1.8182(2.0588) | Total Time 0.00(0.00)\n",
      "Iter 22700 | Time 24.9467(24.9317) | Bit/dim 3.3497(3.3527) | Xent 0.0000(0.0000) | Loss 8.8734(9.2519) | Error 0.0000(0.0000) Steps 982(955.00) | Grad Norm 1.6461(2.0317) | Total Time 0.00(0.00)\n",
      "Iter 22710 | Time 25.7307(24.9490) | Bit/dim 3.3423(3.3511) | Xent 0.0000(0.0000) | Loss 8.8987(9.1295) | Error 0.0000(0.0000) Steps 946(953.12) | Grad Norm 1.5739(1.9870) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 116.8557, Epoch Time 1510.5253(1500.0720), Bit/dim 3.3578(best: 3.3540), Xent 0.0000, Loss 3.3578, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22720 | Time 25.5419(24.9785) | Bit/dim 3.3454(3.3540) | Xent 0.0000(0.0000) | Loss 8.6917(10.0655) | Error 0.0000(0.0000) Steps 970(956.08) | Grad Norm 2.9874(2.1705) | Total Time 0.00(0.00)\n",
      "Iter 22730 | Time 25.9881(25.0315) | Bit/dim 3.3559(3.3542) | Xent 0.0000(0.0000) | Loss 8.8154(9.7438) | Error 0.0000(0.0000) Steps 946(955.65) | Grad Norm 2.2139(2.2608) | Total Time 0.00(0.00)\n",
      "Iter 22740 | Time 24.7048(24.9979) | Bit/dim 3.3658(3.3529) | Xent 0.0000(0.0000) | Loss 8.8280(9.5030) | Error 0.0000(0.0000) Steps 934(953.72) | Grad Norm 2.0971(2.2003) | Total Time 0.00(0.00)\n",
      "Iter 22750 | Time 24.4110(24.9562) | Bit/dim 3.3870(3.3521) | Xent 0.0000(0.0000) | Loss 8.9231(9.3330) | Error 0.0000(0.0000) Steps 958(956.70) | Grad Norm 1.3434(1.9578) | Total Time 0.00(0.00)\n",
      "Iter 22760 | Time 24.3894(24.8192) | Bit/dim 3.3473(3.3516) | Xent 0.0000(0.0000) | Loss 8.6830(9.1946) | Error 0.0000(0.0000) Steps 934(954.50) | Grad Norm 1.4001(1.7650) | Total Time 0.00(0.00)\n",
      "Iter 22770 | Time 24.4442(24.8750) | Bit/dim 3.3293(3.3501) | Xent 0.0000(0.0000) | Loss 8.8148(9.0953) | Error 0.0000(0.0000) Steps 970(956.50) | Grad Norm 1.1649(1.7233) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 117.7321, Epoch Time 1504.7297(1500.2117), Bit/dim 3.3571(best: 3.3540), Xent 0.0000, Loss 3.3571, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22780 | Time 24.2817(24.7341) | Bit/dim 3.3251(3.3505) | Xent 0.0000(0.0000) | Loss 8.8475(9.8809) | Error 0.0000(0.0000) Steps 946(953.66) | Grad Norm 1.3963(1.6403) | Total Time 0.00(0.00)\n",
      "Iter 22790 | Time 24.1673(24.7201) | Bit/dim 3.3616(3.3483) | Xent 0.0000(0.0000) | Loss 8.9704(9.5856) | Error 0.0000(0.0000) Steps 928(950.34) | Grad Norm 1.0913(1.6122) | Total Time 0.00(0.00)\n",
      "Iter 22800 | Time 24.4311(24.8074) | Bit/dim 3.3351(3.3479) | Xent 0.0000(0.0000) | Loss 8.7505(9.3794) | Error 0.0000(0.0000) Steps 922(947.81) | Grad Norm 1.7051(1.5494) | Total Time 0.00(0.00)\n",
      "Iter 22810 | Time 24.6908(24.7289) | Bit/dim 3.3768(3.3514) | Xent 0.0000(0.0000) | Loss 8.9378(9.2404) | Error 0.0000(0.0000) Steps 970(950.54) | Grad Norm 1.5168(1.5251) | Total Time 0.00(0.00)\n",
      "Iter 22820 | Time 25.4025(24.7216) | Bit/dim 3.3555(3.3514) | Xent 0.0000(0.0000) | Loss 8.9008(9.1373) | Error 0.0000(0.0000) Steps 946(949.42) | Grad Norm 1.5319(1.6257) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 117.7666, Epoch Time 1493.2704(1500.0035), Bit/dim 3.3612(best: 3.3540), Xent 0.0000, Loss 3.3612, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22830 | Time 24.8405(24.6953) | Bit/dim 3.3223(3.3540) | Xent 0.0000(0.0000) | Loss 8.8630(10.0613) | Error 0.0000(0.0000) Steps 964(949.67) | Grad Norm 1.9350(1.9219) | Total Time 0.00(0.00)\n",
      "Iter 22840 | Time 25.2892(24.7788) | Bit/dim 3.3735(3.3536) | Xent 0.0000(0.0000) | Loss 8.9637(9.7366) | Error 0.0000(0.0000) Steps 976(952.74) | Grad Norm 1.2091(1.8839) | Total Time 0.00(0.00)\n",
      "Iter 22850 | Time 24.9435(24.8543) | Bit/dim 3.3407(3.3528) | Xent 0.0000(0.0000) | Loss 8.7295(9.5013) | Error 0.0000(0.0000) Steps 922(951.11) | Grad Norm 1.2466(1.9299) | Total Time 0.00(0.00)\n",
      "Iter 22860 | Time 24.4344(24.7906) | Bit/dim 3.3188(3.3499) | Xent 0.0000(0.0000) | Loss 8.6157(9.3040) | Error 0.0000(0.0000) Steps 934(949.53) | Grad Norm 2.2945(2.0457) | Total Time 0.00(0.00)\n",
      "Iter 22870 | Time 24.7143(24.8930) | Bit/dim 3.3687(3.3488) | Xent 0.0000(0.0000) | Loss 8.8785(9.1857) | Error 0.0000(0.0000) Steps 970(953.76) | Grad Norm 2.3170(2.1264) | Total Time 0.00(0.00)\n",
      "Iter 22880 | Time 24.6440(24.9041) | Bit/dim 3.3284(3.3524) | Xent 0.0000(0.0000) | Loss 8.7682(9.0975) | Error 0.0000(0.0000) Steps 976(955.42) | Grad Norm 1.5892(2.1441) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 116.9095, Epoch Time 1505.7409(1500.1756), Bit/dim 3.3535(best: 3.3540), Xent 0.0000, Loss 3.3535, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22890 | Time 24.4631(24.9537) | Bit/dim 3.3336(3.3481) | Xent 0.0000(0.0000) | Loss 8.8230(9.8701) | Error 0.0000(0.0000) Steps 958(953.13) | Grad Norm 0.9225(1.9082) | Total Time 0.00(0.00)\n",
      "Iter 22900 | Time 25.2583(24.9881) | Bit/dim 3.3619(3.3487) | Xent 0.0000(0.0000) | Loss 8.7583(9.5939) | Error 0.0000(0.0000) Steps 970(953.79) | Grad Norm 2.7884(1.9152) | Total Time 0.00(0.00)\n",
      "Iter 22910 | Time 25.3013(25.0174) | Bit/dim 3.3543(3.3514) | Xent 0.0000(0.0000) | Loss 8.7438(9.3962) | Error 0.0000(0.0000) Steps 964(957.24) | Grad Norm 1.1586(1.9050) | Total Time 0.00(0.00)\n",
      "Iter 22920 | Time 24.6231(24.9563) | Bit/dim 3.3506(3.3539) | Xent 0.0000(0.0000) | Loss 8.8238(9.2551) | Error 0.0000(0.0000) Steps 934(958.74) | Grad Norm 2.0238(1.8866) | Total Time 0.00(0.00)\n",
      "Iter 22930 | Time 23.9000(24.9640) | Bit/dim 3.3443(3.3532) | Xent 0.0000(0.0000) | Loss 8.8904(9.1484) | Error 0.0000(0.0000) Steps 952(958.62) | Grad Norm 2.3046(1.9334) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 117.4693, Epoch Time 1510.0473(1500.4717), Bit/dim 3.3563(best: 3.3535), Xent 0.0000, Loss 3.3563, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22940 | Time 25.3478(24.9391) | Bit/dim 3.3897(3.3543) | Xent 0.0000(0.0000) | Loss 9.0097(10.0641) | Error 0.0000(0.0000) Steps 1012(958.34) | Grad Norm 1.9648(1.9653) | Total Time 0.00(0.00)\n",
      "Iter 22950 | Time 23.0575(24.8676) | Bit/dim 3.3344(3.3526) | Xent 0.0000(0.0000) | Loss 8.7194(9.7420) | Error 0.0000(0.0000) Steps 940(959.15) | Grad Norm 1.8806(1.9033) | Total Time 0.00(0.00)\n",
      "Iter 22960 | Time 24.4680(24.8376) | Bit/dim 3.3724(3.3548) | Xent 0.0000(0.0000) | Loss 8.7665(9.5095) | Error 0.0000(0.0000) Steps 946(958.12) | Grad Norm 2.5230(1.8136) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_cifar10_bs900_rl_stdscale_6_run2 --resume ../experiments_published/cnf_cifar10_bs900_rl_stdscale_6_run2/epoch_250_checkpt.pth --seed 2 --lr 0.0001 --conditional False --controlled_tol False --log_freq 10 --scale_fac 1.0 --scale_std 6.0\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
