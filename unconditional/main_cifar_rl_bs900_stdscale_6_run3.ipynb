{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import torch.utils.data as data\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "plt.rcParams['figure.dpi'] = 300\n",
      "\n",
      "from PIL import Image\n",
      "import os.path\n",
      "import errno\n",
      "import codecs\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"colormnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--y_class\", type=int, default=10)\n",
      "parser.add_argument(\"--y_color\", type=int, default=10)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "class ColorMNIST(data.Dataset):\n",
      "    \"\"\"\n",
      "    ColorMNIST\n",
      "    \"\"\"\n",
      "    urls = [\n",
      "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
      "    ]\n",
      "    raw_folder = 'raw'\n",
      "    processed_folder = 'processed'\n",
      "    training_file = 'training.pt'\n",
      "    test_file = 'test.pt'\n",
      "\n",
      "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
      "        self.root = os.path.expanduser(root)\n",
      "        self.transform = transform\n",
      "        self.target_transform = target_transform\n",
      "        self.train = train  # training set or test set\n",
      "\n",
      "        if download:\n",
      "            self.download()\n",
      "\n",
      "        if not self._check_exists():\n",
      "            raise RuntimeError('Dataset not found.' +\n",
      "                               ' You can use download=True to download it')\n",
      "\n",
      "        if self.train:\n",
      "            self.train_data, self.train_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
      "            \n",
      "            self.train_data = np.tile(self.train_data[:, :, :, np.newaxis], 3)\n",
      "        else:\n",
      "            self.test_data, self.test_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "            \n",
      "            self.test_data = np.tile(self.test_data[:, :, :, np.newaxis], 3)\n",
      "        \n",
      "        self.pallette = [[31, 119, 180],\n",
      "                         [255, 127, 14],\n",
      "                         [44, 160, 44],\n",
      "                         [214, 39, 40],\n",
      "                         [148, 103, 189],\n",
      "                         [140, 86, 75],\n",
      "                         [227, 119, 194],\n",
      "                         [127, 127, 127],\n",
      "                         [188, 189, 34],\n",
      "                         [23, 190, 207]]\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            index (int): Index\n",
      "\n",
      "        Returns:\n",
      "            tuple: (image, target) where target is index of the target class.\n",
      "        \"\"\"\n",
      "        if self.train:\n",
      "            img, target = self.train_data[index].copy(), self.train_labels[index]\n",
      "        else:\n",
      "            img, target = self.test_data[index].copy(), self.test_labels[index]\n",
      "        \n",
      "        # doing this so that it is consistent with all other datasets\n",
      "        # to return a PIL Image\n",
      "        y_color_digit = np.random.randint(0, args.y_color)\n",
      "        c_digit = self.pallette[y_color_digit]\n",
      "        \n",
      "        img[:, :, 0] = img[:, :, 0] / 255 * c_digit[0]\n",
      "        img[:, :, 1] = img[:, :, 1] / 255 * c_digit[1]\n",
      "        img[:, :, 2] = img[:, :, 2] / 255 * c_digit[2]\n",
      "        \n",
      "        img = Image.fromarray(img)\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "\n",
      "        return img, [target,torch.from_numpy(np.array(y_color_digit))]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.train:\n",
      "            return len(self.train_data)\n",
      "        else:\n",
      "            return len(self.test_data)\n",
      "\n",
      "    def _check_exists(self):\n",
      "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
      "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "\n",
      "    def download(self):\n",
      "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
      "        from six.moves import urllib\n",
      "        import gzip\n",
      "\n",
      "        if self._check_exists():\n",
      "            return\n",
      "\n",
      "        # download files\n",
      "        try:\n",
      "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
      "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
      "        except OSError as e:\n",
      "            if e.errno == errno.EEXIST:\n",
      "                pass\n",
      "            else:\n",
      "                raise\n",
      "\n",
      "        for url in self.urls:\n",
      "            print('Downloading ' + url)\n",
      "            data = urllib.request.urlopen(url)\n",
      "            filename = url.rpartition('/')[2]\n",
      "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
      "            with open(file_path, 'wb') as f:\n",
      "                f.write(data.read())\n",
      "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
      "                    gzip.GzipFile(file_path) as zip_f:\n",
      "                out_f.write(zip_f.read())\n",
      "            os.unlink(file_path)\n",
      "\n",
      "        # process and save as torch files\n",
      "        print('Processing...')\n",
      "\n",
      "        training_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
      "        )\n",
      "        test_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
      "        )\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
      "            torch.save(training_set, f)\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
      "            torch.save(test_set, f)\n",
      "\n",
      "        print('Done!')\n",
      "\n",
      "    def __repr__(self):\n",
      "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
      "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
      "        tmp = 'train' if self.train is True else 'test'\n",
      "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
      "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
      "        tmp = '    Transforms (if any): '\n",
      "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        tmp = '    Target Transforms (if any): '\n",
      "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        return fmt_str\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"colormnist\":\n",
      "        im_dim = 3\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = ColorMNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = ColorMNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,\n",
      "            y_class = args.y_class)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            if args.data == \"colormnist\":\n",
      "                y = y[0]\n",
      "            \n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        if args.data == \"colormnist\":\n",
      "            # print train images\n",
      "            xall = []\n",
      "            ximg = x[0:40].cpu().numpy().transpose((0,2,3,1))\n",
      "            for i in range(ximg.shape[0]):\n",
      "                xall.append(ximg[i])\n",
      "        \n",
      "            xall = np.hstack(xall)\n",
      "\n",
      "            plt.imshow(xall)\n",
      "            plt.axis('off')\n",
      "            plt.show()\n",
      "            \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if args.data == \"colormnist\":\n",
      "                        y = y[0]\n",
      "                        \n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                if args.data == \"colormnist\":\n",
      "                    # print test images\n",
      "                    xall = []\n",
      "                    ximg = x[0:40].cpu().numpy().transpose((0,2,3,1))\n",
      "                    for i in range(ximg.shape[0]):\n",
      "                        xall.append(ximg[i])\n",
      "\n",
      "                    xall = np.hstack(xall)\n",
      "\n",
      "                    plt.imshow(xall)\n",
      "                    plt.axis('off')\n",
      "                    plt.show()\n",
      "                    \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=False, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=False, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.0, eta=0.1, gamma=0.99, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_cifar10_bs900_rl_stdscale_6_run3/epoch_250_checkpt.pth', rl_weight=0.01, rtol=1e-05, save='../experiments_published/cnf_cifar10_bs900_rl_stdscale_6_run3', scale=1.0, scale_fac=1.0, scale_std=6.0, seed=3, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5, y_class=10, y_color=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1450732\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 13760 | Time 22.8550(23.0732) | Bit/dim 3.4263(3.4209) | Xent 0.0000(0.0000) | Loss 8.7868(9.4887) | Error 0.0000(0.0000) Steps 916(901.56) | Grad Norm 3.0373(4.5435) | Total Time 0.00(0.00)\n",
      "Iter 13770 | Time 23.5230(23.0365) | Bit/dim 3.3869(3.4168) | Xent 0.0000(0.0000) | Loss 8.5488(9.2530) | Error 0.0000(0.0000) Steps 892(903.10) | Grad Norm 2.2429(3.8537) | Total Time 0.00(0.00)\n",
      "Iter 13780 | Time 23.8047(23.0406) | Bit/dim 3.4092(3.4119) | Xent 0.0000(0.0000) | Loss 8.5679(9.0737) | Error 0.0000(0.0000) Steps 886(901.87) | Grad Norm 1.2208(3.1724) | Total Time 0.00(0.00)\n",
      "Iter 13790 | Time 22.7227(22.9955) | Bit/dim 3.4082(3.4137) | Xent 0.0000(0.0000) | Loss 8.6785(8.9637) | Error 0.0000(0.0000) Steps 916(900.92) | Grad Norm 0.5147(2.5510) | Total Time 0.00(0.00)\n",
      "Iter 13800 | Time 22.3424(23.0192) | Bit/dim 3.4066(3.4143) | Xent 0.0000(0.0000) | Loss 8.4975(8.8855) | Error 0.0000(0.0000) Steps 904(903.25) | Grad Norm 0.5302(2.0294) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 107.8898, Epoch Time 1415.0973(1294.1643), Bit/dim 3.4148(best: inf), Xent 0.0000, Loss 3.4148, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13810 | Time 22.4455(22.9916) | Bit/dim 3.3911(3.4145) | Xent 0.0000(0.0000) | Loss 8.5965(9.6517) | Error 0.0000(0.0000) Steps 880(902.58) | Grad Norm 0.5260(1.6483) | Total Time 0.00(0.00)\n",
      "Iter 13820 | Time 22.8724(23.0423) | Bit/dim 3.3811(3.4102) | Xent 0.0000(0.0000) | Loss 8.6980(9.3853) | Error 0.0000(0.0000) Steps 892(902.09) | Grad Norm 0.6718(1.3746) | Total Time 0.00(0.00)\n",
      "Iter 13830 | Time 22.8095(22.9954) | Bit/dim 3.3986(3.4104) | Xent 0.0000(0.0000) | Loss 8.6310(9.1979) | Error 0.0000(0.0000) Steps 910(901.30) | Grad Norm 0.5308(1.1577) | Total Time 0.00(0.00)\n",
      "Iter 13840 | Time 22.7997(23.0264) | Bit/dim 3.4173(3.4098) | Xent 0.0000(0.0000) | Loss 8.7092(9.0621) | Error 0.0000(0.0000) Steps 886(902.18) | Grad Norm 0.6186(0.9930) | Total Time 0.00(0.00)\n",
      "Iter 13850 | Time 23.0099(22.9346) | Bit/dim 3.3853(3.4105) | Xent 0.0000(0.0000) | Loss 8.5526(8.9540) | Error 0.0000(0.0000) Steps 904(902.03) | Grad Norm 0.5706(0.8767) | Total Time 0.00(0.00)\n",
      "Iter 13860 | Time 22.8379(22.9331) | Bit/dim 3.4374(3.4152) | Xent 0.0000(0.0000) | Loss 8.7256(8.8847) | Error 0.0000(0.0000) Steps 928(900.95) | Grad Norm 0.5382(0.7994) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 104.6140, Epoch Time 1385.3794(1296.9007), Bit/dim 3.4167(best: 3.4148), Xent 0.0000, Loss 3.4167, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13870 | Time 21.6647(22.9462) | Bit/dim 3.4015(3.4144) | Xent 0.0000(0.0000) | Loss 8.6472(9.5761) | Error 0.0000(0.0000) Steps 892(900.35) | Grad Norm 0.5373(0.7388) | Total Time 0.00(0.00)\n",
      "Iter 13880 | Time 22.9321(22.9444) | Bit/dim 3.4370(3.4113) | Xent 0.0000(0.0000) | Loss 8.6939(9.3313) | Error 0.0000(0.0000) Steps 868(898.61) | Grad Norm 0.5153(0.6949) | Total Time 0.00(0.00)\n",
      "Iter 13890 | Time 23.2489(22.9368) | Bit/dim 3.3921(3.4090) | Xent 0.0000(0.0000) | Loss 8.4958(9.1384) | Error 0.0000(0.0000) Steps 916(897.38) | Grad Norm 0.5432(0.6471) | Total Time 0.00(0.00)\n",
      "Iter 13900 | Time 22.5515(22.9291) | Bit/dim 3.4091(3.4101) | Xent 0.0000(0.0000) | Loss 8.6702(9.0209) | Error 0.0000(0.0000) Steps 904(899.99) | Grad Norm 0.5683(0.6251) | Total Time 0.00(0.00)\n",
      "Iter 13910 | Time 22.4273(22.9306) | Bit/dim 3.4033(3.4126) | Xent 0.0000(0.0000) | Loss 8.6755(8.9451) | Error 0.0000(0.0000) Steps 892(900.32) | Grad Norm 0.7927(0.6218) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 104.3811, Epoch Time 1385.2048(1299.5499), Bit/dim 3.4180(best: 3.4148), Xent 0.0000, Loss 3.4180, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13920 | Time 21.9242(22.9187) | Bit/dim 3.3943(3.4098) | Xent 0.0000(0.0000) | Loss 8.5394(9.6961) | Error 0.0000(0.0000) Steps 880(899.40) | Grad Norm 0.6535(0.6108) | Total Time 0.00(0.00)\n",
      "Iter 13930 | Time 22.9362(22.9946) | Bit/dim 3.4324(3.4117) | Xent 0.0000(0.0000) | Loss 8.7665(9.4402) | Error 0.0000(0.0000) Steps 904(898.83) | Grad Norm 0.6514(0.6009) | Total Time 0.00(0.00)\n",
      "Iter 13940 | Time 23.3779(22.9861) | Bit/dim 3.3969(3.4104) | Xent 0.0000(0.0000) | Loss 8.6582(9.2399) | Error 0.0000(0.0000) Steps 916(898.39) | Grad Norm 0.5625(0.5876) | Total Time 0.00(0.00)\n",
      "Iter 13950 | Time 22.3220(22.9202) | Bit/dim 3.4183(3.4097) | Xent 0.0000(0.0000) | Loss 8.7588(9.0808) | Error 0.0000(0.0000) Steps 898(899.16) | Grad Norm 0.5918(0.5899) | Total Time 0.00(0.00)\n",
      "Iter 13960 | Time 22.9478(22.9168) | Bit/dim 3.4159(3.4126) | Xent 0.0000(0.0000) | Loss 8.7340(8.9649) | Error 0.0000(0.0000) Steps 868(900.74) | Grad Norm 0.5259(0.5809) | Total Time 0.00(0.00)\n",
      "Iter 13970 | Time 22.6217(22.8752) | Bit/dim 3.4344(3.4127) | Xent 0.0000(0.0000) | Loss 8.6313(8.8867) | Error 0.0000(0.0000) Steps 886(901.50) | Grad Norm 0.5684(0.5741) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 104.1092, Epoch Time 1382.4539(1302.0370), Bit/dim 3.4178(best: 3.4148), Xent 0.0000, Loss 3.4178, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13980 | Time 22.9596(22.8983) | Bit/dim 3.4315(3.4097) | Xent 0.0000(0.0000) | Loss 8.6900(9.5314) | Error 0.0000(0.0000) Steps 880(897.65) | Grad Norm 0.6823(0.5863) | Total Time 0.00(0.00)\n",
      "Iter 13990 | Time 22.5442(22.8841) | Bit/dim 3.3802(3.4099) | Xent 0.0000(0.0000) | Loss 8.4113(9.2930) | Error 0.0000(0.0000) Steps 880(897.85) | Grad Norm 0.6906(0.5891) | Total Time 0.00(0.00)\n",
      "Iter 14000 | Time 22.4796(22.9080) | Bit/dim 3.3918(3.4103) | Xent 0.0000(0.0000) | Loss 8.6821(9.1323) | Error 0.0000(0.0000) Steps 892(899.81) | Grad Norm 0.5354(0.5790) | Total Time 0.00(0.00)\n",
      "Iter 14010 | Time 23.4824(22.9341) | Bit/dim 3.4066(3.4128) | Xent 0.0000(0.0000) | Loss 8.7604(9.0208) | Error 0.0000(0.0000) Steps 898(901.08) | Grad Norm 0.5238(0.5722) | Total Time 0.00(0.00)\n",
      "Iter 14020 | Time 23.9363(22.9875) | Bit/dim 3.4079(3.4103) | Xent 0.0000(0.0000) | Loss 8.6582(8.9198) | Error 0.0000(0.0000) Steps 892(901.19) | Grad Norm 0.6223(0.5677) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 105.1819, Epoch Time 1388.1825(1304.6213), Bit/dim 3.4163(best: 3.4148), Xent 0.0000, Loss 3.4163, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14030 | Time 23.2133(22.9871) | Bit/dim 3.4090(3.4089) | Xent 0.0000(0.0000) | Loss 8.7388(9.6990) | Error 0.0000(0.0000) Steps 856(899.83) | Grad Norm 0.6201(0.5828) | Total Time 0.00(0.00)\n",
      "Iter 14040 | Time 22.5695(23.0225) | Bit/dim 3.4618(3.4126) | Xent 0.0000(0.0000) | Loss 8.6582(9.4345) | Error 0.0000(0.0000) Steps 892(899.31) | Grad Norm 0.7629(0.6032) | Total Time 0.00(0.00)\n",
      "Iter 14050 | Time 23.4749(22.9995) | Bit/dim 3.4315(3.4120) | Xent 0.0000(0.0000) | Loss 8.6567(9.2242) | Error 0.0000(0.0000) Steps 898(898.66) | Grad Norm 0.5341(0.6091) | Total Time 0.00(0.00)\n",
      "Iter 14060 | Time 22.7980(22.9934) | Bit/dim 3.3997(3.4111) | Xent 0.0000(0.0000) | Loss 8.6097(9.0771) | Error 0.0000(0.0000) Steps 898(899.69) | Grad Norm 0.4936(0.5986) | Total Time 0.00(0.00)\n",
      "Iter 14070 | Time 23.4802(22.9980) | Bit/dim 3.3878(3.4111) | Xent 0.0000(0.0000) | Loss 8.5833(8.9680) | Error 0.0000(0.0000) Steps 928(899.08) | Grad Norm 0.4924(0.5988) | Total Time 0.00(0.00)\n",
      "Iter 14080 | Time 22.8326(22.9588) | Bit/dim 3.3934(3.4111) | Xent 0.0000(0.0000) | Loss 8.5575(8.8936) | Error 0.0000(0.0000) Steps 892(899.54) | Grad Norm 0.5683(0.5962) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 104.5363, Epoch Time 1386.4029(1307.0748), Bit/dim 3.4176(best: 3.4148), Xent 0.0000, Loss 3.4176, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14090 | Time 23.7929(23.0161) | Bit/dim 3.3992(3.4090) | Xent 0.0000(0.0000) | Loss 8.6545(9.5695) | Error 0.0000(0.0000) Steps 916(900.74) | Grad Norm 0.5419(0.5860) | Total Time 0.00(0.00)\n",
      "Iter 14100 | Time 23.5191(23.0222) | Bit/dim 3.4001(3.4104) | Xent 0.0000(0.0000) | Loss 8.6390(9.3404) | Error 0.0000(0.0000) Steps 904(902.17) | Grad Norm 0.5554(0.5876) | Total Time 0.00(0.00)\n",
      "Iter 14110 | Time 22.3245(23.0033) | Bit/dim 3.4333(3.4114) | Xent 0.0000(0.0000) | Loss 8.6472(9.1638) | Error 0.0000(0.0000) Steps 904(904.99) | Grad Norm 0.5444(0.5816) | Total Time 0.00(0.00)\n",
      "Iter 14120 | Time 22.0367(22.9825) | Bit/dim 3.3918(3.4102) | Xent 0.0000(0.0000) | Loss 8.5546(9.0404) | Error 0.0000(0.0000) Steps 886(905.31) | Grad Norm 0.5360(0.5772) | Total Time 0.00(0.00)\n",
      "Iter 14130 | Time 23.5235(23.0194) | Bit/dim 3.4153(3.4084) | Xent 0.0000(0.0000) | Loss 8.6381(8.9296) | Error 0.0000(0.0000) Steps 928(904.62) | Grad Norm 0.6252(0.5941) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 105.6676, Epoch Time 1393.0241(1309.6533), Bit/dim 3.4162(best: 3.4148), Xent 0.0000, Loss 3.4162, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14140 | Time 23.2284(23.0682) | Bit/dim 3.4385(3.4098) | Xent 0.0000(0.0000) | Loss 8.7918(9.7236) | Error 0.0000(0.0000) Steps 946(905.57) | Grad Norm 0.6578(0.6076) | Total Time 0.00(0.00)\n",
      "Iter 14150 | Time 22.8560(23.0134) | Bit/dim 3.4120(3.4115) | Xent 0.0000(0.0000) | Loss 8.6552(9.4406) | Error 0.0000(0.0000) Steps 880(903.13) | Grad Norm 0.6626(0.6052) | Total Time 0.00(0.00)\n",
      "Iter 14160 | Time 23.5126(23.0824) | Bit/dim 3.3842(3.4121) | Xent 0.0000(0.0000) | Loss 8.6925(9.2450) | Error 0.0000(0.0000) Steps 928(904.26) | Grad Norm 0.5408(0.6099) | Total Time 0.00(0.00)\n",
      "Iter 14170 | Time 23.4677(23.1820) | Bit/dim 3.3991(3.4100) | Xent 0.0000(0.0000) | Loss 8.6241(9.0975) | Error 0.0000(0.0000) Steps 910(906.77) | Grad Norm 0.5584(0.6096) | Total Time 0.00(0.00)\n",
      "Iter 14180 | Time 22.6469(23.1479) | Bit/dim 3.3943(3.4091) | Xent 0.0000(0.0000) | Loss 8.5654(8.9806) | Error 0.0000(0.0000) Steps 886(903.33) | Grad Norm 0.5951(0.6091) | Total Time 0.00(0.00)\n",
      "Iter 14190 | Time 23.5416(23.1162) | Bit/dim 3.4544(3.4107) | Xent 0.0000(0.0000) | Loss 8.8121(8.9063) | Error 0.0000(0.0000) Steps 874(902.38) | Grad Norm 0.6273(0.6262) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 104.8608, Epoch Time 1394.8185(1312.2082), Bit/dim 3.4156(best: 3.4148), Xent 0.0000, Loss 3.4156, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14200 | Time 22.8053(23.0537) | Bit/dim 3.4399(3.4118) | Xent 0.0000(0.0000) | Loss 8.8906(9.5822) | Error 0.0000(0.0000) Steps 934(903.05) | Grad Norm 0.5377(0.6194) | Total Time 0.00(0.00)\n",
      "Iter 14210 | Time 23.1017(23.0386) | Bit/dim 3.3930(3.4124) | Xent 0.0000(0.0000) | Loss 8.6548(9.3446) | Error 0.0000(0.0000) Steps 910(900.90) | Grad Norm 0.6011(0.6247) | Total Time 0.00(0.00)\n",
      "Iter 14220 | Time 23.7388(22.9940) | Bit/dim 3.4102(3.4110) | Xent 0.0000(0.0000) | Loss 8.7641(9.1614) | Error 0.0000(0.0000) Steps 892(901.29) | Grad Norm 0.7005(0.6440) | Total Time 0.00(0.00)\n",
      "Iter 14230 | Time 22.2706(22.9347) | Bit/dim 3.4095(3.4091) | Xent 0.0000(0.0000) | Loss 8.6242(9.0377) | Error 0.0000(0.0000) Steps 886(900.17) | Grad Norm 0.5658(0.6575) | Total Time 0.00(0.00)\n",
      "Iter 14240 | Time 22.6897(22.9283) | Bit/dim 3.4389(3.4120) | Xent 0.0000(0.0000) | Loss 8.7034(8.9430) | Error 0.0000(0.0000) Steps 898(900.65) | Grad Norm 0.7337(0.6543) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 105.1461, Epoch Time 1380.9043(1314.2691), Bit/dim 3.4139(best: 3.4148), Xent 0.0000, Loss 3.4139, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14250 | Time 23.2158(22.9811) | Bit/dim 3.3997(3.4112) | Xent 0.0000(0.0000) | Loss 8.5588(9.7134) | Error 0.0000(0.0000) Steps 898(902.67) | Grad Norm 0.7955(0.6608) | Total Time 0.00(0.00)\n",
      "Iter 14260 | Time 22.9709(22.9786) | Bit/dim 3.3727(3.4076) | Xent 0.0000(0.0000) | Loss 8.4814(9.4269) | Error 0.0000(0.0000) Steps 880(903.30) | Grad Norm 0.4810(0.6450) | Total Time 0.00(0.00)\n",
      "Iter 14270 | Time 22.5741(22.9360) | Bit/dim 3.4246(3.4092) | Xent 0.0000(0.0000) | Loss 8.6045(9.2346) | Error 0.0000(0.0000) Steps 916(905.75) | Grad Norm 0.7221(0.6352) | Total Time 0.00(0.00)\n",
      "Iter 14280 | Time 23.3092(22.9341) | Bit/dim 3.4330(3.4109) | Xent 0.0000(0.0000) | Loss 8.8285(9.1003) | Error 0.0000(0.0000) Steps 910(906.68) | Grad Norm 0.6278(0.6373) | Total Time 0.00(0.00)\n",
      "Iter 14290 | Time 22.3776(23.0015) | Bit/dim 3.4084(3.4093) | Xent 0.0000(0.0000) | Loss 8.6736(8.9846) | Error 0.0000(0.0000) Steps 892(905.46) | Grad Norm 0.8060(0.6720) | Total Time 0.00(0.00)\n",
      "Iter 14300 | Time 22.7098(22.9967) | Bit/dim 3.4395(3.4109) | Xent 0.0000(0.0000) | Loss 8.6767(8.9159) | Error 0.0000(0.0000) Steps 898(905.59) | Grad Norm 0.8998(0.7066) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 105.5584, Epoch Time 1390.0664(1316.5430), Bit/dim 3.4156(best: 3.4139), Xent 0.0000, Loss 3.4156, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14310 | Time 23.3172(23.0212) | Bit/dim 3.4121(3.4133) | Xent 0.0000(0.0000) | Loss 8.7209(9.5992) | Error 0.0000(0.0000) Steps 934(902.63) | Grad Norm 0.7881(0.7001) | Total Time 0.00(0.00)\n",
      "Iter 14320 | Time 23.1716(23.0469) | Bit/dim 3.3794(3.4104) | Xent 0.0000(0.0000) | Loss 8.7116(9.3642) | Error 0.0000(0.0000) Steps 898(901.17) | Grad Norm 0.7682(0.7132) | Total Time 0.00(0.00)\n",
      "Iter 14330 | Time 22.6471(23.0630) | Bit/dim 3.3772(3.4092) | Xent 0.0000(0.0000) | Loss 8.5257(9.1862) | Error 0.0000(0.0000) Steps 868(900.62) | Grad Norm 0.6452(0.7234) | Total Time 0.00(0.00)\n",
      "Iter 14340 | Time 23.7488(23.0963) | Bit/dim 3.4235(3.4087) | Xent 0.0000(0.0000) | Loss 8.8141(9.0669) | Error 0.0000(0.0000) Steps 934(901.21) | Grad Norm 0.7377(0.6926) | Total Time 0.00(0.00)\n",
      "Iter 14350 | Time 22.9917(23.0752) | Bit/dim 3.4073(3.4100) | Xent 0.0000(0.0000) | Loss 8.6586(8.9817) | Error 0.0000(0.0000) Steps 898(902.22) | Grad Norm 0.6180(0.6880) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 105.6527, Epoch Time 1393.7374(1318.8588), Bit/dim 3.4140(best: 3.4139), Xent 0.0000, Loss 3.4140, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14360 | Time 24.0262(23.0895) | Bit/dim 3.3906(3.4104) | Xent 0.0000(0.0000) | Loss 8.7182(9.7533) | Error 0.0000(0.0000) Steps 898(903.12) | Grad Norm 0.6775(0.6795) | Total Time 0.00(0.00)\n",
      "Iter 14370 | Time 22.4814(22.9885) | Bit/dim 3.4446(3.4094) | Xent 0.0000(0.0000) | Loss 8.6733(9.4787) | Error 0.0000(0.0000) Steps 898(904.56) | Grad Norm 0.8640(0.6840) | Total Time 0.00(0.00)\n",
      "Iter 14380 | Time 23.2872(22.9635) | Bit/dim 3.4162(3.4087) | Xent 0.0000(0.0000) | Loss 8.8881(9.2706) | Error 0.0000(0.0000) Steps 922(905.01) | Grad Norm 0.6369(0.6801) | Total Time 0.00(0.00)\n",
      "Iter 14390 | Time 22.6147(22.9154) | Bit/dim 3.4143(3.4083) | Xent 0.0000(0.0000) | Loss 8.6787(9.1199) | Error 0.0000(0.0000) Steps 886(902.84) | Grad Norm 0.5569(0.6683) | Total Time 0.00(0.00)\n",
      "Iter 14400 | Time 23.4506(22.9575) | Bit/dim 3.4407(3.4098) | Xent 0.0000(0.0000) | Loss 8.8301(9.0195) | Error 0.0000(0.0000) Steps 898(903.65) | Grad Norm 0.5931(0.7137) | Total Time 0.00(0.00)\n",
      "Iter 14410 | Time 23.0816(22.8991) | Bit/dim 3.3939(3.4121) | Xent 0.0000(0.0000) | Loss 8.7016(8.9320) | Error 0.0000(0.0000) Steps 928(903.83) | Grad Norm 0.7712(0.7302) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 107.3042, Epoch Time 1384.2977(1320.8220), Bit/dim 3.4190(best: 3.4139), Xent 0.0000, Loss 3.4190, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14420 | Time 23.0533(23.0532) | Bit/dim 3.4139(3.4117) | Xent 0.0000(0.0000) | Loss 8.7497(9.6112) | Error 0.0000(0.0000) Steps 898(903.83) | Grad Norm 0.7767(0.7345) | Total Time 0.00(0.00)\n",
      "Iter 14430 | Time 23.0960(23.0454) | Bit/dim 3.4151(3.4106) | Xent 0.0000(0.0000) | Loss 8.7577(9.3647) | Error 0.0000(0.0000) Steps 904(903.43) | Grad Norm 0.6261(0.7180) | Total Time 0.00(0.00)\n",
      "Iter 14440 | Time 23.1753(23.1472) | Bit/dim 3.3971(3.4081) | Xent 0.0000(0.0000) | Loss 8.7043(9.1944) | Error 0.0000(0.0000) Steps 934(905.68) | Grad Norm 0.5368(0.6876) | Total Time 0.00(0.00)\n",
      "Iter 14450 | Time 23.2347(23.1712) | Bit/dim 3.4443(3.4084) | Xent 0.0000(0.0000) | Loss 8.7687(9.0623) | Error 0.0000(0.0000) Steps 904(904.90) | Grad Norm 0.4445(0.6651) | Total Time 0.00(0.00)\n",
      "Iter 14460 | Time 22.6780(23.0572) | Bit/dim 3.4345(3.4118) | Xent 0.0000(0.0000) | Loss 8.7747(8.9768) | Error 0.0000(0.0000) Steps 898(903.75) | Grad Norm 0.6498(0.6650) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 104.8690, Epoch Time 1399.2712(1323.1755), Bit/dim 3.4135(best: 3.4139), Xent 0.0000, Loss 3.4135, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14470 | Time 23.6125(23.0655) | Bit/dim 3.4443(3.4095) | Xent 0.0000(0.0000) | Loss 8.6447(9.7672) | Error 0.0000(0.0000) Steps 904(905.05) | Grad Norm 0.6481(0.6638) | Total Time 0.00(0.00)\n",
      "Iter 14480 | Time 23.2923(23.0431) | Bit/dim 3.3947(3.4103) | Xent 0.0000(0.0000) | Loss 8.7118(9.4917) | Error 0.0000(0.0000) Steps 928(904.66) | Grad Norm 0.5658(0.6628) | Total Time 0.00(0.00)\n",
      "Iter 14490 | Time 22.6967(22.9534) | Bit/dim 3.3884(3.4089) | Xent 0.0000(0.0000) | Loss 8.5016(9.2709) | Error 0.0000(0.0000) Steps 910(904.76) | Grad Norm 0.8275(0.6477) | Total Time 0.00(0.00)\n",
      "Iter 14500 | Time 23.2836(22.9916) | Bit/dim 3.3969(3.4066) | Xent 0.0000(0.0000) | Loss 8.6301(9.1030) | Error 0.0000(0.0000) Steps 898(903.45) | Grad Norm 0.8216(0.6486) | Total Time 0.00(0.00)\n",
      "Iter 14510 | Time 21.6167(22.9603) | Bit/dim 3.4041(3.4088) | Xent 0.0000(0.0000) | Loss 8.5919(8.9976) | Error 0.0000(0.0000) Steps 886(900.58) | Grad Norm 0.6691(0.6550) | Total Time 0.00(0.00)\n",
      "Iter 14520 | Time 23.5524(22.9474) | Bit/dim 3.4029(3.4111) | Xent 0.0000(0.0000) | Loss 8.7107(8.9203) | Error 0.0000(0.0000) Steps 910(899.39) | Grad Norm 0.5657(0.6560) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 105.8433, Epoch Time 1384.0816(1325.0027), Bit/dim 3.4148(best: 3.4135), Xent 0.0000, Loss 3.4148, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14530 | Time 22.1057(22.9461) | Bit/dim 3.4034(3.4123) | Xent 0.0000(0.0000) | Loss 8.5609(9.6293) | Error 0.0000(0.0000) Steps 904(901.12) | Grad Norm 0.5992(0.6504) | Total Time 0.00(0.00)\n",
      "Iter 14540 | Time 23.5983(23.0660) | Bit/dim 3.4003(3.4107) | Xent 0.0000(0.0000) | Loss 8.6233(9.3870) | Error 0.0000(0.0000) Steps 898(903.23) | Grad Norm 0.5177(0.6563) | Total Time 0.00(0.00)\n",
      "Iter 14550 | Time 22.8365(23.0039) | Bit/dim 3.4175(3.4094) | Xent 0.0000(0.0000) | Loss 8.7552(9.2003) | Error 0.0000(0.0000) Steps 916(903.92) | Grad Norm 0.7243(0.6718) | Total Time 0.00(0.00)\n",
      "Iter 14560 | Time 22.9997(23.0379) | Bit/dim 3.4139(3.4100) | Xent 0.0000(0.0000) | Loss 8.6155(9.0672) | Error 0.0000(0.0000) Steps 904(902.50) | Grad Norm 0.8886(0.6842) | Total Time 0.00(0.00)\n",
      "Iter 14570 | Time 23.7008(23.0909) | Bit/dim 3.4372(3.4093) | Xent 0.0000(0.0000) | Loss 8.6556(8.9766) | Error 0.0000(0.0000) Steps 904(905.39) | Grad Norm 0.6521(0.7388) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 105.8979, Epoch Time 1396.0829(1327.1351), Bit/dim 3.4176(best: 3.4135), Xent 0.0000, Loss 3.4176, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14580 | Time 23.1749(23.0846) | Bit/dim 3.3975(3.4082) | Xent 0.0000(0.0000) | Loss 8.6891(9.7753) | Error 0.0000(0.0000) Steps 916(905.38) | Grad Norm 1.0365(0.7856) | Total Time 0.00(0.00)\n",
      "Iter 14590 | Time 22.2379(23.0514) | Bit/dim 3.4239(3.4094) | Xent 0.0000(0.0000) | Loss 8.7518(9.5034) | Error 0.0000(0.0000) Steps 928(906.91) | Grad Norm 0.5912(0.7935) | Total Time 0.00(0.00)\n",
      "Iter 14600 | Time 23.3173(23.0812) | Bit/dim 3.4114(3.4093) | Xent 0.0000(0.0000) | Loss 8.6989(9.2970) | Error 0.0000(0.0000) Steps 910(906.80) | Grad Norm 0.7452(0.7499) | Total Time 0.00(0.00)\n",
      "Iter 14610 | Time 23.7491(23.1040) | Bit/dim 3.4127(3.4103) | Xent 0.0000(0.0000) | Loss 8.7496(9.1465) | Error 0.0000(0.0000) Steps 898(905.25) | Grad Norm 0.6704(0.7671) | Total Time 0.00(0.00)\n",
      "Iter 14620 | Time 22.8540(23.0872) | Bit/dim 3.3901(3.4090) | Xent 0.0000(0.0000) | Loss 8.6672(9.0293) | Error 0.0000(0.0000) Steps 934(907.36) | Grad Norm 0.8103(0.7948) | Total Time 0.00(0.00)\n",
      "Iter 14630 | Time 23.2821(23.1974) | Bit/dim 3.3976(3.4097) | Xent 0.0000(0.0000) | Loss 8.6775(8.9525) | Error 0.0000(0.0000) Steps 910(910.56) | Grad Norm 0.7011(0.7972) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 107.8227, Epoch Time 1399.1465(1329.2954), Bit/dim 3.4142(best: 3.4135), Xent 0.0000, Loss 3.4142, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14640 | Time 23.2208(23.2834) | Bit/dim 3.3995(3.4089) | Xent 0.0000(0.0000) | Loss 8.8709(9.6484) | Error 0.0000(0.0000) Steps 922(914.13) | Grad Norm 0.5832(0.7818) | Total Time 0.00(0.00)\n",
      "Iter 14650 | Time 22.8496(23.2941) | Bit/dim 3.4276(3.4097) | Xent 0.0000(0.0000) | Loss 8.6588(9.4047) | Error 0.0000(0.0000) Steps 886(914.33) | Grad Norm 0.6095(0.7562) | Total Time 0.00(0.00)\n",
      "Iter 14660 | Time 22.3259(23.2933) | Bit/dim 3.3636(3.4077) | Xent 0.0000(0.0000) | Loss 8.5392(9.2185) | Error 0.0000(0.0000) Steps 892(918.09) | Grad Norm 0.6917(0.7447) | Total Time 0.00(0.00)\n",
      "Iter 14670 | Time 23.8670(23.4147) | Bit/dim 3.4214(3.4072) | Xent 0.0000(0.0000) | Loss 8.7582(9.0990) | Error 0.0000(0.0000) Steps 958(923.25) | Grad Norm 0.6223(0.7371) | Total Time 0.00(0.00)\n",
      "Iter 14680 | Time 22.4767(23.3492) | Bit/dim 3.4119(3.4073) | Xent 0.0000(0.0000) | Loss 8.7403(9.0042) | Error 0.0000(0.0000) Steps 916(923.33) | Grad Norm 0.4818(0.7213) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0267 | Time 108.2364, Epoch Time 1413.5383(1331.8227), Bit/dim 3.4134(best: 3.4135), Xent 0.0000, Loss 3.4134, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14690 | Time 23.3820(23.3269) | Bit/dim 3.4199(3.4108) | Xent 0.0000(0.0000) | Loss 8.7500(9.8276) | Error 0.0000(0.0000) Steps 880(919.07) | Grad Norm 0.5410(0.6885) | Total Time 0.00(0.00)\n",
      "Iter 14700 | Time 23.5994(23.4392) | Bit/dim 3.4093(3.4125) | Xent 0.0000(0.0000) | Loss 8.7140(9.5498) | Error 0.0000(0.0000) Steps 886(919.07) | Grad Norm 0.7089(0.6863) | Total Time 0.00(0.00)\n",
      "Iter 14710 | Time 23.4647(23.4028) | Bit/dim 3.3718(3.4091) | Xent 0.0000(0.0000) | Loss 8.6571(9.3262) | Error 0.0000(0.0000) Steps 898(918.30) | Grad Norm 0.6485(0.6931) | Total Time 0.00(0.00)\n",
      "Iter 14720 | Time 23.7161(23.3840) | Bit/dim 3.3999(3.4095) | Xent 0.0000(0.0000) | Loss 8.6929(9.1748) | Error 0.0000(0.0000) Steps 952(919.45) | Grad Norm 0.6782(0.7262) | Total Time 0.00(0.00)\n",
      "Iter 14730 | Time 23.3999(23.3502) | Bit/dim 3.3963(3.4069) | Xent 0.0000(0.0000) | Loss 8.5531(9.0521) | Error 0.0000(0.0000) Steps 916(921.28) | Grad Norm 0.7574(0.7370) | Total Time 0.00(0.00)\n",
      "Iter 14740 | Time 24.3024(23.3182) | Bit/dim 3.4209(3.4085) | Xent 0.0000(0.0000) | Loss 8.7120(8.9621) | Error 0.0000(0.0000) Steps 952(920.80) | Grad Norm 0.5239(0.7125) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0268 | Time 107.3536, Epoch Time 1410.5009(1334.1831), Bit/dim 3.4167(best: 3.4134), Xent 0.0000, Loss 3.4167, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14750 | Time 23.0278(23.2878) | Bit/dim 3.3793(3.4051) | Xent 0.0000(0.0000) | Loss 8.5716(9.6529) | Error 0.0000(0.0000) Steps 922(919.97) | Grad Norm 0.6390(0.7045) | Total Time 0.00(0.00)\n",
      "Iter 14760 | Time 22.3516(23.2166) | Bit/dim 3.4107(3.4074) | Xent 0.0000(0.0000) | Loss 8.6964(9.4082) | Error 0.0000(0.0000) Steps 898(919.99) | Grad Norm 0.7359(0.6949) | Total Time 0.00(0.00)\n",
      "Iter 14770 | Time 23.5000(23.2053) | Bit/dim 3.3994(3.4110) | Xent 0.0000(0.0000) | Loss 8.7415(9.2383) | Error 0.0000(0.0000) Steps 928(918.55) | Grad Norm 1.0907(0.7090) | Total Time 0.00(0.00)\n",
      "Iter 14780 | Time 22.9287(23.2601) | Bit/dim 3.4076(3.4103) | Xent 0.0000(0.0000) | Loss 8.7770(9.1086) | Error 0.0000(0.0000) Steps 886(918.19) | Grad Norm 0.6254(0.7138) | Total Time 0.00(0.00)\n",
      "Iter 14790 | Time 23.6496(23.2100) | Bit/dim 3.4325(3.4110) | Xent 0.0000(0.0000) | Loss 8.7904(8.9986) | Error 0.0000(0.0000) Steps 958(917.20) | Grad Norm 0.8334(0.7501) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0269 | Time 107.0383, Epoch Time 1398.4933(1336.1124), Bit/dim 3.4156(best: 3.4134), Xent 0.0000, Loss 3.4156, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14800 | Time 23.5658(23.1865) | Bit/dim 3.4250(3.4085) | Xent 0.0000(0.0000) | Loss 8.7646(9.7667) | Error 0.0000(0.0000) Steps 928(918.71) | Grad Norm 0.7066(0.7551) | Total Time 0.00(0.00)\n",
      "Iter 14810 | Time 23.8672(23.1887) | Bit/dim 3.4018(3.4081) | Xent 0.0000(0.0000) | Loss 8.8137(9.4849) | Error 0.0000(0.0000) Steps 952(919.63) | Grad Norm 0.8498(0.7518) | Total Time 0.00(0.00)\n",
      "Iter 14820 | Time 23.4479(23.1454) | Bit/dim 3.4097(3.4095) | Xent 0.0000(0.0000) | Loss 8.6518(9.2854) | Error 0.0000(0.0000) Steps 910(917.68) | Grad Norm 0.7945(0.7718) | Total Time 0.00(0.00)\n",
      "Iter 14830 | Time 24.0319(23.2026) | Bit/dim 3.4360(3.4109) | Xent 0.0000(0.0000) | Loss 8.7562(9.1421) | Error 0.0000(0.0000) Steps 904(915.33) | Grad Norm 0.7673(0.7784) | Total Time 0.00(0.00)\n",
      "Iter 14840 | Time 23.3601(23.2760) | Bit/dim 3.3951(3.4072) | Xent 0.0000(0.0000) | Loss 8.7598(9.0342) | Error 0.0000(0.0000) Steps 910(914.61) | Grad Norm 0.8928(0.7588) | Total Time 0.00(0.00)\n",
      "Iter 14850 | Time 23.2721(23.3227) | Bit/dim 3.4193(3.4094) | Xent 0.0000(0.0000) | Loss 8.6480(8.9538) | Error 0.0000(0.0000) Steps 892(914.08) | Grad Norm 0.8271(0.7593) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0270 | Time 107.2872, Epoch Time 1406.6922(1338.2298), Bit/dim 3.4126(best: 3.4134), Xent 0.0000, Loss 3.4126, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14860 | Time 22.2675(23.3571) | Bit/dim 3.3905(3.4090) | Xent 0.0000(0.0000) | Loss 8.7146(9.6439) | Error 0.0000(0.0000) Steps 898(914.26) | Grad Norm 1.0037(0.7869) | Total Time 0.00(0.00)\n",
      "Iter 14870 | Time 24.1591(23.3840) | Bit/dim 3.4373(3.4095) | Xent 0.0000(0.0000) | Loss 8.7401(9.3980) | Error 0.0000(0.0000) Steps 946(912.84) | Grad Norm 0.7286(0.8290) | Total Time 0.00(0.00)\n",
      "Iter 14880 | Time 22.8263(23.4231) | Bit/dim 3.4072(3.4116) | Xent 0.0000(0.0000) | Loss 8.6388(9.2177) | Error 0.0000(0.0000) Steps 886(912.73) | Grad Norm 0.6421(0.8000) | Total Time 0.00(0.00)\n",
      "Iter 14890 | Time 23.5546(23.3731) | Bit/dim 3.4063(3.4104) | Xent 0.0000(0.0000) | Loss 8.7315(9.0834) | Error 0.0000(0.0000) Steps 934(914.92) | Grad Norm 0.6696(0.7799) | Total Time 0.00(0.00)\n",
      "Iter 14900 | Time 23.0332(23.4396) | Bit/dim 3.4012(3.4081) | Xent 0.0000(0.0000) | Loss 8.7021(8.9835) | Error 0.0000(0.0000) Steps 916(916.64) | Grad Norm 1.1917(0.8061) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0271 | Time 109.2146, Epoch Time 1418.1042(1340.6260), Bit/dim 3.4117(best: 3.4126), Xent 0.0000, Loss 3.4117, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14910 | Time 23.5665(23.4622) | Bit/dim 3.4307(3.4037) | Xent 0.0000(0.0000) | Loss 8.7348(9.8022) | Error 0.0000(0.0000) Steps 910(916.27) | Grad Norm 1.0199(0.8209) | Total Time 0.00(0.00)\n",
      "Iter 14920 | Time 23.6464(23.4861) | Bit/dim 3.4035(3.4063) | Xent 0.0000(0.0000) | Loss 8.7138(9.5142) | Error 0.0000(0.0000) Steps 940(917.83) | Grad Norm 0.8122(0.8283) | Total Time 0.00(0.00)\n",
      "Iter 14930 | Time 22.9594(23.5168) | Bit/dim 3.4123(3.4066) | Xent 0.0000(0.0000) | Loss 8.6511(9.2993) | Error 0.0000(0.0000) Steps 904(917.00) | Grad Norm 0.9274(0.8334) | Total Time 0.00(0.00)\n",
      "Iter 14940 | Time 23.2132(23.4826) | Bit/dim 3.4141(3.4054) | Xent 0.0000(0.0000) | Loss 8.7786(9.1449) | Error 0.0000(0.0000) Steps 928(917.27) | Grad Norm 1.1980(0.9061) | Total Time 0.00(0.00)\n",
      "Iter 14950 | Time 23.1398(23.4683) | Bit/dim 3.4080(3.4066) | Xent 0.0000(0.0000) | Loss 8.6513(9.0353) | Error 0.0000(0.0000) Steps 904(915.32) | Grad Norm 0.6399(0.9083) | Total Time 0.00(0.00)\n",
      "Iter 14960 | Time 24.7585(23.5385) | Bit/dim 3.4075(3.4070) | Xent 0.0000(0.0000) | Loss 8.6836(8.9536) | Error 0.0000(0.0000) Steps 976(918.76) | Grad Norm 0.8270(0.8808) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0272 | Time 108.2270, Epoch Time 1421.9109(1343.0645), Bit/dim 3.4138(best: 3.4117), Xent 0.0000, Loss 3.4138, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14970 | Time 23.1259(23.5392) | Bit/dim 3.4156(3.4086) | Xent 0.0000(0.0000) | Loss 8.7123(9.6323) | Error 0.0000(0.0000) Steps 892(918.22) | Grad Norm 0.8199(0.8596) | Total Time 0.00(0.00)\n",
      "Iter 14980 | Time 23.3892(23.5373) | Bit/dim 3.4037(3.4085) | Xent 0.0000(0.0000) | Loss 8.6779(9.3954) | Error 0.0000(0.0000) Steps 916(919.44) | Grad Norm 0.8647(0.8774) | Total Time 0.00(0.00)\n",
      "Iter 14990 | Time 24.4541(23.4171) | Bit/dim 3.3969(3.4079) | Xent 0.0000(0.0000) | Loss 8.6803(9.2153) | Error 0.0000(0.0000) Steps 916(918.59) | Grad Norm 0.9257(0.8892) | Total Time 0.00(0.00)\n",
      "Iter 15000 | Time 23.0612(23.4547) | Bit/dim 3.4391(3.4091) | Xent 0.0000(0.0000) | Loss 8.7018(9.0784) | Error 0.0000(0.0000) Steps 916(917.19) | Grad Norm 0.9134(0.8940) | Total Time 0.00(0.00)\n",
      "Iter 15010 | Time 23.0430(23.3496) | Bit/dim 3.4463(3.4078) | Xent 0.0000(0.0000) | Loss 8.7485(8.9721) | Error 0.0000(0.0000) Steps 874(909.98) | Grad Norm 1.0116(0.8915) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0273 | Time 104.8127, Epoch Time 1407.0394(1344.9838), Bit/dim 3.4130(best: 3.4117), Xent 0.0000, Loss 3.4130, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15020 | Time 23.3109(23.2883) | Bit/dim 3.4142(3.4099) | Xent 0.0000(0.0000) | Loss 8.6837(9.7513) | Error 0.0000(0.0000) Steps 910(907.62) | Grad Norm 0.5976(0.9134) | Total Time 0.00(0.00)\n",
      "Iter 15030 | Time 24.0980(23.2841) | Bit/dim 3.3939(3.4092) | Xent 0.0000(0.0000) | Loss 8.6535(9.4769) | Error 0.0000(0.0000) Steps 910(908.18) | Grad Norm 0.6504(0.9235) | Total Time 0.00(0.00)\n",
      "Iter 15040 | Time 23.1256(23.2600) | Bit/dim 3.4357(3.4087) | Xent 0.0000(0.0000) | Loss 8.6949(9.2693) | Error 0.0000(0.0000) Steps 928(906.68) | Grad Norm 0.7345(0.9075) | Total Time 0.00(0.00)\n",
      "Iter 15050 | Time 23.2676(23.2508) | Bit/dim 3.4129(3.4099) | Xent 0.0000(0.0000) | Loss 8.7827(9.1204) | Error 0.0000(0.0000) Steps 934(907.08) | Grad Norm 0.9704(0.8908) | Total Time 0.00(0.00)\n",
      "Iter 15060 | Time 23.1915(23.3035) | Bit/dim 3.3858(3.4074) | Xent 0.0000(0.0000) | Loss 8.6946(9.0050) | Error 0.0000(0.0000) Steps 922(909.44) | Grad Norm 1.4154(0.9109) | Total Time 0.00(0.00)\n",
      "Iter 15070 | Time 22.4271(23.2596) | Bit/dim 3.3976(3.4071) | Xent 0.0000(0.0000) | Loss 8.7082(8.9166) | Error 0.0000(0.0000) Steps 928(906.32) | Grad Norm 0.9622(0.9522) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0274 | Time 105.7711, Epoch Time 1402.1726(1346.6994), Bit/dim 3.4113(best: 3.4117), Xent 0.0000, Loss 3.4113, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15080 | Time 22.8270(23.1645) | Bit/dim 3.4231(3.4092) | Xent 0.0000(0.0000) | Loss 8.6877(9.6016) | Error 0.0000(0.0000) Steps 904(907.59) | Grad Norm 0.7054(0.9592) | Total Time 0.00(0.00)\n",
      "Iter 15090 | Time 22.7932(23.1770) | Bit/dim 3.3964(3.4100) | Xent 0.0000(0.0000) | Loss 8.7141(9.3734) | Error 0.0000(0.0000) Steps 910(908.48) | Grad Norm 0.6971(0.9058) | Total Time 0.00(0.00)\n",
      "Iter 15100 | Time 23.3981(23.1485) | Bit/dim 3.4210(3.4073) | Xent 0.0000(0.0000) | Loss 8.7584(9.1912) | Error 0.0000(0.0000) Steps 898(906.51) | Grad Norm 0.7486(0.8439) | Total Time 0.00(0.00)\n",
      "Iter 15110 | Time 23.1496(23.1510) | Bit/dim 3.4261(3.4064) | Xent 0.0000(0.0000) | Loss 8.7703(9.0547) | Error 0.0000(0.0000) Steps 910(903.67) | Grad Norm 0.8473(0.8251) | Total Time 0.00(0.00)\n",
      "Iter 15120 | Time 21.9957(23.1098) | Bit/dim 3.4014(3.4071) | Xent 0.0000(0.0000) | Loss 8.6934(8.9592) | Error 0.0000(0.0000) Steps 898(901.97) | Grad Norm 0.7143(0.8167) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0275 | Time 105.7506, Epoch Time 1392.5891(1348.0761), Bit/dim 3.4126(best: 3.4113), Xent 0.0000, Loss 3.4126, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15130 | Time 22.6950(23.1347) | Bit/dim 3.4110(3.4110) | Xent 0.0000(0.0000) | Loss 8.7416(9.7720) | Error 0.0000(0.0000) Steps 892(901.59) | Grad Norm 1.5876(0.8721) | Total Time 0.00(0.00)\n",
      "Iter 15140 | Time 23.0221(23.1637) | Bit/dim 3.4030(3.4105) | Xent 0.0000(0.0000) | Loss 8.6633(9.4941) | Error 0.0000(0.0000) Steps 940(904.77) | Grad Norm 0.7024(0.8607) | Total Time 0.00(0.00)\n",
      "Iter 15150 | Time 23.6327(23.1464) | Bit/dim 3.4078(3.4114) | Xent 0.0000(0.0000) | Loss 8.6626(9.2855) | Error 0.0000(0.0000) Steps 868(903.65) | Grad Norm 0.7359(0.8864) | Total Time 0.00(0.00)\n",
      "Iter 15160 | Time 23.2602(23.1275) | Bit/dim 3.3629(3.4090) | Xent 0.0000(0.0000) | Loss 8.5101(9.1338) | Error 0.0000(0.0000) Steps 886(905.35) | Grad Norm 0.7182(0.8931) | Total Time 0.00(0.00)\n",
      "Iter 15170 | Time 23.1732(23.1947) | Bit/dim 3.3760(3.4063) | Xent 0.0000(0.0000) | Loss 8.7857(9.0255) | Error 0.0000(0.0000) Steps 910(906.15) | Grad Norm 0.8274(0.8867) | Total Time 0.00(0.00)\n",
      "Iter 15180 | Time 23.1756(23.2871) | Bit/dim 3.3685(3.4083) | Xent 0.0000(0.0000) | Loss 8.5576(8.9374) | Error 0.0000(0.0000) Steps 946(910.03) | Grad Norm 0.8603(0.9066) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0276 | Time 107.2875, Epoch Time 1405.4826(1349.7983), Bit/dim 3.4093(best: 3.4113), Xent 0.0000, Loss 3.4093, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15190 | Time 21.7970(23.2645) | Bit/dim 3.3984(3.4069) | Xent 0.0000(0.0000) | Loss 8.6028(9.6097) | Error 0.0000(0.0000) Steps 874(906.17) | Grad Norm 0.7634(0.8912) | Total Time 0.00(0.00)\n",
      "Iter 15200 | Time 22.9971(23.2597) | Bit/dim 3.3748(3.4056) | Xent 0.0000(0.0000) | Loss 8.6499(9.3729) | Error 0.0000(0.0000) Steps 916(908.72) | Grad Norm 0.8057(0.8629) | Total Time 0.00(0.00)\n",
      "Iter 15210 | Time 23.1352(23.3301) | Bit/dim 3.4051(3.4073) | Xent 0.0000(0.0000) | Loss 8.7380(9.1979) | Error 0.0000(0.0000) Steps 928(907.37) | Grad Norm 1.1847(0.8819) | Total Time 0.00(0.00)\n",
      "Iter 15220 | Time 22.7831(23.3438) | Bit/dim 3.4069(3.4094) | Xent 0.0000(0.0000) | Loss 8.7093(9.0762) | Error 0.0000(0.0000) Steps 910(908.35) | Grad Norm 0.7162(0.8644) | Total Time 0.00(0.00)\n",
      "Iter 15230 | Time 23.7231(23.3535) | Bit/dim 3.4086(3.4078) | Xent 0.0000(0.0000) | Loss 8.7542(8.9813) | Error 0.0000(0.0000) Steps 928(908.22) | Grad Norm 0.8615(0.8905) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0277 | Time 106.9699, Epoch Time 1409.6693(1351.5945), Bit/dim 3.4135(best: 3.4093), Xent 0.0000, Loss 3.4135, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15240 | Time 22.8115(23.3511) | Bit/dim 3.3805(3.4091) | Xent 0.0000(0.0000) | Loss 8.7089(9.7685) | Error 0.0000(0.0000) Steps 904(910.12) | Grad Norm 0.7226(0.9234) | Total Time 0.00(0.00)\n",
      "Iter 15250 | Time 22.6697(23.2387) | Bit/dim 3.3663(3.4082) | Xent 0.0000(0.0000) | Loss 8.6733(9.4963) | Error 0.0000(0.0000) Steps 886(909.58) | Grad Norm 0.9417(0.9047) | Total Time 0.00(0.00)\n",
      "Iter 15260 | Time 23.8539(23.2684) | Bit/dim 3.4372(3.4081) | Xent 0.0000(0.0000) | Loss 8.7102(9.2909) | Error 0.0000(0.0000) Steps 874(910.36) | Grad Norm 0.7973(0.8849) | Total Time 0.00(0.00)\n",
      "Iter 15270 | Time 23.0658(23.2768) | Bit/dim 3.4003(3.4081) | Xent 0.0000(0.0000) | Loss 8.7014(9.1484) | Error 0.0000(0.0000) Steps 934(909.90) | Grad Norm 1.1287(0.9315) | Total Time 0.00(0.00)\n",
      "Iter 15280 | Time 22.6742(23.2184) | Bit/dim 3.3978(3.4061) | Xent 0.0000(0.0000) | Loss 8.6328(9.0289) | Error 0.0000(0.0000) Steps 910(909.42) | Grad Norm 1.1133(0.9566) | Total Time 0.00(0.00)\n",
      "Iter 15290 | Time 24.3464(23.2245) | Bit/dim 3.4135(3.4086) | Xent 0.0000(0.0000) | Loss 8.8855(8.9551) | Error 0.0000(0.0000) Steps 916(908.25) | Grad Norm 0.9080(0.9282) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0278 | Time 106.8488, Epoch Time 1400.0053(1353.0468), Bit/dim 3.4160(best: 3.4093), Xent 0.0000, Loss 3.4160, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15300 | Time 23.9955(23.3008) | Bit/dim 3.4062(3.4095) | Xent 0.0000(0.0000) | Loss 8.8335(9.6381) | Error 0.0000(0.0000) Steps 928(907.91) | Grad Norm 0.8259(0.9066) | Total Time 0.00(0.00)\n",
      "Iter 15310 | Time 22.7698(23.2730) | Bit/dim 3.3729(3.4061) | Xent 0.0000(0.0000) | Loss 8.4197(9.3776) | Error 0.0000(0.0000) Steps 916(909.46) | Grad Norm 0.6340(0.8582) | Total Time 0.00(0.00)\n",
      "Iter 15320 | Time 24.2198(23.2512) | Bit/dim 3.3831(3.4085) | Xent 0.0000(0.0000) | Loss 8.5838(9.1996) | Error 0.0000(0.0000) Steps 916(909.78) | Grad Norm 0.8321(0.8943) | Total Time 0.00(0.00)\n",
      "Iter 15330 | Time 22.9557(23.1498) | Bit/dim 3.4222(3.4090) | Xent 0.0000(0.0000) | Loss 8.8093(9.0811) | Error 0.0000(0.0000) Steps 922(910.30) | Grad Norm 0.8092(0.9265) | Total Time 0.00(0.00)\n",
      "Iter 15340 | Time 22.6023(23.1456) | Bit/dim 3.4272(3.4097) | Xent 0.0000(0.0000) | Loss 8.7976(8.9915) | Error 0.0000(0.0000) Steps 910(909.40) | Grad Norm 0.8266(0.9258) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0279 | Time 107.0805, Epoch Time 1400.5632(1354.4723), Bit/dim 3.4131(best: 3.4093), Xent 0.0000, Loss 3.4131, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15350 | Time 23.1658(23.1964) | Bit/dim 3.3780(3.4102) | Xent 0.0000(0.0000) | Loss 8.6247(9.7896) | Error 0.0000(0.0000) Steps 898(908.79) | Grad Norm 0.6840(0.8871) | Total Time 0.00(0.00)\n",
      "Iter 15360 | Time 23.4559(23.2023) | Bit/dim 3.4385(3.4099) | Xent 0.0000(0.0000) | Loss 8.8336(9.5188) | Error 0.0000(0.0000) Steps 922(908.71) | Grad Norm 1.1569(0.9426) | Total Time 0.00(0.00)\n",
      "Iter 15370 | Time 22.8549(23.2235) | Bit/dim 3.4358(3.4111) | Xent 0.0000(0.0000) | Loss 8.7769(9.3038) | Error 0.0000(0.0000) Steps 904(905.68) | Grad Norm 0.9220(0.9340) | Total Time 0.00(0.00)\n",
      "Iter 15380 | Time 23.3174(23.2029) | Bit/dim 3.3840(3.4085) | Xent 0.0000(0.0000) | Loss 8.8071(9.1454) | Error 0.0000(0.0000) Steps 898(904.47) | Grad Norm 0.8742(0.9198) | Total Time 0.00(0.00)\n",
      "Iter 15390 | Time 23.4007(23.0932) | Bit/dim 3.4015(3.4048) | Xent 0.0000(0.0000) | Loss 8.7256(9.0229) | Error 0.0000(0.0000) Steps 916(904.46) | Grad Norm 1.6459(0.9644) | Total Time 0.00(0.00)\n",
      "Iter 15400 | Time 22.6332(23.0635) | Bit/dim 3.3992(3.4056) | Xent 0.0000(0.0000) | Loss 8.7308(8.9376) | Error 0.0000(0.0000) Steps 886(903.93) | Grad Norm 1.1785(1.0088) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0280 | Time 106.4287, Epoch Time 1395.6931(1355.7089), Bit/dim 3.4105(best: 3.4093), Xent 0.0000, Loss 3.4105, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15410 | Time 23.3759(23.1188) | Bit/dim 3.3771(3.4037) | Xent 0.0000(0.0000) | Loss 8.7842(9.6311) | Error 0.0000(0.0000) Steps 898(905.89) | Grad Norm 0.8124(1.0192) | Total Time 0.00(0.00)\n",
      "Iter 15420 | Time 23.0629(23.1431) | Bit/dim 3.4238(3.4055) | Xent 0.0000(0.0000) | Loss 8.7056(9.3916) | Error 0.0000(0.0000) Steps 946(908.42) | Grad Norm 0.9705(1.0064) | Total Time 0.00(0.00)\n",
      "Iter 15430 | Time 23.5629(23.2354) | Bit/dim 3.4071(3.4071) | Xent 0.0000(0.0000) | Loss 8.5764(9.2108) | Error 0.0000(0.0000) Steps 880(909.46) | Grad Norm 0.9062(1.0248) | Total Time 0.00(0.00)\n",
      "Iter 15440 | Time 24.4663(23.2213) | Bit/dim 3.4160(3.4075) | Xent 0.0000(0.0000) | Loss 8.8077(9.0740) | Error 0.0000(0.0000) Steps 958(911.98) | Grad Norm 0.7648(0.9972) | Total Time 0.00(0.00)\n",
      "Iter 15450 | Time 22.6007(23.2284) | Bit/dim 3.3909(3.4079) | Xent 0.0000(0.0000) | Loss 8.7614(8.9853) | Error 0.0000(0.0000) Steps 892(913.42) | Grad Norm 0.6857(0.9628) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0281 | Time 106.9781, Epoch Time 1405.2608(1357.1955), Bit/dim 3.4136(best: 3.4093), Xent 0.0000, Loss 3.4136, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15460 | Time 23.2974(23.2381) | Bit/dim 3.4257(3.4076) | Xent 0.0000(0.0000) | Loss 8.6898(9.7877) | Error 0.0000(0.0000) Steps 922(913.35) | Grad Norm 0.7490(0.9590) | Total Time 0.00(0.00)\n",
      "Iter 15470 | Time 23.2128(23.3045) | Bit/dim 3.4316(3.4089) | Xent 0.0000(0.0000) | Loss 8.7733(9.5141) | Error 0.0000(0.0000) Steps 916(913.35) | Grad Norm 0.9534(0.9628) | Total Time 0.00(0.00)\n",
      "Iter 15480 | Time 22.8700(23.2765) | Bit/dim 3.3979(3.4088) | Xent 0.0000(0.0000) | Loss 8.6959(9.3151) | Error 0.0000(0.0000) Steps 910(913.86) | Grad Norm 1.4466(0.9949) | Total Time 0.00(0.00)\n",
      "Iter 15490 | Time 24.0563(23.3089) | Bit/dim 3.4361(3.4082) | Xent 0.0000(0.0000) | Loss 8.8543(9.1592) | Error 0.0000(0.0000) Steps 910(913.86) | Grad Norm 1.5415(0.9969) | Total Time 0.00(0.00)\n",
      "Iter 15500 | Time 23.3153(23.2079) | Bit/dim 3.3993(3.4077) | Xent 0.0000(0.0000) | Loss 8.6005(9.0398) | Error 0.0000(0.0000) Steps 910(910.84) | Grad Norm 1.0046(1.0062) | Total Time 0.00(0.00)\n",
      "Iter 15510 | Time 23.0617(23.2146) | Bit/dim 3.3972(3.4089) | Xent 0.0000(0.0000) | Loss 8.7244(8.9536) | Error 0.0000(0.0000) Steps 898(908.29) | Grad Norm 1.9079(1.0632) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0282 | Time 106.0909, Epoch Time 1403.0671(1358.5716), Bit/dim 3.4120(best: 3.4093), Xent 0.0000, Loss 3.4120, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15520 | Time 23.7350(23.1697) | Bit/dim 3.4041(3.4095) | Xent 0.0000(0.0000) | Loss 8.7372(9.6309) | Error 0.0000(0.0000) Steps 940(909.31) | Grad Norm 0.9044(1.0802) | Total Time 0.00(0.00)\n",
      "Iter 15530 | Time 22.7099(23.1835) | Bit/dim 3.3799(3.4057) | Xent 0.0000(0.0000) | Loss 8.6298(9.3850) | Error 0.0000(0.0000) Steps 904(912.47) | Grad Norm 0.7384(1.0686) | Total Time 0.00(0.00)\n",
      "Iter 15540 | Time 24.3776(23.2918) | Bit/dim 3.4291(3.4060) | Xent 0.0000(0.0000) | Loss 8.9182(9.2194) | Error 0.0000(0.0000) Steps 970(915.63) | Grad Norm 1.5561(1.0893) | Total Time 0.00(0.00)\n",
      "Iter 15550 | Time 24.2404(23.4115) | Bit/dim 3.3946(3.4087) | Xent 0.0000(0.0000) | Loss 8.8206(9.1038) | Error 0.0000(0.0000) Steps 922(918.92) | Grad Norm 1.0083(1.0887) | Total Time 0.00(0.00)\n",
      "Iter 15560 | Time 24.3206(23.4946) | Bit/dim 3.4189(3.4099) | Xent 0.0000(0.0000) | Loss 8.6700(9.0146) | Error 0.0000(0.0000) Steps 982(923.20) | Grad Norm 0.9683(1.1279) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0283 | Time 108.5565, Epoch Time 1415.7128(1360.2858), Bit/dim 3.4120(best: 3.4093), Xent 0.0000, Loss 3.4120, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15570 | Time 23.1333(23.4891) | Bit/dim 3.4197(3.4131) | Xent 0.0000(0.0000) | Loss 8.7696(9.8837) | Error 0.0000(0.0000) Steps 916(925.17) | Grad Norm 1.5562(1.1304) | Total Time 0.00(0.00)\n",
      "Iter 15580 | Time 24.7371(23.5954) | Bit/dim 3.4071(3.4073) | Xent 0.0000(0.0000) | Loss 8.8445(9.5835) | Error 0.0000(0.0000) Steps 988(929.04) | Grad Norm 1.2587(1.1554) | Total Time 0.00(0.00)\n",
      "Iter 15590 | Time 23.0485(23.6143) | Bit/dim 3.4143(3.4063) | Xent 0.0000(0.0000) | Loss 8.7750(9.3757) | Error 0.0000(0.0000) Steps 916(930.27) | Grad Norm 0.9182(1.1449) | Total Time 0.00(0.00)\n",
      "Iter 15600 | Time 23.0469(23.5743) | Bit/dim 3.4114(3.4062) | Xent 0.0000(0.0000) | Loss 8.7539(9.2097) | Error 0.0000(0.0000) Steps 910(928.07) | Grad Norm 0.7411(1.0479) | Total Time 0.00(0.00)\n",
      "Iter 15610 | Time 24.3789(23.5761) | Bit/dim 3.4205(3.4073) | Xent 0.0000(0.0000) | Loss 8.8443(9.0901) | Error 0.0000(0.0000) Steps 958(928.60) | Grad Norm 1.1758(1.0626) | Total Time 0.00(0.00)\n",
      "Iter 15620 | Time 24.1373(23.6062) | Bit/dim 3.4252(3.4077) | Xent 0.0000(0.0000) | Loss 8.7647(8.9933) | Error 0.0000(0.0000) Steps 928(928.86) | Grad Norm 1.2878(1.1253) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0284 | Time 108.1504, Epoch Time 1427.9224(1362.3149), Bit/dim 3.4159(best: 3.4093), Xent 0.0000, Loss 3.4159, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15630 | Time 23.8321(23.5949) | Bit/dim 3.4051(3.4084) | Xent 0.0000(0.0000) | Loss 8.7665(9.7312) | Error 0.0000(0.0000) Steps 946(929.00) | Grad Norm 1.3346(1.1632) | Total Time 0.00(0.00)\n",
      "Iter 15640 | Time 24.5388(23.6275) | Bit/dim 3.4346(3.4084) | Xent 0.0000(0.0000) | Loss 8.8399(9.4758) | Error 0.0000(0.0000) Steps 970(930.63) | Grad Norm 1.1767(1.1546) | Total Time 0.00(0.00)\n",
      "Iter 15650 | Time 23.5483(23.5544) | Bit/dim 3.3920(3.4099) | Xent 0.0000(0.0000) | Loss 8.6443(9.2808) | Error 0.0000(0.0000) Steps 934(927.61) | Grad Norm 0.8872(1.1411) | Total Time 0.00(0.00)\n",
      "Iter 15660 | Time 24.4413(23.6851) | Bit/dim 3.3948(3.4081) | Xent 0.0000(0.0000) | Loss 8.7770(9.1368) | Error 0.0000(0.0000) Steps 940(928.66) | Grad Norm 1.0418(1.0883) | Total Time 0.00(0.00)\n",
      "Iter 15670 | Time 22.7631(23.6889) | Bit/dim 3.4147(3.4081) | Xent 0.0000(0.0000) | Loss 8.7190(9.0383) | Error 0.0000(0.0000) Steps 910(926.38) | Grad Norm 1.0795(1.1017) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0285 | Time 108.2499, Epoch Time 1429.1080(1364.3187), Bit/dim 3.4121(best: 3.4093), Xent 0.0000, Loss 3.4121, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15680 | Time 23.6203(23.6474) | Bit/dim 3.4141(3.4068) | Xent 0.0000(0.0000) | Loss 8.7913(9.8468) | Error 0.0000(0.0000) Steps 898(923.83) | Grad Norm 0.9525(1.1052) | Total Time 0.00(0.00)\n",
      "Iter 15690 | Time 23.9826(23.6444) | Bit/dim 3.4258(3.4075) | Xent 0.0000(0.0000) | Loss 8.7657(9.5680) | Error 0.0000(0.0000) Steps 934(924.59) | Grad Norm 1.3064(1.1198) | Total Time 0.00(0.00)\n",
      "Iter 15700 | Time 22.7882(23.6533) | Bit/dim 3.3912(3.4079) | Xent 0.0000(0.0000) | Loss 8.6313(9.3577) | Error 0.0000(0.0000) Steps 946(926.32) | Grad Norm 1.3163(1.1120) | Total Time 0.00(0.00)\n",
      "Iter 15710 | Time 25.4377(23.8259) | Bit/dim 3.3801(3.4064) | Xent 0.0000(0.0000) | Loss 8.7725(9.1992) | Error 0.0000(0.0000) Steps 982(932.03) | Grad Norm 1.0444(1.0998) | Total Time 0.00(0.00)\n",
      "Iter 15720 | Time 23.6850(23.8109) | Bit/dim 3.4243(3.4052) | Xent 0.0000(0.0000) | Loss 8.8630(9.0849) | Error 0.0000(0.0000) Steps 934(933.42) | Grad Norm 1.5007(1.0941) | Total Time 0.00(0.00)\n",
      "Iter 15730 | Time 23.3897(23.8073) | Bit/dim 3.4286(3.4068) | Xent 0.0000(0.0000) | Loss 8.9006(9.0055) | Error 0.0000(0.0000) Steps 940(933.07) | Grad Norm 1.0953(1.1105) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0286 | Time 108.2520, Epoch Time 1435.1672(1366.4442), Bit/dim 3.4144(best: 3.4093), Xent 0.0000, Loss 3.4144, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15740 | Time 24.3559(23.8169) | Bit/dim 3.4018(3.4045) | Xent 0.0000(0.0000) | Loss 8.7112(9.7309) | Error 0.0000(0.0000) Steps 910(935.07) | Grad Norm 1.2649(1.1237) | Total Time 0.00(0.00)\n",
      "Iter 15750 | Time 24.9542(23.8263) | Bit/dim 3.4038(3.4048) | Xent 0.0000(0.0000) | Loss 8.8928(9.4748) | Error 0.0000(0.0000) Steps 952(936.02) | Grad Norm 1.0730(1.1090) | Total Time 0.00(0.00)\n",
      "Iter 15760 | Time 23.7005(23.8254) | Bit/dim 3.4008(3.4051) | Xent 0.0000(0.0000) | Loss 8.8424(9.2904) | Error 0.0000(0.0000) Steps 976(942.26) | Grad Norm 2.0450(1.1567) | Total Time 0.00(0.00)\n",
      "Iter 15770 | Time 24.1377(23.7761) | Bit/dim 3.4267(3.4068) | Xent 0.0000(0.0000) | Loss 8.6939(9.1537) | Error 0.0000(0.0000) Steps 946(941.66) | Grad Norm 1.0512(1.1991) | Total Time 0.00(0.00)\n",
      "Iter 15780 | Time 23.1512(23.6660) | Bit/dim 3.4372(3.4055) | Xent 0.0000(0.0000) | Loss 8.7784(9.0427) | Error 0.0000(0.0000) Steps 922(941.99) | Grad Norm 1.4588(1.2608) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0287 | Time 110.0361, Epoch Time 1432.8109(1368.4352), Bit/dim 3.4119(best: 3.4093), Xent 0.0000, Loss 3.4119, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15790 | Time 23.7094(23.7425) | Bit/dim 3.3677(3.4066) | Xent 0.0000(0.0000) | Loss 8.5875(9.8988) | Error 0.0000(0.0000) Steps 916(941.09) | Grad Norm 0.9878(1.2807) | Total Time 0.00(0.00)\n",
      "Iter 15800 | Time 23.6223(23.8241) | Bit/dim 3.3891(3.4054) | Xent 0.0000(0.0000) | Loss 8.7690(9.6328) | Error 0.0000(0.0000) Steps 976(947.14) | Grad Norm 1.3172(1.2953) | Total Time 0.00(0.00)\n",
      "Iter 15810 | Time 24.9928(23.8965) | Bit/dim 3.4222(3.4066) | Xent 0.0000(0.0000) | Loss 8.9500(9.4176) | Error 0.0000(0.0000) Steps 994(952.04) | Grad Norm 1.2447(1.2955) | Total Time 0.00(0.00)\n",
      "Iter 15820 | Time 24.2893(24.0518) | Bit/dim 3.4242(3.4086) | Xent 0.0000(0.0000) | Loss 8.7531(9.2709) | Error 0.0000(0.0000) Steps 988(956.21) | Grad Norm 1.3116(1.3194) | Total Time 0.00(0.00)\n",
      "Iter 15830 | Time 23.7196(24.0575) | Bit/dim 3.3953(3.4081) | Xent 0.0000(0.0000) | Loss 8.7150(9.1378) | Error 0.0000(0.0000) Steps 940(955.59) | Grad Norm 0.9544(1.2762) | Total Time 0.00(0.00)\n",
      "Iter 15840 | Time 24.1701(24.0934) | Bit/dim 3.3954(3.4062) | Xent 0.0000(0.0000) | Loss 8.8206(9.0343) | Error 0.0000(0.0000) Steps 928(953.19) | Grad Norm 1.0148(1.3184) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0288 | Time 110.6821, Epoch Time 1458.1854(1371.1277), Bit/dim 3.4140(best: 3.4093), Xent 0.0000, Loss 3.4140, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15850 | Time 24.0680(24.1184) | Bit/dim 3.3832(3.4058) | Xent 0.0000(0.0000) | Loss 8.6020(9.7688) | Error 0.0000(0.0000) Steps 928(951.52) | Grad Norm 1.2653(1.2807) | Total Time 0.00(0.00)\n",
      "Iter 15860 | Time 23.6984(24.1379) | Bit/dim 3.4022(3.4069) | Xent 0.0000(0.0000) | Loss 8.7698(9.5080) | Error 0.0000(0.0000) Steps 916(950.09) | Grad Norm 1.1830(1.2350) | Total Time 0.00(0.00)\n",
      "Iter 15870 | Time 23.9947(24.2138) | Bit/dim 3.4344(3.4079) | Xent 0.0000(0.0000) | Loss 8.8443(9.3164) | Error 0.0000(0.0000) Steps 964(949.22) | Grad Norm 0.8338(1.1892) | Total Time 0.00(0.00)\n",
      "Iter 15880 | Time 24.2536(24.2459) | Bit/dim 3.4009(3.4061) | Xent 0.0000(0.0000) | Loss 8.8158(9.1734) | Error 0.0000(0.0000) Steps 976(947.82) | Grad Norm 1.0338(1.1706) | Total Time 0.00(0.00)\n",
      "Iter 15890 | Time 24.0208(24.2212) | Bit/dim 3.4088(3.4053) | Xent 0.0000(0.0000) | Loss 8.7342(9.0535) | Error 0.0000(0.0000) Steps 958(949.48) | Grad Norm 0.9598(1.1353) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0289 | Time 109.3582, Epoch Time 1460.8130(1373.8183), Bit/dim 3.4107(best: 3.4093), Xent 0.0000, Loss 3.4107, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15900 | Time 23.8193(24.2039) | Bit/dim 3.3962(3.4068) | Xent 0.0000(0.0000) | Loss 8.6762(9.9527) | Error 0.0000(0.0000) Steps 934(949.14) | Grad Norm 0.8668(1.1135) | Total Time 0.00(0.00)\n",
      "Iter 15910 | Time 24.4623(24.1452) | Bit/dim 3.4182(3.4104) | Xent 0.0000(0.0000) | Loss 8.8211(9.6382) | Error 0.0000(0.0000) Steps 958(949.94) | Grad Norm 1.2435(1.1457) | Total Time 0.00(0.00)\n",
      "Iter 15920 | Time 23.8832(24.0405) | Bit/dim 3.3855(3.4068) | Xent 0.0000(0.0000) | Loss 8.7166(9.4065) | Error 0.0000(0.0000) Steps 916(945.89) | Grad Norm 1.7525(1.2102) | Total Time 0.00(0.00)\n",
      "Iter 15930 | Time 22.9051(24.0732) | Bit/dim 3.3891(3.4056) | Xent 0.0000(0.0000) | Loss 8.7070(9.2386) | Error 0.0000(0.0000) Steps 934(948.22) | Grad Norm 1.0062(1.2210) | Total Time 0.00(0.00)\n",
      "Iter 15940 | Time 24.8828(24.0213) | Bit/dim 3.4184(3.4095) | Xent 0.0000(0.0000) | Loss 8.8418(9.1218) | Error 0.0000(0.0000) Steps 916(947.17) | Grad Norm 0.8720(1.1376) | Total Time 0.00(0.00)\n",
      "Iter 15950 | Time 24.6179(24.0797) | Bit/dim 3.3734(3.4062) | Xent 0.0000(0.0000) | Loss 8.6379(9.0203) | Error 0.0000(0.0000) Steps 970(947.90) | Grad Norm 1.3354(1.1673) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0290 | Time 108.6460, Epoch Time 1448.0042(1376.0438), Bit/dim 3.4145(best: 3.4093), Xent 0.0000, Loss 3.4145, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15960 | Time 23.8548(24.0759) | Bit/dim 3.4133(3.4064) | Xent 0.0000(0.0000) | Loss 8.8589(9.7650) | Error 0.0000(0.0000) Steps 940(948.19) | Grad Norm 1.0214(1.1811) | Total Time 0.00(0.00)\n",
      "Iter 15970 | Time 24.1854(24.0784) | Bit/dim 3.3908(3.4058) | Xent 0.0000(0.0000) | Loss 8.7202(9.4976) | Error 0.0000(0.0000) Steps 952(947.73) | Grad Norm 0.6735(1.1296) | Total Time 0.00(0.00)\n",
      "Iter 15980 | Time 23.1051(24.1998) | Bit/dim 3.4170(3.4091) | Xent 0.0000(0.0000) | Loss 8.6219(9.3150) | Error 0.0000(0.0000) Steps 934(946.50) | Grad Norm 1.0784(1.1330) | Total Time 0.00(0.00)\n",
      "Iter 15990 | Time 24.8053(24.2919) | Bit/dim 3.4362(3.4073) | Xent 0.0000(0.0000) | Loss 8.7149(9.1708) | Error 0.0000(0.0000) Steps 940(948.61) | Grad Norm 0.9719(1.1458) | Total Time 0.00(0.00)\n",
      "Iter 16000 | Time 24.1056(24.2370) | Bit/dim 3.3894(3.4054) | Xent 0.0000(0.0000) | Loss 8.7442(9.0587) | Error 0.0000(0.0000) Steps 958(949.48) | Grad Norm 0.9996(1.1454) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0291 | Time 109.5047, Epoch Time 1461.6970(1378.6134), Bit/dim 3.4126(best: 3.4093), Xent 0.0000, Loss 3.4126, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16010 | Time 24.3114(24.2749) | Bit/dim 3.4271(3.4072) | Xent 0.0000(0.0000) | Loss 8.8473(9.9542) | Error 0.0000(0.0000) Steps 928(951.34) | Grad Norm 1.1137(1.1815) | Total Time 0.00(0.00)\n",
      "Iter 16020 | Time 23.9810(24.2977) | Bit/dim 3.4332(3.4073) | Xent 0.0000(0.0000) | Loss 8.8572(9.6509) | Error 0.0000(0.0000) Steps 946(953.18) | Grad Norm 1.1402(1.2223) | Total Time 0.00(0.00)\n",
      "Iter 16030 | Time 23.7525(24.2706) | Bit/dim 3.3774(3.4075) | Xent 0.0000(0.0000) | Loss 8.7124(9.4126) | Error 0.0000(0.0000) Steps 916(950.19) | Grad Norm 1.6257(1.2822) | Total Time 0.00(0.00)\n",
      "Iter 16040 | Time 24.2424(24.2205) | Bit/dim 3.3961(3.4058) | Xent 0.0000(0.0000) | Loss 8.6497(9.2391) | Error 0.0000(0.0000) Steps 934(950.24) | Grad Norm 0.8412(1.3374) | Total Time 0.00(0.00)\n",
      "Iter 16050 | Time 24.2810(24.1638) | Bit/dim 3.4140(3.4068) | Xent 0.0000(0.0000) | Loss 8.7652(9.1228) | Error 0.0000(0.0000) Steps 940(952.55) | Grad Norm 2.2363(1.3844) | Total Time 0.00(0.00)\n",
      "Iter 16060 | Time 24.8017(24.2248) | Bit/dim 3.4365(3.4067) | Xent 0.0000(0.0000) | Loss 8.8246(9.0326) | Error 0.0000(0.0000) Steps 958(950.36) | Grad Norm 1.3392(1.5196) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0292 | Time 109.1302, Epoch Time 1460.8083(1381.0793), Bit/dim 3.4108(best: 3.4093), Xent 0.0000, Loss 3.4108, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16070 | Time 25.1562(24.3586) | Bit/dim 3.4066(3.4072) | Xent 0.0000(0.0000) | Loss 8.8129(9.7833) | Error 0.0000(0.0000) Steps 928(949.91) | Grad Norm 1.8694(1.5728) | Total Time 0.00(0.00)\n",
      "Iter 16080 | Time 23.8570(24.3100) | Bit/dim 3.3643(3.4048) | Xent 0.0000(0.0000) | Loss 8.7193(9.5143) | Error 0.0000(0.0000) Steps 964(949.66) | Grad Norm 0.8041(1.4537) | Total Time 0.00(0.00)\n",
      "Iter 16090 | Time 24.1228(24.3014) | Bit/dim 3.4160(3.4060) | Xent 0.0000(0.0000) | Loss 8.7330(9.3184) | Error 0.0000(0.0000) Steps 916(946.67) | Grad Norm 2.1361(1.4126) | Total Time 0.00(0.00)\n",
      "Iter 16100 | Time 25.2027(24.3036) | Bit/dim 3.3929(3.4051) | Xent 0.0000(0.0000) | Loss 8.7771(9.1714) | Error 0.0000(0.0000) Steps 964(948.55) | Grad Norm 1.2579(1.3908) | Total Time 0.00(0.00)\n",
      "Iter 16110 | Time 23.5505(24.1570) | Bit/dim 3.3860(3.4067) | Xent 0.0000(0.0000) | Loss 8.5610(9.0684) | Error 0.0000(0.0000) Steps 934(949.31) | Grad Norm 1.5057(1.3551) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0293 | Time 109.6738, Epoch Time 1464.3632(1383.5778), Bit/dim 3.4123(best: 3.4093), Xent 0.0000, Loss 3.4123, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16120 | Time 23.6451(24.2398) | Bit/dim 3.4305(3.4074) | Xent 0.0000(0.0000) | Loss 8.7002(9.9350) | Error 0.0000(0.0000) Steps 910(946.48) | Grad Norm 1.0436(1.3505) | Total Time 0.00(0.00)\n",
      "Iter 16130 | Time 23.4436(24.2481) | Bit/dim 3.4013(3.4070) | Xent 0.0000(0.0000) | Loss 8.7766(9.6328) | Error 0.0000(0.0000) Steps 940(946.44) | Grad Norm 0.9432(1.3174) | Total Time 0.00(0.00)\n",
      "Iter 16140 | Time 24.0914(24.2240) | Bit/dim 3.4549(3.4084) | Xent 0.0000(0.0000) | Loss 8.8727(9.4029) | Error 0.0000(0.0000) Steps 922(944.78) | Grad Norm 0.8868(1.2550) | Total Time 0.00(0.00)\n",
      "Iter 16150 | Time 23.8267(24.0947) | Bit/dim 3.4025(3.4062) | Xent 0.0000(0.0000) | Loss 8.7870(9.2250) | Error 0.0000(0.0000) Steps 940(943.94) | Grad Norm 1.6120(1.2067) | Total Time 0.00(0.00)\n",
      "Iter 16160 | Time 23.6756(23.9926) | Bit/dim 3.3814(3.4047) | Xent 0.0000(0.0000) | Loss 8.6988(9.0925) | Error 0.0000(0.0000) Steps 922(940.00) | Grad Norm 1.8837(1.2756) | Total Time 0.00(0.00)\n",
      "Iter 16170 | Time 24.2171(24.0261) | Bit/dim 3.4078(3.4056) | Xent 0.0000(0.0000) | Loss 8.7249(9.0097) | Error 0.0000(0.0000) Steps 958(941.63) | Grad Norm 1.2521(1.3412) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0294 | Time 108.6647, Epoch Time 1447.4300(1385.4934), Bit/dim 3.4120(best: 3.4093), Xent 0.0000, Loss 3.4120, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16180 | Time 24.7491(24.0764) | Bit/dim 3.4197(3.4035) | Xent 0.0000(0.0000) | Loss 8.9357(9.7306) | Error 0.0000(0.0000) Steps 952(942.93) | Grad Norm 1.9409(1.4339) | Total Time 0.00(0.00)\n",
      "Iter 16190 | Time 23.3596(23.9979) | Bit/dim 3.4512(3.4063) | Xent 0.0000(0.0000) | Loss 8.8434(9.4674) | Error 0.0000(0.0000) Steps 940(941.01) | Grad Norm 2.1358(1.5481) | Total Time 0.00(0.00)\n",
      "Iter 16200 | Time 23.8317(23.9880) | Bit/dim 3.3945(3.4048) | Xent 0.0000(0.0000) | Loss 8.8050(9.2782) | Error 0.0000(0.0000) Steps 964(941.29) | Grad Norm 0.9419(1.5510) | Total Time 0.00(0.00)\n",
      "Iter 16210 | Time 25.2649(24.0732) | Bit/dim 3.4320(3.4044) | Xent 0.0000(0.0000) | Loss 8.8866(9.1496) | Error 0.0000(0.0000) Steps 958(945.56) | Grad Norm 1.0040(1.5746) | Total Time 0.00(0.00)\n",
      "Iter 16220 | Time 23.8657(24.0373) | Bit/dim 3.4117(3.4043) | Xent 0.0000(0.0000) | Loss 8.6561(9.0467) | Error 0.0000(0.0000) Steps 946(944.12) | Grad Norm 1.1444(1.5170) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0295 | Time 110.6852, Epoch Time 1449.3794(1387.4099), Bit/dim 3.4124(best: 3.4093), Xent 0.0000, Loss 3.4124, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16230 | Time 24.7120(24.0673) | Bit/dim 3.4558(3.4071) | Xent 0.0000(0.0000) | Loss 8.8480(9.8959) | Error 0.0000(0.0000) Steps 922(947.13) | Grad Norm 0.9094(1.5085) | Total Time 0.00(0.00)\n",
      "Iter 16240 | Time 23.3971(23.9655) | Bit/dim 3.3692(3.4061) | Xent 0.0000(0.0000) | Loss 8.6880(9.5821) | Error 0.0000(0.0000) Steps 952(945.59) | Grad Norm 1.5841(1.4972) | Total Time 0.00(0.00)\n",
      "Iter 16250 | Time 24.7657(24.0246) | Bit/dim 3.3835(3.4056) | Xent 0.0000(0.0000) | Loss 8.7753(9.3674) | Error 0.0000(0.0000) Steps 976(945.15) | Grad Norm 2.7910(1.5308) | Total Time 0.00(0.00)\n",
      "Iter 16260 | Time 23.8524(23.9872) | Bit/dim 3.3863(3.4051) | Xent 0.0000(0.0000) | Loss 8.6477(9.2012) | Error 0.0000(0.0000) Steps 940(942.99) | Grad Norm 1.5950(1.5714) | Total Time 0.00(0.00)\n",
      "Iter 16270 | Time 23.9987(24.0380) | Bit/dim 3.4422(3.4054) | Xent 0.0000(0.0000) | Loss 8.8524(9.0885) | Error 0.0000(0.0000) Steps 928(940.25) | Grad Norm 2.0056(1.6358) | Total Time 0.00(0.00)\n",
      "Iter 16280 | Time 24.1302(24.0810) | Bit/dim 3.3985(3.4065) | Xent 0.0000(0.0000) | Loss 8.8070(9.0039) | Error 0.0000(0.0000) Steps 940(941.79) | Grad Norm 2.3183(1.6303) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0296 | Time 108.4060, Epoch Time 1451.2094(1389.3239), Bit/dim 3.4135(best: 3.4093), Xent 0.0000, Loss 3.4135, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16290 | Time 25.0223(24.0733) | Bit/dim 3.3570(3.4066) | Xent 0.0000(0.0000) | Loss 8.6654(9.7243) | Error 0.0000(0.0000) Steps 964(942.65) | Grad Norm 1.1811(1.6615) | Total Time 0.00(0.00)\n",
      "Iter 16300 | Time 23.9653(24.0783) | Bit/dim 3.3934(3.4040) | Xent 0.0000(0.0000) | Loss 8.8469(9.4540) | Error 0.0000(0.0000) Steps 952(942.47) | Grad Norm 0.9531(1.5518) | Total Time 0.00(0.00)\n",
      "Iter 16310 | Time 23.7712(24.1211) | Bit/dim 3.4189(3.4071) | Xent 0.0000(0.0000) | Loss 8.7517(9.2734) | Error 0.0000(0.0000) Steps 934(944.51) | Grad Norm 1.2951(1.5137) | Total Time 0.00(0.00)\n",
      "Iter 16320 | Time 24.2639(24.1286) | Bit/dim 3.3731(3.4069) | Xent 0.0000(0.0000) | Loss 8.6703(9.1275) | Error 0.0000(0.0000) Steps 946(945.02) | Grad Norm 1.2869(1.5011) | Total Time 0.00(0.00)\n",
      "Iter 16330 | Time 24.7937(24.1187) | Bit/dim 3.4101(3.4061) | Xent 0.0000(0.0000) | Loss 8.9118(9.0200) | Error 0.0000(0.0000) Steps 958(943.97) | Grad Norm 1.0315(1.3984) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0297 | Time 108.7460, Epoch Time 1453.6491(1391.2537), Bit/dim 3.4106(best: 3.4093), Xent 0.0000, Loss 3.4106, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16340 | Time 25.0703(24.1025) | Bit/dim 3.3930(3.4050) | Xent 0.0000(0.0000) | Loss 8.7404(9.8811) | Error 0.0000(0.0000) Steps 952(940.86) | Grad Norm 0.9325(1.3488) | Total Time 0.00(0.00)\n",
      "Iter 16350 | Time 24.3238(24.1304) | Bit/dim 3.3779(3.4048) | Xent 0.0000(0.0000) | Loss 8.6842(9.5797) | Error 0.0000(0.0000) Steps 982(943.68) | Grad Norm 1.8186(1.5142) | Total Time 0.00(0.00)\n",
      "Iter 16360 | Time 24.5427(24.0604) | Bit/dim 3.4085(3.4068) | Xent 0.0000(0.0000) | Loss 8.7661(9.3663) | Error 0.0000(0.0000) Steps 946(943.04) | Grad Norm 1.4534(1.5202) | Total Time 0.00(0.00)\n",
      "Iter 16370 | Time 24.2607(24.1235) | Bit/dim 3.3961(3.4053) | Xent 0.0000(0.0000) | Loss 8.6486(9.2061) | Error 0.0000(0.0000) Steps 964(945.99) | Grad Norm 2.2837(1.5168) | Total Time 0.00(0.00)\n",
      "Iter 16380 | Time 22.8810(24.1008) | Bit/dim 3.3748(3.4058) | Xent 0.0000(0.0000) | Loss 8.6755(9.0862) | Error 0.0000(0.0000) Steps 940(947.20) | Grad Norm 2.6271(1.6131) | Total Time 0.00(0.00)\n",
      "Iter 16390 | Time 24.7062(24.0035) | Bit/dim 3.3688(3.4044) | Xent 0.0000(0.0000) | Loss 8.6788(8.9950) | Error 0.0000(0.0000) Steps 928(944.30) | Grad Norm 3.0960(1.7701) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0298 | Time 108.8765, Epoch Time 1448.7514(1392.9786), Bit/dim 3.4126(best: 3.4093), Xent 0.0000, Loss 3.4126, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16400 | Time 24.1208(24.0357) | Bit/dim 3.4073(3.4048) | Xent 0.0000(0.0000) | Loss 8.7812(9.7270) | Error 0.0000(0.0000) Steps 970(944.89) | Grad Norm 1.4604(1.7027) | Total Time 0.00(0.00)\n",
      "Iter 16410 | Time 24.1040(24.0411) | Bit/dim 3.3696(3.4074) | Xent 0.0000(0.0000) | Loss 8.6847(9.4705) | Error 0.0000(0.0000) Steps 946(944.89) | Grad Norm 1.5756(1.6505) | Total Time 0.00(0.00)\n",
      "Iter 16420 | Time 24.3684(24.1151) | Bit/dim 3.3761(3.4064) | Xent 0.0000(0.0000) | Loss 8.7212(9.2969) | Error 0.0000(0.0000) Steps 934(947.91) | Grad Norm 1.4924(1.8103) | Total Time 0.00(0.00)\n",
      "Iter 16430 | Time 24.8288(24.1626) | Bit/dim 3.3561(3.4049) | Xent 0.0000(0.0000) | Loss 8.7355(9.1473) | Error 0.0000(0.0000) Steps 952(950.57) | Grad Norm 1.2871(1.7160) | Total Time 0.00(0.00)\n",
      "Iter 16440 | Time 24.4675(24.1937) | Bit/dim 3.3676(3.4037) | Xent 0.0000(0.0000) | Loss 8.6685(9.0540) | Error 0.0000(0.0000) Steps 940(952.97) | Grad Norm 1.1453(1.6188) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0299 | Time 110.1354, Epoch Time 1459.6683(1394.9793), Bit/dim 3.4111(best: 3.4093), Xent 0.0000, Loss 3.4111, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16450 | Time 23.9672(24.1974) | Bit/dim 3.4006(3.4053) | Xent 0.0000(0.0000) | Loss 8.7519(9.9352) | Error 0.0000(0.0000) Steps 946(955.03) | Grad Norm 1.4191(1.5491) | Total Time 0.00(0.00)\n",
      "Iter 16460 | Time 24.8752(24.2613) | Bit/dim 3.4005(3.4072) | Xent 0.0000(0.0000) | Loss 8.7448(9.6201) | Error 0.0000(0.0000) Steps 946(953.08) | Grad Norm 1.1822(1.4878) | Total Time 0.00(0.00)\n",
      "Iter 16470 | Time 25.1507(24.3427) | Bit/dim 3.3765(3.4049) | Xent 0.0000(0.0000) | Loss 8.6533(9.3908) | Error 0.0000(0.0000) Steps 964(957.11) | Grad Norm 1.6275(1.4622) | Total Time 0.00(0.00)\n",
      "Iter 16480 | Time 25.6146(24.3933) | Bit/dim 3.3897(3.4053) | Xent 0.0000(0.0000) | Loss 8.7271(9.2370) | Error 0.0000(0.0000) Steps 988(955.63) | Grad Norm 0.9669(1.4680) | Total Time 0.00(0.00)\n",
      "Iter 16490 | Time 24.8853(24.3800) | Bit/dim 3.4184(3.4061) | Xent 0.0000(0.0000) | Loss 8.7351(9.1133) | Error 0.0000(0.0000) Steps 976(956.26) | Grad Norm 2.0990(1.5282) | Total Time 0.00(0.00)\n",
      "Iter 16500 | Time 25.0643(24.3972) | Bit/dim 3.3943(3.4066) | Xent 0.0000(0.0000) | Loss 8.8181(9.0240) | Error 0.0000(0.0000) Steps 970(953.94) | Grad Norm 1.3472(1.4525) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0300 | Time 109.7359, Epoch Time 1472.2783(1397.2983), Bit/dim 3.4139(best: 3.4093), Xent 0.0000, Loss 3.4139, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16510 | Time 24.5938(24.3613) | Bit/dim 3.4151(3.4041) | Xent 0.0000(0.0000) | Loss 8.7433(9.7885) | Error 0.0000(0.0000) Steps 946(950.05) | Grad Norm 1.9517(1.4198) | Total Time 0.00(0.00)\n",
      "Iter 16520 | Time 24.6744(24.3965) | Bit/dim 3.4026(3.4042) | Xent 0.0000(0.0000) | Loss 8.8606(9.5228) | Error 0.0000(0.0000) Steps 928(947.27) | Grad Norm 2.1188(1.4980) | Total Time 0.00(0.00)\n",
      "Iter 16530 | Time 24.6609(24.4296) | Bit/dim 3.3903(3.4059) | Xent 0.0000(0.0000) | Loss 8.7792(9.3310) | Error 0.0000(0.0000) Steps 952(949.83) | Grad Norm 0.9695(1.4314) | Total Time 0.00(0.00)\n",
      "Iter 16540 | Time 25.1250(24.4144) | Bit/dim 3.3899(3.4076) | Xent 0.0000(0.0000) | Loss 8.8838(9.1900) | Error 0.0000(0.0000) Steps 1000(951.30) | Grad Norm 1.5463(1.3450) | Total Time 0.00(0.00)\n",
      "Iter 16550 | Time 25.6891(24.4504) | Bit/dim 3.4380(3.4071) | Xent 0.0000(0.0000) | Loss 8.8197(9.0847) | Error 0.0000(0.0000) Steps 1000(952.01) | Grad Norm 1.9748(1.3426) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0301 | Time 110.2485, Epoch Time 1471.7447(1399.5317), Bit/dim 3.4134(best: 3.4093), Xent 0.0000, Loss 3.4134, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16560 | Time 24.3314(24.3922) | Bit/dim 3.4180(3.4048) | Xent 0.0000(0.0000) | Loss 8.8165(9.9120) | Error 0.0000(0.0000) Steps 982(953.57) | Grad Norm 1.5059(1.3949) | Total Time 0.00(0.00)\n",
      "Iter 16570 | Time 25.6407(24.4266) | Bit/dim 3.4224(3.4069) | Xent 0.0000(0.0000) | Loss 8.7109(9.6160) | Error 0.0000(0.0000) Steps 1000(954.51) | Grad Norm 1.1690(1.3979) | Total Time 0.00(0.00)\n",
      "Iter 16580 | Time 23.9435(24.3923) | Bit/dim 3.3960(3.4024) | Xent 0.0000(0.0000) | Loss 8.7546(9.3941) | Error 0.0000(0.0000) Steps 922(954.57) | Grad Norm 1.0563(1.3992) | Total Time 0.00(0.00)\n",
      "Iter 16590 | Time 24.7208(24.3901) | Bit/dim 3.4315(3.4041) | Xent 0.0000(0.0000) | Loss 8.8298(9.2262) | Error 0.0000(0.0000) Steps 988(954.43) | Grad Norm 1.4181(1.4228) | Total Time 0.00(0.00)\n",
      "Iter 16600 | Time 24.7007(24.3695) | Bit/dim 3.4286(3.4046) | Xent 0.0000(0.0000) | Loss 8.8161(9.1096) | Error 0.0000(0.0000) Steps 934(954.03) | Grad Norm 1.4487(1.5260) | Total Time 0.00(0.00)\n",
      "Iter 16610 | Time 24.8535(24.3644) | Bit/dim 3.4148(3.4071) | Xent 0.0000(0.0000) | Loss 8.7210(9.0305) | Error 0.0000(0.0000) Steps 934(952.93) | Grad Norm 2.2131(1.5690) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0302 | Time 109.8569, Epoch Time 1467.0329(1401.5567), Bit/dim 3.4093(best: 3.4093), Xent 0.0000, Loss 3.4093, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16620 | Time 23.9811(24.3360) | Bit/dim 3.4043(3.4097) | Xent 0.0000(0.0000) | Loss 8.6501(9.7885) | Error 0.0000(0.0000) Steps 952(954.69) | Grad Norm 1.1583(1.5423) | Total Time 0.00(0.00)\n",
      "Iter 16630 | Time 23.7592(24.2386) | Bit/dim 3.3969(3.4073) | Xent 0.0000(0.0000) | Loss 8.7653(9.5172) | Error 0.0000(0.0000) Steps 946(951.30) | Grad Norm 2.6021(1.5672) | Total Time 0.00(0.00)\n",
      "Iter 16640 | Time 25.0421(24.3336) | Bit/dim 3.4267(3.4086) | Xent 0.0000(0.0000) | Loss 8.9110(9.3351) | Error 0.0000(0.0000) Steps 922(954.50) | Grad Norm 1.5174(1.5599) | Total Time 0.00(0.00)\n",
      "Iter 16650 | Time 24.5407(24.3716) | Bit/dim 3.3746(3.4050) | Xent 0.0000(0.0000) | Loss 8.6184(9.1761) | Error 0.0000(0.0000) Steps 964(955.45) | Grad Norm 2.7786(1.6638) | Total Time 0.00(0.00)\n",
      "Iter 16660 | Time 24.6706(24.3697) | Bit/dim 3.4187(3.4042) | Xent 0.0000(0.0000) | Loss 8.7495(9.0680) | Error 0.0000(0.0000) Steps 976(957.91) | Grad Norm 2.3599(1.6894) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0303 | Time 111.4161, Epoch Time 1467.1490(1403.5245), Bit/dim 3.4111(best: 3.4093), Xent 0.0000, Loss 3.4111, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16670 | Time 24.0747(24.3424) | Bit/dim 3.3973(3.4052) | Xent 0.0000(0.0000) | Loss 8.6931(9.9195) | Error 0.0000(0.0000) Steps 958(954.42) | Grad Norm 1.9770(1.6734) | Total Time 0.00(0.00)\n",
      "Iter 16680 | Time 25.3504(24.4331) | Bit/dim 3.4304(3.4030) | Xent 0.0000(0.0000) | Loss 8.8954(9.6141) | Error 0.0000(0.0000) Steps 940(953.39) | Grad Norm 1.1983(1.5917) | Total Time 0.00(0.00)\n",
      "Iter 16690 | Time 24.3841(24.4879) | Bit/dim 3.3857(3.4025) | Xent 0.0000(0.0000) | Loss 8.7444(9.3839) | Error 0.0000(0.0000) Steps 958(954.17) | Grad Norm 1.2926(1.5058) | Total Time 0.00(0.00)\n",
      "Iter 16700 | Time 23.9377(24.4679) | Bit/dim 3.4169(3.4034) | Xent 0.0000(0.0000) | Loss 8.8615(9.2126) | Error 0.0000(0.0000) Steps 922(952.11) | Grad Norm 2.8818(1.6987) | Total Time 0.00(0.00)\n",
      "Iter 16710 | Time 23.8689(24.4855) | Bit/dim 3.3980(3.4037) | Xent 0.0000(0.0000) | Loss 8.7277(9.0953) | Error 0.0000(0.0000) Steps 940(951.02) | Grad Norm 2.4259(1.8463) | Total Time 0.00(0.00)\n",
      "Iter 16720 | Time 23.6871(24.5640) | Bit/dim 3.3819(3.4057) | Xent 0.0000(0.0000) | Loss 8.7306(9.0116) | Error 0.0000(0.0000) Steps 940(952.87) | Grad Norm 1.8479(1.8986) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0304 | Time 110.2654, Epoch Time 1480.3418(1405.8290), Bit/dim 3.4093(best: 3.4093), Xent 0.0000, Loss 3.4093, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16730 | Time 24.5402(24.4712) | Bit/dim 3.3994(3.4031) | Xent 0.0000(0.0000) | Loss 8.7925(9.7466) | Error 0.0000(0.0000) Steps 940(951.75) | Grad Norm 1.4838(1.8148) | Total Time 0.00(0.00)\n",
      "Iter 16740 | Time 24.6097(24.4382) | Bit/dim 3.4118(3.4020) | Xent 0.0000(0.0000) | Loss 8.8073(9.4842) | Error 0.0000(0.0000) Steps 964(949.40) | Grad Norm 1.6506(3.5731) | Total Time 0.00(0.00)\n",
      "Iter 16750 | Time 24.3176(24.3897) | Bit/dim 3.3955(3.4023) | Xent 0.0000(0.0000) | Loss 8.6671(9.2859) | Error 0.0000(0.0000) Steps 928(949.96) | Grad Norm 1.0945(3.2303) | Total Time 0.00(0.00)\n",
      "Iter 16760 | Time 23.9565(24.2425) | Bit/dim 3.4494(3.4054) | Xent 0.0000(0.0000) | Loss 8.7741(9.1397) | Error 0.0000(0.0000) Steps 940(946.44) | Grad Norm 1.7834(2.8798) | Total Time 0.00(0.00)\n",
      "Iter 16770 | Time 23.8939(24.1424) | Bit/dim 3.4393(3.4063) | Xent 0.0000(0.0000) | Loss 8.7848(9.0260) | Error 0.0000(0.0000) Steps 934(943.46) | Grad Norm 2.1965(2.5496) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0305 | Time 109.1121, Epoch Time 1452.2799(1407.2225), Bit/dim 3.4128(best: 3.4093), Xent 0.0000, Loss 3.4128, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16780 | Time 24.4110(24.1182) | Bit/dim 3.3974(3.4055) | Xent 0.0000(0.0000) | Loss 8.8167(9.8485) | Error 0.0000(0.0000) Steps 910(940.02) | Grad Norm 2.2850(2.3841) | Total Time 0.00(0.00)\n",
      "Iter 16790 | Time 24.2188(24.0153) | Bit/dim 3.4123(3.4045) | Xent 0.0000(0.0000) | Loss 8.7056(9.5434) | Error 0.0000(0.0000) Steps 940(937.18) | Grad Norm 3.4902(2.3873) | Total Time 0.00(0.00)\n",
      "Iter 16800 | Time 23.8525(23.9413) | Bit/dim 3.3958(3.4010) | Xent 0.0000(0.0000) | Loss 8.6786(9.3216) | Error 0.0000(0.0000) Steps 928(937.73) | Grad Norm 1.1582(2.2191) | Total Time 0.00(0.00)\n",
      "Iter 16810 | Time 23.4128(23.9579) | Bit/dim 3.3961(3.4036) | Xent 0.0000(0.0000) | Loss 8.6216(9.1722) | Error 0.0000(0.0000) Steps 928(939.85) | Grad Norm 2.0578(2.0370) | Total Time 0.00(0.00)\n",
      "Iter 16820 | Time 24.2653(24.0502) | Bit/dim 3.3897(3.4045) | Xent 0.0000(0.0000) | Loss 8.6719(9.0590) | Error 0.0000(0.0000) Steps 958(939.18) | Grad Norm 1.7228(1.9690) | Total Time 0.00(0.00)\n",
      "Iter 16830 | Time 23.3398(24.0885) | Bit/dim 3.4157(3.4067) | Xent 0.0000(0.0000) | Loss 8.7376(8.9796) | Error 0.0000(0.0000) Steps 928(935.92) | Grad Norm 1.4333(1.8564) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0306 | Time 108.4414, Epoch Time 1446.4705(1408.4000), Bit/dim 3.4100(best: 3.4093), Xent 0.0000, Loss 3.4100, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16840 | Time 24.1429(24.1311) | Bit/dim 3.4008(3.4066) | Xent 0.0000(0.0000) | Loss 8.6167(9.6789) | Error 0.0000(0.0000) Steps 928(938.43) | Grad Norm 2.6135(1.9205) | Total Time 0.00(0.00)\n",
      "Iter 16850 | Time 24.4887(24.1589) | Bit/dim 3.3769(3.4050) | Xent 0.0000(0.0000) | Loss 8.6726(9.4274) | Error 0.0000(0.0000) Steps 982(939.89) | Grad Norm 1.5201(1.8733) | Total Time 0.00(0.00)\n",
      "Iter 16860 | Time 24.2426(24.1521) | Bit/dim 3.4040(3.4036) | Xent 0.0000(0.0000) | Loss 8.7018(9.2432) | Error 0.0000(0.0000) Steps 988(940.36) | Grad Norm 2.0191(1.7903) | Total Time 0.00(0.00)\n",
      "Iter 16870 | Time 23.5154(24.1013) | Bit/dim 3.4152(3.4049) | Xent 0.0000(0.0000) | Loss 8.6923(9.0962) | Error 0.0000(0.0000) Steps 934(940.34) | Grad Norm 0.8542(1.6646) | Total Time 0.00(0.00)\n",
      "Iter 16880 | Time 23.4358(24.0852) | Bit/dim 3.4301(3.4035) | Xent 0.0000(0.0000) | Loss 8.7297(9.0013) | Error 0.0000(0.0000) Steps 928(942.90) | Grad Norm 1.4738(1.5665) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0307 | Time 108.7120, Epoch Time 1456.3777(1409.8393), Bit/dim 3.4107(best: 3.4093), Xent 0.0000, Loss 3.4107, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16890 | Time 24.9058(24.1548) | Bit/dim 3.3737(3.4038) | Xent 0.0000(0.0000) | Loss 8.7363(9.8410) | Error 0.0000(0.0000) Steps 976(946.81) | Grad Norm 1.3567(1.4819) | Total Time 0.00(0.00)\n",
      "Iter 16900 | Time 23.8921(24.1586) | Bit/dim 3.3677(3.4033) | Xent 0.0000(0.0000) | Loss 8.7422(9.5508) | Error 0.0000(0.0000) Steps 922(944.59) | Grad Norm 1.3498(1.4255) | Total Time 0.00(0.00)\n",
      "Iter 16910 | Time 24.0875(24.1370) | Bit/dim 3.4414(3.4036) | Xent 0.0000(0.0000) | Loss 8.8906(9.3322) | Error 0.0000(0.0000) Steps 952(942.70) | Grad Norm 2.0333(1.4751) | Total Time 0.00(0.00)\n",
      "Iter 16920 | Time 24.5177(24.1068) | Bit/dim 3.3854(3.4058) | Xent 0.0000(0.0000) | Loss 8.6455(9.1716) | Error 0.0000(0.0000) Steps 934(942.61) | Grad Norm 1.7390(1.5583) | Total Time 0.00(0.00)\n",
      "Iter 16930 | Time 24.2033(24.1314) | Bit/dim 3.3801(3.4051) | Xent 0.0000(0.0000) | Loss 8.6328(9.0459) | Error 0.0000(0.0000) Steps 940(939.29) | Grad Norm 2.6508(1.5984) | Total Time 0.00(0.00)\n",
      "Iter 16940 | Time 24.2953(24.1249) | Bit/dim 3.4209(3.4064) | Xent 0.0000(0.0000) | Loss 8.8483(8.9638) | Error 0.0000(0.0000) Steps 952(939.35) | Grad Norm 2.3980(1.9000) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0308 | Time 108.6955, Epoch Time 1453.5672(1411.1511), Bit/dim 3.4069(best: 3.4093), Xent 0.0000, Loss 3.4069, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16950 | Time 24.1856(24.0512) | Bit/dim 3.3984(3.4079) | Xent 0.0000(0.0000) | Loss 8.8511(9.6651) | Error 0.0000(0.0000) Steps 952(939.89) | Grad Norm 1.4826(1.8420) | Total Time 0.00(0.00)\n",
      "Iter 16960 | Time 24.6809(24.0328) | Bit/dim 3.3956(3.4065) | Xent 0.0000(0.0000) | Loss 8.7340(9.4248) | Error 0.0000(0.0000) Steps 958(940.46) | Grad Norm 1.3054(1.7095) | Total Time 0.00(0.00)\n",
      "Iter 16970 | Time 23.7180(23.9777) | Bit/dim 3.3950(3.4038) | Xent 0.0000(0.0000) | Loss 8.7278(9.2324) | Error 0.0000(0.0000) Steps 892(941.01) | Grad Norm 1.0713(1.6876) | Total Time 0.00(0.00)\n",
      "Iter 16980 | Time 25.8110(23.9891) | Bit/dim 3.4131(3.4029) | Xent 0.0000(0.0000) | Loss 8.8492(9.0951) | Error 0.0000(0.0000) Steps 1012(944.51) | Grad Norm 1.5641(1.6815) | Total Time 0.00(0.00)\n",
      "Iter 16990 | Time 23.2185(24.0948) | Bit/dim 3.4118(3.4041) | Xent 0.0000(0.0000) | Loss 8.8211(9.0011) | Error 0.0000(0.0000) Steps 928(945.65) | Grad Norm 1.7363(1.6166) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0309 | Time 107.8465, Epoch Time 1446.4590(1412.2104), Bit/dim 3.4103(best: 3.4069), Xent 0.0000, Loss 3.4103, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17000 | Time 23.8656(24.0865) | Bit/dim 3.4210(3.4022) | Xent 0.0000(0.0000) | Loss 8.7252(9.8363) | Error 0.0000(0.0000) Steps 946(946.54) | Grad Norm 1.9103(1.6504) | Total Time 0.00(0.00)\n",
      "Iter 17010 | Time 24.6328(24.0743) | Bit/dim 3.3770(3.4005) | Xent 0.0000(0.0000) | Loss 8.5661(9.5338) | Error 0.0000(0.0000) Steps 922(944.97) | Grad Norm 0.9741(1.6360) | Total Time 0.00(0.00)\n",
      "Iter 17020 | Time 23.6866(24.1877) | Bit/dim 3.4143(3.4037) | Xent 0.0000(0.0000) | Loss 8.7348(9.3348) | Error 0.0000(0.0000) Steps 934(944.17) | Grad Norm 1.9410(1.6472) | Total Time 0.00(0.00)\n",
      "Iter 17030 | Time 23.9693(24.1721) | Bit/dim 3.3895(3.4078) | Xent 0.0000(0.0000) | Loss 8.6758(9.1820) | Error 0.0000(0.0000) Steps 952(944.65) | Grad Norm 1.7763(1.6258) | Total Time 0.00(0.00)\n",
      "Iter 17040 | Time 24.4764(24.2030) | Bit/dim 3.3824(3.4056) | Xent 0.0000(0.0000) | Loss 8.7563(9.0612) | Error 0.0000(0.0000) Steps 946(944.28) | Grad Norm 0.9211(1.5753) | Total Time 0.00(0.00)\n",
      "Iter 17050 | Time 24.4545(24.1718) | Bit/dim 3.3939(3.4033) | Xent 0.0000(0.0000) | Loss 8.6725(8.9662) | Error 0.0000(0.0000) Steps 916(941.62) | Grad Norm 1.5931(1.4926) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0310 | Time 108.8192, Epoch Time 1457.8983(1413.5810), Bit/dim 3.4093(best: 3.4069), Xent 0.0000, Loss 3.4093, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17060 | Time 25.1435(24.0810) | Bit/dim 3.4054(3.4026) | Xent 0.0000(0.0000) | Loss 8.8349(9.6665) | Error 0.0000(0.0000) Steps 916(938.86) | Grad Norm 1.2143(1.4342) | Total Time 0.00(0.00)\n",
      "Iter 17070 | Time 23.7474(24.0255) | Bit/dim 3.3753(3.4039) | Xent 0.0000(0.0000) | Loss 8.6097(9.4215) | Error 0.0000(0.0000) Steps 898(938.82) | Grad Norm 1.6805(1.4910) | Total Time 0.00(0.00)\n",
      "Iter 17080 | Time 23.8729(24.0190) | Bit/dim 3.4213(3.4038) | Xent 0.0000(0.0000) | Loss 8.7880(9.2403) | Error 0.0000(0.0000) Steps 940(938.04) | Grad Norm 2.2085(1.6049) | Total Time 0.00(0.00)\n",
      "Iter 17090 | Time 24.2182(24.0230) | Bit/dim 3.3768(3.4038) | Xent 0.0000(0.0000) | Loss 8.7029(9.1102) | Error 0.0000(0.0000) Steps 964(939.45) | Grad Norm 1.2342(1.5573) | Total Time 0.00(0.00)\n",
      "Iter 17100 | Time 24.0206(24.0677) | Bit/dim 3.4238(3.4046) | Xent 0.0000(0.0000) | Loss 8.7231(9.0107) | Error 0.0000(0.0000) Steps 934(940.44) | Grad Norm 1.3278(1.5281) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0311 | Time 107.9528, Epoch Time 1446.5207(1414.5692), Bit/dim 3.4117(best: 3.4069), Xent 0.0000, Loss 3.4117, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17110 | Time 24.3372(24.0939) | Bit/dim 3.3779(3.4028) | Xent 0.0000(0.0000) | Loss 8.7341(9.8127) | Error 0.0000(0.0000) Steps 946(941.33) | Grad Norm 1.2287(1.4803) | Total Time 0.00(0.00)\n",
      "Iter 17120 | Time 23.5986(24.1278) | Bit/dim 3.4409(3.4060) | Xent 0.0000(0.0000) | Loss 8.8607(9.5362) | Error 0.0000(0.0000) Steps 934(938.95) | Grad Norm 1.5085(1.4741) | Total Time 0.00(0.00)\n",
      "Iter 17130 | Time 24.2368(24.1192) | Bit/dim 3.4174(3.4051) | Xent 0.0000(0.0000) | Loss 8.8793(9.3272) | Error 0.0000(0.0000) Steps 928(939.72) | Grad Norm 1.2690(1.4848) | Total Time 0.00(0.00)\n",
      "Iter 17140 | Time 24.4611(24.2081) | Bit/dim 3.3735(3.4029) | Xent 0.0000(0.0000) | Loss 8.6353(9.1645) | Error 0.0000(0.0000) Steps 982(937.09) | Grad Norm 1.1520(1.4680) | Total Time 0.00(0.00)\n",
      "Iter 17150 | Time 24.3404(24.1464) | Bit/dim 3.3868(3.4051) | Xent 0.0000(0.0000) | Loss 8.6898(9.0576) | Error 0.0000(0.0000) Steps 952(939.19) | Grad Norm 1.4571(1.4688) | Total Time 0.00(0.00)\n",
      "Iter 17160 | Time 24.6736(24.1059) | Bit/dim 3.3992(3.4035) | Xent 0.0000(0.0000) | Loss 8.7708(8.9696) | Error 0.0000(0.0000) Steps 934(939.94) | Grad Norm 1.0362(1.4353) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0312 | Time 109.6619, Epoch Time 1455.9830(1415.8116), Bit/dim 3.4085(best: 3.4069), Xent 0.0000, Loss 3.4085, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17170 | Time 24.5945(24.1592) | Bit/dim 3.3851(3.4040) | Xent 0.0000(0.0000) | Loss 8.4622(9.6750) | Error 0.0000(0.0000) Steps 964(943.29) | Grad Norm 1.0965(1.4525) | Total Time 0.00(0.00)\n",
      "Iter 17180 | Time 24.3149(24.1554) | Bit/dim 3.3772(3.4012) | Xent 0.0000(0.0000) | Loss 8.7089(9.4223) | Error 0.0000(0.0000) Steps 976(943.63) | Grad Norm 1.3341(1.4769) | Total Time 0.00(0.00)\n",
      "Iter 17190 | Time 24.1847(24.1459) | Bit/dim 3.3932(3.4041) | Xent 0.0000(0.0000) | Loss 8.5090(9.2380) | Error 0.0000(0.0000) Steps 898(943.19) | Grad Norm 1.1207(1.4969) | Total Time 0.00(0.00)\n",
      "Iter 17200 | Time 24.1509(24.1644) | Bit/dim 3.3887(3.4057) | Xent 0.0000(0.0000) | Loss 8.6175(9.1076) | Error 0.0000(0.0000) Steps 964(942.96) | Grad Norm 0.8819(1.4425) | Total Time 0.00(0.00)\n",
      "Iter 17210 | Time 24.2099(24.2483) | Bit/dim 3.3901(3.4019) | Xent 0.0000(0.0000) | Loss 8.6762(9.0066) | Error 0.0000(0.0000) Steps 940(943.34) | Grad Norm 1.5938(1.4380) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0313 | Time 108.7965, Epoch Time 1460.1919(1417.1430), Bit/dim 3.4098(best: 3.4069), Xent 0.0000, Loss 3.4098, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17220 | Time 22.9879(24.1562) | Bit/dim 3.4010(3.4041) | Xent 0.0000(0.0000) | Loss 8.5820(9.8265) | Error 0.0000(0.0000) Steps 922(943.79) | Grad Norm 1.1978(1.4712) | Total Time 0.00(0.00)\n",
      "Iter 17230 | Time 24.5824(24.2180) | Bit/dim 3.4132(3.4050) | Xent 0.0000(0.0000) | Loss 8.7806(9.5426) | Error 0.0000(0.0000) Steps 958(946.67) | Grad Norm 0.9900(1.4640) | Total Time 0.00(0.00)\n",
      "Iter 17240 | Time 23.7055(24.1795) | Bit/dim 3.3921(3.4065) | Xent 0.0000(0.0000) | Loss 8.5973(9.3302) | Error 0.0000(0.0000) Steps 904(942.37) | Grad Norm 1.0391(1.4900) | Total Time 0.00(0.00)\n",
      "Iter 17250 | Time 24.0074(24.2010) | Bit/dim 3.4090(3.4044) | Xent 0.0000(0.0000) | Loss 8.6842(9.1752) | Error 0.0000(0.0000) Steps 946(946.65) | Grad Norm 1.2417(1.4919) | Total Time 0.00(0.00)\n",
      "Iter 17260 | Time 23.9472(24.2093) | Bit/dim 3.4015(3.4021) | Xent 0.0000(0.0000) | Loss 8.6634(9.0530) | Error 0.0000(0.0000) Steps 916(946.25) | Grad Norm 1.5680(1.4418) | Total Time 0.00(0.00)\n",
      "Iter 17270 | Time 24.2762(24.1734) | Bit/dim 3.3803(3.4016) | Xent 0.0000(0.0000) | Loss 8.6360(8.9602) | Error 0.0000(0.0000) Steps 958(943.96) | Grad Norm 0.9770(1.3770) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0314 | Time 108.7996, Epoch Time 1455.3917(1418.2905), Bit/dim 3.4092(best: 3.4069), Xent 0.0000, Loss 3.4092, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17280 | Time 24.1705(24.2267) | Bit/dim 3.3853(3.4016) | Xent 0.0000(0.0000) | Loss 8.7397(9.6828) | Error 0.0000(0.0000) Steps 898(943.09) | Grad Norm 1.2258(1.3911) | Total Time 0.00(0.00)\n",
      "Iter 17290 | Time 23.4308(24.1915) | Bit/dim 3.4125(3.4040) | Xent 0.0000(0.0000) | Loss 8.6812(9.4392) | Error 0.0000(0.0000) Steps 970(942.48) | Grad Norm 1.0453(1.4682) | Total Time 0.00(0.00)\n",
      "Iter 17300 | Time 24.6984(24.1885) | Bit/dim 3.3896(3.4063) | Xent 0.0000(0.0000) | Loss 8.7203(9.2619) | Error 0.0000(0.0000) Steps 976(944.53) | Grad Norm 1.4834(1.4192) | Total Time 0.00(0.00)\n",
      "Iter 17310 | Time 24.2438(24.2401) | Bit/dim 3.3857(3.4057) | Xent 0.0000(0.0000) | Loss 8.8310(9.1339) | Error 0.0000(0.0000) Steps 928(944.11) | Grad Norm 1.2543(1.4326) | Total Time 0.00(0.00)\n",
      "Iter 17320 | Time 23.3413(24.2066) | Bit/dim 3.3783(3.4002) | Xent 0.0000(0.0000) | Loss 8.6947(9.0171) | Error 0.0000(0.0000) Steps 934(942.79) | Grad Norm 1.4383(1.5478) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0315 | Time 109.9148, Epoch Time 1459.8551(1419.5374), Bit/dim 3.4095(best: 3.4069), Xent 0.0000, Loss 3.4095, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17330 | Time 24.6654(24.2018) | Bit/dim 3.3481(3.3979) | Xent 0.0000(0.0000) | Loss 8.6618(9.8431) | Error 0.0000(0.0000) Steps 964(943.58) | Grad Norm 2.6269(1.6228) | Total Time 0.00(0.00)\n",
      "Iter 17340 | Time 23.6847(24.1811) | Bit/dim 3.4311(3.3996) | Xent 0.0000(0.0000) | Loss 8.7799(9.5501) | Error 0.0000(0.0000) Steps 976(945.47) | Grad Norm 3.0027(1.7650) | Total Time 0.00(0.00)\n",
      "Iter 17350 | Time 24.1453(24.1636) | Bit/dim 3.3971(3.3988) | Xent 0.0000(0.0000) | Loss 8.8186(9.3349) | Error 0.0000(0.0000) Steps 934(946.21) | Grad Norm 1.2812(1.8246) | Total Time 0.00(0.00)\n",
      "Iter 17360 | Time 24.7483(24.2525) | Bit/dim 3.3986(3.3990) | Xent 0.0000(0.0000) | Loss 8.6642(9.1700) | Error 0.0000(0.0000) Steps 952(945.28) | Grad Norm 2.3306(1.9599) | Total Time 0.00(0.00)\n",
      "Iter 17370 | Time 24.2118(24.2927) | Bit/dim 3.4260(3.3985) | Xent 0.0000(0.0000) | Loss 8.8315(9.0537) | Error 0.0000(0.0000) Steps 940(944.90) | Grad Norm 2.2177(2.1599) | Total Time 0.00(0.00)\n",
      "Iter 17380 | Time 24.0740(24.2802) | Bit/dim 3.4203(3.4011) | Xent 0.0000(0.0000) | Loss 8.7641(8.9758) | Error 0.0000(0.0000) Steps 946(945.13) | Grad Norm 0.9652(2.1311) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0316 | Time 109.0659, Epoch Time 1463.1348(1420.8453), Bit/dim 3.4091(best: 3.4069), Xent 0.0000, Loss 3.4091, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17390 | Time 24.5708(24.2319) | Bit/dim 3.4200(3.4047) | Xent 0.0000(0.0000) | Loss 8.6890(9.7088) | Error 0.0000(0.0000) Steps 946(948.50) | Grad Norm 2.3343(2.0438) | Total Time 0.00(0.00)\n",
      "Iter 17400 | Time 24.6286(24.1904) | Bit/dim 3.4095(3.4019) | Xent 0.0000(0.0000) | Loss 8.7478(9.4557) | Error 0.0000(0.0000) Steps 964(947.78) | Grad Norm 1.2734(1.9446) | Total Time 0.00(0.00)\n",
      "Iter 17410 | Time 24.4100(24.2329) | Bit/dim 3.4063(3.4019) | Xent 0.0000(0.0000) | Loss 8.6852(9.2624) | Error 0.0000(0.0000) Steps 886(944.93) | Grad Norm 2.2988(2.0045) | Total Time 0.00(0.00)\n",
      "Iter 17420 | Time 24.0719(24.3460) | Bit/dim 3.4066(3.4017) | Xent 0.0000(0.0000) | Loss 8.6866(9.1179) | Error 0.0000(0.0000) Steps 958(946.54) | Grad Norm 2.5868(1.9595) | Total Time 0.00(0.00)\n",
      "Iter 17430 | Time 24.1244(24.3307) | Bit/dim 3.3818(3.4010) | Xent 0.0000(0.0000) | Loss 8.7991(9.0199) | Error 0.0000(0.0000) Steps 952(948.53) | Grad Norm 1.3551(1.9475) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0317 | Time 109.2179, Epoch Time 1465.8063(1422.1942), Bit/dim 3.4046(best: 3.4069), Xent 0.0000, Loss 3.4046, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17440 | Time 23.1992(24.3407) | Bit/dim 3.4297(3.4007) | Xent 0.0000(0.0000) | Loss 8.6793(9.8601) | Error 0.0000(0.0000) Steps 952(949.24) | Grad Norm 1.1775(1.8117) | Total Time 0.00(0.00)\n",
      "Iter 17450 | Time 24.7890(24.2181) | Bit/dim 3.4237(3.4014) | Xent 0.0000(0.0000) | Loss 8.7687(9.5647) | Error 0.0000(0.0000) Steps 946(950.04) | Grad Norm 2.8311(1.8478) | Total Time 0.00(0.00)\n",
      "Iter 17460 | Time 23.4071(24.1934) | Bit/dim 3.4030(3.4023) | Xent 0.0000(0.0000) | Loss 8.7006(9.3414) | Error 0.0000(0.0000) Steps 946(948.54) | Grad Norm 1.3057(1.8958) | Total Time 0.00(0.00)\n",
      "Iter 17470 | Time 25.0168(24.2296) | Bit/dim 3.4060(3.4011) | Xent 0.0000(0.0000) | Loss 8.7488(9.1748) | Error 0.0000(0.0000) Steps 958(949.24) | Grad Norm 2.0391(1.9479) | Total Time 0.00(0.00)\n",
      "Iter 17480 | Time 25.3547(24.3970) | Bit/dim 3.4422(3.4032) | Xent 0.0000(0.0000) | Loss 8.9005(9.0715) | Error 0.0000(0.0000) Steps 946(948.98) | Grad Norm 1.4392(1.9099) | Total Time 0.00(0.00)\n",
      "Iter 17490 | Time 24.8572(24.4061) | Bit/dim 3.3759(3.4027) | Xent 0.0000(0.0000) | Loss 8.7513(8.9803) | Error 0.0000(0.0000) Steps 952(947.08) | Grad Norm 2.1765(1.8076) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0318 | Time 108.9119, Epoch Time 1464.0719(1423.4505), Bit/dim 3.4101(best: 3.4046), Xent 0.0000, Loss 3.4101, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17500 | Time 23.3286(24.2851) | Bit/dim 3.3618(3.4004) | Xent 0.0000(0.0000) | Loss 8.5706(9.7106) | Error 0.0000(0.0000) Steps 904(946.79) | Grad Norm 0.9040(1.7401) | Total Time 0.00(0.00)\n",
      "Iter 17510 | Time 23.7709(24.2333) | Bit/dim 3.4181(3.4008) | Xent 0.0000(0.0000) | Loss 8.5444(9.4484) | Error 0.0000(0.0000) Steps 952(947.22) | Grad Norm 1.2011(1.7081) | Total Time 0.00(0.00)\n",
      "Iter 17520 | Time 24.2448(24.1313) | Bit/dim 3.4305(3.4037) | Xent 0.0000(0.0000) | Loss 8.8597(9.2721) | Error 0.0000(0.0000) Steps 958(947.04) | Grad Norm 1.9145(1.6563) | Total Time 0.00(0.00)\n",
      "Iter 17530 | Time 24.0987(24.1164) | Bit/dim 3.3832(3.4020) | Xent 0.0000(0.0000) | Loss 8.7918(9.1381) | Error 0.0000(0.0000) Steps 952(947.48) | Grad Norm 1.5644(1.6882) | Total Time 0.00(0.00)\n",
      "Iter 17540 | Time 23.9418(24.1576) | Bit/dim 3.3575(3.4013) | Xent 0.0000(0.0000) | Loss 8.7520(9.0386) | Error 0.0000(0.0000) Steps 964(946.47) | Grad Norm 2.5257(1.6904) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0319 | Time 110.3429, Epoch Time 1452.9298(1424.3349), Bit/dim 3.4094(best: 3.4046), Xent 0.0000, Loss 3.4094, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17550 | Time 24.3378(24.1978) | Bit/dim 3.3980(3.4040) | Xent 0.0000(0.0000) | Loss 8.8012(9.8616) | Error 0.0000(0.0000) Steps 958(949.52) | Grad Norm 1.0476(1.6642) | Total Time 0.00(0.00)\n",
      "Iter 17560 | Time 24.3076(24.2436) | Bit/dim 3.4158(3.4057) | Xent 0.0000(0.0000) | Loss 8.8292(9.5806) | Error 0.0000(0.0000) Steps 892(951.28) | Grad Norm 1.9267(1.7076) | Total Time 0.00(0.00)\n",
      "Iter 17570 | Time 24.8121(24.2790) | Bit/dim 3.4065(3.4053) | Xent 0.0000(0.0000) | Loss 8.7414(9.3606) | Error 0.0000(0.0000) Steps 928(947.40) | Grad Norm 1.2633(1.8175) | Total Time 0.00(0.00)\n",
      "Iter 17580 | Time 24.0110(24.2430) | Bit/dim 3.4249(3.4057) | Xent 0.0000(0.0000) | Loss 8.7929(9.1899) | Error 0.0000(0.0000) Steps 946(947.42) | Grad Norm 1.3778(1.8191) | Total Time 0.00(0.00)\n",
      "Iter 17590 | Time 24.4498(24.1766) | Bit/dim 3.4108(3.4044) | Xent 0.0000(0.0000) | Loss 8.7714(9.0635) | Error 0.0000(0.0000) Steps 940(948.41) | Grad Norm 2.3051(1.8328) | Total Time 0.00(0.00)\n",
      "Iter 17600 | Time 23.9877(24.2178) | Bit/dim 3.3951(3.4019) | Xent 0.0000(0.0000) | Loss 8.7544(8.9804) | Error 0.0000(0.0000) Steps 916(948.16) | Grad Norm 1.1111(1.6813) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0320 | Time 108.7363, Epoch Time 1461.0328(1425.4358), Bit/dim 3.4080(best: 3.4046), Xent 0.0000, Loss 3.4080, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17610 | Time 25.2514(24.2545) | Bit/dim 3.3842(3.4025) | Xent 0.0000(0.0000) | Loss 8.7565(9.6841) | Error 0.0000(0.0000) Steps 946(946.99) | Grad Norm 1.7878(1.6311) | Total Time 0.00(0.00)\n",
      "Iter 17620 | Time 24.5741(24.3757) | Bit/dim 3.4253(3.4021) | Xent 0.0000(0.0000) | Loss 8.6670(9.4386) | Error 0.0000(0.0000) Steps 946(949.68) | Grad Norm 1.9173(1.6169) | Total Time 0.00(0.00)\n",
      "Iter 17630 | Time 24.6266(24.3735) | Bit/dim 3.4079(3.4025) | Xent 0.0000(0.0000) | Loss 8.9100(9.2641) | Error 0.0000(0.0000) Steps 976(951.55) | Grad Norm 2.0434(1.6566) | Total Time 0.00(0.00)\n",
      "Iter 17640 | Time 23.7886(24.3497) | Bit/dim 3.4227(3.4011) | Xent 0.0000(0.0000) | Loss 8.8324(9.1206) | Error 0.0000(0.0000) Steps 940(951.60) | Grad Norm 1.8316(1.6969) | Total Time 0.00(0.00)\n",
      "Iter 17650 | Time 24.7296(24.3631) | Bit/dim 3.4163(3.4025) | Xent 0.0000(0.0000) | Loss 8.7917(9.0273) | Error 0.0000(0.0000) Steps 952(950.32) | Grad Norm 1.1770(1.6555) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0321 | Time 109.6846, Epoch Time 1472.5684(1426.8498), Bit/dim 3.4091(best: 3.4046), Xent 0.0000, Loss 3.4091, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17660 | Time 23.2448(24.3524) | Bit/dim 3.4209(3.4049) | Xent 0.0000(0.0000) | Loss 8.7664(9.8131) | Error 0.0000(0.0000) Steps 916(950.28) | Grad Norm 1.7256(1.5728) | Total Time 0.00(0.00)\n",
      "Iter 17670 | Time 24.1438(24.3365) | Bit/dim 3.3634(3.4030) | Xent 0.0000(0.0000) | Loss 8.6648(9.5392) | Error 0.0000(0.0000) Steps 964(948.44) | Grad Norm 1.8662(1.6342) | Total Time 0.00(0.00)\n",
      "Iter 17680 | Time 24.2426(24.3619) | Bit/dim 3.4217(3.4017) | Xent 0.0000(0.0000) | Loss 8.7197(9.3202) | Error 0.0000(0.0000) Steps 940(949.47) | Grad Norm 1.2222(1.5909) | Total Time 0.00(0.00)\n",
      "Iter 17690 | Time 23.8285(24.3397) | Bit/dim 3.4195(3.4030) | Xent 0.0000(0.0000) | Loss 8.6702(9.1749) | Error 0.0000(0.0000) Steps 964(950.48) | Grad Norm 1.2497(1.5589) | Total Time 0.00(0.00)\n",
      "Iter 17700 | Time 24.3174(24.2999) | Bit/dim 3.4123(3.4008) | Xent 0.0000(0.0000) | Loss 8.7052(9.0479) | Error 0.0000(0.0000) Steps 970(950.80) | Grad Norm 1.3563(1.5303) | Total Time 0.00(0.00)\n",
      "Iter 17710 | Time 23.5932(24.2492) | Bit/dim 3.4106(3.4057) | Xent 0.0000(0.0000) | Loss 8.7358(8.9688) | Error 0.0000(0.0000) Steps 964(949.70) | Grad Norm 3.6752(1.6943) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0322 | Time 108.7044, Epoch Time 1460.2119(1427.8507), Bit/dim 3.4100(best: 3.4046), Xent 0.0000, Loss 3.4100, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17720 | Time 24.2682(24.3404) | Bit/dim 3.3755(3.4022) | Xent 0.0000(0.0000) | Loss 8.7003(9.6950) | Error 0.0000(0.0000) Steps 958(949.90) | Grad Norm 2.9012(2.0192) | Total Time 0.00(0.00)\n",
      "Iter 17730 | Time 24.6140(24.3653) | Bit/dim 3.4263(3.4033) | Xent 0.0000(0.0000) | Loss 8.7616(9.4306) | Error 0.0000(0.0000) Steps 940(947.85) | Grad Norm 2.5581(2.2060) | Total Time 0.00(0.00)\n",
      "Iter 17740 | Time 24.9208(24.4071) | Bit/dim 3.4239(3.4048) | Xent 0.0000(0.0000) | Loss 8.8249(9.2500) | Error 0.0000(0.0000) Steps 910(949.31) | Grad Norm 1.3075(2.1008) | Total Time 0.00(0.00)\n",
      "Iter 17750 | Time 25.0966(24.4547) | Bit/dim 3.4420(3.4060) | Xent 0.0000(0.0000) | Loss 8.8824(9.1209) | Error 0.0000(0.0000) Steps 958(951.01) | Grad Norm 1.3048(2.0450) | Total Time 0.00(0.00)\n",
      "Iter 17760 | Time 23.5068(24.4380) | Bit/dim 3.4254(3.4066) | Xent 0.0000(0.0000) | Loss 8.7263(9.0260) | Error 0.0000(0.0000) Steps 940(951.97) | Grad Norm 2.9809(1.9999) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0323 | Time 109.7530, Epoch Time 1476.4147(1429.3076), Bit/dim 3.4084(best: 3.4046), Xent 0.0000, Loss 3.4084, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17770 | Time 24.0793(24.4262) | Bit/dim 3.4034(3.4042) | Xent 0.0000(0.0000) | Loss 8.6516(9.8861) | Error 0.0000(0.0000) Steps 958(952.71) | Grad Norm 2.2450(2.0808) | Total Time 0.00(0.00)\n",
      "Iter 17780 | Time 24.9983(24.4223) | Bit/dim 3.3993(3.4023) | Xent 0.0000(0.0000) | Loss 8.7909(9.5847) | Error 0.0000(0.0000) Steps 946(955.12) | Grad Norm 3.1402(2.1495) | Total Time 0.00(0.00)\n",
      "Iter 17790 | Time 24.7987(24.3671) | Bit/dim 3.4112(3.4035) | Xent 0.0000(0.0000) | Loss 8.6479(9.3505) | Error 0.0000(0.0000) Steps 922(950.40) | Grad Norm 2.5427(2.1141) | Total Time 0.00(0.00)\n",
      "Iter 17800 | Time 24.9255(24.4049) | Bit/dim 3.3894(3.4024) | Xent 0.0000(0.0000) | Loss 8.7101(9.1891) | Error 0.0000(0.0000) Steps 958(952.86) | Grad Norm 1.5847(2.2214) | Total Time 0.00(0.00)\n",
      "Iter 17810 | Time 23.1501(24.2728) | Bit/dim 3.3940(3.4026) | Xent 0.0000(0.0000) | Loss 8.6249(9.0531) | Error 0.0000(0.0000) Steps 928(950.35) | Grad Norm 2.2182(2.2549) | Total Time 0.00(0.00)\n",
      "Iter 17820 | Time 25.3388(24.2857) | Bit/dim 3.4182(3.4027) | Xent 0.0000(0.0000) | Loss 8.8133(8.9869) | Error 0.0000(0.0000) Steps 964(955.24) | Grad Norm 1.0927(2.1586) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0324 | Time 111.2850, Epoch Time 1464.2834(1430.3569), Bit/dim 3.4066(best: 3.4046), Xent 0.0000, Loss 3.4066, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17830 | Time 24.6955(24.2347) | Bit/dim 3.4192(3.3991) | Xent 0.0000(0.0000) | Loss 8.7672(9.6909) | Error 0.0000(0.0000) Steps 946(954.28) | Grad Norm 1.6472(2.0998) | Total Time 0.00(0.00)\n",
      "Iter 17840 | Time 24.2543(24.2722) | Bit/dim 3.4221(3.4053) | Xent 0.0000(0.0000) | Loss 8.9322(9.4546) | Error 0.0000(0.0000) Steps 958(955.03) | Grad Norm 1.6419(2.1191) | Total Time 0.00(0.00)\n",
      "Iter 17850 | Time 23.9295(24.2793) | Bit/dim 3.4026(3.4029) | Xent 0.0000(0.0000) | Loss 8.8060(9.2696) | Error 0.0000(0.0000) Steps 952(954.44) | Grad Norm 1.8122(2.0184) | Total Time 0.00(0.00)\n",
      "Iter 17860 | Time 23.9768(24.2785) | Bit/dim 3.4337(3.4039) | Xent 0.0000(0.0000) | Loss 8.8177(9.1266) | Error 0.0000(0.0000) Steps 970(952.93) | Grad Norm 1.8240(1.8576) | Total Time 0.00(0.00)\n",
      "Iter 17870 | Time 23.3378(24.2900) | Bit/dim 3.4031(3.4029) | Xent 0.0000(0.0000) | Loss 8.5926(9.0300) | Error 0.0000(0.0000) Steps 922(951.74) | Grad Norm 3.0706(1.8654) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0325 | Time 109.5171, Epoch Time 1461.6312(1431.2951), Bit/dim 3.4072(best: 3.4046), Xent 0.0000, Loss 3.4072, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17880 | Time 24.0249(24.2363) | Bit/dim 3.4472(3.4047) | Xent 0.0000(0.0000) | Loss 8.8448(9.8400) | Error 0.0000(0.0000) Steps 952(954.67) | Grad Norm 1.2866(1.8023) | Total Time 0.00(0.00)\n",
      "Iter 17890 | Time 23.3982(24.2550) | Bit/dim 3.3868(3.4029) | Xent 0.0000(0.0000) | Loss 8.7674(9.5553) | Error 0.0000(0.0000) Steps 952(955.74) | Grad Norm 1.4778(1.6625) | Total Time 0.00(0.00)\n",
      "Iter 17900 | Time 24.0604(24.3115) | Bit/dim 3.3772(3.4024) | Xent 0.0000(0.0000) | Loss 8.7935(9.3546) | Error 0.0000(0.0000) Steps 964(957.69) | Grad Norm 1.9405(1.5908) | Total Time 0.00(0.00)\n",
      "Iter 17910 | Time 25.2054(24.4155) | Bit/dim 3.4137(3.3997) | Xent 0.0000(0.0000) | Loss 8.7993(9.2043) | Error 0.0000(0.0000) Steps 952(959.93) | Grad Norm 1.1850(1.6211) | Total Time 0.00(0.00)\n",
      "Iter 17920 | Time 25.1081(24.5206) | Bit/dim 3.4476(3.4044) | Xent 0.0000(0.0000) | Loss 8.9517(9.1030) | Error 0.0000(0.0000) Steps 1000(959.05) | Grad Norm 1.9308(1.7663) | Total Time 0.00(0.00)\n",
      "Iter 17930 | Time 25.6534(24.5458) | Bit/dim 3.4143(3.4058) | Xent 0.0000(0.0000) | Loss 8.9047(9.0191) | Error 0.0000(0.0000) Steps 988(957.01) | Grad Norm 2.0565(1.8478) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0326 | Time 109.5622, Epoch Time 1478.1376(1432.7004), Bit/dim 3.4091(best: 3.4046), Xent 0.0000, Loss 3.4091, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17940 | Time 24.1701(24.4752) | Bit/dim 3.4298(3.4051) | Xent 0.0000(0.0000) | Loss 8.8346(9.7177) | Error 0.0000(0.0000) Steps 976(956.76) | Grad Norm 1.0543(1.8519) | Total Time 0.00(0.00)\n",
      "Iter 17950 | Time 24.5269(24.4511) | Bit/dim 3.3898(3.4029) | Xent 0.0000(0.0000) | Loss 8.7262(9.4550) | Error 0.0000(0.0000) Steps 946(956.00) | Grad Norm 1.6115(1.8279) | Total Time 0.00(0.00)\n",
      "Iter 17960 | Time 23.6827(24.4618) | Bit/dim 3.4026(3.4028) | Xent 0.0000(0.0000) | Loss 8.7864(9.2732) | Error 0.0000(0.0000) Steps 946(955.91) | Grad Norm 1.3338(1.7086) | Total Time 0.00(0.00)\n",
      "Iter 17970 | Time 24.7878(24.4021) | Bit/dim 3.4309(3.4041) | Xent 0.0000(0.0000) | Loss 8.5699(9.1328) | Error 0.0000(0.0000) Steps 904(952.05) | Grad Norm 1.0928(1.6839) | Total Time 0.00(0.00)\n",
      "Iter 17980 | Time 24.6098(24.4089) | Bit/dim 3.3836(3.4043) | Xent 0.0000(0.0000) | Loss 8.6735(9.0333) | Error 0.0000(0.0000) Steps 970(954.74) | Grad Norm 2.3671(1.7572) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0327 | Time 109.6785, Epoch Time 1466.3679(1433.7104), Bit/dim 3.4070(best: 3.4046), Xent 0.0000, Loss 3.4070, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17990 | Time 24.5941(24.4024) | Bit/dim 3.4070(3.4040) | Xent 0.0000(0.0000) | Loss 8.8545(9.8691) | Error 0.0000(0.0000) Steps 976(957.41) | Grad Norm 2.9205(1.8220) | Total Time 0.00(0.00)\n",
      "Iter 18000 | Time 25.7170(24.4568) | Bit/dim 3.4098(3.4038) | Xent 0.0000(0.0000) | Loss 8.7350(9.5722) | Error 0.0000(0.0000) Steps 952(957.00) | Grad Norm 1.4970(1.7987) | Total Time 0.00(0.00)\n",
      "Iter 18010 | Time 24.0151(24.4054) | Bit/dim 3.4363(3.4026) | Xent 0.0000(0.0000) | Loss 8.7600(9.3635) | Error 0.0000(0.0000) Steps 928(958.47) | Grad Norm 1.9334(1.8576) | Total Time 0.00(0.00)\n",
      "Iter 18020 | Time 24.2149(24.3975) | Bit/dim 3.3940(3.4009) | Xent 0.0000(0.0000) | Loss 8.6515(9.1885) | Error 0.0000(0.0000) Steps 934(957.88) | Grad Norm 1.3605(1.8441) | Total Time 0.00(0.00)\n",
      "Iter 18030 | Time 24.2627(24.4029) | Bit/dim 3.3795(3.4014) | Xent 0.0000(0.0000) | Loss 8.6333(9.0794) | Error 0.0000(0.0000) Steps 922(956.80) | Grad Norm 1.5608(1.8570) | Total Time 0.00(0.00)\n",
      "Iter 18040 | Time 24.7760(24.4511) | Bit/dim 3.4069(3.4023) | Xent 0.0000(0.0000) | Loss 8.7168(8.9902) | Error 0.0000(0.0000) Steps 970(958.40) | Grad Norm 2.2641(690.5571) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0328 | Time 108.0438, Epoch Time 1471.9282(1434.8569), Bit/dim 3.4086(best: 3.4046), Xent 0.0000, Loss 3.4086, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18050 | Time 25.1638(24.4482) | Bit/dim 3.3883(3.4006) | Xent 0.0000(0.0000) | Loss 8.5920(9.7275) | Error 0.0000(0.0000) Steps 1018(964.27) | Grad Norm 1.7481(509.6701) | Total Time 0.00(0.00)\n",
      "Iter 18060 | Time 24.1991(24.5849) | Bit/dim 3.3832(3.3995) | Xent 0.0000(0.0000) | Loss 8.7928(9.4744) | Error 0.0000(0.0000) Steps 1000(968.98) | Grad Norm 2.1577(376.2988) | Total Time 0.00(0.00)\n",
      "Iter 18070 | Time 24.9530(24.7231) | Bit/dim 3.3833(3.4014) | Xent 0.0000(0.0000) | Loss 8.8016(9.2958) | Error 0.0000(0.0000) Steps 994(976.16) | Grad Norm 1.0491(278.0884) | Total Time 0.00(0.00)\n",
      "Iter 18080 | Time 24.8821(24.7943) | Bit/dim 3.4144(3.4007) | Xent 0.0000(0.0000) | Loss 8.8853(9.1617) | Error 0.0000(0.0000) Steps 1006(975.27) | Grad Norm 2.0331(205.7918) | Total Time 0.00(0.00)\n",
      "Iter 18090 | Time 24.3069(24.8163) | Bit/dim 3.3716(3.4005) | Xent 0.0000(0.0000) | Loss 8.6022(9.0503) | Error 0.0000(0.0000) Steps 964(977.41) | Grad Norm 2.4146(152.3231) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0329 | Time 109.7676, Epoch Time 1495.6080(1436.6795), Bit/dim 3.4082(best: 3.4046), Xent 0.0000, Loss 3.4082, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18100 | Time 25.3418(24.7940) | Bit/dim 3.4003(3.4012) | Xent 0.0000(0.0000) | Loss 8.9269(9.9522) | Error 0.0000(0.0000) Steps 1042(983.24) | Grad Norm 1.6283(112.7507) | Total Time 0.00(0.00)\n",
      "Iter 18110 | Time 24.9567(24.8599) | Bit/dim 3.3886(3.4000) | Xent 0.0000(0.0000) | Loss 8.6806(9.6390) | Error 0.0000(0.0000) Steps 958(983.57) | Grad Norm 1.7408(83.4887) | Total Time 0.00(0.00)\n",
      "Iter 18120 | Time 24.9726(24.8117) | Bit/dim 3.4173(3.4016) | Xent 0.0000(0.0000) | Loss 8.7583(9.4177) | Error 0.0000(0.0000) Steps 976(984.21) | Grad Norm 1.8065(61.9901) | Total Time 0.00(0.00)\n",
      "Iter 18130 | Time 25.1144(24.8371) | Bit/dim 3.3710(3.4013) | Xent 0.0000(0.0000) | Loss 8.7864(9.2465) | Error 0.0000(0.0000) Steps 946(983.15) | Grad Norm 1.6682(46.1946) | Total Time 0.00(0.00)\n",
      "Iter 18140 | Time 25.2445(24.8205) | Bit/dim 3.3872(3.4010) | Xent 0.0000(0.0000) | Loss 8.8609(9.1219) | Error 0.0000(0.0000) Steps 1036(982.21) | Grad Norm 2.6924(34.6376) | Total Time 0.00(0.00)\n",
      "Iter 18150 | Time 24.6722(24.7320) | Bit/dim 3.3983(3.4010) | Xent 0.0000(0.0000) | Loss 8.9029(9.0276) | Error 0.0000(0.0000) Steps 952(977.89) | Grad Norm 2.1214(26.1026) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0330 | Time 111.6147, Epoch Time 1492.7069(1438.3603), Bit/dim 3.4100(best: 3.4046), Xent 0.0000, Loss 3.4100, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18160 | Time 24.7044(24.7615) | Bit/dim 3.4240(3.4021) | Xent 0.0000(0.0000) | Loss 8.8393(9.8123) | Error 0.0000(0.0000) Steps 1000(980.30) | Grad Norm 2.3354(19.8305) | Total Time 0.00(0.00)\n",
      "Iter 18170 | Time 24.4370(24.7921) | Bit/dim 3.3901(3.4031) | Xent 0.0000(0.0000) | Loss 8.7698(9.5341) | Error 0.0000(0.0000) Steps 976(975.43) | Grad Norm 2.1053(15.2001) | Total Time 0.00(0.00)\n",
      "Iter 18180 | Time 25.0504(24.8415) | Bit/dim 3.3723(3.4005) | Xent 0.0000(0.0000) | Loss 8.7139(9.3291) | Error 0.0000(0.0000) Steps 982(976.53) | Grad Norm 1.3187(11.6271) | Total Time 0.00(0.00)\n",
      "Iter 18190 | Time 23.7354(24.7556) | Bit/dim 3.3970(3.3982) | Xent 0.0000(0.0000) | Loss 8.8380(9.1866) | Error 0.0000(0.0000) Steps 964(977.03) | Grad Norm 0.9396(8.9467) | Total Time 0.00(0.00)\n",
      "Iter 18200 | Time 24.5509(24.7967) | Bit/dim 3.3619(3.4000) | Xent 0.0000(0.0000) | Loss 8.6792(9.0720) | Error 0.0000(0.0000) Steps 952(975.33) | Grad Norm 1.5627(6.9807) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0331 | Time 110.7813, Epoch Time 1493.1699(1440.0046), Bit/dim 3.4051(best: 3.4046), Xent 0.0000, Loss 3.4051, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18210 | Time 24.3092(24.7427) | Bit/dim 3.3628(3.3997) | Xent 0.0000(0.0000) | Loss 8.7233(9.9174) | Error 0.0000(0.0000) Steps 970(971.24) | Grad Norm 1.9076(5.6305) | Total Time 0.00(0.00)\n",
      "Iter 18220 | Time 24.8730(24.6998) | Bit/dim 3.4036(3.4010) | Xent 0.0000(0.0000) | Loss 8.8377(9.6153) | Error 0.0000(0.0000) Steps 946(971.48) | Grad Norm 1.9756(4.5624) | Total Time 0.00(0.00)\n",
      "Iter 18230 | Time 24.4777(24.7220) | Bit/dim 3.3976(3.4015) | Xent 0.0000(0.0000) | Loss 8.8497(9.3964) | Error 0.0000(0.0000) Steps 1018(975.52) | Grad Norm 1.6951(3.9086) | Total Time 0.00(0.00)\n",
      "Iter 18240 | Time 25.1249(24.6749) | Bit/dim 3.4099(3.4009) | Xent 0.0000(0.0000) | Loss 8.8821(9.2281) | Error 0.0000(0.0000) Steps 1030(976.62) | Grad Norm 2.2115(3.5320) | Total Time 0.00(0.00)\n",
      "Iter 18250 | Time 24.5698(24.6849) | Bit/dim 3.3770(3.4012) | Xent 0.0000(0.0000) | Loss 8.6976(9.1054) | Error 0.0000(0.0000) Steps 946(975.53) | Grad Norm 4.2194(3.2906) | Total Time 0.00(0.00)\n",
      "Iter 18260 | Time 25.0845(24.7171) | Bit/dim 3.4149(3.4016) | Xent 0.0000(0.0000) | Loss 8.7441(9.0189) | Error 0.0000(0.0000) Steps 1006(975.41) | Grad Norm 2.4042(3.1292) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0332 | Time 110.7930, Epoch Time 1486.6841(1441.4050), Bit/dim 3.4081(best: 3.4046), Xent 0.0000, Loss 3.4081, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18270 | Time 24.7506(24.6832) | Bit/dim 3.4261(3.4037) | Xent 0.0000(0.0000) | Loss 8.7801(9.7501) | Error 0.0000(0.0000) Steps 994(977.12) | Grad Norm 2.6616(2.9084) | Total Time 0.00(0.00)\n",
      "Iter 18280 | Time 24.4015(24.6691) | Bit/dim 3.3960(3.4038) | Xent 0.0000(0.0000) | Loss 8.7133(9.4917) | Error 0.0000(0.0000) Steps 970(975.31) | Grad Norm 1.6044(2.6508) | Total Time 0.00(0.00)\n",
      "Iter 18290 | Time 25.3213(24.7740) | Bit/dim 3.4168(3.4026) | Xent 0.0000(0.0000) | Loss 8.7589(9.3005) | Error 0.0000(0.0000) Steps 1000(975.50) | Grad Norm 3.1486(2.5932) | Total Time 0.00(0.00)\n",
      "Iter 18300 | Time 24.6951(24.6832) | Bit/dim 3.3975(3.4031) | Xent 0.0000(0.0000) | Loss 8.6595(9.1672) | Error 0.0000(0.0000) Steps 946(971.48) | Grad Norm 2.6500(2.6052) | Total Time 0.00(0.00)\n",
      "Iter 18310 | Time 23.7433(24.7535) | Bit/dim 3.3856(3.4002) | Xent 0.0000(0.0000) | Loss 8.7309(9.0488) | Error 0.0000(0.0000) Steps 976(970.27) | Grad Norm 1.3370(2.4501) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 111.0992, Epoch Time 1490.7379(1442.8849), Bit/dim 3.4056(best: 3.4046), Xent 0.0000, Loss 3.4056, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18320 | Time 24.1140(24.7652) | Bit/dim 3.3938(3.4004) | Xent 0.0000(0.0000) | Loss 8.7884(9.9169) | Error 0.0000(0.0000) Steps 958(972.34) | Grad Norm 1.2910(2.2258) | Total Time 0.00(0.00)\n",
      "Iter 18330 | Time 24.3567(24.7282) | Bit/dim 3.3902(3.3987) | Xent 0.0000(0.0000) | Loss 8.6217(9.6024) | Error 0.0000(0.0000) Steps 958(970.56) | Grad Norm 1.2030(2.0237) | Total Time 0.00(0.00)\n",
      "Iter 18340 | Time 24.4550(24.6999) | Bit/dim 3.3996(3.4004) | Xent 0.0000(0.0000) | Loss 8.6037(9.3816) | Error 0.0000(0.0000) Steps 958(969.41) | Grad Norm 1.9574(1.8365) | Total Time 0.00(0.00)\n",
      "Iter 18350 | Time 24.9350(24.7614) | Bit/dim 3.4173(3.3989) | Xent 0.0000(0.0000) | Loss 8.7906(9.2140) | Error 0.0000(0.0000) Steps 952(969.52) | Grad Norm 1.0237(1.8495) | Total Time 0.00(0.00)\n",
      "Iter 18360 | Time 23.6262(24.6923) | Bit/dim 3.3948(3.4016) | Xent 0.0000(0.0000) | Loss 8.7678(9.0976) | Error 0.0000(0.0000) Steps 964(968.83) | Grad Norm 1.4776(1.7555) | Total Time 0.00(0.00)\n",
      "Iter 18370 | Time 24.1402(24.6456) | Bit/dim 3.3847(3.4010) | Xent 0.0000(0.0000) | Loss 8.7916(9.0008) | Error 0.0000(0.0000) Steps 976(970.09) | Grad Norm 1.4343(1.6218) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 112.2029, Epoch Time 1485.9815(1444.1778), Bit/dim 3.4035(best: 3.4046), Xent 0.0000, Loss 3.4035, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18380 | Time 23.8507(24.6290) | Bit/dim 3.4033(3.4003) | Xent 0.0000(0.0000) | Loss 8.7627(9.7744) | Error 0.0000(0.0000) Steps 946(970.78) | Grad Norm 2.0999(1.6080) | Total Time 0.00(0.00)\n",
      "Iter 18390 | Time 25.0132(24.6268) | Bit/dim 3.4016(3.4014) | Xent 0.0000(0.0000) | Loss 8.6709(9.5107) | Error 0.0000(0.0000) Steps 982(972.86) | Grad Norm 1.4507(1.5692) | Total Time 0.00(0.00)\n",
      "Iter 18400 | Time 24.3301(24.6760) | Bit/dim 3.3940(3.4012) | Xent 0.0000(0.0000) | Loss 8.7903(9.3136) | Error 0.0000(0.0000) Steps 964(973.75) | Grad Norm 1.2932(1.5351) | Total Time 0.00(0.00)\n",
      "Iter 18410 | Time 26.6301(24.7503) | Bit/dim 3.4205(3.4002) | Xent 0.0000(0.0000) | Loss 8.8393(9.1718) | Error 0.0000(0.0000) Steps 964(973.10) | Grad Norm 2.4057(1.6428) | Total Time 0.00(0.00)\n",
      "Iter 18420 | Time 24.1994(24.7893) | Bit/dim 3.3689(3.3994) | Xent 0.0000(0.0000) | Loss 8.6427(9.0624) | Error 0.0000(0.0000) Steps 964(975.56) | Grad Norm 3.1324(1.8010) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 110.1286, Epoch Time 1491.7969(1445.6064), Bit/dim 3.4105(best: 3.4035), Xent 0.0000, Loss 3.4105, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18430 | Time 24.9616(24.7799) | Bit/dim 3.4106(3.4023) | Xent 0.0000(0.0000) | Loss 8.7428(9.9509) | Error 0.0000(0.0000) Steps 952(971.79) | Grad Norm 1.9798(1.8911) | Total Time 0.00(0.00)\n",
      "Iter 18440 | Time 24.9777(24.7598) | Bit/dim 3.4073(3.4011) | Xent 0.0000(0.0000) | Loss 8.7307(9.6401) | Error 0.0000(0.0000) Steps 970(970.84) | Grad Norm 2.0036(1.9640) | Total Time 0.00(0.00)\n",
      "Iter 18450 | Time 24.0513(24.7461) | Bit/dim 3.3989(3.4029) | Xent 0.0000(0.0000) | Loss 8.8092(9.4144) | Error 0.0000(0.0000) Steps 958(971.75) | Grad Norm 1.2990(1.8581) | Total Time 0.00(0.00)\n",
      "Iter 18460 | Time 24.9271(24.7764) | Bit/dim 3.3973(3.4017) | Xent 0.0000(0.0000) | Loss 8.7344(9.2455) | Error 0.0000(0.0000) Steps 994(974.16) | Grad Norm 1.9607(1.8340) | Total Time 0.00(0.00)\n",
      "Iter 18470 | Time 24.6674(24.7594) | Bit/dim 3.4029(3.3996) | Xent 0.0000(0.0000) | Loss 8.7144(9.1121) | Error 0.0000(0.0000) Steps 940(970.56) | Grad Norm 1.2417(1.7970) | Total Time 0.00(0.00)\n",
      "Iter 18480 | Time 24.8725(24.7391) | Bit/dim 3.3972(3.4000) | Xent 0.0000(0.0000) | Loss 8.7179(9.0236) | Error 0.0000(0.0000) Steps 1000(973.20) | Grad Norm 1.8943(1.8246) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 111.5648, Epoch Time 1490.2106(1446.9445), Bit/dim 3.4102(best: 3.4035), Xent 0.0000, Loss 3.4102, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18490 | Time 25.4445(24.7415) | Bit/dim 3.4093(3.3986) | Xent 0.0000(0.0000) | Loss 8.8881(9.7771) | Error 0.0000(0.0000) Steps 1012(974.57) | Grad Norm 2.4873(1.8611) | Total Time 0.00(0.00)\n",
      "Iter 18500 | Time 25.1511(24.8387) | Bit/dim 3.3615(3.4002) | Xent 0.0000(0.0000) | Loss 8.6276(9.5093) | Error 0.0000(0.0000) Steps 946(972.79) | Grad Norm 1.3012(1.7679) | Total Time 0.00(0.00)\n",
      "Iter 18510 | Time 24.0684(24.7333) | Bit/dim 3.3855(3.4006) | Xent 0.0000(0.0000) | Loss 8.8099(9.3216) | Error 0.0000(0.0000) Steps 976(972.90) | Grad Norm 1.6904(1.7467) | Total Time 0.00(0.00)\n",
      "Iter 18520 | Time 24.2745(24.7410) | Bit/dim 3.4227(3.4009) | Xent 0.0000(0.0000) | Loss 8.7547(9.1689) | Error 0.0000(0.0000) Steps 970(972.53) | Grad Norm 1.6796(1.7131) | Total Time 0.00(0.00)\n",
      "Iter 18530 | Time 24.6924(24.7971) | Bit/dim 3.3847(3.4017) | Xent 0.0000(0.0000) | Loss 8.5780(9.0456) | Error 0.0000(0.0000) Steps 976(972.03) | Grad Norm 1.5118(1.7565) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 110.4711, Epoch Time 1492.9235(1448.3239), Bit/dim 3.4062(best: 3.4035), Xent 0.0000, Loss 3.4062, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18540 | Time 25.2468(24.8755) | Bit/dim 3.3657(3.4017) | Xent 0.0000(0.0000) | Loss 8.5677(9.8846) | Error 0.0000(0.0000) Steps 952(974.01) | Grad Norm 1.7365(1.8447) | Total Time 0.00(0.00)\n",
      "Iter 18550 | Time 24.8804(24.8860) | Bit/dim 3.4174(3.4040) | Xent 0.0000(0.0000) | Loss 8.7903(9.5902) | Error 0.0000(0.0000) Steps 1000(974.00) | Grad Norm 2.4882(1.9745) | Total Time 0.00(0.00)\n",
      "Iter 18560 | Time 24.8152(24.9386) | Bit/dim 3.4430(3.4060) | Xent 0.0000(0.0000) | Loss 8.8228(9.3799) | Error 0.0000(0.0000) Steps 988(972.26) | Grad Norm 1.4919(1.9564) | Total Time 0.00(0.00)\n",
      "Iter 18570 | Time 24.7258(24.9117) | Bit/dim 3.3458(3.4040) | Xent 0.0000(0.0000) | Loss 8.6899(9.2267) | Error 0.0000(0.0000) Steps 1000(971.01) | Grad Norm 2.2931(1.9485) | Total Time 0.00(0.00)\n",
      "Iter 18580 | Time 25.0479(24.9411) | Bit/dim 3.4224(3.4017) | Xent 0.0000(0.0000) | Loss 8.8055(9.1093) | Error 0.0000(0.0000) Steps 970(970.50) | Grad Norm 2.1043(1.9662) | Total Time 0.00(0.00)\n",
      "Iter 18590 | Time 25.3246(24.9022) | Bit/dim 3.3997(3.4014) | Xent 0.0000(0.0000) | Loss 8.7187(9.0182) | Error 0.0000(0.0000) Steps 982(972.45) | Grad Norm 1.4431(1.8481) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 110.2674, Epoch Time 1502.3031(1449.9433), Bit/dim 3.4063(best: 3.4035), Xent 0.0000, Loss 3.4063, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18600 | Time 23.4488(24.7794) | Bit/dim 3.4039(3.4020) | Xent 0.0000(0.0000) | Loss 8.8712(9.7645) | Error 0.0000(0.0000) Steps 964(972.20) | Grad Norm 1.4244(1.7840) | Total Time 0.00(0.00)\n",
      "Iter 18610 | Time 24.4666(24.7128) | Bit/dim 3.4045(3.4009) | Xent 0.0000(0.0000) | Loss 8.8617(9.4908) | Error 0.0000(0.0000) Steps 970(971.60) | Grad Norm 2.6678(1.9123) | Total Time 0.00(0.00)\n",
      "Iter 18620 | Time 24.6220(24.7500) | Bit/dim 3.3676(3.3992) | Xent 0.0000(0.0000) | Loss 8.8025(9.3024) | Error 0.0000(0.0000) Steps 964(970.46) | Grad Norm 1.2074(91.1540) | Total Time 0.00(0.00)\n",
      "Iter 18630 | Time 24.9707(24.8201) | Bit/dim 3.4267(3.3986) | Xent 0.0000(0.0000) | Loss 8.8142(9.1617) | Error 0.0000(0.0000) Steps 976(972.05) | Grad Norm 1.9318(67.6387) | Total Time 0.00(0.00)\n",
      "Iter 18640 | Time 25.5178(24.8746) | Bit/dim 3.3771(3.3955) | Xent 0.0000(0.0000) | Loss 8.8848(9.0566) | Error 0.0000(0.0000) Steps 994(973.31) | Grad Norm 3.3654(51.1628) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 111.2150, Epoch Time 1493.8590(1451.2608), Bit/dim 3.4074(best: 3.4035), Xent 0.0000, Loss 3.4074, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18650 | Time 24.6433(24.8711) | Bit/dim 3.4214(3.4005) | Xent 0.0000(0.0000) | Loss 8.8065(9.9357) | Error 0.0000(0.0000) Steps 976(974.93) | Grad Norm 1.2377(38.2142) | Total Time 0.00(0.00)\n",
      "Iter 18660 | Time 24.4817(24.8090) | Bit/dim 3.4241(3.3996) | Xent 0.0000(0.0000) | Loss 8.7939(9.6295) | Error 0.0000(0.0000) Steps 1006(978.31) | Grad Norm 1.4608(28.6753) | Total Time 0.00(0.00)\n",
      "Iter 18670 | Time 25.1206(24.7722) | Bit/dim 3.4262(3.4004) | Xent 0.0000(0.0000) | Loss 8.8427(9.4122) | Error 0.0000(0.0000) Steps 982(978.26) | Grad Norm 1.0222(21.5098) | Total Time 0.00(0.00)\n",
      "Iter 18680 | Time 25.1423(24.8152) | Bit/dim 3.3820(3.4010) | Xent 0.0000(0.0000) | Loss 8.6398(9.2528) | Error 0.0000(0.0000) Steps 1006(979.28) | Grad Norm 2.0075(16.3072) | Total Time 0.00(0.00)\n",
      "Iter 18690 | Time 24.4818(24.8075) | Bit/dim 3.4298(3.4015) | Xent 0.0000(0.0000) | Loss 8.8603(9.1343) | Error 0.0000(0.0000) Steps 982(980.67) | Grad Norm 2.4681(12.4579) | Total Time 0.00(0.00)\n",
      "Iter 18700 | Time 24.7626(24.7717) | Bit/dim 3.4154(3.3998) | Xent 0.0000(0.0000) | Loss 8.8049(9.0318) | Error 0.0000(0.0000) Steps 964(977.80) | Grad Norm 1.8866(9.6596) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 111.5079, Epoch Time 1490.2186(1452.4295), Bit/dim 3.4066(best: 3.4035), Xent 0.0000, Loss 3.4066, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18710 | Time 24.7834(24.8097) | Bit/dim 3.4145(3.3996) | Xent 0.0000(0.0000) | Loss 8.7190(9.7799) | Error 0.0000(0.0000) Steps 982(978.07) | Grad Norm 1.6898(7.4952) | Total Time 0.00(0.00)\n",
      "Iter 18720 | Time 24.2518(24.8175) | Bit/dim 3.3491(3.3979) | Xent 0.0000(0.0000) | Loss 8.7126(9.5158) | Error 0.0000(0.0000) Steps 988(978.76) | Grad Norm 1.6831(5.9319) | Total Time 0.00(0.00)\n",
      "Iter 18730 | Time 24.8288(24.8766) | Bit/dim 3.4035(3.3988) | Xent 0.0000(0.0000) | Loss 8.7119(9.3159) | Error 0.0000(0.0000) Steps 976(976.57) | Grad Norm 1.5329(4.7796) | Total Time 0.00(0.00)\n",
      "Iter 18740 | Time 24.4146(24.8821) | Bit/dim 3.4257(3.3994) | Xent 0.0000(0.0000) | Loss 8.7934(9.1677) | Error 0.0000(0.0000) Steps 952(975.94) | Grad Norm 2.4887(4.0346) | Total Time 0.00(0.00)\n",
      "Iter 18750 | Time 24.8050(24.8703) | Bit/dim 3.3915(3.4008) | Xent 0.0000(0.0000) | Loss 8.6306(9.0574) | Error 0.0000(0.0000) Steps 982(975.12) | Grad Norm 1.3052(3.4572) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 111.9714, Epoch Time 1500.8708(1453.8827), Bit/dim 3.4085(best: 3.4035), Xent 0.0000, Loss 3.4085, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18760 | Time 24.4033(24.8343) | Bit/dim 3.3867(3.4025) | Xent 0.0000(0.0000) | Loss 8.6806(9.9456) | Error 0.0000(0.0000) Steps 952(972.95) | Grad Norm 1.4170(3.1661) | Total Time 0.00(0.00)\n",
      "Iter 18770 | Time 26.0517(24.8725) | Bit/dim 3.3821(3.3995) | Xent 0.0000(0.0000) | Loss 8.7433(9.6361) | Error 0.0000(0.0000) Steps 994(977.70) | Grad Norm 2.2102(2.8915) | Total Time 0.00(0.00)\n",
      "Iter 18780 | Time 25.1977(24.8284) | Bit/dim 3.3612(3.3972) | Xent 0.0000(0.0000) | Loss 8.7407(9.4009) | Error 0.0000(0.0000) Steps 982(977.01) | Grad Norm 1.7284(2.4948) | Total Time 0.00(0.00)\n",
      "Iter 18790 | Time 24.7388(24.8340) | Bit/dim 3.3953(3.3987) | Xent 0.0000(0.0000) | Loss 8.6877(9.2377) | Error 0.0000(0.0000) Steps 982(977.83) | Grad Norm 1.1722(2.2190) | Total Time 0.00(0.00)\n",
      "Iter 18800 | Time 24.3319(24.8405) | Bit/dim 3.4085(3.4013) | Xent 0.0000(0.0000) | Loss 8.6459(9.1067) | Error 0.0000(0.0000) Steps 964(977.85) | Grad Norm 1.4794(2.0132) | Total Time 0.00(0.00)\n",
      "Iter 18810 | Time 25.6051(24.9101) | Bit/dim 3.3912(3.4010) | Xent 0.0000(0.0000) | Loss 8.8580(9.0271) | Error 0.0000(0.0000) Steps 988(979.51) | Grad Norm 1.9591(1.9235) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 112.2909, Epoch Time 1497.6247(1455.1950), Bit/dim 3.4071(best: 3.4035), Xent 0.0000, Loss 3.4071, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18820 | Time 25.0476(24.9482) | Bit/dim 3.4246(3.4020) | Xent 0.0000(0.0000) | Loss 8.9367(9.8046) | Error 0.0000(0.0000) Steps 982(978.45) | Grad Norm 2.1249(1.8750) | Total Time 0.00(0.00)\n",
      "Iter 18830 | Time 24.9329(25.0729) | Bit/dim 3.3919(3.3997) | Xent 0.0000(0.0000) | Loss 8.7501(9.5235) | Error 0.0000(0.0000) Steps 994(977.54) | Grad Norm 2.0589(1.8872) | Total Time 0.00(0.00)\n",
      "Iter 18840 | Time 26.0150(25.0946) | Bit/dim 3.3916(3.3985) | Xent 0.0000(0.0000) | Loss 8.5903(9.3182) | Error 0.0000(0.0000) Steps 1030(979.26) | Grad Norm 1.9242(1.8989) | Total Time 0.00(0.00)\n",
      "Iter 18850 | Time 25.1967(25.1695) | Bit/dim 3.3994(3.3996) | Xent 0.0000(0.0000) | Loss 8.6840(9.1761) | Error 0.0000(0.0000) Steps 970(979.86) | Grad Norm 2.1283(1.9494) | Total Time 0.00(0.00)\n",
      "Iter 18860 | Time 25.0653(25.1457) | Bit/dim 3.4068(3.3989) | Xent 0.0000(0.0000) | Loss 8.6090(9.0637) | Error 0.0000(0.0000) Steps 952(976.31) | Grad Norm 1.7007(3571.3627) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 112.1304, Epoch Time 1516.7381(1457.0413), Bit/dim 3.4035(best: 3.4035), Xent 0.0000, Loss 3.4035, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18870 | Time 24.3837(25.1061) | Bit/dim 3.4167(3.3997) | Xent 0.0000(0.0000) | Loss 8.6379(9.8976) | Error 0.0000(0.0000) Steps 976(975.99) | Grad Norm 2.8469(2634.0758) | Total Time 0.00(0.00)\n",
      "Iter 18880 | Time 25.0264(25.0931) | Bit/dim 3.3947(3.3991) | Xent 0.0000(0.0000) | Loss 8.6124(9.5893) | Error 0.0000(0.0000) Steps 952(973.39) | Grad Norm 2.7104(1942.8953) | Total Time 0.00(0.00)\n",
      "Iter 18890 | Time 24.6746(25.0672) | Bit/dim 3.3793(3.3982) | Xent 0.0000(0.0000) | Loss 8.7368(9.3672) | Error 0.0000(0.0000) Steps 946(968.51) | Grad Norm 4.1417(1433.3813) | Total Time 0.00(0.00)\n",
      "Iter 18900 | Time 24.5699(24.9599) | Bit/dim 3.4189(3.3984) | Xent 0.0000(0.0000) | Loss 8.7071(9.1961) | Error 0.0000(0.0000) Steps 988(963.84) | Grad Norm 3.4096(1057.6497) | Total Time 0.00(0.00)\n",
      "Iter 18910 | Time 25.2755(24.8150) | Bit/dim 3.4020(3.4004) | Xent 0.0000(0.0000) | Loss 8.8005(9.0814) | Error 0.0000(0.0000) Steps 988(961.80) | Grad Norm 2.3574(780.5217) | Total Time 0.00(0.00)\n",
      "Iter 18920 | Time 25.2178(24.8024) | Bit/dim 3.4068(3.4020) | Xent 0.0000(0.0000) | Loss 8.7649(8.9969) | Error 0.0000(0.0000) Steps 946(960.92) | Grad Norm 1.0022(576.1889) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 111.9102, Epoch Time 1492.9882(1458.1197), Bit/dim 3.4063(best: 3.4035), Xent 0.0000, Loss 3.4063, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18930 | Time 23.5547(24.7534) | Bit/dim 3.3829(3.4039) | Xent 0.0000(0.0000) | Loss 8.7851(9.7122) | Error 0.0000(0.0000) Steps 934(957.41) | Grad Norm 1.5576(425.4190) | Total Time 0.00(0.00)\n",
      "Iter 18940 | Time 23.6372(24.6674) | Bit/dim 3.4060(3.4049) | Xent 0.0000(0.0000) | Loss 8.7776(9.4566) | Error 0.0000(0.0000) Steps 910(955.81) | Grad Norm 3.7234(314.2937) | Total Time 0.00(0.00)\n",
      "Iter 18950 | Time 24.7567(24.5813) | Bit/dim 3.3916(3.4042) | Xent 0.0000(0.0000) | Loss 8.7007(9.2611) | Error 0.0000(0.0000) Steps 952(956.53) | Grad Norm 2.5583(232.3623) | Total Time 0.00(0.00)\n",
      "Iter 18960 | Time 24.5077(24.5535) | Bit/dim 3.3662(3.4016) | Xent 0.0000(0.0000) | Loss 8.6616(9.1237) | Error 0.0000(0.0000) Steps 982(956.42) | Grad Norm 4.3152(172.0598) | Total Time 0.00(0.00)\n",
      "Iter 18970 | Time 25.0927(24.6038) | Bit/dim 3.3658(3.3967) | Xent 0.0000(0.0000) | Loss 8.6686(9.0180) | Error 0.0000(0.0000) Steps 1012(959.35) | Grad Norm 2.6307(127.7111) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 111.6337, Epoch Time 1479.1479(1458.7505), Bit/dim 3.4058(best: 3.4035), Xent 0.0000, Loss 3.4058, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18980 | Time 24.8110(24.6128) | Bit/dim 3.3913(3.3940) | Xent 0.0000(0.0000) | Loss 8.7659(9.8705) | Error 0.0000(0.0000) Steps 970(963.46) | Grad Norm 1.6442(94.8833) | Total Time 0.00(0.00)\n",
      "Iter 18990 | Time 24.6399(24.6253) | Bit/dim 3.4036(3.3950) | Xent 0.0000(0.0000) | Loss 8.8219(9.5723) | Error 0.0000(0.0000) Steps 964(961.49) | Grad Norm 2.4416(70.4518) | Total Time 0.00(0.00)\n",
      "Iter 19000 | Time 25.1343(24.7147) | Bit/dim 3.4006(3.3953) | Xent 0.0000(0.0000) | Loss 8.8253(9.3531) | Error 0.0000(0.0000) Steps 976(961.54) | Grad Norm 1.3083(52.4130) | Total Time 0.00(0.00)\n",
      "Iter 19010 | Time 24.3011(24.7448) | Bit/dim 3.3924(3.3995) | Xent 0.0000(0.0000) | Loss 8.5737(9.1954) | Error 0.0000(0.0000) Steps 952(964.30) | Grad Norm 2.2187(39.1167) | Total Time 0.00(0.00)\n",
      "Iter 19020 | Time 25.3604(24.7707) | Bit/dim 3.3741(3.4013) | Xent 0.0000(0.0000) | Loss 8.7020(9.0878) | Error 0.0000(0.0000) Steps 964(966.97) | Grad Norm 1.9213(29.3158) | Total Time 0.00(0.00)\n",
      "Iter 19030 | Time 23.9656(24.7385) | Bit/dim 3.3811(3.4017) | Xent 0.0000(0.0000) | Loss 8.6823(9.0068) | Error 0.0000(0.0000) Steps 958(966.99) | Grad Norm 1.8958(22.2329) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 110.7875, Epoch Time 1491.7831(1459.7415), Bit/dim 3.4027(best: 3.4035), Xent 0.0000, Loss 3.4027, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19040 | Time 24.9612(24.6184) | Bit/dim 3.3765(3.3993) | Xent 0.0000(0.0000) | Loss 8.5751(9.6865) | Error 0.0000(0.0000) Steps 940(963.40) | Grad Norm 1.2078(16.9253) | Total Time 0.00(0.00)\n",
      "Iter 19050 | Time 24.0114(24.6222) | Bit/dim 3.4052(3.3981) | Xent 0.0000(0.0000) | Loss 8.6790(9.4345) | Error 0.0000(0.0000) Steps 952(963.32) | Grad Norm 1.7568(12.8811) | Total Time 0.00(0.00)\n",
      "Iter 19060 | Time 23.9967(24.5996) | Bit/dim 3.3986(3.4007) | Xent 0.0000(0.0000) | Loss 8.6281(9.2574) | Error 0.0000(0.0000) Steps 946(964.76) | Grad Norm 1.3203(10.0223) | Total Time 0.00(0.00)\n",
      "Iter 19070 | Time 24.4494(24.5900) | Bit/dim 3.3881(3.4014) | Xent 0.0000(0.0000) | Loss 8.7959(9.1363) | Error 0.0000(0.0000) Steps 964(965.37) | Grad Norm 1.5071(7.9670) | Total Time 0.00(0.00)\n",
      "Iter 19080 | Time 24.1709(24.5963) | Bit/dim 3.4086(3.4026) | Xent 0.0000(0.0000) | Loss 8.7721(9.0377) | Error 0.0000(0.0000) Steps 934(963.19) | Grad Norm 1.3563(6.3190) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 109.6486, Epoch Time 1478.6805(1460.3097), Bit/dim 3.4037(best: 3.4027), Xent 0.0000, Loss 3.4037, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19090 | Time 24.1517(24.6775) | Bit/dim 3.3935(3.4000) | Xent 0.0000(0.0000) | Loss 8.6375(9.8652) | Error 0.0000(0.0000) Steps 964(961.92) | Grad Norm 2.5978(5.2967) | Total Time 0.00(0.00)\n",
      "Iter 19100 | Time 24.9837(24.5791) | Bit/dim 3.4099(3.3974) | Xent 0.0000(0.0000) | Loss 8.8172(9.5663) | Error 0.0000(0.0000) Steps 964(961.04) | Grad Norm 1.9387(4.5858) | Total Time 0.00(0.00)\n",
      "Iter 19110 | Time 24.0377(24.6299) | Bit/dim 3.4335(3.3964) | Xent 0.0000(0.0000) | Loss 8.7670(9.3416) | Error 0.0000(0.0000) Steps 952(962.82) | Grad Norm 2.3960(4.0062) | Total Time 0.00(0.00)\n",
      "Iter 19120 | Time 24.9805(24.6438) | Bit/dim 3.4069(3.3985) | Xent 0.0000(0.0000) | Loss 8.7983(9.1812) | Error 0.0000(0.0000) Steps 982(961.88) | Grad Norm 2.8219(3.5410) | Total Time 0.00(0.00)\n",
      "Iter 19130 | Time 25.7406(24.7702) | Bit/dim 3.4250(3.4005) | Xent 0.0000(0.0000) | Loss 8.8083(9.0731) | Error 0.0000(0.0000) Steps 958(963.13) | Grad Norm 1.7662(3.0373) | Total Time 0.00(0.00)\n",
      "Iter 19140 | Time 24.9070(24.7740) | Bit/dim 3.3516(3.4000) | Xent 0.0000(0.0000) | Loss 8.6957(8.9901) | Error 0.0000(0.0000) Steps 988(965.77) | Grad Norm 2.8312(2.8954) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 109.4266, Epoch Time 1488.8781(1461.1667), Bit/dim 3.4045(best: 3.4027), Xent 0.0000, Loss 3.4045, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19150 | Time 24.2488(24.6746) | Bit/dim 3.4286(3.4024) | Xent 0.0000(0.0000) | Loss 8.7156(9.7095) | Error 0.0000(0.0000) Steps 958(963.19) | Grad Norm 1.3630(2.5930) | Total Time 0.00(0.00)\n",
      "Iter 19160 | Time 23.5798(24.6035) | Bit/dim 3.4119(3.3999) | Xent 0.0000(0.0000) | Loss 8.8762(9.4448) | Error 0.0000(0.0000) Steps 988(964.65) | Grad Norm 2.3292(2.4173) | Total Time 0.00(0.00)\n",
      "Iter 19170 | Time 24.3467(24.6012) | Bit/dim 3.4386(3.4012) | Xent 0.0000(0.0000) | Loss 8.6658(9.2591) | Error 0.0000(0.0000) Steps 952(964.37) | Grad Norm 1.3702(2.1918) | Total Time 0.00(0.00)\n",
      "Iter 19180 | Time 24.3865(24.6249) | Bit/dim 3.4405(3.4020) | Xent 0.0000(0.0000) | Loss 8.8084(9.1310) | Error 0.0000(0.0000) Steps 964(967.25) | Grad Norm 1.7827(2.0953) | Total Time 0.00(0.00)\n",
      "Iter 19190 | Time 24.1767(24.5953) | Bit/dim 3.4043(3.4011) | Xent 0.0000(0.0000) | Loss 8.8024(9.0339) | Error 0.0000(0.0000) Steps 982(969.86) | Grad Norm 1.8220(1.9668) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 111.2395, Epoch Time 1480.9665(1461.7607), Bit/dim 3.4045(best: 3.4027), Xent 0.0000, Loss 3.4045, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19200 | Time 24.8331(24.5949) | Bit/dim 3.3922(3.3957) | Xent 0.0000(0.0000) | Loss 8.7157(9.8758) | Error 0.0000(0.0000) Steps 928(964.68) | Grad Norm 1.4162(1.9847) | Total Time 0.00(0.00)\n",
      "Iter 19210 | Time 25.2922(24.6094) | Bit/dim 3.3755(3.3960) | Xent 0.0000(0.0000) | Loss 8.6565(9.5805) | Error 0.0000(0.0000) Steps 928(963.52) | Grad Norm 2.6994(1.9623) | Total Time 0.00(0.00)\n",
      "Iter 19220 | Time 25.4650(24.6546) | Bit/dim 3.3993(3.3969) | Xent 0.0000(0.0000) | Loss 8.7382(9.3679) | Error 0.0000(0.0000) Steps 1006(965.96) | Grad Norm 1.5106(1.9836) | Total Time 0.00(0.00)\n",
      "Iter 19230 | Time 24.8391(24.6895) | Bit/dim 3.3529(3.3976) | Xent 0.0000(0.0000) | Loss 8.6327(9.2035) | Error 0.0000(0.0000) Steps 952(963.26) | Grad Norm 3.2649(2.3149) | Total Time 0.00(0.00)\n",
      "Iter 19240 | Time 24.9619(24.7023) | Bit/dim 3.3971(3.3983) | Xent 0.0000(0.0000) | Loss 8.7818(9.0835) | Error 0.0000(0.0000) Steps 964(967.62) | Grad Norm 1.4687(2.1794) | Total Time 0.00(0.00)\n",
      "Iter 19250 | Time 24.5572(24.7104) | Bit/dim 3.3948(3.3984) | Xent 0.0000(0.0000) | Loss 8.7492(8.9948) | Error 0.0000(0.0000) Steps 952(965.05) | Grad Norm 1.8943(2.0437) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 111.2768, Epoch Time 1487.7341(1462.5399), Bit/dim 3.4045(best: 3.4027), Xent 0.0000, Loss 3.4045, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19260 | Time 23.8662(24.6944) | Bit/dim 3.3886(3.3997) | Xent 0.0000(0.0000) | Loss 8.7414(9.7138) | Error 0.0000(0.0000) Steps 964(964.96) | Grad Norm 1.6358(1.9879) | Total Time 0.00(0.00)\n",
      "Iter 19270 | Time 24.2148(24.7320) | Bit/dim 3.3557(3.3965) | Xent 0.0000(0.0000) | Loss 8.5671(9.4540) | Error 0.0000(0.0000) Steps 982(969.66) | Grad Norm 1.3831(1.9764) | Total Time 0.00(0.00)\n",
      "Iter 19280 | Time 25.1597(24.8085) | Bit/dim 3.4258(3.3993) | Xent 0.0000(0.0000) | Loss 8.7399(9.2610) | Error 0.0000(0.0000) Steps 982(970.40) | Grad Norm 1.9798(2.0380) | Total Time 0.00(0.00)\n",
      "Iter 19290 | Time 24.8481(24.8283) | Bit/dim 3.3882(3.3996) | Xent 0.0000(0.0000) | Loss 8.7619(9.1198) | Error 0.0000(0.0000) Steps 964(968.54) | Grad Norm 2.3154(1.9348) | Total Time 0.00(0.00)\n",
      "Iter 19300 | Time 24.2312(24.8609) | Bit/dim 3.4288(3.3997) | Xent 0.0000(0.0000) | Loss 8.7921(9.0286) | Error 0.0000(0.0000) Steps 976(969.10) | Grad Norm 1.7610(1.9933) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 110.4244, Epoch Time 1495.7434(1463.5360), Bit/dim 3.4071(best: 3.4027), Xent 0.0000, Loss 3.4071, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19310 | Time 24.6047(24.8148) | Bit/dim 3.4317(3.3991) | Xent 0.0000(0.0000) | Loss 8.7312(9.8682) | Error 0.0000(0.0000) Steps 958(967.74) | Grad Norm 2.2138(1.9207) | Total Time 0.00(0.00)\n",
      "Iter 19320 | Time 24.1113(24.7076) | Bit/dim 3.4203(3.4005) | Xent 0.0000(0.0000) | Loss 8.6707(9.5605) | Error 0.0000(0.0000) Steps 946(964.77) | Grad Norm 2.6151(1.9308) | Total Time 0.00(0.00)\n",
      "Iter 19330 | Time 24.3673(24.7689) | Bit/dim 3.3866(3.3984) | Xent 0.0000(0.0000) | Loss 8.7351(9.3523) | Error 0.0000(0.0000) Steps 970(969.37) | Grad Norm 1.4236(1.9456) | Total Time 0.00(0.00)\n",
      "Iter 19340 | Time 24.7921(24.7143) | Bit/dim 3.3693(3.3974) | Xent 0.0000(0.0000) | Loss 8.7248(9.1895) | Error 0.0000(0.0000) Steps 976(971.00) | Grad Norm 1.3154(2.0183) | Total Time 0.00(0.00)\n",
      "Iter 19350 | Time 24.1750(24.6252) | Bit/dim 3.4245(3.3976) | Xent 0.0000(0.0000) | Loss 8.7265(9.0734) | Error 0.0000(0.0000) Steps 976(971.18) | Grad Norm 2.9478(2.0592) | Total Time 0.00(0.00)\n",
      "Iter 19360 | Time 24.0077(24.5237) | Bit/dim 3.3771(3.3976) | Xent 0.0000(0.0000) | Loss 8.7079(8.9834) | Error 0.0000(0.0000) Steps 970(969.24) | Grad Norm 2.7910(2.1960) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 111.3001, Epoch Time 1478.1932(1463.9757), Bit/dim 3.4060(best: 3.4027), Xent 0.0000, Loss 3.4060, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19370 | Time 24.7343(24.5165) | Bit/dim 3.3708(3.3990) | Xent 0.0000(0.0000) | Loss 8.7678(9.7105) | Error 0.0000(0.0000) Steps 982(968.52) | Grad Norm 1.3279(2.2114) | Total Time 0.00(0.00)\n",
      "Iter 19380 | Time 24.7623(24.5590) | Bit/dim 3.3915(3.3974) | Xent 0.0000(0.0000) | Loss 8.8078(9.4547) | Error 0.0000(0.0000) Steps 988(970.62) | Grad Norm 2.6269(2.2276) | Total Time 0.00(0.00)\n",
      "Iter 19390 | Time 25.1806(24.7291) | Bit/dim 3.3860(3.3964) | Xent 0.0000(0.0000) | Loss 8.7896(9.2740) | Error 0.0000(0.0000) Steps 970(971.01) | Grad Norm 1.7620(2.3744) | Total Time 0.00(0.00)\n",
      "Iter 19400 | Time 24.4179(24.8026) | Bit/dim 3.3736(3.3958) | Xent 0.0000(0.0000) | Loss 8.6867(9.1357) | Error 0.0000(0.0000) Steps 940(971.54) | Grad Norm 1.1832(2.1422) | Total Time 0.00(0.00)\n",
      "Iter 19410 | Time 24.4174(24.8103) | Bit/dim 3.3544(3.3976) | Xent 0.0000(0.0000) | Loss 8.6155(9.0321) | Error 0.0000(0.0000) Steps 982(970.91) | Grad Norm 1.4507(1.9421) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 111.7230, Epoch Time 1493.9633(1464.8754), Bit/dim 3.4066(best: 3.4027), Xent 0.0000, Loss 3.4066, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19420 | Time 25.2942(24.6998) | Bit/dim 3.4082(3.3983) | Xent 0.0000(0.0000) | Loss 8.8814(9.8633) | Error 0.0000(0.0000) Steps 1024(970.42) | Grad Norm 1.6624(1.7995) | Total Time 0.00(0.00)\n",
      "Iter 19430 | Time 24.1851(24.6704) | Bit/dim 3.4008(3.3986) | Xent 0.0000(0.0000) | Loss 8.7479(9.5719) | Error 0.0000(0.0000) Steps 916(969.74) | Grad Norm 1.2138(1.6562) | Total Time 0.00(0.00)\n",
      "Iter 19440 | Time 25.1390(24.6315) | Bit/dim 3.3694(3.3957) | Xent 0.0000(0.0000) | Loss 8.7967(9.3436) | Error 0.0000(0.0000) Steps 952(969.16) | Grad Norm 1.6153(1.6363) | Total Time 0.00(0.00)\n",
      "Iter 19450 | Time 24.6904(24.6138) | Bit/dim 3.3895(3.3950) | Xent 0.0000(0.0000) | Loss 8.5384(9.1694) | Error 0.0000(0.0000) Steps 994(967.32) | Grad Norm 1.9131(1.6415) | Total Time 0.00(0.00)\n",
      "Iter 19460 | Time 24.2563(24.6523) | Bit/dim 3.4286(3.3968) | Xent 0.0000(0.0000) | Loss 8.7263(9.0640) | Error 0.0000(0.0000) Steps 964(965.10) | Grad Norm 2.5869(1.7368) | Total Time 0.00(0.00)\n",
      "Iter 19470 | Time 25.0636(24.6284) | Bit/dim 3.3958(3.3989) | Xent 0.0000(0.0000) | Loss 8.7371(8.9884) | Error 0.0000(0.0000) Steps 994(967.13) | Grad Norm 2.0391(1.8325) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 110.5346, Epoch Time 1480.7086(1465.3504), Bit/dim 3.4020(best: 3.4027), Xent 0.0000, Loss 3.4020, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19480 | Time 25.2269(24.6439) | Bit/dim 3.4603(3.3996) | Xent 0.0000(0.0000) | Loss 8.7873(9.7149) | Error 0.0000(0.0000) Steps 910(968.47) | Grad Norm 1.9308(1.8319) | Total Time 0.00(0.00)\n",
      "Iter 19490 | Time 24.7317(24.7000) | Bit/dim 3.4089(3.4000) | Xent 0.0000(0.0000) | Loss 8.7408(9.4628) | Error 0.0000(0.0000) Steps 982(970.88) | Grad Norm 1.2135(1.7663) | Total Time 0.00(0.00)\n",
      "Iter 19500 | Time 24.3884(24.6937) | Bit/dim 3.3831(3.3981) | Xent 0.0000(0.0000) | Loss 8.7213(9.2810) | Error 0.0000(0.0000) Steps 976(972.12) | Grad Norm 1.4597(1.7767) | Total Time 0.00(0.00)\n",
      "Iter 19510 | Time 24.8258(24.8150) | Bit/dim 3.3737(3.3978) | Xent 0.0000(0.0000) | Loss 8.6467(9.1333) | Error 0.0000(0.0000) Steps 976(970.25) | Grad Norm 2.4651(1.7736) | Total Time 0.00(0.00)\n",
      "Iter 19520 | Time 24.4388(24.7857) | Bit/dim 3.3811(3.3967) | Xent 0.0000(0.0000) | Loss 8.7949(9.0274) | Error 0.0000(0.0000) Steps 994(971.99) | Grad Norm 1.4965(1.7590) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 110.4640, Epoch Time 1492.5159(1466.1653), Bit/dim 3.3994(best: 3.4020), Xent 0.0000, Loss 3.3994, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19530 | Time 25.2182(24.7510) | Bit/dim 3.4100(3.4006) | Xent 0.0000(0.0000) | Loss 8.8232(9.8833) | Error 0.0000(0.0000) Steps 940(972.85) | Grad Norm 1.6117(1.7404) | Total Time 0.00(0.00)\n",
      "Iter 19540 | Time 24.1924(24.7211) | Bit/dim 3.3909(3.4009) | Xent 0.0000(0.0000) | Loss 8.5762(9.5816) | Error 0.0000(0.0000) Steps 946(970.92) | Grad Norm 2.1955(1.7360) | Total Time 0.00(0.00)\n",
      "Iter 19550 | Time 24.0333(24.6958) | Bit/dim 3.4599(3.4013) | Xent 0.0000(0.0000) | Loss 8.9138(9.3718) | Error 0.0000(0.0000) Steps 940(968.85) | Grad Norm 1.6885(1.7579) | Total Time 0.00(0.00)\n",
      "Iter 19560 | Time 25.1847(24.6849) | Bit/dim 3.3441(3.4000) | Xent 0.0000(0.0000) | Loss 8.7007(9.1985) | Error 0.0000(0.0000) Steps 958(968.61) | Grad Norm 1.4447(1.6906) | Total Time 0.00(0.00)\n",
      "Iter 19570 | Time 24.2249(24.6816) | Bit/dim 3.4053(3.3993) | Xent 0.0000(0.0000) | Loss 8.7762(9.0789) | Error 0.0000(0.0000) Steps 988(969.38) | Grad Norm 2.3823(1.8389) | Total Time 0.00(0.00)\n",
      "Iter 19580 | Time 25.0010(24.7247) | Bit/dim 3.4122(3.3981) | Xent 0.0000(0.0000) | Loss 8.7594(8.9950) | Error 0.0000(0.0000) Steps 952(969.77) | Grad Norm 1.4468(1.8206) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 110.2057, Epoch Time 1486.0059(1466.7605), Bit/dim 3.4041(best: 3.3994), Xent 0.0000, Loss 3.4041, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19590 | Time 24.4014(24.7156) | Bit/dim 3.4302(3.3985) | Xent 0.0000(0.0000) | Loss 8.8218(9.7018) | Error 0.0000(0.0000) Steps 970(968.70) | Grad Norm 1.9503(1.9432) | Total Time 0.00(0.00)\n",
      "Iter 19600 | Time 23.5268(24.6417) | Bit/dim 3.4232(3.3993) | Xent 0.0000(0.0000) | Loss 8.8320(9.4506) | Error 0.0000(0.0000) Steps 958(968.37) | Grad Norm 2.2409(2.1942) | Total Time 0.00(0.00)\n",
      "Iter 19610 | Time 24.2418(24.6456) | Bit/dim 3.3709(3.3972) | Xent 0.0000(0.0000) | Loss 8.7547(9.2639) | Error 0.0000(0.0000) Steps 982(968.19) | Grad Norm 1.7648(2.4816) | Total Time 0.00(0.00)\n",
      "Iter 19620 | Time 25.2312(24.7400) | Bit/dim 3.4187(3.3973) | Xent 0.0000(0.0000) | Loss 8.7745(9.1256) | Error 0.0000(0.0000) Steps 970(971.09) | Grad Norm 4.7737(2.7369) | Total Time 0.00(0.00)\n",
      "Iter 19630 | Time 23.0799(24.6762) | Bit/dim 3.4222(3.3969) | Xent 0.0000(0.0000) | Loss 8.6222(9.0209) | Error 0.0000(0.0000) Steps 946(970.55) | Grad Norm 2.0786(2.7481) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 110.6197, Epoch Time 1484.7252(1467.2995), Bit/dim 3.4059(best: 3.3994), Xent 0.0000, Loss 3.4059, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19640 | Time 24.0259(24.6557) | Bit/dim 3.4117(3.3975) | Xent 0.0000(0.0000) | Loss 8.7077(9.8251) | Error 0.0000(0.0000) Steps 1006(969.12) | Grad Norm 1.6626(2.4721) | Total Time 0.00(0.00)\n",
      "Iter 19650 | Time 25.2059(24.6277) | Bit/dim 3.3814(3.3979) | Xent 0.0000(0.0000) | Loss 8.8105(9.5557) | Error 0.0000(0.0000) Steps 976(972.09) | Grad Norm 4.4427(2.5000) | Total Time 0.00(0.00)\n",
      "Iter 19660 | Time 23.6504(24.5927) | Bit/dim 3.3966(3.4002) | Xent 0.0000(0.0000) | Loss 8.8555(9.3464) | Error 0.0000(0.0000) Steps 976(972.70) | Grad Norm 3.6201(2.7222) | Total Time 0.00(0.00)\n",
      "Iter 19670 | Time 24.6235(24.6076) | Bit/dim 3.4120(3.3971) | Xent 0.0000(0.0000) | Loss 8.7751(9.1941) | Error 0.0000(0.0000) Steps 988(971.28) | Grad Norm 3.0667(2.7717) | Total Time 0.00(0.00)\n",
      "Iter 19680 | Time 24.2733(24.5480) | Bit/dim 3.3864(3.3965) | Xent 0.0000(0.0000) | Loss 8.7985(9.0570) | Error 0.0000(0.0000) Steps 982(969.29) | Grad Norm 3.1195(2.8024) | Total Time 0.00(0.00)\n",
      "Iter 19690 | Time 23.8144(24.5026) | Bit/dim 3.4009(3.3964) | Xent 0.0000(0.0000) | Loss 8.7265(8.9786) | Error 0.0000(0.0000) Steps 946(968.86) | Grad Norm 1.8458(2.6876) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 109.7958, Epoch Time 1476.5814(1467.5779), Bit/dim 3.4072(best: 3.3994), Xent 0.0000, Loss 3.4072, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19700 | Time 24.7540(24.5497) | Bit/dim 3.3936(3.3978) | Xent 0.0000(0.0000) | Loss 8.7263(9.7085) | Error 0.0000(0.0000) Steps 958(969.19) | Grad Norm 2.7520(2.5785) | Total Time 0.00(0.00)\n",
      "Iter 19710 | Time 23.7722(24.5308) | Bit/dim 3.3907(3.3986) | Xent 0.0000(0.0000) | Loss 8.7777(9.4500) | Error 0.0000(0.0000) Steps 988(970.37) | Grad Norm 1.6473(2.6566) | Total Time 0.00(0.00)\n",
      "Iter 19720 | Time 24.5269(24.6135) | Bit/dim 3.3646(3.3965) | Xent 0.0000(0.0000) | Loss 8.6230(9.2523) | Error 0.0000(0.0000) Steps 988(968.11) | Grad Norm 1.6949(2.5011) | Total Time 0.00(0.00)\n",
      "Iter 19730 | Time 24.4377(24.6649) | Bit/dim 3.4035(3.3966) | Xent 0.0000(0.0000) | Loss 8.7412(9.1283) | Error 0.0000(0.0000) Steps 970(970.60) | Grad Norm 1.5650(2.2685) | Total Time 0.00(0.00)\n",
      "Iter 19740 | Time 24.3018(24.6511) | Bit/dim 3.4088(3.3959) | Xent 0.0000(0.0000) | Loss 8.6896(9.0261) | Error 0.0000(0.0000) Steps 1000(970.39) | Grad Norm 1.6842(2.1272) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 111.8909, Epoch Time 1487.2468(1468.1680), Bit/dim 3.4045(best: 3.3994), Xent 0.0000, Loss 3.4045, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19750 | Time 25.2328(24.6534) | Bit/dim 3.4486(3.3992) | Xent 0.0000(0.0000) | Loss 8.7687(9.8642) | Error 0.0000(0.0000) Steps 976(971.04) | Grad Norm 1198.0052(37.9346) | Total Time 0.00(0.00)\n",
      "Iter 19760 | Time 24.5409(24.7341) | Bit/dim 3.4045(3.3992) | Xent 0.0000(0.0000) | Loss 8.7513(9.5679) | Error 0.0000(0.0000) Steps 970(969.75) | Grad Norm 2.1447(28.4083) | Total Time 0.00(0.00)\n",
      "Iter 19770 | Time 24.5581(24.7171) | Bit/dim 3.4065(3.3974) | Xent 0.0000(0.0000) | Loss 8.6735(9.3458) | Error 0.0000(0.0000) Steps 982(971.04) | Grad Norm 3.9129(21.6262) | Total Time 0.00(0.00)\n",
      "Iter 19780 | Time 26.6088(24.8133) | Bit/dim 3.3913(3.3949) | Xent 0.0000(0.0000) | Loss 8.6537(9.1791) | Error 0.0000(0.0000) Steps 958(969.40) | Grad Norm 1.6597(16.7337) | Total Time 0.00(0.00)\n",
      "Iter 19790 | Time 24.9689(24.9198) | Bit/dim 3.4214(3.3954) | Xent 0.0000(0.0000) | Loss 8.8052(9.0665) | Error 0.0000(0.0000) Steps 982(971.89) | Grad Norm 2.7487(13.0522) | Total Time 0.00(0.00)\n",
      "Iter 19800 | Time 24.0921(24.9290) | Bit/dim 3.3940(3.3980) | Xent 0.0000(0.0000) | Loss 8.6468(8.9958) | Error 0.0000(0.0000) Steps 952(971.46) | Grad Norm 1.3849(10.1081) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 111.0967, Epoch Time 1501.5349(1469.1690), Bit/dim 3.4051(best: 3.3994), Xent 0.0000, Loss 3.4051, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19810 | Time 24.2248(24.8230) | Bit/dim 3.3618(3.3955) | Xent 0.0000(0.0000) | Loss 8.7500(9.7193) | Error 0.0000(0.0000) Steps 952(971.19) | Grad Norm 2.3544(8.0983) | Total Time 0.00(0.00)\n",
      "Iter 19820 | Time 24.9304(24.7591) | Bit/dim 3.4180(3.3999) | Xent 0.0000(0.0000) | Loss 8.8881(9.4702) | Error 0.0000(0.0000) Steps 1000(973.06) | Grad Norm 3.2305(6.5729) | Total Time 0.00(0.00)\n",
      "Iter 19830 | Time 24.5806(24.7992) | Bit/dim 3.3992(3.3995) | Xent 0.0000(0.0000) | Loss 8.8224(9.2809) | Error 0.0000(0.0000) Steps 958(972.04) | Grad Norm 2.6507(5.4137) | Total Time 0.00(0.00)\n",
      "Iter 19840 | Time 24.8171(24.8194) | Bit/dim 3.3817(3.4005) | Xent 0.0000(0.0000) | Loss 8.6038(9.1364) | Error 0.0000(0.0000) Steps 958(967.03) | Grad Norm 3.5396(4.5369) | Total Time 0.00(0.00)\n",
      "Iter 19850 | Time 24.3846(24.8587) | Bit/dim 3.3859(3.3991) | Xent 0.0000(0.0000) | Loss 8.6062(9.0283) | Error 0.0000(0.0000) Steps 934(966.03) | Grad Norm 3.9543(4.1012) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 110.5106, Epoch Time 1490.8556(1469.8196), Bit/dim 3.4025(best: 3.3994), Xent 0.0000, Loss 3.4025, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19860 | Time 25.5491(24.8769) | Bit/dim 3.3692(3.3933) | Xent 0.0000(0.0000) | Loss 8.8312(9.8724) | Error 0.0000(0.0000) Steps 1018(967.57) | Grad Norm 2.1572(3.7249) | Total Time 0.00(0.00)\n",
      "Iter 19870 | Time 24.9328(24.8134) | Bit/dim 3.3709(3.3939) | Xent 0.0000(0.0000) | Loss 8.7383(9.5804) | Error 0.0000(0.0000) Steps 970(968.71) | Grad Norm 1.8080(3.2648) | Total Time 0.00(0.00)\n",
      "Iter 19880 | Time 24.2270(24.6904) | Bit/dim 3.4004(3.3949) | Xent 0.0000(0.0000) | Loss 8.7104(9.3510) | Error 0.0000(0.0000) Steps 964(969.30) | Grad Norm 2.1125(2.9789) | Total Time 0.00(0.00)\n",
      "Iter 19890 | Time 24.3607(24.7096) | Bit/dim 3.3928(3.3940) | Xent 0.0000(0.0000) | Loss 8.8318(9.2007) | Error 0.0000(0.0000) Steps 976(972.20) | Grad Norm 2.8055(2.8140) | Total Time 0.00(0.00)\n",
      "Iter 19900 | Time 24.4190(24.6849) | Bit/dim 3.3795(3.3952) | Xent 0.0000(0.0000) | Loss 8.7539(9.0811) | Error 0.0000(0.0000) Steps 988(972.86) | Grad Norm 3.0366(2.6189) | Total Time 0.00(0.00)\n",
      "Iter 19910 | Time 24.8450(24.6167) | Bit/dim 3.3960(3.3995) | Xent 0.0000(0.0000) | Loss 8.7513(9.0075) | Error 0.0000(0.0000) Steps 940(971.76) | Grad Norm 1.8678(2.3716) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 111.5734, Epoch Time 1484.3222(1470.2547), Bit/dim 3.4041(best: 3.3994), Xent 0.0000, Loss 3.4041, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19920 | Time 26.3692(24.7360) | Bit/dim 3.3718(3.3977) | Xent 0.0000(0.0000) | Loss 8.6213(9.7044) | Error 0.0000(0.0000) Steps 940(971.95) | Grad Norm 2.9254(2.2690) | Total Time 0.00(0.00)\n",
      "Iter 19930 | Time 25.2575(24.7350) | Bit/dim 3.3977(3.4007) | Xent 0.0000(0.0000) | Loss 8.7800(9.4557) | Error 0.0000(0.0000) Steps 940(972.27) | Grad Norm 1.8411(2.0731) | Total Time 0.00(0.00)\n",
      "Iter 19940 | Time 25.0900(24.7995) | Bit/dim 3.3920(3.3969) | Xent 0.0000(0.0000) | Loss 8.6840(9.2752) | Error 0.0000(0.0000) Steps 1030(975.96) | Grad Norm 2.5787(2.0747) | Total Time 0.00(0.00)\n",
      "Iter 19950 | Time 24.3295(24.8474) | Bit/dim 3.3825(3.3991) | Xent 0.0000(0.0000) | Loss 8.6394(9.1329) | Error 0.0000(0.0000) Steps 976(974.65) | Grad Norm 1.2305(2.0174) | Total Time 0.00(0.00)\n",
      "Iter 19960 | Time 24.5696(24.8276) | Bit/dim 3.4083(3.3976) | Xent 0.0000(0.0000) | Loss 8.7027(9.0161) | Error 0.0000(0.0000) Steps 940(973.37) | Grad Norm 2.6007(2.0499) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 110.2481, Epoch Time 1497.0999(1471.0600), Bit/dim 3.4029(best: 3.3994), Xent 0.0000, Loss 3.4029, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19970 | Time 24.8556(24.8541) | Bit/dim 3.4053(3.3980) | Xent 0.0000(0.0000) | Loss 8.8705(9.8763) | Error 0.0000(0.0000) Steps 976(972.87) | Grad Norm 1.3202(2.1062) | Total Time 0.00(0.00)\n",
      "Iter 19980 | Time 25.5579(24.8975) | Bit/dim 3.4281(3.3988) | Xent 0.0000(0.0000) | Loss 8.8476(9.5799) | Error 0.0000(0.0000) Steps 904(969.59) | Grad Norm 1.3555(2.0110) | Total Time 0.00(0.00)\n",
      "Iter 19990 | Time 25.1834(24.9694) | Bit/dim 3.3952(3.4001) | Xent 0.0000(0.0000) | Loss 8.6993(9.3681) | Error 0.0000(0.0000) Steps 958(974.84) | Grad Norm 1.4939(2.0028) | Total Time 0.00(0.00)\n",
      "Iter 20000 | Time 25.3164(24.9010) | Bit/dim 3.4241(3.3981) | Xent 0.0000(0.0000) | Loss 8.9082(9.2011) | Error 0.0000(0.0000) Steps 988(975.63) | Grad Norm 2.2736(2.0804) | Total Time 0.00(0.00)\n",
      "Iter 20010 | Time 25.1400(25.0278) | Bit/dim 3.4098(3.3979) | Xent 0.0000(0.0000) | Loss 8.7543(9.0884) | Error 0.0000(0.0000) Steps 976(978.12) | Grad Norm 1.7383(2.1158) | Total Time 0.00(0.00)\n",
      "Iter 20020 | Time 24.8205(24.9808) | Bit/dim 3.4409(3.3977) | Xent 0.0000(0.0000) | Loss 8.8953(9.0094) | Error 0.0000(0.0000) Steps 976(976.22) | Grad Norm 1.6917(2.0186) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 110.3296, Epoch Time 1505.1181(1472.0818), Bit/dim 3.4043(best: 3.3994), Xent 0.0000, Loss 3.4043, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20030 | Time 24.7411(24.9123) | Bit/dim 3.3769(3.3991) | Xent 0.0000(0.0000) | Loss 8.6879(9.7340) | Error 0.0000(0.0000) Steps 970(973.75) | Grad Norm 2.7870(2.1340) | Total Time 0.00(0.00)\n",
      "Iter 20040 | Time 26.9051(24.9967) | Bit/dim 3.3863(3.3940) | Xent 0.0000(0.0000) | Loss 8.8610(9.4689) | Error 0.0000(0.0000) Steps 1000(973.76) | Grad Norm 2.9257(2.2988) | Total Time 0.00(0.00)\n",
      "Iter 20050 | Time 23.8658(24.9585) | Bit/dim 3.4016(3.3967) | Xent 0.0000(0.0000) | Loss 8.6696(9.2703) | Error 0.0000(0.0000) Steps 970(973.69) | Grad Norm 1.3500(2.1936) | Total Time 0.00(0.00)\n",
      "Iter 20060 | Time 25.7856(24.8505) | Bit/dim 3.4195(3.3955) | Xent 0.0000(0.0000) | Loss 8.8409(9.1261) | Error 0.0000(0.0000) Steps 994(968.56) | Grad Norm 1.2128(2.1272) | Total Time 0.00(0.00)\n",
      "Iter 20070 | Time 25.9160(24.9218) | Bit/dim 3.4168(3.3985) | Xent 0.0000(0.0000) | Loss 8.8292(9.0387) | Error 0.0000(0.0000) Steps 970(970.67) | Grad Norm 2.5389(1.9711) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 112.7038, Epoch Time 1499.4322(1472.9023), Bit/dim 3.4003(best: 3.3994), Xent 0.0000, Loss 3.4003, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20080 | Time 24.8908(24.9462) | Bit/dim 3.4031(3.3970) | Xent 0.0000(0.0000) | Loss 8.7296(9.8682) | Error 0.0000(0.0000) Steps 976(971.59) | Grad Norm 2.7867(2.0574) | Total Time 0.00(0.00)\n",
      "Iter 20090 | Time 24.9270(24.9911) | Bit/dim 3.4181(3.3959) | Xent 0.0000(0.0000) | Loss 8.7540(9.5704) | Error 0.0000(0.0000) Steps 976(974.25) | Grad Norm 2.4365(2.0479) | Total Time 0.00(0.00)\n",
      "Iter 20100 | Time 25.7295(25.0723) | Bit/dim 3.4230(3.3970) | Xent 0.0000(0.0000) | Loss 8.9185(9.3643) | Error 0.0000(0.0000) Steps 958(973.44) | Grad Norm 3.9966(2.0924) | Total Time 0.00(0.00)\n",
      "Iter 20110 | Time 24.8831(25.0853) | Bit/dim 3.3880(3.3973) | Xent 0.0000(0.0000) | Loss 8.7001(9.2104) | Error 0.0000(0.0000) Steps 982(972.07) | Grad Norm 1.1262(2.0627) | Total Time 0.00(0.00)\n",
      "Iter 20120 | Time 24.4528(25.1291) | Bit/dim 3.3888(3.3988) | Xent 0.0000(0.0000) | Loss 8.6548(9.0935) | Error 0.0000(0.0000) Steps 988(973.67) | Grad Norm 2.7538(1.9756) | Total Time 0.00(0.00)\n",
      "Iter 20130 | Time 24.3751(25.1305) | Bit/dim 3.4424(3.3981) | Xent 0.0000(0.0000) | Loss 8.7802(9.0004) | Error 0.0000(0.0000) Steps 964(972.19) | Grad Norm 4.0242(2.2205) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 113.5970, Epoch Time 1516.9795(1474.2246), Bit/dim 3.4031(best: 3.3994), Xent 0.0000, Loss 3.4031, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20140 | Time 24.4085(25.0016) | Bit/dim 3.3864(3.3963) | Xent 0.0000(0.0000) | Loss 8.7977(9.7157) | Error 0.0000(0.0000) Steps 982(975.70) | Grad Norm 3.8739(2.3267) | Total Time 0.00(0.00)\n",
      "Iter 20150 | Time 25.5158(25.0295) | Bit/dim 3.4005(3.3958) | Xent 0.0000(0.0000) | Loss 8.8744(9.4659) | Error 0.0000(0.0000) Steps 970(976.44) | Grad Norm 1.7504(2.2917) | Total Time 0.00(0.00)\n",
      "Iter 20160 | Time 25.0217(25.0212) | Bit/dim 3.3989(3.3959) | Xent 0.0000(0.0000) | Loss 8.8719(9.2838) | Error 0.0000(0.0000) Steps 958(976.10) | Grad Norm 1.8223(2.1098) | Total Time 0.00(0.00)\n",
      "Iter 20170 | Time 25.5008(25.0334) | Bit/dim 3.3905(3.3968) | Xent 0.0000(0.0000) | Loss 8.7736(9.1377) | Error 0.0000(0.0000) Steps 976(976.94) | Grad Norm 1.1926(1.9373) | Total Time 0.00(0.00)\n",
      "Iter 20180 | Time 25.0154(24.9273) | Bit/dim 3.4073(3.3978) | Xent 0.0000(0.0000) | Loss 8.7574(9.0273) | Error 0.0000(0.0000) Steps 982(971.84) | Grad Norm 1.6520(1.8503) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 112.2525, Epoch Time 1499.3102(1474.9772), Bit/dim 3.4044(best: 3.3994), Xent 0.0000, Loss 3.4044, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20190 | Time 24.2361(24.8774) | Bit/dim 3.4111(3.3992) | Xent 0.0000(0.0000) | Loss 8.7231(9.8701) | Error 0.0000(0.0000) Steps 976(971.93) | Grad Norm 1.5929(1.7841) | Total Time 0.00(0.00)\n",
      "Iter 20200 | Time 24.8801(24.9211) | Bit/dim 3.3930(3.3991) | Xent 0.0000(0.0000) | Loss 8.7809(9.5757) | Error 0.0000(0.0000) Steps 1006(973.44) | Grad Norm 1.2557(1.7529) | Total Time 0.00(0.00)\n",
      "Iter 20210 | Time 25.6205(24.9331) | Bit/dim 3.3796(3.3951) | Xent 0.0000(0.0000) | Loss 8.7102(9.3475) | Error 0.0000(0.0000) Steps 958(972.96) | Grad Norm 1.5871(1.7593) | Total Time 0.00(0.00)\n",
      "Iter 20220 | Time 25.5030(24.9710) | Bit/dim 3.4119(3.3989) | Xent 0.0000(0.0000) | Loss 8.7742(9.2023) | Error 0.0000(0.0000) Steps 1012(974.20) | Grad Norm 2.7487(1.8614) | Total Time 0.00(0.00)\n",
      "Iter 20230 | Time 24.5619(24.8149) | Bit/dim 3.3870(3.3976) | Xent 0.0000(0.0000) | Loss 8.7733(9.0814) | Error 0.0000(0.0000) Steps 1006(975.13) | Grad Norm 2.6403(1.9373) | Total Time 0.00(0.00)\n",
      "Iter 20240 | Time 25.4088(24.8977) | Bit/dim 3.4004(3.3959) | Xent 0.0000(0.0000) | Loss 8.8069(9.0056) | Error 0.0000(0.0000) Steps 958(972.79) | Grad Norm 1.6294(2.0148) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 111.9130, Epoch Time 1499.1305(1475.7018), Bit/dim 3.4015(best: 3.3994), Xent 0.0000, Loss 3.4015, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20250 | Time 24.5273(24.8291) | Bit/dim 3.4401(3.3970) | Xent 0.0000(0.0000) | Loss 8.8844(9.7286) | Error 0.0000(0.0000) Steps 958(975.44) | Grad Norm 1.2096(1.9431) | Total Time 0.00(0.00)\n",
      "Iter 20260 | Time 25.6224(24.9047) | Bit/dim 3.3753(3.3942) | Xent 0.0000(0.0000) | Loss 8.7565(9.4767) | Error 0.0000(0.0000) Steps 994(977.75) | Grad Norm 1.2875(1.9072) | Total Time 0.00(0.00)\n",
      "Iter 20270 | Time 25.8043(24.9917) | Bit/dim 3.3891(3.3936) | Xent 0.0000(0.0000) | Loss 8.7741(9.2801) | Error 0.0000(0.0000) Steps 1006(977.19) | Grad Norm 1.3773(1.8338) | Total Time 0.00(0.00)\n",
      "Iter 20280 | Time 24.9405(24.9906) | Bit/dim 3.4077(3.3993) | Xent 0.0000(0.0000) | Loss 8.8535(9.1552) | Error 0.0000(0.0000) Steps 994(978.91) | Grad Norm 1.3771(1.6895) | Total Time 0.00(0.00)\n",
      "Iter 20290 | Time 25.1377(24.9854) | Bit/dim 3.3572(3.3969) | Xent 0.0000(0.0000) | Loss 8.6389(9.0375) | Error 0.0000(0.0000) Steps 994(976.32) | Grad Norm 1.5902(1.7030) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 110.6945, Epoch Time 1502.8248(1476.5155), Bit/dim 3.4034(best: 3.3994), Xent 0.0000, Loss 3.4034, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20300 | Time 25.3765(25.0165) | Bit/dim 3.3693(3.3957) | Xent 0.0000(0.0000) | Loss 8.7721(9.9126) | Error 0.0000(0.0000) Steps 982(977.65) | Grad Norm 1.1735(1.8313) | Total Time 0.00(0.00)\n",
      "Iter 20310 | Time 24.3655(25.0141) | Bit/dim 3.4199(3.3951) | Xent 0.0000(0.0000) | Loss 8.9175(9.6024) | Error 0.0000(0.0000) Steps 946(977.58) | Grad Norm 1.2194(1.7490) | Total Time 0.00(0.00)\n",
      "Iter 20320 | Time 25.3260(25.0041) | Bit/dim 3.4151(3.3972) | Xent 0.0000(0.0000) | Loss 8.7422(9.3856) | Error 0.0000(0.0000) Steps 1000(978.33) | Grad Norm 1.3925(1.6985) | Total Time 0.00(0.00)\n",
      "Iter 20330 | Time 24.5603(25.0187) | Bit/dim 3.3970(3.3969) | Xent 0.0000(0.0000) | Loss 8.7493(9.2295) | Error 0.0000(0.0000) Steps 982(976.91) | Grad Norm 1.7586(1.8138) | Total Time 0.00(0.00)\n",
      "Iter 20340 | Time 24.4771(24.9588) | Bit/dim 3.4058(3.3987) | Xent 0.0000(0.0000) | Loss 8.8603(9.1162) | Error 0.0000(0.0000) Steps 976(978.87) | Grad Norm 1.2616(1.6894) | Total Time 0.00(0.00)\n",
      "Iter 20350 | Time 25.0417(24.9977) | Bit/dim 3.4009(3.3969) | Xent 0.0000(0.0000) | Loss 8.7786(9.0093) | Error 0.0000(0.0000) Steps 934(976.93) | Grad Norm 2.1875(1.8117) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 110.1653, Epoch Time 1504.6213(1477.3587), Bit/dim 3.4060(best: 3.3994), Xent 0.0000, Loss 3.4060, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20360 | Time 25.8109(25.0455) | Bit/dim 3.4038(3.3966) | Xent 0.0000(0.0000) | Loss 8.7600(9.7244) | Error 0.0000(0.0000) Steps 994(977.93) | Grad Norm 3.7629(2.0346) | Total Time 0.00(0.00)\n",
      "Iter 20370 | Time 25.0930(24.9652) | Bit/dim 3.3797(3.3955) | Xent 0.0000(0.0000) | Loss 8.8544(9.4758) | Error 0.0000(0.0000) Steps 988(977.82) | Grad Norm 1.2599(2.0493) | Total Time 0.00(0.00)\n",
      "Iter 20380 | Time 25.4115(24.9358) | Bit/dim 3.3990(3.3967) | Xent 0.0000(0.0000) | Loss 8.8437(9.2954) | Error 0.0000(0.0000) Steps 1012(981.86) | Grad Norm 2.0941(2.0206) | Total Time 0.00(0.00)\n",
      "Iter 20390 | Time 25.5316(24.9136) | Bit/dim 3.3954(3.3962) | Xent 0.0000(0.0000) | Loss 8.7330(9.1564) | Error 0.0000(0.0000) Steps 988(981.21) | Grad Norm 2.4765(4.3712) | Total Time 0.00(0.00)\n",
      "Iter 20400 | Time 24.6695(24.8886) | Bit/dim 3.3917(3.3968) | Xent 0.0000(0.0000) | Loss 8.7935(9.0447) | Error 0.0000(0.0000) Steps 922(980.89) | Grad Norm 1.6924(3.7334) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 110.8370, Epoch Time 1499.3427(1478.0182), Bit/dim 3.4039(best: 3.3994), Xent 0.0000, Loss 3.4039, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20410 | Time 24.3699(24.9016) | Bit/dim 3.4264(3.3995) | Xent 0.0000(0.0000) | Loss 8.6903(9.8914) | Error 0.0000(0.0000) Steps 964(979.46) | Grad Norm 1.3994(3.1579) | Total Time 0.00(0.00)\n",
      "Iter 20420 | Time 25.2243(25.0568) | Bit/dim 3.3693(3.3965) | Xent 0.0000(0.0000) | Loss 8.7236(9.5876) | Error 0.0000(0.0000) Steps 1000(975.95) | Grad Norm 1.3915(2.7822) | Total Time 0.00(0.00)\n",
      "Iter 20430 | Time 24.4600(25.0334) | Bit/dim 3.3885(3.3949) | Xent 0.0000(0.0000) | Loss 8.7063(9.3633) | Error 0.0000(0.0000) Steps 952(972.76) | Grad Norm 2.3392(2.6426) | Total Time 0.00(0.00)\n",
      "Iter 20440 | Time 25.7282(24.9711) | Bit/dim 3.3860(3.3995) | Xent 0.0000(0.0000) | Loss 8.7461(9.2076) | Error 0.0000(0.0000) Steps 970(971.42) | Grad Norm 2.0561(2.4410) | Total Time 0.00(0.00)\n",
      "Iter 20450 | Time 25.5123(24.9979) | Bit/dim 3.3663(3.3992) | Xent 0.0000(0.0000) | Loss 8.7376(9.0920) | Error 0.0000(0.0000) Steps 958(972.18) | Grad Norm 1.8230(2.3385) | Total Time 0.00(0.00)\n",
      "Iter 20460 | Time 24.6434(24.9710) | Bit/dim 3.4193(3.3987) | Xent 0.0000(0.0000) | Loss 8.9288(9.0065) | Error 0.0000(0.0000) Steps 1000(975.06) | Grad Norm 2.5067(2.1545) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 112.6966, Epoch Time 1506.9863(1478.8872), Bit/dim 3.3999(best: 3.3994), Xent 0.0000, Loss 3.3999, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20470 | Time 25.6500(25.0005) | Bit/dim 3.3652(3.3970) | Xent 0.0000(0.0000) | Loss 8.6933(9.7265) | Error 0.0000(0.0000) Steps 1006(976.82) | Grad Norm 1.3812(1.9865) | Total Time 0.00(0.00)\n",
      "Iter 20480 | Time 23.7081(24.9203) | Bit/dim 3.3798(3.3970) | Xent 0.0000(0.0000) | Loss 8.7313(9.4632) | Error 0.0000(0.0000) Steps 970(973.79) | Grad Norm 2.2638(1.9257) | Total Time 0.00(0.00)\n",
      "Iter 20490 | Time 24.6984(24.9820) | Bit/dim 3.3879(3.3976) | Xent 0.0000(0.0000) | Loss 8.7914(9.2851) | Error 0.0000(0.0000) Steps 994(973.30) | Grad Norm 1.3961(1.9079) | Total Time 0.00(0.00)\n",
      "Iter 20500 | Time 25.2143(24.9538) | Bit/dim 3.3890(3.3959) | Xent 0.0000(0.0000) | Loss 8.7752(9.1392) | Error 0.0000(0.0000) Steps 946(974.43) | Grad Norm 2.0571(1.9092) | Total Time 0.00(0.00)\n",
      "Iter 20510 | Time 25.6278(24.9511) | Bit/dim 3.4240(3.3962) | Xent 0.0000(0.0000) | Loss 8.8777(9.0331) | Error 0.0000(0.0000) Steps 970(975.81) | Grad Norm 1.3686(2.0040) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 112.9034, Epoch Time 1503.4607(1479.6244), Bit/dim 3.4062(best: 3.3994), Xent 0.0000, Loss 3.4062, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20520 | Time 24.7368(24.9592) | Bit/dim 3.3864(3.3960) | Xent 0.0000(0.0000) | Loss 8.6767(9.8735) | Error 0.0000(0.0000) Steps 1000(976.51) | Grad Norm 2.8078(2.0326) | Total Time 0.00(0.00)\n",
      "Iter 20530 | Time 24.3930(24.9589) | Bit/dim 3.3694(3.3936) | Xent 0.0000(0.0000) | Loss 8.7649(9.5790) | Error 0.0000(0.0000) Steps 970(976.35) | Grad Norm 2.4555(2.1069) | Total Time 0.00(0.00)\n",
      "Iter 20540 | Time 25.4436(25.0310) | Bit/dim 3.3616(3.3947) | Xent 0.0000(0.0000) | Loss 8.6383(9.3469) | Error 0.0000(0.0000) Steps 934(973.53) | Grad Norm 2.2954(1.9780) | Total Time 0.00(0.00)\n",
      "Iter 20550 | Time 25.0227(24.9790) | Bit/dim 3.3965(3.3950) | Xent 0.0000(0.0000) | Loss 8.7846(9.1877) | Error 0.0000(0.0000) Steps 970(971.05) | Grad Norm 4.0328(2.0416) | Total Time 0.00(0.00)\n",
      "Iter 20560 | Time 25.2051(24.9603) | Bit/dim 3.3821(3.3932) | Xent 0.0000(0.0000) | Loss 8.7752(9.0630) | Error 0.0000(0.0000) Steps 1006(972.36) | Grad Norm 2.2023(2.0594) | Total Time 0.00(0.00)\n",
      "Iter 20570 | Time 26.2121(24.9731) | Bit/dim 3.4069(3.3963) | Xent 0.0000(0.0000) | Loss 8.8759(8.9989) | Error 0.0000(0.0000) Steps 1018(975.75) | Grad Norm 3.6714(18.8672) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 114.6525, Epoch Time 1508.1167(1480.4792), Bit/dim 3.3996(best: 3.3994), Xent 0.0000, Loss 3.3996, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20580 | Time 25.5488(25.0147) | Bit/dim 3.3885(3.3982) | Xent 0.0000(0.0000) | Loss 8.6218(9.7723) | Error 0.0000(0.0000) Steps 1036(981.25) | Grad Norm 2.9495(14.7375) | Total Time 0.00(0.00)\n",
      "Iter 20590 | Time 25.0169(25.0041) | Bit/dim 3.4216(3.3979) | Xent 0.0000(0.0000) | Loss 8.9943(9.5328) | Error 0.0000(0.0000) Steps 988(986.13) | Grad Norm 3.2254(11.4587) | Total Time 0.00(0.00)\n",
      "Iter 20600 | Time 24.5344(25.0334) | Bit/dim 3.3791(3.3958) | Xent 0.0000(0.0000) | Loss 8.7627(9.3313) | Error 0.0000(0.0000) Steps 976(984.46) | Grad Norm 2.8676(9.1107) | Total Time 0.00(0.00)\n",
      "Iter 20610 | Time 25.4865(25.0451) | Bit/dim 3.3656(3.3956) | Xent 0.0000(0.0000) | Loss 8.7066(9.1921) | Error 0.0000(0.0000) Steps 1012(988.09) | Grad Norm 2.6921(7.3423) | Total Time 0.00(0.00)\n",
      "Iter 20620 | Time 25.5770(25.1496) | Bit/dim 3.4413(3.3952) | Xent 0.0000(0.0000) | Loss 8.9215(9.0783) | Error 0.0000(0.0000) Steps 1018(989.18) | Grad Norm 3.3220(6.0735) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 112.0304, Epoch Time 1512.7737(1481.4480), Bit/dim 3.4018(best: 3.3994), Xent 0.0000, Loss 3.4018, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20630 | Time 25.7779(25.1671) | Bit/dim 3.3709(3.3959) | Xent 0.0000(0.0000) | Loss 8.5412(9.9176) | Error 0.0000(0.0000) Steps 1012(987.85) | Grad Norm 2.8689(5.0914) | Total Time 0.00(0.00)\n",
      "Iter 20640 | Time 25.4331(25.2592) | Bit/dim 3.3789(3.3931) | Xent 0.0000(0.0000) | Loss 8.6984(9.6072) | Error 0.0000(0.0000) Steps 1024(988.27) | Grad Norm 1.9143(4.3270) | Total Time 0.00(0.00)\n",
      "Iter 20650 | Time 25.3406(25.2833) | Bit/dim 3.3685(3.3942) | Xent 0.0000(0.0000) | Loss 8.5682(9.3857) | Error 0.0000(0.0000) Steps 970(985.10) | Grad Norm 2.3872(3.7202) | Total Time 0.00(0.00)\n",
      "Iter 20660 | Time 25.9793(25.2097) | Bit/dim 3.3943(3.3931) | Xent 0.0000(0.0000) | Loss 8.7426(9.2142) | Error 0.0000(0.0000) Steps 1030(984.20) | Grad Norm 1.4075(3.1367) | Total Time 0.00(0.00)\n",
      "Iter 20670 | Time 24.6546(25.1819) | Bit/dim 3.3790(3.3952) | Xent 0.0000(0.0000) | Loss 8.8359(9.1057) | Error 0.0000(0.0000) Steps 964(986.47) | Grad Norm 2.7110(3.1420) | Total Time 0.00(0.00)\n",
      "Iter 20680 | Time 25.0293(25.1568) | Bit/dim 3.4178(3.3965) | Xent 0.0000(0.0000) | Loss 8.7168(9.0065) | Error 0.0000(0.0000) Steps 1006(984.56) | Grad Norm 1.5522(2.8412) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 111.6072, Epoch Time 1517.1111(1482.5179), Bit/dim 3.4006(best: 3.3994), Xent 0.0000, Loss 3.4006, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20690 | Time 24.7921(25.1147) | Bit/dim 3.4232(3.3970) | Xent 0.0000(0.0000) | Loss 8.8457(9.7643) | Error 0.0000(0.0000) Steps 994(987.44) | Grad Norm 1.7321(2.5730) | Total Time 0.00(0.00)\n",
      "Iter 20700 | Time 24.9190(25.0916) | Bit/dim 3.4081(3.3963) | Xent 0.0000(0.0000) | Loss 8.8072(9.5023) | Error 0.0000(0.0000) Steps 1000(986.00) | Grad Norm 1.8832(2.4004) | Total Time 0.00(0.00)\n",
      "Iter 20710 | Time 24.8688(25.0594) | Bit/dim 3.3928(3.3951) | Xent 0.0000(0.0000) | Loss 8.7900(9.3116) | Error 0.0000(0.0000) Steps 994(988.56) | Grad Norm 2.2803(2.5409) | Total Time 0.00(0.00)\n",
      "Iter 20720 | Time 26.7656(25.1853) | Bit/dim 3.4075(3.3966) | Xent 0.0000(0.0000) | Loss 8.7697(9.1739) | Error 0.0000(0.0000) Steps 1012(990.06) | Grad Norm 2.8596(2.4718) | Total Time 0.00(0.00)\n",
      "Iter 20730 | Time 24.6467(25.1572) | Bit/dim 3.4183(3.3957) | Xent 0.0000(0.0000) | Loss 8.7647(9.0706) | Error 0.0000(0.0000) Steps 946(983.26) | Grad Norm 1.7503(2.5768) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 113.1858, Epoch Time 1513.2844(1483.4409), Bit/dim 3.4022(best: 3.3994), Xent 0.0000, Loss 3.4022, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20740 | Time 24.6550(25.1243) | Bit/dim 3.3646(3.3955) | Xent 0.0000(0.0000) | Loss 8.6412(9.8964) | Error 0.0000(0.0000) Steps 976(980.87) | Grad Norm 5.5685(2.8633) | Total Time 0.00(0.00)\n",
      "Iter 20750 | Time 24.8887(25.1069) | Bit/dim 3.4023(3.3968) | Xent 0.0000(0.0000) | Loss 8.7706(9.6091) | Error 0.0000(0.0000) Steps 994(986.54) | Grad Norm 1.3739(3.0184) | Total Time 0.00(0.00)\n",
      "Iter 20760 | Time 24.1263(25.0917) | Bit/dim 3.4631(3.3974) | Xent 0.0000(0.0000) | Loss 8.8542(9.3867) | Error 0.0000(0.0000) Steps 976(985.97) | Grad Norm 1.3586(2.8402) | Total Time 0.00(0.00)\n",
      "Iter 20770 | Time 24.2642(25.0156) | Bit/dim 3.3896(3.3973) | Xent 0.0000(0.0000) | Loss 8.8335(9.2223) | Error 0.0000(0.0000) Steps 994(985.95) | Grad Norm 2.3903(2.5272) | Total Time 0.00(0.00)\n",
      "Iter 20780 | Time 24.8369(24.9059) | Bit/dim 3.3817(3.3959) | Xent 0.0000(0.0000) | Loss 8.7037(9.0950) | Error 0.0000(0.0000) Steps 940(982.88) | Grad Norm 1.8046(2.4454) | Total Time 0.00(0.00)\n",
      "Iter 20790 | Time 24.2363(24.8485) | Bit/dim 3.4004(3.3969) | Xent 0.0000(0.0000) | Loss 8.7952(9.0034) | Error 0.0000(0.0000) Steps 1006(982.67) | Grad Norm 1.5734(2.2696) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 110.0609, Epoch Time 1495.1783(1483.7930), Bit/dim 3.3990(best: 3.3994), Xent 0.0000, Loss 3.3990, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20800 | Time 25.5854(24.9360) | Bit/dim 3.4150(3.3993) | Xent 0.0000(0.0000) | Loss 8.8078(9.7307) | Error 0.0000(0.0000) Steps 988(981.79) | Grad Norm 2.9107(2.2626) | Total Time 0.00(0.00)\n",
      "Iter 20810 | Time 25.3323(24.9382) | Bit/dim 3.4045(3.4000) | Xent 0.0000(0.0000) | Loss 8.8809(9.4873) | Error 0.0000(0.0000) Steps 1006(981.98) | Grad Norm 2.3553(2.3240) | Total Time 0.00(0.00)\n",
      "Iter 20820 | Time 25.4439(24.8926) | Bit/dim 3.3991(3.3974) | Xent 0.0000(0.0000) | Loss 8.7704(9.2899) | Error 0.0000(0.0000) Steps 976(982.15) | Grad Norm 1.4596(2.1495) | Total Time 0.00(0.00)\n",
      "Iter 20830 | Time 24.0698(24.8005) | Bit/dim 3.4048(3.3959) | Xent 0.0000(0.0000) | Loss 8.7462(9.1469) | Error 0.0000(0.0000) Steps 964(982.02) | Grad Norm 2.2201(2.0051) | Total Time 0.00(0.00)\n",
      "Iter 20840 | Time 23.8623(24.8615) | Bit/dim 3.3752(3.3933) | Xent 0.0000(0.0000) | Loss 8.6158(9.0411) | Error 0.0000(0.0000) Steps 976(981.29) | Grad Norm 1.9220(1.9901) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 110.8377, Epoch Time 1497.4723(1484.2034), Bit/dim 3.4022(best: 3.3990), Xent 0.0000, Loss 3.4022, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20850 | Time 27.1740(24.9067) | Bit/dim 3.3963(3.3922) | Xent 0.0000(0.0000) | Loss 8.9013(9.8589) | Error 0.0000(0.0000) Steps 1042(981.83) | Grad Norm 2.1037(1.9941) | Total Time 0.00(0.00)\n",
      "Iter 20860 | Time 23.7940(24.8738) | Bit/dim 3.3803(3.3913) | Xent 0.0000(0.0000) | Loss 8.6680(9.5636) | Error 0.0000(0.0000) Steps 952(977.48) | Grad Norm 2.4116(2.1246) | Total Time 0.00(0.00)\n",
      "Iter 20870 | Time 25.0953(24.9005) | Bit/dim 3.4191(3.3963) | Xent 0.0000(0.0000) | Loss 8.7601(9.3506) | Error 0.0000(0.0000) Steps 994(977.04) | Grad Norm 2.9277(2.4162) | Total Time 0.00(0.00)\n",
      "Iter 20880 | Time 24.6991(24.9566) | Bit/dim 3.4489(3.3972) | Xent 0.0000(0.0000) | Loss 8.6998(9.1931) | Error 0.0000(0.0000) Steps 970(979.08) | Grad Norm 2.9197(2.3965) | Total Time 0.00(0.00)\n",
      "Iter 20890 | Time 24.8344(24.8996) | Bit/dim 3.3727(3.3936) | Xent 0.0000(0.0000) | Loss 8.7699(9.0864) | Error 0.0000(0.0000) Steps 976(975.83) | Grad Norm 1.7527(2.3181) | Total Time 0.00(0.00)\n",
      "Iter 20900 | Time 24.6963(24.9618) | Bit/dim 3.4072(3.3982) | Xent 0.0000(0.0000) | Loss 8.8519(9.0049) | Error 0.0000(0.0000) Steps 1000(979.52) | Grad Norm 1.0829(2.0927) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 112.4962, Epoch Time 1504.1305(1484.8012), Bit/dim 3.4015(best: 3.3990), Xent 0.0000, Loss 3.4015, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20910 | Time 24.7956(24.9183) | Bit/dim 3.3839(3.3963) | Xent 0.0000(0.0000) | Loss 8.5950(9.7433) | Error 0.0000(0.0000) Steps 964(977.95) | Grad Norm 1.8159(1.9539) | Total Time 0.00(0.00)\n",
      "Iter 20920 | Time 24.2499(24.9467) | Bit/dim 3.3931(3.3959) | Xent 0.0000(0.0000) | Loss 8.8142(9.4798) | Error 0.0000(0.0000) Steps 1000(980.05) | Grad Norm 1.9763(2.1151) | Total Time 0.00(0.00)\n",
      "Iter 20930 | Time 24.6184(24.9192) | Bit/dim 3.4022(3.3947) | Xent 0.0000(0.0000) | Loss 8.7228(9.2744) | Error 0.0000(0.0000) Steps 964(977.13) | Grad Norm 2.1805(2.2890) | Total Time 0.00(0.00)\n",
      "Iter 20940 | Time 25.1240(24.9324) | Bit/dim 3.3940(3.3975) | Xent 0.0000(0.0000) | Loss 8.7055(9.1459) | Error 0.0000(0.0000) Steps 1024(982.17) | Grad Norm 1.6510(2.2219) | Total Time 0.00(0.00)\n",
      "Iter 20950 | Time 24.6010(24.8890) | Bit/dim 3.3617(3.3965) | Xent 0.0000(0.0000) | Loss 8.6682(9.0413) | Error 0.0000(0.0000) Steps 958(978.81) | Grad Norm 1.3199(2.2119) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 112.2522, Epoch Time 1498.5189(1485.2128), Bit/dim 3.3973(best: 3.3990), Xent 0.0000, Loss 3.3973, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20960 | Time 24.6894(24.8755) | Bit/dim 3.4063(3.3971) | Xent 0.0000(0.0000) | Loss 8.8196(9.8891) | Error 0.0000(0.0000) Steps 988(979.74) | Grad Norm 3.0267(2.2680) | Total Time 0.00(0.00)\n",
      "Iter 20970 | Time 25.8757(25.0175) | Bit/dim 3.4172(3.3959) | Xent 0.0000(0.0000) | Loss 8.8285(9.5950) | Error 0.0000(0.0000) Steps 922(976.47) | Grad Norm 2.2584(2.1714) | Total Time 0.00(0.00)\n",
      "Iter 20980 | Time 23.8978(25.0579) | Bit/dim 3.3991(3.3963) | Xent 0.0000(0.0000) | Loss 8.6235(9.3573) | Error 0.0000(0.0000) Steps 964(978.46) | Grad Norm 1.4291(2.1099) | Total Time 0.00(0.00)\n",
      "Iter 20990 | Time 24.6292(25.0075) | Bit/dim 3.3788(3.3961) | Xent 0.0000(0.0000) | Loss 8.6313(9.2007) | Error 0.0000(0.0000) Steps 940(977.36) | Grad Norm 1.3745(2.0155) | Total Time 0.00(0.00)\n",
      "Iter 21000 | Time 25.4048(25.0462) | Bit/dim 3.3831(3.3947) | Xent 0.0000(0.0000) | Loss 8.6897(9.0852) | Error 0.0000(0.0000) Steps 988(980.69) | Grad Norm 1.0778(1.8595) | Total Time 0.00(0.00)\n",
      "Iter 21010 | Time 23.7008(25.0101) | Bit/dim 3.3907(3.3948) | Xent 0.0000(0.0000) | Loss 8.6127(9.0006) | Error 0.0000(0.0000) Steps 964(981.32) | Grad Norm 1.5591(1.7585) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 112.2747, Epoch Time 1509.9772(1485.9557), Bit/dim 3.4029(best: 3.3973), Xent 0.0000, Loss 3.4029, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21020 | Time 25.0831(25.0008) | Bit/dim 3.4065(3.3959) | Xent 0.0000(0.0000) | Loss 8.7766(9.7237) | Error 0.0000(0.0000) Steps 964(980.15) | Grad Norm 1.5843(1.7320) | Total Time 0.00(0.00)\n",
      "Iter 21030 | Time 24.7852(24.9430) | Bit/dim 3.3459(3.3951) | Xent 0.0000(0.0000) | Loss 8.6758(9.4670) | Error 0.0000(0.0000) Steps 970(977.76) | Grad Norm 2.2856(1.8288) | Total Time 0.00(0.00)\n",
      "Iter 21040 | Time 24.7562(25.0478) | Bit/dim 3.4271(3.3969) | Xent 0.0000(0.0000) | Loss 8.7916(9.2870) | Error 0.0000(0.0000) Steps 988(980.61) | Grad Norm 1.9379(1.9394) | Total Time 0.00(0.00)\n",
      "Iter 21050 | Time 26.3149(25.0841) | Bit/dim 3.3987(3.3964) | Xent 0.0000(0.0000) | Loss 8.7611(9.1397) | Error 0.0000(0.0000) Steps 1036(982.21) | Grad Norm 1.7118(1.9296) | Total Time 0.00(0.00)\n",
      "Iter 21060 | Time 24.8169(25.0738) | Bit/dim 3.3727(3.3949) | Xent 0.0000(0.0000) | Loss 8.6866(9.0323) | Error 0.0000(0.0000) Steps 952(981.47) | Grad Norm 2.1797(1.8488) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 111.5972, Epoch Time 1509.8945(1486.6739), Bit/dim 3.4005(best: 3.3973), Xent 0.0000, Loss 3.4005, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21070 | Time 25.2198(25.0302) | Bit/dim 3.4056(3.3936) | Xent 0.0000(0.0000) | Loss 8.8616(9.8790) | Error 0.0000(0.0000) Steps 982(980.48) | Grad Norm 1.3859(1.7689) | Total Time 0.00(0.00)\n",
      "Iter 21080 | Time 25.9200(24.9497) | Bit/dim 3.3991(3.3958) | Xent 0.0000(0.0000) | Loss 8.7785(9.5816) | Error 0.0000(0.0000) Steps 1030(979.65) | Grad Norm 1.5867(1.7714) | Total Time 0.00(0.00)\n",
      "Iter 21090 | Time 24.2981(24.9287) | Bit/dim 3.4154(3.3963) | Xent 0.0000(0.0000) | Loss 8.7186(9.3586) | Error 0.0000(0.0000) Steps 922(978.15) | Grad Norm 1.5034(1.6776) | Total Time 0.00(0.00)\n",
      "Iter 21100 | Time 24.8861(25.0368) | Bit/dim 3.3812(3.3956) | Xent 0.0000(0.0000) | Loss 8.5564(9.1947) | Error 0.0000(0.0000) Steps 958(980.76) | Grad Norm 1.7733(2.0524) | Total Time 0.00(0.00)\n",
      "Iter 21110 | Time 25.5936(25.0512) | Bit/dim 3.3909(3.3945) | Xent 0.0000(0.0000) | Loss 8.8815(9.0856) | Error 0.0000(0.0000) Steps 1000(981.29) | Grad Norm 4.5813(2.6735) | Total Time 0.00(0.00)\n",
      "Iter 21120 | Time 24.6464(25.0223) | Bit/dim 3.4011(3.3966) | Xent 0.0000(0.0000) | Loss 8.7729(8.9951) | Error 0.0000(0.0000) Steps 994(980.34) | Grad Norm 4.5417(2.9854) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 111.0826, Epoch Time 1501.3451(1487.1140), Bit/dim 3.3985(best: 3.3973), Xent 0.0000, Loss 3.3985, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21130 | Time 24.2181(24.9800) | Bit/dim 3.4174(3.3969) | Xent 0.0000(0.0000) | Loss 8.7218(9.7218) | Error 0.0000(0.0000) Steps 994(981.66) | Grad Norm 1.6822(2.7434) | Total Time 0.00(0.00)\n",
      "Iter 21140 | Time 24.8801(24.9789) | Bit/dim 3.3785(3.3922) | Xent 0.0000(0.0000) | Loss 8.6327(9.4489) | Error 0.0000(0.0000) Steps 958(982.88) | Grad Norm 1.3203(2.5330) | Total Time 0.00(0.00)\n",
      "Iter 21150 | Time 23.9605(24.8336) | Bit/dim 3.4041(3.3940) | Xent 0.0000(0.0000) | Loss 8.6875(9.2724) | Error 0.0000(0.0000) Steps 964(980.42) | Grad Norm 1.3866(2.2777) | Total Time 0.00(0.00)\n",
      "Iter 21160 | Time 24.6975(24.9236) | Bit/dim 3.4418(3.3980) | Xent 0.0000(0.0000) | Loss 8.8453(9.1528) | Error 0.0000(0.0000) Steps 1000(979.84) | Grad Norm 2.6382(2.1413) | Total Time 0.00(0.00)\n",
      "Iter 21170 | Time 24.5364(24.9582) | Bit/dim 3.3863(3.3948) | Xent 0.0000(0.0000) | Loss 8.6977(9.0518) | Error 0.0000(0.0000) Steps 988(981.68) | Grad Norm 3.2307(2.1471) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 111.4664, Epoch Time 1498.3684(1487.4516), Bit/dim 3.3992(best: 3.3973), Xent 0.0000, Loss 3.3992, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21180 | Time 25.8206(24.9756) | Bit/dim 3.3883(3.3941) | Xent 0.0000(0.0000) | Loss 8.7988(9.8981) | Error 0.0000(0.0000) Steps 1030(985.02) | Grad Norm 1.9776(2.1783) | Total Time 0.00(0.00)\n",
      "Iter 21190 | Time 24.9084(24.9600) | Bit/dim 3.4064(3.3960) | Xent 0.0000(0.0000) | Loss 8.7387(9.6062) | Error 0.0000(0.0000) Steps 988(984.28) | Grad Norm 2.3882(2.1257) | Total Time 0.00(0.00)\n",
      "Iter 21200 | Time 25.8276(24.9823) | Bit/dim 3.3914(3.3955) | Xent 0.0000(0.0000) | Loss 8.8673(9.3772) | Error 0.0000(0.0000) Steps 976(981.77) | Grad Norm 1.8185(2.1134) | Total Time 0.00(0.00)\n",
      "Iter 21210 | Time 24.7484(25.0391) | Bit/dim 3.3858(3.3951) | Xent 0.0000(0.0000) | Loss 8.7502(9.2081) | Error 0.0000(0.0000) Steps 982(981.08) | Grad Norm 2.1081(2.0310) | Total Time 0.00(0.00)\n",
      "Iter 21220 | Time 24.9369(25.0277) | Bit/dim 3.4092(3.3958) | Xent 0.0000(0.0000) | Loss 8.7546(9.0903) | Error 0.0000(0.0000) Steps 1006(982.64) | Grad Norm 2.0061(2.1483) | Total Time 0.00(0.00)\n",
      "Iter 21230 | Time 24.6008(24.9419) | Bit/dim 3.3839(3.3946) | Xent 0.0000(0.0000) | Loss 8.7235(8.9919) | Error 0.0000(0.0000) Steps 988(979.57) | Grad Norm 2.6638(2.2306) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 110.4682, Epoch Time 1503.9676(1487.9471), Bit/dim 3.4013(best: 3.3973), Xent 0.0000, Loss 3.4013, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21240 | Time 25.2228(25.0092) | Bit/dim 3.3814(3.3946) | Xent 0.0000(0.0000) | Loss 8.6968(9.7157) | Error 0.0000(0.0000) Steps 952(980.49) | Grad Norm 2.8875(2.2305) | Total Time 0.00(0.00)\n",
      "Iter 21250 | Time 24.7590(24.9988) | Bit/dim 3.4249(3.3945) | Xent 0.0000(0.0000) | Loss 8.5492(9.4532) | Error 0.0000(0.0000) Steps 958(979.17) | Grad Norm 3.5681(14.1012) | Total Time 0.00(0.00)\n",
      "Iter 21260 | Time 25.2820(25.0712) | Bit/dim 3.3873(3.3956) | Xent 0.0000(0.0000) | Loss 8.7371(9.2584) | Error 0.0000(0.0000) Steps 958(979.28) | Grad Norm 1.5312(10.9260) | Total Time 0.00(0.00)\n",
      "Iter 21270 | Time 25.5429(24.9957) | Bit/dim 3.3444(3.3948) | Xent 0.0000(0.0000) | Loss 8.6143(9.1105) | Error 0.0000(0.0000) Steps 970(978.09) | Grad Norm 3.0185(8.7717) | Total Time 0.00(0.00)\n",
      "Iter 21280 | Time 23.9297(24.9784) | Bit/dim 3.3977(3.3963) | Xent 0.0000(0.0000) | Loss 8.6488(9.0171) | Error 0.0000(0.0000) Steps 976(979.10) | Grad Norm 2.0925(7.0763) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 111.5814, Epoch Time 1505.8870(1488.4853), Bit/dim 3.4015(best: 3.3973), Xent 0.0000, Loss 3.4015, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21290 | Time 25.3534(25.0563) | Bit/dim 3.3916(3.3967) | Xent 0.0000(0.0000) | Loss 8.7124(9.8939) | Error 0.0000(0.0000) Steps 1000(984.55) | Grad Norm 3.1616(5.9575) | Total Time 0.00(0.00)\n",
      "Iter 21300 | Time 24.8691(25.0978) | Bit/dim 3.3870(3.3951) | Xent 0.0000(0.0000) | Loss 8.7376(9.5975) | Error 0.0000(0.0000) Steps 958(981.38) | Grad Norm 1.3567(4.9935) | Total Time 0.00(0.00)\n",
      "Iter 21310 | Time 24.2928(25.0907) | Bit/dim 3.3668(3.3950) | Xent 0.0000(0.0000) | Loss 8.8063(9.3773) | Error 0.0000(0.0000) Steps 1006(981.82) | Grad Norm 1.5051(4.1290) | Total Time 0.00(0.00)\n",
      "Iter 21320 | Time 24.8745(24.9815) | Bit/dim 3.4085(3.3960) | Xent 0.0000(0.0000) | Loss 8.6627(9.2176) | Error 0.0000(0.0000) Steps 940(979.66) | Grad Norm 1.8149(3.4935) | Total Time 0.00(0.00)\n",
      "Iter 21330 | Time 25.8729(24.9154) | Bit/dim 3.3789(3.3949) | Xent 0.0000(0.0000) | Loss 8.6893(9.0903) | Error 0.0000(0.0000) Steps 1018(981.16) | Grad Norm 2.3226(3.1996) | Total Time 0.00(0.00)\n",
      "Iter 21340 | Time 24.5925(24.8756) | Bit/dim 3.4109(3.3945) | Xent 0.0000(0.0000) | Loss 8.8786(9.0052) | Error 0.0000(0.0000) Steps 988(983.11) | Grad Norm 1.3075(2.9870) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 110.8244, Epoch Time 1501.1653(1488.8657), Bit/dim 3.3997(best: 3.3973), Xent 0.0000, Loss 3.3997, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21350 | Time 24.2251(24.9428) | Bit/dim 3.3848(3.3965) | Xent 0.0000(0.0000) | Loss 8.7274(9.7458) | Error 0.0000(0.0000) Steps 952(981.57) | Grad Norm 3.3088(2.7434) | Total Time 0.00(0.00)\n",
      "Iter 21360 | Time 25.1733(24.9887) | Bit/dim 3.4092(3.3972) | Xent 0.0000(0.0000) | Loss 8.8785(9.4866) | Error 0.0000(0.0000) Steps 988(982.76) | Grad Norm 1.5163(2.5454) | Total Time 0.00(0.00)\n",
      "Iter 21370 | Time 24.1722(25.1009) | Bit/dim 3.3868(3.3931) | Xent 0.0000(0.0000) | Loss 8.6824(9.2948) | Error 0.0000(0.0000) Steps 952(981.75) | Grad Norm 2.5010(2.4270) | Total Time 0.00(0.00)\n",
      "Iter 21380 | Time 24.4158(25.1269) | Bit/dim 3.3891(3.3920) | Xent 0.0000(0.0000) | Loss 8.7312(9.1417) | Error 0.0000(0.0000) Steps 952(977.81) | Grad Norm 3.1574(2.4253) | Total Time 0.00(0.00)\n",
      "Iter 21390 | Time 24.1715(25.0700) | Bit/dim 3.4215(3.3934) | Xent 0.0000(0.0000) | Loss 8.7432(9.0422) | Error 0.0000(0.0000) Steps 970(978.38) | Grad Norm 2.9592(2.3731) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 111.4189, Epoch Time 1515.4236(1489.6624), Bit/dim 3.4005(best: 3.3973), Xent 0.0000, Loss 3.4005, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21400 | Time 23.9109(25.0443) | Bit/dim 3.3874(3.3962) | Xent 0.0000(0.0000) | Loss 8.6030(9.8768) | Error 0.0000(0.0000) Steps 964(979.39) | Grad Norm 1.8032(2.2422) | Total Time 0.00(0.00)\n",
      "Iter 21410 | Time 24.0353(25.1091) | Bit/dim 3.3924(3.3960) | Xent 0.0000(0.0000) | Loss 8.7709(9.5875) | Error 0.0000(0.0000) Steps 970(977.99) | Grad Norm 1.9825(2.1716) | Total Time 0.00(0.00)\n",
      "Iter 21420 | Time 25.6942(25.1159) | Bit/dim 3.3742(3.3938) | Xent 0.0000(0.0000) | Loss 8.8396(9.3655) | Error 0.0000(0.0000) Steps 970(979.38) | Grad Norm 3.3769(2.2267) | Total Time 0.00(0.00)\n",
      "Iter 21430 | Time 25.0075(25.0627) | Bit/dim 3.4159(3.3953) | Xent 0.0000(0.0000) | Loss 8.8469(9.2194) | Error 0.0000(0.0000) Steps 988(981.11) | Grad Norm 2.1399(2.2008) | Total Time 0.00(0.00)\n",
      "Iter 21440 | Time 24.5435(25.1185) | Bit/dim 3.3478(3.3938) | Xent 0.0000(0.0000) | Loss 8.7505(9.1012) | Error 0.0000(0.0000) Steps 994(983.42) | Grad Norm 1.5301(2.2955) | Total Time 0.00(0.00)\n",
      "Iter 21450 | Time 25.8277(25.1520) | Bit/dim 3.3968(3.3941) | Xent 0.0000(0.0000) | Loss 8.7645(9.0107) | Error 0.0000(0.0000) Steps 1018(984.02) | Grad Norm 2.8514(2.4544) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 110.9873, Epoch Time 1510.6069(1490.2908), Bit/dim 3.4005(best: 3.3973), Xent 0.0000, Loss 3.4005, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21460 | Time 25.3330(25.2327) | Bit/dim 3.3909(3.3944) | Xent 0.0000(0.0000) | Loss 8.8906(9.7407) | Error 0.0000(0.0000) Steps 988(984.86) | Grad Norm 1.2899(2.4219) | Total Time 0.00(0.00)\n",
      "Iter 21470 | Time 24.6224(25.0975) | Bit/dim 3.4105(3.3957) | Xent 0.0000(0.0000) | Loss 8.8532(9.4913) | Error 0.0000(0.0000) Steps 958(982.96) | Grad Norm 3.7679(2.4537) | Total Time 0.00(0.00)\n",
      "Iter 21480 | Time 26.6593(25.1208) | Bit/dim 3.3878(3.3957) | Xent 0.0000(0.0000) | Loss 8.7590(9.3001) | Error 0.0000(0.0000) Steps 1018(985.06) | Grad Norm 1.6799(2.3738) | Total Time 0.00(0.00)\n",
      "Iter 21490 | Time 26.1644(25.1932) | Bit/dim 3.3737(3.3953) | Xent 0.0000(0.0000) | Loss 8.8094(9.1608) | Error 0.0000(0.0000) Steps 994(982.86) | Grad Norm 2.5121(2.3289) | Total Time 0.00(0.00)\n",
      "Iter 21500 | Time 25.5374(25.2449) | Bit/dim 3.4305(3.3930) | Xent 0.0000(0.0000) | Loss 8.7531(9.0492) | Error 0.0000(0.0000) Steps 982(980.69) | Grad Norm 2.9521(2.3348) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 110.5588, Epoch Time 1515.4917(1491.0468), Bit/dim 3.3990(best: 3.3973), Xent 0.0000, Loss 3.3990, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21510 | Time 25.0807(25.2189) | Bit/dim 3.3756(3.3933) | Xent 0.0000(0.0000) | Loss 8.7489(9.8895) | Error 0.0000(0.0000) Steps 1000(982.89) | Grad Norm 1.7007(2.2426) | Total Time 0.00(0.00)\n",
      "Iter 21520 | Time 24.7524(25.1123) | Bit/dim 3.3781(3.3897) | Xent 0.0000(0.0000) | Loss 8.8272(9.5916) | Error 0.0000(0.0000) Steps 976(983.12) | Grad Norm 1.3070(2.2386) | Total Time 0.00(0.00)\n",
      "Iter 21530 | Time 25.3808(25.1449) | Bit/dim 3.3670(3.3899) | Xent 0.0000(0.0000) | Loss 8.7553(9.3698) | Error 0.0000(0.0000) Steps 1006(981.54) | Grad Norm 2.6348(2.1727) | Total Time 0.00(0.00)\n",
      "Iter 21540 | Time 26.3584(25.1555) | Bit/dim 3.3990(3.3926) | Xent 0.0000(0.0000) | Loss 8.7620(9.2117) | Error 0.0000(0.0000) Steps 1024(984.89) | Grad Norm 1.9205(2.1085) | Total Time 0.00(0.00)\n",
      "Iter 21550 | Time 25.3046(25.1525) | Bit/dim 3.3971(3.3923) | Xent 0.0000(0.0000) | Loss 8.7493(9.0962) | Error 0.0000(0.0000) Steps 1012(984.37) | Grad Norm 2.2687(2.0122) | Total Time 0.00(0.00)\n",
      "Iter 21560 | Time 24.4930(25.0792) | Bit/dim 3.4335(3.3966) | Xent 0.0000(0.0000) | Loss 8.9186(9.0166) | Error 0.0000(0.0000) Steps 1006(984.63) | Grad Norm 1.5789(1.9144) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 110.6526, Epoch Time 1506.3959(1491.5073), Bit/dim 3.3995(best: 3.3973), Xent 0.0000, Loss 3.3995, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21570 | Time 25.3193(25.1030) | Bit/dim 3.4255(3.3962) | Xent 0.0000(0.0000) | Loss 8.7841(9.7408) | Error 0.0000(0.0000) Steps 970(983.43) | Grad Norm 2.2029(1.9136) | Total Time 0.00(0.00)\n",
      "Iter 21580 | Time 26.1109(25.1091) | Bit/dim 3.4058(3.3955) | Xent 0.0000(0.0000) | Loss 8.8660(9.4816) | Error 0.0000(0.0000) Steps 946(980.01) | Grad Norm 2.0212(1.9573) | Total Time 0.00(0.00)\n",
      "Iter 21590 | Time 25.2653(24.9883) | Bit/dim 3.3878(3.3948) | Xent 0.0000(0.0000) | Loss 8.7158(9.2918) | Error 0.0000(0.0000) Steps 1012(979.84) | Grad Norm 1.9394(1.9630) | Total Time 0.00(0.00)\n",
      "Iter 21600 | Time 24.0807(24.9499) | Bit/dim 3.4028(3.3960) | Xent 0.0000(0.0000) | Loss 8.9007(9.1511) | Error 0.0000(0.0000) Steps 994(981.55) | Grad Norm 1.2828(1.9598) | Total Time 0.00(0.00)\n",
      "Iter 21610 | Time 26.2671(24.9929) | Bit/dim 3.4190(3.3955) | Xent 0.0000(0.0000) | Loss 8.8942(9.0508) | Error 0.0000(0.0000) Steps 958(981.08) | Grad Norm 1.2942(1.8659) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 111.6910, Epoch Time 1506.1412(1491.9463), Bit/dim 3.3999(best: 3.3973), Xent 0.0000, Loss 3.3999, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21620 | Time 26.2215(25.1332) | Bit/dim 3.3710(3.3946) | Xent 0.0000(0.0000) | Loss 8.8276(9.9175) | Error 0.0000(0.0000) Steps 994(981.39) | Grad Norm 2.8813(1.8283) | Total Time 0.00(0.00)\n",
      "Iter 21630 | Time 26.0409(25.1428) | Bit/dim 3.3951(3.3951) | Xent 0.0000(0.0000) | Loss 8.6974(9.6130) | Error 0.0000(0.0000) Steps 976(980.68) | Grad Norm 3.3231(2.0292) | Total Time 0.00(0.00)\n",
      "Iter 21640 | Time 25.6257(25.1223) | Bit/dim 3.3778(3.3958) | Xent 0.0000(0.0000) | Loss 8.6914(9.3985) | Error 0.0000(0.0000) Steps 1030(984.51) | Grad Norm 1.6396(2.0139) | Total Time 0.00(0.00)\n",
      "Iter 21650 | Time 25.0561(25.1106) | Bit/dim 3.3716(3.3938) | Xent 0.0000(0.0000) | Loss 8.7124(9.2222) | Error 0.0000(0.0000) Steps 994(980.69) | Grad Norm 2.2551(1.9354) | Total Time 0.00(0.00)\n",
      "Iter 21660 | Time 24.7370(25.1507) | Bit/dim 3.4238(3.3944) | Xent 0.0000(0.0000) | Loss 8.7706(9.0966) | Error 0.0000(0.0000) Steps 958(980.19) | Grad Norm 3.9387(2.1477) | Total Time 0.00(0.00)\n",
      "Iter 21670 | Time 26.1236(25.1581) | Bit/dim 3.3808(3.3946) | Xent 0.0000(0.0000) | Loss 8.7854(9.0071) | Error 0.0000(0.0000) Steps 952(977.39) | Grad Norm 1.7338(2.2510) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 112.2385, Epoch Time 1515.2282(1492.6447), Bit/dim 3.4005(best: 3.3973), Xent 0.0000, Loss 3.4005, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21680 | Time 24.9492(25.0905) | Bit/dim 3.3723(3.3934) | Xent 0.0000(0.0000) | Loss 8.6934(9.7309) | Error 0.0000(0.0000) Steps 970(978.54) | Grad Norm 2.5593(2.1937) | Total Time 0.00(0.00)\n",
      "Iter 21690 | Time 25.3424(25.0683) | Bit/dim 3.3562(3.3928) | Xent 0.0000(0.0000) | Loss 8.6891(9.4631) | Error 0.0000(0.0000) Steps 964(979.05) | Grad Norm 2.7881(2.2133) | Total Time 0.00(0.00)\n",
      "Iter 21700 | Time 25.6660(25.1059) | Bit/dim 3.4091(3.3937) | Xent 0.0000(0.0000) | Loss 8.8921(9.2677) | Error 0.0000(0.0000) Steps 1012(979.58) | Grad Norm 2.2402(2.1800) | Total Time 0.00(0.00)\n",
      "Iter 21710 | Time 25.2398(25.1260) | Bit/dim 3.3767(3.3928) | Xent 0.0000(0.0000) | Loss 8.5661(9.1272) | Error 0.0000(0.0000) Steps 934(980.98) | Grad Norm 3.3804(2.3161) | Total Time 0.00(0.00)\n",
      "Iter 21720 | Time 26.4695(25.1139) | Bit/dim 3.3947(3.3951) | Xent 0.0000(0.0000) | Loss 8.7411(9.0343) | Error 0.0000(0.0000) Steps 1012(981.57) | Grad Norm 2.9221(2.3860) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 112.7405, Epoch Time 1508.6726(1493.1256), Bit/dim 3.4001(best: 3.3973), Xent 0.0000, Loss 3.4001, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21730 | Time 25.2761(25.1180) | Bit/dim 3.3965(3.3944) | Xent 0.0000(0.0000) | Loss 8.7958(9.8738) | Error 0.0000(0.0000) Steps 1000(981.24) | Grad Norm 2.1159(2.2772) | Total Time 0.00(0.00)\n",
      "Iter 21740 | Time 26.3209(25.1710) | Bit/dim 3.4147(3.3929) | Xent 0.0000(0.0000) | Loss 8.7262(9.5739) | Error 0.0000(0.0000) Steps 1006(981.39) | Grad Norm 3.4110(2.4411) | Total Time 0.00(0.00)\n",
      "Iter 21750 | Time 25.4224(25.1761) | Bit/dim 3.3936(3.3935) | Xent 0.0000(0.0000) | Loss 8.6478(9.3633) | Error 0.0000(0.0000) Steps 982(981.67) | Grad Norm 2.4425(2.2876) | Total Time 0.00(0.00)\n",
      "Iter 21760 | Time 24.2619(25.1008) | Bit/dim 3.4212(3.3947) | Xent 0.0000(0.0000) | Loss 8.8001(9.2095) | Error 0.0000(0.0000) Steps 970(979.06) | Grad Norm 0.9920(2.1546) | Total Time 0.00(0.00)\n",
      "Iter 21770 | Time 24.5607(25.0615) | Bit/dim 3.4013(3.3962) | Xent 0.0000(0.0000) | Loss 8.8071(9.0930) | Error 0.0000(0.0000) Steps 958(978.52) | Grad Norm 1.8764(1.9967) | Total Time 0.00(0.00)\n",
      "Iter 21780 | Time 25.0239(25.1766) | Bit/dim 3.3728(3.3964) | Xent 0.0000(0.0000) | Loss 8.7642(8.9972) | Error 0.0000(0.0000) Steps 1000(980.68) | Grad Norm 2.5419(1.9682) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 112.9959, Epoch Time 1516.9681(1493.8409), Bit/dim 3.3995(best: 3.3973), Xent 0.0000, Loss 3.3995, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21790 | Time 24.9721(25.2813) | Bit/dim 3.4115(3.3971) | Xent 0.0000(0.0000) | Loss 8.7018(9.7537) | Error 0.0000(0.0000) Steps 988(984.23) | Grad Norm 1.1941(2.1150) | Total Time 0.00(0.00)\n",
      "Iter 21800 | Time 25.8440(25.2173) | Bit/dim 3.3892(3.3965) | Xent 0.0000(0.0000) | Loss 8.6956(9.4943) | Error 0.0000(0.0000) Steps 976(982.52) | Grad Norm 2.8221(2.2642) | Total Time 0.00(0.00)\n",
      "Iter 21810 | Time 24.2189(25.1719) | Bit/dim 3.3873(3.3958) | Xent 0.0000(0.0000) | Loss 8.5936(9.2952) | Error 0.0000(0.0000) Steps 964(983.54) | Grad Norm 1.6414(2.1240) | Total Time 0.00(0.00)\n",
      "Iter 21820 | Time 24.9161(25.1388) | Bit/dim 3.3942(3.3954) | Xent 0.0000(0.0000) | Loss 8.7123(9.1510) | Error 0.0000(0.0000) Steps 982(982.05) | Grad Norm 1.6620(2.0722) | Total Time 0.00(0.00)\n",
      "Iter 21830 | Time 24.7568(25.0727) | Bit/dim 3.4304(3.3971) | Xent 0.0000(0.0000) | Loss 8.7449(9.0470) | Error 0.0000(0.0000) Steps 982(982.41) | Grad Norm 1.3413(1.9760) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 112.0021, Epoch Time 1510.6798(1494.3460), Bit/dim 3.3964(best: 3.3973), Xent 0.0000, Loss 3.3964, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21840 | Time 25.2902(25.0917) | Bit/dim 3.3992(3.3932) | Xent 0.0000(0.0000) | Loss 8.7130(9.8900) | Error 0.0000(0.0000) Steps 1012(986.30) | Grad Norm 1.5833(2.1281) | Total Time 0.00(0.00)\n",
      "Iter 21850 | Time 25.3730(25.1331) | Bit/dim 3.3866(3.3931) | Xent 0.0000(0.0000) | Loss 8.7520(9.6023) | Error 0.0000(0.0000) Steps 988(988.67) | Grad Norm 1.8481(145.9202) | Total Time 0.00(0.00)\n",
      "Iter 21860 | Time 26.2048(25.1612) | Bit/dim 3.3939(3.3925) | Xent 0.0000(0.0000) | Loss 8.6667(9.3793) | Error 0.0000(0.0000) Steps 988(989.92) | Grad Norm 2.2016(108.2743) | Total Time 0.00(0.00)\n",
      "Iter 21870 | Time 27.0165(25.2634) | Bit/dim 3.3833(3.3932) | Xent 0.0000(0.0000) | Loss 8.7745(9.2241) | Error 0.0000(0.0000) Steps 988(988.93) | Grad Norm 3.6345(80.6444) | Total Time 0.00(0.00)\n",
      "Iter 21880 | Time 25.5684(25.2561) | Bit/dim 3.4100(3.3952) | Xent 0.0000(0.0000) | Loss 8.7647(9.1059) | Error 0.0000(0.0000) Steps 1000(991.22) | Grad Norm 4.3358(60.2950) | Total Time 0.00(0.00)\n",
      "Iter 21890 | Time 25.0684(25.2882) | Bit/dim 3.3948(3.3951) | Xent 0.0000(0.0000) | Loss 8.7639(9.0139) | Error 0.0000(0.0000) Steps 958(988.38) | Grad Norm 1.7571(45.1217) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 113.3344, Epoch Time 1523.9482(1495.2341), Bit/dim 3.3963(best: 3.3964), Xent 0.0000, Loss 3.3963, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21900 | Time 26.2691(25.3447) | Bit/dim 3.3899(3.3950) | Xent 0.0000(0.0000) | Loss 8.6938(9.7580) | Error 0.0000(0.0000) Steps 1018(991.95) | Grad Norm 4.1787(34.0357) | Total Time 0.00(0.00)\n",
      "Iter 21910 | Time 25.3388(25.3871) | Bit/dim 3.4078(3.3925) | Xent 0.0000(0.0000) | Loss 8.6482(9.4807) | Error 0.0000(0.0000) Steps 1000(989.45) | Grad Norm 2.2274(25.7265) | Total Time 0.00(0.00)\n",
      "Iter 21920 | Time 25.5259(25.3831) | Bit/dim 3.3956(3.3952) | Xent 0.0000(0.0000) | Loss 8.7787(9.3054) | Error 0.0000(0.0000) Steps 994(990.07) | Grad Norm 2.7190(19.6881) | Total Time 0.00(0.00)\n",
      "Iter 21930 | Time 25.0396(25.4066) | Bit/dim 3.4069(3.3965) | Xent 0.0000(0.0000) | Loss 8.8083(9.1609) | Error 0.0000(0.0000) Steps 1012(989.21) | Grad Norm 1.4682(15.0911) | Total Time 0.00(0.00)\n",
      "Iter 21940 | Time 25.8490(25.3567) | Bit/dim 3.3810(3.3937) | Xent 0.0000(0.0000) | Loss 8.6617(9.0459) | Error 0.0000(0.0000) Steps 1000(991.12) | Grad Norm 2.8097(11.6555) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 112.8042, Epoch Time 1526.2236(1496.1638), Bit/dim 3.3998(best: 3.3963), Xent 0.0000, Loss 3.3998, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21950 | Time 24.7013(25.2432) | Bit/dim 3.3870(3.3927) | Xent 0.0000(0.0000) | Loss 8.7987(9.8858) | Error 0.0000(0.0000) Steps 1000(991.22) | Grad Norm 1.4933(9.2475) | Total Time 0.00(0.00)\n",
      "Iter 21960 | Time 25.7199(25.2685) | Bit/dim 3.4077(3.3937) | Xent 0.0000(0.0000) | Loss 8.8936(9.5950) | Error 0.0000(0.0000) Steps 988(993.34) | Grad Norm 3.9350(7.6045) | Total Time 0.00(0.00)\n",
      "Iter 21970 | Time 25.5142(25.2590) | Bit/dim 3.3870(3.3930) | Xent 0.0000(0.0000) | Loss 8.7606(9.3696) | Error 0.0000(0.0000) Steps 982(993.32) | Grad Norm 3.3827(6.4299) | Total Time 0.00(0.00)\n",
      "Iter 21980 | Time 25.4853(25.2552) | Bit/dim 3.3802(3.3923) | Xent 0.0000(0.0000) | Loss 8.8003(9.2031) | Error 0.0000(0.0000) Steps 1000(993.25) | Grad Norm 2.6728(5.2607) | Total Time 0.00(0.00)\n",
      "Iter 21990 | Time 24.8850(25.2809) | Bit/dim 3.3636(3.3942) | Xent 0.0000(0.0000) | Loss 8.7909(9.0964) | Error 0.0000(0.0000) Steps 1006(994.69) | Grad Norm 1.3520(4.2736) | Total Time 0.00(0.00)\n",
      "Iter 22000 | Time 25.6298(25.3049) | Bit/dim 3.4169(3.3949) | Xent 0.0000(0.0000) | Loss 8.8063(9.0104) | Error 0.0000(0.0000) Steps 988(992.20) | Grad Norm 1.3533(3.6138) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 113.4649, Epoch Time 1522.0568(1496.9406), Bit/dim 3.3988(best: 3.3963), Xent 0.0000, Loss 3.3988, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22010 | Time 25.4255(25.2660) | Bit/dim 3.3904(3.3941) | Xent 0.0000(0.0000) | Loss 8.6708(9.7397) | Error 0.0000(0.0000) Steps 952(987.94) | Grad Norm 1.6708(3.0875) | Total Time 0.00(0.00)\n",
      "Iter 22020 | Time 25.6472(25.3308) | Bit/dim 3.3967(3.3938) | Xent 0.0000(0.0000) | Loss 8.8658(9.4917) | Error 0.0000(0.0000) Steps 958(988.57) | Grad Norm 2.3742(2.7505) | Total Time 0.00(0.00)\n",
      "Iter 22030 | Time 25.4095(25.2799) | Bit/dim 3.4325(3.3965) | Xent 0.0000(0.0000) | Loss 8.8486(9.3019) | Error 0.0000(0.0000) Steps 988(984.82) | Grad Norm 1.7632(2.5617) | Total Time 0.00(0.00)\n",
      "Iter 22040 | Time 25.9209(25.2016) | Bit/dim 3.3883(3.3960) | Xent 0.0000(0.0000) | Loss 8.6469(9.1613) | Error 0.0000(0.0000) Steps 1024(987.44) | Grad Norm 1.5009(2.4676) | Total Time 0.00(0.00)\n",
      "Iter 22050 | Time 25.0474(25.2267) | Bit/dim 3.3623(3.3943) | Xent 0.0000(0.0000) | Loss 8.6378(9.0565) | Error 0.0000(0.0000) Steps 1024(986.51) | Grad Norm 2.3365(2.3515) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 113.7212, Epoch Time 1518.8137(1497.5968), Bit/dim 3.3977(best: 3.3963), Xent 0.0000, Loss 3.3977, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22060 | Time 25.4730(25.2426) | Bit/dim 3.3826(3.3973) | Xent 0.0000(0.0000) | Loss 8.6976(9.9254) | Error 0.0000(0.0000) Steps 1012(984.32) | Grad Norm 1.8642(2.2305) | Total Time 0.00(0.00)\n",
      "Iter 22070 | Time 24.9608(25.1615) | Bit/dim 3.4023(3.3960) | Xent 0.0000(0.0000) | Loss 8.8007(9.6193) | Error 0.0000(0.0000) Steps 1018(984.81) | Grad Norm 3.4689(2.3453) | Total Time 0.00(0.00)\n",
      "Iter 22080 | Time 24.5113(25.0551) | Bit/dim 3.4041(3.3934) | Xent 0.0000(0.0000) | Loss 8.7634(9.3836) | Error 0.0000(0.0000) Steps 1006(984.90) | Grad Norm 4.0431(2.5495) | Total Time 0.00(0.00)\n",
      "Iter 22090 | Time 25.2929(25.0265) | Bit/dim 3.4046(3.3940) | Xent 0.0000(0.0000) | Loss 8.8635(9.2178) | Error 0.0000(0.0000) Steps 982(984.11) | Grad Norm 1.4089(2.6584) | Total Time 0.00(0.00)\n",
      "Iter 22100 | Time 25.4280(25.0469) | Bit/dim 3.3991(3.3930) | Xent 0.0000(0.0000) | Loss 8.8361(9.0963) | Error 0.0000(0.0000) Steps 1024(983.16) | Grad Norm 4.7984(2.7790) | Total Time 0.00(0.00)\n",
      "Iter 22110 | Time 25.9837(25.1328) | Bit/dim 3.3564(3.3921) | Xent 0.0000(0.0000) | Loss 8.5146(8.9930) | Error 0.0000(0.0000) Steps 1006(982.97) | Grad Norm 44.0631(3.9711) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 113.1483, Epoch Time 1508.9459(1497.9372), Bit/dim 3.4003(best: 3.3963), Xent 0.0000, Loss 3.4003, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22120 | Time 25.6506(25.1606) | Bit/dim 3.4046(3.3924) | Xent 0.0000(0.0000) | Loss 8.6840(9.7386) | Error 0.0000(0.0000) Steps 1006(989.77) | Grad Norm 3.4216(3.6184) | Total Time 0.00(0.00)\n",
      "Iter 22130 | Time 24.8874(25.1931) | Bit/dim 3.3995(3.3928) | Xent 0.0000(0.0000) | Loss 8.7628(9.4782) | Error 0.0000(0.0000) Steps 964(991.69) | Grad Norm 2.4874(3.2153) | Total Time 0.00(0.00)\n",
      "Iter 22140 | Time 24.7872(25.1947) | Bit/dim 3.3572(3.3938) | Xent 0.0000(0.0000) | Loss 8.7180(9.2990) | Error 0.0000(0.0000) Steps 1012(994.17) | Grad Norm 2.2221(2.8648) | Total Time 0.00(0.00)\n",
      "Iter 22150 | Time 25.4919(25.2425) | Bit/dim 3.4002(3.3929) | Xent 0.0000(0.0000) | Loss 8.8085(9.1562) | Error 0.0000(0.0000) Steps 970(994.08) | Grad Norm 3.2241(2.6705) | Total Time 0.00(0.00)\n",
      "Iter 22160 | Time 25.6478(25.2327) | Bit/dim 3.4063(3.3910) | Xent 0.0000(0.0000) | Loss 8.9232(9.0439) | Error 0.0000(0.0000) Steps 988(992.73) | Grad Norm 1.8875(2.4727) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 112.0339, Epoch Time 1518.4289(1498.5520), Bit/dim 3.3970(best: 3.3963), Xent 0.0000, Loss 3.3970, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22170 | Time 25.4637(25.2023) | Bit/dim 3.4447(3.3942) | Xent 0.0000(0.0000) | Loss 8.9325(9.8932) | Error 0.0000(0.0000) Steps 1042(993.93) | Grad Norm 1.9055(2.4291) | Total Time 0.00(0.00)\n",
      "Iter 22180 | Time 25.2675(25.2436) | Bit/dim 3.3794(3.3932) | Xent 0.0000(0.0000) | Loss 8.7580(9.5927) | Error 0.0000(0.0000) Steps 1006(993.80) | Grad Norm 3.0424(2.4064) | Total Time 0.00(0.00)\n",
      "Iter 22190 | Time 24.9270(25.2993) | Bit/dim 3.4036(3.3923) | Xent 0.0000(0.0000) | Loss 8.6944(9.3737) | Error 0.0000(0.0000) Steps 1000(996.12) | Grad Norm 2.2210(2.3704) | Total Time 0.00(0.00)\n",
      "Iter 22200 | Time 25.4201(25.2510) | Bit/dim 3.4071(3.3922) | Xent 0.0000(0.0000) | Loss 8.7245(9.2083) | Error 0.0000(0.0000) Steps 1012(995.79) | Grad Norm 1.7179(2.2637) | Total Time 0.00(0.00)\n",
      "Iter 22210 | Time 25.5575(25.3108) | Bit/dim 3.3812(3.3926) | Xent 0.0000(0.0000) | Loss 8.7941(9.1011) | Error 0.0000(0.0000) Steps 1060(993.92) | Grad Norm 2.7610(2.2582) | Total Time 0.00(0.00)\n",
      "Iter 22220 | Time 26.0107(25.2784) | Bit/dim 3.3798(3.3926) | Xent 0.0000(0.0000) | Loss 8.8109(9.0136) | Error 0.0000(0.0000) Steps 1018(993.37) | Grad Norm 2.8880(2.2746) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 112.0235, Epoch Time 1521.3508(1499.2359), Bit/dim 3.3989(best: 3.3963), Xent 0.0000, Loss 3.3989, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22230 | Time 25.6214(25.3307) | Bit/dim 3.4031(3.3959) | Xent 0.0000(0.0000) | Loss 8.8674(9.7631) | Error 0.0000(0.0000) Steps 970(990.04) | Grad Norm 1.7043(2.2646) | Total Time 0.00(0.00)\n",
      "Iter 22240 | Time 27.0729(25.3458) | Bit/dim 3.4105(3.3965) | Xent 0.0000(0.0000) | Loss 8.9285(9.5055) | Error 0.0000(0.0000) Steps 1030(989.79) | Grad Norm 1.6884(2.2597) | Total Time 0.00(0.00)\n",
      "Iter 22250 | Time 25.8592(25.3313) | Bit/dim 3.3941(3.3928) | Xent 0.0000(0.0000) | Loss 8.7756(9.3140) | Error 0.0000(0.0000) Steps 1012(989.03) | Grad Norm 1.4845(2.2407) | Total Time 0.00(0.00)\n",
      "Iter 22260 | Time 25.0637(25.2360) | Bit/dim 3.3942(3.3925) | Xent 0.0000(0.0000) | Loss 8.6885(9.1616) | Error 0.0000(0.0000) Steps 970(986.45) | Grad Norm 4.3659(2.3417) | Total Time 0.00(0.00)\n",
      "Iter 22270 | Time 25.2273(25.2729) | Bit/dim 3.4168(3.3915) | Xent 0.0000(0.0000) | Loss 8.7182(9.0520) | Error 0.0000(0.0000) Steps 982(987.36) | Grad Norm 2.7265(2.4736) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 113.1695, Epoch Time 1522.3884(1499.9305), Bit/dim 3.3974(best: 3.3963), Xent 0.0000, Loss 3.3974, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22280 | Time 27.0158(25.2646) | Bit/dim 3.4080(3.3924) | Xent 0.0000(0.0000) | Loss 8.8105(9.9029) | Error 0.0000(0.0000) Steps 964(986.96) | Grad Norm 1.1796(2.3562) | Total Time 0.00(0.00)\n",
      "Iter 22290 | Time 24.9432(25.1914) | Bit/dim 3.3481(3.3928) | Xent 0.0000(0.0000) | Loss 8.6966(9.6029) | Error 0.0000(0.0000) Steps 988(986.05) | Grad Norm 3.1646(2.3614) | Total Time 0.00(0.00)\n",
      "Iter 22300 | Time 24.6706(25.1972) | Bit/dim 3.3859(3.3946) | Xent 0.0000(0.0000) | Loss 8.7363(9.3780) | Error 0.0000(0.0000) Steps 1024(986.70) | Grad Norm 1.5180(2.1824) | Total Time 0.00(0.00)\n",
      "Iter 22310 | Time 23.8705(25.1297) | Bit/dim 3.3486(3.3923) | Xent 0.0000(0.0000) | Loss 8.6142(9.2131) | Error 0.0000(0.0000) Steps 982(985.48) | Grad Norm 3.3190(2.1743) | Total Time 0.00(0.00)\n",
      "Iter 22320 | Time 25.0365(25.1106) | Bit/dim 3.3784(3.3909) | Xent 0.0000(0.0000) | Loss 8.7620(9.0840) | Error 0.0000(0.0000) Steps 1012(985.44) | Grad Norm 4.1599(2.3437) | Total Time 0.00(0.00)\n",
      "Iter 22330 | Time 24.7835(25.0841) | Bit/dim 3.4269(3.3944) | Xent 0.0000(0.0000) | Loss 8.8246(9.0070) | Error 0.0000(0.0000) Steps 982(985.25) | Grad Norm 2.5013(2.5350) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 112.8337, Epoch Time 1510.3003(1500.2416), Bit/dim 3.3982(best: 3.3963), Xent 0.0000, Loss 3.3982, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22340 | Time 25.4711(25.2521) | Bit/dim 3.4399(3.3961) | Xent 0.0000(0.0000) | Loss 8.7653(9.7643) | Error 0.0000(0.0000) Steps 1006(985.99) | Grad Norm 1.7020(2.6591) | Total Time 0.00(0.00)\n",
      "Iter 22350 | Time 25.6978(25.3323) | Bit/dim 3.4207(3.3935) | Xent 0.0000(0.0000) | Loss 8.8077(9.5019) | Error 0.0000(0.0000) Steps 1012(989.70) | Grad Norm 3.4776(2.9690) | Total Time 0.00(0.00)\n",
      "Iter 22360 | Time 26.0546(25.4042) | Bit/dim 3.4333(3.3944) | Xent 0.0000(0.0000) | Loss 8.7773(9.3074) | Error 0.0000(0.0000) Steps 982(989.32) | Grad Norm 2.8664(3.0581) | Total Time 0.00(0.00)\n",
      "Iter 22370 | Time 25.3773(25.4179) | Bit/dim 3.4034(3.3935) | Xent 0.0000(0.0000) | Loss 8.7538(9.1595) | Error 0.0000(0.0000) Steps 982(987.83) | Grad Norm 3.7391(3.0904) | Total Time 0.00(0.00)\n",
      "Iter 22380 | Time 25.1060(25.4312) | Bit/dim 3.3985(3.3922) | Xent 0.0000(0.0000) | Loss 8.7973(9.0573) | Error 0.0000(0.0000) Steps 982(991.92) | Grad Norm 3.6891(3.0087) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 114.7122, Epoch Time 1540.1509(1501.4389), Bit/dim 3.3971(best: 3.3963), Xent 0.0000, Loss 3.3971, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22390 | Time 25.3949(25.5639) | Bit/dim 3.3999(3.3927) | Xent 0.0000(0.0000) | Loss 8.8031(9.9229) | Error 0.0000(0.0000) Steps 1000(995.35) | Grad Norm 2.6713(2.8611) | Total Time 0.00(0.00)\n",
      "Iter 22400 | Time 25.6911(25.4645) | Bit/dim 3.3775(3.3898) | Xent 0.0000(0.0000) | Loss 8.7558(9.6205) | Error 0.0000(0.0000) Steps 982(996.28) | Grad Norm 1.9077(2.6103) | Total Time 0.00(0.00)\n",
      "Iter 22410 | Time 24.8135(25.3725) | Bit/dim 3.3632(3.3912) | Xent 0.0000(0.0000) | Loss 8.7421(9.3948) | Error 0.0000(0.0000) Steps 1006(990.89) | Grad Norm 1.5091(2.3522) | Total Time 0.00(0.00)\n",
      "Iter 22420 | Time 24.7274(25.3404) | Bit/dim 3.4034(3.3916) | Xent 0.0000(0.0000) | Loss 8.9053(9.2296) | Error 0.0000(0.0000) Steps 1000(988.75) | Grad Norm 1.8886(4.4948) | Total Time 0.00(0.00)\n",
      "Iter 22430 | Time 25.2152(25.3683) | Bit/dim 3.4202(3.3911) | Xent 0.0000(0.0000) | Loss 8.8027(9.1007) | Error 0.0000(0.0000) Steps 1012(990.75) | Grad Norm 1.2000(3.8849) | Total Time 0.00(0.00)\n",
      "Iter 22440 | Time 25.4517(25.3414) | Bit/dim 3.4369(3.3923) | Xent 0.0000(0.0000) | Loss 8.8887(8.9968) | Error 0.0000(0.0000) Steps 970(988.63) | Grad Norm 1.3986(3.2610) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 111.9432, Epoch Time 1523.7101(1502.1070), Bit/dim 3.3962(best: 3.3963), Xent 0.0000, Loss 3.3962, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22450 | Time 25.7008(25.3904) | Bit/dim 3.4173(3.3940) | Xent 0.0000(0.0000) | Loss 8.8391(9.7451) | Error 0.0000(0.0000) Steps 1012(987.77) | Grad Norm 2.4186(2.8632) | Total Time 0.00(0.00)\n",
      "Iter 22460 | Time 24.5741(25.3189) | Bit/dim 3.3843(3.3922) | Xent 0.0000(0.0000) | Loss 8.8087(9.4773) | Error 0.0000(0.0000) Steps 1006(985.74) | Grad Norm 2.0946(2.6549) | Total Time 0.00(0.00)\n",
      "Iter 22470 | Time 25.2367(25.2420) | Bit/dim 3.4058(3.3904) | Xent 0.0000(0.0000) | Loss 8.8405(9.2790) | Error 0.0000(0.0000) Steps 1018(984.15) | Grad Norm 2.3398(2.4757) | Total Time 0.00(0.00)\n",
      "Iter 22480 | Time 26.7353(25.3256) | Bit/dim 3.3770(3.3918) | Xent 0.0000(0.0000) | Loss 8.7368(9.1351) | Error 0.0000(0.0000) Steps 1006(985.06) | Grad Norm 1.0601(2.2069) | Total Time 0.00(0.00)\n",
      "Iter 22490 | Time 24.6092(25.3013) | Bit/dim 3.3682(3.3928) | Xent 0.0000(0.0000) | Loss 8.8028(9.0389) | Error 0.0000(0.0000) Steps 1024(984.79) | Grad Norm 2.5513(2.1670) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 113.2642, Epoch Time 1521.7845(1502.6973), Bit/dim 3.3974(best: 3.3962), Xent 0.0000, Loss 3.3974, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22500 | Time 24.8100(25.3266) | Bit/dim 3.3654(3.3920) | Xent 0.0000(0.0000) | Loss 8.7143(9.8804) | Error 0.0000(0.0000) Steps 994(982.63) | Grad Norm 2.4914(2.0601) | Total Time 0.00(0.00)\n",
      "Iter 22510 | Time 24.9664(25.3809) | Bit/dim 3.3893(3.3913) | Xent 0.0000(0.0000) | Loss 8.6708(9.5788) | Error 0.0000(0.0000) Steps 976(983.90) | Grad Norm 2.6486(2.1411) | Total Time 0.00(0.00)\n",
      "Iter 22520 | Time 25.6992(25.3706) | Bit/dim 3.4050(3.3921) | Xent 0.0000(0.0000) | Loss 8.8685(9.3705) | Error 0.0000(0.0000) Steps 970(983.32) | Grad Norm 2.3952(2.2470) | Total Time 0.00(0.00)\n",
      "Iter 22530 | Time 26.1857(25.4014) | Bit/dim 3.3684(3.3890) | Xent 0.0000(0.0000) | Loss 8.7168(9.1960) | Error 0.0000(0.0000) Steps 964(983.96) | Grad Norm 2.0321(2.3640) | Total Time 0.00(0.00)\n",
      "Iter 22540 | Time 25.7525(25.3335) | Bit/dim 3.3769(3.3899) | Xent 0.0000(0.0000) | Loss 8.8233(9.0769) | Error 0.0000(0.0000) Steps 976(984.22) | Grad Norm 3.0944(2.3778) | Total Time 0.00(0.00)\n",
      "Iter 22550 | Time 25.1229(25.3600) | Bit/dim 3.4200(3.3955) | Xent 0.0000(0.0000) | Loss 8.7748(9.0020) | Error 0.0000(0.0000) Steps 958(986.09) | Grad Norm 1.8722(2.2456) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 114.2537, Epoch Time 1529.4640(1503.5003), Bit/dim 3.3987(best: 3.3962), Xent 0.0000, Loss 3.3987, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22560 | Time 24.9915(25.3161) | Bit/dim 3.4351(3.3973) | Xent 0.0000(0.0000) | Loss 8.9404(9.7380) | Error 0.0000(0.0000) Steps 976(986.71) | Grad Norm 1.5061(2.1130) | Total Time 0.00(0.00)\n",
      "Iter 22570 | Time 25.2323(25.2510) | Bit/dim 3.4163(3.3979) | Xent 0.0000(0.0000) | Loss 8.8111(9.4809) | Error 0.0000(0.0000) Steps 1018(984.19) | Grad Norm 2.6974(2.0345) | Total Time 0.00(0.00)\n",
      "Iter 22580 | Time 26.1634(25.3281) | Bit/dim 3.3539(3.3964) | Xent 0.0000(0.0000) | Loss 8.5938(9.2777) | Error 0.0000(0.0000) Steps 964(984.88) | Grad Norm 2.4979(2.1688) | Total Time 0.00(0.00)\n",
      "Iter 22590 | Time 25.4967(25.3727) | Bit/dim 3.3886(3.3930) | Xent 0.0000(0.0000) | Loss 8.7752(9.1277) | Error 0.0000(0.0000) Steps 994(986.73) | Grad Norm 2.2452(2.1724) | Total Time 0.00(0.00)\n",
      "Iter 22600 | Time 25.5263(25.2950) | Bit/dim 3.3487(3.3911) | Xent 0.0000(0.0000) | Loss 8.7581(9.0296) | Error 0.0000(0.0000) Steps 1006(988.31) | Grad Norm 3.1101(2.1935) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 114.1656, Epoch Time 1524.0911(1504.1181), Bit/dim 3.3981(best: 3.3962), Xent 0.0000, Loss 3.3981, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22610 | Time 25.6554(25.3420) | Bit/dim 3.4001(3.3922) | Xent 0.0000(0.0000) | Loss 8.8645(9.9424) | Error 0.0000(0.0000) Steps 1000(990.41) | Grad Norm 3.3246(4.9476) | Total Time 0.00(0.00)\n",
      "Iter 22620 | Time 25.0916(25.3763) | Bit/dim 3.3835(3.3908) | Xent 0.0000(0.0000) | Loss 8.6388(9.6472) | Error 0.0000(0.0000) Steps 1006(991.20) | Grad Norm 1.7237(4.2643) | Total Time 0.00(0.00)\n",
      "Iter 22630 | Time 25.6184(25.4802) | Bit/dim 3.4031(3.3909) | Xent 0.0000(0.0000) | Loss 8.8987(9.4282) | Error 0.0000(0.0000) Steps 1012(995.65) | Grad Norm 1.9282(3.6421) | Total Time 0.00(0.00)\n",
      "Iter 22640 | Time 24.9963(25.5318) | Bit/dim 3.4317(3.3920) | Xent 0.0000(0.0000) | Loss 8.6986(9.2555) | Error 0.0000(0.0000) Steps 976(997.08) | Grad Norm 1.5247(3.3119) | Total Time 0.00(0.00)\n",
      "Iter 22650 | Time 26.4125(25.6423) | Bit/dim 3.3950(3.3936) | Xent 0.0000(0.0000) | Loss 8.8056(9.1427) | Error 0.0000(0.0000) Steps 1054(998.02) | Grad Norm 2.3919(3.0770) | Total Time 0.00(0.00)\n",
      "Iter 22660 | Time 25.3501(25.5991) | Bit/dim 3.3585(3.3923) | Xent 0.0000(0.0000) | Loss 8.7038(9.0551) | Error 0.0000(0.0000) Steps 970(999.39) | Grad Norm 1.6670(2.9487) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 115.5549, Epoch Time 1544.9093(1505.3418), Bit/dim 3.3995(best: 3.3962), Xent 0.0000, Loss 3.3995, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22670 | Time 26.3563(25.5983) | Bit/dim 3.3571(3.3901) | Xent 0.0000(0.0000) | Loss 8.7231(9.8192) | Error 0.0000(0.0000) Steps 1000(1001.04) | Grad Norm 1.4820(2.6268) | Total Time 0.00(0.00)\n",
      "Iter 22680 | Time 26.6110(25.5950) | Bit/dim 3.3934(3.3903) | Xent 0.0000(0.0000) | Loss 8.9055(9.5480) | Error 0.0000(0.0000) Steps 1042(1001.80) | Grad Norm 3.3903(2.5807) | Total Time 0.00(0.00)\n",
      "Iter 22690 | Time 25.4757(25.4344) | Bit/dim 3.4265(3.3910) | Xent 0.0000(0.0000) | Loss 9.0056(9.3468) | Error 0.0000(0.0000) Steps 976(1000.63) | Grad Norm 3.8243(2.6223) | Total Time 0.00(0.00)\n",
      "Iter 22700 | Time 25.6035(25.4179) | Bit/dim 3.4023(3.3909) | Xent 0.0000(0.0000) | Loss 8.8784(9.2047) | Error 0.0000(0.0000) Steps 964(999.03) | Grad Norm 3.7038(2.7847) | Total Time 0.00(0.00)\n",
      "Iter 22710 | Time 25.2013(25.4393) | Bit/dim 3.3740(3.3931) | Xent 0.0000(0.0000) | Loss 8.7807(9.1064) | Error 0.0000(0.0000) Steps 1012(1000.80) | Grad Norm 3.3463(2.8767) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 113.2853, Epoch Time 1526.4649(1505.9755), Bit/dim 3.4023(best: 3.3962), Xent 0.0000, Loss 3.4023, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22720 | Time 26.2182(25.4255) | Bit/dim 3.3896(3.3938) | Xent 0.0000(0.0000) | Loss 8.8585(9.9710) | Error 0.0000(0.0000) Steps 1042(999.72) | Grad Norm 2.0953(2.7011) | Total Time 0.00(0.00)\n",
      "Iter 22730 | Time 26.8111(25.5377) | Bit/dim 3.4096(3.3931) | Xent 0.0000(0.0000) | Loss 8.8478(9.6594) | Error 0.0000(0.0000) Steps 994(1005.54) | Grad Norm 2.0159(2.6097) | Total Time 0.00(0.00)\n",
      "Iter 22740 | Time 25.4892(25.5833) | Bit/dim 3.4302(3.3948) | Xent 0.0000(0.0000) | Loss 8.9173(9.4299) | Error 0.0000(0.0000) Steps 970(1002.69) | Grad Norm 2.9947(2.7348) | Total Time 0.00(0.00)\n",
      "Iter 22750 | Time 25.2510(25.4852) | Bit/dim 3.3987(3.3947) | Xent 0.0000(0.0000) | Loss 8.7415(9.2712) | Error 0.0000(0.0000) Steps 1024(1004.09) | Grad Norm 3.3128(2.7630) | Total Time 0.00(0.00)\n",
      "Iter 22760 | Time 25.3500(25.4875) | Bit/dim 3.3985(3.3943) | Xent 0.0000(0.0000) | Loss 8.8270(9.1379) | Error 0.0000(0.0000) Steps 964(1004.38) | Grad Norm 1.6065(2.7055) | Total Time 0.00(0.00)\n",
      "Iter 22770 | Time 25.3637(25.5396) | Bit/dim 3.3982(3.3949) | Xent 0.0000(0.0000) | Loss 8.7691(9.0423) | Error 0.0000(0.0000) Steps 994(1005.71) | Grad Norm 1.1229(2.6007) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 114.0537, Epoch Time 1540.9781(1507.0256), Bit/dim 3.3964(best: 3.3962), Xent 0.0000, Loss 3.3964, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22780 | Time 26.1359(25.6020) | Bit/dim 3.4047(3.3936) | Xent 0.0000(0.0000) | Loss 8.9545(9.7830) | Error 0.0000(0.0000) Steps 988(1004.55) | Grad Norm 1.4286(2.3829) | Total Time 0.00(0.00)\n",
      "Iter 22790 | Time 24.6615(25.5208) | Bit/dim 3.3777(3.3900) | Xent 0.0000(0.0000) | Loss 8.5278(9.5168) | Error 0.0000(0.0000) Steps 976(998.77) | Grad Norm 3.3321(2.2902) | Total Time 0.00(0.00)\n",
      "Iter 22800 | Time 25.7022(25.5473) | Bit/dim 3.4308(3.3915) | Xent 0.0000(0.0000) | Loss 8.8716(9.3343) | Error 0.0000(0.0000) Steps 982(998.93) | Grad Norm 2.2710(2.2877) | Total Time 0.00(0.00)\n",
      "Iter 22810 | Time 25.5488(25.5043) | Bit/dim 3.4190(3.3942) | Xent 0.0000(0.0000) | Loss 8.8738(9.2056) | Error 0.0000(0.0000) Steps 1006(1001.81) | Grad Norm 1.7732(2.2495) | Total Time 0.00(0.00)\n",
      "Iter 22820 | Time 24.5744(25.5359) | Bit/dim 3.3693(3.3927) | Xent 0.0000(0.0000) | Loss 8.6622(9.0921) | Error 0.0000(0.0000) Steps 988(1001.59) | Grad Norm 1.4438(2.0927) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 116.0817, Epoch Time 1542.0480(1508.0763), Bit/dim 3.3975(best: 3.3962), Xent 0.0000, Loss 3.3975, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22830 | Time 26.6025(25.6365) | Bit/dim 3.3685(3.3912) | Xent 0.0000(0.0000) | Loss 8.7183(9.9836) | Error 0.0000(0.0000) Steps 982(1004.74) | Grad Norm 1.9697(2.0778) | Total Time 0.00(0.00)\n",
      "Iter 22840 | Time 25.9994(25.6543) | Bit/dim 3.3654(3.3904) | Xent 0.0000(0.0000) | Loss 8.7652(9.6631) | Error 0.0000(0.0000) Steps 1036(1005.49) | Grad Norm 3.0131(2.0932) | Total Time 0.00(0.00)\n",
      "Iter 22850 | Time 25.1595(25.7151) | Bit/dim 3.3971(3.3922) | Xent 0.0000(0.0000) | Loss 8.8197(9.4375) | Error 0.0000(0.0000) Steps 1012(1004.54) | Grad Norm 2.4983(2.2491) | Total Time 0.00(0.00)\n",
      "Iter 22860 | Time 25.1897(25.6144) | Bit/dim 3.3736(3.3911) | Xent 0.0000(0.0000) | Loss 8.6647(9.2580) | Error 0.0000(0.0000) Steps 982(1004.04) | Grad Norm 1.0675(2.2331) | Total Time 0.00(0.00)\n",
      "Iter 22870 | Time 25.6890(25.6260) | Bit/dim 3.4134(3.3937) | Xent 0.0000(0.0000) | Loss 8.7474(9.1494) | Error 0.0000(0.0000) Steps 1018(1002.72) | Grad Norm 1.8815(2.1388) | Total Time 0.00(0.00)\n",
      "Iter 22880 | Time 25.5330(25.6243) | Bit/dim 3.3875(3.3927) | Xent 0.0000(0.0000) | Loss 8.6584(9.0566) | Error 0.0000(0.0000) Steps 976(1000.88) | Grad Norm 1.1364(2.0753) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 114.1431, Epoch Time 1542.7433(1509.1163), Bit/dim 3.4000(best: 3.3962), Xent 0.0000, Loss 3.4000, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22890 | Time 25.8357(25.5858) | Bit/dim 3.3905(3.3913) | Xent 0.0000(0.0000) | Loss 8.7511(9.8151) | Error 0.0000(0.0000) Steps 970(1001.42) | Grad Norm 1.7334(1.9249) | Total Time 0.00(0.00)\n",
      "Iter 22900 | Time 25.3512(25.6299) | Bit/dim 3.3805(3.3911) | Xent 0.0000(0.0000) | Loss 8.8231(9.5490) | Error 0.0000(0.0000) Steps 964(1003.20) | Grad Norm 1.8861(1.9111) | Total Time 0.00(0.00)\n",
      "Iter 22910 | Time 25.4723(25.5730) | Bit/dim 3.3790(3.3932) | Xent 0.0000(0.0000) | Loss 8.7708(9.3536) | Error 0.0000(0.0000) Steps 1006(1000.35) | Grad Norm 3.2469(2.0759) | Total Time 0.00(0.00)\n",
      "Iter 22920 | Time 26.3269(25.6861) | Bit/dim 3.3848(3.3930) | Xent 0.0000(0.0000) | Loss 8.8910(9.2096) | Error 0.0000(0.0000) Steps 1084(999.52) | Grad Norm 1.3492(2.0370) | Total Time 0.00(0.00)\n",
      "Iter 22930 | Time 25.7566(25.6326) | Bit/dim 3.3844(3.3936) | Xent 0.0000(0.0000) | Loss 8.8248(9.0957) | Error 0.0000(0.0000) Steps 982(995.45) | Grad Norm 1.7617(2.0530) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 116.3129, Epoch Time 1541.4871(1510.0874), Bit/dim 3.3973(best: 3.3962), Xent 0.0000, Loss 3.3973, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22940 | Time 25.1442(25.5764) | Bit/dim 3.4006(3.3923) | Xent 0.0000(0.0000) | Loss 8.8489(9.9638) | Error 0.0000(0.0000) Steps 1012(999.20) | Grad Norm 1.7136(2.0644) | Total Time 0.00(0.00)\n",
      "Iter 22950 | Time 25.4529(25.5301) | Bit/dim 3.4030(3.3908) | Xent 0.0000(0.0000) | Loss 8.9035(9.6550) | Error 0.0000(0.0000) Steps 1030(1000.00) | Grad Norm 2.3594(2.2093) | Total Time 0.00(0.00)\n",
      "Iter 22960 | Time 24.6090(25.4586) | Bit/dim 3.3886(3.3913) | Xent 0.0000(0.0000) | Loss 8.6012(9.4253) | Error 0.0000(0.0000) Steps 1000(998.88) | Grad Norm 4.5228(2.4538) | Total Time 0.00(0.00)\n",
      "Iter 22970 | Time 25.9850(25.5140) | Bit/dim 3.3925(3.3911) | Xent 0.0000(0.0000) | Loss 8.8824(9.2656) | Error 0.0000(0.0000) Steps 994(1002.16) | Grad Norm 2.5351(2.5619) | Total Time 0.00(0.00)\n",
      "Iter 22980 | Time 26.5346(25.5845) | Bit/dim 3.4193(3.3924) | Xent 0.0000(0.0000) | Loss 8.8483(9.1466) | Error 0.0000(0.0000) Steps 988(1001.76) | Grad Norm 1.4620(2.5982) | Total Time 0.00(0.00)\n",
      "Iter 22990 | Time 26.1917(25.6089) | Bit/dim 3.3916(3.3924) | Xent 0.0000(0.0000) | Loss 8.7814(9.0551) | Error 0.0000(0.0000) Steps 976(1001.68) | Grad Norm 1.8078(2.4363) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 113.9067, Epoch Time 1538.4972(1510.9397), Bit/dim 3.4013(best: 3.3962), Xent 0.0000, Loss 3.4013, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23000 | Time 25.6231(25.5970) | Bit/dim 3.3808(3.3911) | Xent 0.0000(0.0000) | Loss 8.6157(9.7710) | Error 0.0000(0.0000) Steps 1042(1004.52) | Grad Norm 1.3815(2.2600) | Total Time 0.00(0.00)\n",
      "Iter 23010 | Time 26.6232(25.7406) | Bit/dim 3.3836(3.3901) | Xent 0.0000(0.0000) | Loss 8.7512(9.5099) | Error 0.0000(0.0000) Steps 988(1004.12) | Grad Norm 1.8382(2.1898) | Total Time 0.00(0.00)\n",
      "Iter 23020 | Time 25.6043(25.7513) | Bit/dim 3.3594(3.3915) | Xent 0.0000(0.0000) | Loss 8.8359(9.3274) | Error 0.0000(0.0000) Steps 1000(1003.03) | Grad Norm 4.3311(2.4149) | Total Time 0.00(0.00)\n",
      "Iter 23030 | Time 25.7361(25.7652) | Bit/dim 3.3899(3.3908) | Xent 0.0000(0.0000) | Loss 8.5682(9.1760) | Error 0.0000(0.0000) Steps 946(1003.70) | Grad Norm 4.4755(2.6774) | Total Time 0.00(0.00)\n",
      "Iter 23040 | Time 25.5218(25.7422) | Bit/dim 3.4318(3.3925) | Xent 0.0000(0.0000) | Loss 8.8882(9.0774) | Error 0.0000(0.0000) Steps 1030(1006.31) | Grad Norm 1.9550(2.6982) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 114.1278, Epoch Time 1551.9796(1512.1709), Bit/dim 3.3983(best: 3.3962), Xent 0.0000, Loss 3.3983, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23050 | Time 25.3804(25.7384) | Bit/dim 3.4128(3.3963) | Xent 0.0000(0.0000) | Loss 8.8689(9.9289) | Error 0.0000(0.0000) Steps 1018(1003.76) | Grad Norm 1.0954(2.4238) | Total Time 0.00(0.00)\n",
      "Iter 23060 | Time 26.4081(25.6511) | Bit/dim 3.3735(3.3961) | Xent 0.0000(0.0000) | Loss 8.8568(9.6345) | Error 0.0000(0.0000) Steps 1006(1005.73) | Grad Norm 1.7971(2.2580) | Total Time 0.00(0.00)\n",
      "Iter 23070 | Time 26.4965(25.7285) | Bit/dim 3.3952(3.3955) | Xent 0.0000(0.0000) | Loss 8.9565(9.4151) | Error 0.0000(0.0000) Steps 1054(1007.83) | Grad Norm 3.4720(2.2932) | Total Time 0.00(0.00)\n",
      "Iter 23080 | Time 25.9748(25.8037) | Bit/dim 3.3892(3.3929) | Xent 0.0000(0.0000) | Loss 8.7390(9.2590) | Error 0.0000(0.0000) Steps 994(1011.30) | Grad Norm 2.1719(2.4393) | Total Time 0.00(0.00)\n",
      "Iter 23090 | Time 25.7010(25.7890) | Bit/dim 3.3497(3.3894) | Xent 0.0000(0.0000) | Loss 8.6870(9.1349) | Error 0.0000(0.0000) Steps 1030(1011.03) | Grad Norm 3.0627(2.4042) | Total Time 0.00(0.00)\n",
      "Iter 23100 | Time 26.4284(25.7676) | Bit/dim 3.4090(3.3912) | Xent 0.0000(0.0000) | Loss 8.9013(9.0445) | Error 0.0000(0.0000) Steps 964(1005.17) | Grad Norm 1.6044(2.3343) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 114.4235, Epoch Time 1547.9970(1513.2457), Bit/dim 3.3954(best: 3.3962), Xent 0.0000, Loss 3.3954, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23110 | Time 26.2864(25.6543) | Bit/dim 3.3832(3.3914) | Xent 0.0000(0.0000) | Loss 8.8041(9.8087) | Error 0.0000(0.0000) Steps 1006(1005.55) | Grad Norm 1.4568(2.4946) | Total Time 0.00(0.00)\n",
      "Iter 23120 | Time 25.6615(25.6692) | Bit/dim 3.3899(3.3942) | Xent 0.0000(0.0000) | Loss 8.7058(9.5284) | Error 0.0000(0.0000) Steps 1000(1003.80) | Grad Norm 1.8667(2.2890) | Total Time 0.00(0.00)\n",
      "Iter 23130 | Time 26.5010(25.6290) | Bit/dim 3.3956(3.3925) | Xent 0.0000(0.0000) | Loss 8.8682(9.3383) | Error 0.0000(0.0000) Steps 1036(1006.21) | Grad Norm 2.0872(2.2353) | Total Time 0.00(0.00)\n",
      "Iter 23140 | Time 25.5719(25.6645) | Bit/dim 3.3891(3.3940) | Xent 0.0000(0.0000) | Loss 8.7884(9.1948) | Error 0.0000(0.0000) Steps 970(1007.11) | Grad Norm 2.6786(2.1831) | Total Time 0.00(0.00)\n",
      "Iter 23150 | Time 26.9853(25.6139) | Bit/dim 3.3967(3.3900) | Xent 0.0000(0.0000) | Loss 8.8578(9.0755) | Error 0.0000(0.0000) Steps 982(1005.59) | Grad Norm 1.6843(2.1020) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 115.0623, Epoch Time 1537.9690(1513.9874), Bit/dim 3.3951(best: 3.3954), Xent 0.0000, Loss 3.3951, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23160 | Time 25.3521(25.5648) | Bit/dim 3.4095(3.3869) | Xent 0.0000(0.0000) | Loss 8.6725(9.9441) | Error 0.0000(0.0000) Steps 1000(1006.34) | Grad Norm 1.6063(2.1300) | Total Time 0.00(0.00)\n",
      "Iter 23170 | Time 25.4151(25.5880) | Bit/dim 3.4158(3.3887) | Xent 0.0000(0.0000) | Loss 8.6348(9.6412) | Error 0.0000(0.0000) Steps 964(1006.08) | Grad Norm 1.8301(2.1973) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_cifar10_bs900_rl_stdscale_6_run3 --resume ../experiments_published/cnf_cifar10_bs900_rl_stdscale_6_run3/epoch_250_checkpt.pth --seed 3 --lr 0.0001 --conditional False --controlled_tol False --log_freq 10 --scale_fac 1.0 --scale_std 6.0\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
