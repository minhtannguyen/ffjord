{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, conditional=False, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume=None, rtol=1e-05, save='../experiments_published/cnf_cifar10_published_baseline_bs900_3', seed=3, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=6144, bias=True)\n",
      "  (project_class): LinearZeros(in_features=3072, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1469494\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 0010 | Time 12.7340(33.2019) | Bit/dim 9.2523(9.4929) | Xent 0.0000(0.0000) | Loss 9.2523(9.4929) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 17.1377(20.4788) | Total Time 14.00(14.00)\n",
      "Iter 0020 | Time 12.9781(27.8852) | Bit/dim 8.6445(9.3373) | Xent 0.0000(0.0000) | Loss 8.6445(9.3373) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 7.7802(18.1985) | Total Time 14.00(14.00)\n",
      "Iter 0030 | Time 13.2150(23.9875) | Bit/dim 8.4203(9.1184) | Xent 0.0000(0.0000) | Loss 8.4203(9.1184) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 3.2423(14.5774) | Total Time 14.00(14.00)\n",
      "Iter 0040 | Time 13.2963(21.1175) | Bit/dim 8.2673(8.9098) | Xent 0.0000(0.0000) | Loss 8.2673(8.9098) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 3.6299(11.6648) | Total Time 14.00(14.00)\n",
      "Iter 0050 | Time 13.0246(18.9920) | Bit/dim 8.0111(8.7057) | Xent 0.0000(0.0000) | Loss 8.0111(8.7057) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 2.3783(9.3255) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 80.2629, Epoch Time 840.2765(840.2765), Bit/dim 7.8598(best: inf), Xent 0.0000, Loss 7.8598, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0060 | Time 12.7694(17.4789) | Bit/dim 7.7509(8.4866) | Xent 0.0000(0.0000) | Loss 7.7509(8.4866) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 2.6493(7.5557) | Total Time 14.00(14.00)\n",
      "Iter 0070 | Time 13.4387(16.2969) | Bit/dim 7.4590(8.2502) | Xent 0.0000(0.0000) | Loss 7.4590(8.2502) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 2.0439(6.1718) | Total Time 14.00(14.00)\n",
      "Iter 0080 | Time 12.8324(15.4104) | Bit/dim 7.2456(8.0075) | Xent 0.0000(0.0000) | Loss 7.2456(8.0075) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 1.6260(5.0422) | Total Time 14.00(14.00)\n",
      "Iter 0090 | Time 13.0646(14.7882) | Bit/dim 7.1202(7.7871) | Xent 0.0000(0.0000) | Loss 7.1202(7.7871) | Error 0.0000(0.0000) Steps 580(574.52) | Grad Norm 1.3636(4.1040) | Total Time 14.00(14.00)\n",
      "Iter 0100 | Time 13.9299(14.4008) | Bit/dim 7.0789(7.6024) | Xent 0.0000(0.0000) | Loss 7.0789(7.6024) | Error 0.0000(0.0000) Steps 586(576.31) | Grad Norm 0.9436(3.3015) | Total Time 14.00(14.00)\n",
      "Iter 0110 | Time 13.7978(14.2162) | Bit/dim 7.0006(7.4518) | Xent 0.0000(0.0000) | Loss 7.0006(7.4518) | Error 0.0000(0.0000) Steps 592(579.54) | Grad Norm 0.5557(2.5908) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 77.0236, Epoch Time 820.9598(839.6970), Bit/dim 7.0091(best: 7.8598), Xent 0.0000, Loss 7.0091, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0120 | Time 14.1072(14.1287) | Bit/dim 6.9607(7.3296) | Xent 0.0000(0.0000) | Loss 6.9607(7.3296) | Error 0.0000(0.0000) Steps 592(582.81) | Grad Norm 0.5779(2.0515) | Total Time 14.00(14.00)\n",
      "Iter 0130 | Time 13.7702(14.1609) | Bit/dim 6.9479(7.2322) | Xent 0.0000(0.0000) | Loss 6.9479(7.2322) | Error 0.0000(0.0000) Steps 598(586.57) | Grad Norm 0.4816(1.6152) | Total Time 14.00(14.00)\n",
      "Iter 0140 | Time 14.3037(14.2473) | Bit/dim 6.8932(7.1507) | Xent 0.0000(0.0000) | Loss 6.8932(7.1507) | Error 0.0000(0.0000) Steps 604(591.00) | Grad Norm 0.3118(1.3015) | Total Time 14.00(14.00)\n",
      "Iter 0150 | Time 14.7095(14.4418) | Bit/dim 6.8501(7.0795) | Xent 0.0000(0.0000) | Loss 6.8501(7.0795) | Error 0.0000(0.0000) Steps 616(596.07) | Grad Norm 0.4460(1.0800) | Total Time 14.00(14.00)\n",
      "Iter 0160 | Time 14.8026(14.6022) | Bit/dim 6.7529(7.0074) | Xent 0.0000(0.0000) | Loss 6.7529(7.0074) | Error 0.0000(0.0000) Steps 610(600.81) | Grad Norm 0.5949(0.9246) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 79.1081, Epoch Time 897.8460(841.4414), Bit/dim 6.7052(best: 7.0091), Xent 0.0000, Loss 6.7052, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0170 | Time 14.8935(14.6487) | Bit/dim 6.6298(6.9255) | Xent 0.0000(0.0000) | Loss 6.6298(6.9255) | Error 0.0000(0.0000) Steps 610(603.37) | Grad Norm 2.0788(0.9291) | Total Time 14.00(14.00)\n",
      "Iter 0180 | Time 14.5383(14.6410) | Bit/dim 6.4379(6.8201) | Xent 0.0000(0.0000) | Loss 6.4379(6.8201) | Error 0.0000(0.0000) Steps 610(605.11) | Grad Norm 2.4216(1.0427) | Total Time 14.00(14.00)\n",
      "Iter 0190 | Time 14.8670(14.6877) | Bit/dim 6.1417(6.6775) | Xent 0.0000(0.0000) | Loss 6.1417(6.6775) | Error 0.0000(0.0000) Steps 616(607.97) | Grad Norm 13.0143(4.6116) | Total Time 14.00(14.00)\n",
      "Iter 0200 | Time 15.1733(14.7722) | Bit/dim 5.9648(6.5092) | Xent 0.0000(0.0000) | Loss 5.9648(6.5092) | Error 0.0000(0.0000) Steps 610(609.87) | Grad Norm 20.3198(8.2206) | Total Time 14.00(14.00)\n",
      "Iter 0210 | Time 15.1024(14.8263) | Bit/dim 5.8048(6.3380) | Xent 0.0000(0.0000) | Loss 5.8048(6.3380) | Error 0.0000(0.0000) Steps 616(610.67) | Grad Norm 5.7356(8.6737) | Total Time 14.00(14.00)\n",
      "Iter 0220 | Time 14.4381(14.8198) | Bit/dim 5.6963(6.1814) | Xent 0.0000(0.0000) | Loss 5.6963(6.1814) | Error 0.0000(0.0000) Steps 604(610.89) | Grad Norm 4.0584(7.9683) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 79.0925, Epoch Time 912.6746(843.5784), Bit/dim 5.6938(best: 6.7052), Xent 0.0000, Loss 5.6938, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0230 | Time 14.3178(14.6871) | Bit/dim 5.6992(6.0455) | Xent 0.0000(0.0000) | Loss 5.6992(6.0455) | Error 0.0000(0.0000) Steps 604(609.38) | Grad Norm 1.9229(6.5463) | Total Time 14.00(14.00)\n",
      "Iter 0240 | Time 14.4437(14.6547) | Bit/dim 5.5793(5.9328) | Xent 0.0000(0.0000) | Loss 5.5793(5.9328) | Error 0.0000(0.0000) Steps 604(607.96) | Grad Norm 2.4944(5.2998) | Total Time 14.00(14.00)\n",
      "Iter 0250 | Time 15.0235(14.6048) | Bit/dim 5.5227(5.8336) | Xent 0.0000(0.0000) | Loss 5.5227(5.8336) | Error 0.0000(0.0000) Steps 616(608.90) | Grad Norm 4.7556(4.9604) | Total Time 14.00(14.00)\n",
      "Iter 0260 | Time 15.1800(14.7225) | Bit/dim 5.4582(5.7426) | Xent 0.0000(0.0000) | Loss 5.4582(5.7426) | Error 0.0000(0.0000) Steps 628(612.56) | Grad Norm 1.0731(4.1965) | Total Time 14.00(14.00)\n",
      "Iter 0270 | Time 14.6749(14.8122) | Bit/dim 5.3456(5.6575) | Xent 0.0000(0.0000) | Loss 5.3456(5.6575) | Error 0.0000(0.0000) Steps 628(617.57) | Grad Norm 7.3140(4.5131) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 83.7639, Epoch Time 912.6244(845.6498), Bit/dim 5.3186(best: 5.6938), Xent 0.0000, Loss 5.3186, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0280 | Time 15.5323(14.9855) | Bit/dim 5.2815(5.5736) | Xent 0.0000(0.0000) | Loss 5.2815(5.5736) | Error 0.0000(0.0000) Steps 652(624.38) | Grad Norm 4.9849(4.6571) | Total Time 14.00(14.00)\n",
      "Iter 0290 | Time 15.5736(15.1581) | Bit/dim 5.2415(5.4909) | Xent 0.0000(0.0000) | Loss 5.2415(5.4909) | Error 0.0000(0.0000) Steps 664(632.66) | Grad Norm 2.4006(4.5618) | Total Time 14.00(14.00)\n",
      "Iter 0300 | Time 16.3156(15.3611) | Bit/dim 5.2373(5.4203) | Xent 0.0000(0.0000) | Loss 5.2373(5.4203) | Error 0.0000(0.0000) Steps 664(641.08) | Grad Norm 8.7422(5.3027) | Total Time 14.00(14.00)\n",
      "Iter 0310 | Time 16.5030(15.5624) | Bit/dim 5.1575(5.3524) | Xent 0.0000(0.0000) | Loss 5.1575(5.3524) | Error 0.0000(0.0000) Steps 676(648.75) | Grad Norm 10.6645(6.1058) | Total Time 14.00(14.00)\n",
      "Iter 0320 | Time 16.9418(15.8372) | Bit/dim 5.0811(5.2963) | Xent 0.0000(0.0000) | Loss 5.0811(5.2963) | Error 0.0000(0.0000) Steps 682(656.90) | Grad Norm 4.3816(5.8875) | Total Time 14.00(14.00)\n",
      "Iter 0330 | Time 16.6757(15.9490) | Bit/dim 5.0503(5.2466) | Xent 0.0000(0.0000) | Loss 5.0503(5.2466) | Error 0.0000(0.0000) Steps 688(662.99) | Grad Norm 8.6041(7.0672) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 88.9508, Epoch Time 990.1928(849.9861), Bit/dim 5.0648(best: 5.3186), Xent 0.0000, Loss 5.0648, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0340 | Time 16.7592(16.0616) | Bit/dim 5.0486(5.1961) | Xent 0.0000(0.0000) | Loss 5.0486(5.1961) | Error 0.0000(0.0000) Steps 688(668.77) | Grad Norm 10.9377(7.1109) | Total Time 14.00(14.00)\n",
      "Iter 0350 | Time 16.6566(16.2422) | Bit/dim 5.1061(5.1704) | Xent 0.0000(0.0000) | Loss 5.1061(5.1704) | Error 0.0000(0.0000) Steps 688(674.23) | Grad Norm 11.7513(9.4065) | Total Time 14.00(14.00)\n",
      "Iter 0360 | Time 16.4996(16.3960) | Bit/dim 4.9674(5.1407) | Xent 0.0000(0.0000) | Loss 4.9674(5.1407) | Error 0.0000(0.0000) Steps 688(679.42) | Grad Norm 3.7681(9.6334) | Total Time 14.00(14.00)\n",
      "Iter 0370 | Time 17.0989(16.5509) | Bit/dim 4.9503(5.0966) | Xent 0.0000(0.0000) | Loss 4.9503(5.0966) | Error 0.0000(0.0000) Steps 700(683.85) | Grad Norm 7.1161(8.9212) | Total Time 14.00(14.00)\n",
      "Iter 0380 | Time 17.2491(16.7307) | Bit/dim 4.9031(5.0511) | Xent 0.0000(0.0000) | Loss 4.9031(5.0511) | Error 0.0000(0.0000) Steps 706(689.41) | Grad Norm 3.7116(7.9070) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 91.1863, Epoch Time 1035.8055(855.5607), Bit/dim 4.9079(best: 5.0648), Xent 0.0000, Loss 4.9079, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0390 | Time 17.2228(16.8718) | Bit/dim 4.8901(5.0133) | Xent 0.0000(0.0000) | Loss 4.8901(5.0133) | Error 0.0000(0.0000) Steps 706(693.95) | Grad Norm 10.1205(7.6558) | Total Time 14.00(14.00)\n",
      "Iter 0400 | Time 17.8533(17.0314) | Bit/dim 4.8592(4.9806) | Xent 0.0000(0.0000) | Loss 4.8592(4.9806) | Error 0.0000(0.0000) Steps 724(698.93) | Grad Norm 2.9549(7.9543) | Total Time 14.00(14.00)\n",
      "Iter 0410 | Time 17.9008(17.2367) | Bit/dim 4.8450(4.9480) | Xent 0.0000(0.0000) | Loss 4.8450(4.9480) | Error 0.0000(0.0000) Steps 718(705.43) | Grad Norm 8.4298(7.7914) | Total Time 14.00(14.00)\n",
      "Iter 0420 | Time 17.8268(17.4462) | Bit/dim 4.7681(4.9121) | Xent 0.0000(0.0000) | Loss 4.7681(4.9121) | Error 0.0000(0.0000) Steps 736(712.64) | Grad Norm 3.5000(7.4097) | Total Time 14.00(14.00)\n",
      "Iter 0430 | Time 18.7871(17.6647) | Bit/dim 4.7368(4.8767) | Xent 0.0000(0.0000) | Loss 4.7368(4.8767) | Error 0.0000(0.0000) Steps 748(720.05) | Grad Norm 4.2651(7.1270) | Total Time 14.00(14.00)\n",
      "Iter 0440 | Time 17.7264(17.7435) | Bit/dim 5.6071(4.9741) | Xent 0.0000(0.0000) | Loss 5.6071(4.9741) | Error 0.0000(0.0000) Steps 754(726.80) | Grad Norm 14.2693(11.4994) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 97.0933, Epoch Time 1097.5908(862.8216), Bit/dim 5.3212(best: 4.9079), Xent 0.0000, Loss 5.3212, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0450 | Time 16.4895(17.6348) | Bit/dim 5.0450(5.0198) | Xent 0.0000(0.0000) | Loss 5.0450(5.0198) | Error 0.0000(0.0000) Steps 694(724.09) | Grad Norm 8.0018(11.5440) | Total Time 14.00(14.00)\n",
      "Iter 0460 | Time 18.2221(17.6179) | Bit/dim 4.8478(4.9938) | Xent 0.0000(0.0000) | Loss 4.8478(4.9938) | Error 0.0000(0.0000) Steps 700(719.78) | Grad Norm 4.1865(9.7849) | Total Time 14.00(14.00)\n",
      "Iter 0470 | Time 17.6728(17.6189) | Bit/dim 4.7719(4.9488) | Xent 0.0000(0.0000) | Loss 4.7719(4.9488) | Error 0.0000(0.0000) Steps 718(717.52) | Grad Norm 1.9251(7.8080) | Total Time 14.00(14.00)\n",
      "Iter 0480 | Time 17.5906(17.5861) | Bit/dim 4.7513(4.9035) | Xent 0.0000(0.0000) | Loss 4.7513(4.9035) | Error 0.0000(0.0000) Steps 718(716.45) | Grad Norm 4.0256(6.4035) | Total Time 14.00(14.00)\n",
      "Iter 0490 | Time 18.1673(17.6533) | Bit/dim 4.7246(4.8626) | Xent 0.0000(0.0000) | Loss 4.7246(4.8626) | Error 0.0000(0.0000) Steps 730(715.92) | Grad Norm 8.0642(5.8835) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 92.1102, Epoch Time 1080.3847(869.3485), Bit/dim 4.7237(best: 4.9079), Xent 0.0000, Loss 4.7237, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0500 | Time 18.7378(17.8420) | Bit/dim 4.6931(4.8250) | Xent 0.0000(0.0000) | Loss 4.6931(4.8250) | Error 0.0000(0.0000) Steps 736(717.74) | Grad Norm 5.6220(5.7632) | Total Time 14.00(14.00)\n",
      "Iter 0510 | Time 18.5185(18.0117) | Bit/dim 4.7000(4.7943) | Xent 0.0000(0.0000) | Loss 4.7000(4.7943) | Error 0.0000(0.0000) Steps 730(720.26) | Grad Norm 1.2092(5.3738) | Total Time 14.00(14.00)\n",
      "Iter 0520 | Time 18.1524(18.1826) | Bit/dim 4.7154(4.7649) | Xent 0.0000(0.0000) | Loss 4.7154(4.7649) | Error 0.0000(0.0000) Steps 748(726.14) | Grad Norm 5.4797(5.1739) | Total Time 14.00(14.00)\n",
      "Iter 0530 | Time 18.1525(18.2708) | Bit/dim 4.6422(4.7374) | Xent 0.0000(0.0000) | Loss 4.6422(4.7374) | Error 0.0000(0.0000) Steps 748(731.53) | Grad Norm 11.5583(5.6399) | Total Time 14.00(14.00)\n",
      "Iter 0540 | Time 18.9776(18.4362) | Bit/dim 4.6712(4.7163) | Xent 0.0000(0.0000) | Loss 4.6712(4.7163) | Error 0.0000(0.0000) Steps 754(736.21) | Grad Norm 7.2559(5.7496) | Total Time 14.00(14.00)\n",
      "Iter 0550 | Time 18.5699(18.5682) | Bit/dim 4.6455(4.6993) | Xent 0.0000(0.0000) | Loss 4.6455(4.6993) | Error 0.0000(0.0000) Steps 736(740.10) | Grad Norm 10.3486(6.4570) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 97.9320, Epoch Time 1142.5925(877.5458), Bit/dim 4.6494(best: 4.7237), Xent 0.0000, Loss 4.6494, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0560 | Time 19.0984(18.6243) | Bit/dim 4.6582(4.6922) | Xent 0.0000(0.0000) | Loss 4.6582(4.6922) | Error 0.0000(0.0000) Steps 766(742.62) | Grad Norm 13.1087(8.0389) | Total Time 14.00(14.00)\n",
      "Iter 0570 | Time 19.0209(18.5913) | Bit/dim 4.6739(4.7096) | Xent 0.0000(0.0000) | Loss 4.6739(4.7096) | Error 0.0000(0.0000) Steps 748(742.85) | Grad Norm 6.9928(10.0312) | Total Time 14.00(14.00)\n",
      "Iter 0580 | Time 18.5538(18.6206) | Bit/dim 4.6047(4.6945) | Xent 0.0000(0.0000) | Loss 4.6047(4.6945) | Error 0.0000(0.0000) Steps 724(742.44) | Grad Norm 4.9558(9.1201) | Total Time 14.00(14.00)\n",
      "Iter 0590 | Time 18.4867(18.4816) | Bit/dim 4.5826(4.6745) | Xent 0.0000(0.0000) | Loss 4.5826(4.6745) | Error 0.0000(0.0000) Steps 718(737.12) | Grad Norm 6.5916(7.8981) | Total Time 14.00(14.00)\n",
      "Iter 0600 | Time 18.7997(18.5082) | Bit/dim 4.5765(4.6512) | Xent 0.0000(0.0000) | Loss 4.5765(4.6512) | Error 0.0000(0.0000) Steps 718(734.13) | Grad Norm 4.8488(6.8292) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 94.0719, Epoch Time 1131.7121(885.1708), Bit/dim 4.5660(best: 4.6494), Xent 0.0000, Loss 4.5660, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0610 | Time 19.0223(18.5024) | Bit/dim 4.5917(4.6300) | Xent 0.0000(0.0000) | Loss 4.5917(4.6300) | Error 0.0000(0.0000) Steps 724(733.74) | Grad Norm 3.2641(5.7953) | Total Time 14.00(14.00)\n",
      "Iter 0620 | Time 18.6328(18.4558) | Bit/dim 4.5510(4.6134) | Xent 0.0000(0.0000) | Loss 4.5510(4.6134) | Error 0.0000(0.0000) Steps 742(733.84) | Grad Norm 7.0544(6.3032) | Total Time 14.00(14.00)\n",
      "Iter 0630 | Time 18.4581(18.4087) | Bit/dim 4.6530(4.6033) | Xent 0.0000(0.0000) | Loss 4.6530(4.6033) | Error 0.0000(0.0000) Steps 736(733.47) | Grad Norm 21.7099(7.5259) | Total Time 14.00(14.00)\n",
      "Iter 0640 | Time 17.5430(18.3904) | Bit/dim 4.5963(4.6174) | Xent 0.0000(0.0000) | Loss 4.5963(4.6174) | Error 0.0000(0.0000) Steps 724(733.45) | Grad Norm 9.3681(8.7351) | Total Time 14.00(14.00)\n",
      "Iter 0650 | Time 18.1941(18.3892) | Bit/dim 4.5401(4.6039) | Xent 0.0000(0.0000) | Loss 4.5401(4.6039) | Error 0.0000(0.0000) Steps 730(732.97) | Grad Norm 2.7110(7.7684) | Total Time 14.00(14.00)\n",
      "Iter 0660 | Time 18.5083(18.3214) | Bit/dim 4.5400(4.5859) | Xent 0.0000(0.0000) | Loss 4.5400(4.5859) | Error 0.0000(0.0000) Steps 718(729.26) | Grad Norm 3.9697(6.6324) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 92.4480, Epoch Time 1115.7578(892.0884), Bit/dim 4.5104(best: 4.5660), Xent 0.0000, Loss 4.5104, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0670 | Time 18.1289(18.2513) | Bit/dim 4.5143(4.5680) | Xent 0.0000(0.0000) | Loss 4.5143(4.5680) | Error 0.0000(0.0000) Steps 712(725.28) | Grad Norm 6.1423(6.0873) | Total Time 14.00(14.00)\n",
      "Iter 0680 | Time 18.0535(18.1968) | Bit/dim 4.4831(4.5487) | Xent 0.0000(0.0000) | Loss 4.4831(4.5487) | Error 0.0000(0.0000) Steps 724(723.08) | Grad Norm 4.6534(6.1453) | Total Time 14.00(14.00)\n",
      "Iter 0690 | Time 17.9893(18.2010) | Bit/dim 4.4848(4.5330) | Xent 0.0000(0.0000) | Loss 4.4848(4.5330) | Error 0.0000(0.0000) Steps 712(721.73) | Grad Norm 7.1052(6.1043) | Total Time 14.00(14.00)\n",
      "Iter 0700 | Time 18.0069(18.1696) | Bit/dim 4.5174(4.5170) | Xent 0.0000(0.0000) | Loss 4.5174(4.5170) | Error 0.0000(0.0000) Steps 712(719.33) | Grad Norm 14.2866(6.4984) | Total Time 14.00(14.00)\n",
      "Iter 0710 | Time 18.7809(18.1696) | Bit/dim 4.4630(4.5060) | Xent 0.0000(0.0000) | Loss 4.4630(4.5060) | Error 0.0000(0.0000) Steps 718(717.12) | Grad Norm 8.1617(6.8834) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 92.2948, Epoch Time 1107.4530(898.5493), Bit/dim 4.4476(best: 4.5104), Xent 0.0000, Loss 4.4476, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0720 | Time 17.7222(18.1282) | Bit/dim 4.4281(4.4961) | Xent 0.0000(0.0000) | Loss 4.4281(4.4961) | Error 0.0000(0.0000) Steps 712(716.10) | Grad Norm 1.6973(7.1344) | Total Time 14.00(14.00)\n",
      "Iter 0730 | Time 18.1106(18.0441) | Bit/dim 4.5417(4.5199) | Xent 0.0000(0.0000) | Loss 4.5417(4.5199) | Error 0.0000(0.0000) Steps 724(715.53) | Grad Norm 10.5617(8.8760) | Total Time 14.00(14.00)\n",
      "Iter 0740 | Time 17.9047(17.9965) | Bit/dim 4.4664(4.5102) | Xent 0.0000(0.0000) | Loss 4.4664(4.5102) | Error 0.0000(0.0000) Steps 706(714.68) | Grad Norm 3.1088(7.6861) | Total Time 14.00(14.00)\n",
      "Iter 0750 | Time 17.6243(17.8899) | Bit/dim 4.4217(4.4904) | Xent 0.0000(0.0000) | Loss 4.4217(4.4904) | Error 0.0000(0.0000) Steps 694(710.74) | Grad Norm 1.5847(6.3566) | Total Time 14.00(14.00)\n",
      "Iter 0760 | Time 18.7165(17.9097) | Bit/dim 4.5274(4.4716) | Xent 0.0000(0.0000) | Loss 4.5274(4.4716) | Error 0.0000(0.0000) Steps 712(708.08) | Grad Norm 20.7793(6.5629) | Total Time 14.00(14.00)\n",
      "Iter 0770 | Time 17.0606(17.9061) | Bit/dim 4.4174(4.4736) | Xent 0.0000(0.0000) | Loss 4.4174(4.4736) | Error 0.0000(0.0000) Steps 700(708.32) | Grad Norm 4.7051(7.7193) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 93.3101, Epoch Time 1090.6079(904.3111), Bit/dim 4.4710(best: 4.4476), Xent 0.0000, Loss 4.4710, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0780 | Time 18.7673(17.9708) | Bit/dim 4.4077(4.4608) | Xent 0.0000(0.0000) | Loss 4.4077(4.4608) | Error 0.0000(0.0000) Steps 706(707.30) | Grad Norm 5.6462(7.5381) | Total Time 14.00(14.00)\n",
      "Iter 0790 | Time 18.7162(18.0510) | Bit/dim 4.3874(4.4396) | Xent 0.0000(0.0000) | Loss 4.3874(4.4396) | Error 0.0000(0.0000) Steps 724(707.93) | Grad Norm 1.9497(6.7834) | Total Time 14.00(14.00)\n",
      "Iter 0800 | Time 18.6886(18.1720) | Bit/dim 4.3495(4.4176) | Xent 0.0000(0.0000) | Loss 4.3495(4.4176) | Error 0.0000(0.0000) Steps 724(711.12) | Grad Norm 6.5766(6.1393) | Total Time 14.00(14.00)\n",
      "Iter 0810 | Time 18.8626(18.3716) | Bit/dim 4.3858(4.3983) | Xent 0.0000(0.0000) | Loss 4.3858(4.3983) | Error 0.0000(0.0000) Steps 724(715.63) | Grad Norm 14.5711(6.4408) | Total Time 14.00(14.00)\n",
      "Iter 0820 | Time 18.3492(18.3476) | Bit/dim 4.4028(4.3920) | Xent 0.0000(0.0000) | Loss 4.4028(4.3920) | Error 0.0000(0.0000) Steps 718(717.12) | Grad Norm 13.2469(7.5547) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 92.3055, Epoch Time 1124.7809(910.9252), Bit/dim 4.3555(best: 4.4476), Xent 0.0000, Loss 4.3555, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0830 | Time 18.7538(18.3930) | Bit/dim 4.3479(4.3811) | Xent 0.0000(0.0000) | Loss 4.3479(4.3811) | Error 0.0000(0.0000) Steps 694(717.41) | Grad Norm 2.7645(6.9461) | Total Time 14.00(14.00)\n",
      "Iter 0840 | Time 18.1008(18.3632) | Bit/dim 4.3061(4.3613) | Xent 0.0000(0.0000) | Loss 4.3061(4.3613) | Error 0.0000(0.0000) Steps 724(715.90) | Grad Norm 4.8772(6.1142) | Total Time 14.00(14.00)\n",
      "Iter 0850 | Time 18.3137(18.3469) | Bit/dim 4.2927(4.3393) | Xent 0.0000(0.0000) | Loss 4.2927(4.3393) | Error 0.0000(0.0000) Steps 718(716.10) | Grad Norm 9.7516(5.4409) | Total Time 14.00(14.00)\n",
      "Iter 0860 | Time 18.6483(18.2432) | Bit/dim 4.4688(4.3740) | Xent 0.0000(0.0000) | Loss 4.4688(4.3740) | Error 0.0000(0.0000) Steps 730(715.24) | Grad Norm 9.9242(8.0036) | Total Time 14.00(14.00)\n",
      "Iter 0870 | Time 17.1805(18.1709) | Bit/dim 4.3151(4.3712) | Xent 0.0000(0.0000) | Loss 4.3151(4.3712) | Error 0.0000(0.0000) Steps 682(716.31) | Grad Norm 4.8986(7.0261) | Total Time 14.00(14.00)\n",
      "Iter 0880 | Time 18.5478(18.0360) | Bit/dim 4.2876(4.3520) | Xent 0.0000(0.0000) | Loss 4.2876(4.3520) | Error 0.0000(0.0000) Steps 700(710.90) | Grad Norm 1.5677(5.8829) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 90.5113, Epoch Time 1101.6384(916.6466), Bit/dim 4.2704(best: 4.3555), Xent 0.0000, Loss 4.2704, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0890 | Time 17.9864(18.1042) | Bit/dim 4.2335(4.3264) | Xent 0.0000(0.0000) | Loss 4.2335(4.3264) | Error 0.0000(0.0000) Steps 742(713.73) | Grad Norm 2.7918(4.8178) | Total Time 14.00(14.00)\n",
      "Iter 0900 | Time 18.8013(18.2236) | Bit/dim 4.2436(4.3066) | Xent 0.0000(0.0000) | Loss 4.2436(4.3066) | Error 0.0000(0.0000) Steps 718(716.14) | Grad Norm 4.5560(5.5003) | Total Time 14.00(14.00)\n",
      "Iter 0910 | Time 17.9415(18.3546) | Bit/dim 4.2168(4.2864) | Xent 0.0000(0.0000) | Loss 4.2168(4.2864) | Error 0.0000(0.0000) Steps 730(721.50) | Grad Norm 3.0409(4.8752) | Total Time 14.00(14.00)\n",
      "Iter 0920 | Time 18.9259(18.5026) | Bit/dim 4.2363(4.2779) | Xent 0.0000(0.0000) | Loss 4.2363(4.2779) | Error 0.0000(0.0000) Steps 736(724.50) | Grad Norm 3.3900(5.6364) | Total Time 14.00(14.00)\n",
      "Iter 0930 | Time 18.4066(18.6536) | Bit/dim 4.2572(4.2759) | Xent 0.0000(0.0000) | Loss 4.2572(4.2759) | Error 0.0000(0.0000) Steps 754(734.73) | Grad Norm 8.7973(6.8025) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 92.0906, Epoch Time 1141.9969(923.4071), Bit/dim 4.2151(best: 4.2704), Xent 0.0000, Loss 4.2151, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0940 | Time 18.8750(18.7362) | Bit/dim 4.1955(4.2635) | Xent 0.0000(0.0000) | Loss 4.1955(4.2635) | Error 0.0000(0.0000) Steps 742(740.72) | Grad Norm 5.0641(6.4855) | Total Time 14.00(14.00)\n",
      "Iter 0950 | Time 19.3056(18.7748) | Bit/dim 4.1941(4.2457) | Xent 0.0000(0.0000) | Loss 4.1941(4.2457) | Error 0.0000(0.0000) Steps 736(740.07) | Grad Norm 4.6396(5.8552) | Total Time 14.00(14.00)\n",
      "Iter 0960 | Time 18.5485(18.7754) | Bit/dim 4.1686(4.2267) | Xent 0.0000(0.0000) | Loss 4.1686(4.2267) | Error 0.0000(0.0000) Steps 754(744.35) | Grad Norm 3.7086(5.3214) | Total Time 14.00(14.00)\n",
      "Iter 0970 | Time 18.8803(18.7460) | Bit/dim 4.1704(4.2129) | Xent 0.0000(0.0000) | Loss 4.1704(4.2129) | Error 0.0000(0.0000) Steps 754(746.87) | Grad Norm 5.7252(5.5647) | Total Time 14.00(14.00)\n",
      "Iter 0980 | Time 18.5924(18.7806) | Bit/dim 4.0798(4.1948) | Xent 0.0000(0.0000) | Loss 4.0798(4.1948) | Error 0.0000(0.0000) Steps 754(748.75) | Grad Norm 4.2575(5.5748) | Total Time 14.00(14.00)\n",
      "Iter 0990 | Time 18.9752(18.7761) | Bit/dim 4.0970(4.1797) | Xent 0.0000(0.0000) | Loss 4.0970(4.1797) | Error 0.0000(0.0000) Steps 754(749.78) | Grad Norm 3.6468(5.6892) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 93.8191, Epoch Time 1144.8102(930.0492), Bit/dim 4.1283(best: 4.2151), Xent 0.0000, Loss 4.1283, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1000 | Time 18.5733(18.7530) | Bit/dim 4.1117(4.1657) | Xent 0.0000(0.0000) | Loss 4.1117(4.1657) | Error 0.0000(0.0000) Steps 760(751.44) | Grad Norm 3.9683(5.4887) | Total Time 14.00(14.00)\n",
      "Iter 1010 | Time 19.0380(18.7570) | Bit/dim 4.1112(4.1531) | Xent 0.0000(0.0000) | Loss 4.1112(4.1531) | Error 0.0000(0.0000) Steps 760(753.39) | Grad Norm 4.5862(5.4428) | Total Time 14.00(14.00)\n",
      "Iter 1020 | Time 18.4244(18.7521) | Bit/dim 4.1369(4.1409) | Xent 0.0000(0.0000) | Loss 4.1369(4.1409) | Error 0.0000(0.0000) Steps 754(754.78) | Grad Norm 10.8019(5.7439) | Total Time 14.00(14.00)\n",
      "Iter 1030 | Time 19.0975(18.7779) | Bit/dim 4.1138(4.1338) | Xent 0.0000(0.0000) | Loss 4.1138(4.1338) | Error 0.0000(0.0000) Steps 766(757.75) | Grad Norm 2.6690(5.9384) | Total Time 14.00(14.00)\n",
      "Iter 1040 | Time 18.3303(18.7739) | Bit/dim 4.0836(4.1336) | Xent 0.0000(0.0000) | Loss 4.0836(4.1336) | Error 0.0000(0.0000) Steps 760(758.02) | Grad Norm 3.2718(6.5568) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 94.4842, Epoch Time 1144.8422(936.4930), Bit/dim 4.0893(best: 4.1283), Xent 0.0000, Loss 4.0893, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1050 | Time 18.9759(18.7659) | Bit/dim 4.0842(4.1214) | Xent 0.0000(0.0000) | Loss 4.0842(4.1214) | Error 0.0000(0.0000) Steps 766(760.04) | Grad Norm 4.8860(6.0566) | Total Time 14.00(14.00)\n",
      "Iter 1060 | Time 19.1182(18.7095) | Bit/dim 4.0466(4.1098) | Xent 0.0000(0.0000) | Loss 4.0466(4.1098) | Error 0.0000(0.0000) Steps 754(759.20) | Grad Norm 2.2490(5.1824) | Total Time 14.00(14.00)\n",
      "Iter 1070 | Time 18.6870(18.6583) | Bit/dim 4.0309(4.0936) | Xent 0.0000(0.0000) | Loss 4.0309(4.0936) | Error 0.0000(0.0000) Steps 772(759.21) | Grad Norm 1.6356(4.5070) | Total Time 14.00(14.00)\n",
      "Iter 1080 | Time 19.3469(18.6833) | Bit/dim 4.0345(4.0777) | Xent 0.0000(0.0000) | Loss 4.0345(4.0777) | Error 0.0000(0.0000) Steps 778(762.82) | Grad Norm 6.1797(4.7251) | Total Time 14.00(14.00)\n",
      "Iter 1090 | Time 19.4273(18.8303) | Bit/dim 4.0500(4.0701) | Xent 0.0000(0.0000) | Loss 4.0500(4.0701) | Error 0.0000(0.0000) Steps 784(766.84) | Grad Norm 7.5500(5.2826) | Total Time 14.00(14.00)\n",
      "Iter 1100 | Time 18.2827(18.8475) | Bit/dim 4.0349(4.0673) | Xent 0.0000(0.0000) | Loss 4.0349(4.0673) | Error 0.0000(0.0000) Steps 766(767.47) | Grad Norm 10.6081(6.4670) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 92.3852, Epoch Time 1142.9805(942.6876), Bit/dim 4.0567(best: 4.0893), Xent 0.0000, Loss 4.0567, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1110 | Time 19.1646(18.8353) | Bit/dim 4.0206(4.0575) | Xent 0.0000(0.0000) | Loss 4.0206(4.0575) | Error 0.0000(0.0000) Steps 772(768.71) | Grad Norm 4.5145(6.3409) | Total Time 14.00(14.00)\n",
      "Iter 1120 | Time 18.8182(18.8359) | Bit/dim 4.0074(4.0426) | Xent 0.0000(0.0000) | Loss 4.0074(4.0426) | Error 0.0000(0.0000) Steps 796(771.44) | Grad Norm 1.0298(5.4103) | Total Time 14.00(14.00)\n",
      "Iter 1130 | Time 18.7865(18.8591) | Bit/dim 4.0092(4.0295) | Xent 0.0000(0.0000) | Loss 4.0092(4.0295) | Error 0.0000(0.0000) Steps 790(776.61) | Grad Norm 2.7178(4.8179) | Total Time 14.00(14.00)\n",
      "Iter 1140 | Time 19.0062(18.9131) | Bit/dim 3.9696(4.0173) | Xent 0.0000(0.0000) | Loss 3.9696(4.0173) | Error 0.0000(0.0000) Steps 784(778.88) | Grad Norm 0.8622(4.2073) | Total Time 14.00(14.00)\n",
      "Iter 1150 | Time 19.0806(18.9662) | Bit/dim 4.0121(4.0094) | Xent 0.0000(0.0000) | Loss 4.0121(4.0094) | Error 0.0000(0.0000) Steps 790(781.22) | Grad Norm 4.9346(4.2737) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 96.5853, Epoch Time 1157.2874(949.1256), Bit/dim 3.9675(best: 4.0567), Xent 0.0000, Loss 3.9675, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1160 | Time 19.0868(19.0015) | Bit/dim 3.9647(4.0003) | Xent 0.0000(0.0000) | Loss 3.9647(4.0003) | Error 0.0000(0.0000) Steps 784(782.89) | Grad Norm 3.4661(4.0137) | Total Time 14.00(14.00)\n",
      "Iter 1170 | Time 18.8284(19.0079) | Bit/dim 3.9664(3.9899) | Xent 0.0000(0.0000) | Loss 3.9664(3.9899) | Error 0.0000(0.0000) Steps 790(784.30) | Grad Norm 2.0661(4.1117) | Total Time 14.00(14.00)\n",
      "Iter 1180 | Time 19.0885(18.9903) | Bit/dim 3.9095(3.9798) | Xent 0.0000(0.0000) | Loss 3.9095(3.9798) | Error 0.0000(0.0000) Steps 790(785.97) | Grad Norm 1.4127(4.2141) | Total Time 14.00(14.00)\n",
      "Iter 1190 | Time 18.9687(18.9871) | Bit/dim 3.9297(3.9715) | Xent 0.0000(0.0000) | Loss 3.9297(3.9715) | Error 0.0000(0.0000) Steps 790(786.71) | Grad Norm 1.8798(3.9191) | Total Time 14.00(14.00)\n",
      "Iter 1200 | Time 19.1381(19.0166) | Bit/dim 3.9393(3.9626) | Xent 0.0000(0.0000) | Loss 3.9393(3.9626) | Error 0.0000(0.0000) Steps 796(787.62) | Grad Norm 3.9129(3.7828) | Total Time 14.00(14.00)\n",
      "Iter 1210 | Time 19.0196(19.0443) | Bit/dim 3.9326(3.9540) | Xent 0.0000(0.0000) | Loss 3.9326(3.9540) | Error 0.0000(0.0000) Steps 796(788.73) | Grad Norm 3.9501(3.8042) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 98.0092, Epoch Time 1162.5242(955.5275), Bit/dim 3.9252(best: 3.9675), Xent 0.0000, Loss 3.9252, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1220 | Time 19.4910(19.0328) | Bit/dim 3.9366(3.9500) | Xent 0.0000(0.0000) | Loss 3.9366(3.9500) | Error 0.0000(0.0000) Steps 796(789.54) | Grad Norm 7.3737(3.8643) | Total Time 14.00(14.00)\n",
      "Iter 1230 | Time 19.6565(19.0332) | Bit/dim 3.8960(3.9447) | Xent 0.0000(0.0000) | Loss 3.8960(3.9447) | Error 0.0000(0.0000) Steps 784(789.97) | Grad Norm 5.8293(4.3308) | Total Time 14.00(14.00)\n",
      "Iter 1240 | Time 18.7480(19.0414) | Bit/dim 3.9184(3.9383) | Xent 0.0000(0.0000) | Loss 3.9184(3.9383) | Error 0.0000(0.0000) Steps 790(791.03) | Grad Norm 5.9062(4.7064) | Total Time 14.00(14.00)\n",
      "Iter 1250 | Time 18.7747(19.0924) | Bit/dim 3.8961(3.9284) | Xent 0.0000(0.0000) | Loss 3.8961(3.9284) | Error 0.0000(0.0000) Steps 790(792.79) | Grad Norm 1.6584(4.4800) | Total Time 14.00(14.00)\n",
      "Iter 1260 | Time 18.7946(19.1239) | Bit/dim 3.8906(3.9226) | Xent 0.0000(0.0000) | Loss 3.8906(3.9226) | Error 0.0000(0.0000) Steps 802(794.13) | Grad Norm 3.6656(4.8219) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 96.5565, Epoch Time 1165.0730(961.8139), Bit/dim 3.9098(best: 3.9252), Xent 0.0000, Loss 3.9098, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1270 | Time 19.4701(19.1428) | Bit/dim 3.8851(3.9168) | Xent 0.0000(0.0000) | Loss 3.8851(3.9168) | Error 0.0000(0.0000) Steps 796(794.63) | Grad Norm 3.0349(4.6566) | Total Time 14.00(14.00)\n",
      "Iter 1280 | Time 18.8805(19.1249) | Bit/dim 3.8934(3.9105) | Xent 0.0000(0.0000) | Loss 3.8934(3.9105) | Error 0.0000(0.0000) Steps 790(794.20) | Grad Norm 2.8094(4.3693) | Total Time 14.00(14.00)\n",
      "Iter 1290 | Time 19.6014(19.1526) | Bit/dim 3.8565(3.9043) | Xent 0.0000(0.0000) | Loss 3.8565(3.9043) | Error 0.0000(0.0000) Steps 796(794.49) | Grad Norm 2.4998(4.1863) | Total Time 14.00(14.00)\n",
      "Iter 1300 | Time 20.3060(19.1924) | Bit/dim 3.8866(3.9011) | Xent 0.0000(0.0000) | Loss 3.8866(3.9011) | Error 0.0000(0.0000) Steps 814(796.55) | Grad Norm 6.7068(4.0621) | Total Time 14.00(14.00)\n",
      "Iter 1310 | Time 19.2196(19.1844) | Bit/dim 3.9072(3.8971) | Xent 0.0000(0.0000) | Loss 3.9072(3.8971) | Error 0.0000(0.0000) Steps 802(797.08) | Grad Norm 5.4770(4.6062) | Total Time 14.00(14.00)\n",
      "Iter 1320 | Time 19.2543(19.2140) | Bit/dim 3.8778(3.8920) | Xent 0.0000(0.0000) | Loss 3.8778(3.8920) | Error 0.0000(0.0000) Steps 802(798.55) | Grad Norm 5.2412(4.6371) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 96.2355, Epoch Time 1170.7794(968.0829), Bit/dim 3.8761(best: 3.9098), Xent 0.0000, Loss 3.8761, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1330 | Time 19.5404(19.2421) | Bit/dim 3.8934(3.8864) | Xent 0.0000(0.0000) | Loss 3.8934(3.8864) | Error 0.0000(0.0000) Steps 802(799.15) | Grad Norm 4.0716(4.3527) | Total Time 14.00(14.00)\n",
      "Iter 1340 | Time 19.3672(19.2297) | Bit/dim 3.8678(3.8797) | Xent 0.0000(0.0000) | Loss 3.8678(3.8797) | Error 0.0000(0.0000) Steps 802(798.99) | Grad Norm 4.7431(4.1716) | Total Time 14.00(14.00)\n",
      "Iter 1350 | Time 19.0693(19.2816) | Bit/dim 3.8771(3.8731) | Xent 0.0000(0.0000) | Loss 3.8771(3.8731) | Error 0.0000(0.0000) Steps 802(799.32) | Grad Norm 4.3941(3.8908) | Total Time 14.00(14.00)\n",
      "Iter 1360 | Time 19.1677(19.2276) | Bit/dim 3.8221(3.8676) | Xent 0.0000(0.0000) | Loss 3.8221(3.8676) | Error 0.0000(0.0000) Steps 802(799.56) | Grad Norm 4.1836(4.1943) | Total Time 14.00(14.00)\n",
      "Iter 1370 | Time 19.3710(19.2410) | Bit/dim 3.8812(3.8651) | Xent 0.0000(0.0000) | Loss 3.8812(3.8651) | Error 0.0000(0.0000) Steps 808(800.24) | Grad Norm 4.6968(4.4917) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 96.6514, Epoch Time 1174.7995(974.2844), Bit/dim 3.8412(best: 3.8761), Xent 0.0000, Loss 3.8412, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1380 | Time 19.3922(19.2560) | Bit/dim 3.8449(3.8612) | Xent 0.0000(0.0000) | Loss 3.8449(3.8612) | Error 0.0000(0.0000) Steps 802(800.27) | Grad Norm 3.7170(4.3305) | Total Time 14.00(14.00)\n",
      "Iter 1390 | Time 19.7286(19.2872) | Bit/dim 3.8447(3.8553) | Xent 0.0000(0.0000) | Loss 3.8447(3.8553) | Error 0.0000(0.0000) Steps 802(800.70) | Grad Norm 4.7836(3.9714) | Total Time 14.00(14.00)\n",
      "Iter 1400 | Time 19.6537(19.3620) | Bit/dim 3.7892(3.8507) | Xent 0.0000(0.0000) | Loss 3.7892(3.8507) | Error 0.0000(0.0000) Steps 802(800.55) | Grad Norm 2.3983(4.4621) | Total Time 14.00(14.00)\n",
      "Iter 1410 | Time 19.1728(19.3594) | Bit/dim 3.8252(3.8488) | Xent 0.0000(0.0000) | Loss 3.8252(3.8488) | Error 0.0000(0.0000) Steps 802(800.61) | Grad Norm 1.7180(4.5259) | Total Time 14.00(14.00)\n",
      "Iter 1420 | Time 19.3095(19.3331) | Bit/dim 3.8404(3.8426) | Xent 0.0000(0.0000) | Loss 3.8404(3.8426) | Error 0.0000(0.0000) Steps 802(800.66) | Grad Norm 1.9637(4.2331) | Total Time 14.00(14.00)\n",
      "Iter 1430 | Time 19.4471(19.3193) | Bit/dim 3.8100(3.8395) | Xent 0.0000(0.0000) | Loss 3.8100(3.8395) | Error 0.0000(0.0000) Steps 802(800.62) | Grad Norm 4.2903(3.8001) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 97.3545, Epoch Time 1179.3800(980.4372), Bit/dim 3.8246(best: 3.8412), Xent 0.0000, Loss 3.8246, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1440 | Time 19.2325(19.3093) | Bit/dim 3.8308(3.8366) | Xent 0.0000(0.0000) | Loss 3.8308(3.8366) | Error 0.0000(0.0000) Steps 802(801.02) | Grad Norm 6.4393(4.0805) | Total Time 14.00(14.00)\n",
      "Iter 1450 | Time 19.2794(19.2782) | Bit/dim 3.8150(3.8314) | Xent 0.0000(0.0000) | Loss 3.8150(3.8314) | Error 0.0000(0.0000) Steps 796(801.25) | Grad Norm 5.3295(4.2154) | Total Time 14.00(14.00)\n",
      "Iter 1460 | Time 19.2304(19.2423) | Bit/dim 3.8077(3.8297) | Xent 0.0000(0.0000) | Loss 3.8077(3.8297) | Error 0.0000(0.0000) Steps 796(800.93) | Grad Norm 5.3723(4.7208) | Total Time 14.00(14.00)\n",
      "Iter 1470 | Time 19.8525(19.2970) | Bit/dim 3.8315(3.8266) | Xent 0.0000(0.0000) | Loss 3.8315(3.8266) | Error 0.0000(0.0000) Steps 814(802.40) | Grad Norm 3.4935(4.4503) | Total Time 14.00(14.00)\n",
      "Iter 1480 | Time 19.7805(19.2987) | Bit/dim 3.8029(3.8208) | Xent 0.0000(0.0000) | Loss 3.8029(3.8208) | Error 0.0000(0.0000) Steps 802(803.23) | Grad Norm 2.9582(4.2199) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 96.2565, Epoch Time 1174.2674(986.2522), Bit/dim 3.8030(best: 3.8246), Xent 0.0000, Loss 3.8030, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1490 | Time 18.9466(19.3057) | Bit/dim 3.8265(3.8183) | Xent 0.0000(0.0000) | Loss 3.8265(3.8183) | Error 0.0000(0.0000) Steps 796(802.65) | Grad Norm 6.4072(4.2498) | Total Time 14.00(14.00)\n",
      "Iter 1500 | Time 19.8748(19.3342) | Bit/dim 3.8157(3.8112) | Xent 0.0000(0.0000) | Loss 3.8157(3.8112) | Error 0.0000(0.0000) Steps 796(802.32) | Grad Norm 6.7465(4.3255) | Total Time 14.00(14.00)\n",
      "Iter 1510 | Time 19.9554(19.3600) | Bit/dim 3.8220(3.8068) | Xent 0.0000(0.0000) | Loss 3.8220(3.8068) | Error 0.0000(0.0000) Steps 796(803.20) | Grad Norm 1.6110(4.4345) | Total Time 14.00(14.00)\n",
      "Iter 1520 | Time 19.5785(19.3590) | Bit/dim 3.7915(3.8037) | Xent 0.0000(0.0000) | Loss 3.7915(3.8037) | Error 0.0000(0.0000) Steps 808(804.51) | Grad Norm 3.0396(4.3238) | Total Time 14.00(14.00)\n",
      "Iter 1530 | Time 19.2527(19.3867) | Bit/dim 3.7909(3.8014) | Xent 0.0000(0.0000) | Loss 3.7909(3.8014) | Error 0.0000(0.0000) Steps 820(807.34) | Grad Norm 2.2283(3.9568) | Total Time 14.00(14.00)\n",
      "Iter 1540 | Time 19.4686(19.4019) | Bit/dim 3.7957(3.8019) | Xent 0.0000(0.0000) | Loss 3.7957(3.8019) | Error 0.0000(0.0000) Steps 814(808.80) | Grad Norm 5.3521(4.1699) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 96.7112, Epoch Time 1182.2296(992.1315), Bit/dim 3.7898(best: 3.8030), Xent 0.0000, Loss 3.7898, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1550 | Time 19.8560(19.5467) | Bit/dim 3.8143(3.7980) | Xent 0.0000(0.0000) | Loss 3.8143(3.7980) | Error 0.0000(0.0000) Steps 808(810.43) | Grad Norm 6.8801(4.3173) | Total Time 14.00(14.00)\n",
      "Iter 1560 | Time 19.7732(19.5598) | Bit/dim 3.7814(3.7984) | Xent 0.0000(0.0000) | Loss 3.7814(3.7984) | Error 0.0000(0.0000) Steps 814(810.60) | Grad Norm 4.3006(4.6816) | Total Time 14.00(14.00)\n",
      "Iter 1570 | Time 19.2531(19.5263) | Bit/dim 3.7680(3.7942) | Xent 0.0000(0.0000) | Loss 3.7680(3.7942) | Error 0.0000(0.0000) Steps 808(809.43) | Grad Norm 2.8639(4.5141) | Total Time 14.00(14.00)\n",
      "Iter 1580 | Time 19.4187(19.5106) | Bit/dim 3.7898(3.7903) | Xent 0.0000(0.0000) | Loss 3.7898(3.7903) | Error 0.0000(0.0000) Steps 802(808.70) | Grad Norm 3.5705(4.3152) | Total Time 14.00(14.00)\n",
      "Iter 1590 | Time 19.2822(19.4970) | Bit/dim 3.7871(3.7876) | Xent 0.0000(0.0000) | Loss 3.7871(3.7876) | Error 0.0000(0.0000) Steps 814(808.86) | Grad Norm 3.1349(4.1324) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 96.8030, Epoch Time 1191.4496(998.1110), Bit/dim 3.7704(best: 3.7898), Xent 0.0000, Loss 3.7704, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1600 | Time 19.6207(19.4649) | Bit/dim 3.7693(3.7824) | Xent 0.0000(0.0000) | Loss 3.7693(3.7824) | Error 0.0000(0.0000) Steps 808(809.71) | Grad Norm 3.9711(3.9401) | Total Time 14.00(14.00)\n",
      "Iter 1610 | Time 19.2007(19.4064) | Bit/dim 3.7656(3.7774) | Xent 0.0000(0.0000) | Loss 3.7656(3.7774) | Error 0.0000(0.0000) Steps 802(809.54) | Grad Norm 2.2470(3.8499) | Total Time 14.00(14.00)\n",
      "Iter 1620 | Time 19.5450(19.3571) | Bit/dim 3.7829(3.7769) | Xent 0.0000(0.0000) | Loss 3.7829(3.7769) | Error 0.0000(0.0000) Steps 820(810.63) | Grad Norm 2.7674(3.8039) | Total Time 14.00(14.00)\n",
      "Iter 1630 | Time 19.0296(19.3567) | Bit/dim 3.7929(3.7749) | Xent 0.0000(0.0000) | Loss 3.7929(3.7749) | Error 0.0000(0.0000) Steps 808(810.98) | Grad Norm 4.1257(4.2955) | Total Time 14.00(14.00)\n",
      "Iter 1640 | Time 19.2402(19.3426) | Bit/dim 3.7859(3.7731) | Xent 0.0000(0.0000) | Loss 3.7859(3.7731) | Error 0.0000(0.0000) Steps 808(811.65) | Grad Norm 7.1202(4.5187) | Total Time 14.00(14.00)\n",
      "Iter 1650 | Time 19.6742(19.3692) | Bit/dim 3.7641(3.7723) | Xent 0.0000(0.0000) | Loss 3.7641(3.7723) | Error 0.0000(0.0000) Steps 814(811.08) | Grad Norm 2.4168(4.4529) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 97.7703, Epoch Time 1177.0695(1003.4798), Bit/dim 3.7599(best: 3.7704), Xent 0.0000, Loss 3.7599, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1660 | Time 19.6628(19.4127) | Bit/dim 3.7790(3.7680) | Xent 0.0000(0.0000) | Loss 3.7790(3.7680) | Error 0.0000(0.0000) Steps 808(810.81) | Grad Norm 3.7845(4.0078) | Total Time 14.00(14.00)\n",
      "Iter 1670 | Time 19.5366(19.4431) | Bit/dim 3.7481(3.7668) | Xent 0.0000(0.0000) | Loss 3.7481(3.7668) | Error 0.0000(0.0000) Steps 802(810.18) | Grad Norm 3.8661(4.1109) | Total Time 14.00(14.00)\n",
      "Iter 1680 | Time 19.2927(19.3985) | Bit/dim 3.7446(3.7637) | Xent 0.0000(0.0000) | Loss 3.7446(3.7637) | Error 0.0000(0.0000) Steps 808(809.45) | Grad Norm 4.1511(4.0223) | Total Time 14.00(14.00)\n",
      "Iter 1690 | Time 18.8909(19.3591) | Bit/dim 3.7283(3.7597) | Xent 0.0000(0.0000) | Loss 3.7283(3.7597) | Error 0.0000(0.0000) Steps 808(809.42) | Grad Norm 3.2029(3.9338) | Total Time 14.00(14.00)\n",
      "Iter 1700 | Time 19.2971(19.3230) | Bit/dim 3.7333(3.7530) | Xent 0.0000(0.0000) | Loss 3.7333(3.7530) | Error 0.0000(0.0000) Steps 808(809.02) | Grad Norm 1.5893(3.3954) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 96.8507, Epoch Time 1179.8161(1008.7699), Bit/dim 3.7778(best: 3.7599), Xent 0.0000, Loss 3.7778, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1710 | Time 19.2022(19.3059) | Bit/dim 3.7647(3.7585) | Xent 0.0000(0.0000) | Loss 3.7647(3.7585) | Error 0.0000(0.0000) Steps 808(808.63) | Grad Norm 6.0396(4.1112) | Total Time 14.00(14.00)\n",
      "Iter 1720 | Time 19.5970(19.2855) | Bit/dim 3.7134(3.7544) | Xent 0.0000(0.0000) | Loss 3.7134(3.7544) | Error 0.0000(0.0000) Steps 808(808.45) | Grad Norm 2.4356(4.0403) | Total Time 14.00(14.00)\n",
      "Iter 1730 | Time 19.4224(19.3895) | Bit/dim 3.7654(3.7515) | Xent 0.0000(0.0000) | Loss 3.7654(3.7515) | Error 0.0000(0.0000) Steps 802(808.36) | Grad Norm 5.2364(4.3089) | Total Time 14.00(14.00)\n",
      "Iter 1740 | Time 19.2784(19.4239) | Bit/dim 3.7277(3.7469) | Xent 0.0000(0.0000) | Loss 3.7277(3.7469) | Error 0.0000(0.0000) Steps 802(807.77) | Grad Norm 4.0857(4.1288) | Total Time 14.00(14.00)\n",
      "Iter 1750 | Time 20.0442(19.5746) | Bit/dim 3.7321(3.7431) | Xent 0.0000(0.0000) | Loss 3.7321(3.7431) | Error 0.0000(0.0000) Steps 802(808.13) | Grad Norm 1.3048(3.6502) | Total Time 14.00(14.00)\n",
      "Iter 1760 | Time 19.6129(19.5207) | Bit/dim 3.7436(3.7455) | Xent 0.0000(0.0000) | Loss 3.7436(3.7455) | Error 0.0000(0.0000) Steps 802(807.89) | Grad Norm 7.0622(4.0169) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 96.4542, Epoch Time 1187.6560(1014.1364), Bit/dim 3.7472(best: 3.7599), Xent 0.0000, Loss 3.7472, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1770 | Time 19.6818(19.5055) | Bit/dim 3.7295(3.7430) | Xent 0.0000(0.0000) | Loss 3.7295(3.7430) | Error 0.0000(0.0000) Steps 814(807.79) | Grad Norm 4.3993(4.1502) | Total Time 14.00(14.00)\n",
      "Iter 1780 | Time 19.7526(19.4792) | Bit/dim 3.7433(3.7426) | Xent 0.0000(0.0000) | Loss 3.7433(3.7426) | Error 0.0000(0.0000) Steps 814(808.81) | Grad Norm 4.7839(4.1481) | Total Time 14.00(14.00)\n",
      "Iter 1790 | Time 18.7907(19.4578) | Bit/dim 3.7425(3.7397) | Xent 0.0000(0.0000) | Loss 3.7425(3.7397) | Error 0.0000(0.0000) Steps 802(809.05) | Grad Norm 3.6362(4.1419) | Total Time 14.00(14.00)\n",
      "Iter 1800 | Time 19.9591(19.4209) | Bit/dim 3.7159(3.7359) | Xent 0.0000(0.0000) | Loss 3.7159(3.7359) | Error 0.0000(0.0000) Steps 808(808.66) | Grad Norm 4.1189(4.0794) | Total Time 14.00(14.00)\n",
      "Iter 1810 | Time 19.3434(19.4226) | Bit/dim 3.7102(3.7327) | Xent 0.0000(0.0000) | Loss 3.7102(3.7327) | Error 0.0000(0.0000) Steps 808(808.50) | Grad Norm 1.9783(3.7825) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 97.3701, Epoch Time 1182.1523(1019.1769), Bit/dim 3.7265(best: 3.7472), Xent 0.0000, Loss 3.7265, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1820 | Time 20.2601(19.4430) | Bit/dim 3.7299(3.7316) | Xent 0.0000(0.0000) | Loss 3.7299(3.7316) | Error 0.0000(0.0000) Steps 808(808.88) | Grad Norm 6.0089(3.9651) | Total Time 14.00(14.00)\n",
      "Iter 1830 | Time 18.8888(19.4134) | Bit/dim 3.6988(3.7280) | Xent 0.0000(0.0000) | Loss 3.6988(3.7280) | Error 0.0000(0.0000) Steps 814(809.16) | Grad Norm 3.8266(4.1226) | Total Time 14.00(14.00)\n",
      "Iter 1840 | Time 19.3245(19.4039) | Bit/dim 3.7100(3.7261) | Xent 0.0000(0.0000) | Loss 3.7100(3.7261) | Error 0.0000(0.0000) Steps 814(809.50) | Grad Norm 5.7804(4.4362) | Total Time 14.00(14.00)\n",
      "Iter 1850 | Time 19.4094(19.4368) | Bit/dim 3.6980(3.7280) | Xent 0.0000(0.0000) | Loss 3.6980(3.7280) | Error 0.0000(0.0000) Steps 808(810.40) | Grad Norm 2.5486(4.5422) | Total Time 14.00(14.00)\n",
      "Iter 1860 | Time 19.9298(19.4308) | Bit/dim 3.7543(3.7280) | Xent 0.0000(0.0000) | Loss 3.7543(3.7280) | Error 0.0000(0.0000) Steps 808(809.77) | Grad Norm 1.6772(4.0544) | Total Time 14.00(14.00)\n",
      "Iter 1870 | Time 19.9134(19.4531) | Bit/dim 3.7404(3.7258) | Xent 0.0000(0.0000) | Loss 3.7404(3.7258) | Error 0.0000(0.0000) Steps 814(809.98) | Grad Norm 3.9421(3.6993) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 96.9343, Epoch Time 1184.3432(1024.1319), Bit/dim 3.7145(best: 3.7265), Xent 0.0000, Loss 3.7145, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1880 | Time 19.7858(19.4345) | Bit/dim 3.6902(3.7214) | Xent 0.0000(0.0000) | Loss 3.6902(3.7214) | Error 0.0000(0.0000) Steps 808(808.70) | Grad Norm 1.2557(3.5622) | Total Time 14.00(14.00)\n",
      "Iter 1890 | Time 19.3789(19.4382) | Bit/dim 3.7242(3.7174) | Xent 0.0000(0.0000) | Loss 3.7242(3.7174) | Error 0.0000(0.0000) Steps 814(808.39) | Grad Norm 4.5546(3.6536) | Total Time 14.00(14.00)\n",
      "Iter 1900 | Time 19.2222(19.4573) | Bit/dim 3.6851(3.7163) | Xent 0.0000(0.0000) | Loss 3.6851(3.7163) | Error 0.0000(0.0000) Steps 808(808.32) | Grad Norm 2.2010(3.6132) | Total Time 14.00(14.00)\n",
      "Iter 1910 | Time 19.4021(19.4581) | Bit/dim 3.7206(3.7149) | Xent 0.0000(0.0000) | Loss 3.7206(3.7149) | Error 0.0000(0.0000) Steps 808(808.08) | Grad Norm 4.9111(3.7433) | Total Time 14.00(14.00)\n",
      "Iter 1920 | Time 19.1706(19.4425) | Bit/dim 3.6951(3.7135) | Xent 0.0000(0.0000) | Loss 3.6951(3.7135) | Error 0.0000(0.0000) Steps 808(807.16) | Grad Norm 2.9412(3.7265) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 97.3320, Epoch Time 1184.5582(1028.9447), Bit/dim 3.7132(best: 3.7145), Xent 0.0000, Loss 3.7132, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1930 | Time 19.5744(19.4448) | Bit/dim 3.7026(3.7133) | Xent 0.0000(0.0000) | Loss 3.7026(3.7133) | Error 0.0000(0.0000) Steps 796(806.87) | Grad Norm 3.2158(4.1319) | Total Time 14.00(14.00)\n",
      "Iter 1940 | Time 19.1597(19.4157) | Bit/dim 3.7044(3.7132) | Xent 0.0000(0.0000) | Loss 3.7044(3.7132) | Error 0.0000(0.0000) Steps 808(806.33) | Grad Norm 4.2622(4.0700) | Total Time 14.00(14.00)\n",
      "Iter 1950 | Time 19.5950(19.4199) | Bit/dim 3.6760(3.7094) | Xent 0.0000(0.0000) | Loss 3.6760(3.7094) | Error 0.0000(0.0000) Steps 802(805.55) | Grad Norm 1.2493(3.8082) | Total Time 14.00(14.00)\n",
      "Iter 1960 | Time 19.1680(19.4039) | Bit/dim 3.7165(3.7053) | Xent 0.0000(0.0000) | Loss 3.7165(3.7053) | Error 0.0000(0.0000) Steps 808(806.05) | Grad Norm 3.0851(3.4859) | Total Time 14.00(14.00)\n",
      "Iter 1970 | Time 18.8240(19.4057) | Bit/dim 3.7160(3.7030) | Xent 0.0000(0.0000) | Loss 3.7160(3.7030) | Error 0.0000(0.0000) Steps 802(805.95) | Grad Norm 3.5972(3.5541) | Total Time 14.00(14.00)\n",
      "Iter 1980 | Time 19.4455(19.4301) | Bit/dim 3.6882(3.7030) | Xent 0.0000(0.0000) | Loss 3.6882(3.7030) | Error 0.0000(0.0000) Steps 814(806.69) | Grad Norm 3.8139(3.6449) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 97.0467, Epoch Time 1182.3527(1033.5469), Bit/dim 3.7037(best: 3.7132), Xent 0.0000, Loss 3.7037, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1990 | Time 19.7535(19.4742) | Bit/dim 3.6745(3.7025) | Xent 0.0000(0.0000) | Loss 3.6745(3.7025) | Error 0.0000(0.0000) Steps 814(806.45) | Grad Norm 3.9398(3.8207) | Total Time 14.00(14.00)\n",
      "Iter 2000 | Time 19.5084(19.4857) | Bit/dim 3.7209(3.6961) | Xent 0.0000(0.0000) | Loss 3.7209(3.6961) | Error 0.0000(0.0000) Steps 802(806.83) | Grad Norm 3.7610(3.7464) | Total Time 14.00(14.00)\n",
      "Iter 2010 | Time 20.1268(19.4429) | Bit/dim 3.7037(3.6961) | Xent 0.0000(0.0000) | Loss 3.7037(3.6961) | Error 0.0000(0.0000) Steps 814(806.08) | Grad Norm 3.5761(3.9647) | Total Time 14.00(14.00)\n",
      "Iter 2020 | Time 19.5354(19.4405) | Bit/dim 3.6965(3.6974) | Xent 0.0000(0.0000) | Loss 3.6965(3.6974) | Error 0.0000(0.0000) Steps 808(804.94) | Grad Norm 2.8345(3.7806) | Total Time 14.00(14.00)\n",
      "Iter 2030 | Time 19.4379(19.4851) | Bit/dim 3.7575(3.6981) | Xent 0.0000(0.0000) | Loss 3.7575(3.6981) | Error 0.0000(0.0000) Steps 808(805.32) | Grad Norm 5.0352(3.9356) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 97.1933, Epoch Time 1185.4046(1038.1027), Bit/dim 3.6915(best: 3.7037), Xent 0.0000, Loss 3.6915, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2040 | Time 18.8788(19.4141) | Bit/dim 3.6835(3.6939) | Xent 0.0000(0.0000) | Loss 3.6835(3.6939) | Error 0.0000(0.0000) Steps 808(804.37) | Grad Norm 6.2965(3.9234) | Total Time 14.00(14.00)\n",
      "Iter 2050 | Time 18.8179(19.3370) | Bit/dim 3.6997(3.6942) | Xent 0.0000(0.0000) | Loss 3.6997(3.6942) | Error 0.0000(0.0000) Steps 802(803.53) | Grad Norm 1.4028(3.8224) | Total Time 14.00(14.00)\n",
      "Iter 2060 | Time 19.0478(19.3178) | Bit/dim 3.6699(3.6937) | Xent 0.0000(0.0000) | Loss 3.6699(3.6937) | Error 0.0000(0.0000) Steps 802(802.99) | Grad Norm 2.8523(3.6227) | Total Time 14.00(14.00)\n",
      "Iter 2070 | Time 19.7153(19.3616) | Bit/dim 3.6551(3.6895) | Xent 0.0000(0.0000) | Loss 3.6551(3.6895) | Error 0.0000(0.0000) Steps 808(803.17) | Grad Norm 2.3809(3.4677) | Total Time 14.00(14.00)\n",
      "Iter 2080 | Time 19.5382(19.4125) | Bit/dim 3.7027(3.6889) | Xent 0.0000(0.0000) | Loss 3.7027(3.6889) | Error 0.0000(0.0000) Steps 790(803.44) | Grad Norm 1.6785(3.8121) | Total Time 14.00(14.00)\n",
      "Iter 2090 | Time 19.1165(19.3408) | Bit/dim 3.6643(3.6869) | Xent 0.0000(0.0000) | Loss 3.6643(3.6869) | Error 0.0000(0.0000) Steps 796(800.53) | Grad Norm 4.3176(3.8251) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 96.3931, Epoch Time 1176.4712(1042.2537), Bit/dim 3.6802(best: 3.6915), Xent 0.0000, Loss 3.6802, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2100 | Time 19.6401(19.3568) | Bit/dim 3.6979(3.6829) | Xent 0.0000(0.0000) | Loss 3.6979(3.6829) | Error 0.0000(0.0000) Steps 802(800.79) | Grad Norm 3.3497(3.5746) | Total Time 14.00(14.00)\n",
      "Iter 2110 | Time 19.5700(19.3886) | Bit/dim 3.6486(3.6835) | Xent 0.0000(0.0000) | Loss 3.6486(3.6835) | Error 0.0000(0.0000) Steps 802(800.88) | Grad Norm 1.7107(3.2924) | Total Time 14.00(14.00)\n",
      "Iter 2120 | Time 19.8740(19.3881) | Bit/dim 3.6932(3.6813) | Xent 0.0000(0.0000) | Loss 3.6932(3.6813) | Error 0.0000(0.0000) Steps 796(800.74) | Grad Norm 5.7547(3.5885) | Total Time 14.00(14.00)\n",
      "Iter 2130 | Time 19.3638(19.3608) | Bit/dim 3.7008(3.6821) | Xent 0.0000(0.0000) | Loss 3.7008(3.6821) | Error 0.0000(0.0000) Steps 796(800.11) | Grad Norm 4.3191(4.0658) | Total Time 14.00(14.00)\n",
      "Iter 2140 | Time 19.5021(19.3709) | Bit/dim 3.6756(3.6795) | Xent 0.0000(0.0000) | Loss 3.6756(3.6795) | Error 0.0000(0.0000) Steps 796(799.48) | Grad Norm 3.0324(4.0130) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 97.7462, Epoch Time 1181.8174(1046.4406), Bit/dim 3.6692(best: 3.6802), Xent 0.0000, Loss 3.6692, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2150 | Time 18.9499(19.3823) | Bit/dim 3.6542(3.6796) | Xent 0.0000(0.0000) | Loss 3.6542(3.6796) | Error 0.0000(0.0000) Steps 790(799.93) | Grad Norm 3.3391(3.6731) | Total Time 14.00(14.00)\n",
      "Iter 2160 | Time 20.0469(19.4813) | Bit/dim 3.6991(3.6766) | Xent 0.0000(0.0000) | Loss 3.6991(3.6766) | Error 0.0000(0.0000) Steps 820(800.01) | Grad Norm 3.7205(3.4342) | Total Time 14.00(14.00)\n",
      "Iter 2170 | Time 20.1540(19.5586) | Bit/dim 3.6505(3.6757) | Xent 0.0000(0.0000) | Loss 3.6505(3.6757) | Error 0.0000(0.0000) Steps 820(800.19) | Grad Norm 2.3112(3.2317) | Total Time 14.00(14.00)\n",
      "Iter 2180 | Time 20.7539(19.6641) | Bit/dim 3.6653(3.6732) | Xent 0.0000(0.0000) | Loss 3.6653(3.6732) | Error 0.0000(0.0000) Steps 808(801.18) | Grad Norm 5.1777(3.5360) | Total Time 14.00(14.00)\n",
      "Iter 2190 | Time 19.6852(19.6191) | Bit/dim 3.6742(3.6749) | Xent 0.0000(0.0000) | Loss 3.6742(3.6749) | Error 0.0000(0.0000) Steps 814(801.64) | Grad Norm 4.2401(3.6958) | Total Time 14.00(14.00)\n",
      "Iter 2200 | Time 18.8720(19.5794) | Bit/dim 3.6738(3.6705) | Xent 0.0000(0.0000) | Loss 3.6738(3.6705) | Error 0.0000(0.0000) Steps 796(802.61) | Grad Norm 3.6479(3.3672) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 96.9122, Epoch Time 1196.3048(1050.9366), Bit/dim 3.6737(best: 3.6692), Xent 0.0000, Loss 3.6737, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2210 | Time 19.8010(19.5453) | Bit/dim 3.6539(3.6690) | Xent 0.0000(0.0000) | Loss 3.6539(3.6690) | Error 0.0000(0.0000) Steps 802(803.04) | Grad Norm 1.5743(3.5430) | Total Time 14.00(14.00)\n",
      "Iter 2220 | Time 19.1372(19.5055) | Bit/dim 3.6341(3.6652) | Xent 0.0000(0.0000) | Loss 3.6341(3.6652) | Error 0.0000(0.0000) Steps 808(802.70) | Grad Norm 4.2975(3.4344) | Total Time 14.00(14.00)\n",
      "Iter 2230 | Time 19.5860(19.5468) | Bit/dim 3.6525(3.6667) | Xent 0.0000(0.0000) | Loss 3.6525(3.6667) | Error 0.0000(0.0000) Steps 796(803.60) | Grad Norm 3.0285(3.3526) | Total Time 14.00(14.00)\n",
      "Iter 2240 | Time 19.6711(19.5059) | Bit/dim 3.6288(3.6660) | Xent 0.0000(0.0000) | Loss 3.6288(3.6660) | Error 0.0000(0.0000) Steps 784(804.32) | Grad Norm 3.5231(3.5353) | Total Time 14.00(14.00)\n",
      "Iter 2250 | Time 19.5299(19.5504) | Bit/dim 3.6451(3.6663) | Xent 0.0000(0.0000) | Loss 3.6451(3.6663) | Error 0.0000(0.0000) Steps 802(805.28) | Grad Norm 3.8986(3.6515) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 97.1393, Epoch Time 1189.5631(1055.0954), Bit/dim 3.6621(best: 3.6692), Xent 0.0000, Loss 3.6621, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2260 | Time 19.4642(19.6092) | Bit/dim 3.6720(3.6630) | Xent 0.0000(0.0000) | Loss 3.6720(3.6630) | Error 0.0000(0.0000) Steps 808(806.91) | Grad Norm 2.6572(3.5941) | Total Time 14.00(14.00)\n",
      "Iter 2270 | Time 20.0213(19.6171) | Bit/dim 3.6560(3.6613) | Xent 0.0000(0.0000) | Loss 3.6560(3.6613) | Error 0.0000(0.0000) Steps 796(807.17) | Grad Norm 2.6165(3.6831) | Total Time 14.00(14.00)\n",
      "Iter 2280 | Time 20.1546(19.7086) | Bit/dim 3.6803(3.6603) | Xent 0.0000(0.0000) | Loss 3.6803(3.6603) | Error 0.0000(0.0000) Steps 814(808.20) | Grad Norm 3.7606(3.4156) | Total Time 14.00(14.00)\n",
      "Iter 2290 | Time 19.9970(19.6442) | Bit/dim 3.6297(3.6600) | Xent 0.0000(0.0000) | Loss 3.6297(3.6600) | Error 0.0000(0.0000) Steps 802(806.75) | Grad Norm 3.9102(3.7524) | Total Time 14.00(14.00)\n",
      "Iter 2300 | Time 19.8737(19.7265) | Bit/dim 3.6565(3.6581) | Xent 0.0000(0.0000) | Loss 3.6565(3.6581) | Error 0.0000(0.0000) Steps 820(808.12) | Grad Norm 2.9430(3.5322) | Total Time 14.00(14.00)\n",
      "Iter 2310 | Time 20.3108(19.7361) | Bit/dim 3.6305(3.6581) | Xent 0.0000(0.0000) | Loss 3.6305(3.6581) | Error 0.0000(0.0000) Steps 814(808.78) | Grad Norm 1.5609(3.3124) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 97.3893, Epoch Time 1201.3856(1059.4841), Bit/dim 3.6498(best: 3.6621), Xent 0.0000, Loss 3.6498, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2320 | Time 19.8342(19.6902) | Bit/dim 3.6667(3.6551) | Xent 0.0000(0.0000) | Loss 3.6667(3.6551) | Error 0.0000(0.0000) Steps 820(808.58) | Grad Norm 4.6788(3.3742) | Total Time 14.00(14.00)\n",
      "Iter 2330 | Time 19.3061(19.6579) | Bit/dim 3.6350(3.6541) | Xent 0.0000(0.0000) | Loss 3.6350(3.6541) | Error 0.0000(0.0000) Steps 790(809.48) | Grad Norm 2.4933(3.6091) | Total Time 14.00(14.00)\n",
      "Iter 2340 | Time 18.6154(19.6954) | Bit/dim 3.6884(3.6557) | Xent 0.0000(0.0000) | Loss 3.6884(3.6557) | Error 0.0000(0.0000) Steps 796(808.53) | Grad Norm 2.4043(3.4653) | Total Time 14.00(14.00)\n",
      "Iter 2350 | Time 19.8107(19.7149) | Bit/dim 3.6323(3.6531) | Xent 0.0000(0.0000) | Loss 3.6323(3.6531) | Error 0.0000(0.0000) Steps 808(806.83) | Grad Norm 7.2049(3.3505) | Total Time 14.00(14.00)\n",
      "Iter 2360 | Time 19.1086(19.6620) | Bit/dim 3.5979(3.6523) | Xent 0.0000(0.0000) | Loss 3.5979(3.6523) | Error 0.0000(0.0000) Steps 796(806.59) | Grad Norm 4.2015(3.4768) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 97.3545, Epoch Time 1195.4388(1063.5627), Bit/dim 3.6476(best: 3.6498), Xent 0.0000, Loss 3.6476, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2370 | Time 20.1184(19.7009) | Bit/dim 3.6044(3.6512) | Xent 0.0000(0.0000) | Loss 3.6044(3.6512) | Error 0.0000(0.0000) Steps 796(808.63) | Grad Norm 2.6400(3.2714) | Total Time 14.00(14.00)\n",
      "Iter 2380 | Time 19.4654(19.7073) | Bit/dim 3.6333(3.6523) | Xent 0.0000(0.0000) | Loss 3.6333(3.6523) | Error 0.0000(0.0000) Steps 808(809.14) | Grad Norm 3.3602(3.4057) | Total Time 14.00(14.00)\n",
      "Iter 2390 | Time 20.1011(19.7081) | Bit/dim 3.6627(3.6526) | Xent 0.0000(0.0000) | Loss 3.6627(3.6526) | Error 0.0000(0.0000) Steps 820(808.43) | Grad Norm 3.3742(3.6657) | Total Time 14.00(14.00)\n",
      "Iter 2400 | Time 19.7785(19.7518) | Bit/dim 3.6255(3.6488) | Xent 0.0000(0.0000) | Loss 3.6255(3.6488) | Error 0.0000(0.0000) Steps 814(808.03) | Grad Norm 2.2388(3.3898) | Total Time 14.00(14.00)\n",
      "Iter 2410 | Time 20.3302(19.7938) | Bit/dim 3.6627(3.6477) | Xent 0.0000(0.0000) | Loss 3.6627(3.6477) | Error 0.0000(0.0000) Steps 796(809.28) | Grad Norm 2.5695(3.0820) | Total Time 14.00(14.00)\n",
      "Iter 2420 | Time 19.8909(19.8455) | Bit/dim 3.6381(3.6476) | Xent 0.0000(0.0000) | Loss 3.6381(3.6476) | Error 0.0000(0.0000) Steps 802(808.98) | Grad Norm 4.0570(3.5408) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 97.2940, Epoch Time 1207.1445(1067.8702), Bit/dim 3.6422(best: 3.6476), Xent 0.0000, Loss 3.6422, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2430 | Time 19.4430(19.9050) | Bit/dim 3.6571(3.6463) | Xent 0.0000(0.0000) | Loss 3.6571(3.6463) | Error 0.0000(0.0000) Steps 802(809.20) | Grad Norm 2.8511(3.4384) | Total Time 14.00(14.00)\n",
      "Iter 2440 | Time 20.1715(19.9754) | Bit/dim 3.6088(3.6411) | Xent 0.0000(0.0000) | Loss 3.6088(3.6411) | Error 0.0000(0.0000) Steps 820(810.67) | Grad Norm 1.9792(3.1016) | Total Time 14.00(14.00)\n",
      "Iter 2450 | Time 19.5774(19.8968) | Bit/dim 3.6539(3.6411) | Xent 0.0000(0.0000) | Loss 3.6539(3.6411) | Error 0.0000(0.0000) Steps 784(810.97) | Grad Norm 4.0199(3.3572) | Total Time 14.00(14.00)\n",
      "Iter 2460 | Time 19.7396(19.9396) | Bit/dim 3.6643(3.6432) | Xent 0.0000(0.0000) | Loss 3.6643(3.6432) | Error 0.0000(0.0000) Steps 820(812.72) | Grad Norm 2.1931(3.4831) | Total Time 14.00(14.00)\n",
      "Iter 2470 | Time 20.0015(19.9849) | Bit/dim 3.6335(3.6444) | Xent 0.0000(0.0000) | Loss 3.6335(3.6444) | Error 0.0000(0.0000) Steps 832(814.53) | Grad Norm 2.2599(3.5793) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 96.5196, Epoch Time 1214.7614(1072.2769), Bit/dim 3.6362(best: 3.6422), Xent 0.0000, Loss 3.6362, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2480 | Time 20.0904(20.0379) | Bit/dim 3.6684(3.6416) | Xent 0.0000(0.0000) | Loss 3.6684(3.6416) | Error 0.0000(0.0000) Steps 808(814.20) | Grad Norm 1.8866(3.5019) | Total Time 14.00(14.00)\n",
      "Iter 2490 | Time 18.4055(19.9967) | Bit/dim 3.6440(3.6397) | Xent 0.0000(0.0000) | Loss 3.6440(3.6397) | Error 0.0000(0.0000) Steps 790(814.17) | Grad Norm 2.8713(3.2723) | Total Time 14.00(14.00)\n",
      "Iter 2500 | Time 19.4920(20.0145) | Bit/dim 3.6147(3.6395) | Xent 0.0000(0.0000) | Loss 3.6147(3.6395) | Error 0.0000(0.0000) Steps 790(815.46) | Grad Norm 1.9803(3.0498) | Total Time 14.00(14.00)\n",
      "Iter 2510 | Time 19.6391(20.0671) | Bit/dim 3.6205(3.6350) | Xent 0.0000(0.0000) | Loss 3.6205(3.6350) | Error 0.0000(0.0000) Steps 826(816.82) | Grad Norm 4.5994(3.3217) | Total Time 14.00(14.00)\n",
      "Iter 2520 | Time 21.0746(20.0865) | Bit/dim 3.6202(3.6357) | Xent 0.0000(0.0000) | Loss 3.6202(3.6357) | Error 0.0000(0.0000) Steps 832(816.66) | Grad Norm 2.2829(3.5417) | Total Time 14.00(14.00)\n",
      "Iter 2530 | Time 20.7282(20.1391) | Bit/dim 3.6295(3.6355) | Xent 0.0000(0.0000) | Loss 3.6295(3.6355) | Error 0.0000(0.0000) Steps 826(816.65) | Grad Norm 3.5598(3.4470) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 96.7887, Epoch Time 1221.8870(1076.7652), Bit/dim 3.6356(best: 3.6362), Xent 0.0000, Loss 3.6356, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2540 | Time 20.0734(20.1148) | Bit/dim 3.6156(3.6345) | Xent 0.0000(0.0000) | Loss 3.6156(3.6345) | Error 0.0000(0.0000) Steps 790(815.66) | Grad Norm 5.5225(3.5277) | Total Time 14.00(14.00)\n",
      "Iter 2550 | Time 19.6211(20.1341) | Bit/dim 3.6347(3.6337) | Xent 0.0000(0.0000) | Loss 3.6347(3.6337) | Error 0.0000(0.0000) Steps 790(814.39) | Grad Norm 1.8637(3.4443) | Total Time 14.00(14.00)\n",
      "Iter 2560 | Time 19.7141(20.1649) | Bit/dim 3.6069(3.6309) | Xent 0.0000(0.0000) | Loss 3.6069(3.6309) | Error 0.0000(0.0000) Steps 802(815.18) | Grad Norm 2.0273(3.1663) | Total Time 14.00(14.00)\n",
      "Iter 2570 | Time 20.2381(20.1255) | Bit/dim 3.6252(3.6300) | Xent 0.0000(0.0000) | Loss 3.6252(3.6300) | Error 0.0000(0.0000) Steps 838(817.79) | Grad Norm 4.3581(3.2080) | Total Time 14.00(14.00)\n",
      "Iter 2580 | Time 20.8939(20.1354) | Bit/dim 3.6338(3.6304) | Xent 0.0000(0.0000) | Loss 3.6338(3.6304) | Error 0.0000(0.0000) Steps 832(816.34) | Grad Norm 5.5820(3.3556) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 97.2320, Epoch Time 1223.3885(1081.1639), Bit/dim 3.6339(best: 3.6356), Xent 0.0000, Loss 3.6339, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2590 | Time 20.7885(20.1914) | Bit/dim 3.6453(3.6301) | Xent 0.0000(0.0000) | Loss 3.6453(3.6301) | Error 0.0000(0.0000) Steps 802(816.12) | Grad Norm 4.2028(3.5455) | Total Time 14.00(14.00)\n",
      "Iter 2600 | Time 20.0325(20.1896) | Bit/dim 3.6342(3.6294) | Xent 0.0000(0.0000) | Loss 3.6342(3.6294) | Error 0.0000(0.0000) Steps 814(814.94) | Grad Norm 2.3889(3.2764) | Total Time 14.00(14.00)\n",
      "Iter 2610 | Time 20.3446(20.2052) | Bit/dim 3.6266(3.6302) | Xent 0.0000(0.0000) | Loss 3.6266(3.6302) | Error 0.0000(0.0000) Steps 826(816.61) | Grad Norm 4.7045(3.1601) | Total Time 14.00(14.00)\n",
      "Iter 2620 | Time 19.8459(20.1283) | Bit/dim 3.6084(3.6261) | Xent 0.0000(0.0000) | Loss 3.6084(3.6261) | Error 0.0000(0.0000) Steps 820(815.91) | Grad Norm 2.1405(3.2641) | Total Time 14.00(14.00)\n",
      "Iter 2630 | Time 19.5468(20.1377) | Bit/dim 3.6271(3.6241) | Xent 0.0000(0.0000) | Loss 3.6271(3.6241) | Error 0.0000(0.0000) Steps 802(815.26) | Grad Norm 4.7236(3.4136) | Total Time 14.00(14.00)\n",
      "Iter 2640 | Time 19.4006(20.1773) | Bit/dim 3.6119(3.6248) | Xent 0.0000(0.0000) | Loss 3.6119(3.6248) | Error 0.0000(0.0000) Steps 802(813.88) | Grad Norm 2.4327(3.4077) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 96.9741, Epoch Time 1224.5538(1085.4656), Bit/dim 3.6202(best: 3.6339), Xent 0.0000, Loss 3.6202, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2650 | Time 20.2574(20.1493) | Bit/dim 3.6362(3.6232) | Xent 0.0000(0.0000) | Loss 3.6362(3.6232) | Error 0.0000(0.0000) Steps 814(811.69) | Grad Norm 2.6431(3.2867) | Total Time 14.00(14.00)\n",
      "Iter 2660 | Time 20.3745(20.2068) | Bit/dim 3.6380(3.6230) | Xent 0.0000(0.0000) | Loss 3.6380(3.6230) | Error 0.0000(0.0000) Steps 808(812.60) | Grad Norm 2.9032(3.0488) | Total Time 14.00(14.00)\n",
      "Iter 2670 | Time 20.8553(20.2546) | Bit/dim 3.6076(3.6226) | Xent 0.0000(0.0000) | Loss 3.6076(3.6226) | Error 0.0000(0.0000) Steps 844(813.70) | Grad Norm 3.0467(3.3016) | Total Time 14.00(14.00)\n",
      "Iter 2680 | Time 20.3058(20.2162) | Bit/dim 3.6267(3.6209) | Xent 0.0000(0.0000) | Loss 3.6267(3.6209) | Error 0.0000(0.0000) Steps 802(812.15) | Grad Norm 2.9110(3.2821) | Total Time 14.00(14.00)\n",
      "Iter 2690 | Time 19.6896(20.2168) | Bit/dim 3.6344(3.6201) | Xent 0.0000(0.0000) | Loss 3.6344(3.6201) | Error 0.0000(0.0000) Steps 808(810.84) | Grad Norm 3.0957(3.1052) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 96.4742, Epoch Time 1228.1757(1089.7469), Bit/dim 3.6169(best: 3.6202), Xent 0.0000, Loss 3.6169, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2700 | Time 20.6573(20.2576) | Bit/dim 3.6078(3.6195) | Xent 0.0000(0.0000) | Loss 3.6078(3.6195) | Error 0.0000(0.0000) Steps 826(812.04) | Grad Norm 3.0028(3.0670) | Total Time 14.00(14.00)\n",
      "Iter 2710 | Time 20.4319(20.2336) | Bit/dim 3.6068(3.6173) | Xent 0.0000(0.0000) | Loss 3.6068(3.6173) | Error 0.0000(0.0000) Steps 814(810.87) | Grad Norm 3.3509(3.3751) | Total Time 14.00(14.00)\n",
      "Iter 2720 | Time 20.7136(20.2817) | Bit/dim 3.6275(3.6189) | Xent 0.0000(0.0000) | Loss 3.6275(3.6189) | Error 0.0000(0.0000) Steps 832(814.03) | Grad Norm 5.0908(3.3844) | Total Time 14.00(14.00)\n",
      "Iter 2730 | Time 19.7577(20.1972) | Bit/dim 3.6001(3.6182) | Xent 0.0000(0.0000) | Loss 3.6001(3.6182) | Error 0.0000(0.0000) Steps 826(813.36) | Grad Norm 3.3765(3.4823) | Total Time 14.00(14.00)\n",
      "Iter 2740 | Time 19.9460(20.2044) | Bit/dim 3.6117(3.6164) | Xent 0.0000(0.0000) | Loss 3.6117(3.6164) | Error 0.0000(0.0000) Steps 802(813.10) | Grad Norm 3.4763(3.2794) | Total Time 14.00(14.00)\n",
      "Iter 2750 | Time 19.5615(20.1630) | Bit/dim 3.6433(3.6165) | Xent 0.0000(0.0000) | Loss 3.6433(3.6165) | Error 0.0000(0.0000) Steps 802(812.51) | Grad Norm 4.3479(3.4667) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 97.2213, Epoch Time 1224.2085(1093.7807), Bit/dim 3.6167(best: 3.6169), Xent 0.0000, Loss 3.6167, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2760 | Time 20.3296(20.1895) | Bit/dim 3.5713(3.6162) | Xent 0.0000(0.0000) | Loss 3.5713(3.6162) | Error 0.0000(0.0000) Steps 832(815.17) | Grad Norm 3.5125(3.4203) | Total Time 14.00(14.00)\n",
      "Iter 2770 | Time 20.2107(20.2241) | Bit/dim 3.6084(3.6133) | Xent 0.0000(0.0000) | Loss 3.6084(3.6133) | Error 0.0000(0.0000) Steps 820(814.18) | Grad Norm 3.0987(3.2637) | Total Time 14.00(14.00)\n",
      "Iter 2780 | Time 20.4144(20.2302) | Bit/dim 3.5806(3.6116) | Xent 0.0000(0.0000) | Loss 3.5806(3.6116) | Error 0.0000(0.0000) Steps 820(813.65) | Grad Norm 4.4218(3.3467) | Total Time 14.00(14.00)\n",
      "Iter 2790 | Time 19.2718(20.1687) | Bit/dim 3.6071(3.6096) | Xent 0.0000(0.0000) | Loss 3.6071(3.6096) | Error 0.0000(0.0000) Steps 802(811.28) | Grad Norm 2.2881(3.0917) | Total Time 14.00(14.00)\n",
      "Iter 2800 | Time 20.1657(20.1584) | Bit/dim 3.6058(3.6101) | Xent 0.0000(0.0000) | Loss 3.6058(3.6101) | Error 0.0000(0.0000) Steps 808(811.55) | Grad Norm 3.5935(3.1308) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 97.5422, Epoch Time 1224.7219(1097.7090), Bit/dim 3.6064(best: 3.6167), Xent 0.0000, Loss 3.6064, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2810 | Time 20.3947(20.1487) | Bit/dim 3.6338(3.6105) | Xent 0.0000(0.0000) | Loss 3.6338(3.6105) | Error 0.0000(0.0000) Steps 808(812.36) | Grad Norm 3.5891(3.1111) | Total Time 14.00(14.00)\n",
      "Iter 2820 | Time 19.6990(20.1276) | Bit/dim 3.6034(3.6069) | Xent 0.0000(0.0000) | Loss 3.6034(3.6069) | Error 0.0000(0.0000) Steps 820(812.23) | Grad Norm 4.1173(3.1864) | Total Time 14.00(14.00)\n",
      "Iter 2830 | Time 19.8002(20.0961) | Bit/dim 3.6307(3.6071) | Xent 0.0000(0.0000) | Loss 3.6307(3.6071) | Error 0.0000(0.0000) Steps 814(812.07) | Grad Norm 4.1935(3.2075) | Total Time 14.00(14.00)\n",
      "Iter 2840 | Time 19.9404(20.1025) | Bit/dim 3.6414(3.6081) | Xent 0.0000(0.0000) | Loss 3.6414(3.6081) | Error 0.0000(0.0000) Steps 820(811.76) | Grad Norm 4.6723(3.3199) | Total Time 14.00(14.00)\n",
      "Iter 2850 | Time 19.9560(20.1244) | Bit/dim 3.6274(3.6115) | Xent 0.0000(0.0000) | Loss 3.6274(3.6115) | Error 0.0000(0.0000) Steps 790(810.06) | Grad Norm 2.1946(3.2343) | Total Time 14.00(14.00)\n",
      "Iter 2860 | Time 20.3034(20.1030) | Bit/dim 3.5696(3.6062) | Xent 0.0000(0.0000) | Loss 3.5696(3.6062) | Error 0.0000(0.0000) Steps 808(810.14) | Grad Norm 3.9410(3.2220) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 96.7024, Epoch Time 1220.1465(1101.3821), Bit/dim 3.6120(best: 3.6064), Xent 0.0000, Loss 3.6120, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2870 | Time 19.8886(20.0864) | Bit/dim 3.5931(3.6053) | Xent 0.0000(0.0000) | Loss 3.5931(3.6053) | Error 0.0000(0.0000) Steps 802(810.07) | Grad Norm 2.1207(3.1833) | Total Time 14.00(14.00)\n",
      "Iter 2880 | Time 19.3187(20.0991) | Bit/dim 3.5847(3.6047) | Xent 0.0000(0.0000) | Loss 3.5847(3.6047) | Error 0.0000(0.0000) Steps 802(808.83) | Grad Norm 2.4586(2.9686) | Total Time 14.00(14.00)\n",
      "Iter 2890 | Time 20.2202(20.1045) | Bit/dim 3.6284(3.6032) | Xent 0.0000(0.0000) | Loss 3.6284(3.6032) | Error 0.0000(0.0000) Steps 802(810.98) | Grad Norm 2.2222(3.1634) | Total Time 14.00(14.00)\n",
      "Iter 2900 | Time 20.1421(20.1413) | Bit/dim 3.6128(3.6038) | Xent 0.0000(0.0000) | Loss 3.6128(3.6038) | Error 0.0000(0.0000) Steps 814(811.57) | Grad Norm 1.5804(3.0690) | Total Time 14.00(14.00)\n",
      "Iter 2910 | Time 19.8335(20.1533) | Bit/dim 3.5946(3.6029) | Xent 0.0000(0.0000) | Loss 3.5946(3.6029) | Error 0.0000(0.0000) Steps 802(810.77) | Grad Norm 6.2178(3.1710) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 96.8412, Epoch Time 1222.0597(1105.0024), Bit/dim 3.6021(best: 3.6064), Xent 0.0000, Loss 3.6021, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2920 | Time 19.5801(20.0922) | Bit/dim 3.6027(3.6040) | Xent 0.0000(0.0000) | Loss 3.6027(3.6040) | Error 0.0000(0.0000) Steps 802(809.51) | Grad Norm 2.4563(3.1573) | Total Time 14.00(14.00)\n",
      "Iter 2930 | Time 20.2393(20.1026) | Bit/dim 3.6016(3.6048) | Xent 0.0000(0.0000) | Loss 3.6016(3.6048) | Error 0.0000(0.0000) Steps 790(808.25) | Grad Norm 3.3109(3.0630) | Total Time 14.00(14.00)\n",
      "Iter 2940 | Time 20.0919(20.0822) | Bit/dim 3.5984(3.6038) | Xent 0.0000(0.0000) | Loss 3.5984(3.6038) | Error 0.0000(0.0000) Steps 814(808.38) | Grad Norm 2.3857(3.0303) | Total Time 14.00(14.00)\n",
      "Iter 2950 | Time 19.4570(20.0206) | Bit/dim 3.6083(3.6029) | Xent 0.0000(0.0000) | Loss 3.6083(3.6029) | Error 0.0000(0.0000) Steps 808(807.81) | Grad Norm 1.7791(3.2159) | Total Time 14.00(14.00)\n",
      "Iter 2960 | Time 19.7577(20.0251) | Bit/dim 3.5701(3.5999) | Xent 0.0000(0.0000) | Loss 3.5701(3.5999) | Error 0.0000(0.0000) Steps 808(809.06) | Grad Norm 2.0434(3.0496) | Total Time 14.00(14.00)\n",
      "Iter 2970 | Time 19.9292(20.0116) | Bit/dim 3.6093(3.5969) | Xent 0.0000(0.0000) | Loss 3.6093(3.5969) | Error 0.0000(0.0000) Steps 814(808.61) | Grad Norm 3.5878(3.2941) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 96.6313, Epoch Time 1213.9349(1108.2704), Bit/dim 3.6030(best: 3.6021), Xent 0.0000, Loss 3.6030, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2980 | Time 19.3746(19.9750) | Bit/dim 3.6085(3.5983) | Xent 0.0000(0.0000) | Loss 3.6085(3.5983) | Error 0.0000(0.0000) Steps 790(806.95) | Grad Norm 3.3279(3.1277) | Total Time 14.00(14.00)\n",
      "Iter 2990 | Time 19.6196(20.0281) | Bit/dim 3.6037(3.5967) | Xent 0.0000(0.0000) | Loss 3.6037(3.5967) | Error 0.0000(0.0000) Steps 802(806.64) | Grad Norm 1.9433(3.0328) | Total Time 14.00(14.00)\n",
      "Iter 3000 | Time 19.5130(20.0554) | Bit/dim 3.6078(3.5962) | Xent 0.0000(0.0000) | Loss 3.6078(3.5962) | Error 0.0000(0.0000) Steps 808(807.49) | Grad Norm 5.1926(3.1446) | Total Time 14.00(14.00)\n",
      "Iter 3010 | Time 20.2340(20.0411) | Bit/dim 3.6103(3.5946) | Xent 0.0000(0.0000) | Loss 3.6103(3.5946) | Error 0.0000(0.0000) Steps 802(807.71) | Grad Norm 3.3629(3.2115) | Total Time 14.00(14.00)\n",
      "Iter 3020 | Time 19.9552(20.0086) | Bit/dim 3.5792(3.5934) | Xent 0.0000(0.0000) | Loss 3.5792(3.5934) | Error 0.0000(0.0000) Steps 802(806.18) | Grad Norm 3.6326(3.0627) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 96.4854, Epoch Time 1215.9832(1111.5018), Bit/dim 3.5910(best: 3.6021), Xent 0.0000, Loss 3.5910, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3030 | Time 20.1774(20.0032) | Bit/dim 3.5856(3.5931) | Xent 0.0000(0.0000) | Loss 3.5856(3.5931) | Error 0.0000(0.0000) Steps 808(805.86) | Grad Norm 2.9672(3.1035) | Total Time 14.00(14.00)\n",
      "Iter 3040 | Time 19.8998(19.9641) | Bit/dim 3.5789(3.5935) | Xent 0.0000(0.0000) | Loss 3.5789(3.5935) | Error 0.0000(0.0000) Steps 790(805.34) | Grad Norm 2.8325(3.2252) | Total Time 14.00(14.00)\n",
      "Iter 3050 | Time 20.6012(19.9216) | Bit/dim 3.6172(3.5954) | Xent 0.0000(0.0000) | Loss 3.6172(3.5954) | Error 0.0000(0.0000) Steps 802(804.50) | Grad Norm 2.0115(3.0977) | Total Time 14.00(14.00)\n",
      "Iter 3060 | Time 20.1713(19.9855) | Bit/dim 3.5901(3.5932) | Xent 0.0000(0.0000) | Loss 3.5901(3.5932) | Error 0.0000(0.0000) Steps 814(804.67) | Grad Norm 3.2171(3.0131) | Total Time 14.00(14.00)\n",
      "Iter 3070 | Time 20.1537(20.0611) | Bit/dim 3.5907(3.5909) | Xent 0.0000(0.0000) | Loss 3.5907(3.5909) | Error 0.0000(0.0000) Steps 802(806.76) | Grad Norm 2.0363(2.9590) | Total Time 14.00(14.00)\n",
      "Iter 3080 | Time 20.2796(20.1000) | Bit/dim 3.5793(3.5881) | Xent 0.0000(0.0000) | Loss 3.5793(3.5881) | Error 0.0000(0.0000) Steps 814(807.10) | Grad Norm 1.2234(2.5915) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 96.4919, Epoch Time 1216.8908(1114.6635), Bit/dim 3.5844(best: 3.5910), Xent 0.0000, Loss 3.5844, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3090 | Time 19.7440(20.0443) | Bit/dim 3.5490(3.5892) | Xent 0.0000(0.0000) | Loss 3.5490(3.5892) | Error 0.0000(0.0000) Steps 802(807.17) | Grad Norm 5.3936(3.1028) | Total Time 14.00(14.00)\n",
      "Iter 3100 | Time 19.8665(20.0348) | Bit/dim 3.5889(3.5901) | Xent 0.0000(0.0000) | Loss 3.5889(3.5901) | Error 0.0000(0.0000) Steps 802(806.69) | Grad Norm 2.1473(2.9520) | Total Time 14.00(14.00)\n",
      "Iter 3110 | Time 19.6575(19.9983) | Bit/dim 3.6135(3.5892) | Xent 0.0000(0.0000) | Loss 3.6135(3.5892) | Error 0.0000(0.0000) Steps 796(805.70) | Grad Norm 2.1107(2.9309) | Total Time 14.00(14.00)\n",
      "Iter 3120 | Time 20.2445(20.0014) | Bit/dim 3.5700(3.5870) | Xent 0.0000(0.0000) | Loss 3.5700(3.5870) | Error 0.0000(0.0000) Steps 802(805.80) | Grad Norm 2.7155(2.8152) | Total Time 14.00(14.00)\n",
      "Iter 3130 | Time 19.8569(19.9578) | Bit/dim 3.5797(3.5870) | Xent 0.0000(0.0000) | Loss 3.5797(3.5870) | Error 0.0000(0.0000) Steps 802(805.20) | Grad Norm 3.1798(2.9113) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 96.5011, Epoch Time 1210.1071(1117.5268), Bit/dim 3.5866(best: 3.5844), Xent 0.0000, Loss 3.5866, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3140 | Time 20.0566(19.9425) | Bit/dim 3.5922(3.5891) | Xent 0.0000(0.0000) | Loss 3.5922(3.5891) | Error 0.0000(0.0000) Steps 814(806.22) | Grad Norm 1.5763(3.0971) | Total Time 14.00(14.00)\n",
      "Iter 3150 | Time 20.8110(19.9221) | Bit/dim 3.5834(3.5894) | Xent 0.0000(0.0000) | Loss 3.5834(3.5894) | Error 0.0000(0.0000) Steps 808(804.86) | Grad Norm 3.5815(3.1278) | Total Time 14.00(14.00)\n",
      "Iter 3160 | Time 20.1337(19.9565) | Bit/dim 3.5716(3.5889) | Xent 0.0000(0.0000) | Loss 3.5716(3.5889) | Error 0.0000(0.0000) Steps 802(805.14) | Grad Norm 1.9186(2.8540) | Total Time 14.00(14.00)\n",
      "Iter 3170 | Time 20.1792(19.9711) | Bit/dim 3.5794(3.5848) | Xent 0.0000(0.0000) | Loss 3.5794(3.5848) | Error 0.0000(0.0000) Steps 802(805.65) | Grad Norm 2.6022(3.0215) | Total Time 14.00(14.00)\n",
      "Iter 3180 | Time 19.1527(19.9528) | Bit/dim 3.5791(3.5850) | Xent 0.0000(0.0000) | Loss 3.5791(3.5850) | Error 0.0000(0.0000) Steps 820(805.65) | Grad Norm 3.6524(2.9321) | Total Time 14.00(14.00)\n",
      "Iter 3190 | Time 19.3798(19.8885) | Bit/dim 3.5734(3.5819) | Xent 0.0000(0.0000) | Loss 3.5734(3.5819) | Error 0.0000(0.0000) Steps 808(806.00) | Grad Norm 2.2504(3.1013) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 96.8403, Epoch Time 1209.1940(1120.2768), Bit/dim 3.5854(best: 3.5844), Xent 0.0000, Loss 3.5854, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3200 | Time 18.7353(19.8559) | Bit/dim 3.5834(3.5831) | Xent 0.0000(0.0000) | Loss 3.5834(3.5831) | Error 0.0000(0.0000) Steps 790(806.46) | Grad Norm 2.5589(3.0597) | Total Time 14.00(14.00)\n",
      "Iter 3210 | Time 19.6369(19.8058) | Bit/dim 3.6120(3.5814) | Xent 0.0000(0.0000) | Loss 3.6120(3.5814) | Error 0.0000(0.0000) Steps 808(806.24) | Grad Norm 3.9380(2.9223) | Total Time 14.00(14.00)\n",
      "Iter 3220 | Time 19.5562(19.7868) | Bit/dim 3.5968(3.5804) | Xent 0.0000(0.0000) | Loss 3.5968(3.5804) | Error 0.0000(0.0000) Steps 802(806.04) | Grad Norm 3.4162(3.1961) | Total Time 14.00(14.00)\n",
      "Iter 3230 | Time 19.8180(19.7958) | Bit/dim 3.5779(3.5807) | Xent 0.0000(0.0000) | Loss 3.5779(3.5807) | Error 0.0000(0.0000) Steps 790(805.65) | Grad Norm 2.8815(3.3669) | Total Time 14.00(14.00)\n",
      "Iter 3240 | Time 19.8032(19.7532) | Bit/dim 3.5754(3.5809) | Xent 0.0000(0.0000) | Loss 3.5754(3.5809) | Error 0.0000(0.0000) Steps 808(806.34) | Grad Norm 3.4590(3.3484) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 98.4153, Epoch Time 1201.7625(1122.7214), Bit/dim 3.5808(best: 3.5844), Xent 0.0000, Loss 3.5808, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3250 | Time 19.6848(19.7727) | Bit/dim 3.5510(3.5797) | Xent 0.0000(0.0000) | Loss 3.5510(3.5797) | Error 0.0000(0.0000) Steps 808(807.18) | Grad Norm 3.0025(3.2524) | Total Time 14.00(14.00)\n",
      "Iter 3260 | Time 20.2659(19.8016) | Bit/dim 3.5669(3.5799) | Xent 0.0000(0.0000) | Loss 3.5669(3.5799) | Error 0.0000(0.0000) Steps 820(807.62) | Grad Norm 1.5796(3.1774) | Total Time 14.00(14.00)\n",
      "Iter 3270 | Time 20.0619(19.7804) | Bit/dim 3.5553(3.5800) | Xent 0.0000(0.0000) | Loss 3.5553(3.5800) | Error 0.0000(0.0000) Steps 820(806.38) | Grad Norm 2.2505(2.9828) | Total Time 14.00(14.00)\n",
      "Iter 3280 | Time 19.3111(19.7321) | Bit/dim 3.5704(3.5787) | Xent 0.0000(0.0000) | Loss 3.5704(3.5787) | Error 0.0000(0.0000) Steps 796(806.58) | Grad Norm 2.1190(2.6779) | Total Time 14.00(14.00)\n",
      "Iter 3290 | Time 19.7653(19.7325) | Bit/dim 3.5786(3.5771) | Xent 0.0000(0.0000) | Loss 3.5786(3.5771) | Error 0.0000(0.0000) Steps 808(806.56) | Grad Norm 1.7907(2.7113) | Total Time 14.00(14.00)\n",
      "Iter 3300 | Time 19.4747(19.7683) | Bit/dim 3.5915(3.5758) | Xent 0.0000(0.0000) | Loss 3.5915(3.5758) | Error 0.0000(0.0000) Steps 796(805.67) | Grad Norm 3.3450(2.9390) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 97.1804, Epoch Time 1202.1874(1125.1053), Bit/dim 3.5782(best: 3.5808), Xent 0.0000, Loss 3.5782, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3310 | Time 19.9437(19.7370) | Bit/dim 3.5524(3.5751) | Xent 0.0000(0.0000) | Loss 3.5524(3.5751) | Error 0.0000(0.0000) Steps 808(805.76) | Grad Norm 1.7426(2.7513) | Total Time 14.00(14.00)\n",
      "Iter 3320 | Time 20.2634(19.7900) | Bit/dim 3.5554(3.5733) | Xent 0.0000(0.0000) | Loss 3.5554(3.5733) | Error 0.0000(0.0000) Steps 826(807.20) | Grad Norm 2.7371(2.6489) | Total Time 14.00(14.00)\n",
      "Iter 3330 | Time 19.3304(19.8272) | Bit/dim 3.5835(3.5747) | Xent 0.0000(0.0000) | Loss 3.5835(3.5747) | Error 0.0000(0.0000) Steps 802(807.28) | Grad Norm 3.2474(2.8658) | Total Time 14.00(14.00)\n",
      "Iter 3340 | Time 19.5845(19.8735) | Bit/dim 3.5345(3.5738) | Xent 0.0000(0.0000) | Loss 3.5345(3.5738) | Error 0.0000(0.0000) Steps 808(806.90) | Grad Norm 3.0216(2.7456) | Total Time 14.00(14.00)\n",
      "Iter 3350 | Time 19.9485(19.8375) | Bit/dim 3.5616(3.5722) | Xent 0.0000(0.0000) | Loss 3.5616(3.5722) | Error 0.0000(0.0000) Steps 802(807.02) | Grad Norm 2.6603(3.0605) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 97.5530, Epoch Time 1206.8233(1127.5569), Bit/dim 3.5726(best: 3.5782), Xent 0.0000, Loss 3.5726, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3360 | Time 19.7376(19.8306) | Bit/dim 3.5547(3.5747) | Xent 0.0000(0.0000) | Loss 3.5547(3.5747) | Error 0.0000(0.0000) Steps 808(808.13) | Grad Norm 3.1319(3.0282) | Total Time 14.00(14.00)\n",
      "Iter 3370 | Time 20.3102(19.8618) | Bit/dim 3.5373(3.5729) | Xent 0.0000(0.0000) | Loss 3.5373(3.5729) | Error 0.0000(0.0000) Steps 820(809.65) | Grad Norm 1.6763(2.8798) | Total Time 14.00(14.00)\n",
      "Iter 3380 | Time 20.1365(19.8803) | Bit/dim 3.5964(3.5714) | Xent 0.0000(0.0000) | Loss 3.5964(3.5714) | Error 0.0000(0.0000) Steps 808(809.79) | Grad Norm 4.7959(2.9981) | Total Time 14.00(14.00)\n",
      "Iter 3390 | Time 19.8624(19.8828) | Bit/dim 3.5742(3.5728) | Xent 0.0000(0.0000) | Loss 3.5742(3.5728) | Error 0.0000(0.0000) Steps 826(811.69) | Grad Norm 2.1118(2.8950) | Total Time 14.00(14.00)\n",
      "Iter 3400 | Time 20.0155(19.8991) | Bit/dim 3.5662(3.5709) | Xent 0.0000(0.0000) | Loss 3.5662(3.5709) | Error 0.0000(0.0000) Steps 808(811.00) | Grad Norm 1.9253(2.8783) | Total Time 14.00(14.00)\n",
      "Iter 3410 | Time 20.4634(19.8638) | Bit/dim 3.5667(3.5685) | Xent 0.0000(0.0000) | Loss 3.5667(3.5685) | Error 0.0000(0.0000) Steps 802(810.66) | Grad Norm 1.6856(2.7346) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 97.6682, Epoch Time 1208.8501(1129.9957), Bit/dim 3.5658(best: 3.5726), Xent 0.0000, Loss 3.5658, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3420 | Time 20.5125(19.8537) | Bit/dim 3.5557(3.5663) | Xent 0.0000(0.0000) | Loss 3.5557(3.5663) | Error 0.0000(0.0000) Steps 826(811.72) | Grad Norm 4.3901(2.6528) | Total Time 14.00(14.00)\n",
      "Iter 3430 | Time 19.8896(19.9329) | Bit/dim 3.5484(3.5674) | Xent 0.0000(0.0000) | Loss 3.5484(3.5674) | Error 0.0000(0.0000) Steps 814(813.61) | Grad Norm 1.5829(2.8119) | Total Time 14.00(14.00)\n",
      "Iter 3440 | Time 19.5458(19.9100) | Bit/dim 3.5431(3.5646) | Xent 0.0000(0.0000) | Loss 3.5431(3.5646) | Error 0.0000(0.0000) Steps 802(813.97) | Grad Norm 2.9640(2.8033) | Total Time 14.00(14.00)\n",
      "Iter 3450 | Time 20.4537(19.9596) | Bit/dim 3.5710(3.5654) | Xent 0.0000(0.0000) | Loss 3.5710(3.5654) | Error 0.0000(0.0000) Steps 820(814.53) | Grad Norm 1.8173(2.9103) | Total Time 14.00(14.00)\n",
      "Iter 3460 | Time 20.2800(20.0101) | Bit/dim 3.5763(3.5672) | Xent 0.0000(0.0000) | Loss 3.5763(3.5672) | Error 0.0000(0.0000) Steps 808(815.43) | Grad Norm 3.2418(3.0053) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 97.5585, Epoch Time 1215.7496(1132.5683), Bit/dim 3.5660(best: 3.5658), Xent 0.0000, Loss 3.5660, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3470 | Time 20.6177(19.9799) | Bit/dim 3.5530(3.5690) | Xent 0.0000(0.0000) | Loss 3.5530(3.5690) | Error 0.0000(0.0000) Steps 826(816.97) | Grad Norm 3.7665(2.9497) | Total Time 14.00(14.00)\n",
      "Iter 3480 | Time 19.7540(19.9171) | Bit/dim 3.5460(3.5675) | Xent 0.0000(0.0000) | Loss 3.5460(3.5675) | Error 0.0000(0.0000) Steps 814(815.65) | Grad Norm 4.5783(3.1005) | Total Time 14.00(14.00)\n",
      "Iter 3490 | Time 19.8603(19.9160) | Bit/dim 3.5931(3.5650) | Xent 0.0000(0.0000) | Loss 3.5931(3.5650) | Error 0.0000(0.0000) Steps 826(815.56) | Grad Norm 2.4427(3.0320) | Total Time 14.00(14.00)\n",
      "Iter 3500 | Time 19.5201(19.9117) | Bit/dim 3.5467(3.5630) | Xent 0.0000(0.0000) | Loss 3.5467(3.5630) | Error 0.0000(0.0000) Steps 814(815.83) | Grad Norm 1.6507(2.6895) | Total Time 14.00(14.00)\n",
      "Iter 3510 | Time 19.6882(19.9380) | Bit/dim 3.5862(3.5620) | Xent 0.0000(0.0000) | Loss 3.5862(3.5620) | Error 0.0000(0.0000) Steps 808(815.45) | Grad Norm 3.5293(2.7182) | Total Time 14.00(14.00)\n",
      "Iter 3520 | Time 19.2871(19.9033) | Bit/dim 3.5890(3.5648) | Xent 0.0000(0.0000) | Loss 3.5890(3.5648) | Error 0.0000(0.0000) Steps 802(813.44) | Grad Norm 3.7476(2.8861) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 97.7938, Epoch Time 1208.8300(1134.8561), Bit/dim 3.5674(best: 3.5658), Xent 0.0000, Loss 3.5674, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3530 | Time 20.0542(19.8960) | Bit/dim 3.5834(3.5628) | Xent 0.0000(0.0000) | Loss 3.5834(3.5628) | Error 0.0000(0.0000) Steps 808(815.16) | Grad Norm 3.4900(2.7937) | Total Time 14.00(14.00)\n",
      "Iter 3540 | Time 19.7457(19.9113) | Bit/dim 3.5494(3.5628) | Xent 0.0000(0.0000) | Loss 3.5494(3.5628) | Error 0.0000(0.0000) Steps 826(814.79) | Grad Norm 2.8364(2.7730) | Total Time 14.00(14.00)\n",
      "Iter 3550 | Time 20.4119(19.9275) | Bit/dim 3.5833(3.5630) | Xent 0.0000(0.0000) | Loss 3.5833(3.5630) | Error 0.0000(0.0000) Steps 826(816.09) | Grad Norm 2.9615(2.9163) | Total Time 14.00(14.00)\n",
      "Iter 3560 | Time 19.6246(19.8999) | Bit/dim 3.5312(3.5613) | Xent 0.0000(0.0000) | Loss 3.5312(3.5613) | Error 0.0000(0.0000) Steps 832(816.99) | Grad Norm 2.5556(2.8730) | Total Time 14.00(14.00)\n",
      "Iter 3570 | Time 19.9139(19.8998) | Bit/dim 3.5500(3.5621) | Xent 0.0000(0.0000) | Loss 3.5500(3.5621) | Error 0.0000(0.0000) Steps 820(819.88) | Grad Norm 2.7311(2.8983) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 97.0371, Epoch Time 1210.2430(1137.1177), Bit/dim 3.5642(best: 3.5658), Xent 0.0000, Loss 3.5642, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3580 | Time 19.1679(19.8729) | Bit/dim 3.5632(3.5620) | Xent 0.0000(0.0000) | Loss 3.5632(3.5620) | Error 0.0000(0.0000) Steps 814(820.45) | Grad Norm 3.1692(3.0171) | Total Time 14.00(14.00)\n",
      "Iter 3590 | Time 19.8964(19.8878) | Bit/dim 3.5797(3.5604) | Xent 0.0000(0.0000) | Loss 3.5797(3.5604) | Error 0.0000(0.0000) Steps 820(820.30) | Grad Norm 4.1746(3.0157) | Total Time 14.00(14.00)\n",
      "Iter 3600 | Time 20.7148(19.9058) | Bit/dim 3.5359(3.5591) | Xent 0.0000(0.0000) | Loss 3.5359(3.5591) | Error 0.0000(0.0000) Steps 808(820.31) | Grad Norm 3.7803(3.1602) | Total Time 14.00(14.00)\n",
      "Iter 3610 | Time 19.8009(19.9295) | Bit/dim 3.5557(3.5578) | Xent 0.0000(0.0000) | Loss 3.5557(3.5578) | Error 0.0000(0.0000) Steps 838(820.59) | Grad Norm 1.9448(3.0334) | Total Time 14.00(14.00)\n",
      "Iter 3620 | Time 20.1812(20.0428) | Bit/dim 3.5701(3.5579) | Xent 0.0000(0.0000) | Loss 3.5701(3.5579) | Error 0.0000(0.0000) Steps 802(822.12) | Grad Norm 2.1317(2.7439) | Total Time 14.00(14.00)\n",
      "Iter 3630 | Time 19.4965(20.0661) | Bit/dim 3.5753(3.5589) | Xent 0.0000(0.0000) | Loss 3.5753(3.5589) | Error 0.0000(0.0000) Steps 826(823.11) | Grad Norm 2.6653(2.8763) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 97.9005, Epoch Time 1217.4900(1139.5289), Bit/dim 3.5617(best: 3.5642), Xent 0.0000, Loss 3.5617, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3640 | Time 20.5487(20.0644) | Bit/dim 3.5708(3.5603) | Xent 0.0000(0.0000) | Loss 3.5708(3.5603) | Error 0.0000(0.0000) Steps 832(823.45) | Grad Norm 1.2417(2.9337) | Total Time 14.00(14.00)\n",
      "Iter 3650 | Time 20.5881(20.1342) | Bit/dim 3.6068(3.5596) | Xent 0.0000(0.0000) | Loss 3.6068(3.5596) | Error 0.0000(0.0000) Steps 808(822.80) | Grad Norm 3.6486(2.9175) | Total Time 14.00(14.00)\n",
      "Iter 3660 | Time 20.0607(20.0854) | Bit/dim 3.5593(3.5606) | Xent 0.0000(0.0000) | Loss 3.5593(3.5606) | Error 0.0000(0.0000) Steps 808(823.45) | Grad Norm 2.8171(2.8759) | Total Time 14.00(14.00)\n",
      "Iter 3670 | Time 19.5983(20.0761) | Bit/dim 3.5525(3.5565) | Xent 0.0000(0.0000) | Loss 3.5525(3.5565) | Error 0.0000(0.0000) Steps 832(824.40) | Grad Norm 2.1761(2.6961) | Total Time 14.00(14.00)\n",
      "Iter 3680 | Time 21.0215(20.1141) | Bit/dim 3.5293(3.5524) | Xent 0.0000(0.0000) | Loss 3.5293(3.5524) | Error 0.0000(0.0000) Steps 838(824.99) | Grad Norm 2.1852(2.8898) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 99.8138, Epoch Time 1224.3750(1142.0743), Bit/dim 3.5624(best: 3.5617), Xent 0.0000, Loss 3.5624, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3690 | Time 20.9752(20.1541) | Bit/dim 3.5391(3.5522) | Xent 0.0000(0.0000) | Loss 3.5391(3.5522) | Error 0.0000(0.0000) Steps 832(826.03) | Grad Norm 2.6007(2.8918) | Total Time 14.00(14.00)\n",
      "Iter 3700 | Time 20.2647(20.1852) | Bit/dim 3.5269(3.5508) | Xent 0.0000(0.0000) | Loss 3.5269(3.5508) | Error 0.0000(0.0000) Steps 826(825.43) | Grad Norm 4.8340(2.8755) | Total Time 14.00(14.00)\n",
      "Iter 3710 | Time 19.9404(20.1991) | Bit/dim 3.5867(3.5509) | Xent 0.0000(0.0000) | Loss 3.5867(3.5509) | Error 0.0000(0.0000) Steps 832(825.95) | Grad Norm 2.4384(2.9938) | Total Time 14.00(14.00)\n",
      "Iter 3720 | Time 20.6927(20.2140) | Bit/dim 3.5399(3.5506) | Xent 0.0000(0.0000) | Loss 3.5399(3.5506) | Error 0.0000(0.0000) Steps 844(826.46) | Grad Norm 2.5443(2.8661) | Total Time 14.00(14.00)\n",
      "Iter 3730 | Time 19.4523(20.1807) | Bit/dim 3.5562(3.5516) | Xent 0.0000(0.0000) | Loss 3.5562(3.5516) | Error 0.0000(0.0000) Steps 826(826.41) | Grad Norm 4.1142(2.8435) | Total Time 14.00(14.00)\n",
      "Iter 3740 | Time 20.3749(20.1748) | Bit/dim 3.5528(3.5529) | Xent 0.0000(0.0000) | Loss 3.5528(3.5529) | Error 0.0000(0.0000) Steps 820(827.19) | Grad Norm 3.8255(2.8710) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 99.0471, Epoch Time 1228.2861(1144.6607), Bit/dim 3.5573(best: 3.5617), Xent 0.0000, Loss 3.5573, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3750 | Time 19.9917(20.1683) | Bit/dim 3.5688(3.5514) | Xent 0.0000(0.0000) | Loss 3.5688(3.5514) | Error 0.0000(0.0000) Steps 820(827.76) | Grad Norm 2.0875(2.7947) | Total Time 14.00(14.00)\n",
      "Iter 3760 | Time 20.1144(20.1402) | Bit/dim 3.5795(3.5517) | Xent 0.0000(0.0000) | Loss 3.5795(3.5517) | Error 0.0000(0.0000) Steps 820(827.23) | Grad Norm 4.3294(2.8731) | Total Time 14.00(14.00)\n",
      "Iter 3770 | Time 19.5546(20.1260) | Bit/dim 3.5592(3.5509) | Xent 0.0000(0.0000) | Loss 3.5592(3.5509) | Error 0.0000(0.0000) Steps 826(826.98) | Grad Norm 1.9919(2.6885) | Total Time 14.00(14.00)\n",
      "Iter 3780 | Time 20.1537(20.1737) | Bit/dim 3.5972(3.5513) | Xent 0.0000(0.0000) | Loss 3.5972(3.5513) | Error 0.0000(0.0000) Steps 820(828.00) | Grad Norm 3.1544(2.8291) | Total Time 14.00(14.00)\n",
      "Iter 3790 | Time 20.0588(20.1622) | Bit/dim 3.5419(3.5519) | Xent 0.0000(0.0000) | Loss 3.5419(3.5519) | Error 0.0000(0.0000) Steps 838(828.71) | Grad Norm 2.2127(2.7885) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 98.9936, Epoch Time 1225.7560(1147.0935), Bit/dim 3.5525(best: 3.5573), Xent 0.0000, Loss 3.5525, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3800 | Time 19.4550(20.1701) | Bit/dim 3.5387(3.5497) | Xent 0.0000(0.0000) | Loss 3.5387(3.5497) | Error 0.0000(0.0000) Steps 820(828.50) | Grad Norm 2.8484(2.8930) | Total Time 14.00(14.00)\n",
      "Iter 3810 | Time 20.3191(20.1801) | Bit/dim 3.5392(3.5475) | Xent 0.0000(0.0000) | Loss 3.5392(3.5475) | Error 0.0000(0.0000) Steps 826(827.73) | Grad Norm 2.6679(2.9495) | Total Time 14.00(14.00)\n",
      "Iter 3820 | Time 20.4261(20.2070) | Bit/dim 3.5832(3.5463) | Xent 0.0000(0.0000) | Loss 3.5832(3.5463) | Error 0.0000(0.0000) Steps 838(826.93) | Grad Norm 3.9582(3.0516) | Total Time 14.00(14.00)\n",
      "Iter 3830 | Time 20.4007(20.1636) | Bit/dim 3.5565(3.5478) | Xent 0.0000(0.0000) | Loss 3.5565(3.5478) | Error 0.0000(0.0000) Steps 838(827.25) | Grad Norm 1.6914(2.9295) | Total Time 14.00(14.00)\n",
      "Iter 3840 | Time 20.4490(20.1467) | Bit/dim 3.5768(3.5479) | Xent 0.0000(0.0000) | Loss 3.5768(3.5479) | Error 0.0000(0.0000) Steps 814(827.10) | Grad Norm 2.1074(2.8603) | Total Time 14.00(14.00)\n",
      "Iter 3850 | Time 19.9853(20.1109) | Bit/dim 3.5205(3.5474) | Xent 0.0000(0.0000) | Loss 3.5205(3.5474) | Error 0.0000(0.0000) Steps 820(826.96) | Grad Norm 2.9604(2.7684) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 99.1451, Epoch Time 1223.8207(1149.3953), Bit/dim 3.5465(best: 3.5525), Xent 0.0000, Loss 3.5465, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3860 | Time 19.9945(20.1590) | Bit/dim 3.5547(3.5462) | Xent 0.0000(0.0000) | Loss 3.5547(3.5462) | Error 0.0000(0.0000) Steps 814(827.32) | Grad Norm 2.2205(2.7618) | Total Time 14.00(14.00)\n",
      "Iter 3870 | Time 21.2350(20.2212) | Bit/dim 3.5386(3.5458) | Xent 0.0000(0.0000) | Loss 3.5386(3.5458) | Error 0.0000(0.0000) Steps 814(827.22) | Grad Norm 3.9058(2.8843) | Total Time 14.00(14.00)\n",
      "Iter 3880 | Time 19.8859(20.1845) | Bit/dim 3.5169(3.5437) | Xent 0.0000(0.0000) | Loss 3.5169(3.5437) | Error 0.0000(0.0000) Steps 832(827.66) | Grad Norm 2.5458(2.8260) | Total Time 14.00(14.00)\n",
      "Iter 3890 | Time 19.4022(20.1478) | Bit/dim 3.5403(3.5431) | Xent 0.0000(0.0000) | Loss 3.5403(3.5431) | Error 0.0000(0.0000) Steps 820(826.50) | Grad Norm 1.7607(2.7210) | Total Time 14.00(14.00)\n",
      "Iter 3900 | Time 20.1199(20.1123) | Bit/dim 3.5179(3.5449) | Xent 0.0000(0.0000) | Loss 3.5179(3.5449) | Error 0.0000(0.0000) Steps 832(828.69) | Grad Norm 1.4334(2.6134) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 98.2203, Epoch Time 1224.9583(1151.6622), Bit/dim 3.5491(best: 3.5465), Xent 0.0000, Loss 3.5491, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3910 | Time 19.6746(20.1133) | Bit/dim 3.5300(3.5432) | Xent 0.0000(0.0000) | Loss 3.5300(3.5432) | Error 0.0000(0.0000) Steps 826(829.55) | Grad Norm 3.3382(2.8645) | Total Time 14.00(14.00)\n",
      "Iter 3920 | Time 20.3968(20.1483) | Bit/dim 3.5278(3.5414) | Xent 0.0000(0.0000) | Loss 3.5278(3.5414) | Error 0.0000(0.0000) Steps 826(830.19) | Grad Norm 2.8297(2.8183) | Total Time 14.00(14.00)\n",
      "Iter 3930 | Time 20.2394(20.2005) | Bit/dim 3.5499(3.5431) | Xent 0.0000(0.0000) | Loss 3.5499(3.5431) | Error 0.0000(0.0000) Steps 838(829.94) | Grad Norm 2.8562(2.7472) | Total Time 14.00(14.00)\n",
      "Iter 3940 | Time 20.1146(20.2561) | Bit/dim 3.5259(3.5423) | Xent 0.0000(0.0000) | Loss 3.5259(3.5423) | Error 0.0000(0.0000) Steps 844(831.20) | Grad Norm 2.4531(2.5666) | Total Time 14.00(14.00)\n",
      "Iter 3950 | Time 20.3810(20.2955) | Bit/dim 3.4924(3.5417) | Xent 0.0000(0.0000) | Loss 3.4924(3.5417) | Error 0.0000(0.0000) Steps 844(831.18) | Grad Norm 2.3098(2.7330) | Total Time 14.00(14.00)\n",
      "Iter 3960 | Time 19.8724(20.2774) | Bit/dim 3.5404(3.5414) | Xent 0.0000(0.0000) | Loss 3.5404(3.5414) | Error 0.0000(0.0000) Steps 832(832.04) | Grad Norm 2.3597(2.6220) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 98.7209, Epoch Time 1233.4888(1154.1170), Bit/dim 3.5383(best: 3.5465), Xent 0.0000, Loss 3.5383, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3970 | Time 19.7159(20.2436) | Bit/dim 3.5499(3.5418) | Xent 0.0000(0.0000) | Loss 3.5499(3.5418) | Error 0.0000(0.0000) Steps 832(830.45) | Grad Norm 4.1519(2.6460) | Total Time 14.00(14.00)\n",
      "Iter 3980 | Time 20.0539(20.2767) | Bit/dim 3.5457(3.5402) | Xent 0.0000(0.0000) | Loss 3.5457(3.5402) | Error 0.0000(0.0000) Steps 820(830.99) | Grad Norm 3.5607(2.6287) | Total Time 14.00(14.00)\n",
      "Iter 3990 | Time 20.1250(20.2447) | Bit/dim 3.5468(3.5387) | Xent 0.0000(0.0000) | Loss 3.5468(3.5387) | Error 0.0000(0.0000) Steps 820(830.02) | Grad Norm 1.8420(2.7244) | Total Time 14.00(14.00)\n",
      "Iter 4000 | Time 19.9970(20.2322) | Bit/dim 3.5430(3.5390) | Xent 0.0000(0.0000) | Loss 3.5430(3.5390) | Error 0.0000(0.0000) Steps 838(829.77) | Grad Norm 3.6287(2.8610) | Total Time 14.00(14.00)\n",
      "Iter 4010 | Time 19.8261(20.1888) | Bit/dim 3.5565(3.5392) | Xent 0.0000(0.0000) | Loss 3.5565(3.5392) | Error 0.0000(0.0000) Steps 820(829.92) | Grad Norm 1.9784(2.8813) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 100.0262, Epoch Time 1228.9319(1156.3615), Bit/dim 3.5374(best: 3.5383), Xent 0.0000, Loss 3.5374, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4020 | Time 20.6246(20.2048) | Bit/dim 3.5381(3.5363) | Xent 0.0000(0.0000) | Loss 3.5381(3.5363) | Error 0.0000(0.0000) Steps 820(830.45) | Grad Norm 4.5665(2.8818) | Total Time 14.00(14.00)\n",
      "Iter 4030 | Time 20.0330(20.1536) | Bit/dim 3.5450(3.5394) | Xent 0.0000(0.0000) | Loss 3.5450(3.5394) | Error 0.0000(0.0000) Steps 844(830.74) | Grad Norm 2.1959(2.8833) | Total Time 14.00(14.00)\n",
      "Iter 4040 | Time 20.2289(20.1680) | Bit/dim 3.5135(3.5403) | Xent 0.0000(0.0000) | Loss 3.5135(3.5403) | Error 0.0000(0.0000) Steps 826(831.51) | Grad Norm 2.6827(2.8141) | Total Time 14.00(14.00)\n",
      "Iter 4050 | Time 20.2928(20.2457) | Bit/dim 3.5282(3.5381) | Xent 0.0000(0.0000) | Loss 3.5282(3.5381) | Error 0.0000(0.0000) Steps 832(831.08) | Grad Norm 2.4730(2.7756) | Total Time 14.00(14.00)\n",
      "Iter 4060 | Time 19.5447(20.3014) | Bit/dim 3.5579(3.5363) | Xent 0.0000(0.0000) | Loss 3.5579(3.5363) | Error 0.0000(0.0000) Steps 814(833.11) | Grad Norm 2.4427(2.9345) | Total Time 14.00(14.00)\n",
      "Iter 4070 | Time 19.4638(20.2656) | Bit/dim 3.5497(3.5355) | Xent 0.0000(0.0000) | Loss 3.5497(3.5355) | Error 0.0000(0.0000) Steps 832(834.09) | Grad Norm 2.9300(2.7803) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 100.7766, Epoch Time 1233.0475(1158.6620), Bit/dim 3.5346(best: 3.5374), Xent 0.0000, Loss 3.5346, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4080 | Time 19.8671(20.3386) | Bit/dim 3.5060(3.5362) | Xent 0.0000(0.0000) | Loss 3.5060(3.5362) | Error 0.0000(0.0000) Steps 826(833.87) | Grad Norm 4.3820(2.8457) | Total Time 14.00(14.00)\n",
      "Iter 4090 | Time 21.1314(20.4867) | Bit/dim 3.5333(3.5345) | Xent 0.0000(0.0000) | Loss 3.5333(3.5345) | Error 0.0000(0.0000) Steps 850(834.91) | Grad Norm 3.3959(2.7694) | Total Time 14.00(14.00)\n",
      "Iter 4100 | Time 20.4090(20.4438) | Bit/dim 3.5002(3.5338) | Xent 0.0000(0.0000) | Loss 3.5002(3.5338) | Error 0.0000(0.0000) Steps 844(835.80) | Grad Norm 2.8442(2.7305) | Total Time 14.00(14.00)\n",
      "Iter 4110 | Time 20.3970(20.3893) | Bit/dim 3.5601(3.5341) | Xent 0.0000(0.0000) | Loss 3.5601(3.5341) | Error 0.0000(0.0000) Steps 850(836.84) | Grad Norm 1.8730(2.7642) | Total Time 14.00(14.00)\n",
      "Iter 4120 | Time 20.6718(20.4139) | Bit/dim 3.5264(3.5322) | Xent 0.0000(0.0000) | Loss 3.5264(3.5322) | Error 0.0000(0.0000) Steps 850(837.14) | Grad Norm 3.1115(2.8334) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 100.5587, Epoch Time 1244.4295(1161.2351), Bit/dim 3.5336(best: 3.5346), Xent 0.0000, Loss 3.5336, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4130 | Time 20.7980(20.4339) | Bit/dim 3.5363(3.5320) | Xent 0.0000(0.0000) | Loss 3.5363(3.5320) | Error 0.0000(0.0000) Steps 844(837.55) | Grad Norm 2.9833(2.8613) | Total Time 14.00(14.00)\n",
      "Iter 4140 | Time 20.6910(20.4794) | Bit/dim 3.5275(3.5311) | Xent 0.0000(0.0000) | Loss 3.5275(3.5311) | Error 0.0000(0.0000) Steps 856(839.40) | Grad Norm 3.4889(2.8823) | Total Time 14.00(14.00)\n",
      "Iter 4150 | Time 20.0066(20.5394) | Bit/dim 3.5038(3.5301) | Xent 0.0000(0.0000) | Loss 3.5038(3.5301) | Error 0.0000(0.0000) Steps 850(841.23) | Grad Norm 3.1860(2.7777) | Total Time 14.00(14.00)\n",
      "Iter 4160 | Time 20.1436(20.5567) | Bit/dim 3.5271(3.5302) | Xent 0.0000(0.0000) | Loss 3.5271(3.5302) | Error 0.0000(0.0000) Steps 850(842.52) | Grad Norm 2.1029(2.6267) | Total Time 14.00(14.00)\n",
      "Iter 4170 | Time 20.8608(20.5824) | Bit/dim 3.5190(3.5289) | Xent 0.0000(0.0000) | Loss 3.5190(3.5289) | Error 0.0000(0.0000) Steps 832(840.32) | Grad Norm 1.7789(2.4795) | Total Time 14.00(14.00)\n",
      "Iter 4180 | Time 19.5105(20.6259) | Bit/dim 3.5489(3.5312) | Xent 0.0000(0.0000) | Loss 3.5489(3.5312) | Error 0.0000(0.0000) Steps 832(838.35) | Grad Norm 2.4370(2.6113) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 100.7393, Epoch Time 1255.3992(1164.0600), Bit/dim 3.5260(best: 3.5336), Xent 0.0000, Loss 3.5260, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4190 | Time 21.3606(20.6257) | Bit/dim 3.5020(3.5296) | Xent 0.0000(0.0000) | Loss 3.5020(3.5296) | Error 0.0000(0.0000) Steps 838(838.10) | Grad Norm 2.5832(2.5717) | Total Time 14.00(14.00)\n",
      "Iter 4200 | Time 21.0661(20.5663) | Bit/dim 3.5009(3.5295) | Xent 0.0000(0.0000) | Loss 3.5009(3.5295) | Error 0.0000(0.0000) Steps 862(837.70) | Grad Norm 4.1936(2.6255) | Total Time 14.00(14.00)\n",
      "Iter 4210 | Time 20.1811(20.5772) | Bit/dim 3.5025(3.5273) | Xent 0.0000(0.0000) | Loss 3.5025(3.5273) | Error 0.0000(0.0000) Steps 832(838.64) | Grad Norm 3.6042(2.7318) | Total Time 14.00(14.00)\n",
      "Iter 4220 | Time 20.4265(20.5886) | Bit/dim 3.5122(3.5276) | Xent 0.0000(0.0000) | Loss 3.5122(3.5276) | Error 0.0000(0.0000) Steps 844(837.65) | Grad Norm 2.9049(2.7189) | Total Time 14.00(14.00)\n",
      "Iter 4230 | Time 20.7533(20.5675) | Bit/dim 3.5464(3.5274) | Xent 0.0000(0.0000) | Loss 3.5464(3.5274) | Error 0.0000(0.0000) Steps 832(838.11) | Grad Norm 4.3773(2.8073) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 100.8828, Epoch Time 1247.9909(1166.5779), Bit/dim 3.5281(best: 3.5260), Xent 0.0000, Loss 3.5281, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4240 | Time 19.9598(20.5250) | Bit/dim 3.5045(3.5281) | Xent 0.0000(0.0000) | Loss 3.5045(3.5281) | Error 0.0000(0.0000) Steps 838(840.10) | Grad Norm 3.0208(2.7494) | Total Time 14.00(14.00)\n",
      "Iter 4250 | Time 20.7630(20.5410) | Bit/dim 3.5339(3.5297) | Xent 0.0000(0.0000) | Loss 3.5339(3.5297) | Error 0.0000(0.0000) Steps 856(840.07) | Grad Norm 1.7742(2.9072) | Total Time 14.00(14.00)\n",
      "Iter 4260 | Time 21.3306(20.5283) | Bit/dim 3.5315(3.5306) | Xent 0.0000(0.0000) | Loss 3.5315(3.5306) | Error 0.0000(0.0000) Steps 820(840.38) | Grad Norm 2.2204(2.8348) | Total Time 14.00(14.00)\n",
      "Iter 4270 | Time 19.8769(20.4287) | Bit/dim 3.4973(3.5279) | Xent 0.0000(0.0000) | Loss 3.4973(3.5279) | Error 0.0000(0.0000) Steps 832(839.40) | Grad Norm 2.6543(2.7110) | Total Time 14.00(14.00)\n",
      "Iter 4280 | Time 21.0744(20.4930) | Bit/dim 3.5351(3.5270) | Xent 0.0000(0.0000) | Loss 3.5351(3.5270) | Error 0.0000(0.0000) Steps 844(841.06) | Grad Norm 3.9437(2.6914) | Total Time 14.00(14.00)\n",
      "Iter 4290 | Time 21.1094(20.4702) | Bit/dim 3.4981(3.5236) | Xent 0.0000(0.0000) | Loss 3.4981(3.5236) | Error 0.0000(0.0000) Steps 832(839.69) | Grad Norm 1.8060(2.6646) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 100.2446, Epoch Time 1242.6098(1168.8589), Bit/dim 3.5217(best: 3.5260), Xent 0.0000, Loss 3.5217, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4300 | Time 19.9720(20.4565) | Bit/dim 3.5468(3.5226) | Xent 0.0000(0.0000) | Loss 3.5468(3.5226) | Error 0.0000(0.0000) Steps 838(840.34) | Grad Norm 1.9322(2.4123) | Total Time 14.00(14.00)\n",
      "Iter 4310 | Time 20.9098(20.4236) | Bit/dim 3.5153(3.5204) | Xent 0.0000(0.0000) | Loss 3.5153(3.5204) | Error 0.0000(0.0000) Steps 826(839.89) | Grad Norm 3.0450(2.4883) | Total Time 14.00(14.00)\n",
      "Iter 4330 | Time 20.3493(20.4904) | Bit/dim 3.5514(3.5258) | Xent 0.0000(0.0000) | Loss 3.5514(3.5258) | Error 0.0000(0.0000) Steps 826(841.37) | Grad Norm 1.9568(2.8250) | Total Time 14.00(14.00)\n",
      "Iter 4340 | Time 20.2337(20.4562) | Bit/dim 3.5230(3.5247) | Xent 0.0000(0.0000) | Loss 3.5230(3.5247) | Error 0.0000(0.0000) Steps 844(840.09) | Grad Norm 1.9226(2.6936) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 101.4630, Epoch Time 1245.3839(1171.1546), Bit/dim 3.5258(best: 3.5217), Xent 0.0000, Loss 3.5258, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4350 | Time 19.7930(20.4687) | Bit/dim 3.5367(3.5236) | Xent 0.0000(0.0000) | Loss 3.5367(3.5236) | Error 0.0000(0.0000) Steps 826(842.55) | Grad Norm 3.3736(2.7158) | Total Time 14.00(14.00)\n",
      "Iter 4360 | Time 20.3370(20.4515) | Bit/dim 3.5250(3.5246) | Xent 0.0000(0.0000) | Loss 3.5250(3.5246) | Error 0.0000(0.0000) Steps 844(842.70) | Grad Norm 2.3440(2.8791) | Total Time 14.00(14.00)\n",
      "Iter 4370 | Time 20.4954(20.5221) | Bit/dim 3.5168(3.5250) | Xent 0.0000(0.0000) | Loss 3.5168(3.5250) | Error 0.0000(0.0000) Steps 844(843.88) | Grad Norm 2.8388(2.8894) | Total Time 14.00(14.00)\n",
      "Iter 4380 | Time 21.0514(20.5507) | Bit/dim 3.5252(3.5232) | Xent 0.0000(0.0000) | Loss 3.5252(3.5232) | Error 0.0000(0.0000) Steps 868(845.49) | Grad Norm 1.9084(2.7515) | Total Time 14.00(14.00)\n",
      "Iter 4390 | Time 21.0170(20.6133) | Bit/dim 3.4917(3.5212) | Xent 0.0000(0.0000) | Loss 3.4917(3.5212) | Error 0.0000(0.0000) Steps 832(844.63) | Grad Norm 1.9401(2.6619) | Total Time 14.00(14.00)\n",
      "Iter 4400 | Time 19.9333(20.6156) | Bit/dim 3.5326(3.5216) | Xent 0.0000(0.0000) | Loss 3.5326(3.5216) | Error 0.0000(0.0000) Steps 844(846.97) | Grad Norm 3.1734(2.7972) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 101.5973, Epoch Time 1252.8926(1173.6068), Bit/dim 3.5230(best: 3.5217), Xent 0.0000, Loss 3.5230, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4410 | Time 19.7368(20.5878) | Bit/dim 3.5167(3.5209) | Xent 0.0000(0.0000) | Loss 3.5167(3.5209) | Error 0.0000(0.0000) Steps 832(848.21) | Grad Norm 1.8134(2.8046) | Total Time 14.00(14.00)\n",
      "Iter 4420 | Time 20.5423(20.5986) | Bit/dim 3.5253(3.5229) | Xent 0.0000(0.0000) | Loss 3.5253(3.5229) | Error 0.0000(0.0000) Steps 874(849.95) | Grad Norm 2.9073(2.7893) | Total Time 14.00(14.00)\n",
      "Iter 4430 | Time 20.3038(20.5856) | Bit/dim 3.5078(3.5234) | Xent 0.0000(0.0000) | Loss 3.5078(3.5234) | Error 0.0000(0.0000) Steps 862(849.13) | Grad Norm 2.5360(2.6089) | Total Time 14.00(14.00)\n",
      "Iter 4440 | Time 20.9255(20.6218) | Bit/dim 3.5408(3.5214) | Xent 0.0000(0.0000) | Loss 3.5408(3.5214) | Error 0.0000(0.0000) Steps 862(849.85) | Grad Norm 2.0140(2.6770) | Total Time 14.00(14.00)\n",
      "Iter 4450 | Time 21.3432(20.6399) | Bit/dim 3.5470(3.5196) | Xent 0.0000(0.0000) | Loss 3.5470(3.5196) | Error 0.0000(0.0000) Steps 868(849.12) | Grad Norm 4.6056(2.6980) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 102.1928, Epoch Time 1254.1449(1176.0229), Bit/dim 3.5210(best: 3.5217), Xent 0.0000, Loss 3.5210, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4460 | Time 20.5694(20.6389) | Bit/dim 3.5593(3.5215) | Xent 0.0000(0.0000) | Loss 3.5593(3.5215) | Error 0.0000(0.0000) Steps 832(848.33) | Grad Norm 1.8286(2.5929) | Total Time 14.00(14.00)\n",
      "Iter 4470 | Time 20.6284(20.6928) | Bit/dim 3.5101(3.5195) | Xent 0.0000(0.0000) | Loss 3.5101(3.5195) | Error 0.0000(0.0000) Steps 850(849.79) | Grad Norm 1.8174(2.6237) | Total Time 14.00(14.00)\n",
      "Iter 4480 | Time 20.4269(20.6811) | Bit/dim 3.5158(3.5165) | Xent 0.0000(0.0000) | Loss 3.5158(3.5165) | Error 0.0000(0.0000) Steps 868(850.46) | Grad Norm 2.9086(2.5727) | Total Time 14.00(14.00)\n",
      "Iter 4490 | Time 20.5130(20.6351) | Bit/dim 3.5163(3.5181) | Xent 0.0000(0.0000) | Loss 3.5163(3.5181) | Error 0.0000(0.0000) Steps 850(851.61) | Grad Norm 2.5887(2.5080) | Total Time 14.00(14.00)\n",
      "Iter 4500 | Time 20.5209(20.6732) | Bit/dim 3.5139(3.5181) | Xent 0.0000(0.0000) | Loss 3.5139(3.5181) | Error 0.0000(0.0000) Steps 850(851.30) | Grad Norm 1.8941(2.5839) | Total Time 14.00(14.00)\n",
      "Iter 4510 | Time 21.1239(20.6856) | Bit/dim 3.5317(3.5179) | Xent 0.0000(0.0000) | Loss 3.5317(3.5179) | Error 0.0000(0.0000) Steps 850(849.84) | Grad Norm 1.9560(2.6972) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 100.0741, Epoch Time 1255.9120(1178.4196), Bit/dim 3.5199(best: 3.5210), Xent 0.0000, Loss 3.5199, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4520 | Time 20.5848(20.6496) | Bit/dim 3.5355(3.5176) | Xent 0.0000(0.0000) | Loss 3.5355(3.5176) | Error 0.0000(0.0000) Steps 844(848.93) | Grad Norm 2.8914(2.6621) | Total Time 14.00(14.00)\n",
      "Iter 4530 | Time 21.1012(20.7085) | Bit/dim 3.5088(3.5148) | Xent 0.0000(0.0000) | Loss 3.5088(3.5148) | Error 0.0000(0.0000) Steps 862(850.76) | Grad Norm 1.8859(2.5351) | Total Time 14.00(14.00)\n",
      "Iter 4540 | Time 21.1023(20.7399) | Bit/dim 3.5157(3.5126) | Xent 0.0000(0.0000) | Loss 3.5157(3.5126) | Error 0.0000(0.0000) Steps 856(852.43) | Grad Norm 2.5855(2.6321) | Total Time 14.00(14.00)\n",
      "Iter 4550 | Time 20.1799(20.6760) | Bit/dim 3.5113(3.5152) | Xent 0.0000(0.0000) | Loss 3.5113(3.5152) | Error 0.0000(0.0000) Steps 874(852.15) | Grad Norm 2.3800(2.5215) | Total Time 14.00(14.00)\n",
      "Iter 4560 | Time 20.9041(20.6888) | Bit/dim 3.5397(3.5162) | Xent 0.0000(0.0000) | Loss 3.5397(3.5162) | Error 0.0000(0.0000) Steps 826(852.65) | Grad Norm 3.3328(2.7727) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 101.0566, Epoch Time 1254.9270(1180.7148), Bit/dim 3.5136(best: 3.5199), Xent 0.0000, Loss 3.5136, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4570 | Time 20.1102(20.5851) | Bit/dim 3.5412(3.5171) | Xent 0.0000(0.0000) | Loss 3.5412(3.5171) | Error 0.0000(0.0000) Steps 838(850.20) | Grad Norm 2.1848(2.6233) | Total Time 14.00(14.00)\n",
      "Iter 4580 | Time 20.6250(20.5986) | Bit/dim 3.4755(3.5152) | Xent 0.0000(0.0000) | Loss 3.4755(3.5152) | Error 0.0000(0.0000) Steps 868(852.61) | Grad Norm 3.9460(2.5732) | Total Time 14.00(14.00)\n",
      "Iter 4590 | Time 20.2029(20.6021) | Bit/dim 3.5179(3.5177) | Xent 0.0000(0.0000) | Loss 3.5179(3.5177) | Error 0.0000(0.0000) Steps 868(853.99) | Grad Norm 2.5537(2.5244) | Total Time 14.00(14.00)\n",
      "Iter 4600 | Time 21.2616(20.6305) | Bit/dim 3.5163(3.5153) | Xent 0.0000(0.0000) | Loss 3.5163(3.5153) | Error 0.0000(0.0000) Steps 856(855.49) | Grad Norm 1.9505(2.7471) | Total Time 14.00(14.00)\n",
      "Iter 4610 | Time 21.0777(20.6770) | Bit/dim 3.4797(3.5147) | Xent 0.0000(0.0000) | Loss 3.4797(3.5147) | Error 0.0000(0.0000) Steps 838(855.01) | Grad Norm 1.8660(2.6880) | Total Time 14.00(14.00)\n",
      "Iter 4620 | Time 21.3404(20.6711) | Bit/dim 3.4730(3.5129) | Xent 0.0000(0.0000) | Loss 3.4730(3.5129) | Error 0.0000(0.0000) Steps 850(855.47) | Grad Norm 1.9974(2.5782) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 102.2837, Epoch Time 1256.4086(1182.9856), Bit/dim 3.5138(best: 3.5136), Xent 0.0000, Loss 3.5138, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4630 | Time 21.5011(20.7302) | Bit/dim 3.5049(3.5115) | Xent 0.0000(0.0000) | Loss 3.5049(3.5115) | Error 0.0000(0.0000) Steps 850(857.10) | Grad Norm 3.2549(2.6686) | Total Time 14.00(14.00)\n",
      "Iter 4640 | Time 21.0536(20.7497) | Bit/dim 3.5142(3.5099) | Xent 0.0000(0.0000) | Loss 3.5142(3.5099) | Error 0.0000(0.0000) Steps 874(857.17) | Grad Norm 1.8573(2.5235) | Total Time 14.00(14.00)\n",
      "Iter 4650 | Time 20.4384(20.7054) | Bit/dim 3.4827(3.5095) | Xent 0.0000(0.0000) | Loss 3.4827(3.5095) | Error 0.0000(0.0000) Steps 874(858.26) | Grad Norm 2.0166(2.6183) | Total Time 14.00(14.00)\n",
      "Iter 4660 | Time 21.0018(20.7494) | Bit/dim 3.5511(3.5118) | Xent 0.0000(0.0000) | Loss 3.5511(3.5118) | Error 0.0000(0.0000) Steps 868(857.77) | Grad Norm 3.3285(2.6701) | Total Time 14.00(14.00)\n",
      "Iter 4670 | Time 20.5036(20.7856) | Bit/dim 3.5014(3.5111) | Xent 0.0000(0.0000) | Loss 3.5014(3.5111) | Error 0.0000(0.0000) Steps 844(858.32) | Grad Norm 3.0240(2.7326) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 102.2558, Epoch Time 1262.7296(1185.3779), Bit/dim 3.5134(best: 3.5136), Xent 0.0000, Loss 3.5134, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4680 | Time 20.6242(20.7187) | Bit/dim 3.5081(3.5120) | Xent 0.0000(0.0000) | Loss 3.5081(3.5120) | Error 0.0000(0.0000) Steps 880(858.74) | Grad Norm 3.1703(2.8056) | Total Time 14.00(14.00)\n",
      "Iter 4690 | Time 20.8786(20.6650) | Bit/dim 3.5199(3.5135) | Xent 0.0000(0.0000) | Loss 3.5199(3.5135) | Error 0.0000(0.0000) Steps 862(860.85) | Grad Norm 2.2613(2.7059) | Total Time 14.00(14.00)\n",
      "Iter 4700 | Time 21.0253(20.7919) | Bit/dim 3.5124(3.5078) | Xent 0.0000(0.0000) | Loss 3.5124(3.5078) | Error 0.0000(0.0000) Steps 850(861.05) | Grad Norm 3.6334(2.6082) | Total Time 14.00(14.00)\n",
      "Iter 4710 | Time 20.9584(20.8138) | Bit/dim 3.4838(3.5086) | Xent 0.0000(0.0000) | Loss 3.4838(3.5086) | Error 0.0000(0.0000) Steps 844(857.47) | Grad Norm 2.3353(2.5629) | Total Time 14.00(14.00)\n",
      "Iter 4720 | Time 21.0121(20.8266) | Bit/dim 3.5026(3.5106) | Xent 0.0000(0.0000) | Loss 3.5026(3.5106) | Error 0.0000(0.0000) Steps 850(858.97) | Grad Norm 4.9022(2.5809) | Total Time 14.00(14.00)\n",
      "Iter 4730 | Time 21.2395(20.8380) | Bit/dim 3.5092(3.5103) | Xent 0.0000(0.0000) | Loss 3.5092(3.5103) | Error 0.0000(0.0000) Steps 850(860.45) | Grad Norm 2.4665(2.6572) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 102.8680, Epoch Time 1266.3092(1187.8059), Bit/dim 3.5113(best: 3.5134), Xent 0.0000, Loss 3.5113, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4740 | Time 20.6090(20.7775) | Bit/dim 3.5108(3.5084) | Xent 0.0000(0.0000) | Loss 3.5108(3.5084) | Error 0.0000(0.0000) Steps 874(863.00) | Grad Norm 1.7235(2.5725) | Total Time 14.00(14.00)\n",
      "Iter 4750 | Time 21.2042(20.8242) | Bit/dim 3.5217(3.5102) | Xent 0.0000(0.0000) | Loss 3.5217(3.5102) | Error 0.0000(0.0000) Steps 886(866.22) | Grad Norm 2.3632(2.5055) | Total Time 14.00(14.00)\n",
      "Iter 4760 | Time 20.3697(20.8371) | Bit/dim 3.5315(3.5117) | Xent 0.0000(0.0000) | Loss 3.5315(3.5117) | Error 0.0000(0.0000) Steps 856(865.39) | Grad Norm 3.6497(2.4695) | Total Time 14.00(14.00)\n",
      "Iter 4770 | Time 20.3384(20.8073) | Bit/dim 3.5148(3.5096) | Xent 0.0000(0.0000) | Loss 3.5148(3.5096) | Error 0.0000(0.0000) Steps 850(862.92) | Grad Norm 2.9861(2.6433) | Total Time 14.00(14.00)\n",
      "Iter 4780 | Time 20.7496(20.8434) | Bit/dim 3.5015(3.5070) | Xent 0.0000(0.0000) | Loss 3.5015(3.5070) | Error 0.0000(0.0000) Steps 856(863.38) | Grad Norm 3.8054(2.7724) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 103.0641, Epoch Time 1267.9657(1190.2107), Bit/dim 3.5083(best: 3.5113), Xent 0.0000, Loss 3.5083, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4790 | Time 21.4392(20.8982) | Bit/dim 3.4892(3.5083) | Xent 0.0000(0.0000) | Loss 3.4892(3.5083) | Error 0.0000(0.0000) Steps 868(862.75) | Grad Norm 2.4895(2.7623) | Total Time 14.00(14.00)\n",
      "Iter 4800 | Time 20.8654(20.9440) | Bit/dim 3.5138(3.5075) | Xent 0.0000(0.0000) | Loss 3.5138(3.5075) | Error 0.0000(0.0000) Steps 880(865.37) | Grad Norm 3.7747(2.6802) | Total Time 14.00(14.00)\n",
      "Iter 4810 | Time 21.3943(20.9606) | Bit/dim 3.5142(3.5080) | Xent 0.0000(0.0000) | Loss 3.5142(3.5080) | Error 0.0000(0.0000) Steps 886(866.37) | Grad Norm 2.2580(2.6172) | Total Time 14.00(14.00)\n",
      "Iter 4820 | Time 20.9218(20.9434) | Bit/dim 3.5001(3.5088) | Xent 0.0000(0.0000) | Loss 3.5001(3.5088) | Error 0.0000(0.0000) Steps 880(868.10) | Grad Norm 4.1018(2.5883) | Total Time 14.00(14.00)\n",
      "Iter 4830 | Time 20.9352(20.9391) | Bit/dim 3.4948(3.5077) | Xent 0.0000(0.0000) | Loss 3.4948(3.5077) | Error 0.0000(0.0000) Steps 892(870.23) | Grad Norm 1.6708(2.6610) | Total Time 14.00(14.00)\n",
      "Iter 4840 | Time 20.0805(20.9630) | Bit/dim 3.4722(3.5048) | Xent 0.0000(0.0000) | Loss 3.4722(3.5048) | Error 0.0000(0.0000) Steps 862(871.25) | Grad Norm 3.9872(2.6744) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 103.0494, Epoch Time 1274.5716(1192.7415), Bit/dim 3.5105(best: 3.5083), Xent 0.0000, Loss 3.5105, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4850 | Time 20.8381(20.9475) | Bit/dim 3.4820(3.5047) | Xent 0.0000(0.0000) | Loss 3.4820(3.5047) | Error 0.0000(0.0000) Steps 874(872.61) | Grad Norm 3.1134(2.6124) | Total Time 14.00(14.00)\n",
      "Iter 4860 | Time 21.0882(20.9802) | Bit/dim 3.5361(3.5033) | Xent 0.0000(0.0000) | Loss 3.5361(3.5033) | Error 0.0000(0.0000) Steps 880(873.26) | Grad Norm 1.0436(2.6037) | Total Time 14.00(14.00)\n",
      "Iter 4870 | Time 20.3096(20.9553) | Bit/dim 3.5375(3.5040) | Xent 0.0000(0.0000) | Loss 3.5375(3.5040) | Error 0.0000(0.0000) Steps 856(871.94) | Grad Norm 2.4607(2.4794) | Total Time 14.00(14.00)\n",
      "Iter 4880 | Time 20.9299(21.0147) | Bit/dim 3.5028(3.5047) | Xent 0.0000(0.0000) | Loss 3.5028(3.5047) | Error 0.0000(0.0000) Steps 874(873.97) | Grad Norm 2.1219(2.5915) | Total Time 14.00(14.00)\n",
      "Iter 4890 | Time 21.5529(21.0270) | Bit/dim 3.5058(3.5025) | Xent 0.0000(0.0000) | Loss 3.5058(3.5025) | Error 0.0000(0.0000) Steps 898(874.55) | Grad Norm 1.8606(2.4955) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 103.4246, Epoch Time 1276.7791(1195.2626), Bit/dim 3.5082(best: 3.5083), Xent 0.0000, Loss 3.5082, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4900 | Time 20.3598(20.9923) | Bit/dim 3.4663(3.5020) | Xent 0.0000(0.0000) | Loss 3.4663(3.5020) | Error 0.0000(0.0000) Steps 868(874.79) | Grad Norm 2.8025(2.6029) | Total Time 14.00(14.00)\n",
      "Iter 4910 | Time 20.7966(20.9966) | Bit/dim 3.4806(3.5044) | Xent 0.0000(0.0000) | Loss 3.4806(3.5044) | Error 0.0000(0.0000) Steps 850(872.81) | Grad Norm 1.9100(2.5569) | Total Time 14.00(14.00)\n",
      "Iter 4920 | Time 21.2152(20.9658) | Bit/dim 3.5367(3.5014) | Xent 0.0000(0.0000) | Loss 3.5367(3.5014) | Error 0.0000(0.0000) Steps 868(871.19) | Grad Norm 2.9821(2.5256) | Total Time 14.00(14.00)\n",
      "Iter 4930 | Time 20.5576(20.9532) | Bit/dim 3.5029(3.5008) | Xent 0.0000(0.0000) | Loss 3.5029(3.5008) | Error 0.0000(0.0000) Steps 880(871.45) | Grad Norm 3.1842(2.5460) | Total Time 14.00(14.00)\n",
      "Iter 4940 | Time 21.6082(21.0379) | Bit/dim 3.5083(3.5040) | Xent 0.0000(0.0000) | Loss 3.5083(3.5040) | Error 0.0000(0.0000) Steps 868(872.26) | Grad Norm 4.4035(2.6899) | Total Time 14.00(14.00)\n",
      "Iter 4950 | Time 20.8753(21.0074) | Bit/dim 3.5076(3.5033) | Xent 0.0000(0.0000) | Loss 3.5076(3.5033) | Error 0.0000(0.0000) Steps 874(871.49) | Grad Norm 1.6777(2.7129) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 103.4903, Epoch Time 1275.4933(1197.6696), Bit/dim 3.5006(best: 3.5082), Xent 0.0000, Loss 3.5006, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4960 | Time 21.0648(21.0118) | Bit/dim 3.5125(3.5010) | Xent 0.0000(0.0000) | Loss 3.5125(3.5010) | Error 0.0000(0.0000) Steps 856(871.30) | Grad Norm 2.3608(2.5920) | Total Time 14.00(14.00)\n",
      "Iter 4970 | Time 20.4030(20.9920) | Bit/dim 3.5040(3.5015) | Xent 0.0000(0.0000) | Loss 3.5040(3.5015) | Error 0.0000(0.0000) Steps 862(870.83) | Grad Norm 3.7775(2.5564) | Total Time 14.00(14.00)\n",
      "Iter 4980 | Time 20.6930(21.0260) | Bit/dim 3.5165(3.5001) | Xent 0.0000(0.0000) | Loss 3.5165(3.5001) | Error 0.0000(0.0000) Steps 874(871.74) | Grad Norm 2.9470(2.6395) | Total Time 14.00(14.00)\n",
      "Iter 4990 | Time 21.3607(20.9692) | Bit/dim 3.4941(3.5007) | Xent 0.0000(0.0000) | Loss 3.4941(3.5007) | Error 0.0000(0.0000) Steps 880(871.38) | Grad Norm 2.5945(2.6970) | Total Time 14.00(14.00)\n",
      "Iter 5000 | Time 20.6747(20.9241) | Bit/dim 3.5103(3.5020) | Xent 0.0000(0.0000) | Loss 3.5103(3.5020) | Error 0.0000(0.0000) Steps 880(870.69) | Grad Norm 1.6155(2.5871) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 103.3291, Epoch Time 1273.0698(1199.9316), Bit/dim 3.5024(best: 3.5006), Xent 0.0000, Loss 3.5024, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5010 | Time 20.8113(20.8935) | Bit/dim 3.5136(3.5015) | Xent 0.0000(0.0000) | Loss 3.5136(3.5015) | Error 0.0000(0.0000) Steps 886(869.11) | Grad Norm 3.7108(2.6423) | Total Time 14.00(14.00)\n",
      "Iter 5020 | Time 21.3630(20.9111) | Bit/dim 3.4767(3.5024) | Xent 0.0000(0.0000) | Loss 3.4767(3.5024) | Error 0.0000(0.0000) Steps 874(869.17) | Grad Norm 3.3455(2.5882) | Total Time 14.00(14.00)\n",
      "Iter 5030 | Time 20.8332(20.9045) | Bit/dim 3.5136(3.5029) | Xent 0.0000(0.0000) | Loss 3.5136(3.5029) | Error 0.0000(0.0000) Steps 880(872.39) | Grad Norm 2.5465(2.6865) | Total Time 14.00(14.00)\n",
      "Iter 5040 | Time 20.4615(20.8666) | Bit/dim 3.4845(3.5016) | Xent 0.0000(0.0000) | Loss 3.4845(3.5016) | Error 0.0000(0.0000) Steps 862(872.25) | Grad Norm 1.3885(2.4660) | Total Time 14.00(14.00)\n",
      "Iter 5050 | Time 21.0950(20.9354) | Bit/dim 3.4989(3.5004) | Xent 0.0000(0.0000) | Loss 3.4989(3.5004) | Error 0.0000(0.0000) Steps 862(873.32) | Grad Norm 3.0242(2.5309) | Total Time 14.00(14.00)\n",
      "Iter 5060 | Time 20.7798(20.8941) | Bit/dim 3.4425(3.4973) | Xent 0.0000(0.0000) | Loss 3.4425(3.4973) | Error 0.0000(0.0000) Steps 856(873.29) | Grad Norm 2.9304(2.5525) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 102.8864, Epoch Time 1269.1982(1202.0096), Bit/dim 3.5039(best: 3.5006), Xent 0.0000, Loss 3.5039, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5070 | Time 20.3741(20.8999) | Bit/dim 3.5112(3.4979) | Xent 0.0000(0.0000) | Loss 3.5112(3.4979) | Error 0.0000(0.0000) Steps 856(872.46) | Grad Norm 2.4900(2.5492) | Total Time 14.00(14.00)\n",
      "Iter 5080 | Time 21.3459(20.9166) | Bit/dim 3.4864(3.4966) | Xent 0.0000(0.0000) | Loss 3.4864(3.4966) | Error 0.0000(0.0000) Steps 856(871.99) | Grad Norm 1.8618(2.6065) | Total Time 14.00(14.00)\n",
      "Iter 5090 | Time 20.7043(20.9153) | Bit/dim 3.4885(3.4967) | Xent 0.0000(0.0000) | Loss 3.4885(3.4967) | Error 0.0000(0.0000) Steps 886(871.69) | Grad Norm 3.8510(2.5867) | Total Time 14.00(14.00)\n",
      "Iter 5100 | Time 20.4777(20.8515) | Bit/dim 3.5209(3.4977) | Xent 0.0000(0.0000) | Loss 3.5209(3.4977) | Error 0.0000(0.0000) Steps 880(871.18) | Grad Norm 1.8568(2.6263) | Total Time 14.00(14.00)\n",
      "Iter 5110 | Time 20.6129(20.8798) | Bit/dim 3.4978(3.4966) | Xent 0.0000(0.0000) | Loss 3.4978(3.4966) | Error 0.0000(0.0000) Steps 850(870.86) | Grad Norm 2.3939(2.5030) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 101.3735, Epoch Time 1266.8142(1203.9537), Bit/dim 3.4993(best: 3.5006), Xent 0.0000, Loss 3.4993, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5120 | Time 20.7969(20.8285) | Bit/dim 3.4641(3.4954) | Xent 0.0000(0.0000) | Loss 3.4641(3.4954) | Error 0.0000(0.0000) Steps 856(870.83) | Grad Norm 1.5748(2.4480) | Total Time 14.00(14.00)\n",
      "Iter 5130 | Time 20.2334(20.8071) | Bit/dim 3.4776(3.4942) | Xent 0.0000(0.0000) | Loss 3.4776(3.4942) | Error 0.0000(0.0000) Steps 850(870.38) | Grad Norm 2.8262(2.6174) | Total Time 14.00(14.00)\n",
      "Iter 5140 | Time 21.5209(20.8956) | Bit/dim 3.4865(3.4955) | Xent 0.0000(0.0000) | Loss 3.4865(3.4955) | Error 0.0000(0.0000) Steps 886(870.33) | Grad Norm 2.3390(2.4578) | Total Time 14.00(14.00)\n",
      "Iter 5150 | Time 21.2474(20.9782) | Bit/dim 3.5065(3.4953) | Xent 0.0000(0.0000) | Loss 3.5065(3.4953) | Error 0.0000(0.0000) Steps 862(870.26) | Grad Norm 4.5096(2.6688) | Total Time 14.00(14.00)\n",
      "Iter 5160 | Time 21.0423(20.9508) | Bit/dim 3.4777(3.4952) | Xent 0.0000(0.0000) | Loss 3.4777(3.4952) | Error 0.0000(0.0000) Steps 862(868.80) | Grad Norm 1.8565(2.5590) | Total Time 14.00(14.00)\n",
      "Iter 5170 | Time 20.1719(20.9374) | Bit/dim 3.5251(3.4968) | Xent 0.0000(0.0000) | Loss 3.5251(3.4968) | Error 0.0000(0.0000) Steps 880(868.73) | Grad Norm 4.2546(2.5797) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 102.9688, Epoch Time 1272.8698(1206.0212), Bit/dim 3.5002(best: 3.4993), Xent 0.0000, Loss 3.5002, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5180 | Time 21.1020(20.8721) | Bit/dim 3.4889(3.4959) | Xent 0.0000(0.0000) | Loss 3.4889(3.4959) | Error 0.0000(0.0000) Steps 886(868.43) | Grad Norm 2.3553(2.5763) | Total Time 14.00(14.00)\n",
      "Iter 5190 | Time 20.2065(20.8105) | Bit/dim 3.5217(3.4967) | Xent 0.0000(0.0000) | Loss 3.5217(3.4967) | Error 0.0000(0.0000) Steps 862(868.40) | Grad Norm 2.1352(2.6296) | Total Time 14.00(14.00)\n",
      "Iter 5200 | Time 21.5597(20.9104) | Bit/dim 3.4856(3.4951) | Xent 0.0000(0.0000) | Loss 3.4856(3.4951) | Error 0.0000(0.0000) Steps 856(866.65) | Grad Norm 2.6256(2.5637) | Total Time 14.00(14.00)\n",
      "Iter 5210 | Time 20.7014(20.9521) | Bit/dim 3.4699(3.4954) | Xent 0.0000(0.0000) | Loss 3.4699(3.4954) | Error 0.0000(0.0000) Steps 856(866.25) | Grad Norm 1.9797(2.6697) | Total Time 14.00(14.00)\n",
      "Iter 5220 | Time 20.2156(20.9285) | Bit/dim 3.5191(3.4949) | Xent 0.0000(0.0000) | Loss 3.5191(3.4949) | Error 0.0000(0.0000) Steps 856(864.73) | Grad Norm 3.0275(2.6982) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 103.2118, Epoch Time 1271.6539(1207.9902), Bit/dim 3.4916(best: 3.4993), Xent 0.0000, Loss 3.4916, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5230 | Time 21.1164(20.9375) | Bit/dim 3.4785(3.4938) | Xent 0.0000(0.0000) | Loss 3.4785(3.4938) | Error 0.0000(0.0000) Steps 886(866.52) | Grad Norm 2.9321(2.5842) | Total Time 14.00(14.00)\n",
      "Iter 5240 | Time 21.6676(20.9735) | Bit/dim 3.5030(3.4941) | Xent 0.0000(0.0000) | Loss 3.5030(3.4941) | Error 0.0000(0.0000) Steps 880(867.30) | Grad Norm 2.4829(2.5993) | Total Time 14.00(14.00)\n",
      "Iter 5250 | Time 20.7993(21.0165) | Bit/dim 3.5012(3.4900) | Xent 0.0000(0.0000) | Loss 3.5012(3.4900) | Error 0.0000(0.0000) Steps 862(869.68) | Grad Norm 2.0850(2.5271) | Total Time 14.00(14.00)\n",
      "Iter 5260 | Time 20.4851(21.0256) | Bit/dim 3.4804(3.4923) | Xent 0.0000(0.0000) | Loss 3.4804(3.4923) | Error 0.0000(0.0000) Steps 868(870.41) | Grad Norm 1.8781(2.6013) | Total Time 14.00(14.00)\n",
      "Iter 5270 | Time 20.0730(20.9276) | Bit/dim 3.5066(3.4943) | Xent 0.0000(0.0000) | Loss 3.5066(3.4943) | Error 0.0000(0.0000) Steps 856(869.19) | Grad Norm 2.6141(2.6966) | Total Time 14.00(14.00)\n",
      "Iter 5280 | Time 21.1161(20.8686) | Bit/dim 3.4949(3.4920) | Xent 0.0000(0.0000) | Loss 3.4949(3.4920) | Error 0.0000(0.0000) Steps 844(867.05) | Grad Norm 1.7915(2.5296) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 102.3119, Epoch Time 1269.7799(1209.8439), Bit/dim 3.4909(best: 3.4916), Xent 0.0000, Loss 3.4909, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5290 | Time 20.6465(20.8169) | Bit/dim 3.5010(3.4930) | Xent 0.0000(0.0000) | Loss 3.5010(3.4930) | Error 0.0000(0.0000) Steps 862(867.04) | Grad Norm 2.2460(2.6289) | Total Time 14.00(14.00)\n",
      "Iter 5300 | Time 21.3684(20.8164) | Bit/dim 3.4916(3.4913) | Xent 0.0000(0.0000) | Loss 3.4916(3.4913) | Error 0.0000(0.0000) Steps 892(867.78) | Grad Norm 1.5297(2.3621) | Total Time 14.00(14.00)\n",
      "Iter 5310 | Time 21.2445(20.8431) | Bit/dim 3.4763(3.4902) | Xent 0.0000(0.0000) | Loss 3.4763(3.4902) | Error 0.0000(0.0000) Steps 862(868.83) | Grad Norm 2.8430(2.6005) | Total Time 14.00(14.00)\n",
      "Iter 5320 | Time 20.5916(20.9129) | Bit/dim 3.4611(3.4894) | Xent 0.0000(0.0000) | Loss 3.4611(3.4894) | Error 0.0000(0.0000) Steps 880(871.14) | Grad Norm 1.6839(2.4408) | Total Time 14.00(14.00)\n",
      "Iter 5330 | Time 20.9499(20.9648) | Bit/dim 3.4869(3.4902) | Xent 0.0000(0.0000) | Loss 3.4869(3.4902) | Error 0.0000(0.0000) Steps 886(872.37) | Grad Norm 2.0144(2.5072) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 101.8001, Epoch Time 1270.6677(1211.6686), Bit/dim 3.4906(best: 3.4909), Xent 0.0000, Loss 3.4906, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5340 | Time 20.8488(20.9589) | Bit/dim 3.5168(3.4892) | Xent 0.0000(0.0000) | Loss 3.5168(3.4892) | Error 0.0000(0.0000) Steps 868(874.37) | Grad Norm 3.5430(2.5634) | Total Time 14.00(14.00)\n",
      "Iter 5350 | Time 20.2578(20.8930) | Bit/dim 3.4708(3.4880) | Xent 0.0000(0.0000) | Loss 3.4708(3.4880) | Error 0.0000(0.0000) Steps 856(874.40) | Grad Norm 1.5844(2.4369) | Total Time 14.00(14.00)\n",
      "Iter 5360 | Time 20.9340(20.8654) | Bit/dim 3.4504(3.4891) | Xent 0.0000(0.0000) | Loss 3.4504(3.4891) | Error 0.0000(0.0000) Steps 886(875.25) | Grad Norm 2.6966(2.5625) | Total Time 14.00(14.00)\n",
      "Iter 5370 | Time 20.7746(20.8176) | Bit/dim 3.4778(3.4891) | Xent 0.0000(0.0000) | Loss 3.4778(3.4891) | Error 0.0000(0.0000) Steps 880(874.20) | Grad Norm 1.7530(2.3756) | Total Time 14.00(14.00)\n",
      "Iter 5380 | Time 20.0448(20.8076) | Bit/dim 3.4787(3.4898) | Xent 0.0000(0.0000) | Loss 3.4787(3.4898) | Error 0.0000(0.0000) Steps 874(873.33) | Grad Norm 2.2065(2.4848) | Total Time 14.00(14.00)\n",
      "Iter 5390 | Time 21.0579(20.7246) | Bit/dim 3.5204(3.4897) | Xent 0.0000(0.0000) | Loss 3.5204(3.4897) | Error 0.0000(0.0000) Steps 862(871.05) | Grad Norm 2.1375(2.4729) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 102.0154, Epoch Time 1258.7019(1213.0796), Bit/dim 3.4907(best: 3.4906), Xent 0.0000, Loss 3.4907, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5400 | Time 20.5044(20.6809) | Bit/dim 3.4980(3.4885) | Xent 0.0000(0.0000) | Loss 3.4980(3.4885) | Error 0.0000(0.0000) Steps 874(871.41) | Grad Norm 1.7751(2.5616) | Total Time 14.00(14.00)\n",
      "Iter 5410 | Time 20.6108(20.6697) | Bit/dim 3.5008(3.4872) | Xent 0.0000(0.0000) | Loss 3.5008(3.4872) | Error 0.0000(0.0000) Steps 856(870.12) | Grad Norm 2.0368(2.5385) | Total Time 14.00(14.00)\n",
      "Iter 5420 | Time 21.3947(20.6929) | Bit/dim 3.5004(3.4876) | Xent 0.0000(0.0000) | Loss 3.5004(3.4876) | Error 0.0000(0.0000) Steps 862(869.03) | Grad Norm 2.2939(2.6191) | Total Time 14.00(14.00)\n",
      "Iter 5430 | Time 20.8617(20.7472) | Bit/dim 3.4803(3.4873) | Xent 0.0000(0.0000) | Loss 3.4803(3.4873) | Error 0.0000(0.0000) Steps 874(868.28) | Grad Norm 3.9936(2.5335) | Total Time 14.00(14.00)\n",
      "Iter 5440 | Time 20.5338(20.8104) | Bit/dim 3.4958(3.4864) | Xent 0.0000(0.0000) | Loss 3.4958(3.4864) | Error 0.0000(0.0000) Steps 880(870.16) | Grad Norm 2.1652(2.7009) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 103.2904, Epoch Time 1262.0040(1214.5473), Bit/dim 3.4889(best: 3.4906), Xent 0.0000, Loss 3.4889, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5450 | Time 20.7887(20.7767) | Bit/dim 3.4857(3.4896) | Xent 0.0000(0.0000) | Loss 3.4857(3.4896) | Error 0.0000(0.0000) Steps 856(869.99) | Grad Norm 2.1954(2.6793) | Total Time 14.00(14.00)\n",
      "Iter 5460 | Time 21.2683(20.7811) | Bit/dim 3.4824(3.4866) | Xent 0.0000(0.0000) | Loss 3.4824(3.4866) | Error 0.0000(0.0000) Steps 886(872.11) | Grad Norm 1.6532(2.5356) | Total Time 14.00(14.00)\n",
      "Iter 5470 | Time 20.8027(20.7729) | Bit/dim 3.4626(3.4844) | Xent 0.0000(0.0000) | Loss 3.4626(3.4844) | Error 0.0000(0.0000) Steps 856(870.95) | Grad Norm 2.6722(2.5056) | Total Time 14.00(14.00)\n",
      "Iter 5480 | Time 20.3890(20.7626) | Bit/dim 3.4636(3.4865) | Xent 0.0000(0.0000) | Loss 3.4636(3.4865) | Error 0.0000(0.0000) Steps 886(871.45) | Grad Norm 2.4056(2.5650) | Total Time 14.00(14.00)\n",
      "Iter 5490 | Time 20.1384(20.8056) | Bit/dim 3.4710(3.4879) | Xent 0.0000(0.0000) | Loss 3.4710(3.4879) | Error 0.0000(0.0000) Steps 856(871.96) | Grad Norm 1.7801(2.3470) | Total Time 14.00(14.00)\n",
      "Iter 5500 | Time 20.8415(20.8057) | Bit/dim 3.4476(3.4874) | Xent 0.0000(0.0000) | Loss 3.4476(3.4874) | Error 0.0000(0.0000) Steps 874(870.58) | Grad Norm 1.6561(2.3730) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 101.3994, Epoch Time 1263.1556(1216.0055), Bit/dim 3.4869(best: 3.4889), Xent 0.0000, Loss 3.4869, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5510 | Time 21.0387(20.8234) | Bit/dim 3.4614(3.4881) | Xent 0.0000(0.0000) | Loss 3.4614(3.4881) | Error 0.0000(0.0000) Steps 868(870.94) | Grad Norm 2.7111(2.5328) | Total Time 14.00(14.00)\n",
      "Iter 5520 | Time 20.4500(20.8245) | Bit/dim 3.5214(3.4875) | Xent 0.0000(0.0000) | Loss 3.5214(3.4875) | Error 0.0000(0.0000) Steps 880(868.96) | Grad Norm 1.6708(2.3774) | Total Time 14.00(14.00)\n",
      "Iter 5530 | Time 20.9838(20.7268) | Bit/dim 3.5170(3.4877) | Xent 0.0000(0.0000) | Loss 3.5170(3.4877) | Error 0.0000(0.0000) Steps 892(868.45) | Grad Norm 2.5967(2.5922) | Total Time 14.00(14.00)\n",
      "Iter 5540 | Time 20.4648(20.7372) | Bit/dim 3.4998(3.4855) | Xent 0.0000(0.0000) | Loss 3.4998(3.4855) | Error 0.0000(0.0000) Steps 874(867.54) | Grad Norm 2.6673(2.5504) | Total Time 14.00(14.00)\n",
      "Iter 5550 | Time 21.1768(20.7714) | Bit/dim 3.4803(3.4840) | Xent 0.0000(0.0000) | Loss 3.4803(3.4840) | Error 0.0000(0.0000) Steps 874(869.82) | Grad Norm 1.9183(2.3715) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 102.2830, Epoch Time 1260.6320(1217.3443), Bit/dim 3.4854(best: 3.4869), Xent 0.0000, Loss 3.4854, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5560 | Time 21.1289(20.7522) | Bit/dim 3.5139(3.4842) | Xent 0.0000(0.0000) | Loss 3.5139(3.4842) | Error 0.0000(0.0000) Steps 874(870.40) | Grad Norm 2.9001(2.5332) | Total Time 14.00(14.00)\n",
      "Iter 5570 | Time 20.6650(20.8340) | Bit/dim 3.5045(3.4820) | Xent 0.0000(0.0000) | Loss 3.5045(3.4820) | Error 0.0000(0.0000) Steps 874(870.08) | Grad Norm 1.8899(2.3561) | Total Time 14.00(14.00)\n",
      "Iter 5580 | Time 19.7658(20.7940) | Bit/dim 3.4831(3.4832) | Xent 0.0000(0.0000) | Loss 3.4831(3.4832) | Error 0.0000(0.0000) Steps 856(870.75) | Grad Norm 2.3857(2.4813) | Total Time 14.00(14.00)\n",
      "Iter 5590 | Time 19.7589(20.7751) | Bit/dim 3.5089(3.4831) | Xent 0.0000(0.0000) | Loss 3.5089(3.4831) | Error 0.0000(0.0000) Steps 856(869.18) | Grad Norm 2.6519(2.4593) | Total Time 14.00(14.00)\n",
      "Iter 5600 | Time 20.5808(20.7986) | Bit/dim 3.4957(3.4853) | Xent 0.0000(0.0000) | Loss 3.4957(3.4853) | Error 0.0000(0.0000) Steps 868(870.82) | Grad Norm 3.9580(2.6817) | Total Time 14.00(14.00)\n",
      "Iter 5610 | Time 19.6798(20.7391) | Bit/dim 3.4814(3.4853) | Xent 0.0000(0.0000) | Loss 3.4814(3.4853) | Error 0.0000(0.0000) Steps 874(871.57) | Grad Norm 1.5625(2.5602) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 100.5684, Epoch Time 1261.7072(1218.6752), Bit/dim 3.4816(best: 3.4854), Xent 0.0000, Loss 3.4816, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5620 | Time 20.6842(20.7866) | Bit/dim 3.4659(3.4839) | Xent 0.0000(0.0000) | Loss 3.4659(3.4839) | Error 0.0000(0.0000) Steps 868(872.07) | Grad Norm 2.6660(2.6235) | Total Time 14.00(14.00)\n",
      "Iter 5630 | Time 21.4550(20.7723) | Bit/dim 3.4953(3.4826) | Xent 0.0000(0.0000) | Loss 3.4953(3.4826) | Error 0.0000(0.0000) Steps 844(869.85) | Grad Norm 2.2256(2.5871) | Total Time 14.00(14.00)\n",
      "Iter 5640 | Time 20.8739(20.8343) | Bit/dim 3.4828(3.4844) | Xent 0.0000(0.0000) | Loss 3.4828(3.4844) | Error 0.0000(0.0000) Steps 886(872.36) | Grad Norm 1.2684(2.5670) | Total Time 14.00(14.00)\n",
      "Iter 5650 | Time 21.1537(20.8552) | Bit/dim 3.4797(3.4826) | Xent 0.0000(0.0000) | Loss 3.4797(3.4826) | Error 0.0000(0.0000) Steps 862(872.40) | Grad Norm 1.5554(2.5247) | Total Time 14.00(14.00)\n",
      "Iter 5660 | Time 20.4694(20.8881) | Bit/dim 3.5091(3.4828) | Xent 0.0000(0.0000) | Loss 3.5091(3.4828) | Error 0.0000(0.0000) Steps 880(874.32) | Grad Norm 2.6752(2.4899) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 101.2869, Epoch Time 1268.0922(1220.1577), Bit/dim 3.4801(best: 3.4816), Xent 0.0000, Loss 3.4801, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5670 | Time 21.1081(20.8285) | Bit/dim 3.4601(3.4816) | Xent 0.0000(0.0000) | Loss 3.4601(3.4816) | Error 0.0000(0.0000) Steps 892(873.84) | Grad Norm 2.1843(2.4283) | Total Time 14.00(14.00)\n",
      "Iter 5680 | Time 20.8377(20.8400) | Bit/dim 3.4508(3.4822) | Xent 0.0000(0.0000) | Loss 3.4508(3.4822) | Error 0.0000(0.0000) Steps 874(875.60) | Grad Norm 1.9818(2.4827) | Total Time 14.00(14.00)\n",
      "Iter 5690 | Time 20.8567(20.8208) | Bit/dim 3.4348(3.4827) | Xent 0.0000(0.0000) | Loss 3.4348(3.4827) | Error 0.0000(0.0000) Steps 880(874.08) | Grad Norm 2.1831(2.4316) | Total Time 14.00(14.00)\n",
      "Iter 5700 | Time 20.3298(20.8038) | Bit/dim 3.5110(3.4829) | Xent 0.0000(0.0000) | Loss 3.5110(3.4829) | Error 0.0000(0.0000) Steps 856(872.78) | Grad Norm 2.9102(2.3509) | Total Time 14.00(14.00)\n",
      "Iter 5710 | Time 20.7927(20.8014) | Bit/dim 3.4790(3.4802) | Xent 0.0000(0.0000) | Loss 3.4790(3.4802) | Error 0.0000(0.0000) Steps 874(874.27) | Grad Norm 2.7208(2.5736) | Total Time 14.00(14.00)\n",
      "Iter 5720 | Time 20.7355(20.7941) | Bit/dim 3.4688(3.4801) | Xent 0.0000(0.0000) | Loss 3.4688(3.4801) | Error 0.0000(0.0000) Steps 892(875.44) | Grad Norm 1.8844(2.5273) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 102.5962, Epoch Time 1263.0871(1221.4456), Bit/dim 3.4792(best: 3.4801), Xent 0.0000, Loss 3.4792, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5730 | Time 21.3384(20.8706) | Bit/dim 3.4897(3.4822) | Xent 0.0000(0.0000) | Loss 3.4897(3.4822) | Error 0.0000(0.0000) Steps 868(875.41) | Grad Norm 2.1826(2.4583) | Total Time 14.00(14.00)\n",
      "Iter 5740 | Time 21.3339(20.9173) | Bit/dim 3.4656(3.4830) | Xent 0.0000(0.0000) | Loss 3.4656(3.4830) | Error 0.0000(0.0000) Steps 892(878.60) | Grad Norm 2.7943(2.3160) | Total Time 14.00(14.00)\n",
      "Iter 5750 | Time 20.5586(20.8652) | Bit/dim 3.4782(3.4828) | Xent 0.0000(0.0000) | Loss 3.4782(3.4828) | Error 0.0000(0.0000) Steps 856(877.21) | Grad Norm 3.3901(2.4980) | Total Time 14.00(14.00)\n",
      "Iter 5760 | Time 20.5711(20.9039) | Bit/dim 3.4812(3.4795) | Xent 0.0000(0.0000) | Loss 3.4812(3.4795) | Error 0.0000(0.0000) Steps 892(877.26) | Grad Norm 2.3700(2.4313) | Total Time 14.00(14.00)\n",
      "Iter 5770 | Time 21.1999(20.9411) | Bit/dim 3.4717(3.4777) | Xent 0.0000(0.0000) | Loss 3.4717(3.4777) | Error 0.0000(0.0000) Steps 886(877.34) | Grad Norm 2.5160(2.6540) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 102.4090, Epoch Time 1273.6313(1223.0112), Bit/dim 3.4793(best: 3.4792), Xent 0.0000, Loss 3.4793, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5780 | Time 21.3458(20.9030) | Bit/dim 3.4979(3.4789) | Xent 0.0000(0.0000) | Loss 3.4979(3.4789) | Error 0.0000(0.0000) Steps 874(876.08) | Grad Norm 1.3983(2.5188) | Total Time 14.00(14.00)\n",
      "Iter 5790 | Time 20.5738(20.9683) | Bit/dim 3.4510(3.4768) | Xent 0.0000(0.0000) | Loss 3.4510(3.4768) | Error 0.0000(0.0000) Steps 874(878.21) | Grad Norm 1.6170(2.3990) | Total Time 14.00(14.00)\n",
      "Iter 5800 | Time 21.3318(20.9777) | Bit/dim 3.4497(3.4771) | Xent 0.0000(0.0000) | Loss 3.4497(3.4771) | Error 0.0000(0.0000) Steps 862(877.23) | Grad Norm 3.0619(2.4809) | Total Time 14.00(14.00)\n",
      "Iter 5810 | Time 21.2551(20.8879) | Bit/dim 3.4792(3.4787) | Xent 0.0000(0.0000) | Loss 3.4792(3.4787) | Error 0.0000(0.0000) Steps 886(875.49) | Grad Norm 2.6424(2.5159) | Total Time 14.00(14.00)\n",
      "Iter 5820 | Time 21.9945(21.0506) | Bit/dim 3.4762(3.4750) | Xent 0.0000(0.0000) | Loss 3.4762(3.4750) | Error 0.0000(0.0000) Steps 880(876.79) | Grad Norm 2.4024(2.4687) | Total Time 14.00(14.00)\n",
      "Iter 5830 | Time 21.0706(20.9934) | Bit/dim 3.4890(3.4756) | Xent 0.0000(0.0000) | Loss 3.4890(3.4756) | Error 0.0000(0.0000) Steps 868(876.73) | Grad Norm 1.2371(2.2518) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 103.3352, Epoch Time 1275.5769(1224.5882), Bit/dim 3.4744(best: 3.4792), Xent 0.0000, Loss 3.4744, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5840 | Time 20.2415(20.9490) | Bit/dim 3.4976(3.4757) | Xent 0.0000(0.0000) | Loss 3.4976(3.4757) | Error 0.0000(0.0000) Steps 874(876.32) | Grad Norm 2.0533(2.0279) | Total Time 14.00(14.00)\n",
      "Iter 5850 | Time 20.6155(20.9136) | Bit/dim 3.4558(3.4757) | Xent 0.0000(0.0000) | Loss 3.4558(3.4757) | Error 0.0000(0.0000) Steps 892(877.61) | Grad Norm 3.6670(2.3334) | Total Time 14.00(14.00)\n",
      "Iter 5860 | Time 20.4042(20.9100) | Bit/dim 3.4889(3.4739) | Xent 0.0000(0.0000) | Loss 3.4889(3.4739) | Error 0.0000(0.0000) Steps 886(878.43) | Grad Norm 1.8117(2.3972) | Total Time 14.00(14.00)\n",
      "Iter 5870 | Time 20.7988(20.9219) | Bit/dim 3.4774(3.4698) | Xent 0.0000(0.0000) | Loss 3.4774(3.4698) | Error 0.0000(0.0000) Steps 874(877.33) | Grad Norm 1.8727(2.3363) | Total Time 14.00(14.00)\n",
      "Iter 5880 | Time 20.6845(20.8721) | Bit/dim 3.5092(3.4774) | Xent 0.0000(0.0000) | Loss 3.5092(3.4774) | Error 0.0000(0.0000) Steps 856(875.94) | Grad Norm 2.8081(2.4892) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 104.5329, Epoch Time 1268.9163(1225.9180), Bit/dim 3.4811(best: 3.4744), Xent 0.0000, Loss 3.4811, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5890 | Time 20.3089(20.7678) | Bit/dim 3.4841(3.4809) | Xent 0.0000(0.0000) | Loss 3.4841(3.4809) | Error 0.0000(0.0000) Steps 862(874.50) | Grad Norm 1.9412(2.5033) | Total Time 14.00(14.00)\n",
      "Iter 5900 | Time 20.9411(20.7627) | Bit/dim 3.4683(3.4795) | Xent 0.0000(0.0000) | Loss 3.4683(3.4795) | Error 0.0000(0.0000) Steps 874(874.35) | Grad Norm 2.2309(2.4598) | Total Time 14.00(14.00)\n",
      "Iter 5910 | Time 21.1199(20.8171) | Bit/dim 3.4583(3.4797) | Xent 0.0000(0.0000) | Loss 3.4583(3.4797) | Error 0.0000(0.0000) Steps 892(875.34) | Grad Norm 4.1476(2.5902) | Total Time 14.00(14.00)\n",
      "Iter 5920 | Time 21.1510(20.8738) | Bit/dim 3.4909(3.4778) | Xent 0.0000(0.0000) | Loss 3.4909(3.4778) | Error 0.0000(0.0000) Steps 844(875.35) | Grad Norm 2.7678(2.5265) | Total Time 14.00(14.00)\n",
      "Iter 5930 | Time 19.9283(20.7720) | Bit/dim 3.4777(3.4758) | Xent 0.0000(0.0000) | Loss 3.4777(3.4758) | Error 0.0000(0.0000) Steps 874(876.57) | Grad Norm 2.2122(2.4411) | Total Time 14.00(14.00)\n",
      "Iter 5940 | Time 21.1606(20.7493) | Bit/dim 3.4889(3.4751) | Xent 0.0000(0.0000) | Loss 3.4889(3.4751) | Error 0.0000(0.0000) Steps 880(874.95) | Grad Norm 2.2686(2.6901) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 101.7849, Epoch Time 1259.5423(1226.9267), Bit/dim 3.4752(best: 3.4744), Xent 0.0000, Loss 3.4752, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5950 | Time 20.6455(20.7008) | Bit/dim 3.4668(3.4754) | Xent 0.0000(0.0000) | Loss 3.4668(3.4754) | Error 0.0000(0.0000) Steps 862(873.69) | Grad Norm 1.9624(2.6113) | Total Time 14.00(14.00)\n",
      "Iter 5960 | Time 20.0466(20.7266) | Bit/dim 3.5068(3.4764) | Xent 0.0000(0.0000) | Loss 3.5068(3.4764) | Error 0.0000(0.0000) Steps 874(874.24) | Grad Norm 2.3618(2.3746) | Total Time 14.00(14.00)\n",
      "Iter 5970 | Time 20.5257(20.7634) | Bit/dim 3.4542(3.4761) | Xent 0.0000(0.0000) | Loss 3.4542(3.4761) | Error 0.0000(0.0000) Steps 886(875.93) | Grad Norm 2.7390(2.4880) | Total Time 14.00(14.00)\n",
      "Iter 5980 | Time 20.4624(20.8188) | Bit/dim 3.4795(3.4741) | Xent 0.0000(0.0000) | Loss 3.4795(3.4741) | Error 0.0000(0.0000) Steps 886(876.33) | Grad Norm 2.7700(2.4276) | Total Time 14.00(14.00)\n",
      "Iter 5990 | Time 21.2847(20.8983) | Bit/dim 3.4473(3.4709) | Xent 0.0000(0.0000) | Loss 3.4473(3.4709) | Error 0.0000(0.0000) Steps 892(876.95) | Grad Norm 1.9448(2.5815) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 103.8848, Epoch Time 1270.3675(1228.2300), Bit/dim 3.4741(best: 3.4744), Xent 0.0000, Loss 3.4741, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6000 | Time 21.4784(20.9578) | Bit/dim 3.4731(3.4714) | Xent 0.0000(0.0000) | Loss 3.4731(3.4714) | Error 0.0000(0.0000) Steps 880(878.22) | Grad Norm 1.8979(2.4441) | Total Time 14.00(14.00)\n",
      "Iter 6010 | Time 21.8357(20.8983) | Bit/dim 3.4671(3.4720) | Xent 0.0000(0.0000) | Loss 3.4671(3.4720) | Error 0.0000(0.0000) Steps 874(876.18) | Grad Norm 1.6031(2.4741) | Total Time 14.00(14.00)\n",
      "Iter 6020 | Time 21.0373(20.9178) | Bit/dim 3.4619(3.4716) | Xent 0.0000(0.0000) | Loss 3.4619(3.4716) | Error 0.0000(0.0000) Steps 886(876.02) | Grad Norm 1.8658(2.4041) | Total Time 14.00(14.00)\n",
      "Iter 6030 | Time 20.9881(20.8615) | Bit/dim 3.4702(3.4719) | Xent 0.0000(0.0000) | Loss 3.4702(3.4719) | Error 0.0000(0.0000) Steps 880(876.65) | Grad Norm 3.6883(2.4427) | Total Time 14.00(14.00)\n",
      "Iter 6040 | Time 21.2619(20.8998) | Bit/dim 3.4963(3.4737) | Xent 0.0000(0.0000) | Loss 3.4963(3.4737) | Error 0.0000(0.0000) Steps 862(877.45) | Grad Norm 2.1734(2.4221) | Total Time 14.00(14.00)\n",
      "Iter 6050 | Time 21.5505(20.8800) | Bit/dim 3.4603(3.4729) | Xent 0.0000(0.0000) | Loss 3.4603(3.4729) | Error 0.0000(0.0000) Steps 856(877.48) | Grad Norm 3.5257(2.3845) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 103.8552, Epoch Time 1269.6836(1229.4736), Bit/dim 3.4792(best: 3.4741), Xent 0.0000, Loss 3.4792, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6060 | Time 20.4957(20.8436) | Bit/dim 3.4816(3.4751) | Xent 0.0000(0.0000) | Loss 3.4816(3.4751) | Error 0.0000(0.0000) Steps 874(877.95) | Grad Norm 2.5404(2.4941) | Total Time 14.00(14.00)\n",
      "Iter 6070 | Time 20.5594(20.9043) | Bit/dim 3.4511(3.4729) | Xent 0.0000(0.0000) | Loss 3.4511(3.4729) | Error 0.0000(0.0000) Steps 856(878.56) | Grad Norm 2.2316(2.4242) | Total Time 14.00(14.00)\n",
      "Iter 6080 | Time 21.3387(20.9415) | Bit/dim 3.4621(3.4729) | Xent 0.0000(0.0000) | Loss 3.4621(3.4729) | Error 0.0000(0.0000) Steps 874(878.08) | Grad Norm 1.5962(2.3943) | Total Time 14.00(14.00)\n",
      "Iter 6090 | Time 20.6102(20.8825) | Bit/dim 3.4867(3.4740) | Xent 0.0000(0.0000) | Loss 3.4867(3.4740) | Error 0.0000(0.0000) Steps 892(875.77) | Grad Norm 1.4536(2.4360) | Total Time 14.00(14.00)\n",
      "Iter 6100 | Time 20.7727(20.8989) | Bit/dim 3.4577(3.4729) | Xent 0.0000(0.0000) | Loss 3.4577(3.4729) | Error 0.0000(0.0000) Steps 892(877.40) | Grad Norm 2.8505(2.3073) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 102.3949, Epoch Time 1268.5218(1230.6450), Bit/dim 3.4757(best: 3.4741), Xent 0.0000, Loss 3.4757, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6110 | Time 20.5710(20.8394) | Bit/dim 3.4529(3.4698) | Xent 0.0000(0.0000) | Loss 3.4529(3.4698) | Error 0.0000(0.0000) Steps 868(875.76) | Grad Norm 1.8890(2.4507) | Total Time 14.00(14.00)\n",
      "Iter 6120 | Time 21.0429(20.8992) | Bit/dim 3.4520(3.4680) | Xent 0.0000(0.0000) | Loss 3.4520(3.4680) | Error 0.0000(0.0000) Steps 880(877.95) | Grad Norm 2.0631(2.3364) | Total Time 14.00(14.00)\n",
      "Iter 6130 | Time 21.1709(20.8735) | Bit/dim 3.4734(3.4682) | Xent 0.0000(0.0000) | Loss 3.4734(3.4682) | Error 0.0000(0.0000) Steps 886(880.86) | Grad Norm 1.8353(2.3899) | Total Time 14.00(14.00)\n",
      "Iter 6140 | Time 21.0480(20.8425) | Bit/dim 3.4783(3.4695) | Xent 0.0000(0.0000) | Loss 3.4783(3.4695) | Error 0.0000(0.0000) Steps 862(880.81) | Grad Norm 3.0605(2.5106) | Total Time 14.00(14.00)\n",
      "Iter 6150 | Time 20.6564(20.8927) | Bit/dim 3.4726(3.4689) | Xent 0.0000(0.0000) | Loss 3.4726(3.4689) | Error 0.0000(0.0000) Steps 886(881.41) | Grad Norm 3.4277(2.5502) | Total Time 14.00(14.00)\n",
      "Iter 6160 | Time 21.7386(20.8961) | Bit/dim 3.5030(3.4707) | Xent 0.0000(0.0000) | Loss 3.5030(3.4707) | Error 0.0000(0.0000) Steps 874(883.48) | Grad Norm 2.0389(2.4454) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 104.3030, Epoch Time 1271.4111(1231.8680), Bit/dim 3.4706(best: 3.4741), Xent 0.0000, Loss 3.4706, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6170 | Time 20.4568(20.8750) | Bit/dim 3.4831(3.4697) | Xent 0.0000(0.0000) | Loss 3.4831(3.4697) | Error 0.0000(0.0000) Steps 886(882.64) | Grad Norm 4.2418(2.5024) | Total Time 14.00(14.00)\n",
      "Iter 6180 | Time 20.8410(20.8625) | Bit/dim 3.4529(3.4718) | Xent 0.0000(0.0000) | Loss 3.4529(3.4718) | Error 0.0000(0.0000) Steps 874(881.65) | Grad Norm 1.6504(2.4405) | Total Time 14.00(14.00)\n",
      "Iter 6190 | Time 21.3780(20.9070) | Bit/dim 3.4639(3.4732) | Xent 0.0000(0.0000) | Loss 3.4639(3.4732) | Error 0.0000(0.0000) Steps 880(878.67) | Grad Norm 1.9813(2.2874) | Total Time 14.00(14.00)\n",
      "Iter 6200 | Time 21.0535(20.9610) | Bit/dim 3.4818(3.4723) | Xent 0.0000(0.0000) | Loss 3.4818(3.4723) | Error 0.0000(0.0000) Steps 892(880.50) | Grad Norm 1.9228(2.3829) | Total Time 14.00(14.00)\n",
      "Iter 6210 | Time 20.6122(20.9042) | Bit/dim 3.4398(3.4685) | Xent 0.0000(0.0000) | Loss 3.4398(3.4685) | Error 0.0000(0.0000) Steps 892(880.30) | Grad Norm 2.3881(2.3669) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 104.5556, Epoch Time 1272.8317(1233.0969), Bit/dim 3.4669(best: 3.4706), Xent 0.0000, Loss 3.4669, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6220 | Time 20.0033(20.8900) | Bit/dim 3.4992(3.4674) | Xent 0.0000(0.0000) | Loss 3.4992(3.4674) | Error 0.0000(0.0000) Steps 874(881.36) | Grad Norm 2.9210(2.3603) | Total Time 14.00(14.00)\n",
      "Iter 6230 | Time 20.8468(20.9066) | Bit/dim 3.4940(3.4681) | Xent 0.0000(0.0000) | Loss 3.4940(3.4681) | Error 0.0000(0.0000) Steps 886(882.38) | Grad Norm 2.1932(2.4149) | Total Time 14.00(14.00)\n",
      "Iter 6240 | Time 21.1959(20.9323) | Bit/dim 3.5039(3.4708) | Xent 0.0000(0.0000) | Loss 3.5039(3.4708) | Error 0.0000(0.0000) Steps 874(882.83) | Grad Norm 1.9405(2.5329) | Total Time 14.00(14.00)\n",
      "Iter 6250 | Time 20.5382(20.8203) | Bit/dim 3.4805(3.4696) | Xent 0.0000(0.0000) | Loss 3.4805(3.4696) | Error 0.0000(0.0000) Steps 850(879.50) | Grad Norm 2.1684(2.4977) | Total Time 14.00(14.00)\n",
      "Iter 6260 | Time 20.6276(20.7822) | Bit/dim 3.4626(3.4684) | Xent 0.0000(0.0000) | Loss 3.4626(3.4684) | Error 0.0000(0.0000) Steps 868(877.49) | Grad Norm 3.3969(2.5359) | Total Time 14.00(14.00)\n",
      "Iter 6270 | Time 20.6772(20.8745) | Bit/dim 3.4452(3.4660) | Xent 0.0000(0.0000) | Loss 3.4452(3.4660) | Error 0.0000(0.0000) Steps 904(877.41) | Grad Norm 2.1989(2.5100) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 105.4858, Epoch Time 1269.8989(1234.2010), Bit/dim 3.4705(best: 3.4669), Xent 0.0000, Loss 3.4705, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6280 | Time 21.2259(20.8660) | Bit/dim 3.4963(3.4670) | Xent 0.0000(0.0000) | Loss 3.4963(3.4670) | Error 0.0000(0.0000) Steps 898(879.08) | Grad Norm 1.9705(2.4922) | Total Time 14.00(14.00)\n",
      "Iter 6290 | Time 20.7595(20.8389) | Bit/dim 3.4604(3.4649) | Xent 0.0000(0.0000) | Loss 3.4604(3.4649) | Error 0.0000(0.0000) Steps 868(878.53) | Grad Norm 2.4809(2.5483) | Total Time 14.00(14.00)\n",
      "Iter 6300 | Time 20.9635(20.7945) | Bit/dim 3.4772(3.4689) | Xent 0.0000(0.0000) | Loss 3.4772(3.4689) | Error 0.0000(0.0000) Steps 880(878.41) | Grad Norm 1.6074(2.4349) | Total Time 14.00(14.00)\n",
      "Iter 6310 | Time 20.5368(20.8245) | Bit/dim 3.4855(3.4670) | Xent 0.0000(0.0000) | Loss 3.4855(3.4670) | Error 0.0000(0.0000) Steps 892(882.38) | Grad Norm 1.7654(2.5775) | Total Time 14.00(14.00)\n",
      "Iter 6320 | Time 21.0441(20.8438) | Bit/dim 3.4673(3.4657) | Xent 0.0000(0.0000) | Loss 3.4673(3.4657) | Error 0.0000(0.0000) Steps 898(883.18) | Grad Norm 1.3027(2.4798) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 104.6246, Epoch Time 1265.7841(1235.1485), Bit/dim 3.4724(best: 3.4669), Xent 0.0000, Loss 3.4724, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6330 | Time 20.4955(20.8401) | Bit/dim 3.4718(3.4686) | Xent 0.0000(0.0000) | Loss 3.4718(3.4686) | Error 0.0000(0.0000) Steps 886(882.35) | Grad Norm 1.8742(2.4797) | Total Time 14.00(14.00)\n",
      "Iter 6340 | Time 21.0533(20.8769) | Bit/dim 3.4360(3.4673) | Xent 0.0000(0.0000) | Loss 3.4360(3.4673) | Error 0.0000(0.0000) Steps 886(883.93) | Grad Norm 2.1246(2.4155) | Total Time 14.00(14.00)\n",
      "Iter 6350 | Time 20.8386(20.9461) | Bit/dim 3.4672(3.4658) | Xent 0.0000(0.0000) | Loss 3.4672(3.4658) | Error 0.0000(0.0000) Steps 868(881.64) | Grad Norm 1.9196(2.3706) | Total Time 14.00(14.00)\n",
      "Iter 6360 | Time 21.4736(20.9616) | Bit/dim 3.5077(3.4659) | Xent 0.0000(0.0000) | Loss 3.5077(3.4659) | Error 0.0000(0.0000) Steps 886(881.73) | Grad Norm 3.3306(2.3184) | Total Time 14.00(14.00)\n",
      "Iter 6370 | Time 20.8613(20.9167) | Bit/dim 3.4548(3.4643) | Xent 0.0000(0.0000) | Loss 3.4548(3.4643) | Error 0.0000(0.0000) Steps 862(881.74) | Grad Norm 2.5681(2.4483) | Total Time 14.00(14.00)\n",
      "Iter 6380 | Time 20.9806(21.0658) | Bit/dim 3.4116(3.4644) | Xent 0.0000(0.0000) | Loss 3.4116(3.4644) | Error 0.0000(0.0000) Steps 880(883.06) | Grad Norm 1.8373(2.2135) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 103.9920, Epoch Time 1281.0630(1236.5259), Bit/dim 3.4693(best: 3.4669), Xent 0.0000, Loss 3.4693, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6390 | Time 21.7188(21.0741) | Bit/dim 3.4821(3.4647) | Xent 0.0000(0.0000) | Loss 3.4821(3.4647) | Error 0.0000(0.0000) Steps 904(883.90) | Grad Norm 2.2430(2.4473) | Total Time 14.00(14.00)\n",
      "Iter 6400 | Time 20.9038(20.9984) | Bit/dim 3.4638(3.4668) | Xent 0.0000(0.0000) | Loss 3.4638(3.4668) | Error 0.0000(0.0000) Steps 892(883.13) | Grad Norm 1.2909(2.4218) | Total Time 14.00(14.00)\n",
      "Iter 6410 | Time 20.8726(21.0220) | Bit/dim 3.4254(3.4653) | Xent 0.0000(0.0000) | Loss 3.4254(3.4653) | Error 0.0000(0.0000) Steps 862(882.67) | Grad Norm 2.0763(2.2260) | Total Time 14.00(14.00)\n",
      "Iter 6420 | Time 21.0807(20.9739) | Bit/dim 3.4542(3.4667) | Xent 0.0000(0.0000) | Loss 3.4542(3.4667) | Error 0.0000(0.0000) Steps 886(882.22) | Grad Norm 3.7578(2.3063) | Total Time 14.00(14.00)\n",
      "Iter 6430 | Time 21.5085(20.9903) | Bit/dim 3.4286(3.4653) | Xent 0.0000(0.0000) | Loss 3.4286(3.4653) | Error 0.0000(0.0000) Steps 910(881.56) | Grad Norm 2.1954(2.3800) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 104.2865, Epoch Time 1275.0691(1237.6822), Bit/dim 3.4638(best: 3.4669), Xent 0.0000, Loss 3.4638, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6440 | Time 21.4324(21.0547) | Bit/dim 3.4600(3.4612) | Xent 0.0000(0.0000) | Loss 3.4600(3.4612) | Error 0.0000(0.0000) Steps 898(883.16) | Grad Norm 1.7896(2.2699) | Total Time 14.00(14.00)\n",
      "Iter 6450 | Time 20.7018(20.9988) | Bit/dim 3.4536(3.4613) | Xent 0.0000(0.0000) | Loss 3.4536(3.4613) | Error 0.0000(0.0000) Steps 886(883.75) | Grad Norm 2.6854(2.4258) | Total Time 14.00(14.00)\n",
      "Iter 6460 | Time 21.3613(21.1169) | Bit/dim 3.4425(3.4608) | Xent 0.0000(0.0000) | Loss 3.4425(3.4608) | Error 0.0000(0.0000) Steps 886(885.05) | Grad Norm 2.7997(2.4959) | Total Time 14.00(14.00)\n",
      "Iter 6470 | Time 21.0270(21.1283) | Bit/dim 3.4951(3.4616) | Xent 0.0000(0.0000) | Loss 3.4951(3.4616) | Error 0.0000(0.0000) Steps 904(887.48) | Grad Norm 2.8171(2.4116) | Total Time 14.00(14.00)\n",
      "Iter 6480 | Time 20.8244(21.1194) | Bit/dim 3.4441(3.4637) | Xent 0.0000(0.0000) | Loss 3.4441(3.4637) | Error 0.0000(0.0000) Steps 880(887.03) | Grad Norm 2.2984(2.4101) | Total Time 14.00(14.00)\n",
      "Iter 6490 | Time 21.1471(21.0475) | Bit/dim 3.4528(3.4630) | Xent 0.0000(0.0000) | Loss 3.4528(3.4630) | Error 0.0000(0.0000) Steps 892(886.97) | Grad Norm 2.5260(2.3323) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 105.0994, Epoch Time 1284.7743(1239.0950), Bit/dim 3.4654(best: 3.4638), Xent 0.0000, Loss 3.4654, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6500 | Time 21.1609(21.0380) | Bit/dim 3.4767(3.4640) | Xent 0.0000(0.0000) | Loss 3.4767(3.4640) | Error 0.0000(0.0000) Steps 910(886.87) | Grad Norm 2.5712(2.4604) | Total Time 14.00(14.00)\n",
      "Iter 6510 | Time 21.7709(21.0922) | Bit/dim 3.4682(3.4647) | Xent 0.0000(0.0000) | Loss 3.4682(3.4647) | Error 0.0000(0.0000) Steps 886(887.31) | Grad Norm 2.5800(2.4761) | Total Time 14.00(14.00)\n",
      "Iter 6520 | Time 21.6980(21.0397) | Bit/dim 3.4819(3.4656) | Xent 0.0000(0.0000) | Loss 3.4819(3.4656) | Error 0.0000(0.0000) Steps 880(887.32) | Grad Norm 3.1418(2.5162) | Total Time 14.00(14.00)\n",
      "Iter 6530 | Time 20.7328(21.0339) | Bit/dim 3.4523(3.4640) | Xent 0.0000(0.0000) | Loss 3.4523(3.4640) | Error 0.0000(0.0000) Steps 874(886.28) | Grad Norm 3.3067(2.5283) | Total Time 14.00(14.00)\n",
      "Iter 6540 | Time 21.3602(21.0717) | Bit/dim 3.4537(3.4614) | Xent 0.0000(0.0000) | Loss 3.4537(3.4614) | Error 0.0000(0.0000) Steps 874(886.14) | Grad Norm 2.2863(2.5130) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 105.1781, Epoch Time 1282.2408(1240.3893), Bit/dim 3.4685(best: 3.4638), Xent 0.0000, Loss 3.4685, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6550 | Time 20.5358(21.0967) | Bit/dim 3.4767(3.4599) | Xent 0.0000(0.0000) | Loss 3.4767(3.4599) | Error 0.0000(0.0000) Steps 880(890.02) | Grad Norm 2.3665(2.4914) | Total Time 14.00(14.00)\n",
      "Iter 6560 | Time 21.0470(21.1552) | Bit/dim 3.4666(3.4616) | Xent 0.0000(0.0000) | Loss 3.4666(3.4616) | Error 0.0000(0.0000) Steps 910(892.88) | Grad Norm 2.2770(2.3699) | Total Time 14.00(14.00)\n",
      "Iter 6570 | Time 21.3760(21.0850) | Bit/dim 3.4288(3.4596) | Xent 0.0000(0.0000) | Loss 3.4288(3.4596) | Error 0.0000(0.0000) Steps 898(891.57) | Grad Norm 1.8781(2.3251) | Total Time 14.00(14.00)\n",
      "Iter 6580 | Time 20.2883(21.0762) | Bit/dim 3.4798(3.4605) | Xent 0.0000(0.0000) | Loss 3.4798(3.4605) | Error 0.0000(0.0000) Steps 868(889.59) | Grad Norm 2.7885(2.3410) | Total Time 14.00(14.00)\n",
      "Iter 6590 | Time 20.7439(21.0839) | Bit/dim 3.4358(3.4616) | Xent 0.0000(0.0000) | Loss 3.4358(3.4616) | Error 0.0000(0.0000) Steps 886(888.66) | Grad Norm 2.7971(2.3329) | Total Time 14.00(14.00)\n",
      "Iter 6600 | Time 20.9341(21.1169) | Bit/dim 3.4708(3.4617) | Xent 0.0000(0.0000) | Loss 3.4708(3.4617) | Error 0.0000(0.0000) Steps 892(889.00) | Grad Norm 2.4382(2.4675) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 104.1642, Epoch Time 1283.3352(1241.6777), Bit/dim 3.4623(best: 3.4638), Xent 0.0000, Loss 3.4623, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6610 | Time 20.2181(21.1076) | Bit/dim 3.4491(3.4624) | Xent 0.0000(0.0000) | Loss 3.4491(3.4624) | Error 0.0000(0.0000) Steps 874(885.26) | Grad Norm 3.2163(2.4381) | Total Time 14.00(14.00)\n",
      "Iter 6620 | Time 20.1949(21.0646) | Bit/dim 3.4697(3.4603) | Xent 0.0000(0.0000) | Loss 3.4697(3.4603) | Error 0.0000(0.0000) Steps 892(886.24) | Grad Norm 2.0727(2.4222) | Total Time 14.00(14.00)\n",
      "Iter 6630 | Time 20.5575(21.0835) | Bit/dim 3.4714(3.4603) | Xent 0.0000(0.0000) | Loss 3.4714(3.4603) | Error 0.0000(0.0000) Steps 880(887.48) | Grad Norm 2.5031(2.4635) | Total Time 14.00(14.00)\n",
      "Iter 6640 | Time 21.3947(21.1447) | Bit/dim 3.4323(3.4603) | Xent 0.0000(0.0000) | Loss 3.4323(3.4603) | Error 0.0000(0.0000) Steps 904(888.01) | Grad Norm 2.5942(2.4081) | Total Time 14.00(14.00)\n",
      "Iter 6650 | Time 21.4488(21.1214) | Bit/dim 3.4483(3.4609) | Xent 0.0000(0.0000) | Loss 3.4483(3.4609) | Error 0.0000(0.0000) Steps 898(888.72) | Grad Norm 2.5686(2.5154) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 102.8636, Epoch Time 1282.7310(1242.9093), Bit/dim 3.4623(best: 3.4623), Xent 0.0000, Loss 3.4623, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6660 | Time 21.1821(21.1482) | Bit/dim 3.4903(3.4614) | Xent 0.0000(0.0000) | Loss 3.4903(3.4614) | Error 0.0000(0.0000) Steps 886(888.13) | Grad Norm 2.5060(2.3385) | Total Time 14.00(14.00)\n",
      "Iter 6670 | Time 21.5128(21.1643) | Bit/dim 3.4786(3.4624) | Xent 0.0000(0.0000) | Loss 3.4786(3.4624) | Error 0.0000(0.0000) Steps 898(891.00) | Grad Norm 2.4015(2.4332) | Total Time 14.00(14.00)\n",
      "Iter 6680 | Time 20.8393(21.2073) | Bit/dim 3.4522(3.4602) | Xent 0.0000(0.0000) | Loss 3.4522(3.4602) | Error 0.0000(0.0000) Steps 904(892.49) | Grad Norm 2.3770(2.4479) | Total Time 14.00(14.00)\n",
      "Iter 6690 | Time 22.2650(21.1991) | Bit/dim 3.4664(3.4627) | Xent 0.0000(0.0000) | Loss 3.4664(3.4627) | Error 0.0000(0.0000) Steps 922(891.97) | Grad Norm 1.6131(2.3999) | Total Time 14.00(14.00)\n",
      "Iter 6700 | Time 21.5440(21.1790) | Bit/dim 3.4564(3.4611) | Xent 0.0000(0.0000) | Loss 3.4564(3.4611) | Error 0.0000(0.0000) Steps 868(889.69) | Grad Norm 3.7147(2.4788) | Total Time 14.00(14.00)\n",
      "Iter 6710 | Time 21.5635(21.1632) | Bit/dim 3.4385(3.4573) | Xent 0.0000(0.0000) | Loss 3.4385(3.4573) | Error 0.0000(0.0000) Steps 892(889.56) | Grad Norm 1.7683(2.4109) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 102.7652, Epoch Time 1285.7153(1244.1935), Bit/dim 3.4626(best: 3.4623), Xent 0.0000, Loss 3.4626, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6720 | Time 21.0688(21.1410) | Bit/dim 3.4272(3.4561) | Xent 0.0000(0.0000) | Loss 3.4272(3.4561) | Error 0.0000(0.0000) Steps 886(889.26) | Grad Norm 3.1080(2.3785) | Total Time 14.00(14.00)\n",
      "Iter 6730 | Time 21.3811(21.1540) | Bit/dim 3.4573(3.4567) | Xent 0.0000(0.0000) | Loss 3.4573(3.4567) | Error 0.0000(0.0000) Steps 868(888.26) | Grad Norm 1.3597(2.4040) | Total Time 14.00(14.00)\n",
      "Iter 6740 | Time 20.6450(21.1759) | Bit/dim 3.4657(3.4573) | Xent 0.0000(0.0000) | Loss 3.4657(3.4573) | Error 0.0000(0.0000) Steps 898(887.49) | Grad Norm 3.6453(2.3398) | Total Time 14.00(14.00)\n",
      "Iter 6750 | Time 20.8863(21.1461) | Bit/dim 3.4923(3.4604) | Xent 0.0000(0.0000) | Loss 3.4923(3.4604) | Error 0.0000(0.0000) Steps 904(890.05) | Grad Norm 2.8924(2.3532) | Total Time 14.00(14.00)\n",
      "Iter 6760 | Time 21.2907(21.2473) | Bit/dim 3.4302(3.4576) | Xent 0.0000(0.0000) | Loss 3.4302(3.4576) | Error 0.0000(0.0000) Steps 856(888.88) | Grad Norm 2.2952(2.2900) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 104.2419, Epoch Time 1286.8552(1245.4733), Bit/dim 3.4577(best: 3.4623), Xent 0.0000, Loss 3.4577, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6770 | Time 20.9167(21.1749) | Bit/dim 3.4801(3.4599) | Xent 0.0000(0.0000) | Loss 3.4801(3.4599) | Error 0.0000(0.0000) Steps 892(887.27) | Grad Norm 3.1796(2.4495) | Total Time 14.00(14.00)\n",
      "Iter 6780 | Time 21.4105(21.1481) | Bit/dim 3.4554(3.4602) | Xent 0.0000(0.0000) | Loss 3.4554(3.4602) | Error 0.0000(0.0000) Steps 892(886.29) | Grad Norm 1.5504(2.3032) | Total Time 14.00(14.00)\n",
      "Iter 6790 | Time 20.6429(21.1066) | Bit/dim 3.4666(3.4592) | Xent 0.0000(0.0000) | Loss 3.4666(3.4592) | Error 0.0000(0.0000) Steps 874(884.43) | Grad Norm 2.6201(2.3933) | Total Time 14.00(14.00)\n",
      "Iter 6800 | Time 21.7589(21.1886) | Bit/dim 3.4744(3.4591) | Xent 0.0000(0.0000) | Loss 3.4744(3.4591) | Error 0.0000(0.0000) Steps 892(887.46) | Grad Norm 1.4223(2.4210) | Total Time 14.00(14.00)\n",
      "Iter 6810 | Time 21.2109(21.2284) | Bit/dim 3.4624(3.4585) | Xent 0.0000(0.0000) | Loss 3.4624(3.4585) | Error 0.0000(0.0000) Steps 910(889.44) | Grad Norm 2.5530(2.4401) | Total Time 14.00(14.00)\n",
      "Iter 6820 | Time 21.3081(21.2657) | Bit/dim 3.4499(3.4582) | Xent 0.0000(0.0000) | Loss 3.4499(3.4582) | Error 0.0000(0.0000) Steps 886(888.70) | Grad Norm 2.2772(2.3286) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 104.2283, Epoch Time 1289.6003(1246.7971), Bit/dim 3.4577(best: 3.4577), Xent 0.0000, Loss 3.4577, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6830 | Time 21.5534(21.2293) | Bit/dim 3.4338(3.4591) | Xent 0.0000(0.0000) | Loss 3.4338(3.4591) | Error 0.0000(0.0000) Steps 892(888.90) | Grad Norm 2.0255(2.3732) | Total Time 14.00(14.00)\n",
      "Iter 6840 | Time 21.9195(21.2851) | Bit/dim 3.4238(3.4569) | Xent 0.0000(0.0000) | Loss 3.4238(3.4569) | Error 0.0000(0.0000) Steps 904(893.19) | Grad Norm 1.7390(2.3115) | Total Time 14.00(14.00)\n",
      "Iter 6850 | Time 21.1806(21.2576) | Bit/dim 3.4821(3.4550) | Xent 0.0000(0.0000) | Loss 3.4821(3.4550) | Error 0.0000(0.0000) Steps 898(894.99) | Grad Norm 2.4399(2.4524) | Total Time 14.00(14.00)\n",
      "Iter 6860 | Time 21.3976(21.2811) | Bit/dim 3.4426(3.4570) | Xent 0.0000(0.0000) | Loss 3.4426(3.4570) | Error 0.0000(0.0000) Steps 892(895.53) | Grad Norm 2.2057(2.3083) | Total Time 14.00(14.00)\n",
      "Iter 6870 | Time 21.6343(21.3014) | Bit/dim 3.4220(3.4562) | Xent 0.0000(0.0000) | Loss 3.4220(3.4562) | Error 0.0000(0.0000) Steps 916(898.40) | Grad Norm 2.0163(2.3002) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 104.6502, Epoch Time 1293.5328(1248.1992), Bit/dim 3.4570(best: 3.4577), Xent 0.0000, Loss 3.4570, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6880 | Time 21.8980(21.2977) | Bit/dim 3.4713(3.4559) | Xent 0.0000(0.0000) | Loss 3.4713(3.4559) | Error 0.0000(0.0000) Steps 916(897.05) | Grad Norm 2.5585(2.2316) | Total Time 14.00(14.00)\n",
      "Iter 6890 | Time 21.4020(21.2923) | Bit/dim 3.4631(3.4563) | Xent 0.0000(0.0000) | Loss 3.4631(3.4563) | Error 0.0000(0.0000) Steps 898(894.53) | Grad Norm 2.1167(2.3208) | Total Time 14.00(14.00)\n",
      "Iter 6900 | Time 21.3439(21.3032) | Bit/dim 3.4356(3.4585) | Xent 0.0000(0.0000) | Loss 3.4356(3.4585) | Error 0.0000(0.0000) Steps 886(894.52) | Grad Norm 2.4773(2.3235) | Total Time 14.00(14.00)\n",
      "Iter 6910 | Time 21.2306(21.3112) | Bit/dim 3.4670(3.4570) | Xent 0.0000(0.0000) | Loss 3.4670(3.4570) | Error 0.0000(0.0000) Steps 874(894.60) | Grad Norm 2.6262(2.3455) | Total Time 14.00(14.00)\n",
      "Iter 6920 | Time 21.7116(21.2949) | Bit/dim 3.4421(3.4566) | Xent 0.0000(0.0000) | Loss 3.4421(3.4566) | Error 0.0000(0.0000) Steps 904(895.27) | Grad Norm 2.9313(2.3773) | Total Time 14.00(14.00)\n",
      "Iter 6930 | Time 20.9105(21.3103) | Bit/dim 3.4663(3.4556) | Xent 0.0000(0.0000) | Loss 3.4663(3.4556) | Error 0.0000(0.0000) Steps 856(896.05) | Grad Norm 2.1397(2.3770) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 104.8926, Epoch Time 1294.4863(1249.5878), Bit/dim 3.4541(best: 3.4570), Xent 0.0000, Loss 3.4541, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6940 | Time 21.3877(21.3101) | Bit/dim 3.4588(3.4539) | Xent 0.0000(0.0000) | Loss 3.4588(3.4539) | Error 0.0000(0.0000) Steps 892(894.57) | Grad Norm 2.2197(2.3280) | Total Time 14.00(14.00)\n",
      "Iter 6950 | Time 20.9244(21.3291) | Bit/dim 3.4498(3.4523) | Xent 0.0000(0.0000) | Loss 3.4498(3.4523) | Error 0.0000(0.0000) Steps 916(895.51) | Grad Norm 2.4681(2.3939) | Total Time 14.00(14.00)\n",
      "Iter 6960 | Time 21.3934(21.3444) | Bit/dim 3.4594(3.4539) | Xent 0.0000(0.0000) | Loss 3.4594(3.4539) | Error 0.0000(0.0000) Steps 892(894.52) | Grad Norm 1.9028(2.4711) | Total Time 14.00(14.00)\n",
      "Iter 6970 | Time 22.2133(21.3697) | Bit/dim 3.4397(3.4541) | Xent 0.0000(0.0000) | Loss 3.4397(3.4541) | Error 0.0000(0.0000) Steps 916(894.26) | Grad Norm 2.3913(2.4312) | Total Time 14.00(14.00)\n",
      "Iter 6980 | Time 21.1008(21.3041) | Bit/dim 3.4607(3.4561) | Xent 0.0000(0.0000) | Loss 3.4607(3.4561) | Error 0.0000(0.0000) Steps 904(893.41) | Grad Norm 1.5415(2.4965) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 104.9677, Epoch Time 1295.2234(1250.9569), Bit/dim 3.4549(best: 3.4541), Xent 0.0000, Loss 3.4549, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6990 | Time 21.6589(21.2944) | Bit/dim 3.4342(3.4542) | Xent 0.0000(0.0000) | Loss 3.4342(3.4542) | Error 0.0000(0.0000) Steps 892(895.30) | Grad Norm 2.0526(2.3819) | Total Time 14.00(14.00)\n",
      "Iter 7000 | Time 21.2788(21.3258) | Bit/dim 3.4822(3.4559) | Xent 0.0000(0.0000) | Loss 3.4822(3.4559) | Error 0.0000(0.0000) Steps 910(895.40) | Grad Norm 2.5288(2.4245) | Total Time 14.00(14.00)\n",
      "Iter 7010 | Time 20.4449(21.3035) | Bit/dim 3.4594(3.4546) | Xent 0.0000(0.0000) | Loss 3.4594(3.4546) | Error 0.0000(0.0000) Steps 856(891.92) | Grad Norm 2.4465(2.4097) | Total Time 14.00(14.00)\n",
      "Iter 7020 | Time 22.2583(21.3883) | Bit/dim 3.4490(3.4529) | Xent 0.0000(0.0000) | Loss 3.4490(3.4529) | Error 0.0000(0.0000) Steps 904(893.70) | Grad Norm 2.6030(2.2497) | Total Time 14.00(14.00)\n",
      "Iter 7030 | Time 21.3831(21.3517) | Bit/dim 3.4603(3.4565) | Xent 0.0000(0.0000) | Loss 3.4603(3.4565) | Error 0.0000(0.0000) Steps 910(895.28) | Grad Norm 2.2588(2.3902) | Total Time 14.00(14.00)\n",
      "Iter 7040 | Time 22.1298(21.3465) | Bit/dim 3.4597(3.4534) | Xent 0.0000(0.0000) | Loss 3.4597(3.4534) | Error 0.0000(0.0000) Steps 910(897.55) | Grad Norm 2.5969(2.3619) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 106.2728, Epoch Time 1299.2100(1252.4045), Bit/dim 3.4550(best: 3.4541), Xent 0.0000, Loss 3.4550, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7050 | Time 20.7828(21.3318) | Bit/dim 3.4284(3.4523) | Xent 0.0000(0.0000) | Loss 3.4284(3.4523) | Error 0.0000(0.0000) Steps 886(901.50) | Grad Norm 3.1305(2.3814) | Total Time 14.00(14.00)\n",
      "Iter 7060 | Time 21.3945(21.2765) | Bit/dim 3.4698(3.4524) | Xent 0.0000(0.0000) | Loss 3.4698(3.4524) | Error 0.0000(0.0000) Steps 916(898.97) | Grad Norm 1.7730(2.2754) | Total Time 14.00(14.00)\n",
      "Iter 7070 | Time 20.8967(21.2663) | Bit/dim 3.4153(3.4520) | Xent 0.0000(0.0000) | Loss 3.4153(3.4520) | Error 0.0000(0.0000) Steps 904(898.48) | Grad Norm 2.3105(2.3252) | Total Time 14.00(14.00)\n",
      "Iter 7080 | Time 21.3519(21.3287) | Bit/dim 3.4619(3.4505) | Xent 0.0000(0.0000) | Loss 3.4619(3.4505) | Error 0.0000(0.0000) Steps 922(899.12) | Grad Norm 2.8237(2.2797) | Total Time 14.00(14.00)\n",
      "Iter 7090 | Time 21.1567(21.2345) | Bit/dim 3.4319(3.4546) | Xent 0.0000(0.0000) | Loss 3.4319(3.4546) | Error 0.0000(0.0000) Steps 904(897.10) | Grad Norm 2.4442(2.3602) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 104.7382, Epoch Time 1288.7324(1253.4943), Bit/dim 3.4557(best: 3.4541), Xent 0.0000, Loss 3.4557, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7100 | Time 20.6935(21.2228) | Bit/dim 3.4989(3.4557) | Xent 0.0000(0.0000) | Loss 3.4989(3.4557) | Error 0.0000(0.0000) Steps 880(897.97) | Grad Norm 1.6628(2.3605) | Total Time 14.00(14.00)\n",
      "Iter 7110 | Time 21.1778(21.2014) | Bit/dim 3.4591(3.4557) | Xent 0.0000(0.0000) | Loss 3.4591(3.4557) | Error 0.0000(0.0000) Steps 892(898.43) | Grad Norm 3.9140(2.4429) | Total Time 14.00(14.00)\n",
      "Iter 7120 | Time 21.3079(21.2432) | Bit/dim 3.4736(3.4575) | Xent 0.0000(0.0000) | Loss 3.4736(3.4575) | Error 0.0000(0.0000) Steps 898(898.34) | Grad Norm 1.4917(2.3195) | Total Time 14.00(14.00)\n",
      "Iter 7130 | Time 21.5300(21.2543) | Bit/dim 3.4121(3.4533) | Xent 0.0000(0.0000) | Loss 3.4121(3.4533) | Error 0.0000(0.0000) Steps 910(897.67) | Grad Norm 2.5649(2.4156) | Total Time 14.00(14.00)\n",
      "Iter 7140 | Time 21.1687(21.2986) | Bit/dim 3.4481(3.4494) | Xent 0.0000(0.0000) | Loss 3.4481(3.4494) | Error 0.0000(0.0000) Steps 868(898.27) | Grad Norm 3.0102(2.4379) | Total Time 14.00(14.00)\n",
      "Iter 7150 | Time 21.0114(21.2381) | Bit/dim 3.4678(3.4503) | Xent 0.0000(0.0000) | Loss 3.4678(3.4503) | Error 0.0000(0.0000) Steps 904(897.90) | Grad Norm 1.5209(2.4285) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 103.6195, Epoch Time 1290.9547(1254.6181), Bit/dim 3.4499(best: 3.4541), Xent 0.0000, Loss 3.4499, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7160 | Time 20.5688(21.2176) | Bit/dim 3.4298(3.4518) | Xent 0.0000(0.0000) | Loss 3.4298(3.4518) | Error 0.0000(0.0000) Steps 898(897.07) | Grad Norm 2.1807(2.4630) | Total Time 14.00(14.00)\n",
      "Iter 7170 | Time 20.9779(21.2484) | Bit/dim 3.4581(3.4536) | Xent 0.0000(0.0000) | Loss 3.4581(3.4536) | Error 0.0000(0.0000) Steps 904(898.29) | Grad Norm 3.3978(2.4227) | Total Time 14.00(14.00)\n",
      "Iter 7180 | Time 21.1233(21.2746) | Bit/dim 3.4717(3.4530) | Xent 0.0000(0.0000) | Loss 3.4717(3.4530) | Error 0.0000(0.0000) Steps 892(899.40) | Grad Norm 2.2773(2.4711) | Total Time 14.00(14.00)\n",
      "Iter 7190 | Time 20.7381(21.2412) | Bit/dim 3.4263(3.4490) | Xent 0.0000(0.0000) | Loss 3.4263(3.4490) | Error 0.0000(0.0000) Steps 898(898.88) | Grad Norm 1.9978(2.3393) | Total Time 14.00(14.00)\n",
      "Iter 7200 | Time 20.7961(21.2239) | Bit/dim 3.4509(3.4503) | Xent 0.0000(0.0000) | Loss 3.4509(3.4503) | Error 0.0000(0.0000) Steps 904(899.17) | Grad Norm 3.4366(2.2171) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 105.5862, Epoch Time 1291.4595(1255.7234), Bit/dim 3.4554(best: 3.4499), Xent 0.0000, Loss 3.4554, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7210 | Time 21.2364(21.2360) | Bit/dim 3.4478(3.4473) | Xent 0.0000(0.0000) | Loss 3.4478(3.4473) | Error 0.0000(0.0000) Steps 898(896.96) | Grad Norm 2.4504(2.2755) | Total Time 14.00(14.00)\n",
      "Iter 7220 | Time 21.7504(21.3931) | Bit/dim 3.4221(3.4474) | Xent 0.0000(0.0000) | Loss 3.4221(3.4474) | Error 0.0000(0.0000) Steps 922(896.93) | Grad Norm 2.4394(2.3732) | Total Time 14.00(14.00)\n",
      "Iter 7230 | Time 21.5567(21.3956) | Bit/dim 3.4379(3.4485) | Xent 0.0000(0.0000) | Loss 3.4379(3.4485) | Error 0.0000(0.0000) Steps 928(898.71) | Grad Norm 1.7990(2.3184) | Total Time 14.00(14.00)\n",
      "Iter 7240 | Time 21.5445(21.4123) | Bit/dim 3.4457(3.4484) | Xent 0.0000(0.0000) | Loss 3.4457(3.4484) | Error 0.0000(0.0000) Steps 880(901.38) | Grad Norm 2.6105(2.2780) | Total Time 14.00(14.00)\n",
      "Iter 7250 | Time 20.9017(21.3503) | Bit/dim 3.4378(3.4503) | Xent 0.0000(0.0000) | Loss 3.4378(3.4503) | Error 0.0000(0.0000) Steps 886(900.36) | Grad Norm 2.6844(2.1707) | Total Time 14.00(14.00)\n",
      "Iter 7260 | Time 21.5553(21.3546) | Bit/dim 3.4502(3.4519) | Xent 0.0000(0.0000) | Loss 3.4502(3.4519) | Error 0.0000(0.0000) Steps 904(900.45) | Grad Norm 2.0181(2.4175) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 106.1674, Epoch Time 1303.3851(1257.1532), Bit/dim 3.4620(best: 3.4499), Xent 0.0000, Loss 3.4620, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7270 | Time 21.0193(21.3605) | Bit/dim 3.4519(3.4520) | Xent 0.0000(0.0000) | Loss 3.4519(3.4520) | Error 0.0000(0.0000) Steps 910(897.61) | Grad Norm 1.8889(2.4420) | Total Time 14.00(14.00)\n",
      "Iter 7280 | Time 21.0217(21.3667) | Bit/dim 3.4332(3.4507) | Xent 0.0000(0.0000) | Loss 3.4332(3.4507) | Error 0.0000(0.0000) Steps 892(899.11) | Grad Norm 1.3088(2.3450) | Total Time 14.00(14.00)\n",
      "Iter 7290 | Time 21.7695(21.3838) | Bit/dim 3.4256(3.4486) | Xent 0.0000(0.0000) | Loss 3.4256(3.4486) | Error 0.0000(0.0000) Steps 922(903.95) | Grad Norm 2.0652(2.2061) | Total Time 14.00(14.00)\n",
      "Iter 7300 | Time 20.7572(21.3807) | Bit/dim 3.4576(3.4496) | Xent 0.0000(0.0000) | Loss 3.4576(3.4496) | Error 0.0000(0.0000) Steps 886(903.86) | Grad Norm 4.2110(2.2354) | Total Time 14.00(14.00)\n",
      "Iter 7310 | Time 21.2270(21.3534) | Bit/dim 3.4730(3.4494) | Xent 0.0000(0.0000) | Loss 3.4730(3.4494) | Error 0.0000(0.0000) Steps 916(902.86) | Grad Norm 1.9454(2.2472) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 104.3002, Epoch Time 1297.3754(1258.3599), Bit/dim 3.4508(best: 3.4499), Xent 0.0000, Loss 3.4508, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7320 | Time 20.6688(21.3274) | Bit/dim 3.4637(3.4497) | Xent 0.0000(0.0000) | Loss 3.4637(3.4497) | Error 0.0000(0.0000) Steps 862(899.93) | Grad Norm 2.3470(2.2262) | Total Time 14.00(14.00)\n",
      "Iter 7330 | Time 21.0696(21.2929) | Bit/dim 3.4621(3.4519) | Xent 0.0000(0.0000) | Loss 3.4621(3.4519) | Error 0.0000(0.0000) Steps 892(899.05) | Grad Norm 2.0872(2.2966) | Total Time 14.00(14.00)\n",
      "Iter 7340 | Time 21.0366(21.2550) | Bit/dim 3.4517(3.4528) | Xent 0.0000(0.0000) | Loss 3.4517(3.4528) | Error 0.0000(0.0000) Steps 898(898.90) | Grad Norm 1.1509(2.2371) | Total Time 14.00(14.00)\n",
      "Iter 7350 | Time 21.6438(21.2654) | Bit/dim 3.4491(3.4488) | Xent 0.0000(0.0000) | Loss 3.4491(3.4488) | Error 0.0000(0.0000) Steps 892(899.05) | Grad Norm 2.3039(2.1050) | Total Time 14.00(14.00)\n",
      "Iter 7360 | Time 21.3510(21.3273) | Bit/dim 3.4304(3.4470) | Xent 0.0000(0.0000) | Loss 3.4304(3.4470) | Error 0.0000(0.0000) Steps 886(900.62) | Grad Norm 1.9789(2.2422) | Total Time 14.00(14.00)\n",
      "Iter 7370 | Time 21.0213(21.3796) | Bit/dim 3.4435(3.4470) | Xent 0.0000(0.0000) | Loss 3.4435(3.4470) | Error 0.0000(0.0000) Steps 898(900.18) | Grad Norm 1.6892(2.2071) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 104.7959, Epoch Time 1294.4565(1259.4428), Bit/dim 3.4465(best: 3.4499), Xent 0.0000, Loss 3.4465, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7380 | Time 21.7237(21.3674) | Bit/dim 3.4367(3.4482) | Xent 0.0000(0.0000) | Loss 3.4367(3.4482) | Error 0.0000(0.0000) Steps 922(898.74) | Grad Norm 3.2938(2.3088) | Total Time 14.00(14.00)\n",
      "Iter 7390 | Time 21.3828(21.3384) | Bit/dim 3.4557(3.4463) | Xent 0.0000(0.0000) | Loss 3.4557(3.4463) | Error 0.0000(0.0000) Steps 886(896.67) | Grad Norm 1.9462(2.2173) | Total Time 14.00(14.00)\n",
      "Iter 7400 | Time 21.2762(21.3154) | Bit/dim 3.4106(3.4444) | Xent 0.0000(0.0000) | Loss 3.4106(3.4444) | Error 0.0000(0.0000) Steps 922(896.69) | Grad Norm 1.7510(2.3377) | Total Time 14.00(14.00)\n",
      "Iter 7410 | Time 21.8210(21.3625) | Bit/dim 3.4741(3.4443) | Xent 0.0000(0.0000) | Loss 3.4741(3.4443) | Error 0.0000(0.0000) Steps 922(899.25) | Grad Norm 2.9009(2.3324) | Total Time 14.00(14.00)\n",
      "Iter 7420 | Time 22.0160(21.3958) | Bit/dim 3.4548(3.4483) | Xent 0.0000(0.0000) | Loss 3.4548(3.4483) | Error 0.0000(0.0000) Steps 898(901.96) | Grad Norm 1.3885(2.3249) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 105.0718, Epoch Time 1300.5181(1260.6751), Bit/dim 3.4483(best: 3.4465), Xent 0.0000, Loss 3.4483, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7430 | Time 21.3379(21.4387) | Bit/dim 3.4686(3.4482) | Xent 0.0000(0.0000) | Loss 3.4686(3.4482) | Error 0.0000(0.0000) Steps 880(905.02) | Grad Norm 1.2470(2.2270) | Total Time 14.00(14.00)\n",
      "Iter 7440 | Time 21.0912(21.4138) | Bit/dim 3.4644(3.4510) | Xent 0.0000(0.0000) | Loss 3.4644(3.4510) | Error 0.0000(0.0000) Steps 904(908.64) | Grad Norm 2.0416(2.1951) | Total Time 14.00(14.00)\n",
      "Iter 7450 | Time 20.6802(21.2954) | Bit/dim 3.4830(3.4489) | Xent 0.0000(0.0000) | Loss 3.4830(3.4489) | Error 0.0000(0.0000) Steps 886(907.69) | Grad Norm 2.5476(2.2898) | Total Time 14.00(14.00)\n",
      "Iter 7460 | Time 20.7199(21.2725) | Bit/dim 3.4505(3.4484) | Xent 0.0000(0.0000) | Loss 3.4505(3.4484) | Error 0.0000(0.0000) Steps 892(901.58) | Grad Norm 3.1197(2.2474) | Total Time 14.00(14.00)\n",
      "Iter 7470 | Time 20.6027(21.2386) | Bit/dim 3.4286(3.4469) | Xent 0.0000(0.0000) | Loss 3.4286(3.4469) | Error 0.0000(0.0000) Steps 904(901.12) | Grad Norm 1.8729(2.3731) | Total Time 14.00(14.00)\n",
      "Iter 7480 | Time 21.0988(21.2442) | Bit/dim 3.4363(3.4449) | Xent 0.0000(0.0000) | Loss 3.4363(3.4449) | Error 0.0000(0.0000) Steps 898(902.06) | Grad Norm 1.8953(2.2647) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Iter 7490 | Time 20.9445(21.2828) | Bit/dim 3.4433(3.4444) | Xent 0.0000(0.0000) | Loss 3.4433(3.4444) | Error 0.0000(0.0000) Steps 898(900.36) | Grad Norm 1.5665(2.2429) | Total Time 14.00(14.00)\n",
      "Iter 7500 | Time 21.5414(21.3534) | Bit/dim 3.4457(3.4456) | Xent 0.0000(0.0000) | Loss 3.4457(3.4456) | Error 0.0000(0.0000) Steps 910(900.06) | Grad Norm 2.4329(2.2579) | Total Time 14.00(14.00)\n",
      "Iter 7510 | Time 21.4788(21.4014) | Bit/dim 3.4209(3.4433) | Xent 0.0000(0.0000) | Loss 3.4209(3.4433) | Error 0.0000(0.0000) Steps 916(901.88) | Grad Norm 2.0852(2.3792) | Total Time 14.00(14.00)\n",
      "Iter 7520 | Time 21.1655(21.4311) | Bit/dim 3.4853(3.4466) | Xent 0.0000(0.0000) | Loss 3.4853(3.4466) | Error 0.0000(0.0000) Steps 928(906.24) | Grad Norm 2.9379(2.2856) | Total Time 14.00(14.00)\n",
      "Iter 7530 | Time 22.0051(21.4766) | Bit/dim 3.4497(3.4450) | Xent 0.0000(0.0000) | Loss 3.4497(3.4450) | Error 0.0000(0.0000) Steps 940(909.39) | Grad Norm 2.4405(2.3440) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 104.6313, Epoch Time 1307.5158(1262.8793), Bit/dim 3.4491(best: 3.4465), Xent 0.0000, Loss 3.4491, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7540 | Time 20.7511(21.4430) | Bit/dim 3.4545(3.4464) | Xent 0.0000(0.0000) | Loss 3.4545(3.4464) | Error 0.0000(0.0000) Steps 874(906.64) | Grad Norm 2.3193(2.5036) | Total Time 14.00(14.00)\n",
      "Iter 7550 | Time 21.0810(21.4533) | Bit/dim 3.4205(3.4451) | Xent 0.0000(0.0000) | Loss 3.4205(3.4451) | Error 0.0000(0.0000) Steps 886(903.50) | Grad Norm 2.8435(2.4403) | Total Time 14.00(14.00)\n",
      "Iter 7560 | Time 21.2927(21.4779) | Bit/dim 3.4260(3.4444) | Xent 0.0000(0.0000) | Loss 3.4260(3.4444) | Error 0.0000(0.0000) Steps 916(904.83) | Grad Norm 2.1704(2.4076) | Total Time 14.00(14.00)\n",
      "Iter 7570 | Time 21.3504(21.4933) | Bit/dim 3.4211(3.4429) | Xent 0.0000(0.0000) | Loss 3.4211(3.4429) | Error 0.0000(0.0000) Steps 916(906.37) | Grad Norm 2.1520(2.3648) | Total Time 14.00(14.00)\n",
      "Iter 7580 | Time 21.9804(21.5435) | Bit/dim 3.4208(3.4425) | Xent 0.0000(0.0000) | Loss 3.4208(3.4425) | Error 0.0000(0.0000) Steps 916(905.08) | Grad Norm 1.6387(2.2378) | Total Time 14.00(14.00)\n",
      "Iter 7590 | Time 21.1820(21.5095) | Bit/dim 3.4318(3.4445) | Xent 0.0000(0.0000) | Loss 3.4318(3.4445) | Error 0.0000(0.0000) Steps 910(905.03) | Grad Norm 3.2704(2.1892) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 105.8670, Epoch Time 1305.0100(1264.1432), Bit/dim 3.4492(best: 3.4465), Xent 0.0000, Loss 3.4492, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7600 | Time 21.2510(21.4676) | Bit/dim 3.4175(3.4448) | Xent 0.0000(0.0000) | Loss 3.4175(3.4448) | Error 0.0000(0.0000) Steps 880(901.61) | Grad Norm 2.7096(2.4482) | Total Time 14.00(14.00)\n",
      "Iter 7610 | Time 21.7462(21.4312) | Bit/dim 3.4635(3.4466) | Xent 0.0000(0.0000) | Loss 3.4635(3.4466) | Error 0.0000(0.0000) Steps 928(899.96) | Grad Norm 1.3696(2.1804) | Total Time 14.00(14.00)\n",
      "Iter 7620 | Time 21.3734(21.4004) | Bit/dim 3.4180(3.4425) | Xent 0.0000(0.0000) | Loss 3.4180(3.4425) | Error 0.0000(0.0000) Steps 928(900.01) | Grad Norm 3.4934(2.3219) | Total Time 14.00(14.00)\n",
      "Iter 7630 | Time 20.7297(21.3739) | Bit/dim 3.4180(3.4423) | Xent 0.0000(0.0000) | Loss 3.4180(3.4423) | Error 0.0000(0.0000) Steps 874(900.40) | Grad Norm 2.0644(2.4089) | Total Time 14.00(14.00)\n",
      "Iter 7640 | Time 20.9632(21.3331) | Bit/dim 3.4419(3.4454) | Xent 0.0000(0.0000) | Loss 3.4419(3.4454) | Error 0.0000(0.0000) Steps 904(899.41) | Grad Norm 2.3236(2.3939) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 105.7851, Epoch Time 1294.3050(1265.0480), Bit/dim 3.4436(best: 3.4465), Xent 0.0000, Loss 3.4436, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7650 | Time 21.7352(21.3579) | Bit/dim 3.4415(3.4440) | Xent 0.0000(0.0000) | Loss 3.4415(3.4440) | Error 0.0000(0.0000) Steps 904(899.24) | Grad Norm 2.0533(2.2908) | Total Time 14.00(14.00)\n",
      "Iter 7660 | Time 21.5098(21.3143) | Bit/dim 3.4500(3.4438) | Xent 0.0000(0.0000) | Loss 3.4500(3.4438) | Error 0.0000(0.0000) Steps 886(899.43) | Grad Norm 4.2067(2.4381) | Total Time 14.00(14.00)\n",
      "Iter 7670 | Time 21.5856(21.3457) | Bit/dim 3.4422(3.4425) | Xent 0.0000(0.0000) | Loss 3.4422(3.4425) | Error 0.0000(0.0000) Steps 904(901.61) | Grad Norm 2.0926(2.4477) | Total Time 14.00(14.00)\n",
      "Iter 7680 | Time 21.8227(21.3683) | Bit/dim 3.3939(3.4411) | Xent 0.0000(0.0000) | Loss 3.3939(3.4411) | Error 0.0000(0.0000) Steps 880(901.14) | Grad Norm 2.6023(2.2987) | Total Time 14.00(14.00)\n",
      "Iter 7690 | Time 20.7750(21.3738) | Bit/dim 3.4279(3.4418) | Xent 0.0000(0.0000) | Loss 3.4279(3.4418) | Error 0.0000(0.0000) Steps 892(901.29) | Grad Norm 2.8477(2.3317) | Total Time 14.00(14.00)\n",
      "Iter 7700 | Time 21.2432(21.3573) | Bit/dim 3.4426(3.4432) | Xent 0.0000(0.0000) | Loss 3.4426(3.4432) | Error 0.0000(0.0000) Steps 904(901.02) | Grad Norm 2.0576(2.3055) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 104.6584, Epoch Time 1298.6332(1266.0556), Bit/dim 3.4463(best: 3.4436), Xent 0.0000, Loss 3.4463, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7710 | Time 21.5666(21.4085) | Bit/dim 3.4316(3.4423) | Xent 0.0000(0.0000) | Loss 3.4316(3.4423) | Error 0.0000(0.0000) Steps 910(901.95) | Grad Norm 3.1163(2.2886) | Total Time 14.00(14.00)\n",
      "Iter 7720 | Time 20.8254(21.4229) | Bit/dim 3.4497(3.4423) | Xent 0.0000(0.0000) | Loss 3.4497(3.4423) | Error 0.0000(0.0000) Steps 880(899.34) | Grad Norm 1.7157(2.2670) | Total Time 14.00(14.00)\n",
      "Iter 7730 | Time 22.1541(21.4094) | Bit/dim 3.4453(3.4420) | Xent 0.0000(0.0000) | Loss 3.4453(3.4420) | Error 0.0000(0.0000) Steps 886(897.64) | Grad Norm 1.9752(2.2791) | Total Time 14.00(14.00)\n",
      "Iter 7740 | Time 21.4015(21.4368) | Bit/dim 3.4344(3.4422) | Xent 0.0000(0.0000) | Loss 3.4344(3.4422) | Error 0.0000(0.0000) Steps 892(898.77) | Grad Norm 2.0956(2.2502) | Total Time 14.00(14.00)\n",
      "Iter 7750 | Time 21.6645(21.4539) | Bit/dim 3.4264(3.4417) | Xent 0.0000(0.0000) | Loss 3.4264(3.4417) | Error 0.0000(0.0000) Steps 904(901.24) | Grad Norm 3.1862(2.3251) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0141 | Time 105.8910, Epoch Time 1304.1301(1267.1978), Bit/dim 3.4444(best: 3.4436), Xent 0.0000, Loss 3.4444, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7760 | Time 21.1384(21.4240) | Bit/dim 3.4782(3.4429) | Xent 0.0000(0.0000) | Loss 3.4782(3.4429) | Error 0.0000(0.0000) Steps 898(902.06) | Grad Norm 2.3381(2.3514) | Total Time 14.00(14.00)\n",
      "Iter 7770 | Time 21.5495(21.4052) | Bit/dim 3.4550(3.4447) | Xent 0.0000(0.0000) | Loss 3.4550(3.4447) | Error 0.0000(0.0000) Steps 910(901.46) | Grad Norm 2.6353(2.3620) | Total Time 14.00(14.00)\n",
      "Iter 7780 | Time 21.5516(21.4824) | Bit/dim 3.4567(3.4421) | Xent 0.0000(0.0000) | Loss 3.4567(3.4421) | Error 0.0000(0.0000) Steps 898(901.90) | Grad Norm 1.3168(2.2741) | Total Time 14.00(14.00)\n",
      "Iter 7790 | Time 20.9917(21.5195) | Bit/dim 3.4367(3.4448) | Xent 0.0000(0.0000) | Loss 3.4367(3.4448) | Error 0.0000(0.0000) Steps 904(903.50) | Grad Norm 3.1582(2.2834) | Total Time 14.00(14.00)\n",
      "Iter 7800 | Time 21.4300(21.5636) | Bit/dim 3.4491(3.4430) | Xent 0.0000(0.0000) | Loss 3.4491(3.4430) | Error 0.0000(0.0000) Steps 892(905.14) | Grad Norm 2.9354(2.3772) | Total Time 14.00(14.00)\n",
      "Iter 7810 | Time 21.5230(21.5251) | Bit/dim 3.4119(3.4408) | Xent 0.0000(0.0000) | Loss 3.4119(3.4408) | Error 0.0000(0.0000) Steps 904(902.08) | Grad Norm 1.6737(2.3092) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0142 | Time 104.9931, Epoch Time 1307.7618(1268.4148), Bit/dim 3.4422(best: 3.4436), Xent 0.0000, Loss 3.4422, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7820 | Time 21.8834(21.5034) | Bit/dim 3.4789(3.4420) | Xent 0.0000(0.0000) | Loss 3.4789(3.4420) | Error 0.0000(0.0000) Steps 916(902.58) | Grad Norm 1.5572(2.1381) | Total Time 14.00(14.00)\n",
      "Iter 7830 | Time 22.1001(21.5484) | Bit/dim 3.4399(3.4431) | Xent 0.0000(0.0000) | Loss 3.4399(3.4431) | Error 0.0000(0.0000) Steps 892(904.19) | Grad Norm 1.5165(2.0574) | Total Time 14.00(14.00)\n",
      "Iter 7840 | Time 21.6525(21.5231) | Bit/dim 3.4263(3.4436) | Xent 0.0000(0.0000) | Loss 3.4263(3.4436) | Error 0.0000(0.0000) Steps 922(903.07) | Grad Norm 2.7606(2.2861) | Total Time 14.00(14.00)\n",
      "Iter 7850 | Time 21.2668(21.5213) | Bit/dim 3.4273(3.4427) | Xent 0.0000(0.0000) | Loss 3.4273(3.4427) | Error 0.0000(0.0000) Steps 922(898.50) | Grad Norm 3.2714(2.2892) | Total Time 14.00(14.00)\n",
      "Iter 7860 | Time 21.7859(21.5991) | Bit/dim 3.4377(3.4392) | Xent 0.0000(0.0000) | Loss 3.4377(3.4392) | Error 0.0000(0.0000) Steps 898(899.61) | Grad Norm 2.9040(2.3886) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0143 | Time 107.2868, Epoch Time 1310.8128(1269.6867), Bit/dim 3.4410(best: 3.4422), Xent 0.0000, Loss 3.4410, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7870 | Time 21.9541(21.5556) | Bit/dim 3.4320(3.4370) | Xent 0.0000(0.0000) | Loss 3.4320(3.4370) | Error 0.0000(0.0000) Steps 916(903.23) | Grad Norm 1.7424(2.2232) | Total Time 14.00(14.00)\n",
      "Iter 7880 | Time 21.1169(21.5064) | Bit/dim 3.4152(3.4367) | Xent 0.0000(0.0000) | Loss 3.4152(3.4367) | Error 0.0000(0.0000) Steps 892(903.29) | Grad Norm 1.4903(2.3180) | Total Time 14.00(14.00)\n",
      "Iter 7890 | Time 20.2929(21.4102) | Bit/dim 3.4105(3.4364) | Xent 0.0000(0.0000) | Loss 3.4105(3.4364) | Error 0.0000(0.0000) Steps 886(903.29) | Grad Norm 2.9337(2.3406) | Total Time 14.00(14.00)\n",
      "Iter 7900 | Time 21.7360(21.4188) | Bit/dim 3.4493(3.4381) | Xent 0.0000(0.0000) | Loss 3.4493(3.4381) | Error 0.0000(0.0000) Steps 892(902.53) | Grad Norm 2.1063(2.2723) | Total Time 14.00(14.00)\n",
      "Iter 7910 | Time 21.5262(21.3526) | Bit/dim 3.4392(3.4383) | Xent 0.0000(0.0000) | Loss 3.4392(3.4383) | Error 0.0000(0.0000) Steps 892(902.36) | Grad Norm 1.6846(2.2367) | Total Time 14.00(14.00)\n",
      "Iter 7920 | Time 21.2535(21.3035) | Bit/dim 3.4201(3.4395) | Xent 0.0000(0.0000) | Loss 3.4201(3.4395) | Error 0.0000(0.0000) Steps 922(903.29) | Grad Norm 1.3716(2.3394) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0144 | Time 106.2865, Epoch Time 1294.0595(1270.4179), Bit/dim 3.4429(best: 3.4410), Xent 0.0000, Loss 3.4429, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7930 | Time 21.5764(21.3413) | Bit/dim 3.4298(3.4415) | Xent 0.0000(0.0000) | Loss 3.4298(3.4415) | Error 0.0000(0.0000) Steps 922(904.27) | Grad Norm 1.6043(2.2247) | Total Time 14.00(14.00)\n",
      "Iter 7940 | Time 21.8229(21.3920) | Bit/dim 3.3949(3.4388) | Xent 0.0000(0.0000) | Loss 3.3949(3.4388) | Error 0.0000(0.0000) Steps 916(903.54) | Grad Norm 3.0171(2.2640) | Total Time 14.00(14.00)\n",
      "Iter 7950 | Time 22.0184(21.3602) | Bit/dim 3.4153(3.4388) | Xent 0.0000(0.0000) | Loss 3.4153(3.4388) | Error 0.0000(0.0000) Steps 922(904.37) | Grad Norm 2.4520(2.2899) | Total Time 14.00(14.00)\n",
      "Iter 7960 | Time 21.4244(21.3579) | Bit/dim 3.4668(3.4411) | Xent 0.0000(0.0000) | Loss 3.4668(3.4411) | Error 0.0000(0.0000) Steps 898(903.63) | Grad Norm 2.8851(2.2021) | Total Time 14.00(14.00)\n",
      "Iter 7970 | Time 20.9488(21.3401) | Bit/dim 3.4513(3.4393) | Xent 0.0000(0.0000) | Loss 3.4513(3.4393) | Error 0.0000(0.0000) Steps 862(900.27) | Grad Norm 3.2965(2.2936) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0145 | Time 106.1970, Epoch Time 1298.8437(1271.2707), Bit/dim 3.4402(best: 3.4410), Xent 0.0000, Loss 3.4402, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7980 | Time 20.9665(21.2903) | Bit/dim 3.4127(3.4378) | Xent 0.0000(0.0000) | Loss 3.4127(3.4378) | Error 0.0000(0.0000) Steps 910(902.23) | Grad Norm 1.9647(2.2267) | Total Time 14.00(14.00)\n",
      "Iter 7990 | Time 21.7306(21.2783) | Bit/dim 3.4397(3.4404) | Xent 0.0000(0.0000) | Loss 3.4397(3.4404) | Error 0.0000(0.0000) Steps 898(903.71) | Grad Norm 2.5409(2.3279) | Total Time 14.00(14.00)\n",
      "Iter 8000 | Time 21.1476(21.2486) | Bit/dim 3.4099(3.4387) | Xent 0.0000(0.0000) | Loss 3.4099(3.4387) | Error 0.0000(0.0000) Steps 916(902.42) | Grad Norm 2.9108(2.4084) | Total Time 14.00(14.00)\n",
      "Iter 8010 | Time 21.0614(21.2436) | Bit/dim 3.4427(3.4397) | Xent 0.0000(0.0000) | Loss 3.4427(3.4397) | Error 0.0000(0.0000) Steps 868(900.42) | Grad Norm 2.5085(2.3632) | Total Time 14.00(14.00)\n",
      "Iter 8020 | Time 22.1202(21.2832) | Bit/dim 3.4194(3.4402) | Xent 0.0000(0.0000) | Loss 3.4194(3.4402) | Error 0.0000(0.0000) Steps 934(901.62) | Grad Norm 2.0006(2.2536) | Total Time 14.00(14.00)\n",
      "Iter 8030 | Time 21.2504(21.2090) | Bit/dim 3.4676(3.4373) | Xent 0.0000(0.0000) | Loss 3.4676(3.4373) | Error 0.0000(0.0000) Steps 868(899.60) | Grad Norm 3.1601(2.4201) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0146 | Time 105.1237, Epoch Time 1288.6517(1271.7921), Bit/dim 3.4418(best: 3.4402), Xent 0.0000, Loss 3.4418, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8040 | Time 21.5658(21.2952) | Bit/dim 3.4827(3.4372) | Xent 0.0000(0.0000) | Loss 3.4827(3.4372) | Error 0.0000(0.0000) Steps 922(899.95) | Grad Norm 1.8168(2.3665) | Total Time 14.00(14.00)\n",
      "Iter 8050 | Time 22.4723(21.2970) | Bit/dim 3.4549(3.4369) | Xent 0.0000(0.0000) | Loss 3.4549(3.4369) | Error 0.0000(0.0000) Steps 880(899.18) | Grad Norm 2.0923(2.3787) | Total Time 14.00(14.00)\n",
      "Iter 8060 | Time 21.6547(21.2741) | Bit/dim 3.4618(3.4398) | Xent 0.0000(0.0000) | Loss 3.4618(3.4398) | Error 0.0000(0.0000) Steps 922(901.49) | Grad Norm 2.8039(2.2697) | Total Time 14.00(14.00)\n",
      "Iter 8070 | Time 21.2244(21.2820) | Bit/dim 3.4224(3.4366) | Xent 0.0000(0.0000) | Loss 3.4224(3.4366) | Error 0.0000(0.0000) Steps 922(905.00) | Grad Norm 3.9448(2.4305) | Total Time 14.00(14.00)\n",
      "Iter 8080 | Time 21.3297(21.3042) | Bit/dim 3.4259(3.4388) | Xent 0.0000(0.0000) | Loss 3.4259(3.4388) | Error 0.0000(0.0000) Steps 904(905.04) | Grad Norm 1.9178(2.3368) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0147 | Time 108.2363, Epoch Time 1298.6908(1272.5990), Bit/dim 3.4407(best: 3.4402), Xent 0.0000, Loss 3.4407, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8090 | Time 21.4275(21.2995) | Bit/dim 3.4313(3.4391) | Xent 0.0000(0.0000) | Loss 3.4313(3.4391) | Error 0.0000(0.0000) Steps 892(905.94) | Grad Norm 1.7766(2.3977) | Total Time 14.00(14.00)\n",
      "Iter 8100 | Time 21.2895(21.3103) | Bit/dim 3.3976(3.4364) | Xent 0.0000(0.0000) | Loss 3.3976(3.4364) | Error 0.0000(0.0000) Steps 892(904.19) | Grad Norm 2.1844(2.3508) | Total Time 14.00(14.00)\n",
      "Iter 8110 | Time 21.3881(21.3237) | Bit/dim 3.4345(3.4387) | Xent 0.0000(0.0000) | Loss 3.4345(3.4387) | Error 0.0000(0.0000) Steps 904(904.76) | Grad Norm 3.0079(2.2346) | Total Time 14.00(14.00)\n",
      "Iter 8120 | Time 21.5310(21.3280) | Bit/dim 3.4646(3.4372) | Xent 0.0000(0.0000) | Loss 3.4646(3.4372) | Error 0.0000(0.0000) Steps 916(906.19) | Grad Norm 2.5966(2.3267) | Total Time 14.00(14.00)\n",
      "Iter 8130 | Time 21.4694(21.3665) | Bit/dim 3.4450(3.4388) | Xent 0.0000(0.0000) | Loss 3.4450(3.4388) | Error 0.0000(0.0000) Steps 940(906.92) | Grad Norm 2.0061(2.3232) | Total Time 14.00(14.00)\n",
      "Iter 8140 | Time 21.0464(21.3896) | Bit/dim 3.4169(3.4366) | Xent 0.0000(0.0000) | Loss 3.4169(3.4366) | Error 0.0000(0.0000) Steps 916(906.07) | Grad Norm 2.1807(2.3028) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0148 | Time 106.6817, Epoch Time 1301.4794(1273.4655), Bit/dim 3.4386(best: 3.4402), Xent 0.0000, Loss 3.4386, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8150 | Time 21.5926(21.3739) | Bit/dim 3.4305(3.4369) | Xent 0.0000(0.0000) | Loss 3.4305(3.4369) | Error 0.0000(0.0000) Steps 886(907.17) | Grad Norm 1.8705(2.2223) | Total Time 14.00(14.00)\n",
      "Iter 8160 | Time 21.3757(21.4093) | Bit/dim 3.4430(3.4353) | Xent 0.0000(0.0000) | Loss 3.4430(3.4353) | Error 0.0000(0.0000) Steps 892(905.49) | Grad Norm 2.7143(2.3739) | Total Time 14.00(14.00)\n",
      "Iter 8170 | Time 21.3548(21.3954) | Bit/dim 3.3826(3.4352) | Xent 0.0000(0.0000) | Loss 3.3826(3.4352) | Error 0.0000(0.0000) Steps 916(907.09) | Grad Norm 1.9755(2.3412) | Total Time 14.00(14.00)\n",
      "Iter 8180 | Time 22.0453(21.3855) | Bit/dim 3.4264(3.4346) | Xent 0.0000(0.0000) | Loss 3.4264(3.4346) | Error 0.0000(0.0000) Steps 928(907.02) | Grad Norm 1.8374(2.2433) | Total Time 14.00(14.00)\n",
      "Iter 8190 | Time 21.5367(21.3702) | Bit/dim 3.4426(3.4366) | Xent 0.0000(0.0000) | Loss 3.4426(3.4366) | Error 0.0000(0.0000) Steps 928(907.32) | Grad Norm 2.2614(2.3063) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0149 | Time 106.0473, Epoch Time 1297.3924(1274.1833), Bit/dim 3.4383(best: 3.4386), Xent 0.0000, Loss 3.4383, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8200 | Time 21.1958(21.3089) | Bit/dim 3.4421(3.4349) | Xent 0.0000(0.0000) | Loss 3.4421(3.4349) | Error 0.0000(0.0000) Steps 916(906.03) | Grad Norm 1.5639(2.2667) | Total Time 14.00(14.00)\n",
      "Iter 8210 | Time 21.3807(21.3033) | Bit/dim 3.4215(3.4332) | Xent 0.0000(0.0000) | Loss 3.4215(3.4332) | Error 0.0000(0.0000) Steps 928(907.59) | Grad Norm 2.7477(2.2498) | Total Time 14.00(14.00)\n",
      "Iter 8220 | Time 20.5951(21.2716) | Bit/dim 3.4314(3.4328) | Xent 0.0000(0.0000) | Loss 3.4314(3.4328) | Error 0.0000(0.0000) Steps 874(905.47) | Grad Norm 2.6371(2.1366) | Total Time 14.00(14.00)\n",
      "Iter 8230 | Time 21.1273(21.2395) | Bit/dim 3.4540(3.4335) | Xent 0.0000(0.0000) | Loss 3.4540(3.4335) | Error 0.0000(0.0000) Steps 874(904.78) | Grad Norm 2.1158(2.0921) | Total Time 14.00(14.00)\n",
      "Iter 8240 | Time 20.7608(21.2198) | Bit/dim 3.4122(3.4375) | Xent 0.0000(0.0000) | Loss 3.4122(3.4375) | Error 0.0000(0.0000) Steps 898(904.16) | Grad Norm 2.8373(2.2404) | Total Time 14.00(14.00)\n",
      "Iter 8250 | Time 20.5312(21.1556) | Bit/dim 3.4207(3.4362) | Xent 0.0000(0.0000) | Loss 3.4207(3.4362) | Error 0.0000(0.0000) Steps 910(903.73) | Grad Norm 2.0111(2.2675) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0150 | Time 105.8240, Epoch Time 1287.7323(1274.5897), Bit/dim 3.4375(best: 3.4383), Xent 0.0000, Loss 3.4375, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8260 | Time 20.9719(21.1898) | Bit/dim 3.4300(3.4369) | Xent 0.0000(0.0000) | Loss 3.4300(3.4369) | Error 0.0000(0.0000) Steps 910(904.40) | Grad Norm 2.7780(2.2843) | Total Time 14.00(14.00)\n",
      "Iter 8270 | Time 21.3840(21.2212) | Bit/dim 3.4406(3.4337) | Xent 0.0000(0.0000) | Loss 3.4406(3.4337) | Error 0.0000(0.0000) Steps 904(906.61) | Grad Norm 2.2044(2.3099) | Total Time 14.00(14.00)\n",
      "Iter 8280 | Time 21.0390(21.2410) | Bit/dim 3.4245(3.4350) | Xent 0.0000(0.0000) | Loss 3.4245(3.4350) | Error 0.0000(0.0000) Steps 922(908.04) | Grad Norm 1.2654(2.1772) | Total Time 14.00(14.00)\n",
      "Iter 8290 | Time 21.6372(21.2740) | Bit/dim 3.4472(3.4333) | Xent 0.0000(0.0000) | Loss 3.4472(3.4333) | Error 0.0000(0.0000) Steps 880(908.30) | Grad Norm 2.7938(2.2323) | Total Time 14.00(14.00)\n",
      "Iter 8300 | Time 20.8771(21.2558) | Bit/dim 3.4310(3.4341) | Xent 0.0000(0.0000) | Loss 3.4310(3.4341) | Error 0.0000(0.0000) Steps 898(907.93) | Grad Norm 2.3762(2.2238) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0151 | Time 107.3093, Epoch Time 1296.2255(1275.2388), Bit/dim 3.4363(best: 3.4375), Xent 0.0000, Loss 3.4363, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8310 | Time 20.9301(21.1969) | Bit/dim 3.4233(3.4348) | Xent 0.0000(0.0000) | Loss 3.4233(3.4348) | Error 0.0000(0.0000) Steps 934(909.21) | Grad Norm 2.6448(2.3029) | Total Time 14.00(14.00)\n",
      "Iter 8320 | Time 21.2513(21.2237) | Bit/dim 3.4407(3.4331) | Xent 0.0000(0.0000) | Loss 3.4407(3.4331) | Error 0.0000(0.0000) Steps 898(907.47) | Grad Norm 3.4174(2.2310) | Total Time 14.00(14.00)\n",
      "Iter 8330 | Time 21.1708(21.2229) | Bit/dim 3.4364(3.4351) | Xent 0.0000(0.0000) | Loss 3.4364(3.4351) | Error 0.0000(0.0000) Steps 886(905.03) | Grad Norm 2.4824(2.2782) | Total Time 14.00(14.00)\n",
      "Iter 8340 | Time 22.0037(21.3120) | Bit/dim 3.4478(3.4336) | Xent 0.0000(0.0000) | Loss 3.4478(3.4336) | Error 0.0000(0.0000) Steps 886(905.08) | Grad Norm 2.8882(2.2845) | Total Time 14.00(14.00)\n",
      "Iter 8350 | Time 21.4810(21.2830) | Bit/dim 3.4474(3.4339) | Xent 0.0000(0.0000) | Loss 3.4474(3.4339) | Error 0.0000(0.0000) Steps 922(906.57) | Grad Norm 1.6528(2.3028) | Total Time 14.00(14.00)\n",
      "Iter 8360 | Time 21.2705(21.2856) | Bit/dim 3.4586(3.4334) | Xent 0.0000(0.0000) | Loss 3.4586(3.4334) | Error 0.0000(0.0000) Steps 916(909.35) | Grad Norm 1.7319(2.2926) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0152 | Time 107.8173, Epoch Time 1295.4582(1275.8454), Bit/dim 3.4375(best: 3.4363), Xent 0.0000, Loss 3.4375, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8370 | Time 20.9157(21.2959) | Bit/dim 3.4769(3.4347) | Xent 0.0000(0.0000) | Loss 3.4769(3.4347) | Error 0.0000(0.0000) Steps 916(911.13) | Grad Norm 3.9165(2.4149) | Total Time 14.00(14.00)\n",
      "Iter 8380 | Time 20.7916(21.2174) | Bit/dim 3.4374(3.4353) | Xent 0.0000(0.0000) | Loss 3.4374(3.4353) | Error 0.0000(0.0000) Steps 916(910.02) | Grad Norm 2.7855(2.4230) | Total Time 14.00(14.00)\n",
      "Iter 8390 | Time 21.6094(21.2357) | Bit/dim 3.4169(3.4343) | Xent 0.0000(0.0000) | Loss 3.4169(3.4343) | Error 0.0000(0.0000) Steps 928(910.34) | Grad Norm 1.7874(2.2427) | Total Time 14.00(14.00)\n",
      "Iter 8400 | Time 21.1981(21.3194) | Bit/dim 3.4281(3.4333) | Xent 0.0000(0.0000) | Loss 3.4281(3.4333) | Error 0.0000(0.0000) Steps 916(911.33) | Grad Norm 3.6059(2.1733) | Total Time 14.00(14.00)\n",
      "Iter 8410 | Time 20.7099(21.2564) | Bit/dim 3.4039(3.4314) | Xent 0.0000(0.0000) | Loss 3.4039(3.4314) | Error 0.0000(0.0000) Steps 886(908.24) | Grad Norm 2.6034(2.2101) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0153 | Time 108.8098, Epoch Time 1296.6336(1276.4690), Bit/dim 3.4330(best: 3.4363), Xent 0.0000, Loss 3.4330, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8420 | Time 21.2634(21.2857) | Bit/dim 3.4351(3.4320) | Xent 0.0000(0.0000) | Loss 3.4351(3.4320) | Error 0.0000(0.0000) Steps 910(908.96) | Grad Norm 3.3953(2.1898) | Total Time 14.00(14.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_cifar10_published_baseline_bs900_3 --seed 3 --conditional False --controlled_tol False  --log_freq 10\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -p ../train_cnf.py --data mnist --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_published_baseline_bs900_1 --resume ../experiments_published/cnf_published_baseline_bs900_1/current_checkpt.pth --seed 1 --conditional False --controlled_tol False  --log_freq 10\n",
    "# #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
