{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import torch.utils.data as data\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "plt.rcParams['figure.dpi'] = 300\n",
      "\n",
      "from PIL import Image\n",
      "import os.path\n",
      "import errno\n",
      "import codecs\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"colormnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--y_class\", type=int, default=10)\n",
      "parser.add_argument(\"--y_color\", type=int, default=10)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "class ColorMNIST(data.Dataset):\n",
      "    \"\"\"\n",
      "    ColorMNIST\n",
      "    \"\"\"\n",
      "    urls = [\n",
      "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
      "    ]\n",
      "    raw_folder = 'raw'\n",
      "    processed_folder = 'processed'\n",
      "    training_file = 'training.pt'\n",
      "    test_file = 'test.pt'\n",
      "\n",
      "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
      "        self.root = os.path.expanduser(root)\n",
      "        self.transform = transform\n",
      "        self.target_transform = target_transform\n",
      "        self.train = train  # training set or test set\n",
      "\n",
      "        if download:\n",
      "            self.download()\n",
      "\n",
      "        if not self._check_exists():\n",
      "            raise RuntimeError('Dataset not found.' +\n",
      "                               ' You can use download=True to download it')\n",
      "\n",
      "        if self.train:\n",
      "            self.train_data, self.train_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
      "            \n",
      "            self.train_data = np.tile(self.train_data[:, :, :, np.newaxis], 3)\n",
      "        else:\n",
      "            self.test_data, self.test_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "            \n",
      "            self.test_data = np.tile(self.test_data[:, :, :, np.newaxis], 3)\n",
      "        \n",
      "        self.pallette = [[31, 119, 180],\n",
      "                         [255, 127, 14],\n",
      "                         [44, 160, 44],\n",
      "                         [214, 39, 40],\n",
      "                         [148, 103, 189],\n",
      "                         [140, 86, 75],\n",
      "                         [227, 119, 194],\n",
      "                         [127, 127, 127],\n",
      "                         [188, 189, 34],\n",
      "                         [23, 190, 207]]\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            index (int): Index\n",
      "\n",
      "        Returns:\n",
      "            tuple: (image, target) where target is index of the target class.\n",
      "        \"\"\"\n",
      "        if self.train:\n",
      "            img, target = self.train_data[index].copy(), self.train_labels[index]\n",
      "        else:\n",
      "            img, target = self.test_data[index].copy(), self.test_labels[index]\n",
      "        \n",
      "        # doing this so that it is consistent with all other datasets\n",
      "        # to return a PIL Image\n",
      "        y_color_digit = np.random.randint(0, args.y_color)\n",
      "        c_digit = self.pallette[y_color_digit]\n",
      "        \n",
      "        img[:, :, 0] = img[:, :, 0] / 255 * c_digit[0]\n",
      "        img[:, :, 1] = img[:, :, 1] / 255 * c_digit[1]\n",
      "        img[:, :, 2] = img[:, :, 2] / 255 * c_digit[2]\n",
      "        \n",
      "        img = Image.fromarray(img)\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "\n",
      "        return img, [target,torch.from_numpy(np.array(y_color_digit))]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.train:\n",
      "            return len(self.train_data)\n",
      "        else:\n",
      "            return len(self.test_data)\n",
      "\n",
      "    def _check_exists(self):\n",
      "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
      "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "\n",
      "    def download(self):\n",
      "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
      "        from six.moves import urllib\n",
      "        import gzip\n",
      "\n",
      "        if self._check_exists():\n",
      "            return\n",
      "\n",
      "        # download files\n",
      "        try:\n",
      "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
      "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
      "        except OSError as e:\n",
      "            if e.errno == errno.EEXIST:\n",
      "                pass\n",
      "            else:\n",
      "                raise\n",
      "\n",
      "        for url in self.urls:\n",
      "            print('Downloading ' + url)\n",
      "            data = urllib.request.urlopen(url)\n",
      "            filename = url.rpartition('/')[2]\n",
      "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
      "            with open(file_path, 'wb') as f:\n",
      "                f.write(data.read())\n",
      "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
      "                    gzip.GzipFile(file_path) as zip_f:\n",
      "                out_f.write(zip_f.read())\n",
      "            os.unlink(file_path)\n",
      "\n",
      "        # process and save as torch files\n",
      "        print('Processing...')\n",
      "\n",
      "        training_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
      "        )\n",
      "        test_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
      "        )\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
      "            torch.save(training_set, f)\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
      "            torch.save(test_set, f)\n",
      "\n",
      "        print('Done!')\n",
      "\n",
      "    def __repr__(self):\n",
      "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
      "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
      "        tmp = 'train' if self.train is True else 'test'\n",
      "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
      "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
      "        tmp = '    Transforms (if any): '\n",
      "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        tmp = '    Target Transforms (if any): '\n",
      "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        return fmt_str\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"colormnist\":\n",
      "        im_dim = 3\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = ColorMNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = ColorMNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,\n",
      "            y_class = args.y_class)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            if args.data == \"colormnist\":\n",
      "                y = y[0]\n",
      "            \n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        if args.data == \"colormnist\":\n",
      "            # print train images\n",
      "            xall = []\n",
      "            ximg = x[0:40].cpu().numpy().transpose((0,2,3,1))\n",
      "            for i in range(ximg.shape[0]):\n",
      "                xall.append(ximg[i])\n",
      "        \n",
      "            xall = np.hstack(xall)\n",
      "\n",
      "            plt.imshow(xall)\n",
      "            plt.axis('off')\n",
      "            plt.show()\n",
      "            \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if args.data == \"colormnist\":\n",
      "                        y = y[0]\n",
      "                        \n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                if args.data == \"colormnist\":\n",
      "                    # print test images\n",
      "                    xall = []\n",
      "                    ximg = x[0:40].cpu().numpy().transpose((0,2,3,1))\n",
      "                    for i in range(ximg.shape[0]):\n",
      "                        xall.append(ximg[i])\n",
      "\n",
      "                    xall = np.hstack(xall)\n",
      "\n",
      "                    plt.imshow(xall)\n",
      "                    plt.axis('off')\n",
      "                    plt.show()\n",
      "                    \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=False, atol=0.0001, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=False, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.0, eta=0.1, gamma=0.99, gate='cnn2', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.001, max_grad_norm=20.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_cifar10_bs8K_rl_stdlearnscale_30_run2/epoch_200_checkpt.pth', rl_weight=0.01, rtol=0.0001, save='../experiments_published/cnf_cifar10_bs8K_rl_stdlearnscale_30_run2', scale=1.0, scale_fac=1.0, scale_std=15.0, seed=2, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000.0, weight_decay=0.0, weight_y=0.5, y_class=10, y_color=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1450886\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 1201 | Time 120.8855(61.8100) | Bit/dim 3.5528(3.5699) | Xent 0.0000(0.0000) | Loss 10.7158(9.1194) | Error 0.0000(0.0000) Steps 640(633.34) | Grad Norm 2.4734(3.4667) | Total Time 0.00(0.00)\n",
      "Iter 1202 | Time 64.4323(61.8887) | Bit/dim 3.5468(3.5692) | Xent 0.0000(0.0000) | Loss 8.3262(9.0956) | Error 0.0000(0.0000) Steps 652(633.90) | Grad Norm 2.0462(3.4241) | Total Time 0.00(0.00)\n",
      "Iter 1203 | Time 61.9674(61.8911) | Bit/dim 3.5364(3.5683) | Xent 0.0000(0.0000) | Loss 8.2714(9.0708) | Error 0.0000(0.0000) Steps 640(634.08) | Grad Norm 1.1997(3.3573) | Total Time 0.00(0.00)\n",
      "Iter 1204 | Time 59.6381(61.8235) | Bit/dim 3.5261(3.5670) | Xent 0.0000(0.0000) | Loss 8.3162(9.0482) | Error 0.0000(0.0000) Steps 622(633.72) | Grad Norm 0.6401(3.2758) | Total Time 0.00(0.00)\n",
      "Iter 1205 | Time 63.6192(61.8773) | Bit/dim 3.5315(3.5659) | Xent 0.0000(0.0000) | Loss 8.5887(9.0344) | Error 0.0000(0.0000) Steps 664(634.63) | Grad Norm 1.4152(3.2200) | Total Time 0.00(0.00)\n",
      "Iter 1206 | Time 65.7457(61.9934) | Bit/dim 3.5310(3.5649) | Xent 0.0000(0.0000) | Loss 8.3981(9.0153) | Error 0.0000(0.0000) Steps 676(635.87) | Grad Norm 1.7990(3.1774) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0201 | Time 39.1838, Epoch Time 491.5436(386.0316), Bit/dim 3.5335(best: inf), Xent 0.0000, Loss 3.5335, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1207 | Time 67.1028(62.1467) | Bit/dim 3.5302(3.5638) | Xent 0.0000(0.0000) | Loss 12.0664(9.1069) | Error 0.0000(0.0000) Steps 628(635.63) | Grad Norm 1.6657(3.1320) | Total Time 0.00(0.00)\n",
      "Iter 1208 | Time 66.6491(62.2817) | Bit/dim 3.5283(3.5628) | Xent 0.0000(0.0000) | Loss 8.5696(9.0907) | Error 0.0000(0.0000) Steps 682(637.02) | Grad Norm 1.0732(3.0702) | Total Time 0.00(0.00)\n",
      "Iter 1209 | Time 60.3223(62.2230) | Bit/dim 3.5269(3.5617) | Xent 0.0000(0.0000) | Loss 8.2980(9.0670) | Error 0.0000(0.0000) Steps 634(636.93) | Grad Norm 0.7468(3.0005) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 61.4615(62.2001) | Bit/dim 3.5256(3.5606) | Xent 0.0000(0.0000) | Loss 8.4370(9.0481) | Error 0.0000(0.0000) Steps 646(637.21) | Grad Norm 1.0926(2.9433) | Total Time 0.00(0.00)\n",
      "Iter 1211 | Time 61.9727(62.1933) | Bit/dim 3.5348(3.5598) | Xent 0.0000(0.0000) | Loss 8.4000(9.0286) | Error 0.0000(0.0000) Steps 658(637.83) | Grad Norm 1.2855(2.8936) | Total Time 0.00(0.00)\n",
      "Iter 1212 | Time 64.7504(62.2700) | Bit/dim 3.5330(3.5590) | Xent 0.0000(0.0000) | Loss 8.5505(9.0143) | Error 0.0000(0.0000) Steps 652(638.25) | Grad Norm 1.1760(2.8420) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0202 | Time 23.1519, Epoch Time 421.2136(387.0870), Bit/dim 3.5245(best: 3.5335), Xent 0.0000, Loss 3.5245, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1213 | Time 62.1331(62.2659) | Bit/dim 3.5273(3.5581) | Xent 0.0000(0.0000) | Loss 11.7073(9.0951) | Error 0.0000(0.0000) Steps 616(637.59) | Grad Norm 0.8328(2.7818) | Total Time 0.00(0.00)\n",
      "Iter 1214 | Time 60.6169(62.2164) | Bit/dim 3.5282(3.5572) | Xent 0.0000(0.0000) | Loss 8.1541(9.0668) | Error 0.0000(0.0000) Steps 616(636.94) | Grad Norm 0.7252(2.7201) | Total Time 0.00(0.00)\n",
      "Iter 1215 | Time 67.2771(62.3683) | Bit/dim 3.5344(3.5565) | Xent 0.0000(0.0000) | Loss 8.4136(9.0472) | Error 0.0000(0.0000) Steps 646(637.21) | Grad Norm 0.9832(2.6680) | Total Time 0.00(0.00)\n",
      "Iter 1216 | Time 66.6402(62.4964) | Bit/dim 3.5256(3.5556) | Xent 0.0000(0.0000) | Loss 8.3118(9.0252) | Error 0.0000(0.0000) Steps 652(637.66) | Grad Norm 1.1022(2.6210) | Total Time 0.00(0.00)\n",
      "Iter 1217 | Time 63.6131(62.5299) | Bit/dim 3.5209(3.5545) | Xent 0.0000(0.0000) | Loss 8.2520(9.0020) | Error 0.0000(0.0000) Steps 646(637.91) | Grad Norm 0.9550(2.5710) | Total Time 0.00(0.00)\n",
      "Iter 1218 | Time 62.5534(62.5306) | Bit/dim 3.5249(3.5536) | Xent 0.0000(0.0000) | Loss 8.4056(8.9841) | Error 0.0000(0.0000) Steps 652(638.33) | Grad Norm 0.6520(2.5134) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0203 | Time 23.0785, Epoch Time 421.6615(388.1243), Bit/dim 3.5251(best: 3.5245), Xent 0.0000, Loss 3.5251, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1219 | Time 64.4482(62.5881) | Bit/dim 3.5175(3.5526) | Xent 0.0000(0.0000) | Loss 12.0209(9.0752) | Error 0.0000(0.0000) Steps 646(638.56) | Grad Norm 0.8074(2.4623) | Total Time 0.00(0.00)\n",
      "Iter 1220 | Time 63.8339(62.6255) | Bit/dim 3.5136(3.5514) | Xent 0.0000(0.0000) | Loss 8.4524(9.0565) | Error 0.0000(0.0000) Steps 640(638.60) | Grad Norm 0.8841(2.4149) | Total Time 0.00(0.00)\n",
      "Iter 1221 | Time 59.9862(62.5463) | Bit/dim 3.5442(3.5512) | Xent 0.0000(0.0000) | Loss 8.3878(9.0364) | Error 0.0000(0.0000) Steps 616(637.92) | Grad Norm 0.9292(2.3703) | Total Time 0.00(0.00)\n",
      "Iter 1222 | Time 63.7687(62.5830) | Bit/dim 3.5321(3.5506) | Xent 0.0000(0.0000) | Loss 8.4502(9.0189) | Error 0.0000(0.0000) Steps 670(638.89) | Grad Norm 0.7148(2.3207) | Total Time 0.00(0.00)\n",
      "Iter 1223 | Time 60.8104(62.5298) | Bit/dim 3.5197(3.5497) | Xent 0.0000(0.0000) | Loss 8.2516(8.9958) | Error 0.0000(0.0000) Steps 646(639.10) | Grad Norm 0.5424(2.2673) | Total Time 0.00(0.00)\n",
      "Iter 1224 | Time 62.8561(62.5396) | Bit/dim 3.5294(3.5491) | Xent 0.0000(0.0000) | Loss 8.5163(8.9815) | Error 0.0000(0.0000) Steps 640(639.13) | Grad Norm 0.5967(2.2172) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0204 | Time 24.3159, Epoch Time 416.0369(388.9617), Bit/dim 3.5274(best: 3.5245), Xent 0.0000, Loss 3.5274, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1225 | Time 66.8242(62.6682) | Bit/dim 3.5223(3.5483) | Xent 0.0000(0.0000) | Loss 12.1752(9.0773) | Error 0.0000(0.0000) Steps 664(639.87) | Grad Norm 0.7474(2.1731) | Total Time 0.00(0.00)\n",
      "Iter 1226 | Time 61.6395(62.6373) | Bit/dim 3.5154(3.5473) | Xent 0.0000(0.0000) | Loss 8.3541(9.0556) | Error 0.0000(0.0000) Steps 646(640.06) | Grad Norm 0.6745(2.1282) | Total Time 0.00(0.00)\n",
      "Iter 1227 | Time 64.3001(62.6872) | Bit/dim 3.5351(3.5469) | Xent 0.0000(0.0000) | Loss 8.3558(9.0346) | Error 0.0000(0.0000) Steps 664(640.77) | Grad Norm 0.5323(2.0803) | Total Time 0.00(0.00)\n",
      "Iter 1228 | Time 65.6199(62.7752) | Bit/dim 3.5163(3.5460) | Xent 0.0000(0.0000) | Loss 8.3826(9.0150) | Error 0.0000(0.0000) Steps 658(641.29) | Grad Norm 0.4569(2.0316) | Total Time 0.00(0.00)\n",
      "Iter 1229 | Time 63.3222(62.7916) | Bit/dim 3.5159(3.5451) | Xent 0.0000(0.0000) | Loss 8.4037(8.9967) | Error 0.0000(0.0000) Steps 646(641.43) | Grad Norm 0.5772(1.9880) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 64.5998(62.8458) | Bit/dim 3.5199(3.5443) | Xent 0.0000(0.0000) | Loss 8.3603(8.9776) | Error 0.0000(0.0000) Steps 646(641.57) | Grad Norm 0.6379(1.9474) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0205 | Time 23.5939, Epoch Time 425.8222(390.0675), Bit/dim 3.5225(best: 3.5245), Xent 0.0000, Loss 3.5225, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1231 | Time 64.2390(62.8876) | Bit/dim 3.5222(3.5437) | Xent 0.0000(0.0000) | Loss 11.7686(9.0613) | Error 0.0000(0.0000) Steps 652(641.88) | Grad Norm 0.6831(1.9095) | Total Time 0.00(0.00)\n",
      "Iter 1232 | Time 66.9946(63.0108) | Bit/dim 3.5203(3.5430) | Xent 0.0000(0.0000) | Loss 8.3013(9.0385) | Error 0.0000(0.0000) Steps 640(641.83) | Grad Norm 0.4520(1.8658) | Total Time 0.00(0.00)\n",
      "Iter 1233 | Time 65.1083(63.0737) | Bit/dim 3.5278(3.5425) | Xent 0.0000(0.0000) | Loss 8.4848(9.0219) | Error 0.0000(0.0000) Steps 664(642.49) | Grad Norm 0.3450(1.8202) | Total Time 0.00(0.00)\n",
      "Iter 1234 | Time 64.1428(63.1058) | Bit/dim 3.5246(3.5420) | Xent 0.0000(0.0000) | Loss 8.4720(9.0054) | Error 0.0000(0.0000) Steps 646(642.60) | Grad Norm 0.4432(1.7789) | Total Time 0.00(0.00)\n",
      "Iter 1235 | Time 66.8792(63.2190) | Bit/dim 3.5251(3.5415) | Xent 0.0000(0.0000) | Loss 8.4054(8.9874) | Error 0.0000(0.0000) Steps 658(643.06) | Grad Norm 0.4445(1.7388) | Total Time 0.00(0.00)\n",
      "Iter 1236 | Time 61.7015(63.1735) | Bit/dim 3.5156(3.5407) | Xent 0.0000(0.0000) | Loss 8.2454(8.9651) | Error 0.0000(0.0000) Steps 628(642.61) | Grad Norm 0.4341(1.6997) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0206 | Time 24.2574, Epoch Time 428.8648(391.2314), Bit/dim 3.5232(best: 3.5225), Xent 0.0000, Loss 3.5232, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1237 | Time 58.5651(63.0352) | Bit/dim 3.5297(3.5404) | Xent 0.0000(0.0000) | Loss 11.9753(9.0555) | Error 0.0000(0.0000) Steps 646(642.71) | Grad Norm 0.5412(1.6649) | Total Time 0.00(0.00)\n",
      "Iter 1238 | Time 60.3840(62.9557) | Bit/dim 3.5167(3.5397) | Xent 0.0000(0.0000) | Loss 8.1706(9.0289) | Error 0.0000(0.0000) Steps 658(643.17) | Grad Norm 0.3516(1.6255) | Total Time 0.00(0.00)\n",
      "Iter 1239 | Time 62.4065(62.9392) | Bit/dim 3.5226(3.5391) | Xent 0.0000(0.0000) | Loss 8.4023(9.0101) | Error 0.0000(0.0000) Steps 640(643.07) | Grad Norm 0.3492(1.5872) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 65.8820(63.0275) | Bit/dim 3.5228(3.5387) | Xent 0.0000(0.0000) | Loss 8.4206(8.9924) | Error 0.0000(0.0000) Steps 646(643.16) | Grad Norm 0.3499(1.5501) | Total Time 0.00(0.00)\n",
      "Iter 1241 | Time 60.5459(62.9531) | Bit/dim 3.5196(3.5381) | Xent 0.0000(0.0000) | Loss 8.2203(8.9693) | Error 0.0000(0.0000) Steps 628(642.71) | Grad Norm 0.2916(1.5124) | Total Time 0.00(0.00)\n",
      "Iter 1242 | Time 59.9769(62.8638) | Bit/dim 3.5307(3.5379) | Xent 0.0000(0.0000) | Loss 8.4141(8.9526) | Error 0.0000(0.0000) Steps 640(642.62) | Grad Norm 0.2656(1.4750) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0207 | Time 24.1338, Epoch Time 407.3712(391.7156), Bit/dim 3.5242(best: 3.5225), Xent 0.0000, Loss 3.5242, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1243 | Time 63.9989(62.8978) | Bit/dim 3.5355(3.5378) | Xent 0.0000(0.0000) | Loss 12.1937(9.0498) | Error 0.0000(0.0000) Steps 634(642.37) | Grad Norm 0.3249(1.4405) | Total Time 0.00(0.00)\n",
      "Iter 1244 | Time 60.3097(62.8202) | Bit/dim 3.5102(3.5370) | Xent 0.0000(0.0000) | Loss 8.3496(9.0288) | Error 0.0000(0.0000) Steps 622(641.75) | Grad Norm 0.2893(1.4059) | Total Time 0.00(0.00)\n",
      "Iter 1245 | Time 66.4329(62.9286) | Bit/dim 3.5267(3.5367) | Xent 0.0000(0.0000) | Loss 8.4075(9.0102) | Error 0.0000(0.0000) Steps 664(642.42) | Grad Norm 0.3420(1.3740) | Total Time 0.00(0.00)\n",
      "Iter 1246 | Time 60.6404(62.8599) | Bit/dim 3.5286(3.5364) | Xent 0.0000(0.0000) | Loss 8.5445(8.9962) | Error 0.0000(0.0000) Steps 646(642.53) | Grad Norm 0.2368(1.3399) | Total Time 0.00(0.00)\n",
      "Iter 1247 | Time 59.6712(62.7643) | Bit/dim 3.5180(3.5359) | Xent 0.0000(0.0000) | Loss 8.3451(8.9767) | Error 0.0000(0.0000) Steps 616(641.73) | Grad Norm 0.2933(1.3085) | Total Time 0.00(0.00)\n",
      "Iter 1248 | Time 62.4901(62.7560) | Bit/dim 3.5149(3.5352) | Xent 0.0000(0.0000) | Loss 8.3364(8.9575) | Error 0.0000(0.0000) Steps 640(641.68) | Grad Norm 0.2981(1.2782) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0208 | Time 23.5435, Epoch Time 412.7701(392.3472), Bit/dim 3.5207(best: 3.5225), Xent 0.0000, Loss 3.5207, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1249 | Time 59.9349(62.6714) | Bit/dim 3.5296(3.5351) | Xent 0.0000(0.0000) | Loss 11.1852(9.0243) | Error 0.0000(0.0000) Steps 622(641.09) | Grad Norm 0.6174(1.2584) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 59.7952(62.5851) | Bit/dim 3.5246(3.5347) | Xent 0.0000(0.0000) | Loss 8.2089(8.9998) | Error 0.0000(0.0000) Steps 622(640.52) | Grad Norm 0.2501(1.2281) | Total Time 0.00(0.00)\n",
      "Iter 1251 | Time 65.3028(62.6666) | Bit/dim 3.5312(3.5346) | Xent 0.0000(0.0000) | Loss 8.4906(8.9846) | Error 0.0000(0.0000) Steps 664(641.22) | Grad Norm 0.2011(1.1973) | Total Time 0.00(0.00)\n",
      "Iter 1252 | Time 63.0760(62.6789) | Bit/dim 3.5088(3.5339) | Xent 0.0000(0.0000) | Loss 8.2602(8.9628) | Error 0.0000(0.0000) Steps 622(640.65) | Grad Norm 0.2057(1.1675) | Total Time 0.00(0.00)\n",
      "Iter 1253 | Time 61.5436(62.6449) | Bit/dim 3.5199(3.5334) | Xent 0.0000(0.0000) | Loss 8.2394(8.9411) | Error 0.0000(0.0000) Steps 658(641.17) | Grad Norm 0.3019(1.1416) | Total Time 0.00(0.00)\n",
      "Iter 1254 | Time 64.6492(62.7050) | Bit/dim 3.5229(3.5331) | Xent 0.0000(0.0000) | Loss 8.2085(8.9192) | Error 0.0000(0.0000) Steps 652(641.49) | Grad Norm 0.3232(1.1170) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0209 | Time 24.3110, Epoch Time 414.9368(393.0249), Bit/dim 3.5270(best: 3.5207), Xent 0.0000, Loss 3.5270, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1255 | Time 59.6069(62.6121) | Bit/dim 3.5196(3.5327) | Xent 0.0000(0.0000) | Loss 11.6595(9.0014) | Error 0.0000(0.0000) Steps 628(641.09) | Grad Norm 0.3356(1.0936) | Total Time 0.00(0.00)\n",
      "Iter 1256 | Time 61.0926(62.5665) | Bit/dim 3.5226(3.5324) | Xent 0.0000(0.0000) | Loss 8.0657(8.9733) | Error 0.0000(0.0000) Steps 634(640.87) | Grad Norm 0.2884(1.0694) | Total Time 0.00(0.00)\n",
      "Iter 1257 | Time 58.7364(62.4516) | Bit/dim 3.5209(3.5321) | Xent 0.0000(0.0000) | Loss 8.3711(8.9552) | Error 0.0000(0.0000) Steps 640(640.85) | Grad Norm 0.2275(1.0442) | Total Time 0.00(0.00)\n",
      "Iter 1258 | Time 60.7570(62.4007) | Bit/dim 3.5212(3.5317) | Xent 0.0000(0.0000) | Loss 8.3086(8.9358) | Error 0.0000(0.0000) Steps 634(640.64) | Grad Norm 0.2651(1.0208) | Total Time 0.00(0.00)\n",
      "Iter 1259 | Time 64.4660(62.4627) | Bit/dim 3.5179(3.5313) | Xent 0.0000(0.0000) | Loss 8.3263(8.9175) | Error 0.0000(0.0000) Steps 652(640.98) | Grad Norm 0.2518(0.9977) | Total Time 0.00(0.00)\n",
      "Iter 1260 | Time 59.6975(62.3797) | Bit/dim 3.5153(3.5309) | Xent 0.0000(0.0000) | Loss 8.4017(8.9021) | Error 0.0000(0.0000) Steps 646(641.13) | Grad Norm 0.2063(0.9740) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0210 | Time 23.4269, Epoch Time 403.6079(393.3424), Bit/dim 3.5222(best: 3.5207), Xent 0.0000, Loss 3.5222, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1261 | Time 61.8812(62.3648) | Bit/dim 3.5178(3.5305) | Xent 0.0000(0.0000) | Loss 11.7983(8.9890) | Error 0.0000(0.0000) Steps 646(641.28) | Grad Norm 0.3677(0.9558) | Total Time 0.00(0.00)\n",
      "Iter 1262 | Time 62.9674(62.3829) | Bit/dim 3.5163(3.5300) | Xent 0.0000(0.0000) | Loss 8.4857(8.9739) | Error 0.0000(0.0000) Steps 646(641.42) | Grad Norm 0.1867(0.9327) | Total Time 0.00(0.00)\n",
      "Iter 1263 | Time 61.4167(62.3539) | Bit/dim 3.5307(3.5301) | Xent 0.0000(0.0000) | Loss 8.3153(8.9541) | Error 0.0000(0.0000) Steps 628(641.02) | Grad Norm 0.2269(0.9115) | Total Time 0.00(0.00)\n",
      "Iter 1264 | Time 57.0157(62.1937) | Bit/dim 3.5266(3.5300) | Xent 0.0000(0.0000) | Loss 8.3472(8.9359) | Error 0.0000(0.0000) Steps 628(640.63) | Grad Norm 0.2098(0.8905) | Total Time 0.00(0.00)\n",
      "Iter 1265 | Time 60.4916(62.1427) | Bit/dim 3.5250(3.5298) | Xent 0.0000(0.0000) | Loss 8.3805(8.9192) | Error 0.0000(0.0000) Steps 658(641.15) | Grad Norm 0.1584(0.8685) | Total Time 0.00(0.00)\n",
      "Iter 1266 | Time 64.3693(62.2095) | Bit/dim 3.5193(3.5295) | Xent 0.0000(0.0000) | Loss 8.1970(8.8976) | Error 0.0000(0.0000) Steps 652(641.47) | Grad Norm 0.3185(0.8520) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0211 | Time 23.5813, Epoch Time 407.7361(393.7742), Bit/dim 3.5217(best: 3.5207), Xent 0.0000, Loss 3.5217, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1267 | Time 59.3485(62.1236) | Bit/dim 3.5284(3.5295) | Xent 0.0000(0.0000) | Loss 12.1067(8.9938) | Error 0.0000(0.0000) Steps 640(641.43) | Grad Norm 0.2132(0.8329) | Total Time 0.00(0.00)\n",
      "Iter 1268 | Time 66.4203(62.2525) | Bit/dim 3.5226(3.5292) | Xent 0.0000(0.0000) | Loss 8.4972(8.9789) | Error 0.0000(0.0000) Steps 646(641.57) | Grad Norm 0.1764(0.8132) | Total Time 0.00(0.00)\n",
      "Iter 1269 | Time 61.0277(62.2158) | Bit/dim 3.5220(3.5290) | Xent 0.0000(0.0000) | Loss 8.4201(8.9622) | Error 0.0000(0.0000) Steps 652(641.88) | Grad Norm 0.2173(0.7953) | Total Time 0.00(0.00)\n",
      "Iter 1270 | Time 60.6955(62.1702) | Bit/dim 3.5193(3.5287) | Xent 0.0000(0.0000) | Loss 8.3234(8.9430) | Error 0.0000(0.0000) Steps 628(641.46) | Grad Norm 0.2327(0.7784) | Total Time 0.00(0.00)\n",
      "Iter 1271 | Time 61.4873(62.1497) | Bit/dim 3.5171(3.5284) | Xent 0.0000(0.0000) | Loss 8.4746(8.9290) | Error 0.0000(0.0000) Steps 646(641.60) | Grad Norm 0.1721(0.7602) | Total Time 0.00(0.00)\n",
      "Iter 1272 | Time 63.5777(62.1925) | Bit/dim 3.5157(3.5280) | Xent 0.0000(0.0000) | Loss 8.5075(8.9163) | Error 0.0000(0.0000) Steps 658(642.09) | Grad Norm 0.1489(0.7419) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0212 | Time 23.9851, Epoch Time 412.3824(394.3325), Bit/dim 3.5272(best: 3.5207), Xent 0.0000, Loss 3.5272, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1273 | Time 63.2612(62.2246) | Bit/dim 3.5136(3.5276) | Xent 0.0000(0.0000) | Loss 12.2191(9.0154) | Error 0.0000(0.0000) Steps 646(642.21) | Grad Norm 0.2144(0.7261) | Total Time 0.00(0.00)\n",
      "Iter 1274 | Time 62.5876(62.2355) | Bit/dim 3.5195(3.5273) | Xent 0.0000(0.0000) | Loss 8.2929(8.9937) | Error 0.0000(0.0000) Steps 646(642.32) | Grad Norm 0.3670(0.7153) | Total Time 0.00(0.00)\n",
      "Iter 1275 | Time 61.8542(62.2240) | Bit/dim 3.5216(3.5272) | Xent 0.0000(0.0000) | Loss 8.2590(8.9717) | Error 0.0000(0.0000) Steps 640(642.25) | Grad Norm 0.1734(0.6990) | Total Time 0.00(0.00)\n",
      "Iter 1276 | Time 62.3532(62.2279) | Bit/dim 3.5169(3.5269) | Xent 0.0000(0.0000) | Loss 8.4152(8.9550) | Error 0.0000(0.0000) Steps 640(642.19) | Grad Norm 0.1769(0.6834) | Total Time 0.00(0.00)\n",
      "Iter 1277 | Time 64.9849(62.3106) | Bit/dim 3.5318(3.5270) | Xent 0.0000(0.0000) | Loss 8.5262(8.9421) | Error 0.0000(0.0000) Steps 652(642.48) | Grad Norm 0.1870(0.6685) | Total Time 0.00(0.00)\n",
      "Iter 1278 | Time 66.4408(62.4345) | Bit/dim 3.5161(3.5267) | Xent 0.0000(0.0000) | Loss 8.3911(8.9256) | Error 0.0000(0.0000) Steps 676(643.49) | Grad Norm 0.2316(0.6554) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0213 | Time 23.3877, Epoch Time 420.8754(395.1287), Bit/dim 3.5242(best: 3.5207), Xent 0.0000, Loss 3.5242, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1279 | Time 64.6302(62.5004) | Bit/dim 3.5127(3.5263) | Xent 0.0000(0.0000) | Loss 12.1214(9.0215) | Error 0.0000(0.0000) Steps 658(643.92) | Grad Norm 0.2130(0.6421) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 64.5615(62.5622) | Bit/dim 3.5158(3.5259) | Xent 0.0000(0.0000) | Loss 8.3516(9.0014) | Error 0.0000(0.0000) Steps 652(644.16) | Grad Norm 0.1633(0.6277) | Total Time 0.00(0.00)\n",
      "Iter 1281 | Time 64.7832(62.6289) | Bit/dim 3.5199(3.5258) | Xent 0.0000(0.0000) | Loss 8.3432(8.9816) | Error 0.0000(0.0000) Steps 664(644.76) | Grad Norm 0.2778(0.6172) | Total Time 0.00(0.00)\n",
      "Iter 1282 | Time 64.0055(62.6702) | Bit/dim 3.5247(3.5257) | Xent 0.0000(0.0000) | Loss 8.4903(8.9669) | Error 0.0000(0.0000) Steps 652(644.98) | Grad Norm 0.1684(0.6038) | Total Time 0.00(0.00)\n",
      "Iter 1283 | Time 60.3589(62.6008) | Bit/dim 3.5238(3.5257) | Xent 0.0000(0.0000) | Loss 8.2581(8.9456) | Error 0.0000(0.0000) Steps 658(645.37) | Grad Norm 0.3087(0.5949) | Total Time 0.00(0.00)\n",
      "Iter 1284 | Time 65.3075(62.6820) | Bit/dim 3.5198(3.5255) | Xent 0.0000(0.0000) | Loss 8.3217(8.9269) | Error 0.0000(0.0000) Steps 688(646.65) | Grad Norm 0.2823(0.5855) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0214 | Time 24.0483, Epoch Time 423.1054(395.9680), Bit/dim 3.5211(best: 3.5207), Xent 0.0000, Loss 3.5211, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1285 | Time 65.0935(62.7544) | Bit/dim 3.5282(3.5256) | Xent 0.0000(0.0000) | Loss 12.0703(9.0212) | Error 0.0000(0.0000) Steps 646(646.63) | Grad Norm 0.2394(0.5752) | Total Time 0.00(0.00)\n",
      "Iter 1286 | Time 63.8095(62.7860) | Bit/dim 3.5221(3.5255) | Xent 0.0000(0.0000) | Loss 8.3780(9.0019) | Error 0.0000(0.0000) Steps 640(646.43) | Grad Norm 0.2200(0.5645) | Total Time 0.00(0.00)\n",
      "Iter 1287 | Time 64.5737(62.8397) | Bit/dim 3.5170(3.5252) | Xent 0.0000(0.0000) | Loss 8.4874(8.9865) | Error 0.0000(0.0000) Steps 682(647.49) | Grad Norm 0.1984(0.5535) | Total Time 0.00(0.00)\n",
      "Iter 1288 | Time 63.4275(62.8573) | Bit/dim 3.5198(3.5251) | Xent 0.0000(0.0000) | Loss 8.4726(8.9711) | Error 0.0000(0.0000) Steps 658(647.81) | Grad Norm 0.1757(0.5422) | Total Time 0.00(0.00)\n",
      "Iter 1289 | Time 60.0965(62.7745) | Bit/dim 3.5187(3.5249) | Xent 0.0000(0.0000) | Loss 8.2925(8.9507) | Error 0.0000(0.0000) Steps 640(647.58) | Grad Norm 0.2073(0.5321) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 63.5578(62.7980) | Bit/dim 3.5149(3.5246) | Xent 0.0000(0.0000) | Loss 8.1369(8.9263) | Error 0.0000(0.0000) Steps 646(647.53) | Grad Norm 0.2469(0.5236) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0215 | Time 23.7023, Epoch Time 420.1550(396.6936), Bit/dim 3.5188(best: 3.5207), Xent 0.0000, Loss 3.5188, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1291 | Time 62.1021(62.7771) | Bit/dim 3.5134(3.5242) | Xent 0.0000(0.0000) | Loss 11.8926(9.0153) | Error 0.0000(0.0000) Steps 658(647.84) | Grad Norm 0.2428(0.5152) | Total Time 0.00(0.00)\n",
      "Iter 1292 | Time 67.1790(62.9091) | Bit/dim 3.5136(3.5239) | Xent 0.0000(0.0000) | Loss 8.4584(8.9986) | Error 0.0000(0.0000) Steps 664(648.33) | Grad Norm 0.1787(0.5051) | Total Time 0.00(0.00)\n",
      "Iter 1293 | Time 65.7560(62.9945) | Bit/dim 3.5242(3.5239) | Xent 0.0000(0.0000) | Loss 8.4185(8.9812) | Error 0.0000(0.0000) Steps 646(648.26) | Grad Norm 0.2073(0.4961) | Total Time 0.00(0.00)\n",
      "Iter 1294 | Time 61.5757(62.9520) | Bit/dim 3.5150(3.5237) | Xent 0.0000(0.0000) | Loss 8.4692(8.9658) | Error 0.0000(0.0000) Steps 646(648.19) | Grad Norm 0.1951(0.4871) | Total Time 0.00(0.00)\n",
      "Iter 1295 | Time 61.3491(62.9039) | Bit/dim 3.5165(3.5234) | Xent 0.0000(0.0000) | Loss 8.0969(8.9397) | Error 0.0000(0.0000) Steps 652(648.30) | Grad Norm 0.3038(0.4816) | Total Time 0.00(0.00)\n",
      "Iter 1296 | Time 65.7738(62.9900) | Bit/dim 3.5294(3.5236) | Xent 0.0000(0.0000) | Loss 8.5937(8.9294) | Error 0.0000(0.0000) Steps 658(648.59) | Grad Norm 0.2077(0.4734) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0216 | Time 23.9067, Epoch Time 423.4305(397.4958), Bit/dim 3.5222(best: 3.5188), Xent 0.0000, Loss 3.5222, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1297 | Time 62.3377(62.9704) | Bit/dim 3.5215(3.5236) | Xent 0.0000(0.0000) | Loss 11.7765(9.0148) | Error 0.0000(0.0000) Steps 646(648.52) | Grad Norm 0.4242(0.4719) | Total Time 0.00(0.00)\n",
      "Iter 1298 | Time 60.9271(62.9091) | Bit/dim 3.5198(3.5234) | Xent 0.0000(0.0000) | Loss 8.4987(8.9993) | Error 0.0000(0.0000) Steps 652(648.62) | Grad Norm 0.1381(0.4619) | Total Time 0.00(0.00)\n",
      "Iter 1299 | Time 59.3098(62.8011) | Bit/dim 3.5202(3.5233) | Xent 0.0000(0.0000) | Loss 8.2967(8.9782) | Error 0.0000(0.0000) Steps 634(648.18) | Grad Norm 0.3324(0.4580) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 61.2820(62.7556) | Bit/dim 3.5174(3.5232) | Xent 0.0000(0.0000) | Loss 8.3475(8.9593) | Error 0.0000(0.0000) Steps 646(648.12) | Grad Norm 0.2461(0.4516) | Total Time 0.00(0.00)\n",
      "Iter 1301 | Time 61.9895(62.7326) | Bit/dim 3.5210(3.5231) | Xent 0.0000(0.0000) | Loss 8.3846(8.9421) | Error 0.0000(0.0000) Steps 640(647.87) | Grad Norm 0.1707(0.4432) | Total Time 0.00(0.00)\n",
      "Iter 1302 | Time 58.7433(62.6129) | Bit/dim 3.5323(3.5234) | Xent 0.0000(0.0000) | Loss 8.4832(8.9283) | Error 0.0000(0.0000) Steps 622(647.10) | Grad Norm 0.1613(0.4348) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0217 | Time 23.7794, Epoch Time 404.5677(397.7079), Bit/dim 3.5245(best: 3.5188), Xent 0.0000, Loss 3.5245, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1303 | Time 62.0195(62.5951) | Bit/dim 3.5226(3.5234) | Xent 0.0000(0.0000) | Loss 11.7675(9.0135) | Error 0.0000(0.0000) Steps 640(646.88) | Grad Norm 0.3423(0.4320) | Total Time 0.00(0.00)\n",
      "Iter 1304 | Time 61.2649(62.5552) | Bit/dim 3.5120(3.5230) | Xent 0.0000(0.0000) | Loss 8.3789(8.9944) | Error 0.0000(0.0000) Steps 652(647.04) | Grad Norm 0.2414(0.4263) | Total Time 0.00(0.00)\n",
      "Iter 1305 | Time 61.3822(62.5200) | Bit/dim 3.5188(3.5229) | Xent 0.0000(0.0000) | Loss 8.3868(8.9762) | Error 0.0000(0.0000) Steps 634(646.65) | Grad Norm 0.1611(0.4183) | Total Time 0.00(0.00)\n",
      "Iter 1306 | Time 66.6036(62.6425) | Bit/dim 3.5302(3.5231) | Xent 0.0000(0.0000) | Loss 8.1670(8.9519) | Error 0.0000(0.0000) Steps 658(646.99) | Grad Norm 0.2186(0.4123) | Total Time 0.00(0.00)\n",
      "Iter 1307 | Time 61.4567(62.6069) | Bit/dim 3.5249(3.5232) | Xent 0.0000(0.0000) | Loss 8.4657(8.9373) | Error 0.0000(0.0000) Steps 652(647.14) | Grad Norm 0.2101(0.4063) | Total Time 0.00(0.00)\n",
      "Iter 1308 | Time 61.4394(62.5719) | Bit/dim 3.5185(3.5230) | Xent 0.0000(0.0000) | Loss 8.3331(8.9192) | Error 0.0000(0.0000) Steps 652(647.28) | Grad Norm 0.2327(0.4010) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0218 | Time 24.3772, Epoch Time 414.5762(398.2140), Bit/dim 3.5229(best: 3.5188), Xent 0.0000, Loss 3.5229, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1309 | Time 60.5305(62.5107) | Bit/dim 3.5157(3.5228) | Xent 0.0000(0.0000) | Loss 12.1512(9.0162) | Error 0.0000(0.0000) Steps 646(647.25) | Grad Norm 0.2002(0.3950) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 67.3172(62.6549) | Bit/dim 3.5256(3.5229) | Xent 0.0000(0.0000) | Loss 8.3542(8.9963) | Error 0.0000(0.0000) Steps 658(647.57) | Grad Norm 0.1832(0.3887) | Total Time 0.00(0.00)\n",
      "Iter 1311 | Time 64.0866(62.6978) | Bit/dim 3.5270(3.5230) | Xent 0.0000(0.0000) | Loss 8.3733(8.9776) | Error 0.0000(0.0000) Steps 646(647.52) | Grad Norm 0.2158(0.3835) | Total Time 0.00(0.00)\n",
      "Iter 1312 | Time 66.1795(62.8023) | Bit/dim 3.5141(3.5227) | Xent 0.0000(0.0000) | Loss 8.5032(8.9634) | Error 0.0000(0.0000) Steps 682(648.56) | Grad Norm 0.1743(0.3772) | Total Time 0.00(0.00)\n",
      "Iter 1313 | Time 64.5360(62.8543) | Bit/dim 3.5058(3.5222) | Xent 0.0000(0.0000) | Loss 8.4566(8.9482) | Error 0.0000(0.0000) Steps 652(648.66) | Grad Norm 0.1271(0.3697) | Total Time 0.00(0.00)\n",
      "Iter 1314 | Time 64.3885(62.9003) | Bit/dim 3.5240(3.5223) | Xent 0.0000(0.0000) | Loss 8.2425(8.9270) | Error 0.0000(0.0000) Steps 664(649.12) | Grad Norm 0.4136(0.3710) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0219 | Time 23.8205, Epoch Time 426.8832(399.0740), Bit/dim 3.5176(best: 3.5188), Xent 0.0000, Loss 3.5176, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1315 | Time 64.1853(62.9389) | Bit/dim 3.5226(3.5223) | Xent 0.0000(0.0000) | Loss 12.2202(9.0258) | Error 0.0000(0.0000) Steps 664(649.57) | Grad Norm 0.2559(0.3676) | Total Time 0.00(0.00)\n",
      "Iter 1316 | Time 65.5292(63.0166) | Bit/dim 3.5220(3.5223) | Xent 0.0000(0.0000) | Loss 8.2415(9.0023) | Error 0.0000(0.0000) Steps 658(649.82) | Grad Norm 0.2415(0.3638) | Total Time 0.00(0.00)\n",
      "Iter 1317 | Time 61.6689(62.9761) | Bit/dim 3.5111(3.5220) | Xent 0.0000(0.0000) | Loss 8.5179(8.9878) | Error 0.0000(0.0000) Steps 646(649.70) | Grad Norm 0.1565(0.3576) | Total Time 0.00(0.00)\n",
      "Iter 1318 | Time 59.7752(62.8801) | Bit/dim 3.5256(3.5221) | Xent 0.0000(0.0000) | Loss 8.3821(8.9696) | Error 0.0000(0.0000) Steps 652(649.77) | Grad Norm 0.3175(0.3564) | Total Time 0.00(0.00)\n",
      "Iter 1319 | Time 62.4901(62.8684) | Bit/dim 3.5116(3.5218) | Xent 0.0000(0.0000) | Loss 8.4843(8.9550) | Error 0.0000(0.0000) Steps 664(650.20) | Grad Norm 0.2514(0.3532) | Total Time 0.00(0.00)\n",
      "Iter 1320 | Time 64.1420(62.9066) | Bit/dim 3.5197(3.5217) | Xent 0.0000(0.0000) | Loss 8.3200(8.9360) | Error 0.0000(0.0000) Steps 658(650.43) | Grad Norm 0.1987(0.3486) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0220 | Time 23.9500, Epoch Time 418.0357(399.6429), Bit/dim 3.5177(best: 3.5176), Xent 0.0000, Loss 3.5177, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1321 | Time 61.3039(62.8585) | Bit/dim 3.5214(3.5217) | Xent 0.0000(0.0000) | Loss 11.8858(9.0245) | Error 0.0000(0.0000) Steps 658(650.66) | Grad Norm 0.2754(0.3464) | Total Time 0.00(0.00)\n",
      "Iter 1322 | Time 53.9877(62.5924) | Bit/dim 3.5172(3.5215) | Xent 0.0000(0.0000) | Loss 8.1846(8.9993) | Error 0.0000(0.0000) Steps 628(649.98) | Grad Norm 0.3587(0.3468) | Total Time 0.00(0.00)\n",
      "Iter 1323 | Time 58.3833(62.4661) | Bit/dim 3.5206(3.5215) | Xent 0.0000(0.0000) | Loss 8.2879(8.9779) | Error 0.0000(0.0000) Steps 652(650.04) | Grad Norm 0.2900(0.3451) | Total Time 0.00(0.00)\n",
      "Iter 1324 | Time 63.3972(62.4941) | Bit/dim 3.5265(3.5217) | Xent 0.0000(0.0000) | Loss 8.2111(8.9549) | Error 0.0000(0.0000) Steps 664(650.46) | Grad Norm 0.3105(0.3440) | Total Time 0.00(0.00)\n",
      "Iter 1325 | Time 66.0493(62.6007) | Bit/dim 3.5264(3.5218) | Xent 0.0000(0.0000) | Loss 8.4535(8.9399) | Error 0.0000(0.0000) Steps 658(650.69) | Grad Norm 0.2050(0.3398) | Total Time 0.00(0.00)\n",
      "Iter 1326 | Time 61.6068(62.5709) | Bit/dim 3.5189(3.5217) | Xent 0.0000(0.0000) | Loss 8.2394(8.9189) | Error 0.0000(0.0000) Steps 658(650.91) | Grad Norm 0.2525(0.3372) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0221 | Time 23.6541, Epoch Time 404.4359(399.7867), Bit/dim 3.5175(best: 3.5176), Xent 0.0000, Loss 3.5175, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1327 | Time 62.8369(62.5789) | Bit/dim 3.5134(3.5215) | Xent 0.0000(0.0000) | Loss 11.8214(9.0059) | Error 0.0000(0.0000) Steps 658(651.12) | Grad Norm 0.2591(0.3349) | Total Time 0.00(0.00)\n",
      "Iter 1328 | Time 64.5912(62.6393) | Bit/dim 3.5163(3.5213) | Xent 0.0000(0.0000) | Loss 8.5377(8.9919) | Error 0.0000(0.0000) Steps 670(651.68) | Grad Norm 0.1639(0.3298) | Total Time 0.00(0.00)\n",
      "Iter 1329 | Time 64.3912(62.6918) | Bit/dim 3.5186(3.5212) | Xent 0.0000(0.0000) | Loss 8.3642(8.9731) | Error 0.0000(0.0000) Steps 652(651.69) | Grad Norm 0.1743(0.3251) | Total Time 0.00(0.00)\n",
      "Iter 1330 | Time 60.1049(62.6142) | Bit/dim 3.5148(3.5210) | Xent 0.0000(0.0000) | Loss 8.4221(8.9565) | Error 0.0000(0.0000) Steps 646(651.52) | Grad Norm 0.2094(0.3216) | Total Time 0.00(0.00)\n",
      "Iter 1331 | Time 62.0855(62.5983) | Bit/dim 3.5140(3.5208) | Xent 0.0000(0.0000) | Loss 8.5665(8.9448) | Error 0.0000(0.0000) Steps 664(651.90) | Grad Norm 0.1499(0.3165) | Total Time 0.00(0.00)\n",
      "Iter 1332 | Time 60.4512(62.5339) | Bit/dim 3.5202(3.5208) | Xent 0.0000(0.0000) | Loss 8.4990(8.9315) | Error 0.0000(0.0000) Steps 670(652.44) | Grad Norm 0.1694(0.3121) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0222 | Time 23.6156, Epoch Time 414.2299(400.2200), Bit/dim 3.5199(best: 3.5175), Xent 0.0000, Loss 3.5199, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1333 | Time 60.5943(62.4757) | Bit/dim 3.5122(3.5206) | Xent 0.0000(0.0000) | Loss 11.6938(9.0143) | Error 0.0000(0.0000) Steps 646(652.25) | Grad Norm 0.2689(0.3108) | Total Time 0.00(0.00)\n",
      "Iter 1334 | Time 62.0895(62.4642) | Bit/dim 3.5194(3.5205) | Xent 0.0000(0.0000) | Loss 8.3503(8.9944) | Error 0.0000(0.0000) Steps 652(652.24) | Grad Norm 0.1596(0.3062) | Total Time 0.00(0.00)\n",
      "Iter 1335 | Time 66.1225(62.5739) | Bit/dim 3.5183(3.5205) | Xent 0.0000(0.0000) | Loss 8.5102(8.9799) | Error 0.0000(0.0000) Steps 694(653.49) | Grad Norm 0.2206(0.3037) | Total Time 0.00(0.00)\n",
      "Iter 1336 | Time 64.9845(62.6462) | Bit/dim 3.5263(3.5206) | Xent 0.0000(0.0000) | Loss 8.2868(8.9591) | Error 0.0000(0.0000) Steps 658(653.63) | Grad Norm 0.2202(0.3012) | Total Time 0.00(0.00)\n",
      "Iter 1337 | Time 68.2358(62.8139) | Bit/dim 3.5147(3.5205) | Xent 0.0000(0.0000) | Loss 8.5547(8.9470) | Error 0.0000(0.0000) Steps 676(654.30) | Grad Norm 0.1662(0.2971) | Total Time 0.00(0.00)\n",
      "Iter 1338 | Time 62.2611(62.7973) | Bit/dim 3.5242(3.5206) | Xent 0.0000(0.0000) | Loss 8.5509(8.9351) | Error 0.0000(0.0000) Steps 652(654.23) | Grad Norm 0.1750(0.2934) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0223 | Time 24.1376, Epoch Time 424.3427(400.9437), Bit/dim 3.5176(best: 3.5175), Xent 0.0000, Loss 3.5176, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1339 | Time 60.9418(62.7417) | Bit/dim 3.5167(3.5204) | Xent 0.0000(0.0000) | Loss 12.0390(9.0282) | Error 0.0000(0.0000) Steps 634(653.62) | Grad Norm 0.2287(0.2915) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 63.0719(62.7516) | Bit/dim 3.5293(3.5207) | Xent 0.0000(0.0000) | Loss 8.3711(9.0085) | Error 0.0000(0.0000) Steps 652(653.57) | Grad Norm 0.2503(0.2903) | Total Time 0.00(0.00)\n",
      "Iter 1341 | Time 62.5254(62.7448) | Bit/dim 3.5022(3.5202) | Xent 0.0000(0.0000) | Loss 8.5014(8.9933) | Error 0.0000(0.0000) Steps 658(653.71) | Grad Norm 0.1882(0.2872) | Total Time 0.00(0.00)\n",
      "Iter 1342 | Time 62.2708(62.7306) | Bit/dim 3.5180(3.5201) | Xent 0.0000(0.0000) | Loss 8.4386(8.9766) | Error 0.0000(0.0000) Steps 658(653.84) | Grad Norm 0.1699(0.2837) | Total Time 0.00(0.00)\n",
      "Iter 1343 | Time 63.8271(62.7635) | Bit/dim 3.5128(3.5199) | Xent 0.0000(0.0000) | Loss 8.3495(8.9578) | Error 0.0000(0.0000) Steps 652(653.78) | Grad Norm 0.5411(0.2914) | Total Time 0.00(0.00)\n",
      "Iter 1344 | Time 59.7250(62.6723) | Bit/dim 3.5144(3.5197) | Xent 0.0000(0.0000) | Loss 8.3429(8.9394) | Error 0.0000(0.0000) Steps 646(653.55) | Grad Norm 0.2672(0.2907) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0224 | Time 23.8248, Epoch Time 411.6358(401.2644), Bit/dim 3.5150(best: 3.5175), Xent 0.0000, Loss 3.5150, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1345 | Time 63.4803(62.6965) | Bit/dim 3.5204(3.5197) | Xent 0.0000(0.0000) | Loss 11.8600(9.0270) | Error 0.0000(0.0000) Steps 646(653.32) | Grad Norm 0.2632(0.2899) | Total Time 0.00(0.00)\n",
      "Iter 1346 | Time 62.4839(62.6902) | Bit/dim 3.5093(3.5194) | Xent 0.0000(0.0000) | Loss 8.3929(9.0080) | Error 0.0000(0.0000) Steps 646(653.10) | Grad Norm 0.1971(0.2871) | Total Time 0.00(0.00)\n",
      "Iter 1347 | Time 60.7808(62.6329) | Bit/dim 3.5208(3.5195) | Xent 0.0000(0.0000) | Loss 8.4534(8.9913) | Error 0.0000(0.0000) Steps 664(653.43) | Grad Norm 0.2019(0.2845) | Total Time 0.00(0.00)\n",
      "Iter 1348 | Time 63.0631(62.6458) | Bit/dim 3.5156(3.5193) | Xent 0.0000(0.0000) | Loss 8.2667(8.9696) | Error 0.0000(0.0000) Steps 658(653.57) | Grad Norm 0.2264(0.2828) | Total Time 0.00(0.00)\n",
      "Iter 1349 | Time 60.9374(62.5945) | Bit/dim 3.5263(3.5196) | Xent 0.0000(0.0000) | Loss 8.3716(8.9517) | Error 0.0000(0.0000) Steps 640(653.16) | Grad Norm 0.1957(0.2802) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 64.6972(62.6576) | Bit/dim 3.5170(3.5195) | Xent 0.0000(0.0000) | Loss 8.3133(8.9325) | Error 0.0000(0.0000) Steps 676(653.84) | Grad Norm 0.2094(0.2780) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0225 | Time 23.5059, Epoch Time 414.3771(401.6578), Bit/dim 3.5180(best: 3.5150), Xent 0.0000, Loss 3.5180, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1351 | Time 61.4387(62.6211) | Bit/dim 3.5138(3.5193) | Xent 0.0000(0.0000) | Loss 11.7904(9.0182) | Error 0.0000(0.0000) Steps 664(654.15) | Grad Norm 0.3050(0.2789) | Total Time 0.00(0.00)\n",
      "Iter 1352 | Time 66.5395(62.7386) | Bit/dim 3.5111(3.5191) | Xent 0.0000(0.0000) | Loss 8.4312(9.0006) | Error 0.0000(0.0000) Steps 682(654.98) | Grad Norm 0.1776(0.2758) | Total Time 0.00(0.00)\n",
      "Iter 1353 | Time 64.3689(62.7875) | Bit/dim 3.5187(3.5191) | Xent 0.0000(0.0000) | Loss 8.3312(8.9805) | Error 0.0000(0.0000) Steps 652(654.89) | Grad Norm 0.1780(0.2729) | Total Time 0.00(0.00)\n",
      "Iter 1354 | Time 66.3453(62.8942) | Bit/dim 3.5233(3.5192) | Xent 0.0000(0.0000) | Loss 8.4996(8.9661) | Error 0.0000(0.0000) Steps 670(655.35) | Grad Norm 0.2518(0.2722) | Total Time 0.00(0.00)\n",
      "Iter 1355 | Time 63.3176(62.9069) | Bit/dim 3.5104(3.5189) | Xent 0.0000(0.0000) | Loss 8.3463(8.9475) | Error 0.0000(0.0000) Steps 676(655.97) | Grad Norm 0.1520(0.2686) | Total Time 0.00(0.00)\n",
      "Iter 1356 | Time 65.1222(62.9734) | Bit/dim 3.5209(3.5190) | Xent 0.0000(0.0000) | Loss 8.4349(8.9321) | Error 0.0000(0.0000) Steps 658(656.03) | Grad Norm 0.1808(0.2660) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0226 | Time 23.4263, Epoch Time 426.1948(402.3939), Bit/dim 3.5169(best: 3.5150), Xent 0.0000, Loss 3.5169, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1357 | Time 60.8002(62.9082) | Bit/dim 3.5108(3.5187) | Xent 0.0000(0.0000) | Loss 11.6634(9.0141) | Error 0.0000(0.0000) Steps 634(655.37) | Grad Norm 0.3905(0.2697) | Total Time 0.00(0.00)\n",
      "Iter 1358 | Time 65.3992(62.9829) | Bit/dim 3.5213(3.5188) | Xent 0.0000(0.0000) | Loss 8.5329(8.9996) | Error 0.0000(0.0000) Steps 646(655.09) | Grad Norm 0.2168(0.2682) | Total Time 0.00(0.00)\n",
      "Iter 1359 | Time 65.3877(63.0551) | Bit/dim 3.5140(3.5187) | Xent 0.0000(0.0000) | Loss 8.4152(8.9821) | Error 0.0000(0.0000) Steps 682(655.89) | Grad Norm 0.2256(0.2669) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 65.0247(63.1142) | Bit/dim 3.5129(3.5185) | Xent 0.0000(0.0000) | Loss 8.4509(8.9662) | Error 0.0000(0.0000) Steps 640(655.42) | Grad Norm 0.1779(0.2642) | Total Time 0.00(0.00)\n",
      "Iter 1361 | Time 61.8575(63.0765) | Bit/dim 3.5138(3.5184) | Xent 0.0000(0.0000) | Loss 8.4724(8.9514) | Error 0.0000(0.0000) Steps 652(655.31) | Grad Norm 0.2267(0.2631) | Total Time 0.00(0.00)\n",
      "Iter 1362 | Time 64.5292(63.1201) | Bit/dim 3.5208(3.5184) | Xent 0.0000(0.0000) | Loss 8.4801(8.9372) | Error 0.0000(0.0000) Steps 658(655.40) | Grad Norm 0.2003(0.2612) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0227 | Time 23.9716, Epoch Time 423.3404(403.0223), Bit/dim 3.5225(best: 3.5150), Xent 0.0000, Loss 3.5225, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1363 | Time 61.4088(63.0687) | Bit/dim 3.5099(3.5182) | Xent 0.0000(0.0000) | Loss 12.0625(9.0310) | Error 0.0000(0.0000) Steps 670(655.83) | Grad Norm 0.4193(0.2659) | Total Time 0.00(0.00)\n",
      "Iter 1364 | Time 64.3583(63.1074) | Bit/dim 3.5259(3.5184) | Xent 0.0000(0.0000) | Loss 8.4307(9.0130) | Error 0.0000(0.0000) Steps 676(656.44) | Grad Norm 0.2208(0.2646) | Total Time 0.00(0.00)\n",
      "Iter 1365 | Time 61.3010(63.0532) | Bit/dim 3.5229(3.5185) | Xent 0.0000(0.0000) | Loss 8.1975(8.9885) | Error 0.0000(0.0000) Steps 640(655.95) | Grad Norm 0.2993(0.2656) | Total Time 0.00(0.00)\n",
      "Iter 1366 | Time 64.3694(63.0927) | Bit/dim 3.5053(3.5181) | Xent 0.0000(0.0000) | Loss 8.3042(8.9680) | Error 0.0000(0.0000) Steps 658(656.01) | Grad Norm 0.1816(0.2631) | Total Time 0.00(0.00)\n",
      "Iter 1367 | Time 62.5295(63.0758) | Bit/dim 3.5160(3.5181) | Xent 0.0000(0.0000) | Loss 8.3501(8.9494) | Error 0.0000(0.0000) Steps 640(655.53) | Grad Norm 0.2067(0.2614) | Total Time 0.00(0.00)\n",
      "Iter 1368 | Time 59.4501(62.9670) | Bit/dim 3.5189(3.5181) | Xent 0.0000(0.0000) | Loss 8.2817(8.9294) | Error 0.0000(0.0000) Steps 646(655.24) | Grad Norm 0.2648(0.2615) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0228 | Time 24.4794, Epoch Time 413.5640(403.3386), Bit/dim 3.5199(best: 3.5150), Xent 0.0000, Loss 3.5199, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1369 | Time 64.1167(63.0015) | Bit/dim 3.5190(3.5181) | Xent 0.0000(0.0000) | Loss 11.8547(9.0172) | Error 0.0000(0.0000) Steps 658(655.32) | Grad Norm 0.2661(0.2617) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 66.1891(63.0971) | Bit/dim 3.5161(3.5181) | Xent 0.0000(0.0000) | Loss 8.3422(8.9969) | Error 0.0000(0.0000) Steps 664(655.58) | Grad Norm 0.1888(0.2595) | Total Time 0.00(0.00)\n",
      "Iter 1371 | Time 63.5853(63.1118) | Bit/dim 3.5164(3.5180) | Xent 0.0000(0.0000) | Loss 8.5494(8.9835) | Error 0.0000(0.0000) Steps 682(656.38) | Grad Norm 0.1920(0.2574) | Total Time 0.00(0.00)\n",
      "Iter 1372 | Time 68.8305(63.2834) | Bit/dim 3.5062(3.5177) | Xent 0.0000(0.0000) | Loss 8.4685(8.9680) | Error 0.0000(0.0000) Steps 676(656.97) | Grad Norm 0.1965(0.2556) | Total Time 0.00(0.00)\n",
      "Iter 1373 | Time 63.2333(63.2819) | Bit/dim 3.5162(3.5176) | Xent 0.0000(0.0000) | Loss 8.4533(8.9526) | Error 0.0000(0.0000) Steps 676(657.54) | Grad Norm 0.1767(0.2533) | Total Time 0.00(0.00)\n",
      "Iter 1374 | Time 61.0921(63.2162) | Bit/dim 3.5140(3.5175) | Xent 0.0000(0.0000) | Loss 8.3690(8.9351) | Error 0.0000(0.0000) Steps 652(657.37) | Grad Norm 0.2037(0.2518) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0229 | Time 24.5572, Epoch Time 427.7227(404.0701), Bit/dim 3.5142(best: 3.5150), Xent 0.0000, Loss 3.5142, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1375 | Time 60.3062(63.1289) | Bit/dim 3.5169(3.5175) | Xent 0.0000(0.0000) | Loss 11.9136(9.0244) | Error 0.0000(0.0000) Steps 646(657.03) | Grad Norm 0.2958(0.2531) | Total Time 0.00(0.00)\n",
      "Iter 1376 | Time 70.2944(63.3438) | Bit/dim 3.5114(3.5173) | Xent 0.0000(0.0000) | Loss 8.4298(9.0066) | Error 0.0000(0.0000) Steps 664(657.24) | Grad Norm 0.1653(0.2505) | Total Time 0.00(0.00)\n",
      "Iter 1377 | Time 61.8267(63.2983) | Bit/dim 3.5231(3.5175) | Xent 0.0000(0.0000) | Loss 8.3297(8.9863) | Error 0.0000(0.0000) Steps 658(657.26) | Grad Norm 0.2039(0.2491) | Total Time 0.00(0.00)\n",
      "Iter 1378 | Time 63.5558(63.3060) | Bit/dim 3.5154(3.5174) | Xent 0.0000(0.0000) | Loss 8.1024(8.9598) | Error 0.0000(0.0000) Steps 652(657.10) | Grad Norm 0.3754(0.2528) | Total Time 0.00(0.00)\n",
      "Iter 1379 | Time 62.6165(63.2854) | Bit/dim 3.5168(3.5174) | Xent 0.0000(0.0000) | Loss 8.4549(8.9446) | Error 0.0000(0.0000) Steps 670(657.49) | Grad Norm 0.1827(0.2507) | Total Time 0.00(0.00)\n",
      "Iter 1380 | Time 63.6472(63.2962) | Bit/dim 3.5155(3.5173) | Xent 0.0000(0.0000) | Loss 8.3791(8.9277) | Error 0.0000(0.0000) Steps 652(657.33) | Grad Norm 0.1712(0.2484) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0230 | Time 23.1527, Epoch Time 421.3393(404.5882), Bit/dim 3.5220(best: 3.5142), Xent 0.0000, Loss 3.5220, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1381 | Time 61.4847(63.2419) | Bit/dim 3.5153(3.5173) | Xent 0.0000(0.0000) | Loss 11.7958(9.0137) | Error 0.0000(0.0000) Steps 652(657.17) | Grad Norm 0.2660(0.2489) | Total Time 0.00(0.00)\n",
      "Iter 1382 | Time 63.6886(63.2553) | Bit/dim 3.5138(3.5172) | Xent 0.0000(0.0000) | Loss 8.4439(8.9966) | Error 0.0000(0.0000) Steps 658(657.19) | Grad Norm 0.1659(0.2464) | Total Time 0.00(0.00)\n",
      "Iter 1383 | Time 60.6576(63.1773) | Bit/dim 3.5237(3.5174) | Xent 0.0000(0.0000) | Loss 8.4349(8.9798) | Error 0.0000(0.0000) Steps 652(657.03) | Grad Norm 0.2070(0.2452) | Total Time 0.00(0.00)\n",
      "Iter 1384 | Time 63.0693(63.1741) | Bit/dim 3.5093(3.5171) | Xent 0.0000(0.0000) | Loss 8.2300(8.9573) | Error 0.0000(0.0000) Steps 640(656.52) | Grad Norm 0.1908(0.2436) | Total Time 0.00(0.00)\n",
      "Iter 1385 | Time 62.9864(63.1685) | Bit/dim 3.5211(3.5172) | Xent 0.0000(0.0000) | Loss 8.4226(8.9412) | Error 0.0000(0.0000) Steps 634(655.85) | Grad Norm 0.1888(0.2419) | Total Time 0.00(0.00)\n",
      "Iter 1386 | Time 64.3246(63.2031) | Bit/dim 3.5192(3.5173) | Xent 0.0000(0.0000) | Loss 8.5209(8.9286) | Error 0.0000(0.0000) Steps 652(655.73) | Grad Norm 0.2108(0.2410) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0231 | Time 23.5747, Epoch Time 415.7680(404.9236), Bit/dim 3.5197(best: 3.5142), Xent 0.0000, Loss 3.5197, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1387 | Time 64.7471(63.2495) | Bit/dim 3.5182(3.5173) | Xent 0.0000(0.0000) | Loss 12.2049(9.0269) | Error 0.0000(0.0000) Steps 670(656.16) | Grad Norm 0.2947(0.2426) | Total Time 0.00(0.00)\n",
      "Iter 1388 | Time 68.1402(63.3962) | Bit/dim 3.5198(3.5174) | Xent 0.0000(0.0000) | Loss 8.3869(9.0077) | Error 0.0000(0.0000) Steps 652(656.04) | Grad Norm 0.2388(0.2425) | Total Time 0.00(0.00)\n",
      "Iter 1389 | Time 62.5145(63.3697) | Bit/dim 3.5218(3.5175) | Xent 0.0000(0.0000) | Loss 8.2427(8.9848) | Error 0.0000(0.0000) Steps 646(655.73) | Grad Norm 0.2829(0.2437) | Total Time 0.00(0.00)\n",
      "Iter 1390 | Time 68.1532(63.5132) | Bit/dim 3.4975(3.5169) | Xent 0.0000(0.0000) | Loss 8.0889(8.9579) | Error 0.0000(0.0000) Steps 670(656.16) | Grad Norm 0.2720(0.2446) | Total Time 0.00(0.00)\n",
      "Iter 1391 | Time 68.7075(63.6691) | Bit/dim 3.5143(3.5169) | Xent 0.0000(0.0000) | Loss 8.4083(8.9414) | Error 0.0000(0.0000) Steps 688(657.12) | Grad Norm 0.2045(0.2434) | Total Time 0.00(0.00)\n",
      "Iter 1392 | Time 65.0773(63.7113) | Bit/dim 3.5317(3.5173) | Xent 0.0000(0.0000) | Loss 8.5676(8.9302) | Error 0.0000(0.0000) Steps 676(657.68) | Grad Norm 0.1999(0.2421) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0232 | Time 24.2994, Epoch Time 437.4697(405.8999), Bit/dim 3.5123(best: 3.5142), Xent 0.0000, Loss 3.5123, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1393 | Time 63.0646(63.6919) | Bit/dim 3.5194(3.5174) | Xent 0.0000(0.0000) | Loss 12.1690(9.0273) | Error 0.0000(0.0000) Steps 682(658.41) | Grad Norm 0.2036(0.2409) | Total Time 0.00(0.00)\n",
      "Iter 1394 | Time 64.0491(63.7026) | Bit/dim 3.5132(3.5172) | Xent 0.0000(0.0000) | Loss 8.4126(9.0089) | Error 0.0000(0.0000) Steps 652(658.22) | Grad Norm 0.1576(0.2384) | Total Time 0.00(0.00)\n",
      "Iter 1395 | Time 63.4082(63.6938) | Bit/dim 3.5272(3.5175) | Xent 0.0000(0.0000) | Loss 8.3483(8.9891) | Error 0.0000(0.0000) Steps 664(658.39) | Grad Norm 0.1989(0.2372) | Total Time 0.00(0.00)\n",
      "Iter 1396 | Time 62.5548(63.6596) | Bit/dim 3.5298(3.5179) | Xent 0.0000(0.0000) | Loss 8.1748(8.9647) | Error 0.0000(0.0000) Steps 640(657.84) | Grad Norm 0.3436(0.2404) | Total Time 0.00(0.00)\n",
      "Iter 1397 | Time 62.8865(63.6364) | Bit/dim 3.5078(3.5176) | Xent 0.0000(0.0000) | Loss 8.3286(8.9456) | Error 0.0000(0.0000) Steps 652(657.67) | Grad Norm 0.2030(0.2393) | Total Time 0.00(0.00)\n",
      "Iter 1398 | Time 63.7269(63.6391) | Bit/dim 3.5088(3.5173) | Xent 0.0000(0.0000) | Loss 8.2815(8.9257) | Error 0.0000(0.0000) Steps 646(657.32) | Grad Norm 0.1984(0.2381) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0233 | Time 23.6341, Epoch Time 418.8804(406.2894), Bit/dim 3.5212(best: 3.5123), Xent 0.0000, Loss 3.5212, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1399 | Time 65.7660(63.7030) | Bit/dim 3.5137(3.5172) | Xent 0.0000(0.0000) | Loss 11.5542(9.0045) | Error 0.0000(0.0000) Steps 676(657.88) | Grad Norm 0.3949(0.2428) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 59.8716(63.5880) | Bit/dim 3.5112(3.5171) | Xent 0.0000(0.0000) | Loss 8.3819(8.9858) | Error 0.0000(0.0000) Steps 658(657.88) | Grad Norm 0.2136(0.2419) | Total Time 0.00(0.00)\n",
      "Iter 1401 | Time 61.0921(63.5131) | Bit/dim 3.5196(3.5171) | Xent 0.0000(0.0000) | Loss 8.2297(8.9631) | Error 0.0000(0.0000) Steps 658(657.89) | Grad Norm 0.2477(0.2421) | Total Time 0.00(0.00)\n",
      "Iter 1402 | Time 62.6105(63.4861) | Bit/dim 3.5057(3.5168) | Xent 0.0000(0.0000) | Loss 8.3919(8.9460) | Error 0.0000(0.0000) Steps 646(657.53) | Grad Norm 0.1590(0.2396) | Total Time 0.00(0.00)\n",
      "Iter 1403 | Time 61.5672(63.4285) | Bit/dim 3.5233(3.5170) | Xent 0.0000(0.0000) | Loss 8.1957(8.9235) | Error 0.0000(0.0000) Steps 640(657.00) | Grad Norm 0.2314(0.2393) | Total Time 0.00(0.00)\n",
      "Iter 1404 | Time 63.1945(63.4215) | Bit/dim 3.5290(3.5173) | Xent 0.0000(0.0000) | Loss 8.4385(8.9090) | Error 0.0000(0.0000) Steps 658(657.03) | Grad Norm 0.2273(0.2390) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0234 | Time 24.4014, Epoch Time 414.4956(406.5355), Bit/dim 3.5226(best: 3.5123), Xent 0.0000, Loss 3.5226, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1405 | Time 65.0062(63.4690) | Bit/dim 3.5094(3.5171) | Xent 0.0000(0.0000) | Loss 11.6562(8.9914) | Error 0.0000(0.0000) Steps 634(656.34) | Grad Norm 0.3003(0.2408) | Total Time 0.00(0.00)\n",
      "Iter 1406 | Time 63.2397(63.4621) | Bit/dim 3.5169(3.5171) | Xent 0.0000(0.0000) | Loss 8.4035(8.9737) | Error 0.0000(0.0000) Steps 646(656.03) | Grad Norm 0.1537(0.2382) | Total Time 0.00(0.00)\n",
      "Iter 1407 | Time 62.0502(63.4198) | Bit/dim 3.5072(3.5168) | Xent 0.0000(0.0000) | Loss 8.2447(8.9519) | Error 0.0000(0.0000) Steps 646(655.73) | Grad Norm 0.1940(0.2369) | Total Time 0.00(0.00)\n",
      "Iter 1408 | Time 61.1021(63.3502) | Bit/dim 3.5288(3.5172) | Xent 0.0000(0.0000) | Loss 8.2134(8.9297) | Error 0.0000(0.0000) Steps 646(655.44) | Grad Norm 0.2070(0.2360) | Total Time 0.00(0.00)\n",
      "Iter 1409 | Time 63.2463(63.3471) | Bit/dim 3.5098(3.5169) | Xent 0.0000(0.0000) | Loss 8.2679(8.9099) | Error 0.0000(0.0000) Steps 658(655.52) | Grad Norm 0.2127(0.2353) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 65.5439(63.4130) | Bit/dim 3.5134(3.5168) | Xent 0.0000(0.0000) | Loss 8.2839(8.8911) | Error 0.0000(0.0000) Steps 676(656.13) | Grad Norm 0.2018(0.2343) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0235 | Time 23.3633, Epoch Time 419.7129(406.9309), Bit/dim 3.5181(best: 3.5123), Xent 0.0000, Loss 3.5181, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1411 | Time 62.4140(63.3831) | Bit/dim 3.5087(3.5166) | Xent 0.0000(0.0000) | Loss 12.1848(8.9899) | Error 0.0000(0.0000) Steps 652(656.01) | Grad Norm 0.2249(0.2340) | Total Time 0.00(0.00)\n",
      "Iter 1412 | Time 65.2210(63.4382) | Bit/dim 3.5101(3.5164) | Xent 0.0000(0.0000) | Loss 8.4799(8.9746) | Error 0.0000(0.0000) Steps 670(656.43) | Grad Norm 0.1532(0.2316) | Total Time 0.00(0.00)\n",
      "Iter 1413 | Time 61.2724(63.3732) | Bit/dim 3.5180(3.5164) | Xent 0.0000(0.0000) | Loss 8.3639(8.9563) | Error 0.0000(0.0000) Steps 646(656.11) | Grad Norm 0.1835(0.2301) | Total Time 0.00(0.00)\n",
      "Iter 1414 | Time 63.9742(63.3912) | Bit/dim 3.5159(3.5164) | Xent 0.0000(0.0000) | Loss 8.5587(8.9443) | Error 0.0000(0.0000) Steps 676(656.71) | Grad Norm 0.1537(0.2278) | Total Time 0.00(0.00)\n",
      "Iter 1415 | Time 64.8904(63.4362) | Bit/dim 3.5269(3.5167) | Xent 0.0000(0.0000) | Loss 8.4846(8.9305) | Error 0.0000(0.0000) Steps 646(656.39) | Grad Norm 0.1588(0.2258) | Total Time 0.00(0.00)\n",
      "Iter 1416 | Time 61.4863(63.3777) | Bit/dim 3.5103(3.5166) | Xent 0.0000(0.0000) | Loss 8.5022(8.9177) | Error 0.0000(0.0000) Steps 664(656.62) | Grad Norm 0.1605(0.2238) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0236 | Time 24.2159, Epoch Time 419.6632(407.3128), Bit/dim 3.5192(best: 3.5123), Xent 0.0000, Loss 3.5192, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1417 | Time 64.7439(63.4187) | Bit/dim 3.5136(3.5165) | Xent 0.0000(0.0000) | Loss 12.1318(9.0141) | Error 0.0000(0.0000) Steps 688(657.56) | Grad Norm 0.2285(0.2239) | Total Time 0.00(0.00)\n",
      "Iter 1418 | Time 63.0447(63.4075) | Bit/dim 3.5213(3.5166) | Xent 0.0000(0.0000) | Loss 8.5059(8.9989) | Error 0.0000(0.0000) Steps 664(657.75) | Grad Norm 0.1547(0.2219) | Total Time 0.00(0.00)\n",
      "Iter 1419 | Time 66.3631(63.4962) | Bit/dim 3.5211(3.5167) | Xent 0.0000(0.0000) | Loss 8.4020(8.9810) | Error 0.0000(0.0000) Steps 676(658.30) | Grad Norm 0.2033(0.2213) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 68.6039(63.6494) | Bit/dim 3.5144(3.5167) | Xent 0.0000(0.0000) | Loss 8.4694(8.9656) | Error 0.0000(0.0000) Steps 658(658.29) | Grad Norm 0.1623(0.2195) | Total Time 0.00(0.00)\n",
      "Iter 1421 | Time 62.6922(63.6207) | Bit/dim 3.5137(3.5166) | Xent 0.0000(0.0000) | Loss 8.5488(8.9531) | Error 0.0000(0.0000) Steps 670(658.64) | Grad Norm 0.2266(0.2198) | Total Time 0.00(0.00)\n",
      "Iter 1422 | Time 66.6010(63.7101) | Bit/dim 3.5135(3.5165) | Xent 0.0000(0.0000) | Loss 8.1757(8.9298) | Error 0.0000(0.0000) Steps 658(658.62) | Grad Norm 0.2569(0.2209) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0237 | Time 24.0463, Epoch Time 432.0091(408.0537), Bit/dim 3.5168(best: 3.5123), Xent 0.0000, Loss 3.5168, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1423 | Time 60.0199(63.5994) | Bit/dim 3.5241(3.5167) | Xent 0.0000(0.0000) | Loss 11.8015(9.0159) | Error 0.0000(0.0000) Steps 646(658.24) | Grad Norm 0.2496(0.2217) | Total Time 0.00(0.00)\n",
      "Iter 1424 | Time 67.0036(63.7015) | Bit/dim 3.5084(3.5165) | Xent 0.0000(0.0000) | Loss 8.3277(8.9953) | Error 0.0000(0.0000) Steps 676(658.78) | Grad Norm 0.4333(0.2281) | Total Time 0.00(0.00)\n",
      "Iter 1425 | Time 65.8717(63.7666) | Bit/dim 3.5178(3.5165) | Xent 0.0000(0.0000) | Loss 8.4211(8.9781) | Error 0.0000(0.0000) Steps 652(658.57) | Grad Norm 0.1525(0.2258) | Total Time 0.00(0.00)\n",
      "Iter 1426 | Time 65.5112(63.8190) | Bit/dim 3.5113(3.5164) | Xent 0.0000(0.0000) | Loss 8.4029(8.9608) | Error 0.0000(0.0000) Steps 670(658.92) | Grad Norm 0.1967(0.2249) | Total Time 0.00(0.00)\n",
      "Iter 1427 | Time 63.3931(63.8062) | Bit/dim 3.5197(3.5165) | Xent 0.0000(0.0000) | Loss 8.3543(8.9426) | Error 0.0000(0.0000) Steps 622(657.81) | Grad Norm 0.2020(0.2243) | Total Time 0.00(0.00)\n",
      "Iter 1428 | Time 63.5855(63.7996) | Bit/dim 3.5155(3.5164) | Xent 0.0000(0.0000) | Loss 8.3416(8.9246) | Error 0.0000(0.0000) Steps 664(657.99) | Grad Norm 0.2633(0.2254) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0238 | Time 23.8678, Epoch Time 425.0259(408.5629), Bit/dim 3.5199(best: 3.5123), Xent 0.0000, Loss 3.5199, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1429 | Time 63.9272(63.8034) | Bit/dim 3.5118(3.5163) | Xent 0.0000(0.0000) | Loss 12.0035(9.0170) | Error 0.0000(0.0000) Steps 688(658.89) | Grad Norm 0.4400(0.2319) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 59.0165(63.6598) | Bit/dim 3.5206(3.5164) | Xent 0.0000(0.0000) | Loss 8.2068(8.9926) | Error 0.0000(0.0000) Steps 640(658.33) | Grad Norm 0.2357(0.2320) | Total Time 0.00(0.00)\n",
      "Iter 1431 | Time 67.4764(63.7743) | Bit/dim 3.5199(3.5165) | Xent 0.0000(0.0000) | Loss 8.3611(8.9737) | Error 0.0000(0.0000) Steps 676(658.86) | Grad Norm 0.2910(0.2337) | Total Time 0.00(0.00)\n",
      "Iter 1432 | Time 60.9260(63.6888) | Bit/dim 3.5229(3.5167) | Xent 0.0000(0.0000) | Loss 8.4527(8.9581) | Error 0.0000(0.0000) Steps 646(658.47) | Grad Norm 0.1664(0.2317) | Total Time 0.00(0.00)\n",
      "Iter 1433 | Time 60.9861(63.6077) | Bit/dim 3.5242(3.5169) | Xent 0.0000(0.0000) | Loss 8.2514(8.9369) | Error 0.0000(0.0000) Steps 628(657.56) | Grad Norm 0.2456(0.2321) | Total Time 0.00(0.00)\n",
      "Iter 1434 | Time 61.8400(63.5547) | Bit/dim 3.5061(3.5166) | Xent 0.0000(0.0000) | Loss 8.3250(8.9185) | Error 0.0000(0.0000) Steps 646(657.21) | Grad Norm 0.1826(0.2307) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0239 | Time 23.7945, Epoch Time 413.4347(408.7090), Bit/dim 3.5136(best: 3.5123), Xent 0.0000, Loss 3.5136, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1435 | Time 67.4191(63.6706) | Bit/dim 3.5202(3.5167) | Xent 0.0000(0.0000) | Loss 12.0609(9.0128) | Error 0.0000(0.0000) Steps 676(657.77) | Grad Norm 0.2137(0.2301) | Total Time 0.00(0.00)\n",
      "Iter 1436 | Time 65.7676(63.7336) | Bit/dim 3.5182(3.5168) | Xent 0.0000(0.0000) | Loss 8.3903(8.9941) | Error 0.0000(0.0000) Steps 664(657.96) | Grad Norm 0.1999(0.2292) | Total Time 0.00(0.00)\n",
      "Iter 1437 | Time 63.8358(63.7366) | Bit/dim 3.5145(3.5167) | Xent 0.0000(0.0000) | Loss 8.3651(8.9752) | Error 0.0000(0.0000) Steps 646(657.60) | Grad Norm 0.1863(0.2280) | Total Time 0.00(0.00)\n",
      "Iter 1438 | Time 68.0005(63.8645) | Bit/dim 3.5103(3.5165) | Xent 0.0000(0.0000) | Loss 8.4212(8.9586) | Error 0.0000(0.0000) Steps 658(657.61) | Grad Norm 0.1541(0.2257) | Total Time 0.00(0.00)\n",
      "Iter 1439 | Time 68.0217(63.9893) | Bit/dim 3.5226(3.5167) | Xent 0.0000(0.0000) | Loss 8.5731(8.9471) | Error 0.0000(0.0000) Steps 682(658.35) | Grad Norm 0.2029(0.2251) | Total Time 0.00(0.00)\n",
      "Iter 1440 | Time 57.7582(63.8023) | Bit/dim 3.5184(3.5167) | Xent 0.0000(0.0000) | Loss 8.1356(8.9227) | Error 0.0000(0.0000) Steps 640(657.80) | Grad Norm 0.6116(0.2367) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0240 | Time 24.6304, Epoch Time 431.0131(409.3782), Bit/dim 3.5180(best: 3.5123), Xent 0.0000, Loss 3.5180, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1441 | Time 67.7210(63.9199) | Bit/dim 3.5034(3.5163) | Xent 0.0000(0.0000) | Loss 12.0202(9.0156) | Error 0.0000(0.0000) Steps 682(658.52) | Grad Norm 0.4042(0.2417) | Total Time 0.00(0.00)\n",
      "Iter 1442 | Time 66.6297(64.0012) | Bit/dim 3.5119(3.5162) | Xent 0.0000(0.0000) | Loss 8.2974(8.9941) | Error 0.0000(0.0000) Steps 658(658.51) | Grad Norm 0.3021(0.2435) | Total Time 0.00(0.00)\n",
      "Iter 1443 | Time 66.7441(64.0835) | Bit/dim 3.5179(3.5163) | Xent 0.0000(0.0000) | Loss 8.4029(8.9764) | Error 0.0000(0.0000) Steps 670(658.85) | Grad Norm 0.3011(0.2452) | Total Time 0.00(0.00)\n",
      "Iter 1444 | Time 60.8239(63.9857) | Bit/dim 3.5131(3.5162) | Xent 0.0000(0.0000) | Loss 8.3024(8.9561) | Error 0.0000(0.0000) Steps 652(658.65) | Grad Norm 0.2302(0.2448) | Total Time 0.00(0.00)\n",
      "Iter 1445 | Time 64.9189(64.0137) | Bit/dim 3.5228(3.5164) | Xent 0.0000(0.0000) | Loss 8.2629(8.9353) | Error 0.0000(0.0000) Steps 658(658.63) | Grad Norm 0.2986(0.2464) | Total Time 0.00(0.00)\n",
      "Iter 1446 | Time 63.9713(64.0124) | Bit/dim 3.5095(3.5162) | Xent 0.0000(0.0000) | Loss 8.2231(8.9140) | Error 0.0000(0.0000) Steps 634(657.89) | Grad Norm 0.2245(0.2457) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0241 | Time 24.1388, Epoch Time 430.5959(410.0147), Bit/dim 3.5156(best: 3.5123), Xent 0.0000, Loss 3.5156, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1447 | Time 59.1352(63.8661) | Bit/dim 3.5083(3.5159) | Xent 0.0000(0.0000) | Loss 11.5395(8.9927) | Error 0.0000(0.0000) Steps 634(657.17) | Grad Norm 0.3742(0.2496) | Total Time 0.00(0.00)\n",
      "Iter 1448 | Time 64.0237(63.8708) | Bit/dim 3.5212(3.5161) | Xent 0.0000(0.0000) | Loss 8.3982(8.9749) | Error 0.0000(0.0000) Steps 670(657.56) | Grad Norm 0.2043(0.2482) | Total Time 0.00(0.00)\n",
      "Iter 1449 | Time 62.2024(63.8208) | Bit/dim 3.5148(3.5160) | Xent 0.0000(0.0000) | Loss 8.3376(8.9558) | Error 0.0000(0.0000) Steps 640(657.03) | Grad Norm 0.2375(0.2479) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 63.1223(63.7998) | Bit/dim 3.5090(3.5158) | Xent 0.0000(0.0000) | Loss 8.4874(8.9417) | Error 0.0000(0.0000) Steps 670(657.42) | Grad Norm 0.1670(0.2455) | Total Time 0.00(0.00)\n",
      "Iter 1451 | Time 66.0079(63.8661) | Bit/dim 3.5139(3.5158) | Xent 0.0000(0.0000) | Loss 8.4352(8.9265) | Error 0.0000(0.0000) Steps 664(657.62) | Grad Norm 0.2078(0.2443) | Total Time 0.00(0.00)\n",
      "Iter 1452 | Time 66.0947(63.9329) | Bit/dim 3.5136(3.5157) | Xent 0.0000(0.0000) | Loss 8.3530(8.9093) | Error 0.0000(0.0000) Steps 676(658.17) | Grad Norm 0.2111(0.2433) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0242 | Time 23.5472, Epoch Time 419.4219(410.2969), Bit/dim 3.5179(best: 3.5123), Xent 0.0000, Loss 3.5179, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1453 | Time 59.5900(63.8026) | Bit/dim 3.5091(3.5155) | Xent 0.0000(0.0000) | Loss 11.8180(8.9966) | Error 0.0000(0.0000) Steps 646(657.80) | Grad Norm 0.5327(0.2520) | Total Time 0.00(0.00)\n",
      "Iter 1454 | Time 68.0339(63.9296) | Bit/dim 3.5207(3.5157) | Xent 0.0000(0.0000) | Loss 8.5268(8.9825) | Error 0.0000(0.0000) Steps 694(658.89) | Grad Norm 0.2274(0.2513) | Total Time 0.00(0.00)\n",
      "Iter 1455 | Time 64.3779(63.9430) | Bit/dim 3.5080(3.5154) | Xent 0.0000(0.0000) | Loss 8.3147(8.9625) | Error 0.0000(0.0000) Steps 676(659.40) | Grad Norm 0.2463(0.2511) | Total Time 0.00(0.00)\n",
      "Iter 1456 | Time 59.6638(63.8146) | Bit/dim 3.5169(3.5155) | Xent 0.0000(0.0000) | Loss 8.1879(8.9392) | Error 0.0000(0.0000) Steps 646(659.00) | Grad Norm 0.2040(0.2497) | Total Time 0.00(0.00)\n",
      "Iter 1457 | Time 65.8271(63.8750) | Bit/dim 3.5172(3.5155) | Xent 0.0000(0.0000) | Loss 8.2180(8.9176) | Error 0.0000(0.0000) Steps 652(658.79) | Grad Norm 0.3586(0.2530) | Total Time 0.00(0.00)\n",
      "Iter 1458 | Time 63.9233(63.8765) | Bit/dim 3.5128(3.5154) | Xent 0.0000(0.0000) | Loss 8.3066(8.8993) | Error 0.0000(0.0000) Steps 652(658.59) | Grad Norm 0.2444(0.2527) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0243 | Time 23.6024, Epoch Time 420.6923(410.6088), Bit/dim 3.5130(best: 3.5123), Xent 0.0000, Loss 3.5130, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1459 | Time 62.5920(63.8379) | Bit/dim 3.5117(3.5153) | Xent 0.0000(0.0000) | Loss 12.1664(8.9973) | Error 0.0000(0.0000) Steps 670(658.93) | Grad Norm 0.2135(0.2516) | Total Time 0.00(0.00)\n",
      "Iter 1460 | Time 67.3440(63.9431) | Bit/dim 3.5138(3.5153) | Xent 0.0000(0.0000) | Loss 8.4886(8.9820) | Error 0.0000(0.0000) Steps 676(659.44) | Grad Norm 0.2160(0.2505) | Total Time 0.00(0.00)\n",
      "Iter 1461 | Time 66.9019(64.0319) | Bit/dim 3.5128(3.5152) | Xent 0.0000(0.0000) | Loss 8.4189(8.9651) | Error 0.0000(0.0000) Steps 664(659.58) | Grad Norm 0.1736(0.2482) | Total Time 0.00(0.00)\n",
      "Iter 1462 | Time 66.7185(64.1125) | Bit/dim 3.5140(3.5152) | Xent 0.0000(0.0000) | Loss 8.3460(8.9465) | Error 0.0000(0.0000) Steps 664(659.71) | Grad Norm 0.2801(0.2491) | Total Time 0.00(0.00)\n",
      "Iter 1463 | Time 64.0925(64.1119) | Bit/dim 3.5096(3.5150) | Xent 0.0000(0.0000) | Loss 8.3138(8.9276) | Error 0.0000(0.0000) Steps 670(660.02) | Grad Norm 0.2203(0.2483) | Total Time 0.00(0.00)\n",
      "Iter 1464 | Time 61.4401(64.0317) | Bit/dim 3.5115(3.5149) | Xent 0.0000(0.0000) | Loss 8.2255(8.9065) | Error 0.0000(0.0000) Steps 664(660.14) | Grad Norm 0.2530(0.2484) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0244 | Time 24.1733, Epoch Time 429.1608(411.1653), Bit/dim 3.5117(best: 3.5123), Xent 0.0000, Loss 3.5117, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1465 | Time 61.2262(63.9475) | Bit/dim 3.5121(3.5148) | Xent 0.0000(0.0000) | Loss 11.7973(8.9932) | Error 0.0000(0.0000) Steps 640(659.53) | Grad Norm 0.2690(0.2490) | Total Time 0.00(0.00)\n",
      "Iter 1466 | Time 64.5456(63.9655) | Bit/dim 3.5128(3.5148) | Xent 0.0000(0.0000) | Loss 8.3027(8.9725) | Error 0.0000(0.0000) Steps 652(659.31) | Grad Norm 0.2293(0.2484) | Total Time 0.00(0.00)\n",
      "Iter 1467 | Time 68.6802(64.1069) | Bit/dim 3.5186(3.5149) | Xent 0.0000(0.0000) | Loss 8.5110(8.9587) | Error 0.0000(0.0000) Steps 682(659.99) | Grad Norm 0.1764(0.2463) | Total Time 0.00(0.00)\n",
      "Iter 1468 | Time 62.7872(64.0673) | Bit/dim 3.5113(3.5148) | Xent 0.0000(0.0000) | Loss 8.2643(8.9378) | Error 0.0000(0.0000) Steps 658(659.93) | Grad Norm 0.2817(0.2473) | Total Time 0.00(0.00)\n",
      "Iter 1469 | Time 64.6914(64.0861) | Bit/dim 3.5102(3.5146) | Xent 0.0000(0.0000) | Loss 8.3603(8.9205) | Error 0.0000(0.0000) Steps 652(659.69) | Grad Norm 0.1733(0.2451) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 65.5009(64.1285) | Bit/dim 3.5168(3.5147) | Xent 0.0000(0.0000) | Loss 8.3085(8.9021) | Error 0.0000(0.0000) Steps 658(659.64) | Grad Norm 0.1648(0.2427) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0245 | Time 24.0152, Epoch Time 427.2143(411.6468), Bit/dim 3.5108(best: 3.5117), Xent 0.0000, Loss 3.5108, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1471 | Time 63.0827(64.0971) | Bit/dim 3.5303(3.5152) | Xent 0.0000(0.0000) | Loss 12.0816(8.9975) | Error 0.0000(0.0000) Steps 652(659.41) | Grad Norm 0.2875(0.2441) | Total Time 0.00(0.00)\n",
      "Iter 1472 | Time 65.5568(64.1409) | Bit/dim 3.5106(3.5150) | Xent 0.0000(0.0000) | Loss 8.3315(8.9775) | Error 0.0000(0.0000) Steps 658(659.37) | Grad Norm 0.1840(0.2422) | Total Time 0.00(0.00)\n",
      "Iter 1473 | Time 64.2720(64.1449) | Bit/dim 3.5157(3.5150) | Xent 0.0000(0.0000) | Loss 8.0259(8.9490) | Error 0.0000(0.0000) Steps 652(659.15) | Grad Norm 0.3244(0.2447) | Total Time 0.00(0.00)\n",
      "Iter 1474 | Time 64.3696(64.1516) | Bit/dim 3.4963(3.5145) | Xent 0.0000(0.0000) | Loss 8.4271(8.9333) | Error 0.0000(0.0000) Steps 646(658.75) | Grad Norm 0.1819(0.2428) | Total Time 0.00(0.00)\n",
      "Iter 1475 | Time 65.4754(64.1913) | Bit/dim 3.5120(3.5144) | Xent 0.0000(0.0000) | Loss 8.4071(8.9176) | Error 0.0000(0.0000) Steps 670(659.09) | Grad Norm 0.2107(0.2419) | Total Time 0.00(0.00)\n",
      "Iter 1476 | Time 64.9849(64.2151) | Bit/dim 3.5076(3.5142) | Xent 0.0000(0.0000) | Loss 8.3561(8.9007) | Error 0.0000(0.0000) Steps 664(659.24) | Grad Norm 0.1996(0.2406) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0246 | Time 24.0562, Epoch Time 427.7938(412.1312), Bit/dim 3.5147(best: 3.5108), Xent 0.0000, Loss 3.5147, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1477 | Time 62.6805(64.1691) | Bit/dim 3.5173(3.5143) | Xent 0.0000(0.0000) | Loss 11.7220(8.9853) | Error 0.0000(0.0000) Steps 652(659.02) | Grad Norm 0.2515(0.2409) | Total Time 0.00(0.00)\n",
      "Iter 1478 | Time 61.6007(64.0920) | Bit/dim 3.5147(3.5143) | Xent 0.0000(0.0000) | Loss 8.4255(8.9686) | Error 0.0000(0.0000) Steps 646(658.63) | Grad Norm 0.1608(0.2385) | Total Time 0.00(0.00)\n",
      "Iter 1479 | Time 64.2904(64.0980) | Bit/dim 3.5111(3.5142) | Xent 0.0000(0.0000) | Loss 8.3225(8.9492) | Error 0.0000(0.0000) Steps 658(658.61) | Grad Norm 0.1939(0.2372) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 67.1469(64.1894) | Bit/dim 3.5110(3.5141) | Xent 0.0000(0.0000) | Loss 8.5264(8.9365) | Error 0.0000(0.0000) Steps 688(659.49) | Grad Norm 0.2000(0.2361) | Total Time 0.00(0.00)\n",
      "Iter 1481 | Time 63.1484(64.1582) | Bit/dim 3.5214(3.5143) | Xent 0.0000(0.0000) | Loss 8.3179(8.9179) | Error 0.0000(0.0000) Steps 652(659.27) | Grad Norm 0.2356(0.2361) | Total Time 0.00(0.00)\n",
      "Iter 1482 | Time 65.4191(64.1960) | Bit/dim 3.5029(3.5140) | Xent 0.0000(0.0000) | Loss 8.4607(8.9042) | Error 0.0000(0.0000) Steps 658(659.23) | Grad Norm 0.1881(0.2346) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0247 | Time 23.7973, Epoch Time 424.5411(412.5035), Bit/dim 3.5112(best: 3.5108), Xent 0.0000, Loss 3.5112, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1483 | Time 62.8518(64.1557) | Bit/dim 3.5149(3.5140) | Xent 0.0000(0.0000) | Loss 12.2631(9.0050) | Error 0.0000(0.0000) Steps 670(659.55) | Grad Norm 0.2090(0.2338) | Total Time 0.00(0.00)\n",
      "Iter 1484 | Time 61.9061(64.0882) | Bit/dim 3.5120(3.5140) | Xent 0.0000(0.0000) | Loss 8.3520(8.9854) | Error 0.0000(0.0000) Steps 664(659.69) | Grad Norm 0.2399(0.2340) | Total Time 0.00(0.00)\n",
      "Iter 1485 | Time 63.9705(64.0847) | Bit/dim 3.5177(3.5141) | Xent 0.0000(0.0000) | Loss 8.4087(8.9681) | Error 0.0000(0.0000) Steps 670(660.00) | Grad Norm 0.1899(0.2327) | Total Time 0.00(0.00)\n",
      "Iter 1486 | Time 66.8242(64.1669) | Bit/dim 3.5050(3.5138) | Xent 0.0000(0.0000) | Loss 8.3990(8.9510) | Error 0.0000(0.0000) Steps 688(660.84) | Grad Norm 0.1901(0.2314) | Total Time 0.00(0.00)\n",
      "Iter 1487 | Time 63.1963(64.1378) | Bit/dim 3.5074(3.5136) | Xent 0.0000(0.0000) | Loss 8.3563(8.9332) | Error 0.0000(0.0000) Steps 676(661.29) | Grad Norm 0.2517(0.2320) | Total Time 0.00(0.00)\n",
      "Iter 1488 | Time 62.8297(64.0985) | Bit/dim 3.5201(3.5138) | Xent 0.0000(0.0000) | Loss 8.2759(8.9135) | Error 0.0000(0.0000) Steps 640(660.65) | Grad Norm 0.2267(0.2319) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0248 | Time 23.9406, Epoch Time 422.0355(412.7895), Bit/dim 3.5197(best: 3.5108), Xent 0.0000, Loss 3.5197, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1489 | Time 62.1927(64.0414) | Bit/dim 3.5177(3.5139) | Xent 0.0000(0.0000) | Loss 11.8639(9.0020) | Error 0.0000(0.0000) Steps 664(660.75) | Grad Norm 0.2653(0.2329) | Total Time 0.00(0.00)\n",
      "Iter 1490 | Time 64.5566(64.0568) | Bit/dim 3.5164(3.5140) | Xent 0.0000(0.0000) | Loss 8.4537(8.9855) | Error 0.0000(0.0000) Steps 676(661.21) | Grad Norm 0.1988(0.2319) | Total Time 0.00(0.00)\n",
      "Iter 1491 | Time 66.9247(64.1428) | Bit/dim 3.5087(3.5138) | Xent 0.0000(0.0000) | Loss 8.3492(8.9664) | Error 0.0000(0.0000) Steps 676(661.65) | Grad Norm 0.1945(0.2307) | Total Time 0.00(0.00)\n",
      "Iter 1492 | Time 64.3166(64.1481) | Bit/dim 3.4965(3.5133) | Xent 0.0000(0.0000) | Loss 8.2820(8.9459) | Error 0.0000(0.0000) Steps 646(661.18) | Grad Norm 0.1661(0.2288) | Total Time 0.00(0.00)\n",
      "Iter 1493 | Time 64.5216(64.1593) | Bit/dim 3.5214(3.5136) | Xent 0.0000(0.0000) | Loss 8.3860(8.9291) | Error 0.0000(0.0000) Steps 664(661.27) | Grad Norm 0.1807(0.2273) | Total Time 0.00(0.00)\n",
      "Iter 1494 | Time 62.3594(64.1053) | Bit/dim 3.5130(3.5135) | Xent 0.0000(0.0000) | Loss 8.4274(8.9141) | Error 0.0000(0.0000) Steps 646(660.81) | Grad Norm 0.1630(0.2254) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0249 | Time 24.0489, Epoch Time 424.9193(413.1534), Bit/dim 3.5200(best: 3.5108), Xent 0.0000, Loss 3.5200, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1495 | Time 62.6035(64.0602) | Bit/dim 3.5122(3.5135) | Xent 0.0000(0.0000) | Loss 12.1353(9.0107) | Error 0.0000(0.0000) Steps 652(660.55) | Grad Norm 0.2976(0.2276) | Total Time 0.00(0.00)\n",
      "Iter 1496 | Time 66.6730(64.1386) | Bit/dim 3.5172(3.5136) | Xent 0.0000(0.0000) | Loss 8.4352(8.9934) | Error 0.0000(0.0000) Steps 676(661.01) | Grad Norm 0.1663(0.2257) | Total Time 0.00(0.00)\n",
      "Iter 1497 | Time 64.0083(64.1347) | Bit/dim 3.5084(3.5134) | Xent 0.0000(0.0000) | Loss 8.2282(8.9705) | Error 0.0000(0.0000) Steps 664(661.10) | Grad Norm 0.3132(0.2284) | Total Time 0.00(0.00)\n",
      "Iter 1498 | Time 61.4740(64.0549) | Bit/dim 3.5041(3.5132) | Xent 0.0000(0.0000) | Loss 8.4373(8.9545) | Error 0.0000(0.0000) Steps 652(660.83) | Grad Norm 0.1749(0.2268) | Total Time 0.00(0.00)\n",
      "Iter 1499 | Time 66.4360(64.1263) | Bit/dim 3.5230(3.5135) | Xent 0.0000(0.0000) | Loss 8.3265(8.9356) | Error 0.0000(0.0000) Steps 676(661.28) | Grad Norm 0.1822(0.2254) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 61.7138(64.0539) | Bit/dim 3.5116(3.5134) | Xent 0.0000(0.0000) | Loss 8.3835(8.9191) | Error 0.0000(0.0000) Steps 664(661.36) | Grad Norm 0.1880(0.2243) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0250 | Time 24.7230, Epoch Time 423.7969(413.4727), Bit/dim 3.5125(best: 3.5108), Xent 0.0000, Loss 3.5125, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1501 | Time 65.5949(64.1002) | Bit/dim 3.5134(3.5134) | Xent 0.0000(0.0000) | Loss 11.9131(9.0089) | Error 0.0000(0.0000) Steps 664(661.44) | Grad Norm 0.1935(0.2234) | Total Time 0.00(0.00)\n",
      "Iter 1502 | Time 77.8609(64.5130) | Bit/dim 3.5142(3.5134) | Xent 0.0000(0.0000) | Loss 8.4671(8.9926) | Error 0.0000(0.0000) Steps 658(661.34) | Grad Norm 0.1710(0.2218) | Total Time 0.00(0.00)\n",
      "Iter 1503 | Time 76.0989(64.8606) | Bit/dim 3.5082(3.5133) | Xent 0.0000(0.0000) | Loss 8.4320(8.9758) | Error 0.0000(0.0000) Steps 664(661.42) | Grad Norm 0.3239(0.2249) | Total Time 0.00(0.00)\n",
      "Iter 1504 | Time 65.9681(64.8938) | Bit/dim 3.5154(3.5133) | Xent 0.0000(0.0000) | Loss 8.2506(8.9541) | Error 0.0000(0.0000) Steps 652(661.14) | Grad Norm 0.2790(0.2265) | Total Time 0.00(0.00)\n",
      "Iter 1505 | Time 76.6711(65.2471) | Bit/dim 3.5166(3.5134) | Xent 0.0000(0.0000) | Loss 8.3430(8.9357) | Error 0.0000(0.0000) Steps 664(661.22) | Grad Norm 0.2456(0.2271) | Total Time 0.00(0.00)\n",
      "Iter 1506 | Time 72.7200(65.4713) | Bit/dim 3.5126(3.5134) | Xent 0.0000(0.0000) | Loss 8.2922(8.9164) | Error 0.0000(0.0000) Steps 652(660.95) | Grad Norm 0.2665(0.2283) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 23.3927, Epoch Time 474.2881(415.2971), Bit/dim 3.5168(best: 3.5108), Xent 0.0000, Loss 3.5168, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1507 | Time 71.2200(65.6437) | Bit/dim 3.5051(3.5132) | Xent 0.0000(0.0000) | Loss 11.6680(8.9990) | Error 0.0000(0.0000) Steps 670(661.22) | Grad Norm 0.3227(0.2311) | Total Time 0.00(0.00)\n",
      "Iter 1508 | Time 76.0995(65.9574) | Bit/dim 3.5047(3.5129) | Xent 0.0000(0.0000) | Loss 8.3528(8.9796) | Error 0.0000(0.0000) Steps 664(661.30) | Grad Norm 0.2476(0.2316) | Total Time 0.00(0.00)\n",
      "Iter 1509 | Time 68.3015(66.0277) | Bit/dim 3.5242(3.5132) | Xent 0.0000(0.0000) | Loss 8.2592(8.9580) | Error 0.0000(0.0000) Steps 646(660.84) | Grad Norm 0.1814(0.2301) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 73.8283(66.2618) | Bit/dim 3.5057(3.5130) | Xent 0.0000(0.0000) | Loss 8.5825(8.9467) | Error 0.0000(0.0000) Steps 688(661.66) | Grad Norm 0.1711(0.2283) | Total Time 0.00(0.00)\n",
      "Iter 1511 | Time 72.5675(66.4509) | Bit/dim 3.5183(3.5132) | Xent 0.0000(0.0000) | Loss 8.3953(8.9302) | Error 0.0000(0.0000) Steps 658(661.55) | Grad Norm 0.1692(0.2265) | Total Time 0.00(0.00)\n",
      "Iter 1512 | Time 76.3266(66.7472) | Bit/dim 3.5207(3.5134) | Xent 0.0000(0.0000) | Loss 8.4300(8.9152) | Error 0.0000(0.0000) Steps 664(661.62) | Grad Norm 0.1923(0.2255) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 23.9770, Epoch Time 478.2892(417.1869), Bit/dim 3.5108(best: 3.5108), Xent 0.0000, Loss 3.5108, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1513 | Time 73.7433(66.9571) | Bit/dim 3.5141(3.5134) | Xent 0.0000(0.0000) | Loss 11.9740(9.0069) | Error 0.0000(0.0000) Steps 694(662.59) | Grad Norm 0.2769(0.2270) | Total Time 0.00(0.00)\n",
      "Iter 1514 | Time 83.8916(67.4651) | Bit/dim 3.5068(3.5132) | Xent 0.0000(0.0000) | Loss 8.4886(8.9914) | Error 0.0000(0.0000) Steps 700(663.71) | Grad Norm 0.1605(0.2250) | Total Time 0.00(0.00)\n",
      "Iter 1515 | Time 69.2851(67.5197) | Bit/dim 3.5132(3.5132) | Xent 0.0000(0.0000) | Loss 8.3817(8.9731) | Error 0.0000(0.0000) Steps 646(663.18) | Grad Norm 0.2066(0.2245) | Total Time 0.00(0.00)\n",
      "Iter 1516 | Time 76.1771(67.7794) | Bit/dim 3.5190(3.5134) | Xent 0.0000(0.0000) | Loss 8.4043(8.9560) | Error 0.0000(0.0000) Steps 676(663.57) | Grad Norm 0.2169(0.2243) | Total Time 0.00(0.00)\n",
      "Iter 1517 | Time 71.8034(67.9002) | Bit/dim 3.5121(3.5134) | Xent 0.0000(0.0000) | Loss 8.2388(8.9345) | Error 0.0000(0.0000) Steps 646(663.04) | Grad Norm 0.1953(0.2234) | Total Time 0.00(0.00)\n",
      "Iter 1518 | Time 77.7822(68.1966) | Bit/dim 3.5086(3.5132) | Xent 0.0000(0.0000) | Loss 8.4362(8.9196) | Error 0.0000(0.0000) Steps 670(663.25) | Grad Norm 0.1798(0.2221) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 23.6418, Epoch Time 492.0774(419.4336), Bit/dim 3.5156(best: 3.5108), Xent 0.0000, Loss 3.5156, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1519 | Time 70.3799(68.2621) | Bit/dim 3.5083(3.5131) | Xent 0.0000(0.0000) | Loss 12.1634(9.0169) | Error 0.0000(0.0000) Steps 670(663.45) | Grad Norm 0.2126(0.2218) | Total Time 0.00(0.00)\n",
      "Iter 1520 | Time 71.3754(68.3555) | Bit/dim 3.5145(3.5131) | Xent 0.0000(0.0000) | Loss 8.2429(8.9937) | Error 0.0000(0.0000) Steps 652(663.11) | Grad Norm 0.2098(0.2214) | Total Time 0.00(0.00)\n",
      "Iter 1521 | Time 74.5074(68.5401) | Bit/dim 3.5230(3.5134) | Xent 0.0000(0.0000) | Loss 8.2960(8.9727) | Error 0.0000(0.0000) Steps 652(662.77) | Grad Norm 0.1764(0.2201) | Total Time 0.00(0.00)\n",
      "Iter 1522 | Time 72.5112(68.6592) | Bit/dim 3.5221(3.5137) | Xent 0.0000(0.0000) | Loss 8.2797(8.9519) | Error 0.0000(0.0000) Steps 676(663.17) | Grad Norm 0.2796(0.2219) | Total Time 0.00(0.00)\n",
      "Iter 1523 | Time 73.2895(68.7981) | Bit/dim 3.5066(3.5135) | Xent 0.0000(0.0000) | Loss 8.4941(8.9382) | Error 0.0000(0.0000) Steps 658(663.02) | Grad Norm 0.1590(0.2200) | Total Time 0.00(0.00)\n",
      "Iter 1524 | Time 76.1015(69.0172) | Bit/dim 3.5099(3.5134) | Xent 0.0000(0.0000) | Loss 8.3633(8.9209) | Error 0.0000(0.0000) Steps 670(663.23) | Grad Norm 0.2050(0.2195) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 23.6086, Epoch Time 477.7958(421.1845), Bit/dim 3.5158(best: 3.5108), Xent 0.0000, Loss 3.5158, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1525 | Time 73.0884(69.1394) | Bit/dim 3.5173(3.5135) | Xent 0.0000(0.0000) | Loss 11.8317(9.0083) | Error 0.0000(0.0000) Steps 652(662.89) | Grad Norm 0.4141(0.2254) | Total Time 0.00(0.00)\n",
      "Iter 1526 | Time 72.6221(69.2438) | Bit/dim 3.5035(3.5132) | Xent 0.0000(0.0000) | Loss 8.2904(8.9867) | Error 0.0000(0.0000) Steps 652(662.56) | Grad Norm 0.2056(0.2248) | Total Time 0.00(0.00)\n",
      "Iter 1527 | Time 83.2980(69.6655) | Bit/dim 3.5072(3.5130) | Xent 0.0000(0.0000) | Loss 8.3706(8.9683) | Error 0.0000(0.0000) Steps 688(663.33) | Grad Norm 0.2330(0.2250) | Total Time 0.00(0.00)\n",
      "Iter 1528 | Time 72.1246(69.7392) | Bit/dim 3.5121(3.5130) | Xent 0.0000(0.0000) | Loss 8.3473(8.9496) | Error 0.0000(0.0000) Steps 652(662.99) | Grad Norm 0.2658(0.2263) | Total Time 0.00(0.00)\n",
      "Iter 1529 | Time 73.4774(69.8514) | Bit/dim 3.5103(3.5129) | Xent 0.0000(0.0000) | Loss 8.4561(8.9348) | Error 0.0000(0.0000) Steps 652(662.66) | Grad Norm 0.1801(0.2249) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 77.3719(70.0770) | Bit/dim 3.5092(3.5128) | Xent 0.0000(0.0000) | Loss 8.2768(8.9151) | Error 0.0000(0.0000) Steps 646(662.16) | Grad Norm 0.3967(0.2300) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 24.6546, Epoch Time 492.6900(423.3296), Bit/dim 3.5114(best: 3.5108), Xent 0.0000, Loss 3.5114, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1531 | Time 75.9922(70.2545) | Bit/dim 3.5187(3.5130) | Xent 0.0000(0.0000) | Loss 12.0257(9.0084) | Error 0.0000(0.0000) Steps 670(662.39) | Grad Norm 0.2723(0.2313) | Total Time 0.00(0.00)\n",
      "Iter 1532 | Time 70.9483(70.2753) | Bit/dim 3.5221(3.5132) | Xent 0.0000(0.0000) | Loss 8.2055(8.9843) | Error 0.0000(0.0000) Steps 646(661.90) | Grad Norm 0.2123(0.2307) | Total Time 0.00(0.00)\n",
      "Iter 1533 | Time 71.7946(70.3208) | Bit/dim 3.5102(3.5131) | Xent 0.0000(0.0000) | Loss 8.3518(8.9653) | Error 0.0000(0.0000) Steps 658(661.78) | Grad Norm 0.1463(0.2282) | Total Time 0.00(0.00)\n",
      "Iter 1534 | Time 73.9468(70.4296) | Bit/dim 3.5204(3.5134) | Xent 0.0000(0.0000) | Loss 8.4080(8.9486) | Error 0.0000(0.0000) Steps 670(662.03) | Grad Norm 0.1742(0.2266) | Total Time 0.00(0.00)\n",
      "Iter 1535 | Time 73.8211(70.5314) | Bit/dim 3.5004(3.5130) | Xent 0.0000(0.0000) | Loss 8.2689(8.9282) | Error 0.0000(0.0000) Steps 658(661.91) | Grad Norm 0.2034(0.2259) | Total Time 0.00(0.00)\n",
      "Iter 1536 | Time 73.8550(70.6311) | Bit/dim 3.5023(3.5126) | Xent 0.0000(0.0000) | Loss 8.4651(8.9143) | Error 0.0000(0.0000) Steps 688(662.69) | Grad Norm 0.3406(0.2293) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 23.9348, Epoch Time 480.1294(425.0336), Bit/dim 3.5137(best: 3.5108), Xent 0.0000, Loss 3.5137, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1537 | Time 74.1901(70.7379) | Bit/dim 3.5117(3.5126) | Xent 0.0000(0.0000) | Loss 11.8740(9.0031) | Error 0.0000(0.0000) Steps 658(662.55) | Grad Norm 0.2543(0.2301) | Total Time 0.00(0.00)\n",
      "Iter 1538 | Time 68.3086(70.6650) | Bit/dim 3.5148(3.5127) | Xent 0.0000(0.0000) | Loss 8.2524(8.9806) | Error 0.0000(0.0000) Steps 658(662.41) | Grad Norm 0.2465(0.2306) | Total Time 0.00(0.00)\n",
      "Iter 1539 | Time 70.1919(70.6508) | Bit/dim 3.5229(3.5130) | Xent 0.0000(0.0000) | Loss 8.3343(8.9612) | Error 0.0000(0.0000) Steps 652(662.10) | Grad Norm 0.2004(0.2297) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 69.2118(70.6076) | Bit/dim 3.5101(3.5129) | Xent 0.0000(0.0000) | Loss 8.3147(8.9418) | Error 0.0000(0.0000) Steps 646(661.62) | Grad Norm 0.2886(0.2314) | Total Time 0.00(0.00)\n",
      "Iter 1541 | Time 71.6583(70.6391) | Bit/dim 3.5089(3.5128) | Xent 0.0000(0.0000) | Loss 8.3725(8.9247) | Error 0.0000(0.0000) Steps 652(661.33) | Grad Norm 0.1615(0.2293) | Total Time 0.00(0.00)\n",
      "Iter 1542 | Time 71.8911(70.6767) | Bit/dim 3.5070(3.5126) | Xent 0.0000(0.0000) | Loss 8.1755(8.9023) | Error 0.0000(0.0000) Steps 646(660.87) | Grad Norm 0.2766(0.2307) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 24.5170, Epoch Time 465.5659(426.2496), Bit/dim 3.5071(best: 3.5108), Xent 0.0000, Loss 3.5071, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1543 | Time 70.3693(70.6675) | Bit/dim 3.4981(3.5122) | Xent 0.0000(0.0000) | Loss 12.0581(8.9969) | Error 0.0000(0.0000) Steps 640(660.24) | Grad Norm 0.1838(0.2293) | Total Time 0.00(0.00)\n",
      "Iter 1544 | Time 74.9488(70.7959) | Bit/dim 3.5208(3.5124) | Xent 0.0000(0.0000) | Loss 8.2538(8.9746) | Error 0.0000(0.0000) Steps 664(660.36) | Grad Norm 0.2567(0.2302) | Total Time 0.00(0.00)\n",
      "Iter 1545 | Time 79.4612(71.0559) | Bit/dim 3.5157(3.5125) | Xent 0.0000(0.0000) | Loss 8.4717(8.9596) | Error 0.0000(0.0000) Steps 676(660.83) | Grad Norm 0.2435(0.2306) | Total Time 0.00(0.00)\n",
      "Iter 1546 | Time 67.9108(70.9615) | Bit/dim 3.5121(3.5125) | Xent 0.0000(0.0000) | Loss 8.2479(8.9382) | Error 0.0000(0.0000) Steps 628(659.84) | Grad Norm 0.2120(0.2300) | Total Time 0.00(0.00)\n",
      "Iter 1547 | Time 73.0856(71.0252) | Bit/dim 3.5088(3.5124) | Xent 0.0000(0.0000) | Loss 8.4942(8.9249) | Error 0.0000(0.0000) Steps 664(659.97) | Grad Norm 0.1765(0.2284) | Total Time 0.00(0.00)\n",
      "Iter 1548 | Time 74.2784(71.1228) | Bit/dim 3.5134(3.5124) | Xent 0.0000(0.0000) | Loss 8.4346(8.9102) | Error 0.0000(0.0000) Steps 694(660.99) | Grad Norm 0.2191(0.2281) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 24.1326, Epoch Time 480.4050(427.8743), Bit/dim 3.5097(best: 3.5071), Xent 0.0000, Loss 3.5097, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1549 | Time 68.5141(71.0446) | Bit/dim 3.5217(3.5127) | Xent 0.0000(0.0000) | Loss 11.5145(8.9883) | Error 0.0000(0.0000) Steps 652(660.72) | Grad Norm 0.3671(0.2323) | Total Time 0.00(0.00)\n",
      "Iter 1550 | Time 80.2884(71.3219) | Bit/dim 3.5050(3.5125) | Xent 0.0000(0.0000) | Loss 8.2409(8.9659) | Error 0.0000(0.0000) Steps 682(661.36) | Grad Norm 0.3244(0.2351) | Total Time 0.00(0.00)\n",
      "Iter 1551 | Time 76.6507(71.4818) | Bit/dim 3.5073(3.5123) | Xent 0.0000(0.0000) | Loss 8.2677(8.9449) | Error 0.0000(0.0000) Steps 646(660.90) | Grad Norm 0.2110(0.2343) | Total Time 0.00(0.00)\n",
      "Iter 1552 | Time 71.5848(71.4848) | Bit/dim 3.5110(3.5123) | Xent 0.0000(0.0000) | Loss 8.3819(8.9280) | Error 0.0000(0.0000) Steps 670(661.17) | Grad Norm 0.1820(0.2328) | Total Time 0.00(0.00)\n",
      "Iter 1553 | Time 75.9419(71.6186) | Bit/dim 3.5166(3.5124) | Xent 0.0000(0.0000) | Loss 8.3880(8.9118) | Error 0.0000(0.0000) Steps 652(660.89) | Grad Norm 0.1806(0.2312) | Total Time 0.00(0.00)\n",
      "Iter 1554 | Time 69.4316(71.5530) | Bit/dim 3.5086(3.5123) | Xent 0.0000(0.0000) | Loss 8.5194(8.9001) | Error 0.0000(0.0000) Steps 664(660.99) | Grad Norm 0.1796(0.2296) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 23.7421, Epoch Time 482.1425(429.5023), Bit/dim 3.5136(best: 3.5071), Xent 0.0000, Loss 3.5136, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1555 | Time 74.0088(71.6266) | Bit/dim 3.5066(3.5121) | Xent 0.0000(0.0000) | Loss 11.9999(8.9931) | Error 0.0000(0.0000) Steps 658(660.90) | Grad Norm 0.2492(0.2302) | Total Time 0.00(0.00)\n",
      "Iter 1556 | Time 68.0766(71.5201) | Bit/dim 3.5158(3.5122) | Xent 0.0000(0.0000) | Loss 8.3561(8.9740) | Error 0.0000(0.0000) Steps 646(660.45) | Grad Norm 0.2241(0.2301) | Total Time 0.00(0.00)\n",
      "Iter 1557 | Time 74.0092(71.5948) | Bit/dim 3.5128(3.5123) | Xent 0.0000(0.0000) | Loss 8.1684(8.9498) | Error 0.0000(0.0000) Steps 658(660.38) | Grad Norm 0.2282(0.2300) | Total Time 0.00(0.00)\n",
      "Iter 1558 | Time 72.5074(71.6222) | Bit/dim 3.5112(3.5122) | Xent 0.0000(0.0000) | Loss 8.0861(8.9239) | Error 0.0000(0.0000) Steps 652(660.13) | Grad Norm 0.2942(0.2319) | Total Time 0.00(0.00)\n",
      "Iter 1559 | Time 75.5695(71.7406) | Bit/dim 3.5095(3.5121) | Xent 0.0000(0.0000) | Loss 8.1494(8.9006) | Error 0.0000(0.0000) Steps 652(659.88) | Grad Norm 0.2927(0.2337) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 71.4426(71.7317) | Bit/dim 3.5060(3.5120) | Xent 0.0000(0.0000) | Loss 8.3662(8.8846) | Error 0.0000(0.0000) Steps 676(660.37) | Grad Norm 0.2034(0.2328) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 23.8507, Epoch Time 475.6919(430.8880), Bit/dim 3.5159(best: 3.5071), Xent 0.0000, Loss 3.5159, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1561 | Time 76.1095(71.8630) | Bit/dim 3.5022(3.5117) | Xent 0.0000(0.0000) | Loss 12.1691(8.9831) | Error 0.0000(0.0000) Steps 682(661.01) | Grad Norm 0.2458(0.2332) | Total Time 0.00(0.00)\n",
      "Iter 1562 | Time 71.5603(71.8539) | Bit/dim 3.5048(3.5115) | Xent 0.0000(0.0000) | Loss 8.2868(8.9623) | Error 0.0000(0.0000) Steps 640(660.38) | Grad Norm 0.1607(0.2311) | Total Time 0.00(0.00)\n",
      "Iter 1563 | Time 73.8375(71.9134) | Bit/dim 3.5038(3.5112) | Xent 0.0000(0.0000) | Loss 8.2798(8.9418) | Error 0.0000(0.0000) Steps 658(660.31) | Grad Norm 0.2290(0.2310) | Total Time 0.00(0.00)\n",
      "Iter 1564 | Time 75.2491(72.0135) | Bit/dim 3.5130(3.5113) | Xent 0.0000(0.0000) | Loss 8.1696(8.9186) | Error 0.0000(0.0000) Steps 670(660.60) | Grad Norm 0.6595(0.2438) | Total Time 0.00(0.00)\n",
      "Iter 1565 | Time 74.0495(72.0746) | Bit/dim 3.5165(3.5114) | Xent 0.0000(0.0000) | Loss 8.4220(8.9037) | Error 0.0000(0.0000) Steps 676(661.06) | Grad Norm 0.2342(0.2436) | Total Time 0.00(0.00)\n",
      "Iter 1566 | Time 75.0635(72.1642) | Bit/dim 3.5237(3.5118) | Xent 0.0000(0.0000) | Loss 8.2677(8.8846) | Error 0.0000(0.0000) Steps 664(661.15) | Grad Norm 0.2696(0.2443) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 23.7137, Epoch Time 485.6576(432.5311), Bit/dim 3.5078(best: 3.5071), Xent 0.0000, Loss 3.5078, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1567 | Time 75.1241(72.2530) | Bit/dim 3.5169(3.5120) | Xent 0.0000(0.0000) | Loss 11.9837(8.9776) | Error 0.0000(0.0000) Steps 682(661.78) | Grad Norm 0.2979(0.2459) | Total Time 0.00(0.00)\n",
      "Iter 1568 | Time 71.6161(72.2339) | Bit/dim 3.5115(3.5119) | Xent 0.0000(0.0000) | Loss 8.3830(8.9598) | Error 0.0000(0.0000) Steps 658(661.66) | Grad Norm 0.1901(0.2443) | Total Time 0.00(0.00)\n",
      "Iter 1569 | Time 76.3394(72.3571) | Bit/dim 3.5161(3.5121) | Xent 0.0000(0.0000) | Loss 8.3829(8.9425) | Error 0.0000(0.0000) Steps 664(661.73) | Grad Norm 0.3693(0.2480) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 68.4237(72.2391) | Bit/dim 3.5076(3.5119) | Xent 0.0000(0.0000) | Loss 8.4736(8.9284) | Error 0.0000(0.0000) Steps 676(662.16) | Grad Norm 0.1735(0.2458) | Total Time 0.00(0.00)\n",
      "Iter 1571 | Time 69.7374(72.1640) | Bit/dim 3.4982(3.5115) | Xent 0.0000(0.0000) | Loss 8.4159(8.9130) | Error 0.0000(0.0000) Steps 658(662.04) | Grad Norm 0.3098(0.2477) | Total Time 0.00(0.00)\n",
      "Iter 1572 | Time 73.2761(72.1974) | Bit/dim 3.5025(3.5113) | Xent 0.0000(0.0000) | Loss 8.4433(8.8989) | Error 0.0000(0.0000) Steps 676(662.46) | Grad Norm 0.2774(0.2486) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 24.2670, Epoch Time 474.9541(433.8038), Bit/dim 3.5125(best: 3.5071), Xent 0.0000, Loss 3.5125, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1573 | Time 72.7374(72.2136) | Bit/dim 3.5198(3.5115) | Xent 0.0000(0.0000) | Loss 12.0254(8.9927) | Error 0.0000(0.0000) Steps 664(662.50) | Grad Norm 0.2378(0.2483) | Total Time 0.00(0.00)\n",
      "Iter 1574 | Time 72.8361(72.2323) | Bit/dim 3.5030(3.5113) | Xent 0.0000(0.0000) | Loss 8.0330(8.9639) | Error 0.0000(0.0000) Steps 658(662.37) | Grad Norm 0.7232(0.2625) | Total Time 0.00(0.00)\n",
      "Iter 1575 | Time 70.7455(72.1877) | Bit/dim 3.5110(3.5112) | Xent 0.0000(0.0000) | Loss 8.2951(8.9439) | Error 0.0000(0.0000) Steps 652(662.06) | Grad Norm 0.2124(0.2610) | Total Time 0.00(0.00)\n",
      "Iter 1576 | Time 78.5438(72.3784) | Bit/dim 3.5156(3.5114) | Xent 0.0000(0.0000) | Loss 8.5365(8.9316) | Error 0.0000(0.0000) Steps 700(663.20) | Grad Norm 0.2680(0.2612) | Total Time 0.00(0.00)\n",
      "Iter 1577 | Time 76.5378(72.5031) | Bit/dim 3.4964(3.5109) | Xent 0.0000(0.0000) | Loss 8.3418(8.9140) | Error 0.0000(0.0000) Steps 682(663.76) | Grad Norm 0.2597(0.2612) | Total Time 0.00(0.00)\n",
      "Iter 1578 | Time 72.9745(72.5173) | Bit/dim 3.5150(3.5111) | Xent 0.0000(0.0000) | Loss 8.4195(8.8991) | Error 0.0000(0.0000) Steps 664(663.77) | Grad Norm 0.1917(0.2591) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 23.7093, Epoch Time 484.0200(435.3103), Bit/dim 3.5160(best: 3.5071), Xent 0.0000, Loss 3.5160, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1579 | Time 70.9076(72.4690) | Bit/dim 3.5164(3.5112) | Xent 0.0000(0.0000) | Loss 12.0153(8.9926) | Error 0.0000(0.0000) Steps 664(663.77) | Grad Norm 0.2842(0.2598) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 74.0350(72.5160) | Bit/dim 3.5064(3.5111) | Xent 0.0000(0.0000) | Loss 8.4507(8.9763) | Error 0.0000(0.0000) Steps 664(663.78) | Grad Norm 0.2454(0.2594) | Total Time 0.00(0.00)\n",
      "Iter 1581 | Time 70.9441(72.4688) | Bit/dim 3.5096(3.5110) | Xent 0.0000(0.0000) | Loss 8.4566(8.9608) | Error 0.0000(0.0000) Steps 664(663.79) | Grad Norm 0.2065(0.2578) | Total Time 0.00(0.00)\n",
      "Iter 1582 | Time 75.5137(72.5602) | Bit/dim 3.5155(3.5112) | Xent 0.0000(0.0000) | Loss 8.4715(8.9461) | Error 0.0000(0.0000) Steps 664(663.79) | Grad Norm 0.3942(0.2619) | Total Time 0.00(0.00)\n",
      "Iter 1583 | Time 72.4369(72.5565) | Bit/dim 3.5100(3.5111) | Xent 0.0000(0.0000) | Loss 8.3984(8.9296) | Error 0.0000(0.0000) Steps 658(663.62) | Grad Norm 0.2654(0.2620) | Total Time 0.00(0.00)\n",
      "Iter 1584 | Time 68.7706(72.4429) | Bit/dim 3.5044(3.5109) | Xent 0.0000(0.0000) | Loss 8.2269(8.9086) | Error 0.0000(0.0000) Steps 670(663.81) | Grad Norm 0.2513(0.2617) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 23.9359, Epoch Time 472.4998(436.4260), Bit/dim 3.5146(best: 3.5071), Xent 0.0000, Loss 3.5146, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1585 | Time 76.1967(72.5555) | Bit/dim 3.5072(3.5108) | Xent 0.0000(0.0000) | Loss 12.2246(9.0080) | Error 0.0000(0.0000) Steps 676(664.18) | Grad Norm 0.2702(0.2620) | Total Time 0.00(0.00)\n",
      "Iter 1586 | Time 73.7370(72.5910) | Bit/dim 3.5106(3.5108) | Xent 0.0000(0.0000) | Loss 8.6247(8.9965) | Error 0.0000(0.0000) Steps 658(663.99) | Grad Norm 0.2224(0.2608) | Total Time 0.00(0.00)\n",
      "Iter 1587 | Time 71.9022(72.5703) | Bit/dim 3.5170(3.5110) | Xent 0.0000(0.0000) | Loss 8.3099(8.9759) | Error 0.0000(0.0000) Steps 646(663.45) | Grad Norm 0.2189(0.2595) | Total Time 0.00(0.00)\n",
      "Iter 1588 | Time 77.2852(72.7117) | Bit/dim 3.5067(3.5109) | Xent 0.0000(0.0000) | Loss 8.3428(8.9570) | Error 0.0000(0.0000) Steps 670(663.65) | Grad Norm 0.5236(0.2674) | Total Time 0.00(0.00)\n",
      "Iter 1589 | Time 69.6909(72.6211) | Bit/dim 3.5138(3.5110) | Xent 0.0000(0.0000) | Loss 8.3674(8.9393) | Error 0.0000(0.0000) Steps 646(663.12) | Grad Norm 0.2422(0.2667) | Total Time 0.00(0.00)\n",
      "Iter 1590 | Time 69.0515(72.5140) | Bit/dim 3.5130(3.5110) | Xent 0.0000(0.0000) | Loss 8.4748(8.9253) | Error 0.0000(0.0000) Steps 676(663.51) | Grad Norm 0.3213(0.2683) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 23.6967, Epoch Time 477.2705(437.6513), Bit/dim 3.5161(best: 3.5071), Xent 0.0000, Loss 3.5161, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1591 | Time 68.1573(72.3833) | Bit/dim 3.5124(3.5111) | Xent 0.0000(0.0000) | Loss 11.6874(9.0082) | Error 0.0000(0.0000) Steps 646(662.98) | Grad Norm 0.4781(0.2746) | Total Time 0.00(0.00)\n",
      "Iter 1592 | Time 72.4266(72.3846) | Bit/dim 3.5155(3.5112) | Xent 0.0000(0.0000) | Loss 8.4176(8.9905) | Error 0.0000(0.0000) Steps 676(663.37) | Grad Norm 0.2997(0.2754) | Total Time 0.00(0.00)\n",
      "Iter 1593 | Time 77.8732(72.5493) | Bit/dim 3.5099(3.5111) | Xent 0.0000(0.0000) | Loss 8.4156(8.9732) | Error 0.0000(0.0000) Steps 664(663.39) | Grad Norm 0.3060(0.2763) | Total Time 0.00(0.00)\n",
      "Iter 1594 | Time 70.0730(72.4750) | Bit/dim 3.5010(3.5108) | Xent 0.0000(0.0000) | Loss 8.1613(8.9489) | Error 0.0000(0.0000) Steps 658(663.23) | Grad Norm 0.4069(0.2802) | Total Time 0.00(0.00)\n",
      "Iter 1595 | Time 74.2083(72.5270) | Bit/dim 3.5188(3.5111) | Xent 0.0000(0.0000) | Loss 8.3673(8.9314) | Error 0.0000(0.0000) Steps 670(663.43) | Grad Norm 0.3036(0.2809) | Total Time 0.00(0.00)\n",
      "Iter 1596 | Time 71.7940(72.5050) | Bit/dim 3.5037(3.5109) | Xent 0.0000(0.0000) | Loss 8.3157(8.9130) | Error 0.0000(0.0000) Steps 658(663.27) | Grad Norm 0.2440(0.2798) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 24.0377, Epoch Time 474.2771(438.7501), Bit/dim 3.5132(best: 3.5071), Xent 0.0000, Loss 3.5132, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1597 | Time 66.2173(72.3164) | Bit/dim 3.5135(3.5109) | Xent 0.0000(0.0000) | Loss 11.3995(8.9876) | Error 0.0000(0.0000) Steps 652(662.93) | Grad Norm 0.6795(0.2918) | Total Time 0.00(0.00)\n",
      "Iter 1598 | Time 70.4932(72.2617) | Bit/dim 3.5026(3.5107) | Xent 0.0000(0.0000) | Loss 8.3845(8.9695) | Error 0.0000(0.0000) Steps 658(662.78) | Grad Norm 0.2827(0.2915) | Total Time 0.00(0.00)\n",
      "Iter 1599 | Time 71.4547(72.2375) | Bit/dim 3.5119(3.5107) | Xent 0.0000(0.0000) | Loss 8.4256(8.9531) | Error 0.0000(0.0000) Steps 652(662.46) | Grad Norm 0.2497(0.2903) | Total Time 0.00(0.00)\n",
      "Iter 1600 | Time 80.5343(72.4864) | Bit/dim 3.5072(3.5106) | Xent 0.0000(0.0000) | Loss 8.2499(8.9320) | Error 0.0000(0.0000) Steps 682(663.04) | Grad Norm 0.3735(0.2928) | Total Time 0.00(0.00)\n",
      "Iter 1601 | Time 71.7006(72.4628) | Bit/dim 3.5022(3.5104) | Xent 0.0000(0.0000) | Loss 8.4326(8.9171) | Error 0.0000(0.0000) Steps 646(662.53) | Grad Norm 0.2438(0.2913) | Total Time 0.00(0.00)\n",
      "Iter 1602 | Time 76.0572(72.5706) | Bit/dim 3.5247(3.5108) | Xent 0.0000(0.0000) | Loss 8.3984(8.9015) | Error 0.0000(0.0000) Steps 676(662.94) | Grad Norm 0.3838(0.2941) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0267 | Time 23.9589, Epoch Time 476.3831(439.8791), Bit/dim 3.5142(best: 3.5071), Xent 0.0000, Loss 3.5142, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1603 | Time 76.7106(72.6948) | Bit/dim 3.5169(3.5110) | Xent 0.0000(0.0000) | Loss 11.7417(8.9867) | Error 0.0000(0.0000) Steps 676(663.33) | Grad Norm 0.3608(0.2961) | Total Time 0.00(0.00)\n",
      "Iter 1604 | Time 76.1377(72.7981) | Bit/dim 3.5208(3.5113) | Xent 0.0000(0.0000) | Loss 8.5155(8.9726) | Error 0.0000(0.0000) Steps 688(664.07) | Grad Norm 0.2815(0.2956) | Total Time 0.00(0.00)\n",
      "Iter 1605 | Time 75.4015(72.8762) | Bit/dim 3.5026(3.5110) | Xent 0.0000(0.0000) | Loss 8.3963(8.9553) | Error 0.0000(0.0000) Steps 652(663.71) | Grad Norm 0.2782(0.2951) | Total Time 0.00(0.00)\n",
      "Iter 1606 | Time 79.1181(73.0635) | Bit/dim 3.5086(3.5109) | Xent 0.0000(0.0000) | Loss 8.2848(8.9352) | Error 0.0000(0.0000) Steps 670(663.90) | Grad Norm 0.2660(0.2942) | Total Time 0.00(0.00)\n",
      "Iter 1607 | Time 69.8275(72.9664) | Bit/dim 3.4935(3.5104) | Xent 0.0000(0.0000) | Loss 8.0590(8.9089) | Error 0.0000(0.0000) Steps 664(663.90) | Grad Norm 0.4370(0.2985) | Total Time 0.00(0.00)\n",
      "Iter 1608 | Time 72.7361(72.9595) | Bit/dim 3.5198(3.5107) | Xent 0.0000(0.0000) | Loss 8.5526(8.8982) | Error 0.0000(0.0000) Steps 676(664.26) | Grad Norm 0.2244(0.2963) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0268 | Time 23.7747, Epoch Time 489.6114(441.3710), Bit/dim 3.5100(best: 3.5071), Xent 0.0000, Loss 3.5100, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1609 | Time 80.6025(73.1888) | Bit/dim 3.5120(3.5107) | Xent 0.0000(0.0000) | Loss 11.8250(8.9860) | Error 0.0000(0.0000) Steps 664(664.25) | Grad Norm 0.3154(0.2969) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 73.6719(73.2033) | Bit/dim 3.5040(3.5105) | Xent 0.0000(0.0000) | Loss 8.4673(8.9704) | Error 0.0000(0.0000) Steps 664(664.25) | Grad Norm 0.2482(0.2954) | Total Time 0.00(0.00)\n",
      "Iter 1611 | Time 69.7834(73.1007) | Bit/dim 3.5126(3.5106) | Xent 0.0000(0.0000) | Loss 8.3556(8.9520) | Error 0.0000(0.0000) Steps 640(663.52) | Grad Norm 0.1896(0.2922) | Total Time 0.00(0.00)\n",
      "Iter 1612 | Time 74.5553(73.1443) | Bit/dim 3.5081(3.5105) | Xent 0.0000(0.0000) | Loss 8.5514(8.9400) | Error 0.0000(0.0000) Steps 688(664.25) | Grad Norm 0.2739(0.2917) | Total Time 0.00(0.00)\n",
      "Iter 1613 | Time 71.7793(73.1034) | Bit/dim 3.5074(3.5104) | Xent 0.0000(0.0000) | Loss 8.1124(8.9151) | Error 0.0000(0.0000) Steps 664(664.25) | Grad Norm 0.4015(0.2950) | Total Time 0.00(0.00)\n",
      "Iter 1614 | Time 76.1840(73.1958) | Bit/dim 3.5182(3.5107) | Xent 0.0000(0.0000) | Loss 8.4236(8.9004) | Error 0.0000(0.0000) Steps 688(664.96) | Grad Norm 0.2978(0.2951) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0269 | Time 23.7521, Epoch Time 486.1985(442.7158), Bit/dim 3.5134(best: 3.5071), Xent 0.0000, Loss 3.5134, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1615 | Time 69.6655(73.0899) | Bit/dim 3.5020(3.5104) | Xent 0.0000(0.0000) | Loss 11.5040(8.9785) | Error 0.0000(0.0000) Steps 664(664.93) | Grad Norm 0.9553(0.3149) | Total Time 0.00(0.00)\n",
      "Iter 1616 | Time 75.9625(73.1761) | Bit/dim 3.4963(3.5100) | Xent 0.0000(0.0000) | Loss 8.5070(8.9644) | Error 0.0000(0.0000) Steps 670(665.08) | Grad Norm 0.1839(0.3109) | Total Time 0.00(0.00)\n",
      "Iter 1617 | Time 69.9343(73.0788) | Bit/dim 3.5139(3.5101) | Xent 0.0000(0.0000) | Loss 8.2619(8.9433) | Error 0.0000(0.0000) Steps 646(664.51) | Grad Norm 0.1808(0.3070) | Total Time 0.00(0.00)\n",
      "Iter 1618 | Time 78.2131(73.2328) | Bit/dim 3.5215(3.5104) | Xent 0.0000(0.0000) | Loss 8.4389(8.9282) | Error 0.0000(0.0000) Steps 646(663.95) | Grad Norm 0.2092(0.3041) | Total Time 0.00(0.00)\n",
      "Iter 1619 | Time 76.3044(73.3250) | Bit/dim 3.5133(3.5105) | Xent 0.0000(0.0000) | Loss 8.3755(8.9116) | Error 0.0000(0.0000) Steps 670(664.14) | Grad Norm 0.1879(0.3006) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 70.3043(73.2344) | Bit/dim 3.5036(3.5103) | Xent 0.0000(0.0000) | Loss 8.4703(8.8983) | Error 0.0000(0.0000) Steps 646(663.59) | Grad Norm 0.2043(0.2977) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0270 | Time 23.8802, Epoch Time 480.2622(443.8422), Bit/dim 3.5139(best: 3.5071), Xent 0.0000, Loss 3.5139, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1621 | Time 74.9598(73.2861) | Bit/dim 3.5102(3.5103) | Xent 0.0000(0.0000) | Loss 12.0552(8.9930) | Error 0.0000(0.0000) Steps 676(663.96) | Grad Norm 0.2221(0.2955) | Total Time 0.00(0.00)\n",
      "Iter 1622 | Time 78.4917(73.4423) | Bit/dim 3.5074(3.5102) | Xent 0.0000(0.0000) | Loss 8.4981(8.9782) | Error 0.0000(0.0000) Steps 682(664.51) | Grad Norm 0.1693(0.2917) | Total Time 0.00(0.00)\n",
      "Iter 1623 | Time 73.7224(73.4507) | Bit/dim 3.5128(3.5103) | Xent 0.0000(0.0000) | Loss 8.3566(8.9595) | Error 0.0000(0.0000) Steps 664(664.49) | Grad Norm 0.7948(0.3068) | Total Time 0.00(0.00)\n",
      "Iter 1624 | Time 75.8354(73.5222) | Bit/dim 3.5015(3.5100) | Xent 0.0000(0.0000) | Loss 8.4631(8.9447) | Error 0.0000(0.0000) Steps 688(665.20) | Grad Norm 0.2329(0.3045) | Total Time 0.00(0.00)\n",
      "Iter 1625 | Time 74.8508(73.5621) | Bit/dim 3.4920(3.5095) | Xent 0.0000(0.0000) | Loss 8.2841(8.9248) | Error 0.0000(0.0000) Steps 652(664.80) | Grad Norm 0.2474(0.3028) | Total Time 0.00(0.00)\n",
      "Iter 1626 | Time 70.1528(73.4598) | Bit/dim 3.5288(3.5101) | Xent 0.0000(0.0000) | Loss 8.1616(8.9019) | Error 0.0000(0.0000) Steps 640(664.06) | Grad Norm 0.2365(0.3008) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0271 | Time 24.3208, Epoch Time 488.4458(445.1803), Bit/dim 3.5097(best: 3.5071), Xent 0.0000, Loss 3.5097, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1627 | Time 76.2280(73.5429) | Bit/dim 3.5075(3.5100) | Xent 0.0000(0.0000) | Loss 11.9124(8.9923) | Error 0.0000(0.0000) Steps 658(663.87) | Grad Norm 0.3236(0.3015) | Total Time 0.00(0.00)\n",
      "Iter 1628 | Time 76.0587(73.6183) | Bit/dim 3.5145(3.5101) | Xent 0.0000(0.0000) | Loss 8.5587(8.9793) | Error 0.0000(0.0000) Steps 664(663.88) | Grad Norm 0.1921(0.2982) | Total Time 0.00(0.00)\n",
      "Iter 1629 | Time 74.2542(73.6374) | Bit/dim 3.4955(3.5097) | Xent 0.0000(0.0000) | Loss 8.2187(8.9564) | Error 0.0000(0.0000) Steps 646(663.34) | Grad Norm 0.2552(0.2970) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 72.1738(73.5935) | Bit/dim 3.5077(3.5096) | Xent 0.0000(0.0000) | Loss 8.2012(8.9338) | Error 0.0000(0.0000) Steps 652(663.00) | Grad Norm 0.2436(0.2954) | Total Time 0.00(0.00)\n",
      "Iter 1631 | Time 71.1012(73.5187) | Bit/dim 3.5055(3.5095) | Xent 0.0000(0.0000) | Loss 8.4039(8.9179) | Error 0.0000(0.0000) Steps 664(663.03) | Grad Norm 0.1869(0.2921) | Total Time 0.00(0.00)\n",
      "Iter 1632 | Time 76.0435(73.5945) | Bit/dim 3.5210(3.5099) | Xent 0.0000(0.0000) | Loss 8.3943(8.9022) | Error 0.0000(0.0000) Steps 664(663.06) | Grad Norm 0.2104(0.2897) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0272 | Time 23.9408, Epoch Time 485.4929(446.3897), Bit/dim 3.5136(best: 3.5071), Xent 0.0000, Loss 3.5136, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1633 | Time 72.5248(73.5624) | Bit/dim 3.5068(3.5098) | Xent 0.0000(0.0000) | Loss 11.7516(8.9877) | Error 0.0000(0.0000) Steps 664(663.09) | Grad Norm 0.4072(0.2932) | Total Time 0.00(0.00)\n",
      "Iter 1634 | Time 73.1234(73.5492) | Bit/dim 3.5093(3.5098) | Xent 0.0000(0.0000) | Loss 8.5110(8.9734) | Error 0.0000(0.0000) Steps 682(663.66) | Grad Norm 0.2259(0.2912) | Total Time 0.00(0.00)\n",
      "Iter 1635 | Time 70.0022(73.4428) | Bit/dim 3.5091(3.5097) | Xent 0.0000(0.0000) | Loss 8.2505(8.9517) | Error 0.0000(0.0000) Steps 664(663.67) | Grad Norm 0.2640(0.2903) | Total Time 0.00(0.00)\n",
      "Iter 1636 | Time 74.1426(73.4638) | Bit/dim 3.5173(3.5100) | Xent 0.0000(0.0000) | Loss 8.2346(8.9302) | Error 0.0000(0.0000) Steps 658(663.50) | Grad Norm 0.2451(0.2890) | Total Time 0.00(0.00)\n",
      "Iter 1637 | Time 70.7643(73.3828) | Bit/dim 3.5036(3.5098) | Xent 0.0000(0.0000) | Loss 8.5271(8.9181) | Error 0.0000(0.0000) Steps 658(663.33) | Grad Norm 0.2217(0.2870) | Total Time 0.00(0.00)\n",
      "Iter 1638 | Time 77.3986(73.5033) | Bit/dim 3.5123(3.5098) | Xent 0.0000(0.0000) | Loss 8.4037(8.9026) | Error 0.0000(0.0000) Steps 688(664.07) | Grad Norm 0.3012(0.2874) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0273 | Time 23.9477, Epoch Time 477.9102(447.3353), Bit/dim 3.5108(best: 3.5071), Xent 0.0000, Loss 3.5108, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1639 | Time 69.2493(73.3757) | Bit/dim 3.5245(3.5103) | Xent 0.0000(0.0000) | Loss 12.0947(8.9984) | Error 0.0000(0.0000) Steps 664(664.07) | Grad Norm 0.3492(0.2893) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 74.3179(73.4039) | Bit/dim 3.4958(3.5098) | Xent 0.0000(0.0000) | Loss 8.4142(8.9809) | Error 0.0000(0.0000) Steps 694(664.97) | Grad Norm 0.2271(0.2874) | Total Time 0.00(0.00)\n",
      "Iter 1641 | Time 74.8507(73.4473) | Bit/dim 3.5136(3.5100) | Xent 0.0000(0.0000) | Loss 8.3280(8.9613) | Error 0.0000(0.0000) Steps 670(665.12) | Grad Norm 0.2078(0.2850) | Total Time 0.00(0.00)\n",
      "Iter 1642 | Time 66.0852(73.2265) | Bit/dim 3.5102(3.5100) | Xent 0.0000(0.0000) | Loss 8.0899(8.9351) | Error 0.0000(0.0000) Steps 646(664.54) | Grad Norm 0.2913(0.2852) | Total Time 0.00(0.00)\n",
      "Iter 1643 | Time 71.8323(73.1846) | Bit/dim 3.5078(3.5099) | Xent 0.0000(0.0000) | Loss 8.3069(8.9163) | Error 0.0000(0.0000) Steps 670(664.71) | Grad Norm 0.2258(0.2834) | Total Time 0.00(0.00)\n",
      "Iter 1644 | Time 73.2011(73.1851) | Bit/dim 3.5074(3.5098) | Xent 0.0000(0.0000) | Loss 8.2971(8.8977) | Error 0.0000(0.0000) Steps 640(663.97) | Grad Norm 0.2089(0.2812) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0274 | Time 24.0954, Epoch Time 469.8628(448.0112), Bit/dim 3.5074(best: 3.5071), Xent 0.0000, Loss 3.5074, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1645 | Time 70.3152(73.0990) | Bit/dim 3.5064(3.5097) | Xent 0.0000(0.0000) | Loss 11.9898(8.9905) | Error 0.0000(0.0000) Steps 652(663.61) | Grad Norm 0.3359(0.2828) | Total Time 0.00(0.00)\n",
      "Iter 1646 | Time 71.4925(73.0508) | Bit/dim 3.4967(3.5093) | Xent 0.0000(0.0000) | Loss 8.3077(8.9700) | Error 0.0000(0.0000) Steps 670(663.80) | Grad Norm 0.2370(0.2814) | Total Time 0.00(0.00)\n",
      "Iter 1647 | Time 64.2955(72.7882) | Bit/dim 3.5049(3.5092) | Xent 0.0000(0.0000) | Loss 7.8722(8.9371) | Error 0.0000(0.0000) Steps 622(662.55) | Grad Norm 0.4690(0.2871) | Total Time 0.00(0.00)\n",
      "Iter 1648 | Time 75.3484(72.8650) | Bit/dim 3.5091(3.5092) | Xent 0.0000(0.0000) | Loss 8.3997(8.9209) | Error 0.0000(0.0000) Steps 676(662.95) | Grad Norm 0.2592(0.2862) | Total Time 0.00(0.00)\n",
      "Iter 1649 | Time 75.4521(72.9426) | Bit/dim 3.5161(3.5094) | Xent 0.0000(0.0000) | Loss 8.4090(8.9056) | Error 0.0000(0.0000) Steps 688(663.70) | Grad Norm 0.2575(0.2854) | Total Time 0.00(0.00)\n",
      "Iter 1650 | Time 78.0271(73.0951) | Bit/dim 3.5137(3.5095) | Xent 0.0000(0.0000) | Loss 8.3257(8.8882) | Error 0.0000(0.0000) Steps 676(664.07) | Grad Norm 0.2557(0.2845) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0275 | Time 23.8849, Epoch Time 475.2429(448.8281), Bit/dim 3.5098(best: 3.5071), Xent 0.0000, Loss 3.5098, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1651 | Time 74.6208(73.1409) | Bit/dim 3.5138(3.5097) | Xent 0.0000(0.0000) | Loss 12.0130(8.9819) | Error 0.0000(0.0000) Steps 664(664.07) | Grad Norm 0.2973(0.2849) | Total Time 0.00(0.00)\n",
      "Iter 1652 | Time 77.1306(73.2606) | Bit/dim 3.5129(3.5098) | Xent 0.0000(0.0000) | Loss 8.4451(8.9658) | Error 0.0000(0.0000) Steps 676(664.43) | Grad Norm 0.2232(0.2830) | Total Time 0.00(0.00)\n",
      "Iter 1653 | Time 72.8765(73.2491) | Bit/dim 3.5232(3.5102) | Xent 0.0000(0.0000) | Loss 8.3773(8.9482) | Error 0.0000(0.0000) Steps 664(664.41) | Grad Norm 0.2972(0.2834) | Total Time 0.00(0.00)\n",
      "Iter 1654 | Time 77.1094(73.3649) | Bit/dim 3.5041(3.5100) | Xent 0.0000(0.0000) | Loss 8.2428(8.9270) | Error 0.0000(0.0000) Steps 670(664.58) | Grad Norm 0.2512(0.2825) | Total Time 0.00(0.00)\n",
      "Iter 1655 | Time 75.1147(73.4174) | Bit/dim 3.5034(3.5098) | Xent 0.0000(0.0000) | Loss 8.5086(8.9145) | Error 0.0000(0.0000) Steps 670(664.74) | Grad Norm 0.1871(0.2796) | Total Time 0.00(0.00)\n",
      "Iter 1656 | Time 76.8141(73.5193) | Bit/dim 3.4976(3.5094) | Xent 0.0000(0.0000) | Loss 8.4614(8.9009) | Error 0.0000(0.0000) Steps 682(665.26) | Grad Norm 0.2010(0.2773) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0276 | Time 23.9218, Epoch Time 493.6038(450.1714), Bit/dim 3.5098(best: 3.5071), Xent 0.0000, Loss 3.5098, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1657 | Time 72.7178(73.4952) | Bit/dim 3.5088(3.5094) | Xent 0.0000(0.0000) | Loss 11.7198(8.9854) | Error 0.0000(0.0000) Steps 658(665.04) | Grad Norm 0.3671(0.2800) | Total Time 0.00(0.00)\n",
      "Iter 1658 | Time 73.4944(73.4952) | Bit/dim 3.5055(3.5093) | Xent 0.0000(0.0000) | Loss 8.4323(8.9688) | Error 0.0000(0.0000) Steps 676(665.37) | Grad Norm 0.1983(0.2775) | Total Time 0.00(0.00)\n",
      "Iter 1659 | Time 77.7436(73.6227) | Bit/dim 3.5150(3.5095) | Xent 0.0000(0.0000) | Loss 8.3444(8.9501) | Error 0.0000(0.0000) Steps 682(665.87) | Grad Norm 0.2545(0.2768) | Total Time 0.00(0.00)\n",
      "Iter 1660 | Time 73.8655(73.6300) | Bit/dim 3.5122(3.5095) | Xent 0.0000(0.0000) | Loss 8.2755(8.9299) | Error 0.0000(0.0000) Steps 658(665.63) | Grad Norm 0.2894(0.2772) | Total Time 0.00(0.00)\n",
      "Iter 1661 | Time 73.5595(73.6278) | Bit/dim 3.5073(3.5095) | Xent 0.0000(0.0000) | Loss 8.4707(8.9161) | Error 0.0000(0.0000) Steps 658(665.41) | Grad Norm 0.1783(0.2742) | Total Time 0.00(0.00)\n",
      "Iter 1662 | Time 74.7662(73.6620) | Bit/dim 3.5052(3.5093) | Xent 0.0000(0.0000) | Loss 8.4577(8.9023) | Error 0.0000(0.0000) Steps 682(665.90) | Grad Norm 0.1882(0.2716) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0277 | Time 24.0368, Epoch Time 486.0236(451.2470), Bit/dim 3.5095(best: 3.5071), Xent 0.0000, Loss 3.5095, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1663 | Time 78.2239(73.7988) | Bit/dim 3.5094(3.5093) | Xent 0.0000(0.0000) | Loss 11.8012(8.9893) | Error 0.0000(0.0000) Steps 682(666.39) | Grad Norm 0.3395(0.2737) | Total Time 0.00(0.00)\n",
      "Iter 1664 | Time 73.0480(73.7763) | Bit/dim 3.5091(3.5093) | Xent 0.0000(0.0000) | Loss 8.5880(8.9773) | Error 0.0000(0.0000) Steps 670(666.49) | Grad Norm 0.1962(0.2714) | Total Time 0.00(0.00)\n",
      "Iter 1665 | Time 69.8118(73.6574) | Bit/dim 3.4984(3.5090) | Xent 0.0000(0.0000) | Loss 8.2267(8.9548) | Error 0.0000(0.0000) Steps 652(666.06) | Grad Norm 0.1756(0.2685) | Total Time 0.00(0.00)\n",
      "Iter 1666 | Time 76.8571(73.7534) | Bit/dim 3.5122(3.5091) | Xent 0.0000(0.0000) | Loss 8.5254(8.9419) | Error 0.0000(0.0000) Steps 688(666.72) | Grad Norm 0.2078(0.2667) | Total Time 0.00(0.00)\n",
      "Iter 1667 | Time 71.2959(73.6797) | Bit/dim 3.5167(3.5093) | Xent 0.0000(0.0000) | Loss 8.2417(8.9209) | Error 0.0000(0.0000) Steps 652(666.28) | Grad Norm 0.2547(0.2663) | Total Time 0.00(0.00)\n",
      "Iter 1668 | Time 75.0227(73.7199) | Bit/dim 3.5061(3.5092) | Xent 0.0000(0.0000) | Loss 8.5328(8.9092) | Error 0.0000(0.0000) Steps 688(666.93) | Grad Norm 0.1824(0.2638) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0278 | Time 24.2282, Epoch Time 484.3087(452.2388), Bit/dim 3.5104(best: 3.5071), Xent 0.0000, Loss 3.5104, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1669 | Time 78.7035(73.8694) | Bit/dim 3.5087(3.5092) | Xent 0.0000(0.0000) | Loss 11.8726(8.9981) | Error 0.0000(0.0000) Steps 652(666.48) | Grad Norm 0.3322(0.2658) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 79.2108(74.0297) | Bit/dim 3.5188(3.5095) | Xent 0.0000(0.0000) | Loss 8.4788(8.9825) | Error 0.0000(0.0000) Steps 694(667.31) | Grad Norm 0.2185(0.2644) | Total Time 0.00(0.00)\n",
      "Iter 1671 | Time 73.9184(74.0264) | Bit/dim 3.5086(3.5095) | Xent 0.0000(0.0000) | Loss 8.1938(8.9589) | Error 0.0000(0.0000) Steps 652(666.85) | Grad Norm 0.2773(0.2648) | Total Time 0.00(0.00)\n",
      "Iter 1672 | Time 70.7431(73.9279) | Bit/dim 3.4953(3.5091) | Xent 0.0000(0.0000) | Loss 8.3427(8.9404) | Error 0.0000(0.0000) Steps 658(666.58) | Grad Norm 0.2120(0.2632) | Total Time 0.00(0.00)\n",
      "Iter 1673 | Time 69.9117(73.8074) | Bit/dim 3.4932(3.5086) | Xent 0.0000(0.0000) | Loss 8.3941(8.9240) | Error 0.0000(0.0000) Steps 658(666.32) | Grad Norm 0.2157(0.2618) | Total Time 0.00(0.00)\n",
      "Iter 1674 | Time 70.9284(73.7210) | Bit/dim 3.5161(3.5088) | Xent 0.0000(0.0000) | Loss 8.4117(8.9086) | Error 0.0000(0.0000) Steps 658(666.07) | Grad Norm 0.1922(0.2597) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0279 | Time 23.7431, Epoch Time 482.9150(453.1591), Bit/dim 3.5060(best: 3.5071), Xent 0.0000, Loss 3.5060, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1675 | Time 76.1065(73.7926) | Bit/dim 3.5107(3.5089) | Xent 0.0000(0.0000) | Loss 11.7067(8.9926) | Error 0.0000(0.0000) Steps 670(666.19) | Grad Norm 0.3520(0.2625) | Total Time 0.00(0.00)\n",
      "Iter 1676 | Time 75.4462(73.8422) | Bit/dim 3.5123(3.5090) | Xent 0.0000(0.0000) | Loss 8.4626(8.9767) | Error 0.0000(0.0000) Steps 676(666.49) | Grad Norm 0.1891(0.2603) | Total Time 0.00(0.00)\n",
      "Iter 1677 | Time 67.6264(73.6557) | Bit/dim 3.5030(3.5088) | Xent 0.0000(0.0000) | Loss 8.3320(8.9573) | Error 0.0000(0.0000) Steps 652(666.05) | Grad Norm 0.3030(0.2616) | Total Time 0.00(0.00)\n",
      "Iter 1678 | Time 73.0806(73.6384) | Bit/dim 3.5083(3.5088) | Xent 0.0000(0.0000) | Loss 8.4004(8.9406) | Error 0.0000(0.0000) Steps 658(665.81) | Grad Norm 0.2150(0.2602) | Total Time 0.00(0.00)\n",
      "Iter 1679 | Time 75.9922(73.7091) | Bit/dim 3.5108(3.5088) | Xent 0.0000(0.0000) | Loss 8.0630(8.9143) | Error 0.0000(0.0000) Steps 664(665.76) | Grad Norm 0.2097(0.2586) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 77.2498(73.8153) | Bit/dim 3.5096(3.5089) | Xent 0.0000(0.0000) | Loss 8.3913(8.8986) | Error 0.0000(0.0000) Steps 688(666.42) | Grad Norm 0.2588(0.2586) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0280 | Time 23.7114, Epoch Time 485.3273(454.1241), Bit/dim 3.5122(best: 3.5060), Xent 0.0000, Loss 3.5122, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1681 | Time 76.0948(73.8837) | Bit/dim 3.5150(3.5090) | Xent 0.0000(0.0000) | Loss 12.1874(8.9973) | Error 0.0000(0.0000) Steps 688(667.07) | Grad Norm 0.2904(0.2596) | Total Time 0.00(0.00)\n",
      "Iter 1682 | Time 69.8204(73.7618) | Bit/dim 3.5048(3.5089) | Xent 0.0000(0.0000) | Loss 8.4677(8.9814) | Error 0.0000(0.0000) Steps 664(666.98) | Grad Norm 0.2604(0.2596) | Total Time 0.00(0.00)\n",
      "Iter 1683 | Time 72.4348(73.7220) | Bit/dim 3.5088(3.5089) | Xent 0.0000(0.0000) | Loss 8.3085(8.9612) | Error 0.0000(0.0000) Steps 652(666.53) | Grad Norm 0.2164(0.2583) | Total Time 0.00(0.00)\n",
      "Iter 1684 | Time 76.4108(73.8026) | Bit/dim 3.5056(3.5088) | Xent 0.0000(0.0000) | Loss 8.5082(8.9476) | Error 0.0000(0.0000) Steps 676(666.81) | Grad Norm 0.2044(0.2567) | Total Time 0.00(0.00)\n",
      "Iter 1685 | Time 70.1595(73.6933) | Bit/dim 3.5105(3.5089) | Xent 0.0000(0.0000) | Loss 8.4233(8.9319) | Error 0.0000(0.0000) Steps 664(666.73) | Grad Norm 0.2345(0.2560) | Total Time 0.00(0.00)\n",
      "Iter 1686 | Time 71.0109(73.6129) | Bit/dim 3.4992(3.5086) | Xent 0.0000(0.0000) | Loss 8.4535(8.9175) | Error 0.0000(0.0000) Steps 670(666.83) | Grad Norm 0.1715(0.2535) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0281 | Time 24.0990, Epoch Time 475.9744(454.7796), Bit/dim 3.5064(best: 3.5060), Xent 0.0000, Loss 3.5064, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1687 | Time 72.6066(73.5827) | Bit/dim 3.5034(3.5084) | Xent 0.0000(0.0000) | Loss 12.2266(9.0168) | Error 0.0000(0.0000) Steps 682(667.28) | Grad Norm 0.2277(0.2527) | Total Time 0.00(0.00)\n",
      "Iter 1688 | Time 64.2595(73.3030) | Bit/dim 3.5005(3.5082) | Xent 0.0000(0.0000) | Loss 8.2422(8.9936) | Error 0.0000(0.0000) Steps 634(666.28) | Grad Norm 0.3592(0.2559) | Total Time 0.00(0.00)\n",
      "Iter 1689 | Time 68.8737(73.1701) | Bit/dim 3.5071(3.5081) | Xent 0.0000(0.0000) | Loss 8.4503(8.9773) | Error 0.0000(0.0000) Steps 658(666.03) | Grad Norm 0.2148(0.2547) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 70.7992(73.0990) | Bit/dim 3.5041(3.5080) | Xent 0.0000(0.0000) | Loss 8.5244(8.9637) | Error 0.0000(0.0000) Steps 676(666.33) | Grad Norm 0.2187(0.2536) | Total Time 0.00(0.00)\n",
      "Iter 1691 | Time 74.3581(73.1367) | Bit/dim 3.5113(3.5081) | Xent 0.0000(0.0000) | Loss 8.4098(8.9471) | Error 0.0000(0.0000) Steps 664(666.26) | Grad Norm 0.2120(0.2524) | Total Time 0.00(0.00)\n",
      "Iter 1692 | Time 75.7313(73.2146) | Bit/dim 3.5114(3.5082) | Xent 0.0000(0.0000) | Loss 8.4897(8.9333) | Error 0.0000(0.0000) Steps 676(666.56) | Grad Norm 0.1872(0.2504) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0282 | Time 23.3609, Epoch Time 465.5704(455.1034), Bit/dim 3.5094(best: 3.5060), Xent 0.0000, Loss 3.5094, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1693 | Time 76.1282(73.3020) | Bit/dim 3.5057(3.5081) | Xent 0.0000(0.0000) | Loss 11.9135(9.0228) | Error 0.0000(0.0000) Steps 676(666.84) | Grad Norm 0.2830(0.2514) | Total Time 0.00(0.00)\n",
      "Iter 1694 | Time 71.2568(73.2406) | Bit/dim 3.5160(3.5084) | Xent 0.0000(0.0000) | Loss 8.2264(8.9989) | Error 0.0000(0.0000) Steps 658(666.57) | Grad Norm 0.3259(0.2536) | Total Time 0.00(0.00)\n",
      "Iter 1695 | Time 73.8575(73.2591) | Bit/dim 3.5170(3.5086) | Xent 0.0000(0.0000) | Loss 8.4455(8.9823) | Error 0.0000(0.0000) Steps 634(665.60) | Grad Norm 0.2081(0.2523) | Total Time 0.00(0.00)\n",
      "Iter 1696 | Time 72.1177(73.2249) | Bit/dim 3.5033(3.5085) | Xent 0.0000(0.0000) | Loss 8.2580(8.9605) | Error 0.0000(0.0000) Steps 682(666.09) | Grad Norm 0.2675(0.2527) | Total Time 0.00(0.00)\n",
      "Iter 1697 | Time 76.4455(73.3215) | Bit/dim 3.5070(3.5084) | Xent 0.0000(0.0000) | Loss 8.3575(8.9424) | Error 0.0000(0.0000) Steps 664(666.03) | Grad Norm 0.2205(0.2517) | Total Time 0.00(0.00)\n",
      "Iter 1698 | Time 70.4279(73.2347) | Bit/dim 3.5106(3.5085) | Xent 0.0000(0.0000) | Loss 8.4762(8.9285) | Error 0.0000(0.0000) Steps 664(665.97) | Grad Norm 0.1879(0.2498) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0283 | Time 23.6300, Epoch Time 479.6960(455.8411), Bit/dim 3.5075(best: 3.5060), Xent 0.0000, Loss 3.5075, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1699 | Time 74.1243(73.2614) | Bit/dim 3.5007(3.5083) | Xent 0.0000(0.0000) | Loss 12.1099(9.0239) | Error 0.0000(0.0000) Steps 646(665.37) | Grad Norm 0.2664(0.2503) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 73.0403(73.2548) | Bit/dim 3.5046(3.5082) | Xent 0.0000(0.0000) | Loss 8.4418(9.0064) | Error 0.0000(0.0000) Steps 676(665.69) | Grad Norm 0.2429(0.2501) | Total Time 0.00(0.00)\n",
      "Iter 1701 | Time 77.1388(73.3713) | Bit/dim 3.5117(3.5083) | Xent 0.0000(0.0000) | Loss 8.4256(8.9890) | Error 0.0000(0.0000) Steps 682(666.18) | Grad Norm 0.2490(0.2501) | Total Time 0.00(0.00)\n",
      "Iter 1702 | Time 75.6286(73.4390) | Bit/dim 3.4997(3.5080) | Xent 0.0000(0.0000) | Loss 8.3881(8.9710) | Error 0.0000(0.0000) Steps 664(666.11) | Grad Norm 0.2304(0.2495) | Total Time 0.00(0.00)\n",
      "Iter 1703 | Time 76.4982(73.5308) | Bit/dim 3.5105(3.5081) | Xent 0.0000(0.0000) | Loss 8.3388(8.9520) | Error 0.0000(0.0000) Steps 688(666.77) | Grad Norm 0.2522(0.2496) | Total Time 0.00(0.00)\n",
      "Iter 1704 | Time 73.1871(73.5205) | Bit/dim 3.5076(3.5081) | Xent 0.0000(0.0000) | Loss 8.5794(8.9408) | Error 0.0000(0.0000) Steps 676(667.04) | Grad Norm 0.2016(0.2481) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0284 | Time 23.9639, Epoch Time 489.3303(456.8458), Bit/dim 3.5111(best: 3.5060), Xent 0.0000, Loss 3.5111, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1705 | Time 75.8534(73.5905) | Bit/dim 3.5042(3.5079) | Xent 0.0000(0.0000) | Loss 12.1952(9.0385) | Error 0.0000(0.0000) Steps 670(667.13) | Grad Norm 0.2601(0.2485) | Total Time 0.00(0.00)\n",
      "Iter 1706 | Time 69.4282(73.4656) | Bit/dim 3.5144(3.5081) | Xent 0.0000(0.0000) | Loss 8.4364(9.0204) | Error 0.0000(0.0000) Steps 658(666.86) | Grad Norm 0.2195(0.2476) | Total Time 0.00(0.00)\n",
      "Iter 1707 | Time 71.4902(73.4063) | Bit/dim 3.5038(3.5080) | Xent 0.0000(0.0000) | Loss 8.2587(8.9976) | Error 0.0000(0.0000) Steps 676(667.13) | Grad Norm 0.2936(0.2490) | Total Time 0.00(0.00)\n",
      "Iter 1708 | Time 72.8144(73.3886) | Bit/dim 3.5092(3.5080) | Xent 0.0000(0.0000) | Loss 8.5347(8.9837) | Error 0.0000(0.0000) Steps 682(667.58) | Grad Norm 0.2236(0.2482) | Total Time 0.00(0.00)\n",
      "Iter 1709 | Time 74.8163(73.4314) | Bit/dim 3.5104(3.5081) | Xent 0.0000(0.0000) | Loss 8.3453(8.9645) | Error 0.0000(0.0000) Steps 670(667.65) | Grad Norm 0.2005(0.2468) | Total Time 0.00(0.00)\n",
      "Iter 1710 | Time 75.6728(73.4986) | Bit/dim 3.4996(3.5079) | Xent 0.0000(0.0000) | Loss 8.1880(8.9412) | Error 0.0000(0.0000) Steps 670(667.72) | Grad Norm 0.2073(0.2456) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0285 | Time 24.3139, Epoch Time 480.5061(457.5556), Bit/dim 3.5083(best: 3.5060), Xent 0.0000, Loss 3.5083, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1711 | Time 73.4783(73.4980) | Bit/dim 3.5091(3.5079) | Xent 0.0000(0.0000) | Loss 12.2186(9.0395) | Error 0.0000(0.0000) Steps 670(667.79) | Grad Norm 0.2512(0.2458) | Total Time 0.00(0.00)\n",
      "Iter 1712 | Time 72.1381(73.4572) | Bit/dim 3.5101(3.5080) | Xent 0.0000(0.0000) | Loss 8.4403(9.0216) | Error 0.0000(0.0000) Steps 682(668.22) | Grad Norm 0.2094(0.2447) | Total Time 0.00(0.00)\n",
      "Iter 1713 | Time 73.4028(73.4556) | Bit/dim 3.4942(3.5075) | Xent 0.0000(0.0000) | Loss 8.3514(9.0015) | Error 0.0000(0.0000) Steps 658(667.91) | Grad Norm 0.2122(0.2437) | Total Time 0.00(0.00)\n",
      "Iter 1714 | Time 72.9602(73.4407) | Bit/dim 3.5149(3.5078) | Xent 0.0000(0.0000) | Loss 8.4564(8.9851) | Error 0.0000(0.0000) Steps 676(668.15) | Grad Norm 0.1800(0.2418) | Total Time 0.00(0.00)\n",
      "Iter 1715 | Time 71.8358(73.3926) | Bit/dim 3.5114(3.5079) | Xent 0.0000(0.0000) | Loss 8.3231(8.9652) | Error 0.0000(0.0000) Steps 664(668.03) | Grad Norm 0.2326(0.2415) | Total Time 0.00(0.00)\n",
      "Iter 1716 | Time 74.0616(73.4127) | Bit/dim 3.5023(3.5077) | Xent 0.0000(0.0000) | Loss 8.2271(8.9431) | Error 0.0000(0.0000) Steps 646(667.37) | Grad Norm 0.2577(0.2420) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0286 | Time 23.5999, Epoch Time 477.7424(458.1612), Bit/dim 3.5045(best: 3.5060), Xent 0.0000, Loss 3.5045, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1717 | Time 74.9089(73.4576) | Bit/dim 3.4961(3.5074) | Xent 0.0000(0.0000) | Loss 12.1208(9.0384) | Error 0.0000(0.0000) Steps 682(667.81) | Grad Norm 0.2025(0.2408) | Total Time 0.00(0.00)\n",
      "Iter 1718 | Time 71.7815(73.4073) | Bit/dim 3.5087(3.5074) | Xent 0.0000(0.0000) | Loss 8.3266(9.0171) | Error 0.0000(0.0000) Steps 646(667.15) | Grad Norm 0.2176(0.2401) | Total Time 0.00(0.00)\n",
      "Iter 1719 | Time 74.1748(73.4303) | Bit/dim 3.5067(3.5074) | Xent 0.0000(0.0000) | Loss 8.3544(8.9972) | Error 0.0000(0.0000) Steps 658(666.88) | Grad Norm 0.2119(0.2393) | Total Time 0.00(0.00)\n",
      "Iter 1720 | Time 79.6019(73.6154) | Bit/dim 3.5086(3.5074) | Xent 0.0000(0.0000) | Loss 8.2682(8.9753) | Error 0.0000(0.0000) Steps 694(667.69) | Grad Norm 0.2275(0.2389) | Total Time 0.00(0.00)\n",
      "Iter 1721 | Time 76.9125(73.7144) | Bit/dim 3.5088(3.5075) | Xent 0.0000(0.0000) | Loss 8.1970(8.9520) | Error 0.0000(0.0000) Steps 688(668.30) | Grad Norm 0.2857(0.2403) | Total Time 0.00(0.00)\n",
      "Iter 1722 | Time 76.4071(73.7951) | Bit/dim 3.4999(3.5072) | Xent 0.0000(0.0000) | Loss 8.3390(8.9336) | Error 0.0000(0.0000) Steps 688(668.89) | Grad Norm 0.2194(0.2397) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0287 | Time 24.1060, Epoch Time 493.7987(459.2304), Bit/dim 3.5157(best: 3.5045), Xent 0.0000, Loss 3.5157, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1723 | Time 73.3687(73.7823) | Bit/dim 3.5037(3.5071) | Xent 0.0000(0.0000) | Loss 12.2204(9.0322) | Error 0.0000(0.0000) Steps 646(668.20) | Grad Norm 0.2832(0.2410) | Total Time 0.00(0.00)\n",
      "Iter 1724 | Time 74.6045(73.8070) | Bit/dim 3.4946(3.5068) | Xent 0.0000(0.0000) | Loss 7.9847(9.0008) | Error 0.0000(0.0000) Steps 676(668.44) | Grad Norm 0.7252(0.2555) | Total Time 0.00(0.00)\n",
      "Iter 1725 | Time 70.8429(73.7181) | Bit/dim 3.5094(3.5068) | Xent 0.0000(0.0000) | Loss 8.4860(8.9853) | Error 0.0000(0.0000) Steps 676(668.67) | Grad Norm 0.2161(0.2544) | Total Time 0.00(0.00)\n",
      "Iter 1726 | Time 79.1781(73.8819) | Bit/dim 3.5019(3.5067) | Xent 0.0000(0.0000) | Loss 8.4725(8.9699) | Error 0.0000(0.0000) Steps 700(669.61) | Grad Norm 0.2673(0.2547) | Total Time 0.00(0.00)\n",
      "Iter 1727 | Time 73.2736(73.8636) | Bit/dim 3.5158(3.5070) | Xent 0.0000(0.0000) | Loss 8.3037(8.9500) | Error 0.0000(0.0000) Steps 682(669.98) | Grad Norm 0.2245(0.2538) | Total Time 0.00(0.00)\n",
      "Iter 1728 | Time 70.6872(73.7683) | Bit/dim 3.5118(3.5071) | Xent 0.0000(0.0000) | Loss 8.5741(8.9387) | Error 0.0000(0.0000) Steps 682(670.34) | Grad Norm 0.2460(0.2536) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0288 | Time 23.7507, Epoch Time 481.5777(459.9008), Bit/dim 3.5147(best: 3.5045), Xent 0.0000, Loss 3.5147, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1729 | Time 71.3649(73.6962) | Bit/dim 3.5153(3.5074) | Xent 0.0000(0.0000) | Loss 12.0966(9.0334) | Error 0.0000(0.0000) Steps 652(669.79) | Grad Norm 0.2392(0.2532) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 73.8902(73.7021) | Bit/dim 3.5033(3.5072) | Xent 0.0000(0.0000) | Loss 8.3795(9.0138) | Error 0.0000(0.0000) Steps 682(670.15) | Grad Norm 0.3281(0.2554) | Total Time 0.00(0.00)\n",
      "Iter 1731 | Time 75.1132(73.7444) | Bit/dim 3.5070(3.5072) | Xent 0.0000(0.0000) | Loss 8.3092(8.9927) | Error 0.0000(0.0000) Steps 664(669.97) | Grad Norm 0.2416(0.2550) | Total Time 0.00(0.00)\n",
      "Iter 1732 | Time 74.5474(73.7685) | Bit/dim 3.5185(3.5076) | Xent 0.0000(0.0000) | Loss 8.4913(8.9776) | Error 0.0000(0.0000) Steps 688(670.51) | Grad Norm 0.1886(0.2530) | Total Time 0.00(0.00)\n",
      "Iter 1733 | Time 75.0232(73.8061) | Bit/dim 3.4987(3.5073) | Xent 0.0000(0.0000) | Loss 8.4029(8.9604) | Error 0.0000(0.0000) Steps 688(671.04) | Grad Norm 0.1824(0.2509) | Total Time 0.00(0.00)\n",
      "Iter 1734 | Time 70.4978(73.7069) | Bit/dim 3.5006(3.5071) | Xent 0.0000(0.0000) | Loss 8.3956(8.9434) | Error 0.0000(0.0000) Steps 652(670.46) | Grad Norm 0.2038(0.2495) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0289 | Time 23.8236, Epoch Time 480.4050(460.5159), Bit/dim 3.5078(best: 3.5045), Xent 0.0000, Loss 3.5078, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1735 | Time 71.4801(73.6401) | Bit/dim 3.5141(3.5073) | Xent 0.0000(0.0000) | Loss 11.7872(9.0287) | Error 0.0000(0.0000) Steps 664(670.27) | Grad Norm 0.3280(0.2518) | Total Time 0.00(0.00)\n",
      "Iter 1736 | Time 73.6102(73.6392) | Bit/dim 3.5002(3.5071) | Xent 0.0000(0.0000) | Loss 8.0986(9.0008) | Error 0.0000(0.0000) Steps 664(670.08) | Grad Norm 0.3082(0.2535) | Total Time 0.00(0.00)\n",
      "Iter 1737 | Time 81.7336(73.8820) | Bit/dim 3.5054(3.5070) | Xent 0.0000(0.0000) | Loss 8.4704(8.9849) | Error 0.0000(0.0000) Steps 658(669.72) | Grad Norm 0.1951(0.2518) | Total Time 0.00(0.00)\n",
      "Iter 1738 | Time 75.9334(73.9436) | Bit/dim 3.5074(3.5070) | Xent 0.0000(0.0000) | Loss 8.4436(8.9687) | Error 0.0000(0.0000) Steps 670(669.73) | Grad Norm 0.2230(0.2509) | Total Time 0.00(0.00)\n",
      "Iter 1739 | Time 74.6182(73.9638) | Bit/dim 3.5077(3.5071) | Xent 0.0000(0.0000) | Loss 8.5242(8.9554) | Error 0.0000(0.0000) Steps 670(669.74) | Grad Norm 0.1955(0.2493) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 75.8377(74.0200) | Bit/dim 3.5026(3.5069) | Xent 0.0000(0.0000) | Loss 8.3241(8.9364) | Error 0.0000(0.0000) Steps 658(669.38) | Grad Norm 0.2367(0.2489) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0290 | Time 24.7573, Epoch Time 493.7067(461.5116), Bit/dim 3.5103(best: 3.5045), Xent 0.0000, Loss 3.5103, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1741 | Time 72.1363(73.9635) | Bit/dim 3.5003(3.5067) | Xent 0.0000(0.0000) | Loss 11.9325(9.0263) | Error 0.0000(0.0000) Steps 664(669.22) | Grad Norm 0.2894(0.2501) | Total Time 0.00(0.00)\n",
      "Iter 1742 | Time 71.9301(73.9025) | Bit/dim 3.5027(3.5066) | Xent 0.0000(0.0000) | Loss 8.3542(9.0061) | Error 0.0000(0.0000) Steps 658(668.89) | Grad Norm 0.2054(0.2487) | Total Time 0.00(0.00)\n",
      "Iter 1743 | Time 78.0846(74.0280) | Bit/dim 3.5123(3.5068) | Xent 0.0000(0.0000) | Loss 8.4518(8.9895) | Error 0.0000(0.0000) Steps 670(668.92) | Grad Norm 0.2068(0.2475) | Total Time 0.00(0.00)\n",
      "Iter 1744 | Time 73.7176(74.0187) | Bit/dim 3.5043(3.5067) | Xent 0.0000(0.0000) | Loss 8.3319(8.9698) | Error 0.0000(0.0000) Steps 658(668.59) | Grad Norm 0.1685(0.2451) | Total Time 0.00(0.00)\n",
      "Iter 1745 | Time 75.0208(74.0487) | Bit/dim 3.5066(3.5067) | Xent 0.0000(0.0000) | Loss 8.4474(8.9541) | Error 0.0000(0.0000) Steps 682(668.99) | Grad Norm 0.2737(0.2460) | Total Time 0.00(0.00)\n",
      "Iter 1746 | Time 71.2485(73.9647) | Bit/dim 3.5104(3.5068) | Xent 0.0000(0.0000) | Loss 8.1626(8.9304) | Error 0.0000(0.0000) Steps 640(668.12) | Grad Norm 0.3942(0.2504) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0291 | Time 24.5900, Epoch Time 482.0089(462.1265), Bit/dim 3.5084(best: 3.5045), Xent 0.0000, Loss 3.5084, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1747 | Time 75.0959(73.9986) | Bit/dim 3.5089(3.5069) | Xent 0.0000(0.0000) | Loss 12.3106(9.0318) | Error 0.0000(0.0000) Steps 700(669.08) | Grad Norm 0.2285(0.2498) | Total Time 0.00(0.00)\n",
      "Iter 1748 | Time 71.6117(73.9270) | Bit/dim 3.5191(3.5072) | Xent 0.0000(0.0000) | Loss 8.6433(9.0201) | Error 0.0000(0.0000) Steps 694(669.83) | Grad Norm 0.1869(0.2479) | Total Time 0.00(0.00)\n",
      "Iter 1749 | Time 70.6875(73.8299) | Bit/dim 3.4973(3.5069) | Xent 0.0000(0.0000) | Loss 8.2865(8.9981) | Error 0.0000(0.0000) Steps 652(669.29) | Grad Norm 0.2711(0.2486) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 80.9861(74.0445) | Bit/dim 3.5005(3.5068) | Xent 0.0000(0.0000) | Loss 8.2220(8.9748) | Error 0.0000(0.0000) Steps 694(670.03) | Grad Norm 0.2184(0.2477) | Total Time 0.00(0.00)\n",
      "Iter 1751 | Time 71.7609(73.9760) | Bit/dim 3.5149(3.5070) | Xent 0.0000(0.0000) | Loss 8.4025(8.9577) | Error 0.0000(0.0000) Steps 664(669.85) | Grad Norm 0.2993(0.2492) | Total Time 0.00(0.00)\n",
      "Iter 1752 | Time 80.1630(74.1616) | Bit/dim 3.5030(3.5069) | Xent 0.0000(0.0000) | Loss 8.3388(8.9391) | Error 0.0000(0.0000) Steps 658(669.50) | Grad Norm 0.2120(0.2481) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0292 | Time 24.1254, Epoch Time 490.4155(462.9752), Bit/dim 3.5089(best: 3.5045), Xent 0.0000, Loss 3.5089, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1753 | Time 80.2372(74.3439) | Bit/dim 3.4932(3.5065) | Xent 0.0000(0.0000) | Loss 12.3925(9.0427) | Error 0.0000(0.0000) Steps 688(670.05) | Grad Norm 0.2879(0.2493) | Total Time 0.00(0.00)\n",
      "Iter 1754 | Time 72.5632(74.2905) | Bit/dim 3.5166(3.5068) | Xent 0.0000(0.0000) | Loss 8.5311(9.0273) | Error 0.0000(0.0000) Steps 676(670.23) | Grad Norm 0.2128(0.2482) | Total Time 0.00(0.00)\n",
      "Iter 1755 | Time 73.1177(74.2553) | Bit/dim 3.5136(3.5070) | Xent 0.0000(0.0000) | Loss 8.4049(9.0087) | Error 0.0000(0.0000) Steps 652(669.68) | Grad Norm 0.2405(0.2480) | Total Time 0.00(0.00)\n",
      "Iter 1756 | Time 77.6193(74.3562) | Bit/dim 3.4998(3.5068) | Xent 0.0000(0.0000) | Loss 8.4162(8.9909) | Error 0.0000(0.0000) Steps 652(669.15) | Grad Norm 0.2011(0.2466) | Total Time 0.00(0.00)\n",
      "Iter 1757 | Time 70.6497(74.2450) | Bit/dim 3.5101(3.5069) | Xent 0.0000(0.0000) | Loss 8.3185(8.9707) | Error 0.0000(0.0000) Steps 664(669.00) | Grad Norm 0.3074(0.2484) | Total Time 0.00(0.00)\n",
      "Iter 1758 | Time 74.5775(74.2550) | Bit/dim 3.5060(3.5068) | Xent 0.0000(0.0000) | Loss 8.3529(8.9522) | Error 0.0000(0.0000) Steps 658(668.67) | Grad Norm 0.2365(0.2480) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0293 | Time 24.2352, Epoch Time 489.1599(463.7608), Bit/dim 3.5044(best: 3.5045), Xent 0.0000, Loss 3.5044, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1759 | Time 72.4576(74.2011) | Bit/dim 3.4986(3.5066) | Xent 0.0000(0.0000) | Loss 11.9540(9.0422) | Error 0.0000(0.0000) Steps 670(668.71) | Grad Norm 0.2995(0.2496) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 74.5255(74.2108) | Bit/dim 3.5144(3.5068) | Xent 0.0000(0.0000) | Loss 8.2924(9.0198) | Error 0.0000(0.0000) Steps 676(668.93) | Grad Norm 0.2341(0.2491) | Total Time 0.00(0.00)\n",
      "Iter 1761 | Time 68.6575(74.0442) | Bit/dim 3.5050(3.5068) | Xent 0.0000(0.0000) | Loss 8.5200(9.0048) | Error 0.0000(0.0000) Steps 676(669.14) | Grad Norm 0.2193(0.2482) | Total Time 0.00(0.00)\n",
      "Iter 1762 | Time 71.7197(73.9745) | Bit/dim 3.5066(3.5068) | Xent 0.0000(0.0000) | Loss 8.1485(8.9791) | Error 0.0000(0.0000) Steps 664(668.99) | Grad Norm 0.2491(0.2482) | Total Time 0.00(0.00)\n",
      "Iter 1763 | Time 72.9479(73.9437) | Bit/dim 3.4969(3.5065) | Xent 0.0000(0.0000) | Loss 8.4781(8.9640) | Error 0.0000(0.0000) Steps 664(668.84) | Grad Norm 0.2497(0.2483) | Total Time 0.00(0.00)\n",
      "Iter 1764 | Time 71.1326(73.8593) | Bit/dim 3.5084(3.5065) | Xent 0.0000(0.0000) | Loss 8.4362(8.9482) | Error 0.0000(0.0000) Steps 652(668.33) | Grad Norm 0.1671(0.2459) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0294 | Time 23.9482, Epoch Time 471.1580(463.9827), Bit/dim 3.5121(best: 3.5044), Xent 0.0000, Loss 3.5121, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1765 | Time 75.3612(73.9044) | Bit/dim 3.5180(3.5069) | Xent 0.0000(0.0000) | Loss 12.1809(9.0452) | Error 0.0000(0.0000) Steps 670(668.38) | Grad Norm 0.2613(0.2463) | Total Time 0.00(0.00)\n",
      "Iter 1766 | Time 78.5713(74.0444) | Bit/dim 3.5033(3.5068) | Xent 0.0000(0.0000) | Loss 8.4657(9.0278) | Error 0.0000(0.0000) Steps 688(668.97) | Grad Norm 0.2236(0.2456) | Total Time 0.00(0.00)\n",
      "Iter 1767 | Time 69.5720(73.9102) | Bit/dim 3.5085(3.5068) | Xent 0.0000(0.0000) | Loss 8.3830(9.0085) | Error 0.0000(0.0000) Steps 652(668.46) | Grad Norm 0.2596(0.2461) | Total Time 0.00(0.00)\n",
      "Iter 1768 | Time 70.8060(73.8171) | Bit/dim 3.5044(3.5067) | Xent 0.0000(0.0000) | Loss 8.4957(8.9931) | Error 0.0000(0.0000) Steps 676(668.69) | Grad Norm 0.2218(0.2453) | Total Time 0.00(0.00)\n",
      "Iter 1769 | Time 68.6694(73.6627) | Bit/dim 3.4919(3.5063) | Xent 0.0000(0.0000) | Loss 8.2075(8.9695) | Error 0.0000(0.0000) Steps 652(668.19) | Grad Norm 0.2769(0.2463) | Total Time 0.00(0.00)\n",
      "Iter 1770 | Time 71.9017(73.6098) | Bit/dim 3.5094(3.5064) | Xent 0.0000(0.0000) | Loss 8.2515(8.9480) | Error 0.0000(0.0000) Steps 670(668.24) | Grad Norm 0.2577(0.2466) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0295 | Time 23.8086, Epoch Time 474.5181(464.2987), Bit/dim 3.5105(best: 3.5044), Xent 0.0000, Loss 3.5105, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1771 | Time 74.5237(73.6373) | Bit/dim 3.5092(3.5065) | Xent 0.0000(0.0000) | Loss 11.8811(9.0360) | Error 0.0000(0.0000) Steps 652(667.75) | Grad Norm 0.3515(0.2498) | Total Time 0.00(0.00)\n",
      "Iter 1772 | Time 74.5507(73.6647) | Bit/dim 3.5040(3.5064) | Xent 0.0000(0.0000) | Loss 8.4583(9.0186) | Error 0.0000(0.0000) Steps 652(667.28) | Grad Norm 0.2081(0.2485) | Total Time 0.00(0.00)\n",
      "Iter 1773 | Time 73.5709(73.6619) | Bit/dim 3.5030(3.5063) | Xent 0.0000(0.0000) | Loss 8.3417(8.9983) | Error 0.0000(0.0000) Steps 658(667.00) | Grad Norm 0.1804(0.2465) | Total Time 0.00(0.00)\n",
      "Iter 1774 | Time 80.4062(73.8642) | Bit/dim 3.4976(3.5060) | Xent 0.0000(0.0000) | Loss 8.3413(8.9786) | Error 0.0000(0.0000) Steps 676(667.27) | Grad Norm 0.3515(0.2496) | Total Time 0.00(0.00)\n",
      "Iter 1775 | Time 74.7008(73.8893) | Bit/dim 3.5030(3.5059) | Xent 0.0000(0.0000) | Loss 8.4841(8.9638) | Error 0.0000(0.0000) Steps 664(667.17) | Grad Norm 0.2247(0.2489) | Total Time 0.00(0.00)\n",
      "Iter 1776 | Time 70.8663(73.7986) | Bit/dim 3.5009(3.5058) | Xent 0.0000(0.0000) | Loss 8.4231(8.9476) | Error 0.0000(0.0000) Steps 676(667.44) | Grad Norm 0.1896(0.2471) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0296 | Time 24.7912, Epoch Time 489.6453(465.0591), Bit/dim 3.5097(best: 3.5044), Xent 0.0000, Loss 3.5097, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1777 | Time 76.6336(73.8836) | Bit/dim 3.5158(3.5061) | Xent 0.0000(0.0000) | Loss 12.0127(9.0395) | Error 0.0000(0.0000) Steps 694(668.24) | Grad Norm 0.2813(0.2481) | Total Time 0.00(0.00)\n",
      "Iter 1778 | Time 78.7045(74.0283) | Bit/dim 3.5043(3.5060) | Xent 0.0000(0.0000) | Loss 8.5912(9.0261) | Error 0.0000(0.0000) Steps 682(668.65) | Grad Norm 0.1957(0.2466) | Total Time 0.00(0.00)\n",
      "Iter 1779 | Time 71.9998(73.9674) | Bit/dim 3.5128(3.5062) | Xent 0.0000(0.0000) | Loss 8.1280(8.9991) | Error 0.0000(0.0000) Steps 664(668.51) | Grad Norm 0.3580(0.2499) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 68.9553(73.8170) | Bit/dim 3.4955(3.5059) | Xent 0.0000(0.0000) | Loss 8.1920(8.9749) | Error 0.0000(0.0000) Steps 652(668.01) | Grad Norm 0.2721(0.2506) | Total Time 0.00(0.00)\n",
      "Iter 1781 | Time 80.9564(74.0312) | Bit/dim 3.5058(3.5059) | Xent 0.0000(0.0000) | Loss 8.1954(8.9515) | Error 0.0000(0.0000) Steps 688(668.61) | Grad Norm 0.2791(0.2514) | Total Time 0.00(0.00)\n",
      "Iter 1782 | Time 75.4752(74.0745) | Bit/dim 3.5058(3.5059) | Xent 0.0000(0.0000) | Loss 8.4404(8.9362) | Error 0.0000(0.0000) Steps 676(668.84) | Grad Norm 0.1594(0.2487) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0297 | Time 24.3279, Epoch Time 493.3173(465.9069), Bit/dim 3.5041(best: 3.5044), Xent 0.0000, Loss 3.5041, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1783 | Time 68.2809(73.9007) | Bit/dim 3.4923(3.5055) | Xent 0.0000(0.0000) | Loss 11.7854(9.0217) | Error 0.0000(0.0000) Steps 646(668.15) | Grad Norm 0.3076(0.2504) | Total Time 0.00(0.00)\n",
      "Iter 1784 | Time 77.4976(74.0086) | Bit/dim 3.5049(3.5055) | Xent 0.0000(0.0000) | Loss 8.2871(8.9996) | Error 0.0000(0.0000) Steps 658(667.85) | Grad Norm 0.2603(0.2507) | Total Time 0.00(0.00)\n",
      "Iter 1785 | Time 73.2258(73.9852) | Bit/dim 3.4994(3.5053) | Xent 0.0000(0.0000) | Loss 8.4314(8.9826) | Error 0.0000(0.0000) Steps 676(668.09) | Grad Norm 0.1843(0.2487) | Total Time 0.00(0.00)\n",
      "Iter 1786 | Time 75.2805(74.0240) | Bit/dim 3.5205(3.5058) | Xent 0.0000(0.0000) | Loss 8.4898(8.9678) | Error 0.0000(0.0000) Steps 664(667.97) | Grad Norm 0.1705(0.2464) | Total Time 0.00(0.00)\n",
      "Iter 1787 | Time 74.1868(74.0289) | Bit/dim 3.5032(3.5057) | Xent 0.0000(0.0000) | Loss 8.3529(8.9493) | Error 0.0000(0.0000) Steps 670(668.03) | Grad Norm 0.1818(0.2444) | Total Time 0.00(0.00)\n",
      "Iter 1788 | Time 74.8610(74.0539) | Bit/dim 3.5095(3.5058) | Xent 0.0000(0.0000) | Loss 8.3822(8.9323) | Error 0.0000(0.0000) Steps 664(667.91) | Grad Norm 0.2658(0.2451) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0298 | Time 24.3253, Epoch Time 483.7520(466.4422), Bit/dim 3.5136(best: 3.5041), Xent 0.0000, Loss 3.5136, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1789 | Time 80.1021(74.2353) | Bit/dim 3.4962(3.5055) | Xent 0.0000(0.0000) | Loss 12.1295(9.0282) | Error 0.0000(0.0000) Steps 700(668.87) | Grad Norm 0.2701(0.2458) | Total Time 0.00(0.00)\n",
      "Iter 1790 | Time 71.3747(74.1495) | Bit/dim 3.5057(3.5055) | Xent 0.0000(0.0000) | Loss 8.3916(9.0092) | Error 0.0000(0.0000) Steps 658(668.54) | Grad Norm 0.2206(0.2451) | Total Time 0.00(0.00)\n",
      "Iter 1791 | Time 72.4472(74.0984) | Bit/dim 3.5030(3.5054) | Xent 0.0000(0.0000) | Loss 8.3854(8.9904) | Error 0.0000(0.0000) Steps 670(668.59) | Grad Norm 0.1969(0.2436) | Total Time 0.00(0.00)\n",
      "Iter 1792 | Time 71.5553(74.0221) | Bit/dim 3.5005(3.5053) | Xent 0.0000(0.0000) | Loss 8.4253(8.9735) | Error 0.0000(0.0000) Steps 652(668.09) | Grad Norm 0.2563(0.2440) | Total Time 0.00(0.00)\n",
      "Iter 1793 | Time 74.5460(74.0378) | Bit/dim 3.5155(3.5056) | Xent 0.0000(0.0000) | Loss 8.2907(8.9530) | Error 0.0000(0.0000) Steps 640(667.25) | Grad Norm 0.1984(0.2426) | Total Time 0.00(0.00)\n",
      "Iter 1794 | Time 72.1678(73.9817) | Bit/dim 3.5109(3.5058) | Xent 0.0000(0.0000) | Loss 8.4687(8.9385) | Error 0.0000(0.0000) Steps 676(667.51) | Grad Norm 0.2209(0.2420) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0299 | Time 23.6498, Epoch Time 482.0618(466.9108), Bit/dim 3.5075(best: 3.5041), Xent 0.0000, Loss 3.5075, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1795 | Time 72.7096(73.9436) | Bit/dim 3.4879(3.5052) | Xent 0.0000(0.0000) | Loss 11.7396(9.0225) | Error 0.0000(0.0000) Steps 652(667.04) | Grad Norm 0.2754(0.2430) | Total Time 0.00(0.00)\n",
      "Iter 1796 | Time 71.8287(73.8801) | Bit/dim 3.5037(3.5052) | Xent 0.0000(0.0000) | Loss 8.1385(8.9960) | Error 0.0000(0.0000) Steps 658(666.77) | Grad Norm 0.3014(0.2448) | Total Time 0.00(0.00)\n",
      "Iter 1797 | Time 71.7290(73.8156) | Bit/dim 3.5077(3.5052) | Xent 0.0000(0.0000) | Loss 8.2605(8.9739) | Error 0.0000(0.0000) Steps 664(666.69) | Grad Norm 0.3192(0.2470) | Total Time 0.00(0.00)\n",
      "Iter 1798 | Time 73.0376(73.7923) | Bit/dim 3.5113(3.5054) | Xent 0.0000(0.0000) | Loss 8.5191(8.9603) | Error 0.0000(0.0000) Steps 676(666.97) | Grad Norm 0.1737(0.2448) | Total Time 0.00(0.00)\n",
      "Iter 1799 | Time 79.9022(73.9756) | Bit/dim 3.4982(3.5052) | Xent 0.0000(0.0000) | Loss 8.3800(8.9429) | Error 0.0000(0.0000) Steps 670(667.06) | Grad Norm 0.2383(0.2446) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 74.0030(73.9764) | Bit/dim 3.5069(3.5053) | Xent 0.0000(0.0000) | Loss 8.4450(8.9279) | Error 0.0000(0.0000) Steps 664(666.97) | Grad Norm 0.1960(0.2431) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0300 | Time 23.8424, Epoch Time 482.6393(467.3827), Bit/dim 3.5045(best: 3.5041), Xent 0.0000, Loss 3.5045, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1801 | Time 78.4084(74.1093) | Bit/dim 3.4916(3.5049) | Xent 0.0000(0.0000) | Loss 11.6738(9.0103) | Error 0.0000(0.0000) Steps 682(667.42) | Grad Norm 0.7660(0.2588) | Total Time 0.00(0.00)\n",
      "Iter 1802 | Time 69.0268(73.9569) | Bit/dim 3.5019(3.5048) | Xent 0.0000(0.0000) | Loss 8.2885(8.9887) | Error 0.0000(0.0000) Steps 640(666.60) | Grad Norm 0.3914(0.2628) | Total Time 0.00(0.00)\n",
      "Iter 1803 | Time 76.5707(74.0353) | Bit/dim 3.5104(3.5049) | Xent 0.0000(0.0000) | Loss 8.4213(8.9716) | Error 0.0000(0.0000) Steps 676(666.88) | Grad Norm 0.2100(0.2612) | Total Time 0.00(0.00)\n",
      "Iter 1804 | Time 75.4760(74.0785) | Bit/dim 3.5065(3.5050) | Xent 0.0000(0.0000) | Loss 8.3900(8.9542) | Error 0.0000(0.0000) Steps 670(666.97) | Grad Norm 0.3335(0.2634) | Total Time 0.00(0.00)\n",
      "Iter 1805 | Time 73.0880(74.0488) | Bit/dim 3.5132(3.5052) | Xent 0.0000(0.0000) | Loss 8.3565(8.9363) | Error 0.0000(0.0000) Steps 658(666.70) | Grad Norm 0.1810(0.2609) | Total Time 0.00(0.00)\n",
      "Iter 1806 | Time 74.1774(74.0526) | Bit/dim 3.5017(3.5051) | Xent 0.0000(0.0000) | Loss 8.3989(8.9201) | Error 0.0000(0.0000) Steps 658(666.44) | Grad Norm 0.2394(0.2603) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0301 | Time 24.0997, Epoch Time 486.9812(467.9706), Bit/dim 3.5069(best: 3.5041), Xent 0.0000, Loss 3.5069, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1807 | Time 71.7768(73.9844) | Bit/dim 3.5054(3.5051) | Xent 0.0000(0.0000) | Loss 11.7900(9.0062) | Error 0.0000(0.0000) Steps 658(666.19) | Grad Norm 0.6067(0.2707) | Total Time 0.00(0.00)\n",
      "Iter 1808 | Time 77.2551(74.0825) | Bit/dim 3.5120(3.5053) | Xent 0.0000(0.0000) | Loss 8.5288(8.9919) | Error 0.0000(0.0000) Steps 682(666.66) | Grad Norm 0.3591(0.2733) | Total Time 0.00(0.00)\n",
      "Iter 1809 | Time 77.4065(74.1822) | Bit/dim 3.5028(3.5053) | Xent 0.0000(0.0000) | Loss 8.4910(8.9769) | Error 0.0000(0.0000) Steps 664(666.58) | Grad Norm 0.2517(0.2727) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 75.9452(74.2351) | Bit/dim 3.5084(3.5054) | Xent 0.0000(0.0000) | Loss 8.3372(8.9577) | Error 0.0000(0.0000) Steps 670(666.69) | Grad Norm 0.3583(0.2752) | Total Time 0.00(0.00)\n",
      "Iter 1811 | Time 74.4960(74.2429) | Bit/dim 3.4962(3.5051) | Xent 0.0000(0.0000) | Loss 8.4770(8.9433) | Error 0.0000(0.0000) Steps 688(667.33) | Grad Norm 0.2012(0.2730) | Total Time 0.00(0.00)\n",
      "Iter 1812 | Time 73.7253(74.2274) | Bit/dim 3.5091(3.5052) | Xent 0.0000(0.0000) | Loss 8.1867(8.9206) | Error 0.0000(0.0000) Steps 664(667.23) | Grad Norm 0.3982(0.2768) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0302 | Time 23.5445, Epoch Time 490.2488(468.6390), Bit/dim 3.5079(best: 3.5041), Xent 0.0000, Loss 3.5079, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1813 | Time 70.7432(74.1229) | Bit/dim 3.4991(3.5050) | Xent 0.0000(0.0000) | Loss 12.0899(9.0157) | Error 0.0000(0.0000) Steps 658(666.95) | Grad Norm 0.3179(0.2780) | Total Time 0.00(0.00)\n",
      "Iter 1814 | Time 69.8821(73.9957) | Bit/dim 3.5037(3.5050) | Xent 0.0000(0.0000) | Loss 8.4841(8.9997) | Error 0.0000(0.0000) Steps 664(666.86) | Grad Norm 0.3289(0.2795) | Total Time 0.00(0.00)\n",
      "Iter 1815 | Time 73.5479(73.9822) | Bit/dim 3.5070(3.5050) | Xent 0.0000(0.0000) | Loss 8.3768(8.9810) | Error 0.0000(0.0000) Steps 670(666.95) | Grad Norm 0.3077(0.2804) | Total Time 0.00(0.00)\n",
      "Iter 1816 | Time 75.5633(74.0297) | Bit/dim 3.5098(3.5052) | Xent 0.0000(0.0000) | Loss 8.4677(8.9656) | Error 0.0000(0.0000) Steps 670(667.05) | Grad Norm 0.3126(0.2813) | Total Time 0.00(0.00)\n",
      "Iter 1817 | Time 79.2460(74.1861) | Bit/dim 3.4949(3.5049) | Xent 0.0000(0.0000) | Loss 8.4373(8.9498) | Error 0.0000(0.0000) Steps 700(668.03) | Grad Norm 0.4591(0.2867) | Total Time 0.00(0.00)\n",
      "Iter 1818 | Time 76.0662(74.2425) | Bit/dim 3.5100(3.5050) | Xent 0.0000(0.0000) | Loss 8.3491(8.9317) | Error 0.0000(0.0000) Steps 670(668.09) | Grad Norm 0.3028(0.2872) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0303 | Time 24.3833, Epoch Time 485.5289(469.1457), Bit/dim 3.5002(best: 3.5041), Xent 0.0000, Loss 3.5002, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1819 | Time 72.9238(74.2030) | Bit/dim 3.5029(3.5050) | Xent 0.0000(0.0000) | Loss 12.3721(9.0350) | Error 0.0000(0.0000) Steps 658(667.79) | Grad Norm 0.2975(0.2875) | Total Time 0.00(0.00)\n",
      "Iter 1820 | Time 72.9654(74.1659) | Bit/dim 3.5034(3.5049) | Xent 0.0000(0.0000) | Loss 8.4196(9.0165) | Error 0.0000(0.0000) Steps 676(668.04) | Grad Norm 0.2710(0.2870) | Total Time 0.00(0.00)\n",
      "Iter 1821 | Time 73.8167(74.1554) | Bit/dim 3.4937(3.5046) | Xent 0.0000(0.0000) | Loss 8.3007(8.9950) | Error 0.0000(0.0000) Steps 664(667.92) | Grad Norm 0.3484(0.2888) | Total Time 0.00(0.00)\n",
      "Iter 1822 | Time 80.6610(74.3506) | Bit/dim 3.5098(3.5047) | Xent 0.0000(0.0000) | Loss 8.4256(8.9779) | Error 0.0000(0.0000) Steps 694(668.70) | Grad Norm 0.2934(0.2889) | Total Time 0.00(0.00)\n",
      "Iter 1823 | Time 78.0709(74.4622) | Bit/dim 3.5069(3.5048) | Xent 0.0000(0.0000) | Loss 8.4385(8.9618) | Error 0.0000(0.0000) Steps 670(668.74) | Grad Norm 0.2734(0.2885) | Total Time 0.00(0.00)\n",
      "Iter 1824 | Time 76.7476(74.5307) | Bit/dim 3.5098(3.5050) | Xent 0.0000(0.0000) | Loss 8.2473(8.9403) | Error 0.0000(0.0000) Steps 676(668.96) | Grad Norm 0.3087(0.2891) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0304 | Time 23.0507, Epoch Time 493.8378(469.8864), Bit/dim 3.5087(best: 3.5002), Xent 0.0000, Loss 3.5087, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1825 | Time 74.6285(74.5337) | Bit/dim 3.4997(3.5048) | Xent 0.0000(0.0000) | Loss 11.8440(9.0274) | Error 0.0000(0.0000) Steps 652(668.45) | Grad Norm 0.4185(0.2930) | Total Time 0.00(0.00)\n",
      "Iter 1826 | Time 73.9706(74.5168) | Bit/dim 3.5109(3.5050) | Xent 0.0000(0.0000) | Loss 8.4737(9.0108) | Error 0.0000(0.0000) Steps 688(669.03) | Grad Norm 0.2633(0.2921) | Total Time 0.00(0.00)\n",
      "Iter 1827 | Time 73.1183(74.4748) | Bit/dim 3.4959(3.5047) | Xent 0.0000(0.0000) | Loss 8.2801(8.9889) | Error 0.0000(0.0000) Steps 670(669.06) | Grad Norm 0.3015(0.2924) | Total Time 0.00(0.00)\n",
      "Iter 1828 | Time 70.5855(74.3581) | Bit/dim 3.5084(3.5048) | Xent 0.0000(0.0000) | Loss 8.2765(8.9675) | Error 0.0000(0.0000) Steps 652(668.55) | Grad Norm 0.2374(0.2907) | Total Time 0.00(0.00)\n",
      "Iter 1829 | Time 72.3000(74.2964) | Bit/dim 3.5048(3.5048) | Xent 0.0000(0.0000) | Loss 8.3709(8.9496) | Error 0.0000(0.0000) Steps 676(668.77) | Grad Norm 0.3063(0.2912) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 71.2296(74.2044) | Bit/dim 3.5064(3.5049) | Xent 0.0000(0.0000) | Loss 8.4341(8.9342) | Error 0.0000(0.0000) Steps 670(668.81) | Grad Norm 0.2652(0.2904) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0305 | Time 24.2102, Epoch Time 476.2024(470.0759), Bit/dim 3.5075(best: 3.5002), Xent 0.0000, Loss 3.5075, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1831 | Time 73.2617(74.1761) | Bit/dim 3.4997(3.5047) | Xent 0.0000(0.0000) | Loss 11.8826(9.0226) | Error 0.0000(0.0000) Steps 676(669.03) | Grad Norm 0.3750(0.2929) | Total Time 0.00(0.00)\n",
      "Iter 1832 | Time 72.3845(74.1224) | Bit/dim 3.5047(3.5047) | Xent 0.0000(0.0000) | Loss 8.4353(9.0050) | Error 0.0000(0.0000) Steps 664(668.88) | Grad Norm 0.2305(0.2911) | Total Time 0.00(0.00)\n",
      "Iter 1833 | Time 71.4924(74.0435) | Bit/dim 3.5050(3.5047) | Xent 0.0000(0.0000) | Loss 8.4348(8.9879) | Error 0.0000(0.0000) Steps 670(668.91) | Grad Norm 0.2619(0.2902) | Total Time 0.00(0.00)\n",
      "Iter 1834 | Time 73.7735(74.0354) | Bit/dim 3.4962(3.5045) | Xent 0.0000(0.0000) | Loss 8.4350(8.9713) | Error 0.0000(0.0000) Steps 670(668.94) | Grad Norm 0.1978(0.2874) | Total Time 0.00(0.00)\n",
      "Iter 1835 | Time 73.4948(74.0191) | Bit/dim 3.4931(3.5041) | Xent 0.0000(0.0000) | Loss 8.2884(8.9508) | Error 0.0000(0.0000) Steps 652(668.43) | Grad Norm 0.2158(0.2853) | Total Time 0.00(0.00)\n",
      "Iter 1836 | Time 78.9483(74.1670) | Bit/dim 3.5168(3.5045) | Xent 0.0000(0.0000) | Loss 8.5092(8.9376) | Error 0.0000(0.0000) Steps 664(668.30) | Grad Norm 0.1982(0.2827) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0306 | Time 23.6610, Epoch Time 483.0425(470.4649), Bit/dim 3.5082(best: 3.5002), Xent 0.0000, Loss 3.5082, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1837 | Time 75.8616(74.2179) | Bit/dim 3.4978(3.5043) | Xent 0.0000(0.0000) | Loss 12.1747(9.0347) | Error 0.0000(0.0000) Steps 688(668.89) | Grad Norm 0.2793(0.2826) | Total Time 0.00(0.00)\n",
      "Iter 1838 | Time 69.9846(74.0909) | Bit/dim 3.5032(3.5043) | Xent 0.0000(0.0000) | Loss 7.8757(8.9999) | Error 0.0000(0.0000) Steps 652(668.39) | Grad Norm 0.3236(0.2838) | Total Time 0.00(0.00)\n",
      "Iter 1839 | Time 72.8089(74.0524) | Bit/dim 3.5072(3.5044) | Xent 0.0000(0.0000) | Loss 8.4000(8.9819) | Error 0.0000(0.0000) Steps 658(668.07) | Grad Norm 0.2690(0.2833) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 68.5419(73.8871) | Bit/dim 3.5061(3.5044) | Xent 0.0000(0.0000) | Loss 8.2442(8.9598) | Error 0.0000(0.0000) Steps 670(668.13) | Grad Norm 0.4522(0.2884) | Total Time 0.00(0.00)\n",
      "Iter 1841 | Time 75.9751(73.9497) | Bit/dim 3.5016(3.5043) | Xent 0.0000(0.0000) | Loss 8.4342(8.9440) | Error 0.0000(0.0000) Steps 676(668.37) | Grad Norm 0.2792(0.2881) | Total Time 0.00(0.00)\n",
      "Iter 1842 | Time 74.1237(73.9549) | Bit/dim 3.5071(3.5044) | Xent 0.0000(0.0000) | Loss 8.1938(8.9215) | Error 0.0000(0.0000) Steps 646(667.70) | Grad Norm 0.6262(0.2983) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0307 | Time 23.8419, Epoch Time 477.3888(470.6726), Bit/dim 3.5082(best: 3.5002), Xent 0.0000, Loss 3.5082, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1843 | Time 70.0447(73.8376) | Bit/dim 3.5102(3.5046) | Xent 0.0000(0.0000) | Loss 12.1234(9.0176) | Error 0.0000(0.0000) Steps 658(667.41) | Grad Norm 0.2403(0.2965) | Total Time 0.00(0.00)\n",
      "Iter 1844 | Time 76.3771(73.9138) | Bit/dim 3.5106(3.5048) | Xent 0.0000(0.0000) | Loss 8.3890(8.9987) | Error 0.0000(0.0000) Steps 670(667.48) | Grad Norm 0.3037(0.2968) | Total Time 0.00(0.00)\n",
      "Iter 1845 | Time 73.8390(73.9116) | Bit/dim 3.4917(3.5044) | Xent 0.0000(0.0000) | Loss 8.3401(8.9789) | Error 0.0000(0.0000) Steps 646(666.84) | Grad Norm 0.2116(0.2942) | Total Time 0.00(0.00)\n",
      "Iter 1846 | Time 74.9720(73.9434) | Bit/dim 3.5105(3.5046) | Xent 0.0000(0.0000) | Loss 8.3483(8.9600) | Error 0.0000(0.0000) Steps 640(666.03) | Grad Norm 0.3380(0.2955) | Total Time 0.00(0.00)\n",
      "Iter 1847 | Time 74.7675(73.9681) | Bit/dim 3.4997(3.5044) | Xent 0.0000(0.0000) | Loss 8.3833(8.9427) | Error 0.0000(0.0000) Steps 676(666.33) | Grad Norm 0.2361(0.2937) | Total Time 0.00(0.00)\n",
      "Iter 1848 | Time 74.6477(73.9885) | Bit/dim 3.5096(3.5046) | Xent 0.0000(0.0000) | Loss 8.3727(8.9256) | Error 0.0000(0.0000) Steps 658(666.08) | Grad Norm 0.2330(0.2919) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0308 | Time 24.1797, Epoch Time 484.8118(471.0968), Bit/dim 3.5045(best: 3.5002), Xent 0.0000, Loss 3.5045, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1849 | Time 73.9712(73.9880) | Bit/dim 3.4987(3.5044) | Xent 0.0000(0.0000) | Loss 11.9948(9.0177) | Error 0.0000(0.0000) Steps 670(666.20) | Grad Norm 0.4158(0.2956) | Total Time 0.00(0.00)\n",
      "Iter 1850 | Time 70.4471(73.8818) | Bit/dim 3.5150(3.5047) | Xent 0.0000(0.0000) | Loss 8.5212(9.0028) | Error 0.0000(0.0000) Steps 664(666.13) | Grad Norm 0.2814(0.2952) | Total Time 0.00(0.00)\n",
      "Iter 1851 | Time 71.7581(73.8180) | Bit/dim 3.4970(3.5045) | Xent 0.0000(0.0000) | Loss 8.3975(8.9847) | Error 0.0000(0.0000) Steps 670(666.25) | Grad Norm 0.1813(0.2918) | Total Time 0.00(0.00)\n",
      "Iter 1852 | Time 80.2815(74.0119) | Bit/dim 3.4959(3.5042) | Xent 0.0000(0.0000) | Loss 8.5548(8.9718) | Error 0.0000(0.0000) Steps 712(667.62) | Grad Norm 0.3070(0.2922) | Total Time 0.00(0.00)\n",
      "Iter 1853 | Time 68.3493(73.8421) | Bit/dim 3.4989(3.5041) | Xent 0.0000(0.0000) | Loss 8.2197(8.9492) | Error 0.0000(0.0000) Steps 658(667.33) | Grad Norm 0.2764(0.2918) | Total Time 0.00(0.00)\n",
      "Iter 1854 | Time 79.0101(73.9971) | Bit/dim 3.5088(3.5042) | Xent 0.0000(0.0000) | Loss 8.5157(8.9362) | Error 0.0000(0.0000) Steps 688(667.95) | Grad Norm 0.1827(0.2885) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0309 | Time 23.8782, Epoch Time 483.5932(471.4717), Bit/dim 3.5045(best: 3.5002), Xent 0.0000, Loss 3.5045, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1855 | Time 76.3898(74.0689) | Bit/dim 3.5023(3.5041) | Xent 0.0000(0.0000) | Loss 12.0631(9.0300) | Error 0.0000(0.0000) Steps 670(668.02) | Grad Norm 0.2579(0.2876) | Total Time 0.00(0.00)\n",
      "Iter 1856 | Time 72.9112(74.0342) | Bit/dim 3.5008(3.5040) | Xent 0.0000(0.0000) | Loss 8.2539(9.0067) | Error 0.0000(0.0000) Steps 664(667.89) | Grad Norm 0.2360(0.2860) | Total Time 0.00(0.00)\n",
      "Iter 1857 | Time 70.9179(73.9407) | Bit/dim 3.5008(3.5040) | Xent 0.0000(0.0000) | Loss 8.4301(8.9894) | Error 0.0000(0.0000) Steps 670(667.96) | Grad Norm 0.2610(0.2853) | Total Time 0.00(0.00)\n",
      "Iter 1858 | Time 72.8217(73.9071) | Bit/dim 3.5051(3.5040) | Xent 0.0000(0.0000) | Loss 8.3786(8.9711) | Error 0.0000(0.0000) Steps 658(667.66) | Grad Norm 0.2588(0.2845) | Total Time 0.00(0.00)\n",
      "Iter 1859 | Time 72.3230(73.8596) | Bit/dim 3.4933(3.5037) | Xent 0.0000(0.0000) | Loss 8.2762(8.9502) | Error 0.0000(0.0000) Steps 646(667.01) | Grad Norm 0.1843(0.2815) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 78.4668(73.9978) | Bit/dim 3.5121(3.5039) | Xent 0.0000(0.0000) | Loss 8.5009(8.9368) | Error 0.0000(0.0000) Steps 664(666.92) | Grad Norm 0.1877(0.2787) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0310 | Time 23.8720, Epoch Time 483.7574(471.8403), Bit/dim 3.5012(best: 3.5002), Xent 0.0000, Loss 3.5012, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1861 | Time 69.4555(73.8615) | Bit/dim 3.5003(3.5038) | Xent 0.0000(0.0000) | Loss 11.9563(9.0273) | Error 0.0000(0.0000) Steps 652(666.47) | Grad Norm 0.3682(0.2813) | Total Time 0.00(0.00)\n",
      "Iter 1862 | Time 71.7615(73.7985) | Bit/dim 3.5044(3.5038) | Xent 0.0000(0.0000) | Loss 8.3586(9.0073) | Error 0.0000(0.0000) Steps 676(666.76) | Grad Norm 0.2156(0.2794) | Total Time 0.00(0.00)\n",
      "Iter 1863 | Time 70.6529(73.7042) | Bit/dim 3.5194(3.5043) | Xent 0.0000(0.0000) | Loss 8.4066(8.9893) | Error 0.0000(0.0000) Steps 658(666.49) | Grad Norm 0.2541(0.2786) | Total Time 0.00(0.00)\n",
      "Iter 1864 | Time 72.8662(73.6790) | Bit/dim 3.4919(3.5039) | Xent 0.0000(0.0000) | Loss 8.4285(8.9724) | Error 0.0000(0.0000) Steps 676(666.78) | Grad Norm 0.2604(0.2781) | Total Time 0.00(0.00)\n",
      "Iter 1865 | Time 74.8704(73.7148) | Bit/dim 3.4997(3.5038) | Xent 0.0000(0.0000) | Loss 8.3326(8.9532) | Error 0.0000(0.0000) Steps 670(666.88) | Grad Norm 0.2951(0.2786) | Total Time 0.00(0.00)\n",
      "Iter 1866 | Time 70.7001(73.6243) | Bit/dim 3.4993(3.5037) | Xent 0.0000(0.0000) | Loss 8.4129(8.9370) | Error 0.0000(0.0000) Steps 664(666.79) | Grad Norm 0.2473(0.2776) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0311 | Time 24.0774, Epoch Time 470.4626(471.7989), Bit/dim 3.5082(best: 3.5002), Xent 0.0000, Loss 3.5082, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1867 | Time 73.1596(73.6104) | Bit/dim 3.5038(3.5037) | Xent 0.0000(0.0000) | Loss 11.8937(9.0257) | Error 0.0000(0.0000) Steps 646(666.17) | Grad Norm 0.2939(0.2781) | Total Time 0.00(0.00)\n",
      "Iter 1868 | Time 76.7202(73.7037) | Bit/dim 3.5048(3.5037) | Xent 0.0000(0.0000) | Loss 8.3697(9.0061) | Error 0.0000(0.0000) Steps 658(665.92) | Grad Norm 0.2163(0.2763) | Total Time 0.00(0.00)\n",
      "Iter 1869 | Time 72.3268(73.6624) | Bit/dim 3.5081(3.5038) | Xent 0.0000(0.0000) | Loss 8.4050(8.9880) | Error 0.0000(0.0000) Steps 646(665.32) | Grad Norm 0.2440(0.2753) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 74.1572(73.6772) | Bit/dim 3.5000(3.5037) | Xent 0.0000(0.0000) | Loss 8.4058(8.9706) | Error 0.0000(0.0000) Steps 664(665.28) | Grad Norm 0.2165(0.2735) | Total Time 0.00(0.00)\n",
      "Iter 1871 | Time 72.5170(73.6424) | Bit/dim 3.5133(3.5040) | Xent 0.0000(0.0000) | Loss 8.0328(8.9424) | Error 0.0000(0.0000) Steps 664(665.25) | Grad Norm 0.4002(0.2773) | Total Time 0.00(0.00)\n",
      "Iter 1872 | Time 72.0733(73.5953) | Bit/dim 3.4933(3.5037) | Xent 0.0000(0.0000) | Loss 8.2553(8.9218) | Error 0.0000(0.0000) Steps 670(665.39) | Grad Norm 0.2106(0.2753) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0312 | Time 24.0947, Epoch Time 481.0887(472.0776), Bit/dim 3.5022(best: 3.5002), Xent 0.0000, Loss 3.5022, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1873 | Time 71.4960(73.5324) | Bit/dim 3.4879(3.5032) | Xent 0.0000(0.0000) | Loss 11.6648(9.0041) | Error 0.0000(0.0000) Steps 652(664.99) | Grad Norm 0.3351(0.2771) | Total Time 0.00(0.00)\n",
      "Iter 1874 | Time 74.5835(73.5639) | Bit/dim 3.5161(3.5036) | Xent 0.0000(0.0000) | Loss 8.4299(8.9869) | Error 0.0000(0.0000) Steps 688(665.68) | Grad Norm 0.2039(0.2749) | Total Time 0.00(0.00)\n",
      "Iter 1875 | Time 78.7886(73.7206) | Bit/dim 3.5085(3.5037) | Xent 0.0000(0.0000) | Loss 8.4317(8.9702) | Error 0.0000(0.0000) Steps 676(665.99) | Grad Norm 0.2130(0.2731) | Total Time 0.00(0.00)\n",
      "Iter 1876 | Time 70.1115(73.6124) | Bit/dim 3.4960(3.5035) | Xent 0.0000(0.0000) | Loss 8.4472(8.9545) | Error 0.0000(0.0000) Steps 664(665.93) | Grad Norm 0.2174(0.2714) | Total Time 0.00(0.00)\n",
      "Iter 1877 | Time 72.4883(73.5786) | Bit/dim 3.5020(3.5035) | Xent 0.0000(0.0000) | Loss 8.2021(8.9320) | Error 0.0000(0.0000) Steps 670(666.05) | Grad Norm 0.2193(0.2698) | Total Time 0.00(0.00)\n",
      "Iter 1878 | Time 72.9763(73.5606) | Bit/dim 3.4992(3.5033) | Xent 0.0000(0.0000) | Loss 8.4780(8.9183) | Error 0.0000(0.0000) Steps 670(666.17) | Grad Norm 0.1918(0.2675) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0313 | Time 24.0008, Epoch Time 480.7452(472.3377), Bit/dim 3.5056(best: 3.5002), Xent 0.0000, Loss 3.5056, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1879 | Time 77.1075(73.6670) | Bit/dim 3.5052(3.5034) | Xent 0.0000(0.0000) | Loss 11.9553(9.0094) | Error 0.0000(0.0000) Steps 658(665.92) | Grad Norm 0.3538(0.2701) | Total Time 0.00(0.00)\n",
      "Iter 1880 | Time 72.8632(73.6429) | Bit/dim 3.5056(3.5035) | Xent 0.0000(0.0000) | Loss 8.2315(8.9861) | Error 0.0000(0.0000) Steps 670(666.05) | Grad Norm 0.2567(0.2697) | Total Time 0.00(0.00)\n",
      "Iter 1881 | Time 70.7539(73.5562) | Bit/dim 3.4990(3.5033) | Xent 0.0000(0.0000) | Loss 8.3950(8.9684) | Error 0.0000(0.0000) Steps 652(665.62) | Grad Norm 0.2209(0.2682) | Total Time 0.00(0.00)\n",
      "Iter 1882 | Time 79.7112(73.7408) | Bit/dim 3.5133(3.5036) | Xent 0.0000(0.0000) | Loss 8.5391(8.9555) | Error 0.0000(0.0000) Steps 688(666.30) | Grad Norm 0.2364(0.2673) | Total Time 0.00(0.00)\n",
      "Iter 1883 | Time 80.8627(73.9545) | Bit/dim 3.4930(3.5033) | Xent 0.0000(0.0000) | Loss 8.4196(8.9394) | Error 0.0000(0.0000) Steps 682(666.77) | Grad Norm 0.2222(0.2659) | Total Time 0.00(0.00)\n",
      "Iter 1884 | Time 72.5577(73.9126) | Bit/dim 3.4912(3.5029) | Xent 0.0000(0.0000) | Loss 8.4183(8.9238) | Error 0.0000(0.0000) Steps 670(666.86) | Grad Norm 0.2726(0.2661) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0314 | Time 24.0186, Epoch Time 493.8052(472.9817), Bit/dim 3.5054(best: 3.5002), Xent 0.0000, Loss 3.5054, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1885 | Time 70.1987(73.8012) | Bit/dim 3.5057(3.5030) | Xent 0.0000(0.0000) | Loss 12.1413(9.0203) | Error 0.0000(0.0000) Steps 664(666.78) | Grad Norm 0.3019(0.2672) | Total Time 0.00(0.00)\n",
      "Iter 1886 | Time 74.5852(73.8247) | Bit/dim 3.4990(3.5029) | Xent 0.0000(0.0000) | Loss 8.4747(9.0039) | Error 0.0000(0.0000) Steps 664(666.69) | Grad Norm 0.2398(0.2664) | Total Time 0.00(0.00)\n",
      "Iter 1887 | Time 69.1653(73.6849) | Bit/dim 3.5152(3.5033) | Xent 0.0000(0.0000) | Loss 8.1587(8.9786) | Error 0.0000(0.0000) Steps 646(666.07) | Grad Norm 0.2597(0.2662) | Total Time 0.00(0.00)\n",
      "Iter 1888 | Time 79.7514(73.8669) | Bit/dim 3.4989(3.5031) | Xent 0.0000(0.0000) | Loss 8.4537(8.9628) | Error 0.0000(0.0000) Steps 694(666.91) | Grad Norm 0.2284(0.2650) | Total Time 0.00(0.00)\n",
      "Iter 1889 | Time 72.0064(73.8111) | Bit/dim 3.5034(3.5032) | Xent 0.0000(0.0000) | Loss 8.3278(8.9438) | Error 0.0000(0.0000) Steps 664(666.82) | Grad Norm 0.2312(0.2640) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 67.9732(73.6360) | Bit/dim 3.5168(3.5036) | Xent 0.0000(0.0000) | Loss 8.1142(8.9189) | Error 0.0000(0.0000) Steps 652(666.38) | Grad Norm 0.3575(0.2668) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0315 | Time 23.3964, Epoch Time 472.9403(472.9804), Bit/dim 3.5049(best: 3.5002), Xent 0.0000, Loss 3.5049, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1891 | Time 72.1397(73.5911) | Bit/dim 3.5121(3.5038) | Xent 0.0000(0.0000) | Loss 12.0693(9.0134) | Error 0.0000(0.0000) Steps 640(665.59) | Grad Norm 0.2418(0.2661) | Total Time 0.00(0.00)\n",
      "Iter 1892 | Time 69.2463(73.4607) | Bit/dim 3.5007(3.5037) | Xent 0.0000(0.0000) | Loss 8.1195(8.9866) | Error 0.0000(0.0000) Steps 652(665.18) | Grad Norm 0.4420(0.2714) | Total Time 0.00(0.00)\n",
      "Iter 1893 | Time 77.0394(73.5681) | Bit/dim 3.5029(3.5037) | Xent 0.0000(0.0000) | Loss 8.4406(8.9702) | Error 0.0000(0.0000) Steps 658(664.96) | Grad Norm 0.2673(0.2712) | Total Time 0.00(0.00)\n",
      "Iter 1894 | Time 72.8352(73.5461) | Bit/dim 3.4982(3.5035) | Xent 0.0000(0.0000) | Loss 8.4256(8.9539) | Error 0.0000(0.0000) Steps 670(665.12) | Grad Norm 0.3077(0.2723) | Total Time 0.00(0.00)\n",
      "Iter 1895 | Time 73.5852(73.5473) | Bit/dim 3.5001(3.5034) | Xent 0.0000(0.0000) | Loss 8.3821(8.9367) | Error 0.0000(0.0000) Steps 670(665.26) | Grad Norm 0.3423(0.2744) | Total Time 0.00(0.00)\n",
      "Iter 1896 | Time 72.3307(73.5108) | Bit/dim 3.4986(3.5033) | Xent 0.0000(0.0000) | Loss 8.4950(8.9235) | Error 0.0000(0.0000) Steps 676(665.58) | Grad Norm 0.2763(0.2745) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0316 | Time 23.8290, Epoch Time 476.9172(473.0985), Bit/dim 3.5069(best: 3.5002), Xent 0.0000, Loss 3.5069, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1897 | Time 74.3013(73.5345) | Bit/dim 3.5041(3.5033) | Xent 0.0000(0.0000) | Loss 11.9300(9.0137) | Error 0.0000(0.0000) Steps 682(666.08) | Grad Norm 0.3703(0.2774) | Total Time 0.00(0.00)\n",
      "Iter 1898 | Time 75.9748(73.6077) | Bit/dim 3.4794(3.5026) | Xent 0.0000(0.0000) | Loss 8.4456(8.9966) | Error 0.0000(0.0000) Steps 670(666.19) | Grad Norm 0.2363(0.2761) | Total Time 0.00(0.00)\n",
      "Iter 1899 | Time 69.6567(73.4892) | Bit/dim 3.5075(3.5027) | Xent 0.0000(0.0000) | Loss 8.5191(8.9823) | Error 0.0000(0.0000) Steps 682(666.67) | Grad Norm 0.2647(0.2758) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 76.8235(73.5892) | Bit/dim 3.5116(3.5030) | Xent 0.0000(0.0000) | Loss 8.3702(8.9639) | Error 0.0000(0.0000) Steps 670(666.77) | Grad Norm 0.1971(0.2734) | Total Time 0.00(0.00)\n",
      "Iter 1901 | Time 73.9315(73.5995) | Bit/dim 3.5043(3.5030) | Xent 0.0000(0.0000) | Loss 8.4261(8.9478) | Error 0.0000(0.0000) Steps 676(667.05) | Grad Norm 0.1811(0.2707) | Total Time 0.00(0.00)\n",
      "Iter 1902 | Time 71.4241(73.5342) | Bit/dim 3.4990(3.5029) | Xent 0.0000(0.0000) | Loss 8.4457(8.9327) | Error 0.0000(0.0000) Steps 676(667.31) | Grad Norm 0.2247(0.2693) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0317 | Time 23.6859, Epoch Time 481.8525(473.3612), Bit/dim 3.5068(best: 3.5002), Xent 0.0000, Loss 3.5068, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1903 | Time 69.5632(73.4151) | Bit/dim 3.4819(3.5023) | Xent 0.0000(0.0000) | Loss 11.8496(9.0202) | Error 0.0000(0.0000) Steps 640(666.49) | Grad Norm 0.2372(0.2683) | Total Time 0.00(0.00)\n",
      "Iter 1904 | Time 71.7576(73.3654) | Bit/dim 3.5131(3.5026) | Xent 0.0000(0.0000) | Loss 8.3806(9.0011) | Error 0.0000(0.0000) Steps 646(665.88) | Grad Norm 0.2552(0.2679) | Total Time 0.00(0.00)\n",
      "Iter 1905 | Time 64.8754(73.1107) | Bit/dim 3.5044(3.5027) | Xent 0.0000(0.0000) | Loss 8.0683(8.9731) | Error 0.0000(0.0000) Steps 640(665.10) | Grad Norm 0.4211(0.2725) | Total Time 0.00(0.00)\n",
      "Iter 1906 | Time 76.1270(73.2011) | Bit/dim 3.4946(3.5024) | Xent 0.0000(0.0000) | Loss 8.4469(8.9573) | Error 0.0000(0.0000) Steps 676(665.43) | Grad Norm 0.2645(0.2723) | Total Time 0.00(0.00)\n",
      "Iter 1907 | Time 69.7054(73.0963) | Bit/dim 3.5003(3.5024) | Xent 0.0000(0.0000) | Loss 8.1403(8.9328) | Error 0.0000(0.0000) Steps 634(664.49) | Grad Norm 0.4084(0.2764) | Total Time 0.00(0.00)\n",
      "Iter 1908 | Time 75.5342(73.1694) | Bit/dim 3.5182(3.5028) | Xent 0.0000(0.0000) | Loss 8.2524(8.9124) | Error 0.0000(0.0000) Steps 646(663.93) | Grad Norm 0.2948(0.2769) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0318 | Time 24.1366, Epoch Time 467.6159(473.1888), Bit/dim 3.5094(best: 3.5002), Xent 0.0000, Loss 3.5094, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1909 | Time 69.5952(73.0622) | Bit/dim 3.4976(3.5027) | Xent 0.0000(0.0000) | Loss 11.9762(9.0043) | Error 0.0000(0.0000) Steps 658(663.75) | Grad Norm 0.2887(0.2773) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 75.8840(73.1468) | Bit/dim 3.4998(3.5026) | Xent 0.0000(0.0000) | Loss 8.4647(8.9881) | Error 0.0000(0.0000) Steps 664(663.76) | Grad Norm 0.2335(0.2760) | Total Time 0.00(0.00)\n",
      "Iter 1911 | Time 83.4094(73.4547) | Bit/dim 3.5063(3.5027) | Xent 0.0000(0.0000) | Loss 8.4641(8.9724) | Error 0.0000(0.0000) Steps 688(664.49) | Grad Norm 0.2379(0.2748) | Total Time 0.00(0.00)\n",
      "Iter 1912 | Time 77.7903(73.5848) | Bit/dim 3.4989(3.5026) | Xent 0.0000(0.0000) | Loss 8.3452(8.9536) | Error 0.0000(0.0000) Steps 670(664.65) | Grad Norm 0.2834(0.2751) | Total Time 0.00(0.00)\n",
      "Iter 1913 | Time 73.3744(73.5785) | Bit/dim 3.5070(3.5027) | Xent 0.0000(0.0000) | Loss 8.3200(8.9346) | Error 0.0000(0.0000) Steps 676(665.00) | Grad Norm 0.3627(0.2777) | Total Time 0.00(0.00)\n",
      "Iter 1914 | Time 73.3495(73.5716) | Bit/dim 3.4994(3.5026) | Xent 0.0000(0.0000) | Loss 8.5081(8.9218) | Error 0.0000(0.0000) Steps 658(664.79) | Grad Norm 0.2260(0.2761) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0319 | Time 24.4808, Epoch Time 493.4816(473.7976), Bit/dim 3.5049(best: 3.5002), Xent 0.0000, Loss 3.5049, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1915 | Time 69.9995(73.4644) | Bit/dim 3.5055(3.5027) | Xent 0.0000(0.0000) | Loss 11.6503(9.0036) | Error 0.0000(0.0000) Steps 652(664.40) | Grad Norm 0.6252(0.2866) | Total Time 0.00(0.00)\n",
      "Iter 1916 | Time 77.1123(73.5739) | Bit/dim 3.4944(3.5025) | Xent 0.0000(0.0000) | Loss 8.2705(8.9816) | Error 0.0000(0.0000) Steps 670(664.57) | Grad Norm 0.2792(0.2864) | Total Time 0.00(0.00)\n",
      "Iter 1917 | Time 72.3557(73.5373) | Bit/dim 3.4981(3.5023) | Xent 0.0000(0.0000) | Loss 8.0977(8.9551) | Error 0.0000(0.0000) Steps 652(664.19) | Grad Norm 0.3055(0.2870) | Total Time 0.00(0.00)\n",
      "Iter 1918 | Time 73.0817(73.5237) | Bit/dim 3.5100(3.5026) | Xent 0.0000(0.0000) | Loss 8.3273(8.9363) | Error 0.0000(0.0000) Steps 682(664.73) | Grad Norm 0.3124(0.2877) | Total Time 0.00(0.00)\n",
      "Iter 1919 | Time 71.9462(73.4763) | Bit/dim 3.4956(3.5024) | Xent 0.0000(0.0000) | Loss 8.3051(8.9173) | Error 0.0000(0.0000) Steps 658(664.52) | Grad Norm 0.1953(0.2850) | Total Time 0.00(0.00)\n",
      "Iter 1920 | Time 72.6208(73.4507) | Bit/dim 3.5127(3.5027) | Xent 0.0000(0.0000) | Loss 8.3338(8.8998) | Error 0.0000(0.0000) Steps 658(664.33) | Grad Norm 0.2980(0.2854) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0320 | Time 23.9040, Epoch Time 476.6046(473.8818), Bit/dim 3.5056(best: 3.5002), Xent 0.0000, Loss 3.5056, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1921 | Time 69.9916(73.3469) | Bit/dim 3.4953(3.5024) | Xent 0.0000(0.0000) | Loss 12.1830(8.9983) | Error 0.0000(0.0000) Steps 664(664.32) | Grad Norm 0.2943(0.2856) | Total Time 0.00(0.00)\n",
      "Iter 1922 | Time 74.4721(73.3807) | Bit/dim 3.5074(3.5026) | Xent 0.0000(0.0000) | Loss 8.4221(8.9810) | Error 0.0000(0.0000) Steps 676(664.67) | Grad Norm 0.2478(0.2845) | Total Time 0.00(0.00)\n",
      "Iter 1923 | Time 71.7727(73.3324) | Bit/dim 3.5149(3.5030) | Xent 0.0000(0.0000) | Loss 8.4214(8.9642) | Error 0.0000(0.0000) Steps 664(664.65) | Grad Norm 0.2473(0.2834) | Total Time 0.00(0.00)\n",
      "Iter 1924 | Time 78.2570(73.4802) | Bit/dim 3.5030(3.5030) | Xent 0.0000(0.0000) | Loss 8.1775(8.9406) | Error 0.0000(0.0000) Steps 670(664.81) | Grad Norm 0.2296(0.2818) | Total Time 0.00(0.00)\n",
      "Iter 1925 | Time 72.6984(73.4567) | Bit/dim 3.5024(3.5029) | Xent 0.0000(0.0000) | Loss 8.4459(8.9258) | Error 0.0000(0.0000) Steps 682(665.33) | Grad Norm 0.3000(0.2823) | Total Time 0.00(0.00)\n",
      "Iter 1926 | Time 75.8191(73.5276) | Bit/dim 3.4932(3.5027) | Xent 0.0000(0.0000) | Loss 8.2508(8.9056) | Error 0.0000(0.0000) Steps 664(665.29) | Grad Norm 0.2229(0.2805) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0321 | Time 24.2434, Epoch Time 483.4184(474.1679), Bit/dim 3.5017(best: 3.5002), Xent 0.0000, Loss 3.5017, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1927 | Time 78.6574(73.6815) | Bit/dim 3.5057(3.5027) | Xent 0.0000(0.0000) | Loss 12.0256(8.9992) | Error 0.0000(0.0000) Steps 664(665.25) | Grad Norm 0.3516(0.2827) | Total Time 0.00(0.00)\n",
      "Iter 1928 | Time 72.7800(73.6544) | Bit/dim 3.5175(3.5032) | Xent 0.0000(0.0000) | Loss 8.2711(8.9773) | Error 0.0000(0.0000) Steps 652(664.85) | Grad Norm 0.2393(0.2814) | Total Time 0.00(0.00)\n",
      "Iter 1929 | Time 71.8632(73.6007) | Bit/dim 3.4895(3.5028) | Xent 0.0000(0.0000) | Loss 8.4037(8.9601) | Error 0.0000(0.0000) Steps 664(664.82) | Grad Norm 0.3178(0.2824) | Total Time 0.00(0.00)\n",
      "Iter 1930 | Time 78.5084(73.7479) | Bit/dim 3.5019(3.5027) | Xent 0.0000(0.0000) | Loss 8.3096(8.9406) | Error 0.0000(0.0000) Steps 652(664.44) | Grad Norm 0.2323(0.2809) | Total Time 0.00(0.00)\n",
      "Iter 1931 | Time 74.4129(73.7679) | Bit/dim 3.5062(3.5029) | Xent 0.0000(0.0000) | Loss 8.3283(8.9222) | Error 0.0000(0.0000) Steps 664(664.43) | Grad Norm 0.3142(0.2819) | Total Time 0.00(0.00)\n",
      "Iter 1932 | Time 75.4744(73.8191) | Bit/dim 3.4913(3.5025) | Xent 0.0000(0.0000) | Loss 8.3830(8.9060) | Error 0.0000(0.0000) Steps 664(664.41) | Grad Norm 0.2822(0.2819) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0322 | Time 23.9582, Epoch Time 491.6015(474.6909), Bit/dim 3.5006(best: 3.5002), Xent 0.0000, Loss 3.5006, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1933 | Time 73.7522(73.8171) | Bit/dim 3.4990(3.5024) | Xent 0.0000(0.0000) | Loss 11.6746(8.9891) | Error 0.0000(0.0000) Steps 658(664.22) | Grad Norm 0.3573(0.2842) | Total Time 0.00(0.00)\n",
      "Iter 1934 | Time 75.1185(73.8561) | Bit/dim 3.5104(3.5026) | Xent 0.0000(0.0000) | Loss 8.2302(8.9663) | Error 0.0000(0.0000) Steps 664(664.21) | Grad Norm 0.3245(0.2854) | Total Time 0.00(0.00)\n",
      "Iter 1935 | Time 78.4756(73.9947) | Bit/dim 3.4930(3.5024) | Xent 0.0000(0.0000) | Loss 8.3325(8.9473) | Error 0.0000(0.0000) Steps 676(664.57) | Grad Norm 0.2888(0.2855) | Total Time 0.00(0.00)\n",
      "Iter 1936 | Time 74.1839(74.0004) | Bit/dim 3.5081(3.5025) | Xent 0.0000(0.0000) | Loss 8.3509(8.9294) | Error 0.0000(0.0000) Steps 676(664.91) | Grad Norm 0.3166(0.2864) | Total Time 0.00(0.00)\n",
      "Iter 1937 | Time 70.2087(73.8866) | Bit/dim 3.5013(3.5025) | Xent 0.0000(0.0000) | Loss 8.3631(8.9124) | Error 0.0000(0.0000) Steps 676(665.24) | Grad Norm 0.2835(0.2864) | Total Time 0.00(0.00)\n",
      "Iter 1938 | Time 77.3845(73.9916) | Bit/dim 3.4942(3.5022) | Xent 0.0000(0.0000) | Loss 8.3926(8.8968) | Error 0.0000(0.0000) Steps 670(665.39) | Grad Norm 0.2712(0.2859) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0323 | Time 24.5674, Epoch Time 489.5451(475.1365), Bit/dim 3.5048(best: 3.5002), Xent 0.0000, Loss 3.5048, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1939 | Time 74.2132(73.9982) | Bit/dim 3.5086(3.5024) | Xent 0.0000(0.0000) | Loss 12.2185(8.9965) | Error 0.0000(0.0000) Steps 676(665.71) | Grad Norm 0.4002(0.2893) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 79.0639(74.1502) | Bit/dim 3.5000(3.5024) | Xent 0.0000(0.0000) | Loss 8.2826(8.9751) | Error 0.0000(0.0000) Steps 676(666.01) | Grad Norm 0.3282(0.2905) | Total Time 0.00(0.00)\n",
      "Iter 1941 | Time 74.5695(74.1628) | Bit/dim 3.4984(3.5022) | Xent 0.0000(0.0000) | Loss 8.4156(8.9583) | Error 0.0000(0.0000) Steps 676(666.31) | Grad Norm 0.3453(0.2921) | Total Time 0.00(0.00)\n",
      "Iter 1942 | Time 75.5852(74.2054) | Bit/dim 3.5053(3.5023) | Xent 0.0000(0.0000) | Loss 8.4554(8.9432) | Error 0.0000(0.0000) Steps 682(666.78) | Grad Norm 0.3289(0.2932) | Total Time 0.00(0.00)\n",
      "Iter 1943 | Time 71.9256(74.1370) | Bit/dim 3.5048(3.5024) | Xent 0.0000(0.0000) | Loss 8.2274(8.9217) | Error 0.0000(0.0000) Steps 646(666.16) | Grad Norm 0.3092(0.2937) | Total Time 0.00(0.00)\n",
      "Iter 1944 | Time 71.0796(74.0453) | Bit/dim 3.5016(3.5024) | Xent 0.0000(0.0000) | Loss 8.2341(8.9011) | Error 0.0000(0.0000) Steps 646(665.56) | Grad Norm 0.2764(0.2932) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0324 | Time 24.4502, Epoch Time 487.0074(475.4927), Bit/dim 3.5031(best: 3.5002), Xent 0.0000, Loss 3.5031, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1945 | Time 78.2385(74.1711) | Bit/dim 3.5053(3.5025) | Xent 0.0000(0.0000) | Loss 12.3575(9.0048) | Error 0.0000(0.0000) Steps 694(666.41) | Grad Norm 0.2789(0.2928) | Total Time 0.00(0.00)\n",
      "Iter 1946 | Time 70.4109(74.0583) | Bit/dim 3.5035(3.5025) | Xent 0.0000(0.0000) | Loss 8.2082(8.9809) | Error 0.0000(0.0000) Steps 676(666.70) | Grad Norm 0.4034(0.2961) | Total Time 0.00(0.00)\n",
      "Iter 1947 | Time 79.6192(74.2251) | Bit/dim 3.4912(3.5022) | Xent 0.0000(0.0000) | Loss 8.4287(8.9643) | Error 0.0000(0.0000) Steps 670(666.80) | Grad Norm 0.2614(0.2950) | Total Time 0.00(0.00)\n",
      "Iter 1948 | Time 72.7237(74.1801) | Bit/dim 3.5026(3.5022) | Xent 0.0000(0.0000) | Loss 8.4900(8.9501) | Error 0.0000(0.0000) Steps 676(667.07) | Grad Norm 0.3150(0.2956) | Total Time 0.00(0.00)\n",
      "Iter 1949 | Time 72.7451(74.1370) | Bit/dim 3.5115(3.5025) | Xent 0.0000(0.0000) | Loss 8.2444(8.9289) | Error 0.0000(0.0000) Steps 646(666.44) | Grad Norm 0.2754(0.2950) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 78.3023(74.2620) | Bit/dim 3.4906(3.5021) | Xent 0.0000(0.0000) | Loss 8.3607(8.9119) | Error 0.0000(0.0000) Steps 676(666.73) | Grad Norm 0.3245(0.2959) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0325 | Time 23.6990, Epoch Time 491.3994(475.9699), Bit/dim 3.5039(best: 3.5002), Xent 0.0000, Loss 3.5039, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1951 | Time 76.1485(74.3186) | Bit/dim 3.4972(3.5020) | Xent 0.0000(0.0000) | Loss 12.1114(9.0079) | Error 0.0000(0.0000) Steps 682(667.18) | Grad Norm 0.2731(0.2952) | Total Time 0.00(0.00)\n",
      "Iter 1952 | Time 76.0390(74.3702) | Bit/dim 3.5009(3.5019) | Xent 0.0000(0.0000) | Loss 8.1110(8.9810) | Error 0.0000(0.0000) Steps 646(666.55) | Grad Norm 0.2948(0.2952) | Total Time 0.00(0.00)\n",
      "Iter 1953 | Time 80.2977(74.5480) | Bit/dim 3.4834(3.5014) | Xent 0.0000(0.0000) | Loss 8.3671(8.9625) | Error 0.0000(0.0000) Steps 664(666.47) | Grad Norm 0.2787(0.2947) | Total Time 0.00(0.00)\n",
      "Iter 1954 | Time 70.8863(74.4382) | Bit/dim 3.4989(3.5013) | Xent 0.0000(0.0000) | Loss 8.2042(8.9398) | Error 0.0000(0.0000) Steps 646(665.86) | Grad Norm 0.2052(0.2920) | Total Time 0.00(0.00)\n",
      "Iter 1955 | Time 77.0598(74.5168) | Bit/dim 3.5095(3.5015) | Xent 0.0000(0.0000) | Loss 8.4976(8.9265) | Error 0.0000(0.0000) Steps 682(666.34) | Grad Norm 0.2762(0.2916) | Total Time 0.00(0.00)\n",
      "Iter 1956 | Time 75.1356(74.5354) | Bit/dim 3.4992(3.5015) | Xent 0.0000(0.0000) | Loss 8.2470(8.9061) | Error 0.0000(0.0000) Steps 640(665.55) | Grad Norm 0.3865(0.2944) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0326 | Time 24.1715, Epoch Time 495.5289(476.5566), Bit/dim 3.5019(best: 3.5002), Xent 0.0000, Loss 3.5019, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1957 | Time 77.9512(74.6379) | Bit/dim 3.4989(3.5014) | Xent 0.0000(0.0000) | Loss 11.9545(8.9976) | Error 0.0000(0.0000) Steps 640(664.79) | Grad Norm 0.3132(0.2950) | Total Time 0.00(0.00)\n",
      "Iter 1958 | Time 78.7039(74.7598) | Bit/dim 3.5003(3.5014) | Xent 0.0000(0.0000) | Loss 8.3659(8.9786) | Error 0.0000(0.0000) Steps 694(665.66) | Grad Norm 0.2918(0.2949) | Total Time 0.00(0.00)\n",
      "Iter 1959 | Time 77.9972(74.8570) | Bit/dim 3.4965(3.5012) | Xent 0.0000(0.0000) | Loss 8.4363(8.9624) | Error 0.0000(0.0000) Steps 694(666.51) | Grad Norm 0.2378(0.2932) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 75.7688(74.8843) | Bit/dim 3.5009(3.5012) | Xent 0.0000(0.0000) | Loss 8.3874(8.9451) | Error 0.0000(0.0000) Steps 676(666.80) | Grad Norm 0.2781(0.2927) | Total Time 0.00(0.00)\n",
      "Iter 1961 | Time 74.3015(74.8668) | Bit/dim 3.4998(3.5012) | Xent 0.0000(0.0000) | Loss 8.3323(8.9267) | Error 0.0000(0.0000) Steps 652(666.35) | Grad Norm 0.2238(0.2907) | Total Time 0.00(0.00)\n",
      "Iter 1962 | Time 69.0606(74.6926) | Bit/dim 3.5006(3.5011) | Xent 0.0000(0.0000) | Loss 8.3637(8.9098) | Error 0.0000(0.0000) Steps 658(666.10) | Grad Norm 0.2656(0.2899) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0327 | Time 23.4804, Epoch Time 493.5193(477.0655), Bit/dim 3.5054(best: 3.5002), Xent 0.0000, Loss 3.5054, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1963 | Time 74.6692(74.6919) | Bit/dim 3.5020(3.5012) | Xent 0.0000(0.0000) | Loss 12.0737(9.0048) | Error 0.0000(0.0000) Steps 682(666.58) | Grad Norm 0.3012(0.2902) | Total Time 0.00(0.00)\n",
      "Iter 1964 | Time 73.5986(74.6591) | Bit/dim 3.4936(3.5009) | Xent 0.0000(0.0000) | Loss 8.2163(8.9811) | Error 0.0000(0.0000) Steps 688(667.22) | Grad Norm 0.2394(0.2887) | Total Time 0.00(0.00)\n",
      "Iter 1965 | Time 75.2454(74.6767) | Bit/dim 3.5127(3.5013) | Xent 0.0000(0.0000) | Loss 8.5193(8.9672) | Error 0.0000(0.0000) Steps 664(667.13) | Grad Norm 0.3466(0.2904) | Total Time 0.00(0.00)\n",
      "Iter 1966 | Time 75.5719(74.7036) | Bit/dim 3.5039(3.5014) | Xent 0.0000(0.0000) | Loss 8.3750(8.9495) | Error 0.0000(0.0000) Steps 676(667.39) | Grad Norm 0.2241(0.2885) | Total Time 0.00(0.00)\n",
      "Iter 1967 | Time 74.7695(74.7056) | Bit/dim 3.5056(3.5015) | Xent 0.0000(0.0000) | Loss 8.3679(8.9320) | Error 0.0000(0.0000) Steps 664(667.29) | Grad Norm 0.2860(0.2884) | Total Time 0.00(0.00)\n",
      "Iter 1968 | Time 75.8864(74.7410) | Bit/dim 3.4925(3.5012) | Xent 0.0000(0.0000) | Loss 8.2328(8.9111) | Error 0.0000(0.0000) Steps 682(667.73) | Grad Norm 0.2739(0.2880) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0328 | Time 23.7182, Epoch Time 489.4632(477.4374), Bit/dim 3.5033(best: 3.5002), Xent 0.0000, Loss 3.5033, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1969 | Time 74.8276(74.7436) | Bit/dim 3.5070(3.5014) | Xent 0.0000(0.0000) | Loss 11.9271(9.0015) | Error 0.0000(0.0000) Steps 658(667.44) | Grad Norm 0.2829(0.2878) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 75.7836(74.7748) | Bit/dim 3.4972(3.5013) | Xent 0.0000(0.0000) | Loss 8.4590(8.9853) | Error 0.0000(0.0000) Steps 670(667.52) | Grad Norm 0.2644(0.2871) | Total Time 0.00(0.00)\n",
      "Iter 1971 | Time 70.0327(74.6325) | Bit/dim 3.4964(3.5011) | Xent 0.0000(0.0000) | Loss 8.4961(8.9706) | Error 0.0000(0.0000) Steps 640(666.69) | Grad Norm 0.2233(0.2852) | Total Time 0.00(0.00)\n",
      "Iter 1972 | Time 72.6163(74.5720) | Bit/dim 3.5009(3.5011) | Xent 0.0000(0.0000) | Loss 8.3634(8.9524) | Error 0.0000(0.0000) Steps 646(666.07) | Grad Norm 0.2883(0.2853) | Total Time 0.00(0.00)\n",
      "Iter 1973 | Time 71.0418(74.4661) | Bit/dim 3.4980(3.5010) | Xent 0.0000(0.0000) | Loss 8.0254(8.9246) | Error 0.0000(0.0000) Steps 670(666.19) | Grad Norm 0.4978(0.2917) | Total Time 0.00(0.00)\n",
      "Iter 1974 | Time 76.5633(74.5290) | Bit/dim 3.4994(3.5010) | Xent 0.0000(0.0000) | Loss 8.4632(8.9107) | Error 0.0000(0.0000) Steps 682(666.66) | Grad Norm 0.1984(0.2889) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0329 | Time 24.1500, Epoch Time 480.8146(477.5388), Bit/dim 3.5001(best: 3.5002), Xent 0.0000, Loss 3.5001, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1975 | Time 73.4482(74.4966) | Bit/dim 3.5035(3.5011) | Xent 0.0000(0.0000) | Loss 11.8400(8.9986) | Error 0.0000(0.0000) Steps 670(666.76) | Grad Norm 0.4155(0.2927) | Total Time 0.00(0.00)\n",
      "Iter 1976 | Time 75.1968(74.5176) | Bit/dim 3.4971(3.5009) | Xent 0.0000(0.0000) | Loss 8.3338(8.9787) | Error 0.0000(0.0000) Steps 664(666.68) | Grad Norm 0.3424(0.2941) | Total Time 0.00(0.00)\n",
      "Iter 1977 | Time 70.7916(74.4058) | Bit/dim 3.5102(3.5012) | Xent 0.0000(0.0000) | Loss 8.3561(8.9600) | Error 0.0000(0.0000) Steps 658(666.42) | Grad Norm 0.2723(0.2935) | Total Time 0.00(0.00)\n",
      "Iter 1978 | Time 74.5336(74.4097) | Bit/dim 3.5098(3.5015) | Xent 0.0000(0.0000) | Loss 8.3666(8.9422) | Error 0.0000(0.0000) Steps 670(666.53) | Grad Norm 0.3622(0.2956) | Total Time 0.00(0.00)\n",
      "Iter 1979 | Time 73.8218(74.3920) | Bit/dim 3.4908(3.5012) | Xent 0.0000(0.0000) | Loss 8.3096(8.9232) | Error 0.0000(0.0000) Steps 640(665.73) | Grad Norm 0.2628(0.2946) | Total Time 0.00(0.00)\n",
      "Iter 1980 | Time 78.7230(74.5220) | Bit/dim 3.4898(3.5008) | Xent 0.0000(0.0000) | Loss 8.4014(8.9075) | Error 0.0000(0.0000) Steps 676(666.04) | Grad Norm 0.3094(0.2950) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0330 | Time 24.1155, Epoch Time 486.5935(477.8104), Bit/dim 3.5031(best: 3.5001), Xent 0.0000, Loss 3.5031, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1981 | Time 74.1843(74.5118) | Bit/dim 3.5010(3.5008) | Xent 0.0000(0.0000) | Loss 11.9090(8.9976) | Error 0.0000(0.0000) Steps 658(665.80) | Grad Norm 0.4258(0.2989) | Total Time 0.00(0.00)\n",
      "Iter 1982 | Time 73.9830(74.4960) | Bit/dim 3.5105(3.5011) | Xent 0.0000(0.0000) | Loss 8.5121(8.9830) | Error 0.0000(0.0000) Steps 682(666.28) | Grad Norm 0.4278(0.3028) | Total Time 0.00(0.00)\n",
      "Iter 1983 | Time 78.6595(74.6209) | Bit/dim 3.5054(3.5012) | Xent 0.0000(0.0000) | Loss 8.4615(8.9674) | Error 0.0000(0.0000) Steps 676(666.58) | Grad Norm 0.3823(0.3052) | Total Time 0.00(0.00)\n",
      "Iter 1984 | Time 71.8469(74.5377) | Bit/dim 3.4947(3.5010) | Xent 0.0000(0.0000) | Loss 8.1690(8.9434) | Error 0.0000(0.0000) Steps 658(666.32) | Grad Norm 0.3822(0.3075) | Total Time 0.00(0.00)\n",
      "Iter 1985 | Time 68.5191(74.3571) | Bit/dim 3.4952(3.5009) | Xent 0.0000(0.0000) | Loss 8.0419(8.9164) | Error 0.0000(0.0000) Steps 640(665.53) | Grad Norm 0.4996(0.3133) | Total Time 0.00(0.00)\n",
      "Iter 1986 | Time 81.5507(74.5729) | Bit/dim 3.4860(3.5004) | Xent 0.0000(0.0000) | Loss 8.3452(8.8993) | Error 0.0000(0.0000) Steps 682(666.02) | Grad Norm 0.2376(0.3110) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0331 | Time 24.1326, Epoch Time 488.8250(478.1408), Bit/dim 3.4982(best: 3.5001), Xent 0.0000, Loss 3.4982, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1987 | Time 77.9823(74.6752) | Bit/dim 3.4991(3.5004) | Xent 0.0000(0.0000) | Loss 12.4263(9.0051) | Error 0.0000(0.0000) Steps 700(667.04) | Grad Norm 0.3876(0.3133) | Total Time 0.00(0.00)\n",
      "Iter 1988 | Time 75.6592(74.7047) | Bit/dim 3.4997(3.5004) | Xent 0.0000(0.0000) | Loss 8.2508(8.9824) | Error 0.0000(0.0000) Steps 676(667.31) | Grad Norm 0.2995(0.3129) | Total Time 0.00(0.00)\n",
      "Iter 1989 | Time 75.2823(74.7220) | Bit/dim 3.5042(3.5005) | Xent 0.0000(0.0000) | Loss 8.4889(8.9676) | Error 0.0000(0.0000) Steps 682(667.75) | Grad Norm 0.4173(0.3160) | Total Time 0.00(0.00)\n",
      "Iter 1990 | Time 77.0214(74.7910) | Bit/dim 3.5004(3.5005) | Xent 0.0000(0.0000) | Loss 8.0252(8.9394) | Error 0.0000(0.0000) Steps 658(667.46) | Grad Norm 0.4308(0.3195) | Total Time 0.00(0.00)\n",
      "Iter 1991 | Time 73.7673(74.7603) | Bit/dim 3.4888(3.5001) | Xent 0.0000(0.0000) | Loss 8.3915(8.9229) | Error 0.0000(0.0000) Steps 670(667.54) | Grad Norm 0.2918(0.3186) | Total Time 0.00(0.00)\n",
      "Iter 1992 | Time 76.6663(74.8175) | Bit/dim 3.5034(3.5002) | Xent 0.0000(0.0000) | Loss 8.5745(8.9125) | Error 0.0000(0.0000) Steps 682(667.97) | Grad Norm 0.3842(0.3206) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0332 | Time 23.3841, Epoch Time 495.6290(478.6655), Bit/dim 3.5029(best: 3.4982), Xent 0.0000, Loss 3.5029, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1993 | Time 71.3366(74.7131) | Bit/dim 3.5025(3.5003) | Xent 0.0000(0.0000) | Loss 11.9351(9.0031) | Error 0.0000(0.0000) Steps 682(668.39) | Grad Norm 0.3750(0.3222) | Total Time 0.00(0.00)\n",
      "Iter 1994 | Time 71.7184(74.6232) | Bit/dim 3.5039(3.5004) | Xent 0.0000(0.0000) | Loss 8.3613(8.9839) | Error 0.0000(0.0000) Steps 682(668.80) | Grad Norm 0.4389(0.3257) | Total Time 0.00(0.00)\n",
      "Iter 1995 | Time 68.8519(74.4501) | Bit/dim 3.4891(3.5001) | Xent 0.0000(0.0000) | Loss 8.1564(8.9591) | Error 0.0000(0.0000) Steps 652(668.29) | Grad Norm 0.4988(0.3309) | Total Time 0.00(0.00)\n",
      "Iter 1996 | Time 74.4998(74.4516) | Bit/dim 3.5122(3.5004) | Xent 0.0000(0.0000) | Loss 8.2671(8.9383) | Error 0.0000(0.0000) Steps 670(668.35) | Grad Norm 0.3433(0.3313) | Total Time 0.00(0.00)\n",
      "Iter 1997 | Time 74.6960(74.4589) | Bit/dim 3.4973(3.5003) | Xent 0.0000(0.0000) | Loss 8.2289(8.9170) | Error 0.0000(0.0000) Steps 676(668.58) | Grad Norm 0.4218(0.3340) | Total Time 0.00(0.00)\n",
      "Iter 1998 | Time 76.1793(74.5105) | Bit/dim 3.5006(3.5003) | Xent 0.0000(0.0000) | Loss 8.4785(8.9039) | Error 0.0000(0.0000) Steps 700(669.52) | Grad Norm 0.4187(0.3365) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 23.6316, Epoch Time 476.7047(478.6067), Bit/dim 3.5030(best: 3.4982), Xent 0.0000, Loss 3.5030, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1999 | Time 73.6520(74.4848) | Bit/dim 3.5207(3.5009) | Xent 0.0000(0.0000) | Loss 12.1885(9.0024) | Error 0.0000(0.0000) Steps 682(669.89) | Grad Norm 0.3254(0.3362) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 69.3046(74.3294) | Bit/dim 3.5152(3.5014) | Xent 0.0000(0.0000) | Loss 8.3827(8.9838) | Error 0.0000(0.0000) Steps 664(669.72) | Grad Norm 0.3270(0.3359) | Total Time 0.00(0.00)\n",
      "Iter 2001 | Time 78.0669(74.4415) | Bit/dim 3.5002(3.5013) | Xent 0.0000(0.0000) | Loss 8.4157(8.9668) | Error 0.0000(0.0000) Steps 676(669.90) | Grad Norm 0.4140(0.3383) | Total Time 0.00(0.00)\n",
      "Iter 2002 | Time 73.5808(74.4157) | Bit/dim 3.4982(3.5012) | Xent 0.0000(0.0000) | Loss 8.4410(8.9510) | Error 0.0000(0.0000) Steps 670(669.91) | Grad Norm 0.2052(0.3343) | Total Time 0.00(0.00)\n",
      "Iter 2003 | Time 73.8990(74.4002) | Bit/dim 3.4841(3.5007) | Xent 0.0000(0.0000) | Loss 8.4796(8.9369) | Error 0.0000(0.0000) Steps 688(670.45) | Grad Norm 0.2955(0.3331) | Total Time 0.00(0.00)\n",
      "Iter 2004 | Time 71.9054(74.3253) | Bit/dim 3.4914(3.5005) | Xent 0.0000(0.0000) | Loss 8.0293(8.9096) | Error 0.0000(0.0000) Steps 658(670.08) | Grad Norm 0.3753(0.3344) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 24.4400, Epoch Time 480.6553(478.6681), Bit/dim 3.5010(best: 3.4982), Xent 0.0000, Loss 3.5010, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2005 | Time 74.3514(74.3261) | Bit/dim 3.4997(3.5004) | Xent 0.0000(0.0000) | Loss 12.0920(9.0051) | Error 0.0000(0.0000) Steps 676(670.25) | Grad Norm 0.3067(0.3336) | Total Time 0.00(0.00)\n",
      "Iter 2006 | Time 76.3787(74.3877) | Bit/dim 3.4982(3.5004) | Xent 0.0000(0.0000) | Loss 8.1165(8.9784) | Error 0.0000(0.0000) Steps 682(670.61) | Grad Norm 0.3957(0.3354) | Total Time 0.00(0.00)\n",
      "Iter 2007 | Time 69.8224(74.2507) | Bit/dim 3.5075(3.5006) | Xent 0.0000(0.0000) | Loss 8.1442(8.9534) | Error 0.0000(0.0000) Steps 664(670.41) | Grad Norm 0.2939(0.3342) | Total Time 0.00(0.00)\n",
      "Iter 2008 | Time 71.2553(74.1609) | Bit/dim 3.5090(3.5008) | Xent 0.0000(0.0000) | Loss 8.3633(8.9357) | Error 0.0000(0.0000) Steps 664(670.22) | Grad Norm 0.2536(0.3318) | Total Time 0.00(0.00)\n",
      "Iter 2009 | Time 71.8153(74.0905) | Bit/dim 3.4854(3.5004) | Xent 0.0000(0.0000) | Loss 8.4862(8.9222) | Error 0.0000(0.0000) Steps 682(670.57) | Grad Norm 0.2328(0.3288) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 73.4380(74.0709) | Bit/dim 3.4954(3.5002) | Xent 0.0000(0.0000) | Loss 8.3158(8.9040) | Error 0.0000(0.0000) Steps 652(670.01) | Grad Norm 0.2656(0.3269) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 24.0511, Epoch Time 476.9033(478.6152), Bit/dim 3.5000(best: 3.4982), Xent 0.0000, Loss 3.5000, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2011 | Time 70.0458(73.9502) | Bit/dim 3.4988(3.5002) | Xent 0.0000(0.0000) | Loss 11.8489(8.9924) | Error 0.0000(0.0000) Steps 664(669.83) | Grad Norm 0.4739(0.3313) | Total Time 0.00(0.00)\n",
      "Iter 2012 | Time 76.3637(74.0226) | Bit/dim 3.5031(3.5003) | Xent 0.0000(0.0000) | Loss 8.4008(8.9746) | Error 0.0000(0.0000) Steps 676(670.02) | Grad Norm 0.3834(0.3329) | Total Time 0.00(0.00)\n",
      "Iter 2013 | Time 68.4609(73.8557) | Bit/dim 3.4957(3.5001) | Xent 0.0000(0.0000) | Loss 8.2633(8.9533) | Error 0.0000(0.0000) Steps 658(669.66) | Grad Norm 0.2886(0.3315) | Total Time 0.00(0.00)\n",
      "Iter 2014 | Time 70.1241(73.7438) | Bit/dim 3.4943(3.4999) | Xent 0.0000(0.0000) | Loss 8.3621(8.9356) | Error 0.0000(0.0000) Steps 658(669.31) | Grad Norm 0.4664(0.3356) | Total Time 0.00(0.00)\n",
      "Iter 2015 | Time 71.1990(73.6674) | Bit/dim 3.4946(3.4998) | Xent 0.0000(0.0000) | Loss 8.1878(8.9131) | Error 0.0000(0.0000) Steps 646(668.61) | Grad Norm 0.3510(0.3360) | Total Time 0.00(0.00)\n",
      "Iter 2016 | Time 79.4421(73.8407) | Bit/dim 3.5085(3.5000) | Xent 0.0000(0.0000) | Loss 8.3671(8.8967) | Error 0.0000(0.0000) Steps 688(669.19) | Grad Norm 0.3790(0.3373) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 24.1146, Epoch Time 475.9402(478.5349), Bit/dim 3.5042(best: 3.4982), Xent 0.0000, Loss 3.5042, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2017 | Time 76.9409(73.9337) | Bit/dim 3.5041(3.5002) | Xent 0.0000(0.0000) | Loss 12.0220(8.9905) | Error 0.0000(0.0000) Steps 688(669.75) | Grad Norm 0.4567(0.3409) | Total Time 0.00(0.00)\n",
      "Iter 2018 | Time 75.1280(73.9695) | Bit/dim 3.4905(3.4999) | Xent 0.0000(0.0000) | Loss 8.3704(8.9719) | Error 0.0000(0.0000) Steps 670(669.76) | Grad Norm 0.2982(0.3396) | Total Time 0.00(0.00)\n",
      "Iter 2019 | Time 78.8565(74.1161) | Bit/dim 3.5022(3.5000) | Xent 0.0000(0.0000) | Loss 8.2887(8.9514) | Error 0.0000(0.0000) Steps 682(670.13) | Grad Norm 0.5244(0.3452) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 65.6150(73.8611) | Bit/dim 3.5053(3.5001) | Xent 0.0000(0.0000) | Loss 8.2394(8.9300) | Error 0.0000(0.0000) Steps 658(669.76) | Grad Norm 0.3955(0.3467) | Total Time 0.00(0.00)\n",
      "Iter 2021 | Time 73.6091(73.8535) | Bit/dim 3.4933(3.4999) | Xent 0.0000(0.0000) | Loss 8.0668(8.9041) | Error 0.0000(0.0000) Steps 652(669.23) | Grad Norm 0.3887(0.3479) | Total Time 0.00(0.00)\n",
      "Iter 2022 | Time 72.6821(73.8184) | Bit/dim 3.5036(3.5000) | Xent 0.0000(0.0000) | Loss 8.3741(8.8882) | Error 0.0000(0.0000) Steps 664(669.07) | Grad Norm 0.5416(0.3538) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 23.6659, Epoch Time 482.3136(478.6483), Bit/dim 3.5025(best: 3.4982), Xent 0.0000, Loss 3.5025, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2023 | Time 74.3836(73.8353) | Bit/dim 3.4980(3.5000) | Xent 0.0000(0.0000) | Loss 12.1886(8.9873) | Error 0.0000(0.0000) Steps 688(669.64) | Grad Norm 0.5282(0.3590) | Total Time 0.00(0.00)\n",
      "Iter 2024 | Time 77.1978(73.9362) | Bit/dim 3.5061(3.5001) | Xent 0.0000(0.0000) | Loss 8.3210(8.9673) | Error 0.0000(0.0000) Steps 664(669.47) | Grad Norm 0.3387(0.3584) | Total Time 0.00(0.00)\n",
      "Iter 2025 | Time 78.2892(74.0668) | Bit/dim 3.4919(3.4999) | Xent 0.0000(0.0000) | Loss 8.3614(8.9491) | Error 0.0000(0.0000) Steps 664(669.31) | Grad Norm 0.5319(0.3636) | Total Time 0.00(0.00)\n",
      "Iter 2026 | Time 71.7905(73.9985) | Bit/dim 3.5071(3.5001) | Xent 0.0000(0.0000) | Loss 8.0982(8.9236) | Error 0.0000(0.0000) Steps 670(669.33) | Grad Norm 0.4718(0.3668) | Total Time 0.00(0.00)\n",
      "Iter 2027 | Time 76.2884(74.0672) | Bit/dim 3.5038(3.5002) | Xent 0.0000(0.0000) | Loss 8.4502(8.9094) | Error 0.0000(0.0000) Steps 682(669.71) | Grad Norm 0.3104(0.3651) | Total Time 0.00(0.00)\n",
      "Iter 2028 | Time 71.6870(73.9958) | Bit/dim 3.4987(3.5002) | Xent 0.0000(0.0000) | Loss 8.2772(8.8904) | Error 0.0000(0.0000) Steps 664(669.54) | Grad Norm 0.5622(0.3710) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 23.9439, Epoch Time 489.4586(478.9726), Bit/dim 3.5031(best: 3.4982), Xent 0.0000, Loss 3.5031, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2029 | Time 82.5796(74.2533) | Bit/dim 3.5110(3.5005) | Xent 0.0000(0.0000) | Loss 12.1931(8.9895) | Error 0.0000(0.0000) Steps 688(670.09) | Grad Norm 0.3821(0.3714) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 75.3000(74.2847) | Bit/dim 3.4885(3.5001) | Xent 0.0000(0.0000) | Loss 8.4342(8.9728) | Error 0.0000(0.0000) Steps 688(670.63) | Grad Norm 0.3888(0.3719) | Total Time 0.00(0.00)\n",
      "Iter 2031 | Time 73.6989(74.2671) | Bit/dim 3.4951(3.5000) | Xent 0.0000(0.0000) | Loss 8.1276(8.9475) | Error 0.0000(0.0000) Steps 670(670.61) | Grad Norm 0.5197(0.3763) | Total Time 0.00(0.00)\n",
      "Iter 2032 | Time 75.5905(74.3068) | Bit/dim 3.5148(3.5004) | Xent 0.0000(0.0000) | Loss 8.1743(8.9243) | Error 0.0000(0.0000) Steps 670(670.59) | Grad Norm 0.4206(0.3777) | Total Time 0.00(0.00)\n",
      "Iter 2033 | Time 73.1040(74.2708) | Bit/dim 3.4998(3.5004) | Xent 0.0000(0.0000) | Loss 8.4693(8.9106) | Error 0.0000(0.0000) Steps 676(670.75) | Grad Norm 0.3527(0.3769) | Total Time 0.00(0.00)\n",
      "Iter 2034 | Time 72.3707(74.2138) | Bit/dim 3.4881(3.5000) | Xent 0.0000(0.0000) | Loss 8.5254(8.8991) | Error 0.0000(0.0000) Steps 682(671.09) | Grad Norm 0.7012(0.3866) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 24.2968, Epoch Time 492.9214(479.3911), Bit/dim 3.4994(best: 3.4982), Xent 0.0000, Loss 3.4994, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2035 | Time 71.5350(74.1334) | Bit/dim 3.4963(3.4999) | Xent 0.0000(0.0000) | Loss 11.5292(8.9780) | Error 0.0000(0.0000) Steps 652(670.52) | Grad Norm 0.5766(0.3923) | Total Time 0.00(0.00)\n",
      "Iter 2036 | Time 78.5487(74.2658) | Bit/dim 3.4898(3.4996) | Xent 0.0000(0.0000) | Loss 8.3023(8.9577) | Error 0.0000(0.0000) Steps 676(670.68) | Grad Norm 0.4485(0.3940) | Total Time 0.00(0.00)\n",
      "Iter 2037 | Time 72.2231(74.2046) | Bit/dim 3.5069(3.4998) | Xent 0.0000(0.0000) | Loss 8.0845(8.9315) | Error 0.0000(0.0000) Steps 658(670.30) | Grad Norm 0.6290(0.4011) | Total Time 0.00(0.00)\n",
      "Iter 2038 | Time 78.2324(74.3254) | Bit/dim 3.5031(3.4999) | Xent 0.0000(0.0000) | Loss 8.5338(8.9196) | Error 0.0000(0.0000) Steps 694(671.01) | Grad Norm 0.3079(0.3983) | Total Time 0.00(0.00)\n",
      "Iter 2039 | Time 76.2608(74.3835) | Bit/dim 3.5080(3.5002) | Xent 0.0000(0.0000) | Loss 8.1083(8.8952) | Error 0.0000(0.0000) Steps 676(671.16) | Grad Norm 0.5016(0.4014) | Total Time 0.00(0.00)\n",
      "Iter 2040 | Time 81.8434(74.6073) | Bit/dim 3.5049(3.5003) | Xent 0.0000(0.0000) | Loss 8.6008(8.8864) | Error 0.0000(0.0000) Steps 712(672.39) | Grad Norm 0.5658(0.4063) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 24.4763, Epoch Time 499.2333(479.9863), Bit/dim 3.5021(best: 3.4982), Xent 0.0000, Loss 3.5021, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2041 | Time 74.3705(74.6002) | Bit/dim 3.5110(3.5006) | Xent 0.0000(0.0000) | Loss 11.8858(8.9764) | Error 0.0000(0.0000) Steps 658(671.96) | Grad Norm 0.5070(0.4093) | Total Time 0.00(0.00)\n",
      "Iter 2042 | Time 77.1810(74.6776) | Bit/dim 3.5006(3.5006) | Xent 0.0000(0.0000) | Loss 8.3013(8.9561) | Error 0.0000(0.0000) Steps 676(672.08) | Grad Norm 0.6540(0.4167) | Total Time 0.00(0.00)\n",
      "Iter 2043 | Time 71.6625(74.5871) | Bit/dim 3.4840(3.5001) | Xent 0.0000(0.0000) | Loss 8.2307(8.9344) | Error 0.0000(0.0000) Steps 646(671.30) | Grad Norm 0.5607(0.4210) | Total Time 0.00(0.00)\n",
      "Iter 2044 | Time 64.6292(74.2884) | Bit/dim 3.5014(3.5002) | Xent 0.0000(0.0000) | Loss 8.1057(8.9095) | Error 0.0000(0.0000) Steps 664(671.08) | Grad Norm 0.4433(0.4217) | Total Time 0.00(0.00)\n",
      "Iter 2045 | Time 73.0794(74.2521) | Bit/dim 3.4996(3.5002) | Xent 0.0000(0.0000) | Loss 8.0263(8.8830) | Error 0.0000(0.0000) Steps 640(670.14) | Grad Norm 0.4891(0.4237) | Total Time 0.00(0.00)\n",
      "Iter 2046 | Time 75.9716(74.3037) | Bit/dim 3.5069(3.5004) | Xent 0.0000(0.0000) | Loss 8.2886(8.8652) | Error 0.0000(0.0000) Steps 688(670.68) | Grad Norm 0.4015(0.4230) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 23.4985, Epoch Time 476.2595(479.8745), Bit/dim 3.5011(best: 3.4982), Xent 0.0000, Loss 3.5011, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2047 | Time 73.4523(74.2782) | Bit/dim 3.4927(3.5001) | Xent 0.0000(0.0000) | Loss 11.8299(8.9541) | Error 0.0000(0.0000) Steps 682(671.02) | Grad Norm 0.4671(0.4243) | Total Time 0.00(0.00)\n",
      "Iter 2048 | Time 74.5802(74.2872) | Bit/dim 3.4853(3.4997) | Xent 0.0000(0.0000) | Loss 8.2489(8.9330) | Error 0.0000(0.0000) Steps 664(670.81) | Grad Norm 0.4944(0.4264) | Total Time 0.00(0.00)\n",
      "Iter 2049 | Time 71.4789(74.2030) | Bit/dim 3.4956(3.4996) | Xent 0.0000(0.0000) | Loss 8.2563(8.9127) | Error 0.0000(0.0000) Steps 658(670.43) | Grad Norm 0.5989(0.4316) | Total Time 0.00(0.00)\n",
      "Iter 2050 | Time 78.2853(74.3254) | Bit/dim 3.5093(3.4999) | Xent 0.0000(0.0000) | Loss 8.2773(8.8936) | Error 0.0000(0.0000) Steps 688(670.95) | Grad Norm 0.5283(0.4345) | Total Time 0.00(0.00)\n",
      "Iter 2051 | Time 71.6847(74.2462) | Bit/dim 3.5090(3.5001) | Xent 0.0000(0.0000) | Loss 8.3682(8.8778) | Error 0.0000(0.0000) Steps 670(670.92) | Grad Norm 0.3111(0.4308) | Total Time 0.00(0.00)\n",
      "Iter 2052 | Time 71.6096(74.1671) | Bit/dim 3.4987(3.5001) | Xent 0.0000(0.0000) | Loss 8.3460(8.8619) | Error 0.0000(0.0000) Steps 652(670.36) | Grad Norm 0.3091(0.4272) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 24.6870, Epoch Time 481.2455(479.9156), Bit/dim 3.4984(best: 3.4982), Xent 0.0000, Loss 3.4984, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2053 | Time 71.2333(74.0791) | Bit/dim 3.4915(3.4998) | Xent 0.0000(0.0000) | Loss 12.3350(8.9661) | Error 0.0000(0.0000) Steps 676(670.53) | Grad Norm 0.2826(0.4228) | Total Time 0.00(0.00)\n",
      "Iter 2054 | Time 76.4356(74.1498) | Bit/dim 3.5012(3.4999) | Xent 0.0000(0.0000) | Loss 8.4656(8.9511) | Error 0.0000(0.0000) Steps 676(670.69) | Grad Norm 0.3024(0.4192) | Total Time 0.00(0.00)\n",
      "Iter 2055 | Time 73.9377(74.1434) | Bit/dim 3.4921(3.4996) | Xent 0.0000(0.0000) | Loss 8.3305(8.9324) | Error 0.0000(0.0000) Steps 682(671.03) | Grad Norm 0.2420(0.4139) | Total Time 0.00(0.00)\n",
      "Iter 2056 | Time 68.5955(73.9770) | Bit/dim 3.5221(3.5003) | Xent 0.0000(0.0000) | Loss 8.3458(8.9149) | Error 0.0000(0.0000) Steps 670(671.00) | Grad Norm 0.3784(0.4128) | Total Time 0.00(0.00)\n",
      "Iter 2057 | Time 70.2770(73.8660) | Bit/dim 3.4901(3.5000) | Xent 0.0000(0.0000) | Loss 8.4369(8.9005) | Error 0.0000(0.0000) Steps 670(670.97) | Grad Norm 0.3020(0.4095) | Total Time 0.00(0.00)\n",
      "Iter 2058 | Time 79.6269(74.0388) | Bit/dim 3.4986(3.5000) | Xent 0.0000(0.0000) | Loss 8.1640(8.8784) | Error 0.0000(0.0000) Steps 682(671.30) | Grad Norm 0.3152(0.4067) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 23.7804, Epoch Time 479.9746(479.9174), Bit/dim 3.4998(best: 3.4982), Xent 0.0000, Loss 3.4998, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2059 | Time 76.7355(74.1197) | Bit/dim 3.4934(3.4998) | Xent 0.0000(0.0000) | Loss 11.8049(8.9662) | Error 0.0000(0.0000) Steps 688(671.80) | Grad Norm 0.3671(0.4055) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 73.7340(74.1082) | Bit/dim 3.4914(3.4995) | Xent 0.0000(0.0000) | Loss 8.0625(8.9391) | Error 0.0000(0.0000) Steps 676(671.93) | Grad Norm 0.3425(0.4036) | Total Time 0.00(0.00)\n",
      "Iter 2061 | Time 79.4096(74.2672) | Bit/dim 3.5000(3.4995) | Xent 0.0000(0.0000) | Loss 8.1502(8.9154) | Error 0.0000(0.0000) Steps 682(672.23) | Grad Norm 0.4872(0.4061) | Total Time 0.00(0.00)\n",
      "Iter 2062 | Time 77.4311(74.3621) | Bit/dim 3.4966(3.4994) | Xent 0.0000(0.0000) | Loss 8.4917(8.9027) | Error 0.0000(0.0000) Steps 694(672.88) | Grad Norm 0.4492(0.4074) | Total Time 0.00(0.00)\n",
      "Iter 2063 | Time 77.5647(74.4582) | Bit/dim 3.4979(3.4994) | Xent 0.0000(0.0000) | Loss 8.4561(8.8893) | Error 0.0000(0.0000) Steps 694(673.52) | Grad Norm 0.5745(0.4124) | Total Time 0.00(0.00)\n",
      "Iter 2064 | Time 79.2156(74.6009) | Bit/dim 3.4963(3.4993) | Xent 0.0000(0.0000) | Loss 8.4608(8.8765) | Error 0.0000(0.0000) Steps 706(674.49) | Grad Norm 0.4684(0.4141) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 23.3560, Epoch Time 502.8201(480.6045), Bit/dim 3.5025(best: 3.4982), Xent 0.0000, Loss 3.5025, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2065 | Time 75.7475(74.6353) | Bit/dim 3.4959(3.4992) | Xent 0.0000(0.0000) | Loss 11.9355(8.9682) | Error 0.0000(0.0000) Steps 676(674.53) | Grad Norm 0.3418(0.4119) | Total Time 0.00(0.00)\n",
      "Iter 2066 | Time 79.2642(74.7742) | Bit/dim 3.4974(3.4992) | Xent 0.0000(0.0000) | Loss 8.2064(8.9454) | Error 0.0000(0.0000) Steps 670(674.40) | Grad Norm 0.5083(0.4148) | Total Time 0.00(0.00)\n",
      "Iter 2067 | Time 74.7338(74.7730) | Bit/dim 3.5054(3.4993) | Xent 0.0000(0.0000) | Loss 8.4862(8.9316) | Error 0.0000(0.0000) Steps 688(674.81) | Grad Norm 0.5206(0.4180) | Total Time 0.00(0.00)\n",
      "Iter 2068 | Time 72.6920(74.7105) | Bit/dim 3.4951(3.4992) | Xent 0.0000(0.0000) | Loss 8.2779(8.9120) | Error 0.0000(0.0000) Steps 670(674.66) | Grad Norm 0.5129(0.4208) | Total Time 0.00(0.00)\n",
      "Iter 2069 | Time 73.6761(74.6795) | Bit/dim 3.4969(3.4991) | Xent 0.0000(0.0000) | Loss 8.3831(8.8961) | Error 0.0000(0.0000) Steps 694(675.24) | Grad Norm 0.4413(0.4215) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 78.0078(74.7794) | Bit/dim 3.4992(3.4991) | Xent 0.0000(0.0000) | Loss 8.4192(8.8818) | Error 0.0000(0.0000) Steps 694(675.81) | Grad Norm 0.2070(0.4150) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 23.8559, Epoch Time 493.8703(481.0025), Bit/dim 3.5021(best: 3.4982), Xent 0.0000, Loss 3.5021, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2071 | Time 77.6198(74.8646) | Bit/dim 3.5016(3.4992) | Xent 0.0000(0.0000) | Loss 12.1674(8.9804) | Error 0.0000(0.0000) Steps 688(676.17) | Grad Norm 0.4908(0.4173) | Total Time 0.00(0.00)\n",
      "Iter 2072 | Time 77.5458(74.9450) | Bit/dim 3.5039(3.4994) | Xent 0.0000(0.0000) | Loss 8.5988(8.9689) | Error 0.0000(0.0000) Steps 706(677.07) | Grad Norm 0.4276(0.4176) | Total Time 0.00(0.00)\n",
      "Iter 2073 | Time 74.1236(74.9204) | Bit/dim 3.4911(3.4991) | Xent 0.0000(0.0000) | Loss 8.3186(8.9494) | Error 0.0000(0.0000) Steps 658(676.49) | Grad Norm 0.2474(0.4125) | Total Time 0.00(0.00)\n",
      "Iter 2074 | Time 76.0222(74.9534) | Bit/dim 3.5136(3.4995) | Xent 0.0000(0.0000) | Loss 8.3457(8.9313) | Error 0.0000(0.0000) Steps 664(676.12) | Grad Norm 0.4456(0.4135) | Total Time 0.00(0.00)\n",
      "Iter 2075 | Time 73.5273(74.9106) | Bit/dim 3.4928(3.4993) | Xent 0.0000(0.0000) | Loss 8.4558(8.9171) | Error 0.0000(0.0000) Steps 688(676.48) | Grad Norm 0.3771(0.4124) | Total Time 0.00(0.00)\n",
      "Iter 2076 | Time 83.6656(75.1733) | Bit/dim 3.4994(3.4993) | Xent 0.0000(0.0000) | Loss 8.4617(8.9034) | Error 0.0000(0.0000) Steps 700(677.18) | Grad Norm 0.5010(0.4151) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 24.1001, Epoch Time 502.3506(481.6429), Bit/dim 3.4917(best: 3.4982), Xent 0.0000, Loss 3.4917, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2077 | Time 82.1419(75.3823) | Bit/dim 3.4845(3.4989) | Xent 0.0000(0.0000) | Loss 12.2121(9.0027) | Error 0.0000(0.0000) Steps 712(678.23) | Grad Norm 0.3294(0.4125) | Total Time 0.00(0.00)\n",
      "Iter 2078 | Time 70.6367(75.2400) | Bit/dim 3.4988(3.4989) | Xent 0.0000(0.0000) | Loss 8.4860(8.9872) | Error 0.0000(0.0000) Steps 670(677.98) | Grad Norm 0.3277(0.4099) | Total Time 0.00(0.00)\n",
      "Iter 2079 | Time 73.9856(75.2023) | Bit/dim 3.4964(3.4988) | Xent 0.0000(0.0000) | Loss 8.3449(8.9679) | Error 0.0000(0.0000) Steps 676(677.92) | Grad Norm 0.3878(0.4093) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 72.6364(75.1254) | Bit/dim 3.5028(3.4989) | Xent 0.0000(0.0000) | Loss 8.0876(8.9415) | Error 0.0000(0.0000) Steps 646(676.96) | Grad Norm 0.2516(0.4045) | Total Time 0.00(0.00)\n",
      "Iter 2081 | Time 70.5174(74.9871) | Bit/dim 3.4982(3.4989) | Xent 0.0000(0.0000) | Loss 8.3322(8.9232) | Error 0.0000(0.0000) Steps 664(676.57) | Grad Norm 0.4478(0.4058) | Total Time 0.00(0.00)\n",
      "Iter 2082 | Time 72.3538(74.9081) | Bit/dim 3.4912(3.4987) | Xent 0.0000(0.0000) | Loss 8.3619(8.9064) | Error 0.0000(0.0000) Steps 682(676.74) | Grad Norm 0.3740(0.4049) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 23.9054, Epoch Time 482.1137(481.6570), Bit/dim 3.4961(best: 3.4917), Xent 0.0000, Loss 3.4961, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2083 | Time 74.8064(74.9051) | Bit/dim 3.5057(3.4989) | Xent 0.0000(0.0000) | Loss 11.7891(8.9928) | Error 0.0000(0.0000) Steps 664(676.35) | Grad Norm 0.4312(0.4057) | Total Time 0.00(0.00)\n",
      "Iter 2084 | Time 68.6713(74.7181) | Bit/dim 3.4930(3.4987) | Xent 0.0000(0.0000) | Loss 8.3227(8.9727) | Error 0.0000(0.0000) Steps 658(675.80) | Grad Norm 0.6060(0.4117) | Total Time 0.00(0.00)\n",
      "Iter 2085 | Time 72.6135(74.6549) | Bit/dim 3.4783(3.4981) | Xent 0.0000(0.0000) | Loss 8.5544(8.9602) | Error 0.0000(0.0000) Steps 694(676.35) | Grad Norm 0.2390(0.4065) | Total Time 0.00(0.00)\n",
      "Iter 2086 | Time 79.7723(74.8084) | Bit/dim 3.5007(3.4982) | Xent 0.0000(0.0000) | Loss 8.3110(8.9407) | Error 0.0000(0.0000) Steps 682(676.52) | Grad Norm 0.5551(0.4110) | Total Time 0.00(0.00)\n",
      "Iter 2087 | Time 78.5872(74.9218) | Bit/dim 3.4932(3.4980) | Xent 0.0000(0.0000) | Loss 8.4586(8.9262) | Error 0.0000(0.0000) Steps 712(677.58) | Grad Norm 0.3593(0.4094) | Total Time 0.00(0.00)\n",
      "Iter 2088 | Time 72.5400(74.8504) | Bit/dim 3.5029(3.4982) | Xent 0.0000(0.0000) | Loss 8.3276(8.9083) | Error 0.0000(0.0000) Steps 694(678.08) | Grad Norm 0.3486(0.4076) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 24.3971, Epoch Time 486.9849(481.8169), Bit/dim 3.4979(best: 3.4917), Xent 0.0000, Loss 3.4979, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2089 | Time 74.9620(74.8537) | Bit/dim 3.4938(3.4981) | Xent 0.0000(0.0000) | Loss 12.1566(9.0057) | Error 0.0000(0.0000) Steps 670(677.83) | Grad Norm 0.6431(0.4147) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 73.3992(74.8101) | Bit/dim 3.4920(3.4979) | Xent 0.0000(0.0000) | Loss 8.4068(8.9878) | Error 0.0000(0.0000) Steps 688(678.14) | Grad Norm 0.4059(0.4144) | Total Time 0.00(0.00)\n",
      "Iter 2091 | Time 75.7055(74.8369) | Bit/dim 3.5010(3.4980) | Xent 0.0000(0.0000) | Loss 8.2636(8.9660) | Error 0.0000(0.0000) Steps 682(678.25) | Grad Norm 0.4713(0.4161) | Total Time 0.00(0.00)\n",
      "Iter 2092 | Time 77.6541(74.9214) | Bit/dim 3.5019(3.4981) | Xent 0.0000(0.0000) | Loss 8.3234(8.9468) | Error 0.0000(0.0000) Steps 682(678.37) | Grad Norm 0.5817(0.4211) | Total Time 0.00(0.00)\n",
      "Iter 2093 | Time 77.1267(74.9876) | Bit/dim 3.5015(3.4982) | Xent 0.0000(0.0000) | Loss 8.4091(8.9306) | Error 0.0000(0.0000) Steps 688(678.66) | Grad Norm 0.4489(0.4219) | Total Time 0.00(0.00)\n",
      "Iter 2094 | Time 68.0496(74.7795) | Bit/dim 3.4929(3.4980) | Xent 0.0000(0.0000) | Loss 8.2367(8.9098) | Error 0.0000(0.0000) Steps 652(677.86) | Grad Norm 0.4820(0.4237) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 23.6629, Epoch Time 486.6459(481.9617), Bit/dim 3.4944(best: 3.4917), Xent 0.0000, Loss 3.4944, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2095 | Time 71.8716(74.6922) | Bit/dim 3.4929(3.4979) | Xent 0.0000(0.0000) | Loss 12.1180(9.0061) | Error 0.0000(0.0000) Steps 670(677.62) | Grad Norm 0.3253(0.4208) | Total Time 0.00(0.00)\n",
      "Iter 2096 | Time 74.7321(74.6934) | Bit/dim 3.4920(3.4977) | Xent 0.0000(0.0000) | Loss 8.3926(8.9877) | Error 0.0000(0.0000) Steps 676(677.57) | Grad Norm 0.3948(0.4200) | Total Time 0.00(0.00)\n",
      "Iter 2097 | Time 76.4017(74.7447) | Bit/dim 3.5010(3.4978) | Xent 0.0000(0.0000) | Loss 8.2557(8.9657) | Error 0.0000(0.0000) Steps 676(677.52) | Grad Norm 0.5048(0.4225) | Total Time 0.00(0.00)\n",
      "Iter 2098 | Time 68.3684(74.5534) | Bit/dim 3.4952(3.4977) | Xent 0.0000(0.0000) | Loss 8.1752(8.9420) | Error 0.0000(0.0000) Steps 640(676.40) | Grad Norm 0.4065(0.4220) | Total Time 0.00(0.00)\n",
      "Iter 2099 | Time 74.5039(74.5519) | Bit/dim 3.4996(3.4978) | Xent 0.0000(0.0000) | Loss 8.2563(8.9214) | Error 0.0000(0.0000) Steps 670(676.21) | Grad Norm 0.5738(0.4266) | Total Time 0.00(0.00)\n",
      "Iter 2100 | Time 68.1017(74.3584) | Bit/dim 3.5017(3.4979) | Xent 0.0000(0.0000) | Loss 8.3702(8.9049) | Error 0.0000(0.0000) Steps 682(676.38) | Grad Norm 0.4864(0.4284) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 23.5469, Epoch Time 473.5902(481.7106), Bit/dim 3.4984(best: 3.4917), Xent 0.0000, Loss 3.4984, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2101 | Time 76.4876(74.4223) | Bit/dim 3.5046(3.4981) | Xent 0.0000(0.0000) | Loss 11.9825(8.9972) | Error 0.0000(0.0000) Steps 694(676.91) | Grad Norm 0.8282(0.4404) | Total Time 0.00(0.00)\n",
      "Iter 2102 | Time 69.6581(74.2793) | Bit/dim 3.5040(3.4983) | Xent 0.0000(0.0000) | Loss 8.4717(8.9814) | Error 0.0000(0.0000) Steps 664(676.52) | Grad Norm 0.4736(0.4414) | Total Time 0.00(0.00)\n",
      "Iter 2103 | Time 72.9953(74.2408) | Bit/dim 3.4991(3.4983) | Xent 0.0000(0.0000) | Loss 8.5165(8.9675) | Error 0.0000(0.0000) Steps 682(676.69) | Grad Norm 0.2370(0.4352) | Total Time 0.00(0.00)\n",
      "Iter 2104 | Time 76.8153(74.3181) | Bit/dim 3.4890(3.4980) | Xent 0.0000(0.0000) | Loss 8.2421(8.9457) | Error 0.0000(0.0000) Steps 676(676.67) | Grad Norm 0.5228(0.4379) | Total Time 0.00(0.00)\n",
      "Iter 2105 | Time 76.6686(74.3886) | Bit/dim 3.4986(3.4980) | Xent 0.0000(0.0000) | Loss 8.4795(8.9318) | Error 0.0000(0.0000) Steps 688(677.01) | Grad Norm 0.4959(0.4396) | Total Time 0.00(0.00)\n",
      "Iter 2106 | Time 70.4475(74.2703) | Bit/dim 3.4925(3.4979) | Xent 0.0000(0.0000) | Loss 8.3267(8.9136) | Error 0.0000(0.0000) Steps 676(676.98) | Grad Norm 0.4605(0.4402) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 23.3726, Epoch Time 482.2631(481.7272), Bit/dim 3.5058(best: 3.4917), Xent 0.0000, Loss 3.5058, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2107 | Time 68.9106(74.1096) | Bit/dim 3.4821(3.4974) | Xent 0.0000(0.0000) | Loss 11.8456(9.0016) | Error 0.0000(0.0000) Steps 688(677.31) | Grad Norm 0.4654(0.4410) | Total Time 0.00(0.00)\n",
      "Iter 2108 | Time 74.9280(74.1341) | Bit/dim 3.5020(3.4975) | Xent 0.0000(0.0000) | Loss 8.4830(8.9860) | Error 0.0000(0.0000) Steps 682(677.45) | Grad Norm 0.3134(0.4372) | Total Time 0.00(0.00)\n",
      "Iter 2109 | Time 73.9681(74.1291) | Bit/dim 3.5000(3.4976) | Xent 0.0000(0.0000) | Loss 8.5929(8.9742) | Error 0.0000(0.0000) Steps 700(678.12) | Grad Norm 0.3667(0.4351) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 72.9710(74.0944) | Bit/dim 3.4884(3.4973) | Xent 0.0000(0.0000) | Loss 8.3197(8.9546) | Error 0.0000(0.0000) Steps 688(678.42) | Grad Norm 0.2928(0.4308) | Total Time 0.00(0.00)\n",
      "Iter 2111 | Time 77.1406(74.1858) | Bit/dim 3.4934(3.4972) | Xent 0.0000(0.0000) | Loss 8.2713(8.9341) | Error 0.0000(0.0000) Steps 688(678.71) | Grad Norm 0.3218(0.4275) | Total Time 0.00(0.00)\n",
      "Iter 2112 | Time 78.3123(74.3096) | Bit/dim 3.5020(3.4974) | Xent 0.0000(0.0000) | Loss 8.5018(8.9211) | Error 0.0000(0.0000) Steps 682(678.81) | Grad Norm 0.3654(0.4257) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 24.3944, Epoch Time 486.8492(481.8808), Bit/dim 3.4985(best: 3.4917), Xent 0.0000, Loss 3.4985, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2113 | Time 74.9963(74.3302) | Bit/dim 3.4984(3.4974) | Xent 0.0000(0.0000) | Loss 12.1438(9.0178) | Error 0.0000(0.0000) Steps 682(678.90) | Grad Norm 0.3607(0.4237) | Total Time 0.00(0.00)\n",
      "Iter 2114 | Time 76.1564(74.3850) | Bit/dim 3.5000(3.4975) | Xent 0.0000(0.0000) | Loss 8.3044(8.9964) | Error 0.0000(0.0000) Steps 688(679.17) | Grad Norm 0.2830(0.4195) | Total Time 0.00(0.00)\n",
      "Iter 2115 | Time 69.6208(74.2420) | Bit/dim 3.4928(3.4973) | Xent 0.0000(0.0000) | Loss 8.3849(8.9780) | Error 0.0000(0.0000) Steps 682(679.26) | Grad Norm 0.3568(0.4176) | Total Time 0.00(0.00)\n",
      "Iter 2116 | Time 75.5489(74.2812) | Bit/dim 3.4978(3.4973) | Xent 0.0000(0.0000) | Loss 8.4521(8.9623) | Error 0.0000(0.0000) Steps 706(680.06) | Grad Norm 0.2222(0.4117) | Total Time 0.00(0.00)\n",
      "Iter 2117 | Time 73.3690(74.2539) | Bit/dim 3.4896(3.4971) | Xent 0.0000(0.0000) | Loss 8.1904(8.9391) | Error 0.0000(0.0000) Steps 658(679.40) | Grad Norm 0.2721(0.4076) | Total Time 0.00(0.00)\n",
      "Iter 2118 | Time 77.3545(74.3469) | Bit/dim 3.4991(3.4972) | Xent 0.0000(0.0000) | Loss 8.4595(8.9247) | Error 0.0000(0.0000) Steps 670(679.12) | Grad Norm 0.2497(0.4028) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 24.2394, Epoch Time 487.0034(482.0345), Bit/dim 3.4968(best: 3.4917), Xent 0.0000, Loss 3.4968, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2119 | Time 71.2724(74.2547) | Bit/dim 3.4930(3.4970) | Xent 0.0000(0.0000) | Loss 12.1086(9.0202) | Error 0.0000(0.0000) Steps 658(678.48) | Grad Norm 0.2286(0.3976) | Total Time 0.00(0.00)\n",
      "Iter 2120 | Time 78.2433(74.3743) | Bit/dim 3.4994(3.4971) | Xent 0.0000(0.0000) | Loss 8.3601(9.0004) | Error 0.0000(0.0000) Steps 688(678.77) | Grad Norm 0.2433(0.3930) | Total Time 0.00(0.00)\n",
      "Iter 2121 | Time 75.6985(74.4140) | Bit/dim 3.4919(3.4970) | Xent 0.0000(0.0000) | Loss 8.3749(8.9817) | Error 0.0000(0.0000) Steps 652(677.97) | Grad Norm 0.3251(0.3909) | Total Time 0.00(0.00)\n",
      "Iter 2122 | Time 75.1656(74.4366) | Bit/dim 3.5000(3.4970) | Xent 0.0000(0.0000) | Loss 8.3536(8.9628) | Error 0.0000(0.0000) Steps 670(677.73) | Grad Norm 0.2215(0.3858) | Total Time 0.00(0.00)\n",
      "Iter 2123 | Time 77.9162(74.5410) | Bit/dim 3.4848(3.4967) | Xent 0.0000(0.0000) | Loss 8.3856(8.9455) | Error 0.0000(0.0000) Steps 676(677.68) | Grad Norm 0.2628(0.3822) | Total Time 0.00(0.00)\n",
      "Iter 2124 | Time 69.2136(74.3812) | Bit/dim 3.5001(3.4968) | Xent 0.0000(0.0000) | Loss 8.3816(8.9286) | Error 0.0000(0.0000) Steps 688(677.99) | Grad Norm 0.2392(0.3779) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 23.8207, Epoch Time 487.5563(482.2002), Bit/dim 3.4975(best: 3.4917), Xent 0.0000, Loss 3.4975, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2125 | Time 77.7013(74.4808) | Bit/dim 3.5001(3.4969) | Xent 0.0000(0.0000) | Loss 11.9993(9.0207) | Error 0.0000(0.0000) Steps 682(678.11) | Grad Norm 0.2694(0.3746) | Total Time 0.00(0.00)\n",
      "Iter 2126 | Time 74.6518(74.4859) | Bit/dim 3.5019(3.4970) | Xent 0.0000(0.0000) | Loss 8.4195(9.0027) | Error 0.0000(0.0000) Steps 664(677.68) | Grad Norm 0.2213(0.3700) | Total Time 0.00(0.00)\n",
      "Iter 2127 | Time 74.6184(74.4899) | Bit/dim 3.4882(3.4968) | Xent 0.0000(0.0000) | Loss 8.3318(8.9825) | Error 0.0000(0.0000) Steps 670(677.45) | Grad Norm 0.2607(0.3667) | Total Time 0.00(0.00)\n",
      "Iter 2128 | Time 71.0215(74.3858) | Bit/dim 3.4941(3.4967) | Xent 0.0000(0.0000) | Loss 8.3197(8.9627) | Error 0.0000(0.0000) Steps 670(677.23) | Grad Norm 0.3293(0.3656) | Total Time 0.00(0.00)\n",
      "Iter 2129 | Time 73.1716(74.3494) | Bit/dim 3.5084(3.4970) | Xent 0.0000(0.0000) | Loss 8.2013(8.9398) | Error 0.0000(0.0000) Steps 664(676.83) | Grad Norm 0.3015(0.3637) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 73.5741(74.3261) | Bit/dim 3.4978(3.4971) | Xent 0.0000(0.0000) | Loss 8.5366(8.9277) | Error 0.0000(0.0000) Steps 658(676.27) | Grad Norm 0.4646(0.3667) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 23.9898, Epoch Time 484.8643(482.2801), Bit/dim 3.4968(best: 3.4917), Xent 0.0000, Loss 3.4968, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2131 | Time 78.8181(74.4609) | Bit/dim 3.4950(3.4970) | Xent 0.0000(0.0000) | Loss 12.1023(9.0230) | Error 0.0000(0.0000) Steps 700(676.98) | Grad Norm 0.5394(0.3719) | Total Time 0.00(0.00)\n",
      "Iter 2132 | Time 69.7034(74.3182) | Bit/dim 3.4987(3.4971) | Xent 0.0000(0.0000) | Loss 8.1768(8.9976) | Error 0.0000(0.0000) Steps 664(676.59) | Grad Norm 0.4842(0.3753) | Total Time 0.00(0.00)\n",
      "Iter 2133 | Time 75.8730(74.3648) | Bit/dim 3.4968(3.4970) | Xent 0.0000(0.0000) | Loss 8.1850(8.9732) | Error 0.0000(0.0000) Steps 688(676.93) | Grad Norm 0.3463(0.3744) | Total Time 0.00(0.00)\n",
      "Iter 2134 | Time 74.0136(74.3543) | Bit/dim 3.4956(3.4970) | Xent 0.0000(0.0000) | Loss 8.2858(8.9526) | Error 0.0000(0.0000) Steps 670(676.72) | Grad Norm 0.4266(0.3760) | Total Time 0.00(0.00)\n",
      "Iter 2135 | Time 72.6690(74.3037) | Bit/dim 3.4951(3.4969) | Xent 0.0000(0.0000) | Loss 8.4169(8.9365) | Error 0.0000(0.0000) Steps 688(677.06) | Grad Norm 0.7029(0.3858) | Total Time 0.00(0.00)\n",
      "Iter 2136 | Time 74.0988(74.2976) | Bit/dim 3.4997(3.4970) | Xent 0.0000(0.0000) | Loss 8.3409(8.9186) | Error 0.0000(0.0000) Steps 676(677.03) | Grad Norm 0.6929(0.3950) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 23.7514, Epoch Time 484.9211(482.3593), Bit/dim 3.5000(best: 3.4917), Xent 0.0000, Loss 3.5000, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2137 | Time 67.7177(74.1002) | Bit/dim 3.5104(3.4974) | Xent 0.0000(0.0000) | Loss 12.2470(9.0185) | Error 0.0000(0.0000) Steps 670(676.82) | Grad Norm 0.4618(0.3970) | Total Time 0.00(0.00)\n",
      "Iter 2138 | Time 71.1350(74.0112) | Bit/dim 3.4881(3.4971) | Xent 0.0000(0.0000) | Loss 8.3841(8.9995) | Error 0.0000(0.0000) Steps 658(676.25) | Grad Norm 0.3265(0.3949) | Total Time 0.00(0.00)\n",
      "Iter 2139 | Time 73.5805(73.9983) | Bit/dim 3.4854(3.4968) | Xent 0.0000(0.0000) | Loss 8.3949(8.9813) | Error 0.0000(0.0000) Steps 676(676.25) | Grad Norm 0.5895(0.4007) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 73.2837(73.9769) | Bit/dim 3.5070(3.4971) | Xent 0.0000(0.0000) | Loss 8.4744(8.9661) | Error 0.0000(0.0000) Steps 694(676.78) | Grad Norm 0.7865(0.4123) | Total Time 0.00(0.00)\n",
      "Iter 2141 | Time 73.4485(73.9610) | Bit/dim 3.4936(3.4970) | Xent 0.0000(0.0000) | Loss 8.4369(8.9502) | Error 0.0000(0.0000) Steps 670(676.58) | Grad Norm 0.7531(0.4225) | Total Time 0.00(0.00)\n",
      "Iter 2142 | Time 80.3394(74.1524) | Bit/dim 3.4906(3.4968) | Xent 0.0000(0.0000) | Loss 8.3704(8.9328) | Error 0.0000(0.0000) Steps 724(678.00) | Grad Norm 0.5581(0.4266) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 23.5925, Epoch Time 478.7641(482.2515), Bit/dim 3.4974(best: 3.4917), Xent 0.0000, Loss 3.4974, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2143 | Time 74.3021(74.1568) | Bit/dim 3.4907(3.4966) | Xent 0.0000(0.0000) | Loss 12.0037(9.0250) | Error 0.0000(0.0000) Steps 682(678.12) | Grad Norm 0.3046(0.4229) | Total Time 0.00(0.00)\n",
      "Iter 2144 | Time 74.3100(74.1614) | Bit/dim 3.5001(3.4967) | Xent 0.0000(0.0000) | Loss 8.2283(9.0011) | Error 0.0000(0.0000) Steps 670(677.88) | Grad Norm 0.4855(0.4248) | Total Time 0.00(0.00)\n",
      "Iter 2145 | Time 72.7089(74.1179) | Bit/dim 3.5027(3.4969) | Xent 0.0000(0.0000) | Loss 8.1807(8.9765) | Error 0.0000(0.0000) Steps 676(677.82) | Grad Norm 0.4521(0.4256) | Total Time 0.00(0.00)\n",
      "Iter 2146 | Time 76.5057(74.1895) | Bit/dim 3.4939(3.4968) | Xent 0.0000(0.0000) | Loss 8.5822(8.9646) | Error 0.0000(0.0000) Steps 706(678.66) | Grad Norm 0.1911(0.4186) | Total Time 0.00(0.00)\n",
      "Iter 2147 | Time 77.1658(74.2788) | Bit/dim 3.4873(3.4965) | Xent 0.0000(0.0000) | Loss 8.4039(8.9478) | Error 0.0000(0.0000) Steps 682(678.76) | Grad Norm 0.4966(0.4209) | Total Time 0.00(0.00)\n",
      "Iter 2148 | Time 72.6611(74.2303) | Bit/dim 3.4977(3.4966) | Xent 0.0000(0.0000) | Loss 8.1004(8.9224) | Error 0.0000(0.0000) Steps 664(678.32) | Grad Norm 0.8061(0.4325) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 24.0259, Epoch Time 487.6581(482.4137), Bit/dim 3.5009(best: 3.4917), Xent 0.0000, Loss 3.5009, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2149 | Time 74.4527(74.2369) | Bit/dim 3.4870(3.4963) | Xent 0.0000(0.0000) | Loss 11.7130(9.0061) | Error 0.0000(0.0000) Steps 682(678.43) | Grad Norm 0.7729(0.4427) | Total Time 0.00(0.00)\n",
      "Iter 2150 | Time 78.5898(74.3675) | Bit/dim 3.4947(3.4962) | Xent 0.0000(0.0000) | Loss 8.5056(8.9911) | Error 0.0000(0.0000) Steps 706(679.26) | Grad Norm 0.5261(0.4452) | Total Time 0.00(0.00)\n",
      "Iter 2151 | Time 73.1898(74.3322) | Bit/dim 3.4965(3.4962) | Xent 0.0000(0.0000) | Loss 8.4709(8.9755) | Error 0.0000(0.0000) Steps 670(678.98) | Grad Norm 0.2916(0.4406) | Total Time 0.00(0.00)\n",
      "Iter 2152 | Time 78.8135(74.4666) | Bit/dim 3.4838(3.4959) | Xent 0.0000(0.0000) | Loss 8.4163(8.9587) | Error 0.0000(0.0000) Steps 706(679.79) | Grad Norm 0.3747(0.4386) | Total Time 0.00(0.00)\n",
      "Iter 2153 | Time 70.8132(74.3570) | Bit/dim 3.4971(3.4959) | Xent 0.0000(0.0000) | Loss 8.3332(8.9399) | Error 0.0000(0.0000) Steps 676(679.68) | Grad Norm 0.6839(0.4460) | Total Time 0.00(0.00)\n",
      "Iter 2154 | Time 72.6194(74.3049) | Bit/dim 3.5062(3.4962) | Xent 0.0000(0.0000) | Loss 8.2861(8.9203) | Error 0.0000(0.0000) Steps 676(679.57) | Grad Norm 0.7056(0.4538) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 23.1030, Epoch Time 487.6803(482.5717), Bit/dim 3.4958(best: 3.4917), Xent 0.0000, Loss 3.4958, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2155 | Time 76.6940(74.3766) | Bit/dim 3.4887(3.4960) | Xent 0.0000(0.0000) | Loss 12.2940(9.0215) | Error 0.0000(0.0000) Steps 712(680.54) | Grad Norm 0.5284(0.4560) | Total Time 0.00(0.00)\n",
      "Iter 2156 | Time 75.8701(74.4214) | Bit/dim 3.4961(3.4960) | Xent 0.0000(0.0000) | Loss 8.5361(9.0070) | Error 0.0000(0.0000) Steps 712(681.48) | Grad Norm 0.3776(0.4536) | Total Time 0.00(0.00)\n",
      "Iter 2157 | Time 76.1008(74.4718) | Bit/dim 3.5031(3.4962) | Xent 0.0000(0.0000) | Loss 8.1643(8.9817) | Error 0.0000(0.0000) Steps 670(681.14) | Grad Norm 0.3496(0.4505) | Total Time 0.00(0.00)\n",
      "Iter 2158 | Time 72.6135(74.4160) | Bit/dim 3.4901(3.4960) | Xent 0.0000(0.0000) | Loss 8.4793(8.9666) | Error 0.0000(0.0000) Steps 706(681.89) | Grad Norm 0.3263(0.4468) | Total Time 0.00(0.00)\n",
      "Iter 2159 | Time 73.0415(74.3748) | Bit/dim 3.5038(3.4962) | Xent 0.0000(0.0000) | Loss 8.2946(8.9465) | Error 0.0000(0.0000) Steps 688(682.07) | Grad Norm 0.4959(0.4483) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 80.8803(74.5699) | Bit/dim 3.4968(3.4963) | Xent 0.0000(0.0000) | Loss 8.2852(8.9266) | Error 0.0000(0.0000) Steps 664(681.53) | Grad Norm 0.7507(0.4573) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 23.4941, Epoch Time 494.5030(482.9296), Bit/dim 3.4975(best: 3.4917), Xent 0.0000, Loss 3.4975, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2161 | Time 71.5599(74.4796) | Bit/dim 3.4992(3.4964) | Xent 0.0000(0.0000) | Loss 11.3910(9.0006) | Error 0.0000(0.0000) Steps 670(681.18) | Grad Norm 1.0226(0.4743) | Total Time 0.00(0.00)\n",
      "Iter 2162 | Time 77.6866(74.5758) | Bit/dim 3.5006(3.4965) | Xent 0.0000(0.0000) | Loss 8.4820(8.9850) | Error 0.0000(0.0000) Steps 700(681.75) | Grad Norm 0.8010(0.4841) | Total Time 0.00(0.00)\n",
      "Iter 2163 | Time 74.9880(74.5882) | Bit/dim 3.4938(3.4964) | Xent 0.0000(0.0000) | Loss 8.4550(8.9691) | Error 0.0000(0.0000) Steps 676(681.57) | Grad Norm 0.5783(0.4869) | Total Time 0.00(0.00)\n",
      "Iter 2164 | Time 77.3028(74.6697) | Bit/dim 3.4936(3.4963) | Xent 0.0000(0.0000) | Loss 8.5283(8.9559) | Error 0.0000(0.0000) Steps 670(681.23) | Grad Norm 0.2549(0.4800) | Total Time 0.00(0.00)\n",
      "Iter 2165 | Time 75.5189(74.6951) | Bit/dim 3.4870(3.4960) | Xent 0.0000(0.0000) | Loss 8.4367(8.9403) | Error 0.0000(0.0000) Steps 676(681.07) | Grad Norm 0.4314(0.4785) | Total Time 0.00(0.00)\n",
      "Iter 2166 | Time 68.7979(74.5182) | Bit/dim 3.4871(3.4958) | Xent 0.0000(0.0000) | Loss 8.3684(8.9231) | Error 0.0000(0.0000) Steps 670(680.74) | Grad Norm 0.6331(0.4831) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 24.0228, Epoch Time 486.1053(483.0249), Bit/dim 3.4989(best: 3.4917), Xent 0.0000, Loss 3.4989, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2167 | Time 73.8098(74.4970) | Bit/dim 3.5064(3.4961) | Xent 0.0000(0.0000) | Loss 12.3374(9.0256) | Error 0.0000(0.0000) Steps 694(681.14) | Grad Norm 0.5984(0.4866) | Total Time 0.00(0.00)\n",
      "Iter 2168 | Time 76.5413(74.5583) | Bit/dim 3.4977(3.4961) | Xent 0.0000(0.0000) | Loss 8.4577(9.0085) | Error 0.0000(0.0000) Steps 694(681.52) | Grad Norm 0.4084(0.4843) | Total Time 0.00(0.00)\n",
      "Iter 2169 | Time 77.7891(74.6552) | Bit/dim 3.4893(3.4959) | Xent 0.0000(0.0000) | Loss 8.4000(8.9903) | Error 0.0000(0.0000) Steps 688(681.72) | Grad Norm 0.2184(0.4763) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 73.4853(74.6201) | Bit/dim 3.4895(3.4957) | Xent 0.0000(0.0000) | Loss 8.0689(8.9626) | Error 0.0000(0.0000) Steps 646(680.64) | Grad Norm 0.4196(0.4746) | Total Time 0.00(0.00)\n",
      "Iter 2171 | Time 75.9557(74.6602) | Bit/dim 3.5130(3.4963) | Xent 0.0000(0.0000) | Loss 8.3991(8.9457) | Error 0.0000(0.0000) Steps 688(680.86) | Grad Norm 0.4449(0.4737) | Total Time 0.00(0.00)\n",
      "Iter 2172 | Time 70.3924(74.5322) | Bit/dim 3.4933(3.4962) | Xent 0.0000(0.0000) | Loss 8.2327(8.9243) | Error 0.0000(0.0000) Steps 658(680.18) | Grad Norm 0.4670(0.4735) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 24.4140, Epoch Time 488.4317(483.1871), Bit/dim 3.4984(best: 3.4917), Xent 0.0000, Loss 3.4984, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2173 | Time 76.0639(74.5781) | Bit/dim 3.4906(3.4960) | Xent 0.0000(0.0000) | Loss 12.1279(9.0205) | Error 0.0000(0.0000) Steps 676(680.05) | Grad Norm 0.4496(0.4728) | Total Time 0.00(0.00)\n",
      "Iter 2174 | Time 69.0738(74.4130) | Bit/dim 3.5029(3.4962) | Xent 0.0000(0.0000) | Loss 8.3484(9.0003) | Error 0.0000(0.0000) Steps 676(679.93) | Grad Norm 0.3697(0.4697) | Total Time 0.00(0.00)\n",
      "Iter 2175 | Time 68.2779(74.2289) | Bit/dim 3.4952(3.4962) | Xent 0.0000(0.0000) | Loss 8.3480(8.9807) | Error 0.0000(0.0000) Steps 664(679.45) | Grad Norm 0.2770(0.4639) | Total Time 0.00(0.00)\n",
      "Iter 2176 | Time 72.6989(74.1830) | Bit/dim 3.5012(3.4963) | Xent 0.0000(0.0000) | Loss 8.1110(8.9546) | Error 0.0000(0.0000) Steps 682(679.53) | Grad Norm 0.5745(0.4672) | Total Time 0.00(0.00)\n",
      "Iter 2177 | Time 75.3141(74.2170) | Bit/dim 3.4938(3.4963) | Xent 0.0000(0.0000) | Loss 8.5027(8.9411) | Error 0.0000(0.0000) Steps 712(680.50) | Grad Norm 0.3010(0.4622) | Total Time 0.00(0.00)\n",
      "Iter 2178 | Time 77.5484(74.3169) | Bit/dim 3.4894(3.4960) | Xent 0.0000(0.0000) | Loss 8.4718(8.9270) | Error 0.0000(0.0000) Steps 682(680.55) | Grad Norm 0.4650(0.4623) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 23.8077, Epoch Time 478.5707(483.0486), Bit/dim 3.4996(best: 3.4917), Xent 0.0000, Loss 3.4996, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2179 | Time 70.7399(74.2096) | Bit/dim 3.4874(3.4958) | Xent 0.0000(0.0000) | Loss 11.8953(9.0160) | Error 0.0000(0.0000) Steps 670(680.23) | Grad Norm 0.5492(0.4649) | Total Time 0.00(0.00)\n",
      "Iter 2180 | Time 72.3390(74.1535) | Bit/dim 3.5040(3.4960) | Xent 0.0000(0.0000) | Loss 8.5031(9.0007) | Error 0.0000(0.0000) Steps 688(680.47) | Grad Norm 0.5456(0.4673) | Total Time 0.00(0.00)\n",
      "Iter 2181 | Time 76.3602(74.2197) | Bit/dim 3.4947(3.4960) | Xent 0.0000(0.0000) | Loss 8.2326(8.9776) | Error 0.0000(0.0000) Steps 670(680.15) | Grad Norm 0.5219(0.4690) | Total Time 0.00(0.00)\n",
      "Iter 2182 | Time 74.9617(74.2419) | Bit/dim 3.4929(3.4959) | Xent 0.0000(0.0000) | Loss 8.4068(8.9605) | Error 0.0000(0.0000) Steps 676(680.03) | Grad Norm 0.3042(0.4640) | Total Time 0.00(0.00)\n",
      "Iter 2183 | Time 70.6647(74.1346) | Bit/dim 3.4978(3.4960) | Xent 0.0000(0.0000) | Loss 8.3738(8.9429) | Error 0.0000(0.0000) Steps 694(680.45) | Grad Norm 0.2231(0.4568) | Total Time 0.00(0.00)\n",
      "Iter 2184 | Time 75.8774(74.1869) | Bit/dim 3.4959(3.4960) | Xent 0.0000(0.0000) | Loss 8.4696(8.9287) | Error 0.0000(0.0000) Steps 682(680.49) | Grad Norm 0.3085(0.4524) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 24.0539, Epoch Time 481.0276(482.9880), Bit/dim 3.4958(best: 3.4917), Xent 0.0000, Loss 3.4958, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2185 | Time 73.9367(74.1794) | Bit/dim 3.4840(3.4956) | Xent 0.0000(0.0000) | Loss 12.2081(9.0271) | Error 0.0000(0.0000) Steps 682(680.54) | Grad Norm 0.8443(0.4641) | Total Time 0.00(0.00)\n",
      "Iter 2186 | Time 75.9256(74.2318) | Bit/dim 3.4938(3.4955) | Xent 0.0000(0.0000) | Loss 8.3753(9.0075) | Error 0.0000(0.0000) Steps 688(680.76) | Grad Norm 1.0842(0.4827) | Total Time 0.00(0.00)\n",
      "Iter 2187 | Time 73.2132(74.2012) | Bit/dim 3.4910(3.4954) | Xent 0.0000(0.0000) | Loss 8.3293(8.9872) | Error 0.0000(0.0000) Steps 682(680.80) | Grad Norm 1.2848(0.5068) | Total Time 0.00(0.00)\n",
      "Iter 2188 | Time 71.7738(74.1284) | Bit/dim 3.4980(3.4955) | Xent 0.0000(0.0000) | Loss 8.4073(8.9698) | Error 0.0000(0.0000) Steps 676(680.66) | Grad Norm 0.8981(0.5185) | Total Time 0.00(0.00)\n",
      "Iter 2189 | Time 72.6496(74.0840) | Bit/dim 3.4976(3.4956) | Xent 0.0000(0.0000) | Loss 8.5267(8.9565) | Error 0.0000(0.0000) Steps 682(680.70) | Grad Norm 0.7946(0.5268) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 75.9621(74.1404) | Bit/dim 3.5155(3.4962) | Xent 0.0000(0.0000) | Loss 8.4576(8.9415) | Error 0.0000(0.0000) Steps 688(680.91) | Grad Norm 0.6889(0.5317) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 23.6203, Epoch Time 483.4724(483.0025), Bit/dim 3.5034(best: 3.4917), Xent 0.0000, Loss 3.5034, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2191 | Time 71.3698(74.0573) | Bit/dim 3.4886(3.4959) | Xent 0.0000(0.0000) | Loss 12.3036(9.0424) | Error 0.0000(0.0000) Steps 670(680.59) | Grad Norm 0.4150(0.5282) | Total Time 0.00(0.00)\n",
      "Iter 2192 | Time 69.5985(73.9235) | Bit/dim 3.5026(3.4961) | Xent 0.0000(0.0000) | Loss 8.5712(9.0282) | Error 0.0000(0.0000) Steps 670(680.27) | Grad Norm 0.7061(0.5335) | Total Time 0.00(0.00)\n",
      "Iter 2193 | Time 74.7959(73.9497) | Bit/dim 3.4925(3.4960) | Xent 0.0000(0.0000) | Loss 8.3905(9.0091) | Error 0.0000(0.0000) Steps 670(679.96) | Grad Norm 0.8351(0.5426) | Total Time 0.00(0.00)\n",
      "Iter 2194 | Time 78.3605(74.0820) | Bit/dim 3.4975(3.4961) | Xent 0.0000(0.0000) | Loss 8.4511(8.9924) | Error 0.0000(0.0000) Steps 682(680.02) | Grad Norm 0.4143(0.5387) | Total Time 0.00(0.00)\n",
      "Iter 2195 | Time 78.2669(74.2075) | Bit/dim 3.4880(3.4958) | Xent 0.0000(0.0000) | Loss 8.4854(8.9772) | Error 0.0000(0.0000) Steps 700(680.62) | Grad Norm 0.4523(0.5361) | Total Time 0.00(0.00)\n",
      "Iter 2196 | Time 73.8023(74.1954) | Bit/dim 3.4847(3.4955) | Xent 0.0000(0.0000) | Loss 8.4259(8.9606) | Error 0.0000(0.0000) Steps 676(680.48) | Grad Norm 0.7609(0.5429) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 24.2706, Epoch Time 486.3011(483.1014), Bit/dim 3.4966(best: 3.4917), Xent 0.0000, Loss 3.4966, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2197 | Time 75.2602(74.2273) | Bit/dim 3.4986(3.4956) | Xent 0.0000(0.0000) | Loss 12.1738(9.0570) | Error 0.0000(0.0000) Steps 682(680.53) | Grad Norm 0.6453(0.5459) | Total Time 0.00(0.00)\n",
      "Iter 2198 | Time 75.4388(74.2637) | Bit/dim 3.4968(3.4956) | Xent 0.0000(0.0000) | Loss 8.2539(9.0329) | Error 0.0000(0.0000) Steps 670(680.21) | Grad Norm 0.7164(0.5510) | Total Time 0.00(0.00)\n",
      "Iter 2199 | Time 71.9746(74.1950) | Bit/dim 3.4956(3.4956) | Xent 0.0000(0.0000) | Loss 8.4896(9.0166) | Error 0.0000(0.0000) Steps 700(680.81) | Grad Norm 1.2076(0.5707) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 71.0159(74.0996) | Bit/dim 3.4882(3.4954) | Xent 0.0000(0.0000) | Loss 8.2513(8.9937) | Error 0.0000(0.0000) Steps 670(680.48) | Grad Norm 1.1182(0.5872) | Total Time 0.00(0.00)\n",
      "Iter 2201 | Time 73.9216(74.0943) | Bit/dim 3.4884(3.4952) | Xent 0.0000(0.0000) | Loss 8.2246(8.9706) | Error 0.0000(0.0000) Steps 664(679.99) | Grad Norm 0.7369(0.5917) | Total Time 0.00(0.00)\n",
      "Iter 2202 | Time 74.7193(74.1130) | Bit/dim 3.4970(3.4952) | Xent 0.0000(0.0000) | Loss 8.0948(8.9443) | Error 0.0000(0.0000) Steps 682(680.05) | Grad Norm 0.6754(0.5942) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 24.0476, Epoch Time 482.9240(483.0961), Bit/dim 3.4935(best: 3.4917), Xent 0.0000, Loss 3.4935, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2203 | Time 73.3883(74.0913) | Bit/dim 3.5030(3.4955) | Xent 0.0000(0.0000) | Loss 12.0674(9.0380) | Error 0.0000(0.0000) Steps 682(680.11) | Grad Norm 0.5393(0.5925) | Total Time 0.00(0.00)\n",
      "Iter 2204 | Time 71.3288(74.0084) | Bit/dim 3.4979(3.4955) | Xent 0.0000(0.0000) | Loss 8.3634(9.0178) | Error 0.0000(0.0000) Steps 676(679.98) | Grad Norm 0.4692(0.5888) | Total Time 0.00(0.00)\n",
      "Iter 2205 | Time 73.2346(73.9852) | Bit/dim 3.4870(3.4953) | Xent 0.0000(0.0000) | Loss 8.1765(8.9925) | Error 0.0000(0.0000) Steps 652(679.14) | Grad Norm 0.7802(0.5946) | Total Time 0.00(0.00)\n",
      "Iter 2206 | Time 79.7431(74.1579) | Bit/dim 3.4890(3.4951) | Xent 0.0000(0.0000) | Loss 8.3602(8.9736) | Error 0.0000(0.0000) Steps 688(679.41) | Grad Norm 0.5255(0.5925) | Total Time 0.00(0.00)\n",
      "Iter 2207 | Time 72.7174(74.1147) | Bit/dim 3.4903(3.4950) | Xent 0.0000(0.0000) | Loss 8.4094(8.9566) | Error 0.0000(0.0000) Steps 682(679.49) | Grad Norm 0.4007(0.5867) | Total Time 0.00(0.00)\n",
      "Iter 2208 | Time 72.7746(74.0745) | Bit/dim 3.4987(3.4951) | Xent 0.0000(0.0000) | Loss 8.2365(8.9350) | Error 0.0000(0.0000) Steps 664(679.02) | Grad Norm 0.8848(0.5957) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 23.5686, Epoch Time 482.7801(483.0866), Bit/dim 3.5003(best: 3.4917), Xent 0.0000, Loss 3.5003, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2209 | Time 80.6890(74.2730) | Bit/dim 3.4939(3.4950) | Xent 0.0000(0.0000) | Loss 12.3242(9.0367) | Error 0.0000(0.0000) Steps 724(680.37) | Grad Norm 0.7231(0.5995) | Total Time 0.00(0.00)\n",
      "Iter 2210 | Time 74.6665(74.2848) | Bit/dim 3.4894(3.4949) | Xent 0.0000(0.0000) | Loss 8.4136(9.0180) | Error 0.0000(0.0000) Steps 688(680.60) | Grad Norm 0.6729(0.6017) | Total Time 0.00(0.00)\n",
      "Iter 2211 | Time 77.4518(74.3798) | Bit/dim 3.4906(3.4947) | Xent 0.0000(0.0000) | Loss 8.1659(8.9925) | Error 0.0000(0.0000) Steps 688(680.82) | Grad Norm 1.2006(0.6197) | Total Time 0.00(0.00)\n",
      "Iter 2212 | Time 73.9589(74.3671) | Bit/dim 3.4930(3.4947) | Xent 0.0000(0.0000) | Loss 8.4101(8.9750) | Error 0.0000(0.0000) Steps 658(680.14) | Grad Norm 0.7061(0.6223) | Total Time 0.00(0.00)\n",
      "Iter 2213 | Time 80.0247(74.5369) | Bit/dim 3.4906(3.4946) | Xent 0.0000(0.0000) | Loss 8.3271(8.9555) | Error 0.0000(0.0000) Steps 694(680.55) | Grad Norm 0.3851(0.6152) | Total Time 0.00(0.00)\n",
      "Iter 2214 | Time 75.7111(74.5721) | Bit/dim 3.4975(3.4946) | Xent 0.0000(0.0000) | Loss 8.3554(8.9375) | Error 0.0000(0.0000) Steps 694(680.96) | Grad Norm 0.9068(0.6239) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 23.5581, Epoch Time 501.7334(483.6460), Bit/dim 3.4970(best: 3.4917), Xent 0.0000, Loss 3.4970, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2215 | Time 71.1168(74.4684) | Bit/dim 3.5012(3.4948) | Xent 0.0000(0.0000) | Loss 12.2133(9.0358) | Error 0.0000(0.0000) Steps 682(680.99) | Grad Norm 0.8117(0.6295) | Total Time 0.00(0.00)\n",
      "Iter 2216 | Time 76.5436(74.5307) | Bit/dim 3.5021(3.4951) | Xent 0.0000(0.0000) | Loss 8.0948(9.0076) | Error 0.0000(0.0000) Steps 682(681.02) | Grad Norm 0.7170(0.6322) | Total Time 0.00(0.00)\n",
      "Iter 2217 | Time 74.3917(74.5265) | Bit/dim 3.4901(3.4949) | Xent 0.0000(0.0000) | Loss 8.3347(8.9874) | Error 0.0000(0.0000) Steps 670(680.69) | Grad Norm 0.6450(0.6325) | Total Time 0.00(0.00)\n",
      "Iter 2218 | Time 74.6946(74.5316) | Bit/dim 3.4895(3.4947) | Xent 0.0000(0.0000) | Loss 8.3745(8.9690) | Error 0.0000(0.0000) Steps 688(680.91) | Grad Norm 0.9233(0.6413) | Total Time 0.00(0.00)\n",
      "Iter 2219 | Time 75.6765(74.5659) | Bit/dim 3.4986(3.4949) | Xent 0.0000(0.0000) | Loss 8.3936(8.9517) | Error 0.0000(0.0000) Steps 682(680.94) | Grad Norm 1.0851(0.6546) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 83.4509(74.8325) | Bit/dim 3.4930(3.4948) | Xent 0.0000(0.0000) | Loss 8.4725(8.9374) | Error 0.0000(0.0000) Steps 712(681.87) | Grad Norm 1.0741(0.6672) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 24.0687, Epoch Time 495.3073(483.9959), Bit/dim 3.4975(best: 3.4917), Xent 0.0000, Loss 3.4975, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2221 | Time 71.9412(74.7457) | Bit/dim 3.5030(3.4951) | Xent 0.0000(0.0000) | Loss 12.4023(9.0413) | Error 0.0000(0.0000) Steps 682(681.88) | Grad Norm 0.9234(0.6749) | Total Time 0.00(0.00)\n",
      "Iter 2222 | Time 71.7847(74.6569) | Bit/dim 3.4887(3.4949) | Xent 0.0000(0.0000) | Loss 8.3357(9.0202) | Error 0.0000(0.0000) Steps 670(681.52) | Grad Norm 0.5534(0.6712) | Total Time 0.00(0.00)\n",
      "Iter 2223 | Time 71.6559(74.5669) | Bit/dim 3.4754(3.4943) | Xent 0.0000(0.0000) | Loss 8.3281(8.9994) | Error 0.0000(0.0000) Steps 658(680.81) | Grad Norm 0.2406(0.6583) | Total Time 0.00(0.00)\n",
      "Iter 2224 | Time 78.3041(74.6790) | Bit/dim 3.4993(3.4944) | Xent 0.0000(0.0000) | Loss 8.3711(8.9805) | Error 0.0000(0.0000) Steps 682(680.85) | Grad Norm 0.6441(0.6579) | Total Time 0.00(0.00)\n",
      "Iter 2225 | Time 73.1789(74.6340) | Bit/dim 3.4865(3.4942) | Xent 0.0000(0.0000) | Loss 8.4588(8.9649) | Error 0.0000(0.0000) Steps 688(681.06) | Grad Norm 1.0260(0.6689) | Total Time 0.00(0.00)\n",
      "Iter 2226 | Time 77.2071(74.7112) | Bit/dim 3.5149(3.4948) | Xent 0.0000(0.0000) | Loss 8.5336(8.9520) | Error 0.0000(0.0000) Steps 688(681.27) | Grad Norm 1.0891(0.6815) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 23.8667, Epoch Time 483.9800(483.9954), Bit/dim 3.4985(best: 3.4917), Xent 0.0000, Loss 3.4985, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2227 | Time 67.2163(74.4863) | Bit/dim 3.4936(3.4948) | Xent 0.0000(0.0000) | Loss 12.0523(9.0450) | Error 0.0000(0.0000) Steps 670(680.93) | Grad Norm 1.0402(0.6923) | Total Time 0.00(0.00)\n",
      "Iter 2228 | Time 76.1481(74.5362) | Bit/dim 3.4882(3.4946) | Xent 0.0000(0.0000) | Loss 8.1956(9.0195) | Error 0.0000(0.0000) Steps 658(680.25) | Grad Norm 0.9633(0.7004) | Total Time 0.00(0.00)\n",
      "Iter 2229 | Time 73.1281(74.4939) | Bit/dim 3.5050(3.4949) | Xent 0.0000(0.0000) | Loss 8.3705(9.0000) | Error 0.0000(0.0000) Steps 670(679.94) | Grad Norm 0.7707(0.7025) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 70.1709(74.3643) | Bit/dim 3.4907(3.4948) | Xent 0.0000(0.0000) | Loss 8.1398(8.9742) | Error 0.0000(0.0000) Steps 664(679.46) | Grad Norm 0.4781(0.6958) | Total Time 0.00(0.00)\n",
      "Iter 2231 | Time 73.8768(74.3496) | Bit/dim 3.4965(3.4948) | Xent 0.0000(0.0000) | Loss 8.3668(8.9560) | Error 0.0000(0.0000) Steps 682(679.54) | Grad Norm 0.5988(0.6929) | Total Time 0.00(0.00)\n",
      "Iter 2232 | Time 75.5937(74.3869) | Bit/dim 3.4833(3.4945) | Xent 0.0000(0.0000) | Loss 8.2701(8.9354) | Error 0.0000(0.0000) Steps 706(680.33) | Grad Norm 1.0591(0.7039) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 23.9181, Epoch Time 476.3139(483.7650), Bit/dim 3.4960(best: 3.4917), Xent 0.0000, Loss 3.4960, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2233 | Time 75.3474(74.4158) | Bit/dim 3.4766(3.4939) | Xent 0.0000(0.0000) | Loss 11.9748(9.0266) | Error 0.0000(0.0000) Steps 688(680.56) | Grad Norm 1.5097(0.7280) | Total Time 0.00(0.00)\n",
      "Iter 2234 | Time 74.3587(74.4141) | Bit/dim 3.4988(3.4941) | Xent 0.0000(0.0000) | Loss 8.3786(9.0071) | Error 0.0000(0.0000) Steps 670(680.24) | Grad Norm 1.8386(0.7614) | Total Time 0.00(0.00)\n",
      "Iter 2235 | Time 74.1413(74.4059) | Bit/dim 3.5016(3.4943) | Xent 0.0000(0.0000) | Loss 8.5510(8.9935) | Error 0.0000(0.0000) Steps 682(680.30) | Grad Norm 1.7728(0.7917) | Total Time 0.00(0.00)\n",
      "Iter 2236 | Time 75.9531(74.4523) | Bit/dim 3.4963(3.4944) | Xent 0.0000(0.0000) | Loss 8.2509(8.9712) | Error 0.0000(0.0000) Steps 688(680.53) | Grad Norm 1.3905(0.8097) | Total Time 0.00(0.00)\n",
      "Iter 2237 | Time 72.8715(74.4049) | Bit/dim 3.5000(3.4945) | Xent 0.0000(0.0000) | Loss 8.4318(8.9550) | Error 0.0000(0.0000) Steps 670(680.21) | Grad Norm 0.6118(0.8037) | Total Time 0.00(0.00)\n",
      "Iter 2238 | Time 72.2230(74.3394) | Bit/dim 3.4914(3.4944) | Xent 0.0000(0.0000) | Loss 8.2239(8.9331) | Error 0.0000(0.0000) Steps 670(679.91) | Grad Norm 0.6755(0.7999) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 24.7029, Epoch Time 485.2843(483.8105), Bit/dim 3.4987(best: 3.4917), Xent 0.0000, Loss 3.4987, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2239 | Time 80.9314(74.5372) | Bit/dim 3.5080(3.4949) | Xent 0.0000(0.0000) | Loss 12.2863(9.0337) | Error 0.0000(0.0000) Steps 712(680.87) | Grad Norm 1.3597(0.8167) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 75.3599(74.5618) | Bit/dim 3.4996(3.4950) | Xent 0.0000(0.0000) | Loss 7.9519(9.0012) | Error 0.0000(0.0000) Steps 676(680.72) | Grad Norm 1.8634(0.8481) | Total Time 0.00(0.00)\n",
      "Iter 2241 | Time 72.1002(74.4880) | Bit/dim 3.4846(3.4947) | Xent 0.0000(0.0000) | Loss 8.3932(8.9830) | Error 0.0000(0.0000) Steps 676(680.58) | Grad Norm 1.9064(0.8798) | Total Time 0.00(0.00)\n",
      "Iter 2242 | Time 76.8020(74.5574) | Bit/dim 3.4949(3.4947) | Xent 0.0000(0.0000) | Loss 8.5545(8.9701) | Error 0.0000(0.0000) Steps 718(681.70) | Grad Norm 1.6268(0.9022) | Total Time 0.00(0.00)\n",
      "Iter 2243 | Time 70.3587(74.4315) | Bit/dim 3.4935(3.4947) | Xent 0.0000(0.0000) | Loss 8.3442(8.9513) | Error 0.0000(0.0000) Steps 676(681.53) | Grad Norm 1.1386(0.9093) | Total Time 0.00(0.00)\n",
      "Iter 2244 | Time 71.0753(74.3308) | Bit/dim 3.4888(3.4945) | Xent 0.0000(0.0000) | Loss 8.3242(8.9325) | Error 0.0000(0.0000) Steps 676(681.37) | Grad Norm 0.5212(0.8977) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 24.1269, Epoch Time 486.6635(483.8961), Bit/dim 3.4966(best: 3.4917), Xent 0.0000, Loss 3.4966, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2245 | Time 70.9213(74.2285) | Bit/dim 3.4993(3.4946) | Xent 0.0000(0.0000) | Loss 11.8531(9.0201) | Error 0.0000(0.0000) Steps 658(680.67) | Grad Norm 0.5884(0.8884) | Total Time 0.00(0.00)\n",
      "Iter 2246 | Time 74.0030(74.2217) | Bit/dim 3.4950(3.4946) | Xent 0.0000(0.0000) | Loss 8.2735(8.9977) | Error 0.0000(0.0000) Steps 676(680.53) | Grad Norm 0.6572(0.8815) | Total Time 0.00(0.00)\n",
      "Iter 2247 | Time 67.7015(74.0261) | Bit/dim 3.4929(3.4946) | Xent 0.0000(0.0000) | Loss 8.4069(8.9800) | Error 0.0000(0.0000) Steps 670(680.21) | Grad Norm 0.8029(0.8791) | Total Time 0.00(0.00)\n",
      "Iter 2248 | Time 74.8990(74.0523) | Bit/dim 3.4968(3.4946) | Xent 0.0000(0.0000) | Loss 8.4181(8.9632) | Error 0.0000(0.0000) Steps 694(680.62) | Grad Norm 1.1509(0.8873) | Total Time 0.00(0.00)\n",
      "Iter 2249 | Time 75.7111(74.1021) | Bit/dim 3.4828(3.4943) | Xent 0.0000(0.0000) | Loss 8.3625(8.9451) | Error 0.0000(0.0000) Steps 688(680.84) | Grad Norm 1.4809(0.9051) | Total Time 0.00(0.00)\n",
      "Iter 2250 | Time 72.3613(74.0498) | Bit/dim 3.4999(3.4945) | Xent 0.0000(0.0000) | Loss 8.3032(8.9259) | Error 0.0000(0.0000) Steps 682(680.88) | Grad Norm 1.5554(0.9246) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 23.9839, Epoch Time 475.2916(483.6380), Bit/dim 3.4948(best: 3.4917), Xent 0.0000, Loss 3.4948, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2251 | Time 70.3476(73.9388) | Bit/dim 3.5003(3.4946) | Xent 0.0000(0.0000) | Loss 12.1433(9.0224) | Error 0.0000(0.0000) Steps 670(680.55) | Grad Norm 1.3629(0.9377) | Total Time 0.00(0.00)\n",
      "Iter 2252 | Time 77.4027(74.0427) | Bit/dim 3.4913(3.4945) | Xent 0.0000(0.0000) | Loss 8.4742(9.0060) | Error 0.0000(0.0000) Steps 706(681.32) | Grad Norm 1.0200(0.9402) | Total Time 0.00(0.00)\n",
      "Iter 2253 | Time 75.1525(74.0760) | Bit/dim 3.4956(3.4946) | Xent 0.0000(0.0000) | Loss 8.3951(8.9876) | Error 0.0000(0.0000) Steps 682(681.34) | Grad Norm 0.5707(0.9291) | Total Time 0.00(0.00)\n",
      "Iter 2254 | Time 75.2559(74.1114) | Bit/dim 3.4769(3.4940) | Xent 0.0000(0.0000) | Loss 8.3561(8.9687) | Error 0.0000(0.0000) Steps 694(681.72) | Grad Norm 0.2728(0.9094) | Total Time 0.00(0.00)\n",
      "Iter 2255 | Time 72.9352(74.0761) | Bit/dim 3.4877(3.4938) | Xent 0.0000(0.0000) | Loss 8.1109(8.9430) | Error 0.0000(0.0000) Steps 658(681.01) | Grad Norm 0.5737(0.8994) | Total Time 0.00(0.00)\n",
      "Iter 2256 | Time 77.3607(74.1746) | Bit/dim 3.4954(3.4939) | Xent 0.0000(0.0000) | Loss 8.3520(8.9252) | Error 0.0000(0.0000) Steps 676(680.86) | Grad Norm 0.7958(0.8962) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 23.2712, Epoch Time 487.7645(483.7618), Bit/dim 3.5021(best: 3.4917), Xent 0.0000, Loss 3.5021, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2257 | Time 74.6528(74.1890) | Bit/dim 3.5002(3.4941) | Xent 0.0000(0.0000) | Loss 11.9258(9.0152) | Error 0.0000(0.0000) Steps 670(680.53) | Grad Norm 1.0604(0.9012) | Total Time 0.00(0.00)\n",
      "Iter 2258 | Time 76.1945(74.2491) | Bit/dim 3.4955(3.4941) | Xent 0.0000(0.0000) | Loss 8.4925(8.9996) | Error 0.0000(0.0000) Steps 700(681.11) | Grad Norm 1.2729(0.9123) | Total Time 0.00(0.00)\n",
      "Iter 2259 | Time 71.2733(74.1599) | Bit/dim 3.4869(3.4939) | Xent 0.0000(0.0000) | Loss 8.3503(8.9801) | Error 0.0000(0.0000) Steps 682(681.14) | Grad Norm 1.3231(0.9246) | Total Time 0.00(0.00)\n",
      "Iter 2260 | Time 73.4976(74.1400) | Bit/dim 3.4940(3.4939) | Xent 0.0000(0.0000) | Loss 8.4997(8.9657) | Error 0.0000(0.0000) Steps 700(681.71) | Grad Norm 1.2009(0.9329) | Total Time 0.00(0.00)\n",
      "Iter 2261 | Time 72.6691(74.0959) | Bit/dim 3.4837(3.4936) | Xent 0.0000(0.0000) | Loss 8.4263(8.9495) | Error 0.0000(0.0000) Steps 694(682.07) | Grad Norm 1.1221(0.9386) | Total Time 0.00(0.00)\n",
      "Iter 2262 | Time 75.5760(74.1403) | Bit/dim 3.4948(3.4936) | Xent 0.0000(0.0000) | Loss 8.4210(8.9336) | Error 0.0000(0.0000) Steps 676(681.89) | Grad Norm 1.0520(0.9420) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 24.1528, Epoch Time 484.5799(483.7863), Bit/dim 3.4956(best: 3.4917), Xent 0.0000, Loss 3.4956, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2263 | Time 71.8763(74.0724) | Bit/dim 3.4848(3.4934) | Xent 0.0000(0.0000) | Loss 12.2981(9.0346) | Error 0.0000(0.0000) Steps 682(681.90) | Grad Norm 0.9700(0.9428) | Total Time 0.00(0.00)\n",
      "Iter 2264 | Time 74.2762(74.0785) | Bit/dim 3.4910(3.4933) | Xent 0.0000(0.0000) | Loss 8.2083(9.0098) | Error 0.0000(0.0000) Steps 664(681.36) | Grad Norm 1.0208(0.9452) | Total Time 0.00(0.00)\n",
      "Iter 2265 | Time 73.4404(74.0593) | Bit/dim 3.4891(3.4932) | Xent 0.0000(0.0000) | Loss 8.2724(8.9877) | Error 0.0000(0.0000) Steps 658(680.66) | Grad Norm 1.2264(0.9536) | Total Time 0.00(0.00)\n",
      "Iter 2266 | Time 73.9716(74.0567) | Bit/dim 3.5014(3.4934) | Xent 0.0000(0.0000) | Loss 8.4957(8.9729) | Error 0.0000(0.0000) Steps 694(681.06) | Grad Norm 1.3584(0.9658) | Total Time 0.00(0.00)\n",
      "Iter 2267 | Time 73.3784(74.0364) | Bit/dim 3.5085(3.4939) | Xent 0.0000(0.0000) | Loss 8.3383(8.9539) | Error 0.0000(0.0000) Steps 676(680.91) | Grad Norm 1.2805(0.9752) | Total Time 0.00(0.00)\n",
      "Iter 2268 | Time 70.0239(73.9160) | Bit/dim 3.4870(3.4937) | Xent 0.0000(0.0000) | Loss 8.2911(8.9340) | Error 0.0000(0.0000) Steps 658(680.22) | Grad Norm 1.1113(0.9793) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 23.8554, Epoch Time 476.7042(483.5739), Bit/dim 3.4931(best: 3.4917), Xent 0.0000, Loss 3.4931, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2269 | Time 77.3605(74.0193) | Bit/dim 3.4987(3.4938) | Xent 0.0000(0.0000) | Loss 11.9250(9.0237) | Error 0.0000(0.0000) Steps 694(680.63) | Grad Norm 0.8966(0.9768) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 71.7589(73.9515) | Bit/dim 3.4871(3.4936) | Xent 0.0000(0.0000) | Loss 8.4172(9.0055) | Error 0.0000(0.0000) Steps 694(681.03) | Grad Norm 0.5945(0.9653) | Total Time 0.00(0.00)\n",
      "Iter 2271 | Time 76.6946(74.0338) | Bit/dim 3.4912(3.4936) | Xent 0.0000(0.0000) | Loss 8.3555(8.9860) | Error 0.0000(0.0000) Steps 676(680.88) | Grad Norm 0.2536(0.9440) | Total Time 0.00(0.00)\n",
      "Iter 2272 | Time 74.9481(74.0612) | Bit/dim 3.4900(3.4934) | Xent 0.0000(0.0000) | Loss 8.1738(8.9617) | Error 0.0000(0.0000) Steps 688(681.10) | Grad Norm 0.5595(0.9325) | Total Time 0.00(0.00)\n",
      "Iter 2273 | Time 67.1849(73.8549) | Bit/dim 3.4951(3.4935) | Xent 0.0000(0.0000) | Loss 8.3022(8.9419) | Error 0.0000(0.0000) Steps 664(680.58) | Grad Norm 0.6126(0.9229) | Total Time 0.00(0.00)\n",
      "Iter 2274 | Time 76.8923(73.9461) | Bit/dim 3.4921(3.4935) | Xent 0.0000(0.0000) | Loss 8.3519(8.9242) | Error 0.0000(0.0000) Steps 712(681.53) | Grad Norm 0.8015(0.9192) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 24.2318, Epoch Time 484.9512(483.6152), Bit/dim 3.4947(best: 3.4917), Xent 0.0000, Loss 3.4947, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2275 | Time 72.8469(73.9131) | Bit/dim 3.4921(3.4934) | Xent 0.0000(0.0000) | Loss 12.3379(9.0266) | Error 0.0000(0.0000) Steps 700(682.08) | Grad Norm 1.0942(0.9245) | Total Time 0.00(0.00)\n",
      "Iter 2276 | Time 73.8520(73.9113) | Bit/dim 3.4947(3.4935) | Xent 0.0000(0.0000) | Loss 8.2017(9.0018) | Error 0.0000(0.0000) Steps 676(681.90) | Grad Norm 1.3797(0.9381) | Total Time 0.00(0.00)\n",
      "Iter 2277 | Time 72.3764(73.8652) | Bit/dim 3.4826(3.4931) | Xent 0.0000(0.0000) | Loss 8.3366(8.9819) | Error 0.0000(0.0000) Steps 670(681.54) | Grad Norm 1.4690(0.9541) | Total Time 0.00(0.00)\n",
      "Iter 2278 | Time 72.3476(73.8197) | Bit/dim 3.4943(3.4932) | Xent 0.0000(0.0000) | Loss 8.3120(8.9618) | Error 0.0000(0.0000) Steps 700(682.09) | Grad Norm 1.6252(0.9742) | Total Time 0.00(0.00)\n",
      "Iter 2279 | Time 73.0608(73.7969) | Bit/dim 3.4977(3.4933) | Xent 0.0000(0.0000) | Loss 8.2776(8.9413) | Error 0.0000(0.0000) Steps 670(681.73) | Grad Norm 1.6355(0.9940) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 76.1139(73.8664) | Bit/dim 3.4973(3.4934) | Xent 0.0000(0.0000) | Loss 8.4100(8.9253) | Error 0.0000(0.0000) Steps 700(682.28) | Grad Norm 1.5739(1.0114) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 24.6089, Epoch Time 481.3512(483.5473), Bit/dim 3.4921(best: 3.4917), Xent 0.0000, Loss 3.4921, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2281 | Time 77.5023(73.9755) | Bit/dim 3.4774(3.4929) | Xent 0.0000(0.0000) | Loss 12.2128(9.0239) | Error 0.0000(0.0000) Steps 706(682.99) | Grad Norm 1.4377(1.0242) | Total Time 0.00(0.00)\n",
      "Iter 2282 | Time 70.5974(73.8742) | Bit/dim 3.5119(3.4935) | Xent 0.0000(0.0000) | Loss 8.5385(9.0094) | Error 0.0000(0.0000) Steps 688(683.14) | Grad Norm 1.2991(1.0325) | Total Time 0.00(0.00)\n",
      "Iter 2283 | Time 75.9980(73.9379) | Bit/dim 3.4980(3.4936) | Xent 0.0000(0.0000) | Loss 8.4954(8.9940) | Error 0.0000(0.0000) Steps 700(683.65) | Grad Norm 1.3026(1.0406) | Total Time 0.00(0.00)\n",
      "Iter 2284 | Time 74.8081(73.9640) | Bit/dim 3.4882(3.4935) | Xent 0.0000(0.0000) | Loss 8.0776(8.9665) | Error 0.0000(0.0000) Steps 682(683.60) | Grad Norm 1.2597(1.0471) | Total Time 0.00(0.00)\n",
      "Iter 2285 | Time 75.7727(74.0182) | Bit/dim 3.4974(3.4936) | Xent 0.0000(0.0000) | Loss 8.4818(8.9519) | Error 0.0000(0.0000) Steps 694(683.91) | Grad Norm 1.1218(1.0494) | Total Time 0.00(0.00)\n",
      "Iter 2286 | Time 69.3466(73.8781) | Bit/dim 3.4877(3.4934) | Xent 0.0000(0.0000) | Loss 8.3132(8.9328) | Error 0.0000(0.0000) Steps 676(683.67) | Grad Norm 1.0709(1.0500) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 25.0169, Epoch Time 485.0204(483.5915), Bit/dim 3.4963(best: 3.4917), Xent 0.0000, Loss 3.4963, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2287 | Time 78.6075(74.0200) | Bit/dim 3.4937(3.4934) | Xent 0.0000(0.0000) | Loss 12.5418(9.0410) | Error 0.0000(0.0000) Steps 712(684.52) | Grad Norm 1.0849(1.0511) | Total Time 0.00(0.00)\n",
      "Iter 2288 | Time 71.0827(73.9319) | Bit/dim 3.4859(3.4932) | Xent 0.0000(0.0000) | Loss 8.2319(9.0168) | Error 0.0000(0.0000) Steps 694(684.81) | Grad Norm 1.0399(1.0507) | Total Time 0.00(0.00)\n",
      "Iter 2289 | Time 74.7138(73.9553) | Bit/dim 3.5087(3.4937) | Xent 0.0000(0.0000) | Loss 8.3866(8.9979) | Error 0.0000(0.0000) Steps 700(685.26) | Grad Norm 1.0328(1.0502) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 76.6403(74.0359) | Bit/dim 3.4932(3.4937) | Xent 0.0000(0.0000) | Loss 8.4891(8.9826) | Error 0.0000(0.0000) Steps 712(686.06) | Grad Norm 1.0399(1.0499) | Total Time 0.00(0.00)\n",
      "Iter 2291 | Time 78.5015(74.1698) | Bit/dim 3.4883(3.4935) | Xent 0.0000(0.0000) | Loss 8.5238(8.9688) | Error 0.0000(0.0000) Steps 712(686.84) | Grad Norm 1.0623(1.0503) | Total Time 0.00(0.00)\n",
      "Iter 2292 | Time 72.3776(74.1161) | Bit/dim 3.4910(3.4934) | Xent 0.0000(0.0000) | Loss 8.3875(8.9514) | Error 0.0000(0.0000) Steps 694(687.06) | Grad Norm 1.2860(1.0573) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 24.1401, Epoch Time 491.9604(483.8425), Bit/dim 3.4974(best: 3.4917), Xent 0.0000, Loss 3.4974, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2293 | Time 77.1448(74.2069) | Bit/dim 3.4885(3.4933) | Xent 0.0000(0.0000) | Loss 11.8419(9.0381) | Error 0.0000(0.0000) Steps 682(686.91) | Grad Norm 1.6722(1.0758) | Total Time 0.00(0.00)\n",
      "Iter 2294 | Time 73.6718(74.1909) | Bit/dim 3.4953(3.4933) | Xent 0.0000(0.0000) | Loss 8.4624(9.0208) | Error 0.0000(0.0000) Steps 694(687.12) | Grad Norm 1.9895(1.1032) | Total Time 0.00(0.00)\n",
      "Iter 2295 | Time 74.4718(74.1993) | Bit/dim 3.4944(3.4934) | Xent 0.0000(0.0000) | Loss 8.3149(8.9997) | Error 0.0000(0.0000) Steps 682(686.97) | Grad Norm 2.2077(1.1363) | Total Time 0.00(0.00)\n",
      "Iter 2296 | Time 74.0388(74.1945) | Bit/dim 3.4931(3.4934) | Xent 0.0000(0.0000) | Loss 8.5217(8.9853) | Error 0.0000(0.0000) Steps 700(687.36) | Grad Norm 2.1172(1.1658) | Total Time 0.00(0.00)\n",
      "Iter 2297 | Time 73.2031(74.1647) | Bit/dim 3.4887(3.4932) | Xent 0.0000(0.0000) | Loss 8.1712(8.9609) | Error 0.0000(0.0000) Steps 688(687.38) | Grad Norm 1.9143(1.1882) | Total Time 0.00(0.00)\n",
      "Iter 2298 | Time 77.2926(74.2586) | Bit/dim 3.4898(3.4931) | Xent 0.0000(0.0000) | Loss 8.3023(8.9411) | Error 0.0000(0.0000) Steps 676(687.03) | Grad Norm 1.3939(1.1944) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 24.2226, Epoch Time 489.7488(484.0197), Bit/dim 3.4905(best: 3.4917), Xent 0.0000, Loss 3.4905, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2299 | Time 75.8204(74.3054) | Bit/dim 3.4984(3.4933) | Xent 0.0000(0.0000) | Loss 11.5880(9.0205) | Error 0.0000(0.0000) Steps 670(686.52) | Grad Norm 0.7496(1.1810) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 73.5471(74.2827) | Bit/dim 3.4892(3.4932) | Xent 0.0000(0.0000) | Loss 8.3912(9.0017) | Error 0.0000(0.0000) Steps 682(686.39) | Grad Norm 0.4622(1.1595) | Total Time 0.00(0.00)\n",
      "Iter 2301 | Time 75.5219(74.3199) | Bit/dim 3.4914(3.4931) | Xent 0.0000(0.0000) | Loss 8.4969(8.9865) | Error 0.0000(0.0000) Steps 694(686.62) | Grad Norm 0.8942(1.1515) | Total Time 0.00(0.00)\n",
      "Iter 2302 | Time 75.6525(74.3598) | Bit/dim 3.4874(3.4929) | Xent 0.0000(0.0000) | Loss 8.4095(8.9692) | Error 0.0000(0.0000) Steps 682(686.48) | Grad Norm 1.2526(1.1545) | Total Time 0.00(0.00)\n",
      "Iter 2303 | Time 76.7591(74.4318) | Bit/dim 3.4959(3.4930) | Xent 0.0000(0.0000) | Loss 8.2432(8.9474) | Error 0.0000(0.0000) Steps 676(686.16) | Grad Norm 1.7307(1.1718) | Total Time 0.00(0.00)\n",
      "Iter 2304 | Time 72.6958(74.3797) | Bit/dim 3.5005(3.4932) | Xent 0.0000(0.0000) | Loss 8.4417(8.9323) | Error 0.0000(0.0000) Steps 682(686.04) | Grad Norm 2.1737(1.2019) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 24.0619, Epoch Time 489.6365(484.1882), Bit/dim 3.4897(best: 3.4905), Xent 0.0000, Loss 3.4897, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2305 | Time 71.0018(74.2784) | Bit/dim 3.4919(3.4932) | Xent 0.0000(0.0000) | Loss 12.1347(9.0283) | Error 0.0000(0.0000) Steps 682(685.92) | Grad Norm 2.3298(1.2357) | Total Time 0.00(0.00)\n",
      "Iter 2306 | Time 71.1059(74.1832) | Bit/dim 3.4967(3.4933) | Xent 0.0000(0.0000) | Loss 8.1627(9.0024) | Error 0.0000(0.0000) Steps 664(685.26) | Grad Norm 1.9243(1.2564) | Total Time 0.00(0.00)\n",
      "Iter 2307 | Time 74.1406(74.1819) | Bit/dim 3.4851(3.4931) | Xent 0.0000(0.0000) | Loss 8.4213(8.9849) | Error 0.0000(0.0000) Steps 682(685.16) | Grad Norm 1.4954(1.2635) | Total Time 0.00(0.00)\n",
      "Iter 2308 | Time 79.0119(74.3268) | Bit/dim 3.4930(3.4931) | Xent 0.0000(0.0000) | Loss 8.3451(8.9657) | Error 0.0000(0.0000) Steps 682(685.07) | Grad Norm 1.3590(1.2664) | Total Time 0.00(0.00)\n",
      "Iter 2309 | Time 66.5861(74.0946) | Bit/dim 3.4914(3.4930) | Xent 0.0000(0.0000) | Loss 8.0161(8.9372) | Error 0.0000(0.0000) Steps 658(684.25) | Grad Norm 1.0015(1.2585) | Total Time 0.00(0.00)\n",
      "Iter 2310 | Time 75.3129(74.1312) | Bit/dim 3.4951(3.4931) | Xent 0.0000(0.0000) | Loss 8.5262(8.9249) | Error 0.0000(0.0000) Steps 700(684.73) | Grad Norm 0.3169(1.2302) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 24.4587, Epoch Time 477.4010(483.9846), Bit/dim 3.4993(best: 3.4897), Xent 0.0000, Loss 3.4993, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2311 | Time 71.1103(74.0405) | Bit/dim 3.4885(3.4929) | Xent 0.0000(0.0000) | Loss 12.2752(9.0254) | Error 0.0000(0.0000) Steps 682(684.65) | Grad Norm 0.5750(1.2106) | Total Time 0.00(0.00)\n",
      "Iter 2312 | Time 71.2775(73.9576) | Bit/dim 3.4844(3.4927) | Xent 0.0000(0.0000) | Loss 8.3369(9.0048) | Error 0.0000(0.0000) Steps 682(684.57) | Grad Norm 1.1164(1.2077) | Total Time 0.00(0.00)\n",
      "Iter 2313 | Time 72.5580(73.9157) | Bit/dim 3.4863(3.4925) | Xent 0.0000(0.0000) | Loss 8.4936(8.9894) | Error 0.0000(0.0000) Steps 688(684.67) | Grad Norm 1.7521(1.2241) | Total Time 0.00(0.00)\n",
      "Iter 2314 | Time 77.4237(74.0209) | Bit/dim 3.4888(3.4924) | Xent 0.0000(0.0000) | Loss 8.3589(8.9705) | Error 0.0000(0.0000) Steps 676(684.41) | Grad Norm 2.4077(1.2596) | Total Time 0.00(0.00)\n",
      "Iter 2315 | Time 71.3041(73.9394) | Bit/dim 3.4900(3.4923) | Xent 0.0000(0.0000) | Loss 8.0884(8.9440) | Error 0.0000(0.0000) Steps 700(684.88) | Grad Norm 2.5711(1.2989) | Total Time 0.00(0.00)\n",
      "Iter 2316 | Time 76.5034(74.0163) | Bit/dim 3.5114(3.4929) | Xent 0.0000(0.0000) | Loss 8.3517(8.9263) | Error 0.0000(0.0000) Steps 688(684.97) | Grad Norm 1.6351(1.3090) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 24.4949, Epoch Time 480.3600(483.8759), Bit/dim 3.4990(best: 3.4897), Xent 0.0000, Loss 3.4990, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2317 | Time 71.3834(73.9373) | Bit/dim 3.4773(3.4924) | Xent 0.0000(0.0000) | Loss 12.1161(9.0220) | Error 0.0000(0.0000) Steps 676(684.70) | Grad Norm 0.8872(1.2964) | Total Time 0.00(0.00)\n",
      "Iter 2318 | Time 75.9236(73.9969) | Bit/dim 3.4951(3.4925) | Xent 0.0000(0.0000) | Loss 8.4345(9.0043) | Error 0.0000(0.0000) Steps 682(684.62) | Grad Norm 0.8175(1.2820) | Total Time 0.00(0.00)\n",
      "Iter 2319 | Time 70.1966(73.8829) | Bit/dim 3.4926(3.4925) | Xent 0.0000(0.0000) | Loss 8.3479(8.9847) | Error 0.0000(0.0000) Steps 670(684.18) | Grad Norm 1.2761(1.2818) | Total Time 0.00(0.00)\n",
      "Iter 2320 | Time 78.7441(74.0287) | Bit/dim 3.4827(3.4922) | Xent 0.0000(0.0000) | Loss 8.3552(8.9658) | Error 0.0000(0.0000) Steps 700(684.66) | Grad Norm 1.8576(1.2991) | Total Time 0.00(0.00)\n",
      "Iter 2321 | Time 72.9430(73.9962) | Bit/dim 3.5049(3.4926) | Xent 0.0000(0.0000) | Loss 8.2745(8.9450) | Error 0.0000(0.0000) Steps 670(684.22) | Grad Norm 2.1309(1.3240) | Total Time 0.00(0.00)\n",
      "Iter 2322 | Time 76.3915(74.0680) | Bit/dim 3.5037(3.4929) | Xent 0.0000(0.0000) | Loss 8.4054(8.9288) | Error 0.0000(0.0000) Steps 700(684.69) | Grad Norm 2.0872(1.3469) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 24.6185, Epoch Time 485.9985(483.9395), Bit/dim 3.4910(best: 3.4897), Xent 0.0000, Loss 3.4910, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2323 | Time 70.9852(73.9755) | Bit/dim 3.4818(3.4926) | Xent 0.0000(0.0000) | Loss 12.2189(9.0275) | Error 0.0000(0.0000) Steps 682(684.61) | Grad Norm 1.7227(1.3582) | Total Time 0.00(0.00)\n",
      "Iter 2324 | Time 71.1721(73.8914) | Bit/dim 3.4814(3.4922) | Xent 0.0000(0.0000) | Loss 8.2637(9.0046) | Error 0.0000(0.0000) Steps 688(684.71) | Grad Norm 1.2869(1.3561) | Total Time 0.00(0.00)\n",
      "Iter 2325 | Time 79.0547(74.0463) | Bit/dim 3.5054(3.4926) | Xent 0.0000(0.0000) | Loss 8.5300(8.9904) | Error 0.0000(0.0000) Steps 712(685.53) | Grad Norm 0.8087(1.3396) | Total Time 0.00(0.00)\n",
      "Iter 2326 | Time 79.7627(74.2178) | Bit/dim 3.5021(3.4929) | Xent 0.0000(0.0000) | Loss 8.4990(8.9756) | Error 0.0000(0.0000) Steps 724(686.68) | Grad Norm 0.3681(1.3105) | Total Time 0.00(0.00)\n",
      "Iter 2327 | Time 75.7577(74.2640) | Bit/dim 3.4846(3.4927) | Xent 0.0000(0.0000) | Loss 8.4595(8.9602) | Error 0.0000(0.0000) Steps 688(686.72) | Grad Norm 0.7701(1.2943) | Total Time 0.00(0.00)\n",
      "Iter 2328 | Time 73.9524(74.2547) | Bit/dim 3.5000(3.4929) | Xent 0.0000(0.0000) | Loss 8.4007(8.9434) | Error 0.0000(0.0000) Steps 676(686.40) | Grad Norm 1.2205(1.2921) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 24.1843, Epoch Time 490.5437(484.1377), Bit/dim 3.4940(best: 3.4897), Xent 0.0000, Loss 3.4940, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2329 | Time 71.3487(74.1675) | Bit/dim 3.4970(3.4930) | Xent 0.0000(0.0000) | Loss 11.8446(9.0304) | Error 0.0000(0.0000) Steps 652(685.37) | Grad Norm 1.4417(1.2966) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 78.2388(74.2896) | Bit/dim 3.5020(3.4933) | Xent 0.0000(0.0000) | Loss 8.2749(9.0077) | Error 0.0000(0.0000) Steps 688(685.45) | Grad Norm 1.5299(1.3036) | Total Time 0.00(0.00)\n",
      "Iter 2331 | Time 71.6296(74.2098) | Bit/dim 3.5009(3.4935) | Xent 0.0000(0.0000) | Loss 8.5543(8.9941) | Error 0.0000(0.0000) Steps 676(685.17) | Grad Norm 1.6839(1.3150) | Total Time 0.00(0.00)\n",
      "Iter 2332 | Time 77.6828(74.3140) | Bit/dim 3.4885(3.4934) | Xent 0.0000(0.0000) | Loss 8.3799(8.9757) | Error 0.0000(0.0000) Steps 682(685.07) | Grad Norm 1.9374(1.3336) | Total Time 0.00(0.00)\n",
      "Iter 2333 | Time 72.0745(74.2468) | Bit/dim 3.4747(3.4928) | Xent 0.0000(0.0000) | Loss 8.4215(8.9591) | Error 0.0000(0.0000) Steps 694(685.34) | Grad Norm 2.2488(1.3611) | Total Time 0.00(0.00)\n",
      "Iter 2334 | Time 75.8430(74.2947) | Bit/dim 3.4876(3.4926) | Xent 0.0000(0.0000) | Loss 8.4567(8.9440) | Error 0.0000(0.0000) Steps 706(685.96) | Grad Norm 2.3444(1.3906) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 24.2569, Epoch Time 487.1874(484.2292), Bit/dim 3.4997(best: 3.4897), Xent 0.0000, Loss 3.4997, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2335 | Time 76.9545(74.3745) | Bit/dim 3.4923(3.4926) | Xent 0.0000(0.0000) | Loss 12.2145(9.0421) | Error 0.0000(0.0000) Steps 688(686.02) | Grad Norm 2.1780(1.4142) | Total Time 0.00(0.00)\n",
      "Iter 2336 | Time 76.7595(74.4461) | Bit/dim 3.4927(3.4926) | Xent 0.0000(0.0000) | Loss 8.5401(9.0271) | Error 0.0000(0.0000) Steps 694(686.26) | Grad Norm 1.8979(1.4287) | Total Time 0.00(0.00)\n",
      "Iter 2337 | Time 78.5931(74.5705) | Bit/dim 3.4888(3.4925) | Xent 0.0000(0.0000) | Loss 8.4524(9.0098) | Error 0.0000(0.0000) Steps 718(687.21) | Grad Norm 1.5681(1.4329) | Total Time 0.00(0.00)\n",
      "Iter 2338 | Time 73.3789(74.5347) | Bit/dim 3.4848(3.4923) | Xent 0.0000(0.0000) | Loss 8.4158(8.9920) | Error 0.0000(0.0000) Steps 694(687.41) | Grad Norm 1.1451(1.4243) | Total Time 0.00(0.00)\n",
      "Iter 2339 | Time 74.1133(74.5221) | Bit/dim 3.4915(3.4923) | Xent 0.0000(0.0000) | Loss 8.4727(8.9764) | Error 0.0000(0.0000) Steps 694(687.61) | Grad Norm 0.8468(1.4070) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 70.5942(74.4042) | Bit/dim 3.5040(3.4926) | Xent 0.0000(0.0000) | Loss 8.2873(8.9558) | Error 0.0000(0.0000) Steps 664(686.90) | Grad Norm 0.6191(1.3833) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 24.0217, Epoch Time 490.1918(484.4080), Bit/dim 3.4953(best: 3.4897), Xent 0.0000, Loss 3.4953, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2341 | Time 77.5049(74.4973) | Bit/dim 3.4955(3.4927) | Xent 0.0000(0.0000) | Loss 11.9899(9.0468) | Error 0.0000(0.0000) Steps 682(686.76) | Grad Norm 0.5451(1.3582) | Total Time 0.00(0.00)\n",
      "Iter 2342 | Time 74.6898(74.5030) | Bit/dim 3.4866(3.4925) | Xent 0.0000(0.0000) | Loss 8.3309(9.0253) | Error 0.0000(0.0000) Steps 706(687.33) | Grad Norm 0.6208(1.3360) | Total Time 0.00(0.00)\n",
      "Iter 2343 | Time 78.7399(74.6301) | Bit/dim 3.4834(3.4922) | Xent 0.0000(0.0000) | Loss 8.3066(9.0037) | Error 0.0000(0.0000) Steps 688(687.35) | Grad Norm 1.0051(1.3261) | Total Time 0.00(0.00)\n",
      "Iter 2344 | Time 75.5365(74.6573) | Bit/dim 3.4899(3.4922) | Xent 0.0000(0.0000) | Loss 8.5529(8.9902) | Error 0.0000(0.0000) Steps 712(688.09) | Grad Norm 1.4810(1.3308) | Total Time 0.00(0.00)\n",
      "Iter 2345 | Time 73.3998(74.6196) | Bit/dim 3.4931(3.4922) | Xent 0.0000(0.0000) | Loss 8.4018(8.9726) | Error 0.0000(0.0000) Steps 676(687.73) | Grad Norm 1.7799(1.3442) | Total Time 0.00(0.00)\n",
      "Iter 2346 | Time 76.8421(74.6863) | Bit/dim 3.4984(3.4924) | Xent 0.0000(0.0000) | Loss 8.4105(8.9557) | Error 0.0000(0.0000) Steps 700(688.10) | Grad Norm 2.0107(1.3642) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 24.6373, Epoch Time 497.1893(484.7915), Bit/dim 3.4950(best: 3.4897), Xent 0.0000, Loss 3.4950, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2347 | Time 68.3036(74.4948) | Bit/dim 3.4880(3.4923) | Xent 0.0000(0.0000) | Loss 12.2530(9.0546) | Error 0.0000(0.0000) Steps 688(688.10) | Grad Norm 2.1962(1.3892) | Total Time 0.00(0.00)\n",
      "Iter 2348 | Time 72.9322(74.4479) | Bit/dim 3.5009(3.4925) | Xent 0.0000(0.0000) | Loss 8.4874(9.0376) | Error 0.0000(0.0000) Steps 682(687.91) | Grad Norm 2.3395(1.4177) | Total Time 0.00(0.00)\n",
      "Iter 2349 | Time 72.2700(74.3826) | Bit/dim 3.4868(3.4923) | Xent 0.0000(0.0000) | Loss 8.1958(9.0124) | Error 0.0000(0.0000) Steps 670(687.38) | Grad Norm 2.3461(1.4456) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 72.5461(74.3275) | Bit/dim 3.4822(3.4920) | Xent 0.0000(0.0000) | Loss 8.3129(8.9914) | Error 0.0000(0.0000) Steps 700(687.75) | Grad Norm 1.7908(1.4559) | Total Time 0.00(0.00)\n",
      "Iter 2351 | Time 73.5595(74.3045) | Bit/dim 3.4876(3.4919) | Xent 0.0000(0.0000) | Loss 8.3962(8.9735) | Error 0.0000(0.0000) Steps 700(688.12) | Grad Norm 0.9158(1.4397) | Total Time 0.00(0.00)\n",
      "Iter 2352 | Time 72.4094(74.2476) | Bit/dim 3.4919(3.4919) | Xent 0.0000(0.0000) | Loss 8.4049(8.9565) | Error 0.0000(0.0000) Steps 676(687.76) | Grad Norm 0.2832(1.4050) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 24.4442, Epoch Time 472.0883(484.4104), Bit/dim 3.4943(best: 3.4897), Xent 0.0000, Loss 3.4943, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2353 | Time 78.8887(74.3868) | Bit/dim 3.5061(3.4923) | Xent 0.0000(0.0000) | Loss 12.2498(9.0553) | Error 0.0000(0.0000) Steps 712(688.49) | Grad Norm 0.6689(1.3829) | Total Time 0.00(0.00)\n",
      "Iter 2354 | Time 67.0204(74.1658) | Bit/dim 3.4901(3.4923) | Xent 0.0000(0.0000) | Loss 8.3723(9.0348) | Error 0.0000(0.0000) Steps 700(688.83) | Grad Norm 1.1296(1.3753) | Total Time 0.00(0.00)\n",
      "Iter 2355 | Time 69.1802(74.0163) | Bit/dim 3.4829(3.4920) | Xent 0.0000(0.0000) | Loss 8.2607(9.0115) | Error 0.0000(0.0000) Steps 664(688.09) | Grad Norm 1.5605(1.3809) | Total Time 0.00(0.00)\n",
      "Iter 2356 | Time 73.3232(73.9955) | Bit/dim 3.4837(3.4917) | Xent 0.0000(0.0000) | Loss 8.4182(8.9937) | Error 0.0000(0.0000) Steps 694(688.26) | Grad Norm 1.8724(1.3956) | Total Time 0.00(0.00)\n",
      "Iter 2357 | Time 74.9038(74.0227) | Bit/dim 3.4886(3.4916) | Xent 0.0000(0.0000) | Loss 8.4537(8.9775) | Error 0.0000(0.0000) Steps 682(688.08) | Grad Norm 1.9794(1.4131) | Total Time 0.00(0.00)\n",
      "Iter 2358 | Time 73.4170(74.0046) | Bit/dim 3.4925(3.4917) | Xent 0.0000(0.0000) | Loss 8.4577(8.9620) | Error 0.0000(0.0000) Steps 694(688.25) | Grad Norm 2.1003(1.4338) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 24.2971, Epoch Time 476.7517(484.1806), Bit/dim 3.4891(best: 3.4897), Xent 0.0000, Loss 3.4891, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2359 | Time 76.6196(74.0830) | Bit/dim 3.4882(3.4916) | Xent 0.0000(0.0000) | Loss 11.9527(9.0517) | Error 0.0000(0.0000) Steps 700(688.61) | Grad Norm 2.2463(1.4581) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 74.8212(74.1052) | Bit/dim 3.4886(3.4915) | Xent 0.0000(0.0000) | Loss 8.2866(9.0287) | Error 0.0000(0.0000) Steps 694(688.77) | Grad Norm 2.2564(1.4821) | Total Time 0.00(0.00)\n",
      "Iter 2361 | Time 72.3158(74.0515) | Bit/dim 3.4955(3.4916) | Xent 0.0000(0.0000) | Loss 8.4432(9.0112) | Error 0.0000(0.0000) Steps 694(688.92) | Grad Norm 1.8638(1.4935) | Total Time 0.00(0.00)\n",
      "Iter 2362 | Time 71.3620(73.9708) | Bit/dim 3.4923(3.4916) | Xent 0.0000(0.0000) | Loss 8.3595(8.9916) | Error 0.0000(0.0000) Steps 676(688.54) | Grad Norm 1.3776(1.4901) | Total Time 0.00(0.00)\n",
      "Iter 2363 | Time 70.2777(73.8600) | Bit/dim 3.4898(3.4916) | Xent 0.0000(0.0000) | Loss 8.1771(8.9672) | Error 0.0000(0.0000) Steps 664(687.80) | Grad Norm 0.9366(1.4734) | Total Time 0.00(0.00)\n",
      "Iter 2364 | Time 78.4262(73.9970) | Bit/dim 3.4803(3.4912) | Xent 0.0000(0.0000) | Loss 8.3382(8.9483) | Error 0.0000(0.0000) Steps 712(688.53) | Grad Norm 0.9138(1.4567) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 24.7915, Epoch Time 484.7881(484.1988), Bit/dim 3.4898(best: 3.4891), Xent 0.0000, Loss 3.4898, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2365 | Time 72.1603(73.9419) | Bit/dim 3.4822(3.4910) | Xent 0.0000(0.0000) | Loss 12.0428(9.0411) | Error 0.0000(0.0000) Steps 694(688.69) | Grad Norm 1.2597(1.4507) | Total Time 0.00(0.00)\n",
      "Iter 2366 | Time 73.2388(73.9208) | Bit/dim 3.4985(3.4912) | Xent 0.0000(0.0000) | Loss 8.0944(9.0127) | Error 0.0000(0.0000) Steps 664(687.95) | Grad Norm 1.2708(1.4453) | Total Time 0.00(0.00)\n",
      "Iter 2367 | Time 70.5136(73.8186) | Bit/dim 3.4888(3.4911) | Xent 0.0000(0.0000) | Loss 8.2391(8.9895) | Error 0.0000(0.0000) Steps 658(687.05) | Grad Norm 0.7411(1.4242) | Total Time 0.00(0.00)\n",
      "Iter 2368 | Time 70.3913(73.7158) | Bit/dim 3.4836(3.4909) | Xent 0.0000(0.0000) | Loss 8.3893(8.9715) | Error 0.0000(0.0000) Steps 682(686.90) | Grad Norm 0.5925(1.3993) | Total Time 0.00(0.00)\n",
      "Iter 2369 | Time 71.2357(73.6414) | Bit/dim 3.4964(3.4911) | Xent 0.0000(0.0000) | Loss 8.5107(8.9577) | Error 0.0000(0.0000) Steps 682(686.75) | Grad Norm 0.9713(1.3864) | Total Time 0.00(0.00)\n",
      "Iter 2370 | Time 75.3158(73.6916) | Bit/dim 3.4870(3.4909) | Xent 0.0000(0.0000) | Loss 8.3737(8.9402) | Error 0.0000(0.0000) Steps 688(686.79) | Grad Norm 1.3229(1.3845) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 24.0968, Epoch Time 473.2651(483.8708), Bit/dim 3.4957(best: 3.4891), Xent 0.0000, Loss 3.4957, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2371 | Time 73.5710(73.6880) | Bit/dim 3.4838(3.4907) | Xent 0.0000(0.0000) | Loss 12.3365(9.0421) | Error 0.0000(0.0000) Steps 688(686.83) | Grad Norm 1.3576(1.3837) | Total Time 0.00(0.00)\n",
      "Iter 2372 | Time 74.8285(73.7222) | Bit/dim 3.4872(3.4906) | Xent 0.0000(0.0000) | Loss 8.4772(9.0251) | Error 0.0000(0.0000) Steps 700(687.22) | Grad Norm 1.4089(1.3845) | Total Time 0.00(0.00)\n",
      "Iter 2373 | Time 74.3205(73.7401) | Bit/dim 3.4928(3.4907) | Xent 0.0000(0.0000) | Loss 8.3355(9.0044) | Error 0.0000(0.0000) Steps 682(687.07) | Grad Norm 2.0287(1.4038) | Total Time 0.00(0.00)\n",
      "Iter 2374 | Time 75.7939(73.8018) | Bit/dim 3.4898(3.4906) | Xent 0.0000(0.0000) | Loss 8.2896(8.9830) | Error 0.0000(0.0000) Steps 700(687.45) | Grad Norm 2.6598(1.4415) | Total Time 0.00(0.00)\n",
      "Iter 2375 | Time 78.5684(73.9448) | Bit/dim 3.4913(3.4907) | Xent 0.0000(0.0000) | Loss 8.4057(8.9657) | Error 0.0000(0.0000) Steps 700(687.83) | Grad Norm 2.8950(1.4851) | Total Time 0.00(0.00)\n",
      "Iter 2376 | Time 73.7449(73.9388) | Bit/dim 3.4939(3.4908) | Xent 0.0000(0.0000) | Loss 8.2151(8.9431) | Error 0.0000(0.0000) Steps 676(687.47) | Grad Norm 2.6344(1.5196) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 24.2670, Epoch Time 491.1476(484.0891), Bit/dim 3.4899(best: 3.4891), Xent 0.0000, Loss 3.4899, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2377 | Time 70.5717(73.8377) | Bit/dim 3.4837(3.4906) | Xent 0.0000(0.0000) | Loss 11.8364(9.0299) | Error 0.0000(0.0000) Steps 688(687.49) | Grad Norm 1.9521(1.5325) | Total Time 0.00(0.00)\n",
      "Iter 2378 | Time 72.6962(73.8035) | Bit/dim 3.4906(3.4906) | Xent 0.0000(0.0000) | Loss 8.3246(9.0088) | Error 0.0000(0.0000) Steps 670(686.97) | Grad Norm 1.2785(1.5249) | Total Time 0.00(0.00)\n",
      "Iter 2379 | Time 75.9959(73.8693) | Bit/dim 3.4873(3.4905) | Xent 0.0000(0.0000) | Loss 8.1607(8.9833) | Error 0.0000(0.0000) Steps 694(687.18) | Grad Norm 1.0222(1.5098) | Total Time 0.00(0.00)\n",
      "Iter 2380 | Time 71.1517(73.7877) | Bit/dim 3.4850(3.4903) | Xent 0.0000(0.0000) | Loss 8.1221(8.9575) | Error 0.0000(0.0000) Steps 676(686.84) | Grad Norm 0.8518(1.4901) | Total Time 0.00(0.00)\n",
      "Iter 2381 | Time 70.2073(73.6803) | Bit/dim 3.4932(3.4904) | Xent 0.0000(0.0000) | Loss 8.3804(8.9402) | Error 0.0000(0.0000) Steps 688(686.88) | Grad Norm 0.5663(1.4624) | Total Time 0.00(0.00)\n",
      "Iter 2382 | Time 74.2926(73.6987) | Bit/dim 3.4962(3.4906) | Xent 0.0000(0.0000) | Loss 8.3074(8.9212) | Error 0.0000(0.0000) Steps 682(686.73) | Grad Norm 0.4914(1.4332) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 24.4872, Epoch Time 475.3338(483.8265), Bit/dim 3.4951(best: 3.4891), Xent 0.0000, Loss 3.4951, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2383 | Time 74.1989(73.7137) | Bit/dim 3.4942(3.4907) | Xent 0.0000(0.0000) | Loss 11.4027(8.9956) | Error 0.0000(0.0000) Steps 664(686.05) | Grad Norm 1.1346(1.4243) | Total Time 0.00(0.00)\n",
      "Iter 2384 | Time 73.6778(73.7126) | Bit/dim 3.4953(3.4908) | Xent 0.0000(0.0000) | Loss 8.2390(8.9729) | Error 0.0000(0.0000) Steps 682(685.93) | Grad Norm 0.9163(1.4090) | Total Time 0.00(0.00)\n",
      "Iter 2385 | Time 76.5962(73.7991) | Bit/dim 3.4950(3.4909) | Xent 0.0000(0.0000) | Loss 8.3968(8.9557) | Error 0.0000(0.0000) Steps 682(685.81) | Grad Norm 1.1173(1.4003) | Total Time 0.00(0.00)\n",
      "Iter 2386 | Time 72.3690(73.7562) | Bit/dim 3.4773(3.4905) | Xent 0.0000(0.0000) | Loss 8.3893(8.9387) | Error 0.0000(0.0000) Steps 682(685.69) | Grad Norm 1.6288(1.4072) | Total Time 0.00(0.00)\n",
      "Iter 2387 | Time 73.0815(73.7360) | Bit/dim 3.4827(3.4903) | Xent 0.0000(0.0000) | Loss 8.3643(8.9214) | Error 0.0000(0.0000) Steps 688(685.76) | Grad Norm 2.3491(1.4354) | Total Time 0.00(0.00)\n",
      "Iter 2388 | Time 76.4473(73.8173) | Bit/dim 3.4931(3.4904) | Xent 0.0000(0.0000) | Loss 8.0082(8.8940) | Error 0.0000(0.0000) Steps 682(685.65) | Grad Norm 2.9256(1.4801) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 24.8401, Epoch Time 487.1107(483.9250), Bit/dim 3.4944(best: 3.4891), Xent 0.0000, Loss 3.4944, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2389 | Time 72.9055(73.7900) | Bit/dim 3.4868(3.4903) | Xent 0.0000(0.0000) | Loss 12.1694(8.9923) | Error 0.0000(0.0000) Steps 670(685.18) | Grad Norm 3.1270(1.5295) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 70.5511(73.6928) | Bit/dim 3.4943(3.4904) | Xent 0.0000(0.0000) | Loss 8.3565(8.9732) | Error 0.0000(0.0000) Steps 688(685.27) | Grad Norm 3.0225(1.5743) | Total Time 0.00(0.00)\n",
      "Iter 2391 | Time 72.9831(73.6715) | Bit/dim 3.4960(3.4906) | Xent 0.0000(0.0000) | Loss 8.3519(8.9546) | Error 0.0000(0.0000) Steps 676(684.99) | Grad Norm 2.5923(1.6049) | Total Time 0.00(0.00)\n",
      "Iter 2392 | Time 74.6678(73.7014) | Bit/dim 3.4941(3.4907) | Xent 0.0000(0.0000) | Loss 8.4103(8.9383) | Error 0.0000(0.0000) Steps 688(685.08) | Grad Norm 1.9138(1.6141) | Total Time 0.00(0.00)\n",
      "Iter 2393 | Time 71.5695(73.6374) | Bit/dim 3.4915(3.4907) | Xent 0.0000(0.0000) | Loss 8.3834(8.9216) | Error 0.0000(0.0000) Steps 688(685.17) | Grad Norm 1.2747(1.6039) | Total Time 0.00(0.00)\n",
      "Iter 2394 | Time 80.4769(73.8426) | Bit/dim 3.4901(3.4907) | Xent 0.0000(0.0000) | Loss 8.4668(8.9080) | Error 0.0000(0.0000) Steps 712(685.97) | Grad Norm 0.8743(1.5820) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 25.0813, Epoch Time 484.4859(483.9418), Bit/dim 3.4886(best: 3.4891), Xent 0.0000, Loss 3.4886, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2395 | Time 80.8299(74.0522) | Bit/dim 3.4792(3.4903) | Xent 0.0000(0.0000) | Loss 12.1588(9.0055) | Error 0.0000(0.0000) Steps 700(686.39) | Grad Norm 0.5398(1.5508) | Total Time 0.00(0.00)\n",
      "Iter 2396 | Time 77.2218(74.1473) | Bit/dim 3.4836(3.4901) | Xent 0.0000(0.0000) | Loss 8.4044(8.9875) | Error 0.0000(0.0000) Steps 706(686.98) | Grad Norm 0.6257(1.5230) | Total Time 0.00(0.00)\n",
      "Iter 2397 | Time 73.7927(74.1367) | Bit/dim 3.4992(3.4904) | Xent 0.0000(0.0000) | Loss 8.4196(8.9704) | Error 0.0000(0.0000) Steps 682(686.83) | Grad Norm 0.7287(1.4992) | Total Time 0.00(0.00)\n",
      "Iter 2398 | Time 74.9946(74.1624) | Bit/dim 3.4876(3.4903) | Xent 0.0000(0.0000) | Loss 8.3183(8.9509) | Error 0.0000(0.0000) Steps 688(686.87) | Grad Norm 0.6852(1.4748) | Total Time 0.00(0.00)\n",
      "Iter 2399 | Time 75.9719(74.2167) | Bit/dim 3.4943(3.4904) | Xent 0.0000(0.0000) | Loss 8.2687(8.9304) | Error 0.0000(0.0000) Steps 700(687.26) | Grad Norm 0.6190(1.4491) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 72.1819(74.1557) | Bit/dim 3.4899(3.4904) | Xent 0.0000(0.0000) | Loss 8.2864(8.9111) | Error 0.0000(0.0000) Steps 682(687.10) | Grad Norm 0.4911(1.4204) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 24.5616, Epoch Time 495.6172(484.2921), Bit/dim 3.4897(best: 3.4886), Xent 0.0000, Loss 3.4897, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2401 | Time 75.3138(74.1904) | Bit/dim 3.4867(3.4903) | Xent 0.0000(0.0000) | Loss 12.1761(9.0090) | Error 0.0000(0.0000) Steps 706(687.67) | Grad Norm 0.5257(1.3935) | Total Time 0.00(0.00)\n",
      "Iter 2402 | Time 78.7377(74.3268) | Bit/dim 3.4990(3.4906) | Xent 0.0000(0.0000) | Loss 8.4499(8.9923) | Error 0.0000(0.0000) Steps 688(687.68) | Grad Norm 0.9343(1.3797) | Total Time 0.00(0.00)\n",
      "Iter 2403 | Time 72.7700(74.2801) | Bit/dim 3.4971(3.4908) | Xent 0.0000(0.0000) | Loss 8.4543(8.9761) | Error 0.0000(0.0000) Steps 688(687.69) | Grad Norm 1.5771(1.3857) | Total Time 0.00(0.00)\n",
      "Iter 2404 | Time 68.3733(74.1029) | Bit/dim 3.4886(3.4907) | Xent 0.0000(0.0000) | Loss 8.0151(8.9473) | Error 0.0000(0.0000) Steps 670(687.16) | Grad Norm 2.2160(1.4106) | Total Time 0.00(0.00)\n",
      "Iter 2405 | Time 75.5430(74.1461) | Bit/dim 3.4924(3.4907) | Xent 0.0000(0.0000) | Loss 8.3960(8.9308) | Error 0.0000(0.0000) Steps 706(687.72) | Grad Norm 2.6513(1.4478) | Total Time 0.00(0.00)\n",
      "Iter 2406 | Time 79.5024(74.3068) | Bit/dim 3.4890(3.4907) | Xent 0.0000(0.0000) | Loss 8.4352(8.9159) | Error 0.0000(0.0000) Steps 730(688.99) | Grad Norm 3.1024(1.4974) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 24.4846, Epoch Time 490.4103(484.4756), Bit/dim 3.4959(best: 3.4886), Xent 0.0000, Loss 3.4959, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2407 | Time 73.5982(74.2856) | Bit/dim 3.4900(3.4907) | Xent 0.0000(0.0000) | Loss 11.7664(9.0014) | Error 0.0000(0.0000) Steps 670(688.42) | Grad Norm 3.1112(1.5459) | Total Time 0.00(0.00)\n",
      "Iter 2408 | Time 77.1963(74.3729) | Bit/dim 3.4865(3.4905) | Xent 0.0000(0.0000) | Loss 8.4083(8.9836) | Error 0.0000(0.0000) Steps 676(688.05) | Grad Norm 2.3065(1.5687) | Total Time 0.00(0.00)\n",
      "Iter 2409 | Time 77.4997(74.4667) | Bit/dim 3.4965(3.4907) | Xent 0.0000(0.0000) | Loss 8.6137(8.9725) | Error 0.0000(0.0000) Steps 724(689.13) | Grad Norm 1.5372(1.5677) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 80.8545(74.6583) | Bit/dim 3.4873(3.4906) | Xent 0.0000(0.0000) | Loss 8.5220(8.9590) | Error 0.0000(0.0000) Steps 742(690.71) | Grad Norm 1.2283(1.5575) | Total Time 0.00(0.00)\n",
      "Iter 2411 | Time 71.8845(74.5751) | Bit/dim 3.4885(3.4906) | Xent 0.0000(0.0000) | Loss 8.4160(8.9427) | Error 0.0000(0.0000) Steps 706(691.17) | Grad Norm 1.2166(1.5473) | Total Time 0.00(0.00)\n",
      "Iter 2412 | Time 77.1313(74.6518) | Bit/dim 3.4981(3.4908) | Xent 0.0000(0.0000) | Loss 8.3900(8.9261) | Error 0.0000(0.0000) Steps 700(691.44) | Grad Norm 1.3150(1.5403) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 24.4909, Epoch Time 498.3708(484.8925), Bit/dim 3.4896(best: 3.4886), Xent 0.0000, Loss 3.4896, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2413 | Time 71.1444(74.5466) | Bit/dim 3.4884(3.4907) | Xent 0.0000(0.0000) | Loss 12.0749(9.0206) | Error 0.0000(0.0000) Steps 670(690.79) | Grad Norm 1.4034(1.5362) | Total Time 0.00(0.00)\n",
      "Iter 2414 | Time 73.9194(74.5278) | Bit/dim 3.4852(3.4905) | Xent 0.0000(0.0000) | Loss 8.4111(9.0023) | Error 0.0000(0.0000) Steps 682(690.53) | Grad Norm 1.7666(1.5431) | Total Time 0.00(0.00)\n",
      "Iter 2415 | Time 78.8461(74.6573) | Bit/dim 3.4855(3.4904) | Xent 0.0000(0.0000) | Loss 8.2960(8.9811) | Error 0.0000(0.0000) Steps 706(690.99) | Grad Norm 2.5105(1.5722) | Total Time 0.00(0.00)\n",
      "Iter 2416 | Time 74.3737(74.6488) | Bit/dim 3.4950(3.4905) | Xent 0.0000(0.0000) | Loss 8.5887(8.9693) | Error 0.0000(0.0000) Steps 712(691.62) | Grad Norm 2.9178(1.6125) | Total Time 0.00(0.00)\n",
      "Iter 2417 | Time 70.7783(74.5327) | Bit/dim 3.4920(3.4906) | Xent 0.0000(0.0000) | Loss 8.1084(8.9435) | Error 0.0000(0.0000) Steps 658(690.62) | Grad Norm 2.9853(1.6537) | Total Time 0.00(0.00)\n",
      "Iter 2418 | Time 74.8443(74.5420) | Bit/dim 3.4921(3.4906) | Xent 0.0000(0.0000) | Loss 8.3268(8.9250) | Error 0.0000(0.0000) Steps 682(690.36) | Grad Norm 2.4247(1.6769) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 24.3332, Epoch Time 484.4021(484.8778), Bit/dim 3.4948(best: 3.4886), Xent 0.0000, Loss 3.4948, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2419 | Time 68.2419(74.3530) | Bit/dim 3.4893(3.4906) | Xent 0.0000(0.0000) | Loss 12.0273(9.0181) | Error 0.0000(0.0000) Steps 670(689.75) | Grad Norm 1.4220(1.6692) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 70.6243(74.2412) | Bit/dim 3.4849(3.4904) | Xent 0.0000(0.0000) | Loss 8.3580(8.9983) | Error 0.0000(0.0000) Steps 676(689.33) | Grad Norm 0.4380(1.6323) | Total Time 0.00(0.00)\n",
      "Iter 2421 | Time 77.2156(74.3304) | Bit/dim 3.4998(3.4907) | Xent 0.0000(0.0000) | Loss 8.3471(8.9787) | Error 0.0000(0.0000) Steps 700(689.65) | Grad Norm 1.3600(1.6241) | Total Time 0.00(0.00)\n",
      "Iter 2422 | Time 73.6717(74.3106) | Bit/dim 3.4916(3.4907) | Xent 0.0000(0.0000) | Loss 8.3917(8.9611) | Error 0.0000(0.0000) Steps 670(689.06) | Grad Norm 2.4444(1.6487) | Total Time 0.00(0.00)\n",
      "Iter 2423 | Time 80.1113(74.4847) | Bit/dim 3.4905(3.4907) | Xent 0.0000(0.0000) | Loss 8.6680(8.9523) | Error 0.0000(0.0000) Steps 742(690.65) | Grad Norm 3.1637(1.6942) | Total Time 0.00(0.00)\n",
      "Iter 2424 | Time 78.0651(74.5921) | Bit/dim 3.4874(3.4906) | Xent 0.0000(0.0000) | Loss 8.2772(8.9321) | Error 0.0000(0.0000) Steps 694(690.75) | Grad Norm 3.1542(1.7380) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 23.5858, Epoch Time 487.4354(484.9545), Bit/dim 3.4942(best: 3.4886), Xent 0.0000, Loss 3.4942, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2425 | Time 68.5728(74.4115) | Bit/dim 3.4848(3.4904) | Xent 0.0000(0.0000) | Loss 12.2483(9.0316) | Error 0.0000(0.0000) Steps 688(690.67) | Grad Norm 2.5161(1.7613) | Total Time 0.00(0.00)\n",
      "Iter 2426 | Time 73.9498(74.3976) | Bit/dim 3.4969(3.4906) | Xent 0.0000(0.0000) | Loss 8.0969(9.0035) | Error 0.0000(0.0000) Steps 664(689.87) | Grad Norm 1.5103(1.7538) | Total Time 0.00(0.00)\n",
      "Iter 2427 | Time 78.1937(74.5115) | Bit/dim 3.4939(3.4907) | Xent 0.0000(0.0000) | Loss 8.4326(8.9864) | Error 0.0000(0.0000) Steps 682(689.63) | Grad Norm 0.7363(1.7232) | Total Time 0.00(0.00)\n",
      "Iter 2428 | Time 70.9426(74.4045) | Bit/dim 3.4882(3.4907) | Xent 0.0000(0.0000) | Loss 8.3867(8.9684) | Error 0.0000(0.0000) Steps 694(689.77) | Grad Norm 1.5828(1.7190) | Total Time 0.00(0.00)\n",
      "Iter 2429 | Time 70.7515(74.2949) | Bit/dim 3.5023(3.4910) | Xent 0.0000(0.0000) | Loss 8.3742(8.9506) | Error 0.0000(0.0000) Steps 676(689.35) | Grad Norm 2.4517(1.7410) | Total Time 0.00(0.00)\n",
      "Iter 2430 | Time 77.4717(74.3902) | Bit/dim 3.4860(3.4909) | Xent 0.0000(0.0000) | Loss 8.3958(8.9339) | Error 0.0000(0.0000) Steps 700(689.67) | Grad Norm 2.9319(1.7767) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 23.9780, Epoch Time 479.7004(484.7969), Bit/dim 3.4931(best: 3.4886), Xent 0.0000, Loss 3.4931, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2431 | Time 70.2638(74.2664) | Bit/dim 3.4866(3.4907) | Xent 0.0000(0.0000) | Loss 12.1666(9.0309) | Error 0.0000(0.0000) Steps 670(689.08) | Grad Norm 2.8417(1.8087) | Total Time 0.00(0.00)\n",
      "Iter 2432 | Time 73.4580(74.2421) | Bit/dim 3.4838(3.4905) | Xent 0.0000(0.0000) | Loss 8.4088(9.0123) | Error 0.0000(0.0000) Steps 694(689.23) | Grad Norm 2.3344(1.8245) | Total Time 0.00(0.00)\n",
      "Iter 2433 | Time 75.5883(74.2825) | Bit/dim 3.4910(3.4905) | Xent 0.0000(0.0000) | Loss 8.5605(8.9987) | Error 0.0000(0.0000) Steps 724(690.27) | Grad Norm 1.7697(1.8228) | Total Time 0.00(0.00)\n",
      "Iter 2434 | Time 71.5712(74.2012) | Bit/dim 3.4891(3.4905) | Xent 0.0000(0.0000) | Loss 8.4012(8.9808) | Error 0.0000(0.0000) Steps 688(690.20) | Grad Norm 1.4932(1.8129) | Total Time 0.00(0.00)\n",
      "Iter 2435 | Time 72.5259(74.1509) | Bit/dim 3.4869(3.4904) | Xent 0.0000(0.0000) | Loss 8.4455(8.9647) | Error 0.0000(0.0000) Steps 688(690.14) | Grad Norm 1.7181(1.8101) | Total Time 0.00(0.00)\n",
      "Iter 2436 | Time 70.6532(74.0460) | Bit/dim 3.4981(3.4906) | Xent 0.0000(0.0000) | Loss 8.3901(8.9475) | Error 0.0000(0.0000) Steps 706(690.61) | Grad Norm 2.0881(1.8184) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 24.8362, Epoch Time 474.5442(484.4893), Bit/dim 3.4889(best: 3.4886), Xent 0.0000, Loss 3.4889, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2437 | Time 67.7984(73.8586) | Bit/dim 3.4877(3.4905) | Xent 0.0000(0.0000) | Loss 12.0306(9.0400) | Error 0.0000(0.0000) Steps 664(689.82) | Grad Norm 2.1233(1.8276) | Total Time 0.00(0.00)\n",
      "Iter 2438 | Time 73.1937(73.8386) | Bit/dim 3.4961(3.4907) | Xent 0.0000(0.0000) | Loss 8.2869(9.0174) | Error 0.0000(0.0000) Steps 688(689.76) | Grad Norm 1.9007(1.8298) | Total Time 0.00(0.00)\n",
      "Iter 2439 | Time 77.1206(73.9371) | Bit/dim 3.4813(3.4904) | Xent 0.0000(0.0000) | Loss 8.3552(8.9975) | Error 0.0000(0.0000) Steps 694(689.89) | Grad Norm 1.4789(1.8192) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 75.0256(73.9697) | Bit/dim 3.4992(3.4907) | Xent 0.0000(0.0000) | Loss 8.3941(8.9794) | Error 0.0000(0.0000) Steps 694(690.01) | Grad Norm 1.0425(1.7959) | Total Time 0.00(0.00)\n",
      "Iter 2441 | Time 79.5053(74.1358) | Bit/dim 3.4840(3.4905) | Xent 0.0000(0.0000) | Loss 8.4586(8.9638) | Error 0.0000(0.0000) Steps 724(691.03) | Grad Norm 0.8116(1.7664) | Total Time 0.00(0.00)\n",
      "Iter 2442 | Time 77.5700(74.2388) | Bit/dim 3.4878(3.4904) | Xent 0.0000(0.0000) | Loss 8.5246(8.9506) | Error 0.0000(0.0000) Steps 706(691.48) | Grad Norm 0.6872(1.7340) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 24.5343, Epoch Time 490.6709(484.6748), Bit/dim 3.4909(best: 3.4886), Xent 0.0000, Loss 3.4909, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2443 | Time 70.4627(74.1255) | Bit/dim 3.4931(3.4905) | Xent 0.0000(0.0000) | Loss 12.0208(9.0427) | Error 0.0000(0.0000) Steps 682(691.20) | Grad Norm 0.8630(1.7079) | Total Time 0.00(0.00)\n",
      "Iter 2444 | Time 75.8367(74.1769) | Bit/dim 3.4771(3.4901) | Xent 0.0000(0.0000) | Loss 8.5491(9.0279) | Error 0.0000(0.0000) Steps 712(691.82) | Grad Norm 0.8279(1.6815) | Total Time 0.00(0.00)\n",
      "Iter 2445 | Time 76.8581(74.2573) | Bit/dim 3.4853(3.4899) | Xent 0.0000(0.0000) | Loss 8.5018(9.0121) | Error 0.0000(0.0000) Steps 694(691.89) | Grad Norm 1.0695(1.6631) | Total Time 0.00(0.00)\n",
      "Iter 2446 | Time 73.5375(74.2357) | Bit/dim 3.4840(3.4898) | Xent 0.0000(0.0000) | Loss 8.4280(8.9946) | Error 0.0000(0.0000) Steps 724(692.85) | Grad Norm 1.5833(1.6607) | Total Time 0.00(0.00)\n",
      "Iter 2447 | Time 77.6454(74.3380) | Bit/dim 3.4894(3.4897) | Xent 0.0000(0.0000) | Loss 8.3364(8.9749) | Error 0.0000(0.0000) Steps 688(692.70) | Grad Norm 2.2216(1.6776) | Total Time 0.00(0.00)\n",
      "Iter 2448 | Time 74.7554(74.3505) | Bit/dim 3.5010(3.4901) | Xent 0.0000(0.0000) | Loss 8.3832(8.9571) | Error 0.0000(0.0000) Steps 688(692.56) | Grad Norm 2.9764(1.7165) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 23.6313, Epoch Time 488.6346(484.7936), Bit/dim 3.4959(best: 3.4886), Xent 0.0000, Loss 3.4959, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2449 | Time 72.0233(74.2807) | Bit/dim 3.5049(3.4905) | Xent 0.0000(0.0000) | Loss 12.3012(9.0574) | Error 0.0000(0.0000) Steps 706(692.97) | Grad Norm 3.4965(1.7699) | Total Time 0.00(0.00)\n",
      "Iter 2450 | Time 77.5270(74.3781) | Bit/dim 3.4982(3.4908) | Xent 0.0000(0.0000) | Loss 8.2537(9.0333) | Error 0.0000(0.0000) Steps 688(692.82) | Grad Norm 3.1987(1.8128) | Total Time 0.00(0.00)\n",
      "Iter 2451 | Time 70.9412(74.2750) | Bit/dim 3.4788(3.4904) | Xent 0.0000(0.0000) | Loss 8.0499(9.0038) | Error 0.0000(0.0000) Steps 676(692.31) | Grad Norm 2.2997(1.8274) | Total Time 0.00(0.00)\n",
      "Iter 2452 | Time 74.7458(74.2891) | Bit/dim 3.4975(3.4906) | Xent 0.0000(0.0000) | Loss 8.4179(8.9862) | Error 0.0000(0.0000) Steps 694(692.36) | Grad Norm 1.3785(1.8139) | Total Time 0.00(0.00)\n",
      "Iter 2453 | Time 82.4992(74.5354) | Bit/dim 3.4837(3.4904) | Xent 0.0000(0.0000) | Loss 8.4943(8.9715) | Error 0.0000(0.0000) Steps 712(692.95) | Grad Norm 0.6377(1.7786) | Total Time 0.00(0.00)\n",
      "Iter 2454 | Time 72.7385(74.4815) | Bit/dim 3.4744(3.4899) | Xent 0.0000(0.0000) | Loss 8.5052(8.9575) | Error 0.0000(0.0000) Steps 706(693.34) | Grad Norm 0.4536(1.7389) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 23.7738, Epoch Time 490.0271(484.9506), Bit/dim 3.4897(best: 3.4886), Xent 0.0000, Loss 3.4897, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2455 | Time 73.9146(74.4645) | Bit/dim 3.4836(3.4897) | Xent 0.0000(0.0000) | Loss 12.4464(9.0622) | Error 0.0000(0.0000) Steps 700(693.54) | Grad Norm 0.7559(1.7094) | Total Time 0.00(0.00)\n",
      "Iter 2456 | Time 70.1409(74.3348) | Bit/dim 3.4819(3.4895) | Xent 0.0000(0.0000) | Loss 8.0867(9.0329) | Error 0.0000(0.0000) Steps 682(693.20) | Grad Norm 1.0877(1.6908) | Total Time 0.00(0.00)\n",
      "Iter 2457 | Time 76.5794(74.4021) | Bit/dim 3.4951(3.4897) | Xent 0.0000(0.0000) | Loss 8.5329(9.0179) | Error 0.0000(0.0000) Steps 712(693.76) | Grad Norm 1.5002(1.6850) | Total Time 0.00(0.00)\n",
      "Iter 2458 | Time 74.3130(74.3995) | Bit/dim 3.4844(3.4895) | Xent 0.0000(0.0000) | Loss 8.4412(9.0006) | Error 0.0000(0.0000) Steps 694(693.77) | Grad Norm 2.3152(1.7039) | Total Time 0.00(0.00)\n",
      "Iter 2459 | Time 71.7737(74.3207) | Bit/dim 3.4917(3.4896) | Xent 0.0000(0.0000) | Loss 8.3651(8.9815) | Error 0.0000(0.0000) Steps 688(693.59) | Grad Norm 3.1866(1.7484) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 78.0467(74.4325) | Bit/dim 3.5037(3.4900) | Xent 0.0000(0.0000) | Loss 8.4651(8.9660) | Error 0.0000(0.0000) Steps 718(694.33) | Grad Norm 3.5538(1.8026) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 24.6657, Epoch Time 485.4676(484.9661), Bit/dim 3.4910(best: 3.4886), Xent 0.0000, Loss 3.4910, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2461 | Time 67.8138(74.2339) | Bit/dim 3.4926(3.4901) | Xent 0.0000(0.0000) | Loss 12.0594(9.0588) | Error 0.0000(0.0000) Steps 664(693.42) | Grad Norm 3.3643(1.8494) | Total Time 0.00(0.00)\n",
      "Iter 2462 | Time 76.2964(74.2958) | Bit/dim 3.4865(3.4900) | Xent 0.0000(0.0000) | Loss 8.3683(9.0381) | Error 0.0000(0.0000) Steps 712(693.97) | Grad Norm 2.4736(1.8682) | Total Time 0.00(0.00)\n",
      "Iter 2463 | Time 81.3143(74.5063) | Bit/dim 3.4913(3.4900) | Xent 0.0000(0.0000) | Loss 8.5062(9.0222) | Error 0.0000(0.0000) Steps 724(694.88) | Grad Norm 1.3555(1.8528) | Total Time 0.00(0.00)\n",
      "Iter 2464 | Time 76.3558(74.5618) | Bit/dim 3.4987(3.4903) | Xent 0.0000(0.0000) | Loss 8.5579(9.0082) | Error 0.0000(0.0000) Steps 700(695.03) | Grad Norm 0.8526(1.8228) | Total Time 0.00(0.00)\n",
      "Iter 2465 | Time 71.4297(74.4679) | Bit/dim 3.4920(3.4903) | Xent 0.0000(0.0000) | Loss 8.5264(8.9938) | Error 0.0000(0.0000) Steps 694(695.00) | Grad Norm 0.9558(1.7968) | Total Time 0.00(0.00)\n",
      "Iter 2466 | Time 78.9214(74.6015) | Bit/dim 3.4876(3.4902) | Xent 0.0000(0.0000) | Loss 8.3372(8.9741) | Error 0.0000(0.0000) Steps 700(695.15) | Grad Norm 1.7343(1.7949) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 24.8148, Epoch Time 492.6751(485.1973), Bit/dim 3.4882(best: 3.4886), Xent 0.0000, Loss 3.4882, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2467 | Time 74.8002(74.6074) | Bit/dim 3.4792(3.4899) | Xent 0.0000(0.0000) | Loss 11.7707(9.0580) | Error 0.0000(0.0000) Steps 694(695.11) | Grad Norm 2.2913(1.8098) | Total Time 0.00(0.00)\n",
      "Iter 2468 | Time 74.2342(74.5962) | Bit/dim 3.4996(3.4902) | Xent 0.0000(0.0000) | Loss 8.4509(9.0398) | Error 0.0000(0.0000) Steps 700(695.26) | Grad Norm 2.1568(1.8202) | Total Time 0.00(0.00)\n",
      "Iter 2469 | Time 75.5026(74.6234) | Bit/dim 3.4823(3.4900) | Xent 0.0000(0.0000) | Loss 8.2749(9.0168) | Error 0.0000(0.0000) Steps 682(694.86) | Grad Norm 2.0997(1.8286) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 74.7868(74.6283) | Bit/dim 3.4793(3.4896) | Xent 0.0000(0.0000) | Loss 8.4510(8.9999) | Error 0.0000(0.0000) Steps 694(694.84) | Grad Norm 2.3218(1.8434) | Total Time 0.00(0.00)\n",
      "Iter 2471 | Time 73.4823(74.5939) | Bit/dim 3.4970(3.4899) | Xent 0.0000(0.0000) | Loss 8.3067(8.9791) | Error 0.0000(0.0000) Steps 694(694.81) | Grad Norm 2.5450(1.8644) | Total Time 0.00(0.00)\n",
      "Iter 2472 | Time 80.2906(74.7648) | Bit/dim 3.4942(3.4900) | Xent 0.0000(0.0000) | Loss 8.5286(8.9655) | Error 0.0000(0.0000) Steps 712(695.33) | Grad Norm 2.9449(1.8968) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 25.1527, Epoch Time 493.8027(485.4555), Bit/dim 3.4853(best: 3.4882), Xent 0.0000, Loss 3.4853, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2473 | Time 80.3165(74.9314) | Bit/dim 3.4924(3.4901) | Xent 0.0000(0.0000) | Loss 11.8439(9.0519) | Error 0.0000(0.0000) Steps 688(695.11) | Grad Norm 3.2883(1.9386) | Total Time 0.00(0.00)\n",
      "Iter 2474 | Time 76.8484(74.9889) | Bit/dim 3.4962(3.4902) | Xent 0.0000(0.0000) | Loss 8.4174(9.0329) | Error 0.0000(0.0000) Steps 724(695.97) | Grad Norm 3.1818(1.9759) | Total Time 0.00(0.00)\n",
      "Iter 2475 | Time 82.5455(75.2156) | Bit/dim 3.4818(3.4900) | Xent 0.0000(0.0000) | Loss 8.4513(9.0154) | Error 0.0000(0.0000) Steps 700(696.09) | Grad Norm 2.7795(2.0000) | Total Time 0.00(0.00)\n",
      "Iter 2476 | Time 81.8319(75.4141) | Bit/dim 3.4949(3.4901) | Xent 0.0000(0.0000) | Loss 8.4942(8.9998) | Error 0.0000(0.0000) Steps 712(696.57) | Grad Norm 2.2957(2.0089) | Total Time 0.00(0.00)\n",
      "Iter 2477 | Time 76.1664(75.4367) | Bit/dim 3.4983(3.4904) | Xent 0.0000(0.0000) | Loss 8.5534(8.9864) | Error 0.0000(0.0000) Steps 712(697.03) | Grad Norm 1.8466(2.0040) | Total Time 0.00(0.00)\n",
      "Iter 2478 | Time 79.8430(75.5688) | Bit/dim 3.4804(3.4901) | Xent 0.0000(0.0000) | Loss 8.3963(8.9687) | Error 0.0000(0.0000) Steps 712(697.48) | Grad Norm 1.8240(1.9986) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 24.9689, Epoch Time 518.9339(486.4599), Bit/dim 3.4968(best: 3.4853), Xent 0.0000, Loss 3.4968, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2479 | Time 79.4774(75.6861) | Bit/dim 3.4920(3.4901) | Xent 0.0000(0.0000) | Loss 12.3276(9.0694) | Error 0.0000(0.0000) Steps 682(697.02) | Grad Norm 2.4410(2.0119) | Total Time 0.00(0.00)\n",
      "Iter 2480 | Time 73.5800(75.6229) | Bit/dim 3.4922(3.4902) | Xent 0.0000(0.0000) | Loss 8.4279(9.0502) | Error 0.0000(0.0000) Steps 688(696.75) | Grad Norm 2.9254(2.0393) | Total Time 0.00(0.00)\n",
      "Iter 2481 | Time 78.2056(75.7004) | Bit/dim 3.4849(3.4900) | Xent 0.0000(0.0000) | Loss 8.4548(9.0323) | Error 0.0000(0.0000) Steps 712(697.21) | Grad Norm 3.2596(2.0759) | Total Time 0.00(0.00)\n",
      "Iter 2482 | Time 73.8757(75.6457) | Bit/dim 3.4921(3.4901) | Xent 0.0000(0.0000) | Loss 8.3386(9.0115) | Error 0.0000(0.0000) Steps 688(696.93) | Grad Norm 3.2981(2.1125) | Total Time 0.00(0.00)\n",
      "Iter 2483 | Time 72.8956(75.5632) | Bit/dim 3.4977(3.4903) | Xent 0.0000(0.0000) | Loss 8.1522(8.9857) | Error 0.0000(0.0000) Steps 658(695.76) | Grad Norm 2.6519(2.1287) | Total Time 0.00(0.00)\n",
      "Iter 2484 | Time 76.5897(75.5940) | Bit/dim 3.4933(3.4904) | Xent 0.0000(0.0000) | Loss 8.0725(8.9583) | Error 0.0000(0.0000) Steps 694(695.71) | Grad Norm 1.3772(2.1062) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 25.5678, Epoch Time 495.9073(486.7433), Bit/dim 3.4927(best: 3.4853), Xent 0.0000, Loss 3.4927, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2485 | Time 74.7189(75.5677) | Bit/dim 3.4949(3.4906) | Xent 0.0000(0.0000) | Loss 12.1883(9.0552) | Error 0.0000(0.0000) Steps 706(696.02) | Grad Norm 0.7702(2.0661) | Total Time 0.00(0.00)\n",
      "Iter 2486 | Time 76.6246(75.5994) | Bit/dim 3.4838(3.4904) | Xent 0.0000(0.0000) | Loss 8.2697(9.0317) | Error 0.0000(0.0000) Steps 700(696.14) | Grad Norm 1.7683(2.0572) | Total Time 0.00(0.00)\n",
      "Iter 2487 | Time 76.6791(75.6318) | Bit/dim 3.4843(3.4902) | Xent 0.0000(0.0000) | Loss 8.2159(9.0072) | Error 0.0000(0.0000) Steps 676(695.53) | Grad Norm 2.6724(2.0756) | Total Time 0.00(0.00)\n",
      "Iter 2488 | Time 74.9031(75.6099) | Bit/dim 3.4797(3.4899) | Xent 0.0000(0.0000) | Loss 8.3693(8.9881) | Error 0.0000(0.0000) Steps 700(695.67) | Grad Norm 3.1214(2.1070) | Total Time 0.00(0.00)\n",
      "Iter 2489 | Time 74.8240(75.5864) | Bit/dim 3.5003(3.4902) | Xent 0.0000(0.0000) | Loss 8.3594(8.9692) | Error 0.0000(0.0000) Steps 676(695.08) | Grad Norm 3.0339(2.1348) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 74.2635(75.5467) | Bit/dim 3.5060(3.4906) | Xent 0.0000(0.0000) | Loss 8.2689(8.9482) | Error 0.0000(0.0000) Steps 670(694.33) | Grad Norm 2.4170(2.1433) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 24.7502, Epoch Time 492.9125(486.9283), Bit/dim 3.4962(best: 3.4853), Xent 0.0000, Loss 3.4962, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2491 | Time 80.5852(75.6978) | Bit/dim 3.4742(3.4902) | Xent 0.0000(0.0000) | Loss 12.4047(9.0519) | Error 0.0000(0.0000) Steps 694(694.32) | Grad Norm 1.6053(2.1271) | Total Time 0.00(0.00)\n",
      "Iter 2492 | Time 78.5428(75.7832) | Bit/dim 3.4889(3.4901) | Xent 0.0000(0.0000) | Loss 8.5032(9.0354) | Error 0.0000(0.0000) Steps 712(694.85) | Grad Norm 1.3042(2.1024) | Total Time 0.00(0.00)\n",
      "Iter 2493 | Time 74.9265(75.7575) | Bit/dim 3.4960(3.4903) | Xent 0.0000(0.0000) | Loss 8.1760(9.0096) | Error 0.0000(0.0000) Steps 706(695.18) | Grad Norm 1.9059(2.0965) | Total Time 0.00(0.00)\n",
      "Iter 2494 | Time 78.2615(75.8326) | Bit/dim 3.4795(3.4900) | Xent 0.0000(0.0000) | Loss 8.2229(8.9860) | Error 0.0000(0.0000) Steps 700(695.33) | Grad Norm 2.9351(2.1217) | Total Time 0.00(0.00)\n",
      "Iter 2495 | Time 69.0271(75.6284) | Bit/dim 3.4970(3.4902) | Xent 0.0000(0.0000) | Loss 8.2847(8.9650) | Error 0.0000(0.0000) Steps 694(695.29) | Grad Norm 3.3813(2.1595) | Total Time 0.00(0.00)\n",
      "Iter 2496 | Time 76.4653(75.6535) | Bit/dim 3.4902(3.4902) | Xent 0.0000(0.0000) | Loss 8.3910(8.9478) | Error 0.0000(0.0000) Steps 694(695.25) | Grad Norm 3.1301(2.1886) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 24.0806, Epoch Time 497.4098(487.2428), Bit/dim 3.4904(best: 3.4853), Xent 0.0000, Loss 3.4904, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2497 | Time 74.2390(75.6111) | Bit/dim 3.4903(3.4902) | Xent 0.0000(0.0000) | Loss 12.0786(9.0417) | Error 0.0000(0.0000) Steps 712(695.75) | Grad Norm 2.3113(2.1923) | Total Time 0.00(0.00)\n",
      "Iter 2498 | Time 80.7818(75.7662) | Bit/dim 3.4800(3.4899) | Xent 0.0000(0.0000) | Loss 8.3963(9.0223) | Error 0.0000(0.0000) Steps 706(696.06) | Grad Norm 1.2081(2.1628) | Total Time 0.00(0.00)\n",
      "Iter 2499 | Time 75.5363(75.7593) | Bit/dim 3.4809(3.4896) | Xent 0.0000(0.0000) | Loss 8.4170(9.0042) | Error 0.0000(0.0000) Steps 694(696.00) | Grad Norm 1.3293(2.1378) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 81.2374(75.9237) | Bit/dim 3.4912(3.4897) | Xent 0.0000(0.0000) | Loss 8.4905(8.9888) | Error 0.0000(0.0000) Steps 712(696.48) | Grad Norm 2.5369(2.1497) | Total Time 0.00(0.00)\n",
      "Iter 2501 | Time 73.7061(75.8571) | Bit/dim 3.5009(3.4900) | Xent 0.0000(0.0000) | Loss 8.3935(8.9709) | Error 0.0000(0.0000) Steps 658(695.32) | Grad Norm 3.5102(2.1905) | Total Time 0.00(0.00)\n",
      "Iter 2502 | Time 78.4915(75.9362) | Bit/dim 3.4970(3.4902) | Xent 0.0000(0.0000) | Loss 8.4476(8.9552) | Error 0.0000(0.0000) Steps 694(695.28) | Grad Norm 3.5946(2.2327) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 24.4581, Epoch Time 504.2858(487.7541), Bit/dim 3.4914(best: 3.4853), Xent 0.0000, Loss 3.4914, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2503 | Time 70.5908(75.7758) | Bit/dim 3.4812(3.4899) | Xent 0.0000(0.0000) | Loss 12.1688(9.0516) | Error 0.0000(0.0000) Steps 682(694.88) | Grad Norm 2.7930(2.2495) | Total Time 0.00(0.00)\n",
      "Iter 2504 | Time 79.5539(75.8892) | Bit/dim 3.5019(3.4903) | Xent 0.0000(0.0000) | Loss 8.4305(9.0330) | Error 0.0000(0.0000) Steps 712(695.40) | Grad Norm 1.7665(2.2350) | Total Time 0.00(0.00)\n",
      "Iter 2505 | Time 82.8439(76.0978) | Bit/dim 3.4791(3.4900) | Xent 0.0000(0.0000) | Loss 8.3880(9.0136) | Error 0.0000(0.0000) Steps 724(696.25) | Grad Norm 2.1400(2.2321) | Total Time 0.00(0.00)\n",
      "Iter 2506 | Time 72.0636(75.9768) | Bit/dim 3.4903(3.4900) | Xent 0.0000(0.0000) | Loss 8.0590(8.9850) | Error 0.0000(0.0000) Steps 664(695.29) | Grad Norm 3.2899(2.2639) | Total Time 0.00(0.00)\n",
      "Iter 2507 | Time 78.9786(76.0668) | Bit/dim 3.4991(3.4902) | Xent 0.0000(0.0000) | Loss 8.3434(8.9658) | Error 0.0000(0.0000) Steps 706(695.61) | Grad Norm 3.7531(2.3086) | Total Time 0.00(0.00)\n",
      "Iter 2508 | Time 78.4743(76.1391) | Bit/dim 3.4961(3.4904) | Xent 0.0000(0.0000) | Loss 8.3116(8.9461) | Error 0.0000(0.0000) Steps 688(695.38) | Grad Norm 3.1032(2.3324) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 24.1620, Epoch Time 503.1667(488.2165), Bit/dim 3.4942(best: 3.4853), Xent 0.0000, Loss 3.4942, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2509 | Time 73.6509(76.0644) | Bit/dim 3.4883(3.4904) | Xent 0.0000(0.0000) | Loss 12.1722(9.0429) | Error 0.0000(0.0000) Steps 706(695.70) | Grad Norm 2.3222(2.3321) | Total Time 0.00(0.00)\n",
      "Iter 2510 | Time 82.4527(76.2561) | Bit/dim 3.4816(3.4901) | Xent 0.0000(0.0000) | Loss 8.4006(9.0236) | Error 0.0000(0.0000) Steps 724(696.55) | Grad Norm 2.4962(2.3370) | Total Time 0.00(0.00)\n",
      "Iter 2511 | Time 76.7663(76.2714) | Bit/dim 3.5025(3.4905) | Xent 0.0000(0.0000) | Loss 8.1721(8.9981) | Error 0.0000(0.0000) Steps 676(695.93) | Grad Norm 3.5932(2.3747) | Total Time 0.00(0.00)\n",
      "Iter 2512 | Time 77.8740(76.3194) | Bit/dim 3.4947(3.4906) | Xent 0.0000(0.0000) | Loss 8.5066(8.9834) | Error 0.0000(0.0000) Steps 718(696.59) | Grad Norm 3.7695(2.4165) | Total Time 0.00(0.00)\n",
      "Iter 2513 | Time 78.6934(76.3907) | Bit/dim 3.4826(3.4904) | Xent 0.0000(0.0000) | Loss 8.3116(8.9632) | Error 0.0000(0.0000) Steps 700(696.70) | Grad Norm 2.7539(2.4267) | Total Time 0.00(0.00)\n",
      "Iter 2514 | Time 76.2178(76.3855) | Bit/dim 3.4887(3.4903) | Xent 0.0000(0.0000) | Loss 8.2713(8.9424) | Error 0.0000(0.0000) Steps 700(696.79) | Grad Norm 1.5427(2.4001) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 24.3347, Epoch Time 505.8504(488.7455), Bit/dim 3.4918(best: 3.4853), Xent 0.0000, Loss 3.4918, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2515 | Time 79.9481(76.4924) | Bit/dim 3.4886(3.4903) | Xent 0.0000(0.0000) | Loss 12.3026(9.0433) | Error 0.0000(0.0000) Steps 706(697.07) | Grad Norm 0.7726(2.3513) | Total Time 0.00(0.00)\n",
      "Iter 2516 | Time 81.5588(76.6443) | Bit/dim 3.4953(3.4904) | Xent 0.0000(0.0000) | Loss 8.3230(9.0216) | Error 0.0000(0.0000) Steps 688(696.80) | Grad Norm 0.9186(2.3083) | Total Time 0.00(0.00)\n",
      "Iter 2517 | Time 77.4697(76.6691) | Bit/dim 3.4779(3.4900) | Xent 0.0000(0.0000) | Loss 8.3672(9.0020) | Error 0.0000(0.0000) Steps 700(696.89) | Grad Norm 1.6054(2.2872) | Total Time 0.00(0.00)\n",
      "Iter 2518 | Time 74.7197(76.6106) | Bit/dim 3.4844(3.4899) | Xent 0.0000(0.0000) | Loss 8.2827(8.9804) | Error 0.0000(0.0000) Steps 682(696.45) | Grad Norm 2.4626(2.2925) | Total Time 0.00(0.00)\n",
      "Iter 2519 | Time 78.9763(76.6816) | Bit/dim 3.5013(3.4902) | Xent 0.0000(0.0000) | Loss 8.2101(8.9573) | Error 0.0000(0.0000) Steps 706(696.73) | Grad Norm 2.8299(2.3086) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 79.2586(76.7589) | Bit/dim 3.4935(3.4903) | Xent 0.0000(0.0000) | Loss 8.4130(8.9410) | Error 0.0000(0.0000) Steps 706(697.01) | Grad Norm 2.4900(2.3141) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 24.2456, Epoch Time 512.0713(489.4453), Bit/dim 3.4898(best: 3.4853), Xent 0.0000, Loss 3.4898, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2521 | Time 80.8851(76.8827) | Bit/dim 3.4829(3.4901) | Xent 0.0000(0.0000) | Loss 12.0151(9.0332) | Error 0.0000(0.0000) Steps 712(697.46) | Grad Norm 1.7203(2.2963) | Total Time 0.00(0.00)\n",
      "Iter 2522 | Time 81.7030(77.0273) | Bit/dim 3.4938(3.4902) | Xent 0.0000(0.0000) | Loss 8.3115(9.0116) | Error 0.0000(0.0000) Steps 688(697.18) | Grad Norm 1.0966(2.2603) | Total Time 0.00(0.00)\n",
      "Iter 2523 | Time 82.4967(77.1914) | Bit/dim 3.4888(3.4902) | Xent 0.0000(0.0000) | Loss 8.3897(8.9929) | Error 0.0000(0.0000) Steps 718(697.80) | Grad Norm 0.6702(2.2126) | Total Time 0.00(0.00)\n",
      "Iter 2524 | Time 82.7382(77.3578) | Bit/dim 3.4914(3.4902) | Xent 0.0000(0.0000) | Loss 8.3017(8.9722) | Error 0.0000(0.0000) Steps 718(698.41) | Grad Norm 1.1062(2.1794) | Total Time 0.00(0.00)\n",
      "Iter 2525 | Time 80.9866(77.4667) | Bit/dim 3.4872(3.4901) | Xent 0.0000(0.0000) | Loss 8.5673(8.9600) | Error 0.0000(0.0000) Steps 736(699.54) | Grad Norm 1.6143(2.1624) | Total Time 0.00(0.00)\n",
      "Iter 2526 | Time 80.1346(77.5467) | Bit/dim 3.4864(3.4900) | Xent 0.0000(0.0000) | Loss 8.2306(8.9381) | Error 0.0000(0.0000) Steps 706(699.73) | Grad Norm 2.6079(2.1758) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 24.4417, Epoch Time 529.4632(490.6458), Bit/dim 3.4943(best: 3.4853), Xent 0.0000, Loss 3.4943, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2527 | Time 79.2342(77.5973) | Bit/dim 3.4877(3.4899) | Xent 0.0000(0.0000) | Loss 12.1786(9.0354) | Error 0.0000(0.0000) Steps 706(699.92) | Grad Norm 3.4525(2.2141) | Total Time 0.00(0.00)\n",
      "Iter 2528 | Time 74.9277(77.5172) | Bit/dim 3.4808(3.4896) | Xent 0.0000(0.0000) | Loss 8.2347(9.0113) | Error 0.0000(0.0000) Steps 688(699.56) | Grad Norm 3.9373(2.2658) | Total Time 0.00(0.00)\n",
      "Iter 2529 | Time 82.8939(77.6785) | Bit/dim 3.4973(3.4899) | Xent 0.0000(0.0000) | Loss 8.2675(8.9890) | Error 0.0000(0.0000) Steps 688(699.21) | Grad Norm 3.7361(2.3099) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 81.8067(77.8024) | Bit/dim 3.4926(3.4900) | Xent 0.0000(0.0000) | Loss 8.5432(8.9756) | Error 0.0000(0.0000) Steps 730(700.14) | Grad Norm 2.8635(2.3265) | Total Time 0.00(0.00)\n",
      "Iter 2531 | Time 82.6038(77.9464) | Bit/dim 3.4857(3.4898) | Xent 0.0000(0.0000) | Loss 8.3845(8.9579) | Error 0.0000(0.0000) Steps 724(700.85) | Grad Norm 1.6157(2.3052) | Total Time 0.00(0.00)\n",
      "Iter 2532 | Time 81.0197(78.0386) | Bit/dim 3.5003(3.4901) | Xent 0.0000(0.0000) | Loss 8.2937(8.9380) | Error 0.0000(0.0000) Steps 706(701.01) | Grad Norm 1.7270(2.2878) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 24.7188, Epoch Time 523.0455(491.6178), Bit/dim 3.4932(best: 3.4853), Xent 0.0000, Loss 3.4932, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2533 | Time 86.6866(78.2981) | Bit/dim 3.4884(3.4901) | Xent 0.0000(0.0000) | Loss 12.1272(9.0337) | Error 0.0000(0.0000) Steps 724(701.70) | Grad Norm 2.8891(2.3059) | Total Time 0.00(0.00)\n",
      "Iter 2534 | Time 84.7737(78.4923) | Bit/dim 3.4839(3.4899) | Xent 0.0000(0.0000) | Loss 8.3746(9.0139) | Error 0.0000(0.0000) Steps 724(702.37) | Grad Norm 3.5586(2.3434) | Total Time 0.00(0.00)\n",
      "Iter 2535 | Time 79.3130(78.5169) | Bit/dim 3.4826(3.4897) | Xent 0.0000(0.0000) | Loss 8.3131(8.9929) | Error 0.0000(0.0000) Steps 712(702.66) | Grad Norm 3.1057(2.3663) | Total Time 0.00(0.00)\n",
      "Iter 2536 | Time 78.3043(78.5106) | Bit/dim 3.4819(3.4895) | Xent 0.0000(0.0000) | Loss 8.0186(8.9636) | Error 0.0000(0.0000) Steps 688(702.22) | Grad Norm 1.7740(2.3485) | Total Time 0.00(0.00)\n",
      "Iter 2537 | Time 79.0186(78.5258) | Bit/dim 3.4960(3.4897) | Xent 0.0000(0.0000) | Loss 8.1311(8.9387) | Error 0.0000(0.0000) Steps 682(701.61) | Grad Norm 0.4819(2.2925) | Total Time 0.00(0.00)\n",
      "Iter 2538 | Time 82.4361(78.6431) | Bit/dim 3.4904(3.4897) | Xent 0.0000(0.0000) | Loss 8.4323(8.9235) | Error 0.0000(0.0000) Steps 724(702.28) | Grad Norm 1.6191(2.2723) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 25.3189, Epoch Time 531.7040(492.8204), Bit/dim 3.4887(best: 3.4853), Xent 0.0000, Loss 3.4887, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2539 | Time 86.0628(78.8657) | Bit/dim 3.4889(3.4896) | Xent 0.0000(0.0000) | Loss 12.5922(9.0335) | Error 0.0000(0.0000) Steps 730(703.11) | Grad Norm 2.8069(2.2884) | Total Time 0.00(0.00)\n",
      "Iter 2540 | Time 80.7053(78.9209) | Bit/dim 3.4809(3.4894) | Xent 0.0000(0.0000) | Loss 8.5847(9.0201) | Error 0.0000(0.0000) Steps 730(703.92) | Grad Norm 3.4025(2.3218) | Total Time 0.00(0.00)\n",
      "Iter 2541 | Time 80.4853(78.9678) | Bit/dim 3.4887(3.4894) | Xent 0.0000(0.0000) | Loss 8.3880(9.0011) | Error 0.0000(0.0000) Steps 712(704.16) | Grad Norm 3.3277(2.3520) | Total Time 0.00(0.00)\n",
      "Iter 2542 | Time 82.3080(79.0680) | Bit/dim 3.4827(3.4892) | Xent 0.0000(0.0000) | Loss 8.3357(8.9811) | Error 0.0000(0.0000) Steps 712(704.40) | Grad Norm 2.6459(2.3608) | Total Time 0.00(0.00)\n",
      "Iter 2543 | Time 78.5868(79.0536) | Bit/dim 3.4936(3.4893) | Xent 0.0000(0.0000) | Loss 8.5111(8.9670) | Error 0.0000(0.0000) Steps 694(704.09) | Grad Norm 2.2674(2.3580) | Total Time 0.00(0.00)\n",
      "Iter 2544 | Time 79.0659(79.0540) | Bit/dim 3.4891(3.4893) | Xent 0.0000(0.0000) | Loss 8.3973(8.9500) | Error 0.0000(0.0000) Steps 706(704.14) | Grad Norm 2.8427(2.3725) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 24.3484, Epoch Time 527.3893(493.8574), Bit/dim 3.4984(best: 3.4853), Xent 0.0000, Loss 3.4984, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2545 | Time 81.5137(79.1278) | Bit/dim 3.4951(3.4895) | Xent 0.0000(0.0000) | Loss 12.5904(9.0592) | Error 0.0000(0.0000) Steps 724(704.74) | Grad Norm 3.3784(2.4027) | Total Time 0.00(0.00)\n",
      "Iter 2546 | Time 77.5105(79.0792) | Bit/dim 3.4801(3.4892) | Xent 0.0000(0.0000) | Loss 8.2450(9.0347) | Error 0.0000(0.0000) Steps 712(704.96) | Grad Norm 3.4277(2.4335) | Total Time 0.00(0.00)\n",
      "Iter 2547 | Time 83.4230(79.2096) | Bit/dim 3.4882(3.4892) | Xent 0.0000(0.0000) | Loss 8.4484(9.0172) | Error 0.0000(0.0000) Steps 706(704.99) | Grad Norm 2.7147(2.4419) | Total Time 0.00(0.00)\n",
      "Iter 2548 | Time 80.0689(79.2353) | Bit/dim 3.4745(3.4887) | Xent 0.0000(0.0000) | Loss 8.2824(8.9951) | Error 0.0000(0.0000) Steps 712(705.20) | Grad Norm 1.7957(2.4225) | Total Time 0.00(0.00)\n",
      "Iter 2549 | Time 78.8722(79.2244) | Bit/dim 3.4906(3.4888) | Xent 0.0000(0.0000) | Loss 8.5145(8.9807) | Error 0.0000(0.0000) Steps 706(705.22) | Grad Norm 1.9352(2.4079) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 84.8505(79.3932) | Bit/dim 3.4859(3.4887) | Xent 0.0000(0.0000) | Loss 8.5705(8.9684) | Error 0.0000(0.0000) Steps 724(705.79) | Grad Norm 2.6803(2.4161) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 24.4871, Epoch Time 526.7102(494.8430), Bit/dim 3.4884(best: 3.4853), Xent 0.0000, Loss 3.4884, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2551 | Time 80.4997(79.4264) | Bit/dim 3.4957(3.4889) | Xent 0.0000(0.0000) | Loss 11.9763(9.0586) | Error 0.0000(0.0000) Steps 694(705.43) | Grad Norm 2.9266(2.4314) | Total Time 0.00(0.00)\n",
      "Iter 2552 | Time 82.0506(79.5051) | Bit/dim 3.4913(3.4890) | Xent 0.0000(0.0000) | Loss 8.4465(9.0403) | Error 0.0000(0.0000) Steps 724(705.99) | Grad Norm 2.5245(2.4342) | Total Time 0.00(0.00)\n",
      "Iter 2553 | Time 79.3505(79.5005) | Bit/dim 3.4843(3.4888) | Xent 0.0000(0.0000) | Loss 8.1754(9.0143) | Error 0.0000(0.0000) Steps 700(705.81) | Grad Norm 1.6234(2.4099) | Total Time 0.00(0.00)\n",
      "Iter 2554 | Time 88.9327(79.7835) | Bit/dim 3.4877(3.4888) | Xent 0.0000(0.0000) | Loss 8.4309(8.9968) | Error 0.0000(0.0000) Steps 712(705.99) | Grad Norm 0.5918(2.3553) | Total Time 0.00(0.00)\n",
      "Iter 2555 | Time 78.2709(79.7381) | Bit/dim 3.4838(3.4886) | Xent 0.0000(0.0000) | Loss 8.4646(8.9808) | Error 0.0000(0.0000) Steps 700(705.81) | Grad Norm 1.0643(2.3166) | Total Time 0.00(0.00)\n",
      "Iter 2556 | Time 79.3367(79.7260) | Bit/dim 3.4743(3.4882) | Xent 0.0000(0.0000) | Loss 8.3490(8.9619) | Error 0.0000(0.0000) Steps 706(705.82) | Grad Norm 2.0290(2.3080) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 24.5829, Epoch Time 529.2512(495.8753), Bit/dim 3.4890(best: 3.4853), Xent 0.0000, Loss 3.4890, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2557 | Time 82.1680(79.7993) | Bit/dim 3.4930(3.4884) | Xent 0.0000(0.0000) | Loss 12.4534(9.0666) | Error 0.0000(0.0000) Steps 730(706.55) | Grad Norm 2.5863(2.3163) | Total Time 0.00(0.00)\n",
      "Iter 2558 | Time 81.8928(79.8621) | Bit/dim 3.4884(3.4884) | Xent 0.0000(0.0000) | Loss 8.3493(9.0451) | Error 0.0000(0.0000) Steps 706(706.53) | Grad Norm 2.6608(2.3266) | Total Time 0.00(0.00)\n",
      "Iter 2559 | Time 80.2130(79.8726) | Bit/dim 3.4966(3.4886) | Xent 0.0000(0.0000) | Loss 8.2990(9.0227) | Error 0.0000(0.0000) Steps 694(706.15) | Grad Norm 2.4735(2.3310) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 78.2657(79.8244) | Bit/dim 3.4834(3.4885) | Xent 0.0000(0.0000) | Loss 8.3469(9.0025) | Error 0.0000(0.0000) Steps 706(706.15) | Grad Norm 2.2821(2.3296) | Total Time 0.00(0.00)\n",
      "Iter 2561 | Time 87.5001(80.0547) | Bit/dim 3.4834(3.4883) | Xent 0.0000(0.0000) | Loss 8.5350(8.9884) | Error 0.0000(0.0000) Steps 718(706.50) | Grad Norm 2.8404(2.3449) | Total Time 0.00(0.00)\n",
      "Iter 2562 | Time 79.5862(80.0406) | Bit/dim 3.4846(3.4882) | Xent 0.0000(0.0000) | Loss 8.2673(8.9668) | Error 0.0000(0.0000) Steps 712(706.67) | Grad Norm 3.6867(2.3852) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 24.7469, Epoch Time 529.9609(496.8978), Bit/dim 3.4910(best: 3.4853), Xent 0.0000, Loss 3.4910, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2563 | Time 79.9432(80.0377) | Bit/dim 3.4933(3.4883) | Xent 0.0000(0.0000) | Loss 12.3898(9.0695) | Error 0.0000(0.0000) Steps 712(706.83) | Grad Norm 3.7214(2.4252) | Total Time 0.00(0.00)\n",
      "Iter 2564 | Time 80.2861(80.0452) | Bit/dim 3.4843(3.4882) | Xent 0.0000(0.0000) | Loss 8.4510(9.0509) | Error 0.0000(0.0000) Steps 700(706.62) | Grad Norm 2.8178(2.4370) | Total Time 0.00(0.00)\n",
      "Iter 2565 | Time 79.4918(80.0286) | Bit/dim 3.4862(3.4882) | Xent 0.0000(0.0000) | Loss 8.4160(9.0319) | Error 0.0000(0.0000) Steps 694(706.25) | Grad Norm 1.4933(2.4087) | Total Time 0.00(0.00)\n",
      "Iter 2566 | Time 79.3896(80.0094) | Bit/dim 3.4879(3.4882) | Xent 0.0000(0.0000) | Loss 8.4257(9.0137) | Error 0.0000(0.0000) Steps 694(705.88) | Grad Norm 0.7019(2.3575) | Total Time 0.00(0.00)\n",
      "Iter 2567 | Time 84.1843(80.1346) | Bit/dim 3.4883(3.4882) | Xent 0.0000(0.0000) | Loss 8.3294(8.9932) | Error 0.0000(0.0000) Steps 700(705.70) | Grad Norm 1.5572(2.3335) | Total Time 0.00(0.00)\n",
      "Iter 2568 | Time 87.2449(80.3480) | Bit/dim 3.4925(3.4883) | Xent 0.0000(0.0000) | Loss 8.3985(8.9753) | Error 0.0000(0.0000) Steps 712(705.89) | Grad Norm 2.1974(2.3294) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 24.5707, Epoch Time 530.9024(497.9180), Bit/dim 3.4872(best: 3.4853), Xent 0.0000, Loss 3.4872, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2569 | Time 75.3383(80.1977) | Bit/dim 3.4926(3.4884) | Xent 0.0000(0.0000) | Loss 12.3231(9.0758) | Error 0.0000(0.0000) Steps 718(706.25) | Grad Norm 2.5337(2.3355) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 76.9651(80.1007) | Bit/dim 3.4872(3.4884) | Xent 0.0000(0.0000) | Loss 8.3344(9.0535) | Error 0.0000(0.0000) Steps 676(705.35) | Grad Norm 2.4963(2.3404) | Total Time 0.00(0.00)\n",
      "Iter 2571 | Time 82.6649(80.1776) | Bit/dim 3.4928(3.4885) | Xent 0.0000(0.0000) | Loss 8.4498(9.0354) | Error 0.0000(0.0000) Steps 724(705.91) | Grad Norm 2.1656(2.3351) | Total Time 0.00(0.00)\n",
      "Iter 2572 | Time 80.3740(80.1835) | Bit/dim 3.4797(3.4882) | Xent 0.0000(0.0000) | Loss 8.2888(9.0130) | Error 0.0000(0.0000) Steps 700(705.73) | Grad Norm 2.0906(2.3278) | Total Time 0.00(0.00)\n",
      "Iter 2573 | Time 81.2690(80.2161) | Bit/dim 3.4866(3.4882) | Xent 0.0000(0.0000) | Loss 8.3468(8.9930) | Error 0.0000(0.0000) Steps 694(705.38) | Grad Norm 2.7163(2.3394) | Total Time 0.00(0.00)\n",
      "Iter 2574 | Time 81.1084(80.2428) | Bit/dim 3.4782(3.4879) | Xent 0.0000(0.0000) | Loss 8.3175(8.9728) | Error 0.0000(0.0000) Steps 700(705.22) | Grad Norm 3.5141(2.3747) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 25.0777, Epoch Time 518.8099(498.5447), Bit/dim 3.4911(best: 3.4853), Xent 0.0000, Loss 3.4911, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2575 | Time 84.8095(80.3798) | Bit/dim 3.4868(3.4879) | Xent 0.0000(0.0000) | Loss 12.3227(9.0733) | Error 0.0000(0.0000) Steps 724(705.78) | Grad Norm 3.6498(2.4129) | Total Time 0.00(0.00)\n",
      "Iter 2576 | Time 77.9250(80.3062) | Bit/dim 3.4897(3.4879) | Xent 0.0000(0.0000) | Loss 8.3494(9.0515) | Error 0.0000(0.0000) Steps 694(705.43) | Grad Norm 3.1443(2.4349) | Total Time 0.00(0.00)\n",
      "Iter 2577 | Time 79.9658(80.2960) | Bit/dim 3.4957(3.4882) | Xent 0.0000(0.0000) | Loss 8.3001(9.0290) | Error 0.0000(0.0000) Steps 700(705.26) | Grad Norm 2.1997(2.4278) | Total Time 0.00(0.00)\n",
      "Iter 2578 | Time 83.9288(80.4050) | Bit/dim 3.4747(3.4878) | Xent 0.0000(0.0000) | Loss 8.2841(9.0067) | Error 0.0000(0.0000) Steps 712(705.47) | Grad Norm 1.0531(2.3866) | Total Time 0.00(0.00)\n",
      "Iter 2579 | Time 78.3837(80.3443) | Bit/dim 3.4822(3.4876) | Xent 0.0000(0.0000) | Loss 8.4083(8.9887) | Error 0.0000(0.0000) Steps 706(705.48) | Grad Norm 1.3164(2.3545) | Total Time 0.00(0.00)\n",
      "Iter 2580 | Time 80.8850(80.3606) | Bit/dim 3.4888(3.4876) | Xent 0.0000(0.0000) | Loss 8.1469(8.9634) | Error 0.0000(0.0000) Steps 706(705.50) | Grad Norm 2.4266(2.3566) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 24.8308, Epoch Time 526.9417(499.3966), Bit/dim 3.4917(best: 3.4853), Xent 0.0000, Loss 3.4917, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2581 | Time 83.8377(80.4649) | Bit/dim 3.4859(3.4876) | Xent 0.0000(0.0000) | Loss 11.9036(9.0517) | Error 0.0000(0.0000) Steps 718(705.87) | Grad Norm 2.9818(2.3754) | Total Time 0.00(0.00)\n",
      "Iter 2582 | Time 82.3976(80.5228) | Bit/dim 3.4918(3.4877) | Xent 0.0000(0.0000) | Loss 8.4342(9.0331) | Error 0.0000(0.0000) Steps 688(705.34) | Grad Norm 2.7523(2.3867) | Total Time 0.00(0.00)\n",
      "Iter 2583 | Time 77.0277(80.4180) | Bit/dim 3.4847(3.4876) | Xent 0.0000(0.0000) | Loss 8.1498(9.0066) | Error 0.0000(0.0000) Steps 694(705.00) | Grad Norm 2.1660(2.3801) | Total Time 0.00(0.00)\n",
      "Iter 2584 | Time 80.6199(80.4240) | Bit/dim 3.4774(3.4873) | Xent 0.0000(0.0000) | Loss 8.0812(8.9789) | Error 0.0000(0.0000) Steps 700(704.85) | Grad Norm 1.4961(2.3536) | Total Time 0.00(0.00)\n",
      "Iter 2585 | Time 82.9954(80.5012) | Bit/dim 3.4940(3.4875) | Xent 0.0000(0.0000) | Loss 8.3087(8.9588) | Error 0.0000(0.0000) Steps 712(705.06) | Grad Norm 1.6429(2.3322) | Total Time 0.00(0.00)\n",
      "Iter 2586 | Time 80.6789(80.5065) | Bit/dim 3.4916(3.4876) | Xent 0.0000(0.0000) | Loss 8.1894(8.9357) | Error 0.0000(0.0000) Steps 700(704.91) | Grad Norm 2.0997(2.3253) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 24.5630, Epoch Time 528.1331(500.2587), Bit/dim 3.4847(best: 3.4853), Xent 0.0000, Loss 3.4847, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2587 | Time 81.7970(80.5452) | Bit/dim 3.4818(3.4875) | Xent 0.0000(0.0000) | Loss 12.2787(9.0360) | Error 0.0000(0.0000) Steps 724(705.48) | Grad Norm 2.4023(2.3276) | Total Time 0.00(0.00)\n",
      "Iter 2588 | Time 76.3776(80.4202) | Bit/dim 3.4877(3.4875) | Xent 0.0000(0.0000) | Loss 8.4361(9.0180) | Error 0.0000(0.0000) Steps 706(705.50) | Grad Norm 2.3759(2.3290) | Total Time 0.00(0.00)\n",
      "Iter 2589 | Time 78.8262(80.3724) | Bit/dim 3.4751(3.4871) | Xent 0.0000(0.0000) | Loss 8.3694(8.9985) | Error 0.0000(0.0000) Steps 700(705.33) | Grad Norm 2.0921(2.3219) | Total Time 0.00(0.00)\n",
      "Iter 2590 | Time 79.6531(80.3508) | Bit/dim 3.5005(3.4875) | Xent 0.0000(0.0000) | Loss 8.5130(8.9840) | Error 0.0000(0.0000) Steps 700(705.17) | Grad Norm 1.6534(2.3019) | Total Time 0.00(0.00)\n",
      "Iter 2591 | Time 81.6219(80.3889) | Bit/dim 3.4879(3.4875) | Xent 0.0000(0.0000) | Loss 8.3961(8.9663) | Error 0.0000(0.0000) Steps 694(704.84) | Grad Norm 0.8842(2.2593) | Total Time 0.00(0.00)\n",
      "Iter 2592 | Time 79.8508(80.3728) | Bit/dim 3.4842(3.4874) | Xent 0.0000(0.0000) | Loss 8.5361(8.9534) | Error 0.0000(0.0000) Steps 712(705.05) | Grad Norm 0.4976(2.2065) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 24.4885, Epoch Time 518.6798(500.8114), Bit/dim 3.4934(best: 3.4847), Xent 0.0000, Loss 3.4934, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2593 | Time 80.2633(80.3695) | Bit/dim 3.4951(3.4876) | Xent 0.0000(0.0000) | Loss 11.9770(9.0441) | Error 0.0000(0.0000) Steps 718(705.44) | Grad Norm 0.7010(2.1613) | Total Time 0.00(0.00)\n",
      "Iter 2594 | Time 78.6130(80.3168) | Bit/dim 3.4879(3.4876) | Xent 0.0000(0.0000) | Loss 8.3423(9.0231) | Error 0.0000(0.0000) Steps 700(705.28) | Grad Norm 1.0186(2.1270) | Total Time 0.00(0.00)\n",
      "Iter 2595 | Time 80.6603(80.3271) | Bit/dim 3.4821(3.4875) | Xent 0.0000(0.0000) | Loss 8.2076(8.9986) | Error 0.0000(0.0000) Steps 730(706.02) | Grad Norm 1.2384(2.1004) | Total Time 0.00(0.00)\n",
      "Iter 2596 | Time 82.3308(80.3872) | Bit/dim 3.4946(3.4877) | Xent 0.0000(0.0000) | Loss 8.4501(8.9821) | Error 0.0000(0.0000) Steps 706(706.02) | Grad Norm 1.3524(2.0779) | Total Time 0.00(0.00)\n",
      "Iter 2597 | Time 80.2658(80.3836) | Bit/dim 3.4868(3.4877) | Xent 0.0000(0.0000) | Loss 8.5152(8.9681) | Error 0.0000(0.0000) Steps 730(706.74) | Grad Norm 1.4654(2.0596) | Total Time 0.00(0.00)\n",
      "Iter 2598 | Time 80.0220(80.3727) | Bit/dim 3.4693(3.4871) | Xent 0.0000(0.0000) | Loss 8.3193(8.9487) | Error 0.0000(0.0000) Steps 706(706.72) | Grad Norm 1.7889(2.0514) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 24.3272, Epoch Time 522.1717(501.4522), Bit/dim 3.4847(best: 3.4847), Xent 0.0000, Loss 3.4847, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2599 | Time 74.4500(80.1951) | Bit/dim 3.4866(3.4871) | Xent 0.0000(0.0000) | Loss 12.1154(9.0437) | Error 0.0000(0.0000) Steps 694(706.33) | Grad Norm 2.3089(2.0592) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 80.7987(80.2132) | Bit/dim 3.4856(3.4870) | Xent 0.0000(0.0000) | Loss 8.2305(9.0193) | Error 0.0000(0.0000) Steps 700(706.14) | Grad Norm 2.5815(2.0748) | Total Time 0.00(0.00)\n",
      "Iter 2601 | Time 76.4383(80.0999) | Bit/dim 3.4988(3.4874) | Xent 0.0000(0.0000) | Loss 8.4633(9.0026) | Error 0.0000(0.0000) Steps 712(706.32) | Grad Norm 2.6328(2.0916) | Total Time 0.00(0.00)\n",
      "Iter 2602 | Time 79.9449(80.0953) | Bit/dim 3.4719(3.4869) | Xent 0.0000(0.0000) | Loss 8.4729(8.9867) | Error 0.0000(0.0000) Steps 730(707.03) | Grad Norm 2.8908(2.1156) | Total Time 0.00(0.00)\n",
      "Iter 2603 | Time 81.3731(80.1336) | Bit/dim 3.4939(3.4871) | Xent 0.0000(0.0000) | Loss 8.5252(8.9729) | Error 0.0000(0.0000) Steps 730(707.72) | Grad Norm 3.3353(2.1521) | Total Time 0.00(0.00)\n",
      "Iter 2604 | Time 82.1161(80.1931) | Bit/dim 3.4780(3.4869) | Xent 0.0000(0.0000) | Loss 8.4499(8.9572) | Error 0.0000(0.0000) Steps 700(707.49) | Grad Norm 3.8520(2.2031) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 24.4497, Epoch Time 515.5095(501.8739), Bit/dim 3.4892(best: 3.4847), Xent 0.0000, Loss 3.4892, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2605 | Time 83.9504(80.3058) | Bit/dim 3.4878(3.4869) | Xent 0.0000(0.0000) | Loss 12.4710(9.0626) | Error 0.0000(0.0000) Steps 724(707.98) | Grad Norm 4.0659(2.2590) | Total Time 0.00(0.00)\n",
      "Iter 2606 | Time 77.5335(80.2226) | Bit/dim 3.4854(3.4869) | Xent 0.0000(0.0000) | Loss 8.4244(9.0434) | Error 0.0000(0.0000) Steps 706(707.92) | Grad Norm 3.7482(2.3037) | Total Time 0.00(0.00)\n",
      "Iter 2607 | Time 76.0129(80.0963) | Bit/dim 3.5012(3.4873) | Xent 0.0000(0.0000) | Loss 7.8955(9.0090) | Error 0.0000(0.0000) Steps 706(707.87) | Grad Norm 2.9822(2.3240) | Total Time 0.00(0.00)\n",
      "Iter 2608 | Time 83.1130(80.1868) | Bit/dim 3.4803(3.4871) | Xent 0.0000(0.0000) | Loss 8.3734(8.9899) | Error 0.0000(0.0000) Steps 706(707.81) | Grad Norm 1.0773(2.2866) | Total Time 0.00(0.00)\n",
      "Iter 2609 | Time 74.8352(80.0263) | Bit/dim 3.4884(3.4871) | Xent 0.0000(0.0000) | Loss 8.4250(8.9730) | Error 0.0000(0.0000) Steps 700(707.58) | Grad Norm 1.1975(2.2540) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 78.0348(79.9665) | Bit/dim 3.4743(3.4867) | Xent 0.0000(0.0000) | Loss 8.3138(8.9532) | Error 0.0000(0.0000) Steps 712(707.71) | Grad Norm 2.7465(2.2687) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 24.1373, Epoch Time 513.3566(502.2184), Bit/dim 3.4931(best: 3.4847), Xent 0.0000, Loss 3.4931, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2611 | Time 78.7712(79.9307) | Bit/dim 3.4762(3.4864) | Xent 0.0000(0.0000) | Loss 12.1327(9.0486) | Error 0.0000(0.0000) Steps 706(707.66) | Grad Norm 3.6018(2.3087) | Total Time 0.00(0.00)\n",
      "Iter 2612 | Time 84.5636(80.0697) | Bit/dim 3.4804(3.4862) | Xent 0.0000(0.0000) | Loss 8.4159(9.0296) | Error 0.0000(0.0000) Steps 730(708.33) | Grad Norm 3.3935(2.3413) | Total Time 0.00(0.00)\n",
      "Iter 2613 | Time 77.8492(80.0031) | Bit/dim 3.5020(3.4867) | Xent 0.0000(0.0000) | Loss 8.4934(9.0135) | Error 0.0000(0.0000) Steps 718(708.62) | Grad Norm 2.2767(2.3393) | Total Time 0.00(0.00)\n",
      "Iter 2614 | Time 81.5566(80.0497) | Bit/dim 3.4808(3.4865) | Xent 0.0000(0.0000) | Loss 8.0611(8.9850) | Error 0.0000(0.0000) Steps 706(708.54) | Grad Norm 0.9914(2.2989) | Total Time 0.00(0.00)\n",
      "Iter 2615 | Time 75.1528(79.9028) | Bit/dim 3.4834(3.4864) | Xent 0.0000(0.0000) | Loss 8.4058(8.9676) | Error 0.0000(0.0000) Steps 682(707.74) | Grad Norm 1.2807(2.2684) | Total Time 0.00(0.00)\n",
      "Iter 2616 | Time 75.9912(79.7854) | Bit/dim 3.4904(3.4866) | Xent 0.0000(0.0000) | Loss 8.2871(8.9472) | Error 0.0000(0.0000) Steps 700(707.51) | Grad Norm 2.2417(2.2676) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 24.6118, Epoch Time 514.1983(502.5778), Bit/dim 3.4876(best: 3.4847), Xent 0.0000, Loss 3.4876, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2617 | Time 79.3260(79.7716) | Bit/dim 3.4899(3.4867) | Xent 0.0000(0.0000) | Loss 12.4326(9.0517) | Error 0.0000(0.0000) Steps 724(708.01) | Grad Norm 2.6341(2.2786) | Total Time 0.00(0.00)\n",
      "Iter 2618 | Time 84.7647(79.9214) | Bit/dim 3.4844(3.4866) | Xent 0.0000(0.0000) | Loss 8.2693(9.0283) | Error 0.0000(0.0000) Steps 724(708.49) | Grad Norm 2.5088(2.2855) | Total Time 0.00(0.00)\n",
      "Iter 2619 | Time 78.6983(79.8847) | Bit/dim 3.4867(3.4866) | Xent 0.0000(0.0000) | Loss 8.3908(9.0091) | Error 0.0000(0.0000) Steps 688(707.87) | Grad Norm 2.2392(2.2841) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 79.7441(79.8805) | Bit/dim 3.4899(3.4867) | Xent 0.0000(0.0000) | Loss 8.3998(8.9909) | Error 0.0000(0.0000) Steps 712(707.99) | Grad Norm 2.2792(2.2839) | Total Time 0.00(0.00)\n",
      "Iter 2621 | Time 77.5599(79.8109) | Bit/dim 3.4891(3.4868) | Xent 0.0000(0.0000) | Loss 8.5427(8.9774) | Error 0.0000(0.0000) Steps 718(708.29) | Grad Norm 2.7274(2.2972) | Total Time 0.00(0.00)\n",
      "Iter 2622 | Time 80.7140(79.8380) | Bit/dim 3.4863(3.4867) | Xent 0.0000(0.0000) | Loss 8.4310(8.9610) | Error 0.0000(0.0000) Steps 712(708.41) | Grad Norm 3.0289(2.3192) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 24.0341, Epoch Time 520.6898(503.1211), Bit/dim 3.4877(best: 3.4847), Xent 0.0000, Loss 3.4877, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2623 | Time 81.6318(79.8918) | Bit/dim 3.4953(3.4870) | Xent 0.0000(0.0000) | Loss 11.8595(9.0480) | Error 0.0000(0.0000) Steps 700(708.15) | Grad Norm 2.8176(2.3341) | Total Time 0.00(0.00)\n",
      "Iter 2624 | Time 75.4076(79.7573) | Bit/dim 3.4858(3.4870) | Xent 0.0000(0.0000) | Loss 8.1906(9.0223) | Error 0.0000(0.0000) Steps 706(708.09) | Grad Norm 1.9116(2.3215) | Total Time 0.00(0.00)\n",
      "Iter 2625 | Time 81.5368(79.8107) | Bit/dim 3.4901(3.4871) | Xent 0.0000(0.0000) | Loss 8.3229(9.0013) | Error 0.0000(0.0000) Steps 706(708.03) | Grad Norm 0.7946(2.2757) | Total Time 0.00(0.00)\n",
      "Iter 2626 | Time 82.2976(79.8853) | Bit/dim 3.4746(3.4867) | Xent 0.0000(0.0000) | Loss 8.4129(8.9836) | Error 0.0000(0.0000) Steps 712(708.15) | Grad Norm 1.0741(2.2396) | Total Time 0.00(0.00)\n",
      "Iter 2627 | Time 84.6795(80.0291) | Bit/dim 3.4739(3.4863) | Xent 0.0000(0.0000) | Loss 8.2506(8.9616) | Error 0.0000(0.0000) Steps 712(708.26) | Grad Norm 2.3215(2.2421) | Total Time 0.00(0.00)\n",
      "Iter 2628 | Time 77.5441(79.9545) | Bit/dim 3.4817(3.4862) | Xent 0.0000(0.0000) | Loss 8.3864(8.9444) | Error 0.0000(0.0000) Steps 694(707.83) | Grad Norm 3.2330(2.2718) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 24.8122, Epoch Time 523.7658(503.7405), Bit/dim 3.4884(best: 3.4847), Xent 0.0000, Loss 3.4884, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2629 | Time 79.0129(79.9263) | Bit/dim 3.4942(3.4864) | Xent 0.0000(0.0000) | Loss 12.3538(9.0467) | Error 0.0000(0.0000) Steps 712(707.96) | Grad Norm 3.4947(2.3085) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 76.2218(79.8152) | Bit/dim 3.4843(3.4863) | Xent 0.0000(0.0000) | Loss 8.4605(9.0291) | Error 0.0000(0.0000) Steps 712(708.08) | Grad Norm 3.2261(2.3360) | Total Time 0.00(0.00)\n",
      "Iter 2631 | Time 76.7611(79.7235) | Bit/dim 3.4935(3.4866) | Xent 0.0000(0.0000) | Loss 8.1539(9.0028) | Error 0.0000(0.0000) Steps 694(707.66) | Grad Norm 2.4281(2.3388) | Total Time 0.00(0.00)\n",
      "Iter 2632 | Time 80.8977(79.7588) | Bit/dim 3.4809(3.4864) | Xent 0.0000(0.0000) | Loss 8.2522(8.9803) | Error 0.0000(0.0000) Steps 706(707.61) | Grad Norm 1.6818(2.3191) | Total Time 0.00(0.00)\n",
      "Iter 2633 | Time 85.1900(79.9217) | Bit/dim 3.4912(3.4865) | Xent 0.0000(0.0000) | Loss 8.5239(8.9666) | Error 0.0000(0.0000) Steps 736(708.46) | Grad Norm 1.8173(2.3040) | Total Time 0.00(0.00)\n",
      "Iter 2634 | Time 85.0083(80.0743) | Bit/dim 3.4803(3.4863) | Xent 0.0000(0.0000) | Loss 8.3810(8.9490) | Error 0.0000(0.0000) Steps 724(708.93) | Grad Norm 2.4555(2.3086) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 24.8611, Epoch Time 523.7932(504.3421), Bit/dim 3.4851(best: 3.4847), Xent 0.0000, Loss 3.4851, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2635 | Time 82.8820(80.1585) | Bit/dim 3.4849(3.4863) | Xent 0.0000(0.0000) | Loss 12.3567(9.0513) | Error 0.0000(0.0000) Steps 724(709.38) | Grad Norm 2.9591(2.3281) | Total Time 0.00(0.00)\n",
      "Iter 2636 | Time 84.3907(80.2855) | Bit/dim 3.4937(3.4865) | Xent 0.0000(0.0000) | Loss 8.6151(9.0382) | Error 0.0000(0.0000) Steps 724(709.82) | Grad Norm 3.1091(2.3515) | Total Time 0.00(0.00)\n",
      "Iter 2637 | Time 82.1546(80.3416) | Bit/dim 3.4811(3.4864) | Xent 0.0000(0.0000) | Loss 8.4157(9.0195) | Error 0.0000(0.0000) Steps 718(710.06) | Grad Norm 2.6586(2.3607) | Total Time 0.00(0.00)\n",
      "Iter 2638 | Time 76.9615(80.2402) | Bit/dim 3.4847(3.4863) | Xent 0.0000(0.0000) | Loss 8.3420(8.9992) | Error 0.0000(0.0000) Steps 706(709.94) | Grad Norm 1.8320(2.3449) | Total Time 0.00(0.00)\n",
      "Iter 2639 | Time 79.1838(80.2085) | Bit/dim 3.4890(3.4864) | Xent 0.0000(0.0000) | Loss 8.2953(8.9781) | Error 0.0000(0.0000) Steps 682(709.10) | Grad Norm 0.8024(2.2986) | Total Time 0.00(0.00)\n",
      "Iter 2640 | Time 76.9754(80.1115) | Bit/dim 3.4852(3.4864) | Xent 0.0000(0.0000) | Loss 8.2993(8.9577) | Error 0.0000(0.0000) Steps 700(708.83) | Grad Norm 0.9329(2.2576) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 24.6674, Epoch Time 522.8999(504.8988), Bit/dim 3.4858(best: 3.4847), Xent 0.0000, Loss 3.4858, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2641 | Time 74.9924(79.9579) | Bit/dim 3.4840(3.4863) | Xent 0.0000(0.0000) | Loss 12.4838(9.0635) | Error 0.0000(0.0000) Steps 724(709.28) | Grad Norm 1.8891(2.2466) | Total Time 0.00(0.00)\n",
      "Iter 2642 | Time 80.3885(79.9708) | Bit/dim 3.4890(3.4864) | Xent 0.0000(0.0000) | Loss 8.2417(9.0388) | Error 0.0000(0.0000) Steps 682(708.47) | Grad Norm 2.6048(2.2573) | Total Time 0.00(0.00)\n",
      "Iter 2643 | Time 78.2952(79.9206) | Bit/dim 3.4883(3.4864) | Xent 0.0000(0.0000) | Loss 8.4009(9.0197) | Error 0.0000(0.0000) Steps 712(708.57) | Grad Norm 3.2831(2.2881) | Total Time 0.00(0.00)\n",
      "Iter 2644 | Time 78.4894(79.8776) | Bit/dim 3.4838(3.4863) | Xent 0.0000(0.0000) | Loss 8.3164(8.9986) | Error 0.0000(0.0000) Steps 694(708.13) | Grad Norm 3.5820(2.3269) | Total Time 0.00(0.00)\n",
      "Iter 2645 | Time 84.3088(80.0106) | Bit/dim 3.4930(3.4865) | Xent 0.0000(0.0000) | Loss 8.3420(8.9789) | Error 0.0000(0.0000) Steps 730(708.79) | Grad Norm 3.2720(2.3552) | Total Time 0.00(0.00)\n",
      "Iter 2646 | Time 75.6833(79.8807) | Bit/dim 3.4897(3.4866) | Xent 0.0000(0.0000) | Loss 7.9810(8.9490) | Error 0.0000(0.0000) Steps 694(708.35) | Grad Norm 2.7532(2.3672) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 23.9362, Epoch Time 511.8891(505.1085), Bit/dim 3.4865(best: 3.4847), Xent 0.0000, Loss 3.4865, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2647 | Time 84.2083(80.0106) | Bit/dim 3.4844(3.4866) | Xent 0.0000(0.0000) | Loss 12.1567(9.0452) | Error 0.0000(0.0000) Steps 694(707.92) | Grad Norm 2.4511(2.3697) | Total Time 0.00(0.00)\n",
      "Iter 2648 | Time 78.3064(79.9594) | Bit/dim 3.4755(3.4862) | Xent 0.0000(0.0000) | Loss 8.4109(9.0262) | Error 0.0000(0.0000) Steps 718(708.22) | Grad Norm 2.4297(2.3715) | Total Time 0.00(0.00)\n",
      "Iter 2649 | Time 81.4521(80.0042) | Bit/dim 3.4800(3.4861) | Xent 0.0000(0.0000) | Loss 8.3684(9.0064) | Error 0.0000(0.0000) Steps 700(707.97) | Grad Norm 2.4548(2.3740) | Total Time 0.00(0.00)\n",
      "Iter 2650 | Time 85.3592(80.1649) | Bit/dim 3.4903(3.4862) | Xent 0.0000(0.0000) | Loss 8.6144(8.9947) | Error 0.0000(0.0000) Steps 742(708.99) | Grad Norm 2.2750(2.3710) | Total Time 0.00(0.00)\n",
      "Iter 2651 | Time 83.2133(80.2563) | Bit/dim 3.4754(3.4859) | Xent 0.0000(0.0000) | Loss 8.3195(8.9744) | Error 0.0000(0.0000) Steps 712(709.08) | Grad Norm 2.1430(2.3642) | Total Time 0.00(0.00)\n",
      "Iter 2652 | Time 80.4941(80.2635) | Bit/dim 3.4911(3.4860) | Xent 0.0000(0.0000) | Loss 8.2085(8.9514) | Error 0.0000(0.0000) Steps 688(708.45) | Grad Norm 2.3524(2.3638) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 24.7729, Epoch Time 533.4209(505.9579), Bit/dim 3.4875(best: 3.4847), Xent 0.0000, Loss 3.4875, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2653 | Time 81.8149(80.3100) | Bit/dim 3.4852(3.4860) | Xent 0.0000(0.0000) | Loss 12.1031(9.0460) | Error 0.0000(0.0000) Steps 718(708.74) | Grad Norm 2.7643(2.3758) | Total Time 0.00(0.00)\n",
      "Iter 2654 | Time 77.2153(80.2172) | Bit/dim 3.4879(3.4860) | Xent 0.0000(0.0000) | Loss 8.1172(9.0181) | Error 0.0000(0.0000) Steps 688(708.12) | Grad Norm 3.1528(2.3992) | Total Time 0.00(0.00)\n",
      "Iter 2655 | Time 81.9354(80.2687) | Bit/dim 3.4803(3.4859) | Xent 0.0000(0.0000) | Loss 8.3582(8.9983) | Error 0.0000(0.0000) Steps 706(708.05) | Grad Norm 3.1092(2.4205) | Total Time 0.00(0.00)\n",
      "Iter 2656 | Time 80.7268(80.2824) | Bit/dim 3.4922(3.4861) | Xent 0.0000(0.0000) | Loss 8.2368(8.9755) | Error 0.0000(0.0000) Steps 694(707.63) | Grad Norm 2.4929(2.4226) | Total Time 0.00(0.00)\n",
      "Iter 2657 | Time 85.9769(80.4533) | Bit/dim 3.4909(3.4862) | Xent 0.0000(0.0000) | Loss 8.4104(8.9585) | Error 0.0000(0.0000) Steps 712(707.76) | Grad Norm 1.6893(2.4006) | Total Time 0.00(0.00)\n",
      "Iter 2658 | Time 80.7498(80.4622) | Bit/dim 3.4796(3.4860) | Xent 0.0000(0.0000) | Loss 8.3909(8.9415) | Error 0.0000(0.0000) Steps 718(708.07) | Grad Norm 0.9234(2.3563) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 24.8382, Epoch Time 528.6873(506.6398), Bit/dim 3.4895(best: 3.4847), Xent 0.0000, Loss 3.4895, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2659 | Time 80.4012(80.4603) | Bit/dim 3.4924(3.4862) | Xent 0.0000(0.0000) | Loss 12.4056(9.0454) | Error 0.0000(0.0000) Steps 718(708.37) | Grad Norm 0.3975(2.2975) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 85.4155(80.6090) | Bit/dim 3.4836(3.4861) | Xent 0.0000(0.0000) | Loss 8.3340(9.0241) | Error 0.0000(0.0000) Steps 694(707.94) | Grad Norm 1.0218(2.2593) | Total Time 0.00(0.00)\n",
      "Iter 2661 | Time 82.0873(80.6534) | Bit/dim 3.4762(3.4858) | Xent 0.0000(0.0000) | Loss 8.3977(9.0053) | Error 0.0000(0.0000) Steps 724(708.42) | Grad Norm 1.6144(2.2399) | Total Time 0.00(0.00)\n",
      "Iter 2662 | Time 83.7187(80.7453) | Bit/dim 3.4753(3.4855) | Xent 0.0000(0.0000) | Loss 8.3929(8.9869) | Error 0.0000(0.0000) Steps 712(708.52) | Grad Norm 2.1253(2.2365) | Total Time 0.00(0.00)\n",
      "Iter 2663 | Time 86.8060(80.9271) | Bit/dim 3.4930(3.4857) | Xent 0.0000(0.0000) | Loss 8.5351(8.9734) | Error 0.0000(0.0000) Steps 724(708.99) | Grad Norm 2.5634(2.2463) | Total Time 0.00(0.00)\n",
      "Iter 2664 | Time 75.3147(80.7588) | Bit/dim 3.4914(3.4859) | Xent 0.0000(0.0000) | Loss 8.1692(8.9492) | Error 0.0000(0.0000) Steps 694(708.54) | Grad Norm 2.7714(2.2621) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 25.1865, Epoch Time 534.7070(507.4818), Bit/dim 3.4859(best: 3.4847), Xent 0.0000, Loss 3.4859, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2665 | Time 79.9150(80.7334) | Bit/dim 3.4823(3.4858) | Xent 0.0000(0.0000) | Loss 11.8604(9.0366) | Error 0.0000(0.0000) Steps 688(707.92) | Grad Norm 3.2242(2.2909) | Total Time 0.00(0.00)\n",
      "Iter 2666 | Time 85.3989(80.8734) | Bit/dim 3.4854(3.4858) | Xent 0.0000(0.0000) | Loss 8.4365(9.0186) | Error 0.0000(0.0000) Steps 730(708.59) | Grad Norm 3.3556(2.3229) | Total Time 0.00(0.00)\n",
      "Iter 2667 | Time 85.6261(81.0160) | Bit/dim 3.4859(3.4858) | Xent 0.0000(0.0000) | Loss 8.4603(9.0018) | Error 0.0000(0.0000) Steps 724(709.05) | Grad Norm 3.2903(2.3519) | Total Time 0.00(0.00)\n",
      "Iter 2668 | Time 79.3374(80.9656) | Bit/dim 3.4847(3.4858) | Xent 0.0000(0.0000) | Loss 8.5990(8.9897) | Error 0.0000(0.0000) Steps 730(709.68) | Grad Norm 3.0044(2.3715) | Total Time 0.00(0.00)\n",
      "Iter 2669 | Time 81.5972(80.9846) | Bit/dim 3.4916(3.4859) | Xent 0.0000(0.0000) | Loss 8.2662(8.9680) | Error 0.0000(0.0000) Steps 694(709.21) | Grad Norm 3.1027(2.3934) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 79.0135(80.9254) | Bit/dim 3.4827(3.4858) | Xent 0.0000(0.0000) | Loss 8.4107(8.9513) | Error 0.0000(0.0000) Steps 700(708.93) | Grad Norm 3.1794(2.4170) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 25.0074, Epoch Time 531.4684(508.2014), Bit/dim 3.4895(best: 3.4847), Xent 0.0000, Loss 3.4895, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2671 | Time 77.3304(80.8176) | Bit/dim 3.4871(3.4859) | Xent 0.0000(0.0000) | Loss 12.1584(9.0475) | Error 0.0000(0.0000) Steps 718(709.20) | Grad Norm 2.8845(2.4310) | Total Time 0.00(0.00)\n",
      "Iter 2672 | Time 79.0624(80.7649) | Bit/dim 3.4959(3.4862) | Xent 0.0000(0.0000) | Loss 8.6200(9.0347) | Error 0.0000(0.0000) Steps 706(709.11) | Grad Norm 2.4123(2.4304) | Total Time 0.00(0.00)\n",
      "Iter 2673 | Time 80.7424(80.7643) | Bit/dim 3.4945(3.4864) | Xent 0.0000(0.0000) | Loss 8.4933(9.0185) | Error 0.0000(0.0000) Steps 700(708.83) | Grad Norm 1.9772(2.4168) | Total Time 0.00(0.00)\n",
      "Iter 2674 | Time 79.7279(80.7332) | Bit/dim 3.4832(3.4863) | Xent 0.0000(0.0000) | Loss 8.2501(8.9954) | Error 0.0000(0.0000) Steps 712(708.93) | Grad Norm 2.0381(2.4055) | Total Time 0.00(0.00)\n",
      "Iter 2675 | Time 76.5066(80.6064) | Bit/dim 3.4704(3.4858) | Xent 0.0000(0.0000) | Loss 8.3243(8.9753) | Error 0.0000(0.0000) Steps 730(709.56) | Grad Norm 2.8787(2.4197) | Total Time 0.00(0.00)\n",
      "Iter 2676 | Time 79.2007(80.5642) | Bit/dim 3.4772(3.4856) | Xent 0.0000(0.0000) | Loss 8.1655(8.9510) | Error 0.0000(0.0000) Steps 688(708.91) | Grad Norm 3.5441(2.4534) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 23.5077, Epoch Time 511.7618(508.3082), Bit/dim 3.4900(best: 3.4847), Xent 0.0000, Loss 3.4900, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2677 | Time 83.8532(80.6629) | Bit/dim 3.4829(3.4855) | Xent 0.0000(0.0000) | Loss 12.4582(9.0562) | Error 0.0000(0.0000) Steps 706(708.83) | Grad Norm 3.6715(2.4900) | Total Time 0.00(0.00)\n",
      "Iter 2678 | Time 78.8660(80.6090) | Bit/dim 3.4832(3.4854) | Xent 0.0000(0.0000) | Loss 8.2907(9.0332) | Error 0.0000(0.0000) Steps 712(708.92) | Grad Norm 3.1759(2.5105) | Total Time 0.00(0.00)\n",
      "Iter 2679 | Time 79.2893(80.5694) | Bit/dim 3.4921(3.4856) | Xent 0.0000(0.0000) | Loss 8.4277(9.0151) | Error 0.0000(0.0000) Steps 706(708.83) | Grad Norm 1.9606(2.4940) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 83.5868(80.6599) | Bit/dim 3.4680(3.4851) | Xent 0.0000(0.0000) | Loss 8.3883(8.9963) | Error 0.0000(0.0000) Steps 718(709.11) | Grad Norm 1.5988(2.4672) | Total Time 0.00(0.00)\n",
      "Iter 2681 | Time 78.0917(80.5828) | Bit/dim 3.4971(3.4855) | Xent 0.0000(0.0000) | Loss 8.1025(8.9695) | Error 0.0000(0.0000) Steps 694(708.66) | Grad Norm 2.1777(2.4585) | Total Time 0.00(0.00)\n",
      "Iter 2682 | Time 80.8662(80.5914) | Bit/dim 3.4940(3.4857) | Xent 0.0000(0.0000) | Loss 8.4754(8.9546) | Error 0.0000(0.0000) Steps 706(708.58) | Grad Norm 2.4886(2.4594) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 24.4602, Epoch Time 524.6613(508.7988), Bit/dim 3.4843(best: 3.4847), Xent 0.0000, Loss 3.4843, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2683 | Time 81.8273(80.6284) | Bit/dim 3.4847(3.4857) | Xent 0.0000(0.0000) | Loss 12.5503(9.0625) | Error 0.0000(0.0000) Steps 730(709.22) | Grad Norm 2.4618(2.4595) | Total Time 0.00(0.00)\n",
      "Iter 2684 | Time 80.7182(80.6311) | Bit/dim 3.4860(3.4857) | Xent 0.0000(0.0000) | Loss 8.1530(9.0352) | Error 0.0000(0.0000) Steps 694(708.76) | Grad Norm 2.0725(2.4479) | Total Time 0.00(0.00)\n",
      "Iter 2685 | Time 79.5013(80.5972) | Bit/dim 3.4794(3.4855) | Xent 0.0000(0.0000) | Loss 8.3296(9.0140) | Error 0.0000(0.0000) Steps 718(709.04) | Grad Norm 1.8937(2.4312) | Total Time 0.00(0.00)\n",
      "Iter 2686 | Time 81.1094(80.6126) | Bit/dim 3.4690(3.4850) | Xent 0.0000(0.0000) | Loss 8.3931(8.9954) | Error 0.0000(0.0000) Steps 712(709.13) | Grad Norm 2.5625(2.4352) | Total Time 0.00(0.00)\n",
      "Iter 2687 | Time 81.9359(80.6523) | Bit/dim 3.4933(3.4853) | Xent 0.0000(0.0000) | Loss 8.5204(8.9812) | Error 0.0000(0.0000) Steps 724(709.57) | Grad Norm 3.3090(2.4614) | Total Time 0.00(0.00)\n",
      "Iter 2688 | Time 79.2362(80.6098) | Bit/dim 3.4861(3.4853) | Xent 0.0000(0.0000) | Loss 8.2137(8.9581) | Error 0.0000(0.0000) Steps 694(709.11) | Grad Norm 3.0237(2.4783) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 24.9662, Epoch Time 525.1003(509.2878), Bit/dim 3.4833(best: 3.4843), Xent 0.0000, Loss 3.4833, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2689 | Time 78.5723(80.5487) | Bit/dim 3.4845(3.4853) | Xent 0.0000(0.0000) | Loss 12.2539(9.0570) | Error 0.0000(0.0000) Steps 706(709.01) | Grad Norm 1.7149(2.4554) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 79.0820(80.5047) | Bit/dim 3.4765(3.4850) | Xent 0.0000(0.0000) | Loss 8.3534(9.0359) | Error 0.0000(0.0000) Steps 712(709.10) | Grad Norm 0.9573(2.4104) | Total Time 0.00(0.00)\n",
      "Iter 2691 | Time 80.0623(80.4914) | Bit/dim 3.4811(3.4849) | Xent 0.0000(0.0000) | Loss 8.2157(9.0113) | Error 0.0000(0.0000) Steps 688(708.47) | Grad Norm 2.0050(2.3982) | Total Time 0.00(0.00)\n",
      "Iter 2692 | Time 79.3470(80.4571) | Bit/dim 3.4885(3.4850) | Xent 0.0000(0.0000) | Loss 8.3434(8.9913) | Error 0.0000(0.0000) Steps 706(708.40) | Grad Norm 2.9166(2.4138) | Total Time 0.00(0.00)\n",
      "Iter 2693 | Time 80.8474(80.4688) | Bit/dim 3.4885(3.4851) | Xent 0.0000(0.0000) | Loss 8.4379(8.9747) | Error 0.0000(0.0000) Steps 700(708.14) | Grad Norm 3.1131(2.4348) | Total Time 0.00(0.00)\n",
      "Iter 2694 | Time 74.1573(80.2794) | Bit/dim 3.4686(3.4846) | Xent 0.0000(0.0000) | Loss 8.0772(8.9477) | Error 0.0000(0.0000) Steps 682(707.36) | Grad Norm 2.5282(2.4376) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 24.5266, Epoch Time 512.3998(509.3812), Bit/dim 3.4838(best: 3.4833), Xent 0.0000, Loss 3.4838, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2695 | Time 80.7906(80.2948) | Bit/dim 3.4784(3.4844) | Xent 0.0000(0.0000) | Loss 12.5622(9.0562) | Error 0.0000(0.0000) Steps 730(708.04) | Grad Norm 1.2469(2.4019) | Total Time 0.00(0.00)\n",
      "Iter 2696 | Time 76.7598(80.1887) | Bit/dim 3.4775(3.4842) | Xent 0.0000(0.0000) | Loss 8.4541(9.0381) | Error 0.0000(0.0000) Steps 724(708.52) | Grad Norm 1.0387(2.3610) | Total Time 0.00(0.00)\n",
      "Iter 2697 | Time 82.7045(80.2642) | Bit/dim 3.4804(3.4841) | Xent 0.0000(0.0000) | Loss 8.5579(9.0237) | Error 0.0000(0.0000) Steps 718(708.80) | Grad Norm 2.3207(2.3598) | Total Time 0.00(0.00)\n",
      "Iter 2698 | Time 83.4824(80.3607) | Bit/dim 3.4826(3.4841) | Xent 0.0000(0.0000) | Loss 8.3305(9.0029) | Error 0.0000(0.0000) Steps 730(709.44) | Grad Norm 3.0257(2.3797) | Total Time 0.00(0.00)\n",
      "Iter 2699 | Time 81.9432(80.4082) | Bit/dim 3.4944(3.4844) | Xent 0.0000(0.0000) | Loss 8.4645(8.9868) | Error 0.0000(0.0000) Steps 736(710.23) | Grad Norm 2.6266(2.3871) | Total Time 0.00(0.00)\n",
      "Iter 2700 | Time 77.1736(80.3112) | Bit/dim 3.4832(3.4843) | Xent 0.0000(0.0000) | Loss 8.2660(8.9651) | Error 0.0000(0.0000) Steps 712(710.29) | Grad Norm 1.6159(2.3640) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 24.6515, Epoch Time 523.6444(509.8091), Bit/dim 3.4852(best: 3.4833), Xent 0.0000, Loss 3.4852, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2701 | Time 79.8138(80.2963) | Bit/dim 3.4781(3.4841) | Xent 0.0000(0.0000) | Loss 12.4147(9.0686) | Error 0.0000(0.0000) Steps 700(709.98) | Grad Norm 0.7689(2.3162) | Total Time 0.00(0.00)\n",
      "Iter 2702 | Time 85.7793(80.4608) | Bit/dim 3.4808(3.4840) | Xent 0.0000(0.0000) | Loss 8.5612(9.0534) | Error 0.0000(0.0000) Steps 724(710.40) | Grad Norm 1.3179(2.2862) | Total Time 0.00(0.00)\n",
      "Iter 2703 | Time 79.9281(80.4448) | Bit/dim 3.4800(3.4839) | Xent 0.0000(0.0000) | Loss 8.3212(9.0314) | Error 0.0000(0.0000) Steps 700(710.09) | Grad Norm 2.3097(2.2869) | Total Time 0.00(0.00)\n",
      "Iter 2704 | Time 82.3954(80.5033) | Bit/dim 3.4847(3.4839) | Xent 0.0000(0.0000) | Loss 8.2002(9.0065) | Error 0.0000(0.0000) Steps 718(710.33) | Grad Norm 2.8079(2.3025) | Total Time 0.00(0.00)\n",
      "Iter 2705 | Time 82.7922(80.5720) | Bit/dim 3.4756(3.4837) | Xent 0.0000(0.0000) | Loss 8.3677(8.9873) | Error 0.0000(0.0000) Steps 724(710.74) | Grad Norm 2.7399(2.3157) | Total Time 0.00(0.00)\n",
      "Iter 2706 | Time 81.2642(80.5927) | Bit/dim 3.4851(3.4837) | Xent 0.0000(0.0000) | Loss 8.4846(8.9723) | Error 0.0000(0.0000) Steps 736(711.49) | Grad Norm 2.5471(2.3226) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 24.6391, Epoch Time 532.4009(510.4868), Bit/dim 3.4828(best: 3.4833), Xent 0.0000, Loss 3.4828, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2707 | Time 82.4799(80.6493) | Bit/dim 3.4806(3.4836) | Xent 0.0000(0.0000) | Loss 12.4190(9.0757) | Error 0.0000(0.0000) Steps 718(711.69) | Grad Norm 2.9865(2.3425) | Total Time 0.00(0.00)\n",
      "Iter 2708 | Time 81.1546(80.6645) | Bit/dim 3.4909(3.4839) | Xent 0.0000(0.0000) | Loss 8.4776(9.0577) | Error 0.0000(0.0000) Steps 706(711.52) | Grad Norm 3.6573(2.3820) | Total Time 0.00(0.00)\n",
      "Iter 2709 | Time 80.9809(80.6740) | Bit/dim 3.4924(3.4841) | Xent 0.0000(0.0000) | Loss 8.5203(9.0416) | Error 0.0000(0.0000) Steps 736(712.25) | Grad Norm 3.6086(2.4188) | Total Time 0.00(0.00)\n",
      "Iter 2710 | Time 81.3584(80.6945) | Bit/dim 3.4852(3.4841) | Xent 0.0000(0.0000) | Loss 8.4505(9.0239) | Error 0.0000(0.0000) Steps 712(712.24) | Grad Norm 2.6709(2.4263) | Total Time 0.00(0.00)\n",
      "Iter 2711 | Time 78.8831(80.6402) | Bit/dim 3.4743(3.4838) | Xent 0.0000(0.0000) | Loss 8.3096(9.0024) | Error 0.0000(0.0000) Steps 694(711.70) | Grad Norm 1.5014(2.3986) | Total Time 0.00(0.00)\n",
      "Iter 2712 | Time 80.7195(80.6426) | Bit/dim 3.4786(3.4837) | Xent 0.0000(0.0000) | Loss 8.2062(8.9785) | Error 0.0000(0.0000) Steps 688(710.99) | Grad Norm 0.4672(2.3406) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 25.1755, Epoch Time 526.3712(510.9634), Bit/dim 3.4857(best: 3.4828), Xent 0.0000, Loss 3.4857, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2713 | Time 82.7497(80.7058) | Bit/dim 3.4811(3.4836) | Xent 0.0000(0.0000) | Loss 12.4358(9.0823) | Error 0.0000(0.0000) Steps 700(710.66) | Grad Norm 0.9866(2.3000) | Total Time 0.00(0.00)\n",
      "Iter 2714 | Time 86.1920(80.8704) | Bit/dim 3.4839(3.4836) | Xent 0.0000(0.0000) | Loss 8.4342(9.0628) | Error 0.0000(0.0000) Steps 730(711.24) | Grad Norm 2.0551(2.2927) | Total Time 0.00(0.00)\n",
      "Iter 2715 | Time 83.4458(80.9476) | Bit/dim 3.4784(3.4835) | Xent 0.0000(0.0000) | Loss 8.3711(9.0421) | Error 0.0000(0.0000) Steps 706(711.08) | Grad Norm 3.1013(2.3169) | Total Time 0.00(0.00)\n",
      "Iter 2716 | Time 79.7704(80.9123) | Bit/dim 3.4866(3.4836) | Xent 0.0000(0.0000) | Loss 8.2187(9.0174) | Error 0.0000(0.0000) Steps 706(710.93) | Grad Norm 3.5609(2.3542) | Total Time 0.00(0.00)\n",
      "Iter 2717 | Time 78.4603(80.8387) | Bit/dim 3.4859(3.4836) | Xent 0.0000(0.0000) | Loss 8.5054(9.0020) | Error 0.0000(0.0000) Steps 718(711.14) | Grad Norm 3.0229(2.3743) | Total Time 0.00(0.00)\n",
      "Iter 2718 | Time 81.7979(80.8675) | Bit/dim 3.4768(3.4834) | Xent 0.0000(0.0000) | Loss 8.3429(8.9822) | Error 0.0000(0.0000) Steps 700(710.81) | Grad Norm 2.1420(2.3673) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 24.3872, Epoch Time 532.6122(511.6128), Bit/dim 3.4829(best: 3.4828), Xent 0.0000, Loss 3.4829, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2719 | Time 74.3657(80.6725) | Bit/dim 3.4877(3.4836) | Xent 0.0000(0.0000) | Loss 11.9714(9.0719) | Error 0.0000(0.0000) Steps 700(710.48) | Grad Norm 1.4722(2.3405) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 81.5209(80.6979) | Bit/dim 3.4739(3.4833) | Xent 0.0000(0.0000) | Loss 8.2942(9.0486) | Error 0.0000(0.0000) Steps 712(710.53) | Grad Norm 1.3983(2.3122) | Total Time 0.00(0.00)\n",
      "Iter 2721 | Time 78.4934(80.6318) | Bit/dim 3.4836(3.4833) | Xent 0.0000(0.0000) | Loss 8.1218(9.0208) | Error 0.0000(0.0000) Steps 700(710.21) | Grad Norm 1.8944(2.2997) | Total Time 0.00(0.00)\n",
      "Iter 2722 | Time 81.0085(80.6431) | Bit/dim 3.4910(3.4835) | Xent 0.0000(0.0000) | Loss 8.2229(8.9968) | Error 0.0000(0.0000) Steps 694(709.72) | Grad Norm 2.4288(2.3036) | Total Time 0.00(0.00)\n",
      "Iter 2723 | Time 76.6096(80.5221) | Bit/dim 3.4889(3.4837) | Xent 0.0000(0.0000) | Loss 8.1868(8.9725) | Error 0.0000(0.0000) Steps 688(709.07) | Grad Norm 2.6918(2.3152) | Total Time 0.00(0.00)\n",
      "Iter 2724 | Time 79.9170(80.5039) | Bit/dim 3.4664(3.4831) | Xent 0.0000(0.0000) | Loss 8.2533(8.9510) | Error 0.0000(0.0000) Steps 700(708.80) | Grad Norm 2.6763(2.3260) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 24.0521, Epoch Time 511.5250(511.6102), Bit/dim 3.4861(best: 3.4828), Xent 0.0000, Loss 3.4861, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2725 | Time 81.7348(80.5409) | Bit/dim 3.4799(3.4831) | Xent 0.0000(0.0000) | Loss 12.4672(9.0564) | Error 0.0000(0.0000) Steps 718(709.08) | Grad Norm 2.3419(2.3265) | Total Time 0.00(0.00)\n",
      "Iter 2726 | Time 86.3998(80.7166) | Bit/dim 3.4803(3.4830) | Xent 0.0000(0.0000) | Loss 8.5084(9.0400) | Error 0.0000(0.0000) Steps 724(709.52) | Grad Norm 2.1220(2.3204) | Total Time 0.00(0.00)\n",
      "Iter 2727 | Time 80.1699(80.7002) | Bit/dim 3.4761(3.4828) | Xent 0.0000(0.0000) | Loss 8.3875(9.0204) | Error 0.0000(0.0000) Steps 712(709.60) | Grad Norm 2.1967(2.3167) | Total Time 0.00(0.00)\n",
      "Iter 2728 | Time 78.8951(80.6461) | Bit/dim 3.4932(3.4831) | Xent 0.0000(0.0000) | Loss 8.4532(9.0034) | Error 0.0000(0.0000) Steps 712(709.67) | Grad Norm 2.5988(2.3251) | Total Time 0.00(0.00)\n",
      "Iter 2729 | Time 81.5092(80.6720) | Bit/dim 3.4980(3.4835) | Xent 0.0000(0.0000) | Loss 8.4576(8.9870) | Error 0.0000(0.0000) Steps 706(709.56) | Grad Norm 3.2074(2.3516) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 86.9920(80.8616) | Bit/dim 3.4715(3.4832) | Xent 0.0000(0.0000) | Loss 8.3129(8.9668) | Error 0.0000(0.0000) Steps 718(709.81) | Grad Norm 3.5650(2.3880) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 24.2254, Epoch Time 536.0406(512.3431), Bit/dim 3.4854(best: 3.4828), Xent 0.0000, Loss 3.4854, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2731 | Time 80.0733(80.8379) | Bit/dim 3.4760(3.4829) | Xent 0.0000(0.0000) | Loss 12.2988(9.0668) | Error 0.0000(0.0000) Steps 730(710.42) | Grad Norm 3.2458(2.4137) | Total Time 0.00(0.00)\n",
      "Iter 2732 | Time 82.1462(80.8772) | Bit/dim 3.4797(3.4828) | Xent 0.0000(0.0000) | Loss 8.0385(9.0359) | Error 0.0000(0.0000) Steps 682(709.57) | Grad Norm 2.4391(2.4145) | Total Time 0.00(0.00)\n",
      "Iter 2733 | Time 78.5289(80.8067) | Bit/dim 3.4895(3.4830) | Xent 0.0000(0.0000) | Loss 8.0869(9.0075) | Error 0.0000(0.0000) Steps 700(709.28) | Grad Norm 1.5668(2.3891) | Total Time 0.00(0.00)\n",
      "Iter 2734 | Time 79.8450(80.7779) | Bit/dim 3.4790(3.4829) | Xent 0.0000(0.0000) | Loss 8.4437(8.9905) | Error 0.0000(0.0000) Steps 712(709.36) | Grad Norm 0.5926(2.3352) | Total Time 0.00(0.00)\n",
      "Iter 2735 | Time 79.1378(80.7287) | Bit/dim 3.4856(3.4830) | Xent 0.0000(0.0000) | Loss 8.2845(8.9694) | Error 0.0000(0.0000) Steps 706(709.26) | Grad Norm 0.7407(2.2873) | Total Time 0.00(0.00)\n",
      "Iter 2736 | Time 76.4062(80.5990) | Bit/dim 3.4791(3.4829) | Xent 0.0000(0.0000) | Loss 8.2419(8.9475) | Error 0.0000(0.0000) Steps 706(709.16) | Grad Norm 1.6583(2.2685) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 24.9046, Epoch Time 517.1384(512.4870), Bit/dim 3.4854(best: 3.4828), Xent 0.0000, Loss 3.4854, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2737 | Time 76.9526(80.4896) | Bit/dim 3.4799(3.4828) | Xent 0.0000(0.0000) | Loss 12.3660(9.0501) | Error 0.0000(0.0000) Steps 706(709.07) | Grad Norm 2.5330(2.2764) | Total Time 0.00(0.00)\n",
      "Iter 2738 | Time 79.8994(80.4719) | Bit/dim 3.4852(3.4829) | Xent 0.0000(0.0000) | Loss 8.5445(9.0349) | Error 0.0000(0.0000) Steps 706(708.98) | Grad Norm 3.0655(2.3001) | Total Time 0.00(0.00)\n",
      "Iter 2739 | Time 84.0896(80.5804) | Bit/dim 3.4795(3.4828) | Xent 0.0000(0.0000) | Loss 8.4408(9.0171) | Error 0.0000(0.0000) Steps 712(709.07) | Grad Norm 3.1394(2.3253) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 80.4926(80.5778) | Bit/dim 3.4871(3.4829) | Xent 0.0000(0.0000) | Loss 8.3334(8.9966) | Error 0.0000(0.0000) Steps 694(708.61) | Grad Norm 2.8270(2.3403) | Total Time 0.00(0.00)\n",
      "Iter 2741 | Time 80.9044(80.5876) | Bit/dim 3.4760(3.4827) | Xent 0.0000(0.0000) | Loss 8.3846(8.9782) | Error 0.0000(0.0000) Steps 730(709.26) | Grad Norm 2.1783(2.3354) | Total Time 0.00(0.00)\n",
      "Iter 2742 | Time 83.5504(80.6765) | Bit/dim 3.4841(3.4827) | Xent 0.0000(0.0000) | Loss 8.2813(8.9573) | Error 0.0000(0.0000) Steps 706(709.16) | Grad Norm 1.8115(2.3197) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 24.7384, Epoch Time 526.4229(512.9050), Bit/dim 3.4780(best: 3.4828), Xent 0.0000, Loss 3.4780, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2743 | Time 81.5554(80.7028) | Bit/dim 3.4697(3.4823) | Xent 0.0000(0.0000) | Loss 12.0349(9.0496) | Error 0.0000(0.0000) Steps 706(709.06) | Grad Norm 2.1551(2.3148) | Total Time 0.00(0.00)\n",
      "Iter 2744 | Time 85.2435(80.8391) | Bit/dim 3.4813(3.4823) | Xent 0.0000(0.0000) | Loss 8.5847(9.0357) | Error 0.0000(0.0000) Steps 724(709.51) | Grad Norm 2.7413(2.3276) | Total Time 0.00(0.00)\n",
      "Iter 2745 | Time 83.9317(80.9318) | Bit/dim 3.4902(3.4825) | Xent 0.0000(0.0000) | Loss 8.4497(9.0181) | Error 0.0000(0.0000) Steps 724(709.95) | Grad Norm 3.4136(2.3602) | Total Time 0.00(0.00)\n",
      "Iter 2746 | Time 82.8454(80.9892) | Bit/dim 3.4953(3.4829) | Xent 0.0000(0.0000) | Loss 8.5887(9.0052) | Error 0.0000(0.0000) Steps 724(710.37) | Grad Norm 3.6062(2.3975) | Total Time 0.00(0.00)\n",
      "Iter 2747 | Time 84.2197(81.0862) | Bit/dim 3.4810(3.4829) | Xent 0.0000(0.0000) | Loss 8.4277(8.9879) | Error 0.0000(0.0000) Steps 730(710.96) | Grad Norm 3.1155(2.4191) | Total Time 0.00(0.00)\n",
      "Iter 2748 | Time 84.7344(81.1956) | Bit/dim 3.4794(3.4828) | Xent 0.0000(0.0000) | Loss 8.4626(8.9722) | Error 0.0000(0.0000) Steps 712(710.99) | Grad Norm 2.1428(2.4108) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 24.3850, Epoch Time 543.0159(513.8084), Bit/dim 3.4836(best: 3.4780), Xent 0.0000, Loss 3.4836, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2749 | Time 77.6054(81.0879) | Bit/dim 3.4800(3.4827) | Xent 0.0000(0.0000) | Loss 12.4809(9.0774) | Error 0.0000(0.0000) Steps 718(711.20) | Grad Norm 1.2967(2.3774) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 88.1457(81.2996) | Bit/dim 3.4814(3.4826) | Xent 0.0000(0.0000) | Loss 8.5065(9.0603) | Error 0.0000(0.0000) Steps 736(711.94) | Grad Norm 0.9439(2.3344) | Total Time 0.00(0.00)\n",
      "Iter 2751 | Time 79.3874(81.2423) | Bit/dim 3.4826(3.4826) | Xent 0.0000(0.0000) | Loss 8.3972(9.0404) | Error 0.0000(0.0000) Steps 706(711.76) | Grad Norm 1.3323(2.3043) | Total Time 0.00(0.00)\n",
      "Iter 2752 | Time 82.7067(81.2862) | Bit/dim 3.4781(3.4825) | Xent 0.0000(0.0000) | Loss 8.5308(9.0251) | Error 0.0000(0.0000) Steps 718(711.95) | Grad Norm 2.2231(2.3019) | Total Time 0.00(0.00)\n",
      "Iter 2753 | Time 83.9816(81.3671) | Bit/dim 3.4891(3.4827) | Xent 0.0000(0.0000) | Loss 8.5419(9.0106) | Error 0.0000(0.0000) Steps 724(712.31) | Grad Norm 2.9797(2.3222) | Total Time 0.00(0.00)\n",
      "Iter 2754 | Time 86.7970(81.5300) | Bit/dim 3.4842(3.4828) | Xent 0.0000(0.0000) | Loss 8.5451(8.9966) | Error 0.0000(0.0000) Steps 736(713.02) | Grad Norm 3.3160(2.3520) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 23.9345, Epoch Time 538.7082(514.5554), Bit/dim 3.4905(best: 3.4780), Xent 0.0000, Loss 3.4905, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2755 | Time 77.2305(81.4010) | Bit/dim 3.4890(3.4829) | Xent 0.0000(0.0000) | Loss 11.8704(9.0829) | Error 0.0000(0.0000) Steps 694(712.45) | Grad Norm 3.3605(2.3823) | Total Time 0.00(0.00)\n",
      "Iter 2756 | Time 80.9046(81.3861) | Bit/dim 3.4767(3.4828) | Xent 0.0000(0.0000) | Loss 8.6124(9.0687) | Error 0.0000(0.0000) Steps 730(712.98) | Grad Norm 3.0450(2.4022) | Total Time 0.00(0.00)\n",
      "Iter 2757 | Time 75.8936(81.2213) | Bit/dim 3.4887(3.4829) | Xent 0.0000(0.0000) | Loss 8.1067(9.0399) | Error 0.0000(0.0000) Steps 682(712.05) | Grad Norm 2.4719(2.4042) | Total Time 0.00(0.00)\n",
      "Iter 2758 | Time 84.3975(81.3166) | Bit/dim 3.4812(3.4829) | Xent 0.0000(0.0000) | Loss 8.2147(9.0151) | Error 0.0000(0.0000) Steps 730(712.59) | Grad Norm 2.1926(2.3979) | Total Time 0.00(0.00)\n",
      "Iter 2759 | Time 80.3810(81.2885) | Bit/dim 3.4817(3.4828) | Xent 0.0000(0.0000) | Loss 8.4621(8.9985) | Error 0.0000(0.0000) Steps 724(712.93) | Grad Norm 2.4613(2.3998) | Total Time 0.00(0.00)\n",
      "Iter 2760 | Time 81.7034(81.3010) | Bit/dim 3.4763(3.4826) | Xent 0.0000(0.0000) | Loss 8.2750(8.9768) | Error 0.0000(0.0000) Steps 700(712.54) | Grad Norm 2.9712(2.4169) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 25.0697, Epoch Time 521.7756(514.7720), Bit/dim 3.4827(best: 3.4780), Xent 0.0000, Loss 3.4827, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2761 | Time 84.1267(81.3858) | Bit/dim 3.4808(3.4826) | Xent 0.0000(0.0000) | Loss 12.4517(9.0811) | Error 0.0000(0.0000) Steps 748(713.61) | Grad Norm 3.4310(2.4474) | Total Time 0.00(0.00)\n",
      "Iter 2762 | Time 83.5395(81.4504) | Bit/dim 3.4837(3.4826) | Xent 0.0000(0.0000) | Loss 8.3392(9.0588) | Error 0.0000(0.0000) Steps 706(713.38) | Grad Norm 3.3998(2.4759) | Total Time 0.00(0.00)\n",
      "Iter 2763 | Time 86.8352(81.6119) | Bit/dim 3.4872(3.4828) | Xent 0.0000(0.0000) | Loss 8.4765(9.0413) | Error 0.0000(0.0000) Steps 718(713.52) | Grad Norm 2.7476(2.4841) | Total Time 0.00(0.00)\n",
      "Iter 2764 | Time 79.2350(81.5406) | Bit/dim 3.4861(3.4829) | Xent 0.0000(0.0000) | Loss 8.4787(9.0245) | Error 0.0000(0.0000) Steps 712(713.47) | Grad Norm 1.9082(2.4668) | Total Time 0.00(0.00)\n",
      "Iter 2765 | Time 81.6284(81.5432) | Bit/dim 3.4786(3.4827) | Xent 0.0000(0.0000) | Loss 8.4511(9.0073) | Error 0.0000(0.0000) Steps 712(713.43) | Grad Norm 1.4805(2.4372) | Total Time 0.00(0.00)\n",
      "Iter 2766 | Time 84.6788(81.6373) | Bit/dim 3.4732(3.4824) | Xent 0.0000(0.0000) | Loss 8.3475(8.9875) | Error 0.0000(0.0000) Steps 730(713.92) | Grad Norm 1.7187(2.4157) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 24.2766, Epoch Time 539.7697(515.5219), Bit/dim 3.4842(best: 3.4780), Xent 0.0000, Loss 3.4842, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2767 | Time 84.0308(81.7091) | Bit/dim 3.4903(3.4827) | Xent 0.0000(0.0000) | Loss 12.3345(9.0879) | Error 0.0000(0.0000) Steps 736(714.59) | Grad Norm 2.3007(2.4122) | Total Time 0.00(0.00)\n",
      "Iter 2768 | Time 87.1615(81.8727) | Bit/dim 3.4832(3.4827) | Xent 0.0000(0.0000) | Loss 8.4962(9.0701) | Error 0.0000(0.0000) Steps 724(714.87) | Grad Norm 2.7643(2.4228) | Total Time 0.00(0.00)\n",
      "Iter 2769 | Time 80.9002(81.8435) | Bit/dim 3.4818(3.4827) | Xent 0.0000(0.0000) | Loss 8.2528(9.0456) | Error 0.0000(0.0000) Steps 718(714.96) | Grad Norm 3.2043(2.4462) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 89.0966(82.0611) | Bit/dim 3.4777(3.4825) | Xent 0.0000(0.0000) | Loss 8.4891(9.0289) | Error 0.0000(0.0000) Steps 742(715.77) | Grad Norm 3.4390(2.4760) | Total Time 0.00(0.00)\n",
      "Iter 2771 | Time 80.4031(82.0114) | Bit/dim 3.4823(3.4825) | Xent 0.0000(0.0000) | Loss 8.1693(9.0031) | Error 0.0000(0.0000) Steps 706(715.48) | Grad Norm 3.1529(2.4963) | Total Time 0.00(0.00)\n",
      "Iter 2772 | Time 85.4810(82.1155) | Bit/dim 3.4853(3.4826) | Xent 0.0000(0.0000) | Loss 8.3707(8.9842) | Error 0.0000(0.0000) Steps 724(715.74) | Grad Norm 2.4646(2.4954) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 24.5632, Epoch Time 547.3158(516.4757), Bit/dim 3.4834(best: 3.4780), Xent 0.0000, Loss 3.4834, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2773 | Time 83.6986(82.1629) | Bit/dim 3.4828(3.4826) | Xent 0.0000(0.0000) | Loss 12.6258(9.0934) | Error 0.0000(0.0000) Steps 712(715.62) | Grad Norm 1.7784(2.4739) | Total Time 0.00(0.00)\n",
      "Iter 2774 | Time 79.5110(82.0834) | Bit/dim 3.4789(3.4825) | Xent 0.0000(0.0000) | Loss 8.2458(9.0680) | Error 0.0000(0.0000) Steps 718(715.70) | Grad Norm 1.5332(2.4456) | Total Time 0.00(0.00)\n",
      "Iter 2775 | Time 83.6480(82.1303) | Bit/dim 3.4881(3.4827) | Xent 0.0000(0.0000) | Loss 8.4870(9.0505) | Error 0.0000(0.0000) Steps 700(715.22) | Grad Norm 1.6299(2.4212) | Total Time 0.00(0.00)\n",
      "Iter 2776 | Time 77.2165(81.9829) | Bit/dim 3.4751(3.4824) | Xent 0.0000(0.0000) | Loss 8.2083(9.0253) | Error 0.0000(0.0000) Steps 706(714.95) | Grad Norm 1.9071(2.4057) | Total Time 0.00(0.00)\n",
      "Iter 2777 | Time 82.2040(81.9895) | Bit/dim 3.4962(3.4829) | Xent 0.0000(0.0000) | Loss 8.4190(9.0071) | Error 0.0000(0.0000) Steps 712(714.86) | Grad Norm 2.0672(2.3956) | Total Time 0.00(0.00)\n",
      "Iter 2778 | Time 78.3938(81.8817) | Bit/dim 3.4770(3.4827) | Xent 0.0000(0.0000) | Loss 8.0866(8.9795) | Error 0.0000(0.0000) Steps 712(714.77) | Grad Norm 2.2237(2.3904) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 24.8286, Epoch Time 525.2329(516.7384), Bit/dim 3.4857(best: 3.4780), Xent 0.0000, Loss 3.4857, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2779 | Time 77.4627(81.7491) | Bit/dim 3.4876(3.4828) | Xent 0.0000(0.0000) | Loss 12.2032(9.0762) | Error 0.0000(0.0000) Steps 712(714.69) | Grad Norm 2.3169(2.3882) | Total Time 0.00(0.00)\n",
      "Iter 2780 | Time 83.3921(81.7984) | Bit/dim 3.4747(3.4826) | Xent 0.0000(0.0000) | Loss 8.3659(9.0549) | Error 0.0000(0.0000) Steps 706(714.43) | Grad Norm 2.7451(2.3989) | Total Time 0.00(0.00)\n",
      "Iter 2781 | Time 83.4159(81.8469) | Bit/dim 3.4676(3.4821) | Xent 0.0000(0.0000) | Loss 8.3738(9.0345) | Error 0.0000(0.0000) Steps 736(715.08) | Grad Norm 3.2987(2.4259) | Total Time 0.00(0.00)\n",
      "Iter 2782 | Time 80.0859(81.7941) | Bit/dim 3.4812(3.4821) | Xent 0.0000(0.0000) | Loss 8.4914(9.0182) | Error 0.0000(0.0000) Steps 700(714.62) | Grad Norm 3.5866(2.4607) | Total Time 0.00(0.00)\n",
      "Iter 2783 | Time 81.8559(81.7959) | Bit/dim 3.4887(3.4823) | Xent 0.0000(0.0000) | Loss 8.4319(9.0006) | Error 0.0000(0.0000) Steps 730(715.09) | Grad Norm 3.1732(2.4821) | Total Time 0.00(0.00)\n",
      "Iter 2784 | Time 79.3388(81.7222) | Bit/dim 3.4803(3.4822) | Xent 0.0000(0.0000) | Loss 8.3863(8.9821) | Error 0.0000(0.0000) Steps 706(714.81) | Grad Norm 2.2371(2.4748) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 25.0491, Epoch Time 526.2941(517.0251), Bit/dim 3.4805(best: 3.4780), Xent 0.0000, Loss 3.4805, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2785 | Time 80.6570(81.6903) | Bit/dim 3.4871(3.4824) | Xent 0.0000(0.0000) | Loss 12.0461(9.0741) | Error 0.0000(0.0000) Steps 706(714.55) | Grad Norm 1.8502(2.4560) | Total Time 0.00(0.00)\n",
      "Iter 2786 | Time 84.2954(81.7684) | Bit/dim 3.4703(3.4820) | Xent 0.0000(0.0000) | Loss 8.3392(9.0520) | Error 0.0000(0.0000) Steps 736(715.19) | Grad Norm 2.3948(2.4542) | Total Time 0.00(0.00)\n",
      "Iter 2787 | Time 83.5372(81.8215) | Bit/dim 3.4690(3.4816) | Xent 0.0000(0.0000) | Loss 8.4608(9.0343) | Error 0.0000(0.0000) Steps 724(715.46) | Grad Norm 3.2404(2.4778) | Total Time 0.00(0.00)\n",
      "Iter 2788 | Time 87.9374(82.0050) | Bit/dim 3.4937(3.4820) | Xent 0.0000(0.0000) | Loss 8.3815(9.0147) | Error 0.0000(0.0000) Steps 718(715.53) | Grad Norm 3.8587(2.5192) | Total Time 0.00(0.00)\n",
      "Iter 2789 | Time 83.2812(82.0433) | Bit/dim 3.4789(3.4819) | Xent 0.0000(0.0000) | Loss 8.3738(8.9955) | Error 0.0000(0.0000) Steps 712(715.43) | Grad Norm 3.5744(2.5509) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 74.1228(81.8056) | Bit/dim 3.4889(3.4821) | Xent 0.0000(0.0000) | Loss 8.5005(8.9806) | Error 0.0000(0.0000) Steps 706(715.14) | Grad Norm 2.4455(2.5477) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 24.4380, Epoch Time 533.8468(517.5298), Bit/dim 3.4840(best: 3.4780), Xent 0.0000, Loss 3.4840, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2791 | Time 77.4652(81.6754) | Bit/dim 3.4875(3.4823) | Xent 0.0000(0.0000) | Loss 11.9654(9.0702) | Error 0.0000(0.0000) Steps 694(714.51) | Grad Norm 1.8809(2.5277) | Total Time 0.00(0.00)\n",
      "Iter 2792 | Time 78.3084(81.5744) | Bit/dim 3.4902(3.4825) | Xent 0.0000(0.0000) | Loss 8.5689(9.0551) | Error 0.0000(0.0000) Steps 724(714.79) | Grad Norm 2.2048(2.5180) | Total Time 0.00(0.00)\n",
      "Iter 2793 | Time 80.6556(81.5469) | Bit/dim 3.4762(3.4823) | Xent 0.0000(0.0000) | Loss 8.4013(9.0355) | Error 0.0000(0.0000) Steps 712(714.71) | Grad Norm 2.8650(2.5284) | Total Time 0.00(0.00)\n",
      "Iter 2794 | Time 85.7701(81.6735) | Bit/dim 3.4767(3.4822) | Xent 0.0000(0.0000) | Loss 8.5208(9.0201) | Error 0.0000(0.0000) Steps 724(714.99) | Grad Norm 3.1995(2.5486) | Total Time 0.00(0.00)\n",
      "Iter 2795 | Time 77.7876(81.5570) | Bit/dim 3.4737(3.4819) | Xent 0.0000(0.0000) | Loss 8.4276(9.0023) | Error 0.0000(0.0000) Steps 718(715.08) | Grad Norm 2.9083(2.5593) | Total Time 0.00(0.00)\n",
      "Iter 2796 | Time 83.6018(81.6183) | Bit/dim 3.4899(3.4821) | Xent 0.0000(0.0000) | Loss 8.2745(8.9805) | Error 0.0000(0.0000) Steps 700(714.63) | Grad Norm 1.9530(2.5412) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 24.6772, Epoch Time 524.3851(517.7354), Bit/dim 3.4828(best: 3.4780), Xent 0.0000, Loss 3.4828, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2797 | Time 77.8565(81.5055) | Bit/dim 3.4671(3.4817) | Xent 0.0000(0.0000) | Loss 12.1028(9.0741) | Error 0.0000(0.0000) Steps 706(714.37) | Grad Norm 1.3676(2.5060) | Total Time 0.00(0.00)\n",
      "Iter 2798 | Time 78.2199(81.4069) | Bit/dim 3.4795(3.4816) | Xent 0.0000(0.0000) | Loss 8.5809(9.0593) | Error 0.0000(0.0000) Steps 718(714.48) | Grad Norm 1.5751(2.4780) | Total Time 0.00(0.00)\n",
      "Iter 2799 | Time 83.0215(81.4553) | Bit/dim 3.4808(3.4816) | Xent 0.0000(0.0000) | Loss 8.2687(9.0356) | Error 0.0000(0.0000) Steps 700(714.04) | Grad Norm 2.1666(2.4687) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 78.9999(81.3817) | Bit/dim 3.4811(3.4816) | Xent 0.0000(0.0000) | Loss 8.5074(9.0198) | Error 0.0000(0.0000) Steps 706(713.80) | Grad Norm 2.6951(2.4755) | Total Time 0.00(0.00)\n",
      "Iter 2801 | Time 80.6633(81.3601) | Bit/dim 3.4812(3.4816) | Xent 0.0000(0.0000) | Loss 8.4588(9.0029) | Error 0.0000(0.0000) Steps 724(714.11) | Grad Norm 2.9337(2.4892) | Total Time 0.00(0.00)\n",
      "Iter 2802 | Time 81.0895(81.3520) | Bit/dim 3.4945(3.4820) | Xent 0.0000(0.0000) | Loss 8.5063(8.9880) | Error 0.0000(0.0000) Steps 730(714.58) | Grad Norm 2.6742(2.4948) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 24.4872, Epoch Time 520.2851(517.8119), Bit/dim 3.4826(best: 3.4780), Xent 0.0000, Loss 3.4826, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2803 | Time 83.1532(81.4060) | Bit/dim 3.4856(3.4821) | Xent 0.0000(0.0000) | Loss 12.4516(9.0919) | Error 0.0000(0.0000) Steps 718(714.69) | Grad Norm 1.9405(2.4781) | Total Time 0.00(0.00)\n",
      "Iter 2804 | Time 79.9939(81.3637) | Bit/dim 3.4829(3.4821) | Xent 0.0000(0.0000) | Loss 8.2823(9.0677) | Error 0.0000(0.0000) Steps 706(714.43) | Grad Norm 1.1033(2.4369) | Total Time 0.00(0.00)\n",
      "Iter 2805 | Time 78.2691(81.2708) | Bit/dim 3.4792(3.4820) | Xent 0.0000(0.0000) | Loss 8.3940(9.0474) | Error 0.0000(0.0000) Steps 724(714.71) | Grad Norm 0.5852(2.3813) | Total Time 0.00(0.00)\n",
      "Iter 2806 | Time 80.5799(81.2501) | Bit/dim 3.4757(3.4818) | Xent 0.0000(0.0000) | Loss 8.6431(9.0353) | Error 0.0000(0.0000) Steps 730(715.17) | Grad Norm 0.9052(2.3371) | Total Time 0.00(0.00)\n",
      "Iter 2807 | Time 81.4397(81.2558) | Bit/dim 3.4706(3.4815) | Xent 0.0000(0.0000) | Loss 8.5129(9.0196) | Error 0.0000(0.0000) Steps 742(715.98) | Grad Norm 1.4565(2.3106) | Total Time 0.00(0.00)\n",
      "Iter 2808 | Time 78.6762(81.1784) | Bit/dim 3.4867(3.4816) | Xent 0.0000(0.0000) | Loss 8.5417(9.0053) | Error 0.0000(0.0000) Steps 736(716.58) | Grad Norm 1.9544(2.3000) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 24.6844, Epoch Time 522.4394(517.9507), Bit/dim 3.4872(best: 3.4780), Xent 0.0000, Loss 3.4872, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2809 | Time 79.5725(81.1302) | Bit/dim 3.4835(3.4817) | Xent 0.0000(0.0000) | Loss 11.1955(9.0710) | Error 0.0000(0.0000) Steps 688(715.72) | Grad Norm 2.2835(2.2995) | Total Time 0.00(0.00)\n",
      "Iter 2810 | Time 81.3430(81.1366) | Bit/dim 3.4750(3.4815) | Xent 0.0000(0.0000) | Loss 8.1341(9.0429) | Error 0.0000(0.0000) Steps 718(715.79) | Grad Norm 2.1524(2.2951) | Total Time 0.00(0.00)\n",
      "Iter 2811 | Time 76.1724(80.9877) | Bit/dim 3.4928(3.4818) | Xent 0.0000(0.0000) | Loss 8.4231(9.0243) | Error 0.0000(0.0000) Steps 712(715.68) | Grad Norm 1.6539(2.2758) | Total Time 0.00(0.00)\n",
      "Iter 2812 | Time 80.3551(80.9687) | Bit/dim 3.4711(3.4815) | Xent 0.0000(0.0000) | Loss 8.4121(9.0059) | Error 0.0000(0.0000) Steps 730(716.10) | Grad Norm 1.0859(2.2401) | Total Time 0.00(0.00)\n",
      "Iter 2813 | Time 83.7455(81.0520) | Bit/dim 3.4880(3.4817) | Xent 0.0000(0.0000) | Loss 8.4628(8.9896) | Error 0.0000(0.0000) Steps 730(716.52) | Grad Norm 0.4427(2.1862) | Total Time 0.00(0.00)\n",
      "Iter 2814 | Time 82.1215(81.0841) | Bit/dim 3.4723(3.4814) | Xent 0.0000(0.0000) | Loss 8.3812(8.9714) | Error 0.0000(0.0000) Steps 706(716.21) | Grad Norm 1.0778(2.1529) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 24.8663, Epoch Time 523.8566(518.1279), Bit/dim 3.4821(best: 3.4780), Xent 0.0000, Loss 3.4821, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2815 | Time 78.7559(81.0142) | Bit/dim 3.4763(3.4813) | Xent 0.0000(0.0000) | Loss 12.3122(9.0716) | Error 0.0000(0.0000) Steps 730(716.62) | Grad Norm 1.8085(2.1426) | Total Time 0.00(0.00)\n",
      "Iter 2816 | Time 84.2098(81.1101) | Bit/dim 3.4875(3.4815) | Xent 0.0000(0.0000) | Loss 8.4870(9.0541) | Error 0.0000(0.0000) Steps 712(716.48) | Grad Norm 2.5201(2.1539) | Total Time 0.00(0.00)\n",
      "Iter 2817 | Time 82.4679(81.1508) | Bit/dim 3.4915(3.4818) | Xent 0.0000(0.0000) | Loss 8.3661(9.0334) | Error 0.0000(0.0000) Steps 706(716.17) | Grad Norm 3.2012(2.1853) | Total Time 0.00(0.00)\n",
      "Iter 2818 | Time 77.9009(81.0533) | Bit/dim 3.4838(3.4818) | Xent 0.0000(0.0000) | Loss 8.3643(9.0134) | Error 0.0000(0.0000) Steps 694(715.50) | Grad Norm 3.7753(2.2330) | Total Time 0.00(0.00)\n",
      "Iter 2819 | Time 81.8413(81.0770) | Bit/dim 3.4739(3.4816) | Xent 0.0000(0.0000) | Loss 8.6908(9.0037) | Error 0.0000(0.0000) Steps 760(716.84) | Grad Norm 4.0894(2.2887) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 81.4816(81.0891) | Bit/dim 3.4789(3.4815) | Xent 0.0000(0.0000) | Loss 8.4321(8.9865) | Error 0.0000(0.0000) Steps 694(716.15) | Grad Norm 3.9824(2.3395) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 24.3643, Epoch Time 527.1201(518.3977), Bit/dim 3.4826(best: 3.4780), Xent 0.0000, Loss 3.4826, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2821 | Time 70.9681(80.7855) | Bit/dim 3.4834(3.4816) | Xent 0.0000(0.0000) | Loss 11.5024(9.0620) | Error 0.0000(0.0000) Steps 694(715.49) | Grad Norm 3.2363(2.3665) | Total Time 0.00(0.00)\n",
      "Iter 2822 | Time 78.3952(80.7138) | Bit/dim 3.4821(3.4816) | Xent 0.0000(0.0000) | Loss 8.2704(9.0383) | Error 0.0000(0.0000) Steps 706(715.20) | Grad Norm 2.6983(2.3764) | Total Time 0.00(0.00)\n",
      "Iter 2823 | Time 80.9955(80.7222) | Bit/dim 3.4803(3.4815) | Xent 0.0000(0.0000) | Loss 8.4404(9.0203) | Error 0.0000(0.0000) Steps 724(715.47) | Grad Norm 3.3545(2.4057) | Total Time 0.00(0.00)\n",
      "Iter 2824 | Time 87.4393(80.9237) | Bit/dim 3.4717(3.4812) | Xent 0.0000(0.0000) | Loss 8.1904(8.9954) | Error 0.0000(0.0000) Steps 712(715.36) | Grad Norm 3.7966(2.4475) | Total Time 0.00(0.00)\n",
      "Iter 2825 | Time 85.3054(81.0552) | Bit/dim 3.4962(3.4817) | Xent 0.0000(0.0000) | Loss 8.4995(8.9806) | Error 0.0000(0.0000) Steps 724(715.62) | Grad Norm 3.0854(2.4666) | Total Time 0.00(0.00)\n",
      "Iter 2826 | Time 79.4456(81.0069) | Bit/dim 3.4771(3.4816) | Xent 0.0000(0.0000) | Loss 8.3511(8.9617) | Error 0.0000(0.0000) Steps 700(715.15) | Grad Norm 1.2348(2.4297) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 23.8912, Epoch Time 522.6326(518.5247), Bit/dim 3.4849(best: 3.4780), Xent 0.0000, Loss 3.4849, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2827 | Time 82.1639(81.0416) | Bit/dim 3.4795(3.4815) | Xent 0.0000(0.0000) | Loss 12.1846(9.0584) | Error 0.0000(0.0000) Steps 712(715.06) | Grad Norm 1.6192(2.4053) | Total Time 0.00(0.00)\n",
      "Iter 2828 | Time 81.3624(81.0512) | Bit/dim 3.4789(3.4814) | Xent 0.0000(0.0000) | Loss 8.5727(9.0438) | Error 0.0000(0.0000) Steps 724(715.33) | Grad Norm 3.0834(2.4257) | Total Time 0.00(0.00)\n",
      "Iter 2829 | Time 77.4046(80.9418) | Bit/dim 3.4783(3.4813) | Xent 0.0000(0.0000) | Loss 8.3109(9.0218) | Error 0.0000(0.0000) Steps 718(715.41) | Grad Norm 3.5888(2.4606) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 82.0860(80.9762) | Bit/dim 3.4776(3.4812) | Xent 0.0000(0.0000) | Loss 8.4799(9.0055) | Error 0.0000(0.0000) Steps 730(715.84) | Grad Norm 3.2406(2.4840) | Total Time 0.00(0.00)\n",
      "Iter 2831 | Time 84.2286(81.0737) | Bit/dim 3.4761(3.4811) | Xent 0.0000(0.0000) | Loss 8.3439(8.9857) | Error 0.0000(0.0000) Steps 724(716.09) | Grad Norm 2.6999(2.4905) | Total Time 0.00(0.00)\n",
      "Iter 2832 | Time 80.3523(81.0521) | Bit/dim 3.4785(3.4810) | Xent 0.0000(0.0000) | Loss 8.3294(8.9660) | Error 0.0000(0.0000) Steps 712(715.97) | Grad Norm 2.9222(2.5034) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 24.8735, Epoch Time 528.1649(518.8139), Bit/dim 3.4874(best: 3.4780), Xent 0.0000, Loss 3.4874, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2833 | Time 84.4587(81.1543) | Bit/dim 3.4780(3.4809) | Xent 0.0000(0.0000) | Loss 12.2052(9.0632) | Error 0.0000(0.0000) Steps 712(715.85) | Grad Norm 3.5155(2.5338) | Total Time 0.00(0.00)\n",
      "Iter 2834 | Time 82.2090(81.1859) | Bit/dim 3.4842(3.4810) | Xent 0.0000(0.0000) | Loss 8.4634(9.0452) | Error 0.0000(0.0000) Steps 718(715.91) | Grad Norm 3.1767(2.5531) | Total Time 0.00(0.00)\n",
      "Iter 2835 | Time 75.8126(81.0247) | Bit/dim 3.4765(3.4809) | Xent 0.0000(0.0000) | Loss 8.3307(9.0238) | Error 0.0000(0.0000) Steps 706(715.61) | Grad Norm 2.1251(2.5402) | Total Time 0.00(0.00)\n",
      "Iter 2836 | Time 81.9068(81.0512) | Bit/dim 3.4714(3.4806) | Xent 0.0000(0.0000) | Loss 8.4213(9.0057) | Error 0.0000(0.0000) Steps 718(715.69) | Grad Norm 1.0599(2.4958) | Total Time 0.00(0.00)\n",
      "Iter 2837 | Time 84.3091(81.1489) | Bit/dim 3.4747(3.4804) | Xent 0.0000(0.0000) | Loss 8.1766(8.9808) | Error 0.0000(0.0000) Steps 730(716.12) | Grad Norm 0.9636(2.4498) | Total Time 0.00(0.00)\n",
      "Iter 2838 | Time 82.9544(81.2031) | Bit/dim 3.4905(3.4807) | Xent 0.0000(0.0000) | Loss 8.5410(8.9676) | Error 0.0000(0.0000) Steps 736(716.71) | Grad Norm 1.7615(2.4292) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 25.0829, Epoch Time 532.5228(519.2252), Bit/dim 3.4838(best: 3.4780), Xent 0.0000, Loss 3.4838, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2839 | Time 84.8017(81.3111) | Bit/dim 3.4773(3.4806) | Xent 0.0000(0.0000) | Loss 12.1165(9.0621) | Error 0.0000(0.0000) Steps 712(716.57) | Grad Norm 2.3306(2.4262) | Total Time 0.00(0.00)\n",
      "Iter 2840 | Time 83.1399(81.3659) | Bit/dim 3.4744(3.4804) | Xent 0.0000(0.0000) | Loss 8.5010(9.0452) | Error 0.0000(0.0000) Steps 736(717.15) | Grad Norm 2.5458(2.4298) | Total Time 0.00(0.00)\n",
      "Iter 2841 | Time 86.4644(81.5189) | Bit/dim 3.4808(3.4804) | Xent 0.0000(0.0000) | Loss 8.4107(9.0262) | Error 0.0000(0.0000) Steps 730(717.54) | Grad Norm 2.3407(2.4272) | Total Time 0.00(0.00)\n",
      "Iter 2842 | Time 79.2454(81.4507) | Bit/dim 3.4905(3.4807) | Xent 0.0000(0.0000) | Loss 8.5534(9.0120) | Error 0.0000(0.0000) Steps 724(717.73) | Grad Norm 1.6729(2.4045) | Total Time 0.00(0.00)\n",
      "Iter 2843 | Time 86.0560(81.5888) | Bit/dim 3.4772(3.4806) | Xent 0.0000(0.0000) | Loss 8.4075(8.9939) | Error 0.0000(0.0000) Steps 730(718.10) | Grad Norm 0.9875(2.3620) | Total Time 0.00(0.00)\n",
      "Iter 2844 | Time 80.1608(81.5460) | Bit/dim 3.4818(3.4807) | Xent 0.0000(0.0000) | Loss 8.4623(8.9779) | Error 0.0000(0.0000) Steps 718(718.10) | Grad Norm 0.8972(2.3181) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 25.4139, Epoch Time 541.5653(519.8954), Bit/dim 3.4797(best: 3.4780), Xent 0.0000, Loss 3.4797, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2845 | Time 78.4544(81.4532) | Bit/dim 3.4741(3.4805) | Xent 0.0000(0.0000) | Loss 12.1647(9.0735) | Error 0.0000(0.0000) Steps 700(717.56) | Grad Norm 1.7265(2.3003) | Total Time 0.00(0.00)\n",
      "Iter 2846 | Time 82.0660(81.4716) | Bit/dim 3.4792(3.4804) | Xent 0.0000(0.0000) | Loss 8.2675(9.0494) | Error 0.0000(0.0000) Steps 712(717.39) | Grad Norm 2.4185(2.3039) | Total Time 0.00(0.00)\n",
      "Iter 2847 | Time 77.5300(81.3534) | Bit/dim 3.4741(3.4802) | Xent 0.0000(0.0000) | Loss 8.3907(9.0296) | Error 0.0000(0.0000) Steps 706(717.05) | Grad Norm 2.5890(2.3124) | Total Time 0.00(0.00)\n",
      "Iter 2848 | Time 78.7567(81.2755) | Bit/dim 3.4845(3.4804) | Xent 0.0000(0.0000) | Loss 8.4323(9.0117) | Error 0.0000(0.0000) Steps 706(716.72) | Grad Norm 2.9226(2.3307) | Total Time 0.00(0.00)\n",
      "Iter 2849 | Time 84.4641(81.3711) | Bit/dim 3.4847(3.4805) | Xent 0.0000(0.0000) | Loss 8.3035(8.9904) | Error 0.0000(0.0000) Steps 700(716.21) | Grad Norm 3.2452(2.3582) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 88.3291(81.5799) | Bit/dim 3.4753(3.4803) | Xent 0.0000(0.0000) | Loss 8.4376(8.9739) | Error 0.0000(0.0000) Steps 736(716.81) | Grad Norm 3.4514(2.3910) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 24.6100, Epoch Time 530.0387(520.1997), Bit/dim 3.4823(best: 3.4780), Xent 0.0000, Loss 3.4823, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2851 | Time 78.5341(81.4885) | Bit/dim 3.4851(3.4805) | Xent 0.0000(0.0000) | Loss 11.9383(9.0628) | Error 0.0000(0.0000) Steps 712(716.66) | Grad Norm 3.7372(2.4313) | Total Time 0.00(0.00)\n",
      "Iter 2852 | Time 83.5502(81.5504) | Bit/dim 3.4869(3.4807) | Xent 0.0000(0.0000) | Loss 8.1882(9.0366) | Error 0.0000(0.0000) Steps 694(715.98) | Grad Norm 3.2873(2.4570) | Total Time 0.00(0.00)\n",
      "Iter 2853 | Time 80.5882(81.5215) | Bit/dim 3.4838(3.4808) | Xent 0.0000(0.0000) | Loss 8.2240(9.0122) | Error 0.0000(0.0000) Steps 712(715.86) | Grad Norm 2.1982(2.4493) | Total Time 0.00(0.00)\n",
      "Iter 2854 | Time 81.6439(81.5252) | Bit/dim 3.4772(3.4807) | Xent 0.0000(0.0000) | Loss 8.3723(8.9930) | Error 0.0000(0.0000) Steps 712(715.75) | Grad Norm 1.1668(2.4108) | Total Time 0.00(0.00)\n",
      "Iter 2855 | Time 79.6726(81.4696) | Bit/dim 3.4718(3.4804) | Xent 0.0000(0.0000) | Loss 8.4277(8.9760) | Error 0.0000(0.0000) Steps 736(716.36) | Grad Norm 0.9053(2.3656) | Total Time 0.00(0.00)\n",
      "Iter 2856 | Time 77.1150(81.3389) | Bit/dim 3.4806(3.4804) | Xent 0.0000(0.0000) | Loss 8.4469(8.9601) | Error 0.0000(0.0000) Steps 712(716.22) | Grad Norm 1.6533(2.3443) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 24.5528, Epoch Time 521.3766(520.2350), Bit/dim 3.4827(best: 3.4780), Xent 0.0000, Loss 3.4827, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2857 | Time 79.6809(81.2892) | Bit/dim 3.4842(3.4805) | Xent 0.0000(0.0000) | Loss 12.2205(9.0580) | Error 0.0000(0.0000) Steps 706(715.92) | Grad Norm 2.4301(2.3468) | Total Time 0.00(0.00)\n",
      "Iter 2858 | Time 81.7604(81.3033) | Bit/dim 3.4816(3.4805) | Xent 0.0000(0.0000) | Loss 7.9146(9.0237) | Error 0.0000(0.0000) Steps 700(715.44) | Grad Norm 2.9044(2.3636) | Total Time 0.00(0.00)\n",
      "Iter 2859 | Time 72.6695(81.0443) | Bit/dim 3.4700(3.4802) | Xent 0.0000(0.0000) | Loss 8.2979(9.0019) | Error 0.0000(0.0000) Steps 682(714.44) | Grad Norm 3.1019(2.3857) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 78.4138(80.9654) | Bit/dim 3.4748(3.4801) | Xent 0.0000(0.0000) | Loss 8.0586(8.9736) | Error 0.0000(0.0000) Steps 682(713.46) | Grad Norm 3.0330(2.4051) | Total Time 0.00(0.00)\n",
      "Iter 2861 | Time 80.6649(80.9564) | Bit/dim 3.4735(3.4799) | Xent 0.0000(0.0000) | Loss 8.4090(8.9566) | Error 0.0000(0.0000) Steps 718(713.60) | Grad Norm 2.5094(2.4083) | Total Time 0.00(0.00)\n",
      "Iter 2862 | Time 74.7496(80.7702) | Bit/dim 3.4830(3.4800) | Xent 0.0000(0.0000) | Loss 8.3573(8.9387) | Error 0.0000(0.0000) Steps 712(713.55) | Grad Norm 1.9642(2.3949) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 24.5007, Epoch Time 508.3654(519.8789), Bit/dim 3.4801(best: 3.4780), Xent 0.0000, Loss 3.4801, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2863 | Time 82.7665(80.8301) | Bit/dim 3.4718(3.4797) | Xent 0.0000(0.0000) | Loss 12.1234(9.0342) | Error 0.0000(0.0000) Steps 736(714.23) | Grad Norm 1.7291(2.3750) | Total Time 0.00(0.00)\n",
      "Iter 2864 | Time 81.9119(80.8625) | Bit/dim 3.4799(3.4797) | Xent 0.0000(0.0000) | Loss 8.2441(9.0105) | Error 0.0000(0.0000) Steps 724(714.52) | Grad Norm 1.7037(2.3548) | Total Time 0.00(0.00)\n",
      "Iter 2865 | Time 81.0468(80.8681) | Bit/dim 3.4748(3.4796) | Xent 0.0000(0.0000) | Loss 8.2993(8.9892) | Error 0.0000(0.0000) Steps 730(714.98) | Grad Norm 1.8582(2.3399) | Total Time 0.00(0.00)\n",
      "Iter 2866 | Time 81.8018(80.8961) | Bit/dim 3.4801(3.4796) | Xent 0.0000(0.0000) | Loss 8.2997(8.9685) | Error 0.0000(0.0000) Steps 730(715.43) | Grad Norm 2.3397(2.3399) | Total Time 0.00(0.00)\n",
      "Iter 2867 | Time 78.2064(80.8154) | Bit/dim 3.4790(3.4796) | Xent 0.0000(0.0000) | Loss 8.5349(8.9555) | Error 0.0000(0.0000) Steps 736(716.05) | Grad Norm 3.0845(2.3622) | Total Time 0.00(0.00)\n",
      "Iter 2868 | Time 83.9467(80.9093) | Bit/dim 3.4912(3.4799) | Xent 0.0000(0.0000) | Loss 8.3565(8.9375) | Error 0.0000(0.0000) Steps 712(715.93) | Grad Norm 3.4919(2.3961) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 24.5363, Epoch Time 530.5812(520.2000), Bit/dim 3.4828(best: 3.4780), Xent 0.0000, Loss 3.4828, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2869 | Time 83.5599(80.9888) | Bit/dim 3.4829(3.4800) | Xent 0.0000(0.0000) | Loss 12.2902(9.0381) | Error 0.0000(0.0000) Steps 724(716.17) | Grad Norm 3.1278(2.4181) | Total Time 0.00(0.00)\n",
      "Iter 2870 | Time 82.9419(81.0474) | Bit/dim 3.4759(3.4799) | Xent 0.0000(0.0000) | Loss 8.2172(9.0135) | Error 0.0000(0.0000) Steps 712(716.05) | Grad Norm 2.2667(2.4135) | Total Time 0.00(0.00)\n",
      "Iter 2871 | Time 80.6459(81.0354) | Bit/dim 3.4664(3.4795) | Xent 0.0000(0.0000) | Loss 8.5504(8.9996) | Error 0.0000(0.0000) Steps 712(715.92) | Grad Norm 1.2684(2.3792) | Total Time 0.00(0.00)\n",
      "Iter 2872 | Time 86.9264(81.2121) | Bit/dim 3.4878(3.4797) | Xent 0.0000(0.0000) | Loss 8.5034(8.9847) | Error 0.0000(0.0000) Steps 730(716.35) | Grad Norm 0.7845(2.3313) | Total Time 0.00(0.00)\n",
      "Iter 2873 | Time 79.9251(81.1735) | Bit/dim 3.4665(3.4793) | Xent 0.0000(0.0000) | Loss 8.4381(8.9683) | Error 0.0000(0.0000) Steps 706(716.04) | Grad Norm 1.2632(2.2993) | Total Time 0.00(0.00)\n",
      "Iter 2874 | Time 80.5734(81.1555) | Bit/dim 3.4832(3.4795) | Xent 0.0000(0.0000) | Loss 8.3277(8.9491) | Error 0.0000(0.0000) Steps 700(715.56) | Grad Norm 2.1012(2.2934) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 25.1415, Epoch Time 535.9235(520.6717), Bit/dim 3.4815(best: 3.4780), Xent 0.0000, Loss 3.4815, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2875 | Time 86.7663(81.3238) | Bit/dim 3.4886(3.4797) | Xent 0.0000(0.0000) | Loss 12.5224(9.0563) | Error 0.0000(0.0000) Steps 730(715.99) | Grad Norm 3.0049(2.3147) | Total Time 0.00(0.00)\n",
      "Iter 2876 | Time 82.2843(81.3526) | Bit/dim 3.4908(3.4801) | Xent 0.0000(0.0000) | Loss 8.5145(9.0400) | Error 0.0000(0.0000) Steps 718(716.05) | Grad Norm 3.6378(2.3544) | Total Time 0.00(0.00)\n",
      "Iter 2877 | Time 80.8635(81.3380) | Bit/dim 3.4884(3.4803) | Xent 0.0000(0.0000) | Loss 8.2430(9.0161) | Error 0.0000(0.0000) Steps 724(716.29) | Grad Norm 3.5134(2.3892) | Total Time 0.00(0.00)\n",
      "Iter 2878 | Time 83.1704(81.3929) | Bit/dim 3.4704(3.4800) | Xent 0.0000(0.0000) | Loss 8.4064(8.9978) | Error 0.0000(0.0000) Steps 724(716.52) | Grad Norm 2.5850(2.3950) | Total Time 0.00(0.00)\n",
      "Iter 2879 | Time 83.2952(81.4500) | Bit/dim 3.4708(3.4797) | Xent 0.0000(0.0000) | Loss 8.2184(8.9744) | Error 0.0000(0.0000) Steps 718(716.56) | Grad Norm 1.5219(2.3688) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 78.0800(81.3489) | Bit/dim 3.4630(3.4792) | Xent 0.0000(0.0000) | Loss 8.2147(8.9516) | Error 0.0000(0.0000) Steps 712(716.43) | Grad Norm 0.7589(2.3205) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 24.7328, Epoch Time 535.1232(521.1052), Bit/dim 3.4787(best: 3.4780), Xent 0.0000, Loss 3.4787, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2881 | Time 80.6382(81.3276) | Bit/dim 3.4713(3.4790) | Xent 0.0000(0.0000) | Loss 12.0145(9.0435) | Error 0.0000(0.0000) Steps 712(716.29) | Grad Norm 1.1287(2.2848) | Total Time 0.00(0.00)\n",
      "Iter 2882 | Time 87.3228(81.5074) | Bit/dim 3.4787(3.4790) | Xent 0.0000(0.0000) | Loss 8.5288(9.0281) | Error 0.0000(0.0000) Steps 742(717.07) | Grad Norm 1.8222(2.2709) | Total Time 0.00(0.00)\n",
      "Iter 2883 | Time 80.8970(81.4891) | Bit/dim 3.4765(3.4789) | Xent 0.0000(0.0000) | Loss 8.3660(9.0082) | Error 0.0000(0.0000) Steps 700(716.55) | Grad Norm 2.6731(2.2830) | Total Time 0.00(0.00)\n",
      "Iter 2884 | Time 82.2331(81.5115) | Bit/dim 3.4842(3.4791) | Xent 0.0000(0.0000) | Loss 8.4672(8.9920) | Error 0.0000(0.0000) Steps 730(716.96) | Grad Norm 3.4695(2.3186) | Total Time 0.00(0.00)\n",
      "Iter 2885 | Time 84.1766(81.5914) | Bit/dim 3.4832(3.4792) | Xent 0.0000(0.0000) | Loss 8.3526(8.9728) | Error 0.0000(0.0000) Steps 718(716.99) | Grad Norm 3.6132(2.3574) | Total Time 0.00(0.00)\n",
      "Iter 2886 | Time 87.7160(81.7751) | Bit/dim 3.4761(3.4791) | Xent 0.0000(0.0000) | Loss 8.4278(8.9565) | Error 0.0000(0.0000) Steps 724(717.20) | Grad Norm 3.0043(2.3768) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 25.0989, Epoch Time 543.6713(521.7822), Bit/dim 3.4805(best: 3.4780), Xent 0.0000, Loss 3.4805, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2887 | Time 83.1970(81.8178) | Bit/dim 3.4660(3.4787) | Xent 0.0000(0.0000) | Loss 12.6099(9.0661) | Error 0.0000(0.0000) Steps 730(717.58) | Grad Norm 2.1255(2.3693) | Total Time 0.00(0.00)\n",
      "Iter 2888 | Time 84.7755(81.9065) | Bit/dim 3.4759(3.4786) | Xent 0.0000(0.0000) | Loss 8.4955(9.0489) | Error 0.0000(0.0000) Steps 742(718.31) | Grad Norm 1.4453(2.3416) | Total Time 0.00(0.00)\n",
      "Iter 2889 | Time 82.8828(81.9358) | Bit/dim 3.4725(3.4784) | Xent 0.0000(0.0000) | Loss 8.4153(9.0299) | Error 0.0000(0.0000) Steps 718(718.31) | Grad Norm 1.2582(2.3091) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 84.1995(82.0037) | Bit/dim 3.4800(3.4785) | Xent 0.0000(0.0000) | Loss 8.4708(9.0132) | Error 0.0000(0.0000) Steps 724(718.48) | Grad Norm 1.6354(2.2889) | Total Time 0.00(0.00)\n",
      "Iter 2891 | Time 81.1604(81.9784) | Bit/dim 3.4893(3.4788) | Xent 0.0000(0.0000) | Loss 8.4064(8.9950) | Error 0.0000(0.0000) Steps 712(718.28) | Grad Norm 2.3945(2.2920) | Total Time 0.00(0.00)\n",
      "Iter 2892 | Time 82.9318(82.0070) | Bit/dim 3.4889(3.4791) | Xent 0.0000(0.0000) | Loss 8.3114(8.9744) | Error 0.0000(0.0000) Steps 700(717.73) | Grad Norm 3.2572(2.3210) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 24.9541, Epoch Time 539.8358(522.3238), Bit/dim 3.4796(best: 3.4780), Xent 0.0000, Loss 3.4796, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2893 | Time 80.6822(81.9673) | Bit/dim 3.4845(3.4793) | Xent 0.0000(0.0000) | Loss 12.4117(9.0776) | Error 0.0000(0.0000) Steps 706(717.38) | Grad Norm 3.7400(2.3635) | Total Time 0.00(0.00)\n",
      "Iter 2894 | Time 80.8493(81.9337) | Bit/dim 3.4784(3.4792) | Xent 0.0000(0.0000) | Loss 8.2986(9.0542) | Error 0.0000(0.0000) Steps 694(716.68) | Grad Norm 3.5422(2.3989) | Total Time 0.00(0.00)\n",
      "Iter 2895 | Time 85.7032(82.0468) | Bit/dim 3.4607(3.4787) | Xent 0.0000(0.0000) | Loss 8.3445(9.0329) | Error 0.0000(0.0000) Steps 718(716.72) | Grad Norm 2.9607(2.4158) | Total Time 0.00(0.00)\n",
      "Iter 2896 | Time 83.4016(82.0875) | Bit/dim 3.4742(3.4786) | Xent 0.0000(0.0000) | Loss 8.4439(9.0152) | Error 0.0000(0.0000) Steps 736(717.30) | Grad Norm 2.3746(2.4145) | Total Time 0.00(0.00)\n",
      "Iter 2897 | Time 84.1516(82.1494) | Bit/dim 3.4894(3.4789) | Xent 0.0000(0.0000) | Loss 8.6159(9.0033) | Error 0.0000(0.0000) Steps 748(718.22) | Grad Norm 1.8419(2.3973) | Total Time 0.00(0.00)\n",
      "Iter 2898 | Time 82.6547(82.1646) | Bit/dim 3.4764(3.4788) | Xent 0.0000(0.0000) | Loss 8.3104(8.9825) | Error 0.0000(0.0000) Steps 700(717.67) | Grad Norm 1.6439(2.3747) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 25.0429, Epoch Time 538.4187(522.8067), Bit/dim 3.4819(best: 3.4780), Xent 0.0000, Loss 3.4819, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2899 | Time 78.5297(82.0555) | Bit/dim 3.4766(3.4787) | Xent 0.0000(0.0000) | Loss 12.1700(9.0781) | Error 0.0000(0.0000) Steps 706(717.32) | Grad Norm 1.7306(2.3554) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 83.1980(82.0898) | Bit/dim 3.4783(3.4787) | Xent 0.0000(0.0000) | Loss 8.4110(9.0581) | Error 0.0000(0.0000) Steps 712(717.16) | Grad Norm 2.0899(2.3475) | Total Time 0.00(0.00)\n",
      "Iter 2901 | Time 80.0272(82.0279) | Bit/dim 3.4797(3.4788) | Xent 0.0000(0.0000) | Loss 8.4605(9.0402) | Error 0.0000(0.0000) Steps 718(717.19) | Grad Norm 2.8542(2.3627) | Total Time 0.00(0.00)\n",
      "Iter 2902 | Time 80.8693(81.9932) | Bit/dim 3.4831(3.4789) | Xent 0.0000(0.0000) | Loss 8.4376(9.0221) | Error 0.0000(0.0000) Steps 718(717.21) | Grad Norm 3.4927(2.3966) | Total Time 0.00(0.00)\n",
      "Iter 2903 | Time 81.9986(81.9933) | Bit/dim 3.4753(3.4788) | Xent 0.0000(0.0000) | Loss 8.2830(8.9999) | Error 0.0000(0.0000) Steps 730(717.60) | Grad Norm 3.6369(2.4338) | Total Time 0.00(0.00)\n",
      "Iter 2904 | Time 81.9421(81.9918) | Bit/dim 3.4800(3.4788) | Xent 0.0000(0.0000) | Loss 8.4926(8.9847) | Error 0.0000(0.0000) Steps 730(717.97) | Grad Norm 3.1401(2.4550) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 25.6015, Epoch Time 527.8897(522.9592), Bit/dim 3.4795(best: 3.4780), Xent 0.0000, Loss 3.4795, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2905 | Time 81.6319(81.9810) | Bit/dim 3.4798(3.4788) | Xent 0.0000(0.0000) | Loss 12.2851(9.0837) | Error 0.0000(0.0000) Steps 736(718.51) | Grad Norm 1.9793(2.4407) | Total Time 0.00(0.00)\n",
      "Iter 2906 | Time 80.2942(81.9304) | Bit/dim 3.4811(3.4789) | Xent 0.0000(0.0000) | Loss 8.3731(9.0624) | Error 0.0000(0.0000) Steps 718(718.49) | Grad Norm 1.0356(2.3985) | Total Time 0.00(0.00)\n",
      "Iter 2907 | Time 86.0777(82.0548) | Bit/dim 3.4733(3.4787) | Xent 0.0000(0.0000) | Loss 8.3358(9.0406) | Error 0.0000(0.0000) Steps 736(719.02) | Grad Norm 1.2312(2.3635) | Total Time 0.00(0.00)\n",
      "Iter 2908 | Time 81.2331(82.0301) | Bit/dim 3.4770(3.4787) | Xent 0.0000(0.0000) | Loss 8.5162(9.0248) | Error 0.0000(0.0000) Steps 730(719.35) | Grad Norm 1.9637(2.3515) | Total Time 0.00(0.00)\n",
      "Iter 2909 | Time 82.3435(82.0395) | Bit/dim 3.4766(3.4786) | Xent 0.0000(0.0000) | Loss 8.5553(9.0108) | Error 0.0000(0.0000) Steps 736(719.85) | Grad Norm 2.7625(2.3638) | Total Time 0.00(0.00)\n",
      "Iter 2910 | Time 84.0513(82.0999) | Bit/dim 3.4804(3.4787) | Xent 0.0000(0.0000) | Loss 8.3975(8.9924) | Error 0.0000(0.0000) Steps 718(719.79) | Grad Norm 3.4084(2.3952) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 25.0617, Epoch Time 536.5865(523.3680), Bit/dim 3.4812(best: 3.4780), Xent 0.0000, Loss 3.4812, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2911 | Time 88.3519(82.2875) | Bit/dim 3.4726(3.4785) | Xent 0.0000(0.0000) | Loss 12.4524(9.0962) | Error 0.0000(0.0000) Steps 706(719.38) | Grad Norm 3.4477(2.4268) | Total Time 0.00(0.00)\n",
      "Iter 2912 | Time 82.6836(82.2993) | Bit/dim 3.4939(3.4790) | Xent 0.0000(0.0000) | Loss 8.5123(9.0787) | Error 0.0000(0.0000) Steps 730(719.70) | Grad Norm 2.5064(2.4291) | Total Time 0.00(0.00)\n",
      "Iter 2913 | Time 82.0551(82.2920) | Bit/dim 3.4795(3.4790) | Xent 0.0000(0.0000) | Loss 8.4384(9.0594) | Error 0.0000(0.0000) Steps 706(719.29) | Grad Norm 1.3499(2.3968) | Total Time 0.00(0.00)\n",
      "Iter 2914 | Time 86.1073(82.4065) | Bit/dim 3.4723(3.4788) | Xent 0.0000(0.0000) | Loss 8.4133(9.0401) | Error 0.0000(0.0000) Steps 718(719.25) | Grad Norm 1.0896(2.3576) | Total Time 0.00(0.00)\n",
      "Iter 2915 | Time 81.9619(82.3931) | Bit/dim 3.4802(3.4788) | Xent 0.0000(0.0000) | Loss 8.5417(9.0251) | Error 0.0000(0.0000) Steps 736(719.75) | Grad Norm 2.0351(2.3479) | Total Time 0.00(0.00)\n",
      "Iter 2916 | Time 82.4572(82.3951) | Bit/dim 3.4749(3.4787) | Xent 0.0000(0.0000) | Loss 8.4416(9.0076) | Error 0.0000(0.0000) Steps 712(719.52) | Grad Norm 3.1363(2.3715) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 25.1453, Epoch Time 544.6237(524.0057), Bit/dim 3.4819(best: 3.4780), Xent 0.0000, Loss 3.4819, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2917 | Time 83.8253(82.4380) | Bit/dim 3.4881(3.4790) | Xent 0.0000(0.0000) | Loss 13.0261(9.1282) | Error 0.0000(0.0000) Steps 742(720.19) | Grad Norm 3.6725(2.4106) | Total Time 0.00(0.00)\n",
      "Iter 2918 | Time 80.4365(82.3779) | Bit/dim 3.4852(3.4792) | Xent 0.0000(0.0000) | Loss 8.5778(9.1117) | Error 0.0000(0.0000) Steps 724(720.31) | Grad Norm 3.6261(2.4470) | Total Time 0.00(0.00)\n",
      "Iter 2919 | Time 91.2282(82.6434) | Bit/dim 3.4660(3.4788) | Xent 0.0000(0.0000) | Loss 8.3459(9.0887) | Error 0.0000(0.0000) Steps 730(720.60) | Grad Norm 3.2580(2.4714) | Total Time 0.00(0.00)\n",
      "Iter 2920 | Time 86.6953(82.7650) | Bit/dim 3.4749(3.4787) | Xent 0.0000(0.0000) | Loss 8.4354(9.0691) | Error 0.0000(0.0000) Steps 736(721.06) | Grad Norm 2.9976(2.4871) | Total Time 0.00(0.00)\n",
      "Iter 2921 | Time 82.7512(82.7646) | Bit/dim 3.4640(3.4782) | Xent 0.0000(0.0000) | Loss 8.4622(9.0509) | Error 0.0000(0.0000) Steps 742(721.69) | Grad Norm 3.0303(2.5034) | Total Time 0.00(0.00)\n",
      "Iter 2922 | Time 85.2429(82.8389) | Bit/dim 3.4852(3.4784) | Xent 0.0000(0.0000) | Loss 8.6112(9.0377) | Error 0.0000(0.0000) Steps 742(722.30) | Grad Norm 3.0475(2.5198) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 25.6152, Epoch Time 551.7449(524.8378), Bit/dim 3.4795(best: 3.4780), Xent 0.0000, Loss 3.4795, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2923 | Time 89.6220(83.0424) | Bit/dim 3.4818(3.4785) | Xent 0.0000(0.0000) | Loss 11.9184(9.1241) | Error 0.0000(0.0000) Steps 730(722.53) | Grad Norm 2.8637(2.5301) | Total Time 0.00(0.00)\n",
      "Iter 2924 | Time 79.0057(82.9213) | Bit/dim 3.4757(3.4784) | Xent 0.0000(0.0000) | Loss 8.3199(9.1000) | Error 0.0000(0.0000) Steps 718(722.39) | Grad Norm 2.3218(2.5238) | Total Time 0.00(0.00)\n",
      "Iter 2925 | Time 87.1865(83.0493) | Bit/dim 3.4760(3.4784) | Xent 0.0000(0.0000) | Loss 8.5198(9.0826) | Error 0.0000(0.0000) Steps 742(722.98) | Grad Norm 1.7181(2.4997) | Total Time 0.00(0.00)\n",
      "Iter 2926 | Time 88.0456(83.1992) | Bit/dim 3.4733(3.4782) | Xent 0.0000(0.0000) | Loss 8.3955(9.0620) | Error 0.0000(0.0000) Steps 724(723.01) | Grad Norm 10.0829(2.7272) | Total Time 0.00(0.00)\n",
      "Iter 2927 | Time 76.3118(82.9925) | Bit/dim 3.4877(3.4785) | Xent 0.0000(0.0000) | Loss 8.4201(9.0427) | Error 0.0000(0.0000) Steps 712(722.68) | Grad Norm 3.6440(2.7547) | Total Time 0.00(0.00)\n",
      "Iter 2928 | Time 87.8835(83.1393) | Bit/dim 3.5054(3.4793) | Xent 0.0000(0.0000) | Loss 8.4870(9.0260) | Error 0.0000(0.0000) Steps 736(723.08) | Grad Norm 3.8779(2.7884) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 25.2334, Epoch Time 549.1933(525.5685), Bit/dim 3.5051(best: 3.4780), Xent 0.0000, Loss 3.5051, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2929 | Time 105.3001(83.8041) | Bit/dim 3.4946(3.4798) | Xent 0.0000(0.0000) | Loss 12.2024(9.1213) | Error 0.0000(0.0000) Steps 730(723.29) | Grad Norm 149081425484.0994(4472442767.2277) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 118.1381(84.8341) | Bit/dim 3.5614(3.4822) | Xent 0.0000(0.0000) | Loss 8.4023(9.0998) | Error 0.0000(0.0000) Steps 778(724.93) | Grad Norm 8029961.6171(4338510383.0594) | Total Time 0.00(0.00)\n",
      "Iter 2931 | Time 133.8704(86.3052) | Bit/dim 3.6616(3.4876) | Xent 0.0000(0.0000) | Loss 8.7250(9.0885) | Error 0.0000(0.0000) Steps 832(728.14) | Grad Norm 8575673536788.5391(261478561175.2240) | Total Time 0.00(0.00)\n",
      "Iter 2932 | Time 117.1577(87.2308) | Bit/dim 3.7613(3.4958) | Xent 0.0000(0.0000) | Loss 8.9260(9.0836) | Error 0.0000(0.0000) Steps 736(728.38) | Grad Norm 23165872.5141(253634899316.1427) | Total Time 0.00(0.00)\n",
      "Iter 2933 | Time 166.7535(89.6164) | Bit/dim 3.8816(3.5074) | Xent 0.0000(0.0000) | Loss 9.2896(9.0898) | Error 0.0000(0.0000) Steps 922(734.19) | Grad Norm inf(inf) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_cifar10_bs8K_rl_stdlearnscale_30_run2 --resume ../experiments_published/cnf_cifar10_bs8K_rl_stdlearnscale_30_run2/epoch_200_checkpt.pth --seed 2 --conditional False --lr 0.001 --warmup_iters 1000 --atol 1e-4  --rtol 1e-4 --scale_fac 1.0 --gate cnn2 --scale_std 15.0 --max_grad_norm 20.0\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
