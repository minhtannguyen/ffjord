{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=True, atol=0.0001, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=False, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.0, eta=0.1, gamma=0.99, gate='cnn2', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.01, max_grad_norm=20.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume=None, rl_weight=0.01, rtol=0.0001, save='../experiments_published/cnf_cifar10_bs8K_rl_stdlearnscale_30_annealing_run3', scale=1.0, scale_fac=1.0, scale_std=15.0, seed=3, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000.0, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1450886\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 0001 | Time 106.1473(106.1473) | Bit/dim 9.2554(9.2554) | Xent 0.0000(0.0000) | Loss 20.2239(20.2239) | Error 0.0000(0.0000) Steps 478(478.00) | Grad Norm 38.9725(38.9725) | Total Time 0.00(0.00)\n",
      "Iter 0002 | Time 37.0217(104.0735) | Bit/dim 9.1289(9.2516) | Xent 0.0000(0.0000) | Loss 19.9529(20.2158) | Error 0.0000(0.0000) Steps 472(477.82) | Grad Norm 34.8868(38.8499) | Total Time 0.00(0.00)\n",
      "Iter 0003 | Time 39.0510(102.1228) | Bit/dim 8.9921(9.2438) | Xent 0.0000(0.0000) | Loss 19.7892(20.2030) | Error 0.0000(0.0000) Steps 502(478.55) | Grad Norm 29.2791(38.5628) | Total Time 0.00(0.00)\n",
      "Iter 0004 | Time 39.8906(100.2559) | Bit/dim 8.8380(9.2316) | Xent 0.0000(0.0000) | Loss 19.2361(20.1740) | Error 0.0000(0.0000) Steps 466(478.17) | Grad Norm 21.9595(38.0647) | Total Time 0.00(0.00)\n",
      "Iter 0005 | Time 38.8317(98.4131) | Bit/dim 8.7035(9.2158) | Xent 0.0000(0.0000) | Loss 19.0508(20.1403) | Error 0.0000(0.0000) Steps 490(478.52) | Grad Norm 15.3794(37.3842) | Total Time 0.00(0.00)\n",
      "Iter 0006 | Time 38.8867(96.6273) | Bit/dim 8.5902(9.1970) | Xent 0.0000(0.0000) | Loss 18.5970(20.0940) | Error 0.0000(0.0000) Steps 490(478.87) | Grad Norm 10.1523(36.5672) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 36.7562, Epoch Time 356.3648(356.3648), Bit/dim 8.5414(best: inf), Xent 0.0000, Loss 8.5414, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0007 | Time 48.8221(95.1932) | Bit/dim 8.5472(9.1775) | Xent 0.0000(0.0000) | Loss 21.6010(20.1392) | Error 0.0000(0.0000) Steps 490(479.20) | Grad Norm 11.0237(35.8009) | Total Time 0.00(0.00)\n",
      "Iter 0008 | Time 40.0055(93.5376) | Bit/dim 8.5462(9.1586) | Xent 0.0000(0.0000) | Loss 18.5246(20.0907) | Error 0.0000(0.0000) Steps 466(478.81) | Grad Norm 14.6949(35.1677) | Total Time 0.00(0.00)\n",
      "Iter 0009 | Time 40.8636(91.9573) | Bit/dim 8.5116(9.1392) | Xent 0.0000(0.0000) | Loss 18.6368(20.0471) | Error 0.0000(0.0000) Steps 490(479.14) | Grad Norm 16.8226(34.6174) | Total Time 0.00(0.00)\n",
      "Iter 0010 | Time 42.5576(90.4753) | Bit/dim 8.4723(9.1192) | Xent 0.0000(0.0000) | Loss 18.8521(20.0113) | Error 0.0000(0.0000) Steps 502(479.83) | Grad Norm 17.5932(34.1066) | Total Time 0.00(0.00)\n",
      "Iter 0011 | Time 36.7179(88.8626) | Bit/dim 8.4172(9.0981) | Xent 0.0000(0.0000) | Loss 17.3586(19.9317) | Error 0.0000(0.0000) Steps 436(478.51) | Grad Norm 15.2377(33.5406) | Total Time 0.00(0.00)\n",
      "Iter 0012 | Time 34.9182(87.2443) | Bit/dim 8.3221(9.0748) | Xent 0.0000(0.0000) | Loss 17.8878(19.8704) | Error 0.0000(0.0000) Steps 466(478.14) | Grad Norm 12.9389(32.9225) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 20.4980, Epoch Time 283.6346(354.1828), Bit/dim 8.2393(best: 8.5414), Xent 0.0000, Loss 8.2393, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0013 | Time 42.5303(85.9029) | Bit/dim 8.2344(9.0496) | Xent 0.0000(0.0000) | Loss 21.5695(19.9214) | Error 0.0000(0.0000) Steps 508(479.03) | Grad Norm 10.5657(32.2518) | Total Time 0.00(0.00)\n",
      "Iter 0014 | Time 37.7706(84.4589) | Bit/dim 8.1643(9.0230) | Xent 0.0000(0.0000) | Loss 17.9567(19.8624) | Error 0.0000(0.0000) Steps 472(478.82) | Grad Norm 8.1012(31.5273) | Total Time 0.00(0.00)\n",
      "Iter 0015 | Time 38.8797(83.0915) | Bit/dim 8.1298(8.9962) | Xent 0.0000(0.0000) | Loss 17.5200(19.7921) | Error 0.0000(0.0000) Steps 454(478.08) | Grad Norm 7.9121(30.8188) | Total Time 0.00(0.00)\n",
      "Iter 0016 | Time 37.0859(81.7114) | Bit/dim 8.0833(8.9689) | Xent 0.0000(0.0000) | Loss 17.0456(19.7097) | Error 0.0000(0.0000) Steps 460(477.54) | Grad Norm 9.4801(30.1787) | Total Time 0.00(0.00)\n",
      "Iter 0017 | Time 42.4677(80.5340) | Bit/dim 8.0247(8.9405) | Xent 0.0000(0.0000) | Loss 17.5105(19.6438) | Error 0.0000(0.0000) Steps 490(477.91) | Grad Norm 11.5368(29.6194) | Total Time 0.00(0.00)\n",
      "Iter 0018 | Time 44.3266(79.4478) | Bit/dim 7.9493(8.9108) | Xent 0.0000(0.0000) | Loss 17.8603(19.5903) | Error 0.0000(0.0000) Steps 532(479.53) | Grad Norm 12.0346(29.0919) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 20.9362, Epoch Time 283.5617(352.0642), Bit/dim 7.8483(best: 8.2393), Xent 0.0000, Loss 7.8483, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0019 | Time 37.4667(78.1884) | Bit/dim 7.8498(8.8790) | Xent 0.0000(0.0000) | Loss 20.3590(19.6133) | Error 0.0000(0.0000) Steps 460(478.95) | Grad Norm 10.6810(28.5396) | Total Time 0.00(0.00)\n",
      "Iter 0020 | Time 38.2969(76.9916) | Bit/dim 7.7439(8.8449) | Xent 0.0000(0.0000) | Loss 16.3327(19.5149) | Error 0.0000(0.0000) Steps 454(478.20) | Grad Norm 7.5739(27.9106) | Total Time 0.00(0.00)\n",
      "Iter 0021 | Time 42.7948(75.9657) | Bit/dim 7.6522(8.8091) | Xent 0.0000(0.0000) | Loss 16.8776(19.4358) | Error 0.0000(0.0000) Steps 514(479.27) | Grad Norm 5.7359(27.2453) | Total Time 0.00(0.00)\n",
      "Iter 0022 | Time 41.7953(74.9406) | Bit/dim 7.5711(8.7720) | Xent 0.0000(0.0000) | Loss 16.9040(19.3598) | Error 0.0000(0.0000) Steps 514(480.31) | Grad Norm 6.3382(26.6181) | Total Time 0.00(0.00)\n",
      "Iter 0023 | Time 37.6984(73.8234) | Bit/dim 7.5031(8.7339) | Xent 0.0000(0.0000) | Loss 16.4837(19.2736) | Error 0.0000(0.0000) Steps 466(479.88) | Grad Norm 8.0724(26.0618) | Total Time 0.00(0.00)\n",
      "Iter 0024 | Time 40.9157(72.8361) | Bit/dim 7.4334(8.6949) | Xent 0.0000(0.0000) | Loss 16.7445(19.1977) | Error 0.0000(0.0000) Steps 508(480.73) | Grad Norm 9.0727(25.5521) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 20.8270, Epoch Time 279.5341(349.8883), Bit/dim 7.3492(best: 7.8483), Xent 0.0000, Loss 7.3492, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0025 | Time 38.8451(71.8164) | Bit/dim 7.3495(8.6546) | Xent 0.0000(0.0000) | Loss 19.3493(19.2022) | Error 0.0000(0.0000) Steps 484(480.83) | Grad Norm 7.9289(25.0234) | Total Time 0.00(0.00)\n",
      "Iter 0026 | Time 41.1727(70.8971) | Bit/dim 7.2707(8.6130) | Xent 0.0000(0.0000) | Loss 15.9453(19.1045) | Error 0.0000(0.0000) Steps 466(480.38) | Grad Norm 5.8275(24.4475) | Total Time 0.00(0.00)\n",
      "Iter 0027 | Time 41.1663(70.0052) | Bit/dim 7.2128(8.5710) | Xent 0.0000(0.0000) | Loss 15.8376(19.0065) | Error 0.0000(0.0000) Steps 496(480.85) | Grad Norm 4.0562(23.8358) | Total Time 0.00(0.00)\n",
      "Iter 0028 | Time 41.9465(69.1634) | Bit/dim 7.1754(8.5292) | Xent 0.0000(0.0000) | Loss 15.8204(18.9109) | Error 0.0000(0.0000) Steps 490(481.12) | Grad Norm 4.8032(23.2648) | Total Time 0.00(0.00)\n",
      "Iter 0029 | Time 42.9303(68.3764) | Bit/dim 7.1393(8.4875) | Xent 0.0000(0.0000) | Loss 15.9393(18.8218) | Error 0.0000(0.0000) Steps 520(482.29) | Grad Norm 6.3247(22.7566) | Total Time 0.00(0.00)\n",
      "Iter 0030 | Time 38.7089(67.4864) | Bit/dim 7.1218(8.4465) | Xent 0.0000(0.0000) | Loss 15.4010(18.7192) | Error 0.0000(0.0000) Steps 472(481.98) | Grad Norm 6.4029(22.2660) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 21.4187, Epoch Time 285.3093(347.9509), Bit/dim 7.0867(best: 7.3492), Xent 0.0000, Loss 7.0867, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0031 | Time 40.2462(66.6692) | Bit/dim 7.0832(8.4056) | Xent 0.0000(0.0000) | Loss 18.6674(18.7176) | Error 0.0000(0.0000) Steps 502(482.58) | Grad Norm 5.0556(21.7497) | Total Time 0.00(0.00)\n",
      "Iter 0032 | Time 39.6619(65.8590) | Bit/dim 7.0561(8.3651) | Xent 0.0000(0.0000) | Loss 15.3229(18.6158) | Error 0.0000(0.0000) Steps 502(483.16) | Grad Norm 2.9019(21.1842) | Total Time 0.00(0.00)\n",
      "Iter 0033 | Time 43.7623(65.1961) | Bit/dim 7.0464(8.3255) | Xent 0.0000(0.0000) | Loss 15.7881(18.5309) | Error 0.0000(0.0000) Steps 514(484.09) | Grad Norm 3.5799(20.6561) | Total Time 0.00(0.00)\n",
      "Iter 0034 | Time 40.4344(64.4532) | Bit/dim 7.0488(8.2872) | Xent 0.0000(0.0000) | Loss 15.5106(18.4403) | Error 0.0000(0.0000) Steps 496(484.45) | Grad Norm 5.1763(20.1917) | Total Time 0.00(0.00)\n",
      "Iter 0035 | Time 41.3527(63.7602) | Bit/dim 7.0419(8.2499) | Xent 0.0000(0.0000) | Loss 15.5464(18.3535) | Error 0.0000(0.0000) Steps 502(484.97) | Grad Norm 4.8150(19.7304) | Total Time 0.00(0.00)\n",
      "Iter 0036 | Time 39.9801(63.0468) | Bit/dim 7.0312(8.2133) | Xent 0.0000(0.0000) | Loss 15.6078(18.2711) | Error 0.0000(0.0000) Steps 520(486.02) | Grad Norm 2.7937(19.2223) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 21.0381, Epoch Time 290.1402(346.2166), Bit/dim 7.0258(best: 7.0867), Xent 0.0000, Loss 7.0258, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0037 | Time 39.9430(62.3537) | Bit/dim 7.0142(8.1773) | Xent 0.0000(0.0000) | Loss 18.0387(18.2642) | Error 0.0000(0.0000) Steps 460(485.24) | Grad Norm 2.3214(18.7153) | Total Time 0.00(0.00)\n",
      "Iter 0038 | Time 42.5033(61.7582) | Bit/dim 7.0282(8.1429) | Xent 0.0000(0.0000) | Loss 15.5976(18.1842) | Error 0.0000(0.0000) Steps 538(486.83) | Grad Norm 4.5044(18.2890) | Total Time 0.00(0.00)\n",
      "Iter 0039 | Time 45.7578(61.2782) | Bit/dim 7.0248(8.1093) | Xent 0.0000(0.0000) | Loss 15.6290(18.1075) | Error 0.0000(0.0000) Steps 514(487.64) | Grad Norm 4.7765(17.8836) | Total Time 0.00(0.00)\n",
      "Iter 0040 | Time 45.5562(60.8065) | Bit/dim 7.0178(8.0766) | Xent 0.0000(0.0000) | Loss 15.8002(18.0383) | Error 0.0000(0.0000) Steps 526(488.79) | Grad Norm 2.8286(17.4319) | Total Time 0.00(0.00)\n",
      "Iter 0041 | Time 41.9351(60.2404) | Bit/dim 7.0040(8.0444) | Xent 0.0000(0.0000) | Loss 15.2371(17.9543) | Error 0.0000(0.0000) Steps 490(488.83) | Grad Norm 2.2557(16.9766) | Total Time 0.00(0.00)\n",
      "Iter 0042 | Time 43.0364(59.7242) | Bit/dim 7.0105(8.0134) | Xent 0.0000(0.0000) | Loss 15.3334(17.8756) | Error 0.0000(0.0000) Steps 514(489.58) | Grad Norm 3.3428(16.5676) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 20.5401, Epoch Time 298.5373(344.7862), Bit/dim 7.0029(best: 7.0258), Xent 0.0000, Loss 7.0029, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0043 | Time 43.6350(59.2416) | Bit/dim 7.0043(7.9831) | Xent 0.0000(0.0000) | Loss 18.0669(17.8814) | Error 0.0000(0.0000) Steps 514(490.32) | Grad Norm 3.1245(16.1643) | Total Time 0.00(0.00)\n",
      "Iter 0044 | Time 49.5003(58.9493) | Bit/dim 6.9861(7.9532) | Xent 0.0000(0.0000) | Loss 15.5815(17.8124) | Error 0.0000(0.0000) Steps 526(491.39) | Grad Norm 2.0052(15.7396) | Total Time 0.00(0.00)\n",
      "Iter 0045 | Time 44.5438(58.5172) | Bit/dim 6.9757(7.9239) | Xent 0.0000(0.0000) | Loss 15.5736(17.7452) | Error 0.0000(0.0000) Steps 526(492.43) | Grad Norm 2.3036(15.3365) | Total Time 0.00(0.00)\n",
      "Iter 0046 | Time 47.4281(58.1845) | Bit/dim 6.9853(7.8957) | Xent 0.0000(0.0000) | Loss 15.5495(17.6793) | Error 0.0000(0.0000) Steps 532(493.61) | Grad Norm 2.8800(14.9628) | Total Time 0.00(0.00)\n",
      "Iter 0047 | Time 49.8771(57.9353) | Bit/dim 6.9766(7.8682) | Xent 0.0000(0.0000) | Loss 15.7310(17.6209) | Error 0.0000(0.0000) Steps 538(494.94) | Grad Norm 2.5272(14.5897) | Total Time 0.00(0.00)\n",
      "Iter 0048 | Time 51.1075(57.7304) | Bit/dim 6.9490(7.8406) | Xent 0.0000(0.0000) | Loss 15.5838(17.5598) | Error 0.0000(0.0000) Steps 550(496.60) | Grad Norm 1.8625(14.2079) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 22.2592, Epoch Time 327.7465(344.2750), Bit/dim 6.9478(best: 7.0029), Xent 0.0000, Loss 6.9478, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0049 | Time 54.4350(57.6316) | Bit/dim 6.9443(7.8137) | Xent 0.0000(0.0000) | Loss 18.4606(17.5868) | Error 0.0000(0.0000) Steps 556(498.38) | Grad Norm 1.7753(13.8349) | Total Time 0.00(0.00)\n",
      "Iter 0050 | Time 44.5549(57.2393) | Bit/dim 6.9343(7.7873) | Xent 0.0000(0.0000) | Loss 15.4162(17.5217) | Error 0.0000(0.0000) Steps 508(498.67) | Grad Norm 2.1606(13.4847) | Total Time 0.00(0.00)\n",
      "Iter 0051 | Time 46.9869(56.9317) | Bit/dim 6.9273(7.7615) | Xent 0.0000(0.0000) | Loss 15.4251(17.4588) | Error 0.0000(0.0000) Steps 520(499.31) | Grad Norm 2.1827(13.1456) | Total Time 0.00(0.00)\n",
      "Iter 0052 | Time 44.7187(56.5653) | Bit/dim 6.9067(7.7359) | Xent 0.0000(0.0000) | Loss 15.3332(17.3950) | Error 0.0000(0.0000) Steps 502(499.39) | Grad Norm 1.6220(12.7999) | Total Time 0.00(0.00)\n",
      "Iter 0053 | Time 45.2737(56.2266) | Bit/dim 6.8847(7.7103) | Xent 0.0000(0.0000) | Loss 15.5189(17.3387) | Error 0.0000(0.0000) Steps 538(500.55) | Grad Norm 1.8354(12.4710) | Total Time 0.00(0.00)\n",
      "Iter 0054 | Time 46.6161(55.9382) | Bit/dim 6.8594(7.6848) | Xent 0.0000(0.0000) | Loss 15.0864(17.2712) | Error 0.0000(0.0000) Steps 520(501.13) | Grad Norm 2.0813(12.1593) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 22.6790, Epoch Time 323.9767(343.6661), Bit/dim 6.8499(best: 6.9478), Xent 0.0000, Loss 6.8499, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0055 | Time 47.4403(55.6833) | Bit/dim 6.8461(7.6596) | Xent 0.0000(0.0000) | Loss 18.3348(17.3031) | Error 0.0000(0.0000) Steps 520(501.70) | Grad Norm 1.6428(11.8438) | Total Time 0.00(0.00)\n",
      "Iter 0056 | Time 47.4656(55.4368) | Bit/dim 6.8201(7.6345) | Xent 0.0000(0.0000) | Loss 15.3230(17.2437) | Error 0.0000(0.0000) Steps 538(502.78) | Grad Norm 1.7719(11.5416) | Total Time 0.00(0.00)\n",
      "Iter 0057 | Time 45.6836(55.1442) | Bit/dim 6.7986(7.6094) | Xent 0.0000(0.0000) | Loss 15.2259(17.1831) | Error 0.0000(0.0000) Steps 520(503.30) | Grad Norm 2.5784(11.2727) | Total Time 0.00(0.00)\n",
      "Iter 0058 | Time 42.8424(54.7751) | Bit/dim 6.7756(7.5844) | Xent 0.0000(0.0000) | Loss 14.7609(17.1105) | Error 0.0000(0.0000) Steps 502(503.26) | Grad Norm 3.4590(11.0383) | Total Time 0.00(0.00)\n",
      "Iter 0059 | Time 46.2270(54.5187) | Bit/dim 6.7421(7.5591) | Xent 0.0000(0.0000) | Loss 15.0281(17.0480) | Error 0.0000(0.0000) Steps 520(503.76) | Grad Norm 7.1328(10.9212) | Total Time 0.00(0.00)\n",
      "Iter 0060 | Time 55.1607(54.5379) | Bit/dim 6.7454(7.5347) | Xent 0.0000(0.0000) | Loss 15.3500(16.9971) | Error 0.0000(0.0000) Steps 568(505.69) | Grad Norm 17.3456(11.1139) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 22.2796, Epoch Time 326.1230(343.1398), Bit/dim 6.8038(best: 6.8499), Xent 0.0000, Loss 6.8038, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0061 | Time 45.4455(54.2652) | Bit/dim 6.7974(7.5126) | Xent 0.0000(0.0000) | Loss 18.2345(17.0342) | Error 0.0000(0.0000) Steps 526(506.30) | Grad Norm 36.2786(11.8688) | Total Time 0.00(0.00)\n",
      "Iter 0062 | Time 45.2416(53.9945) | Bit/dim 6.6454(7.4865) | Xent 0.0000(0.0000) | Loss 14.7278(16.9650) | Error 0.0000(0.0000) Steps 532(507.07) | Grad Norm 5.4429(11.6761) | Total Time 0.00(0.00)\n",
      "Iter 0063 | Time 45.1820(53.7301) | Bit/dim 6.7974(7.4659) | Xent 0.0000(0.0000) | Loss 15.3943(16.9179) | Error 0.0000(0.0000) Steps 532(507.82) | Grad Norm 49.2008(12.8018) | Total Time 0.00(0.00)\n",
      "Iter 0064 | Time 45.4577(53.4819) | Bit/dim 6.5925(7.4397) | Xent 0.0000(0.0000) | Loss 14.7548(16.8530) | Error 0.0000(0.0000) Steps 496(507.46) | Grad Norm 15.5774(12.8851) | Total Time 0.00(0.00)\n",
      "Iter 0065 | Time 46.9593(53.2862) | Bit/dim 6.9563(7.4252) | Xent 0.0000(0.0000) | Loss 15.4008(16.8094) | Error 0.0000(0.0000) Steps 514(507.66) | Grad Norm 72.6451(14.6779) | Total Time 0.00(0.00)\n",
      "Iter 0066 | Time 44.4183(53.0202) | Bit/dim 6.9518(7.4110) | Xent 0.0000(0.0000) | Loss 15.5794(16.7725) | Error 0.0000(0.0000) Steps 514(507.85) | Grad Norm 75.9395(16.5157) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 21.3498, Epoch Time 313.4931(342.2504), Bit/dim 6.4761(best: 6.8038), Xent 0.0000, Loss 6.4761, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0067 | Time 43.1558(52.7243) | Bit/dim 6.4728(7.3828) | Xent 0.0000(0.0000) | Loss 17.6781(16.7997) | Error 0.0000(0.0000) Steps 514(508.04) | Grad Norm 8.4645(16.2742) | Total Time 0.00(0.00)\n",
      "Iter 0068 | Time 42.4779(52.4169) | Bit/dim 6.9621(7.3702) | Xent 0.0000(0.0000) | Loss 15.3538(16.7563) | Error 0.0000(0.0000) Steps 502(507.85) | Grad Norm 85.2074(18.3422) | Total Time 0.00(0.00)\n",
      "Iter 0069 | Time 42.4920(52.1191) | Bit/dim 7.0442(7.3604) | Xent 0.0000(0.0000) | Loss 15.4652(16.7176) | Error 0.0000(0.0000) Steps 478(506.96) | Grad Norm 92.9371(20.5800) | Total Time 0.00(0.00)\n",
      "Iter 0070 | Time 44.6275(51.8944) | Bit/dim 6.4368(7.3327) | Xent 0.0000(0.0000) | Loss 14.4035(16.6481) | Error 0.0000(0.0000) Steps 496(506.63) | Grad Norm 27.6246(20.7914) | Total Time 0.00(0.00)\n",
      "Iter 0071 | Time 43.8009(51.6516) | Bit/dim 6.7641(7.3157) | Xent 0.0000(0.0000) | Loss 14.8531(16.5943) | Error 0.0000(0.0000) Steps 490(506.13) | Grad Norm 61.3288(22.0075) | Total Time 0.00(0.00)\n",
      "Iter 0072 | Time 43.0445(51.3934) | Bit/dim 7.1147(7.3096) | Xent 0.0000(0.0000) | Loss 15.7165(16.5680) | Error 0.0000(0.0000) Steps 508(506.19) | Grad Norm 83.0944(23.8401) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 22.6009, Epoch Time 300.4068(340.9951), Bit/dim 6.6557(best: 6.4761), Xent 0.0000, Loss 6.6557, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0073 | Time 44.6440(51.1909) | Bit/dim 6.6496(7.2898) | Xent 0.0000(0.0000) | Loss 17.9076(16.6081) | Error 0.0000(0.0000) Steps 508(506.24) | Grad Norm 52.2081(24.6911) | Total Time 0.00(0.00)\n",
      "Iter 0074 | Time 43.5359(50.9612) | Bit/dim 6.2432(7.2584) | Xent 0.0000(0.0000) | Loss 14.0691(16.5320) | Error 0.0000(0.0000) Steps 532(507.01) | Grad Norm 5.5257(24.1162) | Total Time 0.00(0.00)\n",
      "Iter 0075 | Time 43.6093(50.7407) | Bit/dim 6.4853(7.2352) | Xent 0.0000(0.0000) | Loss 14.4444(16.4693) | Error 0.0000(0.0000) Steps 508(507.04) | Grad Norm 43.0121(24.6830) | Total Time 0.00(0.00)\n",
      "Iter 0076 | Time 43.9248(50.5362) | Bit/dim 6.4450(7.2115) | Xent 0.0000(0.0000) | Loss 14.4394(16.4085) | Error 0.0000(0.0000) Steps 508(507.07) | Grad Norm 39.5805(25.1300) | Total Time 0.00(0.00)\n",
      "Iter 0077 | Time 44.0263(50.3409) | Bit/dim 6.1981(7.1811) | Xent 0.0000(0.0000) | Loss 13.7459(16.3286) | Error 0.0000(0.0000) Steps 496(506.74) | Grad Norm 10.5759(24.6933) | Total Time 0.00(0.00)\n",
      "Iter 0078 | Time 43.9948(50.1505) | Bit/dim 6.2168(7.1522) | Xent 0.0000(0.0000) | Loss 13.7976(16.2526) | Error 0.0000(0.0000) Steps 526(507.32) | Grad Norm 21.2855(24.5911) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 21.7944, Epoch Time 304.9761(339.9145), Bit/dim 6.1644(best: 6.4761), Xent 0.0000, Loss 6.1644, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0079 | Time 40.3987(49.8580) | Bit/dim 6.1643(7.1226) | Xent 0.0000(0.0000) | Loss 16.5320(16.2610) | Error 0.0000(0.0000) Steps 484(506.62) | Grad Norm 17.4406(24.3766) | Total Time 0.00(0.00)\n",
      "Iter 0080 | Time 44.5495(49.6987) | Bit/dim 6.0562(7.0906) | Xent 0.0000(0.0000) | Loss 13.3776(16.1745) | Error 0.0000(0.0000) Steps 508(506.66) | Grad Norm 9.8772(23.9416) | Total Time 0.00(0.00)\n",
      "Iter 0081 | Time 46.2080(49.5940) | Bit/dim 6.0557(7.0595) | Xent 0.0000(0.0000) | Loss 13.6913(16.1000) | Error 0.0000(0.0000) Steps 520(507.06) | Grad Norm 15.1672(23.6784) | Total Time 0.00(0.00)\n",
      "Iter 0082 | Time 45.4491(49.4696) | Bit/dim 5.9907(7.0275) | Xent 0.0000(0.0000) | Loss 13.4521(16.0206) | Error 0.0000(0.0000) Steps 538(507.99) | Grad Norm 10.8110(23.2924) | Total Time 0.00(0.00)\n",
      "Iter 0083 | Time 45.6855(49.3561) | Bit/dim 5.9555(6.9953) | Xent 0.0000(0.0000) | Loss 13.5335(15.9460) | Error 0.0000(0.0000) Steps 520(508.35) | Grad Norm 8.3339(22.8436) | Total Time 0.00(0.00)\n",
      "Iter 0084 | Time 45.6386(49.2446) | Bit/dim 5.9734(6.9646) | Xent 0.0000(0.0000) | Loss 13.5582(15.8743) | Error 0.0000(0.0000) Steps 532(509.06) | Grad Norm 12.5860(22.5359) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 22.5395, Epoch Time 309.1062(338.9903), Bit/dim 5.9013(best: 6.1644), Xent 0.0000, Loss 5.9013, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0085 | Time 43.1200(49.0608) | Bit/dim 5.9136(6.9331) | Xent 0.0000(0.0000) | Loss 16.3100(15.8874) | Error 0.0000(0.0000) Steps 502(508.85) | Grad Norm 7.5285(22.0857) | Total Time 0.00(0.00)\n",
      "Iter 0086 | Time 40.4633(48.8029) | Bit/dim 5.8327(6.9001) | Xent 0.0000(0.0000) | Loss 12.7965(15.7947) | Error 0.0000(0.0000) Steps 484(508.10) | Grad Norm 7.1535(21.6377) | Total Time 0.00(0.00)\n",
      "Iter 0087 | Time 44.6815(48.6793) | Bit/dim 5.7914(6.8668) | Xent 0.0000(0.0000) | Loss 12.8757(15.7071) | Error 0.0000(0.0000) Steps 526(508.64) | Grad Norm 4.7540(21.1312) | Total Time 0.00(0.00)\n",
      "Iter 0088 | Time 43.2341(48.5159) | Bit/dim 5.7843(6.8344) | Xent 0.0000(0.0000) | Loss 12.7966(15.6198) | Error 0.0000(0.0000) Steps 508(508.62) | Grad Norm 5.6542(20.6669) | Total Time 0.00(0.00)\n",
      "Iter 0089 | Time 42.4313(48.3334) | Bit/dim 5.7563(6.8020) | Xent 0.0000(0.0000) | Loss 12.7869(15.5348) | Error 0.0000(0.0000) Steps 496(508.24) | Grad Norm 5.3697(20.2080) | Total Time 0.00(0.00)\n",
      "Iter 0090 | Time 44.0542(48.2050) | Bit/dim 5.7209(6.7696) | Xent 0.0000(0.0000) | Loss 12.9065(15.4560) | Error 0.0000(0.0000) Steps 496(507.87) | Grad Norm 3.7566(19.7144) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 21.3462, Epoch Time 297.8463(337.7560), Bit/dim 5.7105(best: 5.9013), Xent 0.0000, Loss 5.7105, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0091 | Time 44.3849(48.0904) | Bit/dim 5.7141(6.7379) | Xent 0.0000(0.0000) | Loss 15.7467(15.4647) | Error 0.0000(0.0000) Steps 514(508.06) | Grad Norm 5.9034(19.3001) | Total Time 0.00(0.00)\n",
      "Iter 0092 | Time 45.0315(47.9986) | Bit/dim 5.6838(6.7063) | Xent 0.0000(0.0000) | Loss 12.9096(15.3880) | Error 0.0000(0.0000) Steps 514(508.24) | Grad Norm 3.9123(18.8385) | Total Time 0.00(0.00)\n",
      "Iter 0093 | Time 40.9666(47.7877) | Bit/dim 5.6687(6.6752) | Xent 0.0000(0.0000) | Loss 12.7394(15.3086) | Error 0.0000(0.0000) Steps 508(508.23) | Grad Norm 4.9329(18.4213) | Total Time 0.00(0.00)\n",
      "Iter 0094 | Time 41.9156(47.6115) | Bit/dim 5.6591(6.6447) | Xent 0.0000(0.0000) | Loss 12.8187(15.2339) | Error 0.0000(0.0000) Steps 508(508.22) | Grad Norm 4.6779(18.0090) | Total Time 0.00(0.00)\n",
      "Iter 0095 | Time 38.1318(47.3271) | Bit/dim 5.6238(6.6141) | Xent 0.0000(0.0000) | Loss 12.4820(15.1513) | Error 0.0000(0.0000) Steps 454(506.59) | Grad Norm 3.6725(17.5789) | Total Time 0.00(0.00)\n",
      "Iter 0096 | Time 44.8902(47.2540) | Bit/dim 5.6004(6.5836) | Xent 0.0000(0.0000) | Loss 12.6639(15.0767) | Error 0.0000(0.0000) Steps 520(507.00) | Grad Norm 2.5658(17.1285) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 20.9293, Epoch Time 295.2403(336.4805), Bit/dim 5.6026(best: 5.7105), Xent 0.0000, Loss 5.6026, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0097 | Time 41.8695(47.0925) | Bit/dim 5.5919(6.5539) | Xent 0.0000(0.0000) | Loss 15.0752(15.0767) | Error 0.0000(0.0000) Steps 472(505.95) | Grad Norm 3.3100(16.7139) | Total Time 0.00(0.00)\n",
      "Iter 0098 | Time 43.1443(46.9740) | Bit/dim 5.5862(6.5249) | Xent 0.0000(0.0000) | Loss 12.3698(14.9954) | Error 0.0000(0.0000) Steps 502(505.83) | Grad Norm 3.9526(16.3311) | Total Time 0.00(0.00)\n",
      "Iter 0099 | Time 44.9841(46.9143) | Bit/dim 5.5572(6.4958) | Xent 0.0000(0.0000) | Loss 12.7902(14.9293) | Error 0.0000(0.0000) Steps 532(506.61) | Grad Norm 2.4534(15.9148) | Total Time 0.00(0.00)\n",
      "Iter 0100 | Time 41.1359(46.7410) | Bit/dim 5.5310(6.4669) | Xent 0.0000(0.0000) | Loss 12.3699(14.8525) | Error 0.0000(0.0000) Steps 466(505.40) | Grad Norm 2.8418(15.5226) | Total Time 0.00(0.00)\n",
      "Iter 0101 | Time 42.5177(46.6143) | Bit/dim 5.5272(6.4387) | Xent 0.0000(0.0000) | Loss 12.5105(14.7822) | Error 0.0000(0.0000) Steps 514(505.65) | Grad Norm 3.0696(15.1490) | Total Time 0.00(0.00)\n",
      "Iter 0102 | Time 44.1227(46.5395) | Bit/dim 5.4890(6.4102) | Xent 0.0000(0.0000) | Loss 12.3828(14.7103) | Error 0.0000(0.0000) Steps 508(505.72) | Grad Norm 2.2884(14.7632) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 20.8065, Epoch Time 297.9749(335.3253), Bit/dim 5.4676(best: 5.6026), Xent 0.0000, Loss 5.4676, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0103 | Time 40.0967(46.3463) | Bit/dim 5.4802(6.3823) | Xent 0.0000(0.0000) | Loss 15.3839(14.7305) | Error 0.0000(0.0000) Steps 490(505.25) | Grad Norm 2.0678(14.3823) | Total Time 0.00(0.00)\n",
      "Iter 0104 | Time 40.3209(46.1655) | Bit/dim 5.4370(6.3540) | Xent 0.0000(0.0000) | Loss 11.9462(14.6469) | Error 0.0000(0.0000) Steps 490(504.79) | Grad Norm 2.4710(14.0250) | Total Time 0.00(0.00)\n",
      "Iter 0105 | Time 40.5609(45.9974) | Bit/dim 5.4326(6.3263) | Xent 0.0000(0.0000) | Loss 12.3363(14.5776) | Error 0.0000(0.0000) Steps 490(504.35) | Grad Norm 2.5292(13.6801) | Total Time 0.00(0.00)\n",
      "Iter 0106 | Time 44.4673(45.9515) | Bit/dim 5.3834(6.2980) | Xent 0.0000(0.0000) | Loss 12.2856(14.5089) | Error 0.0000(0.0000) Steps 538(505.36) | Grad Norm 2.1395(13.3339) | Total Time 0.00(0.00)\n",
      "Iter 0107 | Time 45.2198(45.9295) | Bit/dim 5.3662(6.2701) | Xent 0.0000(0.0000) | Loss 12.0375(14.4347) | Error 0.0000(0.0000) Steps 490(504.90) | Grad Norm 5.7990(13.1078) | Total Time 0.00(0.00)\n",
      "Iter 0108 | Time 44.7653(45.8946) | Bit/dim 5.3699(6.2431) | Xent 0.0000(0.0000) | Loss 12.0573(14.3634) | Error 0.0000(0.0000) Steps 502(504.81) | Grad Norm 19.8342(13.3096) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 21.7172, Epoch Time 295.3908(334.1273), Bit/dim 5.7101(best: 5.4676), Xent 0.0000, Loss 5.7101, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0109 | Time 45.0260(45.8685) | Bit/dim 5.7188(6.2273) | Xent 0.0000(0.0000) | Loss 16.2139(14.4189) | Error 0.0000(0.0000) Steps 508(504.91) | Grad Norm 96.9051(15.8175) | Total Time 0.00(0.00)\n",
      "Iter 0110 | Time 43.2084(45.7887) | Bit/dim 5.3940(6.2023) | Xent 0.0000(0.0000) | Loss 12.2622(14.3542) | Error 0.0000(0.0000) Steps 496(504.64) | Grad Norm 33.8794(16.3594) | Total Time 0.00(0.00)\n",
      "Iter 0111 | Time 41.9837(45.6746) | Bit/dim 5.6670(6.1863) | Xent 0.0000(0.0000) | Loss 12.7305(14.3055) | Error 0.0000(0.0000) Steps 502(504.56) | Grad Norm 45.3983(17.2305) | Total Time 0.00(0.00)\n",
      "Iter 0112 | Time 40.0804(45.5067) | Bit/dim 5.6844(6.1712) | Xent 0.0000(0.0000) | Loss 12.2261(14.2431) | Error 0.0000(0.0000) Steps 466(503.40) | Grad Norm 37.0144(17.8240) | Total Time 0.00(0.00)\n",
      "Iter 0113 | Time 42.5191(45.4171) | Bit/dim 5.3498(6.1466) | Xent 0.0000(0.0000) | Loss 11.9418(14.1741) | Error 0.0000(0.0000) Steps 496(503.18) | Grad Norm 15.0869(17.7419) | Total Time 0.00(0.00)\n",
      "Iter 0114 | Time 44.8940(45.4014) | Bit/dim 5.7424(6.1345) | Xent 0.0000(0.0000) | Loss 12.7255(14.1306) | Error 0.0000(0.0000) Steps 502(503.15) | Grad Norm 65.2693(19.1677) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 21.7870, Epoch Time 298.1999(333.0495), Bit/dim 5.6591(best: 5.4676), Xent 0.0000, Loss 5.6591, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0115 | Time 44.6499(45.3789) | Bit/dim 5.6623(6.1203) | Xent 0.0000(0.0000) | Loss 15.6681(14.1767) | Error 0.0000(0.0000) Steps 490(502.75) | Grad Norm 48.9115(20.0601) | Total Time 0.00(0.00)\n",
      "Iter 0116 | Time 41.3082(45.2568) | Bit/dim 5.3773(6.0980) | Xent 0.0000(0.0000) | Loss 12.3129(14.1208) | Error 0.0000(0.0000) Steps 502(502.73) | Grad Norm 9.9172(19.7558) | Total Time 0.00(0.00)\n",
      "Iter 0117 | Time 43.3374(45.1992) | Bit/dim 5.4016(6.0771) | Xent 0.0000(0.0000) | Loss 11.6643(14.0471) | Error 0.0000(0.0000) Steps 478(501.99) | Grad Norm 8.5929(19.4209) | Total Time 0.00(0.00)\n",
      "Iter 0118 | Time 43.3326(45.1432) | Bit/dim 5.4219(6.0575) | Xent 0.0000(0.0000) | Loss 12.2592(13.9935) | Error 0.0000(0.0000) Steps 496(501.81) | Grad Norm 9.6682(19.1283) | Total Time 0.00(0.00)\n",
      "Iter 0119 | Time 43.1723(45.0840) | Bit/dim 5.3439(6.0360) | Xent 0.0000(0.0000) | Loss 11.9363(13.9318) | Error 0.0000(0.0000) Steps 490(501.45) | Grad Norm 6.8957(18.7613) | Total Time 0.00(0.00)\n",
      "Iter 0120 | Time 42.6423(45.0108) | Bit/dim 5.3286(6.0148) | Xent 0.0000(0.0000) | Loss 12.0680(13.8759) | Error 0.0000(0.0000) Steps 520(502.01) | Grad Norm 7.4058(18.4207) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 22.1252, Epoch Time 305.4771(332.2223), Bit/dim 5.3114(best: 5.4676), Xent 0.0000, Loss 5.3114, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0121 | Time 46.7571(45.0632) | Bit/dim 5.3340(5.9944) | Xent 0.0000(0.0000) | Loss 15.2575(13.9173) | Error 0.0000(0.0000) Steps 520(502.55) | Grad Norm 9.7656(18.1610) | Total Time 0.00(0.00)\n",
      "Iter 0122 | Time 44.8312(45.0562) | Bit/dim 5.2653(5.9725) | Xent 0.0000(0.0000) | Loss 11.9856(13.8594) | Error 0.0000(0.0000) Steps 496(502.35) | Grad Norm 6.6303(17.8151) | Total Time 0.00(0.00)\n",
      "Iter 0123 | Time 42.9722(44.9937) | Bit/dim 5.2359(5.9504) | Xent 0.0000(0.0000) | Loss 11.4984(13.7885) | Error 0.0000(0.0000) Steps 478(501.62) | Grad Norm 6.2869(17.4692) | Total Time 0.00(0.00)\n",
      "Iter 0124 | Time 38.8982(44.8108) | Bit/dim 5.2246(5.9287) | Xent 0.0000(0.0000) | Loss 11.6711(13.7250) | Error 0.0000(0.0000) Steps 460(500.37) | Grad Norm 6.4915(17.1399) | Total Time 0.00(0.00)\n",
      "Iter 0125 | Time 42.9694(44.7556) | Bit/dim 5.2143(5.9072) | Xent 0.0000(0.0000) | Loss 11.9238(13.6710) | Error 0.0000(0.0000) Steps 496(500.24) | Grad Norm 7.5960(16.8536) | Total Time 0.00(0.00)\n",
      "Iter 0126 | Time 43.3453(44.7133) | Bit/dim 5.1708(5.8851) | Xent 0.0000(0.0000) | Loss 11.5547(13.6075) | Error 0.0000(0.0000) Steps 496(500.12) | Grad Norm 4.3236(16.4777) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 21.0456, Epoch Time 299.6107(331.2439), Bit/dim 5.1599(best: 5.3114), Xent 0.0000, Loss 5.1599, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0127 | Time 44.8465(44.7173) | Bit/dim 5.1645(5.8635) | Xent 0.0000(0.0000) | Loss 14.5412(13.6355) | Error 0.0000(0.0000) Steps 502(500.17) | Grad Norm 6.0267(16.1642) | Total Time 0.00(0.00)\n",
      "Iter 0128 | Time 42.0025(44.6358) | Bit/dim 5.1622(5.8425) | Xent 0.0000(0.0000) | Loss 11.6519(13.5760) | Error 0.0000(0.0000) Steps 478(499.51) | Grad Norm 7.5575(15.9060) | Total Time 0.00(0.00)\n",
      "Iter 0129 | Time 43.2539(44.5944) | Bit/dim 5.1243(5.8209) | Xent 0.0000(0.0000) | Loss 11.6948(13.5196) | Error 0.0000(0.0000) Steps 496(499.40) | Grad Norm 3.9086(15.5460) | Total Time 0.00(0.00)\n",
      "Iter 0130 | Time 47.1928(44.6723) | Bit/dim 5.1111(5.7996) | Xent 0.0000(0.0000) | Loss 11.6435(13.4633) | Error 0.0000(0.0000) Steps 526(500.20) | Grad Norm 4.2579(15.2074) | Total Time 0.00(0.00)\n",
      "Iter 0131 | Time 43.7075(44.6434) | Bit/dim 5.0963(5.7785) | Xent 0.0000(0.0000) | Loss 11.4538(13.4030) | Error 0.0000(0.0000) Steps 496(500.07) | Grad Norm 5.0325(14.9021) | Total Time 0.00(0.00)\n",
      "Iter 0132 | Time 44.4410(44.6373) | Bit/dim 5.0903(5.7579) | Xent 0.0000(0.0000) | Loss 11.6398(13.3501) | Error 0.0000(0.0000) Steps 514(500.49) | Grad Norm 4.2561(14.5828) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 21.5888, Epoch Time 305.8330(330.4816), Bit/dim 5.0612(best: 5.1599), Xent 0.0000, Loss 5.0612, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0133 | Time 44.6327(44.6372) | Bit/dim 5.0479(5.7366) | Xent 0.0000(0.0000) | Loss 14.6574(13.3893) | Error 0.0000(0.0000) Steps 514(500.90) | Grad Norm 3.3774(14.2466) | Total Time 0.00(0.00)\n",
      "Iter 0134 | Time 44.6944(44.6389) | Bit/dim 5.0433(5.7158) | Xent 0.0000(0.0000) | Loss 11.6059(13.3358) | Error 0.0000(0.0000) Steps 502(500.93) | Grad Norm 3.6403(13.9284) | Total Time 0.00(0.00)\n",
      "Iter 0135 | Time 50.0982(44.8027) | Bit/dim 5.0455(5.6957) | Xent 0.0000(0.0000) | Loss 11.3075(13.2750) | Error 0.0000(0.0000) Steps 502(500.96) | Grad Norm 4.0229(13.6313) | Total Time 0.00(0.00)\n",
      "Iter 0136 | Time 44.9345(44.8066) | Bit/dim 5.0282(5.6756) | Xent 0.0000(0.0000) | Loss 11.2933(13.2155) | Error 0.0000(0.0000) Steps 490(500.63) | Grad Norm 3.5911(13.3300) | Total Time 0.00(0.00)\n",
      "Iter 0137 | Time 47.1024(44.8755) | Bit/dim 5.0160(5.6559) | Xent 0.0000(0.0000) | Loss 11.2350(13.1561) | Error 0.0000(0.0000) Steps 502(500.67) | Grad Norm 3.9115(13.0475) | Total Time 0.00(0.00)\n",
      "Iter 0138 | Time 45.3918(44.8910) | Bit/dim 4.9829(5.6357) | Xent 0.0000(0.0000) | Loss 11.4218(13.1041) | Error 0.0000(0.0000) Steps 508(500.89) | Grad Norm 3.9343(12.7741) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 21.5148, Epoch Time 316.8423(330.0724), Bit/dim 4.9728(best: 5.0612), Xent 0.0000, Loss 4.9728, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0139 | Time 44.2467(44.8717) | Bit/dim 4.9703(5.6157) | Xent 0.0000(0.0000) | Loss 14.2948(13.1398) | Error 0.0000(0.0000) Steps 496(500.75) | Grad Norm 2.7739(12.4741) | Total Time 0.00(0.00)\n",
      "Iter 0140 | Time 43.2029(44.8216) | Bit/dim 4.9626(5.5961) | Xent 0.0000(0.0000) | Loss 11.1660(13.0806) | Error 0.0000(0.0000) Steps 472(499.88) | Grad Norm 3.2692(12.1979) | Total Time 0.00(0.00)\n",
      "Iter 0141 | Time 46.8041(44.8811) | Bit/dim 4.9575(5.5770) | Xent 0.0000(0.0000) | Loss 11.1390(13.0223) | Error 0.0000(0.0000) Steps 490(499.59) | Grad Norm 3.0570(11.9237) | Total Time 0.00(0.00)\n",
      "Iter 0142 | Time 45.9276(44.9125) | Bit/dim 4.9319(5.5576) | Xent 0.0000(0.0000) | Loss 11.3034(12.9708) | Error 0.0000(0.0000) Steps 514(500.02) | Grad Norm 3.5246(11.6717) | Total Time 0.00(0.00)\n",
      "Iter 0143 | Time 44.1037(44.8882) | Bit/dim 4.9197(5.5385) | Xent 0.0000(0.0000) | Loss 11.1374(12.9158) | Error 0.0000(0.0000) Steps 490(499.72) | Grad Norm 4.5995(11.4596) | Total Time 0.00(0.00)\n",
      "Iter 0144 | Time 42.9712(44.8307) | Bit/dim 4.9371(5.5204) | Xent 0.0000(0.0000) | Loss 11.3495(12.8688) | Error 0.0000(0.0000) Steps 496(499.61) | Grad Norm 10.0335(11.4168) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 20.7968, Epoch Time 306.9699(329.3794), Bit/dim 5.0016(best: 4.9728), Xent 0.0000, Loss 5.0016, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0145 | Time 43.3553(44.7864) | Bit/dim 5.0045(5.5050) | Xent 0.0000(0.0000) | Loss 14.2089(12.9090) | Error 0.0000(0.0000) Steps 466(498.60) | Grad Norm 21.4163(11.7168) | Total Time 0.00(0.00)\n",
      "Iter 0146 | Time 46.7615(44.8457) | Bit/dim 4.9891(5.4895) | Xent 0.0000(0.0000) | Loss 11.1901(12.8574) | Error 0.0000(0.0000) Steps 508(498.88) | Grad Norm 29.0102(12.2356) | Total Time 0.00(0.00)\n",
      "Iter 0147 | Time 39.9737(44.6995) | Bit/dim 4.9295(5.4727) | Xent 0.0000(0.0000) | Loss 10.9129(12.7991) | Error 0.0000(0.0000) Steps 472(498.08) | Grad Norm 11.7609(12.2213) | Total Time 0.00(0.00)\n",
      "Iter 0148 | Time 41.9912(44.6183) | Bit/dim 4.8926(5.4553) | Xent 0.0000(0.0000) | Loss 11.2087(12.7514) | Error 0.0000(0.0000) Steps 484(497.65) | Grad Norm 7.1134(12.0681) | Total Time 0.00(0.00)\n",
      "Iter 0149 | Time 40.7666(44.5027) | Bit/dim 4.9618(5.4405) | Xent 0.0000(0.0000) | Loss 11.1577(12.7036) | Error 0.0000(0.0000) Steps 472(496.88) | Grad Norm 24.5254(12.4418) | Total Time 0.00(0.00)\n",
      "Iter 0150 | Time 46.3896(44.5593) | Bit/dim 4.9078(5.4245) | Xent 0.0000(0.0000) | Loss 11.0858(12.6550) | Error 0.0000(0.0000) Steps 490(496.68) | Grad Norm 12.8909(12.4553) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 21.2284, Epoch Time 298.8999(328.4650), Bit/dim 4.8776(best: 4.9728), Xent 0.0000, Loss 4.8776, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0151 | Time 43.2230(44.5192) | Bit/dim 4.8727(5.4079) | Xent 0.0000(0.0000) | Loss 13.9297(12.6933) | Error 0.0000(0.0000) Steps 472(495.94) | Grad Norm 9.2807(12.3601) | Total Time 0.00(0.00)\n",
      "Iter 0152 | Time 40.9411(44.4119) | Bit/dim 4.9029(5.3928) | Xent 0.0000(0.0000) | Loss 11.1209(12.6461) | Error 0.0000(0.0000) Steps 478(495.40) | Grad Norm 18.5084(12.5445) | Total Time 0.00(0.00)\n",
      "Iter 0153 | Time 45.5889(44.4472) | Bit/dim 4.8849(5.3776) | Xent 0.0000(0.0000) | Loss 11.1431(12.6010) | Error 0.0000(0.0000) Steps 502(495.60) | Grad Norm 10.0604(12.4700) | Total Time 0.00(0.00)\n",
      "Iter 0154 | Time 43.5816(44.4212) | Bit/dim 4.8774(5.3625) | Xent 0.0000(0.0000) | Loss 11.2439(12.5603) | Error 0.0000(0.0000) Steps 496(495.61) | Grad Norm 9.6021(12.3839) | Total Time 0.00(0.00)\n",
      "Iter 0155 | Time 46.9521(44.4972) | Bit/dim 4.8854(5.3482) | Xent 0.0000(0.0000) | Loss 11.1958(12.5194) | Error 0.0000(0.0000) Steps 484(495.26) | Grad Norm 15.9561(12.4911) | Total Time 0.00(0.00)\n",
      "Iter 0156 | Time 41.9141(44.4197) | Bit/dim 4.8536(5.3334) | Xent 0.0000(0.0000) | Loss 11.1038(12.4769) | Error 0.0000(0.0000) Steps 484(494.92) | Grad Norm 10.9153(12.4438) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 20.9577, Epoch Time 301.8037(327.6651), Bit/dim 4.8485(best: 4.8776), Xent 0.0000, Loss 4.8485, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0157 | Time 42.6359(44.3662) | Bit/dim 4.8401(5.3186) | Xent 0.0000(0.0000) | Loss 14.0386(12.5237) | Error 0.0000(0.0000) Steps 472(494.24) | Grad Norm 7.0097(12.2808) | Total Time 0.00(0.00)\n",
      "Iter 0158 | Time 42.3115(44.3045) | Bit/dim 4.8325(5.3040) | Xent 0.0000(0.0000) | Loss 10.9805(12.4774) | Error 0.0000(0.0000) Steps 448(492.85) | Grad Norm 8.3587(12.1631) | Total Time 0.00(0.00)\n",
      "Iter 0159 | Time 41.2317(44.2123) | Bit/dim 4.8051(5.2890) | Xent 0.0000(0.0000) | Loss 10.9757(12.4324) | Error 0.0000(0.0000) Steps 472(492.22) | Grad Norm 5.2110(11.9546) | Total Time 0.00(0.00)\n",
      "Iter 0160 | Time 42.2477(44.1534) | Bit/dim 4.8029(5.2745) | Xent 0.0000(0.0000) | Loss 10.8947(12.3863) | Error 0.0000(0.0000) Steps 466(491.44) | Grad Norm 6.6771(11.7963) | Total Time 0.00(0.00)\n",
      "Iter 0161 | Time 41.9493(44.0873) | Bit/dim 4.7917(5.2600) | Xent 0.0000(0.0000) | Loss 10.9810(12.3441) | Error 0.0000(0.0000) Steps 484(491.21) | Grad Norm 4.9465(11.5908) | Total Time 0.00(0.00)\n",
      "Iter 0162 | Time 42.3749(44.0359) | Bit/dim 4.7703(5.2453) | Xent 0.0000(0.0000) | Loss 10.6962(12.2947) | Error 0.0000(0.0000) Steps 472(490.64) | Grad Norm 5.2291(11.3999) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 19.8959, Epoch Time 291.4435(326.5785), Bit/dim 4.7571(best: 4.8485), Xent 0.0000, Loss 4.7571, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0163 | Time 44.8288(44.0597) | Bit/dim 4.7473(5.2303) | Xent 0.0000(0.0000) | Loss 13.9363(12.3439) | Error 0.0000(0.0000) Steps 490(490.62) | Grad Norm 5.8234(11.2326) | Total Time 0.00(0.00)\n",
      "Iter 0164 | Time 43.2390(44.0351) | Bit/dim 4.7524(5.2160) | Xent 0.0000(0.0000) | Loss 10.7862(12.2972) | Error 0.0000(0.0000) Steps 478(490.24) | Grad Norm 5.8103(11.0699) | Total Time 0.00(0.00)\n",
      "Iter 0165 | Time 44.1816(44.0395) | Bit/dim 4.7557(5.2022) | Xent 0.0000(0.0000) | Loss 10.9258(12.2560) | Error 0.0000(0.0000) Steps 484(490.05) | Grad Norm 8.3091(10.9871) | Total Time 0.00(0.00)\n",
      "Iter 0166 | Time 41.5748(43.9655) | Bit/dim 4.7366(5.1882) | Xent 0.0000(0.0000) | Loss 10.5757(12.2056) | Error 0.0000(0.0000) Steps 460(489.15) | Grad Norm 11.6397(11.0067) | Total Time 0.00(0.00)\n",
      "Iter 0167 | Time 43.3047(43.9457) | Bit/dim 4.7432(5.1749) | Xent 0.0000(0.0000) | Loss 10.5669(12.1565) | Error 0.0000(0.0000) Steps 472(488.64) | Grad Norm 12.5404(11.0527) | Total Time 0.00(0.00)\n",
      "Iter 0168 | Time 43.8251(43.9421) | Bit/dim 4.7443(5.1620) | Xent 0.0000(0.0000) | Loss 10.7723(12.1149) | Error 0.0000(0.0000) Steps 460(487.78) | Grad Norm 13.4257(11.1239) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 20.8767, Epoch Time 300.7878(325.8048), Bit/dim 4.7446(best: 4.7571), Xent 0.0000, Loss 4.7446, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0169 | Time 41.1403(43.8580) | Bit/dim 4.7437(5.1494) | Xent 0.0000(0.0000) | Loss 14.0229(12.1722) | Error 0.0000(0.0000) Steps 478(487.48) | Grad Norm 14.0950(11.2130) | Total Time 0.00(0.00)\n",
      "Iter 0170 | Time 46.1833(43.9278) | Bit/dim 4.7122(5.1363) | Xent 0.0000(0.0000) | Loss 10.7506(12.1295) | Error 0.0000(0.0000) Steps 490(487.56) | Grad Norm 11.1673(11.2117) | Total Time 0.00(0.00)\n",
      "Iter 0171 | Time 46.7524(44.0125) | Bit/dim 4.6899(5.1229) | Xent 0.0000(0.0000) | Loss 10.7822(12.0891) | Error 0.0000(0.0000) Steps 490(487.63) | Grad Norm 5.9346(11.0534) | Total Time 0.00(0.00)\n",
      "Iter 0172 | Time 48.0154(44.1326) | Bit/dim 4.6692(5.1093) | Xent 0.0000(0.0000) | Loss 10.6066(12.0446) | Error 0.0000(0.0000) Steps 502(488.06) | Grad Norm 5.4113(10.8841) | Total Time 0.00(0.00)\n",
      "Iter 0173 | Time 43.6407(44.1179) | Bit/dim 4.6620(5.0959) | Xent 0.0000(0.0000) | Loss 10.6661(12.0033) | Error 0.0000(0.0000) Steps 484(487.94) | Grad Norm 3.7084(10.6688) | Total Time 0.00(0.00)\n",
      "Iter 0174 | Time 43.6694(44.1044) | Bit/dim 4.6761(5.0833) | Xent 0.0000(0.0000) | Loss 10.7801(11.9666) | Error 0.0000(0.0000) Steps 466(487.28) | Grad Norm 8.1059(10.5919) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 21.0699, Epoch Time 308.6187(325.2892), Bit/dim 4.7273(best: 4.7446), Xent 0.0000, Loss 4.7273, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0175 | Time 46.0138(44.1617) | Bit/dim 4.7204(5.0724) | Xent 0.0000(0.0000) | Loss 13.4606(12.0114) | Error 0.0000(0.0000) Steps 478(487.00) | Grad Norm 22.5493(10.9507) | Total Time 0.00(0.00)\n",
      "Iter 0176 | Time 42.6290(44.1157) | Bit/dim 4.8303(5.0651) | Xent 0.0000(0.0000) | Loss 11.0408(11.9823) | Error 0.0000(0.0000) Steps 472(486.55) | Grad Norm 22.6932(11.3029) | Total Time 0.00(0.00)\n",
      "Iter 0177 | Time 43.1117(44.0856) | Bit/dim 4.6684(5.0532) | Xent 0.0000(0.0000) | Loss 10.6343(11.9419) | Error 0.0000(0.0000) Steps 490(486.66) | Grad Norm 5.8160(11.1383) | Total Time 0.00(0.00)\n",
      "Iter 0178 | Time 42.3028(44.0321) | Bit/dim 4.8167(5.0461) | Xent 0.0000(0.0000) | Loss 10.9339(11.9116) | Error 0.0000(0.0000) Steps 460(485.86) | Grad Norm 23.4608(11.5080) | Total Time 0.00(0.00)\n",
      "Iter 0179 | Time 41.9879(43.9708) | Bit/dim 4.8011(5.0388) | Xent 0.0000(0.0000) | Loss 10.9858(11.8838) | Error 0.0000(0.0000) Steps 478(485.62) | Grad Norm 15.8415(11.6380) | Total Time 0.00(0.00)\n",
      "Iter 0180 | Time 43.8549(43.9673) | Bit/dim 4.7816(5.0311) | Xent 0.0000(0.0000) | Loss 11.0612(11.8592) | Error 0.0000(0.0000) Steps 490(485.75) | Grad Norm 13.6706(11.6990) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 20.7951, Epoch Time 299.0593(324.5023), Bit/dim 4.7168(best: 4.7273), Xent 0.0000, Loss 4.7168, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0181 | Time 40.5359(43.8644) | Bit/dim 4.7187(5.0217) | Xent 0.0000(0.0000) | Loss 13.7656(11.9164) | Error 0.0000(0.0000) Steps 466(485.16) | Grad Norm 11.1302(11.6819) | Total Time 0.00(0.00)\n",
      "Iter 0182 | Time 41.8505(43.8039) | Bit/dim 4.7121(5.0124) | Xent 0.0000(0.0000) | Loss 10.4424(11.8721) | Error 0.0000(0.0000) Steps 448(484.05) | Grad Norm 14.1485(11.7559) | Total Time 0.00(0.00)\n",
      "Iter 0183 | Time 44.8484(43.8353) | Bit/dim 4.6826(5.0025) | Xent 0.0000(0.0000) | Loss 10.5570(11.8327) | Error 0.0000(0.0000) Steps 502(484.58) | Grad Norm 9.1660(11.6782) | Total Time 0.00(0.00)\n",
      "Iter 0184 | Time 41.0454(43.7516) | Bit/dim 4.7175(4.9940) | Xent 0.0000(0.0000) | Loss 10.4743(11.7919) | Error 0.0000(0.0000) Steps 466(484.03) | Grad Norm 13.3769(11.7292) | Total Time 0.00(0.00)\n",
      "Iter 0185 | Time 44.5875(43.7767) | Bit/dim 4.6394(4.9833) | Xent 0.0000(0.0000) | Loss 10.4409(11.7514) | Error 0.0000(0.0000) Steps 472(483.67) | Grad Norm 7.6589(11.6071) | Total Time 0.00(0.00)\n",
      "Iter 0186 | Time 47.6782(43.8937) | Bit/dim 4.7173(4.9753) | Xent 0.0000(0.0000) | Loss 10.7558(11.7215) | Error 0.0000(0.0000) Steps 496(484.04) | Grad Norm 14.1656(11.6838) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 20.9731, Epoch Time 300.7668(323.7902), Bit/dim 4.7403(best: 4.7168), Xent 0.0000, Loss 4.7403, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0187 | Time 44.1816(43.9023) | Bit/dim 4.7353(4.9681) | Xent 0.0000(0.0000) | Loss 14.0658(11.7919) | Error 0.0000(0.0000) Steps 496(484.40) | Grad Norm 14.2523(11.7609) | Total Time 0.00(0.00)\n",
      "Iter 0188 | Time 45.3210(43.9449) | Bit/dim 4.8116(4.9634) | Xent 0.0000(0.0000) | Loss 11.0545(11.7697) | Error 0.0000(0.0000) Steps 496(484.74) | Grad Norm 18.0663(11.9500) | Total Time 0.00(0.00)\n",
      "Iter 0189 | Time 42.8948(43.9134) | Bit/dim 4.7344(4.9566) | Xent 0.0000(0.0000) | Loss 10.7650(11.7396) | Error 0.0000(0.0000) Steps 472(484.36) | Grad Norm 11.5312(11.9375) | Total Time 0.00(0.00)\n",
      "Iter 0190 | Time 43.6361(43.9051) | Bit/dim 4.6943(4.9487) | Xent 0.0000(0.0000) | Loss 10.8514(11.7129) | Error 0.0000(0.0000) Steps 460(483.63) | Grad Norm 13.1764(11.9746) | Total Time 0.00(0.00)\n",
      "Iter 0191 | Time 40.8471(43.8133) | Bit/dim 4.7045(4.9414) | Xent 0.0000(0.0000) | Loss 10.6919(11.6823) | Error 0.0000(0.0000) Steps 478(483.46) | Grad Norm 12.4661(11.9894) | Total Time 0.00(0.00)\n",
      "Iter 0192 | Time 45.6755(43.8692) | Bit/dim 4.6379(4.9323) | Xent 0.0000(0.0000) | Loss 10.5626(11.6487) | Error 0.0000(0.0000) Steps 490(483.66) | Grad Norm 7.2194(11.8463) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 20.7878, Epoch Time 303.1958(323.1724), Bit/dim 4.6405(best: 4.7168), Xent 0.0000, Loss 4.6405, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0193 | Time 44.1297(43.8770) | Bit/dim 4.6410(4.9235) | Xent 0.0000(0.0000) | Loss 13.5275(11.7051) | Error 0.0000(0.0000) Steps 484(483.67) | Grad Norm 8.4511(11.7444) | Total Time 0.00(0.00)\n",
      "Iter 0194 | Time 42.9096(43.8480) | Bit/dim 4.6229(4.9145) | Xent 0.0000(0.0000) | Loss 10.4962(11.6688) | Error 0.0000(0.0000) Steps 478(483.50) | Grad Norm 4.8936(11.5389) | Total Time 0.00(0.00)\n",
      "Iter 0195 | Time 40.4719(43.7467) | Bit/dim 4.6311(4.9060) | Xent 0.0000(0.0000) | Loss 10.5179(11.6343) | Error 0.0000(0.0000) Steps 472(483.15) | Grad Norm 5.6006(11.3608) | Total Time 0.00(0.00)\n",
      "Iter 0196 | Time 47.1116(43.8477) | Bit/dim 4.6175(4.8974) | Xent 0.0000(0.0000) | Loss 10.3197(11.5949) | Error 0.0000(0.0000) Steps 496(483.54) | Grad Norm 8.0272(11.2608) | Total Time 0.00(0.00)\n",
      "Iter 0197 | Time 43.1235(43.8259) | Bit/dim 4.5825(4.8879) | Xent 0.0000(0.0000) | Loss 10.6473(11.5664) | Error 0.0000(0.0000) Steps 484(483.55) | Grad Norm 4.4029(11.0550) | Total Time 0.00(0.00)\n",
      "Iter 0198 | Time 43.4999(43.8162) | Bit/dim 4.5622(4.8781) | Xent 0.0000(0.0000) | Loss 10.3901(11.5311) | Error 0.0000(0.0000) Steps 490(483.75) | Grad Norm 4.8315(10.8683) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 21.5658, Epoch Time 301.9355(322.5353), Bit/dim 4.5808(best: 4.6405), Xent 0.0000, Loss 4.5808, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0199 | Time 43.8604(43.8175) | Bit/dim 4.5773(4.8691) | Xent 0.0000(0.0000) | Loss 13.7090(11.5965) | Error 0.0000(0.0000) Steps 502(484.29) | Grad Norm 9.1682(10.8173) | Total Time 0.00(0.00)\n",
      "Iter 0200 | Time 42.2695(43.7710) | Bit/dim 4.5979(4.8610) | Xent 0.0000(0.0000) | Loss 10.3467(11.5590) | Error 0.0000(0.0000) Steps 472(483.92) | Grad Norm 9.4901(10.7775) | Total Time 0.00(0.00)\n",
      "Iter 0201 | Time 46.8494(43.8634) | Bit/dim 4.7574(4.8579) | Xent 0.0000(0.0000) | Loss 11.1349(11.5463) | Error 0.0000(0.0000) Steps 514(484.83) | Grad Norm 30.5713(11.3713) | Total Time 0.00(0.00)\n",
      "Iter 0202 | Time 41.2899(43.7862) | Bit/dim 4.6392(4.8513) | Xent 0.0000(0.0000) | Loss 10.7067(11.5211) | Error 0.0000(0.0000) Steps 478(484.62) | Grad Norm 15.3549(11.4908) | Total Time 0.00(0.00)\n",
      "Iter 0203 | Time 44.5844(43.8101) | Bit/dim 4.5923(4.8435) | Xent 0.0000(0.0000) | Loss 10.4157(11.4879) | Error 0.0000(0.0000) Steps 478(484.42) | Grad Norm 6.8951(11.3529) | Total Time 0.00(0.00)\n",
      "Iter 0204 | Time 40.8772(43.7221) | Bit/dim 4.6544(4.8379) | Xent 0.0000(0.0000) | Loss 10.4580(11.4570) | Error 0.0000(0.0000) Steps 460(483.69) | Grad Norm 15.1874(11.4680) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 20.5972, Epoch Time 299.2182(321.8358), Bit/dim 4.5632(best: 4.5808), Xent 0.0000, Loss 4.5632, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0205 | Time 43.4312(43.7134) | Bit/dim 4.5658(4.8297) | Xent 0.0000(0.0000) | Loss 12.7582(11.4960) | Error 0.0000(0.0000) Steps 454(482.80) | Grad Norm 5.7400(11.2961) | Total Time 0.00(0.00)\n",
      "Iter 0206 | Time 42.0227(43.6627) | Bit/dim 4.5893(4.8225) | Xent 0.0000(0.0000) | Loss 10.5580(11.4679) | Error 0.0000(0.0000) Steps 490(483.02) | Grad Norm 9.0825(11.2297) | Total Time 0.00(0.00)\n",
      "Iter 0207 | Time 44.7319(43.6948) | Bit/dim 4.5273(4.8136) | Xent 0.0000(0.0000) | Loss 10.3644(11.4348) | Error 0.0000(0.0000) Steps 472(482.69) | Grad Norm 5.8278(11.0677) | Total Time 0.00(0.00)\n",
      "Iter 0208 | Time 41.1332(43.6179) | Bit/dim 4.5509(4.8058) | Xent 0.0000(0.0000) | Loss 10.3511(11.4023) | Error 0.0000(0.0000) Steps 466(482.18) | Grad Norm 9.9186(11.0332) | Total Time 0.00(0.00)\n",
      "Iter 0209 | Time 43.6345(43.6184) | Bit/dim 4.5486(4.7980) | Xent 0.0000(0.0000) | Loss 10.4659(11.3742) | Error 0.0000(0.0000) Steps 454(481.34) | Grad Norm 6.9709(10.9113) | Total Time 0.00(0.00)\n",
      "Iter 0210 | Time 46.5397(43.7061) | Bit/dim 4.5345(4.7901) | Xent 0.0000(0.0000) | Loss 10.5503(11.3495) | Error 0.0000(0.0000) Steps 490(481.60) | Grad Norm 7.4899(10.8087) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 20.4014, Epoch Time 301.0899(321.2134), Bit/dim 4.5061(best: 4.5632), Xent 0.0000, Loss 4.5061, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0211 | Time 43.8638(43.7108) | Bit/dim 4.5040(4.7815) | Xent 0.0000(0.0000) | Loss 13.2352(11.4061) | Error 0.0000(0.0000) Steps 478(481.49) | Grad Norm 5.3459(10.6448) | Total Time 0.00(0.00)\n",
      "Iter 0212 | Time 42.0582(43.6612) | Bit/dim 4.5015(4.7731) | Xent 0.0000(0.0000) | Loss 10.3104(11.3732) | Error 0.0000(0.0000) Steps 478(481.39) | Grad Norm 5.3177(10.4850) | Total Time 0.00(0.00)\n",
      "Iter 0213 | Time 43.3785(43.6527) | Bit/dim 4.5058(4.7651) | Xent 0.0000(0.0000) | Loss 10.1650(11.3369) | Error 0.0000(0.0000) Steps 484(481.46) | Grad Norm 11.0353(10.5015) | Total Time 0.00(0.00)\n",
      "Iter 0214 | Time 46.6492(43.7426) | Bit/dim 4.5282(4.7580) | Xent 0.0000(0.0000) | Loss 10.4321(11.3098) | Error 0.0000(0.0000) Steps 496(481.90) | Grad Norm 12.7323(10.5684) | Total Time 0.00(0.00)\n",
      "Iter 0215 | Time 40.3654(43.6413) | Bit/dim 4.5312(4.7512) | Xent 0.0000(0.0000) | Loss 10.4314(11.2834) | Error 0.0000(0.0000) Steps 466(481.42) | Grad Norm 11.6419(10.6006) | Total Time 0.00(0.00)\n",
      "Iter 0216 | Time 40.3419(43.5423) | Bit/dim 4.4883(4.7433) | Xent 0.0000(0.0000) | Loss 10.2636(11.2528) | Error 0.0000(0.0000) Steps 466(480.96) | Grad Norm 6.9041(10.4897) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 21.1179, Epoch Time 296.1138(320.4604), Bit/dim 4.4923(best: 4.5061), Xent 0.0000, Loss 4.4923, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0217 | Time 41.3525(43.4766) | Bit/dim 4.4949(4.7359) | Xent 0.0000(0.0000) | Loss 13.4252(11.3180) | Error 0.0000(0.0000) Steps 472(480.69) | Grad Norm 8.0233(10.4157) | Total Time 0.00(0.00)\n",
      "Iter 0218 | Time 43.7280(43.4842) | Bit/dim 4.4664(4.7278) | Xent 0.0000(0.0000) | Loss 10.2356(11.2855) | Error 0.0000(0.0000) Steps 478(480.61) | Grad Norm 4.6589(10.2430) | Total Time 0.00(0.00)\n",
      "Iter 0219 | Time 45.8558(43.5553) | Bit/dim 4.4651(4.7199) | Xent 0.0000(0.0000) | Loss 10.1199(11.2506) | Error 0.0000(0.0000) Steps 478(480.53) | Grad Norm 7.7065(10.1669) | Total Time 0.00(0.00)\n",
      "Iter 0220 | Time 44.6953(43.5895) | Bit/dim 4.4574(4.7120) | Xent 0.0000(0.0000) | Loss 10.0120(11.2134) | Error 0.0000(0.0000) Steps 484(480.64) | Grad Norm 4.2453(9.9893) | Total Time 0.00(0.00)\n",
      "Iter 0221 | Time 41.8644(43.5378) | Bit/dim 4.4359(4.7038) | Xent 0.0000(0.0000) | Loss 10.1593(11.1818) | Error 0.0000(0.0000) Steps 466(480.20) | Grad Norm 6.8054(9.8938) | Total Time 0.00(0.00)\n",
      "Iter 0222 | Time 40.9309(43.4596) | Bit/dim 4.4348(4.6957) | Xent 0.0000(0.0000) | Loss 10.2695(11.1544) | Error 0.0000(0.0000) Steps 472(479.95) | Grad Norm 6.3234(9.7867) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 20.7749, Epoch Time 297.4444(319.7699), Bit/dim 4.4675(best: 4.4923), Xent 0.0000, Loss 4.4675, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0223 | Time 46.3276(43.5456) | Bit/dim 4.4708(4.6889) | Xent 0.0000(0.0000) | Loss 13.1851(11.2153) | Error 0.0000(0.0000) Steps 472(479.71) | Grad Norm 13.1727(9.8882) | Total Time 0.00(0.00)\n",
      "Iter 0224 | Time 41.0122(43.4696) | Bit/dim 4.5542(4.6849) | Xent 0.0000(0.0000) | Loss 10.3587(11.1896) | Error 0.0000(0.0000) Steps 466(479.30) | Grad Norm 19.6718(10.1818) | Total Time 0.00(0.00)\n",
      "Iter 0225 | Time 43.2739(43.4637) | Bit/dim 4.6125(4.6827) | Xent 0.0000(0.0000) | Loss 10.5814(11.1714) | Error 0.0000(0.0000) Steps 484(479.44) | Grad Norm 24.7879(10.6199) | Total Time 0.00(0.00)\n",
      "Iter 0226 | Time 41.3367(43.3999) | Bit/dim 4.5009(4.6773) | Xent 0.0000(0.0000) | Loss 10.3507(11.1468) | Error 0.0000(0.0000) Steps 472(479.22) | Grad Norm 13.9750(10.7206) | Total Time 0.00(0.00)\n",
      "Iter 0227 | Time 39.4851(43.2825) | Bit/dim 4.5384(4.6731) | Xent 0.0000(0.0000) | Loss 10.3086(11.1216) | Error 0.0000(0.0000) Steps 460(478.64) | Grad Norm 14.5593(10.8357) | Total Time 0.00(0.00)\n",
      "Iter 0228 | Time 39.9049(43.1811) | Bit/dim 4.5000(4.6679) | Xent 0.0000(0.0000) | Loss 10.1386(11.0921) | Error 0.0000(0.0000) Steps 460(478.08) | Grad Norm 11.0569(10.8424) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 20.8680, Epoch Time 290.8757(318.9031), Bit/dim 4.4894(best: 4.4675), Xent 0.0000, Loss 4.4894, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0229 | Time 40.9423(43.1140) | Bit/dim 4.4937(4.6627) | Xent 0.0000(0.0000) | Loss 13.4381(11.1625) | Error 0.0000(0.0000) Steps 472(477.90) | Grad Norm 11.2000(10.8531) | Total Time 0.00(0.00)\n",
      "Iter 0230 | Time 44.5200(43.1562) | Bit/dim 4.4701(4.6569) | Xent 0.0000(0.0000) | Loss 9.9694(11.1267) | Error 0.0000(0.0000) Steps 466(477.54) | Grad Norm 9.5044(10.8127) | Total Time 0.00(0.00)\n",
      "Iter 0231 | Time 42.1903(43.1272) | Bit/dim 4.4524(4.6508) | Xent 0.0000(0.0000) | Loss 10.2440(11.1002) | Error 0.0000(0.0000) Steps 472(477.38) | Grad Norm 6.2340(10.6753) | Total Time 0.00(0.00)\n",
      "Iter 0232 | Time 45.3840(43.1949) | Bit/dim 4.4502(4.6448) | Xent 0.0000(0.0000) | Loss 10.3088(11.0765) | Error 0.0000(0.0000) Steps 490(477.76) | Grad Norm 8.4774(10.6094) | Total Time 0.00(0.00)\n",
      "Iter 0233 | Time 47.5188(43.3246) | Bit/dim 4.4230(4.6381) | Xent 0.0000(0.0000) | Loss 10.1690(11.0493) | Error 0.0000(0.0000) Steps 502(478.48) | Grad Norm 6.0334(10.4721) | Total Time 0.00(0.00)\n",
      "Iter 0234 | Time 40.8566(43.2506) | Bit/dim 4.4119(4.6313) | Xent 0.0000(0.0000) | Loss 10.0855(11.0204) | Error 0.0000(0.0000) Steps 466(478.11) | Grad Norm 8.6811(10.4183) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 20.6838, Epoch Time 300.9422(318.3643), Bit/dim 4.4004(best: 4.4675), Xent 0.0000, Loss 4.4004, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0235 | Time 43.4637(43.2570) | Bit/dim 4.4017(4.6244) | Xent 0.0000(0.0000) | Loss 13.3063(11.0889) | Error 0.0000(0.0000) Steps 490(478.47) | Grad Norm 5.4842(10.2703) | Total Time 0.00(0.00)\n",
      "Iter 0236 | Time 42.5370(43.2354) | Bit/dim 4.3935(4.6175) | Xent 0.0000(0.0000) | Loss 10.1693(11.0614) | Error 0.0000(0.0000) Steps 478(478.45) | Grad Norm 7.5419(10.1885) | Total Time 0.00(0.00)\n",
      "Iter 0237 | Time 40.6238(43.1570) | Bit/dim 4.3960(4.6109) | Xent 0.0000(0.0000) | Loss 9.9179(11.0271) | Error 0.0000(0.0000) Steps 466(478.08) | Grad Norm 6.1991(10.0688) | Total Time 0.00(0.00)\n",
      "Iter 0238 | Time 44.9840(43.2118) | Bit/dim 4.3785(4.6039) | Xent 0.0000(0.0000) | Loss 9.9002(10.9932) | Error 0.0000(0.0000) Steps 472(477.90) | Grad Norm 5.6496(9.9362) | Total Time 0.00(0.00)\n",
      "Iter 0239 | Time 40.7808(43.1389) | Bit/dim 4.3829(4.5973) | Xent 0.0000(0.0000) | Loss 10.0237(10.9642) | Error 0.0000(0.0000) Steps 460(477.36) | Grad Norm 6.8656(9.8441) | Total Time 0.00(0.00)\n",
      "Iter 0240 | Time 43.6934(43.1555) | Bit/dim 4.4215(4.5920) | Xent 0.0000(0.0000) | Loss 9.7760(10.9285) | Error 0.0000(0.0000) Steps 454(476.66) | Grad Norm 9.3600(9.8296) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 22.5524, Epoch Time 297.8676(317.7494), Bit/dim 4.4897(best: 4.4004), Xent 0.0000, Loss 4.4897, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0241 | Time 46.9793(43.2702) | Bit/dim 4.4952(4.5891) | Xent 0.0000(0.0000) | Loss 13.3418(11.0009) | Error 0.0000(0.0000) Steps 490(477.06) | Grad Norm 15.9886(10.0143) | Total Time 0.00(0.00)\n",
      "Iter 0242 | Time 43.3842(43.2737) | Bit/dim 4.4922(4.5862) | Xent 0.0000(0.0000) | Loss 10.3308(10.9808) | Error 0.0000(0.0000) Steps 490(477.45) | Grad Norm 12.7007(10.0949) | Total Time 0.00(0.00)\n",
      "Iter 0243 | Time 41.3795(43.2168) | Bit/dim 4.3857(4.5802) | Xent 0.0000(0.0000) | Loss 9.9457(10.9498) | Error 0.0000(0.0000) Steps 466(477.10) | Grad Norm 6.0728(9.9743) | Total Time 0.00(0.00)\n",
      "Iter 0244 | Time 46.3996(43.3123) | Bit/dim 4.4686(4.5768) | Xent 0.0000(0.0000) | Loss 10.0895(10.9239) | Error 0.0000(0.0000) Steps 496(477.67) | Grad Norm 13.1262(10.0688) | Total Time 0.00(0.00)\n",
      "Iter 0245 | Time 44.7145(43.3544) | Bit/dim 4.3702(4.5706) | Xent 0.0000(0.0000) | Loss 9.9778(10.8956) | Error 0.0000(0.0000) Steps 472(477.50) | Grad Norm 4.7868(9.9104) | Total Time 0.00(0.00)\n",
      "Iter 0246 | Time 47.7686(43.4868) | Bit/dim 4.4131(4.5659) | Xent 0.0000(0.0000) | Loss 10.2502(10.8762) | Error 0.0000(0.0000) Steps 478(477.52) | Grad Norm 7.5807(9.8405) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 20.5525, Epoch Time 310.1852(317.5224), Bit/dim 4.3661(best: 4.4004), Xent 0.0000, Loss 4.3661, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0247 | Time 40.3278(43.3920) | Bit/dim 4.3683(4.5600) | Xent 0.0000(0.0000) | Loss 13.0458(10.9413) | Error 0.0000(0.0000) Steps 472(477.35) | Grad Norm 6.6892(9.7459) | Total Time 0.00(0.00)\n",
      "Iter 0248 | Time 41.6448(43.3396) | Bit/dim 4.3728(4.5543) | Xent 0.0000(0.0000) | Loss 10.0565(10.9147) | Error 0.0000(0.0000) Steps 466(477.01) | Grad Norm 8.1617(9.6984) | Total Time 0.00(0.00)\n",
      "Iter 0249 | Time 42.5546(43.3161) | Bit/dim 4.3447(4.5481) | Xent 0.0000(0.0000) | Loss 9.8061(10.8815) | Error 0.0000(0.0000) Steps 472(476.86) | Grad Norm 5.4901(9.5722) | Total Time 0.00(0.00)\n",
      "Iter 0250 | Time 45.1369(43.3707) | Bit/dim 4.3403(4.5418) | Xent 0.0000(0.0000) | Loss 10.0309(10.8560) | Error 0.0000(0.0000) Steps 502(477.61) | Grad Norm 6.4435(9.4783) | Total Time 0.00(0.00)\n",
      "Iter 0251 | Time 42.1781(43.3349) | Bit/dim 4.3320(4.5355) | Xent 0.0000(0.0000) | Loss 9.7416(10.8225) | Error 0.0000(0.0000) Steps 478(477.62) | Grad Norm 6.4436(9.3873) | Total Time 0.00(0.00)\n",
      "Iter 0252 | Time 44.0878(43.3575) | Bit/dim 4.3389(4.5296) | Xent 0.0000(0.0000) | Loss 10.1710(10.8030) | Error 0.0000(0.0000) Steps 490(478.00) | Grad Norm 9.8833(9.4021) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 20.4881, Epoch Time 295.2003(316.8528), Bit/dim 4.3143(best: 4.3661), Xent 0.0000, Loss 4.3143, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0253 | Time 45.2296(43.4137) | Bit/dim 4.3100(4.5230) | Xent 0.0000(0.0000) | Loss 13.1974(10.8748) | Error 0.0000(0.0000) Steps 478(478.00) | Grad Norm 7.2817(9.3385) | Total Time 0.00(0.00)\n",
      "Iter 0254 | Time 43.2497(43.4087) | Bit/dim 4.3094(4.5166) | Xent 0.0000(0.0000) | Loss 9.7676(10.8416) | Error 0.0000(0.0000) Steps 478(478.00) | Grad Norm 7.6957(9.2892) | Total Time 0.00(0.00)\n",
      "Iter 0255 | Time 42.7471(43.3889) | Bit/dim 4.2980(4.5101) | Xent 0.0000(0.0000) | Loss 9.9205(10.8140) | Error 0.0000(0.0000) Steps 478(478.00) | Grad Norm 4.4468(9.1440) | Total Time 0.00(0.00)\n",
      "Iter 0256 | Time 41.1268(43.3210) | Bit/dim 4.2970(4.5037) | Xent 0.0000(0.0000) | Loss 9.7557(10.7822) | Error 0.0000(0.0000) Steps 460(477.46) | Grad Norm 5.2563(9.0273) | Total Time 0.00(0.00)\n",
      "Iter 0257 | Time 44.2872(43.3500) | Bit/dim 4.2937(4.4974) | Xent 0.0000(0.0000) | Loss 9.9129(10.7561) | Error 0.0000(0.0000) Steps 490(477.83) | Grad Norm 5.1661(8.9115) | Total Time 0.00(0.00)\n",
      "Iter 0258 | Time 42.2628(43.3174) | Bit/dim 4.2802(4.4909) | Xent 0.0000(0.0000) | Loss 9.5737(10.7207) | Error 0.0000(0.0000) Steps 472(477.66) | Grad Norm 5.8607(8.8200) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 21.1090, Epoch Time 298.8840(316.3137), Bit/dim 4.2742(best: 4.3143), Xent 0.0000, Loss 4.2742, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0259 | Time 41.8797(43.2743) | Bit/dim 4.2682(4.4842) | Xent 0.0000(0.0000) | Loss 13.1233(10.7928) | Error 0.0000(0.0000) Steps 490(478.03) | Grad Norm 4.6531(8.6950) | Total Time 0.00(0.00)\n",
      "Iter 0260 | Time 46.9974(43.3860) | Bit/dim 4.2757(4.4779) | Xent 0.0000(0.0000) | Loss 9.8764(10.7653) | Error 0.0000(0.0000) Steps 496(478.57) | Grad Norm 6.1626(8.6190) | Total Time 0.00(0.00)\n",
      "Iter 0261 | Time 40.7960(43.3083) | Bit/dim 4.2803(4.4720) | Xent 0.0000(0.0000) | Loss 9.9176(10.7398) | Error 0.0000(0.0000) Steps 466(478.19) | Grad Norm 8.2029(8.6065) | Total Time 0.00(0.00)\n",
      "Iter 0262 | Time 45.4120(43.3714) | Bit/dim 4.3285(4.4677) | Xent 0.0000(0.0000) | Loss 9.9145(10.7151) | Error 0.0000(0.0000) Steps 484(478.36) | Grad Norm 14.9120(8.7957) | Total Time 0.00(0.00)\n",
      "Iter 0263 | Time 43.7689(43.3833) | Bit/dim 4.3842(4.4652) | Xent 0.0000(0.0000) | Loss 9.9622(10.6925) | Error 0.0000(0.0000) Steps 484(478.53) | Grad Norm 16.9175(9.0393) | Total Time 0.00(0.00)\n",
      "Iter 0264 | Time 46.9163(43.4893) | Bit/dim 4.3841(4.4628) | Xent 0.0000(0.0000) | Loss 10.1087(10.6750) | Error 0.0000(0.0000) Steps 502(479.24) | Grad Norm 15.3868(9.2298) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 20.5462, Epoch Time 306.1468(316.0087), Bit/dim 4.3017(best: 4.2742), Xent 0.0000, Loss 4.3017, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0265 | Time 44.6430(43.5239) | Bit/dim 4.3083(4.4581) | Xent 0.0000(0.0000) | Loss 13.2716(10.7529) | Error 0.0000(0.0000) Steps 484(479.38) | Grad Norm 8.4146(9.2053) | Total Time 0.00(0.00)\n",
      "Iter 0266 | Time 43.9381(43.5363) | Bit/dim 4.3396(4.4546) | Xent 0.0000(0.0000) | Loss 9.9607(10.7291) | Error 0.0000(0.0000) Steps 484(479.52) | Grad Norm 9.4348(9.2122) | Total Time 0.00(0.00)\n",
      "Iter 0267 | Time 43.2040(43.5264) | Bit/dim 4.2777(4.4493) | Xent 0.0000(0.0000) | Loss 9.8457(10.7026) | Error 0.0000(0.0000) Steps 484(479.65) | Grad Norm 6.5996(9.1338) | Total Time 0.00(0.00)\n",
      "Iter 0268 | Time 43.9103(43.5379) | Bit/dim 4.3025(4.4449) | Xent 0.0000(0.0000) | Loss 10.1207(10.6851) | Error 0.0000(0.0000) Steps 472(479.42) | Grad Norm 8.2645(9.1077) | Total Time 0.00(0.00)\n",
      "Iter 0269 | Time 40.8694(43.4578) | Bit/dim 4.2741(4.4397) | Xent 0.0000(0.0000) | Loss 9.5560(10.6513) | Error 0.0000(0.0000) Steps 460(478.84) | Grad Norm 6.8273(9.0393) | Total Time 0.00(0.00)\n",
      "Iter 0270 | Time 44.8179(43.4986) | Bit/dim 4.2795(4.4349) | Xent 0.0000(0.0000) | Loss 9.7678(10.6248) | Error 0.0000(0.0000) Steps 472(478.64) | Grad Norm 11.6203(9.1167) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 21.0556, Epoch Time 300.1494(315.5329), Bit/dim 4.3038(best: 4.2742), Xent 0.0000, Loss 4.3038, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0271 | Time 43.1436(43.4880) | Bit/dim 4.2940(4.4307) | Xent 0.0000(0.0000) | Loss 12.3021(10.6751) | Error 0.0000(0.0000) Steps 460(478.08) | Grad Norm 12.4576(9.2170) | Total Time 0.00(0.00)\n",
      "Iter 0272 | Time 45.3376(43.5435) | Bit/dim 4.3055(4.4269) | Xent 0.0000(0.0000) | Loss 10.0012(10.6549) | Error 0.0000(0.0000) Steps 484(478.25) | Grad Norm 8.3127(9.1898) | Total Time 0.00(0.00)\n",
      "Iter 0273 | Time 42.2841(43.5057) | Bit/dim 4.2892(4.4228) | Xent 0.0000(0.0000) | Loss 9.8824(10.6317) | Error 0.0000(0.0000) Steps 460(477.71) | Grad Norm 10.0180(9.2147) | Total Time 0.00(0.00)\n",
      "Iter 0274 | Time 41.4340(43.4435) | Bit/dim 4.2808(4.4186) | Xent 0.0000(0.0000) | Loss 9.6412(10.6020) | Error 0.0000(0.0000) Steps 490(478.08) | Grad Norm 7.5280(9.1641) | Total Time 0.00(0.00)\n",
      "Iter 0275 | Time 43.0140(43.4306) | Bit/dim 4.2579(4.4137) | Xent 0.0000(0.0000) | Loss 9.7521(10.5765) | Error 0.0000(0.0000) Steps 478(478.07) | Grad Norm 7.9898(9.1289) | Total Time 0.00(0.00)\n",
      "Iter 0276 | Time 39.8121(43.3221) | Bit/dim 4.2811(4.4098) | Xent 0.0000(0.0000) | Loss 9.9114(10.5565) | Error 0.0000(0.0000) Steps 466(477.71) | Grad Norm 12.0459(9.2164) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 21.7977, Epoch Time 300.6536(315.0866), Bit/dim 4.2368(best: 4.2742), Xent 0.0000, Loss 4.2368, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0277 | Time 40.9250(43.2502) | Bit/dim 4.2426(4.4047) | Xent 0.0000(0.0000) | Loss 12.4752(10.6141) | Error 0.0000(0.0000) Steps 460(477.18) | Grad Norm 8.2400(9.1871) | Total Time 0.00(0.00)\n",
      "Iter 0278 | Time 46.9038(43.3598) | Bit/dim 4.2336(4.3996) | Xent 0.0000(0.0000) | Loss 9.6632(10.5856) | Error 0.0000(0.0000) Steps 502(477.92) | Grad Norm 5.8121(9.0858) | Total Time 0.00(0.00)\n",
      "Iter 0279 | Time 42.9290(43.3469) | Bit/dim 4.2375(4.3947) | Xent 0.0000(0.0000) | Loss 9.8589(10.5638) | Error 0.0000(0.0000) Steps 472(477.75) | Grad Norm 8.2617(9.0611) | Total Time 0.00(0.00)\n",
      "Iter 0280 | Time 44.9962(43.3963) | Bit/dim 4.2432(4.3902) | Xent 0.0000(0.0000) | Loss 9.8583(10.5426) | Error 0.0000(0.0000) Steps 472(477.57) | Grad Norm 6.8298(8.9942) | Total Time 0.00(0.00)\n",
      "Iter 0281 | Time 41.6344(43.3435) | Bit/dim 4.2037(4.3846) | Xent 0.0000(0.0000) | Loss 9.7245(10.5181) | Error 0.0000(0.0000) Steps 472(477.41) | Grad Norm 4.7161(8.8658) | Total Time 0.00(0.00)\n",
      "Iter 0282 | Time 42.1618(43.3080) | Bit/dim 4.1855(4.3786) | Xent 0.0000(0.0000) | Loss 9.7457(10.4949) | Error 0.0000(0.0000) Steps 472(477.24) | Grad Norm 4.5550(8.7365) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 21.0935, Epoch Time 299.2721(314.6121), Bit/dim 4.2003(best: 4.2368), Xent 0.0000, Loss 4.2003, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0283 | Time 40.3212(43.2184) | Bit/dim 4.2028(4.3734) | Xent 0.0000(0.0000) | Loss 12.8622(10.5659) | Error 0.0000(0.0000) Steps 466(476.91) | Grad Norm 6.5150(8.6699) | Total Time 0.00(0.00)\n",
      "Iter 0284 | Time 44.8323(43.2668) | Bit/dim 4.2053(4.3683) | Xent 0.0000(0.0000) | Loss 9.7515(10.5415) | Error 0.0000(0.0000) Steps 502(477.66) | Grad Norm 7.4350(8.6328) | Total Time 0.00(0.00)\n",
      "Iter 0285 | Time 43.5499(43.2753) | Bit/dim 4.1800(4.3627) | Xent 0.0000(0.0000) | Loss 9.6401(10.5144) | Error 0.0000(0.0000) Steps 472(477.49) | Grad Norm 6.7450(8.5762) | Total Time 0.00(0.00)\n",
      "Iter 0286 | Time 41.3331(43.2171) | Bit/dim 4.1692(4.3569) | Xent 0.0000(0.0000) | Loss 9.7435(10.4913) | Error 0.0000(0.0000) Steps 478(477.51) | Grad Norm 5.5828(8.4864) | Total Time 0.00(0.00)\n",
      "Iter 0287 | Time 44.3209(43.2502) | Bit/dim 4.1466(4.3506) | Xent 0.0000(0.0000) | Loss 9.7866(10.4702) | Error 0.0000(0.0000) Steps 496(478.06) | Grad Norm 3.9142(8.3492) | Total Time 0.00(0.00)\n",
      "Iter 0288 | Time 45.4368(43.3158) | Bit/dim 4.1480(4.3445) | Xent 0.0000(0.0000) | Loss 9.4492(10.4395) | Error 0.0000(0.0000) Steps 484(478.24) | Grad Norm 4.3700(8.2298) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 20.6558, Epoch Time 298.2999(314.1228), Bit/dim 4.1605(best: 4.2003), Xent 0.0000, Loss 4.1605, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0289 | Time 42.9464(43.3047) | Bit/dim 4.1643(4.3391) | Xent 0.0000(0.0000) | Loss 12.6637(10.5063) | Error 0.0000(0.0000) Steps 478(478.23) | Grad Norm 8.2986(8.2319) | Total Time 0.00(0.00)\n",
      "Iter 0290 | Time 43.3247(43.3053) | Bit/dim 4.1945(4.3347) | Xent 0.0000(0.0000) | Loss 9.8433(10.4864) | Error 0.0000(0.0000) Steps 484(478.40) | Grad Norm 12.5830(8.3624) | Total Time 0.00(0.00)\n",
      "Iter 0291 | Time 45.8236(43.3809) | Bit/dim 4.2059(4.3309) | Xent 0.0000(0.0000) | Loss 9.5369(10.4579) | Error 0.0000(0.0000) Steps 490(478.75) | Grad Norm 13.1885(8.5072) | Total Time 0.00(0.00)\n",
      "Iter 0292 | Time 42.3168(43.3489) | Bit/dim 4.1972(4.3269) | Xent 0.0000(0.0000) | Loss 9.3502(10.4247) | Error 0.0000(0.0000) Steps 466(478.37) | Grad Norm 9.8387(8.5472) | Total Time 0.00(0.00)\n",
      "Iter 0293 | Time 45.2209(43.4051) | Bit/dim 4.1663(4.3220) | Xent 0.0000(0.0000) | Loss 9.6068(10.4001) | Error 0.0000(0.0000) Steps 478(478.36) | Grad Norm 7.2704(8.5089) | Total Time 0.00(0.00)\n",
      "Iter 0294 | Time 43.6923(43.4137) | Bit/dim 4.1906(4.3181) | Xent 0.0000(0.0000) | Loss 9.5198(10.3737) | Error 0.0000(0.0000) Steps 472(478.17) | Grad Norm 12.3168(8.6231) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 21.3594, Epoch Time 304.2751(313.8273), Bit/dim 4.1690(best: 4.1605), Xent 0.0000, Loss 4.1690, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0295 | Time 44.6643(43.4512) | Bit/dim 4.1737(4.3138) | Xent 0.0000(0.0000) | Loss 13.0898(10.4552) | Error 0.0000(0.0000) Steps 508(479.06) | Grad Norm 10.1652(8.6694) | Total Time 0.00(0.00)\n",
      "Iter 0296 | Time 43.7767(43.4610) | Bit/dim 4.1381(4.3085) | Xent 0.0000(0.0000) | Loss 9.6192(10.4301) | Error 0.0000(0.0000) Steps 484(479.21) | Grad Norm 5.1251(8.5630) | Total Time 0.00(0.00)\n",
      "Iter 0297 | Time 45.6281(43.5260) | Bit/dim 4.1552(4.3039) | Xent 0.0000(0.0000) | Loss 9.7035(10.4083) | Error 0.0000(0.0000) Steps 490(479.53) | Grad Norm 11.1683(8.6412) | Total Time 0.00(0.00)\n",
      "Iter 0298 | Time 45.8186(43.5948) | Bit/dim 4.1323(4.2988) | Xent 0.0000(0.0000) | Loss 9.4986(10.3810) | Error 0.0000(0.0000) Steps 508(480.39) | Grad Norm 8.3761(8.6332) | Total Time 0.00(0.00)\n",
      "Iter 0299 | Time 45.7196(43.6585) | Bit/dim 4.1401(4.2940) | Xent 0.0000(0.0000) | Loss 9.4747(10.3538) | Error 0.0000(0.0000) Steps 478(480.32) | Grad Norm 5.8375(8.5494) | Total Time 0.00(0.00)\n",
      "Iter 0300 | Time 44.6019(43.6868) | Bit/dim 4.1306(4.2891) | Xent 0.0000(0.0000) | Loss 9.5909(10.3309) | Error 0.0000(0.0000) Steps 490(480.61) | Grad Norm 7.0447(8.5042) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 21.7334, Epoch Time 310.5635(313.7294), Bit/dim 4.1201(best: 4.1605), Xent 0.0000, Loss 4.1201, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0301 | Time 48.9438(43.8445) | Bit/dim 4.1138(4.2838) | Xent 0.0000(0.0000) | Loss 12.9657(10.4100) | Error 0.0000(0.0000) Steps 520(481.79) | Grad Norm 6.6920(8.4499) | Total Time 0.00(0.00)\n",
      "Iter 0302 | Time 41.4095(43.7715) | Bit/dim 4.1403(4.2795) | Xent 0.0000(0.0000) | Loss 9.3783(10.3790) | Error 0.0000(0.0000) Steps 460(481.14) | Grad Norm 10.4766(8.5107) | Total Time 0.00(0.00)\n",
      "Iter 0303 | Time 42.8255(43.7431) | Bit/dim 4.2112(4.2775) | Xent 0.0000(0.0000) | Loss 9.7480(10.3601) | Error 0.0000(0.0000) Steps 484(481.22) | Grad Norm 18.1184(8.7989) | Total Time 0.00(0.00)\n",
      "Iter 0304 | Time 46.0257(43.8116) | Bit/dim 4.5492(4.2856) | Xent 0.0000(0.0000) | Loss 10.6903(10.3700) | Error 0.0000(0.0000) Steps 496(481.67) | Grad Norm 32.3453(9.5053) | Total Time 0.00(0.00)\n",
      "Iter 0305 | Time 42.2307(43.7642) | Bit/dim 4.2548(4.2847) | Xent 0.0000(0.0000) | Loss 9.7670(10.3519) | Error 0.0000(0.0000) Steps 502(482.28) | Grad Norm 14.3552(9.6508) | Total Time 0.00(0.00)\n",
      "Iter 0306 | Time 44.3338(43.7812) | Bit/dim 4.2257(4.2829) | Xent 0.0000(0.0000) | Loss 9.5750(10.3286) | Error 0.0000(0.0000) Steps 496(482.69) | Grad Norm 8.3482(9.6117) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 21.2386, Epoch Time 305.5854(313.4851), Bit/dim 4.2520(best: 4.1201), Xent 0.0000, Loss 4.2520, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0307 | Time 39.4294(43.6507) | Bit/dim 4.2517(4.2820) | Xent 0.0000(0.0000) | Loss 12.7346(10.4008) | Error 0.0000(0.0000) Steps 460(482.01) | Grad Norm 14.4095(9.7556) | Total Time 0.00(0.00)\n",
      "Iter 0308 | Time 40.5846(43.5587) | Bit/dim 4.2434(4.2808) | Xent 0.0000(0.0000) | Loss 9.9648(10.3877) | Error 0.0000(0.0000) Steps 472(481.71) | Grad Norm 10.8495(9.7884) | Total Time 0.00(0.00)\n",
      "Iter 0309 | Time 42.5640(43.5289) | Bit/dim 4.2101(4.2787) | Xent 0.0000(0.0000) | Loss 9.5479(10.3625) | Error 0.0000(0.0000) Steps 478(481.59) | Grad Norm 7.3381(9.7149) | Total Time 0.00(0.00)\n",
      "Iter 0310 | Time 44.3368(43.5531) | Bit/dim 4.1933(4.2762) | Xent 0.0000(0.0000) | Loss 9.8668(10.3477) | Error 0.0000(0.0000) Steps 508(482.39) | Grad Norm 5.5449(9.5898) | Total Time 0.00(0.00)\n",
      "Iter 0311 | Time 41.5776(43.4938) | Bit/dim 4.1857(4.2734) | Xent 0.0000(0.0000) | Loss 9.7027(10.3283) | Error 0.0000(0.0000) Steps 484(482.44) | Grad Norm 8.7242(9.5639) | Total Time 0.00(0.00)\n",
      "Iter 0312 | Time 43.4315(43.4920) | Bit/dim 4.1516(4.2698) | Xent 0.0000(0.0000) | Loss 9.5167(10.3040) | Error 0.0000(0.0000) Steps 484(482.48) | Grad Norm 5.3559(9.4376) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 20.7621, Epoch Time 291.8477(312.8360), Bit/dim 4.1455(best: 4.1201), Xent 0.0000, Loss 4.1455, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0313 | Time 45.2503(43.5447) | Bit/dim 4.1521(4.2663) | Xent 0.0000(0.0000) | Loss 13.0007(10.3849) | Error 0.0000(0.0000) Steps 520(483.61) | Grad Norm 7.6155(9.3830) | Total Time 0.00(0.00)\n",
      "Iter 0314 | Time 42.0393(43.4996) | Bit/dim 4.1430(4.2626) | Xent 0.0000(0.0000) | Loss 9.5586(10.3601) | Error 0.0000(0.0000) Steps 490(483.80) | Grad Norm 4.0938(9.2243) | Total Time 0.00(0.00)\n",
      "Iter 0315 | Time 47.1197(43.6082) | Bit/dim 4.1377(4.2588) | Xent 0.0000(0.0000) | Loss 9.6630(10.3392) | Error 0.0000(0.0000) Steps 520(484.89) | Grad Norm 7.2823(9.1660) | Total Time 0.00(0.00)\n",
      "Iter 0316 | Time 43.8331(43.6149) | Bit/dim 4.1060(4.2542) | Xent 0.0000(0.0000) | Loss 9.3464(10.3094) | Error 0.0000(0.0000) Steps 508(485.58) | Grad Norm 3.9970(9.0110) | Total Time 0.00(0.00)\n",
      "Iter 0317 | Time 46.0957(43.6893) | Bit/dim 4.1089(4.2499) | Xent 0.0000(0.0000) | Loss 9.4775(10.2844) | Error 0.0000(0.0000) Steps 484(485.53) | Grad Norm 5.8656(8.9166) | Total Time 0.00(0.00)\n",
      "Iter 0318 | Time 51.0739(43.9109) | Bit/dim 4.0891(4.2450) | Xent 0.0000(0.0000) | Loss 9.1500(10.2504) | Error 0.0000(0.0000) Steps 472(485.13) | Grad Norm 3.9308(8.7670) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 20.9823, Epoch Time 314.7677(312.8939), Bit/dim 4.0920(best: 4.1201), Xent 0.0000, Loss 4.0920, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0319 | Time 51.9112(44.1509) | Bit/dim 4.0904(4.2404) | Xent 0.0000(0.0000) | Loss 12.6136(10.3213) | Error 0.0000(0.0000) Steps 466(484.55) | Grad Norm 4.9447(8.6524) | Total Time 0.00(0.00)\n",
      "Iter 0320 | Time 47.4224(44.2490) | Bit/dim 4.0763(4.2355) | Xent 0.0000(0.0000) | Loss 9.3132(10.2910) | Error 0.0000(0.0000) Steps 466(484.00) | Grad Norm 3.7250(8.5045) | Total Time 0.00(0.00)\n",
      "Iter 0321 | Time 51.0012(44.4516) | Bit/dim 4.0815(4.2309) | Xent 0.0000(0.0000) | Loss 9.4078(10.2645) | Error 0.0000(0.0000) Steps 472(483.64) | Grad Norm 4.4418(8.3827) | Total Time 0.00(0.00)\n",
      "Iter 0322 | Time 48.2861(44.5666) | Bit/dim 4.0635(4.2258) | Xent 0.0000(0.0000) | Loss 9.2318(10.2336) | Error 0.0000(0.0000) Steps 454(482.75) | Grad Norm 4.0054(8.2513) | Total Time 0.00(0.00)\n",
      "Iter 0323 | Time 47.3708(44.6508) | Bit/dim 4.0650(4.2210) | Xent 0.0000(0.0000) | Loss 9.1797(10.2019) | Error 0.0000(0.0000) Steps 454(481.88) | Grad Norm 2.9984(8.0937) | Total Time 0.00(0.00)\n",
      "Iter 0324 | Time 52.4470(44.8846) | Bit/dim 4.0482(4.2158) | Xent 0.0000(0.0000) | Loss 9.3883(10.1775) | Error 0.0000(0.0000) Steps 496(482.31) | Grad Norm 4.0024(7.9710) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 20.5614, Epoch Time 337.7928(313.6409), Bit/dim 4.0434(best: 4.0920), Xent 0.0000, Loss 4.0434, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0325 | Time 49.0745(45.0103) | Bit/dim 4.0455(4.2107) | Xent 0.0000(0.0000) | Loss 12.4953(10.2471) | Error 0.0000(0.0000) Steps 490(482.54) | Grad Norm 2.8289(7.8167) | Total Time 0.00(0.00)\n",
      "Iter 0326 | Time 45.5727(45.0272) | Bit/dim 4.0389(4.2056) | Xent 0.0000(0.0000) | Loss 9.4317(10.2226) | Error 0.0000(0.0000) Steps 448(481.50) | Grad Norm 3.6357(7.6913) | Total Time 0.00(0.00)\n",
      "Iter 0327 | Time 47.8850(45.1129) | Bit/dim 4.0259(4.2002) | Xent 0.0000(0.0000) | Loss 9.1756(10.1912) | Error 0.0000(0.0000) Steps 472(481.22) | Grad Norm 2.9631(7.5495) | Total Time 0.00(0.00)\n",
      "Iter 0328 | Time 49.1793(45.2349) | Bit/dim 4.0299(4.1951) | Xent 0.0000(0.0000) | Loss 9.4189(10.1680) | Error 0.0000(0.0000) Steps 460(480.58) | Grad Norm 2.9313(7.4109) | Total Time 0.00(0.00)\n",
      "Iter 0329 | Time 45.7533(45.2505) | Bit/dim 4.0268(4.1900) | Xent 0.0000(0.0000) | Loss 9.2778(10.1413) | Error 0.0000(0.0000) Steps 454(479.78) | Grad Norm 2.9741(7.2778) | Total Time 0.00(0.00)\n",
      "Iter 0330 | Time 51.0960(45.4258) | Bit/dim 4.0111(4.1847) | Xent 0.0000(0.0000) | Loss 9.2751(10.1153) | Error 0.0000(0.0000) Steps 484(479.91) | Grad Norm 2.8685(7.1455) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 21.2487, Epoch Time 328.5920(314.0894), Bit/dim 4.0069(best: 4.0434), Xent 0.0000, Loss 4.0069, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0331 | Time 44.7274(45.4049) | Bit/dim 4.0104(4.1794) | Xent 0.0000(0.0000) | Loss 12.1701(10.1770) | Error 0.0000(0.0000) Steps 454(479.13) | Grad Norm 3.0255(7.0219) | Total Time 0.00(0.00)\n",
      "Iter 0332 | Time 49.8055(45.5369) | Bit/dim 3.9982(4.1740) | Xent 0.0000(0.0000) | Loss 9.2412(10.1489) | Error 0.0000(0.0000) Steps 484(479.28) | Grad Norm 3.2112(6.9076) | Total Time 0.00(0.00)\n",
      "Iter 0333 | Time 51.3612(45.7116) | Bit/dim 4.0076(4.1690) | Xent 0.0000(0.0000) | Loss 9.2505(10.1220) | Error 0.0000(0.0000) Steps 466(478.88) | Grad Norm 2.2314(6.7673) | Total Time 0.00(0.00)\n",
      "Iter 0334 | Time 46.4973(45.7352) | Bit/dim 4.0036(4.1640) | Xent 0.0000(0.0000) | Loss 9.3165(10.0978) | Error 0.0000(0.0000) Steps 478(478.85) | Grad Norm 4.2411(6.6915) | Total Time 0.00(0.00)\n",
      "Iter 0335 | Time 54.2073(45.9894) | Bit/dim 4.0001(4.1591) | Xent 0.0000(0.0000) | Loss 9.2337(10.0719) | Error 0.0000(0.0000) Steps 490(479.19) | Grad Norm 3.8617(6.6067) | Total Time 0.00(0.00)\n",
      "Iter 0336 | Time 49.4637(46.0936) | Bit/dim 3.9884(4.1540) | Xent 0.0000(0.0000) | Loss 9.1803(10.0451) | Error 0.0000(0.0000) Steps 472(478.97) | Grad Norm 3.6368(6.5176) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 22.0897, Epoch Time 337.0885(314.7794), Bit/dim 3.9929(best: 4.0069), Xent 0.0000, Loss 3.9929, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0337 | Time 51.6854(46.2614) | Bit/dim 3.9854(4.1489) | Xent 0.0000(0.0000) | Loss 12.7476(10.1262) | Error 0.0000(0.0000) Steps 496(479.48) | Grad Norm 5.2050(6.4782) | Total Time 0.00(0.00)\n",
      "Iter 0338 | Time 49.3488(46.3540) | Bit/dim 3.9879(4.1441) | Xent 0.0000(0.0000) | Loss 9.1611(10.0972) | Error 0.0000(0.0000) Steps 478(479.44) | Grad Norm 6.2180(6.4704) | Total Time 0.00(0.00)\n",
      "Iter 0339 | Time 50.3382(46.4735) | Bit/dim 3.9996(4.1398) | Xent 0.0000(0.0000) | Loss 9.3154(10.0738) | Error 0.0000(0.0000) Steps 490(479.76) | Grad Norm 6.5522(6.4728) | Total Time 0.00(0.00)\n",
      "Iter 0340 | Time 47.7549(46.5119) | Bit/dim 3.9931(4.1354) | Xent 0.0000(0.0000) | Loss 9.1344(10.0456) | Error 0.0000(0.0000) Steps 472(479.52) | Grad Norm 5.9588(6.4574) | Total Time 0.00(0.00)\n",
      "Iter 0341 | Time 48.4712(46.5707) | Bit/dim 3.9810(4.1307) | Xent 0.0000(0.0000) | Loss 9.1642(10.0192) | Error 0.0000(0.0000) Steps 484(479.66) | Grad Norm 4.8470(6.4091) | Total Time 0.00(0.00)\n",
      "Iter 0342 | Time 50.8554(46.6993) | Bit/dim 3.9720(4.1260) | Xent 0.0000(0.0000) | Loss 9.2903(9.9973) | Error 0.0000(0.0000) Steps 490(479.97) | Grad Norm 3.9543(6.3355) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 21.6169, Epoch Time 339.0053(315.5062), Bit/dim 3.9732(best: 3.9929), Xent 0.0000, Loss 3.9732, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0343 | Time 50.7363(46.8204) | Bit/dim 3.9744(4.1214) | Xent 0.0000(0.0000) | Loss 12.1493(10.0619) | Error 0.0000(0.0000) Steps 502(480.63) | Grad Norm 4.1923(6.2712) | Total Time 0.00(0.00)\n",
      "Iter 0344 | Time 45.8366(46.7909) | Bit/dim 3.9690(4.1169) | Xent 0.0000(0.0000) | Loss 9.3178(10.0395) | Error 0.0000(0.0000) Steps 490(480.91) | Grad Norm 4.9382(6.2312) | Total Time 0.00(0.00)\n",
      "Iter 0345 | Time 52.8289(46.9720) | Bit/dim 3.9744(4.1126) | Xent 0.0000(0.0000) | Loss 9.2973(10.0173) | Error 0.0000(0.0000) Steps 502(481.54) | Grad Norm 6.2382(6.2314) | Total Time 0.00(0.00)\n",
      "Iter 0346 | Time 47.9296(47.0007) | Bit/dim 3.9988(4.1092) | Xent 0.0000(0.0000) | Loss 9.3835(9.9983) | Error 0.0000(0.0000) Steps 490(481.80) | Grad Norm 7.2053(6.2606) | Total Time 0.00(0.00)\n",
      "Iter 0347 | Time 50.0368(47.0918) | Bit/dim 3.9980(4.1058) | Xent 0.0000(0.0000) | Loss 9.3270(9.9781) | Error 0.0000(0.0000) Steps 496(482.22) | Grad Norm 8.0529(6.3144) | Total Time 0.00(0.00)\n",
      "Iter 0348 | Time 54.8700(47.3252) | Bit/dim 3.9855(4.1022) | Xent 0.0000(0.0000) | Loss 9.2258(9.9555) | Error 0.0000(0.0000) Steps 496(482.64) | Grad Norm 9.7840(6.4185) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 21.4332, Epoch Time 342.3136(316.3104), Bit/dim 3.9952(best: 3.9732), Xent 0.0000, Loss 3.9952, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0349 | Time 46.3050(47.2946) | Bit/dim 3.9973(4.0991) | Xent 0.0000(0.0000) | Loss 12.2194(10.0235) | Error 0.0000(0.0000) Steps 460(481.96) | Grad Norm 11.3178(6.5654) | Total Time 0.00(0.00)\n",
      "Iter 0350 | Time 49.3079(47.3550) | Bit/dim 3.9898(4.0958) | Xent 0.0000(0.0000) | Loss 9.2495(10.0002) | Error 0.0000(0.0000) Steps 484(482.02) | Grad Norm 11.5695(6.7156) | Total Time 0.00(0.00)\n",
      "Iter 0351 | Time 49.1810(47.4097) | Bit/dim 3.9781(4.0923) | Xent 0.0000(0.0000) | Loss 9.2158(9.9767) | Error 0.0000(0.0000) Steps 478(481.90) | Grad Norm 8.4254(6.7669) | Total Time 0.00(0.00)\n",
      "Iter 0352 | Time 51.2201(47.5240) | Bit/dim 3.9613(4.0883) | Xent 0.0000(0.0000) | Loss 8.9782(9.9468) | Error 0.0000(0.0000) Steps 490(482.14) | Grad Norm 5.2650(6.7218) | Total Time 0.00(0.00)\n",
      "Iter 0353 | Time 53.3200(47.6979) | Bit/dim 3.9754(4.0850) | Xent 0.0000(0.0000) | Loss 9.2806(9.9268) | Error 0.0000(0.0000) Steps 502(482.74) | Grad Norm 10.2334(6.8271) | Total Time 0.00(0.00)\n",
      "Iter 0354 | Time 48.8062(47.7312) | Bit/dim 3.9631(4.0813) | Xent 0.0000(0.0000) | Loss 9.0903(9.9017) | Error 0.0000(0.0000) Steps 478(482.59) | Grad Norm 7.0722(6.8345) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 21.1931, Epoch Time 337.8858(316.9577), Bit/dim 3.9545(best: 3.9732), Xent 0.0000, Loss 3.9545, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0355 | Time 48.6271(47.7580) | Bit/dim 3.9512(4.0774) | Xent 0.0000(0.0000) | Loss 12.2827(9.9731) | Error 0.0000(0.0000) Steps 472(482.28) | Grad Norm 4.4363(6.7626) | Total Time 0.00(0.00)\n",
      "Iter 0356 | Time 51.5549(47.8720) | Bit/dim 3.9564(4.0738) | Xent 0.0000(0.0000) | Loss 9.3421(9.9542) | Error 0.0000(0.0000) Steps 478(482.15) | Grad Norm 7.6587(6.7894) | Total Time 0.00(0.00)\n",
      "Iter 0357 | Time 55.6568(48.1055) | Bit/dim 3.9454(4.0699) | Xent 0.0000(0.0000) | Loss 9.1162(9.9290) | Error 0.0000(0.0000) Steps 508(482.92) | Grad Norm 5.5136(6.7512) | Total Time 0.00(0.00)\n",
      "Iter 0358 | Time 54.5280(48.2982) | Bit/dim 3.9581(4.0666) | Xent 0.0000(0.0000) | Loss 9.2312(9.9081) | Error 0.0000(0.0000) Steps 490(483.14) | Grad Norm 4.6446(6.6880) | Total Time 0.00(0.00)\n",
      "Iter 0359 | Time 54.4041(48.4814) | Bit/dim 3.9465(4.0630) | Xent 0.0000(0.0000) | Loss 9.2464(9.8882) | Error 0.0000(0.0000) Steps 496(483.52) | Grad Norm 4.4516(6.6209) | Total Time 0.00(0.00)\n",
      "Iter 0360 | Time 50.5321(48.5429) | Bit/dim 3.9346(4.0591) | Xent 0.0000(0.0000) | Loss 9.0208(9.8622) | Error 0.0000(0.0000) Steps 496(483.90) | Grad Norm 4.9773(6.5716) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 21.4785, Epoch Time 355.6160(318.1174), Bit/dim 3.9446(best: 3.9545), Xent 0.0000, Loss 3.9446, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0361 | Time 51.3588(48.6273) | Bit/dim 3.9274(4.0552) | Xent 0.0000(0.0000) | Loss 12.3072(9.9356) | Error 0.0000(0.0000) Steps 490(484.08) | Grad Norm 5.8228(6.5491) | Total Time 0.00(0.00)\n",
      "Iter 0362 | Time 51.4094(48.7108) | Bit/dim 3.9251(4.0513) | Xent 0.0000(0.0000) | Loss 8.9320(9.9055) | Error 0.0000(0.0000) Steps 478(483.90) | Grad Norm 2.6465(6.4320) | Total Time 0.00(0.00)\n",
      "Iter 0363 | Time 51.4110(48.7918) | Bit/dim 3.9278(4.0476) | Xent 0.0000(0.0000) | Loss 9.0390(9.8795) | Error 0.0000(0.0000) Steps 478(483.72) | Grad Norm 4.9788(6.3884) | Total Time 0.00(0.00)\n",
      "Iter 0364 | Time 48.7839(48.7916) | Bit/dim 3.9311(4.0441) | Xent 0.0000(0.0000) | Loss 8.8560(9.8488) | Error 0.0000(0.0000) Steps 472(483.37) | Grad Norm 5.2829(6.3553) | Total Time 0.00(0.00)\n",
      "Iter 0365 | Time 50.0303(48.8287) | Bit/dim 3.9118(4.0401) | Xent 0.0000(0.0000) | Loss 9.2806(9.8317) | Error 0.0000(0.0000) Steps 496(483.75) | Grad Norm 3.7505(6.2771) | Total Time 0.00(0.00)\n",
      "Iter 0366 | Time 54.8206(49.0085) | Bit/dim 3.9348(4.0369) | Xent 0.0000(0.0000) | Loss 9.2231(9.8135) | Error 0.0000(0.0000) Steps 502(484.29) | Grad Norm 5.3117(6.2482) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 21.0488, Epoch Time 347.2235(318.9906), Bit/dim 3.9203(best: 3.9446), Xent 0.0000, Loss 3.9203, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0367 | Time 58.3039(49.2874) | Bit/dim 3.9307(4.0337) | Xent 0.0000(0.0000) | Loss 12.2565(9.8868) | Error 0.0000(0.0000) Steps 484(484.29) | Grad Norm 5.3787(6.2221) | Total Time 0.00(0.00)\n",
      "Iter 0368 | Time 53.5525(49.4153) | Bit/dim 3.9305(4.0307) | Xent 0.0000(0.0000) | Loss 9.2761(9.8684) | Error 0.0000(0.0000) Steps 508(485.00) | Grad Norm 8.4450(6.2888) | Total Time 0.00(0.00)\n",
      "Iter 0369 | Time 52.4107(49.5052) | Bit/dim 3.9313(4.0277) | Xent 0.0000(0.0000) | Loss 9.3738(9.8536) | Error 0.0000(0.0000) Steps 502(485.51) | Grad Norm 10.2351(6.4072) | Total Time 0.00(0.00)\n",
      "Iter 0370 | Time 55.7573(49.6927) | Bit/dim 3.9273(4.0247) | Xent 0.0000(0.0000) | Loss 9.2427(9.8353) | Error 0.0000(0.0000) Steps 490(485.64) | Grad Norm 8.5911(6.4727) | Total Time 0.00(0.00)\n",
      "Iter 0371 | Time 46.5698(49.5990) | Bit/dim 3.9401(4.0221) | Xent 0.0000(0.0000) | Loss 9.1115(9.8136) | Error 0.0000(0.0000) Steps 466(485.05) | Grad Norm 6.4850(6.4730) | Total Time 0.00(0.00)\n",
      "Iter 0372 | Time 49.2036(49.5872) | Bit/dim 3.9224(4.0191) | Xent 0.0000(0.0000) | Loss 9.2155(9.7956) | Error 0.0000(0.0000) Steps 490(485.20) | Grad Norm 4.8054(6.4230) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 20.8338, Epoch Time 355.2340(320.0779), Bit/dim 3.9097(best: 3.9203), Xent 0.0000, Loss 3.9097, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0373 | Time 50.8035(49.6237) | Bit/dim 3.8990(4.0155) | Xent 0.0000(0.0000) | Loss 12.3001(9.8708) | Error 0.0000(0.0000) Steps 478(484.99) | Grad Norm 4.3464(6.3607) | Total Time 0.00(0.00)\n",
      "Iter 0374 | Time 48.7676(49.5980) | Bit/dim 3.9229(4.0127) | Xent 0.0000(0.0000) | Loss 9.1470(9.8490) | Error 0.0000(0.0000) Steps 484(484.96) | Grad Norm 5.0201(6.3205) | Total Time 0.00(0.00)\n",
      "Iter 0375 | Time 52.7835(49.6936) | Bit/dim 3.9150(4.0098) | Xent 0.0000(0.0000) | Loss 9.2216(9.8302) | Error 0.0000(0.0000) Steps 496(485.29) | Grad Norm 5.4210(6.2935) | Total Time 0.00(0.00)\n",
      "Iter 0376 | Time 51.1611(49.7376) | Bit/dim 3.9029(4.0066) | Xent 0.0000(0.0000) | Loss 9.0544(9.8069) | Error 0.0000(0.0000) Steps 472(484.89) | Grad Norm 5.6402(6.2739) | Total Time 0.00(0.00)\n",
      "Iter 0377 | Time 50.6372(49.7646) | Bit/dim 3.9007(4.0034) | Xent 0.0000(0.0000) | Loss 9.0552(9.7844) | Error 0.0000(0.0000) Steps 496(485.22) | Grad Norm 4.9607(6.2345) | Total Time 0.00(0.00)\n",
      "Iter 0378 | Time 48.3411(49.7219) | Bit/dim 3.9023(4.0004) | Xent 0.0000(0.0000) | Loss 9.0600(9.7627) | Error 0.0000(0.0000) Steps 466(484.65) | Grad Norm 4.3746(6.1787) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 21.5627, Epoch Time 343.5590(320.7823), Bit/dim 3.9010(best: 3.9097), Xent 0.0000, Loss 3.9010, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0379 | Time 49.2882(49.7089) | Bit/dim 3.9052(3.9975) | Xent 0.0000(0.0000) | Loss 11.9991(9.8297) | Error 0.0000(0.0000) Steps 478(484.45) | Grad Norm 5.6995(6.1643) | Total Time 0.00(0.00)\n",
      "Iter 0380 | Time 49.5069(49.7028) | Bit/dim 3.9089(3.9949) | Xent 0.0000(0.0000) | Loss 9.1840(9.8104) | Error 0.0000(0.0000) Steps 484(484.43) | Grad Norm 6.5882(6.1771) | Total Time 0.00(0.00)\n",
      "Iter 0381 | Time 50.7173(49.7332) | Bit/dim 3.8874(3.9917) | Xent 0.0000(0.0000) | Loss 8.9005(9.7831) | Error 0.0000(0.0000) Steps 484(484.42) | Grad Norm 4.4454(6.1251) | Total Time 0.00(0.00)\n",
      "Iter 0382 | Time 51.9287(49.7991) | Bit/dim 3.8948(3.9888) | Xent 0.0000(0.0000) | Loss 9.2428(9.7669) | Error 0.0000(0.0000) Steps 484(484.41) | Grad Norm 4.6687(6.0814) | Total Time 0.00(0.00)\n",
      "Iter 0383 | Time 55.8748(49.9814) | Bit/dim 3.9061(3.9863) | Xent 0.0000(0.0000) | Loss 9.2151(9.7503) | Error 0.0000(0.0000) Steps 508(485.11) | Grad Norm 5.5621(6.0658) | Total Time 0.00(0.00)\n",
      "Iter 0384 | Time 52.9131(50.0693) | Bit/dim 3.9098(3.9840) | Xent 0.0000(0.0000) | Loss 8.8420(9.7231) | Error 0.0000(0.0000) Steps 496(485.44) | Grad Norm 5.8950(6.0607) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 21.4586, Epoch Time 350.2615(321.6667), Bit/dim 3.9219(best: 3.9010), Xent 0.0000, Loss 3.9219, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0385 | Time 50.7874(50.0909) | Bit/dim 3.9186(3.9820) | Xent 0.0000(0.0000) | Loss 12.2398(9.7986) | Error 0.0000(0.0000) Steps 478(485.22) | Grad Norm 7.0633(6.0908) | Total Time 0.00(0.00)\n",
      "Iter 0386 | Time 54.7673(50.2312) | Bit/dim 3.8984(3.9795) | Xent 0.0000(0.0000) | Loss 9.1002(9.7776) | Error 0.0000(0.0000) Steps 508(485.90) | Grad Norm 6.6111(6.1064) | Total Time 0.00(0.00)\n",
      "Iter 0387 | Time 52.7290(50.3061) | Bit/dim 3.8951(3.9770) | Xent 0.0000(0.0000) | Loss 9.0110(9.7546) | Error 0.0000(0.0000) Steps 508(486.56) | Grad Norm 7.2439(6.1405) | Total Time 0.00(0.00)\n",
      "Iter 0388 | Time 54.6328(50.4359) | Bit/dim 3.9010(3.9747) | Xent 0.0000(0.0000) | Loss 9.0939(9.7348) | Error 0.0000(0.0000) Steps 490(486.67) | Grad Norm 7.8312(6.1912) | Total Time 0.00(0.00)\n",
      "Iter 0389 | Time 44.8927(50.2696) | Bit/dim 3.9020(3.9725) | Xent 0.0000(0.0000) | Loss 8.8060(9.7069) | Error 0.0000(0.0000) Steps 466(486.05) | Grad Norm 8.6285(6.2644) | Total Time 0.00(0.00)\n",
      "Iter 0390 | Time 49.3170(50.2410) | Bit/dim 3.8951(3.9702) | Xent 0.0000(0.0000) | Loss 8.8355(9.6808) | Error 0.0000(0.0000) Steps 478(485.81) | Grad Norm 8.0874(6.3191) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 21.9019, Epoch Time 348.1261(322.4605), Bit/dim 3.8960(best: 3.9010), Xent 0.0000, Loss 3.8960, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0391 | Time 50.3460(50.2442) | Bit/dim 3.8842(3.9676) | Xent 0.0000(0.0000) | Loss 12.3061(9.7596) | Error 0.0000(0.0000) Steps 478(485.57) | Grad Norm 8.3537(6.3801) | Total Time 0.00(0.00)\n",
      "Iter 0392 | Time 47.9148(50.1743) | Bit/dim 3.9327(3.9666) | Xent 0.0000(0.0000) | Loss 9.1965(9.7427) | Error 0.0000(0.0000) Steps 496(485.88) | Grad Norm 9.7817(6.4821) | Total Time 0.00(0.00)\n",
      "Iter 0393 | Time 53.6398(50.2783) | Bit/dim 3.9284(3.9654) | Xent 0.0000(0.0000) | Loss 9.2019(9.7264) | Error 0.0000(0.0000) Steps 484(485.83) | Grad Norm 8.7401(6.5499) | Total Time 0.00(0.00)\n",
      "Iter 0394 | Time 54.4627(50.4038) | Bit/dim 3.9193(3.9640) | Xent 0.0000(0.0000) | Loss 9.0698(9.7067) | Error 0.0000(0.0000) Steps 484(485.77) | Grad Norm 7.9799(6.5928) | Total Time 0.00(0.00)\n",
      "Iter 0395 | Time 56.1966(50.5776) | Bit/dim 3.9130(3.9625) | Xent 0.0000(0.0000) | Loss 9.0705(9.6876) | Error 0.0000(0.0000) Steps 508(486.44) | Grad Norm 7.7095(6.6263) | Total Time 0.00(0.00)\n",
      "Iter 0396 | Time 50.9950(50.5901) | Bit/dim 3.8931(3.9604) | Xent 0.0000(0.0000) | Loss 9.0122(9.6674) | Error 0.0000(0.0000) Steps 484(486.37) | Grad Norm 5.8223(6.6022) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 20.5858, Epoch Time 352.0899(323.3494), Bit/dim 3.8912(best: 3.8960), Xent 0.0000, Loss 3.8912, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0397 | Time 50.9625(50.6013) | Bit/dim 3.8915(3.9584) | Xent 0.0000(0.0000) | Loss 12.0144(9.7378) | Error 0.0000(0.0000) Steps 496(486.66) | Grad Norm 5.3989(6.5661) | Total Time 0.00(0.00)\n",
      "Iter 0398 | Time 54.6792(50.7236) | Bit/dim 3.9016(3.9567) | Xent 0.0000(0.0000) | Loss 9.3238(9.7254) | Error 0.0000(0.0000) Steps 496(486.94) | Grad Norm 7.0101(6.5794) | Total Time 0.00(0.00)\n",
      "Iter 0399 | Time 48.0341(50.6429) | Bit/dim 3.8979(3.9549) | Xent 0.0000(0.0000) | Loss 9.2712(9.7118) | Error 0.0000(0.0000) Steps 496(487.21) | Grad Norm 5.1391(6.5362) | Total Time 0.00(0.00)\n",
      "Iter 0400 | Time 49.8139(50.6181) | Bit/dim 3.8890(3.9529) | Xent 0.0000(0.0000) | Loss 9.1070(9.6936) | Error 0.0000(0.0000) Steps 472(486.75) | Grad Norm 5.8168(6.5146) | Total Time 0.00(0.00)\n",
      "Iter 0401 | Time 51.5687(50.6466) | Bit/dim 3.8847(3.9509) | Xent 0.0000(0.0000) | Loss 8.8606(9.6686) | Error 0.0000(0.0000) Steps 490(486.85) | Grad Norm 7.2383(6.5363) | Total Time 0.00(0.00)\n",
      "Iter 0402 | Time 51.3049(50.6663) | Bit/dim 3.8922(3.9491) | Xent 0.0000(0.0000) | Loss 9.1351(9.6526) | Error 0.0000(0.0000) Steps 472(486.40) | Grad Norm 5.9368(6.5183) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 22.1135, Epoch Time 347.4943(324.0737), Bit/dim 3.8705(best: 3.8912), Xent 0.0000, Loss 3.8705, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0403 | Time 50.1901(50.6520) | Bit/dim 3.8734(3.9468) | Xent 0.0000(0.0000) | Loss 12.3186(9.7326) | Error 0.0000(0.0000) Steps 472(485.97) | Grad Norm 3.9244(6.4405) | Total Time 0.00(0.00)\n",
      "Iter 0404 | Time 53.7853(50.7460) | Bit/dim 3.8807(3.9449) | Xent 0.0000(0.0000) | Loss 9.1947(9.7165) | Error 0.0000(0.0000) Steps 490(486.09) | Grad Norm 5.7172(6.4188) | Total Time 0.00(0.00)\n",
      "Iter 0405 | Time 52.1740(50.7889) | Bit/dim 3.8698(3.9426) | Xent 0.0000(0.0000) | Loss 9.1816(9.7004) | Error 0.0000(0.0000) Steps 490(486.21) | Grad Norm 5.1815(6.3817) | Total Time 0.00(0.00)\n",
      "Iter 0406 | Time 53.6908(50.8759) | Bit/dim 3.8517(3.9399) | Xent 0.0000(0.0000) | Loss 8.7799(9.6728) | Error 0.0000(0.0000) Steps 484(486.14) | Grad Norm 3.0551(6.2819) | Total Time 0.00(0.00)\n",
      "Iter 0407 | Time 52.2073(50.9159) | Bit/dim 3.8677(3.9377) | Xent 0.0000(0.0000) | Loss 9.0693(9.6547) | Error 0.0000(0.0000) Steps 472(485.72) | Grad Norm 5.7117(6.2648) | Total Time 0.00(0.00)\n",
      "Iter 0408 | Time 49.6862(50.8790) | Bit/dim 3.8613(3.9354) | Xent 0.0000(0.0000) | Loss 9.0771(9.6374) | Error 0.0000(0.0000) Steps 484(485.67) | Grad Norm 4.6611(6.2167) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 21.2471, Epoch Time 351.1421(324.8858), Bit/dim 3.8493(best: 3.8705), Xent 0.0000, Loss 3.8493, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0409 | Time 52.8798(50.9390) | Bit/dim 3.8426(3.9326) | Xent 0.0000(0.0000) | Loss 12.0019(9.7083) | Error 0.0000(0.0000) Steps 484(485.62) | Grad Norm 4.0144(6.1506) | Total Time 0.00(0.00)\n",
      "Iter 0410 | Time 50.4864(50.9254) | Bit/dim 3.8550(3.9303) | Xent 0.0000(0.0000) | Loss 9.0862(9.6896) | Error 0.0000(0.0000) Steps 478(485.39) | Grad Norm 6.8183(6.1706) | Total Time 0.00(0.00)\n",
      "Iter 0411 | Time 54.3133(51.0271) | Bit/dim 3.8708(3.9285) | Xent 0.0000(0.0000) | Loss 9.1247(9.6727) | Error 0.0000(0.0000) Steps 484(485.35) | Grad Norm 8.2399(6.2327) | Total Time 0.00(0.00)\n",
      "Iter 0412 | Time 54.0649(51.1182) | Bit/dim 3.8568(3.9264) | Xent 0.0000(0.0000) | Loss 9.0666(9.6545) | Error 0.0000(0.0000) Steps 502(485.85) | Grad Norm 7.4903(6.2704) | Total Time 0.00(0.00)\n",
      "Iter 0413 | Time 51.6611(51.1345) | Bit/dim 3.8894(3.9253) | Xent 0.0000(0.0000) | Loss 8.8697(9.6310) | Error 0.0000(0.0000) Steps 478(485.61) | Grad Norm 6.9805(6.2917) | Total Time 0.00(0.00)\n",
      "Iter 0414 | Time 53.3395(51.2006) | Bit/dim 3.8661(3.9235) | Xent 0.0000(0.0000) | Loss 9.2170(9.6185) | Error 0.0000(0.0000) Steps 496(485.92) | Grad Norm 5.7432(6.2753) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 21.4674, Epoch Time 357.0697(325.8513), Bit/dim 3.8740(best: 3.8493), Xent 0.0000, Loss 3.8740, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0415 | Time 54.2883(51.2933) | Bit/dim 3.8689(3.9218) | Xent 0.0000(0.0000) | Loss 12.2759(9.6983) | Error 0.0000(0.0000) Steps 484(485.87) | Grad Norm 6.9911(6.2968) | Total Time 0.00(0.00)\n",
      "Iter 0416 | Time 51.0386(51.2856) | Bit/dim 3.8840(3.9207) | Xent 0.0000(0.0000) | Loss 9.2158(9.6838) | Error 0.0000(0.0000) Steps 490(485.99) | Grad Norm 9.5740(6.3951) | Total Time 0.00(0.00)\n",
      "Iter 0417 | Time 53.2708(51.3452) | Bit/dim 3.8817(3.9195) | Xent 0.0000(0.0000) | Loss 9.1805(9.6687) | Error 0.0000(0.0000) Steps 514(486.83) | Grad Norm 9.9841(6.5028) | Total Time 0.00(0.00)\n",
      "Iter 0418 | Time 50.6859(51.3254) | Bit/dim 3.8597(3.9177) | Xent 0.0000(0.0000) | Loss 9.1707(9.6537) | Error 0.0000(0.0000) Steps 490(486.92) | Grad Norm 7.0982(6.5206) | Total Time 0.00(0.00)\n",
      "Iter 0419 | Time 58.2078(51.5319) | Bit/dim 3.8643(3.9161) | Xent 0.0000(0.0000) | Loss 9.2050(9.6403) | Error 0.0000(0.0000) Steps 514(487.74) | Grad Norm 6.0887(6.5077) | Total Time 0.00(0.00)\n",
      "Iter 0420 | Time 55.3492(51.6464) | Bit/dim 3.8531(3.9142) | Xent 0.0000(0.0000) | Loss 9.1468(9.6255) | Error 0.0000(0.0000) Steps 496(487.99) | Grad Norm 4.5314(6.4484) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 22.0523, Epoch Time 363.6789(326.9861), Bit/dim 3.8358(best: 3.8493), Xent 0.0000, Loss 3.8358, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0421 | Time 50.6658(51.6170) | Bit/dim 3.8420(3.9121) | Xent 0.0000(0.0000) | Loss 12.2133(9.7031) | Error 0.0000(0.0000) Steps 472(487.51) | Grad Norm 4.4799(6.3893) | Total Time 0.00(0.00)\n",
      "Iter 0422 | Time 51.8058(51.6226) | Bit/dim 3.8287(3.9096) | Xent 0.0000(0.0000) | Loss 8.8452(9.6774) | Error 0.0000(0.0000) Steps 484(487.40) | Grad Norm 4.4590(6.3314) | Total Time 0.00(0.00)\n",
      "Iter 0423 | Time 55.1509(51.7285) | Bit/dim 3.8358(3.9074) | Xent 0.0000(0.0000) | Loss 8.9973(9.6570) | Error 0.0000(0.0000) Steps 484(487.30) | Grad Norm 3.4959(6.2463) | Total Time 0.00(0.00)\n",
      "Iter 0424 | Time 52.9208(51.7643) | Bit/dim 3.8313(3.9051) | Xent 0.0000(0.0000) | Loss 8.8601(9.6331) | Error 0.0000(0.0000) Steps 478(487.02) | Grad Norm 3.9597(6.1777) | Total Time 0.00(0.00)\n",
      "Iter 0425 | Time 53.6402(51.8205) | Bit/dim 3.8208(3.9026) | Xent 0.0000(0.0000) | Loss 8.9806(9.6135) | Error 0.0000(0.0000) Steps 490(487.11) | Grad Norm 3.5481(6.0989) | Total Time 0.00(0.00)\n",
      "Iter 0426 | Time 51.1067(51.7991) | Bit/dim 3.8216(3.9001) | Xent 0.0000(0.0000) | Loss 8.9177(9.5926) | Error 0.0000(0.0000) Steps 484(487.02) | Grad Norm 3.5710(6.0230) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 21.4012, Epoch Time 355.6869(327.8471), Bit/dim 3.8287(best: 3.8358), Xent 0.0000, Loss 3.8287, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0427 | Time 51.2000(51.7811) | Bit/dim 3.8189(3.8977) | Xent 0.0000(0.0000) | Loss 12.0959(9.6677) | Error 0.0000(0.0000) Steps 490(487.11) | Grad Norm 4.1538(5.9669) | Total Time 0.00(0.00)\n",
      "Iter 0428 | Time 51.9747(51.7870) | Bit/dim 3.8181(3.8953) | Xent 0.0000(0.0000) | Loss 8.7902(9.6414) | Error 0.0000(0.0000) Steps 490(487.19) | Grad Norm 4.2257(5.9147) | Total Time 0.00(0.00)\n",
      "Iter 0429 | Time 57.7181(51.9649) | Bit/dim 3.8255(3.8932) | Xent 0.0000(0.0000) | Loss 9.1112(9.6255) | Error 0.0000(0.0000) Steps 514(488.00) | Grad Norm 5.3676(5.8983) | Total Time 0.00(0.00)\n",
      "Iter 0430 | Time 52.1695(51.9710) | Bit/dim 3.8231(3.8911) | Xent 0.0000(0.0000) | Loss 8.9270(9.6045) | Error 0.0000(0.0000) Steps 490(488.06) | Grad Norm 8.9041(5.9885) | Total Time 0.00(0.00)\n",
      "Iter 0431 | Time 55.4005(52.0739) | Bit/dim 3.8802(3.8908) | Xent 0.0000(0.0000) | Loss 8.9419(9.5847) | Error 0.0000(0.0000) Steps 484(487.93) | Grad Norm 11.2919(6.1476) | Total Time 0.00(0.00)\n",
      "Iter 0432 | Time 53.8474(52.1271) | Bit/dim 3.8353(3.8891) | Xent 0.0000(0.0000) | Loss 8.9751(9.5664) | Error 0.0000(0.0000) Steps 490(488.00) | Grad Norm 7.0163(6.1736) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 21.2886, Epoch Time 364.4530(328.9453), Bit/dim 3.8236(best: 3.8287), Xent 0.0000, Loss 3.8236, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0433 | Time 53.8108(52.1776) | Bit/dim 3.8168(3.8869) | Xent 0.0000(0.0000) | Loss 12.2085(9.6456) | Error 0.0000(0.0000) Steps 496(488.24) | Grad Norm 5.1327(6.1424) | Total Time 0.00(0.00)\n",
      "Iter 0434 | Time 59.3177(52.3918) | Bit/dim 3.8430(3.8856) | Xent 0.0000(0.0000) | Loss 9.0900(9.6290) | Error 0.0000(0.0000) Steps 502(488.65) | Grad Norm 9.1375(6.2323) | Total Time 0.00(0.00)\n",
      "Iter 0435 | Time 48.9676(52.2891) | Bit/dim 3.8452(3.8844) | Xent 0.0000(0.0000) | Loss 9.0392(9.6113) | Error 0.0000(0.0000) Steps 484(488.51) | Grad Norm 7.5950(6.2731) | Total Time 0.00(0.00)\n",
      "Iter 0436 | Time 55.3461(52.3808) | Bit/dim 3.8676(3.8839) | Xent 0.0000(0.0000) | Loss 9.1443(9.5973) | Error 0.0000(0.0000) Steps 502(488.91) | Grad Norm 7.6728(6.3151) | Total Time 0.00(0.00)\n",
      "Iter 0437 | Time 50.0231(52.3101) | Bit/dim 3.9087(3.8846) | Xent 0.0000(0.0000) | Loss 9.0826(9.5818) | Error 0.0000(0.0000) Steps 478(488.59) | Grad Norm 8.1359(6.3697) | Total Time 0.00(0.00)\n",
      "Iter 0438 | Time 57.2225(52.4575) | Bit/dim 3.8927(3.8849) | Xent 0.0000(0.0000) | Loss 9.1615(9.5692) | Error 0.0000(0.0000) Steps 490(488.63) | Grad Norm 7.8381(6.4138) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 21.4121, Epoch Time 365.5543(330.0436), Bit/dim 3.8679(best: 3.8236), Xent 0.0000, Loss 3.8679, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0439 | Time 51.3020(52.4228) | Bit/dim 3.8605(3.8842) | Xent 0.0000(0.0000) | Loss 12.0272(9.6430) | Error 0.0000(0.0000) Steps 484(488.49) | Grad Norm 7.3491(6.4419) | Total Time 0.00(0.00)\n",
      "Iter 0440 | Time 52.8825(52.4366) | Bit/dim 3.8710(3.8838) | Xent 0.0000(0.0000) | Loss 9.1104(9.6270) | Error 0.0000(0.0000) Steps 490(488.54) | Grad Norm 6.9128(6.4560) | Total Time 0.00(0.00)\n",
      "Iter 0441 | Time 55.3725(52.5247) | Bit/dim 3.8751(3.8835) | Xent 0.0000(0.0000) | Loss 8.9689(9.6072) | Error 0.0000(0.0000) Steps 532(489.84) | Grad Norm 8.5749(6.5196) | Total Time 0.00(0.00)\n",
      "Iter 0442 | Time 53.8627(52.5648) | Bit/dim 3.8619(3.8829) | Xent 0.0000(0.0000) | Loss 9.0417(9.5903) | Error 0.0000(0.0000) Steps 478(489.48) | Grad Norm 6.5253(6.5197) | Total Time 0.00(0.00)\n",
      "Iter 0443 | Time 50.6415(52.5071) | Bit/dim 3.8464(3.8818) | Xent 0.0000(0.0000) | Loss 8.8575(9.5683) | Error 0.0000(0.0000) Steps 478(489.14) | Grad Norm 4.5203(6.4597) | Total Time 0.00(0.00)\n",
      "Iter 0444 | Time 55.1355(52.5860) | Bit/dim 3.8568(3.8810) | Xent 0.0000(0.0000) | Loss 9.0917(9.5540) | Error 0.0000(0.0000) Steps 502(489.53) | Grad Norm 5.0152(6.4164) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 21.7738, Epoch Time 359.5308(330.9282), Bit/dim 3.8276(best: 3.8236), Xent 0.0000, Loss 3.8276, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0445 | Time 53.1374(52.6025) | Bit/dim 3.8199(3.8792) | Xent 0.0000(0.0000) | Loss 11.6177(9.6159) | Error 0.0000(0.0000) Steps 490(489.54) | Grad Norm 4.1882(6.3496) | Total Time 0.00(0.00)\n",
      "Iter 0446 | Time 52.7326(52.6064) | Bit/dim 3.8251(3.8776) | Xent 0.0000(0.0000) | Loss 9.0720(9.5996) | Error 0.0000(0.0000) Steps 502(489.91) | Grad Norm 5.3522(6.3196) | Total Time 0.00(0.00)\n",
      "Iter 0447 | Time 51.3729(52.5694) | Bit/dim 3.8314(3.8762) | Xent 0.0000(0.0000) | Loss 8.9061(9.5788) | Error 0.0000(0.0000) Steps 490(489.92) | Grad Norm 3.6678(6.2401) | Total Time 0.00(0.00)\n",
      "Iter 0448 | Time 55.8452(52.6677) | Bit/dim 3.8387(3.8751) | Xent 0.0000(0.0000) | Loss 9.0657(9.5634) | Error 0.0000(0.0000) Steps 502(490.28) | Grad Norm 4.7473(6.1953) | Total Time 0.00(0.00)\n",
      "Iter 0449 | Time 55.5249(52.7534) | Bit/dim 3.8034(3.8729) | Xent 0.0000(0.0000) | Loss 8.6703(9.5366) | Error 0.0000(0.0000) Steps 496(490.45) | Grad Norm 4.0863(6.1320) | Total Time 0.00(0.00)\n",
      "Iter 0450 | Time 55.6168(52.8393) | Bit/dim 3.8191(3.8713) | Xent 0.0000(0.0000) | Loss 8.8215(9.5151) | Error 0.0000(0.0000) Steps 478(490.08) | Grad Norm 3.7667(6.0611) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 21.3605, Epoch Time 364.7797(331.9437), Bit/dim 3.8093(best: 3.8236), Xent 0.0000, Loss 3.8093, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0451 | Time 53.5999(52.8621) | Bit/dim 3.8077(3.8694) | Xent 0.0000(0.0000) | Loss 12.0537(9.5913) | Error 0.0000(0.0000) Steps 478(489.71) | Grad Norm 3.8144(5.9937) | Total Time 0.00(0.00)\n",
      "Iter 0452 | Time 51.7254(52.8280) | Bit/dim 3.8075(3.8675) | Xent 0.0000(0.0000) | Loss 8.9376(9.5717) | Error 0.0000(0.0000) Steps 490(489.72) | Grad Norm 3.9149(5.9313) | Total Time 0.00(0.00)\n",
      "Iter 0453 | Time 55.5049(52.9083) | Bit/dim 3.7983(3.8654) | Xent 0.0000(0.0000) | Loss 9.0543(9.5562) | Error 0.0000(0.0000) Steps 502(490.09) | Grad Norm 4.6038(5.8915) | Total Time 0.00(0.00)\n",
      "Iter 0454 | Time 57.6130(53.0495) | Bit/dim 3.8074(3.8637) | Xent 0.0000(0.0000) | Loss 8.8881(9.5361) | Error 0.0000(0.0000) Steps 508(490.63) | Grad Norm 6.4651(5.9087) | Total Time 0.00(0.00)\n",
      "Iter 0455 | Time 52.6610(53.0378) | Bit/dim 3.8288(3.8627) | Xent 0.0000(0.0000) | Loss 9.0214(9.5207) | Error 0.0000(0.0000) Steps 496(490.79) | Grad Norm 8.6852(5.9920) | Total Time 0.00(0.00)\n",
      "Iter 0456 | Time 49.1149(52.9201) | Bit/dim 3.8232(3.8615) | Xent 0.0000(0.0000) | Loss 9.0473(9.5065) | Error 0.0000(0.0000) Steps 484(490.59) | Grad Norm 8.7853(6.0758) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 21.7426, Epoch Time 361.2923(332.8242), Bit/dim 3.8053(best: 3.8093), Xent 0.0000, Loss 3.8053, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0457 | Time 52.5907(52.9102) | Bit/dim 3.7982(3.8596) | Xent 0.0000(0.0000) | Loss 12.1272(9.5851) | Error 0.0000(0.0000) Steps 490(490.57) | Grad Norm 5.8276(6.0683) | Total Time 0.00(0.00)\n",
      "Iter 0458 | Time 54.1196(52.9465) | Bit/dim 3.8010(3.8578) | Xent 0.0000(0.0000) | Loss 8.9347(9.5656) | Error 0.0000(0.0000) Steps 484(490.37) | Grad Norm 3.0783(5.9786) | Total Time 0.00(0.00)\n",
      "Iter 0459 | Time 53.6686(52.9682) | Bit/dim 3.7845(3.8556) | Xent 0.0000(0.0000) | Loss 8.9327(9.5466) | Error 0.0000(0.0000) Steps 496(490.54) | Grad Norm 5.4734(5.9635) | Total Time 0.00(0.00)\n",
      "Iter 0460 | Time 54.7159(53.0206) | Bit/dim 3.8086(3.8542) | Xent 0.0000(0.0000) | Loss 8.9137(9.5276) | Error 0.0000(0.0000) Steps 502(490.88) | Grad Norm 6.3816(5.9760) | Total Time 0.00(0.00)\n",
      "Iter 0461 | Time 50.4885(52.9446) | Bit/dim 3.7975(3.8525) | Xent 0.0000(0.0000) | Loss 8.8245(9.5065) | Error 0.0000(0.0000) Steps 472(490.32) | Grad Norm 4.8413(5.9420) | Total Time 0.00(0.00)\n",
      "Iter 0462 | Time 51.7586(52.9091) | Bit/dim 3.7941(3.8508) | Xent 0.0000(0.0000) | Loss 9.0251(9.4921) | Error 0.0000(0.0000) Steps 508(490.85) | Grad Norm 3.8793(5.8801) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 20.7460, Epoch Time 356.3387(333.5296), Bit/dim 3.8037(best: 3.8053), Xent 0.0000, Loss 3.8037, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0463 | Time 51.2552(52.8594) | Bit/dim 3.8064(3.8494) | Xent 0.0000(0.0000) | Loss 12.0189(9.5679) | Error 0.0000(0.0000) Steps 478(490.46) | Grad Norm 5.5304(5.8696) | Total Time 0.00(0.00)\n",
      "Iter 0464 | Time 50.2095(52.7799) | Bit/dim 3.8122(3.8483) | Xent 0.0000(0.0000) | Loss 8.9143(9.5483) | Error 0.0000(0.0000) Steps 478(490.09) | Grad Norm 8.6037(5.9516) | Total Time 0.00(0.00)\n",
      "Iter 0465 | Time 47.6222(52.6252) | Bit/dim 3.8619(3.8487) | Xent 0.0000(0.0000) | Loss 8.8009(9.5259) | Error 0.0000(0.0000) Steps 466(489.37) | Grad Norm 9.8583(6.0688) | Total Time 0.00(0.00)\n",
      "Iter 0466 | Time 50.7503(52.5690) | Bit/dim 3.8576(3.8490) | Xent 0.0000(0.0000) | Loss 9.1202(9.5137) | Error 0.0000(0.0000) Steps 484(489.21) | Grad Norm 9.8248(6.1815) | Total Time 0.00(0.00)\n",
      "Iter 0467 | Time 47.8024(52.4260) | Bit/dim 3.8512(3.8490) | Xent 0.0000(0.0000) | Loss 8.9462(9.4967) | Error 0.0000(0.0000) Steps 472(488.69) | Grad Norm 8.9885(6.2657) | Total Time 0.00(0.00)\n",
      "Iter 0468 | Time 51.7831(52.4067) | Bit/dim 3.8147(3.8480) | Xent 0.0000(0.0000) | Loss 8.8986(9.4787) | Error 0.0000(0.0000) Steps 478(488.37) | Grad Norm 5.8902(6.2545) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 22.0846, Epoch Time 340.2828(333.7322), Bit/dim 3.8421(best: 3.8037), Xent 0.0000, Loss 3.8421, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0469 | Time 52.1397(52.3987) | Bit/dim 3.8489(3.8480) | Xent 0.0000(0.0000) | Loss 12.3248(9.5641) | Error 0.0000(0.0000) Steps 496(488.60) | Grad Norm 6.9874(6.2765) | Total Time 0.00(0.00)\n",
      "Iter 0470 | Time 52.4980(52.4016) | Bit/dim 3.8125(3.8470) | Xent 0.0000(0.0000) | Loss 9.1110(9.5505) | Error 0.0000(0.0000) Steps 496(488.82) | Grad Norm 4.9752(6.2374) | Total Time 0.00(0.00)\n",
      "Iter 0471 | Time 52.1646(52.3945) | Bit/dim 3.8158(3.8460) | Xent 0.0000(0.0000) | Loss 8.8770(9.5303) | Error 0.0000(0.0000) Steps 496(489.03) | Grad Norm 4.6835(6.1908) | Total Time 0.00(0.00)\n",
      "Iter 0472 | Time 51.9881(52.3823) | Bit/dim 3.8358(3.8457) | Xent 0.0000(0.0000) | Loss 8.9452(9.5127) | Error 0.0000(0.0000) Steps 484(488.88) | Grad Norm 7.1842(6.2206) | Total Time 0.00(0.00)\n",
      "Iter 0473 | Time 53.4672(52.4149) | Bit/dim 3.8105(3.8447) | Xent 0.0000(0.0000) | Loss 8.9917(9.4971) | Error 0.0000(0.0000) Steps 502(489.28) | Grad Norm 5.9110(6.2113) | Total Time 0.00(0.00)\n",
      "Iter 0474 | Time 54.1739(52.4677) | Bit/dim 3.8193(3.8439) | Xent 0.0000(0.0000) | Loss 8.7037(9.4733) | Error 0.0000(0.0000) Steps 496(489.48) | Grad Norm 6.5084(6.2202) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 22.2706, Epoch Time 356.6335(334.4193), Bit/dim 3.7971(best: 3.8037), Xent 0.0000, Loss 3.7971, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0475 | Time 54.8754(52.5399) | Bit/dim 3.7925(3.8424) | Xent 0.0000(0.0000) | Loss 11.7573(9.5418) | Error 0.0000(0.0000) Steps 496(489.67) | Grad Norm 4.6370(6.1727) | Total Time 0.00(0.00)\n",
      "Iter 0476 | Time 51.6369(52.5128) | Bit/dim 3.8089(3.8414) | Xent 0.0000(0.0000) | Loss 8.9917(9.5253) | Error 0.0000(0.0000) Steps 490(489.68) | Grad Norm 5.4618(6.1514) | Total Time 0.00(0.00)\n",
      "Iter 0477 | Time 49.7736(52.4306) | Bit/dim 3.8036(3.8402) | Xent 0.0000(0.0000) | Loss 8.6665(9.4996) | Error 0.0000(0.0000) Steps 484(489.51) | Grad Norm 4.3266(6.0967) | Total Time 0.00(0.00)\n",
      "Iter 0478 | Time 54.5360(52.4938) | Bit/dim 3.7752(3.8383) | Xent 0.0000(0.0000) | Loss 8.7757(9.4779) | Error 0.0000(0.0000) Steps 502(489.89) | Grad Norm 4.6728(6.0539) | Total Time 0.00(0.00)\n",
      "Iter 0479 | Time 52.7295(52.5009) | Bit/dim 3.8029(3.8372) | Xent 0.0000(0.0000) | Loss 9.0540(9.4651) | Error 0.0000(0.0000) Steps 496(490.07) | Grad Norm 5.9762(6.0516) | Total Time 0.00(0.00)\n",
      "Iter 0480 | Time 52.9418(52.5141) | Bit/dim 3.7811(3.8355) | Xent 0.0000(0.0000) | Loss 8.8028(9.4453) | Error 0.0000(0.0000) Steps 490(490.07) | Grad Norm 4.0296(5.9909) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 22.1323, Epoch Time 357.7047(335.1178), Bit/dim 3.7812(best: 3.7971), Xent 0.0000, Loss 3.7812, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0481 | Time 55.2140(52.5951) | Bit/dim 3.7793(3.8339) | Xent 0.0000(0.0000) | Loss 12.0507(9.5234) | Error 0.0000(0.0000) Steps 496(490.25) | Grad Norm 3.5472(5.9176) | Total Time 0.00(0.00)\n",
      "Iter 0482 | Time 49.7119(52.5086) | Bit/dim 3.7786(3.8322) | Xent 0.0000(0.0000) | Loss 9.0171(9.5082) | Error 0.0000(0.0000) Steps 490(490.24) | Grad Norm 3.8449(5.8555) | Total Time 0.00(0.00)\n",
      "Iter 0483 | Time 52.6428(52.5126) | Bit/dim 3.7841(3.8308) | Xent 0.0000(0.0000) | Loss 8.7916(9.4867) | Error 0.0000(0.0000) Steps 496(490.41) | Grad Norm 4.9370(5.8279) | Total Time 0.00(0.00)\n",
      "Iter 0484 | Time 54.5435(52.5735) | Bit/dim 3.7875(3.8295) | Xent 0.0000(0.0000) | Loss 8.8030(9.4662) | Error 0.0000(0.0000) Steps 502(490.76) | Grad Norm 6.6005(5.8511) | Total Time 0.00(0.00)\n",
      "Iter 0485 | Time 55.2930(52.6551) | Bit/dim 3.8049(3.8287) | Xent 0.0000(0.0000) | Loss 8.8681(9.4483) | Error 0.0000(0.0000) Steps 502(491.10) | Grad Norm 8.4912(5.9303) | Total Time 0.00(0.00)\n",
      "Iter 0486 | Time 52.1554(52.6401) | Bit/dim 3.7894(3.8276) | Xent 0.0000(0.0000) | Loss 8.9037(9.4319) | Error 0.0000(0.0000) Steps 478(490.70) | Grad Norm 9.8872(6.0490) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 22.6515, Epoch Time 360.9559(335.8930), Bit/dim 3.8149(best: 3.7812), Xent 0.0000, Loss 3.8149, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0487 | Time 52.7023(52.6420) | Bit/dim 3.8192(3.8273) | Xent 0.0000(0.0000) | Loss 12.2064(9.5152) | Error 0.0000(0.0000) Steps 496(490.86) | Grad Norm 8.8600(6.1333) | Total Time 0.00(0.00)\n",
      "Iter 0488 | Time 60.9354(52.8908) | Bit/dim 3.8060(3.8267) | Xent 0.0000(0.0000) | Loss 9.1757(9.5050) | Error 0.0000(0.0000) Steps 520(491.74) | Grad Norm 5.3656(6.1103) | Total Time 0.00(0.00)\n",
      "Iter 0489 | Time 51.3943(52.8459) | Bit/dim 3.8073(3.8261) | Xent 0.0000(0.0000) | Loss 8.8009(9.4839) | Error 0.0000(0.0000) Steps 478(491.33) | Grad Norm 6.3844(6.1185) | Total Time 0.00(0.00)\n",
      "Iter 0490 | Time 52.7474(52.8430) | Bit/dim 3.7961(3.8252) | Xent 0.0000(0.0000) | Loss 8.7672(9.4624) | Error 0.0000(0.0000) Steps 502(491.65) | Grad Norm 7.0557(6.1466) | Total Time 0.00(0.00)\n",
      "Iter 0491 | Time 56.3559(52.9483) | Bit/dim 3.7805(3.8238) | Xent 0.0000(0.0000) | Loss 8.8829(9.4450) | Error 0.0000(0.0000) Steps 526(492.68) | Grad Norm 4.4109(6.0946) | Total Time 0.00(0.00)\n",
      "Iter 0492 | Time 55.2888(53.0186) | Bit/dim 3.7807(3.8225) | Xent 0.0000(0.0000) | Loss 9.0017(9.4317) | Error 0.0000(0.0000) Steps 502(492.96) | Grad Norm 4.9089(6.0590) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 22.3233, Epoch Time 369.1905(336.8919), Bit/dim 3.7916(best: 3.7812), Xent 0.0000, Loss 3.7916, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0493 | Time 54.1485(53.0525) | Bit/dim 3.7835(3.8214) | Xent 0.0000(0.0000) | Loss 12.2935(9.5175) | Error 0.0000(0.0000) Steps 502(493.23) | Grad Norm 5.2798(6.0356) | Total Time 0.00(0.00)\n",
      "Iter 0494 | Time 51.7890(53.0145) | Bit/dim 3.7866(3.8203) | Xent 0.0000(0.0000) | Loss 8.9534(9.5006) | Error 0.0000(0.0000) Steps 490(493.13) | Grad Norm 4.6133(5.9929) | Total Time 0.00(0.00)\n",
      "Iter 0495 | Time 55.5218(53.0898) | Bit/dim 3.7801(3.8191) | Xent 0.0000(0.0000) | Loss 8.7687(9.4787) | Error 0.0000(0.0000) Steps 496(493.22) | Grad Norm 3.6731(5.9233) | Total Time 0.00(0.00)\n",
      "Iter 0496 | Time 52.4229(53.0698) | Bit/dim 3.7672(3.8176) | Xent 0.0000(0.0000) | Loss 8.8015(9.4583) | Error 0.0000(0.0000) Steps 490(493.12) | Grad Norm 3.6787(5.8560) | Total Time 0.00(0.00)\n",
      "Iter 0497 | Time 55.1707(53.1328) | Bit/dim 3.7687(3.8161) | Xent 0.0000(0.0000) | Loss 8.9379(9.4427) | Error 0.0000(0.0000) Steps 484(492.85) | Grad Norm 3.5829(5.7878) | Total Time 0.00(0.00)\n",
      "Iter 0498 | Time 58.4922(53.2936) | Bit/dim 3.7615(3.8145) | Xent 0.0000(0.0000) | Loss 8.5498(9.4159) | Error 0.0000(0.0000) Steps 496(492.94) | Grad Norm 3.3174(5.7137) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 21.7089, Epoch Time 368.3050(337.8343), Bit/dim 3.7681(best: 3.7812), Xent 0.0000, Loss 3.7681, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0499 | Time 49.5912(53.1825) | Bit/dim 3.7678(3.8131) | Xent 0.0000(0.0000) | Loss 11.0439(9.4648) | Error 0.0000(0.0000) Steps 484(492.67) | Grad Norm 3.3747(5.6435) | Total Time 0.00(0.00)\n",
      "Iter 0500 | Time 54.2578(53.2148) | Bit/dim 3.7585(3.8114) | Xent 0.0000(0.0000) | Loss 8.6157(9.4393) | Error 0.0000(0.0000) Steps 478(492.23) | Grad Norm 2.9815(5.5637) | Total Time 0.00(0.00)\n",
      "Iter 0501 | Time 55.8817(53.2948) | Bit/dim 3.7620(3.8099) | Xent 0.0000(0.0000) | Loss 8.7920(9.4199) | Error 0.0000(0.0000) Steps 490(492.17) | Grad Norm 4.1198(5.5204) | Total Time 0.00(0.00)\n",
      "Iter 0502 | Time 54.7682(53.3390) | Bit/dim 3.7490(3.8081) | Xent 0.0000(0.0000) | Loss 8.8998(9.4043) | Error 0.0000(0.0000) Steps 496(492.28) | Grad Norm 5.4073(5.5170) | Total Time 0.00(0.00)\n",
      "Iter 0503 | Time 57.2548(53.4564) | Bit/dim 3.7628(3.8068) | Xent 0.0000(0.0000) | Loss 9.0160(9.3926) | Error 0.0000(0.0000) Steps 508(492.75) | Grad Norm 6.9572(5.5602) | Total Time 0.00(0.00)\n",
      "Iter 0504 | Time 52.4742(53.4270) | Bit/dim 3.7730(3.8057) | Xent 0.0000(0.0000) | Loss 8.8670(9.3769) | Error 0.0000(0.0000) Steps 502(493.03) | Grad Norm 7.8522(5.6289) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 22.5138, Epoch Time 365.8700(338.6754), Bit/dim 3.7722(best: 3.7681), Xent 0.0000, Loss 3.7722, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0505 | Time 52.0976(53.3871) | Bit/dim 3.7585(3.8043) | Xent 0.0000(0.0000) | Loss 12.2657(9.4635) | Error 0.0000(0.0000) Steps 502(493.30) | Grad Norm 7.6760(5.6903) | Total Time 0.00(0.00)\n",
      "Iter 0506 | Time 49.3416(53.2657) | Bit/dim 3.7970(3.8041) | Xent 0.0000(0.0000) | Loss 8.8929(9.4464) | Error 0.0000(0.0000) Steps 490(493.20) | Grad Norm 7.8989(5.7566) | Total Time 0.00(0.00)\n",
      "Iter 0507 | Time 52.9044(53.2549) | Bit/dim 3.8312(3.8049) | Xent 0.0000(0.0000) | Loss 9.0037(9.4331) | Error 0.0000(0.0000) Steps 496(493.28) | Grad Norm 10.0355(5.8850) | Total Time 0.00(0.00)\n",
      "Iter 0508 | Time 54.4610(53.2911) | Bit/dim 3.8601(3.8066) | Xent 0.0000(0.0000) | Loss 8.9953(9.4200) | Error 0.0000(0.0000) Steps 496(493.37) | Grad Norm 9.1293(5.9823) | Total Time 0.00(0.00)\n",
      "Iter 0509 | Time 56.0401(53.3735) | Bit/dim 3.7767(3.8057) | Xent 0.0000(0.0000) | Loss 9.0575(9.4091) | Error 0.0000(0.0000) Steps 502(493.62) | Grad Norm 3.9198(5.9204) | Total Time 0.00(0.00)\n",
      "Iter 0510 | Time 57.9688(53.5114) | Bit/dim 3.8229(3.8062) | Xent 0.0000(0.0000) | Loss 9.1668(9.4019) | Error 0.0000(0.0000) Steps 508(494.06) | Grad Norm 8.3516(5.9934) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 21.8456, Epoch Time 364.2061(339.4413), Bit/dim 3.8164(best: 3.7681), Xent 0.0000, Loss 3.8164, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0511 | Time 51.4177(53.4486) | Bit/dim 3.8114(3.8064) | Xent 0.0000(0.0000) | Loss 12.2169(9.4863) | Error 0.0000(0.0000) Steps 484(493.75) | Grad Norm 6.2362(6.0006) | Total Time 0.00(0.00)\n",
      "Iter 0512 | Time 57.2451(53.5625) | Bit/dim 3.8064(3.8064) | Xent 0.0000(0.0000) | Loss 9.0394(9.4729) | Error 0.0000(0.0000) Steps 520(494.54) | Grad Norm 8.9523(6.0892) | Total Time 0.00(0.00)\n",
      "Iter 0513 | Time 51.6403(53.5048) | Bit/dim 3.8325(3.8071) | Xent 0.0000(0.0000) | Loss 9.1117(9.4621) | Error 0.0000(0.0000) Steps 484(494.23) | Grad Norm 8.6463(6.1659) | Total Time 0.00(0.00)\n",
      "Iter 0514 | Time 54.5912(53.5374) | Bit/dim 3.8085(3.8072) | Xent 0.0000(0.0000) | Loss 9.0114(9.4485) | Error 0.0000(0.0000) Steps 502(494.46) | Grad Norm 5.1476(6.1354) | Total Time 0.00(0.00)\n",
      "Iter 0515 | Time 49.6985(53.4222) | Bit/dim 3.8013(3.8070) | Xent 0.0000(0.0000) | Loss 8.9294(9.4330) | Error 0.0000(0.0000) Steps 496(494.50) | Grad Norm 5.5062(6.1165) | Total Time 0.00(0.00)\n",
      "Iter 0516 | Time 53.4618(53.4234) | Bit/dim 3.7924(3.8066) | Xent 0.0000(0.0000) | Loss 9.0708(9.4221) | Error 0.0000(0.0000) Steps 502(494.73) | Grad Norm 4.8294(6.0779) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 21.9676, Epoch Time 358.4595(340.0118), Bit/dim 3.7880(best: 3.7681), Xent 0.0000, Loss 3.7880, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0517 | Time 53.6540(53.4304) | Bit/dim 3.7894(3.8060) | Xent 0.0000(0.0000) | Loss 12.2722(9.5076) | Error 0.0000(0.0000) Steps 514(495.31) | Grad Norm 5.2263(6.0523) | Total Time 0.00(0.00)\n",
      "Iter 0518 | Time 53.6788(53.4378) | Bit/dim 3.7804(3.8053) | Xent 0.0000(0.0000) | Loss 8.9312(9.4903) | Error 0.0000(0.0000) Steps 502(495.51) | Grad Norm 5.0796(6.0231) | Total Time 0.00(0.00)\n",
      "Iter 0519 | Time 52.2340(53.4017) | Bit/dim 3.7805(3.8045) | Xent 0.0000(0.0000) | Loss 8.8626(9.4715) | Error 0.0000(0.0000) Steps 490(495.34) | Grad Norm 5.7029(6.0135) | Total Time 0.00(0.00)\n",
      "Iter 0520 | Time 54.0855(53.4222) | Bit/dim 3.7672(3.8034) | Xent 0.0000(0.0000) | Loss 8.8884(9.4540) | Error 0.0000(0.0000) Steps 490(495.18) | Grad Norm 4.5317(5.9691) | Total Time 0.00(0.00)\n",
      "Iter 0521 | Time 52.4392(53.3927) | Bit/dim 3.7716(3.8025) | Xent 0.0000(0.0000) | Loss 8.9004(9.4374) | Error 0.0000(0.0000) Steps 496(495.21) | Grad Norm 4.4976(5.9249) | Total Time 0.00(0.00)\n",
      "Iter 0522 | Time 49.0879(53.2636) | Bit/dim 3.7769(3.8017) | Xent 0.0000(0.0000) | Loss 8.4330(9.4072) | Error 0.0000(0.0000) Steps 484(494.87) | Grad Norm 3.2890(5.8458) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 21.9284, Epoch Time 356.6583(340.5112), Bit/dim 3.7656(best: 3.7681), Xent 0.0000, Loss 3.7656, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0523 | Time 55.4049(53.3278) | Bit/dim 3.7552(3.8003) | Xent 0.0000(0.0000) | Loss 12.1686(9.4901) | Error 0.0000(0.0000) Steps 496(494.91) | Grad Norm 4.3221(5.8001) | Total Time 0.00(0.00)\n",
      "Iter 0524 | Time 54.2250(53.3547) | Bit/dim 3.7731(3.7995) | Xent 0.0000(0.0000) | Loss 8.8229(9.4701) | Error 0.0000(0.0000) Steps 502(495.12) | Grad Norm 6.1004(5.8091) | Total Time 0.00(0.00)\n",
      "Iter 0525 | Time 51.5520(53.3006) | Bit/dim 3.7709(3.7986) | Xent 0.0000(0.0000) | Loss 8.8102(9.4503) | Error 0.0000(0.0000) Steps 484(494.78) | Grad Norm 6.3870(5.8265) | Total Time 0.00(0.00)\n",
      "Iter 0526 | Time 58.0982(53.4446) | Bit/dim 3.7757(3.7979) | Xent 0.0000(0.0000) | Loss 8.8574(9.4325) | Error 0.0000(0.0000) Steps 502(495.00) | Grad Norm 6.6522(5.8513) | Total Time 0.00(0.00)\n",
      "Iter 0527 | Time 54.5923(53.4790) | Bit/dim 3.7672(3.7970) | Xent 0.0000(0.0000) | Loss 8.7617(9.4124) | Error 0.0000(0.0000) Steps 490(494.85) | Grad Norm 6.4051(5.8679) | Total Time 0.00(0.00)\n",
      "Iter 0528 | Time 54.6553(53.5143) | Bit/dim 3.7671(3.7961) | Xent 0.0000(0.0000) | Loss 8.9131(9.3974) | Error 0.0000(0.0000) Steps 502(495.07) | Grad Norm 4.8229(5.8365) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 22.1674, Epoch Time 369.6643(341.3858), Bit/dim 3.7536(best: 3.7656), Xent 0.0000, Loss 3.7536, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0529 | Time 57.4910(53.6336) | Bit/dim 3.7612(3.7951) | Xent 0.0000(0.0000) | Loss 11.8086(9.4697) | Error 0.0000(0.0000) Steps 502(495.27) | Grad Norm 3.5627(5.7683) | Total Time 0.00(0.00)\n",
      "Iter 0530 | Time 58.0728(53.7668) | Bit/dim 3.7591(3.7940) | Xent 0.0000(0.0000) | Loss 8.8916(9.4524) | Error 0.0000(0.0000) Steps 502(495.48) | Grad Norm 4.4311(5.7282) | Total Time 0.00(0.00)\n",
      "Iter 0531 | Time 60.9034(53.9809) | Bit/dim 3.7387(3.7923) | Xent 0.0000(0.0000) | Loss 8.8504(9.4343) | Error 0.0000(0.0000) Steps 502(495.67) | Grad Norm 4.3444(5.6867) | Total Time 0.00(0.00)\n",
      "Iter 0532 | Time 55.2864(54.0200) | Bit/dim 3.7490(3.7910) | Xent 0.0000(0.0000) | Loss 8.9517(9.4198) | Error 0.0000(0.0000) Steps 508(496.04) | Grad Norm 5.5673(5.6831) | Total Time 0.00(0.00)\n",
      "Iter 0533 | Time 55.3289(54.0593) | Bit/dim 3.7662(3.7903) | Xent 0.0000(0.0000) | Loss 9.0403(9.4085) | Error 0.0000(0.0000) Steps 502(496.22) | Grad Norm 6.6523(5.7122) | Total Time 0.00(0.00)\n",
      "Iter 0534 | Time 57.2202(54.1541) | Bit/dim 3.7589(3.7893) | Xent 0.0000(0.0000) | Loss 8.7207(9.3878) | Error 0.0000(0.0000) Steps 502(496.39) | Grad Norm 6.0737(5.7230) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 22.3036, Epoch Time 384.2627(342.6721), Bit/dim 3.7583(best: 3.7536), Xent 0.0000, Loss 3.7583, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0535 | Time 57.7431(54.2618) | Bit/dim 3.7508(3.7882) | Xent 0.0000(0.0000) | Loss 11.8878(9.4628) | Error 0.0000(0.0000) Steps 502(496.56) | Grad Norm 5.5839(5.7188) | Total Time 0.00(0.00)\n",
      "Iter 0536 | Time 52.5553(54.2106) | Bit/dim 3.7458(3.7869) | Xent 0.0000(0.0000) | Loss 8.7379(9.4411) | Error 0.0000(0.0000) Steps 490(496.36) | Grad Norm 4.7520(5.6898) | Total Time 0.00(0.00)\n",
      "Iter 0537 | Time 57.2344(54.3013) | Bit/dim 3.7445(3.7856) | Xent 0.0000(0.0000) | Loss 8.9431(9.4261) | Error 0.0000(0.0000) Steps 502(496.53) | Grad Norm 4.1921(5.6449) | Total Time 0.00(0.00)\n",
      "Iter 0538 | Time 53.2584(54.2700) | Bit/dim 3.7501(3.7846) | Xent 0.0000(0.0000) | Loss 8.8339(9.4084) | Error 0.0000(0.0000) Steps 496(496.52) | Grad Norm 5.4822(5.6400) | Total Time 0.00(0.00)\n",
      "Iter 0539 | Time 52.7880(54.2256) | Bit/dim 3.7401(3.7832) | Xent 0.0000(0.0000) | Loss 8.8030(9.3902) | Error 0.0000(0.0000) Steps 502(496.68) | Grad Norm 3.7372(5.5829) | Total Time 0.00(0.00)\n",
      "Iter 0540 | Time 55.5563(54.2655) | Bit/dim 3.7495(3.7822) | Xent 0.0000(0.0000) | Loss 9.0045(9.3786) | Error 0.0000(0.0000) Steps 514(497.20) | Grad Norm 4.0038(5.5356) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 21.6603, Epoch Time 369.1761(343.4672), Bit/dim 3.7487(best: 3.7536), Xent 0.0000, Loss 3.7487, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0541 | Time 52.9939(54.2273) | Bit/dim 3.7406(3.7810) | Xent 0.0000(0.0000) | Loss 12.1139(9.4607) | Error 0.0000(0.0000) Steps 502(497.35) | Grad Norm 4.2151(5.4959) | Total Time 0.00(0.00)\n",
      "Iter 0542 | Time 52.5088(54.1758) | Bit/dim 3.7366(3.7797) | Xent 0.0000(0.0000) | Loss 8.7090(9.4381) | Error 0.0000(0.0000) Steps 502(497.49) | Grad Norm 3.3120(5.4304) | Total Time 0.00(0.00)\n",
      "Iter 0543 | Time 55.1919(54.2063) | Bit/dim 3.7315(3.7782) | Xent 0.0000(0.0000) | Loss 8.7480(9.4174) | Error 0.0000(0.0000) Steps 502(497.62) | Grad Norm 4.5788(5.4049) | Total Time 0.00(0.00)\n",
      "Iter 0544 | Time 56.2732(54.2683) | Bit/dim 3.7488(3.7773) | Xent 0.0000(0.0000) | Loss 8.9445(9.4032) | Error 0.0000(0.0000) Steps 508(497.93) | Grad Norm 5.6978(5.4137) | Total Time 0.00(0.00)\n",
      "Iter 0545 | Time 51.9941(54.2001) | Bit/dim 3.7442(3.7763) | Xent 0.0000(0.0000) | Loss 8.7415(9.3834) | Error 0.0000(0.0000) Steps 490(497.69) | Grad Norm 5.4586(5.4150) | Total Time 0.00(0.00)\n",
      "Iter 0546 | Time 56.8217(54.2787) | Bit/dim 3.7388(3.7752) | Xent 0.0000(0.0000) | Loss 8.7527(9.3645) | Error 0.0000(0.0000) Steps 502(497.82) | Grad Norm 4.5552(5.3892) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 22.0410, Epoch Time 370.0959(344.2661), Bit/dim 3.7441(best: 3.7487), Xent 0.0000, Loss 3.7441, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0547 | Time 55.7945(54.3242) | Bit/dim 3.7540(3.7746) | Xent 0.0000(0.0000) | Loss 11.9144(9.4410) | Error 0.0000(0.0000) Steps 502(497.95) | Grad Norm 5.5115(5.3929) | Total Time 0.00(0.00)\n",
      "Iter 0548 | Time 53.8023(54.3085) | Bit/dim 3.7377(3.7735) | Xent 0.0000(0.0000) | Loss 8.8581(9.4235) | Error 0.0000(0.0000) Steps 508(498.25) | Grad Norm 6.6693(5.4312) | Total Time 0.00(0.00)\n",
      "Iter 0549 | Time 51.8441(54.2346) | Bit/dim 3.7494(3.7727) | Xent 0.0000(0.0000) | Loss 8.6697(9.4009) | Error 0.0000(0.0000) Steps 502(498.36) | Grad Norm 7.7302(5.5002) | Total Time 0.00(0.00)\n",
      "Iter 0550 | Time 54.1033(54.2307) | Bit/dim 3.7500(3.7721) | Xent 0.0000(0.0000) | Loss 8.9287(9.3867) | Error 0.0000(0.0000) Steps 514(498.83) | Grad Norm 7.1067(5.5483) | Total Time 0.00(0.00)\n",
      "Iter 0551 | Time 55.4656(54.2677) | Bit/dim 3.7444(3.7712) | Xent 0.0000(0.0000) | Loss 8.5866(9.3627) | Error 0.0000(0.0000) Steps 502(498.93) | Grad Norm 4.9798(5.5313) | Total Time 0.00(0.00)\n",
      "Iter 0552 | Time 58.1858(54.3852) | Bit/dim 3.7373(3.7702) | Xent 0.0000(0.0000) | Loss 8.8637(9.3477) | Error 0.0000(0.0000) Steps 496(498.84) | Grad Norm 3.7419(5.4776) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 22.1042, Epoch Time 368.9433(345.0064), Bit/dim 3.7434(best: 3.7441), Xent 0.0000, Loss 3.7434, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0553 | Time 60.0147(54.5541) | Bit/dim 3.7537(3.7697) | Xent 0.0000(0.0000) | Loss 12.3440(9.4376) | Error 0.0000(0.0000) Steps 508(499.11) | Grad Norm 4.7088(5.4545) | Total Time 0.00(0.00)\n",
      "Iter 0554 | Time 54.7544(54.5601) | Bit/dim 3.7409(3.7689) | Xent 0.0000(0.0000) | Loss 8.9913(9.4242) | Error 0.0000(0.0000) Steps 508(499.38) | Grad Norm 4.6117(5.4293) | Total Time 0.00(0.00)\n",
      "Iter 0555 | Time 51.7878(54.4770) | Bit/dim 3.7385(3.7679) | Xent 0.0000(0.0000) | Loss 8.7334(9.4035) | Error 0.0000(0.0000) Steps 496(499.28) | Grad Norm 4.3374(5.3965) | Total Time 0.00(0.00)\n",
      "Iter 0556 | Time 58.1953(54.5885) | Bit/dim 3.7302(3.7668) | Xent 0.0000(0.0000) | Loss 8.6840(9.3819) | Error 0.0000(0.0000) Steps 490(499.00) | Grad Norm 3.9533(5.3532) | Total Time 0.00(0.00)\n",
      "Iter 0557 | Time 52.5442(54.5272) | Bit/dim 3.7108(3.7651) | Xent 0.0000(0.0000) | Loss 8.7983(9.3644) | Error 0.0000(0.0000) Steps 490(498.73) | Grad Norm 3.2307(5.2895) | Total Time 0.00(0.00)\n",
      "Iter 0558 | Time 52.6882(54.4720) | Bit/dim 3.7226(3.7639) | Xent 0.0000(0.0000) | Loss 8.5674(9.3405) | Error 0.0000(0.0000) Steps 490(498.47) | Grad Norm 3.2228(5.2275) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 21.5950, Epoch Time 370.1947(345.7621), Bit/dim 3.7208(best: 3.7434), Xent 0.0000, Loss 3.7208, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0559 | Time 53.0909(54.4306) | Bit/dim 3.7254(3.7627) | Xent 0.0000(0.0000) | Loss 11.8177(9.4148) | Error 0.0000(0.0000) Steps 496(498.39) | Grad Norm 3.6879(5.1813) | Total Time 0.00(0.00)\n",
      "Iter 0560 | Time 55.6616(54.4675) | Bit/dim 3.7170(3.7613) | Xent 0.0000(0.0000) | Loss 8.8816(9.3988) | Error 0.0000(0.0000) Steps 544(499.76) | Grad Norm 5.0350(5.1770) | Total Time 0.00(0.00)\n",
      "Iter 0561 | Time 52.9903(54.4232) | Bit/dim 3.7460(3.7609) | Xent 0.0000(0.0000) | Loss 8.8168(9.3814) | Error 0.0000(0.0000) Steps 508(500.01) | Grad Norm 7.3426(5.2419) | Total Time 0.00(0.00)\n",
      "Iter 0562 | Time 57.3569(54.5112) | Bit/dim 3.7786(3.7614) | Xent 0.0000(0.0000) | Loss 8.8505(9.3654) | Error 0.0000(0.0000) Steps 496(499.89) | Grad Norm 8.2060(5.3308) | Total Time 0.00(0.00)\n",
      "Iter 0563 | Time 52.4444(54.4492) | Bit/dim 3.7622(3.7614) | Xent 0.0000(0.0000) | Loss 8.6091(9.3427) | Error 0.0000(0.0000) Steps 496(499.77) | Grad Norm 8.2277(5.4177) | Total Time 0.00(0.00)\n",
      "Iter 0564 | Time 54.5475(54.4522) | Bit/dim 3.7864(3.7622) | Xent 0.0000(0.0000) | Loss 9.0148(9.3329) | Error 0.0000(0.0000) Steps 496(499.66) | Grad Norm 8.2026(5.5013) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 22.0729, Epoch Time 366.6469(346.3886), Bit/dim 3.7509(best: 3.7208), Xent 0.0000, Loss 3.7509, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0565 | Time 52.1374(54.3827) | Bit/dim 3.7581(3.7621) | Xent 0.0000(0.0000) | Loss 11.7794(9.4063) | Error 0.0000(0.0000) Steps 508(499.91) | Grad Norm 5.1881(5.4919) | Total Time 0.00(0.00)\n",
      "Iter 0566 | Time 52.4412(54.3245) | Bit/dim 3.7691(3.7623) | Xent 0.0000(0.0000) | Loss 8.7834(9.3876) | Error 0.0000(0.0000) Steps 508(500.15) | Grad Norm 6.5856(5.5247) | Total Time 0.00(0.00)\n",
      "Iter 0567 | Time 57.0912(54.4075) | Bit/dim 3.7572(3.7621) | Xent 0.0000(0.0000) | Loss 8.8434(9.3713) | Error 0.0000(0.0000) Steps 508(500.39) | Grad Norm 6.1480(5.5434) | Total Time 0.00(0.00)\n",
      "Iter 0568 | Time 53.6632(54.3851) | Bit/dim 3.7378(3.7614) | Xent 0.0000(0.0000) | Loss 8.7613(9.3530) | Error 0.0000(0.0000) Steps 502(500.44) | Grad Norm 4.4416(5.5104) | Total Time 0.00(0.00)\n",
      "Iter 0569 | Time 52.0271(54.3144) | Bit/dim 3.7574(3.7613) | Xent 0.0000(0.0000) | Loss 8.5035(9.3275) | Error 0.0000(0.0000) Steps 490(500.12) | Grad Norm 5.8143(5.5195) | Total Time 0.00(0.00)\n",
      "Iter 0570 | Time 54.6204(54.3236) | Bit/dim 3.7657(3.7614) | Xent 0.0000(0.0000) | Loss 8.9398(9.3159) | Error 0.0000(0.0000) Steps 502(500.18) | Grad Norm 6.7177(5.5554) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 21.9406, Epoch Time 363.1918(346.8927), Bit/dim 3.7646(best: 3.7208), Xent 0.0000, Loss 3.7646, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0571 | Time 51.8285(54.2487) | Bit/dim 3.7725(3.7617) | Xent 0.0000(0.0000) | Loss 11.9341(9.3944) | Error 0.0000(0.0000) Steps 496(500.05) | Grad Norm 8.2756(5.6370) | Total Time 0.00(0.00)\n",
      "Iter 0572 | Time 56.4615(54.3151) | Bit/dim 3.7793(3.7623) | Xent 0.0000(0.0000) | Loss 8.9209(9.3802) | Error 0.0000(0.0000) Steps 508(500.29) | Grad Norm 7.7324(5.6999) | Total Time 0.00(0.00)\n",
      "Iter 0573 | Time 52.5107(54.2610) | Bit/dim 3.7534(3.7620) | Xent 0.0000(0.0000) | Loss 8.7885(9.3625) | Error 0.0000(0.0000) Steps 502(500.34) | Grad Norm 4.6647(5.6688) | Total Time 0.00(0.00)\n",
      "Iter 0574 | Time 56.1195(54.3167) | Bit/dim 3.7392(3.7613) | Xent 0.0000(0.0000) | Loss 8.6982(9.3425) | Error 0.0000(0.0000) Steps 496(500.21) | Grad Norm 5.2220(5.6554) | Total Time 0.00(0.00)\n",
      "Iter 0575 | Time 49.2566(54.1649) | Bit/dim 3.7573(3.7612) | Xent 0.0000(0.0000) | Loss 8.6222(9.3209) | Error 0.0000(0.0000) Steps 496(500.09) | Grad Norm 4.9292(5.6336) | Total Time 0.00(0.00)\n",
      "Iter 0576 | Time 55.6967(54.2109) | Bit/dim 3.7267(3.7601) | Xent 0.0000(0.0000) | Loss 8.6952(9.3022) | Error 0.0000(0.0000) Steps 508(500.32) | Grad Norm 3.8038(5.5787) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 22.1347, Epoch Time 362.7152(347.3674), Bit/dim 3.7382(best: 3.7208), Xent 0.0000, Loss 3.7382, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0577 | Time 57.3284(54.3044) | Bit/dim 3.7479(3.7598) | Xent 0.0000(0.0000) | Loss 12.2020(9.3891) | Error 0.0000(0.0000) Steps 526(501.09) | Grad Norm 3.8516(5.5269) | Total Time 0.00(0.00)\n",
      "Iter 0578 | Time 57.6984(54.4062) | Bit/dim 3.7486(3.7594) | Xent 0.0000(0.0000) | Loss 8.8008(9.3715) | Error 0.0000(0.0000) Steps 508(501.30) | Grad Norm 4.4445(5.4945) | Total Time 0.00(0.00)\n",
      "Iter 0579 | Time 62.5111(54.6494) | Bit/dim 3.7311(3.7586) | Xent 0.0000(0.0000) | Loss 8.8662(9.3563) | Error 0.0000(0.0000) Steps 520(501.86) | Grad Norm 3.6044(5.4378) | Total Time 0.00(0.00)\n",
      "Iter 0580 | Time 58.3477(54.7603) | Bit/dim 3.7165(3.7573) | Xent 0.0000(0.0000) | Loss 8.8059(9.3398) | Error 0.0000(0.0000) Steps 514(502.23) | Grad Norm 4.0141(5.3950) | Total Time 0.00(0.00)\n",
      "Iter 0581 | Time 55.9534(54.7961) | Bit/dim 3.7155(3.7561) | Xent 0.0000(0.0000) | Loss 8.5443(9.3160) | Error 0.0000(0.0000) Steps 526(502.94) | Grad Norm 3.5924(5.3410) | Total Time 0.00(0.00)\n",
      "Iter 0582 | Time 56.8039(54.8564) | Bit/dim 3.7297(3.7553) | Xent 0.0000(0.0000) | Loss 8.7676(9.2995) | Error 0.0000(0.0000) Steps 502(502.91) | Grad Norm 3.7765(5.2940) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 22.2260, Epoch Time 389.6058(348.6345), Bit/dim 3.7332(best: 3.7208), Xent 0.0000, Loss 3.7332, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0583 | Time 55.2204(54.8673) | Bit/dim 3.7233(3.7543) | Xent 0.0000(0.0000) | Loss 11.6358(9.3696) | Error 0.0000(0.0000) Steps 502(502.88) | Grad Norm 5.0242(5.2859) | Total Time 0.00(0.00)\n",
      "Iter 0584 | Time 60.5779(55.0386) | Bit/dim 3.7317(3.7536) | Xent 0.0000(0.0000) | Loss 8.7361(9.3506) | Error 0.0000(0.0000) Steps 508(503.04) | Grad Norm 6.0218(5.3080) | Total Time 0.00(0.00)\n",
      "Iter 0585 | Time 53.9746(55.0067) | Bit/dim 3.7289(3.7529) | Xent 0.0000(0.0000) | Loss 8.9597(9.3389) | Error 0.0000(0.0000) Steps 514(503.37) | Grad Norm 5.9613(5.3276) | Total Time 0.00(0.00)\n",
      "Iter 0586 | Time 55.1431(55.0108) | Bit/dim 3.7313(3.7523) | Xent 0.0000(0.0000) | Loss 8.6961(9.3196) | Error 0.0000(0.0000) Steps 496(503.15) | Grad Norm 4.8573(5.3135) | Total Time 0.00(0.00)\n",
      "Iter 0587 | Time 55.6070(55.0287) | Bit/dim 3.7321(3.7516) | Xent 0.0000(0.0000) | Loss 8.7487(9.3025) | Error 0.0000(0.0000) Steps 526(503.83) | Grad Norm 5.2393(5.3113) | Total Time 0.00(0.00)\n",
      "Iter 0588 | Time 58.8419(55.1431) | Bit/dim 3.7186(3.7507) | Xent 0.0000(0.0000) | Loss 8.6662(9.2834) | Error 0.0000(0.0000) Steps 514(504.14) | Grad Norm 6.0501(5.3334) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 22.2976, Epoch Time 379.9876(349.5751), Bit/dim 3.7265(best: 3.7208), Xent 0.0000, Loss 3.7265, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0589 | Time 55.5108(55.1541) | Bit/dim 3.7359(3.7502) | Xent 0.0000(0.0000) | Loss 11.7318(9.3568) | Error 0.0000(0.0000) Steps 484(503.53) | Grad Norm 5.8657(5.3494) | Total Time 0.00(0.00)\n",
      "Iter 0590 | Time 56.3175(55.1890) | Bit/dim 3.7307(3.7496) | Xent 0.0000(0.0000) | Loss 8.7413(9.3384) | Error 0.0000(0.0000) Steps 532(504.39) | Grad Norm 4.6849(5.3295) | Total Time 0.00(0.00)\n",
      "Iter 0591 | Time 55.5338(55.1993) | Bit/dim 3.7402(3.7493) | Xent 0.0000(0.0000) | Loss 8.9618(9.3271) | Error 0.0000(0.0000) Steps 502(504.31) | Grad Norm 4.5579(5.3063) | Total Time 0.00(0.00)\n",
      "Iter 0592 | Time 54.5262(55.1791) | Bit/dim 3.7219(3.7485) | Xent 0.0000(0.0000) | Loss 8.6742(9.3075) | Error 0.0000(0.0000) Steps 526(504.97) | Grad Norm 4.3185(5.2767) | Total Time 0.00(0.00)\n",
      "Iter 0593 | Time 50.4350(55.0368) | Bit/dim 3.7129(3.7475) | Xent 0.0000(0.0000) | Loss 8.6283(9.2871) | Error 0.0000(0.0000) Steps 508(505.06) | Grad Norm 4.9858(5.2680) | Total Time 0.00(0.00)\n",
      "Iter 0594 | Time 53.3686(54.9868) | Bit/dim 3.7268(3.7468) | Xent 0.0000(0.0000) | Loss 8.9751(9.2777) | Error 0.0000(0.0000) Steps 514(505.32) | Grad Norm 6.2938(5.2987) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 21.7814, Epoch Time 366.1057(350.0710), Bit/dim 3.7257(best: 3.7208), Xent 0.0000, Loss 3.7257, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0595 | Time 52.9349(54.9252) | Bit/dim 3.7204(3.7460) | Xent 0.0000(0.0000) | Loss 11.6648(9.3494) | Error 0.0000(0.0000) Steps 514(505.59) | Grad Norm 5.2819(5.2982) | Total Time 0.00(0.00)\n",
      "Iter 0596 | Time 59.1857(55.0530) | Bit/dim 3.7273(3.7455) | Xent 0.0000(0.0000) | Loss 8.7857(9.3324) | Error 0.0000(0.0000) Steps 532(506.38) | Grad Norm 4.0601(5.2611) | Total Time 0.00(0.00)\n",
      "Iter 0597 | Time 58.7277(55.1633) | Bit/dim 3.7350(3.7452) | Xent 0.0000(0.0000) | Loss 8.9951(9.3223) | Error 0.0000(0.0000) Steps 538(507.33) | Grad Norm 5.1946(5.2591) | Total Time 0.00(0.00)\n",
      "Iter 0598 | Time 59.8782(55.3047) | Bit/dim 3.7271(3.7446) | Xent 0.0000(0.0000) | Loss 8.7531(9.3052) | Error 0.0000(0.0000) Steps 520(507.71) | Grad Norm 4.9387(5.2495) | Total Time 0.00(0.00)\n",
      "Iter 0599 | Time 60.4146(55.4580) | Bit/dim 3.7126(3.7437) | Xent 0.0000(0.0000) | Loss 8.8137(9.2905) | Error 0.0000(0.0000) Steps 538(508.62) | Grad Norm 3.3125(5.1914) | Total Time 0.00(0.00)\n",
      "Iter 0600 | Time 54.6708(55.4344) | Bit/dim 3.7168(3.7429) | Xent 0.0000(0.0000) | Loss 8.7459(9.2742) | Error 0.0000(0.0000) Steps 502(508.42) | Grad Norm 4.2348(5.1627) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 22.3520, Epoch Time 387.1034(351.1820), Bit/dim 3.7046(best: 3.7208), Xent 0.0000, Loss 3.7046, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0601 | Time 58.5451(55.5277) | Bit/dim 3.7115(3.7419) | Xent 0.0000(0.0000) | Loss 12.1332(9.3599) | Error 0.0000(0.0000) Steps 526(508.94) | Grad Norm 3.9922(5.1276) | Total Time 0.00(0.00)\n",
      "Iter 0602 | Time 60.6192(55.6805) | Bit/dim 3.7332(3.7417) | Xent 0.0000(0.0000) | Loss 8.9279(9.3470) | Error 0.0000(0.0000) Steps 520(509.28) | Grad Norm 5.5346(5.1398) | Total Time 0.00(0.00)\n",
      "Iter 0603 | Time 53.1733(55.6052) | Bit/dim 3.7368(3.7415) | Xent 0.0000(0.0000) | Loss 8.9384(9.3347) | Error 0.0000(0.0000) Steps 514(509.42) | Grad Norm 6.3623(5.1764) | Total Time 0.00(0.00)\n",
      "Iter 0604 | Time 54.9027(55.5842) | Bit/dim 3.7272(3.7411) | Xent 0.0000(0.0000) | Loss 8.8888(9.3213) | Error 0.0000(0.0000) Steps 502(509.20) | Grad Norm 5.6980(5.1921) | Total Time 0.00(0.00)\n",
      "Iter 0605 | Time 55.3613(55.5775) | Bit/dim 3.7186(3.7404) | Xent 0.0000(0.0000) | Loss 8.5135(9.2971) | Error 0.0000(0.0000) Steps 496(508.80) | Grad Norm 4.9213(5.1840) | Total Time 0.00(0.00)\n",
      "Iter 0606 | Time 58.8286(55.6750) | Bit/dim 3.6917(3.7389) | Xent 0.0000(0.0000) | Loss 8.7161(9.2797) | Error 0.0000(0.0000) Steps 526(509.32) | Grad Norm 3.6503(5.1380) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 21.8177, Epoch Time 381.4904(352.0913), Bit/dim 3.7101(best: 3.7046), Xent 0.0000, Loss 3.7101, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0607 | Time 56.8056(55.7089) | Bit/dim 3.7011(3.7378) | Xent 0.0000(0.0000) | Loss 11.8616(9.3571) | Error 0.0000(0.0000) Steps 526(509.82) | Grad Norm 3.4958(5.0887) | Total Time 0.00(0.00)\n",
      "Iter 0608 | Time 56.1948(55.7235) | Bit/dim 3.7103(3.7370) | Xent 0.0000(0.0000) | Loss 8.7848(9.3400) | Error 0.0000(0.0000) Steps 520(510.12) | Grad Norm 4.1442(5.0604) | Total Time 0.00(0.00)\n",
      "Iter 0609 | Time 59.6746(55.8420) | Bit/dim 3.7153(3.7363) | Xent 0.0000(0.0000) | Loss 8.8867(9.3264) | Error 0.0000(0.0000) Steps 514(510.24) | Grad Norm 6.5389(5.1047) | Total Time 0.00(0.00)\n",
      "Iter 0610 | Time 52.4516(55.7403) | Bit/dim 3.7654(3.7372) | Xent 0.0000(0.0000) | Loss 8.9212(9.3142) | Error 0.0000(0.0000) Steps 508(510.17) | Grad Norm 9.5933(5.2394) | Total Time 0.00(0.00)\n",
      "Iter 0611 | Time 54.0505(55.6896) | Bit/dim 3.7519(3.7376) | Xent 0.0000(0.0000) | Loss 8.8749(9.3010) | Error 0.0000(0.0000) Steps 514(510.29) | Grad Norm 8.7636(5.3451) | Total Time 0.00(0.00)\n",
      "Iter 0612 | Time 53.8430(55.6342) | Bit/dim 3.7485(3.7380) | Xent 0.0000(0.0000) | Loss 8.8640(9.2879) | Error 0.0000(0.0000) Steps 502(510.04) | Grad Norm 6.4680(5.3788) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 21.9602, Epoch Time 373.2615(352.7264), Bit/dim 3.7526(best: 3.7046), Xent 0.0000, Loss 3.7526, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0613 | Time 62.8286(55.8501) | Bit/dim 3.7499(3.7383) | Xent 0.0000(0.0000) | Loss 12.4013(9.3813) | Error 0.0000(0.0000) Steps 532(510.70) | Grad Norm 6.7741(5.4207) | Total Time 0.00(0.00)\n",
      "Iter 0614 | Time 60.6780(55.9949) | Bit/dim 3.7239(3.7379) | Xent 0.0000(0.0000) | Loss 8.8633(9.3658) | Error 0.0000(0.0000) Steps 532(511.33) | Grad Norm 4.1184(5.3816) | Total Time 0.00(0.00)\n",
      "Iter 0615 | Time 55.4956(55.9799) | Bit/dim 3.7327(3.7377) | Xent 0.0000(0.0000) | Loss 8.9657(9.3538) | Error 0.0000(0.0000) Steps 544(512.31) | Grad Norm 4.8013(5.3642) | Total Time 0.00(0.00)\n",
      "Iter 0616 | Time 56.8573(56.0063) | Bit/dim 3.7331(3.7376) | Xent 0.0000(0.0000) | Loss 8.7532(9.3358) | Error 0.0000(0.0000) Steps 514(512.37) | Grad Norm 6.0389(5.3844) | Total Time 0.00(0.00)\n",
      "Iter 0617 | Time 55.6313(55.9950) | Bit/dim 3.7576(3.7382) | Xent 0.0000(0.0000) | Loss 9.0215(9.3263) | Error 0.0000(0.0000) Steps 538(513.13) | Grad Norm 8.4015(5.4749) | Total Time 0.00(0.00)\n",
      "Iter 0618 | Time 58.1013(56.0582) | Bit/dim 3.8245(3.7408) | Xent 0.0000(0.0000) | Loss 9.0299(9.3174) | Error 0.0000(0.0000) Steps 508(512.98) | Grad Norm 8.4531(5.5643) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 22.1770, Epoch Time 390.1467(353.8490), Bit/dim 3.7632(best: 3.7046), Xent 0.0000, Loss 3.7632, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0619 | Time 55.7743(56.0497) | Bit/dim 3.7557(3.7412) | Xent 0.0000(0.0000) | Loss 12.3581(9.4087) | Error 0.0000(0.0000) Steps 520(513.19) | Grad Norm 6.3446(5.5877) | Total Time 0.00(0.00)\n",
      "Iter 0620 | Time 52.0297(55.9291) | Bit/dim 3.7749(3.7422) | Xent 0.0000(0.0000) | Loss 8.6706(9.3865) | Error 0.0000(0.0000) Steps 490(512.50) | Grad Norm 6.4709(5.6142) | Total Time 0.00(0.00)\n",
      "Iter 0621 | Time 56.9256(55.9590) | Bit/dim 3.7505(3.7425) | Xent 0.0000(0.0000) | Loss 8.9326(9.3729) | Error 0.0000(0.0000) Steps 532(513.08) | Grad Norm 4.5755(5.5830) | Total Time 0.00(0.00)\n",
      "Iter 0622 | Time 52.6190(55.8588) | Bit/dim 3.7442(3.7425) | Xent 0.0000(0.0000) | Loss 8.7479(9.3541) | Error 0.0000(0.0000) Steps 490(512.39) | Grad Norm 4.8822(5.5620) | Total Time 0.00(0.00)\n",
      "Iter 0623 | Time 51.2930(55.7218) | Bit/dim 3.7352(3.7423) | Xent 0.0000(0.0000) | Loss 8.8130(9.3379) | Error 0.0000(0.0000) Steps 490(511.72) | Grad Norm 4.7237(5.5368) | Total Time 0.00(0.00)\n",
      "Iter 0624 | Time 56.8428(55.7554) | Bit/dim 3.7453(3.7424) | Xent 0.0000(0.0000) | Loss 8.8475(9.3232) | Error 0.0000(0.0000) Steps 538(512.50) | Grad Norm 6.3168(5.5602) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 21.7640, Epoch Time 366.3861(354.2251), Bit/dim 3.7554(best: 3.7046), Xent 0.0000, Loss 3.7554, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0625 | Time 54.1698(55.7079) | Bit/dim 3.7501(3.7426) | Xent 0.0000(0.0000) | Loss 12.3038(9.4126) | Error 0.0000(0.0000) Steps 508(512.37) | Grad Norm 6.7598(5.5962) | Total Time 0.00(0.00)\n",
      "Iter 0626 | Time 56.7469(55.7390) | Bit/dim 3.7868(3.7440) | Xent 0.0000(0.0000) | Loss 8.9999(9.4002) | Error 0.0000(0.0000) Steps 508(512.24) | Grad Norm 10.2549(5.7360) | Total Time 0.00(0.00)\n",
      "Iter 0627 | Time 54.6573(55.7066) | Bit/dim 3.8306(3.7466) | Xent 0.0000(0.0000) | Loss 9.0090(9.3885) | Error 0.0000(0.0000) Steps 514(512.29) | Grad Norm 11.5066(5.9091) | Total Time 0.00(0.00)\n",
      "Iter 0628 | Time 55.0642(55.6873) | Bit/dim 3.7849(3.7477) | Xent 0.0000(0.0000) | Loss 8.9900(9.3765) | Error 0.0000(0.0000) Steps 532(512.88) | Grad Norm 7.4300(5.9547) | Total Time 0.00(0.00)\n",
      "Iter 0629 | Time 52.5379(55.5928) | Bit/dim 3.7794(3.7487) | Xent 0.0000(0.0000) | Loss 8.8007(9.3593) | Error 0.0000(0.0000) Steps 508(512.74) | Grad Norm 6.2212(5.9627) | Total Time 0.00(0.00)\n",
      "Iter 0630 | Time 55.2464(55.5824) | Bit/dim 3.7883(3.7499) | Xent 0.0000(0.0000) | Loss 9.1740(9.3537) | Error 0.0000(0.0000) Steps 526(513.13) | Grad Norm 5.2558(5.9415) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 21.9865, Epoch Time 369.3732(354.6795), Bit/dim 3.7803(best: 3.7046), Xent 0.0000, Loss 3.7803, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0631 | Time 53.2092(55.5112) | Bit/dim 3.7766(3.7507) | Xent 0.0000(0.0000) | Loss 11.9137(9.4305) | Error 0.0000(0.0000) Steps 508(512.98) | Grad Norm 6.7916(5.9670) | Total Time 0.00(0.00)\n",
      "Iter 0632 | Time 63.0280(55.7367) | Bit/dim 3.7644(3.7511) | Xent 0.0000(0.0000) | Loss 8.4680(9.4016) | Error 0.0000(0.0000) Steps 532(513.55) | Grad Norm 5.0082(5.9383) | Total Time 0.00(0.00)\n",
      "Iter 0633 | Time 61.8165(55.9191) | Bit/dim 3.7449(3.7509) | Xent 0.0000(0.0000) | Loss 8.8018(9.3836) | Error 0.0000(0.0000) Steps 538(514.28) | Grad Norm 3.7742(5.8733) | Total Time 0.00(0.00)\n",
      "Iter 0634 | Time 53.9806(55.8610) | Bit/dim 3.7539(3.7510) | Xent 0.0000(0.0000) | Loss 8.7035(9.3632) | Error 0.0000(0.0000) Steps 502(513.92) | Grad Norm 4.4825(5.8316) | Total Time 0.00(0.00)\n",
      "Iter 0635 | Time 59.2497(55.9626) | Bit/dim 3.7232(3.7501) | Xent 0.0000(0.0000) | Loss 8.7631(9.3452) | Error 0.0000(0.0000) Steps 520(514.10) | Grad Norm 3.0751(5.7489) | Total Time 0.00(0.00)\n",
      "Iter 0636 | Time 57.2054(55.9999) | Bit/dim 3.7353(3.7497) | Xent 0.0000(0.0000) | Loss 8.7768(9.3282) | Error 0.0000(0.0000) Steps 502(513.74) | Grad Norm 3.4414(5.6797) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 22.0051, Epoch Time 389.9002(355.7362), Bit/dim 3.7203(best: 3.7046), Xent 0.0000, Loss 3.7203, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0637 | Time 53.6429(55.9292) | Bit/dim 3.7109(3.7485) | Xent 0.0000(0.0000) | Loss 11.9558(9.4070) | Error 0.0000(0.0000) Steps 514(513.74) | Grad Norm 3.3741(5.6105) | Total Time 0.00(0.00)\n",
      "Iter 0638 | Time 58.6553(56.0110) | Bit/dim 3.7105(3.7474) | Xent 0.0000(0.0000) | Loss 8.6950(9.3856) | Error 0.0000(0.0000) Steps 520(513.93) | Grad Norm 2.8182(5.5268) | Total Time 0.00(0.00)\n",
      "Iter 0639 | Time 55.0675(55.9827) | Bit/dim 3.7247(3.7467) | Xent 0.0000(0.0000) | Loss 8.8426(9.3694) | Error 0.0000(0.0000) Steps 502(513.57) | Grad Norm 3.6833(5.4714) | Total Time 0.00(0.00)\n",
      "Iter 0640 | Time 57.4505(56.0267) | Bit/dim 3.7108(3.7456) | Xent 0.0000(0.0000) | Loss 8.7838(9.3518) | Error 0.0000(0.0000) Steps 520(513.77) | Grad Norm 2.7928(5.3911) | Total Time 0.00(0.00)\n",
      "Iter 0641 | Time 58.0599(56.0877) | Bit/dim 3.6894(3.7439) | Xent 0.0000(0.0000) | Loss 8.5696(9.3283) | Error 0.0000(0.0000) Steps 520(513.95) | Grad Norm 2.4957(5.3042) | Total Time 0.00(0.00)\n",
      "Iter 0642 | Time 57.5057(56.1303) | Bit/dim 3.7002(3.7426) | Xent 0.0000(0.0000) | Loss 8.9205(9.3161) | Error 0.0000(0.0000) Steps 532(514.49) | Grad Norm 3.3218(5.2448) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 22.5290, Epoch Time 383.2610(356.5619), Bit/dim 3.6920(best: 3.7046), Xent 0.0000, Loss 3.6920, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0643 | Time 52.4087(56.0186) | Bit/dim 3.6969(3.7413) | Xent 0.0000(0.0000) | Loss 11.9977(9.3965) | Error 0.0000(0.0000) Steps 520(514.66) | Grad Norm 2.5323(5.1634) | Total Time 0.00(0.00)\n",
      "Iter 0644 | Time 56.5771(56.0354) | Bit/dim 3.6845(3.7396) | Xent 0.0000(0.0000) | Loss 8.8188(9.3792) | Error 0.0000(0.0000) Steps 526(515.00) | Grad Norm 2.7127(5.0899) | Total Time 0.00(0.00)\n",
      "Iter 0645 | Time 56.0701(56.0364) | Bit/dim 3.6950(3.7382) | Xent 0.0000(0.0000) | Loss 8.8772(9.3641) | Error 0.0000(0.0000) Steps 526(515.33) | Grad Norm 3.4027(5.0392) | Total Time 0.00(0.00)\n",
      "Iter 0646 | Time 59.5730(56.1425) | Bit/dim 3.6875(3.7367) | Xent 0.0000(0.0000) | Loss 8.9096(9.3505) | Error 0.0000(0.0000) Steps 526(515.65) | Grad Norm 4.2861(5.0167) | Total Time 0.00(0.00)\n",
      "Iter 0647 | Time 56.7438(56.1605) | Bit/dim 3.7013(3.7356) | Xent 0.0000(0.0000) | Loss 8.9297(9.3379) | Error 0.0000(0.0000) Steps 526(515.96) | Grad Norm 5.2434(5.0235) | Total Time 0.00(0.00)\n",
      "Iter 0648 | Time 55.7418(56.1480) | Bit/dim 3.7030(3.7347) | Xent 0.0000(0.0000) | Loss 8.8803(9.3242) | Error 0.0000(0.0000) Steps 526(516.26) | Grad Norm 6.1065(5.0559) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 22.8207, Epoch Time 379.8885(357.2617), Bit/dim 3.7068(best: 3.6920), Xent 0.0000, Loss 3.7068, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0649 | Time 58.7024(56.2246) | Bit/dim 3.6988(3.7336) | Xent 0.0000(0.0000) | Loss 12.2515(9.4120) | Error 0.0000(0.0000) Steps 532(516.73) | Grad Norm 6.0721(5.0864) | Total Time 0.00(0.00)\n",
      "Iter 0650 | Time 58.5766(56.2952) | Bit/dim 3.6972(3.7325) | Xent 0.0000(0.0000) | Loss 8.8928(9.3964) | Error 0.0000(0.0000) Steps 526(517.01) | Grad Norm 4.1425(5.0581) | Total Time 0.00(0.00)\n",
      "Iter 0651 | Time 56.7831(56.3098) | Bit/dim 3.6795(3.7309) | Xent 0.0000(0.0000) | Loss 8.6800(9.3749) | Error 0.0000(0.0000) Steps 514(516.92) | Grad Norm 2.9733(4.9956) | Total Time 0.00(0.00)\n",
      "Iter 0652 | Time 59.8898(56.4172) | Bit/dim 3.6993(3.7300) | Xent 0.0000(0.0000) | Loss 8.8065(9.3579) | Error 0.0000(0.0000) Steps 538(517.55) | Grad Norm 5.2552(5.0034) | Total Time 0.00(0.00)\n",
      "Iter 0653 | Time 54.9921(56.3745) | Bit/dim 3.7022(3.7291) | Xent 0.0000(0.0000) | Loss 8.8305(9.3420) | Error 0.0000(0.0000) Steps 532(517.99) | Grad Norm 6.3833(5.0448) | Total Time 0.00(0.00)\n",
      "Iter 0654 | Time 56.4720(56.3774) | Bit/dim 3.6990(3.7282) | Xent 0.0000(0.0000) | Loss 8.8041(9.3259) | Error 0.0000(0.0000) Steps 526(518.23) | Grad Norm 5.9856(5.0730) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 22.3780, Epoch Time 386.2996(358.1328), Bit/dim 3.7103(best: 3.6920), Xent 0.0000, Loss 3.7103, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0655 | Time 56.2185(56.3726) | Bit/dim 3.7098(3.7277) | Xent 0.0000(0.0000) | Loss 11.9990(9.4061) | Error 0.0000(0.0000) Steps 532(518.64) | Grad Norm 5.3242(5.0805) | Total Time 0.00(0.00)\n",
      "Iter 0656 | Time 56.9862(56.3910) | Bit/dim 3.7004(3.7269) | Xent 0.0000(0.0000) | Loss 8.7774(9.3872) | Error 0.0000(0.0000) Steps 532(519.04) | Grad Norm 4.7148(5.0696) | Total Time 0.00(0.00)\n",
      "Iter 0657 | Time 59.5321(56.4853) | Bit/dim 3.6855(3.7256) | Xent 0.0000(0.0000) | Loss 8.8593(9.3714) | Error 0.0000(0.0000) Steps 532(519.43) | Grad Norm 3.2992(5.0164) | Total Time 0.00(0.00)\n",
      "Iter 0658 | Time 57.2252(56.5075) | Bit/dim 3.6915(3.7246) | Xent 0.0000(0.0000) | Loss 8.7763(9.3535) | Error 0.0000(0.0000) Steps 520(519.45) | Grad Norm 4.1440(4.9903) | Total Time 0.00(0.00)\n",
      "Iter 0659 | Time 55.7906(56.4859) | Bit/dim 3.7121(3.7242) | Xent 0.0000(0.0000) | Loss 8.9621(9.3418) | Error 0.0000(0.0000) Steps 514(519.28) | Grad Norm 5.0274(4.9914) | Total Time 0.00(0.00)\n",
      "Iter 0660 | Time 54.5655(56.4283) | Bit/dim 3.6886(3.7231) | Xent 0.0000(0.0000) | Loss 8.8001(9.3255) | Error 0.0000(0.0000) Steps 514(519.13) | Grad Norm 4.6431(4.9809) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 21.5920, Epoch Time 381.0430(358.8201), Bit/dim 3.6860(best: 3.6920), Xent 0.0000, Loss 3.6860, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0661 | Time 56.0475(56.4169) | Bit/dim 3.6968(3.7224) | Xent 0.0000(0.0000) | Loss 12.0436(9.4071) | Error 0.0000(0.0000) Steps 514(518.97) | Grad Norm 4.4909(4.9662) | Total Time 0.00(0.00)\n",
      "Iter 0662 | Time 57.1690(56.4395) | Bit/dim 3.6731(3.7209) | Xent 0.0000(0.0000) | Loss 8.8212(9.3895) | Error 0.0000(0.0000) Steps 520(519.00) | Grad Norm 4.3406(4.9475) | Total Time 0.00(0.00)\n",
      "Iter 0663 | Time 59.6307(56.5352) | Bit/dim 3.6881(3.7199) | Xent 0.0000(0.0000) | Loss 8.8564(9.3735) | Error 0.0000(0.0000) Steps 544(519.75) | Grad Norm 3.5746(4.9063) | Total Time 0.00(0.00)\n",
      "Iter 0664 | Time 53.8046(56.4533) | Bit/dim 3.6783(3.7186) | Xent 0.0000(0.0000) | Loss 8.9165(9.3598) | Error 0.0000(0.0000) Steps 508(519.40) | Grad Norm 3.4475(4.8625) | Total Time 0.00(0.00)\n",
      "Iter 0665 | Time 57.0296(56.4706) | Bit/dim 3.6993(3.7181) | Xent 0.0000(0.0000) | Loss 8.6718(9.3392) | Error 0.0000(0.0000) Steps 532(519.78) | Grad Norm 3.8768(4.8329) | Total Time 0.00(0.00)\n",
      "Iter 0666 | Time 56.9909(56.4862) | Bit/dim 3.6601(3.7163) | Xent 0.0000(0.0000) | Loss 8.5819(9.3164) | Error 0.0000(0.0000) Steps 514(519.60) | Grad Norm 3.3196(4.7875) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 22.3257, Epoch Time 381.3479(359.4960), Bit/dim 3.6738(best: 3.6860), Xent 0.0000, Loss 3.6738, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0667 | Time 58.4773(56.5459) | Bit/dim 3.6705(3.7150) | Xent 0.0000(0.0000) | Loss 12.0538(9.3986) | Error 0.0000(0.0000) Steps 514(519.44) | Grad Norm 3.2969(4.7428) | Total Time 0.00(0.00)\n",
      "Iter 0668 | Time 56.8561(56.5552) | Bit/dim 3.6925(3.7143) | Xent 0.0000(0.0000) | Loss 8.6104(9.3749) | Error 0.0000(0.0000) Steps 514(519.27) | Grad Norm 4.5384(4.7367) | Total Time 0.00(0.00)\n",
      "Iter 0669 | Time 54.0896(56.4813) | Bit/dim 3.6938(3.7137) | Xent 0.0000(0.0000) | Loss 8.7263(9.3555) | Error 0.0000(0.0000) Steps 496(518.57) | Grad Norm 5.7557(4.7673) | Total Time 0.00(0.00)\n",
      "Iter 0670 | Time 57.4064(56.5090) | Bit/dim 3.7084(3.7135) | Xent 0.0000(0.0000) | Loss 8.6715(9.3349) | Error 0.0000(0.0000) Steps 526(518.80) | Grad Norm 6.6997(4.8252) | Total Time 0.00(0.00)\n",
      "Iter 0671 | Time 55.1013(56.4668) | Bit/dim 3.6955(3.7130) | Xent 0.0000(0.0000) | Loss 8.6719(9.3151) | Error 0.0000(0.0000) Steps 508(518.47) | Grad Norm 5.2899(4.8392) | Total Time 0.00(0.00)\n",
      "Iter 0672 | Time 53.7642(56.3857) | Bit/dim 3.6886(3.7122) | Xent 0.0000(0.0000) | Loss 8.8369(9.3007) | Error 0.0000(0.0000) Steps 520(518.52) | Grad Norm 4.4919(4.8288) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 21.3590, Epoch Time 375.8269(359.9859), Bit/dim 3.6967(best: 3.6738), Xent 0.0000, Loss 3.6967, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0673 | Time 53.2215(56.2908) | Bit/dim 3.6874(3.7115) | Xent 0.0000(0.0000) | Loss 12.1662(9.3867) | Error 0.0000(0.0000) Steps 508(518.20) | Grad Norm 4.8893(4.8306) | Total Time 0.00(0.00)\n",
      "Iter 0674 | Time 54.3558(56.2327) | Bit/dim 3.6840(3.7107) | Xent 0.0000(0.0000) | Loss 8.6215(9.3637) | Error 0.0000(0.0000) Steps 508(517.90) | Grad Norm 4.5794(4.8230) | Total Time 0.00(0.00)\n",
      "Iter 0675 | Time 59.1898(56.3214) | Bit/dim 3.6736(3.7096) | Xent 0.0000(0.0000) | Loss 8.7401(9.3450) | Error 0.0000(0.0000) Steps 508(517.60) | Grad Norm 3.7339(4.7904) | Total Time 0.00(0.00)\n",
      "Iter 0676 | Time 58.1375(56.3759) | Bit/dim 3.6800(3.7087) | Xent 0.0000(0.0000) | Loss 8.7493(9.3271) | Error 0.0000(0.0000) Steps 520(517.67) | Grad Norm 4.5372(4.7828) | Total Time 0.00(0.00)\n",
      "Iter 0677 | Time 55.9716(56.3638) | Bit/dim 3.6992(3.7084) | Xent 0.0000(0.0000) | Loss 8.9202(9.3149) | Error 0.0000(0.0000) Steps 532(518.10) | Grad Norm 4.9803(4.7887) | Total Time 0.00(0.00)\n",
      "Iter 0678 | Time 62.0504(56.5344) | Bit/dim 3.6682(3.7072) | Xent 0.0000(0.0000) | Loss 8.8802(9.3019) | Error 0.0000(0.0000) Steps 532(518.52) | Grad Norm 3.9947(4.7649) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 21.8308, Epoch Time 392.1133(360.9497), Bit/dim 3.6775(best: 3.6738), Xent 0.0000, Loss 3.6775, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0679 | Time 53.1944(56.4342) | Bit/dim 3.6732(3.7062) | Xent 0.0000(0.0000) | Loss 11.7133(9.3742) | Error 0.0000(0.0000) Steps 514(518.38) | Grad Norm 3.4600(4.7257) | Total Time 0.00(0.00)\n",
      "Iter 0680 | Time 54.5592(56.3779) | Bit/dim 3.6687(3.7050) | Xent 0.0000(0.0000) | Loss 8.5311(9.3489) | Error 0.0000(0.0000) Steps 520(518.43) | Grad Norm 3.5329(4.6899) | Total Time 0.00(0.00)\n",
      "Iter 0681 | Time 60.6042(56.5047) | Bit/dim 3.6954(3.7047) | Xent 0.0000(0.0000) | Loss 8.9204(9.3361) | Error 0.0000(0.0000) Steps 544(519.20) | Grad Norm 4.0669(4.6712) | Total Time 0.00(0.00)\n",
      "Iter 0682 | Time 55.1679(56.4646) | Bit/dim 3.6661(3.7036) | Xent 0.0000(0.0000) | Loss 8.4998(9.3110) | Error 0.0000(0.0000) Steps 514(519.04) | Grad Norm 3.9283(4.6490) | Total Time 0.00(0.00)\n",
      "Iter 0683 | Time 54.0864(56.3933) | Bit/dim 3.6857(3.7031) | Xent 0.0000(0.0000) | Loss 8.7501(9.2942) | Error 0.0000(0.0000) Steps 520(519.07) | Grad Norm 5.8777(4.6858) | Total Time 0.00(0.00)\n",
      "Iter 0684 | Time 56.8627(56.4074) | Bit/dim 3.7098(3.7033) | Xent 0.0000(0.0000) | Loss 8.8279(9.2802) | Error 0.0000(0.0000) Steps 520(519.10) | Grad Norm 8.0390(4.7864) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 22.8173, Epoch Time 375.5321(361.3872), Bit/dim 3.7080(best: 3.6738), Xent 0.0000, Loss 3.7080, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0685 | Time 54.5132(56.3505) | Bit/dim 3.7068(3.7034) | Xent 0.0000(0.0000) | Loss 12.5211(9.3774) | Error 0.0000(0.0000) Steps 520(519.13) | Grad Norm 6.8416(4.8481) | Total Time 0.00(0.00)\n",
      "Iter 0686 | Time 54.2390(56.2872) | Bit/dim 3.6929(3.7030) | Xent 0.0000(0.0000) | Loss 8.7199(9.3577) | Error 0.0000(0.0000) Steps 514(518.97) | Grad Norm 4.3837(4.8341) | Total Time 0.00(0.00)\n",
      "Iter 0687 | Time 54.2933(56.2274) | Bit/dim 3.6833(3.7025) | Xent 0.0000(0.0000) | Loss 8.5074(9.3322) | Error 0.0000(0.0000) Steps 490(518.10) | Grad Norm 4.1737(4.8143) | Total Time 0.00(0.00)\n",
      "Iter 0688 | Time 57.1875(56.2562) | Bit/dim 3.6878(3.7020) | Xent 0.0000(0.0000) | Loss 8.9445(9.3205) | Error 0.0000(0.0000) Steps 526(518.34) | Grad Norm 4.3703(4.8010) | Total Time 0.00(0.00)\n",
      "Iter 0689 | Time 55.5464(56.2349) | Bit/dim 3.7238(3.7027) | Xent 0.0000(0.0000) | Loss 8.7307(9.3028) | Error 0.0000(0.0000) Steps 520(518.39) | Grad Norm 4.9657(4.8059) | Total Time 0.00(0.00)\n",
      "Iter 0690 | Time 62.7336(56.4298) | Bit/dim 3.6932(3.7024) | Xent 0.0000(0.0000) | Loss 8.7846(9.2873) | Error 0.0000(0.0000) Steps 532(518.80) | Grad Norm 4.4098(4.7941) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 23.2452, Epoch Time 380.2594(361.9534), Bit/dim 3.7077(best: 3.6738), Xent 0.0000, Loss 3.7077, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0691 | Time 56.6357(56.4360) | Bit/dim 3.6976(3.7022) | Xent 0.0000(0.0000) | Loss 12.0779(9.3710) | Error 0.0000(0.0000) Steps 520(518.84) | Grad Norm 5.3697(4.8113) | Total Time 0.00(0.00)\n",
      "Iter 0692 | Time 54.6064(56.3811) | Bit/dim 3.6867(3.7018) | Xent 0.0000(0.0000) | Loss 8.8155(9.3544) | Error 0.0000(0.0000) Steps 526(519.05) | Grad Norm 5.2840(4.8255) | Total Time 0.00(0.00)\n",
      "Iter 0693 | Time 53.8284(56.3045) | Bit/dim 3.7023(3.7018) | Xent 0.0000(0.0000) | Loss 8.9181(9.3413) | Error 0.0000(0.0000) Steps 520(519.08) | Grad Norm 4.8467(4.8262) | Total Time 0.00(0.00)\n",
      "Iter 0694 | Time 55.3655(56.2764) | Bit/dim 3.6868(3.7013) | Xent 0.0000(0.0000) | Loss 8.7912(9.3248) | Error 0.0000(0.0000) Steps 508(518.75) | Grad Norm 4.0459(4.8027) | Total Time 0.00(0.00)\n",
      "Iter 0695 | Time 56.4669(56.2821) | Bit/dim 3.6899(3.7010) | Xent 0.0000(0.0000) | Loss 8.6675(9.3050) | Error 0.0000(0.0000) Steps 514(518.60) | Grad Norm 4.3152(4.7881) | Total Time 0.00(0.00)\n",
      "Iter 0696 | Time 58.1154(56.3371) | Bit/dim 3.6877(3.7006) | Xent 0.0000(0.0000) | Loss 8.8998(9.2929) | Error 0.0000(0.0000) Steps 502(518.11) | Grad Norm 5.2445(4.8018) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 22.1266, Epoch Time 376.2171(362.3813), Bit/dim 3.6701(best: 3.6738), Xent 0.0000, Loss 3.6701, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0697 | Time 59.8843(56.4435) | Bit/dim 3.6685(3.6996) | Xent 0.0000(0.0000) | Loss 12.2637(9.3820) | Error 0.0000(0.0000) Steps 538(518.70) | Grad Norm 4.1453(4.7821) | Total Time 0.00(0.00)\n",
      "Iter 0698 | Time 57.9020(56.4873) | Bit/dim 3.6854(3.6992) | Xent 0.0000(0.0000) | Loss 8.6925(9.3613) | Error 0.0000(0.0000) Steps 526(518.92) | Grad Norm 3.4511(4.7422) | Total Time 0.00(0.00)\n",
      "Iter 0699 | Time 58.1820(56.5381) | Bit/dim 3.6622(3.6981) | Xent 0.0000(0.0000) | Loss 8.8364(9.3456) | Error 0.0000(0.0000) Steps 544(519.67) | Grad Norm 4.2269(4.7267) | Total Time 0.00(0.00)\n",
      "Iter 0700 | Time 58.3263(56.5917) | Bit/dim 3.6760(3.6974) | Xent 0.0000(0.0000) | Loss 8.9340(9.3332) | Error 0.0000(0.0000) Steps 538(520.22) | Grad Norm 4.7012(4.7260) | Total Time 0.00(0.00)\n",
      "Iter 0701 | Time 53.9072(56.5112) | Bit/dim 3.6799(3.6969) | Xent 0.0000(0.0000) | Loss 8.7503(9.3157) | Error 0.0000(0.0000) Steps 520(520.22) | Grad Norm 4.4395(4.7174) | Total Time 0.00(0.00)\n",
      "Iter 0702 | Time 55.5087(56.4811) | Bit/dim 3.6694(3.6961) | Xent 0.0000(0.0000) | Loss 8.6375(9.2954) | Error 0.0000(0.0000) Steps 508(519.85) | Grad Norm 4.0490(4.6973) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 22.3454, Epoch Time 383.8520(363.0254), Bit/dim 3.6755(best: 3.6701), Xent 0.0000, Loss 3.6755, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0703 | Time 54.7189(56.4283) | Bit/dim 3.6736(3.6954) | Xent 0.0000(0.0000) | Loss 11.9409(9.3748) | Error 0.0000(0.0000) Steps 532(520.21) | Grad Norm 4.3528(4.6870) | Total Time 0.00(0.00)\n",
      "Iter 0704 | Time 57.1827(56.4509) | Bit/dim 3.6749(3.6948) | Xent 0.0000(0.0000) | Loss 8.6992(9.3545) | Error 0.0000(0.0000) Steps 502(519.67) | Grad Norm 4.7132(4.6878) | Total Time 0.00(0.00)\n",
      "Iter 0705 | Time 54.3141(56.3868) | Bit/dim 3.6792(3.6943) | Xent 0.0000(0.0000) | Loss 8.8459(9.3392) | Error 0.0000(0.0000) Steps 526(519.86) | Grad Norm 5.3657(4.7081) | Total Time 0.00(0.00)\n",
      "Iter 0706 | Time 56.8559(56.4009) | Bit/dim 3.6927(3.6943) | Xent 0.0000(0.0000) | Loss 8.6771(9.3194) | Error 0.0000(0.0000) Steps 514(519.68) | Grad Norm 6.6153(4.7653) | Total Time 0.00(0.00)\n",
      "Iter 0707 | Time 53.9605(56.3277) | Bit/dim 3.6892(3.6941) | Xent 0.0000(0.0000) | Loss 8.6512(9.2993) | Error 0.0000(0.0000) Steps 520(519.69) | Grad Norm 6.3743(4.8136) | Total Time 0.00(0.00)\n",
      "Iter 0708 | Time 59.6857(56.4284) | Bit/dim 3.6963(3.6942) | Xent 0.0000(0.0000) | Loss 8.7305(9.2823) | Error 0.0000(0.0000) Steps 520(519.70) | Grad Norm 4.6519(4.8087) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 22.0355, Epoch Time 377.2493(363.4521), Bit/dim 3.6668(best: 3.6701), Xent 0.0000, Loss 3.6668, Error 1.0000(best: inf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0709 | Time 56.4049(56.4277) | Bit/dim 3.6730(3.6936) | Xent 0.0000(0.0000) | Loss 11.7725(9.3570) | Error 0.0000(0.0000) Steps 520(519.71) | Grad Norm 2.9558(4.7532) | Total Time 0.00(0.00)\n",
      "Iter 0710 | Time 56.4607(56.4287) | Bit/dim 3.6747(3.6930) | Xent 0.0000(0.0000) | Loss 8.5528(9.3328) | Error 0.0000(0.0000) Steps 520(519.72) | Grad Norm 3.6380(4.7197) | Total Time 0.00(0.00)\n",
      "Iter 0711 | Time 58.6461(56.4952) | Bit/dim 3.6860(3.6928) | Xent 0.0000(0.0000) | Loss 8.7365(9.3150) | Error 0.0000(0.0000) Steps 514(519.55) | Grad Norm 4.7222(4.7198) | Total Time 0.00(0.00)\n",
      "Iter 0712 | Time 56.9723(56.5095) | Bit/dim 3.6879(3.6926) | Xent 0.0000(0.0000) | Loss 8.6452(9.2949) | Error 0.0000(0.0000) Steps 502(519.02) | Grad Norm 4.4802(4.7126) | Total Time 0.00(0.00)\n",
      "Iter 0713 | Time 59.0621(56.5861) | Bit/dim 3.6649(3.6918) | Xent 0.0000(0.0000) | Loss 8.5707(9.2731) | Error 0.0000(0.0000) Steps 520(519.05) | Grad Norm 3.0465(4.6626) | Total Time 0.00(0.00)\n",
      "Iter 0714 | Time 60.0035(56.6886) | Bit/dim 3.6677(3.6911) | Xent 0.0000(0.0000) | Loss 8.7691(9.2580) | Error 0.0000(0.0000) Steps 544(519.80) | Grad Norm 3.6242(4.6315) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 22.2988, Epoch Time 394.6812(364.3890), Bit/dim 3.6670(best: 3.6668), Xent 0.0000, Loss 3.6670, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0715 | Time 57.7869(56.7216) | Bit/dim 3.6644(3.6903) | Xent 0.0000(0.0000) | Loss 12.0222(9.3409) | Error 0.0000(0.0000) Steps 532(520.16) | Grad Norm 3.7303(4.6044) | Total Time 0.00(0.00)\n",
      "Iter 0716 | Time 54.1525(56.6445) | Bit/dim 3.6585(3.6893) | Xent 0.0000(0.0000) | Loss 8.6842(9.3212) | Error 0.0000(0.0000) Steps 526(520.34) | Grad Norm 4.0215(4.5869) | Total Time 0.00(0.00)\n",
      "Iter 0717 | Time 53.8115(56.5595) | Bit/dim 3.6721(3.6888) | Xent 0.0000(0.0000) | Loss 8.7993(9.3056) | Error 0.0000(0.0000) Steps 514(520.15) | Grad Norm 5.0704(4.6014) | Total Time 0.00(0.00)\n",
      "Iter 0718 | Time 58.3789(56.6141) | Bit/dim 3.6937(3.6890) | Xent 0.0000(0.0000) | Loss 8.8082(9.2907) | Error 0.0000(0.0000) Steps 514(519.97) | Grad Norm 5.3857(4.6250) | Total Time 0.00(0.00)\n",
      "Iter 0719 | Time 58.7670(56.6787) | Bit/dim 3.6725(3.6885) | Xent 0.0000(0.0000) | Loss 8.7665(9.2749) | Error 0.0000(0.0000) Steps 526(520.15) | Grad Norm 4.4631(4.6201) | Total Time 0.00(0.00)\n",
      "Iter 0720 | Time 55.9332(56.6563) | Bit/dim 3.6655(3.6878) | Xent 0.0000(0.0000) | Loss 8.3810(9.2481) | Error 0.0000(0.0000) Steps 526(520.32) | Grad Norm 3.9396(4.5997) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 22.6511, Epoch Time 379.5536(364.8439), Bit/dim 3.6611(best: 3.6668), Xent 0.0000, Loss 3.6611, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0721 | Time 59.6158(56.7451) | Bit/dim 3.6537(3.6868) | Xent 0.0000(0.0000) | Loss 11.8830(9.3272) | Error 0.0000(0.0000) Steps 514(520.13) | Grad Norm 3.2715(4.5598) | Total Time 0.00(0.00)\n",
      "Iter 0722 | Time 54.2660(56.6707) | Bit/dim 3.6542(3.6858) | Xent 0.0000(0.0000) | Loss 8.6657(9.3073) | Error 0.0000(0.0000) Steps 520(520.13) | Grad Norm 3.1976(4.5190) | Total Time 0.00(0.00)\n",
      "Iter 0723 | Time 54.9471(56.6190) | Bit/dim 3.6740(3.6854) | Xent 0.0000(0.0000) | Loss 8.8349(9.2931) | Error 0.0000(0.0000) Steps 526(520.30) | Grad Norm 4.2887(4.5121) | Total Time 0.00(0.00)\n",
      "Iter 0724 | Time 55.8368(56.5955) | Bit/dim 3.6664(3.6848) | Xent 0.0000(0.0000) | Loss 8.6254(9.2731) | Error 0.0000(0.0000) Steps 508(519.94) | Grad Norm 4.3850(4.5083) | Total Time 0.00(0.00)\n",
      "Iter 0725 | Time 58.1643(56.6426) | Bit/dim 3.6633(3.6842) | Xent 0.0000(0.0000) | Loss 8.7089(9.2562) | Error 0.0000(0.0000) Steps 526(520.12) | Grad Norm 4.6544(4.5126) | Total Time 0.00(0.00)\n",
      "Iter 0726 | Time 57.7707(56.6765) | Bit/dim 3.6600(3.6835) | Xent 0.0000(0.0000) | Loss 8.7817(9.2419) | Error 0.0000(0.0000) Steps 520(520.11) | Grad Norm 4.2747(4.5055) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 21.3200, Epoch Time 380.1583(365.3034), Bit/dim 3.6679(best: 3.6611), Xent 0.0000, Loss 3.6679, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0727 | Time 56.0628(56.6580) | Bit/dim 3.6778(3.6833) | Xent 0.0000(0.0000) | Loss 11.7509(9.3172) | Error 0.0000(0.0000) Steps 514(519.93) | Grad Norm 4.4682(4.5044) | Total Time 0.00(0.00)\n",
      "Iter 0728 | Time 56.7404(56.6605) | Bit/dim 3.6763(3.6831) | Xent 0.0000(0.0000) | Loss 8.7691(9.3008) | Error 0.0000(0.0000) Steps 526(520.11) | Grad Norm 4.8328(4.5142) | Total Time 0.00(0.00)\n",
      "Iter 0729 | Time 57.4488(56.6842) | Bit/dim 3.6780(3.6829) | Xent 0.0000(0.0000) | Loss 8.7256(9.2835) | Error 0.0000(0.0000) Steps 514(519.93) | Grad Norm 6.0525(4.5604) | Total Time 0.00(0.00)\n",
      "Iter 0730 | Time 59.4814(56.7681) | Bit/dim 3.7091(3.6837) | Xent 0.0000(0.0000) | Loss 8.9716(9.2742) | Error 0.0000(0.0000) Steps 520(519.93) | Grad Norm 7.2672(4.6416) | Total Time 0.00(0.00)\n",
      "Iter 0731 | Time 53.2057(56.6612) | Bit/dim 3.6976(3.6841) | Xent 0.0000(0.0000) | Loss 8.8148(9.2604) | Error 0.0000(0.0000) Steps 514(519.75) | Grad Norm 5.9249(4.6801) | Total Time 0.00(0.00)\n",
      "Iter 0732 | Time 57.6582(56.6911) | Bit/dim 3.6862(3.6842) | Xent 0.0000(0.0000) | Loss 8.9206(9.2502) | Error 0.0000(0.0000) Steps 526(519.94) | Grad Norm 4.6663(4.6797) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 21.8574, Epoch Time 380.0119(365.7446), Bit/dim 3.7063(best: 3.6611), Xent 0.0000, Loss 3.7063, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0733 | Time 57.1482(56.7048) | Bit/dim 3.6992(3.6847) | Xent 0.0000(0.0000) | Loss 12.0400(9.3339) | Error 0.0000(0.0000) Steps 526(520.12) | Grad Norm 4.5190(4.6749) | Total Time 0.00(0.00)\n",
      "Iter 0734 | Time 57.7391(56.7359) | Bit/dim 3.6898(3.6848) | Xent 0.0000(0.0000) | Loss 8.6108(9.3122) | Error 0.0000(0.0000) Steps 526(520.30) | Grad Norm 4.7149(4.6761) | Total Time 0.00(0.00)\n",
      "Iter 0735 | Time 58.0512(56.7753) | Bit/dim 3.6772(3.6846) | Xent 0.0000(0.0000) | Loss 8.8060(9.2970) | Error 0.0000(0.0000) Steps 526(520.47) | Grad Norm 4.2636(4.6637) | Total Time 0.00(0.00)\n",
      "Iter 0736 | Time 59.8153(56.8665) | Bit/dim 3.6831(3.6845) | Xent 0.0000(0.0000) | Loss 8.8358(9.2832) | Error 0.0000(0.0000) Steps 544(521.18) | Grad Norm 4.9907(4.6735) | Total Time 0.00(0.00)\n",
      "Iter 0737 | Time 56.0592(56.8423) | Bit/dim 3.6749(3.6842) | Xent 0.0000(0.0000) | Loss 8.6803(9.2651) | Error 0.0000(0.0000) Steps 502(520.60) | Grad Norm 4.8119(4.6776) | Total Time 0.00(0.00)\n",
      "Iter 0738 | Time 56.9483(56.8455) | Bit/dim 3.6821(3.6842) | Xent 0.0000(0.0000) | Loss 8.5463(9.2435) | Error 0.0000(0.0000) Steps 532(520.94) | Grad Norm 4.8933(4.6841) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 22.3859, Epoch Time 387.1342(366.3863), Bit/dim 3.6738(best: 3.6611), Xent 0.0000, Loss 3.6738, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0739 | Time 54.4509(56.7736) | Bit/dim 3.6698(3.6838) | Xent 0.0000(0.0000) | Loss 12.1119(9.3296) | Error 0.0000(0.0000) Steps 526(521.09) | Grad Norm 4.3436(4.6739) | Total Time 0.00(0.00)\n",
      "Iter 0740 | Time 59.3465(56.8508) | Bit/dim 3.6598(3.6830) | Xent 0.0000(0.0000) | Loss 8.6482(9.3091) | Error 0.0000(0.0000) Steps 520(521.06) | Grad Norm 3.4348(4.6367) | Total Time 0.00(0.00)\n",
      "Iter 0741 | Time 55.9509(56.8238) | Bit/dim 3.6693(3.6826) | Xent 0.0000(0.0000) | Loss 8.4660(9.2838) | Error 0.0000(0.0000) Steps 508(520.67) | Grad Norm 3.0694(4.5897) | Total Time 0.00(0.00)\n",
      "Iter 0742 | Time 53.9453(56.7375) | Bit/dim 3.6517(3.6817) | Xent 0.0000(0.0000) | Loss 8.5610(9.2622) | Error 0.0000(0.0000) Steps 508(520.29) | Grad Norm 2.9943(4.5418) | Total Time 0.00(0.00)\n",
      "Iter 0743 | Time 55.3758(56.6966) | Bit/dim 3.6533(3.6808) | Xent 0.0000(0.0000) | Loss 8.5980(9.2422) | Error 0.0000(0.0000) Steps 514(520.10) | Grad Norm 3.0030(4.4957) | Total Time 0.00(0.00)\n",
      "Iter 0744 | Time 55.9136(56.6731) | Bit/dim 3.6562(3.6801) | Xent 0.0000(0.0000) | Loss 8.7645(9.2279) | Error 0.0000(0.0000) Steps 514(519.92) | Grad Norm 2.8815(4.4473) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 22.3893, Epoch Time 376.3133(366.6841), Bit/dim 3.6561(best: 3.6611), Xent 0.0000, Loss 3.6561, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0745 | Time 59.3724(56.7541) | Bit/dim 3.6429(3.6790) | Xent 0.0000(0.0000) | Loss 11.9088(9.3083) | Error 0.0000(0.0000) Steps 538(520.46) | Grad Norm 3.4191(4.4164) | Total Time 0.00(0.00)\n",
      "Iter 0746 | Time 52.7552(56.6341) | Bit/dim 3.6540(3.6782) | Xent 0.0000(0.0000) | Loss 8.6128(9.2875) | Error 0.0000(0.0000) Steps 514(520.27) | Grad Norm 4.5310(4.4198) | Total Time 0.00(0.00)\n",
      "Iter 0747 | Time 63.4172(56.8376) | Bit/dim 3.6764(3.6782) | Xent 0.0000(0.0000) | Loss 8.6604(9.2686) | Error 0.0000(0.0000) Steps 550(521.16) | Grad Norm 5.2419(4.4445) | Total Time 0.00(0.00)\n",
      "Iter 0748 | Time 54.2958(56.7614) | Bit/dim 3.6560(3.6775) | Xent 0.0000(0.0000) | Loss 8.6197(9.2492) | Error 0.0000(0.0000) Steps 526(521.30) | Grad Norm 5.2809(4.4696) | Total Time 0.00(0.00)\n",
      "Iter 0749 | Time 60.9445(56.8869) | Bit/dim 3.6565(3.6769) | Xent 0.0000(0.0000) | Loss 8.7281(9.2335) | Error 0.0000(0.0000) Steps 526(521.44) | Grad Norm 5.6215(4.5042) | Total Time 0.00(0.00)\n",
      "Iter 0750 | Time 56.0525(56.8618) | Bit/dim 3.6770(3.6769) | Xent 0.0000(0.0000) | Loss 8.9309(9.2245) | Error 0.0000(0.0000) Steps 526(521.58) | Grad Norm 6.0038(4.5491) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 22.6619, Epoch Time 387.9191(367.3212), Bit/dim 3.6892(best: 3.6561), Xent 0.0000, Loss 3.6892, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0751 | Time 56.2027(56.8421) | Bit/dim 3.6744(3.6768) | Xent 0.0000(0.0000) | Loss 12.0583(9.3095) | Error 0.0000(0.0000) Steps 520(521.53) | Grad Norm 6.9480(4.6211) | Total Time 0.00(0.00)\n",
      "Iter 0752 | Time 55.5522(56.8034) | Bit/dim 3.6622(3.6764) | Xent 0.0000(0.0000) | Loss 8.6864(9.2908) | Error 0.0000(0.0000) Steps 508(521.13) | Grad Norm 4.0184(4.6030) | Total Time 0.00(0.00)\n",
      "Iter 0753 | Time 58.0005(56.8393) | Bit/dim 3.6652(3.6760) | Xent 0.0000(0.0000) | Loss 8.8338(9.2771) | Error 0.0000(0.0000) Steps 520(521.09) | Grad Norm 3.4634(4.5688) | Total Time 0.00(0.00)\n",
      "Iter 0754 | Time 56.2335(56.8211) | Bit/dim 3.6665(3.6758) | Xent 0.0000(0.0000) | Loss 8.7566(9.2615) | Error 0.0000(0.0000) Steps 532(521.42) | Grad Norm 4.0974(4.5547) | Total Time 0.00(0.00)\n",
      "Iter 0755 | Time 54.3271(56.7463) | Bit/dim 3.6674(3.6755) | Xent 0.0000(0.0000) | Loss 8.7252(9.2454) | Error 0.0000(0.0000) Steps 520(521.38) | Grad Norm 3.6146(4.5265) | Total Time 0.00(0.00)\n",
      "Iter 0756 | Time 56.3160(56.7334) | Bit/dim 3.6453(3.6746) | Xent 0.0000(0.0000) | Loss 8.5914(9.2258) | Error 0.0000(0.0000) Steps 526(521.52) | Grad Norm 2.8772(4.4770) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 21.6714, Epoch Time 377.6269(367.6303), Bit/dim 3.6585(best: 3.6561), Xent 0.0000, Loss 3.6585, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n",
      "11.227544910179642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0757 | Time 59.0881(56.8040) | Bit/dim 3.6594(3.6741) | Xent 0.0000(0.0000) | Loss 11.8884(9.3056) | Error 0.0000(0.0000) Steps 532(521.83) | Grad Norm 3.3818(4.4442) | Total Time 0.00(0.00)\n",
      "Iter 0758 | Time 56.6779(56.8002) | Bit/dim 3.6619(3.6738) | Xent 0.0000(0.0000) | Loss 8.8608(9.2923) | Error 0.0000(0.0000) Steps 526(521.96) | Grad Norm 3.1863(4.4064) | Total Time 0.00(0.00)\n",
      "Iter 0759 | Time 56.0421(56.7775) | Bit/dim 3.6521(3.6731) | Xent 0.0000(0.0000) | Loss 8.5841(9.2710) | Error 0.0000(0.0000) Steps 514(521.72) | Grad Norm 3.4361(4.3773) | Total Time 0.00(0.00)\n",
      "Iter 0760 | Time 59.3573(56.8549) | Bit/dim 3.6414(3.6722) | Xent 0.0000(0.0000) | Loss 8.3229(9.2426) | Error 0.0000(0.0000) Steps 520(521.67) | Grad Norm 3.6896(4.3567) | Total Time 0.00(0.00)\n",
      "Iter 0761 | Time 58.0054(56.8894) | Bit/dim 3.6546(3.6716) | Xent 0.0000(0.0000) | Loss 8.7514(9.2279) | Error 0.0000(0.0000) Steps 532(521.98) | Grad Norm 4.4801(4.3604) | Total Time 0.00(0.00)\n",
      "Iter 0762 | Time 58.3702(56.9338) | Bit/dim 3.6508(3.6710) | Xent 0.0000(0.0000) | Loss 8.7701(9.2141) | Error 0.0000(0.0000) Steps 526(522.10) | Grad Norm 6.3761(4.4209) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 22.2082, Epoch Time 388.4994(368.2564), Bit/dim 3.6767(best: 3.6561), Xent 0.0000, Loss 3.6767, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n",
      "11.197604790419161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0763 | Time 61.4684(57.0699) | Bit/dim 3.6795(3.6713) | Xent 0.0000(0.0000) | Loss 12.0658(9.2997) | Error 0.0000(0.0000) Steps 532(522.39) | Grad Norm 6.9114(4.4956) | Total Time 0.00(0.00)\n",
      "Iter 0764 | Time 56.6479(57.0572) | Bit/dim 3.6585(3.6709) | Xent 0.0000(0.0000) | Loss 8.7526(9.2833) | Error 0.0000(0.0000) Steps 508(521.96) | Grad Norm 4.9464(4.5091) | Total Time 0.00(0.00)\n",
      "Iter 0765 | Time 60.8611(57.1713) | Bit/dim 3.6632(3.6707) | Xent 0.0000(0.0000) | Loss 8.7592(9.2676) | Error 0.0000(0.0000) Steps 538(522.44) | Grad Norm 4.2189(4.5004) | Total Time 0.00(0.00)\n",
      "Iter 0766 | Time 57.9456(57.1945) | Bit/dim 3.6593(3.6703) | Xent 0.0000(0.0000) | Loss 8.5814(9.2470) | Error 0.0000(0.0000) Steps 520(522.37) | Grad Norm 4.3984(4.4973) | Total Time 0.00(0.00)\n",
      "Iter 0767 | Time 55.5427(57.1450) | Bit/dim 3.6627(3.6701) | Xent 0.0000(0.0000) | Loss 8.5739(9.2268) | Error 0.0000(0.0000) Steps 514(522.12) | Grad Norm 3.9583(4.4812) | Total Time 0.00(0.00)\n",
      "Iter 0768 | Time 55.7572(57.1034) | Bit/dim 3.6728(3.6702) | Xent 0.0000(0.0000) | Loss 8.8139(9.2144) | Error 0.0000(0.0000) Steps 526(522.24) | Grad Norm 4.8718(4.4929) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 22.5460, Epoch Time 389.2122(368.8851), Bit/dim 3.6723(best: 3.6561), Xent 0.0000, Loss 3.6723, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n",
      "11.167664670658683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0769 | Time 60.2719(57.1984) | Bit/dim 3.6725(3.6702) | Xent 0.0000(0.0000) | Loss 12.1795(9.3033) | Error 0.0000(0.0000) Steps 550(523.07) | Grad Norm 5.1916(4.5138) | Total Time 0.00(0.00)\n",
      "Iter 0770 | Time 58.6955(57.2433) | Bit/dim 3.6846(3.6707) | Xent 0.0000(0.0000) | Loss 8.9451(9.2926) | Error 0.0000(0.0000) Steps 550(523.88) | Grad Norm 6.1732(4.5636) | Total Time 0.00(0.00)\n",
      "Iter 0771 | Time 54.0880(57.1487) | Bit/dim 3.6803(3.6710) | Xent 0.0000(0.0000) | Loss 8.8048(9.2780) | Error 0.0000(0.0000) Steps 514(523.58) | Grad Norm 6.9576(4.6354) | Total Time 0.00(0.00)\n",
      "Iter 0772 | Time 60.1683(57.2393) | Bit/dim 3.6895(3.6715) | Xent 0.0000(0.0000) | Loss 8.7701(9.2627) | Error 0.0000(0.0000) Steps 574(525.09) | Grad Norm 5.6290(4.6652) | Total Time 0.00(0.00)\n",
      "Iter 0773 | Time 57.5024(57.2472) | Bit/dim 3.6555(3.6710) | Xent 0.0000(0.0000) | Loss 8.6072(9.2431) | Error 0.0000(0.0000) Steps 526(525.12) | Grad Norm 3.7133(4.6367) | Total Time 0.00(0.00)\n",
      "Iter 0774 | Time 55.3471(57.1902) | Bit/dim 3.6856(3.6715) | Xent 0.0000(0.0000) | Loss 8.6254(9.2245) | Error 0.0000(0.0000) Steps 514(524.79) | Grad Norm 5.2281(4.6544) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 22.3852, Epoch Time 387.4183(369.4411), Bit/dim 3.6694(best: 3.6561), Xent 0.0000, Loss 3.6694, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n",
      "11.137724550898206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0775 | Time 57.4674(57.1985) | Bit/dim 3.6762(3.6716) | Xent 0.0000(0.0000) | Loss 12.1428(9.3121) | Error 0.0000(0.0000) Steps 514(524.46) | Grad Norm 4.7382(4.6569) | Total Time 0.00(0.00)\n",
      "Iter 0776 | Time 56.0916(57.1653) | Bit/dim 3.6558(3.6711) | Xent 0.0000(0.0000) | Loss 8.5692(9.2898) | Error 0.0000(0.0000) Steps 508(523.97) | Grad Norm 3.6247(4.6260) | Total Time 0.00(0.00)\n",
      "Iter 0777 | Time 60.3771(57.2616) | Bit/dim 3.6538(3.6706) | Xent 0.0000(0.0000) | Loss 8.8255(9.2759) | Error 0.0000(0.0000) Steps 532(524.21) | Grad Norm 3.2075(4.5834) | Total Time 0.00(0.00)\n",
      "Iter 0778 | Time 55.5615(57.2106) | Bit/dim 3.6616(3.6704) | Xent 0.0000(0.0000) | Loss 8.7574(9.2603) | Error 0.0000(0.0000) Steps 508(523.72) | Grad Norm 4.8415(4.5912) | Total Time 0.00(0.00)\n",
      "Iter 0779 | Time 54.7150(57.1357) | Bit/dim 3.6684(3.6703) | Xent 0.0000(0.0000) | Loss 8.7955(9.2464) | Error 0.0000(0.0000) Steps 520(523.61) | Grad Norm 4.9818(4.6029) | Total Time 0.00(0.00)\n",
      "Iter 0780 | Time 55.8749(57.0979) | Bit/dim 3.6732(3.6704) | Xent 0.0000(0.0000) | Loss 8.6892(9.2296) | Error 0.0000(0.0000) Steps 526(523.68) | Grad Norm 4.7553(4.6075) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 22.3086, Epoch Time 381.8520(369.8134), Bit/dim 3.6649(best: 3.6561), Xent 0.0000, Loss 3.6649, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n",
      "11.107784431137725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0781 | Time 54.8286(57.0298) | Bit/dim 3.6591(3.6700) | Xent 0.0000(0.0000) | Loss 12.2269(9.3196) | Error 0.0000(0.0000) Steps 520(523.57) | Grad Norm 4.6635(4.6091) | Total Time 0.00(0.00)\n",
      "Iter 0782 | Time 56.3934(57.0107) | Bit/dim 3.6683(3.6700) | Xent 0.0000(0.0000) | Loss 8.8821(9.3064) | Error 0.0000(0.0000) Steps 538(524.01) | Grad Norm 4.6753(4.6111) | Total Time 0.00(0.00)\n",
      "Iter 0783 | Time 57.0357(57.0115) | Bit/dim 3.6734(3.6701) | Xent 0.0000(0.0000) | Loss 8.7566(9.2899) | Error 0.0000(0.0000) Steps 538(524.43) | Grad Norm 5.3342(4.6328) | Total Time 0.00(0.00)\n",
      "Iter 0784 | Time 58.7450(57.0635) | Bit/dim 3.6564(3.6697) | Xent 0.0000(0.0000) | Loss 8.6477(9.2707) | Error 0.0000(0.0000) Steps 520(524.29) | Grad Norm 4.2487(4.6213) | Total Time 0.00(0.00)\n",
      "Iter 0785 | Time 55.8202(57.0262) | Bit/dim 3.6477(3.6690) | Xent 0.0000(0.0000) | Loss 8.8193(9.2571) | Error 0.0000(0.0000) Steps 538(524.70) | Grad Norm 4.4225(4.6153) | Total Time 0.00(0.00)\n",
      "Iter 0786 | Time 55.4013(56.9774) | Bit/dim 3.6737(3.6692) | Xent 0.0000(0.0000) | Loss 8.6722(9.2396) | Error 0.0000(0.0000) Steps 526(524.74) | Grad Norm 5.9012(4.6539) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 22.3563, Epoch Time 379.8365(370.1141), Bit/dim 3.6637(best: 3.6561), Xent 0.0000, Loss 3.6637, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n",
      "11.077844311377245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0787 | Time 59.0976(57.0411) | Bit/dim 3.6628(3.6690) | Xent 0.0000(0.0000) | Loss 11.7212(9.3140) | Error 0.0000(0.0000) Steps 532(524.96) | Grad Norm 4.3862(4.6459) | Total Time 0.00(0.00)\n",
      "Iter 0788 | Time 56.6264(57.0286) | Bit/dim 3.6482(3.6684) | Xent 0.0000(0.0000) | Loss 8.6341(9.2936) | Error 0.0000(0.0000) Steps 532(525.17) | Grad Norm 3.2517(4.6041) | Total Time 0.00(0.00)\n",
      "Iter 0789 | Time 59.4885(57.1024) | Bit/dim 3.6549(3.6679) | Xent 0.0000(0.0000) | Loss 8.8782(9.2812) | Error 0.0000(0.0000) Steps 538(525.56) | Grad Norm 3.5144(4.5714) | Total Time 0.00(0.00)\n",
      "Iter 0790 | Time 61.1371(57.2234) | Bit/dim 3.6383(3.6671) | Xent 0.0000(0.0000) | Loss 8.7714(9.2659) | Error 0.0000(0.0000) Steps 532(525.75) | Grad Norm 3.4514(4.5378) | Total Time 0.00(0.00)\n",
      "Iter 0791 | Time 55.7901(57.1804) | Bit/dim 3.6412(3.6663) | Xent 0.0000(0.0000) | Loss 8.7347(9.2499) | Error 0.0000(0.0000) Steps 520(525.58) | Grad Norm 3.3713(4.5028) | Total Time 0.00(0.00)\n",
      "Iter 0792 | Time 53.1031(57.0581) | Bit/dim 3.6400(3.6655) | Xent 0.0000(0.0000) | Loss 8.5337(9.2285) | Error 0.0000(0.0000) Steps 514(525.23) | Grad Norm 3.2415(4.4649) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 22.1570, Epoch Time 386.6929(370.6115), Bit/dim 3.6469(best: 3.6561), Xent 0.0000, Loss 3.6469, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n",
      "11.047904191616766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0793 | Time 53.6763(56.9567) | Bit/dim 3.6408(3.6648) | Xent 0.0000(0.0000) | Loss 11.5557(9.2983) | Error 0.0000(0.0000) Steps 526(525.25) | Grad Norm 3.7926(4.4448) | Total Time 0.00(0.00)\n",
      "Iter 0794 | Time 55.2380(56.9051) | Bit/dim 3.6493(3.6643) | Xent 0.0000(0.0000) | Loss 8.4756(9.2736) | Error 0.0000(0.0000) Steps 526(525.28) | Grad Norm 3.6458(4.4208) | Total Time 0.00(0.00)\n",
      "Iter 0795 | Time 59.4532(56.9816) | Bit/dim 3.6421(3.6636) | Xent 0.0000(0.0000) | Loss 8.7327(9.2574) | Error 0.0000(0.0000) Steps 532(525.48) | Grad Norm 4.1240(4.4119) | Total Time 0.00(0.00)\n",
      "Iter 0796 | Time 55.5366(56.9382) | Bit/dim 3.6272(3.6625) | Xent 0.0000(0.0000) | Loss 8.7120(9.2410) | Error 0.0000(0.0000) Steps 532(525.67) | Grad Norm 4.0092(4.3998) | Total Time 0.00(0.00)\n",
      "Iter 0797 | Time 54.0051(56.8502) | Bit/dim 3.6461(3.6620) | Xent 0.0000(0.0000) | Loss 8.7736(9.2270) | Error 0.0000(0.0000) Steps 514(525.32) | Grad Norm 4.7088(4.4091) | Total Time 0.00(0.00)\n",
      "Iter 0798 | Time 57.4199(56.8673) | Bit/dim 3.6592(3.6619) | Xent 0.0000(0.0000) | Loss 8.6233(9.2089) | Error 0.0000(0.0000) Steps 520(525.16) | Grad Norm 5.1847(4.4323) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 22.0371, Epoch Time 375.9581(370.7719), Bit/dim 3.6401(best: 3.6469), Xent 0.0000, Loss 3.6401, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n",
      "11.017964071856287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0799 | Time 57.0281(56.8721) | Bit/dim 3.6344(3.6611) | Xent 0.0000(0.0000) | Loss 12.3045(9.3017) | Error 0.0000(0.0000) Steps 508(524.65) | Grad Norm 4.5648(4.4363) | Total Time 0.00(0.00)\n",
      "Iter 0800 | Time 56.7565(56.8687) | Bit/dim 3.6462(3.6607) | Xent 0.0000(0.0000) | Loss 8.7298(9.2846) | Error 0.0000(0.0000) Steps 538(525.05) | Grad Norm 3.4936(4.4080) | Total Time 0.00(0.00)\n",
      "Iter 0801 | Time 56.5813(56.8600) | Bit/dim 3.6299(3.6597) | Xent 0.0000(0.0000) | Loss 8.7432(9.2683) | Error 0.0000(0.0000) Steps 538(525.44) | Grad Norm 3.0661(4.3678) | Total Time 0.00(0.00)\n",
      "Iter 0802 | Time 53.7718(56.7674) | Bit/dim 3.6322(3.6589) | Xent 0.0000(0.0000) | Loss 8.6797(9.2507) | Error 0.0000(0.0000) Steps 526(525.45) | Grad Norm 3.7384(4.3489) | Total Time 0.00(0.00)\n",
      "Iter 0803 | Time 55.3042(56.7235) | Bit/dim 3.6467(3.6586) | Xent 0.0000(0.0000) | Loss 8.7479(9.2356) | Error 0.0000(0.0000) Steps 532(525.65) | Grad Norm 4.3821(4.3499) | Total Time 0.00(0.00)\n",
      "Iter 0804 | Time 58.8929(56.7886) | Bit/dim 3.6486(3.6583) | Xent 0.0000(0.0000) | Loss 8.5284(9.2144) | Error 0.0000(0.0000) Steps 544(526.20) | Grad Norm 5.1527(4.3740) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 22.5832, Epoch Time 379.1449(371.0231), Bit/dim 3.6473(best: 3.6401), Xent 0.0000, Loss 3.6473, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n",
      "10.988023952095809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0805 | Time 56.3887(56.7766) | Bit/dim 3.6516(3.6581) | Xent 0.0000(0.0000) | Loss 12.0012(9.2980) | Error 0.0000(0.0000) Steps 526(526.20) | Grad Norm 4.5080(4.3780) | Total Time 0.00(0.00)\n",
      "Iter 0806 | Time 60.3530(56.8839) | Bit/dim 3.6177(3.6568) | Xent 0.0000(0.0000) | Loss 8.5213(9.2747) | Error 0.0000(0.0000) Steps 550(526.91) | Grad Norm 3.4172(4.3492) | Total Time 0.00(0.00)\n",
      "Iter 0807 | Time 55.3497(56.8379) | Bit/dim 3.6422(3.6564) | Xent 0.0000(0.0000) | Loss 8.5964(9.2543) | Error 0.0000(0.0000) Steps 544(527.42) | Grad Norm 4.0036(4.3388) | Total Time 0.00(0.00)\n",
      "Iter 0808 | Time 55.0047(56.7829) | Bit/dim 3.6391(3.6559) | Xent 0.0000(0.0000) | Loss 8.6671(9.2367) | Error 0.0000(0.0000) Steps 532(527.56) | Grad Norm 4.8569(4.3544) | Total Time 0.00(0.00)\n",
      "Iter 0809 | Time 61.4226(56.9221) | Bit/dim 3.6147(3.6547) | Xent 0.0000(0.0000) | Loss 8.4771(9.2139) | Error 0.0000(0.0000) Steps 550(528.23) | Grad Norm 3.8707(4.3398) | Total Time 0.00(0.00)\n",
      "Iter 0810 | Time 57.5901(56.9421) | Bit/dim 3.6291(3.6539) | Xent 0.0000(0.0000) | Loss 8.5294(9.1934) | Error 0.0000(0.0000) Steps 514(527.81) | Grad Norm 3.0040(4.2998) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 21.3458, Epoch Time 385.5653(371.4593), Bit/dim 3.6335(best: 3.6401), Xent 0.0000, Loss 3.6335, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n",
      "10.95808383233533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0811 | Time 53.9434(56.8521) | Bit/dim 3.6411(3.6535) | Xent 0.0000(0.0000) | Loss 11.9410(9.2758) | Error 0.0000(0.0000) Steps 520(527.57) | Grad Norm 3.8815(4.2872) | Total Time 0.00(0.00)\n",
      "Iter 0812 | Time 57.0890(56.8592) | Bit/dim 3.6333(3.6529) | Xent 0.0000(0.0000) | Loss 8.5638(9.2545) | Error 0.0000(0.0000) Steps 520(527.34) | Grad Norm 4.6371(4.2977) | Total Time 0.00(0.00)\n",
      "Iter 0813 | Time 63.5070(57.0587) | Bit/dim 3.6360(3.6524) | Xent 0.0000(0.0000) | Loss 8.7901(9.2405) | Error 0.0000(0.0000) Steps 532(527.48) | Grad Norm 5.4763(4.3331) | Total Time 0.00(0.00)\n",
      "Iter 0814 | Time 58.2814(57.0954) | Bit/dim 3.6595(3.6526) | Xent 0.0000(0.0000) | Loss 8.7130(9.2247) | Error 0.0000(0.0000) Steps 532(527.62) | Grad Norm 5.6773(4.3734) | Total Time 0.00(0.00)\n",
      "Iter 0815 | Time 63.1932(57.2783) | Bit/dim 3.6133(3.6514) | Xent 0.0000(0.0000) | Loss 8.7492(9.2104) | Error 0.0000(0.0000) Steps 538(527.93) | Grad Norm 3.7518(4.3548) | Total Time 0.00(0.00)\n",
      "Iter 0816 | Time 62.4937(57.4348) | Bit/dim 3.6476(3.6513) | Xent 0.0000(0.0000) | Loss 8.6291(9.1930) | Error 0.0000(0.0000) Steps 520(527.69) | Grad Norm 3.6245(4.3328) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 21.3441, Epoch Time 398.8017(372.2796), Bit/dim 3.6384(best: 3.6335), Xent 0.0000, Loss 3.6384, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n",
      "10.92814371257485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0817 | Time 58.8956(57.4786) | Bit/dim 3.6334(3.6508) | Xent 0.0000(0.0000) | Loss 11.6794(9.2676) | Error 0.0000(0.0000) Steps 538(528.00) | Grad Norm 3.9754(4.3221) | Total Time 0.00(0.00)\n",
      "Iter 0818 | Time 54.6820(57.3947) | Bit/dim 3.6432(3.6505) | Xent 0.0000(0.0000) | Loss 8.7953(9.2534) | Error 0.0000(0.0000) Steps 538(528.30) | Grad Norm 3.5067(4.2977) | Total Time 0.00(0.00)\n",
      "Iter 0819 | Time 62.8750(57.5591) | Bit/dim 3.6431(3.6503) | Xent 0.0000(0.0000) | Loss 8.6866(9.2364) | Error 0.0000(0.0000) Steps 544(528.77) | Grad Norm 3.8540(4.2843) | Total Time 0.00(0.00)\n",
      "Iter 0820 | Time 58.1007(57.5753) | Bit/dim 3.6497(3.6503) | Xent 0.0000(0.0000) | Loss 8.5451(9.2157) | Error 0.0000(0.0000) Steps 538(529.05) | Grad Norm 5.0277(4.3066) | Total Time 0.00(0.00)\n",
      "Iter 0821 | Time 59.6966(57.6390) | Bit/dim 3.6458(3.6502) | Xent 0.0000(0.0000) | Loss 8.5355(9.1953) | Error 0.0000(0.0000) Steps 532(529.14) | Grad Norm 5.6057(4.3456) | Total Time 0.00(0.00)\n",
      "Iter 0822 | Time 58.2221(57.6565) | Bit/dim 3.6581(3.6504) | Xent 0.0000(0.0000) | Loss 8.7068(9.1806) | Error 0.0000(0.0000) Steps 544(529.58) | Grad Norm 4.8909(4.3620) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 22.1446, Epoch Time 393.2650(372.9092), Bit/dim 3.6419(best: 3.6335), Xent 0.0000, Loss 3.6419, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n",
      "10.89820359281437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0823 | Time 58.4654(57.6807) | Bit/dim 3.6383(3.6500) | Xent 0.0000(0.0000) | Loss 12.0751(9.2675) | Error 0.0000(0.0000) Steps 550(530.20) | Grad Norm 3.9670(4.3501) | Total Time 0.00(0.00)\n",
      "Iter 0824 | Time 62.9256(57.8381) | Bit/dim 3.6660(3.6505) | Xent 0.0000(0.0000) | Loss 8.9293(9.2573) | Error 0.0000(0.0000) Steps 550(530.79) | Grad Norm 5.0924(4.3724) | Total Time 0.00(0.00)\n",
      "Iter 0825 | Time 53.9404(57.7211) | Bit/dim 3.6875(3.6516) | Xent 0.0000(0.0000) | Loss 8.5405(9.2358) | Error 0.0000(0.0000) Steps 508(530.11) | Grad Norm 5.1554(4.3959) | Total Time 0.00(0.00)\n",
      "Iter 0826 | Time 54.8152(57.6340) | Bit/dim 3.6543(3.6517) | Xent 0.0000(0.0000) | Loss 8.7664(9.2217) | Error 0.0000(0.0000) Steps 532(530.16) | Grad Norm 5.4261(4.4268) | Total Time 0.00(0.00)\n",
      "Iter 0827 | Time 53.9600(57.5238) | Bit/dim 3.6570(3.6519) | Xent 0.0000(0.0000) | Loss 8.7565(9.2078) | Error 0.0000(0.0000) Steps 514(529.68) | Grad Norm 5.5311(4.4599) | Total Time 0.00(0.00)\n",
      "Iter 0828 | Time 54.4466(57.4314) | Bit/dim 3.6601(3.6521) | Xent 0.0000(0.0000) | Loss 8.8039(9.1957) | Error 0.0000(0.0000) Steps 526(529.57) | Grad Norm 5.4428(4.4894) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 22.8245, Epoch Time 380.6771(373.1422), Bit/dim 3.6543(best: 3.6335), Xent 0.0000, Loss 3.6543, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n",
      "10.868263473053894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0829 | Time 60.2380(57.5156) | Bit/dim 3.6551(3.6522) | Xent 0.0000(0.0000) | Loss 12.1464(9.2842) | Error 0.0000(0.0000) Steps 514(529.10) | Grad Norm 4.7537(4.4973) | Total Time 0.00(0.00)\n",
      "Iter 0830 | Time 59.0575(57.5619) | Bit/dim 3.6651(3.6526) | Xent 0.0000(0.0000) | Loss 8.6781(9.2660) | Error 0.0000(0.0000) Steps 544(529.55) | Grad Norm 4.7312(4.5044) | Total Time 0.00(0.00)\n",
      "Iter 0831 | Time 55.4212(57.4977) | Bit/dim 3.6609(3.6528) | Xent 0.0000(0.0000) | Loss 8.6244(9.2467) | Error 0.0000(0.0000) Steps 532(529.62) | Grad Norm 4.3427(4.4995) | Total Time 0.00(0.00)\n",
      "Iter 0832 | Time 60.5400(57.5889) | Bit/dim 3.6662(3.6532) | Xent 0.0000(0.0000) | Loss 8.6476(9.2288) | Error 0.0000(0.0000) Steps 532(529.69) | Grad Norm 3.9259(4.4823) | Total Time 0.00(0.00)\n",
      "Iter 0833 | Time 56.1698(57.5464) | Bit/dim 3.6490(3.6531) | Xent 0.0000(0.0000) | Loss 8.7594(9.2147) | Error 0.0000(0.0000) Steps 532(529.76) | Grad Norm 3.9870(4.4674) | Total Time 0.00(0.00)\n",
      "Iter 0834 | Time 58.3311(57.5699) | Bit/dim 3.6386(3.6527) | Xent 0.0000(0.0000) | Loss 8.5706(9.1954) | Error 0.0000(0.0000) Steps 526(529.65) | Grad Norm 3.7990(4.4474) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 22.2998, Epoch Time 390.7974(373.6719), Bit/dim 3.6565(best: 3.6335), Xent 0.0000, Loss 3.6565, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n",
      "10.838323353293413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0835 | Time 54.1020(57.4659) | Bit/dim 3.6518(3.6527) | Xent 0.0000(0.0000) | Loss 11.7975(9.2734) | Error 0.0000(0.0000) Steps 520(529.36) | Grad Norm 5.2255(4.4707) | Total Time 0.00(0.00)\n",
      "Iter 0836 | Time 54.8894(57.3886) | Bit/dim 3.6352(3.6521) | Xent 0.0000(0.0000) | Loss 8.6458(9.2546) | Error 0.0000(0.0000) Steps 514(528.90) | Grad Norm 4.4388(4.4698) | Total Time 0.00(0.00)\n",
      "Iter 0837 | Time 54.4940(57.3017) | Bit/dim 3.6413(3.6518) | Xent 0.0000(0.0000) | Loss 8.4054(9.2291) | Error 0.0000(0.0000) Steps 520(528.63) | Grad Norm 3.5002(4.4407) | Total Time 0.00(0.00)\n",
      "Iter 0838 | Time 60.9842(57.4122) | Bit/dim 3.6453(3.6516) | Xent 0.0000(0.0000) | Loss 8.6452(9.2116) | Error 0.0000(0.0000) Steps 544(529.09) | Grad Norm 3.7462(4.4198) | Total Time 0.00(0.00)\n",
      "Iter 0839 | Time 59.0998(57.4628) | Bit/dim 3.6458(3.6514) | Xent 0.0000(0.0000) | Loss 8.8041(9.1994) | Error 0.0000(0.0000) Steps 544(529.54) | Grad Norm 5.0010(4.4373) | Total Time 0.00(0.00)\n",
      "Iter 0840 | Time 59.8223(57.5336) | Bit/dim 3.6334(3.6509) | Xent 0.0000(0.0000) | Loss 8.7383(9.1856) | Error 0.0000(0.0000) Steps 556(530.33) | Grad Norm 4.5152(4.4396) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 21.4055, Epoch Time 383.1309(373.9556), Bit/dim 3.6357(best: 3.6335), Xent 0.0000, Loss 3.6357, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n",
      "10.808383233532933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0841 | Time 59.5541(57.5942) | Bit/dim 3.6334(3.6504) | Xent 0.0000(0.0000) | Loss 12.1780(9.2753) | Error 0.0000(0.0000) Steps 526(530.20) | Grad Norm 4.0458(4.4278) | Total Time 0.00(0.00)\n",
      "Iter 0842 | Time 58.8724(57.6326) | Bit/dim 3.6429(3.6501) | Xent 0.0000(0.0000) | Loss 8.6738(9.2573) | Error 0.0000(0.0000) Steps 544(530.62) | Grad Norm 3.5869(4.4026) | Total Time 0.00(0.00)\n",
      "Iter 0843 | Time 62.8317(57.7886) | Bit/dim 3.6200(3.6492) | Xent 0.0000(0.0000) | Loss 8.5407(9.2358) | Error 0.0000(0.0000) Steps 538(530.84) | Grad Norm 3.1943(4.3663) | Total Time 0.00(0.00)\n",
      "Iter 0844 | Time 57.8964(57.7918) | Bit/dim 3.6221(3.6484) | Xent 0.0000(0.0000) | Loss 8.7150(9.2202) | Error 0.0000(0.0000) Steps 526(530.69) | Grad Norm 2.9897(4.3250) | Total Time 0.00(0.00)\n",
      "Iter 0845 | Time 57.6278(57.7869) | Bit/dim 3.6238(3.6477) | Xent 0.0000(0.0000) | Loss 8.7303(9.2055) | Error 0.0000(0.0000) Steps 526(530.55) | Grad Norm 2.9116(4.2826) | Total Time 0.00(0.00)\n",
      "Iter 0846 | Time 66.3098(58.0426) | Bit/dim 3.6190(3.6468) | Xent 0.0000(0.0000) | Loss 8.5534(9.1859) | Error 0.0000(0.0000) Steps 544(530.96) | Grad Norm 3.2052(4.2503) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0141 | Time 22.4705, Epoch Time 404.0556(374.8586), Bit/dim 3.6274(best: 3.6335), Xent 0.0000, Loss 3.6274, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n",
      "10.778443113772456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0847 | Time 57.7258(58.0331) | Bit/dim 3.6270(3.6462) | Xent 0.0000(0.0000) | Loss 11.8522(9.2659) | Error 0.0000(0.0000) Steps 526(530.81) | Grad Norm 4.3422(4.2531) | Total Time 0.00(0.00)\n",
      "Iter 0848 | Time 60.5190(58.1076) | Bit/dim 3.6448(3.6462) | Xent 0.0000(0.0000) | Loss 8.6766(9.2482) | Error 0.0000(0.0000) Steps 538(531.02) | Grad Norm 5.2973(4.2844) | Total Time 0.00(0.00)\n",
      "Iter 0849 | Time 53.0425(57.9557) | Bit/dim 3.6492(3.6463) | Xent 0.0000(0.0000) | Loss 8.6154(9.2292) | Error 0.0000(0.0000) Steps 508(530.33) | Grad Norm 5.6089(4.3241) | Total Time 0.00(0.00)\n",
      "Iter 0850 | Time 62.2394(58.0842) | Bit/dim 3.6287(3.6458) | Xent 0.0000(0.0000) | Loss 8.7489(9.2148) | Error 0.0000(0.0000) Steps 532(530.38) | Grad Norm 4.4452(4.3278) | Total Time 0.00(0.00)\n",
      "Iter 0851 | Time 56.6514(58.0412) | Bit/dim 3.6148(3.6448) | Xent 0.0000(0.0000) | Loss 8.5866(9.1960) | Error 0.0000(0.0000) Steps 526(530.25) | Grad Norm 3.0314(4.2889) | Total Time 0.00(0.00)\n",
      "Iter 0852 | Time 56.2049(57.9861) | Bit/dim 3.6315(3.6444) | Xent 0.0000(0.0000) | Loss 8.5831(9.1776) | Error 0.0000(0.0000) Steps 526(530.12) | Grad Norm 3.4128(4.2626) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0142 | Time 21.8687, Epoch Time 387.0173(375.2234), Bit/dim 3.6178(best: 3.6274), Xent 0.0000, Loss 3.6178, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n",
      "10.748502994011977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0853 | Time 58.4912(58.0013) | Bit/dim 3.6284(3.6440) | Xent 0.0000(0.0000) | Loss 11.7780(9.2556) | Error 0.0000(0.0000) Steps 508(529.46) | Grad Norm 3.6047(4.2428) | Total Time 0.00(0.00)\n",
      "Iter 0854 | Time 57.1056(57.9744) | Bit/dim 3.6389(3.6438) | Xent 0.0000(0.0000) | Loss 8.5701(9.2350) | Error 0.0000(0.0000) Steps 532(529.54) | Grad Norm 5.1958(4.2714) | Total Time 0.00(0.00)\n",
      "Iter 0855 | Time 53.0200(57.8258) | Bit/dim 3.6445(3.6438) | Xent 0.0000(0.0000) | Loss 8.3069(9.2072) | Error 0.0000(0.0000) Steps 508(528.89) | Grad Norm 4.7470(4.2857) | Total Time 0.00(0.00)\n",
      "Iter 0856 | Time 53.7084(57.7023) | Bit/dim 3.6130(3.6429) | Xent 0.0000(0.0000) | Loss 8.6839(9.1915) | Error 0.0000(0.0000) Steps 520(528.62) | Grad Norm 3.0422(4.2484) | Total Time 0.00(0.00)\n",
      "Iter 0857 | Time 58.4107(57.7235) | Bit/dim 3.6437(3.6429) | Xent 0.0000(0.0000) | Loss 8.4947(9.1706) | Error 0.0000(0.0000) Steps 520(528.37) | Grad Norm 4.7315(4.2629) | Total Time 0.00(0.00)\n",
      "Iter 0858 | Time 57.8488(57.7273) | Bit/dim 3.6268(3.6424) | Xent 0.0000(0.0000) | Loss 8.7086(9.1567) | Error 0.0000(0.0000) Steps 538(528.65) | Grad Norm 3.6919(4.2458) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0143 | Time 22.5542, Epoch Time 379.9048(375.3638), Bit/dim 3.6354(best: 3.6178), Xent 0.0000, Loss 3.6354, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n",
      "10.718562874251496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0859 | Time 54.7178(57.6370) | Bit/dim 3.6216(3.6418) | Xent 0.0000(0.0000) | Loss 12.3229(9.2517) | Error 0.0000(0.0000) Steps 544(529.11) | Grad Norm 3.2252(4.2151) | Total Time 0.00(0.00)\n",
      "Iter 0860 | Time 60.1112(57.7112) | Bit/dim 3.6517(3.6421) | Xent 0.0000(0.0000) | Loss 8.6579(9.2339) | Error 0.0000(0.0000) Steps 532(529.20) | Grad Norm 4.0984(4.2116) | Total Time 0.00(0.00)\n",
      "Iter 0861 | Time 55.3367(57.6400) | Bit/dim 3.6177(3.6414) | Xent 0.0000(0.0000) | Loss 8.5554(9.2135) | Error 0.0000(0.0000) Steps 526(529.11) | Grad Norm 3.8834(4.2018) | Total Time 0.00(0.00)\n",
      "Iter 0862 | Time 59.6629(57.7007) | Bit/dim 3.6319(3.6411) | Xent 0.0000(0.0000) | Loss 8.6331(9.1961) | Error 0.0000(0.0000) Steps 538(529.37) | Grad Norm 4.1731(4.2009) | Total Time 0.00(0.00)\n",
      "Iter 0863 | Time 62.1510(57.8342) | Bit/dim 3.6460(3.6412) | Xent 0.0000(0.0000) | Loss 8.7058(9.1814) | Error 0.0000(0.0000) Steps 544(529.81) | Grad Norm 4.4405(4.2081) | Total Time 0.00(0.00)\n",
      "Iter 0864 | Time 57.9942(57.8390) | Bit/dim 3.6124(3.6404) | Xent 0.0000(0.0000) | Loss 8.6276(9.1648) | Error 0.0000(0.0000) Steps 544(530.24) | Grad Norm 3.1688(4.1769) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0144 | Time 21.6040, Epoch Time 390.1963(375.8088), Bit/dim 3.6251(best: 3.6178), Xent 0.0000, Loss 3.6251, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n",
      "10.688622754491018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0865 | Time 54.0623(57.7257) | Bit/dim 3.6260(3.6399) | Xent 0.0000(0.0000) | Loss 12.0821(9.2523) | Error 0.0000(0.0000) Steps 532(530.29) | Grad Norm 3.2321(4.1486) | Total Time 0.00(0.00)\n",
      "Iter 0866 | Time 59.3945(57.7757) | Bit/dim 3.6203(3.6394) | Xent 0.0000(0.0000) | Loss 8.7069(9.2360) | Error 0.0000(0.0000) Steps 544(530.70) | Grad Norm 2.7275(4.1060) | Total Time 0.00(0.00)\n",
      "Iter 0867 | Time 59.4990(57.8274) | Bit/dim 3.6108(3.6385) | Xent 0.0000(0.0000) | Loss 8.5029(9.2140) | Error 0.0000(0.0000) Steps 538(530.92) | Grad Norm 3.4384(4.0859) | Total Time 0.00(0.00)\n",
      "Iter 0868 | Time 57.4795(57.8170) | Bit/dim 3.6227(3.6380) | Xent 0.0000(0.0000) | Loss 8.6942(9.1984) | Error 0.0000(0.0000) Steps 532(530.95) | Grad Norm 4.7304(4.1053) | Total Time 0.00(0.00)\n",
      "Iter 0869 | Time 58.2553(57.8301) | Bit/dim 3.6393(3.6381) | Xent 0.0000(0.0000) | Loss 8.6700(9.1825) | Error 0.0000(0.0000) Steps 526(530.80) | Grad Norm 5.2930(4.1409) | Total Time 0.00(0.00)\n",
      "Iter 0870 | Time 62.2646(57.9632) | Bit/dim 3.6466(3.6383) | Xent 0.0000(0.0000) | Loss 8.8588(9.1728) | Error 0.0000(0.0000) Steps 550(531.38) | Grad Norm 5.1553(4.1713) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0145 | Time 21.7716, Epoch Time 390.7581(376.2573), Bit/dim 3.6403(best: 3.6178), Xent 0.0000, Loss 3.6403, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n",
      "10.658682634730539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0871 | Time 56.9776(57.9336) | Bit/dim 3.6232(3.6379) | Xent 0.0000(0.0000) | Loss 12.1107(9.2609) | Error 0.0000(0.0000) Steps 532(531.40) | Grad Norm 4.4991(4.1812) | Total Time 0.00(0.00)\n",
      "Iter 0872 | Time 58.8899(57.9623) | Bit/dim 3.6326(3.6377) | Xent 0.0000(0.0000) | Loss 8.7385(9.2453) | Error 0.0000(0.0000) Steps 532(531.42) | Grad Norm 4.7393(4.1979) | Total Time 0.00(0.00)\n",
      "Iter 0873 | Time 58.7538(57.9860) | Bit/dim 3.6288(3.6374) | Xent 0.0000(0.0000) | Loss 8.7386(9.2301) | Error 0.0000(0.0000) Steps 550(531.97) | Grad Norm 3.8587(4.1877) | Total Time 0.00(0.00)\n",
      "Iter 0874 | Time 62.8593(58.1322) | Bit/dim 3.6158(3.6368) | Xent 0.0000(0.0000) | Loss 8.7636(9.2161) | Error 0.0000(0.0000) Steps 544(532.33) | Grad Norm 3.1073(4.1553) | Total Time 0.00(0.00)\n",
      "Iter 0875 | Time 60.9270(58.2161) | Bit/dim 3.6142(3.6361) | Xent 0.0000(0.0000) | Loss 8.7465(9.2020) | Error 0.0000(0.0000) Steps 538(532.50) | Grad Norm 3.2987(4.1296) | Total Time 0.00(0.00)\n",
      "Iter 0876 | Time 60.1303(58.2735) | Bit/dim 3.6266(3.6358) | Xent 0.0000(0.0000) | Loss 8.4695(9.1800) | Error 0.0000(0.0000) Steps 532(532.49) | Grad Norm 4.7902(4.1494) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0146 | Time 21.7029, Epoch Time 399.5477(376.9560), Bit/dim 3.6347(best: 3.6178), Xent 0.0000, Loss 3.6347, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n",
      "10.62874251497006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0877 | Time 55.1071(58.1785) | Bit/dim 3.6293(3.6356) | Xent 0.0000(0.0000) | Loss 12.0623(9.2665) | Error 0.0000(0.0000) Steps 544(532.83) | Grad Norm 5.4235(4.1877) | Total Time 0.00(0.00)\n",
      "Iter 0878 | Time 54.6973(58.0741) | Bit/dim 3.6335(3.6356) | Xent 0.0000(0.0000) | Loss 8.6384(9.2476) | Error 0.0000(0.0000) Steps 532(532.81) | Grad Norm 4.8374(4.2072) | Total Time 0.00(0.00)\n",
      "Iter 0879 | Time 58.8139(58.0963) | Bit/dim 3.6319(3.6355) | Xent 0.0000(0.0000) | Loss 8.6919(9.2310) | Error 0.0000(0.0000) Steps 538(532.97) | Grad Norm 4.3985(4.2129) | Total Time 0.00(0.00)\n",
      "Iter 0880 | Time 57.4832(58.0779) | Bit/dim 3.6356(3.6355) | Xent 0.0000(0.0000) | Loss 8.7356(9.2161) | Error 0.0000(0.0000) Steps 526(532.76) | Grad Norm 3.9760(4.2058) | Total Time 0.00(0.00)\n",
      "Iter 0881 | Time 56.2959(58.0244) | Bit/dim 3.6092(3.6347) | Xent 0.0000(0.0000) | Loss 8.5240(9.1953) | Error 0.0000(0.0000) Steps 520(532.37) | Grad Norm 3.1014(4.1727) | Total Time 0.00(0.00)\n",
      "Iter 0882 | Time 55.3445(57.9440) | Bit/dim 3.6186(3.6342) | Xent 0.0000(0.0000) | Loss 8.6940(9.1803) | Error 0.0000(0.0000) Steps 538(532.54) | Grad Norm 4.1781(4.1728) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0147 | Time 22.0440, Epoch Time 378.4178(376.9998), Bit/dim 3.6293(best: 3.6178), Xent 0.0000, Loss 3.6293, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n",
      "10.598802395209582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0883 | Time 59.2563(57.9834) | Bit/dim 3.6274(3.6340) | Xent 0.0000(0.0000) | Loss 11.8475(9.2603) | Error 0.0000(0.0000) Steps 526(532.35) | Grad Norm 4.7291(4.1895) | Total Time 0.00(0.00)\n",
      "Iter 0884 | Time 57.8655(57.9799) | Bit/dim 3.6258(3.6337) | Xent 0.0000(0.0000) | Loss 8.6999(9.2435) | Error 0.0000(0.0000) Steps 532(532.34) | Grad Norm 3.8552(4.1795) | Total Time 0.00(0.00)\n",
      "Iter 0885 | Time 59.9760(58.0397) | Bit/dim 3.6021(3.6328) | Xent 0.0000(0.0000) | Loss 8.6044(9.2243) | Error 0.0000(0.0000) Steps 544(532.69) | Grad Norm 3.0479(4.1455) | Total Time 0.00(0.00)\n",
      "Iter 0886 | Time 61.8818(58.1550) | Bit/dim 3.6249(3.6326) | Xent 0.0000(0.0000) | Loss 8.5662(9.2046) | Error 0.0000(0.0000) Steps 532(532.67) | Grad Norm 3.3649(4.1221) | Total Time 0.00(0.00)\n",
      "Iter 0887 | Time 59.4841(58.1949) | Bit/dim 3.6190(3.6321) | Xent 0.0000(0.0000) | Loss 8.5359(9.1845) | Error 0.0000(0.0000) Steps 544(533.01) | Grad Norm 3.8226(4.1131) | Total Time 0.00(0.00)\n",
      "Iter 0888 | Time 59.6361(58.2381) | Bit/dim 3.6119(3.6315) | Xent 0.0000(0.0000) | Loss 8.7138(9.1704) | Error 0.0000(0.0000) Steps 550(533.51) | Grad Norm 4.0973(4.1127) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0148 | Time 22.8268, Epoch Time 399.1719(377.6650), Bit/dim 3.6173(best: 3.6178), Xent 0.0000, Loss 3.6173, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n",
      "10.568862275449101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0889 | Time 55.4201(58.1536) | Bit/dim 3.6246(3.6313) | Xent 0.0000(0.0000) | Loss 11.6778(9.2456) | Error 0.0000(0.0000) Steps 544(533.83) | Grad Norm 4.5543(4.1259) | Total Time 0.00(0.00)\n",
      "Iter 0890 | Time 55.2324(58.0659) | Bit/dim 3.6291(3.6313) | Xent 0.0000(0.0000) | Loss 8.4456(9.2216) | Error 0.0000(0.0000) Steps 514(533.23) | Grad Norm 5.3693(4.1632) | Total Time 0.00(0.00)\n",
      "Iter 0891 | Time 53.1086(57.9172) | Bit/dim 3.6167(3.6308) | Xent 0.0000(0.0000) | Loss 8.5812(9.2024) | Error 0.0000(0.0000) Steps 502(532.30) | Grad Norm 3.6892(4.1490) | Total Time 0.00(0.00)\n",
      "Iter 0892 | Time 56.3655(57.8707) | Bit/dim 3.6151(3.6304) | Xent 0.0000(0.0000) | Loss 8.6013(9.1844) | Error 0.0000(0.0000) Steps 508(531.57) | Grad Norm 2.9589(4.1133) | Total Time 0.00(0.00)\n",
      "Iter 0893 | Time 59.2347(57.9116) | Bit/dim 3.6150(3.6299) | Xent 0.0000(0.0000) | Loss 8.7195(9.1704) | Error 0.0000(0.0000) Steps 526(531.40) | Grad Norm 3.5405(4.0961) | Total Time 0.00(0.00)\n",
      "Iter 0894 | Time 57.1894(57.8899) | Bit/dim 3.6107(3.6293) | Xent 0.0000(0.0000) | Loss 8.6800(9.1557) | Error 0.0000(0.0000) Steps 526(531.24) | Grad Norm 3.0308(4.0641) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0149 | Time 21.2192, Epoch Time 376.2624(377.6229), Bit/dim 3.6221(best: 3.6173), Xent 0.0000, Loss 3.6221, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n",
      "10.538922155688622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0895 | Time 60.5984(57.9712) | Bit/dim 3.6149(3.6289) | Xent 0.0000(0.0000) | Loss 11.6140(9.2295) | Error 0.0000(0.0000) Steps 532(531.26) | Grad Norm 3.3365(4.0423) | Total Time 0.00(0.00)\n",
      "Iter 0896 | Time 55.7372(57.9041) | Bit/dim 3.6200(3.6286) | Xent 0.0000(0.0000) | Loss 8.6744(9.2128) | Error 0.0000(0.0000) Steps 532(531.28) | Grad Norm 4.0354(4.0421) | Total Time 0.00(0.00)\n",
      "Iter 0897 | Time 61.0062(57.9972) | Bit/dim 3.6239(3.6285) | Xent 0.0000(0.0000) | Loss 8.6939(9.1972) | Error 0.0000(0.0000) Steps 538(531.49) | Grad Norm 5.0741(4.0731) | Total Time 0.00(0.00)\n",
      "Iter 0898 | Time 59.8540(58.0529) | Bit/dim 3.6214(3.6283) | Xent 0.0000(0.0000) | Loss 8.6500(9.1808) | Error 0.0000(0.0000) Steps 550(532.04) | Grad Norm 4.7898(4.0946) | Total Time 0.00(0.00)\n",
      "Iter 0899 | Time 56.5115(58.0067) | Bit/dim 3.5995(3.6274) | Xent 0.0000(0.0000) | Loss 8.5450(9.1618) | Error 0.0000(0.0000) Steps 550(532.58) | Grad Norm 3.0956(4.0646) | Total Time 0.00(0.00)\n",
      "Iter 0900 | Time 57.6290(57.9953) | Bit/dim 3.6129(3.6270) | Xent 0.0000(0.0000) | Loss 8.6101(9.1452) | Error 0.0000(0.0000) Steps 526(532.38) | Grad Norm 3.6434(4.0520) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0150 | Time 21.5158, Epoch Time 391.6203(378.0429), Bit/dim 3.6094(best: 3.6173), Xent 0.0000, Loss 3.6094, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n",
      "10.508982035928145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0901 | Time 59.2067(58.0317) | Bit/dim 3.6192(3.6267) | Xent 0.0000(0.0000) | Loss 12.0528(9.2324) | Error 0.0000(0.0000) Steps 544(532.73) | Grad Norm 3.2805(4.0288) | Total Time 0.00(0.00)\n",
      "Iter 0902 | Time 59.4696(58.0748) | Bit/dim 3.6128(3.6263) | Xent 0.0000(0.0000) | Loss 8.5947(9.2133) | Error 0.0000(0.0000) Steps 538(532.89) | Grad Norm 3.2351(4.0050) | Total Time 0.00(0.00)\n",
      "Iter 0903 | Time 58.9237(58.1003) | Bit/dim 3.6128(3.6259) | Xent 0.0000(0.0000) | Loss 8.6692(9.1970) | Error 0.0000(0.0000) Steps 538(533.04) | Grad Norm 3.5450(3.9912) | Total Time 0.00(0.00)\n",
      "Iter 0904 | Time 57.0340(58.0683) | Bit/dim 3.5801(3.6245) | Xent 0.0000(0.0000) | Loss 8.5691(9.1781) | Error 0.0000(0.0000) Steps 538(533.19) | Grad Norm 3.1983(3.9674) | Total Time 0.00(0.00)\n",
      "Iter 0905 | Time 56.8166(58.0307) | Bit/dim 3.6030(3.6239) | Xent 0.0000(0.0000) | Loss 8.7075(9.1640) | Error 0.0000(0.0000) Steps 544(533.52) | Grad Norm 3.2555(3.9461) | Total Time 0.00(0.00)\n",
      "Iter 0906 | Time 56.1188(57.9734) | Bit/dim 3.5987(3.6231) | Xent 0.0000(0.0000) | Loss 8.4770(9.1434) | Error 0.0000(0.0000) Steps 526(533.29) | Grad Norm 3.1543(3.9223) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0151 | Time 21.8333, Epoch Time 388.5037(378.3567), Bit/dim 3.6069(best: 3.6094), Xent 0.0000, Loss 3.6069, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n",
      "10.479041916167665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0907 | Time 58.9386(58.0023) | Bit/dim 3.6081(3.6227) | Xent 0.0000(0.0000) | Loss 11.6922(9.2199) | Error 0.0000(0.0000) Steps 520(532.89) | Grad Norm 3.4849(3.9092) | Total Time 0.00(0.00)\n",
      "Iter 0908 | Time 59.7645(58.0552) | Bit/dim 3.5956(3.6219) | Xent 0.0000(0.0000) | Loss 8.5354(9.1993) | Error 0.0000(0.0000) Steps 538(533.04) | Grad Norm 3.3820(3.8934) | Total Time 0.00(0.00)\n",
      "Iter 0909 | Time 62.8676(58.1996) | Bit/dim 3.5956(3.6211) | Xent 0.0000(0.0000) | Loss 8.3366(9.1735) | Error 0.0000(0.0000) Steps 544(533.37) | Grad Norm 3.0618(3.8684) | Total Time 0.00(0.00)\n",
      "Iter 0910 | Time 59.5484(58.2400) | Bit/dim 3.5941(3.6203) | Xent 0.0000(0.0000) | Loss 8.6765(9.1585) | Error 0.0000(0.0000) Steps 550(533.87) | Grad Norm 3.6634(3.8623) | Total Time 0.00(0.00)\n",
      "Iter 0911 | Time 56.5418(58.1891) | Bit/dim 3.6026(3.6197) | Xent 0.0000(0.0000) | Loss 8.6647(9.1437) | Error 0.0000(0.0000) Steps 538(534.00) | Grad Norm 4.4622(3.8803) | Total Time 0.00(0.00)\n",
      "Iter 0912 | Time 59.0179(58.2140) | Bit/dim 3.6151(3.6196) | Xent 0.0000(0.0000) | Loss 8.7021(9.1305) | Error 0.0000(0.0000) Steps 544(534.30) | Grad Norm 4.2449(3.8912) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0152 | Time 21.7613, Epoch Time 396.8880(378.9126), Bit/dim 3.6073(best: 3.6069), Xent 0.0000, Loss 3.6073, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n",
      "10.449101796407184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0913 | Time 61.4428(58.3108) | Bit/dim 3.6000(3.6190) | Xent 0.0000(0.0000) | Loss 12.0966(9.2195) | Error 0.0000(0.0000) Steps 544(534.59) | Grad Norm 3.5857(3.8820) | Total Time 0.00(0.00)\n",
      "Iter 0914 | Time 61.1424(58.3958) | Bit/dim 3.5992(3.6184) | Xent 0.0000(0.0000) | Loss 8.4037(9.1950) | Error 0.0000(0.0000) Steps 550(535.05) | Grad Norm 3.2334(3.8626) | Total Time 0.00(0.00)\n",
      "Iter 0915 | Time 57.9350(58.3820) | Bit/dim 3.6125(3.6182) | Xent 0.0000(0.0000) | Loss 8.6008(9.1772) | Error 0.0000(0.0000) Steps 520(534.60) | Grad Norm 3.2852(3.8453) | Total Time 0.00(0.00)\n",
      "Iter 0916 | Time 61.1015(58.4635) | Bit/dim 3.6183(3.6182) | Xent 0.0000(0.0000) | Loss 8.7013(9.1629) | Error 0.0000(0.0000) Steps 532(534.52) | Grad Norm 3.1674(3.8249) | Total Time 0.00(0.00)\n",
      "Iter 0917 | Time 63.5434(58.6159) | Bit/dim 3.6021(3.6178) | Xent 0.0000(0.0000) | Loss 8.7734(9.1512) | Error 0.0000(0.0000) Steps 556(535.16) | Grad Norm 2.6322(3.7891) | Total Time 0.00(0.00)\n",
      "Iter 0918 | Time 62.5945(58.7353) | Bit/dim 3.5960(3.6171) | Xent 0.0000(0.0000) | Loss 8.7712(9.1398) | Error 0.0000(0.0000) Steps 580(536.51) | Grad Norm 3.1387(3.7696) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0153 | Time 21.4040, Epoch Time 408.0495(379.7867), Bit/dim 3.5979(best: 3.6069), Xent 0.0000, Loss 3.5979, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n",
      "10.419161676646706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0919 | Time 61.7496(58.8257) | Bit/dim 3.6037(3.6167) | Xent 0.0000(0.0000) | Loss 11.9659(9.2246) | Error 0.0000(0.0000) Steps 550(536.91) | Grad Norm 3.2695(3.7546) | Total Time 0.00(0.00)\n",
      "Iter 0920 | Time 64.7874(59.0046) | Bit/dim 3.5950(3.6161) | Xent 0.0000(0.0000) | Loss 8.6014(9.2059) | Error 0.0000(0.0000) Steps 544(537.13) | Grad Norm 3.4530(3.7456) | Total Time 0.00(0.00)\n",
      "Iter 0921 | Time 55.6733(58.9046) | Bit/dim 3.6012(3.6156) | Xent 0.0000(0.0000) | Loss 8.4233(9.1824) | Error 0.0000(0.0000) Steps 508(536.25) | Grad Norm 4.2601(3.7610) | Total Time 0.00(0.00)\n",
      "Iter 0922 | Time 61.6814(58.9879) | Bit/dim 3.6269(3.6159) | Xent 0.0000(0.0000) | Loss 8.7164(9.1684) | Error 0.0000(0.0000) Steps 538(536.31) | Grad Norm 5.4581(3.8119) | Total Time 0.00(0.00)\n",
      "Iter 0923 | Time 59.0565(58.9900) | Bit/dim 3.6201(3.6161) | Xent 0.0000(0.0000) | Loss 8.7828(9.1569) | Error 0.0000(0.0000) Steps 556(536.90) | Grad Norm 5.5352(3.8636) | Total Time 0.00(0.00)\n",
      "Iter 0924 | Time 61.4566(59.0640) | Bit/dim 3.6147(3.6160) | Xent 0.0000(0.0000) | Loss 8.8104(9.1465) | Error 0.0000(0.0000) Steps 562(537.65) | Grad Norm 4.9724(3.8969) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0154 | Time 21.7206, Epoch Time 405.0334(380.5441), Bit/dim 3.6230(best: 3.5979), Xent 0.0000, Loss 3.6230, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n",
      "10.389221556886227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0925 | Time 60.0341(59.0931) | Bit/dim 3.6172(3.6161) | Xent 0.0000(0.0000) | Loss 11.9933(9.2319) | Error 0.0000(0.0000) Steps 562(538.38) | Grad Norm 4.0599(3.9018) | Total Time 0.00(0.00)\n",
      "Iter 0926 | Time 62.3992(59.1923) | Bit/dim 3.6003(3.6156) | Xent 0.0000(0.0000) | Loss 8.6590(9.2147) | Error 0.0000(0.0000) Steps 550(538.73) | Grad Norm 3.1951(3.8806) | Total Time 0.00(0.00)\n",
      "Iter 0927 | Time 59.4686(59.2006) | Bit/dim 3.6351(3.6162) | Xent 0.0000(0.0000) | Loss 8.6178(9.1968) | Error 0.0000(0.0000) Steps 556(539.25) | Grad Norm 3.9352(3.8822) | Total Time 0.00(0.00)\n",
      "Iter 0928 | Time 61.8977(59.2815) | Bit/dim 3.6290(3.6166) | Xent 0.0000(0.0000) | Loss 8.5881(9.1785) | Error 0.0000(0.0000) Steps 544(539.39) | Grad Norm 4.9570(3.9145) | Total Time 0.00(0.00)\n",
      "Iter 0929 | Time 57.1272(59.2169) | Bit/dim 3.6485(3.6175) | Xent 0.0000(0.0000) | Loss 8.6495(9.1627) | Error 0.0000(0.0000) Steps 538(539.35) | Grad Norm 5.2551(3.9547) | Total Time 0.00(0.00)\n",
      "Iter 0930 | Time 60.5755(59.2576) | Bit/dim 3.6268(3.6178) | Xent 0.0000(0.0000) | Loss 8.6613(9.1476) | Error 0.0000(0.0000) Steps 562(540.03) | Grad Norm 4.7786(3.9794) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0155 | Time 22.1729, Epoch Time 403.2276(381.2246), Bit/dim 3.6365(best: 3.5979), Xent 0.0000, Loss 3.6365, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n",
      "10.359281437125748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0931 | Time 60.5956(59.2978) | Bit/dim 3.6364(3.6184) | Xent 0.0000(0.0000) | Loss 12.1772(9.2385) | Error 0.0000(0.0000) Steps 556(540.51) | Grad Norm 4.6952(4.0009) | Total Time 0.00(0.00)\n",
      "Iter 0932 | Time 60.5355(59.3349) | Bit/dim 3.6415(3.6191) | Xent 0.0000(0.0000) | Loss 8.6528(9.2209) | Error 0.0000(0.0000) Steps 550(540.79) | Grad Norm 3.6558(3.9905) | Total Time 0.00(0.00)\n",
      "Iter 0933 | Time 66.0081(59.5351) | Bit/dim 3.6335(3.6195) | Xent 0.0000(0.0000) | Loss 8.6360(9.2034) | Error 0.0000(0.0000) Steps 544(540.89) | Grad Norm 4.9772(4.0201) | Total Time 0.00(0.00)\n",
      "Iter 0934 | Time 65.9569(59.7277) | Bit/dim 3.6661(3.6209) | Xent 0.0000(0.0000) | Loss 8.8311(9.1922) | Error 0.0000(0.0000) Steps 556(541.34) | Grad Norm 6.7872(4.1031) | Total Time 0.00(0.00)\n",
      "Iter 0935 | Time 59.5391(59.7221) | Bit/dim 3.6761(3.6225) | Xent 0.0000(0.0000) | Loss 8.5864(9.1740) | Error 0.0000(0.0000) Steps 532(541.06) | Grad Norm 5.9202(4.1576) | Total Time 0.00(0.00)\n",
      "Iter 0936 | Time 60.2046(59.7366) | Bit/dim 3.6585(3.6236) | Xent 0.0000(0.0000) | Loss 8.6860(9.1594) | Error 0.0000(0.0000) Steps 568(541.87) | Grad Norm 4.8922(4.1797) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0156 | Time 22.1734, Epoch Time 414.1763(382.2132), Bit/dim 3.6621(best: 3.5979), Xent 0.0000, Loss 3.6621, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n",
      "10.32934131736527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0937 | Time 59.3573(59.7252) | Bit/dim 3.6575(3.6246) | Xent 0.0000(0.0000) | Loss 11.8061(9.2388) | Error 0.0000(0.0000) Steps 520(541.21) | Grad Norm 4.3263(4.1841) | Total Time 0.00(0.00)\n",
      "Iter 0938 | Time 60.0492(59.7349) | Bit/dim 3.6502(3.6254) | Xent 0.0000(0.0000) | Loss 8.8561(9.2273) | Error 0.0000(0.0000) Steps 520(540.58) | Grad Norm 3.5904(4.1663) | Total Time 0.00(0.00)\n",
      "Iter 0939 | Time 59.1036(59.7160) | Bit/dim 3.6495(3.6261) | Xent 0.0000(0.0000) | Loss 8.4955(9.2054) | Error 0.0000(0.0000) Steps 532(540.32) | Grad Norm 3.4483(4.1447) | Total Time 0.00(0.00)\n",
      "Iter 0940 | Time 58.2849(59.6730) | Bit/dim 3.6251(3.6261) | Xent 0.0000(0.0000) | Loss 8.1235(9.1729) | Error 0.0000(0.0000) Steps 544(540.43) | Grad Norm 3.2535(4.1180) | Total Time 0.00(0.00)\n",
      "Iter 0941 | Time 61.0883(59.7155) | Bit/dim 3.6256(3.6261) | Xent 0.0000(0.0000) | Loss 8.7220(9.1594) | Error 0.0000(0.0000) Steps 550(540.72) | Grad Norm 3.6206(4.1031) | Total Time 0.00(0.00)\n",
      "Iter 0942 | Time 56.6113(59.6224) | Bit/dim 3.6303(3.6262) | Xent 0.0000(0.0000) | Loss 8.7840(9.1481) | Error 0.0000(0.0000) Steps 556(541.18) | Grad Norm 3.9437(4.0983) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0157 | Time 23.6789, Epoch Time 397.5280(382.6726), Bit/dim 3.6425(best: 3.5979), Xent 0.0000, Loss 3.6425, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n",
      "10.299401197604789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0943 | Time 61.9777(59.6930) | Bit/dim 3.6565(3.6271) | Xent 0.0000(0.0000) | Loss 12.1452(9.2380) | Error 0.0000(0.0000) Steps 550(541.44) | Grad Norm 4.9485(4.1238) | Total Time 0.00(0.00)\n",
      "Iter 0944 | Time 60.3929(59.7140) | Bit/dim 3.6254(3.6271) | Xent 0.0000(0.0000) | Loss 8.7744(9.2241) | Error 0.0000(0.0000) Steps 562(542.06) | Grad Norm 5.0693(4.1522) | Total Time 0.00(0.00)\n",
      "Iter 0945 | Time 62.9110(59.8099) | Bit/dim 3.6269(3.6271) | Xent 0.0000(0.0000) | Loss 8.5881(9.2050) | Error 0.0000(0.0000) Steps 562(542.65) | Grad Norm 3.4638(4.1315) | Total Time 0.00(0.00)\n",
      "Iter 0946 | Time 60.2848(59.8242) | Bit/dim 3.6119(3.6266) | Xent 0.0000(0.0000) | Loss 8.7700(9.1920) | Error 0.0000(0.0000) Steps 538(542.52) | Grad Norm 2.8584(4.0933) | Total Time 0.00(0.00)\n",
      "Iter 0947 | Time 56.6179(59.7280) | Bit/dim 3.6128(3.6262) | Xent 0.0000(0.0000) | Loss 8.4830(9.1707) | Error 0.0000(0.0000) Steps 526(542.02) | Grad Norm 2.9050(4.0577) | Total Time 0.00(0.00)\n",
      "Iter 0948 | Time 56.9696(59.6452) | Bit/dim 3.6027(3.6255) | Xent 0.0000(0.0000) | Loss 8.6135(9.1540) | Error 0.0000(0.0000) Steps 538(541.90) | Grad Norm 2.5169(4.0114) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0158 | Time 22.6309, Epoch Time 400.6084(383.2107), Bit/dim 3.6166(best: 3.5979), Xent 0.0000, Loss 3.6166, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n",
      "10.269461077844312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0949 | Time 58.0083(59.5961) | Bit/dim 3.6214(3.6254) | Xent 0.0000(0.0000) | Loss 11.9739(9.2386) | Error 0.0000(0.0000) Steps 538(541.78) | Grad Norm 3.0412(3.9823) | Total Time 0.00(0.00)\n",
      "Iter 0950 | Time 64.3568(59.7389) | Bit/dim 3.5983(3.6246) | Xent 0.0000(0.0000) | Loss 8.7856(9.2250) | Error 0.0000(0.0000) Steps 568(542.57) | Grad Norm 2.6565(3.9426) | Total Time 0.00(0.00)\n",
      "Iter 0951 | Time 58.6135(59.7052) | Bit/dim 3.6091(3.6241) | Xent 0.0000(0.0000) | Loss 8.7793(9.2116) | Error 0.0000(0.0000) Steps 562(543.15) | Grad Norm 3.1614(3.9191) | Total Time 0.00(0.00)\n",
      "Iter 0952 | Time 56.2991(59.6030) | Bit/dim 3.5967(3.6233) | Xent 0.0000(0.0000) | Loss 8.4616(9.1891) | Error 0.0000(0.0000) Steps 556(543.54) | Grad Norm 2.6243(3.8803) | Total Time 0.00(0.00)\n",
      "Iter 0953 | Time 60.6645(59.6348) | Bit/dim 3.5961(3.6225) | Xent 0.0000(0.0000) | Loss 8.6658(9.1734) | Error 0.0000(0.0000) Steps 556(543.91) | Grad Norm 2.2589(3.8316) | Total Time 0.00(0.00)\n",
      "Iter 0954 | Time 58.5067(59.6010) | Bit/dim 3.5983(3.6217) | Xent 0.0000(0.0000) | Loss 8.4867(9.1528) | Error 0.0000(0.0000) Steps 550(544.09) | Grad Norm 2.9319(3.8046) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0159 | Time 23.2753, Epoch Time 398.6021(383.6724), Bit/dim 3.5943(best: 3.5979), Xent 0.0000, Loss 3.5943, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n",
      "10.239520958083833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0955 | Time 65.4035(59.7751) | Bit/dim 3.5934(3.6209) | Xent 0.0000(0.0000) | Loss 12.0279(9.2391) | Error 0.0000(0.0000) Steps 580(545.17) | Grad Norm 3.1417(3.7848) | Total Time 0.00(0.00)\n",
      "Iter 0956 | Time 61.9299(59.8397) | Bit/dim 3.6049(3.6204) | Xent 0.0000(0.0000) | Loss 8.6151(9.2204) | Error 0.0000(0.0000) Steps 568(545.86) | Grad Norm 3.6634(3.7811) | Total Time 0.00(0.00)\n",
      "Iter 0957 | Time 59.7805(59.8379) | Bit/dim 3.6042(3.6199) | Xent 0.0000(0.0000) | Loss 8.6550(9.2034) | Error 0.0000(0.0000) Steps 556(546.16) | Grad Norm 4.6366(3.8068) | Total Time 0.00(0.00)\n",
      "Iter 0958 | Time 60.9307(59.8707) | Bit/dim 3.6179(3.6199) | Xent 0.0000(0.0000) | Loss 8.6515(9.1869) | Error 0.0000(0.0000) Steps 550(546.28) | Grad Norm 5.3325(3.8525) | Total Time 0.00(0.00)\n",
      "Iter 0959 | Time 56.8853(59.7812) | Bit/dim 3.6151(3.6197) | Xent 0.0000(0.0000) | Loss 8.6696(9.1713) | Error 0.0000(0.0000) Steps 544(546.21) | Grad Norm 4.4699(3.8711) | Total Time 0.00(0.00)\n",
      "Iter 0960 | Time 59.4370(59.7708) | Bit/dim 3.5973(3.6190) | Xent 0.0000(0.0000) | Loss 8.6794(9.1566) | Error 0.0000(0.0000) Steps 544(546.14) | Grad Norm 2.5153(3.8304) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0160 | Time 22.1277, Epoch Time 405.5378(384.3284), Bit/dim 3.6173(best: 3.5943), Xent 0.0000, Loss 3.6173, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n",
      "10.209580838323353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0961 | Time 57.8670(59.7137) | Bit/dim 3.6171(3.6190) | Xent 0.0000(0.0000) | Loss 11.9824(9.2414) | Error 0.0000(0.0000) Steps 538(545.90) | Grad Norm 4.3045(3.8446) | Total Time 0.00(0.00)\n",
      "Iter 0962 | Time 61.8060(59.7765) | Bit/dim 3.6145(3.6188) | Xent 0.0000(0.0000) | Loss 8.7586(9.2269) | Error 0.0000(0.0000) Steps 550(546.02) | Grad Norm 3.2440(3.8266) | Total Time 0.00(0.00)\n",
      "Iter 0963 | Time 59.3385(59.7633) | Bit/dim 3.5925(3.6181) | Xent 0.0000(0.0000) | Loss 8.7176(9.2116) | Error 0.0000(0.0000) Steps 562(546.50) | Grad Norm 2.3204(3.7814) | Total Time 0.00(0.00)\n",
      "Iter 0964 | Time 63.9387(59.8886) | Bit/dim 3.5869(3.6171) | Xent 0.0000(0.0000) | Loss 8.5645(9.1922) | Error 0.0000(0.0000) Steps 574(547.32) | Grad Norm 3.3270(3.7678) | Total Time 0.00(0.00)\n",
      "Iter 0965 | Time 65.4976(60.0569) | Bit/dim 3.6126(3.6170) | Xent 0.0000(0.0000) | Loss 8.8478(9.1819) | Error 0.0000(0.0000) Steps 556(547.58) | Grad Norm 3.4061(3.7569) | Total Time 0.00(0.00)\n",
      "Iter 0966 | Time 58.1918(60.0009) | Bit/dim 3.5685(3.6155) | Xent 0.0000(0.0000) | Loss 8.7399(9.1686) | Error 0.0000(0.0000) Steps 556(547.84) | Grad Norm 2.5267(3.7200) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0161 | Time 22.6579, Epoch Time 408.4291(385.0514), Bit/dim 3.5851(best: 3.5943), Xent 0.0000, Loss 3.5851, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n",
      "10.179640718562874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0967 | Time 64.6042(60.1390) | Bit/dim 3.5868(3.6147) | Xent 0.0000(0.0000) | Loss 12.3173(9.2631) | Error 0.0000(0.0000) Steps 562(548.26) | Grad Norm 2.3097(3.6777) | Total Time 0.00(0.00)\n",
      "Iter 0968 | Time 59.9024(60.1319) | Bit/dim 3.5915(3.6140) | Xent 0.0000(0.0000) | Loss 8.5785(9.2425) | Error 0.0000(0.0000) Steps 544(548.13) | Grad Norm 2.1466(3.6318) | Total Time 0.00(0.00)\n",
      "Iter 0969 | Time 62.5260(60.2037) | Bit/dim 3.5857(3.6131) | Xent 0.0000(0.0000) | Loss 8.6909(9.2260) | Error 0.0000(0.0000) Steps 574(548.91) | Grad Norm 2.6258(3.6016) | Total Time 0.00(0.00)\n",
      "Iter 0970 | Time 62.7671(60.2806) | Bit/dim 3.5940(3.6126) | Xent 0.0000(0.0000) | Loss 8.7255(9.2110) | Error 0.0000(0.0000) Steps 568(549.48) | Grad Norm 3.2407(3.5908) | Total Time 0.00(0.00)\n",
      "Iter 0971 | Time 62.0029(60.3323) | Bit/dim 3.5815(3.6116) | Xent 0.0000(0.0000) | Loss 8.6964(9.1955) | Error 0.0000(0.0000) Steps 580(550.40) | Grad Norm 3.7809(3.5965) | Total Time 0.00(0.00)\n",
      "Iter 0972 | Time 63.7682(60.4354) | Bit/dim 3.6043(3.6114) | Xent 0.0000(0.0000) | Loss 8.7594(9.1824) | Error 0.0000(0.0000) Steps 556(550.57) | Grad Norm 4.5928(3.6264) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0162 | Time 22.8381, Epoch Time 416.3271(385.9897), Bit/dim 3.6031(best: 3.5851), Xent 0.0000, Loss 3.6031, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n",
      "10.149700598802395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0973 | Time 64.9791(60.5717) | Bit/dim 3.6083(3.6113) | Xent 0.0000(0.0000) | Loss 12.0825(9.2694) | Error 0.0000(0.0000) Steps 568(551.09) | Grad Norm 4.5612(3.6544) | Total Time 0.00(0.00)\n",
      "Iter 0974 | Time 58.4469(60.5080) | Bit/dim 3.5874(3.6106) | Xent 0.0000(0.0000) | Loss 8.4445(9.2447) | Error 0.0000(0.0000) Steps 556(551.24) | Grad Norm 3.0669(3.6368) | Total Time 0.00(0.00)\n",
      "Iter 0975 | Time 57.0593(60.4045) | Bit/dim 3.5822(3.6097) | Xent 0.0000(0.0000) | Loss 8.2941(9.2162) | Error 0.0000(0.0000) Steps 556(551.38) | Grad Norm 2.8477(3.6131) | Total Time 0.00(0.00)\n",
      "Iter 0976 | Time 60.1981(60.3983) | Bit/dim 3.6076(3.6097) | Xent 0.0000(0.0000) | Loss 8.7257(9.2015) | Error 0.0000(0.0000) Steps 550(551.34) | Grad Norm 3.7695(3.6178) | Total Time 0.00(0.00)\n",
      "Iter 0977 | Time 60.8589(60.4121) | Bit/dim 3.5938(3.6092) | Xent 0.0000(0.0000) | Loss 8.6181(9.1840) | Error 0.0000(0.0000) Steps 556(551.48) | Grad Norm 3.2805(3.6077) | Total Time 0.00(0.00)\n",
      "Iter 0978 | Time 67.3614(60.6206) | Bit/dim 3.5962(3.6088) | Xent 0.0000(0.0000) | Loss 8.4362(9.1615) | Error 0.0000(0.0000) Steps 574(552.15) | Grad Norm 3.0448(3.5908) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0163 | Time 23.1323, Epoch Time 410.6248(386.7287), Bit/dim 3.5914(best: 3.5851), Xent 0.0000, Loss 3.5914, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n",
      "10.119760479041917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0979 | Time 59.4955(60.5868) | Bit/dim 3.5984(3.6085) | Xent 0.0000(0.0000) | Loss 11.6258(9.2355) | Error 0.0000(0.0000) Steps 538(551.73) | Grad Norm 2.8141(3.5675) | Total Time 0.00(0.00)\n",
      "Iter 0980 | Time 58.5005(60.5243) | Bit/dim 3.5757(3.6075) | Xent 0.0000(0.0000) | Loss 8.7350(9.2204) | Error 0.0000(0.0000) Steps 556(551.86) | Grad Norm 2.4501(3.5340) | Total Time 0.00(0.00)\n",
      "Iter 0981 | Time 66.0056(60.6887) | Bit/dim 3.5942(3.6071) | Xent 0.0000(0.0000) | Loss 8.7042(9.2050) | Error 0.0000(0.0000) Steps 562(552.16) | Grad Norm 2.9394(3.5161) | Total Time 0.00(0.00)\n",
      "Iter 0982 | Time 58.5337(60.6240) | Bit/dim 3.6014(3.6069) | Xent 0.0000(0.0000) | Loss 8.3945(9.1806) | Error 0.0000(0.0000) Steps 544(551.92) | Grad Norm 2.8151(3.4951) | Total Time 0.00(0.00)\n",
      "Iter 0983 | Time 60.7323(60.6273) | Bit/dim 3.5796(3.6061) | Xent 0.0000(0.0000) | Loss 8.6917(9.1660) | Error 0.0000(0.0000) Steps 556(552.04) | Grad Norm 2.5342(3.4663) | Total Time 0.00(0.00)\n",
      "Iter 0984 | Time 65.4922(60.7732) | Bit/dim 3.5958(3.6058) | Xent 0.0000(0.0000) | Loss 8.6307(9.1499) | Error 0.0000(0.0000) Steps 568(552.52) | Grad Norm 3.8239(3.4770) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0164 | Time 22.6474, Epoch Time 410.6376(387.4460), Bit/dim 3.6126(best: 3.5851), Xent 0.0000, Loss 3.6126, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n",
      "10.089820359281438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0985 | Time 56.3762(60.6413) | Bit/dim 3.6074(3.6059) | Xent 0.0000(0.0000) | Loss 12.2490(9.2429) | Error 0.0000(0.0000) Steps 544(552.26) | Grad Norm 4.9774(3.5220) | Total Time 0.00(0.00)\n",
      "Iter 0986 | Time 61.5931(60.6699) | Bit/dim 3.6369(3.6068) | Xent 0.0000(0.0000) | Loss 8.5229(9.2213) | Error 0.0000(0.0000) Steps 550(552.19) | Grad Norm 5.7695(3.5894) | Total Time 0.00(0.00)\n",
      "Iter 0987 | Time 62.9725(60.7390) | Bit/dim 3.6363(3.6077) | Xent 0.0000(0.0000) | Loss 8.8263(9.2094) | Error 0.0000(0.0000) Steps 574(552.85) | Grad Norm 4.5096(3.6171) | Total Time 0.00(0.00)\n",
      "Iter 0988 | Time 57.6313(60.6457) | Bit/dim 3.5816(3.6069) | Xent 0.0000(0.0000) | Loss 8.4234(9.1859) | Error 0.0000(0.0000) Steps 544(552.58) | Grad Norm 2.5430(3.5848) | Total Time 0.00(0.00)\n",
      "Iter 0989 | Time 59.1584(60.6011) | Bit/dim 3.6173(3.6072) | Xent 0.0000(0.0000) | Loss 8.5805(9.1677) | Error 0.0000(0.0000) Steps 556(552.69) | Grad Norm 3.6860(3.5879) | Total Time 0.00(0.00)\n",
      "Iter 0990 | Time 57.7320(60.5150) | Bit/dim 3.6165(3.6075) | Xent 0.0000(0.0000) | Loss 8.6749(9.1529) | Error 0.0000(0.0000) Steps 544(552.43) | Grad Norm 3.4620(3.5841) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0165 | Time 22.6558, Epoch Time 396.8683(387.7287), Bit/dim 3.6229(best: 3.5851), Xent 0.0000, Loss 3.6229, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n",
      "10.059880239520957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0991 | Time 62.1526(60.5642) | Bit/dim 3.6224(3.6079) | Xent 0.0000(0.0000) | Loss 12.1602(9.2431) | Error 0.0000(0.0000) Steps 562(552.71) | Grad Norm 4.8427(3.6218) | Total Time 0.00(0.00)\n",
      "Iter 0992 | Time 61.0926(60.5800) | Bit/dim 3.6459(3.6091) | Xent 0.0000(0.0000) | Loss 8.6319(9.2248) | Error 0.0000(0.0000) Steps 544(552.45) | Grad Norm 5.2294(3.6701) | Total Time 0.00(0.00)\n",
      "Iter 0993 | Time 55.8292(60.4375) | Bit/dim 3.6419(3.6101) | Xent 0.0000(0.0000) | Loss 8.8011(9.2121) | Error 0.0000(0.0000) Steps 568(552.92) | Grad Norm 5.1032(3.7131) | Total Time 0.00(0.00)\n",
      "Iter 0994 | Time 57.2320(60.3413) | Bit/dim 3.6541(3.6114) | Xent 0.0000(0.0000) | Loss 8.9432(9.2040) | Error 0.0000(0.0000) Steps 556(553.01) | Grad Norm 3.7201(3.7133) | Total Time 0.00(0.00)\n",
      "Iter 0995 | Time 56.5117(60.2264) | Bit/dim 3.6269(3.6118) | Xent 0.0000(0.0000) | Loss 8.6983(9.1888) | Error 0.0000(0.0000) Steps 544(552.74) | Grad Norm 4.3845(3.7334) | Total Time 0.00(0.00)\n",
      "Iter 0996 | Time 67.5686(60.4467) | Bit/dim 3.6489(3.6130) | Xent 0.0000(0.0000) | Loss 8.7783(9.1765) | Error 0.0000(0.0000) Steps 568(553.20) | Grad Norm 4.8841(3.7679) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0166 | Time 23.4936, Epoch Time 402.8463(388.1822), Bit/dim 3.6353(best: 3.5851), Xent 0.0000, Loss 3.6353, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n",
      "10.029940119760479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0997 | Time 61.8896(60.4900) | Bit/dim 3.6412(3.6138) | Xent 0.0000(0.0000) | Loss 12.0655(9.2632) | Error 0.0000(0.0000) Steps 556(553.28) | Grad Norm 4.1187(3.7785) | Total Time 0.00(0.00)\n",
      "Iter 0998 | Time 59.7077(60.4665) | Bit/dim 3.6252(3.6141) | Xent 0.0000(0.0000) | Loss 8.6390(9.2445) | Error 0.0000(0.0000) Steps 556(553.36) | Grad Norm 4.0826(3.7876) | Total Time 0.00(0.00)\n",
      "Iter 0999 | Time 58.0126(60.3929) | Bit/dim 3.6477(3.6152) | Xent 0.0000(0.0000) | Loss 8.9557(9.2358) | Error 0.0000(0.0000) Steps 580(554.16) | Grad Norm 4.1618(3.7988) | Total Time 0.00(0.00)\n",
      "Iter 1000 | Time 58.1446(60.3255) | Bit/dim 3.6292(3.6156) | Xent 0.0000(0.0000) | Loss 8.5210(9.2144) | Error 0.0000(0.0000) Steps 550(554.04) | Grad Norm 3.5816(3.7923) | Total Time 0.00(0.00)\n",
      "Iter 1001 | Time 62.1086(60.3789) | Bit/dim 3.6252(3.6159) | Xent 0.0000(0.0000) | Loss 8.9010(9.2050) | Error 0.0000(0.0000) Steps 550(553.92) | Grad Norm 5.2452(3.8359) | Total Time 0.00(0.00)\n",
      "Iter 1002 | Time 62.8206(60.4522) | Bit/dim 3.6452(3.6167) | Xent 0.0000(0.0000) | Loss 8.6684(9.1889) | Error 0.0000(0.0000) Steps 550(553.80) | Grad Norm 5.0598(3.8726) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0167 | Time 23.0106, Epoch Time 404.4990(388.6717), Bit/dim 3.6320(best: 3.5851), Xent 0.0000, Loss 3.6320, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n",
      "10.000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1003 | Time 60.9214(60.4663) | Bit/dim 3.6203(3.6169) | Xent 0.0000(0.0000) | Loss 12.1354(9.2773) | Error 0.0000(0.0000) Steps 574(554.40) | Grad Norm 3.9240(3.8741) | Total Time 0.00(0.00)\n",
      "Iter 1004 | Time 60.6549(60.4719) | Bit/dim 3.6520(3.6179) | Xent 0.0000(0.0000) | Loss 8.9515(9.2675) | Error 0.0000(0.0000) Steps 568(554.81) | Grad Norm 4.3208(3.8875) | Total Time 0.00(0.00)\n",
      "Iter 1005 | Time 61.8172(60.5123) | Bit/dim 3.6465(3.6188) | Xent 0.0000(0.0000) | Loss 8.7984(9.2534) | Error 0.0000(0.0000) Steps 562(555.03) | Grad Norm 3.6907(3.8816) | Total Time 0.00(0.00)\n",
      "Iter 1006 | Time 62.8289(60.5818) | Bit/dim 3.6114(3.6185) | Xent 0.0000(0.0000) | Loss 8.7411(9.2381) | Error 0.0000(0.0000) Steps 556(555.06) | Grad Norm 3.5443(3.8715) | Total Time 0.00(0.00)\n",
      "Iter 1007 | Time 60.8733(60.5905) | Bit/dim 3.6372(3.6191) | Xent 0.0000(0.0000) | Loss 8.8361(9.2260) | Error 0.0000(0.0000) Steps 538(554.55) | Grad Norm 4.4835(3.8899) | Total Time 0.00(0.00)\n",
      "Iter 1008 | Time 62.5219(60.6485) | Bit/dim 3.6132(3.6189) | Xent 0.0000(0.0000) | Loss 8.6723(9.2094) | Error 0.0000(0.0000) Steps 568(554.95) | Grad Norm 3.3576(3.8739) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0168 | Time 23.3457, Epoch Time 411.7730(389.3647), Bit/dim 3.6266(best: 3.5851), Xent 0.0000, Loss 3.6266, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n",
      "9.970059880239521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1009 | Time 60.7955(60.6529) | Bit/dim 3.6322(3.6193) | Xent 0.0000(0.0000) | Loss 12.2367(9.3002) | Error 0.0000(0.0000) Steps 562(555.16) | Grad Norm 3.9586(3.8765) | Total Time 0.00(0.00)\n",
      "Iter 1010 | Time 62.5660(60.7103) | Bit/dim 3.5982(3.6187) | Xent 0.0000(0.0000) | Loss 8.7558(9.2839) | Error 0.0000(0.0000) Steps 592(556.27) | Grad Norm 2.9524(3.8487) | Total Time 0.00(0.00)\n",
      "Iter 1011 | Time 60.0761(60.6913) | Bit/dim 3.6099(3.6184) | Xent 0.0000(0.0000) | Loss 8.7590(9.2681) | Error 0.0000(0.0000) Steps 562(556.44) | Grad Norm 3.5598(3.8401) | Total Time 0.00(0.00)\n",
      "Iter 1012 | Time 68.5900(60.9282) | Bit/dim 3.5993(3.6179) | Xent 0.0000(0.0000) | Loss 8.7459(9.2525) | Error 0.0000(0.0000) Steps 598(557.68) | Grad Norm 3.9442(3.8432) | Total Time 0.00(0.00)\n",
      "Iter 1013 | Time 67.0146(61.1108) | Bit/dim 3.6051(3.6175) | Xent 0.0000(0.0000) | Loss 8.8226(9.2396) | Error 0.0000(0.0000) Steps 586(558.53) | Grad Norm 3.5236(3.8336) | Total Time 0.00(0.00)\n",
      "Iter 1014 | Time 61.2916(61.1162) | Bit/dim 3.5989(3.6169) | Xent 0.0000(0.0000) | Loss 8.7709(9.2255) | Error 0.0000(0.0000) Steps 568(558.82) | Grad Norm 2.7599(3.8014) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0169 | Time 23.0405, Epoch Time 423.2914(390.3825), Bit/dim 3.5956(best: 3.5851), Xent 0.0000, Loss 3.5956, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n",
      "9.94011976047904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1015 | Time 64.5667(61.2197) | Bit/dim 3.5931(3.6162) | Xent 0.0000(0.0000) | Loss 12.1849(9.3143) | Error 0.0000(0.0000) Steps 574(559.27) | Grad Norm 2.9005(3.7744) | Total Time 0.00(0.00)\n",
      "Iter 1016 | Time 59.5010(61.1682) | Bit/dim 3.5966(3.6156) | Xent 0.0000(0.0000) | Loss 8.7650(9.2978) | Error 0.0000(0.0000) Steps 568(559.54) | Grad Norm 2.6493(3.7406) | Total Time 0.00(0.00)\n",
      "Iter 1017 | Time 61.9343(61.1912) | Bit/dim 3.5840(3.6147) | Xent 0.0000(0.0000) | Loss 8.5834(9.2764) | Error 0.0000(0.0000) Steps 580(560.15) | Grad Norm 2.3645(3.6993) | Total Time 0.00(0.00)\n",
      "Iter 1018 | Time 62.1586(61.2202) | Bit/dim 3.5723(3.6134) | Xent 0.0000(0.0000) | Loss 8.6231(9.2568) | Error 0.0000(0.0000) Steps 562(560.20) | Grad Norm 2.3653(3.6593) | Total Time 0.00(0.00)\n",
      "Iter 1019 | Time 58.7249(61.1453) | Bit/dim 3.5793(3.6124) | Xent 0.0000(0.0000) | Loss 8.4745(9.2333) | Error 0.0000(0.0000) Steps 550(559.90) | Grad Norm 2.6985(3.6305) | Total Time 0.00(0.00)\n",
      "Iter 1020 | Time 64.1398(61.2352) | Bit/dim 3.5799(3.6114) | Xent 0.0000(0.0000) | Loss 8.5076(9.2115) | Error 0.0000(0.0000) Steps 544(559.42) | Grad Norm 2.6675(3.6016) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0170 | Time 23.1044, Epoch Time 413.5221(391.0767), Bit/dim 3.5743(best: 3.5851), Xent 0.0000, Loss 3.5743, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n",
      "9.910179640718564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1021 | Time 62.9900(61.2878) | Bit/dim 3.5662(3.6100) | Xent 0.0000(0.0000) | Loss 12.3967(9.3071) | Error 0.0000(0.0000) Steps 574(559.86) | Grad Norm 2.9137(3.5810) | Total Time 0.00(0.00)\n",
      "Iter 1022 | Time 60.4314(61.2621) | Bit/dim 3.5752(3.6090) | Xent 0.0000(0.0000) | Loss 8.3844(9.2794) | Error 0.0000(0.0000) Steps 544(559.38) | Grad Norm 3.6907(3.5842) | Total Time 0.00(0.00)\n",
      "Iter 1023 | Time 62.0248(61.2850) | Bit/dim 3.5893(3.6084) | Xent 0.0000(0.0000) | Loss 8.8049(9.2652) | Error 0.0000(0.0000) Steps 580(560.00) | Grad Norm 4.2440(3.6040) | Total Time 0.00(0.00)\n",
      "Iter 1024 | Time 63.5819(61.3539) | Bit/dim 3.5846(3.6077) | Xent 0.0000(0.0000) | Loss 8.5244(9.2429) | Error 0.0000(0.0000) Steps 556(559.88) | Grad Norm 3.7717(3.6091) | Total Time 0.00(0.00)\n",
      "Iter 1025 | Time 61.6604(61.3631) | Bit/dim 3.5900(3.6072) | Xent 0.0000(0.0000) | Loss 8.6757(9.2259) | Error 0.0000(0.0000) Steps 574(560.31) | Grad Norm 3.5835(3.6083) | Total Time 0.00(0.00)\n",
      "Iter 1026 | Time 64.4946(61.4570) | Bit/dim 3.5859(3.6065) | Xent 0.0000(0.0000) | Loss 8.6379(9.2083) | Error 0.0000(0.0000) Steps 562(560.36) | Grad Norm 3.0327(3.5910) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0171 | Time 23.0462, Epoch Time 418.1272(391.8882), Bit/dim 3.5785(best: 3.5743), Xent 0.0000, Loss 3.5785, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n",
      "9.880239520958083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1027 | Time 64.4784(61.5477) | Bit/dim 3.5732(3.6055) | Xent 0.0000(0.0000) | Loss 12.2801(9.3004) | Error 0.0000(0.0000) Steps 574(560.77) | Grad Norm 3.1237(3.5770) | Total Time 0.00(0.00)\n",
      "Iter 1028 | Time 65.0016(61.6513) | Bit/dim 3.5837(3.6049) | Xent 0.0000(0.0000) | Loss 8.8285(9.2863) | Error 0.0000(0.0000) Steps 568(560.98) | Grad Norm 3.6213(3.5783) | Total Time 0.00(0.00)\n",
      "Iter 1029 | Time 62.7461(61.6841) | Bit/dim 3.5785(3.6041) | Xent 0.0000(0.0000) | Loss 8.6169(9.2662) | Error 0.0000(0.0000) Steps 562(561.01) | Grad Norm 3.4896(3.5757) | Total Time 0.00(0.00)\n",
      "Iter 1030 | Time 67.9064(61.8708) | Bit/dim 3.5607(3.6028) | Xent 0.0000(0.0000) | Loss 8.6595(9.2480) | Error 0.0000(0.0000) Steps 568(561.22) | Grad Norm 2.3221(3.5381) | Total Time 0.00(0.00)\n",
      "Iter 1031 | Time 58.4542(61.7683) | Bit/dim 3.5666(3.6017) | Xent 0.0000(0.0000) | Loss 8.5324(9.2265) | Error 0.0000(0.0000) Steps 550(560.89) | Grad Norm 1.8252(3.4867) | Total Time 0.00(0.00)\n",
      "Iter 1032 | Time 59.0585(61.6870) | Bit/dim 3.5662(3.6006) | Xent 0.0000(0.0000) | Loss 8.3375(9.1999) | Error 0.0000(0.0000) Steps 568(561.10) | Grad Norm 2.4988(3.4570) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0172 | Time 23.0642, Epoch Time 419.7722(392.7248), Bit/dim 3.5726(best: 3.5743), Xent 0.0000, Loss 3.5726, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n",
      "9.850299401197605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1033 | Time 64.5014(61.7714) | Bit/dim 3.5743(3.5998) | Xent 0.0000(0.0000) | Loss 12.2034(9.2900) | Error 0.0000(0.0000) Steps 568(561.31) | Grad Norm 3.3052(3.4525) | Total Time 0.00(0.00)\n",
      "Iter 1034 | Time 63.2114(61.8146) | Bit/dim 3.5861(3.5994) | Xent 0.0000(0.0000) | Loss 8.5310(9.2672) | Error 0.0000(0.0000) Steps 556(561.15) | Grad Norm 3.3843(3.4504) | Total Time 0.00(0.00)\n",
      "Iter 1035 | Time 62.3868(61.8318) | Bit/dim 3.5568(3.5981) | Xent 0.0000(0.0000) | Loss 8.7885(9.2528) | Error 0.0000(0.0000) Steps 568(561.35) | Grad Norm 2.4396(3.4201) | Total Time 0.00(0.00)\n",
      "Iter 1036 | Time 61.8777(61.8332) | Bit/dim 3.5584(3.5969) | Xent 0.0000(0.0000) | Loss 8.5821(9.2327) | Error 0.0000(0.0000) Steps 580(561.91) | Grad Norm 2.0559(3.3792) | Total Time 0.00(0.00)\n",
      "Iter 1037 | Time 61.3201(61.8178) | Bit/dim 3.5695(3.5961) | Xent 0.0000(0.0000) | Loss 8.4951(9.2106) | Error 0.0000(0.0000) Steps 556(561.73) | Grad Norm 2.1181(3.3414) | Total Time 0.00(0.00)\n",
      "Iter 1038 | Time 63.2663(61.8612) | Bit/dim 3.5563(3.5949) | Xent 0.0000(0.0000) | Loss 8.6566(9.1940) | Error 0.0000(0.0000) Steps 568(561.92) | Grad Norm 2.8784(3.3275) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0173 | Time 23.1898, Epoch Time 418.8406(393.5082), Bit/dim 3.5741(best: 3.5726), Xent 0.0000, Loss 3.5741, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n",
      "9.820359281437126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1039 | Time 62.8972(61.8923) | Bit/dim 3.5702(3.5942) | Xent 0.0000(0.0000) | Loss 12.2921(9.2869) | Error 0.0000(0.0000) Steps 562(561.93) | Grad Norm 4.1130(3.3510) | Total Time 0.00(0.00)\n",
      "Iter 1040 | Time 58.5895(61.7932) | Bit/dim 3.5973(3.5943) | Xent 0.0000(0.0000) | Loss 8.6726(9.2685) | Error 0.0000(0.0000) Steps 574(562.29) | Grad Norm 4.5178(3.3860) | Total Time 0.00(0.00)\n",
      "Iter 1041 | Time 70.0599(62.0412) | Bit/dim 3.5689(3.5935) | Xent 0.0000(0.0000) | Loss 8.6712(9.2506) | Error 0.0000(0.0000) Steps 568(562.46) | Grad Norm 3.4142(3.3869) | Total Time 0.00(0.00)\n",
      "Iter 1042 | Time 62.9384(62.0682) | Bit/dim 3.5736(3.5929) | Xent 0.0000(0.0000) | Loss 8.3216(9.2227) | Error 0.0000(0.0000) Steps 556(562.27) | Grad Norm 3.8314(3.4002) | Total Time 0.00(0.00)\n",
      "Iter 1043 | Time 58.9180(61.9737) | Bit/dim 3.5781(3.5925) | Xent 0.0000(0.0000) | Loss 8.3598(9.1968) | Error 0.0000(0.0000) Steps 556(562.08) | Grad Norm 3.5873(3.4058) | Total Time 0.00(0.00)\n",
      "Iter 1044 | Time 61.2616(61.9523) | Bit/dim 3.5550(3.5914) | Xent 0.0000(0.0000) | Loss 8.6678(9.1809) | Error 0.0000(0.0000) Steps 568(562.25) | Grad Norm 2.4890(3.3783) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0174 | Time 22.8219, Epoch Time 415.4114(394.1653), Bit/dim 3.5696(best: 3.5726), Xent 0.0000, Loss 3.5696, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n",
      "9.790419161676645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1045 | Time 60.0063(61.8939) | Bit/dim 3.5581(3.5904) | Xent 0.0000(0.0000) | Loss 12.2161(9.2720) | Error 0.0000(0.0000) Steps 574(562.61) | Grad Norm 2.3365(3.3471) | Total Time 0.00(0.00)\n",
      "Iter 1046 | Time 60.3266(61.8469) | Bit/dim 3.5648(3.5896) | Xent 0.0000(0.0000) | Loss 8.5671(9.2508) | Error 0.0000(0.0000) Steps 562(562.59) | Grad Norm 2.5306(3.3226) | Total Time 0.00(0.00)\n",
      "Iter 1047 | Time 64.2439(61.9188) | Bit/dim 3.5595(3.5887) | Xent 0.0000(0.0000) | Loss 8.2758(9.2216) | Error 0.0000(0.0000) Steps 550(562.21) | Grad Norm 2.6096(3.3012) | Total Time 0.00(0.00)\n",
      "Iter 1048 | Time 65.1719(62.0164) | Bit/dim 3.5730(3.5882) | Xent 0.0000(0.0000) | Loss 8.4179(9.1975) | Error 0.0000(0.0000) Steps 556(562.02) | Grad Norm 2.8267(3.2870) | Total Time 0.00(0.00)\n",
      "Iter 1049 | Time 58.8083(61.9201) | Bit/dim 3.5592(3.5873) | Xent 0.0000(0.0000) | Loss 8.5891(9.1792) | Error 0.0000(0.0000) Steps 574(562.38) | Grad Norm 2.7004(3.2694) | Total Time 0.00(0.00)\n",
      "Iter 1050 | Time 59.3373(61.8427) | Bit/dim 3.5774(3.5870) | Xent 0.0000(0.0000) | Loss 8.5899(9.1616) | Error 0.0000(0.0000) Steps 550(562.01) | Grad Norm 2.5818(3.2487) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0175 | Time 23.5072, Epoch Time 408.8854(394.6069), Bit/dim 3.5755(best: 3.5696), Xent 0.0000, Loss 3.5755, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n",
      "9.760479041916167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1051 | Time 61.8738(61.8436) | Bit/dim 3.5831(3.5869) | Xent 0.0000(0.0000) | Loss 11.8222(9.2414) | Error 0.0000(0.0000) Steps 574(562.37) | Grad Norm 3.6328(3.2603) | Total Time 0.00(0.00)\n",
      "Iter 1052 | Time 59.8496(61.7838) | Bit/dim 3.5946(3.5872) | Xent 0.0000(0.0000) | Loss 8.8223(9.2288) | Error 0.0000(0.0000) Steps 580(562.90) | Grad Norm 5.4810(3.3269) | Total Time 0.00(0.00)\n",
      "Iter 1053 | Time 63.7793(61.8436) | Bit/dim 3.5999(3.5875) | Xent 0.0000(0.0000) | Loss 8.6520(9.2115) | Error 0.0000(0.0000) Steps 574(563.23) | Grad Norm 5.4123(3.3894) | Total Time 0.00(0.00)\n",
      "Iter 1054 | Time 61.0056(61.8185) | Bit/dim 3.5864(3.5875) | Xent 0.0000(0.0000) | Loss 8.7624(9.1980) | Error 0.0000(0.0000) Steps 562(563.20) | Grad Norm 3.6090(3.3960) | Total Time 0.00(0.00)\n",
      "Iter 1055 | Time 59.5850(61.7515) | Bit/dim 3.6291(3.5888) | Xent 0.0000(0.0000) | Loss 8.8778(9.1884) | Error 0.0000(0.0000) Steps 574(563.52) | Grad Norm 3.8705(3.4103) | Total Time 0.00(0.00)\n",
      "Iter 1056 | Time 66.8410(61.9042) | Bit/dim 3.5793(3.5885) | Xent 0.0000(0.0000) | Loss 8.7699(9.1759) | Error 0.0000(0.0000) Steps 556(563.30) | Grad Norm 4.1613(3.4328) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0176 | Time 22.9577, Epoch Time 414.5000(395.2037), Bit/dim 3.6093(best: 3.5696), Xent 0.0000, Loss 3.6093, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n",
      "9.73053892215569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1057 | Time 64.4724(61.9812) | Bit/dim 3.5994(3.5888) | Xent 0.0000(0.0000) | Loss 12.1400(9.2648) | Error 0.0000(0.0000) Steps 562(563.26) | Grad Norm 4.7450(3.4722) | Total Time 0.00(0.00)\n",
      "Iter 1058 | Time 62.3707(61.9929) | Bit/dim 3.5961(3.5890) | Xent 0.0000(0.0000) | Loss 8.7870(9.2505) | Error 0.0000(0.0000) Steps 580(563.76) | Grad Norm 4.3595(3.4988) | Total Time 0.00(0.00)\n",
      "Iter 1059 | Time 63.3037(62.0322) | Bit/dim 3.5954(3.5892) | Xent 0.0000(0.0000) | Loss 8.7753(9.2362) | Error 0.0000(0.0000) Steps 568(563.89) | Grad Norm 3.5006(3.4988) | Total Time 0.00(0.00)\n",
      "Iter 1060 | Time 59.2056(61.9474) | Bit/dim 3.6016(3.5896) | Xent 0.0000(0.0000) | Loss 8.5657(9.2161) | Error 0.0000(0.0000) Steps 550(563.47) | Grad Norm 2.8820(3.4803) | Total Time 0.00(0.00)\n",
      "Iter 1061 | Time 66.8001(62.0930) | Bit/dim 3.5938(3.5897) | Xent 0.0000(0.0000) | Loss 8.6749(9.1998) | Error 0.0000(0.0000) Steps 586(564.15) | Grad Norm 2.8318(3.4609) | Total Time 0.00(0.00)\n",
      "Iter 1062 | Time 58.3684(61.9813) | Bit/dim 3.5902(3.5897) | Xent 0.0000(0.0000) | Loss 8.5902(9.1816) | Error 0.0000(0.0000) Steps 562(564.08) | Grad Norm 3.1772(3.4524) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0177 | Time 23.9276, Epoch Time 417.5202(395.8732), Bit/dim 3.5918(best: 3.5696), Xent 0.0000, Loss 3.5918, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n",
      "9.70059880239521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1063 | Time 64.3506(62.0524) | Bit/dim 3.5920(3.5898) | Xent 0.0000(0.0000) | Loss 12.6060(9.2843) | Error 0.0000(0.0000) Steps 580(564.56) | Grad Norm 3.3212(3.4484) | Total Time 0.00(0.00)\n",
      "Iter 1064 | Time 65.0904(62.1435) | Bit/dim 3.5882(3.5897) | Xent 0.0000(0.0000) | Loss 8.8006(9.2698) | Error 0.0000(0.0000) Steps 586(565.20) | Grad Norm 3.1307(3.4389) | Total Time 0.00(0.00)\n",
      "Iter 1065 | Time 63.6758(62.1895) | Bit/dim 3.5707(3.5892) | Xent 0.0000(0.0000) | Loss 8.7488(9.2542) | Error 0.0000(0.0000) Steps 574(565.47) | Grad Norm 2.8787(3.4221) | Total Time 0.00(0.00)\n",
      "Iter 1066 | Time 63.0003(62.2138) | Bit/dim 3.5785(3.5889) | Xent 0.0000(0.0000) | Loss 8.4661(9.2305) | Error 0.0000(0.0000) Steps 562(565.36) | Grad Norm 3.7963(3.4333) | Total Time 0.00(0.00)\n",
      "Iter 1067 | Time 59.3610(62.1282) | Bit/dim 3.5831(3.5887) | Xent 0.0000(0.0000) | Loss 8.8006(9.2176) | Error 0.0000(0.0000) Steps 568(565.44) | Grad Norm 4.0987(3.4533) | Total Time 0.00(0.00)\n",
      "Iter 1068 | Time 60.4417(62.0776) | Bit/dim 3.5862(3.5886) | Xent 0.0000(0.0000) | Loss 8.3534(9.1917) | Error 0.0000(0.0000) Steps 556(565.16) | Grad Norm 3.9101(3.4670) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0178 | Time 23.2891, Epoch Time 417.6726(396.5272), Bit/dim 3.5757(best: 3.5696), Xent 0.0000, Loss 3.5757, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n",
      "9.67065868263473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1069 | Time 63.6460(62.1247) | Bit/dim 3.5765(3.5882) | Xent 0.0000(0.0000) | Loss 12.5052(9.2911) | Error 0.0000(0.0000) Steps 592(565.96) | Grad Norm 2.5300(3.4389) | Total Time 0.00(0.00)\n",
      "Iter 1070 | Time 64.0979(62.1839) | Bit/dim 3.5697(3.5877) | Xent 0.0000(0.0000) | Loss 8.7110(9.2737) | Error 0.0000(0.0000) Steps 574(566.20) | Grad Norm 2.6561(3.4154) | Total Time 0.00(0.00)\n",
      "Iter 1071 | Time 62.3176(62.1879) | Bit/dim 3.5704(3.5872) | Xent 0.0000(0.0000) | Loss 8.7428(9.2578) | Error 0.0000(0.0000) Steps 574(566.44) | Grad Norm 3.8367(3.4280) | Total Time 0.00(0.00)\n",
      "Iter 1072 | Time 62.3502(62.1927) | Bit/dim 3.5867(3.5872) | Xent 0.0000(0.0000) | Loss 8.8196(9.2446) | Error 0.0000(0.0000) Steps 574(566.66) | Grad Norm 3.9684(3.4442) | Total Time 0.00(0.00)\n",
      "Iter 1073 | Time 61.6145(62.1754) | Bit/dim 3.5765(3.5868) | Xent 0.0000(0.0000) | Loss 8.7787(9.2306) | Error 0.0000(0.0000) Steps 568(566.70) | Grad Norm 3.1930(3.4367) | Total Time 0.00(0.00)\n",
      "Iter 1074 | Time 63.2405(62.2073) | Bit/dim 3.5650(3.5862) | Xent 0.0000(0.0000) | Loss 8.6753(9.2140) | Error 0.0000(0.0000) Steps 574(566.92) | Grad Norm 2.1554(3.3983) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0179 | Time 23.0275, Epoch Time 418.1390(397.1756), Bit/dim 3.5715(best: 3.5696), Xent 0.0000, Loss 3.5715, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n",
      "9.640718562874252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1075 | Time 58.2203(62.0877) | Bit/dim 3.5687(3.5857) | Xent 0.0000(0.0000) | Loss 12.2414(9.3048) | Error 0.0000(0.0000) Steps 562(566.78) | Grad Norm 2.8633(3.3822) | Total Time 0.00(0.00)\n",
      "Iter 1076 | Time 63.8858(62.1417) | Bit/dim 3.5836(3.5856) | Xent 0.0000(0.0000) | Loss 8.7218(9.2873) | Error 0.0000(0.0000) Steps 574(566.99) | Grad Norm 3.2488(3.3782) | Total Time 0.00(0.00)\n",
      "Iter 1077 | Time 66.6018(62.2755) | Bit/dim 3.5618(3.5849) | Xent 0.0000(0.0000) | Loss 8.6284(9.2675) | Error 0.0000(0.0000) Steps 574(567.20) | Grad Norm 2.8125(3.3612) | Total Time 0.00(0.00)\n",
      "Iter 1078 | Time 64.8273(62.3520) | Bit/dim 3.5728(3.5845) | Xent 0.0000(0.0000) | Loss 8.6771(9.2498) | Error 0.0000(0.0000) Steps 580(567.59) | Grad Norm 2.7814(3.3438) | Total Time 0.00(0.00)\n",
      "Iter 1079 | Time 64.1279(62.4053) | Bit/dim 3.5666(3.5840) | Xent 0.0000(0.0000) | Loss 8.4556(9.2260) | Error 0.0000(0.0000) Steps 562(567.42) | Grad Norm 2.4777(3.3179) | Total Time 0.00(0.00)\n",
      "Iter 1080 | Time 62.0615(62.3950) | Bit/dim 3.5603(3.5833) | Xent 0.0000(0.0000) | Loss 8.6824(9.2097) | Error 0.0000(0.0000) Steps 586(567.98) | Grad Norm 2.4808(3.2927) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0180 | Time 22.9228, Epoch Time 422.0655(397.9223), Bit/dim 3.5702(best: 3.5696), Xent 0.0000, Loss 3.5702, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n",
      "9.610778443113773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1081 | Time 65.6783(62.4935) | Bit/dim 3.5739(3.5830) | Xent 0.0000(0.0000) | Loss 12.2948(9.3022) | Error 0.0000(0.0000) Steps 586(568.52) | Grad Norm 3.3493(3.2944) | Total Time 0.00(0.00)\n",
      "Iter 1082 | Time 62.1469(62.4831) | Bit/dim 3.5752(3.5828) | Xent 0.0000(0.0000) | Loss 8.7238(9.2849) | Error 0.0000(0.0000) Steps 568(568.50) | Grad Norm 3.4735(3.2998) | Total Time 0.00(0.00)\n",
      "Iter 1083 | Time 63.6068(62.5168) | Bit/dim 3.5726(3.5825) | Xent 0.0000(0.0000) | Loss 8.6887(9.2670) | Error 0.0000(0.0000) Steps 568(568.49) | Grad Norm 3.3017(3.2999) | Total Time 0.00(0.00)\n",
      "Iter 1084 | Time 66.9915(62.6511) | Bit/dim 3.5845(3.5825) | Xent 0.0000(0.0000) | Loss 8.8070(9.2532) | Error 0.0000(0.0000) Steps 580(568.83) | Grad Norm 3.8263(3.3157) | Total Time 0.00(0.00)\n",
      "Iter 1085 | Time 63.4767(62.6758) | Bit/dim 3.5613(3.5819) | Xent 0.0000(0.0000) | Loss 8.7890(9.2393) | Error 0.0000(0.0000) Steps 586(569.35) | Grad Norm 2.9988(3.3062) | Total Time 0.00(0.00)\n",
      "Iter 1086 | Time 58.4403(62.5488) | Bit/dim 3.5596(3.5812) | Xent 0.0000(0.0000) | Loss 8.6012(9.2201) | Error 0.0000(0.0000) Steps 562(569.13) | Grad Norm 2.2187(3.2735) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0181 | Time 24.1339, Epoch Time 423.4023(398.6867), Bit/dim 3.5695(best: 3.5696), Xent 0.0000, Loss 3.5695, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n",
      "9.580838323353294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1087 | Time 61.9746(62.5315) | Bit/dim 3.5568(3.5805) | Xent 0.0000(0.0000) | Loss 12.6205(9.3222) | Error 0.0000(0.0000) Steps 574(569.27) | Grad Norm 2.9288(3.2632) | Total Time 0.00(0.00)\n",
      "Iter 1088 | Time 63.1747(62.5508) | Bit/dim 3.5659(3.5800) | Xent 0.0000(0.0000) | Loss 8.7634(9.3054) | Error 0.0000(0.0000) Steps 586(569.77) | Grad Norm 3.2858(3.2639) | Total Time 0.00(0.00)\n",
      "Iter 1089 | Time 62.2073(62.5405) | Bit/dim 3.5624(3.5795) | Xent 0.0000(0.0000) | Loss 8.5404(9.2824) | Error 0.0000(0.0000) Steps 580(570.08) | Grad Norm 3.2785(3.2643) | Total Time 0.00(0.00)\n",
      "Iter 1090 | Time 60.2669(62.4723) | Bit/dim 3.5809(3.5795) | Xent 0.0000(0.0000) | Loss 8.8649(9.2699) | Error 0.0000(0.0000) Steps 574(570.20) | Grad Norm 3.2394(3.2636) | Total Time 0.00(0.00)\n",
      "Iter 1091 | Time 65.2905(62.5569) | Bit/dim 3.5757(3.5794) | Xent 0.0000(0.0000) | Loss 8.6669(9.2518) | Error 0.0000(0.0000) Steps 592(570.85) | Grad Norm 3.0069(3.2559) | Total Time 0.00(0.00)\n",
      "Iter 1092 | Time 66.7598(62.6829) | Bit/dim 3.5468(3.5785) | Xent 0.0000(0.0000) | Loss 8.4391(9.2274) | Error 0.0000(0.0000) Steps 574(570.95) | Grad Norm 2.3720(3.2293) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0182 | Time 22.8406, Epoch Time 421.6059(399.3742), Bit/dim 3.5622(best: 3.5695), Xent 0.0000, Loss 3.5622, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n",
      "9.550898203592814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1093 | Time 67.2348(62.8195) | Bit/dim 3.5595(3.5779) | Xent 0.0000(0.0000) | Loss 12.3632(9.3215) | Error 0.0000(0.0000) Steps 592(571.58) | Grad Norm 2.8770(3.2188) | Total Time 0.00(0.00)\n",
      "Iter 1094 | Time 65.9518(62.9135) | Bit/dim 3.5570(3.5773) | Xent 0.0000(0.0000) | Loss 8.5135(9.2973) | Error 0.0000(0.0000) Steps 574(571.65) | Grad Norm 3.8065(3.2364) | Total Time 0.00(0.00)\n",
      "Iter 1095 | Time 62.4961(62.9009) | Bit/dim 3.5641(3.5769) | Xent 0.0000(0.0000) | Loss 8.6706(9.2785) | Error 0.0000(0.0000) Steps 592(572.26) | Grad Norm 4.3721(3.2705) | Total Time 0.00(0.00)\n",
      "Iter 1096 | Time 66.8378(63.0191) | Bit/dim 3.5909(3.5773) | Xent 0.0000(0.0000) | Loss 8.6848(9.2607) | Error 0.0000(0.0000) Steps 568(572.13) | Grad Norm 4.0581(3.2941) | Total Time 0.00(0.00)\n",
      "Iter 1097 | Time 65.1024(63.0816) | Bit/dim 3.5639(3.5769) | Xent 0.0000(0.0000) | Loss 8.7744(9.2461) | Error 0.0000(0.0000) Steps 580(572.37) | Grad Norm 2.8567(3.2810) | Total Time 0.00(0.00)\n",
      "Iter 1098 | Time 61.6823(63.0396) | Bit/dim 3.5537(3.5762) | Xent 0.0000(0.0000) | Loss 8.6436(9.2280) | Error 0.0000(0.0000) Steps 550(571.70) | Grad Norm 2.3841(3.2541) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0183 | Time 23.2428, Epoch Time 431.5742(400.3402), Bit/dim 3.5682(best: 3.5622), Xent 0.0000, Loss 3.5682, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n",
      "9.520958083832335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1099 | Time 61.0483(62.9798) | Bit/dim 3.5692(3.5760) | Xent 0.0000(0.0000) | Loss 12.3054(9.3203) | Error 0.0000(0.0000) Steps 568(571.59) | Grad Norm 3.4145(3.2589) | Total Time 0.00(0.00)\n",
      "Iter 1100 | Time 61.6423(62.9397) | Bit/dim 3.5624(3.5756) | Xent 0.0000(0.0000) | Loss 8.7676(9.3037) | Error 0.0000(0.0000) Steps 580(571.84) | Grad Norm 3.2071(3.2573) | Total Time 0.00(0.00)\n",
      "Iter 1101 | Time 64.2245(62.9783) | Bit/dim 3.5489(3.5748) | Xent 0.0000(0.0000) | Loss 8.6980(9.2856) | Error 0.0000(0.0000) Steps 580(572.09) | Grad Norm 2.3970(3.2315) | Total Time 0.00(0.00)\n",
      "Iter 1102 | Time 67.5951(63.1168) | Bit/dim 3.5455(3.5739) | Xent 0.0000(0.0000) | Loss 8.6159(9.2655) | Error 0.0000(0.0000) Steps 580(572.32) | Grad Norm 2.2933(3.2034) | Total Time 0.00(0.00)\n",
      "Iter 1103 | Time 63.2997(63.1223) | Bit/dim 3.5543(3.5733) | Xent 0.0000(0.0000) | Loss 8.8005(9.2515) | Error 0.0000(0.0000) Steps 580(572.55) | Grad Norm 3.3202(3.2069) | Total Time 0.00(0.00)\n",
      "Iter 1104 | Time 63.2231(63.1253) | Bit/dim 3.5654(3.5731) | Xent 0.0000(0.0000) | Loss 8.5445(9.2303) | Error 0.0000(0.0000) Steps 574(572.60) | Grad Norm 4.3097(3.2400) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0184 | Time 23.7244, Epoch Time 423.1836(401.0255), Bit/dim 3.5685(best: 3.5622), Xent 0.0000, Loss 3.5685, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n",
      "9.491017964071858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1105 | Time 68.0044(63.2717) | Bit/dim 3.5620(3.5727) | Xent 0.0000(0.0000) | Loss 12.4530(9.3270) | Error 0.0000(0.0000) Steps 568(572.46) | Grad Norm 4.0588(3.2645) | Total Time 0.00(0.00)\n",
      "Iter 1106 | Time 63.2093(63.2698) | Bit/dim 3.5523(3.5721) | Xent 0.0000(0.0000) | Loss 8.7475(9.3096) | Error 0.0000(0.0000) Steps 580(572.68) | Grad Norm 2.6570(3.2463) | Total Time 0.00(0.00)\n",
      "Iter 1107 | Time 64.5553(63.3083) | Bit/dim 3.5679(3.5720) | Xent 0.0000(0.0000) | Loss 8.8620(9.2962) | Error 0.0000(0.0000) Steps 592(573.26) | Grad Norm 2.6618(3.2288) | Total Time 0.00(0.00)\n",
      "Iter 1108 | Time 65.0089(63.3594) | Bit/dim 3.5702(3.5719) | Xent 0.0000(0.0000) | Loss 9.0535(9.2889) | Error 0.0000(0.0000) Steps 598(574.01) | Grad Norm 3.9116(3.2493) | Total Time 0.00(0.00)\n",
      "Iter 1109 | Time 62.9318(63.3465) | Bit/dim 3.5943(3.5726) | Xent 0.0000(0.0000) | Loss 8.8125(9.2746) | Error 0.0000(0.0000) Steps 562(573.65) | Grad Norm 4.1099(3.2751) | Total Time 0.00(0.00)\n",
      "Iter 1110 | Time 64.0182(63.3667) | Bit/dim 3.5725(3.5726) | Xent 0.0000(0.0000) | Loss 8.9520(9.2649) | Error 0.0000(0.0000) Steps 580(573.84) | Grad Norm 3.1764(3.2721) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0185 | Time 23.0768, Epoch Time 429.2645(401.8727), Bit/dim 3.5812(best: 3.5622), Xent 0.0000, Loss 3.5812, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n",
      "9.461077844311378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1111 | Time 68.3275(63.5155) | Bit/dim 3.5764(3.5727) | Xent 0.0000(0.0000) | Loss 12.8832(9.3735) | Error 0.0000(0.0000) Steps 598(574.56) | Grad Norm 4.0110(3.2943) | Total Time 0.00(0.00)\n",
      "Iter 1112 | Time 64.9004(63.5571) | Bit/dim 3.6117(3.5739) | Xent 0.0000(0.0000) | Loss 8.7230(9.3540) | Error 0.0000(0.0000) Steps 568(574.36) | Grad Norm 4.6906(3.3362) | Total Time 0.00(0.00)\n",
      "Iter 1113 | Time 66.5743(63.6476) | Bit/dim 3.5895(3.5744) | Xent 0.0000(0.0000) | Loss 8.8207(9.3380) | Error 0.0000(0.0000) Steps 580(574.53) | Grad Norm 4.2086(3.3623) | Total Time 0.00(0.00)\n",
      "Iter 1114 | Time 59.4695(63.5222) | Bit/dim 3.5863(3.5747) | Xent 0.0000(0.0000) | Loss 8.7093(9.3191) | Error 0.0000(0.0000) Steps 574(574.52) | Grad Norm 4.6078(3.3997) | Total Time 0.00(0.00)\n",
      "Iter 1115 | Time 63.4930(63.5214) | Bit/dim 3.5858(3.5751) | Xent 0.0000(0.0000) | Loss 8.8763(9.3058) | Error 0.0000(0.0000) Steps 586(574.86) | Grad Norm 3.1205(3.3913) | Total Time 0.00(0.00)\n",
      "Iter 1116 | Time 66.0659(63.5977) | Bit/dim 3.5758(3.5751) | Xent 0.0000(0.0000) | Loss 8.7393(9.2888) | Error 0.0000(0.0000) Steps 568(574.66) | Grad Norm 3.0446(3.3809) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0186 | Time 22.6201, Epoch Time 430.6141(402.7349), Bit/dim 3.6039(best: 3.5622), Xent 0.0000, Loss 3.6039, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n",
      "9.431137724550897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1117 | Time 61.4235(63.5325) | Bit/dim 3.5927(3.5756) | Xent 0.0000(0.0000) | Loss 12.4770(9.3845) | Error 0.0000(0.0000) Steps 568(574.46) | Grad Norm 4.1247(3.4032) | Total Time 0.00(0.00)\n",
      "Iter 1118 | Time 67.0574(63.6382) | Bit/dim 3.5751(3.5756) | Xent 0.0000(0.0000) | Loss 8.5434(9.3592) | Error 0.0000(0.0000) Steps 562(574.08) | Grad Norm 2.3647(3.3721) | Total Time 0.00(0.00)\n",
      "Iter 1119 | Time 62.9800(63.6185) | Bit/dim 3.5877(3.5760) | Xent 0.0000(0.0000) | Loss 8.8308(9.3434) | Error 0.0000(0.0000) Steps 586(574.44) | Grad Norm 3.2767(3.3692) | Total Time 0.00(0.00)\n",
      "Iter 1120 | Time 71.7604(63.8627) | Bit/dim 3.5758(3.5760) | Xent 0.0000(0.0000) | Loss 8.8735(9.3293) | Error 0.0000(0.0000) Steps 592(574.97) | Grad Norm 2.9203(3.3558) | Total Time 0.00(0.00)\n",
      "Iter 1121 | Time 64.3291(63.8767) | Bit/dim 3.5766(3.5760) | Xent 0.0000(0.0000) | Loss 8.8492(9.3149) | Error 0.0000(0.0000) Steps 556(574.40) | Grad Norm 4.3950(3.3869) | Total Time 0.00(0.00)\n",
      "Iter 1122 | Time 64.6886(63.9011) | Bit/dim 3.5986(3.5767) | Xent 0.0000(0.0000) | Loss 8.8133(9.2998) | Error 0.0000(0.0000) Steps 586(574.75) | Grad Norm 4.9405(3.4335) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0187 | Time 23.0729, Epoch Time 433.8957(403.6698), Bit/dim 3.5879(best: 3.5622), Xent 0.0000, Loss 3.5879, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n",
      "9.40119760479042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1123 | Time 67.9142(64.0215) | Bit/dim 3.5808(3.5768) | Xent 0.0000(0.0000) | Loss 12.6070(9.3991) | Error 0.0000(0.0000) Steps 592(575.26) | Grad Norm 3.0765(3.4228) | Total Time 0.00(0.00)\n",
      "Iter 1124 | Time 66.8293(64.1057) | Bit/dim 3.5852(3.5770) | Xent 0.0000(0.0000) | Loss 8.7889(9.3808) | Error 0.0000(0.0000) Steps 580(575.41) | Grad Norm 2.8753(3.4064) | Total Time 0.00(0.00)\n",
      "Iter 1125 | Time 66.0769(64.1648) | Bit/dim 3.5790(3.5771) | Xent 0.0000(0.0000) | Loss 8.5877(9.3570) | Error 0.0000(0.0000) Steps 574(575.36) | Grad Norm 3.2219(3.4009) | Total Time 0.00(0.00)\n",
      "Iter 1126 | Time 67.8144(64.2743) | Bit/dim 3.5725(3.5770) | Xent 0.0000(0.0000) | Loss 8.8396(9.3414) | Error 0.0000(0.0000) Steps 592(575.86) | Grad Norm 2.6298(3.3777) | Total Time 0.00(0.00)\n",
      "Iter 1127 | Time 65.7815(64.3195) | Bit/dim 3.5748(3.5769) | Xent 0.0000(0.0000) | Loss 8.5636(9.3181) | Error 0.0000(0.0000) Steps 580(575.99) | Grad Norm 3.1517(3.3710) | Total Time 0.00(0.00)\n",
      "Iter 1128 | Time 65.4542(64.3536) | Bit/dim 3.5857(3.5772) | Xent 0.0000(0.0000) | Loss 8.6185(9.2971) | Error 0.0000(0.0000) Steps 574(575.93) | Grad Norm 3.3594(3.3706) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0188 | Time 24.0175, Epoch Time 441.6824(404.8102), Bit/dim 3.5831(best: 3.5622), Xent 0.0000, Loss 3.5831, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n",
      "9.371257485029941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1129 | Time 67.9888(64.4626) | Bit/dim 3.5823(3.5773) | Xent 0.0000(0.0000) | Loss 12.5548(9.3949) | Error 0.0000(0.0000) Steps 592(576.41) | Grad Norm 3.1486(3.3640) | Total Time 0.00(0.00)\n",
      "Iter 1130 | Time 67.3025(64.5478) | Bit/dim 3.5842(3.5775) | Xent 0.0000(0.0000) | Loss 8.9813(9.3824) | Error 0.0000(0.0000) Steps 610(577.42) | Grad Norm 3.0908(3.3558) | Total Time 0.00(0.00)\n",
      "Iter 1131 | Time 68.5820(64.6689) | Bit/dim 3.5778(3.5775) | Xent 0.0000(0.0000) | Loss 8.8731(9.3672) | Error 0.0000(0.0000) Steps 610(578.39) | Grad Norm 3.0836(3.3476) | Total Time 0.00(0.00)\n",
      "Iter 1132 | Time 69.4078(64.8110) | Bit/dim 3.5794(3.5776) | Xent 0.0000(0.0000) | Loss 8.9275(9.3540) | Error 0.0000(0.0000) Steps 616(579.52) | Grad Norm 3.4370(3.3503) | Total Time 0.00(0.00)\n",
      "Iter 1133 | Time 70.4926(64.9815) | Bit/dim 3.5605(3.5771) | Xent 0.0000(0.0000) | Loss 8.8181(9.3379) | Error 0.0000(0.0000) Steps 580(579.54) | Grad Norm 2.6042(3.3279) | Total Time 0.00(0.00)\n",
      "Iter 1134 | Time 64.3999(64.9640) | Bit/dim 3.5717(3.5769) | Xent 0.0000(0.0000) | Loss 8.7280(9.3196) | Error 0.0000(0.0000) Steps 580(579.55) | Grad Norm 2.3867(3.2997) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0189 | Time 23.7173, Epoch Time 451.4077(406.2081), Bit/dim 3.5676(best: 3.5622), Xent 0.0000, Loss 3.5676, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n",
      "9.341317365269461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1135 | Time 68.3484(65.0656) | Bit/dim 3.5680(3.5766) | Xent 0.0000(0.0000) | Loss 12.4475(9.4134) | Error 0.0000(0.0000) Steps 592(579.92) | Grad Norm 2.5108(3.2760) | Total Time 0.00(0.00)\n",
      "Iter 1136 | Time 69.2764(65.1919) | Bit/dim 3.5896(3.5770) | Xent 0.0000(0.0000) | Loss 8.7702(9.3941) | Error 0.0000(0.0000) Steps 586(580.11) | Grad Norm 3.1333(3.2717) | Total Time 0.00(0.00)\n",
      "Iter 1137 | Time 64.8428(65.1814) | Bit/dim 3.5824(3.5772) | Xent 0.0000(0.0000) | Loss 8.9119(9.3797) | Error 0.0000(0.0000) Steps 586(580.28) | Grad Norm 3.0745(3.2658) | Total Time 0.00(0.00)\n",
      "Iter 1138 | Time 70.1089(65.3292) | Bit/dim 3.5828(3.5774) | Xent 0.0000(0.0000) | Loss 8.7583(9.3610) | Error 0.0000(0.0000) Steps 580(580.28) | Grad Norm 2.9894(3.2575) | Total Time 0.00(0.00)\n",
      "Iter 1139 | Time 63.4211(65.2720) | Bit/dim 3.5848(3.5776) | Xent 0.0000(0.0000) | Loss 8.6448(9.3395) | Error 0.0000(0.0000) Steps 574(580.09) | Grad Norm 2.7649(3.2427) | Total Time 0.00(0.00)\n",
      "Iter 1140 | Time 70.7627(65.4367) | Bit/dim 3.5737(3.5775) | Xent 0.0000(0.0000) | Loss 8.8003(9.3234) | Error 0.0000(0.0000) Steps 598(580.62) | Grad Norm 3.2300(3.2423) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0190 | Time 23.7977, Epoch Time 450.0273(407.5227), Bit/dim 3.6087(best: 3.5622), Xent 0.0000, Loss 3.6087, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n",
      "9.311377245508982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1141 | Time 65.9765(65.4529) | Bit/dim 3.5953(3.5780) | Xent 0.0000(0.0000) | Loss 12.5586(9.4204) | Error 0.0000(0.0000) Steps 592(580.97) | Grad Norm 4.3740(3.2763) | Total Time 0.00(0.00)\n",
      "Iter 1142 | Time 66.6221(65.4880) | Bit/dim 3.6047(3.5788) | Xent 0.0000(0.0000) | Loss 8.9031(9.4049) | Error 0.0000(0.0000) Steps 580(580.94) | Grad Norm 4.4909(3.3127) | Total Time 0.00(0.00)\n",
      "Iter 1143 | Time 71.6563(65.6730) | Bit/dim 3.6061(3.5796) | Xent 0.0000(0.0000) | Loss 8.9714(9.3919) | Error 0.0000(0.0000) Steps 610(581.81) | Grad Norm 3.2441(3.3107) | Total Time 0.00(0.00)\n",
      "Iter 1144 | Time 63.0266(65.5936) | Bit/dim 3.6011(3.5803) | Xent 0.0000(0.0000) | Loss 8.5381(9.3663) | Error 0.0000(0.0000) Steps 580(581.75) | Grad Norm 3.0042(3.3015) | Total Time 0.00(0.00)\n",
      "Iter 1145 | Time 72.4494(65.7993) | Bit/dim 3.5896(3.5805) | Xent 0.0000(0.0000) | Loss 8.8026(9.3494) | Error 0.0000(0.0000) Steps 592(582.06) | Grad Norm 3.5621(3.3093) | Total Time 0.00(0.00)\n",
      "Iter 1146 | Time 72.2801(65.9937) | Bit/dim 3.5973(3.5810) | Xent 0.0000(0.0000) | Loss 8.9492(9.3374) | Error 0.0000(0.0000) Steps 598(582.54) | Grad Norm 2.9610(3.2989) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0191 | Time 24.0122, Epoch Time 455.1855(408.9525), Bit/dim 3.6253(best: 3.5622), Xent 0.0000, Loss 3.6253, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n",
      "9.281437125748502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1147 | Time 67.0908(66.0266) | Bit/dim 3.6252(3.5824) | Xent 0.0000(0.0000) | Loss 12.8513(9.4428) | Error 0.0000(0.0000) Steps 592(582.82) | Grad Norm 4.4457(3.3333) | Total Time 0.00(0.00)\n",
      "Iter 1148 | Time 68.6095(66.1041) | Bit/dim 3.7624(3.5878) | Xent 0.0000(0.0000) | Loss 9.3663(9.4405) | Error 0.0000(0.0000) Steps 628(584.18) | Grad Norm 8.9794(3.5026) | Total Time 0.00(0.00)\n",
      "Iter 1149 | Time 68.0975(66.1639) | Bit/dim 3.7904(3.5938) | Xent 0.0000(0.0000) | Loss 9.1894(9.4330) | Error 0.0000(0.0000) Steps 646(586.03) | Grad Norm 7.4318(3.6205) | Total Time 0.00(0.00)\n",
      "Iter 1150 | Time 71.9085(66.3363) | Bit/dim 3.7754(3.5993) | Xent 0.0000(0.0000) | Loss 9.2355(9.4270) | Error 0.0000(0.0000) Steps 646(587.83) | Grad Norm 5.4643(3.6758) | Total Time 0.00(0.00)\n",
      "Iter 1151 | Time 73.7675(66.5592) | Bit/dim 3.8069(3.6055) | Xent 0.0000(0.0000) | Loss 9.5851(9.4318) | Error 0.0000(0.0000) Steps 712(591.56) | Grad Norm 5.1696(3.7206) | Total Time 0.00(0.00)\n",
      "Iter 1152 | Time 82.9293(67.0503) | Bit/dim 3.8314(3.6123) | Xent 0.0000(0.0000) | Loss 9.4733(9.4330) | Error 0.0000(0.0000) Steps 712(595.17) | Grad Norm 6.2366(3.7961) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0192 | Time 26.6434, Epoch Time 476.8183(410.9885), Bit/dim 4.0657(best: 3.5622), Xent 0.0000, Loss 4.0657, Error 1.0000(best: inf)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "underflow in dt 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mfig_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"figs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{:04d}.jpg\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0mgenerated_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m             \u001b[0mgenerated_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtol_indx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36m_worker\u001b[0;34m(i, module, input, kwargs, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/lib/odenvp_conditional_rl.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, logpx, reverse)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogpx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logdensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/lib/odenvp_conditional_rl.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, z, logpz)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mz_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mz_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_logpz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_logpz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0matol_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mrtol_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlogpa_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogp_actions\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mnfe_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogpa_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfe_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlogpz\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_logpz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogpa_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfe_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/lib/layers/container_gate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, logpx, reverse, inds)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'atol'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0matol_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mrtol_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlogpa_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogp_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mnfe_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/lib/layers/cnf_gate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, logpz, integration_times, reverse)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_atol_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_rtol_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_solver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             )\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/torchdiffeq/_impl/adjoint.py\u001b[0m in \u001b[0;36modeint_adjoint\u001b[0;34m(func, y0, t, rtol, atol, method, options)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mflat_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOdeintAdjointMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/torchdiffeq/_impl/adjoint.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, *args)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSOLVERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0msolution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/torchdiffeq/_impl/dopri5.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mnext_t\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_num_steps exceeded ({}>={})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adaptive_dopri5_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mn_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_interp_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp_coeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/torchdiffeq/_impl/dopri5.py\u001b[0m in \u001b[0;36m_adaptive_dopri5_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m#                      Assertions                      #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'underflow in dt {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0my0_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0m_is_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'non-finite values in state `y`: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: underflow in dt 0.0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         1291112633 function calls (1269795696 primitive calls) in 73079.412 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "     1152 46402.223   40.280 46402.223   40.280 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
       "   260377 20680.210    0.079 20680.210    0.079 {method 'acquire' of '_thread.lock' objects}\n",
       "   390663  644.802    0.002  644.802    0.002 {method '_write_file' of 'torch._C.CudaFloatStorageBase' objects}\n",
       " 11136000  564.756    0.000  958.589    0.000 train_cnf_disentangle_rl.py:143(add_noise)\n",
       " 11136191  354.366    0.000  354.366    0.000 {method 'tobytes' of 'numpy.ndarray' objects}\n",
       " 11136200  312.446    0.000  312.446    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
       " 11136000  298.320    0.000 1361.241    0.000 functional.py:32(to_tensor)\n",
       "      988  293.936    0.298  293.936    0.298 {built-in method io.open}\n",
       " 11136000  220.458    0.000  220.458    0.000 {method 'div' of 'torch._C._TensorBase' objects}\n",
       " 11136000  151.161    0.000  151.161    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
       " 11136382  150.749    0.000 1202.234    0.000 Image.py:2457(fromarray)\n",
       " 11136000  141.027    0.000  141.027    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
       "214250362/214163831  128.043    0.000  128.797    0.000 {built-in method builtins.isinstance}\n",
       "     1536  116.874    0.076  116.874    0.076 {built-in method stack}\n",
       " 11136000  114.954    0.000 4027.479    0.000 cifar.py:103(__getitem__)\n",
       " 20448476   97.391    0.000  147.036    0.000 module.py:537(__setattr__)\n",
       " 11136000   96.729    0.000  300.189    0.000 Image.py:711(tobytes)\n",
       " 11136000   94.109    0.000 2668.037    0.000 transforms.py:47(__call__)\n",
       " 22272000   79.675    0.000   79.675    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}\n",
       " 11943679   78.719    0.000   78.719    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
       " 11136382   74.138    0.000  291.160    0.000 Image.py:2322(new)\n",
       " 33409146   64.003    0.000  100.931    0.000 Image.py:2304(_check_size)\n",
       "112428557/112378025   58.551    0.000   58.609    0.000 {built-in method builtins.len}\n",
       " 11136738   57.750    0.000   57.750    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
       " 11136382   57.658    0.000   57.658    0.000 {built-in method PIL._imaging.fill}\n",
       " 11136382   56.919    0.000   94.097    0.000 Image.py:430(_getdecoder)\n",
       " 11136382   56.482    0.000  199.585    0.000 Image.py:779(frombytes)\n",
       " 15745713   56.455    0.000   88.746    0.000 Image.py:553(_new)\n",
       " 11136382   54.916    0.000  586.936    0.000 Image.py:2353(frombytes)\n",
       "38119563/38119554   53.420    0.000   53.458    0.000 {built-in method builtins.hasattr}\n",
       "    47040   45.961    0.001   45.961    0.001 {method 'clone' of 'torch._C._TensorBase' objects}\n",
       " 11136382   44.378    0.000   75.553    0.000 Image.py:451(_getencoder)\n",
       " 11136000   43.862    0.000   43.862    0.000 {method 'resize_as_' of 'torch._C._TensorBase' objects}\n",
       " 11136000   43.169    0.000   81.569    0.000 functional.py:172(resize)\n",
       "     1728   42.707    0.025  276.099    0.160 replicate.py:5(replicate)\n",
       " 26882095   41.770    0.000   87.085    0.000 Image.py:601(__del__)\n",
       " 11136382   40.824    0.000  673.623    0.000 Image.py:2396(frombuffer)\n",
       " 26882095   39.930    0.000   39.930    0.000 Image.py:529(__init__)\n",
       " 11136191   37.546    0.000   37.546    0.000 {method 'new' of 'torch._C._TensorBase' objects}\n",
       "     2304   36.670    0.016   36.670    0.016 {method 'pin_memory' of 'torch._C._TensorBase' objects}\n",
       " 72501309   36.221    0.000   36.221    0.000 {method 'get' of 'dict' objects}\n",
       "     1733   35.562    0.021   35.562    0.021 {method 'flush' of '_io.TextIOWrapper' objects}\n",
       " 26881140   32.757    0.000   46.340    0.000 functional.py:17(_is_pil_image)\n",
       " 11136000   31.703    0.000   31.703    0.000 {built-in method from_buffer}\n",
       "     3456   29.111    0.008   29.111    0.008 {built-in method torch._C._broadcast_coalesced}\n",
       "    99975   28.874    0.000   28.874    0.000 {built-in method torch._C._gather}\n",
       " 15746095   26.773    0.000   38.028    0.000 Image.py:809(load)\n",
       " 11136382   26.743    0.000   26.743    0.000 {method 'decode' of 'ImagingDecoder' objects}\n",
       "22237635/2404752   25.919    0.000   28.827    0.000 module.py:938(named_modules)\n",
       "     1536   24.372    0.016 4051.851    2.638 dataloader.py:615(<listcomp>)\n",
       " 44545719   24.181    0.000   24.181    0.000 Image.py:549(size)\n",
       " 22692913   23.389    0.000   23.389    0.000 {built-in method builtins.getattr}\n",
       "    47040   22.976    0.000   75.134    0.002 summary.py:150(make_histogram)\n",
       " 11136000   22.892    0.000 1384.133    0.000 transforms.py:68(__call__)\n",
       "    47040   22.397    0.000   22.397    0.000 {method 'sort' of 'numpy.ndarray' objects}\n",
       "     1920   20.735    0.011 4262.292    2.220 dataloader.py:612(__next__)\n",
       " 11136000   20.511    0.000  102.080    0.000 transforms.py:167(__call__)\n",
       "        1   20.163   20.163 73078.953 73078.953 train_cnf_disentangle_rl.py:1(<module>)\n",
       "  9216000   19.697    0.000  112.121    0.000 transforms.py:439(__call__)\n",
       " 11136382   19.184    0.000   19.184    0.000 {built-in method PIL._imaging.raw_decoder}\n",
       "     3264   18.897    0.006   18.897    0.006 {built-in method torch._C._scatter}\n",
       " 10322951   18.742    0.000   33.878    0.000 serialization.py:234(persistent_id)\n",
       "  4609140   17.843    0.000   17.843    0.000 {method 'transpose' of 'ImagingCore' objects}\n",
       "   134150   16.185    0.000   16.185    0.000 {method 'cpu' of 'torch._C._TensorBase' objects}\n",
       "     1920   15.167    0.008   26.806    0.014 sampler.py:158(__iter__)\n",
       " 20819123   14.918    0.000   14.918    0.000 {method 'copy' of 'dict' objects}\n",
       "     3073   14.813    0.005   14.813    0.005 {method 'to' of 'torch._C._TensorBase' objects}\n",
       " 27838075   14.722    0.000   14.722    0.000 {method 'append' of 'list' objects}\n",
       "  4609140   14.584    0.000   68.275    0.000 Image.py:2241(transpose)\n",
       " 11136000   14.317    0.000   14.317    0.000 {built-in method PIL._imaging.raw_encoder}\n",
       " 11185420   13.851    0.000   13.851    0.000 {built-in method builtins.max}\n",
       " 11136573   13.385    0.000   19.594    0.000 _util.py:7(isStringType)\n",
       "   282240   13.141    0.000   13.141    0.000 {built-in method norm}\n",
       "   306711   12.276    0.000   12.276    0.000 {built-in method numpy.core.multiarray.array}\n",
       " 15220230   11.639    0.000   11.639    0.000 {method 'copy' of 'collections.OrderedDict' objects}\n",
       " 11136382   11.534    0.000   11.534    0.000 {method 'setimage' of 'ImagingDecoder' objects}\n",
       " 15746095   11.254    0.000   11.254    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
       "   572320   11.110    0.000   11.110    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n",
       "  4609140   10.556    0.000   86.029    0.000 functional.py:335(hflip)\n",
       "     1728   10.226    0.006 20919.267   12.106 module.py:483(__call__)\n",
       " 11136382   10.064    0.000   10.064    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
       "   564480    9.675    0.000    9.675    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
       "      477    9.573    0.020   47.714    0.100 {method 'dump' of '_pickle.Pickler' objects}\n",
       "      174    8.751    0.050    8.751    0.050 {built-in method posix.mkdir}\n",
       "     6403    8.507    0.001    8.507    0.001 {built-in method posix.stat}\n",
       "4608/1536    8.399    0.002  126.132    0.082 dataloader.py:196(default_collate)\n",
       "    13356    8.183    0.001    8.183    0.001 {method '_write_file' of 'torch._C.CudaLongStorageBase' objects}\n",
       "      584    7.604    0.013    7.604    0.013 {method 'flush' of '_io.BufferedWriter' objects}\n",
       "   301056    7.179    0.000    7.179    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
       " 11137121    6.506    0.000    6.506    0.000 {method 'join' of 'bytes' objects}\n",
       "  9216000    6.394    0.000    6.394    0.000 {method 'random' of '_random.Random' objects}\n",
       " 10322951    6.140    0.000    6.140    0.000 __init__.py:128(is_storage)\n",
       "     1152    6.133    0.005   40.794    0.035 adam.py:49(step)\n",
       "   104967    4.973    0.000   88.229    0.001 {built-in method apply}\n",
       "    44132    4.760    0.000    4.760    0.000 {method 'mean' of 'torch._C._TensorBase' objects}\n",
       "   951714    4.735    0.000   32.986    0.000 module.py:771(_named_members)\n",
       "   282240    4.711    0.000    4.711    0.000 {method 'sqrt' of 'torch._C._TensorBase' objects}\n",
       "   282240    4.353    0.000    4.353    0.000 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n",
       "    47040    4.142    0.000   80.627    0.002 summary.py:126(histogram)\n",
       "  7674790    4.060    0.000    4.060    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
       "   282240    3.942    0.000    3.942    0.000 {method 'addcmul_' of 'torch._C._TensorBase' objects}\n",
       "   188737    3.356    0.000    3.356    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "  3410344    3.339    0.000    4.970    0.000 tensor.py:416(__hash__)\n",
       "  2047088    3.256    0.000    4.239    0.000 module.py:891(named_children)\n",
       "878204/2305    3.004    0.000   10.610    0.005 module.py:203(apply)\n",
       "  4382670    3.001    0.000    4.321    0.000 {method 'add' of 'set' objects}\n",
       "    94080    2.923    0.000    2.923    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
       "    99975    2.919    0.000   42.735    0.000 _functions.py:52(forward)\n",
       "  5076723    2.730    0.000    2.730    0.000 {built-in method __new__ of type object at 0x560d15a7cd60}\n",
       "   404019    2.605    0.000    4.264    0.000 tensor.py:33(__reduce_ex__)\n",
       "    14246    2.509    0.000    2.509    0.000 socket.py:334(send)\n",
       "  2047088    2.508    0.000    6.747    0.000 module.py:882(children)\n",
       "      357    2.501    0.007    2.501    0.007 {method 'cuda' of 'torch._C._TensorBase' objects}\n",
       "    47041    2.444    0.000    2.444    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
       "   103652    2.431    0.000  119.995    0.001 writer.py:82(add_summary)\n",
       "     1152    2.277    0.002   32.998    0.029 clip_grad.py:6(clip_grad_norm_)\n",
       "194616/477    1.826    0.000    2.259    0.005 module.py:602(state_dict)\n",
       "  3644996    1.740    0.000    1.740    0.000 {built-in method builtins.id}\n",
       "   404019    1.681    0.000    1.681    0.000 serialization.py:149(_is_compressed_file)\n",
       "   282083    1.618    0.000    1.618    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
       "  1129869    1.577    0.000    2.105    0.000 module.py:829(<lambda>)\n",
       "      725    1.436    0.002    1.436    0.002 {method 'update' of '_hashlib.HASH' objects}\n",
       "      477    1.415    0.003  713.068    1.495 serialization.py:221(_save)\n",
       "    54884    1.398    0.000    6.404    0.000 summary.py:105(scalar)\n",
       "   201895    1.256    0.000    3.272    0.000 {built-in method builtins.all}\n",
       "    47040    1.216    0.000   45.583    0.001 histograms.py:597(histogram)\n",
       "   103652    1.210    0.000  116.349    0.001 queue.py:115(put)\n",
       "    54884    1.155    0.000   32.015    0.001 writer.py:344(add_scalars)\n",
       "   122651    1.141    0.000    1.141    0.000 {method 'release' of '_thread.lock' objects}\n",
       "    47040    1.125    0.000   14.984    0.000 histograms.py:297(_get_bin_edges)\n",
       "    47080    1.100    0.000    1.100    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "   404019    1.073    0.000    3.216    0.000 serialization.py:157(_should_read_directly)\n",
       "      192    1.053    0.005    1.053    0.005 {built-in method randperm}\n",
       "   870408    0.981    0.000    4.194    0.000 _functions.py:60(<genexpr>)\n",
       "  1205118    0.969    0.000    0.969    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
       "   404019    0.905    0.000    2.143    0.000 serialization.py:102(location_tag)\n",
       "    13931    0.898    0.000    0.898    0.000 {built-in method _thread.start_new_thread}\n",
       "108610/1727    0.889    0.000   45.751    0.026 scatter_gather.py:51(gather_map)\n",
       "   876934    0.877    0.000    1.263    0.000 _functions.py:59(<genexpr>)\n",
       "   156999    0.868    0.000   14.151    0.000 x2num.py:10(make_np)\n",
       "    47423    0.867    0.000    0.867    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "   799800    0.855    0.000    1.431    0.000 _functions.py:67(<lambda>)\n",
       "    47231    0.849    0.000    0.849    0.000 {built-in method numpy.core.multiarray.zeros}\n",
       "        1    0.840    0.840    0.840    0.840 {built-in method caffe2.python.caffe2_pybind11_state_gpu.num_cuda_devices}\n",
       "   799800    0.829    0.000    1.452    0.000 _functions.py:58(<lambda>)\n",
       "   756450    0.826    0.000   23.857    0.000 module.py:808(named_parameters)\n",
       "     1536    0.803    0.001  117.931    0.077 dataloader.py:232(<listcomp>)\n",
       "    54884    0.799    0.000   10.813    0.000 writer.py:303(__append_to_scalar_dict)\n",
       "   634176    0.793    0.000    1.079    0.000 module.py:877(<lambda>)\n",
       "   282240    0.781    0.000   14.092    0.000 functional.py:607(norm)\n",
       "146304/384    0.778    0.000    3.735    0.010 module.py:976(train)\n",
       "      384    0.778    0.002    0.778    0.002 {method 'random_' of 'torch._C._TensorBase' objects}\n",
       "    86151    0.772    0.000   11.761    0.000 x2num.py:27(prepare_pytorch)\n",
       "   709218    0.726    0.000   22.461    0.000 module.py:784(parameters)\n",
       "   404019    0.707    0.000    0.937    0.000 serialization.py:57(_cuda_tag)\n",
       "    47040    0.694    0.000    0.851    0.000 function_base.py:1079(diff)\n",
       "     1152    0.684    0.001    2.541    0.002 optimizer.py:157(zero_grad)\n",
       "   103652    0.649    0.000    2.092    0.000 threading.py:334(notify)\n",
       "   103652    0.643    0.000  117.379    0.001 writer.py:137(_add_event)\n",
       "      191    0.639    0.003    6.496    0.034 summary.py:184(image)\n",
       "    94080    0.638    0.000    0.638    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
       "   804792    0.629    0.000    0.629    0.000 {method 'get_device' of 'torch._C._TensorBase' objects}\n",
       "    47040    0.628    0.000  197.720    0.004 writer.py:390(add_histogram)\n",
       "   635904    0.604    0.000    8.230    0.000 module.py:911(modules)\n",
       "      477    0.579    0.001  713.646    1.496 serialization.py:218(<lambda>)\n",
       "   134150    0.569    0.000    0.569    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
       "  1059940    0.557    0.000    0.557    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
       "   282240    0.552    0.000   14.644    0.000 tensor.py:250(norm)\n",
       "   799800    0.504    0.000    0.504    0.000 _functions.py:54(<lambda>)\n",
       "   438912    0.491    0.000    1.399    0.000 train_misc.py:76(__call__)\n",
       "   404019    0.476    0.000    0.476    0.000 {method 'storage' of 'torch._C._TensorBase' objects}\n",
       "   404019    0.461    0.000    0.461    0.000 {method 'fileno' of '_io.BufferedWriter' objects}\n",
       "816319/815109    0.460    0.000    0.474    0.000 {built-in method builtins.issubclass}\n",
       "    94080    0.460    0.000    8.757    0.000 fromnumeric.py:2651(ndim)\n",
       "   438912    0.458    0.000    0.715    0.000 train_misc.py:96(__call__)\n",
       "   404019    0.457    0.000    0.693    0.000 serialization.py:121(normalize_storage_type)\n",
       "   102443    0.409    0.000    0.409    0.000 {method 'sub' of '_sre.SRE_Pattern' objects}\n",
       "   109959    0.409    0.000    1.256    0.000 numeric.py:1927(isscalar)\n",
       "     1536    0.406    0.000 18812.078   12.247 train_cnf_disentangle_rl.py:278(compute_bits_per_dim)\n",
       "    96997    0.404    0.000    0.405    0.000 {built-in method _warnings.warn}\n",
       "   167600    0.391    0.000    0.601    0.000 _utils.py:5(_get_device_index)\n",
       "     1567    0.387    0.000    0.387    0.000 {built-in method zeros}\n",
       "    47041    0.380    0.000    0.380    0.000 {built-in method numpy.core.multiarray.concatenate}\n",
       "    31730    0.380    0.000  127.004    0.004 threading.py:263(wait)\n",
       "    92239    0.372    0.000    0.625    0.000 abc.py:180(__instancecheck__)\n",
       "        8    0.359    0.045    0.359    0.045 {built-in method _pickle.load}\n",
       "      867    0.357    0.000    0.357    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
       "      192    0.339    0.002    0.339    0.002 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
       "      698    0.333    0.000    0.333    0.000 {method 'read' of '_io.FileIO' objects}\n",
       "   282240    0.326    0.000    0.326    0.000 clip_grad.py:24(<lambda>)\n",
       "   102115    0.325    0.000    0.868    0.000 summary.py:64(_clean_tag)\n",
       "      191    0.310    0.002    0.310    0.002 {method 'encode_to_file' of 'ImagingEncoder' objects}\n",
       "     1728    0.308    0.000    0.855    0.000 replicate.py:12(<dictcomp>)\n",
       "   103652    0.308    0.000  116.657    0.001 event_file_writer.py:131(add_event)\n",
       "       41    0.302    0.007    0.302    0.007 {method 'readline' of '_io.BufferedReader' objects}\n",
       "   404019    0.300    0.000    0.300    0.000 serialization.py:52(_cpu_tag)\n",
       "   404019    0.298    0.000    0.298    0.000 {method 'stride' of 'torch._C._TensorBase' objects}\n",
       "   102115    0.285    0.000    0.430    0.000 writer.py:314(_check_caffe2)\n",
       "      384    0.275    0.001    1.507    0.004 dataloader.py:518(__init__)\n",
       "    47040    0.275    0.000    3.536    0.000 histograms.py:391(_search_sorted_inclusive)\n",
       "    19100    0.268    0.000    0.268    0.000 {method 'copy_' of 'torch._C._TensorBase' objects}\n",
       "   188160    0.263    0.000   12.346    0.000 numeric.py:433(asarray)\n",
       "    47041    0.260    0.000    1.011    0.000 fromnumeric.py:64(_wrapreduction)\n",
       "   425088    0.252    0.000    0.252    0.000 _functions.py:13(<genexpr>)\n",
       "   404019    0.248    0.000    0.248    0.000 {method 'storage_offset' of 'torch._C._TensorBase' objects}\n",
       "   182333    0.248    0.000    0.248    0.000 _weakrefset.py:70(__contains__)\n",
       "   404019    0.245    0.000    0.245    0.000 hooks.py:51(warn_if_has_hooks)\n",
       "   119318    0.243    0.000    0.370    0.000 threading.py:239(__enter__)\n",
       "   141256    0.243    0.000    0.252    0.000 module.py:521(__getattr__)\n",
       "    99975    0.242    0.000   29.116    0.000 comm.py:151(gather)\n",
       "   281995    0.239    0.000    0.239    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}\n",
       "   390663    0.232    0.000    0.232    0.000 {method 'size' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "    47042    0.224    0.000    0.224    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "   390663    0.221    0.000    0.221    0.000 {method 'get_device' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "   135382    0.220    0.000    0.382    0.000 threading.py:254(_is_owned)\n",
       "   282712    0.217    0.000    0.217    0.000 {built-in method math.sqrt}\n",
       "    16347    0.208    0.000    0.208    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}\n",
       "    27/24    0.208    0.008    0.217    0.009 {built-in method _imp.create_dynamic}\n",
       "   195264    0.206    0.000   10.160    0.000 module.py:856(named_buffers)\n",
       "   195264    0.202    0.000   10.362    0.000 module.py:834(buffers)\n",
       "   119732    0.202    0.000    0.302    0.000 queue.py:202(_qsize)\n",
       "   119318    0.197    0.000    0.278    0.000 threading.py:242(__exit__)\n",
       "    47040    0.194    0.000   23.813    0.001 fromnumeric.py:760(sort)\n",
       "    47040    0.192    0.000    0.389    0.000 histograms.py:220(_ravel_and_check_weights)\n",
       "   108863    0.182    0.000    0.182    0.000 {built-in method time.time}\n",
       "      477    0.180    0.000    0.293    0.001 optimizer.py:88(<dictcomp>)\n",
       "     1728    0.170    0.000 20567.593   11.903 parallel_apply.py:21(parallel_apply)\n",
       "     1728    0.165    0.000    0.165    0.000 _functions.py:28(<listcomp>)\n",
       "   103652    0.160    0.000    0.241    0.000 queue.py:206(_put)\n",
       "    15666    0.153    0.000    0.252    0.000 threading.py:498(__init__)\n",
       "     1537    0.153    0.000    0.164    0.000 summary.py:380(text)\n",
       "    58401    0.152    0.000    0.237    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "    47040    0.149    0.000    1.160    0.000 fromnumeric.py:1933(any)\n",
       "    38200    0.146    0.000    0.146    0.000 {method 'narrow' of 'torch._C._TensorBase' objects}\n",
       "     2688    0.144    0.000    0.144    0.000 {built-in method rsub}\n",
       "     1728    0.143    0.000    0.397    0.000 replicate.py:19(<dictcomp>)\n",
       "     1536    0.141    0.000    0.346    0.000 train_misc.py:10(standard_normal_logprob)\n",
       "    47040    0.137    0.000    1.863    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
       "   102601    0.136    0.000    0.136    0.000 {method 'lstrip' of 'str' objects}\n",
       "    15666    0.136    0.000   15.284    0.001 threading.py:533(wait)\n",
       "      698    0.135    0.000    0.468    0.001 <frozen importlib._bootstrap_external>:830(get_data)\n",
       "4017/4013    0.135    0.000    0.241    0.000 {built-in method builtins.__build_class__}\n",
       "      191    0.133    0.001    0.566    0.003 utils.py:6(make_grid)\n",
       "      191    0.131    0.001    0.222    0.001 utils.py:70(make_grid)\n",
       "    86151    0.129    0.000    0.182    0.000 variable.py:6(__instancecheck__)\n",
       "    94656    0.129    0.000    0.237    0.000 numeric.py:504(asanyarray)\n",
       "   119318    0.127    0.000    0.127    0.000 {method '__enter__' of '_thread.lock' objects}\n",
       "    13931    0.125    0.000    0.453    0.000 threading.py:757(__init__)\n",
       "    13931    0.124    0.000   12.832    0.001 threading.py:828(start)\n",
       "    54885    0.121    0.000    0.167    0.000 writer.py:204(get_logdir)\n",
       "      504    0.119    0.000    0.190    0.000 {built-in method builtins.sorted}\n",
       "   149628    0.114    0.000    0.114    0.000 {method 'append' of 'collections.deque' objects}\n",
       "    29805    0.112    0.000 20553.909    0.690 threading.py:1062(_wait_for_tstate_lock)\n",
       "59686/57897    0.110    0.000    2.156    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
       "     1728    0.107    0.000   21.427    0.012 _functions.py:11(forward)\n",
       "   203060    0.103    0.000    0.103    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
       "    47040    0.097    0.000    1.726    0.000 _methods.py:30(_amin)\n",
       "    13824    0.095    0.000 20554.029    1.487 threading.py:1024(join)\n",
       "     1536    0.092    0.000    0.092    0.000 {method 'pow' of 'torch._C._TensorBase' objects}\n",
       "    63485    0.090    0.000    0.090    0.000 {method 'rpartition' of 'str' objects}\n",
       "   103463    0.089    0.000    0.089    0.000 {method 'items' of 'dict' objects}\n",
       "    15987    0.086    0.000    0.086    0.000 threading.py:215(__init__)\n",
       "    16128    0.084    0.000    0.639    0.000 cnf_gate.py:142(num_evals)\n",
       "    14246    0.083    0.000    2.709    0.000 iostream.py:195(schedule)\n",
       "   110304    0.081    0.000    0.081    0.000 {method 'keys' of 'dict' objects}\n",
       "   119318    0.081    0.000    0.081    0.000 {method '__exit__' of '_thread.lock' objects}\n",
       "    47040    0.081    0.000    0.678    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
       "    47040    0.080    0.000    0.629    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "     1152    0.080    0.000 46402.370   40.280 tensor.py:74(backward)\n",
       "     1728    0.076    0.000 20567.711   11.903 data_parallel.py:152(parallel_apply)\n",
       "     1728    0.076    0.000  276.175    0.160 data_parallel.py:146(replicate)\n",
       "      477    0.075    0.000    0.075    0.000 {method 'close' of '_io.BufferedWriter' objects}\n",
       "    23040    0.074    0.000    0.216    0.000 container.py:124(_get_abs_string_index)\n",
       "    47040    0.072    0.000    0.597    0.000 _methods.py:26(_amax)\n",
       "      477    0.072    0.000    0.127    0.000 optimizer.py:84(<listcomp>)\n",
       "     1733    0.070    0.000    0.145    0.000 __init__.py:251(__init__)\n",
       "    31730    0.069    0.000    0.110    0.000 threading.py:251(_acquire_restore)\n",
       "      698    0.067    0.000    0.067    0.000 {built-in method marshal.loads}\n",
       "    29488    0.067    0.000    0.091    0.000 threading.py:1230(current_thread)\n",
       "    47040    0.066    0.000    0.548    0.000 _methods.py:34(_sum)\n",
       "    54884    0.065    0.000    0.065    0.000 {method 'squeeze' of 'numpy.ndarray' objects}\n",
       "     8847    0.064    0.000    2.621    0.000 iostream.py:382(write)\n",
       "    50747    0.062    0.000    0.062    0.000 {built-in method _thread.allocate_lock}\n",
       "     3264    0.060    0.000   19.094    0.006 _functions.py:80(forward)\n",
       "     1536    0.059    0.000    0.059    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
       "     1908    0.059    0.000    0.059    0.000 {built-in method _pickle.dump}\n",
       "    77097    0.058    0.000    0.058    0.000 {method 'remove' of 'collections.deque' objects}\n",
       "      192    0.057    0.000    2.498    0.013 odenvp_conditional_rl.py:84(set_scale_std)\n",
       "    23040    0.057    0.000    0.288    0.000 container.py:133(__getitem__)\n",
       "5760/1920    0.057    0.000   19.240    0.010 scatter_gather.py:11(scatter_map)\n",
       "     1728    0.054    0.000 20909.020   12.100 data_parallel.py:136(forward)\n",
       "    48225    0.054    0.000    0.078    0.000 container.py:153(__len__)\n",
       "    16128    0.050    0.000    0.104    0.000 cnf_regularization_rl.py:33(_num_evals)\n",
       "    47040    0.049    0.000    0.049    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "    16128    0.048    0.000    0.327    0.000 cnf_regularization_rl.py:14(after_odeint)\n",
       "    47040    0.047    0.000    0.047    0.000 {built-in method numpy.core.multiarray.normalize_axis_index}\n",
       "    15981    0.047    0.000    0.099    0.000 threading.py:1104(is_alive)\n",
       "    54885    0.046    0.000    0.046    0.000 event_file_writer.py:118(get_logdir)\n",
       "    31730    0.045    0.000    0.067    0.000 threading.py:248(_release_save)\n",
       "    16128    0.045    0.000    0.260    0.000 odefunc_rl.py:278(after_odeint)\n",
       "     2240    0.044    0.000    0.044    0.000 {built-in method zlib.crc32}\n",
       "     1728    0.044    0.000    0.051    0.000 replicate.py:15(<listcomp>)\n",
       "        1    0.041    0.041    0.041    0.041 {built-in method torch._C._cuda_init}\n",
       "     9855    0.041    0.000    0.041    0.000 {method 'format' of 'str' objects}\n",
       "    13824    0.041    0.000    0.051    0.000 threading.py:966(_stop)\n",
       "     1728    0.041    0.000    0.490    0.000 parallel_apply.py:67(<listcomp>)\n",
       "     1536    0.041    0.000    0.041    0.000 {built-in method sum}\n",
       "3456/1152    0.038    0.000   36.758    0.032 dataloader.py:237(pin_memory_batch)\n",
       "        3    0.036    0.012    0.106    0.035 utils.py:70(parse_header)\n",
       "    43843    0.036    0.000    0.036    0.000 threading.py:506(is_set)\n",
       "    26112    0.035    0.000    0.118    0.000 _functions.py:82(<lambda>)\n",
       "     3466    0.034    0.000   39.982    0.012 __init__.py:982(emit)\n",
       "      412    0.032    0.000    0.032    0.000 {built-in method posix.listdir}\n",
       "      699    0.032    0.000    0.032    0.000 {built-in method torch._C._cuda_isDriverSufficient}\n",
       "    14444    0.030    0.000    0.042    0.000 _weakrefset.py:81(add)\n",
       "     3466    0.029    0.000   39.360    0.011 __init__.py:971(flush)\n",
       "    13816    0.029    0.000    0.040    0.000 _weakrefset.py:38(_remove)\n",
       "     1733    0.029    0.000    0.055    0.000 __init__.py:1376(findCaller)\n",
       "     1152    0.028    0.000    0.028    0.000 {built-in method ones_like}\n",
       "    16459    0.028    0.000    0.028    0.000 {method 'insert' of 'list' objects}\n",
       "  742/127    0.028    0.000    0.098    0.001 sre_parse.py:470(_parse)\n",
       "     1728    0.028    0.000   19.292    0.011 scatter_gather.py:33(scatter_kwargs)\n",
       "    33977    0.027    0.000    0.027    0.000 {built-in method _thread.get_ident}\n",
       "      191    0.025    0.000    0.025    0.000 {method 'close' of '_io.BufferedRandom' objects}\n",
       "     1266    0.024    0.000    0.298    0.000 <frozen importlib._bootstrap_external>:1233(find_spec)\n",
       "     1735    0.024    0.000    3.746    0.002 iostream.py:334(flush)\n",
       "     1152    0.024    0.000    0.030    0.000 train_cnf_disentangle_rl.py:154(update_lr)\n",
       "    13931    0.022    0.000    0.022    0.000 threading.py:727(_newname)\n",
       "     3466    0.022    0.000   40.036    0.012 __init__.py:852(handle)\n",
       "     1537    0.022    0.000    0.295    0.000 writer.py:523(add_text)\n",
       "     3466    0.021    0.000    0.090    0.000 __init__.py:564(format)\n",
       "        1    0.021    0.021    2.268    2.268 train_cnf_disentangle_rl.py:181(get_dataset)\n",
       "     1733    0.020    0.000   40.057    0.023 __init__.py:1500(callHandlers)\n",
       "     9408    0.020    0.000    0.020    0.000 utils.py:74(update)\n",
       " 1482/120    0.019    0.000    0.086    0.001 sre_compile.py:64(_compile)\n",
       "    13824    0.019    0.000    0.065    0.000 parallel_apply.py:45(<lambda>)\n",
       "      191    0.019    0.000    0.019    0.000 {method 'repeat' of 'torch._C._TensorBase' objects}\n",
       "     8756    0.018    0.000    0.054    0.000 <frozen importlib._bootstrap_external>:57(_path_join)\n",
       "    14246    0.018    0.000    0.018    0.000 iostream.py:93(_event_pipe)\n",
       "     8756    0.018    0.000    0.030    0.000 <frozen importlib._bootstrap_external>:59(<listcomp>)\n",
       "    14811    0.018    0.000    0.029    0.000 sre_parse.py:253(get)\n",
       "     8847    0.017    0.000    0.024    0.000 iostream.py:307(_is_master_process)\n",
       "     1528    0.017    0.000    0.040    0.000 version.py:198(__init__)\n",
       "    13824    0.017    0.000    0.058    0.000 replicate.py:8(<lambda>)\n",
       "     1152    0.017    0.000 46402.290   40.280 __init__.py:38(backward)\n",
       "     1733    0.017    0.000   40.295    0.023 __init__.py:1421(_log)\n",
       "    13824    0.017    0.000    0.059    0.000 _functions.py:15(<lambda>)\n",
       "    26850    0.017    0.000    0.017    0.000 {method 'rstrip' of 'str' objects}\n",
       "     1733    0.016    0.000   40.325    0.023 __init__.py:1298(info)\n",
       "     3264    0.016    0.000   18.913    0.006 comm.py:131(scatter)\n",
       "     2690    0.016    0.000    2.157    0.001 {built-in method builtins.print}\n",
       "     1628    0.016    0.000    0.027    0.000 posixpath.py:75(join)\n",
       "     1728    0.015    0.000    0.015    0.000 {built-in method torch._C._get_tracing_state}\n",
       "     2688    0.015    0.000    0.159    0.000 tensor.py:348(__rsub__)\n",
       "    23984    0.015    0.000    0.015    0.000 {method 'startswith' of 'str' objects}\n",
       "     2751    0.015    0.000    0.034    0.000 posixpath.py:121(splitext)\n",
       "     6932    0.015    0.000    0.022    0.000 __init__.py:809(acquire)\n",
       "     1152    0.015    0.000    0.048    0.000 __init__.py:20(_make_grads)\n",
       "      191    0.015    0.000    5.471    0.029 summary.py:248(make_image)\n",
       "     1537    0.014    0.000    3.918    0.003 train_cnf_disentangle_rl.py:416(<lambda>)\n",
       "     1152    0.014    0.000    5.649    0.005 train_misc.py:69(count_nfe_gate)\n",
       "     3456    0.014    0.000   29.125    0.008 comm.py:24(broadcast_coalesced)\n",
       "      576    0.014    0.000    0.032    0.000 _methods.py:58(_mean)\n",
       "    16531    0.014    0.000    0.014    0.000 sre_parse.py:232(__next)\n",
       "     6932    0.013    0.000    0.018    0.000 __init__.py:816(release)\n",
       "      382    0.013    0.000    5.040    0.013 ImageFile.py:463(_save)\n",
       "     1152    0.013    0.000    5.092    0.004 train_misc.py:89(count_total_time)\n",
       "     4167    0.013    0.000    0.035    0.000 enum.py:803(__and__)\n",
       "     1537    0.013    0.000    0.013    0.000 {method 'type' of 'torch._C._TensorBase' objects}\n",
       "     9613    0.013    0.000    0.023    0.000 enum.py:267(__call__)\n",
       "    23040    0.013    0.000    0.013    0.000 {built-in method _operator.index}\n",
       "     2054    0.013    0.000    0.023    0.000 posixpath.py:144(basename)\n",
       "      191    0.012    0.000    0.012    0.000 {method 'copy' of 'ImagingCore' objects}\n",
       "     8847    0.012    0.000    0.606    0.000 iostream.py:320(_schedule_flush)\n",
       "     3551    0.012    0.000    0.012    0.000 {method 'write' of '_io.BytesIO' objects}\n",
       "      382    0.012    0.000  132.732    0.347 Image.py:1892(save)\n",
       "    722/1    0.012    0.000 73079.415 73079.415 {built-in method builtins.exec}\n",
       "     3466    0.012    0.000    0.102    0.000 __init__.py:829(format)\n",
       "    13931    0.011    0.000    0.011    0.000 threading.py:1120(daemon)\n",
       "    13816    0.011    0.000    0.011    0.000 {method 'discard' of 'set' objects}\n",
       "     1152    0.011    0.000   36.706    0.032 dataloader.py:245(<listcomp>)\n",
       "     4608    0.011    0.000    0.017    0.000 container.py:156(__iter__)\n",
       "     2751    0.011    0.000    0.016    0.000 genericpath.py:117(_splitext)\n",
       "     1120    0.011    0.000    0.078    0.000 PngImagePlugin.py:667(putchunk)\n",
       "    11306    0.011    0.000    0.011    0.000 {built-in method posix.fspath}\n",
       "12278/12206    0.011    0.000    0.014    0.000 {method 'join' of 'str' objects}\n",
       "     2250    0.010    0.000   26.836    0.012 {built-in method builtins.next}\n",
       "     3466    0.010    0.000    0.025    0.000 __init__.py:542(usesTime)\n",
       "      191    0.010    0.000    0.010    0.000 {method 'mul' of 'torch._C._TensorBase' objects}\n",
       "     1733    0.010    0.000    0.154    0.000 __init__.py:1406(makeRecord)\n",
       "     8432    0.010    0.000    0.010    0.000 {method 'rfind' of 'str' objects}\n",
       "    13824    0.010    0.000    0.010    0.000 {method 'locked' of '_thread.lock' objects}\n",
       "     1733    0.010    0.000    0.013    0.000 __init__.py:1544(isEnabledFor)\n",
       "      751    0.010    0.000    0.297    0.000 <frozen importlib._bootstrap>:870(_find_spec)\n",
       "     6232    0.009    0.000    0.014    0.000 sre_parse.py:163(__getitem__)\n",
       "     1733    0.009    0.000   40.069    0.023 __init__.py:1446(handle)\n",
       "     3466    0.009    0.000    0.015    0.000 __init__.py:387(usesTime)\n",
       "     1727    0.009    0.000   45.768    0.027 data_parallel.py:155(gather)\n",
       "    13356    0.009    0.000    0.009    0.000 {method 'size' of 'torch._C.CudaLongStorageBase' objects}\n",
       "     1396    0.009    0.000    0.028    0.000 <frozen importlib._bootstrap_external>:263(cache_from_source)\n",
       "     9612    0.009    0.000    0.009    0.000 enum.py:517(__new__)\n",
       "     1334    0.009    0.000    0.014    0.000 PyColorize.py:284(_inner_call_)\n",
       "     1762    0.009    0.000    0.021    0.000 tokenize.py:492(_tokenize)\n",
       "    13356    0.009    0.000    0.009    0.000 {method 'get_device' of 'torch._C.CudaLongStorageBase' objects}\n",
       "      191    0.009    0.000  128.728    0.674 utils.py:90(save_image)\n",
       "     3466    0.009    0.000    0.009    0.000 __init__.py:390(format)\n",
       "     1920    0.009    0.000   19.249    0.010 scatter_gather.py:5(scatter)\n",
       "      698    0.009    0.000    0.013    0.000 <frozen importlib._bootstrap_external>:430(_validate_bytecode_header)\n",
       "      191    0.009    0.000    0.340    0.002 JpegImagePlugin.py:617(_save)\n",
       "     1536    0.009    0.000    0.009    0.000 scatter_gather.py:40(<listcomp>)\n",
       "    10466    0.008    0.000    0.008    0.000 {method 'split' of 'str' objects}\n",
       "    10585    0.008    0.000    0.008    0.000 {built-in method posix.getpid}\n",
       "     4604    0.008    0.000    0.013    0.000 posixpath.py:41(_get_sep)\n",
       "       36    0.008    0.000    0.009    0.000 {method 'readlines' of '_io._IOBase' objects}\n",
       "      698    0.008    0.000    0.624    0.001 <frozen importlib._bootstrap_external>:743(get_code)\n",
       "     5199    0.008    0.000    0.008    0.000 __init__.py:705(filter)\n",
       "     1756    0.008    0.000    0.013    0.000 posixpath.py:52(normcase)\n",
       "     1727    0.008    0.000   45.759    0.026 scatter_gather.py:46(gather)\n",
       "      614    0.008    0.000    0.014    0.000 sre_compile.py:250(_optimize_charset)\n",
       "     3466    0.008    0.000    0.017    0.000 __init__.py:548(formatMessage)\n",
       "     1728    0.008    0.000   19.300    0.011 data_parallel.py:149(scatter)\n",
       "      760    0.007    0.000    0.022    0.000 version.py:131(_legacy_cmpkey)\n",
       "      727    0.007    0.000    0.034    0.000 <frozen importlib._bootstrap>:504(_init_module_attrs)\n",
       "     1733    0.007    0.000   35.678    0.021 __init__.py:1063(emit)\n",
       "       97    0.007    0.000    0.015    0.000 <frozen importlib._bootstrap_external>:1067(_path_hooks)\n",
       "     4841    0.007    0.000    0.238    0.000 <frozen importlib._bootstrap_external>:75(_path_stat)\n",
       "     6953    0.007    0.000    0.007    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "     3466    0.007    0.000    0.027    0.000 __init__.py:329(getMessage)\n",
       "     1733    0.007    0.000    0.010    0.000 __init__.py:157(<lambda>)\n",
       "     3312    0.007    0.000    0.012    0.000 version.py:114(_parse_version_parts)\n",
       "    12319    0.007    0.000    0.007    0.000 {method 'strip' of 'str' objects}\n",
       "      191    0.007    0.000    4.734    0.025 PngImagePlugin.py:689(_save)\n",
       "     1644    0.007    0.000    0.007    0.000 {method 'SerializeToString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "        1    0.007    0.007    0.007    0.007 {built-in method builtins.compile}\n",
       "   762/18    0.007    0.000    2.960    0.164 <frozen importlib._bootstrap>:966(_find_and_load)\n",
       " 2304/962    0.007    0.000    0.009    0.000 sre_parse.py:173(getwidth)\n",
       "     3466    0.007    0.000    0.007    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
       "      490    0.006    0.000    0.006    0.000 {built-in method zeros_like}\n",
       "    816/2    0.006    0.000    0.020    0.010 module.py:1024(__repr__)\n",
       "      477    0.006    0.000  879.609    1.844 serialization.py:131(_with_file_like)\n",
       "     1378    0.006    0.000    0.011    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\n",
       "     3814    0.006    0.000    0.011    0.000 utils.py:51(add_argument)\n",
       "      191    0.006    0.000    0.006    0.000 {method 'byte' of 'torch._C._TensorBase' objects}\n",
       "     3740    0.006    0.000    0.010    0.000 version.py:65(_compare)\n",
       "   740/19    0.006    0.000    2.909    0.153 <frozen importlib._bootstrap>:651(_load_unlocked)\n",
       "     4363    0.006    0.000    0.006    0.000 {method 'find' of 'str' objects}\n",
       "     2952    0.006    0.000    0.006    0.000 {built-in method torch._C.is_grad_enabled}\n",
       "     7557    0.006    0.000    0.006    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\n",
       "      191    0.006    0.000    0.006    0.000 {method 'clamp' of 'torch._C._TensorBase' objects}\n",
       "     3488    0.006    0.000    0.010    0.000 utils.py:81(<lambda>)\n",
       "     1536    0.006    0.000    0.006    0.000 {built-in method math.log}\n",
       "      698    0.006    0.000    0.040    0.000 __init__.py:45(is_available)\n",
       "     3488    0.006    0.000    0.009    0.000 utils.py:79(<lambda>)\n",
       "   762/18    0.006    0.000    2.959    0.164 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)\n",
       "     2688    0.005    0.000    0.030    0.000 cnf_gate.py:148(set_scale_std)\n",
       "       24    0.005    0.000    1.837    0.077 utils.py:16(check_integrity)\n",
       "     1849    0.005    0.000    0.005    0.000 {method 'encode' of 'str' objects}\n",
       "  478/174    0.005    0.000    0.016    0.000 abc.py:196(__subclasscheck__)\n",
       "     5570    0.005    0.000    0.005    0.000 {built-in method builtins.iter}\n",
       "      477    0.005    0.000    0.432    0.001 optimizer.py:72(state_dict)\n",
       "     1728    0.005    0.000    0.005    0.000 replicate.py:23(<listcomp>)\n",
       "  752/751    0.005    0.000    0.275    0.000 <frozen importlib._bootstrap_external>:1117(_get_spec)\n",
       "     8042    0.005    0.000    0.005    0.000 {method 'group' of '_sre.SRE_Match' objects}\n",
       "      191    0.005    0.000    0.231    0.001 utils.py:95(convert_to_HWC)\n",
       "     6953    0.005    0.000    0.005    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "     4154    0.005    0.000    0.005    0.000 {built-in method builtins.setattr}\n",
       "      768    0.005    0.000    0.007    0.000 version.py:343(_cmpkey)\n",
       "      677    0.005    0.000    0.009    0.000 posixpath.py:154(dirname)\n",
       "      381    0.005    0.000    0.033    0.000 module.py:62(__init__)\n",
       "      576    0.005    0.000    0.037    0.000 fromnumeric.py:2817(mean)\n",
       "     2877    0.005    0.000    0.102    0.000 <frozen importlib._bootstrap_external>:85(_path_is_mode_type)\n",
       "     1536    0.005    0.000    0.005    0.000 {method 'nelement' of 'torch._C._TensorBase' objects}\n",
       "     4226    0.005    0.000    0.007    0.000 utils.py:92(<lambda>)\n",
       "     1378    0.005    0.000    0.005    0.000 <frozen importlib._bootstrap>:78(acquire)\n",
       "     5087    0.005    0.000    0.005    0.000 {built-in method builtins.min}\n",
       "     1810    0.004    0.000    0.004    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
       "     1733    0.004    0.000    0.007    0.000 __init__.py:120(getLevelName)\n",
       "     1096    0.004    0.000    8.242    0.008 genericpath.py:16(exists)\n",
       "     1728    0.004    0.000    0.004    0.000 replicate.py:69(<listcomp>)\n",
       "      352    0.004    0.000    0.015    0.000 inspect.py:2100(_signature_from_function)\n",
       "      477    0.004    0.000  879.613    1.844 serialization.py:191(save)\n",
       "     2667    0.004    0.000    0.007    0.000 {built-in method builtins.any}\n",
       "      192    0.004    0.000   11.595    0.060 train_cnf_disentangle_rl.py:167(get_train_loader)\n",
       "     1802    0.004    0.000    0.004    0.000 {method 'match' of '_sre.SRE_Pattern' objects}\n",
       "      193    0.004    0.000    0.013    0.000 dataloader.py:768(__init__)\n",
       "     1378    0.004    0.000    0.005    0.000 <frozen importlib._bootstrap>:103(release)\n",
       "     1531    0.004    0.000    0.004    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n",
       "  498/120    0.004    0.000    0.099    0.001 sre_parse.py:407(_parse_sub)\n",
       "     2240    0.004    0.000    0.049    0.000 PngImagePlugin.py:90(_crc32)\n",
       "     2622    0.004    0.000    0.007    0.000 _binary.py:93(o32be)\n",
       "      477    0.004    0.000    0.133    0.000 optimizer.py:82(pack_group)\n",
       "     3830    0.004    0.000    0.006    0.000 utils.py:75(<lambda>)\n",
       "       14    0.004    0.000    0.004    0.000 {built-in method sqrt}\n",
       "     1728    0.004    0.000    0.004    0.000 function.py:45(mark_non_differentiable)\n",
       "        1    0.004    0.004    0.004    0.004 {built-in method randn}\n",
       "     1925    0.004    0.000    0.205    0.000 re.py:286(_compile)\n",
       "     3488    0.004    0.000    0.006    0.000 utils.py:77(<lambda>)\n",
       "       95    0.004    0.000    0.039    0.000 PyColorize.py:207(format2)\n",
       "        1    0.004    0.004    0.020    0.020 {built-in method torch._C._initExtension}\n",
       "     2491    0.004    0.000    0.096    0.000 <frozen importlib._bootstrap_external>:94(_path_isfile)\n",
       "     2114    0.004    0.000    0.004    0.000 {built-in method sys._getframe}\n",
       "     1733    0.004    0.000    0.004    0.000 __init__.py:1530(getEffectiveLevel)\n",
       "      698    0.004    0.000    0.073    0.000 <frozen importlib._bootstrap_external>:485(_compile_bytecode)\n",
       "     1733    0.004    0.000    0.004    0.000 threading.py:1076(name)\n",
       "        1    0.004    0.004    0.004    0.004 {built-in method _posixsubprocess.fork_exec}\n",
       "      478    0.004    0.000    8.033    0.017 utils.py:8(makedirs)\n",
       "      628    0.004    0.000    0.085    0.000 __init__.py:2027(distributions_from_metadata)\n",
       "     3488    0.004    0.000    0.006    0.000 utils.py:83(<lambda>)\n",
       "        1    0.004    0.004    0.004    0.004 {built-in method posix.read}\n",
       "      320    0.004    0.000    0.064    0.000 __init__.py:2481(from_location)\n",
       "     2250    0.004    0.000    0.004    0.000 {method 'extend' of 'list' objects}\n",
       "     1800    0.003    0.000    0.006    0.000 __init__.py:1972(dist_factory)\n",
       "      612    0.003    0.000    0.008    0.000 grad_mode.py:35(__exit__)\n",
       "     2123    0.003    0.000    0.003    0.000 dataloader.py:811(__setattr__)\n",
       "     4189    0.003    0.000    0.004    0.000 sre_parse.py:248(match)\n",
       "  727/721    0.003    0.000    0.257    0.000 <frozen importlib._bootstrap>:564(module_from_spec)\n",
       "    381/1    0.003    0.000    2.508    2.508 module.py:185(_apply)\n",
       "     1396    0.003    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:63(_path_split)\n",
       "      727    0.003    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:524(spec_from_file_location)\n",
       "     2943    0.003    0.000    0.003    0.000 {built-in method _struct.pack}\n",
       "      727    0.003    0.000    0.008    0.000 <frozen importlib._bootstrap>:318(__exit__)\n",
       "      191    0.003    0.000    6.516    0.034 writer.py:429(add_images)\n",
       "      172    0.003    0.000    0.004    0.000 init.py:178(_calculate_fan_in_and_fan_out)\n",
       "        1    0.003    0.003    0.005    0.005 packages.py:1(<module>)\n",
       "      612    0.003    0.000    0.005    0.000 grad_mode.py:122(__init__)\n",
       "       98    0.003    0.000    0.047    0.000 conv.py:17(__init__)\n",
       "      192    0.003    0.000    1.396    0.007 sampler.py:69(__iter__)\n",
       "      614    0.003    0.000    0.021    0.000 sre_compile.py:223(_compile_charset)\n",
       "   698/18    0.003    0.000    2.907    0.162 <frozen importlib._bootstrap_external>:672(exec_module)\n",
       "      576    0.003    0.000    0.003    0.000 _methods.py:48(_count_reduce_items)\n",
       "     3814    0.003    0.000    0.003    0.000 utils.py:61(__init__)\n",
       "     4479    0.003    0.000    0.003    0.000 {method 'lower' of 'str' objects}\n",
       "      528    0.003    0.000    0.009    0.000 copy.py:66(copy)\n",
       "     2312    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap>:847(__exit__)\n",
       "      352    0.003    0.000    0.007    0.000 inspect.py:2832(_hash_basis)\n",
       "     4608    0.003    0.000    0.003    0.000 {built-in method _imp.release_lock}\n",
       "     1152    0.003    0.000    0.003    0.000 train_misc.py:71(AccNumEvals)\n",
       "      744    0.003    0.000    0.005    0.000 inspect.py:2450(__init__)\n",
       "     1076    0.003    0.000    0.044    0.000 version.py:24(parse)\n",
       "     1152    0.003    0.000    0.003    0.000 train_misc.py:91(Accumulator)\n",
       "     2281    0.003    0.000    0.004    0.000 sre_parse.py:159(__len__)\n",
       "     1334    0.003    0.000    0.017    0.000 PyColorize.py:328(__call__)\n",
       "     2312    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap>:843(__enter__)\n",
       "        1    0.003    0.003    0.040    0.040 binding.py:81(build_conditional_library)\n",
       "      352    0.003    0.000    0.022    0.000 inspect.py:2181(_signature_from_callable)\n",
       "      320    0.003    0.000    0.006    0.000 __init__.py:683(add)\n",
       "      960    0.003    0.000    0.004    0.000 cifar.py:128(__len__)\n",
       "     4608    0.003    0.000    0.003    0.000 {built-in method _imp.acquire_lock}\n",
       "     2992    0.003    0.000    0.003    0.000 version.py:207(<genexpr>)\n",
       "      107    0.003    0.000    0.459    0.004 event_file_writer.py:35(__init__)\n",
       "     3089    0.003    0.000    0.003    0.000 {method 'endswith' of 'str' objects}\n",
       "     2103    0.003    0.000    0.004    0.000 sre_parse.py:171(append)\n",
       "      814    0.003    0.000    0.006    0.000 module.py:11(_addindent)\n",
       "      727    0.002    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:1228(_get_spec)\n",
       "      326    0.002    0.000    0.058    0.000 __init__.py:2094(_handle_ns)\n",
       "      725    0.002    0.000    0.018    0.000 <frozen importlib._bootstrap_external>:361(_get_cached)\n",
       "      751    0.002    0.000    0.004    0.000 <frozen importlib._bootstrap>:176(cb)\n",
       "      384    0.002    0.000    1.510    0.004 dataloader.py:818(__iter__)\n",
       "      612    0.002    0.000    0.004    0.000 grad_mode.py:31(__enter__)\n",
       "     1734    0.002    0.000    0.002    0.000 process.py:35(current_process)\n",
       "     1866    0.002    0.000    0.003    0.000 sre_parse.py:285(tell)\n",
       "     1870    0.002    0.000    0.008    0.000 version.py:47(__lt__)\n",
       "     1870    0.002    0.000    0.007    0.000 version.py:53(__eq__)\n",
       "      107    0.002    0.000    9.439    0.088 event_file_writer.py:90(__init__)\n",
       "      691    0.002    0.000    0.023    0.000 __init__.py:2647(_get_metadata)\n",
       "      138    0.002    0.000    0.002    0.000 {method 'splitlines' of 'str' objects}\n",
       "     1152    0.002    0.000    0.002    0.000 train_misc.py:73(__init__)\n",
       "     4226    0.002    0.000    0.002    0.000 utils.py:94(<lambda>)\n",
       "     1423    0.002    0.000    0.020    0.000 <frozen importlib._bootstrap>:403(cached)\n",
       "     1152    0.002    0.000    0.002    0.000 train_misc.py:93(__init__)\n",
       "     3828    0.002    0.000    0.002    0.000 {method 'partition' of 'str' objects}\n",
       "      192    0.002    0.000    2.501    0.013 train_cnf_disentangle_rl.py:161(update_scale_std)\n",
       "      352    0.002    0.000    0.004    0.000 inspect.py:2730(__init__)\n",
       "     1733    0.002    0.000    0.002    0.000 process.py:146(name)\n",
       "     1396    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:52(_r_long)\n",
       "      452    0.002    0.000    0.030    0.000 __init__.py:1323(safe_version)\n",
       "       94    0.002    0.000    0.002    0.000 function.py:89(__init__)\n",
       "      616    0.002    0.000    0.009    0.000 <frozen importlib._bootstrap>:194(_lock_unlock_module)\n",
       "      762    0.002    0.000    0.014    0.000 <frozen importlib._bootstrap>:147(__enter__)\n",
       "       16    0.002    0.000    0.002    0.000 {method 'AddSerializedFile' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "      150    0.002    0.000    0.035    0.000 utils.py:89(verify_interface)\n",
       "     2908    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:321(<genexpr>)\n",
       "      751    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap>:58(__init__)\n",
       "       47    0.002    0.000    0.002    0.000 {built-in method builtins.dir}\n",
       "      452    0.002    0.000    0.005    0.000 version.py:236(__str__)\n",
       "      406    0.002    0.000    0.002    0.000 {method 'sort' of 'list' objects}\n",
       "      330    0.002    0.000    0.007    0.000 __init__.py:1958(<genexpr>)\n",
       "      191    0.002    0.000    0.002    0.000 {method 'permute' of 'torch._C._TensorBase' objects}\n",
       "      384    0.002    0.000    0.002    0.000 dataloader.py:715(__del__)\n",
       "      191    0.002    0.000    0.018    0.000 Image.py:1738(resize)\n",
       "     1648    0.002    0.000    0.003    0.000 <string>:12(__new__)\n",
       "      956    0.002    0.000    0.003    0.000 __init__.py:2540(key)\n",
       "     1571    0.002    0.000    0.204    0.000 re.py:231(compile)\n",
       "     1124    0.002    0.000    0.004    0.000 _weakrefset.py:58(__iter__)\n",
       "   966/19    0.002    0.000    2.884    0.152 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
       "     1735    0.002    0.000    0.002    0.000 {built-in method _imp.lock_held}\n",
       "      912    0.002    0.000    0.003    0.000 loader.py:150(_is_section_key)\n",
       "       19    0.002    0.000    0.007    0.000 traitlets.py:961(setup_instance)\n",
       "      214    0.002    0.000    0.002    0.000 crc32c.py:77(crc_update)\n",
       "      738    0.002    0.000    0.071    0.000 PngImagePlugin.py:685(write)\n",
       "      471    0.002    0.000    0.004    0.000 copy.py:268(_reconstruct)\n",
       "      342    0.002    0.000    0.176    0.001 __init__.py:1940(find_on_path)\n",
       "       52    0.002    0.000    2.108    0.041 __init__.py:1(<module>)\n",
       "      477    0.002    0.000    0.002    0.000 optimizer.py:83(<dictcomp>)\n",
       "       50    0.002    0.000    0.342    0.007 linecache.py:82(updatecache)\n",
       "      537    0.002    0.000    0.004    0.000 __init__.py:2281(yield_lines)\n",
       "      912    0.002    0.000    0.006    0.000 loader.py:231(_has_section)\n",
       "      191    0.002    0.000    0.002    0.000 {built-in method PIL._imaging.jpeg_encoder}\n",
       "      775    0.002    0.000    0.002    0.000 {method 'split' of '_sre.SRE_Pattern' objects}\n",
       "      983    0.002    0.000    0.017    0.000 <frozen importlib._bootstrap_external>:1080(_path_importer_cache)\n",
       "     1282    0.002    0.000    0.004    0.000 tokenize.py:152(_compile)\n",
       "     1055    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:369(__init__)\n",
       "     2016    0.002    0.000    0.002    0.000 {method 'upper' of 'str' objects}\n",
       "      698    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:393(_check_name_wrapper)\n",
       "      382    0.002    0.000    0.002    0.000 {method 'flush' of '_io.BufferedRandom' objects}\n",
       "      190    0.002    0.000    0.003    0.000 configurable.py:102(<listcomp>)\n",
       "  174/109    0.002    0.000    8.861    0.081 os.py:195(makedirs)\n",
       "     2933    0.002    0.000    0.002    0.000 {method 'write' of '_io.StringIO' objects}\n",
       "       19    0.002    0.000    0.004    0.000 traitlets.py:224(getmembers)\n",
       "      748    0.002    0.000    0.003    0.000 __init__.py:2688(__getattr__)\n",
       "      282    0.002    0.000    0.004    0.000 function_base.py:3895(add_newdoc)\n",
       "        2    0.002    0.001    2.247    1.123 cifar.py:49(__init__)\n",
       "      326    0.001    0.000    0.001    0.000 module.py:17(<listcomp>)\n",
       "      698    0.001    0.000    0.046    0.000 <frozen importlib._bootstrap_external>:840(path_stats)\n",
       "      744    0.001    0.000    0.352    0.000 utils.py:22(<lambda>)\n",
       "       19    0.001    0.000    0.076    0.004 ultratb.py:833(format_record)\n",
       "     2552    0.001    0.000    0.001    0.000 {built-in method builtins.ord}\n",
       "      760    0.001    0.000    0.024    0.000 version.py:74(__init__)\n",
       "   528/44    0.001    0.000    2.070    0.047 {built-in method builtins.__import__}\n",
       "      762    0.001    0.000    0.005    0.000 <frozen importlib._bootstrap>:151(__exit__)\n",
       "     1482    0.001    0.000    0.001    0.000 sre_parse.py:111(__init__)\n",
       "     1396    0.001    0.000    0.001    0.000 {built-in method from_bytes}\n",
       "      630    0.001    0.000    0.003    0.000 sre_compile.py:388(_simple)\n",
       "  920/112    0.001    0.000    0.019    0.000 {built-in method builtins.repr}\n",
       "      174    0.001    0.000    0.003    0.000 posixpath.py:104(split)\n",
       "      323    0.001    0.000    0.050    0.000 <frozen importlib._bootstrap_external>:413(_find_module_shim)\n",
       "       20    0.001    0.000    0.002    0.000 {method 'read' of '_io.TextIOWrapper' objects}\n",
       "    95/19    0.001    0.000    0.011    0.001 configurable.py:106(_find_my_config)\n",
       "      107    0.001    0.000    0.407    0.004 record_writer.py:46(open_file)\n",
       "     1758    0.001    0.000    0.001    0.000 version.py:244(<genexpr>)\n",
       "      751    0.001    0.000    0.277    0.000 <frozen importlib._bootstrap_external>:1149(find_spec)\n",
       "     2304    0.001    0.000    0.001    0.000 version.py:298(_parse_letter_version)\n",
       "      698    0.001    0.000    0.001    0.000 {built-in method _imp._fix_co_filename}\n",
       "       31    0.001    0.000    0.003    0.000 auto.py:107(_make_function_class)\n",
       "       84    0.001    0.000    0.005    0.000 abc.py:132(__new__)\n",
       "      192    0.001    0.000    0.003    0.000 sampler.py:50(__init__)\n",
       "        7    0.001    0.000    0.001    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
       "     1806    0.001    0.000    0.001    0.000 {method 'find' of 'bytearray' objects}\n",
       "      107    0.001    0.000    0.046    0.000 record_writer.py:114(write)\n",
       "       29    0.001    0.000    0.102    0.004 traceback.py:319(extract)\n",
       "     2275    0.001    0.000    0.001    0.000 {method 'isidentifier' of 'str' objects}\n",
       "      159    0.001    0.000    0.002    0.000 __init__.py:2772(<listcomp>)\n",
       "      477    0.001    0.000    0.134    0.000 optimizer.py:86(<listcomp>)\n",
       "      120    0.001    0.000    0.006    0.000 sre_compile.py:482(_compile_info)\n",
       "     1096    0.001    0.000    0.002    0.000 inspect.py:2779(<genexpr>)\n",
       "      191    0.001    0.000    0.001    0.000 summary.py:59(_calc_scale_factor)\n",
       "      314    0.001    0.000    0.045    0.000 __init__.py:1935(<listcomp>)\n",
       "      107    0.001    0.000    8.942    0.084 record_writer.py:35(directory_check)\n",
       "     1709    0.001    0.000    0.001    0.000 ipstruct.py:125(__getattr__)\n",
       "      192    0.001    0.000    0.004    0.000 sampler.py:33(__iter__)\n",
       "      336    0.001    0.000    0.002    0.000 warnings.py:159(_add_filter)\n",
       "      120    0.001    0.000    0.198    0.002 sre_compile.py:557(compile)\n",
       "      121    0.001    0.000    0.004    0.000 __init__.py:1521(_get)\n",
       "      196    0.001    0.000    0.003    0.000 conv.py:53(extra_repr)\n",
       "      700    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:35(_new_module)\n",
       "       98    0.001    0.000    0.025    0.000 conv.py:45(reset_parameters)\n",
       "      275    0.001    0.000    0.003    0.000 module.py:122(register_parameter)\n",
       "      388    0.001    0.000    0.005    0.000 __init__.py:1468(_fn)\n",
       "      931    0.001    0.000    0.002    0.000 loader.py:218(__contains__)\n",
       "        1    0.001    0.001    0.002    0.002 descriptor_pb2.py:4(<module>)\n",
       "     1940    0.001    0.000    0.004    0.000 __init__.py:2248(_normalize_cached)\n",
       "      193    0.001    0.000    0.002    0.000 sampler.py:142(__init__)\n",
       "      314    0.001    0.000    0.049    0.000 __init__.py:1929(_by_version)\n",
       "      320    0.001    0.000    0.026    0.000 __init__.py:2468(__init__)\n",
       "      192    0.001    0.000    1.352    0.007 module.py:992(eval)\n",
       "     1015    0.001    0.000    0.002    0.000 sre_compile.py:102(fixup)\n",
       "      352    0.001    0.000    0.003    0.000 inspect.py:485(unwrap)\n",
       "      107    0.001    0.000    0.003    0.000 queue.py:27(__init__)\n",
       "      496    0.001    0.000    0.001    0.000 _weakrefset.py:36(__init__)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:48(<lambda>)\n",
       "     1096    0.001    0.000    0.002    0.000 inspect.py:2833(<genexpr>)\n",
       "      490    0.001    0.000    0.008    0.000 utils.py:6(parse)\n",
       "      191    0.001    0.000    0.002    0.000 JpegImagePlugin.py:626(<listcomp>)\n",
       "     1224    0.001    0.000    0.001    0.000 {built-in method torch._C.set_grad_enabled}\n",
       "      384    0.001    0.000    0.001    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "      492    0.001    0.000    0.019    0.000 train_misc.py:86(<genexpr>)\n",
       "      335    0.001    0.000    0.001    0.000 pyparsing.py:1144(__init__)\n",
       "      191    0.001    0.000    0.002    0.000 utils.py:102(<listcomp>)\n",
       "      120    0.001    0.000    0.103    0.001 sre_parse.py:844(parse)\n",
       "      727    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:311(__enter__)\n",
       "        3    0.001    0.000    0.434    0.145 __init__.py:9(<module>)\n",
       "        2    0.001    0.001    0.002    0.001 __init__.py:1420(register_all)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:54(<lambda>)\n",
       "      214    0.001    0.000    0.004    0.000 record_writer.py:127(masked_crc32c)\n",
       "      836    0.001    0.000    0.001    0.000 inspect.py:159(isfunction)\n",
       "      471    0.001    0.000    0.010    0.000 pyparsing.py:1167(copy)\n",
       "      176    0.001    0.000    0.009    0.000 inspect.py:2846(__eq__)\n",
       "      159    0.001    0.000    0.005    0.000 __init__.py:2746(insert_on)\n",
       "        1    0.001    0.001    0.001    0.001 encoder.py:65(<module>)\n",
       "        1    0.001    0.001    0.077    0.077 ultratb.py:820(format_records)\n",
       "      267    0.001    0.000    0.003    0.000 enum.py:797(__or__)\n",
       "      191    0.001    0.000    0.016    0.000 Image.py:1083(copy)\n",
       "       28    0.001    0.000    0.009    0.000 batchnorm.py:19(__init__)\n",
       "     1499    0.001    0.000    0.001    0.000 {built-in method _sre.getlower}\n",
       "      751    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap>:780(find_spec)\n",
       "      100    0.001    0.000    0.022    0.000 init.py:261(kaiming_uniform_)\n",
       "      382    0.001    0.000    0.001    0.000 {built-in method builtins.round}\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method torch._C._c10d_init}\n",
       "      159    0.001    0.000    0.054    0.000 __init__.py:2193(fixup_namespace_packages)\n",
       "       19    0.001    0.000    0.040    0.002 ultratb.py:379(_format_traceback_lines)\n",
       "      316    0.001    0.000    0.004    0.000 genericpath.py:39(isdir)\n",
       "       95    0.001    0.000    0.002    0.000 functools.py:44(update_wrapper)\n",
       "        3    0.001    0.000    0.003    0.001 six.py:1(<module>)\n",
       "        1    0.001    0.001    0.929    0.929 writer.py:246(__init__)\n",
       "       19    0.001    0.000    0.002    0.000 traitlets.py:1421(<listcomp>)\n",
       "       72    0.001    0.000    0.001    0.000 {built-in method tensor}\n",
       "      762    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:143(__init__)\n",
       "       15    0.001    0.000    0.003    0.000 enum.py:124(__new__)\n",
       "     1334    0.001    0.000    0.001    0.000 {method 'read' of '_io.StringIO' objects}\n",
       "      352    0.001    0.000    0.001    0.000 inspect.py:2836(<dictcomp>)\n",
       "     1526    0.001    0.000    0.001    0.000 _structures.py:33(__neg__)\n",
       "      732    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}\n",
       "      374    0.001    0.000    0.001    0.000 sre_parse.py:342(_escape)\n",
       "      330    0.001    0.000    0.003    0.000 warnings.py:143(simplefilter)\n",
       "      324    0.001    0.000    0.001    0.000 warnings.py:449(__enter__)\n",
       "     1488    0.001    0.000    0.001    0.000 inspect.py:2512(kind)\n",
       "      751    0.001    0.000    0.001    0.000 {built-in method _imp.is_frozen}\n",
       "       72    0.001    0.000    0.001    0.000 functools.py:74(wraps)\n",
       "     1266    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:41(_relax_case)\n",
       "        1    0.001    0.001    0.005    0.005 caffe2_pb2.py:4(<module>)\n",
       "       18    0.001    0.000    0.012    0.001 __init__.py:357(namedtuple)\n",
       "     1282    0.001    0.000    0.001    0.000 {method 'span' of '_sre.SRE_Match' objects}\n",
       "      133    0.001    0.000    0.003    0.000 pyparsing.py:3260(__init__)\n",
       "     1334    0.001    0.000    0.001    0.000 {method 'seek' of '_io.StringIO' objects}\n",
       "      324    0.001    0.000    0.003    0.000 re.py:184(sub)\n",
       "       24    0.001    0.000    0.185    0.008 __init__.py:609(add_entry)\n",
       "      724    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
       "       98    0.001    0.000    0.018    0.000 <frozen importlib._bootstrap_external>:1281(_fill_cache)\n",
       "       68    0.001    0.000    0.001    0.000 {built-in method posix.lstat}\n",
       "       14    0.001    0.000    0.053    0.004 odefunc.py:99(__init__)\n",
       "      159    0.001    0.000    0.071    0.000 __init__.py:2652(activate)\n",
       "      350    0.001    0.000    0.001    0.000 _weakrefset.py:26(__exit__)\n",
       "      700    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:800(__init__)\n",
       "      471    0.001    0.000    0.001    0.000 {method '__reduce_ex__' of 'object' objects}\n",
       "      727    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:307(__init__)\n",
       "      656    0.001    0.000    0.001    0.000 sre_parse.py:81(groups)\n",
       "      227    0.001    0.000    0.001    0.000 sre_parse.py:294(_class_escape)\n",
       "       64    0.001    0.000    0.005    0.000 argparse.py:1307(add_argument)\n",
       "      324    0.001    0.000    0.001    0.000 warnings.py:468(__exit__)\n",
       "      132    0.001    0.000    0.029    0.000 __init__.py:2451(_version_from_file)\n",
       "    98/50    0.001    0.000    0.001    0.000 typing.py:1164(__setattr__)\n",
       "       98    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:1196(__init__)\n",
       "      267    0.001    0.000    0.007    0.000 __init__.py:1404(has_metadata)\n",
       "      382    0.001    0.000    0.001    0.000 _util.py:10(isPath)\n",
       "       98    0.001    0.000    0.055    0.001 conv.py:307(__init__)\n",
       "      311    0.001    0.000    0.001    0.000 {method 'decode' of 'bytes' objects}\n",
       "      355    0.001    0.000    0.001    0.000 {method 'remove' of 'list' objects}\n",
       "      107    0.001    0.000    9.440    0.088 writer.py:162(__init__)\n",
       "      396    0.001    0.000    0.001    0.000 __init__.py:2456(is_version_line)\n",
       "      161    0.001    0.000    0.011    0.000 abc.py:151(register)\n",
       "      202    0.001    0.000    0.001    0.000 sre_parse.py:84(opengroup)\n",
       "      372    0.001    0.000    0.001    0.000 inspect.py:2559(__eq__)\n",
       "      191    0.001    0.000    0.001    0.000 {built-in method PIL._imaging.zip_encoder}\n",
       "       14    0.001    0.000    0.035    0.003 gate.py:49(__init__)\n",
       "      121    0.001    0.000    0.006    0.000 __init__.py:1407(get_metadata)\n",
       "      191    0.001    0.000    0.001    0.000 {built-in method math.ceil}\n",
       "      722    0.001    0.000    0.001    0.000 {method 'setdefault' of 'dict' objects}\n",
       "      408    0.001    0.000    0.091    0.000 traceback.py:283(line)\n",
       "       38    0.001    0.000    0.020    0.001 traitlets.py:1142(notify_change)\n",
       "     1024    0.001    0.000    0.001    0.000 version.py:352(<lambda>)\n",
       "       86    0.001    0.000    0.001    0.000 _oid.py:11(__init__)\n",
       "       14    0.001    0.000    0.044    0.003 cnf_gate.py:21(__init__)\n",
       "      211    0.001    0.000    0.090    0.000 linecache.py:15(getline)\n",
       "      100    0.001    0.000    0.001    0.000 init.py:8(calculate_gain)\n",
       "      471    0.001    0.000    0.001    0.000 copyreg.py:87(__newobj__)\n",
       "      107    0.001    0.000    0.048    0.000 event_file_writer.py:54(write_event)\n",
       "      726    0.001    0.000    0.001    0.000 {method 'pop' of 'dict' objects}\n",
       "      107    0.001    0.000    0.005    0.000 event_file_writer.py:159(__init__)\n",
       "      380    0.001    0.000    0.001    0.000 train_misc.py:17(_set)\n",
       "      320    0.001    0.000    0.003    0.000 __init__.py:1315(safe_name)\n",
       "      751    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:707(find_spec)\n",
       "       57    0.001    0.000    0.001    0.000 traitlets.py:486(_dynamic_default_callable)\n",
       "       84    0.001    0.000    0.001    0.000 abc.py:135(<setcomp>)\n",
       "      323    0.001    0.000    0.046    0.000 <frozen importlib._bootstrap_external>:1216(find_loader)\n",
       "     1172    0.001    0.000    0.001    0.000 __init__.py:1997(__bool__)\n",
       "      386    0.001    0.000    0.010    0.000 <frozen importlib._bootstrap_external>:99(_path_isdir)\n",
       "       64    0.001    0.000    0.001    0.000 argparse.py:157(__init__)\n",
       "      350    0.001    0.000    0.001    0.000 _weakrefset.py:20(__enter__)\n",
       "     1129    0.001    0.000    0.001    0.000 {built-in method builtins.callable}\n",
       "      214    0.001    0.000    0.002    0.000 crc32c.py:114(crc32c)\n",
       "      107    0.001    0.000    0.407    0.004 record_writer.py:105(__init__)\n",
       "      384    0.001    0.000    0.001    0.000 scatter_gather.py:20(<listcomp>)\n",
       "      518    0.001    0.000    0.001    0.000 module.py:538(remove_from)\n",
       "      374    0.001    0.000    0.001    0.000 descriptor.py:524(__new__)\n",
       "      132    0.001    0.000    0.030    0.000 __init__.py:2858(_reload_version)\n",
       "       82    0.001    0.000    0.001    0.000 pyparsing.py:3719(__init__)\n",
       "      352    0.001    0.000    0.022    0.000 inspect.py:2803(from_callable)\n",
       "      214    0.001    0.000    0.001    0.000 {built-in method _codecs.utf_8_decode}\n",
       "      630    0.001    0.000    0.001    0.000 sre_parse.py:167(__setitem__)\n",
       "        2    0.001    0.000    0.001    0.001 traceback.py:386(format)\n",
       "       36    0.001    0.000    0.322    0.009 tokenize.py:448(open)\n",
       "      247    0.001    0.000    0.001    0.000 {built-in method _make_subclass}\n",
       "       98    0.001    0.000    0.009    0.000 <frozen importlib._bootstrap_external>:1322(path_hook_for_FileFinder)\n",
       "      816    0.001    0.000    0.001    0.000 module.py:1012(_get_name)\n",
       "      984    0.001    0.000    0.001    0.000 {built-in method _warnings._filters_mutated}\n",
       "      253    0.001    0.000    0.342    0.001 linecache.py:37(getlines)\n",
       "      120    0.001    0.000    0.092    0.001 sre_compile.py:542(_code)\n",
       "      352    0.001    0.000    0.023    0.000 inspect.py:3055(signature)\n",
       "      120    0.001    0.000    0.001    0.000 sre_parse.py:223(__init__)\n",
       "       90    0.001    0.000    0.001    0.000 sre_compile.py:378(<listcomp>)\n",
       "      784    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:1202(<genexpr>)\n",
       "      267    0.001    0.000    0.003    0.000 __init__.py:1509(_has)\n",
       "      149    0.001    0.000    0.042    0.000 utils.py:38(register_decorator)\n",
       "      357    0.001    0.000    2.502    0.007 module.py:260(<lambda>)\n",
       "      118    0.000    0.000    0.001    0.000 enum.py:70(__setitem__)\n",
       "       15    0.000    0.000    0.001    0.000 enum.py:160(<setcomp>)\n",
       "      214    0.000    0.000    0.001    0.000 codecs.py:318(decode)\n",
       "      931    0.000    0.000    0.000    0.000 {function Config.__contains__ at 0x7ff727ab4620}\n",
       "       90    0.000    0.000    0.001    0.000 sre_compile.py:376(_mk_bitmap)\n",
       "      247    0.000    0.000    0.001    0.000 parameter.py:23(__new__)\n",
       "       21    0.000    0.000    0.265    0.013 ultratb.py:157(findsource)\n",
       "        4    0.000    0.000    1.838    0.459 cifar.py:134(_check_integrity)\n",
       "      178    0.000    0.000    0.001    0.000 _jit_internal.py:34(createResolutionCallback)\n",
       "      840    0.000    0.000    0.000    0.000 {built-in method builtins.chr}\n",
       "   219/58    0.000    0.000    0.006    0.000 typing.py:1145(__subclasscheck__)\n",
       "    102/2    0.000    0.000    0.002    0.001 pyparsing.py:1370(_parseNoCache)\n",
       "      704    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
       "       27    0.000    0.000    0.001    0.000 {built-in method _imp.exec_dynamic}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.SSL_library_init}\n",
       "      768    0.000    0.000    0.000    0.000 version.py:332(_parse_local_version)\n",
       "      495    0.000    0.000    0.000    0.000 {built-in method torch._C._add_docstr}\n",
       "      382    0.000    0.000    0.020    0.000 Image.py:370(preinit)\n",
       "       56    0.000    0.000    0.046    0.001 basic.py:152(__init__)\n",
       "      191    0.000    0.000    0.001    0.000 __init__.py:119(is_tensor)\n",
       "       60    0.000    0.000    0.003    0.000 six.py:837(wrapper)\n",
       "      286    0.000    0.000    0.001    0.000 _tensor_docs.py:8(add_docstr_all)\n",
       "      100    0.000    0.000    0.002    0.000 init.py:50(uniform_)\n",
       "      382    0.000    0.000    0.000    0.000 ImageFile.py:65(_tilesort)\n",
       "      727    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:424(has_location)\n",
       "      191    0.000    0.000    0.000    0.000 PngImagePlugin.py:681(__init__)\n",
       "      352    0.000    0.000    0.001    0.000 inspect.py:505(_is_wrapper)\n",
       "       64    0.000    0.000    0.001    0.000 argparse.py:1444(_get_optional_kwargs)\n",
       "      136    0.000    0.000    0.001    0.000 os.py:664(__getitem__)\n",
       "        1    0.000    0.000    0.037    0.037 auto.py:268(_generate_function_classes)\n",
       "      698    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:825(get_filename)\n",
       "      374    0.000    0.000    0.000    0.000 {method 'FindFieldByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       84    0.000    0.000    0.002    0.000 pyparsing.py:3390(__init__)\n",
       "       39    0.000    0.000    0.001    0.000 _inspect.py:142(formatargspec)\n",
       "        9    0.000    0.000    0.001    0.000 auto.py:14(_make_function_class_criterion)\n",
       "       91    0.000    0.000    0.001    0.000 _jit_internal.py:105(weak_script_method)\n",
       "       57    0.000    0.000    0.002    0.000 traitlets.py:516(instance_init)\n",
       "      112    0.000    0.000    0.001    0.000 module.py:87(register_buffer)\n",
       "      698    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:669(create_module)\n",
       "      324    0.000    0.000    0.000    0.000 warnings.py:428(__init__)\n",
       "      160    0.000    0.000    0.071    0.000 __init__.py:3153(<genexpr>)\n",
       "      744    0.000    0.000    0.000    0.000 inspect.py:2500(name)\n",
       "      350    0.000    0.000    0.001    0.000 pkgutil.py:402(get_importer)\n",
       "      754    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
       "      192    0.000    0.000    0.002    0.000 sampler.py:168(__len__)\n",
       "      107    0.000    0.000    0.047    0.000 event_file_writer.py:63(_write_serialized_event)\n",
       "      428    0.000    0.000    0.000    0.000 {method 'write' of '_io.BufferedWriter' objects}\n",
       "        1    0.000    0.000    0.846    0.846 _import_c_extension.py:3(<module>)\n",
       "      304    0.000    0.000    0.000    0.000 __init__.py:1837(__init__)\n",
       "      642    0.000    0.000    0.000    0.000 record_writer.py:132(u32)\n",
       "      142    0.000    0.000    0.001    0.000 os.py:742(encode)\n",
       "       33    0.000    0.000    0.001    0.000 posixpath.py:331(normpath)\n",
       "      191    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedRandom' objects}\n",
       "      382    0.000    0.000    0.000    0.000 {method 'cleanup' of 'ImagingEncoder' objects}\n",
       "      100    0.000    0.000    0.003    0.000 init.py:251(_calculate_correct_fan)\n",
       "      704    0.000    0.000    0.000    0.000 inspect.py:2809(parameters)\n",
       "       19    0.000    0.000    0.006    0.000 traitlets.py:1407(traits)\n",
       "      120    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
       "      120    0.000    0.000    0.001    0.000 module.py:161(add_module)\n",
       "        1    0.000    0.000    0.004    0.004 core.py:21(<module>)\n",
       "      103    0.000    0.000    0.001    0.000 TiffTags.py:26(__new__)\n",
       "      178    0.000    0.000    0.001    0.000 inspect.py:1493(currentframe)\n",
       "      240    0.000    0.000    0.000    0.000 sre_compile.py:539(isstring)\n",
       "   131/65    0.000    0.000    0.008    0.000 pyparsing.py:3363(copy)\n",
       "      136    0.000    0.000    0.000    0.000 enum.py:353(__setattr__)\n",
       "      120    0.000    0.000    0.001    0.000 sre_parse.py:828(fix_flags)\n",
       "      551    0.000    0.000    0.000    0.000 {method '__contains__' of 'frozenset' objects}\n",
       "        1    0.000    0.000    0.001    0.001 optimizer.py:174(add_param_group)\n",
       "      190    0.000    0.000    0.003    0.000 configurable.py:99(section_names)\n",
       "       42    0.000    0.000    0.027    0.001 inspect.py:680(getsourcefile)\n",
       "        1    0.000    0.000    0.045    0.045 pyparsing.py:75(<module>)\n",
       "      322    0.000    0.000    0.001    0.000 traitlets.py:545(__get__)\n",
       "      409    0.000    0.000    0.000    0.000 utils.py:47(__init__)\n",
       "        4    0.000    0.000    0.001    0.000 numeric.py:2916(extend_all)\n",
       "       92    0.000    0.000    0.009    0.000 compilerop.py:137(check_linecache_ipython)\n",
       "      191    0.000    0.000    0.000    0.000 linecache.py:147(lazycache)\n",
       "   131/65    0.000    0.000    0.007    0.000 pyparsing.py:3365(<listcomp>)\n",
       "      107    0.000    0.000    0.000    0.000 {built-in method _socket.gethostname}\n",
       "        1    0.000    0.000    0.005    0.005 summary_pb2.py:4(<module>)\n",
       "      202    0.000    0.000    0.007    0.000 sre_parse.py:96(closegroup)\n",
       "      586    0.000    0.000    0.000    0.000 {built-in method _CheckCalledFromGeneratedFile}\n",
       "      350    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)\n",
       "       42    0.000    0.000    0.001    0.000 inspect.py:643(getfile)\n",
       "      296    0.000    0.000    0.000    0.000 weakref.py:406(__setitem__)\n",
       "      154    0.000    0.000    0.000    0.000 argparse.py:1282(_registry_get)\n",
       "       21    0.000    0.000    0.283    0.013 inspect.py:1430(getframeinfo)\n",
       "       57    0.000    0.000    0.001    0.000 sre_parse.py:266(getuntil)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:104(_init)\n",
       "        1    0.000    0.000    0.002    0.002 numerictypes.py:81(<module>)\n",
       "      350    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)\n",
       "       53    0.000    0.000    0.001    0.000 core.py:893(__init__)\n",
       "        1    0.000    0.000 73078.964 73078.964 py3compat.py:184(execfile)\n",
       "       92    0.000    0.000    0.009    0.000 linecache.py:53(checkcache)\n",
       "       69    0.000    0.000    0.001    0.000 pyparsing.py:2412(__init__)\n",
       "      266    0.000    0.000    0.000    0.000 pyparsing.py:3270(<genexpr>)\n",
       "    61/11    0.000    0.000    0.008    0.001 pyparsing.py:3288(leaveWhitespace)\n",
       "       36    0.000    0.000    0.303    0.008 tokenize.py:355(detect_encoding)\n",
       "        2    0.000    0.000    0.019    0.010 {built-in method builtins.sum}\n",
       "       33    0.000    0.000    0.002    0.000 container.py:187(extend)\n",
       "       83    0.000    0.000    0.003    0.000 pyparsing.py:1821(__add__)\n",
       "      166    0.000    0.000    0.000    0.000 six.py:141(__init__)\n",
       "      380    0.000    0.000    0.000    0.000 {method '__subclasses__' of 'type' objects}\n",
       "      352    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
       "      282    0.000    0.000    0.000    0.000 {method 'zfill' of 'str' objects}\n",
       "    32/31    0.000    0.000    0.002    0.000 typing.py:875(__extrahook__)\n",
       "        1    0.000    0.000    0.001    0.001 step_stats_pb2.py:4(<module>)\n",
       "      192    0.000    0.000    0.001    0.000 sampler.py:75(__len__)\n",
       "       19    0.000    0.000    0.021    0.001 configurable.py:38(__init__)\n",
       "   117/99    0.000    0.000    0.000    0.000 sre_compile.py:414(_get_literal_prefix)\n",
       "        1    0.000    0.000    0.451    0.451 event_pb2.py:4(<module>)\n",
       "       28    0.000    0.000    0.002    0.000 batchnorm.py:49(reset_parameters)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.SSL_load_error_strings}\n",
       "        1    0.000    0.000    0.004    0.004 kl.py:1(<module>)\n",
       "        1    0.000    0.000    0.422    0.422 __init__.py:16(<module>)\n",
       "       30    0.000    0.000    0.002    0.000 contextlib.py:129(contextmanager)\n",
       "      192    0.000    0.000    0.003    0.000 dataloader.py:821(__len__)\n",
       "        1    0.000    0.000    0.001    0.001 inspect.py:317(getmembers)\n",
       "      198    0.000    0.000    0.000    0.000 traceback.py:290(walk_stack)\n",
       "        1    0.000    0.000    0.000    0.000 layout_pb2.py:4(<module>)\n",
       "      120    0.000    0.000    0.001    0.000 pyparsing.py:2368(__init__)\n",
       "      121    0.000    0.000    0.007    0.000 __init__.py:1413(get_metadata_lines)\n",
       "        1    0.000    0.000 73079.415 73079.415 interactiveshell.py:2637(safe_execfile)\n",
       "       64    0.000    0.000    0.000    0.000 argparse.py:1364(_add_action)\n",
       "      148    0.000    0.000    0.001    0.000 _oid.py:58(__hash__)\n",
       "       87    0.000    0.000    0.001    0.000 _jit_internal.py:83(weak_script)\n",
       "       97    0.000    0.000    0.001    0.000 contextlib.py:85(__exit__)\n",
       "      352    0.000    0.000    0.000    0.000 inspect.py:2813(return_annotation)\n",
       "       14    0.000    0.000    0.002    0.000 posixpath.py:393(_joinrealpath)\n",
       "       12    0.000    0.000    0.007    0.001 pyparsing.py:2653(__init__)\n",
       "      160    0.000    0.000    0.000    0.000 __init__.py:666(__iter__)\n",
       "        3    0.000    0.000    0.168    0.056 functional.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 token.py:3(<module>)\n",
       "       97    0.000    0.000    0.000    0.000 contextlib.py:59(__init__)\n",
       "       22    0.000    0.000    0.001    0.000 posixpath.py:232(expanduser)\n",
       "        1    0.000    0.000    0.001    0.001 TiffTags.py:349(_populate)\n",
       "        1    0.000    0.000    0.058    0.058 backend.py:5(<module>)\n",
       "       64    0.000    0.000    0.001    0.000 argparse.py:580(_format_args)\n",
       "       95    0.000    0.000    0.000    0.000 loader.py:161(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 getlimits.py:3(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:118(__repr__)\n",
       "      329    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "       48    0.000    0.000    0.019    0.000 genericpath.py:27(isfile)\n",
       "       28    0.000    0.000    0.017    0.001 traceback.py:200(extract_stack)\n",
       "      107    0.000    0.000    0.000    0.000 queue.py:199(_init)\n",
       "       76    0.000    0.000    0.000    0.000 traitlets.py:1067(hold_trait_notifications)\n",
       "        1    0.000    0.000    0.001    0.001 attr_value_pb2.py:4(<module>)\n",
       "       28    0.000    0.000    0.001    0.000 batchnorm.py:43(reset_running_stats)\n",
       "      315    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
       "       28    0.000    0.000    0.000    0.000 {built-in method ones}\n",
       "       64    0.000    0.000    0.001    0.000 argparse.py:1555(_add_action)\n",
       "      249    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "      107    0.000    0.000    0.000    0.000 writer.py:53(__init__)\n",
       "       15    0.000    0.000    0.000    0.000 {built-in method builtins.eval}\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1775(_parse_known_args)\n",
       "        1    0.000    0.000    0.001    0.001 _tensor_docs.py:1(<module>)\n",
       "       26    0.000    0.000    0.048    0.002 pyparsing.py:2779(__init__)\n",
       "      107    0.000    0.000    0.000    0.000 threading.py:1136(daemon)\n",
       "      191    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
       "       86    0.000    0.000    0.000    0.000 six.py:105(__init__)\n",
       "       38    0.000    0.000    0.020    0.001 traitlets.py:558(set)\n",
       "      208    0.000    0.000    0.000    0.000 traitlets.py:526(get)\n",
       "        1    0.000    0.000    0.049    0.049 extensions.py:5(<module>)\n",
       "      120    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
       "      357    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
       "      264    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
       "      364    0.000    0.000    0.000    0.000 module.py:1015(extra_repr)\n",
       "     10/2    0.000    0.000    0.002    0.001 pyparsing.py:3397(parseImpl)\n",
       "        1    0.000    0.000    0.103    0.103 __init__.py:106(<module>)\n",
       "      166    0.000    0.000    0.000    0.000 {method 'mro' of 'type' objects}\n",
       "        1    0.000    0.000    0.061    0.061 add_newdocs.py:10(<module>)\n",
       "       25    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.022    0.022 pyparsing.py:5399(pyparsing_common)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1796(get_metadata)\n",
       "      111    0.000    0.000    0.000    0.000 _jit_internal.py:98(weak_module)\n",
       "        2    0.000    0.000    0.293    0.146 __init__.py:41(<module>)\n",
       "       59    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:861(_find_spec_legacy)\n",
       "        2    0.000    0.000    0.006    0.003 ec.py:5(<module>)\n",
       "      191    0.000    0.000    0.000    0.000 traceback.py:243(__init__)\n",
       "      164    0.000    0.000    0.000    0.000 abc.py:9(abstractmethod)\n",
       "       14    0.000    0.000    0.055    0.004 odenvp_conditional_rl.py:209(_make_odefunc)\n",
       "      113    0.000    0.000    0.000    0.000 descriptor.py:690(__new__)\n",
       "       57    0.000    0.000    0.001    0.000 traitlets.py:587(_validate)\n",
       "      191    0.000    0.000    0.000    0.000 JpegImagePlugin.py:665(validate_qtables)\n",
       "       27    0.000    0.000    0.004    0.000 pyparsing.py:1039(_trim_arity)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:358(__getattr__)\n",
       "       18    0.000    0.000    0.000    0.000 inspect.py:1251(formatargvalues)\n",
       "       97    0.000    0.000    0.000    0.000 contextlib.py:157(helper)\n",
       "        1    0.000    0.000    0.007    0.007 subprocess.py:1208(_execute_child)\n",
       "       52    0.000    0.000    0.000    0.000 posixpath.py:64(isabs)\n",
       "       48    0.000    0.000    0.001    0.000 pyparsing.py:1948(__or__)\n",
       "       64    0.000    0.000    0.000    0.000 argparse.py:1480(_pop_action_class)\n",
       "        1    0.000    0.000    0.004    0.004 numeric.py:1(<module>)\n",
       "      105    0.000    0.000    0.000    0.000 inspect.py:239(isframe)\n",
       "      118    0.000    0.000    0.000    0.000 enum.py:28(_is_dunder)\n",
       "       14    0.000    0.000    0.002    0.000 odefunc_rl.py:257(__init__)\n",
       "      180    0.000    0.000    0.000    0.000 {method 'readline' of '_io.StringIO' objects}\n",
       "        4    0.000    0.000    0.101    0.025 odenvp_conditional_rl.py:194(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 _torch_docs.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 markers.py:4(<module>)\n",
       "        1    0.000    0.000    0.022    0.022 __init__.py:72(<module>)\n",
       "       41    0.000    0.000    0.000    0.000 tokenize.py:385(find_cookie)\n",
       "    27/24    0.000    0.000    0.218    0.009 <frozen importlib._bootstrap_external>:919(create_module)\n",
       "     19/4    0.000    0.000    0.001    0.000 pyparsing.py:3319(streamline)\n",
       "        1    0.000    0.000    0.256    0.256 __init__.py:3126(_initialize_master_working_set)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:36(IgnoreLinear)\n",
       "       73    0.000    0.000    0.000    0.000 sre_compile.py:441(_get_charset_prefix)\n",
       "      127    0.000    0.000    0.000    0.000 typing.py:1019(_abc_negative_cache)\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:2826(__str__)\n",
       "       30    0.000    0.000    0.004    0.000 activation.py:41(__init__)\n",
       "    82/80    0.000    0.000    0.000    0.000 pyparsing.py:372(__init__)\n",
       "        2    0.000    0.000    0.042    0.021 __init__.py:147(_lazy_init)\n",
       "      277    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.add_docstring}\n",
       "      191    0.000    0.000    0.000    0.000 {method 'flush' of '_io.BytesIO' objects}\n",
       "       13    0.000    0.000    0.001    0.000 __init__.py:1161(getLogger)\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:68(RegisterMessage)\n",
       "      214    0.000    0.000    0.000    0.000 crc32c.py:100(crc_finalize)\n",
       "        1    0.000    0.000    0.088    0.088 requirements.py:4(<module>)\n",
       "      252    0.000    0.000    0.000    0.000 six.py:88(__init__)\n",
       "      148    0.000    0.000    0.000    0.000 utils.py:34(<lambda>)\n",
       "       64    0.000    0.000    0.002    0.000 argparse.py:2352(_get_formatter)\n",
       "        1    0.000    0.000    0.009    0.009 TiffImagePlugin.py:42(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 traitlets.py:988(__init__)\n",
       "        1    0.000    0.000    0.911    0.911 workspace.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._autograd_init}\n",
       "      159    0.000    0.000    0.000    0.000 __init__.py:919(_added_new)\n",
       "        3    0.000    0.000    0.048    0.016 _util.py:1(<module>)\n",
       "        1    0.000    0.000    0.020    0.020 __init__.py:184(<module>)\n",
       "       48    0.000    0.000    0.001    0.000 pyparsing.py:3540(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:120(<listcomp>)\n",
       "        1    0.000    0.000    0.013    0.013 utils.py:13(get_logger)\n",
       "       82    0.000    0.000    0.000    0.000 pyparsing.py:363(__new__)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:204(iterencode)\n",
       "       82    0.000    0.000    0.000    0.000 descriptor.py:281(__new__)\n",
       "      168    0.000    0.000    0.000    0.000 inspect.py:690(<genexpr>)\n",
       "        6    0.000    0.000    0.000    0.000 getlimits.py:65(__init__)\n",
       "      126    0.000    0.000    0.000    0.000 inspect.py:687(<genexpr>)\n",
       "       90    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
       "       25    0.000    0.000    0.004    0.000 pyparsing.py:1250(setParseAction)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:930(__init__)\n",
       "       57    0.000    0.000    0.000    0.000 codecs.py:308(__init__)\n",
       "        2    0.000    0.000    0.068    0.034 base.py:5(<module>)\n",
       "       68    0.000    0.000    0.001    0.000 posixpath.py:168(islink)\n",
       "       19    0.000    0.000    0.000    0.000 data.py:23(<listcomp>)\n",
       "       67    0.000    0.000    0.000    0.000 auto.py:95(_find_buffers)\n",
       "        1    0.000    0.000    0.031    0.031 tokenize.py:26(<module>)\n",
       "        1    0.000    0.000    0.008    0.008 optimizer.py:32(__init__)\n",
       "       26    0.000    0.000    0.004    0.000 pyparsing.py:1047(extract_stack)\n",
       "        1    0.000    0.000    0.007    0.007 __init__.py:57(<module>)\n",
       "      118    0.000    0.000    0.000    0.000 enum.py:36(_is_sunder)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:464(_find_new_)\n",
       "        1    0.000    0.000    0.283    0.283 inspect.py:1481(getinnerframes)\n",
       "      115    0.000    0.000    0.000    0.000 py3compat.py:28(cast_unicode)\n",
       "      109    0.000    0.000    0.000    0.000 __init__.py:420(<genexpr>)\n",
       "       51    0.000    0.000    0.000    0.000 _internal.py:715(_ufunc_doc_signature_formatter)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2923(<listcomp>)\n",
       "       19    0.000    0.000    0.012    0.001 configurable.py:131(_load_config)\n",
       "      149    0.000    0.000    0.000    0.000 utils.py:37(register_interface)\n",
       "       97    0.000    0.000    0.000    0.000 contextlib.py:79(__enter__)\n",
       "      109    0.000    0.000    0.000    0.000 __init__.py:422(<genexpr>)\n",
       "       60    0.000    0.000    0.000    0.000 enum.py:20(_is_descriptor)\n",
       "       11    0.000    0.000    0.131    0.012 __init__.py:5(<module>)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:67(getargs)\n",
       "      172    0.000    0.000    0.000    0.000 {method 'ndimension' of 'torch._C._TensorBase' objects}\n",
       "      100    0.000    0.000    0.000    0.000 six.py:177(_add_module)\n",
       "        1    0.000    0.000    0.012    0.012 _big_num_ctypes.py:20(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 types_pb2.py:4(<module>)\n",
       "       88    0.000    0.000    0.000    0.000 typing.py:1033(_abc_negative_cache_version)\n",
       "       19    0.000    0.000    0.000    0.000 ultratb.py:968(<listcomp>)\n",
       "       31    0.000    0.000    0.000    0.000 enum.py:419(_get_mixins_)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:98(getargspec)\n",
       "        1    0.000    0.000    0.115    0.115 crypto.py:1(<module>)\n",
       "       33    0.000    0.000    0.005    0.000 container.py:119(__init__)\n",
       "       63    0.000    0.000    0.000    0.000 argparse.py:835(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 inspect.py:1180(getargvalues)\n",
       "       84    0.000    0.000    0.000    0.000 activation.py:617(extra_repr)\n",
       "      101    0.000    0.000    0.000    0.000 _inspect.py:133(strseq)\n",
       "       95    0.000    0.000    0.000    0.000 bunch.py:11(__getattr__)\n",
       "      195    0.000    0.000    0.000    0.000 pyparsing.py:3392(<genexpr>)\n",
       "       95    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
       "       35    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "        1    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:4(<module>)\n",
       "      128    0.000    0.000    0.000    0.000 typing.py:1089(__eq__)\n",
       "       64    0.000    0.000    0.000    0.000 argparse.py:564(_metavar_formatter)\n",
       "       97    0.000    0.000    0.000    0.000 pyparsing.py:4781(<genexpr>)\n",
       "      188    0.000    0.000    0.000    0.000 pyparsing.py:2656(<genexpr>)\n",
       "        1    0.000    0.000    0.061    0.061 odeint.py:1(<module>)\n",
       "       19    0.000    0.000    0.018    0.001 configurable.py:170(_config_changed)\n",
       "        2    0.000    0.000    0.009    0.004 connection.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:1(<module>)\n",
       "      170    0.000    0.000    0.000    0.000 pyparsing.py:2061(setWhitespaceChars)\n",
       "      108    0.000    0.000    0.000    0.000 utils.py:33(read_only_property)\n",
       "        3    0.000    0.000    0.004    0.001 distributed.py:1(<module>)\n",
       "      189    0.000    0.000    0.000    0.000 status_codes.py:112(<genexpr>)\n",
       "        3    0.000    0.000    0.129    0.043 __init__.py:6(<module>)\n",
       "       28    0.000    0.000    0.010    0.000 gate.py:115(conv3x3)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:857(<listcomp>)\n",
       "        1    0.000    0.000    0.003    0.003 lapack.py:461(<module>)\n",
       "       30    0.000    0.000    0.004    0.000 activation.py:81(__init__)\n",
       "        1    0.000    0.000    0.103    0.103 odenvp_conditional_rl.py:21(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:237(SummaryWriter)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:38(register_kl)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:299(_add_aliases)\n",
       "        2    0.000    0.000    0.000    0.000 traceback.py:367(from_list)\n",
       "       61    0.000    0.000    0.006    0.000 pyparsing.py:3292(<listcomp>)\n",
       "       28    0.000    0.000    0.000    0.000 init.py:113(zeros_)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2710(MaskedArray)\n",
       "       19    0.000    0.000    0.021    0.001 PyColorize.py:180(__init__)\n",
       "       64    0.000    0.000    0.001    0.000 argparse.py:1713(_add_action)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:5(<module>)\n",
       "       14    0.000    0.000    0.002    0.000 pooling.py:14(__init__)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:114(__prepare__)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:50(__init__)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3037(_find_adapter)\n",
       "        1    0.000    0.000    0.002    0.002 core.py:47(<module>)\n",
       "        1    0.000    0.000    0.182    0.182 pyopenssl.py:43(<module>)\n",
       "        1    0.000    0.000    0.102    0.102 odenvp_conditional_rl.py:65(_build_net)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:69(decorator)\n",
       "       19    0.000    0.000    0.007    0.000 traitlets.py:950(__new__)\n",
       "      191    0.000    0.000    0.000    0.000 {method 'close' of '_io.BytesIO' objects}\n",
       "       68    0.000    0.000    0.000    0.000 status_codes.py:111(doc)\n",
       "       64    0.000    0.000    0.000    0.000 argparse.py:573(format)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:37(<listcomp>)\n",
       "      8/6    0.000    0.000    0.006    0.001 __init__.py:2159(declare_namespace)\n",
       "      188    0.000    0.000    0.000    0.000 __init__.py:2498(_reload_version)\n",
       "        1    0.000    0.000    0.004    0.004 oid.py:5(<module>)\n",
       "       84    0.000    0.000    0.000    0.000 inspect.py:229(istraceback)\n",
       "       82    0.000    0.000    0.000    0.000 inspect.py:253(iscode)\n",
       "       38    0.000    0.000    0.002    0.000 traitlets.py:1690(instance_init)\n",
       "        1    0.000    0.000    0.004    0.004 tensor_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.369    0.369 ultratb.py:343(_fixed_getinnerframes)\n",
       "       38    0.000    0.000    0.020    0.001 traitlets.py:1133(_notify_trait)\n",
       "        1    0.000    0.000    0.001    0.001 node_def_pb2.py:4(<module>)\n",
       "       45    0.000    0.000    0.000    0.000 pyparsing.py:1190(setName)\n",
       "        1    0.000    0.000    0.025    0.025 keys.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:1(<module>)\n",
       "       96    0.000    0.000    0.000    0.000 pyparsing.py:2153(__str__)\n",
       "       63    0.000    0.000    0.000    0.000 inspect.py:64(ismodule)\n",
       "       13    0.000    0.000    0.000    0.000 __init__.py:1212(_fixupParents)\n",
       "      178    0.000    0.000    0.000    0.000 {method '__subclasshook__' of 'object' objects}\n",
       "       20    0.000    0.000    0.000    0.000 pyparsing.py:2813(parseImpl)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:261(AuthorityInformationAccess)\n",
       "        1    0.000    0.000    0.001    0.001 arrayprint.py:5(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 types.py:135(__get__)\n",
       "      168    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
       "        1    0.000    0.000    0.045    0.045 utils.py:9(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 extras.py:10(<module>)\n",
       "       86    0.000    0.000    0.000    0.000 inspect.py:81(ismethod)\n",
       "    36/11    0.000    0.000    0.010    0.001 pyparsing.py:3743(leaveWhitespace)\n",
       "       14    0.000    0.000    0.003    0.000 __init__.py:2232(normalize_path)\n",
       "       41    0.000    0.000    0.302    0.007 tokenize.py:379(read_or_stop)\n",
       "       60    0.000    0.000    0.000    0.000 pyparsing.py:1351(preParse)\n",
       "        1    0.000    0.000    0.001    0.001 SSL.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:61(__new__)\n",
       "       19    0.000    0.000    0.000    0.000 inspect.py:1026(_getfullargs)\n",
       "        1    0.000    0.000    0.032    0.032 grammar.py:13(<module>)\n",
       "        2    0.000    0.000    0.009    0.004 ocsp.py:5(<module>)\n",
       "        8    0.000    0.000    0.002    0.000 utils.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.Cryptography_add_osrandom_engine}\n",
       "        2    0.000    0.000    0.001    0.001 function_base.py:1(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 numerictypes.py:229(bitname)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:409(_init)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1740(parse_known_args)\n",
       "      114    0.000    0.000    0.000    0.000 traitlets.py:1047(cross_validation_lock)\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:85(RegisterMessageDescriptor)\n",
       "       44    0.000    0.000    0.001    0.000 core.py:149(get_object_signature)\n",
       "       62    0.000    0.000    0.000    0.000 _inspect.py:146(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 shutil.py:1093(which)\n",
       "       26    0.000    0.000    0.000    0.000 sre_compile.py:393(_generate_overlap_table)\n",
       "       27    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:927(exec_module)\n",
       "        1    0.000    0.000    0.048    0.048 odefunc.py:1(<module>)\n",
       "       95    0.000    0.000    0.000    0.000 {method '__getitem__' of 'dict' objects}\n",
       "       82    0.000    0.000    0.000    0.000 {method 'FindMessageTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3954(_NullToken)\n",
       "       28    0.000    0.000    0.000    0.000 pyparsing.py:3997(__init__)\n",
       "       69    0.000    0.000    0.000    0.000 status_codes.py:117(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 pooling.py:1(<module>)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6573(getdoc)\n",
       "     26/1    0.000    0.000    0.001    0.001 jsonutil.py:109(json_clean)\n",
       "       64    0.000    0.000    0.000    0.000 argparse.py:793(__init__)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:1822(take_action)\n",
       "      114    0.000    0.000    0.000    0.000 tokenize.py:739(generate_tokens)\n",
       "        2    0.000    0.000    0.002    0.001 x25519.py:5(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 resource_handle_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:272(<setcomp>)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2234(_get_values)\n",
       "       38    0.000    0.000    0.001    0.000 pyparsing.py:4230(__init__)\n",
       "        1    0.000    0.000    0.010    0.010 Image.py:30(<module>)\n",
       "       23    0.000    0.000    0.000    0.000 numerictypes.py:216(_evalname)\n",
       "       19    0.000    0.000    0.000    0.000 inspect.py:1016(getargs)\n",
       "       82    0.000    0.000    0.000    0.000 backend.py:13(register_function)\n",
       "       21    0.000    0.000    0.001    0.000 argparse.py:1843(consume_optional)\n",
       "       13    0.000    0.000    0.000    0.000 __init__.py:1268(__init__)\n",
       "        1    0.000    0.000    0.004    0.004 pyparsing.py:4875(_makeTags)\n",
       "       95    0.000    0.000    0.000    0.000 loader.py:165(_ensure_subconfig)\n",
       "        2    0.000    0.000    0.009    0.004 rsa.py:5(<module>)\n",
       "       69    0.000    0.000    0.000    0.000 __init__.py:1265(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:47(CosineSimilarity)\n",
       "       56    0.000    0.000    0.000    0.000 batchnorm.py:78(extra_repr)\n",
       "       38    0.000    0.000    0.000    0.000 traitlets.py:596(_cross_validate)\n",
       "       36    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
       "       23    0.000    0.000    0.000    0.000 pyparsing.py:2742(__str__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _ctypes.dlopen}\n",
       "       97    0.000    0.000    0.000    0.000 {method 'expandtabs' of 'str' objects}\n",
       "        1    0.000    0.000    0.011    0.011 JpegImagePlugin.py:35(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _hashlib.openssl_md5}\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:466(find)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:285(_add_types)\n",
       "        1    0.000    0.000    0.003    0.003 _tqdm.py:9(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 zipfile.py:5(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 pyparsing.py:4565(_escapeRegexRangeChars)\n",
       "        1    0.000    0.000    0.004    0.004 adapters.py:9(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 modes.py:5(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 npyio.py:1(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 loader.py:182(merge)\n",
       "       95    0.000    0.000    0.000    0.000 traitlets.py:911(__get__)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:294(IFDRational)\n",
       "        1    0.000    0.000    0.022    0.022 cookiejar.py:26(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:86(<listcomp>)\n",
       "     20/8    0.000    0.000    0.001    0.000 pyparsing.py:3547(parseImpl)\n",
       "       30    0.000    0.000    0.000    0.000 sre_parse.py:257(getwhile)\n",
       "        1    0.000    0.000    0.003    0.003 models.py:8(<module>)\n",
       "       33    0.000    0.000    0.002    0.000 container.py:159(__iadd__)\n",
       "        1    0.000    0.000    0.001    0.001 odefunc_rl.py:1(<module>)\n",
       "       27    0.000    0.000    0.000    0.000 inspect.py:479(getmro)\n",
       "        2    0.000    0.000    0.000    0.000 pygram.py:22(__init__)\n",
       "        1    0.000    0.000    0.008    0.008 cookies.py:127(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:225(_register_default_ciphers)\n",
       "        1    0.000    0.000    0.015    0.015 connectionpool.py:1(<module>)\n",
       "        2    0.000    0.000    0.008    0.004 transforms.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:58(InstanceNorm1d)\n",
       "       38    0.000    0.000    0.000    0.000 traitlets.py:1694(_resolve_classes)\n",
       "       10    0.000    0.000    0.000    0.000 sre_compile.py:381(_bytes_to_codes)\n",
       "       19    0.000    0.000    0.001    0.000 posixpath.py:369(abspath)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:621(decorator)\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3581(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 distributed_c10d.py:1(<module>)\n",
       "      139    0.000    0.000    0.000    0.000 pyparsing.py:3543(<genexpr>)\n",
       "        3    0.000    0.000    0.007    0.002 container.py:1(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:331(device_count)\n",
       "       24    0.000    0.000    0.001    0.000 __init__.py:1870(find_distributions)\n",
       "        3    0.000    0.000    0.008    0.003 __init__.py:15(<module>)\n",
       "       19    0.000    0.000    0.018    0.001 traitlets.py:805(compatible_observer)\n",
       "      102    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method torch.cuda._get_device_properties}\n",
       "        3    0.000    0.000    0.001    0.000 _utils.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2931(__array_finalize__)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2050(_match_argument)\n",
       "        3    0.000    0.000    0.021    0.007 __init__.py:3(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 utils.py:4(<module>)\n",
       "       64    0.000    0.000    0.000    0.000 argparse.py:202(__init__)\n",
       "       64    0.000    0.000    0.000    0.000 inspect.py:73(isclass)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.putenv}\n",
       "       41    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
       "        1    0.000    0.000    0.000    0.000 stringprep.py:6(<module>)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:15(ismethod)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:321(fix_frame_records_filenames)\n",
       "        2    0.000    0.000    0.002    0.001 hashes.py:5(<module>)\n",
       "       73    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "        1    0.000    0.000    0.002    0.002 TiffTags.py:20(<module>)\n",
       "       62    0.000    0.000    0.000    0.000 numerictypes.py:127(english_lower)\n",
       "       18    0.000    0.000    0.000    0.000 copyreg.py:96(_slotnames)\n",
       "        1    0.000    0.000    0.000    0.000 versions_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.123    0.123 thnn.py:21(_initialize_backend)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:365(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:1(<module>)\n",
       "       25    0.000    0.000    0.001    0.000 typing.py:1025(_abc_negative_cache)\n",
       "      102    0.000    0.000    0.000    0.000 _collections_abc.py:392(__subclasshook__)\n",
       "       60    0.000    0.000    0.000    0.000 {method 'copy' of 'mappingproxy' objects}\n",
       "        1    0.000    0.000    0.002    0.002 graph_pb2.py:4(<module>)\n",
       "       27    0.000    0.000    0.000    0.000 core.py:920(__init__)\n",
       "       40    0.000    0.000    0.000    0.000 numerictypes.py:154(english_upper)\n",
       "        1    0.000    0.000    0.012    0.012 util.py:150(_get_soname)\n",
       "       56    0.000    0.000    0.000    0.000 inspect.py:1262(convert)\n",
       "       19    0.000    0.000    0.000    0.000 traitlets.py:188(parse_notifier_name)\n",
       "       38    0.000    0.000    0.000    0.000 traitlets.py:1673(validate)\n",
       "       78    0.000    0.000    0.000    0.000 _internal.py:726(<genexpr>)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:52(__new__)\n",
       "       14    0.000    0.000    0.001    0.000 pyparsing.py:2026(__call__)\n",
       "       95    0.000    0.000    0.000    0.000 pyparsing.py:203(<genexpr>)\n",
       "        2    0.000    0.000    0.005    0.002 dsa.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:514(X509Name)\n",
       "        1    0.000    0.000    0.001    0.001 activation.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 modules.py:96(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.unsetenv}\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:55(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:308(init_reductions)\n",
       "        2    0.000    0.000    0.010    0.005 __init__.py:45(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:7(<module>)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:26(_fr1)\n",
       "       14    0.000    0.000    0.001    0.000 cnf_regularization_rl.py:6(__init__)\n",
       "        1    0.000    0.000    0.007    0.007 plistlib.py:47(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 blas.py:202(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:170(<dictcomp>)\n",
       "       38    0.000    0.000    0.000    0.000 constraint_registry.py:86(register)\n",
       "       27    0.000    0.000    0.000    0.000 _collections_abc.py:664(__contains__)\n",
       "    13/12    0.000    0.000    0.053    0.004 <frozen importlib._bootstrap>:622(_load_backward_compatible)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:30(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:74(__call__)\n",
       "       64    0.000    0.000    0.000    0.000 argparse.py:1493(_check_conflict)\n",
       "       57    0.000    0.000    0.000    0.000 codecs.py:259(__init__)\n",
       "        3    0.000    0.000    0.003    0.001 __init__.py:10(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 response.py:1(<module>)\n",
       "       12    0.000    0.000    0.010    0.001 pyparsing.py:4251(__init__)\n",
       "       94    0.000    0.000    0.000    0.000 pyparsing.py:4890(<genexpr>)\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3439(<genexpr>)\n",
       "       49    0.000    0.000    0.000    0.000 six.py:184(find_module)\n",
       "        1    0.000    0.000    0.010    0.010 general_name.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 loss.py:1(<module>)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:118(<listcomp>)\n",
       "       19    0.000    0.000    0.007    0.000 traitlets.py:982(setup_instance)\n",
       "        1    0.000    0.000    0.005    0.005 pytorch_graph.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 warnings.py:20(_showwarnmsg_impl)\n",
       "        6    0.000    0.000    0.003    0.000 warnings.py:119(filterwarnings)\n",
       "       13    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:433(spec_from_loader)\n",
       "       82    0.000    0.000    0.000    0.000 {method 'AddDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        1    0.000    0.000    0.005    0.005 sessions.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 encode_asn1.py:5(<module>)\n",
       "        2    0.000    0.000    0.004    0.002 rnn.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 linear.py:47(__init__)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1838(getLogger)\n",
       "       36    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.002    0.002 decoder.py:79(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 pygram.py:4(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 summary.py:30(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 pyparsing.py:411(__getitem__)\n",
       "       61    0.000    0.000    0.000    0.000 pyparsing.py:2159(streamline)\n",
       "        2    0.000    0.000    0.000    0.000 function.py:183(once_differentiable)\n",
       "        1    0.000    0.000    0.001    0.001 tarfile.py:30(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 linalg.py:10(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:71(<lambda>)\n",
       "       41    0.000    0.000    0.000    0.000 enum.py:874(_power_of_two)\n",
       "        1    0.000    0.000    0.003    0.003 type_checkers.py:44(<module>)\n",
       "       10    0.000    0.000    0.001    0.000 six.py:91(__get__)\n",
       "        1    0.000    0.000    0.002    0.002 serialization.py:1(<module>)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:70(<lambda>)\n",
       "       38    0.000    0.000    0.020    0.001 traitlets.py:576(__set__)\n",
       "       19    0.000    0.000    0.000    0.000 traitlets.py:1237(observe)\n",
       "        1    0.000    0.000    0.007    0.007 subprocess.py:588(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
       "       57    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:48(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:766(_construct_lookups)\n",
       "        1    0.000    0.000    0.001    0.001 well_known_types.py:39(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2707(parseImpl)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1790(__init__)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1813(get_metadata_lines)\n",
       "        1    0.000    0.000    0.001    0.001 serialization.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:38(_parse_env)\n",
       "        7    0.000    0.000    0.000    0.000 _jit_internal.py:113(boolean_dispatch)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:146(rng)\n",
       "        4    0.000    0.000    0.474    0.119 __init__.py:2(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 text_format.py:41(<module>)\n",
       "       43    0.000    0.000    0.000    0.000 caffe2_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:4(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 __init__.py:1793(has_metadata)\n",
       "        1    0.000    0.000    0.466    0.466 writer.py:15(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 algorithms.py:5(<module>)\n",
       "       17    0.000    0.000    0.000    0.000 ocsp.py:25(_requires_successful_response)\n",
       "        2    0.000    0.000    0.003    0.002 dh.py:5(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 normalization.py:1(<module>)\n",
       "     24/8    0.000    0.000    0.042    0.005 __init__.py:296(get_device_properties)\n",
       "        1    0.000    0.000    0.007    0.007 index_tricks.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 zmqshell.py:538(_showtraceback)\n",
       "       25    0.000    0.000    0.000    0.000 typing.py:1039(_abc_negative_cache_version)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2190(_get_nargs_pattern)\n",
       "       57    0.000    0.000    0.000    0.000 traitlets.py:216(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:398(__init__)\n",
       "       14    0.000    0.000    0.002    0.000 posixpath.py:384(realpath)\n",
       "        1    0.000    0.000    0.037    0.037 specifiers.py:4(<module>)\n",
       "        3    0.000    0.000    0.001    0.000 utils.py:5(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 algos.py:19(<module>)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:109(has_argument)\n",
       "       11    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:980(_recalculate)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:83(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:1(<module>)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:28(isfunction)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:418(_construct_char_code_lookup)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:17(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1226(__init__)\n",
       "       60    0.000    0.000    0.000    0.000 six.py:835(add_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:4(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:663(__iadd__)\n",
       "        1    0.000    0.000    0.001    0.001 interfaces.py:5(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 shape_base.py:1(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 gettext.py:205(_expand_lang)\n",
       "        6    0.000    0.000    0.053    0.009 __init__.py:35(load_module)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_schur.py:1(<module>)\n",
       "        5    0.000    0.000    0.001    0.000 _torch_docs.py:9(parse_kwargs)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:2(<module>)\n",
       "        1    0.000    0.000    0.006    0.006 _internal.py:6(<module>)\n",
       "       19    0.000    0.000    0.001    0.000 path.py:86(compress_user)\n",
       "       19    0.000    0.000    0.000    0.000 data.py:13(uniq_stable)\n",
       "       13    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:976(_get_parent_path)\n",
       "        1    0.000    0.000    0.001    0.001 GifImagePlugin.py:27(<module>)\n",
       "        3    0.000    0.000    0.005    0.002 misc.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 model.py:1(<module>)\n",
       "       42    0.000    0.000    0.000    0.000 os.py:746(decode)\n",
       "       22    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:411(ImageFileDirectory_v2)\n",
       "        1    0.000    0.000    0.004    0.004 BmpImagePlugin.py:27(<module>)\n",
       "        3    0.000    0.000    0.040    0.013 odenvp_conditional_rl.py:221(<listcomp>)\n",
       "        1    0.000    0.000    0.002    0.002 matfuncs.py:5(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 request.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:88(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 util.py:301(_findLib_prefix)\n",
       "       26    0.000    0.000    0.000    0.000 argparse.py:2286(_get_value)\n",
       "       57    0.000    0.000    0.000    0.000 traitlets.py:215(__init__)\n",
       "       48    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISREG}\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1381(NullProvider)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2263(_is_unpacked_egg)\n",
       "        1    0.000    0.000    0.035    0.035 compat.py:9(<module>)\n",
       "       28    0.000    0.000    0.000    0.000 pooling.py:24(extra_repr)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:126(EventHandle)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:15(Tensor)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:388(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 case.py:1(<module>)\n",
       "       67    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}\n",
       "       16    0.000    0.000    0.001    0.000 pyparsing.py:1204(setResultsName)\n",
       "        1    0.000    0.000    0.004    0.004 x509.py:5(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 exceptions.py:1(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.empty}\n",
       "        1    0.000    0.000    0.449    0.449 interactiveshell.py:1981(showtraceback)\n",
       "       32    0.000    0.000    0.000    0.000 typing.py:889(__extrahook__)\n",
       "       19    0.000    0.000    0.000    0.000 traitlets.py:923(instance_init)\n",
       "       19    0.000    0.000    0.000    0.000 traitlets.py:1178(_add_notifiers)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:3120(<genexpr>)\n",
       "       21    0.000    0.000    0.000    0.000 utils.py:126(__getattr__)\n",
       "        1    0.000    0.000    0.039    0.039 type_check.py:3(<module>)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:43(iscode)\n",
       "       67    0.000    0.000    0.000    0.000 ultratb.py:1466(nullrepr)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _struct.calcsize}\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:219(_acquireLock)\n",
       "        1    0.000    0.000    0.001    0.001 PngImagePlugin.py:34(<module>)\n",
       "        2    0.000    0.000    0.470    0.235 __init__.py:33(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:4757(<lambda>)\n",
       "        1    0.000    0.000    0.003    0.003 sbcsgroupprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PoolKey)\n",
       "        1    0.000    0.000    0.001    0.001 constraint_registry.py:66(<module>)\n",
       "       14    0.000    0.000    0.001    0.000 pooling.py:940(__init__)\n",
       "        1    0.000    0.000    0.006    0.006 linear.py:1(<module>)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6568(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:73(CFUNCTYPE)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:2863(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 six.py:126(__init__)\n",
       "       36    0.000    0.000    0.000    0.000 backend.py:218(register_cipher_adapter)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:23(<dictcomp>)\n",
       "       28    0.000    0.000    0.000    0.000 pooling.py:944(extra_repr)\n",
       "       56    0.000    0.000    0.000    0.000 activation.py:84(extra_repr)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:36(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 fromnumeric.py:3(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 traceback.py:273(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:48(<listcomp>)\n",
       "       16    0.000    0.000    0.002    0.000 descriptor.py:869(__new__)\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:116(RegisterFileDescriptor)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:4017(__str__)\n",
       "        1    0.000    0.000    0.003    0.003 basic.py:7(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 sparse.py:1(<module>)\n",
       "       36    0.000    0.000    0.000    0.000 getlimits.py:69(<lambda>)\n",
       "        1    0.000    0.000    0.006    0.006 __init__.py:206(_sanity_check)\n",
       "        2    0.000    0.000    0.000    0.000 shutil.py:1048(get_terminal_size)\n",
       "       35    0.000    0.000    0.000    0.000 enum.py:822(_high_bit)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:183(dumps)\n",
       "       23    0.000    0.000    0.001    0.000 re.py:169(match)\n",
       "       34    0.000    0.000    0.000    0.000 descriptor_pb2.py:5(<lambda>)\n",
       "     15/4    0.000    0.000    0.001    0.000 pyparsing.py:3762(streamline)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2256(_is_egg_path)\n",
       "        1    0.000    0.000    0.000    0.000 decomp.py:15(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 socks.py:23(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 chardistribution.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:1(<module>)\n",
       "       23    0.000    0.000    0.000    0.000 utils.py:112(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:1(<module>)\n",
       "        1    0.000    0.000    0.120    0.120 auto.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:94(_check_capability)\n",
       "        1    0.000    0.000    0.001    0.001 polynomial.py:56(<module>)\n",
       "        1    0.000    0.000    0.446    0.446 ultratb.py:1056(format_exception_as_a_whole)\n",
       "       34    0.000    0.000    0.000    0.000 argparse.py:1278(register)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:65(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 descriptor.py:919(_ParseOptions)\n",
       "     12/2    0.000    0.000    0.000    0.000 pyparsing.py:1926(makeOptionalList)\n",
       "        1    0.000    0.000    0.001    0.001 poolmanager.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 getlimits.py:376(__new__)\n",
       "       19    0.000    0.000    0.000    0.000 ultratb.py:917(linereader)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:771(__init__)\n",
       "       21    0.000    0.000    0.000    0.000 traceback.py:276(__iter__)\n",
       "       59    0.000    0.000    0.000    0.000 enum.py:594(name)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:165(__setitem__)\n",
       "       11    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:993(__iter__)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
       "       10    0.000    0.000    0.000    0.000 {method 'tolist' of 'memoryview' objects}\n",
       "    13/12    0.000    0.000    0.000    0.000 pyparsing.py:3434(__str__)\n",
       "        2    0.000    0.000    0.001    0.001 pyparsing.py:3859(parseImpl)\n",
       "        1    0.000    0.000    0.014    0.014 version.py:4(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 util.py:15(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:147(deprecated)\n",
       "        1    0.000    0.000    0.042    0.042 data_parallel.py:113(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 profiler.py:1(<module>)\n",
       "        1    0.000    0.000    0.124    0.124 module.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8061(__init__)\n",
       "       18    0.000    0.000    0.000    0.000 core.py:996(__init__)\n",
       "       30    0.000    0.000    0.000    0.000 numerictypes.py:432(_add_array_type)\n",
       "        1    0.000    0.000    0.103    0.103 train_cnf_disentangle_rl.py:331(create_model)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:332(__init__)\n",
       "       27    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:908(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 TiffImagePlugin.py:635(_register_basic)\n",
       "        1    0.000    0.000    0.001    0.001 text_encoding.py:31(<module>)\n",
       "       78    0.000    0.000    0.000    0.000 pyparsing.py:2052(leaveWhitespace)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:11(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 name.py:5(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 mbcsgroupprober.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 data_parallel.py:1(<module>)\n",
       "        1    0.000    0.000    0.016    0.016 __init__.py:7(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 random.py:223(_randbelow)\n",
       "        1    0.000    0.000    0.004    0.004 fixer_util.py:1(<module>)\n",
       "        1    0.000    0.000    0.039    0.039 refactor.py:9(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 grammar.py:105(load)\n",
       "       10    0.000    0.000    0.000    0.000 __init__.py:23(find_module)\n",
       "       16    0.000    0.000    0.007    0.000 __init__.py:2006(safe_listdir)\n",
       "        1    0.000    0.000    0.003    0.003 _iri.py:9(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 constraints.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:88(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:332(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:19(ABCPolyBase)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:340(_add_integer_aliases)\n",
       "        1    0.000    0.000    0.000    0.000 _methods.py:5(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 textwrap.py:414(dedent)\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:190(_checkLevel)\n",
       "        5    0.000    0.000    0.000    0.000 re.py:249(escape)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:49(<listcomp>)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:4681(originalTextFor)\n",
       "       32    0.000    0.000    0.000    0.000 pyparsing.py:209(__init__)\n",
       "        1    0.000    0.000    0.003    0.003 record_writer.py:4(<module>)\n",
       "        1    0.000    0.000    0.452    0.452 event_file_writer.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ssl_.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:59(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 _distributor_init.py:10(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:48(_numeric_methods)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:839(_decompose)\n",
       "       46    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:84(<listcomp>)\n",
       "        1    0.000    0.000    0.012    0.012 descriptor.py:33(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1298(addCondition)\n",
       "        2    0.000    0.000    0.019    0.010 train_misc.py:85(count_parameters)\n",
       "       12    0.000    0.000    0.000    0.000 Image.py:2810(register_extension)\n",
       "        5    0.000    0.000    0.041    0.008 binding.py:122(_ensure_ffi_initialized)\n",
       "        1    0.000    0.000    0.046    0.046 binding.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 core.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 lowrank_multivariate_normal.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 random.py:1(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:242(getdoc)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:118(deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:440(_set_array_types)\n",
       "        2    0.000    0.000    0.001    0.000 _version.py:55(__init__)\n",
       "       49    0.000    0.000    0.000    0.000 reduction.py:43(register)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:1950(<listcomp>)\n",
       "       20    0.000    0.000    0.000    0.000 argparse.py:568(<listcomp>)\n",
       "       17    0.000    0.000    0.000    0.000 __init__.py:685(__init__)\n",
       "        2    0.000    0.000    0.007    0.003 resnet.py:1(<module>)\n",
       "       20    0.000    0.000    0.000    0.000 {method 'setter' of 'property' objects}\n",
       "       11    0.000    0.000    0.000    0.000 {built-in method builtins.delattr}\n",
       "       20    0.000    0.000    0.000    0.000 tokenize.py:48(group)\n",
       "       14    0.000    0.000    0.000    0.000 pyparsing.py:3576(__str__)\n",
       "     16/2    0.000    0.000    0.002    0.001 pyparsing.py:3737(parseImpl)\n",
       "       16    0.000    0.000    0.075    0.005 __init__.py:1914(_by_version_descending)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:81(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 tensor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:59(<module>)\n",
       "        4    0.000    0.000    0.001    0.000 container_gate.py:8(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'isoformat' of 'datetime.datetime' objects}\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:228(_releaseLock)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:366(_create_)\n",
       "        1    0.000    0.000    0.010    0.010 utils.py:3(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 pyparsing.py:3851(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _solvers.py:1(<module>)\n",
       "        1    0.000    0.000    0.006    0.006 train_misc.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:9(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 hmac.py:5(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 ocsp.py:43(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:11(ExtensionOID)\n",
       "        1    0.000    0.000    0.018    0.018 _int.py:32(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:5(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 __config__.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:63(NDArrayOperatorsMixin)\n",
       "        1    0.000    0.000    0.001    0.001 polynomial.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:1(<module>)\n",
       "        1    0.000    0.000    0.120    0.120 cnf_gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.007    0.007 dopri5.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:1(<module>)\n",
       "        1    0.000    0.000    0.007    0.007 __init__.py:1014(__init__)\n",
       "        1    0.000    0.000    0.005    0.005 fractions.py:4(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 descriptor.py:635(__new__)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1805(_warn_on_replacement)\n",
       "        1    0.000    0.000    0.298    0.298 model_zoo.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:59(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:251(_get_machar)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_VCABMState)\n",
       "        1    0.000    0.000    0.024    0.024 tsit5.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 ImageFilter.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1020(prepare_header)\n",
       "       42    0.000    0.000    0.000    0.000 argparse.py:2087(_parse_optional)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:135(<dictcomp>)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:312(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_qr.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:8(<module>)\n",
       "       35    0.000    0.000    0.000    0.000 backend.py:2100(__init__)\n",
       "       11    0.000    0.000    0.000    0.000 name.py:28(<genexpr>)\n",
       "        1    0.000    0.000    0.016    0.016 universaldetector.py:36(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mbcssm.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scope.py:3(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 driver.py:117(load_grammar)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4781(<lambda>)\n",
       "        1    0.000    0.000    0.467    0.467 torchvis.py:1(<module>)\n",
       "        1    0.000    0.000    0.097    0.097 __init__.py:554(__init__)\n",
       "        2    0.000    0.000    0.952    0.476 cifar.py:143(download)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:89(_OCSPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:684(Context)\n",
       "        1    0.000    0.000    0.005    0.005 sjisprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:727(TarInfo)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:83(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _inspect.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_RungeKuttaState)\n",
       "        3    0.000    0.000    0.000    0.000 util.py:136(register_after_fork)\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:1059(system)\n",
       "       13    0.000    0.000    0.000    0.000 _collections_abc.py:72(_check_methods)\n",
       "       28    0.000    0.000    0.000    0.000 TiffImagePlugin.py:368(_delegate)\n",
       "        1    0.000    0.000    0.011    0.011 api_implementation.py:32(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2751(charsAsStr)\n",
       "        7    0.000    0.000    0.000    0.000 six.py:195(load_module)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3027(_always_object)\n",
       "        1    0.000    0.000    0.000    0.000 flinalg.py:5(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 api.py:1(<module>)\n",
       "        1    0.000    0.000    0.019    0.019 _elliptic_curve.py:47(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 activation.py:321(__init__)\n",
       "        2    0.000    0.000    0.001    0.000 linear.py:58(reset_parameters)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:51(<module>)\n",
       "        1    0.000    0.000    0.012    0.012 util.py:310(find_library)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:65(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 context.py:69(RLock)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:864(__call__)\n",
       "       19    0.000    0.000    0.000    0.000 traitlets.py:2045(validate)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:12(pickle)\n",
       "       13    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:966(_find_parent_path_names)\n",
       "        1    0.000    0.000    0.007    0.007 odenvp_conditional_rl.py:226(<listcomp>)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:1069(wrapper)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:1608(parseString)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:586(Response)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:1529(Connection)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.X509_new}\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:271(<dictcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 fftpack.py:32(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 mixins.py:20(_binary_method)\n",
       "        1    0.000    0.000    0.001    0.001 case.py:341(TestCase)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:18(_fr0)\n",
       "        1    0.000    0.000    0.001    0.001 session.py:657(send)\n",
       "        1    0.000    0.000    0.034    0.034 modules.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:1(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 debugger.py:53(make_arrow)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1604(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:960(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 weakref.py:102(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 fractions.py:60(Fraction)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'FindEnumTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       46    0.000    0.000    0.000    0.000 pyparsing.py:1366(postParse)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3781(__str__)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:2237(_cygwin_patch)\n",
       "        6    0.000    0.000    0.001    0.000 __init__.py:2707(from_filename)\n",
       "       12    0.000    0.000    0.000    0.000 dual.py:52(register_func)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:52(NameOID)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:50(_ForceNullParameters)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:8(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 retry.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 reductions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _numpy_fft.py:54(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2491(seterr)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:1506(set_string_function)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1103(ParserElement)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2431(parseImpl)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3829(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:514(Image)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2761(register_open)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:499(_SignedCertificateTimestamp)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(Concat)\n",
       "        6    0.000    0.000    0.000    0.000 _elliptic_curve.py:97(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:170(__mul__)\n",
       "       19    0.000    0.000    0.000    0.000 constraint_registry.py:105(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:63(__init__)\n",
       "        1    0.000    0.000    0.003    0.003 random.py:22(manual_seed)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:3(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:25(register_func)\n",
       "        1    0.000    0.000    0.000    0.000 scimath.py:17(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 loader.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7ff727aa6a60}\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1920(consume_positionals)\n",
       "        6    0.000    0.000    0.000    0.000 locale.py:379(normalize)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1401(_try_wait)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1414(wait)\n",
       "       20    0.000    0.000    0.000    0.000 enum.py:581(__hash__)\n",
       "       43    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:24(with_metaclass)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:98(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:1(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:389(<genexpr>)\n",
       "        7    0.000    0.000    0.000    0.000 specifiers.py:266(_require_version_compare)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(VersionConflict)\n",
       "        1    0.000    0.000    0.001    0.001 scrypt.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 idnadata.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:46(register_decorator)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:33(SingleByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:102(HTTPHeaderDict)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'tobytes' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:265(GaussianDiag)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:1(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 loader.py:252(__getitem__)\n",
       "       39    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:31(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 text_format.py:1006(Tokenizer)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:11(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 patcomp.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:115(copy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4335(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4450(delimitedList)\n",
       "        2    0.000    0.000    0.000    0.000 spectral_norm.py:3(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 _main.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:148(activate_osrandom_engine)\n",
       "        1    0.000    0.000    0.002    0.002 idna.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1078(X509)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:1(<module>)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1414(_get_builtin_table)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:328(ExprBuilder)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:4(is_available)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:10(_ConstantPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 init.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:805(__init__)\n",
       "        4    0.000    0.000    0.001    0.000 core.py:126(doc_note)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:156(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2592(geterr)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate_sep.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 rk_common.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ImageOps.py:20(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 random.py:255(choice)\n",
       "        2    0.000    0.000    0.014    0.007 traceback.py:193(format_stack)\n",
       "       14    0.000    0.000    0.000    0.000 weakref.py:428(get)\n",
       "       12    0.000    0.000    0.000    0.000 six.py:80(_import_module)\n",
       "       34    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_manualSeedAll}\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:27(Parser)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:35(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 symbol_database.py:93(RegisterEnumDescriptor)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3841(__str__)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:338(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:79(EventFileWriter)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:12(qualify)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:150(ImageFolder)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:1(<module>)\n",
       "        1    0.000    0.000    0.016    0.016 lsun.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:2(<module>)\n",
       "        1    0.000    0.000    0.008    0.008 ciphers.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:160(UniformResourceIdentifier)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:78(contains)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1082(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:21(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 convert_parameters.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:279(get_device_capability)\n",
       "        1    0.000    0.000    0.000    0.000 twodim_base.py:3(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:484(cast)\n",
       "        1    0.000    0.000    0.001    0.001 adams.py:1(<module>)\n",
       "        1    0.000    0.000    0.447    0.447 ultratb.py:1128(structured_traceback)\n",
       "        6    0.000    0.000    0.000    0.000 tokenize.py:344(_get_normal_name)\n",
       "        6    0.000    0.000    0.000    0.000 weakref.py:354(__init__)\n",
       "       28    0.000    0.000    0.000    0.000 _collections_abc.py:302(__subclasshook__)\n",
       "        1    0.000    0.000    0.033    0.033 driver.py:12(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:1877(__mul__)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:135(_declare_state)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_svd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:59(LSUN)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:214(_CertificateRevocationList)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:185(CertificateRevocationList)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:5(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:22(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 gumbel.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:6(PixelShuffle)\n",
       "        1    0.000    0.000    0.042    0.042 data_parallel.py:18(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:20(warn_imbalance)\n",
       "       11    0.000    0.000    0.000    0.000 init.py:403(_make_deprecate)\n",
       "       27    0.000    0.000    0.000    0.000 auto.py:339(make_default_double_backwards_fn)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2775(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 nanfunctions.py:22(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:369(_set_up_aliases)\n",
       "        5    0.000    0.000    0.000    0.000 getlimits.py:507(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 jsonutil.py:177(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 session.py:598(serialize)\n",
       "        4    0.000    0.000    0.000    0.000 jsonapi.py:31(dumps)\n",
       "        1    0.000    0.000    0.119    0.119 cnf.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:232(get_context)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:87(__init__)\n",
       "       46    0.000    0.000    0.000    0.000 inspect.py:358(<lambda>)\n",
       "       25    0.000    0.000    0.000    0.000 enum.py:332(<genexpr>)\n",
       "       23    0.000    0.000    0.000    0.000 enum.py:599(value)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rfind' of 'bytes' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'findall' of '_sre.SRE_Pattern' objects}\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:16(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 visdom_writer.py:23(VisdomWriter)\n",
       "        2    0.000    0.000    0.000    0.000 types_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.003    0.003 onnx_graph.py:1(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 pyparsing.py:4825(tokenMap)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:420(__setitem__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:1841(__radd__)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:150(create_regularization_fns)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:112(tqdm)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_init}\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:7(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 constant_time.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:313(SpecifiedECDomain)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:154(cached_property)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:79(Certificate)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 escprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 filepost.py:1(<module>)\n",
       "        1    0.000    0.000    0.018    0.018 __init__.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:77(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 adaptive.py:3(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 linear.py:69(extra_repr)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2905(_update_from)\n",
       "        1    0.000    0.000    0.000    0.000 py3k.py:4(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 numerictypes.py:181(english_capitalize)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:1669(chararray)\n",
       "        1    0.000    0.000    0.000    0.000 train_cnf_disentangle_rl.py:182(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:139(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:752(_addHandlerRef)\n",
       "       22    0.000    0.000    0.000    0.000 traceback.py:303(walk_tb)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:35(_formatwarnmsg_impl)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
       "        1    0.000    0.000    0.003    0.003 noniterators.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:606(WildcardPattern)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:4(<module>)\n",
       "        1    0.000    0.000    0.032    0.032 specifiers.py:275(Specifier)\n",
       "        7    0.000    0.000    0.000    0.000 six.py:114(_resolve)\n",
       "       10    0.000    0.000    0.000    0.000 event_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 dual.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_lu.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:8(TqdmSynchronisationWarning)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:116(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2111(CRL)\n",
       "        1    0.000    0.000    0.001    0.001 certificate_transparency.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 utf8prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:8(Binomial)\n",
       "        1    0.000    0.000    0.000    0.000 rendezvous.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _six.py:21(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8066(getdoc)\n",
       "        1    0.000    0.000    0.004    0.004 __init__.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:934(poly1d)\n",
       "        1    0.000    0.000    0.003    0.003 defmatrix.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 main.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1234(TimedeltaFormat)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint_sep.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interactiveshell.py:1933(_get_exc_info)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1533(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 shutil.py:1106(_access_check)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:767(_create_pseudo_member_)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:182(encode)\n",
       "        1    0.000    0.000    0.000    0.000 sysconfig.py:612(get_platform)\n",
       "        9    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "       10    0.000    0.000    0.000    0.000 {method 'cast' of 'memoryview' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._init_names}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._multiprocessing_init}\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:1(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2045(suppress)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:3935(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:21(FFI)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:81(SignatureAlgorithmOID)\n",
       "        1    0.000    0.000    0.000    0.000 parser.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 escsm.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:104(_has_ipv6)\n",
       "        1    0.000    0.000    0.298    0.298 alexnet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:8(NegativeBinomial)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:18(add_docstr_all)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:1(<module>)\n",
       "        1    0.000    0.000    0.042    0.042 data_parallel.py:11(_check_balance)\n",
       "        1    0.000    0.000    0.001    0.001 gradcheck.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 module.py:23(Module)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:57(_load_cudart)\n",
       "        2    0.000    0.000    0.014    0.007 __init__.py:120(_lazy_call)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:238(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:8(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:40(_inplace_binary_method)\n",
       "        1    0.000    0.000    0.000    0.000 histograms.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:6(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 result.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 util.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:65(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:746(__exit__)\n",
       "        2    0.000    0.000    0.001    0.001 traceback.py:27(format_list)\n",
       "        1    0.000    0.000    0.000    0.000 ImageColor.py:20(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extension_loader.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 visdom_writer.py:1(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 enum_type_wrapper.py:46(__init__)\n",
       "        2    0.000    0.000    0.003    0.001 pyparsing.py:4763(srange)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:9(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 six.py:209(is_package)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2464(Distribution)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:26(_Certificate)\n",
       "        1    0.000    0.000    0.001    0.001 cmac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:102(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 backend.py:128(_get_osurandom_engine)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:491(PrivateKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:10(_Reasons)\n",
       "        1    0.000    0.000    0.002    0.002 exceptions.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 charsetgroupprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 half_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 bernoulli.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 beta.py:10(Beta)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:267(get_device_name)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:45(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:35(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_string_function}\n",
       "       13    0.000    0.000    0.000    0.000 mixins.py:30(_reflected_binary_method)\n",
       "        3    0.000    0.000    0.000    0.000 numerictypes.py:565(obj2sctype)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 einsumfunc.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:583(sign)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:1(<module>)\n",
       "        1    0.000    0.000    0.369    0.369 ultratb.py:307(wrapped)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2312(_check_value)\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:572(dgettext)\n",
       "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:960(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
       "        1    0.000    0.000    0.002    0.002 ImagePalette.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:3(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 btm_matcher.py:6(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 __init__.py:40(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 proto_graph.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 containers.py:40(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3164(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:21(BaseSpecifier)\n",
       "        1    0.000    0.000    0.002    0.002 expat.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_ldl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_cholesky.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_qz.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 Image.py:2821(register_extensions)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2932(_apply_env_variables)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:294(socksocket)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:264(OCSPRequest)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:115(inject_into_urllib3)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:137(_validate_dependencies_met)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:21(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'seed' of 'mtrand.RandomState' objects}\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:239(manager_path)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:2551(_arraymethod)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:493(StringConverter)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'newbyteorder' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:17(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 squeeze.py:7(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:96(seed)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:826(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_TagInfo)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'ParseFromString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1288(addParseAction)\n",
       "        5    0.000    0.000    0.000    0.000 six.py:159(_resolve)\n",
       "        1    0.000    0.000    0.000    0.000 _expm_frechet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 cookiejar.py:1224(CookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:259(Morsel)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_get_default_RAND}\n",
       "        1    0.000    0.000    0.000    0.000 base.py:292(CertificateSigningRequest)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2387(PKCS12)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:124(HTTPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 url.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lowrank_multivariate_normal.py:57(LowRankMultivariateNormal)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:7(Distribution)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 chi2.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 _reduction.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:20(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:1385(TarFile)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:1145(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6266(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:162(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 financial.py:12(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 _version.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:1(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:69(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 _ccallback.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:409(_real_close)\n",
       "        2    0.000    0.000    0.000    0.000 terminal.py:109(get_terminal_size)\n",
       "        7    0.000    0.000    0.000    0.000 __init__.py:1109(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1456(addHandler)\n",
       "        1    0.000    0.000    0.000    0.000 getipython.py:17(get_ipython)\n",
       "        3    0.000    0.000    0.001    0.000 re.py:179(search)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:339(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup}\n",
       "        1    0.000    0.000    0.000    0.000 ImageChops.py:18(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 descriptor_pool.py:56(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 tensor_pb2.py:5(<lambda>)\n",
       "       16    0.000    0.000    0.000    0.000 {method 'AddFileDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       25    0.000    0.000    0.000    0.000 {method 'append' of 'DescriptorSequence' objects}\n",
       "        1    0.000    0.000    0.003    0.003 symbol_database.py:58(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:324(ParseResults)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4003(parseImpl)\n",
       "        1    0.000    0.000    0.011    0.011 version.py:191(Version)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_Version)\n",
       "       12    0.000    0.000    0.000    0.000 __init__.py:15(search_path)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:469(Module_six_moves_urllib)\n",
       "        1    0.000    0.000    0.000    0.000 py31compat.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:2205(file_ns_handler)\n",
       "        1    0.000    0.000    0.097    0.097 __init__.py:567(_build_master)\n",
       "        1    0.000    0.000    0.000    0.000 special_matrices.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:5(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 backend.py:114(openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:109(_register_osrandom_engine)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:581(ReasonFlags)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:714(X509Extension)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:383(PyOpenSSLContext)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:217(PKey)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:58(MultivariateNormal)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:11(StudentT)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 bernoulli.py:10(Bernoulli)\n",
       "        1    0.000    0.000    0.001    0.001 beta.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:8(Categorical)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 grad.py:1(<module>)\n",
       "        1    0.000    0.000    0.123    0.123 thnn.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:54(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 ufunclike.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:942(_register_types)\n",
       "        4    0.000    0.000    0.000    0.000 session.py:102(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_ButcherTableau)\n",
       "        1    0.000    0.000    0.009    0.009 fakedata.py:1(<module>)\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:506(translation)\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:921(uname)\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:193(total_ordering)\n",
       "        1    0.000    0.000    0.000    0.000 JpegPresets.py:67(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:947(TiffImageFile)\n",
       "        2    0.000    0.000    0.000    0.000 extension_loader.py:16(DlopenGuard)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:17(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 decoder.py:263(_StructPackDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:171(RefactoringTool)\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:110(_generate_pickle_name)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:113(calc_output_size)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:47(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 reflection.py:46(<module>)\n",
       "       18    0.000    0.000    0.000    0.000 pyparsing.py:458(__bool__)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:3032(__str__)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:3098(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 six.py:189(__get_module)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ArgSpec)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2787(register_save)\n",
       "        1    0.000    0.000    0.000    0.000 _binary.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:171(RequestsCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1063(ZipFile)\n",
       "        1    0.000    0.000    0.035    0.035 _internal_utils.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 aead.py:5(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 SSL.py:701(<genexpr>)\n",
       "        2    0.000    0.000    0.041    0.020 binding.py:136(init_static_locks)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:172(Encoding)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:15(_ASN1Type)\n",
       "        6    0.000    0.000    0.000    0.000 crypto.py:625(_cmp)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Url)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:7(Independent)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:79(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:1(<module>)\n",
       "        1    0.000    0.000    0.008    0.008 adam.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 comm.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:29(<lambda>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:128(<lambda>)\n",
       "        1    0.000    0.000    0.001    0.001 scatter_gather.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:459(CudnnModule)\n",
       "        4    0.000    0.000    0.000    0.000 _utils_internal.py:16(get_file_path)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:9(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 pytesttester.py:72(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 result.py:12(failfast)\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2478(prod)\n",
       "        2    0.000    0.000    0.000    0.000 jsonutil.py:87(date_default)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:62(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interp.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:162(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 ImageEnhance.py:21(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'bind' of '_socket.socket' objects}\n",
       "       21    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
       "       14    0.000    0.000    0.000    0.000 copy.py:111(_copy_immutable)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:331(__iter__)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:672(__setitem__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.open}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._tracer_warn_use_python}\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:17(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 fractions.py:294(_operator_fallbacks)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:375(EncodeVarint)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Int8Tensor)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:12(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:138(_newer)\n",
       "        2    0.000    0.000    0.001    0.001 driver.py:147(load_packaged_grammar)\n",
       "        3    0.000    0.000    0.000    0.000 grammar.py:77(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:37(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:5(<module>)\n",
       "        1    0.000    0.000    0.047    0.047 __init__.py:85(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:93(StrictVersion)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:102(DescriptorPool)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:38(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'AddEnumDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:4292(__init__)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:317(__getitem__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:668(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:2963(__str__)\n",
       "        1    0.000    0.000    0.003    0.003 specifiers.py:214(LegacySpecifier)\n",
       "       16    0.000    0.000    0.000    0.000 six.py:75(_add_doc)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:385(get_build_platform)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:114(_make_name)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:302(OCSPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_OpenSSLErrorWithText)\n",
       "        3    0.000    0.000    0.000    0.000 extensions.py:915(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:122(_ModuleWithDeprecations)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:48(EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:872(X509Req)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(RequestHistory)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:10(Multinomial)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:10(Geometric)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:8(TransformedDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:10(Normal)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:225(StmtBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adadelta.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:451(__set__)\n",
       "        1    0.000    0.000    0.001    0.001 vision.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:341(FormattedTimesMixin)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:7(Stream)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:323(_get_typecodes)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:1606(Polynomial)\n",
       "        1    0.000    0.000    0.000    0.000 arraypad.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defmatrix.py:70(matrix)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Mismatch)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:561(msg_header)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:564(msg)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:95(copy)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:8(MultiscaleParallelCNF)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:160(<listcomp>)\n",
       "        1    0.000    0.000    0.447    0.447 ultratb.py:1373(structured_traceback)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:133(_get_kwargs)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:586(iteritems)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1348(_handle_exitstatus)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:678(__delitem__)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:349(__subclasshook__)\n",
       "       10    0.000    0.000    0.000    0.000 six.py:181(_get_module)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'end' of '_sre.SRE_Match' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.urandom}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.get_terminal_size}\n",
       "       13    0.000    0.000    0.000    0.000 decoder.py:190(_SimpleDecoder)\n",
       "       11    0.000    0.000    0.000    0.000 attr_value_pb2.py:5(<lambda>)\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:187(Default)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:2376(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3061(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1603(ZipProvider)\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:2310(EntryPoint)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_polar.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 linalg_version.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:264(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:76(Blowfish)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_MemoryBIO)\n",
       "        4    0.000    0.000    0.000    0.000 ocsp.py:63(<genexpr>)\n",
       "        7    0.000    0.000    0.000    0.000 decode_asn1.py:187(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:117(activate_builtin_random)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.OpenSSL_add_all_algorithms}\n",
       "        3    0.000    0.000    0.000    0.000 binding.py:106(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3848(SequenceOf)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:142(AuthorityKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:488(DistributionPoint)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:268(RSAPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:275(X509Backend)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:150(DSAParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:15(EllipticCurveOID)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:103(EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1941(Revoked)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2665(_PassphraseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 universaldetector.py:51(UniversalDetector)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:9(Poisson)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:209(ComposeTransform)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:11(FisherSnedecor)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ScriptMethodStub)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 parallel_apply.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:17(<lambda>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:31(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 activation.py:608(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:7(_StorageBase)\n",
       "        2    0.000    0.000    0.000    0.000 serialization.py:46(register_package)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3080(view)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:2109(Chebyshev)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:17(__enter__)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.seterrobj}\n",
       "       14    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.geterrobj}\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 arraysetops.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:74(_determine_error_states)\n",
       "        3    0.000    0.000    0.000    0.000 ufunclike.py:14(_deprecate_out_named_y)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:845(<lambda>)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2891(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:24(TestResult)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:450(decorating_function)\n",
       "        3    0.000    0.000    0.000    0.000 session.py:132(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization_rl.py:5(RegularizedODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization_rl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:36(FixedGridODESolver)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:167(BoxBlur)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:157(__next__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1236(_fixupChildren)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:773(_get_devnull)\n",
       "        4    0.000    0.000    0.001    0.000 re.py:204(split)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method sys.setdlopenflags}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method atexit.register}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_cudnn_benchmark}\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:561(PyDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:1552(AppendingTiffWriter)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:409(_VarintBytes)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:504(_StructPackEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:32(Base)\n",
       "       13    0.000    0.000    0.000    0.000 summary_pb2.py:5(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 descriptor.py:729(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:392(FieldDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(manifest_mod)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1567(resetCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2991(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3015(parseImpl)\n",
       "        4    0.000    0.000    0.001    0.000 pyparsing.py:3353(setResultsName)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 torchvis.py:19(TorchVis)\n",
       "        1    0.000    0.000    0.000    0.000 _procrustes.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 api.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:863(DefaultCookiePolicy)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:387(_CertificateSigningRequest)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:29(OCSPResponderEncoding)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:34(OCSPResponseStatus)\n",
       "       10    0.000    0.000    0.000    0.000 SSL.py:646(_requires_decorator)\n",
       "        3    0.000    0.000    0.000    0.000 SSL.py:636(_make_requires)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:120(ExtendedKeyUsageOID)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:764(Void)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3050(Sequence)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:388(extended_datetime)\n",
       "        1    0.000    0.000    0.000    0.000 _types.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:232(SubjectKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:744(UserNotice)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:949(KeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1126(Extension)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1343(InvalidityDate)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:964(PublicKeyInfo)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:60(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:21(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:131(DSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:375(_EllipticCurve)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:28(Retry)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:74(_check_cryptography)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:736(HTTPSConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:10(LogitRelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:10(Weibull)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:26(Transform)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:11(HalfCauchy)\n",
       "        1    0.000    0.000    0.000    0.000 exp_family.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:17(Optimizer)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ASMoutput)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PackedSequence)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:13(_BatchNorm)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:1811(HermiteE)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:1764(Laguerre)\n",
       "        2    0.000    0.000    0.000    0.000 helper.py:245(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.copyto}\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:52(_set_function_name)\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:246(_ctypes)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2887(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 case.py:1316(_deprecate)\n",
       "        4    0.000    0.000    0.000    0.000 hmac.py:90(update)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:121(new_id)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:169(utcnow)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:342(_FuncPtr)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:66(reset)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:6(AdaptiveStepsizeODESolver)\n",
       "        2    0.000    0.000    0.000    0.000 odefunc.py:75(__init__)\n",
       "        1    0.000    0.000    0.447    0.447 ultratb.py:1276(structured_traceback)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1354(add_argument_group)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1280(setLevel)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1154(_get_handles)\n",
       "        1    0.000    0.000    0.086    0.086 traceback.py:59(extract_tb)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:334(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 weakref.py:288(update)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:760(getenv)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:252(__subclasshook__)\n",
       "       12    0.000    0.000    0.000    0.000 {method 'groupdict' of '_sre.SRE_Match' objects}\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:16(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 GifImagePlugin.py:46(GifImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:854(ImageFileDirectory_v1)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 compatibility.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 parse.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:10(ODENVP)\n",
       "        9    0.000    0.000    0.000    0.000 step_stats_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:31(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 resource_handle_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:788(ListValue)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'FindOneofByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:4783(<genexpr>)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:506(haskeys)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:2020(__invert__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3962(Optional)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:248(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:78(_IndividualSpecifier)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:589(SpecifierSet)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3114(_initialize)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:11(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:551(WorkingSet)\n",
       "        1    0.000    0.000    0.000    0.000 _sketches.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 Image.py:2776(register_mime)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:300(_DataLoaderIter)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:13(where)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:17(AsymmetricPadding)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:57(OCSPCertStatus)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:12(MACContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:14(Mode)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:33(HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:168(Asn1Value)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:613(EncryptionAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:694(PolicyInformation)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:862(TLSFeature)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:904(TLSFeatureType)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1044(NameConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:369(RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:80(DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:189(DSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:13(LogEntryType)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:247(WrappedSocket)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:70(HTTPConnection)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:8(Laplace)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:7(OneHotCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:10(ExpRelaxedCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:9(Exponential)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:9(Uniform)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:11(Cauchy)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:13(Gamma)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1450(_register_builtin)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:3(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 replicate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 nccl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auto_double_backwards.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 random.py:77(manual_seed_all)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:7(cudaOutputMode)\n",
       "        1    0.000    0.000    0.000    0.000 nvtx.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6348(__setattr__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6256(MaskedConstant)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6449(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:1814(Hermite)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1923(suppress_warnings)\n",
       "        7    0.000    0.000    0.000    0.000 _inspect.py:144(<lambda>)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2896(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_LoggingWatcher)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:63(__new__)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:99(CFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:425(LoadLibrary)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:110(Conv2d)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:62(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:12(PhotoTour)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'copy' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1042(format_exception)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:829(__prepare__)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:1115(append)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'datetime.datetime' objects}\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:760(_missing_)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:104(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:806(fsdecode)\n",
       "        4    0.000    0.000    0.000    0.000 genericpath.py:53(getmtime)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:97(ChunkStream)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:74(ImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:286(PngStream)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:418(TagBytes)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:24(BaseBaseString)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:100(TextWriter)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:593(_Parser)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:115(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:318(Leaf)\n",
       "        4    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:204(<listcomp>)\n",
       "        1    0.000    0.000    0.002    0.002 version.py:27(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 layout_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 x2num.py:2(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 visdom_writer.py:13(_check_connection)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3458(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4163(__lshift__)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:407(AppDirs)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:39(NegativeInfinity)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:164(_SixMetaPathImporter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1525(_register)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:1583(MemoizedZipManifests)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:127(Plist)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:56(S3RecordWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:957(Environment)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1123(ResourceManager)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:156(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 lock.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:102(PrimitiveType)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:93(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 _utils.py:8(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:46(SemLock)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:371(Barrier)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:340(Session)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:91(set_self_blocking)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:318(ZipInfo)\n",
       "        1    0.000    0.000    0.000    0.000 makefile.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:325(_OCSPRequest)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:142(DHPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:96(Binding)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:183(PublicFormat)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:189(ParameterFormat)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:115(DNSName)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:102(RelativeDistinguishedName)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:18(HashAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:22(_OpenSSLError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2706(Null)\n",
       "        1    0.000    0.000    0.000    0.000 _errors.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:180(RSASSAPSSParams)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:300(AccessDescription)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:336(BasicConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:918(InhibitAnyPolicy)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:86(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:329(NamedCurve)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:384(ECDomainParameters)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:92(PrimePoint)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:96(RSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:334(DHBackend)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:32(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:313(EllipticCurvePublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:384(EllipticCurvePrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1573(X509Store)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:22(SignedCertificateTimestamp)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(Version)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:128(HebrewProber)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:113(EUCTWDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 url.py:14(Url)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:49(check_compatibility)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:95(HTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:9(Pareto)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:8(LogNormal)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:164(_InverseTransform)\n",
       "        1    0.000    0.000    0.000    0.000 gumbel.py:13(Gumbel)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:38(Dirichlet)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:1262(_get_methods)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:10(DistributedDataParallelCPU)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:27(DistributedDataParallel)\n",
       "        1    0.000    0.000    0.000    0.000 adadelta.py:6(Adadelta)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:75(LayerNorm)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:169(EmbeddingBag)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:21(RNNBase)\n",
       "        1    0.000    0.000    0.000    0.000 clip_grad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:202(ModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 auto_symbolic.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:39(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:612(_FileInFile)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6440(_extrema_operation)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:1794(Legendre)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:18(NumpyVersion)\n",
       "        9    0.000    0.000    0.000    0.000 _globals.py:73(__repr__)\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:51(BagObj)\n",
       "        3    0.000    0.000    0.000    0.000 index_tricks.py:241(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:759(__getitem__)\n",
       "        6    0.000    0.000    0.000    0.000 case.py:420(addTypeEqualityFunc)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:66(TestLoader)\n",
       "        1    0.000    0.000    0.000    0.000 main.py:49(TestProgram)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:62(MachArLike)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:532(max)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:455(iinfo)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:127(hexdigest)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:26(LowLevelCallable)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:32(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:10(SVHN)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:29(Stat)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:24(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:142(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:48(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:46(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:436(find_recursion)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1011(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1484(_get_handler)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1725(_get_positional_actions)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method utcnow}\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:758(__del__)\n",
       "        3    0.000    0.000    0.000    0.000 threading.py:74(RLock)\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:196(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.TextIOWrapper' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register_error}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.access}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.uname}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'union' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(Iterator)\n",
       "        1    0.000    0.000    0.000    0.000 JpegImagePlugin.py:300(JpegImageFile)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:620(_register_loader)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:630(decorator)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:629(_register_writer)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:542(_FloatingPointEncoder)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:49(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:33(olddict)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:37(oldstr)\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:16(MinNode)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:82(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:208(Node)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:327(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 literals.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:477(suspend_hooks)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:19(LParen)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:252(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:79(Graph_py)\n",
       "        2    0.000    0.000    0.000    0.000 message_factory.py:50(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 node_def_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:343(RepeatedCompositeFieldContainer)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:44(Message)\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:107(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:222(Descriptor)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4296(postParse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1972(__xor__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2765(Regex)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3046(White)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4214(copy)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:72(LegacyVersion)\n",
       "        8    0.000    0.000    0.000    0.000 version.py:261(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:28(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:20(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:10(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:4(VendorImporter)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:103(MovedModule)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:124(_LazyModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1484(EggProvider)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:2876(DistInfoDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:764(_BinaryPlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 crc32c.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:40(SummaryToEventTransformer)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:144(FileWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:175(get_supported_platform)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:342(register_loader_type)\n",
       "        1    0.000    0.000    0.000    0.000 thops.py:1(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 train_misc.py:15(set_cnf_options)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:341(StructOrUnion)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:16(CIFAR10)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:126(BatchSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:46(ConcatDataset)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:332(Event)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:16(ResNeXtBottleneckC)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:95(SessionRedirectMixin)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:84(HTTPAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1961(MozillaCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:485(BaseCookie)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:25(MockRequest)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:60(RequestEncodingMixin)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:329(_RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:14(X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:31(X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:26(AES)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:91(CAST5)\n",
       "        1    0.000    0.000    0.000    0.000 scrypt.py:23(Scrypt)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:15(_HMACContext)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:176(_RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:18(DHPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:49(DHPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:80(DHParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:118(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:185(DHPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:108(_DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:126(_EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:228(_EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 ciphers.py:13(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:20(CipherAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:96(Cipher)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:100(XTS)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:197(GCM)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_by_id}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_set_default_RAND}\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:178(PrivateFormat)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:40(NameAttribute)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:46(CRLEntryExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:146(BLAKE2b)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(Any)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:971(Choice)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2198(OctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:64(register)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:202(extended_date)\n",
       "        1    0.000    0.000    0.000    0.000 _ordereddict.py:23(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:72(Extensions)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:406(CRLDistributionPoints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:447(FreshestCRL)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1210(SubjectAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:54(OtherPrimeInfo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:264(CharacteristicTwo)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:69(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:12(CipherBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:183(EllipticCurveBackend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(AsymmetricSignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:10(ObjectIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1550(X509StoreFlags)\n",
       "        1    0.000    0.000    0.000    0.000 langcyrillicmodel.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:35(CharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:93(MultiDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 compat.py:22(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:18(is_local_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:18(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:8(LogisticNormal)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:92(RelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:19(cuFFTPlanCache)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(PowerTransform)\n",
       "        1    0.000    0.000    0.000    0.000 half_normal.py:11(HalfNormal)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:24(_Dirichlet)\n",
       "        2    0.000    0.000    0.000    0.000 constraint_registry.py:83(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:1279(_make_fail)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:161(MultiStepLR)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:39(SharedCache)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:8(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:550(ignore_lib_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:784(OrderedDictWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:19(DistributedDataParallel)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:110(Unfold)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:10(Embedding)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:10(PackedSequence)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:658(MultiLabelMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:415(ParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:335(CELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:621(Softshrink)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:13(EmbeddingBag)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:129(profile)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:331(NestedIOFunction)\n",
       "        4    0.000    0.000    0.000    0.000 function.py:273(_iter_filter)\n",
       "        1    0.000    0.000    2.508    2.508 module.py:246(cuda)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:86(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:312(_LowLevelFile)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1315(_replace_dtype_fields)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2596(MaskedIterator)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6060(mvoid)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:86(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:184(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:265(DataSource)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:270(NameValidator)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:9(PackageLoader)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:83(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:216(_getintp_ctype)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:34(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:29(TextTestResult)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:120(TextTestRunner)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:156(ones)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2824(errstate)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:217(record)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:88(_str_eps)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:96(_str_xmin)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:739(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:108(_current)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:260(send_multipart)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:236(msg_header)\n",
       "        2    0.000    0.000    0.000    0.000 odefunc_rl.py:75(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 _testutils.py:26(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(MovingBatchNormNd)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate.py:20(CNF_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:151(AdamsBashforthMoulton)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:5(RegularizedODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:12(STL10)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:44(__init__)\n",
       "        1    0.000    0.000    0.369    0.369 ultratb.py:1090(get_records)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1726(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1733(parse_args)\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:611(gettext)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1148(_sys_version)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1255(python_implementation)\n",
       "        6    0.000    0.000    0.000    0.000 inspect.py:1253(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:800(createLock)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:823(setLevel)\n",
       "        4    0.000    0.000    0.000    0.000 sre_parse.py:161(__delitem__)\n",
       "        1    0.000    0.000    0.001    0.001 warnings.py:85(_showwarnmsg)\n",
       "        2    0.000    0.000    0.000    0.000 _collections_abc.py:271(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 _collections_abc.py:406(__subclasshook__)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method sys.getdlopenflags}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.charmap_build}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ImagePalette.py:23(ImagePalette)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:324(Parser)\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:56(BmpImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:137(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:1022(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:134(_SignedVarintDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:17(BMNode)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:22(RParen)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:50(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:415(BasePattern)\n",
       "        2    0.000    0.000    0.000    0.000 tokenize.py:50(maybe)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:10(ParserGenerator)\n",
       "        1    0.000    0.000    0.000    0.000 workspace.py:494(_BlobDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(RTs)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:31(Version)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:267(LooseVersion)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:98(Timestamp)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:241(Duration)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:541(_FieldMaskTree)\n",
       "        3    0.000    0.000    0.000    0.000 graph_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:803(MethodDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:230(RepeatedScalarFieldContainer)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:524(MessageMap)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:434(ScalarMap)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:315(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:460(__iter__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:644(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2527(CaselessKeyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3097(_PositionToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3151(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3195(StringEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3256(ParseExpression)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3368(And)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3523(MatchFirst)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3715(ParseElementEnhance)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:7(Infinity)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:64(install)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:86(_LazyDescr)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:173(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1506(DefaultProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1778(FileMetadata)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:2076(register_namespace_handler)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2973(Requirement)\n",
       "        2    0.000    0.000    0.256    0.128 __init__.py:3109(_call_aside)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:312(_PlistParser)\n",
       "        1    0.000    0.000    0.000    0.000 embedding.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:32(EventsWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:301(DistributionNotFound)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:500(IMetadataProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:523(IResourceProvider)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:25(BaseTypeByIdentity)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:97(BasePrimitiveType)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:82(CocoDetection)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:720(DataLoader)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:210(Condition)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_pandas.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:272(PreparedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:108(HTTPDigestAuth)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:90(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:534(_ZipDecrypter)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:760(ZipExtFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:989(_ZipWriteFile)\n",
       "        1    0.000    0.000    0.003    0.003 certs.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:732(Cookie)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:42(Camellia)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:57(TripleDES)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:106(ARC4)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:148(ChaCha20)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:13(_HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:106(_DHPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:217(_DHPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:170(DHPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:52(Prehashed)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:85(CBC)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:297(_VerifyHelper)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:50(RFC822Name)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:279(IPAddress)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:317(OtherName)\n",
       "        1    0.000    0.000    0.000    0.000 intranges.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:135(CertificatePoliciesOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:167(BLAKE2s)\n",
       "        6    0.000    0.000    0.000    0.000 binding.py:54(_openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'new_allocator' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2501(ParsableOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2737(ObjectIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2964(Enumerated)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:220(SignedDigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:272(SignedDigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:475(RSAESOAEPParams)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:561(EncryptionAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:378(DeltaCRLIndicator)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:594(PolicyConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:655(CertificatePolicies)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:817(ExtendedKeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1315(CRLReason)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1373(PrecertificateSignedCertificateTimestamps)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1421(OCSPNonce)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1449(UnrecognizedExtension)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:54(PrimeCurve)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:54(RSAPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:338(RSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:64(CMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:231(PEMSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:693(RevokedCertificateBuilder)\n",
       "        2    0.000    0.000    0.000    0.000 utils.py:123(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(AsymmetricVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:14(DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:65(DSAPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:227(DSAPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:24(EllipticCurve)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:88(EllipticCurvePrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1696(X509StoreContext)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2568(NetscapeSPKI)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:18(Version)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:36(EUCJPProber)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:33(GB2312Prober)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:34(CP949Prober)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:33(EUCTWProber)\n",
       "        1    0.000    0.000    0.000    0.000 langhebrewmodel.py:38(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 pyopenssl.py:102(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 crypto.py:205(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 escprober.py:35(EscCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:33(CodingStateMachine)\n",
       "        1    0.000    0.000    0.000    0.000 charsetgroupprober.py:32(CharSetGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:96(Latin1Prober)\n",
       "        1    0.000    0.000    0.000    0.000 utf8prober.py:35(UTF8Prober)\n",
       "        1    0.000    0.000    0.000    0.000 sjisprober.py:36(SJISProber)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:34(MultiByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:183(SJISContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:50(RequestField)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:28(RecentlyUsedContainer)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:122(PoolManager)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:8(is_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:87(RelaxedOneHotCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:32(_OpNamespace)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:69(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 chi2.py:6(Chi2)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:254(ReduceLROnPlateau)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:7(Warning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:960(ScriptModule)\n",
       "        3    0.000    0.000    0.000    0.000 rendezvous.py:13(register_rendezvous_handler)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:9(Upsample)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:7(PairwiseDistance)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:11(LocalResponseNorm)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:22(Dropout)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:713(SmoothL1Loss)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:318(ParameterList)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:29(MaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:723(LPPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:6(_InstanceNorm)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:460(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:7(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:190(Conv2d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:10(Threshold)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:818(Softmax)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:897(LogSoftmax)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:11(Linear)\n",
       "        4    0.000    0.000    0.000    0.000 utils.py:5(_ntuple)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(FilterDescriptor)\n",
       "        4    0.000    0.000    0.000    0.000 profiler.py:337(attr_formatter)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:23(THNNBackendBase)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(Function)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:131(Event)\n",
       "        1    0.000    0.000    0.042    0.042 __init__.py:134(init)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:336(_Stream)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:59(metaclass)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:866(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:1362(getmask)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:3350(dtype)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:6260(__has_singleton)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6284(__array_finalize__)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:177(_ndptr)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:20(Arrayterator)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:156(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 mixins.py:55(_unary_method)\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:115(NpzFile)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:231(AxisConcatenator)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:476(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:997(SafeEval)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2902(_setdef)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:44(_Outcome)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:16(BaseTestSuite)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:270(_ErrorHolder)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:76(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:85(format_parser)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:20(memmap)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:100(_str_xmax)\n",
       "        1    0.000    0.000    0.000    0.000 tz.py:206(utcoffset)\n",
       "        2    0.000    0.000    0.000    0.000 jsonutil.py:34(_ensure_tzinfo)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:207(send_multipart)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:242(extract_header)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:11(CNF_augment)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:255(ODEfunc_rl)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:114(_compare)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:17(NumpyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:13(HyperLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:180(ConcatSquashConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:6(BruteForceLayer)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:7(PlanarFlow)\n",
       "        1    0.000    0.000    0.000    0.000 dopri5.py:58(Dopri5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:5(Euler)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:61(VariableCoefficientAdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:7(OdeintAdjointMethod)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint_sep.py:7(OdeintAdjointMethod)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:9(Omniglot)\n",
       "        1    0.000    0.000    0.000    0.000 cnf.py:11(CNF)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:12(MNIST)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:221(Pad)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:306(Color3DLUT)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:55(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:413(close)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1114(get_parts_of_chained_exception)\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:188(iteritems)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:819(with_metaclass)\n",
       "        5    0.000    0.000    0.000    0.000 inspect.py:1254(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1982(createLock)\n",
       "        1    0.000    0.000    0.006    0.006 __init__.py:1056(_open)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:868(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:537(_generate_next_value_)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:106(_formatwarnmsg)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:794(fsencode)\n",
       "        4    0.000    0.000    0.000    0.000 _collections_abc.py:367(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._jit_init}\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:62(GradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:22(PaletteFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:294(StubImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:549(PyCodecState)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:188(iTXt)\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:249(DibImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:540(PngImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:678(_idat)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:209(PngInfo)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:822(_FieldSkipper)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:126(_SimpleSizer)\n",
       "        3    0.000    0.000    0.000    0.000 encoder.py:184(_FixedSizer)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:429(_SimpleEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:272(DebugMode)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:77(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:253(_Printer)\n",
       "        3    0.000    0.000    0.000    0.000 decoder.py:249(_ModifiedDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:288(_FloatDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:26(BottomMatcher)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:794(NegatedPattern)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:38(PatternCompiler)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:241(Py2Fixer)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:692(MultiprocessRefactoringTool)\n",
       "        1    0.000    0.000    0.000    0.000 driver.py:30(Driver)\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:23(Grammar)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:49(any)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:197(Untokenizer)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:347(DFAState)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:50(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:104(_calc_n_scale)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:68(Any)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:398(FieldMask)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:735(Struct)\n",
       "        3    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:843(FileDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:185(BaseContainer)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:41(EnumTypeWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:36(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 symbol_database.py:65(SymbolDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:607(EnumDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:94(DescriptorBase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:165(_NestedDescriptorBase)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:44(Node)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:4383(postParse)\n",
       "        1    0.000    0.000    0.004    0.004 pyparsing.py:4904(makeHTMLTags)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:205(ParseBaseException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2439(Keyword)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3064(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3066(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3130(LineStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3160(LineEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3184(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3199(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3591(Each)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3914(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3923(ZeroOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4141(Forward)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:42(_BaseVersion)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:15(InvalidSpecifier)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:18(InvalidRequirement)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:75(Requirement)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:139(MovedAttribute)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:229(_MovedItems)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:320(Module_six_moves_urllib_parse)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:451(Module_six_moves_urllib_robotparser)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1536(EmptyProvider)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1860(register_finder)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1907(find_nothing)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1989(NoDists)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2857(EggInfoDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:204(Data)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:595(_BinaryPlistParser)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:29(register_writer_factory)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:156(_EventLoggerThread)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:249(ResolutionError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:288(ContextualVersionConflict)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:141(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:138(DeprecatedImport)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:297(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:324(StructOrUnionOrEnum)\n",
       "        2    0.000    0.000    0.000    0.000 Image.py:2798(register_save_all)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:25(deferred_error)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:20(ModeDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:162(InceptionB)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:127(_DenseLayer)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:155(_Transition)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:5(Sampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:7(DistributedSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:26(TensorDataset)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:86(TqdmDefaultWriteLock)\n",
       "        1    0.000    0.000    0.000    0.000 _utils.py:123(Comparable)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:14(TMonitor)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:142(BoundedSemaphore)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:186(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:26(tqdm_gui)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:25(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:58(ResNeXt)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:24(VGG)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:13(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:55(BaseAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:141(SOCKSProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:267(_BaseSocket)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:44(TqdmWarning)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1755(FileCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1841(LWPCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:625(SimpleCookie)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:97(MockResponse)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:13(CaseInsensitiveDict)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:87(LookupDict)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:740(_Tellable)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1819(PyZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:830(CookiePolicy)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:418(_RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:31(PSS)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:32(_X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:119(IDEA)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:133(SEED)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(KeyDerivationFunction)\n",
       "        1    0.000    0.000    0.000    0.000 __version__.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:76(OCSPRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:175(OCSPResponseBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:23(_Integers)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:197(_DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:92(_ECDSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:108(_ECDSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:35(BlockCipherAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:76(AEADDecryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:86(AEADEncryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:164(_AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:228(_AEADEncryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:30(ModeWithInitializationVector)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:48(ModeWithNonce)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:131(OFB)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:146(CFB)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:161(CFB8)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:176(CTR)\n",
       "        1    0.000    0.000    0.000    0.000 cmac.py:16(_CMACContext)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ERR_clear_error}\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:41(GeneralName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:227(DirectoryName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:253(RegisteredID)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:142(Name)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:130(AuthorityInformationAccessOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:60(Hash)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:57(make_assert)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:622(ValueMap)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1572(Primitive)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1695(AbstractString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1776(Boolean)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1910(BitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2286(IntegerBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2370(OctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2448(IntegerOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4298(Set)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4671(GeneralizedTime)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:43(AlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:107(HmacAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:162(MaskGenAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:510(DSASignature)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:57(ExtensionNotFound)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:63(ExtensionType)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:114(CRLNumber)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:781(NoticeReference)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1165(GeneralNames)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1245(IssuerAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1280(CertificateIssuer)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:74(RSAPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:116(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:136(_ECPoint)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:252(Pentanomial)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:301(Curve)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:886(EncryptedPrivateKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:944(PublicKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:33(HashBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:48(HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:79(PBKDF2HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:253(DERSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:389(ScryptBackend)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:431(CertificateBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:598(CertificateRevocationListBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:23(DSAParametersWithNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:39(EllipticCurveSignatureAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1682(X509StoreContextError)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2336(PKCS7)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:34(EUCKRProber)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:34(Big5Prober)\n",
       "        1    0.000    0.000    0.000    0.000 sbcsgroupprober.py:43(SBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 langgreekmodel.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langthaimodel.py:37(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langbulgarianmodel.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langturkishmodel.py:37(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:12(RequestException)\n",
       "        2    0.000    0.000    0.000    0.000 exceptions.py:40(SSLError)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:204(_X509NameInvalidator)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:17(LanguageFilter)\n",
       "        1    0.000    0.000    0.000    0.000 euctwfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:40(CharDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:132(EUCKRDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 euckrfreq.py:41(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 big5freq.py:43(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:116(JapaneseContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 request.py:10(RequestMethods)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:22(DeflateDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:10(LifoQueue)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:362(ProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:223(HTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:29(is_prod_appengine_mvms)\n",
       "        1    0.000    0.000    0.000    0.000 alexnet.py:13(AlexNet)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:55(ConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:207(IncompleteRead)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:117(__getattr__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:6(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(CUDAModule)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:217(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:290(ExpTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:340(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:379(AffineTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:472(StickBreakingTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:514(LowerCholeskyTransform)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:123(_IntegerLessThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:183(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:211(_Interval)\n",
       "        1    0.000    0.000    0.000    0.000 exp_family.py:5(ExponentialFamily)\n",
       "        1    0.000    0.000    0.000    0.000 constraint_registry.py:79(ConstraintRegistry)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1292(TracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1354(_ConstModuleList)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1465(_disable_tracing)\n",
       "        2    0.000    0.000    0.000    0.000 annotations.py:15(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:5(Adamax)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:5(SGD)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:6(Rprop)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:5(RMSprop)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:6(LBFGS)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:10(_LRScheduler)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:56(LambdaLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:126(StepLR)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:42(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:45(DupFd)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:61(_ResourceSharer)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:40(SpawnContext)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:549(TracerWarning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:649(CompilationUnit)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:817(OrderedModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:868(OrderedBufferDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1164(WeakScriptModuleProxy)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:29(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:142(reduce_op)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:5(Adagrad)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:6(Adam)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:8(WeightNorm)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:9(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:147(SpectralNormLoadStateDictPreHook)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:6(Fold)\n",
       "        1    0.000    0.000    0.000    0.000 adaptive.py:15(AdaptiveLogSoftmaxWithLoss)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:35(DataParallel)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:9(Broadcast)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:35(ReduceAddCoalesced)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:50(Gather)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:134(InstanceNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:210(InstanceNorm3d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:165(GroupNorm)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:6(_DropoutNd)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:61(Dropout2d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:105(Dropout3d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(ConstantPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:75(ConstantPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:270(_ReplicationPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:537(RNNCellBase)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:96(NLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:223(PoissonNLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:289(KLDivLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:370(MSELoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:438(BCELoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:507(BCEWithLogitsLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:598(HingeEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:773(SoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:815(CrossEntropyLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:907(MultiLabelSoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:954(CosineEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1112(TripletMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1188(CTCLoss)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:11(Container)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:22(Sequential)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:96(ModuleList)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:9(_MaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:84(MaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:444(AvgPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:568(AvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:647(FractionalMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:766(LPPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:822(_AdaptiveMaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:838(AdaptiveMaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:863(AdaptiveMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:899(AdaptiveMaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:948(AdaptiveAvgPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:1005(AdaptiveAvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:246(BatchNorm3d)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:444(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:11(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:12(_ConvNd)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:69(Conv1d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:323(Conv3d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:451(_ConvTransposeMixin)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:509(ConvTranspose1d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:617(ConvTranspose2d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:760(ConvTranspose3d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:89(RReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:210(ReLU6)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:269(Tanh)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:295(ELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:380(SELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:425(GLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:459(Hardshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:576(Softplus)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:663(PReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:728(Softsign)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:754(Tanhshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:780(Softmin)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:868(Softmax2d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:27(L1Loss)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:5(Parameter)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:75(Bilinear)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:204(TensorDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:226(TensorDescriptorArray)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:377(FunctionEvent)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:5(no_grad)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:4(detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:24(EventList)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:10(_ContextMethodMixin)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:61(_HookMixin)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:108(Function)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:18(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:7(RemovableHandle)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:237(device_of)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:8(__PrinterOptions)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:8048(_convert2ma)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1443(MAxisConcatenator)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1489(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:796(_DomainCheckInterval)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:976(_MaskedBinaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(_replace_dtype_fields_recursive)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2378(_MaskedPrintOption)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:3366(shape)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6557(_frommethod)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:206(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:208(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:224(_FFTCache)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:138(_FileOpeners)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:621(Repository)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:170(LineSplitter)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:14(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:28(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:55(_NoValueType)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:204(dummy_ctype)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:98(nd_grid)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:446(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:481(ndenumerate)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:531(ndindex)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:653(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 function_base.py:1760(vectorize)\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:15(DummyArray)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1212(_Dummy)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1858(clear_and_catch_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:115(NoseTester)\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:47(PytestTester)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:159(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 _inspect.py:145(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:184(_AssertRaisesContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:221(_AssertWarnsContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1338(FunctionTestCase)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1396(_SubTest)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:92(TestSuite)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:23(_FailedTest)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:304(recarray)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:17(MachAr)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:104(_str_resolution)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:305(finfo)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:440(_recursive_guard)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:810(FloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1202(DatetimeFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1249(StructuredVoidFormat)\n",
       "        1    0.000    0.000    0.000    0.000 tz.py:250(_isdst)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:509(msg_id)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate_sep.py:20(CNF_Gate_Sep)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:73(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:94(ODEnet)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:40(AverageMeter)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:9(_ActNorm)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:83(ActNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:95(LinearZeros)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:170(Permute2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:194(InvertibleConv1x1)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:291(Split2d)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:21(PytestTester)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:78(_compare_version)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:136(__lt__)\n",
       "        4    0.000    0.000    0.000    0.000 six.py:67(_add_doc)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:38(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:6(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:128(MovingBatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:7(CouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:6(FeedforwardGateI)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:46(FeedforwardGateII)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:4(SequentialFlow_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:15(Midpoint)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:26(RK4)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:208(AdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:63(Swish)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:94(ODEnet)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:176(AutoencoderDiffEqNet)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:255(ODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:7(SequentialDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:21(MixtureODELayer)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:7(DiffEqWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:29(ReshapeDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:17(SEMEION)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:8(ZeroMeanTransform)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:25(LogitTransform)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:4(SequentialFlow)\n",
       "        1    0.000    0.000    0.000    0.000 tsit5.py:66(Tsit5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:179(EMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 fakedata.py:6(FakeData)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:31(Compose)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:149(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(RandomApply)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:360(RandomCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:436(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:429(RandomHorizontalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:481(RandomResizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:567(FiveCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:606(TenCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:649(LinearTransformation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:695(ColorJitter)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:767(RandomRotation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:834(RandomAffine)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:954(Grayscale)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:43(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:136(ModeFilter)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:39(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1115(get_chained_exception)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1211(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 configurable.py:381(instance)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:136(_get_args)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'pack' of 'Struct' objects}\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:19(encode)\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:60(safe_unicode)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:824(metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method binascii.b2a_hex}\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:98(checkgroup)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:287(seek)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:203(_cleanup)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:185(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rstrip' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'title' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'index' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rjust' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getCompiledVersion}\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:24(GimpPaletteFile)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:103(GimpGradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:48(PpmImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 TiffTags.py:23(TagInfo)\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:372(_VarintEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:387(_SignedVarintEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:470(_ModifiedEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:80(PackTag)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:28(BaseOldDict)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:14(BaseOldStr)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:73(Error)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:92(TypeChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:113(TypeCheckerWithDefault)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:125(IntValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:146(EnumValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:166(UnicodeValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:194(Int32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:202(Uint32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:208(Int64ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:214(Uint64ValueChecker)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:107(_VarintDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:501(LeafPattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:545(NodePattern)\n",
       "        1    0.000    0.000    0.000    0.000 pygram.py:20(Symbols)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:24(PatternSyntaxError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:457(hooks)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:16(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:43(_EveryNode)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:167(FixerError)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:166(StopTokenizing)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:337(NFAState)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:193(StackedCNFLayers)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:72(Node_py_OP)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:1056(Default)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:38(Error)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:46(DescriptorDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:47(MessageFactory)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:60(Error)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:64(ParseError)\n",
       "        2    0.000    0.000    0.000    0.000 versions_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:19(Node_base)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:38(Node_py)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:672(EnumValueDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:712(OneofDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:748(ServiceDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:39(Error)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:41(EncodeError)\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:42(GeneratedProtocolMessageType)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:65(Value)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:71(Op)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:272(Marker)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:51(Error)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:64(DescriptorMetaclass)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:76(_Lock)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:31(UndefinedComparison)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:25(InvalidMarker)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:37(UndefinedEnvironmentName)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:59(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4226(TokenConverter)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4234(Combine)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4278(Group)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4299(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4390(OnlyOnce)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:261(ParseException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:282(ParseFatalException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:287(ParseSyntaxException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:306(RecursiveGrammarException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:314(_ParseResultsWithOffset)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:666(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1455(_UnboundedCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1478(_FifoCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2364(Token)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2372(Empty)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2383(NoMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2398(Literal)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2504(CaselessLiteral)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2545(CloseMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2606(Word)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2838(QuotedString)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2975(CharsNotIn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3104(GoToColumn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3180(StringStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3213(WordStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3233(WordEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3384(_ErrorStop)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:3461(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3444(Or)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3792(FollowedBy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3818(NotAny)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3850(_MultipleMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3888(OneOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4026(SkipTo)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4222(_ForwardNoRecurse)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:36(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:27(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:183(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:195(_Constants)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:360(Module_six_moves_urllib_error)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:380(Module_six_moves_urllib_request)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:430(Module_six_moves_urllib_response)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1549(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1556(ZipManifests)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1817(PathMetadata)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1842(EggMetadata)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2946(RequirementParseError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3165(PkgResourcesDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:79(_InternalDict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:109(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:416(_DumbXMLWriter)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:454(_PlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:587(InvalidFileException)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:89(S3RecordWriterFactory)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:104(RecordWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(PEP440Warning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:905(subscribe)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:937(_ReqExtras)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1107(ExtractionError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1127(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1044(LstsqLapackError)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:22(SqrtmError)\n",
       "        1    0.000    0.000    0.000    0.000 misc.py:11(LinAlgWarning)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(FFIError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:5(CDefError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:16(VerificationError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:20(VerificationMissing)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:72(BaseType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:88(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:85(VoidType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:178(UnknownIntegerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:192(UnknownFloatType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:204(BaseFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:224(RawFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:239(FunctionPtrType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:261(PointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:278(ConstPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:284(NamedPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:293(ArrayType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:475(StructType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:483(EnumType)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:47(DatasetFolder)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:7(CocoCaptions)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:174(CIFAR100)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:40(DecompressionBombWarning)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:44(DecompressionBombError)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:48(_imaging_not_installed)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:479(_E)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2282(ImagePointHandler)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2287(ImageTransformHandler)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:17(Fire)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:40(SqueezeNet)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:33(Inception3)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:130(InceptionA)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:185(InceptionC)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:224(InceptionD)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:250(InceptionE)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:292(InceptionAux)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:317(BasicConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:147(_DenseBlock)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:165(DenseNet)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:14(LSUNClass)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:23(SequentialSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:40(RandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:79(SubsetRandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:96(WeightedRandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:8(Dataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:90(Subset)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:39(ExceptionWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:86(ManagerWatchdog)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:62(TqdmDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:67(TqdmMonitorWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:95(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:123(Semaphore)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:159(Lock)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:184(RLock)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:57(Bottleneck)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:96(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:174(RequestHooksMixin)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:198(Request)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:72(AuthBase)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:79(HTTPBasicAuth)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:100(HTTPProxyAuth)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:59(SOCKSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:129(SOCKSHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:133(SOCKSHTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:137(SOCKSHTTPSConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:110(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:123(GeneralProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:139(SOCKS4Error)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:36(TqdmTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:57(TqdmExperimentalWarning)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1753(LoadError)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:150(CookieError)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:165(CookieConflictError)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:43(BadZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:47(LargeZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:595(LZMACompressor)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:618(LZMADecompressor)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:714(_SharedFile)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1222(Absent)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(PKCS1v15)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:49(OAEP)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:62(MGF1)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:13(_X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:113(_SingleResponse)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:272(_RSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:299(_RSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:186(_X509ExtensionParser)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:36(_DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:47(_DSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:68(_DSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:84(_DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2099(GetCipherByName)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:67(AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:141(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:39(ModeWithTweak)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:57(ModeWithAuthenticationTag)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:124(ECB)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:426(_ALPNSelectHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:477(_OCSPServerCallbackHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:549(_OCSPClientCallbackHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:673(Session)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.RAND_cleanup}\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:118(_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:239(Error)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:249(WantReadError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:253(WantWriteError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:257(WantX509LookupError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:261(ZeroReturnError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:265(SysCallError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:269(_CallbackExceptionHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:336(_NpnAdvertiseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ASN1_STRING_set_default_mask_asc}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_finish}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_free}\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:154(_verify_openssl_version)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:46(cryptography_has_ssl3_method)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:135(cryptography_has_ssl_st)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:198(BestAvailableEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:207(NoEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:35(UnsupportedGeneralNameType)\n",
       "        1    0.000    0.000    0.000    0.000 package_data.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:16(IDNAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:26(InvalidCodepoint)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:31(InvalidCodepointContext)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:42(OCSPExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:104(SHA1)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:111(SHA224)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:118(SHA256)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:125(SHA384)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:132(SHA512)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:139(MD5)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'gc' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 core.py:693(Constructable)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1829(Integer)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2665(ParsableOctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2940(ObjectDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2956(Real)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3032(UTF8String)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4484(SetOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4517(EmbeddedPdv)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4525(NumericString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4534(PrintableString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4543(TeletexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4569(AbstractTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4615(UTCTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4763(GeneralString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4773(UniversalString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4782(CharacterString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4792(BMPString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:14(TeletexCodec)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:23(TeletexIncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:29(TeletexIncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:35(TeletexStreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:146(Codec)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:218(IncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:253(IncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:292(StreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:30(LibraryNotFoundError)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:39(FFIEngineError)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:120(HmacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:127(DigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:141(DigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:149(DigestInfo)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:156(MaskGenAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:174(TrailerField)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:365(Pbkdf2Salt)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:372(Pbkdf2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:381(KdfAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:387(KdfAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:398(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:417(KeyExchangeAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:428(Rc2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:435(Rc5ParamVersion)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:441(Rc5Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:450(Pbes1Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:457(PSourceAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:463(PSourceAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1084(Pbes2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1091(Pbmac1Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1098(Pkcs5MacId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1104(Pkcs5MacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1119(AnyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1129(AnyAlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:852(OCSPNoCheck)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:857(PrecertPoison)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:66(OtherPrimeInfos)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:105(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:206(ECPoint)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:216(SpecifiedECDomainVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:227(FieldType)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:239(CharacteristicTwoBasis)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:284(FieldID)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:396(ECPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:407(ECPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:420(DSAParams)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:435(Attribute)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:446(Attributes)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:454(PrivateKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:473(PrivateKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:899(ValidationParms)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:910(DomainParameters)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:924(PublicKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:24(UnsupportedAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:34(AlreadyUpdated)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:38(NotYetFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:42(InvalidTag)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:46(InvalidSignature)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(InternalError)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:51(DuplicateExtension)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:390(CertificateSigningRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(register_interface_if)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:79(InterfaceNotImplemented)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:115(_DeprecatedValue)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:145(SECT571R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:163(SECT233R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:169(SECT163R2)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:175(SECT571K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:181(SECT409K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:193(SECT233K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:205(SECP521R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:211(SECP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:217(SECP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:223(SECP256K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:235(SECP192R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:241(BrainpoolP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:247(BrainpoolP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:253(BrainpoolP512R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:288(ECDSA)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:420(ECDH)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:16(CryptographyDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:73(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:28(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:36(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:44(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:53(ConnectTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:60(ReadTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:64(URLRequired)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:68(TooManyRedirects)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:76(InvalidSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:80(InvalidURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:88(InvalidProxyURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:96(ContentDecodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:119(FileModeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:124(RequestsDependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:54(UnsupportedExtension)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:76(Error)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:8(InputState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:32(ProbingState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:41(MachineState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:50(SequenceLikelihood)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:65(CharacterCategory)\n",
       "        1    0.000    0.000    0.000    0.000 mbcsgroupprober.py:41(MBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:151(GB2312DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:170(Big5DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:192(SJISDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:217(EUCJPDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312freq.py:42(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jisfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:212(EUCJPContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:55(GzipDecoderState)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:62(GzipDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:65(DummyConnection)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:263(VerifiedHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:14(is_appengine_sandbox)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:23(is_prod_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:8(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:13(HTTPWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:18(PoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:29(RequestError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:55(ProtocolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:66(MaxRetryError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:85(HostChangedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:94(TimeoutStateError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:120(NewConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:125(EmptyPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:140(LocationParseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:161(SubjectAltNameWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:166(InsecureRequestWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:171(SystemTimeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:176(InsecurePlatformWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:181(SNIMissingWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:186(DependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:199(BodyNotHttplibCompatible)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:223(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:228(ProxySchemeUnknown)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:237(HeaderParsingError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:5(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:28(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:68(_Ops)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:362(AbsTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:446(SoftmaxTransform)\n",
       "        1    0.000    0.000    0.000    0.000 kl.py:77(_Match)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:49(Constraint)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:67(_Dependent)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:98(_Boolean)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:106(_IntegerInterval)\n",
       "        2    0.000    0.000    0.000    0.000 constraints.py:143(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:139(_IntegerGreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:155(_Real)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:167(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:163(_GreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:179(_GreaterThanEq)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:195(_LessThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:215(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:228(_HalfOpenInterval)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:245(_Simplex)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:254(_LowerTriangular)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:263(_LowerCholesky)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:291(_RealVector)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:105(lazy_property)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1349(TopLevelTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1384(_ConstSequential)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:90(FrontendError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:102(NotSupportedError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:106(UnsupportedNodeError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:152(SourceContext)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:158(Builder)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:14(Module)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:6(SparseAdam)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:6(ASGD)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:198(ExponentialLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:217(CosineAnnealingLR)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:20(StorageWeakRef)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:13(ExportTypes)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:234(LegacyTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:408(TracingCheckError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:847(OrderedParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:926(ScriptMeta)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:71(reduce_op)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:93(group)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:97(GroupMember)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(dist_backend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:153(_DistributedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:9(_RequiredParameter)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:177(SpectralNormStateDictHook)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:143(UpsamplingNearest2d)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:188(UpsamplingBilinear2d)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:78(Scatter)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:58(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:149(AlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:193(FeatureAlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:130(ConstantPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:166(_ReflectionPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:178(ReflectionPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:220(ReflectionPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:282(ReplicationPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:321(ReplicationPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:370(ReplicationPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:406(ZeroPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:232(RNN)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:333(LSTM)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:441(GRU)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:585(RNNCell)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:658(LSTMCell)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:736(GRUCell)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:213(NLLLoss2d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1001(MarginRankingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1049(MultiMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:151(MaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:222(_MaxUnpoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:231(MaxUnpool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:297(MaxUnpool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:371(MaxUnpool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:434(_AvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:502(AvgPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:707(_LPPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:936(_AdaptiveAvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:971(AdaptiveAvgPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:98(BatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:172(BatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:443(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:464(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:6(VFModule)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:59(ReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:146(Hardtanh)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:242(Sigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:501(LeakyReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:551(LogSigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:12(_Loss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:21(_WeightedLoss)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:196(BroadcastingListCls)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:160(flags_frozen)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:187(CuDNNHandle)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:197(CuDNNError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:277(DropoutDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:321(RNNDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:360(Interval)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:407(FunctionEventAvg)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:431(StringTable)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:497(EnforceUnique)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:7(Type)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:25(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:47(enable_grad)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:91(set_grad_enabled)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:75(set_detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:12(range)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:225(emit_nvtx)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:79(FunctionMeta)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:242(InplaceFunction)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:249(_nested_map)\n",
       "        1    0.000    0.000    0.000    0.000 thnn.py:4(THNNFunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:4(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(FunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:6(Backends)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(THNNCudaBackendStateMixin)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(Argument)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:5(VariableMeta)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:10(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:73(_check_driver)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:130(DeferredCudaCallError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:195(cudaStatus)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:200(CudaError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:211(device)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:499(_CudaBase)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:514(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:522(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:526(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:530(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:275(TarError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:278(ExtractError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:284(CompressionError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:287(StreamError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:290(HeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:293(EmptyHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:305(SubsequentHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:582(_StreamProxy)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:716(ExFileObject)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:68(_Formatter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:218(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:32(SourceChangeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:218(_fromnxfunction)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:273(_fromnxfunction_single)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:304(_fromnxfunction_args)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:329(_fromnxfunction_allargs)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1473(mr_class)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:194(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:198(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:202(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:206(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:829(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(_DomainTan)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:845(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:839(_DomainSafeDivide)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:860(_DomainGreater)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:882(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:876(_DomainGreaterEqual)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:892(_MaskedUFunc)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:902(_MaskedUnaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1124(_DomainedBinaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2384(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:95(MaskedArrayFutureWarning)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:166(MAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:174(MaskError)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:58(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:62(PolyError)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:66(PolyDomainError)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:472(ConverterLockError)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:480(ConversionWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:13(RTLD_for_MKL)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_typeDict}\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:339(PackageLoaderDebug)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:239(_missing_ctypes)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:22(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:351(RClass)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:451(CClass)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:609(IndexExpression)\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:44(LinAlgError)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:13(_WritelnDecorator)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:9(_InterruptHandler)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(KnownFailureException)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1816(IgnoreException)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:57(_Deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:99(skipif)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:683(TooHardError)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:686(AxisError)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:750(_typedict)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:83(ComplexWarning)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2817(_unspecified)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:128(_BaseTestCaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:137(_AssertRaisesBaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:278(_CapturingHandler)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:297(_AssertLogsContext)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:317(_DebugResult)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:92(_str_epsneg)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:33(_ShouldStop)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:38(_UnexpectedSuccess)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:953(FloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:960(LongFloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1109(IntegerFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1122(BoolFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1132(ComplexFloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1161(ComplexFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1176(_TimelikeFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1239(SubArrayFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1286(StructureFormat)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:33(ModuleDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:45(VisibleDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:63(Swish)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:176(AutoencoderDiffEqNet)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:321(AutoencoderODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(RunningAverageMeter)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:115(ParallelSumModules)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:126(ParallelCNFLayers)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:152(Conv2dZeros)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:347(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:16(FPUModeChangeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:9(CData)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:45(ConcatLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:56(ConcatLinear_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:66(SquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:76(ConcatSquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:88(HyperConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:124(IgnoreConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:137(SquashConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:151(ConcatConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:166(ConcatConv2d_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:196(ConcatCoordConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:214(GatedLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:226(GatedConv)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:242(GatedConvTranspose)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:260(BlendLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:272(BlendConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:134(MovingBatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:51(MaskedCouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:89(FeedforwardGateIII)\n",
       "        1    0.000    0.000    0.000    0.000 rk_common.py:8(_RungeKuttaState)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:18(_VCABMState)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:73(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:316(AutoencoderODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:9(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:43(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:155(FashionMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:61(ToTensor)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:82(ToPILImage)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:120(Normalize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:182(Scale)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:192(CenterCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:271(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:289(RandomTransforms)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:341(RandomOrder)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:352(RandomChoice)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:455(RandomVerticalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:557(RandomSizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:984(RandomGrayscale)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:24(_Enhance)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:40(Color)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:58(Contrast)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:74(Brightness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:28(Filter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:32(MultibandFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:36(BuiltinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:71(RankFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:94(MedianFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:108(MinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:122(MaxFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:153(GaussianBlur)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:187(UnsharpMask)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:212(BLUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:223(CONTOUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:232(DETAIL)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:241(EDGE_ENHANCE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:250(EDGE_ENHANCE_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:268(FIND_EDGES)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:286(SMOOTH)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:295(SMOOTH_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:124(synchronize_with_editor)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:45(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:196(get_start_method)\n",
       "        1    0.000    0.000    0.000    0.000 interactiveshell.py:1138(_get_call_pdb)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:422(is_recursion_error)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:595(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:2071(_match_arguments_partial)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:743(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1366(_internal_poll)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:101(checklookbehindgroup)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:22(constructor)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:337(__members__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
       "        1    0.000    0.000    0.000    0.000 {method '__prepare__' of 'type' objects}\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:155(_ModifiedSizer)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:33(basestring)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:323(_DoubleDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:688(MultiprocessingUnsupported)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:164(TokenError)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:7(PgenGrammar)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:63(Node_py_IO)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:42(DescriptorDatabaseConflictingDefinitionError)\n",
       "        2    0.000    0.000    0.000    0.000 api_implementation.py:136(Type)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:40(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:55(TypeTransformationError)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4364(Suppress)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:328(UnknownExtra)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:479(UnionType)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:127(ProxyConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:131(SOCKS5AuthError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:135(SOCKS5Error)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:143(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:40(TqdmKeyError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:377(_NpnSelectHelper)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:151(cryptography_has_locking_callbacks)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:193(KeySerializationEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:21(IDNABidiError)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:62(openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:649(Castable)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2948(InstanceOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3041(RelativeOid)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4552(VideotexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4560(IA5String)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4744(GraphicString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4754(VisibleString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:40(TeletexStreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:295(StreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:411(KeyExchangeAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:211(ECPointBitString)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:30(AlreadyFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:56(InvalidKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:151(SECT409R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:157(SECT283R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:187(SECT283K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:199(SECT163K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:229(SECP224R1)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:32(ConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:72(MissingSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:84(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:92(ChunkedEncodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:100(StreamConsumedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:104(RetryError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:114(RequestsWarning)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:13(NoWayToWaitForSocketError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:45(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:99(TimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(ReadTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:115(ConnectTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:130(ClosedPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:135(LocationValueError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:150(ResponseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:156(SecurityWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:194(ResponseNotChunked)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:244(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:80(_DependentProperty)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:277(_PositiveDefinite)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:119(FrontendTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:149(group)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:369(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:72(BackwardCFunction)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:510(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:518(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:534(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:538(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:281(ReadError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:296(TruncatedHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:299(EOFHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:302(InvalidHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:222(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:28(prepare_multiprocessing_environment)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:291(_fromnxfunction_seq)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:214(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1329(make_mask_descr)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:79(PolyBase)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:464(ConverterError)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:25(SkipTest)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1168(LongComplexFormat)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:89(Sharpness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:259(EMBOSS)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:277(SHARPEN)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        1    0.000    0.000    0.000    0.000 configurable.py:426(initialized)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_cifar10_bs8K_rl_stdlearnscale_30_annealing_run3 --seed 3 --conditional False --lr 0.01 --warmup_iters 1000 --atol 1e-4  --rtol 1e-4 --scale_fac 1.0 --gate cnn2 --scale_std 15.0 --max_grad_norm 20.0 --annealing_std True\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
