{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, conditional=False, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume=None, rtol=1e-05, save='../experiments_published/cnf_cifar10_published_baseline_bs900_2', seed=2, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=6144, bias=True)\n",
      "  (project_class): LinearZeros(in_features=3072, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1469494\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 0010 | Time 13.5481(30.6082) | Bit/dim 8.9792(9.3246) | Xent 0.0000(0.0000) | Loss 8.9792(9.3246) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 18.1431(22.2089) | Total Time 14.00(14.00)\n",
      "Iter 0020 | Time 13.0904(26.0404) | Bit/dim 8.5826(9.1872) | Xent 0.0000(0.0000) | Loss 8.5826(9.1872) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 8.1499(19.4377) | Total Time 14.00(14.00)\n",
      "Iter 0030 | Time 13.0643(22.6553) | Bit/dim 8.4243(9.0167) | Xent 0.0000(0.0000) | Loss 8.4243(9.0167) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 4.5973(15.4489) | Total Time 14.00(14.00)\n",
      "Iter 0040 | Time 13.5986(20.2089) | Bit/dim 8.2522(8.8318) | Xent 0.0000(0.0000) | Loss 8.2522(8.8318) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 2.7265(12.4168) | Total Time 14.00(14.00)\n",
      "Iter 0050 | Time 13.2989(18.3643) | Bit/dim 8.0304(8.6391) | Xent 0.0000(0.0000) | Loss 8.0304(8.6391) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 2.9587(9.8333) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 83.0078, Epoch Time 850.0270(850.0270), Bit/dim 7.8660(best: inf), Xent 0.0000, Loss 7.8660, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0060 | Time 13.0533(17.0193) | Bit/dim 7.7972(8.4378) | Xent 0.0000(0.0000) | Loss 7.7972(8.4378) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 2.7398(7.9288) | Total Time 14.00(14.00)\n",
      "Iter 0070 | Time 13.4088(15.9790) | Bit/dim 7.4910(8.2208) | Xent 0.0000(0.0000) | Loss 7.4910(8.2208) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 2.1641(6.4833) | Total Time 14.00(14.00)\n",
      "Iter 0080 | Time 12.8030(15.1826) | Bit/dim 7.2824(7.9941) | Xent 0.0000(0.0000) | Loss 7.2824(7.9941) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 1.5426(5.2989) | Total Time 14.00(14.00)\n",
      "Iter 0090 | Time 12.9100(14.6304) | Bit/dim 7.1438(7.7836) | Xent 0.0000(0.0000) | Loss 7.1438(7.7836) | Error 0.0000(0.0000) Steps 574(574.00) | Grad Norm 1.3863(4.3124) | Total Time 14.00(14.00)\n",
      "Iter 0100 | Time 13.0087(14.2224) | Bit/dim 7.0903(7.6050) | Xent 0.0000(0.0000) | Loss 7.0903(7.6050) | Error 0.0000(0.0000) Steps 580(575.30) | Grad Norm 0.9465(3.4909) | Total Time 14.00(14.00)\n",
      "Iter 0110 | Time 13.2990(13.9570) | Bit/dim 7.0216(7.4573) | Xent 0.0000(0.0000) | Loss 7.0216(7.4573) | Error 0.0000(0.0000) Steps 580(576.53) | Grad Norm 0.6432(2.7804) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 75.8574, Epoch Time 814.0925(848.9489), Bit/dim 7.0191(best: 7.8660), Xent 0.0000, Loss 7.0191, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0120 | Time 13.5291(13.8867) | Bit/dim 6.9992(7.3381) | Xent 0.0000(0.0000) | Loss 6.9992(7.3381) | Error 0.0000(0.0000) Steps 592(580.03) | Grad Norm 0.4034(2.1792) | Total Time 14.00(14.00)\n",
      "Iter 0130 | Time 14.3259(14.0268) | Bit/dim 6.9712(7.2415) | Xent 0.0000(0.0000) | Loss 6.9712(7.2415) | Error 0.0000(0.0000) Steps 604(585.30) | Grad Norm 0.3740(1.7094) | Total Time 14.00(14.00)\n",
      "Iter 0140 | Time 14.8246(14.1804) | Bit/dim 6.8979(7.1611) | Xent 0.0000(0.0000) | Loss 6.8979(7.1611) | Error 0.0000(0.0000) Steps 610(590.90) | Grad Norm 0.3745(1.3633) | Total Time 14.00(14.00)\n",
      "Iter 0150 | Time 14.6233(14.3075) | Bit/dim 6.8621(7.0891) | Xent 0.0000(0.0000) | Loss 6.8621(7.0891) | Error 0.0000(0.0000) Steps 610(595.92) | Grad Norm 0.4215(1.1191) | Total Time 14.00(14.00)\n",
      "Iter 0160 | Time 14.7580(14.4172) | Bit/dim 6.8211(7.0249) | Xent 0.0000(0.0000) | Loss 6.8211(7.0249) | Error 0.0000(0.0000) Steps 610(599.61) | Grad Norm 0.6522(0.9511) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 79.6369, Epoch Time 890.6176(850.1990), Bit/dim 6.7759(best: 7.0191), Xent 0.0000, Loss 6.7759, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0170 | Time 14.3235(14.4405) | Bit/dim 6.7321(6.9560) | Xent 0.0000(0.0000) | Loss 6.7321(6.9560) | Error 0.0000(0.0000) Steps 610(602.34) | Grad Norm 0.6488(0.8444) | Total Time 14.00(14.00)\n",
      "Iter 0180 | Time 15.4271(14.5975) | Bit/dim 6.5723(6.8790) | Xent 0.0000(0.0000) | Loss 6.5723(6.8790) | Error 0.0000(0.0000) Steps 622(605.71) | Grad Norm 1.3039(0.8379) | Total Time 14.00(14.00)\n",
      "Iter 0190 | Time 15.7798(14.9076) | Bit/dim 6.3840(6.7745) | Xent 0.0000(0.0000) | Loss 6.3840(6.7745) | Error 0.0000(0.0000) Steps 640(612.78) | Grad Norm 18.4777(1.9040) | Total Time 14.00(14.00)\n",
      "Iter 0200 | Time 15.7740(15.2415) | Bit/dim 6.1427(6.6476) | Xent 0.0000(0.0000) | Loss 6.1427(6.6476) | Error 0.0000(0.0000) Steps 646(620.78) | Grad Norm 4.3442(7.2899) | Total Time 14.00(14.00)\n",
      "Iter 0210 | Time 17.4065(15.6393) | Bit/dim 5.9516(6.4879) | Xent 0.0000(0.0000) | Loss 5.9516(6.4879) | Error 0.0000(0.0000) Steps 682(631.10) | Grad Norm 11.2396(9.1209) | Total Time 14.00(14.00)\n",
      "Iter 0220 | Time 17.6966(16.2633) | Bit/dim 5.8210(6.3209) | Xent 0.0000(0.0000) | Loss 5.8210(6.3209) | Error 0.0000(0.0000) Steps 706(650.35) | Grad Norm 4.4254(8.7995) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 90.2417, Epoch Time 997.3640(854.6140), Bit/dim 5.7977(best: 6.7759), Xent 0.0000, Loss 5.7977, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0230 | Time 16.6866(16.5899) | Bit/dim 5.7041(6.1721) | Xent 0.0000(0.0000) | Loss 5.7041(6.1721) | Error 0.0000(0.0000) Steps 670(662.39) | Grad Norm 5.8440(8.5890) | Total Time 14.00(14.00)\n",
      "Iter 0240 | Time 17.2562(16.7742) | Bit/dim 5.6391(6.0434) | Xent 0.0000(0.0000) | Loss 5.6391(6.0434) | Error 0.0000(0.0000) Steps 676(666.11) | Grad Norm 1.3305(7.0750) | Total Time 14.00(14.00)\n",
      "Iter 0250 | Time 16.2137(16.6428) | Bit/dim 5.6299(5.9405) | Xent 0.0000(0.0000) | Loss 5.6299(5.9405) | Error 0.0000(0.0000) Steps 640(663.92) | Grad Norm 1.4165(5.6058) | Total Time 14.00(14.00)\n",
      "Iter 0260 | Time 16.5700(16.5623) | Bit/dim 5.5832(5.8520) | Xent 0.0000(0.0000) | Loss 5.5832(5.8520) | Error 0.0000(0.0000) Steps 652(661.35) | Grad Norm 1.1777(4.6939) | Total Time 14.00(14.00)\n",
      "Iter 0270 | Time 16.6699(16.4265) | Bit/dim 5.5362(5.7803) | Xent 0.0000(0.0000) | Loss 5.5362(5.7803) | Error 0.0000(0.0000) Steps 646(657.60) | Grad Norm 1.9016(3.9778) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 83.5298, Epoch Time 1015.6326(859.4445), Bit/dim 5.5353(best: 5.7977), Xent 0.0000, Loss 5.5353, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0280 | Time 15.4438(16.1958) | Bit/dim 5.5262(5.7188) | Xent 0.0000(0.0000) | Loss 5.5262(5.7188) | Error 0.0000(0.0000) Steps 634(651.69) | Grad Norm 1.1454(3.7007) | Total Time 14.00(14.00)\n",
      "Iter 0290 | Time 15.6340(16.0863) | Bit/dim 5.4167(5.6575) | Xent 0.0000(0.0000) | Loss 5.4167(5.6575) | Error 0.0000(0.0000) Steps 634(647.89) | Grad Norm 2.8609(3.4747) | Total Time 14.00(14.00)\n",
      "Iter 0300 | Time 15.9967(16.1195) | Bit/dim 5.4291(5.5988) | Xent 0.0000(0.0000) | Loss 5.4291(5.5988) | Error 0.0000(0.0000) Steps 664(649.35) | Grad Norm 8.3011(4.0616) | Total Time 14.00(14.00)\n",
      "Iter 0310 | Time 16.6515(16.1059) | Bit/dim 5.3124(5.5358) | Xent 0.0000(0.0000) | Loss 5.3124(5.5358) | Error 0.0000(0.0000) Steps 676(652.10) | Grad Norm 8.4981(4.3481) | Total Time 14.00(14.00)\n",
      "Iter 0320 | Time 17.3433(16.2070) | Bit/dim 5.2833(5.4791) | Xent 0.0000(0.0000) | Loss 5.2833(5.4791) | Error 0.0000(0.0000) Steps 676(657.16) | Grad Norm 12.8756(5.5842) | Total Time 14.00(14.00)\n",
      "Iter 0330 | Time 15.9844(16.2473) | Bit/dim 5.2112(5.4276) | Xent 0.0000(0.0000) | Loss 5.2112(5.4276) | Error 0.0000(0.0000) Steps 688(664.24) | Grad Norm 6.5721(6.0487) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 87.6929, Epoch Time 990.4620(863.3750), Bit/dim 5.2290(best: 5.5353), Xent 0.0000, Loss 5.2290, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0340 | Time 16.7799(16.3310) | Bit/dim 5.2135(5.3759) | Xent 0.0000(0.0000) | Loss 5.2135(5.3759) | Error 0.0000(0.0000) Steps 688(670.93) | Grad Norm 13.2075(6.8779) | Total Time 14.00(14.00)\n",
      "Iter 0350 | Time 16.1070(16.3256) | Bit/dim 5.2254(5.3319) | Xent 0.0000(0.0000) | Loss 5.2254(5.3319) | Error 0.0000(0.0000) Steps 682(674.13) | Grad Norm 8.6107(7.7721) | Total Time 14.00(14.00)\n",
      "Iter 0360 | Time 16.3502(16.3379) | Bit/dim 5.1463(5.2824) | Xent 0.0000(0.0000) | Loss 5.1463(5.2824) | Error 0.0000(0.0000) Steps 694(677.07) | Grad Norm 5.3643(6.8554) | Total Time 14.00(14.00)\n",
      "Iter 0370 | Time 16.4279(16.4206) | Bit/dim 5.1156(5.2336) | Xent 0.0000(0.0000) | Loss 5.1156(5.2336) | Error 0.0000(0.0000) Steps 694(680.26) | Grad Norm 4.7517(7.3264) | Total Time 14.00(14.00)\n",
      "Iter 0380 | Time 16.8133(16.5410) | Bit/dim 5.1699(5.2033) | Xent 0.0000(0.0000) | Loss 5.1699(5.2033) | Error 0.0000(0.0000) Steps 706(684.30) | Grad Norm 18.8793(9.8342) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 89.2581, Epoch Time 1018.8986(868.0407), Bit/dim 5.0659(best: 5.2290), Xent 0.0000, Loss 5.0659, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0390 | Time 16.4946(16.5471) | Bit/dim 5.0692(5.1737) | Xent 0.0000(0.0000) | Loss 5.0692(5.1737) | Error 0.0000(0.0000) Steps 682(684.92) | Grad Norm 11.2369(9.9581) | Total Time 14.00(14.00)\n",
      "Iter 0400 | Time 16.4209(16.4776) | Bit/dim 4.9850(5.1316) | Xent 0.0000(0.0000) | Loss 4.9850(5.1316) | Error 0.0000(0.0000) Steps 676(683.03) | Grad Norm 4.3611(8.9241) | Total Time 14.00(14.00)\n",
      "Iter 0410 | Time 16.7669(16.5559) | Bit/dim 4.9508(5.0888) | Xent 0.0000(0.0000) | Loss 4.9508(5.0888) | Error 0.0000(0.0000) Steps 688(685.32) | Grad Norm 8.3836(7.9417) | Total Time 14.00(14.00)\n",
      "Iter 0420 | Time 16.8622(16.7635) | Bit/dim 4.9317(5.0502) | Xent 0.0000(0.0000) | Loss 4.9317(5.0502) | Error 0.0000(0.0000) Steps 700(688.86) | Grad Norm 6.8879(7.4269) | Total Time 14.00(14.00)\n",
      "Iter 0430 | Time 17.0387(16.9360) | Bit/dim 4.9139(5.0154) | Xent 0.0000(0.0000) | Loss 4.9139(5.0154) | Error 0.0000(0.0000) Steps 688(691.66) | Grad Norm 4.7636(7.6676) | Total Time 14.00(14.00)\n",
      "Iter 0440 | Time 16.6280(17.0433) | Bit/dim 5.0114(5.0056) | Xent 0.0000(0.0000) | Loss 5.0114(5.0056) | Error 0.0000(0.0000) Steps 706(694.65) | Grad Norm 15.2499(10.0352) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 91.1463, Epoch Time 1042.2550(873.2672), Bit/dim 5.0549(best: 5.0659), Xent 0.0000, Loss 5.0549, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0450 | Time 17.3337(17.1019) | Bit/dim 4.9397(5.0015) | Xent 0.0000(0.0000) | Loss 4.9397(5.0015) | Error 0.0000(0.0000) Steps 694(695.89) | Grad Norm 9.5736(10.9470) | Total Time 14.00(14.00)\n",
      "Iter 0460 | Time 17.0709(17.1928) | Bit/dim 4.8931(4.9736) | Xent 0.0000(0.0000) | Loss 4.8931(4.9736) | Error 0.0000(0.0000) Steps 694(695.09) | Grad Norm 5.9445(9.9516) | Total Time 14.00(14.00)\n",
      "Iter 0470 | Time 18.5418(17.4169) | Bit/dim 4.8071(4.9390) | Xent 0.0000(0.0000) | Loss 4.8071(4.9390) | Error 0.0000(0.0000) Steps 700(698.65) | Grad Norm 1.8855(8.5140) | Total Time 14.00(14.00)\n",
      "Iter 0480 | Time 17.1526(17.4949) | Bit/dim 4.8194(4.9034) | Xent 0.0000(0.0000) | Loss 4.8194(4.9034) | Error 0.0000(0.0000) Steps 694(701.17) | Grad Norm 12.8889(8.0380) | Total Time 14.00(14.00)\n",
      "Iter 0490 | Time 18.4626(17.6841) | Bit/dim 4.7876(4.8708) | Xent 0.0000(0.0000) | Loss 4.7876(4.8708) | Error 0.0000(0.0000) Steps 706(704.17) | Grad Norm 9.8401(7.5128) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 93.4917, Epoch Time 1089.1610(879.7440), Bit/dim 4.7920(best: 5.0549), Xent 0.0000, Loss 4.7920, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0500 | Time 18.6157(17.8374) | Bit/dim 4.7960(4.8493) | Xent 0.0000(0.0000) | Loss 4.7960(4.8493) | Error 0.0000(0.0000) Steps 718(709.86) | Grad Norm 13.2654(8.1360) | Total Time 14.00(14.00)\n",
      "Iter 0510 | Time 18.2748(17.8821) | Bit/dim 4.7496(4.8318) | Xent 0.0000(0.0000) | Loss 4.7496(4.8318) | Error 0.0000(0.0000) Steps 730(712.36) | Grad Norm 9.7260(9.4784) | Total Time 14.00(14.00)\n",
      "Iter 0520 | Time 18.7284(17.9836) | Bit/dim 4.7620(4.8103) | Xent 0.0000(0.0000) | Loss 4.7620(4.8103) | Error 0.0000(0.0000) Steps 730(714.27) | Grad Norm 14.3172(9.0528) | Total Time 14.00(14.00)\n",
      "Iter 0530 | Time 18.6971(18.0591) | Bit/dim 4.6841(4.7883) | Xent 0.0000(0.0000) | Loss 4.6841(4.7883) | Error 0.0000(0.0000) Steps 718(715.23) | Grad Norm 1.6631(8.6294) | Total Time 14.00(14.00)\n",
      "Iter 0540 | Time 18.3558(18.0768) | Bit/dim 4.7025(4.7651) | Xent 0.0000(0.0000) | Loss 4.7025(4.7651) | Error 0.0000(0.0000) Steps 736(717.53) | Grad Norm 11.5902(8.2940) | Total Time 14.00(14.00)\n",
      "Iter 0550 | Time 18.2829(18.1152) | Bit/dim 4.6911(4.7486) | Xent 0.0000(0.0000) | Loss 4.6911(4.7486) | Error 0.0000(0.0000) Steps 724(717.91) | Grad Norm 15.4971(8.5301) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 92.0546, Epoch Time 1109.4278(886.6345), Bit/dim 4.6842(best: 4.7920), Xent 0.0000, Loss 4.6842, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0560 | Time 18.4575(18.1026) | Bit/dim 4.6906(4.7319) | Xent 0.0000(0.0000) | Loss 4.6906(4.7319) | Error 0.0000(0.0000) Steps 736(719.59) | Grad Norm 4.8117(8.3064) | Total Time 14.00(14.00)\n",
      "Iter 0570 | Time 18.7880(18.1569) | Bit/dim 4.7014(4.7151) | Xent 0.0000(0.0000) | Loss 4.7014(4.7151) | Error 0.0000(0.0000) Steps 736(720.53) | Grad Norm 13.4039(8.6548) | Total Time 14.00(14.00)\n",
      "Iter 0580 | Time 17.8820(18.1744) | Bit/dim 4.6389(4.6996) | Xent 0.0000(0.0000) | Loss 4.6389(4.6996) | Error 0.0000(0.0000) Steps 724(722.56) | Grad Norm 7.4543(8.9456) | Total Time 14.00(14.00)\n",
      "Iter 0590 | Time 18.1087(18.1419) | Bit/dim 4.6298(4.6849) | Xent 0.0000(0.0000) | Loss 4.6298(4.6849) | Error 0.0000(0.0000) Steps 730(725.79) | Grad Norm 10.2953(9.2046) | Total Time 14.00(14.00)\n",
      "Iter 0600 | Time 17.6049(18.0942) | Bit/dim 4.6666(4.6721) | Xent 0.0000(0.0000) | Loss 4.6666(4.6721) | Error 0.0000(0.0000) Steps 736(726.86) | Grad Norm 18.5888(9.7093) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 93.5127, Epoch Time 1107.8781(893.2718), Bit/dim 4.6689(best: 4.6842), Xent 0.0000, Loss 4.6689, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0610 | Time 17.9739(18.1189) | Bit/dim 4.6389(4.6638) | Xent 0.0000(0.0000) | Loss 4.6389(4.6638) | Error 0.0000(0.0000) Steps 748(728.07) | Grad Norm 8.6320(10.0235) | Total Time 14.00(14.00)\n",
      "Iter 0620 | Time 18.0992(18.1520) | Bit/dim 4.6098(4.6435) | Xent 0.0000(0.0000) | Loss 4.6098(4.6435) | Error 0.0000(0.0000) Steps 736(728.76) | Grad Norm 3.1222(9.0777) | Total Time 14.00(14.00)\n",
      "Iter 0630 | Time 18.7775(18.1732) | Bit/dim 4.5498(4.6273) | Xent 0.0000(0.0000) | Loss 4.5498(4.6273) | Error 0.0000(0.0000) Steps 736(730.71) | Grad Norm 6.5321(8.6365) | Total Time 14.00(14.00)\n",
      "Iter 0640 | Time 17.7768(18.1513) | Bit/dim 4.5200(4.6077) | Xent 0.0000(0.0000) | Loss 4.5200(4.6077) | Error 0.0000(0.0000) Steps 730(730.60) | Grad Norm 1.5246(7.5653) | Total Time 14.00(14.00)\n",
      "Iter 0650 | Time 18.2782(18.1671) | Bit/dim 4.5274(4.5950) | Xent 0.0000(0.0000) | Loss 4.5274(4.5950) | Error 0.0000(0.0000) Steps 730(730.49) | Grad Norm 7.3539(7.7835) | Total Time 14.00(14.00)\n",
      "Iter 0660 | Time 17.8736(18.1439) | Bit/dim 4.5412(4.5772) | Xent 0.0000(0.0000) | Loss 4.5412(4.5772) | Error 0.0000(0.0000) Steps 730(730.04) | Grad Norm 5.6735(7.0233) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 93.2861, Epoch Time 1110.2839(899.7822), Bit/dim 4.5412(best: 4.6689), Xent 0.0000, Loss 4.5412, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0670 | Time 17.7709(18.0775) | Bit/dim 4.7822(4.6150) | Xent 0.0000(0.0000) | Loss 4.7822(4.6150) | Error 0.0000(0.0000) Steps 724(728.86) | Grad Norm 12.1658(9.8351) | Total Time 14.00(14.00)\n",
      "Iter 0680 | Time 18.3065(18.1750) | Bit/dim 4.5304(4.6117) | Xent 0.0000(0.0000) | Loss 4.5304(4.6117) | Error 0.0000(0.0000) Steps 766(734.19) | Grad Norm 2.8755(8.5893) | Total Time 14.00(14.00)\n",
      "Iter 0690 | Time 17.8915(18.1449) | Bit/dim 4.5416(4.5939) | Xent 0.0000(0.0000) | Loss 4.5416(4.5939) | Error 0.0000(0.0000) Steps 718(732.65) | Grad Norm 6.1353(7.3276) | Total Time 14.00(14.00)\n",
      "Iter 0700 | Time 17.7585(18.1117) | Bit/dim 4.4689(4.5678) | Xent 0.0000(0.0000) | Loss 4.4689(4.5678) | Error 0.0000(0.0000) Steps 718(729.05) | Grad Norm 3.3164(6.2118) | Total Time 14.00(14.00)\n",
      "Iter 0710 | Time 17.8646(18.0215) | Bit/dim 4.4970(4.5431) | Xent 0.0000(0.0000) | Loss 4.4970(4.5431) | Error 0.0000(0.0000) Steps 712(724.65) | Grad Norm 3.4384(5.4436) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 90.0544, Epoch Time 1099.6104(905.7770), Bit/dim 4.4925(best: 4.5412), Xent 0.0000, Loss 4.4925, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0720 | Time 17.9402(18.0052) | Bit/dim 4.4709(4.5249) | Xent 0.0000(0.0000) | Loss 4.4709(4.5249) | Error 0.0000(0.0000) Steps 724(721.38) | Grad Norm 9.6112(6.0681) | Total Time 14.00(14.00)\n",
      "Iter 0730 | Time 17.6419(17.9730) | Bit/dim 4.5237(4.5137) | Xent 0.0000(0.0000) | Loss 4.5237(4.5137) | Error 0.0000(0.0000) Steps 718(721.02) | Grad Norm 13.6028(6.7753) | Total Time 14.00(14.00)\n",
      "Iter 0740 | Time 17.5212(17.9227) | Bit/dim 4.4513(4.5006) | Xent 0.0000(0.0000) | Loss 4.4513(4.5006) | Error 0.0000(0.0000) Steps 718(719.37) | Grad Norm 6.6893(7.1806) | Total Time 14.00(14.00)\n",
      "Iter 0750 | Time 17.9064(17.9799) | Bit/dim 4.4338(4.4788) | Xent 0.0000(0.0000) | Loss 4.4338(4.4788) | Error 0.0000(0.0000) Steps 718(719.10) | Grad Norm 3.7485(6.6280) | Total Time 14.00(14.00)\n",
      "Iter 0760 | Time 17.7693(17.8840) | Bit/dim 4.4342(4.4624) | Xent 0.0000(0.0000) | Loss 4.4342(4.4624) | Error 0.0000(0.0000) Steps 724(716.82) | Grad Norm 10.4581(6.5878) | Total Time 14.00(14.00)\n",
      "Iter 0770 | Time 17.7486(17.9162) | Bit/dim 4.3924(4.4396) | Xent 0.0000(0.0000) | Loss 4.3924(4.4396) | Error 0.0000(0.0000) Steps 718(716.53) | Grad Norm 9.4896(6.3441) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 89.7453, Epoch Time 1091.6263(911.3525), Bit/dim 4.3815(best: 4.4925), Xent 0.0000, Loss 4.3815, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0780 | Time 17.7845(17.9142) | Bit/dim 4.3718(4.4229) | Xent 0.0000(0.0000) | Loss 4.3718(4.4229) | Error 0.0000(0.0000) Steps 718(714.68) | Grad Norm 7.3591(6.5169) | Total Time 14.00(14.00)\n",
      "Iter 0790 | Time 17.6836(17.9741) | Bit/dim 4.3413(4.4057) | Xent 0.0000(0.0000) | Loss 4.3413(4.4057) | Error 0.0000(0.0000) Steps 712(714.78) | Grad Norm 7.2417(6.5247) | Total Time 14.00(14.00)\n",
      "Iter 0800 | Time 18.8883(18.0252) | Bit/dim 4.3104(4.3863) | Xent 0.0000(0.0000) | Loss 4.3104(4.3863) | Error 0.0000(0.0000) Steps 748(715.55) | Grad Norm 5.9582(6.5069) | Total Time 14.00(14.00)\n",
      "Iter 0810 | Time 18.3902(18.0524) | Bit/dim 4.3436(4.3777) | Xent 0.0000(0.0000) | Loss 4.3436(4.3777) | Error 0.0000(0.0000) Steps 724(715.58) | Grad Norm 9.1199(7.1210) | Total Time 14.00(14.00)\n",
      "Iter 0820 | Time 17.7585(18.0743) | Bit/dim 4.4260(4.3704) | Xent 0.0000(0.0000) | Loss 4.4260(4.3704) | Error 0.0000(0.0000) Steps 718(716.32) | Grad Norm 12.7205(7.4342) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 90.3242, Epoch Time 1099.6825(917.0024), Bit/dim 4.5244(best: 4.3815), Xent 0.0000, Loss 4.5244, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0830 | Time 18.8835(18.0267) | Bit/dim 4.3903(4.3880) | Xent 0.0000(0.0000) | Loss 4.3903(4.3880) | Error 0.0000(0.0000) Steps 754(718.06) | Grad Norm 4.3097(7.8108) | Total Time 14.00(14.00)\n",
      "Iter 0840 | Time 17.3464(17.9770) | Bit/dim 4.3102(4.3759) | Xent 0.0000(0.0000) | Loss 4.3102(4.3759) | Error 0.0000(0.0000) Steps 700(717.92) | Grad Norm 2.4392(6.7319) | Total Time 14.00(14.00)\n",
      "Iter 0850 | Time 17.5483(17.8389) | Bit/dim 4.2547(4.3546) | Xent 0.0000(0.0000) | Loss 4.2547(4.3546) | Error 0.0000(0.0000) Steps 688(711.93) | Grad Norm 2.2314(5.8242) | Total Time 14.00(14.00)\n",
      "Iter 0860 | Time 18.3708(17.8152) | Bit/dim 4.2643(4.3300) | Xent 0.0000(0.0000) | Loss 4.2643(4.3300) | Error 0.0000(0.0000) Steps 712(710.26) | Grad Norm 5.9758(5.2517) | Total Time 14.00(14.00)\n",
      "Iter 0870 | Time 18.7150(17.8438) | Bit/dim 4.1993(4.3091) | Xent 0.0000(0.0000) | Loss 4.1993(4.3091) | Error 0.0000(0.0000) Steps 712(709.67) | Grad Norm 1.7437(5.3275) | Total Time 14.00(14.00)\n",
      "Iter 0880 | Time 17.2061(17.8909) | Bit/dim 4.4069(4.3285) | Xent 0.0000(0.0000) | Loss 4.4069(4.3285) | Error 0.0000(0.0000) Steps 706(711.48) | Grad Norm 7.2172(6.8084) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 88.1145, Epoch Time 1087.0975(922.1053), Bit/dim 4.4216(best: 4.3815), Xent 0.0000, Loss 4.4216, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0890 | Time 17.8864(17.8680) | Bit/dim 4.2925(4.3320) | Xent 0.0000(0.0000) | Loss 4.2925(4.3320) | Error 0.0000(0.0000) Steps 706(711.54) | Grad Norm 5.1375(6.3589) | Total Time 14.00(14.00)\n",
      "Iter 0900 | Time 17.6460(17.8561) | Bit/dim 4.2221(4.3111) | Xent 0.0000(0.0000) | Loss 4.2221(4.3111) | Error 0.0000(0.0000) Steps 706(709.71) | Grad Norm 3.7035(5.5633) | Total Time 14.00(14.00)\n",
      "Iter 0910 | Time 17.8739(17.8863) | Bit/dim 4.2415(4.2862) | Xent 0.0000(0.0000) | Loss 4.2415(4.2862) | Error 0.0000(0.0000) Steps 718(709.69) | Grad Norm 2.1879(4.9796) | Total Time 14.00(14.00)\n",
      "Iter 0920 | Time 18.3715(17.9548) | Bit/dim 4.2153(4.2599) | Xent 0.0000(0.0000) | Loss 4.2153(4.2599) | Error 0.0000(0.0000) Steps 724(709.99) | Grad Norm 3.0189(4.9919) | Total Time 14.00(14.00)\n",
      "Iter 0930 | Time 17.3224(17.9394) | Bit/dim 4.3410(4.2506) | Xent 0.0000(0.0000) | Loss 4.3410(4.2506) | Error 0.0000(0.0000) Steps 700(709.93) | Grad Norm 12.0047(6.1006) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 87.5778, Epoch Time 1089.3435(927.1224), Bit/dim 4.2375(best: 4.3815), Xent 0.0000, Loss 4.2375, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0940 | Time 17.7319(17.8507) | Bit/dim 4.2201(4.2518) | Xent 0.0000(0.0000) | Loss 4.2201(4.2518) | Error 0.0000(0.0000) Steps 718(709.17) | Grad Norm 3.9750(5.9966) | Total Time 14.00(14.00)\n",
      "Iter 0950 | Time 17.9843(17.8777) | Bit/dim 4.1682(4.2306) | Xent 0.0000(0.0000) | Loss 4.1682(4.2306) | Error 0.0000(0.0000) Steps 706(709.88) | Grad Norm 2.4134(5.2979) | Total Time 14.00(14.00)\n",
      "Iter 0960 | Time 18.4170(18.0307) | Bit/dim 4.1433(4.2096) | Xent 0.0000(0.0000) | Loss 4.1433(4.2096) | Error 0.0000(0.0000) Steps 712(711.65) | Grad Norm 2.9914(4.4989) | Total Time 14.00(14.00)\n",
      "Iter 0970 | Time 17.8629(18.0832) | Bit/dim 4.1088(4.1881) | Xent 0.0000(0.0000) | Loss 4.1088(4.1881) | Error 0.0000(0.0000) Steps 724(714.23) | Grad Norm 4.4551(4.7433) | Total Time 14.00(14.00)\n",
      "Iter 0980 | Time 18.1614(18.1292) | Bit/dim 4.1048(4.1689) | Xent 0.0000(0.0000) | Loss 4.1048(4.1689) | Error 0.0000(0.0000) Steps 718(714.67) | Grad Norm 4.4835(4.8623) | Total Time 14.00(14.00)\n",
      "Iter 0990 | Time 18.2115(18.1303) | Bit/dim 4.1131(4.1595) | Xent 0.0000(0.0000) | Loss 4.1131(4.1595) | Error 0.0000(0.0000) Steps 724(715.05) | Grad Norm 4.4464(5.5488) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 87.9315, Epoch Time 1104.3724(932.4399), Bit/dim 4.2300(best: 4.2375), Xent 0.0000, Loss 4.2300, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1000 | Time 18.6490(18.0474) | Bit/dim 4.1183(4.1660) | Xent 0.0000(0.0000) | Loss 4.1183(4.1660) | Error 0.0000(0.0000) Steps 712(713.62) | Grad Norm 4.3248(6.3559) | Total Time 14.00(14.00)\n",
      "Iter 1010 | Time 17.9975(18.0594) | Bit/dim 4.1343(4.1517) | Xent 0.0000(0.0000) | Loss 4.1343(4.1517) | Error 0.0000(0.0000) Steps 718(715.15) | Grad Norm 4.6072(5.9357) | Total Time 14.00(14.00)\n",
      "Iter 1020 | Time 18.0210(18.0899) | Bit/dim 4.0653(4.1320) | Xent 0.0000(0.0000) | Loss 4.0653(4.1320) | Error 0.0000(0.0000) Steps 718(716.27) | Grad Norm 2.7952(5.2072) | Total Time 14.00(14.00)\n",
      "Iter 1030 | Time 18.2940(18.1135) | Bit/dim 4.0241(4.1146) | Xent 0.0000(0.0000) | Loss 4.0241(4.1146) | Error 0.0000(0.0000) Steps 718(715.40) | Grad Norm 3.1165(5.2182) | Total Time 14.00(14.00)\n",
      "Iter 1040 | Time 17.8597(18.0915) | Bit/dim 4.0503(4.0986) | Xent 0.0000(0.0000) | Loss 4.0503(4.0986) | Error 0.0000(0.0000) Steps 724(715.85) | Grad Norm 5.2636(4.8081) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 89.3079, Epoch Time 1100.8473(937.4921), Bit/dim 4.0463(best: 4.2300), Xent 0.0000, Loss 4.0463, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1050 | Time 18.0530(18.1101) | Bit/dim 4.0502(4.0877) | Xent 0.0000(0.0000) | Loss 4.0502(4.0877) | Error 0.0000(0.0000) Steps 724(715.83) | Grad Norm 4.0913(5.0981) | Total Time 14.00(14.00)\n",
      "Iter 1060 | Time 18.1167(18.1900) | Bit/dim 4.0792(4.0752) | Xent 0.0000(0.0000) | Loss 4.0792(4.0752) | Error 0.0000(0.0000) Steps 712(716.77) | Grad Norm 9.1925(5.0488) | Total Time 14.00(14.00)\n",
      "Iter 1070 | Time 18.8639(18.2466) | Bit/dim 4.0192(4.0618) | Xent 0.0000(0.0000) | Loss 4.0192(4.0618) | Error 0.0000(0.0000) Steps 718(717.56) | Grad Norm 6.8118(5.0648) | Total Time 14.00(14.00)\n",
      "Iter 1080 | Time 17.8548(18.2205) | Bit/dim 3.9835(4.0483) | Xent 0.0000(0.0000) | Loss 3.9835(4.0483) | Error 0.0000(0.0000) Steps 718(717.41) | Grad Norm 1.3681(5.0286) | Total Time 14.00(14.00)\n",
      "Iter 1090 | Time 17.7284(18.2168) | Bit/dim 4.0179(4.0405) | Xent 0.0000(0.0000) | Loss 4.0179(4.0405) | Error 0.0000(0.0000) Steps 712(718.48) | Grad Norm 4.3620(5.2780) | Total Time 14.00(14.00)\n",
      "Iter 1100 | Time 18.7425(18.2261) | Bit/dim 3.9928(4.0276) | Xent 0.0000(0.0000) | Loss 3.9928(4.0276) | Error 0.0000(0.0000) Steps 718(717.98) | Grad Norm 8.8822(5.2971) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 90.6338, Epoch Time 1112.3768(942.7387), Bit/dim 4.0124(best: 4.0463), Xent 0.0000, Loss 4.0124, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1110 | Time 18.6396(18.2132) | Bit/dim 3.9965(4.0189) | Xent 0.0000(0.0000) | Loss 3.9965(4.0189) | Error 0.0000(0.0000) Steps 730(718.14) | Grad Norm 2.3793(5.2929) | Total Time 14.00(14.00)\n",
      "Iter 1120 | Time 17.8624(18.2404) | Bit/dim 3.9443(4.0076) | Xent 0.0000(0.0000) | Loss 3.9443(4.0076) | Error 0.0000(0.0000) Steps 718(718.39) | Grad Norm 7.9543(5.2425) | Total Time 14.00(14.00)\n",
      "Iter 1130 | Time 18.7571(18.3008) | Bit/dim 3.9724(4.0007) | Xent 0.0000(0.0000) | Loss 3.9724(4.0007) | Error 0.0000(0.0000) Steps 718(718.77) | Grad Norm 6.4283(5.3108) | Total Time 14.00(14.00)\n",
      "Iter 1140 | Time 18.3192(18.3282) | Bit/dim 3.9565(3.9903) | Xent 0.0000(0.0000) | Loss 3.9565(3.9903) | Error 0.0000(0.0000) Steps 718(718.39) | Grad Norm 3.8909(5.0693) | Total Time 14.00(14.00)\n",
      "Iter 1150 | Time 18.7830(18.3684) | Bit/dim 3.9632(3.9811) | Xent 0.0000(0.0000) | Loss 3.9632(3.9811) | Error 0.0000(0.0000) Steps 718(719.26) | Grad Norm 4.7442(5.2038) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 89.6629, Epoch Time 1118.6680(948.0165), Bit/dim 3.9437(best: 4.0124), Xent 0.0000, Loss 3.9437, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1160 | Time 18.9466(18.3973) | Bit/dim 3.9658(3.9751) | Xent 0.0000(0.0000) | Loss 3.9658(3.9751) | Error 0.0000(0.0000) Steps 724(719.40) | Grad Norm 3.1690(4.6465) | Total Time 14.00(14.00)\n",
      "Iter 1170 | Time 18.1826(18.3537) | Bit/dim 3.9417(3.9684) | Xent 0.0000(0.0000) | Loss 3.9417(3.9684) | Error 0.0000(0.0000) Steps 712(719.65) | Grad Norm 2.8213(4.7939) | Total Time 14.00(14.00)\n",
      "Iter 1180 | Time 17.7475(18.2933) | Bit/dim 3.9096(3.9583) | Xent 0.0000(0.0000) | Loss 3.9096(3.9583) | Error 0.0000(0.0000) Steps 712(718.68) | Grad Norm 4.4703(4.8094) | Total Time 14.00(14.00)\n",
      "Iter 1190 | Time 17.5441(18.2204) | Bit/dim 3.9422(3.9499) | Xent 0.0000(0.0000) | Loss 3.9422(3.9499) | Error 0.0000(0.0000) Steps 706(717.09) | Grad Norm 10.0687(4.7398) | Total Time 14.00(14.00)\n",
      "Iter 1200 | Time 18.5638(18.2767) | Bit/dim 3.9102(3.9459) | Xent 0.0000(0.0000) | Loss 3.9102(3.9459) | Error 0.0000(0.0000) Steps 730(718.47) | Grad Norm 7.6765(5.1990) | Total Time 14.00(14.00)\n",
      "Iter 1210 | Time 18.2450(18.2153) | Bit/dim 3.9020(3.9380) | Xent 0.0000(0.0000) | Loss 3.9020(3.9380) | Error 0.0000(0.0000) Steps 706(717.61) | Grad Norm 3.2207(4.8280) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 88.3620, Epoch Time 1106.3992(952.7680), Bit/dim 3.9112(best: 3.9437), Xent 0.0000, Loss 3.9112, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1220 | Time 17.9050(18.1669) | Bit/dim 3.9011(3.9319) | Xent 0.0000(0.0000) | Loss 3.9011(3.9319) | Error 0.0000(0.0000) Steps 712(716.14) | Grad Norm 2.8455(5.0008) | Total Time 14.00(14.00)\n",
      "Iter 1230 | Time 18.5996(18.1761) | Bit/dim 3.9012(3.9278) | Xent 0.0000(0.0000) | Loss 3.9012(3.9278) | Error 0.0000(0.0000) Steps 706(714.88) | Grad Norm 5.0897(4.8320) | Total Time 14.00(14.00)\n",
      "Iter 1240 | Time 17.7211(18.1760) | Bit/dim 3.8876(3.9183) | Xent 0.0000(0.0000) | Loss 3.8876(3.9183) | Error 0.0000(0.0000) Steps 706(716.00) | Grad Norm 3.9589(4.6175) | Total Time 14.00(14.00)\n",
      "Iter 1250 | Time 18.5337(18.1589) | Bit/dim 3.8961(3.9126) | Xent 0.0000(0.0000) | Loss 3.8961(3.9126) | Error 0.0000(0.0000) Steps 724(715.43) | Grad Norm 4.4259(4.8757) | Total Time 14.00(14.00)\n",
      "Iter 1260 | Time 18.3834(18.1085) | Bit/dim 3.9070(3.9084) | Xent 0.0000(0.0000) | Loss 3.9070(3.9084) | Error 0.0000(0.0000) Steps 712(713.52) | Grad Norm 4.2070(5.2316) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 87.5567, Epoch Time 1101.5316(957.2309), Bit/dim 3.8876(best: 3.9112), Xent 0.0000, Loss 3.8876, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1270 | Time 17.1877(18.0915) | Bit/dim 3.8978(3.9019) | Xent 0.0000(0.0000) | Loss 3.8978(3.9019) | Error 0.0000(0.0000) Steps 700(710.89) | Grad Norm 4.4983(5.0614) | Total Time 14.00(14.00)\n",
      "Iter 1280 | Time 18.0348(18.0372) | Bit/dim 3.8787(3.8983) | Xent 0.0000(0.0000) | Loss 3.8787(3.8983) | Error 0.0000(0.0000) Steps 712(709.49) | Grad Norm 6.4482(5.3684) | Total Time 14.00(14.00)\n",
      "Iter 1290 | Time 18.7654(18.0138) | Bit/dim 3.8769(3.8930) | Xent 0.0000(0.0000) | Loss 3.8769(3.8930) | Error 0.0000(0.0000) Steps 706(708.10) | Grad Norm 2.8928(5.0970) | Total Time 14.00(14.00)\n",
      "Iter 1300 | Time 17.8461(18.0307) | Bit/dim 3.8487(3.8880) | Xent 0.0000(0.0000) | Loss 3.8487(3.8880) | Error 0.0000(0.0000) Steps 718(708.38) | Grad Norm 1.5953(4.5551) | Total Time 14.00(14.00)\n",
      "Iter 1310 | Time 18.1817(17.9949) | Bit/dim 3.8920(3.8831) | Xent 0.0000(0.0000) | Loss 3.8920(3.8831) | Error 0.0000(0.0000) Steps 718(708.26) | Grad Norm 6.7759(4.3281) | Total Time 14.00(14.00)\n",
      "Iter 1320 | Time 17.8952(17.9792) | Bit/dim 3.8429(3.8748) | Xent 0.0000(0.0000) | Loss 3.8429(3.8748) | Error 0.0000(0.0000) Steps 712(709.10) | Grad Norm 1.4599(4.3462) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 89.1826, Epoch Time 1093.3023(961.3131), Bit/dim 3.8554(best: 3.8876), Xent 0.0000, Loss 3.8554, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1330 | Time 17.8642(17.9294) | Bit/dim 3.8697(3.8686) | Xent 0.0000(0.0000) | Loss 3.8697(3.8686) | Error 0.0000(0.0000) Steps 700(708.40) | Grad Norm 3.4962(4.2115) | Total Time 14.00(14.00)\n",
      "Iter 1340 | Time 18.7980(17.9660) | Bit/dim 3.8313(3.8621) | Xent 0.0000(0.0000) | Loss 3.8313(3.8621) | Error 0.0000(0.0000) Steps 724(708.71) | Grad Norm 3.5396(3.8718) | Total Time 14.00(14.00)\n",
      "Iter 1350 | Time 18.3624(17.9558) | Bit/dim 3.9066(3.8616) | Xent 0.0000(0.0000) | Loss 3.9066(3.8616) | Error 0.0000(0.0000) Steps 712(708.99) | Grad Norm 12.0793(4.5657) | Total Time 14.00(14.00)\n",
      "Iter 1360 | Time 17.8603(17.9499) | Bit/dim 3.8569(3.8613) | Xent 0.0000(0.0000) | Loss 3.8569(3.8613) | Error 0.0000(0.0000) Steps 718(710.03) | Grad Norm 2.4153(4.8811) | Total Time 14.00(14.00)\n",
      "Iter 1370 | Time 18.4047(17.9256) | Bit/dim 3.8289(3.8540) | Xent 0.0000(0.0000) | Loss 3.8289(3.8540) | Error 0.0000(0.0000) Steps 712(709.49) | Grad Norm 3.7749(4.7006) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 89.1307, Epoch Time 1092.2302(965.2406), Bit/dim 3.8337(best: 3.8554), Xent 0.0000, Loss 3.8337, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1380 | Time 17.8646(17.9248) | Bit/dim 3.7927(3.8492) | Xent 0.0000(0.0000) | Loss 3.7927(3.8492) | Error 0.0000(0.0000) Steps 712(708.76) | Grad Norm 6.3632(4.6137) | Total Time 14.00(14.00)\n",
      "Iter 1390 | Time 18.2599(17.9029) | Bit/dim 3.8093(3.8425) | Xent 0.0000(0.0000) | Loss 3.8093(3.8425) | Error 0.0000(0.0000) Steps 706(707.18) | Grad Norm 3.7124(4.4735) | Total Time 14.00(14.00)\n",
      "Iter 1400 | Time 18.0794(17.9385) | Bit/dim 3.7918(3.8370) | Xent 0.0000(0.0000) | Loss 3.7918(3.8370) | Error 0.0000(0.0000) Steps 712(708.44) | Grad Norm 4.6383(4.0546) | Total Time 14.00(14.00)\n",
      "Iter 1410 | Time 17.1733(17.9688) | Bit/dim 3.8337(3.8324) | Xent 0.0000(0.0000) | Loss 3.8337(3.8324) | Error 0.0000(0.0000) Steps 706(709.82) | Grad Norm 2.0271(4.4296) | Total Time 14.00(14.00)\n",
      "Iter 1420 | Time 18.2873(17.9062) | Bit/dim 3.8760(3.8301) | Xent 0.0000(0.0000) | Loss 3.8760(3.8301) | Error 0.0000(0.0000) Steps 706(708.64) | Grad Norm 11.1815(4.5225) | Total Time 14.00(14.00)\n",
      "Iter 1430 | Time 17.6794(17.9216) | Bit/dim 3.8006(3.8302) | Xent 0.0000(0.0000) | Loss 3.8006(3.8302) | Error 0.0000(0.0000) Steps 706(709.33) | Grad Norm 3.8673(4.8672) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 88.9125, Epoch Time 1092.5238(969.0591), Bit/dim 3.8096(best: 3.8337), Xent 0.0000, Loss 3.8096, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1440 | Time 17.9964(17.9190) | Bit/dim 3.7967(3.8245) | Xent 0.0000(0.0000) | Loss 3.7967(3.8245) | Error 0.0000(0.0000) Steps 700(708.90) | Grad Norm 3.1569(4.4800) | Total Time 14.00(14.00)\n",
      "Iter 1450 | Time 17.5624(17.9040) | Bit/dim 3.8214(3.8201) | Xent 0.0000(0.0000) | Loss 3.8214(3.8201) | Error 0.0000(0.0000) Steps 712(710.00) | Grad Norm 5.0705(4.0976) | Total Time 14.00(14.00)\n",
      "Iter 1460 | Time 17.7744(17.8870) | Bit/dim 3.8199(3.8165) | Xent 0.0000(0.0000) | Loss 3.8199(3.8165) | Error 0.0000(0.0000) Steps 712(710.87) | Grad Norm 5.4106(4.5354) | Total Time 14.00(14.00)\n",
      "Iter 1470 | Time 18.2401(17.9247) | Bit/dim 3.7909(3.8111) | Xent 0.0000(0.0000) | Loss 3.7909(3.8111) | Error 0.0000(0.0000) Steps 712(711.20) | Grad Norm 2.9584(4.4851) | Total Time 14.00(14.00)\n",
      "Iter 1480 | Time 18.1978(17.9483) | Bit/dim 3.8022(3.8069) | Xent 0.0000(0.0000) | Loss 3.8022(3.8069) | Error 0.0000(0.0000) Steps 724(711.76) | Grad Norm 5.5013(4.3188) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 87.9108, Epoch Time 1091.1884(972.7230), Bit/dim 3.7903(best: 3.8096), Xent 0.0000, Loss 3.7903, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1490 | Time 18.0514(17.9316) | Bit/dim 3.8388(3.8084) | Xent 0.0000(0.0000) | Loss 3.8388(3.8084) | Error 0.0000(0.0000) Steps 706(711.62) | Grad Norm 1.5920(4.2617) | Total Time 14.00(14.00)\n",
      "Iter 1500 | Time 18.3907(17.9093) | Bit/dim 3.7878(3.8069) | Xent 0.0000(0.0000) | Loss 3.7878(3.8069) | Error 0.0000(0.0000) Steps 712(711.67) | Grad Norm 6.7568(4.6033) | Total Time 14.00(14.00)\n",
      "Iter 1510 | Time 17.5720(17.8831) | Bit/dim 3.7821(3.8011) | Xent 0.0000(0.0000) | Loss 3.7821(3.8011) | Error 0.0000(0.0000) Steps 712(711.28) | Grad Norm 4.7954(4.3749) | Total Time 14.00(14.00)\n",
      "Iter 1520 | Time 18.0217(17.8837) | Bit/dim 3.7567(3.7946) | Xent 0.0000(0.0000) | Loss 3.7567(3.7946) | Error 0.0000(0.0000) Steps 706(710.18) | Grad Norm 2.5298(4.0147) | Total Time 14.00(14.00)\n",
      "Iter 1530 | Time 17.5337(17.9281) | Bit/dim 3.7925(3.7957) | Xent 0.0000(0.0000) | Loss 3.7925(3.7957) | Error 0.0000(0.0000) Steps 712(710.11) | Grad Norm 9.1194(4.9576) | Total Time 14.00(14.00)\n",
      "Iter 1540 | Time 17.9880(17.9275) | Bit/dim 3.7882(3.7923) | Xent 0.0000(0.0000) | Loss 3.7882(3.7923) | Error 0.0000(0.0000) Steps 712(709.66) | Grad Norm 4.1594(4.8722) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 88.8013, Epoch Time 1091.5818(976.2887), Bit/dim 3.7807(best: 3.7903), Xent 0.0000, Loss 3.7807, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1550 | Time 17.8518(17.8751) | Bit/dim 3.7628(3.7861) | Xent 0.0000(0.0000) | Loss 3.7628(3.7861) | Error 0.0000(0.0000) Steps 706(708.99) | Grad Norm 3.2440(4.3996) | Total Time 14.00(14.00)\n",
      "Iter 1560 | Time 18.3255(17.8633) | Bit/dim 3.7545(3.7805) | Xent 0.0000(0.0000) | Loss 3.7545(3.7805) | Error 0.0000(0.0000) Steps 700(708.31) | Grad Norm 4.7435(4.2506) | Total Time 14.00(14.00)\n",
      "Iter 1570 | Time 17.6727(17.8092) | Bit/dim 3.7739(3.7781) | Xent 0.0000(0.0000) | Loss 3.7739(3.7781) | Error 0.0000(0.0000) Steps 706(706.60) | Grad Norm 6.0095(4.0798) | Total Time 14.00(14.00)\n",
      "Iter 1580 | Time 17.7251(17.8171) | Bit/dim 3.7623(3.7766) | Xent 0.0000(0.0000) | Loss 3.7623(3.7766) | Error 0.0000(0.0000) Steps 712(707.58) | Grad Norm 3.9937(4.3238) | Total Time 14.00(14.00)\n",
      "Iter 1590 | Time 18.2572(17.8316) | Bit/dim 3.8018(3.7766) | Xent 0.0000(0.0000) | Loss 3.8018(3.7766) | Error 0.0000(0.0000) Steps 712(708.13) | Grad Norm 4.6102(4.5895) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 88.1325, Epoch Time 1083.0865(979.4927), Bit/dim 3.7571(best: 3.7807), Xent 0.0000, Loss 3.7571, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1600 | Time 17.7238(17.7665) | Bit/dim 3.7596(3.7746) | Xent 0.0000(0.0000) | Loss 3.7596(3.7746) | Error 0.0000(0.0000) Steps 706(707.84) | Grad Norm 1.9301(4.0006) | Total Time 14.00(14.00)\n",
      "Iter 1610 | Time 18.3727(17.8027) | Bit/dim 3.8221(3.7745) | Xent 0.0000(0.0000) | Loss 3.8221(3.7745) | Error 0.0000(0.0000) Steps 712(708.77) | Grad Norm 8.9800(4.7769) | Total Time 14.00(14.00)\n",
      "Iter 1620 | Time 17.5744(17.8205) | Bit/dim 3.7301(3.7726) | Xent 0.0000(0.0000) | Loss 3.7301(3.7726) | Error 0.0000(0.0000) Steps 718(711.08) | Grad Norm 1.0247(4.8808) | Total Time 14.00(14.00)\n",
      "Iter 1630 | Time 17.4095(17.8158) | Bit/dim 3.7448(3.7700) | Xent 0.0000(0.0000) | Loss 3.7448(3.7700) | Error 0.0000(0.0000) Steps 706(711.94) | Grad Norm 5.4478(4.6110) | Total Time 14.00(14.00)\n",
      "Iter 1640 | Time 17.3587(17.8187) | Bit/dim 3.7567(3.7683) | Xent 0.0000(0.0000) | Loss 3.7567(3.7683) | Error 0.0000(0.0000) Steps 712(712.52) | Grad Norm 4.8079(4.8036) | Total Time 14.00(14.00)\n",
      "Iter 1650 | Time 18.0849(17.8595) | Bit/dim 3.7797(3.7638) | Xent 0.0000(0.0000) | Loss 3.7797(3.7638) | Error 0.0000(0.0000) Steps 700(712.81) | Grad Norm 4.4831(4.5653) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 90.0323, Epoch Time 1088.9683(982.7769), Bit/dim 3.7490(best: 3.7571), Xent 0.0000, Loss 3.7490, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1660 | Time 17.5576(17.8091) | Bit/dim 3.7422(3.7611) | Xent 0.0000(0.0000) | Loss 3.7422(3.7611) | Error 0.0000(0.0000) Steps 712(712.89) | Grad Norm 6.4488(4.2361) | Total Time 14.00(14.00)\n",
      "Iter 1670 | Time 17.6547(17.8262) | Bit/dim 3.7499(3.7554) | Xent 0.0000(0.0000) | Loss 3.7499(3.7554) | Error 0.0000(0.0000) Steps 718(713.27) | Grad Norm 4.9186(4.2872) | Total Time 14.00(14.00)\n",
      "Iter 1680 | Time 17.5196(17.8352) | Bit/dim 3.7139(3.7521) | Xent 0.0000(0.0000) | Loss 3.7139(3.7521) | Error 0.0000(0.0000) Steps 706(714.13) | Grad Norm 5.9749(4.3807) | Total Time 14.00(14.00)\n",
      "Iter 1690 | Time 18.0320(17.8741) | Bit/dim 3.7336(3.7494) | Xent 0.0000(0.0000) | Loss 3.7336(3.7494) | Error 0.0000(0.0000) Steps 718(714.85) | Grad Norm 6.6331(4.3105) | Total Time 14.00(14.00)\n",
      "Iter 1700 | Time 18.0650(17.9221) | Bit/dim 3.7621(3.7491) | Xent 0.0000(0.0000) | Loss 3.7621(3.7491) | Error 0.0000(0.0000) Steps 724(716.94) | Grad Norm 6.4852(4.1837) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 90.4053, Epoch Time 1092.9889(986.0833), Bit/dim 3.7410(best: 3.7490), Xent 0.0000, Loss 3.7410, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1710 | Time 17.7987(17.9076) | Bit/dim 3.7465(3.7463) | Xent 0.0000(0.0000) | Loss 3.7465(3.7463) | Error 0.0000(0.0000) Steps 718(718.02) | Grad Norm 3.6844(4.4327) | Total Time 14.00(14.00)\n",
      "Iter 1720 | Time 17.5872(17.9501) | Bit/dim 3.7397(3.7457) | Xent 0.0000(0.0000) | Loss 3.7397(3.7457) | Error 0.0000(0.0000) Steps 724(719.91) | Grad Norm 2.3918(3.8226) | Total Time 14.00(14.00)\n",
      "Iter 1730 | Time 18.3097(17.9345) | Bit/dim 3.7481(3.7461) | Xent 0.0000(0.0000) | Loss 3.7481(3.7461) | Error 0.0000(0.0000) Steps 724(721.00) | Grad Norm 5.0028(4.5080) | Total Time 14.00(14.00)\n",
      "Iter 1740 | Time 18.2742(18.0241) | Bit/dim 3.7541(3.7428) | Xent 0.0000(0.0000) | Loss 3.7541(3.7428) | Error 0.0000(0.0000) Steps 724(721.66) | Grad Norm 3.2537(4.2099) | Total Time 14.00(14.00)\n",
      "Iter 1750 | Time 18.3018(18.0173) | Bit/dim 3.7437(3.7392) | Xent 0.0000(0.0000) | Loss 3.7437(3.7392) | Error 0.0000(0.0000) Steps 724(721.91) | Grad Norm 6.3460(4.4611) | Total Time 14.00(14.00)\n",
      "Iter 1760 | Time 17.9695(18.0329) | Bit/dim 3.7575(3.7383) | Xent 0.0000(0.0000) | Loss 3.7575(3.7383) | Error 0.0000(0.0000) Steps 730(722.83) | Grad Norm 2.7153(4.3934) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 92.3307, Epoch Time 1101.1826(989.5363), Bit/dim 3.7255(best: 3.7410), Xent 0.0000, Loss 3.7255, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1770 | Time 17.7352(18.0856) | Bit/dim 3.7371(3.7347) | Xent 0.0000(0.0000) | Loss 3.7371(3.7347) | Error 0.0000(0.0000) Steps 724(723.47) | Grad Norm 1.9028(4.1661) | Total Time 14.00(14.00)\n",
      "Iter 1780 | Time 18.6106(18.1379) | Bit/dim 3.7410(3.7326) | Xent 0.0000(0.0000) | Loss 3.7410(3.7326) | Error 0.0000(0.0000) Steps 742(726.02) | Grad Norm 9.4828(4.2641) | Total Time 14.00(14.00)\n",
      "Iter 1790 | Time 18.7132(18.1392) | Bit/dim 3.7158(3.7334) | Xent 0.0000(0.0000) | Loss 3.7158(3.7334) | Error 0.0000(0.0000) Steps 730(727.04) | Grad Norm 5.2651(4.5800) | Total Time 14.00(14.00)\n",
      "Iter 1800 | Time 18.6081(18.1582) | Bit/dim 3.7379(3.7299) | Xent 0.0000(0.0000) | Loss 3.7379(3.7299) | Error 0.0000(0.0000) Steps 742(727.91) | Grad Norm 3.5948(4.4129) | Total Time 14.00(14.00)\n",
      "Iter 1810 | Time 17.9489(18.1634) | Bit/dim 3.7252(3.7292) | Xent 0.0000(0.0000) | Loss 3.7252(3.7292) | Error 0.0000(0.0000) Steps 724(729.03) | Grad Norm 5.0530(4.2812) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 92.6902, Epoch Time 1112.7881(993.2338), Bit/dim 3.7244(best: 3.7255), Xent 0.0000, Loss 3.7244, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1820 | Time 17.9108(18.1814) | Bit/dim 3.7392(3.7280) | Xent 0.0000(0.0000) | Loss 3.7392(3.7280) | Error 0.0000(0.0000) Steps 724(730.05) | Grad Norm 4.6045(4.2982) | Total Time 14.00(14.00)\n",
      "Iter 1830 | Time 18.1600(18.2472) | Bit/dim 3.7336(3.7274) | Xent 0.0000(0.0000) | Loss 3.7336(3.7274) | Error 0.0000(0.0000) Steps 742(731.81) | Grad Norm 8.0579(4.4194) | Total Time 14.00(14.00)\n",
      "Iter 1840 | Time 18.0948(18.2147) | Bit/dim 3.6570(3.7218) | Xent 0.0000(0.0000) | Loss 3.6570(3.7218) | Error 0.0000(0.0000) Steps 730(731.97) | Grad Norm 3.0140(4.2427) | Total Time 14.00(14.00)\n",
      "Iter 1850 | Time 18.1341(18.2276) | Bit/dim 3.7328(3.7223) | Xent 0.0000(0.0000) | Loss 3.7328(3.7223) | Error 0.0000(0.0000) Steps 736(732.13) | Grad Norm 6.4457(4.9036) | Total Time 14.00(14.00)\n",
      "Iter 1860 | Time 18.3672(18.2306) | Bit/dim 3.6924(3.7189) | Xent 0.0000(0.0000) | Loss 3.6924(3.7189) | Error 0.0000(0.0000) Steps 730(732.77) | Grad Norm 5.4384(4.7882) | Total Time 14.00(14.00)\n",
      "Iter 1870 | Time 18.8091(18.2908) | Bit/dim 3.7307(3.7184) | Xent 0.0000(0.0000) | Loss 3.7307(3.7184) | Error 0.0000(0.0000) Steps 742(732.84) | Grad Norm 3.9081(4.3629) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 92.1865, Epoch Time 1115.6793(996.9072), Bit/dim 3.7151(best: 3.7244), Xent 0.0000, Loss 3.7151, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1880 | Time 17.9414(18.3447) | Bit/dim 3.7013(3.7136) | Xent 0.0000(0.0000) | Loss 3.7013(3.7136) | Error 0.0000(0.0000) Steps 742(734.06) | Grad Norm 4.0926(4.3427) | Total Time 14.00(14.00)\n",
      "Iter 1890 | Time 18.7574(18.4123) | Bit/dim 3.7339(3.7139) | Xent 0.0000(0.0000) | Loss 3.7339(3.7139) | Error 0.0000(0.0000) Steps 730(735.21) | Grad Norm 6.4261(4.1669) | Total Time 14.00(14.00)\n",
      "Iter 1900 | Time 18.6045(18.4432) | Bit/dim 3.6942(3.7092) | Xent 0.0000(0.0000) | Loss 3.6942(3.7092) | Error 0.0000(0.0000) Steps 736(735.36) | Grad Norm 1.7726(4.3164) | Total Time 14.00(14.00)\n",
      "Iter 1910 | Time 18.5653(18.4961) | Bit/dim 3.6940(3.7098) | Xent 0.0000(0.0000) | Loss 3.6940(3.7098) | Error 0.0000(0.0000) Steps 736(735.97) | Grad Norm 4.2735(4.2086) | Total Time 14.00(14.00)\n",
      "Iter 1920 | Time 18.2942(18.5489) | Bit/dim 3.7141(3.7086) | Xent 0.0000(0.0000) | Loss 3.7141(3.7086) | Error 0.0000(0.0000) Steps 742(736.13) | Grad Norm 3.3037(3.8138) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 91.5228, Epoch Time 1131.7493(1000.9524), Bit/dim 3.7180(best: 3.7151), Xent 0.0000, Loss 3.7180, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1930 | Time 18.0219(18.5136) | Bit/dim 3.7062(3.7099) | Xent 0.0000(0.0000) | Loss 3.7062(3.7099) | Error 0.0000(0.0000) Steps 736(735.74) | Grad Norm 2.8355(4.3288) | Total Time 14.00(14.00)\n",
      "Iter 1940 | Time 18.4879(18.5317) | Bit/dim 3.7193(3.7079) | Xent 0.0000(0.0000) | Loss 3.7193(3.7079) | Error 0.0000(0.0000) Steps 742(735.89) | Grad Norm 3.2562(4.1469) | Total Time 14.00(14.00)\n",
      "Iter 1950 | Time 18.9356(18.6248) | Bit/dim 3.6998(3.7042) | Xent 0.0000(0.0000) | Loss 3.6998(3.7042) | Error 0.0000(0.0000) Steps 736(736.57) | Grad Norm 5.5802(4.0208) | Total Time 14.00(14.00)\n",
      "Iter 1960 | Time 19.1559(18.7117) | Bit/dim 3.6842(3.7027) | Xent 0.0000(0.0000) | Loss 3.6842(3.7027) | Error 0.0000(0.0000) Steps 748(737.60) | Grad Norm 3.4274(4.1797) | Total Time 14.00(14.00)\n",
      "Iter 1970 | Time 19.4801(18.7282) | Bit/dim 3.7058(3.7004) | Xent 0.0000(0.0000) | Loss 3.7058(3.7004) | Error 0.0000(0.0000) Steps 766(738.39) | Grad Norm 2.4332(3.7488) | Total Time 14.00(14.00)\n",
      "Iter 1980 | Time 18.1718(18.7420) | Bit/dim 3.7078(3.6976) | Xent 0.0000(0.0000) | Loss 3.7078(3.6976) | Error 0.0000(0.0000) Steps 718(739.52) | Grad Norm 6.3674(3.6232) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 91.3728, Epoch Time 1140.7082(1005.1451), Bit/dim 3.7156(best: 3.7151), Xent 0.0000, Loss 3.7156, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1990 | Time 18.9441(18.8225) | Bit/dim 3.7268(3.7026) | Xent 0.0000(0.0000) | Loss 3.7268(3.7026) | Error 0.0000(0.0000) Steps 748(740.84) | Grad Norm 4.9012(4.3745) | Total Time 14.00(14.00)\n",
      "Iter 2000 | Time 19.2373(18.8372) | Bit/dim 3.6855(3.7009) | Xent 0.0000(0.0000) | Loss 3.6855(3.7009) | Error 0.0000(0.0000) Steps 742(739.70) | Grad Norm 3.7216(4.0224) | Total Time 14.00(14.00)\n",
      "Iter 2010 | Time 19.0511(18.8984) | Bit/dim 3.6488(3.6981) | Xent 0.0000(0.0000) | Loss 3.6488(3.6981) | Error 0.0000(0.0000) Steps 736(739.44) | Grad Norm 2.6923(4.1168) | Total Time 14.00(14.00)\n",
      "Iter 2020 | Time 19.3695(18.9356) | Bit/dim 3.6982(3.6949) | Xent 0.0000(0.0000) | Loss 3.6982(3.6949) | Error 0.0000(0.0000) Steps 754(741.83) | Grad Norm 3.7489(3.9706) | Total Time 14.00(14.00)\n",
      "Iter 2030 | Time 19.3394(19.0024) | Bit/dim 3.6883(3.6925) | Xent 0.0000(0.0000) | Loss 3.6883(3.6925) | Error 0.0000(0.0000) Steps 760(744.17) | Grad Norm 2.5026(3.7859) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 91.9792, Epoch Time 1157.1522(1009.7053), Bit/dim 3.6960(best: 3.7151), Xent 0.0000, Loss 3.6960, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2040 | Time 18.2031(18.9625) | Bit/dim 3.7056(3.6908) | Xent 0.0000(0.0000) | Loss 3.7056(3.6908) | Error 0.0000(0.0000) Steps 730(744.09) | Grad Norm 6.2397(4.4194) | Total Time 14.00(14.00)\n",
      "Iter 2050 | Time 19.3526(18.9630) | Bit/dim 3.6770(3.6913) | Xent 0.0000(0.0000) | Loss 3.6770(3.6913) | Error 0.0000(0.0000) Steps 730(744.01) | Grad Norm 1.5424(4.1071) | Total Time 14.00(14.00)\n",
      "Iter 2060 | Time 19.9587(19.0205) | Bit/dim 3.6726(3.6865) | Xent 0.0000(0.0000) | Loss 3.6726(3.6865) | Error 0.0000(0.0000) Steps 754(744.29) | Grad Norm 7.1323(4.0355) | Total Time 14.00(14.00)\n",
      "Iter 2070 | Time 19.6378(19.0630) | Bit/dim 3.6636(3.6842) | Xent 0.0000(0.0000) | Loss 3.6636(3.6842) | Error 0.0000(0.0000) Steps 760(747.18) | Grad Norm 3.2211(3.9627) | Total Time 14.00(14.00)\n",
      "Iter 2080 | Time 18.4706(19.0758) | Bit/dim 3.6542(3.6835) | Xent 0.0000(0.0000) | Loss 3.6542(3.6835) | Error 0.0000(0.0000) Steps 748(748.81) | Grad Norm 2.6705(3.8251) | Total Time 14.00(14.00)\n",
      "Iter 2090 | Time 20.0757(19.0197) | Bit/dim 3.6783(3.6859) | Xent 0.0000(0.0000) | Loss 3.6783(3.6859) | Error 0.0000(0.0000) Steps 724(747.84) | Grad Norm 4.8272(4.1425) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 91.8266, Epoch Time 1155.5079(1014.0794), Bit/dim 3.6859(best: 3.6960), Xent 0.0000, Loss 3.6859, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2100 | Time 19.1124(19.0202) | Bit/dim 3.6685(3.6828) | Xent 0.0000(0.0000) | Loss 3.6685(3.6828) | Error 0.0000(0.0000) Steps 754(748.19) | Grad Norm 3.0943(4.2586) | Total Time 14.00(14.00)\n",
      "Iter 2110 | Time 18.6617(19.0113) | Bit/dim 3.6711(3.6828) | Xent 0.0000(0.0000) | Loss 3.6711(3.6828) | Error 0.0000(0.0000) Steps 748(748.99) | Grad Norm 2.7935(4.1869) | Total Time 14.00(14.00)\n",
      "Iter 2120 | Time 18.6894(18.9557) | Bit/dim 3.6726(3.6779) | Xent 0.0000(0.0000) | Loss 3.6726(3.6779) | Error 0.0000(0.0000) Steps 754(750.19) | Grad Norm 3.1966(3.7770) | Total Time 14.00(14.00)\n",
      "Iter 2130 | Time 18.6978(18.9336) | Bit/dim 3.6726(3.6782) | Xent 0.0000(0.0000) | Loss 3.6726(3.6782) | Error 0.0000(0.0000) Steps 760(751.37) | Grad Norm 5.9463(4.0374) | Total Time 14.00(14.00)\n",
      "Iter 2140 | Time 19.1785(18.9691) | Bit/dim 3.6810(3.6786) | Xent 0.0000(0.0000) | Loss 3.6810(3.6786) | Error 0.0000(0.0000) Steps 754(750.72) | Grad Norm 1.8848(4.0940) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 92.4004, Epoch Time 1153.4714(1018.2612), Bit/dim 3.6685(best: 3.6859), Xent 0.0000, Loss 3.6685, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2150 | Time 18.7236(18.9965) | Bit/dim 3.6705(3.6789) | Xent 0.0000(0.0000) | Loss 3.6705(3.6789) | Error 0.0000(0.0000) Steps 754(750.28) | Grad Norm 2.2215(3.7028) | Total Time 14.00(14.00)\n",
      "Iter 2160 | Time 19.1828(18.9772) | Bit/dim 3.6909(3.6759) | Xent 0.0000(0.0000) | Loss 3.6909(3.6759) | Error 0.0000(0.0000) Steps 754(749.79) | Grad Norm 9.5146(3.9987) | Total Time 14.00(14.00)\n",
      "Iter 2170 | Time 18.2932(18.9050) | Bit/dim 3.6849(3.6774) | Xent 0.0000(0.0000) | Loss 3.6849(3.6774) | Error 0.0000(0.0000) Steps 730(749.23) | Grad Norm 5.2336(4.4404) | Total Time 14.00(14.00)\n",
      "Iter 2180 | Time 18.7966(18.9447) | Bit/dim 3.6564(3.6742) | Xent 0.0000(0.0000) | Loss 3.6564(3.6742) | Error 0.0000(0.0000) Steps 754(748.62) | Grad Norm 2.2484(4.0757) | Total Time 14.00(14.00)\n",
      "Iter 2190 | Time 18.3988(18.9448) | Bit/dim 3.6379(3.6716) | Xent 0.0000(0.0000) | Loss 3.6379(3.6716) | Error 0.0000(0.0000) Steps 748(748.80) | Grad Norm 1.8366(3.5983) | Total Time 14.00(14.00)\n",
      "Iter 2200 | Time 18.9902(18.9472) | Bit/dim 3.6870(3.6731) | Xent 0.0000(0.0000) | Loss 3.6870(3.6731) | Error 0.0000(0.0000) Steps 754(747.74) | Grad Norm 4.8993(3.9881) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 91.8435, Epoch Time 1150.4345(1022.2264), Bit/dim 3.6755(best: 3.6685), Xent 0.0000, Loss 3.6755, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2210 | Time 19.3951(18.9741) | Bit/dim 3.6616(3.6730) | Xent 0.0000(0.0000) | Loss 3.6616(3.6730) | Error 0.0000(0.0000) Steps 760(749.28) | Grad Norm 3.4343(3.9625) | Total Time 14.00(14.00)\n",
      "Iter 2220 | Time 18.6307(18.9760) | Bit/dim 3.6676(3.6711) | Xent 0.0000(0.0000) | Loss 3.6676(3.6711) | Error 0.0000(0.0000) Steps 742(748.95) | Grad Norm 2.9289(3.5203) | Total Time 14.00(14.00)\n",
      "Iter 2230 | Time 18.4220(18.9452) | Bit/dim 3.6751(3.6706) | Xent 0.0000(0.0000) | Loss 3.6751(3.6706) | Error 0.0000(0.0000) Steps 742(747.68) | Grad Norm 6.4126(4.1891) | Total Time 14.00(14.00)\n",
      "Iter 2240 | Time 18.9634(18.9885) | Bit/dim 3.6600(3.6694) | Xent 0.0000(0.0000) | Loss 3.6600(3.6694) | Error 0.0000(0.0000) Steps 748(746.76) | Grad Norm 3.1030(4.0889) | Total Time 14.00(14.00)\n",
      "Iter 2250 | Time 18.6786(18.9891) | Bit/dim 3.6779(3.6670) | Xent 0.0000(0.0000) | Loss 3.6779(3.6670) | Error 0.0000(0.0000) Steps 748(747.72) | Grad Norm 4.0295(4.0007) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 92.2115, Epoch Time 1154.3581(1026.1903), Bit/dim 3.6559(best: 3.6685), Xent 0.0000, Loss 3.6559, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2260 | Time 18.8390(18.9562) | Bit/dim 3.6210(3.6628) | Xent 0.0000(0.0000) | Loss 3.6210(3.6628) | Error 0.0000(0.0000) Steps 760(748.75) | Grad Norm 4.2307(3.8050) | Total Time 14.00(14.00)\n",
      "Iter 2270 | Time 19.5785(18.9746) | Bit/dim 3.6857(3.6636) | Xent 0.0000(0.0000) | Loss 3.6857(3.6636) | Error 0.0000(0.0000) Steps 742(748.58) | Grad Norm 3.4550(3.8918) | Total Time 14.00(14.00)\n",
      "Iter 2280 | Time 19.0282(18.9239) | Bit/dim 3.6895(3.6629) | Xent 0.0000(0.0000) | Loss 3.6895(3.6629) | Error 0.0000(0.0000) Steps 766(748.18) | Grad Norm 2.3880(3.5385) | Total Time 14.00(14.00)\n",
      "Iter 2290 | Time 18.8328(18.9709) | Bit/dim 3.6621(3.6606) | Xent 0.0000(0.0000) | Loss 3.6621(3.6606) | Error 0.0000(0.0000) Steps 742(748.75) | Grad Norm 3.4496(3.8315) | Total Time 14.00(14.00)\n",
      "Iter 2300 | Time 19.6730(18.9572) | Bit/dim 3.6435(3.6580) | Xent 0.0000(0.0000) | Loss 3.6435(3.6580) | Error 0.0000(0.0000) Steps 766(749.93) | Grad Norm 3.1084(3.9250) | Total Time 14.00(14.00)\n",
      "Iter 2310 | Time 19.5398(18.9971) | Bit/dim 3.6440(3.6570) | Xent 0.0000(0.0000) | Loss 3.6440(3.6570) | Error 0.0000(0.0000) Steps 736(750.29) | Grad Norm 1.5648(3.9142) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 93.6541, Epoch Time 1154.6768(1030.0449), Bit/dim 3.6533(best: 3.6559), Xent 0.0000, Loss 3.6533, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2320 | Time 18.6995(18.9457) | Bit/dim 3.6331(3.6563) | Xent 0.0000(0.0000) | Loss 3.6331(3.6563) | Error 0.0000(0.0000) Steps 754(749.99) | Grad Norm 3.8999(3.8950) | Total Time 14.00(14.00)\n",
      "Iter 2330 | Time 19.1752(18.9927) | Bit/dim 3.6596(3.6557) | Xent 0.0000(0.0000) | Loss 3.6596(3.6557) | Error 0.0000(0.0000) Steps 766(752.59) | Grad Norm 3.4748(4.0110) | Total Time 14.00(14.00)\n",
      "Iter 2340 | Time 19.4897(18.9841) | Bit/dim 3.6034(3.6546) | Xent 0.0000(0.0000) | Loss 3.6034(3.6546) | Error 0.0000(0.0000) Steps 760(752.37) | Grad Norm 2.4506(3.6175) | Total Time 14.00(14.00)\n",
      "Iter 2350 | Time 18.6149(18.9725) | Bit/dim 3.6150(3.6523) | Xent 0.0000(0.0000) | Loss 3.6150(3.6523) | Error 0.0000(0.0000) Steps 748(751.02) | Grad Norm 4.7113(3.8768) | Total Time 14.00(14.00)\n",
      "Iter 2360 | Time 19.2675(19.0772) | Bit/dim 3.6259(3.6524) | Xent 0.0000(0.0000) | Loss 3.6259(3.6524) | Error 0.0000(0.0000) Steps 766(752.79) | Grad Norm 4.1448(4.0341) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 93.0316, Epoch Time 1158.1136(1033.8870), Bit/dim 3.6513(best: 3.6533), Xent 0.0000, Loss 3.6513, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2370 | Time 18.6472(19.0754) | Bit/dim 3.6465(3.6527) | Xent 0.0000(0.0000) | Loss 3.6465(3.6527) | Error 0.0000(0.0000) Steps 742(751.32) | Grad Norm 1.3241(3.7046) | Total Time 14.00(14.00)\n",
      "Iter 2380 | Time 18.8559(19.0794) | Bit/dim 3.6721(3.6501) | Xent 0.0000(0.0000) | Loss 3.6721(3.6501) | Error 0.0000(0.0000) Steps 760(751.67) | Grad Norm 2.4402(3.3193) | Total Time 14.00(14.00)\n",
      "Iter 2390 | Time 19.4917(19.1312) | Bit/dim 3.6332(3.6533) | Xent 0.0000(0.0000) | Loss 3.6332(3.6533) | Error 0.0000(0.0000) Steps 760(751.62) | Grad Norm 7.3138(4.2330) | Total Time 14.00(14.00)\n",
      "Iter 2400 | Time 18.7357(19.1355) | Bit/dim 3.6542(3.6540) | Xent 0.0000(0.0000) | Loss 3.6542(3.6540) | Error 0.0000(0.0000) Steps 730(750.47) | Grad Norm 3.2613(4.3113) | Total Time 14.00(14.00)\n",
      "Iter 2410 | Time 19.3410(19.1112) | Bit/dim 3.6223(3.6544) | Xent 0.0000(0.0000) | Loss 3.6223(3.6544) | Error 0.0000(0.0000) Steps 742(750.37) | Grad Norm 1.6552(3.9551) | Total Time 14.00(14.00)\n",
      "Iter 2420 | Time 19.6252(19.1336) | Bit/dim 3.6417(3.6487) | Xent 0.0000(0.0000) | Loss 3.6417(3.6487) | Error 0.0000(0.0000) Steps 754(751.32) | Grad Norm 2.8585(3.6296) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 93.9800, Epoch Time 1164.2646(1037.7983), Bit/dim 3.6417(best: 3.6513), Xent 0.0000, Loss 3.6417, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2430 | Time 18.9654(19.1244) | Bit/dim 3.6686(3.6473) | Xent 0.0000(0.0000) | Loss 3.6686(3.6473) | Error 0.0000(0.0000) Steps 748(752.47) | Grad Norm 2.0324(3.2591) | Total Time 14.00(14.00)\n",
      "Iter 2440 | Time 18.8598(19.1220) | Bit/dim 3.6341(3.6429) | Xent 0.0000(0.0000) | Loss 3.6341(3.6429) | Error 0.0000(0.0000) Steps 760(753.07) | Grad Norm 4.7658(3.6822) | Total Time 14.00(14.00)\n",
      "Iter 2450 | Time 18.7125(19.1028) | Bit/dim 3.6193(3.6405) | Xent 0.0000(0.0000) | Loss 3.6193(3.6405) | Error 0.0000(0.0000) Steps 754(753.19) | Grad Norm 2.6591(3.3631) | Total Time 14.00(14.00)\n",
      "Iter 2460 | Time 19.4327(19.0409) | Bit/dim 3.6730(3.6456) | Xent 0.0000(0.0000) | Loss 3.6730(3.6456) | Error 0.0000(0.0000) Steps 736(752.42) | Grad Norm 3.6961(3.8865) | Total Time 14.00(14.00)\n",
      "Iter 2470 | Time 18.9670(19.0278) | Bit/dim 3.6366(3.6445) | Xent 0.0000(0.0000) | Loss 3.6366(3.6445) | Error 0.0000(0.0000) Steps 742(750.94) | Grad Norm 3.4052(3.7054) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 93.2524, Epoch Time 1158.4392(1041.4175), Bit/dim 3.6377(best: 3.6417), Xent 0.0000, Loss 3.6377, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2480 | Time 19.0358(19.0678) | Bit/dim 3.6089(3.6393) | Xent 0.0000(0.0000) | Loss 3.6089(3.6393) | Error 0.0000(0.0000) Steps 760(751.35) | Grad Norm 3.9472(3.7426) | Total Time 14.00(14.00)\n",
      "Iter 2490 | Time 19.1157(19.1333) | Bit/dim 3.6064(3.6385) | Xent 0.0000(0.0000) | Loss 3.6064(3.6385) | Error 0.0000(0.0000) Steps 754(751.61) | Grad Norm 6.5291(3.8452) | Total Time 14.00(14.00)\n",
      "Iter 2500 | Time 18.6140(19.1065) | Bit/dim 3.6241(3.6417) | Xent 0.0000(0.0000) | Loss 3.6241(3.6417) | Error 0.0000(0.0000) Steps 736(750.68) | Grad Norm 3.3804(3.8955) | Total Time 14.00(14.00)\n",
      "Iter 2510 | Time 19.3844(19.1299) | Bit/dim 3.6132(3.6394) | Xent 0.0000(0.0000) | Loss 3.6132(3.6394) | Error 0.0000(0.0000) Steps 754(750.55) | Grad Norm 3.8750(3.7948) | Total Time 14.00(14.00)\n",
      "Iter 2520 | Time 19.2892(19.2233) | Bit/dim 3.6434(3.6392) | Xent 0.0000(0.0000) | Loss 3.6434(3.6392) | Error 0.0000(0.0000) Steps 760(750.62) | Grad Norm 2.7539(3.7168) | Total Time 14.00(14.00)\n",
      "Iter 2530 | Time 19.7070(19.2619) | Bit/dim 3.6241(3.6365) | Xent 0.0000(0.0000) | Loss 3.6241(3.6365) | Error 0.0000(0.0000) Steps 736(750.76) | Grad Norm 3.4598(3.7589) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 93.6882, Epoch Time 1170.7293(1045.2969), Bit/dim 3.6404(best: 3.6377), Xent 0.0000, Loss 3.6404, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2540 | Time 18.7197(19.1813) | Bit/dim 3.6601(3.6383) | Xent 0.0000(0.0000) | Loss 3.6601(3.6383) | Error 0.0000(0.0000) Steps 754(751.73) | Grad Norm 4.6212(3.8590) | Total Time 14.00(14.00)\n",
      "Iter 2550 | Time 19.2043(19.1834) | Bit/dim 3.6302(3.6376) | Xent 0.0000(0.0000) | Loss 3.6302(3.6376) | Error 0.0000(0.0000) Steps 736(751.16) | Grad Norm 2.9566(3.8916) | Total Time 14.00(14.00)\n",
      "Iter 2560 | Time 19.7470(19.2361) | Bit/dim 3.6054(3.6357) | Xent 0.0000(0.0000) | Loss 3.6054(3.6357) | Error 0.0000(0.0000) Steps 766(751.47) | Grad Norm 4.6964(3.8406) | Total Time 14.00(14.00)\n",
      "Iter 2570 | Time 19.7223(19.3096) | Bit/dim 3.6346(3.6325) | Xent 0.0000(0.0000) | Loss 3.6346(3.6325) | Error 0.0000(0.0000) Steps 760(752.35) | Grad Norm 5.8255(3.7609) | Total Time 14.00(14.00)\n",
      "Iter 2580 | Time 19.0490(19.3415) | Bit/dim 3.5991(3.6330) | Xent 0.0000(0.0000) | Loss 3.5991(3.6330) | Error 0.0000(0.0000) Steps 742(752.25) | Grad Norm 3.2197(4.0318) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 94.8320, Epoch Time 1174.7338(1049.1800), Bit/dim 3.6300(best: 3.6377), Xent 0.0000, Loss 3.6300, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2590 | Time 19.1382(19.3725) | Bit/dim 3.6773(3.6315) | Xent 0.0000(0.0000) | Loss 3.6773(3.6315) | Error 0.0000(0.0000) Steps 754(752.80) | Grad Norm 3.7700(3.8766) | Total Time 14.00(14.00)\n",
      "Iter 2600 | Time 19.2201(19.4843) | Bit/dim 3.6260(3.6303) | Xent 0.0000(0.0000) | Loss 3.6260(3.6303) | Error 0.0000(0.0000) Steps 760(754.97) | Grad Norm 2.6085(3.6813) | Total Time 14.00(14.00)\n",
      "Iter 2610 | Time 20.1807(19.5815) | Bit/dim 3.6484(3.6285) | Xent 0.0000(0.0000) | Loss 3.6484(3.6285) | Error 0.0000(0.0000) Steps 736(755.31) | Grad Norm 5.3975(3.8821) | Total Time 14.00(14.00)\n",
      "Iter 2620 | Time 19.6583(19.6050) | Bit/dim 3.6323(3.6295) | Xent 0.0000(0.0000) | Loss 3.6323(3.6295) | Error 0.0000(0.0000) Steps 760(756.31) | Grad Norm 3.5347(3.9201) | Total Time 14.00(14.00)\n",
      "Iter 2630 | Time 19.1756(19.5423) | Bit/dim 3.6230(3.6310) | Xent 0.0000(0.0000) | Loss 3.6230(3.6310) | Error 0.0000(0.0000) Steps 748(755.49) | Grad Norm 8.0790(4.0654) | Total Time 14.00(14.00)\n",
      "Iter 2640 | Time 19.4108(19.5194) | Bit/dim 3.6327(3.6303) | Xent 0.0000(0.0000) | Loss 3.6327(3.6303) | Error 0.0000(0.0000) Steps 766(755.83) | Grad Norm 1.7570(4.0644) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 94.6663, Epoch Time 1190.7642(1053.4275), Bit/dim 3.6229(best: 3.6300), Xent 0.0000, Loss 3.6229, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2650 | Time 19.2585(19.5267) | Bit/dim 3.6426(3.6300) | Xent 0.0000(0.0000) | Loss 3.6426(3.6300) | Error 0.0000(0.0000) Steps 754(756.88) | Grad Norm 4.2709(3.8551) | Total Time 14.00(14.00)\n",
      "Iter 2660 | Time 19.7754(19.5409) | Bit/dim 3.6200(3.6269) | Xent 0.0000(0.0000) | Loss 3.6200(3.6269) | Error 0.0000(0.0000) Steps 760(759.56) | Grad Norm 1.3175(3.5703) | Total Time 14.00(14.00)\n",
      "Iter 2670 | Time 19.5709(19.6113) | Bit/dim 3.6553(3.6272) | Xent 0.0000(0.0000) | Loss 3.6553(3.6272) | Error 0.0000(0.0000) Steps 772(762.00) | Grad Norm 9.2788(3.6520) | Total Time 14.00(14.00)\n",
      "Iter 2680 | Time 19.8032(19.6015) | Bit/dim 3.6466(3.6290) | Xent 0.0000(0.0000) | Loss 3.6466(3.6290) | Error 0.0000(0.0000) Steps 772(761.65) | Grad Norm 4.3870(3.8452) | Total Time 14.00(14.00)\n",
      "Iter 2690 | Time 19.8477(19.6262) | Bit/dim 3.6079(3.6252) | Xent 0.0000(0.0000) | Loss 3.6079(3.6252) | Error 0.0000(0.0000) Steps 754(761.02) | Grad Norm 2.2519(3.5095) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 96.2027, Epoch Time 1194.2199(1057.6513), Bit/dim 3.6230(best: 3.6229), Xent 0.0000, Loss 3.6230, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2700 | Time 19.4697(19.6833) | Bit/dim 3.6226(3.6234) | Xent 0.0000(0.0000) | Loss 3.6226(3.6234) | Error 0.0000(0.0000) Steps 772(761.85) | Grad Norm 1.9895(3.4677) | Total Time 14.00(14.00)\n",
      "Iter 2710 | Time 20.6165(19.7492) | Bit/dim 3.6028(3.6201) | Xent 0.0000(0.0000) | Loss 3.6028(3.6201) | Error 0.0000(0.0000) Steps 760(763.21) | Grad Norm 2.3143(3.1982) | Total Time 14.00(14.00)\n",
      "Iter 2720 | Time 19.2638(19.7685) | Bit/dim 3.6268(3.6183) | Xent 0.0000(0.0000) | Loss 3.6268(3.6183) | Error 0.0000(0.0000) Steps 754(764.58) | Grad Norm 9.9119(3.2547) | Total Time 14.00(14.00)\n",
      "Iter 2730 | Time 19.5981(19.7266) | Bit/dim 3.6342(3.6252) | Xent 0.0000(0.0000) | Loss 3.6342(3.6252) | Error 0.0000(0.0000) Steps 748(761.47) | Grad Norm 4.6434(3.9198) | Total Time 14.00(14.00)\n",
      "Iter 2740 | Time 19.7792(19.7031) | Bit/dim 3.6274(3.6286) | Xent 0.0000(0.0000) | Loss 3.6274(3.6286) | Error 0.0000(0.0000) Steps 772(760.52) | Grad Norm 2.0447(3.5267) | Total Time 14.00(14.00)\n",
      "Iter 2750 | Time 20.0354(19.7387) | Bit/dim 3.6295(3.6228) | Xent 0.0000(0.0000) | Loss 3.6295(3.6228) | Error 0.0000(0.0000) Steps 778(763.76) | Grad Norm 2.4522(3.3284) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 93.9871, Epoch Time 1199.3206(1061.9014), Bit/dim 3.6134(best: 3.6229), Xent 0.0000, Loss 3.6134, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2760 | Time 18.9496(19.7346) | Bit/dim 3.6037(3.6204) | Xent 0.0000(0.0000) | Loss 3.6037(3.6204) | Error 0.0000(0.0000) Steps 748(764.41) | Grad Norm 4.6112(3.6064) | Total Time 14.00(14.00)\n",
      "Iter 2770 | Time 19.5569(19.7821) | Bit/dim 3.6304(3.6201) | Xent 0.0000(0.0000) | Loss 3.6304(3.6201) | Error 0.0000(0.0000) Steps 772(764.09) | Grad Norm 2.9454(3.6143) | Total Time 14.00(14.00)\n",
      "Iter 2780 | Time 19.7969(19.7566) | Bit/dim 3.6230(3.6177) | Xent 0.0000(0.0000) | Loss 3.6230(3.6177) | Error 0.0000(0.0000) Steps 778(766.04) | Grad Norm 2.4031(3.2905) | Total Time 14.00(14.00)\n",
      "Iter 2790 | Time 19.8853(19.8140) | Bit/dim 3.6298(3.6174) | Xent 0.0000(0.0000) | Loss 3.6298(3.6174) | Error 0.0000(0.0000) Steps 754(766.73) | Grad Norm 6.8410(3.2397) | Total Time 14.00(14.00)\n",
      "Iter 2800 | Time 19.4472(19.7798) | Bit/dim 3.6262(3.6190) | Xent 0.0000(0.0000) | Loss 3.6262(3.6190) | Error 0.0000(0.0000) Steps 760(764.92) | Grad Norm 2.1768(3.4205) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 94.3265, Epoch Time 1200.6252(1066.0631), Bit/dim 3.6139(best: 3.6134), Xent 0.0000, Loss 3.6139, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2810 | Time 20.2199(19.8249) | Bit/dim 3.6298(3.6163) | Xent 0.0000(0.0000) | Loss 3.6298(3.6163) | Error 0.0000(0.0000) Steps 766(763.52) | Grad Norm 3.7926(3.4433) | Total Time 14.00(14.00)\n",
      "Iter 2820 | Time 19.7553(19.8525) | Bit/dim 3.6266(3.6129) | Xent 0.0000(0.0000) | Loss 3.6266(3.6129) | Error 0.0000(0.0000) Steps 778(765.30) | Grad Norm 4.6851(3.7532) | Total Time 14.00(14.00)\n",
      "Iter 2830 | Time 20.0196(19.8568) | Bit/dim 3.6235(3.6147) | Xent 0.0000(0.0000) | Loss 3.6235(3.6147) | Error 0.0000(0.0000) Steps 754(766.98) | Grad Norm 2.8376(3.5470) | Total Time 14.00(14.00)\n",
      "Iter 2840 | Time 20.1345(19.9094) | Bit/dim 3.5845(3.6142) | Xent 0.0000(0.0000) | Loss 3.5845(3.6142) | Error 0.0000(0.0000) Steps 784(767.13) | Grad Norm 3.1341(3.7831) | Total Time 14.00(14.00)\n",
      "Iter 2850 | Time 20.1217(19.8904) | Bit/dim 3.6087(3.6107) | Xent 0.0000(0.0000) | Loss 3.6087(3.6107) | Error 0.0000(0.0000) Steps 772(766.62) | Grad Norm 4.6255(3.4908) | Total Time 14.00(14.00)\n",
      "Iter 2860 | Time 19.9940(19.8836) | Bit/dim 3.6142(3.6129) | Xent 0.0000(0.0000) | Loss 3.6142(3.6129) | Error 0.0000(0.0000) Steps 760(766.79) | Grad Norm 3.0651(3.6943) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 94.6195, Epoch Time 1208.5968(1070.3391), Bit/dim 3.6055(best: 3.6134), Xent 0.0000, Loss 3.6055, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2870 | Time 19.8858(19.8315) | Bit/dim 3.6308(3.6128) | Xent 0.0000(0.0000) | Loss 3.6308(3.6128) | Error 0.0000(0.0000) Steps 784(767.24) | Grad Norm 5.1248(3.5361) | Total Time 14.00(14.00)\n",
      "Iter 2880 | Time 20.3205(19.8010) | Bit/dim 3.5575(3.6104) | Xent 0.0000(0.0000) | Loss 3.5575(3.6104) | Error 0.0000(0.0000) Steps 772(767.54) | Grad Norm 3.1354(3.6330) | Total Time 14.00(14.00)\n",
      "Iter 2890 | Time 19.9464(19.7263) | Bit/dim 3.6411(3.6085) | Xent 0.0000(0.0000) | Loss 3.6411(3.6085) | Error 0.0000(0.0000) Steps 772(767.24) | Grad Norm 4.1765(3.3739) | Total Time 14.00(14.00)\n",
      "Iter 2900 | Time 19.3297(19.6763) | Bit/dim 3.6225(3.6114) | Xent 0.0000(0.0000) | Loss 3.6225(3.6114) | Error 0.0000(0.0000) Steps 766(767.32) | Grad Norm 2.3515(3.6907) | Total Time 14.00(14.00)\n",
      "Iter 2910 | Time 19.6587(19.6961) | Bit/dim 3.5792(3.6073) | Xent 0.0000(0.0000) | Loss 3.5792(3.6073) | Error 0.0000(0.0000) Steps 754(767.35) | Grad Norm 3.6080(3.6096) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 94.8867, Epoch Time 1194.6025(1074.0670), Bit/dim 3.6028(best: 3.6055), Xent 0.0000, Loss 3.6028, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2920 | Time 20.0555(19.7913) | Bit/dim 3.6100(3.6080) | Xent 0.0000(0.0000) | Loss 3.6100(3.6080) | Error 0.0000(0.0000) Steps 778(767.93) | Grad Norm 2.7836(3.4235) | Total Time 14.00(14.00)\n",
      "Iter 2930 | Time 20.0870(19.7887) | Bit/dim 3.6280(3.6072) | Xent 0.0000(0.0000) | Loss 3.6280(3.6072) | Error 0.0000(0.0000) Steps 760(768.26) | Grad Norm 4.0472(3.4830) | Total Time 14.00(14.00)\n",
      "Iter 2940 | Time 19.6423(19.7384) | Bit/dim 3.5623(3.6034) | Xent 0.0000(0.0000) | Loss 3.5623(3.6034) | Error 0.0000(0.0000) Steps 778(768.44) | Grad Norm 3.2065(3.4560) | Total Time 14.00(14.00)\n",
      "Iter 2950 | Time 19.8145(19.7454) | Bit/dim 3.6371(3.6045) | Xent 0.0000(0.0000) | Loss 3.6371(3.6045) | Error 0.0000(0.0000) Steps 760(767.64) | Grad Norm 7.9677(3.8260) | Total Time 14.00(14.00)\n",
      "Iter 2960 | Time 18.8228(19.6636) | Bit/dim 3.5954(3.6062) | Xent 0.0000(0.0000) | Loss 3.5954(3.6062) | Error 0.0000(0.0000) Steps 754(767.18) | Grad Norm 3.0246(3.7360) | Total Time 14.00(14.00)\n",
      "Iter 2970 | Time 19.4671(19.5888) | Bit/dim 3.5970(3.6057) | Xent 0.0000(0.0000) | Loss 3.5970(3.6057) | Error 0.0000(0.0000) Steps 772(766.44) | Grad Norm 3.9456(3.7490) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 94.7811, Epoch Time 1192.5929(1077.6228), Bit/dim 3.6026(best: 3.6028), Xent 0.0000, Loss 3.6026, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2980 | Time 19.3787(19.5876) | Bit/dim 3.6050(3.6018) | Xent 0.0000(0.0000) | Loss 3.6050(3.6018) | Error 0.0000(0.0000) Steps 754(765.88) | Grad Norm 4.5667(3.7145) | Total Time 14.00(14.00)\n",
      "Iter 2990 | Time 20.5073(19.7230) | Bit/dim 3.5781(3.5999) | Xent 0.0000(0.0000) | Loss 3.5781(3.5999) | Error 0.0000(0.0000) Steps 790(768.70) | Grad Norm 2.7535(3.4015) | Total Time 14.00(14.00)\n",
      "Iter 3000 | Time 20.0170(19.8151) | Bit/dim 3.5656(3.5982) | Xent 0.0000(0.0000) | Loss 3.5656(3.5982) | Error 0.0000(0.0000) Steps 760(769.20) | Grad Norm 1.9085(3.5645) | Total Time 14.00(14.00)\n",
      "Iter 3010 | Time 20.3074(19.8828) | Bit/dim 3.6151(3.5998) | Xent 0.0000(0.0000) | Loss 3.6151(3.5998) | Error 0.0000(0.0000) Steps 760(769.89) | Grad Norm 2.1493(3.3011) | Total Time 14.00(14.00)\n",
      "Iter 3020 | Time 19.9671(19.8449) | Bit/dim 3.5912(3.6050) | Xent 0.0000(0.0000) | Loss 3.5912(3.6050) | Error 0.0000(0.0000) Steps 760(768.48) | Grad Norm 1.8803(3.7264) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 95.5185, Epoch Time 1206.8336(1081.4991), Bit/dim 3.6005(best: 3.6026), Xent 0.0000, Loss 3.6005, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3030 | Time 19.5291(19.7601) | Bit/dim 3.5923(3.6040) | Xent 0.0000(0.0000) | Loss 3.5923(3.6040) | Error 0.0000(0.0000) Steps 778(768.63) | Grad Norm 2.6823(3.6208) | Total Time 14.00(14.00)\n",
      "Iter 3040 | Time 19.9300(19.7537) | Bit/dim 3.5931(3.5984) | Xent 0.0000(0.0000) | Loss 3.5931(3.5984) | Error 0.0000(0.0000) Steps 772(769.66) | Grad Norm 3.4233(3.3641) | Total Time 14.00(14.00)\n",
      "Iter 3050 | Time 20.3549(19.7852) | Bit/dim 3.5826(3.6004) | Xent 0.0000(0.0000) | Loss 3.5826(3.6004) | Error 0.0000(0.0000) Steps 760(769.33) | Grad Norm 2.9839(3.6930) | Total Time 14.00(14.00)\n",
      "Iter 3060 | Time 18.8208(19.7838) | Bit/dim 3.6248(3.6031) | Xent 0.0000(0.0000) | Loss 3.6248(3.6031) | Error 0.0000(0.0000) Steps 760(768.15) | Grad Norm 5.0744(3.7190) | Total Time 14.00(14.00)\n",
      "Iter 3070 | Time 20.1940(19.7997) | Bit/dim 3.5920(3.6008) | Xent 0.0000(0.0000) | Loss 3.5920(3.6008) | Error 0.0000(0.0000) Steps 784(767.90) | Grad Norm 4.0531(3.6999) | Total Time 14.00(14.00)\n",
      "Iter 3080 | Time 19.7263(19.7666) | Bit/dim 3.5615(3.5992) | Xent 0.0000(0.0000) | Loss 3.5615(3.5992) | Error 0.0000(0.0000) Steps 760(768.69) | Grad Norm 4.1109(3.7129) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 95.2756, Epoch Time 1198.9847(1085.0237), Bit/dim 3.5961(best: 3.6005), Xent 0.0000, Loss 3.5961, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3090 | Time 19.6817(19.7626) | Bit/dim 3.5976(3.5998) | Xent 0.0000(0.0000) | Loss 3.5976(3.5998) | Error 0.0000(0.0000) Steps 760(768.09) | Grad Norm 3.1904(3.5310) | Total Time 14.00(14.00)\n",
      "Iter 3100 | Time 20.0735(19.8133) | Bit/dim 3.5892(3.5954) | Xent 0.0000(0.0000) | Loss 3.5892(3.5954) | Error 0.0000(0.0000) Steps 778(769.46) | Grad Norm 3.1599(3.1543) | Total Time 14.00(14.00)\n",
      "Iter 3110 | Time 20.0725(19.9133) | Bit/dim 3.5869(3.5966) | Xent 0.0000(0.0000) | Loss 3.5869(3.5966) | Error 0.0000(0.0000) Steps 778(769.69) | Grad Norm 4.2296(3.8382) | Total Time 14.00(14.00)\n",
      "Iter 3120 | Time 20.3720(19.9383) | Bit/dim 3.6079(3.5963) | Xent 0.0000(0.0000) | Loss 3.6079(3.5963) | Error 0.0000(0.0000) Steps 760(769.96) | Grad Norm 4.7499(3.8403) | Total Time 14.00(14.00)\n",
      "Iter 3130 | Time 19.2697(19.8795) | Bit/dim 3.5740(3.5957) | Xent 0.0000(0.0000) | Loss 3.5740(3.5957) | Error 0.0000(0.0000) Steps 766(768.62) | Grad Norm 2.2848(3.4748) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 95.5037, Epoch Time 1209.1735(1088.7482), Bit/dim 3.5899(best: 3.5961), Xent 0.0000, Loss 3.5899, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3140 | Time 19.9032(19.8885) | Bit/dim 3.6225(3.5949) | Xent 0.0000(0.0000) | Loss 3.6225(3.5949) | Error 0.0000(0.0000) Steps 778(770.12) | Grad Norm 3.9385(3.1691) | Total Time 14.00(14.00)\n",
      "Iter 3150 | Time 20.8479(19.9694) | Bit/dim 3.5950(3.5951) | Xent 0.0000(0.0000) | Loss 3.5950(3.5951) | Error 0.0000(0.0000) Steps 760(770.94) | Grad Norm 3.8792(3.5972) | Total Time 14.00(14.00)\n",
      "Iter 3160 | Time 19.4515(19.9225) | Bit/dim 3.5533(3.5916) | Xent 0.0000(0.0000) | Loss 3.5533(3.5916) | Error 0.0000(0.0000) Steps 784(771.50) | Grad Norm 3.3213(3.5270) | Total Time 14.00(14.00)\n",
      "Iter 3170 | Time 19.9545(19.9099) | Bit/dim 3.5874(3.5902) | Xent 0.0000(0.0000) | Loss 3.5874(3.5902) | Error 0.0000(0.0000) Steps 778(772.58) | Grad Norm 1.7858(3.4151) | Total Time 14.00(14.00)\n",
      "Iter 3180 | Time 20.2466(19.8908) | Bit/dim 3.6145(3.5895) | Xent 0.0000(0.0000) | Loss 3.6145(3.5895) | Error 0.0000(0.0000) Steps 766(774.30) | Grad Norm 6.0772(3.5878) | Total Time 14.00(14.00)\n",
      "Iter 3190 | Time 20.0467(19.8464) | Bit/dim 3.6203(3.5932) | Xent 0.0000(0.0000) | Loss 3.6203(3.5932) | Error 0.0000(0.0000) Steps 778(773.59) | Grad Norm 2.9820(3.4885) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 96.5356, Epoch Time 1207.7594(1092.3185), Bit/dim 3.5928(best: 3.5899), Xent 0.0000, Loss 3.5928, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3200 | Time 20.1089(19.8674) | Bit/dim 3.6076(3.5903) | Xent 0.0000(0.0000) | Loss 3.6076(3.5903) | Error 0.0000(0.0000) Steps 778(773.16) | Grad Norm 2.1682(3.5686) | Total Time 14.00(14.00)\n",
      "Iter 3210 | Time 19.5288(19.9451) | Bit/dim 3.5766(3.5899) | Xent 0.0000(0.0000) | Loss 3.5766(3.5899) | Error 0.0000(0.0000) Steps 778(774.44) | Grad Norm 3.5359(3.3532) | Total Time 14.00(14.00)\n",
      "Iter 3220 | Time 19.7582(19.8826) | Bit/dim 3.5758(3.5891) | Xent 0.0000(0.0000) | Loss 3.5758(3.5891) | Error 0.0000(0.0000) Steps 790(775.02) | Grad Norm 5.2971(3.5998) | Total Time 14.00(14.00)\n",
      "Iter 3230 | Time 19.8975(19.9033) | Bit/dim 3.6582(3.5925) | Xent 0.0000(0.0000) | Loss 3.6582(3.5925) | Error 0.0000(0.0000) Steps 772(776.51) | Grad Norm 3.0952(3.6278) | Total Time 14.00(14.00)\n",
      "Iter 3240 | Time 19.7328(19.9073) | Bit/dim 3.5424(3.5895) | Xent 0.0000(0.0000) | Loss 3.5424(3.5895) | Error 0.0000(0.0000) Steps 790(778.23) | Grad Norm 3.6208(3.3546) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 94.6966, Epoch Time 1208.5996(1095.8069), Bit/dim 3.5937(best: 3.5899), Xent 0.0000, Loss 3.5937, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3250 | Time 21.0839(19.9717) | Bit/dim 3.6218(3.5892) | Xent 0.0000(0.0000) | Loss 3.6218(3.5892) | Error 0.0000(0.0000) Steps 784(779.92) | Grad Norm 3.7696(3.6305) | Total Time 14.00(14.00)\n",
      "Iter 3260 | Time 19.9036(19.9466) | Bit/dim 3.5894(3.5890) | Xent 0.0000(0.0000) | Loss 3.5894(3.5890) | Error 0.0000(0.0000) Steps 772(779.98) | Grad Norm 4.6108(3.6991) | Total Time 14.00(14.00)\n",
      "Iter 3270 | Time 20.3250(19.9753) | Bit/dim 3.5786(3.5858) | Xent 0.0000(0.0000) | Loss 3.5786(3.5858) | Error 0.0000(0.0000) Steps 796(781.57) | Grad Norm 1.4491(3.4250) | Total Time 14.00(14.00)\n",
      "Iter 3280 | Time 19.8234(20.0296) | Bit/dim 3.5948(3.5865) | Xent 0.0000(0.0000) | Loss 3.5948(3.5865) | Error 0.0000(0.0000) Steps 778(782.87) | Grad Norm 2.9494(3.8105) | Total Time 14.00(14.00)\n",
      "Iter 3290 | Time 19.8063(20.0147) | Bit/dim 3.5731(3.5857) | Xent 0.0000(0.0000) | Loss 3.5731(3.5857) | Error 0.0000(0.0000) Steps 784(782.79) | Grad Norm 2.6685(3.6191) | Total Time 14.00(14.00)\n",
      "Iter 3300 | Time 20.1265(20.0398) | Bit/dim 3.5933(3.5855) | Xent 0.0000(0.0000) | Loss 3.5933(3.5855) | Error 0.0000(0.0000) Steps 784(783.35) | Grad Norm 2.6540(3.3982) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 96.2811, Epoch Time 1217.7648(1099.4657), Bit/dim 3.5788(best: 3.5899), Xent 0.0000, Loss 3.5788, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3310 | Time 20.7254(20.1464) | Bit/dim 3.6137(3.5847) | Xent 0.0000(0.0000) | Loss 3.6137(3.5847) | Error 0.0000(0.0000) Steps 784(783.65) | Grad Norm 6.1989(3.4352) | Total Time 14.00(14.00)\n",
      "Iter 3320 | Time 20.0107(20.1829) | Bit/dim 3.6027(3.5854) | Xent 0.0000(0.0000) | Loss 3.6027(3.5854) | Error 0.0000(0.0000) Steps 778(783.84) | Grad Norm 3.6347(3.5104) | Total Time 14.00(14.00)\n",
      "Iter 3330 | Time 20.0539(20.1733) | Bit/dim 3.6032(3.5840) | Xent 0.0000(0.0000) | Loss 3.6032(3.5840) | Error 0.0000(0.0000) Steps 796(786.65) | Grad Norm 3.0083(3.6372) | Total Time 14.00(14.00)\n",
      "Iter 3340 | Time 20.6467(20.1741) | Bit/dim 3.6026(3.5835) | Xent 0.0000(0.0000) | Loss 3.6026(3.5835) | Error 0.0000(0.0000) Steps 790(786.84) | Grad Norm 3.8805(3.4902) | Total Time 14.00(14.00)\n",
      "Iter 3350 | Time 20.7302(20.3180) | Bit/dim 3.5383(3.5816) | Xent 0.0000(0.0000) | Loss 3.5383(3.5816) | Error 0.0000(0.0000) Steps 772(788.14) | Grad Norm 2.3899(3.4613) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 94.6806, Epoch Time 1230.4698(1103.3958), Bit/dim 3.5777(best: 3.5788), Xent 0.0000, Loss 3.5777, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3360 | Time 20.9306(20.2855) | Bit/dim 3.5927(3.5803) | Xent 0.0000(0.0000) | Loss 3.5927(3.5803) | Error 0.0000(0.0000) Steps 820(791.74) | Grad Norm 2.3098(3.1870) | Total Time 14.00(14.00)\n",
      "Iter 3370 | Time 19.9273(20.3099) | Bit/dim 3.6007(3.5821) | Xent 0.0000(0.0000) | Loss 3.6007(3.5821) | Error 0.0000(0.0000) Steps 802(792.59) | Grad Norm 2.2546(3.5652) | Total Time 14.00(14.00)\n",
      "Iter 3380 | Time 21.1662(20.3461) | Bit/dim 3.5477(3.5807) | Xent 0.0000(0.0000) | Loss 3.5477(3.5807) | Error 0.0000(0.0000) Steps 778(792.56) | Grad Norm 3.2156(3.3105) | Total Time 14.00(14.00)\n",
      "Iter 3390 | Time 20.4281(20.3841) | Bit/dim 3.5854(3.5808) | Xent 0.0000(0.0000) | Loss 3.5854(3.5808) | Error 0.0000(0.0000) Steps 814(793.85) | Grad Norm 2.0424(3.4245) | Total Time 14.00(14.00)\n",
      "Iter 3400 | Time 20.7438(20.4646) | Bit/dim 3.5442(3.5789) | Xent 0.0000(0.0000) | Loss 3.5442(3.5789) | Error 0.0000(0.0000) Steps 808(796.08) | Grad Norm 5.0034(3.5331) | Total Time 14.00(14.00)\n",
      "Iter 3410 | Time 20.2476(20.4407) | Bit/dim 3.5899(3.5783) | Xent 0.0000(0.0000) | Loss 3.5899(3.5783) | Error 0.0000(0.0000) Steps 802(795.26) | Grad Norm 2.1872(3.4331) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 95.6217, Epoch Time 1238.6920(1107.4547), Bit/dim 3.5745(best: 3.5777), Xent 0.0000, Loss 3.5745, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3420 | Time 20.8794(20.4401) | Bit/dim 3.5748(3.5791) | Xent 0.0000(0.0000) | Loss 3.5748(3.5791) | Error 0.0000(0.0000) Steps 808(796.68) | Grad Norm 2.8043(3.5103) | Total Time 14.00(14.00)\n",
      "Iter 3430 | Time 20.6189(20.4451) | Bit/dim 3.5593(3.5781) | Xent 0.0000(0.0000) | Loss 3.5593(3.5781) | Error 0.0000(0.0000) Steps 808(795.88) | Grad Norm 1.7733(3.4051) | Total Time 14.00(14.00)\n",
      "Iter 3440 | Time 21.5195(20.4935) | Bit/dim 3.5711(3.5782) | Xent 0.0000(0.0000) | Loss 3.5711(3.5782) | Error 0.0000(0.0000) Steps 778(796.98) | Grad Norm 4.5831(3.5449) | Total Time 14.00(14.00)\n",
      "Iter 3450 | Time 21.3477(20.5326) | Bit/dim 3.5905(3.5769) | Xent 0.0000(0.0000) | Loss 3.5905(3.5769) | Error 0.0000(0.0000) Steps 814(799.31) | Grad Norm 2.4152(3.3967) | Total Time 14.00(14.00)\n",
      "Iter 3460 | Time 20.6702(20.5365) | Bit/dim 3.5752(3.5771) | Xent 0.0000(0.0000) | Loss 3.5752(3.5771) | Error 0.0000(0.0000) Steps 802(801.19) | Grad Norm 3.3986(3.6055) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 97.3523, Epoch Time 1244.4241(1111.5638), Bit/dim 3.5743(best: 3.5745), Xent 0.0000, Loss 3.5743, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3470 | Time 20.0325(20.5010) | Bit/dim 3.5989(3.5755) | Xent 0.0000(0.0000) | Loss 3.5989(3.5755) | Error 0.0000(0.0000) Steps 820(803.43) | Grad Norm 2.5140(3.4543) | Total Time 14.00(14.00)\n",
      "Iter 3480 | Time 20.4938(20.5138) | Bit/dim 3.5795(3.5746) | Xent 0.0000(0.0000) | Loss 3.5795(3.5746) | Error 0.0000(0.0000) Steps 826(805.07) | Grad Norm 4.2787(3.5385) | Total Time 14.00(14.00)\n",
      "Iter 3490 | Time 20.4615(20.5420) | Bit/dim 3.5829(3.5759) | Xent 0.0000(0.0000) | Loss 3.5829(3.5759) | Error 0.0000(0.0000) Steps 802(805.79) | Grad Norm 2.5802(3.4173) | Total Time 14.00(14.00)\n",
      "Iter 3500 | Time 20.1737(20.5555) | Bit/dim 3.5850(3.5734) | Xent 0.0000(0.0000) | Loss 3.5850(3.5734) | Error 0.0000(0.0000) Steps 808(807.16) | Grad Norm 1.9366(3.5661) | Total Time 14.00(14.00)\n",
      "Iter 3510 | Time 20.7723(20.5897) | Bit/dim 3.6004(3.5747) | Xent 0.0000(0.0000) | Loss 3.6004(3.5747) | Error 0.0000(0.0000) Steps 820(808.79) | Grad Norm 2.4242(3.2516) | Total Time 14.00(14.00)\n",
      "Iter 3520 | Time 20.8410(20.6075) | Bit/dim 3.5620(3.5734) | Xent 0.0000(0.0000) | Loss 3.5620(3.5734) | Error 0.0000(0.0000) Steps 814(809.39) | Grad Norm 3.2068(3.2214) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 99.2886, Epoch Time 1248.9643(1115.6858), Bit/dim 3.5723(best: 3.5743), Xent 0.0000, Loss 3.5723, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3530 | Time 20.1022(20.5565) | Bit/dim 3.5677(3.5712) | Xent 0.0000(0.0000) | Loss 3.5677(3.5712) | Error 0.0000(0.0000) Steps 808(809.85) | Grad Norm 3.9409(3.3705) | Total Time 14.00(14.00)\n",
      "Iter 3540 | Time 20.3752(20.5483) | Bit/dim 3.5839(3.5699) | Xent 0.0000(0.0000) | Loss 3.5839(3.5699) | Error 0.0000(0.0000) Steps 814(810.28) | Grad Norm 3.4104(3.6443) | Total Time 14.00(14.00)\n",
      "Iter 3550 | Time 21.4375(20.5873) | Bit/dim 3.5827(3.5709) | Xent 0.0000(0.0000) | Loss 3.5827(3.5709) | Error 0.0000(0.0000) Steps 820(809.97) | Grad Norm 2.4402(3.3517) | Total Time 14.00(14.00)\n",
      "Iter 3560 | Time 20.6674(20.6001) | Bit/dim 3.5612(3.5696) | Xent 0.0000(0.0000) | Loss 3.5612(3.5696) | Error 0.0000(0.0000) Steps 826(811.84) | Grad Norm 2.1250(3.3266) | Total Time 14.00(14.00)\n",
      "Iter 3570 | Time 20.5312(20.6128) | Bit/dim 3.5745(3.5706) | Xent 0.0000(0.0000) | Loss 3.5745(3.5706) | Error 0.0000(0.0000) Steps 820(812.39) | Grad Norm 3.7726(3.5037) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 99.0847, Epoch Time 1250.5936(1119.7330), Bit/dim 3.5660(best: 3.5723), Xent 0.0000, Loss 3.5660, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3580 | Time 21.0065(20.6822) | Bit/dim 3.5738(3.5726) | Xent 0.0000(0.0000) | Loss 3.5738(3.5726) | Error 0.0000(0.0000) Steps 814(812.87) | Grad Norm 2.8860(3.5507) | Total Time 14.00(14.00)\n",
      "Iter 3590 | Time 20.7454(20.6884) | Bit/dim 3.5993(3.5720) | Xent 0.0000(0.0000) | Loss 3.5993(3.5720) | Error 0.0000(0.0000) Steps 820(814.87) | Grad Norm 2.1224(3.4209) | Total Time 14.00(14.00)\n",
      "Iter 3600 | Time 21.3300(20.6827) | Bit/dim 3.6044(3.5741) | Xent 0.0000(0.0000) | Loss 3.6044(3.5741) | Error 0.0000(0.0000) Steps 820(814.87) | Grad Norm 2.5994(3.4117) | Total Time 14.00(14.00)\n",
      "Iter 3610 | Time 20.2766(20.6420) | Bit/dim 3.5651(3.5732) | Xent 0.0000(0.0000) | Loss 3.5651(3.5732) | Error 0.0000(0.0000) Steps 814(815.09) | Grad Norm 4.1886(3.2314) | Total Time 14.00(14.00)\n",
      "Iter 3620 | Time 19.9426(20.5596) | Bit/dim 3.5764(3.5722) | Xent 0.0000(0.0000) | Loss 3.5764(3.5722) | Error 0.0000(0.0000) Steps 802(814.61) | Grad Norm 3.5127(3.5412) | Total Time 14.00(14.00)\n",
      "Iter 3630 | Time 20.4823(20.5568) | Bit/dim 3.5380(3.5688) | Xent 0.0000(0.0000) | Loss 3.5380(3.5688) | Error 0.0000(0.0000) Steps 808(815.16) | Grad Norm 4.4368(3.5393) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 98.8614, Epoch Time 1248.3090(1123.5903), Bit/dim 3.5713(best: 3.5660), Xent 0.0000, Loss 3.5713, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3640 | Time 20.2351(20.5300) | Bit/dim 3.5635(3.5671) | Xent 0.0000(0.0000) | Loss 3.5635(3.5671) | Error 0.0000(0.0000) Steps 820(815.67) | Grad Norm 2.8486(3.1864) | Total Time 14.00(14.00)\n",
      "Iter 3650 | Time 19.9583(20.5209) | Bit/dim 3.5975(3.5658) | Xent 0.0000(0.0000) | Loss 3.5975(3.5658) | Error 0.0000(0.0000) Steps 814(816.52) | Grad Norm 3.4748(3.2291) | Total Time 14.00(14.00)\n",
      "Iter 3660 | Time 20.9438(20.5332) | Bit/dim 3.5406(3.5674) | Xent 0.0000(0.0000) | Loss 3.5406(3.5674) | Error 0.0000(0.0000) Steps 808(817.39) | Grad Norm 1.9251(2.9894) | Total Time 14.00(14.00)\n",
      "Iter 3670 | Time 21.0328(20.5663) | Bit/dim 3.5464(3.5670) | Xent 0.0000(0.0000) | Loss 3.5464(3.5670) | Error 0.0000(0.0000) Steps 814(818.19) | Grad Norm 5.6167(3.3330) | Total Time 14.00(14.00)\n",
      "Iter 3680 | Time 21.2241(20.5875) | Bit/dim 3.5657(3.5708) | Xent 0.0000(0.0000) | Loss 3.5657(3.5708) | Error 0.0000(0.0000) Steps 826(816.66) | Grad Norm 2.3706(3.4963) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 99.3785, Epoch Time 1246.8492(1127.2881), Bit/dim 3.5645(best: 3.5660), Xent 0.0000, Loss 3.5645, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3690 | Time 20.6171(20.5498) | Bit/dim 3.5519(3.5680) | Xent 0.0000(0.0000) | Loss 3.5519(3.5680) | Error 0.0000(0.0000) Steps 820(816.19) | Grad Norm 2.5782(3.3422) | Total Time 14.00(14.00)\n",
      "Iter 3700 | Time 20.4812(20.5771) | Bit/dim 3.5872(3.5681) | Xent 0.0000(0.0000) | Loss 3.5872(3.5681) | Error 0.0000(0.0000) Steps 796(816.02) | Grad Norm 5.6864(3.2910) | Total Time 14.00(14.00)\n",
      "Iter 3710 | Time 20.9842(20.6712) | Bit/dim 3.5755(3.5696) | Xent 0.0000(0.0000) | Loss 3.5755(3.5696) | Error 0.0000(0.0000) Steps 808(815.73) | Grad Norm 4.0211(3.3984) | Total Time 14.00(14.00)\n",
      "Iter 3720 | Time 20.8841(20.6765) | Bit/dim 3.5527(3.5652) | Xent 0.0000(0.0000) | Loss 3.5527(3.5652) | Error 0.0000(0.0000) Steps 808(815.52) | Grad Norm 3.5095(3.2168) | Total Time 14.00(14.00)\n",
      "Iter 3730 | Time 20.8702(20.7220) | Bit/dim 3.5777(3.5627) | Xent 0.0000(0.0000) | Loss 3.5777(3.5627) | Error 0.0000(0.0000) Steps 808(815.74) | Grad Norm 3.2923(3.3498) | Total Time 14.00(14.00)\n",
      "Iter 3740 | Time 20.8008(20.7224) | Bit/dim 3.5816(3.5610) | Xent 0.0000(0.0000) | Loss 3.5816(3.5610) | Error 0.0000(0.0000) Steps 820(816.86) | Grad Norm 2.1123(3.2441) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 98.0916, Epoch Time 1256.5657(1131.1664), Bit/dim 3.5577(best: 3.5645), Xent 0.0000, Loss 3.5577, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3750 | Time 20.9379(20.6834) | Bit/dim 3.5852(3.5622) | Xent 0.0000(0.0000) | Loss 3.5852(3.5622) | Error 0.0000(0.0000) Steps 808(817.11) | Grad Norm 4.8665(3.2548) | Total Time 14.00(14.00)\n",
      "Iter 3760 | Time 19.9317(20.6026) | Bit/dim 3.5719(3.5643) | Xent 0.0000(0.0000) | Loss 3.5719(3.5643) | Error 0.0000(0.0000) Steps 808(816.73) | Grad Norm 4.4385(3.5131) | Total Time 14.00(14.00)\n",
      "Iter 3770 | Time 20.6220(20.6030) | Bit/dim 3.5558(3.5634) | Xent 0.0000(0.0000) | Loss 3.5558(3.5634) | Error 0.0000(0.0000) Steps 808(815.91) | Grad Norm 2.6334(3.2806) | Total Time 14.00(14.00)\n",
      "Iter 3780 | Time 20.9268(20.5932) | Bit/dim 3.5460(3.5615) | Xent 0.0000(0.0000) | Loss 3.5460(3.5615) | Error 0.0000(0.0000) Steps 814(816.61) | Grad Norm 1.7797(3.3346) | Total Time 14.00(14.00)\n",
      "Iter 3790 | Time 20.1068(20.5695) | Bit/dim 3.5217(3.5589) | Xent 0.0000(0.0000) | Loss 3.5217(3.5589) | Error 0.0000(0.0000) Steps 826(817.55) | Grad Norm 3.2939(3.3766) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 99.5747, Epoch Time 1244.4758(1134.5657), Bit/dim 3.5582(best: 3.5577), Xent 0.0000, Loss 3.5582, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3800 | Time 20.1942(20.5026) | Bit/dim 3.5453(3.5596) | Xent 0.0000(0.0000) | Loss 3.5453(3.5596) | Error 0.0000(0.0000) Steps 820(818.34) | Grad Norm 3.3833(3.3175) | Total Time 14.00(14.00)\n",
      "Iter 3810 | Time 20.3452(20.5058) | Bit/dim 3.5700(3.5566) | Xent 0.0000(0.0000) | Loss 3.5700(3.5566) | Error 0.0000(0.0000) Steps 808(818.35) | Grad Norm 3.9316(3.3986) | Total Time 14.00(14.00)\n",
      "Iter 3820 | Time 20.4813(20.5190) | Bit/dim 3.5467(3.5551) | Xent 0.0000(0.0000) | Loss 3.5467(3.5551) | Error 0.0000(0.0000) Steps 820(818.20) | Grad Norm 2.3207(3.3034) | Total Time 14.00(14.00)\n",
      "Iter 3830 | Time 20.2369(20.5640) | Bit/dim 3.6204(3.5599) | Xent 0.0000(0.0000) | Loss 3.6204(3.5599) | Error 0.0000(0.0000) Steps 808(817.99) | Grad Norm 4.4521(3.4016) | Total Time 14.00(14.00)\n",
      "Iter 3840 | Time 21.0078(20.5544) | Bit/dim 3.5405(3.5610) | Xent 0.0000(0.0000) | Loss 3.5405(3.5610) | Error 0.0000(0.0000) Steps 820(817.89) | Grad Norm 4.5018(3.3423) | Total Time 14.00(14.00)\n",
      "Iter 3850 | Time 20.7653(20.5566) | Bit/dim 3.5667(3.5601) | Xent 0.0000(0.0000) | Loss 3.5667(3.5601) | Error 0.0000(0.0000) Steps 820(818.13) | Grad Norm 1.7693(3.3721) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 98.7436, Epoch Time 1246.5753(1137.9260), Bit/dim 3.5575(best: 3.5577), Xent 0.0000, Loss 3.5575, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3860 | Time 20.6173(20.5353) | Bit/dim 3.5503(3.5601) | Xent 0.0000(0.0000) | Loss 3.5503(3.5601) | Error 0.0000(0.0000) Steps 820(818.11) | Grad Norm 4.7080(3.4433) | Total Time 14.00(14.00)\n",
      "Iter 3870 | Time 20.7466(20.5416) | Bit/dim 3.5384(3.5585) | Xent 0.0000(0.0000) | Loss 3.5384(3.5585) | Error 0.0000(0.0000) Steps 844(819.33) | Grad Norm 1.7477(3.2581) | Total Time 14.00(14.00)\n",
      "Iter 3880 | Time 20.5882(20.5590) | Bit/dim 3.5645(3.5583) | Xent 0.0000(0.0000) | Loss 3.5645(3.5583) | Error 0.0000(0.0000) Steps 820(819.71) | Grad Norm 1.9774(3.3078) | Total Time 14.00(14.00)\n",
      "Iter 3890 | Time 20.2456(20.5693) | Bit/dim 3.5275(3.5566) | Xent 0.0000(0.0000) | Loss 3.5275(3.5566) | Error 0.0000(0.0000) Steps 820(818.94) | Grad Norm 2.4999(3.5553) | Total Time 14.00(14.00)\n",
      "Iter 3900 | Time 21.1612(20.6026) | Bit/dim 3.5213(3.5575) | Xent 0.0000(0.0000) | Loss 3.5213(3.5575) | Error 0.0000(0.0000) Steps 820(819.70) | Grad Norm 2.7713(3.4228) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 99.6409, Epoch Time 1249.4064(1141.2704), Bit/dim 3.5539(best: 3.5575), Xent 0.0000, Loss 3.5539, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3910 | Time 20.6209(20.6099) | Bit/dim 3.5425(3.5539) | Xent 0.0000(0.0000) | Loss 3.5425(3.5539) | Error 0.0000(0.0000) Steps 826(821.06) | Grad Norm 2.3762(3.1414) | Total Time 14.00(14.00)\n",
      "Iter 3920 | Time 20.7882(20.7211) | Bit/dim 3.5532(3.5537) | Xent 0.0000(0.0000) | Loss 3.5532(3.5537) | Error 0.0000(0.0000) Steps 820(820.47) | Grad Norm 2.9773(3.3089) | Total Time 14.00(14.00)\n",
      "Iter 3930 | Time 21.0265(20.7236) | Bit/dim 3.5550(3.5546) | Xent 0.0000(0.0000) | Loss 3.5550(3.5546) | Error 0.0000(0.0000) Steps 808(820.38) | Grad Norm 4.1705(3.2892) | Total Time 14.00(14.00)\n",
      "Iter 3940 | Time 20.7533(20.7439) | Bit/dim 3.5219(3.5535) | Xent 0.0000(0.0000) | Loss 3.5219(3.5535) | Error 0.0000(0.0000) Steps 820(820.23) | Grad Norm 4.1823(3.3907) | Total Time 14.00(14.00)\n",
      "Iter 3950 | Time 20.5870(20.7232) | Bit/dim 3.5545(3.5550) | Xent 0.0000(0.0000) | Loss 3.5545(3.5550) | Error 0.0000(0.0000) Steps 820(820.64) | Grad Norm 1.7277(3.2291) | Total Time 14.00(14.00)\n",
      "Iter 3960 | Time 20.2649(20.7092) | Bit/dim 3.5678(3.5536) | Xent 0.0000(0.0000) | Loss 3.5678(3.5536) | Error 0.0000(0.0000) Steps 820(820.68) | Grad Norm 2.9384(3.1223) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 100.1780, Epoch Time 1259.9798(1144.8317), Bit/dim 3.5519(best: 3.5539), Xent 0.0000, Loss 3.5519, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3970 | Time 20.6581(20.6492) | Bit/dim 3.5675(3.5520) | Xent 0.0000(0.0000) | Loss 3.5675(3.5520) | Error 0.0000(0.0000) Steps 820(821.56) | Grad Norm 5.7121(3.3473) | Total Time 14.00(14.00)\n",
      "Iter 3980 | Time 20.4763(20.6451) | Bit/dim 3.5534(3.5518) | Xent 0.0000(0.0000) | Loss 3.5534(3.5518) | Error 0.0000(0.0000) Steps 832(822.02) | Grad Norm 3.7284(3.4404) | Total Time 14.00(14.00)\n",
      "Iter 3990 | Time 20.4593(20.6448) | Bit/dim 3.5421(3.5533) | Xent 0.0000(0.0000) | Loss 3.5421(3.5533) | Error 0.0000(0.0000) Steps 820(821.63) | Grad Norm 4.0120(3.3008) | Total Time 14.00(14.00)\n",
      "Iter 4000 | Time 20.5301(20.6678) | Bit/dim 3.5515(3.5530) | Xent 0.0000(0.0000) | Loss 3.5515(3.5530) | Error 0.0000(0.0000) Steps 826(821.84) | Grad Norm 3.4201(3.3167) | Total Time 14.00(14.00)\n",
      "Iter 4010 | Time 20.4710(20.6631) | Bit/dim 3.5379(3.5507) | Xent 0.0000(0.0000) | Loss 3.5379(3.5507) | Error 0.0000(0.0000) Steps 820(821.82) | Grad Norm 3.4130(3.2648) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 99.4808, Epoch Time 1252.4998(1148.0617), Bit/dim 3.5557(best: 3.5519), Xent 0.0000, Loss 3.5557, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4020 | Time 20.6634(20.6490) | Bit/dim 3.5385(3.5531) | Xent 0.0000(0.0000) | Loss 3.5385(3.5531) | Error 0.0000(0.0000) Steps 820(822.58) | Grad Norm 3.5471(3.4447) | Total Time 14.00(14.00)\n",
      "Iter 4030 | Time 20.4740(20.6226) | Bit/dim 3.5975(3.5546) | Xent 0.0000(0.0000) | Loss 3.5975(3.5546) | Error 0.0000(0.0000) Steps 820(822.75) | Grad Norm 1.6652(3.1534) | Total Time 14.00(14.00)\n",
      "Iter 4040 | Time 20.6580(20.6461) | Bit/dim 3.5404(3.5506) | Xent 0.0000(0.0000) | Loss 3.5404(3.5506) | Error 0.0000(0.0000) Steps 820(821.75) | Grad Norm 4.8454(3.2098) | Total Time 14.00(14.00)\n",
      "Iter 4050 | Time 20.2547(20.6256) | Bit/dim 3.5325(3.5493) | Xent 0.0000(0.0000) | Loss 3.5325(3.5493) | Error 0.0000(0.0000) Steps 820(820.85) | Grad Norm 2.6453(3.0036) | Total Time 14.00(14.00)\n",
      "Iter 4060 | Time 21.0979(20.6257) | Bit/dim 3.5643(3.5499) | Xent 0.0000(0.0000) | Loss 3.5643(3.5499) | Error 0.0000(0.0000) Steps 814(820.90) | Grad Norm 1.7886(2.9261) | Total Time 14.00(14.00)\n",
      "Iter 4070 | Time 20.4476(20.5808) | Bit/dim 3.5497(3.5493) | Xent 0.0000(0.0000) | Loss 3.5497(3.5493) | Error 0.0000(0.0000) Steps 808(819.97) | Grad Norm 4.9892(3.3908) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 99.2322, Epoch Time 1248.8744(1151.0861), Bit/dim 3.5570(best: 3.5519), Xent 0.0000, Loss 3.5570, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4080 | Time 20.5709(20.5641) | Bit/dim 3.5285(3.5486) | Xent 0.0000(0.0000) | Loss 3.5285(3.5486) | Error 0.0000(0.0000) Steps 826(821.43) | Grad Norm 3.0424(3.3822) | Total Time 14.00(14.00)\n",
      "Iter 4090 | Time 20.1304(20.5112) | Bit/dim 3.5288(3.5483) | Xent 0.0000(0.0000) | Loss 3.5288(3.5483) | Error 0.0000(0.0000) Steps 820(821.20) | Grad Norm 2.5064(3.2592) | Total Time 14.00(14.00)\n",
      "Iter 4100 | Time 20.7801(20.5143) | Bit/dim 3.5188(3.5471) | Xent 0.0000(0.0000) | Loss 3.5188(3.5471) | Error 0.0000(0.0000) Steps 820(821.20) | Grad Norm 2.8632(3.2464) | Total Time 14.00(14.00)\n",
      "Iter 4110 | Time 21.0945(20.6074) | Bit/dim 3.5743(3.5478) | Xent 0.0000(0.0000) | Loss 3.5743(3.5478) | Error 0.0000(0.0000) Steps 820(821.32) | Grad Norm 4.0459(3.3451) | Total Time 14.00(14.00)\n",
      "Iter 4120 | Time 21.4182(20.6952) | Bit/dim 3.5684(3.5489) | Xent 0.0000(0.0000) | Loss 3.5684(3.5489) | Error 0.0000(0.0000) Steps 826(821.76) | Grad Norm 1.5354(3.1626) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 99.6640, Epoch Time 1253.1352(1154.1476), Bit/dim 3.5468(best: 3.5519), Xent 0.0000, Loss 3.5468, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4130 | Time 20.3587(20.6862) | Bit/dim 3.5319(3.5451) | Xent 0.0000(0.0000) | Loss 3.5319(3.5451) | Error 0.0000(0.0000) Steps 826(822.57) | Grad Norm 2.1950(3.0207) | Total Time 14.00(14.00)\n",
      "Iter 4140 | Time 21.3450(20.7919) | Bit/dim 3.5002(3.5447) | Xent 0.0000(0.0000) | Loss 3.5002(3.5447) | Error 0.0000(0.0000) Steps 820(823.13) | Grad Norm 3.6190(3.1911) | Total Time 14.00(14.00)\n",
      "Iter 4150 | Time 21.5443(20.8430) | Bit/dim 3.5754(3.5464) | Xent 0.0000(0.0000) | Loss 3.5754(3.5464) | Error 0.0000(0.0000) Steps 820(823.12) | Grad Norm 2.8350(3.2684) | Total Time 14.00(14.00)\n",
      "Iter 4160 | Time 20.9302(20.8401) | Bit/dim 3.5509(3.5461) | Xent 0.0000(0.0000) | Loss 3.5509(3.5461) | Error 0.0000(0.0000) Steps 820(823.55) | Grad Norm 3.0653(3.1622) | Total Time 14.00(14.00)\n",
      "Iter 4170 | Time 20.9776(20.8159) | Bit/dim 3.5472(3.5440) | Xent 0.0000(0.0000) | Loss 3.5472(3.5440) | Error 0.0000(0.0000) Steps 820(822.92) | Grad Norm 2.6248(3.0843) | Total Time 14.00(14.00)\n",
      "Iter 4180 | Time 20.5837(20.8650) | Bit/dim 3.5330(3.5464) | Xent 0.0000(0.0000) | Loss 3.5330(3.5464) | Error 0.0000(0.0000) Steps 826(823.29) | Grad Norm 3.5421(3.2522) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 99.8100, Epoch Time 1266.7889(1157.5268), Bit/dim 3.5493(best: 3.5468), Xent 0.0000, Loss 3.5493, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4190 | Time 21.1858(20.8752) | Bit/dim 3.4922(3.5427) | Xent 0.0000(0.0000) | Loss 3.4922(3.5427) | Error 0.0000(0.0000) Steps 832(823.95) | Grad Norm 3.0290(3.2405) | Total Time 14.00(14.00)\n",
      "Iter 4200 | Time 20.3768(20.7882) | Bit/dim 3.5386(3.5417) | Xent 0.0000(0.0000) | Loss 3.5386(3.5417) | Error 0.0000(0.0000) Steps 826(824.49) | Grad Norm 5.0233(3.2029) | Total Time 14.00(14.00)\n",
      "Iter 4210 | Time 20.0764(20.7703) | Bit/dim 3.5616(3.5438) | Xent 0.0000(0.0000) | Loss 3.5616(3.5438) | Error 0.0000(0.0000) Steps 826(825.48) | Grad Norm 2.8927(3.2926) | Total Time 14.00(14.00)\n",
      "Iter 4220 | Time 21.1896(20.7594) | Bit/dim 3.5482(3.5434) | Xent 0.0000(0.0000) | Loss 3.5482(3.5434) | Error 0.0000(0.0000) Steps 820(825.72) | Grad Norm 1.6378(3.0649) | Total Time 14.00(14.00)\n",
      "Iter 4230 | Time 21.3340(20.7875) | Bit/dim 3.5436(3.5437) | Xent 0.0000(0.0000) | Loss 3.5436(3.5437) | Error 0.0000(0.0000) Steps 832(825.95) | Grad Norm 2.2997(3.1875) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 100.0212, Epoch Time 1259.3960(1160.5829), Bit/dim 3.5424(best: 3.5468), Xent 0.0000, Loss 3.5424, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4240 | Time 20.9698(20.7908) | Bit/dim 3.5575(3.5458) | Xent 0.0000(0.0000) | Loss 3.5575(3.5458) | Error 0.0000(0.0000) Steps 814(826.09) | Grad Norm 3.5255(3.2908) | Total Time 14.00(14.00)\n",
      "Iter 4250 | Time 20.4533(20.7884) | Bit/dim 3.5262(3.5434) | Xent 0.0000(0.0000) | Loss 3.5262(3.5434) | Error 0.0000(0.0000) Steps 826(827.24) | Grad Norm 3.9309(3.3591) | Total Time 14.00(14.00)\n",
      "Iter 4260 | Time 21.5010(20.7895) | Bit/dim 3.5343(3.5448) | Xent 0.0000(0.0000) | Loss 3.5343(3.5448) | Error 0.0000(0.0000) Steps 826(827.38) | Grad Norm 3.1000(3.2168) | Total Time 14.00(14.00)\n",
      "Iter 4270 | Time 20.0417(20.7301) | Bit/dim 3.5342(3.5427) | Xent 0.0000(0.0000) | Loss 3.5342(3.5427) | Error 0.0000(0.0000) Steps 826(827.17) | Grad Norm 3.3497(3.2914) | Total Time 14.00(14.00)\n",
      "Iter 4280 | Time 21.0830(20.7306) | Bit/dim 3.5500(3.5427) | Xent 0.0000(0.0000) | Loss 3.5500(3.5427) | Error 0.0000(0.0000) Steps 838(827.69) | Grad Norm 3.6356(3.3631) | Total Time 14.00(14.00)\n",
      "Iter 4290 | Time 20.7177(20.7745) | Bit/dim 3.5426(3.5403) | Xent 0.0000(0.0000) | Loss 3.5426(3.5403) | Error 0.0000(0.0000) Steps 832(827.92) | Grad Norm 2.5368(3.2258) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 100.4355, Epoch Time 1259.9007(1163.5624), Bit/dim 3.5392(best: 3.5424), Xent 0.0000, Loss 3.5392, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4300 | Time 20.4391(20.7408) | Bit/dim 3.5636(3.5425) | Xent 0.0000(0.0000) | Loss 3.5636(3.5425) | Error 0.0000(0.0000) Steps 844(829.53) | Grad Norm 4.3692(3.4408) | Total Time 14.00(14.00)\n",
      "Iter 4310 | Time 20.8761(20.7038) | Bit/dim 3.5724(3.5433) | Xent 0.0000(0.0000) | Loss 3.5724(3.5433) | Error 0.0000(0.0000) Steps 820(828.76) | Grad Norm 2.8157(3.3985) | Total Time 14.00(14.00)\n",
      "Iter 4320 | Time 20.8373(20.7169) | Bit/dim 3.5104(3.5398) | Xent 0.0000(0.0000) | Loss 3.5104(3.5398) | Error 0.0000(0.0000) Steps 826(828.69) | Grad Norm 2.0849(3.1374) | Total Time 14.00(14.00)\n",
      "Iter 4330 | Time 21.6999(20.7474) | Bit/dim 3.5562(3.5391) | Xent 0.0000(0.0000) | Loss 3.5562(3.5391) | Error 0.0000(0.0000) Steps 838(828.17) | Grad Norm 5.5753(3.2308) | Total Time 14.00(14.00)\n",
      "Iter 4340 | Time 20.9817(20.8193) | Bit/dim 3.5469(3.5376) | Xent 0.0000(0.0000) | Loss 3.5469(3.5376) | Error 0.0000(0.0000) Steps 832(828.52) | Grad Norm 4.0006(3.4358) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 101.0927, Epoch Time 1260.4349(1166.4686), Bit/dim 3.5395(best: 3.5392), Xent 0.0000, Loss 3.5395, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4350 | Time 20.2832(20.7781) | Bit/dim 3.5311(3.5367) | Xent 0.0000(0.0000) | Loss 3.5311(3.5367) | Error 0.0000(0.0000) Steps 826(828.52) | Grad Norm 3.7620(3.3120) | Total Time 14.00(14.00)\n",
      "Iter 4360 | Time 20.5735(20.8408) | Bit/dim 3.5344(3.5371) | Xent 0.0000(0.0000) | Loss 3.5344(3.5371) | Error 0.0000(0.0000) Steps 832(828.53) | Grad Norm 2.4929(3.2087) | Total Time 14.00(14.00)\n",
      "Iter 4370 | Time 20.9163(20.8111) | Bit/dim 3.5599(3.5390) | Xent 0.0000(0.0000) | Loss 3.5599(3.5390) | Error 0.0000(0.0000) Steps 826(828.78) | Grad Norm 2.9215(3.1604) | Total Time 14.00(14.00)\n",
      "Iter 4380 | Time 21.0835(20.9024) | Bit/dim 3.5579(3.5365) | Xent 0.0000(0.0000) | Loss 3.5579(3.5365) | Error 0.0000(0.0000) Steps 826(829.84) | Grad Norm 3.5891(3.3311) | Total Time 14.00(14.00)\n",
      "Iter 4400 | Time 21.0063(20.8542) | Bit/dim 3.5531(3.5375) | Xent 0.0000(0.0000) | Loss 3.5531(3.5375) | Error 0.0000(0.0000) Steps 826(828.69) | Grad Norm 3.2482(3.2052) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 100.2213, Epoch Time 1266.4033(1169.4666), Bit/dim 3.5355(best: 3.5392), Xent 0.0000, Loss 3.5355, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4410 | Time 21.5598(20.9115) | Bit/dim 3.5780(3.5384) | Xent 0.0000(0.0000) | Loss 3.5780(3.5384) | Error 0.0000(0.0000) Steps 832(829.86) | Grad Norm 4.4743(3.3951) | Total Time 14.00(14.00)\n",
      "Iter 4420 | Time 21.0214(20.9432) | Bit/dim 3.5197(3.5370) | Xent 0.0000(0.0000) | Loss 3.5197(3.5370) | Error 0.0000(0.0000) Steps 826(830.19) | Grad Norm 2.7846(3.2384) | Total Time 14.00(14.00)\n",
      "Iter 4430 | Time 21.4860(21.0001) | Bit/dim 3.5113(3.5352) | Xent 0.0000(0.0000) | Loss 3.5113(3.5352) | Error 0.0000(0.0000) Steps 838(830.87) | Grad Norm 2.3847(2.9941) | Total Time 14.00(14.00)\n",
      "Iter 4440 | Time 20.1386(20.9709) | Bit/dim 3.4977(3.5325) | Xent 0.0000(0.0000) | Loss 3.4977(3.5325) | Error 0.0000(0.0000) Steps 832(832.25) | Grad Norm 2.3114(3.1509) | Total Time 14.00(14.00)\n",
      "Iter 4450 | Time 20.8333(20.9245) | Bit/dim 3.5056(3.5344) | Xent 0.0000(0.0000) | Loss 3.5056(3.5344) | Error 0.0000(0.0000) Steps 844(833.39) | Grad Norm 3.0282(3.0529) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 100.9184, Epoch Time 1274.0467(1172.6040), Bit/dim 3.5339(best: 3.5355), Xent 0.0000, Loss 3.5339, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4460 | Time 21.2851(20.9665) | Bit/dim 3.5468(3.5350) | Xent 0.0000(0.0000) | Loss 3.5468(3.5350) | Error 0.0000(0.0000) Steps 844(834.15) | Grad Norm 4.0115(3.1097) | Total Time 14.00(14.00)\n",
      "Iter 4470 | Time 21.0047(20.9914) | Bit/dim 3.4959(3.5349) | Xent 0.0000(0.0000) | Loss 3.4959(3.5349) | Error 0.0000(0.0000) Steps 832(835.60) | Grad Norm 2.5318(3.2705) | Total Time 14.00(14.00)\n",
      "Iter 4480 | Time 21.4033(21.0679) | Bit/dim 3.5381(3.5327) | Xent 0.0000(0.0000) | Loss 3.5381(3.5327) | Error 0.0000(0.0000) Steps 838(837.18) | Grad Norm 2.2306(3.2189) | Total Time 14.00(14.00)\n",
      "Iter 4490 | Time 21.1070(21.0195) | Bit/dim 3.5606(3.5327) | Xent 0.0000(0.0000) | Loss 3.5606(3.5327) | Error 0.0000(0.0000) Steps 844(836.85) | Grad Norm 3.2089(3.2646) | Total Time 14.00(14.00)\n",
      "Iter 4500 | Time 20.7784(21.0306) | Bit/dim 3.5021(3.5354) | Xent 0.0000(0.0000) | Loss 3.5021(3.5354) | Error 0.0000(0.0000) Steps 826(836.52) | Grad Norm 4.1061(3.3072) | Total Time 14.00(14.00)\n",
      "Iter 4510 | Time 21.2909(21.0205) | Bit/dim 3.4888(3.5339) | Xent 0.0000(0.0000) | Loss 3.4888(3.5339) | Error 0.0000(0.0000) Steps 844(838.59) | Grad Norm 3.1273(3.2526) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 101.2346, Epoch Time 1276.7859(1175.7295), Bit/dim 3.5367(best: 3.5339), Xent 0.0000, Loss 3.5367, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4520 | Time 21.5839(21.0824) | Bit/dim 3.5395(3.5344) | Xent 0.0000(0.0000) | Loss 3.5395(3.5344) | Error 0.0000(0.0000) Steps 850(839.27) | Grad Norm 3.0601(3.1299) | Total Time 14.00(14.00)\n",
      "Iter 4530 | Time 21.5453(21.1639) | Bit/dim 3.5742(3.5316) | Xent 0.0000(0.0000) | Loss 3.5742(3.5316) | Error 0.0000(0.0000) Steps 832(841.48) | Grad Norm 2.2416(2.9698) | Total Time 14.00(14.00)\n",
      "Iter 4540 | Time 22.3100(21.2501) | Bit/dim 3.5598(3.5334) | Xent 0.0000(0.0000) | Loss 3.5598(3.5334) | Error 0.0000(0.0000) Steps 868(843.32) | Grad Norm 3.9868(3.2919) | Total Time 14.00(14.00)\n",
      "Iter 4550 | Time 21.0564(21.2660) | Bit/dim 3.5515(3.5352) | Xent 0.0000(0.0000) | Loss 3.5515(3.5352) | Error 0.0000(0.0000) Steps 844(844.69) | Grad Norm 2.2409(3.0727) | Total Time 14.00(14.00)\n",
      "Iter 4560 | Time 21.6717(21.2957) | Bit/dim 3.5243(3.5323) | Xent 0.0000(0.0000) | Loss 3.5243(3.5323) | Error 0.0000(0.0000) Steps 850(847.87) | Grad Norm 3.7365(3.1537) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 100.7899, Epoch Time 1293.3170(1179.2571), Bit/dim 3.5389(best: 3.5339), Xent 0.0000, Loss 3.5389, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4570 | Time 21.9500(21.3215) | Bit/dim 3.5466(3.5328) | Xent 0.0000(0.0000) | Loss 3.5466(3.5328) | Error 0.0000(0.0000) Steps 856(848.79) | Grad Norm 3.3277(3.3521) | Total Time 14.00(14.00)\n",
      "Iter 4580 | Time 21.0756(21.3673) | Bit/dim 3.5175(3.5319) | Xent 0.0000(0.0000) | Loss 3.5175(3.5319) | Error 0.0000(0.0000) Steps 838(848.24) | Grad Norm 4.9475(3.4182) | Total Time 14.00(14.00)\n",
      "Iter 4590 | Time 21.1560(21.3189) | Bit/dim 3.5128(3.5320) | Xent 0.0000(0.0000) | Loss 3.5128(3.5320) | Error 0.0000(0.0000) Steps 826(846.75) | Grad Norm 3.1836(3.4435) | Total Time 14.00(14.00)\n",
      "Iter 4600 | Time 21.2384(21.3554) | Bit/dim 3.5594(3.5330) | Xent 0.0000(0.0000) | Loss 3.5594(3.5330) | Error 0.0000(0.0000) Steps 856(847.40) | Grad Norm 2.0357(3.2379) | Total Time 14.00(14.00)\n",
      "Iter 4610 | Time 21.7105(21.4096) | Bit/dim 3.5234(3.5335) | Xent 0.0000(0.0000) | Loss 3.5234(3.5335) | Error 0.0000(0.0000) Steps 856(848.60) | Grad Norm 2.0596(3.2477) | Total Time 14.00(14.00)\n",
      "Iter 4620 | Time 20.6408(21.3582) | Bit/dim 3.5237(3.5310) | Xent 0.0000(0.0000) | Loss 3.5237(3.5310) | Error 0.0000(0.0000) Steps 850(850.12) | Grad Norm 2.5857(3.0402) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 102.1534, Epoch Time 1296.2820(1182.7678), Bit/dim 3.5289(best: 3.5339), Xent 0.0000, Loss 3.5289, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4630 | Time 21.7955(21.4008) | Bit/dim 3.5086(3.5286) | Xent 0.0000(0.0000) | Loss 3.5086(3.5286) | Error 0.0000(0.0000) Steps 862(853.64) | Grad Norm 2.5712(3.0612) | Total Time 14.00(14.00)\n",
      "Iter 4640 | Time 21.1134(21.4060) | Bit/dim 3.5549(3.5302) | Xent 0.0000(0.0000) | Loss 3.5549(3.5302) | Error 0.0000(0.0000) Steps 862(855.29) | Grad Norm 3.1772(2.9040) | Total Time 14.00(14.00)\n",
      "Iter 4650 | Time 21.3281(21.4835) | Bit/dim 3.5293(3.5282) | Xent 0.0000(0.0000) | Loss 3.5293(3.5282) | Error 0.0000(0.0000) Steps 838(856.32) | Grad Norm 4.3645(3.1965) | Total Time 14.00(14.00)\n",
      "Iter 4660 | Time 21.4993(21.5306) | Bit/dim 3.5131(3.5284) | Xent 0.0000(0.0000) | Loss 3.5131(3.5284) | Error 0.0000(0.0000) Steps 868(858.32) | Grad Norm 2.3990(3.2308) | Total Time 14.00(14.00)\n",
      "Iter 4670 | Time 21.5595(21.5285) | Bit/dim 3.5493(3.5309) | Xent 0.0000(0.0000) | Loss 3.5493(3.5309) | Error 0.0000(0.0000) Steps 862(859.13) | Grad Norm 3.5663(3.1646) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 103.2641, Epoch Time 1307.8214(1186.5195), Bit/dim 3.5316(best: 3.5289), Xent 0.0000, Loss 3.5316, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4680 | Time 21.9096(21.5458) | Bit/dim 3.4884(3.5257) | Xent 0.0000(0.0000) | Loss 3.4884(3.5257) | Error 0.0000(0.0000) Steps 868(860.20) | Grad Norm 2.1596(3.2101) | Total Time 14.00(14.00)\n",
      "Iter 4690 | Time 21.8253(21.5220) | Bit/dim 3.5124(3.5248) | Xent 0.0000(0.0000) | Loss 3.5124(3.5248) | Error 0.0000(0.0000) Steps 856(859.90) | Grad Norm 2.5087(2.8797) | Total Time 14.00(14.00)\n",
      "Iter 4700 | Time 20.7725(21.5377) | Bit/dim 3.4672(3.5239) | Xent 0.0000(0.0000) | Loss 3.4672(3.5239) | Error 0.0000(0.0000) Steps 856(859.85) | Grad Norm 2.6930(3.0384) | Total Time 14.00(14.00)\n",
      "Iter 4710 | Time 21.3743(21.5089) | Bit/dim 3.5159(3.5255) | Xent 0.0000(0.0000) | Loss 3.5159(3.5255) | Error 0.0000(0.0000) Steps 862(861.05) | Grad Norm 5.5330(3.2161) | Total Time 14.00(14.00)\n",
      "Iter 4720 | Time 20.8885(21.4873) | Bit/dim 3.5270(3.5263) | Xent 0.0000(0.0000) | Loss 3.5270(3.5263) | Error 0.0000(0.0000) Steps 856(861.70) | Grad Norm 2.8388(3.1787) | Total Time 14.00(14.00)\n",
      "Iter 4730 | Time 21.4536(21.4338) | Bit/dim 3.4827(3.5281) | Xent 0.0000(0.0000) | Loss 3.4827(3.5281) | Error 0.0000(0.0000) Steps 856(860.95) | Grad Norm 3.7143(2.9940) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 103.1202, Epoch Time 1299.8082(1189.9181), Bit/dim 3.5372(best: 3.5289), Xent 0.0000, Loss 3.5372, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4740 | Time 20.8153(21.3867) | Bit/dim 3.5339(3.5290) | Xent 0.0000(0.0000) | Loss 3.5339(3.5290) | Error 0.0000(0.0000) Steps 844(860.30) | Grad Norm 4.0429(3.2496) | Total Time 14.00(14.00)\n",
      "Iter 4750 | Time 21.6385(21.3619) | Bit/dim 3.5058(3.5281) | Xent 0.0000(0.0000) | Loss 3.5058(3.5281) | Error 0.0000(0.0000) Steps 862(860.20) | Grad Norm 3.5571(3.0770) | Total Time 14.00(14.00)\n",
      "Iter 4760 | Time 20.9496(21.4090) | Bit/dim 3.5223(3.5268) | Xent 0.0000(0.0000) | Loss 3.5223(3.5268) | Error 0.0000(0.0000) Steps 862(861.48) | Grad Norm 2.2687(3.2982) | Total Time 14.00(14.00)\n",
      "Iter 4770 | Time 21.7369(21.4346) | Bit/dim 3.5032(3.5251) | Xent 0.0000(0.0000) | Loss 3.5032(3.5251) | Error 0.0000(0.0000) Steps 850(862.01) | Grad Norm 4.4517(3.0579) | Total Time 14.00(14.00)\n",
      "Iter 4780 | Time 21.7858(21.5251) | Bit/dim 3.5282(3.5243) | Xent 0.0000(0.0000) | Loss 3.5282(3.5243) | Error 0.0000(0.0000) Steps 862(862.02) | Grad Norm 1.9326(3.0247) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 103.2762, Epoch Time 1303.4913(1193.3253), Bit/dim 3.5215(best: 3.5289), Xent 0.0000, Loss 3.5215, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4790 | Time 21.2941(21.6070) | Bit/dim 3.5480(3.5273) | Xent 0.0000(0.0000) | Loss 3.5480(3.5273) | Error 0.0000(0.0000) Steps 868(862.53) | Grad Norm 3.3559(3.0063) | Total Time 14.00(14.00)\n",
      "Iter 4800 | Time 22.3692(21.6467) | Bit/dim 3.5034(3.5250) | Xent 0.0000(0.0000) | Loss 3.5034(3.5250) | Error 0.0000(0.0000) Steps 868(863.18) | Grad Norm 3.4236(3.1183) | Total Time 14.00(14.00)\n",
      "Iter 4810 | Time 21.3688(21.7236) | Bit/dim 3.5225(3.5222) | Xent 0.0000(0.0000) | Loss 3.5225(3.5222) | Error 0.0000(0.0000) Steps 856(863.61) | Grad Norm 2.4270(3.1741) | Total Time 14.00(14.00)\n",
      "Iter 4820 | Time 22.4697(21.7207) | Bit/dim 3.5556(3.5234) | Xent 0.0000(0.0000) | Loss 3.5556(3.5234) | Error 0.0000(0.0000) Steps 862(864.35) | Grad Norm 1.8844(2.9552) | Total Time 14.00(14.00)\n",
      "Iter 4830 | Time 22.0187(21.7565) | Bit/dim 3.5179(3.5219) | Xent 0.0000(0.0000) | Loss 3.5179(3.5219) | Error 0.0000(0.0000) Steps 868(865.03) | Grad Norm 3.4848(3.0622) | Total Time 14.00(14.00)\n",
      "Iter 4840 | Time 21.2229(21.7625) | Bit/dim 3.5147(3.5217) | Xent 0.0000(0.0000) | Loss 3.5147(3.5217) | Error 0.0000(0.0000) Steps 862(866.36) | Grad Norm 3.3354(3.1328) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 102.7155, Epoch Time 1320.2088(1197.1318), Bit/dim 3.5235(best: 3.5215), Xent 0.0000, Loss 3.5235, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4850 | Time 22.3826(21.8409) | Bit/dim 3.5378(3.5207) | Xent 0.0000(0.0000) | Loss 3.5378(3.5207) | Error 0.0000(0.0000) Steps 856(867.27) | Grad Norm 2.3863(2.9767) | Total Time 14.00(14.00)\n",
      "Iter 4860 | Time 21.4766(21.8169) | Bit/dim 3.5180(3.5213) | Xent 0.0000(0.0000) | Loss 3.5180(3.5213) | Error 0.0000(0.0000) Steps 862(867.45) | Grad Norm 2.6486(3.1321) | Total Time 14.00(14.00)\n",
      "Iter 4870 | Time 21.5266(21.7508) | Bit/dim 3.5331(3.5205) | Xent 0.0000(0.0000) | Loss 3.5331(3.5205) | Error 0.0000(0.0000) Steps 862(867.16) | Grad Norm 5.3161(3.1214) | Total Time 14.00(14.00)\n",
      "Iter 4880 | Time 21.7972(21.7812) | Bit/dim 3.5180(3.5229) | Xent 0.0000(0.0000) | Loss 3.5180(3.5229) | Error 0.0000(0.0000) Steps 856(867.02) | Grad Norm 3.1058(3.1347) | Total Time 14.00(14.00)\n",
      "Iter 4890 | Time 22.4023(21.7685) | Bit/dim 3.5045(3.5229) | Xent 0.0000(0.0000) | Loss 3.5045(3.5229) | Error 0.0000(0.0000) Steps 868(867.33) | Grad Norm 2.3243(3.2534) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 103.5183, Epoch Time 1319.2814(1200.7963), Bit/dim 3.5251(best: 3.5215), Xent 0.0000, Loss 3.5251, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4900 | Time 21.4333(21.7742) | Bit/dim 3.4982(3.5204) | Xent 0.0000(0.0000) | Loss 3.4982(3.5204) | Error 0.0000(0.0000) Steps 868(867.32) | Grad Norm 2.7468(3.1250) | Total Time 14.00(14.00)\n",
      "Iter 4910 | Time 22.3927(21.8326) | Bit/dim 3.5172(3.5192) | Xent 0.0000(0.0000) | Loss 3.5172(3.5192) | Error 0.0000(0.0000) Steps 868(867.79) | Grad Norm 2.2014(3.1576) | Total Time 14.00(14.00)\n",
      "Iter 4920 | Time 21.4022(21.7730) | Bit/dim 3.5127(3.5191) | Xent 0.0000(0.0000) | Loss 3.5127(3.5191) | Error 0.0000(0.0000) Steps 862(867.50) | Grad Norm 1.4359(3.0219) | Total Time 14.00(14.00)\n",
      "Iter 4930 | Time 21.3230(21.7651) | Bit/dim 3.5226(3.5241) | Xent 0.0000(0.0000) | Loss 3.5226(3.5241) | Error 0.0000(0.0000) Steps 862(869.06) | Grad Norm 2.1957(3.0510) | Total Time 14.00(14.00)\n",
      "Iter 4940 | Time 21.4357(21.8316) | Bit/dim 3.5078(3.5212) | Xent 0.0000(0.0000) | Loss 3.5078(3.5212) | Error 0.0000(0.0000) Steps 868(869.24) | Grad Norm 3.5825(3.0821) | Total Time 14.00(14.00)\n",
      "Iter 4950 | Time 21.7555(21.8191) | Bit/dim 3.5229(3.5210) | Xent 0.0000(0.0000) | Loss 3.5229(3.5210) | Error 0.0000(0.0000) Steps 880(869.64) | Grad Norm 3.0565(3.2814) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 103.8548, Epoch Time 1322.4642(1204.4463), Bit/dim 3.5213(best: 3.5215), Xent 0.0000, Loss 3.5213, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4960 | Time 21.9229(21.8782) | Bit/dim 3.5170(3.5183) | Xent 0.0000(0.0000) | Loss 3.5170(3.5183) | Error 0.0000(0.0000) Steps 874(870.87) | Grad Norm 3.9233(3.2860) | Total Time 14.00(14.00)\n",
      "Iter 4970 | Time 21.5652(21.8251) | Bit/dim 3.5649(3.5206) | Xent 0.0000(0.0000) | Loss 3.5649(3.5206) | Error 0.0000(0.0000) Steps 868(870.73) | Grad Norm 3.8104(3.2319) | Total Time 14.00(14.00)\n",
      "Iter 4980 | Time 21.6347(21.7987) | Bit/dim 3.5045(3.5188) | Xent 0.0000(0.0000) | Loss 3.5045(3.5188) | Error 0.0000(0.0000) Steps 874(870.27) | Grad Norm 3.1602(3.2855) | Total Time 14.00(14.00)\n",
      "Iter 4990 | Time 22.3511(21.8970) | Bit/dim 3.5082(3.5197) | Xent 0.0000(0.0000) | Loss 3.5082(3.5197) | Error 0.0000(0.0000) Steps 886(870.97) | Grad Norm 4.1182(3.2590) | Total Time 14.00(14.00)\n",
      "Iter 5000 | Time 22.5845(21.9715) | Bit/dim 3.5147(3.5195) | Xent 0.0000(0.0000) | Loss 3.5147(3.5195) | Error 0.0000(0.0000) Steps 892(871.72) | Grad Norm 1.5931(3.0758) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 103.2729, Epoch Time 1329.0773(1208.1853), Bit/dim 3.5174(best: 3.5213), Xent 0.0000, Loss 3.5174, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5010 | Time 22.1089(21.9700) | Bit/dim 3.5467(3.5206) | Xent 0.0000(0.0000) | Loss 3.5467(3.5206) | Error 0.0000(0.0000) Steps 874(871.57) | Grad Norm 3.9402(2.9581) | Total Time 14.00(14.00)\n",
      "Iter 5020 | Time 21.7272(21.9931) | Bit/dim 3.5244(3.5207) | Xent 0.0000(0.0000) | Loss 3.5244(3.5207) | Error 0.0000(0.0000) Steps 868(872.92) | Grad Norm 3.3896(3.0923) | Total Time 14.00(14.00)\n",
      "Iter 5030 | Time 22.5638(21.9349) | Bit/dim 3.5508(3.5213) | Xent 0.0000(0.0000) | Loss 3.5508(3.5213) | Error 0.0000(0.0000) Steps 868(871.55) | Grad Norm 3.2808(3.2153) | Total Time 14.00(14.00)\n",
      "Iter 5040 | Time 21.4975(21.8514) | Bit/dim 3.5394(3.5184) | Xent 0.0000(0.0000) | Loss 3.5394(3.5184) | Error 0.0000(0.0000) Steps 874(870.82) | Grad Norm 1.9545(3.0849) | Total Time 14.00(14.00)\n",
      "Iter 5050 | Time 21.9058(21.9197) | Bit/dim 3.4911(3.5155) | Xent 0.0000(0.0000) | Loss 3.4911(3.5155) | Error 0.0000(0.0000) Steps 880(871.71) | Grad Norm 2.4590(3.0228) | Total Time 14.00(14.00)\n",
      "Iter 5060 | Time 22.2457(21.9189) | Bit/dim 3.5267(3.5139) | Xent 0.0000(0.0000) | Loss 3.5267(3.5139) | Error 0.0000(0.0000) Steps 874(871.86) | Grad Norm 2.2779(2.8850) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 102.9402, Epoch Time 1324.6313(1211.6786), Bit/dim 3.5160(best: 3.5174), Xent 0.0000, Loss 3.5160, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5070 | Time 22.7702(21.9718) | Bit/dim 3.5658(3.5173) | Xent 0.0000(0.0000) | Loss 3.5658(3.5173) | Error 0.0000(0.0000) Steps 874(872.09) | Grad Norm 2.4801(3.0614) | Total Time 14.00(14.00)\n",
      "Iter 5080 | Time 21.8329(21.9767) | Bit/dim 3.5203(3.5169) | Xent 0.0000(0.0000) | Loss 3.5203(3.5169) | Error 0.0000(0.0000) Steps 874(872.49) | Grad Norm 4.5257(3.1404) | Total Time 14.00(14.00)\n",
      "Iter 5090 | Time 22.2179(21.9979) | Bit/dim 3.5049(3.5180) | Xent 0.0000(0.0000) | Loss 3.5049(3.5180) | Error 0.0000(0.0000) Steps 874(872.64) | Grad Norm 2.6319(3.0288) | Total Time 14.00(14.00)\n",
      "Iter 5100 | Time 21.6069(21.9035) | Bit/dim 3.5093(3.5146) | Xent 0.0000(0.0000) | Loss 3.5093(3.5146) | Error 0.0000(0.0000) Steps 862(872.07) | Grad Norm 3.3430(2.9253) | Total Time 14.00(14.00)\n",
      "Iter 5110 | Time 22.0491(21.9705) | Bit/dim 3.4975(3.5151) | Xent 0.0000(0.0000) | Loss 3.4975(3.5151) | Error 0.0000(0.0000) Steps 874(872.32) | Grad Norm 3.1702(2.9777) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 104.3431, Epoch Time 1332.3861(1215.2999), Bit/dim 3.5197(best: 3.5160), Xent 0.0000, Loss 3.5197, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5120 | Time 22.1352(22.0267) | Bit/dim 3.5089(3.5121) | Xent 0.0000(0.0000) | Loss 3.5089(3.5121) | Error 0.0000(0.0000) Steps 874(873.53) | Grad Norm 2.2063(3.2382) | Total Time 14.00(14.00)\n",
      "Iter 5130 | Time 22.2714(22.0180) | Bit/dim 3.5501(3.5141) | Xent 0.0000(0.0000) | Loss 3.5501(3.5141) | Error 0.0000(0.0000) Steps 880(873.84) | Grad Norm 2.8567(3.3065) | Total Time 14.00(14.00)\n",
      "Iter 5140 | Time 22.2611(22.0129) | Bit/dim 3.5087(3.5129) | Xent 0.0000(0.0000) | Loss 3.5087(3.5129) | Error 0.0000(0.0000) Steps 868(874.96) | Grad Norm 2.3238(3.0961) | Total Time 14.00(14.00)\n",
      "Iter 5150 | Time 21.8324(21.9976) | Bit/dim 3.5045(3.5132) | Xent 0.0000(0.0000) | Loss 3.5045(3.5132) | Error 0.0000(0.0000) Steps 880(874.99) | Grad Norm 4.2876(3.2355) | Total Time 14.00(14.00)\n",
      "Iter 5160 | Time 22.5047(22.0299) | Bit/dim 3.5409(3.5149) | Xent 0.0000(0.0000) | Loss 3.5409(3.5149) | Error 0.0000(0.0000) Steps 886(875.96) | Grad Norm 3.6317(3.1026) | Total Time 14.00(14.00)\n",
      "Iter 5170 | Time 22.1446(22.0551) | Bit/dim 3.5198(3.5139) | Xent 0.0000(0.0000) | Loss 3.5198(3.5139) | Error 0.0000(0.0000) Steps 880(875.44) | Grad Norm 3.2121(3.1762) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 102.9547, Epoch Time 1333.3650(1218.8418), Bit/dim 3.5161(best: 3.5160), Xent 0.0000, Loss 3.5161, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5180 | Time 21.0350(22.0312) | Bit/dim 3.4997(3.5132) | Xent 0.0000(0.0000) | Loss 3.4997(3.5132) | Error 0.0000(0.0000) Steps 874(875.63) | Grad Norm 3.0544(3.3208) | Total Time 14.00(14.00)\n",
      "Iter 5190 | Time 22.0919(21.9518) | Bit/dim 3.5216(3.5130) | Xent 0.0000(0.0000) | Loss 3.5216(3.5130) | Error 0.0000(0.0000) Steps 874(873.86) | Grad Norm 2.3479(3.1329) | Total Time 14.00(14.00)\n",
      "Iter 5200 | Time 21.4847(21.8907) | Bit/dim 3.5130(3.5121) | Xent 0.0000(0.0000) | Loss 3.5130(3.5121) | Error 0.0000(0.0000) Steps 850(871.20) | Grad Norm 5.6796(3.1066) | Total Time 14.00(14.00)\n",
      "Iter 5210 | Time 22.0554(21.9256) | Bit/dim 3.4924(3.5128) | Xent 0.0000(0.0000) | Loss 3.4924(3.5128) | Error 0.0000(0.0000) Steps 850(870.90) | Grad Norm 2.9617(3.1821) | Total Time 14.00(14.00)\n",
      "Iter 5220 | Time 21.7883(21.9761) | Bit/dim 3.4715(3.5117) | Xent 0.0000(0.0000) | Loss 3.4715(3.5117) | Error 0.0000(0.0000) Steps 886(870.57) | Grad Norm 1.9762(3.2163) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 104.6789, Epoch Time 1328.5330(1222.1326), Bit/dim 3.5142(best: 3.5160), Xent 0.0000, Loss 3.5142, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5230 | Time 21.9744(21.9972) | Bit/dim 3.5284(3.5125) | Xent 0.0000(0.0000) | Loss 3.5284(3.5125) | Error 0.0000(0.0000) Steps 886(872.68) | Grad Norm 3.5096(3.2031) | Total Time 14.00(14.00)\n",
      "Iter 5240 | Time 22.4482(21.9743) | Bit/dim 3.5410(3.5157) | Xent 0.0000(0.0000) | Loss 3.5410(3.5157) | Error 0.0000(0.0000) Steps 892(873.55) | Grad Norm 3.6871(3.1599) | Total Time 14.00(14.00)\n",
      "Iter 5250 | Time 21.7144(21.9712) | Bit/dim 3.5110(3.5119) | Xent 0.0000(0.0000) | Loss 3.5110(3.5119) | Error 0.0000(0.0000) Steps 856(873.74) | Grad Norm 1.8809(2.9525) | Total Time 14.00(14.00)\n",
      "Iter 5260 | Time 22.4979(22.0006) | Bit/dim 3.5287(3.5108) | Xent 0.0000(0.0000) | Loss 3.5287(3.5108) | Error 0.0000(0.0000) Steps 874(874.40) | Grad Norm 3.2252(2.7600) | Total Time 14.00(14.00)\n",
      "Iter 5270 | Time 22.7431(22.0508) | Bit/dim 3.5032(3.5113) | Xent 0.0000(0.0000) | Loss 3.5032(3.5113) | Error 0.0000(0.0000) Steps 886(876.50) | Grad Norm 2.2983(3.0846) | Total Time 14.00(14.00)\n",
      "Iter 5280 | Time 22.1039(22.0753) | Bit/dim 3.4843(3.5104) | Xent 0.0000(0.0000) | Loss 3.4843(3.5104) | Error 0.0000(0.0000) Steps 874(877.34) | Grad Norm 2.5392(2.9909) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 102.7936, Epoch Time 1333.2634(1225.4665), Bit/dim 3.5100(best: 3.5142), Xent 0.0000, Loss 3.5100, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5290 | Time 21.9084(22.0463) | Bit/dim 3.5392(3.5092) | Xent 0.0000(0.0000) | Loss 3.5392(3.5092) | Error 0.0000(0.0000) Steps 862(876.20) | Grad Norm 3.2198(2.9039) | Total Time 14.00(14.00)\n",
      "Iter 5300 | Time 22.7225(22.0912) | Bit/dim 3.4800(3.5078) | Xent 0.0000(0.0000) | Loss 3.4800(3.5078) | Error 0.0000(0.0000) Steps 868(878.20) | Grad Norm 2.4006(2.8949) | Total Time 14.00(14.00)\n",
      "Iter 5310 | Time 21.7363(22.1256) | Bit/dim 3.5016(3.5088) | Xent 0.0000(0.0000) | Loss 3.5016(3.5088) | Error 0.0000(0.0000) Steps 874(878.37) | Grad Norm 4.1087(3.1562) | Total Time 14.00(14.00)\n",
      "Iter 5320 | Time 22.8070(22.2354) | Bit/dim 3.5117(3.5091) | Xent 0.0000(0.0000) | Loss 3.5117(3.5091) | Error 0.0000(0.0000) Steps 886(879.75) | Grad Norm 2.1094(2.8556) | Total Time 14.00(14.00)\n",
      "Iter 5330 | Time 22.4299(22.2443) | Bit/dim 3.4978(3.5122) | Xent 0.0000(0.0000) | Loss 3.4978(3.5122) | Error 0.0000(0.0000) Steps 892(880.65) | Grad Norm 2.0280(2.8749) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 102.4295, Epoch Time 1343.0249(1228.9932), Bit/dim 3.5091(best: 3.5100), Xent 0.0000, Loss 3.5091, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5340 | Time 22.4330(22.2609) | Bit/dim 3.5071(3.5097) | Xent 0.0000(0.0000) | Loss 3.5071(3.5097) | Error 0.0000(0.0000) Steps 886(881.75) | Grad Norm 3.4126(2.9904) | Total Time 14.00(14.00)\n",
      "Iter 5350 | Time 21.6452(22.2363) | Bit/dim 3.4921(3.5106) | Xent 0.0000(0.0000) | Loss 3.4921(3.5106) | Error 0.0000(0.0000) Steps 892(882.85) | Grad Norm 3.1561(2.8501) | Total Time 14.00(14.00)\n",
      "Iter 5360 | Time 21.4751(22.2420) | Bit/dim 3.5170(3.5087) | Xent 0.0000(0.0000) | Loss 3.5170(3.5087) | Error 0.0000(0.0000) Steps 886(883.05) | Grad Norm 2.9990(2.9862) | Total Time 14.00(14.00)\n",
      "Iter 5370 | Time 21.6086(22.2220) | Bit/dim 3.4753(3.5066) | Xent 0.0000(0.0000) | Loss 3.4753(3.5066) | Error 0.0000(0.0000) Steps 874(880.97) | Grad Norm 4.2943(2.9198) | Total Time 14.00(14.00)\n",
      "Iter 5380 | Time 22.4005(22.2937) | Bit/dim 3.5224(3.5071) | Xent 0.0000(0.0000) | Loss 3.5224(3.5071) | Error 0.0000(0.0000) Steps 892(882.57) | Grad Norm 3.9173(3.1124) | Total Time 14.00(14.00)\n",
      "Iter 5390 | Time 22.4282(22.2639) | Bit/dim 3.5167(3.5086) | Xent 0.0000(0.0000) | Loss 3.5167(3.5086) | Error 0.0000(0.0000) Steps 880(882.84) | Grad Norm 2.5391(3.0003) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 102.0413, Epoch Time 1344.4070(1232.4557), Bit/dim 3.5068(best: 3.5091), Xent 0.0000, Loss 3.5068, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5400 | Time 22.5049(22.2950) | Bit/dim 3.5121(3.5073) | Xent 0.0000(0.0000) | Loss 3.5121(3.5073) | Error 0.0000(0.0000) Steps 874(883.69) | Grad Norm 3.6045(3.0952) | Total Time 14.00(14.00)\n",
      "Iter 5410 | Time 21.7107(22.2691) | Bit/dim 3.4901(3.5074) | Xent 0.0000(0.0000) | Loss 3.4901(3.5074) | Error 0.0000(0.0000) Steps 886(883.83) | Grad Norm 2.7002(2.9458) | Total Time 14.00(14.00)\n",
      "Iter 5420 | Time 21.9275(22.2481) | Bit/dim 3.5052(3.5024) | Xent 0.0000(0.0000) | Loss 3.5052(3.5024) | Error 0.0000(0.0000) Steps 880(883.65) | Grad Norm 2.6181(3.1625) | Total Time 14.00(14.00)\n",
      "Iter 5430 | Time 22.1594(22.2792) | Bit/dim 3.5093(3.5053) | Xent 0.0000(0.0000) | Loss 3.5093(3.5053) | Error 0.0000(0.0000) Steps 880(883.76) | Grad Norm 2.3441(3.1542) | Total Time 14.00(14.00)\n",
      "Iter 5440 | Time 22.0857(22.2897) | Bit/dim 3.5335(3.5075) | Xent 0.0000(0.0000) | Loss 3.5335(3.5075) | Error 0.0000(0.0000) Steps 886(883.11) | Grad Norm 3.8781(3.1192) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 103.7315, Epoch Time 1346.0362(1235.8631), Bit/dim 3.5043(best: 3.5068), Xent 0.0000, Loss 3.5043, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5450 | Time 22.3710(22.2559) | Bit/dim 3.5223(3.5055) | Xent 0.0000(0.0000) | Loss 3.5223(3.5055) | Error 0.0000(0.0000) Steps 880(883.56) | Grad Norm 2.2317(2.9309) | Total Time 14.00(14.00)\n",
      "Iter 5460 | Time 21.2261(22.2141) | Bit/dim 3.5386(3.5078) | Xent 0.0000(0.0000) | Loss 3.5386(3.5078) | Error 0.0000(0.0000) Steps 874(883.82) | Grad Norm 2.3709(3.2195) | Total Time 14.00(14.00)\n",
      "Iter 5470 | Time 22.1978(22.1803) | Bit/dim 3.5350(3.5076) | Xent 0.0000(0.0000) | Loss 3.5350(3.5076) | Error 0.0000(0.0000) Steps 874(882.49) | Grad Norm 3.7838(3.3221) | Total Time 14.00(14.00)\n",
      "Iter 5480 | Time 21.8283(22.1113) | Bit/dim 3.5152(3.5084) | Xent 0.0000(0.0000) | Loss 3.5152(3.5084) | Error 0.0000(0.0000) Steps 886(882.88) | Grad Norm 2.4937(3.2061) | Total Time 14.00(14.00)\n",
      "Iter 5490 | Time 22.3133(22.2059) | Bit/dim 3.4978(3.5071) | Xent 0.0000(0.0000) | Loss 3.4978(3.5071) | Error 0.0000(0.0000) Steps 880(882.59) | Grad Norm 1.3751(2.9327) | Total Time 14.00(14.00)\n",
      "Iter 5500 | Time 21.8573(22.1978) | Bit/dim 3.5196(3.5052) | Xent 0.0000(0.0000) | Loss 3.5196(3.5052) | Error 0.0000(0.0000) Steps 886(883.41) | Grad Norm 4.0854(3.0365) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 104.3471, Epoch Time 1341.3602(1239.0280), Bit/dim 3.5070(best: 3.5043), Xent 0.0000, Loss 3.5070, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5510 | Time 22.7567(22.1591) | Bit/dim 3.5177(3.5040) | Xent 0.0000(0.0000) | Loss 3.5177(3.5040) | Error 0.0000(0.0000) Steps 886(883.60) | Grad Norm 3.0074(2.9867) | Total Time 14.00(14.00)\n",
      "Iter 5520 | Time 21.7420(22.1784) | Bit/dim 3.5117(3.5048) | Xent 0.0000(0.0000) | Loss 3.5117(3.5048) | Error 0.0000(0.0000) Steps 886(884.12) | Grad Norm 3.5409(3.0763) | Total Time 14.00(14.00)\n",
      "Iter 5530 | Time 22.2433(22.1823) | Bit/dim 3.5029(3.5058) | Xent 0.0000(0.0000) | Loss 3.5029(3.5058) | Error 0.0000(0.0000) Steps 892(885.09) | Grad Norm 3.5167(3.2194) | Total Time 14.00(14.00)\n",
      "Iter 5540 | Time 23.0210(22.2248) | Bit/dim 3.4807(3.5045) | Xent 0.0000(0.0000) | Loss 3.4807(3.5045) | Error 0.0000(0.0000) Steps 874(885.27) | Grad Norm 1.9924(3.0943) | Total Time 14.00(14.00)\n",
      "Iter 5550 | Time 22.2016(22.3037) | Bit/dim 3.5131(3.5044) | Xent 0.0000(0.0000) | Loss 3.5131(3.5044) | Error 0.0000(0.0000) Steps 898(886.58) | Grad Norm 3.8351(3.2121) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 103.8998, Epoch Time 1346.0430(1242.2384), Bit/dim 3.5019(best: 3.5043), Xent 0.0000, Loss 3.5019, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5560 | Time 22.0348(22.2525) | Bit/dim 3.5255(3.5037) | Xent 0.0000(0.0000) | Loss 3.5255(3.5037) | Error 0.0000(0.0000) Steps 880(886.86) | Grad Norm 2.1133(2.9723) | Total Time 14.00(14.00)\n",
      "Iter 5570 | Time 22.5623(22.2739) | Bit/dim 3.4774(3.5037) | Xent 0.0000(0.0000) | Loss 3.4774(3.5037) | Error 0.0000(0.0000) Steps 892(886.58) | Grad Norm 1.8276(2.9534) | Total Time 14.00(14.00)\n",
      "Iter 5580 | Time 21.8689(22.2939) | Bit/dim 3.5057(3.5027) | Xent 0.0000(0.0000) | Loss 3.5057(3.5027) | Error 0.0000(0.0000) Steps 880(885.68) | Grad Norm 3.5847(3.1449) | Total Time 14.00(14.00)\n",
      "Iter 5590 | Time 22.2612(22.3295) | Bit/dim 3.5035(3.5025) | Xent 0.0000(0.0000) | Loss 3.5035(3.5025) | Error 0.0000(0.0000) Steps 892(884.99) | Grad Norm 2.0315(2.9865) | Total Time 14.00(14.00)\n",
      "Iter 5600 | Time 22.1910(22.3942) | Bit/dim 3.4906(3.5006) | Xent 0.0000(0.0000) | Loss 3.4906(3.5006) | Error 0.0000(0.0000) Steps 880(885.60) | Grad Norm 3.8694(3.0752) | Total Time 14.00(14.00)\n",
      "Iter 5610 | Time 22.2594(22.4174) | Bit/dim 3.5018(3.5009) | Xent 0.0000(0.0000) | Loss 3.5018(3.5009) | Error 0.0000(0.0000) Steps 880(886.33) | Grad Norm 3.6142(3.0244) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 105.2160, Epoch Time 1354.4725(1245.6055), Bit/dim 3.5033(best: 3.5019), Xent 0.0000, Loss 3.5033, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5620 | Time 22.7149(22.4752) | Bit/dim 3.5198(3.5030) | Xent 0.0000(0.0000) | Loss 3.5198(3.5030) | Error 0.0000(0.0000) Steps 892(886.25) | Grad Norm 3.5878(3.0508) | Total Time 14.00(14.00)\n",
      "Iter 5630 | Time 21.9812(22.4731) | Bit/dim 3.5290(3.5008) | Xent 0.0000(0.0000) | Loss 3.5290(3.5008) | Error 0.0000(0.0000) Steps 874(886.82) | Grad Norm 3.4949(3.2015) | Total Time 14.00(14.00)\n",
      "Iter 5640 | Time 21.9551(22.3814) | Bit/dim 3.4844(3.5027) | Xent 0.0000(0.0000) | Loss 3.4844(3.5027) | Error 0.0000(0.0000) Steps 886(887.09) | Grad Norm 2.5994(3.1992) | Total Time 14.00(14.00)\n",
      "Iter 5650 | Time 21.8730(22.3395) | Bit/dim 3.4893(3.5029) | Xent 0.0000(0.0000) | Loss 3.4893(3.5029) | Error 0.0000(0.0000) Steps 886(887.44) | Grad Norm 2.5720(3.1150) | Total Time 14.00(14.00)\n",
      "Iter 5660 | Time 22.2405(22.2709) | Bit/dim 3.4817(3.5005) | Xent 0.0000(0.0000) | Loss 3.4817(3.5005) | Error 0.0000(0.0000) Steps 880(886.58) | Grad Norm 1.1781(2.8776) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 103.5186, Epoch Time 1347.2654(1248.6553), Bit/dim 3.5009(best: 3.5019), Xent 0.0000, Loss 3.5009, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5670 | Time 21.8839(22.1873) | Bit/dim 3.5032(3.4995) | Xent 0.0000(0.0000) | Loss 3.5032(3.4995) | Error 0.0000(0.0000) Steps 880(886.00) | Grad Norm 2.7770(2.9592) | Total Time 14.00(14.00)\n",
      "Iter 5680 | Time 22.4626(22.2398) | Bit/dim 3.4900(3.4992) | Xent 0.0000(0.0000) | Loss 3.4900(3.4992) | Error 0.0000(0.0000) Steps 886(886.53) | Grad Norm 2.5167(2.9108) | Total Time 14.00(14.00)\n",
      "Iter 5690 | Time 22.0037(22.2238) | Bit/dim 3.4936(3.5001) | Xent 0.0000(0.0000) | Loss 3.4936(3.5001) | Error 0.0000(0.0000) Steps 898(887.12) | Grad Norm 4.3637(3.0122) | Total Time 14.00(14.00)\n",
      "Iter 5700 | Time 23.0194(22.2774) | Bit/dim 3.4895(3.4994) | Xent 0.0000(0.0000) | Loss 3.4895(3.4994) | Error 0.0000(0.0000) Steps 898(888.41) | Grad Norm 2.3839(2.9793) | Total Time 14.00(14.00)\n",
      "Iter 5710 | Time 22.8515(22.3076) | Bit/dim 3.5157(3.4988) | Xent 0.0000(0.0000) | Loss 3.5157(3.4988) | Error 0.0000(0.0000) Steps 886(887.87) | Grad Norm 2.1835(2.9228) | Total Time 14.00(14.00)\n",
      "Iter 5720 | Time 22.3610(22.3231) | Bit/dim 3.5413(3.5004) | Xent 0.0000(0.0000) | Loss 3.5413(3.5004) | Error 0.0000(0.0000) Steps 898(888.14) | Grad Norm 4.2829(3.0664) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 103.6950, Epoch Time 1348.1362(1251.6397), Bit/dim 3.5009(best: 3.5009), Xent 0.0000, Loss 3.5009, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5730 | Time 22.6819(22.3614) | Bit/dim 3.5235(3.5033) | Xent 0.0000(0.0000) | Loss 3.5235(3.5033) | Error 0.0000(0.0000) Steps 892(889.02) | Grad Norm 1.6158(2.8850) | Total Time 14.00(14.00)\n",
      "Iter 5740 | Time 22.6142(22.3709) | Bit/dim 3.4861(3.5011) | Xent 0.0000(0.0000) | Loss 3.4861(3.5011) | Error 0.0000(0.0000) Steps 892(890.30) | Grad Norm 2.9291(3.0316) | Total Time 14.00(14.00)\n",
      "Iter 5750 | Time 22.6279(22.3484) | Bit/dim 3.5091(3.4993) | Xent 0.0000(0.0000) | Loss 3.5091(3.4993) | Error 0.0000(0.0000) Steps 892(891.07) | Grad Norm 3.8983(2.9356) | Total Time 14.00(14.00)\n",
      "Iter 5760 | Time 22.0021(22.3946) | Bit/dim 3.5074(3.4969) | Xent 0.0000(0.0000) | Loss 3.5074(3.4969) | Error 0.0000(0.0000) Steps 898(892.49) | Grad Norm 2.2846(3.0125) | Total Time 14.00(14.00)\n",
      "Iter 5770 | Time 22.7635(22.4921) | Bit/dim 3.5151(3.4999) | Xent 0.0000(0.0000) | Loss 3.5151(3.4999) | Error 0.0000(0.0000) Steps 898(894.15) | Grad Norm 3.9845(2.8760) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 104.7922, Epoch Time 1360.7957(1254.9144), Bit/dim 3.5111(best: 3.5009), Xent 0.0000, Loss 3.5111, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5780 | Time 22.1563(22.4808) | Bit/dim 3.5172(3.4980) | Xent 0.0000(0.0000) | Loss 3.5172(3.4980) | Error 0.0000(0.0000) Steps 880(893.61) | Grad Norm 4.1770(3.1170) | Total Time 14.00(14.00)\n",
      "Iter 5790 | Time 22.3070(22.4980) | Bit/dim 3.4808(3.4951) | Xent 0.0000(0.0000) | Loss 3.4808(3.4951) | Error 0.0000(0.0000) Steps 886(894.43) | Grad Norm 2.7055(2.9742) | Total Time 14.00(14.00)\n",
      "Iter 5800 | Time 21.9120(22.4688) | Bit/dim 3.4850(3.4962) | Xent 0.0000(0.0000) | Loss 3.4850(3.4962) | Error 0.0000(0.0000) Steps 874(892.39) | Grad Norm 2.9061(2.9801) | Total Time 14.00(14.00)\n",
      "Iter 5810 | Time 22.3609(22.3667) | Bit/dim 3.4956(3.4966) | Xent 0.0000(0.0000) | Loss 3.4956(3.4966) | Error 0.0000(0.0000) Steps 886(890.83) | Grad Norm 2.7642(3.0748) | Total Time 14.00(14.00)\n",
      "Iter 5820 | Time 22.7021(22.3555) | Bit/dim 3.5487(3.4964) | Xent 0.0000(0.0000) | Loss 3.5487(3.4964) | Error 0.0000(0.0000) Steps 892(891.14) | Grad Norm 4.3878(3.1841) | Total Time 14.00(14.00)\n",
      "Iter 5830 | Time 22.4716(22.3416) | Bit/dim 3.5208(3.4998) | Xent 0.0000(0.0000) | Loss 3.5208(3.4998) | Error 0.0000(0.0000) Steps 874(890.64) | Grad Norm 2.9329(3.1232) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 106.3887, Epoch Time 1351.3008(1257.8060), Bit/dim 3.4966(best: 3.5009), Xent 0.0000, Loss 3.4966, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5840 | Time 21.6829(22.2883) | Bit/dim 3.5108(3.5000) | Xent 0.0000(0.0000) | Loss 3.5108(3.5000) | Error 0.0000(0.0000) Steps 898(891.18) | Grad Norm 3.0148(3.1538) | Total Time 14.00(14.00)\n",
      "Iter 5850 | Time 22.0860(22.2611) | Bit/dim 3.4864(3.4978) | Xent 0.0000(0.0000) | Loss 3.4864(3.4978) | Error 0.0000(0.0000) Steps 904(893.23) | Grad Norm 3.4050(3.0424) | Total Time 14.00(14.00)\n",
      "Iter 5860 | Time 22.2520(22.2677) | Bit/dim 3.4736(3.4977) | Xent 0.0000(0.0000) | Loss 3.4736(3.4977) | Error 0.0000(0.0000) Steps 886(893.75) | Grad Norm 3.2595(3.0333) | Total Time 14.00(14.00)\n",
      "Iter 5870 | Time 22.6579(22.2892) | Bit/dim 3.5363(3.4969) | Xent 0.0000(0.0000) | Loss 3.5363(3.4969) | Error 0.0000(0.0000) Steps 898(894.50) | Grad Norm 2.0126(3.0435) | Total Time 14.00(14.00)\n",
      "Iter 5880 | Time 22.7932(22.3389) | Bit/dim 3.5020(3.4953) | Xent 0.0000(0.0000) | Loss 3.5020(3.4953) | Error 0.0000(0.0000) Steps 898(895.10) | Grad Norm 4.2625(2.9422) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 104.8149, Epoch Time 1348.6368(1260.5309), Bit/dim 3.4956(best: 3.4966), Xent 0.0000, Loss 3.4956, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5890 | Time 22.9453(22.3605) | Bit/dim 3.4651(3.4940) | Xent 0.0000(0.0000) | Loss 3.4651(3.4940) | Error 0.0000(0.0000) Steps 898(895.87) | Grad Norm 5.6919(2.9650) | Total Time 14.00(14.00)\n",
      "Iter 5900 | Time 21.8409(22.3732) | Bit/dim 3.5298(3.4952) | Xent 0.0000(0.0000) | Loss 3.5298(3.4952) | Error 0.0000(0.0000) Steps 910(897.79) | Grad Norm 2.2139(2.9125) | Total Time 14.00(14.00)\n",
      "Iter 5910 | Time 22.6170(22.4003) | Bit/dim 3.4827(3.4939) | Xent 0.0000(0.0000) | Loss 3.4827(3.4939) | Error 0.0000(0.0000) Steps 898(898.51) | Grad Norm 1.9455(2.9483) | Total Time 14.00(14.00)\n",
      "Iter 5920 | Time 22.8427(22.5313) | Bit/dim 3.4827(3.4943) | Xent 0.0000(0.0000) | Loss 3.4827(3.4943) | Error 0.0000(0.0000) Steps 904(899.96) | Grad Norm 2.6734(2.7913) | Total Time 14.00(14.00)\n",
      "Iter 5930 | Time 22.9295(22.5836) | Bit/dim 3.4891(3.4937) | Xent 0.0000(0.0000) | Loss 3.4891(3.4937) | Error 0.0000(0.0000) Steps 916(900.51) | Grad Norm 4.2980(2.9851) | Total Time 14.00(14.00)\n",
      "Iter 5940 | Time 22.3951(22.6390) | Bit/dim 3.5182(3.4960) | Xent 0.0000(0.0000) | Loss 3.5182(3.4960) | Error 0.0000(0.0000) Steps 904(901.08) | Grad Norm 3.1653(2.9054) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 105.0258, Epoch Time 1368.3448(1263.7653), Bit/dim 3.5008(best: 3.4956), Xent 0.0000, Loss 3.5008, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5950 | Time 22.4130(22.5857) | Bit/dim 3.5538(3.4964) | Xent 0.0000(0.0000) | Loss 3.5538(3.4964) | Error 0.0000(0.0000) Steps 892(902.78) | Grad Norm 5.0832(2.9721) | Total Time 14.00(14.00)\n",
      "Iter 5960 | Time 22.1995(22.4916) | Bit/dim 3.4834(3.4968) | Xent 0.0000(0.0000) | Loss 3.4834(3.4968) | Error 0.0000(0.0000) Steps 898(902.05) | Grad Norm 3.6527(2.9385) | Total Time 14.00(14.00)\n",
      "Iter 5970 | Time 22.4330(22.4820) | Bit/dim 3.4942(3.4915) | Xent 0.0000(0.0000) | Loss 3.4942(3.4915) | Error 0.0000(0.0000) Steps 898(900.41) | Grad Norm 4.1559(2.9417) | Total Time 14.00(14.00)\n",
      "Iter 5980 | Time 21.9573(22.4234) | Bit/dim 3.4973(3.4941) | Xent 0.0000(0.0000) | Loss 3.4973(3.4941) | Error 0.0000(0.0000) Steps 904(899.41) | Grad Norm 2.0254(3.0517) | Total Time 14.00(14.00)\n",
      "Iter 5990 | Time 23.5486(22.4492) | Bit/dim 3.5332(3.4957) | Xent 0.0000(0.0000) | Loss 3.5332(3.4957) | Error 0.0000(0.0000) Steps 904(899.27) | Grad Norm 1.5636(2.9435) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 105.4487, Epoch Time 1352.9638(1266.4413), Bit/dim 3.4925(best: 3.4956), Xent 0.0000, Loss 3.4925, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6000 | Time 22.7358(22.4313) | Bit/dim 3.4780(3.4939) | Xent 0.0000(0.0000) | Loss 3.4780(3.4939) | Error 0.0000(0.0000) Steps 892(899.41) | Grad Norm 3.0040(2.9250) | Total Time 14.00(14.00)\n",
      "Iter 6010 | Time 23.4479(22.5052) | Bit/dim 3.4673(3.4920) | Xent 0.0000(0.0000) | Loss 3.4673(3.4920) | Error 0.0000(0.0000) Steps 892(899.79) | Grad Norm 4.1062(2.9546) | Total Time 14.00(14.00)\n",
      "Iter 6020 | Time 22.5892(22.5411) | Bit/dim 3.4827(3.4909) | Xent 0.0000(0.0000) | Loss 3.4827(3.4909) | Error 0.0000(0.0000) Steps 898(900.58) | Grad Norm 2.4424(3.0315) | Total Time 14.00(14.00)\n",
      "Iter 6030 | Time 22.8756(22.5335) | Bit/dim 3.4807(3.4899) | Xent 0.0000(0.0000) | Loss 3.4807(3.4899) | Error 0.0000(0.0000) Steps 916(901.24) | Grad Norm 2.7830(3.1109) | Total Time 14.00(14.00)\n",
      "Iter 6040 | Time 22.2412(22.5095) | Bit/dim 3.5137(3.4931) | Xent 0.0000(0.0000) | Loss 3.5137(3.4931) | Error 0.0000(0.0000) Steps 904(901.17) | Grad Norm 4.2701(3.0010) | Total Time 14.00(14.00)\n",
      "Iter 6050 | Time 22.4734(22.4882) | Bit/dim 3.4863(3.4928) | Xent 0.0000(0.0000) | Loss 3.4863(3.4928) | Error 0.0000(0.0000) Steps 904(901.87) | Grad Norm 2.1038(2.9762) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 105.8886, Epoch Time 1363.7155(1269.3595), Bit/dim 3.4930(best: 3.4925), Xent 0.0000, Loss 3.4930, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6060 | Time 22.6453(22.4910) | Bit/dim 3.5066(3.4909) | Xent 0.0000(0.0000) | Loss 3.5066(3.4909) | Error 0.0000(0.0000) Steps 904(901.99) | Grad Norm 2.4784(2.8332) | Total Time 14.00(14.00)\n",
      "Iter 6070 | Time 22.2415(22.5093) | Bit/dim 3.4873(3.4898) | Xent 0.0000(0.0000) | Loss 3.4873(3.4898) | Error 0.0000(0.0000) Steps 904(902.56) | Grad Norm 1.8174(2.8145) | Total Time 14.00(14.00)\n",
      "Iter 6080 | Time 22.8176(22.5958) | Bit/dim 3.5072(3.4883) | Xent 0.0000(0.0000) | Loss 3.5072(3.4883) | Error 0.0000(0.0000) Steps 904(903.96) | Grad Norm 2.6752(2.8540) | Total Time 14.00(14.00)\n",
      "Iter 6090 | Time 22.1524(22.5332) | Bit/dim 3.5123(3.4907) | Xent 0.0000(0.0000) | Loss 3.5123(3.4907) | Error 0.0000(0.0000) Steps 910(903.95) | Grad Norm 2.4326(2.9743) | Total Time 14.00(14.00)\n",
      "Iter 6100 | Time 21.7594(22.5244) | Bit/dim 3.5238(3.4933) | Xent 0.0000(0.0000) | Loss 3.5238(3.4933) | Error 0.0000(0.0000) Steps 898(904.09) | Grad Norm 1.9751(3.0008) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 105.1240, Epoch Time 1363.1920(1272.1745), Bit/dim 3.4903(best: 3.4925), Xent 0.0000, Loss 3.4903, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6110 | Time 23.1337(22.5434) | Bit/dim 3.4611(3.4913) | Xent 0.0000(0.0000) | Loss 3.4611(3.4913) | Error 0.0000(0.0000) Steps 910(904.07) | Grad Norm 2.7145(3.0459) | Total Time 14.00(14.00)\n",
      "Iter 6120 | Time 22.1569(22.4925) | Bit/dim 3.5019(3.4906) | Xent 0.0000(0.0000) | Loss 3.5019(3.4906) | Error 0.0000(0.0000) Steps 904(903.67) | Grad Norm 2.4253(3.0306) | Total Time 14.00(14.00)\n",
      "Iter 6130 | Time 22.4011(22.4852) | Bit/dim 3.5042(3.4907) | Xent 0.0000(0.0000) | Loss 3.5042(3.4907) | Error 0.0000(0.0000) Steps 892(903.54) | Grad Norm 3.1645(3.0435) | Total Time 14.00(14.00)\n",
      "Iter 6140 | Time 22.7483(22.5303) | Bit/dim 3.5002(3.4902) | Xent 0.0000(0.0000) | Loss 3.5002(3.4902) | Error 0.0000(0.0000) Steps 904(904.62) | Grad Norm 2.6366(2.9846) | Total Time 14.00(14.00)\n",
      "Iter 6150 | Time 22.5435(22.5275) | Bit/dim 3.4681(3.4883) | Xent 0.0000(0.0000) | Loss 3.4681(3.4883) | Error 0.0000(0.0000) Steps 892(905.04) | Grad Norm 2.1466(2.9736) | Total Time 14.00(14.00)\n",
      "Iter 6160 | Time 22.9005(22.4987) | Bit/dim 3.4819(3.4894) | Xent 0.0000(0.0000) | Loss 3.4819(3.4894) | Error 0.0000(0.0000) Steps 910(904.13) | Grad Norm 3.9530(3.0058) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 103.5272, Epoch Time 1358.2524(1274.7568), Bit/dim 3.4932(best: 3.4903), Xent 0.0000, Loss 3.4932, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6170 | Time 22.7316(22.5461) | Bit/dim 3.4634(3.4902) | Xent 0.0000(0.0000) | Loss 3.4634(3.4902) | Error 0.0000(0.0000) Steps 898(904.83) | Grad Norm 2.6413(3.0247) | Total Time 14.00(14.00)\n",
      "Iter 6180 | Time 22.4167(22.5163) | Bit/dim 3.5110(3.4912) | Xent 0.0000(0.0000) | Loss 3.5110(3.4912) | Error 0.0000(0.0000) Steps 904(904.43) | Grad Norm 2.5901(2.8831) | Total Time 14.00(14.00)\n",
      "Iter 6190 | Time 22.3318(22.5128) | Bit/dim 3.5236(3.4899) | Xent 0.0000(0.0000) | Loss 3.5236(3.4899) | Error 0.0000(0.0000) Steps 910(905.74) | Grad Norm 1.5485(2.9102) | Total Time 14.00(14.00)\n",
      "Iter 6200 | Time 22.3561(22.5019) | Bit/dim 3.4615(3.4865) | Xent 0.0000(0.0000) | Loss 3.4615(3.4865) | Error 0.0000(0.0000) Steps 904(904.90) | Grad Norm 4.8941(3.1085) | Total Time 14.00(14.00)\n",
      "Iter 6210 | Time 22.0555(22.4714) | Bit/dim 3.4844(3.4865) | Xent 0.0000(0.0000) | Loss 3.4844(3.4865) | Error 0.0000(0.0000) Steps 892(903.42) | Grad Norm 1.7808(3.0381) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 102.2778, Epoch Time 1357.3065(1277.2333), Bit/dim 3.4906(best: 3.4903), Xent 0.0000, Loss 3.4906, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6220 | Time 22.6062(22.4557) | Bit/dim 3.4726(3.4879) | Xent 0.0000(0.0000) | Loss 3.4726(3.4879) | Error 0.0000(0.0000) Steps 892(901.39) | Grad Norm 2.8108(2.8849) | Total Time 14.00(14.00)\n",
      "Iter 6230 | Time 22.3437(22.4186) | Bit/dim 3.4607(3.4859) | Xent 0.0000(0.0000) | Loss 3.4607(3.4859) | Error 0.0000(0.0000) Steps 910(901.66) | Grad Norm 2.2162(2.8427) | Total Time 14.00(14.00)\n",
      "Iter 6240 | Time 21.6829(22.3938) | Bit/dim 3.5065(3.4845) | Xent 0.0000(0.0000) | Loss 3.5065(3.4845) | Error 0.0000(0.0000) Steps 898(901.61) | Grad Norm 2.7532(2.7106) | Total Time 14.00(14.00)\n",
      "Iter 6250 | Time 23.2597(22.4402) | Bit/dim 3.4887(3.4876) | Xent 0.0000(0.0000) | Loss 3.4887(3.4876) | Error 0.0000(0.0000) Steps 904(901.00) | Grad Norm 2.2406(2.8747) | Total Time 14.00(14.00)\n",
      "Iter 6260 | Time 22.9487(22.5353) | Bit/dim 3.4838(3.4872) | Xent 0.0000(0.0000) | Loss 3.4838(3.4872) | Error 0.0000(0.0000) Steps 910(901.39) | Grad Norm 3.0037(3.0255) | Total Time 14.00(14.00)\n",
      "Iter 6270 | Time 21.9123(22.5477) | Bit/dim 3.5005(3.4868) | Xent 0.0000(0.0000) | Loss 3.5005(3.4868) | Error 0.0000(0.0000) Steps 898(899.90) | Grad Norm 3.6798(2.9941) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 104.4792, Epoch Time 1359.6016(1279.7043), Bit/dim 3.4912(best: 3.4903), Xent 0.0000, Loss 3.4912, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6280 | Time 22.1452(22.5719) | Bit/dim 3.4894(3.4844) | Xent 0.0000(0.0000) | Loss 3.4894(3.4844) | Error 0.0000(0.0000) Steps 904(900.65) | Grad Norm 4.3652(3.0586) | Total Time 14.00(14.00)\n",
      "Iter 6290 | Time 23.1405(22.5885) | Bit/dim 3.4320(3.4846) | Xent 0.0000(0.0000) | Loss 3.4320(3.4846) | Error 0.0000(0.0000) Steps 898(900.21) | Grad Norm 2.8588(2.9817) | Total Time 14.00(14.00)\n",
      "Iter 6300 | Time 22.3586(22.6104) | Bit/dim 3.4606(3.4849) | Xent 0.0000(0.0000) | Loss 3.4606(3.4849) | Error 0.0000(0.0000) Steps 904(900.47) | Grad Norm 2.8978(3.0172) | Total Time 14.00(14.00)\n",
      "Iter 6310 | Time 23.0312(22.5660) | Bit/dim 3.5102(3.4872) | Xent 0.0000(0.0000) | Loss 3.5102(3.4872) | Error 0.0000(0.0000) Steps 910(902.10) | Grad Norm 4.6069(2.9003) | Total Time 14.00(14.00)\n",
      "Iter 6320 | Time 22.6419(22.5055) | Bit/dim 3.4495(3.4845) | Xent 0.0000(0.0000) | Loss 3.4495(3.4845) | Error 0.0000(0.0000) Steps 904(902.02) | Grad Norm 1.9075(2.8838) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 104.4811, Epoch Time 1363.0867(1282.2058), Bit/dim 3.4853(best: 3.4903), Xent 0.0000, Loss 3.4853, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6330 | Time 23.3237(22.5499) | Bit/dim 3.4926(3.4844) | Xent 0.0000(0.0000) | Loss 3.4926(3.4844) | Error 0.0000(0.0000) Steps 916(902.63) | Grad Norm 4.4754(2.9927) | Total Time 14.00(14.00)\n",
      "Iter 6340 | Time 22.7069(22.6232) | Bit/dim 3.4821(3.4865) | Xent 0.0000(0.0000) | Loss 3.4821(3.4865) | Error 0.0000(0.0000) Steps 904(903.59) | Grad Norm 2.5763(2.8998) | Total Time 14.00(14.00)\n",
      "Iter 6350 | Time 22.8864(22.6580) | Bit/dim 3.4952(3.4860) | Xent 0.0000(0.0000) | Loss 3.4952(3.4860) | Error 0.0000(0.0000) Steps 898(903.71) | Grad Norm 4.2444(3.0588) | Total Time 14.00(14.00)\n",
      "Iter 6360 | Time 22.6804(22.5438) | Bit/dim 3.4637(3.4864) | Xent 0.0000(0.0000) | Loss 3.4637(3.4864) | Error 0.0000(0.0000) Steps 904(903.15) | Grad Norm 1.7236(2.8944) | Total Time 14.00(14.00)\n",
      "Iter 6370 | Time 21.8521(22.4677) | Bit/dim 3.5141(3.4847) | Xent 0.0000(0.0000) | Loss 3.5141(3.4847) | Error 0.0000(0.0000) Steps 910(903.24) | Grad Norm 3.6010(2.7166) | Total Time 14.00(14.00)\n",
      "Iter 6380 | Time 22.9704(22.5195) | Bit/dim 3.4655(3.4852) | Xent 0.0000(0.0000) | Loss 3.4655(3.4852) | Error 0.0000(0.0000) Steps 904(902.35) | Grad Norm 2.4278(2.7786) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 103.7518, Epoch Time 1361.7765(1284.5929), Bit/dim 3.4858(best: 3.4853), Xent 0.0000, Loss 3.4858, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6390 | Time 22.4766(22.4913) | Bit/dim 3.4859(3.4842) | Xent 0.0000(0.0000) | Loss 3.4859(3.4842) | Error 0.0000(0.0000) Steps 898(902.59) | Grad Norm 2.2401(2.8045) | Total Time 14.00(14.00)\n",
      "Iter 6400 | Time 23.0182(22.4906) | Bit/dim 3.4706(3.4872) | Xent 0.0000(0.0000) | Loss 3.4706(3.4872) | Error 0.0000(0.0000) Steps 916(902.10) | Grad Norm 2.5344(2.9415) | Total Time 14.00(14.00)\n",
      "Iter 6410 | Time 22.1914(22.4343) | Bit/dim 3.4658(3.4870) | Xent 0.0000(0.0000) | Loss 3.4658(3.4870) | Error 0.0000(0.0000) Steps 916(903.42) | Grad Norm 1.9735(2.6714) | Total Time 14.00(14.00)\n",
      "Iter 6420 | Time 22.4310(22.4293) | Bit/dim 3.5127(3.4874) | Xent 0.0000(0.0000) | Loss 3.5127(3.4874) | Error 0.0000(0.0000) Steps 916(904.86) | Grad Norm 4.9601(2.9648) | Total Time 14.00(14.00)\n",
      "Iter 6430 | Time 22.2279(22.3834) | Bit/dim 3.4423(3.4825) | Xent 0.0000(0.0000) | Loss 3.4423(3.4825) | Error 0.0000(0.0000) Steps 910(904.81) | Grad Norm 3.4991(3.0714) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 106.2933, Epoch Time 1353.8781(1286.6715), Bit/dim 3.4864(best: 3.4853), Xent 0.0000, Loss 3.4864, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6440 | Time 22.7660(22.3784) | Bit/dim 3.4973(3.4814) | Xent 0.0000(0.0000) | Loss 3.4973(3.4814) | Error 0.0000(0.0000) Steps 904(904.77) | Grad Norm 3.1779(3.0947) | Total Time 14.00(14.00)\n",
      "Iter 6450 | Time 22.5226(22.3732) | Bit/dim 3.4808(3.4803) | Xent 0.0000(0.0000) | Loss 3.4808(3.4803) | Error 0.0000(0.0000) Steps 904(904.00) | Grad Norm 2.2168(2.9611) | Total Time 14.00(14.00)\n",
      "Iter 6460 | Time 22.7383(22.4125) | Bit/dim 3.4640(3.4821) | Xent 0.0000(0.0000) | Loss 3.4640(3.4821) | Error 0.0000(0.0000) Steps 910(904.01) | Grad Norm 2.1039(2.9010) | Total Time 14.00(14.00)\n",
      "Iter 6470 | Time 22.9413(22.4325) | Bit/dim 3.4990(3.4823) | Xent 0.0000(0.0000) | Loss 3.4990(3.4823) | Error 0.0000(0.0000) Steps 904(904.13) | Grad Norm 3.2263(2.8759) | Total Time 14.00(14.00)\n",
      "Iter 6480 | Time 22.1594(22.4634) | Bit/dim 3.5025(3.4824) | Xent 0.0000(0.0000) | Loss 3.5025(3.4824) | Error 0.0000(0.0000) Steps 904(904.72) | Grad Norm 2.2460(3.0802) | Total Time 14.00(14.00)\n",
      "Iter 6490 | Time 22.1203(22.3920) | Bit/dim 3.4915(3.4835) | Xent 0.0000(0.0000) | Loss 3.4915(3.4835) | Error 0.0000(0.0000) Steps 904(904.34) | Grad Norm 2.1623(2.9162) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 106.2246, Epoch Time 1357.0682(1288.7834), Bit/dim 3.4828(best: 3.4853), Xent 0.0000, Loss 3.4828, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6500 | Time 22.0309(22.4552) | Bit/dim 3.4699(3.4814) | Xent 0.0000(0.0000) | Loss 3.4699(3.4814) | Error 0.0000(0.0000) Steps 910(906.39) | Grad Norm 3.6765(2.8531) | Total Time 14.00(14.00)\n",
      "Iter 6510 | Time 22.7994(22.4192) | Bit/dim 3.4923(3.4826) | Xent 0.0000(0.0000) | Loss 3.4923(3.4826) | Error 0.0000(0.0000) Steps 904(905.55) | Grad Norm 2.2553(2.7602) | Total Time 14.00(14.00)\n",
      "Iter 6520 | Time 22.7754(22.4864) | Bit/dim 3.5006(3.4851) | Xent 0.0000(0.0000) | Loss 3.5006(3.4851) | Error 0.0000(0.0000) Steps 898(905.02) | Grad Norm 2.3257(2.8243) | Total Time 14.00(14.00)\n",
      "Iter 6530 | Time 22.6241(22.5165) | Bit/dim 3.4673(3.4853) | Xent 0.0000(0.0000) | Loss 3.4673(3.4853) | Error 0.0000(0.0000) Steps 910(905.53) | Grad Norm 4.3651(2.8972) | Total Time 14.00(14.00)\n",
      "Iter 6540 | Time 22.9649(22.5416) | Bit/dim 3.4949(3.4807) | Xent 0.0000(0.0000) | Loss 3.4949(3.4807) | Error 0.0000(0.0000) Steps 898(904.33) | Grad Norm 2.6299(2.9065) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 106.0721, Epoch Time 1364.2346(1291.0469), Bit/dim 3.4846(best: 3.4828), Xent 0.0000, Loss 3.4846, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6550 | Time 23.0646(22.5293) | Bit/dim 3.4707(3.4821) | Xent 0.0000(0.0000) | Loss 3.4707(3.4821) | Error 0.0000(0.0000) Steps 910(903.82) | Grad Norm 2.3296(2.8144) | Total Time 14.00(14.00)\n",
      "Iter 6560 | Time 21.9886(22.4632) | Bit/dim 3.4776(3.4811) | Xent 0.0000(0.0000) | Loss 3.4776(3.4811) | Error 0.0000(0.0000) Steps 910(904.69) | Grad Norm 3.8236(2.6585) | Total Time 14.00(14.00)\n",
      "Iter 6570 | Time 22.7776(22.4846) | Bit/dim 3.4463(3.4802) | Xent 0.0000(0.0000) | Loss 3.4463(3.4802) | Error 0.0000(0.0000) Steps 910(906.22) | Grad Norm 3.5176(2.8981) | Total Time 14.00(14.00)\n",
      "Iter 6580 | Time 22.0741(22.4598) | Bit/dim 3.4726(3.4801) | Xent 0.0000(0.0000) | Loss 3.4726(3.4801) | Error 0.0000(0.0000) Steps 904(906.78) | Grad Norm 2.7760(2.9856) | Total Time 14.00(14.00)\n",
      "Iter 6590 | Time 22.1456(22.4326) | Bit/dim 3.4818(3.4792) | Xent 0.0000(0.0000) | Loss 3.4818(3.4792) | Error 0.0000(0.0000) Steps 910(905.92) | Grad Norm 2.0070(2.8511) | Total Time 14.00(14.00)\n",
      "Iter 6600 | Time 21.7997(22.4335) | Bit/dim 3.5063(3.4808) | Xent 0.0000(0.0000) | Loss 3.5063(3.4808) | Error 0.0000(0.0000) Steps 916(906.34) | Grad Norm 2.6719(2.8696) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 104.7761, Epoch Time 1355.5867(1292.9831), Bit/dim 3.4848(best: 3.4828), Xent 0.0000, Loss 3.4848, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6610 | Time 22.3322(22.4265) | Bit/dim 3.4442(3.4799) | Xent 0.0000(0.0000) | Loss 3.4442(3.4799) | Error 0.0000(0.0000) Steps 910(905.87) | Grad Norm 1.8999(2.9179) | Total Time 14.00(14.00)\n",
      "Iter 6620 | Time 22.6805(22.4826) | Bit/dim 3.5076(3.4819) | Xent 0.0000(0.0000) | Loss 3.5076(3.4819) | Error 0.0000(0.0000) Steps 898(905.97) | Grad Norm 3.0270(3.0036) | Total Time 14.00(14.00)\n",
      "Iter 6630 | Time 22.4289(22.4496) | Bit/dim 3.4625(3.4775) | Xent 0.0000(0.0000) | Loss 3.4625(3.4775) | Error 0.0000(0.0000) Steps 916(905.69) | Grad Norm 1.6725(2.8726) | Total Time 14.00(14.00)\n",
      "Iter 6640 | Time 22.2810(22.4404) | Bit/dim 3.4943(3.4777) | Xent 0.0000(0.0000) | Loss 3.4943(3.4777) | Error 0.0000(0.0000) Steps 904(906.32) | Grad Norm 2.0310(2.9049) | Total Time 14.00(14.00)\n",
      "Iter 6650 | Time 22.5211(22.4792) | Bit/dim 3.4504(3.4791) | Xent 0.0000(0.0000) | Loss 3.4504(3.4791) | Error 0.0000(0.0000) Steps 916(907.75) | Grad Norm 2.5859(2.8110) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 104.9583, Epoch Time 1359.9025(1294.9907), Bit/dim 3.4820(best: 3.4828), Xent 0.0000, Loss 3.4820, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6660 | Time 22.9009(22.5268) | Bit/dim 3.4625(3.4802) | Xent 0.0000(0.0000) | Loss 3.4625(3.4802) | Error 0.0000(0.0000) Steps 910(907.58) | Grad Norm 3.2750(2.9150) | Total Time 14.00(14.00)\n",
      "Iter 6670 | Time 22.7455(22.5553) | Bit/dim 3.4813(3.4800) | Xent 0.0000(0.0000) | Loss 3.4813(3.4800) | Error 0.0000(0.0000) Steps 898(906.97) | Grad Norm 3.1789(3.0023) | Total Time 14.00(14.00)\n",
      "Iter 6680 | Time 22.1850(22.6169) | Bit/dim 3.4961(3.4807) | Xent 0.0000(0.0000) | Loss 3.4961(3.4807) | Error 0.0000(0.0000) Steps 910(907.63) | Grad Norm 1.7957(2.8458) | Total Time 14.00(14.00)\n",
      "Iter 6690 | Time 22.0962(22.5973) | Bit/dim 3.4837(3.4763) | Xent 0.0000(0.0000) | Loss 3.4837(3.4763) | Error 0.0000(0.0000) Steps 904(906.82) | Grad Norm 3.2642(2.8975) | Total Time 14.00(14.00)\n",
      "Iter 6700 | Time 22.8769(22.5938) | Bit/dim 3.4941(3.4774) | Xent 0.0000(0.0000) | Loss 3.4941(3.4774) | Error 0.0000(0.0000) Steps 910(907.05) | Grad Norm 2.7032(2.8834) | Total Time 14.00(14.00)\n",
      "Iter 6710 | Time 22.5020(22.5133) | Bit/dim 3.5173(3.4784) | Xent 0.0000(0.0000) | Loss 3.5173(3.4784) | Error 0.0000(0.0000) Steps 904(906.05) | Grad Norm 2.3707(2.9199) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 104.4133, Epoch Time 1364.0340(1297.0620), Bit/dim 3.4806(best: 3.4820), Xent 0.0000, Loss 3.4806, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6720 | Time 22.9720(22.4992) | Bit/dim 3.4737(3.4771) | Xent 0.0000(0.0000) | Loss 3.4737(3.4771) | Error 0.0000(0.0000) Steps 904(907.24) | Grad Norm 2.2289(2.8248) | Total Time 14.00(14.00)\n",
      "Iter 6730 | Time 22.7062(22.5888) | Bit/dim 3.4751(3.4763) | Xent 0.0000(0.0000) | Loss 3.4751(3.4763) | Error 0.0000(0.0000) Steps 904(906.70) | Grad Norm 1.7041(2.9245) | Total Time 14.00(14.00)\n",
      "Iter 6740 | Time 23.1070(22.6495) | Bit/dim 3.4550(3.4747) | Xent 0.0000(0.0000) | Loss 3.4550(3.4747) | Error 0.0000(0.0000) Steps 910(906.50) | Grad Norm 4.1699(2.9789) | Total Time 14.00(14.00)\n",
      "Iter 6750 | Time 22.7685(22.6410) | Bit/dim 3.4871(3.4771) | Xent 0.0000(0.0000) | Loss 3.4871(3.4771) | Error 0.0000(0.0000) Steps 916(906.72) | Grad Norm 1.8925(2.8448) | Total Time 14.00(14.00)\n",
      "Iter 6760 | Time 23.0010(22.6269) | Bit/dim 3.4713(3.4787) | Xent 0.0000(0.0000) | Loss 3.4713(3.4787) | Error 0.0000(0.0000) Steps 910(907.73) | Grad Norm 3.6103(2.8366) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 105.2949, Epoch Time 1369.6755(1299.2404), Bit/dim 3.4752(best: 3.4806), Xent 0.0000, Loss 3.4752, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6770 | Time 22.2793(22.6008) | Bit/dim 3.4781(3.4760) | Xent 0.0000(0.0000) | Loss 3.4781(3.4760) | Error 0.0000(0.0000) Steps 916(908.47) | Grad Norm 3.7969(2.8772) | Total Time 14.00(14.00)\n",
      "Iter 6780 | Time 22.5502(22.5574) | Bit/dim 3.4799(3.4749) | Xent 0.0000(0.0000) | Loss 3.4799(3.4749) | Error 0.0000(0.0000) Steps 910(907.21) | Grad Norm 2.0316(2.9042) | Total Time 14.00(14.00)\n",
      "Iter 6790 | Time 22.4341(22.5237) | Bit/dim 3.4765(3.4737) | Xent 0.0000(0.0000) | Loss 3.4765(3.4737) | Error 0.0000(0.0000) Steps 910(906.33) | Grad Norm 2.0443(2.8961) | Total Time 14.00(14.00)\n",
      "Iter 6800 | Time 22.4252(22.4886) | Bit/dim 3.4962(3.4773) | Xent 0.0000(0.0000) | Loss 3.4962(3.4773) | Error 0.0000(0.0000) Steps 910(906.95) | Grad Norm 3.0229(2.7390) | Total Time 14.00(14.00)\n",
      "Iter 6810 | Time 22.9246(22.5651) | Bit/dim 3.4576(3.4773) | Xent 0.0000(0.0000) | Loss 3.4576(3.4773) | Error 0.0000(0.0000) Steps 910(907.81) | Grad Norm 2.5525(2.7698) | Total Time 14.00(14.00)\n",
      "Iter 6820 | Time 22.1029(22.5325) | Bit/dim 3.4962(3.4770) | Xent 0.0000(0.0000) | Loss 3.4962(3.4770) | Error 0.0000(0.0000) Steps 916(907.23) | Grad Norm 4.0671(2.7333) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 104.5746, Epoch Time 1358.8225(1301.0279), Bit/dim 3.4819(best: 3.4752), Xent 0.0000, Loss 3.4819, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6830 | Time 22.8231(22.5945) | Bit/dim 3.4479(3.4766) | Xent 0.0000(0.0000) | Loss 3.4479(3.4766) | Error 0.0000(0.0000) Steps 910(906.65) | Grad Norm 3.3962(2.9602) | Total Time 14.00(14.00)\n",
      "Iter 6840 | Time 23.0349(22.6098) | Bit/dim 3.4868(3.4755) | Xent 0.0000(0.0000) | Loss 3.4868(3.4755) | Error 0.0000(0.0000) Steps 916(906.64) | Grad Norm 3.1839(2.8929) | Total Time 14.00(14.00)\n",
      "Iter 6850 | Time 22.2952(22.6290) | Bit/dim 3.4706(3.4762) | Xent 0.0000(0.0000) | Loss 3.4706(3.4762) | Error 0.0000(0.0000) Steps 910(906.95) | Grad Norm 3.0565(2.9043) | Total Time 14.00(14.00)\n",
      "Iter 6860 | Time 23.0515(22.6161) | Bit/dim 3.4701(3.4770) | Xent 0.0000(0.0000) | Loss 3.4701(3.4770) | Error 0.0000(0.0000) Steps 904(907.60) | Grad Norm 2.6223(2.7402) | Total Time 14.00(14.00)\n",
      "Iter 6870 | Time 23.7474(22.6966) | Bit/dim 3.4727(3.4760) | Xent 0.0000(0.0000) | Loss 3.4727(3.4760) | Error 0.0000(0.0000) Steps 910(908.62) | Grad Norm 3.4477(2.8801) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 104.5325, Epoch Time 1372.0365(1303.1581), Bit/dim 3.4749(best: 3.4752), Xent 0.0000, Loss 3.4749, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6880 | Time 22.0899(22.6941) | Bit/dim 3.4492(3.4750) | Xent 0.0000(0.0000) | Loss 3.4492(3.4750) | Error 0.0000(0.0000) Steps 898(907.69) | Grad Norm 2.1141(2.7524) | Total Time 14.00(14.00)\n",
      "Iter 6890 | Time 22.1361(22.6518) | Bit/dim 3.4966(3.4753) | Xent 0.0000(0.0000) | Loss 3.4966(3.4753) | Error 0.0000(0.0000) Steps 916(907.83) | Grad Norm 3.5552(2.8957) | Total Time 14.00(14.00)\n",
      "Iter 6900 | Time 22.5168(22.6463) | Bit/dim 3.4794(3.4746) | Xent 0.0000(0.0000) | Loss 3.4794(3.4746) | Error 0.0000(0.0000) Steps 904(907.81) | Grad Norm 1.9193(2.9073) | Total Time 14.00(14.00)\n",
      "Iter 6910 | Time 22.7127(22.6694) | Bit/dim 3.4796(3.4742) | Xent 0.0000(0.0000) | Loss 3.4796(3.4742) | Error 0.0000(0.0000) Steps 904(908.27) | Grad Norm 2.5558(2.8513) | Total Time 14.00(14.00)\n",
      "Iter 6920 | Time 22.0714(22.6160) | Bit/dim 3.4712(3.4734) | Xent 0.0000(0.0000) | Loss 3.4712(3.4734) | Error 0.0000(0.0000) Steps 916(908.47) | Grad Norm 1.9843(2.7483) | Total Time 14.00(14.00)\n",
      "Epoch 0126 | Time 105.1387, Epoch Time 1366.1054(1305.0465), Bit/dim 3.4748(best: 3.4749), Xent 0.0000, Loss 3.4748, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6940 | Time 22.9786(22.6115) | Bit/dim 3.4698(3.4744) | Xent 0.0000(0.0000) | Loss 3.4698(3.4744) | Error 0.0000(0.0000) Steps 910(907.50) | Grad Norm 2.2890(2.7970) | Total Time 14.00(14.00)\n",
      "Iter 6950 | Time 22.4506(22.6350) | Bit/dim 3.5065(3.4729) | Xent 0.0000(0.0000) | Loss 3.5065(3.4729) | Error 0.0000(0.0000) Steps 910(907.78) | Grad Norm 3.4733(2.8455) | Total Time 14.00(14.00)\n",
      "Iter 6960 | Time 22.7024(22.6470) | Bit/dim 3.4827(3.4724) | Xent 0.0000(0.0000) | Loss 3.4827(3.4724) | Error 0.0000(0.0000) Steps 910(906.97) | Grad Norm 1.6017(2.7975) | Total Time 14.00(14.00)\n",
      "Iter 6970 | Time 23.2575(22.7041) | Bit/dim 3.4765(3.4754) | Xent 0.0000(0.0000) | Loss 3.4765(3.4754) | Error 0.0000(0.0000) Steps 910(907.63) | Grad Norm 3.1696(2.9687) | Total Time 14.00(14.00)\n",
      "Iter 6980 | Time 22.9168(22.7210) | Bit/dim 3.4954(3.4751) | Xent 0.0000(0.0000) | Loss 3.4954(3.4751) | Error 0.0000(0.0000) Steps 916(906.05) | Grad Norm 4.3111(2.9706) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 105.9328, Epoch Time 1371.7884(1307.0488), Bit/dim 3.4741(best: 3.4748), Xent 0.0000, Loss 3.4741, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6990 | Time 22.9034(22.7054) | Bit/dim 3.4783(3.4718) | Xent 0.0000(0.0000) | Loss 3.4783(3.4718) | Error 0.0000(0.0000) Steps 904(905.86) | Grad Norm 3.6546(2.9925) | Total Time 14.00(14.00)\n",
      "Iter 7000 | Time 22.4912(22.6747) | Bit/dim 3.5190(3.4720) | Xent 0.0000(0.0000) | Loss 3.5190(3.4720) | Error 0.0000(0.0000) Steps 904(905.25) | Grad Norm 2.4427(2.9592) | Total Time 14.00(14.00)\n",
      "Iter 7010 | Time 22.6973(22.6779) | Bit/dim 3.5060(3.4750) | Xent 0.0000(0.0000) | Loss 3.5060(3.4750) | Error 0.0000(0.0000) Steps 916(906.08) | Grad Norm 3.0558(2.9447) | Total Time 14.00(14.00)\n",
      "Iter 7020 | Time 23.1988(22.6732) | Bit/dim 3.4599(3.4741) | Xent 0.0000(0.0000) | Loss 3.4599(3.4741) | Error 0.0000(0.0000) Steps 904(905.18) | Grad Norm 2.4695(2.8736) | Total Time 14.00(14.00)\n",
      "Iter 7030 | Time 21.9132(22.5832) | Bit/dim 3.4733(3.4737) | Xent 0.0000(0.0000) | Loss 3.4733(3.4737) | Error 0.0000(0.0000) Steps 904(904.89) | Grad Norm 2.2408(2.9275) | Total Time 14.00(14.00)\n",
      "Iter 7040 | Time 23.0057(22.5874) | Bit/dim 3.4987(3.4726) | Xent 0.0000(0.0000) | Loss 3.4987(3.4726) | Error 0.0000(0.0000) Steps 904(905.81) | Grad Norm 2.3042(2.8619) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 105.0326, Epoch Time 1364.7942(1308.7812), Bit/dim 3.4694(best: 3.4741), Xent 0.0000, Loss 3.4694, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7050 | Time 22.3096(22.4849) | Bit/dim 3.4724(3.4718) | Xent 0.0000(0.0000) | Loss 3.4724(3.4718) | Error 0.0000(0.0000) Steps 916(906.30) | Grad Norm 3.0353(2.8379) | Total Time 14.00(14.00)\n",
      "Iter 7060 | Time 22.7128(22.4684) | Bit/dim 3.4529(3.4686) | Xent 0.0000(0.0000) | Loss 3.4529(3.4686) | Error 0.0000(0.0000) Steps 916(906.69) | Grad Norm 2.7095(2.8656) | Total Time 14.00(14.00)\n",
      "Iter 7070 | Time 22.2260(22.4755) | Bit/dim 3.4916(3.4708) | Xent 0.0000(0.0000) | Loss 3.4916(3.4708) | Error 0.0000(0.0000) Steps 916(908.54) | Grad Norm 2.5197(2.8919) | Total Time 14.00(14.00)\n",
      "Iter 7080 | Time 22.3841(22.5524) | Bit/dim 3.4749(3.4737) | Xent 0.0000(0.0000) | Loss 3.4749(3.4737) | Error 0.0000(0.0000) Steps 898(907.49) | Grad Norm 2.7110(2.7281) | Total Time 14.00(14.00)\n",
      "Iter 7090 | Time 23.4241(22.6087) | Bit/dim 3.4529(3.4725) | Xent 0.0000(0.0000) | Loss 3.4529(3.4725) | Error 0.0000(0.0000) Steps 904(907.31) | Grad Norm 3.4122(2.8338) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 106.0363, Epoch Time 1363.6769(1310.4280), Bit/dim 3.4700(best: 3.4694), Xent 0.0000, Loss 3.4700, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7100 | Time 22.9801(22.5982) | Bit/dim 3.4841(3.4710) | Xent 0.0000(0.0000) | Loss 3.4841(3.4710) | Error 0.0000(0.0000) Steps 910(907.30) | Grad Norm 4.1946(2.9446) | Total Time 14.00(14.00)\n",
      "Iter 7110 | Time 22.3997(22.5453) | Bit/dim 3.4812(3.4701) | Xent 0.0000(0.0000) | Loss 3.4812(3.4701) | Error 0.0000(0.0000) Steps 910(907.40) | Grad Norm 3.4512(2.8853) | Total Time 14.00(14.00)\n",
      "Iter 7120 | Time 22.7426(22.5714) | Bit/dim 3.4795(3.4737) | Xent 0.0000(0.0000) | Loss 3.4795(3.4737) | Error 0.0000(0.0000) Steps 904(906.38) | Grad Norm 2.9079(2.9710) | Total Time 14.00(14.00)\n",
      "Iter 7130 | Time 22.3892(22.5940) | Bit/dim 3.4888(3.4711) | Xent 0.0000(0.0000) | Loss 3.4888(3.4711) | Error 0.0000(0.0000) Steps 910(906.08) | Grad Norm 2.0498(2.7342) | Total Time 14.00(14.00)\n",
      "Iter 7140 | Time 22.4774(22.5473) | Bit/dim 3.4856(3.4700) | Xent 0.0000(0.0000) | Loss 3.4856(3.4700) | Error 0.0000(0.0000) Steps 910(906.79) | Grad Norm 2.7143(2.8239) | Total Time 14.00(14.00)\n",
      "Iter 7150 | Time 22.2025(22.5359) | Bit/dim 3.4549(3.4698) | Xent 0.0000(0.0000) | Loss 3.4549(3.4698) | Error 0.0000(0.0000) Steps 904(907.07) | Grad Norm 2.1900(2.8602) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 104.5391, Epoch Time 1360.7144(1311.9366), Bit/dim 3.4700(best: 3.4694), Xent 0.0000, Loss 3.4700, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7160 | Time 22.8130(22.5603) | Bit/dim 3.4717(3.4686) | Xent 0.0000(0.0000) | Loss 3.4717(3.4686) | Error 0.0000(0.0000) Steps 922(907.54) | Grad Norm 1.7660(2.7962) | Total Time 14.00(14.00)\n",
      "Iter 7170 | Time 21.9381(22.5486) | Bit/dim 3.4666(3.4681) | Xent 0.0000(0.0000) | Loss 3.4666(3.4681) | Error 0.0000(0.0000) Steps 904(907.36) | Grad Norm 1.8427(2.8360) | Total Time 14.00(14.00)\n",
      "Iter 7180 | Time 22.7687(22.5752) | Bit/dim 3.4484(3.4698) | Xent 0.0000(0.0000) | Loss 3.4484(3.4698) | Error 0.0000(0.0000) Steps 904(906.79) | Grad Norm 3.7253(2.8034) | Total Time 14.00(14.00)\n",
      "Iter 7190 | Time 23.1238(22.6862) | Bit/dim 3.4929(3.4723) | Xent 0.0000(0.0000) | Loss 3.4929(3.4723) | Error 0.0000(0.0000) Steps 898(906.93) | Grad Norm 2.6879(2.8241) | Total Time 14.00(14.00)\n",
      "Iter 7200 | Time 23.0813(22.7853) | Bit/dim 3.4608(3.4695) | Xent 0.0000(0.0000) | Loss 3.4608(3.4695) | Error 0.0000(0.0000) Steps 898(908.05) | Grad Norm 2.2680(2.7039) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 106.5142, Epoch Time 1376.7715(1313.8817), Bit/dim 3.4703(best: 3.4694), Xent 0.0000, Loss 3.4703, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7210 | Time 23.3100(22.7861) | Bit/dim 3.4987(3.4694) | Xent 0.0000(0.0000) | Loss 3.4987(3.4694) | Error 0.0000(0.0000) Steps 910(908.85) | Grad Norm 3.8447(2.8621) | Total Time 14.00(14.00)\n",
      "Iter 7220 | Time 22.8082(22.7994) | Bit/dim 3.4672(3.4680) | Xent 0.0000(0.0000) | Loss 3.4672(3.4680) | Error 0.0000(0.0000) Steps 904(908.40) | Grad Norm 3.1649(2.8882) | Total Time 14.00(14.00)\n",
      "Iter 7230 | Time 22.5501(22.7073) | Bit/dim 3.5046(3.4694) | Xent 0.0000(0.0000) | Loss 3.5046(3.4694) | Error 0.0000(0.0000) Steps 910(907.40) | Grad Norm 2.5833(2.7660) | Total Time 14.00(14.00)\n",
      "Iter 7240 | Time 22.3633(22.6204) | Bit/dim 3.4572(3.4679) | Xent 0.0000(0.0000) | Loss 3.4572(3.4679) | Error 0.0000(0.0000) Steps 916(907.50) | Grad Norm 2.7407(2.8994) | Total Time 14.00(14.00)\n",
      "Iter 7250 | Time 23.5349(22.6583) | Bit/dim 3.4458(3.4680) | Xent 0.0000(0.0000) | Loss 3.4458(3.4680) | Error 0.0000(0.0000) Steps 916(908.79) | Grad Norm 3.0264(2.8560) | Total Time 14.00(14.00)\n",
      "Iter 7260 | Time 22.6425(22.6381) | Bit/dim 3.4579(3.4657) | Xent 0.0000(0.0000) | Loss 3.4579(3.4657) | Error 0.0000(0.0000) Steps 910(908.75) | Grad Norm 4.7532(2.9462) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 106.1070, Epoch Time 1367.8455(1315.5006), Bit/dim 3.4766(best: 3.4694), Xent 0.0000, Loss 3.4766, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7270 | Time 22.4433(22.5998) | Bit/dim 3.4493(3.4667) | Xent 0.0000(0.0000) | Loss 3.4493(3.4667) | Error 0.0000(0.0000) Steps 892(908.03) | Grad Norm 2.2124(2.7873) | Total Time 14.00(14.00)\n",
      "Iter 7280 | Time 22.1066(22.5359) | Bit/dim 3.4836(3.4683) | Xent 0.0000(0.0000) | Loss 3.4836(3.4683) | Error 0.0000(0.0000) Steps 892(905.58) | Grad Norm 3.0835(2.7681) | Total Time 14.00(14.00)\n",
      "Iter 7290 | Time 22.5431(22.5425) | Bit/dim 3.4815(3.4682) | Xent 0.0000(0.0000) | Loss 3.4815(3.4682) | Error 0.0000(0.0000) Steps 898(905.73) | Grad Norm 3.4140(2.8478) | Total Time 14.00(14.00)\n",
      "Iter 7300 | Time 22.4046(22.5242) | Bit/dim 3.4659(3.4676) | Xent 0.0000(0.0000) | Loss 3.4659(3.4676) | Error 0.0000(0.0000) Steps 904(904.93) | Grad Norm 2.8574(2.9174) | Total Time 14.00(14.00)\n",
      "Iter 7310 | Time 23.0129(22.5435) | Bit/dim 3.4518(3.4662) | Xent 0.0000(0.0000) | Loss 3.4518(3.4662) | Error 0.0000(0.0000) Steps 910(905.05) | Grad Norm 3.2757(2.8770) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 105.7013, Epoch Time 1363.1594(1316.9303), Bit/dim 3.4642(best: 3.4694), Xent 0.0000, Loss 3.4642, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7320 | Time 22.4177(22.6174) | Bit/dim 3.4632(3.4659) | Xent 0.0000(0.0000) | Loss 3.4632(3.4659) | Error 0.0000(0.0000) Steps 916(906.23) | Grad Norm 2.3914(2.5957) | Total Time 14.00(14.00)\n",
      "Iter 7330 | Time 22.8337(22.6002) | Bit/dim 3.4665(3.4678) | Xent 0.0000(0.0000) | Loss 3.4665(3.4678) | Error 0.0000(0.0000) Steps 892(904.98) | Grad Norm 3.9952(2.7632) | Total Time 14.00(14.00)\n",
      "Iter 7340 | Time 22.5807(22.5977) | Bit/dim 3.4669(3.4664) | Xent 0.0000(0.0000) | Loss 3.4669(3.4664) | Error 0.0000(0.0000) Steps 904(904.67) | Grad Norm 2.0307(2.7166) | Total Time 14.00(14.00)\n",
      "Iter 7350 | Time 22.8413(22.7103) | Bit/dim 3.4693(3.4677) | Xent 0.0000(0.0000) | Loss 3.4693(3.4677) | Error 0.0000(0.0000) Steps 916(906.55) | Grad Norm 3.1507(2.7741) | Total Time 14.00(14.00)\n",
      "Iter 7360 | Time 22.9024(22.6877) | Bit/dim 3.4746(3.4676) | Xent 0.0000(0.0000) | Loss 3.4746(3.4676) | Error 0.0000(0.0000) Steps 904(904.93) | Grad Norm 2.0443(2.7791) | Total Time 14.00(14.00)\n",
      "Iter 7370 | Time 22.8821(22.6981) | Bit/dim 3.4827(3.4666) | Xent 0.0000(0.0000) | Loss 3.4827(3.4666) | Error 0.0000(0.0000) Steps 910(905.44) | Grad Norm 3.2611(2.7739) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 105.4570, Epoch Time 1371.7700(1318.5755), Bit/dim 3.4708(best: 3.4642), Xent 0.0000, Loss 3.4708, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7380 | Time 22.6092(22.6328) | Bit/dim 3.4530(3.4644) | Xent 0.0000(0.0000) | Loss 3.4530(3.4644) | Error 0.0000(0.0000) Steps 910(905.56) | Grad Norm 3.6612(2.8063) | Total Time 14.00(14.00)\n",
      "Iter 7390 | Time 22.8967(22.6600) | Bit/dim 3.4740(3.4653) | Xent 0.0000(0.0000) | Loss 3.4740(3.4653) | Error 0.0000(0.0000) Steps 892(904.16) | Grad Norm 3.9917(2.9086) | Total Time 14.00(14.00)\n",
      "Iter 7400 | Time 22.2716(22.5668) | Bit/dim 3.4916(3.4679) | Xent 0.0000(0.0000) | Loss 3.4916(3.4679) | Error 0.0000(0.0000) Steps 898(902.71) | Grad Norm 1.5385(2.8583) | Total Time 14.00(14.00)\n",
      "Iter 7410 | Time 23.2687(22.5592) | Bit/dim 3.4784(3.4679) | Xent 0.0000(0.0000) | Loss 3.4784(3.4679) | Error 0.0000(0.0000) Steps 916(903.12) | Grad Norm 3.6019(2.8971) | Total Time 14.00(14.00)\n",
      "Iter 7420 | Time 22.1393(22.4994) | Bit/dim 3.4273(3.4644) | Xent 0.0000(0.0000) | Loss 3.4273(3.4644) | Error 0.0000(0.0000) Steps 904(903.64) | Grad Norm 2.3829(2.8497) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 105.5882, Epoch Time 1359.9373(1319.8164), Bit/dim 3.4650(best: 3.4642), Xent 0.0000, Loss 3.4650, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7430 | Time 23.0873(22.5468) | Bit/dim 3.4859(3.4648) | Xent 0.0000(0.0000) | Loss 3.4859(3.4648) | Error 0.0000(0.0000) Steps 898(902.93) | Grad Norm 3.9200(2.8684) | Total Time 14.00(14.00)\n",
      "Iter 7440 | Time 23.0371(22.5676) | Bit/dim 3.4574(3.4642) | Xent 0.0000(0.0000) | Loss 3.4574(3.4642) | Error 0.0000(0.0000) Steps 904(903.12) | Grad Norm 1.8649(2.6795) | Total Time 14.00(14.00)\n",
      "Iter 7450 | Time 22.4637(22.5905) | Bit/dim 3.4339(3.4637) | Xent 0.0000(0.0000) | Loss 3.4339(3.4637) | Error 0.0000(0.0000) Steps 916(904.96) | Grad Norm 3.8956(2.7195) | Total Time 14.00(14.00)\n",
      "Iter 7460 | Time 22.6239(22.5937) | Bit/dim 3.4993(3.4644) | Xent 0.0000(0.0000) | Loss 3.4993(3.4644) | Error 0.0000(0.0000) Steps 910(905.52) | Grad Norm 4.3064(2.7900) | Total Time 14.00(14.00)\n",
      "Iter 7470 | Time 22.5736(22.5956) | Bit/dim 3.4621(3.4637) | Xent 0.0000(0.0000) | Loss 3.4621(3.4637) | Error 0.0000(0.0000) Steps 892(904.41) | Grad Norm 3.6249(2.9295) | Total Time 14.00(14.00)\n",
      "Iter 7480 | Time 22.5514(22.6158) | Bit/dim 3.4472(3.4635) | Xent 0.0000(0.0000) | Loss 3.4472(3.4635) | Error 0.0000(0.0000) Steps 910(904.66) | Grad Norm 2.7373(2.6955) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 105.3600, Epoch Time 1368.2844(1321.2704), Bit/dim 3.4673(best: 3.4642), Xent 0.0000, Loss 3.4673, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7490 | Time 22.5938(22.5896) | Bit/dim 3.4861(3.4636) | Xent 0.0000(0.0000) | Loss 3.4861(3.4636) | Error 0.0000(0.0000) Steps 898(903.67) | Grad Norm 3.2339(2.8297) | Total Time 14.00(14.00)\n",
      "Iter 7500 | Time 22.5075(22.5958) | Bit/dim 3.4650(3.4635) | Xent 0.0000(0.0000) | Loss 3.4650(3.4635) | Error 0.0000(0.0000) Steps 898(904.35) | Grad Norm 2.5496(2.8346) | Total Time 14.00(14.00)\n",
      "Iter 7510 | Time 23.1220(22.5695) | Bit/dim 3.4391(3.4626) | Xent 0.0000(0.0000) | Loss 3.4391(3.4626) | Error 0.0000(0.0000) Steps 898(903.84) | Grad Norm 2.0991(2.6665) | Total Time 14.00(14.00)\n",
      "Iter 7520 | Time 22.4553(22.5541) | Bit/dim 3.4963(3.4624) | Xent 0.0000(0.0000) | Loss 3.4963(3.4624) | Error 0.0000(0.0000) Steps 904(903.12) | Grad Norm 1.9902(2.6449) | Total Time 14.00(14.00)\n",
      "Iter 7530 | Time 22.5161(22.5923) | Bit/dim 3.4573(3.4612) | Xent 0.0000(0.0000) | Loss 3.4573(3.4612) | Error 0.0000(0.0000) Steps 898(904.00) | Grad Norm 1.5146(2.7238) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 105.5057, Epoch Time 1364.4136(1322.5647), Bit/dim 3.4632(best: 3.4642), Xent 0.0000, Loss 3.4632, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7540 | Time 22.9905(22.6339) | Bit/dim 3.4701(3.4622) | Xent 0.0000(0.0000) | Loss 3.4701(3.4622) | Error 0.0000(0.0000) Steps 904(904.01) | Grad Norm 4.5540(2.8615) | Total Time 14.00(14.00)\n",
      "Iter 7550 | Time 23.2798(22.6216) | Bit/dim 3.4738(3.4631) | Xent 0.0000(0.0000) | Loss 3.4738(3.4631) | Error 0.0000(0.0000) Steps 910(904.53) | Grad Norm 2.8846(2.8417) | Total Time 14.00(14.00)\n",
      "Iter 7560 | Time 22.9871(22.6371) | Bit/dim 3.4768(3.4621) | Xent 0.0000(0.0000) | Loss 3.4768(3.4621) | Error 0.0000(0.0000) Steps 898(904.65) | Grad Norm 2.8443(2.8242) | Total Time 14.00(14.00)\n",
      "Iter 7570 | Time 22.3432(22.6429) | Bit/dim 3.4937(3.4646) | Xent 0.0000(0.0000) | Loss 3.4937(3.4646) | Error 0.0000(0.0000) Steps 904(905.03) | Grad Norm 3.1926(2.7117) | Total Time 14.00(14.00)\n",
      "Iter 7580 | Time 22.9455(22.6980) | Bit/dim 3.4628(3.4623) | Xent 0.0000(0.0000) | Loss 3.4628(3.4623) | Error 0.0000(0.0000) Steps 904(906.57) | Grad Norm 3.2268(2.7507) | Total Time 14.00(14.00)\n",
      "Iter 7590 | Time 22.9809(22.7059) | Bit/dim 3.4752(3.4623) | Xent 0.0000(0.0000) | Loss 3.4752(3.4623) | Error 0.0000(0.0000) Steps 904(906.21) | Grad Norm 1.6558(2.6800) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 106.2624, Epoch Time 1373.7202(1324.0994), Bit/dim 3.4614(best: 3.4632), Xent 0.0000, Loss 3.4614, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7600 | Time 22.8641(22.6611) | Bit/dim 3.4814(3.4634) | Xent 0.0000(0.0000) | Loss 3.4814(3.4634) | Error 0.0000(0.0000) Steps 910(906.30) | Grad Norm 4.3310(2.6633) | Total Time 14.00(14.00)\n",
      "Iter 7610 | Time 22.4833(22.7090) | Bit/dim 3.4794(3.4644) | Xent 0.0000(0.0000) | Loss 3.4794(3.4644) | Error 0.0000(0.0000) Steps 910(906.73) | Grad Norm 1.7255(2.7452) | Total Time 14.00(14.00)\n",
      "Iter 7620 | Time 22.1369(22.7116) | Bit/dim 3.4760(3.4639) | Xent 0.0000(0.0000) | Loss 3.4760(3.4639) | Error 0.0000(0.0000) Steps 898(906.22) | Grad Norm 3.3093(2.7859) | Total Time 14.00(14.00)\n",
      "Iter 7630 | Time 22.0310(22.6365) | Bit/dim 3.4473(3.4623) | Xent 0.0000(0.0000) | Loss 3.4473(3.4623) | Error 0.0000(0.0000) Steps 898(904.72) | Grad Norm 3.0810(2.6283) | Total Time 14.00(14.00)\n",
      "Iter 7640 | Time 22.3738(22.6153) | Bit/dim 3.4406(3.4624) | Xent 0.0000(0.0000) | Loss 3.4406(3.4624) | Error 0.0000(0.0000) Steps 898(903.85) | Grad Norm 2.7605(2.6839) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 104.4698, Epoch Time 1365.7933(1325.3502), Bit/dim 3.4636(best: 3.4614), Xent 0.0000, Loss 3.4636, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7650 | Time 22.9539(22.5889) | Bit/dim 3.4557(3.4614) | Xent 0.0000(0.0000) | Loss 3.4557(3.4614) | Error 0.0000(0.0000) Steps 904(903.59) | Grad Norm 1.6202(2.6543) | Total Time 14.00(14.00)\n",
      "Iter 7660 | Time 22.9102(22.5811) | Bit/dim 3.4575(3.4622) | Xent 0.0000(0.0000) | Loss 3.4575(3.4622) | Error 0.0000(0.0000) Steps 916(903.59) | Grad Norm 3.9485(2.7555) | Total Time 14.00(14.00)\n",
      "Iter 7670 | Time 22.4711(22.5596) | Bit/dim 3.4285(3.4603) | Xent 0.0000(0.0000) | Loss 3.4285(3.4603) | Error 0.0000(0.0000) Steps 898(903.16) | Grad Norm 1.7261(2.6267) | Total Time 14.00(14.00)\n",
      "Iter 7680 | Time 22.5790(22.5745) | Bit/dim 3.4734(3.4610) | Xent 0.0000(0.0000) | Loss 3.4734(3.4610) | Error 0.0000(0.0000) Steps 910(904.35) | Grad Norm 1.5234(2.5669) | Total Time 14.00(14.00)\n",
      "Iter 7690 | Time 22.2178(22.4986) | Bit/dim 3.4780(3.4608) | Xent 0.0000(0.0000) | Loss 3.4780(3.4608) | Error 0.0000(0.0000) Steps 904(903.16) | Grad Norm 3.6294(2.6811) | Total Time 14.00(14.00)\n",
      "Iter 7700 | Time 22.4929(22.5270) | Bit/dim 3.4838(3.4600) | Xent 0.0000(0.0000) | Loss 3.4838(3.4600) | Error 0.0000(0.0000) Steps 904(902.57) | Grad Norm 2.6916(2.6475) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 106.2829, Epoch Time 1362.7918(1326.4734), Bit/dim 3.4644(best: 3.4614), Xent 0.0000, Loss 3.4644, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7710 | Time 23.3927(22.5806) | Bit/dim 3.4668(3.4599) | Xent 0.0000(0.0000) | Loss 3.4668(3.4599) | Error 0.0000(0.0000) Steps 904(904.19) | Grad Norm 3.0786(2.7229) | Total Time 14.00(14.00)\n",
      "Iter 7720 | Time 22.0112(22.5499) | Bit/dim 3.4762(3.4573) | Xent 0.0000(0.0000) | Loss 3.4762(3.4573) | Error 0.0000(0.0000) Steps 898(903.90) | Grad Norm 1.7115(2.5029) | Total Time 14.00(14.00)\n",
      "Iter 7730 | Time 22.3460(22.6087) | Bit/dim 3.4755(3.4578) | Xent 0.0000(0.0000) | Loss 3.4755(3.4578) | Error 0.0000(0.0000) Steps 904(905.40) | Grad Norm 4.1969(2.6652) | Total Time 14.00(14.00)\n",
      "Iter 7740 | Time 22.3244(22.5945) | Bit/dim 3.4574(3.4615) | Xent 0.0000(0.0000) | Loss 3.4574(3.4615) | Error 0.0000(0.0000) Steps 898(904.22) | Grad Norm 3.4242(2.7109) | Total Time 14.00(14.00)\n",
      "Iter 7750 | Time 22.8223(22.5644) | Bit/dim 3.4700(3.4638) | Xent 0.0000(0.0000) | Loss 3.4700(3.4638) | Error 0.0000(0.0000) Steps 910(903.60) | Grad Norm 3.7326(2.7973) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0141 | Time 106.1767, Epoch Time 1366.6791(1327.6796), Bit/dim 3.4596(best: 3.4614), Xent 0.0000, Loss 3.4596, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7760 | Time 22.9629(22.5470) | Bit/dim 3.4341(3.4600) | Xent 0.0000(0.0000) | Loss 3.4341(3.4600) | Error 0.0000(0.0000) Steps 904(902.91) | Grad Norm 2.2897(2.6828) | Total Time 14.00(14.00)\n",
      "Iter 7770 | Time 22.5921(22.5421) | Bit/dim 3.4673(3.4596) | Xent 0.0000(0.0000) | Loss 3.4673(3.4596) | Error 0.0000(0.0000) Steps 898(902.68) | Grad Norm 3.2562(2.7997) | Total Time 14.00(14.00)\n",
      "Iter 7780 | Time 22.5212(22.5189) | Bit/dim 3.4833(3.4605) | Xent 0.0000(0.0000) | Loss 3.4833(3.4605) | Error 0.0000(0.0000) Steps 898(902.11) | Grad Norm 2.4246(2.6598) | Total Time 14.00(14.00)\n",
      "Iter 7790 | Time 22.4573(22.5746) | Bit/dim 3.4640(3.4603) | Xent 0.0000(0.0000) | Loss 3.4640(3.4603) | Error 0.0000(0.0000) Steps 910(902.67) | Grad Norm 1.4885(2.7135) | Total Time 14.00(14.00)\n",
      "Iter 7800 | Time 23.2496(22.5916) | Bit/dim 3.4850(3.4587) | Xent 0.0000(0.0000) | Loss 3.4850(3.4587) | Error 0.0000(0.0000) Steps 910(902.89) | Grad Norm 3.8302(2.6935) | Total Time 14.00(14.00)\n",
      "Epoch 0142 | Time 104.1427, Epoch Time 1362.9765(1328.7385), Bit/dim 3.4662(best: 3.4596), Xent 0.0000, Loss 3.4662, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7820 | Time 22.1423(22.5187) | Bit/dim 3.4107(3.4569) | Xent 0.0000(0.0000) | Loss 3.4107(3.4569) | Error 0.0000(0.0000) Steps 904(902.86) | Grad Norm 3.1181(2.7356) | Total Time 14.00(14.00)\n",
      "Iter 7830 | Time 22.2615(22.4855) | Bit/dim 3.4647(3.4585) | Xent 0.0000(0.0000) | Loss 3.4647(3.4585) | Error 0.0000(0.0000) Steps 904(903.31) | Grad Norm 3.3009(2.8241) | Total Time 14.00(14.00)\n",
      "Iter 7840 | Time 22.4138(22.5256) | Bit/dim 3.4690(3.4591) | Xent 0.0000(0.0000) | Loss 3.4690(3.4591) | Error 0.0000(0.0000) Steps 910(904.34) | Grad Norm 2.2674(2.6922) | Total Time 14.00(14.00)\n",
      "Iter 7850 | Time 23.0546(22.5646) | Bit/dim 3.5012(3.4611) | Xent 0.0000(0.0000) | Loss 3.5012(3.4611) | Error 0.0000(0.0000) Steps 910(904.73) | Grad Norm 2.8992(2.7178) | Total Time 14.00(14.00)\n",
      "Iter 7860 | Time 22.9167(22.5926) | Bit/dim 3.4775(3.4584) | Xent 0.0000(0.0000) | Loss 3.4775(3.4584) | Error 0.0000(0.0000) Steps 904(903.97) | Grad Norm 2.8755(2.7042) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0143 | Time 105.8994, Epoch Time 1365.8112(1329.8507), Bit/dim 3.4622(best: 3.4596), Xent 0.0000, Loss 3.4622, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7870 | Time 22.5022(22.6340) | Bit/dim 3.4691(3.4566) | Xent 0.0000(0.0000) | Loss 3.4691(3.4566) | Error 0.0000(0.0000) Steps 910(903.97) | Grad Norm 3.6255(2.8653) | Total Time 14.00(14.00)\n",
      "Iter 7880 | Time 22.3067(22.6222) | Bit/dim 3.4926(3.4567) | Xent 0.0000(0.0000) | Loss 3.4926(3.4567) | Error 0.0000(0.0000) Steps 910(904.83) | Grad Norm 3.8916(2.8531) | Total Time 14.00(14.00)\n",
      "Iter 7890 | Time 23.1334(22.5907) | Bit/dim 3.4486(3.4594) | Xent 0.0000(0.0000) | Loss 3.4486(3.4594) | Error 0.0000(0.0000) Steps 910(904.72) | Grad Norm 2.5852(2.7415) | Total Time 14.00(14.00)\n",
      "Iter 7900 | Time 22.5060(22.6726) | Bit/dim 3.4258(3.4588) | Xent 0.0000(0.0000) | Loss 3.4258(3.4588) | Error 0.0000(0.0000) Steps 898(904.17) | Grad Norm 2.7496(2.7373) | Total Time 14.00(14.00)\n",
      "Iter 7910 | Time 23.2038(22.7100) | Bit/dim 3.4086(3.4580) | Xent 0.0000(0.0000) | Loss 3.4086(3.4580) | Error 0.0000(0.0000) Steps 910(902.89) | Grad Norm 2.8563(2.6531) | Total Time 14.00(14.00)\n",
      "Iter 7920 | Time 22.4481(22.6880) | Bit/dim 3.4345(3.4559) | Xent 0.0000(0.0000) | Loss 3.4345(3.4559) | Error 0.0000(0.0000) Steps 892(902.92) | Grad Norm 2.6640(2.7402) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0144 | Time 105.1559, Epoch Time 1369.9833(1331.0547), Bit/dim 3.4583(best: 3.4596), Xent 0.0000, Loss 3.4583, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7930 | Time 22.7760(22.6192) | Bit/dim 3.4673(3.4567) | Xent 0.0000(0.0000) | Loss 3.4673(3.4567) | Error 0.0000(0.0000) Steps 922(903.24) | Grad Norm 2.8286(2.6800) | Total Time 14.00(14.00)\n",
      "Iter 7940 | Time 22.2516(22.5889) | Bit/dim 3.4444(3.4551) | Xent 0.0000(0.0000) | Loss 3.4444(3.4551) | Error 0.0000(0.0000) Steps 898(902.90) | Grad Norm 2.0740(2.6409) | Total Time 14.00(14.00)\n",
      "Iter 7950 | Time 22.6136(22.6193) | Bit/dim 3.4609(3.4548) | Xent 0.0000(0.0000) | Loss 3.4609(3.4548) | Error 0.0000(0.0000) Steps 910(904.32) | Grad Norm 3.9910(2.8218) | Total Time 14.00(14.00)\n",
      "Iter 7960 | Time 22.6870(22.5948) | Bit/dim 3.4821(3.4570) | Xent 0.0000(0.0000) | Loss 3.4821(3.4570) | Error 0.0000(0.0000) Steps 904(905.11) | Grad Norm 2.6423(2.8329) | Total Time 14.00(14.00)\n",
      "Iter 7970 | Time 22.9413(22.6144) | Bit/dim 3.4743(3.4565) | Xent 0.0000(0.0000) | Loss 3.4743(3.4565) | Error 0.0000(0.0000) Steps 910(906.13) | Grad Norm 2.0982(2.6584) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0145 | Time 105.1852, Epoch Time 1364.3576(1332.0538), Bit/dim 3.4564(best: 3.4583), Xent 0.0000, Loss 3.4564, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7980 | Time 23.2442(22.6453) | Bit/dim 3.4676(3.4575) | Xent 0.0000(0.0000) | Loss 3.4676(3.4575) | Error 0.0000(0.0000) Steps 922(906.84) | Grad Norm 1.7408(2.6164) | Total Time 14.00(14.00)\n",
      "Iter 7990 | Time 23.0782(22.6964) | Bit/dim 3.4845(3.4580) | Xent 0.0000(0.0000) | Loss 3.4845(3.4580) | Error 0.0000(0.0000) Steps 910(906.74) | Grad Norm 2.9406(2.7696) | Total Time 14.00(14.00)\n",
      "Iter 8000 | Time 22.7520(22.8046) | Bit/dim 3.4409(3.4575) | Xent 0.0000(0.0000) | Loss 3.4409(3.4575) | Error 0.0000(0.0000) Steps 910(907.23) | Grad Norm 2.2320(2.6121) | Total Time 14.00(14.00)\n",
      "Iter 8010 | Time 22.6255(22.8533) | Bit/dim 3.4751(3.4592) | Xent 0.0000(0.0000) | Loss 3.4751(3.4592) | Error 0.0000(0.0000) Steps 898(907.87) | Grad Norm 2.3694(2.7229) | Total Time 14.00(14.00)\n",
      "Iter 8020 | Time 22.4590(22.8402) | Bit/dim 3.4153(3.4558) | Xent 0.0000(0.0000) | Loss 3.4153(3.4558) | Error 0.0000(0.0000) Steps 898(906.50) | Grad Norm 3.1810(2.7756) | Total Time 14.00(14.00)\n",
      "Iter 8030 | Time 22.4797(22.7958) | Bit/dim 3.4571(3.4530) | Xent 0.0000(0.0000) | Loss 3.4571(3.4530) | Error 0.0000(0.0000) Steps 904(905.95) | Grad Norm 1.6650(2.5908) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0146 | Time 106.3174, Epoch Time 1382.1869(1333.5578), Bit/dim 3.4546(best: 3.4564), Xent 0.0000, Loss 3.4546, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8040 | Time 23.2378(22.8486) | Bit/dim 3.4459(3.4521) | Xent 0.0000(0.0000) | Loss 3.4459(3.4521) | Error 0.0000(0.0000) Steps 916(907.09) | Grad Norm 2.9524(2.6512) | Total Time 14.00(14.00)\n",
      "Iter 8050 | Time 22.8114(22.8266) | Bit/dim 3.4937(3.4544) | Xent 0.0000(0.0000) | Loss 3.4937(3.4544) | Error 0.0000(0.0000) Steps 904(907.75) | Grad Norm 2.8014(2.6959) | Total Time 14.00(14.00)\n",
      "Iter 8060 | Time 22.3850(22.8280) | Bit/dim 3.4623(3.4576) | Xent 0.0000(0.0000) | Loss 3.4623(3.4576) | Error 0.0000(0.0000) Steps 910(907.95) | Grad Norm 1.8295(2.5454) | Total Time 14.00(14.00)\n",
      "Iter 8070 | Time 22.3021(22.8061) | Bit/dim 3.4488(3.4563) | Xent 0.0000(0.0000) | Loss 3.4488(3.4563) | Error 0.0000(0.0000) Steps 910(908.02) | Grad Norm 4.1532(2.6046) | Total Time 14.00(14.00)\n",
      "Iter 8080 | Time 22.2315(22.7631) | Bit/dim 3.4655(3.4554) | Xent 0.0000(0.0000) | Loss 3.4655(3.4554) | Error 0.0000(0.0000) Steps 910(906.95) | Grad Norm 3.1506(2.7011) | Total Time 14.00(14.00)\n",
      "Epoch 0147 | Time 105.0960, Epoch Time 1376.2244(1334.8378), Bit/dim 3.4560(best: 3.4546), Xent 0.0000, Loss 3.4560, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8090 | Time 22.5694(22.6948) | Bit/dim 3.4509(3.4564) | Xent 0.0000(0.0000) | Loss 3.4509(3.4564) | Error 0.0000(0.0000) Steps 904(906.32) | Grad Norm 1.9874(2.6219) | Total Time 14.00(14.00)\n",
      "Iter 8100 | Time 22.5794(22.7020) | Bit/dim 3.4277(3.4529) | Xent 0.0000(0.0000) | Loss 3.4277(3.4529) | Error 0.0000(0.0000) Steps 904(906.35) | Grad Norm 3.1662(2.6824) | Total Time 14.00(14.00)\n",
      "Iter 8110 | Time 22.6734(22.6552) | Bit/dim 3.4355(3.4553) | Xent 0.0000(0.0000) | Loss 3.4355(3.4553) | Error 0.0000(0.0000) Steps 904(905.23) | Grad Norm 3.4218(2.5988) | Total Time 14.00(14.00)\n",
      "Iter 8120 | Time 22.4830(22.6992) | Bit/dim 3.4819(3.4554) | Xent 0.0000(0.0000) | Loss 3.4819(3.4554) | Error 0.0000(0.0000) Steps 916(905.08) | Grad Norm 3.8729(2.6595) | Total Time 14.00(14.00)\n",
      "Iter 8130 | Time 23.5666(22.7243) | Bit/dim 3.4318(3.4560) | Xent 0.0000(0.0000) | Loss 3.4318(3.4560) | Error 0.0000(0.0000) Steps 928(906.86) | Grad Norm 1.8008(2.7187) | Total Time 14.00(14.00)\n",
      "Iter 8140 | Time 23.3976(22.7504) | Bit/dim 3.4377(3.4528) | Xent 0.0000(0.0000) | Loss 3.4377(3.4528) | Error 0.0000(0.0000) Steps 910(906.21) | Grad Norm 4.0957(2.7041) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0148 | Time 108.8652, Epoch Time 1375.1637(1336.0475), Bit/dim 3.4554(best: 3.4546), Xent 0.0000, Loss 3.4554, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8150 | Time 23.0501(22.7880) | Bit/dim 3.4652(3.4506) | Xent 0.0000(0.0000) | Loss 3.4652(3.4506) | Error 0.0000(0.0000) Steps 916(907.01) | Grad Norm 3.2182(2.5297) | Total Time 14.00(14.00)\n",
      "Iter 8160 | Time 22.8389(22.8105) | Bit/dim 3.4704(3.4507) | Xent 0.0000(0.0000) | Loss 3.4704(3.4507) | Error 0.0000(0.0000) Steps 916(907.44) | Grad Norm 2.0376(2.6883) | Total Time 14.00(14.00)\n",
      "Iter 8170 | Time 23.6729(22.8672) | Bit/dim 3.4574(3.4504) | Xent 0.0000(0.0000) | Loss 3.4574(3.4504) | Error 0.0000(0.0000) Steps 934(908.84) | Grad Norm 2.4817(2.6494) | Total Time 14.00(14.00)\n",
      "Iter 8180 | Time 21.9530(22.8425) | Bit/dim 3.4560(3.4513) | Xent 0.0000(0.0000) | Loss 3.4560(3.4513) | Error 0.0000(0.0000) Steps 904(910.55) | Grad Norm 3.4690(2.7562) | Total Time 14.00(14.00)\n",
      "Iter 8190 | Time 22.5839(22.8044) | Bit/dim 3.4371(3.4543) | Xent 0.0000(0.0000) | Loss 3.4371(3.4543) | Error 0.0000(0.0000) Steps 910(909.16) | Grad Norm 1.7661(2.7013) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0149 | Time 107.9036, Epoch Time 1382.2507(1337.4336), Bit/dim 3.4580(best: 3.4546), Xent 0.0000, Loss 3.4580, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8200 | Time 23.4166(22.7682) | Bit/dim 3.4970(3.4555) | Xent 0.0000(0.0000) | Loss 3.4970(3.4555) | Error 0.0000(0.0000) Steps 916(909.38) | Grad Norm 2.8120(2.7587) | Total Time 14.00(14.00)\n",
      "Iter 8210 | Time 22.4285(22.6947) | Bit/dim 3.4618(3.4551) | Xent 0.0000(0.0000) | Loss 3.4618(3.4551) | Error 0.0000(0.0000) Steps 904(909.03) | Grad Norm 1.7853(2.5261) | Total Time 14.00(14.00)\n",
      "Iter 8220 | Time 22.7015(22.6793) | Bit/dim 3.4291(3.4531) | Xent 0.0000(0.0000) | Loss 3.4291(3.4531) | Error 0.0000(0.0000) Steps 910(908.20) | Grad Norm 4.0583(2.6009) | Total Time 14.00(14.00)\n",
      "Iter 8230 | Time 23.2204(22.7558) | Bit/dim 3.4618(3.4537) | Xent 0.0000(0.0000) | Loss 3.4618(3.4537) | Error 0.0000(0.0000) Steps 916(908.18) | Grad Norm 1.7097(2.6898) | Total Time 14.00(14.00)\n",
      "Iter 8240 | Time 22.8423(22.7268) | Bit/dim 3.4636(3.4550) | Xent 0.0000(0.0000) | Loss 3.4636(3.4550) | Error 0.0000(0.0000) Steps 910(908.04) | Grad Norm 2.6463(2.7434) | Total Time 14.00(14.00)\n",
      "Iter 8250 | Time 22.9447(22.7646) | Bit/dim 3.4483(3.4538) | Xent 0.0000(0.0000) | Loss 3.4483(3.4538) | Error 0.0000(0.0000) Steps 916(908.22) | Grad Norm 2.2229(2.7008) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0150 | Time 107.4016, Epoch Time 1373.8181(1338.5252), Bit/dim 3.4528(best: 3.4546), Xent 0.0000, Loss 3.4528, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8260 | Time 22.9973(22.7365) | Bit/dim 3.4208(3.4514) | Xent 0.0000(0.0000) | Loss 3.4208(3.4514) | Error 0.0000(0.0000) Steps 910(908.66) | Grad Norm 1.6668(2.4033) | Total Time 14.00(14.00)\n",
      "Iter 8270 | Time 23.3124(22.8829) | Bit/dim 3.4600(3.4500) | Xent 0.0000(0.0000) | Loss 3.4600(3.4500) | Error 0.0000(0.0000) Steps 904(910.07) | Grad Norm 4.1947(2.4785) | Total Time 14.00(14.00)\n",
      "Iter 8280 | Time 22.3686(22.8691) | Bit/dim 3.4462(3.4529) | Xent 0.0000(0.0000) | Loss 3.4462(3.4529) | Error 0.0000(0.0000) Steps 904(908.98) | Grad Norm 1.8786(2.3794) | Total Time 14.00(14.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_cifar10_published_baseline_bs900_2 --resume ../experiments_published/cnf_cifar10_published_baseline_bs900_2/current_checkpt.pth --seed 2 --lr 0.0001 --conditional False --controlled_tol False  --log_freq 10\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -p ../train_cnf.py --data mnist --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_published_baseline_bs900_1 --resume ../experiments_published/cnf_published_baseline_bs900_1/current_checkpt.pth --seed 1 --conditional False --controlled_tol False  --log_freq 10\n",
    "# #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
