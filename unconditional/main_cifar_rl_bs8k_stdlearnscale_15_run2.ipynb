{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import torch.utils.data as data\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "plt.rcParams['figure.dpi'] = 300\n",
      "\n",
      "from PIL import Image\n",
      "import os.path\n",
      "import errno\n",
      "import codecs\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"colormnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--y_class\", type=int, default=10)\n",
      "parser.add_argument(\"--y_color\", type=int, default=10)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "class ColorMNIST(data.Dataset):\n",
      "    \"\"\"\n",
      "    ColorMNIST\n",
      "    \"\"\"\n",
      "    urls = [\n",
      "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
      "    ]\n",
      "    raw_folder = 'raw'\n",
      "    processed_folder = 'processed'\n",
      "    training_file = 'training.pt'\n",
      "    test_file = 'test.pt'\n",
      "\n",
      "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
      "        self.root = os.path.expanduser(root)\n",
      "        self.transform = transform\n",
      "        self.target_transform = target_transform\n",
      "        self.train = train  # training set or test set\n",
      "\n",
      "        if download:\n",
      "            self.download()\n",
      "\n",
      "        if not self._check_exists():\n",
      "            raise RuntimeError('Dataset not found.' +\n",
      "                               ' You can use download=True to download it')\n",
      "\n",
      "        if self.train:\n",
      "            self.train_data, self.train_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
      "            \n",
      "            self.train_data = np.tile(self.train_data[:, :, :, np.newaxis], 3)\n",
      "        else:\n",
      "            self.test_data, self.test_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "            \n",
      "            self.test_data = np.tile(self.test_data[:, :, :, np.newaxis], 3)\n",
      "        \n",
      "        self.pallette = [[31, 119, 180],\n",
      "                         [255, 127, 14],\n",
      "                         [44, 160, 44],\n",
      "                         [214, 39, 40],\n",
      "                         [148, 103, 189],\n",
      "                         [140, 86, 75],\n",
      "                         [227, 119, 194],\n",
      "                         [127, 127, 127],\n",
      "                         [188, 189, 34],\n",
      "                         [23, 190, 207]]\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            index (int): Index\n",
      "\n",
      "        Returns:\n",
      "            tuple: (image, target) where target is index of the target class.\n",
      "        \"\"\"\n",
      "        if self.train:\n",
      "            img, target = self.train_data[index].copy(), self.train_labels[index]\n",
      "        else:\n",
      "            img, target = self.test_data[index].copy(), self.test_labels[index]\n",
      "        \n",
      "        # doing this so that it is consistent with all other datasets\n",
      "        # to return a PIL Image\n",
      "        y_color_digit = np.random.randint(0, args.y_color)\n",
      "        c_digit = self.pallette[y_color_digit]\n",
      "        \n",
      "        img[:, :, 0] = img[:, :, 0] / 255 * c_digit[0]\n",
      "        img[:, :, 1] = img[:, :, 1] / 255 * c_digit[1]\n",
      "        img[:, :, 2] = img[:, :, 2] / 255 * c_digit[2]\n",
      "        \n",
      "        img = Image.fromarray(img)\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "\n",
      "        return img, [target,torch.from_numpy(np.array(y_color_digit))]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.train:\n",
      "            return len(self.train_data)\n",
      "        else:\n",
      "            return len(self.test_data)\n",
      "\n",
      "    def _check_exists(self):\n",
      "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
      "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "\n",
      "    def download(self):\n",
      "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
      "        from six.moves import urllib\n",
      "        import gzip\n",
      "\n",
      "        if self._check_exists():\n",
      "            return\n",
      "\n",
      "        # download files\n",
      "        try:\n",
      "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
      "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
      "        except OSError as e:\n",
      "            if e.errno == errno.EEXIST:\n",
      "                pass\n",
      "            else:\n",
      "                raise\n",
      "\n",
      "        for url in self.urls:\n",
      "            print('Downloading ' + url)\n",
      "            data = urllib.request.urlopen(url)\n",
      "            filename = url.rpartition('/')[2]\n",
      "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
      "            with open(file_path, 'wb') as f:\n",
      "                f.write(data.read())\n",
      "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
      "                    gzip.GzipFile(file_path) as zip_f:\n",
      "                out_f.write(zip_f.read())\n",
      "            os.unlink(file_path)\n",
      "\n",
      "        # process and save as torch files\n",
      "        print('Processing...')\n",
      "\n",
      "        training_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
      "        )\n",
      "        test_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
      "        )\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
      "            torch.save(training_set, f)\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
      "            torch.save(test_set, f)\n",
      "\n",
      "        print('Done!')\n",
      "\n",
      "    def __repr__(self):\n",
      "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
      "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
      "        tmp = 'train' if self.train is True else 'test'\n",
      "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
      "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
      "        tmp = '    Transforms (if any): '\n",
      "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        tmp = '    Target Transforms (if any): '\n",
      "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        return fmt_str\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"colormnist\":\n",
      "        im_dim = 3\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = ColorMNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = ColorMNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,\n",
      "            y_class = args.y_class)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            if args.data == \"colormnist\":\n",
      "                y = y[0]\n",
      "            \n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        if args.data == \"colormnist\":\n",
      "            # print train images\n",
      "            xall = []\n",
      "            ximg = x[0:40].cpu().numpy().transpose((0,2,3,1))\n",
      "            for i in range(ximg.shape[0]):\n",
      "                xall.append(ximg[i])\n",
      "        \n",
      "            xall = np.hstack(xall)\n",
      "\n",
      "            plt.imshow(xall)\n",
      "            plt.axis('off')\n",
      "            plt.show()\n",
      "            \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if args.data == \"colormnist\":\n",
      "                        y = y[0]\n",
      "                        \n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                if args.data == \"colormnist\":\n",
      "                    # print test images\n",
      "                    xall = []\n",
      "                    ximg = x[0:40].cpu().numpy().transpose((0,2,3,1))\n",
      "                    for i in range(ximg.shape[0]):\n",
      "                        xall.append(ximg[i])\n",
      "\n",
      "                    xall = np.hstack(xall)\n",
      "\n",
      "                    plt.imshow(xall)\n",
      "                    plt.axis('off')\n",
      "                    plt.show()\n",
      "                    \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=False, atol=0.0001, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=False, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.0, eta=0.1, gamma=0.99, gate='cnn2', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.001, max_grad_norm=10.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_cifar10_bs8K_rl_stdlearnscale_15_run2/epoch_200_checkpt.pth', rl_weight=0.01, rtol=0.0001, save='../experiments_published/cnf_cifar10_bs8K_rl_stdlearnscale_15_run2', scale=1.0, scale_fac=1.0, scale_std=15.0, seed=2, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000.0, weight_decay=0.0, weight_y=0.5, y_class=10, y_color=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1450886\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 1201 | Time 119.8045(63.9109) | Bit/dim 3.5637(3.5655) | Xent 0.0000(0.0000) | Loss 11.6453(9.6257) | Error 0.0000(0.0000) Steps 682(662.79) | Grad Norm 3.7601(3.6613) | Total Time 0.00(0.00)\n",
      "Iter 1202 | Time 60.8510(63.8191) | Bit/dim 3.5535(3.5651) | Xent 0.0000(0.0000) | Loss 8.8107(9.6013) | Error 0.0000(0.0000) Steps 646(662.29) | Grad Norm 3.1243(3.6452) | Total Time 0.00(0.00)\n",
      "Iter 1203 | Time 62.2852(63.7731) | Bit/dim 3.5390(3.5643) | Xent 0.0000(0.0000) | Loss 8.7897(9.5769) | Error 0.0000(0.0000) Steps 652(661.98) | Grad Norm 1.8422(3.5911) | Total Time 0.00(0.00)\n",
      "Iter 1204 | Time 58.1526(63.6045) | Bit/dim 3.5249(3.5631) | Xent 0.0000(0.0000) | Loss 8.8228(9.5543) | Error 0.0000(0.0000) Steps 670(662.22) | Grad Norm 1.0036(3.5134) | Total Time 0.00(0.00)\n",
      "Iter 1205 | Time 63.9018(63.6134) | Bit/dim 3.5301(3.5621) | Xent 0.0000(0.0000) | Loss 9.0795(9.5401) | Error 0.0000(0.0000) Steps 694(663.18) | Grad Norm 2.0238(3.4688) | Total Time 0.00(0.00)\n",
      "Iter 1206 | Time 59.3694(63.4861) | Bit/dim 3.5320(3.5612) | Xent 0.0000(0.0000) | Loss 8.9110(9.5212) | Error 0.0000(0.0000) Steps 664(663.20) | Grad Norm 2.5097(3.4400) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0201 | Time 40.2565, Epoch Time 481.8133(394.9123), Bit/dim 3.5364(best: inf), Xent 0.0000, Loss 3.5364, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1207 | Time 73.7299(63.7934) | Bit/dim 3.5313(3.5603) | Xent 0.0000(0.0000) | Loss 13.5611(9.6424) | Error 0.0000(0.0000) Steps 658(663.04) | Grad Norm 2.3556(3.4075) | Total Time 0.00(0.00)\n",
      "Iter 1208 | Time 63.4826(63.7840) | Bit/dim 3.5326(3.5595) | Xent 0.0000(0.0000) | Loss 9.1081(9.6264) | Error 0.0000(0.0000) Steps 682(663.61) | Grad Norm 1.8189(3.3598) | Total Time 0.00(0.00)\n",
      "Iter 1209 | Time 60.3277(63.6804) | Bit/dim 3.5289(3.5586) | Xent 0.0000(0.0000) | Loss 8.7750(9.6008) | Error 0.0000(0.0000) Steps 652(663.26) | Grad Norm 1.3982(3.3010) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 63.9338(63.6880) | Bit/dim 3.5241(3.5576) | Xent 0.0000(0.0000) | Loss 8.9468(9.5812) | Error 0.0000(0.0000) Steps 688(664.01) | Grad Norm 1.3922(3.2437) | Total Time 0.00(0.00)\n",
      "Iter 1211 | Time 63.3824(63.6788) | Bit/dim 3.5324(3.5568) | Xent 0.0000(0.0000) | Loss 8.8946(9.5606) | Error 0.0000(0.0000) Steps 676(664.37) | Grad Norm 1.5844(3.1939) | Total Time 0.00(0.00)\n",
      "Iter 1212 | Time 70.0311(63.8694) | Bit/dim 3.5330(3.5561) | Xent 0.0000(0.0000) | Loss 9.0855(9.5464) | Error 0.0000(0.0000) Steps 694(665.26) | Grad Norm 1.6206(3.1467) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0202 | Time 25.4129, Epoch Time 436.6960(396.1658), Bit/dim 3.5263(best: 3.5364), Xent 0.0000, Loss 3.5263, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1213 | Time 59.1647(63.7282) | Bit/dim 3.5293(3.5553) | Xent 0.0000(0.0000) | Loss 13.0608(9.6518) | Error 0.0000(0.0000) Steps 652(664.86) | Grad Norm 1.4769(3.0966) | Total Time 0.00(0.00)\n",
      "Iter 1214 | Time 59.3847(63.5979) | Bit/dim 3.5302(3.5545) | Xent 0.0000(0.0000) | Loss 8.6743(9.6225) | Error 0.0000(0.0000) Steps 640(664.11) | Grad Norm 1.3317(3.0437) | Total Time 0.00(0.00)\n",
      "Iter 1215 | Time 63.4507(63.5935) | Bit/dim 3.5318(3.5539) | Xent 0.0000(0.0000) | Loss 8.9123(9.6012) | Error 0.0000(0.0000) Steps 664(664.11) | Grad Norm 1.2779(2.9907) | Total Time 0.00(0.00)\n",
      "Iter 1216 | Time 57.9606(63.4245) | Bit/dim 3.5243(3.5530) | Xent 0.0000(0.0000) | Loss 8.8235(9.5778) | Error 0.0000(0.0000) Steps 664(664.11) | Grad Norm 0.9875(2.9306) | Total Time 0.00(0.00)\n",
      "Iter 1217 | Time 65.8800(63.4982) | Bit/dim 3.5180(3.5519) | Xent 0.0000(0.0000) | Loss 8.7981(9.5544) | Error 0.0000(0.0000) Steps 676(664.46) | Grad Norm 0.9868(2.8723) | Total Time 0.00(0.00)\n",
      "Iter 1218 | Time 62.4441(63.4666) | Bit/dim 3.5245(3.5511) | Xent 0.0000(0.0000) | Loss 8.9213(9.5354) | Error 0.0000(0.0000) Steps 682(664.99) | Grad Norm 1.1806(2.8215) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0203 | Time 25.7232, Epoch Time 410.1399(396.5850), Bit/dim 3.5252(best: 3.5263), Xent 0.0000, Loss 3.5252, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1219 | Time 61.9921(63.4223) | Bit/dim 3.5169(3.5501) | Xent 0.0000(0.0000) | Loss 13.7173(9.6609) | Error 0.0000(0.0000) Steps 694(665.86) | Grad Norm 1.2414(2.7741) | Total Time 0.00(0.00)\n",
      "Iter 1220 | Time 64.6024(63.4577) | Bit/dim 3.5097(3.5489) | Xent 0.0000(0.0000) | Loss 8.9887(9.6407) | Error 0.0000(0.0000) Steps 694(666.70) | Grad Norm 1.0170(2.7214) | Total Time 0.00(0.00)\n",
      "Iter 1221 | Time 58.6147(63.3124) | Bit/dim 3.5446(3.5487) | Xent 0.0000(0.0000) | Loss 8.9402(9.6197) | Error 0.0000(0.0000) Steps 676(666.98) | Grad Norm 0.7244(2.6615) | Total Time 0.00(0.00)\n",
      "Iter 1222 | Time 65.3188(63.3726) | Bit/dim 3.5291(3.5481) | Xent 0.0000(0.0000) | Loss 8.9713(9.6003) | Error 0.0000(0.0000) Steps 676(667.25) | Grad Norm 0.8134(2.6061) | Total Time 0.00(0.00)\n",
      "Iter 1223 | Time 58.2184(63.2180) | Bit/dim 3.5186(3.5473) | Xent 0.0000(0.0000) | Loss 8.7574(9.5750) | Error 0.0000(0.0000) Steps 664(667.16) | Grad Norm 0.9338(2.5559) | Total Time 0.00(0.00)\n",
      "Iter 1224 | Time 61.7764(63.1747) | Bit/dim 3.5272(3.5467) | Xent 0.0000(0.0000) | Loss 9.0153(9.5582) | Error 0.0000(0.0000) Steps 670(667.24) | Grad Norm 0.9202(2.5068) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0204 | Time 26.0505, Epoch Time 412.6553(397.0671), Bit/dim 3.5251(best: 3.5252), Xent 0.0000, Loss 3.5251, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1225 | Time 64.2037(63.2056) | Bit/dim 3.5196(3.5458) | Xent 0.0000(0.0000) | Loss 13.7159(9.6829) | Error 0.0000(0.0000) Steps 688(667.86) | Grad Norm 0.7814(2.4551) | Total Time 0.00(0.00)\n",
      "Iter 1226 | Time 59.3097(63.0887) | Bit/dim 3.5135(3.5449) | Xent 0.0000(0.0000) | Loss 8.8653(9.6584) | Error 0.0000(0.0000) Steps 652(667.39) | Grad Norm 0.7702(2.4045) | Total Time 0.00(0.00)\n",
      "Iter 1227 | Time 61.2202(63.0327) | Bit/dim 3.5328(3.5445) | Xent 0.0000(0.0000) | Loss 8.8482(9.6341) | Error 0.0000(0.0000) Steps 664(667.29) | Grad Norm 0.7659(2.3554) | Total Time 0.00(0.00)\n",
      "Iter 1228 | Time 64.4746(63.0759) | Bit/dim 3.5124(3.5435) | Xent 0.0000(0.0000) | Loss 8.9163(9.6126) | Error 0.0000(0.0000) Steps 688(667.91) | Grad Norm 0.7986(2.3087) | Total Time 0.00(0.00)\n",
      "Iter 1229 | Time 61.3464(63.0241) | Bit/dim 3.5146(3.5427) | Xent 0.0000(0.0000) | Loss 8.9340(9.5922) | Error 0.0000(0.0000) Steps 682(668.33) | Grad Norm 0.6219(2.2581) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 62.9867(63.0229) | Bit/dim 3.5165(3.5419) | Xent 0.0000(0.0000) | Loss 8.8713(9.5706) | Error 0.0000(0.0000) Steps 688(668.92) | Grad Norm 0.6443(2.2096) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0205 | Time 25.8185, Epoch Time 415.4805(397.6195), Bit/dim 3.5203(best: 3.5251), Xent 0.0000, Loss 3.5203, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1231 | Time 63.2067(63.0284) | Bit/dim 3.5218(3.5413) | Xent 0.0000(0.0000) | Loss 13.3146(9.6829) | Error 0.0000(0.0000) Steps 682(669.31) | Grad Norm 0.8912(2.1701) | Total Time 0.00(0.00)\n",
      "Iter 1232 | Time 63.0464(63.0290) | Bit/dim 3.5188(3.5406) | Xent 0.0000(0.0000) | Loss 8.8498(9.6579) | Error 0.0000(0.0000) Steps 676(669.51) | Grad Norm 0.7438(2.1273) | Total Time 0.00(0.00)\n",
      "Iter 1233 | Time 65.8998(63.1151) | Bit/dim 3.5254(3.5402) | Xent 0.0000(0.0000) | Loss 9.0290(9.6390) | Error 0.0000(0.0000) Steps 694(670.25) | Grad Norm 0.4822(2.0779) | Total Time 0.00(0.00)\n",
      "Iter 1234 | Time 62.1516(63.0862) | Bit/dim 3.5208(3.5396) | Xent 0.0000(0.0000) | Loss 8.9508(9.6184) | Error 0.0000(0.0000) Steps 670(670.24) | Grad Norm 0.4869(2.0302) | Total Time 0.00(0.00)\n",
      "Iter 1235 | Time 64.8591(63.1394) | Bit/dim 3.5212(3.5390) | Xent 0.0000(0.0000) | Loss 8.9354(9.5979) | Error 0.0000(0.0000) Steps 706(671.31) | Grad Norm 0.6095(1.9876) | Total Time 0.00(0.00)\n",
      "Iter 1236 | Time 58.6672(63.0052) | Bit/dim 3.5157(3.5383) | Xent 0.0000(0.0000) | Loss 8.7793(9.5733) | Error 0.0000(0.0000) Steps 652(670.73) | Grad Norm 0.5771(1.9453) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0206 | Time 25.0464, Epoch Time 418.4730(398.2451), Bit/dim 3.5210(best: 3.5203), Xent 0.0000, Loss 3.5210, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1237 | Time 61.5258(62.9608) | Bit/dim 3.5260(3.5380) | Xent 0.0000(0.0000) | Loss 13.1585(9.6809) | Error 0.0000(0.0000) Steps 670(670.71) | Grad Norm 1.0518(1.9185) | Total Time 0.00(0.00)\n",
      "Iter 1238 | Time 60.7118(62.8934) | Bit/dim 3.5129(3.5372) | Xent 0.0000(0.0000) | Loss 8.6776(9.6508) | Error 0.0000(0.0000) Steps 658(670.33) | Grad Norm 0.5647(1.8779) | Total Time 0.00(0.00)\n",
      "Iter 1239 | Time 62.9731(62.8958) | Bit/dim 3.5191(3.5367) | Xent 0.0000(0.0000) | Loss 8.9022(9.6283) | Error 0.0000(0.0000) Steps 664(670.14) | Grad Norm 0.3539(1.8321) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 63.8105(62.9232) | Bit/dim 3.5189(3.5361) | Xent 0.0000(0.0000) | Loss 8.9514(9.6080) | Error 0.0000(0.0000) Steps 676(670.32) | Grad Norm 0.4387(1.7903) | Total Time 0.00(0.00)\n",
      "Iter 1241 | Time 59.6538(62.8251) | Bit/dim 3.5163(3.5355) | Xent 0.0000(0.0000) | Loss 8.6416(9.5790) | Error 0.0000(0.0000) Steps 652(669.77) | Grad Norm 0.4169(1.7491) | Total Time 0.00(0.00)\n",
      "Iter 1242 | Time 60.8395(62.7656) | Bit/dim 3.5280(3.5353) | Xent 0.0000(0.0000) | Loss 8.9621(9.5605) | Error 0.0000(0.0000) Steps 676(669.95) | Grad Norm 0.3668(1.7077) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0207 | Time 24.2208, Epoch Time 409.5014(398.5828), Bit/dim 3.5226(best: 3.5203), Xent 0.0000, Loss 3.5226, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1243 | Time 60.2915(62.6913) | Bit/dim 3.5323(3.5352) | Xent 0.0000(0.0000) | Loss 13.5451(9.6801) | Error 0.0000(0.0000) Steps 682(670.32) | Grad Norm 0.4548(1.6701) | Total Time 0.00(0.00)\n",
      "Iter 1244 | Time 61.2350(62.6476) | Bit/dim 3.5059(3.5343) | Xent 0.0000(0.0000) | Loss 8.8801(9.6561) | Error 0.0000(0.0000) Steps 688(670.85) | Grad Norm 0.3246(1.6297) | Total Time 0.00(0.00)\n",
      "Iter 1245 | Time 60.6666(62.5882) | Bit/dim 3.5250(3.5341) | Xent 0.0000(0.0000) | Loss 8.8991(9.6334) | Error 0.0000(0.0000) Steps 682(671.18) | Grad Norm 0.3180(1.5904) | Total Time 0.00(0.00)\n",
      "Iter 1246 | Time 62.3977(62.5825) | Bit/dim 3.5260(3.5338) | Xent 0.0000(0.0000) | Loss 9.0781(9.6167) | Error 0.0000(0.0000) Steps 688(671.68) | Grad Norm 0.2968(1.5516) | Total Time 0.00(0.00)\n",
      "Iter 1247 | Time 62.0124(62.5654) | Bit/dim 3.5149(3.5332) | Xent 0.0000(0.0000) | Loss 8.8304(9.5931) | Error 0.0000(0.0000) Steps 664(671.45) | Grad Norm 0.2998(1.5140) | Total Time 0.00(0.00)\n",
      "Iter 1248 | Time 61.0952(62.5213) | Bit/dim 3.5122(3.5326) | Xent 0.0000(0.0000) | Loss 8.8196(9.5699) | Error 0.0000(0.0000) Steps 658(671.05) | Grad Norm 0.3019(1.4776) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0208 | Time 24.7997, Epoch Time 408.5011(398.8804), Bit/dim 3.5178(best: 3.5203), Xent 0.0000, Loss 3.5178, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1249 | Time 56.4409(62.3389) | Bit/dim 3.5270(3.5324) | Xent 0.0000(0.0000) | Loss 12.4399(9.6560) | Error 0.0000(0.0000) Steps 652(670.48) | Grad Norm 1.0173(1.4638) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 62.5887(62.3464) | Bit/dim 3.5208(3.5321) | Xent 0.0000(0.0000) | Loss 8.7393(9.6285) | Error 0.0000(0.0000) Steps 664(670.28) | Grad Norm 0.3203(1.4295) | Total Time 0.00(0.00)\n",
      "Iter 1251 | Time 63.4213(62.3786) | Bit/dim 3.5280(3.5320) | Xent 0.0000(0.0000) | Loss 9.0317(9.6106) | Error 0.0000(0.0000) Steps 694(671.00) | Grad Norm 0.2808(1.3951) | Total Time 0.00(0.00)\n",
      "Iter 1252 | Time 64.3570(62.4380) | Bit/dim 3.5053(3.5312) | Xent 0.0000(0.0000) | Loss 8.7682(9.5853) | Error 0.0000(0.0000) Steps 664(670.79) | Grad Norm 0.2480(1.3606) | Total Time 0.00(0.00)\n",
      "Iter 1253 | Time 61.4969(62.4097) | Bit/dim 3.5170(3.5308) | Xent 0.0000(0.0000) | Loss 8.7514(9.5603) | Error 0.0000(0.0000) Steps 670(670.76) | Grad Norm 0.2662(1.3278) | Total Time 0.00(0.00)\n",
      "Iter 1254 | Time 66.7731(62.5406) | Bit/dim 3.5203(3.5304) | Xent 0.0000(0.0000) | Loss 8.7443(9.5358) | Error 0.0000(0.0000) Steps 688(671.28) | Grad Norm 0.3834(1.2995) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0209 | Time 25.0132, Epoch Time 416.1634(399.3989), Bit/dim 3.5240(best: 3.5178), Xent 0.0000, Loss 3.5240, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1255 | Time 62.5791(62.5418) | Bit/dim 3.5166(3.5300) | Xent 0.0000(0.0000) | Loss 13.0754(9.6420) | Error 0.0000(0.0000) Steps 670(671.24) | Grad Norm 0.4524(1.2741) | Total Time 0.00(0.00)\n",
      "Iter 1256 | Time 61.3170(62.5051) | Bit/dim 3.5201(3.5297) | Xent 0.0000(0.0000) | Loss 8.5562(9.6094) | Error 0.0000(0.0000) Steps 658(670.84) | Grad Norm 0.3645(1.2468) | Total Time 0.00(0.00)\n",
      "Iter 1257 | Time 64.4618(62.5638) | Bit/dim 3.5174(3.5294) | Xent 0.0000(0.0000) | Loss 8.8400(9.5864) | Error 0.0000(0.0000) Steps 676(671.00) | Grad Norm 0.3623(1.2202) | Total Time 0.00(0.00)\n",
      "Iter 1258 | Time 60.0056(62.4870) | Bit/dim 3.5186(3.5290) | Xent 0.0000(0.0000) | Loss 8.8319(9.5637) | Error 0.0000(0.0000) Steps 670(670.97) | Grad Norm 0.2616(1.1915) | Total Time 0.00(0.00)\n",
      "Iter 1259 | Time 61.1470(62.4468) | Bit/dim 3.5147(3.5286) | Xent 0.0000(0.0000) | Loss 8.8048(9.5410) | Error 0.0000(0.0000) Steps 682(671.30) | Grad Norm 0.2740(1.1640) | Total Time 0.00(0.00)\n",
      "Iter 1260 | Time 60.1425(62.3777) | Bit/dim 3.5133(3.5281) | Xent 0.0000(0.0000) | Loss 8.9411(9.5230) | Error 0.0000(0.0000) Steps 676(671.44) | Grad Norm 0.2441(1.1364) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0210 | Time 25.6860, Epoch Time 410.7726(399.7401), Bit/dim 3.5190(best: 3.5178), Xent 0.0000, Loss 3.5190, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1261 | Time 58.1267(62.2502) | Bit/dim 3.5165(3.5278) | Xent 0.0000(0.0000) | Loss 13.2671(9.6353) | Error 0.0000(0.0000) Steps 664(671.22) | Grad Norm 0.2822(1.1107) | Total Time 0.00(0.00)\n",
      "Iter 1262 | Time 61.9393(62.2408) | Bit/dim 3.5136(3.5274) | Xent 0.0000(0.0000) | Loss 9.0021(9.6163) | Error 0.0000(0.0000) Steps 670(671.18) | Grad Norm 0.2249(1.0842) | Total Time 0.00(0.00)\n",
      "Iter 1263 | Time 62.2461(62.2410) | Bit/dim 3.5277(3.5274) | Xent 0.0000(0.0000) | Loss 8.8092(9.5921) | Error 0.0000(0.0000) Steps 664(670.97) | Grad Norm 0.4643(1.0656) | Total Time 0.00(0.00)\n",
      "Iter 1264 | Time 59.9341(62.1718) | Bit/dim 3.5255(3.5273) | Xent 0.0000(0.0000) | Loss 8.8154(9.5688) | Error 0.0000(0.0000) Steps 658(670.58) | Grad Norm 0.2635(1.0415) | Total Time 0.00(0.00)\n",
      "Iter 1265 | Time 59.2598(62.0844) | Bit/dim 3.5232(3.5272) | Xent 0.0000(0.0000) | Loss 8.8631(9.5476) | Error 0.0000(0.0000) Steps 664(670.38) | Grad Norm 0.1961(1.0161) | Total Time 0.00(0.00)\n",
      "Iter 1266 | Time 63.7135(62.1333) | Bit/dim 3.5175(3.5269) | Xent 0.0000(0.0000) | Loss 8.7534(9.5238) | Error 0.0000(0.0000) Steps 676(670.55) | Grad Norm 0.3860(0.9972) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0211 | Time 25.3854, Epoch Time 406.6011(399.9459), Bit/dim 3.5187(best: 3.5178), Xent 0.0000, Loss 3.5187, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1267 | Time 62.9715(62.1584) | Bit/dim 3.5251(3.5268) | Xent 0.0000(0.0000) | Loss 13.5843(9.6456) | Error 0.0000(0.0000) Steps 664(670.35) | Grad Norm 0.2933(0.9761) | Total Time 0.00(0.00)\n",
      "Iter 1268 | Time 64.7421(62.2359) | Bit/dim 3.5190(3.5266) | Xent 0.0000(0.0000) | Loss 9.0350(9.6273) | Error 0.0000(0.0000) Steps 670(670.34) | Grad Norm 0.2211(0.9535) | Total Time 0.00(0.00)\n",
      "Iter 1269 | Time 59.6827(62.1593) | Bit/dim 3.5213(3.5265) | Xent 0.0000(0.0000) | Loss 8.9340(9.6065) | Error 0.0000(0.0000) Steps 664(670.15) | Grad Norm 0.2670(0.9329) | Total Time 0.00(0.00)\n",
      "Iter 1270 | Time 58.2056(62.0407) | Bit/dim 3.5170(3.5262) | Xent 0.0000(0.0000) | Loss 8.8639(9.5842) | Error 0.0000(0.0000) Steps 652(669.61) | Grad Norm 0.3596(0.9157) | Total Time 0.00(0.00)\n",
      "Iter 1271 | Time 62.4856(62.0541) | Bit/dim 3.5143(3.5258) | Xent 0.0000(0.0000) | Loss 8.9779(9.5660) | Error 0.0000(0.0000) Steps 682(669.98) | Grad Norm 0.1862(0.8938) | Total Time 0.00(0.00)\n",
      "Iter 1272 | Time 63.1918(62.0882) | Bit/dim 3.5132(3.5254) | Xent 0.0000(0.0000) | Loss 9.0368(9.5501) | Error 0.0000(0.0000) Steps 682(670.34) | Grad Norm 0.1868(0.8726) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0212 | Time 25.8727, Epoch Time 413.2179(400.3441), Bit/dim 3.5246(best: 3.5178), Xent 0.0000, Loss 3.5246, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1273 | Time 61.2850(62.0641) | Bit/dim 3.5107(3.5250) | Xent 0.0000(0.0000) | Loss 13.5300(9.6695) | Error 0.0000(0.0000) Steps 682(670.69) | Grad Norm 0.2832(0.8549) | Total Time 0.00(0.00)\n",
      "Iter 1274 | Time 63.0931(62.0950) | Bit/dim 3.5167(3.5247) | Xent 0.0000(0.0000) | Loss 8.7498(9.6419) | Error 0.0000(0.0000) Steps 676(670.85) | Grad Norm 0.2255(0.8360) | Total Time 0.00(0.00)\n",
      "Iter 1275 | Time 61.1604(62.0669) | Bit/dim 3.5190(3.5246) | Xent 0.0000(0.0000) | Loss 8.7875(9.6163) | Error 0.0000(0.0000) Steps 658(670.46) | Grad Norm 0.2796(0.8193) | Total Time 0.00(0.00)\n",
      "Iter 1276 | Time 60.4364(62.0180) | Bit/dim 3.5147(3.5243) | Xent 0.0000(0.0000) | Loss 8.8850(9.5944) | Error 0.0000(0.0000) Steps 664(670.27) | Grad Norm 0.1977(0.8007) | Total Time 0.00(0.00)\n",
      "Iter 1277 | Time 67.1592(62.1723) | Bit/dim 3.5283(3.5244) | Xent 0.0000(0.0000) | Loss 8.9948(9.5764) | Error 0.0000(0.0000) Steps 706(671.34) | Grad Norm 0.2417(0.7839) | Total Time 0.00(0.00)\n",
      "Iter 1278 | Time 62.8278(62.1919) | Bit/dim 3.5155(3.5241) | Xent 0.0000(0.0000) | Loss 8.8524(9.5547) | Error 0.0000(0.0000) Steps 664(671.12) | Grad Norm 0.2612(0.7682) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0213 | Time 24.5522, Epoch Time 416.1564(400.8184), Bit/dim 3.5213(best: 3.5178), Xent 0.0000, Loss 3.5213, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1279 | Time 63.1033(62.2193) | Bit/dim 3.5099(3.5237) | Xent 0.0000(0.0000) | Loss 13.3832(9.6695) | Error 0.0000(0.0000) Steps 688(671.63) | Grad Norm 0.2171(0.7517) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 65.0816(62.3051) | Bit/dim 3.5132(3.5234) | Xent 0.0000(0.0000) | Loss 8.8009(9.6435) | Error 0.0000(0.0000) Steps 676(671.76) | Grad Norm 0.2261(0.7359) | Total Time 0.00(0.00)\n",
      "Iter 1281 | Time 64.5277(62.3718) | Bit/dim 3.5160(3.5232) | Xent 0.0000(0.0000) | Loss 8.8585(9.6199) | Error 0.0000(0.0000) Steps 694(672.43) | Grad Norm 0.2356(0.7209) | Total Time 0.00(0.00)\n",
      "Iter 1282 | Time 63.5096(62.4060) | Bit/dim 3.5208(3.5231) | Xent 0.0000(0.0000) | Loss 9.0050(9.6015) | Error 0.0000(0.0000) Steps 676(672.53) | Grad Norm 0.1823(0.7048) | Total Time 0.00(0.00)\n",
      "Iter 1283 | Time 62.0705(62.3959) | Bit/dim 3.5242(3.5231) | Xent 0.0000(0.0000) | Loss 8.7811(9.5769) | Error 0.0000(0.0000) Steps 652(671.92) | Grad Norm 0.2925(0.6924) | Total Time 0.00(0.00)\n",
      "Iter 1284 | Time 62.3854(62.3956) | Bit/dim 3.5191(3.5230) | Xent 0.0000(0.0000) | Loss 8.7973(9.5535) | Error 0.0000(0.0000) Steps 670(671.86) | Grad Norm 0.2780(0.6800) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0214 | Time 25.4140, Epoch Time 421.8879(401.4505), Bit/dim 3.5184(best: 3.5178), Xent 0.0000, Loss 3.5184, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1285 | Time 65.7302(62.4956) | Bit/dim 3.5248(3.5231) | Xent 0.0000(0.0000) | Loss 13.2255(9.6636) | Error 0.0000(0.0000) Steps 694(672.52) | Grad Norm 0.2887(0.6682) | Total Time 0.00(0.00)\n",
      "Iter 1286 | Time 61.9096(62.4780) | Bit/dim 3.5186(3.5229) | Xent 0.0000(0.0000) | Loss 8.8704(9.6398) | Error 0.0000(0.0000) Steps 664(672.27) | Grad Norm 0.2074(0.6544) | Total Time 0.00(0.00)\n",
      "Iter 1287 | Time 64.1643(62.5286) | Bit/dim 3.5146(3.5227) | Xent 0.0000(0.0000) | Loss 8.9720(9.6198) | Error 0.0000(0.0000) Steps 688(672.74) | Grad Norm 0.2523(0.6423) | Total Time 0.00(0.00)\n",
      "Iter 1288 | Time 62.6232(62.5315) | Bit/dim 3.5174(3.5225) | Xent 0.0000(0.0000) | Loss 9.0101(9.6015) | Error 0.0000(0.0000) Steps 682(673.02) | Grad Norm 0.1880(0.6287) | Total Time 0.00(0.00)\n",
      "Iter 1289 | Time 58.1975(62.4014) | Bit/dim 3.5162(3.5223) | Xent 0.0000(0.0000) | Loss 8.8512(9.5790) | Error 0.0000(0.0000) Steps 670(672.93) | Grad Norm 0.2252(0.6166) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 62.0880(62.3920) | Bit/dim 3.5120(3.5220) | Xent 0.0000(0.0000) | Loss 8.6225(9.5503) | Error 0.0000(0.0000) Steps 664(672.66) | Grad Norm 0.2902(0.6068) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0215 | Time 24.9267, Epoch Time 415.3752(401.8683), Bit/dim 3.5181(best: 3.5178), Xent 0.0000, Loss 3.5181, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1291 | Time 62.8312(62.4052) | Bit/dim 3.5104(3.5217) | Xent 0.0000(0.0000) | Loss 13.2642(9.6617) | Error 0.0000(0.0000) Steps 652(672.04) | Grad Norm 0.2600(0.5964) | Total Time 0.00(0.00)\n",
      "Iter 1292 | Time 66.1149(62.5165) | Bit/dim 3.5104(3.5213) | Xent 0.0000(0.0000) | Loss 8.9994(9.6418) | Error 0.0000(0.0000) Steps 694(672.70) | Grad Norm 0.2265(0.5853) | Total Time 0.00(0.00)\n",
      "Iter 1293 | Time 64.9988(62.5910) | Bit/dim 3.5219(3.5214) | Xent 0.0000(0.0000) | Loss 8.9151(9.6200) | Error 0.0000(0.0000) Steps 694(673.34) | Grad Norm 0.2594(0.5755) | Total Time 0.00(0.00)\n",
      "Iter 1294 | Time 61.3974(62.5552) | Bit/dim 3.5118(3.5211) | Xent 0.0000(0.0000) | Loss 8.9775(9.6008) | Error 0.0000(0.0000) Steps 676(673.42) | Grad Norm 0.2039(0.5644) | Total Time 0.00(0.00)\n",
      "Iter 1295 | Time 61.5845(62.5260) | Bit/dim 3.5144(3.5209) | Xent 0.0000(0.0000) | Loss 8.5762(9.5700) | Error 0.0000(0.0000) Steps 664(673.13) | Grad Norm 0.4893(0.5621) | Total Time 0.00(0.00)\n",
      "Iter 1296 | Time 67.6264(62.6791) | Bit/dim 3.5259(3.5210) | Xent 0.0000(0.0000) | Loss 9.1004(9.5559) | Error 0.0000(0.0000) Steps 694(673.76) | Grad Norm 0.2213(0.5519) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0216 | Time 25.3244, Epoch Time 425.4613(402.5761), Bit/dim 3.5196(best: 3.5178), Xent 0.0000, Loss 3.5196, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1297 | Time 61.7353(62.6507) | Bit/dim 3.5184(3.5209) | Xent 0.0000(0.0000) | Loss 13.1287(9.6631) | Error 0.0000(0.0000) Steps 670(673.65) | Grad Norm 0.4678(0.5494) | Total Time 0.00(0.00)\n",
      "Iter 1298 | Time 63.4274(62.6740) | Bit/dim 3.5169(3.5208) | Xent 0.0000(0.0000) | Loss 8.9962(9.6431) | Error 0.0000(0.0000) Steps 688(674.08) | Grad Norm 0.1713(0.5380) | Total Time 0.00(0.00)\n",
      "Iter 1299 | Time 58.6884(62.5545) | Bit/dim 3.5202(3.5208) | Xent 0.0000(0.0000) | Loss 8.8080(9.6181) | Error 0.0000(0.0000) Steps 664(673.78) | Grad Norm 0.2784(0.5302) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 61.9837(62.5373) | Bit/dim 3.5160(3.5207) | Xent 0.0000(0.0000) | Loss 8.8243(9.5943) | Error 0.0000(0.0000) Steps 670(673.66) | Grad Norm 0.2939(0.5232) | Total Time 0.00(0.00)\n",
      "Iter 1301 | Time 63.9358(62.5793) | Bit/dim 3.5182(3.5206) | Xent 0.0000(0.0000) | Loss 8.9066(9.5736) | Error 0.0000(0.0000) Steps 676(673.73) | Grad Norm 0.2912(0.5162) | Total Time 0.00(0.00)\n",
      "Iter 1302 | Time 64.9466(62.6503) | Bit/dim 3.5290(3.5208) | Xent 0.0000(0.0000) | Loss 8.9982(9.5564) | Error 0.0000(0.0000) Steps 688(674.16) | Grad Norm 0.1949(0.5066) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0217 | Time 25.7270, Epoch Time 416.0796(402.9812), Bit/dim 3.5220(best: 3.5178), Xent 0.0000, Loss 3.5220, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1303 | Time 62.0378(62.6319) | Bit/dim 3.5198(3.5208) | Xent 0.0000(0.0000) | Loss 13.3647(9.6706) | Error 0.0000(0.0000) Steps 706(675.12) | Grad Norm 0.3980(0.5033) | Total Time 0.00(0.00)\n",
      "Iter 1304 | Time 64.6863(62.6936) | Bit/dim 3.5094(3.5205) | Xent 0.0000(0.0000) | Loss 8.8945(9.6473) | Error 0.0000(0.0000) Steps 682(675.32) | Grad Norm 0.4130(0.5006) | Total Time 0.00(0.00)\n",
      "Iter 1305 | Time 62.5379(62.6889) | Bit/dim 3.5168(3.5204) | Xent 0.0000(0.0000) | Loss 8.9141(9.6253) | Error 0.0000(0.0000) Steps 682(675.52) | Grad Norm 0.3832(0.4971) | Total Time 0.00(0.00)\n",
      "Iter 1306 | Time 58.2894(62.5569) | Bit/dim 3.5278(3.5206) | Xent 0.0000(0.0000) | Loss 8.5835(9.5941) | Error 0.0000(0.0000) Steps 652(674.82) | Grad Norm 0.2301(0.4891) | Total Time 0.00(0.00)\n",
      "Iter 1307 | Time 58.9902(62.4499) | Bit/dim 3.5222(3.5206) | Xent 0.0000(0.0000) | Loss 8.9764(9.5755) | Error 0.0000(0.0000) Steps 670(674.67) | Grad Norm 0.3483(0.4848) | Total Time 0.00(0.00)\n",
      "Iter 1308 | Time 61.5094(62.4217) | Bit/dim 3.5156(3.5205) | Xent 0.0000(0.0000) | Loss 8.8772(9.5546) | Error 0.0000(0.0000) Steps 682(674.89) | Grad Norm 0.4147(0.4827) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0218 | Time 25.3959, Epoch Time 409.4041(403.1739), Bit/dim 3.5206(best: 3.5178), Xent 0.0000, Loss 3.5206, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1309 | Time 62.2113(62.4154) | Bit/dim 3.5129(3.5202) | Xent 0.0000(0.0000) | Loss 13.5355(9.6740) | Error 0.0000(0.0000) Steps 670(674.75) | Grad Norm 0.2274(0.4751) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 61.3448(62.3833) | Bit/dim 3.5234(3.5203) | Xent 0.0000(0.0000) | Loss 8.9007(9.6508) | Error 0.0000(0.0000) Steps 676(674.78) | Grad Norm 0.2392(0.4680) | Total Time 0.00(0.00)\n",
      "Iter 1311 | Time 61.6316(62.3607) | Bit/dim 3.5245(3.5205) | Xent 0.0000(0.0000) | Loss 8.8999(9.6283) | Error 0.0000(0.0000) Steps 676(674.82) | Grad Norm 0.3006(0.4630) | Total Time 0.00(0.00)\n",
      "Iter 1312 | Time 59.9036(62.2870) | Bit/dim 3.5118(3.5202) | Xent 0.0000(0.0000) | Loss 9.0120(9.6098) | Error 0.0000(0.0000) Steps 670(674.68) | Grad Norm 0.3363(0.4592) | Total Time 0.00(0.00)\n",
      "Iter 1313 | Time 62.6435(62.2977) | Bit/dim 3.5035(3.5197) | Xent 0.0000(0.0000) | Loss 8.9960(9.5914) | Error 0.0000(0.0000) Steps 682(674.89) | Grad Norm 0.1628(0.4503) | Total Time 0.00(0.00)\n",
      "Iter 1314 | Time 63.1059(62.3219) | Bit/dim 3.5225(3.5198) | Xent 0.0000(0.0000) | Loss 8.7629(9.5665) | Error 0.0000(0.0000) Steps 688(675.29) | Grad Norm 0.3192(0.4464) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0219 | Time 25.5701, Epoch Time 412.1379(403.4428), Bit/dim 3.5148(best: 3.5178), Xent 0.0000, Loss 3.5148, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1315 | Time 64.4276(62.3851) | Bit/dim 3.5194(3.5198) | Xent 0.0000(0.0000) | Loss 13.5397(9.6857) | Error 0.0000(0.0000) Steps 694(675.85) | Grad Norm 0.3836(0.4445) | Total Time 0.00(0.00)\n",
      "Iter 1316 | Time 60.7204(62.3352) | Bit/dim 3.5202(3.5198) | Xent 0.0000(0.0000) | Loss 8.7344(9.6572) | Error 0.0000(0.0000) Steps 652(675.13) | Grad Norm 0.3296(0.4410) | Total Time 0.00(0.00)\n",
      "Iter 1317 | Time 61.4914(62.3099) | Bit/dim 3.5084(3.5194) | Xent 0.0000(0.0000) | Loss 9.0309(9.6384) | Error 0.0000(0.0000) Steps 688(675.52) | Grad Norm 0.1703(0.4329) | Total Time 0.00(0.00)\n",
      "Iter 1318 | Time 60.7913(62.2643) | Bit/dim 3.5253(3.5196) | Xent 0.0000(0.0000) | Loss 8.8482(9.6147) | Error 0.0000(0.0000) Steps 652(674.81) | Grad Norm 0.2983(0.4289) | Total Time 0.00(0.00)\n",
      "Iter 1319 | Time 65.1639(62.3513) | Bit/dim 3.5086(3.5193) | Xent 0.0000(0.0000) | Loss 8.9969(9.5962) | Error 0.0000(0.0000) Steps 694(675.39) | Grad Norm 0.2327(0.4230) | Total Time 0.00(0.00)\n",
      "Iter 1320 | Time 65.2088(62.4370) | Bit/dim 3.5163(3.5192) | Xent 0.0000(0.0000) | Loss 8.8213(9.5729) | Error 0.0000(0.0000) Steps 700(676.13) | Grad Norm 0.2644(0.4182) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0220 | Time 25.0085, Epoch Time 418.4848(403.8940), Bit/dim 3.5152(best: 3.5148), Xent 0.0000, Loss 3.5152, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1321 | Time 62.9105(62.4512) | Bit/dim 3.5194(3.5192) | Xent 0.0000(0.0000) | Loss 13.2387(9.6829) | Error 0.0000(0.0000) Steps 670(675.94) | Grad Norm 0.4188(0.4182) | Total Time 0.00(0.00)\n",
      "Iter 1322 | Time 57.6091(62.3060) | Bit/dim 3.5180(3.5192) | Xent 0.0000(0.0000) | Loss 8.6869(9.6530) | Error 0.0000(0.0000) Steps 652(675.23) | Grad Norm 0.3557(0.4164) | Total Time 0.00(0.00)\n",
      "Iter 1323 | Time 63.9575(62.3555) | Bit/dim 3.5176(3.5191) | Xent 0.0000(0.0000) | Loss 8.7398(9.6256) | Error 0.0000(0.0000) Steps 664(674.89) | Grad Norm 0.4556(0.4175) | Total Time 0.00(0.00)\n",
      "Iter 1324 | Time 57.4294(62.2077) | Bit/dim 3.5245(3.5193) | Xent 0.0000(0.0000) | Loss 8.7376(9.5990) | Error 0.0000(0.0000) Steps 664(674.56) | Grad Norm 0.4932(0.4198) | Total Time 0.00(0.00)\n",
      "Iter 1325 | Time 66.8311(62.3464) | Bit/dim 3.5233(3.5194) | Xent 0.0000(0.0000) | Loss 8.9957(9.5809) | Error 0.0000(0.0000) Steps 706(675.51) | Grad Norm 0.2735(0.4154) | Total Time 0.00(0.00)\n",
      "Iter 1326 | Time 62.2276(62.3429) | Bit/dim 3.5174(3.5193) | Xent 0.0000(0.0000) | Loss 8.6941(9.5543) | Error 0.0000(0.0000) Steps 670(675.34) | Grad Norm 0.3030(0.4120) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0221 | Time 25.4313, Epoch Time 412.1693(404.1423), Bit/dim 3.5163(best: 3.5148), Xent 0.0000, Loss 3.5163, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1327 | Time 64.3560(62.4033) | Bit/dim 3.5115(3.5191) | Xent 0.0000(0.0000) | Loss 13.5406(9.6739) | Error 0.0000(0.0000) Steps 688(675.72) | Grad Norm 0.3387(0.4098) | Total Time 0.00(0.00)\n",
      "Iter 1328 | Time 61.4149(62.3736) | Bit/dim 3.5142(3.5190) | Xent 0.0000(0.0000) | Loss 9.0756(9.6559) | Error 0.0000(0.0000) Steps 694(676.27) | Grad Norm 0.2001(0.4036) | Total Time 0.00(0.00)\n",
      "Iter 1329 | Time 67.9233(62.5401) | Bit/dim 3.5161(3.5189) | Xent 0.0000(0.0000) | Loss 8.8773(9.6326) | Error 0.0000(0.0000) Steps 688(676.62) | Grad Norm 0.2555(0.3991) | Total Time 0.00(0.00)\n",
      "Iter 1330 | Time 65.0437(62.6152) | Bit/dim 3.5126(3.5187) | Xent 0.0000(0.0000) | Loss 8.9426(9.6119) | Error 0.0000(0.0000) Steps 706(677.50) | Grad Norm 0.3090(0.3964) | Total Time 0.00(0.00)\n",
      "Iter 1331 | Time 62.9219(62.6244) | Bit/dim 3.5116(3.5185) | Xent 0.0000(0.0000) | Loss 9.0868(9.5961) | Error 0.0000(0.0000) Steps 688(677.82) | Grad Norm 0.1851(0.3901) | Total Time 0.00(0.00)\n",
      "Iter 1332 | Time 64.8718(62.6918) | Bit/dim 3.5187(3.5185) | Xent 0.0000(0.0000) | Loss 9.0065(9.5784) | Error 0.0000(0.0000) Steps 700(678.48) | Grad Norm 0.2234(0.3851) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0222 | Time 25.2828, Epoch Time 427.4748(404.8423), Bit/dim 3.5179(best: 3.5148), Xent 0.0000, Loss 3.5179, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1333 | Time 62.4574(62.6848) | Bit/dim 3.5093(3.5182) | Xent 0.0000(0.0000) | Loss 13.0729(9.6833) | Error 0.0000(0.0000) Steps 676(678.41) | Grad Norm 0.3062(0.3827) | Total Time 0.00(0.00)\n",
      "Iter 1334 | Time 60.8524(62.6298) | Bit/dim 3.5163(3.5182) | Xent 0.0000(0.0000) | Loss 8.8467(9.6582) | Error 0.0000(0.0000) Steps 670(678.16) | Grad Norm 0.2097(0.3775) | Total Time 0.00(0.00)\n",
      "Iter 1335 | Time 63.4651(62.6549) | Bit/dim 3.5155(3.5181) | Xent 0.0000(0.0000) | Loss 9.0197(9.6390) | Error 0.0000(0.0000) Steps 694(678.63) | Grad Norm 0.2282(0.3730) | Total Time 0.00(0.00)\n",
      "Iter 1336 | Time 62.7144(62.6567) | Bit/dim 3.5238(3.5182) | Xent 0.0000(0.0000) | Loss 8.8376(9.6150) | Error 0.0000(0.0000) Steps 682(678.73) | Grad Norm 0.2850(0.3704) | Total Time 0.00(0.00)\n",
      "Iter 1337 | Time 64.2086(62.7032) | Bit/dim 3.5112(3.5180) | Xent 0.0000(0.0000) | Loss 9.0283(9.5974) | Error 0.0000(0.0000) Steps 694(679.19) | Grad Norm 0.2527(0.3669) | Total Time 0.00(0.00)\n",
      "Iter 1338 | Time 60.9787(62.6515) | Bit/dim 3.5213(3.5181) | Xent 0.0000(0.0000) | Loss 9.0864(9.5820) | Error 0.0000(0.0000) Steps 688(679.45) | Grad Norm 0.1681(0.3609) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0223 | Time 25.7245, Epoch Time 416.0708(405.1791), Bit/dim 3.5149(best: 3.5148), Xent 0.0000, Loss 3.5149, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1339 | Time 60.4728(62.5861) | Bit/dim 3.5148(3.5180) | Xent 0.0000(0.0000) | Loss 13.5905(9.7023) | Error 0.0000(0.0000) Steps 676(679.35) | Grad Norm 0.2654(0.3580) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 61.6396(62.5577) | Bit/dim 3.5283(3.5183) | Xent 0.0000(0.0000) | Loss 8.9327(9.6792) | Error 0.0000(0.0000) Steps 670(679.07) | Grad Norm 0.2767(0.3556) | Total Time 0.00(0.00)\n",
      "Iter 1341 | Time 61.9106(62.5383) | Bit/dim 3.4999(3.5178) | Xent 0.0000(0.0000) | Loss 9.0495(9.6603) | Error 0.0000(0.0000) Steps 682(679.16) | Grad Norm 0.2080(0.3512) | Total Time 0.00(0.00)\n",
      "Iter 1342 | Time 63.6492(62.5716) | Bit/dim 3.5160(3.5177) | Xent 0.0000(0.0000) | Loss 8.9367(9.6386) | Error 0.0000(0.0000) Steps 700(679.78) | Grad Norm 0.2136(0.3470) | Total Time 0.00(0.00)\n",
      "Iter 1343 | Time 63.7832(62.6080) | Bit/dim 3.5100(3.5175) | Xent 0.0000(0.0000) | Loss 8.8756(9.6157) | Error 0.0000(0.0000) Steps 688(680.03) | Grad Norm 0.3480(0.3471) | Total Time 0.00(0.00)\n",
      "Iter 1344 | Time 57.9643(62.4687) | Bit/dim 3.5120(3.5173) | Xent 0.0000(0.0000) | Loss 8.8879(9.5939) | Error 0.0000(0.0000) Steps 670(679.73) | Grad Norm 0.2662(0.3446) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0224 | Time 25.2388, Epoch Time 410.3515(405.3343), Bit/dim 3.5122(best: 3.5148), Xent 0.0000, Loss 3.5122, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1345 | Time 60.6569(62.4143) | Bit/dim 3.5174(3.5173) | Xent 0.0000(0.0000) | Loss 12.9915(9.6958) | Error 0.0000(0.0000) Steps 670(679.44) | Grad Norm 0.2434(0.3416) | Total Time 0.00(0.00)\n",
      "Iter 1346 | Time 66.9050(62.5490) | Bit/dim 3.5064(3.5170) | Xent 0.0000(0.0000) | Loss 8.8567(9.6706) | Error 0.0000(0.0000) Steps 694(679.87) | Grad Norm 0.2317(0.3383) | Total Time 0.00(0.00)\n",
      "Iter 1347 | Time 60.8533(62.4982) | Bit/dim 3.5183(3.5170) | Xent 0.0000(0.0000) | Loss 8.9797(9.6499) | Error 0.0000(0.0000) Steps 676(679.76) | Grad Norm 0.1832(0.3337) | Total Time 0.00(0.00)\n",
      "Iter 1348 | Time 62.4172(62.4957) | Bit/dim 3.5137(3.5169) | Xent 0.0000(0.0000) | Loss 8.7471(9.6228) | Error 0.0000(0.0000) Steps 670(679.47) | Grad Norm 0.2544(0.3313) | Total Time 0.00(0.00)\n",
      "Iter 1349 | Time 60.9811(62.4503) | Bit/dim 3.5243(3.5172) | Xent 0.0000(0.0000) | Loss 8.9498(9.6026) | Error 0.0000(0.0000) Steps 676(679.36) | Grad Norm 0.2385(0.3285) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 64.0351(62.4978) | Bit/dim 3.5140(3.5171) | Xent 0.0000(0.0000) | Loss 8.8065(9.5787) | Error 0.0000(0.0000) Steps 688(679.62) | Grad Norm 0.3333(0.3286) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0225 | Time 25.7804, Epoch Time 417.3928(405.6961), Bit/dim 3.5150(best: 3.5122), Xent 0.0000, Loss 3.5150, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1351 | Time 59.6790(62.4133) | Bit/dim 3.5123(3.5169) | Xent 0.0000(0.0000) | Loss 13.1990(9.6874) | Error 0.0000(0.0000) Steps 682(679.69) | Grad Norm 0.2935(0.3276) | Total Time 0.00(0.00)\n",
      "Iter 1352 | Time 59.1111(62.3142) | Bit/dim 3.5093(3.5167) | Xent 0.0000(0.0000) | Loss 8.9453(9.6651) | Error 0.0000(0.0000) Steps 682(679.76) | Grad Norm 0.2645(0.3257) | Total Time 0.00(0.00)\n",
      "Iter 1353 | Time 61.0651(62.2767) | Bit/dim 3.5175(3.5167) | Xent 0.0000(0.0000) | Loss 8.8227(9.6398) | Error 0.0000(0.0000) Steps 670(679.47) | Grad Norm 0.3755(0.3272) | Total Time 0.00(0.00)\n",
      "Iter 1354 | Time 66.4782(62.4028) | Bit/dim 3.5209(3.5169) | Xent 0.0000(0.0000) | Loss 8.9891(9.6203) | Error 0.0000(0.0000) Steps 694(679.90) | Grad Norm 0.2451(0.3247) | Total Time 0.00(0.00)\n",
      "Iter 1355 | Time 59.1953(62.3066) | Bit/dim 3.5089(3.5166) | Xent 0.0000(0.0000) | Loss 8.8844(9.5982) | Error 0.0000(0.0000) Steps 664(679.43) | Grad Norm 0.2433(0.3223) | Total Time 0.00(0.00)\n",
      "Iter 1356 | Time 62.1215(62.3010) | Bit/dim 3.5206(3.5167) | Xent 0.0000(0.0000) | Loss 8.9309(9.5782) | Error 0.0000(0.0000) Steps 676(679.32) | Grad Norm 0.3340(0.3226) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0226 | Time 25.5392, Epoch Time 408.8951(405.7920), Bit/dim 3.5145(best: 3.5122), Xent 0.0000, Loss 3.5145, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1357 | Time 61.1209(62.2656) | Bit/dim 3.5090(3.5165) | Xent 0.0000(0.0000) | Loss 13.1514(9.6854) | Error 0.0000(0.0000) Steps 670(679.04) | Grad Norm 0.6133(0.3313) | Total Time 0.00(0.00)\n",
      "Iter 1358 | Time 63.1967(62.2935) | Bit/dim 3.5190(3.5166) | Xent 0.0000(0.0000) | Loss 9.0696(9.6669) | Error 0.0000(0.0000) Steps 676(678.95) | Grad Norm 0.2910(0.3301) | Total Time 0.00(0.00)\n",
      "Iter 1359 | Time 64.8941(62.3716) | Bit/dim 3.5122(3.5164) | Xent 0.0000(0.0000) | Loss 8.8833(9.6434) | Error 0.0000(0.0000) Steps 694(679.40) | Grad Norm 0.3772(0.3315) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 65.1849(62.4560) | Bit/dim 3.5106(3.5163) | Xent 0.0000(0.0000) | Loss 8.9599(9.6229) | Error 0.0000(0.0000) Steps 688(679.66) | Grad Norm 0.4042(0.3337) | Total Time 0.00(0.00)\n",
      "Iter 1361 | Time 62.3969(62.4542) | Bit/dim 3.5115(3.5161) | Xent 0.0000(0.0000) | Loss 9.0100(9.6045) | Error 0.0000(0.0000) Steps 682(679.73) | Grad Norm 0.4285(0.3366) | Total Time 0.00(0.00)\n",
      "Iter 1362 | Time 64.0357(62.5016) | Bit/dim 3.5169(3.5161) | Xent 0.0000(0.0000) | Loss 9.0086(9.5866) | Error 0.0000(0.0000) Steps 700(680.34) | Grad Norm 0.2588(0.3342) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0227 | Time 25.2928, Epoch Time 421.6224(406.2669), Bit/dim 3.5213(best: 3.5122), Xent 0.0000, Loss 3.5213, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1363 | Time 64.1851(62.5521) | Bit/dim 3.5067(3.5159) | Xent 0.0000(0.0000) | Loss 13.5068(9.7043) | Error 0.0000(0.0000) Steps 688(680.57) | Grad Norm 0.3886(0.3359) | Total Time 0.00(0.00)\n",
      "Iter 1364 | Time 63.3073(62.5748) | Bit/dim 3.5233(3.5161) | Xent 0.0000(0.0000) | Loss 8.9341(9.6811) | Error 0.0000(0.0000) Steps 694(680.97) | Grad Norm 0.3578(0.3365) | Total Time 0.00(0.00)\n",
      "Iter 1365 | Time 63.8458(62.6129) | Bit/dim 3.5228(3.5163) | Xent 0.0000(0.0000) | Loss 8.7360(9.6528) | Error 0.0000(0.0000) Steps 664(680.46) | Grad Norm 0.2945(0.3353) | Total Time 0.00(0.00)\n",
      "Iter 1366 | Time 67.4724(62.7587) | Bit/dim 3.5019(3.5159) | Xent 0.0000(0.0000) | Loss 8.7550(9.6259) | Error 0.0000(0.0000) Steps 694(680.87) | Grad Norm 0.2311(0.3321) | Total Time 0.00(0.00)\n",
      "Iter 1367 | Time 60.2376(62.6831) | Bit/dim 3.5140(3.5158) | Xent 0.0000(0.0000) | Loss 8.8840(9.6036) | Error 0.0000(0.0000) Steps 676(680.72) | Grad Norm 0.3342(0.3322) | Total Time 0.00(0.00)\n",
      "Iter 1368 | Time 60.0164(62.6031) | Bit/dim 3.5186(3.5159) | Xent 0.0000(0.0000) | Loss 8.7393(9.5777) | Error 0.0000(0.0000) Steps 658(680.04) | Grad Norm 0.3389(0.3324) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0228 | Time 26.1802, Epoch Time 420.9330(406.7069), Bit/dim 3.5175(best: 3.5122), Xent 0.0000, Loss 3.5175, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1369 | Time 63.9973(62.6449) | Bit/dim 3.5174(3.5159) | Xent 0.0000(0.0000) | Loss 13.4689(9.6944) | Error 0.0000(0.0000) Steps 676(679.92) | Grad Norm 0.2634(0.3303) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 68.2026(62.8116) | Bit/dim 3.5129(3.5158) | Xent 0.0000(0.0000) | Loss 8.8794(9.6700) | Error 0.0000(0.0000) Steps 676(679.80) | Grad Norm 0.3405(0.3306) | Total Time 0.00(0.00)\n",
      "Iter 1371 | Time 65.9822(62.9067) | Bit/dim 3.5143(3.5158) | Xent 0.0000(0.0000) | Loss 9.0646(9.6518) | Error 0.0000(0.0000) Steps 694(680.23) | Grad Norm 0.2989(0.3297) | Total Time 0.00(0.00)\n",
      "Iter 1372 | Time 64.7204(62.9611) | Bit/dim 3.5026(3.5154) | Xent 0.0000(0.0000) | Loss 9.0019(9.6323) | Error 0.0000(0.0000) Steps 700(680.82) | Grad Norm 0.2540(0.3274) | Total Time 0.00(0.00)\n",
      "Iter 1373 | Time 61.2168(62.9088) | Bit/dim 3.5143(3.5154) | Xent 0.0000(0.0000) | Loss 8.9874(9.6130) | Error 0.0000(0.0000) Steps 670(680.50) | Grad Norm 0.3447(0.3279) | Total Time 0.00(0.00)\n",
      "Iter 1374 | Time 64.1763(62.9468) | Bit/dim 3.5112(3.5152) | Xent 0.0000(0.0000) | Loss 8.8956(9.5914) | Error 0.0000(0.0000) Steps 670(680.18) | Grad Norm 0.3998(0.3301) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0229 | Time 25.7731, Epoch Time 429.9910(407.4054), Bit/dim 3.5112(best: 3.5122), Xent 0.0000, Loss 3.5112, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1375 | Time 63.7403(62.9706) | Bit/dim 3.5149(3.5152) | Xent 0.0000(0.0000) | Loss 13.3833(9.7052) | Error 0.0000(0.0000) Steps 688(680.42) | Grad Norm 0.3756(0.3315) | Total Time 0.00(0.00)\n",
      "Iter 1376 | Time 63.9093(62.9988) | Bit/dim 3.5083(3.5150) | Xent 0.0000(0.0000) | Loss 8.9337(9.6820) | Error 0.0000(0.0000) Steps 694(680.82) | Grad Norm 0.3044(0.3306) | Total Time 0.00(0.00)\n",
      "Iter 1377 | Time 63.5896(63.0165) | Bit/dim 3.5206(3.5152) | Xent 0.0000(0.0000) | Loss 8.7824(9.6551) | Error 0.0000(0.0000) Steps 688(681.04) | Grad Norm 0.3393(0.3309) | Total Time 0.00(0.00)\n",
      "Iter 1378 | Time 63.9941(63.0459) | Bit/dim 3.5137(3.5151) | Xent 0.0000(0.0000) | Loss 8.6003(9.6234) | Error 0.0000(0.0000) Steps 700(681.61) | Grad Norm 0.5629(0.3379) | Total Time 0.00(0.00)\n",
      "Iter 1379 | Time 62.8201(63.0391) | Bit/dim 3.5142(3.5151) | Xent 0.0000(0.0000) | Loss 8.9848(9.6043) | Error 0.0000(0.0000) Steps 676(681.44) | Grad Norm 0.3434(0.3380) | Total Time 0.00(0.00)\n",
      "Iter 1380 | Time 60.5804(62.9653) | Bit/dim 3.5128(3.5150) | Xent 0.0000(0.0000) | Loss 8.8683(9.5822) | Error 0.0000(0.0000) Steps 670(681.10) | Grad Norm 0.3057(0.3371) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0230 | Time 24.6329, Epoch Time 419.1967(407.7592), Bit/dim 3.5213(best: 3.5112), Xent 0.0000, Loss 3.5213, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1381 | Time 64.3402(63.0066) | Bit/dim 3.5128(3.5150) | Xent 0.0000(0.0000) | Loss 13.1267(9.6885) | Error 0.0000(0.0000) Steps 682(681.12) | Grad Norm 0.5378(0.3431) | Total Time 0.00(0.00)\n",
      "Iter 1382 | Time 65.0526(63.0680) | Bit/dim 3.5110(3.5149) | Xent 0.0000(0.0000) | Loss 8.9146(9.6653) | Error 0.0000(0.0000) Steps 688(681.33) | Grad Norm 0.3069(0.3420) | Total Time 0.00(0.00)\n",
      "Iter 1383 | Time 62.7085(63.0572) | Bit/dim 3.5221(3.5151) | Xent 0.0000(0.0000) | Loss 8.9315(9.6433) | Error 0.0000(0.0000) Steps 700(681.89) | Grad Norm 0.4148(0.3442) | Total Time 0.00(0.00)\n",
      "Iter 1384 | Time 60.2745(62.9737) | Bit/dim 3.5079(3.5149) | Xent 0.0000(0.0000) | Loss 8.7218(9.6156) | Error 0.0000(0.0000) Steps 670(681.53) | Grad Norm 0.2828(0.3423) | Total Time 0.00(0.00)\n",
      "Iter 1385 | Time 63.0073(62.9747) | Bit/dim 3.5185(3.5150) | Xent 0.0000(0.0000) | Loss 8.9087(9.5944) | Error 0.0000(0.0000) Steps 676(681.37) | Grad Norm 0.2673(0.3401) | Total Time 0.00(0.00)\n",
      "Iter 1386 | Time 63.1712(62.9806) | Bit/dim 3.5173(3.5150) | Xent 0.0000(0.0000) | Loss 9.0306(9.5775) | Error 0.0000(0.0000) Steps 694(681.75) | Grad Norm 0.3269(0.3397) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0231 | Time 25.0665, Epoch Time 419.1825(408.1019), Bit/dim 3.5178(best: 3.5112), Xent 0.0000, Loss 3.5178, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1387 | Time 63.9383(63.0093) | Bit/dim 3.5150(3.5150) | Xent 0.0000(0.0000) | Loss 13.5211(9.6958) | Error 0.0000(0.0000) Steps 670(681.39) | Grad Norm 0.4042(0.3416) | Total Time 0.00(0.00)\n",
      "Iter 1388 | Time 63.9660(63.0380) | Bit/dim 3.5175(3.5151) | Xent 0.0000(0.0000) | Loss 8.9209(9.6726) | Error 0.0000(0.0000) Steps 694(681.77) | Grad Norm 0.3269(0.3412) | Total Time 0.00(0.00)\n",
      "Iter 1389 | Time 59.9843(62.9464) | Bit/dim 3.5181(3.5152) | Xent 0.0000(0.0000) | Loss 8.7258(9.6442) | Error 0.0000(0.0000) Steps 670(681.42) | Grad Norm 0.4239(0.3437) | Total Time 0.00(0.00)\n",
      "Iter 1390 | Time 66.3186(63.0476) | Bit/dim 3.4938(3.5146) | Xent 0.0000(0.0000) | Loss 8.6234(9.6135) | Error 0.0000(0.0000) Steps 712(682.34) | Grad Norm 0.3624(0.3442) | Total Time 0.00(0.00)\n",
      "Iter 1391 | Time 70.8389(63.2813) | Bit/dim 3.5107(3.5144) | Xent 0.0000(0.0000) | Loss 8.9327(9.5931) | Error 0.0000(0.0000) Steps 712(683.23) | Grad Norm 0.3117(0.3433) | Total Time 0.00(0.00)\n",
      "Iter 1392 | Time 61.9231(63.2406) | Bit/dim 3.5286(3.5149) | Xent 0.0000(0.0000) | Loss 9.0538(9.5769) | Error 0.0000(0.0000) Steps 694(683.55) | Grad Norm 0.3325(0.3429) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0232 | Time 26.0458, Epoch Time 428.6474(408.7182), Bit/dim 3.5091(best: 3.5112), Xent 0.0000, Loss 3.5091, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1393 | Time 59.7492(63.1358) | Bit/dim 3.5162(3.5149) | Xent 0.0000(0.0000) | Loss 13.6650(9.6996) | Error 0.0000(0.0000) Steps 676(683.32) | Grad Norm 0.2579(0.3404) | Total Time 0.00(0.00)\n",
      "Iter 1394 | Time 59.8288(63.0366) | Bit/dim 3.5117(3.5148) | Xent 0.0000(0.0000) | Loss 8.9722(9.6778) | Error 0.0000(0.0000) Steps 688(683.46) | Grad Norm 0.2100(0.3365) | Total Time 0.00(0.00)\n",
      "Iter 1395 | Time 62.1880(63.0112) | Bit/dim 3.5236(3.5151) | Xent 0.0000(0.0000) | Loss 8.8688(9.6535) | Error 0.0000(0.0000) Steps 670(683.06) | Grad Norm 0.3599(0.3372) | Total Time 0.00(0.00)\n",
      "Iter 1396 | Time 61.9509(62.9793) | Bit/dim 3.5304(3.5155) | Xent 0.0000(0.0000) | Loss 8.6946(9.6247) | Error 0.0000(0.0000) Steps 664(682.49) | Grad Norm 0.4269(0.3399) | Total Time 0.00(0.00)\n",
      "Iter 1397 | Time 57.7435(62.8223) | Bit/dim 3.5073(3.5153) | Xent 0.0000(0.0000) | Loss 8.8780(9.6023) | Error 0.0000(0.0000) Steps 670(682.11) | Grad Norm 0.2225(0.3363) | Total Time 0.00(0.00)\n",
      "Iter 1398 | Time 60.2343(62.7446) | Bit/dim 3.5066(3.5150) | Xent 0.0000(0.0000) | Loss 8.7810(9.5777) | Error 0.0000(0.0000) Steps 670(681.75) | Grad Norm 0.2296(0.3331) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0233 | Time 25.1733, Epoch Time 402.7153(408.5382), Bit/dim 3.5179(best: 3.5091), Xent 0.0000, Loss 3.5179, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1399 | Time 67.4169(62.8848) | Bit/dim 3.5105(3.5149) | Xent 0.0000(0.0000) | Loss 12.5453(9.6667) | Error 0.0000(0.0000) Steps 664(681.22) | Grad Norm 0.7583(0.3459) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 63.4264(62.9010) | Bit/dim 3.5080(3.5147) | Xent 0.0000(0.0000) | Loss 8.8934(9.6435) | Error 0.0000(0.0000) Steps 694(681.60) | Grad Norm 0.3277(0.3453) | Total Time 0.00(0.00)\n",
      "Iter 1401 | Time 64.6365(62.9531) | Bit/dim 3.5169(3.5147) | Xent 0.0000(0.0000) | Loss 8.7373(9.6163) | Error 0.0000(0.0000) Steps 670(681.25) | Grad Norm 0.4655(0.3489) | Total Time 0.00(0.00)\n",
      "Iter 1402 | Time 61.6617(62.9144) | Bit/dim 3.5035(3.5144) | Xent 0.0000(0.0000) | Loss 8.8963(9.5947) | Error 0.0000(0.0000) Steps 664(680.74) | Grad Norm 0.2439(0.3458) | Total Time 0.00(0.00)\n",
      "Iter 1403 | Time 60.5810(62.8444) | Bit/dim 3.5212(3.5146) | Xent 0.0000(0.0000) | Loss 8.7365(9.5690) | Error 0.0000(0.0000) Steps 682(680.77) | Grad Norm 0.3869(0.3470) | Total Time 0.00(0.00)\n",
      "Iter 1404 | Time 60.1580(62.7638) | Bit/dim 3.5269(3.5150) | Xent 0.0000(0.0000) | Loss 8.9521(9.5505) | Error 0.0000(0.0000) Steps 670(680.45) | Grad Norm 0.3878(0.3483) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0234 | Time 25.8976, Epoch Time 419.5104(408.8673), Bit/dim 3.5203(best: 3.5091), Xent 0.0000, Loss 3.5203, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1405 | Time 60.4636(62.6948) | Bit/dim 3.5066(3.5147) | Xent 0.0000(0.0000) | Loss 13.2065(9.6601) | Error 0.0000(0.0000) Steps 652(679.60) | Grad Norm 0.4358(0.3509) | Total Time 0.00(0.00)\n",
      "Iter 1406 | Time 60.8025(62.6380) | Bit/dim 3.5146(3.5147) | Xent 0.0000(0.0000) | Loss 8.9086(9.6376) | Error 0.0000(0.0000) Steps 682(679.67) | Grad Norm 0.2227(0.3470) | Total Time 0.00(0.00)\n",
      "Iter 1407 | Time 58.5525(62.5154) | Bit/dim 3.5059(3.5145) | Xent 0.0000(0.0000) | Loss 8.7414(9.6107) | Error 0.0000(0.0000) Steps 664(679.20) | Grad Norm 0.2198(0.3432) | Total Time 0.00(0.00)\n",
      "Iter 1408 | Time 62.5923(62.5177) | Bit/dim 3.5260(3.5148) | Xent 0.0000(0.0000) | Loss 8.7184(9.5839) | Error 0.0000(0.0000) Steps 664(678.74) | Grad Norm 0.2875(0.3415) | Total Time 0.00(0.00)\n",
      "Iter 1409 | Time 58.2706(62.3903) | Bit/dim 3.5089(3.5146) | Xent 0.0000(0.0000) | Loss 8.7741(9.5597) | Error 0.0000(0.0000) Steps 664(678.30) | Grad Norm 0.2740(0.3395) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 60.9032(62.3457) | Bit/dim 3.5103(3.5145) | Xent 0.0000(0.0000) | Loss 8.8067(9.5371) | Error 0.0000(0.0000) Steps 682(678.41) | Grad Norm 0.2646(0.3373) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0235 | Time 25.5437, Epoch Time 402.8778(408.6876), Bit/dim 3.5163(best: 3.5091), Xent 0.0000, Loss 3.5163, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1411 | Time 60.4534(62.2889) | Bit/dim 3.5060(3.5142) | Xent 0.0000(0.0000) | Loss 13.8711(9.6671) | Error 0.0000(0.0000) Steps 676(678.34) | Grad Norm 0.2972(0.3361) | Total Time 0.00(0.00)\n",
      "Iter 1412 | Time 63.6365(62.3294) | Bit/dim 3.5082(3.5141) | Xent 0.0000(0.0000) | Loss 8.9871(9.6467) | Error 0.0000(0.0000) Steps 670(678.09) | Grad Norm 0.2297(0.3329) | Total Time 0.00(0.00)\n",
      "Iter 1413 | Time 60.4579(62.2732) | Bit/dim 3.5175(3.5142) | Xent 0.0000(0.0000) | Loss 8.9047(9.6244) | Error 0.0000(0.0000) Steps 670(677.85) | Grad Norm 0.2262(0.3297) | Total Time 0.00(0.00)\n",
      "Iter 1414 | Time 66.2148(62.3915) | Bit/dim 3.5138(3.5142) | Xent 0.0000(0.0000) | Loss 9.0902(9.6084) | Error 0.0000(0.0000) Steps 694(678.33) | Grad Norm 0.2116(0.3261) | Total Time 0.00(0.00)\n",
      "Iter 1415 | Time 62.6581(62.3995) | Bit/dim 3.5250(3.5145) | Xent 0.0000(0.0000) | Loss 9.0328(9.5911) | Error 0.0000(0.0000) Steps 682(678.44) | Grad Norm 0.2317(0.3233) | Total Time 0.00(0.00)\n",
      "Iter 1416 | Time 59.5894(62.3152) | Bit/dim 3.5090(3.5143) | Xent 0.0000(0.0000) | Loss 9.0521(9.5750) | Error 0.0000(0.0000) Steps 676(678.37) | Grad Norm 0.2057(0.3198) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0236 | Time 25.0160, Epoch Time 413.7768(408.8403), Bit/dim 3.5168(best: 3.5091), Xent 0.0000, Loss 3.5168, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1417 | Time 66.5598(62.4425) | Bit/dim 3.5111(3.5142) | Xent 0.0000(0.0000) | Loss 13.3251(9.6875) | Error 0.0000(0.0000) Steps 682(678.48) | Grad Norm 0.2893(0.3189) | Total Time 0.00(0.00)\n",
      "Iter 1418 | Time 65.2080(62.5255) | Bit/dim 3.5193(3.5144) | Xent 0.0000(0.0000) | Loss 8.9641(9.6658) | Error 0.0000(0.0000) Steps 676(678.40) | Grad Norm 0.2252(0.3160) | Total Time 0.00(0.00)\n",
      "Iter 1419 | Time 66.2694(62.6378) | Bit/dim 3.5179(3.5145) | Xent 0.0000(0.0000) | Loss 8.8653(9.6417) | Error 0.0000(0.0000) Steps 688(678.69) | Grad Norm 0.2516(0.3141) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 65.0860(62.7112) | Bit/dim 3.5118(3.5144) | Xent 0.0000(0.0000) | Loss 9.0151(9.6229) | Error 0.0000(0.0000) Steps 712(679.69) | Grad Norm 0.1982(0.3106) | Total Time 0.00(0.00)\n",
      "Iter 1421 | Time 66.6364(62.8290) | Bit/dim 3.5107(3.5143) | Xent 0.0000(0.0000) | Loss 9.0862(9.6068) | Error 0.0000(0.0000) Steps 712(680.66) | Grad Norm 0.2430(0.3086) | Total Time 0.00(0.00)\n",
      "Iter 1422 | Time 59.2212(62.7208) | Bit/dim 3.5124(3.5142) | Xent 0.0000(0.0000) | Loss 8.6748(9.5789) | Error 0.0000(0.0000) Steps 652(679.80) | Grad Norm 0.3941(0.3112) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0237 | Time 25.4939, Epoch Time 430.2461(409.4825), Bit/dim 3.5148(best: 3.5091), Xent 0.0000, Loss 3.5148, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1423 | Time 60.4836(62.6537) | Bit/dim 3.5217(3.5144) | Xent 0.0000(0.0000) | Loss 13.3973(9.6934) | Error 0.0000(0.0000) Steps 658(679.15) | Grad Norm 0.4106(0.3142) | Total Time 0.00(0.00)\n",
      "Iter 1424 | Time 65.1270(62.7279) | Bit/dim 3.5066(3.5142) | Xent 0.0000(0.0000) | Loss 8.7963(9.6665) | Error 0.0000(0.0000) Steps 670(678.87) | Grad Norm 0.4046(0.3169) | Total Time 0.00(0.00)\n",
      "Iter 1425 | Time 66.6123(62.8444) | Bit/dim 3.5164(3.5143) | Xent 0.0000(0.0000) | Loss 8.9165(9.6440) | Error 0.0000(0.0000) Steps 682(678.96) | Grad Norm 0.2826(0.3158) | Total Time 0.00(0.00)\n",
      "Iter 1426 | Time 68.1624(63.0039) | Bit/dim 3.5088(3.5141) | Xent 0.0000(0.0000) | Loss 8.8441(9.6200) | Error 0.0000(0.0000) Steps 670(678.70) | Grad Norm 0.2689(0.3144) | Total Time 0.00(0.00)\n",
      "Iter 1427 | Time 61.2794(62.9522) | Bit/dim 3.5183(3.5142) | Xent 0.0000(0.0000) | Loss 8.9067(9.5986) | Error 0.0000(0.0000) Steps 676(678.61) | Grad Norm 0.2849(0.3135) | Total Time 0.00(0.00)\n",
      "Iter 1428 | Time 62.4037(62.9357) | Bit/dim 3.5137(3.5142) | Xent 0.0000(0.0000) | Loss 8.7940(9.5745) | Error 0.0000(0.0000) Steps 676(678.54) | Grad Norm 0.2567(0.3118) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0238 | Time 25.6015, Epoch Time 425.4375(409.9611), Bit/dim 3.5166(best: 3.5091), Xent 0.0000, Loss 3.5166, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1429 | Time 64.4098(62.9800) | Bit/dim 3.5098(3.5141) | Xent 0.0000(0.0000) | Loss 13.3481(9.6877) | Error 0.0000(0.0000) Steps 694(679.00) | Grad Norm 0.3839(0.3140) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 61.3639(62.9315) | Bit/dim 3.5177(3.5142) | Xent 0.0000(0.0000) | Loss 8.6632(9.6570) | Error 0.0000(0.0000) Steps 682(679.09) | Grad Norm 0.3608(0.3154) | Total Time 0.00(0.00)\n",
      "Iter 1431 | Time 65.3253(63.0033) | Bit/dim 3.5162(3.5143) | Xent 0.0000(0.0000) | Loss 8.8440(9.6326) | Error 0.0000(0.0000) Steps 670(678.82) | Grad Norm 0.5003(0.3209) | Total Time 0.00(0.00)\n",
      "Iter 1432 | Time 63.1785(63.0085) | Bit/dim 3.5212(3.5145) | Xent 0.0000(0.0000) | Loss 8.9966(9.6135) | Error 0.0000(0.0000) Steps 670(678.55) | Grad Norm 0.3458(0.3217) | Total Time 0.00(0.00)\n",
      "Iter 1433 | Time 61.4329(62.9613) | Bit/dim 3.5219(3.5147) | Xent 0.0000(0.0000) | Loss 8.7543(9.5877) | Error 0.0000(0.0000) Steps 658(677.94) | Grad Norm 0.4717(0.3262) | Total Time 0.00(0.00)\n",
      "Iter 1434 | Time 63.9631(62.9913) | Bit/dim 3.5045(3.5144) | Xent 0.0000(0.0000) | Loss 8.8319(9.5650) | Error 0.0000(0.0000) Steps 664(677.52) | Grad Norm 0.2656(0.3244) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0239 | Time 25.2040, Epoch Time 420.6002(410.2803), Bit/dim 3.5108(best: 3.5091), Xent 0.0000, Loss 3.5108, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1435 | Time 65.0864(63.0542) | Bit/dim 3.5176(3.5145) | Xent 0.0000(0.0000) | Loss 13.6799(9.6885) | Error 0.0000(0.0000) Steps 694(678.01) | Grad Norm 0.3241(0.3244) | Total Time 0.00(0.00)\n",
      "Iter 1436 | Time 65.8996(63.1395) | Bit/dim 3.5143(3.5145) | Xent 0.0000(0.0000) | Loss 8.8528(9.6634) | Error 0.0000(0.0000) Steps 688(678.31) | Grad Norm 0.4128(0.3270) | Total Time 0.00(0.00)\n",
      "Iter 1437 | Time 62.8174(63.1299) | Bit/dim 3.5121(3.5144) | Xent 0.0000(0.0000) | Loss 8.8321(9.6385) | Error 0.0000(0.0000) Steps 682(678.42) | Grad Norm 0.3027(0.3263) | Total Time 0.00(0.00)\n",
      "Iter 1438 | Time 65.2250(63.1927) | Bit/dim 3.5071(3.5142) | Xent 0.0000(0.0000) | Loss 8.9369(9.6174) | Error 0.0000(0.0000) Steps 682(678.53) | Grad Norm 0.2668(0.3245) | Total Time 0.00(0.00)\n",
      "Iter 1439 | Time 64.0576(63.2187) | Bit/dim 3.5194(3.5143) | Xent 0.0000(0.0000) | Loss 9.1283(9.6028) | Error 0.0000(0.0000) Steps 688(678.81) | Grad Norm 0.3213(0.3244) | Total Time 0.00(0.00)\n",
      "Iter 1440 | Time 58.0252(63.0629) | Bit/dim 3.5162(3.5144) | Xent 0.0000(0.0000) | Loss 8.6276(9.5735) | Error 0.0000(0.0000) Steps 658(678.19) | Grad Norm 0.6534(0.3343) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0240 | Time 25.4089, Epoch Time 422.2286(410.6388), Bit/dim 3.5151(best: 3.5091), Xent 0.0000, Loss 3.5151, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1441 | Time 67.0633(63.1829) | Bit/dim 3.4999(3.5140) | Xent 0.0000(0.0000) | Loss 13.4498(9.6898) | Error 0.0000(0.0000) Steps 718(679.38) | Grad Norm 0.3874(0.3359) | Total Time 0.00(0.00)\n",
      "Iter 1442 | Time 60.8628(63.1133) | Bit/dim 3.5104(3.5139) | Xent 0.0000(0.0000) | Loss 8.7969(9.6630) | Error 0.0000(0.0000) Steps 670(679.10) | Grad Norm 0.3696(0.3369) | Total Time 0.00(0.00)\n",
      "Iter 1443 | Time 63.0280(63.1107) | Bit/dim 3.5167(3.5139) | Xent 0.0000(0.0000) | Loss 8.9340(9.6411) | Error 0.0000(0.0000) Steps 676(679.01) | Grad Norm 0.3204(0.3364) | Total Time 0.00(0.00)\n",
      "Iter 1444 | Time 63.5481(63.1239) | Bit/dim 3.5108(3.5138) | Xent 0.0000(0.0000) | Loss 8.7961(9.6158) | Error 0.0000(0.0000) Steps 670(678.74) | Grad Norm 0.4274(0.3391) | Total Time 0.00(0.00)\n",
      "Iter 1445 | Time 58.5522(62.9867) | Bit/dim 3.5213(3.5141) | Xent 0.0000(0.0000) | Loss 8.7353(9.5894) | Error 0.0000(0.0000) Steps 646(677.76) | Grad Norm 0.4200(0.3415) | Total Time 0.00(0.00)\n",
      "Iter 1446 | Time 60.0064(62.8973) | Bit/dim 3.5081(3.5139) | Xent 0.0000(0.0000) | Loss 8.7397(9.5639) | Error 0.0000(0.0000) Steps 670(677.52) | Grad Norm 0.3366(0.3414) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0241 | Time 25.5548, Epoch Time 414.5551(410.7562), Bit/dim 3.5143(best: 3.5091), Xent 0.0000, Loss 3.5143, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1447 | Time 61.6544(62.8600) | Bit/dim 3.5065(3.5137) | Xent 0.0000(0.0000) | Loss 13.0339(9.6680) | Error 0.0000(0.0000) Steps 670(677.30) | Grad Norm 0.5308(0.3471) | Total Time 0.00(0.00)\n",
      "Iter 1448 | Time 62.2240(62.8409) | Bit/dim 3.5198(3.5139) | Xent 0.0000(0.0000) | Loss 8.8988(9.6449) | Error 0.0000(0.0000) Steps 664(676.90) | Grad Norm 0.3523(0.3472) | Total Time 0.00(0.00)\n",
      "Iter 1449 | Time 64.3372(62.8858) | Bit/dim 3.5128(3.5138) | Xent 0.0000(0.0000) | Loss 8.8462(9.6209) | Error 0.0000(0.0000) Steps 676(676.87) | Grad Norm 0.3859(0.3484) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 60.8916(62.8260) | Bit/dim 3.5077(3.5136) | Xent 0.0000(0.0000) | Loss 9.0090(9.6026) | Error 0.0000(0.0000) Steps 670(676.67) | Grad Norm 0.2917(0.3467) | Total Time 0.00(0.00)\n",
      "Iter 1451 | Time 59.7045(62.7323) | Bit/dim 3.5137(3.5136) | Xent 0.0000(0.0000) | Loss 8.9049(9.5817) | Error 0.0000(0.0000) Steps 670(676.47) | Grad Norm 0.2907(0.3450) | Total Time 0.00(0.00)\n",
      "Iter 1452 | Time 64.3036(62.7795) | Bit/dim 3.5129(3.5136) | Xent 0.0000(0.0000) | Loss 8.8331(9.5592) | Error 0.0000(0.0000) Steps 676(676.45) | Grad Norm 0.3265(0.3445) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0242 | Time 24.9257, Epoch Time 413.8916(410.8503), Bit/dim 3.5159(best: 3.5091), Xent 0.0000, Loss 3.5159, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1453 | Time 59.3875(62.6777) | Bit/dim 3.5062(3.5134) | Xent 0.0000(0.0000) | Loss 13.1307(9.6663) | Error 0.0000(0.0000) Steps 664(676.08) | Grad Norm 0.9120(0.3615) | Total Time 0.00(0.00)\n",
      "Iter 1454 | Time 66.4156(62.7899) | Bit/dim 3.5181(3.5135) | Xent 0.0000(0.0000) | Loss 8.9928(9.6461) | Error 0.0000(0.0000) Steps 688(676.44) | Grad Norm 0.3426(0.3609) | Total Time 0.00(0.00)\n",
      "Iter 1455 | Time 63.4166(62.8087) | Bit/dim 3.5060(3.5133) | Xent 0.0000(0.0000) | Loss 8.7849(9.6203) | Error 0.0000(0.0000) Steps 682(676.60) | Grad Norm 0.4875(0.3647) | Total Time 0.00(0.00)\n",
      "Iter 1456 | Time 59.4993(62.7094) | Bit/dim 3.5156(3.5134) | Xent 0.0000(0.0000) | Loss 8.6910(9.5924) | Error 0.0000(0.0000) Steps 658(676.05) | Grad Norm 0.3365(0.3639) | Total Time 0.00(0.00)\n",
      "Iter 1457 | Time 61.4228(62.6708) | Bit/dim 3.5145(3.5134) | Xent 0.0000(0.0000) | Loss 8.7197(9.5662) | Error 0.0000(0.0000) Steps 670(675.86) | Grad Norm 0.4793(0.3673) | Total Time 0.00(0.00)\n",
      "Iter 1458 | Time 60.0450(62.5920) | Bit/dim 3.5098(3.5133) | Xent 0.0000(0.0000) | Loss 8.8162(9.5437) | Error 0.0000(0.0000) Steps 664(675.51) | Grad Norm 0.3122(0.3657) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0243 | Time 25.0116, Epoch Time 410.8402(410.8500), Bit/dim 3.5105(best: 3.5091), Xent 0.0000, Loss 3.5105, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1459 | Time 60.9048(62.5414) | Bit/dim 3.5113(3.5132) | Xent 0.0000(0.0000) | Loss 13.3368(9.6575) | Error 0.0000(0.0000) Steps 676(675.52) | Grad Norm 0.3377(0.3648) | Total Time 0.00(0.00)\n",
      "Iter 1460 | Time 66.6498(62.6646) | Bit/dim 3.5112(3.5132) | Xent 0.0000(0.0000) | Loss 8.9865(9.6374) | Error 0.0000(0.0000) Steps 712(676.62) | Grad Norm 0.3853(0.3655) | Total Time 0.00(0.00)\n",
      "Iter 1461 | Time 61.5682(62.6318) | Bit/dim 3.5091(3.5131) | Xent 0.0000(0.0000) | Loss 8.9178(9.6158) | Error 0.0000(0.0000) Steps 682(676.78) | Grad Norm 0.2895(0.3632) | Total Time 0.00(0.00)\n",
      "Iter 1462 | Time 61.1321(62.5868) | Bit/dim 3.5153(3.5131) | Xent 0.0000(0.0000) | Loss 8.9109(9.5947) | Error 0.0000(0.0000) Steps 688(677.12) | Grad Norm 0.3630(0.3632) | Total Time 0.00(0.00)\n",
      "Iter 1463 | Time 60.6795(62.5295) | Bit/dim 3.5085(3.5130) | Xent 0.0000(0.0000) | Loss 8.8597(9.5726) | Error 0.0000(0.0000) Steps 670(676.90) | Grad Norm 0.3062(0.3615) | Total Time 0.00(0.00)\n",
      "Iter 1464 | Time 62.0599(62.5155) | Bit/dim 3.5088(3.5129) | Xent 0.0000(0.0000) | Loss 8.6923(9.5462) | Error 0.0000(0.0000) Steps 682(677.05) | Grad Norm 0.3889(0.3623) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0244 | Time 25.4588, Epoch Time 414.5075(410.9597), Bit/dim 3.5096(best: 3.5091), Xent 0.0000, Loss 3.5096, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1465 | Time 58.2819(62.3884) | Bit/dim 3.5101(3.5128) | Xent 0.0000(0.0000) | Loss 13.3427(9.6601) | Error 0.0000(0.0000) Steps 646(676.12) | Grad Norm 0.4700(0.3655) | Total Time 0.00(0.00)\n",
      "Iter 1466 | Time 64.3597(62.4476) | Bit/dim 3.5110(3.5127) | Xent 0.0000(0.0000) | Loss 8.8028(9.6344) | Error 0.0000(0.0000) Steps 676(676.12) | Grad Norm 0.2446(0.3619) | Total Time 0.00(0.00)\n",
      "Iter 1467 | Time 69.7807(62.6676) | Bit/dim 3.5159(3.5128) | Xent 0.0000(0.0000) | Loss 9.0040(9.6155) | Error 0.0000(0.0000) Steps 712(677.20) | Grad Norm 0.2683(0.3591) | Total Time 0.00(0.00)\n",
      "Iter 1468 | Time 59.4281(62.5704) | Bit/dim 3.5087(3.5127) | Xent 0.0000(0.0000) | Loss 8.7894(9.5907) | Error 0.0000(0.0000) Steps 664(676.80) | Grad Norm 0.3119(0.3577) | Total Time 0.00(0.00)\n",
      "Iter 1469 | Time 63.1173(62.5868) | Bit/dim 3.5084(3.5126) | Xent 0.0000(0.0000) | Loss 8.8272(9.5678) | Error 0.0000(0.0000) Steps 676(676.78) | Grad Norm 0.2440(0.3543) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 60.8455(62.5346) | Bit/dim 3.5150(3.5126) | Xent 0.0000(0.0000) | Loss 8.8201(9.5453) | Error 0.0000(0.0000) Steps 670(676.57) | Grad Norm 0.2673(0.3516) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0245 | Time 25.5321, Epoch Time 417.1248(411.1447), Bit/dim 3.5086(best: 3.5091), Xent 0.0000, Loss 3.5086, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1471 | Time 61.1126(62.4919) | Bit/dim 3.5281(3.5131) | Xent 0.0000(0.0000) | Loss 13.6002(9.6670) | Error 0.0000(0.0000) Steps 676(676.56) | Grad Norm 0.3766(0.3524) | Total Time 0.00(0.00)\n",
      "Iter 1472 | Time 60.5858(62.4347) | Bit/dim 3.5085(3.5130) | Xent 0.0000(0.0000) | Loss 8.8471(9.6424) | Error 0.0000(0.0000) Steps 670(676.36) | Grad Norm 0.2996(0.3508) | Total Time 0.00(0.00)\n",
      "Iter 1473 | Time 65.0648(62.5136) | Bit/dim 3.5130(3.5130) | Xent 0.0000(0.0000) | Loss 8.5109(9.6085) | Error 0.0000(0.0000) Steps 676(676.35) | Grad Norm 0.3864(0.3519) | Total Time 0.00(0.00)\n",
      "Iter 1474 | Time 64.1866(62.5638) | Bit/dim 3.4937(3.5124) | Xent 0.0000(0.0000) | Loss 8.9328(9.5882) | Error 0.0000(0.0000) Steps 676(676.34) | Grad Norm 0.3766(0.3526) | Total Time 0.00(0.00)\n",
      "Iter 1475 | Time 60.8646(62.5128) | Bit/dim 3.5108(3.5123) | Xent 0.0000(0.0000) | Loss 8.9243(9.5683) | Error 0.0000(0.0000) Steps 670(676.15) | Grad Norm 0.3044(0.3512) | Total Time 0.00(0.00)\n",
      "Iter 1476 | Time 61.6967(62.4883) | Bit/dim 3.5052(3.5121) | Xent 0.0000(0.0000) | Loss 8.8633(9.5471) | Error 0.0000(0.0000) Steps 658(675.60) | Grad Norm 0.2804(0.3491) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0246 | Time 25.3458, Epoch Time 414.6985(411.2513), Bit/dim 3.5121(best: 3.5086), Xent 0.0000, Loss 3.5121, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1477 | Time 62.3206(62.4833) | Bit/dim 3.5156(3.5122) | Xent 0.0000(0.0000) | Loss 13.0939(9.6535) | Error 0.0000(0.0000) Steps 670(675.44) | Grad Norm 0.4404(0.3518) | Total Time 0.00(0.00)\n",
      "Iter 1478 | Time 62.2263(62.4756) | Bit/dim 3.5132(3.5123) | Xent 0.0000(0.0000) | Loss 8.9745(9.6331) | Error 0.0000(0.0000) Steps 676(675.45) | Grad Norm 0.1895(0.3469) | Total Time 0.00(0.00)\n",
      "Iter 1479 | Time 60.0006(62.4014) | Bit/dim 3.5086(3.5122) | Xent 0.0000(0.0000) | Loss 8.7927(9.6079) | Error 0.0000(0.0000) Steps 670(675.29) | Grad Norm 0.3220(0.3462) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 61.8290(62.3842) | Bit/dim 3.5081(3.5120) | Xent 0.0000(0.0000) | Loss 9.0200(9.5903) | Error 0.0000(0.0000) Steps 694(675.85) | Grad Norm 0.3023(0.3449) | Total Time 0.00(0.00)\n",
      "Iter 1481 | Time 61.5742(62.3599) | Bit/dim 3.5218(3.5123) | Xent 0.0000(0.0000) | Loss 8.8496(9.5681) | Error 0.0000(0.0000) Steps 670(675.67) | Grad Norm 0.3027(0.3436) | Total Time 0.00(0.00)\n",
      "Iter 1482 | Time 60.2729(62.2973) | Bit/dim 3.5015(3.5120) | Xent 0.0000(0.0000) | Loss 9.0169(9.5515) | Error 0.0000(0.0000) Steps 676(675.68) | Grad Norm 0.2326(0.3403) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0247 | Time 25.2362, Epoch Time 410.0138(411.2142), Bit/dim 3.5108(best: 3.5086), Xent 0.0000, Loss 3.5108, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1483 | Time 64.6514(62.3679) | Bit/dim 3.5120(3.5120) | Xent 0.0000(0.0000) | Loss 13.5220(9.6707) | Error 0.0000(0.0000) Steps 688(676.05) | Grad Norm 0.2898(0.3387) | Total Time 0.00(0.00)\n",
      "Iter 1484 | Time 60.6551(62.3165) | Bit/dim 3.5101(3.5119) | Xent 0.0000(0.0000) | Loss 8.8744(9.6468) | Error 0.0000(0.0000) Steps 688(676.41) | Grad Norm 0.2601(0.3364) | Total Time 0.00(0.00)\n",
      "Iter 1485 | Time 60.7753(62.2703) | Bit/dim 3.5169(3.5121) | Xent 0.0000(0.0000) | Loss 8.9294(9.6253) | Error 0.0000(0.0000) Steps 664(676.04) | Grad Norm 0.2734(0.3345) | Total Time 0.00(0.00)\n",
      "Iter 1486 | Time 64.1414(62.3264) | Bit/dim 3.5013(3.5118) | Xent 0.0000(0.0000) | Loss 8.9088(9.6038) | Error 0.0000(0.0000) Steps 682(676.22) | Grad Norm 0.2326(0.3314) | Total Time 0.00(0.00)\n",
      "Iter 1487 | Time 64.9688(62.4057) | Bit/dim 3.5063(3.5116) | Xent 0.0000(0.0000) | Loss 8.8839(9.5822) | Error 0.0000(0.0000) Steps 682(676.39) | Grad Norm 0.2945(0.3303) | Total Time 0.00(0.00)\n",
      "Iter 1488 | Time 62.7022(62.4146) | Bit/dim 3.5196(3.5118) | Xent 0.0000(0.0000) | Loss 8.8201(9.5593) | Error 0.0000(0.0000) Steps 676(676.38) | Grad Norm 0.2558(0.3281) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0248 | Time 25.8472, Epoch Time 420.0583(411.4795), Bit/dim 3.5177(best: 3.5086), Xent 0.0000, Loss 3.5177, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1489 | Time 61.8133(62.3965) | Bit/dim 3.5160(3.5120) | Xent 0.0000(0.0000) | Loss 13.3686(9.6736) | Error 0.0000(0.0000) Steps 652(675.65) | Grad Norm 0.3994(0.3302) | Total Time 0.00(0.00)\n",
      "Iter 1490 | Time 59.5483(62.3111) | Bit/dim 3.5145(3.5120) | Xent 0.0000(0.0000) | Loss 8.9613(9.6522) | Error 0.0000(0.0000) Steps 664(675.30) | Grad Norm 0.2259(0.3271) | Total Time 0.00(0.00)\n",
      "Iter 1491 | Time 64.2650(62.3697) | Bit/dim 3.5056(3.5119) | Xent 0.0000(0.0000) | Loss 8.8693(9.6287) | Error 0.0000(0.0000) Steps 676(675.32) | Grad Norm 0.2670(0.3253) | Total Time 0.00(0.00)\n",
      "Iter 1492 | Time 64.4234(62.4313) | Bit/dim 3.4949(3.5113) | Xent 0.0000(0.0000) | Loss 8.7731(9.6031) | Error 0.0000(0.0000) Steps 670(675.16) | Grad Norm 0.2247(0.3223) | Total Time 0.00(0.00)\n",
      "Iter 1493 | Time 61.7456(62.4107) | Bit/dim 3.5195(3.5116) | Xent 0.0000(0.0000) | Loss 8.8654(9.5809) | Error 0.0000(0.0000) Steps 664(674.83) | Grad Norm 0.2188(0.3192) | Total Time 0.00(0.00)\n",
      "Iter 1494 | Time 63.0570(62.4301) | Bit/dim 3.5113(3.5116) | Xent 0.0000(0.0000) | Loss 8.9243(9.5612) | Error 0.0000(0.0000) Steps 670(674.68) | Grad Norm 0.2028(0.3157) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0249 | Time 25.4915, Epoch Time 416.5487(411.6316), Bit/dim 3.5185(best: 3.5086), Xent 0.0000, Loss 3.5185, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1495 | Time 65.2943(62.5161) | Bit/dim 3.5109(3.5116) | Xent 0.0000(0.0000) | Loss 13.4619(9.6782) | Error 0.0000(0.0000) Steps 676(674.72) | Grad Norm 0.6275(0.3250) | Total Time 0.00(0.00)\n",
      "Iter 1496 | Time 61.0784(62.4729) | Bit/dim 3.5163(3.5117) | Xent 0.0000(0.0000) | Loss 8.9706(9.6570) | Error 0.0000(0.0000) Steps 676(674.76) | Grad Norm 0.2431(0.3226) | Total Time 0.00(0.00)\n",
      "Iter 1497 | Time 60.9786(62.4281) | Bit/dim 3.5066(3.5115) | Xent 0.0000(0.0000) | Loss 8.7260(9.6291) | Error 0.0000(0.0000) Steps 670(674.62) | Grad Norm 0.5093(0.3282) | Total Time 0.00(0.00)\n",
      "Iter 1498 | Time 67.9152(62.5927) | Bit/dim 3.5020(3.5113) | Xent 0.0000(0.0000) | Loss 8.9779(9.6095) | Error 0.0000(0.0000) Steps 694(675.20) | Grad Norm 0.1950(0.3242) | Total Time 0.00(0.00)\n",
      "Iter 1499 | Time 63.6832(62.6254) | Bit/dim 3.5210(3.5115) | Xent 0.0000(0.0000) | Loss 8.8114(9.5856) | Error 0.0000(0.0000) Steps 664(674.86) | Grad Norm 0.3477(0.3249) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 65.8438(62.7220) | Bit/dim 3.5094(3.5115) | Xent 0.0000(0.0000) | Loss 8.8836(9.5645) | Error 0.0000(0.0000) Steps 688(675.26) | Grad Norm 0.2268(0.3220) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0250 | Time 25.1350, Epoch Time 425.8550(412.0583), Bit/dim 3.5108(best: 3.5086), Xent 0.0000, Loss 3.5108, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1501 | Time 63.4745(62.7446) | Bit/dim 3.5114(3.5115) | Xent 0.0000(0.0000) | Loss 13.3589(9.6784) | Error 0.0000(0.0000) Steps 676(675.28) | Grad Norm 0.2412(0.3195) | Total Time 0.00(0.00)\n",
      "Iter 1502 | Time 63.4220(62.7649) | Bit/dim 3.5131(3.5115) | Xent 0.0000(0.0000) | Loss 8.9650(9.6570) | Error 0.0000(0.0000) Steps 676(675.30) | Grad Norm 0.2168(0.3165) | Total Time 0.00(0.00)\n",
      "Iter 1503 | Time 60.4585(62.6957) | Bit/dim 3.5073(3.5114) | Xent 0.0000(0.0000) | Loss 8.9395(9.6355) | Error 0.0000(0.0000) Steps 670(675.14) | Grad Norm 0.2329(0.3139) | Total Time 0.00(0.00)\n",
      "Iter 1504 | Time 58.9026(62.5819) | Bit/dim 3.5138(3.5115) | Xent 0.0000(0.0000) | Loss 8.7496(9.6089) | Error 0.0000(0.0000) Steps 676(675.17) | Grad Norm 0.3546(0.3152) | Total Time 0.00(0.00)\n",
      "Iter 1505 | Time 64.7531(62.6470) | Bit/dim 3.5145(3.5116) | Xent 0.0000(0.0000) | Loss 8.8270(9.5854) | Error 0.0000(0.0000) Steps 676(675.19) | Grad Norm 0.3416(0.3160) | Total Time 0.00(0.00)\n",
      "Iter 1506 | Time 62.6074(62.6458) | Bit/dim 3.5105(3.5115) | Xent 0.0000(0.0000) | Loss 8.7999(9.5619) | Error 0.0000(0.0000) Steps 676(675.22) | Grad Norm 0.2404(0.3137) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 25.2108, Epoch Time 414.8236(412.1412), Bit/dim 3.5156(best: 3.5086), Xent 0.0000, Loss 3.5156, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1507 | Time 59.7278(62.5583) | Bit/dim 3.5034(3.5113) | Xent 0.0000(0.0000) | Loss 13.0032(9.6651) | Error 0.0000(0.0000) Steps 664(674.88) | Grad Norm 0.3527(0.3149) | Total Time 0.00(0.00)\n",
      "Iter 1508 | Time 64.1647(62.6065) | Bit/dim 3.5030(3.5110) | Xent 0.0000(0.0000) | Loss 8.8833(9.6416) | Error 0.0000(0.0000) Steps 694(675.45) | Grad Norm 0.2281(0.3123) | Total Time 0.00(0.00)\n",
      "Iter 1509 | Time 63.6828(62.6388) | Bit/dim 3.5229(3.5114) | Xent 0.0000(0.0000) | Loss 8.7523(9.6150) | Error 0.0000(0.0000) Steps 658(674.93) | Grad Norm 0.2597(0.3107) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 63.3728(62.6608) | Bit/dim 3.5037(3.5112) | Xent 0.0000(0.0000) | Loss 9.1025(9.5996) | Error 0.0000(0.0000) Steps 676(674.96) | Grad Norm 0.2625(0.3092) | Total Time 0.00(0.00)\n",
      "Iter 1511 | Time 61.3873(62.6226) | Bit/dim 3.5166(3.5113) | Xent 0.0000(0.0000) | Loss 8.9492(9.5801) | Error 0.0000(0.0000) Steps 670(674.81) | Grad Norm 0.2353(0.3070) | Total Time 0.00(0.00)\n",
      "Iter 1512 | Time 64.8301(62.6888) | Bit/dim 3.5184(3.5115) | Xent 0.0000(0.0000) | Loss 8.8803(9.5591) | Error 0.0000(0.0000) Steps 688(675.21) | Grad Norm 0.2623(0.3057) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 25.1599, Epoch Time 418.3170(412.3265), Bit/dim 3.5092(best: 3.5086), Xent 0.0000, Loss 3.5092, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1513 | Time 63.1858(62.7037) | Bit/dim 3.5115(3.5115) | Xent 0.0000(0.0000) | Loss 13.2788(9.6707) | Error 0.0000(0.0000) Steps 688(675.59) | Grad Norm 0.3218(0.3062) | Total Time 0.00(0.00)\n",
      "Iter 1514 | Time 67.3487(62.8431) | Bit/dim 3.5040(3.5113) | Xent 0.0000(0.0000) | Loss 9.0127(9.6509) | Error 0.0000(0.0000) Steps 694(676.14) | Grad Norm 0.2039(0.3031) | Total Time 0.00(0.00)\n",
      "Iter 1515 | Time 57.9677(62.6968) | Bit/dim 3.5130(3.5114) | Xent 0.0000(0.0000) | Loss 8.9384(9.6296) | Error 0.0000(0.0000) Steps 670(675.96) | Grad Norm 0.2813(0.3024) | Total Time 0.00(0.00)\n",
      "Iter 1516 | Time 61.5670(62.6629) | Bit/dim 3.5187(3.5116) | Xent 0.0000(0.0000) | Loss 8.8579(9.6064) | Error 0.0000(0.0000) Steps 664(675.60) | Grad Norm 0.2907(0.3021) | Total Time 0.00(0.00)\n",
      "Iter 1517 | Time 60.7947(62.6069) | Bit/dim 3.5112(3.5116) | Xent 0.0000(0.0000) | Loss 8.7561(9.5809) | Error 0.0000(0.0000) Steps 670(675.43) | Grad Norm 0.2605(0.3008) | Total Time 0.00(0.00)\n",
      "Iter 1518 | Time 63.5817(62.6361) | Bit/dim 3.5057(3.5114) | Xent 0.0000(0.0000) | Loss 8.9885(9.5631) | Error 0.0000(0.0000) Steps 688(675.81) | Grad Norm 0.2789(0.3002) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 25.2580, Epoch Time 415.1611(412.4115), Bit/dim 3.5142(best: 3.5086), Xent 0.0000, Loss 3.5142, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1519 | Time 63.5977(62.6650) | Bit/dim 3.5068(3.5113) | Xent 0.0000(0.0000) | Loss 13.8074(9.6905) | Error 0.0000(0.0000) Steps 682(676.00) | Grad Norm 0.3439(0.3015) | Total Time 0.00(0.00)\n",
      "Iter 1520 | Time 62.4486(62.6585) | Bit/dim 3.5123(3.5113) | Xent 0.0000(0.0000) | Loss 8.7441(9.6621) | Error 0.0000(0.0000) Steps 664(675.64) | Grad Norm 0.2752(0.3007) | Total Time 0.00(0.00)\n",
      "Iter 1521 | Time 64.0379(62.6999) | Bit/dim 3.5216(3.5116) | Xent 0.0000(0.0000) | Loss 8.7705(9.6353) | Error 0.0000(0.0000) Steps 670(675.47) | Grad Norm 0.1956(0.2976) | Total Time 0.00(0.00)\n",
      "Iter 1522 | Time 65.6378(62.7880) | Bit/dim 3.5204(3.5119) | Xent 0.0000(0.0000) | Loss 8.7463(9.6086) | Error 0.0000(0.0000) Steps 658(674.94) | Grad Norm 0.2775(0.2970) | Total Time 0.00(0.00)\n",
      "Iter 1523 | Time 63.3198(62.8040) | Bit/dim 3.5050(3.5117) | Xent 0.0000(0.0000) | Loss 9.0262(9.5912) | Error 0.0000(0.0000) Steps 688(675.33) | Grad Norm 0.2372(0.2952) | Total Time 0.00(0.00)\n",
      "Iter 1524 | Time 61.8649(62.7758) | Bit/dim 3.5096(3.5116) | Xent 0.0000(0.0000) | Loss 8.8876(9.5701) | Error 0.0000(0.0000) Steps 688(675.71) | Grad Norm 0.2638(0.2942) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 25.6122, Epoch Time 422.7265(412.7210), Bit/dim 3.5150(best: 3.5086), Xent 0.0000, Loss 3.5150, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1525 | Time 66.6328(62.8915) | Bit/dim 3.5155(3.5117) | Xent 0.0000(0.0000) | Loss 13.4415(9.6862) | Error 0.0000(0.0000) Steps 688(676.08) | Grad Norm 0.4772(0.2997) | Total Time 0.00(0.00)\n",
      "Iter 1526 | Time 61.3232(62.8444) | Bit/dim 3.5026(3.5114) | Xent 0.0000(0.0000) | Loss 8.8356(9.6607) | Error 0.0000(0.0000) Steps 670(675.90) | Grad Norm 0.2360(0.2978) | Total Time 0.00(0.00)\n",
      "Iter 1527 | Time 64.8026(62.9032) | Bit/dim 3.5046(3.5112) | Xent 0.0000(0.0000) | Loss 8.9051(9.6380) | Error 0.0000(0.0000) Steps 682(676.08) | Grad Norm 0.2747(0.2971) | Total Time 0.00(0.00)\n",
      "Iter 1528 | Time 62.3996(62.8881) | Bit/dim 3.5092(3.5112) | Xent 0.0000(0.0000) | Loss 8.8925(9.6157) | Error 0.0000(0.0000) Steps 688(676.44) | Grad Norm 0.4843(0.3027) | Total Time 0.00(0.00)\n",
      "Iter 1529 | Time 65.0235(62.9521) | Bit/dim 3.5077(3.5111) | Xent 0.0000(0.0000) | Loss 9.0078(9.5974) | Error 0.0000(0.0000) Steps 670(676.25) | Grad Norm 0.2156(0.3001) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 61.7254(62.9153) | Bit/dim 3.5080(3.5110) | Xent 0.0000(0.0000) | Loss 8.7913(9.5732) | Error 0.0000(0.0000) Steps 664(675.88) | Grad Norm 0.2991(0.3001) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 25.8266, Epoch Time 423.8269(413.0542), Bit/dim 3.5087(best: 3.5086), Xent 0.0000, Loss 3.5087, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1531 | Time 65.4235(62.9906) | Bit/dim 3.5160(3.5111) | Xent 0.0000(0.0000) | Loss 13.5902(9.6937) | Error 0.0000(0.0000) Steps 694(676.42) | Grad Norm 0.3984(0.3030) | Total Time 0.00(0.00)\n",
      "Iter 1532 | Time 59.1976(62.8768) | Bit/dim 3.5199(3.5114) | Xent 0.0000(0.0000) | Loss 8.6788(9.6633) | Error 0.0000(0.0000) Steps 658(675.87) | Grad Norm 0.2519(0.3015) | Total Time 0.00(0.00)\n",
      "Iter 1533 | Time 63.2638(62.8884) | Bit/dim 3.5070(3.5113) | Xent 0.0000(0.0000) | Loss 8.7895(9.6371) | Error 0.0000(0.0000) Steps 664(675.52) | Grad Norm 0.2085(0.2987) | Total Time 0.00(0.00)\n",
      "Iter 1534 | Time 62.5772(62.8791) | Bit/dim 3.5195(3.5115) | Xent 0.0000(0.0000) | Loss 8.9063(9.6152) | Error 0.0000(0.0000) Steps 694(676.07) | Grad Norm 0.2370(0.2968) | Total Time 0.00(0.00)\n",
      "Iter 1535 | Time 60.1473(62.7971) | Bit/dim 3.4986(3.5111) | Xent 0.0000(0.0000) | Loss 8.7773(9.5900) | Error 0.0000(0.0000) Steps 676(676.07) | Grad Norm 0.2856(0.2965) | Total Time 0.00(0.00)\n",
      "Iter 1536 | Time 64.3329(62.8432) | Bit/dim 3.5006(3.5108) | Xent 0.0000(0.0000) | Loss 8.9517(9.5709) | Error 0.0000(0.0000) Steps 688(676.43) | Grad Norm 0.3341(0.2976) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 25.6025, Epoch Time 416.4865(413.1571), Bit/dim 3.5113(best: 3.5086), Xent 0.0000, Loss 3.5113, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1537 | Time 64.9193(62.9055) | Bit/dim 3.5103(3.5108) | Xent 0.0000(0.0000) | Loss 13.2955(9.6826) | Error 0.0000(0.0000) Steps 670(676.23) | Grad Norm 0.3069(0.2979) | Total Time 0.00(0.00)\n",
      "Iter 1538 | Time 62.9403(62.9065) | Bit/dim 3.5125(3.5108) | Xent 0.0000(0.0000) | Loss 8.7313(9.6541) | Error 0.0000(0.0000) Steps 676(676.23) | Grad Norm 0.4336(0.3020) | Total Time 0.00(0.00)\n",
      "Iter 1539 | Time 59.5863(62.8069) | Bit/dim 3.5207(3.5111) | Xent 0.0000(0.0000) | Loss 8.8496(9.6299) | Error 0.0000(0.0000) Steps 652(675.50) | Grad Norm 0.2754(0.3012) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 62.4657(62.7967) | Bit/dim 3.5084(3.5111) | Xent 0.0000(0.0000) | Loss 8.8345(9.6061) | Error 0.0000(0.0000) Steps 664(675.15) | Grad Norm 0.2321(0.2991) | Total Time 0.00(0.00)\n",
      "Iter 1541 | Time 61.9486(62.7712) | Bit/dim 3.5070(3.5109) | Xent 0.0000(0.0000) | Loss 8.8854(9.5845) | Error 0.0000(0.0000) Steps 682(675.36) | Grad Norm 0.2398(0.2973) | Total Time 0.00(0.00)\n",
      "Iter 1542 | Time 60.5230(62.7038) | Bit/dim 3.5063(3.5108) | Xent 0.0000(0.0000) | Loss 8.6943(9.5578) | Error 0.0000(0.0000) Steps 664(675.02) | Grad Norm 0.3925(0.3002) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 25.4215, Epoch Time 414.0482(413.1839), Bit/dim 3.5044(best: 3.5086), Xent 0.0000, Loss 3.5044, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1543 | Time 62.2001(62.6887) | Bit/dim 3.4971(3.5104) | Xent 0.0000(0.0000) | Loss 13.3912(9.6728) | Error 0.0000(0.0000) Steps 676(675.05) | Grad Norm 0.2841(0.2997) | Total Time 0.00(0.00)\n",
      "Iter 1544 | Time 62.2403(62.6752) | Bit/dim 3.5205(3.5107) | Xent 0.0000(0.0000) | Loss 8.8103(9.6469) | Error 0.0000(0.0000) Steps 676(675.08) | Grad Norm 0.2689(0.2988) | Total Time 0.00(0.00)\n",
      "Iter 1545 | Time 64.1665(62.7200) | Bit/dim 3.5140(3.5108) | Xent 0.0000(0.0000) | Loss 8.9548(9.6261) | Error 0.0000(0.0000) Steps 682(675.28) | Grad Norm 0.3074(0.2990) | Total Time 0.00(0.00)\n",
      "Iter 1546 | Time 60.1895(62.6441) | Bit/dim 3.5098(3.5108) | Xent 0.0000(0.0000) | Loss 8.7702(9.6004) | Error 0.0000(0.0000) Steps 670(675.13) | Grad Norm 0.2535(0.2977) | Total Time 0.00(0.00)\n",
      "Iter 1547 | Time 66.3983(62.7567) | Bit/dim 3.5069(3.5106) | Xent 0.0000(0.0000) | Loss 9.0062(9.5826) | Error 0.0000(0.0000) Steps 670(674.97) | Grad Norm 0.2136(0.2952) | Total Time 0.00(0.00)\n",
      "Iter 1548 | Time 62.9507(62.7625) | Bit/dim 3.5116(3.5107) | Xent 0.0000(0.0000) | Loss 8.8708(9.5613) | Error 0.0000(0.0000) Steps 688(675.36) | Grad Norm 0.2176(0.2928) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 25.3037, Epoch Time 419.5303(413.3743), Bit/dim 3.5085(best: 3.5044), Xent 0.0000, Loss 3.5085, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1549 | Time 58.7046(62.6408) | Bit/dim 3.5217(3.5110) | Xent 0.0000(0.0000) | Loss 13.0591(9.6662) | Error 0.0000(0.0000) Steps 664(675.02) | Grad Norm 0.3498(0.2945) | Total Time 0.00(0.00)\n",
      "Iter 1550 | Time 65.6678(62.7316) | Bit/dim 3.5017(3.5107) | Xent 0.0000(0.0000) | Loss 8.7189(9.6378) | Error 0.0000(0.0000) Steps 688(675.41) | Grad Norm 0.3232(0.2954) | Total Time 0.00(0.00)\n",
      "Iter 1551 | Time 63.1926(62.7454) | Bit/dim 3.5054(3.5106) | Xent 0.0000(0.0000) | Loss 8.7551(9.6113) | Error 0.0000(0.0000) Steps 670(675.25) | Grad Norm 0.2277(0.2934) | Total Time 0.00(0.00)\n",
      "Iter 1552 | Time 62.8409(62.7483) | Bit/dim 3.5089(3.5105) | Xent 0.0000(0.0000) | Loss 8.8239(9.5877) | Error 0.0000(0.0000) Steps 658(674.73) | Grad Norm 0.2253(0.2913) | Total Time 0.00(0.00)\n",
      "Iter 1553 | Time 61.8753(62.7221) | Bit/dim 3.5152(3.5107) | Xent 0.0000(0.0000) | Loss 8.8902(9.5667) | Error 0.0000(0.0000) Steps 664(674.41) | Grad Norm 0.2630(0.2905) | Total Time 0.00(0.00)\n",
      "Iter 1554 | Time 62.9180(62.7280) | Bit/dim 3.5066(3.5105) | Xent 0.0000(0.0000) | Loss 9.0586(9.5515) | Error 0.0000(0.0000) Steps 670(674.28) | Grad Norm 0.2314(0.2887) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 24.6840, Epoch Time 415.9737(413.4523), Bit/dim 3.5120(best: 3.5044), Xent 0.0000, Loss 3.5120, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1555 | Time 63.0958(62.7390) | Bit/dim 3.5034(3.5103) | Xent 0.0000(0.0000) | Loss 13.3872(9.6666) | Error 0.0000(0.0000) Steps 670(674.15) | Grad Norm 0.3969(0.2919) | Total Time 0.00(0.00)\n",
      "Iter 1556 | Time 63.8180(62.7714) | Bit/dim 3.5125(3.5104) | Xent 0.0000(0.0000) | Loss 8.9007(9.6436) | Error 0.0000(0.0000) Steps 694(674.74) | Grad Norm 0.3283(0.2930) | Total Time 0.00(0.00)\n",
      "Iter 1557 | Time 59.8785(62.6846) | Bit/dim 3.5117(3.5104) | Xent 0.0000(0.0000) | Loss 8.7192(9.6159) | Error 0.0000(0.0000) Steps 676(674.78) | Grad Norm 0.3024(0.2933) | Total Time 0.00(0.00)\n",
      "Iter 1558 | Time 60.7113(62.6254) | Bit/dim 3.5097(3.5104) | Xent 0.0000(0.0000) | Loss 8.5593(9.5842) | Error 0.0000(0.0000) Steps 646(673.92) | Grad Norm 0.4745(0.2988) | Total Time 0.00(0.00)\n",
      "Iter 1559 | Time 61.5591(62.5934) | Bit/dim 3.5072(3.5103) | Xent 0.0000(0.0000) | Loss 8.6772(9.5570) | Error 0.0000(0.0000) Steps 682(674.16) | Grad Norm 0.2581(0.2975) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 60.4064(62.5278) | Bit/dim 3.5039(3.5101) | Xent 0.0000(0.0000) | Loss 8.8983(9.5372) | Error 0.0000(0.0000) Steps 676(674.22) | Grad Norm 0.2878(0.2972) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 25.0275, Epoch Time 410.8401(413.3739), Bit/dim 3.5141(best: 3.5044), Xent 0.0000, Loss 3.5141, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1561 | Time 61.9765(62.5112) | Bit/dim 3.5004(3.5098) | Xent 0.0000(0.0000) | Loss 13.5025(9.6562) | Error 0.0000(0.0000) Steps 664(673.91) | Grad Norm 0.3200(0.2979) | Total Time 0.00(0.00)\n",
      "Iter 1562 | Time 63.8975(62.5528) | Bit/dim 3.5027(3.5096) | Xent 0.0000(0.0000) | Loss 8.7964(9.6304) | Error 0.0000(0.0000) Steps 670(673.79) | Grad Norm 0.2639(0.2969) | Total Time 0.00(0.00)\n",
      "Iter 1563 | Time 60.9772(62.5056) | Bit/dim 3.5025(3.5094) | Xent 0.0000(0.0000) | Loss 8.8120(9.6058) | Error 0.0000(0.0000) Steps 670(673.68) | Grad Norm 0.3081(0.2972) | Total Time 0.00(0.00)\n",
      "Iter 1564 | Time 61.2564(62.4681) | Bit/dim 3.5098(3.5094) | Xent 0.0000(0.0000) | Loss 8.6575(9.5774) | Error 0.0000(0.0000) Steps 688(674.11) | Grad Norm 0.3708(0.2995) | Total Time 0.00(0.00)\n",
      "Iter 1565 | Time 62.1465(62.4584) | Bit/dim 3.5140(3.5095) | Xent 0.0000(0.0000) | Loss 8.9484(9.5585) | Error 0.0000(0.0000) Steps 694(674.71) | Grad Norm 0.2730(0.2987) | Total Time 0.00(0.00)\n",
      "Iter 1566 | Time 67.1107(62.5980) | Bit/dim 3.5209(3.5099) | Xent 0.0000(0.0000) | Loss 8.7678(9.5348) | Error 0.0000(0.0000) Steps 694(675.28) | Grad Norm 0.3015(0.2987) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 25.2287, Epoch Time 418.7244(413.5344), Bit/dim 3.5064(best: 3.5044), Xent 0.0000, Loss 3.5064, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1567 | Time 64.8001(62.6641) | Bit/dim 3.5145(3.5100) | Xent 0.0000(0.0000) | Loss 13.3650(9.6497) | Error 0.0000(0.0000) Steps 688(675.67) | Grad Norm 0.3426(0.3001) | Total Time 0.00(0.00)\n",
      "Iter 1568 | Time 65.2558(62.7418) | Bit/dim 3.5104(3.5100) | Xent 0.0000(0.0000) | Loss 8.9550(9.6288) | Error 0.0000(0.0000) Steps 688(676.04) | Grad Norm 0.2446(0.2984) | Total Time 0.00(0.00)\n",
      "Iter 1569 | Time 62.8222(62.7442) | Bit/dim 3.5147(3.5102) | Xent 0.0000(0.0000) | Loss 8.9085(9.6072) | Error 0.0000(0.0000) Steps 676(676.03) | Grad Norm 0.2755(0.2977) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 60.3052(62.6711) | Bit/dim 3.5045(3.5100) | Xent 0.0000(0.0000) | Loss 8.9928(9.5888) | Error 0.0000(0.0000) Steps 682(676.21) | Grad Norm 0.1965(0.2947) | Total Time 0.00(0.00)\n",
      "Iter 1571 | Time 63.8955(62.7078) | Bit/dim 3.4962(3.5096) | Xent 0.0000(0.0000) | Loss 8.9255(9.5689) | Error 0.0000(0.0000) Steps 676(676.21) | Grad Norm 0.2512(0.2934) | Total Time 0.00(0.00)\n",
      "Iter 1572 | Time 62.7719(62.7097) | Bit/dim 3.5009(3.5093) | Xent 0.0000(0.0000) | Loss 8.9506(9.5504) | Error 0.0000(0.0000) Steps 682(676.38) | Grad Norm 0.2348(0.2916) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 25.1979, Epoch Time 421.0564(413.7601), Bit/dim 3.5102(best: 3.5044), Xent 0.0000, Loss 3.5102, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1573 | Time 65.5069(62.7936) | Bit/dim 3.5171(3.5096) | Xent 0.0000(0.0000) | Loss 13.5298(9.6697) | Error 0.0000(0.0000) Steps 664(676.01) | Grad Norm 0.2518(0.2904) | Total Time 0.00(0.00)\n",
      "Iter 1574 | Time 62.3900(62.7815) | Bit/dim 3.5023(3.5093) | Xent 0.0000(0.0000) | Loss 8.5267(9.6354) | Error 0.0000(0.0000) Steps 664(675.65) | Grad Norm 0.4107(0.2940) | Total Time 0.00(0.00)\n",
      "Iter 1575 | Time 64.2658(62.8261) | Bit/dim 3.5087(3.5093) | Xent 0.0000(0.0000) | Loss 8.8118(9.6107) | Error 0.0000(0.0000) Steps 676(675.66) | Grad Norm 0.2533(0.2928) | Total Time 0.00(0.00)\n",
      "Iter 1576 | Time 67.8551(62.9769) | Bit/dim 3.5129(3.5094) | Xent 0.0000(0.0000) | Loss 9.0146(9.5929) | Error 0.0000(0.0000) Steps 700(676.39) | Grad Norm 0.2439(0.2913) | Total Time 0.00(0.00)\n",
      "Iter 1577 | Time 64.0390(63.0088) | Bit/dim 3.4934(3.5090) | Xent 0.0000(0.0000) | Loss 8.8533(9.5707) | Error 0.0000(0.0000) Steps 694(676.92) | Grad Norm 0.2096(0.2889) | Total Time 0.00(0.00)\n",
      "Iter 1578 | Time 58.6994(62.8795) | Bit/dim 3.5141(3.5091) | Xent 0.0000(0.0000) | Loss 8.9372(9.5517) | Error 0.0000(0.0000) Steps 670(676.71) | Grad Norm 0.2668(0.2882) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 25.5812, Epoch Time 424.2763(414.0755), Bit/dim 3.5142(best: 3.5044), Xent 0.0000, Loss 3.5142, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1579 | Time 62.8074(62.8773) | Bit/dim 3.5147(3.5093) | Xent 0.0000(0.0000) | Loss 13.4689(9.6692) | Error 0.0000(0.0000) Steps 676(676.69) | Grad Norm 0.2645(0.2875) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 65.2929(62.9498) | Bit/dim 3.5053(3.5092) | Xent 0.0000(0.0000) | Loss 8.9131(9.6465) | Error 0.0000(0.0000) Steps 676(676.67) | Grad Norm 0.2697(0.2870) | Total Time 0.00(0.00)\n",
      "Iter 1581 | Time 61.7793(62.9147) | Bit/dim 3.5066(3.5091) | Xent 0.0000(0.0000) | Loss 9.0233(9.6278) | Error 0.0000(0.0000) Steps 676(676.65) | Grad Norm 0.2377(0.2855) | Total Time 0.00(0.00)\n",
      "Iter 1582 | Time 64.0458(62.9486) | Bit/dim 3.5142(3.5092) | Xent 0.0000(0.0000) | Loss 9.0154(9.6094) | Error 0.0000(0.0000) Steps 694(677.17) | Grad Norm 0.2641(0.2848) | Total Time 0.00(0.00)\n",
      "Iter 1583 | Time 64.5596(62.9970) | Bit/dim 3.5084(3.5092) | Xent 0.0000(0.0000) | Loss 8.9105(9.5885) | Error 0.0000(0.0000) Steps 676(677.13) | Grad Norm 0.2814(0.2847) | Total Time 0.00(0.00)\n",
      "Iter 1584 | Time 62.9435(62.9954) | Bit/dim 3.5015(3.5090) | Xent 0.0000(0.0000) | Loss 8.6670(9.5608) | Error 0.0000(0.0000) Steps 658(676.56) | Grad Norm 0.3603(0.2870) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 25.0120, Epoch Time 422.2675(414.3213), Bit/dim 3.5139(best: 3.5044), Xent 0.0000, Loss 3.5139, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1585 | Time 65.4068(63.0677) | Bit/dim 3.5044(3.5088) | Xent 0.0000(0.0000) | Loss 13.7494(9.6865) | Error 0.0000(0.0000) Steps 700(677.26) | Grad Norm 0.3478(0.2888) | Total Time 0.00(0.00)\n",
      "Iter 1586 | Time 67.8673(63.2117) | Bit/dim 3.5081(3.5088) | Xent 0.0000(0.0000) | Loss 9.1442(9.6702) | Error 0.0000(0.0000) Steps 700(677.95) | Grad Norm 0.2497(0.2877) | Total Time 0.00(0.00)\n",
      "Iter 1587 | Time 60.5731(63.1325) | Bit/dim 3.5144(3.5090) | Xent 0.0000(0.0000) | Loss 8.8430(9.6454) | Error 0.0000(0.0000) Steps 676(677.89) | Grad Norm 0.3948(0.2909) | Total Time 0.00(0.00)\n",
      "Iter 1588 | Time 61.4717(63.0827) | Bit/dim 3.5045(3.5088) | Xent 0.0000(0.0000) | Loss 8.8617(9.6219) | Error 0.0000(0.0000) Steps 694(678.37) | Grad Norm 0.2915(0.2909) | Total Time 0.00(0.00)\n",
      "Iter 1589 | Time 61.1352(63.0243) | Bit/dim 3.5118(3.5089) | Xent 0.0000(0.0000) | Loss 8.8943(9.6001) | Error 0.0000(0.0000) Steps 682(678.48) | Grad Norm 0.3128(0.2916) | Total Time 0.00(0.00)\n",
      "Iter 1590 | Time 62.1276(62.9974) | Bit/dim 3.5103(3.5090) | Xent 0.0000(0.0000) | Loss 8.9277(9.5799) | Error 0.0000(0.0000) Steps 676(678.40) | Grad Norm 0.4976(0.2977) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 25.0635, Epoch Time 419.8875(414.4883), Bit/dim 3.5149(best: 3.5044), Xent 0.0000, Loss 3.5149, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1591 | Time 61.9977(62.9674) | Bit/dim 3.5094(3.5090) | Xent 0.0000(0.0000) | Loss 12.9442(9.6808) | Error 0.0000(0.0000) Steps 670(678.15) | Grad Norm 0.7966(0.3127) | Total Time 0.00(0.00)\n",
      "Iter 1592 | Time 60.2964(62.8873) | Bit/dim 3.5144(3.5092) | Xent 0.0000(0.0000) | Loss 8.8740(9.6566) | Error 0.0000(0.0000) Steps 670(677.91) | Grad Norm 0.3529(0.3139) | Total Time 0.00(0.00)\n",
      "Iter 1593 | Time 60.7698(62.8237) | Bit/dim 3.5095(3.5092) | Xent 0.0000(0.0000) | Loss 8.9599(9.6357) | Error 0.0000(0.0000) Steps 688(678.21) | Grad Norm 0.2959(0.3134) | Total Time 0.00(0.00)\n",
      "Iter 1594 | Time 59.4514(62.7226) | Bit/dim 3.5006(3.5089) | Xent 0.0000(0.0000) | Loss 8.6303(9.6055) | Error 0.0000(0.0000) Steps 664(677.78) | Grad Norm 0.4138(0.3164) | Total Time 0.00(0.00)\n",
      "Iter 1595 | Time 60.3719(62.6520) | Bit/dim 3.5187(3.5092) | Xent 0.0000(0.0000) | Loss 8.8865(9.5840) | Error 0.0000(0.0000) Steps 676(677.73) | Grad Norm 0.2998(0.3159) | Total Time 0.00(0.00)\n",
      "Iter 1596 | Time 61.9500(62.6310) | Bit/dim 3.5026(3.5090) | Xent 0.0000(0.0000) | Loss 8.7647(9.5594) | Error 0.0000(0.0000) Steps 694(678.22) | Grad Norm 0.3155(0.3159) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 24.6969, Epoch Time 405.2983(414.2126), Bit/dim 3.5122(best: 3.5044), Xent 0.0000, Loss 3.5122, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1597 | Time 57.8716(62.4882) | Bit/dim 3.5120(3.5091) | Xent 0.0000(0.0000) | Loss 12.8503(9.6581) | Error 0.0000(0.0000) Steps 658(677.61) | Grad Norm 1.2648(0.3443) | Total Time 0.00(0.00)\n",
      "Iter 1598 | Time 63.7740(62.5268) | Bit/dim 3.5001(3.5088) | Xent 0.0000(0.0000) | Loss 8.9125(9.6358) | Error 0.0000(0.0000) Steps 694(678.10) | Grad Norm 0.3406(0.3442) | Total Time 0.00(0.00)\n",
      "Iter 1599 | Time 58.3078(62.4002) | Bit/dim 3.5111(3.5089) | Xent 0.0000(0.0000) | Loss 8.9488(9.6151) | Error 0.0000(0.0000) Steps 664(677.68) | Grad Norm 0.3294(0.3438) | Total Time 0.00(0.00)\n",
      "Iter 1600 | Time 64.3923(62.4600) | Bit/dim 3.5048(3.5088) | Xent 0.0000(0.0000) | Loss 8.7070(9.5879) | Error 0.0000(0.0000) Steps 694(678.17) | Grad Norm 0.3510(0.3440) | Total Time 0.00(0.00)\n",
      "Iter 1601 | Time 62.1268(62.4500) | Bit/dim 3.4997(3.5085) | Xent 0.0000(0.0000) | Loss 8.9829(9.5698) | Error 0.0000(0.0000) Steps 670(677.93) | Grad Norm 0.2592(0.3415) | Total Time 0.00(0.00)\n",
      "Iter 1602 | Time 61.8175(62.4310) | Bit/dim 3.5249(3.5090) | Xent 0.0000(0.0000) | Loss 8.8996(9.5496) | Error 0.0000(0.0000) Steps 676(677.87) | Grad Norm 0.3261(0.3410) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0267 | Time 24.8175, Epoch Time 409.2404(414.0634), Bit/dim 3.5133(best: 3.5044), Xent 0.0000, Loss 3.5133, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1603 | Time 62.8696(62.4442) | Bit/dim 3.5162(3.5092) | Xent 0.0000(0.0000) | Loss 13.0838(9.6557) | Error 0.0000(0.0000) Steps 670(677.63) | Grad Norm 0.4084(0.3430) | Total Time 0.00(0.00)\n",
      "Iter 1604 | Time 63.1471(62.4653) | Bit/dim 3.5190(3.5095) | Xent 0.0000(0.0000) | Loss 8.9666(9.6350) | Error 0.0000(0.0000) Steps 688(677.94) | Grad Norm 0.3113(0.3421) | Total Time 0.00(0.00)\n",
      "Iter 1605 | Time 60.3839(62.4028) | Bit/dim 3.5020(3.5093) | Xent 0.0000(0.0000) | Loss 8.9597(9.6147) | Error 0.0000(0.0000) Steps 688(678.24) | Grad Norm 0.2469(0.3392) | Total Time 0.00(0.00)\n",
      "Iter 1606 | Time 62.5688(62.4078) | Bit/dim 3.5071(3.5092) | Xent 0.0000(0.0000) | Loss 8.7744(9.5895) | Error 0.0000(0.0000) Steps 688(678.54) | Grad Norm 0.3069(0.3382) | Total Time 0.00(0.00)\n",
      "Iter 1607 | Time 61.3844(62.3771) | Bit/dim 3.4902(3.5086) | Xent 0.0000(0.0000) | Loss 8.5417(9.5581) | Error 0.0000(0.0000) Steps 670(678.28) | Grad Norm 0.7413(0.3503) | Total Time 0.00(0.00)\n",
      "Iter 1608 | Time 63.3480(62.4062) | Bit/dim 3.5181(3.5089) | Xent 0.0000(0.0000) | Loss 9.0345(9.5424) | Error 0.0000(0.0000) Steps 676(678.21) | Grad Norm 0.2701(0.3479) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0268 | Time 25.8574, Epoch Time 415.4605(414.1053), Bit/dim 3.5076(best: 3.5044), Xent 0.0000, Loss 3.5076, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1609 | Time 67.4406(62.5572) | Bit/dim 3.5095(3.5089) | Xent 0.0000(0.0000) | Loss 13.1018(9.6492) | Error 0.0000(0.0000) Steps 712(679.23) | Grad Norm 0.4506(0.3510) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 64.7829(62.6240) | Bit/dim 3.5037(3.5088) | Xent 0.0000(0.0000) | Loss 8.9804(9.6291) | Error 0.0000(0.0000) Steps 676(679.13) | Grad Norm 0.2424(0.3477) | Total Time 0.00(0.00)\n",
      "Iter 1611 | Time 57.7937(62.4791) | Bit/dim 3.5114(3.5089) | Xent 0.0000(0.0000) | Loss 8.9078(9.6075) | Error 0.0000(0.0000) Steps 664(678.68) | Grad Norm 0.3462(0.3477) | Total Time 0.00(0.00)\n",
      "Iter 1612 | Time 64.1517(62.5293) | Bit/dim 3.5052(3.5088) | Xent 0.0000(0.0000) | Loss 9.1150(9.5927) | Error 0.0000(0.0000) Steps 694(679.14) | Grad Norm 0.2939(0.3461) | Total Time 0.00(0.00)\n",
      "Iter 1613 | Time 61.6084(62.5017) | Bit/dim 3.5069(3.5087) | Xent 0.0000(0.0000) | Loss 8.6444(9.5642) | Error 0.0000(0.0000) Steps 694(679.58) | Grad Norm 0.5269(0.3515) | Total Time 0.00(0.00)\n",
      "Iter 1614 | Time 59.7623(62.4195) | Bit/dim 3.5178(3.5090) | Xent 0.0000(0.0000) | Loss 8.9067(9.5445) | Error 0.0000(0.0000) Steps 658(678.93) | Grad Norm 0.3763(0.3523) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0269 | Time 24.7667, Epoch Time 416.5112(414.1775), Bit/dim 3.5119(best: 3.5044), Xent 0.0000, Loss 3.5119, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1615 | Time 63.6008(62.4549) | Bit/dim 3.5004(3.5087) | Xent 0.0000(0.0000) | Loss 12.7450(9.6405) | Error 0.0000(0.0000) Steps 670(678.67) | Grad Norm 0.5093(0.3570) | Total Time 0.00(0.00)\n",
      "Iter 1616 | Time 62.1975(62.4472) | Bit/dim 3.4949(3.5083) | Xent 0.0000(0.0000) | Loss 8.9855(9.6209) | Error 0.0000(0.0000) Steps 688(678.95) | Grad Norm 0.3587(0.3570) | Total Time 0.00(0.00)\n",
      "Iter 1617 | Time 63.8300(62.4887) | Bit/dim 3.5126(3.5084) | Xent 0.0000(0.0000) | Loss 8.7678(9.5953) | Error 0.0000(0.0000) Steps 664(678.50) | Grad Norm 0.2669(0.3543) | Total Time 0.00(0.00)\n",
      "Iter 1618 | Time 64.6692(62.5541) | Bit/dim 3.5194(3.5088) | Xent 0.0000(0.0000) | Loss 8.9801(9.5768) | Error 0.0000(0.0000) Steps 694(678.96) | Grad Norm 0.3026(0.3528) | Total Time 0.00(0.00)\n",
      "Iter 1619 | Time 63.9477(62.5959) | Bit/dim 3.5120(3.5089) | Xent 0.0000(0.0000) | Loss 8.9214(9.5572) | Error 0.0000(0.0000) Steps 682(679.05) | Grad Norm 0.2946(0.3510) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 63.2860(62.6166) | Bit/dim 3.5028(3.5087) | Xent 0.0000(0.0000) | Loss 9.0293(9.5413) | Error 0.0000(0.0000) Steps 682(679.14) | Grad Norm 0.2437(0.3478) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0270 | Time 25.3480, Epoch Time 423.0340(414.4432), Bit/dim 3.5124(best: 3.5044), Xent 0.0000, Loss 3.5124, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1621 | Time 66.7636(62.7410) | Bit/dim 3.5080(3.5087) | Xent 0.0000(0.0000) | Loss 13.3990(9.6571) | Error 0.0000(0.0000) Steps 706(679.95) | Grad Norm 0.3753(0.3486) | Total Time 0.00(0.00)\n",
      "Iter 1622 | Time 61.9960(62.7187) | Bit/dim 3.5064(3.5086) | Xent 0.0000(0.0000) | Loss 9.0462(9.6387) | Error 0.0000(0.0000) Steps 682(680.01) | Grad Norm 0.2110(0.3445) | Total Time 0.00(0.00)\n",
      "Iter 1623 | Time 64.8274(62.7819) | Bit/dim 3.5117(3.5087) | Xent 0.0000(0.0000) | Loss 8.8858(9.6162) | Error 0.0000(0.0000) Steps 700(680.61) | Grad Norm 0.4187(0.3467) | Total Time 0.00(0.00)\n",
      "Iter 1624 | Time 65.5280(62.8643) | Bit/dim 3.4992(3.5084) | Xent 0.0000(0.0000) | Loss 8.9802(9.5971) | Error 0.0000(0.0000) Steps 694(681.01) | Grad Norm 0.2769(0.3446) | Total Time 0.00(0.00)\n",
      "Iter 1625 | Time 63.2330(62.8754) | Bit/dim 3.4893(3.5078) | Xent 0.0000(0.0000) | Loss 8.8193(9.5737) | Error 0.0000(0.0000) Steps 664(680.50) | Grad Norm 0.2618(0.3421) | Total Time 0.00(0.00)\n",
      "Iter 1626 | Time 58.4019(62.7412) | Bit/dim 3.5279(3.5084) | Xent 0.0000(0.0000) | Loss 8.6805(9.5469) | Error 0.0000(0.0000) Steps 652(679.65) | Grad Norm 0.4992(0.3469) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0271 | Time 24.8538, Epoch Time 421.8117(414.6643), Bit/dim 3.5096(best: 3.5044), Xent 0.0000, Loss 3.5096, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1627 | Time 65.3595(62.8197) | Bit/dim 3.5050(3.5083) | Xent 0.0000(0.0000) | Loss 13.4134(9.6629) | Error 0.0000(0.0000) Steps 694(680.08) | Grad Norm 0.4488(0.3499) | Total Time 0.00(0.00)\n",
      "Iter 1628 | Time 64.9128(62.8825) | Bit/dim 3.5133(3.5085) | Xent 0.0000(0.0000) | Loss 9.1212(9.6467) | Error 0.0000(0.0000) Steps 682(680.13) | Grad Norm 0.4604(0.3532) | Total Time 0.00(0.00)\n",
      "Iter 1629 | Time 60.9706(62.8251) | Bit/dim 3.4938(3.5080) | Xent 0.0000(0.0000) | Loss 8.7039(9.6184) | Error 0.0000(0.0000) Steps 676(680.01) | Grad Norm 0.3340(0.3526) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 64.3892(62.8721) | Bit/dim 3.5068(3.5080) | Xent 0.0000(0.0000) | Loss 8.6758(9.5901) | Error 0.0000(0.0000) Steps 670(679.71) | Grad Norm 0.4854(0.3566) | Total Time 0.00(0.00)\n",
      "Iter 1631 | Time 61.7687(62.8390) | Bit/dim 3.5040(3.5079) | Xent 0.0000(0.0000) | Loss 8.9022(9.5695) | Error 0.0000(0.0000) Steps 664(679.24) | Grad Norm 0.2141(0.3524) | Total Time 0.00(0.00)\n",
      "Iter 1632 | Time 63.4980(62.8587) | Bit/dim 3.5208(3.5083) | Xent 0.0000(0.0000) | Loss 8.8851(9.5490) | Error 0.0000(0.0000) Steps 688(679.50) | Grad Norm 0.2771(0.3501) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0272 | Time 25.4412, Epoch Time 422.7511(414.9069), Bit/dim 3.5120(best: 3.5044), Xent 0.0000, Loss 3.5120, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1633 | Time 60.0911(62.7757) | Bit/dim 3.5065(3.5082) | Xent 0.0000(0.0000) | Loss 13.2553(9.6601) | Error 0.0000(0.0000) Steps 670(679.22) | Grad Norm 0.9686(0.3687) | Total Time 0.00(0.00)\n",
      "Iter 1634 | Time 65.6746(62.8627) | Bit/dim 3.5074(3.5082) | Xent 0.0000(0.0000) | Loss 9.0576(9.6421) | Error 0.0000(0.0000) Steps 694(679.66) | Grad Norm 0.5595(0.3744) | Total Time 0.00(0.00)\n",
      "Iter 1635 | Time 61.8097(62.8311) | Bit/dim 3.5079(3.5082) | Xent 0.0000(0.0000) | Loss 8.6876(9.6134) | Error 0.0000(0.0000) Steps 676(679.55) | Grad Norm 0.6222(0.3818) | Total Time 0.00(0.00)\n",
      "Iter 1636 | Time 60.9310(62.7741) | Bit/dim 3.5161(3.5084) | Xent 0.0000(0.0000) | Loss 8.7734(9.5882) | Error 0.0000(0.0000) Steps 664(679.08) | Grad Norm 0.4727(0.3845) | Total Time 0.00(0.00)\n",
      "Iter 1637 | Time 59.8946(62.6877) | Bit/dim 3.5025(3.5082) | Xent 0.0000(0.0000) | Loss 9.0456(9.5720) | Error 0.0000(0.0000) Steps 676(678.99) | Grad Norm 0.4162(0.3855) | Total Time 0.00(0.00)\n",
      "Iter 1638 | Time 64.2301(62.7340) | Bit/dim 3.5100(3.5083) | Xent 0.0000(0.0000) | Loss 8.8971(9.5517) | Error 0.0000(0.0000) Steps 694(679.44) | Grad Norm 0.4004(0.3859) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0273 | Time 25.7309, Epoch Time 414.4566(414.8934), Bit/dim 3.5092(best: 3.5044), Xent 0.0000, Loss 3.5092, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1639 | Time 60.9558(62.6806) | Bit/dim 3.5226(3.5087) | Xent 0.0000(0.0000) | Loss 13.6055(9.6733) | Error 0.0000(0.0000) Steps 682(679.52) | Grad Norm 0.5966(0.3923) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 64.3778(62.7315) | Bit/dim 3.4928(3.5082) | Xent 0.0000(0.0000) | Loss 8.9428(9.6514) | Error 0.0000(0.0000) Steps 700(680.13) | Grad Norm 0.2940(0.3893) | Total Time 0.00(0.00)\n",
      "Iter 1641 | Time 59.5849(62.6371) | Bit/dim 3.5116(3.5083) | Xent 0.0000(0.0000) | Loss 8.8413(9.6271) | Error 0.0000(0.0000) Steps 676(680.01) | Grad Norm 0.3416(0.3879) | Total Time 0.00(0.00)\n",
      "Iter 1642 | Time 59.0151(62.5285) | Bit/dim 3.5106(3.5084) | Xent 0.0000(0.0000) | Loss 8.5612(9.5951) | Error 0.0000(0.0000) Steps 646(678.99) | Grad Norm 0.3942(0.3881) | Total Time 0.00(0.00)\n",
      "Iter 1643 | Time 64.3402(62.5828) | Bit/dim 3.5084(3.5084) | Xent 0.0000(0.0000) | Loss 8.8250(9.5720) | Error 0.0000(0.0000) Steps 676(678.90) | Grad Norm 0.3945(0.3883) | Total Time 0.00(0.00)\n",
      "Iter 1644 | Time 63.6954(62.6162) | Bit/dim 3.5059(3.5083) | Xent 0.0000(0.0000) | Loss 8.7791(9.5482) | Error 0.0000(0.0000) Steps 664(678.45) | Grad Norm 0.4962(0.3915) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0274 | Time 24.9676, Epoch Time 412.7860(414.8301), Bit/dim 3.5057(best: 3.5044), Xent 0.0000, Loss 3.5057, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1645 | Time 60.9423(62.5660) | Bit/dim 3.5041(3.5082) | Xent 0.0000(0.0000) | Loss 13.2808(9.6602) | Error 0.0000(0.0000) Steps 664(678.02) | Grad Norm 0.6516(0.3993) | Total Time 0.00(0.00)\n",
      "Iter 1646 | Time 63.3335(62.5890) | Bit/dim 3.4965(3.5079) | Xent 0.0000(0.0000) | Loss 8.7347(9.6324) | Error 0.0000(0.0000) Steps 664(677.60) | Grad Norm 0.3904(0.3990) | Total Time 0.00(0.00)\n",
      "Iter 1647 | Time 61.9914(62.5711) | Bit/dim 3.5027(3.5077) | Xent 0.0000(0.0000) | Loss 8.3259(9.5933) | Error 0.0000(0.0000) Steps 664(677.19) | Grad Norm 0.6446(0.4064) | Total Time 0.00(0.00)\n",
      "Iter 1648 | Time 62.0082(62.5542) | Bit/dim 3.5097(3.5078) | Xent 0.0000(0.0000) | Loss 8.9451(9.5738) | Error 0.0000(0.0000) Steps 676(677.15) | Grad Norm 0.4460(0.4076) | Total Time 0.00(0.00)\n",
      "Iter 1649 | Time 63.5778(62.5849) | Bit/dim 3.5147(3.5080) | Xent 0.0000(0.0000) | Loss 8.8991(9.5536) | Error 0.0000(0.0000) Steps 676(677.12) | Grad Norm 0.3976(0.4073) | Total Time 0.00(0.00)\n",
      "Iter 1650 | Time 61.7665(62.5604) | Bit/dim 3.5149(3.5082) | Xent 0.0000(0.0000) | Loss 8.8342(9.5320) | Error 0.0000(0.0000) Steps 664(676.73) | Grad Norm 0.3707(0.4062) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0275 | Time 24.9535, Epoch Time 414.7633(414.8281), Bit/dim 3.5094(best: 3.5044), Xent 0.0000, Loss 3.5094, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1651 | Time 63.1797(62.5789) | Bit/dim 3.5118(3.5083) | Xent 0.0000(0.0000) | Loss 13.5300(9.6519) | Error 0.0000(0.0000) Steps 688(677.06) | Grad Norm 0.5011(0.4090) | Total Time 0.00(0.00)\n",
      "Iter 1652 | Time 65.6888(62.6722) | Bit/dim 3.5112(3.5084) | Xent 0.0000(0.0000) | Loss 8.9299(9.6303) | Error 0.0000(0.0000) Steps 700(677.75) | Grad Norm 0.3741(0.4080) | Total Time 0.00(0.00)\n",
      "Iter 1653 | Time 58.5813(62.5495) | Bit/dim 3.5223(3.5088) | Xent 0.0000(0.0000) | Loss 8.8382(9.6065) | Error 0.0000(0.0000) Steps 670(677.52) | Grad Norm 0.3190(0.4053) | Total Time 0.00(0.00)\n",
      "Iter 1654 | Time 66.8960(62.6799) | Bit/dim 3.5024(3.5086) | Xent 0.0000(0.0000) | Loss 8.6916(9.5791) | Error 0.0000(0.0000) Steps 694(678.01) | Grad Norm 0.4440(0.4065) | Total Time 0.00(0.00)\n",
      "Iter 1655 | Time 63.7942(62.7133) | Bit/dim 3.5013(3.5084) | Xent 0.0000(0.0000) | Loss 9.0363(9.5628) | Error 0.0000(0.0000) Steps 688(678.31) | Grad Norm 0.3398(0.4045) | Total Time 0.00(0.00)\n",
      "Iter 1656 | Time 67.7171(62.8634) | Bit/dim 3.4955(3.5080) | Xent 0.0000(0.0000) | Loss 8.9778(9.5452) | Error 0.0000(0.0000) Steps 706(679.14) | Grad Norm 0.3894(0.4040) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0276 | Time 24.8337, Epoch Time 426.9522(415.1919), Bit/dim 3.5077(best: 3.5044), Xent 0.0000, Loss 3.5077, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1657 | Time 59.6238(62.7663) | Bit/dim 3.5100(3.5081) | Xent 0.0000(0.0000) | Loss 13.0898(9.6516) | Error 0.0000(0.0000) Steps 670(678.87) | Grad Norm 0.4509(0.4054) | Total Time 0.00(0.00)\n",
      "Iter 1658 | Time 62.2102(62.7496) | Bit/dim 3.5036(3.5079) | Xent 0.0000(0.0000) | Loss 8.9343(9.6300) | Error 0.0000(0.0000) Steps 682(678.96) | Grad Norm 0.3329(0.4033) | Total Time 0.00(0.00)\n",
      "Iter 1659 | Time 66.8011(62.8711) | Bit/dim 3.5163(3.5082) | Xent 0.0000(0.0000) | Loss 8.8386(9.6063) | Error 0.0000(0.0000) Steps 688(679.23) | Grad Norm 0.4702(0.4053) | Total Time 0.00(0.00)\n",
      "Iter 1660 | Time 62.4366(62.8581) | Bit/dim 3.5106(3.5082) | Xent 0.0000(0.0000) | Loss 8.8052(9.5823) | Error 0.0000(0.0000) Steps 664(678.78) | Grad Norm 0.4383(0.4063) | Total Time 0.00(0.00)\n",
      "Iter 1661 | Time 59.3024(62.7514) | Bit/dim 3.5065(3.5082) | Xent 0.0000(0.0000) | Loss 8.9682(9.5638) | Error 0.0000(0.0000) Steps 664(678.33) | Grad Norm 0.3257(0.4038) | Total Time 0.00(0.00)\n",
      "Iter 1662 | Time 61.8865(62.7255) | Bit/dim 3.5040(3.5081) | Xent 0.0000(0.0000) | Loss 8.9503(9.5454) | Error 0.0000(0.0000) Steps 682(678.44) | Grad Norm 0.2709(0.3999) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0277 | Time 25.2946, Epoch Time 413.7085(415.1474), Bit/dim 3.5085(best: 3.5044), Xent 0.0000, Loss 3.5085, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1663 | Time 62.5600(62.7205) | Bit/dim 3.5093(3.5081) | Xent 0.0000(0.0000) | Loss 13.1409(9.6533) | Error 0.0000(0.0000) Steps 658(677.83) | Grad Norm 0.3973(0.3998) | Total Time 0.00(0.00)\n",
      "Iter 1664 | Time 63.5381(62.7450) | Bit/dim 3.5085(3.5081) | Xent 0.0000(0.0000) | Loss 9.1477(9.6381) | Error 0.0000(0.0000) Steps 694(678.32) | Grad Norm 0.2192(0.3944) | Total Time 0.00(0.00)\n",
      "Iter 1665 | Time 62.5897(62.7404) | Bit/dim 3.4979(3.5078) | Xent 0.0000(0.0000) | Loss 8.6972(9.6099) | Error 0.0000(0.0000) Steps 670(678.07) | Grad Norm 0.3077(0.3918) | Total Time 0.00(0.00)\n",
      "Iter 1666 | Time 64.4601(62.7920) | Bit/dim 3.5105(3.5079) | Xent 0.0000(0.0000) | Loss 9.0915(9.5944) | Error 0.0000(0.0000) Steps 706(678.90) | Grad Norm 0.3027(0.3891) | Total Time 0.00(0.00)\n",
      "Iter 1667 | Time 62.4516(62.7818) | Bit/dim 3.5160(3.5081) | Xent 0.0000(0.0000) | Loss 8.7784(9.5699) | Error 0.0000(0.0000) Steps 670(678.64) | Grad Norm 0.3135(0.3868) | Total Time 0.00(0.00)\n",
      "Iter 1668 | Time 61.4863(62.7429) | Bit/dim 3.5050(3.5080) | Xent 0.0000(0.0000) | Loss 9.0549(9.5544) | Error 0.0000(0.0000) Steps 688(678.92) | Grad Norm 0.2444(0.3826) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0278 | Time 25.0454, Epoch Time 417.8484(415.2284), Bit/dim 3.5099(best: 3.5044), Xent 0.0000, Loss 3.5099, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1669 | Time 59.8693(62.6567) | Bit/dim 3.5094(3.5081) | Xent 0.0000(0.0000) | Loss 13.2438(9.6651) | Error 0.0000(0.0000) Steps 664(678.47) | Grad Norm 0.3398(0.3813) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 65.4260(62.7398) | Bit/dim 3.5162(3.5083) | Xent 0.0000(0.0000) | Loss 8.9380(9.6433) | Error 0.0000(0.0000) Steps 694(678.94) | Grad Norm 0.3622(0.3807) | Total Time 0.00(0.00)\n",
      "Iter 1671 | Time 61.1131(62.6910) | Bit/dim 3.5096(3.5084) | Xent 0.0000(0.0000) | Loss 8.7058(9.6152) | Error 0.0000(0.0000) Steps 658(678.31) | Grad Norm 0.3372(0.3794) | Total Time 0.00(0.00)\n",
      "Iter 1672 | Time 61.2833(62.6487) | Bit/dim 3.4938(3.5079) | Xent 0.0000(0.0000) | Loss 8.7730(9.5899) | Error 0.0000(0.0000) Steps 676(678.24) | Grad Norm 0.3690(0.3791) | Total Time 0.00(0.00)\n",
      "Iter 1673 | Time 61.0694(62.6013) | Bit/dim 3.4924(3.5075) | Xent 0.0000(0.0000) | Loss 8.9272(9.5700) | Error 0.0000(0.0000) Steps 670(677.99) | Grad Norm 0.3939(0.3795) | Total Time 0.00(0.00)\n",
      "Iter 1674 | Time 65.4126(62.6857) | Bit/dim 3.5155(3.5077) | Xent 0.0000(0.0000) | Loss 8.9288(9.5508) | Error 0.0000(0.0000) Steps 700(678.65) | Grad Norm 0.2886(0.3768) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0279 | Time 25.0324, Epoch Time 415.1940(415.2274), Bit/dim 3.5051(best: 3.5044), Xent 0.0000, Loss 3.5051, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1675 | Time 64.5103(62.7404) | Bit/dim 3.5081(3.5077) | Xent 0.0000(0.0000) | Loss 13.0779(9.6566) | Error 0.0000(0.0000) Steps 670(678.39) | Grad Norm 0.4738(0.3797) | Total Time 0.00(0.00)\n",
      "Iter 1676 | Time 71.9255(63.0160) | Bit/dim 3.5116(3.5078) | Xent 0.0000(0.0000) | Loss 8.9593(9.6357) | Error 0.0000(0.0000) Steps 712(679.40) | Grad Norm 0.2517(0.3759) | Total Time 0.00(0.00)\n",
      "Iter 1677 | Time 64.2688(63.0536) | Bit/dim 3.5008(3.5076) | Xent 0.0000(0.0000) | Loss 8.8270(9.6114) | Error 0.0000(0.0000) Steps 688(679.66) | Grad Norm 0.5231(0.3803) | Total Time 0.00(0.00)\n",
      "Iter 1678 | Time 63.6763(63.0722) | Bit/dim 3.5083(3.5076) | Xent 0.0000(0.0000) | Loss 8.9289(9.5909) | Error 0.0000(0.0000) Steps 670(679.37) | Grad Norm 0.3559(0.3796) | Total Time 0.00(0.00)\n",
      "Iter 1679 | Time 66.1815(63.1655) | Bit/dim 3.5094(3.5077) | Xent 0.0000(0.0000) | Loss 8.5051(9.5584) | Error 0.0000(0.0000) Steps 682(679.45) | Grad Norm 0.4300(0.3811) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 61.1755(63.1058) | Bit/dim 3.5089(3.5077) | Xent 0.0000(0.0000) | Loss 8.8921(9.5384) | Error 0.0000(0.0000) Steps 706(680.24) | Grad Norm 0.2998(0.3786) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0280 | Time 25.1797, Epoch Time 433.0959(415.7634), Bit/dim 3.5123(best: 3.5044), Xent 0.0000, Loss 3.5123, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1681 | Time 65.5279(63.1785) | Bit/dim 3.5128(3.5079) | Xent 0.0000(0.0000) | Loss 13.4382(9.6554) | Error 0.0000(0.0000) Steps 706(681.02) | Grad Norm 0.4039(0.3794) | Total Time 0.00(0.00)\n",
      "Iter 1682 | Time 61.7275(63.1350) | Bit/dim 3.5041(3.5078) | Xent 0.0000(0.0000) | Loss 9.0132(9.6361) | Error 0.0000(0.0000) Steps 688(681.23) | Grad Norm 0.3740(0.3792) | Total Time 0.00(0.00)\n",
      "Iter 1683 | Time 59.8727(63.0371) | Bit/dim 3.5081(3.5078) | Xent 0.0000(0.0000) | Loss 8.8252(9.6118) | Error 0.0000(0.0000) Steps 682(681.25) | Grad Norm 0.2510(0.3754) | Total Time 0.00(0.00)\n",
      "Iter 1684 | Time 64.5632(63.0829) | Bit/dim 3.5036(3.5076) | Xent 0.0000(0.0000) | Loss 9.0518(9.5950) | Error 0.0000(0.0000) Steps 706(681.99) | Grad Norm 0.2802(0.3725) | Total Time 0.00(0.00)\n",
      "Iter 1685 | Time 65.5753(63.1576) | Bit/dim 3.5106(3.5077) | Xent 0.0000(0.0000) | Loss 8.9538(9.5758) | Error 0.0000(0.0000) Steps 670(681.63) | Grad Norm 0.2669(0.3694) | Total Time 0.00(0.00)\n",
      "Iter 1686 | Time 61.8629(63.1188) | Bit/dim 3.4988(3.5075) | Xent 0.0000(0.0000) | Loss 8.9934(9.5583) | Error 0.0000(0.0000) Steps 694(682.00) | Grad Norm 0.2789(0.3666) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0281 | Time 25.2970, Epoch Time 420.6255(415.9093), Bit/dim 3.5043(best: 3.5044), Xent 0.0000, Loss 3.5043, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1687 | Time 64.8309(63.1702) | Bit/dim 3.5024(3.5073) | Xent 0.0000(0.0000) | Loss 13.7437(9.6838) | Error 0.0000(0.0000) Steps 694(682.36) | Grad Norm 0.3481(0.3661) | Total Time 0.00(0.00)\n",
      "Iter 1688 | Time 63.1212(63.1687) | Bit/dim 3.5019(3.5072) | Xent 0.0000(0.0000) | Loss 8.7970(9.6572) | Error 0.0000(0.0000) Steps 694(682.71) | Grad Norm 0.5443(0.3714) | Total Time 0.00(0.00)\n",
      "Iter 1689 | Time 66.6669(63.2736) | Bit/dim 3.5057(3.5071) | Xent 0.0000(0.0000) | Loss 8.9049(9.6347) | Error 0.0000(0.0000) Steps 676(682.51) | Grad Norm 0.3127(0.3697) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 64.4462(63.3088) | Bit/dim 3.5051(3.5071) | Xent 0.0000(0.0000) | Loss 9.0754(9.6179) | Error 0.0000(0.0000) Steps 700(683.04) | Grad Norm 0.4758(0.3729) | Total Time 0.00(0.00)\n",
      "Iter 1691 | Time 63.0954(63.3024) | Bit/dim 3.5108(3.5072) | Xent 0.0000(0.0000) | Loss 8.9378(9.5975) | Error 0.0000(0.0000) Steps 688(683.18) | Grad Norm 0.3354(0.3717) | Total Time 0.00(0.00)\n",
      "Iter 1692 | Time 63.5853(63.3109) | Bit/dim 3.5111(3.5073) | Xent 0.0000(0.0000) | Loss 8.9905(9.5793) | Error 0.0000(0.0000) Steps 724(684.41) | Grad Norm 0.2790(0.3689) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0282 | Time 25.2633, Epoch Time 426.8960(416.2389), Bit/dim 3.5083(best: 3.5043), Xent 0.0000, Loss 3.5083, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1693 | Time 63.7839(63.3251) | Bit/dim 3.5059(3.5072) | Xent 0.0000(0.0000) | Loss 13.4430(9.6952) | Error 0.0000(0.0000) Steps 688(684.52) | Grad Norm 0.4269(0.3707) | Total Time 0.00(0.00)\n",
      "Iter 1694 | Time 64.0296(63.3462) | Bit/dim 3.5155(3.5075) | Xent 0.0000(0.0000) | Loss 8.7134(9.6657) | Error 0.0000(0.0000) Steps 700(684.98) | Grad Norm 0.4195(0.3721) | Total Time 0.00(0.00)\n",
      "Iter 1695 | Time 65.5129(63.4112) | Bit/dim 3.5151(3.5077) | Xent 0.0000(0.0000) | Loss 8.9877(9.6454) | Error 0.0000(0.0000) Steps 694(685.25) | Grad Norm 0.2695(0.3691) | Total Time 0.00(0.00)\n",
      "Iter 1696 | Time 63.2468(63.4063) | Bit/dim 3.5012(3.5075) | Xent 0.0000(0.0000) | Loss 8.7500(9.6185) | Error 0.0000(0.0000) Steps 688(685.33) | Grad Norm 0.3200(0.3676) | Total Time 0.00(0.00)\n",
      "Iter 1697 | Time 63.3507(63.4046) | Bit/dim 3.5073(3.5075) | Xent 0.0000(0.0000) | Loss 8.8344(9.5950) | Error 0.0000(0.0000) Steps 682(685.23) | Grad Norm 0.3061(0.3658) | Total Time 0.00(0.00)\n",
      "Iter 1698 | Time 65.4312(63.4654) | Bit/dim 3.5087(3.5076) | Xent 0.0000(0.0000) | Loss 9.0081(9.5774) | Error 0.0000(0.0000) Steps 694(685.50) | Grad Norm 0.2605(0.3626) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0283 | Time 24.7943, Epoch Time 426.3544(416.5423), Bit/dim 3.5068(best: 3.5043), Xent 0.0000, Loss 3.5068, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1699 | Time 68.2995(63.6104) | Bit/dim 3.4992(3.5073) | Xent 0.0000(0.0000) | Loss 13.5128(9.6955) | Error 0.0000(0.0000) Steps 700(685.93) | Grad Norm 0.3759(0.3630) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 63.4272(63.6049) | Bit/dim 3.5042(3.5072) | Xent 0.0000(0.0000) | Loss 8.9786(9.6740) | Error 0.0000(0.0000) Steps 676(685.63) | Grad Norm 0.2669(0.3601) | Total Time 0.00(0.00)\n",
      "Iter 1701 | Time 63.0462(63.5882) | Bit/dim 3.5126(3.5074) | Xent 0.0000(0.0000) | Loss 8.9419(9.6520) | Error 0.0000(0.0000) Steps 688(685.71) | Grad Norm 0.4012(0.3613) | Total Time 0.00(0.00)\n",
      "Iter 1702 | Time 60.8040(63.5047) | Bit/dim 3.4997(3.5071) | Xent 0.0000(0.0000) | Loss 8.8755(9.6287) | Error 0.0000(0.0000) Steps 670(685.23) | Grad Norm 0.2879(0.3591) | Total Time 0.00(0.00)\n",
      "Iter 1703 | Time 68.5793(63.6569) | Bit/dim 3.5092(3.5072) | Xent 0.0000(0.0000) | Loss 8.8900(9.6065) | Error 0.0000(0.0000) Steps 706(685.86) | Grad Norm 0.3609(0.3592) | Total Time 0.00(0.00)\n",
      "Iter 1704 | Time 66.8342(63.7522) | Bit/dim 3.5066(3.5072) | Xent 0.0000(0.0000) | Loss 9.0878(9.5910) | Error 0.0000(0.0000) Steps 700(686.28) | Grad Norm 0.3307(0.3583) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0284 | Time 25.2728, Epoch Time 432.0822(417.0085), Bit/dim 3.5110(best: 3.5043), Xent 0.0000, Loss 3.5110, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1705 | Time 68.4095(63.8919) | Bit/dim 3.5030(3.5071) | Xent 0.0000(0.0000) | Loss 13.6260(9.7120) | Error 0.0000(0.0000) Steps 682(686.15) | Grad Norm 0.2911(0.3563) | Total Time 0.00(0.00)\n",
      "Iter 1706 | Time 70.1380(64.0793) | Bit/dim 3.5133(3.5072) | Xent 0.0000(0.0000) | Loss 8.8996(9.6877) | Error 0.0000(0.0000) Steps 712(686.93) | Grad Norm 0.3345(0.3557) | Total Time 0.00(0.00)\n",
      "Iter 1707 | Time 63.7764(64.0702) | Bit/dim 3.5036(3.5071) | Xent 0.0000(0.0000) | Loss 8.7293(9.6589) | Error 0.0000(0.0000) Steps 682(686.78) | Grad Norm 0.3670(0.3560) | Total Time 0.00(0.00)\n",
      "Iter 1708 | Time 63.0560(64.0398) | Bit/dim 3.5084(3.5072) | Xent 0.0000(0.0000) | Loss 9.0740(9.6414) | Error 0.0000(0.0000) Steps 706(687.36) | Grad Norm 0.3295(0.3552) | Total Time 0.00(0.00)\n",
      "Iter 1709 | Time 61.9189(63.9762) | Bit/dim 3.5117(3.5073) | Xent 0.0000(0.0000) | Loss 8.8151(9.6166) | Error 0.0000(0.0000) Steps 694(687.56) | Grad Norm 0.2716(0.3527) | Total Time 0.00(0.00)\n",
      "Iter 1710 | Time 62.1270(63.9207) | Bit/dim 3.4981(3.5070) | Xent 0.0000(0.0000) | Loss 8.6429(9.5874) | Error 0.0000(0.0000) Steps 676(687.21) | Grad Norm 0.3279(0.3520) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0285 | Time 25.3142, Epoch Time 430.6526(417.4179), Bit/dim 3.5071(best: 3.5043), Xent 0.0000, Loss 3.5071, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1711 | Time 65.4682(63.9671) | Bit/dim 3.5074(3.5070) | Xent 0.0000(0.0000) | Loss 13.6943(9.7106) | Error 0.0000(0.0000) Steps 724(688.31) | Grad Norm 0.3495(0.3519) | Total Time 0.00(0.00)\n",
      "Iter 1712 | Time 66.5347(64.0442) | Bit/dim 3.5078(3.5071) | Xent 0.0000(0.0000) | Loss 8.9519(9.6878) | Error 0.0000(0.0000) Steps 712(689.02) | Grad Norm 0.3744(0.3526) | Total Time 0.00(0.00)\n",
      "Iter 1713 | Time 62.5457(63.9992) | Bit/dim 3.4933(3.5066) | Xent 0.0000(0.0000) | Loss 8.8856(9.6637) | Error 0.0000(0.0000) Steps 694(689.17) | Grad Norm 0.2987(0.3509) | Total Time 0.00(0.00)\n",
      "Iter 1714 | Time 68.1178(64.1228) | Bit/dim 3.5137(3.5069) | Xent 0.0000(0.0000) | Loss 8.9216(9.6415) | Error 0.0000(0.0000) Steps 700(689.50) | Grad Norm 0.2418(0.3477) | Total Time 0.00(0.00)\n",
      "Iter 1715 | Time 63.0441(64.0904) | Bit/dim 3.5092(3.5069) | Xent 0.0000(0.0000) | Loss 8.8157(9.6167) | Error 0.0000(0.0000) Steps 700(689.81) | Grad Norm 0.4064(0.3494) | Total Time 0.00(0.00)\n",
      "Iter 1716 | Time 60.3956(63.9796) | Bit/dim 3.5037(3.5068) | Xent 0.0000(0.0000) | Loss 8.6823(9.5887) | Error 0.0000(0.0000) Steps 676(689.40) | Grad Norm 0.3850(0.3505) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0286 | Time 24.8511, Epoch Time 426.9599(417.7041), Bit/dim 3.5030(best: 3.5043), Xent 0.0000, Loss 3.5030, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1717 | Time 63.2467(63.9576) | Bit/dim 3.4961(3.5065) | Xent 0.0000(0.0000) | Loss 13.6733(9.7112) | Error 0.0000(0.0000) Steps 694(689.54) | Grad Norm 0.3219(0.3496) | Total Time 0.00(0.00)\n",
      "Iter 1718 | Time 60.7771(63.8622) | Bit/dim 3.5095(3.5066) | Xent 0.0000(0.0000) | Loss 8.8870(9.6865) | Error 0.0000(0.0000) Steps 688(689.49) | Grad Norm 0.3422(0.3494) | Total Time 0.00(0.00)\n",
      "Iter 1719 | Time 60.5595(63.7631) | Bit/dim 3.5062(3.5066) | Xent 0.0000(0.0000) | Loss 8.8711(9.6620) | Error 0.0000(0.0000) Steps 670(688.91) | Grad Norm 0.2929(0.3477) | Total Time 0.00(0.00)\n",
      "Iter 1720 | Time 63.9392(63.7684) | Bit/dim 3.5065(3.5066) | Xent 0.0000(0.0000) | Loss 8.7068(9.6334) | Error 0.0000(0.0000) Steps 682(688.70) | Grad Norm 0.3610(0.3481) | Total Time 0.00(0.00)\n",
      "Iter 1721 | Time 67.1037(63.8684) | Bit/dim 3.5070(3.5066) | Xent 0.0000(0.0000) | Loss 8.7266(9.6062) | Error 0.0000(0.0000) Steps 712(689.40) | Grad Norm 0.3884(0.3493) | Total Time 0.00(0.00)\n",
      "Iter 1722 | Time 70.2404(64.0596) | Bit/dim 3.4978(3.5063) | Xent 0.0000(0.0000) | Loss 8.7954(9.5818) | Error 0.0000(0.0000) Steps 718(690.26) | Grad Norm 0.3077(0.3481) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0287 | Time 25.3083, Epoch Time 427.3711(417.9941), Bit/dim 3.5155(best: 3.5030), Xent 0.0000, Loss 3.5155, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1723 | Time 62.4461(64.0112) | Bit/dim 3.5030(3.5062) | Xent 0.0000(0.0000) | Loss 13.3763(9.6957) | Error 0.0000(0.0000) Steps 688(690.19) | Grad Norm 0.4458(0.3510) | Total Time 0.00(0.00)\n",
      "Iter 1724 | Time 64.2715(64.0190) | Bit/dim 3.4919(3.5058) | Xent 0.0000(0.0000) | Loss 8.4389(9.6580) | Error 0.0000(0.0000) Steps 688(690.12) | Grad Norm 1.3128(0.3799) | Total Time 0.00(0.00)\n",
      "Iter 1725 | Time 63.5186(64.0040) | Bit/dim 3.5094(3.5059) | Xent 0.0000(0.0000) | Loss 8.9953(9.6381) | Error 0.0000(0.0000) Steps 688(690.06) | Grad Norm 0.4129(0.3809) | Total Time 0.00(0.00)\n",
      "Iter 1726 | Time 68.5478(64.1403) | Bit/dim 3.5008(3.5058) | Xent 0.0000(0.0000) | Loss 8.9918(9.6187) | Error 0.0000(0.0000) Steps 712(690.72) | Grad Norm 0.3560(0.3801) | Total Time 0.00(0.00)\n",
      "Iter 1727 | Time 64.9407(64.1643) | Bit/dim 3.5151(3.5060) | Xent 0.0000(0.0000) | Loss 8.7537(9.5928) | Error 0.0000(0.0000) Steps 670(690.10) | Grad Norm 0.3901(0.3804) | Total Time 0.00(0.00)\n",
      "Iter 1728 | Time 63.7372(64.1515) | Bit/dim 3.5108(3.5062) | Xent 0.0000(0.0000) | Loss 9.0723(9.5771) | Error 0.0000(0.0000) Steps 700(690.39) | Grad Norm 0.3909(0.3807) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0288 | Time 24.4726, Epoch Time 427.8744(418.2905), Bit/dim 3.5134(best: 3.5030), Xent 0.0000, Loss 3.5134, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1729 | Time 67.8631(64.2628) | Bit/dim 3.5144(3.5064) | Xent 0.0000(0.0000) | Loss 13.2882(9.6885) | Error 0.0000(0.0000) Steps 688(690.32) | Grad Norm 0.3900(0.3810) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 63.0627(64.2268) | Bit/dim 3.5029(3.5063) | Xent 0.0000(0.0000) | Loss 8.8759(9.6641) | Error 0.0000(0.0000) Steps 688(690.25) | Grad Norm 0.3826(0.3811) | Total Time 0.00(0.00)\n",
      "Iter 1731 | Time 62.2892(64.1687) | Bit/dim 3.5062(3.5063) | Xent 0.0000(0.0000) | Loss 8.8308(9.6391) | Error 0.0000(0.0000) Steps 700(690.54) | Grad Norm 0.3424(0.3799) | Total Time 0.00(0.00)\n",
      "Iter 1732 | Time 66.1125(64.2270) | Bit/dim 3.5169(3.5066) | Xent 0.0000(0.0000) | Loss 8.9330(9.6179) | Error 0.0000(0.0000) Steps 712(691.19) | Grad Norm 0.3440(0.3788) | Total Time 0.00(0.00)\n",
      "Iter 1733 | Time 69.0322(64.3712) | Bit/dim 3.4981(3.5064) | Xent 0.0000(0.0000) | Loss 8.8991(9.5963) | Error 0.0000(0.0000) Steps 718(691.99) | Grad Norm 0.2916(0.3762) | Total Time 0.00(0.00)\n",
      "Iter 1734 | Time 66.5320(64.4360) | Bit/dim 3.4994(3.5062) | Xent 0.0000(0.0000) | Loss 8.9377(9.5766) | Error 0.0000(0.0000) Steps 700(692.23) | Grad Norm 0.3334(0.3749) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0289 | Time 25.1418, Epoch Time 436.1502(418.8263), Bit/dim 3.5080(best: 3.5030), Xent 0.0000, Loss 3.5080, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1735 | Time 61.4305(64.3458) | Bit/dim 3.5142(3.5064) | Xent 0.0000(0.0000) | Loss 13.1617(9.6841) | Error 0.0000(0.0000) Steps 676(691.75) | Grad Norm 0.4158(0.3761) | Total Time 0.00(0.00)\n",
      "Iter 1736 | Time 60.9424(64.2437) | Bit/dim 3.5015(3.5063) | Xent 0.0000(0.0000) | Loss 8.6251(9.6524) | Error 0.0000(0.0000) Steps 682(691.45) | Grad Norm 0.4861(0.3794) | Total Time 0.00(0.00)\n",
      "Iter 1737 | Time 67.7221(64.3481) | Bit/dim 3.5031(3.5062) | Xent 0.0000(0.0000) | Loss 9.0417(9.6340) | Error 0.0000(0.0000) Steps 718(692.25) | Grad Norm 0.3507(0.3786) | Total Time 0.00(0.00)\n",
      "Iter 1738 | Time 63.0391(64.3088) | Bit/dim 3.5076(3.5062) | Xent 0.0000(0.0000) | Loss 8.9666(9.6140) | Error 0.0000(0.0000) Steps 688(692.12) | Grad Norm 0.3573(0.3779) | Total Time 0.00(0.00)\n",
      "Iter 1739 | Time 66.7996(64.3835) | Bit/dim 3.5060(3.5062) | Xent 0.0000(0.0000) | Loss 9.0182(9.5961) | Error 0.0000(0.0000) Steps 706(692.54) | Grad Norm 0.2465(0.3740) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 68.4240(64.5048) | Bit/dim 3.5018(3.5061) | Xent 0.0000(0.0000) | Loss 8.8103(9.5726) | Error 0.0000(0.0000) Steps 694(692.58) | Grad Norm 0.3804(0.3742) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0290 | Time 25.2008, Epoch Time 429.7758(419.1548), Bit/dim 3.5088(best: 3.5030), Xent 0.0000, Loss 3.5088, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1741 | Time 64.7694(64.5127) | Bit/dim 3.5012(3.5059) | Xent 0.0000(0.0000) | Loss 13.5366(9.6915) | Error 0.0000(0.0000) Steps 700(692.80) | Grad Norm 0.4284(0.3758) | Total Time 0.00(0.00)\n",
      "Iter 1742 | Time 69.0773(64.6496) | Bit/dim 3.5009(3.5058) | Xent 0.0000(0.0000) | Loss 8.8539(9.6664) | Error 0.0000(0.0000) Steps 706(693.20) | Grad Norm 0.3109(0.3739) | Total Time 0.00(0.00)\n",
      "Iter 1743 | Time 62.8844(64.5967) | Bit/dim 3.5127(3.5060) | Xent 0.0000(0.0000) | Loss 8.9680(9.6454) | Error 0.0000(0.0000) Steps 682(692.86) | Grad Norm 0.2570(0.3704) | Total Time 0.00(0.00)\n",
      "Iter 1744 | Time 62.1416(64.5230) | Bit/dim 3.5034(3.5059) | Xent 0.0000(0.0000) | Loss 8.8704(9.6222) | Error 0.0000(0.0000) Steps 670(692.18) | Grad Norm 0.2849(0.3678) | Total Time 0.00(0.00)\n",
      "Iter 1745 | Time 66.1619(64.5722) | Bit/dim 3.5048(3.5059) | Xent 0.0000(0.0000) | Loss 8.9771(9.6028) | Error 0.0000(0.0000) Steps 694(692.23) | Grad Norm 0.2602(0.3646) | Total Time 0.00(0.00)\n",
      "Iter 1746 | Time 61.0964(64.4679) | Bit/dim 3.5101(3.5060) | Xent 0.0000(0.0000) | Loss 8.6286(9.5736) | Error 0.0000(0.0000) Steps 646(690.85) | Grad Norm 0.7204(0.3752) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0291 | Time 25.7280, Epoch Time 427.7435(419.4125), Bit/dim 3.5073(best: 3.5030), Xent 0.0000, Loss 3.5073, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1747 | Time 69.0991(64.6068) | Bit/dim 3.5075(3.5060) | Xent 0.0000(0.0000) | Loss 13.9337(9.7044) | Error 0.0000(0.0000) Steps 724(691.84) | Grad Norm 0.3942(0.3758) | Total Time 0.00(0.00)\n",
      "Iter 1748 | Time 67.8449(64.7040) | Bit/dim 3.5186(3.5064) | Xent 0.0000(0.0000) | Loss 9.1560(9.6879) | Error 0.0000(0.0000) Steps 700(692.09) | Grad Norm 0.3562(0.3752) | Total Time 0.00(0.00)\n",
      "Iter 1749 | Time 60.4336(64.5759) | Bit/dim 3.4966(3.5061) | Xent 0.0000(0.0000) | Loss 8.7913(9.6610) | Error 0.0000(0.0000) Steps 682(691.78) | Grad Norm 0.4497(0.3775) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 69.2149(64.7150) | Bit/dim 3.4983(3.5059) | Xent 0.0000(0.0000) | Loss 8.7461(9.6336) | Error 0.0000(0.0000) Steps 718(692.57) | Grad Norm 0.3136(0.3755) | Total Time 0.00(0.00)\n",
      "Iter 1751 | Time 63.6807(64.6840) | Bit/dim 3.5149(3.5062) | Xent 0.0000(0.0000) | Loss 8.9527(9.6132) | Error 0.0000(0.0000) Steps 676(692.07) | Grad Norm 0.4925(0.3791) | Total Time 0.00(0.00)\n",
      "Iter 1752 | Time 65.7233(64.7152) | Bit/dim 3.5006(3.5060) | Xent 0.0000(0.0000) | Loss 8.8581(9.5905) | Error 0.0000(0.0000) Steps 706(692.49) | Grad Norm 0.3745(0.3789) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0292 | Time 25.3273, Epoch Time 437.0710(419.9422), Bit/dim 3.5095(best: 3.5030), Xent 0.0000, Loss 3.5095, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1753 | Time 66.9834(64.7832) | Bit/dim 3.4910(3.5055) | Xent 0.0000(0.0000) | Loss 13.7449(9.7151) | Error 0.0000(0.0000) Steps 736(693.80) | Grad Norm 0.4757(0.3818) | Total Time 0.00(0.00)\n",
      "Iter 1754 | Time 63.3266(64.7395) | Bit/dim 3.5159(3.5059) | Xent 0.0000(0.0000) | Loss 9.0825(9.6962) | Error 0.0000(0.0000) Steps 694(693.80) | Grad Norm 0.3132(0.3798) | Total Time 0.00(0.00)\n",
      "Iter 1755 | Time 61.7984(64.6513) | Bit/dim 3.5124(3.5060) | Xent 0.0000(0.0000) | Loss 8.9144(9.6727) | Error 0.0000(0.0000) Steps 682(693.45) | Grad Norm 0.3269(0.3782) | Total Time 0.00(0.00)\n",
      "Iter 1756 | Time 64.0125(64.6321) | Bit/dim 3.4996(3.5059) | Xent 0.0000(0.0000) | Loss 8.9654(9.6515) | Error 0.0000(0.0000) Steps 688(693.28) | Grad Norm 0.3873(0.3784) | Total Time 0.00(0.00)\n",
      "Iter 1757 | Time 61.2835(64.5317) | Bit/dim 3.5088(3.5059) | Xent 0.0000(0.0000) | Loss 8.8945(9.6288) | Error 0.0000(0.0000) Steps 688(693.13) | Grad Norm 0.4738(0.3813) | Total Time 0.00(0.00)\n",
      "Iter 1758 | Time 66.0588(64.5775) | Bit/dim 3.5063(3.5060) | Xent 0.0000(0.0000) | Loss 8.8584(9.6057) | Error 0.0000(0.0000) Steps 706(693.51) | Grad Norm 0.3923(0.3816) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0293 | Time 24.5005, Epoch Time 423.9867(420.0636), Bit/dim 3.5045(best: 3.5030), Xent 0.0000, Loss 3.5045, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1759 | Time 66.2093(64.6265) | Bit/dim 3.4964(3.5057) | Xent 0.0000(0.0000) | Loss 13.3720(9.7187) | Error 0.0000(0.0000) Steps 718(694.25) | Grad Norm 0.4140(0.3826) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 65.2748(64.6459) | Bit/dim 3.5151(3.5060) | Xent 0.0000(0.0000) | Loss 8.7756(9.6904) | Error 0.0000(0.0000) Steps 706(694.60) | Grad Norm 0.4577(0.3849) | Total Time 0.00(0.00)\n",
      "Iter 1761 | Time 66.5078(64.7018) | Bit/dim 3.5029(3.5059) | Xent 0.0000(0.0000) | Loss 9.0526(9.6712) | Error 0.0000(0.0000) Steps 718(695.30) | Grad Norm 0.2726(0.3815) | Total Time 0.00(0.00)\n",
      "Iter 1762 | Time 62.6485(64.6402) | Bit/dim 3.5052(3.5058) | Xent 0.0000(0.0000) | Loss 8.6106(9.6394) | Error 0.0000(0.0000) Steps 688(695.08) | Grad Norm 0.3699(0.3811) | Total Time 0.00(0.00)\n",
      "Iter 1763 | Time 65.1912(64.6567) | Bit/dim 3.4949(3.5055) | Xent 0.0000(0.0000) | Loss 8.9370(9.6183) | Error 0.0000(0.0000) Steps 688(694.87) | Grad Norm 0.3216(0.3794) | Total Time 0.00(0.00)\n",
      "Iter 1764 | Time 63.6323(64.6260) | Bit/dim 3.5077(3.5056) | Xent 0.0000(0.0000) | Loss 8.9352(9.5978) | Error 0.0000(0.0000) Steps 688(694.66) | Grad Norm 0.4058(0.3802) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0294 | Time 24.8955, Epoch Time 430.3059(420.3708), Bit/dim 3.5107(best: 3.5030), Xent 0.0000, Loss 3.5107, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1765 | Time 61.4325(64.5302) | Bit/dim 3.5188(3.5060) | Xent 0.0000(0.0000) | Loss 13.6163(9.7184) | Error 0.0000(0.0000) Steps 700(694.82) | Grad Norm 0.3914(0.3805) | Total Time 0.00(0.00)\n",
      "Iter 1766 | Time 68.1883(64.6399) | Bit/dim 3.5019(3.5059) | Xent 0.0000(0.0000) | Loss 8.9651(9.6958) | Error 0.0000(0.0000) Steps 718(695.52) | Grad Norm 0.3763(0.3804) | Total Time 0.00(0.00)\n",
      "Iter 1767 | Time 65.4544(64.6643) | Bit/dim 3.5080(3.5059) | Xent 0.0000(0.0000) | Loss 8.8937(9.6717) | Error 0.0000(0.0000) Steps 688(695.29) | Grad Norm 0.2837(0.3775) | Total Time 0.00(0.00)\n",
      "Iter 1768 | Time 68.6131(64.7828) | Bit/dim 3.5034(3.5058) | Xent 0.0000(0.0000) | Loss 9.0550(9.6532) | Error 0.0000(0.0000) Steps 718(695.97) | Grad Norm 0.2561(0.3738) | Total Time 0.00(0.00)\n",
      "Iter 1769 | Time 59.4571(64.6230) | Bit/dim 3.4917(3.5054) | Xent 0.0000(0.0000) | Loss 8.6939(9.6245) | Error 0.0000(0.0000) Steps 688(695.74) | Grad Norm 0.3427(0.3729) | Total Time 0.00(0.00)\n",
      "Iter 1770 | Time 61.5332(64.5303) | Bit/dim 3.5105(3.5056) | Xent 0.0000(0.0000) | Loss 8.7317(9.5977) | Error 0.0000(0.0000) Steps 688(695.50) | Grad Norm 0.4197(0.3743) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0295 | Time 25.3261, Epoch Time 426.2498(420.5472), Bit/dim 3.5101(best: 3.5030), Xent 0.0000, Loss 3.5101, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1771 | Time 63.8671(64.5104) | Bit/dim 3.5090(3.5057) | Xent 0.0000(0.0000) | Loss 13.4708(9.7139) | Error 0.0000(0.0000) Steps 688(695.28) | Grad Norm 0.4944(0.3779) | Total Time 0.00(0.00)\n",
      "Iter 1772 | Time 69.0506(64.6466) | Bit/dim 3.5033(3.5056) | Xent 0.0000(0.0000) | Loss 8.9802(9.6919) | Error 0.0000(0.0000) Steps 700(695.42) | Grad Norm 0.3284(0.3764) | Total Time 0.00(0.00)\n",
      "Iter 1773 | Time 62.1550(64.5719) | Bit/dim 3.5018(3.5055) | Xent 0.0000(0.0000) | Loss 8.8939(9.6679) | Error 0.0000(0.0000) Steps 688(695.20) | Grad Norm 0.2979(0.3741) | Total Time 0.00(0.00)\n",
      "Iter 1774 | Time 66.5468(64.6311) | Bit/dim 3.4959(3.5052) | Xent 0.0000(0.0000) | Loss 8.8060(9.6421) | Error 0.0000(0.0000) Steps 688(694.98) | Grad Norm 0.4179(0.3754) | Total Time 0.00(0.00)\n",
      "Iter 1775 | Time 63.7499(64.6047) | Bit/dim 3.5022(3.5051) | Xent 0.0000(0.0000) | Loss 9.0349(9.6238) | Error 0.0000(0.0000) Steps 712(695.49) | Grad Norm 0.3185(0.3737) | Total Time 0.00(0.00)\n",
      "Iter 1776 | Time 64.9589(64.6153) | Bit/dim 3.5001(3.5050) | Xent 0.0000(0.0000) | Loss 8.9709(9.6043) | Error 0.0000(0.0000) Steps 712(695.99) | Grad Norm 0.2639(0.3704) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0296 | Time 25.5656, Epoch Time 432.0660(420.8928), Bit/dim 3.5089(best: 3.5030), Xent 0.0000, Loss 3.5089, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1777 | Time 65.5628(64.6438) | Bit/dim 3.5154(3.5053) | Xent 0.0000(0.0000) | Loss 13.4625(9.7200) | Error 0.0000(0.0000) Steps 700(696.11) | Grad Norm 0.3434(0.3696) | Total Time 0.00(0.00)\n",
      "Iter 1778 | Time 65.3107(64.6638) | Bit/dim 3.5035(3.5052) | Xent 0.0000(0.0000) | Loss 9.1071(9.7016) | Error 0.0000(0.0000) Steps 706(696.40) | Grad Norm 0.2833(0.3670) | Total Time 0.00(0.00)\n",
      "Iter 1779 | Time 66.5225(64.7195) | Bit/dim 3.5114(3.5054) | Xent 0.0000(0.0000) | Loss 8.6338(9.6696) | Error 0.0000(0.0000) Steps 694(696.33) | Grad Norm 0.4711(0.3701) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 61.7609(64.6308) | Bit/dim 3.4961(3.5051) | Xent 0.0000(0.0000) | Loss 8.7358(9.6416) | Error 0.0000(0.0000) Steps 694(696.26) | Grad Norm 0.5428(0.3753) | Total Time 0.00(0.00)\n",
      "Iter 1781 | Time 67.6588(64.7216) | Bit/dim 3.5054(3.5051) | Xent 0.0000(0.0000) | Loss 8.6407(9.6115) | Error 0.0000(0.0000) Steps 712(696.73) | Grad Norm 0.3764(0.3753) | Total Time 0.00(0.00)\n",
      "Iter 1782 | Time 67.2787(64.7983) | Bit/dim 3.5056(3.5051) | Xent 0.0000(0.0000) | Loss 8.9679(9.5922) | Error 0.0000(0.0000) Steps 694(696.65) | Grad Norm 0.3437(0.3744) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0297 | Time 24.9746, Epoch Time 435.3163(421.3255), Bit/dim 3.5043(best: 3.5030), Xent 0.0000, Loss 3.5043, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1783 | Time 65.0967(64.8073) | Bit/dim 3.4909(3.5047) | Xent 0.0000(0.0000) | Loss 13.3045(9.7036) | Error 0.0000(0.0000) Steps 694(696.57) | Grad Norm 0.4368(0.3762) | Total Time 0.00(0.00)\n",
      "Iter 1784 | Time 61.3384(64.7032) | Bit/dim 3.5052(3.5047) | Xent 0.0000(0.0000) | Loss 8.7744(9.6757) | Error 0.0000(0.0000) Steps 676(695.96) | Grad Norm 0.4399(0.3782) | Total Time 0.00(0.00)\n",
      "Iter 1785 | Time 63.7891(64.6758) | Bit/dim 3.4992(3.5046) | Xent 0.0000(0.0000) | Loss 8.9891(9.6551) | Error 0.0000(0.0000) Steps 700(696.08) | Grad Norm 0.3294(0.3767) | Total Time 0.00(0.00)\n",
      "Iter 1786 | Time 65.7343(64.7075) | Bit/dim 3.5201(3.5050) | Xent 0.0000(0.0000) | Loss 9.0053(9.6356) | Error 0.0000(0.0000) Steps 700(696.19) | Grad Norm 0.4485(0.3788) | Total Time 0.00(0.00)\n",
      "Iter 1787 | Time 61.0492(64.5978) | Bit/dim 3.5030(3.5050) | Xent 0.0000(0.0000) | Loss 8.8641(9.6125) | Error 0.0000(0.0000) Steps 718(696.85) | Grad Norm 0.3206(0.3771) | Total Time 0.00(0.00)\n",
      "Iter 1788 | Time 63.0821(64.5523) | Bit/dim 3.5112(3.5052) | Xent 0.0000(0.0000) | Loss 8.8922(9.5909) | Error 0.0000(0.0000) Steps 688(696.58) | Grad Norm 0.5657(0.3828) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0298 | Time 25.0872, Epoch Time 421.0211(421.3163), Bit/dim 3.5128(best: 3.5030), Xent 0.0000, Loss 3.5128, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1789 | Time 66.0120(64.5961) | Bit/dim 3.4955(3.5049) | Xent 0.0000(0.0000) | Loss 13.4867(9.7077) | Error 0.0000(0.0000) Steps 718(697.23) | Grad Norm 0.4886(0.3859) | Total Time 0.00(0.00)\n",
      "Iter 1790 | Time 64.5561(64.5949) | Bit/dim 3.5046(3.5049) | Xent 0.0000(0.0000) | Loss 8.8931(9.6833) | Error 0.0000(0.0000) Steps 682(696.77) | Grad Norm 0.4366(0.3875) | Total Time 0.00(0.00)\n",
      "Iter 1791 | Time 66.4171(64.6496) | Bit/dim 3.5051(3.5049) | Xent 0.0000(0.0000) | Loss 8.8650(9.6588) | Error 0.0000(0.0000) Steps 694(696.69) | Grad Norm 0.4347(0.3889) | Total Time 0.00(0.00)\n",
      "Iter 1792 | Time 64.5254(64.6458) | Bit/dim 3.4994(3.5047) | Xent 0.0000(0.0000) | Loss 8.9208(9.6366) | Error 0.0000(0.0000) Steps 706(696.97) | Grad Norm 0.3115(0.3865) | Total Time 0.00(0.00)\n",
      "Iter 1793 | Time 68.6519(64.7660) | Bit/dim 3.5163(3.5051) | Xent 0.0000(0.0000) | Loss 8.8438(9.6128) | Error 0.0000(0.0000) Steps 730(697.96) | Grad Norm 0.4710(0.3891) | Total Time 0.00(0.00)\n",
      "Iter 1794 | Time 64.5899(64.7607) | Bit/dim 3.5103(3.5052) | Xent 0.0000(0.0000) | Loss 8.9842(9.5940) | Error 0.0000(0.0000) Steps 718(698.56) | Grad Norm 0.3756(0.3887) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0299 | Time 25.2767, Epoch Time 435.6555(421.7465), Bit/dim 3.5064(best: 3.5030), Xent 0.0000, Loss 3.5064, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1795 | Time 68.2947(64.8668) | Bit/dim 3.4875(3.5047) | Xent 0.0000(0.0000) | Loss 13.0821(9.6986) | Error 0.0000(0.0000) Steps 700(698.60) | Grad Norm 0.4597(0.3908) | Total Time 0.00(0.00)\n",
      "Iter 1796 | Time 65.9606(64.8996) | Bit/dim 3.5052(3.5047) | Xent 0.0000(0.0000) | Loss 8.6226(9.6663) | Error 0.0000(0.0000) Steps 706(698.82) | Grad Norm 0.3917(0.3908) | Total Time 0.00(0.00)\n",
      "Iter 1797 | Time 62.1187(64.8162) | Bit/dim 3.5076(3.5048) | Xent 0.0000(0.0000) | Loss 8.7733(9.6396) | Error 0.0000(0.0000) Steps 688(698.50) | Grad Norm 0.4879(0.3937) | Total Time 0.00(0.00)\n",
      "Iter 1798 | Time 65.0785(64.8240) | Bit/dim 3.5112(3.5050) | Xent 0.0000(0.0000) | Loss 9.0707(9.6225) | Error 0.0000(0.0000) Steps 700(698.54) | Grad Norm 0.3363(0.3920) | Total Time 0.00(0.00)\n",
      "Iter 1799 | Time 64.5894(64.8170) | Bit/dim 3.4972(3.5047) | Xent 0.0000(0.0000) | Loss 8.9077(9.6010) | Error 0.0000(0.0000) Steps 718(699.13) | Grad Norm 0.4638(0.3942) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 68.1968(64.9184) | Bit/dim 3.5078(3.5048) | Xent 0.0000(0.0000) | Loss 8.9927(9.5828) | Error 0.0000(0.0000) Steps 706(699.33) | Grad Norm 0.5092(0.3976) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0300 | Time 25.1198, Epoch Time 436.2331(422.1811), Bit/dim 3.5040(best: 3.5030), Xent 0.0000, Loss 3.5040, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1801 | Time 61.8287(64.8257) | Bit/dim 3.4923(3.5045) | Xent 0.0000(0.0000) | Loss 12.9972(9.6852) | Error 0.0000(0.0000) Steps 694(699.17) | Grad Norm 0.4715(0.3998) | Total Time 0.00(0.00)\n",
      "Iter 1802 | Time 63.1773(64.7762) | Bit/dim 3.5019(3.5044) | Xent 0.0000(0.0000) | Loss 8.8181(9.6592) | Error 0.0000(0.0000) Steps 676(698.48) | Grad Norm 0.6174(0.4064) | Total Time 0.00(0.00)\n",
      "Iter 1803 | Time 62.8827(64.7194) | Bit/dim 3.5101(3.5046) | Xent 0.0000(0.0000) | Loss 8.9605(9.6382) | Error 0.0000(0.0000) Steps 694(698.34) | Grad Norm 0.3909(0.4059) | Total Time 0.00(0.00)\n",
      "Iter 1804 | Time 62.3265(64.6476) | Bit/dim 3.5044(3.5045) | Xent 0.0000(0.0000) | Loss 8.9458(9.6175) | Error 0.0000(0.0000) Steps 712(698.75) | Grad Norm 0.6017(0.4118) | Total Time 0.00(0.00)\n",
      "Iter 1805 | Time 62.4285(64.5811) | Bit/dim 3.5127(3.5048) | Xent 0.0000(0.0000) | Loss 8.8358(9.5940) | Error 0.0000(0.0000) Steps 700(698.79) | Grad Norm 0.3757(0.4107) | Total Time 0.00(0.00)\n",
      "Iter 1806 | Time 67.7892(64.6773) | Bit/dim 3.5001(3.5047) | Xent 0.0000(0.0000) | Loss 8.8978(9.5731) | Error 0.0000(0.0000) Steps 724(699.55) | Grad Norm 0.7217(0.4200) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0301 | Time 24.7520, Epoch Time 421.4755(422.1599), Bit/dim 3.5068(best: 3.5030), Xent 0.0000, Loss 3.5068, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1807 | Time 65.9838(64.7165) | Bit/dim 3.5049(3.5047) | Xent 0.0000(0.0000) | Loss 13.0593(9.6777) | Error 0.0000(0.0000) Steps 712(699.92) | Grad Norm 0.7464(0.4298) | Total Time 0.00(0.00)\n",
      "Iter 1808 | Time 66.0570(64.7567) | Bit/dim 3.5098(3.5048) | Xent 0.0000(0.0000) | Loss 9.0838(9.6599) | Error 0.0000(0.0000) Steps 724(700.64) | Grad Norm 0.7888(0.4406) | Total Time 0.00(0.00)\n",
      "Iter 1809 | Time 66.3968(64.8059) | Bit/dim 3.5025(3.5047) | Xent 0.0000(0.0000) | Loss 9.0263(9.6409) | Error 0.0000(0.0000) Steps 706(700.80) | Grad Norm 0.4164(0.4399) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 64.4918(64.7965) | Bit/dim 3.5060(3.5048) | Xent 0.0000(0.0000) | Loss 8.8522(9.6172) | Error 0.0000(0.0000) Steps 682(700.24) | Grad Norm 0.6387(0.4458) | Total Time 0.00(0.00)\n",
      "Iter 1811 | Time 64.9846(64.8021) | Bit/dim 3.4951(3.5045) | Xent 0.0000(0.0000) | Loss 8.9681(9.5978) | Error 0.0000(0.0000) Steps 706(700.41) | Grad Norm 0.5963(0.4503) | Total Time 0.00(0.00)\n",
      "Iter 1812 | Time 65.9855(64.8376) | Bit/dim 3.5089(3.5046) | Xent 0.0000(0.0000) | Loss 8.7339(9.5718) | Error 0.0000(0.0000) Steps 706(700.58) | Grad Norm 0.6737(0.4570) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0302 | Time 24.9042, Epoch Time 434.8836(422.5417), Bit/dim 3.5075(best: 3.5030), Xent 0.0000, Loss 3.5075, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1813 | Time 60.9089(64.7198) | Bit/dim 3.4998(3.5045) | Xent 0.0000(0.0000) | Loss 13.5889(9.6924) | Error 0.0000(0.0000) Steps 694(700.38) | Grad Norm 0.8269(0.4681) | Total Time 0.00(0.00)\n",
      "Iter 1814 | Time 65.8309(64.7531) | Bit/dim 3.5034(3.5044) | Xent 0.0000(0.0000) | Loss 8.9792(9.6710) | Error 0.0000(0.0000) Steps 676(699.65) | Grad Norm 0.5043(0.4692) | Total Time 0.00(0.00)\n",
      "Iter 1815 | Time 65.2898(64.7692) | Bit/dim 3.5066(3.5045) | Xent 0.0000(0.0000) | Loss 8.8951(9.6477) | Error 0.0000(0.0000) Steps 706(699.84) | Grad Norm 0.6656(0.4751) | Total Time 0.00(0.00)\n",
      "Iter 1816 | Time 68.1795(64.8715) | Bit/dim 3.5094(3.5047) | Xent 0.0000(0.0000) | Loss 9.0246(9.6290) | Error 0.0000(0.0000) Steps 730(700.75) | Grad Norm 0.3981(0.4728) | Total Time 0.00(0.00)\n",
      "Iter 1817 | Time 66.7688(64.9284) | Bit/dim 3.4938(3.5043) | Xent 0.0000(0.0000) | Loss 8.9267(9.6079) | Error 0.0000(0.0000) Steps 718(701.26) | Grad Norm 0.6659(0.4786) | Total Time 0.00(0.00)\n",
      "Iter 1818 | Time 61.5577(64.8273) | Bit/dim 3.5099(3.5045) | Xent 0.0000(0.0000) | Loss 8.8644(9.5856) | Error 0.0000(0.0000) Steps 688(700.87) | Grad Norm 0.3407(0.4745) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0303 | Time 25.2554, Epoch Time 430.0495(422.7669), Bit/dim 3.4994(best: 3.5030), Xent 0.0000, Loss 3.4994, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1819 | Time 67.0340(64.8935) | Bit/dim 3.5020(3.5044) | Xent 0.0000(0.0000) | Loss 13.8482(9.7135) | Error 0.0000(0.0000) Steps 718(701.38) | Grad Norm 0.6564(0.4799) | Total Time 0.00(0.00)\n",
      "Iter 1820 | Time 66.5388(64.9429) | Bit/dim 3.5021(3.5044) | Xent 0.0000(0.0000) | Loss 8.9074(9.6893) | Error 0.0000(0.0000) Steps 694(701.16) | Grad Norm 0.3473(0.4759) | Total Time 0.00(0.00)\n",
      "Iter 1821 | Time 68.2148(65.0410) | Bit/dim 3.4920(3.5040) | Xent 0.0000(0.0000) | Loss 8.8022(9.6627) | Error 0.0000(0.0000) Steps 724(701.84) | Grad Norm 0.5928(0.4794) | Total Time 0.00(0.00)\n",
      "Iter 1822 | Time 70.1287(65.1937) | Bit/dim 3.5077(3.5041) | Xent 0.0000(0.0000) | Loss 8.9028(9.6399) | Error 0.0000(0.0000) Steps 730(702.69) | Grad Norm 0.3217(0.4747) | Total Time 0.00(0.00)\n",
      "Iter 1823 | Time 68.2135(65.2843) | Bit/dim 3.5070(3.5042) | Xent 0.0000(0.0000) | Loss 9.0113(9.6210) | Error 0.0000(0.0000) Steps 706(702.79) | Grad Norm 0.5331(0.4765) | Total Time 0.00(0.00)\n",
      "Iter 1824 | Time 64.7065(65.2669) | Bit/dim 3.5101(3.5044) | Xent 0.0000(0.0000) | Loss 8.7564(9.5951) | Error 0.0000(0.0000) Steps 676(701.98) | Grad Norm 0.3722(0.4733) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0304 | Time 25.2926, Epoch Time 446.1452(423.4682), Bit/dim 3.5090(best: 3.4994), Xent 0.0000, Loss 3.5090, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1825 | Time 65.2955(65.2678) | Bit/dim 3.4981(3.5042) | Xent 0.0000(0.0000) | Loss 13.1709(9.7024) | Error 0.0000(0.0000) Steps 700(701.92) | Grad Norm 0.6512(0.4787) | Total Time 0.00(0.00)\n",
      "Iter 1826 | Time 64.6157(65.2482) | Bit/dim 3.5112(3.5044) | Xent 0.0000(0.0000) | Loss 9.0058(9.6815) | Error 0.0000(0.0000) Steps 706(702.05) | Grad Norm 0.3130(0.4737) | Total Time 0.00(0.00)\n",
      "Iter 1827 | Time 64.6983(65.2317) | Bit/dim 3.4974(3.5042) | Xent 0.0000(0.0000) | Loss 8.7980(9.6550) | Error 0.0000(0.0000) Steps 706(702.17) | Grad Norm 0.4702(0.4736) | Total Time 0.00(0.00)\n",
      "Iter 1828 | Time 66.3320(65.2647) | Bit/dim 3.5085(3.5043) | Xent 0.0000(0.0000) | Loss 8.7901(9.6290) | Error 0.0000(0.0000) Steps 706(702.28) | Grad Norm 0.4124(0.4718) | Total Time 0.00(0.00)\n",
      "Iter 1829 | Time 65.9386(65.2849) | Bit/dim 3.5041(3.5043) | Xent 0.0000(0.0000) | Loss 8.8939(9.6070) | Error 0.0000(0.0000) Steps 694(702.03) | Grad Norm 0.5172(0.4731) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 63.6921(65.2372) | Bit/dim 3.5073(3.5044) | Xent 0.0000(0.0000) | Loss 8.9217(9.5864) | Error 0.0000(0.0000) Steps 724(702.69) | Grad Norm 0.4195(0.4715) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0305 | Time 25.3636, Epoch Time 431.9697(423.7233), Bit/dim 3.5073(best: 3.4994), Xent 0.0000, Loss 3.5073, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1831 | Time 64.3968(65.2120) | Bit/dim 3.4999(3.5043) | Xent 0.0000(0.0000) | Loss 13.3811(9.7003) | Error 0.0000(0.0000) Steps 688(702.25) | Grad Norm 0.3992(0.4693) | Total Time 0.00(0.00)\n",
      "Iter 1832 | Time 63.6380(65.1647) | Bit/dim 3.5051(3.5043) | Xent 0.0000(0.0000) | Loss 8.9917(9.6790) | Error 0.0000(0.0000) Steps 712(702.54) | Grad Norm 0.4458(0.4686) | Total Time 0.00(0.00)\n",
      "Iter 1833 | Time 69.4197(65.2924) | Bit/dim 3.5034(3.5043) | Xent 0.0000(0.0000) | Loss 8.9804(9.6580) | Error 0.0000(0.0000) Steps 724(703.19) | Grad Norm 0.3762(0.4659) | Total Time 0.00(0.00)\n",
      "Iter 1834 | Time 64.7037(65.2747) | Bit/dim 3.4959(3.5040) | Xent 0.0000(0.0000) | Loss 8.9437(9.6366) | Error 0.0000(0.0000) Steps 706(703.27) | Grad Norm 0.3639(0.4628) | Total Time 0.00(0.00)\n",
      "Iter 1835 | Time 65.9185(65.2940) | Bit/dim 3.4935(3.5037) | Xent 0.0000(0.0000) | Loss 8.7911(9.6113) | Error 0.0000(0.0000) Steps 694(702.99) | Grad Norm 0.3206(0.4585) | Total Time 0.00(0.00)\n",
      "Iter 1836 | Time 66.9854(65.3448) | Bit/dim 3.5169(3.5041) | Xent 0.0000(0.0000) | Loss 9.0258(9.5937) | Error 0.0000(0.0000) Steps 712(703.26) | Grad Norm 0.4429(0.4581) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0306 | Time 24.9544, Epoch Time 435.9369(424.0897), Bit/dim 3.5090(best: 3.4994), Xent 0.0000, Loss 3.5090, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1837 | Time 70.1889(65.4901) | Bit/dim 3.4965(3.5039) | Xent 0.0000(0.0000) | Loss 13.8448(9.7212) | Error 0.0000(0.0000) Steps 730(704.07) | Grad Norm 0.3599(0.4551) | Total Time 0.00(0.00)\n",
      "Iter 1838 | Time 61.8134(65.3798) | Bit/dim 3.5055(3.5039) | Xent 0.0000(0.0000) | Loss 8.3238(9.6793) | Error 0.0000(0.0000) Steps 676(703.22) | Grad Norm 0.7059(0.4627) | Total Time 0.00(0.00)\n",
      "Iter 1839 | Time 66.8023(65.4225) | Bit/dim 3.5063(3.5040) | Xent 0.0000(0.0000) | Loss 8.9486(9.6574) | Error 0.0000(0.0000) Steps 724(703.85) | Grad Norm 0.4969(0.4637) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 68.4269(65.5126) | Bit/dim 3.5052(3.5040) | Xent 0.0000(0.0000) | Loss 8.7909(9.6314) | Error 0.0000(0.0000) Steps 700(703.73) | Grad Norm 0.4873(0.4644) | Total Time 0.00(0.00)\n",
      "Iter 1841 | Time 65.9740(65.5265) | Bit/dim 3.5043(3.5040) | Xent 0.0000(0.0000) | Loss 8.9587(9.6112) | Error 0.0000(0.0000) Steps 712(703.98) | Grad Norm 0.4643(0.4644) | Total Time 0.00(0.00)\n",
      "Iter 1842 | Time 67.2919(65.5794) | Bit/dim 3.5067(3.5041) | Xent 0.0000(0.0000) | Loss 8.6924(9.5836) | Error 0.0000(0.0000) Steps 742(705.12) | Grad Norm 0.3991(0.4624) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0307 | Time 25.1429, Epoch Time 441.4285(424.6099), Bit/dim 3.5079(best: 3.4994), Xent 0.0000, Loss 3.5079, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1843 | Time 65.1051(65.5652) | Bit/dim 3.5093(3.5043) | Xent 0.0000(0.0000) | Loss 13.5807(9.7036) | Error 0.0000(0.0000) Steps 700(704.97) | Grad Norm 0.5393(0.4647) | Total Time 0.00(0.00)\n",
      "Iter 1844 | Time 67.4811(65.6227) | Bit/dim 3.5096(3.5044) | Xent 0.0000(0.0000) | Loss 8.9194(9.6800) | Error 0.0000(0.0000) Steps 730(705.72) | Grad Norm 0.4288(0.4637) | Total Time 0.00(0.00)\n",
      "Iter 1845 | Time 64.7342(65.5960) | Bit/dim 3.4911(3.5040) | Xent 0.0000(0.0000) | Loss 8.8193(9.6542) | Error 0.0000(0.0000) Steps 700(705.55) | Grad Norm 0.4195(0.4623) | Total Time 0.00(0.00)\n",
      "Iter 1846 | Time 70.3462(65.7385) | Bit/dim 3.5100(3.5042) | Xent 0.0000(0.0000) | Loss 8.8713(9.6307) | Error 0.0000(0.0000) Steps 736(706.46) | Grad Norm 0.3094(0.4577) | Total Time 0.00(0.00)\n",
      "Iter 1847 | Time 65.4641(65.7303) | Bit/dim 3.4996(3.5041) | Xent 0.0000(0.0000) | Loss 8.8983(9.6087) | Error 0.0000(0.0000) Steps 712(706.63) | Grad Norm 0.4874(0.4586) | Total Time 0.00(0.00)\n",
      "Iter 1848 | Time 67.3184(65.7779) | Bit/dim 3.5092(3.5042) | Xent 0.0000(0.0000) | Loss 8.8870(9.5871) | Error 0.0000(0.0000) Steps 700(706.43) | Grad Norm 0.4079(0.4571) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0308 | Time 25.2986, Epoch Time 441.6735(425.1218), Bit/dim 3.5048(best: 3.4994), Xent 0.0000, Loss 3.5048, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1849 | Time 68.4249(65.8573) | Bit/dim 3.4988(3.5041) | Xent 0.0000(0.0000) | Loss 13.4718(9.7036) | Error 0.0000(0.0000) Steps 712(706.59) | Grad Norm 0.4075(0.4556) | Total Time 0.00(0.00)\n",
      "Iter 1850 | Time 69.0885(65.9543) | Bit/dim 3.5147(3.5044) | Xent 0.0000(0.0000) | Loss 9.0927(9.6853) | Error 0.0000(0.0000) Steps 712(706.76) | Grad Norm 0.4189(0.4545) | Total Time 0.00(0.00)\n",
      "Iter 1851 | Time 69.6141(66.0641) | Bit/dim 3.4965(3.5041) | Xent 0.0000(0.0000) | Loss 8.8970(9.6617) | Error 0.0000(0.0000) Steps 700(706.55) | Grad Norm 0.3898(0.4526) | Total Time 0.00(0.00)\n",
      "Iter 1852 | Time 73.0084(66.2724) | Bit/dim 3.4946(3.5039) | Xent 0.0000(0.0000) | Loss 9.0738(9.6440) | Error 0.0000(0.0000) Steps 748(707.80) | Grad Norm 0.4714(0.4531) | Total Time 0.00(0.00)\n",
      "Iter 1853 | Time 62.9853(66.1738) | Bit/dim 3.4970(3.5036) | Xent 0.0000(0.0000) | Loss 8.7265(9.6165) | Error 0.0000(0.0000) Steps 700(707.56) | Grad Norm 0.4125(0.4519) | Total Time 0.00(0.00)\n",
      "Iter 1854 | Time 66.6737(66.1888) | Bit/dim 3.5069(3.5037) | Xent 0.0000(0.0000) | Loss 9.0605(9.5998) | Error 0.0000(0.0000) Steps 718(707.88) | Grad Norm 0.3440(0.4487) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0309 | Time 25.1503, Epoch Time 450.7919(425.8919), Bit/dim 3.5042(best: 3.4994), Xent 0.0000, Loss 3.5042, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1855 | Time 67.0697(66.2152) | Bit/dim 3.5028(3.5037) | Xent 0.0000(0.0000) | Loss 13.6890(9.7225) | Error 0.0000(0.0000) Steps 706(707.82) | Grad Norm 0.3890(0.4469) | Total Time 0.00(0.00)\n",
      "Iter 1856 | Time 65.5381(66.1949) | Bit/dim 3.5007(3.5036) | Xent 0.0000(0.0000) | Loss 8.7922(9.6946) | Error 0.0000(0.0000) Steps 682(707.05) | Grad Norm 0.3907(0.4452) | Total Time 0.00(0.00)\n",
      "Iter 1857 | Time 63.0751(66.1013) | Bit/dim 3.5005(3.5035) | Xent 0.0000(0.0000) | Loss 8.9821(9.6732) | Error 0.0000(0.0000) Steps 718(707.37) | Grad Norm 0.4612(0.4457) | Total Time 0.00(0.00)\n",
      "Iter 1858 | Time 63.7164(66.0298) | Bit/dim 3.5049(3.5036) | Xent 0.0000(0.0000) | Loss 8.9142(9.6504) | Error 0.0000(0.0000) Steps 712(707.51) | Grad Norm 0.3236(0.4420) | Total Time 0.00(0.00)\n",
      "Iter 1859 | Time 65.6545(66.0185) | Bit/dim 3.4923(3.5032) | Xent 0.0000(0.0000) | Loss 8.7644(9.6239) | Error 0.0000(0.0000) Steps 700(707.29) | Grad Norm 0.3893(0.4404) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 67.0102(66.0482) | Bit/dim 3.5112(3.5035) | Xent 0.0000(0.0000) | Loss 9.0240(9.6059) | Error 0.0000(0.0000) Steps 706(707.25) | Grad Norm 0.3371(0.4373) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0310 | Time 25.5857, Epoch Time 434.3379(426.1453), Bit/dim 3.5005(best: 3.4994), Xent 0.0000, Loss 3.5005, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1861 | Time 68.3127(66.1162) | Bit/dim 3.4986(3.5033) | Xent 0.0000(0.0000) | Loss 13.4406(9.7209) | Error 0.0000(0.0000) Steps 730(707.93) | Grad Norm 0.3721(0.4354) | Total Time 0.00(0.00)\n",
      "Iter 1862 | Time 66.5810(66.1301) | Bit/dim 3.5038(3.5033) | Xent 0.0000(0.0000) | Loss 8.8582(9.6950) | Error 0.0000(0.0000) Steps 694(707.51) | Grad Norm 0.3697(0.4334) | Total Time 0.00(0.00)\n",
      "Iter 1863 | Time 62.6123(66.0246) | Bit/dim 3.5187(3.5038) | Xent 0.0000(0.0000) | Loss 8.8999(9.6712) | Error 0.0000(0.0000) Steps 700(707.29) | Grad Norm 0.3486(0.4309) | Total Time 0.00(0.00)\n",
      "Iter 1864 | Time 64.4288(65.9767) | Bit/dim 3.4916(3.5034) | Xent 0.0000(0.0000) | Loss 8.9100(9.6483) | Error 0.0000(0.0000) Steps 694(706.89) | Grad Norm 0.3580(0.4287) | Total Time 0.00(0.00)\n",
      "Iter 1865 | Time 69.3534(66.0780) | Bit/dim 3.4986(3.5033) | Xent 0.0000(0.0000) | Loss 8.8486(9.6243) | Error 0.0000(0.0000) Steps 700(706.68) | Grad Norm 0.3794(0.4272) | Total Time 0.00(0.00)\n",
      "Iter 1866 | Time 65.4593(66.0595) | Bit/dim 3.4997(3.5032) | Xent 0.0000(0.0000) | Loss 8.8933(9.6024) | Error 0.0000(0.0000) Steps 688(706.12) | Grad Norm 0.2796(0.4228) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0311 | Time 25.3288, Epoch Time 438.2332(426.5079), Bit/dim 3.5082(best: 3.4994), Xent 0.0000, Loss 3.5082, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1867 | Time 71.8963(66.2346) | Bit/dim 3.5029(3.5032) | Xent 0.0000(0.0000) | Loss 13.5483(9.7208) | Error 0.0000(0.0000) Steps 718(706.48) | Grad Norm 0.4216(0.4227) | Total Time 0.00(0.00)\n",
      "Iter 1868 | Time 63.9215(66.1652) | Bit/dim 3.5052(3.5032) | Xent 0.0000(0.0000) | Loss 8.9106(9.6965) | Error 0.0000(0.0000) Steps 682(705.74) | Grad Norm 0.3807(0.4215) | Total Time 0.00(0.00)\n",
      "Iter 1869 | Time 61.1871(66.0158) | Bit/dim 3.5073(3.5034) | Xent 0.0000(0.0000) | Loss 8.9317(9.6735) | Error 0.0000(0.0000) Steps 676(704.85) | Grad Norm 0.3741(0.4201) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 66.3400(66.0256) | Bit/dim 3.4984(3.5032) | Xent 0.0000(0.0000) | Loss 8.9043(9.6505) | Error 0.0000(0.0000) Steps 706(704.89) | Grad Norm 0.3625(0.4183) | Total Time 0.00(0.00)\n",
      "Iter 1871 | Time 65.4512(66.0083) | Bit/dim 3.5113(3.5035) | Xent 0.0000(0.0000) | Loss 8.5509(9.6175) | Error 0.0000(0.0000) Steps 700(704.74) | Grad Norm 0.4381(0.4189) | Total Time 0.00(0.00)\n",
      "Iter 1872 | Time 62.5761(65.9054) | Bit/dim 3.4925(3.5031) | Xent 0.0000(0.0000) | Loss 8.7953(9.5928) | Error 0.0000(0.0000) Steps 682(704.06) | Grad Norm 0.3082(0.4156) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0312 | Time 25.5143, Epoch Time 433.0076(426.7029), Bit/dim 3.5030(best: 3.4994), Xent 0.0000, Loss 3.5030, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1873 | Time 64.8383(65.8733) | Bit/dim 3.4870(3.5026) | Xent 0.0000(0.0000) | Loss 13.1396(9.6992) | Error 0.0000(0.0000) Steps 682(703.40) | Grad Norm 0.5338(0.4192) | Total Time 0.00(0.00)\n",
      "Iter 1874 | Time 62.6129(65.7755) | Bit/dim 3.5165(3.5031) | Xent 0.0000(0.0000) | Loss 8.9255(9.6760) | Error 0.0000(0.0000) Steps 676(702.57) | Grad Norm 0.4196(0.4192) | Total Time 0.00(0.00)\n",
      "Iter 1875 | Time 65.7393(65.7744) | Bit/dim 3.5079(3.5032) | Xent 0.0000(0.0000) | Loss 8.9298(9.6536) | Error 0.0000(0.0000) Steps 682(701.96) | Grad Norm 0.3136(0.4160) | Total Time 0.00(0.00)\n",
      "Iter 1876 | Time 66.9221(65.8089) | Bit/dim 3.4955(3.5030) | Xent 0.0000(0.0000) | Loss 8.9893(9.6337) | Error 0.0000(0.0000) Steps 712(702.26) | Grad Norm 0.3788(0.4149) | Total Time 0.00(0.00)\n",
      "Iter 1877 | Time 60.6849(65.6552) | Bit/dim 3.5023(3.5030) | Xent 0.0000(0.0000) | Loss 8.7049(9.6058) | Error 0.0000(0.0000) Steps 682(701.65) | Grad Norm 0.3512(0.4130) | Total Time 0.00(0.00)\n",
      "Iter 1878 | Time 69.9601(65.7843) | Bit/dim 3.4983(3.5028) | Xent 0.0000(0.0000) | Loss 8.9831(9.5871) | Error 0.0000(0.0000) Steps 730(702.50) | Grad Norm 0.3303(0.4105) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0313 | Time 24.9634, Epoch Time 431.7921(426.8556), Bit/dim 3.5054(best: 3.4994), Xent 0.0000, Loss 3.5054, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1879 | Time 62.2473(65.6782) | Bit/dim 3.5055(3.5029) | Xent 0.0000(0.0000) | Loss 13.4062(9.7017) | Error 0.0000(0.0000) Steps 706(702.61) | Grad Norm 0.5448(0.4145) | Total Time 0.00(0.00)\n",
      "Iter 1880 | Time 61.3642(65.5488) | Bit/dim 3.5062(3.5030) | Xent 0.0000(0.0000) | Loss 8.7431(9.6730) | Error 0.0000(0.0000) Steps 676(701.81) | Grad Norm 0.4375(0.4152) | Total Time 0.00(0.00)\n",
      "Iter 1881 | Time 67.4623(65.6062) | Bit/dim 3.4993(3.5029) | Xent 0.0000(0.0000) | Loss 8.8950(9.6496) | Error 0.0000(0.0000) Steps 712(702.11) | Grad Norm 0.3524(0.4133) | Total Time 0.00(0.00)\n",
      "Iter 1882 | Time 69.0365(65.7091) | Bit/dim 3.5114(3.5031) | Xent 0.0000(0.0000) | Loss 9.0847(9.6327) | Error 0.0000(0.0000) Steps 712(702.41) | Grad Norm 0.3647(0.4119) | Total Time 0.00(0.00)\n",
      "Iter 1883 | Time 68.1244(65.7815) | Bit/dim 3.4919(3.5028) | Xent 0.0000(0.0000) | Loss 8.8950(9.6105) | Error 0.0000(0.0000) Steps 700(702.34) | Grad Norm 0.3953(0.4114) | Total Time 0.00(0.00)\n",
      "Iter 1884 | Time 61.8516(65.6636) | Bit/dim 3.4919(3.5025) | Xent 0.0000(0.0000) | Loss 8.9516(9.5908) | Error 0.0000(0.0000) Steps 694(702.09) | Grad Norm 0.3873(0.4106) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0314 | Time 25.3278, Epoch Time 431.2812(426.9883), Bit/dim 3.5060(best: 3.4994), Xent 0.0000, Loss 3.5060, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1885 | Time 66.3616(65.6846) | Bit/dim 3.5068(3.5026) | Xent 0.0000(0.0000) | Loss 13.7722(9.7162) | Error 0.0000(0.0000) Steps 718(702.56) | Grad Norm 0.4664(0.4123) | Total Time 0.00(0.00)\n",
      "Iter 1886 | Time 66.1954(65.6999) | Bit/dim 3.4998(3.5025) | Xent 0.0000(0.0000) | Loss 8.9211(9.6924) | Error 0.0000(0.0000) Steps 688(702.13) | Grad Norm 0.3583(0.4107) | Total Time 0.00(0.00)\n",
      "Iter 1887 | Time 64.6302(65.6678) | Bit/dim 3.5161(3.5029) | Xent 0.0000(0.0000) | Loss 8.6409(9.6608) | Error 0.0000(0.0000) Steps 688(701.70) | Grad Norm 0.3635(0.4093) | Total Time 0.00(0.00)\n",
      "Iter 1888 | Time 69.4406(65.7810) | Bit/dim 3.4969(3.5027) | Xent 0.0000(0.0000) | Loss 8.9602(9.6398) | Error 0.0000(0.0000) Steps 706(701.83) | Grad Norm 0.4118(0.4094) | Total Time 0.00(0.00)\n",
      "Iter 1889 | Time 66.0009(65.7876) | Bit/dim 3.5051(3.5028) | Xent 0.0000(0.0000) | Loss 8.8572(9.6163) | Error 0.0000(0.0000) Steps 694(701.60) | Grad Norm 0.2813(0.4055) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 63.2287(65.7108) | Bit/dim 3.5168(3.5032) | Xent 0.0000(0.0000) | Loss 8.6461(9.5872) | Error 0.0000(0.0000) Steps 676(700.83) | Grad Norm 0.6658(0.4133) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0315 | Time 25.2524, Epoch Time 437.1502(427.2932), Bit/dim 3.5036(best: 3.4994), Xent 0.0000, Loss 3.5036, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1891 | Time 65.9865(65.7191) | Bit/dim 3.5117(3.5035) | Xent 0.0000(0.0000) | Loss 13.4754(9.7039) | Error 0.0000(0.0000) Steps 712(701.17) | Grad Norm 0.4662(0.4149) | Total Time 0.00(0.00)\n",
      "Iter 1892 | Time 63.4389(65.6507) | Bit/dim 3.5013(3.5034) | Xent 0.0000(0.0000) | Loss 8.5875(9.6704) | Error 0.0000(0.0000) Steps 688(700.77) | Grad Norm 0.4280(0.4153) | Total Time 0.00(0.00)\n",
      "Iter 1893 | Time 67.3651(65.7021) | Bit/dim 3.5034(3.5034) | Xent 0.0000(0.0000) | Loss 8.9766(9.6495) | Error 0.0000(0.0000) Steps 712(701.11) | Grad Norm 0.5581(0.4196) | Total Time 0.00(0.00)\n",
      "Iter 1894 | Time 69.2481(65.8085) | Bit/dim 3.4964(3.5032) | Xent 0.0000(0.0000) | Loss 8.9530(9.6286) | Error 0.0000(0.0000) Steps 712(701.43) | Grad Norm 0.3386(0.4172) | Total Time 0.00(0.00)\n",
      "Iter 1895 | Time 65.9533(65.8129) | Bit/dim 3.4995(3.5031) | Xent 0.0000(0.0000) | Loss 8.8833(9.6063) | Error 0.0000(0.0000) Steps 718(701.93) | Grad Norm 0.4759(0.4189) | Total Time 0.00(0.00)\n",
      "Iter 1896 | Time 61.2548(65.6761) | Bit/dim 3.4992(3.5030) | Xent 0.0000(0.0000) | Loss 9.0407(9.5893) | Error 0.0000(0.0000) Steps 706(702.05) | Grad Norm 0.4626(0.4202) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0316 | Time 24.9829, Epoch Time 434.3743(427.5056), Bit/dim 3.5064(best: 3.4994), Xent 0.0000, Loss 3.5064, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1897 | Time 60.3135(65.5152) | Bit/dim 3.5042(3.5030) | Xent 0.0000(0.0000) | Loss 13.3707(9.7028) | Error 0.0000(0.0000) Steps 676(701.27) | Grad Norm 0.5279(0.4235) | Total Time 0.00(0.00)\n",
      "Iter 1898 | Time 64.0434(65.4711) | Bit/dim 3.4799(3.5023) | Xent 0.0000(0.0000) | Loss 9.0093(9.6820) | Error 0.0000(0.0000) Steps 712(701.59) | Grad Norm 0.4826(0.4252) | Total Time 0.00(0.00)\n",
      "Iter 1899 | Time 70.2810(65.6154) | Bit/dim 3.5063(3.5024) | Xent 0.0000(0.0000) | Loss 9.0098(9.6618) | Error 0.0000(0.0000) Steps 706(701.73) | Grad Norm 0.5406(0.4287) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 65.6952(65.6178) | Bit/dim 3.5108(3.5027) | Xent 0.0000(0.0000) | Loss 8.8061(9.6361) | Error 0.0000(0.0000) Steps 700(701.67) | Grad Norm 0.4280(0.4287) | Total Time 0.00(0.00)\n",
      "Iter 1901 | Time 62.5604(65.5261) | Bit/dim 3.5041(3.5027) | Xent 0.0000(0.0000) | Loss 8.9669(9.6160) | Error 0.0000(0.0000) Steps 700(701.62) | Grad Norm 0.5353(0.4319) | Total Time 0.00(0.00)\n",
      "Iter 1902 | Time 63.6491(65.4697) | Bit/dim 3.4998(3.5026) | Xent 0.0000(0.0000) | Loss 8.9876(9.5972) | Error 0.0000(0.0000) Steps 706(701.75) | Grad Norm 0.2875(0.4275) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0317 | Time 25.5797, Epoch Time 428.0799(427.5228), Bit/dim 3.5064(best: 3.4994), Xent 0.0000, Loss 3.5064, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1903 | Time 66.1077(65.4889) | Bit/dim 3.4804(3.5020) | Xent 0.0000(0.0000) | Loss 13.3881(9.7109) | Error 0.0000(0.0000) Steps 724(702.42) | Grad Norm 0.6247(0.4335) | Total Time 0.00(0.00)\n",
      "Iter 1904 | Time 67.1353(65.5383) | Bit/dim 3.5114(3.5023) | Xent 0.0000(0.0000) | Loss 8.9080(9.6868) | Error 0.0000(0.0000) Steps 706(702.53) | Grad Norm 0.3781(0.4318) | Total Time 0.00(0.00)\n",
      "Iter 1905 | Time 60.3158(65.3816) | Bit/dim 3.5069(3.5024) | Xent 0.0000(0.0000) | Loss 8.5165(9.6517) | Error 0.0000(0.0000) Steps 682(701.91) | Grad Norm 0.7524(0.4414) | Total Time 0.00(0.00)\n",
      "Iter 1906 | Time 66.3229(65.4098) | Bit/dim 3.4935(3.5021) | Xent 0.0000(0.0000) | Loss 8.9742(9.6314) | Error 0.0000(0.0000) Steps 706(702.04) | Grad Norm 0.4224(0.4408) | Total Time 0.00(0.00)\n",
      "Iter 1907 | Time 61.6720(65.2977) | Bit/dim 3.5035(3.5022) | Xent 0.0000(0.0000) | Loss 8.6201(9.6011) | Error 0.0000(0.0000) Steps 682(701.44) | Grad Norm 0.7154(0.4491) | Total Time 0.00(0.00)\n",
      "Iter 1908 | Time 63.9648(65.2577) | Bit/dim 3.5193(3.5027) | Xent 0.0000(0.0000) | Loss 8.7290(9.5749) | Error 0.0000(0.0000) Steps 712(701.75) | Grad Norm 0.7321(0.4576) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0318 | Time 24.2631, Epoch Time 425.4867(427.4618), Bit/dim 3.5102(best: 3.4994), Xent 0.0000, Loss 3.5102, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1909 | Time 66.0156(65.2805) | Bit/dim 3.4999(3.5026) | Xent 0.0000(0.0000) | Loss 13.3618(9.6885) | Error 0.0000(0.0000) Steps 712(702.06) | Grad Norm 0.5132(0.4592) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 67.9381(65.3602) | Bit/dim 3.4998(3.5025) | Xent 0.0000(0.0000) | Loss 8.9756(9.6671) | Error 0.0000(0.0000) Steps 706(702.18) | Grad Norm 0.5524(0.4620) | Total Time 0.00(0.00)\n",
      "Iter 1911 | Time 68.9351(65.4674) | Bit/dim 3.5067(3.5026) | Xent 0.0000(0.0000) | Loss 8.9627(9.6460) | Error 0.0000(0.0000) Steps 712(702.47) | Grad Norm 0.6126(0.4665) | Total Time 0.00(0.00)\n",
      "Iter 1912 | Time 69.5355(65.5895) | Bit/dim 3.4993(3.5025) | Xent 0.0000(0.0000) | Loss 8.8827(9.6231) | Error 0.0000(0.0000) Steps 724(703.12) | Grad Norm 0.4995(0.4675) | Total Time 0.00(0.00)\n",
      "Iter 1913 | Time 68.1714(65.6669) | Bit/dim 3.5071(3.5027) | Xent 0.0000(0.0000) | Loss 8.7767(9.5977) | Error 0.0000(0.0000) Steps 688(702.66) | Grad Norm 0.4972(0.4684) | Total Time 0.00(0.00)\n",
      "Iter 1914 | Time 69.1360(65.7710) | Bit/dim 3.5003(3.5026) | Xent 0.0000(0.0000) | Loss 9.0292(9.5806) | Error 0.0000(0.0000) Steps 712(702.94) | Grad Norm 0.4486(0.4678) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0319 | Time 25.1563, Epoch Time 450.7141(428.1593), Bit/dim 3.5070(best: 3.4994), Xent 0.0000, Loss 3.5070, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1915 | Time 61.1040(65.6310) | Bit/dim 3.5060(3.5027) | Xent 0.0000(0.0000) | Loss 12.9681(9.6823) | Error 0.0000(0.0000) Steps 700(702.86) | Grad Norm 1.3127(0.4932) | Total Time 0.00(0.00)\n",
      "Iter 1916 | Time 64.6351(65.6011) | Bit/dim 3.4970(3.5025) | Xent 0.0000(0.0000) | Loss 8.7764(9.6551) | Error 0.0000(0.0000) Steps 712(703.13) | Grad Norm 0.6854(0.4989) | Total Time 0.00(0.00)\n",
      "Iter 1917 | Time 62.6537(65.5127) | Bit/dim 3.5013(3.5025) | Xent 0.0000(0.0000) | Loss 8.6123(9.6238) | Error 0.0000(0.0000) Steps 706(703.22) | Grad Norm 0.7104(0.5053) | Total Time 0.00(0.00)\n",
      "Iter 1918 | Time 65.5321(65.5133) | Bit/dim 3.5117(3.5028) | Xent 0.0000(0.0000) | Loss 8.8220(9.5997) | Error 0.0000(0.0000) Steps 688(702.76) | Grad Norm 0.5609(0.5070) | Total Time 0.00(0.00)\n",
      "Iter 1919 | Time 70.1281(65.6517) | Bit/dim 3.4964(3.5026) | Xent 0.0000(0.0000) | Loss 8.8278(9.5766) | Error 0.0000(0.0000) Steps 712(703.04) | Grad Norm 0.6675(0.5118) | Total Time 0.00(0.00)\n",
      "Iter 1920 | Time 63.9906(65.6019) | Bit/dim 3.5155(3.5030) | Xent 0.0000(0.0000) | Loss 8.8519(9.5548) | Error 0.0000(0.0000) Steps 688(702.59) | Grad Norm 0.6070(0.5146) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0320 | Time 25.6144, Epoch Time 431.5804(428.2620), Bit/dim 3.5052(best: 3.4994), Xent 0.0000, Loss 3.5052, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1921 | Time 68.1516(65.6784) | Bit/dim 3.4961(3.5028) | Xent 0.0000(0.0000) | Loss 13.8929(9.6850) | Error 0.0000(0.0000) Steps 700(702.51) | Grad Norm 0.5665(0.5162) | Total Time 0.00(0.00)\n",
      "Iter 1922 | Time 67.0627(65.7199) | Bit/dim 3.5069(3.5029) | Xent 0.0000(0.0000) | Loss 8.9603(9.6632) | Error 0.0000(0.0000) Steps 730(703.33) | Grad Norm 0.5286(0.5166) | Total Time 0.00(0.00)\n",
      "Iter 1923 | Time 61.8103(65.6026) | Bit/dim 3.5156(3.5033) | Xent 0.0000(0.0000) | Loss 8.9569(9.6421) | Error 0.0000(0.0000) Steps 682(702.69) | Grad Norm 0.4687(0.5151) | Total Time 0.00(0.00)\n",
      "Iter 1924 | Time 63.1431(65.5288) | Bit/dim 3.5042(3.5033) | Xent 0.0000(0.0000) | Loss 8.6482(9.6122) | Error 0.0000(0.0000) Steps 682(702.07) | Grad Norm 0.5613(0.5165) | Total Time 0.00(0.00)\n",
      "Iter 1925 | Time 66.2048(65.5491) | Bit/dim 3.5041(3.5033) | Xent 0.0000(0.0000) | Loss 8.9542(9.5925) | Error 0.0000(0.0000) Steps 688(701.65) | Grad Norm 0.4932(0.5158) | Total Time 0.00(0.00)\n",
      "Iter 1926 | Time 65.7456(65.5550) | Bit/dim 3.4942(3.5031) | Xent 0.0000(0.0000) | Loss 8.7039(9.5658) | Error 0.0000(0.0000) Steps 682(701.06) | Grad Norm 0.5655(0.5173) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0321 | Time 25.1928, Epoch Time 433.3679(428.4151), Bit/dim 3.5027(best: 3.4994), Xent 0.0000, Loss 3.5027, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1927 | Time 65.9928(65.5681) | Bit/dim 3.5050(3.5031) | Xent 0.0000(0.0000) | Loss 13.4303(9.6818) | Error 0.0000(0.0000) Steps 712(701.39) | Grad Norm 0.5345(0.5178) | Total Time 0.00(0.00)\n",
      "Iter 1928 | Time 65.7675(65.5741) | Bit/dim 3.5167(3.5035) | Xent 0.0000(0.0000) | Loss 8.8187(9.6559) | Error 0.0000(0.0000) Steps 706(701.53) | Grad Norm 0.3690(0.5133) | Total Time 0.00(0.00)\n",
      "Iter 1929 | Time 67.5904(65.6346) | Bit/dim 3.4894(3.5031) | Xent 0.0000(0.0000) | Loss 8.9429(9.6345) | Error 0.0000(0.0000) Steps 712(701.84) | Grad Norm 0.4437(0.5113) | Total Time 0.00(0.00)\n",
      "Iter 1930 | Time 68.0994(65.7086) | Bit/dim 3.5002(3.5030) | Xent 0.0000(0.0000) | Loss 8.7983(9.6094) | Error 0.0000(0.0000) Steps 706(701.97) | Grad Norm 0.4277(0.5088) | Total Time 0.00(0.00)\n",
      "Iter 1931 | Time 64.1801(65.6627) | Bit/dim 3.5052(3.5031) | Xent 0.0000(0.0000) | Loss 8.8129(9.5855) | Error 0.0000(0.0000) Steps 712(702.27) | Grad Norm 0.4456(0.5069) | Total Time 0.00(0.00)\n",
      "Iter 1932 | Time 65.1615(65.6477) | Bit/dim 3.4911(3.5027) | Xent 0.0000(0.0000) | Loss 8.9590(9.5667) | Error 0.0000(0.0000) Steps 706(702.38) | Grad Norm 0.4021(0.5037) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0322 | Time 25.7672, Epoch Time 438.5835(428.7202), Bit/dim 3.5005(best: 3.4994), Xent 0.0000, Loss 3.5005, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1933 | Time 67.4918(65.7030) | Bit/dim 3.5002(3.5026) | Xent 0.0000(0.0000) | Loss 13.0482(9.6712) | Error 0.0000(0.0000) Steps 688(701.95) | Grad Norm 0.5701(0.5057) | Total Time 0.00(0.00)\n",
      "Iter 1934 | Time 64.4894(65.6666) | Bit/dim 3.5111(3.5029) | Xent 0.0000(0.0000) | Loss 8.7716(9.6442) | Error 0.0000(0.0000) Steps 682(701.35) | Grad Norm 0.4654(0.5045) | Total Time 0.00(0.00)\n",
      "Iter 1935 | Time 64.3445(65.6269) | Bit/dim 3.4928(3.5026) | Xent 0.0000(0.0000) | Loss 8.8792(9.6212) | Error 0.0000(0.0000) Steps 676(700.59) | Grad Norm 0.3750(0.5006) | Total Time 0.00(0.00)\n",
      "Iter 1936 | Time 62.1099(65.5214) | Bit/dim 3.5079(3.5027) | Xent 0.0000(0.0000) | Loss 8.8770(9.5989) | Error 0.0000(0.0000) Steps 712(700.93) | Grad Norm 0.4131(0.4980) | Total Time 0.00(0.00)\n",
      "Iter 1937 | Time 67.4773(65.5801) | Bit/dim 3.5006(3.5027) | Xent 0.0000(0.0000) | Loss 8.8332(9.5759) | Error 0.0000(0.0000) Steps 694(700.72) | Grad Norm 0.3524(0.4936) | Total Time 0.00(0.00)\n",
      "Iter 1938 | Time 66.5327(65.6087) | Bit/dim 3.4950(3.5025) | Xent 0.0000(0.0000) | Loss 8.9181(9.5562) | Error 0.0000(0.0000) Steps 718(701.24) | Grad Norm 0.4557(0.4925) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0323 | Time 25.0428, Epoch Time 434.1478(428.8830), Bit/dim 3.5058(best: 3.4994), Xent 0.0000, Loss 3.5058, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1939 | Time 69.1254(65.7142) | Bit/dim 3.5078(3.5026) | Xent 0.0000(0.0000) | Loss 13.6173(9.6780) | Error 0.0000(0.0000) Steps 730(702.10) | Grad Norm 0.4666(0.4917) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 65.4133(65.7051) | Bit/dim 3.5009(3.5026) | Xent 0.0000(0.0000) | Loss 8.8029(9.6518) | Error 0.0000(0.0000) Steps 706(702.22) | Grad Norm 0.3368(0.4871) | Total Time 0.00(0.00)\n",
      "Iter 1941 | Time 62.8040(65.6181) | Bit/dim 3.5007(3.5025) | Xent 0.0000(0.0000) | Loss 8.9686(9.6313) | Error 0.0000(0.0000) Steps 700(702.15) | Grad Norm 0.4442(0.4858) | Total Time 0.00(0.00)\n",
      "Iter 1942 | Time 67.2184(65.6661) | Bit/dim 3.5040(3.5026) | Xent 0.0000(0.0000) | Loss 8.9805(9.6118) | Error 0.0000(0.0000) Steps 706(702.27) | Grad Norm 0.4701(0.4853) | Total Time 0.00(0.00)\n",
      "Iter 1943 | Time 62.7974(65.5801) | Bit/dim 3.5068(3.5027) | Xent 0.0000(0.0000) | Loss 8.7755(9.5867) | Error 0.0000(0.0000) Steps 694(702.02) | Grad Norm 0.3911(0.4825) | Total Time 0.00(0.00)\n",
      "Iter 1944 | Time 67.9671(65.6517) | Bit/dim 3.5006(3.5026) | Xent 0.0000(0.0000) | Loss 8.7569(9.5618) | Error 0.0000(0.0000) Steps 706(702.14) | Grad Norm 0.3673(0.4790) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0324 | Time 25.2920, Epoch Time 436.5722(429.1137), Bit/dim 3.5036(best: 3.4994), Xent 0.0000, Loss 3.5036, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1945 | Time 70.7487(65.8046) | Bit/dim 3.5048(3.5027) | Xent 0.0000(0.0000) | Loss 13.8657(9.6909) | Error 0.0000(0.0000) Steps 724(702.80) | Grad Norm 0.4348(0.4777) | Total Time 0.00(0.00)\n",
      "Iter 1946 | Time 62.2570(65.6981) | Bit/dim 3.5063(3.5028) | Xent 0.0000(0.0000) | Loss 8.7162(9.6616) | Error 0.0000(0.0000) Steps 688(702.35) | Grad Norm 0.4683(0.4774) | Total Time 0.00(0.00)\n",
      "Iter 1947 | Time 70.6427(65.8465) | Bit/dim 3.4906(3.5024) | Xent 0.0000(0.0000) | Loss 8.9366(9.6399) | Error 0.0000(0.0000) Steps 730(703.18) | Grad Norm 0.3852(0.4746) | Total Time 0.00(0.00)\n",
      "Iter 1948 | Time 66.1508(65.8556) | Bit/dim 3.5016(3.5024) | Xent 0.0000(0.0000) | Loss 8.9761(9.6200) | Error 0.0000(0.0000) Steps 718(703.63) | Grad Norm 0.4628(0.4743) | Total Time 0.00(0.00)\n",
      "Iter 1949 | Time 69.0737(65.9521) | Bit/dim 3.5117(3.5027) | Xent 0.0000(0.0000) | Loss 8.7891(9.5951) | Error 0.0000(0.0000) Steps 676(702.80) | Grad Norm 0.4412(0.4733) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 73.9321(66.1915) | Bit/dim 3.4922(3.5024) | Xent 0.0000(0.0000) | Loss 8.8512(9.5727) | Error 0.0000(0.0000) Steps 700(702.71) | Grad Norm 0.5245(0.4748) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0325 | Time 25.2035, Epoch Time 454.1117(429.8636), Bit/dim 3.5045(best: 3.4994), Xent 0.0000, Loss 3.5045, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1951 | Time 80.3980(66.6177) | Bit/dim 3.4966(3.5022) | Xent 0.0000(0.0000) | Loss 13.5473(9.6920) | Error 0.0000(0.0000) Steps 718(703.17) | Grad Norm 0.6018(0.4786) | Total Time 0.00(0.00)\n",
      "Iter 1952 | Time 75.6053(66.8874) | Bit/dim 3.5012(3.5022) | Xent 0.0000(0.0000) | Loss 8.6580(9.6610) | Error 0.0000(0.0000) Steps 682(702.54) | Grad Norm 0.6308(0.4832) | Total Time 0.00(0.00)\n",
      "Iter 1953 | Time 79.8038(67.2749) | Bit/dim 3.4824(3.5016) | Xent 0.0000(0.0000) | Loss 8.8999(9.6381) | Error 0.0000(0.0000) Steps 712(702.82) | Grad Norm 0.4970(0.4836) | Total Time 0.00(0.00)\n",
      "Iter 1954 | Time 76.2298(67.5435) | Bit/dim 3.4993(3.5015) | Xent 0.0000(0.0000) | Loss 8.6907(9.6097) | Error 0.0000(0.0000) Steps 706(702.92) | Grad Norm 0.5680(0.4862) | Total Time 0.00(0.00)\n",
      "Iter 1955 | Time 77.8690(67.8533) | Bit/dim 3.5084(3.5017) | Xent 0.0000(0.0000) | Loss 9.0632(9.5933) | Error 0.0000(0.0000) Steps 712(703.19) | Grad Norm 0.4963(0.4865) | Total Time 0.00(0.00)\n",
      "Iter 1956 | Time 74.8439(68.0630) | Bit/dim 3.4987(3.5016) | Xent 0.0000(0.0000) | Loss 8.7714(9.5687) | Error 0.0000(0.0000) Steps 706(703.27) | Grad Norm 0.5670(0.4889) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0326 | Time 25.1901, Epoch Time 505.6933(432.1385), Bit/dim 3.5028(best: 3.4994), Xent 0.0000, Loss 3.5028, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1957 | Time 72.1779(68.1864) | Bit/dim 3.4997(3.5016) | Xent 0.0000(0.0000) | Loss 13.4798(9.6860) | Error 0.0000(0.0000) Steps 694(703.00) | Grad Norm 0.6334(0.4932) | Total Time 0.00(0.00)\n",
      "Iter 1958 | Time 79.2188(68.5174) | Bit/dim 3.4992(3.5015) | Xent 0.0000(0.0000) | Loss 8.8110(9.6597) | Error 0.0000(0.0000) Steps 700(702.91) | Grad Norm 0.5899(0.4961) | Total Time 0.00(0.00)\n",
      "Iter 1959 | Time 79.7064(68.8531) | Bit/dim 3.4977(3.5014) | Xent 0.0000(0.0000) | Loss 8.9771(9.6393) | Error 0.0000(0.0000) Steps 724(703.54) | Grad Norm 0.6048(0.4994) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 76.7634(69.0904) | Bit/dim 3.5004(3.5013) | Xent 0.0000(0.0000) | Loss 8.9531(9.6187) | Error 0.0000(0.0000) Steps 706(703.61) | Grad Norm 0.6599(0.5042) | Total Time 0.00(0.00)\n",
      "Iter 1961 | Time 72.2359(69.1848) | Bit/dim 3.5000(3.5013) | Xent 0.0000(0.0000) | Loss 8.8720(9.5963) | Error 0.0000(0.0000) Steps 694(703.32) | Grad Norm 0.5827(0.5065) | Total Time 0.00(0.00)\n",
      "Iter 1962 | Time 72.0250(69.2700) | Bit/dim 3.5016(3.5013) | Xent 0.0000(0.0000) | Loss 8.9177(9.5759) | Error 0.0000(0.0000) Steps 706(703.40) | Grad Norm 0.6155(0.5098) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0327 | Time 25.4944, Epoch Time 493.6033(433.9825), Bit/dim 3.5062(best: 3.4994), Xent 0.0000, Loss 3.5062, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1963 | Time 75.5381(69.4580) | Bit/dim 3.5025(3.5013) | Xent 0.0000(0.0000) | Loss 13.6897(9.6993) | Error 0.0000(0.0000) Steps 712(703.66) | Grad Norm 0.6847(0.5151) | Total Time 0.00(0.00)\n",
      "Iter 1964 | Time 76.2795(69.6627) | Bit/dim 3.4929(3.5011) | Xent 0.0000(0.0000) | Loss 8.7335(9.6704) | Error 0.0000(0.0000) Steps 718(704.09) | Grad Norm 0.4089(0.5119) | Total Time 0.00(0.00)\n",
      "Iter 1965 | Time 81.6310(70.0217) | Bit/dim 3.5128(3.5014) | Xent 0.0000(0.0000) | Loss 9.0608(9.6521) | Error 0.0000(0.0000) Steps 718(704.51) | Grad Norm 0.8290(0.5214) | Total Time 0.00(0.00)\n",
      "Iter 1966 | Time 77.4481(70.2445) | Bit/dim 3.5044(3.5015) | Xent 0.0000(0.0000) | Loss 8.9263(9.6303) | Error 0.0000(0.0000) Steps 712(704.73) | Grad Norm 0.4515(0.5193) | Total Time 0.00(0.00)\n",
      "Iter 1967 | Time 74.9095(70.3844) | Bit/dim 3.5059(3.5017) | Xent 0.0000(0.0000) | Loss 8.8428(9.6067) | Error 0.0000(0.0000) Steps 706(704.77) | Grad Norm 0.8265(0.5285) | Total Time 0.00(0.00)\n",
      "Iter 1968 | Time 72.6314(70.4519) | Bit/dim 3.4935(3.5014) | Xent 0.0000(0.0000) | Loss 8.7633(9.5814) | Error 0.0000(0.0000) Steps 694(704.45) | Grad Norm 0.6878(0.5333) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0328 | Time 25.4664, Epoch Time 500.1750(435.9682), Bit/dim 3.5037(best: 3.4994), Xent 0.0000, Loss 3.5037, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1969 | Time 76.7487(70.6408) | Bit/dim 3.5066(3.5016) | Xent 0.0000(0.0000) | Loss 13.3891(9.6956) | Error 0.0000(0.0000) Steps 700(704.32) | Grad Norm 0.6350(0.5363) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 76.5651(70.8185) | Bit/dim 3.4973(3.5014) | Xent 0.0000(0.0000) | Loss 8.9688(9.6738) | Error 0.0000(0.0000) Steps 712(704.55) | Grad Norm 0.9563(0.5489) | Total Time 0.00(0.00)\n",
      "Iter 1971 | Time 79.7020(71.0850) | Bit/dim 3.4961(3.5013) | Xent 0.0000(0.0000) | Loss 9.0564(9.6553) | Error 0.0000(0.0000) Steps 712(704.77) | Grad Norm 0.3052(0.5416) | Total Time 0.00(0.00)\n",
      "Iter 1972 | Time 72.6504(71.1320) | Bit/dim 3.5000(3.5012) | Xent 0.0000(0.0000) | Loss 8.9098(9.6329) | Error 0.0000(0.0000) Steps 694(704.45) | Grad Norm 0.9960(0.5553) | Total Time 0.00(0.00)\n",
      "Iter 1973 | Time 69.6336(71.0870) | Bit/dim 3.4985(3.5012) | Xent 0.0000(0.0000) | Loss 8.5552(9.6006) | Error 0.0000(0.0000) Steps 694(704.13) | Grad Norm 1.0165(0.5691) | Total Time 0.00(0.00)\n",
      "Iter 1974 | Time 78.8130(71.3188) | Bit/dim 3.4995(3.5011) | Xent 0.0000(0.0000) | Loss 8.9890(9.5822) | Error 0.0000(0.0000) Steps 706(704.19) | Grad Norm 0.8043(0.5761) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0329 | Time 25.2990, Epoch Time 495.8994(437.7662), Bit/dim 3.5001(best: 3.4994), Xent 0.0000, Loss 3.5001, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1975 | Time 69.7364(71.2713) | Bit/dim 3.5040(3.5012) | Xent 0.0000(0.0000) | Loss 13.4431(9.6981) | Error 0.0000(0.0000) Steps 712(704.42) | Grad Norm 0.8594(0.5846) | Total Time 0.00(0.00)\n",
      "Iter 1976 | Time 79.0528(71.5048) | Bit/dim 3.4964(3.5011) | Xent 0.0000(0.0000) | Loss 8.8962(9.6740) | Error 0.0000(0.0000) Steps 724(705.01) | Grad Norm 0.6227(0.5858) | Total Time 0.00(0.00)\n",
      "Iter 1977 | Time 77.3281(71.6795) | Bit/dim 3.5091(3.5013) | Xent 0.0000(0.0000) | Loss 8.8910(9.6505) | Error 0.0000(0.0000) Steps 700(704.86) | Grad Norm 0.9456(0.5966) | Total Time 0.00(0.00)\n",
      "Iter 1978 | Time 73.2057(71.7252) | Bit/dim 3.5103(3.5016) | Xent 0.0000(0.0000) | Loss 8.8665(9.6270) | Error 0.0000(0.0000) Steps 670(703.81) | Grad Norm 0.5579(0.5954) | Total Time 0.00(0.00)\n",
      "Iter 1979 | Time 76.9558(71.8822) | Bit/dim 3.4895(3.5012) | Xent 0.0000(0.0000) | Loss 8.8324(9.6032) | Error 0.0000(0.0000) Steps 712(704.06) | Grad Norm 0.8521(0.6031) | Total Time 0.00(0.00)\n",
      "Iter 1980 | Time 79.4012(72.1077) | Bit/dim 3.4888(3.5008) | Xent 0.0000(0.0000) | Loss 8.9407(9.5833) | Error 0.0000(0.0000) Steps 712(704.30) | Grad Norm 0.4551(0.5987) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0330 | Time 25.0824, Epoch Time 496.7866(439.5368), Bit/dim 3.5035(best: 3.4994), Xent 0.0000, Loss 3.5035, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1981 | Time 74.2551(72.1722) | Bit/dim 3.5008(3.5008) | Xent 0.0000(0.0000) | Loss 13.3219(9.6954) | Error 0.0000(0.0000) Steps 694(703.99) | Grad Norm 0.6695(0.6008) | Total Time 0.00(0.00)\n",
      "Iter 1982 | Time 73.7586(72.2197) | Bit/dim 3.5098(3.5011) | Xent 0.0000(0.0000) | Loss 9.0501(9.6761) | Error 0.0000(0.0000) Steps 706(704.05) | Grad Norm 0.5635(0.5997) | Total Time 0.00(0.00)\n",
      "Iter 1983 | Time 80.3670(72.4642) | Bit/dim 3.5047(3.5012) | Xent 0.0000(0.0000) | Loss 9.0220(9.6565) | Error 0.0000(0.0000) Steps 718(704.47) | Grad Norm 0.6470(0.6011) | Total Time 0.00(0.00)\n",
      "Iter 1984 | Time 75.1745(72.5455) | Bit/dim 3.4942(3.5010) | Xent 0.0000(0.0000) | Loss 8.7110(9.6281) | Error 0.0000(0.0000) Steps 706(704.51) | Grad Norm 0.6550(0.6027) | Total Time 0.00(0.00)\n",
      "Iter 1985 | Time 76.2921(72.6579) | Bit/dim 3.4976(3.5009) | Xent 0.0000(0.0000) | Loss 8.5031(9.5943) | Error 0.0000(0.0000) Steps 694(704.20) | Grad Norm 0.6053(0.6028) | Total Time 0.00(0.00)\n",
      "Iter 1986 | Time 77.8070(72.8123) | Bit/dim 3.4842(3.5004) | Xent 0.0000(0.0000) | Loss 8.8235(9.5712) | Error 0.0000(0.0000) Steps 718(704.61) | Grad Norm 0.5083(0.6000) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0331 | Time 25.9054, Epoch Time 499.8293(441.3456), Bit/dim 3.4968(best: 3.4994), Xent 0.0000, Loss 3.4968, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1987 | Time 77.6195(72.9566) | Bit/dim 3.4997(3.5004) | Xent 0.0000(0.0000) | Loss 13.5901(9.6918) | Error 0.0000(0.0000) Steps 712(704.83) | Grad Norm 0.4067(0.5942) | Total Time 0.00(0.00)\n",
      "Iter 1988 | Time 74.1119(72.9912) | Bit/dim 3.5018(3.5004) | Xent 0.0000(0.0000) | Loss 8.7796(9.6644) | Error 0.0000(0.0000) Steps 700(704.69) | Grad Norm 0.4141(0.5888) | Total Time 0.00(0.00)\n",
      "Iter 1989 | Time 75.7254(73.0732) | Bit/dim 3.5050(3.5006) | Xent 0.0000(0.0000) | Loss 8.9938(9.6443) | Error 0.0000(0.0000) Steps 712(704.91) | Grad Norm 0.4253(0.5839) | Total Time 0.00(0.00)\n",
      "Iter 1990 | Time 73.6271(73.0899) | Bit/dim 3.4995(3.5005) | Xent 0.0000(0.0000) | Loss 8.4998(9.6100) | Error 0.0000(0.0000) Steps 688(704.40) | Grad Norm 0.7827(0.5898) | Total Time 0.00(0.00)\n",
      "Iter 1991 | Time 74.4014(73.1292) | Bit/dim 3.4897(3.5002) | Xent 0.0000(0.0000) | Loss 8.8849(9.5882) | Error 0.0000(0.0000) Steps 694(704.09) | Grad Norm 0.4807(0.5865) | Total Time 0.00(0.00)\n",
      "Iter 1992 | Time 76.6184(73.2339) | Bit/dim 3.5023(3.5003) | Xent 0.0000(0.0000) | Loss 9.0550(9.5722) | Error 0.0000(0.0000) Steps 712(704.33) | Grad Norm 0.4383(0.5821) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0332 | Time 25.3484, Epoch Time 493.2631(442.9031), Bit/dim 3.5024(best: 3.4968), Xent 0.0000, Loss 3.5024, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1993 | Time 73.0280(73.2277) | Bit/dim 3.5028(3.5003) | Xent 0.0000(0.0000) | Loss 13.6354(9.6941) | Error 0.0000(0.0000) Steps 694(704.02) | Grad Norm 0.5032(0.5797) | Total Time 0.00(0.00)\n",
      "Iter 1994 | Time 78.4382(73.3840) | Bit/dim 3.5076(3.5006) | Xent 0.0000(0.0000) | Loss 8.8656(9.6693) | Error 0.0000(0.0000) Steps 694(703.72) | Grad Norm 0.6663(0.5823) | Total Time 0.00(0.00)\n",
      "Iter 1995 | Time 72.7300(73.3644) | Bit/dim 3.4904(3.5002) | Xent 0.0000(0.0000) | Loss 8.6522(9.6387) | Error 0.0000(0.0000) Steps 706(703.78) | Grad Norm 0.4219(0.5775) | Total Time 0.00(0.00)\n",
      "Iter 1996 | Time 75.9148(73.4409) | Bit/dim 3.5132(3.5006) | Xent 0.0000(0.0000) | Loss 8.8065(9.6138) | Error 0.0000(0.0000) Steps 700(703.67) | Grad Norm 0.5363(0.5763) | Total Time 0.00(0.00)\n",
      "Iter 1997 | Time 77.0129(73.5481) | Bit/dim 3.4981(3.5006) | Xent 0.0000(0.0000) | Loss 8.7140(9.5868) | Error 0.0000(0.0000) Steps 688(703.20) | Grad Norm 0.4750(0.5732) | Total Time 0.00(0.00)\n",
      "Iter 1998 | Time 80.5228(73.7573) | Bit/dim 3.4998(3.5005) | Xent 0.0000(0.0000) | Loss 9.0184(9.5697) | Error 0.0000(0.0000) Steps 724(703.83) | Grad Norm 0.5657(0.5730) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 25.2468, Epoch Time 498.9096(444.5833), Bit/dim 3.5042(best: 3.4968), Xent 0.0000, Loss 3.5042, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1999 | Time 80.7613(73.9674) | Bit/dim 3.5202(3.5011) | Xent 0.0000(0.0000) | Loss 13.6425(9.6919) | Error 0.0000(0.0000) Steps 706(703.89) | Grad Norm 0.4060(0.5680) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 78.7108(74.1097) | Bit/dim 3.5145(3.5015) | Xent 0.0000(0.0000) | Loss 8.8866(9.6678) | Error 0.0000(0.0000) Steps 700(703.77) | Grad Norm 0.5272(0.5668) | Total Time 0.00(0.00)\n",
      "Iter 2001 | Time 76.4322(74.1794) | Bit/dim 3.4997(3.5015) | Xent 0.0000(0.0000) | Loss 8.9384(9.6459) | Error 0.0000(0.0000) Steps 724(704.38) | Grad Norm 0.3741(0.5610) | Total Time 0.00(0.00)\n",
      "Iter 2002 | Time 81.6641(74.4040) | Bit/dim 3.4979(3.5014) | Xent 0.0000(0.0000) | Loss 9.0098(9.6268) | Error 0.0000(0.0000) Steps 718(704.79) | Grad Norm 0.4677(0.5582) | Total Time 0.00(0.00)\n",
      "Iter 2003 | Time 76.7999(74.4758) | Bit/dim 3.4830(3.5008) | Xent 0.0000(0.0000) | Loss 8.9883(9.6076) | Error 0.0000(0.0000) Steps 700(704.65) | Grad Norm 0.3202(0.5511) | Total Time 0.00(0.00)\n",
      "Iter 2004 | Time 79.0771(74.6139) | Bit/dim 3.4911(3.5005) | Xent 0.0000(0.0000) | Loss 8.5019(9.5745) | Error 0.0000(0.0000) Steps 700(704.51) | Grad Norm 0.5886(0.5522) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 25.2160, Epoch Time 514.7243(446.6875), Bit/dim 3.5013(best: 3.4968), Xent 0.0000, Loss 3.5013, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2005 | Time 76.0555(74.6571) | Bit/dim 3.5009(3.5005) | Xent 0.0000(0.0000) | Loss 13.6320(9.6962) | Error 0.0000(0.0000) Steps 706(704.55) | Grad Norm 0.6583(0.5554) | Total Time 0.00(0.00)\n",
      "Iter 2006 | Time 79.1116(74.7908) | Bit/dim 3.4986(3.5005) | Xent 0.0000(0.0000) | Loss 8.6514(9.6649) | Error 0.0000(0.0000) Steps 712(704.77) | Grad Norm 0.4597(0.5525) | Total Time 0.00(0.00)\n",
      "Iter 2007 | Time 80.1536(74.9516) | Bit/dim 3.5078(3.5007) | Xent 0.0000(0.0000) | Loss 8.6059(9.6331) | Error 0.0000(0.0000) Steps 700(704.63) | Grad Norm 0.5166(0.5514) | Total Time 0.00(0.00)\n",
      "Iter 2008 | Time 71.8520(74.8587) | Bit/dim 3.5105(3.5010) | Xent 0.0000(0.0000) | Loss 8.8616(9.6099) | Error 0.0000(0.0000) Steps 676(703.77) | Grad Norm 0.4176(0.5474) | Total Time 0.00(0.00)\n",
      "Iter 2009 | Time 77.2619(74.9307) | Bit/dim 3.4846(3.5005) | Xent 0.0000(0.0000) | Loss 8.9918(9.5914) | Error 0.0000(0.0000) Steps 736(704.74) | Grad Norm 0.4884(0.5456) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 75.4175(74.9453) | Bit/dim 3.4963(3.5004) | Xent 0.0000(0.0000) | Loss 8.8424(9.5689) | Error 0.0000(0.0000) Steps 712(704.96) | Grad Norm 0.5185(0.5448) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 25.0365, Epoch Time 500.7195(448.3085), Bit/dim 3.5011(best: 3.4968), Xent 0.0000, Loss 3.5011, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2011 | Time 74.6648(74.9369) | Bit/dim 3.5013(3.5004) | Xent 0.0000(0.0000) | Loss 13.1524(9.6764) | Error 0.0000(0.0000) Steps 712(705.17) | Grad Norm 0.5043(0.5436) | Total Time 0.00(0.00)\n",
      "Iter 2012 | Time 77.5271(75.0146) | Bit/dim 3.5031(3.5005) | Xent 0.0000(0.0000) | Loss 8.9523(9.6547) | Error 0.0000(0.0000) Steps 706(705.19) | Grad Norm 0.5490(0.5438) | Total Time 0.00(0.00)\n",
      "Iter 2013 | Time 79.0288(75.1351) | Bit/dim 3.4953(3.5003) | Xent 0.0000(0.0000) | Loss 8.8094(9.6294) | Error 0.0000(0.0000) Steps 724(705.76) | Grad Norm 0.7197(0.5491) | Total Time 0.00(0.00)\n",
      "Iter 2014 | Time 78.7447(75.2434) | Bit/dim 3.4933(3.5001) | Xent 0.0000(0.0000) | Loss 8.9430(9.6088) | Error 0.0000(0.0000) Steps 730(706.48) | Grad Norm 0.4366(0.5457) | Total Time 0.00(0.00)\n",
      "Iter 2015 | Time 77.7086(75.3173) | Bit/dim 3.4967(3.5000) | Xent 0.0000(0.0000) | Loss 8.7162(9.5820) | Error 0.0000(0.0000) Steps 688(705.93) | Grad Norm 0.6979(0.5502) | Total Time 0.00(0.00)\n",
      "Iter 2016 | Time 80.5995(75.4758) | Bit/dim 3.5080(3.5003) | Xent 0.0000(0.0000) | Loss 8.8901(9.5612) | Error 0.0000(0.0000) Steps 736(706.83) | Grad Norm 0.4258(0.5465) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 24.9238, Epoch Time 509.0418(450.1305), Bit/dim 3.5037(best: 3.4968), Xent 0.0000, Loss 3.5037, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2017 | Time 79.9900(75.6112) | Bit/dim 3.5032(3.5003) | Xent 0.0000(0.0000) | Loss 13.1638(9.6693) | Error 0.0000(0.0000) Steps 712(706.99) | Grad Norm 0.5903(0.5478) | Total Time 0.00(0.00)\n",
      "Iter 2018 | Time 73.3559(75.5435) | Bit/dim 3.4921(3.5001) | Xent 0.0000(0.0000) | Loss 8.8828(9.6457) | Error 0.0000(0.0000) Steps 700(706.78) | Grad Norm 0.7250(0.5531) | Total Time 0.00(0.00)\n",
      "Iter 2019 | Time 76.8320(75.5822) | Bit/dim 3.5047(3.5002) | Xent 0.0000(0.0000) | Loss 8.8552(9.6220) | Error 0.0000(0.0000) Steps 700(706.57) | Grad Norm 0.4671(0.5506) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 76.4569(75.6084) | Bit/dim 3.5084(3.5005) | Xent 0.0000(0.0000) | Loss 8.7662(9.5963) | Error 0.0000(0.0000) Steps 694(706.20) | Grad Norm 0.7415(0.5563) | Total Time 0.00(0.00)\n",
      "Iter 2021 | Time 71.1272(75.4740) | Bit/dim 3.4944(3.5003) | Xent 0.0000(0.0000) | Loss 8.5718(9.5656) | Error 0.0000(0.0000) Steps 700(706.01) | Grad Norm 0.6330(0.5586) | Total Time 0.00(0.00)\n",
      "Iter 2022 | Time 81.4957(75.6547) | Bit/dim 3.5034(3.5004) | Xent 0.0000(0.0000) | Loss 8.9321(9.5466) | Error 0.0000(0.0000) Steps 724(706.55) | Grad Norm 0.3089(0.5511) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 24.9139, Epoch Time 500.2261(451.6333), Bit/dim 3.5021(best: 3.4968), Xent 0.0000, Loss 3.5021, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2023 | Time 79.7661(75.7780) | Bit/dim 3.4978(3.5003) | Xent 0.0000(0.0000) | Loss 13.5328(9.6662) | Error 0.0000(0.0000) Steps 718(706.89) | Grad Norm 0.6338(0.5536) | Total Time 0.00(0.00)\n",
      "Iter 2024 | Time 76.2759(75.7929) | Bit/dim 3.5048(3.5004) | Xent 0.0000(0.0000) | Loss 8.8196(9.6408) | Error 0.0000(0.0000) Steps 718(707.23) | Grad Norm 0.4898(0.5517) | Total Time 0.00(0.00)\n",
      "Iter 2025 | Time 76.4853(75.8137) | Bit/dim 3.4909(3.5002) | Xent 0.0000(0.0000) | Loss 8.9329(9.6195) | Error 0.0000(0.0000) Steps 730(707.91) | Grad Norm 0.4416(0.5484) | Total Time 0.00(0.00)\n",
      "Iter 2026 | Time 78.4029(75.8914) | Bit/dim 3.5062(3.5003) | Xent 0.0000(0.0000) | Loss 8.5419(9.5872) | Error 0.0000(0.0000) Steps 688(707.31) | Grad Norm 0.6773(0.5522) | Total Time 0.00(0.00)\n",
      "Iter 2027 | Time 76.6299(75.9135) | Bit/dim 3.5054(3.5005) | Xent 0.0000(0.0000) | Loss 8.9616(9.5684) | Error 0.0000(0.0000) Steps 730(707.99) | Grad Norm 0.4449(0.5490) | Total Time 0.00(0.00)\n",
      "Iter 2028 | Time 78.0080(75.9764) | Bit/dim 3.4994(3.5005) | Xent 0.0000(0.0000) | Loss 8.8354(9.5464) | Error 0.0000(0.0000) Steps 694(707.57) | Grad Norm 0.4917(0.5473) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 25.6955, Epoch Time 507.7046(453.3155), Bit/dim 3.5024(best: 3.4968), Xent 0.0000, Loss 3.5024, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2029 | Time 75.5990(75.9650) | Bit/dim 3.5101(3.5007) | Xent 0.0000(0.0000) | Loss 13.7898(9.6737) | Error 0.0000(0.0000) Steps 706(707.53) | Grad Norm 0.6208(0.5495) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 71.0666(75.8181) | Bit/dim 3.4894(3.5004) | Xent 0.0000(0.0000) | Loss 8.9790(9.6529) | Error 0.0000(0.0000) Steps 700(707.30) | Grad Norm 0.4437(0.5463) | Total Time 0.00(0.00)\n",
      "Iter 2031 | Time 72.8469(75.7290) | Bit/dim 3.4959(3.5003) | Xent 0.0000(0.0000) | Loss 8.6591(9.6231) | Error 0.0000(0.0000) Steps 688(706.72) | Grad Norm 0.4702(0.5440) | Total Time 0.00(0.00)\n",
      "Iter 2032 | Time 78.2739(75.8053) | Bit/dim 3.5141(3.5007) | Xent 0.0000(0.0000) | Loss 8.6663(9.5944) | Error 0.0000(0.0000) Steps 694(706.34) | Grad Norm 0.6225(0.5464) | Total Time 0.00(0.00)\n",
      "Iter 2033 | Time 73.5595(75.7379) | Bit/dim 3.5001(3.5007) | Xent 0.0000(0.0000) | Loss 8.9274(9.5744) | Error 0.0000(0.0000) Steps 706(706.33) | Grad Norm 0.3414(0.5402) | Total Time 0.00(0.00)\n",
      "Iter 2034 | Time 76.6044(75.7639) | Bit/dim 3.4877(3.5003) | Xent 0.0000(0.0000) | Loss 9.0132(9.5575) | Error 0.0000(0.0000) Steps 724(706.86) | Grad Norm 0.6346(0.5431) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 25.9962, Epoch Time 489.9642(454.4149), Bit/dim 3.4990(best: 3.4968), Xent 0.0000, Loss 3.4990, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2035 | Time 79.3181(75.8706) | Bit/dim 3.4952(3.5001) | Xent 0.0000(0.0000) | Loss 12.8449(9.6562) | Error 0.0000(0.0000) Steps 706(706.83) | Grad Norm 0.7652(0.5497) | Total Time 0.00(0.00)\n",
      "Iter 2036 | Time 83.0594(76.0862) | Bit/dim 3.4885(3.4998) | Xent 0.0000(0.0000) | Loss 8.7894(9.6302) | Error 0.0000(0.0000) Steps 718(707.17) | Grad Norm 0.3419(0.5435) | Total Time 0.00(0.00)\n",
      "Iter 2037 | Time 72.8449(75.9890) | Bit/dim 3.5089(3.5000) | Xent 0.0000(0.0000) | Loss 8.6269(9.6001) | Error 0.0000(0.0000) Steps 682(706.41) | Grad Norm 0.6031(0.5453) | Total Time 0.00(0.00)\n",
      "Iter 2038 | Time 74.0992(75.9323) | Bit/dim 3.5041(3.5002) | Xent 0.0000(0.0000) | Loss 9.0257(9.5828) | Error 0.0000(0.0000) Steps 694(706.04) | Grad Norm 0.4017(0.5410) | Total Time 0.00(0.00)\n",
      "Iter 2039 | Time 77.7233(75.9860) | Bit/dim 3.5068(3.5004) | Xent 0.0000(0.0000) | Loss 8.6171(9.5539) | Error 0.0000(0.0000) Steps 712(706.22) | Grad Norm 0.5837(0.5423) | Total Time 0.00(0.00)\n",
      "Iter 2040 | Time 75.9234(75.9841) | Bit/dim 3.5038(3.5005) | Xent 0.0000(0.0000) | Loss 9.1070(9.5404) | Error 0.0000(0.0000) Steps 724(706.75) | Grad Norm 0.6248(0.5447) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 25.5111, Epoch Time 504.7354(455.9246), Bit/dim 3.5016(best: 3.4968), Xent 0.0000, Loss 3.5016, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2041 | Time 71.9067(75.8618) | Bit/dim 3.5126(3.5008) | Xent 0.0000(0.0000) | Loss 13.1271(9.6480) | Error 0.0000(0.0000) Steps 700(706.55) | Grad Norm 0.4980(0.5433) | Total Time 0.00(0.00)\n",
      "Iter 2042 | Time 73.7534(75.7986) | Bit/dim 3.5022(3.5009) | Xent 0.0000(0.0000) | Loss 8.8553(9.6243) | Error 0.0000(0.0000) Steps 694(706.17) | Grad Norm 0.4650(0.5410) | Total Time 0.00(0.00)\n",
      "Iter 2043 | Time 75.6614(75.7944) | Bit/dim 3.4834(3.5004) | Xent 0.0000(0.0000) | Loss 8.7697(9.5986) | Error 0.0000(0.0000) Steps 694(705.81) | Grad Norm 0.6209(0.5434) | Total Time 0.00(0.00)\n",
      "Iter 2044 | Time 78.6060(75.8788) | Bit/dim 3.5057(3.5005) | Xent 0.0000(0.0000) | Loss 8.6182(9.5692) | Error 0.0000(0.0000) Steps 706(705.82) | Grad Norm 0.5256(0.5429) | Total Time 0.00(0.00)\n",
      "Iter 2045 | Time 73.5731(75.8096) | Bit/dim 3.4998(3.5005) | Xent 0.0000(0.0000) | Loss 8.5633(9.5390) | Error 0.0000(0.0000) Steps 694(705.46) | Grad Norm 0.5032(0.5417) | Total Time 0.00(0.00)\n",
      "Iter 2046 | Time 78.8659(75.9013) | Bit/dim 3.5062(3.5007) | Xent 0.0000(0.0000) | Loss 8.8540(9.5185) | Error 0.0000(0.0000) Steps 706(705.48) | Grad Norm 0.4380(0.5386) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 24.8217, Epoch Time 493.4298(457.0497), Bit/dim 3.5015(best: 3.4968), Xent 0.0000, Loss 3.5015, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2047 | Time 77.3663(75.9453) | Bit/dim 3.4947(3.5005) | Xent 0.0000(0.0000) | Loss 13.2575(9.6307) | Error 0.0000(0.0000) Steps 712(705.67) | Grad Norm 0.5591(0.5392) | Total Time 0.00(0.00)\n",
      "Iter 2048 | Time 74.5209(75.9025) | Bit/dim 3.4861(3.5001) | Xent 0.0000(0.0000) | Loss 8.7655(9.6047) | Error 0.0000(0.0000) Steps 688(705.14) | Grad Norm 0.4693(0.5371) | Total Time 0.00(0.00)\n",
      "Iter 2049 | Time 74.7918(75.8692) | Bit/dim 3.4960(3.4999) | Xent 0.0000(0.0000) | Loss 8.7534(9.5792) | Error 0.0000(0.0000) Steps 706(705.17) | Grad Norm 0.4534(0.5346) | Total Time 0.00(0.00)\n",
      "Iter 2050 | Time 74.6478(75.8326) | Bit/dim 3.5117(3.5003) | Xent 0.0000(0.0000) | Loss 8.7618(9.5546) | Error 0.0000(0.0000) Steps 706(705.19) | Grad Norm 0.7286(0.5404) | Total Time 0.00(0.00)\n",
      "Iter 2051 | Time 79.0944(75.9304) | Bit/dim 3.5084(3.5005) | Xent 0.0000(0.0000) | Loss 8.9205(9.5356) | Error 0.0000(0.0000) Steps 706(705.22) | Grad Norm 0.5369(0.5403) | Total Time 0.00(0.00)\n",
      "Iter 2052 | Time 77.0482(75.9640) | Bit/dim 3.4990(3.5005) | Xent 0.0000(0.0000) | Loss 8.8661(9.5155) | Error 0.0000(0.0000) Steps 706(705.24) | Grad Norm 0.3980(0.5360) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 25.5879, Epoch Time 499.0345(458.3093), Bit/dim 3.4991(best: 3.4968), Xent 0.0000, Loss 3.4991, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2053 | Time 81.0584(76.1168) | Bit/dim 3.4918(3.5002) | Xent 0.0000(0.0000) | Loss 13.8810(9.6465) | Error 0.0000(0.0000) Steps 718(705.62) | Grad Norm 0.6180(0.5385) | Total Time 0.00(0.00)\n",
      "Iter 2054 | Time 77.8798(76.1697) | Bit/dim 3.5023(3.5003) | Xent 0.0000(0.0000) | Loss 8.9430(9.6254) | Error 0.0000(0.0000) Steps 712(705.81) | Grad Norm 0.5734(0.5395) | Total Time 0.00(0.00)\n",
      "Iter 2055 | Time 75.1392(76.1388) | Bit/dim 3.4943(3.5001) | Xent 0.0000(0.0000) | Loss 8.8324(9.6016) | Error 0.0000(0.0000) Steps 724(706.36) | Grad Norm 0.5603(0.5401) | Total Time 0.00(0.00)\n",
      "Iter 2056 | Time 71.4440(75.9979) | Bit/dim 3.5224(3.5008) | Xent 0.0000(0.0000) | Loss 8.8750(9.5798) | Error 0.0000(0.0000) Steps 706(706.35) | Grad Norm 0.8111(0.5483) | Total Time 0.00(0.00)\n",
      "Iter 2057 | Time 78.9467(76.0864) | Bit/dim 3.4908(3.5005) | Xent 0.0000(0.0000) | Loss 8.9623(9.5613) | Error 0.0000(0.0000) Steps 706(706.34) | Grad Norm 0.5404(0.5480) | Total Time 0.00(0.00)\n",
      "Iter 2058 | Time 73.4513(76.0073) | Bit/dim 3.5004(3.5005) | Xent 0.0000(0.0000) | Loss 8.6563(9.5341) | Error 0.0000(0.0000) Steps 700(706.15) | Grad Norm 0.7648(0.5545) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 25.4397, Epoch Time 499.7827(459.5535), Bit/dim 3.4996(best: 3.4968), Xent 0.0000, Loss 3.4996, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2059 | Time 82.0323(76.1881) | Bit/dim 3.4929(3.5002) | Xent 0.0000(0.0000) | Loss 13.5015(9.6531) | Error 0.0000(0.0000) Steps 724(706.68) | Grad Norm 0.8183(0.5625) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 81.4697(76.3465) | Bit/dim 3.4897(3.4999) | Xent 0.0000(0.0000) | Loss 8.5798(9.6210) | Error 0.0000(0.0000) Steps 718(707.02) | Grad Norm 0.4639(0.5595) | Total Time 0.00(0.00)\n",
      "Iter 2061 | Time 75.2710(76.3143) | Bit/dim 3.4998(3.4999) | Xent 0.0000(0.0000) | Loss 8.6707(9.5924) | Error 0.0000(0.0000) Steps 712(707.17) | Grad Norm 0.5265(0.5585) | Total Time 0.00(0.00)\n",
      "Iter 2062 | Time 72.6078(76.2031) | Bit/dim 3.4974(3.4998) | Xent 0.0000(0.0000) | Loss 8.9696(9.5738) | Error 0.0000(0.0000) Steps 694(706.78) | Grad Norm 0.4265(0.5545) | Total Time 0.00(0.00)\n",
      "Iter 2063 | Time 79.2197(76.2936) | Bit/dim 3.4978(3.4998) | Xent 0.0000(0.0000) | Loss 8.9699(9.5556) | Error 0.0000(0.0000) Steps 712(706.93) | Grad Norm 0.4453(0.5513) | Total Time 0.00(0.00)\n",
      "Iter 2064 | Time 77.1691(76.3198) | Bit/dim 3.4953(3.4997) | Xent 0.0000(0.0000) | Loss 8.9462(9.5374) | Error 0.0000(0.0000) Steps 712(707.09) | Grad Norm 0.6656(0.5547) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 25.0301, Epoch Time 508.4043(461.0190), Bit/dim 3.5018(best: 3.4968), Xent 0.0000, Loss 3.5018, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2065 | Time 78.2634(76.3781) | Bit/dim 3.4948(3.4995) | Xent 0.0000(0.0000) | Loss 13.4729(9.6554) | Error 0.0000(0.0000) Steps 718(707.41) | Grad Norm 0.4743(0.5523) | Total Time 0.00(0.00)\n",
      "Iter 2066 | Time 78.4360(76.4399) | Bit/dim 3.4988(3.4995) | Xent 0.0000(0.0000) | Loss 8.6902(9.6265) | Error 0.0000(0.0000) Steps 700(707.19) | Grad Norm 0.5687(0.5528) | Total Time 0.00(0.00)\n",
      "Iter 2067 | Time 79.4068(76.5289) | Bit/dim 3.5048(3.4996) | Xent 0.0000(0.0000) | Loss 8.9697(9.6068) | Error 0.0000(0.0000) Steps 712(707.34) | Grad Norm 0.5041(0.5513) | Total Time 0.00(0.00)\n",
      "Iter 2068 | Time 80.6812(76.6535) | Bit/dim 3.4946(3.4995) | Xent 0.0000(0.0000) | Loss 8.8124(9.5829) | Error 0.0000(0.0000) Steps 700(707.12) | Grad Norm 0.4161(0.5473) | Total Time 0.00(0.00)\n",
      "Iter 2069 | Time 81.7708(76.8070) | Bit/dim 3.4966(3.4994) | Xent 0.0000(0.0000) | Loss 8.8185(9.5600) | Error 0.0000(0.0000) Steps 712(707.26) | Grad Norm 0.4803(0.5453) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 78.2771(76.8511) | Bit/dim 3.4982(3.4994) | Xent 0.0000(0.0000) | Loss 8.9042(9.5403) | Error 0.0000(0.0000) Steps 718(707.58) | Grad Norm 0.3563(0.5396) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 25.0755, Epoch Time 517.8665(462.7244), Bit/dim 3.5027(best: 3.4968), Xent 0.0000, Loss 3.5027, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2071 | Time 80.3157(76.9550) | Bit/dim 3.5008(3.4994) | Xent 0.0000(0.0000) | Loss 13.7186(9.6657) | Error 0.0000(0.0000) Steps 718(707.90) | Grad Norm 0.5073(0.5386) | Total Time 0.00(0.00)\n",
      "Iter 2072 | Time 79.2813(77.0248) | Bit/dim 3.5025(3.4995) | Xent 0.0000(0.0000) | Loss 9.1131(9.6491) | Error 0.0000(0.0000) Steps 718(708.20) | Grad Norm 0.5418(0.5387) | Total Time 0.00(0.00)\n",
      "Iter 2073 | Time 80.7246(77.1358) | Bit/dim 3.4909(3.4992) | Xent 0.0000(0.0000) | Loss 8.8496(9.6251) | Error 0.0000(0.0000) Steps 718(708.49) | Grad Norm 0.4658(0.5365) | Total Time 0.00(0.00)\n",
      "Iter 2074 | Time 75.9263(77.0995) | Bit/dim 3.5154(3.4997) | Xent 0.0000(0.0000) | Loss 8.8300(9.6013) | Error 0.0000(0.0000) Steps 688(707.88) | Grad Norm 0.4203(0.5330) | Total Time 0.00(0.00)\n",
      "Iter 2075 | Time 75.1900(77.0422) | Bit/dim 3.4916(3.4995) | Xent 0.0000(0.0000) | Loss 8.9584(9.5820) | Error 0.0000(0.0000) Steps 724(708.36) | Grad Norm 0.4848(0.5316) | Total Time 0.00(0.00)\n",
      "Iter 2076 | Time 73.9094(76.9482) | Bit/dim 3.4998(3.4995) | Xent 0.0000(0.0000) | Loss 9.0123(9.5649) | Error 0.0000(0.0000) Steps 712(708.47) | Grad Norm 0.6707(0.5358) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 25.5060, Epoch Time 507.1170(464.0562), Bit/dim 3.4909(best: 3.4968), Xent 0.0000, Loss 3.4909, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2077 | Time 85.5888(77.2075) | Bit/dim 3.4834(3.4990) | Xent 0.0000(0.0000) | Loss 13.6842(9.6885) | Error 0.0000(0.0000) Steps 754(709.84) | Grad Norm 0.7149(0.5411) | Total Time 0.00(0.00)\n",
      "Iter 2078 | Time 80.5300(77.3071) | Bit/dim 3.4985(3.4990) | Xent 0.0000(0.0000) | Loss 9.0346(9.6688) | Error 0.0000(0.0000) Steps 706(709.72) | Grad Norm 0.5585(0.5417) | Total Time 0.00(0.00)\n",
      "Iter 2079 | Time 72.2147(77.1544) | Bit/dim 3.4963(3.4989) | Xent 0.0000(0.0000) | Loss 8.8490(9.6443) | Error 0.0000(0.0000) Steps 694(709.25) | Grad Norm 0.3267(0.5352) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 75.8400(77.1149) | Bit/dim 3.5023(3.4990) | Xent 0.0000(0.0000) | Loss 8.6460(9.6143) | Error 0.0000(0.0000) Steps 694(708.79) | Grad Norm 0.4438(0.5325) | Total Time 0.00(0.00)\n",
      "Iter 2081 | Time 75.6566(77.0712) | Bit/dim 3.4976(3.4990) | Xent 0.0000(0.0000) | Loss 8.8794(9.5923) | Error 0.0000(0.0000) Steps 700(708.53) | Grad Norm 0.3908(0.5282) | Total Time 0.00(0.00)\n",
      "Iter 2082 | Time 80.0233(77.1597) | Bit/dim 3.4906(3.4987) | Xent 0.0000(0.0000) | Loss 8.8786(9.5709) | Error 0.0000(0.0000) Steps 724(708.99) | Grad Norm 0.3452(0.5227) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 24.8041, Epoch Time 510.5893(465.4522), Bit/dim 3.4965(best: 3.4909), Xent 0.0000, Loss 3.4965, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2083 | Time 81.5411(77.2912) | Bit/dim 3.5054(3.4989) | Xent 0.0000(0.0000) | Loss 13.2118(9.6801) | Error 0.0000(0.0000) Steps 718(709.26) | Grad Norm 0.4749(0.5213) | Total Time 0.00(0.00)\n",
      "Iter 2084 | Time 75.8246(77.2472) | Bit/dim 3.4923(3.4987) | Xent 0.0000(0.0000) | Loss 8.8047(9.6538) | Error 0.0000(0.0000) Steps 718(709.53) | Grad Norm 0.3672(0.5167) | Total Time 0.00(0.00)\n",
      "Iter 2085 | Time 81.8413(77.3850) | Bit/dim 3.4771(3.4981) | Xent 0.0000(0.0000) | Loss 9.0303(9.6351) | Error 0.0000(0.0000) Steps 718(709.78) | Grad Norm 0.5012(0.5162) | Total Time 0.00(0.00)\n",
      "Iter 2086 | Time 81.2745(77.5017) | Bit/dim 3.5012(3.4982) | Xent 0.0000(0.0000) | Loss 8.8008(9.6101) | Error 0.0000(0.0000) Steps 706(709.67) | Grad Norm 0.5757(0.5180) | Total Time 0.00(0.00)\n",
      "Iter 2087 | Time 83.4536(77.6803) | Bit/dim 3.4915(3.4980) | Xent 0.0000(0.0000) | Loss 9.0204(9.5924) | Error 0.0000(0.0000) Steps 718(709.92) | Grad Norm 0.3387(0.5126) | Total Time 0.00(0.00)\n",
      "Iter 2088 | Time 77.0033(77.6599) | Bit/dim 3.5028(3.4981) | Xent 0.0000(0.0000) | Loss 8.8074(9.5688) | Error 0.0000(0.0000) Steps 712(709.98) | Grad Norm 0.4925(0.5120) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 25.5662, Epoch Time 522.0888(467.1513), Bit/dim 3.4975(best: 3.4909), Xent 0.0000, Loss 3.4975, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2089 | Time 76.1420(77.6144) | Bit/dim 3.4946(3.4980) | Xent 0.0000(0.0000) | Loss 13.7144(9.6932) | Error 0.0000(0.0000) Steps 706(709.86) | Grad Norm 0.5790(0.5140) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 78.1191(77.6295) | Bit/dim 3.4922(3.4978) | Xent 0.0000(0.0000) | Loss 8.9236(9.6701) | Error 0.0000(0.0000) Steps 724(710.28) | Grad Norm 0.3501(0.5091) | Total Time 0.00(0.00)\n",
      "Iter 2091 | Time 78.1962(77.6465) | Bit/dim 3.5000(3.4979) | Xent 0.0000(0.0000) | Loss 8.7067(9.6412) | Error 0.0000(0.0000) Steps 718(710.52) | Grad Norm 0.4389(0.5070) | Total Time 0.00(0.00)\n",
      "Iter 2092 | Time 83.4561(77.8208) | Bit/dim 3.5017(3.4980) | Xent 0.0000(0.0000) | Loss 8.8391(9.6172) | Error 0.0000(0.0000) Steps 736(711.28) | Grad Norm 0.5653(0.5087) | Total Time 0.00(0.00)\n",
      "Iter 2093 | Time 82.8443(77.9715) | Bit/dim 3.5004(3.4981) | Xent 0.0000(0.0000) | Loss 8.9040(9.5958) | Error 0.0000(0.0000) Steps 700(710.94) | Grad Norm 0.5316(0.5094) | Total Time 0.00(0.00)\n",
      "Iter 2094 | Time 80.0883(78.0350) | Bit/dim 3.4920(3.4979) | Xent 0.0000(0.0000) | Loss 8.7432(9.5702) | Error 0.0000(0.0000) Steps 718(711.15) | Grad Norm 0.5654(0.5111) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 25.0065, Epoch Time 519.9076(468.7340), Bit/dim 3.4945(best: 3.4909), Xent 0.0000, Loss 3.4945, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2095 | Time 77.9928(78.0338) | Bit/dim 3.4922(3.4977) | Xent 0.0000(0.0000) | Loss 13.6620(9.6929) | Error 0.0000(0.0000) Steps 730(711.72) | Grad Norm 0.3946(0.5076) | Total Time 0.00(0.00)\n",
      "Iter 2096 | Time 73.2274(77.8896) | Bit/dim 3.4920(3.4976) | Xent 0.0000(0.0000) | Loss 8.9492(9.6706) | Error 0.0000(0.0000) Steps 694(711.19) | Grad Norm 0.4627(0.5063) | Total Time 0.00(0.00)\n",
      "Iter 2097 | Time 75.6045(77.8210) | Bit/dim 3.5021(3.4977) | Xent 0.0000(0.0000) | Loss 8.7602(9.6433) | Error 0.0000(0.0000) Steps 700(710.85) | Grad Norm 0.6486(0.5105) | Total Time 0.00(0.00)\n",
      "Iter 2098 | Time 75.9370(77.7645) | Bit/dim 3.4973(3.4977) | Xent 0.0000(0.0000) | Loss 8.6808(9.6144) | Error 0.0000(0.0000) Steps 700(710.53) | Grad Norm 0.3756(0.5065) | Total Time 0.00(0.00)\n",
      "Iter 2099 | Time 78.8430(77.7969) | Bit/dim 3.4980(3.4977) | Xent 0.0000(0.0000) | Loss 8.7863(9.5896) | Error 0.0000(0.0000) Steps 700(710.21) | Grad Norm 0.5925(0.5091) | Total Time 0.00(0.00)\n",
      "Iter 2100 | Time 75.7682(77.7360) | Bit/dim 3.5002(3.4978) | Xent 0.0000(0.0000) | Loss 8.8384(9.5671) | Error 0.0000(0.0000) Steps 706(710.08) | Grad Norm 0.7166(0.5153) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 24.9489, Epoch Time 498.0521(469.6135), Bit/dim 3.4987(best: 3.4909), Xent 0.0000, Loss 3.4987, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2101 | Time 74.5802(77.6413) | Bit/dim 3.5055(3.4980) | Xent 0.0000(0.0000) | Loss 13.1991(9.6760) | Error 0.0000(0.0000) Steps 700(709.78) | Grad Norm 0.8206(0.5245) | Total Time 0.00(0.00)\n",
      "Iter 2102 | Time 76.8087(77.6163) | Bit/dim 3.5044(3.4982) | Xent 0.0000(0.0000) | Loss 9.0051(9.6559) | Error 0.0000(0.0000) Steps 700(709.49) | Grad Norm 0.7223(0.5304) | Total Time 0.00(0.00)\n",
      "Iter 2103 | Time 72.8213(77.4725) | Bit/dim 3.4990(3.4982) | Xent 0.0000(0.0000) | Loss 9.0164(9.6367) | Error 0.0000(0.0000) Steps 718(709.74) | Grad Norm 0.5169(0.5300) | Total Time 0.00(0.00)\n",
      "Iter 2104 | Time 77.1797(77.4637) | Bit/dim 3.4875(3.4979) | Xent 0.0000(0.0000) | Loss 8.7727(9.6108) | Error 0.0000(0.0000) Steps 712(709.81) | Grad Norm 0.3996(0.5261) | Total Time 0.00(0.00)\n",
      "Iter 2105 | Time 81.0075(77.5700) | Bit/dim 3.4980(3.4979) | Xent 0.0000(0.0000) | Loss 9.0104(9.5928) | Error 0.0000(0.0000) Steps 730(710.42) | Grad Norm 0.6656(0.5303) | Total Time 0.00(0.00)\n",
      "Iter 2106 | Time 76.6433(77.5422) | Bit/dim 3.4950(3.4978) | Xent 0.0000(0.0000) | Loss 8.8581(9.5707) | Error 0.0000(0.0000) Steps 706(710.28) | Grad Norm 0.7731(0.5376) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 24.8063, Epoch Time 499.9288(470.5230), Bit/dim 3.5053(best: 3.4909), Xent 0.0000, Loss 3.5053, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2107 | Time 79.7069(77.6072) | Bit/dim 3.4807(3.4973) | Xent 0.0000(0.0000) | Loss 13.1898(9.6793) | Error 0.0000(0.0000) Steps 706(710.16) | Grad Norm 0.7444(0.5438) | Total Time 0.00(0.00)\n",
      "Iter 2108 | Time 76.5109(77.5743) | Bit/dim 3.5030(3.4975) | Xent 0.0000(0.0000) | Loss 8.9912(9.6587) | Error 0.0000(0.0000) Steps 700(709.85) | Grad Norm 0.6297(0.5463) | Total Time 0.00(0.00)\n",
      "Iter 2109 | Time 79.9035(77.6442) | Bit/dim 3.5006(3.4976) | Xent 0.0000(0.0000) | Loss 9.0442(9.6402) | Error 0.0000(0.0000) Steps 712(709.92) | Grad Norm 0.4320(0.5429) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 81.0149(77.7453) | Bit/dim 3.4872(3.4973) | Xent 0.0000(0.0000) | Loss 8.8066(9.6152) | Error 0.0000(0.0000) Steps 718(710.16) | Grad Norm 0.4539(0.5402) | Total Time 0.00(0.00)\n",
      "Iter 2111 | Time 73.4646(77.6169) | Bit/dim 3.4937(3.4971) | Xent 0.0000(0.0000) | Loss 8.7709(9.5899) | Error 0.0000(0.0000) Steps 682(709.31) | Grad Norm 0.6867(0.5446) | Total Time 0.00(0.00)\n",
      "Iter 2112 | Time 74.9896(77.5380) | Bit/dim 3.5028(3.4973) | Xent 0.0000(0.0000) | Loss 9.0275(9.5730) | Error 0.0000(0.0000) Steps 718(709.57) | Grad Norm 0.6202(0.5469) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 25.3487, Epoch Time 507.1252(471.6210), Bit/dim 3.4992(best: 3.4909), Xent 0.0000, Loss 3.4992, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2113 | Time 80.0138(77.6123) | Bit/dim 3.4971(3.4973) | Xent 0.0000(0.0000) | Loss 13.5438(9.6921) | Error 0.0000(0.0000) Steps 718(709.83) | Grad Norm 0.3819(0.5419) | Total Time 0.00(0.00)\n",
      "Iter 2114 | Time 75.7240(77.5557) | Bit/dim 3.4984(3.4973) | Xent 0.0000(0.0000) | Loss 8.7871(9.6650) | Error 0.0000(0.0000) Steps 700(709.53) | Grad Norm 0.6690(0.5458) | Total Time 0.00(0.00)\n",
      "Iter 2115 | Time 75.6100(77.4973) | Bit/dim 3.4960(3.4973) | Xent 0.0000(0.0000) | Loss 8.8994(9.6420) | Error 0.0000(0.0000) Steps 706(709.43) | Grad Norm 0.8461(0.5548) | Total Time 0.00(0.00)\n",
      "Iter 2116 | Time 79.8944(77.5692) | Bit/dim 3.4965(3.4973) | Xent 0.0000(0.0000) | Loss 9.0072(9.6230) | Error 0.0000(0.0000) Steps 712(709.50) | Grad Norm 0.4057(0.5503) | Total Time 0.00(0.00)\n",
      "Iter 2117 | Time 73.2000(77.4381) | Bit/dim 3.4902(3.4971) | Xent 0.0000(0.0000) | Loss 8.6791(9.5947) | Error 0.0000(0.0000) Steps 694(709.04) | Grad Norm 0.6711(0.5539) | Total Time 0.00(0.00)\n",
      "Iter 2118 | Time 81.7532(77.5676) | Bit/dim 3.4985(3.4971) | Xent 0.0000(0.0000) | Loss 9.0171(9.5773) | Error 0.0000(0.0000) Steps 712(709.13) | Grad Norm 0.9384(0.5655) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 25.0373, Epoch Time 507.2166(472.6889), Bit/dim 3.4957(best: 3.4909), Xent 0.0000, Loss 3.4957, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2119 | Time 84.0877(77.7632) | Bit/dim 3.4912(3.4969) | Xent 0.0000(0.0000) | Loss 13.7273(9.7018) | Error 0.0000(0.0000) Steps 724(709.57) | Grad Norm 0.7589(0.5713) | Total Time 0.00(0.00)\n",
      "Iter 2120 | Time 77.4033(77.7524) | Bit/dim 3.4996(3.4970) | Xent 0.0000(0.0000) | Loss 8.9042(9.6779) | Error 0.0000(0.0000) Steps 706(709.47) | Grad Norm 0.5837(0.5716) | Total Time 0.00(0.00)\n",
      "Iter 2121 | Time 82.6185(77.8984) | Bit/dim 3.4908(3.4968) | Xent 0.0000(0.0000) | Loss 8.9440(9.6559) | Error 0.0000(0.0000) Steps 724(709.90) | Grad Norm 0.5632(0.5714) | Total Time 0.00(0.00)\n",
      "Iter 2122 | Time 83.1166(78.0549) | Bit/dim 3.4993(3.4969) | Xent 0.0000(0.0000) | Loss 8.9252(9.6340) | Error 0.0000(0.0000) Steps 730(710.50) | Grad Norm 0.6696(0.5743) | Total Time 0.00(0.00)\n",
      "Iter 2123 | Time 79.2930(78.0921) | Bit/dim 3.4840(3.4965) | Xent 0.0000(0.0000) | Loss 8.9144(9.6124) | Error 0.0000(0.0000) Steps 706(710.37) | Grad Norm 0.7027(0.5782) | Total Time 0.00(0.00)\n",
      "Iter 2124 | Time 85.5230(78.3150) | Bit/dim 3.4991(3.4966) | Xent 0.0000(0.0000) | Loss 8.9289(9.5919) | Error 0.0000(0.0000) Steps 730(710.96) | Grad Norm 0.4264(0.5736) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 25.3789, Epoch Time 533.7809(474.5217), Bit/dim 3.4974(best: 3.4909), Xent 0.0000, Loss 3.4974, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2125 | Time 80.5590(78.3823) | Bit/dim 3.4987(3.4967) | Xent 0.0000(0.0000) | Loss 13.7111(9.7155) | Error 0.0000(0.0000) Steps 724(711.35) | Grad Norm 0.4854(0.5710) | Total Time 0.00(0.00)\n",
      "Iter 2126 | Time 78.4330(78.3838) | Bit/dim 3.5007(3.4968) | Xent 0.0000(0.0000) | Loss 8.9354(9.6921) | Error 0.0000(0.0000) Steps 712(711.37) | Grad Norm 0.8928(0.5806) | Total Time 0.00(0.00)\n",
      "Iter 2127 | Time 77.8913(78.3691) | Bit/dim 3.4893(3.4966) | Xent 0.0000(0.0000) | Loss 8.8755(9.6676) | Error 0.0000(0.0000) Steps 718(711.57) | Grad Norm 0.8002(0.5872) | Total Time 0.00(0.00)\n",
      "Iter 2128 | Time 77.4791(78.3424) | Bit/dim 3.4953(3.4965) | Xent 0.0000(0.0000) | Loss 8.8201(9.6421) | Error 0.0000(0.0000) Steps 700(711.22) | Grad Norm 0.3670(0.5806) | Total Time 0.00(0.00)\n",
      "Iter 2129 | Time 77.0448(78.3034) | Bit/dim 3.5077(3.4969) | Xent 0.0000(0.0000) | Loss 8.7063(9.6141) | Error 0.0000(0.0000) Steps 724(711.60) | Grad Norm 0.6307(0.5821) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 79.6648(78.3443) | Bit/dim 3.4968(3.4968) | Xent 0.0000(0.0000) | Loss 9.0036(9.5957) | Error 0.0000(0.0000) Steps 742(712.52) | Grad Norm 0.8611(0.5905) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 25.5984, Epoch Time 512.4870(475.6606), Bit/dim 3.4963(best: 3.4909), Xent 0.0000, Loss 3.4963, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2131 | Time 74.6346(78.2330) | Bit/dim 3.4942(3.4968) | Xent 0.0000(0.0000) | Loss 13.7093(9.7191) | Error 0.0000(0.0000) Steps 706(712.32) | Grad Norm 0.6810(0.5932) | Total Time 0.00(0.00)\n",
      "Iter 2132 | Time 79.4573(78.2697) | Bit/dim 3.4985(3.4968) | Xent 0.0000(0.0000) | Loss 8.6121(9.6859) | Error 0.0000(0.0000) Steps 700(711.95) | Grad Norm 0.5544(0.5920) | Total Time 0.00(0.00)\n",
      "Iter 2133 | Time 83.0279(78.4125) | Bit/dim 3.4951(3.4968) | Xent 0.0000(0.0000) | Loss 8.6996(9.6563) | Error 0.0000(0.0000) Steps 736(712.67) | Grad Norm 0.6663(0.5943) | Total Time 0.00(0.00)\n",
      "Iter 2134 | Time 78.3373(78.4102) | Bit/dim 3.4957(3.4967) | Xent 0.0000(0.0000) | Loss 8.7614(9.6295) | Error 0.0000(0.0000) Steps 718(712.83) | Grad Norm 0.6072(0.5947) | Total Time 0.00(0.00)\n",
      "Iter 2135 | Time 78.3298(78.4078) | Bit/dim 3.4934(3.4966) | Xent 0.0000(0.0000) | Loss 8.9502(9.6091) | Error 0.0000(0.0000) Steps 724(713.17) | Grad Norm 0.4886(0.5915) | Total Time 0.00(0.00)\n",
      "Iter 2136 | Time 73.5442(78.2619) | Bit/dim 3.4996(3.4967) | Xent 0.0000(0.0000) | Loss 8.8750(9.5871) | Error 0.0000(0.0000) Steps 676(712.05) | Grad Norm 0.4496(0.5872) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 25.0224, Epoch Time 508.2485(476.6383), Bit/dim 3.4992(best: 3.4909), Xent 0.0000, Loss 3.4992, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2137 | Time 76.8195(78.2186) | Bit/dim 3.5082(3.4971) | Xent 0.0000(0.0000) | Loss 13.5950(9.7073) | Error 0.0000(0.0000) Steps 724(712.41) | Grad Norm 0.6925(0.5904) | Total Time 0.00(0.00)\n",
      "Iter 2138 | Time 76.2781(78.1604) | Bit/dim 3.4878(3.4968) | Xent 0.0000(0.0000) | Loss 8.9123(9.6835) | Error 0.0000(0.0000) Steps 700(712.04) | Grad Norm 0.6988(0.5936) | Total Time 0.00(0.00)\n",
      "Iter 2139 | Time 80.1243(78.2193) | Bit/dim 3.4842(3.4964) | Xent 0.0000(0.0000) | Loss 8.8422(9.6582) | Error 0.0000(0.0000) Steps 700(711.68) | Grad Norm 0.7336(0.5978) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 76.6229(78.1714) | Bit/dim 3.5069(3.4967) | Xent 0.0000(0.0000) | Loss 8.9795(9.6379) | Error 0.0000(0.0000) Steps 712(711.69) | Grad Norm 0.4583(0.5936) | Total Time 0.00(0.00)\n",
      "Iter 2141 | Time 80.9596(78.2551) | Bit/dim 3.4949(3.4967) | Xent 0.0000(0.0000) | Loss 8.9282(9.6166) | Error 0.0000(0.0000) Steps 706(711.52) | Grad Norm 0.3350(0.5859) | Total Time 0.00(0.00)\n",
      "Iter 2142 | Time 86.7769(78.5107) | Bit/dim 3.4891(3.4964) | Xent 0.0000(0.0000) | Loss 8.8369(9.5932) | Error 0.0000(0.0000) Steps 712(711.53) | Grad Norm 0.4432(0.5816) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 25.5131, Epoch Time 519.1015(477.9122), Bit/dim 3.4977(best: 3.4909), Xent 0.0000, Loss 3.4977, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2143 | Time 77.6267(78.4842) | Bit/dim 3.4918(3.4963) | Xent 0.0000(0.0000) | Loss 13.5085(9.7107) | Error 0.0000(0.0000) Steps 706(711.37) | Grad Norm 0.4992(0.5791) | Total Time 0.00(0.00)\n",
      "Iter 2144 | Time 76.1266(78.4135) | Bit/dim 3.4993(3.4964) | Xent 0.0000(0.0000) | Loss 8.7530(9.6819) | Error 0.0000(0.0000) Steps 706(711.20) | Grad Norm 0.6246(0.5805) | Total Time 0.00(0.00)\n",
      "Iter 2145 | Time 79.1093(78.4343) | Bit/dim 3.5019(3.4966) | Xent 0.0000(0.0000) | Loss 8.6576(9.6512) | Error 0.0000(0.0000) Steps 694(710.69) | Grad Norm 0.4120(0.5754) | Total Time 0.00(0.00)\n",
      "Iter 2146 | Time 75.1056(78.3345) | Bit/dim 3.4944(3.4965) | Xent 0.0000(0.0000) | Loss 9.0855(9.6342) | Error 0.0000(0.0000) Steps 700(710.37) | Grad Norm 0.2762(0.5665) | Total Time 0.00(0.00)\n",
      "Iter 2147 | Time 78.5337(78.3405) | Bit/dim 3.4879(3.4962) | Xent 0.0000(0.0000) | Loss 8.9822(9.6147) | Error 0.0000(0.0000) Steps 736(711.14) | Grad Norm 0.6228(0.5682) | Total Time 0.00(0.00)\n",
      "Iter 2148 | Time 79.3001(78.3692) | Bit/dim 3.4973(3.4963) | Xent 0.0000(0.0000) | Loss 8.5620(9.5831) | Error 0.0000(0.0000) Steps 682(710.26) | Grad Norm 0.8147(0.5755) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 25.1477, Epoch Time 507.1093(478.7881), Bit/dim 3.5003(best: 3.4909), Xent 0.0000, Loss 3.5003, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2149 | Time 80.5727(78.4354) | Bit/dim 3.4858(3.4960) | Xent 0.0000(0.0000) | Loss 13.1895(9.6913) | Error 0.0000(0.0000) Steps 706(710.13) | Grad Norm 0.9189(0.5858) | Total Time 0.00(0.00)\n",
      "Iter 2150 | Time 78.7579(78.4450) | Bit/dim 3.4931(3.4959) | Xent 0.0000(0.0000) | Loss 8.9689(9.6696) | Error 0.0000(0.0000) Steps 706(710.01) | Grad Norm 0.5279(0.5841) | Total Time 0.00(0.00)\n",
      "Iter 2151 | Time 77.3613(78.4125) | Bit/dim 3.4950(3.4958) | Xent 0.0000(0.0000) | Loss 8.9859(9.6491) | Error 0.0000(0.0000) Steps 706(709.89) | Grad Norm 0.3338(0.5766) | Total Time 0.00(0.00)\n",
      "Iter 2152 | Time 77.6222(78.3888) | Bit/dim 3.4823(3.4954) | Xent 0.0000(0.0000) | Loss 8.8635(9.6255) | Error 0.0000(0.0000) Steps 706(709.77) | Grad Norm 0.5063(0.5745) | Total Time 0.00(0.00)\n",
      "Iter 2153 | Time 80.5954(78.4550) | Bit/dim 3.4965(3.4955) | Xent 0.0000(0.0000) | Loss 8.7991(9.6007) | Error 0.0000(0.0000) Steps 688(709.12) | Grad Norm 0.7560(0.5799) | Total Time 0.00(0.00)\n",
      "Iter 2154 | Time 76.5204(78.3970) | Bit/dim 3.5073(3.4958) | Xent 0.0000(0.0000) | Loss 8.7666(9.5757) | Error 0.0000(0.0000) Steps 700(708.85) | Grad Norm 0.7099(0.5838) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 25.3041, Epoch Time 512.5955(479.8023), Bit/dim 3.4961(best: 3.4909), Xent 0.0000, Loss 3.4961, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2155 | Time 80.3211(78.4547) | Bit/dim 3.4885(3.4956) | Xent 0.0000(0.0000) | Loss 13.7594(9.7012) | Error 0.0000(0.0000) Steps 724(709.30) | Grad Norm 0.4761(0.5806) | Total Time 0.00(0.00)\n",
      "Iter 2156 | Time 77.0352(78.4121) | Bit/dim 3.4945(3.4956) | Xent 0.0000(0.0000) | Loss 9.0367(9.6813) | Error 0.0000(0.0000) Steps 724(709.74) | Grad Norm 0.4371(0.5763) | Total Time 0.00(0.00)\n",
      "Iter 2157 | Time 74.8448(78.3051) | Bit/dim 3.5051(3.4959) | Xent 0.0000(0.0000) | Loss 8.7049(9.6520) | Error 0.0000(0.0000) Steps 688(709.09) | Grad Norm 0.5592(0.5758) | Total Time 0.00(0.00)\n",
      "Iter 2158 | Time 78.7274(78.3178) | Bit/dim 3.4891(3.4957) | Xent 0.0000(0.0000) | Loss 8.9733(9.6316) | Error 0.0000(0.0000) Steps 718(709.36) | Grad Norm 0.6712(0.5786) | Total Time 0.00(0.00)\n",
      "Iter 2159 | Time 79.7432(78.3605) | Bit/dim 3.5022(3.4958) | Xent 0.0000(0.0000) | Loss 8.8041(9.6068) | Error 0.0000(0.0000) Steps 724(709.80) | Grad Norm 0.8247(0.5860) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 79.1732(78.3849) | Bit/dim 3.4954(3.4958) | Xent 0.0000(0.0000) | Loss 8.7933(9.5824) | Error 0.0000(0.0000) Steps 694(709.32) | Grad Norm 0.6122(0.5868) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 25.1052, Epoch Time 511.4361(480.7513), Bit/dim 3.4968(best: 3.4909), Xent 0.0000, Loss 3.4968, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2161 | Time 78.2897(78.3820) | Bit/dim 3.4978(3.4959) | Xent 0.0000(0.0000) | Loss 12.6745(9.6752) | Error 0.0000(0.0000) Steps 700(709.04) | Grad Norm 0.7934(0.5930) | Total Time 0.00(0.00)\n",
      "Iter 2162 | Time 79.0236(78.4013) | Bit/dim 3.4994(3.4960) | Xent 0.0000(0.0000) | Loss 8.9466(9.6533) | Error 0.0000(0.0000) Steps 706(708.95) | Grad Norm 0.3695(0.5863) | Total Time 0.00(0.00)\n",
      "Iter 2163 | Time 81.7520(78.5018) | Bit/dim 3.4919(3.4959) | Xent 0.0000(0.0000) | Loss 8.9900(9.6334) | Error 0.0000(0.0000) Steps 706(708.86) | Grad Norm 0.4228(0.5814) | Total Time 0.00(0.00)\n",
      "Iter 2164 | Time 83.6194(78.6553) | Bit/dim 3.4915(3.4958) | Xent 0.0000(0.0000) | Loss 9.0285(9.6153) | Error 0.0000(0.0000) Steps 724(709.32) | Grad Norm 0.5319(0.5799) | Total Time 0.00(0.00)\n",
      "Iter 2165 | Time 79.2445(78.6730) | Bit/dim 3.4873(3.4955) | Xent 0.0000(0.0000) | Loss 8.9201(9.5944) | Error 0.0000(0.0000) Steps 718(709.58) | Grad Norm 0.4709(0.5766) | Total Time 0.00(0.00)\n",
      "Iter 2166 | Time 80.8025(78.7369) | Bit/dim 3.4850(3.4952) | Xent 0.0000(0.0000) | Loss 8.8786(9.5729) | Error 0.0000(0.0000) Steps 718(709.83) | Grad Norm 0.4227(0.5720) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 25.5025, Epoch Time 524.0367(482.0499), Bit/dim 3.4985(best: 3.4909), Xent 0.0000, Loss 3.4985, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2167 | Time 80.2360(78.7819) | Bit/dim 3.5059(3.4955) | Xent 0.0000(0.0000) | Loss 13.6914(9.6965) | Error 0.0000(0.0000) Steps 700(709.54) | Grad Norm 0.6168(0.5734) | Total Time 0.00(0.00)\n",
      "Iter 2168 | Time 81.1674(78.8534) | Bit/dim 3.4964(3.4955) | Xent 0.0000(0.0000) | Loss 8.9764(9.6749) | Error 0.0000(0.0000) Steps 718(709.79) | Grad Norm 0.7446(0.5785) | Total Time 0.00(0.00)\n",
      "Iter 2169 | Time 81.3711(78.9290) | Bit/dim 3.4884(3.4953) | Xent 0.0000(0.0000) | Loss 8.8915(9.6514) | Error 0.0000(0.0000) Steps 724(710.22) | Grad Norm 0.7268(0.5830) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 75.7625(78.8340) | Bit/dim 3.4933(3.4953) | Xent 0.0000(0.0000) | Loss 8.5781(9.6192) | Error 0.0000(0.0000) Steps 700(709.91) | Grad Norm 0.5605(0.5823) | Total Time 0.00(0.00)\n",
      "Iter 2171 | Time 78.5149(78.8244) | Bit/dim 3.5128(3.4958) | Xent 0.0000(0.0000) | Loss 8.9180(9.5981) | Error 0.0000(0.0000) Steps 724(710.33) | Grad Norm 0.4361(0.5779) | Total Time 0.00(0.00)\n",
      "Iter 2172 | Time 79.4495(78.8432) | Bit/dim 3.4928(3.4957) | Xent 0.0000(0.0000) | Loss 8.7461(9.5726) | Error 0.0000(0.0000) Steps 700(710.02) | Grad Norm 0.5082(0.5758) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 25.3216, Epoch Time 517.7371(483.1205), Bit/dim 3.4976(best: 3.4909), Xent 0.0000, Loss 3.4976, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2173 | Time 80.0041(78.8780) | Bit/dim 3.4898(3.4955) | Xent 0.0000(0.0000) | Loss 13.4602(9.6892) | Error 0.0000(0.0000) Steps 694(709.54) | Grad Norm 0.5921(0.5763) | Total Time 0.00(0.00)\n",
      "Iter 2174 | Time 77.3709(78.8328) | Bit/dim 3.5061(3.4958) | Xent 0.0000(0.0000) | Loss 8.8339(9.6636) | Error 0.0000(0.0000) Steps 700(709.26) | Grad Norm 0.3788(0.5704) | Total Time 0.00(0.00)\n",
      "Iter 2175 | Time 82.2828(78.9363) | Bit/dim 3.4938(3.4958) | Xent 0.0000(0.0000) | Loss 8.8864(9.6402) | Error 0.0000(0.0000) Steps 700(708.98) | Grad Norm 0.4704(0.5674) | Total Time 0.00(0.00)\n",
      "Iter 2176 | Time 76.9086(78.8754) | Bit/dim 3.4998(3.4959) | Xent 0.0000(0.0000) | Loss 8.5529(9.6076) | Error 0.0000(0.0000) Steps 706(708.89) | Grad Norm 0.9249(0.5781) | Total Time 0.00(0.00)\n",
      "Iter 2177 | Time 80.8207(78.9338) | Bit/dim 3.4920(3.4958) | Xent 0.0000(0.0000) | Loss 9.0310(9.5903) | Error 0.0000(0.0000) Steps 724(709.34) | Grad Norm 0.8369(0.5859) | Total Time 0.00(0.00)\n",
      "Iter 2178 | Time 80.1456(78.9702) | Bit/dim 3.4891(3.4956) | Xent 0.0000(0.0000) | Loss 8.9306(9.5705) | Error 0.0000(0.0000) Steps 700(709.06) | Grad Norm 1.0656(0.6003) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 25.3255, Epoch Time 519.1048(484.2000), Bit/dim 3.4990(best: 3.4909), Xent 0.0000, Loss 3.4990, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2179 | Time 77.4702(78.9252) | Bit/dim 3.4874(3.4953) | Xent 0.0000(0.0000) | Loss 13.1810(9.6788) | Error 0.0000(0.0000) Steps 706(708.97) | Grad Norm 1.0948(0.6151) | Total Time 0.00(0.00)\n",
      "Iter 2180 | Time 81.9412(79.0156) | Bit/dim 3.5020(3.4955) | Xent 0.0000(0.0000) | Loss 8.9997(9.6585) | Error 0.0000(0.0000) Steps 736(709.78) | Grad Norm 0.6592(0.6164) | Total Time 0.00(0.00)\n",
      "Iter 2181 | Time 73.8374(78.8603) | Bit/dim 3.4947(3.4955) | Xent 0.0000(0.0000) | Loss 8.6862(9.6293) | Error 0.0000(0.0000) Steps 700(709.49) | Grad Norm 0.5937(0.6157) | Total Time 0.00(0.00)\n",
      "Iter 2182 | Time 76.8546(78.8001) | Bit/dim 3.4923(3.4954) | Xent 0.0000(0.0000) | Loss 8.9123(9.6078) | Error 0.0000(0.0000) Steps 694(709.02) | Grad Norm 0.9480(0.6257) | Total Time 0.00(0.00)\n",
      "Iter 2183 | Time 83.0928(78.9289) | Bit/dim 3.4972(3.4955) | Xent 0.0000(0.0000) | Loss 8.7890(9.5832) | Error 0.0000(0.0000) Steps 712(709.11) | Grad Norm 0.9198(0.6345) | Total Time 0.00(0.00)\n",
      "Iter 2184 | Time 77.3449(78.8814) | Bit/dim 3.4951(3.4955) | Xent 0.0000(0.0000) | Loss 8.9285(9.5636) | Error 0.0000(0.0000) Steps 706(709.02) | Grad Norm 0.7928(0.6393) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 24.9228, Epoch Time 511.3493(485.0145), Bit/dim 3.4949(best: 3.4909), Xent 0.0000, Loss 3.4949, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2185 | Time 75.2875(78.7736) | Bit/dim 3.4841(3.4951) | Xent 0.0000(0.0000) | Loss 13.6158(9.6852) | Error 0.0000(0.0000) Steps 712(709.11) | Grad Norm 0.9546(0.6487) | Total Time 0.00(0.00)\n",
      "Iter 2186 | Time 83.0644(78.9023) | Bit/dim 3.4930(3.4950) | Xent 0.0000(0.0000) | Loss 8.8819(9.6611) | Error 0.0000(0.0000) Steps 730(709.73) | Grad Norm 0.7817(0.6527) | Total Time 0.00(0.00)\n",
      "Iter 2187 | Time 82.9011(79.0223) | Bit/dim 3.4895(3.4949) | Xent 0.0000(0.0000) | Loss 8.8708(9.6373) | Error 0.0000(0.0000) Steps 706(709.62) | Grad Norm 0.9025(0.6602) | Total Time 0.00(0.00)\n",
      "Iter 2188 | Time 74.7568(78.8943) | Bit/dim 3.4958(3.4949) | Xent 0.0000(0.0000) | Loss 8.9731(9.6174) | Error 0.0000(0.0000) Steps 712(709.69) | Grad Norm 0.8395(0.6656) | Total Time 0.00(0.00)\n",
      "Iter 2189 | Time 81.0699(78.9596) | Bit/dim 3.4957(3.4949) | Xent 0.0000(0.0000) | Loss 9.0478(9.6003) | Error 0.0000(0.0000) Steps 742(710.66) | Grad Norm 0.5534(0.6622) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 77.3615(78.9116) | Bit/dim 3.5155(3.4955) | Xent 0.0000(0.0000) | Loss 8.9127(9.5797) | Error 0.0000(0.0000) Steps 706(710.52) | Grad Norm 0.6323(0.6613) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 25.0177, Epoch Time 515.1692(485.9191), Bit/dim 3.5040(best: 3.4909), Xent 0.0000, Loss 3.5040, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2191 | Time 78.4298(78.8972) | Bit/dim 3.4875(3.4953) | Xent 0.0000(0.0000) | Loss 13.8155(9.7068) | Error 0.0000(0.0000) Steps 718(710.75) | Grad Norm 1.0704(0.6736) | Total Time 0.00(0.00)\n",
      "Iter 2192 | Time 78.7440(78.8926) | Bit/dim 3.5012(3.4955) | Xent 0.0000(0.0000) | Loss 9.0454(9.6869) | Error 0.0000(0.0000) Steps 706(710.60) | Grad Norm 0.8547(0.6790) | Total Time 0.00(0.00)\n",
      "Iter 2193 | Time 82.2081(78.9920) | Bit/dim 3.4908(3.4953) | Xent 0.0000(0.0000) | Loss 8.9003(9.6633) | Error 0.0000(0.0000) Steps 706(710.47) | Grad Norm 0.4074(0.6709) | Total Time 0.00(0.00)\n",
      "Iter 2194 | Time 80.7688(79.0453) | Bit/dim 3.4961(3.4954) | Xent 0.0000(0.0000) | Loss 8.9781(9.6428) | Error 0.0000(0.0000) Steps 724(710.87) | Grad Norm 0.5438(0.6671) | Total Time 0.00(0.00)\n",
      "Iter 2195 | Time 81.1715(79.1091) | Bit/dim 3.4874(3.4951) | Xent 0.0000(0.0000) | Loss 9.0308(9.6244) | Error 0.0000(0.0000) Steps 724(711.27) | Grad Norm 0.9485(0.6755) | Total Time 0.00(0.00)\n",
      "Iter 2196 | Time 84.8509(79.2814) | Bit/dim 3.4840(3.4948) | Xent 0.0000(0.0000) | Loss 8.9686(9.6047) | Error 0.0000(0.0000) Steps 724(711.65) | Grad Norm 0.8872(0.6819) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 25.4526, Epoch Time 527.3545(487.1622), Bit/dim 3.4948(best: 3.4909), Xent 0.0000, Loss 3.4948, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2197 | Time 80.7637(79.3258) | Bit/dim 3.4971(3.4949) | Xent 0.0000(0.0000) | Loss 13.5987(9.7246) | Error 0.0000(0.0000) Steps 706(711.48) | Grad Norm 0.8003(0.6854) | Total Time 0.00(0.00)\n",
      "Iter 2198 | Time 78.4986(79.3010) | Bit/dim 3.4957(3.4949) | Xent 0.0000(0.0000) | Loss 8.7539(9.6954) | Error 0.0000(0.0000) Steps 718(711.67) | Grad Norm 0.8288(0.6897) | Total Time 0.00(0.00)\n",
      "Iter 2199 | Time 79.0287(79.2929) | Bit/dim 3.4936(3.4948) | Xent 0.0000(0.0000) | Loss 8.9476(9.6730) | Error 0.0000(0.0000) Steps 718(711.86) | Grad Norm 0.6858(0.6896) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 73.5321(79.1200) | Bit/dim 3.4886(3.4947) | Xent 0.0000(0.0000) | Loss 8.7718(9.6460) | Error 0.0000(0.0000) Steps 694(711.33) | Grad Norm 0.5128(0.6843) | Total Time 0.00(0.00)\n",
      "Iter 2201 | Time 77.0565(79.0581) | Bit/dim 3.4890(3.4945) | Xent 0.0000(0.0000) | Loss 8.7772(9.6199) | Error 0.0000(0.0000) Steps 724(711.71) | Grad Norm 0.3683(0.6748) | Total Time 0.00(0.00)\n",
      "Iter 2202 | Time 77.8043(79.0205) | Bit/dim 3.4955(3.4945) | Xent 0.0000(0.0000) | Loss 8.6324(9.5903) | Error 0.0000(0.0000) Steps 706(711.54) | Grad Norm 0.6869(0.6752) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 25.5595, Epoch Time 508.6534(487.8069), Bit/dim 3.4927(best: 3.4909), Xent 0.0000, Loss 3.4927, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2203 | Time 76.3886(78.9416) | Bit/dim 3.5024(3.4948) | Xent 0.0000(0.0000) | Loss 13.6993(9.7136) | Error 0.0000(0.0000) Steps 712(711.55) | Grad Norm 0.7773(0.6782) | Total Time 0.00(0.00)\n",
      "Iter 2204 | Time 82.5151(79.0488) | Bit/dim 3.4971(3.4948) | Xent 0.0000(0.0000) | Loss 8.9081(9.6894) | Error 0.0000(0.0000) Steps 712(711.56) | Grad Norm 0.6252(0.6767) | Total Time 0.00(0.00)\n",
      "Iter 2205 | Time 75.4310(78.9402) | Bit/dim 3.4855(3.4945) | Xent 0.0000(0.0000) | Loss 8.6260(9.6575) | Error 0.0000(0.0000) Steps 682(710.68) | Grad Norm 0.6634(0.6763) | Total Time 0.00(0.00)\n",
      "Iter 2206 | Time 78.0215(78.9127) | Bit/dim 3.4895(3.4944) | Xent 0.0000(0.0000) | Loss 8.8761(9.6340) | Error 0.0000(0.0000) Steps 706(710.54) | Grad Norm 0.5054(0.6711) | Total Time 0.00(0.00)\n",
      "Iter 2207 | Time 78.8733(78.9115) | Bit/dim 3.4889(3.4942) | Xent 0.0000(0.0000) | Loss 8.9162(9.6125) | Error 0.0000(0.0000) Steps 700(710.22) | Grad Norm 0.6774(0.6713) | Total Time 0.00(0.00)\n",
      "Iter 2208 | Time 81.4698(78.9882) | Bit/dim 3.4973(3.4943) | Xent 0.0000(0.0000) | Loss 8.7951(9.5880) | Error 0.0000(0.0000) Steps 724(710.63) | Grad Norm 0.8174(0.6757) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 25.1409, Epoch Time 514.3558(488.6034), Bit/dim 3.5012(best: 3.4909), Xent 0.0000, Loss 3.5012, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2209 | Time 80.6973(79.0395) | Bit/dim 3.4923(3.4943) | Xent 0.0000(0.0000) | Loss 13.6127(9.7087) | Error 0.0000(0.0000) Steps 730(711.22) | Grad Norm 0.8552(0.6811) | Total Time 0.00(0.00)\n",
      "Iter 2210 | Time 80.2102(79.0746) | Bit/dim 3.4877(3.4941) | Xent 0.0000(0.0000) | Loss 8.9546(9.6861) | Error 0.0000(0.0000) Steps 718(711.42) | Grad Norm 1.0884(0.6933) | Total Time 0.00(0.00)\n",
      "Iter 2211 | Time 80.7519(79.1249) | Bit/dim 3.4891(3.4939) | Xent 0.0000(0.0000) | Loss 8.6562(9.6552) | Error 0.0000(0.0000) Steps 694(710.90) | Grad Norm 1.2597(0.7103) | Total Time 0.00(0.00)\n",
      "Iter 2212 | Time 80.8138(79.1756) | Bit/dim 3.4928(3.4939) | Xent 0.0000(0.0000) | Loss 8.9482(9.6340) | Error 0.0000(0.0000) Steps 724(711.29) | Grad Norm 1.0002(0.7190) | Total Time 0.00(0.00)\n",
      "Iter 2213 | Time 78.0490(79.1418) | Bit/dim 3.4893(3.4937) | Xent 0.0000(0.0000) | Loss 8.7913(9.6087) | Error 0.0000(0.0000) Steps 706(711.13) | Grad Norm 0.7728(0.7206) | Total Time 0.00(0.00)\n",
      "Iter 2214 | Time 81.4616(79.2114) | Bit/dim 3.4954(3.4938) | Xent 0.0000(0.0000) | Loss 8.8587(9.5862) | Error 0.0000(0.0000) Steps 718(711.34) | Grad Norm 1.3469(0.7394) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 25.3729, Epoch Time 523.6038(489.6534), Bit/dim 3.4960(best: 3.4909), Xent 0.0000, Loss 3.4960, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2215 | Time 76.7220(79.1367) | Bit/dim 3.4996(3.4940) | Xent 0.0000(0.0000) | Loss 13.5559(9.7053) | Error 0.0000(0.0000) Steps 706(711.18) | Grad Norm 1.7490(0.7697) | Total Time 0.00(0.00)\n",
      "Iter 2216 | Time 82.1124(79.2260) | Bit/dim 3.5012(3.4942) | Xent 0.0000(0.0000) | Loss 8.5615(9.6710) | Error 0.0000(0.0000) Steps 706(711.02) | Grad Norm 1.5180(0.7921) | Total Time 0.00(0.00)\n",
      "Iter 2217 | Time 83.2631(79.3471) | Bit/dim 3.4884(3.4940) | Xent 0.0000(0.0000) | Loss 8.8090(9.6451) | Error 0.0000(0.0000) Steps 718(711.23) | Grad Norm 0.9433(0.7967) | Total Time 0.00(0.00)\n",
      "Iter 2218 | Time 80.7016(79.3877) | Bit/dim 3.4882(3.4938) | Xent 0.0000(0.0000) | Loss 8.8409(9.6210) | Error 0.0000(0.0000) Steps 712(711.25) | Grad Norm 0.5555(0.7894) | Total Time 0.00(0.00)\n",
      "Iter 2219 | Time 76.5541(79.3027) | Bit/dim 3.4985(3.4940) | Xent 0.0000(0.0000) | Loss 8.8982(9.5993) | Error 0.0000(0.0000) Steps 706(711.10) | Grad Norm 0.7699(0.7888) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 79.8583(79.3194) | Bit/dim 3.4906(3.4939) | Xent 0.0000(0.0000) | Loss 8.9207(9.5790) | Error 0.0000(0.0000) Steps 712(711.12) | Grad Norm 0.8211(0.7898) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 26.0064, Epoch Time 520.8922(490.5906), Bit/dim 3.4957(best: 3.4909), Xent 0.0000, Loss 3.4957, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2221 | Time 74.6431(79.1791) | Bit/dim 3.5047(3.4942) | Xent 0.0000(0.0000) | Loss 13.6301(9.7005) | Error 0.0000(0.0000) Steps 694(710.61) | Grad Norm 0.5984(0.7841) | Total Time 0.00(0.00)\n",
      "Iter 2222 | Time 81.0912(79.2365) | Bit/dim 3.4866(3.4940) | Xent 0.0000(0.0000) | Loss 8.8944(9.6763) | Error 0.0000(0.0000) Steps 730(711.19) | Grad Norm 0.7592(0.7833) | Total Time 0.00(0.00)\n",
      "Iter 2223 | Time 77.0557(79.1710) | Bit/dim 3.4737(3.4934) | Xent 0.0000(0.0000) | Loss 8.8186(9.6506) | Error 0.0000(0.0000) Steps 700(710.86) | Grad Norm 0.9535(0.7884) | Total Time 0.00(0.00)\n",
      "Iter 2224 | Time 76.3059(79.0851) | Bit/dim 3.4993(3.4935) | Xent 0.0000(0.0000) | Loss 8.8958(9.6279) | Error 0.0000(0.0000) Steps 694(710.35) | Grad Norm 0.9741(0.7940) | Total Time 0.00(0.00)\n",
      "Iter 2225 | Time 74.5237(78.9483) | Bit/dim 3.4840(3.4933) | Xent 0.0000(0.0000) | Loss 8.9455(9.6075) | Error 0.0000(0.0000) Steps 706(710.22) | Grad Norm 0.8932(0.7970) | Total Time 0.00(0.00)\n",
      "Iter 2226 | Time 78.0887(78.9225) | Bit/dim 3.5129(3.4939) | Xent 0.0000(0.0000) | Loss 9.0697(9.5913) | Error 0.0000(0.0000) Steps 712(710.27) | Grad Norm 0.7864(0.7967) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 25.6753, Epoch Time 503.7501(490.9854), Bit/dim 3.4972(best: 3.4909), Xent 0.0000, Loss 3.4972, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2227 | Time 75.2531(78.8124) | Bit/dim 3.4959(3.4939) | Xent 0.0000(0.0000) | Loss 13.6991(9.7146) | Error 0.0000(0.0000) Steps 688(709.60) | Grad Norm 0.8160(0.7972) | Total Time 0.00(0.00)\n",
      "Iter 2228 | Time 79.0619(78.8199) | Bit/dim 3.4905(3.4938) | Xent 0.0000(0.0000) | Loss 8.7067(9.6843) | Error 0.0000(0.0000) Steps 706(709.50) | Grad Norm 0.5524(0.7899) | Total Time 0.00(0.00)\n",
      "Iter 2229 | Time 79.1704(78.8304) | Bit/dim 3.5036(3.4941) | Xent 0.0000(0.0000) | Loss 8.8563(9.6595) | Error 0.0000(0.0000) Steps 712(709.57) | Grad Norm 0.4405(0.7794) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 75.8372(78.7406) | Bit/dim 3.4927(3.4941) | Xent 0.0000(0.0000) | Loss 8.6226(9.6284) | Error 0.0000(0.0000) Steps 712(709.64) | Grad Norm 0.9130(0.7834) | Total Time 0.00(0.00)\n",
      "Iter 2231 | Time 77.4037(78.7005) | Bit/dim 3.4962(3.4941) | Xent 0.0000(0.0000) | Loss 8.8761(9.6058) | Error 0.0000(0.0000) Steps 700(709.36) | Grad Norm 1.1075(0.7931) | Total Time 0.00(0.00)\n",
      "Iter 2232 | Time 80.0173(78.7400) | Bit/dim 3.4821(3.4938) | Xent 0.0000(0.0000) | Loss 8.7744(9.5809) | Error 0.0000(0.0000) Steps 724(709.79) | Grad Norm 1.0115(0.7997) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 25.2209, Epoch Time 507.7611(491.4886), Bit/dim 3.4947(best: 3.4909), Xent 0.0000, Loss 3.4947, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2233 | Time 79.3924(78.7596) | Bit/dim 3.4772(3.4933) | Xent 0.0000(0.0000) | Loss 13.4821(9.6979) | Error 0.0000(0.0000) Steps 712(709.86) | Grad Norm 1.0157(0.8062) | Total Time 0.00(0.00)\n",
      "Iter 2234 | Time 81.6649(78.8467) | Bit/dim 3.4970(3.4934) | Xent 0.0000(0.0000) | Loss 8.8902(9.6737) | Error 0.0000(0.0000) Steps 706(709.75) | Grad Norm 0.9741(0.8112) | Total Time 0.00(0.00)\n",
      "Iter 2235 | Time 80.4494(78.8948) | Bit/dim 3.5007(3.4936) | Xent 0.0000(0.0000) | Loss 9.0384(9.6546) | Error 0.0000(0.0000) Steps 700(709.45) | Grad Norm 0.7561(0.8096) | Total Time 0.00(0.00)\n",
      "Iter 2236 | Time 81.2624(78.9658) | Bit/dim 3.4953(3.4936) | Xent 0.0000(0.0000) | Loss 8.7494(9.6275) | Error 0.0000(0.0000) Steps 718(709.71) | Grad Norm 0.4611(0.7991) | Total Time 0.00(0.00)\n",
      "Iter 2237 | Time 74.7524(78.8394) | Bit/dim 3.4983(3.4938) | Xent 0.0000(0.0000) | Loss 8.9005(9.6057) | Error 0.0000(0.0000) Steps 700(709.42) | Grad Norm 0.4996(0.7901) | Total Time 0.00(0.00)\n",
      "Iter 2238 | Time 78.4744(78.8285) | Bit/dim 3.4899(3.4937) | Xent 0.0000(0.0000) | Loss 8.7091(9.5788) | Error 0.0000(0.0000) Steps 682(708.60) | Grad Norm 0.7723(0.7896) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 25.1806, Epoch Time 517.0624(492.2558), Bit/dim 3.4981(best: 3.4909), Xent 0.0000, Loss 3.4981, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2239 | Time 84.1297(78.9875) | Bit/dim 3.5059(3.4940) | Xent 0.0000(0.0000) | Loss 13.6574(9.7011) | Error 0.0000(0.0000) Steps 730(709.24) | Grad Norm 1.1187(0.7995) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 81.7300(79.0698) | Bit/dim 3.4979(3.4942) | Xent 0.0000(0.0000) | Loss 8.4729(9.6643) | Error 0.0000(0.0000) Steps 724(709.68) | Grad Norm 1.0572(0.8072) | Total Time 0.00(0.00)\n",
      "Iter 2241 | Time 77.2704(79.0158) | Bit/dim 3.4823(3.4938) | Xent 0.0000(0.0000) | Loss 8.8755(9.6406) | Error 0.0000(0.0000) Steps 706(709.57) | Grad Norm 0.7500(0.8055) | Total Time 0.00(0.00)\n",
      "Iter 2242 | Time 82.9641(79.1343) | Bit/dim 3.4938(3.4938) | Xent 0.0000(0.0000) | Loss 8.9942(9.6212) | Error 0.0000(0.0000) Steps 736(710.36) | Grad Norm 0.5654(0.7983) | Total Time 0.00(0.00)\n",
      "Iter 2243 | Time 81.6669(79.2102) | Bit/dim 3.4919(3.4937) | Xent 0.0000(0.0000) | Loss 8.8162(9.5971) | Error 0.0000(0.0000) Steps 718(710.59) | Grad Norm 0.4465(0.7877) | Total Time 0.00(0.00)\n",
      "Iter 2244 | Time 80.4242(79.2467) | Bit/dim 3.4877(3.4936) | Xent 0.0000(0.0000) | Loss 8.8797(9.5756) | Error 0.0000(0.0000) Steps 730(711.17) | Grad Norm 0.7124(0.7855) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 24.8938, Epoch Time 529.2424(493.3654), Bit/dim 3.4964(best: 3.4909), Xent 0.0000, Loss 3.4964, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2245 | Time 82.7263(79.3510) | Bit/dim 3.4990(3.4937) | Xent 0.0000(0.0000) | Loss 13.1031(9.6814) | Error 0.0000(0.0000) Steps 718(711.38) | Grad Norm 1.1129(0.7953) | Total Time 0.00(0.00)\n",
      "Iter 2246 | Time 79.6588(79.3603) | Bit/dim 3.4950(3.4938) | Xent 0.0000(0.0000) | Loss 8.8126(9.6553) | Error 0.0000(0.0000) Steps 700(711.04) | Grad Norm 1.1652(0.8064) | Total Time 0.00(0.00)\n",
      "Iter 2247 | Time 80.7532(79.4021) | Bit/dim 3.4907(3.4937) | Xent 0.0000(0.0000) | Loss 8.8784(9.6320) | Error 0.0000(0.0000) Steps 730(711.61) | Grad Norm 1.2639(0.8201) | Total Time 0.00(0.00)\n",
      "Iter 2248 | Time 75.4535(79.2836) | Bit/dim 3.4971(3.4938) | Xent 0.0000(0.0000) | Loss 8.9476(9.6115) | Error 0.0000(0.0000) Steps 730(712.16) | Grad Norm 1.4164(0.8380) | Total Time 0.00(0.00)\n",
      "Iter 2249 | Time 80.3608(79.3159) | Bit/dim 3.4814(3.4934) | Xent 0.0000(0.0000) | Loss 8.8439(9.5884) | Error 0.0000(0.0000) Steps 706(711.97) | Grad Norm 1.5655(0.8598) | Total Time 0.00(0.00)\n",
      "Iter 2250 | Time 79.9538(79.3351) | Bit/dim 3.5005(3.4936) | Xent 0.0000(0.0000) | Loss 8.7769(9.5641) | Error 0.0000(0.0000) Steps 712(711.97) | Grad Norm 1.4958(0.8789) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 24.9014, Epoch Time 519.8630(494.1604), Bit/dim 3.4943(best: 3.4909), Xent 0.0000, Loss 3.4943, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2251 | Time 77.2399(79.2722) | Bit/dim 3.4991(3.4938) | Xent 0.0000(0.0000) | Loss 13.6445(9.6865) | Error 0.0000(0.0000) Steps 724(712.34) | Grad Norm 1.2734(0.8907) | Total Time 0.00(0.00)\n",
      "Iter 2252 | Time 79.3688(79.2751) | Bit/dim 3.4902(3.4937) | Xent 0.0000(0.0000) | Loss 8.9482(9.6644) | Error 0.0000(0.0000) Steps 706(712.15) | Grad Norm 1.0009(0.8940) | Total Time 0.00(0.00)\n",
      "Iter 2253 | Time 81.4910(79.3416) | Bit/dim 3.4947(3.4937) | Xent 0.0000(0.0000) | Loss 8.8544(9.6401) | Error 0.0000(0.0000) Steps 724(712.50) | Grad Norm 0.8958(0.8941) | Total Time 0.00(0.00)\n",
      "Iter 2254 | Time 78.3996(79.3133) | Bit/dim 3.4748(3.4931) | Xent 0.0000(0.0000) | Loss 8.8433(9.6162) | Error 0.0000(0.0000) Steps 730(713.03) | Grad Norm 0.6840(0.8878) | Total Time 0.00(0.00)\n",
      "Iter 2255 | Time 78.7449(79.2963) | Bit/dim 3.4882(3.4930) | Xent 0.0000(0.0000) | Loss 8.5910(9.5854) | Error 0.0000(0.0000) Steps 718(713.17) | Grad Norm 0.4987(0.8761) | Total Time 0.00(0.00)\n",
      "Iter 2256 | Time 83.2453(79.4147) | Bit/dim 3.4947(3.4930) | Xent 0.0000(0.0000) | Loss 8.8183(9.5624) | Error 0.0000(0.0000) Steps 706(712.96) | Grad Norm 0.4621(0.8637) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 25.3145, Epoch Time 519.6646(494.9255), Bit/dim 3.5004(best: 3.4909), Xent 0.0000, Loss 3.5004, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2257 | Time 71.5222(79.1780) | Bit/dim 3.5003(3.4933) | Xent 0.0000(0.0000) | Loss 13.3842(9.6770) | Error 0.0000(0.0000) Steps 700(712.57) | Grad Norm 0.6075(0.8560) | Total Time 0.00(0.00)\n",
      "Iter 2258 | Time 74.6188(79.0412) | Bit/dim 3.4958(3.4933) | Xent 0.0000(0.0000) | Loss 8.9828(9.6562) | Error 0.0000(0.0000) Steps 706(712.37) | Grad Norm 0.5014(0.8454) | Total Time 0.00(0.00)\n",
      "Iter 2259 | Time 78.6161(79.0284) | Bit/dim 3.4849(3.4931) | Xent 0.0000(0.0000) | Loss 8.8729(9.6327) | Error 0.0000(0.0000) Steps 718(712.54) | Grad Norm 0.6739(0.8402) | Total Time 0.00(0.00)\n",
      "Iter 2260 | Time 77.1792(78.9730) | Bit/dim 3.4926(3.4931) | Xent 0.0000(0.0000) | Loss 8.9788(9.6131) | Error 0.0000(0.0000) Steps 712(712.53) | Grad Norm 0.7106(0.8363) | Total Time 0.00(0.00)\n",
      "Iter 2261 | Time 78.6734(78.9640) | Bit/dim 3.4821(3.4927) | Xent 0.0000(0.0000) | Loss 8.9342(9.5927) | Error 0.0000(0.0000) Steps 718(712.69) | Grad Norm 0.6630(0.8311) | Total Time 0.00(0.00)\n",
      "Iter 2262 | Time 80.4731(79.0092) | Bit/dim 3.4953(3.4928) | Xent 0.0000(0.0000) | Loss 8.9238(9.5727) | Error 0.0000(0.0000) Steps 712(712.67) | Grad Norm 0.6932(0.8270) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 26.1398, Epoch Time 503.1096(495.1710), Bit/dim 3.4944(best: 3.4909), Xent 0.0000, Loss 3.4944, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2263 | Time 76.9231(78.9467) | Bit/dim 3.4833(3.4925) | Xent 0.0000(0.0000) | Loss 13.6703(9.6956) | Error 0.0000(0.0000) Steps 706(712.47) | Grad Norm 0.8334(0.8272) | Total Time 0.00(0.00)\n",
      "Iter 2264 | Time 80.6353(78.9973) | Bit/dim 3.4902(3.4925) | Xent 0.0000(0.0000) | Loss 8.6889(9.6654) | Error 0.0000(0.0000) Steps 700(712.10) | Grad Norm 0.9483(0.8308) | Total Time 0.00(0.00)\n",
      "Iter 2265 | Time 79.5986(79.0154) | Bit/dim 3.4904(3.4924) | Xent 0.0000(0.0000) | Loss 8.7806(9.6389) | Error 0.0000(0.0000) Steps 694(711.55) | Grad Norm 0.8989(0.8329) | Total Time 0.00(0.00)\n",
      "Iter 2266 | Time 83.4987(79.1499) | Bit/dim 3.4998(3.4926) | Xent 0.0000(0.0000) | Loss 9.0049(9.6198) | Error 0.0000(0.0000) Steps 718(711.75) | Grad Norm 0.6505(0.8274) | Total Time 0.00(0.00)\n",
      "Iter 2267 | Time 83.6332(79.2844) | Bit/dim 3.5069(3.4930) | Xent 0.0000(0.0000) | Loss 8.8764(9.5975) | Error 0.0000(0.0000) Steps 724(712.11) | Grad Norm 0.5379(0.8187) | Total Time 0.00(0.00)\n",
      "Iter 2268 | Time 74.4607(79.1397) | Bit/dim 3.4886(3.4929) | Xent 0.0000(0.0000) | Loss 8.7924(9.5734) | Error 0.0000(0.0000) Steps 718(712.29) | Grad Norm 0.8695(0.8202) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 25.2865, Epoch Time 520.3351(495.9259), Bit/dim 3.4943(best: 3.4909), Xent 0.0000, Loss 3.4943, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2269 | Time 79.3325(79.1454) | Bit/dim 3.4977(3.4931) | Xent 0.0000(0.0000) | Loss 13.4000(9.6882) | Error 0.0000(0.0000) Steps 712(712.28) | Grad Norm 1.3845(0.8372) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 76.4702(79.0652) | Bit/dim 3.4873(3.4929) | Xent 0.0000(0.0000) | Loss 8.9373(9.6657) | Error 0.0000(0.0000) Steps 712(712.27) | Grad Norm 1.5330(0.8580) | Total Time 0.00(0.00)\n",
      "Iter 2271 | Time 81.8155(79.1477) | Bit/dim 3.4901(3.4928) | Xent 0.0000(0.0000) | Loss 8.8238(9.6404) | Error 0.0000(0.0000) Steps 700(711.90) | Grad Norm 1.3345(0.8723) | Total Time 0.00(0.00)\n",
      "Iter 2272 | Time 80.7045(79.1944) | Bit/dim 3.4892(3.4927) | Xent 0.0000(0.0000) | Loss 8.6980(9.6121) | Error 0.0000(0.0000) Steps 712(711.91) | Grad Norm 1.1791(0.8815) | Total Time 0.00(0.00)\n",
      "Iter 2273 | Time 79.9190(79.2161) | Bit/dim 3.4982(3.4929) | Xent 0.0000(0.0000) | Loss 8.8478(9.5892) | Error 0.0000(0.0000) Steps 712(711.91) | Grad Norm 1.5458(0.9015) | Total Time 0.00(0.00)\n",
      "Iter 2274 | Time 74.6272(79.0785) | Bit/dim 3.4910(3.4928) | Xent 0.0000(0.0000) | Loss 8.8360(9.5666) | Error 0.0000(0.0000) Steps 718(712.09) | Grad Norm 1.9507(0.9329) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 25.7763, Epoch Time 514.7838(496.4917), Bit/dim 3.4950(best: 3.4909), Xent 0.0000, Loss 3.4950, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2275 | Time 78.7556(79.0688) | Bit/dim 3.4910(3.4927) | Xent 0.0000(0.0000) | Loss 13.8325(9.6946) | Error 0.0000(0.0000) Steps 730(712.63) | Grad Norm 2.0694(0.9670) | Total Time 0.00(0.00)\n",
      "Iter 2276 | Time 75.8468(78.9721) | Bit/dim 3.4961(3.4929) | Xent 0.0000(0.0000) | Loss 8.6575(9.6635) | Error 0.0000(0.0000) Steps 688(711.89) | Grad Norm 2.1545(1.0027) | Total Time 0.00(0.00)\n",
      "Iter 2277 | Time 78.8811(78.9694) | Bit/dim 3.4826(3.4925) | Xent 0.0000(0.0000) | Loss 8.8756(9.6398) | Error 0.0000(0.0000) Steps 718(712.07) | Grad Norm 2.1931(1.0384) | Total Time 0.00(0.00)\n",
      "Iter 2278 | Time 77.8589(78.9361) | Bit/dim 3.4929(3.4926) | Xent 0.0000(0.0000) | Loss 8.7670(9.6136) | Error 0.0000(0.0000) Steps 724(712.43) | Grad Norm 2.4039(1.0793) | Total Time 0.00(0.00)\n",
      "Iter 2279 | Time 81.5866(79.0156) | Bit/dim 3.4969(3.4927) | Xent 0.0000(0.0000) | Loss 8.7610(9.5881) | Error 0.0000(0.0000) Steps 718(712.60) | Grad Norm 2.3140(1.1164) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 80.1171(79.0486) | Bit/dim 3.4968(3.4928) | Xent 0.0000(0.0000) | Loss 8.9426(9.5687) | Error 0.0000(0.0000) Steps 724(712.94) | Grad Norm 1.8591(1.1387) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 25.8159, Epoch Time 514.9129(497.0443), Bit/dim 3.4906(best: 3.4909), Xent 0.0000, Loss 3.4906, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2281 | Time 80.4844(79.0917) | Bit/dim 3.4750(3.4923) | Xent 0.0000(0.0000) | Loss 13.6989(9.6926) | Error 0.0000(0.0000) Steps 730(713.45) | Grad Norm 1.4503(1.1480) | Total Time 0.00(0.00)\n",
      "Iter 2282 | Time 81.8639(79.1749) | Bit/dim 3.5108(3.4928) | Xent 0.0000(0.0000) | Loss 9.0633(9.6737) | Error 0.0000(0.0000) Steps 724(713.77) | Grad Norm 1.3604(1.1544) | Total Time 0.00(0.00)\n",
      "Iter 2283 | Time 80.0363(79.2007) | Bit/dim 3.4958(3.4929) | Xent 0.0000(0.0000) | Loss 8.9700(9.6526) | Error 0.0000(0.0000) Steps 706(713.54) | Grad Norm 1.3359(1.1598) | Total Time 0.00(0.00)\n",
      "Iter 2284 | Time 78.4127(79.1771) | Bit/dim 3.4886(3.4928) | Xent 0.0000(0.0000) | Loss 8.5707(9.6202) | Error 0.0000(0.0000) Steps 688(712.77) | Grad Norm 1.2646(1.1630) | Total Time 0.00(0.00)\n",
      "Iter 2285 | Time 78.6090(79.1600) | Bit/dim 3.4985(3.4930) | Xent 0.0000(0.0000) | Loss 8.9524(9.6001) | Error 0.0000(0.0000) Steps 724(713.11) | Grad Norm 1.2825(1.1666) | Total Time 0.00(0.00)\n",
      "Iter 2286 | Time 76.0333(79.0662) | Bit/dim 3.4867(3.4928) | Xent 0.0000(0.0000) | Loss 8.8056(9.5763) | Error 0.0000(0.0000) Steps 700(712.71) | Grad Norm 1.5457(1.1779) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 25.7491, Epoch Time 517.3297(497.6529), Bit/dim 3.4963(best: 3.4906), Xent 0.0000, Loss 3.4963, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2287 | Time 77.6542(79.0239) | Bit/dim 3.4909(3.4927) | Xent 0.0000(0.0000) | Loss 13.7145(9.7004) | Error 0.0000(0.0000) Steps 718(712.87) | Grad Norm 1.5024(1.1877) | Total Time 0.00(0.00)\n",
      "Iter 2288 | Time 79.5788(79.0405) | Bit/dim 3.4850(3.4925) | Xent 0.0000(0.0000) | Loss 8.7240(9.6711) | Error 0.0000(0.0000) Steps 730(713.39) | Grad Norm 1.3735(1.1932) | Total Time 0.00(0.00)\n",
      "Iter 2289 | Time 77.1458(78.9837) | Bit/dim 3.5083(3.4930) | Xent 0.0000(0.0000) | Loss 8.9103(9.6483) | Error 0.0000(0.0000) Steps 712(713.35) | Grad Norm 0.9744(1.1867) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 77.5400(78.9404) | Bit/dim 3.4941(3.4930) | Xent 0.0000(0.0000) | Loss 8.9524(9.6274) | Error 0.0000(0.0000) Steps 724(713.66) | Grad Norm 0.8447(1.1764) | Total Time 0.00(0.00)\n",
      "Iter 2291 | Time 84.2944(79.1010) | Bit/dim 3.4868(3.4928) | Xent 0.0000(0.0000) | Loss 8.9811(9.6080) | Error 0.0000(0.0000) Steps 724(713.97) | Grad Norm 1.0588(1.1729) | Total Time 0.00(0.00)\n",
      "Iter 2292 | Time 80.0857(79.1305) | Bit/dim 3.4903(3.4927) | Xent 0.0000(0.0000) | Loss 8.8858(9.5864) | Error 0.0000(0.0000) Steps 724(714.28) | Grad Norm 1.1024(1.1708) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 25.4499, Epoch Time 518.1041(498.2664), Bit/dim 3.4971(best: 3.4906), Xent 0.0000, Loss 3.4971, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2293 | Time 77.0759(79.0689) | Bit/dim 3.4860(3.4925) | Xent 0.0000(0.0000) | Loss 13.2721(9.6970) | Error 0.0000(0.0000) Steps 688(713.49) | Grad Norm 0.9042(1.1628) | Total Time 0.00(0.00)\n",
      "Iter 2294 | Time 73.8440(78.9121) | Bit/dim 3.4931(3.4925) | Xent 0.0000(0.0000) | Loss 8.9429(9.6743) | Error 0.0000(0.0000) Steps 700(713.08) | Grad Norm 1.0949(1.1607) | Total Time 0.00(0.00)\n",
      "Iter 2295 | Time 82.1051(79.0079) | Bit/dim 3.4924(3.4925) | Xent 0.0000(0.0000) | Loss 8.8214(9.6487) | Error 0.0000(0.0000) Steps 718(713.23) | Grad Norm 1.9111(1.1833) | Total Time 0.00(0.00)\n",
      "Iter 2296 | Time 85.5103(79.2030) | Bit/dim 3.4927(3.4925) | Xent 0.0000(0.0000) | Loss 9.0343(9.6303) | Error 0.0000(0.0000) Steps 742(714.09) | Grad Norm 2.3629(1.2186) | Total Time 0.00(0.00)\n",
      "Iter 2297 | Time 82.7709(79.3100) | Bit/dim 3.4870(3.4924) | Xent 0.0000(0.0000) | Loss 8.6665(9.6014) | Error 0.0000(0.0000) Steps 712(714.03) | Grad Norm 2.3521(1.2526) | Total Time 0.00(0.00)\n",
      "Iter 2298 | Time 82.5988(79.4087) | Bit/dim 3.4897(3.4923) | Xent 0.0000(0.0000) | Loss 8.8178(9.5779) | Error 0.0000(0.0000) Steps 712(713.97) | Grad Norm 2.0046(1.2752) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 25.3549, Epoch Time 525.0950(499.0713), Bit/dim 3.4908(best: 3.4906), Xent 0.0000, Loss 3.4908, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2299 | Time 75.1620(79.2813) | Bit/dim 3.5002(3.4925) | Xent 0.0000(0.0000) | Loss 12.9180(9.6781) | Error 0.0000(0.0000) Steps 694(713.37) | Grad Norm 2.0919(1.2997) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 78.3095(79.2522) | Bit/dim 3.4885(3.4924) | Xent 0.0000(0.0000) | Loss 8.8072(9.6520) | Error 0.0000(0.0000) Steps 694(712.79) | Grad Norm 1.8730(1.3169) | Total Time 0.00(0.00)\n",
      "Iter 2301 | Time 78.4848(79.2291) | Bit/dim 3.4899(3.4923) | Xent 0.0000(0.0000) | Loss 9.0243(9.6331) | Error 0.0000(0.0000) Steps 736(713.49) | Grad Norm 1.1067(1.3106) | Total Time 0.00(0.00)\n",
      "Iter 2302 | Time 78.3307(79.2022) | Bit/dim 3.4871(3.4922) | Xent 0.0000(0.0000) | Loss 8.8914(9.6109) | Error 0.0000(0.0000) Steps 688(712.72) | Grad Norm 0.5109(1.2866) | Total Time 0.00(0.00)\n",
      "Iter 2303 | Time 80.0064(79.2263) | Bit/dim 3.4943(3.4922) | Xent 0.0000(0.0000) | Loss 8.7022(9.5836) | Error 0.0000(0.0000) Steps 712(712.70) | Grad Norm 0.4492(1.2615) | Total Time 0.00(0.00)\n",
      "Iter 2304 | Time 78.1845(79.1951) | Bit/dim 3.4990(3.4924) | Xent 0.0000(0.0000) | Loss 8.9038(9.5632) | Error 0.0000(0.0000) Steps 694(712.14) | Grad Norm 0.6232(1.2423) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 25.1283, Epoch Time 509.6167(499.3876), Bit/dim 3.4884(best: 3.4906), Xent 0.0000, Loss 3.4884, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2305 | Time 78.8135(79.1836) | Bit/dim 3.4899(3.4924) | Xent 0.0000(0.0000) | Loss 13.6509(9.6859) | Error 0.0000(0.0000) Steps 712(712.13) | Grad Norm 0.7554(1.2277) | Total Time 0.00(0.00)\n",
      "Iter 2306 | Time 77.1509(79.1226) | Bit/dim 3.4980(3.4925) | Xent 0.0000(0.0000) | Loss 8.6846(9.6558) | Error 0.0000(0.0000) Steps 694(711.59) | Grad Norm 0.8872(1.2175) | Total Time 0.00(0.00)\n",
      "Iter 2307 | Time 78.7008(79.1100) | Bit/dim 3.4842(3.4923) | Xent 0.0000(0.0000) | Loss 8.9140(9.6336) | Error 0.0000(0.0000) Steps 700(711.24) | Grad Norm 1.2606(1.2188) | Total Time 0.00(0.00)\n",
      "Iter 2308 | Time 78.2469(79.0841) | Bit/dim 3.4921(3.4923) | Xent 0.0000(0.0000) | Loss 8.8196(9.6091) | Error 0.0000(0.0000) Steps 694(710.73) | Grad Norm 1.7576(1.2350) | Total Time 0.00(0.00)\n",
      "Iter 2309 | Time 71.8628(78.8674) | Bit/dim 3.4938(3.4923) | Xent 0.0000(0.0000) | Loss 8.4724(9.5750) | Error 0.0000(0.0000) Steps 670(709.50) | Grad Norm 2.2907(1.2666) | Total Time 0.00(0.00)\n",
      "Iter 2310 | Time 81.7005(78.9524) | Bit/dim 3.4956(3.4924) | Xent 0.0000(0.0000) | Loss 9.0632(9.5597) | Error 0.0000(0.0000) Steps 712(709.58) | Grad Norm 2.6132(1.3070) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 25.6694, Epoch Time 507.9371(499.6441), Bit/dim 3.4993(best: 3.4884), Xent 0.0000, Loss 3.4993, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2311 | Time 76.2302(78.8708) | Bit/dim 3.4898(3.4923) | Xent 0.0000(0.0000) | Loss 13.8079(9.6871) | Error 0.0000(0.0000) Steps 694(709.11) | Grad Norm 2.6055(1.3460) | Total Time 0.00(0.00)\n",
      "Iter 2312 | Time 77.9914(78.8444) | Bit/dim 3.4842(3.4921) | Xent 0.0000(0.0000) | Loss 8.8547(9.6622) | Error 0.0000(0.0000) Steps 700(708.84) | Grad Norm 2.2086(1.3719) | Total Time 0.00(0.00)\n",
      "Iter 2313 | Time 77.2103(78.7954) | Bit/dim 3.4867(3.4919) | Xent 0.0000(0.0000) | Loss 9.0044(9.6424) | Error 0.0000(0.0000) Steps 706(708.75) | Grad Norm 1.9873(1.3903) | Total Time 0.00(0.00)\n",
      "Iter 2314 | Time 87.0335(79.0425) | Bit/dim 3.4869(3.4918) | Xent 0.0000(0.0000) | Loss 8.8452(9.6185) | Error 0.0000(0.0000) Steps 718(709.03) | Grad Norm 1.9110(1.4060) | Total Time 0.00(0.00)\n",
      "Iter 2315 | Time 80.7531(79.0938) | Bit/dim 3.4873(3.4917) | Xent 0.0000(0.0000) | Loss 8.5920(9.5877) | Error 0.0000(0.0000) Steps 712(709.12) | Grad Norm 1.7310(1.4157) | Total Time 0.00(0.00)\n",
      "Iter 2316 | Time 79.2943(79.0998) | Bit/dim 3.5100(3.4922) | Xent 0.0000(0.0000) | Loss 8.7809(9.5635) | Error 0.0000(0.0000) Steps 712(709.21) | Grad Norm 1.4822(1.4177) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 25.1867, Epoch Time 519.4769(500.2391), Bit/dim 3.4989(best: 3.4884), Xent 0.0000, Loss 3.4989, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2317 | Time 80.4585(79.1406) | Bit/dim 3.4761(3.4917) | Xent 0.0000(0.0000) | Loss 13.5741(9.6838) | Error 0.0000(0.0000) Steps 724(709.65) | Grad Norm 1.7279(1.4270) | Total Time 0.00(0.00)\n",
      "Iter 2318 | Time 80.5141(79.1818) | Bit/dim 3.4944(3.4918) | Xent 0.0000(0.0000) | Loss 8.9529(9.6619) | Error 0.0000(0.0000) Steps 724(710.08) | Grad Norm 1.9735(1.4434) | Total Time 0.00(0.00)\n",
      "Iter 2319 | Time 83.6794(79.3167) | Bit/dim 3.4914(3.4918) | Xent 0.0000(0.0000) | Loss 8.8720(9.6382) | Error 0.0000(0.0000) Steps 718(710.32) | Grad Norm 2.2255(1.4669) | Total Time 0.00(0.00)\n",
      "Iter 2320 | Time 84.9943(79.4871) | Bit/dim 3.4820(3.4915) | Xent 0.0000(0.0000) | Loss 8.8725(9.6152) | Error 0.0000(0.0000) Steps 742(711.27) | Grad Norm 2.4721(1.4970) | Total Time 0.00(0.00)\n",
      "Iter 2321 | Time 78.0333(79.4434) | Bit/dim 3.5049(3.4919) | Xent 0.0000(0.0000) | Loss 8.7828(9.5903) | Error 0.0000(0.0000) Steps 706(711.11) | Grad Norm 2.2549(1.5198) | Total Time 0.00(0.00)\n",
      "Iter 2322 | Time 83.6055(79.5683) | Bit/dim 3.5011(3.4922) | Xent 0.0000(0.0000) | Loss 8.8643(9.5685) | Error 0.0000(0.0000) Steps 724(711.50) | Grad Norm 1.6399(1.5234) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 25.4499, Epoch Time 532.3660(501.2029), Bit/dim 3.4894(best: 3.4884), Xent 0.0000, Loss 3.4894, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2323 | Time 76.5974(79.4792) | Bit/dim 3.4808(3.4918) | Xent 0.0000(0.0000) | Loss 13.5471(9.6878) | Error 0.0000(0.0000) Steps 718(711.69) | Grad Norm 1.2884(1.5163) | Total Time 0.00(0.00)\n",
      "Iter 2324 | Time 74.8519(79.3404) | Bit/dim 3.4828(3.4916) | Xent 0.0000(0.0000) | Loss 8.7597(9.6600) | Error 0.0000(0.0000) Steps 718(711.88) | Grad Norm 1.2940(1.5096) | Total Time 0.00(0.00)\n",
      "Iter 2325 | Time 80.4183(79.3727) | Bit/dim 3.5057(3.4920) | Xent 0.0000(0.0000) | Loss 8.9794(9.6396) | Error 0.0000(0.0000) Steps 736(712.60) | Grad Norm 1.2735(1.5026) | Total Time 0.00(0.00)\n",
      "Iter 2326 | Time 80.6745(79.4118) | Bit/dim 3.5003(3.4922) | Xent 0.0000(0.0000) | Loss 8.9807(9.6198) | Error 0.0000(0.0000) Steps 742(713.49) | Grad Norm 1.2936(1.4963) | Total Time 0.00(0.00)\n",
      "Iter 2327 | Time 84.9437(79.5777) | Bit/dim 3.4838(3.4920) | Xent 0.0000(0.0000) | Loss 8.9167(9.5987) | Error 0.0000(0.0000) Steps 748(714.52) | Grad Norm 1.4275(1.4942) | Total Time 0.00(0.00)\n",
      "Iter 2328 | Time 82.0123(79.6508) | Bit/dim 3.4997(3.4922) | Xent 0.0000(0.0000) | Loss 8.9040(9.5779) | Error 0.0000(0.0000) Steps 706(714.27) | Grad Norm 1.6878(1.5000) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 25.3874, Epoch Time 520.6824(501.7873), Bit/dim 3.4947(best: 3.4884), Xent 0.0000, Loss 3.4947, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2329 | Time 80.3958(79.6731) | Bit/dim 3.4961(3.4923) | Xent 0.0000(0.0000) | Loss 13.2114(9.6869) | Error 0.0000(0.0000) Steps 736(714.92) | Grad Norm 1.7463(1.5074) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 80.7194(79.7045) | Bit/dim 3.5011(3.4926) | Xent 0.0000(0.0000) | Loss 8.8031(9.6604) | Error 0.0000(0.0000) Steps 706(714.65) | Grad Norm 1.3367(1.5023) | Total Time 0.00(0.00)\n",
      "Iter 2331 | Time 83.0782(79.8057) | Bit/dim 3.4989(3.4928) | Xent 0.0000(0.0000) | Loss 9.0734(9.6428) | Error 0.0000(0.0000) Steps 730(715.11) | Grad Norm 0.9702(1.4863) | Total Time 0.00(0.00)\n",
      "Iter 2332 | Time 74.1061(79.6347) | Bit/dim 3.4882(3.4926) | Xent 0.0000(0.0000) | Loss 8.9018(9.6205) | Error 0.0000(0.0000) Steps 706(714.84) | Grad Norm 0.6746(1.4620) | Total Time 0.00(0.00)\n",
      "Iter 2333 | Time 80.3285(79.6555) | Bit/dim 3.4726(3.4920) | Xent 0.0000(0.0000) | Loss 8.9038(9.5990) | Error 0.0000(0.0000) Steps 694(714.21) | Grad Norm 0.7845(1.4417) | Total Time 0.00(0.00)\n",
      "Iter 2334 | Time 81.2134(79.7023) | Bit/dim 3.4845(3.4918) | Xent 0.0000(0.0000) | Loss 8.9565(9.5798) | Error 0.0000(0.0000) Steps 730(714.69) | Grad Norm 1.0934(1.4312) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 25.3713, Epoch Time 521.6641(502.3836), Bit/dim 3.4974(best: 3.4884), Xent 0.0000, Loss 3.4974, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2335 | Time 86.2992(79.9002) | Bit/dim 3.4905(3.4918) | Xent 0.0000(0.0000) | Loss 13.8852(9.7089) | Error 0.0000(0.0000) Steps 748(715.69) | Grad Norm 1.2480(1.4257) | Total Time 0.00(0.00)\n",
      "Iter 2336 | Time 83.6612(80.0130) | Bit/dim 3.4907(3.4917) | Xent 0.0000(0.0000) | Loss 9.0103(9.6880) | Error 0.0000(0.0000) Steps 712(715.58) | Grad Norm 1.2839(1.4215) | Total Time 0.00(0.00)\n",
      "Iter 2337 | Time 81.5299(80.0585) | Bit/dim 3.4862(3.4916) | Xent 0.0000(0.0000) | Loss 8.8818(9.6638) | Error 0.0000(0.0000) Steps 706(715.29) | Grad Norm 1.1416(1.4131) | Total Time 0.00(0.00)\n",
      "Iter 2338 | Time 82.7403(80.1390) | Bit/dim 3.4845(3.4914) | Xent 0.0000(0.0000) | Loss 8.8935(9.6407) | Error 0.0000(0.0000) Steps 736(715.91) | Grad Norm 1.0970(1.4036) | Total Time 0.00(0.00)\n",
      "Iter 2339 | Time 75.2595(79.9926) | Bit/dim 3.4925(3.4914) | Xent 0.0000(0.0000) | Loss 8.9641(9.6204) | Error 0.0000(0.0000) Steps 736(716.51) | Grad Norm 1.6738(1.4117) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 73.3312(79.7927) | Bit/dim 3.5052(3.4918) | Xent 0.0000(0.0000) | Loss 8.8192(9.5963) | Error 0.0000(0.0000) Steps 700(716.02) | Grad Norm 2.4342(1.4424) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 25.4503, Epoch Time 524.7034(503.0532), Bit/dim 3.4963(best: 3.4884), Xent 0.0000, Loss 3.4963, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2341 | Time 79.8261(79.7937) | Bit/dim 3.4956(3.4919) | Xent 0.0000(0.0000) | Loss 13.3445(9.7088) | Error 0.0000(0.0000) Steps 712(715.90) | Grad Norm 3.0138(1.4895) | Total Time 0.00(0.00)\n",
      "Iter 2342 | Time 76.7596(79.7027) | Bit/dim 3.4888(3.4918) | Xent 0.0000(0.0000) | Loss 8.8166(9.6820) | Error 0.0000(0.0000) Steps 706(715.60) | Grad Norm 3.1324(1.5388) | Total Time 0.00(0.00)\n",
      "Iter 2343 | Time 81.1707(79.7468) | Bit/dim 3.4851(3.4916) | Xent 0.0000(0.0000) | Loss 8.8277(9.6564) | Error 0.0000(0.0000) Steps 730(716.03) | Grad Norm 2.5259(1.5684) | Total Time 0.00(0.00)\n",
      "Iter 2344 | Time 81.8191(79.8089) | Bit/dim 3.4885(3.4915) | Xent 0.0000(0.0000) | Loss 9.0613(9.6385) | Error 0.0000(0.0000) Steps 748(716.99) | Grad Norm 2.1648(1.5863) | Total Time 0.00(0.00)\n",
      "Iter 2345 | Time 81.9889(79.8743) | Bit/dim 3.4915(3.4915) | Xent 0.0000(0.0000) | Loss 8.9026(9.6165) | Error 0.0000(0.0000) Steps 724(717.20) | Grad Norm 2.2000(1.6047) | Total Time 0.00(0.00)\n",
      "Iter 2346 | Time 79.3961(79.8600) | Bit/dim 3.4962(3.4917) | Xent 0.0000(0.0000) | Loss 8.9164(9.5955) | Error 0.0000(0.0000) Steps 736(717.76) | Grad Norm 2.0914(1.6193) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 25.6635, Epoch Time 522.6082(503.6398), Bit/dim 3.4935(best: 3.4884), Xent 0.0000, Loss 3.4935, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2347 | Time 77.3225(79.7839) | Bit/dim 3.4860(3.4915) | Xent 0.0000(0.0000) | Loss 13.6398(9.7168) | Error 0.0000(0.0000) Steps 712(717.59) | Grad Norm 1.7442(1.6231) | Total Time 0.00(0.00)\n",
      "Iter 2348 | Time 80.7494(79.8128) | Bit/dim 3.4998(3.4918) | Xent 0.0000(0.0000) | Loss 8.9816(9.6947) | Error 0.0000(0.0000) Steps 718(717.60) | Grad Norm 0.8764(1.6007) | Total Time 0.00(0.00)\n",
      "Iter 2349 | Time 78.7576(79.7812) | Bit/dim 3.4848(3.4915) | Xent 0.0000(0.0000) | Loss 8.7006(9.6649) | Error 0.0000(0.0000) Steps 718(717.62) | Grad Norm 0.9322(1.5806) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 77.2775(79.7061) | Bit/dim 3.4827(3.4913) | Xent 0.0000(0.0000) | Loss 8.8184(9.6395) | Error 0.0000(0.0000) Steps 712(717.45) | Grad Norm 1.6694(1.5833) | Total Time 0.00(0.00)\n",
      "Iter 2351 | Time 79.4998(79.6999) | Bit/dim 3.4866(3.4911) | Xent 0.0000(0.0000) | Loss 8.8980(9.6173) | Error 0.0000(0.0000) Steps 724(717.64) | Grad Norm 2.4921(1.6105) | Total Time 0.00(0.00)\n",
      "Iter 2352 | Time 81.7320(79.7608) | Bit/dim 3.4912(3.4911) | Xent 0.0000(0.0000) | Loss 8.9302(9.5967) | Error 0.0000(0.0000) Steps 730(718.01) | Grad Norm 2.8381(1.6474) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 25.5613, Epoch Time 517.1050(504.0438), Bit/dim 3.4951(best: 3.4884), Xent 0.0000, Loss 3.4951, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2353 | Time 82.6146(79.8464) | Bit/dim 3.5056(3.4916) | Xent 0.0000(0.0000) | Loss 13.6702(9.7189) | Error 0.0000(0.0000) Steps 724(718.19) | Grad Norm 2.7489(1.6804) | Total Time 0.00(0.00)\n",
      "Iter 2354 | Time 75.3505(79.7116) | Bit/dim 3.4926(3.4916) | Xent 0.0000(0.0000) | Loss 8.8667(9.6933) | Error 0.0000(0.0000) Steps 706(717.83) | Grad Norm 2.2349(1.6970) | Total Time 0.00(0.00)\n",
      "Iter 2355 | Time 79.6178(79.7088) | Bit/dim 3.4835(3.4914) | Xent 0.0000(0.0000) | Loss 8.7377(9.6646) | Error 0.0000(0.0000) Steps 718(717.83) | Grad Norm 1.5921(1.6939) | Total Time 0.00(0.00)\n",
      "Iter 2356 | Time 85.2411(79.8747) | Bit/dim 3.4823(3.4911) | Xent 0.0000(0.0000) | Loss 8.9254(9.6425) | Error 0.0000(0.0000) Steps 736(718.38) | Grad Norm 1.4391(1.6863) | Total Time 0.00(0.00)\n",
      "Iter 2357 | Time 82.6399(79.9577) | Bit/dim 3.4862(3.4909) | Xent 0.0000(0.0000) | Loss 8.9750(9.6224) | Error 0.0000(0.0000) Steps 724(718.55) | Grad Norm 1.3799(1.6771) | Total Time 0.00(0.00)\n",
      "Iter 2358 | Time 81.1493(79.9934) | Bit/dim 3.4902(3.4909) | Xent 0.0000(0.0000) | Loss 8.9067(9.6010) | Error 0.0000(0.0000) Steps 712(718.35) | Grad Norm 1.4996(1.6717) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 25.2113, Epoch Time 527.6903(504.7532), Bit/dim 3.4873(best: 3.4884), Xent 0.0000, Loss 3.4873, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2359 | Time 78.7868(79.9572) | Bit/dim 3.4863(3.4908) | Xent 0.0000(0.0000) | Loss 13.2488(9.7104) | Error 0.0000(0.0000) Steps 730(718.70) | Grad Norm 1.4682(1.6656) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 79.5273(79.9443) | Bit/dim 3.4861(3.4906) | Xent 0.0000(0.0000) | Loss 8.7653(9.6820) | Error 0.0000(0.0000) Steps 712(718.50) | Grad Norm 1.3736(1.6569) | Total Time 0.00(0.00)\n",
      "Iter 2361 | Time 79.2096(79.9223) | Bit/dim 3.4941(3.4907) | Xent 0.0000(0.0000) | Loss 8.9643(9.6605) | Error 0.0000(0.0000) Steps 712(718.30) | Grad Norm 1.3746(1.6484) | Total Time 0.00(0.00)\n",
      "Iter 2362 | Time 80.7714(79.9478) | Bit/dim 3.4911(3.4908) | Xent 0.0000(0.0000) | Loss 8.8376(9.6358) | Error 0.0000(0.0000) Steps 718(718.30) | Grad Norm 1.4759(1.6432) | Total Time 0.00(0.00)\n",
      "Iter 2363 | Time 79.6722(79.9395) | Bit/dim 3.4887(3.4907) | Xent 0.0000(0.0000) | Loss 8.6728(9.6069) | Error 0.0000(0.0000) Steps 712(718.11) | Grad Norm 1.7928(1.6477) | Total Time 0.00(0.00)\n",
      "Iter 2364 | Time 82.9790(80.0307) | Bit/dim 3.4786(3.4903) | Xent 0.0000(0.0000) | Loss 8.8109(9.5830) | Error 0.0000(0.0000) Steps 718(718.10) | Grad Norm 2.2901(1.6670) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 25.6242, Epoch Time 522.6792(505.2910), Bit/dim 3.4896(best: 3.4873), Xent 0.0000, Loss 3.4896, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2365 | Time 79.8175(80.0243) | Bit/dim 3.4816(3.4901) | Xent 0.0000(0.0000) | Loss 13.2369(9.6927) | Error 0.0000(0.0000) Steps 718(718.10) | Grad Norm 2.5152(1.6924) | Total Time 0.00(0.00)\n",
      "Iter 2366 | Time 79.4916(80.0083) | Bit/dim 3.4976(3.4903) | Xent 0.0000(0.0000) | Loss 8.6086(9.6601) | Error 0.0000(0.0000) Steps 718(718.10) | Grad Norm 2.4746(1.7159) | Total Time 0.00(0.00)\n",
      "Iter 2367 | Time 81.0159(80.0385) | Bit/dim 3.4868(3.4902) | Xent 0.0000(0.0000) | Loss 8.7664(9.6333) | Error 0.0000(0.0000) Steps 730(718.45) | Grad Norm 2.1506(1.7289) | Total Time 0.00(0.00)\n",
      "Iter 2368 | Time 77.8529(79.9730) | Bit/dim 3.4825(3.4900) | Xent 0.0000(0.0000) | Loss 8.8858(9.6109) | Error 0.0000(0.0000) Steps 724(718.62) | Grad Norm 1.5755(1.7243) | Total Time 0.00(0.00)\n",
      "Iter 2369 | Time 87.5357(80.1998) | Bit/dim 3.4947(3.4901) | Xent 0.0000(0.0000) | Loss 9.0179(9.5931) | Error 0.0000(0.0000) Steps 730(718.96) | Grad Norm 1.0872(1.7052) | Total Time 0.00(0.00)\n",
      "Iter 2370 | Time 75.5209(80.0595) | Bit/dim 3.4877(3.4900) | Xent 0.0000(0.0000) | Loss 8.8638(9.5712) | Error 0.0000(0.0000) Steps 694(718.21) | Grad Norm 0.8081(1.6783) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 25.7227, Epoch Time 522.9379(505.8204), Bit/dim 3.4938(best: 3.4873), Xent 0.0000, Loss 3.4938, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2371 | Time 74.4046(79.8898) | Bit/dim 3.4813(3.4898) | Xent 0.0000(0.0000) | Loss 13.8115(9.6984) | Error 0.0000(0.0000) Steps 700(717.67) | Grad Norm 0.8549(1.6536) | Total Time 0.00(0.00)\n",
      "Iter 2372 | Time 79.8851(79.8897) | Bit/dim 3.4876(3.4897) | Xent 0.0000(0.0000) | Loss 8.9920(9.6773) | Error 0.0000(0.0000) Steps 718(717.68) | Grad Norm 0.8817(1.6305) | Total Time 0.00(0.00)\n",
      "Iter 2373 | Time 77.9782(79.8323) | Bit/dim 3.4920(3.4898) | Xent 0.0000(0.0000) | Loss 8.8566(9.6526) | Error 0.0000(0.0000) Steps 694(716.97) | Grad Norm 1.0848(1.6141) | Total Time 0.00(0.00)\n",
      "Iter 2374 | Time 75.2165(79.6939) | Bit/dim 3.4895(3.4898) | Xent 0.0000(0.0000) | Loss 8.8219(9.6277) | Error 0.0000(0.0000) Steps 724(717.18) | Grad Norm 1.4065(1.6079) | Total Time 0.00(0.00)\n",
      "Iter 2375 | Time 82.6905(79.7838) | Bit/dim 3.4902(3.4898) | Xent 0.0000(0.0000) | Loss 8.8911(9.6056) | Error 0.0000(0.0000) Steps 712(717.02) | Grad Norm 1.6721(1.6098) | Total Time 0.00(0.00)\n",
      "Iter 2376 | Time 79.1265(79.7640) | Bit/dim 3.4929(3.4899) | Xent 0.0000(0.0000) | Loss 8.7099(9.5787) | Error 0.0000(0.0000) Steps 700(716.51) | Grad Norm 2.0963(1.6244) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 25.3981, Epoch Time 510.7959(505.9696), Bit/dim 3.4886(best: 3.4873), Xent 0.0000, Loss 3.4886, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2377 | Time 74.0247(79.5919) | Bit/dim 3.4823(3.4896) | Xent 0.0000(0.0000) | Loss 13.2029(9.6875) | Error 0.0000(0.0000) Steps 700(716.02) | Grad Norm 2.6869(1.6563) | Total Time 0.00(0.00)\n",
      "Iter 2378 | Time 79.8584(79.5999) | Bit/dim 3.4906(3.4897) | Xent 0.0000(0.0000) | Loss 8.8422(9.6621) | Error 0.0000(0.0000) Steps 712(715.90) | Grad Norm 2.6673(1.6866) | Total Time 0.00(0.00)\n",
      "Iter 2379 | Time 74.0084(79.4321) | Bit/dim 3.4898(3.4897) | Xent 0.0000(0.0000) | Loss 8.6494(9.6317) | Error 0.0000(0.0000) Steps 694(715.24) | Grad Norm 2.6193(1.7146) | Total Time 0.00(0.00)\n",
      "Iter 2380 | Time 77.6241(79.3779) | Bit/dim 3.4870(3.4896) | Xent 0.0000(0.0000) | Loss 8.6672(9.6028) | Error 0.0000(0.0000) Steps 712(715.14) | Grad Norm 2.2963(1.7320) | Total Time 0.00(0.00)\n",
      "Iter 2381 | Time 85.0955(79.5494) | Bit/dim 3.4932(3.4897) | Xent 0.0000(0.0000) | Loss 8.8995(9.5817) | Error 0.0000(0.0000) Steps 718(715.23) | Grad Norm 1.7589(1.7328) | Total Time 0.00(0.00)\n",
      "Iter 2382 | Time 78.1911(79.5087) | Bit/dim 3.4964(3.4899) | Xent 0.0000(0.0000) | Loss 8.8136(9.5587) | Error 0.0000(0.0000) Steps 706(714.95) | Grad Norm 1.3592(1.7216) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 25.6028, Epoch Time 510.4201(506.1032), Bit/dim 3.4944(best: 3.4873), Xent 0.0000, Loss 3.4944, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2383 | Time 78.9274(79.4912) | Bit/dim 3.4926(3.4900) | Xent 0.0000(0.0000) | Loss 12.7974(9.6558) | Error 0.0000(0.0000) Steps 700(714.50) | Grad Norm 1.3431(1.7103) | Total Time 0.00(0.00)\n",
      "Iter 2384 | Time 73.0726(79.2987) | Bit/dim 3.4952(3.4901) | Xent 0.0000(0.0000) | Loss 8.7589(9.6289) | Error 0.0000(0.0000) Steps 700(714.07) | Grad Norm 1.0280(1.6898) | Total Time 0.00(0.00)\n",
      "Iter 2385 | Time 84.5404(79.4559) | Bit/dim 3.4940(3.4903) | Xent 0.0000(0.0000) | Loss 8.9198(9.6076) | Error 0.0000(0.0000) Steps 712(714.00) | Grad Norm 0.8605(1.6649) | Total Time 0.00(0.00)\n",
      "Iter 2386 | Time 76.4602(79.3660) | Bit/dim 3.4752(3.4898) | Xent 0.0000(0.0000) | Loss 8.9020(9.5865) | Error 0.0000(0.0000) Steps 712(713.94) | Grad Norm 0.9411(1.6432) | Total Time 0.00(0.00)\n",
      "Iter 2387 | Time 78.0684(79.3271) | Bit/dim 3.4798(3.4895) | Xent 0.0000(0.0000) | Loss 8.8846(9.5654) | Error 0.0000(0.0000) Steps 724(714.25) | Grad Norm 1.0637(1.6258) | Total Time 0.00(0.00)\n",
      "Iter 2388 | Time 75.4427(79.2106) | Bit/dim 3.4900(3.4895) | Xent 0.0000(0.0000) | Loss 8.4275(9.5313) | Error 0.0000(0.0000) Steps 670(712.92) | Grad Norm 1.2087(1.6133) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 25.5294, Epoch Time 508.1993(506.1660), Bit/dim 3.4913(best: 3.4873), Xent 0.0000, Loss 3.4913, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2389 | Time 79.4394(79.2174) | Bit/dim 3.4851(3.4894) | Xent 0.0000(0.0000) | Loss 13.6066(9.6535) | Error 0.0000(0.0000) Steps 730(713.43) | Grad Norm 1.5573(1.6116) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 78.1510(79.1855) | Bit/dim 3.4928(3.4895) | Xent 0.0000(0.0000) | Loss 8.8349(9.6290) | Error 0.0000(0.0000) Steps 706(713.21) | Grad Norm 2.0633(1.6252) | Total Time 0.00(0.00)\n",
      "Iter 2391 | Time 84.7785(79.3532) | Bit/dim 3.4936(3.4896) | Xent 0.0000(0.0000) | Loss 8.8225(9.6048) | Error 0.0000(0.0000) Steps 706(712.99) | Grad Norm 2.7030(1.6575) | Total Time 0.00(0.00)\n",
      "Iter 2392 | Time 75.9148(79.2501) | Bit/dim 3.4953(3.4898) | Xent 0.0000(0.0000) | Loss 8.9202(9.5842) | Error 0.0000(0.0000) Steps 688(712.24) | Grad Norm 3.2008(1.7038) | Total Time 0.00(0.00)\n",
      "Iter 2393 | Time 81.0234(79.3033) | Bit/dim 3.4915(3.4898) | Xent 0.0000(0.0000) | Loss 8.8042(9.5608) | Error 0.0000(0.0000) Steps 706(712.06) | Grad Norm 3.5247(1.7584) | Total Time 0.00(0.00)\n",
      "Iter 2394 | Time 79.7556(79.3169) | Bit/dim 3.4906(3.4899) | Xent 0.0000(0.0000) | Loss 8.9247(9.5418) | Error 0.0000(0.0000) Steps 718(712.23) | Grad Norm 3.3685(1.8067) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 25.6255, Epoch Time 520.4375(506.5942), Bit/dim 3.4879(best: 3.4873), Xent 0.0000, Loss 3.4879, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2395 | Time 75.9991(79.2173) | Bit/dim 3.4780(3.4895) | Xent 0.0000(0.0000) | Loss 13.2354(9.6526) | Error 0.0000(0.0000) Steps 694(711.69) | Grad Norm 2.3668(1.8235) | Total Time 0.00(0.00)\n",
      "Iter 2396 | Time 81.2291(79.2777) | Bit/dim 3.4826(3.4893) | Xent 0.0000(0.0000) | Loss 8.9446(9.6313) | Error 0.0000(0.0000) Steps 724(712.06) | Grad Norm 1.3194(1.8084) | Total Time 0.00(0.00)\n",
      "Iter 2397 | Time 75.1045(79.1525) | Bit/dim 3.4967(3.4895) | Xent 0.0000(0.0000) | Loss 8.8830(9.6089) | Error 0.0000(0.0000) Steps 694(711.51) | Grad Norm 0.8764(1.7805) | Total Time 0.00(0.00)\n",
      "Iter 2398 | Time 78.8994(79.1449) | Bit/dim 3.4884(3.4895) | Xent 0.0000(0.0000) | Loss 8.8067(9.5848) | Error 0.0000(0.0000) Steps 700(711.17) | Grad Norm 1.4001(1.7690) | Total Time 0.00(0.00)\n",
      "Iter 2399 | Time 76.2023(79.0566) | Bit/dim 3.4944(3.4896) | Xent 0.0000(0.0000) | Loss 8.7807(9.5607) | Error 0.0000(0.0000) Steps 694(710.65) | Grad Norm 2.0859(1.7785) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 80.7274(79.1067) | Bit/dim 3.4892(3.4896) | Xent 0.0000(0.0000) | Loss 8.7630(9.5368) | Error 0.0000(0.0000) Steps 700(710.33) | Grad Norm 2.3991(1.7972) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 25.6233, Epoch Time 509.7064(506.6876), Bit/dim 3.4896(best: 3.4873), Xent 0.0000, Loss 3.4896, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2401 | Time 75.6624(79.0034) | Bit/dim 3.4883(3.4896) | Xent 0.0000(0.0000) | Loss 13.4376(9.6538) | Error 0.0000(0.0000) Steps 682(709.48) | Grad Norm 2.8286(1.8281) | Total Time 0.00(0.00)\n",
      "Iter 2402 | Time 80.5585(79.0501) | Bit/dim 3.4992(3.4899) | Xent 0.0000(0.0000) | Loss 8.9715(9.6333) | Error 0.0000(0.0000) Steps 724(709.92) | Grad Norm 3.0373(1.8644) | Total Time 0.00(0.00)\n",
      "Iter 2403 | Time 81.7129(79.1299) | Bit/dim 3.4969(3.4901) | Xent 0.0000(0.0000) | Loss 8.9647(9.6133) | Error 0.0000(0.0000) Steps 730(710.52) | Grad Norm 2.8748(1.8947) | Total Time 0.00(0.00)\n",
      "Iter 2404 | Time 80.2335(79.1631) | Bit/dim 3.4913(3.4901) | Xent 0.0000(0.0000) | Loss 8.4486(9.5783) | Error 0.0000(0.0000) Steps 682(709.67) | Grad Norm 2.1594(1.9026) | Total Time 0.00(0.00)\n",
      "Iter 2405 | Time 77.5004(79.1132) | Bit/dim 3.4899(3.4901) | Xent 0.0000(0.0000) | Loss 8.8106(9.5553) | Error 0.0000(0.0000) Steps 712(709.74) | Grad Norm 1.2277(1.8824) | Total Time 0.00(0.00)\n",
      "Iter 2406 | Time 84.9412(79.2880) | Bit/dim 3.4844(3.4899) | Xent 0.0000(0.0000) | Loss 8.9311(9.5366) | Error 0.0000(0.0000) Steps 736(710.52) | Grad Norm 0.7425(1.8482) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 25.9470, Epoch Time 522.8252(507.1717), Bit/dim 3.4925(best: 3.4873), Xent 0.0000, Loss 3.4925, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2407 | Time 79.2405(79.2866) | Bit/dim 3.4855(3.4898) | Xent 0.0000(0.0000) | Loss 12.9472(9.6389) | Error 0.0000(0.0000) Steps 706(710.39) | Grad Norm 1.0714(1.8249) | Total Time 0.00(0.00)\n",
      "Iter 2408 | Time 81.3667(79.3490) | Bit/dim 3.4857(3.4897) | Xent 0.0000(0.0000) | Loss 8.9338(9.6177) | Error 0.0000(0.0000) Steps 700(710.08) | Grad Norm 1.6382(1.8193) | Total Time 0.00(0.00)\n",
      "Iter 2409 | Time 79.0946(79.3414) | Bit/dim 3.4942(3.4898) | Xent 0.0000(0.0000) | Loss 9.0885(9.6018) | Error 0.0000(0.0000) Steps 748(711.21) | Grad Norm 2.3977(1.8366) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 81.0322(79.3921) | Bit/dim 3.4859(3.4897) | Xent 0.0000(0.0000) | Loss 8.9861(9.5834) | Error 0.0000(0.0000) Steps 736(711.96) | Grad Norm 3.1994(1.8775) | Total Time 0.00(0.00)\n",
      "Iter 2411 | Time 82.4175(79.4828) | Bit/dim 3.4871(3.4896) | Xent 0.0000(0.0000) | Loss 8.8723(9.5620) | Error 0.0000(0.0000) Steps 724(712.32) | Grad Norm 3.5411(1.9274) | Total Time 0.00(0.00)\n",
      "Iter 2412 | Time 80.3456(79.5087) | Bit/dim 3.4982(3.4899) | Xent 0.0000(0.0000) | Loss 8.8903(9.5419) | Error 0.0000(0.0000) Steps 724(712.67) | Grad Norm 3.1481(1.9640) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 25.6784, Epoch Time 525.2948(507.7154), Bit/dim 3.4888(best: 3.4873), Xent 0.0000, Loss 3.4888, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2413 | Time 79.5699(79.5106) | Bit/dim 3.4875(3.4898) | Xent 0.0000(0.0000) | Loss 13.5941(9.6635) | Error 0.0000(0.0000) Steps 730(713.19) | Grad Norm 2.6298(1.9840) | Total Time 0.00(0.00)\n",
      "Iter 2414 | Time 86.3131(79.7146) | Bit/dim 3.4842(3.4896) | Xent 0.0000(0.0000) | Loss 8.8647(9.6395) | Error 0.0000(0.0000) Steps 724(713.51) | Grad Norm 2.4568(1.9982) | Total Time 0.00(0.00)\n",
      "Iter 2415 | Time 81.7813(79.7766) | Bit/dim 3.4834(3.4894) | Xent 0.0000(0.0000) | Loss 8.7001(9.6113) | Error 0.0000(0.0000) Steps 712(713.47) | Grad Norm 2.5869(2.0159) | Total Time 0.00(0.00)\n",
      "Iter 2416 | Time 83.9542(79.9020) | Bit/dim 3.4931(3.4896) | Xent 0.0000(0.0000) | Loss 9.1017(9.5960) | Error 0.0000(0.0000) Steps 730(713.96) | Grad Norm 2.9505(2.0439) | Total Time 0.00(0.00)\n",
      "Iter 2417 | Time 83.0808(79.9973) | Bit/dim 3.4896(3.4896) | Xent 0.0000(0.0000) | Loss 8.5672(9.5652) | Error 0.0000(0.0000) Steps 700(713.55) | Grad Norm 3.1639(2.0775) | Total Time 0.00(0.00)\n",
      "Iter 2418 | Time 79.9075(79.9946) | Bit/dim 3.4914(3.4896) | Xent 0.0000(0.0000) | Loss 8.8712(9.5443) | Error 0.0000(0.0000) Steps 724(713.86) | Grad Norm 2.5447(2.0915) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 25.3421, Epoch Time 536.0114(508.5643), Bit/dim 3.4944(best: 3.4873), Xent 0.0000, Loss 3.4944, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2419 | Time 76.4933(79.8896) | Bit/dim 3.4899(3.4896) | Xent 0.0000(0.0000) | Loss 13.5097(9.6633) | Error 0.0000(0.0000) Steps 688(713.08) | Grad Norm 1.4358(2.0719) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 76.1875(79.7785) | Bit/dim 3.4835(3.4894) | Xent 0.0000(0.0000) | Loss 8.7795(9.6368) | Error 0.0000(0.0000) Steps 694(712.51) | Grad Norm 1.2120(2.0461) | Total Time 0.00(0.00)\n",
      "Iter 2421 | Time 85.9783(79.9645) | Bit/dim 3.4981(3.4897) | Xent 0.0000(0.0000) | Loss 8.8855(9.6142) | Error 0.0000(0.0000) Steps 730(713.04) | Grad Norm 2.2057(2.0508) | Total Time 0.00(0.00)\n",
      "Iter 2422 | Time 83.6002(80.0736) | Bit/dim 3.4916(3.4897) | Xent 0.0000(0.0000) | Loss 8.8024(9.5899) | Error 0.0000(0.0000) Steps 694(712.46) | Grad Norm 2.9791(2.0787) | Total Time 0.00(0.00)\n",
      "Iter 2423 | Time 83.4006(80.1734) | Bit/dim 3.4878(3.4897) | Xent 0.0000(0.0000) | Loss 9.0817(9.5746) | Error 0.0000(0.0000) Steps 724(712.81) | Grad Norm 3.3625(2.1172) | Total Time 0.00(0.00)\n",
      "Iter 2424 | Time 77.9939(80.1080) | Bit/dim 3.4871(3.4896) | Xent 0.0000(0.0000) | Loss 8.7248(9.5492) | Error 0.0000(0.0000) Steps 712(712.79) | Grad Norm 2.9724(2.1429) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 24.9846, Epoch Time 524.4221(509.0400), Bit/dim 3.4923(best: 3.4873), Xent 0.0000, Loss 3.4923, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2425 | Time 83.0148(80.1952) | Bit/dim 3.4818(3.4894) | Xent 0.0000(0.0000) | Loss 13.6938(9.6735) | Error 0.0000(0.0000) Steps 718(712.94) | Grad Norm 2.1218(2.1422) | Total Time 0.00(0.00)\n",
      "Iter 2426 | Time 78.3382(80.1395) | Bit/dim 3.4964(3.4896) | Xent 0.0000(0.0000) | Loss 8.5108(9.6386) | Error 0.0000(0.0000) Steps 688(712.19) | Grad Norm 1.3500(2.1185) | Total Time 0.00(0.00)\n",
      "Iter 2427 | Time 80.6853(80.1559) | Bit/dim 3.4927(3.4897) | Xent 0.0000(0.0000) | Loss 8.8615(9.6153) | Error 0.0000(0.0000) Steps 712(712.19) | Grad Norm 2.0857(2.1175) | Total Time 0.00(0.00)\n",
      "Iter 2428 | Time 78.7487(80.1137) | Bit/dim 3.4880(3.4896) | Xent 0.0000(0.0000) | Loss 8.8624(9.5927) | Error 0.0000(0.0000) Steps 712(712.18) | Grad Norm 3.0350(2.1450) | Total Time 0.00(0.00)\n",
      "Iter 2429 | Time 83.1336(80.2043) | Bit/dim 3.5018(3.4900) | Xent 0.0000(0.0000) | Loss 8.8363(9.5700) | Error 0.0000(0.0000) Steps 706(712.00) | Grad Norm 3.1028(2.1737) | Total Time 0.00(0.00)\n",
      "Iter 2430 | Time 81.8922(80.2549) | Bit/dim 3.4831(3.4898) | Xent 0.0000(0.0000) | Loss 8.8821(9.5494) | Error 0.0000(0.0000) Steps 712(712.00) | Grad Norm 2.4974(2.1834) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 26.0299, Epoch Time 527.8107(509.6031), Bit/dim 3.4908(best: 3.4873), Xent 0.0000, Loss 3.4908, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2431 | Time 79.5000(80.2323) | Bit/dim 3.4850(3.4896) | Xent 0.0000(0.0000) | Loss 13.6298(9.6718) | Error 0.0000(0.0000) Steps 706(711.82) | Grad Norm 1.4132(2.1603) | Total Time 0.00(0.00)\n",
      "Iter 2432 | Time 83.8209(80.3399) | Bit/dim 3.4809(3.4894) | Xent 0.0000(0.0000) | Loss 8.8452(9.6470) | Error 0.0000(0.0000) Steps 712(711.82) | Grad Norm 0.7691(2.1186) | Total Time 0.00(0.00)\n",
      "Iter 2433 | Time 78.8529(80.2953) | Bit/dim 3.4887(3.4894) | Xent 0.0000(0.0000) | Loss 8.9640(9.6265) | Error 0.0000(0.0000) Steps 706(711.65) | Grad Norm 1.4399(2.0982) | Total Time 0.00(0.00)\n",
      "Iter 2434 | Time 72.4510(80.0600) | Bit/dim 3.4895(3.4894) | Xent 0.0000(0.0000) | Loss 8.8882(9.6044) | Error 0.0000(0.0000) Steps 706(711.48) | Grad Norm 2.0466(2.0967) | Total Time 0.00(0.00)\n",
      "Iter 2435 | Time 78.2860(80.0068) | Bit/dim 3.4861(3.4893) | Xent 0.0000(0.0000) | Loss 8.9670(9.5852) | Error 0.0000(0.0000) Steps 712(711.49) | Grad Norm 2.4596(2.1076) | Total Time 0.00(0.00)\n",
      "Iter 2436 | Time 77.8587(79.9423) | Bit/dim 3.4949(3.4894) | Xent 0.0000(0.0000) | Loss 8.7951(9.5615) | Error 0.0000(0.0000) Steps 718(711.69) | Grad Norm 2.3471(2.1148) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 26.0977, Epoch Time 512.5034(509.6901), Bit/dim 3.4869(best: 3.4873), Xent 0.0000, Loss 3.4869, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2437 | Time 77.1849(79.8596) | Bit/dim 3.4890(3.4894) | Xent 0.0000(0.0000) | Loss 13.5284(9.6805) | Error 0.0000(0.0000) Steps 706(711.52) | Grad Norm 1.7954(2.1052) | Total Time 0.00(0.00)\n",
      "Iter 2438 | Time 77.8947(79.8007) | Bit/dim 3.4941(3.4896) | Xent 0.0000(0.0000) | Loss 8.7612(9.6530) | Error 0.0000(0.0000) Steps 700(711.17) | Grad Norm 0.9846(2.0716) | Total Time 0.00(0.00)\n",
      "Iter 2439 | Time 74.0487(79.6281) | Bit/dim 3.4810(3.4893) | Xent 0.0000(0.0000) | Loss 8.8377(9.6285) | Error 0.0000(0.0000) Steps 718(711.38) | Grad Norm 0.6967(2.0303) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 81.2732(79.6774) | Bit/dim 3.4981(3.4896) | Xent 0.0000(0.0000) | Loss 8.8870(9.6063) | Error 0.0000(0.0000) Steps 712(711.40) | Grad Norm 1.2906(2.0081) | Total Time 0.00(0.00)\n",
      "Iter 2441 | Time 80.6469(79.7065) | Bit/dim 3.4830(3.4894) | Xent 0.0000(0.0000) | Loss 8.9041(9.5852) | Error 0.0000(0.0000) Steps 730(711.95) | Grad Norm 1.7492(2.0004) | Total Time 0.00(0.00)\n",
      "Iter 2442 | Time 84.5720(79.8525) | Bit/dim 3.4870(3.4893) | Xent 0.0000(0.0000) | Loss 9.0120(9.5680) | Error 0.0000(0.0000) Steps 742(712.86) | Grad Norm 1.8068(1.9946) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 25.2736, Epoch Time 516.7739(509.9026), Bit/dim 3.4915(best: 3.4869), Xent 0.0000, Loss 3.4915, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2443 | Time 75.0843(79.7094) | Bit/dim 3.4945(3.4895) | Xent 0.0000(0.0000) | Loss 13.3643(9.6819) | Error 0.0000(0.0000) Steps 718(713.01) | Grad Norm 1.6382(1.9839) | Total Time 0.00(0.00)\n",
      "Iter 2444 | Time 81.3158(79.7576) | Bit/dim 3.4758(3.4890) | Xent 0.0000(0.0000) | Loss 9.0011(9.6615) | Error 0.0000(0.0000) Steps 706(712.80) | Grad Norm 1.2968(1.9633) | Total Time 0.00(0.00)\n",
      "Iter 2445 | Time 77.6535(79.6945) | Bit/dim 3.4823(3.4888) | Xent 0.0000(0.0000) | Loss 8.9230(9.6393) | Error 0.0000(0.0000) Steps 730(713.32) | Grad Norm 1.0491(1.9358) | Total Time 0.00(0.00)\n",
      "Iter 2446 | Time 79.8327(79.6987) | Bit/dim 3.4812(3.4886) | Xent 0.0000(0.0000) | Loss 8.8557(9.6158) | Error 0.0000(0.0000) Steps 724(713.64) | Grad Norm 1.4883(1.9224) | Total Time 0.00(0.00)\n",
      "Iter 2447 | Time 81.7474(79.7601) | Bit/dim 3.4866(3.4886) | Xent 0.0000(0.0000) | Loss 8.8252(9.5921) | Error 0.0000(0.0000) Steps 724(713.95) | Grad Norm 2.2371(1.9318) | Total Time 0.00(0.00)\n",
      "Iter 2448 | Time 81.4058(79.8095) | Bit/dim 3.4990(3.4889) | Xent 0.0000(0.0000) | Loss 8.8409(9.5695) | Error 0.0000(0.0000) Steps 718(714.07) | Grad Norm 2.8735(1.9601) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 25.4441, Epoch Time 518.6177(510.1641), Bit/dim 3.4940(best: 3.4869), Xent 0.0000, Loss 3.4940, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2449 | Time 79.0406(79.7864) | Bit/dim 3.5033(3.4893) | Xent 0.0000(0.0000) | Loss 13.5050(9.6876) | Error 0.0000(0.0000) Steps 700(713.65) | Grad Norm 3.1379(1.9954) | Total Time 0.00(0.00)\n",
      "Iter 2450 | Time 81.5557(79.8395) | Bit/dim 3.4938(3.4894) | Xent 0.0000(0.0000) | Loss 8.6895(9.6577) | Error 0.0000(0.0000) Steps 712(713.60) | Grad Norm 2.9307(2.0235) | Total Time 0.00(0.00)\n",
      "Iter 2451 | Time 81.1030(79.8774) | Bit/dim 3.4750(3.4890) | Xent 0.0000(0.0000) | Loss 8.4998(9.6229) | Error 0.0000(0.0000) Steps 730(714.09) | Grad Norm 2.2324(2.0298) | Total Time 0.00(0.00)\n",
      "Iter 2452 | Time 76.0206(79.7617) | Bit/dim 3.4937(3.4891) | Xent 0.0000(0.0000) | Loss 8.8854(9.6008) | Error 0.0000(0.0000) Steps 712(714.03) | Grad Norm 1.4505(2.0124) | Total Time 0.00(0.00)\n",
      "Iter 2453 | Time 83.4173(79.8714) | Bit/dim 3.4817(3.4889) | Xent 0.0000(0.0000) | Loss 9.0124(9.5832) | Error 0.0000(0.0000) Steps 748(715.05) | Grad Norm 1.3330(1.9920) | Total Time 0.00(0.00)\n",
      "Iter 2454 | Time 83.7510(79.9878) | Bit/dim 3.4723(3.4884) | Xent 0.0000(0.0000) | Loss 8.9420(9.5639) | Error 0.0000(0.0000) Steps 736(715.67) | Grad Norm 1.6025(1.9803) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 25.2612, Epoch Time 526.4557(510.6528), Bit/dim 3.4882(best: 3.4869), Xent 0.0000, Loss 3.4882, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2455 | Time 83.7581(80.1009) | Bit/dim 3.4808(3.4882) | Xent 0.0000(0.0000) | Loss 13.7673(9.6900) | Error 0.0000(0.0000) Steps 730(716.10) | Grad Norm 2.3828(1.9924) | Total Time 0.00(0.00)\n",
      "Iter 2456 | Time 77.0826(80.0103) | Bit/dim 3.4822(3.4880) | Xent 0.0000(0.0000) | Loss 8.5948(9.6572) | Error 0.0000(0.0000) Steps 706(715.80) | Grad Norm 2.9287(2.0205) | Total Time 0.00(0.00)\n",
      "Iter 2457 | Time 80.4001(80.0220) | Bit/dim 3.4929(3.4882) | Xent 0.0000(0.0000) | Loss 8.9904(9.6372) | Error 0.0000(0.0000) Steps 730(716.23) | Grad Norm 2.6157(2.0383) | Total Time 0.00(0.00)\n",
      "Iter 2458 | Time 80.6628(80.0412) | Bit/dim 3.4815(3.4880) | Xent 0.0000(0.0000) | Loss 8.9445(9.6164) | Error 0.0000(0.0000) Steps 712(716.10) | Grad Norm 1.9724(2.0364) | Total Time 0.00(0.00)\n",
      "Iter 2459 | Time 79.9875(80.0396) | Bit/dim 3.4868(3.4879) | Xent 0.0000(0.0000) | Loss 8.8689(9.5940) | Error 0.0000(0.0000) Steps 706(715.80) | Grad Norm 1.2584(2.0130) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 82.2481(80.1059) | Bit/dim 3.4989(3.4883) | Xent 0.0000(0.0000) | Loss 8.9511(9.5747) | Error 0.0000(0.0000) Steps 718(715.86) | Grad Norm 0.6837(1.9731) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 25.8274, Epoch Time 525.9108(511.1106), Bit/dim 3.4870(best: 3.4869), Xent 0.0000, Loss 3.4870, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2461 | Time 74.7867(79.9463) | Bit/dim 3.4897(3.4883) | Xent 0.0000(0.0000) | Loss 13.7159(9.6989) | Error 0.0000(0.0000) Steps 700(715.39) | Grad Norm 0.5886(1.9316) | Total Time 0.00(0.00)\n",
      "Iter 2462 | Time 76.8913(79.8547) | Bit/dim 3.4814(3.4881) | Xent 0.0000(0.0000) | Loss 8.8533(9.6735) | Error 0.0000(0.0000) Steps 712(715.29) | Grad Norm 1.0541(1.9053) | Total Time 0.00(0.00)\n",
      "Iter 2463 | Time 83.8590(79.9748) | Bit/dim 3.4886(3.4881) | Xent 0.0000(0.0000) | Loss 8.8993(9.6503) | Error 0.0000(0.0000) Steps 730(715.73) | Grad Norm 1.4547(1.8918) | Total Time 0.00(0.00)\n",
      "Iter 2464 | Time 78.1108(79.9189) | Bit/dim 3.4954(3.4883) | Xent 0.0000(0.0000) | Loss 9.0108(9.6311) | Error 0.0000(0.0000) Steps 700(715.26) | Grad Norm 1.8824(1.8915) | Total Time 0.00(0.00)\n",
      "Iter 2465 | Time 83.9594(80.0401) | Bit/dim 3.4906(3.4884) | Xent 0.0000(0.0000) | Loss 8.9572(9.6109) | Error 0.0000(0.0000) Steps 706(714.98) | Grad Norm 2.2973(1.9037) | Total Time 0.00(0.00)\n",
      "Iter 2466 | Time 79.0578(80.0106) | Bit/dim 3.4860(3.4883) | Xent 0.0000(0.0000) | Loss 8.7565(9.5853) | Error 0.0000(0.0000) Steps 694(714.35) | Grad Norm 2.2858(1.9151) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 25.6767, Epoch Time 518.0657(511.3192), Bit/dim 3.4852(best: 3.4869), Xent 0.0000, Loss 3.4852, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2467 | Time 81.4104(80.0526) | Bit/dim 3.4780(3.4880) | Xent 0.0000(0.0000) | Loss 13.0045(9.6879) | Error 0.0000(0.0000) Steps 712(714.28) | Grad Norm 2.3233(1.9274) | Total Time 0.00(0.00)\n",
      "Iter 2468 | Time 85.5012(80.2161) | Bit/dim 3.4967(3.4883) | Xent 0.0000(0.0000) | Loss 8.9533(9.6658) | Error 0.0000(0.0000) Steps 742(715.11) | Grad Norm 1.4433(1.9128) | Total Time 0.00(0.00)\n",
      "Iter 2469 | Time 78.8070(80.1738) | Bit/dim 3.4827(3.4881) | Xent 0.0000(0.0000) | Loss 8.7544(9.6385) | Error 0.0000(0.0000) Steps 706(714.84) | Grad Norm 2.4135(1.9279) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 82.5837(80.2461) | Bit/dim 3.4797(3.4879) | Xent 0.0000(0.0000) | Loss 8.9206(9.6169) | Error 0.0000(0.0000) Steps 730(715.29) | Grad Norm 3.6772(1.9803) | Total Time 0.00(0.00)\n",
      "Iter 2471 | Time 81.0991(80.2717) | Bit/dim 3.4979(3.4882) | Xent 0.0000(0.0000) | Loss 8.7113(9.5898) | Error 0.0000(0.0000) Steps 694(714.65) | Grad Norm 3.4257(2.0237) | Total Time 0.00(0.00)\n",
      "Iter 2472 | Time 83.0949(80.3564) | Bit/dim 3.4928(3.4883) | Xent 0.0000(0.0000) | Loss 9.0450(9.5734) | Error 0.0000(0.0000) Steps 730(715.11) | Grad Norm 2.6913(2.0437) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 24.8354, Epoch Time 533.0441(511.9710), Bit/dim 3.4830(best: 3.4852), Xent 0.0000, Loss 3.4830, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2473 | Time 76.0320(80.2266) | Bit/dim 3.4912(3.4884) | Xent 0.0000(0.0000) | Loss 12.9598(9.6750) | Error 0.0000(0.0000) Steps 694(714.48) | Grad Norm 1.9001(2.0394) | Total Time 0.00(0.00)\n",
      "Iter 2474 | Time 76.4663(80.1138) | Bit/dim 3.4940(3.4886) | Xent 0.0000(0.0000) | Loss 8.8602(9.6506) | Error 0.0000(0.0000) Steps 694(713.87) | Grad Norm 1.3475(2.0187) | Total Time 0.00(0.00)\n",
      "Iter 2475 | Time 85.0011(80.2605) | Bit/dim 3.4791(3.4883) | Xent 0.0000(0.0000) | Loss 8.9423(9.6293) | Error 0.0000(0.0000) Steps 730(714.35) | Grad Norm 1.2420(1.9954) | Total Time 0.00(0.00)\n",
      "Iter 2476 | Time 77.0542(80.1643) | Bit/dim 3.4959(3.4885) | Xent 0.0000(0.0000) | Loss 9.0076(9.6107) | Error 0.0000(0.0000) Steps 706(714.10) | Grad Norm 1.5837(1.9830) | Total Time 0.00(0.00)\n",
      "Iter 2477 | Time 79.4115(80.1417) | Bit/dim 3.4970(3.4888) | Xent 0.0000(0.0000) | Loss 8.9922(9.5921) | Error 0.0000(0.0000) Steps 718(714.22) | Grad Norm 1.8754(1.9798) | Total Time 0.00(0.00)\n",
      "Iter 2478 | Time 79.9014(80.1345) | Bit/dim 3.4800(3.4885) | Xent 0.0000(0.0000) | Loss 8.8572(9.5701) | Error 0.0000(0.0000) Steps 712(714.15) | Grad Norm 2.6593(2.0002) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 25.2975, Epoch Time 514.9103(512.0592), Bit/dim 3.4955(best: 3.4830), Xent 0.0000, Loss 3.4955, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2479 | Time 79.6513(80.1200) | Bit/dim 3.4904(3.4885) | Xent 0.0000(0.0000) | Loss 13.5629(9.6899) | Error 0.0000(0.0000) Steps 724(714.45) | Grad Norm 3.2363(2.0373) | Total Time 0.00(0.00)\n",
      "Iter 2480 | Time 77.7682(80.0494) | Bit/dim 3.4901(3.4886) | Xent 0.0000(0.0000) | Loss 8.8886(9.6658) | Error 0.0000(0.0000) Steps 712(714.37) | Grad Norm 3.3895(2.0778) | Total Time 0.00(0.00)\n",
      "Iter 2481 | Time 78.8605(80.0138) | Bit/dim 3.4835(3.4884) | Xent 0.0000(0.0000) | Loss 8.8459(9.6412) | Error 0.0000(0.0000) Steps 724(714.66) | Grad Norm 3.2210(2.1121) | Total Time 0.00(0.00)\n",
      "Iter 2482 | Time 80.1327(80.0173) | Bit/dim 3.4893(3.4885) | Xent 0.0000(0.0000) | Loss 8.8034(9.6161) | Error 0.0000(0.0000) Steps 712(714.58) | Grad Norm 2.5629(2.1256) | Total Time 0.00(0.00)\n",
      "Iter 2483 | Time 79.5812(80.0042) | Bit/dim 3.4943(3.4886) | Xent 0.0000(0.0000) | Loss 8.5881(9.5852) | Error 0.0000(0.0000) Steps 694(713.96) | Grad Norm 1.4817(2.1063) | Total Time 0.00(0.00)\n",
      "Iter 2484 | Time 72.6548(79.7838) | Bit/dim 3.4959(3.4889) | Xent 0.0000(0.0000) | Loss 8.5356(9.5538) | Error 0.0000(0.0000) Steps 688(713.18) | Grad Norm 1.2328(2.0801) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 25.3282, Epoch Time 510.1698(512.0025), Bit/dim 3.4919(best: 3.4830), Xent 0.0000, Loss 3.4919, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2485 | Time 73.9649(79.6092) | Bit/dim 3.4943(3.4890) | Xent 0.0000(0.0000) | Loss 13.4489(9.6706) | Error 0.0000(0.0000) Steps 712(713.15) | Grad Norm 2.2172(2.0842) | Total Time 0.00(0.00)\n",
      "Iter 2486 | Time 82.1257(79.6847) | Bit/dim 3.4822(3.4888) | Xent 0.0000(0.0000) | Loss 8.7317(9.6424) | Error 0.0000(0.0000) Steps 724(713.47) | Grad Norm 2.5653(2.0987) | Total Time 0.00(0.00)\n",
      "Iter 2487 | Time 81.5387(79.7403) | Bit/dim 3.4820(3.4886) | Xent 0.0000(0.0000) | Loss 8.6827(9.6137) | Error 0.0000(0.0000) Steps 718(713.61) | Grad Norm 2.7612(2.1185) | Total Time 0.00(0.00)\n",
      "Iter 2488 | Time 76.7057(79.6493) | Bit/dim 3.4772(3.4883) | Xent 0.0000(0.0000) | Loss 8.7869(9.5888) | Error 0.0000(0.0000) Steps 712(713.56) | Grad Norm 2.6327(2.1340) | Total Time 0.00(0.00)\n",
      "Iter 2489 | Time 79.3934(79.6416) | Bit/dim 3.4966(3.4885) | Xent 0.0000(0.0000) | Loss 8.7978(9.5651) | Error 0.0000(0.0000) Steps 706(713.34) | Grad Norm 2.0300(2.1308) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 81.8149(79.7068) | Bit/dim 3.5026(3.4889) | Xent 0.0000(0.0000) | Loss 8.7359(9.5402) | Error 0.0000(0.0000) Steps 700(712.93) | Grad Norm 1.2638(2.1048) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 25.9480, Epoch Time 517.2493(512.1599), Bit/dim 3.4940(best: 3.4830), Xent 0.0000, Loss 3.4940, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2491 | Time 82.1776(79.7809) | Bit/dim 3.4733(3.4885) | Xent 0.0000(0.0000) | Loss 13.5236(9.6597) | Error 0.0000(0.0000) Steps 712(712.91) | Grad Norm 0.7547(2.0643) | Total Time 0.00(0.00)\n",
      "Iter 2492 | Time 81.1794(79.8229) | Bit/dim 3.4868(3.4884) | Xent 0.0000(0.0000) | Loss 9.0106(9.6403) | Error 0.0000(0.0000) Steps 730(713.42) | Grad Norm 0.6704(2.0225) | Total Time 0.00(0.00)\n",
      "Iter 2493 | Time 73.6869(79.6388) | Bit/dim 3.4956(3.4886) | Xent 0.0000(0.0000) | Loss 8.6450(9.6104) | Error 0.0000(0.0000) Steps 706(713.20) | Grad Norm 1.0989(1.9948) | Total Time 0.00(0.00)\n",
      "Iter 2494 | Time 80.0442(79.6510) | Bit/dim 3.4758(3.4883) | Xent 0.0000(0.0000) | Loss 8.7184(9.5836) | Error 0.0000(0.0000) Steps 718(713.34) | Grad Norm 1.4881(1.9796) | Total Time 0.00(0.00)\n",
      "Iter 2495 | Time 82.2066(79.7276) | Bit/dim 3.4960(3.4885) | Xent 0.0000(0.0000) | Loss 8.7520(9.5587) | Error 0.0000(0.0000) Steps 718(713.48) | Grad Norm 1.7975(1.9741) | Total Time 0.00(0.00)\n",
      "Iter 2496 | Time 75.1016(79.5888) | Bit/dim 3.4896(3.4885) | Xent 0.0000(0.0000) | Loss 8.8292(9.5368) | Error 0.0000(0.0000) Steps 706(713.26) | Grad Norm 2.0752(1.9772) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 24.9710, Epoch Time 515.5389(512.2613), Bit/dim 3.4890(best: 3.4830), Xent 0.0000, Loss 3.4890, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2497 | Time 83.2428(79.6985) | Bit/dim 3.4891(3.4885) | Xent 0.0000(0.0000) | Loss 13.3909(9.6524) | Error 0.0000(0.0000) Steps 712(713.22) | Grad Norm 2.2014(1.9839) | Total Time 0.00(0.00)\n",
      "Iter 2498 | Time 80.2092(79.7138) | Bit/dim 3.4777(3.4882) | Xent 0.0000(0.0000) | Loss 8.9290(9.6307) | Error 0.0000(0.0000) Steps 730(713.72) | Grad Norm 2.1052(1.9875) | Total Time 0.00(0.00)\n",
      "Iter 2499 | Time 79.6941(79.7132) | Bit/dim 3.4789(3.4879) | Xent 0.0000(0.0000) | Loss 8.8885(9.6085) | Error 0.0000(0.0000) Steps 718(713.85) | Grad Norm 2.0296(1.9888) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 74.2694(79.5499) | Bit/dim 3.4901(3.4880) | Xent 0.0000(0.0000) | Loss 8.9134(9.5876) | Error 0.0000(0.0000) Steps 700(713.44) | Grad Norm 1.9580(1.9879) | Total Time 0.00(0.00)\n",
      "Iter 2501 | Time 80.7126(79.5848) | Bit/dim 3.4958(3.4882) | Xent 0.0000(0.0000) | Loss 8.8836(9.5665) | Error 0.0000(0.0000) Steps 718(713.57) | Grad Norm 2.2178(1.9948) | Total Time 0.00(0.00)\n",
      "Iter 2502 | Time 80.6260(79.6160) | Bit/dim 3.4937(3.4884) | Xent 0.0000(0.0000) | Loss 8.8966(9.5464) | Error 0.0000(0.0000) Steps 730(714.06) | Grad Norm 2.7690(2.0180) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 25.3693, Epoch Time 519.8355(512.4885), Bit/dim 3.4887(best: 3.4830), Xent 0.0000, Loss 3.4887, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2503 | Time 78.9183(79.5951) | Bit/dim 3.4824(3.4882) | Xent 0.0000(0.0000) | Loss 13.3964(9.6619) | Error 0.0000(0.0000) Steps 718(714.18) | Grad Norm 3.2179(2.0540) | Total Time 0.00(0.00)\n",
      "Iter 2504 | Time 80.4984(79.6222) | Bit/dim 3.5007(3.4886) | Xent 0.0000(0.0000) | Loss 8.8168(9.6365) | Error 0.0000(0.0000) Steps 718(714.30) | Grad Norm 3.5009(2.0974) | Total Time 0.00(0.00)\n",
      "Iter 2505 | Time 78.8241(79.5982) | Bit/dim 3.4794(3.4883) | Xent 0.0000(0.0000) | Loss 8.9010(9.6145) | Error 0.0000(0.0000) Steps 730(714.77) | Grad Norm 3.2728(2.1327) | Total Time 0.00(0.00)\n",
      "Iter 2506 | Time 80.3920(79.6220) | Bit/dim 3.4851(3.4882) | Xent 0.0000(0.0000) | Loss 8.5043(9.5812) | Error 0.0000(0.0000) Steps 724(715.05) | Grad Norm 2.6666(2.1487) | Total Time 0.00(0.00)\n",
      "Iter 2507 | Time 77.3902(79.5551) | Bit/dim 3.4957(3.4884) | Xent 0.0000(0.0000) | Loss 8.7662(9.5567) | Error 0.0000(0.0000) Steps 718(715.13) | Grad Norm 1.8617(2.1401) | Total Time 0.00(0.00)\n",
      "Iter 2508 | Time 74.0591(79.3902) | Bit/dim 3.4944(3.4886) | Xent 0.0000(0.0000) | Loss 8.7624(9.5329) | Error 0.0000(0.0000) Steps 700(714.68) | Grad Norm 1.4519(2.1194) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 25.7955, Epoch Time 513.9610(512.5327), Bit/dim 3.4900(best: 3.4830), Xent 0.0000, Loss 3.4900, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2509 | Time 78.8796(79.3749) | Bit/dim 3.4832(3.4885) | Xent 0.0000(0.0000) | Loss 13.7551(9.6596) | Error 0.0000(0.0000) Steps 730(715.14) | Grad Norm 1.9799(2.1152) | Total Time 0.00(0.00)\n",
      "Iter 2510 | Time 79.9791(79.3930) | Bit/dim 3.4781(3.4881) | Xent 0.0000(0.0000) | Loss 8.8544(9.6354) | Error 0.0000(0.0000) Steps 712(715.05) | Grad Norm 1.9128(2.1092) | Total Time 0.00(0.00)\n",
      "Iter 2511 | Time 75.2905(79.2699) | Bit/dim 3.4991(3.4885) | Xent 0.0000(0.0000) | Loss 8.6231(9.6050) | Error 0.0000(0.0000) Steps 694(714.41) | Grad Norm 1.8558(2.1016) | Total Time 0.00(0.00)\n",
      "Iter 2512 | Time 82.8336(79.3768) | Bit/dim 3.4892(3.4885) | Xent 0.0000(0.0000) | Loss 8.9534(9.5855) | Error 0.0000(0.0000) Steps 742(715.24) | Grad Norm 1.7642(2.0914) | Total Time 0.00(0.00)\n",
      "Iter 2513 | Time 76.9473(79.3040) | Bit/dim 3.4777(3.4882) | Xent 0.0000(0.0000) | Loss 8.7503(9.5604) | Error 0.0000(0.0000) Steps 718(715.32) | Grad Norm 1.8740(2.0849) | Total Time 0.00(0.00)\n",
      "Iter 2514 | Time 82.6812(79.4053) | Bit/dim 3.4862(3.4881) | Xent 0.0000(0.0000) | Loss 8.7337(9.5356) | Error 0.0000(0.0000) Steps 712(715.22) | Grad Norm 2.5317(2.0983) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 25.6387, Epoch Time 517.9422(512.6949), Bit/dim 3.4915(best: 3.4830), Xent 0.0000, Loss 3.4915, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2515 | Time 78.4456(79.3765) | Bit/dim 3.4881(3.4881) | Xent 0.0000(0.0000) | Loss 13.6325(9.6585) | Error 0.0000(0.0000) Steps 724(715.49) | Grad Norm 3.5300(2.1413) | Total Time 0.00(0.00)\n",
      "Iter 2516 | Time 86.1841(79.5807) | Bit/dim 3.4944(3.4883) | Xent 0.0000(0.0000) | Loss 8.8416(9.6340) | Error 0.0000(0.0000) Steps 736(716.10) | Grad Norm 3.8337(2.1920) | Total Time 0.00(0.00)\n",
      "Iter 2517 | Time 79.9339(79.5913) | Bit/dim 3.4774(3.4880) | Xent 0.0000(0.0000) | Loss 8.8949(9.6119) | Error 0.0000(0.0000) Steps 712(715.98) | Grad Norm 3.2276(2.2231) | Total Time 0.00(0.00)\n",
      "Iter 2518 | Time 82.7462(79.6860) | Bit/dim 3.4818(3.4878) | Xent 0.0000(0.0000) | Loss 8.8023(9.5876) | Error 0.0000(0.0000) Steps 712(715.86) | Grad Norm 2.1459(2.2208) | Total Time 0.00(0.00)\n",
      "Iter 2519 | Time 79.6573(79.6851) | Bit/dim 3.5005(3.4882) | Xent 0.0000(0.0000) | Loss 8.6626(9.5598) | Error 0.0000(0.0000) Steps 724(716.11) | Grad Norm 1.1903(2.1899) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 80.5317(79.7105) | Bit/dim 3.4890(3.4882) | Xent 0.0000(0.0000) | Loss 8.9235(9.5407) | Error 0.0000(0.0000) Steps 718(716.16) | Grad Norm 0.6179(2.1427) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 25.4520, Epoch Time 531.0679(513.2461), Bit/dim 3.4887(best: 3.4830), Xent 0.0000, Loss 3.4887, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2521 | Time 86.2569(79.9069) | Bit/dim 3.4799(3.4879) | Xent 0.0000(0.0000) | Loss 13.6063(9.6627) | Error 0.0000(0.0000) Steps 748(717.12) | Grad Norm 1.4316(2.1214) | Total Time 0.00(0.00)\n",
      "Iter 2522 | Time 82.0144(79.9701) | Bit/dim 3.4909(3.4880) | Xent 0.0000(0.0000) | Loss 8.7953(9.6367) | Error 0.0000(0.0000) Steps 736(717.68) | Grad Norm 2.2139(2.1242) | Total Time 0.00(0.00)\n",
      "Iter 2523 | Time 76.2213(79.8576) | Bit/dim 3.4916(3.4881) | Xent 0.0000(0.0000) | Loss 8.8719(9.6137) | Error 0.0000(0.0000) Steps 736(718.23) | Grad Norm 3.2585(2.1582) | Total Time 0.00(0.00)\n",
      "Iter 2524 | Time 79.5122(79.8473) | Bit/dim 3.4892(3.4882) | Xent 0.0000(0.0000) | Loss 8.7521(9.5879) | Error 0.0000(0.0000) Steps 754(719.31) | Grad Norm 3.9157(2.2109) | Total Time 0.00(0.00)\n",
      "Iter 2525 | Time 79.6038(79.8400) | Bit/dim 3.4852(3.4881) | Xent 0.0000(0.0000) | Loss 9.0635(9.5722) | Error 0.0000(0.0000) Steps 748(720.17) | Grad Norm 3.6736(2.2548) | Total Time 0.00(0.00)\n",
      "Iter 2526 | Time 83.5521(79.9513) | Bit/dim 3.4845(3.4880) | Xent 0.0000(0.0000) | Loss 8.6899(9.5457) | Error 0.0000(0.0000) Steps 718(720.10) | Grad Norm 2.7262(2.2689) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 25.2266, Epoch Time 528.5623(513.7056), Bit/dim 3.4894(best: 3.4830), Xent 0.0000, Loss 3.4894, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2527 | Time 79.0730(79.9250) | Bit/dim 3.4841(3.4879) | Xent 0.0000(0.0000) | Loss 13.6773(9.6696) | Error 0.0000(0.0000) Steps 730(720.40) | Grad Norm 1.6683(2.2509) | Total Time 0.00(0.00)\n",
      "Iter 2528 | Time 76.3380(79.8174) | Bit/dim 3.4755(3.4875) | Xent 0.0000(0.0000) | Loss 8.6912(9.6403) | Error 0.0000(0.0000) Steps 706(719.97) | Grad Norm 1.6672(2.2334) | Total Time 0.00(0.00)\n",
      "Iter 2529 | Time 74.1679(79.6479) | Bit/dim 3.4952(3.4877) | Xent 0.0000(0.0000) | Loss 8.7627(9.6140) | Error 0.0000(0.0000) Steps 706(719.55) | Grad Norm 2.2288(2.2333) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 82.0137(79.7189) | Bit/dim 3.4888(3.4878) | Xent 0.0000(0.0000) | Loss 8.9821(9.5950) | Error 0.0000(0.0000) Steps 730(719.86) | Grad Norm 2.7853(2.2498) | Total Time 0.00(0.00)\n",
      "Iter 2531 | Time 80.7394(79.7495) | Bit/dim 3.4841(3.4876) | Xent 0.0000(0.0000) | Loss 8.9006(9.5742) | Error 0.0000(0.0000) Steps 730(720.17) | Grad Norm 3.1157(2.2758) | Total Time 0.00(0.00)\n",
      "Iter 2532 | Time 81.4216(79.7997) | Bit/dim 3.5004(3.4880) | Xent 0.0000(0.0000) | Loss 8.8192(9.5515) | Error 0.0000(0.0000) Steps 748(721.00) | Grad Norm 3.0474(2.2990) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 25.9047, Epoch Time 515.4946(513.7593), Bit/dim 3.4904(best: 3.4830), Xent 0.0000, Loss 3.4904, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2533 | Time 76.4877(79.7003) | Bit/dim 3.4890(3.4881) | Xent 0.0000(0.0000) | Loss 13.2356(9.6620) | Error 0.0000(0.0000) Steps 712(720.73) | Grad Norm 2.5130(2.3054) | Total Time 0.00(0.00)\n",
      "Iter 2534 | Time 83.0855(79.8019) | Bit/dim 3.4807(3.4878) | Xent 0.0000(0.0000) | Loss 8.7999(9.6362) | Error 0.0000(0.0000) Steps 730(721.01) | Grad Norm 2.0829(2.2987) | Total Time 0.00(0.00)\n",
      "Iter 2535 | Time 77.7706(79.7409) | Bit/dim 3.4798(3.4876) | Xent 0.0000(0.0000) | Loss 8.8075(9.6113) | Error 0.0000(0.0000) Steps 712(720.74) | Grad Norm 1.8505(2.2853) | Total Time 0.00(0.00)\n",
      "Iter 2536 | Time 80.0582(79.7504) | Bit/dim 3.4801(3.4874) | Xent 0.0000(0.0000) | Loss 8.4688(9.5770) | Error 0.0000(0.0000) Steps 718(720.66) | Grad Norm 2.0520(2.2783) | Total Time 0.00(0.00)\n",
      "Iter 2537 | Time 78.1510(79.7024) | Bit/dim 3.4941(3.4876) | Xent 0.0000(0.0000) | Loss 8.6266(9.5485) | Error 0.0000(0.0000) Steps 724(720.76) | Grad Norm 2.2580(2.2777) | Total Time 0.00(0.00)\n",
      "Iter 2538 | Time 83.4351(79.8144) | Bit/dim 3.4888(3.4876) | Xent 0.0000(0.0000) | Loss 8.9604(9.5309) | Error 0.0000(0.0000) Steps 748(721.57) | Grad Norm 2.2231(2.2760) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 25.9061, Epoch Time 520.7328(513.9685), Bit/dim 3.4859(best: 3.4830), Xent 0.0000, Loss 3.4859, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2539 | Time 81.3816(79.8614) | Bit/dim 3.4881(3.4876) | Xent 0.0000(0.0000) | Loss 13.7251(9.6567) | Error 0.0000(0.0000) Steps 730(721.83) | Grad Norm 2.2376(2.2749) | Total Time 0.00(0.00)\n",
      "Iter 2540 | Time 78.4447(79.8189) | Bit/dim 3.4788(3.4874) | Xent 0.0000(0.0000) | Loss 9.0000(9.6370) | Error 0.0000(0.0000) Steps 706(721.35) | Grad Norm 2.1959(2.2725) | Total Time 0.00(0.00)\n",
      "Iter 2541 | Time 75.1125(79.6777) | Bit/dim 3.4880(3.4874) | Xent 0.0000(0.0000) | Loss 8.8579(9.6136) | Error 0.0000(0.0000) Steps 694(720.53) | Grad Norm 2.4295(2.2772) | Total Time 0.00(0.00)\n",
      "Iter 2542 | Time 82.0535(79.7490) | Bit/dim 3.4816(3.4872) | Xent 0.0000(0.0000) | Loss 8.8029(9.5893) | Error 0.0000(0.0000) Steps 724(720.64) | Grad Norm 2.8631(2.2948) | Total Time 0.00(0.00)\n",
      "Iter 2543 | Time 82.9908(79.8463) | Bit/dim 3.4927(3.4874) | Xent 0.0000(0.0000) | Loss 8.9475(9.5701) | Error 0.0000(0.0000) Steps 730(720.92) | Grad Norm 3.0552(2.3176) | Total Time 0.00(0.00)\n",
      "Iter 2544 | Time 82.1168(79.9144) | Bit/dim 3.4886(3.4874) | Xent 0.0000(0.0000) | Loss 8.8565(9.5486) | Error 0.0000(0.0000) Steps 724(721.01) | Grad Norm 3.2897(2.3468) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 25.8863, Epoch Time 523.8361(514.2645), Bit/dim 3.4971(best: 3.4830), Xent 0.0000, Loss 3.4971, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2545 | Time 82.2518(79.9845) | Bit/dim 3.4930(3.4876) | Xent 0.0000(0.0000) | Loss 13.8509(9.6777) | Error 0.0000(0.0000) Steps 736(721.46) | Grad Norm 3.4576(2.3801) | Total Time 0.00(0.00)\n",
      "Iter 2546 | Time 82.7493(80.0675) | Bit/dim 3.4786(3.4873) | Xent 0.0000(0.0000) | Loss 8.6293(9.6463) | Error 0.0000(0.0000) Steps 700(720.81) | Grad Norm 3.1434(2.4030) | Total Time 0.00(0.00)\n",
      "Iter 2547 | Time 81.9153(80.1229) | Bit/dim 3.4854(3.4872) | Xent 0.0000(0.0000) | Loss 8.9342(9.6249) | Error 0.0000(0.0000) Steps 730(721.09) | Grad Norm 2.6959(2.4118) | Total Time 0.00(0.00)\n",
      "Iter 2548 | Time 77.6230(80.0479) | Bit/dim 3.4767(3.4869) | Xent 0.0000(0.0000) | Loss 8.7380(9.5983) | Error 0.0000(0.0000) Steps 688(720.10) | Grad Norm 2.6241(2.4181) | Total Time 0.00(0.00)\n",
      "Iter 2549 | Time 80.5189(80.0620) | Bit/dim 3.4911(3.4871) | Xent 0.0000(0.0000) | Loss 9.0374(9.5815) | Error 0.0000(0.0000) Steps 724(720.21) | Grad Norm 2.9060(2.4328) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 81.1930(80.0960) | Bit/dim 3.4845(3.4870) | Xent 0.0000(0.0000) | Loss 8.9997(9.5640) | Error 0.0000(0.0000) Steps 736(720.69) | Grad Norm 3.3460(2.4602) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 25.4798, Epoch Time 527.6311(514.6655), Bit/dim 3.4879(best: 3.4830), Xent 0.0000, Loss 3.4879, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2551 | Time 81.5293(80.1390) | Bit/dim 3.4963(3.4873) | Xent 0.0000(0.0000) | Loss 13.3662(9.6781) | Error 0.0000(0.0000) Steps 724(720.79) | Grad Norm 3.3285(2.4862) | Total Time 0.00(0.00)\n",
      "Iter 2552 | Time 83.3682(80.2358) | Bit/dim 3.4902(3.4873) | Xent 0.0000(0.0000) | Loss 8.8582(9.6535) | Error 0.0000(0.0000) Steps 730(721.06) | Grad Norm 2.8401(2.4968) | Total Time 0.00(0.00)\n",
      "Iter 2553 | Time 75.5667(80.0958) | Bit/dim 3.4855(3.4873) | Xent 0.0000(0.0000) | Loss 8.6777(9.6242) | Error 0.0000(0.0000) Steps 700(720.43) | Grad Norm 2.3105(2.4913) | Total Time 0.00(0.00)\n",
      "Iter 2554 | Time 86.4864(80.2875) | Bit/dim 3.4862(3.4873) | Xent 0.0000(0.0000) | Loss 8.8797(9.6019) | Error 0.0000(0.0000) Steps 736(720.90) | Grad Norm 1.6648(2.4665) | Total Time 0.00(0.00)\n",
      "Iter 2555 | Time 75.4294(80.1417) | Bit/dim 3.4829(3.4871) | Xent 0.0000(0.0000) | Loss 8.9187(9.5814) | Error 0.0000(0.0000) Steps 706(720.45) | Grad Norm 1.1078(2.4257) | Total Time 0.00(0.00)\n",
      "Iter 2556 | Time 73.0381(79.9286) | Bit/dim 3.4747(3.4868) | Xent 0.0000(0.0000) | Loss 8.7714(9.5571) | Error 0.0000(0.0000) Steps 688(719.48) | Grad Norm 0.9131(2.3803) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 25.6037, Epoch Time 516.7556(514.7282), Bit/dim 3.4872(best: 3.4830), Xent 0.0000, Loss 3.4872, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2557 | Time 80.1537(79.9354) | Bit/dim 3.4897(3.4868) | Xent 0.0000(0.0000) | Loss 13.6579(9.6801) | Error 0.0000(0.0000) Steps 730(719.79) | Grad Norm 0.7149(2.3304) | Total Time 0.00(0.00)\n",
      "Iter 2558 | Time 80.5259(79.9531) | Bit/dim 3.4850(3.4868) | Xent 0.0000(0.0000) | Loss 8.7475(9.6521) | Error 0.0000(0.0000) Steps 724(719.92) | Grad Norm 0.4987(2.2754) | Total Time 0.00(0.00)\n",
      "Iter 2559 | Time 82.0430(80.0158) | Bit/dim 3.4938(3.4870) | Xent 0.0000(0.0000) | Loss 8.8152(9.6270) | Error 0.0000(0.0000) Steps 730(720.22) | Grad Norm 0.5732(2.2243) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 80.0444(80.0166) | Bit/dim 3.4812(3.4868) | Xent 0.0000(0.0000) | Loss 8.8460(9.6036) | Error 0.0000(0.0000) Steps 712(719.98) | Grad Norm 0.9210(2.1852) | Total Time 0.00(0.00)\n",
      "Iter 2561 | Time 82.8931(80.1029) | Bit/dim 3.4805(3.4866) | Xent 0.0000(0.0000) | Loss 9.0159(9.5860) | Error 0.0000(0.0000) Steps 730(720.28) | Grad Norm 1.4200(2.1623) | Total Time 0.00(0.00)\n",
      "Iter 2562 | Time 76.6861(80.0004) | Bit/dim 3.4833(3.4865) | Xent 0.0000(0.0000) | Loss 8.7287(9.5602) | Error 0.0000(0.0000) Steps 706(719.85) | Grad Norm 2.1250(2.1612) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 25.7790, Epoch Time 524.0463(515.0078), Bit/dim 3.4883(best: 3.4830), Xent 0.0000, Loss 3.4883, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2563 | Time 82.2768(80.0687) | Bit/dim 3.4912(3.4867) | Xent 0.0000(0.0000) | Loss 13.5049(9.6786) | Error 0.0000(0.0000) Steps 730(720.15) | Grad Norm 2.7256(2.1781) | Total Time 0.00(0.00)\n",
      "Iter 2564 | Time 81.8729(80.1229) | Bit/dim 3.4819(3.4865) | Xent 0.0000(0.0000) | Loss 8.9428(9.6565) | Error 0.0000(0.0000) Steps 748(720.99) | Grad Norm 3.4367(2.2159) | Total Time 0.00(0.00)\n",
      "Iter 2565 | Time 89.0698(80.3913) | Bit/dim 3.4854(3.4865) | Xent 0.0000(0.0000) | Loss 8.9441(9.6351) | Error 0.0000(0.0000) Steps 742(721.62) | Grad Norm 3.7763(2.2627) | Total Time 0.00(0.00)\n",
      "Iter 2566 | Time 80.2933(80.3883) | Bit/dim 3.4869(3.4865) | Xent 0.0000(0.0000) | Loss 8.9181(9.6136) | Error 0.0000(0.0000) Steps 736(722.05) | Grad Norm 3.5872(2.3024) | Total Time 0.00(0.00)\n",
      "Iter 2567 | Time 81.3309(80.4166) | Bit/dim 3.4883(3.4866) | Xent 0.0000(0.0000) | Loss 8.7409(9.5874) | Error 0.0000(0.0000) Steps 700(721.39) | Grad Norm 3.2950(2.3322) | Total Time 0.00(0.00)\n",
      "Iter 2568 | Time 87.0448(80.6154) | Bit/dim 3.4906(3.4867) | Xent 0.0000(0.0000) | Loss 8.9115(9.5672) | Error 0.0000(0.0000) Steps 730(721.65) | Grad Norm 3.2488(2.3597) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 25.5856, Epoch Time 543.0590(515.8493), Bit/dim 3.4896(best: 3.4830), Xent 0.0000, Loss 3.4896, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2569 | Time 82.8235(80.6817) | Bit/dim 3.4915(3.4868) | Xent 0.0000(0.0000) | Loss 13.4525(9.6837) | Error 0.0000(0.0000) Steps 748(722.44) | Grad Norm 3.5404(2.3951) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 81.1078(80.6945) | Bit/dim 3.4868(3.4868) | Xent 0.0000(0.0000) | Loss 8.8071(9.6574) | Error 0.0000(0.0000) Steps 718(722.30) | Grad Norm 3.6538(2.4329) | Total Time 0.00(0.00)\n",
      "Iter 2571 | Time 82.2679(80.7417) | Bit/dim 3.4939(3.4870) | Xent 0.0000(0.0000) | Loss 8.9064(9.6349) | Error 0.0000(0.0000) Steps 724(722.36) | Grad Norm 3.1514(2.4544) | Total Time 0.00(0.00)\n",
      "Iter 2572 | Time 83.1107(80.8127) | Bit/dim 3.4798(3.4868) | Xent 0.0000(0.0000) | Loss 8.8149(9.6103) | Error 0.0000(0.0000) Steps 748(723.12) | Grad Norm 2.6383(2.4599) | Total Time 0.00(0.00)\n",
      "Iter 2573 | Time 80.2197(80.7950) | Bit/dim 3.4845(3.4868) | Xent 0.0000(0.0000) | Loss 8.8552(9.5876) | Error 0.0000(0.0000) Steps 730(723.33) | Grad Norm 2.1698(2.4512) | Total Time 0.00(0.00)\n",
      "Iter 2574 | Time 83.5667(80.8781) | Bit/dim 3.4751(3.4864) | Xent 0.0000(0.0000) | Loss 8.7988(9.5640) | Error 0.0000(0.0000) Steps 730(723.53) | Grad Norm 1.7954(2.4316) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 26.0244, Epoch Time 535.0431(516.4251), Bit/dim 3.4863(best: 3.4830), Xent 0.0000, Loss 3.4863, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2575 | Time 88.3960(81.1036) | Bit/dim 3.4821(3.4863) | Xent 0.0000(0.0000) | Loss 13.7715(9.6902) | Error 0.0000(0.0000) Steps 748(724.27) | Grad Norm 1.8729(2.4148) | Total Time 0.00(0.00)\n",
      "Iter 2576 | Time 82.1840(81.1361) | Bit/dim 3.4855(3.4863) | Xent 0.0000(0.0000) | Loss 8.8498(9.6650) | Error 0.0000(0.0000) Steps 748(724.98) | Grad Norm 1.8027(2.3964) | Total Time 0.00(0.00)\n",
      "Iter 2577 | Time 78.1720(81.0471) | Bit/dim 3.4924(3.4864) | Xent 0.0000(0.0000) | Loss 8.7378(9.6372) | Error 0.0000(0.0000) Steps 706(724.41) | Grad Norm 1.4800(2.3689) | Total Time 0.00(0.00)\n",
      "Iter 2578 | Time 79.3086(80.9950) | Bit/dim 3.4735(3.4860) | Xent 0.0000(0.0000) | Loss 8.7437(9.6104) | Error 0.0000(0.0000) Steps 706(723.86) | Grad Norm 1.4668(2.3419) | Total Time 0.00(0.00)\n",
      "Iter 2579 | Time 75.6424(80.8344) | Bit/dim 3.4835(3.4860) | Xent 0.0000(0.0000) | Loss 8.9049(9.5892) | Error 0.0000(0.0000) Steps 730(724.04) | Grad Norm 1.6455(2.3210) | Total Time 0.00(0.00)\n",
      "Iter 2580 | Time 81.0555(80.8410) | Bit/dim 3.4859(3.4860) | Xent 0.0000(0.0000) | Loss 8.5871(9.5591) | Error 0.0000(0.0000) Steps 712(723.68) | Grad Norm 2.1250(2.3151) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 25.6664, Epoch Time 526.1109(516.7157), Bit/dim 3.4889(best: 3.4830), Xent 0.0000, Loss 3.4889, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2581 | Time 83.5595(80.9226) | Bit/dim 3.4829(3.4859) | Xent 0.0000(0.0000) | Loss 13.1925(9.6681) | Error 0.0000(0.0000) Steps 724(723.69) | Grad Norm 2.3238(2.3154) | Total Time 0.00(0.00)\n",
      "Iter 2582 | Time 84.4885(81.0296) | Bit/dim 3.4897(3.4860) | Xent 0.0000(0.0000) | Loss 8.9509(9.6466) | Error 0.0000(0.0000) Steps 724(723.70) | Grad Norm 2.7040(2.3270) | Total Time 0.00(0.00)\n",
      "Iter 2583 | Time 81.8308(81.0536) | Bit/dim 3.4839(3.4859) | Xent 0.0000(0.0000) | Loss 8.6423(9.6165) | Error 0.0000(0.0000) Steps 742(724.25) | Grad Norm 2.9911(2.3470) | Total Time 0.00(0.00)\n",
      "Iter 2584 | Time 81.8275(81.0768) | Bit/dim 3.4799(3.4857) | Xent 0.0000(0.0000) | Loss 8.5420(9.5843) | Error 0.0000(0.0000) Steps 712(723.88) | Grad Norm 2.7650(2.3595) | Total Time 0.00(0.00)\n",
      "Iter 2585 | Time 84.4115(81.1769) | Bit/dim 3.4932(3.4860) | Xent 0.0000(0.0000) | Loss 8.8059(9.5609) | Error 0.0000(0.0000) Steps 754(724.78) | Grad Norm 2.1395(2.3529) | Total Time 0.00(0.00)\n",
      "Iter 2586 | Time 76.5708(81.0387) | Bit/dim 3.4910(3.4861) | Xent 0.0000(0.0000) | Loss 8.7289(9.5360) | Error 0.0000(0.0000) Steps 706(724.22) | Grad Norm 1.6797(2.3327) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 25.5677, Epoch Time 533.9948(517.2341), Bit/dim 3.4830(best: 3.4830), Xent 0.0000, Loss 3.4830, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2587 | Time 79.2498(80.9850) | Bit/dim 3.4796(3.4859) | Xent 0.0000(0.0000) | Loss 13.8448(9.6652) | Error 0.0000(0.0000) Steps 706(723.67) | Grad Norm 1.9136(2.3201) | Total Time 0.00(0.00)\n",
      "Iter 2588 | Time 80.0264(80.9563) | Bit/dim 3.4850(3.4859) | Xent 0.0000(0.0000) | Loss 8.9693(9.6443) | Error 0.0000(0.0000) Steps 730(723.86) | Grad Norm 2.4046(2.3227) | Total Time 0.00(0.00)\n",
      "Iter 2589 | Time 83.8402(81.0428) | Bit/dim 3.4736(3.4855) | Xent 0.0000(0.0000) | Loss 8.8692(9.6211) | Error 0.0000(0.0000) Steps 730(724.05) | Grad Norm 2.8526(2.3386) | Total Time 0.00(0.00)\n",
      "Iter 2590 | Time 81.8106(81.0658) | Bit/dim 3.5007(3.4860) | Xent 0.0000(0.0000) | Loss 9.0517(9.6040) | Error 0.0000(0.0000) Steps 700(723.33) | Grad Norm 3.2396(2.3656) | Total Time 0.00(0.00)\n",
      "Iter 2591 | Time 76.9322(80.9418) | Bit/dim 3.4902(3.4861) | Xent 0.0000(0.0000) | Loss 8.8791(9.5823) | Error 0.0000(0.0000) Steps 700(722.63) | Grad Norm 3.2058(2.3908) | Total Time 0.00(0.00)\n",
      "Iter 2592 | Time 81.6919(80.9643) | Bit/dim 3.4837(3.4860) | Xent 0.0000(0.0000) | Loss 9.0662(9.5668) | Error 0.0000(0.0000) Steps 736(723.03) | Grad Norm 2.8073(2.4033) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 25.8217, Epoch Time 525.1197(517.4706), Bit/dim 3.4929(best: 3.4830), Xent 0.0000, Loss 3.4929, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2593 | Time 78.4300(80.8883) | Bit/dim 3.4967(3.4864) | Xent 0.0000(0.0000) | Loss 13.3474(9.6802) | Error 0.0000(0.0000) Steps 718(722.88) | Grad Norm 2.3871(2.4028) | Total Time 0.00(0.00)\n",
      "Iter 2594 | Time 77.9826(80.8011) | Bit/dim 3.4875(3.4864) | Xent 0.0000(0.0000) | Loss 8.8027(9.6539) | Error 0.0000(0.0000) Steps 712(722.55) | Grad Norm 2.1019(2.3938) | Total Time 0.00(0.00)\n",
      "Iter 2595 | Time 78.5479(80.7335) | Bit/dim 3.4814(3.4862) | Xent 0.0000(0.0000) | Loss 8.6309(9.6232) | Error 0.0000(0.0000) Steps 706(722.05) | Grad Norm 2.2271(2.3888) | Total Time 0.00(0.00)\n",
      "Iter 2596 | Time 83.6398(80.8207) | Bit/dim 3.4946(3.4865) | Xent 0.0000(0.0000) | Loss 8.9468(9.6029) | Error 0.0000(0.0000) Steps 724(722.11) | Grad Norm 3.0881(2.4098) | Total Time 0.00(0.00)\n",
      "Iter 2597 | Time 84.0583(80.9178) | Bit/dim 3.4869(3.4865) | Xent 0.0000(0.0000) | Loss 9.0137(9.5852) | Error 0.0000(0.0000) Steps 724(722.17) | Grad Norm 4.0625(2.4593) | Total Time 0.00(0.00)\n",
      "Iter 2598 | Time 79.4773(80.8746) | Bit/dim 3.4690(3.4860) | Xent 0.0000(0.0000) | Loss 8.7365(9.5597) | Error 0.0000(0.0000) Steps 712(721.86) | Grad Norm 3.8972(2.5025) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 25.0249, Epoch Time 523.6625(517.6564), Bit/dim 3.4837(best: 3.4830), Xent 0.0000, Loss 3.4837, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2599 | Time 82.8478(80.9338) | Bit/dim 3.4846(3.4859) | Xent 0.0000(0.0000) | Loss 13.3433(9.6733) | Error 0.0000(0.0000) Steps 718(721.75) | Grad Norm 2.7540(2.5100) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 83.4990(81.0108) | Bit/dim 3.4834(3.4859) | Xent 0.0000(0.0000) | Loss 8.6415(9.6423) | Error 0.0000(0.0000) Steps 706(721.28) | Grad Norm 1.6261(2.4835) | Total Time 0.00(0.00)\n",
      "Iter 2601 | Time 79.7776(80.9738) | Bit/dim 3.4969(3.4862) | Xent 0.0000(0.0000) | Loss 8.9071(9.6202) | Error 0.0000(0.0000) Steps 718(721.18) | Grad Norm 1.2462(2.4464) | Total Time 0.00(0.00)\n",
      "Iter 2602 | Time 89.9133(81.2420) | Bit/dim 3.4684(3.4857) | Xent 0.0000(0.0000) | Loss 8.9654(9.6006) | Error 0.0000(0.0000) Steps 730(721.44) | Grad Norm 2.4343(2.4460) | Total Time 0.00(0.00)\n",
      "Iter 2603 | Time 83.1792(81.3001) | Bit/dim 3.4925(3.4859) | Xent 0.0000(0.0000) | Loss 8.9872(9.5822) | Error 0.0000(0.0000) Steps 724(721.52) | Grad Norm 3.5153(2.4781) | Total Time 0.00(0.00)\n",
      "Iter 2604 | Time 84.6348(81.4001) | Bit/dim 3.4752(3.4855) | Xent 0.0000(0.0000) | Loss 8.9638(9.5636) | Error 0.0000(0.0000) Steps 736(721.95) | Grad Norm 3.6122(2.5121) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 25.8059, Epoch Time 545.2868(518.4853), Bit/dim 3.4860(best: 3.4830), Xent 0.0000, Loss 3.4860, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2605 | Time 87.2067(81.5743) | Bit/dim 3.4851(3.4855) | Xent 0.0000(0.0000) | Loss 13.4832(9.6812) | Error 0.0000(0.0000) Steps 730(722.19) | Grad Norm 3.1128(2.5301) | Total Time 0.00(0.00)\n",
      "Iter 2606 | Time 79.7856(81.5207) | Bit/dim 3.4813(3.4854) | Xent 0.0000(0.0000) | Loss 8.9163(9.6583) | Error 0.0000(0.0000) Steps 724(722.25) | Grad Norm 2.3315(2.5242) | Total Time 0.00(0.00)\n",
      "Iter 2607 | Time 79.8439(81.4704) | Bit/dim 3.4983(3.4858) | Xent 0.0000(0.0000) | Loss 8.3806(9.6200) | Error 0.0000(0.0000) Steps 688(721.22) | Grad Norm 1.3995(2.4904) | Total Time 0.00(0.00)\n",
      "Iter 2608 | Time 80.5222(81.4419) | Bit/dim 3.4808(3.4856) | Xent 0.0000(0.0000) | Loss 8.8610(9.5972) | Error 0.0000(0.0000) Steps 712(720.94) | Grad Norm 0.7254(2.4375) | Total Time 0.00(0.00)\n",
      "Iter 2609 | Time 82.8349(81.4837) | Bit/dim 3.4861(3.4857) | Xent 0.0000(0.0000) | Loss 8.8467(9.5747) | Error 0.0000(0.0000) Steps 694(720.14) | Grad Norm 2.2836(2.4329) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 83.4712(81.5433) | Bit/dim 3.4725(3.4853) | Xent 0.0000(0.0000) | Loss 8.7904(9.5511) | Error 0.0000(0.0000) Steps 706(719.71) | Grad Norm 3.4461(2.4633) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 25.6340, Epoch Time 535.1673(518.9858), Bit/dim 3.4908(best: 3.4830), Xent 0.0000, Loss 3.4908, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2611 | Time 82.2012(81.5631) | Bit/dim 3.4741(3.4849) | Xent 0.0000(0.0000) | Loss 13.6457(9.6740) | Error 0.0000(0.0000) Steps 706(719.30) | Grad Norm 3.9516(2.5079) | Total Time 0.00(0.00)\n",
      "Iter 2612 | Time 82.9087(81.6034) | Bit/dim 3.4779(3.4847) | Xent 0.0000(0.0000) | Loss 8.8470(9.6492) | Error 0.0000(0.0000) Steps 730(719.62) | Grad Norm 3.2896(2.5314) | Total Time 0.00(0.00)\n",
      "Iter 2613 | Time 80.7758(81.5786) | Bit/dim 3.5006(3.4852) | Xent 0.0000(0.0000) | Loss 8.9226(9.6274) | Error 0.0000(0.0000) Steps 724(719.75) | Grad Norm 1.7794(2.5088) | Total Time 0.00(0.00)\n",
      "Iter 2614 | Time 82.2087(81.5975) | Bit/dim 3.4811(3.4851) | Xent 0.0000(0.0000) | Loss 8.5628(9.5954) | Error 0.0000(0.0000) Steps 718(719.70) | Grad Norm 0.8533(2.4591) | Total Time 0.00(0.00)\n",
      "Iter 2615 | Time 83.1148(81.6430) | Bit/dim 3.4821(3.4850) | Xent 0.0000(0.0000) | Loss 8.8318(9.5725) | Error 0.0000(0.0000) Steps 718(719.65) | Grad Norm 2.1112(2.4487) | Total Time 0.00(0.00)\n",
      "Iter 2616 | Time 84.0778(81.7161) | Bit/dim 3.4884(3.4851) | Xent 0.0000(0.0000) | Loss 8.6981(9.5463) | Error 0.0000(0.0000) Steps 712(719.42) | Grad Norm 3.0893(2.4679) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 25.7194, Epoch Time 536.8183(519.5207), Bit/dim 3.4865(best: 3.4830), Xent 0.0000, Loss 3.4865, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2617 | Time 82.5382(81.7407) | Bit/dim 3.4894(3.4852) | Xent 0.0000(0.0000) | Loss 13.6350(9.6690) | Error 0.0000(0.0000) Steps 718(719.38) | Grad Norm 3.2195(2.4905) | Total Time 0.00(0.00)\n",
      "Iter 2618 | Time 82.1976(81.7544) | Bit/dim 3.4823(3.4851) | Xent 0.0000(0.0000) | Loss 8.7709(9.6420) | Error 0.0000(0.0000) Steps 742(720.06) | Grad Norm 2.7234(2.4975) | Total Time 0.00(0.00)\n",
      "Iter 2619 | Time 84.6278(81.8406) | Bit/dim 3.4843(3.4851) | Xent 0.0000(0.0000) | Loss 8.8260(9.6175) | Error 0.0000(0.0000) Steps 718(719.99) | Grad Norm 2.0846(2.4851) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 78.9187(81.7530) | Bit/dim 3.4868(3.4852) | Xent 0.0000(0.0000) | Loss 8.8763(9.5953) | Error 0.0000(0.0000) Steps 712(719.75) | Grad Norm 1.7508(2.4630) | Total Time 0.00(0.00)\n",
      "Iter 2621 | Time 84.0186(81.8209) | Bit/dim 3.4865(3.4852) | Xent 0.0000(0.0000) | Loss 9.0311(9.5784) | Error 0.0000(0.0000) Steps 724(719.88) | Grad Norm 2.0587(2.4509) | Total Time 0.00(0.00)\n",
      "Iter 2622 | Time 78.0691(81.7084) | Bit/dim 3.4853(3.4852) | Xent 0.0000(0.0000) | Loss 8.9328(9.5590) | Error 0.0000(0.0000) Steps 712(719.65) | Grad Norm 2.8886(2.4640) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 25.8171, Epoch Time 531.8045(519.8892), Bit/dim 3.4865(best: 3.4830), Xent 0.0000, Loss 3.4865, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2623 | Time 79.0495(81.6286) | Bit/dim 3.4955(3.4855) | Xent 0.0000(0.0000) | Loss 12.9936(9.6620) | Error 0.0000(0.0000) Steps 718(719.60) | Grad Norm 3.3928(2.4919) | Total Time 0.00(0.00)\n",
      "Iter 2624 | Time 78.7952(81.5436) | Bit/dim 3.4847(3.4855) | Xent 0.0000(0.0000) | Loss 8.7011(9.6332) | Error 0.0000(0.0000) Steps 712(719.37) | Grad Norm 2.9749(2.5064) | Total Time 0.00(0.00)\n",
      "Iter 2625 | Time 79.7601(81.4901) | Bit/dim 3.4909(3.4856) | Xent 0.0000(0.0000) | Loss 8.8064(9.6084) | Error 0.0000(0.0000) Steps 700(718.79) | Grad Norm 2.1578(2.4959) | Total Time 0.00(0.00)\n",
      "Iter 2626 | Time 81.5459(81.4918) | Bit/dim 3.4740(3.4853) | Xent 0.0000(0.0000) | Loss 8.8884(9.5868) | Error 0.0000(0.0000) Steps 712(718.58) | Grad Norm 1.9663(2.4801) | Total Time 0.00(0.00)\n",
      "Iter 2627 | Time 85.0001(81.5970) | Bit/dim 3.4723(3.4849) | Xent 0.0000(0.0000) | Loss 8.7301(9.5611) | Error 0.0000(0.0000) Steps 712(718.39) | Grad Norm 2.8708(2.4918) | Total Time 0.00(0.00)\n",
      "Iter 2628 | Time 82.3750(81.6204) | Bit/dim 3.4789(3.4847) | Xent 0.0000(0.0000) | Loss 8.8618(9.5401) | Error 0.0000(0.0000) Steps 742(719.09) | Grad Norm 3.6049(2.5252) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 26.0748, Epoch Time 528.3835(520.1441), Bit/dim 3.4867(best: 3.4830), Xent 0.0000, Loss 3.4867, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2629 | Time 84.7441(81.7141) | Bit/dim 3.4918(3.4849) | Xent 0.0000(0.0000) | Loss 13.7516(9.6665) | Error 0.0000(0.0000) Steps 754(720.14) | Grad Norm 3.4419(2.5527) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 80.0425(81.6639) | Bit/dim 3.4820(3.4848) | Xent 0.0000(0.0000) | Loss 8.8992(9.6435) | Error 0.0000(0.0000) Steps 724(720.26) | Grad Norm 2.7162(2.5576) | Total Time 0.00(0.00)\n",
      "Iter 2631 | Time 82.1452(81.6784) | Bit/dim 3.4905(3.4850) | Xent 0.0000(0.0000) | Loss 8.6290(9.6130) | Error 0.0000(0.0000) Steps 724(720.37) | Grad Norm 1.7537(2.5335) | Total Time 0.00(0.00)\n",
      "Iter 2632 | Time 78.3160(81.5775) | Bit/dim 3.4788(3.4848) | Xent 0.0000(0.0000) | Loss 8.7125(9.5860) | Error 0.0000(0.0000) Steps 706(719.94) | Grad Norm 0.7868(2.4811) | Total Time 0.00(0.00)\n",
      "Iter 2633 | Time 82.1496(81.5947) | Bit/dim 3.4898(3.4850) | Xent 0.0000(0.0000) | Loss 8.9985(9.5684) | Error 0.0000(0.0000) Steps 754(720.96) | Grad Norm 0.9190(2.4342) | Total Time 0.00(0.00)\n",
      "Iter 2634 | Time 82.3297(81.6167) | Bit/dim 3.4777(3.4848) | Xent 0.0000(0.0000) | Loss 8.8736(9.5475) | Error 0.0000(0.0000) Steps 742(721.59) | Grad Norm 1.7986(2.4151) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 26.1972, Epoch Time 531.5583(520.4865), Bit/dim 3.4830(best: 3.4830), Xent 0.0000, Loss 3.4830, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2635 | Time 81.9872(81.6278) | Bit/dim 3.4824(3.4847) | Xent 0.0000(0.0000) | Loss 13.7159(9.6726) | Error 0.0000(0.0000) Steps 724(721.66) | Grad Norm 2.8789(2.4290) | Total Time 0.00(0.00)\n",
      "Iter 2636 | Time 83.9331(81.6970) | Bit/dim 3.4911(3.4849) | Xent 0.0000(0.0000) | Loss 9.1000(9.6554) | Error 0.0000(0.0000) Steps 748(722.45) | Grad Norm 3.4373(2.4593) | Total Time 0.00(0.00)\n",
      "Iter 2637 | Time 84.8692(81.7922) | Bit/dim 3.4801(3.4847) | Xent 0.0000(0.0000) | Loss 8.8979(9.6327) | Error 0.0000(0.0000) Steps 730(722.68) | Grad Norm 3.3086(2.4848) | Total Time 0.00(0.00)\n",
      "Iter 2638 | Time 78.5053(81.6936) | Bit/dim 3.4866(3.4848) | Xent 0.0000(0.0000) | Loss 8.8211(9.6083) | Error 0.0000(0.0000) Steps 724(722.72) | Grad Norm 2.6471(2.4896) | Total Time 0.00(0.00)\n",
      "Iter 2639 | Time 84.8562(81.7884) | Bit/dim 3.4870(3.4849) | Xent 0.0000(0.0000) | Loss 8.7807(9.5835) | Error 0.0000(0.0000) Steps 742(723.30) | Grad Norm 1.6292(2.4638) | Total Time 0.00(0.00)\n",
      "Iter 2640 | Time 82.6780(81.8151) | Bit/dim 3.4827(3.4848) | Xent 0.0000(0.0000) | Loss 8.7609(9.5588) | Error 0.0000(0.0000) Steps 730(723.50) | Grad Norm 0.8861(2.4165) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 26.2344, Epoch Time 538.8918(521.0387), Bit/dim 3.4831(best: 3.4830), Xent 0.0000, Loss 3.4831, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2641 | Time 83.5129(81.8661) | Bit/dim 3.4819(3.4847) | Xent 0.0000(0.0000) | Loss 13.8544(9.6877) | Error 0.0000(0.0000) Steps 724(723.51) | Grad Norm 1.8000(2.3980) | Total Time 0.00(0.00)\n",
      "Iter 2642 | Time 76.8801(81.7165) | Bit/dim 3.4890(3.4848) | Xent 0.0000(0.0000) | Loss 8.7615(9.6599) | Error 0.0000(0.0000) Steps 712(723.17) | Grad Norm 2.8248(2.4108) | Total Time 0.00(0.00)\n",
      "Iter 2643 | Time 83.4576(81.7687) | Bit/dim 3.4835(3.4848) | Xent 0.0000(0.0000) | Loss 8.8230(9.6348) | Error 0.0000(0.0000) Steps 736(723.55) | Grad Norm 3.1181(2.4320) | Total Time 0.00(0.00)\n",
      "Iter 2644 | Time 81.9564(81.7743) | Bit/dim 3.4824(3.4847) | Xent 0.0000(0.0000) | Loss 8.8353(9.6108) | Error 0.0000(0.0000) Steps 718(723.39) | Grad Norm 2.9266(2.4469) | Total Time 0.00(0.00)\n",
      "Iter 2645 | Time 80.7012(81.7421) | Bit/dim 3.4910(3.4849) | Xent 0.0000(0.0000) | Loss 8.8270(9.5873) | Error 0.0000(0.0000) Steps 730(723.59) | Grad Norm 2.9979(2.4634) | Total Time 0.00(0.00)\n",
      "Iter 2646 | Time 80.4741(81.7041) | Bit/dim 3.4889(3.4850) | Xent 0.0000(0.0000) | Loss 8.4508(9.5532) | Error 0.0000(0.0000) Steps 724(723.60) | Grad Norm 3.5223(2.4952) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 25.9129, Epoch Time 528.7624(521.2704), Bit/dim 3.4864(best: 3.4830), Xent 0.0000, Loss 3.4864, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2647 | Time 79.8733(81.6492) | Bit/dim 3.4870(3.4851) | Xent 0.0000(0.0000) | Loss 13.6323(9.6756) | Error 0.0000(0.0000) Steps 718(723.43) | Grad Norm 3.7145(2.5317) | Total Time 0.00(0.00)\n",
      "Iter 2648 | Time 85.7575(81.7724) | Bit/dim 3.4742(3.4848) | Xent 0.0000(0.0000) | Loss 8.8738(9.6515) | Error 0.0000(0.0000) Steps 736(723.81) | Grad Norm 3.7501(2.5683) | Total Time 0.00(0.00)\n",
      "Iter 2649 | Time 81.2484(81.7567) | Bit/dim 3.4796(3.4846) | Xent 0.0000(0.0000) | Loss 8.8309(9.6269) | Error 0.0000(0.0000) Steps 730(723.99) | Grad Norm 3.5968(2.5991) | Total Time 0.00(0.00)\n",
      "Iter 2650 | Time 85.2192(81.8606) | Bit/dim 3.4888(3.4847) | Xent 0.0000(0.0000) | Loss 9.0522(9.6097) | Error 0.0000(0.0000) Steps 748(724.71) | Grad Norm 2.9014(2.6082) | Total Time 0.00(0.00)\n",
      "Iter 2651 | Time 80.3185(81.8143) | Bit/dim 3.4736(3.4844) | Xent 0.0000(0.0000) | Loss 8.7905(9.5851) | Error 0.0000(0.0000) Steps 724(724.69) | Grad Norm 1.9985(2.5899) | Total Time 0.00(0.00)\n",
      "Iter 2652 | Time 83.0685(81.8519) | Bit/dim 3.4893(3.4846) | Xent 0.0000(0.0000) | Loss 8.6660(9.5575) | Error 0.0000(0.0000) Steps 706(724.13) | Grad Norm 1.0709(2.5444) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 25.1818, Epoch Time 536.4920(521.7270), Bit/dim 3.4855(best: 3.4830), Xent 0.0000, Loss 3.4855, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2653 | Time 76.9938(81.7062) | Bit/dim 3.4809(3.4844) | Xent 0.0000(0.0000) | Loss 13.4898(9.6755) | Error 0.0000(0.0000) Steps 712(723.77) | Grad Norm 0.7154(2.4895) | Total Time 0.00(0.00)\n",
      "Iter 2654 | Time 84.2669(81.7830) | Bit/dim 3.4838(3.4844) | Xent 0.0000(0.0000) | Loss 8.6010(9.6433) | Error 0.0000(0.0000) Steps 724(723.77) | Grad Norm 0.8884(2.4415) | Total Time 0.00(0.00)\n",
      "Iter 2655 | Time 83.5256(81.8353) | Bit/dim 3.4768(3.4842) | Xent 0.0000(0.0000) | Loss 8.8674(9.6200) | Error 0.0000(0.0000) Steps 724(723.78) | Grad Norm 1.4625(2.4121) | Total Time 0.00(0.00)\n",
      "Iter 2656 | Time 78.2251(81.7270) | Bit/dim 3.4905(3.4844) | Xent 0.0000(0.0000) | Loss 8.7440(9.5937) | Error 0.0000(0.0000) Steps 718(723.61) | Grad Norm 2.3044(2.4089) | Total Time 0.00(0.00)\n",
      "Iter 2657 | Time 84.6793(81.8156) | Bit/dim 3.4907(3.4846) | Xent 0.0000(0.0000) | Loss 8.9316(9.5738) | Error 0.0000(0.0000) Steps 706(723.08) | Grad Norm 3.2318(2.4335) | Total Time 0.00(0.00)\n",
      "Iter 2658 | Time 87.4111(81.9834) | Bit/dim 3.4801(3.4844) | Xent 0.0000(0.0000) | Loss 8.8533(9.5522) | Error 0.0000(0.0000) Steps 724(723.11) | Grad Norm 3.8876(2.4772) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 25.9181, Epoch Time 537.0659(522.1872), Bit/dim 3.4913(best: 3.4830), Xent 0.0000, Loss 3.4913, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2659 | Time 79.8751(81.9202) | Bit/dim 3.4933(3.4847) | Xent 0.0000(0.0000) | Loss 13.8382(9.6808) | Error 0.0000(0.0000) Steps 718(722.95) | Grad Norm 3.5570(2.5096) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 85.4116(82.0249) | Bit/dim 3.4828(3.4846) | Xent 0.0000(0.0000) | Loss 8.8266(9.6552) | Error 0.0000(0.0000) Steps 742(723.52) | Grad Norm 2.7540(2.5169) | Total Time 0.00(0.00)\n",
      "Iter 2661 | Time 81.5789(82.0115) | Bit/dim 3.4754(3.4844) | Xent 0.0000(0.0000) | Loss 8.9201(9.6331) | Error 0.0000(0.0000) Steps 742(724.08) | Grad Norm 1.8560(2.4971) | Total Time 0.00(0.00)\n",
      "Iter 2662 | Time 83.5083(82.0564) | Bit/dim 3.4731(3.4840) | Xent 0.0000(0.0000) | Loss 8.8507(9.6097) | Error 0.0000(0.0000) Steps 724(724.08) | Grad Norm 2.2525(2.4897) | Total Time 0.00(0.00)\n",
      "Iter 2663 | Time 91.0986(82.3277) | Bit/dim 3.4911(3.4842) | Xent 0.0000(0.0000) | Loss 9.0000(9.5914) | Error 0.0000(0.0000) Steps 736(724.43) | Grad Norm 3.1406(2.5093) | Total Time 0.00(0.00)\n",
      "Iter 2664 | Time 75.2060(82.1141) | Bit/dim 3.4919(3.4845) | Xent 0.0000(0.0000) | Loss 8.6587(9.5634) | Error 0.0000(0.0000) Steps 706(723.88) | Grad Norm 3.3530(2.5346) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 25.1557, Epoch Time 537.5548(522.6482), Bit/dim 3.4848(best: 3.4830), Xent 0.0000, Loss 3.4848, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2665 | Time 85.1503(82.2051) | Bit/dim 3.4802(3.4843) | Xent 0.0000(0.0000) | Loss 13.1457(9.6709) | Error 0.0000(0.0000) Steps 736(724.25) | Grad Norm 2.7378(2.5407) | Total Time 0.00(0.00)\n",
      "Iter 2666 | Time 79.6000(82.1270) | Bit/dim 3.4837(3.4843) | Xent 0.0000(0.0000) | Loss 8.9224(9.6484) | Error 0.0000(0.0000) Steps 724(724.24) | Grad Norm 1.7381(2.5166) | Total Time 0.00(0.00)\n",
      "Iter 2667 | Time 86.1177(82.2467) | Bit/dim 3.4816(3.4842) | Xent 0.0000(0.0000) | Loss 8.9622(9.6278) | Error 0.0000(0.0000) Steps 730(724.41) | Grad Norm 1.0340(2.4721) | Total Time 0.00(0.00)\n",
      "Iter 2668 | Time 83.0825(82.2718) | Bit/dim 3.4806(3.4841) | Xent 0.0000(0.0000) | Loss 9.0710(9.6111) | Error 0.0000(0.0000) Steps 736(724.76) | Grad Norm 2.0385(2.4591) | Total Time 0.00(0.00)\n",
      "Iter 2669 | Time 84.1600(82.3284) | Bit/dim 3.4895(3.4843) | Xent 0.0000(0.0000) | Loss 8.7439(9.5851) | Error 0.0000(0.0000) Steps 712(724.38) | Grad Norm 3.2431(2.4826) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 81.1687(82.2936) | Bit/dim 3.4824(3.4842) | Xent 0.0000(0.0000) | Loss 8.9127(9.5649) | Error 0.0000(0.0000) Steps 718(724.18) | Grad Norm 3.8455(2.5235) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 25.7730, Epoch Time 540.7386(523.1909), Bit/dim 3.4881(best: 3.4830), Xent 0.0000, Loss 3.4881, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2671 | Time 80.1758(82.2301) | Bit/dim 3.4850(3.4843) | Xent 0.0000(0.0000) | Loss 13.4524(9.6816) | Error 0.0000(0.0000) Steps 724(724.18) | Grad Norm 3.6066(2.5560) | Total Time 0.00(0.00)\n",
      "Iter 2672 | Time 85.0507(82.3147) | Bit/dim 3.4920(3.4845) | Xent 0.0000(0.0000) | Loss 9.0969(9.6640) | Error 0.0000(0.0000) Steps 748(724.89) | Grad Norm 2.7080(2.5606) | Total Time 0.00(0.00)\n",
      "Iter 2673 | Time 83.2766(82.3436) | Bit/dim 3.4922(3.4847) | Xent 0.0000(0.0000) | Loss 8.9886(9.6437) | Error 0.0000(0.0000) Steps 724(724.87) | Grad Norm 1.7195(2.5353) | Total Time 0.00(0.00)\n",
      "Iter 2674 | Time 78.4784(82.2276) | Bit/dim 3.4820(3.4846) | Xent 0.0000(0.0000) | Loss 8.7379(9.6166) | Error 0.0000(0.0000) Steps 718(724.66) | Grad Norm 1.8151(2.5137) | Total Time 0.00(0.00)\n",
      "Iter 2675 | Time 82.8457(82.2462) | Bit/dim 3.4673(3.4841) | Xent 0.0000(0.0000) | Loss 8.7797(9.5915) | Error 0.0000(0.0000) Steps 736(725.00) | Grad Norm 2.5660(2.5153) | Total Time 0.00(0.00)\n",
      "Iter 2676 | Time 84.3797(82.3102) | Bit/dim 3.4744(3.4838) | Xent 0.0000(0.0000) | Loss 8.6218(9.5624) | Error 0.0000(0.0000) Steps 718(724.79) | Grad Norm 3.0850(2.5324) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 26.6892, Epoch Time 536.7320(523.5972), Bit/dim 3.4878(best: 3.4830), Xent 0.0000, Loss 3.4878, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2677 | Time 84.9242(82.3886) | Bit/dim 3.4796(3.4837) | Xent 0.0000(0.0000) | Loss 13.9877(9.6951) | Error 0.0000(0.0000) Steps 748(725.49) | Grad Norm 3.4643(2.5603) | Total Time 0.00(0.00)\n",
      "Iter 2678 | Time 85.2639(82.4749) | Bit/dim 3.4808(3.4836) | Xent 0.0000(0.0000) | Loss 8.7371(9.6664) | Error 0.0000(0.0000) Steps 736(725.80) | Grad Norm 3.3333(2.5835) | Total Time 0.00(0.00)\n",
      "Iter 2679 | Time 83.0269(82.4914) | Bit/dim 3.4899(3.4838) | Xent 0.0000(0.0000) | Loss 8.9247(9.6441) | Error 0.0000(0.0000) Steps 724(725.75) | Grad Norm 2.4229(2.5787) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 87.0826(82.6292) | Bit/dim 3.4657(3.4833) | Xent 0.0000(0.0000) | Loss 8.8910(9.6215) | Error 0.0000(0.0000) Steps 754(726.60) | Grad Norm 1.3951(2.5432) | Total Time 0.00(0.00)\n",
      "Iter 2681 | Time 86.6291(82.7491) | Bit/dim 3.4939(3.4836) | Xent 0.0000(0.0000) | Loss 8.5665(9.5899) | Error 0.0000(0.0000) Steps 724(726.52) | Grad Norm 1.0187(2.4975) | Total Time 0.00(0.00)\n",
      "Iter 2682 | Time 85.0739(82.8189) | Bit/dim 3.4908(3.4838) | Xent 0.0000(0.0000) | Loss 8.9641(9.5711) | Error 0.0000(0.0000) Steps 718(726.26) | Grad Norm 1.1291(2.4564) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 26.1227, Epoch Time 554.0190(524.5098), Bit/dim 3.4817(best: 3.4830), Xent 0.0000, Loss 3.4817, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2683 | Time 87.7540(82.9669) | Bit/dim 3.4807(3.4837) | Xent 0.0000(0.0000) | Loss 14.0362(9.7051) | Error 0.0000(0.0000) Steps 730(726.37) | Grad Norm 1.7172(2.4342) | Total Time 0.00(0.00)\n",
      "Iter 2684 | Time 83.1879(82.9736) | Bit/dim 3.4833(3.4837) | Xent 0.0000(0.0000) | Loss 8.6389(9.6731) | Error 0.0000(0.0000) Steps 712(725.94) | Grad Norm 2.1936(2.4270) | Total Time 0.00(0.00)\n",
      "Iter 2685 | Time 83.8914(83.0011) | Bit/dim 3.4778(3.4835) | Xent 0.0000(0.0000) | Loss 8.7541(9.6455) | Error 0.0000(0.0000) Steps 730(726.07) | Grad Norm 2.2673(2.4222) | Total Time 0.00(0.00)\n",
      "Iter 2686 | Time 78.8980(82.8780) | Bit/dim 3.4681(3.4831) | Xent 0.0000(0.0000) | Loss 8.8675(9.6222) | Error 0.0000(0.0000) Steps 694(725.10) | Grad Norm 2.1592(2.4143) | Total Time 0.00(0.00)\n",
      "Iter 2687 | Time 84.4655(82.9256) | Bit/dim 3.4893(3.4832) | Xent 0.0000(0.0000) | Loss 9.0160(9.6040) | Error 0.0000(0.0000) Steps 730(725.25) | Grad Norm 2.0838(2.4044) | Total Time 0.00(0.00)\n",
      "Iter 2688 | Time 86.1297(83.0218) | Bit/dim 3.4824(3.4832) | Xent 0.0000(0.0000) | Loss 8.6861(9.5765) | Error 0.0000(0.0000) Steps 736(725.57) | Grad Norm 2.2594(2.4001) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 26.8833, Epoch Time 546.9915(525.1843), Bit/dim 3.4807(best: 3.4817), Xent 0.0000, Loss 3.4807, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2689 | Time 81.2566(82.9688) | Bit/dim 3.4824(3.4832) | Xent 0.0000(0.0000) | Loss 13.6906(9.6999) | Error 0.0000(0.0000) Steps 742(726.07) | Grad Norm 2.4437(2.4014) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 80.8062(82.9039) | Bit/dim 3.4747(3.4829) | Xent 0.0000(0.0000) | Loss 8.8094(9.6732) | Error 0.0000(0.0000) Steps 730(726.18) | Grad Norm 2.4768(2.4036) | Total Time 0.00(0.00)\n",
      "Iter 2691 | Time 87.6344(83.0458) | Bit/dim 3.4777(3.4828) | Xent 0.0000(0.0000) | Loss 8.7152(9.6444) | Error 0.0000(0.0000) Steps 766(727.38) | Grad Norm 2.4609(2.4054) | Total Time 0.00(0.00)\n",
      "Iter 2692 | Time 82.3953(83.0263) | Bit/dim 3.4856(3.4829) | Xent 0.0000(0.0000) | Loss 8.7997(9.6191) | Error 0.0000(0.0000) Steps 736(727.64) | Grad Norm 2.2263(2.4000) | Total Time 0.00(0.00)\n",
      "Iter 2693 | Time 84.2821(83.0640) | Bit/dim 3.4858(3.4830) | Xent 0.0000(0.0000) | Loss 8.8925(9.5973) | Error 0.0000(0.0000) Steps 754(728.43) | Grad Norm 2.0878(2.3906) | Total Time 0.00(0.00)\n",
      "Iter 2694 | Time 80.0212(82.9727) | Bit/dim 3.4655(3.4824) | Xent 0.0000(0.0000) | Loss 8.5354(9.5654) | Error 0.0000(0.0000) Steps 730(728.47) | Grad Norm 2.1788(2.3843) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 25.9623, Epoch Time 538.0857(525.5713), Bit/dim 3.4826(best: 3.4807), Xent 0.0000, Loss 3.4826, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2695 | Time 88.9487(83.1520) | Bit/dim 3.4768(3.4823) | Xent 0.0000(0.0000) | Loss 13.9587(9.6972) | Error 0.0000(0.0000) Steps 742(728.88) | Grad Norm 2.3471(2.3832) | Total Time 0.00(0.00)\n",
      "Iter 2696 | Time 86.6164(83.2559) | Bit/dim 3.4769(3.4821) | Xent 0.0000(0.0000) | Loss 8.9360(9.6744) | Error 0.0000(0.0000) Steps 748(729.45) | Grad Norm 3.0886(2.4043) | Total Time 0.00(0.00)\n",
      "Iter 2697 | Time 87.0160(83.3687) | Bit/dim 3.4812(3.4821) | Xent 0.0000(0.0000) | Loss 9.0336(9.6552) | Error 0.0000(0.0000) Steps 754(730.19) | Grad Norm 4.3201(2.4618) | Total Time 0.00(0.00)\n",
      "Iter 2698 | Time 77.7011(83.1987) | Bit/dim 3.4859(3.4822) | Xent 0.0000(0.0000) | Loss 8.8145(9.6299) | Error 0.0000(0.0000) Steps 712(729.64) | Grad Norm 4.9546(2.5366) | Total Time 0.00(0.00)\n",
      "Iter 2699 | Time 77.9515(83.0413) | Bit/dim 3.4973(3.4826) | Xent 0.0000(0.0000) | Loss 8.9384(9.6092) | Error 0.0000(0.0000) Steps 718(729.30) | Grad Norm 4.0452(2.5818) | Total Time 0.00(0.00)\n",
      "Iter 2700 | Time 83.2890(83.0487) | Bit/dim 3.4813(3.4826) | Xent 0.0000(0.0000) | Loss 8.7529(9.5835) | Error 0.0000(0.0000) Steps 724(729.14) | Grad Norm 2.6289(2.5832) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 26.0155, Epoch Time 543.4336(526.1072), Bit/dim 3.4842(best: 3.4807), Xent 0.0000, Loss 3.4842, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2701 | Time 81.4937(83.0021) | Bit/dim 3.4765(3.4824) | Xent 0.0000(0.0000) | Loss 13.8118(9.7104) | Error 0.0000(0.0000) Steps 742(729.52) | Grad Norm 2.2094(2.5720) | Total Time 0.00(0.00)\n",
      "Iter 2702 | Time 85.3208(83.0716) | Bit/dim 3.4809(3.4824) | Xent 0.0000(0.0000) | Loss 8.9723(9.6882) | Error 0.0000(0.0000) Steps 730(729.54) | Grad Norm 3.3435(2.5952) | Total Time 0.00(0.00)\n",
      "Iter 2703 | Time 83.5034(83.0846) | Bit/dim 3.4805(3.4823) | Xent 0.0000(0.0000) | Loss 8.7900(9.6613) | Error 0.0000(0.0000) Steps 724(729.37) | Grad Norm 3.8708(2.6334) | Total Time 0.00(0.00)\n",
      "Iter 2704 | Time 82.8310(83.0770) | Bit/dim 3.4841(3.4824) | Xent 0.0000(0.0000) | Loss 8.6830(9.6319) | Error 0.0000(0.0000) Steps 724(729.21) | Grad Norm 2.9803(2.6439) | Total Time 0.00(0.00)\n",
      "Iter 2705 | Time 84.2903(83.1134) | Bit/dim 3.4720(3.4821) | Xent 0.0000(0.0000) | Loss 8.8488(9.6084) | Error 0.0000(0.0000) Steps 736(729.41) | Grad Norm 1.8262(2.6193) | Total Time 0.00(0.00)\n",
      "Iter 2706 | Time 81.6781(83.0703) | Bit/dim 3.4827(3.4821) | Xent 0.0000(0.0000) | Loss 8.9455(9.5885) | Error 0.0000(0.0000) Steps 748(729.97) | Grad Norm 2.3891(2.6124) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 26.5407, Epoch Time 541.5030(526.5691), Bit/dim 3.4808(best: 3.4807), Xent 0.0000, Loss 3.4808, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2707 | Time 85.3441(83.1385) | Bit/dim 3.4804(3.4820) | Xent 0.0000(0.0000) | Loss 13.7389(9.7131) | Error 0.0000(0.0000) Steps 736(730.15) | Grad Norm 3.6757(2.6443) | Total Time 0.00(0.00)\n",
      "Iter 2708 | Time 85.5474(83.2108) | Bit/dim 3.4901(3.4823) | Xent 0.0000(0.0000) | Loss 8.9499(9.6902) | Error 0.0000(0.0000) Steps 736(730.33) | Grad Norm 4.2546(2.6926) | Total Time 0.00(0.00)\n",
      "Iter 2709 | Time 82.2188(83.1810) | Bit/dim 3.4893(3.4825) | Xent 0.0000(0.0000) | Loss 9.0162(9.6699) | Error 0.0000(0.0000) Steps 748(730.86) | Grad Norm 3.6571(2.7216) | Total Time 0.00(0.00)\n",
      "Iter 2710 | Time 92.7198(83.4672) | Bit/dim 3.4813(3.4824) | Xent 0.0000(0.0000) | Loss 8.9209(9.6475) | Error 0.0000(0.0000) Steps 748(731.37) | Grad Norm 2.0306(2.7008) | Total Time 0.00(0.00)\n",
      "Iter 2711 | Time 81.9505(83.4217) | Bit/dim 3.4720(3.4821) | Xent 0.0000(0.0000) | Loss 8.8108(9.6224) | Error 0.0000(0.0000) Steps 736(731.51) | Grad Norm 0.3781(2.6312) | Total Time 0.00(0.00)\n",
      "Iter 2712 | Time 79.7739(83.3123) | Bit/dim 3.4784(3.4820) | Xent 0.0000(0.0000) | Loss 8.6455(9.5931) | Error 0.0000(0.0000) Steps 700(730.57) | Grad Norm 2.1417(2.6165) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 26.1738, Epoch Time 549.3926(527.2538), Bit/dim 3.4851(best: 3.4807), Xent 0.0000, Loss 3.4851, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2713 | Time 86.0951(83.3957) | Bit/dim 3.4816(3.4820) | Xent 0.0000(0.0000) | Loss 13.5252(9.7110) | Error 0.0000(0.0000) Steps 754(731.27) | Grad Norm 3.2488(2.6354) | Total Time 0.00(0.00)\n",
      "Iter 2714 | Time 82.4340(83.3669) | Bit/dim 3.4829(3.4820) | Xent 0.0000(0.0000) | Loss 8.9543(9.6883) | Error 0.0000(0.0000) Steps 730(731.23) | Grad Norm 3.0448(2.6477) | Total Time 0.00(0.00)\n",
      "Iter 2715 | Time 82.6320(83.3448) | Bit/dim 3.4764(3.4819) | Xent 0.0000(0.0000) | Loss 8.8359(9.6627) | Error 0.0000(0.0000) Steps 730(731.19) | Grad Norm 2.4391(2.6415) | Total Time 0.00(0.00)\n",
      "Iter 2716 | Time 85.8962(83.4214) | Bit/dim 3.4809(3.4818) | Xent 0.0000(0.0000) | Loss 8.6893(9.6335) | Error 0.0000(0.0000) Steps 724(730.98) | Grad Norm 1.7316(2.6142) | Total Time 0.00(0.00)\n",
      "Iter 2717 | Time 86.7920(83.5225) | Bit/dim 3.4823(3.4819) | Xent 0.0000(0.0000) | Loss 8.9846(9.6141) | Error 0.0000(0.0000) Steps 724(730.77) | Grad Norm 0.9024(2.5628) | Total Time 0.00(0.00)\n",
      "Iter 2718 | Time 82.5361(83.4929) | Bit/dim 3.4740(3.4816) | Xent 0.0000(0.0000) | Loss 8.7384(9.5878) | Error 0.0000(0.0000) Steps 718(730.39) | Grad Norm 0.5952(2.5038) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 25.5815, Epoch Time 547.9127(527.8735), Bit/dim 3.4801(best: 3.4807), Xent 0.0000, Loss 3.4801, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2719 | Time 88.3416(83.6384) | Bit/dim 3.4852(3.4817) | Xent 0.0000(0.0000) | Loss 13.2215(9.6968) | Error 0.0000(0.0000) Steps 718(730.01) | Grad Norm 0.8786(2.4550) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 80.4629(83.5431) | Bit/dim 3.4730(3.4815) | Xent 0.0000(0.0000) | Loss 8.8068(9.6701) | Error 0.0000(0.0000) Steps 736(730.19) | Grad Norm 1.7483(2.4338) | Total Time 0.00(0.00)\n",
      "Iter 2721 | Time 79.3621(83.4177) | Bit/dim 3.4808(3.4814) | Xent 0.0000(0.0000) | Loss 8.5828(9.6375) | Error 0.0000(0.0000) Steps 712(729.65) | Grad Norm 3.0467(2.4522) | Total Time 0.00(0.00)\n",
      "Iter 2722 | Time 83.6428(83.4244) | Bit/dim 3.4907(3.4817) | Xent 0.0000(0.0000) | Loss 8.6828(9.6089) | Error 0.0000(0.0000) Steps 700(728.76) | Grad Norm 3.4816(2.4831) | Total Time 0.00(0.00)\n",
      "Iter 2723 | Time 74.4753(83.1560) | Bit/dim 3.4895(3.4820) | Xent 0.0000(0.0000) | Loss 8.6805(9.5810) | Error 0.0000(0.0000) Steps 700(727.90) | Grad Norm 3.1072(2.5018) | Total Time 0.00(0.00)\n",
      "Iter 2724 | Time 84.1234(83.1850) | Bit/dim 3.4652(3.4815) | Xent 0.0000(0.0000) | Loss 8.6989(9.5545) | Error 0.0000(0.0000) Steps 718(727.60) | Grad Norm 2.6118(2.5051) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 25.2158, Epoch Time 531.7590(527.9901), Bit/dim 3.4850(best: 3.4801), Xent 0.0000, Loss 3.4850, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2725 | Time 83.2504(83.1869) | Bit/dim 3.4778(3.4813) | Xent 0.0000(0.0000) | Loss 13.6787(9.6783) | Error 0.0000(0.0000) Steps 736(727.85) | Grad Norm 2.3116(2.4993) | Total Time 0.00(0.00)\n",
      "Iter 2726 | Time 81.2579(83.1291) | Bit/dim 3.4789(3.4813) | Xent 0.0000(0.0000) | Loss 8.9124(9.6553) | Error 0.0000(0.0000) Steps 736(728.09) | Grad Norm 2.2922(2.4931) | Total Time 0.00(0.00)\n",
      "Iter 2727 | Time 80.9711(83.0643) | Bit/dim 3.4746(3.4811) | Xent 0.0000(0.0000) | Loss 8.8565(9.6313) | Error 0.0000(0.0000) Steps 718(727.79) | Grad Norm 2.3953(2.4902) | Total Time 0.00(0.00)\n",
      "Iter 2728 | Time 83.6486(83.0819) | Bit/dim 3.4908(3.4814) | Xent 0.0000(0.0000) | Loss 8.9588(9.6111) | Error 0.0000(0.0000) Steps 748(728.40) | Grad Norm 2.6283(2.4943) | Total Time 0.00(0.00)\n",
      "Iter 2729 | Time 79.6457(82.9788) | Bit/dim 3.4950(3.4818) | Xent 0.0000(0.0000) | Loss 8.8746(9.5891) | Error 0.0000(0.0000) Steps 718(728.09) | Grad Norm 2.8566(2.5052) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 87.2726(83.1076) | Bit/dim 3.4671(3.4813) | Xent 0.0000(0.0000) | Loss 8.8435(9.5667) | Error 0.0000(0.0000) Steps 754(728.86) | Grad Norm 2.7731(2.5132) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 25.6087, Epoch Time 537.3418(528.2706), Bit/dim 3.4828(best: 3.4801), Xent 0.0000, Loss 3.4828, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2731 | Time 80.9691(83.0434) | Bit/dim 3.4746(3.4811) | Xent 0.0000(0.0000) | Loss 13.7206(9.6913) | Error 0.0000(0.0000) Steps 718(728.54) | Grad Norm 2.5773(2.5151) | Total Time 0.00(0.00)\n",
      "Iter 2732 | Time 78.0558(82.8938) | Bit/dim 3.4772(3.4810) | Xent 0.0000(0.0000) | Loss 8.4678(9.6546) | Error 0.0000(0.0000) Steps 700(727.68) | Grad Norm 2.7458(2.5221) | Total Time 0.00(0.00)\n",
      "Iter 2733 | Time 84.9913(82.9567) | Bit/dim 3.4886(3.4812) | Xent 0.0000(0.0000) | Loss 8.5738(9.6222) | Error 0.0000(0.0000) Steps 730(727.75) | Grad Norm 3.0025(2.5365) | Total Time 0.00(0.00)\n",
      "Iter 2734 | Time 82.9245(82.9558) | Bit/dim 3.4784(3.4812) | Xent 0.0000(0.0000) | Loss 8.8895(9.6002) | Error 0.0000(0.0000) Steps 736(728.00) | Grad Norm 3.1485(2.5548) | Total Time 0.00(0.00)\n",
      "Iter 2735 | Time 83.6325(82.9761) | Bit/dim 3.4855(3.4813) | Xent 0.0000(0.0000) | Loss 8.7847(9.5757) | Error 0.0000(0.0000) Steps 718(727.70) | Grad Norm 3.4939(2.5830) | Total Time 0.00(0.00)\n",
      "Iter 2736 | Time 78.7051(82.8479) | Bit/dim 3.4797(3.4812) | Xent 0.0000(0.0000) | Loss 8.6753(9.5487) | Error 0.0000(0.0000) Steps 706(727.05) | Grad Norm 3.3040(2.6046) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 25.7263, Epoch Time 531.0254(528.3533), Bit/dim 3.4841(best: 3.4801), Xent 0.0000, Loss 3.4841, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2737 | Time 81.1884(82.7982) | Bit/dim 3.4779(3.4811) | Xent 0.0000(0.0000) | Loss 13.7235(9.6740) | Error 0.0000(0.0000) Steps 706(726.42) | Grad Norm 2.6674(2.6065) | Total Time 0.00(0.00)\n",
      "Iter 2738 | Time 83.6432(82.8235) | Bit/dim 3.4807(3.4811) | Xent 0.0000(0.0000) | Loss 9.0121(9.6541) | Error 0.0000(0.0000) Steps 730(726.52) | Grad Norm 2.1393(2.5925) | Total Time 0.00(0.00)\n",
      "Iter 2739 | Time 84.0025(82.8589) | Bit/dim 3.4767(3.4810) | Xent 0.0000(0.0000) | Loss 9.0120(9.6348) | Error 0.0000(0.0000) Steps 748(727.17) | Grad Norm 1.8766(2.5710) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 86.3356(82.9632) | Bit/dim 3.4838(3.4811) | Xent 0.0000(0.0000) | Loss 8.8096(9.6101) | Error 0.0000(0.0000) Steps 724(727.07) | Grad Norm 2.5269(2.5697) | Total Time 0.00(0.00)\n",
      "Iter 2741 | Time 84.3013(83.0033) | Bit/dim 3.4746(3.4809) | Xent 0.0000(0.0000) | Loss 8.8130(9.5862) | Error 0.0000(0.0000) Steps 724(726.98) | Grad Norm 3.2254(2.5894) | Total Time 0.00(0.00)\n",
      "Iter 2742 | Time 76.9594(82.8220) | Bit/dim 3.4860(3.4810) | Xent 0.0000(0.0000) | Loss 8.7747(9.5618) | Error 0.0000(0.0000) Steps 712(726.53) | Grad Norm 3.4279(2.6145) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 26.3399, Epoch Time 538.5733(528.6599), Bit/dim 3.4776(best: 3.4801), Xent 0.0000, Loss 3.4776, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2743 | Time 83.8640(82.8533) | Bit/dim 3.4708(3.4807) | Xent 0.0000(0.0000) | Loss 13.4861(9.6796) | Error 0.0000(0.0000) Steps 730(726.64) | Grad Norm 3.1119(2.6294) | Total Time 0.00(0.00)\n",
      "Iter 2744 | Time 85.2216(82.9243) | Bit/dim 3.4793(3.4807) | Xent 0.0000(0.0000) | Loss 9.0565(9.6609) | Error 0.0000(0.0000) Steps 772(728.00) | Grad Norm 2.6769(2.6309) | Total Time 0.00(0.00)\n",
      "Iter 2745 | Time 80.3291(82.8465) | Bit/dim 3.4884(3.4809) | Xent 0.0000(0.0000) | Loss 8.9096(9.6383) | Error 0.0000(0.0000) Steps 712(727.52) | Grad Norm 2.7356(2.6340) | Total Time 0.00(0.00)\n",
      "Iter 2746 | Time 82.5922(82.8388) | Bit/dim 3.4923(3.4813) | Xent 0.0000(0.0000) | Loss 9.0721(9.6213) | Error 0.0000(0.0000) Steps 742(727.95) | Grad Norm 3.0464(2.6464) | Total Time 0.00(0.00)\n",
      "Iter 2747 | Time 86.0840(82.9362) | Bit/dim 3.4794(3.4812) | Xent 0.0000(0.0000) | Loss 8.9017(9.5997) | Error 0.0000(0.0000) Steps 736(728.19) | Grad Norm 3.4868(2.6716) | Total Time 0.00(0.00)\n",
      "Iter 2748 | Time 84.4884(82.9827) | Bit/dim 3.4790(3.4811) | Xent 0.0000(0.0000) | Loss 8.8796(9.5781) | Error 0.0000(0.0000) Steps 724(728.07) | Grad Norm 3.6040(2.6996) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 26.4633, Epoch Time 544.8048(529.1442), Bit/dim 3.4831(best: 3.4776), Xent 0.0000, Loss 3.4831, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2749 | Time 81.0918(82.9260) | Bit/dim 3.4788(3.4811) | Xent 0.0000(0.0000) | Loss 13.6856(9.7014) | Error 0.0000(0.0000) Steps 724(727.94) | Grad Norm 3.3511(2.7191) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 80.6614(82.8581) | Bit/dim 3.4804(3.4810) | Xent 0.0000(0.0000) | Loss 8.9587(9.6791) | Error 0.0000(0.0000) Steps 754(728.73) | Grad Norm 2.9919(2.7273) | Total Time 0.00(0.00)\n",
      "Iter 2751 | Time 84.2259(82.8991) | Bit/dim 3.4812(3.4811) | Xent 0.0000(0.0000) | Loss 8.9114(9.6561) | Error 0.0000(0.0000) Steps 730(728.76) | Grad Norm 2.2339(2.7125) | Total Time 0.00(0.00)\n",
      "Iter 2752 | Time 83.2394(82.9093) | Bit/dim 3.4753(3.4809) | Xent 0.0000(0.0000) | Loss 9.0015(9.6364) | Error 0.0000(0.0000) Steps 730(728.80) | Grad Norm 1.5887(2.6788) | Total Time 0.00(0.00)\n",
      "Iter 2753 | Time 80.8219(82.8467) | Bit/dim 3.4858(3.4810) | Xent 0.0000(0.0000) | Loss 9.0366(9.6184) | Error 0.0000(0.0000) Steps 724(728.66) | Grad Norm 1.2917(2.6372) | Total Time 0.00(0.00)\n",
      "Iter 2754 | Time 83.4546(82.8649) | Bit/dim 3.4810(3.4810) | Xent 0.0000(0.0000) | Loss 9.0148(9.6003) | Error 0.0000(0.0000) Steps 742(729.06) | Grad Norm 1.2518(2.5956) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 26.3460, Epoch Time 535.6249(529.3387), Bit/dim 3.4859(best: 3.4776), Xent 0.0000, Loss 3.4859, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2755 | Time 77.2380(82.6961) | Bit/dim 3.4863(3.4812) | Xent 0.0000(0.0000) | Loss 13.2621(9.7102) | Error 0.0000(0.0000) Steps 718(728.73) | Grad Norm 1.5203(2.5633) | Total Time 0.00(0.00)\n",
      "Iter 2756 | Time 80.4848(82.6298) | Bit/dim 3.4733(3.4809) | Xent 0.0000(0.0000) | Loss 9.0367(9.6900) | Error 0.0000(0.0000) Steps 730(728.76) | Grad Norm 1.8332(2.5414) | Total Time 0.00(0.00)\n",
      "Iter 2757 | Time 82.8446(82.6362) | Bit/dim 3.4866(3.4811) | Xent 0.0000(0.0000) | Loss 8.5903(9.6570) | Error 0.0000(0.0000) Steps 706(728.08) | Grad Norm 2.4859(2.5398) | Total Time 0.00(0.00)\n",
      "Iter 2758 | Time 80.1796(82.5625) | Bit/dim 3.4801(3.4811) | Xent 0.0000(0.0000) | Loss 8.6659(9.6272) | Error 0.0000(0.0000) Steps 712(727.60) | Grad Norm 2.9133(2.5510) | Total Time 0.00(0.00)\n",
      "Iter 2759 | Time 83.1401(82.5799) | Bit/dim 3.4814(3.4811) | Xent 0.0000(0.0000) | Loss 8.9630(9.6073) | Error 0.0000(0.0000) Steps 748(728.21) | Grad Norm 3.4149(2.5769) | Total Time 0.00(0.00)\n",
      "Iter 2760 | Time 82.9333(82.5905) | Bit/dim 3.4755(3.4809) | Xent 0.0000(0.0000) | Loss 8.7244(9.5808) | Error 0.0000(0.0000) Steps 718(727.90) | Grad Norm 3.7168(2.6111) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 25.8991, Epoch Time 528.3889(529.3102), Bit/dim 3.4802(best: 3.4776), Xent 0.0000, Loss 3.4802, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2761 | Time 83.4649(82.6167) | Bit/dim 3.4786(3.4809) | Xent 0.0000(0.0000) | Loss 13.7667(9.7064) | Error 0.0000(0.0000) Steps 736(728.15) | Grad Norm 3.6484(2.6422) | Total Time 0.00(0.00)\n",
      "Iter 2762 | Time 84.8713(82.6843) | Bit/dim 3.4808(3.4809) | Xent 0.0000(0.0000) | Loss 8.8068(9.6794) | Error 0.0000(0.0000) Steps 742(728.56) | Grad Norm 3.3071(2.6622) | Total Time 0.00(0.00)\n",
      "Iter 2763 | Time 85.2218(82.7605) | Bit/dim 3.4854(3.4810) | Xent 0.0000(0.0000) | Loss 9.0017(9.6591) | Error 0.0000(0.0000) Steps 760(729.51) | Grad Norm 2.7873(2.6659) | Total Time 0.00(0.00)\n",
      "Iter 2764 | Time 82.9307(82.7656) | Bit/dim 3.4867(3.4812) | Xent 0.0000(0.0000) | Loss 8.9569(9.6380) | Error 0.0000(0.0000) Steps 736(729.70) | Grad Norm 2.1430(2.6502) | Total Time 0.00(0.00)\n",
      "Iter 2765 | Time 83.1293(82.7765) | Bit/dim 3.4796(3.4811) | Xent 0.0000(0.0000) | Loss 8.9512(9.6174) | Error 0.0000(0.0000) Steps 730(729.71) | Grad Norm 2.7085(2.6520) | Total Time 0.00(0.00)\n",
      "Iter 2766 | Time 82.5807(82.7706) | Bit/dim 3.4758(3.4810) | Xent 0.0000(0.0000) | Loss 8.8509(9.5944) | Error 0.0000(0.0000) Steps 742(730.08) | Grad Norm 3.5580(2.6792) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 26.1002, Epoch Time 544.3237(529.7606), Bit/dim 3.4868(best: 3.4776), Xent 0.0000, Loss 3.4868, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2767 | Time 85.8325(82.8625) | Bit/dim 3.4904(3.4812) | Xent 0.0000(0.0000) | Loss 13.7204(9.7182) | Error 0.0000(0.0000) Steps 760(730.98) | Grad Norm 3.9195(2.7164) | Total Time 0.00(0.00)\n",
      "Iter 2768 | Time 84.8206(82.9212) | Bit/dim 3.4834(3.4813) | Xent 0.0000(0.0000) | Loss 8.9521(9.6952) | Error 0.0000(0.0000) Steps 742(731.31) | Grad Norm 3.4886(2.7395) | Total Time 0.00(0.00)\n",
      "Iter 2769 | Time 85.7438(83.0059) | Bit/dim 3.4794(3.4812) | Xent 0.0000(0.0000) | Loss 8.7954(9.6682) | Error 0.0000(0.0000) Steps 766(732.35) | Grad Norm 2.5180(2.7329) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 80.8991(82.9427) | Bit/dim 3.4745(3.4810) | Xent 0.0000(0.0000) | Loss 8.9423(9.6464) | Error 0.0000(0.0000) Steps 730(732.28) | Grad Norm 1.5955(2.6988) | Total Time 0.00(0.00)\n",
      "Iter 2771 | Time 82.0885(82.9171) | Bit/dim 3.4796(3.4810) | Xent 0.0000(0.0000) | Loss 8.6658(9.6170) | Error 0.0000(0.0000) Steps 724(732.03) | Grad Norm 1.1758(2.6531) | Total Time 0.00(0.00)\n",
      "Iter 2772 | Time 83.9894(82.9492) | Bit/dim 3.4825(3.4810) | Xent 0.0000(0.0000) | Loss 8.8815(9.5950) | Error 0.0000(0.0000) Steps 742(732.33) | Grad Norm 1.8016(2.6275) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 26.0085, Epoch Time 545.4722(530.2319), Bit/dim 3.4826(best: 3.4776), Xent 0.0000, Loss 3.4826, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2773 | Time 83.9924(82.9805) | Bit/dim 3.4810(3.4810) | Xent 0.0000(0.0000) | Loss 13.9866(9.7267) | Error 0.0000(0.0000) Steps 736(732.44) | Grad Norm 2.7224(2.6304) | Total Time 0.00(0.00)\n",
      "Iter 2774 | Time 82.8081(82.9753) | Bit/dim 3.4799(3.4810) | Xent 0.0000(0.0000) | Loss 8.7144(9.6963) | Error 0.0000(0.0000) Steps 724(732.19) | Grad Norm 3.1064(2.6447) | Total Time 0.00(0.00)\n",
      "Iter 2775 | Time 85.0584(83.0378) | Bit/dim 3.4873(3.4812) | Xent 0.0000(0.0000) | Loss 9.0183(9.6760) | Error 0.0000(0.0000) Steps 724(731.94) | Grad Norm 3.0647(2.6573) | Total Time 0.00(0.00)\n",
      "Iter 2776 | Time 81.4230(82.9894) | Bit/dim 3.4739(3.4810) | Xent 0.0000(0.0000) | Loss 8.7402(9.6479) | Error 0.0000(0.0000) Steps 736(732.06) | Grad Norm 2.8058(2.6617) | Total Time 0.00(0.00)\n",
      "Iter 2777 | Time 84.7642(83.0426) | Bit/dim 3.4943(3.4814) | Xent 0.0000(0.0000) | Loss 8.9186(9.6260) | Error 0.0000(0.0000) Steps 730(732.00) | Grad Norm 2.3231(2.6516) | Total Time 0.00(0.00)\n",
      "Iter 2778 | Time 79.2508(82.9289) | Bit/dim 3.4751(3.4812) | Xent 0.0000(0.0000) | Loss 8.5457(9.5936) | Error 0.0000(0.0000) Steps 730(731.94) | Grad Norm 2.0483(2.6335) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 26.4639, Epoch Time 539.4844(530.5095), Bit/dim 3.4849(best: 3.4776), Xent 0.0000, Loss 3.4849, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2779 | Time 85.7374(83.0131) | Bit/dim 3.4860(3.4813) | Xent 0.0000(0.0000) | Loss 13.4676(9.7098) | Error 0.0000(0.0000) Steps 754(732.60) | Grad Norm 1.7622(2.6073) | Total Time 0.00(0.00)\n",
      "Iter 2780 | Time 80.0025(82.9228) | Bit/dim 3.4738(3.4811) | Xent 0.0000(0.0000) | Loss 8.8846(9.6851) | Error 0.0000(0.0000) Steps 730(732.52) | Grad Norm 2.6095(2.6074) | Total Time 0.00(0.00)\n",
      "Iter 2781 | Time 84.5378(82.9713) | Bit/dim 3.4653(3.4806) | Xent 0.0000(0.0000) | Loss 8.8070(9.6587) | Error 0.0000(0.0000) Steps 742(732.81) | Grad Norm 3.7718(2.6423) | Total Time 0.00(0.00)\n",
      "Iter 2782 | Time 81.0993(82.9151) | Bit/dim 3.4809(3.4806) | Xent 0.0000(0.0000) | Loss 8.9795(9.6384) | Error 0.0000(0.0000) Steps 742(733.08) | Grad Norm 4.1264(2.6868) | Total Time 0.00(0.00)\n",
      "Iter 2783 | Time 84.5586(82.9644) | Bit/dim 3.4874(3.4808) | Xent 0.0000(0.0000) | Loss 8.8969(9.6161) | Error 0.0000(0.0000) Steps 736(733.17) | Grad Norm 3.5226(2.7119) | Total Time 0.00(0.00)\n",
      "Iter 2784 | Time 85.6312(83.0444) | Bit/dim 3.4793(3.4808) | Xent 0.0000(0.0000) | Loss 8.8534(9.5932) | Error 0.0000(0.0000) Steps 736(733.26) | Grad Norm 2.7130(2.7119) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 26.2835, Epoch Time 543.5255(530.9000), Bit/dim 3.4788(best: 3.4776), Xent 0.0000, Loss 3.4788, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2785 | Time 82.5637(83.0300) | Bit/dim 3.4850(3.4809) | Xent 0.0000(0.0000) | Loss 13.5333(9.7114) | Error 0.0000(0.0000) Steps 724(732.98) | Grad Norm 1.9824(2.6901) | Total Time 0.00(0.00)\n",
      "Iter 2786 | Time 86.8972(83.1460) | Bit/dim 3.4675(3.4805) | Xent 0.0000(0.0000) | Loss 8.7817(9.6836) | Error 0.0000(0.0000) Steps 748(733.43) | Grad Norm 2.2729(2.6775) | Total Time 0.00(0.00)\n",
      "Iter 2787 | Time 83.8541(83.1673) | Bit/dim 3.4673(3.4801) | Xent 0.0000(0.0000) | Loss 8.9819(9.6625) | Error 0.0000(0.0000) Steps 736(733.51) | Grad Norm 3.3943(2.6990) | Total Time 0.00(0.00)\n",
      "Iter 2788 | Time 84.4940(83.2071) | Bit/dim 3.4923(3.4805) | Xent 0.0000(0.0000) | Loss 8.8516(9.6382) | Error 0.0000(0.0000) Steps 730(733.40) | Grad Norm 4.2195(2.7447) | Total Time 0.00(0.00)\n",
      "Iter 2789 | Time 83.7190(83.2224) | Bit/dim 3.4784(3.4804) | Xent 0.0000(0.0000) | Loss 8.8841(9.6156) | Error 0.0000(0.0000) Steps 736(733.48) | Grad Norm 4.2825(2.7908) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 80.1823(83.1312) | Bit/dim 3.4876(3.4806) | Xent 0.0000(0.0000) | Loss 8.9296(9.5950) | Error 0.0000(0.0000) Steps 718(733.01) | Grad Norm 3.1736(2.8023) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 25.9349, Epoch Time 543.5868(531.2806), Bit/dim 3.4811(best: 3.4776), Xent 0.0000, Loss 3.4811, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2791 | Time 74.2534(82.8649) | Bit/dim 3.4864(3.4808) | Xent 0.0000(0.0000) | Loss 13.4658(9.7111) | Error 0.0000(0.0000) Steps 706(732.20) | Grad Norm 1.7167(2.7697) | Total Time 0.00(0.00)\n",
      "Iter 2792 | Time 79.7258(82.7707) | Bit/dim 3.4867(3.4810) | Xent 0.0000(0.0000) | Loss 9.0099(9.6901) | Error 0.0000(0.0000) Steps 730(732.14) | Grad Norm 1.6659(2.7366) | Total Time 0.00(0.00)\n",
      "Iter 2793 | Time 83.8460(82.8030) | Bit/dim 3.4739(3.4808) | Xent 0.0000(0.0000) | Loss 8.9143(9.6668) | Error 0.0000(0.0000) Steps 742(732.43) | Grad Norm 2.8282(2.7393) | Total Time 0.00(0.00)\n",
      "Iter 2794 | Time 86.7092(82.9202) | Bit/dim 3.4742(3.4806) | Xent 0.0000(0.0000) | Loss 8.9664(9.6458) | Error 0.0000(0.0000) Steps 730(732.36) | Grad Norm 3.7528(2.7698) | Total Time 0.00(0.00)\n",
      "Iter 2795 | Time 86.1275(83.0164) | Bit/dim 3.4723(3.4803) | Xent 0.0000(0.0000) | Loss 8.8642(9.6223) | Error 0.0000(0.0000) Steps 736(732.47) | Grad Norm 3.7410(2.7989) | Total Time 0.00(0.00)\n",
      "Iter 2796 | Time 81.1853(82.9614) | Bit/dim 3.4881(3.4806) | Xent 0.0000(0.0000) | Loss 8.7710(9.5968) | Error 0.0000(0.0000) Steps 736(732.58) | Grad Norm 2.7977(2.7989) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 26.6923, Epoch Time 534.6455(531.3815), Bit/dim 3.4809(best: 3.4776), Xent 0.0000, Loss 3.4809, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2797 | Time 80.3793(82.8840) | Bit/dim 3.4655(3.4801) | Xent 0.0000(0.0000) | Loss 13.5466(9.7153) | Error 0.0000(0.0000) Steps 724(732.32) | Grad Norm 1.8665(2.7709) | Total Time 0.00(0.00)\n",
      "Iter 2798 | Time 85.0987(82.9504) | Bit/dim 3.4779(3.4801) | Xent 0.0000(0.0000) | Loss 9.0448(9.6952) | Error 0.0000(0.0000) Steps 724(732.07) | Grad Norm 2.6137(2.7662) | Total Time 0.00(0.00)\n",
      "Iter 2799 | Time 82.9863(82.9515) | Bit/dim 3.4799(3.4800) | Xent 0.0000(0.0000) | Loss 8.7578(9.6670) | Error 0.0000(0.0000) Steps 736(732.19) | Grad Norm 3.7824(2.7967) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 78.9228(82.8306) | Bit/dim 3.4798(3.4800) | Xent 0.0000(0.0000) | Loss 8.9589(9.6458) | Error 0.0000(0.0000) Steps 700(731.22) | Grad Norm 3.9237(2.8305) | Total Time 0.00(0.00)\n",
      "Iter 2801 | Time 84.1382(82.8699) | Bit/dim 3.4785(3.4800) | Xent 0.0000(0.0000) | Loss 8.9012(9.6235) | Error 0.0000(0.0000) Steps 712(730.64) | Grad Norm 3.1629(2.8404) | Total Time 0.00(0.00)\n",
      "Iter 2802 | Time 84.6911(82.9245) | Bit/dim 3.4903(3.4803) | Xent 0.0000(0.0000) | Loss 8.9647(9.6037) | Error 0.0000(0.0000) Steps 718(730.27) | Grad Norm 2.1211(2.8189) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 25.8159, Epoch Time 538.3338(531.5901), Bit/dim 3.4792(best: 3.4776), Xent 0.0000, Loss 3.4792, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2803 | Time 87.7806(83.0702) | Bit/dim 3.4817(3.4803) | Xent 0.0000(0.0000) | Loss 13.9268(9.7334) | Error 0.0000(0.0000) Steps 730(730.26) | Grad Norm 0.9628(2.7632) | Total Time 0.00(0.00)\n",
      "Iter 2804 | Time 81.2843(83.0166) | Bit/dim 3.4797(3.4803) | Xent 0.0000(0.0000) | Loss 8.7712(9.7045) | Error 0.0000(0.0000) Steps 712(729.71) | Grad Norm 0.7345(2.7023) | Total Time 0.00(0.00)\n",
      "Iter 2805 | Time 86.9095(83.1334) | Bit/dim 3.4772(3.4802) | Xent 0.0000(0.0000) | Loss 8.9020(9.6805) | Error 0.0000(0.0000) Steps 760(730.62) | Grad Norm 1.5112(2.6666) | Total Time 0.00(0.00)\n",
      "Iter 2806 | Time 82.8488(83.1249) | Bit/dim 3.4731(3.4800) | Xent 0.0000(0.0000) | Loss 9.0656(9.6620) | Error 0.0000(0.0000) Steps 730(730.60) | Grad Norm 2.2947(2.6554) | Total Time 0.00(0.00)\n",
      "Iter 2807 | Time 86.1624(83.2160) | Bit/dim 3.4685(3.4797) | Xent 0.0000(0.0000) | Loss 8.9057(9.6393) | Error 0.0000(0.0000) Steps 730(730.58) | Grad Norm 2.8006(2.6598) | Total Time 0.00(0.00)\n",
      "Iter 2808 | Time 83.6323(83.2285) | Bit/dim 3.4851(3.4798) | Xent 0.0000(0.0000) | Loss 8.9671(9.6192) | Error 0.0000(0.0000) Steps 730(730.56) | Grad Norm 3.0973(2.6729) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 26.1535, Epoch Time 550.7095(532.1637), Bit/dim 3.4852(best: 3.4776), Xent 0.0000, Loss 3.4852, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2809 | Time 84.5637(83.2685) | Bit/dim 3.4817(3.4799) | Xent 0.0000(0.0000) | Loss 12.5561(9.7073) | Error 0.0000(0.0000) Steps 724(730.37) | Grad Norm 3.0813(2.6852) | Total Time 0.00(0.00)\n",
      "Iter 2810 | Time 80.0231(83.1712) | Bit/dim 3.4749(3.4797) | Xent 0.0000(0.0000) | Loss 8.6198(9.6746) | Error 0.0000(0.0000) Steps 730(730.36) | Grad Norm 3.1478(2.6990) | Total Time 0.00(0.00)\n",
      "Iter 2811 | Time 84.4788(83.2104) | Bit/dim 3.4938(3.4802) | Xent 0.0000(0.0000) | Loss 8.8918(9.6512) | Error 0.0000(0.0000) Steps 736(730.53) | Grad Norm 3.8102(2.7324) | Total Time 0.00(0.00)\n",
      "Iter 2812 | Time 80.2955(83.1229) | Bit/dim 3.4718(3.4799) | Xent 0.0000(0.0000) | Loss 8.8553(9.6273) | Error 0.0000(0.0000) Steps 724(730.33) | Grad Norm 3.7971(2.7643) | Total Time 0.00(0.00)\n",
      "Iter 2813 | Time 80.6169(83.0478) | Bit/dim 3.4890(3.4802) | Xent 0.0000(0.0000) | Loss 8.9431(9.6067) | Error 0.0000(0.0000) Steps 730(730.32) | Grad Norm 2.6451(2.7607) | Total Time 0.00(0.00)\n",
      "Iter 2814 | Time 85.6974(83.1273) | Bit/dim 3.4711(3.4799) | Xent 0.0000(0.0000) | Loss 8.9175(9.5861) | Error 0.0000(0.0000) Steps 724(730.13) | Grad Norm 1.0755(2.7102) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 25.8014, Epoch Time 537.1935(532.3146), Bit/dim 3.4799(best: 3.4776), Xent 0.0000, Loss 3.4799, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2815 | Time 80.7546(83.0561) | Bit/dim 3.4741(3.4797) | Xent 0.0000(0.0000) | Loss 13.5550(9.7051) | Error 0.0000(0.0000) Steps 712(729.59) | Grad Norm 1.2802(2.6673) | Total Time 0.00(0.00)\n",
      "Iter 2816 | Time 86.3428(83.1547) | Bit/dim 3.4854(3.4799) | Xent 0.0000(0.0000) | Loss 8.8761(9.6803) | Error 0.0000(0.0000) Steps 748(730.14) | Grad Norm 2.2231(2.6540) | Total Time 0.00(0.00)\n",
      "Iter 2817 | Time 82.7972(83.1440) | Bit/dim 3.4912(3.4802) | Xent 0.0000(0.0000) | Loss 8.8503(9.6554) | Error 0.0000(0.0000) Steps 730(730.13) | Grad Norm 3.1894(2.6700) | Total Time 0.00(0.00)\n",
      "Iter 2818 | Time 79.2898(83.0283) | Bit/dim 3.4824(3.4803) | Xent 0.0000(0.0000) | Loss 8.8083(9.6300) | Error 0.0000(0.0000) Steps 718(729.77) | Grad Norm 3.6956(2.7008) | Total Time 0.00(0.00)\n",
      "Iter 2819 | Time 85.6787(83.1078) | Bit/dim 3.4711(3.4800) | Xent 0.0000(0.0000) | Loss 9.1193(9.6146) | Error 0.0000(0.0000) Steps 748(730.32) | Grad Norm 3.5297(2.7256) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 83.2969(83.1135) | Bit/dim 3.4757(3.4799) | Xent 0.0000(0.0000) | Loss 8.9498(9.5947) | Error 0.0000(0.0000) Steps 742(730.67) | Grad Norm 3.8977(2.7608) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 25.5355, Epoch Time 539.6029(532.5332), Bit/dim 3.4812(best: 3.4776), Xent 0.0000, Loss 3.4812, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2821 | Time 74.9927(82.8699) | Bit/dim 3.4838(3.4800) | Xent 0.0000(0.0000) | Loss 12.8522(9.6924) | Error 0.0000(0.0000) Steps 706(729.93) | Grad Norm 4.0477(2.7994) | Total Time 0.00(0.00)\n",
      "Iter 2822 | Time 84.6707(82.9239) | Bit/dim 3.4816(3.4801) | Xent 0.0000(0.0000) | Loss 8.7911(9.6654) | Error 0.0000(0.0000) Steps 748(730.47) | Grad Norm 2.9994(2.8054) | Total Time 0.00(0.00)\n",
      "Iter 2823 | Time 81.8346(82.8912) | Bit/dim 3.4759(3.4799) | Xent 0.0000(0.0000) | Loss 8.8897(9.6421) | Error 0.0000(0.0000) Steps 754(731.18) | Grad Norm 2.0850(2.7838) | Total Time 0.00(0.00)\n",
      "Iter 2824 | Time 83.8912(82.9212) | Bit/dim 3.4660(3.4795) | Xent 0.0000(0.0000) | Loss 8.7008(9.6139) | Error 0.0000(0.0000) Steps 754(731.86) | Grad Norm 2.1988(2.7663) | Total Time 0.00(0.00)\n",
      "Iter 2825 | Time 87.4450(83.0569) | Bit/dim 3.4924(3.4799) | Xent 0.0000(0.0000) | Loss 8.9836(9.5950) | Error 0.0000(0.0000) Steps 760(732.70) | Grad Norm 2.6827(2.7637) | Total Time 0.00(0.00)\n",
      "Iter 2826 | Time 82.9411(83.0535) | Bit/dim 3.4765(3.4798) | Xent 0.0000(0.0000) | Loss 8.8337(9.5721) | Error 0.0000(0.0000) Steps 718(732.26) | Grad Norm 3.3118(2.7802) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 26.1235, Epoch Time 537.6909(532.6879), Bit/dim 3.4854(best: 3.4776), Xent 0.0000, Loss 3.4854, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2827 | Time 83.8460(83.0772) | Bit/dim 3.4779(3.4798) | Xent 0.0000(0.0000) | Loss 13.7153(9.6964) | Error 0.0000(0.0000) Steps 718(731.84) | Grad Norm 3.5952(2.8046) | Total Time 0.00(0.00)\n",
      "Iter 2828 | Time 83.2000(83.0809) | Bit/dim 3.4762(3.4796) | Xent 0.0000(0.0000) | Loss 9.0220(9.6762) | Error 0.0000(0.0000) Steps 748(732.32) | Grad Norm 3.1279(2.8143) | Total Time 0.00(0.00)\n",
      "Iter 2829 | Time 85.3899(83.1502) | Bit/dim 3.4744(3.4795) | Xent 0.0000(0.0000) | Loss 8.7287(9.6478) | Error 0.0000(0.0000) Steps 730(732.25) | Grad Norm 2.8223(2.8146) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 85.9123(83.2331) | Bit/dim 3.4744(3.4793) | Xent 0.0000(0.0000) | Loss 8.8887(9.6250) | Error 0.0000(0.0000) Steps 730(732.18) | Grad Norm 2.2233(2.7968) | Total Time 0.00(0.00)\n",
      "Iter 2831 | Time 79.3667(83.1171) | Bit/dim 3.4742(3.4792) | Xent 0.0000(0.0000) | Loss 8.7549(9.5989) | Error 0.0000(0.0000) Steps 706(731.40) | Grad Norm 1.8201(2.7675) | Total Time 0.00(0.00)\n",
      "Iter 2832 | Time 79.4089(83.0058) | Bit/dim 3.4755(3.4791) | Xent 0.0000(0.0000) | Loss 8.7596(9.5737) | Error 0.0000(0.0000) Steps 706(730.64) | Grad Norm 1.7169(2.7360) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 25.7247, Epoch Time 538.6492(532.8668), Bit/dim 3.4835(best: 3.4776), Xent 0.0000, Loss 3.4835, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2833 | Time 80.0894(82.9183) | Bit/dim 3.4742(3.4789) | Xent 0.0000(0.0000) | Loss 13.4626(9.6904) | Error 0.0000(0.0000) Steps 724(730.44) | Grad Norm 1.5219(2.6996) | Total Time 0.00(0.00)\n",
      "Iter 2834 | Time 83.1085(82.9240) | Bit/dim 3.4804(3.4790) | Xent 0.0000(0.0000) | Loss 8.9147(9.6671) | Error 0.0000(0.0000) Steps 736(730.60) | Grad Norm 1.4445(2.6619) | Total Time 0.00(0.00)\n",
      "Iter 2835 | Time 83.3651(82.9373) | Bit/dim 3.4747(3.4788) | Xent 0.0000(0.0000) | Loss 8.8160(9.6416) | Error 0.0000(0.0000) Steps 736(730.77) | Grad Norm 1.6944(2.6329) | Total Time 0.00(0.00)\n",
      "Iter 2836 | Time 84.3179(82.9787) | Bit/dim 3.4704(3.4786) | Xent 0.0000(0.0000) | Loss 8.8566(9.6180) | Error 0.0000(0.0000) Steps 730(730.74) | Grad Norm 2.1487(2.6184) | Total Time 0.00(0.00)\n",
      "Iter 2837 | Time 84.5804(83.0267) | Bit/dim 3.4736(3.4784) | Xent 0.0000(0.0000) | Loss 8.6299(9.5884) | Error 0.0000(0.0000) Steps 742(731.08) | Grad Norm 2.8187(2.6244) | Total Time 0.00(0.00)\n",
      "Iter 2838 | Time 80.8334(82.9609) | Bit/dim 3.4892(3.4788) | Xent 0.0000(0.0000) | Loss 8.9685(9.5698) | Error 0.0000(0.0000) Steps 730(731.05) | Grad Norm 3.3479(2.6461) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 26.2995, Epoch Time 538.5480(533.0372), Bit/dim 3.4824(best: 3.4776), Xent 0.0000, Loss 3.4824, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2839 | Time 82.6120(82.9505) | Bit/dim 3.4769(3.4787) | Xent 0.0000(0.0000) | Loss 13.2700(9.6808) | Error 0.0000(0.0000) Steps 736(731.20) | Grad Norm 3.6401(2.6759) | Total Time 0.00(0.00)\n",
      "Iter 2840 | Time 85.6055(83.0301) | Bit/dim 3.4721(3.4785) | Xent 0.0000(0.0000) | Loss 8.9566(9.6591) | Error 0.0000(0.0000) Steps 742(731.52) | Grad Norm 3.3694(2.6967) | Total Time 0.00(0.00)\n",
      "Iter 2841 | Time 85.7766(83.1125) | Bit/dim 3.4794(3.4785) | Xent 0.0000(0.0000) | Loss 8.8976(9.6362) | Error 0.0000(0.0000) Steps 748(732.02) | Grad Norm 3.2217(2.7125) | Total Time 0.00(0.00)\n",
      "Iter 2842 | Time 87.4029(83.2412) | Bit/dim 3.4885(3.4788) | Xent 0.0000(0.0000) | Loss 9.0423(9.6184) | Error 0.0000(0.0000) Steps 754(732.67) | Grad Norm 3.2305(2.7280) | Total Time 0.00(0.00)\n",
      "Iter 2843 | Time 85.9134(83.3214) | Bit/dim 3.4760(3.4788) | Xent 0.0000(0.0000) | Loss 8.8416(9.5951) | Error 0.0000(0.0000) Steps 730(732.59) | Grad Norm 3.1519(2.7407) | Total Time 0.00(0.00)\n",
      "Iter 2844 | Time 85.1174(83.3753) | Bit/dim 3.4812(3.4788) | Xent 0.0000(0.0000) | Loss 8.9282(9.5751) | Error 0.0000(0.0000) Steps 736(732.70) | Grad Norm 3.1000(2.7515) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 26.3984, Epoch Time 555.0089(533.6964), Bit/dim 3.4792(best: 3.4776), Xent 0.0000, Loss 3.4792, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2845 | Time 80.5264(83.2898) | Bit/dim 3.4730(3.4787) | Xent 0.0000(0.0000) | Loss 13.6244(9.6966) | Error 0.0000(0.0000) Steps 724(732.44) | Grad Norm 3.0418(2.7602) | Total Time 0.00(0.00)\n",
      "Iter 2846 | Time 80.7011(83.2121) | Bit/dim 3.4776(3.4786) | Xent 0.0000(0.0000) | Loss 8.7043(9.6668) | Error 0.0000(0.0000) Steps 718(732.00) | Grad Norm 3.2163(2.7739) | Total Time 0.00(0.00)\n",
      "Iter 2847 | Time 82.7222(83.1974) | Bit/dim 3.4716(3.4784) | Xent 0.0000(0.0000) | Loss 8.8994(9.6438) | Error 0.0000(0.0000) Steps 766(733.02) | Grad Norm 3.4494(2.7942) | Total Time 0.00(0.00)\n",
      "Iter 2848 | Time 86.0059(83.2817) | Bit/dim 3.4819(3.4785) | Xent 0.0000(0.0000) | Loss 8.8347(9.6195) | Error 0.0000(0.0000) Steps 736(733.11) | Grad Norm 3.5363(2.8164) | Total Time 0.00(0.00)\n",
      "Iter 2849 | Time 84.1445(83.3076) | Bit/dim 3.4824(3.4786) | Xent 0.0000(0.0000) | Loss 8.7332(9.5929) | Error 0.0000(0.0000) Steps 748(733.56) | Grad Norm 3.3295(2.8318) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 83.0234(83.2991) | Bit/dim 3.4721(3.4784) | Xent 0.0000(0.0000) | Loss 8.9107(9.5724) | Error 0.0000(0.0000) Steps 736(733.63) | Grad Norm 3.1373(2.8410) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 25.9889, Epoch Time 538.8649(533.8514), Bit/dim 3.4785(best: 3.4776), Xent 0.0000, Loss 3.4785, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2851 | Time 80.6294(83.2190) | Bit/dim 3.4811(3.4785) | Xent 0.0000(0.0000) | Loss 13.3901(9.6870) | Error 0.0000(0.0000) Steps 736(733.70) | Grad Norm 2.8942(2.8426) | Total Time 0.00(0.00)\n",
      "Iter 2852 | Time 83.2417(83.2197) | Bit/dim 3.4835(3.4787) | Xent 0.0000(0.0000) | Loss 8.6499(9.6559) | Error 0.0000(0.0000) Steps 730(733.59) | Grad Norm 2.6485(2.8368) | Total Time 0.00(0.00)\n",
      "Iter 2853 | Time 79.5845(83.1106) | Bit/dim 3.4820(3.4788) | Xent 0.0000(0.0000) | Loss 8.6354(9.6253) | Error 0.0000(0.0000) Steps 706(732.76) | Grad Norm 2.6394(2.8308) | Total Time 0.00(0.00)\n",
      "Iter 2854 | Time 80.9173(83.0448) | Bit/dim 3.4758(3.4787) | Xent 0.0000(0.0000) | Loss 8.8862(9.6031) | Error 0.0000(0.0000) Steps 742(733.04) | Grad Norm 2.2439(2.8132) | Total Time 0.00(0.00)\n",
      "Iter 2855 | Time 81.3182(82.9930) | Bit/dim 3.4698(3.4784) | Xent 0.0000(0.0000) | Loss 8.8893(9.5817) | Error 0.0000(0.0000) Steps 742(733.31) | Grad Norm 2.0177(2.7894) | Total Time 0.00(0.00)\n",
      "Iter 2856 | Time 87.9802(83.1426) | Bit/dim 3.4788(3.4784) | Xent 0.0000(0.0000) | Loss 9.0343(9.5652) | Error 0.0000(0.0000) Steps 766(734.29) | Grad Norm 2.1524(2.7703) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 25.8343, Epoch Time 535.4059(533.8981), Bit/dim 3.4808(best: 3.4776), Xent 0.0000, Loss 3.4808, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2857 | Time 84.5527(83.1849) | Bit/dim 3.4815(3.4785) | Xent 0.0000(0.0000) | Loss 13.7414(9.6905) | Error 0.0000(0.0000) Steps 736(734.34) | Grad Norm 2.4966(2.7620) | Total Time 0.00(0.00)\n",
      "Iter 2858 | Time 77.3416(83.0096) | Bit/dim 3.4783(3.4785) | Xent 0.0000(0.0000) | Loss 8.4104(9.6521) | Error 0.0000(0.0000) Steps 718(733.85) | Grad Norm 2.9127(2.7666) | Total Time 0.00(0.00)\n",
      "Iter 2859 | Time 78.9671(82.8883) | Bit/dim 3.4672(3.4782) | Xent 0.0000(0.0000) | Loss 8.7552(9.6252) | Error 0.0000(0.0000) Steps 712(733.20) | Grad Norm 3.0128(2.7740) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 80.9319(82.8297) | Bit/dim 3.4734(3.4780) | Xent 0.0000(0.0000) | Loss 8.5891(9.5941) | Error 0.0000(0.0000) Steps 712(732.56) | Grad Norm 2.8793(2.7771) | Total Time 0.00(0.00)\n",
      "Iter 2861 | Time 79.4823(82.7292) | Bit/dim 3.4704(3.4778) | Xent 0.0000(0.0000) | Loss 8.8982(9.5733) | Error 0.0000(0.0000) Steps 736(732.66) | Grad Norm 2.5889(2.7715) | Total Time 0.00(0.00)\n",
      "Iter 2862 | Time 80.2535(82.6550) | Bit/dim 3.4803(3.4779) | Xent 0.0000(0.0000) | Loss 8.8240(9.5508) | Error 0.0000(0.0000) Steps 724(732.40) | Grad Norm 2.3204(2.7579) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 25.9212, Epoch Time 523.0489(533.5726), Bit/dim 3.4784(best: 3.4776), Xent 0.0000, Loss 3.4784, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2863 | Time 82.4356(82.6484) | Bit/dim 3.4716(3.4777) | Xent 0.0000(0.0000) | Loss 13.3768(9.6656) | Error 0.0000(0.0000) Steps 724(732.15) | Grad Norm 2.0827(2.7377) | Total Time 0.00(0.00)\n",
      "Iter 2864 | Time 81.7112(82.6203) | Bit/dim 3.4781(3.4777) | Xent 0.0000(0.0000) | Loss 8.7183(9.6371) | Error 0.0000(0.0000) Steps 712(731.55) | Grad Norm 1.9739(2.7148) | Total Time 0.00(0.00)\n",
      "Iter 2865 | Time 82.5993(82.6196) | Bit/dim 3.4727(3.4775) | Xent 0.0000(0.0000) | Loss 8.7942(9.6119) | Error 0.0000(0.0000) Steps 724(731.32) | Grad Norm 2.7471(2.7157) | Total Time 0.00(0.00)\n",
      "Iter 2866 | Time 85.0478(82.6925) | Bit/dim 3.4788(3.4776) | Xent 0.0000(0.0000) | Loss 8.7725(9.5867) | Error 0.0000(0.0000) Steps 730(731.28) | Grad Norm 3.4983(2.7392) | Total Time 0.00(0.00)\n",
      "Iter 2867 | Time 83.9220(82.7294) | Bit/dim 3.4776(3.4776) | Xent 0.0000(0.0000) | Loss 9.0110(9.5694) | Error 0.0000(0.0000) Steps 742(731.60) | Grad Norm 3.7228(2.7687) | Total Time 0.00(0.00)\n",
      "Iter 2868 | Time 79.8979(82.6444) | Bit/dim 3.4890(3.4779) | Xent 0.0000(0.0000) | Loss 8.7912(9.5461) | Error 0.0000(0.0000) Steps 718(731.19) | Grad Norm 3.6259(2.7944) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 25.8935, Epoch Time 537.2275(533.6822), Bit/dim 3.4794(best: 3.4776), Xent 0.0000, Loss 3.4794, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2869 | Time 83.0771(82.6574) | Bit/dim 3.4796(3.4780) | Xent 0.0000(0.0000) | Loss 13.3925(9.6615) | Error 0.0000(0.0000) Steps 724(730.98) | Grad Norm 2.7477(2.7930) | Total Time 0.00(0.00)\n",
      "Iter 2870 | Time 89.2728(82.8559) | Bit/dim 3.4727(3.4778) | Xent 0.0000(0.0000) | Loss 8.6975(9.6325) | Error 0.0000(0.0000) Steps 748(731.49) | Grad Norm 2.1408(2.7735) | Total Time 0.00(0.00)\n",
      "Iter 2871 | Time 82.4047(82.8423) | Bit/dim 3.4662(3.4775) | Xent 0.0000(0.0000) | Loss 9.0196(9.6141) | Error 0.0000(0.0000) Steps 730(731.44) | Grad Norm 3.0079(2.7805) | Total Time 0.00(0.00)\n",
      "Iter 2872 | Time 83.4697(82.8611) | Bit/dim 3.4901(3.4778) | Xent 0.0000(0.0000) | Loss 8.9109(9.5931) | Error 0.0000(0.0000) Steps 718(731.04) | Grad Norm 4.1905(2.8228) | Total Time 0.00(0.00)\n",
      "Iter 2873 | Time 88.2753(83.0236) | Bit/dim 3.4675(3.4775) | Xent 0.0000(0.0000) | Loss 8.9362(9.5733) | Error 0.0000(0.0000) Steps 742(731.37) | Grad Norm 4.3350(2.8682) | Total Time 0.00(0.00)\n",
      "Iter 2874 | Time 84.8790(83.0792) | Bit/dim 3.4820(3.4777) | Xent 0.0000(0.0000) | Loss 8.7899(9.5498) | Error 0.0000(0.0000) Steps 736(731.51) | Grad Norm 3.4758(2.8864) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 25.8852, Epoch Time 553.2515(534.2693), Bit/dim 3.4792(best: 3.4776), Xent 0.0000, Loss 3.4792, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2875 | Time 84.8948(83.1337) | Bit/dim 3.4860(3.4779) | Xent 0.0000(0.0000) | Loss 13.6038(9.6715) | Error 0.0000(0.0000) Steps 748(732.00) | Grad Norm 1.9941(2.8596) | Total Time 0.00(0.00)\n",
      "Iter 2876 | Time 83.1903(83.1354) | Bit/dim 3.4859(3.4782) | Xent 0.0000(0.0000) | Loss 9.0011(9.6513) | Error 0.0000(0.0000) Steps 748(732.48) | Grad Norm 0.4102(2.7861) | Total Time 0.00(0.00)\n",
      "Iter 2877 | Time 79.8673(83.0374) | Bit/dim 3.4844(3.4783) | Xent 0.0000(0.0000) | Loss 8.7077(9.6230) | Error 0.0000(0.0000) Steps 718(732.05) | Grad Norm 1.6009(2.7506) | Total Time 0.00(0.00)\n",
      "Iter 2878 | Time 83.9052(83.0634) | Bit/dim 3.4681(3.4780) | Xent 0.0000(0.0000) | Loss 8.8776(9.6007) | Error 0.0000(0.0000) Steps 742(732.35) | Grad Norm 2.6592(2.7478) | Total Time 0.00(0.00)\n",
      "Iter 2879 | Time 84.5752(83.1087) | Bit/dim 3.4701(3.4778) | Xent 0.0000(0.0000) | Loss 8.6999(9.5737) | Error 0.0000(0.0000) Steps 736(732.46) | Grad Norm 3.2687(2.7635) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 81.3142(83.0549) | Bit/dim 3.4627(3.4773) | Xent 0.0000(0.0000) | Loss 8.6699(9.5465) | Error 0.0000(0.0000) Steps 730(732.38) | Grad Norm 3.3301(2.7805) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 25.9533, Epoch Time 539.7611(534.4341), Bit/dim 3.4776(best: 3.4776), Xent 0.0000, Loss 3.4776, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2881 | Time 82.3390(83.0334) | Bit/dim 3.4699(3.4771) | Xent 0.0000(0.0000) | Loss 13.5448(9.6665) | Error 0.0000(0.0000) Steps 730(732.31) | Grad Norm 2.7679(2.7801) | Total Time 0.00(0.00)\n",
      "Iter 2882 | Time 87.9962(83.1823) | Bit/dim 3.4766(3.4771) | Xent 0.0000(0.0000) | Loss 8.9438(9.6448) | Error 0.0000(0.0000) Steps 772(733.50) | Grad Norm 2.1193(2.7603) | Total Time 0.00(0.00)\n",
      "Iter 2883 | Time 82.4598(83.1606) | Bit/dim 3.4732(3.4770) | Xent 0.0000(0.0000) | Loss 8.8183(9.6200) | Error 0.0000(0.0000) Steps 730(733.40) | Grad Norm 2.8229(2.7621) | Total Time 0.00(0.00)\n",
      "Iter 2884 | Time 85.2216(83.2225) | Bit/dim 3.4818(3.4771) | Xent 0.0000(0.0000) | Loss 8.9440(9.5997) | Error 0.0000(0.0000) Steps 748(733.84) | Grad Norm 4.1711(2.8044) | Total Time 0.00(0.00)\n",
      "Iter 2885 | Time 83.8775(83.2421) | Bit/dim 3.4828(3.4773) | Xent 0.0000(0.0000) | Loss 8.8561(9.5774) | Error 0.0000(0.0000) Steps 742(734.08) | Grad Norm 4.3618(2.8511) | Total Time 0.00(0.00)\n",
      "Iter 2886 | Time 83.1831(83.2403) | Bit/dim 3.4732(3.4772) | Xent 0.0000(0.0000) | Loss 8.8678(9.5561) | Error 0.0000(0.0000) Steps 742(734.32) | Grad Norm 3.0161(2.8561) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 25.6289, Epoch Time 546.8495(534.8065), Bit/dim 3.4779(best: 3.4776), Xent 0.0000, Loss 3.4779, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2887 | Time 86.0901(83.3258) | Bit/dim 3.4645(3.4768) | Xent 0.0000(0.0000) | Loss 13.7996(9.6834) | Error 0.0000(0.0000) Steps 724(734.01) | Grad Norm 1.5093(2.8157) | Total Time 0.00(0.00)\n",
      "Iter 2888 | Time 90.5958(83.5439) | Bit/dim 3.4737(3.4767) | Xent 0.0000(0.0000) | Loss 8.9764(9.6622) | Error 0.0000(0.0000) Steps 754(734.61) | Grad Norm 0.7421(2.7535) | Total Time 0.00(0.00)\n",
      "Iter 2889 | Time 81.9655(83.4966) | Bit/dim 3.4700(3.4765) | Xent 0.0000(0.0000) | Loss 8.9133(9.6398) | Error 0.0000(0.0000) Steps 748(735.01) | Grad Norm 1.6177(2.7194) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 84.1352(83.5157) | Bit/dim 3.4790(3.4766) | Xent 0.0000(0.0000) | Loss 8.9954(9.6204) | Error 0.0000(0.0000) Steps 742(735.22) | Grad Norm 3.0412(2.7291) | Total Time 0.00(0.00)\n",
      "Iter 2891 | Time 84.1471(83.5347) | Bit/dim 3.4885(3.4769) | Xent 0.0000(0.0000) | Loss 8.9321(9.5998) | Error 0.0000(0.0000) Steps 730(735.06) | Grad Norm 3.7842(2.7607) | Total Time 0.00(0.00)\n",
      "Iter 2892 | Time 85.5956(83.5965) | Bit/dim 3.4883(3.4773) | Xent 0.0000(0.0000) | Loss 8.7879(9.5754) | Error 0.0000(0.0000) Steps 742(735.27) | Grad Norm 3.7334(2.7899) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 26.4814, Epoch Time 554.7215(535.4040), Bit/dim 3.4774(best: 3.4776), Xent 0.0000, Loss 3.4774, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2893 | Time 86.0813(83.6711) | Bit/dim 3.4814(3.4774) | Xent 0.0000(0.0000) | Loss 13.7671(9.7012) | Error 0.0000(0.0000) Steps 742(735.47) | Grad Norm 3.3224(2.8059) | Total Time 0.00(0.00)\n",
      "Iter 2894 | Time 83.4889(83.6656) | Bit/dim 3.4749(3.4773) | Xent 0.0000(0.0000) | Loss 8.7787(9.6735) | Error 0.0000(0.0000) Steps 742(735.67) | Grad Norm 2.8054(2.8058) | Total Time 0.00(0.00)\n",
      "Iter 2895 | Time 82.7064(83.6368) | Bit/dim 3.4574(3.4767) | Xent 0.0000(0.0000) | Loss 8.7798(9.6467) | Error 0.0000(0.0000) Steps 736(735.68) | Grad Norm 2.3670(2.7927) | Total Time 0.00(0.00)\n",
      "Iter 2896 | Time 83.7592(83.6405) | Bit/dim 3.4729(3.4766) | Xent 0.0000(0.0000) | Loss 8.8977(9.6242) | Error 0.0000(0.0000) Steps 748(736.05) | Grad Norm 2.7058(2.7901) | Total Time 0.00(0.00)\n",
      "Iter 2897 | Time 90.9972(83.8612) | Bit/dim 3.4877(3.4769) | Xent 0.0000(0.0000) | Loss 9.1353(9.6096) | Error 0.0000(0.0000) Steps 790(737.67) | Grad Norm 3.2954(2.8052) | Total Time 0.00(0.00)\n",
      "Iter 2898 | Time 83.0243(83.8361) | Bit/dim 3.4754(3.4769) | Xent 0.0000(0.0000) | Loss 8.8393(9.5864) | Error 0.0000(0.0000) Steps 724(737.26) | Grad Norm 3.4758(2.8254) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 26.1965, Epoch Time 552.1013(535.9049), Bit/dim 3.4805(best: 3.4774), Xent 0.0000, Loss 3.4805, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2899 | Time 81.6727(83.7712) | Bit/dim 3.4754(3.4769) | Xent 0.0000(0.0000) | Loss 13.5403(9.7051) | Error 0.0000(0.0000) Steps 754(737.76) | Grad Norm 2.7444(2.8229) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 81.1966(83.6939) | Bit/dim 3.4756(3.4768) | Xent 0.0000(0.0000) | Loss 8.9064(9.6811) | Error 0.0000(0.0000) Steps 712(736.99) | Grad Norm 1.6757(2.7885) | Total Time 0.00(0.00)\n",
      "Iter 2901 | Time 89.5010(83.8682) | Bit/dim 3.4755(3.4768) | Xent 0.0000(0.0000) | Loss 9.0253(9.6614) | Error 0.0000(0.0000) Steps 772(738.04) | Grad Norm 0.7468(2.7273) | Total Time 0.00(0.00)\n",
      "Iter 2902 | Time 85.5543(83.9187) | Bit/dim 3.4781(3.4768) | Xent 0.0000(0.0000) | Loss 8.9540(9.6402) | Error 0.0000(0.0000) Steps 730(737.80) | Grad Norm 0.7946(2.6693) | Total Time 0.00(0.00)\n",
      "Iter 2903 | Time 82.3614(83.8720) | Bit/dim 3.4701(3.4766) | Xent 0.0000(0.0000) | Loss 8.6806(9.6114) | Error 0.0000(0.0000) Steps 718(737.20) | Grad Norm 1.6679(2.6392) | Total Time 0.00(0.00)\n",
      "Iter 2904 | Time 85.2677(83.9139) | Bit/dim 3.4769(3.4766) | Xent 0.0000(0.0000) | Loss 8.9338(9.5911) | Error 0.0000(0.0000) Steps 766(738.07) | Grad Norm 2.5752(2.6373) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 26.4306, Epoch Time 547.9665(536.2667), Bit/dim 3.4794(best: 3.4774), Xent 0.0000, Loss 3.4794, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2905 | Time 83.0763(83.8888) | Bit/dim 3.4783(3.4767) | Xent 0.0000(0.0000) | Loss 13.5751(9.7106) | Error 0.0000(0.0000) Steps 766(738.90) | Grad Norm 3.1249(2.6519) | Total Time 0.00(0.00)\n",
      "Iter 2906 | Time 84.3291(83.9020) | Bit/dim 3.4792(3.4767) | Xent 0.0000(0.0000) | Loss 8.9004(9.6863) | Error 0.0000(0.0000) Steps 748(739.18) | Grad Norm 3.0096(2.6627) | Total Time 0.00(0.00)\n",
      "Iter 2907 | Time 83.0193(83.8755) | Bit/dim 3.4720(3.4766) | Xent 0.0000(0.0000) | Loss 8.8212(9.6604) | Error 0.0000(0.0000) Steps 760(739.80) | Grad Norm 2.5573(2.6595) | Total Time 0.00(0.00)\n",
      "Iter 2908 | Time 81.7600(83.8120) | Bit/dim 3.4744(3.4765) | Xent 0.0000(0.0000) | Loss 9.0301(9.6414) | Error 0.0000(0.0000) Steps 748(740.05) | Grad Norm 1.8192(2.6343) | Total Time 0.00(0.00)\n",
      "Iter 2909 | Time 83.9970(83.8176) | Bit/dim 3.4725(3.4764) | Xent 0.0000(0.0000) | Loss 8.9959(9.6221) | Error 0.0000(0.0000) Steps 754(740.47) | Grad Norm 0.9932(2.5851) | Total Time 0.00(0.00)\n",
      "Iter 2910 | Time 80.7805(83.7265) | Bit/dim 3.4748(3.4764) | Xent 0.0000(0.0000) | Loss 8.8767(9.5997) | Error 0.0000(0.0000) Steps 736(740.33) | Grad Norm 1.0918(2.5403) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 27.0592, Epoch Time 539.9590(536.3775), Bit/dim 3.4757(best: 3.4774), Xent 0.0000, Loss 3.4757, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2911 | Time 85.0860(83.7672) | Bit/dim 3.4673(3.4761) | Xent 0.0000(0.0000) | Loss 13.6955(9.7226) | Error 0.0000(0.0000) Steps 730(740.02) | Grad Norm 1.7054(2.5152) | Total Time 0.00(0.00)\n",
      "Iter 2912 | Time 81.2142(83.6907) | Bit/dim 3.4907(3.4765) | Xent 0.0000(0.0000) | Loss 9.0009(9.7009) | Error 0.0000(0.0000) Steps 742(740.08) | Grad Norm 2.5833(2.5173) | Total Time 0.00(0.00)\n",
      "Iter 2913 | Time 84.1507(83.7045) | Bit/dim 3.4788(3.4766) | Xent 0.0000(0.0000) | Loss 8.9581(9.6787) | Error 0.0000(0.0000) Steps 742(740.14) | Grad Norm 3.7292(2.5536) | Total Time 0.00(0.00)\n",
      "Iter 2914 | Time 84.7899(83.7370) | Bit/dim 3.4722(3.4765) | Xent 0.0000(0.0000) | Loss 8.9488(9.6568) | Error 0.0000(0.0000) Steps 766(740.91) | Grad Norm 4.4493(2.6105) | Total Time 0.00(0.00)\n",
      "Iter 2915 | Time 84.6150(83.7634) | Bit/dim 3.4808(3.4766) | Xent 0.0000(0.0000) | Loss 8.9754(9.6363) | Error 0.0000(0.0000) Steps 742(740.95) | Grad Norm 4.2475(2.6596) | Total Time 0.00(0.00)\n",
      "Iter 2916 | Time 91.2681(83.9885) | Bit/dim 3.4721(3.4765) | Xent 0.0000(0.0000) | Loss 8.8833(9.6137) | Error 0.0000(0.0000) Steps 748(741.16) | Grad Norm 3.7828(2.6933) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 26.2460, Epoch Time 553.4523(536.8898), Bit/dim 3.4793(best: 3.4757), Xent 0.0000, Loss 3.4793, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2917 | Time 86.6991(84.0698) | Bit/dim 3.4849(3.4767) | Xent 0.0000(0.0000) | Loss 14.2504(9.7528) | Error 0.0000(0.0000) Steps 778(742.26) | Grad Norm 3.5830(2.7200) | Total Time 0.00(0.00)\n",
      "Iter 2918 | Time 81.6670(83.9977) | Bit/dim 3.4832(3.4769) | Xent 0.0000(0.0000) | Loss 9.0315(9.7312) | Error 0.0000(0.0000) Steps 742(742.26) | Grad Norm 3.7173(2.7499) | Total Time 0.00(0.00)\n",
      "Iter 2919 | Time 80.4088(83.8901) | Bit/dim 3.4664(3.4766) | Xent 0.0000(0.0000) | Loss 8.7777(9.7026) | Error 0.0000(0.0000) Steps 736(742.07) | Grad Norm 4.0234(2.7881) | Total Time 0.00(0.00)\n",
      "Iter 2920 | Time 85.4894(83.9380) | Bit/dim 3.4735(3.4765) | Xent 0.0000(0.0000) | Loss 8.8472(9.6769) | Error 0.0000(0.0000) Steps 748(742.25) | Grad Norm 3.8227(2.8192) | Total Time 0.00(0.00)\n",
      "Iter 2921 | Time 87.0566(84.0316) | Bit/dim 3.4615(3.4761) | Xent 0.0000(0.0000) | Loss 8.8808(9.6530) | Error 0.0000(0.0000) Steps 742(742.24) | Grad Norm 3.2722(2.8327) | Total Time 0.00(0.00)\n",
      "Iter 2922 | Time 85.4238(84.0734) | Bit/dim 3.4818(3.4762) | Xent 0.0000(0.0000) | Loss 9.1518(9.6380) | Error 0.0000(0.0000) Steps 766(742.95) | Grad Norm 2.6869(2.8284) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 26.5028, Epoch Time 549.1856(537.2586), Bit/dim 3.4758(best: 3.4757), Xent 0.0000, Loss 3.4758, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2923 | Time 85.2216(84.1078) | Bit/dim 3.4780(3.4763) | Xent 0.0000(0.0000) | Loss 13.2664(9.7469) | Error 0.0000(0.0000) Steps 736(742.74) | Grad Norm 2.1838(2.8090) | Total Time 0.00(0.00)\n",
      "Iter 2924 | Time 86.2646(84.1725) | Bit/dim 3.4720(3.4762) | Xent 0.0000(0.0000) | Loss 8.7939(9.7183) | Error 0.0000(0.0000) Steps 742(742.72) | Grad Norm 1.1948(2.7606) | Total Time 0.00(0.00)\n",
      "Iter 2925 | Time 81.8169(84.1019) | Bit/dim 3.4724(3.4760) | Xent 0.0000(0.0000) | Loss 8.9682(9.6958) | Error 0.0000(0.0000) Steps 742(742.70) | Grad Norm 0.8232(2.7025) | Total Time 0.00(0.00)\n",
      "Iter 2926 | Time 80.3760(83.9901) | Bit/dim 3.4708(3.4759) | Xent 0.0000(0.0000) | Loss 8.7965(9.6688) | Error 0.0000(0.0000) Steps 718(741.96) | Grad Norm 1.5711(2.6685) | Total Time 0.00(0.00)\n",
      "Iter 2927 | Time 81.0558(83.9020) | Bit/dim 3.4730(3.4758) | Xent 0.0000(0.0000) | Loss 8.8571(9.6444) | Error 0.0000(0.0000) Steps 718(741.24) | Grad Norm 2.2616(2.6563) | Total Time 0.00(0.00)\n",
      "Iter 2928 | Time 83.4828(83.8895) | Bit/dim 3.4792(3.4759) | Xent 0.0000(0.0000) | Loss 8.8918(9.6219) | Error 0.0000(0.0000) Steps 748(741.44) | Grad Norm 2.7554(2.6593) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 26.0274, Epoch Time 539.9352(537.3389), Bit/dim 3.4770(best: 3.4757), Xent 0.0000, Loss 3.4770, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2929 | Time 85.1408(83.9270) | Bit/dim 3.4676(3.4756) | Xent 0.0000(0.0000) | Loss 13.3392(9.7334) | Error 0.0000(0.0000) Steps 718(740.74) | Grad Norm 2.8338(2.6645) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 88.5051(84.0644) | Bit/dim 3.4761(3.4757) | Xent 0.0000(0.0000) | Loss 8.7005(9.7024) | Error 0.0000(0.0000) Steps 748(740.96) | Grad Norm 2.5214(2.6602) | Total Time 0.00(0.00)\n",
      "Iter 2931 | Time 88.2864(84.1910) | Bit/dim 3.4819(3.4758) | Xent 0.0000(0.0000) | Loss 8.8559(9.6770) | Error 0.0000(0.0000) Steps 748(741.17) | Grad Norm 2.3232(2.6501) | Total Time 0.00(0.00)\n",
      "Iter 2932 | Time 84.9229(84.2130) | Bit/dim 3.4770(3.4759) | Xent 0.0000(0.0000) | Loss 8.7631(9.6496) | Error 0.0000(0.0000) Steps 742(741.19) | Grad Norm 1.7757(2.6239) | Total Time 0.00(0.00)\n",
      "Iter 2933 | Time 83.3148(84.1860) | Bit/dim 3.4786(3.4760) | Xent 0.0000(0.0000) | Loss 8.8613(9.6259) | Error 0.0000(0.0000) Steps 718(740.50) | Grad Norm 1.6338(2.5942) | Total Time 0.00(0.00)\n",
      "Iter 2934 | Time 83.5662(84.1674) | Bit/dim 3.4730(3.4759) | Xent 0.0000(0.0000) | Loss 8.6873(9.5978) | Error 0.0000(0.0000) Steps 724(740.00) | Grad Norm 1.9177(2.5739) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0489 | Time 26.2243, Epoch Time 556.2450(537.9061), Bit/dim 3.4763(best: 3.4757), Xent 0.0000, Loss 3.4763, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2935 | Time 83.4925(84.1472) | Bit/dim 3.4829(3.4761) | Xent 0.0000(0.0000) | Loss 13.9500(9.7283) | Error 0.0000(0.0000) Steps 724(739.52) | Grad Norm 2.1691(2.5618) | Total Time 0.00(0.00)\n",
      "Iter 2936 | Time 90.5348(84.3388) | Bit/dim 3.4787(3.4762) | Xent 0.0000(0.0000) | Loss 8.8917(9.7032) | Error 0.0000(0.0000) Steps 742(739.60) | Grad Norm 2.8903(2.5716) | Total Time 0.00(0.00)\n",
      "Iter 2937 | Time 89.8264(84.5034) | Bit/dim 3.4769(3.4762) | Xent 0.0000(0.0000) | Loss 8.8406(9.6774) | Error 0.0000(0.0000) Steps 742(739.67) | Grad Norm 3.8093(2.6087) | Total Time 0.00(0.00)\n",
      "Iter 2938 | Time 84.1691(84.4934) | Bit/dim 3.4817(3.4764) | Xent 0.0000(0.0000) | Loss 9.0027(9.6571) | Error 0.0000(0.0000) Steps 754(740.10) | Grad Norm 4.2885(2.6591) | Total Time 0.00(0.00)\n",
      "Iter 2939 | Time 86.1611(84.5434) | Bit/dim 3.4742(3.4763) | Xent 0.0000(0.0000) | Loss 9.0394(9.6386) | Error 0.0000(0.0000) Steps 778(741.24) | Grad Norm 4.1534(2.7040) | Total Time 0.00(0.00)\n",
      "Iter 2940 | Time 84.5744(84.5444) | Bit/dim 3.4658(3.4760) | Xent 0.0000(0.0000) | Loss 8.9213(9.6171) | Error 0.0000(0.0000) Steps 742(741.26) | Grad Norm 3.4757(2.7271) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0490 | Time 26.3907, Epoch Time 560.9437(538.5972), Bit/dim 3.4797(best: 3.4757), Xent 0.0000, Loss 3.4797, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2941 | Time 83.7249(84.5198) | Bit/dim 3.4652(3.4756) | Xent 0.0000(0.0000) | Loss 14.0220(9.7492) | Error 0.0000(0.0000) Steps 736(741.10) | Grad Norm 2.6840(2.7258) | Total Time 0.00(0.00)\n",
      "Iter 2942 | Time 80.0129(84.3846) | Bit/dim 3.4803(3.4758) | Xent 0.0000(0.0000) | Loss 8.6914(9.7175) | Error 0.0000(0.0000) Steps 712(740.23) | Grad Norm 2.6575(2.7238) | Total Time 0.00(0.00)\n",
      "Iter 2943 | Time 81.1188(84.2866) | Bit/dim 3.4783(3.4759) | Xent 0.0000(0.0000) | Loss 8.9299(9.6939) | Error 0.0000(0.0000) Steps 730(739.92) | Grad Norm 3.1200(2.7357) | Total Time 0.00(0.00)\n",
      "Iter 2944 | Time 84.1273(84.2818) | Bit/dim 3.4777(3.4759) | Xent 0.0000(0.0000) | Loss 9.0389(9.6742) | Error 0.0000(0.0000) Steps 772(740.88) | Grad Norm 3.1427(2.7479) | Total Time 0.00(0.00)\n",
      "Iter 2945 | Time 83.7984(84.2673) | Bit/dim 3.4688(3.4757) | Xent 0.0000(0.0000) | Loss 8.6483(9.6434) | Error 0.0000(0.0000) Steps 730(740.56) | Grad Norm 2.9924(2.7552) | Total Time 0.00(0.00)\n",
      "Iter 2946 | Time 84.5245(84.2750) | Bit/dim 3.4831(3.4759) | Xent 0.0000(0.0000) | Loss 8.7906(9.6178) | Error 0.0000(0.0000) Steps 742(740.60) | Grad Norm 2.7116(2.7539) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0491 | Time 26.7298, Epoch Time 539.6944(538.6302), Bit/dim 3.4729(best: 3.4757), Xent 0.0000, Loss 3.4729, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2947 | Time 88.2864(84.3954) | Bit/dim 3.4693(3.4757) | Xent 0.0000(0.0000) | Loss 13.9321(9.7473) | Error 0.0000(0.0000) Steps 760(741.18) | Grad Norm 2.2696(2.7394) | Total Time 0.00(0.00)\n",
      "Iter 2948 | Time 87.0359(84.4746) | Bit/dim 3.4776(3.4758) | Xent 0.0000(0.0000) | Loss 8.9013(9.7219) | Error 0.0000(0.0000) Steps 730(740.85) | Grad Norm 2.3223(2.7269) | Total Time 0.00(0.00)\n",
      "Iter 2949 | Time 85.7221(84.5120) | Bit/dim 3.4739(3.4757) | Xent 0.0000(0.0000) | Loss 8.8531(9.6958) | Error 0.0000(0.0000) Steps 766(741.60) | Grad Norm 2.9242(2.7328) | Total Time 0.00(0.00)\n",
      "Iter 2950 | Time 85.6114(84.5450) | Bit/dim 3.4726(3.4756) | Xent 0.0000(0.0000) | Loss 8.5313(9.6609) | Error 0.0000(0.0000) Steps 742(741.61) | Grad Norm 3.6334(2.7598) | Total Time 0.00(0.00)\n",
      "Iter 2951 | Time 86.0268(84.5895) | Bit/dim 3.4729(3.4756) | Xent 0.0000(0.0000) | Loss 8.8636(9.6370) | Error 0.0000(0.0000) Steps 736(741.44) | Grad Norm 4.0092(2.7973) | Total Time 0.00(0.00)\n",
      "Iter 2952 | Time 86.1691(84.6368) | Bit/dim 3.4804(3.4757) | Xent 0.0000(0.0000) | Loss 9.0483(9.6193) | Error 0.0000(0.0000) Steps 760(742.00) | Grad Norm 3.6596(2.8231) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0492 | Time 26.0936, Epoch Time 560.6868(539.2919), Bit/dim 3.4745(best: 3.4729), Xent 0.0000, Loss 3.4745, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2953 | Time 88.5745(84.7550) | Bit/dim 3.4634(3.4753) | Xent 0.0000(0.0000) | Loss 13.8443(9.7461) | Error 0.0000(0.0000) Steps 748(742.18) | Grad Norm 2.7440(2.8208) | Total Time 0.00(0.00)\n",
      "Iter 2954 | Time 82.2046(84.6785) | Bit/dim 3.4914(3.4758) | Xent 0.0000(0.0000) | Loss 8.8151(9.7181) | Error 0.0000(0.0000) Steps 748(742.36) | Grad Norm 1.9995(2.7961) | Total Time 0.00(0.00)\n",
      "Iter 2955 | Time 79.2925(84.5169) | Bit/dim 3.4693(3.4756) | Xent 0.0000(0.0000) | Loss 8.8382(9.6917) | Error 0.0000(0.0000) Steps 712(741.45) | Grad Norm 1.6396(2.7614) | Total Time 0.00(0.00)\n",
      "Iter 2956 | Time 85.4575(84.5451) | Bit/dim 3.4801(3.4757) | Xent 0.0000(0.0000) | Loss 8.7818(9.6644) | Error 0.0000(0.0000) Steps 742(741.46) | Grad Norm 2.0859(2.7412) | Total Time 0.00(0.00)\n",
      "Iter 2957 | Time 88.5140(84.6642) | Bit/dim 3.4760(3.4758) | Xent 0.0000(0.0000) | Loss 8.7680(9.6375) | Error 0.0000(0.0000) Steps 760(742.02) | Grad Norm 2.8255(2.7437) | Total Time 0.00(0.00)\n",
      "Iter 2958 | Time 86.9708(84.7334) | Bit/dim 3.4616(3.4753) | Xent 0.0000(0.0000) | Loss 8.7384(9.6106) | Error 0.0000(0.0000) Steps 742(742.02) | Grad Norm 3.4675(2.7654) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0493 | Time 25.7845, Epoch Time 552.6535(539.6927), Bit/dim 3.4780(best: 3.4729), Xent 0.0000, Loss 3.4780, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2959 | Time 82.1154(84.6548) | Bit/dim 3.4817(3.4755) | Xent 0.0000(0.0000) | Loss 13.8189(9.7368) | Error 0.0000(0.0000) Steps 742(742.02) | Grad Norm 3.5049(2.7876) | Total Time 0.00(0.00)\n",
      "Iter 2960 | Time 77.3553(84.4358) | Bit/dim 3.4709(3.4754) | Xent 0.0000(0.0000) | Loss 8.6063(9.7029) | Error 0.0000(0.0000) Steps 700(740.76) | Grad Norm 2.9029(2.7911) | Total Time 0.00(0.00)\n",
      "Iter 2961 | Time 88.3769(84.5541) | Bit/dim 3.4718(3.4753) | Xent 0.0000(0.0000) | Loss 8.9351(9.6799) | Error 0.0000(0.0000) Steps 772(741.69) | Grad Norm 1.6849(2.7579) | Total Time 0.00(0.00)\n",
      "Iter 2962 | Time 86.4352(84.6105) | Bit/dim 3.4759(3.4753) | Xent 0.0000(0.0000) | Loss 8.5861(9.6471) | Error 0.0000(0.0000) Steps 724(741.16) | Grad Norm 1.0357(2.7062) | Total Time 0.00(0.00)\n",
      "Iter 2963 | Time 81.6670(84.5222) | Bit/dim 3.4753(3.4753) | Xent 0.0000(0.0000) | Loss 8.7152(9.6191) | Error 0.0000(0.0000) Steps 760(741.73) | Grad Norm 1.9912(2.6848) | Total Time 0.00(0.00)\n",
      "Iter 2964 | Time 86.9122(84.5939) | Bit/dim 3.4625(3.4749) | Xent 0.0000(0.0000) | Loss 8.8520(9.5961) | Error 0.0000(0.0000) Steps 736(741.56) | Grad Norm 3.0388(2.6954) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0494 | Time 26.4418, Epoch Time 545.5852(539.8695), Bit/dim 3.4754(best: 3.4729), Xent 0.0000, Loss 3.4754, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2965 | Time 87.8520(84.6916) | Bit/dim 3.4706(3.4748) | Xent 0.0000(0.0000) | Loss 13.8567(9.7239) | Error 0.0000(0.0000) Steps 760(742.11) | Grad Norm 3.7003(2.7255) | Total Time 0.00(0.00)\n",
      "Iter 2966 | Time 87.7290(84.7828) | Bit/dim 3.4614(3.4744) | Xent 0.0000(0.0000) | Loss 8.9174(9.6997) | Error 0.0000(0.0000) Steps 772(743.01) | Grad Norm 3.8661(2.7597) | Total Time 0.00(0.00)\n",
      "Iter 2967 | Time 87.0200(84.8499) | Bit/dim 3.4898(3.4748) | Xent 0.0000(0.0000) | Loss 8.8919(9.6755) | Error 0.0000(0.0000) Steps 760(743.52) | Grad Norm 3.2551(2.7746) | Total Time 0.00(0.00)\n",
      "Iter 2968 | Time 88.2946(84.9532) | Bit/dim 3.4815(3.4750) | Xent 0.0000(0.0000) | Loss 8.9823(9.6547) | Error 0.0000(0.0000) Steps 748(743.65) | Grad Norm 2.1584(2.7561) | Total Time 0.00(0.00)\n",
      "Iter 2969 | Time 82.0352(84.8657) | Bit/dim 3.4675(3.4748) | Xent 0.0000(0.0000) | Loss 8.7898(9.6287) | Error 0.0000(0.0000) Steps 718(742.88) | Grad Norm 1.0078(2.7037) | Total Time 0.00(0.00)\n",
      "Iter 2970 | Time 85.4084(84.8820) | Bit/dim 3.4727(3.4748) | Xent 0.0000(0.0000) | Loss 8.9501(9.6084) | Error 0.0000(0.0000) Steps 778(743.93) | Grad Norm 1.1490(2.6570) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0495 | Time 25.8518, Epoch Time 560.4304(540.4863), Bit/dim 3.4750(best: 3.4729), Xent 0.0000, Loss 3.4750, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2971 | Time 83.0783(84.8279) | Bit/dim 3.4677(3.4745) | Xent 0.0000(0.0000) | Loss 13.9868(9.7397) | Error 0.0000(0.0000) Steps 730(743.52) | Grad Norm 2.3431(2.6476) | Total Time 0.00(0.00)\n",
      "Iter 2972 | Time 81.1406(84.7172) | Bit/dim 3.4729(3.4745) | Xent 0.0000(0.0000) | Loss 8.7795(9.7109) | Error 0.0000(0.0000) Steps 748(743.65) | Grad Norm 3.2196(2.6648) | Total Time 0.00(0.00)\n",
      "Iter 2973 | Time 84.3997(84.7077) | Bit/dim 3.4824(3.4747) | Xent 0.0000(0.0000) | Loss 8.8830(9.6861) | Error 0.0000(0.0000) Steps 754(743.96) | Grad Norm 3.3195(2.6844) | Total Time 0.00(0.00)\n",
      "Iter 2974 | Time 89.0226(84.8372) | Bit/dim 3.4733(3.4747) | Xent 0.0000(0.0000) | Loss 8.9280(9.6633) | Error 0.0000(0.0000) Steps 748(744.08) | Grad Norm 2.7332(2.6859) | Total Time 0.00(0.00)\n",
      "Iter 2975 | Time 82.0404(84.7533) | Bit/dim 3.4713(3.4746) | Xent 0.0000(0.0000) | Loss 8.8231(9.6381) | Error 0.0000(0.0000) Steps 742(744.02) | Grad Norm 2.4578(2.6790) | Total Time 0.00(0.00)\n",
      "Iter 2976 | Time 82.1578(84.6754) | Bit/dim 3.4780(3.4747) | Xent 0.0000(0.0000) | Loss 8.5631(9.6059) | Error 0.0000(0.0000) Steps 712(743.06) | Grad Norm 2.8598(2.6845) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0496 | Time 26.1750, Epoch Time 543.8058(540.5859), Bit/dim 3.4757(best: 3.4729), Xent 0.0000, Loss 3.4757, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2977 | Time 80.9951(84.5650) | Bit/dim 3.4978(3.4754) | Xent 0.0000(0.0000) | Loss 12.9233(9.7054) | Error 0.0000(0.0000) Steps 718(742.31) | Grad Norm 3.0727(2.6961) | Total Time 0.00(0.00)\n",
      "Iter 2978 | Time 82.7611(84.5109) | Bit/dim 3.4660(3.4751) | Xent 0.0000(0.0000) | Loss 8.8093(9.6785) | Error 0.0000(0.0000) Steps 736(742.12) | Grad Norm 2.8514(2.7008) | Total Time 0.00(0.00)\n",
      "Iter 2979 | Time 87.6737(84.6058) | Bit/dim 3.4711(3.4750) | Xent 0.0000(0.0000) | Loss 8.7877(9.6518) | Error 0.0000(0.0000) Steps 772(743.02) | Grad Norm 2.7215(2.7014) | Total Time 0.00(0.00)\n",
      "Iter 2980 | Time 87.5178(84.6931) | Bit/dim 3.4725(3.4749) | Xent 0.0000(0.0000) | Loss 8.5688(9.6193) | Error 0.0000(0.0000) Steps 736(742.80) | Grad Norm 2.5341(2.6964) | Total Time 0.00(0.00)\n",
      "Iter 2981 | Time 81.0244(84.5831) | Bit/dim 3.4713(3.4748) | Xent 0.0000(0.0000) | Loss 8.6681(9.5908) | Error 0.0000(0.0000) Steps 742(742.78) | Grad Norm 1.9849(2.6750) | Total Time 0.00(0.00)\n",
      "Iter 2982 | Time 80.6854(84.4661) | Bit/dim 3.4790(3.4749) | Xent 0.0000(0.0000) | Loss 8.7454(9.5654) | Error 0.0000(0.0000) Steps 730(742.40) | Grad Norm 1.3016(2.6338) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0497 | Time 27.0445, Epoch Time 543.9439(540.6866), Bit/dim 3.4747(best: 3.4729), Xent 0.0000, Loss 3.4747, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2983 | Time 85.0319(84.4831) | Bit/dim 3.4811(3.4751) | Xent 0.0000(0.0000) | Loss 13.1608(9.6733) | Error 0.0000(0.0000) Steps 730(742.03) | Grad Norm 1.1605(2.5896) | Total Time 0.00(0.00)\n",
      "Iter 2984 | Time 89.0281(84.6194) | Bit/dim 3.4671(3.4749) | Xent 0.0000(0.0000) | Loss 8.9298(9.6510) | Error 0.0000(0.0000) Steps 766(742.74) | Grad Norm 1.4698(2.5560) | Total Time 0.00(0.00)\n",
      "Iter 2985 | Time 80.6141(84.4993) | Bit/dim 3.4647(3.4746) | Xent 0.0000(0.0000) | Loss 8.8409(9.6267) | Error 0.0000(0.0000) Steps 736(742.54) | Grad Norm 2.3371(2.5495) | Total Time 0.00(0.00)\n",
      "Iter 2986 | Time 81.5928(84.4121) | Bit/dim 3.4684(3.4744) | Xent 0.0000(0.0000) | Loss 8.8508(9.6034) | Error 0.0000(0.0000) Steps 730(742.17) | Grad Norm 3.6692(2.5830) | Total Time 0.00(0.00)\n",
      "Iter 2987 | Time 83.2661(84.3777) | Bit/dim 3.4722(3.4743) | Xent 0.0000(0.0000) | Loss 8.9628(9.5842) | Error 0.0000(0.0000) Steps 742(742.16) | Grad Norm 4.7032(2.6467) | Total Time 0.00(0.00)\n",
      "Iter 2988 | Time 76.6827(84.1469) | Bit/dim 3.4924(3.4749) | Xent 0.0000(0.0000) | Loss 8.7598(9.5594) | Error 0.0000(0.0000) Steps 718(741.44) | Grad Norm 4.8959(2.7141) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0498 | Time 26.6747, Epoch Time 538.8313(540.6310), Bit/dim 3.4762(best: 3.4729), Xent 0.0000, Loss 3.4762, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2989 | Time 83.8167(84.1370) | Bit/dim 3.4700(3.4747) | Xent 0.0000(0.0000) | Loss 13.7602(9.6855) | Error 0.0000(0.0000) Steps 748(741.63) | Grad Norm 3.7049(2.7439) | Total Time 0.00(0.00)\n",
      "Iter 2990 | Time 79.1854(83.9884) | Bit/dim 3.4827(3.4750) | Xent 0.0000(0.0000) | Loss 8.8079(9.6591) | Error 0.0000(0.0000) Steps 724(741.10) | Grad Norm 2.0996(2.7245) | Total Time 0.00(0.00)\n",
      "Iter 2991 | Time 87.0709(84.0809) | Bit/dim 3.4692(3.4748) | Xent 0.0000(0.0000) | Loss 8.8298(9.6343) | Error 0.0000(0.0000) Steps 742(741.13) | Grad Norm 2.3256(2.7126) | Total Time 0.00(0.00)\n",
      "Iter 2992 | Time 76.9908(83.8682) | Bit/dim 3.4912(3.4753) | Xent 0.0000(0.0000) | Loss 8.7740(9.6085) | Error 0.0000(0.0000) Steps 724(740.62) | Grad Norm 3.4046(2.7333) | Total Time 0.00(0.00)\n",
      "Iter 2993 | Time 80.7925(83.7759) | Bit/dim 3.4738(3.4752) | Xent 0.0000(0.0000) | Loss 8.7570(9.5829) | Error 0.0000(0.0000) Steps 730(740.30) | Grad Norm 3.8989(2.7683) | Total Time 0.00(0.00)\n",
      "Iter 2994 | Time 81.1432(83.6969) | Bit/dim 3.4702(3.4751) | Xent 0.0000(0.0000) | Loss 8.7206(9.5570) | Error 0.0000(0.0000) Steps 730(739.99) | Grad Norm 3.6081(2.7935) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0499 | Time 25.8063, Epoch Time 530.6792(540.3324), Bit/dim 3.4712(best: 3.4729), Xent 0.0000, Loss 3.4712, Error 1.0000(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2995 | Time 84.3904(83.7177) | Bit/dim 3.4851(3.4754) | Xent 0.0000(0.0000) | Loss 13.2086(9.6666) | Error 0.0000(0.0000) Steps 736(739.87) | Grad Norm 2.4633(2.7836) | Total Time 0.00(0.00)\n",
      "Iter 2996 | Time 78.7823(83.5697) | Bit/dim 3.4786(3.4755) | Xent 0.0000(0.0000) | Loss 8.8560(9.6423) | Error 0.0000(0.0000) Steps 730(739.57) | Grad Norm 1.1128(2.7335) | Total Time 0.00(0.00)\n",
      "Iter 2997 | Time 89.0948(83.7354) | Bit/dim 3.4694(3.4753) | Xent 0.0000(0.0000) | Loss 9.0054(9.6232) | Error 0.0000(0.0000) Steps 772(740.55) | Grad Norm 1.1656(2.6864) | Total Time 0.00(0.00)\n",
      "Iter 2998 | Time 84.0859(83.7459) | Bit/dim 3.4679(3.4751) | Xent 0.0000(0.0000) | Loss 8.9339(9.6025) | Error 0.0000(0.0000) Steps 742(740.59) | Grad Norm 2.2539(2.6734) | Total Time 0.00(0.00)\n",
      "Iter 2999 | Time 87.2970(83.8525) | Bit/dim 3.4766(3.4751) | Xent 0.0000(0.0000) | Loss 8.7816(9.5779) | Error 0.0000(0.0000) Steps 730(740.27) | Grad Norm 3.4332(2.6962) | Total Time 0.00(0.00)\n",
      "Iter 3000 | Time 90.4386(84.0501) | Bit/dim 3.4807(3.4753) | Xent 0.0000(0.0000) | Loss 8.9741(9.5597) | Error 0.0000(0.0000) Steps 766(741.04) | Grad Norm 3.7654(2.7283) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0500 | Time 26.6071, Epoch Time 556.5106(540.8178), Bit/dim 3.4726(best: 3.4712), Xent 0.0000, Loss 3.4726, Error 1.0000(best: inf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         2007746207 function calls (1974551081 primitive calls) in 151147.754 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "     1800 102547.130   56.971 102547.130   56.971 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
       "   525475 41386.413    0.079 41386.413    0.079 {method 'acquire' of '_thread.lock' objects}\n",
       " 17400000  744.379    0.000 1268.391    0.000 train_cnf_disentangle_rl.py:307(add_noise)\n",
       " 17400300  472.956    0.000  472.956    0.000 {method 'tobytes' of 'numpy.ndarray' objects}\n",
       " 17400200  424.350    0.000  424.350    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
       "   518427  413.764    0.001  413.764    0.001 {method '_write_file' of 'torch._C.CudaFloatStorageBase' objects}\n",
       " 17400000  384.767    0.000 1794.233    0.000 functional.py:32(to_tensor)\n",
       " 17400000  296.468    0.000  296.468    0.000 {method 'div' of 'torch._C._TensorBase' objects}\n",
       " 17400000  206.160    0.000  206.160    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
       " 17400600  201.369    0.000 1583.467    0.000 Image.py:2457(fromarray)\n",
       " 17400000  188.318    0.000  188.318    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
       "332251593/332116385  164.667    0.000  165.890    0.000 {built-in method builtins.isinstance}\n",
       "     2400  162.740    0.068  162.740    0.068 {built-in method stack}\n",
       " 17400000  154.022    0.000 5319.092    0.000 cifar.py:103(__getitem__)\n",
       " 31943252  130.791    0.000  193.773    0.000 module.py:537(__setattr__)\n",
       " 17400000  125.852    0.000  387.260    0.000 Image.py:711(tobytes)\n",
       " 17400000  121.566    0.000 3524.022    0.000 transforms.py:47(__call__)\n",
       " 34800000  108.135    0.000  108.135    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}\n",
       " 18662700  105.708    0.000  105.708    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
       " 17400600   98.432    0.000  379.561    0.000 Image.py:2322(new)\n",
       " 52201800   85.092    0.000  133.645    0.000 Image.py:2304(_check_size)\n",
       "     1272   77.974    0.061   77.975    0.061 {built-in method io.open}\n",
       " 17400600   76.922    0.000  125.688    0.000 Image.py:430(_getdecoder)\n",
       "175579867/175560267   74.844    0.000   74.867    0.000 {built-in method builtins.len}\n",
       " 24599381   73.561    0.000  116.574    0.000 Image.py:553(_new)\n",
       " 17400600   73.045    0.000   73.045    0.000 {built-in method PIL._imaging.fill}\n",
       "59549060/59549051   71.654    0.000   71.697    0.000 {built-in method builtins.hasattr}\n",
       " 17400600   71.546    0.000  262.110    0.000 Image.py:779(frombytes)\n",
       " 17400600   70.304    0.000  765.299    0.000 Image.py:2353(frombytes)\n",
       " 17401200   69.864    0.000   69.864    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
       "      740   67.110    0.091   67.110    0.091 {method 'flush' of '_io.BufferedWriter' objects}\n",
       "      300   63.287    0.211   63.287    0.211 {method 'encode_to_file' of 'ImagingEncoder' objects}\n",
       " 17400600   57.264    0.000   99.036    0.000 Image.py:451(_getencoder)\n",
       " 17400000   56.467    0.000  107.508    0.000 functional.py:172(resize)\n",
       " 41999981   55.613    0.000  117.394    0.000 Image.py:601(__del__)\n",
       " 17400000   55.430    0.000   55.430    0.000 {method 'resize_as_' of 'torch._C._TensorBase' objects}\n",
       " 41999981   53.832    0.000   53.832    0.000 Image.py:529(__init__)\n",
       "     2700   53.726    0.020  355.290    0.132 replicate.py:5(replicate)\n",
       " 17400600   52.817    0.000  880.095    0.000 Image.py:2396(frombuffer)\n",
       "     3600   49.224    0.014   49.224    0.014 {method 'pin_memory' of 'torch._C._TensorBase' objects}\n",
       "113264451   45.788    0.000   45.789    0.000 {method 'get' of 'dict' objects}\n",
       " 17400790   44.251    0.000   44.251    0.000 {method 'new' of 'torch._C._TensorBase' objects}\n",
       " 41998481   43.503    0.000   61.215    0.000 functional.py:17(_is_pil_image)\n",
       " 17400000   42.846    0.000   42.846    0.000 {built-in method from_buffer}\n",
       "   156300   38.779    0.000   38.779    0.000 {built-in method torch._C._gather}\n",
       "    73500   38.075    0.001   38.075    0.001 {method 'sort' of 'numpy.ndarray' objects}\n",
       " 24599981   36.109    0.000   51.356    0.000 Image.py:809(load)\n",
       " 17400600   35.691    0.000   35.691    0.000 {method 'decode' of 'ImagingDecoder' objects}\n",
       "     5400   35.153    0.007   35.153    0.007 {built-in method torch._C._broadcast_coalesced}\n",
       "    73500   34.775    0.000  116.695    0.002 summary.py:150(make_histogram)\n",
       "     2400   34.337    0.014 5353.429    2.231 dataloader.py:615(<listcomp>)\n",
       "34740687/3756804   33.284    0.000   36.821    0.000 module.py:938(named_modules)\n",
       " 69602700   31.343    0.000   31.343    0.000 Image.py:549(size)\n",
       " 17400000   30.515    0.000 1824.748    0.000 transforms.py:68(__call__)\n",
       " 35358439   30.510    0.000   30.510    0.000 {built-in method builtins.getattr}\n",
       " 17400000   29.131    0.000  136.639    0.000 transforms.py:167(__call__)\n",
       " 14400000   28.333    0.000  148.856    0.000 transforms.py:439(__call__)\n",
       "        1   27.948   27.948 151147.738 151147.738 train_cnf_disentangle_rl.py:1(<module>)\n",
       "     3000   26.604    0.009 5645.906    1.882 dataloader.py:612(__next__)\n",
       " 17400600   25.752    0.000   25.752    0.000 {built-in method PIL._imaging.raw_decoder}\n",
       "     6271   24.124    0.004   24.137    0.004 {method 'to' of 'torch._C._TensorBase' objects}\n",
       " 13702271   22.964    0.000   41.082    0.000 serialization.py:234(persistent_id)\n",
       "  7198481   22.092    0.000   22.092    0.000 {method 'transpose' of 'ImagingCore' objects}\n",
       "   209700   22.065    0.000   22.065    0.000 {method 'cpu' of 'torch._C._TensorBase' objects}\n",
       "     3000   20.702    0.007   37.120    0.012 sampler.py:158(__iter__)\n",
       " 43487662   19.896    0.000   19.896    0.000 {method 'append' of 'list' objects}\n",
       " 17400000   19.450    0.000   19.450    0.000 {built-in method PIL._imaging.raw_encoder}\n",
       " 17476914   19.345    0.000   19.345    0.000 {built-in method builtins.max}\n",
       " 32526588   19.309    0.000   19.309    0.000 {method 'copy' of 'dict' objects}\n",
       "   441000   18.998    0.000   18.998    0.000 {built-in method norm}\n",
       "  7198481   18.874    0.000   89.324    0.000 Image.py:2241(transpose)\n",
       "   479603   18.859    0.000   18.859    0.000 {built-in method numpy.core.multiarray.array}\n",
       "     5100   17.714    0.003   17.714    0.003 {built-in method torch._C._scatter}\n",
       " 17400900   17.302    0.000   25.146    0.000 _util.py:7(isStringType)\n",
       "7200/2400   15.440    0.002  179.391    0.075 dataloader.py:196(default_collate)\n",
       " 24599981   15.247    0.000   15.247    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
       "   882000   14.961    0.000   14.961    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n",
       " 17400600   14.784    0.000   14.784    0.000 {method 'setimage' of 'ImagingDecoder' objects}\n",
       " 23781607   14.636    0.000   14.636    0.000 {method 'copy' of 'collections.OrderedDict' objects}\n",
       "     2700   14.392    0.005 41308.759   15.300 module.py:483(__call__)\n",
       "  7198481   13.615    0.000  112.274    0.000 functional.py:335(hflip)\n",
       "   882000   13.492    0.000   13.492    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
       " 17400600   12.911    0.000   12.911    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
       "      633   11.826    0.019   57.997    0.092 {method 'dump' of '_pickle.Pickler' objects}\n",
       "     2705   11.314    0.004   11.314    0.004 {method 'flush' of '_io.TextIOWrapper' objects}\n",
       "   470400   10.010    0.000   10.010    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
       "    17724    9.822    0.001    9.822    0.001 {method '_write_file' of 'torch._C.CudaLongStorageBase' objects}\n",
       "     1800    8.600    0.005   56.367    0.031 adam.py:49(step)\n",
       " 17401801    8.559    0.000    8.559    0.000 {method 'join' of 'bytes' objects}\n",
       " 14400000    8.249    0.000    8.249    0.000 {method 'random' of '_random.Random' objects}\n",
       "    69000    7.872    0.000    7.872    0.000 {method 'mean' of 'torch._C._TensorBase' objects}\n",
       " 13702271    7.473    0.000    7.473    0.000 __init__.py:128(is_storage)\n",
       "    13533    6.873    0.001    6.873    0.001 socket.py:334(send)\n",
       "   164100    6.773    0.000  107.510    0.001 {built-in method apply}\n",
       "   441000    6.599    0.000    6.599    0.000 {method 'sqrt' of 'torch._C._TensorBase' objects}\n",
       "    73500    6.354    0.000  124.978    0.002 summary.py:126(histogram)\n",
       "    73501    6.277    0.000    6.277    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
       "  1486638    6.225    0.000   42.885    0.000 module.py:771(_named_members)\n",
       "   441000    5.916    0.000    5.916    0.000 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n",
       "    73500    5.872    0.000    5.872    0.000 {method 'clone' of 'torch._C._TensorBase' objects}\n",
       "   441000    5.564    0.000    5.564    0.000 {method 'addcmul_' of 'torch._C._TensorBase' objects}\n",
       "   294920    4.956    0.000    4.956    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       " 11853652    4.823    0.000    4.823    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
       "  5327560    4.321    0.000    6.435    0.000 tensor.py:416(__hash__)\n",
       "  3197720    4.229    0.000    5.487    0.000 module.py:891(named_children)\n",
       "     6693    4.147    0.001    4.147    0.001 {built-in method posix.stat}\n",
       "  6845818    3.916    0.000    5.651    0.000 {method 'add' of 'set' objects}\n",
       "1371980/3601    3.829    0.000   13.450    0.004 module.py:203(apply)\n",
       "   156300    3.698    0.000   56.498    0.000 _functions.py:52(forward)\n",
       "   162001    3.673    0.000  539.598    0.003 writer.py:82(add_summary)\n",
       "  7930068    3.479    0.000    3.479    0.000 {built-in method __new__ of type object at 0x5634e8c0ed60}\n",
       "  3197720    3.301    0.000    8.788    0.000 module.py:882(children)\n",
       "   536151    3.228    0.000    5.090    0.000 tensor.py:33(__reduce_ex__)\n",
       "     1800    3.143    0.002   45.625    0.025 clip_grad.py:6(clip_grad_norm_)\n",
       "   147000    2.638    0.000    2.638    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
       "   440843    2.353    0.000    2.353    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
       "258264/633    2.338    0.000    2.791    0.004 module.py:602(state_dict)\n",
       "    85800    2.312    0.000   10.639    0.000 summary.py:105(scalar)\n",
       "  5643034    2.247    0.000    2.247    0.000 {built-in method builtins.id}\n",
       "   162001    2.060    0.000  534.024    0.003 queue.py:115(put)\n",
       "  1764801    2.056    0.000    2.736    0.000 module.py:829(<lambda>)\n",
       "      300    2.028    0.007   11.521    0.038 summary.py:184(image)\n",
       "    85800    1.894    0.000   39.541    0.000 writer.py:344(add_scalars)\n",
       "    73500    1.718    0.000   69.288    0.001 histograms.py:597(histogram)\n",
       "   536152    1.609    0.000    1.609    0.000 serialization.py:149(_is_compressed_file)\n",
       "      633    1.605    0.003  553.742    0.875 serialization.py:221(_save)\n",
       "   315667    1.600    0.000    4.181    0.000 {built-in method builtins.all}\n",
       "   191419    1.478    0.000    1.478    0.000 {method 'release' of '_thread.lock' objects}\n",
       "   245400    1.396    0.000   23.753    0.000 x2num.py:10(make_np)\n",
       "    85800    1.330    0.000   18.249    0.000 writer.py:303(__append_to_scalar_dict)\n",
       "   134700    1.320    0.000   19.811    0.000 x2num.py:27(prepare_pytorch)\n",
       "    21707    1.303    0.000    1.303    0.000 {built-in method _thread.start_new_thread}\n",
       "    73500    1.282    0.000   22.272    0.000 histograms.py:297(_get_bin_edges)\n",
       "      300    1.272    0.004    1.272    0.004 {built-in method randperm}\n",
       "  1360800    1.228    0.000    5.379    0.000 _functions.py:60(<genexpr>)\n",
       "    74413    1.218    0.000    1.218    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "   536152    1.215    0.000    3.298    0.000 serialization.py:157(_should_read_directly)\n",
       "      720    1.194    0.002    1.194    0.002 {method 'update' of '_hashlib.HASH' objects}\n",
       "   536151    1.166    0.000    2.658    0.000 serialization.py:102(location_tag)\n",
       "  1788885    1.151    0.000    1.151    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
       "169800/2700    1.141    0.000   60.518    0.022 scatter_gather.py:51(gather_map)\n",
       "228600/600    1.137    0.000    5.328    0.009 module.py:976(train)\n",
       "     2400    1.136    0.000  164.245    0.068 dataloader.py:232(<listcomp>)\n",
       "  1371000    1.129    0.000    1.617    0.000 _functions.py:59(<genexpr>)\n",
       "  1181538    1.087    0.000   31.273    0.000 module.py:808(named_parameters)\n",
       "  1250400    1.079    0.000    1.797    0.000 _functions.py:67(<lambda>)\n",
       "  1250400    1.065    0.000    1.855    0.000 _functions.py:58(<lambda>)\n",
       "   441000    1.051    0.000   20.273    0.000 functional.py:607(norm)\n",
       "    73500    1.039    0.000    1.269    0.000 function_base.py:1079(diff)\n",
       "    73500    1.014    0.000  659.689    0.009 writer.py:390(add_histogram)\n",
       "   162001    0.997    0.000  535.637    0.003 writer.py:137(_add_event)\n",
       "   162001    0.983    0.000    2.893    0.000 threading.py:334(notify)\n",
       "   147000    0.981    0.000    0.981    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
       "   990900    0.977    0.000    1.340    0.000 module.py:877(<lambda>)\n",
       "  1107738    0.942    0.000   28.980    0.000 module.py:784(parameters)\n",
       "   209700    0.936    0.000    0.936    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
       "    81409    0.902    0.000  549.085    0.007 threading.py:263(wait)\n",
       "     1800    0.902    0.001    3.551    0.002 optimizer.py:157(zero_grad)\n",
       "   536151    0.840    0.000    1.124    0.000 serialization.py:57(_cuda_tag)\n",
       "    73540    0.828    0.000    0.828    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "        1    0.823    0.823    0.823    0.823 {built-in method caffe2.python.caffe2_pybind11_state_gpu.num_cuda_devices}\n",
       "  1258200    0.797    0.000    0.797    0.000 {method 'get_device' of 'torch._C._TensorBase' objects}\n",
       "   993600    0.780    0.000   10.086    0.000 module.py:911(modules)\n",
       "      819    0.726    0.001    0.726    0.001 {method '_set_from_file' of 'torch._C.FloatStorageBase' objects}\n",
       "   171960    0.724    0.000    2.146    0.000 numeric.py:1927(isscalar)\n",
       "  1656768    0.714    0.000    0.714    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
       "   441000    0.696    0.000   20.970    0.000 tensor.py:250(norm)\n",
       "      600    0.690    0.001    0.690    0.001 {method 'random_' of 'torch._C._TensorBase' objects}\n",
       "   147000    0.673    0.000   13.442    0.000 fromnumeric.py:2651(ndim)\n",
       "   160315    0.658    0.000    0.658    0.000 {method 'sub' of '_sre.SRE_Pattern' objects}\n",
       "      633    0.649    0.001  554.391    0.876 serialization.py:218(<lambda>)\n",
       "  1250400    0.641    0.000    0.641    0.000 _functions.py:54(<lambda>)\n",
       "    73802    0.641    0.000    0.641    0.000 {built-in method numpy.core.multiarray.zeros}\n",
       "   685800    0.623    0.000    1.814    0.000 train_misc.py:76(__call__)\n",
       "   144390    0.616    0.000    1.026    0.000 abc.py:180(__instancecheck__)\n",
       "   685800    0.579    0.000    0.912    0.000 train_misc.py:96(__call__)\n",
       "    73501    0.565    0.000    0.565    0.000 {built-in method numpy.core.multiarray.concatenate}\n",
       "      300    0.559    0.002    0.559    0.002 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
       "   536151    0.558    0.000    0.827    0.000 serialization.py:121(normalize_storage_type)\n",
       "   151493    0.549    0.000    0.550    0.000 {built-in method _warnings.warn}\n",
       "     2400    0.549    0.000 36532.981   15.222 train_cnf_disentangle_rl.py:447(compute_bits_per_dim)\n",
       "1080601/1079235    0.531    0.000    0.543    0.000 {built-in method builtins.issubclass}\n",
       "   159600    0.517    0.000    1.377    0.000 summary.py:64(_clean_tag)\n",
       "   536641    0.514    0.000    0.514    0.000 {method 'storage' of 'torch._C._TensorBase' objects}\n",
       "   262431    0.507    0.000    0.772    0.000 _utils.py:5(_get_device_index)\n",
       "   162001    0.501    0.000  534.526    0.003 event_file_writer.py:131(add_event)\n",
       "   536151    0.474    0.000    0.474    0.000 {method 'fileno' of '_io.BufferedWriter' objects}\n",
       "   294031    0.410    0.000   18.999    0.000 numeric.py:433(asarray)\n",
       "    30357    0.408    0.000    0.408    0.000 {method 'copy_' of 'torch._C._TensorBase' objects}\n",
       "   441000    0.407    0.000    0.407    0.000 clip_grad.py:24(<lambda>)\n",
       "   219033    0.405    0.000    0.592    0.000 queue.py:202(_qsize)\n",
       "   285054    0.404    0.000    0.404    0.000 _weakrefset.py:70(__contains__)\n",
       "     2700    0.403    0.000    1.108    0.000 replicate.py:12(<dictcomp>)\n",
       "    73500    0.393    0.000    3.478    0.000 histograms.py:391(_search_sorted_inclusive)\n",
       "   243410    0.392    0.000    0.679    0.000 threading.py:254(_is_owned)\n",
       "    73501    0.388    0.000    1.264    0.000 fromnumeric.py:64(_wrapreduction)\n",
       "      868    0.382    0.000    0.382    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
       "   186413    0.381    0.000    0.574    0.000 threading.py:239(__enter__)\n",
       "   536151    0.367    0.000    0.367    0.000 serialization.py:52(_cpu_tag)\n",
       "   159600    0.347    0.000    0.566    0.000 writer.py:314(_check_caffe2)\n",
       "   536641    0.344    0.000    0.344    0.000 {method 'stride' of 'torch._C._TensorBase' objects}\n",
       "       12    0.337    0.028    0.337    0.028 {built-in method _pickle.load}\n",
       "     2431    0.334    0.000    0.334    0.000 {built-in method zeros}\n",
       "   664200    0.326    0.000    0.326    0.000 _functions.py:13(<genexpr>)\n",
       "   156300    0.323    0.000   39.101    0.000 comm.py:151(gather)\n",
       "    24412    0.316    0.000    0.447    0.000 threading.py:498(__init__)\n",
       "    73502    0.316    0.000    0.316    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "   186413    0.309    0.000    0.434    0.000 threading.py:242(__exit__)\n",
       "    73500    0.308    0.000    0.608    0.000 histograms.py:220(_ravel_and_check_weights)\n",
       "    25528    0.303    0.000    0.303    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}\n",
       "    73500    0.297    0.000   39.380    0.001 fromnumeric.py:760(sort)\n",
       "   440755    0.297    0.000    0.297    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}\n",
       "   536641    0.288    0.000    0.288    0.000 {method 'storage_offset' of 'torch._C._TensorBase' objects}\n",
       "   536151    0.287    0.000    0.287    0.000 hooks.py:51(warn_if_has_hooks)\n",
       "   170020    0.278    0.000    0.278    0.000 {built-in method time.time}\n",
       "   518427    0.273    0.000    0.273    0.000 {method 'get_device' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "   188128    0.269    0.000    0.280    0.000 module.py:521(__getattr__)\n",
       "   305100    0.263    0.000   12.962    0.000 module.py:856(named_buffers)\n",
       "   305100    0.261    0.000   13.223    0.000 module.py:834(buffers)\n",
       "   518427    0.259    0.000    0.259    0.000 {method 'size' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "   162001    0.253    0.000    0.379    0.000 queue.py:206(_put)\n",
       "   441472    0.248    0.000    0.248    0.000 {built-in method math.sqrt}\n",
       "    90450    0.240    0.000    0.392    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "     2700    0.229    0.000    0.229    0.000 _functions.py:28(<listcomp>)\n",
       "     2401    0.223    0.000    0.239    0.000 summary.py:380(text)\n",
       "     2700    0.221    0.000 40859.886   15.133 parallel_apply.py:21(parallel_apply)\n",
       "    73500    0.216    0.000    1.481    0.000 fromnumeric.py:1933(any)\n",
       "   160501    0.207    0.000    0.207    0.000 {method 'lstrip' of 'str' objects}\n",
       "    24412    0.206    0.000   22.199    0.001 threading.py:533(wait)\n",
       "    73500    0.204    0.000    2.874    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
       "    60000    0.203    0.000    0.203    0.000 {method 'narrow' of 'torch._C._TensorBase' objects}\n",
       "    85801    0.202    0.000    0.274    0.000 writer.py:204(get_logdir)\n",
       "     4200    0.199    0.000    0.199    0.000 {built-in method rsub}\n",
       "   134700    0.197    0.000    0.284    0.000 variable.py:6(__instancecheck__)\n",
       "   148020    0.193    0.000    0.348    0.000 numeric.py:504(asanyarray)\n",
       "   186413    0.192    0.000    0.192    0.000 {method '__enter__' of '_thread.lock' objects}\n",
       "      300    0.192    0.001    0.830    0.003 utils.py:6(make_grid)\n",
       "      785    0.192    0.000    0.192    0.000 {method 'read' of '_io.FileIO' objects}\n",
       "   256943    0.192    0.000    0.192    0.000 {method 'append' of 'collections.deque' objects}\n",
       "      300    0.186    0.001    0.323    0.001 utils.py:70(make_grid)\n",
       "     2700    0.186    0.000    0.511    0.000 replicate.py:19(<dictcomp>)\n",
       "      633    0.180    0.000    0.315    0.000 optimizer.py:88(<dictcomp>)\n",
       "    21707    0.176    0.000   19.721    0.001 threading.py:828(start)\n",
       "    37/34    0.175    0.005    0.181    0.005 {built-in method _imp.create_dynamic}\n",
       "5924/5857    0.170    0.000    0.337    0.000 {built-in method builtins.__build_class__}\n",
       "92174/90290    0.170    0.000    2.192    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
       "     2400    0.169    0.000    0.442    0.000 train_misc.py:10(standard_normal_logprob)\n",
       "    81409    0.168    0.000    0.268    0.000 threading.py:251(_acquire_restore)\n",
       "    21707    0.162    0.000    0.700    0.000 threading.py:757(__init__)\n",
       "    96165    0.156    0.000    0.156    0.000 {method 'rpartition' of 'str' objects}\n",
       "    37838    0.153    0.000 40838.912    1.079 threading.py:1062(_wait_for_tstate_lock)\n",
       "   162985    0.144    0.000    0.144    0.000 {method 'items' of 'dict' objects}\n",
       "    73500    0.143    0.000    2.670    0.000 _methods.py:30(_amin)\n",
       "     2700    0.140    0.000   26.263    0.010 _functions.py:11(forward)\n",
       "    21600    0.134    0.000 40839.095    1.891 threading.py:1024(join)\n",
       "   172296    0.128    0.000    0.128    0.000 {method 'keys' of 'dict' objects}\n",
       "   113726    0.126    0.000    0.126    0.000 {built-in method _thread.allocate_lock}\n",
       "   271653    0.126    0.000    0.126    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
       "   186413    0.125    0.000    0.125    0.000 {method '__exit__' of '_thread.lock' objects}\n",
       "    73500    0.122    0.000    1.004    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "    73500    0.119    0.000    1.023    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
       "      702    0.119    0.000    0.172    0.000 {built-in method builtins.sorted}\n",
       "      785    0.115    0.000    0.307    0.000 <frozen importlib._bootstrap_external>:830(get_data)\n",
       "    24733    0.115    0.000    0.115    0.000 threading.py:215(__init__)\n",
       "     2400    0.115    0.000    0.115    0.000 {method 'pow' of 'torch._C._TensorBase' objects}\n",
       "    81409    0.109    0.000    0.161    0.000 threading.py:248(_release_save)\n",
       "     2705    0.107    0.000    0.226    0.000 __init__.py:251(__init__)\n",
       "     2700    0.107    0.000 40860.048   15.133 data_parallel.py:152(parallel_apply)\n",
       "    25200    0.105    0.000    0.843    0.000 cnf_gate.py:142(num_evals)\n",
       "    85800    0.102    0.000    0.102    0.000 {method 'squeeze' of 'numpy.ndarray' objects}\n",
       "     1800    0.099    0.000 102547.317   56.971 tensor.py:74(backward)\n",
       "      633    0.099    0.000    0.099    0.000 {method 'close' of '_io.BufferedWriter' objects}\n",
       "    73500    0.097    0.000    0.904    0.000 _methods.py:26(_amax)\n",
       "     2700    0.097    0.000  355.387    0.132 data_parallel.py:146(replicate)\n",
       "    73500    0.092    0.000    0.883    0.000 _methods.py:34(_sum)\n",
       "      633    0.091    0.000    0.157    0.000 optimizer.py:84(<listcomp>)\n",
       "    13533    0.090    0.000    7.088    0.001 iostream.py:195(schedule)\n",
       "    46012    0.090    0.000    0.123    0.000 threading.py:1230(current_thread)\n",
       "   187768    0.084    0.000    0.084    0.000 {method 'startswith' of 'str' objects}\n",
       "      600    0.084    0.000    1.175    0.002 dataloader.py:518(__init__)\n",
       "     5100    0.082    0.000   17.976    0.004 _functions.py:80(forward)\n",
       "9000/3000    0.080    0.000   18.186    0.006 scatter_gather.py:11(scatter_map)\n",
       "     2700    0.077    0.000 41294.338   15.294 data_parallel.py:136(forward)\n",
       "    73500    0.076    0.000    0.076    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "      785    0.074    0.000    0.074    0.000 {built-in method marshal.loads}\n",
       "    85801    0.072    0.000    0.072    0.000 event_file_writer.py:118(get_logdir)\n",
       "    73500    0.071    0.000    0.071    0.000 {built-in method numpy.core.multiarray.normalize_axis_index}\n",
       "     2400    0.070    0.000    0.070    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
       "     3600    0.070    0.000    0.070    0.000 {built-in method zlib.crc32}\n",
       "      408    0.070    0.000    0.141    0.000 module.py:647(_load_from_state_dict)\n",
       "     2532    0.069    0.000    0.069    0.000 {built-in method _pickle.dump}\n",
       "    25200    0.065    0.000    0.133    0.000 cnf_regularization_rl.py:33(_num_evals)\n",
       "    88410    0.064    0.000    0.064    0.000 {method 'remove' of 'collections.deque' objects}\n",
       "    25200    0.063    0.000    0.455    0.000 cnf_regularization_rl.py:14(after_odeint)\n",
       "    13486    0.059    0.000    0.059    0.000 {method 'format' of 'str' objects}\n",
       "     2700    0.058    0.000    0.067    0.000 replicate.py:15(<listcomp>)\n",
       "    25200    0.058    0.000    0.366    0.000 odefunc_rl.py:278(after_odeint)\n",
       "     2700    0.057    0.000    0.753    0.000 parallel_apply.py:67(<listcomp>)\n",
       "     5415    0.057    0.000    6.718    0.001 iostream.py:382(write)\n",
       "     5410    0.055    0.000   22.843    0.004 __init__.py:982(emit)\n",
       "     2400    0.055    0.000    0.055    0.000 {built-in method sum}\n",
       "    21600    0.055    0.000    0.069    0.000 threading.py:966(_stop)\n",
       "    16238    0.052    0.000    0.109    0.000 threading.py:1104(is_alive)\n",
       "5400/1800    0.052    0.000   49.349    0.027 dataloader.py:237(pin_memory_batch)\n",
       "    59652    0.050    0.000    0.050    0.000 threading.py:506(is_set)\n",
       "    40800    0.048    0.000    0.154    0.000 _functions.py:82(<lambda>)\n",
       "     5410    0.045    0.000   15.927    0.003 __init__.py:971(flush)\n",
       "     2705    0.044    0.000    0.082    0.000 __init__.py:1376(findCaller)\n",
       "      300    0.043    0.000    0.043    0.000 {method 'close' of '_io.BufferedRandom' objects}\n",
       "    22281    0.039    0.000    0.053    0.000 _weakrefset.py:81(add)\n",
       "    55075    0.039    0.000    0.039    0.000 {built-in method _thread.get_ident}\n",
       "    21600    0.038    0.000    0.053    0.000 _weakrefset.py:38(_remove)\n",
       "     2700    0.038    0.000   18.257    0.007 scatter_gather.py:33(scatter_kwargs)\n",
       "     1800    0.037    0.000    0.037    0.000 {built-in method ones_like}\n",
       "     2705    0.035    0.000    4.533    0.002 iostream.py:334(flush)\n",
       "     5410    0.033    0.000   22.926    0.004 __init__.py:852(handle)\n",
       "     7200    0.033    0.000    0.072    0.000 container.py:124(_get_abs_string_index)\n",
       "     1800    0.033    0.000    0.043    0.000 train_cnf_disentangle_rl.py:318(update_lr)\n",
       "     2705    0.033    0.000   22.958    0.008 __init__.py:1500(callHandlers)\n",
       "    25570    0.031    0.000    0.031    0.000 {method 'insert' of 'list' objects}\n",
       "      963    0.031    0.000    0.031    0.000 {built-in method torch._C._cuda_isDriverSufficient}\n",
       "     5410    0.030    0.000    0.116    0.000 __init__.py:564(format)\n",
       "     2401    0.030    0.000    0.433    0.000 writer.py:523(add_text)\n",
       "    21707    0.029    0.000    0.029    0.000 threading.py:727(_newname)\n",
       "        1    0.028    0.028    0.028    0.028 visdom_writer.py:23(VisdomWriter)\n",
       "        3    0.028    0.009    0.082    0.027 utils.py:70(parse_header)\n",
       "  955/231    0.027    0.000    0.093    0.000 sre_parse.py:470(_parse)\n",
       "    14700    0.027    0.000    0.027    0.000 utils.py:74(update)\n",
       "        1    0.025    0.025    2.143    2.143 train_cnf_disentangle_rl.py:345(get_dataset)\n",
       "     2705    0.025    0.000   23.330    0.009 __init__.py:1421(_log)\n",
       "     2705    0.025    0.000   23.376    0.009 __init__.py:1298(info)\n",
       "      300    0.025    0.000    0.025    0.000 {method 'repeat' of 'torch._C._TensorBase' objects}\n",
       "      421    0.024    0.000    0.024    0.000 {built-in method posix.listdir}\n",
       "    10820    0.023    0.000    0.035    0.000 __init__.py:809(acquire)\n",
       "    21600    0.023    0.000    0.077    0.000 parallel_apply.py:45(<lambda>)\n",
       "     1800    0.022    0.000 102547.218   56.971 __init__.py:38(backward)\n",
       "     7200    0.022    0.000    0.099    0.000 container.py:133(__getitem__)\n",
       "    21600    0.022    0.000    0.074    0.000 replicate.py:8(<lambda>)\n",
       "     5100    0.021    0.000   17.735    0.003 comm.py:131(scatter)\n",
       "    21600    0.021    0.000    0.075    0.000 _functions.py:15(<lambda>)\n",
       "      300    0.021    0.000    8.920    0.030 summary.py:248(make_image)\n",
       "     1387    0.021    0.000    0.233    0.000 <frozen importlib._bootstrap_external>:1233(find_spec)\n",
       "    13533    0.021    0.000    0.021    0.000 iostream.py:93(_event_pipe)\n",
       "     2700    0.020    0.000    0.020    0.000 {built-in method torch._C._get_tracing_state}\n",
       "     3941    0.020    0.000    0.049    0.000 posixpath.py:121(splitext)\n",
       "     1800    0.020    0.000    0.064    0.000 __init__.py:20(_make_grads)\n",
       "     5700    0.019    0.000    0.019    0.000 {method 'write' of '_io.BytesIO' objects}\n",
       "     2891    0.019    0.000    7.794    0.003 train_cnf_disentangle_rl.py:586(<lambda>)\n",
       "     3052    0.019    0.000    0.035    0.000 posixpath.py:144(basename)\n",
       " 1888/222    0.019    0.000    0.073    0.000 sre_compile.py:64(_compile)\n",
       "     2025    0.018    0.000    0.031    0.000 posixpath.py:75(join)\n",
       "    10820    0.018    0.000    0.026    0.000 __init__.py:816(release)\n",
       "      600    0.018    0.000   71.173    0.119 ImageFile.py:463(_save)\n",
       "      900    0.018    0.000    0.044    0.000 _methods.py:58(_mean)\n",
       "      300    0.018    0.000    0.018    0.000 {method 'copy' of 'ImagingCore' objects}\n",
       "     5410    0.018    0.000    0.134    0.000 __init__.py:829(format)\n",
       "     4200    0.018    0.000    0.217    0.000 tensor.py:348(__rsub__)\n",
       "     2705    0.017    0.000    0.244    0.000 __init__.py:1406(makeRecord)\n",
       "     5400    0.017    0.000   35.170    0.007 comm.py:24(broadcast_coalesced)\n",
       "     2891    0.017    0.000    0.017    0.000 {method 'type' of 'torch._C._TensorBase' objects}\n",
       "     1800    0.017    0.000    7.137    0.004 train_misc.py:69(count_nfe_gate)\n",
       "     3941    0.017    0.000    0.024    0.000 genericpath.py:117(_splitext)\n",
       "    16233    0.017    0.000    0.023    0.000 container.py:153(__len__)\n",
       "     1800    0.017    0.000   49.275    0.027 dataloader.py:245(<listcomp>)\n",
       "     1800    0.017    0.000    0.122    0.000 PngImagePlugin.py:667(putchunk)\n",
       "     1800    0.016    0.000    6.485    0.004 train_misc.py:89(count_total_time)\n",
       "     9416    0.016    0.000    0.045    0.000 <frozen importlib._bootstrap_external>:57(_path_join)\n",
       "     2705    0.016    0.000   22.979    0.008 __init__.py:1446(handle)\n",
       "    11783    0.016    0.000    0.016    0.000 {method 'rfind' of 'str' objects}\n",
       "      600    0.016    0.000   96.860    0.161 Image.py:1892(save)\n",
       "     7200    0.016    0.000    0.025    0.000 container.py:156(__iter__)\n",
       "     5410    0.015    0.000    0.037    0.000 __init__.py:542(usesTime)\n",
       "    21707    0.015    0.000    0.015    0.000 threading.py:1120(daemon)\n",
       "    21600    0.015    0.000    0.015    0.000 {method 'discard' of 'set' objects}\n",
       "     2716    0.015    0.000    0.021    0.000 __init__.py:1544(isEnabledFor)\n",
       "     5415    0.015    0.000    0.019    0.000 iostream.py:307(_is_master_process)\n",
       "    16412    0.015    0.000    0.026    0.000 sre_parse.py:253(get)\n",
       "     9416    0.015    0.000    0.024    0.000 <frozen importlib._bootstrap_external>:59(<listcomp>)\n",
       "     5410    0.014    0.000    0.022    0.000 __init__.py:387(usesTime)\n",
       "    28163    0.014    0.000    0.014    0.000 {method 'rstrip' of 'str' objects}\n",
       "    21600    0.014    0.000    0.014    0.000 {method 'locked' of '_thread.lock' objects}\n",
       "    15249    0.014    0.000    0.014    0.000 {built-in method posix.fspath}\n",
       "     3199    0.013    0.000   37.149    0.012 {built-in method builtins.next}\n",
       "    18455    0.013    0.000    0.013    0.000 sre_parse.py:232(__next)\n",
       "      300    0.013    0.000    0.013    0.000 {method 'mul' of 'torch._C._TensorBase' objects}\n",
       "     5410    0.013    0.000    0.013    0.000 __init__.py:390(format)\n",
       "      300    0.013    0.000   90.019    0.300 utils.py:90(save_image)\n",
       "        1    0.013    0.013    0.013    0.013 {built-in method torch._C._cuda_init}\n",
       "     2728    0.013    0.000    0.020    0.000 posixpath.py:52(normcase)\n",
       "     1528    0.013    0.000    0.031    0.000 version.py:198(__init__)\n",
       "     5415    0.013    0.000    1.914    0.000 iostream.py:320(_schedule_flush)\n",
       "     3000    0.012    0.000   18.198    0.006 scatter_gather.py:5(scatter)\n",
       "     2700    0.012    0.000   18.269    0.007 data_parallel.py:149(scatter)\n",
       "    11921    0.012    0.000    0.022    0.000 enum.py:267(__call__)\n",
       "     2700    0.012    0.000   60.541    0.022 data_parallel.py:155(gather)\n",
       "     3179    0.012    0.000    0.022    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\n",
       "    816/1    0.012    0.000 151147.755 151147.755 {built-in method builtins.exec}\n",
       "     2400    0.012    0.000    0.012    0.000 scatter_gather.py:40(<listcomp>)\n",
       "    17724    0.012    0.000    0.012    0.000 {method 'get_device' of 'torch._C.CudaLongStorageBase' objects}\n",
       "    10861    0.012    0.000    0.012    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "     8115    0.011    0.000    0.011    0.000 __init__.py:705(filter)\n",
       " 1706/866    0.011    0.000    2.794    0.003 <frozen importlib._bootstrap>:966(_find_and_load)\n",
       "     2700    0.011    0.000   60.529    0.022 scatter_gather.py:46(gather)\n",
       "      969    0.011    0.000    0.038    0.000 inspect.py:2100(_signature_from_function)\n",
       "     2705    0.011    0.000   11.479    0.004 __init__.py:1063(emit)\n",
       "      300    0.011    0.000   63.326    0.211 JpegImagePlugin.py:617(_save)\n",
       "     4403    0.011    0.000    0.029    0.000 enum.py:803(__and__)\n",
       "     5410    0.010    0.000    0.023    0.000 __init__.py:548(formatMessage)\n",
       "     2705    0.010    0.000    0.015    0.000 __init__.py:157(<lambda>)\n",
       "    17724    0.010    0.000    0.010    0.000 {method 'size' of 'torch._C.CudaLongStorageBase' objects}\n",
       "    16687    0.010    0.000    0.010    0.000 {method 'split' of 'str' objects}\n",
       "      357    0.010    0.000    0.010    0.000 {method 'cuda' of 'torch._C._TensorBase' objects}\n",
       "     5410    0.010    0.000    0.025    0.000 __init__.py:329(getMessage)\n",
       "      300    0.010    0.000    7.895    0.026 PngImagePlugin.py:689(_save)\n",
       "      785    0.010    0.000    0.013    0.000 <frozen importlib._bootstrap_external>:430(_validate_bytecode_header)\n",
       "13390/13314    0.010    0.000    0.013    0.000 {method 'join' of 'str' objects}\n",
       "     6019    0.010    0.000    0.014    0.000 posixpath.py:41(_get_sep)\n",
       "     5410    0.009    0.000    0.009    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
       "     2508    0.009    0.000    0.009    0.000 {method 'SerializeToString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "     6631    0.009    0.000    0.009    0.000 {method 'find' of 'str' objects}\n",
       "      300    0.009    0.000    0.009    0.000 {method 'byte' of 'torch._C._TensorBase' objects}\n",
       "    10759    0.009    0.000    0.014    0.000 mathtext.py:2739(<genexpr>)\n",
       "    11919    0.009    0.000    0.009    0.000 enum.py:517(__new__)\n",
       "      300    0.009    0.000    0.009    0.000 {method 'clamp' of 'torch._C._TensorBase' objects}\n",
       "     3522    0.009    0.000    0.025    0.000 {built-in method builtins.any}\n",
       "      848    0.009    0.000    0.240    0.000 <frozen importlib._bootstrap>:870(_find_spec)\n",
       "     8686    0.008    0.000    0.008    0.000 {built-in method builtins.iter}\n",
       "     7648    0.008    0.000    0.012    0.000 sre_parse.py:163(__getitem__)\n",
       "     2679    0.008    0.000    0.008    0.000 {method 'encode' of 'str' objects}\n",
       "      633    0.008    0.000  605.143    0.956 serialization.py:131(_with_file_like)\n",
       "     1570    0.008    0.000    0.025    0.000 <frozen importlib._bootstrap_external>:263(cache_from_source)\n",
       "      785    0.008    0.000    0.458    0.001 <frozen importlib._bootstrap_external>:743(get_code)\n",
       "        1    0.008    0.008    0.008    0.008 {built-in method builtins.compile}\n",
       "    10861    0.008    0.000    0.008    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "     8124    0.007    0.000    0.007    0.000 {built-in method posix.getpid}\n",
       "      962    0.007    0.000    0.041    0.000 __init__.py:45(is_available)\n",
       "    17209    0.007    0.000    0.007    0.000 {method 'strip' of 'str' objects}\n",
       "     2569    0.007    0.000    0.014    0.000 inspect.py:2450(__init__)\n",
       "     2414    0.007    0.000    0.007    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n",
       "      300    0.007    0.000    0.335    0.001 utils.py:95(convert_to_HWC)\n",
       "      824    0.007    0.000    0.031    0.000 <frozen importlib._bootstrap>:504(_init_module_attrs)\n",
       "     5336    0.007    0.000    0.007    0.000 {built-in method torch._C.is_grad_enabled}\n",
       "     2705    0.007    0.000    0.010    0.000 __init__.py:120(getLevelName)\n",
       "2991/1344    0.007    0.000    0.010    0.000 sre_parse.py:173(getwidth)\n",
       "      576    0.007    0.000    0.037    0.000 inspect.py:1087(getfullargspec)\n",
       "     2700    0.007    0.000    0.007    0.000 replicate.py:23(<listcomp>)\n",
       "     3179    0.007    0.000    0.008    0.000 <frozen importlib._bootstrap>:78(acquire)\n",
       "      900    0.007    0.000    0.051    0.000 fromnumeric.py:2817(mean)\n",
       "     2402    0.007    0.000    0.007    0.000 {built-in method math.log}\n",
       "      633    0.007    0.000  605.150    0.956 serialization.py:191(save)\n",
       "      636    0.007    0.000    0.011    0.000 sre_compile.py:250(_optimize_charset)\n",
       "     2458    0.007    0.000    0.007    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
       "   2225/1    0.007    0.000    0.035    0.035 copy.py:132(deepcopy)\n",
       "      633    0.007    0.000    0.488    0.001 optimizer.py:72(state_dict)\n",
       "     3179    0.006    0.000    0.008    0.000 <frozen importlib._bootstrap>:103(release)\n",
       "     3600    0.006    0.000    0.076    0.000 PngImagePlugin.py:90(_crc32)\n",
       "       27    0.006    0.000    0.034    0.001 __init__.py:978(_rc_params_in_file)\n",
       "   837/21    0.006    0.000    2.733    0.130 <frozen importlib._bootstrap>:651(_load_unlocked)\n",
       "     4200    0.006    0.000    0.010    0.000 _binary.py:93(o32be)\n",
       "      785    0.006    0.000    0.011    0.000 posixpath.py:154(dirname)\n",
       "      300    0.006    0.000   11.682    0.039 train_cnf_disentangle_rl.py:331(get_train_loader)\n",
       "     2400    0.006    0.000    0.006    0.000 {method 'nelement' of 'torch._C._TensorBase' objects}\n",
       "     2716    0.006    0.000    0.006    0.000 __init__.py:1530(getEffectiveLevel)\n",
       "      301    0.006    0.000    0.019    0.000 dataloader.py:768(__init__)\n",
       "     2705    0.006    0.000    0.006    0.000 threading.py:1076(name)\n",
       "     6891    0.006    0.000    0.006    0.000 {built-in method builtins.min}\n",
       "     2700    0.006    0.000    0.006    0.000 replicate.py:69(<listcomp>)\n",
       "     5178    0.006    0.000    0.183    0.000 <frozen importlib._bootstrap_external>:75(_path_stat)\n",
       "       24    0.006    0.000    1.657    0.069 utils.py:16(check_integrity)\n",
       "     2700    0.005    0.000    0.005    0.000 function.py:45(mark_non_differentiable)\n",
       "     8294    0.005    0.000    0.005    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\n",
       "     1008    0.005    0.000    0.010    0.000 inspect.py:2730(__init__)\n",
       "     2542    0.005    0.000    0.009    0.000 <frozen importlib._bootstrap>:176(cb)\n",
       "        1    0.005    0.005 151147.753 151147.753 py3compat.py:184(execfile)\n",
       "      633    0.005    0.000    0.164    0.000 optimizer.py:82(pack_group)\n",
       "      105    0.005    0.000    0.013    0.000 <frozen importlib._bootstrap_external>:1067(_path_hooks)\n",
       "   859/19    0.005    0.000    2.760    0.145 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)\n",
       "     3311    0.005    0.000    0.005    0.000 dataloader.py:811(__setattr__)\n",
       "      760    0.005    0.000    0.016    0.000 version.py:131(_legacy_cmpkey)\n",
       "     1318    0.005    0.000    0.012    0.000 grad_mode.py:35(__exit__)\n",
       "     1318    0.005    0.000    0.007    0.000 grad_mode.py:122(__init__)\n",
       "      969    0.005    0.000    0.047    0.000 inspect.py:2181(_signature_from_callable)\n",
       "     2618    0.005    0.000    0.194    0.000 re.py:286(_compile)\n",
       "     3814    0.005    0.000    0.008    0.000 utils.py:51(add_argument)\n",
       "    816/2    0.005    0.000    0.015    0.007 module.py:1024(__repr__)\n",
       "     3140    0.005    0.000    0.005    0.000 {built-in method sys._getframe}\n",
       "     3312    0.005    0.000    0.008    0.000 version.py:114(_parse_version_parts)\n",
       "  587/175    0.005    0.000    0.014    0.000 abc.py:196(__subclasscheck__)\n",
       "       12    0.005    0.000    0.043    0.004 artist.py:1179(_get_setters_and_targets)\n",
       "      300    0.005    0.000   11.548    0.038 writer.py:429(add_images)\n",
       "     2542    0.005    0.000    0.007    0.000 <frozen importlib._bootstrap>:58(__init__)\n",
       "     3740    0.005    0.000    0.008    0.000 version.py:65(_compare)\n",
       "     3488    0.005    0.000    0.007    0.000 utils.py:79(<lambda>)\n",
       "       26    0.005    0.000    0.005    0.000 {method 'readlines' of '_io._IOBase' objects}\n",
       "     4521    0.004    0.000    0.004    0.000 {built-in method _struct.pack}\n",
       "      634    0.004    0.000    3.759    0.006 utils.py:8(makedirs)\n",
       "     3488    0.004    0.000    0.008    0.000 utils.py:81(<lambda>)\n",
       "     7260    0.004    0.000    0.004    0.000 {built-in method _operator.index}\n",
       "     1318    0.004    0.000    0.006    0.000 grad_mode.py:31(__enter__)\n",
       "  849/848    0.004    0.000    0.220    0.000 <frozen importlib._bootstrap_external>:1117(_get_spec)\n",
       "     8709    0.004    0.000    0.004    0.000 {method 'group' of '_sre.SRE_Match' objects}\n",
       "      900    0.004    0.000    0.005    0.000 _methods.py:48(_count_reduce_items)\n",
       "     5424    0.004    0.000    0.005    0.000 {built-in method builtins.setattr}\n",
       "      957    0.004    0.000    0.013    0.000 copy.py:66(copy)\n",
       "      300    0.004    0.000    1.838    0.006 sampler.py:69(__iter__)\n",
       "      490    0.004    0.000    0.021    0.000 tensor.py:16(__deepcopy__)\n",
       "      847    0.004    0.000    0.046    0.000 _utils.py:127(_rebuild_tensor)\n",
       "  702/222    0.004    0.000    0.095    0.000 sre_parse.py:407(_parse_sub)\n",
       "     3094    0.004    0.000    0.005    0.000 {method 'extend' of 'list' objects}\n",
       "     1044    0.004    0.000    3.928    0.004 genericpath.py:16(exists)\n",
       "     2705    0.004    0.000    0.004    0.000 process.py:146(name)\n",
       "     3006    0.004    0.000    0.075    0.000 <frozen importlib._bootstrap_external>:85(_path_is_mode_type)\n",
       "      768    0.004    0.000    0.005    0.000 version.py:343(_cmpkey)\n",
       "     1337    0.004    0.000    0.004    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
       "     8491    0.004    0.000    0.004    0.000 {built-in method _imp.release_lock}\n",
       "     1800    0.004    0.000    0.004    0.000 train_misc.py:71(AccNumEvals)\n",
       "      600    0.004    0.000    1.179    0.002 dataloader.py:818(__iter__)\n",
       "     1500    0.004    0.000    0.005    0.000 cifar.py:128(__len__)\n",
       "     1800    0.004    0.000    0.004    0.000 train_misc.py:91(Accumulator)\n",
       "     8491    0.004    0.000    0.004    0.000 {built-in method _imp.acquire_lock}\n",
       "     4226    0.004    0.000    0.005    0.000 utils.py:92(<lambda>)\n",
       "        1    0.004    0.004    0.004    0.004 {built-in method posix.read}\n",
       "      381    0.004    0.000    0.024    0.000 module.py:62(__init__)\n",
       "        1    0.003    0.003    0.057    0.057 {method 'load' of '_pickle.Unpickler' objects}\n",
       "      490    0.003    0.000    0.003    0.000 {method 'copy_' of 'torch._C.FloatStorageBase' objects}\n",
       "     3830    0.003    0.000    0.005    0.000 utils.py:75(<lambda>)\n",
       "      785    0.003    0.000    0.079    0.000 <frozen importlib._bootstrap_external>:485(_compile_bytecode)\n",
       "      847    0.003    0.000    0.007    0.000 serialization.py:513(persistent_load)\n",
       "       14    0.003    0.000    0.003    0.000 {built-in method sqrt}\n",
       "     1706    0.003    0.000    0.023    0.000 <frozen importlib._bootstrap>:147(__enter__)\n",
       "      824    0.003    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:524(spec_from_file_location)\n",
       "     1473    0.003    0.000    0.016    0.000 <frozen importlib._bootstrap>:194(_lock_unlock_module)\n",
       "     2706    0.003    0.000    0.003    0.000 process.py:35(current_process)\n",
       "      824    0.003    0.000    0.008    0.000 <frozen importlib._bootstrap>:318(__exit__)\n",
       "     1799    0.003    0.000    0.030    0.000 __init__.py:829(__setitem__)\n",
       "     4956    0.003    0.000    0.004    0.000 sre_parse.py:248(match)\n",
       "     3499    0.003    0.000    0.004    0.000 inspect.py:2779(<genexpr>)\n",
       "  824/818    0.003    0.000    0.218    0.000 <frozen importlib._bootstrap>:564(module_from_spec)\n",
       "   785/20    0.003    0.000    2.731    0.137 <frozen importlib._bootstrap_external>:672(exec_module)\n",
       "     5894    0.003    0.000    0.003    0.000 {method 'lower' of 'str' objects}\n",
       "     3185    0.003    0.000    0.004    0.000 sre_parse.py:171(append)\n",
       "      300    0.003    0.000    0.027    0.000 Image.py:1738(resize)\n",
       "     3488    0.003    0.000    0.005    0.000 utils.py:83(<lambda>)\n",
       "        1    0.003    0.003    0.015    0.015 {built-in method torch._C._initExtension}\n",
       "     1570    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap_external>:63(_path_split)\n",
       "      320    0.003    0.000    0.050    0.000 __init__.py:2481(from_location)\n",
       "     2612    0.003    0.000    0.070    0.000 <frozen importlib._bootstrap_external>:94(_path_isfile)\n",
       "     3488    0.003    0.000    0.004    0.000 utils.py:77(<lambda>)\n",
       "     2952    0.003    0.000    0.004    0.000 sre_parse.py:159(__len__)\n",
       "      373    0.003    0.000    0.007    0.000 colors.py:184(_to_rgba_no_colorcycle)\n",
       "    381/1    0.003    0.000    0.016    0.016 module.py:185(_apply)\n",
       "     1804    0.003    0.000    0.004    0.000 __init__.py:1972(dist_factory)\n",
       "     2292    0.003    0.000    0.003    0.000 {method 'match' of '_sre.SRE_Pattern' objects}\n",
       "      628    0.003    0.000    0.066    0.000 __init__.py:2027(distributions_from_metadata)\n",
       "        1    0.003    0.003    0.003    0.003 {built-in method _posixsubprocess.fork_exec}\n",
       "     2603    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap>:847(__exit__)\n",
       "     1800    0.003    0.000    0.003    0.000 train_misc.py:93(__init__)\n",
       "      300    0.003    0.000    0.003    0.000 {method 'permute' of 'torch._C._TensorBase' objects}\n",
       "        1    0.003    0.003    0.003    0.003 {built-in method randn}\n",
       "      600    0.003    0.000    0.003    0.000 {method 'flush' of '_io.BufferedRandom' objects}\n",
       "     2603    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap>:843(__enter__)\n",
       "     3428    0.003    0.000    0.003    0.000 {method 'endswith' of 'str' objects}\n",
       "     3814    0.003    0.000    0.003    0.000 utils.py:61(__init__)\n",
       "     1800    0.003    0.000    0.003    0.000 train_misc.py:73(__init__)\n",
       "     1200    0.002    0.000    0.111    0.000 PngImagePlugin.py:685(write)\n",
       "     2458    0.002    0.000    0.003    0.000 sre_parse.py:285(tell)\n",
       "      616    0.002    0.000    0.003    0.000 {method 'sort' of 'list' objects}\n",
       "      107    0.002    0.000    1.664    0.016 event_file_writer.py:35(__init__)\n",
       "      636    0.002    0.000    0.017    0.000 sre_compile.py:223(_compile_charset)\n",
       "      313    0.002    0.000    0.005    0.000 functools.py:44(update_wrapper)\n",
       "     2705    0.002    0.000    0.002    0.000 {built-in method _imp.lock_held}\n",
       "      490    0.002    0.000    0.008    0.000 storage.py:40(clone)\n",
       "      822    0.002    0.000    0.016    0.000 <frozen importlib._bootstrap_external>:361(_get_cached)\n",
       "      172    0.002    0.000    0.003    0.000 init.py:178(_calculate_fan_in_and_fan_out)\n",
       "      410    0.002    0.000    0.035    0.000 artist.py:1142(get_valid_values)\n",
       "      300    0.002    0.000    0.007    0.000 sampler.py:33(__iter__)\n",
       "      900    0.002    0.000    0.005    0.000 copy.py:268(_reconstruct)\n",
       "  980/245    0.002    0.000    0.006    0.000 optimizer.py:122(cast)\n",
       "       98    0.002    0.000    0.033    0.000 conv.py:17(__init__)\n",
       "        1    0.002    0.002    0.004    0.004 packages.py:1(<module>)\n",
       "      824    0.002    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:1228(_get_spec)\n",
       "      300    0.002    0.000    0.005    0.000 sampler.py:50(__init__)\n",
       "       33    0.002    0.000    0.002    0.000 {built-in method builtins.dir}\n",
       "      352    0.002    0.000    0.005    0.000 inspect.py:2832(_hash_basis)\n",
       "      320    0.002    0.000    0.005    0.000 __init__.py:683(add)\n",
       "       64    0.002    0.000    0.012    0.000 colors.py:713(from_list)\n",
       "      633    0.002    0.000    0.002    0.000 optimizer.py:83(<dictcomp>)\n",
       "     1706    0.002    0.000    0.007    0.000 <frozen importlib._bootstrap>:151(__exit__)\n",
       "     4696    0.002    0.000    0.002    0.000 inspect.py:2500(name)\n",
       "     2210    0.002    0.000    0.003    0.000 inspect.py:159(isfunction)\n",
       "      300    0.002    0.000    0.002    0.000 summary.py:59(_calc_scale_factor)\n",
       "        2    0.002    0.001    2.118    1.059 cifar.py:49(__init__)\n",
       "     2992    0.002    0.000    0.002    0.000 version.py:207(<genexpr>)\n",
       "      300    0.002    0.000    0.002    0.000 {built-in method PIL._imaging.jpeg_encoder}\n",
       "     1375    0.002    0.000    0.005    0.000 re.py:169(match)\n",
       "       12    0.002    0.000    0.004    0.000 artist.py:1125(<listcomp>)\n",
       "    408/1    0.002    0.000    0.143    0.143 module.py:746(load)\n",
       "     1536    0.002    0.000    0.006    0.000 colors.py:116(_is_nth_color)\n",
       "     1076    0.002    0.000    0.031    0.000 version.py:24(parse)\n",
       "      814    0.002    0.000    0.005    0.000 module.py:11(_addindent)\n",
       "       94    0.002    0.000    0.002    0.000 function.py:89(__init__)\n",
       "      326    0.002    0.000    0.043    0.000 __init__.py:2094(_handle_ns)\n",
       "      107    0.002    0.000    1.871    0.017 event_file_writer.py:90(__init__)\n",
       "      222    0.002    0.000    0.008    0.000 sre_compile.py:482(_compile_info)\n",
       "     1607    0.002    0.000    0.018    0.000 <frozen importlib._bootstrap>:403(cached)\n",
       "      214    0.002    0.000    0.002    0.000 crc32c.py:77(crc_update)\n",
       "     1045    0.002    0.000    0.011    0.000 colors.py:150(to_rgba)\n",
       "     3828    0.002    0.000    0.002    0.000 {method 'partition' of 'str' objects}\n",
       "    248/1    0.002    0.000    0.035    0.035 copy.py:236(_deepcopy_dict)\n",
       "     3296    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:321(<genexpr>)\n",
       "      144    0.002    0.000    0.002    0.000 {method 'splitlines' of 'str' objects}\n",
       "        1    0.002    0.002    0.026    0.026 binding.py:81(build_conditional_library)\n",
       "      150    0.002    0.000    0.028    0.000 utils.py:89(verify_interface)\n",
       "       12    0.002    0.000    0.010    0.001 artist.py:1114(get_aliases)\n",
       "      222    0.002    0.000    0.185    0.001 sre_compile.py:557(compile)\n",
       "     1570    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:52(_r_long)\n",
       "      691    0.002    0.000    0.018    0.000 __init__.py:2647(_get_metadata)\n",
       "     1870    0.002    0.000    0.006    0.000 version.py:47(__lt__)\n",
       "     4226    0.002    0.000    0.002    0.000 utils.py:94(<lambda>)\n",
       "      301    0.002    0.000    0.002    0.000 sampler.py:142(__init__)\n",
       "      452    0.002    0.000    0.023    0.000 __init__.py:1323(safe_version)\n",
       "     4076    0.002    0.000    0.002    0.000 inspect.py:2512(kind)\n",
       "     1870    0.002    0.000    0.005    0.000 version.py:53(__eq__)\n",
       "      816    0.002    0.000    0.003    0.000 sre_compile.py:388(_simple)\n",
       "       16    0.002    0.000    0.002    0.000 {method 'AddSerializedFile' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "     1195    0.002    0.000    0.004    0.000 _weakrefset.py:58(__iter__)\n",
       "      300    0.002    0.000    0.023    0.000 Image.py:1083(copy)\n",
       "       57    0.002    0.000    2.041    0.036 __init__.py:1(<module>)\n",
       "     1592    0.002    0.000    0.002    0.000 artist.py:1225(is_alias)\n",
       "      492    0.002    0.000    0.011    0.000 rcsetup.py:358(validate_color)\n",
       "     1888    0.002    0.000    0.002    0.000 sre_parse.py:111(__init__)\n",
       "      300    0.001    0.000    0.003    0.000 utils.py:102(<listcomp>)\n",
       "      633    0.001    0.000    0.166    0.000 optimizer.py:86(<listcomp>)\n",
       "     2636    0.001    0.000    0.001    0.000 {built-in method torch._C.set_grad_enabled}\n",
       "     1111    0.001    0.000    0.015    0.000 <frozen importlib._bootstrap_external>:1080(_path_importer_cache)\n",
       "      602    0.001    0.000    0.001    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "      326    0.001    0.000    0.001    0.000 module.py:17(<listcomp>)\n",
       "      848    0.001    0.000    0.041    0.000 __init__.py:108(import_module)\n",
       "      452    0.001    0.000    0.004    0.000 version.py:236(__str__)\n",
       "      785    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:393(_check_name_wrapper)\n",
       "  1093/21    0.001    0.000    2.717    0.129 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
       "     1152    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:369(__init__)\n",
       "       50    0.001    0.000    0.014    0.000 traceback.py:319(extract)\n",
       "     2293    0.001    0.000    0.001    0.000 {method 'replace' of 'str' objects}\n",
       "     1694    0.001    0.000    0.002    0.000 serialization.py:502(maybe_decode_ascii)\n",
       "     3383    0.001    0.000    0.001    0.000 {built-in method builtins.ord}\n",
       "        8    0.001    0.000    0.001    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
       "     1649    0.001    0.000    0.001    0.000 {method 'upper' of 'str' objects}\n",
       "     1706    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:143(__init__)\n",
       "     1586    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}\n",
       "      787    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:35(_new_module)\n",
       "      785    0.001    0.000    0.001    0.000 {built-in method _imp._fix_co_filename}\n",
       "      785    0.001    0.000    0.036    0.000 <frozen importlib._bootstrap_external>:840(path_stats)\n",
       "     3508    0.001    0.000    0.001    0.000 {built-in method builtins.callable}\n",
       "      330    0.001    0.000    0.005    0.000 __init__.py:1958(<genexpr>)\n",
       "      222    0.001    0.000    0.099    0.000 sre_parse.py:844(parse)\n",
       "      781    0.001    0.000    0.001    0.000 {method 'split' of '_sre.SRE_Pattern' objects}\n",
       "   260/11    0.001    0.000    0.006    0.001 pyparsing.py:1380(_parseNoCache)\n",
       "      107    0.001    0.000    1.614    0.015 record_writer.py:46(open_file)\n",
       "      848    0.001    0.000    0.221    0.000 <frozen importlib._bootstrap_external>:1149(find_spec)\n",
       "  849/848    0.001    0.000    0.039    0.000 <frozen importlib._bootstrap>:982(_gcd_import)\n",
       "      956    0.001    0.000    0.002    0.000 __init__.py:2540(key)\n",
       "     2899    0.001    0.000    0.001    0.000 {method 'isidentifier' of 'str' objects}\n",
       "      300    0.001    0.000    0.003    0.000 JpegImagePlugin.py:626(<listcomp>)\n",
       "   550/61    0.001    0.000    1.909    0.031 {built-in method builtins.__import__}\n",
       "      342    0.001    0.000    0.133    0.000 __init__.py:1940(find_on_path)\n",
       "      106    0.001    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:1196(__init__)\n",
       "      335    0.001    0.000    0.001    0.000 pyparsing.py:1144(__init__)\n",
       "      600    0.001    0.000    0.001    0.000 {built-in method builtins.round}\n",
       "       31    0.001    0.000    0.003    0.000 auto.py:107(_make_function_class)\n",
       "        1    0.001    0.001    0.900    0.900 serialization.py:385(_load)\n",
       "      744    0.001    0.000    0.266    0.000 utils.py:22(<lambda>)\n",
       "       88    0.001    0.000    0.005    0.000 abc.py:132(__new__)\n",
       "     1035    0.001    0.000    0.002    0.000 __init__.py:119(is_tensor)\n",
       "     1570    0.001    0.000    0.001    0.000 {built-in method from_bytes}\n",
       "      847    0.001    0.000    0.047    0.000 _utils.py:134(_rebuild_tensor_v2)\n",
       "      107    0.001    0.000    0.045    0.000 record_writer.py:114(write)\n",
       "      748    0.001    0.000    0.002    0.000 __init__.py:2688(__getattr__)\n",
       "       39    0.001    0.000    0.010    0.000 __init__.py:1638(param)\n",
       "      740    0.001    0.000    0.002    0.000 copy.py:252(_keep_alive)\n",
       "      451    0.001    0.000    0.002    0.000 artist.py:1204(_replace_path)\n",
       "       11    0.001    0.000    0.077    0.007 artist.py:1268(pprint_setters)\n",
       "       68    0.001    0.000    0.001    0.000 {built-in method posix.lstat}\n",
       "      490    0.001    0.000    0.010    0.000 storage.py:24(__deepcopy__)\n",
       "      537    0.001    0.000    0.003    0.000 __init__.py:2281(yield_lines)\n",
       "      988    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
       "        1    0.001    0.001    0.002    0.002 descriptor_pb2.py:4(<module>)\n",
       "      282    0.001    0.000    0.003    0.000 function_base.py:3895(add_newdoc)\n",
       "       60    0.001    0.000    0.002    0.000 function_base.py:25(linspace)\n",
       "     1890    0.001    0.000    0.001    0.000 {method 'find' of 'bytearray' objects}\n",
       "  958/150    0.001    0.000    0.015    0.000 {built-in method builtins.repr}\n",
       "     1049    0.001    0.000    0.001    0.000 sre_parse.py:81(groups)\n",
       "      531    0.001    0.000    0.001    0.000 _weakrefset.py:36(__init__)\n",
       "      600    0.001    0.000    0.002    0.000 _util.py:10(isPath)\n",
       "      314    0.001    0.000    0.033    0.000 __init__.py:1935(<listcomp>)\n",
       "     1758    0.001    0.000    0.001    0.000 version.py:244(<genexpr>)\n",
       "      760    0.001    0.000    0.017    0.000 version.py:74(__init__)\n",
       "      121    0.001    0.000    0.003    0.000 __init__.py:1521(_get)\n",
       "      900    0.001    0.000    0.001    0.000 {method '__reduce_ex__' of 'object' objects}\n",
       "     2304    0.001    0.000    0.001    0.000 version.py:298(_parse_letter_version)\n",
       "      393    0.001    0.000    0.002    0.000 inspect.py:485(unwrap)\n",
       "      159    0.001    0.000    0.002    0.000 __init__.py:2772(<listcomp>)\n",
       "      214    0.001    0.000    0.004    0.000 record_writer.py:127(masked_crc32c)\n",
       "      824    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:311(__enter__)\n",
       "        3    0.001    0.000    0.345    0.115 __init__.py:9(<module>)\n",
       "     1096    0.001    0.000    0.001    0.000 inspect.py:2833(<genexpr>)\n",
       "      323    0.001    0.000    0.037    0.000 <frozen importlib._bootstrap_external>:413(_find_module_shim)\n",
       "       25    0.001    0.000    0.013    0.001 __init__.py:357(namedtuple)\n",
       "      300    0.001    0.000    1.822    0.006 module.py:992(eval)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:48(<lambda>)\n",
       "      388    0.001    0.000    0.004    0.000 __init__.py:1468(_fn)\n",
       "     1015    0.001    0.000    0.001    0.000 sre_compile.py:102(fixup)\n",
       "      492    0.001    0.000    0.018    0.000 train_misc.py:86(<genexpr>)\n",
       "      300    0.001    0.000    0.001    0.000 {built-in method PIL._imaging.zip_encoder}\n",
       "      300    0.001    0.000    0.001    0.000 {built-in method math.ceil}\n",
       "       98    0.001    0.000    0.018    0.000 conv.py:45(reset_parameters)\n",
       "      126    0.001    0.000    0.006    0.000 deprecation.py:178(deprecate)\n",
       "      320    0.001    0.000    0.020    0.000 __init__.py:2468(__init__)\n",
       "      848    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap>:780(find_spec)\n",
       "      314    0.001    0.000    0.036    0.000 __init__.py:1929(_by_version)\n",
       "      847    0.001    0.000    0.001    0.000 serialization.py:401(restore_location)\n",
       "      900    0.001    0.000    0.001    0.000 copyreg.py:87(__newobj__)\n",
       "      147    0.001    0.000    0.001    0.000 enum.py:353(__setattr__)\n",
       "      341    0.001    0.000    0.002    0.000 warnings.py:159(_add_filter)\n",
       "        2    0.001    0.000    0.002    0.001 __init__.py:1420(register_all)\n",
       "      600    0.001    0.000    0.001    0.000 scatter_gather.py:20(<listcomp>)\n",
       "     1260    0.001    0.000    0.001    0.000 colors.py:236(<genexpr>)\n",
       "      196    0.001    0.000    0.002    0.000 conv.py:53(extra_repr)\n",
       "       16    0.001    0.000    0.004    0.000 enum.py:124(__new__)\n",
       "      107    0.001    0.000    0.003    0.000 queue.py:27(__init__)\n",
       "      272    0.001    0.000    0.002    0.000 enum.py:797(__or__)\n",
       "      400    0.001    0.000    0.001    0.000 sre_parse.py:342(_escape)\n",
       "      275    0.001    0.000    0.002    0.000 module.py:122(register_parameter)\n",
       "      849    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:917(_sanity_check)\n",
       "     1940    0.001    0.000    0.003    0.000 __init__.py:2248(_normalize_cached)\n",
       "     1321    0.001    0.000    0.001    0.000 {method 'values' of 'mappingproxy' objects}\n",
       "      490    0.001    0.000    0.006    0.000 utils.py:6(parse)\n",
       "      212    0.001    0.000    0.004    0.000 __init__.py:540(dedent)\n",
       "      176    0.001    0.000    0.007    0.000 inspect.py:2846(__eq__)\n",
       "      491    0.001    0.000    0.009    0.000 colors.py:121(is_color_like)\n",
       "      222    0.001    0.000    0.082    0.000 sre_compile.py:542(_code)\n",
       "      479    0.001    0.000    0.030    0.000 re.py:179(search)\n",
       "      848    0.001    0.000    0.001    0.000 {built-in method _imp.is_frozen}\n",
       "      159    0.001    0.000    0.004    0.000 __init__.py:2746(insert_on)\n",
       "  230/199    0.001    0.000    0.001    0.000 sre_compile.py:414(_get_literal_prefix)\n",
       "     1828    0.001    0.000    0.001    0.000 inspect.py:2504(default)\n",
       "       31    0.001    0.000    0.010    0.000 _collections_abc.py:824(update)\n",
       "       30    0.001    0.000    0.006    0.000 {built-in method builtins.eval}\n",
       "      129    0.001    0.000    0.001    0.000 inspect.py:614(cleandoc)\n",
       "      297    0.001    0.000    0.002    0.000 sre_parse.py:84(opengroup)\n",
       "        1    0.001    0.001    0.004    0.004 caffe2_pb2.py:4(<module>)\n",
       "     1329    0.001    0.000    0.001    0.000 {method 'setdefault' of 'dict' objects}\n",
       "     1387    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:41(_relax_case)\n",
       "        3    0.001    0.000    0.002    0.001 six.py:1(<module>)\n",
       "     1499    0.001    0.000    0.001    0.000 {built-in method _sre.getlower}\n",
       "        1    0.001    0.001    0.896    0.896 writer.py:246(__init__)\n",
       "      107    0.001    0.000    0.171    0.002 record_writer.py:35(directory_check)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:54(<lambda>)\n",
       "      408    0.001    0.000    0.001    0.000 module.py:684(<dictcomp>)\n",
       "        1    0.001    0.001    0.001    0.001 case.py:297(_AssertLogsContext)\n",
       "      106    0.001    0.000    0.014    0.000 <frozen importlib._bootstrap_external>:1281(_fill_cache)\n",
       "      107    0.001    0.000    1.872    0.017 writer.py:162(__init__)\n",
       "      787    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:800(__init__)\n",
       "      438    0.001    0.000    0.003    0.000 re.py:184(sub)\n",
       "       21    0.001    0.000    0.001    0.000 {method 'read' of '_io.TextIOWrapper' objects}\n",
       "      100    0.001    0.000    0.016    0.000 init.py:261(kaiming_uniform_)\n",
       "      407    0.001    0.000    0.001    0.000 _weakrefset.py:26(__exit__)\n",
       "      600    0.001    0.000    0.001    0.000 dataloader.py:715(__del__)\n",
       "      471    0.001    0.000    0.008    0.000 pyparsing.py:1167(copy)\n",
       "       24    0.001    0.000    0.139    0.006 __init__.py:609(add_entry)\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method torch._C._c10d_init}\n",
       "       59    0.001    0.000    0.001    0.000 posixpath.py:331(normpath)\n",
       "      335    0.001    0.000    0.003    0.000 warnings.py:143(simplefilter)\n",
       "      300    0.001    0.000    0.001    0.000 PngImagePlugin.py:681(__init__)\n",
       "      300    0.001    0.000    0.003    0.000 sampler.py:168(__len__)\n",
       "      355    0.001    0.000    0.001    0.000 warnings.py:449(__enter__)\n",
       "      352    0.001    0.000    0.001    0.000 inspect.py:2836(<dictcomp>)\n",
       "     1526    0.001    0.000    0.001    0.000 _structures.py:33(__neg__)\n",
       "     1398    0.001    0.000    0.001    0.000 inspect.py:2508(annotation)\n",
       "      824    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:307(__init__)\n",
       "        1    0.001    0.001    0.005    0.005 pyplot.py:2043(_setup_pyplot_info_docstrings)\n",
       "       28    0.001    0.000    0.006    0.000 batchnorm.py:19(__init__)\n",
       "     1016    0.001    0.000    0.001    0.000 {method 'pop' of 'dict' objects}\n",
       "      133    0.001    0.000    0.002    0.000 pyparsing.py:3260(__init__)\n",
       "        2    0.001    0.000    0.001    0.000 {built-in method _openssl.SSL_library_init}\n",
       "      316    0.001    0.000    0.003    0.000 genericpath.py:39(isdir)\n",
       "      232    0.001    0.000    0.001    0.000 pyparsing.py:1154(__init__)\n",
       "       72    0.001    0.000    0.001    0.000 {built-in method tensor}\n",
       "      101    0.001    0.000    0.003    0.000 font_manager.py:850(_json_decode)\n",
       "      214    0.001    0.000    0.003    0.000 crc32c.py:114(crc32c)\n",
       "      245    0.001    0.000    0.005    0.000 optimizer.py:132(<dictcomp>)\n",
       "      254    0.001    0.000    0.008    0.000 rcsetup.py:342(validate_color_for_prop_cycle)\n",
       "      374    0.001    0.000    0.001    0.000 descriptor.py:524(__new__)\n",
       "      159    0.001    0.000    0.039    0.000 __init__.py:2193(fixup_namespace_packages)\n",
       "      600    0.001    0.000    0.015    0.000 Image.py:370(preinit)\n",
       "      130    0.001    0.000    0.003    0.000 textwrap.py:414(dedent)\n",
       "      223    0.001    0.000    0.001    0.000 sre_parse.py:223(__init__)\n",
       "      490    0.001    0.000    0.002    0.000 __init__.py:219(__init__)\n",
       "      159    0.001    0.000    0.052    0.000 __init__.py:2652(activate)\n",
       "      275    0.001    0.000    0.001    0.000 {built-in method _codecs.utf_8_decode}\n",
       "        1    0.001    0.001    0.001    0.001 binding.py:96(Binding)\n",
       "      243    0.001    0.000    0.001    0.000 sre_parse.py:294(_class_escape)\n",
       "       14    0.001    0.000    0.038    0.003 odefunc.py:99(__init__)\n",
       "    102/2    0.001    0.000    0.002    0.001 pyparsing.py:1370(_parseNoCache)\n",
       "      429    0.001    0.000    0.007    0.000 pyparsing.py:1177(copy)\n",
       "      130    0.001    0.000    0.001    0.000 {method 'findall' of '_sre.SRE_Pattern' objects}\n",
       "      576    0.001    0.000    0.001    0.000 <string>:12(__new__)\n",
       "      600    0.001    0.000    0.001    0.000 {method 'cleanup' of 'ImagingEncoder' objects}\n",
       "      355    0.001    0.000    0.001    0.000 warnings.py:468(__exit__)\n",
       "      107    0.001    0.000    0.047    0.000 event_file_writer.py:54(write_event)\n",
       "      132    0.001    0.000    0.022    0.000 __init__.py:2451(_version_from_file)\n",
       "      267    0.001    0.000    0.006    0.000 __init__.py:1404(has_metadata)\n",
       "     1321    0.001    0.000    0.001    0.000 inspect.py:2809(parameters)\n",
       "      454    0.001    0.000    0.010    0.000 traceback.py:283(line)\n",
       "      117    0.001    0.000    0.008    0.000 rcsetup.py:90(<listcomp>)\n",
       "      300    0.001    0.000    0.001    0.000 {method 'fileno' of '_io.BufferedRandom' objects}\n",
       "      848    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:707(find_spec)\n",
       "      372    0.001    0.000    0.001    0.000 inspect.py:2559(__eq__)\n",
       "      561    0.001    0.000    0.001    0.000 {method 'mro' of 'type' objects}\n",
       "      600    0.001    0.000    0.001    0.000 ImageFile.py:65(_tilesort)\n",
       "      393    0.001    0.000    0.023    0.000 inspect.py:2803(from_callable)\n",
       "       37    0.001    0.000    0.001    0.000 {built-in method _imp.exec_dynamic}\n",
       "       66    0.001    0.000    0.004    0.000 argparse.py:1307(add_argument)\n",
       "      266    0.001    0.000    0.001    0.000 {method 'decode' of 'bytes' objects}\n",
       "       19    0.001    0.000    0.012    0.001 rcsetup.py:825(validate_cycler)\n",
       "      107    0.001    0.000    0.004    0.000 event_file_writer.py:159(__init__)\n",
       "   268/71    0.001    0.000    0.006    0.000 typing.py:1145(__subclasscheck__)\n",
       "      428    0.001    0.000    0.001    0.000 {method 'write' of '_io.BufferedWriter' objects}\n",
       "      125    0.001    0.000    0.001    0.000 enum.py:70(__setitem__)\n",
       "      360    0.001    0.000    0.001    0.000 {method 'remove' of 'list' objects}\n",
       "      394    0.001    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:99(_path_isdir)\n",
       "       98    0.001    0.000    0.040    0.000 conv.py:307(__init__)\n",
       "      396    0.000    0.000    0.001    0.000 __init__.py:2456(is_version_line)\n",
       "      162    0.000    0.000    0.009    0.000 abc.py:151(register)\n",
       "      107    0.000    0.000    1.614    0.015 record_writer.py:105(__init__)\n",
       "      393    0.000    0.000    0.023    0.000 inspect.py:3055(signature)\n",
       "      100    0.000    0.000    0.001    0.000 sre_compile.py:376(_mk_bitmap)\n",
       "      320    0.000    0.000    0.003    0.000 __init__.py:1315(safe_name)\n",
       "      222    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
       "      444    0.000    0.000    0.001    0.000 sre_compile.py:539(isstring)\n",
       "      407    0.000    0.000    0.001    0.000 _weakrefset.py:20(__enter__)\n",
       "      848    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1202(<genexpr>)\n",
       "     1484    0.000    0.000    0.000    0.000 copy.py:190(_deepcopy_atomic)\n",
       "      366    0.000    0.000    0.001    0.000 rcsetup.py:118(validate_bool)\n",
       "      300    0.000    0.000    0.001    0.000 sampler.py:75(__len__)\n",
       "        1    0.000    0.000    0.827    0.827 _import_c_extension.py:3(<module>)\n",
       "      816    0.000    0.000    0.000    0.000 sre_parse.py:167(__setitem__)\n",
       "      177    0.000    0.000    0.011    0.000 rcsetup.py:69(f)\n",
       "      323    0.000    0.000    0.034    0.000 <frozen importlib._bootstrap_external>:1216(find_loader)\n",
       "      380    0.000    0.000    0.001    0.000 train_misc.py:17(_set)\n",
       "      100    0.000    0.000    0.000    0.000 sre_compile.py:378(<listcomp>)\n",
       "       66    0.000    0.000    0.001    0.000 argparse.py:157(__init__)\n",
       "      275    0.000    0.000    0.001    0.000 codecs.py:318(decode)\n",
       "      132    0.000    0.000    0.001    0.000 deprecation.py:23(_generate_deprecation_message)\n",
       "       86    0.000    0.000    0.001    0.000 _oid.py:11(__init__)\n",
       "       75    0.000    0.000    0.001    0.000 cm.py:65(_reverse_cmap_spec)\n",
       "        2    0.000    0.000    0.001    0.000 traceback.py:386(format)\n",
       "       40    0.000    0.000    0.009    0.000 linecache.py:82(updatecache)\n",
       "        1    0.000    0.000    0.010    0.010 utils.py:13(get_logger)\n",
       "     1024    0.000    0.000    0.000    0.000 version.py:352(<lambda>)\n",
       "       14    0.000    0.000    0.025    0.002 gate.py:49(__init__)\n",
       "        1    0.000    0.000    0.042    0.042 optimizer.py:95(load_state_dict)\n",
       "      121    0.000    0.000    0.005    0.000 __init__.py:1407(get_metadata)\n",
       "       88    0.000    0.000    0.001    0.000 abc.py:135(<setcomp>)\n",
       "       83    0.000    0.000    0.001    0.000 pyparsing.py:3326(__init__)\n",
       "      300    0.000    0.000    0.004    0.000 dataloader.py:821(__len__)\n",
       "      297    0.000    0.000    0.006    0.000 sre_parse.py:96(closegroup)\n",
       "      785    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:825(get_filename)\n",
       "      816    0.000    0.000    0.000    0.000 module.py:1012(_get_name)\n",
       "      222    0.000    0.000    0.001    0.000 sre_parse.py:828(fix_flags)\n",
       "      946    0.000    0.000    0.000    0.000 {built-in method builtins.chr}\n",
       "      928    0.000    0.000    0.000    0.000 inspect.py:2813(return_annotation)\n",
       "      106    0.000    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:1322(path_hook_for_FileFinder)\n",
       "        1    0.000    0.000    0.902    0.902 serialization.py:300(load)\n",
       "      237    0.000    0.000    0.010    0.000 linecache.py:15(getline)\n",
       "     1051    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
       "     1176    0.000    0.000    0.000    0.000 __init__.py:1997(__bool__)\n",
       "      100    0.000    0.000    0.001    0.000 init.py:8(calculate_gain)\n",
       "      357    0.000    0.000    0.011    0.000 module.py:260(<lambda>)\n",
       "      149    0.000    0.000    0.034    0.000 utils.py:38(register_decorator)\n",
       "      518    0.000    0.000    0.000    0.000 module.py:538(remove_from)\n",
       "  263/261    0.000    0.000    0.001    0.000 pyparsing.py:382(__init__)\n",
       "        2    0.000    0.000    0.003    0.002 decoder.py:345(raw_decode)\n",
       "        1    0.000    0.000    0.019    0.019 mathtext.py:2738(<listcomp>)\n",
       "      768    0.000    0.000    0.000    0.000 version.py:332(_parse_local_version)\n",
       "       14    0.000    0.000    0.032    0.002 cnf_gate.py:21(__init__)\n",
       "      132    0.000    0.000    0.023    0.000 __init__.py:2858(_reload_version)\n",
       "       16    0.000    0.000    0.001    0.000 enum.py:160(<setcomp>)\n",
       "      824    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:424(has_location)\n",
       "      267    0.000    0.000    0.002    0.000 __init__.py:1509(_has)\n",
       "       60    0.000    0.000    0.003    0.000 six.py:837(wrapper)\n",
       "      785    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:669(create_module)\n",
       "      393    0.000    0.000    0.001    0.000 inspect.py:505(_is_wrapper)\n",
       "      355    0.000    0.000    0.000    0.000 warnings.py:428(__init__)\n",
       "      130    0.000    0.000    0.001    0.000 pyplot.py:1795(<genexpr>)\n",
       "       19    0.000    0.000    0.001    0.000 cycler.py:349(by_key)\n",
       "        4    0.000    0.000    1.657    0.414 cifar.py:134(_check_integrity)\n",
       "        6    0.000    0.000    0.006    0.001 patches.py:1830(_pprint_styles)\n",
       "      432    0.000    0.000    0.000    0.000 colors.py:204(<genexpr>)\n",
       "        1    0.000    0.000    0.029    0.029 auto.py:268(_generate_function_classes)\n",
       "       54    0.000    0.000    0.002    0.000 __init__.py:961(_open_file_or_url)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method gc.collect}\n",
       "     72/4    0.000    0.000    0.003    0.001 pyparsing.py:1564(_parseCache)\n",
       "      322    0.000    0.000    0.163    0.001 re.py:231(compile)\n",
       "      178    0.000    0.000    0.001    0.000 _jit_internal.py:34(createResolutionCallback)\n",
       "      642    0.000    0.000    0.000    0.000 record_writer.py:132(u32)\n",
       "       56    0.000    0.000    0.033    0.001 basic.py:152(__init__)\n",
       "      263    0.000    0.000    0.001    0.000 pyparsing.py:373(__new__)\n",
       "      236    0.000    0.000    0.000    0.000 linecache.py:147(lazycache)\n",
       "      157    0.000    0.000    0.001    0.000 posixpath.py:64(isabs)\n",
       "      490    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
       "        1    0.000    0.000    0.002    0.002 numerictypes.py:81(<module>)\n",
       "      884    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
       "      100    0.000    0.000    0.001    0.000 init.py:50(uniform_)\n",
       "      237    0.000    0.000    0.009    0.000 linecache.py:37(getlines)\n",
       "      495    0.000    0.000    0.000    0.000 {built-in method torch._C._add_docstr}\n",
       "        9    0.000    0.000    0.001    0.000 auto.py:14(_make_function_class_criterion)\n",
       "       39    0.000    0.000    0.001    0.000 _inspect.py:142(formatargspec)\n",
       "      160    0.000    0.000    0.053    0.000 __init__.py:3153(<genexpr>)\n",
       "      247    0.000    0.000    0.000    0.000 {built-in method _make_subclass}\n",
       "        1    0.000    0.000    0.001    0.001 optimizer.py:174(add_param_group)\n",
       "      490    0.000    0.000    0.000    0.000 __init__.py:231(__exit__)\n",
       "       26    0.000    0.000    0.002    0.000 tokenize.py:448(open)\n",
       "       66    0.000    0.000    0.001    0.000 argparse.py:1444(_get_optional_kwargs)\n",
       "      847    0.000    0.000    0.000    0.000 train_cnf_disentangle_rl.py:622(<lambda>)\n",
       "      374    0.000    0.000    0.000    0.000 {method 'FindFieldByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "      107    0.000    0.000    0.045    0.000 event_file_writer.py:63(_write_serialized_event)\n",
       "      247    0.000    0.000    0.001    0.000 parameter.py:23(__new__)\n",
       "      304    0.000    0.000    0.000    0.000 __init__.py:1837(__init__)\n",
       "       84    0.000    0.000    0.000    0.000 docstring.py:40(__call__)\n",
       "       84    0.000    0.000    0.002    0.000 pyparsing.py:3390(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.SSL_load_error_strings}\n",
       "        1    0.000    0.000    0.034    0.034 pyparsing.py:76(<module>)\n",
       "       82    0.000    0.000    0.001    0.000 pyparsing.py:3719(__init__)\n",
       "      350    0.000    0.000    0.001    0.000 pkgutil.py:402(get_importer)\n",
       "      150    0.000    0.000    0.012    0.000 cm.py:81(_generate_cmap)\n",
       "        1    0.000    0.000    0.006    0.006 mlab.py:155(<module>)\n",
       "      286    0.000    0.000    0.001    0.000 _tensor_docs.py:8(add_docstr_all)\n",
       "      490    0.000    0.000    0.000    0.000 __init__.py:223(__enter__)\n",
       "      120    0.000    0.000    0.001    0.000 module.py:161(add_module)\n",
       "    63/11    0.000    0.000    0.006    0.001 pyparsing.py:3463(parseImpl)\n",
       "        2    0.000    0.000    0.018    0.009 {built-in method builtins.sum}\n",
       "      145    0.000    0.000    0.001    0.000 inspect.py:714(getmodule)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:104(_init)\n",
       "      407    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)\n",
       "        1    0.000    0.000    0.003    0.003 core.py:21(<module>)\n",
       "        1    0.000    0.000 151147.755 151147.755 interactiveshell.py:2637(safe_execfile)\n",
       "   114/58    0.000    0.000    0.001    0.000 typing.py:1164(__setattr__)\n",
       "    40/39    0.000    0.000    0.002    0.000 typing.py:875(__extrahook__)\n",
       "   131/65    0.000    0.000    0.006    0.000 pyparsing.py:3363(copy)\n",
       "       57    0.000    0.000    0.001    0.000 sre_parse.py:266(getuntil)\n",
       "        1    0.000    0.000    0.269    0.269 pyplot.py:19(<module>)\n",
       "       66    0.000    0.000    0.001    0.000 pyparsing.py:3785(__init__)\n",
       "      276    0.000    0.000    0.000    0.000 functools.py:74(wraps)\n",
       "      300    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
       "      490    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.FloatStorageBase' objects}\n",
       "       50    0.000    0.000    0.015    0.000 traceback.py:200(extract_stack)\n",
       "      410    0.000    0.000    0.000    0.000 artist.py:1235(aliased_name)\n",
       "      582    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "      108    0.000    0.000    0.002    0.000 deprecation.py:237(finalize)\n",
       "      407    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)\n",
       "        1    0.000    0.000    0.000    0.000 _cm_listed.py:1(<module>)\n",
       "      222    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
       "      100    0.000    0.000    0.002    0.000 init.py:251(_calculate_correct_fan)\n",
       "   131/65    0.000    0.000    0.005    0.000 pyparsing.py:3365(<listcomp>)\n",
       "       33    0.000    0.000    0.001    0.000 container.py:187(extend)\n",
       "       30    0.000    0.000    0.000    0.000 {method 'readline' of '_io.BufferedReader' objects}\n",
       "      296    0.000    0.000    0.000    0.000 weakref.py:406(__setitem__)\n",
       "      168    0.000    0.000    0.003    0.000 docstring.py:90(dedent)\n",
       "        1    0.000    0.000    0.004    0.004 summary_pb2.py:4(<module>)\n",
       "       67    0.000    0.000    0.001    0.000 pyparsing.py:3456(__init__)\n",
       "      286    0.000    0.000    0.000    0.000 traceback.py:290(walk_stack)\n",
       "       66    0.000    0.000    0.002    0.000 pyparsing.py:1843(__add__)\n",
       "   121/59    0.000    0.000    0.006    0.000 pyparsing.py:3429(copy)\n",
       "      445    0.000    0.000    0.000    0.000 {method '__subclasses__' of 'type' objects}\n",
       "      300    0.000    0.000    0.000    0.000 JpegImagePlugin.py:665(validate_qtables)\n",
       "      107    0.000    0.000    0.001    0.000 os.py:664(__getitem__)\n",
       "      112    0.000    0.000    0.001    0.000 module.py:87(register_buffer)\n",
       "      101    0.000    0.000    0.002    0.000 compilerop.py:137(check_linecache_ipython)\n",
       "      107    0.000    0.000    0.000    0.000 {built-in method _socket.gethostname}\n",
       "       91    0.000    0.000    0.001    0.000 _jit_internal.py:105(weak_script_method)\n",
       "      164    0.000    0.000    0.000    0.000 colors.py:439(__init__)\n",
       "      300    0.000    0.000    0.000    0.000 {method 'flush' of '_io.BytesIO' objects}\n",
       "        4    0.000    0.000    0.000    0.000 numeric.py:2916(extend_all)\n",
       "        1    0.000    0.000    0.001    0.001 step_stats_pb2.py:4(<module>)\n",
       "      409    0.000    0.000    0.000    0.000 utils.py:47(__init__)\n",
       "        1    0.000    0.000    0.019    0.019 pyparsing.py:75(<module>)\n",
       "       33    0.000    0.000    0.001    0.000 __init__.py:1161(getLogger)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:1896(_define_aliases)\n",
       "      178    0.000    0.000    0.000    0.000 inspect.py:1493(currentframe)\n",
       "       60    0.000    0.000    0.001    0.000 rcsetup.py:72(<listcomp>)\n",
       "      164    0.000    0.000    0.000    0.000 sre_compile.py:441(_get_charset_prefix)\n",
       "   121/59    0.000    0.000    0.004    0.000 pyparsing.py:3431(<listcomp>)\n",
       "        1    0.000    0.000    0.011    0.011 _axes.py:119(Axes)\n",
       "     33/5    0.000    0.000    0.001    0.000 pyparsing.py:3385(streamline)\n",
       "       79    0.000    0.000    0.000    0.000 sre_parse.py:784(_parse_flags)\n",
       "      101    0.000    0.000    0.002    0.000 linecache.py:53(checkcache)\n",
       "      2/1    0.000    0.000    0.001    0.001 copy.py:210(_deepcopy_list)\n",
       "       69    0.000    0.000    0.000    0.000 pyparsing.py:2412(__init__)\n",
       "        1    0.000    0.000    0.035    0.035 core.py:182(read_style_directory)\n",
       "      144    0.000    0.000    0.000    0.000 pyparsing.py:2226(__hash__)\n",
       "      148    0.000    0.000    0.000    0.000 _oid.py:58(__hash__)\n",
       "      126    0.000    0.000    0.000    0.000 colors.py:639(__init__)\n",
       "      322    0.000    0.000    0.000    0.000 rcsetup.py:144(validate_float)\n",
       "      586    0.000    0.000    0.000    0.000 {built-in method _CheckCalledFromGeneratedFile}\n",
       "        1    0.000    0.000    0.327    0.327 event_pb2.py:4(<module>)\n",
       "      166    0.000    0.000    0.000    0.000 six.py:141(__init__)\n",
       "      160    0.000    0.000    0.000    0.000 __init__.py:666(__iter__)\n",
       "    58/10    0.000    0.000    0.006    0.001 pyparsing.py:3354(leaveWhitespace)\n",
       "       83    0.000    0.000    0.002    0.000 pyparsing.py:1821(__add__)\n",
       "      266    0.000    0.000    0.000    0.000 pyparsing.py:3270(<genexpr>)\n",
       "      414    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _color_data.py:992(<dictcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 getlimits.py:3(<module>)\n",
       "    37/34    0.000    0.000    0.182    0.005 <frozen importlib._bootstrap_external>:919(create_module)\n",
       "      121    0.000    0.000    0.005    0.000 __init__.py:1413(get_metadata_lines)\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:765(copy)\n",
       "        1    0.000    0.000    0.000    0.000 attr_value_pb2.py:4(<module>)\n",
       "    61/11    0.000    0.000    0.006    0.001 pyparsing.py:3288(leaveWhitespace)\n",
       "      252    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.can_cast}\n",
       "       39    0.000    0.000    0.001    0.000 __init__.py:1563(_add_data_doc)\n",
       "       88    0.000    0.000    0.001    0.000 docstring.py:122(<lambda>)\n",
       "      107    0.000    0.000    0.000    0.000 threading.py:1136(daemon)\n",
       "      168    0.000    0.000    0.000    0.000 rcsetup.py:59(__call__)\n",
       "       48    0.000    0.000    0.041    0.001 genericpath.py:27(isfile)\n",
       "      393    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
       "      274    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "       27    0.000    0.000    0.002    0.000 core.py:172(iter_style_files)\n",
       "        1    0.000    0.000    0.003    0.003 numeric.py:1(<module>)\n",
       "        1    0.000    0.000    0.006    0.006 subprocess.py:1208(_execute_child)\n",
       "      113    0.000    0.000    0.000    0.000 os.py:742(encode)\n",
       "        1    0.000    0.000    0.086    0.086 __init__.py:106(<module>)\n",
       "       14    0.000    0.000    0.002    0.000 posixpath.py:393(_joinrealpath)\n",
       "        1    0.000    0.000    0.008    0.008 optimizer.py:32(__init__)\n",
       "      164    0.000    0.000    0.000    0.000 abc.py:9(abstractmethod)\n",
       "        3    0.000    0.000    0.131    0.044 functional.py:1(<module>)\n",
       "      364    0.000    0.000    0.000    0.000 module.py:1015(extra_repr)\n",
       "       87    0.000    0.000    0.001    0.000 _jit_internal.py:83(weak_script)\n",
       "       26    0.000    0.000    0.001    0.000 tokenize.py:355(detect_encoding)\n",
       "       54    0.000    0.000    0.000    0.000 pyparsing.py:2870(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 layout_pb2.py:4(<module>)\n",
       "      107    0.000    0.000    0.000    0.000 writer.py:53(__init__)\n",
       "       27    0.000    0.000    0.012    0.000 pyparsing.py:2816(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:118(__repr__)\n",
       "      168    0.000    0.000    0.000    0.000 typing.py:1019(_abc_negative_cache)\n",
       "      164    0.000    0.000    0.000    0.000 rcsetup.py:399(validate_string)\n",
       "      107    0.000    0.000    0.000    0.000 queue.py:199(_init)\n",
       "      224    0.000    0.000    0.000    0.000 patches.py:1822(<genexpr>)\n",
       "       27    0.000    0.000    0.040    0.001 __init__.py:1056(rc_params_from_file)\n",
       "      143    0.000    0.000    0.000    0.000 __init__.py:422(<genexpr>)\n",
       "      108    0.000    0.000    0.000    0.000 utils.py:33(read_only_property)\n",
       "       28    0.000    0.000    0.000    0.000 batchnorm.py:43(reset_running_stats)\n",
       "       32    0.000    0.000    0.000    0.000 __init__.py:1212(_fixupParents)\n",
       "        1    0.000    0.000    0.015    0.015 cm.py:19(<module>)\n",
       "       53    0.000    0.000    0.000    0.000 core.py:893(__init__)\n",
       "       32    0.000    0.000    0.000    0.000 __init__.py:1268(__init__)\n",
       "      300    0.000    0.000    0.000    0.000 {method 'close' of '_io.BytesIO' objects}\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1796(get_metadata)\n",
       "        1    0.000    0.000    0.069    0.069 __init__.py:101(<module>)\n",
       "      158    0.000    0.000    0.000    0.000 argparse.py:1282(_registry_get)\n",
       "        1    0.000    0.000    0.003    0.003 kl.py:1(<module>)\n",
       "        1    0.000    0.000    0.051    0.051 add_newdocs.py:10(<module>)\n",
       "       37    0.000    0.000    0.000    0.000 pyparsing.py:2852(parseImpl)\n",
       "      282    0.000    0.000    0.000    0.000 {method 'zfill' of 'str' objects}\n",
       "       72    0.000    0.000    0.000    0.000 pyparsing.py:1509(set)\n",
       "       80    0.000    0.000    0.003    0.000 docstring.py:109(dedent_interpd)\n",
       "        1    0.000    0.000    0.046    0.046 rcsetup.py:15(<module>)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:1364(_add_action)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1775(_parse_known_args)\n",
       "      125    0.000    0.000    0.000    0.000 enum.py:28(_is_dunder)\n",
       "       28    0.000    0.000    0.000    0.000 {built-in method ones}\n",
       "       67    0.000    0.000    0.000    0.000 auto.py:95(_find_buffers)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:933(<dictcomp>)\n",
       "       16    0.000    0.000    0.006    0.000 rcsetup.py:740(cycler)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:580(_format_args)\n",
       "       10    0.000    0.000    0.005    0.000 pyparsing.py:2675(__init__)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:1555(_add_action)\n",
       "       26    0.000    0.000    0.026    0.001 pyparsing.py:2779(__init__)\n",
       "        2    0.000    0.000    0.230    0.115 __init__.py:41(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 inspect.py:317(getmembers)\n",
       "       28    0.000    0.000    0.001    0.000 batchnorm.py:49(reset_parameters)\n",
       "      148    0.000    0.000    0.000    0.000 rcsetup.py:52(func)\n",
       "      321    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
       "       12    0.000    0.000    0.001    0.000 pyparsing.py:2653(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}\n",
       "      121    0.000    0.000    0.000    0.000 pyparsing.py:1361(preParse)\n",
       "      236    0.000    0.000    0.000    0.000 traceback.py:243(__init__)\n",
       "        1    0.000    0.000    0.017    0.017 pyparsing.py:5558(pyparsing_common)\n",
       "        1    0.000    0.000    0.040    0.040 extensions.py:5(<module>)\n",
       "       27    0.000    0.000    0.003    0.000 pyparsing.py:1039(_trim_arity)\n",
       "      204    0.000    0.000    0.000    0.000 patches.py:1815(<genexpr>)\n",
       "        1    0.000    0.000    0.002    0.002 serialization.py:1(<module>)\n",
       "      143    0.000    0.000    0.000    0.000 __init__.py:420(<genexpr>)\n",
       "       19    0.000    0.000    0.001    0.000 path.py:96(__init__)\n",
       "      113    0.000    0.000    0.000    0.000 typing.py:1033(_abc_negative_cache_version)\n",
       "       75    0.000    0.000    0.000    0.000 codecs.py:308(__init__)\n",
       "     19/4    0.000    0.000    0.001    0.000 pyparsing.py:3319(streamline)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._autograd_init}\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:67(getargs)\n",
       "      168    0.000    0.000    0.000    0.000 typing.py:1089(__eq__)\n",
       "        1    0.000    0.000    0.000    0.000 TiffTags.py:349(_populate)\n",
       "       36    0.000    0.000    0.000    0.000 pyparsing.py:2434(__init__)\n",
       "       16    0.000    0.000    0.000    0.000 enum.py:464(_find_new_)\n",
       "        2    0.000    0.000    0.005    0.002 ec.py:5(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 getlimits.py:65(__init__)\n",
       "       48    0.000    0.000    0.001    0.000 pyparsing.py:3540(__init__)\n",
       "      120    0.000    0.000    0.000    0.000 pyparsing.py:2368(__init__)\n",
       "       17    0.000    0.000    0.000    0.000 cycler.py:191(_from_iter)\n",
       "        1    0.000    0.000    0.001    0.001 _torch_docs.py:1(<module>)\n",
       "       60    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.arange}\n",
       "      312    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
       "      166    0.000    0.000    0.000    0.000 pyparsing.py:3336(<genexpr>)\n",
       "       41    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "       60    0.000    0.000    0.000    0.000 cm.py:60(<listcomp>)\n",
       "        1    0.000    0.000    0.003    0.003 pyparsing.py:5028(_makeTags)\n",
       "       37    0.000    0.000    0.001    0.000 contextlib.py:129(contextmanager)\n",
       "        1    0.000    0.000    0.002    0.002 markers.py:4(<module>)\n",
       "       31    0.000    0.000    0.000    0.000 cm.py:48(revcmap)\n",
       "        1    0.000    0.000    0.001    0.001 arrayprint.py:5(<module>)\n",
       "       45    0.000    0.000    0.001    0.000 posixpath.py:369(abspath)\n",
       "        1    0.000    0.000    0.001    0.001 _tensor_docs.py:1(<module>)\n",
       "       55    0.000    0.000    0.000    0.000 rcsetup.py:939(_validate_linestyle)\n",
       "       65    0.000    0.000    0.000    0.000 enum.py:20(_is_descriptor)\n",
       "        1    0.000    0.000    0.304    0.304 __init__.py:16(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 pyparsing.py:5399(pyparsing_common)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:79(Certificate)\n",
       "       59    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:861(_find_spec_legacy)\n",
       "       11    0.000    0.000    0.107    0.010 __init__.py:5(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 core.py:47(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:120(<listcomp>)\n",
       "      111    0.000    0.000    0.000    0.000 _jit_internal.py:98(weak_module)\n",
       "       26    0.000    0.000    0.000    0.000 numerictypes.py:229(bitname)\n",
       "       63    0.000    0.000    0.000    0.000 rcsetup.py:429(validate_fontsize)\n",
       "    82/80    0.000    0.000    0.000    0.000 pyparsing.py:372(__init__)\n",
       "        1    0.000    0.000    0.017    0.017 __init__.py:72(<module>)\n",
       "       28    0.000    0.000    0.010    0.000 batchnorm.py:82(_load_from_state_dict)\n",
       "       84    0.000    0.000    0.000    0.000 activation.py:617(extra_repr)\n",
       "       16    0.000    0.000    0.000    0.000 enum.py:114(__prepare__)\n",
       "       34    0.000    0.000    0.000    0.000 enum.py:419(_get_mixins_)\n",
       "      214    0.000    0.000    0.000    0.000 crc32c.py:100(crc_finalize)\n",
       "        2    0.000    0.000    0.016    0.008 __init__.py:7(<module>)\n",
       "      277    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.add_docstring}\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:1480(_pop_action_class)\n",
       "      252    0.000    0.000    0.000    0.000 six.py:88(__init__)\n",
       "        4    0.000    0.000    0.023    0.006 __init__.py:3(<module>)\n",
       "      113    0.000    0.000    0.000    0.000 descriptor.py:690(__new__)\n",
       "        1    0.000    0.000    0.006    0.006 __init__.py:57(<module>)\n",
       "        1    0.000    0.000    0.047    0.047 backend.py:5(<module>)\n",
       "       23    0.000    0.000    0.003    0.000 pyparsing.py:1049(_trim_arity)\n",
       "      258    0.000    0.000    0.000    0.000 {method 'end' of '_sre.SRE_Match' objects}\n",
       "        1    0.000    0.000    0.192    0.192 __init__.py:3126(_initialize_master_working_set)\n",
       "        1    0.000    0.000    0.015    0.015 __init__.py:184(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 descriptor.py:281(__new__)\n",
       "      148    0.000    0.000    0.000    0.000 utils.py:34(<lambda>)\n",
       "       23    0.000    0.000    0.000    0.000 rcsetup.py:57(<dictcomp>)\n",
       "        1    0.000    0.000    0.053    0.053 requirements.py:4(<module>)\n",
       "       61    0.000    0.000    0.004    0.000 pyparsing.py:3292(<listcomp>)\n",
       "      302    0.000    0.000    0.000    0.000 __init__.py:907(__iter__)\n",
       "       65    0.000    0.000    0.000    0.000 argparse.py:835(__init__)\n",
       "       48    0.000    0.000    0.001    0.000 pyparsing.py:1948(__or__)\n",
       "        1    0.000    0.000    0.879    0.879 workspace.py:3(<module>)\n",
       "       30    0.000    0.000    0.000    0.000 tokenize.py:385(find_cookie)\n",
       "       68    0.000    0.000    0.001    0.000 posixpath.py:168(islink)\n",
       "       37    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:927(exec_module)\n",
       "        1    0.000    0.000    0.000    0.000 figure.py:250(Figure)\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:68(RegisterMessage)\n",
       "      170    0.000    0.000    0.000    0.000 pyparsing.py:2061(setWhitespaceChars)\n",
       "        1    0.000    0.000    0.000    0.000 _mathtext_data.py:1751(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 encode_asn1.py:5(<module>)\n",
       "        2    0.000    0.000    0.056    0.028 base.py:5(<module>)\n",
       "      125    0.000    0.000    0.000    0.000 enum.py:36(_is_sunder)\n",
       "      103    0.000    0.000    0.000    0.000 TiffTags.py:26(__new__)\n",
       "      189    0.000    0.000    0.000    0.000 status_codes.py:112(<genexpr>)\n",
       "       14    0.000    0.000    0.002    0.000 odefunc_rl.py:257(__init__)\n",
       "       83    0.000    0.000    0.000    0.000 pyparsing.py:2390(__init__)\n",
       "       32    0.000    0.000    0.000    0.000 copyreg.py:96(_slotnames)\n",
       "        1    0.000    0.000    0.007    0.007 TiffImagePlugin.py:42(<module>)\n",
       "       29    0.000    0.000    0.000    0.000 contextlib.py:59(__init__)\n",
       "      172    0.000    0.000    0.000    0.000 {method 'ndimension' of 'torch._C._TensorBase' objects}\n",
       "      159    0.000    0.000    0.000    0.000 __init__.py:919(_added_new)\n",
       "       68    0.000    0.000    0.000    0.000 status_codes.py:111(doc)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:98(getargspec)\n",
       "       24    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:2826(__str__)\n",
       "        1    0.000    0.000    0.001    0.001 markers.py:165(MarkerStyle)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2710(MaskedArray)\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:1079(wrapper)\n",
       "       21    0.000    0.000    0.001    0.000 argparse.py:1843(consume_optional)\n",
       "        8    0.000    0.000    0.002    0.000 utils.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 resource_handle_pb2.py:4(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 pyparsing.py:363(__new__)\n",
       "       30    0.000    0.000    0.002    0.000 activation.py:41(__init__)\n",
       "       76    0.000    0.000    0.000    0.000 __init__.py:329(iterable)\n",
       "       34    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:50(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:170(<dictcomp>)\n",
       "       26    0.000    0.000    0.000    0.000 argparse.py:2286(_get_value)\n",
       "       25    0.000    0.000    0.003    0.000 pyparsing.py:1250(setParseAction)\n",
       "       29    0.000    0.000    0.000    0.000 contextlib.py:85(__exit__)\n",
       "       34    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
       "     20/8    0.000    0.000    0.001    0.000 pyparsing.py:3547(parseImpl)\n",
       "        1    0.000    0.000    0.088    0.088 crypto.py:1(<module>)\n",
       "       21    0.000    0.000    0.003    0.000 pyparsing.py:1260(setParseAction)\n",
       "        2    0.000    0.000    0.000    0.000 traceback.py:367(from_list)\n",
       "       31    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "      160    0.000    0.000    0.000    0.000 cycler.py:227(<genexpr>)\n",
       "       35    0.000    0.000    0.000    0.000 sre_compile.py:393(_generate_overlap_table)\n",
       "       11    0.000    0.000    0.086    0.008 artist.py:1511(kwdoc)\n",
       "       86    0.000    0.000    0.000    0.000 pyparsing.py:3505(<genexpr>)\n",
       "       15    0.000    0.000    0.000    0.000 pathlib.py:51(parse_parts)\n",
       "        1    0.000    0.000    0.004    0.004 tensor_pb2.py:4(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 path.py:193(_update_values)\n",
       "       79    0.000    0.000    0.000    0.000 __init__.py:870(__getitem__)\n",
       "      145    0.000    0.000    0.000    0.000 inspect.py:64(ismodule)\n",
       "       26    0.000    0.000    0.003    0.000 pyparsing.py:1047(extract_stack)\n",
       "       96    0.000    0.000    0.000    0.000 pyparsing.py:2153(__str__)\n",
       "       24    0.000    0.000    0.001    0.000 dviread.py:155(decorate)\n",
       "       33    0.000    0.000    0.004    0.000 container.py:119(__init__)\n",
       "       60    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.result_type}\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2923(<listcomp>)\n",
       "       30    0.000    0.000    0.000    0.000 rcsetup.py:288(__call__)\n",
       "       92    0.000    0.000    0.000    0.000 textwrap.py:479(prefixed_lines)\n",
       "       82    0.000    0.000    0.000    0.000 types.py:135(__get__)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:37(<listcomp>)\n",
       "        1    0.000    0.000    0.002    0.002 lapack.py:461(<module>)\n",
       "       22    0.000    0.000    0.001    0.000 artist.py:32(allow_rasterization)\n",
       "      163    0.000    0.000    0.000    0.000 {method '__subclasshook__' of 'object' objects}\n",
       "        1    0.000    0.000    0.019    0.019 mathtext.py:2202(Parser)\n",
       "       14    0.000    0.000    0.001    0.000 pooling.py:14(__init__)\n",
       "      100    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
       "       72    0.000    0.000    0.000    0.000 pyparsing.py:1506(get)\n",
       "       55    0.000    0.000    0.000    0.000 rcsetup.py:667(__call__)\n",
       "       75    0.000    0.000    0.000    0.000 codecs.py:259(__init__)\n",
       "        4    0.000    0.000    0.073    0.018 odenvp_conditional_rl.py:194(__init__)\n",
       "       20    0.000    0.000    0.000    0.000 pyparsing.py:2813(parseImpl)\n",
       "      188    0.000    0.000    0.000    0.000 __init__.py:2498(_reload_version)\n",
       "       66    0.000    0.000    0.001    0.000 argparse.py:2352(_get_formatter)\n",
       "        2    0.000    0.000    0.008    0.004 ocsp.py:5(<module>)\n",
       "       22    0.000    0.000    0.003    0.000 pyparsing.py:1057(extract_stack)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:299(_add_aliases)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:793(__init__)\n",
       "        1    0.000    0.000    0.075    0.075 odenvp_conditional_rl.py:21(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 node_def_pb2.py:4(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3037(_find_adapter)\n",
       "        1    0.000    0.000    0.008    0.008 font_manager.py:21(<module>)\n",
       "       58    0.000    0.000    0.004    0.000 pyparsing.py:3358(<listcomp>)\n",
       "      186    0.000    0.000    0.000    0.000 {method 'ljust' of 'str' objects}\n",
       "        1    0.000    0.000    0.014    0.014 patches.py:1(<module>)\n",
       "        3    0.000    0.000    0.099    0.033 __init__.py:6(<module>)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:38(register_kl)\n",
       "        1    0.000    0.000    0.001    0.001 extras.py:10(<module>)\n",
       "      158    0.000    0.000    0.000    0.000 pyparsing.py:3458(<genexpr>)\n",
       "      211    0.000    0.000    0.000    0.000 {method 'start' of '_sre.SRE_Match' objects}\n",
       "       82    0.000    0.000    0.000    0.000 {method 'FindMessageTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        1    0.000    0.000    0.021    0.021 keys.py:15(<module>)\n",
       "       36    0.000    0.000    0.001    0.000 __init__.py:1838(getLogger)\n",
       "      8/6    0.000    0.000    0.005    0.001 __init__.py:2159(declare_namespace)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:5(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:930(__init__)\n",
       "       51    0.000    0.000    0.000    0.000 _internal.py:715(_ufunc_doc_signature_formatter)\n",
       "       86    0.000    0.000    0.000    0.000 six.py:105(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:4(<module>)\n",
       "      100    0.000    0.000    0.000    0.000 six.py:177(_add_module)\n",
       "        1    0.000    0.000    0.000    0.000 _mathtext_data.py:3(<module>)\n",
       "       17    0.000    0.000    0.000    0.000 cycler.py:112(__init__)\n",
       "        3    0.000    0.000    0.007    0.002 __init__.py:15(<module>)\n",
       "        1    0.000    0.000    0.034    0.034 utils.py:9(<module>)\n",
       "       93    0.000    0.000    0.000    0.000 pyparsing.py:219(__init__)\n",
       "       14    0.000    0.000    0.040    0.003 odenvp_conditional_rl.py:209(_make_odefunc)\n",
       "        1    0.000    0.000    0.026    0.026 textpath.py:1(<module>)\n",
       "        1    0.000    0.000    0.142    0.142 pyopenssl.py:43(<module>)\n",
       "      115    0.000    0.000    0.000    0.000 pyparsing.py:2175(__str__)\n",
       "    24/12    0.000    0.000    0.002    0.000 pyparsing.py:3613(parseImpl)\n",
       "        1    0.000    0.000    0.003    0.003 oid.py:5(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 utils.py:5(_ntuple)\n",
       "  109/105    0.000    0.000    0.001    0.000 __init__.py:409(wrapper)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1740(parse_known_args)\n",
       "        1    0.000    0.000    0.023    0.023 tokenize.py:26(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 serialization.py:5(<module>)\n",
       "      149    0.000    0.000    0.000    0.000 utils.py:37(register_interface)\n",
       "       44    0.000    0.000    0.001    0.000 core.py:149(get_object_signature)\n",
       "      126    0.000    0.000    0.000    0.000 deprecation.py:115(deprecated)\n",
       "      139    0.000    0.000    0.000    0.000 pyparsing.py:3543(<genexpr>)\n",
       "       28    0.000    0.000    0.007    0.000 gate.py:115(conv3x3)\n",
       "        1    0.000    0.000    0.068    0.068 figure.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _pylab_helpers.py:10(Gcf)\n",
       "        1    0.000    0.000    0.021    0.021 mathtext.py:16(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:87(LookupDict)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.Cryptography_add_osrandom_engine}\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:286(Verbose)\n",
       "      138    0.000    0.000    0.000    0.000 cycler.py:212(<genexpr>)\n",
       "        1    0.000    0.000    0.010    0.010 util.py:150(_get_soname)\n",
       "       30    0.000    0.000    0.010    0.000 __init__.py:826(__init__)\n",
       "       41    0.000    0.000    0.000    0.000 __init__.py:219(_acquireLock)\n",
       "       30    0.000    0.000    0.000    0.000 sre_parse.py:257(getwhile)\n",
       "       37    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:908(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:83(<listcomp>)\n",
       "      195    0.000    0.000    0.000    0.000 pyparsing.py:3392(<genexpr>)\n",
       "      137    0.000    0.000    0.000    0.000 pyparsing.py:2083(setWhitespaceChars)\n",
       "        1    0.000    0.000    0.000    0.000 _color_data.py:1(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 backend.py:13(register_function)\n",
       "      101    0.000    0.000    0.000    0.000 _inspect.py:133(strseq)\n",
       "       94    0.000    0.000    0.000    0.000 pyparsing.py:5043(<genexpr>)\n",
       "       29    0.000    0.000    0.000    0.000 typing.py:1025(_abc_negative_cache)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:1822(take_action)\n",
       "       27    0.000    0.000    0.000    0.000 locale.py:631(getpreferredencoding)\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:85(RegisterMessageDescriptor)\n",
       "       69    0.000    0.000    0.000    0.000 __init__.py:1265(<lambda>)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6573(getdoc)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:70(<lambda>)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:564(_metavar_formatter)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2234(_get_values)\n",
       "       41    0.000    0.000    0.000    0.000 __init__.py:228(_releaseLock)\n",
       "        1    0.000    0.000    0.000    0.000 tritools.py:10(TriAnalyzer)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1569(FigureCanvasBase)\n",
       "      188    0.000    0.000    0.000    0.000 pyparsing.py:2678(<genexpr>)\n",
       "      142    0.000    0.000    0.000    0.000 {method 'expandtabs' of 'str' objects}\n",
       "       12    0.000    0.000    0.010    0.001 artist.py:1094(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 cycler.py:225(__iter__)\n",
       "        2    0.000    0.000    0.005    0.002 dsa.py:5(<module>)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:69(decorator)\n",
       "       60    0.000    0.000    0.000    0.000 function_base.py:13(_index_deprecate)\n",
       "    33/10    0.000    0.000    0.007    0.001 pyparsing.py:3809(leaveWhitespace)\n",
       "      143    0.000    0.000    0.000    0.000 {method '__contains__' of 'frozenset' objects}\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:71(Op)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:89(<dictcomp>)\n",
       "        2    0.000    0.000    0.006    0.003 transforms.py:1(<module>)\n",
       "       56    0.000    0.000    0.000    0.000 batchnorm.py:78(extra_repr)\n",
       "       30    0.000    0.000    0.002    0.000 activation.py:81(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 nanfunctions.py:22(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 function_base.py:1(<module>)\n",
       "       23    0.000    0.000    0.000    0.000 rcsetup.py:47(__init__)\n",
       "      188    0.000    0.000    0.000    0.000 pyparsing.py:2656(<genexpr>)\n",
       "     10/2    0.000    0.000    0.002    0.001 pyparsing.py:3397(parseImpl)\n",
       "        1    0.000    0.000    0.002    0.002 dates.py:134(<module>)\n",
       "       69    0.000    0.000    0.000    0.000 status_codes.py:117(<genexpr>)\n",
       "       28    0.000    0.000    0.000    0.000 init.py:113(zeros_)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _ctypes.dlopen}\n",
       "       45    0.000    0.000    0.000    0.000 pyparsing.py:1200(setName)\n",
       "       97    0.000    0.000    0.000    0.000 pyparsing.py:4934(<genexpr>)\n",
       "       66    0.000    0.000    0.001    0.000 argparse.py:1713(_add_action)\n",
       "       61    0.000    0.000    0.000    0.000 {built-in method builtins.vars}\n",
       "       38    0.000    0.000    0.000    0.000 colors.py:788(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:112(tqdm)\n",
       "        1    0.000    0.000    0.010    0.010 _big_num_ctypes.py:20(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Url)\n",
       "        1    0.000    0.000    0.002    0.002 utils.py:4(<module>)\n",
       "       18    0.000    0.000    0.002    0.000 pyparsing.py:4092(parseImpl)\n",
       "       23    0.000    0.000    0.000    0.000 pyparsing.py:2742(__str__)\n",
       "    36/11    0.000    0.000    0.008    0.001 pyparsing.py:3743(leaveWhitespace)\n",
       "       39    0.000    0.000    0.001    0.000 inspect.py:2817(replace)\n",
       "       48    0.000    0.000    0.000    0.000 traceback.py:273(__getitem__)\n",
       "      163    0.000    0.000    0.000    0.000 _collections_abc.py:392(__subclasshook__)\n",
       "        1    0.000    0.000    0.024    0.024 grammar.py:13(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyplot.py:2078(<listcomp>)\n",
       "       17    0.000    0.000    0.000    0.000 cycler.py:55(_process_keys)\n",
       "        1    0.000    0.000    0.007    0.007 cookies.py:127(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:86(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:61(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.unsetenv}\n",
       "       60    0.000    0.000    0.000    0.000 pyparsing.py:1351(preParse)\n",
       "        1    0.000    0.000    0.009    0.009 Image.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:8(Categorical)\n",
       "       78    0.000    0.000    0.000    0.000 _internal.py:726(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.putenv}\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:4(<module>)\n",
       "       97    0.000    0.000    0.000    0.000 pyparsing.py:4781(<genexpr>)\n",
       "        1    0.000    0.000    0.003    0.003 models.py:8(<module>)\n",
       "       86    0.000    0.000    0.000    0.000 textwrap.py:476(predicate)\n",
       "       45    0.000    0.000    0.000    0.000 pyparsing.py:1190(setName)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:409(_init)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:573(format)\n",
       "       24    0.000    0.000    0.001    0.000 __init__.py:1870(find_distributions)\n",
       "       45    0.000    0.000    0.000    0.000 docstring.py:44(update)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:73(__init__)\n",
       "        1    0.000    0.000    0.017    0.017 cookiejar.py:26(<module>)\n",
       "        3    0.000    0.000    0.003    0.001 distributed.py:1(<module>)\n",
       "       48    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
       "        1    0.000    0.000    0.000    0.000 types_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 versions_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 patches.py:3102(ArrowStyle)\n",
       "        1    0.000    0.000    0.003    0.003 modes.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 stringprep.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:7(OneHotCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:308(init_reductions)\n",
       "        1    0.000    0.000    0.002    0.002 npyio.py:1(<module>)\n",
       "       62    0.000    0.000    0.000    0.000 numerictypes.py:127(english_lower)\n",
       "       14    0.000    0.000    0.000    0.000 pathlib.py:631(_parse_args)\n",
       "       15    0.000    0.000    0.000    0.000 pyparsing.py:4565(_escapeRegexRangeChars)\n",
       "        4    0.000    0.000    0.005    0.001 container.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:7(Independent)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:272(<setcomp>)\n",
       "       86    0.000    0.000    0.000    0.000 rcsetup.py:201(validate_int)\n",
       "       15    0.000    0.000    0.000    0.000 rcsetup.py:906(validate_animation_writer_path)\n",
       "       28    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
       "       38    0.000    0.000    0.000    0.000 pyparsing.py:4230(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 dviread.py:173(Dvi)\n",
       "        1    0.000    0.000    0.003    0.003 adapters.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:1(<module>)\n",
       "       20    0.000    0.000    0.003    0.000 pyparsing.py:4012(parseImpl)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:202(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:857(<listcomp>)\n",
       "       41    0.000    0.000    0.000    0.000 {method 'groupdict' of '_sre.SRE_Match' objects}\n",
       "      102    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}\n",
       "        1    0.000    0.000    0.002    0.002 graph_pb2.py:4(<module>)\n",
       "       49    0.000    0.000    0.000    0.000 pyparsing.py:421(__getitem__)\n",
       "       36    0.000    0.000    0.000    0.000 __init__.py:685(__init__)\n",
       "       60    0.000    0.000    0.000    0.000 {method 'copy' of 'mappingproxy' objects}\n",
       "        1    0.000    0.000    0.003    0.003 summary.py:30(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 backend_bases.py:33(<module>)\n",
       "        2    0.000    0.000    0.007    0.003 rsa.py:5(<module>)\n",
       "        1    0.000    0.000    0.012    0.012 connectionpool.py:1(<module>)\n",
       "       29    0.000    0.000    0.000    0.000 typing.py:1039(_abc_negative_cache_version)\n",
       "        2    0.000    0.000    0.001    0.000 enum.py:366(_create_)\n",
       "       28    0.000    0.000    0.000    0.000 {method '_set_from_file' of 'torch._C.LongStorageBase' objects}\n",
       "        1    0.000    0.000    0.003    0.003 dviread.py:18(<module>)\n",
       "        6    0.000    0.000    0.001    0.000 patches.py:1811(_pprint_table)\n",
       "       95    0.000    0.000    0.000    0.000 cycler.py:138(keys)\n",
       "       62    0.000    0.000    0.000    0.000 _inspect.py:146(<lambda>)\n",
       "       47    0.000    0.000    0.000    0.000 pyparsing.py:2453(parseImpl)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _hashlib.openssl_md5}\n",
       "    13/12    0.000    0.000    0.025    0.002 <frozen importlib._bootstrap>:622(_load_backward_compatible)\n",
       "       94    0.000    0.000    0.000    0.000 pyparsing.py:4890(<genexpr>)\n",
       "        1    0.000    0.000    0.063    0.063 text.py:3(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 algorithms.py:5(<module>)\n",
       "        2    0.000    0.000    0.002    0.001 hashes.py:5(<module>)\n",
       "        1    0.000    0.000    0.008    0.008 general_name.py:5(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 __init__.py:296(get_device_properties)\n",
       "       21    0.000    0.000    0.000    0.000 pyparsing.py:2764(__str__)\n",
       "       44    0.000    0.000    0.000    0.000 pyparsing.py:3647(<genexpr>)\n",
       "       56    0.000    0.000    0.000    0.000 {method 'setter' of 'property' objects}\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:1(<module>)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6568(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:792(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1078(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:466(find)\n",
       "       14    0.000    0.000    0.002    0.000 posixpath.py:384(realpath)\n",
       "       28    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
       "       14    0.000    0.000    0.003    0.000 __init__.py:2232(normalize_path)\n",
       "        1    0.000    0.000    0.047    0.047 collections.py:10(<module>)\n",
       "       17    0.000    0.000    0.000    0.000 ocsp.py:25(_requires_successful_response)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:365(__getitem__)\n",
       "        1    0.000    0.000    0.003    0.003 fontconfig_pattern.py:65(__init__)\n",
       "       29    0.000    0.000    0.000    0.000 contextlib.py:157(helper)\n",
       "        2    0.000    0.000    0.009    0.005 __init__.py:45(<module>)\n",
       "       49    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISREG}\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:663(__iadd__)\n",
       "        1    0.000    0.000    0.001    0.001 pyparsing.py:4875(_makeTags)\n",
       "       14    0.000    0.000    0.001    0.000 cnf_regularization_rl.py:6(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _base.py:396(_AxesBase)\n",
       "        1    0.000    0.000    0.007    0.007 _base.py:1(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 core.py:55(is_style_file)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:225(_register_default_ciphers)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:26(_fr1)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:3606(__init__)\n",
       "       78    0.000    0.000    0.000    0.000 pyparsing.py:2052(leaveWhitespace)\n",
       "        6    0.000    0.000    0.025    0.004 __init__.py:35(load_module)\n",
       "        1    0.000    0.000    0.036    0.036 odefunc.py:1(<module>)\n",
       "        1    0.000    0.000    0.041    0.041 _axes.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 socks.py:23(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 shape_base.py:1(<module>)\n",
       "       30    0.000    0.000    0.000    0.000 numerictypes.py:432(_add_array_type)\n",
       "       25    0.000    0.000    0.000    0.000 pyparsing.py:4150(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 __init__.py:1357(_to_unmasked_float_array)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:1493(_check_conflict)\n",
       "       16    0.000    0.000    0.000    0.000 enum.py:65(__init__)\n",
       "        2    0.000    0.000    0.007    0.004 connection.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 PngImagePlugin.py:34(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 {method 'AddDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3439(<genexpr>)\n",
       "        1    0.000    0.000    0.005    0.005 plistlib.py:47(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(<listcomp>)\n",
       "        1    0.000    0.000    0.096    0.096 thnn.py:21(_initialize_backend)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:109(has_argument)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:19(ABCPolyBase)\n",
       "       20    0.000    0.000    0.000    0.000 pyparsing.py:1589(resetCache)\n",
       "        6    0.000    0.000    0.000    0.000 gettext.py:205(_expand_lang)\n",
       "       10    0.000    0.000    0.000    0.000 sre_compile.py:381(_bytes_to_codes)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method torch.cuda._get_device_properties}\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:52(__new__)\n",
       "       56    0.000    0.000    0.000    0.000 patches.py:1919(_register_style)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2474(CompositeAffine2D)\n",
       "        1    0.000    0.000    0.001    0.001 loss.py:1(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:74(__call__)\n",
       "       40    0.000    0.000    0.000    0.000 numerictypes.py:154(english_upper)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:766(_construct_lookups)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2707(parseImpl)\n",
       "       28    0.000    0.000    0.000    0.000 pyparsing.py:3997(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 patches.py:1822(<listcomp>)\n",
       "        1    0.000    0.000    0.002    0.002 colors.py:61(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 response.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:285(_add_types)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2729(parseImpl)\n",
       "    34/26    0.000    0.000    0.000    0.000 pyparsing.py:3500(__str__)\n",
       "     23/7    0.000    0.000    0.001    0.000 pyparsing.py:3828(streamline)\n",
       "       25    0.000    0.000    0.000    0.000 rcsetup.py:300(<listcomp>)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2050(_match_argument)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:4757(<lambda>)\n",
       "       49    0.000    0.000    0.000    0.000 six.py:184(find_module)\n",
       "        1    0.000    0.000    0.001    0.001 texmanager.py:48(TexManager)\n",
       "       89    0.000    0.000    0.000    0.000 docstring.py:98(do_copy)\n",
       "       88    0.000    0.000    0.000    0.000 docstring.py:115(copy_dedent)\n",
       "        1    0.000    0.000    0.004    0.004 algos.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:514(X509Name)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:118(deprecate)\n",
       "       36    0.000    0.000    0.000    0.000 getlimits.py:69(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:340(_add_integer_aliases)\n",
       "       39    0.000    0.000    0.000    0.000 __init__.py:1598(_preprocess_data)\n",
       "       44    0.000    0.000    0.000    0.000 typing.py:889(__extrahook__)\n",
       "       32    0.000    0.000    0.000    0.000 inspect.py:73(isclass)\n",
       "        4    0.000    0.000    0.371    0.093 __init__.py:2(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 blas.py:202(<module>)\n",
       "        1    0.000    0.000    0.015    0.015 lines.py:4(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 cm.py:99(<dictcomp>)\n",
       "        1    0.000    0.000    0.153    0.153 colorbar.py:20(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:30(<module>)\n",
       "        9    0.000    0.000    0.005    0.001 fontconfig_pattern.py:113(parse)\n",
       "       27    0.000    0.000    0.000    0.000 __init__.py:956(is_url)\n",
       "        3    0.000    0.000    0.028    0.009 odenvp_conditional_rl.py:221(<listcomp>)\n",
       "        1    0.000    0.000    0.003    0.003 sessions.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:126(EventHandle)\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:88(<module>)\n",
       "        1    0.000    0.000    0.006    0.006 index_tricks.py:1(<module>)\n",
       "      138    0.000    0.000    0.000    0.000 pyparsing.py:1376(postParse)\n",
       "        6    0.000    0.000    0.003    0.000 warnings.py:119(filterwarnings)\n",
       "       13    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:433(spec_from_loader)\n",
       "        1    0.000    0.000    0.006    0.006 image.py:4(<module>)\n",
       "        1    0.000    0.000    0.012    0.012 artist.py:1(<module>)\n",
       "       17    0.000    0.000    0.001    0.000 cycler.py:468(cycler)\n",
       "        2    0.000    0.000    0.001    0.000 request.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 activation.py:1(<module>)\n",
       "       98    0.000    0.000    0.000    0.000 pyparsing.py:2181(streamline)\n",
       "       20    0.000    0.000    0.002    0.000 pyparsing.py:4156(parseImpl)\n",
       "       11    0.000    0.000    0.000    0.000 pyparsing.py:4718(_escapeRegexRangeChars)\n",
       "       61    0.000    0.000    0.000    0.000 __init__.py:1916(make_alias)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1226(__init__)\n",
       "       40    0.000    0.000    0.000    0.000 __init__.py:190(_checkLevel)\n",
       "        2    0.000    0.000    0.003    0.002 dh.py:5(<module>)\n",
       "        1    0.000    0.000    0.337    0.337 writer.py:15(<module>)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1813(get_metadata_lines)\n",
       "        1    0.000    0.000    0.002    0.002 backend_inline.py:1(<module>)\n",
       "       89    0.000    0.000    0.000    0.000 docstring.py:96(copy)\n",
       "        1    0.000    0.000    0.001    0.001 pooling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:418(_construct_char_code_lookup)\n",
       "       11    0.000    0.000    0.007    0.001 pyparsing.py:1630(parseString)\n",
       "       41    0.000    0.000    0.000    0.000 enum.py:874(_power_of_two)\n",
       "       10    0.000    0.000    0.000    0.000 {method 'tolist' of 'memoryview' objects}\n",
       "        9    0.000    0.000    0.000    0.000 six.py:91(__get__)\n",
       "        1    0.000    0.000    0.001    0.001 ticker.py:165(<module>)\n",
       "       38    0.000    0.000    0.000    0.000 cycler.py:371(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 interfaces.py:5(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2905(_update_from)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:71(<lambda>)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:15(ismethod)\n",
       "        3    0.000    0.000    0.000    0.000 _utils.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 pygram.py:22(__init__)\n",
       "       95    0.000    0.000    0.000    0.000 pyparsing.py:203(<genexpr>)\n",
       "        1    0.000    0.000    0.005    0.005 dopri5.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.X509_new}\n",
       "        1    0.000    0.000    0.014    0.014 universaldetector.py:36(<module>)\n",
       "       38    0.000    0.000    0.000    0.000 constraint_registry.py:86(register)\n",
       "        1    0.000    0.000    0.001    0.001 distributed_c10d.py:1(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.empty}\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:332(__init__)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:1970(__or__)\n",
       "       27    0.000    0.000    0.000    0.000 pyparsing.py:4383(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 TiffTags.py:20(<module>)\n",
       "        3    0.000    0.000    0.003    0.001 __init__.py:10(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 well_known_types.py:39(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 normalization.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 legend.py:307(Legend)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:1(<module>)\n",
       "       33    0.000    0.000    0.001    0.000 container.py:159(__iadd__)\n",
       "        1    0.000    0.000    0.002    0.002 case.py:1(<module>)\n",
       "       23    0.000    0.000    0.000    0.000 numerictypes.py:216(_evalname)\n",
       "        7    0.000    0.000    0.000    0.000 _common.py:9(__init__)\n",
       "        2    0.000    0.000    0.916    0.458 cifar.py:143(download)\n",
       "        9    0.000    0.000    0.000    0.000 pathlib.py:385(wrapped)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
       "        1    0.000    0.000    0.001    0.001 text_encoding.py:31(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3781(__str__)\n",
       "        3    0.000    0.000    0.033    0.011 _util.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:1(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 patches.py:1815(<listcomp>)\n",
       "        5    0.000    0.000    0.027    0.005 binding.py:122(_ensure_ffi_initialized)\n",
       "        1    0.000    0.000    0.001    0.001 odefunc_rl.py:1(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 legend.py:22(<module>)\n",
       "        1    0.000    0.000    0.077    0.077 contour.py:3(<module>)\n",
       "       17    0.000    0.000    0.000    0.000 cycler.py:529(_cycler)\n",
       "        1    0.000    0.000    0.003    0.003 sbcsgroupprober.py:29(<module>)\n",
       "       30    0.000    0.000    0.005    0.000 rcsetup.py:446(validate_font_properties)\n",
       "       34    0.000    0.000    0.000    0.000 argparse.py:1278(register)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2190(_get_nargs_pattern)\n",
       "       30    0.000    0.000    0.000    0.000 tokenize.py:379(read_or_stop)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:411(ImageFileDirectory_v2)\n",
       "        1    0.000    0.000    0.008    0.008 JpegImagePlugin.py:35(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 type_checkers.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:65(<module>)\n",
       "        2    0.000    0.000    0.340    0.170 __init__.py:33(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 token.py:3(<module>)\n",
       "        1    0.000    0.000    0.073    0.073 odenvp_conditional_rl.py:65(_build_net)\n",
       "       16    0.000    0.000    0.002    0.000 descriptor.py:869(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:55(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 _tqdm.py:9(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:78(contains)\n",
       "       27    0.000    0.000    0.000    0.000 core.py:920(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1113(ParserElement)\n",
       "       95    0.000    0.000    0.000    0.000 pyparsing.py:213(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 util.py:136(register_after_fork)\n",
       "       60    0.000    0.000    0.000    0.000 six.py:835(add_metaclass)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
       "        1    0.000    0.000    0.001    0.001 decoder.py:79(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:48(<listcomp>)\n",
       "       12    0.000    0.000    0.008    0.001 pyparsing.py:4251(__init__)\n",
       "        1    0.000    0.000    0.006    0.006 axis.py:3(<module>)\n",
       "        1    0.000    0.000    0.007    0.007 offsetbox.py:15(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 pyplot.py:2363(<lambda>)\n",
       "        3    0.000    0.000    0.001    0.000 utils.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ssl_.py:1(<module>)\n",
       "       28    0.000    0.000    0.000    0.000 pooling.py:24(extra_repr)\n",
       "        2    0.000    0.000    0.001    0.000 linear.py:47(__init__)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:118(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:156(<module>)\n",
       "        1    0.000    0.000    0.006    0.006 _internal.py:6(<module>)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:28(isfunction)\n",
       "       74    0.000    0.000    0.000    0.000 pyparsing.py:2074(leaveWhitespace)\n",
       "       61    0.000    0.000    0.000    0.000 pyparsing.py:2159(streamline)\n",
       "        1    0.000    0.000    0.000    0.000 _cm.py:7(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 constraint_registry.py:66(<module>)\n",
       "       56    0.000    0.000    0.000    0.000 activation.py:84(extra_repr)\n",
       "       32    0.000    0.000    0.001    0.000 rcsetup.py:822(<genexpr>)\n",
       "        6    0.000    0.000    0.000    0.000 pathlib.py:1343(is_dir)\n",
       "       14    0.000    0.000    0.000    0.000 functools.py:479(decorating_function)\n",
       "       11    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:980(_recalculate)\n",
       "       67    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method posix.mkdir}\n",
       "        1    0.000    0.000    0.001    0.001 pytorch_graph.py:1(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 __init__.py:1793(has_metadata)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2263(_is_unpacked_egg)\n",
       "        1    0.000    0.000    0.001    0.001 matfuncs.py:5(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 basic.py:7(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 patches.py:1927(BoxStyle)\n",
       "        1    0.000    0.000    0.004    0.004 pyplot.py:177(switch_backend)\n",
       "        2    0.000    0.000    0.003    0.002 rnn.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 profiler.py:1(<module>)\n",
       "        1    0.000    0.000    0.093    0.093 auto.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:17(<module>)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:43(iscode)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:369(_set_up_aliases)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:673(__iadd__)\n",
       "        1    0.000    0.000    0.003    0.003 onnx_graph.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 modules.py:96(__init__)\n",
       "        1    0.000    0.000    0.004    0.004 x509.py:5(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 exceptions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:2(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 util.py:301(_findLib_prefix)\n",
       "       12    0.000    0.000    0.000    0.000 pathlib.py:998(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:146(rng)\n",
       "        3    0.000    0.000    0.004    0.001 misc.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 fixer_util.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:84(<listcomp>)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:2863(__init__)\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3581(<genexpr>)\n",
       "       14    0.000    0.000    0.000    0.000 pyparsing.py:3576(__str__)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2256(_is_egg_path)\n",
       "        1    0.000    0.000    0.003    0.003 font_manager.py:883(json_load)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 poolmanager.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 chardistribution.py:28(<module>)\n",
       "       14    0.000    0.000    0.001    0.000 pooling.py:940(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:242(getdoc)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:332(<dictcomp>)\n",
       "       19    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.001    0.001 linalg.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defmatrix.py:70(matrix)\n",
       "        1    0.000    0.000    0.001    0.001 fromnumeric.py:3(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 getlimits.py:376(__new__)\n",
       "     20/6    0.000    0.000    0.001    0.000 pyparsing.py:3803(parseImpl)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:4910(<lambda>)\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:516(haskeys)\n",
       "       12    0.000    0.000    0.000    0.000 rcsetup.py:68(_listify_validator)\n",
       "       12    0.000    0.000    0.000    0.000 pathlib.py:651(_from_parts)\n",
       "       29    0.000    0.000    0.002    0.000 contextlib.py:79(__enter__)\n",
       "       16    0.000    0.000    0.001    0.000 pyparsing.py:1204(setResultsName)\n",
       "        1    0.000    0.000    0.000    0.000 config.py:39(InlineBackend)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:10(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 cookiejar.py:1224(CookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:148(activate_osrandom_engine)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:147(deprecated)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:113(__init__)\n",
       "        1    0.000    0.000    0.075    0.075 train_cnf_disentangle_rl.py:500(create_model)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:358(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1120(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 ImageOps.py:20(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:1(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _struct.calcsize}\n",
       "        1    0.000    0.000    0.007    0.007 subprocess.py:588(__init__)\n",
       "       59    0.000    0.000    0.000    0.000 enum.py:594(name)\n",
       "       11    0.000    0.000    0.000    0.000 _collections_abc.py:664(__contains__)\n",
       "        3    0.000    0.000    0.000    0.000 sparse.py:1(<module>)\n",
       "       16    0.000    0.000    0.001    0.000 {built-in method _functools.reduce}\n",
       "     12/2    0.000    0.000    0.001    0.000 pyparsing.py:1926(makeOptionalList)\n",
       "       24    0.000    0.000    0.000    0.000 pyparsing.py:411(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:19(Patch)\n",
       "        1    0.000    0.000    0.002    0.002 pyplot.py:1782(get_plot_commands)\n",
       "        1    0.000    0.000    0.032    0.032 binding.py:5(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 name.py:5(<module>)\n",
       "        1    0.000    0.000    0.015    0.015 _int.py:32(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:11(FisherSnedecor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:94(_check_capability)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:331(device_count)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:48(_numeric_methods)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:590(_get_xdg_cache_dir)\n",
       "        6    0.000    0.000    0.000    0.000 version.py:307(parse)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:1950(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:771(__init__)\n",
       "       35    0.000    0.000    0.000    0.000 enum.py:822(_high_bit)\n",
       "       13    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:976(_get_parent_path)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:49(<listcomp>)\n",
       "     15/4    0.000    0.000    0.000    0.000 pyparsing.py:3762(streamline)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:265(GaussianDiag)\n",
       "        1    0.000    0.000    0.046    0.046 odeint.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 quiver.py:15(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 transforms.py:30(<module>)\n",
       "        1    0.000    0.000    0.114    0.114 tarfile.py:2276(next)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:88(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:3642(__str__)\n",
       "        7    0.000    0.000    0.000    0.000 tokenize.py:344(_get_normal_name)\n",
       "        5    0.000    0.000    0.000    0.000 re.py:249(escape)\n",
       "       16    0.000    0.000    0.000    0.000 enum.py:135(<dictcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:165(__setitem__)\n",
       "        4    0.000    0.000    0.000    0.000 weakref.py:102(__init__)\n",
       "        1    0.000    0.000    0.029    0.029 refactor.py:9(<module>)\n",
       "       16    0.000    0.000    0.054    0.003 __init__.py:1914(_by_version_descending)\n",
       "        1    0.000    0.000    0.001    0.001 backend_agg.py:21(<module>)\n",
       "        1    0.000    0.000    0.027    0.027 compat.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:9(parse_kwargs)\n",
       "        1    0.000    0.000    0.001    0.001 beta.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:118(<dictcomp>)\n",
       "       28    0.000    0.000    0.000    0.000 pooling.py:944(extra_repr)\n",
       "        7    0.000    0.000    0.000    0.000 _jit_internal.py:113(boolean_dispatch)\n",
       "        2    0.000    0.000    0.001    0.001 tensor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:59(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 polynomial.py:56(<module>)\n",
       "       10    0.000    0.000    0.007    0.001 pyparsing.py:4404(__init__)\n",
       "       16    0.000    0.000    0.000    0.000 pathlib.py:282(splitroot)\n",
       "       19    0.000    0.000    0.000    0.000 pathlib.py:691(__str__)\n",
       "        2    0.000    0.000    0.001    0.000 grammar.py:105(load)\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:116(RegisterFileDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 dopri5.py:58(Dopri5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:1(<module>)\n",
       "       33    0.000    0.000    0.000    0.000 cm.py:40(_reverser)\n",
       "        2    0.000    0.000    0.001    0.001 x25519.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 core.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.008    0.008 mbcsgroupprober.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:1(<module>)\n",
       "       23    0.000    0.000    0.000    0.000 utils.py:112(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:1024(frombuf)\n",
       "     12/2    0.000    0.000    0.000    0.000 pyparsing.py:1948(makeOptionalList)\n",
       "       13    0.000    0.000    0.000    0.000 pyparsing.py:3847(__str__)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4934(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:162(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 shutil.py:1093(which)\n",
       "        7    0.000    0.000    0.000    0.000 TiffImagePlugin.py:635(_register_basic)\n",
       "        1    0.000    0.000    0.007    0.007 text_format.py:41(<module>)\n",
       "       34    0.000    0.000    0.000    0.000 descriptor_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:38(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 __init__.py:23(find_module)\n",
       "        1    0.000    0.000    0.000    0.000 decomp.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_schur.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend_agg.py:62(RendererAgg)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:687(Axis)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:594(_ReducedHCT_Element)\n",
       "        1    0.000    0.000    0.000    0.000 trirefine.py:3(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 csv.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 path.py:21(Path)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5891(Hiragana)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 util.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:142(AuthorityKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:51(<module>)\n",
       "       18    0.000    0.000    0.000    0.000 core.py:996(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2931(__array_finalize__)\n",
       "        1    0.000    0.000    0.005    0.005 __init__.py:206(_sanity_check)\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:63(NDArrayOperatorsMixin)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:440(_set_array_types)\n",
       "       58    0.000    0.000    0.000    0.000 pyparsing.py:468(__bool__)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:839(_decompose)\n",
       "       15    0.000    0.000    0.000    0.000 _collections_abc.py:72(_check_methods)\n",
       "       49    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
       "        1    0.000    0.000    0.004    0.004 fractions.py:4(<module>)\n",
       "       43    0.000    0.000    0.000    0.000 caffe2_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.010    0.010 descriptor.py:33(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 api_implementation.py:32(<module>)\n",
       "       32    0.000    0.000    0.000    0.000 pyparsing.py:209(__init__)\n",
       "        1    0.000    0.000    0.328    0.328 event_file_writer.py:15(<module>)\n",
       "        1    0.000    0.000    0.028    0.028 modules.py:1(<module>)\n",
       "        2    0.000    0.000    0.006    0.003 resnet.py:1(<module>)\n",
       "        1    0.000    0.000    0.015    0.015 tsit5.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _subplots.py:203(subplot_class_factory)\n",
       "        1    0.000    0.000    0.059    0.059 _subplots.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 afm.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_init}\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:11(ExtensionOID)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:126(doc_note)\n",
       "        1    0.000    0.000    0.033    0.033 type_check.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:4(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:73(CFUNCTYPE)\n",
       "       16    0.000    0.000    0.000    0.000 enum.py:312(__getattr__)\n",
       "       86    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "       72    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
       "        1    0.000    0.000    0.001    0.001 GifImagePlugin.py:27(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 pygram.py:4(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 pyparsing.py:3164(__init__)\n",
       "       11    0.000    0.000    0.000    0.000 pyparsing.py:3851(__init__)\n",
       "        1    0.000    0.000    0.028    0.028 specifiers.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _solvers.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 table.py:21(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text.py:109(Text)\n",
       "       12    0.000    0.000    0.000    0.000 Image.py:2810(register_extension)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:89(_OCSPResponse)\n",
       "       36    0.000    0.000    0.000    0.000 backend.py:218(register_cipher_adapter)\n",
       "       21    0.000    0.000    0.000    0.000 utils.py:126(__getattr__)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1414(_get_builtin_table)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:271(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:83(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:59(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 twodim_base.py:140(eye)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2491(seterr)\n",
       "       10    0.000    0.000    0.000    0.000 rcsetup.py:329(validate_color_or_inherit)\n",
       "        1    0.000    0.000    0.041    0.041 fontconfig_pattern.py:7(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 BmpImagePlugin.py:27(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 descriptor.py:919(_ParseOptions)\n",
       "        1    0.000    0.000    0.011    0.011 version.py:4(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 record_writer.py:4(<module>)\n",
       "        1    0.000    0.000    0.035    0.035 core.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cycler.py:41(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mbcssm.py:28(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 sjisprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 constraints.py:19(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 linear.py:58(reset_parameters)\n",
       "        1    0.000    0.000    0.097    0.097 module.py:1(<module>)\n",
       "        1    0.000    0.000    0.013    0.013 __init__.py:147(_lazy_init)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:63(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:251(_get_machar)\n",
       "       14    0.000    0.000    0.000    0.000 rcsetup.py:178(validate_axisbelow)\n",
       "       15    0.000    0.000    0.000    0.000 rcsetup.py:291(<listcomp>)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:468(validate_whiskers)\n",
       "        1    0.000    0.000    0.001    0.001 ImageFilter.py:18(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 random.py:223(_randbelow)\n",
       "       42    0.000    0.000    0.000    0.000 argparse.py:2087(_parse_optional)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:294(IFDRational)\n",
       "        1    0.000    0.000    0.008    0.008 utils.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scope.py:3(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'FindEnumTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       14    0.000    0.000    0.001    0.000 pyparsing.py:2026(__call__)\n",
       "    13/12    0.000    0.000    0.000    0.000 pyparsing.py:3434(__str__)\n",
       "     16/2    0.000    0.000    0.001    0.001 pyparsing.py:3737(parseImpl)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:3120(<genexpr>)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1805(_warn_on_replacement)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend_inline.py:151(_enable_matplotlib_integration)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:582(get_scale_docs)\n",
       "        1    0.000    0.000    0.001    0.001 patches.py:2645(ConnectionStyle)\n",
       "       15    0.000    0.000    0.000    0.000 pyplot.py:2358(_autogen_docstring)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:114(_make_name)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:168(Asn1Value)\n",
       "        1    0.000    0.000    0.015    0.015 _elliptic_curve.py:47(<module>)\n",
       "        1    0.000    0.000    0.114    0.114 tarfile.py:1411(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 fftpack.py:32(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:341(TestCase)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_LoggingWatcher)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:36(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 pyparsing.py:4004(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 fontconfig_pattern.py:152(_property)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:265(_parse_commandline)\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:1059(system)\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:2853(_bind)\n",
       "        4    0.000    0.000    0.000    0.000 traitlets.py:1627(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:157(__next__)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:758(__del__)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:963(expand_template)\n",
       "       12    0.000    0.000    0.000    0.000 six.py:126(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 six.py:195(load_module)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:30(<module>)\n",
       "        1    0.000    0.000 151147.755 151147.755 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:48(<module>)\n",
       "       20    0.000    0.000    0.000    0.000 tokenize.py:48(group)\n",
       "        1    0.000    0.000    0.000    0.000 x2num.py:2(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 train_misc.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_polar.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:62(__init__)\n",
       "        1    0.000    0.000    0.011    0.011 cnf_gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:157(iter_user_libraries)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1758(DraggableAnnotation)\n",
       "        1    0.000    0.000    0.000    0.000 font_manager.py:516(FontProperties)\n",
       "        1    0.000    0.000    0.000    0.000 lines.py:208(Line2D)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:52(NameOID)\n",
       "        1    0.000    0.000    0.002    0.002 _iri.py:9(<module>)\n",
       "        1    0.000    0.000    0.233    0.233 model_zoo.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:1(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 linear.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 random.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8061(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:177(_ndptr)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:59(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 defmatrix.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 loader.py:1(<module>)\n",
       "        1    0.000    0.000    0.010    0.010 util.py:310(find_library)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:312(__call__)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:108(validate_path_exists)\n",
       "       20    0.000    0.000    0.000    0.000 argparse.py:568(<listcomp>)\n",
       "       11    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:993(__iter__)\n",
       "        5    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:1069(wrapper)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:4681(originalTextFor)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4781(<lambda>)\n",
       "        6    0.000    0.000    0.001    0.000 __init__.py:2707(from_filename)\n",
       "        2    0.000    0.000    0.000    0.000 __config__.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:781(AxesImage)\n",
       "        1    0.000    0.000    0.000    0.000 afm.py:390(AFM)\n",
       "        1    0.000    0.000    0.000    0.000 artist.py:69(Artist)\n",
       "        1    0.000    0.000    0.002    0.002 api.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:14(TMonitor)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:81(Backend)\n",
       "       35    0.000    0.000    0.000    0.000 backend.py:2100(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:684(Context)\n",
       "       11    0.000    0.000    0.000    0.000 name.py:28(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 idnadata.py:3(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:154(cached_property)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:11(HalfCauchy)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 runner.py:1(<module>)\n",
       "       44    0.000    0.000    0.000    0.000 pyparsing.py:3609(<genexpr>)\n",
       "       10    0.000    0.000    0.000    0.000 rcsetup.py:284(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 fontconfig_pattern.py:132(_family)\n",
       "        9    0.000    0.000    0.000    0.000 fontconfig_pattern.py:144(_families)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:430(__setitem__)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:864(__call__)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1604(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 locale.py:379(normalize)\n",
       "       23    0.000    0.000    0.000    0.000 inspect.py:81(ismethod)\n",
       "       14    0.000    0.000    0.000    0.000 functools.py:448(lru_cache)\n",
       "        1    0.000    0.000    0.000    0.000 fractions.py:60(Fraction)\n",
       "       13    0.000    0.000    0.000    0.000 descriptor.py:635(__new__)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2431(parseImpl)\n",
       "        1    0.000    0.000    0.366    0.366 torchvis.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_lu.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:55(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:65(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:25(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 _layoutbox.py:16(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 patches.py:1820(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1780(QuadMesh)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:244(BboxBase)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:90(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:1529(Connection)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PoolKey)\n",
       "        1    0.000    0.000    0.001    0.001 retry.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 init.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:617(ConvTranspose2d)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:15(Tensor)\n",
       "       19    0.000    0.000    0.000    0.000 _methods.py:45(_all)\n",
       "       10    0.000    0.000    0.000    0.000 rcsetup.py:221(validate_fonttype)\n",
       "       18    0.000    0.000    0.000    0.000 deprecation.py:189(finalize)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:2468(__init__)\n",
       "       27    0.000    0.000    0.000    0.000 inspect.py:479(getmro)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:742(setup_class)\n",
       "       20    0.000    0.000    0.000    0.000 enum.py:581(__hash__)\n",
       "       28    0.000    0.000    0.000    0.000 _collections_abc.py:302(__subclasshook__)\n",
       "       26    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}\n",
       "        8    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.OrderedDict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:115(copy)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2751(charsAsStr)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:8(MultiscaleParallelCNF)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:686(TextArea)\n",
       "        1    0.000    0.000    0.000    0.000 contour.py:52(ContourLabeler)\n",
       "        1    0.000    0.000    0.001    0.001 markers.py:146(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2761(register_open)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:108(_ECDSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:62(openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4773(UniversalString)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:435(Attribute)\n",
       "        6    0.000    0.000    0.000    0.000 _elliptic_curve.py:97(__init__)\n",
       "        1    0.000    0.000    0.015    0.015 __init__.py:19(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:21(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:328(ExprBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:2363(_check)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8066(getdoc)\n",
       "        1    0.000    0.000    0.000    0.000 scimath.py:17(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 function_base.py:1912(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1202(DatetimeFormat)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:1669(chararray)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:18(_fr0)\n",
       "        5    0.000    0.000    0.000    0.000 getlimits.py:507(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 pyparsing.py:2773(charsAsStr)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3299(WordEnd)\n",
       "       15    0.000    0.000    0.000    0.000 pyparsing.py:4170(__str__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:602(_get_config_or_cache_dir)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:783(RcParams)\n",
       "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7f5429a82a60}\n",
       "       25    0.000    0.000    0.000    0.000 enum.py:332(<genexpr>)\n",
       "       13    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:966(_find_parent_path_names)\n",
       "       28    0.000    0.000    0.000    0.000 {built-in method sys.intern}\n",
       "       26    0.000    0.000    0.000    0.000 {method 'groups' of '_sre.SRE_Match' objects}\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:621(decorator)\n",
       "        2    0.000    0.000    0.001    0.001 driver.py:117(load_grammar)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:324(ParseResults)\n",
       "       46    0.000    0.000    0.000    0.000 pyparsing.py:1366(postParse)\n",
       "       11    0.000    0.000    0.000    0.000 six.py:80(_import_module)\n",
       "       16    0.000    0.000    0.005    0.000 __init__.py:2006(safe_listdir)\n",
       "        1    0.000    0.000    0.000    0.000 dual.py:12(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 spectral_norm.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1767(_Edge_integer)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:514(Image)\n",
       "        1    0.000    0.000    0.001    0.001 _main.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scrypt.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:52(Prehashed)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:41(GeneralName)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:104(_has_ipv6)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:11(_check_balance)\n",
       "        1    0.000    0.000    0.001    0.001 data_parallel.py:1(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:25(register_func)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
       "       19    0.000    0.000    0.000    0.000 mixins.py:20(_binary_method)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:890(validate_hist_bins)\n",
       "       49    0.000    0.000    0.000    0.000 reduction.py:43(register)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:139(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1348(_handle_exitstatus)\n",
       "        9    0.000    0.000    0.000    0.000 re.py:324(_subx)\n",
       "        1    0.000    0.000    0.003    0.003 text_format.py:1006(Tokenizer)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:9(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 symbol_database.py:93(RegisterEnumDescriptor)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2045(suppress)\n",
       "        2    0.000    0.000    0.001    0.001 pyparsing.py:3859(parseImpl)\n",
       "        6    0.000    0.000    0.000    0.000 six.py:114(_resolve)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3027(_always_object)\n",
       "       12    0.000    0.000    0.000    0.000 dual.py:52(register_func)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_svd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate_sep.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rk_common.py:8(_RungeKuttaState)\n",
       "        1    0.000    0.000    0.003    0.003 gridspec.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text.py:1980(Annotation)\n",
       "        1    0.000    0.000    0.003    0.003 artist.py:1217(get_setters)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.OpenSSL_add_all_algorithms}\n",
       "        1    0.000    0.000    0.003    0.003 constant_time.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:7(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 idna.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 filepost.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 lowrank_multivariate_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:8(NegativeBinomial)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adaptive.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:57(_load_cudart)\n",
       "        1    0.000    0.000    0.002    0.002 random.py:22(manual_seed)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:238(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2775(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 _numpy_fft.py:54(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 twodim_base.py:3(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2592(geterr)\n",
       "        1    0.000    0.000    0.000    0.000 _methods.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 train_cnf_disentangle_rl.py:346(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:1863(__radd__)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3994(__str__)\n",
       "        6    0.000    0.000    0.000    0.000 deprecation.py:54(warn_deprecated)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}\n",
       "        8    0.000    0.000    0.000    0.000 random.py:255(choice)\n",
       "       46    0.000    0.000    0.000    0.000 inspect.py:358(<lambda>)\n",
       "        6    0.000    0.000    0.000    0.000 traitlets.py:419(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:767(_create_pseudo_member_)\n",
       "        2    0.000    0.000    0.003    0.002 __init__.py:302(loads)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:35(_formatwarnmsg_impl)\n",
       "        2    0.000    0.000    0.001    0.000 _distributor_init.py:10(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
       "       43    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:11(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:3935(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 specifiers.py:266(_require_version_compare)\n",
       "        1    0.000    0.000    0.025    0.025 specifiers.py:275(Specifier)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:135(_declare_state)\n",
       "        1    0.000    0.000    0.001    0.001 adams.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:3(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 category.py:12(<module>)\n",
       "        1    0.000    0.000    0.010    0.010 _constrained_layout.py:16(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:25(Collection)\n",
       "       15    0.000    0.000    0.000    0.000 docstring.py:84(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:752(Bbox)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:302(OCSPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:81(SignatureAlgorithmOID)\n",
       "        1    0.000    0.000    0.001    0.001 certificate_transparency.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 escsm.py:28(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 constraint_registry.py:105(<lambda>)\n",
       "       11    0.000    0.000    0.000    0.000 init.py:403(_make_deprecate)\n",
       "        1    0.000    0.000    0.096    0.096 thnn.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:174(nti)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:6(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4603(delimitedList)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:175(compare_versions)\n",
       "        9    0.000    0.000    0.000    0.000 pathlib.py:674(_format_parsed_parts)\n",
       "        3    0.000    0.000    0.000    0.000 pathlib.py:1057(home)\n",
       "        3    0.000    0.000    0.000    0.000 pathlib.py:1241(mkdir)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:1286(debug)\n",
       "        2    0.000    0.000    0.000    0.000 getipython.py:17(get_ipython)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1414(wait)\n",
       "        6    0.000    0.000    0.000    0.000 weakref.py:354(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:16(<module>)\n",
       "        1    0.000    0.000    0.028    0.028 visdom_writer.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:420(__setitem__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1103(ParserElement)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:3098(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:4017(__str__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4450(delimitedList)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:150(create_regularization_fns)\n",
       "        3    0.000    0.000    0.001    0.000 _version.py:7(<module>)\n",
       "        4    0.000    0.000    0.001    0.000 container_gate.py:8(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint_sep.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 table.py:204(Table)\n",
       "       24    0.000    0.000    0.000    0.000 dviread.py:156(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:117(activate_builtin_random)\n",
       "        2    0.000    0.000    0.000    0.000 backend.py:128(_get_osurandom_engine)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1078(X509)\n",
       "        1    0.000    0.000    0.001    0.001 escprober.py:28(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:23(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:21(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:20(warn_imbalance)\n",
       "       27    0.000    0.000    0.000    0.000 auto.py:339(make_default_double_backwards_fn)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:279(get_device_capability)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:2551(_arraymethod)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:4(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 main.py:1(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 numerictypes.py:181(english_capitalize)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:484(cast)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:1214(setResultsName)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:1899(__mul__)\n",
       "        7    0.000    0.000    0.000    0.000 pyparsing.py:4088(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 pyparsing.py:4978(tokenMap)\n",
       "        8    0.000    0.000    0.000    0.000 fontconfig_pattern.py:138(_name)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:734(gen_candidates)\n",
       "        2    0.000    0.000    0.001    0.000 rcsetup.py:78(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 events.py:42(register)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2312(_check_value)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:752(_addHandlerRef)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:1109(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:71(search_function)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:2(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._multiprocessing_init}\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:18(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 noniterators.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 containers.py:40(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 descriptor_pool.py:56(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:1841(__radd__)\n",
       "        3    0.000    0.000    0.001    0.000 pyparsing.py:1877(__mul__)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:4763(srange)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:389(<genexpr>)\n",
       "       10    0.000    0.000    0.000    0.000 event_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.072    0.072 __init__.py:554(__init__)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1790(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_qz.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 rk_common.py:2(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 legend_handler.py:57(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 legend_handler.py:134(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 path.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:307(ColorbarBase)\n",
       "        1    0.000    0.000    0.000    0.000 pyplot.py:82(install_repl_displayhook)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:26(_Certificate)\n",
       "        1    0.000    0.000    0.006    0.006 ciphers.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 cmac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 parser.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:137(_validate_dependencies_met)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1082(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 half_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 bernoulli.py:1(<module>)\n",
       "        1    0.000    0.000    0.008    0.008 adam.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 rendezvous.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gradcheck.py:1(<module>)\n",
       "        1    0.000    0.000    0.143    0.143 module.py:723(load_state_dict)\n",
       "        1    0.000    0.000    0.000    0.000 module.py:23(Module)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:727(TarInfo)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:45(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:934(poly1d)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 py3k.py:4(<module>)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:4916(srange)\n",
       "        9    0.000    0.000    0.000    0.000 rcsetup.py:249(validate_backend)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:390(_logged_cached)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:1(<module>)\n",
       "        2    0.000    0.000    0.010    0.005 traceback.py:193(format_stack)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:746(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:876(parse_template)\n",
       "       14    0.000    0.000    0.000    0.000 weakref.py:428(get)\n",
       "        9    0.000    0.000    0.000    0.000 os.py:746(decode)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(normalize_encoding)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method posix.access}\n",
       "        1    0.000    0.000    0.000    0.000 ImageColor.py:20(<module>)\n",
       "       28    0.000    0.000    0.000    0.000 TiffImagePlugin.py:368(_delegate)\n",
       "        1    0.000    0.000    0.000    0.000 ImageChops.py:18(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:40(<module>)\n",
       "        1    0.000    0.000    0.025    0.025 driver.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 proto_graph.py:1(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 enum_type_wrapper.py:46(__init__)\n",
       "       11    0.000    0.000    0.000    0.000 tensor_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3061(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 pyparsing.py:4825(tokenMap)\n",
       "        7    0.000    0.000    0.000    0.000 six.py:159(_resolve)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:9(<module>)\n",
       "        2    0.000    0.000    0.018    0.009 train_misc.py:85(count_parameters)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_ldl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_qr.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 special_matrices.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:1(<module>)\n",
       "        1    0.000    0.000    0.272    0.272 cnf.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:4(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 rrule.py:70(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3270(export)\n",
       "        1    0.000    0.000    0.001    0.001 texmanager.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 bezier.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 font_manager.py:939(FontManager)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:21(FFI)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:1(<module>)\n",
       "        1    0.000    0.000    0.014    0.014 lsun.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:97(MockResponse)\n",
       "        1    0.000    0.000    0.001    0.001 hmac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:491(PrivateKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:292(CertificateSigningRequest)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:116(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 utf8prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 gumbel.py:1(<module>)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1450(_register_builtin)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _reduction.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _csv.register_dialect}\n",
       "        2    0.000    0.000    0.010    0.005 __init__.py:120(_lazy_call)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:1385(TarFile)\n",
       "        4    0.000    0.000    0.000    0.000 _utils_internal.py:16(get_file_path)\n",
       "        1    0.000    0.000    0.000    0.000 _six.py:21(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6266(__new__)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:493(StringConverter)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:9(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:40(_inplace_binary_method)\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 ufunclike.py:14(_deprecate_out_named_y)\n",
       "        1    0.000    0.000    0.000    0.000 ufunclike.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 histograms.py:3(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 util.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 einsumfunc.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 train_cnf_disentangle_rl.py:155(ColorMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:4(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 context.py:69(RLock)\n",
       "       15    0.000    0.000    0.000    0.000 pathlib.py:1008(_init)\n",
       "        6    0.000    0.000    0.000    0.000 textwrap.py:467(indent)\n",
       "        8    0.000    0.000    0.000    0.000 shutil.py:1106(_access_check)\n",
       "        2    0.000    0.000    0.001    0.000 traceback.py:27(format_list)\n",
       "        1    0.000    0.000    0.000    0.000 sysconfig.py:612(get_platform)\n",
       "        1    0.000    0.000    0.000    0.000 latin_1.py:41(getregentry)\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup}\n",
       "       10    0.000    0.000    0.000    0.000 {method 'cast' of 'memoryview' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._init_names}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_manualSeedAll}\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_TagInfo)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:6(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:4(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 attr_value_pb2.py:5(<lambda>)\n",
       "       16    0.000    0.000    0.000    0.000 {method 'AddFileDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       25    0.000    0.000    0.000    0.000 {method 'append' of 'DescriptorSequence' objects}\n",
       "       13    0.000    0.000    0.000    0.000 summary_pb2.py:5(<lambda>)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:3032(__str__)\n",
       "        1    0.000    0.000    0.001    0.001 expat.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_cholesky.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:833(PolarAxes)\n",
       "        1    0.000    0.000    0.000    0.000 spines.py:13(Spine)\n",
       "        8    0.000    0.000    0.000    0.000 rrule.py:77(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1365(AnnotationBbox)\n",
       "        1    0.000    0.000    0.000    0.000 blocking_input.py:20(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 dviread.py:124(_dispatch)\n",
       "       24    0.000    0.000    0.000    0.000 patches.py:1816(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 textpath.py:24(TextToPath)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2084(IdentityTransform)\n",
       "       15    0.000    0.000    0.000    0.000 docstring.py:80(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5864(pyparsing_unicode)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(KeyDerivationFunction)\n",
       "        7    0.000    0.000    0.000    0.000 ocsp.py:43(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:10(_Reasons)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 url.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:124(HTTPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:22(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:8(Binomial)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 bernoulli.py:10(Bernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:7(Distribution)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:128(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:815(CrossEntropyLoss)\n",
       "        4    0.000    0.000    0.000    0.000 linear.py:69(extra_repr)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:20(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:1(<module>)\n",
       "        1    0.000    0.000    0.114    0.114 tarfile.py:1522(open)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'seed' of 'mtrand.RandomState' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:323(_get_typecodes)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:1145(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'newbyteorder' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:17(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 result.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 numerictypes.py:565(obj2sctype)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3269(parseImpl)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:4098(__str__)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:703(matplotlib_fname)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:409(_real_close)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:826(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:722(__new__)\n",
       "       23    0.000    0.000    0.000    0.000 enum.py:599(value)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:20(_showwarnmsg_impl)\n",
       "        4    0.000    0.000    0.000    0.000 weakref.py:288(update)\n",
       "       13    0.000    0.000    0.000    0.000 {built-in method builtins.delattr}\n",
       "        1    0.000    0.000    0.001    0.001 ImagePalette.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extension_loader.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:3(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 symbol_database.py:58(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:102(DescriptorPool)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:2020(__invert__)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:338(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:21(BaseSpecifier)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:2205(file_ns_handler)\n",
       "        1    0.000    0.000    0.001    0.001 _ccallback.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 spines.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 quiver.py:414(Quiver)\n",
       "        1    0.000    0.000    0.000    0.000 units.py:43(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 dates.py:581(DateFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:180(_ImageBase)\n",
       "        1    0.000    0.000    0.000    0.000 _layoutbox.py:48(LayoutBox)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:634(BakomaFonts)\n",
       "        1    0.000    0.000    0.000    0.000 docstring.py:1(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 cycler.py:145(change_key)\n",
       "        1    0.000    0.000    0.000    0.000 _binary.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:294(socksocket)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:586(Response)\n",
       "        1    0.000    0.000    0.004    0.004 api.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:259(Morsel)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1063(ZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:202(extended_date)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:949(KeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:136(_ECPoint)\n",
       "        1    0.000    0.000    0.001    0.001 exceptions.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:275(X509Backend)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 charsetgroupprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:58(MultivariateNormal)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:225(StmtBuilder)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:29(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:79(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 comm.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3080(view)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.copyto}\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:35(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 pytesttester.py:72(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:942(_register_types)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:334(ParseResults)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3230(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3982(__init__)\n",
       "       13    0.000    0.000    0.000    0.000 rcsetup.py:336(validate_color_or_auto)\n",
       "       11    0.000    0.000    0.000    0.000 pyparsing.py:470(__iter__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:555(get_home)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 backcall.py:49(adapt)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1533(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:572(dgettext)\n",
       "        5    0.000    0.000    0.000    0.000 traitlets.py:651(tag)\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:193(total_ordering)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:672(__setitem__)\n",
       "       15    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_cudnn_benchmark}\n",
       "        4    0.000    0.000    0.000    0.000 fractions.py:294(_operator_fallbacks)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Int8Tensor)\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:5(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 visdom_writer.py:13(_check_connection)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'ParseFromString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:187(Default)\n",
       "        4    0.000    0.000    0.000    0.000 descriptor.py:729(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3591(Each)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3841(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_Version)\n",
       "       14    0.000    0.000    0.000    0.000 six.py:189(__get_module)\n",
       "        1    0.000    0.000    0.000    0.000 py31compat.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2464(Distribution)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:237(SummaryWriter)\n",
       "        1    0.000    0.000    0.072    0.072 __init__.py:567(_build_master)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:2237(_cygwin_patch)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_VCABMState)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_RungeKuttaState)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 config.py:4(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 scale.py:592(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:38(Tick)\n",
       "        1    0.000    0.000    0.000    0.000 tricontour.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:81(DictReader)\n",
       "        4    0.000    0.000    0.000    0.000 legend_handler.py:179(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:2522(NavigationToolbar2)\n",
       "        1    0.000    0.000    0.000    0.000 _pylab_helpers.py:67(destroy_all)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Text)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Font)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2932(_apply_env_variables)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:214(_CertificateRevocationList)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:102(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_OpenSSLErrorWithText)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:18(HashAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3050(Sequence)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:581(ReasonFlags)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:115(inject_into_urllib3)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:217(PKey)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(RequestHistory)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:18(add_docstr_all)\n",
       "        1    0.000    0.000    0.233    0.233 alexnet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:9(Exponential)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:267(get_device_name)\n",
       "        1    0.000    0.000    0.114    0.114 serialization.py:448(legacy_load)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:388(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:1517(clear)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:268(validate_toolbar)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:921(validate_webagg_address)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:46(__exit__)\n",
       "        3    0.000    0.000    0.000    0.000 pathlib.py:664(_from_parsed_parts)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:96(seed)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:586(iteritems)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:737(__init__)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:1014(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1456(addHandler)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:283(__init__)\n",
       "        2    0.000    0.000    0.003    0.002 decoder.py:334(decode)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method sys.setdlopenflags}\n",
       "       14    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 JpegPresets.py:67(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:171(RefactoringTool)\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:138(_newer)\n",
       "        2    0.000    0.000    0.001    0.001 driver.py:147(load_packaged_grammar)\n",
       "        1    0.000    0.000    0.036    0.036 __init__.py:85(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'AddEnumDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        2    0.000    0.000    0.000    0.000 message_factory.py:50(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:47(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1288(addParseAction)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:1608(parseString)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:2963(__str__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3353(setResultsName)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3829(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:248(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:78(_IndividualSpecifier)\n",
       "        1    0.000    0.000    0.002    0.002 specifiers.py:214(LegacySpecifier)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:469(Module_six_moves_urllib)\n",
       "        7    0.000    0.000    0.000    0.000 six.py:209(is_package)\n",
       "        1    0.000    0.000    0.000    0.000 _expm_frechet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _procrustes.py:4(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:70(set)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:26(LowLevelCallable)\n",
       "        3    0.000    0.000    0.000    0.000 squeeze.py:7(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:65(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_ButcherTableau)\n",
       "        1    0.000    0.000    0.001    0.001 triangulation.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:127(RendererBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:728(GraphicsContextBase)\n",
       "        1    0.000    0.000    0.000    0.000 tight_layout.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:3204(MathTextParser)\n",
       "        1    0.000    0.000    0.000    0.000 textpath.py:412(TextPath)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Page)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Box)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2413(FancyBboxPatch)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:20(get_versions)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2787(register_save)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:387(_CertificateSigningRequest)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:109(_register_osrandom_engine)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:50(RFC822Name)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:268(RSAPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:80(DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 universaldetector.py:51(UniversalDetector)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:10(Multinomial)\n",
       "        1    0.000    0.000    0.000    0.000 chi2.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:10(Geometric)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:9(Uniform)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:17(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 adadelta.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 activation.py:321(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 activation.py:608(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 function.py:183(once_differentiable)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:7(_StorageBase)\n",
       "        2    0.000    0.000    0.000    0.000 serialization.py:46(register_package)\n",
       "        1    0.000    0.000    0.114    0.114 tarfile.py:1087(fromtarfile)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:239(manager_path)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:2109(Chebyshev)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:1794(Legendre)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:1814(Hermite)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:1811(HermiteE)\n",
       "        1    0.000    0.000    0.000    0.000 arraypad.py:5(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 helper.py:245(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.seterrobj}\n",
       "        1    0.000    0.000    0.000    0.000 financial.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:74(_determine_error_states)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:69(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:997(SafeEval)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2171(identity)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:450(decorating_function)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:24(TestResult)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Mismatch)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:7(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:342(_FuncPtr)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1595(enablePackrat)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3127(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 rcsetup.py:501(validate_ps_distiller)\n",
       "        9    0.000    0.000    0.000    0.000 fontconfig_pattern.py:145(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:578(_get_xdg_config_dir)\n",
       "        6    0.000    0.000    0.000    0.000 version.py:302(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 ImageEnhance.py:21(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'bind' of '_socket.socket' objects}\n",
       "        6    0.000    0.000    0.000    0.000 pathlib.py:1153(stat)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1354(add_argument_group)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:611(gettext)\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:921(uname)\n",
       "        6    0.000    0.000    0.000    0.000 traitlets.py:181(is_trait)\n",
       "        4    0.000    0.000    0.000    0.000 re.py:204(split)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:331(__iter__)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:274(load)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:398(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:678(__delitem__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.open}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._tracer_warn_use_python}\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:1552(AppendingTiffWriter)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:593(_Parser)\n",
       "        4    0.000    0.000    0.000    0.000 decoder.py:263(_StructPackDecoder)\n",
       "        2    0.000    0.000    0.000    0.000 extension_loader.py:16(DlopenGuard)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:24(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:11(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:110(_generate_pickle_name)\n",
       "        3    0.000    0.000    0.000    0.000 grammar.py:77(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:113(calc_output_size)\n",
       "        9    0.000    0.000    0.000    0.000 step_stats_pb2.py:5(<lambda>)\n",
       "        6    0.000    0.000    0.000    0.000 layout_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 reflection.py:46(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:392(FieldDescriptor)\n",
       "       18    0.000    0.000    0.000    0.000 pyparsing.py:458(__bool__)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:506(haskeys)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:668(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2991(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4163(__lshift__)\n",
       "        1    0.000    0.000    0.009    0.009 version.py:191(Version)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:317(__getitem__)\n",
       "       10    0.000    0.000    0.000    0.000 six.py:181(_get_module)\n",
       "       12    0.000    0.000    0.000    0.000 __init__.py:15(search_path)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ArgSpec)\n",
       "        1    0.000    0.000    0.000    0.000 flinalg.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 linalg_version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization_rl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interp.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:15(GeoAxes)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:33(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 trifinder.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 table.py:32(Cell)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:1300(rruleset)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:2436(FigureManagerBase)\n",
       "        1    0.000    0.000    0.000    0.000 _pylab_helpers.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:342(MathtextBackendCairo)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(CompositePart)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(CharMetrics)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:481(ScalarFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1297(EventCollection)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:264(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1961(MozillaCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_MemoryBIO)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:34(OCSPResponseStatus)\n",
       "        1    0.000    0.000    0.000    0.000 aead.py:5(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 SSL.py:701(<genexpr>)\n",
       "        2    0.000    0.000    0.027    0.013 binding.py:136(init_static_locks)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:40(NameAttribute)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:120(ExtendedKeyUsageOID)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:172(Encoding)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3848(SequenceOf)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:488(DistributionPoint)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:103(EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:131(DSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(Version)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:185(CertificateRevocationList)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:15(EllipticCurveOID)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:383(PyOpenSSLContext)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:872(X509Req)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:36(EUCJPProber)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:10(LogitRelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:74(_check_cryptography)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:95(HTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:8(LogisticNormal)\n",
       "        1    0.000    0.000    0.000    0.000 lowrank_multivariate_normal.py:57(LowRankMultivariateNormal)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:9(Pareto)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:11(Cauchy)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:209(ComposeTransform)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ScriptMethodStub)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:18(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 clip_grad.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 vision.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:451(__set__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:459(CudnnModule)\n",
       "        1    0.000    0.000    0.000    0.000 grad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:54(with_metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6449(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:1764(Laguerre)\n",
       "       14    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.geterrobj}\n",
       "        1    0.000    0.000    0.000    0.000 _inspect.py:7(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 numeric.py:156(ones)\n",
       "        1    0.000    0.000    0.000    0.000 pylabtools.py:302(activate_matplotlib)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1298(addParseAction)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:2042(__invert__)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:2067(suppress)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:3098(__str__)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:4445(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:324(<listcomp>)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:644(validate_sketch)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:327(__getitem__)\n",
       "        6    0.000    0.000    0.000    0.000 version.py:312(<listcomp>)\n",
       "      2/1    0.000    0.000    0.000    0.000 deprecation.py:248(wrapper)\n",
       "        1    0.000    0.000    0.000    0.000 deprecation.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 pathlib.py:357(gethomedir)\n",
       "        2    0.000    0.000    0.000    0.000 pathlib.py:685(_make_child)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:133(_get_kwargs)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1484(_get_handler)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:2175(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:2275(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 copy.py:111(_copy_immutable)\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:219(_deepcopy_tuple)\n",
       "        1    0.000    0.000    0.000    0.000 re.py:314(_compile_repl)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:349(__subclasshook__)\n",
       "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:960(__init__)\n",
       "       16    0.000    0.000    0.000    0.000 six.py:75(_add_doc)\n",
       "        9    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:947(TiffImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:16(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 compatibility.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:115(__init__)\n",
       "       13    0.000    0.000    0.000    0.000 decoder.py:190(_SimpleDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:375(EncodeVarint)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:33(olddict)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:32(Base)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:37(<listcomp>)\n",
       "        7    0.000    0.000    0.000    0.000 node_def_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:44(Message)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(manifest_mod)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1298(addCondition)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1567(resetCache)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:2376(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3015(parseImpl)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4003(parseImpl)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:4292(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:4(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:2310(EntryPoint)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:385(get_build_platform)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1123(ResourceManager)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:1790(XAxis)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:2164(YAxis)\n",
       "        1    0.000    0.000    0.000    0.000 trirefine.py:47(UniformTriRefiner)\n",
       "        1    0.000    0.000    0.000    0.000 tripcolor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:846(rrulewrapper)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:5(Container)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:562(ToolViewsPositions)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1949(RectangleSelector)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1096(TimerBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:35(ToolBase)\n",
       "        8    0.000    0.000    0.000    0.000 mathtext.py:1853(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3901(FancyArrowPatch)\n",
       "        1    0.000    0.000    0.000    0.000 bezier.py:147(BezierSegment)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:625(Rectangle)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:794(RegularPolygon)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2057(LogLocator)\n",
       "        1    0.000    0.000    0.000    0.000 _cm.py:57(cubehelix)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1718(AffineBase)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1865(Affine2D)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_XYPair)\n",
       "        4    0.000    0.000    0.000    0.000 docstring.py:35(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1224(Transform)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:1510(LightSource)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:427(Colormap)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5844(unicode_set)\n",
       "        5    0.000    0.000    0.000    0.000 Image.py:2776(register_mime)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:84(HTTPAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:13(where)\n",
       "        1    0.000    0.000    0.027    0.027 _internal_utils.py:9(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 ocsp.py:63(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:22(_OpenSSLError)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:15(_ASN1Type)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:613(EncryptionAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2737(ObjectIdentifier)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:60(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:170(__mul__)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:261(AuthorityInformationAccess)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:655(CertificatePolicies)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1449(UnrecognizedExtension)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:329(NamedCurve)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:21(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:253(DERSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:32(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:375(_EllipticCurve)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:714(X509Extension)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sjisprober.py:36(SJISProber)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:28(Retry)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:102(HTTPHeaderDict)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:92(RelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:10(ExpRelaxedCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:49(check_compatibility)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:10(Normal)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:8(Laplace)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:9(Poisson)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:26(Transform)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:8(TransformedDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:179(_GreaterThanEq)\n",
       "        1    0.000    0.000    0.000    0.000 beta.py:10(Beta)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:113(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 scatter_gather.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PackedSequence)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ASMoutput)\n",
       "        1    0.000    0.000    0.000    0.000 parallel_apply.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 replicate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:7(cudaOutputMode)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:173(_check_seekable)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:17(__enter__)\n",
       "        9    0.000    0.000    0.000    0.000 _globals.py:73(__repr__)\n",
       "        1    0.000    0.000    0.000    0.000 arraysetops.py:27(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 mixins.py:30(_reflected_binary_method)\n",
       "        4    0.000    0.000    0.000    0.000 mixins.py:55(_unary_method)\n",
       "        4    0.000    0.000    0.000    0.000 function_base.py:241(iterable)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1923(suppress_warnings)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:52(_set_function_name)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2887(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2891(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2478(prod)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:217(record)\n",
       "        3    0.000    0.000    0.000    0.000 result.py:12(failfast)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:246(_ctypes)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3057(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:607(validate_hinting)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:656(_get_data_path)\n",
       "        3    0.000    0.000    0.000    0.000 version.py:69(__ge__)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:93(StrictVersion)\n",
       "        1    0.000    0.000    0.002    0.002 version.py:27(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:903(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:110(GzipFile)\n",
       "        1    0.000    0.000    0.000    0.000 rcsetup.py:46(ValidateInStrings)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:24(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:55(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 pathlib.py:814(with_name)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1726(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1920(consume_positionals)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:506(translation)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:2558(class_init)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:1115(append)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:773(_get_devnull)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1154(_get_handles)\n",
       "        4    0.000    0.000    0.000    0.000 threading.py:74(RLock)\n",
       "        7    0.000    0.000    0.000    0.000 enum.py:537(_generate_next_value_)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:760(_missing_)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:339(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:334(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:806(fsdecode)\n",
       "        4    0.000    0.000    0.000    0.000 _collections_abc.py:252(__subclasshook__)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method atexit.register}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'title' of 'str' objects}\n",
       "        5    0.000    0.000    0.000    0.000 {method 'intersection' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:561(PyDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:854(ImageFileDirectory_v1)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:37(oldstr)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:318(Leaf)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:606(WildcardPattern)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:10(ODENVP)\n",
       "        3    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:5(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'FindOneofByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        1    0.000    0.000    0.000    0.000 message.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1972(__xor__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3458(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4141(Forward)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:589(SpecifierSet)\n",
       "        1    0.000    0.000    0.000    0.000 _sketches.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:56(S3RecordWriter)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 odefunc.py:75(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:6(AdaptiveStepsizeODESolver)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:230(ThetaLocator)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:34(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:527(YTick)\n",
       "        1    0.000    0.000    0.000    0.000 tritools.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:237(LinearTriInterpolator)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:1231(_Sparse_Matrix_coo)\n",
       "        1    0.000    0.000    0.000    0.000 quiver.py:235(QuiverKey)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:1409(_rrulestr)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:218(reload_library)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:2538(PolygonSelector)\n",
       "        3    0.000    0.000    0.000    0.000 legend_handler.py:340(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:1024(ToolHelpBase)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:635(TextBox)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1440(_SelectorWidget)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1890(ToolHandles)\n",
       "        1    0.000    0.000    0.000    0.000 blocking_input.py:100(BlockingMouseInput)\n",
       "        1    0.000    0.000    0.000    0.000 gridspec.py:175(GridSpec)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1060(StandardPsFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1425(Char)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1105(Arrow)\n",
       "        1    0.000    0.000    0.000    0.000 text.py:1280(TextWithDash)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:911(Polygon)\n",
       "        1    0.000    0.000    0.000    0.000 contour.py:738(ContourSet)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1026(RegularPolyCollection)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2344(CompositeGenericTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1095(LockableBbox)\n",
       "        1    0.000    0.000    0.000    0.000 cycler.py:77(Cycler)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:40(SqueezeNet)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:171(RequestsCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:830(CookiePolicy)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:13(_X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:76(Blowfish)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:264(OCSPRequest)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:217(_DHPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:80(DHParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:185(DHPublicKey)\n",
       "        5    0.000    0.000    0.000    0.000 backend.py:114(openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ASN1_STRING_set_default_mask_asc}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_get_default_RAND}\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:33(HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:146(BLAKE2b)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:180(RSASSAPSSParams)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:764(Void)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:473(PrivateKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:964(PublicKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:92(PrimePoint)\n",
       "        1    0.000    0.000    0.000    0.000 _errors.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _types.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:336(BasicConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:594(PolicyConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:904(TLSFeatureType)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:12(CipherBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:114(CRLNumber)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:46(register_decorator)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:150(DSAParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:227(DSAPrivateNumbers)\n",
       "        6    0.000    0.000    0.000    0.000 crypto.py:625(_cmp)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1941(Revoked)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2111(CRL)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:13(LogEntryType)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:33(GB2312Prober)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:34(Big5Prober)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:128(HebrewProber)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:70(HTTPConnection)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:11(StudentT)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:13(Gamma)\n",
       "        1    0.000    0.000    0.000    0.000 exp_family.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:38(Dirichlet)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:38(_parse_env)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:1262(_get_methods)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:17(Optimizer)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:44(__setstate__)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:254(ReduceLROnPlateau)\n",
       "        1    0.000    0.000    0.000    0.000 nccl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:13(_BatchNorm)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:760(ConvTranspose3d)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:75(Bilinear)\n",
       "        1    0.000    0.000    0.000    0.000 auto_double_backwards.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 auto_symbolic.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 profiler.py:337(attr_formatter)\n",
       "        1    0.000    0.000    0.002    0.002 random.py:77(manual_seed_all)\n",
       "        1    0.000    0.000    0.000    0.000 nvtx.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:7(Stream)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:166(nts)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:612(_FileInFile)\n",
       "        1    0.000    0.000    0.114    0.114 tarfile.py:1613(taropen)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6284(__array_finalize__)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6348(__setattr__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6256(MaskedConstant)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:1606(Polynomial)\n",
       "        3    0.000    0.000    0.000    0.000 index_tricks.py:241(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:270(_ErrorHolder)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:66(TestLoader)\n",
       "        1    0.000    0.000    0.000    0.000 main.py:49(TestProgram)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2896(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:1506(set_string_function)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:96(_str_xmin)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:532(max)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:455(iinfo)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:216(_getintp_ctype)\n",
       "        7    0.000    0.000    0.000    0.000 _inspect.py:144(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:759(__getitem__)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:99(CFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1501(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3081(parseImpl)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:4936(<genexpr>)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:413(validate_aspect)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:484(update_savefig_format)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:631(validate_bbox)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:666(get_candidate_paths)\n",
       "        3    0.000    0.000    0.000    0.000 version.py:331(_cmp)\n",
       "        1    0.000    0.000    0.007    0.007 fakedata.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:48(__enter__)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _socket.inet_aton}\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1725(_get_positional_actions)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1733(parse_args)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:824(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:2335(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:800(createLock)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1236(_fixupChildren)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1401(_try_wait)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register_error}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.uname}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:74(ImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:286(PngStream)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:146(EnumValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:288(_FloatDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:418(TagBytes)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:504(_StructPackEncoder)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:49(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:19(LParen)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:208(Node)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:241(Py2Fixer)\n",
       "        1    0.000    0.000    0.005    0.005 odenvp_conditional_rl.py:226(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:241(Duration)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:72(Node_py_OP)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:107(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:31(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 resource_handle_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:843(FileDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2439(Keyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2504(CaselessLiteral)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3233(WordEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3914(__str__)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:4783(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:28(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:20(with_metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:103(MovedModule)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:164(_SixMetaPathImporter)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:407(AppDirs)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:2876(DistInfoDistribution)\n",
       "        2    0.000    0.000    0.192    0.096 __init__.py:3109(_call_aside)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:312(_PlistParser)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:10(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:957(Environment)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1506(DefaultProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1603(ZipProvider)\n",
       "        1    0.000    0.000    0.000    0.000 thops.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crc32c.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:156(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:40(AverageMeter)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:62(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:7(CouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization_rl.py:5(RegularizedODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate_sep.py:20(CNF_Gate_Sep)\n",
       "        2    0.000    0.000    0.000    0.000 odefunc_rl.py:75(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:94(ODEnet)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:32(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:36(FixedGridODESolver)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:19(PolarTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:271(AitoffTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:85(LogTransformBase)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:6(ProjectionRegistry)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:293(CubicTriInterpolator)\n",
       "        1    0.000    0.000    0.000    0.000 triplot.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 quiver.py:890(Barbs)\n",
       "        1    0.000    0.000    0.000    0.000 stackplot.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:302(Grid)\n",
       "        1    0.000    0.000    0.000    0.000 table.py:145(CustomCell)\n",
       "        1    0.000    0.000    0.000    0.000 triangulation.py:7(Triangulation)\n",
       "        1    0.000    0.000    0.000    0.000 units.py:87(ConversionInterface)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:1308(_genitem)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:41(HandlerBase)\n",
       "        3    0.000    0.000    0.000    0.000 legend_handler.py:210(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 legend_handler.py:262(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:553(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:237(SetCursorBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:384(ToolQuit)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:832(ToolZoom)\n",
       "        1    0.000    0.000    0.000    0.000 tight_bbox.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:61(Widget)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:134(Button)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:138(OffsetBox)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:471(PaddedBox)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:554(DrawingArea)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:856(AuxTransformBox)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:966(AnchoredOffsetbox)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:901(NonUniformImage)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:83(MathtextBackend)\n",
       "        1    0.000    0.000    0.000    0.000 dviread.py:766(PsfontsMap)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1014(Wedge)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1863(_Style)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:561(Shadow)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:808(LogFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1711(MultipleLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1810(MaxNLocator)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:912(PolyCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1713(TriMesh)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1725(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1777(Affine2DBase)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2131(BlendedGenericTransform)\n",
       "        1    0.000    0.000    0.001    0.001 artist.py:1088(ArtistInspector)\n",
       "        1    0.000    0.000    0.000    0.000 pyplot.py:621(close)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:1068(SymLogNorm)\n",
       "       11    0.000    0.000    0.000    0.000 _color_data.py:31(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 lock.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:102(PrimitiveType)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:720(DataLoader)\n",
       "        3    0.000    0.000    0.000    0.000 Image.py:2821(register_extensions)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:5(Sampler)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:91(set_self_blocking)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:210(Condition)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:371(Barrier)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:25(MockRequest)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:108(HTTPDigestAuth)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:340(Session)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:863(DefaultCookiePolicy)\n",
       "        1    0.000    0.000    0.000    0.000 makefile.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:325(_OCSPRequest)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:175(OCSPResponseBuilder)\n",
       "        7    0.000    0.000    0.000    0.000 decode_asn1.py:187(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:142(DHPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:197(_DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:12(MACContext)\n",
       "        6    0.000    0.000    0.000    0.000 binding.py:54(_openssl_assert)\n",
       "        3    0.000    0.000    0.000    0.000 binding.py:106(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:183(PublicFormat)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:253(RegisteredID)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:64(register)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:220(SignedDigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:561(EncryptionAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(Any)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:971(Choice)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(Concat)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1695(AbstractString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1910(BitString)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:388(extended_datetime)\n",
       "        1    0.000    0.000    0.000    0.000 _ordereddict.py:23(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:300(AccessDescription)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:447(FreshestCRL)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:694(PolicyInformation)\n",
       "        3    0.000    0.000    0.000    0.000 extensions.py:915(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1044(NameConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1210(SubjectAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1315(CRLReason)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1421(OCSPNonce)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:54(OtherPrimeInfo)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:313(EllipticCurvePublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:384(EllipticCurvePrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:231(PEMSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:598(CertificateRevocationListBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(AsymmetricSignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:14(DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:247(WrappedSocket)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2387(PKCS12)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2568(NetscapeSPKI)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2665(_PassphraseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:18(Version)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:22(SignedCertificateTimestamp)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 compat.py:22(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:35(CharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 escprober.py:35(EscCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:18(is_local_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:18(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:10(Weibull)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:8(LogNormal)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:164(_InverseTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:290(ExpTransform)\n",
       "        1    0.000    0.000    0.000    0.000 gumbel.py:13(Gumbel)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:63(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:31(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:19(DistributedDataParallel)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:4(is_available)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:27(DistributedDataParallel)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:21(RNNBase)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:10(PackedSequence)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:576(Softplus)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:507(BCEWithLogitsLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1112(TripletMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:415(ParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:204(TensorDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:7(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:7(Type)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:13(EmbeddingBag)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:4(detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:1(<module>)\n",
       "        1    0.000    0.000    0.016    0.016 module.py:246(cuda)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6060(mvoid)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:845(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:86(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:184(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 info.py:156(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:83(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:138(_FileOpeners)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:270(NameValidator)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:34(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:44(_Outcome)\n",
       "        6    0.000    0.000    0.000    0.000 case.py:420(addTypeEqualityFunc)\n",
       "       10    0.000    0.000    0.000    0.000 case.py:1316(_deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:17(MachAr)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:100(_str_xmax)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:425(LoadLibrary)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1308(addCondition)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2461(Keyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2798(Regex)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3510(Or)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4003(_MultipleMatch)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:153(validate_float_or_None)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:209(validate_int_or_None)\n",
       "       11    0.000    0.000    0.000    0.000 rcsetup.py:661(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:678(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:687(get_data_path)\n",
       "        1    0.000    0.000    0.009    0.009 __init__.py:936(rc_params)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1404(get_backend)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:267(LooseVersion)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:629(Stack)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:10(SVHN)\n",
       "        2    0.000    0.000    0.000    0.000 configurable.py:381(instance)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:757(setup_class)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:960(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:160(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:220(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:12(pickle)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:885(addgroup)\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:196(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:794(fsencode)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:93(__new__)\n",
       "        6    0.000    0.000    0.000    0.000 {method 'isalnum' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:324(Parser)\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:56(BmpImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImagePalette.py:23(ImagePalette)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:97(ChunkStream)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:137(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(Iterator)\n",
       "        1    0.000    0.000    0.000    0.000 GifImagePlugin.py:46(GifImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:409(_VarintBytes)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:542(_FloatingPointEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 literals.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:82(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:10(ParserGenerator)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:22(RParen)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:50(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:327(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:252(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:104(_calc_n_scale)\n",
       "        4    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:204(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:541(_FieldMaskTree)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:788(ListValue)\n",
       "        3    0.000    0.000    0.000    0.000 graph_pb2.py:5(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 versions_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:434(ScalarMap)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:222(Descriptor)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:230(RepeatedScalarFieldContainer)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:343(RepeatedCompositeFieldContainer)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:607(EnumDescriptor)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:460(__iter__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1455(_UnboundedCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2545(CloseMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2765(Regex)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3066(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4214(copy)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:4383(postParse)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:72(LegacyVersion)\n",
       "        8    0.000    0.000    0.000    0.000 version.py:261(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:205(ParseBaseException)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:315(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:314(_ParseResultsWithOffset)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:124(_LazyModule)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3114(_initialize)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:64(install)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:4(VendorImporter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(VersionConflict)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:342(register_loader_type)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:551(WorkingSet)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1381(NullProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1525(_register)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:2076(register_namespace_handler)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:138(DeprecatedImport)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:66(reset)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(RunningAverageMeter)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:9(_ActNorm)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:110(Conv2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:152(Conv2dZeros)\n",
       "        3    0.000    0.000    0.000    0.000 _testutils.py:26(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:17(NumpyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:214(GatedLinear)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(MovingBatchNormNd)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:151(AdamsBashforthMoulton)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:5(RegularizedODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 backend_agg.py:372(FigureCanvasAgg)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:86(PolarAffine)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:521(RadialTick)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:759(_WedgeBbox)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:268(AitoffAxes)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:368(MollweideAxes)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:442(LambertAxes)\n",
       "        3    0.000    0.000    0.000    0.000 scale.py:551(get_scale_names)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:13(register)\n",
       "        1    0.000    0.000    0.000    0.000 _base.py:131(_process_plot_var_args)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:338(bytespdate2num)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:951(DateLocator)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:93(rrulebase)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:1105(_iterinfo)\n",
       "        1    0.000    0.000    0.000    0.000 figure.py:60(AxesStack)\n",
       "        1    0.000    0.000    0.000    0.000 _subplots.py:11(SubplotBase)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:440(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:549(HandlerStem)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3179(_Backend)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1607(DraggableBase)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:746(UnicodeFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:861(DejaVuFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1893(Filll)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1378(CirclePolygon)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1407(Ellipse)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1534(Arc)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3009(Bar)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3558(BracketAB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:4332(ConnectionPatch)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:371(FuncFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:886(PathCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1544(CircleCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1564(EllipseCollection)\n",
       "        1    0.000    0.000    0.000    0.000 cm.py:185(ScalarMappable)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1621(TransformWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2675(BboxTransformFrom)\n",
       "        1    0.000    0.000    0.000    0.000 docstring.py:61(Appender)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:55(TransformNode)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:306(ColorConverter)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:5833(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:12(qualify)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:25(BaseTypeByIdentity)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:79(SubsetRandomSampler)\n",
       "        4    0.000    0.000    0.000    0.000 _utils.py:8(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:46(SemLock)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:60(RequestEncodingMixin)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:272(PreparedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:485(BaseCookie)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:329(_RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:418(_RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:26(AES)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:91(CAST5)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:126(_EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:228(_EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:176(_RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:499(_SignedCertificateTimestamp)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:57(OCSPCertStatus)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:106(_DHPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:18(DHPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:118(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:170(DHPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:108(_DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 ciphers.py:13(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:86(AEADEncryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:14(Mode)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:131(OFB)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:197(GCM)\n",
       "        1    0.000    0.000    0.000    0.000 cmac.py:16(_CMACContext)\n",
       "       10    0.000    0.000    0.000    0.000 SSL.py:646(_requires_decorator)\n",
       "        1    0.000    0.000    0.000    0.000 intranges.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:142(Name)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:135(CertificatePoliciesOID)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:178(PrivateFormat)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:189(ParameterFormat)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:317(OtherName)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:29(TeletexIncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:50(_ForceNullParameters)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:272(SignedDigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2964(Enumerated)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:54(PrimeCurve)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:232(SubjectKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:862(TLSFeature)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:918(InhibitAnyPolicy)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:86(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:116(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:264(CharacteristicTwo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:384(ECDomainParameters)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:48(EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:10(ObjectIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:96(RSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:334(DHBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:389(ScryptBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:63(ExtensionType)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:72(Extensions)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(register_interface_if)\n",
       "        2    0.000    0.000    0.000    0.000 utils.py:123(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:65(DSAPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:189(DSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1550(X509StoreFlags)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1696(X509StoreContext)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:34(EUCKRProber)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:33(SingleByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 langcyrillicmodel.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langthaimodel.py:37(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:33(CodingStateMachine)\n",
       "        1    0.000    0.000    0.000    0.000 utf8prober.py:35(UTF8Prober)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:34(MultiByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 url.py:14(Url)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:87(RelaxedOneHotCategorical)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:6(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:69(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:736(HTTPSConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 half_normal.py:11(HalfNormal)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:24(_Dirichlet)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:784(OrderedDictWrapper)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:1279(_make_fail)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:154(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:56(LambdaLR)\n",
       "        3    0.000    0.000    0.000    0.000 rendezvous.py:13(register_rendezvous_handler)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:58(__setstate__)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:10(Embedding)\n",
       "        1    0.000    0.000    0.000    0.000 convert_parameters.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:6(PixelShuffle)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:7(PairwiseDistance)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:971(AdaptiveAvgPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:6(_InstanceNorm)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:134(InstanceNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:75(LayerNorm)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:10(_ConstantPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:10(Threshold)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:269(Tanh)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:27(L1Loss)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:96(ModuleList)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:297(MaxUnpool2d)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:460(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:11(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:11(Linear)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:129(profile)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:341(FormattedTimesMixin)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:39(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:331(NestedIOFunction)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:23(THNNBackendBase)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:108(Function)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:86(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:131(Event)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:336(_Stream)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1443(MAxisConcatenator)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:59(metaclass)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:805(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1315(_replace_dtype_fields)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:3350(dtype)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:18(NumpyVersion)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'tobytes' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:9(PackageLoader)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:20(Arrayterator)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:231(AxisConcatenator)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:29(TextTestResult)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2902(_setdef)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1338(FunctionTestCase)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:16(BaseTestSuite)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:92(TestSuite)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:62(MachArLike)\n",
       "        5    0.000    0.000    0.000    0.000 _inspect.py:145(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:845(<lambda>)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:2048(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2398(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2787(Char)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3132(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3196(LineStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3322(ParseExpression)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4179(SkipTo)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4449(postParse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4517(Suppress)\n",
       "        1    0.000    0.000    0.003    0.003 pyparsing.py:5057(makeHTMLTags)\n",
       "        2    0.000    0.000    0.000    0.000 rcsetup.py:315(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 rcsetup.py:596(validate_svg_fonttype)\n",
       "        1    0.000    0.000    0.000    0.000 fontconfig_pattern.py:30(FontconfigPatternParser)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:467(__len__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:654(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:625(get_configdir)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:645(get_cachedir)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:615(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1769(Locked)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:377(_GzipReader)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:29(Stat)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:9(Omniglot)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:16(CIFAR10)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:12(PhotoTour)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:44(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:455(RandomVerticalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:413(close)\n",
       "        2    0.000    0.000    0.000    0.000 pathlib.py:898(__truediv__)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1011(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:2071(_match_arguments_partial)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1148(_sys_version)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1255(python_implementation)\n",
       "        2    0.000    0.000    0.000    0.000 configurable.py:426(initialized)\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:2984(bind)\n",
       "        6    0.000    0.000    0.000    0.000 traitlets.py:383(class_init)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1280(setLevel)\n",
       "        4    0.000    0.000    0.000    0.000 sre_parse.py:161(__delitem__)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:85(_showwarnmsg)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:760(getenv)\n",
       "        4    0.000    0.000    0.000    0.000 genericpath.py:53(getmtime)\n",
       "        2    0.000    0.000    0.000    0.000 _collections_abc.py:271(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'count' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rfind' of 'bytes' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method sys.getdlopenflags}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.charmap_build}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'union' of 'set' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:549(PyCodecState)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:209(PngInfo)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:540(PngImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:48(PpmImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:188(iTXt)\n",
       "        1    0.000    0.000    0.000    0.000 TiffTags.py:23(TagInfo)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:620(_register_loader)\n",
       "        1    0.000    0.000    0.000    0.000 JpegImagePlugin.py:300(JpegImageFile)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:134(_SignedVarintDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:323(_DoubleDecoder)\n",
       "        3    0.000    0.000    0.000    0.000 encoder.py:184(_FixedSizer)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:17(BMNode)\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:16(MinNode)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:272(DebugMode)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:415(BasePattern)\n",
       "        1    0.000    0.000    0.000    0.000 workspace.py:494(_BlobDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(RTs)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:27(Parser)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:692(MultiprocessRefactoringTool)\n",
       "        1    0.000    0.000    0.000    0.000 driver.py:30(Driver)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:49(any)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:197(Untokenizer)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:98(Timestamp)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:398(FieldMask)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:735(Struct)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:524(MessageMap)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:41(EnumTypeWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 symbol_database.py:65(SymbolDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:46(DescriptorDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:94(DescriptorBase)\n",
       "        2    0.000    0.000    0.000    0.000 api_implementation.py:136(Type)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:185(BaseContainer)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:712(OneofDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:748(ServiceDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:803(MethodDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3046(White)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3184(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3199(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3256(ParseExpression)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3368(And)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3444(Or)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3715(ParseElementEnhance)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3962(Optional)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4296(postParse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4335(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:42(_BaseVersion)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:7(Infinity)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:39(NegativeInfinity)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:173(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:360(Module_six_moves_urllib_error)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:380(Module_six_moves_urllib_request)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:86(_LazyDescr)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2973(Requirement)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:79(_InternalDict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:204(Data)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:40(SummaryToEventTransformer)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:144(FileWriter)\n",
       "        1    0.000    0.000    0.000    0.000 embedding.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:32(EventsWriter)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:79(EventFileWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:175(get_supported_platform)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:288(ContextualVersionConflict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:301(DistributionNotFound)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:500(IMetadataProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:523(IResourceProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1583(MemoizedZipManifests)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1907(find_nothing)\n",
       "        1    0.000    0.000    0.003    0.003 train_misc.py:15(set_cnf_options)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:141(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:11(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 torchvis.py:19(TorchVis)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:170(Permute2d)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:136(__lt__)\n",
       "        4    0.000    0.000    0.000    0.000 six.py:67(_add_doc)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:260(BlendLinear)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:6(BruteForceLayer)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:7(PlanarFlow)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate.py:20(CNF_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:4(SequentialFlow_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:11(CNF_augment)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:94(ODEnet)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:255(ODEfunc_rl)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:5(Euler)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:7(OdeintAdjointMethod)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:7(SequentialDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:13(HyperLinear)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:4(SequentialFlow)\n",
       "        1    0.000    0.000    0.000    0.000 cnf.py:11(CNF)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:96(get_projection_names)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:241(_GeoTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:344(InvertedHammerTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:319(HammerAxes)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:445(LambertTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:12(ScaleBase)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:191(LogScale)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:450(LogitTransform)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:404(XTick)\n",
       "        2    0.000    0.000    0.000    0.000 axis.py:663(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:16(TriInterpolator)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:1012(_DOF_estimator)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:239(DomainMap)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:1557(PCA)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3601(GaussianKDE)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:24(Dialect)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:55(excel)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:131(DictWriter)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:166(Sniffer)\n",
       "        1    0.000    0.000    0.000    0.000 category.py:23(StrCategoryConverter)\n",
       "        1    0.000    0.000    0.000    0.000 category.py:127(StrCategoryFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 units.py:136(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1031(RRuleLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1136(AutoDateLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1459(WeekdayLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1574(MicrosecondLocator)\n",
       "        4    0.000    0.000    0.000    0.000 rrule.py:80(_invalidates_cache)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:649(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:492(ToolMinorGrid)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:512(ToolFullScreen)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:542(ToolYScale)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:552(ToolXScale)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:726(ToolHome)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:760(SaveFigureBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:958(ToolPan)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:1066(ToolCopyToClipboardBase)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:23(LockDraw)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:92(AxesWidget)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:481(CheckButtons)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1085(SubplotTool)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1325(MultiCursor)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:1155(FigureImage)\n",
       "        4    0.000    0.000    0.000    0.000 backend_bases.py:92(register_backend)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3011(ToolContainerBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:26(Cursors)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:147(ToolToggleBase)\n",
       "        1    0.000    0.000    0.000    0.000 legend.py:50(DraggableLegend)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1260(OffsetImage)\n",
       "        1    0.000    0.000    0.000    0.000 blocking_input.py:30(BlockingInput)\n",
       "        1    0.000    0.000    0.000    0.000 gridspec.py:30(GridSpecBase)\n",
       "        1    0.000    0.000    0.000    0.000 gridspec.py:409(SubplotSpec)\n",
       "        1    0.000    0.000    0.019    0.019 mathtext.py:2738(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:3227(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:217(MathtextBackendPs)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:370(Fonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:529(TruetypeFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:934(StixFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1532(List)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1705(Vlist)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1816(Glue)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1930(Kern)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:2037(Ship)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:2523(State)\n",
       "        1    0.000    0.000    0.000    0.000 dviread.py:490(DviFont)\n",
       "        1    0.000    0.000    0.000    0.000 dviread.py:934(Encoding)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1172(FancyArrow)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1274(YAArrow)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1490(Circle)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1854(_simpleprint_styles)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2687(_Base)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3141(_Base)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3220(_Curve)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3846(Wedge)\n",
       "        1    0.000    0.000    0.000    0.000 textpath.py:32(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 text.py:1682(OffsetFrom)\n",
       "        1    0.000    0.000    0.000    0.000 text.py:1766(_AnnotationBase)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:880(PathPatch)\n",
       "        1    0.000    0.000    0.000    0.000 contour.py:1453(QuadContourSet)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:205(_DummyAxis)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:231(TickHelper)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:252(Formatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1169(EngFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1283(PercentFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1399(Locator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1669(Base)\n",
       "        1    0.000    0.000    0.000    0.000 lines.py:1348(VertexSelector)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:837(_CollectionWithSizes)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:979(BrokenBarHCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1105(LineCollection)\n",
       "        2    0.000    0.000    0.000    0.000 cm.py:77(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2253(BlendedAffine2D)\n",
       "        1    0.000    0.000    0.000    0.000 artist.py:1223(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 docstring.py:7(Substitution)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:83(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1019(TransformedBbox)\n",
       "        1    0.000    0.000    0.000    0.000 pyplot.py:1801(colormaps)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:218(_ColorbarAutoLocator)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:248(_ColorbarAutoMinorLocator)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:1058(Colorbar)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:632(LinearSegmentedColormap)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:870(Normalize)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:72(_ColorMapping)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:94(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:46(ConcatDataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:300(_DataLoaderIter)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_pandas.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:16(ResNeXtBottleneckC)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:58(ResNeXt)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:127(_DenseLayer)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:14(LSUNClass)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:59(SOCKSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:141(SOCKSProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:93(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _utils.py:123(Comparable)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:186(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:13(CaseInsensitiveDict)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:198(Request)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:13(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:95(SessionRedirectMixin)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:55(BaseAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:732(Cookie)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:318(ZipInfo)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:760(ZipExtFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:989(_ZipWriteFile)\n",
       "        1    0.000    0.000    0.002    0.002 certs.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:299(_RSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:17(AsymmetricPadding)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:31(PSS)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:14(X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:31(X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:42(Camellia)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:57(TripleDES)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:106(ARC4)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:119(IDEA)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:133(SEED)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:148(ChaCha20)\n",
       "        1    0.000    0.000    0.000    0.000 __version__.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:13(_HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:15(_HMACContext)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:29(OCSPResponderEncoding)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:49(DHPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:84(_DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:20(CipherAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:67(AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:164(_AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:228(_AEADEncryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:30(ModeWithInitializationVector)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:85(CBC)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:100(XTS)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:146(CFB)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:161(CFB8)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:176(CTR)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_by_id}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_set_default_RAND}\n",
       "        1    0.000    0.000    0.000    0.000 name.py:102(RelativeDistinguishedName)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:46(CRLEntryExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:130(AuthorityInformationAccessOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:60(Hash)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:167(BLAKE2s)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:57(make_assert)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'new_allocator' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:115(DNSName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:160(UniformResourceIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:227(DirectoryName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:279(IPAddress)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:107(HmacAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:372(Pbkdf2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:475(RSAESOAEPParams)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:693(Constructable)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2198(OctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2370(OctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2501(ParsableOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2706(Null)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:944(PublicKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:378(DeltaCRLIndicator)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:406(CRLDistributionPoints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:744(UserNotice)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:781(NoticeReference)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:817(ExtendedKeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1126(Extension)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1245(IssuerAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1280(CertificateIssuer)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1343(InvalidityDate)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1373(PrecertificateSignedCertificateTimestamps)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:74(RSAPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:252(Pentanomial)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:313(SpecifiedECDomain)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:288(ECDSA)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:54(RSAPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:69(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:338(RSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:64(CMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:369(RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:431(CertificateBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:23(DSAParametersWithNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:24(EllipticCurve)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:39(EllipticCurveSignatureAlgorithm)\n",
       "        2    0.000    0.000    0.000    0.000 exceptions.py:40(SSLError)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:76(Error)\n",
       "        2    0.000    0.000    0.000    0.000 crypto.py:205(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:204(_X509NameInvalidator)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1573(X509Store)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2336(PKCS7)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:116(JapaneseContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:183(SJISContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:34(CP949Prober)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:33(EUCTWProber)\n",
       "        1    0.000    0.000    0.000    0.000 langgreekmodel.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langbulgarianmodel.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langhebrewmodel.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langturkishmodel.py:37(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:122(PoolManager)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:362(ProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 charsetgroupprober.py:32(CharSetGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:17(LanguageFilter)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:50(SequenceLikelihood)\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:96(Latin1Prober)\n",
       "        1    0.000    0.000    0.000    0.000 euctwfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:40(CharDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 big5freq.py:43(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:8(is_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:23(is_prod_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:28(RecentlyUsedContainer)\n",
       "        1    0.000    0.000    0.000    0.000 request.py:10(RequestMethods)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:50(RequestField)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:22(DeflateDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:117(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:19(cuFFTPlanCache)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:32(_OpNamespace)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:68(_Ops)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:55(ConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 kl.py:77(_Match)\n",
       "        1    0.000    0.000    0.000    0.000 chi2.py:6(Chi2)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:217(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(PowerTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:340(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:362(AbsTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:379(AffineTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:472(StickBreakingTransform)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:49(Constraint)\n",
       "        2    0.000    0.000    0.000    0.000 constraints.py:143(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 exp_family.py:5(ExponentialFamily)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:234(LegacyTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:550(ignore_lib_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:817(OrderedModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:868(OrderedBufferDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:960(ScriptModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1164(WeakScriptModuleProxy)\n",
       "        2    0.000    0.000    0.000    0.000 annotations.py:15(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:111(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:119(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:5(Adagrad)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:6(Adam)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:5(Adamax)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:6(ASGD)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:5(SGD)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:5(RMSprop)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:6(LBFGS)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:42(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:61(_ResourceSharer)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:8(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:7(Warning)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:35(DataParallel)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:9(Broadcast)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:35(ReduceAddCoalesced)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:10(DistributedDataParallelCPU)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:169(EmbeddingBag)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:8(WeightNorm)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:9(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:9(Upsample)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:47(CosineSimilarity)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:6(Fold)\n",
       "        1    0.000    0.000    0.000    0.000 adaptive.py:15(AdaptiveLogSoftmaxWithLoss)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:444(AvgPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:707(_LPPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:723(LPPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:766(LPPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:948(AdaptiveAvgPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:58(InstanceNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:11(LocalResponseNorm)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:165(GroupNorm)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:22(Dropout)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:149(AlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:146(Hardtanh)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:242(Sigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:295(ELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:335(CELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:380(SELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:425(GLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:459(Hardshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:501(LeakyReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:621(Softshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:780(Softmin)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:897(LogSoftmax)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:96(NLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:223(PoissonNLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:289(KLDivLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:438(BCELoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:713(SmoothL1Loss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:954(CosineEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1001(MarginRankingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1049(MultiMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:22(Sequential)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:202(ModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:318(ParameterList)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:9(_MaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:84(MaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:464(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:190(Conv2d)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:377(FunctionEvent)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:5(no_grad)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:18(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:10(_ContextMethodMixin)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:73(_check_driver)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6440(_extrema_operation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6557(_frommethod)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:8048(_convert2ma)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:218(_fromnxfunction)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:273(_fromnxfunction_single)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:206(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:976(_MaskedBinaryOperation)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:1362(getmask)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2378(_MaskedPrintOption)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2596(MaskedIterator)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:3366(shape)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:28(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:224(_FFTCache)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_string_function}\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:115(NpzFile)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:162(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:265(DataSource)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:621(Repository)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:170(LineSplitter)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:98(nd_grid)\n",
       "        1    0.000    0.000    0.000    0.000 function_base.py:1760(vectorize)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:23(_FailedTest)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:76(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:120(TextTestRunner)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1858(clear_and_catch_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:57(_Deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2824(errstate)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:810(FloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:184(_AssertRaisesContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1396(_SubTest)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:85(format_parser)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:304(recarray)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:20(memmap)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:104(_str_resolution)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:305(finfo)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3041(CharsNotIn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3250(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:3265(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3279(WordStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3419(setResultsName)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3434(And)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3781(ParseElementEnhance)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4067(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4294(Forward)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4387(Combine)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:190(validate_dpi)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:422(validate_fontsize_None)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:215(ParseBaseException)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:325(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:676(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1415(interactive)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:31(Version)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:70(_StrongRef)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:88(CallbackRegistry)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:904(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:867(Grouper)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:306(Color3DLUT)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:17(SEMEION)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:308(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:7(CocoCaptions)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:82(CocoDetection)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:174(CIFAR100)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:12(STL10)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:12(MNIST)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:149(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:360(RandomCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:436(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:954(Grayscale)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:45(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:232(get_context)\n",
       "        2    0.000    0.000    0.000    0.000 pathlib.py:89(join_parsed_parts)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
       "        1    0.000    0.000    0.000    0.000 six.py:829(__prepare__)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:819(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:2259(class_init)\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:2589(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:545(__get__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:823(setLevel)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:1056(_open)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1982(createLock)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:203(_cleanup)\n",
       "        1    0.000    0.000    0.000    0.000 re.py:330(filter)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:22(constructor)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:106(_formatwarnmsg)\n",
       "        5    0.000    0.000    0.000    0.000 _collections_abc.py:367(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 _collections_abc.py:406(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rstrip' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedReader' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'index' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method '__prepare__' of 'type' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getCompiledVersion}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._jit_init}\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:294(StubImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:249(DibImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:24(GimpPaletteFile)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:62(GradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:678(_idat)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:630(decorator)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:629(_register_writer)\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:103(GimpGradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:22(PaletteFile)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:77(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:100(TextWriter)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:253(_Printer)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:1022(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:98(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:92(TypeChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:125(IntValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:166(UnicodeValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:194(Int32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:202(Uint32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:208(Int64ValueChecker)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:107(_VarintDecoder)\n",
       "        3    0.000    0.000    0.000    0.000 decoder.py:249(_ModifiedDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:822(_FieldSkipper)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:126(_SimpleSizer)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:429(_SimpleEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:470(_ModifiedEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:80(PackTag)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:38(PatternCompiler)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:26(BottomMatcher)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:24(BaseBaseString)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:14(BaseOldStr)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:7(PgenGrammar)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:347(DFAState)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:501(LeafPattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:545(NodePattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:794(NegatedPattern)\n",
       "        1    0.000    0.000    0.000    0.000 pygram.py:20(Symbols)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:457(hooks)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:477(suspend_hooks)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:16(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:43(_EveryNode)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:688(MultiprocessingUnsupported)\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:23(Grammar)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:164(TokenError)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:166(StopTokenizing)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:50(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl.py:193(StackedCNFLayers)\n",
       "        2    0.000    0.000    0.000    0.000 types_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:19(Node_base)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:38(Node_py)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:63(Node_py_IO)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:79(Graph_py)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:36(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:40(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:42(GeneratedProtocolMessageType)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:38(Error)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:42(DescriptorDatabaseConflictingDefinitionError)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:47(MessageFactory)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:64(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:68(Any)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:165(_NestedDescriptorBase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:672(EnumValueDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:44(Node)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:59(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:272(Marker)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:55(TypeTransformationError)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:64(DescriptorMetaclass)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:76(_Lock)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:31(UndefinedComparison)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:25(InvalidMarker)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:37(UndefinedEnvironmentName)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:644(__getattr__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:666(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1478(_FifoCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2364(Token)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2383(NoMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2398(Literal)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2527(CaselessKeyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2606(Word)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2838(QuotedString)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2975(CharsNotIn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3097(_PositionToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3104(GoToColumn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3151(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3180(StringStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3195(StringEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3213(WordStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3384(_ErrorStop)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:3461(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3523(MatchFirst)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3792(FollowedBy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3818(NotAny)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3923(ZeroOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3954(_NullToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4026(SkipTo)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4222(_ForwardNoRecurse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4226(TokenConverter)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4234(Combine)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4278(Group)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4299(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4364(Suppress)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4390(OnlyOnce)\n",
       "        1    0.000    0.000    0.001    0.001 pyparsing.py:4904(makeHTMLTags)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:15(InvalidSpecifier)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:27(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:18(InvalidRequirement)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:75(Requirement)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:183(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:261(ParseException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:282(ParseFatalException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:287(ParseSyntaxException)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:139(MovedAttribute)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:229(_MovedItems)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:430(Module_six_moves_urllib_response)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:451(Module_six_moves_urllib_robotparser)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:36(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2857(EggInfoDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2946(RequirementParseError)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:109(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:127(Plist)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:416(_DumbXMLWriter)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:454(_PlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:587(InvalidFileException)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:595(_BinaryPlistParser)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:764(_BinaryPlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:156(_EventLoggerThread)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:249(ResolutionError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:328(UnknownExtra)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:905(subscribe)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:937(_ReqExtras)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1127(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1484(EggProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1549(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1536(EmptyProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1556(ZipManifests)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1778(FileMetadata)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1817(PathMetadata)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1989(NoDists)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:89(S3RecordWriterFactory)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:104(RecordWriter)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:22(SqrtmError)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1044(LstsqLapackError)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:115(ParallelSumModules)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:126(ParallelCNFLayers)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:83(ActNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:95(LinearZeros)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:194(InvertibleConv1x1)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:291(Split2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:347(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:361(MultiLinearZeros)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:21(PytestTester)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:78(_compare_version)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:114(_compare)\n",
       "        1    0.000    0.000    0.000    0.000 misc.py:11(LinAlgWarning)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:88(HyperConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:124(IgnoreConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:137(SquashConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:151(ConcatConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:180(ConcatSquashConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:196(ConcatCoordConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:226(GatedConv)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:242(GatedConvTranspose)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:6(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:128(MovingBatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:134(MovingBatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:51(MaskedCouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:6(FeedforwardGateI)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:46(FeedforwardGateII)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:89(FeedforwardGateIII)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:63(Swish)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:176(AutoencoderDiffEqNet)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:321(AutoencoderODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:15(Midpoint)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:26(RK4)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:208(AdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:18(_VCABMState)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:61(VariableCoefficientAdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint_sep.py:7(OdeintAdjointMethod)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:63(Swish)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:73(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:176(AutoencoderDiffEqNet)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:255(ODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:316(AutoencoderODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:21(MixtureODELayer)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:7(DiffEqWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:29(ReshapeDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:9(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:38(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:36(IgnoreLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:45(ConcatLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:56(ConcatLinear_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:66(SquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:76(ConcatSquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 backend_agg.py:592(_BackendAgg)\n",
       "        1    0.000    0.000    0.000    0.000 tsit5.py:66(Tsit5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:8(ZeroMeanTransform)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:25(LogitTransform)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:43(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:125(InvertedPolarTransform)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:184(ThetaFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:207(_AxisWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:270(ThetaTick)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:373(ThetaAxis)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:418(RadialLocator)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:462(_ThetaShift)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:705(RadialAxis)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:17(ThetaFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:298(InvertedAitoffTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:322(HammerTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:371(MollweideTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:413(InvertedMollweideTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:488(InvertedLambertTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:53(LinearScale)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:118(InvertedLogTransformBase)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:152(InvertedLog2Transform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:159(NaturalLogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:166(InvertedNaturalLogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:173(LogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:182(InvertedLogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:298(SymmetricalLogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:331(InvertedSymmetricalLogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:363(SymmetricalLogScale)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:478(LogisticTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:499(LogitScale)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:600(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(get_projection_names)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:650(Ticker)\n",
       "        1    0.000    0.000    0.000    0.000 trifinder.py:25(TrapezoidMapTriFinder)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:1080(_DOF_estimator_user)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:1089(_DOF_estimator_geom)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:1173(_DOF_estimator_min_E)\n",
       "        1    0.000    0.000    0.000    0.000 trirefine.py:10(TriRefiner)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:229(StreamplotSet)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:349(StreamMask)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:404(TerminateTrajectory)\n",
       "        1    0.000    0.000    0.000    0.000 tricontour.py:8(TriContourSet)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:2943(FormatObj)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:2962(FormatString)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:2969(FormatFormatStr)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:2980(FormatFloat)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:2999(FormatInt)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3012(FormatBool)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3039(FormatDate)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3057(FormatDatetime)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:70(unix_dialect)\n",
       "        1    0.000    0.000    0.000    0.000 category.py:109(StrCategoryLocator)\n",
       "        1    0.000    0.000    0.000    0.000 units.py:52(AxisInfo)\n",
       "        1    0.000    0.000    0.000    0.000 units.py:132(Registry)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:322(strpdate2num)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:723(IndexDateFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:747(AutoDateFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1370(YearLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1487(DayLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1514(HourLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1766(DateConverter)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:66(weekday)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:304(rrule)\n",
       "        1    0.000    0.000    0.000    0.000 figure.py:169(SubplotParams)\n",
       "        1    0.000    0.000    0.000    0.000 _subplots.py:218(<genexpr>)\n",
       "        1    0.000    0.000    0.035    0.035 core.py:151(load_base_library)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:164(update_user_library)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:2751(Lasso)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:103(BarContainer)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:130(HandlerNpoints)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:174(HandlerNpointsYoffsets)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:206(HandlerLine2D)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:258(HandlerPatch)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:304(HandlerLineCollection)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:336(HandlerRegularPolyCollection)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:411(HandlerPathCollection)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:436(HandlerErrorbar)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:632(HandlerTuple)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:687(HandlerPolyCollection)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:309(ToolCursorPosition)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:356(RubberbandBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:394(ToolQuitAll)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:404(ToolEnableAllNavigation)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:420(ToolEnableNavigation)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:437(_ToolGridBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:471(ToolGrid)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:525(AxisScaleBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:735(ToolBack)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:744(ToolForward)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:753(ConfigureSubplotsBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:768(ZoomPanBase)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:256(Slider)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:940(RadioButtons)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1234(Cursor)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1669(SpanSelector)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:2380(EllipseSelector)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:2451(LassoSelector)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:1023(PcolorImage)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:1216(BboxImage)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1251(Event)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1275(DrawEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1303(ResizeEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1324(CloseEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1333(LocationEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1428(MouseEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1485(PickEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1529(KeyEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:2432(NonGuiException)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3156(StatusbarBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3292(ShowBase)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:273(PackerBase)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:317(VPacker)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:393(HPacker)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1214(AnchoredText)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1730(DraggableOffsetBox)\n",
       "        1    0.000    0.000    0.000    0.000 blocking_input.py:267(BlockingContourLabeler)\n",
       "        1    0.000    0.000    0.000    0.000 blocking_input.py:326(BlockingKeyMouseInput)\n",
       "        1    0.000    0.000    0.000    0.000 gridspec.py:348(GridSpecFromSubplotSpec)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:137(MathtextBackendAgg)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:211(MathtextBackendBitmap)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:257(MathtextBackendPdf)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:285(MathtextBackendSvg)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:314(MathtextBackendPath)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:904(DejaVuSerifFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:919(DejaVuSansFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1244(FontConstantsBase)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1280(ComputerModernFontConstants)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1291(STIXFontConstants)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1311(DejaVuSansFontConstants)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1352(MathTextWarning)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1355(Node)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1385(Box)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1411(Vbox)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1418(Hbox)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1503(Accent)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1594(Hlist)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1779(Rule)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1807(Vrule)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1849(GlueSpec)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1897(NegFil)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1901(NegFill)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1905(NegFilll)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1909(SsGlue)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1913(HCentered)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1922(VCentered)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1959(SubSuperCluster)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:2010(AutoWidthChar)\n",
       "        1    0.000    0.000    0.000    0.000 dviread.py:580(Vf)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1963(_Base)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2012(Square)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2041(Circle)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2063(LArrow)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2101(RArrow)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2116(DArrow)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2166(Round)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2281(Sawtooth)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2379(Roundtooth)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2700(SimpleEvent)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2779(Arc3)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2815(Angle3)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2853(Angle)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3355(Curve)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3364(CurveA)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3383(CurveB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3402(CurveAB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3421(CurveFilledA)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3441(CurveFilledB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3481(_Bracket)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3592(BracketA)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3636(BarAB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3664(Simple)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3747(Fancy)\n",
       "        1    0.000    0.000    0.000    0.000 bezier.py:11(NonIntersectingPathException)\n",
       "        1    0.000    0.000    0.000    0.000 font_manager.py:284(FontEntry)\n",
       "        1    0.000    0.000    0.000    0.000 font_manager.py:832(JSONEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 font_manager.py:901(TempCache)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:305(IndexFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:327(NullFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:338(FixedFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:391(FormatStrFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:410(StrMethodFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:431(OldScalarFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1043(LogFormatterExponent)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1059(LogFormatterMathtext)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1124(LogFormatterSciNotation)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1144(LogitFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1498(IndexLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1527(FixedLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1571(NullLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1591(LinearLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2256(SymmetricalLogLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2429(LogitLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2541(AutoMinorLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2604(OldAutoLocator)\n",
       "        1    0.000    0.000    0.000    0.000 contour.py:37(ClabelText)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1091(StarPolygonCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1098(AsteriskPolygonCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1658(PatchCollection)\n",
       "        3    0.000    0.000    0.000    0.000 _cm.py:96(get_color_function)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2563(BboxTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2611(BboxTransformTo)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2654(BboxTransformToMaxOnly)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2715(ScaledTranslation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2747(TransformedPath)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:275(_ColorbarLogLocator)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:1485(ColorbarPatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyplot.py:92(_NotIPython)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:781(ListedColormap)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:997(LogNorm)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:1186(PowerNorm)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:1252(BoundaryNorm)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5832(_lazyclassproperty)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5867(Latin1)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5872(Greek)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5888(Kanji)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5894(Katakana)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5885(Japanese)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5907(Arabic)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5910(Hebrew)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5913(Devanagari)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:20(ModeDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(FFIError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:5(CDefError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:20(VerificationMissing)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:72(BaseType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:88(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:85(VoidType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:178(UnknownIntegerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:204(BaseFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:224(RawFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:239(FunctionPtrType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:261(PointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:278(ConstPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:284(NamedPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:297(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:293(ArrayType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:324(StructOrUnionOrEnum)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:341(StructOrUnion)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:475(StructType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:479(UnionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:483(EnumType)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:96(WeightedRandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:126(BatchSampler)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:7(DistributedSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:8(Dataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:26(TensorDataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:90(Subset)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:39(ExceptionWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:86(ManagerWatchdog)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:40(DecompressionBombWarning)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:48(_imaging_not_installed)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:479(_E)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2282(ImagePointHandler)\n",
       "        2    0.000    0.000    0.000    0.000 Image.py:2798(register_save_all)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:26(tqdm_gui)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:25(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:57(Bottleneck)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:96(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:24(VGG)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:17(Fire)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:33(Inception3)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:130(InceptionA)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:224(InceptionD)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:250(InceptionE)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:147(_DenseBlock)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:155(_Transition)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:165(DenseNet)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:59(LSUN)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:23(SequentialSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:40(RandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:110(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:123(GeneralProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:135(SOCKS5Error)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:139(SOCKS4Error)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:267(_BaseSocket)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:40(TqdmKeyError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:44(TqdmWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:62(TqdmDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:67(TqdmMonitorWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:95(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:86(TqdmDefaultWriteLock)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:8(TqdmSynchronisationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:123(Semaphore)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:142(BoundedSemaphore)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:159(Lock)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:332(Event)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:165(CookieConflictError)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:174(RequestHooksMixin)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:72(AuthBase)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:79(HTTPBasicAuth)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1222(Absent)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1753(LoadError)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1755(FileCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1841(LWPCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:150(CookieError)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:625(SimpleCookie)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:534(_ZipDecrypter)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:595(LZMACompressor)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:618(LZMADecompressor)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:714(_SharedFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:740(_Tellable)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1819(PyZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:272(_RSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(PKCS1v15)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:62(MGF1)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:32(_X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 scrypt.py:23(Scrypt)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:92(_ECDSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:76(OCSPRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:113(_SingleResponse)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:186(_X509ExtensionParser)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:36(_DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:47(_DSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:68(_DSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2099(GetCipherByName)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:35(BlockCipherAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:76(AEADDecryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:96(Cipher)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:141(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:39(ModeWithTweak)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:48(ModeWithNonce)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:57(ModeWithAuthenticationTag)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:23(_Integers)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:118(_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:239(Error)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:249(WantReadError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:253(WantWriteError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:257(WantX509LookupError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:261(ZeroReturnError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:265(SysCallError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:269(_CallbackExceptionHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:297(_VerifyHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:377(_NpnSelectHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:426(_ALPNSelectHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:477(_OCSPServerCallbackHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:549(_OCSPClientCallbackHelper)\n",
       "        3    0.000    0.000    0.000    0.000 SSL.py:636(_make_requires)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_free}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ERR_clear_error}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_finish}\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:154(_verify_openssl_version)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:46(cryptography_has_ssl3_method)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:42(OCSPExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:104(SHA1)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:111(SHA224)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:118(SHA256)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:125(SHA384)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:132(SHA512)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:139(MD5)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'gc' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:198(BestAvailableEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:207(NoEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:35(UnsupportedGeneralNameType)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:16(IDNAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:21(IDNABidiError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:26(InvalidCodepoint)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4298(Set)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4484(SetOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4534(PrintableString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4543(TeletexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4552(VideotexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4560(IA5String)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4569(AbstractTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4615(UTCTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4671(GeneralizedTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4744(GraphicString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4754(VisibleString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4763(GeneralString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4782(CharacterString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4792(BMPString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:14(TeletexCodec)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:23(TeletexIncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:40(TeletexStreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:120(HmacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:127(DigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:141(DigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:149(DigestInfo)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:156(MaskGenAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:162(MaskGenAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:174(TrailerField)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:381(KdfAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:387(KdfAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:398(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:411(KeyExchangeAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:417(KeyExchangeAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:428(Rc2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:435(Rc5ParamVersion)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:441(Rc5Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:450(Pbes1Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:463(PSourceAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:510(DSASignature)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1104(Pkcs5MacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1129(AnyAlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:622(ValueMap)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:649(Castable)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1572(Primitive)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1776(Boolean)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1829(Integer)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2286(IntegerBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2448(IntegerOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2665(ParsableOctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2940(ObjectDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2956(Real)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3032(UTF8String)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:396(ECPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:407(ECPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:420(DSAParams)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:446(Attributes)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:454(PrivateKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:886(EncryptedPrivateKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:899(ValidationParms)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:910(DomainParameters)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:924(PublicKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:146(Codec)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:292(StreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:295(StreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:39(FFIEngineError)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:43(AlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:852(OCSPNoCheck)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:857(PrecertPoison)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1165(GeneralNames)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:206(ECPoint)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:211(ECPointBitString)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:216(SpecifiedECDomainVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:227(FieldType)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:239(CharacteristicTwoBasis)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:284(FieldID)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:301(Curve)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:145(SECT571R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:151(SECT409R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:157(SECT283R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:163(SECT233R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:169(SECT163R2)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:175(SECT571K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:187(SECT283K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:199(SECT163K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:217(SECP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:223(SECP256K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:235(SECP192R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:253(BrainpoolP512R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:420(ECDH)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:24(UnsupportedAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:34(AlreadyUpdated)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:38(NotYetFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(InternalError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:56(InvalidKey)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:33(HashBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:48(HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:79(PBKDF2HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:183(EllipticCurveBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:51(DuplicateExtension)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:57(ExtensionNotFound)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:73(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:390(CertificateSigningRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:693(RevokedCertificateBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:115(_DeprecatedValue)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:122(_ModuleWithDeprecations)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(AsymmetricVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:36(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:72(MissingSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:76(InvalidSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:92(ChunkedEncodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:100(StreamConsumedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:104(RetryError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:114(RequestsWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:119(FileModeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:54(UnsupportedExtension)\n",
       "        4    0.000    0.000    0.000    0.000 pyopenssl.py:102(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1682(X509StoreContextError)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:16(CryptographyDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:212(EUCJPContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 sbcsgroupprober.py:43(SBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:12(RequestException)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:8(InputState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:32(ProbingState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:41(MachineState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:65(CharacterCategory)\n",
       "        1    0.000    0.000    0.000    0.000 mbcsgroupprober.py:41(MBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:113(EUCTWDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:132(EUCKRDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:151(GB2312DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:170(Big5DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:192(SJISDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:217(EUCJPDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 euckrfreq.py:41(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312freq.py:42(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jisfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:14(is_appengine_sandbox)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:29(is_prod_appengine_mvms)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:55(GzipDecoderState)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:62(GzipDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:93(MultiDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:10(LifoQueue)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:55(ProtocolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:66(MaxRetryError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:85(HostChangedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:94(TimeoutStateError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:99(TimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(ReadTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:115(ConnectTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:135(LocationValueError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:161(SubjectAltNameWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:176(InsecurePlatformWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:186(DependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:207(IncompleteRead)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:244(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:65(DummyConnection)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:223(HTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:263(VerifiedHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:5(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:28(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(CUDAModule)\n",
       "        1    0.000    0.000    0.000    0.000 alexnet.py:13(AlexNet)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:8(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:13(HTTPWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:18(PoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:29(RequestError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:45(ProxyError)\n",
       "        2    0.000    0.000    0.000    0.000 constraint_registry.py:83(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraint_registry.py:79(ConstraintRegistry)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:77(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:446(SoftmaxTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:514(LowerCholeskyTransform)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:98(_Boolean)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:106(_IntegerInterval)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:139(_IntegerGreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:155(_Real)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:167(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:163(_GreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:183(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:195(_LessThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:215(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:211(_Interval)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:228(_HalfOpenInterval)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:254(_LowerTriangular)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:277(_PositiveDefinite)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:291(_RealVector)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:105(lazy_property)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:408(TracingCheckError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:549(TracerWarning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:649(CompilationUnit)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:847(OrderedParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:926(ScriptMeta)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1292(TracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1349(TopLevelTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1354(_ConstModuleList)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1384(_ConstSequential)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1465(_disable_tracing)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:102(NotSupportedError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:106(UnsupportedNodeError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:119(FrontendTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:152(SourceContext)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:158(Builder)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:14(Module)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:112(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:150(update_group)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:6(SparseAdam)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:6(Rprop)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:10(_LRScheduler)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:126(StepLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:161(MultiStepLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:198(ExponentialLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:217(CosineAnnealingLR)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:20(StorageWeakRef)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:39(SharedCache)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:40(SpawnContext)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:13(ExportTypes)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:50(Gather)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:78(Scatter)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:29(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:71(reduce_op)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:93(group)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:97(GroupMember)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(dist_backend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:142(reduce_op)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:153(_DistributedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 adadelta.py:6(Adadelta)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:9(_RequiredParameter)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:232(RNN)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:333(LSTM)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:441(GRU)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:537(RNNCellBase)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:585(RNNCell)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:658(LSTMCell)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:736(GRUCell)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:147(SpectralNormLoadStateDictPreHook)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:177(SpectralNormStateDictHook)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:143(UpsamplingNearest2d)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:188(UpsamplingBilinear2d)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:110(Unfold)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:568(AvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:647(FractionalMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:822(_AdaptiveMaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:838(AdaptiveMaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:899(AdaptiveMaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:936(_AdaptiveAvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:1005(AdaptiveAvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:98(BatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:172(BatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:246(BatchNorm3d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:58(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:6(_DropoutNd)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:61(Dropout2d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:105(Dropout3d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:193(FeatureAlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(ConstantPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:75(ConstantPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:166(_ReflectionPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:178(ReflectionPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:220(ReflectionPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:270(_ReplicationPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:321(ReplicationPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:370(ReplicationPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:59(ReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:89(RReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:210(ReLU6)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:551(LogSigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:663(PReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:728(Softsign)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:818(Softmax)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:868(Softmax2d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:12(_Loss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:21(_WeightedLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:213(NLLLoss2d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:370(MSELoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:598(HingeEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:658(MultiLabelMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:773(SoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:907(MultiLabelSoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1188(CTCLoss)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:11(Container)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:29(MaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:151(MaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:231(MaxUnpool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:371(MaxUnpool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:434(_AvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:196(BroadcastingListCls)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:160(flags_frozen)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:187(CuDNNHandle)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:197(CuDNNError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:226(TensorDescriptorArray)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(FilterDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:277(DropoutDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:321(RNNDescriptor)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:444(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:443(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:6(VFModule)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:12(_ConvNd)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:69(Conv1d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:323(Conv3d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:451(_ConvTransposeMixin)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:509(ConvTranspose1d)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:25(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:5(Parameter)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:75(set_detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:12(range)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:24(EventList)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:225(emit_nvtx)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:360(Interval)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:369(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:407(FunctionEventAvg)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:47(enable_grad)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:91(set_grad_enabled)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:242(InplaceFunction)\n",
       "        4    0.000    0.000    0.000    0.000 function.py:273(_iter_filter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:6(Backends)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(THNNCudaBackendStateMixin)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(Function)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:5(VariableMeta)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:61(_HookMixin)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:72(BackwardCFunction)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:79(FunctionMeta)\n",
       "        1    0.000    0.000    0.000    0.000 thnn.py:4(THNNFunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:4(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(FunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:7(RemovableHandle)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:195(cudaStatus)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:200(CudaError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:211(device)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:499(_CudaBase)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:510(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:514(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:518(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:526(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:530(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:32(SourceChangeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:275(TarError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:278(ExtractError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:281(ReadError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:287(StreamError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:290(HeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:296(TruncatedHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:299(EOFHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:302(InvalidHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:305(SubsequentHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:312(_LowLevelFile)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:582(_StreamProxy)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:8(__PrinterOptions)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1489(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1473(mr_class)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:194(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:214(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:28(prepare_multiprocessing_environment)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:6260(__has_singleton)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:291(_fromnxfunction_seq)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:304(_fromnxfunction_args)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:329(_fromnxfunction_allargs)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:95(MaskedArrayFutureWarning)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:166(MAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:174(MaskError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:208(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:796(_DomainCheckInterval)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:829(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(_DomainTan)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:839(_DomainSafeDivide)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:866(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:882(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:876(_DomainGreaterEqual)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:892(_MaskedUFunc)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:902(_MaskedUnaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1124(_DomainedBinaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(_replace_dtype_fields_recursive)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1329(make_mask_descr)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2384(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:14(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:13(RTLD_for_MKL)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:58(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:62(PolyError)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:79(PolyBase)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_typeDict}\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:33(ModuleDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:55(_NoValueType)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:339(PackageLoaderDebug)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:204(dummy_ctype)\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:51(BagObj)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:464(ConverterError)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:472(ConverterLockError)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:480(ConversionWarning)\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:15(DummyArray)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:22(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:115(NoseTester)\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:47(PytestTester)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:446(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:476(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:451(CClass)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:481(ndenumerate)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:531(ndindex)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:653(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:44(LinAlgError)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:317(_DebugResult)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:13(_WritelnDecorator)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:9(_InterruptHandler)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(KnownFailureException)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1212(_Dummy)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1816(IgnoreException)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2817(_unspecified)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:440(_recursive_guard)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:953(FloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:960(LongFloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1122(BoolFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1132(ComplexFloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1161(ComplexFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1168(LongComplexFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1176(_TimelikeFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1234(TimedeltaFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1239(SubArrayFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1249(StructuredVoidFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1286(StructureFormat)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:38(_UnexpectedSuccess)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:128(_BaseTestCaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:137(_AssertRaisesBaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:221(_AssertWarnsContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:278(_CapturingHandler)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:88(_str_eps)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:92(_str_epsneg)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:239(_missing_ctypes)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:683(TooHardError)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:686(AxisError)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:750(_typedict)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:83(ComplexWarning)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1477(_UnboundedCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1500(_FifoCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2386(Token)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2405(NoMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2420(Literal)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2526(CaselessLiteral)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2549(CaselessKeyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2567(CloseMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2628(Word)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2904(QuotedString)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3130(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3112(White)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3163(_PositionToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3170(GoToColumn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3217(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3226(LineEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3246(StringStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3261(StringEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3589(MatchFirst)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3657(Each)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3858(FollowedBy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3960(NotAny)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4076(ZeroOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4107(_NullToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4115(Optional)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4375(_ForwardNoRecurse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4379(TokenConverter)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4488(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4452(Dict)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:4536(postParse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4543(OnlyOnce)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:256(validate_qt4)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:262(validate_qt5)\n",
       "        1    0.000    0.000    0.000    0.000 rcsetup.py:283(validate_nseq_float)\n",
       "        1    0.000    0.000    0.000    0.000 rcsetup.py:309(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 rcsetup.py:308(validate_nseq_int)\n",
       "        1    0.000    0.000    0.000    0.000 rcsetup.py:657(ValidateInterval)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:196(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:292(ParseFatalException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:297(ParseSyntaxException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:316(RecursiveGrammarException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:324(_ParseResultsWithOffset)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:525(checkdep_usetex)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:932(copy)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1264(rc_context)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1424(is_interactive)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:225(silent_list)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:250(IgnoredKeywordWarning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:315(Bunch)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:505(GetRealpathAndStat)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:609(maxdict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1274(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2020(_OrderedSet)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:69(_PaddedFile)\n",
       "        1    0.000    0.000    0.000    0.000 deprecation.py:6(MatplotlibDeprecationWarning)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:103(validate_any)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:24(_Enhance)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:40(Color)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:58(Contrast)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:89(Sharpness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:28(Filter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:43(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:71(RankFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:94(MedianFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:108(MinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:136(ModeFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:153(GaussianBlur)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:167(BoxBlur)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:187(UnsharpMask)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:232(DETAIL)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:241(EDGE_ENHANCE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:277(SHARPEN)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:286(SMOOTH)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:292(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:313(set_level)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:47(DatasetFolder)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:150(ImageFolder)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:155(FashionMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:179(EMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 fakedata.py:6(FakeData)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:31(Compose)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:61(ToTensor)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:82(ToPILImage)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:120(Normalize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:182(Scale)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:192(CenterCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:221(Pad)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:271(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:289(RandomTransforms)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(RandomApply)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:341(RandomOrder)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:352(RandomChoice)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:429(RandomHorizontalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:481(RandomResizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:557(RandomSizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:567(FiveCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:606(TenCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:649(LinearTransformation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:695(ColorJitter)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:767(RandomRotation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:834(RandomAffine)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:984(RandomGrayscale)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:39(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:196(get_start_method)\n",
       "        1    0.000    0.000    0.000    0.000 pathlib.py:777(name)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        1    0.000    0.000    0.000    0.000 random.py:87(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1211(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'pack' of 'Struct' objects}\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:526(get)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1366(_internal_poll)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:337(__members__)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:868(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:98(checkgroup)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:101(checklookbehindgroup)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:287(seek)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:185(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:73(Error)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:113(TypeCheckerWithDefault)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:214(Uint64ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:155(_ModifiedSizer)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:372(_VarintEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:387(_SignedVarintEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:33(basestring)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:28(BaseOldDict)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:337(NFAState)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:24(PatternSyntaxError)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:167(FixerError)\n",
       "        2    0.000    0.000    0.000    0.000 tokenize.py:50(maybe)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:39(Error)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:41(EncodeError)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:1056(Default)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:60(Error)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:65(Value)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:51(Error)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2372(Empty)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3064(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3130(LineStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3160(LineEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3850(_MultipleMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3888(OneOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:195(_Constants)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:306(RecursiveGrammarException)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:320(Module_six_moves_urllib_parse)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3165(PkgResourcesDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(PEP440Warning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1107(ExtractionError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1842(EggMetadata)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1860(register_finder)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:29(register_writer_factory)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:16(FPUModeChangeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:9(CData)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:166(ConcatConv2d_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:272(BlendConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:73(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 config.py:36(InlineBackendConfig)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:131(Log10Transform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:138(InvertedLog10Transform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:145(Log2Transform)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:655(_LazyTickList)\n",
       "        1    0.000    0.000    0.000    0.000 trifinder.py:7(TriFinder)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:400(InvalidIndexError)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3021(FormatPercent)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3027(FormatThousands)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3033(FormatMillions)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:65(excel_tab)\n",
       "        1    0.000    0.000    0.000    0.000 category.py:156(UnitData)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1434(MonthLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1534(MinuteLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1554(SecondLocator)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:128(ErrorbarContainer)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:160(StemContainer)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:424(HandlerCircleCollection)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:714(ViewsPositionsBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3284(Show)\n",
       "        5    0.000    0.000    0.000    0.000 texmanager.py:96(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1053(StixSansFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1300(STIXSansFontConstants)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1307(DejaVuSerifFontConstants)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1796(Hrule)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1885(Fil)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1889(Fill)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1973(AutoHeightChar)\n",
       "        1    0.000    0.000    0.000    0.000 dviread.py:711(Tfm)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2228(Round4)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2915(Arc)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3461(CurveFilledAB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3614(BracketB)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2521(AutoLocator)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2821(TransformedPatchPath)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:1338(NoNorm)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5879(Cyrillic)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5882(Chinese)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5897(Korean)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5900(CJK)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5904(Thai)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:16(VerificationError)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:97(BasePrimitiveType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:192(UnknownFloatType)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:44(DecompressionBombError)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2287(ImageTransformHandler)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:25(deferred_error)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:162(InceptionB)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:185(InceptionC)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:292(InceptionAux)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:317(BasicConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:129(SOCKSHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:133(SOCKSHTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:137(SOCKSHTTPSConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:127(ProxyConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:131(SOCKS5AuthError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:143(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:36(TqdmTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:57(TqdmExperimentalWarning)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:184(RLock)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:100(HTTPProxyAuth)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:43(BadZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:47(LargeZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:49(OAEP)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:124(ECB)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:336(_NpnAdvertiseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:673(Session)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.RAND_cleanup}\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:135(cryptography_has_ssl_st)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:151(cryptography_has_locking_callbacks)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:193(KeySerializationEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 package_data.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:31(InvalidCodepointContext)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4517(EmbeddedPdv)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4525(NumericString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:35(TeletexStreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:365(Pbkdf2Salt)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:457(PSourceAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1084(Pbes2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1091(Pbmac1Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1098(Pkcs5MacId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1119(AnyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2948(InstanceOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3041(RelativeOid)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:218(IncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:253(IncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:30(LibraryNotFoundError)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:66(OtherPrimeInfos)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:105(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:88(EllipticCurvePrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:181(SECT409K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:193(SECT233K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:205(SECP521R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:211(SECP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:229(SECP224R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:241(BrainpoolP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:247(BrainpoolP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:30(AlreadyFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:42(InvalidTag)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:46(InvalidSignature)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:79(InterfaceNotImplemented)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:44(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:53(ConnectTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:60(ReadTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:64(URLRequired)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:68(TooManyRedirects)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:80(InvalidURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:84(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:88(InvalidProxyURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:96(ContentDecodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:124(RequestsDependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:28(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:32(ConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:120(NewConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:125(EmptyPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:130(ClosedPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:140(LocationParseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:150(ResponseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:156(SecurityWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:166(InsecureRequestWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:171(SystemTimeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:181(SNIMissingWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:194(ResponseNotChunked)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:199(BodyNotHttplibCompatible)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:223(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:228(ProxySchemeUnknown)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:237(HeaderParsingError)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:13(NoWayToWaitForSocketError)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:67(_Dependent)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:80(_DependentProperty)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:123(_IntegerLessThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:245(_Simplex)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:263(_LowerCholesky)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:90(FrontendError)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:120(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:45(DupFd)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:149(group)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:502(AvgPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:863(AdaptiveMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:210(InstanceNorm3d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:130(ConstantPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:282(ReplicationPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:406(ZeroPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:754(Tanhshrink)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:222(_MaxUnpoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:431(StringTable)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:497(EnforceUnique)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:249(_nested_map)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(Argument)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:10(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:130(DeferredCudaCallError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:237(device_of)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:522(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:534(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:538(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:284(CompressionError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:293(EmptyHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:716(ExFileObject)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:68(_Formatter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:198(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:202(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:206(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:218(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:222(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:860(_DomainGreater)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:66(PolyDomainError)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:45(VisibleDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:351(RClass)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:609(IndexExpression)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:99(skipif)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1109(IntegerFormat)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:25(SkipTest)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:33(_ShouldStop)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2394(Empty)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3450(_ErrorStop)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3887(PrecededBy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4041(OneOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4431(Group)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:168(validate_string_or_None)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:271(ParseException)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1784(TimeoutError)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:1876(_str_equal)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:74(Brightness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:32(MultibandFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:36(BuiltinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:122(MaxFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:212(BLUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:223(CONTOUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:250(EDGE_ENHANCE_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:259(EMBOSS)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:268(FIND_EDGES)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:295(SMOOTH_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:491(checkdep_ps_distiller)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:136(_get_args)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:595(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:743(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:213(setstate)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_cifar10_bs8K_rl_stdlearnscale_15_run2 --resume ../experiments_published/cnf_cifar10_bs8K_rl_stdlearnscale_15_run2/epoch_200_checkpt.pth --seed 2 --conditional False --lr 0.001 --warmup_iters 1000 --atol 1e-4  --rtol 1e-4 --scale_fac 1.0 --gate cnn2 --scale_std 15.0 --max_grad_norm 10.0\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
