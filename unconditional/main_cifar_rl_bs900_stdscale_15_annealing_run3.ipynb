{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=True, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=False, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.0, eta=0.1, gamma=0.99, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume=None, rl_weight=0.01, rtol=1e-05, save='../experiments_published/cnf_cifar10_bs900_rl_stdscale_15_annealing_run3', scale=1.0, scale_fac=1.0, scale_std=15.0, seed=3, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1450732\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 0010 | Time 11.6831(31.3754) | Bit/dim 8.7878(8.9815) | Xent 0.0000(0.0000) | Loss 18.4827(18.5225) | Error 0.0000(0.0000) Steps 472(434.42) | Grad Norm 18.0980(27.3404) | Total Time 0.00(0.00)\n",
      "Iter 0020 | Time 11.4106(26.1879) | Bit/dim 8.5197(8.8913) | Xent 0.0000(0.0000) | Loss 17.6605(18.3608) | Error 0.0000(0.0000) Steps 430(435.71) | Grad Norm 8.5127(23.0497) | Total Time 0.00(0.00)\n",
      "Iter 0030 | Time 10.6053(22.2983) | Bit/dim 8.4063(8.7659) | Xent 0.0000(0.0000) | Loss 17.3600(18.1208) | Error 0.0000(0.0000) Steps 424(436.61) | Grad Norm 6.8197(18.9780) | Total Time 0.00(0.00)\n",
      "Iter 0040 | Time 12.6250(19.4901) | Bit/dim 8.0807(8.6202) | Xent 0.0000(0.0000) | Loss 16.9819(17.8574) | Error 0.0000(0.0000) Steps 430(436.98) | Grad Norm 5.0085(15.3485) | Total Time 0.00(0.00)\n",
      "Iter 0050 | Time 11.2983(17.4847) | Bit/dim 7.8753(8.4522) | Xent 0.0000(0.0000) | Loss 16.1862(17.5527) | Error 0.0000(0.0000) Steps 430(442.94) | Grad Norm 4.8900(12.6018) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 70.5131, Epoch Time 755.4467(755.4467), Bit/dim 7.7071(best: inf), Xent 0.0000, Loss 7.7071, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0060 | Time 11.7934(15.9864) | Bit/dim 7.6000(8.2606) | Xent 0.0000(0.0000) | Loss 15.9534(17.6508) | Error 0.0000(0.0000) Steps 466(443.02) | Grad Norm 4.5125(10.5475) | Total Time 0.00(0.00)\n",
      "Iter 0070 | Time 11.9903(14.9085) | Bit/dim 7.3307(8.0430) | Xent 0.0000(0.0000) | Loss 15.5109(17.1140) | Error 0.0000(0.0000) Steps 490(447.12) | Grad Norm 3.6041(8.8385) | Total Time 0.00(0.00)\n",
      "Iter 0080 | Time 11.5250(14.1286) | Bit/dim 7.1519(7.8258) | Xent 0.0000(0.0000) | Loss 15.0063(16.6058) | Error 0.0000(0.0000) Steps 448(451.28) | Grad Norm 2.2113(7.2079) | Total Time 0.00(0.00)\n",
      "Iter 0090 | Time 11.9591(13.6039) | Bit/dim 7.0693(7.6332) | Xent 0.0000(0.0000) | Loss 14.8855(16.1716) | Error 0.0000(0.0000) Steps 466(453.89) | Grad Norm 1.3641(5.7576) | Total Time 0.00(0.00)\n",
      "Iter 0100 | Time 12.2526(13.2953) | Bit/dim 6.9952(7.4765) | Xent 0.0000(0.0000) | Loss 14.6619(15.8131) | Error 0.0000(0.0000) Steps 448(457.67) | Grad Norm 0.9634(4.5530) | Total Time 0.00(0.00)\n",
      "Iter 0110 | Time 12.4704(13.1015) | Bit/dim 7.0037(7.3518) | Xent 0.0000(0.0000) | Loss 14.7715(15.5294) | Error 0.0000(0.0000) Steps 454(460.69) | Grad Norm 0.9578(3.6273) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 71.1025, Epoch Time 761.2186(755.6198), Bit/dim 6.9840(best: 7.7071), Xent 0.0000, Loss 6.9840, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0120 | Time 13.5092(12.9984) | Bit/dim 6.9426(7.2502) | Xent 0.0000(0.0000) | Loss 14.7433(15.7443) | Error 0.0000(0.0000) Steps 496(465.21) | Grad Norm 1.0210(2.9111) | Total Time 0.00(0.00)\n",
      "Iter 0130 | Time 12.6946(12.8968) | Bit/dim 6.9207(7.1652) | Xent 0.0000(0.0000) | Loss 14.5876(15.4440) | Error 0.0000(0.0000) Steps 496(468.78) | Grad Norm 0.6244(2.3604) | Total Time 0.00(0.00)\n",
      "Iter 0140 | Time 12.7979(12.8464) | Bit/dim 6.8603(7.0907) | Xent 0.0000(0.0000) | Loss 14.2399(15.1802) | Error 0.0000(0.0000) Steps 442(469.14) | Grad Norm 0.6931(1.9451) | Total Time 0.00(0.00)\n",
      "Iter 0150 | Time 13.7004(13.0125) | Bit/dim 6.7560(7.0183) | Xent 0.0000(0.0000) | Loss 14.2971(14.9850) | Error 0.0000(0.0000) Steps 490(474.17) | Grad Norm 0.9307(1.6926) | Total Time 0.00(0.00)\n",
      "Iter 0160 | Time 12.6259(13.0437) | Bit/dim 6.6443(6.9385) | Xent 0.0000(0.0000) | Loss 14.0888(14.7900) | Error 0.0000(0.0000) Steps 502(480.28) | Grad Norm 2.3847(1.6439) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 73.2271, Epoch Time 806.6236(757.1499), Bit/dim 6.5497(best: 6.9840), Xent 0.0000, Loss 6.5497, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0170 | Time 13.4906(13.1237) | Bit/dim 6.4821(6.8357) | Xent 0.0000(0.0000) | Loss 13.5850(15.0169) | Error 0.0000(0.0000) Steps 490(483.29) | Grad Norm 27.2269(3.6174) | Total Time 0.00(0.00)\n",
      "Iter 0180 | Time 13.6452(13.2303) | Bit/dim 6.2812(6.7101) | Xent 0.0000(0.0000) | Loss 13.4015(14.6282) | Error 0.0000(0.0000) Steps 478(486.70) | Grad Norm 57.6384(12.2487) | Total Time 0.00(0.00)\n",
      "Iter 0190 | Time 14.3077(13.3072) | Bit/dim 5.9921(6.5498) | Xent 0.0000(0.0000) | Loss 12.8014(14.2026) | Error 0.0000(0.0000) Steps 496(491.41) | Grad Norm 47.4934(20.7160) | Total Time 0.00(0.00)\n",
      "Iter 0200 | Time 13.0818(13.2504) | Bit/dim 5.8079(6.3726) | Xent 0.0000(0.0000) | Loss 12.4964(13.7590) | Error 0.0000(0.0000) Steps 490(493.29) | Grad Norm 32.0052(24.4232) | Total Time 0.00(0.00)\n",
      "Iter 0210 | Time 13.6578(13.2934) | Bit/dim 5.7271(6.2066) | Xent 0.0000(0.0000) | Loss 12.3129(13.3545) | Error 0.0000(0.0000) Steps 508(496.89) | Grad Norm 18.7997(22.2839) | Total Time 0.00(0.00)\n",
      "Iter 0220 | Time 13.1851(13.3277) | Bit/dim 5.6389(6.0674) | Xent 0.0000(0.0000) | Loss 12.0010(13.0409) | Error 0.0000(0.0000) Steps 514(499.88) | Grad Norm 9.7436(18.5418) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 73.5721, Epoch Time 830.1234(759.3391), Bit/dim 5.6370(best: 6.5497), Xent 0.0000, Loss 5.6370, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0230 | Time 12.9017(13.2948) | Bit/dim 5.6405(5.9498) | Xent 0.0000(0.0000) | Loss 12.0684(13.1912) | Error 0.0000(0.0000) Steps 502(499.25) | Grad Norm 5.7599(16.1824) | Total Time 0.00(0.00)\n",
      "Iter 0240 | Time 13.2098(13.3012) | Bit/dim 5.7069(5.8593) | Xent 0.0000(0.0000) | Loss 11.9023(12.8636) | Error 0.0000(0.0000) Steps 448(498.25) | Grad Norm 88.5506(19.4959) | Total Time 0.00(0.00)\n",
      "Iter 0250 | Time 13.6101(13.3790) | Bit/dim 5.5641(5.7892) | Xent 0.0000(0.0000) | Loss 12.0245(12.6424) | Error 0.0000(0.0000) Steps 508(497.38) | Grad Norm 7.5627(20.8845) | Total Time 0.00(0.00)\n",
      "Iter 0260 | Time 13.2913(13.3910) | Bit/dim 5.5071(5.7243) | Xent 0.0000(0.0000) | Loss 11.9214(12.4508) | Error 0.0000(0.0000) Steps 532(499.22) | Grad Norm 6.1657(18.2965) | Total Time 0.00(0.00)\n",
      "Iter 0270 | Time 13.5673(13.4024) | Bit/dim 5.4721(5.6645) | Xent 0.0000(0.0000) | Loss 11.7539(12.2729) | Error 0.0000(0.0000) Steps 502(499.66) | Grad Norm 5.7300(14.8585) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 75.3806, Epoch Time 833.5757(761.5662), Bit/dim 5.4605(best: 5.6370), Xent 0.0000, Loss 5.4605, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0280 | Time 13.4227(13.4838) | Bit/dim 5.4510(5.6107) | Xent 0.0000(0.0000) | Loss 11.8221(12.6385) | Error 0.0000(0.0000) Steps 532(504.18) | Grad Norm 9.1475(12.5184) | Total Time 0.00(0.00)\n",
      "Iter 0290 | Time 13.6615(13.5138) | Bit/dim 5.3995(5.5615) | Xent 0.0000(0.0000) | Loss 11.4437(12.3766) | Error 0.0000(0.0000) Steps 520(505.00) | Grad Norm 6.4471(13.9524) | Total Time 0.00(0.00)\n",
      "Iter 0300 | Time 13.2377(13.5588) | Bit/dim 5.3928(5.5116) | Xent 0.0000(0.0000) | Loss 11.5588(12.1533) | Error 0.0000(0.0000) Steps 526(506.17) | Grad Norm 31.5546(14.6094) | Total Time 0.00(0.00)\n",
      "Iter 0310 | Time 14.2656(13.5984) | Bit/dim 5.3419(5.4643) | Xent 0.0000(0.0000) | Loss 11.4563(11.9814) | Error 0.0000(0.0000) Steps 508(509.04) | Grad Norm 5.7807(15.2547) | Total Time 0.00(0.00)\n",
      "Iter 0320 | Time 13.8567(13.6601) | Bit/dim 5.2770(5.4157) | Xent 0.0000(0.0000) | Loss 11.3644(11.8290) | Error 0.0000(0.0000) Steps 520(512.72) | Grad Norm 16.9610(14.5811) | Total Time 0.00(0.00)\n",
      "Iter 0330 | Time 13.0465(13.7715) | Bit/dim 5.2522(5.3683) | Xent 0.0000(0.0000) | Loss 11.2296(11.6927) | Error 0.0000(0.0000) Steps 502(513.47) | Grad Norm 29.4365(13.9910) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 78.5295, Epoch Time 856.3792(764.4106), Bit/dim 5.2476(best: 5.4605), Xent 0.0000, Loss 5.2476, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0340 | Time 14.5064(13.8424) | Bit/dim 5.1679(5.3287) | Xent 0.0000(0.0000) | Loss 11.1483(12.0273) | Error 0.0000(0.0000) Steps 526(515.36) | Grad Norm 16.0903(15.4950) | Total Time 0.00(0.00)\n",
      "Iter 0350 | Time 13.5230(13.8701) | Bit/dim 5.1689(5.2954) | Xent 0.0000(0.0000) | Loss 11.1640(11.8234) | Error 0.0000(0.0000) Steps 520(516.58) | Grad Norm 10.2370(17.3385) | Total Time 0.00(0.00)\n",
      "Iter 0360 | Time 13.4840(13.8328) | Bit/dim 5.1424(5.2576) | Xent 0.0000(0.0000) | Loss 11.0337(11.6367) | Error 0.0000(0.0000) Steps 496(514.41) | Grad Norm 11.9050(15.8356) | Total Time 0.00(0.00)\n",
      "Iter 0370 | Time 14.0767(13.8341) | Bit/dim 5.1070(5.2185) | Xent 0.0000(0.0000) | Loss 10.9907(11.4864) | Error 0.0000(0.0000) Steps 496(512.98) | Grad Norm 12.6205(14.8914) | Total Time 0.00(0.00)\n",
      "Iter 0380 | Time 13.5764(13.8267) | Bit/dim 5.0424(5.1783) | Xent 0.0000(0.0000) | Loss 10.8717(11.3350) | Error 0.0000(0.0000) Steps 496(510.20) | Grad Norm 4.4060(13.7162) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 76.8314, Epoch Time 859.6002(767.2663), Bit/dim 5.0237(best: 5.2476), Xent 0.0000, Loss 5.0237, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0390 | Time 14.6102(13.8880) | Bit/dim 5.0457(5.1404) | Xent 0.0000(0.0000) | Loss 10.9670(11.7296) | Error 0.0000(0.0000) Steps 544(513.82) | Grad Norm 8.4795(13.6807) | Total Time 0.00(0.00)\n",
      "Iter 0400 | Time 14.5070(13.9021) | Bit/dim 5.0755(5.1057) | Xent 0.0000(0.0000) | Loss 10.9397(11.4862) | Error 0.0000(0.0000) Steps 526(515.13) | Grad Norm 58.8124(16.0580) | Total Time 0.00(0.00)\n",
      "Iter 0410 | Time 13.9773(14.0681) | Bit/dim 4.9591(5.0883) | Xent 0.0000(0.0000) | Loss 10.8076(11.3401) | Error 0.0000(0.0000) Steps 532(518.57) | Grad Norm 9.5183(20.4746) | Total Time 0.00(0.00)\n",
      "Iter 0420 | Time 14.5945(14.2834) | Bit/dim 4.9515(5.0597) | Xent 0.0000(0.0000) | Loss 10.6734(11.1972) | Error 0.0000(0.0000) Steps 532(523.05) | Grad Norm 30.6968(21.0164) | Total Time 0.00(0.00)\n",
      "Iter 0430 | Time 14.6601(14.4515) | Bit/dim 4.8840(5.0217) | Xent 0.0000(0.0000) | Loss 10.5182(11.0523) | Error 0.0000(0.0000) Steps 526(527.22) | Grad Norm 8.1072(19.1539) | Total Time 0.00(0.00)\n",
      "Iter 0440 | Time 15.2754(14.5804) | Bit/dim 4.8600(4.9819) | Xent 0.0000(0.0000) | Loss 10.6037(10.9324) | Error 0.0000(0.0000) Steps 538(532.29) | Grad Norm 12.3835(16.7282) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 79.8734, Epoch Time 903.2137(771.3447), Bit/dim 4.8601(best: 5.0237), Xent 0.0000, Loss 4.8601, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0450 | Time 15.4923(14.7860) | Bit/dim 4.8502(4.9477) | Xent 0.0000(0.0000) | Loss 10.6845(11.2748) | Error 0.0000(0.0000) Steps 556(534.14) | Grad Norm 9.8331(16.0953) | Total Time 0.00(0.00)\n",
      "Iter 0460 | Time 14.5190(14.8384) | Bit/dim 4.7952(4.9126) | Xent 0.0000(0.0000) | Loss 10.4665(11.0600) | Error 0.0000(0.0000) Steps 532(533.60) | Grad Norm 8.7538(13.8994) | Total Time 0.00(0.00)\n",
      "Iter 0470 | Time 15.7636(14.8955) | Bit/dim 5.2195(4.9082) | Xent 0.0000(0.0000) | Loss 11.3826(10.9463) | Error 0.0000(0.0000) Steps 568(536.07) | Grad Norm 118.9114(20.3125) | Total Time 0.00(0.00)\n",
      "Iter 0480 | Time 14.6672(14.9673) | Bit/dim 5.0264(4.9542) | Xent 0.0000(0.0000) | Loss 10.8465(10.9735) | Error 0.0000(0.0000) Steps 562(537.56) | Grad Norm 15.2950(22.1142) | Total Time 0.00(0.00)\n",
      "Iter 0490 | Time 15.0378(14.9175) | Bit/dim 4.8223(4.9363) | Xent 0.0000(0.0000) | Loss 10.3998(10.8661) | Error 0.0000(0.0000) Steps 520(534.45) | Grad Norm 4.8182(18.8714) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 78.0477, Epoch Time 927.3028(776.0235), Bit/dim 4.7979(best: 4.8601), Xent 0.0000, Loss 4.7979, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0500 | Time 14.2230(14.9746) | Bit/dim 4.7774(4.9021) | Xent 0.0000(0.0000) | Loss 10.2582(11.2606) | Error 0.0000(0.0000) Steps 538(532.00) | Grad Norm 4.5027(16.3469) | Total Time 0.00(0.00)\n",
      "Iter 0510 | Time 15.3881(14.9522) | Bit/dim 4.7087(4.8626) | Xent 0.0000(0.0000) | Loss 10.0895(11.0083) | Error 0.0000(0.0000) Steps 526(529.35) | Grad Norm 9.8076(15.6296) | Total Time 0.00(0.00)\n",
      "Iter 0520 | Time 15.1479(15.0088) | Bit/dim 4.7208(4.8283) | Xent 0.0000(0.0000) | Loss 10.1870(10.8246) | Error 0.0000(0.0000) Steps 520(529.55) | Grad Norm 11.7110(15.1527) | Total Time 0.00(0.00)\n",
      "Iter 0530 | Time 15.5125(15.0827) | Bit/dim 4.6881(4.7947) | Xent 0.0000(0.0000) | Loss 10.2949(10.6808) | Error 0.0000(0.0000) Steps 544(527.89) | Grad Norm 5.4330(13.9493) | Total Time 0.00(0.00)\n",
      "Iter 0540 | Time 15.0457(15.0513) | Bit/dim 4.6500(4.7651) | Xent 0.0000(0.0000) | Loss 10.1368(10.5575) | Error 0.0000(0.0000) Steps 532(530.79) | Grad Norm 7.1155(13.1043) | Total Time 0.00(0.00)\n",
      "Iter 0550 | Time 14.6380(15.1035) | Bit/dim 4.6923(4.7419) | Xent 0.0000(0.0000) | Loss 10.1515(10.4729) | Error 0.0000(0.0000) Steps 538(531.72) | Grad Norm 24.0285(13.4415) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 80.1092, Epoch Time 931.0987(780.6757), Bit/dim 4.6622(best: 4.7979), Xent 0.0000, Loss 4.6622, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0560 | Time 15.3222(15.1089) | Bit/dim 4.6361(4.7206) | Xent 0.0000(0.0000) | Loss 10.1665(10.8658) | Error 0.0000(0.0000) Steps 550(531.48) | Grad Norm 14.8064(13.5259) | Total Time 0.00(0.00)\n",
      "Iter 0570 | Time 15.2534(15.2127) | Bit/dim 4.7559(4.7135) | Xent 0.0000(0.0000) | Loss 10.4071(10.7163) | Error 0.0000(0.0000) Steps 520(532.99) | Grad Norm 44.3220(17.7523) | Total Time 0.00(0.00)\n",
      "Iter 0580 | Time 14.6533(15.1776) | Bit/dim 4.6360(4.7039) | Xent 0.0000(0.0000) | Loss 9.9858(10.5823) | Error 0.0000(0.0000) Steps 514(534.96) | Grad Norm 25.0032(18.4456) | Total Time 0.00(0.00)\n",
      "Iter 0590 | Time 16.0545(15.2114) | Bit/dim 4.6000(4.6862) | Xent 0.0000(0.0000) | Loss 10.2214(10.4819) | Error 0.0000(0.0000) Steps 586(534.88) | Grad Norm 4.6412(18.0133) | Total Time 0.00(0.00)\n",
      "Iter 0600 | Time 14.0713(15.1081) | Bit/dim 4.6189(4.6726) | Xent 0.0000(0.0000) | Loss 10.0677(10.4017) | Error 0.0000(0.0000) Steps 520(532.73) | Grad Norm 17.8875(19.0353) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 79.2829, Epoch Time 932.2044(785.2216), Bit/dim 4.6105(best: 4.6622), Xent 0.0000, Loss 4.6105, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0610 | Time 15.1574(15.0801) | Bit/dim 4.5865(4.6551) | Xent 0.0000(0.0000) | Loss 10.0837(10.8332) | Error 0.0000(0.0000) Steps 538(532.99) | Grad Norm 20.1789(18.0851) | Total Time 0.00(0.00)\n",
      "Iter 0620 | Time 14.5638(15.1754) | Bit/dim 4.6170(4.6381) | Xent 0.0000(0.0000) | Loss 9.9688(10.6330) | Error 0.0000(0.0000) Steps 508(534.38) | Grad Norm 16.5772(17.0697) | Total Time 0.00(0.00)\n",
      "Iter 0630 | Time 15.4545(15.1268) | Bit/dim 4.6273(4.6311) | Xent 0.0000(0.0000) | Loss 10.3295(10.4931) | Error 0.0000(0.0000) Steps 532(530.94) | Grad Norm 24.9341(19.1540) | Total Time 0.00(0.00)\n",
      "Iter 0640 | Time 15.0195(15.0592) | Bit/dim 4.5699(4.6178) | Xent 0.0000(0.0000) | Loss 9.9908(10.3797) | Error 0.0000(0.0000) Steps 538(531.92) | Grad Norm 7.5341(17.4245) | Total Time 0.00(0.00)\n",
      "Iter 0650 | Time 14.6018(15.0906) | Bit/dim 4.5568(4.6030) | Xent 0.0000(0.0000) | Loss 10.0318(10.2882) | Error 0.0000(0.0000) Steps 526(531.32) | Grad Norm 9.4995(15.7068) | Total Time 0.00(0.00)\n",
      "Iter 0660 | Time 15.1573(15.0514) | Bit/dim 4.5199(4.5863) | Xent 0.0000(0.0000) | Loss 9.9513(10.1910) | Error 0.0000(0.0000) Steps 586(532.97) | Grad Norm 12.5474(13.8208) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 80.8775, Epoch Time 931.6829(789.6154), Bit/dim 4.5229(best: 4.6105), Xent 0.0000, Loss 4.5229, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0670 | Time 14.4815(15.0623) | Bit/dim 4.5066(4.5697) | Xent 0.0000(0.0000) | Loss 9.9337(10.5795) | Error 0.0000(0.0000) Steps 532(535.48) | Grad Norm 4.5525(13.3107) | Total Time 0.00(0.00)\n",
      "Iter 0680 | Time 15.3931(15.0234) | Bit/dim 4.5053(4.5523) | Xent 0.0000(0.0000) | Loss 9.9846(10.3970) | Error 0.0000(0.0000) Steps 568(535.95) | Grad Norm 16.4893(13.2485) | Total Time 0.00(0.00)\n",
      "Iter 0690 | Time 15.5732(15.0646) | Bit/dim 4.4844(4.5365) | Xent 0.0000(0.0000) | Loss 9.9460(10.2721) | Error 0.0000(0.0000) Steps 556(538.86) | Grad Norm 25.9569(14.3280) | Total Time 0.00(0.00)\n",
      "Iter 0700 | Time 15.0734(15.1054) | Bit/dim 4.5024(4.5216) | Xent 0.0000(0.0000) | Loss 9.9411(10.1589) | Error 0.0000(0.0000) Steps 538(540.20) | Grad Norm 19.4850(13.9423) | Total Time 0.00(0.00)\n",
      "Iter 0710 | Time 15.1225(15.0922) | Bit/dim 4.4948(4.5252) | Xent 0.0000(0.0000) | Loss 9.9099(10.1119) | Error 0.0000(0.0000) Steps 532(540.52) | Grad Norm 14.6244(17.1654) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 79.1267, Epoch Time 929.3648(793.8079), Bit/dim 4.4953(best: 4.5229), Xent 0.0000, Loss 4.4953, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0720 | Time 14.5649(15.0157) | Bit/dim 4.4744(4.5153) | Xent 0.0000(0.0000) | Loss 9.7186(10.5727) | Error 0.0000(0.0000) Steps 538(539.61) | Grad Norm 11.8991(17.0408) | Total Time 0.00(0.00)\n",
      "Iter 0730 | Time 15.7214(15.1539) | Bit/dim 4.4336(4.4980) | Xent 0.0000(0.0000) | Loss 9.7795(10.3702) | Error 0.0000(0.0000) Steps 556(541.19) | Grad Norm 7.5980(14.8807) | Total Time 0.00(0.00)\n",
      "Iter 0740 | Time 14.3994(15.0829) | Bit/dim 4.3871(4.4779) | Xent 0.0000(0.0000) | Loss 9.4920(10.1893) | Error 0.0000(0.0000) Steps 556(538.18) | Grad Norm 3.9913(12.8067) | Total Time 0.00(0.00)\n",
      "Iter 0750 | Time 14.0807(15.0536) | Bit/dim 5.7348(4.5602) | Xent 0.0000(0.0000) | Loss 12.2938(10.2490) | Error 0.0000(0.0000) Steps 514(538.58) | Grad Norm 39.7570(19.1844) | Total Time 0.00(0.00)\n",
      "Iter 0760 | Time 16.1258(15.3066) | Bit/dim 4.7627(4.6627) | Xent 0.0000(0.0000) | Loss 10.3899(10.4214) | Error 0.0000(0.0000) Steps 574(548.57) | Grad Norm 6.4815(17.7077) | Total Time 0.00(0.00)\n",
      "Iter 0770 | Time 16.1824(15.4031) | Bit/dim 4.5651(4.6613) | Xent 0.0000(0.0000) | Loss 10.0981(10.3859) | Error 0.0000(0.0000) Steps 550(555.78) | Grad Norm 4.6461(14.4696) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 81.5085, Epoch Time 945.6458(798.3631), Bit/dim 4.5560(best: 4.4953), Xent 0.0000, Loss 4.5560, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0780 | Time 14.5634(15.1805) | Bit/dim 4.4948(4.6261) | Xent 0.0000(0.0000) | Loss 9.6403(10.7643) | Error 0.0000(0.0000) Steps 490(548.40) | Grad Norm 2.9925(11.5868) | Total Time 0.00(0.00)\n",
      "Iter 0790 | Time 13.4951(14.9341) | Bit/dim 4.4548(4.5818) | Xent 0.0000(0.0000) | Loss 9.6360(10.4905) | Error 0.0000(0.0000) Steps 508(535.49) | Grad Norm 4.7338(9.5682) | Total Time 0.00(0.00)\n",
      "Iter 0800 | Time 14.2235(14.7103) | Bit/dim 4.4149(4.5404) | Xent 0.0000(0.0000) | Loss 9.6630(10.2679) | Error 0.0000(0.0000) Steps 478(526.93) | Grad Norm 1.9411(7.6526) | Total Time 0.00(0.00)\n",
      "Iter 0810 | Time 13.9675(14.5875) | Bit/dim 4.3979(4.5047) | Xent 0.0000(0.0000) | Loss 9.5188(10.1001) | Error 0.0000(0.0000) Steps 538(523.80) | Grad Norm 1.3463(6.3738) | Total Time 0.00(0.00)\n",
      "Iter 0820 | Time 14.0158(14.5431) | Bit/dim 4.4157(4.4754) | Xent 0.0000(0.0000) | Loss 9.5504(9.9797) | Error 0.0000(0.0000) Steps 472(520.98) | Grad Norm 6.6658(6.0725) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 78.8208, Epoch Time 887.4935(801.0370), Bit/dim 4.3684(best: 4.4953), Xent 0.0000, Loss 4.3684, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0830 | Time 14.2629(14.5294) | Bit/dim 4.3518(4.4457) | Xent 0.0000(0.0000) | Loss 9.5333(10.3827) | Error 0.0000(0.0000) Steps 496(521.42) | Grad Norm 6.6938(5.5012) | Total Time 0.00(0.00)\n",
      "Iter 0840 | Time 14.4416(14.5693) | Bit/dim 4.3755(4.4226) | Xent 0.0000(0.0000) | Loss 9.6150(10.1698) | Error 0.0000(0.0000) Steps 526(522.27) | Grad Norm 15.4756(5.3259) | Total Time 0.00(0.00)\n",
      "Iter 0850 | Time 14.0666(14.5095) | Bit/dim 4.3377(4.4087) | Xent 0.0000(0.0000) | Loss 9.5209(10.0181) | Error 0.0000(0.0000) Steps 508(520.05) | Grad Norm 3.6276(7.8357) | Total Time 0.00(0.00)\n",
      "Iter 0860 | Time 14.4447(14.5514) | Bit/dim 4.3171(4.3892) | Xent 0.0000(0.0000) | Loss 9.4913(9.8852) | Error 0.0000(0.0000) Steps 526(518.39) | Grad Norm 8.8711(8.2050) | Total Time 0.00(0.00)\n",
      "Iter 0870 | Time 14.6800(14.5490) | Bit/dim 4.2767(4.3675) | Xent 0.0000(0.0000) | Loss 9.3606(9.7700) | Error 0.0000(0.0000) Steps 532(520.76) | Grad Norm 6.7413(8.7764) | Total Time 0.00(0.00)\n",
      "Iter 0880 | Time 14.6003(14.6183) | Bit/dim 4.2718(4.3487) | Xent 0.0000(0.0000) | Loss 9.3739(9.6861) | Error 0.0000(0.0000) Steps 538(522.71) | Grad Norm 9.5099(8.0336) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 78.8683, Epoch Time 902.2004(804.0719), Bit/dim 4.2844(best: 4.3684), Xent 0.0000, Loss 4.2844, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0890 | Time 15.4012(14.7120) | Bit/dim 4.2756(4.3346) | Xent 0.0000(0.0000) | Loss 9.5363(10.0486) | Error 0.0000(0.0000) Steps 562(524.05) | Grad Norm 13.4244(9.7078) | Total Time 0.00(0.00)\n",
      "Iter 0900 | Time 14.7293(14.7187) | Bit/dim 4.2889(4.3204) | Xent 0.0000(0.0000) | Loss 9.3062(9.8797) | Error 0.0000(0.0000) Steps 544(526.50) | Grad Norm 5.9021(9.8753) | Total Time 0.00(0.00)\n",
      "Iter 0910 | Time 14.6729(14.7857) | Bit/dim 4.2049(4.3002) | Xent 0.0000(0.0000) | Loss 9.1689(9.7329) | Error 0.0000(0.0000) Steps 484(523.16) | Grad Norm 8.1130(9.2453) | Total Time 0.00(0.00)\n",
      "Iter 0920 | Time 15.8913(14.8868) | Bit/dim 4.4841(4.3163) | Xent 0.0000(0.0000) | Loss 9.7903(9.6999) | Error 0.0000(0.0000) Steps 580(524.58) | Grad Norm 27.6883(13.2704) | Total Time 0.00(0.00)\n",
      "Iter 0930 | Time 14.9585(14.8252) | Bit/dim 4.3041(4.3236) | Xent 0.0000(0.0000) | Loss 9.4458(9.6638) | Error 0.0000(0.0000) Steps 490(521.90) | Grad Norm 11.4527(13.7053) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 78.0913, Epoch Time 918.2215(807.4964), Bit/dim 4.2512(best: 4.2844), Xent 0.0000, Loss 4.2512, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0940 | Time 15.3959(14.8936) | Bit/dim 4.2488(4.3078) | Xent 0.0000(0.0000) | Loss 9.3445(10.1090) | Error 0.0000(0.0000) Steps 556(523.67) | Grad Norm 5.0895(11.8618) | Total Time 0.00(0.00)\n",
      "Iter 0950 | Time 14.3203(14.8631) | Bit/dim 4.2205(4.2859) | Xent 0.0000(0.0000) | Loss 9.2820(9.9061) | Error 0.0000(0.0000) Steps 496(524.96) | Grad Norm 3.6437(9.8964) | Total Time 0.00(0.00)\n",
      "Iter 0960 | Time 15.0113(14.9460) | Bit/dim 4.1574(4.2603) | Xent 0.0000(0.0000) | Loss 9.1744(9.7261) | Error 0.0000(0.0000) Steps 538(526.12) | Grad Norm 6.5811(8.4179) | Total Time 0.00(0.00)\n",
      "Iter 0970 | Time 15.9068(15.0697) | Bit/dim 4.1927(4.2393) | Xent 0.0000(0.0000) | Loss 9.2013(9.5953) | Error 0.0000(0.0000) Steps 514(527.97) | Grad Norm 18.5112(7.8178) | Total Time 0.00(0.00)\n",
      "Iter 0980 | Time 14.8242(15.0768) | Bit/dim 4.1620(4.2242) | Xent 0.0000(0.0000) | Loss 9.0234(9.4916) | Error 0.0000(0.0000) Steps 538(528.91) | Grad Norm 10.5702(9.4939) | Total Time 0.00(0.00)\n",
      "Iter 0990 | Time 15.6719(15.1413) | Bit/dim 4.1538(4.2073) | Xent 0.0000(0.0000) | Loss 9.1031(9.4014) | Error 0.0000(0.0000) Steps 562(529.83) | Grad Norm 8.3060(9.0269) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 77.9786, Epoch Time 931.6617(811.2213), Bit/dim 4.1429(best: 4.2512), Xent 0.0000, Loss 4.1429, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1000 | Time 15.7041(15.2197) | Bit/dim 4.1477(4.1964) | Xent 0.0000(0.0000) | Loss 9.0663(9.7815) | Error 0.0000(0.0000) Steps 568(534.02) | Grad Norm 12.3908(10.6238) | Total Time 0.00(0.00)\n",
      "Iter 1010 | Time 14.6932(15.1627) | Bit/dim 4.1861(4.1867) | Xent 0.0000(0.0000) | Loss 9.2241(9.6228) | Error 0.0000(0.0000) Steps 538(534.02) | Grad Norm 23.8842(10.8325) | Total Time 0.00(0.00)\n",
      "Iter 1020 | Time 16.1036(15.1751) | Bit/dim 4.1113(4.1761) | Xent 0.0000(0.0000) | Loss 9.1302(9.5040) | Error 0.0000(0.0000) Steps 538(533.54) | Grad Norm 3.6709(10.6555) | Total Time 0.00(0.00)\n",
      "Iter 1030 | Time 15.0387(15.1965) | Bit/dim 4.1178(4.1604) | Xent 0.0000(0.0000) | Loss 9.1344(9.4036) | Error 0.0000(0.0000) Steps 538(534.68) | Grad Norm 14.2601(10.2877) | Total Time 0.00(0.00)\n",
      "Iter 1040 | Time 14.6622(15.1010) | Bit/dim 4.1418(4.1500) | Xent 0.0000(0.0000) | Loss 9.1308(9.3127) | Error 0.0000(0.0000) Steps 538(533.99) | Grad Norm 14.2961(10.9792) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 78.8224, Epoch Time 931.0152(814.8151), Bit/dim 4.1019(best: 4.1429), Xent 0.0000, Loss 4.1019, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1050 | Time 14.7415(15.0655) | Bit/dim 4.0998(4.1326) | Xent 0.0000(0.0000) | Loss 9.0865(9.7319) | Error 0.0000(0.0000) Steps 544(533.26) | Grad Norm 7.6722(10.5078) | Total Time 0.00(0.00)\n",
      "Iter 1060 | Time 15.5329(15.0161) | Bit/dim 4.2005(4.1265) | Xent 0.0000(0.0000) | Loss 9.3896(9.5536) | Error 0.0000(0.0000) Steps 544(531.74) | Grad Norm 28.7627(11.6774) | Total Time 0.00(0.00)\n",
      "Iter 1070 | Time 15.5010(15.0758) | Bit/dim 4.1528(4.1370) | Xent 0.0000(0.0000) | Loss 9.0853(9.4580) | Error 0.0000(0.0000) Steps 550(531.00) | Grad Norm 16.1414(13.9529) | Total Time 0.00(0.00)\n",
      "Iter 1080 | Time 15.0688(15.0768) | Bit/dim 4.1053(4.1297) | Xent 0.0000(0.0000) | Loss 9.0501(9.3599) | Error 0.0000(0.0000) Steps 550(531.61) | Grad Norm 7.2375(13.2727) | Total Time 0.00(0.00)\n",
      "Iter 1090 | Time 15.6863(15.1195) | Bit/dim 4.0476(4.1123) | Xent 0.0000(0.0000) | Loss 9.0096(9.2712) | Error 0.0000(0.0000) Steps 526(534.01) | Grad Norm 5.9335(11.5424) | Total Time 0.00(0.00)\n",
      "Iter 1100 | Time 14.3338(15.1343) | Bit/dim 4.0718(4.1000) | Xent 0.0000(0.0000) | Loss 8.9350(9.1970) | Error 0.0000(0.0000) Steps 520(532.16) | Grad Norm 6.0008(9.9233) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 78.5779, Epoch Time 929.6312(818.2596), Bit/dim 4.0544(best: 4.1019), Xent 0.0000, Loss 4.0544, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1110 | Time 14.4222(15.0427) | Bit/dim 4.0426(4.0864) | Xent 0.0000(0.0000) | Loss 9.0166(9.5724) | Error 0.0000(0.0000) Steps 532(529.09) | Grad Norm 3.8367(9.2428) | Total Time 0.00(0.00)\n",
      "Iter 1120 | Time 15.5555(15.0238) | Bit/dim 4.0563(4.0750) | Xent 0.0000(0.0000) | Loss 8.9416(9.4065) | Error 0.0000(0.0000) Steps 544(529.31) | Grad Norm 10.0672(9.7160) | Total Time 0.00(0.00)\n",
      "Iter 1130 | Time 14.8783(15.0563) | Bit/dim 4.0580(4.0660) | Xent 0.0000(0.0000) | Loss 8.9120(9.2761) | Error 0.0000(0.0000) Steps 526(528.51) | Grad Norm 17.2761(9.7973) | Total Time 0.00(0.00)\n",
      "Iter 1140 | Time 15.6383(15.0744) | Bit/dim 4.0402(4.0566) | Xent 0.0000(0.0000) | Loss 8.9374(9.1817) | Error 0.0000(0.0000) Steps 514(528.44) | Grad Norm 14.8387(9.7636) | Total Time 0.00(0.00)\n",
      "Iter 1150 | Time 15.3345(15.0618) | Bit/dim 4.0048(4.0440) | Xent 0.0000(0.0000) | Loss 8.8275(9.0969) | Error 0.0000(0.0000) Steps 502(528.19) | Grad Norm 7.2056(9.2497) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 78.2296, Epoch Time 926.1321(821.4958), Bit/dim 4.0066(best: 4.0544), Xent 0.0000, Loss 4.0066, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1160 | Time 14.5027(15.0967) | Bit/dim 4.0406(4.0344) | Xent 0.0000(0.0000) | Loss 8.8927(9.5610) | Error 0.0000(0.0000) Steps 514(529.92) | Grad Norm 7.5619(10.1899) | Total Time 0.00(0.00)\n",
      "Iter 1170 | Time 14.7834(14.9836) | Bit/dim 4.0081(4.0311) | Xent 0.0000(0.0000) | Loss 8.8730(9.3829) | Error 0.0000(0.0000) Steps 508(527.84) | Grad Norm 13.9166(10.9656) | Total Time 0.00(0.00)\n",
      "Iter 1180 | Time 15.6396(14.9358) | Bit/dim 4.0019(4.0227) | Xent 0.0000(0.0000) | Loss 8.7970(9.2395) | Error 0.0000(0.0000) Steps 532(527.33) | Grad Norm 5.5985(10.1688) | Total Time 0.00(0.00)\n",
      "Iter 1190 | Time 13.9363(14.8915) | Bit/dim 4.0046(4.0150) | Xent 0.0000(0.0000) | Loss 8.9048(9.1380) | Error 0.0000(0.0000) Steps 526(524.01) | Grad Norm 10.6989(10.2345) | Total Time 0.00(0.00)\n",
      "Iter 1200 | Time 13.4928(14.7790) | Bit/dim 3.9832(4.0078) | Xent 0.0000(0.0000) | Loss 8.7633(9.0604) | Error 0.0000(0.0000) Steps 496(525.29) | Grad Norm 7.4672(9.6665) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 14.4932(14.7070) | Bit/dim 3.9950(4.0001) | Xent 0.0000(0.0000) | Loss 8.8046(8.9981) | Error 0.0000(0.0000) Steps 526(524.95) | Grad Norm 20.8421(9.2278) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 78.3850, Epoch Time 905.7735(824.0241), Bit/dim 4.0481(best: 4.0066), Xent 0.0000, Loss 4.0481, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1220 | Time 15.0220(14.6925) | Bit/dim 3.9973(3.9991) | Xent 0.0000(0.0000) | Loss 8.8587(9.3803) | Error 0.0000(0.0000) Steps 538(525.90) | Grad Norm 12.1368(10.3000) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 15.0069(14.7527) | Bit/dim 3.9653(3.9913) | Xent 0.0000(0.0000) | Loss 8.7388(9.2305) | Error 0.0000(0.0000) Steps 544(528.40) | Grad Norm 6.9341(9.6391) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 15.2076(14.7792) | Bit/dim 3.9432(3.9871) | Xent 0.0000(0.0000) | Loss 8.7801(9.1206) | Error 0.0000(0.0000) Steps 520(528.55) | Grad Norm 5.6856(10.3298) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 14.2955(14.7067) | Bit/dim 3.9848(3.9811) | Xent 0.0000(0.0000) | Loss 8.7945(9.0314) | Error 0.0000(0.0000) Steps 520(526.57) | Grad Norm 10.2870(9.8274) | Total Time 0.00(0.00)\n",
      "Iter 1260 | Time 15.3579(14.7699) | Bit/dim 3.9938(3.9729) | Xent 0.0000(0.0000) | Loss 8.8491(8.9620) | Error 0.0000(0.0000) Steps 568(527.46) | Grad Norm 13.4164(9.2958) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 80.7830, Epoch Time 913.2722(826.7016), Bit/dim 3.9525(best: 4.0066), Xent 0.0000, Loss 3.9525, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1270 | Time 14.0829(14.6984) | Bit/dim 3.9358(3.9701) | Xent 0.0000(0.0000) | Loss 8.7131(9.4366) | Error 0.0000(0.0000) Steps 502(526.11) | Grad Norm 8.1954(9.7860) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 15.1485(14.6632) | Bit/dim 3.9918(3.9659) | Xent 0.0000(0.0000) | Loss 8.8146(9.2654) | Error 0.0000(0.0000) Steps 544(524.49) | Grad Norm 23.1452(10.1481) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 14.4990(14.6905) | Bit/dim 3.9738(3.9629) | Xent 0.0000(0.0000) | Loss 8.7722(9.1377) | Error 0.0000(0.0000) Steps 526(524.35) | Grad Norm 8.5642(10.6040) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 14.2527(14.7038) | Bit/dim 3.9493(3.9564) | Xent 0.0000(0.0000) | Loss 8.8141(9.0378) | Error 0.0000(0.0000) Steps 508(523.90) | Grad Norm 8.4345(10.0684) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 15.3282(14.6995) | Bit/dim 3.9131(3.9474) | Xent 0.0000(0.0000) | Loss 8.7165(8.9496) | Error 0.0000(0.0000) Steps 502(521.04) | Grad Norm 4.9689(9.0339) | Total Time 0.00(0.00)\n",
      "Iter 1320 | Time 14.1150(14.6812) | Bit/dim 3.9135(3.9402) | Xent 0.0000(0.0000) | Loss 8.7334(8.8810) | Error 0.0000(0.0000) Steps 532(521.69) | Grad Norm 13.8594(8.6721) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 79.6447, Epoch Time 905.3187(829.0601), Bit/dim 3.9314(best: 3.9525), Xent 0.0000, Loss 3.9314, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1330 | Time 13.9975(14.7234) | Bit/dim 3.9488(3.9382) | Xent 0.0000(0.0000) | Loss 8.7800(9.2907) | Error 0.0000(0.0000) Steps 556(524.33) | Grad Norm 15.0343(9.6043) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 15.0548(14.7886) | Bit/dim 3.9072(3.9327) | Xent 0.0000(0.0000) | Loss 8.7654(9.1488) | Error 0.0000(0.0000) Steps 532(527.50) | Grad Norm 14.5194(9.5252) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 14.8358(14.7823) | Bit/dim 3.9161(3.9263) | Xent 0.0000(0.0000) | Loss 8.7574(9.0300) | Error 0.0000(0.0000) Steps 526(528.50) | Grad Norm 9.0620(10.1213) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 15.0557(14.7309) | Bit/dim 3.9219(3.9205) | Xent 0.0000(0.0000) | Loss 8.7548(8.9396) | Error 0.0000(0.0000) Steps 508(527.83) | Grad Norm 8.8569(9.8514) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 14.5844(14.6993) | Bit/dim 3.9077(3.9160) | Xent 0.0000(0.0000) | Loss 8.7406(8.8755) | Error 0.0000(0.0000) Steps 508(528.42) | Grad Norm 19.3995(9.4870) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 80.0705, Epoch Time 912.7596(831.5711), Bit/dim 3.9168(best: 3.9314), Xent 0.0000, Loss 3.9168, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1380 | Time 14.8527(14.7163) | Bit/dim 3.9010(3.9185) | Xent 0.0000(0.0000) | Loss 8.7460(9.3737) | Error 0.0000(0.0000) Steps 508(530.13) | Grad Norm 12.3087(10.5669) | Total Time 0.00(0.00)\n",
      "Iter 1390 | Time 14.1921(14.6749) | Bit/dim 3.8878(3.9123) | Xent 0.0000(0.0000) | Loss 8.6373(9.1939) | Error 0.0000(0.0000) Steps 514(531.14) | Grad Norm 6.7682(9.8632) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 15.0796(14.6976) | Bit/dim 3.9003(3.9067) | Xent 0.0000(0.0000) | Loss 8.6619(9.0540) | Error 0.0000(0.0000) Steps 544(531.75) | Grad Norm 13.7404(9.6806) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 14.4608(14.7393) | Bit/dim 3.8528(3.8996) | Xent 0.0000(0.0000) | Loss 8.4760(8.9466) | Error 0.0000(0.0000) Steps 508(531.02) | Grad Norm 9.7267(9.6979) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 14.8477(14.7114) | Bit/dim 3.8626(3.8935) | Xent 0.0000(0.0000) | Loss 8.7410(8.8738) | Error 0.0000(0.0000) Steps 526(531.09) | Grad Norm 11.3937(10.2561) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 14.2675(14.7035) | Bit/dim 3.8316(3.8892) | Xent 0.0000(0.0000) | Loss 8.4651(8.8041) | Error 0.0000(0.0000) Steps 532(527.42) | Grad Norm 7.6464(9.5227) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 79.7587, Epoch Time 907.5205(833.8495), Bit/dim 3.8697(best: 3.9168), Xent 0.0000, Loss 3.8697, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1440 | Time 13.2820(14.5897) | Bit/dim 3.8819(3.8838) | Xent 0.0000(0.0000) | Loss 8.5669(9.1916) | Error 0.0000(0.0000) Steps 508(524.29) | Grad Norm 15.9527(9.7788) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 14.7432(14.6016) | Bit/dim 3.8420(3.8789) | Xent 0.0000(0.0000) | Loss 8.5708(9.0420) | Error 0.0000(0.0000) Steps 514(524.58) | Grad Norm 8.4839(10.1356) | Total Time 0.00(0.00)\n",
      "Iter 1460 | Time 14.4699(14.5950) | Bit/dim 3.8426(3.8764) | Xent 0.0000(0.0000) | Loss 8.6371(8.9267) | Error 0.0000(0.0000) Steps 508(522.40) | Grad Norm 6.5933(10.3795) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 14.7135(14.6048) | Bit/dim 3.8499(3.8744) | Xent 0.0000(0.0000) | Loss 8.6181(8.8493) | Error 0.0000(0.0000) Steps 538(521.84) | Grad Norm 7.8921(10.0875) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 14.0938(14.5878) | Bit/dim 3.8528(3.8702) | Xent 0.0000(0.0000) | Loss 8.6523(8.7901) | Error 0.0000(0.0000) Steps 556(524.72) | Grad Norm 8.6492(10.1874) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 79.9487, Epoch Time 896.9889(835.7437), Bit/dim 3.8606(best: 3.8697), Xent 0.0000, Loss 3.8606, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1490 | Time 14.7874(14.5027) | Bit/dim 3.8331(3.8676) | Xent 0.0000(0.0000) | Loss 8.6124(9.2496) | Error 0.0000(0.0000) Steps 532(524.55) | Grad Norm 9.2785(10.3150) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 13.9212(14.4974) | Bit/dim 3.8260(3.8625) | Xent 0.0000(0.0000) | Loss 8.5778(9.0820) | Error 0.0000(0.0000) Steps 502(522.28) | Grad Norm 14.3443(9.8542) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 14.4107(14.4561) | Bit/dim 3.8564(3.8580) | Xent 0.0000(0.0000) | Loss 8.5429(8.9520) | Error 0.0000(0.0000) Steps 526(521.04) | Grad Norm 4.8897(10.0688) | Total Time 0.00(0.00)\n",
      "Iter 1520 | Time 14.0643(14.4333) | Bit/dim 3.8262(3.8532) | Xent 0.0000(0.0000) | Loss 8.5679(8.8570) | Error 0.0000(0.0000) Steps 526(520.88) | Grad Norm 4.5799(9.3772) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 13.6581(14.4469) | Bit/dim 3.8320(3.8501) | Xent 0.0000(0.0000) | Loss 8.4782(8.7797) | Error 0.0000(0.0000) Steps 508(521.15) | Grad Norm 4.8796(10.2352) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 13.3838(14.4506) | Bit/dim 3.8300(3.8483) | Xent 0.0000(0.0000) | Loss 8.6657(8.7308) | Error 0.0000(0.0000) Steps 514(522.97) | Grad Norm 9.4726(9.9016) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 78.1282, Epoch Time 892.0565(837.4331), Bit/dim 3.8358(best: 3.8606), Xent 0.0000, Loss 3.8358, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1550 | Time 14.8130(14.5056) | Bit/dim 3.8294(3.8447) | Xent 0.0000(0.0000) | Loss 8.5973(9.1151) | Error 0.0000(0.0000) Steps 538(522.31) | Grad Norm 7.8849(9.5430) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 14.4507(14.4996) | Bit/dim 3.8161(3.8393) | Xent 0.0000(0.0000) | Loss 8.3148(8.9489) | Error 0.0000(0.0000) Steps 532(521.51) | Grad Norm 13.9984(10.2448) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 15.2780(14.5281) | Bit/dim 3.7784(3.8355) | Xent 0.0000(0.0000) | Loss 8.4013(8.8346) | Error 0.0000(0.0000) Steps 538(522.03) | Grad Norm 2.9051(9.3137) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 14.5544(14.4783) | Bit/dim 3.8470(3.8314) | Xent 0.0000(0.0000) | Loss 8.5959(8.7592) | Error 0.0000(0.0000) Steps 520(521.00) | Grad Norm 15.6606(9.4787) | Total Time 0.00(0.00)\n",
      "Iter 1590 | Time 15.0024(14.4881) | Bit/dim 3.8314(3.8321) | Xent 0.0000(0.0000) | Loss 8.5996(8.7076) | Error 0.0000(0.0000) Steps 538(521.39) | Grad Norm 10.2437(10.6047) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 78.3754, Epoch Time 897.5027(839.2352), Bit/dim 3.8200(best: 3.8358), Xent 0.0000, Loss 3.8200, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1600 | Time 13.7017(14.5055) | Bit/dim 3.7855(3.8285) | Xent 0.0000(0.0000) | Loss 8.4136(9.1647) | Error 0.0000(0.0000) Steps 502(520.76) | Grad Norm 8.9544(10.0351) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 14.8641(14.4974) | Bit/dim 3.8468(3.8243) | Xent 0.0000(0.0000) | Loss 8.6099(8.9983) | Error 0.0000(0.0000) Steps 526(520.33) | Grad Norm 14.8376(9.8811) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 14.4255(14.4930) | Bit/dim 3.8382(3.8232) | Xent 0.0000(0.0000) | Loss 8.5711(8.8677) | Error 0.0000(0.0000) Steps 514(518.75) | Grad Norm 12.8146(9.9104) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 15.3303(14.5582) | Bit/dim 3.7788(3.8173) | Xent 0.0000(0.0000) | Loss 8.5722(8.7692) | Error 0.0000(0.0000) Steps 532(519.27) | Grad Norm 7.6938(10.2709) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 13.8695(14.3968) | Bit/dim 3.7881(3.8094) | Xent 0.0000(0.0000) | Loss 8.4685(8.6827) | Error 0.0000(0.0000) Steps 538(518.78) | Grad Norm 14.5421(10.0727) | Total Time 0.00(0.00)\n",
      "Iter 1650 | Time 14.4697(14.3756) | Bit/dim 3.7870(3.8074) | Xent 0.0000(0.0000) | Loss 8.5038(8.6313) | Error 0.0000(0.0000) Steps 532(518.93) | Grad Norm 8.2133(10.2501) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 77.7496, Epoch Time 890.1026(840.7612), Bit/dim 3.7932(best: 3.8200), Xent 0.0000, Loss 3.7932, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1660 | Time 14.4454(14.3606) | Bit/dim 3.7596(3.8004) | Xent 0.0000(0.0000) | Loss 8.5243(9.0332) | Error 0.0000(0.0000) Steps 490(520.57) | Grad Norm 9.1990(9.1734) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 14.0481(14.3912) | Bit/dim 3.8108(3.7999) | Xent 0.0000(0.0000) | Loss 8.5123(8.8883) | Error 0.0000(0.0000) Steps 502(519.26) | Grad Norm 10.6204(9.8745) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 13.6980(14.3864) | Bit/dim 3.7851(3.7978) | Xent 0.0000(0.0000) | Loss 8.3638(8.7776) | Error 0.0000(0.0000) Steps 520(520.57) | Grad Norm 10.3928(9.9484) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 14.3531(14.4631) | Bit/dim 3.7895(3.7964) | Xent 0.0000(0.0000) | Loss 8.5575(8.6920) | Error 0.0000(0.0000) Steps 544(521.89) | Grad Norm 4.7987(10.2391) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 14.4788(14.5153) | Bit/dim 3.7630(3.7923) | Xent 0.0000(0.0000) | Loss 8.4766(8.6312) | Error 0.0000(0.0000) Steps 508(523.98) | Grad Norm 6.8899(9.2897) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 79.6835, Epoch Time 899.1463(842.5128), Bit/dim 3.7953(best: 3.7932), Xent 0.0000, Loss 3.7953, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1710 | Time 13.8901(14.5452) | Bit/dim 3.7909(3.7905) | Xent 0.0000(0.0000) | Loss 8.4166(9.0956) | Error 0.0000(0.0000) Steps 502(525.68) | Grad Norm 8.3536(10.1996) | Total Time 0.00(0.00)\n",
      "Iter 1720 | Time 14.7510(14.5223) | Bit/dim 3.7978(3.7883) | Xent 0.0000(0.0000) | Loss 8.4967(8.9303) | Error 0.0000(0.0000) Steps 532(525.38) | Grad Norm 6.0451(9.9499) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 14.7543(14.5451) | Bit/dim 3.7654(3.7839) | Xent 0.0000(0.0000) | Loss 8.4201(8.8066) | Error 0.0000(0.0000) Steps 538(526.12) | Grad Norm 8.4444(9.6516) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 14.2694(14.5087) | Bit/dim 3.7925(3.7807) | Xent 0.0000(0.0000) | Loss 8.5390(8.7098) | Error 0.0000(0.0000) Steps 550(524.47) | Grad Norm 11.6987(9.8352) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 14.6162(14.4918) | Bit/dim 3.7479(3.7782) | Xent 0.0000(0.0000) | Loss 8.3024(8.6304) | Error 0.0000(0.0000) Steps 514(523.25) | Grad Norm 6.9069(9.9433) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 14.9288(14.5289) | Bit/dim 3.7510(3.7753) | Xent 0.0000(0.0000) | Loss 8.4336(8.5702) | Error 0.0000(0.0000) Steps 538(521.95) | Grad Norm 14.0335(9.3599) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 77.5498, Epoch Time 895.2861(844.0960), Bit/dim 3.7741(best: 3.7932), Xent 0.0000, Loss 3.7741, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1770 | Time 13.7375(14.5374) | Bit/dim 3.7558(3.7737) | Xent 0.0000(0.0000) | Loss 8.3931(8.9639) | Error 0.0000(0.0000) Steps 526(522.33) | Grad Norm 2.4480(9.4204) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 14.3390(14.6171) | Bit/dim 3.7277(3.7660) | Xent 0.0000(0.0000) | Loss 8.3071(8.8122) | Error 0.0000(0.0000) Steps 532(522.25) | Grad Norm 9.4388(8.4246) | Total Time 0.00(0.00)\n",
      "Iter 1790 | Time 14.6435(14.5939) | Bit/dim 3.7774(3.7638) | Xent 0.0000(0.0000) | Loss 8.4956(8.7044) | Error 0.0000(0.0000) Steps 544(523.33) | Grad Norm 12.9508(8.8606) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 13.8694(14.5307) | Bit/dim 3.7550(3.7679) | Xent 0.0000(0.0000) | Loss 8.5090(8.6382) | Error 0.0000(0.0000) Steps 550(522.70) | Grad Norm 11.3275(9.9707) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 15.0027(14.5977) | Bit/dim 3.7744(3.7671) | Xent 0.0000(0.0000) | Loss 8.3145(8.5791) | Error 0.0000(0.0000) Steps 532(525.19) | Grad Norm 12.7332(10.2696) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 78.4799, Epoch Time 903.6130(845.8815), Bit/dim 3.7558(best: 3.7741), Xent 0.0000, Loss 3.7558, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1820 | Time 15.3560(14.6408) | Bit/dim 3.7589(3.7667) | Xent 0.0000(0.0000) | Loss 8.3833(9.0534) | Error 0.0000(0.0000) Steps 502(523.96) | Grad Norm 9.0225(9.7284) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 14.8680(14.7200) | Bit/dim 3.7692(3.7594) | Xent 0.0000(0.0000) | Loss 8.5172(8.8774) | Error 0.0000(0.0000) Steps 550(525.71) | Grad Norm 18.1282(10.3587) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 14.6309(14.7169) | Bit/dim 3.7395(3.7560) | Xent 0.0000(0.0000) | Loss 8.4065(8.7597) | Error 0.0000(0.0000) Steps 538(525.39) | Grad Norm 4.7471(9.8645) | Total Time 0.00(0.00)\n",
      "Iter 1850 | Time 14.0437(14.7034) | Bit/dim 3.7509(3.7522) | Xent 0.0000(0.0000) | Loss 8.3811(8.6562) | Error 0.0000(0.0000) Steps 520(524.81) | Grad Norm 11.1774(8.7080) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 15.3021(14.7960) | Bit/dim 3.7615(3.7509) | Xent 0.0000(0.0000) | Loss 8.5058(8.5862) | Error 0.0000(0.0000) Steps 550(526.75) | Grad Norm 5.1365(8.7889) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 15.0586(14.7100) | Bit/dim 3.7522(3.7485) | Xent 0.0000(0.0000) | Loss 8.4074(8.5261) | Error 0.0000(0.0000) Steps 502(522.61) | Grad Norm 9.5974(8.9668) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 77.9989, Epoch Time 910.0110(847.8054), Bit/dim 3.7433(best: 3.7558), Xent 0.0000, Loss 3.7433, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1880 | Time 15.0140(14.7308) | Bit/dim 3.7341(3.7454) | Xent 0.0000(0.0000) | Loss 8.3578(8.9365) | Error 0.0000(0.0000) Steps 520(521.51) | Grad Norm 11.5158(8.3023) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 16.1394(14.7170) | Bit/dim 3.7572(3.7441) | Xent 0.0000(0.0000) | Loss 8.4138(8.7891) | Error 0.0000(0.0000) Steps 502(522.87) | Grad Norm 7.8127(9.2395) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 15.6865(14.7956) | Bit/dim 3.7221(3.7429) | Xent 0.0000(0.0000) | Loss 8.3009(8.6747) | Error 0.0000(0.0000) Steps 496(521.41) | Grad Norm 8.1225(8.6100) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 15.0191(14.8433) | Bit/dim 3.7158(3.7400) | Xent 0.0000(0.0000) | Loss 8.3589(8.5915) | Error 0.0000(0.0000) Steps 544(521.96) | Grad Norm 10.6171(9.5893) | Total Time 0.00(0.00)\n",
      "Iter 1920 | Time 14.8705(14.8298) | Bit/dim 3.7425(3.7385) | Xent 0.0000(0.0000) | Loss 8.3860(8.5353) | Error 0.0000(0.0000) Steps 514(520.53) | Grad Norm 7.7427(9.4736) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 77.3471, Epoch Time 912.9056(849.7584), Bit/dim 3.7240(best: 3.7433), Xent 0.0000, Loss 3.7240, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1930 | Time 15.5140(14.7874) | Bit/dim 3.7264(3.7333) | Xent 0.0000(0.0000) | Loss 8.3329(8.9955) | Error 0.0000(0.0000) Steps 532(521.25) | Grad Norm 6.9208(8.2355) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 14.5431(14.8541) | Bit/dim 3.7474(3.7327) | Xent 0.0000(0.0000) | Loss 8.3556(8.8342) | Error 0.0000(0.0000) Steps 544(522.71) | Grad Norm 9.2309(9.0321) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 14.6054(14.8362) | Bit/dim 3.7042(3.7302) | Xent 0.0000(0.0000) | Loss 8.2109(8.6993) | Error 0.0000(0.0000) Steps 502(522.11) | Grad Norm 5.9881(8.0051) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 15.4790(14.8114) | Bit/dim 3.6920(3.7263) | Xent 0.0000(0.0000) | Loss 8.3726(8.6001) | Error 0.0000(0.0000) Steps 532(521.56) | Grad Norm 4.7648(8.3260) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 14.9246(14.7932) | Bit/dim 3.7524(3.7263) | Xent 0.0000(0.0000) | Loss 8.4452(8.5330) | Error 0.0000(0.0000) Steps 526(521.07) | Grad Norm 16.4860(9.2625) | Total Time 0.00(0.00)\n",
      "Iter 1980 | Time 15.0969(14.8256) | Bit/dim 3.7319(3.7263) | Xent 0.0000(0.0000) | Loss 8.4611(8.4819) | Error 0.0000(0.0000) Steps 544(521.07) | Grad Norm 4.3126(9.1216) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 78.0540, Epoch Time 913.0965(851.6585), Bit/dim 3.7172(best: 3.7240), Xent 0.0000, Loss 3.7172, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1990 | Time 15.1471(14.8461) | Bit/dim 3.7294(3.7230) | Xent 0.0000(0.0000) | Loss 8.3073(8.8686) | Error 0.0000(0.0000) Steps 526(520.93) | Grad Norm 17.9026(9.4479) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 14.6566(14.8089) | Bit/dim 3.7075(3.7208) | Xent 0.0000(0.0000) | Loss 8.4270(8.7232) | Error 0.0000(0.0000) Steps 538(521.72) | Grad Norm 5.3641(8.9391) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 15.5991(14.8139) | Bit/dim 3.7042(3.7176) | Xent 0.0000(0.0000) | Loss 8.3431(8.6128) | Error 0.0000(0.0000) Steps 538(522.39) | Grad Norm 7.5176(7.9960) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 14.8023(14.7997) | Bit/dim 3.7262(3.7177) | Xent 0.0000(0.0000) | Loss 8.2668(8.5363) | Error 0.0000(0.0000) Steps 514(521.57) | Grad Norm 9.2179(7.7942) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 15.3938(14.7725) | Bit/dim 3.7420(3.7153) | Xent 0.0000(0.0000) | Loss 8.3518(8.4698) | Error 0.0000(0.0000) Steps 526(521.80) | Grad Norm 7.5028(8.4201) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 78.4250, Epoch Time 910.3200(853.4184), Bit/dim 3.7098(best: 3.7172), Xent 0.0000, Loss 3.7098, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2040 | Time 14.5503(14.7280) | Bit/dim 3.6692(3.7130) | Xent 0.0000(0.0000) | Loss 8.0302(8.9338) | Error 0.0000(0.0000) Steps 490(519.85) | Grad Norm 4.2409(7.6227) | Total Time 0.00(0.00)\n",
      "Iter 2050 | Time 14.1219(14.6614) | Bit/dim 3.6903(3.7110) | Xent 0.0000(0.0000) | Loss 8.2383(8.7702) | Error 0.0000(0.0000) Steps 520(520.48) | Grad Norm 8.5621(8.1547) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 14.3399(14.5922) | Bit/dim 3.7242(3.7095) | Xent 0.0000(0.0000) | Loss 8.3547(8.6436) | Error 0.0000(0.0000) Steps 520(520.06) | Grad Norm 6.2953(7.4341) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 14.3308(14.7048) | Bit/dim 3.7202(3.7115) | Xent 0.0000(0.0000) | Loss 8.2559(8.5639) | Error 0.0000(0.0000) Steps 520(521.62) | Grad Norm 8.2879(8.4826) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 14.1477(14.6362) | Bit/dim 3.7213(3.7104) | Xent 0.0000(0.0000) | Loss 8.3175(8.4892) | Error 0.0000(0.0000) Steps 502(521.69) | Grad Norm 18.8608(8.9599) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 15.7823(14.7238) | Bit/dim 3.6927(3.7086) | Xent 0.0000(0.0000) | Loss 8.3581(8.4397) | Error 0.0000(0.0000) Steps 508(520.99) | Grad Norm 6.9498(9.3130) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 78.7533, Epoch Time 903.8437(854.9311), Bit/dim 3.7060(best: 3.7098), Xent 0.0000, Loss 3.7060, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2100 | Time 14.7372(14.7703) | Bit/dim 3.6841(3.7060) | Xent 0.0000(0.0000) | Loss 8.1103(8.8254) | Error 0.0000(0.0000) Steps 472(519.63) | Grad Norm 9.1135(8.9961) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 14.4346(14.7060) | Bit/dim 3.6916(3.7037) | Xent 0.0000(0.0000) | Loss 8.2717(8.6773) | Error 0.0000(0.0000) Steps 520(518.32) | Grad Norm 4.5170(7.9569) | Total Time 0.00(0.00)\n",
      "Iter 2120 | Time 14.9237(14.7461) | Bit/dim 3.7209(3.7014) | Xent 0.0000(0.0000) | Loss 8.3228(8.5658) | Error 0.0000(0.0000) Steps 550(520.29) | Grad Norm 2.3788(7.0509) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 14.7312(14.7857) | Bit/dim 3.7049(3.6998) | Xent 0.0000(0.0000) | Loss 8.3869(8.4929) | Error 0.0000(0.0000) Steps 520(520.28) | Grad Norm 12.6496(8.0096) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 14.8898(14.7291) | Bit/dim 3.7012(3.6979) | Xent 0.0000(0.0000) | Loss 8.2738(8.4260) | Error 0.0000(0.0000) Steps 532(521.14) | Grad Norm 12.9799(8.1850) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 78.8178, Epoch Time 912.1636(856.6481), Bit/dim 3.6940(best: 3.7060), Xent 0.0000, Loss 3.6940, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2150 | Time 14.7608(14.7620) | Bit/dim 3.6842(3.6995) | Xent 0.0000(0.0000) | Loss 8.1835(8.9072) | Error 0.0000(0.0000) Steps 508(520.79) | Grad Norm 5.5550(8.5176) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 14.7678(14.6948) | Bit/dim 3.7055(3.7011) | Xent 0.0000(0.0000) | Loss 8.3053(8.7405) | Error 0.0000(0.0000) Steps 520(520.94) | Grad Norm 7.7362(8.1799) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 14.2468(14.6082) | Bit/dim 3.6730(3.6972) | Xent 0.0000(0.0000) | Loss 8.2346(8.6173) | Error 0.0000(0.0000) Steps 526(521.80) | Grad Norm 11.6203(8.7712) | Total Time 0.00(0.00)\n",
      "Iter 2180 | Time 14.0405(14.6749) | Bit/dim 3.6757(3.6937) | Xent 0.0000(0.0000) | Loss 8.2335(8.5267) | Error 0.0000(0.0000) Steps 514(524.79) | Grad Norm 8.3537(8.3746) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 14.8734(14.8047) | Bit/dim 3.6940(3.6951) | Xent 0.0000(0.0000) | Loss 8.2678(8.4632) | Error 0.0000(0.0000) Steps 526(528.54) | Grad Norm 3.5194(7.9222) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 13.9180(14.7829) | Bit/dim 3.6643(3.6888) | Xent 0.0000(0.0000) | Loss 8.1869(8.4039) | Error 0.0000(0.0000) Steps 508(527.25) | Grad Norm 14.7571(7.3488) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 78.8347, Epoch Time 907.4115(858.1710), Bit/dim 3.7075(best: 3.6940), Xent 0.0000, Loss 3.7075, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2210 | Time 15.1018(14.8225) | Bit/dim 3.6890(3.6878) | Xent 0.0000(0.0000) | Loss 8.3859(8.8212) | Error 0.0000(0.0000) Steps 526(529.53) | Grad Norm 5.3174(7.7088) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 14.6384(14.7979) | Bit/dim 3.6661(3.6860) | Xent 0.0000(0.0000) | Loss 8.2253(8.6660) | Error 0.0000(0.0000) Steps 538(528.08) | Grad Norm 8.1774(8.0375) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 15.0205(14.7937) | Bit/dim 3.6902(3.6883) | Xent 0.0000(0.0000) | Loss 8.0956(8.5636) | Error 0.0000(0.0000) Steps 472(525.95) | Grad Norm 6.1034(8.0329) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 15.0228(14.8492) | Bit/dim 3.7183(3.6870) | Xent 0.0000(0.0000) | Loss 8.1996(8.4804) | Error 0.0000(0.0000) Steps 544(526.33) | Grad Norm 10.4991(8.4939) | Total Time 0.00(0.00)\n",
      "Iter 2250 | Time 14.9258(14.8435) | Bit/dim 3.6684(3.6836) | Xent 0.0000(0.0000) | Loss 8.2581(8.4146) | Error 0.0000(0.0000) Steps 526(526.46) | Grad Norm 7.3967(7.9921) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 77.9902, Epoch Time 916.6585(859.9256), Bit/dim 3.6738(best: 3.6940), Xent 0.0000, Loss 3.6738, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2260 | Time 15.0038(14.8737) | Bit/dim 3.6999(3.6833) | Xent 0.0000(0.0000) | Loss 8.3004(8.9031) | Error 0.0000(0.0000) Steps 496(526.32) | Grad Norm 7.7779(7.8162) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 14.4157(14.9340) | Bit/dim 3.6885(3.6808) | Xent 0.0000(0.0000) | Loss 8.2403(8.7335) | Error 0.0000(0.0000) Steps 514(528.84) | Grad Norm 4.4232(7.1177) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 14.1775(14.8814) | Bit/dim 3.6465(3.6802) | Xent 0.0000(0.0000) | Loss 8.2260(8.6034) | Error 0.0000(0.0000) Steps 508(527.93) | Grad Norm 11.2998(7.9565) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 15.2594(14.8561) | Bit/dim 3.6627(3.6770) | Xent 0.0000(0.0000) | Loss 8.1510(8.5105) | Error 0.0000(0.0000) Steps 508(527.89) | Grad Norm 9.9482(7.9736) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 15.4244(14.8213) | Bit/dim 3.6778(3.6760) | Xent 0.0000(0.0000) | Loss 8.2203(8.4440) | Error 0.0000(0.0000) Steps 508(526.98) | Grad Norm 8.4363(7.5824) | Total Time 0.00(0.00)\n",
      "Iter 2310 | Time 15.6849(14.8699) | Bit/dim 3.6939(3.6742) | Xent 0.0000(0.0000) | Loss 8.2835(8.3945) | Error 0.0000(0.0000) Steps 508(527.77) | Grad Norm 5.1609(7.2725) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 78.8590, Epoch Time 916.3598(861.6187), Bit/dim 3.6673(best: 3.6738), Xent 0.0000, Loss 3.6673, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2320 | Time 15.0458(14.8447) | Bit/dim 3.6634(3.6727) | Xent 0.0000(0.0000) | Loss 8.2814(8.8047) | Error 0.0000(0.0000) Steps 520(528.62) | Grad Norm 4.7171(7.0733) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 15.5715(14.8482) | Bit/dim 3.6270(3.6684) | Xent 0.0000(0.0000) | Loss 8.2149(8.6545) | Error 0.0000(0.0000) Steps 544(528.55) | Grad Norm 5.6548(6.4439) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 15.5109(14.8578) | Bit/dim 3.6701(3.6699) | Xent 0.0000(0.0000) | Loss 8.2200(8.5468) | Error 0.0000(0.0000) Steps 514(524.86) | Grad Norm 5.9279(7.4726) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 14.8735(14.8857) | Bit/dim 3.6672(3.6712) | Xent 0.0000(0.0000) | Loss 8.2825(8.4693) | Error 0.0000(0.0000) Steps 550(525.94) | Grad Norm 11.8149(8.2962) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 14.7451(14.9136) | Bit/dim 3.6489(3.6727) | Xent 0.0000(0.0000) | Loss 8.1051(8.4191) | Error 0.0000(0.0000) Steps 538(527.79) | Grad Norm 5.8604(8.3460) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 77.7514, Epoch Time 917.0573(863.2818), Bit/dim 3.6699(best: 3.6673), Xent 0.0000, Loss 3.6699, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2370 | Time 14.8795(14.9062) | Bit/dim 3.6910(3.6722) | Xent 0.0000(0.0000) | Loss 8.2247(8.8929) | Error 0.0000(0.0000) Steps 508(528.70) | Grad Norm 5.8837(8.2348) | Total Time 0.00(0.00)\n",
      "Iter 2380 | Time 14.6486(14.8868) | Bit/dim 3.6556(3.6697) | Xent 0.0000(0.0000) | Loss 8.2799(8.7276) | Error 0.0000(0.0000) Steps 526(531.18) | Grad Norm 5.0881(7.6150) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 14.8051(14.8987) | Bit/dim 3.6989(3.6686) | Xent 0.0000(0.0000) | Loss 8.3333(8.6036) | Error 0.0000(0.0000) Steps 556(531.55) | Grad Norm 5.1847(7.5473) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 15.6463(14.9345) | Bit/dim 3.6576(3.6649) | Xent 0.0000(0.0000) | Loss 8.2955(8.5046) | Error 0.0000(0.0000) Steps 526(532.71) | Grad Norm 6.4619(7.7750) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 15.2352(14.8953) | Bit/dim 3.6395(3.6615) | Xent 0.0000(0.0000) | Loss 8.2259(8.4286) | Error 0.0000(0.0000) Steps 550(531.46) | Grad Norm 7.9041(7.2295) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 15.4155(14.8796) | Bit/dim 3.6652(3.6613) | Xent 0.0000(0.0000) | Loss 8.2418(8.3889) | Error 0.0000(0.0000) Steps 568(532.66) | Grad Norm 10.5296(7.5478) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 79.3437, Epoch Time 917.7567(864.9161), Bit/dim 3.6558(best: 3.6673), Xent 0.0000, Loss 3.6558, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2430 | Time 15.0668(14.9085) | Bit/dim 3.6728(3.6587) | Xent 0.0000(0.0000) | Loss 8.3528(8.8217) | Error 0.0000(0.0000) Steps 532(531.18) | Grad Norm 10.8764(8.0649) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 14.8184(14.9465) | Bit/dim 3.7052(3.6605) | Xent 0.0000(0.0000) | Loss 8.3513(8.6661) | Error 0.0000(0.0000) Steps 550(530.56) | Grad Norm 5.5913(7.4032) | Total Time 0.00(0.00)\n",
      "Iter 2450 | Time 16.0621(15.0321) | Bit/dim 3.6426(3.6576) | Xent 0.0000(0.0000) | Loss 8.2456(8.5505) | Error 0.0000(0.0000) Steps 562(533.70) | Grad Norm 6.0322(6.5529) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 15.7705(15.0630) | Bit/dim 3.6739(3.6557) | Xent 0.0000(0.0000) | Loss 8.3377(8.4696) | Error 0.0000(0.0000) Steps 520(533.33) | Grad Norm 5.2929(6.8547) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 14.8733(15.0417) | Bit/dim 3.6507(3.6533) | Xent 0.0000(0.0000) | Loss 8.1207(8.4022) | Error 0.0000(0.0000) Steps 520(533.10) | Grad Norm 2.9863(6.2001) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 78.4978, Epoch Time 927.5290(866.7944), Bit/dim 3.6628(best: 3.6558), Xent 0.0000, Loss 3.6628, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2480 | Time 14.5461(15.0029) | Bit/dim 3.7036(3.6552) | Xent 0.0000(0.0000) | Loss 8.3363(8.8817) | Error 0.0000(0.0000) Steps 544(533.76) | Grad Norm 5.3475(6.8166) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 14.3547(14.9786) | Bit/dim 3.6262(3.6553) | Xent 0.0000(0.0000) | Loss 8.2032(8.7059) | Error 0.0000(0.0000) Steps 532(532.86) | Grad Norm 9.0736(7.3415) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 14.3233(14.9656) | Bit/dim 3.6364(3.6544) | Xent 0.0000(0.0000) | Loss 8.2377(8.5847) | Error 0.0000(0.0000) Steps 532(532.23) | Grad Norm 10.2820(7.4666) | Total Time 0.00(0.00)\n",
      "Iter 2510 | Time 14.6626(14.9909) | Bit/dim 3.6292(3.6528) | Xent 0.0000(0.0000) | Loss 8.1108(8.4845) | Error 0.0000(0.0000) Steps 520(530.12) | Grad Norm 5.0789(7.2124) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 15.8795(15.0629) | Bit/dim 3.6761(3.6513) | Xent 0.0000(0.0000) | Loss 8.3144(8.4181) | Error 0.0000(0.0000) Steps 562(531.82) | Grad Norm 5.5834(7.4120) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 14.7974(15.1094) | Bit/dim 3.6402(3.6506) | Xent 0.0000(0.0000) | Loss 8.2655(8.3676) | Error 0.0000(0.0000) Steps 520(533.59) | Grad Norm 5.7426(7.0141) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 78.4104, Epoch Time 934.7485(868.8331), Bit/dim 3.6529(best: 3.6558), Xent 0.0000, Loss 3.6529, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2540 | Time 14.9206(15.0481) | Bit/dim 3.5919(3.6515) | Xent 0.0000(0.0000) | Loss 8.1187(8.7823) | Error 0.0000(0.0000) Steps 544(535.12) | Grad Norm 4.0372(7.9816) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 15.6690(15.0410) | Bit/dim 3.6352(3.6484) | Xent 0.0000(0.0000) | Loss 8.2880(8.6211) | Error 0.0000(0.0000) Steps 544(534.99) | Grad Norm 8.6255(7.9097) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 14.9689(15.0668) | Bit/dim 3.6665(3.6506) | Xent 0.0000(0.0000) | Loss 8.2680(8.5190) | Error 0.0000(0.0000) Steps 526(534.71) | Grad Norm 10.1310(8.0563) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 14.1456(15.0583) | Bit/dim 3.6058(3.6485) | Xent 0.0000(0.0000) | Loss 8.1385(8.4351) | Error 0.0000(0.0000) Steps 526(534.41) | Grad Norm 4.2827(7.2459) | Total Time 0.00(0.00)\n",
      "Iter 2580 | Time 15.5014(15.0665) | Bit/dim 3.6541(3.6468) | Xent 0.0000(0.0000) | Loss 8.3487(8.3728) | Error 0.0000(0.0000) Steps 550(534.11) | Grad Norm 11.4520(7.5477) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 83.0051, Epoch Time 933.7406(870.7803), Bit/dim 3.6390(best: 3.6529), Xent 0.0000, Loss 3.6390, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2590 | Time 15.7494(15.0960) | Bit/dim 3.6340(3.6445) | Xent 0.0000(0.0000) | Loss 8.2200(8.8709) | Error 0.0000(0.0000) Steps 574(538.50) | Grad Norm 5.8482(7.4881) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 15.4083(15.0739) | Bit/dim 3.6077(3.6421) | Xent 0.0000(0.0000) | Loss 8.1387(8.6926) | Error 0.0000(0.0000) Steps 568(536.37) | Grad Norm 6.3780(6.6827) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 15.3975(15.0854) | Bit/dim 3.6439(3.6437) | Xent 0.0000(0.0000) | Loss 8.2438(8.5733) | Error 0.0000(0.0000) Steps 526(537.67) | Grad Norm 3.8916(7.0354) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 15.2603(15.1568) | Bit/dim 3.6323(3.6411) | Xent 0.0000(0.0000) | Loss 8.1473(8.4772) | Error 0.0000(0.0000) Steps 544(539.09) | Grad Norm 6.3209(6.7872) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 14.8638(15.1633) | Bit/dim 3.6026(3.6408) | Xent 0.0000(0.0000) | Loss 8.1421(8.4100) | Error 0.0000(0.0000) Steps 550(540.54) | Grad Norm 4.9864(7.3142) | Total Time 0.00(0.00)\n",
      "Iter 2640 | Time 13.8806(15.1078) | Bit/dim 3.6012(3.6394) | Xent 0.0000(0.0000) | Loss 8.1756(8.3588) | Error 0.0000(0.0000) Steps 514(538.83) | Grad Norm 5.7204(7.7123) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 81.0783, Epoch Time 932.8854(872.6435), Bit/dim 3.6530(best: 3.6390), Xent 0.0000, Loss 3.6530, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2650 | Time 14.4207(15.0524) | Bit/dim 3.6413(3.6409) | Xent 0.0000(0.0000) | Loss 8.2077(8.7755) | Error 0.0000(0.0000) Steps 514(538.87) | Grad Norm 8.6697(8.1714) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 15.5094(15.0855) | Bit/dim 3.6028(3.6421) | Xent 0.0000(0.0000) | Loss 8.1262(8.6269) | Error 0.0000(0.0000) Steps 550(537.32) | Grad Norm 8.6692(7.7751) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 15.6113(15.1938) | Bit/dim 3.6078(3.6394) | Xent 0.0000(0.0000) | Loss 8.1598(8.5174) | Error 0.0000(0.0000) Steps 562(537.62) | Grad Norm 7.6407(7.2864) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 14.2028(15.1543) | Bit/dim 3.5859(3.6362) | Xent 0.0000(0.0000) | Loss 8.1126(8.4205) | Error 0.0000(0.0000) Steps 550(537.77) | Grad Norm 8.3882(7.0245) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 15.9636(15.1512) | Bit/dim 3.5997(3.6331) | Xent 0.0000(0.0000) | Loss 8.1426(8.3626) | Error 0.0000(0.0000) Steps 520(538.35) | Grad Norm 7.7351(6.9414) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 86.9088, Epoch Time 947.8175(874.8987), Bit/dim 3.6393(best: 3.6390), Xent 0.0000, Loss 3.6393, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2700 | Time 14.8929(15.1978) | Bit/dim 3.6299(3.6337) | Xent 0.0000(0.0000) | Loss 8.2248(8.8578) | Error 0.0000(0.0000) Steps 544(539.70) | Grad Norm 8.1530(7.2473) | Total Time 0.00(0.00)\n",
      "Iter 2710 | Time 15.0262(15.2029) | Bit/dim 3.6297(3.6364) | Xent 0.0000(0.0000) | Loss 8.2438(8.6815) | Error 0.0000(0.0000) Steps 520(538.00) | Grad Norm 7.3687(7.4648) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 14.7724(15.1955) | Bit/dim 3.6111(3.6333) | Xent 0.0000(0.0000) | Loss 8.0809(8.5475) | Error 0.0000(0.0000) Steps 490(537.67) | Grad Norm 10.1877(7.0464) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 15.3585(15.2690) | Bit/dim 3.6116(3.6318) | Xent 0.0000(0.0000) | Loss 8.1645(8.4600) | Error 0.0000(0.0000) Steps 532(537.60) | Grad Norm 4.7732(7.0093) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 14.1780(15.2184) | Bit/dim 3.6457(3.6308) | Xent 0.0000(0.0000) | Loss 8.1757(8.3918) | Error 0.0000(0.0000) Steps 532(537.68) | Grad Norm 6.8556(6.4495) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 14.9029(15.2245) | Bit/dim 3.6121(3.6300) | Xent 0.0000(0.0000) | Loss 8.2128(8.3371) | Error 0.0000(0.0000) Steps 526(537.33) | Grad Norm 6.7633(6.5213) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 80.6355, Epoch Time 944.6277(876.9905), Bit/dim 3.6311(best: 3.6390), Xent 0.0000, Loss 3.6311, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2760 | Time 14.9377(15.1768) | Bit/dim 3.6316(3.6284) | Xent 0.0000(0.0000) | Loss 8.1970(8.7684) | Error 0.0000(0.0000) Steps 526(539.50) | Grad Norm 7.7451(7.1869) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 15.7261(15.2831) | Bit/dim 3.6205(3.6270) | Xent 0.0000(0.0000) | Loss 8.2329(8.6179) | Error 0.0000(0.0000) Steps 568(540.69) | Grad Norm 5.8664(6.6837) | Total Time 0.00(0.00)\n",
      "Iter 2780 | Time 14.7489(15.2379) | Bit/dim 3.6131(3.6283) | Xent 0.0000(0.0000) | Loss 8.1998(8.5094) | Error 0.0000(0.0000) Steps 532(540.64) | Grad Norm 5.2224(6.9175) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 15.3576(15.2474) | Bit/dim 3.6103(3.6300) | Xent 0.0000(0.0000) | Loss 8.2756(8.4374) | Error 0.0000(0.0000) Steps 562(540.86) | Grad Norm 6.3446(6.9928) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 15.6893(15.2628) | Bit/dim 3.6608(3.6284) | Xent 0.0000(0.0000) | Loss 8.2446(8.3775) | Error 0.0000(0.0000) Steps 550(541.99) | Grad Norm 7.6415(7.0405) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 88.7132, Epoch Time 946.5253(879.0766), Bit/dim 3.6248(best: 3.6311), Xent 0.0000, Loss 3.6248, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2810 | Time 15.6601(15.1731) | Bit/dim 3.6265(3.6245) | Xent 0.0000(0.0000) | Loss 8.2293(8.8574) | Error 0.0000(0.0000) Steps 574(541.34) | Grad Norm 2.5880(6.4233) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 15.1948(15.2306) | Bit/dim 3.6358(3.6255) | Xent 0.0000(0.0000) | Loss 8.1454(8.6893) | Error 0.0000(0.0000) Steps 532(541.05) | Grad Norm 8.5219(6.6416) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 16.4994(15.2025) | Bit/dim 3.6102(3.6203) | Xent 0.0000(0.0000) | Loss 8.2029(8.5569) | Error 0.0000(0.0000) Steps 610(542.06) | Grad Norm 8.1969(6.9142) | Total Time 0.00(0.00)\n",
      "Iter 2840 | Time 15.7194(15.2796) | Bit/dim 3.6493(3.6211) | Xent 0.0000(0.0000) | Loss 8.2523(8.4578) | Error 0.0000(0.0000) Steps 538(544.18) | Grad Norm 3.8429(6.5948) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 14.5546(15.2289) | Bit/dim 3.6314(3.6205) | Xent 0.0000(0.0000) | Loss 8.2108(8.3884) | Error 0.0000(0.0000) Steps 532(542.91) | Grad Norm 3.3216(6.1488) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 15.4060(15.2337) | Bit/dim 3.6373(3.6227) | Xent 0.0000(0.0000) | Loss 8.1752(8.3420) | Error 0.0000(0.0000) Steps 562(542.04) | Grad Norm 10.5541(6.7937) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 82.6857, Epoch Time 946.5525(881.1009), Bit/dim 3.6345(best: 3.6248), Xent 0.0000, Loss 3.6345, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2870 | Time 15.1755(15.2553) | Bit/dim 3.6306(3.6273) | Xent 0.0000(0.0000) | Loss 8.1073(8.7839) | Error 0.0000(0.0000) Steps 550(543.81) | Grad Norm 11.0836(7.5585) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 15.4631(15.2840) | Bit/dim 3.6086(3.6244) | Xent 0.0000(0.0000) | Loss 8.2121(8.6293) | Error 0.0000(0.0000) Steps 526(544.41) | Grad Norm 8.3710(7.5178) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 15.0062(15.3267) | Bit/dim 3.6359(3.6237) | Xent 0.0000(0.0000) | Loss 8.3210(8.5228) | Error 0.0000(0.0000) Steps 556(541.09) | Grad Norm 6.2637(6.9342) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 15.8884(15.3169) | Bit/dim 3.5896(3.6191) | Xent 0.0000(0.0000) | Loss 8.0775(8.4263) | Error 0.0000(0.0000) Steps 526(537.78) | Grad Norm 5.0938(6.6118) | Total Time 0.00(0.00)\n",
      "Iter 2910 | Time 15.1028(15.3185) | Bit/dim 3.6331(3.6172) | Xent 0.0000(0.0000) | Loss 8.1963(8.3618) | Error 0.0000(0.0000) Steps 538(539.44) | Grad Norm 8.8766(6.5953) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 82.2705, Epoch Time 954.4311(883.3008), Bit/dim 3.6164(best: 3.6248), Xent 0.0000, Loss 3.6164, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2920 | Time 14.0175(15.2386) | Bit/dim 3.6002(3.6173) | Xent 0.0000(0.0000) | Loss 8.1007(8.8561) | Error 0.0000(0.0000) Steps 538(539.11) | Grad Norm 3.8779(6.9648) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 15.7999(15.2651) | Bit/dim 3.6311(3.6142) | Xent 0.0000(0.0000) | Loss 8.2990(8.6769) | Error 0.0000(0.0000) Steps 574(538.43) | Grad Norm 4.8641(6.7808) | Total Time 0.00(0.00)\n",
      "Iter 2940 | Time 15.2373(15.2424) | Bit/dim 3.5934(3.6120) | Xent 0.0000(0.0000) | Loss 8.1295(8.5381) | Error 0.0000(0.0000) Steps 538(536.23) | Grad Norm 5.1908(6.0388) | Total Time 0.00(0.00)\n",
      "Iter 2950 | Time 14.2924(15.2137) | Bit/dim 3.6188(3.6124) | Xent 0.0000(0.0000) | Loss 8.2905(8.4413) | Error 0.0000(0.0000) Steps 526(537.27) | Grad Norm 5.5238(6.3759) | Total Time 0.00(0.00)\n",
      "Iter 2960 | Time 14.9792(15.1836) | Bit/dim 3.6038(3.6114) | Xent 0.0000(0.0000) | Loss 8.1685(8.3699) | Error 0.0000(0.0000) Steps 544(536.99) | Grad Norm 7.5448(5.8703) | Total Time 0.00(0.00)\n",
      "Iter 2970 | Time 15.5579(15.1826) | Bit/dim 3.5928(3.6142) | Xent 0.0000(0.0000) | Loss 8.1571(8.3300) | Error 0.0000(0.0000) Steps 520(537.85) | Grad Norm 6.5725(6.7602) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 81.4066, Epoch Time 935.9298(884.8796), Bit/dim 3.6140(best: 3.6164), Xent 0.0000, Loss 3.6140, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2980 | Time 14.9855(15.2001) | Bit/dim 3.6094(3.6120) | Xent 0.0000(0.0000) | Loss 8.2291(8.7656) | Error 0.0000(0.0000) Steps 562(540.78) | Grad Norm 8.2132(7.0344) | Total Time 0.00(0.00)\n",
      "Iter 2990 | Time 14.8377(15.1736) | Bit/dim 3.6111(3.6107) | Xent 0.0000(0.0000) | Loss 8.2352(8.6148) | Error 0.0000(0.0000) Steps 520(541.79) | Grad Norm 5.0064(7.1370) | Total Time 0.00(0.00)\n",
      "Iter 3000 | Time 15.1666(15.2875) | Bit/dim 3.5975(3.6090) | Xent 0.0000(0.0000) | Loss 8.1515(8.4992) | Error 0.0000(0.0000) Steps 550(541.68) | Grad Norm 5.8804(6.5790) | Total Time 0.00(0.00)\n",
      "Iter 3010 | Time 15.6105(15.3069) | Bit/dim 3.6460(3.6094) | Xent 0.0000(0.0000) | Loss 8.1872(8.4124) | Error 0.0000(0.0000) Steps 574(544.80) | Grad Norm 4.8720(5.8136) | Total Time 0.00(0.00)\n",
      "Iter 3020 | Time 14.2983(15.2169) | Bit/dim 3.6410(3.6097) | Xent 0.0000(0.0000) | Loss 8.2102(8.3447) | Error 0.0000(0.0000) Steps 502(542.34) | Grad Norm 4.6828(5.9981) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 81.3523, Epoch Time 943.9119(886.6506), Bit/dim 3.6088(best: 3.6140), Xent 0.0000, Loss 3.6088, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3030 | Time 15.3940(15.2450) | Bit/dim 3.6071(3.6085) | Xent 0.0000(0.0000) | Loss 8.2413(8.8600) | Error 0.0000(0.0000) Steps 574(545.04) | Grad Norm 11.7927(6.4444) | Total Time 0.00(0.00)\n",
      "Iter 3040 | Time 15.4330(15.2517) | Bit/dim 3.6150(3.6074) | Xent 0.0000(0.0000) | Loss 8.1553(8.6711) | Error 0.0000(0.0000) Steps 550(545.02) | Grad Norm 9.4743(6.7693) | Total Time 0.00(0.00)\n",
      "Iter 3050 | Time 15.9634(15.2887) | Bit/dim 3.5930(3.6034) | Xent 0.0000(0.0000) | Loss 8.1131(8.5358) | Error 0.0000(0.0000) Steps 568(545.69) | Grad Norm 4.6073(6.6307) | Total Time 0.00(0.00)\n",
      "Iter 3060 | Time 14.8767(15.2841) | Bit/dim 3.5927(3.6048) | Xent 0.0000(0.0000) | Loss 8.0687(8.4443) | Error 0.0000(0.0000) Steps 538(544.96) | Grad Norm 3.8579(6.2863) | Total Time 0.00(0.00)\n",
      "Iter 3070 | Time 15.0195(15.2385) | Bit/dim 3.5867(3.6056) | Xent 0.0000(0.0000) | Loss 8.1169(8.3772) | Error 0.0000(0.0000) Steps 538(544.53) | Grad Norm 4.6703(6.5329) | Total Time 0.00(0.00)\n",
      "Iter 3080 | Time 15.2973(15.2448) | Bit/dim 3.6193(3.6077) | Xent 0.0000(0.0000) | Loss 8.2018(8.3283) | Error 0.0000(0.0000) Steps 544(544.14) | Grad Norm 5.1200(6.7124) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 80.0704, Epoch Time 946.6670(888.4511), Bit/dim 3.6046(best: 3.6088), Xent 0.0000, Loss 3.6046, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3090 | Time 15.4785(15.2252) | Bit/dim 3.5972(3.6074) | Xent 0.0000(0.0000) | Loss 8.0641(8.7398) | Error 0.0000(0.0000) Steps 556(543.54) | Grad Norm 6.0911(6.8538) | Total Time 0.00(0.00)\n",
      "Iter 3100 | Time 15.2786(15.1595) | Bit/dim 3.5777(3.6045) | Xent 0.0000(0.0000) | Loss 8.1058(8.5860) | Error 0.0000(0.0000) Steps 544(544.08) | Grad Norm 8.1789(6.8322) | Total Time 0.00(0.00)\n",
      "Iter 3110 | Time 14.5470(15.1501) | Bit/dim 3.6043(3.6023) | Xent 0.0000(0.0000) | Loss 8.1355(8.4718) | Error 0.0000(0.0000) Steps 526(543.44) | Grad Norm 4.5985(6.6419) | Total Time 0.00(0.00)\n",
      "Iter 3120 | Time 15.3970(15.1565) | Bit/dim 3.6093(3.6033) | Xent 0.0000(0.0000) | Loss 8.1177(8.3815) | Error 0.0000(0.0000) Steps 532(542.87) | Grad Norm 6.7266(6.7560) | Total Time 0.00(0.00)\n",
      "Iter 3130 | Time 14.9231(15.1630) | Bit/dim 3.6211(3.6011) | Xent 0.0000(0.0000) | Loss 8.1680(8.3229) | Error 0.0000(0.0000) Steps 520(542.16) | Grad Norm 4.9931(6.9198) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 90.6853, Epoch Time 956.0233(890.4783), Bit/dim 3.6021(best: 3.6046), Xent 0.0000, Loss 3.6021, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3140 | Time 14.9740(15.1858) | Bit/dim 3.5660(3.6008) | Xent 0.0000(0.0000) | Loss 8.1536(8.8380) | Error 0.0000(0.0000) Steps 556(545.60) | Grad Norm 7.6411(6.6322) | Total Time 0.00(0.00)\n",
      "Iter 3150 | Time 15.4216(15.2537) | Bit/dim 3.5588(3.5995) | Xent 0.0000(0.0000) | Loss 8.1607(8.6637) | Error 0.0000(0.0000) Steps 538(545.20) | Grad Norm 5.5795(6.5216) | Total Time 0.00(0.00)\n",
      "Iter 3160 | Time 15.4212(15.2684) | Bit/dim 3.6377(3.5992) | Xent 0.0000(0.0000) | Loss 8.2974(8.5291) | Error 0.0000(0.0000) Steps 526(542.38) | Grad Norm 5.3282(6.6408) | Total Time 0.00(0.00)\n",
      "Iter 3170 | Time 15.0048(15.3454) | Bit/dim 3.5692(3.5996) | Xent 0.0000(0.0000) | Loss 8.0706(8.4351) | Error 0.0000(0.0000) Steps 538(542.87) | Grad Norm 2.9949(5.9087) | Total Time 0.00(0.00)\n",
      "Iter 3180 | Time 15.5166(15.4072) | Bit/dim 3.5711(3.5985) | Xent 0.0000(0.0000) | Loss 8.0401(8.3570) | Error 0.0000(0.0000) Steps 550(544.28) | Grad Norm 5.1676(6.2588) | Total Time 0.00(0.00)\n",
      "Iter 3190 | Time 16.2987(15.4032) | Bit/dim 3.6184(3.6002) | Xent 0.0000(0.0000) | Loss 8.2591(8.3126) | Error 0.0000(0.0000) Steps 580(548.07) | Grad Norm 7.3697(6.3742) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 81.8259, Epoch Time 965.5107(892.7292), Bit/dim 3.5968(best: 3.6021), Xent 0.0000, Loss 3.5968, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3200 | Time 15.5496(15.4176) | Bit/dim 3.5849(3.6019) | Xent 0.0000(0.0000) | Loss 8.2680(8.7490) | Error 0.0000(0.0000) Steps 580(551.70) | Grad Norm 5.3340(6.6078) | Total Time 0.00(0.00)\n",
      "Iter 3210 | Time 15.6085(15.3969) | Bit/dim 3.5843(3.5990) | Xent 0.0000(0.0000) | Loss 8.1848(8.6019) | Error 0.0000(0.0000) Steps 538(550.18) | Grad Norm 6.7736(6.1925) | Total Time 0.00(0.00)\n",
      "Iter 3220 | Time 15.3961(15.4167) | Bit/dim 3.5852(3.5964) | Xent 0.0000(0.0000) | Loss 8.1715(8.4837) | Error 0.0000(0.0000) Steps 574(552.57) | Grad Norm 8.7483(6.6011) | Total Time 0.00(0.00)\n",
      "Iter 3230 | Time 14.9215(15.4184) | Bit/dim 3.5984(3.5955) | Xent 0.0000(0.0000) | Loss 8.2473(8.4042) | Error 0.0000(0.0000) Steps 544(556.40) | Grad Norm 4.3494(6.8254) | Total Time 0.00(0.00)\n",
      "Iter 3240 | Time 15.1065(15.4986) | Bit/dim 3.6009(3.5951) | Xent 0.0000(0.0000) | Loss 8.2351(8.3442) | Error 0.0000(0.0000) Steps 568(560.00) | Grad Norm 8.9451(6.4682) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 88.7454, Epoch Time 968.9269(895.0152), Bit/dim 3.5954(best: 3.5968), Xent 0.0000, Loss 3.5954, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3250 | Time 14.8339(15.5097) | Bit/dim 3.6105(3.5937) | Xent 0.0000(0.0000) | Loss 8.1471(8.8683) | Error 0.0000(0.0000) Steps 550(561.94) | Grad Norm 6.4216(6.8189) | Total Time 0.00(0.00)\n",
      "Iter 3260 | Time 15.1492(15.4729) | Bit/dim 3.5618(3.5907) | Xent 0.0000(0.0000) | Loss 8.0359(8.6740) | Error 0.0000(0.0000) Steps 562(560.53) | Grad Norm 5.0786(6.6552) | Total Time 0.00(0.00)\n",
      "Iter 3270 | Time 15.4926(15.5109) | Bit/dim 3.6009(3.5924) | Xent 0.0000(0.0000) | Loss 8.1526(8.5472) | Error 0.0000(0.0000) Steps 550(559.63) | Grad Norm 5.9887(6.0591) | Total Time 0.00(0.00)\n",
      "Iter 3280 | Time 16.1492(15.5675) | Bit/dim 3.5686(3.5958) | Xent 0.0000(0.0000) | Loss 8.1020(8.4529) | Error 0.0000(0.0000) Steps 598(561.51) | Grad Norm 2.6283(5.8738) | Total Time 0.00(0.00)\n",
      "Iter 3290 | Time 15.2671(15.6224) | Bit/dim 3.5709(3.5934) | Xent 0.0000(0.0000) | Loss 8.1500(8.3733) | Error 0.0000(0.0000) Steps 574(563.31) | Grad Norm 7.6957(6.1083) | Total Time 0.00(0.00)\n",
      "Iter 3300 | Time 15.2371(15.6405) | Bit/dim 3.5760(3.5902) | Xent 0.0000(0.0000) | Loss 8.1159(8.3137) | Error 0.0000(0.0000) Steps 580(563.48) | Grad Norm 3.6830(5.9642) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 83.5795, Epoch Time 969.2358(897.2418), Bit/dim 3.5868(best: 3.5954), Xent 0.0000, Loss 3.5868, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3310 | Time 15.4478(15.6770) | Bit/dim 3.5831(3.5891) | Xent 0.0000(0.0000) | Loss 8.2329(8.7462) | Error 0.0000(0.0000) Steps 550(562.67) | Grad Norm 3.2381(6.2078) | Total Time 0.00(0.00)\n",
      "Iter 3320 | Time 16.0747(15.6766) | Bit/dim 3.5511(3.5897) | Xent 0.0000(0.0000) | Loss 8.0826(8.5990) | Error 0.0000(0.0000) Steps 562(562.58) | Grad Norm 4.8510(6.3647) | Total Time 0.00(0.00)\n",
      "Iter 3330 | Time 16.5078(15.7292) | Bit/dim 3.6063(3.5904) | Xent 0.0000(0.0000) | Loss 8.2425(8.4892) | Error 0.0000(0.0000) Steps 556(562.61) | Grad Norm 7.5959(6.9218) | Total Time 0.00(0.00)\n",
      "Iter 3340 | Time 15.4359(15.6875) | Bit/dim 3.5623(3.5913) | Xent 0.0000(0.0000) | Loss 8.0814(8.4074) | Error 0.0000(0.0000) Steps 568(564.65) | Grad Norm 6.1705(6.9358) | Total Time 0.00(0.00)\n",
      "Iter 3350 | Time 14.8314(15.6897) | Bit/dim 3.6085(3.5930) | Xent 0.0000(0.0000) | Loss 8.1532(8.3431) | Error 0.0000(0.0000) Steps 544(564.39) | Grad Norm 3.2336(7.3584) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 83.0429, Epoch Time 973.4502(899.5280), Bit/dim 3.5903(best: 3.5868), Xent 0.0000, Loss 3.5903, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3360 | Time 15.9352(15.7157) | Bit/dim 3.5626(3.5904) | Xent 0.0000(0.0000) | Loss 8.1400(8.8443) | Error 0.0000(0.0000) Steps 562(567.05) | Grad Norm 5.8806(7.0278) | Total Time 0.00(0.00)\n",
      "Iter 3370 | Time 16.6324(15.7914) | Bit/dim 3.6223(3.5920) | Xent 0.0000(0.0000) | Loss 8.2909(8.6746) | Error 0.0000(0.0000) Steps 568(568.55) | Grad Norm 7.2946(6.5709) | Total Time 0.00(0.00)\n",
      "Iter 3380 | Time 15.4537(15.8082) | Bit/dim 3.5953(3.5893) | Xent 0.0000(0.0000) | Loss 8.2768(8.5400) | Error 0.0000(0.0000) Steps 574(570.80) | Grad Norm 3.3380(6.1164) | Total Time 0.00(0.00)\n",
      "Iter 3390 | Time 15.7540(15.8767) | Bit/dim 3.5546(3.5856) | Xent 0.0000(0.0000) | Loss 8.0533(8.4325) | Error 0.0000(0.0000) Steps 580(572.95) | Grad Norm 7.0867(5.8416) | Total Time 0.00(0.00)\n",
      "Iter 3400 | Time 16.0084(15.9486) | Bit/dim 3.5602(3.5871) | Xent 0.0000(0.0000) | Loss 8.0949(8.3689) | Error 0.0000(0.0000) Steps 592(574.84) | Grad Norm 5.1140(6.0339) | Total Time 0.00(0.00)\n",
      "Iter 3410 | Time 15.4928(15.9188) | Bit/dim 3.5759(3.5845) | Xent 0.0000(0.0000) | Loss 8.1755(8.3096) | Error 0.0000(0.0000) Steps 568(576.44) | Grad Norm 7.4403(6.0231) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 84.7340, Epoch Time 987.8985(902.1792), Bit/dim 3.5851(best: 3.5868), Xent 0.0000, Loss 3.5851, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3420 | Time 15.3891(15.9471) | Bit/dim 3.5653(3.5849) | Xent 0.0000(0.0000) | Loss 7.9382(8.7507) | Error 0.0000(0.0000) Steps 568(575.62) | Grad Norm 9.8008(6.2041) | Total Time 0.00(0.00)\n",
      "Iter 3430 | Time 16.0703(15.9584) | Bit/dim 3.5631(3.5821) | Xent 0.0000(0.0000) | Loss 8.1229(8.5915) | Error 0.0000(0.0000) Steps 568(575.81) | Grad Norm 7.8894(6.5409) | Total Time 0.00(0.00)\n",
      "Iter 3440 | Time 16.2639(15.9524) | Bit/dim 3.5646(3.5842) | Xent 0.0000(0.0000) | Loss 7.9675(8.4771) | Error 0.0000(0.0000) Steps 562(576.09) | Grad Norm 5.7499(6.3557) | Total Time 0.00(0.00)\n",
      "Iter 3450 | Time 15.4554(15.9504) | Bit/dim 3.5676(3.5848) | Xent 0.0000(0.0000) | Loss 8.0775(8.3955) | Error 0.0000(0.0000) Steps 556(575.84) | Grad Norm 7.5356(6.3800) | Total Time 0.00(0.00)\n",
      "Iter 3460 | Time 16.8096(15.9903) | Bit/dim 3.5655(3.5807) | Xent 0.0000(0.0000) | Loss 8.1089(8.3284) | Error 0.0000(0.0000) Steps 592(579.20) | Grad Norm 4.6947(6.3671) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 84.6407, Epoch Time 992.4668(904.8878), Bit/dim 3.5788(best: 3.5851), Xent 0.0000, Loss 3.5788, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3470 | Time 15.8084(15.9902) | Bit/dim 3.5817(3.5824) | Xent 0.0000(0.0000) | Loss 8.0488(8.8526) | Error 0.0000(0.0000) Steps 574(580.08) | Grad Norm 6.7743(6.1265) | Total Time 0.00(0.00)\n",
      "Iter 3480 | Time 16.7265(16.0003) | Bit/dim 3.5852(3.5827) | Xent 0.0000(0.0000) | Loss 8.1667(8.6745) | Error 0.0000(0.0000) Steps 586(580.97) | Grad Norm 5.5965(6.3729) | Total Time 0.00(0.00)\n",
      "Iter 3490 | Time 15.6503(15.9877) | Bit/dim 3.5625(3.5829) | Xent 0.0000(0.0000) | Loss 8.0197(8.5376) | Error 0.0000(0.0000) Steps 574(582.43) | Grad Norm 4.3286(6.4305) | Total Time 0.00(0.00)\n",
      "Iter 3500 | Time 16.0644(15.9753) | Bit/dim 3.5881(3.5807) | Xent 0.0000(0.0000) | Loss 8.1553(8.4381) | Error 0.0000(0.0000) Steps 586(583.03) | Grad Norm 7.0930(6.3299) | Total Time 0.00(0.00)\n",
      "Iter 3510 | Time 16.3512(15.9998) | Bit/dim 3.5725(3.5787) | Xent 0.0000(0.0000) | Loss 8.1075(8.3576) | Error 0.0000(0.0000) Steps 592(585.05) | Grad Norm 5.6017(6.6702) | Total Time 0.00(0.00)\n",
      "Iter 3520 | Time 16.7292(16.0711) | Bit/dim 3.5589(3.5781) | Xent 0.0000(0.0000) | Loss 8.0936(8.2998) | Error 0.0000(0.0000) Steps 598(586.37) | Grad Norm 6.2987(6.5777) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 84.6761, Epoch Time 987.1264(907.3549), Bit/dim 3.5805(best: 3.5788), Xent 0.0000, Loss 3.5805, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3530 | Time 17.0864(16.1460) | Bit/dim 3.5581(3.5769) | Xent 0.0000(0.0000) | Loss 8.1490(8.7529) | Error 0.0000(0.0000) Steps 592(587.71) | Grad Norm 3.4136(6.0739) | Total Time 0.00(0.00)\n",
      "Iter 3540 | Time 15.3296(16.0862) | Bit/dim 3.5837(3.5784) | Xent 0.0000(0.0000) | Loss 8.1317(8.6039) | Error 0.0000(0.0000) Steps 568(587.47) | Grad Norm 4.9784(5.7318) | Total Time 0.00(0.00)\n",
      "Iter 3550 | Time 15.7283(16.0867) | Bit/dim 3.5621(3.5808) | Xent 0.0000(0.0000) | Loss 8.1451(8.4964) | Error 0.0000(0.0000) Steps 574(586.30) | Grad Norm 9.1922(6.2748) | Total Time 0.00(0.00)\n",
      "Iter 3560 | Time 15.6717(16.0901) | Bit/dim 3.5563(3.5797) | Xent 0.0000(0.0000) | Loss 8.2137(8.4125) | Error 0.0000(0.0000) Steps 574(584.83) | Grad Norm 5.0222(6.2120) | Total Time 0.00(0.00)\n",
      "Iter 3570 | Time 15.7941(16.1424) | Bit/dim 3.5493(3.5751) | Xent 0.0000(0.0000) | Loss 8.1047(8.3392) | Error 0.0000(0.0000) Steps 580(586.58) | Grad Norm 8.0657(6.7480) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 85.3465, Epoch Time 994.9884(909.9839), Bit/dim 3.5776(best: 3.5788), Xent 0.0000, Loss 3.5776, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3580 | Time 16.5319(16.1734) | Bit/dim 3.5239(3.5723) | Xent 0.0000(0.0000) | Loss 8.1101(8.8532) | Error 0.0000(0.0000) Steps 580(587.50) | Grad Norm 4.0359(6.2600) | Total Time 0.00(0.00)\n",
      "Iter 3590 | Time 16.3952(16.2558) | Bit/dim 3.5984(3.5741) | Xent 0.0000(0.0000) | Loss 8.2217(8.6755) | Error 0.0000(0.0000) Steps 598(590.63) | Grad Norm 4.5622(6.4498) | Total Time 0.00(0.00)\n",
      "Iter 3600 | Time 15.5520(16.2421) | Bit/dim 3.5672(3.5735) | Xent 0.0000(0.0000) | Loss 8.1968(8.5406) | Error 0.0000(0.0000) Steps 592(593.32) | Grad Norm 6.2560(6.7331) | Total Time 0.00(0.00)\n",
      "Iter 3610 | Time 15.3303(16.2282) | Bit/dim 3.5724(3.5736) | Xent 0.0000(0.0000) | Loss 8.1435(8.4356) | Error 0.0000(0.0000) Steps 610(594.25) | Grad Norm 8.2504(6.9155) | Total Time 0.00(0.00)\n",
      "Iter 3620 | Time 16.4348(16.1793) | Bit/dim 3.5925(3.5713) | Xent 0.0000(0.0000) | Loss 8.2169(8.3597) | Error 0.0000(0.0000) Steps 586(591.24) | Grad Norm 5.1214(6.3938) | Total Time 0.00(0.00)\n",
      "Iter 3630 | Time 15.6145(16.1577) | Bit/dim 3.5853(3.5717) | Xent 0.0000(0.0000) | Loss 8.1625(8.3084) | Error 0.0000(0.0000) Steps 598(591.90) | Grad Norm 5.0250(6.0160) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 84.8832, Epoch Time 1002.8424(912.7697), Bit/dim 3.5734(best: 3.5776), Xent 0.0000, Loss 3.5734, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3640 | Time 16.2540(16.2007) | Bit/dim 3.5892(3.5742) | Xent 0.0000(0.0000) | Loss 8.1249(8.7725) | Error 0.0000(0.0000) Steps 574(589.93) | Grad Norm 8.8724(6.1761) | Total Time 0.00(0.00)\n",
      "Iter 3650 | Time 16.8082(16.1986) | Bit/dim 3.5771(3.5711) | Xent 0.0000(0.0000) | Loss 8.1699(8.6126) | Error 0.0000(0.0000) Steps 610(589.78) | Grad Norm 6.1396(6.1292) | Total Time 0.00(0.00)\n",
      "Iter 3660 | Time 16.2991(16.1818) | Bit/dim 3.5722(3.5711) | Xent 0.0000(0.0000) | Loss 8.1012(8.4873) | Error 0.0000(0.0000) Steps 586(590.69) | Grad Norm 5.8750(6.3333) | Total Time 0.00(0.00)\n",
      "Iter 3670 | Time 16.4500(16.2341) | Bit/dim 3.5714(3.5704) | Xent 0.0000(0.0000) | Loss 8.1312(8.3946) | Error 0.0000(0.0000) Steps 562(589.59) | Grad Norm 4.0008(5.9950) | Total Time 0.00(0.00)\n",
      "Iter 3680 | Time 17.2117(16.2633) | Bit/dim 3.5485(3.5698) | Xent 0.0000(0.0000) | Loss 8.1460(8.3305) | Error 0.0000(0.0000) Steps 604(588.56) | Grad Norm 6.7733(6.1728) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 86.2517, Epoch Time 1007.3960(915.6085), Bit/dim 3.5630(best: 3.5734), Xent 0.0000, Loss 3.5630, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3690 | Time 16.5533(16.2761) | Bit/dim 3.5992(3.5685) | Xent 0.0000(0.0000) | Loss 8.1205(8.8551) | Error 0.0000(0.0000) Steps 598(588.34) | Grad Norm 8.5027(5.8759) | Total Time 0.00(0.00)\n",
      "Iter 3700 | Time 15.6337(16.2587) | Bit/dim 3.5866(3.5696) | Xent 0.0000(0.0000) | Loss 8.1797(8.6704) | Error 0.0000(0.0000) Steps 592(591.10) | Grad Norm 4.9838(6.2545) | Total Time 0.00(0.00)\n",
      "Iter 3710 | Time 15.9808(16.1633) | Bit/dim 3.5674(3.5697) | Xent 0.0000(0.0000) | Loss 8.1275(8.5300) | Error 0.0000(0.0000) Steps 586(589.24) | Grad Norm 5.9341(6.2190) | Total Time 0.00(0.00)\n",
      "Iter 3720 | Time 16.2650(16.1687) | Bit/dim 3.5745(3.5680) | Xent 0.0000(0.0000) | Loss 8.2047(8.4265) | Error 0.0000(0.0000) Steps 580(588.39) | Grad Norm 9.5704(6.1074) | Total Time 0.00(0.00)\n",
      "Iter 3730 | Time 16.6741(16.2810) | Bit/dim 3.6051(3.5694) | Xent 0.0000(0.0000) | Loss 8.2812(8.3604) | Error 0.0000(0.0000) Steps 586(592.92) | Grad Norm 6.2340(6.1938) | Total Time 0.00(0.00)\n",
      "Iter 3740 | Time 17.1128(16.3257) | Bit/dim 3.5414(3.5687) | Xent 0.0000(0.0000) | Loss 8.1845(8.3058) | Error 0.0000(0.0000) Steps 604(592.45) | Grad Norm 5.2491(6.4349) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 86.1213, Epoch Time 1001.0056(918.1704), Bit/dim 3.5737(best: 3.5630), Xent 0.0000, Loss 3.5737, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3750 | Time 15.7046(16.3346) | Bit/dim 3.5246(3.5659) | Xent 0.0000(0.0000) | Loss 8.0081(8.7655) | Error 0.0000(0.0000) Steps 580(595.62) | Grad Norm 2.9175(6.3076) | Total Time 0.00(0.00)\n",
      "Iter 3760 | Time 15.6662(16.2969) | Bit/dim 3.5900(3.5662) | Xent 0.0000(0.0000) | Loss 8.0251(8.6011) | Error 0.0000(0.0000) Steps 562(593.91) | Grad Norm 10.8107(6.4706) | Total Time 0.00(0.00)\n",
      "Iter 3770 | Time 16.6089(16.2745) | Bit/dim 3.5924(3.5690) | Xent 0.0000(0.0000) | Loss 8.2649(8.4949) | Error 0.0000(0.0000) Steps 634(594.77) | Grad Norm 4.4860(6.4592) | Total Time 0.00(0.00)\n",
      "Iter 3780 | Time 16.3663(16.2779) | Bit/dim 3.5458(3.5676) | Xent 0.0000(0.0000) | Loss 8.2120(8.4098) | Error 0.0000(0.0000) Steps 616(596.21) | Grad Norm 4.8302(6.4994) | Total Time 0.00(0.00)\n",
      "Iter 3790 | Time 16.1486(16.2971) | Bit/dim 3.5215(3.5658) | Xent 0.0000(0.0000) | Loss 8.1736(8.3455) | Error 0.0000(0.0000) Steps 586(597.17) | Grad Norm 8.2789(6.3220) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 85.7893, Epoch Time 1006.6629(920.8252), Bit/dim 3.5682(best: 3.5630), Xent 0.0000, Loss 3.5682, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3800 | Time 16.2795(16.2829) | Bit/dim 3.5685(3.5682) | Xent 0.0000(0.0000) | Loss 8.1798(8.8633) | Error 0.0000(0.0000) Steps 598(597.21) | Grad Norm 11.1683(6.3651) | Total Time 0.00(0.00)\n",
      "Iter 3810 | Time 16.1290(16.2768) | Bit/dim 3.5764(3.5696) | Xent 0.0000(0.0000) | Loss 8.2390(8.6891) | Error 0.0000(0.0000) Steps 616(597.97) | Grad Norm 5.9743(6.2916) | Total Time 0.00(0.00)\n",
      "Iter 3820 | Time 16.5986(16.3172) | Bit/dim 3.5675(3.5679) | Xent 0.0000(0.0000) | Loss 8.1797(8.5494) | Error 0.0000(0.0000) Steps 622(601.32) | Grad Norm 8.4280(6.1705) | Total Time 0.00(0.00)\n",
      "Iter 3830 | Time 17.1368(16.3781) | Bit/dim 3.5808(3.5676) | Xent 0.0000(0.0000) | Loss 8.1943(8.4368) | Error 0.0000(0.0000) Steps 604(599.52) | Grad Norm 3.4661(6.0294) | Total Time 0.00(0.00)\n",
      "Iter 3840 | Time 16.5480(16.3601) | Bit/dim 3.5757(3.5658) | Xent 0.0000(0.0000) | Loss 8.1624(8.3525) | Error 0.0000(0.0000) Steps 616(599.96) | Grad Norm 9.3092(5.9612) | Total Time 0.00(0.00)\n",
      "Iter 3850 | Time 15.6093(16.3402) | Bit/dim 3.5541(3.5631) | Xent 0.0000(0.0000) | Loss 8.2190(8.3055) | Error 0.0000(0.0000) Steps 604(602.94) | Grad Norm 5.1201(6.1483) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 86.9760, Epoch Time 1008.7869(923.4640), Bit/dim 3.5655(best: 3.5630), Xent 0.0000, Loss 3.5655, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3860 | Time 16.5437(16.2763) | Bit/dim 3.5467(3.5629) | Xent 0.0000(0.0000) | Loss 8.1844(8.7620) | Error 0.0000(0.0000) Steps 610(599.66) | Grad Norm 6.5504(6.0197) | Total Time 0.00(0.00)\n",
      "Iter 3870 | Time 16.1357(16.3048) | Bit/dim 3.5816(3.5619) | Xent 0.0000(0.0000) | Loss 8.0977(8.6038) | Error 0.0000(0.0000) Steps 592(598.62) | Grad Norm 5.0997(5.9354) | Total Time 0.00(0.00)\n",
      "Iter 3880 | Time 16.4222(16.3186) | Bit/dim 3.5652(3.5618) | Xent 0.0000(0.0000) | Loss 8.2514(8.4895) | Error 0.0000(0.0000) Steps 610(600.12) | Grad Norm 4.7453(6.0742) | Total Time 0.00(0.00)\n",
      "Iter 3890 | Time 15.6161(16.2787) | Bit/dim 3.5802(3.5599) | Xent 0.0000(0.0000) | Loss 8.2263(8.3911) | Error 0.0000(0.0000) Steps 580(599.62) | Grad Norm 4.5982(5.5897) | Total Time 0.00(0.00)\n",
      "Iter 3900 | Time 16.7898(16.3829) | Bit/dim 3.5758(3.5607) | Xent 0.0000(0.0000) | Loss 8.2358(8.3342) | Error 0.0000(0.0000) Steps 616(600.91) | Grad Norm 9.6378(6.0863) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 87.0929, Epoch Time 1012.4489(926.1336), Bit/dim 3.5632(best: 3.5630), Xent 0.0000, Loss 3.5632, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3910 | Time 15.7548(16.3725) | Bit/dim 3.5780(3.5634) | Xent 0.0000(0.0000) | Loss 8.1384(8.8361) | Error 0.0000(0.0000) Steps 586(601.98) | Grad Norm 4.3067(6.0012) | Total Time 0.00(0.00)\n",
      "Iter 3920 | Time 16.6861(16.4420) | Bit/dim 3.5309(3.5616) | Xent 0.0000(0.0000) | Loss 8.0955(8.6621) | Error 0.0000(0.0000) Steps 580(601.77) | Grad Norm 11.7351(6.1604) | Total Time 0.00(0.00)\n",
      "Iter 3930 | Time 16.2380(16.3355) | Bit/dim 3.5738(3.5597) | Xent 0.0000(0.0000) | Loss 8.1417(8.5203) | Error 0.0000(0.0000) Steps 580(598.57) | Grad Norm 4.5175(5.9801) | Total Time 0.00(0.00)\n",
      "Iter 3940 | Time 16.5511(16.4120) | Bit/dim 3.5713(3.5601) | Xent 0.0000(0.0000) | Loss 8.0680(8.4277) | Error 0.0000(0.0000) Steps 610(599.58) | Grad Norm 3.5871(5.8794) | Total Time 0.00(0.00)\n",
      "Iter 3950 | Time 15.5285(16.3582) | Bit/dim 3.5624(3.5575) | Xent 0.0000(0.0000) | Loss 8.0971(8.3432) | Error 0.0000(0.0000) Steps 592(597.35) | Grad Norm 4.1102(5.8309) | Total Time 0.00(0.00)\n",
      "Iter 3960 | Time 16.2432(16.3730) | Bit/dim 3.5704(3.5628) | Xent 0.0000(0.0000) | Loss 8.1163(8.2955) | Error 0.0000(0.0000) Steps 586(596.50) | Grad Norm 5.7314(6.1413) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 85.9636, Epoch Time 1011.9078(928.7068), Bit/dim 3.5618(best: 3.5630), Xent 0.0000, Loss 3.5618, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3970 | Time 16.3174(16.3683) | Bit/dim 3.5363(3.5592) | Xent 0.0000(0.0000) | Loss 8.1594(8.7464) | Error 0.0000(0.0000) Steps 616(596.71) | Grad Norm 7.7130(6.2560) | Total Time 0.00(0.00)\n",
      "Iter 3980 | Time 15.6251(16.3462) | Bit/dim 3.5809(3.5594) | Xent 0.0000(0.0000) | Loss 8.1866(8.5839) | Error 0.0000(0.0000) Steps 592(595.81) | Grad Norm 7.5154(6.3288) | Total Time 0.00(0.00)\n",
      "Iter 3990 | Time 16.5321(16.3613) | Bit/dim 3.5721(3.5601) | Xent 0.0000(0.0000) | Loss 8.2255(8.4755) | Error 0.0000(0.0000) Steps 598(596.75) | Grad Norm 5.5965(6.2694) | Total Time 0.00(0.00)\n",
      "Iter 4000 | Time 16.5040(16.3996) | Bit/dim 3.5911(3.5604) | Xent 0.0000(0.0000) | Loss 8.2642(8.3922) | Error 0.0000(0.0000) Steps 604(599.28) | Grad Norm 3.9973(6.2109) | Total Time 0.00(0.00)\n",
      "Iter 4010 | Time 16.6585(16.4165) | Bit/dim 3.5794(3.5602) | Xent 0.0000(0.0000) | Loss 8.1695(8.3336) | Error 0.0000(0.0000) Steps 604(601.17) | Grad Norm 7.4673(6.1404) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 87.4674, Epoch Time 1009.4925(931.1304), Bit/dim 3.5583(best: 3.5618), Xent 0.0000, Loss 3.5583, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4020 | Time 16.4909(16.3948) | Bit/dim 3.5548(3.5573) | Xent 0.0000(0.0000) | Loss 8.0717(8.8765) | Error 0.0000(0.0000) Steps 622(601.71) | Grad Norm 7.0142(6.1580) | Total Time 0.00(0.00)\n",
      "Iter 4030 | Time 16.0175(16.3858) | Bit/dim 3.5479(3.5549) | Xent 0.0000(0.0000) | Loss 8.1798(8.6828) | Error 0.0000(0.0000) Steps 598(601.98) | Grad Norm 5.6849(6.2597) | Total Time 0.00(0.00)\n",
      "Iter 4040 | Time 16.5911(16.4298) | Bit/dim 3.5558(3.5549) | Xent 0.0000(0.0000) | Loss 8.0292(8.5286) | Error 0.0000(0.0000) Steps 580(601.88) | Grad Norm 5.1266(5.9101) | Total Time 0.00(0.00)\n",
      "Iter 4050 | Time 15.8235(16.4247) | Bit/dim 3.5442(3.5539) | Xent 0.0000(0.0000) | Loss 8.1048(8.4285) | Error 0.0000(0.0000) Steps 592(601.97) | Grad Norm 6.5452(6.0720) | Total Time 0.00(0.00)\n",
      "Iter 4060 | Time 15.2391(16.3703) | Bit/dim 3.5446(3.5541) | Xent 0.0000(0.0000) | Loss 8.0420(8.3409) | Error 0.0000(0.0000) Steps 574(601.59) | Grad Norm 8.6682(6.0266) | Total Time 0.00(0.00)\n",
      "Iter 4070 | Time 16.5098(16.4808) | Bit/dim 3.5675(3.5538) | Xent 0.0000(0.0000) | Loss 8.1887(8.3002) | Error 0.0000(0.0000) Steps 610(602.87) | Grad Norm 4.5843(5.9492) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 88.4681, Epoch Time 1017.0348(933.7075), Bit/dim 3.5489(best: 3.5583), Xent 0.0000, Loss 3.5489, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4080 | Time 16.5852(16.5345) | Bit/dim 3.5684(3.5495) | Xent 0.0000(0.0000) | Loss 8.1797(8.7466) | Error 0.0000(0.0000) Steps 598(604.23) | Grad Norm 5.4338(5.9101) | Total Time 0.00(0.00)\n",
      "Iter 4090 | Time 17.1824(16.6115) | Bit/dim 3.5688(3.5557) | Xent 0.0000(0.0000) | Loss 8.2720(8.6011) | Error 0.0000(0.0000) Steps 622(607.67) | Grad Norm 4.9032(6.1852) | Total Time 0.00(0.00)\n",
      "Iter 4100 | Time 16.9653(16.6324) | Bit/dim 3.5528(3.5534) | Xent 0.0000(0.0000) | Loss 8.2041(8.4832) | Error 0.0000(0.0000) Steps 616(609.49) | Grad Norm 5.5352(6.1276) | Total Time 0.00(0.00)\n",
      "Iter 4110 | Time 16.3134(16.5981) | Bit/dim 3.5787(3.5534) | Xent 0.0000(0.0000) | Loss 8.2031(8.3886) | Error 0.0000(0.0000) Steps 640(610.84) | Grad Norm 3.8053(6.0678) | Total Time 0.00(0.00)\n",
      "Iter 4120 | Time 16.4768(16.6180) | Bit/dim 3.5623(3.5532) | Xent 0.0000(0.0000) | Loss 8.0264(8.3293) | Error 0.0000(0.0000) Steps 622(612.87) | Grad Norm 10.9659(6.5831) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 87.1444, Epoch Time 1030.8391(936.6215), Bit/dim 3.5561(best: 3.5489), Xent 0.0000, Loss 3.5561, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4130 | Time 16.9808(16.6618) | Bit/dim 3.5938(3.5553) | Xent 0.0000(0.0000) | Loss 8.2909(8.8505) | Error 0.0000(0.0000) Steps 622(612.94) | Grad Norm 5.5182(6.4449) | Total Time 0.00(0.00)\n",
      "Iter 4140 | Time 17.5048(16.8008) | Bit/dim 3.5317(3.5527) | Xent 0.0000(0.0000) | Loss 8.1638(8.6699) | Error 0.0000(0.0000) Steps 652(617.27) | Grad Norm 3.4537(6.0646) | Total Time 0.00(0.00)\n",
      "Iter 4150 | Time 16.6049(16.8012) | Bit/dim 3.5275(3.5518) | Xent 0.0000(0.0000) | Loss 8.1746(8.5409) | Error 0.0000(0.0000) Steps 622(618.70) | Grad Norm 5.5228(5.8971) | Total Time 0.00(0.00)\n",
      "Iter 4160 | Time 16.8585(16.8362) | Bit/dim 3.5614(3.5487) | Xent 0.0000(0.0000) | Loss 8.1800(8.4405) | Error 0.0000(0.0000) Steps 634(621.74) | Grad Norm 6.3274(5.9227) | Total Time 0.00(0.00)\n",
      "Iter 4170 | Time 17.6412(16.8988) | Bit/dim 3.5882(3.5526) | Xent 0.0000(0.0000) | Loss 8.3213(8.3786) | Error 0.0000(0.0000) Steps 652(622.15) | Grad Norm 3.4523(5.6663) | Total Time 0.00(0.00)\n",
      "Iter 4180 | Time 16.9258(16.9500) | Bit/dim 3.5593(3.5534) | Xent 0.0000(0.0000) | Loss 8.2144(8.3201) | Error 0.0000(0.0000) Steps 640(624.13) | Grad Norm 3.4571(5.8118) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 88.3296, Epoch Time 1050.2802(940.0312), Bit/dim 3.5486(best: 3.5489), Xent 0.0000, Loss 3.5486, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4190 | Time 17.1402(16.9698) | Bit/dim 3.5795(3.5516) | Xent 0.0000(0.0000) | Loss 8.2374(8.7533) | Error 0.0000(0.0000) Steps 628(626.42) | Grad Norm 5.8791(5.5971) | Total Time 0.00(0.00)\n",
      "Iter 4200 | Time 17.8271(17.0530) | Bit/dim 3.5304(3.5495) | Xent 0.0000(0.0000) | Loss 8.1174(8.5875) | Error 0.0000(0.0000) Steps 628(627.96) | Grad Norm 5.5119(5.9621) | Total Time 0.00(0.00)\n",
      "Iter 4210 | Time 17.0177(17.0436) | Bit/dim 3.5510(3.5492) | Xent 0.0000(0.0000) | Loss 8.1851(8.4737) | Error 0.0000(0.0000) Steps 640(629.56) | Grad Norm 6.9735(5.9429) | Total Time 0.00(0.00)\n",
      "Iter 4220 | Time 16.8535(17.0262) | Bit/dim 3.5740(3.5494) | Xent 0.0000(0.0000) | Loss 7.9783(8.3795) | Error 0.0000(0.0000) Steps 616(631.54) | Grad Norm 7.3639(5.8666) | Total Time 0.00(0.00)\n",
      "Iter 4230 | Time 16.6671(17.0930) | Bit/dim 3.5280(3.5485) | Xent 0.0000(0.0000) | Loss 8.0683(8.3171) | Error 0.0000(0.0000) Steps 622(630.65) | Grad Norm 5.7973(5.6712) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 88.4552, Epoch Time 1054.9874(943.4799), Bit/dim 3.5464(best: 3.5486), Xent 0.0000, Loss 3.5464, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4240 | Time 16.8705(17.1805) | Bit/dim 3.5449(3.5477) | Xent 0.0000(0.0000) | Loss 8.2191(8.8529) | Error 0.0000(0.0000) Steps 634(630.80) | Grad Norm 3.5017(5.8031) | Total Time 0.00(0.00)\n",
      "Iter 4250 | Time 16.9839(17.1479) | Bit/dim 3.5580(3.5469) | Xent 0.0000(0.0000) | Loss 8.1557(8.6619) | Error 0.0000(0.0000) Steps 652(633.48) | Grad Norm 11.1469(5.6221) | Total Time 0.00(0.00)\n",
      "Iter 4260 | Time 17.1245(17.1747) | Bit/dim 3.5853(3.5467) | Xent 0.0000(0.0000) | Loss 8.1679(8.5361) | Error 0.0000(0.0000) Steps 616(634.89) | Grad Norm 5.6984(5.8535) | Total Time 0.00(0.00)\n",
      "Iter 4270 | Time 17.1956(17.2132) | Bit/dim 3.5360(3.5444) | Xent 0.0000(0.0000) | Loss 8.0573(8.4220) | Error 0.0000(0.0000) Steps 658(634.59) | Grad Norm 5.0589(5.4954) | Total Time 0.00(0.00)\n",
      "Iter 4280 | Time 17.2069(17.2549) | Bit/dim 3.5223(3.5438) | Xent 0.0000(0.0000) | Loss 8.0041(8.3500) | Error 0.0000(0.0000) Steps 640(633.92) | Grad Norm 4.7801(5.1326) | Total Time 0.00(0.00)\n",
      "Iter 4290 | Time 16.5581(17.2386) | Bit/dim 3.5496(3.5451) | Xent 0.0000(0.0000) | Loss 8.1228(8.2939) | Error 0.0000(0.0000) Steps 634(634.48) | Grad Norm 5.2701(5.7455) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 88.4151, Epoch Time 1068.0688(947.2176), Bit/dim 3.5462(best: 3.5464), Xent 0.0000, Loss 3.5462, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4300 | Time 16.4627(17.2384) | Bit/dim 3.5351(3.5429) | Xent 0.0000(0.0000) | Loss 7.9436(8.7577) | Error 0.0000(0.0000) Steps 622(634.55) | Grad Norm 7.6933(5.7725) | Total Time 0.00(0.00)\n",
      "Iter 4310 | Time 17.0360(17.2456) | Bit/dim 3.5193(3.5413) | Xent 0.0000(0.0000) | Loss 8.1513(8.5965) | Error 0.0000(0.0000) Steps 640(636.60) | Grad Norm 4.6010(5.8706) | Total Time 0.00(0.00)\n",
      "Iter 4320 | Time 17.4184(17.3658) | Bit/dim 3.5212(3.5431) | Xent 0.0000(0.0000) | Loss 8.1600(8.4879) | Error 0.0000(0.0000) Steps 616(639.16) | Grad Norm 5.5793(6.1903) | Total Time 0.00(0.00)\n",
      "Iter 4330 | Time 17.4869(17.3511) | Bit/dim 3.5528(3.5422) | Xent 0.0000(0.0000) | Loss 8.2398(8.4001) | Error 0.0000(0.0000) Steps 658(641.51) | Grad Norm 7.0503(6.1575) | Total Time 0.00(0.00)\n",
      "Iter 4340 | Time 16.6484(17.2993) | Bit/dim 3.5122(3.5414) | Xent 0.0000(0.0000) | Loss 8.0056(8.3258) | Error 0.0000(0.0000) Steps 646(640.66) | Grad Norm 5.6729(6.0517) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 89.7514, Epoch Time 1063.6279(950.7099), Bit/dim 3.5416(best: 3.5462), Xent 0.0000, Loss 3.5416, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4350 | Time 18.2765(17.3283) | Bit/dim 3.5387(3.5415) | Xent 0.0000(0.0000) | Loss 8.2777(8.8708) | Error 0.0000(0.0000) Steps 628(639.42) | Grad Norm 6.6136(5.8548) | Total Time 0.00(0.00)\n",
      "Iter 4360 | Time 17.5662(17.3928) | Bit/dim 3.5220(3.5394) | Xent 0.0000(0.0000) | Loss 8.0317(8.6733) | Error 0.0000(0.0000) Steps 616(640.61) | Grad Norm 3.8298(5.6573) | Total Time 0.00(0.00)\n",
      "Iter 4370 | Time 16.8721(17.4179) | Bit/dim 3.5598(3.5407) | Xent 0.0000(0.0000) | Loss 8.1449(8.5452) | Error 0.0000(0.0000) Steps 634(640.04) | Grad Norm 8.0054(5.6742) | Total Time 0.00(0.00)\n",
      "Iter 4380 | Time 17.2986(17.4754) | Bit/dim 3.5093(3.5408) | Xent 0.0000(0.0000) | Loss 8.1763(8.4437) | Error 0.0000(0.0000) Steps 658(641.65) | Grad Norm 6.2804(6.0873) | Total Time 0.00(0.00)\n",
      "Iter 4390 | Time 18.4370(17.4814) | Bit/dim 3.5289(3.5403) | Xent 0.0000(0.0000) | Loss 8.1482(8.3644) | Error 0.0000(0.0000) Steps 634(641.41) | Grad Norm 5.9116(6.0220) | Total Time 0.00(0.00)\n",
      "Iter 4400 | Time 17.8073(17.5503) | Bit/dim 3.5347(3.5402) | Xent 0.0000(0.0000) | Loss 8.1873(8.3082) | Error 0.0000(0.0000) Steps 658(644.02) | Grad Norm 6.9209(6.3072) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 90.4021, Epoch Time 1077.7814(954.5220), Bit/dim 3.5422(best: 3.5416), Xent 0.0000, Loss 3.5422, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4410 | Time 17.7748(17.6045) | Bit/dim 3.5609(3.5404) | Xent 0.0000(0.0000) | Loss 8.2202(8.7881) | Error 0.0000(0.0000) Steps 652(645.88) | Grad Norm 7.8463(6.0939) | Total Time 0.00(0.00)\n",
      "Iter 4420 | Time 17.3668(17.5873) | Bit/dim 3.5213(3.5400) | Xent 0.0000(0.0000) | Loss 8.0568(8.6151) | Error 0.0000(0.0000) Steps 646(647.99) | Grad Norm 6.5847(5.8291) | Total Time 0.00(0.00)\n",
      "Iter 4430 | Time 17.8108(17.6620) | Bit/dim 3.5097(3.5372) | Xent 0.0000(0.0000) | Loss 8.0919(8.4862) | Error 0.0000(0.0000) Steps 646(648.25) | Grad Norm 6.6696(5.9500) | Total Time 0.00(0.00)\n",
      "Iter 4440 | Time 18.1816(17.7295) | Bit/dim 3.5331(3.5346) | Xent 0.0000(0.0000) | Loss 8.2495(8.4022) | Error 0.0000(0.0000) Steps 634(650.58) | Grad Norm 6.0336(5.7777) | Total Time 0.00(0.00)\n",
      "Iter 4450 | Time 17.9165(17.7080) | Bit/dim 3.4999(3.5371) | Xent 0.0000(0.0000) | Loss 8.1036(8.3338) | Error 0.0000(0.0000) Steps 646(650.49) | Grad Norm 6.5737(6.0521) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 90.8148, Epoch Time 1087.4389(958.5095), Bit/dim 3.5354(best: 3.5416), Xent 0.0000, Loss 3.5354, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4460 | Time 17.4693(17.7034) | Bit/dim 3.5021(3.5365) | Xent 0.0000(0.0000) | Loss 8.1104(8.8586) | Error 0.0000(0.0000) Steps 628(648.97) | Grad Norm 6.8460(5.8758) | Total Time 0.00(0.00)\n",
      "Iter 4470 | Time 18.2351(17.6922) | Bit/dim 3.5408(3.5375) | Xent 0.0000(0.0000) | Loss 8.1950(8.6698) | Error 0.0000(0.0000) Steps 682(651.53) | Grad Norm 7.2352(6.1778) | Total Time 0.00(0.00)\n",
      "Iter 4480 | Time 17.0505(17.7214) | Bit/dim 3.5341(3.5376) | Xent 0.0000(0.0000) | Loss 8.1966(8.5362) | Error 0.0000(0.0000) Steps 658(654.74) | Grad Norm 7.2014(5.9098) | Total Time 0.00(0.00)\n",
      "Iter 4490 | Time 18.0193(17.7542) | Bit/dim 3.5488(3.5365) | Xent 0.0000(0.0000) | Loss 8.2200(8.4332) | Error 0.0000(0.0000) Steps 676(657.14) | Grad Norm 7.7348(5.8583) | Total Time 0.00(0.00)\n",
      "Iter 4500 | Time 16.9929(17.7777) | Bit/dim 3.5092(3.5369) | Xent 0.0000(0.0000) | Loss 8.0643(8.3582) | Error 0.0000(0.0000) Steps 640(658.42) | Grad Norm 5.1008(5.9892) | Total Time 0.00(0.00)\n",
      "Iter 4510 | Time 17.6876(17.8422) | Bit/dim 3.5479(3.5376) | Xent 0.0000(0.0000) | Loss 8.1331(8.3112) | Error 0.0000(0.0000) Steps 652(657.90) | Grad Norm 8.5031(5.9756) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 92.3595, Epoch Time 1094.8938(962.6011), Bit/dim 3.5377(best: 3.5354), Xent 0.0000, Loss 3.5377, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4520 | Time 16.8162(17.7291) | Bit/dim 3.5534(3.5385) | Xent 0.0000(0.0000) | Loss 8.1464(8.7811) | Error 0.0000(0.0000) Steps 628(654.05) | Grad Norm 4.3867(5.9367) | Total Time 0.00(0.00)\n",
      "Iter 4530 | Time 17.8595(17.8166) | Bit/dim 3.5314(3.5380) | Xent 0.0000(0.0000) | Loss 8.1020(8.6161) | Error 0.0000(0.0000) Steps 676(657.36) | Grad Norm 7.7976(5.9327) | Total Time 0.00(0.00)\n",
      "Iter 4540 | Time 17.9249(17.8744) | Bit/dim 3.5565(3.5365) | Xent 0.0000(0.0000) | Loss 8.1329(8.4919) | Error 0.0000(0.0000) Steps 676(660.97) | Grad Norm 7.1653(5.9468) | Total Time 0.00(0.00)\n",
      "Iter 4550 | Time 18.1514(17.8989) | Bit/dim 3.5308(3.5365) | Xent 0.0000(0.0000) | Loss 8.0490(8.4071) | Error 0.0000(0.0000) Steps 664(661.54) | Grad Norm 7.9779(5.9287) | Total Time 0.00(0.00)\n",
      "Iter 4560 | Time 17.3712(17.9669) | Bit/dim 3.5164(3.5336) | Xent 0.0000(0.0000) | Loss 8.1021(8.3269) | Error 0.0000(0.0000) Steps 700(660.35) | Grad Norm 6.0990(5.9119) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 91.3265, Epoch Time 1099.5304(966.7089), Bit/dim 3.5299(best: 3.5354), Xent 0.0000, Loss 3.5299, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4570 | Time 17.6488(17.9897) | Bit/dim 3.5214(3.5325) | Xent 0.0000(0.0000) | Loss 8.1749(8.8750) | Error 0.0000(0.0000) Steps 676(663.42) | Grad Norm 5.3031(5.4084) | Total Time 0.00(0.00)\n",
      "Iter 4580 | Time 18.5119(18.0363) | Bit/dim 3.5199(3.5308) | Xent 0.0000(0.0000) | Loss 8.0598(8.6796) | Error 0.0000(0.0000) Steps 664(666.30) | Grad Norm 6.0932(5.6083) | Total Time 0.00(0.00)\n",
      "Iter 4590 | Time 17.5467(18.0756) | Bit/dim 3.5287(3.5318) | Xent 0.0000(0.0000) | Loss 8.0269(8.5398) | Error 0.0000(0.0000) Steps 622(665.69) | Grad Norm 3.4950(5.5186) | Total Time 0.00(0.00)\n",
      "Iter 4600 | Time 18.4526(18.1340) | Bit/dim 3.5442(3.5303) | Xent 0.0000(0.0000) | Loss 8.2049(8.4340) | Error 0.0000(0.0000) Steps 682(666.47) | Grad Norm 6.3751(5.8076) | Total Time 0.00(0.00)\n",
      "Iter 4610 | Time 18.3914(18.1702) | Bit/dim 3.5226(3.5317) | Xent 0.0000(0.0000) | Loss 8.1502(8.3618) | Error 0.0000(0.0000) Steps 658(664.68) | Grad Norm 4.1706(5.3409) | Total Time 0.00(0.00)\n",
      "Iter 4620 | Time 18.2076(18.1928) | Bit/dim 3.5170(3.5308) | Xent 0.0000(0.0000) | Loss 8.1699(8.2986) | Error 0.0000(0.0000) Steps 682(667.34) | Grad Norm 5.3320(5.4293) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 91.3306, Epoch Time 1113.1711(971.1028), Bit/dim 3.5312(best: 3.5299), Xent 0.0000, Loss 3.5312, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4630 | Time 18.7232(18.2206) | Bit/dim 3.5350(3.5300) | Xent 0.0000(0.0000) | Loss 8.1704(8.7623) | Error 0.0000(0.0000) Steps 676(667.57) | Grad Norm 7.1776(5.6644) | Total Time 0.00(0.00)\n",
      "Iter 4640 | Time 18.7377(18.2388) | Bit/dim 3.5283(3.5310) | Xent 0.0000(0.0000) | Loss 8.0697(8.6054) | Error 0.0000(0.0000) Steps 676(669.42) | Grad Norm 4.4969(5.5366) | Total Time 0.00(0.00)\n",
      "Iter 4650 | Time 17.7390(18.1567) | Bit/dim 3.5239(3.5306) | Xent 0.0000(0.0000) | Loss 8.2324(8.4869) | Error 0.0000(0.0000) Steps 688(667.91) | Grad Norm 8.2136(5.8174) | Total Time 0.00(0.00)\n",
      "Iter 4660 | Time 18.5974(18.2545) | Bit/dim 3.5479(3.5289) | Xent 0.0000(0.0000) | Loss 8.1912(8.3993) | Error 0.0000(0.0000) Steps 682(670.22) | Grad Norm 5.5946(5.5601) | Total Time 0.00(0.00)\n",
      "Iter 4670 | Time 17.9323(18.2321) | Bit/dim 3.4933(3.5275) | Xent 0.0000(0.0000) | Loss 8.0332(8.3317) | Error 0.0000(0.0000) Steps 622(668.94) | Grad Norm 4.5626(5.5831) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 91.8661, Epoch Time 1126.2330(975.7567), Bit/dim 3.5326(best: 3.5299), Xent 0.0000, Loss 3.5326, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4680 | Time 17.8090(18.2659) | Bit/dim 3.5352(3.5292) | Xent 0.0000(0.0000) | Loss 8.1485(8.8967) | Error 0.0000(0.0000) Steps 676(672.86) | Grad Norm 5.3269(5.4577) | Total Time 0.00(0.00)\n",
      "Iter 4690 | Time 18.1599(18.2523) | Bit/dim 3.5328(3.5281) | Xent 0.0000(0.0000) | Loss 8.1131(8.6979) | Error 0.0000(0.0000) Steps 670(676.06) | Grad Norm 3.3830(5.7483) | Total Time 0.00(0.00)\n",
      "Iter 4700 | Time 18.0976(18.2695) | Bit/dim 3.5305(3.5295) | Xent 0.0000(0.0000) | Loss 8.2530(8.5588) | Error 0.0000(0.0000) Steps 688(674.72) | Grad Norm 5.4605(5.3679) | Total Time 0.00(0.00)\n",
      "Iter 4710 | Time 18.4998(18.3305) | Bit/dim 3.5327(3.5299) | Xent 0.0000(0.0000) | Loss 8.1351(8.4552) | Error 0.0000(0.0000) Steps 664(677.13) | Grad Norm 4.8306(5.9961) | Total Time 0.00(0.00)\n",
      "Iter 4720 | Time 18.5421(18.3584) | Bit/dim 3.5345(3.5278) | Xent 0.0000(0.0000) | Loss 8.1199(8.3720) | Error 0.0000(0.0000) Steps 664(676.06) | Grad Norm 9.1734(5.9080) | Total Time 0.00(0.00)\n",
      "Iter 4730 | Time 17.8851(18.3506) | Bit/dim 3.5194(3.5277) | Xent 0.0000(0.0000) | Loss 8.0319(8.3130) | Error 0.0000(0.0000) Steps 658(676.41) | Grad Norm 3.9681(5.9280) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 91.3550, Epoch Time 1131.4256(980.4268), Bit/dim 3.5315(best: 3.5299), Xent 0.0000, Loss 3.5315, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4740 | Time 18.4418(18.3664) | Bit/dim 3.5324(3.5251) | Xent 0.0000(0.0000) | Loss 8.2774(8.7840) | Error 0.0000(0.0000) Steps 688(676.77) | Grad Norm 5.3482(5.6375) | Total Time 0.00(0.00)\n",
      "Iter 4750 | Time 18.1216(18.3897) | Bit/dim 3.4851(3.5256) | Xent 0.0000(0.0000) | Loss 8.0427(8.6152) | Error 0.0000(0.0000) Steps 688(675.19) | Grad Norm 4.2843(5.3699) | Total Time 0.00(0.00)\n",
      "Iter 4760 | Time 19.4405(18.3600) | Bit/dim 3.5073(3.5260) | Xent 0.0000(0.0000) | Loss 8.1970(8.5049) | Error 0.0000(0.0000) Steps 688(675.92) | Grad Norm 7.3217(5.7560) | Total Time 0.00(0.00)\n",
      "Iter 4770 | Time 19.1201(18.4356) | Bit/dim 3.5460(3.5263) | Xent 0.0000(0.0000) | Loss 8.1437(8.4089) | Error 0.0000(0.0000) Steps 658(674.70) | Grad Norm 4.5069(5.7029) | Total Time 0.00(0.00)\n",
      "Iter 4780 | Time 18.5304(18.3932) | Bit/dim 3.5047(3.5262) | Xent 0.0000(0.0000) | Loss 7.9879(8.3269) | Error 0.0000(0.0000) Steps 652(669.23) | Grad Norm 4.3388(5.6961) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 90.5267, Epoch Time 1130.9736(984.9432), Bit/dim 3.5235(best: 3.5299), Xent 0.0000, Loss 3.5235, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4790 | Time 18.1603(18.4050) | Bit/dim 3.4893(3.5255) | Xent 0.0000(0.0000) | Loss 8.0193(8.8447) | Error 0.0000(0.0000) Steps 676(670.35) | Grad Norm 3.7704(5.4250) | Total Time 0.00(0.00)\n",
      "Iter 4800 | Time 18.0430(18.3225) | Bit/dim 3.5389(3.5277) | Xent 0.0000(0.0000) | Loss 8.1541(8.6611) | Error 0.0000(0.0000) Steps 694(671.25) | Grad Norm 7.7980(5.7287) | Total Time 0.00(0.00)\n",
      "Iter 4810 | Time 17.9055(18.2813) | Bit/dim 3.5650(3.5293) | Xent 0.0000(0.0000) | Loss 8.1988(8.5297) | Error 0.0000(0.0000) Steps 694(671.07) | Grad Norm 7.0430(5.9009) | Total Time 0.00(0.00)\n",
      "Iter 4820 | Time 17.6861(18.3503) | Bit/dim 3.4639(3.5267) | Xent 0.0000(0.0000) | Loss 8.0413(8.4358) | Error 0.0000(0.0000) Steps 652(672.60) | Grad Norm 5.3870(5.7785) | Total Time 0.00(0.00)\n",
      "Iter 4830 | Time 19.0214(18.4137) | Bit/dim 3.5393(3.5241) | Xent 0.0000(0.0000) | Loss 8.2162(8.3643) | Error 0.0000(0.0000) Steps 688(674.42) | Grad Norm 6.8787(5.6816) | Total Time 0.00(0.00)\n",
      "Iter 4840 | Time 17.9774(18.4510) | Bit/dim 3.5150(3.5230) | Xent 0.0000(0.0000) | Loss 8.0928(8.3067) | Error 0.0000(0.0000) Steps 694(673.83) | Grad Norm 5.3264(5.3852) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 90.7207, Epoch Time 1123.7636(989.1078), Bit/dim 3.5227(best: 3.5235), Xent 0.0000, Loss 3.5227, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4850 | Time 18.6823(18.4598) | Bit/dim 3.5251(3.5233) | Xent 0.0000(0.0000) | Loss 8.2533(8.7870) | Error 0.0000(0.0000) Steps 658(673.91) | Grad Norm 4.7874(5.4648) | Total Time 0.00(0.00)\n",
      "Iter 4860 | Time 18.0470(18.5032) | Bit/dim 3.5214(3.5220) | Xent 0.0000(0.0000) | Loss 8.2023(8.6088) | Error 0.0000(0.0000) Steps 646(672.05) | Grad Norm 7.7143(5.5671) | Total Time 0.00(0.00)\n",
      "Iter 4870 | Time 18.4671(18.5421) | Bit/dim 3.4862(3.5206) | Xent 0.0000(0.0000) | Loss 8.1480(8.4880) | Error 0.0000(0.0000) Steps 670(673.30) | Grad Norm 4.5964(5.7831) | Total Time 0.00(0.00)\n",
      "Iter 4880 | Time 18.9490(18.4567) | Bit/dim 3.5465(3.5199) | Xent 0.0000(0.0000) | Loss 8.2348(8.3959) | Error 0.0000(0.0000) Steps 706(672.25) | Grad Norm 5.8123(5.8701) | Total Time 0.00(0.00)\n",
      "Iter 4890 | Time 19.5580(18.4434) | Bit/dim 3.4988(3.5159) | Xent 0.0000(0.0000) | Loss 8.1457(8.3215) | Error 0.0000(0.0000) Steps 676(671.38) | Grad Norm 8.5558(5.5926) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 91.4932, Epoch Time 1127.0787(993.2469), Bit/dim 3.5250(best: 3.5227), Xent 0.0000, Loss 3.5250, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4900 | Time 18.7284(18.4715) | Bit/dim 3.5376(3.5207) | Xent 0.0000(0.0000) | Loss 8.1678(8.8709) | Error 0.0000(0.0000) Steps 688(672.30) | Grad Norm 4.8756(5.8006) | Total Time 0.00(0.00)\n",
      "Iter 4910 | Time 18.3733(18.4468) | Bit/dim 3.5412(3.5195) | Xent 0.0000(0.0000) | Loss 8.1699(8.6776) | Error 0.0000(0.0000) Steps 676(673.05) | Grad Norm 6.6385(5.8822) | Total Time 0.00(0.00)\n",
      "Iter 4920 | Time 19.4877(18.4623) | Bit/dim 3.5391(3.5196) | Xent 0.0000(0.0000) | Loss 8.2155(8.5451) | Error 0.0000(0.0000) Steps 670(672.10) | Grad Norm 2.7028(5.7094) | Total Time 0.00(0.00)\n",
      "Iter 4930 | Time 17.8182(18.4924) | Bit/dim 3.4989(3.5196) | Xent 0.0000(0.0000) | Loss 8.0248(8.4487) | Error 0.0000(0.0000) Steps 640(673.50) | Grad Norm 5.0489(5.7029) | Total Time 0.00(0.00)\n",
      "Iter 4940 | Time 18.8172(18.5168) | Bit/dim 3.5443(3.5194) | Xent 0.0000(0.0000) | Loss 8.2219(8.3765) | Error 0.0000(0.0000) Steps 670(676.94) | Grad Norm 4.6122(5.4478) | Total Time 0.00(0.00)\n",
      "Iter 4950 | Time 18.5403(18.4969) | Bit/dim 3.5362(3.5183) | Xent 0.0000(0.0000) | Loss 8.1823(8.3135) | Error 0.0000(0.0000) Steps 706(678.74) | Grad Norm 5.1519(5.5837) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 92.9708, Epoch Time 1139.3666(997.6305), Bit/dim 3.5212(best: 3.5227), Xent 0.0000, Loss 3.5212, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4960 | Time 18.2252(18.4945) | Bit/dim 3.5341(3.5183) | Xent 0.0000(0.0000) | Loss 8.1397(8.7964) | Error 0.0000(0.0000) Steps 694(679.75) | Grad Norm 5.2889(5.4597) | Total Time 0.00(0.00)\n",
      "Iter 4970 | Time 18.8314(18.5367) | Bit/dim 3.4656(3.5162) | Xent 0.0000(0.0000) | Loss 8.0584(8.6285) | Error 0.0000(0.0000) Steps 694(679.37) | Grad Norm 5.0107(5.3870) | Total Time 0.00(0.00)\n",
      "Iter 4980 | Time 18.8271(18.6668) | Bit/dim 3.5227(3.5169) | Xent 0.0000(0.0000) | Loss 8.1542(8.5035) | Error 0.0000(0.0000) Steps 730(684.16) | Grad Norm 3.8990(5.5072) | Total Time 0.00(0.00)\n",
      "Iter 4990 | Time 18.2968(18.5958) | Bit/dim 3.5455(3.5173) | Xent 0.0000(0.0000) | Loss 8.1910(8.4084) | Error 0.0000(0.0000) Steps 670(682.70) | Grad Norm 4.4707(5.6628) | Total Time 0.00(0.00)\n",
      "Iter 5000 | Time 17.7286(18.6078) | Bit/dim 3.5082(3.5184) | Xent 0.0000(0.0000) | Loss 8.0159(8.3384) | Error 0.0000(0.0000) Steps 670(682.64) | Grad Norm 4.8570(5.6822) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 92.7190, Epoch Time 1138.8781(1001.8679), Bit/dim 3.5214(best: 3.5212), Xent 0.0000, Loss 3.5214, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5010 | Time 18.4442(18.6277) | Bit/dim 3.5037(3.5203) | Xent 0.0000(0.0000) | Loss 8.0988(8.9094) | Error 0.0000(0.0000) Steps 688(683.83) | Grad Norm 4.8113(5.9790) | Total Time 0.00(0.00)\n",
      "Iter 5020 | Time 18.8301(18.6353) | Bit/dim 3.4946(3.5163) | Xent 0.0000(0.0000) | Loss 8.0999(8.7078) | Error 0.0000(0.0000) Steps 700(684.56) | Grad Norm 5.8084(5.8617) | Total Time 0.00(0.00)\n",
      "Iter 5030 | Time 18.1079(18.5795) | Bit/dim 3.4779(3.5136) | Xent 0.0000(0.0000) | Loss 8.1346(8.5550) | Error 0.0000(0.0000) Steps 700(682.45) | Grad Norm 4.3373(5.7762) | Total Time 0.00(0.00)\n",
      "Iter 5040 | Time 18.2693(18.5176) | Bit/dim 3.5115(3.5152) | Xent 0.0000(0.0000) | Loss 8.1133(8.4546) | Error 0.0000(0.0000) Steps 664(684.00) | Grad Norm 4.5565(5.9270) | Total Time 0.00(0.00)\n",
      "Iter 5050 | Time 18.9815(18.5694) | Bit/dim 3.5183(3.5166) | Xent 0.0000(0.0000) | Loss 8.0328(8.3676) | Error 0.0000(0.0000) Steps 730(685.54) | Grad Norm 3.9508(5.3303) | Total Time 0.00(0.00)\n",
      "Iter 5060 | Time 18.4251(18.5636) | Bit/dim 3.5024(3.5160) | Xent 0.0000(0.0000) | Loss 8.2652(8.3211) | Error 0.0000(0.0000) Steps 706(686.94) | Grad Norm 4.4731(5.4824) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 93.3872, Epoch Time 1140.0831(1006.0144), Bit/dim 3.5169(best: 3.5212), Xent 0.0000, Loss 3.5169, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5070 | Time 19.4496(18.6582) | Bit/dim 3.5357(3.5157) | Xent 0.0000(0.0000) | Loss 8.3382(8.8277) | Error 0.0000(0.0000) Steps 718(690.32) | Grad Norm 4.4783(5.2974) | Total Time 0.00(0.00)\n",
      "Iter 5080 | Time 18.3439(18.5997) | Bit/dim 3.5035(3.5139) | Xent 0.0000(0.0000) | Loss 8.1247(8.6458) | Error 0.0000(0.0000) Steps 694(689.19) | Grad Norm 7.3440(5.7623) | Total Time 0.00(0.00)\n",
      "Iter 5090 | Time 17.7319(18.6002) | Bit/dim 3.5069(3.5128) | Xent 0.0000(0.0000) | Loss 7.9545(8.5109) | Error 0.0000(0.0000) Steps 646(685.85) | Grad Norm 6.7998(5.9219) | Total Time 0.00(0.00)\n",
      "Iter 5100 | Time 18.6092(18.6460) | Bit/dim 3.5064(3.5135) | Xent 0.0000(0.0000) | Loss 8.0837(8.4152) | Error 0.0000(0.0000) Steps 670(683.95) | Grad Norm 6.2309(5.8728) | Total Time 0.00(0.00)\n",
      "Iter 5110 | Time 17.7391(18.5920) | Bit/dim 3.5181(3.5124) | Xent 0.0000(0.0000) | Loss 8.0342(8.3441) | Error 0.0000(0.0000) Steps 658(684.50) | Grad Norm 2.9678(5.6028) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 91.0660, Epoch Time 1135.5545(1009.9006), Bit/dim 3.5116(best: 3.5169), Xent 0.0000, Loss 3.5116, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5120 | Time 19.5684(18.6091) | Bit/dim 3.5267(3.5134) | Xent 0.0000(0.0000) | Loss 8.0691(8.9136) | Error 0.0000(0.0000) Steps 682(684.57) | Grad Norm 3.9834(5.6982) | Total Time 0.00(0.00)\n",
      "Iter 5130 | Time 18.5005(18.6190) | Bit/dim 3.5122(3.5130) | Xent 0.0000(0.0000) | Loss 8.0374(8.7115) | Error 0.0000(0.0000) Steps 688(686.66) | Grad Norm 8.3227(5.8072) | Total Time 0.00(0.00)\n",
      "Iter 5140 | Time 19.3031(18.6634) | Bit/dim 3.4941(3.5112) | Xent 0.0000(0.0000) | Loss 8.1385(8.5703) | Error 0.0000(0.0000) Steps 694(687.14) | Grad Norm 5.5704(5.5035) | Total Time 0.00(0.00)\n",
      "Iter 5150 | Time 18.4962(18.7482) | Bit/dim 3.5242(3.5115) | Xent 0.0000(0.0000) | Loss 8.1371(8.4598) | Error 0.0000(0.0000) Steps 670(685.45) | Grad Norm 3.9683(5.7833) | Total Time 0.00(0.00)\n",
      "Iter 5160 | Time 19.0730(18.8047) | Bit/dim 3.5176(3.5127) | Xent 0.0000(0.0000) | Loss 8.3327(8.3931) | Error 0.0000(0.0000) Steps 706(690.44) | Grad Norm 7.7036(5.5963) | Total Time 0.00(0.00)\n",
      "Iter 5170 | Time 19.0824(18.8677) | Bit/dim 3.5183(3.5139) | Xent 0.0000(0.0000) | Loss 8.1871(8.3376) | Error 0.0000(0.0000) Steps 718(691.48) | Grad Norm 5.2256(5.7654) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 93.2273, Epoch Time 1155.8614(1014.2794), Bit/dim 3.5132(best: 3.5116), Xent 0.0000, Loss 3.5132, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5180 | Time 18.6005(18.7942) | Bit/dim 3.4940(3.5151) | Xent 0.0000(0.0000) | Loss 8.1921(8.8200) | Error 0.0000(0.0000) Steps 688(691.37) | Grad Norm 4.6097(5.2004) | Total Time 0.00(0.00)\n",
      "Iter 5190 | Time 19.3532(18.7943) | Bit/dim 3.5120(3.5156) | Xent 0.0000(0.0000) | Loss 8.2141(8.6480) | Error 0.0000(0.0000) Steps 706(691.55) | Grad Norm 3.4568(5.5705) | Total Time 0.00(0.00)\n",
      "Iter 5200 | Time 18.5901(18.7856) | Bit/dim 3.5035(3.5144) | Xent 0.0000(0.0000) | Loss 8.1231(8.5107) | Error 0.0000(0.0000) Steps 670(691.05) | Grad Norm 7.1383(5.6571) | Total Time 0.00(0.00)\n",
      "Iter 5210 | Time 18.0740(18.7146) | Bit/dim 3.4784(3.5119) | Xent 0.0000(0.0000) | Loss 8.0802(8.4137) | Error 0.0000(0.0000) Steps 640(688.38) | Grad Norm 5.8026(5.8364) | Total Time 0.00(0.00)\n",
      "Iter 5220 | Time 18.8994(18.7517) | Bit/dim 3.4776(3.5065) | Xent 0.0000(0.0000) | Loss 8.0808(8.3387) | Error 0.0000(0.0000) Steps 712(689.75) | Grad Norm 6.1086(5.6639) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 92.4446, Epoch Time 1143.0669(1018.1430), Bit/dim 3.5124(best: 3.5116), Xent 0.0000, Loss 3.5124, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5230 | Time 18.5583(18.7649) | Bit/dim 3.4950(3.5032) | Xent 0.0000(0.0000) | Loss 8.1632(8.9042) | Error 0.0000(0.0000) Steps 700(690.93) | Grad Norm 3.3206(5.6426) | Total Time 0.00(0.00)\n",
      "Iter 5240 | Time 19.0442(18.7743) | Bit/dim 3.5130(3.5052) | Xent 0.0000(0.0000) | Loss 8.2722(8.7115) | Error 0.0000(0.0000) Steps 700(691.01) | Grad Norm 3.9393(5.7442) | Total Time 0.00(0.00)\n",
      "Iter 5250 | Time 19.1278(18.8294) | Bit/dim 3.5089(3.5057) | Xent 0.0000(0.0000) | Loss 8.2613(8.5683) | Error 0.0000(0.0000) Steps 706(693.24) | Grad Norm 5.1027(5.5785) | Total Time 0.00(0.00)\n",
      "Iter 5260 | Time 17.8055(18.8899) | Bit/dim 3.4966(3.5093) | Xent 0.0000(0.0000) | Loss 7.9915(8.4609) | Error 0.0000(0.0000) Steps 670(694.04) | Grad Norm 5.4186(5.6381) | Total Time 0.00(0.00)\n",
      "Iter 5270 | Time 19.0484(18.8770) | Bit/dim 3.4769(3.5102) | Xent 0.0000(0.0000) | Loss 8.1159(8.3930) | Error 0.0000(0.0000) Steps 712(694.87) | Grad Norm 4.6119(5.4445) | Total Time 0.00(0.00)\n",
      "Iter 5280 | Time 18.1841(18.8753) | Bit/dim 3.4837(3.5094) | Xent 0.0000(0.0000) | Loss 8.0469(8.3398) | Error 0.0000(0.0000) Steps 676(694.96) | Grad Norm 4.1950(5.3418) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 94.4532, Epoch Time 1155.5200(1022.2643), Bit/dim 3.5047(best: 3.5116), Xent 0.0000, Loss 3.5047, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5290 | Time 18.3019(18.8769) | Bit/dim 3.4845(3.5074) | Xent 0.0000(0.0000) | Loss 8.0092(8.8161) | Error 0.0000(0.0000) Steps 688(695.01) | Grad Norm 6.1674(5.7431) | Total Time 0.00(0.00)\n",
      "Iter 5300 | Time 18.0227(18.8760) | Bit/dim 3.5147(3.5057) | Xent 0.0000(0.0000) | Loss 8.1220(8.6397) | Error 0.0000(0.0000) Steps 706(697.43) | Grad Norm 6.0806(5.4833) | Total Time 0.00(0.00)\n",
      "Iter 5310 | Time 18.6044(18.8983) | Bit/dim 3.5077(3.5081) | Xent 0.0000(0.0000) | Loss 8.1098(8.5269) | Error 0.0000(0.0000) Steps 730(701.06) | Grad Norm 6.7987(5.6758) | Total Time 0.00(0.00)\n",
      "Iter 5320 | Time 18.9569(18.9647) | Bit/dim 3.4899(3.5083) | Xent 0.0000(0.0000) | Loss 8.1825(8.4448) | Error 0.0000(0.0000) Steps 700(702.31) | Grad Norm 4.2415(5.4855) | Total Time 0.00(0.00)\n",
      "Iter 5330 | Time 19.4969(18.9814) | Bit/dim 3.5090(3.5086) | Xent 0.0000(0.0000) | Loss 8.1486(8.3752) | Error 0.0000(0.0000) Steps 700(702.79) | Grad Norm 4.2673(5.3269) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 95.6076, Epoch Time 1160.1410(1026.4006), Bit/dim 3.5056(best: 3.5047), Xent 0.0000, Loss 3.5056, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5340 | Time 19.1835(18.9504) | Bit/dim 3.4958(3.5064) | Xent 0.0000(0.0000) | Loss 8.0210(8.9517) | Error 0.0000(0.0000) Steps 658(701.02) | Grad Norm 3.1093(5.6088) | Total Time 0.00(0.00)\n",
      "Iter 5350 | Time 19.3695(18.9641) | Bit/dim 3.5026(3.5032) | Xent 0.0000(0.0000) | Loss 8.1924(8.7411) | Error 0.0000(0.0000) Steps 724(702.42) | Grad Norm 2.9945(5.4225) | Total Time 0.00(0.00)\n",
      "Iter 5360 | Time 19.0298(18.9851) | Bit/dim 3.5470(3.5023) | Xent 0.0000(0.0000) | Loss 8.2421(8.5845) | Error 0.0000(0.0000) Steps 694(702.34) | Grad Norm 8.8661(5.5513) | Total Time 0.00(0.00)\n",
      "Iter 5370 | Time 18.6765(19.0031) | Bit/dim 3.5100(3.5038) | Xent 0.0000(0.0000) | Loss 8.2940(8.4759) | Error 0.0000(0.0000) Steps 724(703.83) | Grad Norm 4.5532(5.2810) | Total Time 0.00(0.00)\n",
      "Iter 5380 | Time 19.4812(19.0378) | Bit/dim 3.5305(3.5059) | Xent 0.0000(0.0000) | Loss 8.2289(8.4041) | Error 0.0000(0.0000) Steps 706(702.77) | Grad Norm 3.7287(5.6078) | Total Time 0.00(0.00)\n",
      "Iter 5390 | Time 19.6761(18.9677) | Bit/dim 3.4528(3.5051) | Xent 0.0000(0.0000) | Loss 8.1147(8.3410) | Error 0.0000(0.0000) Steps 712(701.59) | Grad Norm 3.4896(5.3783) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 95.1874, Epoch Time 1162.4266(1030.4814), Bit/dim 3.5062(best: 3.5047), Xent 0.0000, Loss 3.5062, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5400 | Time 18.4463(18.9736) | Bit/dim 3.5383(3.5076) | Xent 0.0000(0.0000) | Loss 8.1976(8.8455) | Error 0.0000(0.0000) Steps 676(701.20) | Grad Norm 8.3672(5.6203) | Total Time 0.00(0.00)\n",
      "Iter 5410 | Time 20.1626(19.0161) | Bit/dim 3.5182(3.5046) | Xent 0.0000(0.0000) | Loss 8.2586(8.6548) | Error 0.0000(0.0000) Steps 688(702.85) | Grad Norm 7.0369(5.5904) | Total Time 0.00(0.00)\n",
      "Iter 5420 | Time 18.9268(18.9952) | Bit/dim 3.5408(3.5058) | Xent 0.0000(0.0000) | Loss 8.0802(8.5267) | Error 0.0000(0.0000) Steps 682(701.27) | Grad Norm 4.6471(5.6129) | Total Time 0.00(0.00)\n",
      "Iter 5430 | Time 19.6183(19.0307) | Bit/dim 3.5416(3.5059) | Xent 0.0000(0.0000) | Loss 8.1804(8.4388) | Error 0.0000(0.0000) Steps 706(703.94) | Grad Norm 5.5458(5.3229) | Total Time 0.00(0.00)\n",
      "Iter 5440 | Time 18.6708(19.0831) | Bit/dim 3.5082(3.5050) | Xent 0.0000(0.0000) | Loss 8.1869(8.3771) | Error 0.0000(0.0000) Steps 688(704.37) | Grad Norm 5.6515(5.6434) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 97.4998, Epoch Time 1171.0162(1034.6975), Bit/dim 3.5015(best: 3.5047), Xent 0.0000, Loss 3.5015, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5450 | Time 19.8501(19.1749) | Bit/dim 3.4884(3.4988) | Xent 0.0000(0.0000) | Loss 8.1417(8.9817) | Error 0.0000(0.0000) Steps 706(705.78) | Grad Norm 3.3678(5.4389) | Total Time 0.00(0.00)\n",
      "Iter 5460 | Time 18.5689(19.2014) | Bit/dim 3.4741(3.4988) | Xent 0.0000(0.0000) | Loss 8.0869(8.7702) | Error 0.0000(0.0000) Steps 676(707.77) | Grad Norm 4.6118(5.2798) | Total Time 0.00(0.00)\n",
      "Iter 5470 | Time 19.1930(19.1719) | Bit/dim 3.4997(3.4995) | Xent 0.0000(0.0000) | Loss 8.2337(8.6206) | Error 0.0000(0.0000) Steps 730(708.69) | Grad Norm 2.8263(5.2788) | Total Time 0.00(0.00)\n",
      "Iter 5480 | Time 18.7207(19.1516) | Bit/dim 3.4685(3.5005) | Xent 0.0000(0.0000) | Loss 8.1123(8.4982) | Error 0.0000(0.0000) Steps 700(706.42) | Grad Norm 9.8749(5.5014) | Total Time 0.00(0.00)\n",
      "Iter 5490 | Time 20.2752(19.2353) | Bit/dim 3.5011(3.5021) | Xent 0.0000(0.0000) | Loss 8.2667(8.4234) | Error 0.0000(0.0000) Steps 760(708.52) | Grad Norm 5.1266(5.4799) | Total Time 0.00(0.00)\n",
      "Iter 5500 | Time 18.8703(19.2025) | Bit/dim 3.4977(3.5025) | Xent 0.0000(0.0000) | Loss 8.2108(8.3580) | Error 0.0000(0.0000) Steps 712(706.41) | Grad Norm 4.2518(5.5046) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 96.4892, Epoch Time 1177.6695(1038.9866), Bit/dim 3.5038(best: 3.5015), Xent 0.0000, Loss 3.5038, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5510 | Time 19.1379(19.1677) | Bit/dim 3.4996(3.5041) | Xent 0.0000(0.0000) | Loss 8.1966(8.8569) | Error 0.0000(0.0000) Steps 742(705.08) | Grad Norm 10.6754(5.7850) | Total Time 0.00(0.00)\n",
      "Iter 5520 | Time 18.7276(19.2070) | Bit/dim 3.4626(3.5013) | Xent 0.0000(0.0000) | Loss 7.9895(8.6756) | Error 0.0000(0.0000) Steps 706(707.62) | Grad Norm 4.9908(5.9248) | Total Time 0.00(0.00)\n",
      "Iter 5530 | Time 19.1135(19.2600) | Bit/dim 3.5204(3.5027) | Xent 0.0000(0.0000) | Loss 8.0944(8.5321) | Error 0.0000(0.0000) Steps 712(708.12) | Grad Norm 4.8502(5.6476) | Total Time 0.00(0.00)\n",
      "Iter 5540 | Time 19.6695(19.2378) | Bit/dim 3.4850(3.5012) | Xent 0.0000(0.0000) | Loss 8.2352(8.4366) | Error 0.0000(0.0000) Steps 706(708.69) | Grad Norm 3.9657(5.0511) | Total Time 0.00(0.00)\n",
      "Iter 5550 | Time 20.1938(19.3151) | Bit/dim 3.5245(3.5007) | Xent 0.0000(0.0000) | Loss 8.1760(8.3732) | Error 0.0000(0.0000) Steps 730(710.23) | Grad Norm 4.3973(5.3486) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 96.2473, Epoch Time 1178.3350(1043.1671), Bit/dim 3.5003(best: 3.5015), Xent 0.0000, Loss 3.5003, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5560 | Time 18.9992(19.2249) | Bit/dim 3.5319(3.4998) | Xent 0.0000(0.0000) | Loss 8.1820(8.9548) | Error 0.0000(0.0000) Steps 706(708.75) | Grad Norm 6.0186(5.2604) | Total Time 0.00(0.00)\n",
      "Iter 5570 | Time 18.9030(19.1682) | Bit/dim 3.5247(3.5014) | Xent 0.0000(0.0000) | Loss 8.1502(8.7424) | Error 0.0000(0.0000) Steps 688(705.66) | Grad Norm 6.9674(5.4797) | Total Time 0.00(0.00)\n",
      "Iter 5580 | Time 19.1217(19.2422) | Bit/dim 3.4840(3.4993) | Xent 0.0000(0.0000) | Loss 8.1042(8.5992) | Error 0.0000(0.0000) Steps 694(706.51) | Grad Norm 5.0752(5.4950) | Total Time 0.00(0.00)\n",
      "Iter 5590 | Time 19.1380(19.2808) | Bit/dim 3.4636(3.4981) | Xent 0.0000(0.0000) | Loss 8.1634(8.4847) | Error 0.0000(0.0000) Steps 688(704.74) | Grad Norm 5.1839(5.5986) | Total Time 0.00(0.00)\n",
      "Iter 5600 | Time 20.2877(19.3206) | Bit/dim 3.5232(3.4977) | Xent 0.0000(0.0000) | Loss 8.1914(8.4053) | Error 0.0000(0.0000) Steps 742(706.27) | Grad Norm 4.3895(5.6061) | Total Time 0.00(0.00)\n",
      "Iter 5610 | Time 18.9873(19.3047) | Bit/dim 3.4729(3.4974) | Xent 0.0000(0.0000) | Loss 8.1268(8.3514) | Error 0.0000(0.0000) Steps 664(708.08) | Grad Norm 4.2633(5.5076) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 96.0976, Epoch Time 1179.4273(1047.2549), Bit/dim 3.5019(best: 3.5003), Xent 0.0000, Loss 3.5019, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5620 | Time 18.7077(19.2824) | Bit/dim 3.4710(3.4989) | Xent 0.0000(0.0000) | Loss 8.1670(8.8691) | Error 0.0000(0.0000) Steps 664(708.77) | Grad Norm 4.9450(5.6465) | Total Time 0.00(0.00)\n",
      "Iter 5630 | Time 19.2178(19.3371) | Bit/dim 3.4890(3.4969) | Xent 0.0000(0.0000) | Loss 8.1838(8.6854) | Error 0.0000(0.0000) Steps 712(709.73) | Grad Norm 5.4702(5.5941) | Total Time 0.00(0.00)\n",
      "Iter 5640 | Time 21.4334(19.3799) | Bit/dim 3.4811(3.4949) | Xent 0.0000(0.0000) | Loss 8.2349(8.5590) | Error 0.0000(0.0000) Steps 718(712.62) | Grad Norm 5.6697(5.4553) | Total Time 0.00(0.00)\n",
      "Iter 5650 | Time 19.6384(19.3418) | Bit/dim 3.4701(3.4941) | Xent 0.0000(0.0000) | Loss 8.1476(8.4650) | Error 0.0000(0.0000) Steps 724(715.12) | Grad Norm 5.9912(5.7753) | Total Time 0.00(0.00)\n",
      "Iter 5660 | Time 18.6761(19.2896) | Bit/dim 3.4553(3.4957) | Xent 0.0000(0.0000) | Loss 8.0464(8.3938) | Error 0.0000(0.0000) Steps 700(715.08) | Grad Norm 4.6051(5.5488) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 98.5453, Epoch Time 1185.4997(1051.4022), Bit/dim 3.5013(best: 3.5003), Xent 0.0000, Loss 3.5013, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5670 | Time 19.5295(19.3192) | Bit/dim 3.5043(3.4961) | Xent 0.0000(0.0000) | Loss 8.2990(9.0000) | Error 0.0000(0.0000) Steps 688(714.18) | Grad Norm 6.5407(5.6176) | Total Time 0.00(0.00)\n",
      "Iter 5680 | Time 19.9998(19.2773) | Bit/dim 3.4970(3.4959) | Xent 0.0000(0.0000) | Loss 8.2405(8.7938) | Error 0.0000(0.0000) Steps 736(713.78) | Grad Norm 5.2550(5.3920) | Total Time 0.00(0.00)\n",
      "Iter 5690 | Time 19.6119(19.3480) | Bit/dim 3.4653(3.4929) | Xent 0.0000(0.0000) | Loss 8.2536(8.6265) | Error 0.0000(0.0000) Steps 736(713.52) | Grad Norm 3.5249(5.5622) | Total Time 0.00(0.00)\n",
      "Iter 5700 | Time 18.7996(19.3660) | Bit/dim 3.4839(3.4919) | Xent 0.0000(0.0000) | Loss 8.0240(8.4971) | Error 0.0000(0.0000) Steps 718(714.74) | Grad Norm 3.6452(5.2888) | Total Time 0.00(0.00)\n",
      "Iter 5710 | Time 19.7134(19.4050) | Bit/dim 3.5215(3.4936) | Xent 0.0000(0.0000) | Loss 8.1514(8.4266) | Error 0.0000(0.0000) Steps 736(713.56) | Grad Norm 3.8906(5.4180) | Total Time 0.00(0.00)\n",
      "Iter 5720 | Time 18.7491(19.3334) | Bit/dim 3.4969(3.4958) | Xent 0.0000(0.0000) | Loss 8.1993(8.3742) | Error 0.0000(0.0000) Steps 706(711.00) | Grad Norm 6.3548(5.4971) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 96.1872, Epoch Time 1182.0844(1055.3227), Bit/dim 3.4956(best: 3.5003), Xent 0.0000, Loss 3.4956, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5730 | Time 18.7842(19.3259) | Bit/dim 3.5517(3.4960) | Xent 0.0000(0.0000) | Loss 8.2835(8.8686) | Error 0.0000(0.0000) Steps 730(711.35) | Grad Norm 4.6788(5.3883) | Total Time 0.00(0.00)\n",
      "Iter 5740 | Time 18.7119(19.3550) | Bit/dim 3.5040(3.4963) | Xent 0.0000(0.0000) | Loss 8.1723(8.6933) | Error 0.0000(0.0000) Steps 706(715.19) | Grad Norm 4.7377(5.3252) | Total Time 0.00(0.00)\n",
      "Iter 5750 | Time 20.8009(19.4754) | Bit/dim 3.4895(3.4948) | Xent 0.0000(0.0000) | Loss 8.2129(8.5701) | Error 0.0000(0.0000) Steps 706(714.02) | Grad Norm 10.1096(5.6642) | Total Time 0.00(0.00)\n",
      "Iter 5760 | Time 19.1393(19.4740) | Bit/dim 3.4710(3.4940) | Xent 0.0000(0.0000) | Loss 8.0824(8.4661) | Error 0.0000(0.0000) Steps 700(716.90) | Grad Norm 5.2738(5.4804) | Total Time 0.00(0.00)\n",
      "Iter 5770 | Time 19.6256(19.3949) | Bit/dim 3.4756(3.4926) | Xent 0.0000(0.0000) | Loss 8.2540(8.3895) | Error 0.0000(0.0000) Steps 712(715.98) | Grad Norm 4.2703(5.6715) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 97.0316, Epoch Time 1186.0950(1059.2459), Bit/dim 3.4935(best: 3.4956), Xent 0.0000, Loss 3.4935, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5780 | Time 19.3707(19.3881) | Bit/dim 3.4977(3.4956) | Xent 0.0000(0.0000) | Loss 8.2778(8.9978) | Error 0.0000(0.0000) Steps 688(713.42) | Grad Norm 3.0981(5.4117) | Total Time 0.00(0.00)\n",
      "Iter 5790 | Time 19.2217(19.3919) | Bit/dim 3.4862(3.4959) | Xent 0.0000(0.0000) | Loss 8.0807(8.7892) | Error 0.0000(0.0000) Steps 718(712.92) | Grad Norm 4.0825(5.5064) | Total Time 0.00(0.00)\n",
      "Iter 5800 | Time 19.4749(19.4021) | Bit/dim 3.5545(3.4961) | Xent 0.0000(0.0000) | Loss 8.4465(8.6462) | Error 0.0000(0.0000) Steps 712(712.62) | Grad Norm 7.0149(5.5805) | Total Time 0.00(0.00)\n",
      "Iter 5810 | Time 19.2900(19.4135) | Bit/dim 3.4354(3.4942) | Xent 0.0000(0.0000) | Loss 8.2217(8.5261) | Error 0.0000(0.0000) Steps 724(711.56) | Grad Norm 3.8614(5.3907) | Total Time 0.00(0.00)\n",
      "Iter 5820 | Time 19.7911(19.3748) | Bit/dim 3.4957(3.4926) | Xent 0.0000(0.0000) | Loss 8.2399(8.4441) | Error 0.0000(0.0000) Steps 742(712.54) | Grad Norm 4.9544(5.2103) | Total Time 0.00(0.00)\n",
      "Iter 5830 | Time 18.9556(19.4589) | Bit/dim 3.5052(3.4920) | Xent 0.0000(0.0000) | Loss 8.1885(8.3820) | Error 0.0000(0.0000) Steps 736(717.39) | Grad Norm 5.8779(5.5337) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 97.9617, Epoch Time 1189.4715(1063.1526), Bit/dim 3.4951(best: 3.4935), Xent 0.0000, Loss 3.4951, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5840 | Time 19.0147(19.4267) | Bit/dim 3.5276(3.4926) | Xent 0.0000(0.0000) | Loss 8.3049(8.8873) | Error 0.0000(0.0000) Steps 724(716.72) | Grad Norm 7.2526(5.3756) | Total Time 0.00(0.00)\n",
      "Iter 5850 | Time 20.7584(19.5135) | Bit/dim 3.5252(3.4933) | Xent 0.0000(0.0000) | Loss 8.3685(8.7160) | Error 0.0000(0.0000) Steps 694(717.43) | Grad Norm 9.5581(5.6369) | Total Time 0.00(0.00)\n",
      "Iter 5860 | Time 19.6485(19.5815) | Bit/dim 3.4581(3.4912) | Xent 0.0000(0.0000) | Loss 8.2193(8.5853) | Error 0.0000(0.0000) Steps 718(719.17) | Grad Norm 5.1858(5.5185) | Total Time 0.00(0.00)\n",
      "Iter 5870 | Time 19.4385(19.5878) | Bit/dim 3.5106(3.4906) | Xent 0.0000(0.0000) | Loss 8.2140(8.4898) | Error 0.0000(0.0000) Steps 712(716.14) | Grad Norm 3.7959(5.3463) | Total Time 0.00(0.00)\n",
      "Iter 5880 | Time 18.8536(19.5082) | Bit/dim 3.5150(3.4898) | Xent 0.0000(0.0000) | Loss 8.1075(8.4114) | Error 0.0000(0.0000) Steps 724(717.19) | Grad Norm 6.3163(5.5285) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 99.2759, Epoch Time 1196.4357(1067.1511), Bit/dim 3.5003(best: 3.4935), Xent 0.0000, Loss 3.5003, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5890 | Time 20.5802(19.5762) | Bit/dim 3.5009(3.4905) | Xent 0.0000(0.0000) | Loss 8.1682(8.9988) | Error 0.0000(0.0000) Steps 706(716.10) | Grad Norm 3.9269(5.6838) | Total Time 0.00(0.00)\n",
      "Iter 5900 | Time 20.0849(19.6685) | Bit/dim 3.4647(3.4896) | Xent 0.0000(0.0000) | Loss 8.2372(8.8073) | Error 0.0000(0.0000) Steps 706(718.97) | Grad Norm 3.4619(5.1899) | Total Time 0.00(0.00)\n",
      "Iter 5910 | Time 20.8301(19.7141) | Bit/dim 3.4875(3.4914) | Xent 0.0000(0.0000) | Loss 8.3380(8.6530) | Error 0.0000(0.0000) Steps 730(722.40) | Grad Norm 5.7824(5.0049) | Total Time 0.00(0.00)\n",
      "Iter 5920 | Time 19.2554(19.7059) | Bit/dim 3.4990(3.4886) | Xent 0.0000(0.0000) | Loss 8.2233(8.5403) | Error 0.0000(0.0000) Steps 694(719.19) | Grad Norm 4.1932(5.2309) | Total Time 0.00(0.00)\n",
      "Iter 5930 | Time 20.3237(19.7475) | Bit/dim 3.4745(3.4877) | Xent 0.0000(0.0000) | Loss 8.2928(8.4418) | Error 0.0000(0.0000) Steps 742(722.86) | Grad Norm 4.1112(5.2605) | Total Time 0.00(0.00)\n",
      "Iter 5940 | Time 19.5163(19.7934) | Bit/dim 3.4900(3.4872) | Xent 0.0000(0.0000) | Loss 8.1887(8.3833) | Error 0.0000(0.0000) Steps 718(724.34) | Grad Norm 3.3681(5.3314) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 98.5498, Epoch Time 1217.0138(1071.6470), Bit/dim 3.4938(best: 3.4935), Xent 0.0000, Loss 3.4938, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5950 | Time 18.8300(19.6895) | Bit/dim 3.4859(3.4885) | Xent 0.0000(0.0000) | Loss 8.2289(8.9153) | Error 0.0000(0.0000) Steps 688(722.17) | Grad Norm 3.2730(5.0223) | Total Time 0.00(0.00)\n",
      "Iter 5960 | Time 20.2532(19.5939) | Bit/dim 3.4762(3.4895) | Xent 0.0000(0.0000) | Loss 8.2456(8.7288) | Error 0.0000(0.0000) Steps 712(721.17) | Grad Norm 3.5823(5.1778) | Total Time 0.00(0.00)\n",
      "Iter 5970 | Time 19.2168(19.5750) | Bit/dim 3.4543(3.4869) | Xent 0.0000(0.0000) | Loss 8.0805(8.5818) | Error 0.0000(0.0000) Steps 730(725.28) | Grad Norm 5.6806(5.0632) | Total Time 0.00(0.00)\n",
      "Iter 5980 | Time 18.9683(19.6292) | Bit/dim 3.4941(3.4870) | Xent 0.0000(0.0000) | Loss 8.1952(8.4919) | Error 0.0000(0.0000) Steps 718(728.53) | Grad Norm 5.9381(5.4144) | Total Time 0.00(0.00)\n",
      "Iter 5990 | Time 20.0502(19.7080) | Bit/dim 3.4987(3.4860) | Xent 0.0000(0.0000) | Loss 8.1317(8.4190) | Error 0.0000(0.0000) Steps 706(726.26) | Grad Norm 5.8605(5.2352) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 102.5622, Epoch Time 1200.1689(1075.5027), Bit/dim 3.4885(best: 3.4935), Xent 0.0000, Loss 3.4885, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6000 | Time 19.0886(19.6554) | Bit/dim 3.5340(3.4886) | Xent 0.0000(0.0000) | Loss 8.2086(9.0231) | Error 0.0000(0.0000) Steps 688(722.85) | Grad Norm 2.5186(5.2721) | Total Time 0.00(0.00)\n",
      "Iter 6010 | Time 19.6115(19.6169) | Bit/dim 3.4888(3.4883) | Xent 0.0000(0.0000) | Loss 8.2290(8.8018) | Error 0.0000(0.0000) Steps 712(720.84) | Grad Norm 6.8565(5.3277) | Total Time 0.00(0.00)\n",
      "Iter 6020 | Time 19.8058(19.5515) | Bit/dim 3.4959(3.4864) | Xent 0.0000(0.0000) | Loss 8.1654(8.6389) | Error 0.0000(0.0000) Steps 736(720.69) | Grad Norm 4.6349(5.4329) | Total Time 0.00(0.00)\n",
      "Iter 6030 | Time 20.2115(19.5472) | Bit/dim 3.4755(3.4836) | Xent 0.0000(0.0000) | Loss 8.1433(8.5226) | Error 0.0000(0.0000) Steps 718(719.95) | Grad Norm 5.3074(5.3362) | Total Time 0.00(0.00)\n",
      "Iter 6040 | Time 19.6407(19.5702) | Bit/dim 3.5075(3.4844) | Xent 0.0000(0.0000) | Loss 8.2762(8.4472) | Error 0.0000(0.0000) Steps 742(721.44) | Grad Norm 4.5958(5.5786) | Total Time 0.00(0.00)\n",
      "Iter 6050 | Time 20.3293(19.6694) | Bit/dim 3.4867(3.4869) | Xent 0.0000(0.0000) | Loss 8.1086(8.3992) | Error 0.0000(0.0000) Steps 742(726.08) | Grad Norm 7.3370(5.6041) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 97.6509, Epoch Time 1201.1310(1079.2715), Bit/dim 3.4927(best: 3.4885), Xent 0.0000, Loss 3.4927, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6060 | Time 20.9824(19.6892) | Bit/dim 3.4487(3.4845) | Xent 0.0000(0.0000) | Loss 8.2488(8.9150) | Error 0.0000(0.0000) Steps 784(726.87) | Grad Norm 3.6658(5.6144) | Total Time 0.00(0.00)\n",
      "Iter 6070 | Time 19.6886(19.7705) | Bit/dim 3.5050(3.4882) | Xent 0.0000(0.0000) | Loss 8.3421(8.7352) | Error 0.0000(0.0000) Steps 742(725.24) | Grad Norm 5.2285(5.5433) | Total Time 0.00(0.00)\n",
      "Iter 6080 | Time 19.8715(19.7242) | Bit/dim 3.4904(3.4871) | Xent 0.0000(0.0000) | Loss 8.3366(8.5985) | Error 0.0000(0.0000) Steps 742(729.84) | Grad Norm 8.1404(5.4645) | Total Time 0.00(0.00)\n",
      "Iter 6090 | Time 19.0568(19.6998) | Bit/dim 3.4739(3.4889) | Xent 0.0000(0.0000) | Loss 8.1084(8.4998) | Error 0.0000(0.0000) Steps 694(724.38) | Grad Norm 5.5288(5.6265) | Total Time 0.00(0.00)\n",
      "Iter 6100 | Time 17.8540(19.6436) | Bit/dim 3.4740(3.4869) | Xent 0.0000(0.0000) | Loss 8.0907(8.4198) | Error 0.0000(0.0000) Steps 676(724.96) | Grad Norm 4.4934(5.4052) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 100.4122, Epoch Time 1202.8392(1082.9785), Bit/dim 3.4867(best: 3.4885), Xent 0.0000, Loss 3.4867, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6110 | Time 20.0258(19.6045) | Bit/dim 3.4573(3.4813) | Xent 0.0000(0.0000) | Loss 8.2903(9.0436) | Error 0.0000(0.0000) Steps 706(725.60) | Grad Norm 6.3488(5.5022) | Total Time 0.00(0.00)\n",
      "Iter 6120 | Time 21.1935(19.6606) | Bit/dim 3.4561(3.4814) | Xent 0.0000(0.0000) | Loss 8.2005(8.8239) | Error 0.0000(0.0000) Steps 766(729.91) | Grad Norm 3.8324(5.1950) | Total Time 0.00(0.00)\n",
      "Iter 6130 | Time 18.9991(19.5472) | Bit/dim 3.4870(3.4821) | Xent 0.0000(0.0000) | Loss 8.1997(8.6552) | Error 0.0000(0.0000) Steps 712(727.19) | Grad Norm 5.6693(5.4229) | Total Time 0.00(0.00)\n",
      "Iter 6140 | Time 21.2855(19.6016) | Bit/dim 3.4832(3.4808) | Xent 0.0000(0.0000) | Loss 8.3477(8.5515) | Error 0.0000(0.0000) Steps 724(726.47) | Grad Norm 6.7266(5.5235) | Total Time 0.00(0.00)\n",
      "Iter 6150 | Time 19.6253(19.6761) | Bit/dim 3.4620(3.4817) | Xent 0.0000(0.0000) | Loss 8.1898(8.4640) | Error 0.0000(0.0000) Steps 754(728.52) | Grad Norm 3.5219(5.3708) | Total Time 0.00(0.00)\n",
      "Iter 6160 | Time 18.8835(19.6110) | Bit/dim 3.4871(3.4856) | Xent 0.0000(0.0000) | Loss 8.2280(8.4108) | Error 0.0000(0.0000) Steps 730(723.52) | Grad Norm 9.2228(5.4432) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 100.3001, Epoch Time 1202.2332(1086.5562), Bit/dim 3.4882(best: 3.4867), Xent 0.0000, Loss 3.4882, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6170 | Time 19.0386(19.5597) | Bit/dim 3.4511(3.4833) | Xent 0.0000(0.0000) | Loss 8.1109(8.9389) | Error 0.0000(0.0000) Steps 718(723.02) | Grad Norm 3.3787(5.3335) | Total Time 0.00(0.00)\n",
      "Iter 6180 | Time 19.7936(19.5978) | Bit/dim 3.4820(3.4861) | Xent 0.0000(0.0000) | Loss 8.2104(8.7525) | Error 0.0000(0.0000) Steps 694(723.92) | Grad Norm 3.0587(5.2102) | Total Time 0.00(0.00)\n",
      "Iter 6190 | Time 19.1918(19.5763) | Bit/dim 3.4791(3.4818) | Xent 0.0000(0.0000) | Loss 8.1591(8.6162) | Error 0.0000(0.0000) Steps 718(725.35) | Grad Norm 6.3441(5.2457) | Total Time 0.00(0.00)\n",
      "Iter 6200 | Time 19.0923(19.5736) | Bit/dim 3.4636(3.4834) | Xent 0.0000(0.0000) | Loss 8.1216(8.5097) | Error 0.0000(0.0000) Steps 736(725.18) | Grad Norm 4.0295(5.2892) | Total Time 0.00(0.00)\n",
      "Iter 6210 | Time 21.1109(19.6470) | Bit/dim 3.4879(3.4819) | Xent 0.0000(0.0000) | Loss 8.2389(8.4227) | Error 0.0000(0.0000) Steps 748(723.74) | Grad Norm 5.1256(5.3929) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 97.8854, Epoch Time 1199.1940(1089.9353), Bit/dim 3.4853(best: 3.4867), Xent 0.0000, Loss 3.4853, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6220 | Time 20.8406(19.6824) | Bit/dim 3.4886(3.4824) | Xent 0.0000(0.0000) | Loss 8.3504(9.0493) | Error 0.0000(0.0000) Steps 742(721.06) | Grad Norm 5.2073(5.3721) | Total Time 0.00(0.00)\n",
      "Iter 6230 | Time 19.5938(19.6752) | Bit/dim 3.5129(3.4838) | Xent 0.0000(0.0000) | Loss 8.2954(8.8317) | Error 0.0000(0.0000) Steps 736(719.62) | Grad Norm 7.9155(5.6388) | Total Time 0.00(0.00)\n",
      "Iter 6240 | Time 19.7566(19.6141) | Bit/dim 3.4783(3.4846) | Xent 0.0000(0.0000) | Loss 8.1389(8.6688) | Error 0.0000(0.0000) Steps 724(718.13) | Grad Norm 6.4421(5.5227) | Total Time 0.00(0.00)\n",
      "Iter 6250 | Time 20.4216(19.6133) | Bit/dim 3.5065(3.4822) | Xent 0.0000(0.0000) | Loss 8.3949(8.5457) | Error 0.0000(0.0000) Steps 772(723.13) | Grad Norm 3.6342(5.4554) | Total Time 0.00(0.00)\n",
      "Iter 6260 | Time 19.8913(19.6564) | Bit/dim 3.4910(3.4811) | Xent 0.0000(0.0000) | Loss 8.1833(8.4617) | Error 0.0000(0.0000) Steps 736(726.57) | Grad Norm 5.2479(5.6156) | Total Time 0.00(0.00)\n",
      "Iter 6270 | Time 19.8006(19.6127) | Bit/dim 3.5178(3.4802) | Xent 0.0000(0.0000) | Loss 8.3286(8.4112) | Error 0.0000(0.0000) Steps 718(728.34) | Grad Norm 3.1148(5.5235) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 97.7052, Epoch Time 1197.8726(1093.1734), Bit/dim 3.4809(best: 3.4853), Xent 0.0000, Loss 3.4809, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6280 | Time 18.9911(19.6192) | Bit/dim 3.4655(3.4816) | Xent 0.0000(0.0000) | Loss 8.1782(8.9509) | Error 0.0000(0.0000) Steps 730(728.56) | Grad Norm 7.1245(5.6028) | Total Time 0.00(0.00)\n",
      "Iter 6290 | Time 18.7304(19.5929) | Bit/dim 3.4696(3.4766) | Xent 0.0000(0.0000) | Loss 8.3338(8.7566) | Error 0.0000(0.0000) Steps 736(727.85) | Grad Norm 7.2300(5.7477) | Total Time 0.00(0.00)\n",
      "Iter 6300 | Time 18.7553(19.6056) | Bit/dim 3.4820(3.4786) | Xent 0.0000(0.0000) | Loss 8.1548(8.6074) | Error 0.0000(0.0000) Steps 706(726.73) | Grad Norm 4.3337(5.4519) | Total Time 0.00(0.00)\n",
      "Iter 6310 | Time 20.1234(19.6270) | Bit/dim 3.4970(3.4772) | Xent 0.0000(0.0000) | Loss 8.2818(8.5018) | Error 0.0000(0.0000) Steps 748(728.03) | Grad Norm 2.7229(5.4354) | Total Time 0.00(0.00)\n",
      "Iter 6320 | Time 19.1756(19.6637) | Bit/dim 3.4968(3.4805) | Xent 0.0000(0.0000) | Loss 8.2873(8.4382) | Error 0.0000(0.0000) Steps 712(725.51) | Grad Norm 4.3646(5.6238) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 98.4773, Epoch Time 1200.5510(1096.3948), Bit/dim 3.4754(best: 3.4809), Xent 0.0000, Loss 3.4754, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6330 | Time 19.3212(19.6668) | Bit/dim 3.4787(3.4786) | Xent 0.0000(0.0000) | Loss 8.1581(9.0304) | Error 0.0000(0.0000) Steps 718(725.23) | Grad Norm 2.4015(5.4064) | Total Time 0.00(0.00)\n",
      "Iter 6340 | Time 19.6657(19.7211) | Bit/dim 3.5105(3.4775) | Xent 0.0000(0.0000) | Loss 8.2560(8.8132) | Error 0.0000(0.0000) Steps 718(725.95) | Grad Norm 9.8867(5.4909) | Total Time 0.00(0.00)\n",
      "Iter 6350 | Time 19.3257(19.8282) | Bit/dim 3.5068(3.4801) | Xent 0.0000(0.0000) | Loss 8.3781(8.6678) | Error 0.0000(0.0000) Steps 718(727.30) | Grad Norm 6.3784(5.4889) | Total Time 0.00(0.00)\n",
      "Iter 6360 | Time 19.8973(19.8169) | Bit/dim 3.4709(3.4802) | Xent 0.0000(0.0000) | Loss 8.1367(8.5512) | Error 0.0000(0.0000) Steps 718(725.48) | Grad Norm 4.9128(5.3569) | Total Time 0.00(0.00)\n",
      "Iter 6370 | Time 19.1091(19.8579) | Bit/dim 3.4672(3.4804) | Xent 0.0000(0.0000) | Loss 8.1936(8.4692) | Error 0.0000(0.0000) Steps 730(727.00) | Grad Norm 5.5170(5.2673) | Total Time 0.00(0.00)\n",
      "Iter 6380 | Time 18.5677(19.8281) | Bit/dim 3.5250(3.4797) | Xent 0.0000(0.0000) | Loss 8.2502(8.4020) | Error 0.0000(0.0000) Steps 724(722.85) | Grad Norm 6.5003(5.5769) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 100.7245, Epoch Time 1214.7200(1099.9445), Bit/dim 3.4776(best: 3.4754), Xent 0.0000, Loss 3.4776, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6390 | Time 20.1135(19.7573) | Bit/dim 3.4671(3.4776) | Xent 0.0000(0.0000) | Loss 8.2671(8.9361) | Error 0.0000(0.0000) Steps 718(722.91) | Grad Norm 4.5804(5.4620) | Total Time 0.00(0.00)\n",
      "Iter 6400 | Time 20.8041(19.7814) | Bit/dim 3.4813(3.4771) | Xent 0.0000(0.0000) | Loss 8.3696(8.7489) | Error 0.0000(0.0000) Steps 736(725.77) | Grad Norm 5.1484(5.4234) | Total Time 0.00(0.00)\n",
      "Iter 6410 | Time 19.5623(19.7046) | Bit/dim 3.4788(3.4764) | Xent 0.0000(0.0000) | Loss 8.3462(8.6132) | Error 0.0000(0.0000) Steps 718(725.57) | Grad Norm 6.5288(5.3709) | Total Time 0.00(0.00)\n",
      "Iter 6420 | Time 19.9350(19.6495) | Bit/dim 3.4660(3.4771) | Xent 0.0000(0.0000) | Loss 8.2287(8.5062) | Error 0.0000(0.0000) Steps 730(725.51) | Grad Norm 3.9697(5.2028) | Total Time 0.00(0.00)\n",
      "Iter 6430 | Time 19.3451(19.5884) | Bit/dim 3.4882(3.4780) | Xent 0.0000(0.0000) | Loss 8.2266(8.4242) | Error 0.0000(0.0000) Steps 724(723.27) | Grad Norm 6.1875(5.2105) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 100.0055, Epoch Time 1199.1965(1102.9221), Bit/dim 3.4877(best: 3.4754), Xent 0.0000, Loss 3.4877, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6440 | Time 19.7966(19.6448) | Bit/dim 3.4906(3.4795) | Xent 0.0000(0.0000) | Loss 8.1869(9.0494) | Error 0.0000(0.0000) Steps 694(722.28) | Grad Norm 4.4604(5.3759) | Total Time 0.00(0.00)\n",
      "Iter 6450 | Time 20.9221(19.8005) | Bit/dim 3.4747(3.4787) | Xent 0.0000(0.0000) | Loss 8.2453(8.8326) | Error 0.0000(0.0000) Steps 742(723.24) | Grad Norm 7.4968(5.3445) | Total Time 0.00(0.00)\n",
      "Iter 6460 | Time 19.5476(19.8135) | Bit/dim 3.4584(3.4750) | Xent 0.0000(0.0000) | Loss 8.2009(8.6641) | Error 0.0000(0.0000) Steps 736(723.93) | Grad Norm 4.8794(5.6276) | Total Time 0.00(0.00)\n",
      "Iter 6470 | Time 20.3989(19.8047) | Bit/dim 3.4867(3.4777) | Xent 0.0000(0.0000) | Loss 8.2425(8.5605) | Error 0.0000(0.0000) Steps 748(728.52) | Grad Norm 6.0805(5.3633) | Total Time 0.00(0.00)\n",
      "Iter 6480 | Time 18.2273(19.7650) | Bit/dim 3.4616(3.4766) | Xent 0.0000(0.0000) | Loss 8.1523(8.4718) | Error 0.0000(0.0000) Steps 694(730.63) | Grad Norm 3.9588(5.5673) | Total Time 0.00(0.00)\n",
      "Iter 6490 | Time 19.3080(19.8343) | Bit/dim 3.4775(3.4743) | Xent 0.0000(0.0000) | Loss 8.2492(8.4118) | Error 0.0000(0.0000) Steps 742(729.13) | Grad Norm 5.4312(5.1337) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 98.9753, Epoch Time 1219.3813(1106.4159), Bit/dim 3.4748(best: 3.4754), Xent 0.0000, Loss 3.4748, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6500 | Time 19.7847(19.8282) | Bit/dim 3.5192(3.4755) | Xent 0.0000(0.0000) | Loss 8.3415(8.9409) | Error 0.0000(0.0000) Steps 712(729.01) | Grad Norm 6.9113(5.4344) | Total Time 0.00(0.00)\n",
      "Iter 6510 | Time 20.0569(19.9571) | Bit/dim 3.4486(3.4729) | Xent 0.0000(0.0000) | Loss 8.2128(8.7516) | Error 0.0000(0.0000) Steps 748(731.35) | Grad Norm 4.4635(5.5353) | Total Time 0.00(0.00)\n",
      "Iter 6520 | Time 19.8955(19.8924) | Bit/dim 3.4659(3.4714) | Xent 0.0000(0.0000) | Loss 8.2827(8.6055) | Error 0.0000(0.0000) Steps 748(727.51) | Grad Norm 3.6369(5.1009) | Total Time 0.00(0.00)\n",
      "Iter 6530 | Time 20.7009(19.9160) | Bit/dim 3.4830(3.4765) | Xent 0.0000(0.0000) | Loss 8.3067(8.5178) | Error 0.0000(0.0000) Steps 754(730.92) | Grad Norm 5.0160(5.1096) | Total Time 0.00(0.00)\n",
      "Iter 6540 | Time 19.3980(19.8779) | Bit/dim 3.4375(3.4736) | Xent 0.0000(0.0000) | Loss 8.0990(8.4296) | Error 0.0000(0.0000) Steps 760(730.82) | Grad Norm 4.6159(5.0702) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 98.2325, Epoch Time 1214.6674(1109.6634), Bit/dim 3.4792(best: 3.4748), Xent 0.0000, Loss 3.4792, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6550 | Time 19.5499(19.9008) | Bit/dim 3.4456(3.4723) | Xent 0.0000(0.0000) | Loss 8.2261(9.0598) | Error 0.0000(0.0000) Steps 730(729.86) | Grad Norm 4.6503(5.3137) | Total Time 0.00(0.00)\n",
      "Iter 6560 | Time 19.9610(19.8922) | Bit/dim 3.4960(3.4718) | Xent 0.0000(0.0000) | Loss 8.3397(8.8326) | Error 0.0000(0.0000) Steps 754(729.42) | Grad Norm 3.8423(5.2397) | Total Time 0.00(0.00)\n",
      "Iter 6570 | Time 21.4118(19.8679) | Bit/dim 3.4937(3.4742) | Xent 0.0000(0.0000) | Loss 8.2729(8.6761) | Error 0.0000(0.0000) Steps 724(724.39) | Grad Norm 4.3039(5.5329) | Total Time 0.00(0.00)\n",
      "Iter 6580 | Time 21.0796(19.8172) | Bit/dim 3.4745(3.4741) | Xent 0.0000(0.0000) | Loss 8.2147(8.5636) | Error 0.0000(0.0000) Steps 766(723.45) | Grad Norm 3.7374(5.3751) | Total Time 0.00(0.00)\n",
      "Iter 6590 | Time 20.6801(19.8237) | Bit/dim 3.4843(3.4753) | Xent 0.0000(0.0000) | Loss 8.3649(8.4847) | Error 0.0000(0.0000) Steps 778(724.07) | Grad Norm 6.8462(5.2620) | Total Time 0.00(0.00)\n",
      "Iter 6600 | Time 20.0044(19.7881) | Bit/dim 3.4691(3.4736) | Xent 0.0000(0.0000) | Loss 8.2302(8.4058) | Error 0.0000(0.0000) Steps 706(724.24) | Grad Norm 3.7064(5.2893) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 99.1358, Epoch Time 1207.6416(1112.6027), Bit/dim 3.4783(best: 3.4748), Xent 0.0000, Loss 3.4783, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6610 | Time 19.7874(19.8658) | Bit/dim 3.4821(3.4726) | Xent 0.0000(0.0000) | Loss 8.2489(8.9201) | Error 0.0000(0.0000) Steps 730(728.49) | Grad Norm 6.9082(5.0825) | Total Time 0.00(0.00)\n",
      "Iter 6620 | Time 19.6098(19.8957) | Bit/dim 3.4529(3.4720) | Xent 0.0000(0.0000) | Loss 8.3040(8.7463) | Error 0.0000(0.0000) Steps 748(728.71) | Grad Norm 4.5018(5.3532) | Total Time 0.00(0.00)\n",
      "Iter 6630 | Time 20.3853(19.9374) | Bit/dim 3.4755(3.4730) | Xent 0.0000(0.0000) | Loss 8.2941(8.6144) | Error 0.0000(0.0000) Steps 724(729.03) | Grad Norm 5.4829(5.4461) | Total Time 0.00(0.00)\n",
      "Iter 6640 | Time 19.2878(19.9573) | Bit/dim 3.4697(3.4716) | Xent 0.0000(0.0000) | Loss 8.1820(8.5164) | Error 0.0000(0.0000) Steps 712(730.24) | Grad Norm 2.9691(5.0715) | Total Time 0.00(0.00)\n",
      "Iter 6650 | Time 20.1033(19.9643) | Bit/dim 3.4743(3.4721) | Xent 0.0000(0.0000) | Loss 8.3092(8.4362) | Error 0.0000(0.0000) Steps 772(730.75) | Grad Norm 8.3932(5.2136) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 98.9709, Epoch Time 1225.2097(1115.9810), Bit/dim 3.4744(best: 3.4748), Xent 0.0000, Loss 3.4744, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6660 | Time 20.2262(19.9148) | Bit/dim 3.4987(3.4746) | Xent 0.0000(0.0000) | Loss 8.1888(9.0576) | Error 0.0000(0.0000) Steps 718(731.23) | Grad Norm 4.6276(5.1818) | Total Time 0.00(0.00)\n",
      "Iter 6670 | Time 20.0007(19.8846) | Bit/dim 3.4394(3.4714) | Xent 0.0000(0.0000) | Loss 8.1422(8.8338) | Error 0.0000(0.0000) Steps 688(728.35) | Grad Norm 3.6125(5.2440) | Total Time 0.00(0.00)\n",
      "Iter 6680 | Time 21.0515(19.9263) | Bit/dim 3.4714(3.4705) | Xent 0.0000(0.0000) | Loss 8.1757(8.6683) | Error 0.0000(0.0000) Steps 736(727.87) | Grad Norm 8.4438(5.6071) | Total Time 0.00(0.00)\n",
      "Iter 6690 | Time 20.7018(19.9293) | Bit/dim 3.4633(3.4747) | Xent 0.0000(0.0000) | Loss 8.2643(8.5605) | Error 0.0000(0.0000) Steps 784(729.41) | Grad Norm 5.4864(5.3405) | Total Time 0.00(0.00)\n",
      "Iter 6700 | Time 20.3609(20.0582) | Bit/dim 3.4389(3.4735) | Xent 0.0000(0.0000) | Loss 8.2006(8.4758) | Error 0.0000(0.0000) Steps 730(726.47) | Grad Norm 5.1476(4.9482) | Total Time 0.00(0.00)\n",
      "Iter 6710 | Time 20.4093(20.1089) | Bit/dim 3.4912(3.4734) | Xent 0.0000(0.0000) | Loss 8.3182(8.4111) | Error 0.0000(0.0000) Steps 712(726.30) | Grad Norm 3.6620(5.2953) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 98.0290, Epoch Time 1220.9557(1119.1302), Bit/dim 3.4753(best: 3.4744), Xent 0.0000, Loss 3.4753, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6720 | Time 20.2772(20.1261) | Bit/dim 3.4376(3.4721) | Xent 0.0000(0.0000) | Loss 8.1445(8.9506) | Error 0.0000(0.0000) Steps 718(727.11) | Grad Norm 5.4564(5.4320) | Total Time 0.00(0.00)\n",
      "Iter 6730 | Time 19.9603(20.1713) | Bit/dim 3.4507(3.4714) | Xent 0.0000(0.0000) | Loss 8.1709(8.7493) | Error 0.0000(0.0000) Steps 706(726.00) | Grad Norm 5.9423(5.3621) | Total Time 0.00(0.00)\n",
      "Iter 6740 | Time 21.6579(20.2176) | Bit/dim 3.4559(3.4714) | Xent 0.0000(0.0000) | Loss 8.2694(8.6153) | Error 0.0000(0.0000) Steps 748(731.19) | Grad Norm 3.4911(5.2761) | Total Time 0.00(0.00)\n",
      "Iter 6750 | Time 21.4754(20.1296) | Bit/dim 3.4633(3.4691) | Xent 0.0000(0.0000) | Loss 8.2594(8.5064) | Error 0.0000(0.0000) Steps 730(731.16) | Grad Norm 4.2652(5.1914) | Total Time 0.00(0.00)\n",
      "Iter 6760 | Time 21.0167(20.1236) | Bit/dim 3.5015(3.4693) | Xent 0.0000(0.0000) | Loss 8.3779(8.4276) | Error 0.0000(0.0000) Steps 772(732.89) | Grad Norm 6.8505(5.0164) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 97.2605, Epoch Time 1224.9371(1122.3044), Bit/dim 3.4797(best: 3.4744), Xent 0.0000, Loss 3.4797, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6770 | Time 20.7761(20.0937) | Bit/dim 3.4637(3.4701) | Xent 0.0000(0.0000) | Loss 8.1532(9.0418) | Error 0.0000(0.0000) Steps 700(731.74) | Grad Norm 3.9913(5.1453) | Total Time 0.00(0.00)\n",
      "Iter 6780 | Time 19.5032(20.0903) | Bit/dim 3.4421(3.4679) | Xent 0.0000(0.0000) | Loss 8.2458(8.8329) | Error 0.0000(0.0000) Steps 724(734.19) | Grad Norm 3.1082(5.2809) | Total Time 0.00(0.00)\n",
      "Iter 6790 | Time 19.5995(20.0737) | Bit/dim 3.4327(3.4685) | Xent 0.0000(0.0000) | Loss 8.1598(8.6634) | Error 0.0000(0.0000) Steps 718(734.41) | Grad Norm 4.1285(4.9773) | Total Time 0.00(0.00)\n",
      "Iter 6800 | Time 20.5550(20.0269) | Bit/dim 3.4711(3.4688) | Xent 0.0000(0.0000) | Loss 8.2551(8.5441) | Error 0.0000(0.0000) Steps 742(734.58) | Grad Norm 6.4714(5.2655) | Total Time 0.00(0.00)\n",
      "Iter 6810 | Time 20.2898(19.9493) | Bit/dim 3.4579(3.4670) | Xent 0.0000(0.0000) | Loss 8.2770(8.4516) | Error 0.0000(0.0000) Steps 730(731.54) | Grad Norm 6.3307(5.4797) | Total Time 0.00(0.00)\n",
      "Iter 6820 | Time 20.2168(20.0709) | Bit/dim 3.4782(3.4692) | Xent 0.0000(0.0000) | Loss 8.2568(8.4023) | Error 0.0000(0.0000) Steps 718(734.07) | Grad Norm 5.7663(5.2372) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 99.6511, Epoch Time 1223.2455(1125.3326), Bit/dim 3.4695(best: 3.4744), Xent 0.0000, Loss 3.4695, Error 1.0000(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6830 | Time 20.0617(20.1326) | Bit/dim 3.4584(3.4705) | Xent 0.0000(0.0000) | Loss 8.1202(8.9448) | Error 0.0000(0.0000) Steps 754(735.50) | Grad Norm 3.9048(5.0259) | Total Time 0.00(0.00)\n",
      "Iter 6840 | Time 20.2377(20.1279) | Bit/dim 3.5092(3.4699) | Xent 0.0000(0.0000) | Loss 8.4428(8.7690) | Error 0.0000(0.0000) Steps 748(739.19) | Grad Norm 12.3032(5.2603) | Total Time 0.00(0.00)\n",
      "Iter 6850 | Time 20.9228(20.1626) | Bit/dim 3.4574(3.4686) | Xent 0.0000(0.0000) | Loss 8.1281(8.6202) | Error 0.0000(0.0000) Steps 700(736.13) | Grad Norm 6.1229(5.4900) | Total Time 0.00(0.00)\n",
      "Iter 6860 | Time 20.1301(20.1393) | Bit/dim 3.4335(3.4682) | Xent 0.0000(0.0000) | Loss 8.1598(8.5234) | Error 0.0000(0.0000) Steps 748(739.42) | Grad Norm 3.4719(5.3449) | Total Time 0.00(0.00)\n",
      "Iter 6870 | Time 20.0233(20.0580) | Bit/dim 3.5129(3.4675) | Xent 0.0000(0.0000) | Loss 8.3873(8.4450) | Error 0.0000(0.0000) Steps 742(740.38) | Grad Norm 5.2085(5.1892) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 97.2324, Epoch Time 1223.4637(1128.2766), Bit/dim 3.4680(best: 3.4695), Xent 0.0000, Loss 3.4680, Error 1.0000(best: inf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6880 | Time 20.7362(20.0995) | Bit/dim 3.4443(3.4682) | Xent 0.0000(0.0000) | Loss 8.0644(9.0587) | Error 0.0000(0.0000) Steps 700(738.35) | Grad Norm 4.2917(5.4157) | Total Time 0.00(0.00)\n",
      "Iter 6890 | Time 20.9745(20.1555) | Bit/dim 3.4462(3.4647) | Xent 0.0000(0.0000) | Loss 8.2164(8.8320) | Error 0.0000(0.0000) Steps 790(739.16) | Grad Norm 5.6213(5.4699) | Total Time 0.00(0.00)\n",
      "Iter 6900 | Time 21.5405(20.2681) | Bit/dim 3.4403(3.4649) | Xent 0.0000(0.0000) | Loss 8.0631(8.6738) | Error 0.0000(0.0000) Steps 670(738.18) | Grad Norm 7.5352(5.2138) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_cifar10_bs900_rl_stdscale_15_annealing_run3 --seed 3 --lr 0.001 --conditional False --controlled_tol False --log_freq 10 --scale_fac 1.0 --scale_std 15.0 --annealing_std True\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
