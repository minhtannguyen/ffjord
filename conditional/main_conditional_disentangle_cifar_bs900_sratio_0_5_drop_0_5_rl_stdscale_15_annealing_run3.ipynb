{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=True, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, eta=0.1, gamma=0.99, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume=None, rl_weight=0.01, rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_15_annealing_run3', scale=1.0, scale_fac=1.0, scale_std=15.0, seed=3, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1450732\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 0010 | Time 11.4602(29.3219) | Bit/dim 8.9022(9.0696) | Xent 2.2766(2.2999) | Loss 20.6032(21.1800) | Error 0.7511(0.8716) Steps 466(460.91) | Grad Norm 20.4550(29.4829) | Total Time 0.00(0.00)\n",
      "Iter 0020 | Time 11.2595(24.6480) | Bit/dim 8.5315(8.9471) | Xent 2.2347(2.2872) | Loss 19.9874(20.8880) | Error 0.7667(0.8420) Steps 442(455.78) | Grad Norm 9.1356(24.9165) | Total Time 0.00(0.00)\n",
      "Iter 0030 | Time 11.1676(21.1194) | Bit/dim 8.3455(8.8029) | Xent 2.1768(2.2633) | Loss 19.4295(20.5405) | Error 0.7500(0.8169) Steps 430(452.00) | Grad Norm 7.4894(20.5838) | Total Time 0.00(0.00)\n",
      "Iter 0040 | Time 11.4501(18.5443) | Bit/dim 8.1205(8.6446) | Xent 2.1244(2.2349) | Loss 19.1336(20.1924) | Error 0.7244(0.7969) Steps 448(450.96) | Grad Norm 6.4910(16.8106) | Total Time 0.00(0.00)\n",
      "Iter 0050 | Time 11.8824(16.6492) | Bit/dim 7.8697(8.4706) | Xent 2.0937(2.2045) | Loss 18.6321(19.8192) | Error 0.7256(0.7783) Steps 472(450.30) | Grad Norm 5.5638(13.8818) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 70.9099, Epoch Time 741.1159(741.1159), Bit/dim 7.7088(best: inf), Xent 2.0815, Loss 8.7496, Error 0.6979(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n",
      "14.97005988023952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0060 | Time 11.8987(15.3116) | Bit/dim 7.5657(8.2751) | Xent 2.0675(2.1737) | Loss 17.9717(19.8466) | Error 0.6978(0.7585) Steps 442(449.54) | Grad Norm 4.8793(11.6341) | Total Time 0.00(0.00)\n",
      "Iter 0070 | Time 11.8182(14.3984) | Bit/dim 7.3300(8.0560) | Xent 2.0639(2.1473) | Loss 17.3335(19.2853) | Error 0.6889(0.7391) Steps 478(451.78) | Grad Norm 3.9319(9.8109) | Total Time 0.00(0.00)\n",
      "Iter 0080 | Time 12.1923(13.8031) | Bit/dim 7.1441(7.8358) | Xent 2.0766(2.1296) | Loss 17.2741(18.7654) | Error 0.6844(0.7252) Steps 484(453.25) | Grad Norm 2.7741(8.1101) | Total Time 0.00(0.00)\n",
      "Iter 0090 | Time 11.4745(13.3111) | Bit/dim 7.0743(7.6434) | Xent 2.1001(2.1214) | Loss 16.9340(18.3147) | Error 0.7200(0.7203) Steps 460(454.97) | Grad Norm 3.1337(6.8337) | Total Time 0.00(0.00)\n",
      "Iter 0100 | Time 12.9174(12.9594) | Bit/dim 7.0378(7.4869) | Xent 2.0952(2.1128) | Loss 17.0067(17.9474) | Error 0.7200(0.7198) Steps 526(458.89) | Grad Norm 2.3019(5.7998) | Total Time 0.00(0.00)\n",
      "Iter 0110 | Time 12.6637(12.7309) | Bit/dim 6.9918(7.3623) | Xent 2.0765(2.1023) | Loss 16.7545(17.6479) | Error 0.7089(0.7165) Steps 484(461.52) | Grad Norm 3.0574(5.1082) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 69.1527, Epoch Time 747.5310(741.3084), Bit/dim 6.9959(best: 7.7088), Xent 2.0526, Loss 8.0222, Error 0.6911(best: 0.6979)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n",
      "14.940119760479043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0120 | Time 12.5374(12.6183) | Bit/dim 6.9555(7.2617) | Xent 2.0468(2.0898) | Loss 16.4775(17.8154) | Error 0.6933(0.7114) Steps 466(463.43) | Grad Norm 4.0916(4.6719) | Total Time 0.00(0.00)\n",
      "Iter 0130 | Time 12.0081(12.5462) | Bit/dim 6.9351(7.1765) | Xent 2.0539(2.0784) | Loss 16.4733(17.4990) | Error 0.7111(0.7063) Steps 460(465.13) | Grad Norm 7.9723(4.6216) | Total Time 0.00(0.00)\n",
      "Iter 0140 | Time 12.3804(12.5521) | Bit/dim 6.8864(7.1054) | Xent 2.0403(2.0730) | Loss 16.5985(17.2746) | Error 0.6822(0.7052) Steps 490(469.06) | Grad Norm 8.0179(5.7451) | Total Time 0.00(0.00)\n",
      "Iter 0150 | Time 12.0846(12.5261) | Bit/dim 6.8108(7.0370) | Xent 2.0405(2.0624) | Loss 16.2303(17.0497) | Error 0.7022(0.7019) Steps 478(468.81) | Grad Norm 12.3063(6.5377) | Total Time 0.00(0.00)\n",
      "Iter 0160 | Time 12.4830(12.6662) | Bit/dim 6.7512(6.9687) | Xent 2.0576(2.0526) | Loss 16.3311(16.8654) | Error 0.7300(0.6977) Steps 448(472.50) | Grad Norm 15.6230(7.8266) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 71.8359, Epoch Time 783.6969(742.5800), Bit/dim 6.6861(best: 6.9959), Xent 1.9986, Loss 7.6854, Error 0.6629(best: 0.6911)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n",
      "14.910179640718562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0170 | Time 12.5632(12.7234) | Bit/dim 6.6488(6.8984) | Xent 2.0327(2.0535) | Loss 15.9506(17.1589) | Error 0.6989(0.7018) Steps 496(476.98) | Grad Norm 34.2128(13.9591) | Total Time 0.00(0.00)\n",
      "Iter 0180 | Time 13.2961(12.8453) | Bit/dim 6.5082(6.8121) | Xent 2.0046(2.0415) | Loss 15.8523(16.8344) | Error 0.6933(0.6963) Steps 460(480.49) | Grad Norm 15.6240(15.0877) | Total Time 0.00(0.00)\n",
      "Iter 0190 | Time 13.1580(12.9400) | Bit/dim 6.3602(6.7110) | Xent 2.0684(2.0466) | Loss 15.4520(16.5143) | Error 0.7356(0.7060) Steps 496(485.21) | Grad Norm 65.3468(23.0004) | Total Time 0.00(0.00)\n",
      "Iter 0200 | Time 13.4766(13.0382) | Bit/dim 6.3773(6.5923) | Xent 2.7004(2.0686) | Loss 16.4004(16.2424) | Error 0.8100(0.7143) Steps 508(490.44) | Grad Norm 250.7391(36.4182) | Total Time 0.00(0.00)\n",
      "Iter 0210 | Time 13.8379(13.1320) | Bit/dim 6.1089(6.4883) | Xent 2.0683(2.0858) | Loss 15.2973(16.0099) | Error 0.7278(0.7211) Steps 490(494.20) | Grad Norm 33.1586(46.4045) | Total Time 0.00(0.00)\n",
      "Iter 0220 | Time 13.5074(13.2019) | Bit/dim 5.9373(6.3594) | Xent 2.0592(2.0793) | Loss 14.6668(15.7154) | Error 0.7144(0.7186) Steps 526(496.31) | Grad Norm 56.6491(41.3590) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 73.0723, Epoch Time 822.5386(744.9788), Bit/dim 5.9209(best: 6.6861), Xent 2.0880, Loss 6.9649, Error 0.7386(best: 0.6629)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n",
      "14.880239520958083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0230 | Time 13.6169(13.2816) | Bit/dim 5.8056(6.2333) | Xent 2.1134(2.0854) | Loss 14.6058(15.8584) | Error 0.7733(0.7251) Steps 472(497.55) | Grad Norm 49.0590(45.8743) | Total Time 0.00(0.00)\n",
      "Iter 0240 | Time 13.6400(13.2459) | Bit/dim 5.6972(6.1105) | Xent 2.0130(2.0684) | Loss 14.1912(15.4608) | Error 0.6878(0.7148) Steps 520(499.92) | Grad Norm 29.3991(39.5083) | Total Time 0.00(0.00)\n",
      "Iter 0250 | Time 12.4464(13.2027) | Bit/dim 5.6695(6.0064) | Xent 1.9956(2.0522) | Loss 14.0150(15.1231) | Error 0.6967(0.7083) Steps 502(499.31) | Grad Norm 38.2296(36.3252) | Total Time 0.00(0.00)\n",
      "Iter 0260 | Time 12.7605(13.1670) | Bit/dim 5.6254(5.9160) | Xent 1.9654(2.0366) | Loss 13.9896(14.8539) | Error 0.6778(0.7021) Steps 514(498.91) | Grad Norm 18.1118(34.0956) | Total Time 0.00(0.00)\n",
      "Iter 0270 | Time 13.3520(13.1234) | Bit/dim 5.6033(5.8376) | Xent 1.9404(2.0189) | Loss 13.8774(14.6212) | Error 0.6567(0.6939) Steps 496(499.54) | Grad Norm 21.6889(31.0702) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 72.7522, Epoch Time 815.6656(747.0994), Bit/dim 5.5943(best: 5.9209), Xent 1.9316, Loss 6.5601, Error 0.6463(best: 0.6629)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n",
      "14.850299401197605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0280 | Time 12.9587(13.1239) | Bit/dim 5.5747(5.7771) | Xent 1.9804(2.0045) | Loss 14.0382(14.9461) | Error 0.6944(0.6902) Steps 508(497.59) | Grad Norm 22.0264(34.1521) | Total Time 0.00(0.00)\n",
      "Iter 0290 | Time 13.5836(13.1823) | Bit/dim 5.5019(5.7187) | Xent 1.9167(1.9910) | Loss 13.7770(14.6721) | Error 0.6356(0.6856) Steps 466(497.87) | Grad Norm 19.1198(34.0715) | Total Time 0.00(0.00)\n",
      "Iter 0300 | Time 13.2257(13.1964) | Bit/dim 5.5536(5.6749) | Xent 1.9524(1.9919) | Loss 13.7715(14.4660) | Error 0.6911(0.6908) Steps 526(499.98) | Grad Norm 50.1806(38.8099) | Total Time 0.00(0.00)\n",
      "Iter 0310 | Time 13.3196(13.1856) | Bit/dim 5.5105(5.6309) | Xent 2.0206(1.9853) | Loss 14.0218(14.2905) | Error 0.6833(0.6879) Steps 514(501.66) | Grad Norm 40.7116(37.6390) | Total Time 0.00(0.00)\n",
      "Iter 0320 | Time 13.4876(13.1817) | Bit/dim 5.4386(5.5926) | Xent 1.9214(1.9739) | Loss 13.5817(14.1320) | Error 0.6622(0.6826) Steps 502(501.26) | Grad Norm 10.3079(33.0982) | Total Time 0.00(0.00)\n",
      "Iter 0330 | Time 13.2313(13.1916) | Bit/dim 5.4272(5.5504) | Xent 1.8985(1.9596) | Loss 13.6215(13.9921) | Error 0.6467(0.6766) Steps 502(499.92) | Grad Norm 32.4598(30.4415) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 75.4722, Epoch Time 823.3359(749.3865), Bit/dim 5.4119(best: 5.5943), Xent 1.8831, Loss 6.3535, Error 0.6311(best: 0.6463)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n",
      "14.820359281437126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0340 | Time 13.0859(13.2625) | Bit/dim 5.4097(5.5123) | Xent 1.9097(1.9430) | Loss 13.6396(14.3095) | Error 0.6489(0.6701) Steps 508(503.94) | Grad Norm 19.0092(28.5870) | Total Time 0.00(0.00)\n",
      "Iter 0350 | Time 13.2276(13.2789) | Bit/dim 5.3442(5.4791) | Xent 1.8868(1.9338) | Loss 13.3128(14.0845) | Error 0.6600(0.6671) Steps 502(506.61) | Grad Norm 62.9330(33.0120) | Total Time 0.00(0.00)\n",
      "Iter 0360 | Time 13.3303(13.4216) | Bit/dim 5.3740(5.4426) | Xent 1.8777(1.9266) | Loss 13.4014(13.9164) | Error 0.6544(0.6642) Steps 532(511.39) | Grad Norm 20.2799(29.2961) | Total Time 0.00(0.00)\n",
      "Iter 0370 | Time 13.9820(13.4293) | Bit/dim 5.3038(5.4066) | Xent 1.9752(1.9317) | Loss 13.5070(13.7804) | Error 0.6956(0.6672) Steps 526(513.07) | Grad Norm 74.2058(32.2726) | Total Time 0.00(0.00)\n",
      "Iter 0380 | Time 12.5053(13.4562) | Bit/dim 5.3029(5.3851) | Xent 2.0028(1.9717) | Loss 13.5230(13.7236) | Error 0.6911(0.6827) Steps 502(511.77) | Grad Norm 29.8859(38.1803) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 76.0554, Epoch Time 839.4783(752.0892), Bit/dim 5.2724(best: 5.4119), Xent 1.9613, Loss 6.2531, Error 0.6778(best: 0.6311)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n",
      "14.790419161676645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0390 | Time 14.1162(13.4516) | Bit/dim 5.3046(5.3637) | Xent 1.9488(1.9714) | Loss 13.5771(14.1564) | Error 0.6756(0.6821) Steps 502(509.70) | Grad Norm 21.1749(33.9473) | Total Time 0.00(0.00)\n",
      "Iter 0400 | Time 13.4625(13.5025) | Bit/dim 5.2172(5.3312) | Xent 1.9405(1.9624) | Loss 13.0913(13.9304) | Error 0.6689(0.6760) Steps 526(510.77) | Grad Norm 9.5432(28.9272) | Total Time 0.00(0.00)\n",
      "Iter 0410 | Time 14.3484(13.5863) | Bit/dim 5.1933(5.2963) | Xent 1.9290(1.9525) | Loss 13.2052(13.7152) | Error 0.6689(0.6732) Steps 532(511.75) | Grad Norm 5.7578(23.6352) | Total Time 0.00(0.00)\n",
      "Iter 0420 | Time 14.3942(13.6774) | Bit/dim 5.1631(5.2677) | Xent 1.8876(1.9382) | Loss 13.0273(13.5553) | Error 0.6389(0.6677) Steps 496(510.88) | Grad Norm 11.6205(19.7968) | Total Time 0.00(0.00)\n",
      "Iter 0430 | Time 14.0234(13.7757) | Bit/dim 5.1763(5.2374) | Xent 1.9016(1.9258) | Loss 13.1135(13.4213) | Error 0.6411(0.6639) Steps 490(510.85) | Grad Norm 15.6312(17.6458) | Total Time 0.00(0.00)\n",
      "Iter 0440 | Time 13.1238(13.7312) | Bit/dim 5.1727(5.2151) | Xent 1.9819(1.9216) | Loss 13.2749(13.3272) | Error 0.6944(0.6646) Steps 496(511.93) | Grad Norm 58.9260(23.2671) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 76.6923, Epoch Time 857.9310(755.2645), Bit/dim 5.1231(best: 5.2724), Xent 1.9073, Loss 6.0767, Error 0.6629(best: 0.6311)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n",
      "14.760479041916168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0450 | Time 13.6585(13.7804) | Bit/dim 5.0728(5.1919) | Xent 1.8998(1.9182) | Loss 12.9350(13.6703) | Error 0.6889(0.6659) Steps 526(512.26) | Grad Norm 27.7716(24.0760) | Total Time 0.00(0.00)\n",
      "Iter 0460 | Time 15.0469(13.8787) | Bit/dim 5.0606(5.1681) | Xent 1.8581(1.9119) | Loss 12.8336(13.4765) | Error 0.6389(0.6633) Steps 568(514.51) | Grad Norm 26.0169(24.0930) | Total Time 0.00(0.00)\n",
      "Iter 0470 | Time 14.5953(13.9216) | Bit/dim 5.0568(5.1389) | Xent 1.9236(1.9082) | Loss 12.8803(13.3091) | Error 0.6922(0.6652) Steps 526(515.44) | Grad Norm 45.7126(24.6759) | Total Time 0.00(0.00)\n",
      "Iter 0480 | Time 14.5752(14.0052) | Bit/dim 5.0307(5.1091) | Xent 1.9369(1.9038) | Loss 12.7705(13.1653) | Error 0.6900(0.6655) Steps 508(518.35) | Grad Norm 42.1041(26.5691) | Total Time 0.00(0.00)\n",
      "Iter 0490 | Time 14.7450(14.0856) | Bit/dim 4.9616(5.0802) | Xent 1.9445(1.9088) | Loss 12.5756(13.0556) | Error 0.6889(0.6684) Steps 520(518.86) | Grad Norm 28.2948(27.0923) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 78.3018, Epoch Time 875.7744(758.8798), Bit/dim 4.9799(best: 5.1231), Xent 1.8534, Loss 5.9065, Error 0.6536(best: 0.6311)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n",
      "14.730538922155688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0500 | Time 14.1618(14.1486) | Bit/dim 4.9774(5.0518) | Xent 1.8665(1.9075) | Loss 12.7527(13.4612) | Error 0.6589(0.6673) Steps 520(518.63) | Grad Norm 28.7479(26.8410) | Total Time 0.00(0.00)\n",
      "Iter 0510 | Time 13.8899(14.1723) | Bit/dim 4.8884(5.0230) | Xent 1.8353(1.8977) | Loss 12.4018(13.2278) | Error 0.6489(0.6628) Steps 532(519.17) | Grad Norm 12.7127(24.9484) | Total Time 0.00(0.00)\n",
      "Iter 0520 | Time 14.4434(14.2476) | Bit/dim 4.9503(4.9946) | Xent 1.9013(1.8798) | Loss 12.6711(13.0287) | Error 0.6567(0.6582) Steps 526(524.38) | Grad Norm 49.5942(25.8493) | Total Time 0.00(0.00)\n",
      "Iter 0530 | Time 15.0461(14.3591) | Bit/dim 4.8661(4.9665) | Xent 1.8162(1.8650) | Loss 12.4969(12.8839) | Error 0.6478(0.6547) Steps 562(530.73) | Grad Norm 33.0706(25.6544) | Total Time 0.00(0.00)\n",
      "Iter 0540 | Time 14.2975(14.4682) | Bit/dim 4.9584(4.9439) | Xent 1.9436(1.8588) | Loss 12.5739(12.7483) | Error 0.6933(0.6531) Steps 538(533.52) | Grad Norm 86.9951(28.7808) | Total Time 0.00(0.00)\n",
      "Iter 0550 | Time 15.5456(14.5413) | Bit/dim 5.0656(4.9801) | Xent 2.0821(1.9332) | Loss 13.0556(12.8596) | Error 0.7400(0.6794) Steps 574(539.59) | Grad Norm 28.1496(34.6243) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 84.3838, Epoch Time 905.7631(763.2863), Bit/dim 5.0404(best: 4.9799), Xent 2.0612, Loss 6.0710, Error 0.7353(best: 0.6311)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n",
      "14.70059880239521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0560 | Time 13.8082(14.5673) | Bit/dim 4.8763(4.9791) | Xent 1.9424(1.9513) | Loss 12.4974(13.2940) | Error 0.6978(0.6891) Steps 514(540.05) | Grad Norm 7.0210(29.4356) | Total Time 0.00(0.00)\n",
      "Iter 0570 | Time 14.3908(14.5095) | Bit/dim 4.8774(4.9514) | Xent 1.9415(1.9427) | Loss 12.6689(13.0923) | Error 0.6878(0.6877) Steps 556(537.50) | Grad Norm 23.2281(25.1036) | Total Time 0.00(0.00)\n",
      "Iter 0580 | Time 14.0694(14.4718) | Bit/dim 4.7821(4.9157) | Xent 1.8448(1.9209) | Loss 12.2491(12.8938) | Error 0.6444(0.6776) Steps 520(536.26) | Grad Norm 16.1897(21.8149) | Total Time 0.00(0.00)\n",
      "Iter 0590 | Time 14.4013(14.4903) | Bit/dim 4.7900(4.8826) | Xent 1.7932(1.8989) | Loss 12.0938(12.7252) | Error 0.6289(0.6697) Steps 556(536.33) | Grad Norm 6.5073(21.3304) | Total Time 0.00(0.00)\n",
      "Iter 0600 | Time 15.1939(14.5968) | Bit/dim 4.7265(4.8545) | Xent 1.8220(1.8786) | Loss 12.1831(12.6102) | Error 0.6244(0.6629) Steps 520(536.93) | Grad Norm 30.0012(22.6786) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 81.4340, Epoch Time 905.2261(767.5445), Bit/dim 4.7458(best: 4.9799), Xent 1.7260, Loss 5.6088, Error 0.5938(best: 0.6311)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n",
      "14.67065868263473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0610 | Time 14.4887(14.7237) | Bit/dim 4.7210(4.8253) | Xent 1.7203(1.8517) | Loss 12.0428(13.0167) | Error 0.6011(0.6520) Steps 544(541.32) | Grad Norm 7.7356(22.2512) | Total Time 0.00(0.00)\n",
      "Iter 0620 | Time 14.9800(14.8055) | Bit/dim 4.8174(4.8040) | Xent 2.0034(1.8335) | Loss 12.6443(12.7848) | Error 0.6956(0.6452) Steps 544(541.53) | Grad Norm 69.7202(21.8234) | Total Time 0.00(0.00)\n",
      "Iter 0630 | Time 15.6923(14.9684) | Bit/dim 4.7451(4.7885) | Xent 1.8310(1.8220) | Loss 12.2379(12.6326) | Error 0.6389(0.6405) Steps 562(546.33) | Grad Norm 47.9222(25.7441) | Total Time 0.00(0.00)\n",
      "Iter 0640 | Time 15.5753(15.1249) | Bit/dim 4.7193(4.7755) | Xent 1.9430(1.8209) | Loss 12.3413(12.5147) | Error 0.6789(0.6405) Steps 580(552.56) | Grad Norm 62.1457(28.9171) | Total Time 0.00(0.00)\n",
      "Iter 0650 | Time 14.6987(15.1531) | Bit/dim 4.6688(4.7547) | Xent 1.8058(1.8225) | Loss 12.0575(12.4155) | Error 0.6711(0.6433) Steps 568(554.11) | Grad Norm 21.3809(27.7399) | Total Time 0.00(0.00)\n",
      "Iter 0660 | Time 15.2796(15.1858) | Bit/dim 4.7443(4.7391) | Xent 1.7565(1.8062) | Loss 12.1284(12.3168) | Error 0.6300(0.6392) Steps 544(555.02) | Grad Norm 16.7924(25.2706) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 81.5112, Epoch Time 942.6158(772.7966), Bit/dim 4.6867(best: 4.7458), Xent 1.6773, Loss 5.5253, Error 0.5804(best: 0.5938)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n",
      "14.640718562874252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0670 | Time 15.5085(15.2040) | Bit/dim 4.6731(4.7262) | Xent 1.7075(1.7883) | Loss 11.8466(12.6972) | Error 0.6033(0.6331) Steps 544(556.91) | Grad Norm 21.1452(25.5544) | Total Time 0.00(0.00)\n",
      "Iter 0680 | Time 17.6667(15.2938) | Bit/dim 4.7112(4.7090) | Xent 1.7354(1.7678) | Loss 12.2293(12.4886) | Error 0.6044(0.6260) Steps 664(562.13) | Grad Norm 54.3401(24.1185) | Total Time 0.00(0.00)\n",
      "Iter 0690 | Time 15.2227(15.3890) | Bit/dim 4.6615(4.7066) | Xent 1.6832(1.7786) | Loss 11.7885(12.3775) | Error 0.5956(0.6316) Steps 550(565.51) | Grad Norm 15.5230(27.9220) | Total Time 0.00(0.00)\n",
      "Iter 0700 | Time 15.9108(15.4508) | Bit/dim 4.6271(4.6965) | Xent 1.8537(1.7783) | Loss 12.0489(12.2736) | Error 0.6589(0.6310) Steps 544(564.85) | Grad Norm 38.9494(27.9616) | Total Time 0.00(0.00)\n",
      "Iter 0710 | Time 15.1774(15.4524) | Bit/dim 4.6267(4.6894) | Xent 1.7055(1.7701) | Loss 11.8362(12.1823) | Error 0.5922(0.6292) Steps 550(565.96) | Grad Norm 11.6694(27.3720) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 82.2083, Epoch Time 951.9130(778.1701), Bit/dim 4.6415(best: 4.6867), Xent 1.6722, Loss 5.4776, Error 0.5825(best: 0.5804)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n",
      "14.610778443113773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0720 | Time 15.8862(15.4168) | Bit/dim 4.6225(4.6734) | Xent 1.6646(1.7594) | Loss 11.8527(12.6570) | Error 0.5833(0.6239) Steps 598(567.63) | Grad Norm 15.9803(25.2114) | Total Time 0.00(0.00)\n",
      "Iter 0730 | Time 14.8418(15.3676) | Bit/dim 4.6539(4.6608) | Xent 1.7319(1.7430) | Loss 11.8466(12.4249) | Error 0.6122(0.6183) Steps 568(565.50) | Grad Norm 30.8130(23.9838) | Total Time 0.00(0.00)\n",
      "Iter 0740 | Time 14.7391(15.4316) | Bit/dim 4.6157(4.6479) | Xent 1.7028(1.7228) | Loss 11.7409(12.2584) | Error 0.6144(0.6128) Steps 562(563.34) | Grad Norm 34.9892(22.9719) | Total Time 0.00(0.00)\n",
      "Iter 0750 | Time 15.4372(15.4283) | Bit/dim 4.7545(4.6518) | Xent 1.8277(1.7355) | Loss 12.3144(12.1876) | Error 0.6400(0.6169) Steps 604(567.82) | Grad Norm 42.2107(26.3007) | Total Time 0.00(0.00)\n",
      "Iter 0760 | Time 15.0537(15.3895) | Bit/dim 4.6002(4.6443) | Xent 1.6777(1.7321) | Loss 11.7571(12.1075) | Error 0.5900(0.6147) Steps 568(567.73) | Grad Norm 10.5179(23.9358) | Total Time 0.00(0.00)\n",
      "Iter 0770 | Time 15.2326(15.4504) | Bit/dim 4.5692(4.6258) | Xent 1.6922(1.7190) | Loss 11.6216(11.9995) | Error 0.5900(0.6090) Steps 574(569.43) | Grad Norm 9.7524(20.8897) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 84.6452, Epoch Time 954.5383(783.4612), Bit/dim 4.5650(best: 4.6415), Xent 1.5812, Loss 5.3556, Error 0.5699(best: 0.5804)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n",
      "14.580838323353294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0780 | Time 15.7590(15.5180) | Bit/dim 4.5168(4.6064) | Xent 1.6424(1.6873) | Loss 11.5956(12.3647) | Error 0.5944(0.5983) Steps 574(572.55) | Grad Norm 8.7639(17.6246) | Total Time 0.00(0.00)\n",
      "Iter 0790 | Time 15.2460(15.5393) | Bit/dim 4.5331(4.5918) | Xent 1.6309(1.6712) | Loss 11.6610(12.1820) | Error 0.5800(0.5927) Steps 568(577.64) | Grad Norm 16.9389(17.3217) | Total Time 0.00(0.00)\n",
      "Iter 0800 | Time 14.7803(15.4446) | Bit/dim 4.5760(4.5777) | Xent 1.7157(1.6646) | Loss 11.8173(12.0368) | Error 0.6000(0.5911) Steps 562(577.19) | Grad Norm 36.7694(18.1263) | Total Time 0.00(0.00)\n",
      "Iter 0810 | Time 15.8099(15.4925) | Bit/dim 4.6266(4.5763) | Xent 1.7207(1.7029) | Loss 12.0089(11.9928) | Error 0.6244(0.6054) Steps 592(579.43) | Grad Norm 47.6534(21.9584) | Total Time 0.00(0.00)\n",
      "Iter 0820 | Time 15.3687(15.5568) | Bit/dim 4.5541(4.5706) | Xent 1.6886(1.7018) | Loss 11.6196(11.9132) | Error 0.5944(0.6045) Steps 586(578.65) | Grad Norm 18.1907(21.8343) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 83.4908, Epoch Time 958.7570(788.7200), Bit/dim 4.5212(best: 4.5650), Xent 1.5670, Loss 5.3047, Error 0.5662(best: 0.5699)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n",
      "14.550898203592814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0830 | Time 14.4372(15.4561) | Bit/dim 4.5429(4.5576) | Xent 1.6059(1.6828) | Loss 11.6263(12.3679) | Error 0.5744(0.5989) Steps 562(578.57) | Grad Norm 18.4557(19.6951) | Total Time 0.00(0.00)\n",
      "Iter 0840 | Time 15.5061(15.3409) | Bit/dim 4.5010(4.5412) | Xent 1.5682(1.6619) | Loss 11.4855(12.1372) | Error 0.5522(0.5919) Steps 592(577.35) | Grad Norm 12.8017(17.6378) | Total Time 0.00(0.00)\n",
      "Iter 0850 | Time 14.8669(15.2785) | Bit/dim 4.4693(4.5305) | Xent 1.6034(1.6477) | Loss 11.4287(11.9703) | Error 0.5700(0.5878) Steps 568(576.08) | Grad Norm 13.9708(18.2252) | Total Time 0.00(0.00)\n",
      "Iter 0860 | Time 15.4304(15.3268) | Bit/dim 4.4908(4.5248) | Xent 1.7038(1.6493) | Loss 11.5579(11.8641) | Error 0.6211(0.5889) Steps 562(575.15) | Grad Norm 15.0016(20.4620) | Total Time 0.00(0.00)\n",
      "Iter 0870 | Time 15.5341(15.3479) | Bit/dim 4.4784(4.5139) | Xent 1.6467(1.6548) | Loss 11.1805(11.7591) | Error 0.5900(0.5908) Steps 604(573.55) | Grad Norm 18.9245(20.8826) | Total Time 0.00(0.00)\n",
      "Iter 0880 | Time 15.3777(15.3752) | Bit/dim 4.4464(4.4966) | Xent 1.6014(1.6491) | Loss 11.5078(11.6840) | Error 0.5822(0.5907) Steps 598(573.78) | Grad Norm 10.1179(18.6356) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 84.2058, Epoch Time 944.4316(793.3914), Bit/dim 4.4409(best: 4.5212), Xent 1.5318, Loss 5.2068, Error 0.5508(best: 0.5662)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n",
      "14.520958083832337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0890 | Time 15.4096(15.3314) | Bit/dim 4.4207(4.4837) | Xent 1.6313(1.6399) | Loss 11.3871(12.0800) | Error 0.5900(0.5884) Steps 622(577.17) | Grad Norm 17.8833(18.1309) | Total Time 0.00(0.00)\n",
      "Iter 0900 | Time 15.4850(15.3841) | Bit/dim 4.4156(4.4693) | Xent 1.5534(1.6290) | Loss 11.3479(11.9001) | Error 0.5711(0.5844) Steps 592(577.72) | Grad Norm 25.5830(18.3960) | Total Time 0.00(0.00)\n",
      "Iter 0910 | Time 15.6769(15.3931) | Bit/dim 4.4280(4.4551) | Xent 1.6191(1.6142) | Loss 11.2879(11.7374) | Error 0.5800(0.5785) Steps 556(574.76) | Grad Norm 20.7128(18.2269) | Total Time 0.00(0.00)\n",
      "Iter 0920 | Time 17.0253(15.4354) | Bit/dim 4.3947(4.4422) | Xent 1.5416(1.6075) | Loss 11.3284(11.6180) | Error 0.5433(0.5775) Steps 562(574.17) | Grad Norm 6.1662(17.5702) | Total Time 0.00(0.00)\n",
      "Iter 0930 | Time 15.3135(15.4672) | Bit/dim 4.4865(4.4368) | Xent 1.6243(1.6129) | Loss 11.5065(11.5564) | Error 0.5933(0.5799) Steps 598(577.51) | Grad Norm 37.9699(19.1072) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 84.2463, Epoch Time 954.4267(798.2224), Bit/dim 4.4063(best: 4.4409), Xent 1.5675, Loss 5.1901, Error 0.5734(best: 0.5508)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n",
      "14.491017964071856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 0940 | Time 16.0595(15.5079) | Bit/dim 4.3917(4.4319) | Xent 1.5436(1.6122) | Loss 11.2331(12.0228) | Error 0.5911(0.5804) Steps 544(573.99) | Grad Norm 9.2124(18.9675) | Total Time 0.00(0.00)\n",
      "Iter 0950 | Time 15.5386(15.4364) | Bit/dim 4.3897(4.4167) | Xent 1.5444(1.6027) | Loss 11.1880(11.8244) | Error 0.5633(0.5767) Steps 586(576.18) | Grad Norm 15.5415(18.4199) | Total Time 0.00(0.00)\n",
      "Iter 0960 | Time 14.9123(15.4731) | Bit/dim 4.3459(4.4015) | Xent 1.5666(1.5870) | Loss 11.0907(11.6544) | Error 0.5822(0.5714) Steps 586(577.00) | Grad Norm 14.4850(17.2577) | Total Time 0.00(0.00)\n",
      "Iter 0970 | Time 15.3216(15.4244) | Bit/dim 4.3629(4.3872) | Xent 1.5526(1.5782) | Loss 11.1387(11.5277) | Error 0.5578(0.5697) Steps 598(579.68) | Grad Norm 18.4243(16.4001) | Total Time 0.00(0.00)\n",
      "Iter 0980 | Time 14.2943(15.3655) | Bit/dim 4.6738(4.3816) | Xent 1.7774(1.5813) | Loss 12.1023(11.4408) | Error 0.6622(0.5704) Steps 556(580.50) | Grad Norm 48.3822(17.8168) | Total Time 0.00(0.00)\n",
      "Iter 0990 | Time 16.4220(15.4507) | Bit/dim 4.4269(4.4018) | Xent 1.6701(1.6155) | Loss 11.5903(11.4693) | Error 0.6122(0.5813) Steps 616(583.44) | Grad Norm 17.0500(20.5353) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 88.9252, Epoch Time 957.7257(803.0075), Bit/dim 4.4051(best: 4.4063), Xent 1.5846, Loss 5.1973, Error 0.5708(best: 0.5508)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n",
      "14.461077844311378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1000 | Time 15.4721(15.4961) | Bit/dim 4.3618(4.3928) | Xent 1.5739(1.6074) | Loss 11.1530(11.9487) | Error 0.5889(0.5814) Steps 598(590.67) | Grad Norm 6.9420(18.1871) | Total Time 0.00(0.00)\n",
      "Iter 1010 | Time 14.9172(15.4304) | Bit/dim 4.3097(4.3738) | Xent 1.5419(1.5909) | Loss 10.9719(11.7295) | Error 0.5556(0.5757) Steps 580(589.28) | Grad Norm 15.1915(16.0628) | Total Time 0.00(0.00)\n",
      "Iter 1020 | Time 15.4853(15.3899) | Bit/dim 4.3747(4.3587) | Xent 1.6471(1.5751) | Loss 11.3739(11.5636) | Error 0.5800(0.5688) Steps 568(587.49) | Grad Norm 33.8184(16.8227) | Total Time 0.00(0.00)\n",
      "Iter 1030 | Time 15.3612(15.3132) | Bit/dim 4.2976(4.3451) | Xent 1.5457(1.5747) | Loss 11.1406(11.4417) | Error 0.5511(0.5693) Steps 592(588.20) | Grad Norm 22.4315(17.6562) | Total Time 0.00(0.00)\n",
      "Iter 1040 | Time 14.5717(15.2737) | Bit/dim 4.3013(4.3307) | Xent 1.5292(1.5673) | Loss 11.0629(11.3352) | Error 0.5367(0.5665) Steps 574(587.36) | Grad Norm 16.7761(17.1551) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 82.3934, Epoch Time 943.9951(807.2372), Bit/dim 4.2940(best: 4.4051), Xent 1.4856, Loss 5.0368, Error 0.5283(best: 0.5508)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n",
      "14.431137724550899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1050 | Time 15.3528(15.2950) | Bit/dim 4.2574(4.3207) | Xent 1.4436(1.5624) | Loss 10.8826(11.7881) | Error 0.5311(0.5641) Steps 568(583.47) | Grad Norm 13.6671(17.5762) | Total Time 0.00(0.00)\n",
      "Iter 1060 | Time 15.9895(15.3056) | Bit/dim 4.2780(4.3056) | Xent 1.4581(1.5432) | Loss 10.9434(11.5577) | Error 0.5000(0.5548) Steps 574(582.03) | Grad Norm 5.8469(15.8172) | Total Time 0.00(0.00)\n",
      "Iter 1070 | Time 14.5850(15.2850) | Bit/dim 4.2803(4.2922) | Xent 1.5105(1.5256) | Loss 10.9829(11.3861) | Error 0.5378(0.5486) Steps 562(579.52) | Grad Norm 8.5708(13.8117) | Total Time 0.00(0.00)\n",
      "Iter 1080 | Time 14.7834(15.2989) | Bit/dim 4.2345(4.2788) | Xent 1.5167(1.5107) | Loss 10.7390(11.2507) | Error 0.5322(0.5435) Steps 586(581.46) | Grad Norm 19.1154(13.2172) | Total Time 0.00(0.00)\n",
      "Iter 1090 | Time 15.1148(15.1918) | Bit/dim 4.2441(4.2708) | Xent 1.5512(1.5168) | Loss 10.9934(11.1658) | Error 0.5678(0.5456) Steps 604(580.98) | Grad Norm 27.8537(15.8996) | Total Time 0.00(0.00)\n",
      "Iter 1100 | Time 16.1432(15.1881) | Bit/dim 4.2522(4.2643) | Xent 1.4202(1.5140) | Loss 10.9299(11.1063) | Error 0.5067(0.5456) Steps 586(581.75) | Grad Norm 12.0946(15.6104) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 85.2681, Epoch Time 941.8209(811.2747), Bit/dim 4.2545(best: 4.2940), Xent 1.4203, Loss 4.9647, Error 0.5136(best: 0.5283)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n",
      "14.40119760479042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1110 | Time 14.9807(15.2047) | Bit/dim 4.2876(4.2664) | Xent 1.5539(1.5178) | Loss 10.9407(11.5506) | Error 0.5678(0.5460) Steps 580(584.58) | Grad Norm 17.7099(18.0750) | Total Time 0.00(0.00)\n",
      "Iter 1120 | Time 16.0676(15.1789) | Bit/dim 4.1912(4.2555) | Xent 1.4980(1.5121) | Loss 10.7917(11.3694) | Error 0.5611(0.5443) Steps 550(582.29) | Grad Norm 11.4050(16.3096) | Total Time 0.00(0.00)\n",
      "Iter 1130 | Time 14.6530(15.2490) | Bit/dim 4.2169(4.2445) | Xent 1.4621(1.4937) | Loss 10.8367(11.2253) | Error 0.5411(0.5392) Steps 586(582.97) | Grad Norm 9.2204(14.6082) | Total Time 0.00(0.00)\n",
      "Iter 1140 | Time 15.0002(15.1973) | Bit/dim 4.1862(4.2318) | Xent 1.3920(1.4797) | Loss 10.6613(11.0975) | Error 0.5089(0.5346) Steps 574(583.83) | Grad Norm 8.4973(14.0231) | Total Time 0.00(0.00)\n",
      "Iter 1150 | Time 15.1063(15.2128) | Bit/dim 4.1830(4.2180) | Xent 1.4329(1.4720) | Loss 10.8053(11.0012) | Error 0.5378(0.5327) Steps 586(582.53) | Grad Norm 9.2269(13.1609) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 83.5527, Epoch Time 943.4737(815.2406), Bit/dim 4.1744(best: 4.2545), Xent 1.3266, Loss 4.8377, Error 0.4741(best: 0.5136)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n",
      "14.37125748502994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1160 | Time 15.4045(15.2700) | Bit/dim 4.1859(4.2094) | Xent 1.4922(1.4543) | Loss 10.9823(11.4791) | Error 0.5322(0.5267) Steps 604(583.45) | Grad Norm 31.7885(12.7593) | Total Time 0.00(0.00)\n",
      "Iter 1170 | Time 14.9278(15.2757) | Bit/dim 4.1818(4.2014) | Xent 1.4404(1.4605) | Loss 10.5146(11.2812) | Error 0.5011(0.5255) Steps 598(584.83) | Grad Norm 9.4101(14.0964) | Total Time 0.00(0.00)\n",
      "Iter 1180 | Time 15.4390(15.3017) | Bit/dim 4.1297(4.1917) | Xent 1.4915(1.4497) | Loss 10.7924(11.1242) | Error 0.5422(0.5218) Steps 580(586.23) | Grad Norm 32.6907(14.5602) | Total Time 0.00(0.00)\n",
      "Iter 1190 | Time 15.6317(15.3199) | Bit/dim 4.1974(4.1884) | Xent 1.4532(1.4487) | Loss 10.7005(11.0184) | Error 0.5322(0.5226) Steps 604(588.63) | Grad Norm 26.4690(15.8630) | Total Time 0.00(0.00)\n",
      "Iter 1200 | Time 15.3707(15.3479) | Bit/dim 4.1395(4.1798) | Xent 1.4275(1.4513) | Loss 10.6099(10.9328) | Error 0.5200(0.5241) Steps 580(587.31) | Grad Norm 11.0903(16.1683) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 15.6967(15.3788) | Bit/dim 4.1630(4.1691) | Xent 1.4138(1.4442) | Loss 10.6888(10.8584) | Error 0.5189(0.5229) Steps 604(588.42) | Grad Norm 15.6839(15.6738) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 81.7477, Epoch Time 947.5406(819.2096), Bit/dim 4.1504(best: 4.1744), Xent 1.3355, Loss 4.8182, Error 0.4820(best: 0.4741)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n",
      "14.341317365269461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1220 | Time 15.9219(15.3832) | Bit/dim 4.1468(4.1657) | Xent 1.4455(1.4410) | Loss 10.6552(11.2658) | Error 0.5233(0.5205) Steps 598(589.50) | Grad Norm 7.7436(16.6238) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 15.0814(15.3205) | Bit/dim 4.1368(4.1593) | Xent 1.3920(1.4254) | Loss 10.5973(11.0986) | Error 0.5056(0.5143) Steps 592(591.20) | Grad Norm 9.3698(15.1797) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 15.4064(15.2218) | Bit/dim 4.1300(4.1497) | Xent 1.3785(1.4101) | Loss 10.4813(10.9332) | Error 0.4911(0.5093) Steps 604(587.68) | Grad Norm 14.9650(14.0737) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 15.2530(15.1823) | Bit/dim 4.1279(4.1410) | Xent 1.4642(1.4036) | Loss 10.6686(10.8305) | Error 0.5189(0.5062) Steps 586(587.09) | Grad Norm 26.0699(13.8179) | Total Time 0.00(0.00)\n",
      "Iter 1260 | Time 15.3121(15.2042) | Bit/dim 4.1382(4.1403) | Xent 1.3598(1.4005) | Loss 10.5922(10.7605) | Error 0.4844(0.5066) Steps 574(587.32) | Grad Norm 9.4796(14.7912) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 82.8575, Epoch Time 937.9875(822.7730), Bit/dim 4.1088(best: 4.1504), Xent 1.3132, Loss 4.7654, Error 0.4781(best: 0.4741)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n",
      "14.311377245508982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1270 | Time 15.5494(15.2846) | Bit/dim 4.0883(4.1305) | Xent 1.3700(1.3950) | Loss 10.6299(11.2592) | Error 0.4856(0.5038) Steps 574(587.36) | Grad Norm 8.8007(14.0036) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 15.8796(15.2964) | Bit/dim 4.0732(4.1193) | Xent 1.3276(1.3873) | Loss 10.4951(11.0574) | Error 0.4822(0.5021) Steps 598(588.05) | Grad Norm 11.1666(14.2827) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 14.9125(15.2330) | Bit/dim 4.1108(4.1169) | Xent 1.3383(1.3754) | Loss 10.5304(10.9082) | Error 0.4711(0.4963) Steps 574(586.10) | Grad Norm 12.8373(14.4184) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 15.1894(15.2201) | Bit/dim 4.0956(4.1108) | Xent 1.3637(1.3692) | Loss 10.4565(10.7790) | Error 0.5122(0.4950) Steps 586(586.91) | Grad Norm 10.5040(13.7421) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 15.0021(15.2005) | Bit/dim 4.1215(4.1036) | Xent 1.3386(1.3624) | Loss 10.3927(10.6758) | Error 0.4944(0.4914) Steps 568(585.89) | Grad Norm 22.3132(13.7600) | Total Time 0.00(0.00)\n",
      "Iter 1320 | Time 15.5527(15.1974) | Bit/dim 4.0899(4.0979) | Xent 1.3735(1.3576) | Loss 10.5127(10.6159) | Error 0.4978(0.4882) Steps 610(584.80) | Grad Norm 14.5562(13.6445) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 85.3908, Epoch Time 943.0045(826.3799), Bit/dim 4.0841(best: 4.1088), Xent 1.2724, Loss 4.7203, Error 0.4610(best: 0.4741)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n",
      "14.281437125748502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1330 | Time 16.3021(15.2801) | Bit/dim 4.1285(4.0911) | Xent 1.3322(1.3487) | Loss 10.5624(11.0458) | Error 0.4856(0.4867) Steps 580(586.39) | Grad Norm 24.4587(14.1991) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 15.6806(15.2945) | Bit/dim 4.0333(4.0878) | Xent 1.3775(1.3584) | Loss 10.2758(10.8900) | Error 0.4867(0.4898) Steps 592(586.03) | Grad Norm 15.0755(15.5965) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 15.3964(15.3222) | Bit/dim 4.0548(4.0821) | Xent 1.3407(1.3492) | Loss 10.4041(10.7612) | Error 0.4800(0.4860) Steps 568(584.93) | Grad Norm 16.7798(14.8378) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 15.7750(15.4232) | Bit/dim 4.0619(4.0784) | Xent 1.2813(1.3456) | Loss 10.3988(10.6735) | Error 0.4689(0.4851) Steps 592(583.04) | Grad Norm 9.7489(14.3644) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 15.0577(15.4199) | Bit/dim 4.0315(4.0734) | Xent 1.3597(1.3398) | Loss 10.2523(10.5949) | Error 0.4889(0.4825) Steps 586(582.73) | Grad Norm 15.0634(14.0026) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 85.6126, Epoch Time 954.2547(830.2162), Bit/dim 4.0484(best: 4.0841), Xent 1.2584, Loss 4.6776, Error 0.4540(best: 0.4610)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n",
      "14.251497005988025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1380 | Time 15.2098(15.3565) | Bit/dim 4.0602(4.0708) | Xent 1.2102(1.3350) | Loss 10.2893(11.1151) | Error 0.4389(0.4810) Steps 586(584.44) | Grad Norm 12.6749(13.9779) | Total Time 0.00(0.00)\n",
      "Iter 1390 | Time 15.1380(15.3397) | Bit/dim 4.0593(4.0653) | Xent 1.3013(1.3296) | Loss 10.4579(10.9200) | Error 0.4722(0.4785) Steps 604(587.10) | Grad Norm 16.0886(14.0691) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 14.6921(15.2775) | Bit/dim 4.0386(4.0603) | Xent 1.3017(1.3288) | Loss 10.2720(10.7683) | Error 0.4644(0.4775) Steps 550(586.55) | Grad Norm 11.5643(14.3809) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 15.5259(15.2742) | Bit/dim 4.0705(4.0548) | Xent 1.3361(1.3264) | Loss 10.4499(10.6546) | Error 0.4767(0.4781) Steps 574(586.01) | Grad Norm 16.1101(15.3472) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 14.2690(15.2123) | Bit/dim 3.9992(4.0481) | Xent 1.2810(1.3206) | Loss 10.2130(10.5590) | Error 0.4700(0.4766) Steps 586(585.73) | Grad Norm 8.5175(14.4521) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 14.6792(15.2251) | Bit/dim 4.0330(4.0437) | Xent 1.2427(1.3100) | Loss 10.1582(10.4832) | Error 0.4422(0.4726) Steps 586(587.66) | Grad Norm 9.6329(12.9417) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 84.6615, Epoch Time 941.2897(833.5484), Bit/dim 4.0167(best: 4.0484), Xent 1.2138, Loss 4.6236, Error 0.4369(best: 0.4540)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n",
      "14.221556886227544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1440 | Time 14.7174(15.2562) | Bit/dim 4.0529(4.0391) | Xent 1.3115(1.2945) | Loss 10.2332(10.9092) | Error 0.4667(0.4669) Steps 574(587.31) | Grad Norm 14.7819(12.3461) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 15.7165(15.2789) | Bit/dim 4.0439(4.0381) | Xent 1.3979(1.2988) | Loss 10.3337(10.7499) | Error 0.4900(0.4667) Steps 568(586.53) | Grad Norm 21.0998(14.2429) | Total Time 0.00(0.00)\n",
      "Iter 1460 | Time 15.9431(15.3472) | Bit/dim 4.0068(4.0354) | Xent 1.3133(1.3063) | Loss 10.3565(10.6489) | Error 0.4633(0.4687) Steps 634(586.69) | Grad Norm 17.6434(14.2461) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 15.6477(15.3883) | Bit/dim 4.0100(4.0301) | Xent 1.2639(1.2959) | Loss 10.2610(10.5456) | Error 0.4389(0.4662) Steps 586(584.51) | Grad Norm 14.2722(13.7251) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 15.0827(15.4443) | Bit/dim 4.0001(4.0246) | Xent 1.2939(1.2956) | Loss 10.2641(10.4699) | Error 0.4978(0.4667) Steps 598(585.99) | Grad Norm 8.1883(13.4766) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 83.9313, Epoch Time 952.7998(837.1259), Bit/dim 4.0060(best: 4.0167), Xent 1.2233, Loss 4.6176, Error 0.4433(best: 0.4369)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n",
      "14.191616766467066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1490 | Time 15.0895(15.3746) | Bit/dim 3.9905(4.0201) | Xent 1.2232(1.2943) | Loss 9.9947(10.9505) | Error 0.4533(0.4670) Steps 592(583.73) | Grad Norm 7.5825(13.7919) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 15.7983(15.3731) | Bit/dim 3.9778(4.0150) | Xent 1.1906(1.2795) | Loss 9.9695(10.7313) | Error 0.4500(0.4624) Steps 616(585.59) | Grad Norm 7.4882(12.2532) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 14.5579(15.3056) | Bit/dim 4.0110(4.0134) | Xent 1.2884(1.2747) | Loss 10.2394(10.6031) | Error 0.4633(0.4597) Steps 562(586.20) | Grad Norm 7.0118(12.2163) | Total Time 0.00(0.00)\n",
      "Iter 1520 | Time 14.8778(15.3522) | Bit/dim 4.0093(4.0079) | Xent 1.1978(1.2719) | Loss 10.1333(10.4928) | Error 0.4211(0.4580) Steps 574(584.69) | Grad Norm 7.2177(12.1763) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 15.3003(15.3107) | Bit/dim 3.9671(4.0007) | Xent 1.2487(1.2681) | Loss 10.1763(10.4005) | Error 0.4733(0.4568) Steps 610(586.62) | Grad Norm 8.8879(13.1361) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 14.0489(15.2141) | Bit/dim 3.9967(3.9991) | Xent 1.2573(1.2696) | Loss 10.1752(10.3531) | Error 0.4567(0.4576) Steps 568(588.19) | Grad Norm 14.3069(13.8074) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 84.0360, Epoch Time 941.8694(840.2682), Bit/dim 3.9801(best: 4.0060), Xent 1.1748, Loss 4.5675, Error 0.4251(best: 0.4369)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n",
      "14.161676646706587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1550 | Time 16.6423(15.2759) | Bit/dim 3.9884(3.9944) | Xent 1.1352(1.2535) | Loss 10.1241(10.7484) | Error 0.4333(0.4522) Steps 592(589.09) | Grad Norm 5.5848(12.3001) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 15.2533(15.3012) | Bit/dim 3.9702(3.9904) | Xent 1.2582(1.2474) | Loss 10.0621(10.5793) | Error 0.4456(0.4499) Steps 616(588.83) | Grad Norm 13.7755(12.0638) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 15.1159(15.3370) | Bit/dim 4.0015(3.9875) | Xent 1.2328(1.2530) | Loss 10.2390(10.4760) | Error 0.4422(0.4515) Steps 580(588.21) | Grad Norm 15.2216(13.8083) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 14.5955(15.3071) | Bit/dim 3.9812(3.9846) | Xent 1.1690(1.2438) | Loss 10.0417(10.3762) | Error 0.4300(0.4489) Steps 592(585.87) | Grad Norm 13.6212(13.2510) | Total Time 0.00(0.00)\n",
      "Iter 1590 | Time 15.1844(15.3165) | Bit/dim 3.9678(3.9807) | Xent 1.2598(1.2463) | Loss 10.1176(10.3061) | Error 0.4567(0.4494) Steps 580(586.25) | Grad Norm 7.7426(13.5294) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 84.5470, Epoch Time 948.8550(843.5258), Bit/dim 3.9794(best: 3.9801), Xent 1.1873, Loss 4.5731, Error 0.4298(best: 0.4251)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n",
      "14.131736526946108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1600 | Time 16.6633(15.3039) | Bit/dim 3.9484(3.9750) | Xent 1.1791(1.2393) | Loss 9.9843(10.7796) | Error 0.4022(0.4464) Steps 586(585.78) | Grad Norm 7.6933(12.8341) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 15.4313(15.2810) | Bit/dim 3.9998(3.9719) | Xent 1.1913(1.2336) | Loss 9.8651(10.5938) | Error 0.4278(0.4431) Steps 604(584.70) | Grad Norm 7.1603(12.6668) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 15.4959(15.3050) | Bit/dim 3.9419(3.9685) | Xent 1.1675(1.2224) | Loss 9.9457(10.4436) | Error 0.4133(0.4396) Steps 610(585.92) | Grad Norm 7.5562(11.9288) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 15.7686(15.2547) | Bit/dim 3.9379(3.9635) | Xent 1.2027(1.2220) | Loss 9.8959(10.3358) | Error 0.4289(0.4408) Steps 568(585.96) | Grad Norm 10.1167(11.5080) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 14.5177(15.2378) | Bit/dim 3.9521(3.9584) | Xent 1.1154(1.2136) | Loss 9.9216(10.2535) | Error 0.4178(0.4373) Steps 574(586.49) | Grad Norm 11.9356(11.1072) | Total Time 0.00(0.00)\n",
      "Iter 1650 | Time 15.3460(15.3238) | Bit/dim 3.9580(3.9571) | Xent 1.1880(1.2117) | Loss 10.0575(10.2044) | Error 0.4233(0.4360) Steps 592(589.96) | Grad Norm 11.5770(11.8073) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 85.0364, Epoch Time 946.8763(846.6263), Bit/dim 3.9511(best: 3.9794), Xent 1.1255, Loss 4.5139, Error 0.4097(best: 0.4251)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n",
      "14.101796407185628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1660 | Time 15.7458(15.4484) | Bit/dim 3.9264(3.9557) | Xent 1.1835(1.2093) | Loss 9.9576(10.6525) | Error 0.4133(0.4343) Steps 616(593.22) | Grad Norm 9.8565(13.3723) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 14.4169(15.5327) | Bit/dim 3.9341(3.9549) | Xent 1.2318(1.2087) | Loss 10.0246(10.5116) | Error 0.4356(0.4329) Steps 580(594.08) | Grad Norm 22.7675(13.0834) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 15.0657(15.4441) | Bit/dim 3.9223(3.9515) | Xent 1.2021(1.2006) | Loss 9.9985(10.3776) | Error 0.4211(0.4291) Steps 568(590.13) | Grad Norm 9.0501(12.7125) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 14.6021(15.3518) | Bit/dim 3.9786(3.9490) | Xent 1.1538(1.1953) | Loss 9.9883(10.2681) | Error 0.4111(0.4269) Steps 568(585.98) | Grad Norm 8.2817(12.6798) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 16.4972(15.2880) | Bit/dim 3.9206(3.9460) | Xent 1.1776(1.1913) | Loss 9.9968(10.1972) | Error 0.4311(0.4265) Steps 592(585.26) | Grad Norm 10.2939(11.9039) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 84.8373, Epoch Time 953.8672(849.8436), Bit/dim 3.9386(best: 3.9511), Xent 1.1185, Loss 4.4978, Error 0.4073(best: 0.4097)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n",
      "14.07185628742515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1710 | Time 15.4731(15.3586) | Bit/dim 3.9357(3.9436) | Xent 1.2239(1.1854) | Loss 9.9919(10.7021) | Error 0.4333(0.4251) Steps 580(586.13) | Grad Norm 18.0743(12.7404) | Total Time 0.00(0.00)\n",
      "Iter 1720 | Time 14.8426(15.3650) | Bit/dim 3.9136(3.9422) | Xent 1.1917(1.1816) | Loss 10.0151(10.5151) | Error 0.4356(0.4233) Steps 568(584.21) | Grad Norm 13.4080(13.2994) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 15.0937(15.3127) | Bit/dim 3.9365(3.9398) | Xent 1.1101(1.1721) | Loss 10.0632(10.3733) | Error 0.3989(0.4199) Steps 604(582.48) | Grad Norm 11.7159(13.3048) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 15.2854(15.2949) | Bit/dim 3.9109(3.9364) | Xent 1.1619(1.1657) | Loss 9.9571(10.2436) | Error 0.4189(0.4178) Steps 616(581.53) | Grad Norm 11.1580(12.3372) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 15.8263(15.3477) | Bit/dim 3.9477(3.9342) | Xent 1.2005(1.1664) | Loss 10.1403(10.1810) | Error 0.4300(0.4179) Steps 616(584.98) | Grad Norm 15.0274(13.1829) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 14.8483(15.3324) | Bit/dim 3.9060(3.9305) | Xent 1.1156(1.1750) | Loss 9.9539(10.1308) | Error 0.4233(0.4204) Steps 586(586.12) | Grad Norm 9.7399(13.0490) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 83.4567, Epoch Time 946.7131(852.7496), Bit/dim 3.9140(best: 3.9386), Xent 1.1333, Loss 4.4806, Error 0.4024(best: 0.4073)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n",
      "14.04191616766467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1770 | Time 15.9920(15.3042) | Bit/dim 3.8878(3.9276) | Xent 1.1790(1.1678) | Loss 9.9516(10.5535) | Error 0.4122(0.4188) Steps 634(586.68) | Grad Norm 16.2461(13.1343) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 14.6599(15.3641) | Bit/dim 3.9233(3.9267) | Xent 1.1408(1.1578) | Loss 9.9055(10.3914) | Error 0.3978(0.4156) Steps 562(586.95) | Grad Norm 9.6228(12.8471) | Total Time 0.00(0.00)\n",
      "Iter 1790 | Time 14.7035(15.2899) | Bit/dim 3.9011(3.9229) | Xent 1.1222(1.1439) | Loss 9.7959(10.2490) | Error 0.4089(0.4094) Steps 568(584.87) | Grad Norm 9.0260(11.5798) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 15.4341(15.2466) | Bit/dim 3.8920(3.9181) | Xent 1.1384(1.1345) | Loss 9.7577(10.1411) | Error 0.3967(0.4063) Steps 604(583.19) | Grad Norm 7.6509(11.3750) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 15.3753(15.2405) | Bit/dim 3.9006(3.9192) | Xent 1.1912(1.1522) | Loss 9.6675(10.0859) | Error 0.4178(0.4101) Steps 598(583.81) | Grad Norm 10.7917(13.1377) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 82.8064, Epoch Time 942.6586(855.4469), Bit/dim 3.9015(best: 3.9140), Xent 1.0828, Loss 4.4429, Error 0.3864(best: 0.4024)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n",
      "14.011976047904191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1820 | Time 14.2507(15.2398) | Bit/dim 3.8875(3.9159) | Xent 1.1367(1.1483) | Loss 9.8622(10.5713) | Error 0.4089(0.4092) Steps 562(582.02) | Grad Norm 15.0051(13.1906) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 14.7820(15.2380) | Bit/dim 3.9122(3.9126) | Xent 1.1824(1.1343) | Loss 9.8780(10.3708) | Error 0.4300(0.4058) Steps 592(581.45) | Grad Norm 12.1779(12.2833) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 16.4352(15.2911) | Bit/dim 3.9076(3.9111) | Xent 1.0495(1.1220) | Loss 9.8795(10.2391) | Error 0.3578(0.4017) Steps 544(579.22) | Grad Norm 6.3847(11.8197) | Total Time 0.00(0.00)\n",
      "Iter 1850 | Time 14.8567(15.2600) | Bit/dim 3.8718(3.9064) | Xent 1.1851(1.1224) | Loss 9.9470(10.1371) | Error 0.4278(0.4014) Steps 580(577.98) | Grad Norm 10.1974(11.6442) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 15.0471(15.2760) | Bit/dim 3.9299(3.9046) | Xent 1.1960(1.1244) | Loss 9.9626(10.0626) | Error 0.4333(0.4028) Steps 556(578.10) | Grad Norm 19.4922(11.9289) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 14.4625(15.2542) | Bit/dim 3.8515(3.8982) | Xent 1.0749(1.1193) | Loss 9.7690(9.9995) | Error 0.3944(0.4005) Steps 568(577.94) | Grad Norm 7.0950(12.0763) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 81.8045, Epoch Time 940.7879(858.0071), Bit/dim 3.8896(best: 3.9015), Xent 1.0543, Loss 4.4168, Error 0.3781(best: 0.3864)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n",
      "13.982035928143713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1880 | Time 14.5513(15.2104) | Bit/dim 3.8593(3.8972) | Xent 1.1020(1.1203) | Loss 9.7071(10.4067) | Error 0.3833(0.4004) Steps 562(577.45) | Grad Norm 11.4200(12.3432) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 15.2804(15.2793) | Bit/dim 3.9083(3.8991) | Xent 1.1022(1.1118) | Loss 9.8469(10.2507) | Error 0.3811(0.3981) Steps 544(580.23) | Grad Norm 9.8064(12.1485) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 14.6216(15.2240) | Bit/dim 3.9072(3.8971) | Xent 1.0895(1.1025) | Loss 9.7949(10.1174) | Error 0.3811(0.3952) Steps 568(579.82) | Grad Norm 19.0400(11.9955) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 15.5224(15.2948) | Bit/dim 3.8836(3.8932) | Xent 1.1333(1.1016) | Loss 9.9732(10.0420) | Error 0.3956(0.3936) Steps 598(581.05) | Grad Norm 7.5760(11.9369) | Total Time 0.00(0.00)\n",
      "Iter 1920 | Time 14.6352(15.2912) | Bit/dim 3.8991(3.8896) | Xent 1.0272(1.0954) | Loss 9.7798(9.9562) | Error 0.3656(0.3909) Steps 568(581.26) | Grad Norm 11.1655(11.2231) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 82.5163, Epoch Time 943.7322(860.5789), Bit/dim 3.8836(best: 3.8896), Xent 1.0345, Loss 4.4008, Error 0.3664(best: 0.3781)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n",
      "13.952095808383234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1930 | Time 15.0062(15.3091) | Bit/dim 3.8863(3.8869) | Xent 1.0338(1.0889) | Loss 9.7479(10.4594) | Error 0.3856(0.3870) Steps 580(581.25) | Grad Norm 7.5467(11.1429) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 15.4575(15.3321) | Bit/dim 3.8802(3.8820) | Xent 0.9794(1.0849) | Loss 9.7455(10.2768) | Error 0.3622(0.3858) Steps 598(582.51) | Grad Norm 8.2986(10.7427) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 16.0524(15.3243) | Bit/dim 3.8529(3.8801) | Xent 1.1243(1.0823) | Loss 9.7248(10.1357) | Error 0.3933(0.3860) Steps 598(582.58) | Grad Norm 9.8880(10.5110) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 15.7872(15.3472) | Bit/dim 3.8507(3.8758) | Xent 1.0662(1.0780) | Loss 9.8107(10.0255) | Error 0.3856(0.3847) Steps 598(582.47) | Grad Norm 9.8431(10.1963) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 16.3334(15.4690) | Bit/dim 3.8642(3.8751) | Xent 1.0738(1.0834) | Loss 9.7951(9.9757) | Error 0.3889(0.3857) Steps 598(583.61) | Grad Norm 19.2992(11.4393) | Total Time 0.00(0.00)\n",
      "Iter 1980 | Time 15.2533(15.5165) | Bit/dim 3.8601(3.8756) | Xent 1.2264(1.0938) | Loss 9.8512(9.9273) | Error 0.4422(0.3900) Steps 592(582.33) | Grad Norm 19.5732(12.5258) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 81.9780, Epoch Time 954.9561(863.4102), Bit/dim 3.8645(best: 3.8836), Xent 1.0324, Loss 4.3807, Error 0.3651(best: 0.3664)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n",
      "13.922155688622754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 1990 | Time 15.0260(15.4998) | Bit/dim 3.8646(3.8738) | Xent 1.0758(1.0900) | Loss 9.6448(10.3303) | Error 0.3789(0.3890) Steps 586(582.46) | Grad Norm 17.3133(12.0971) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 15.0978(15.5158) | Bit/dim 3.8796(3.8724) | Xent 1.0583(1.0827) | Loss 9.7009(10.1691) | Error 0.3844(0.3874) Steps 580(582.33) | Grad Norm 9.5285(12.0071) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 14.7709(15.4122) | Bit/dim 3.8554(3.8701) | Xent 1.0337(1.0722) | Loss 9.6438(10.0410) | Error 0.3622(0.3818) Steps 586(581.21) | Grad Norm 11.1526(11.6765) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 14.8510(15.3870) | Bit/dim 3.8701(3.8671) | Xent 1.0145(1.0674) | Loss 9.6712(9.9532) | Error 0.3578(0.3787) Steps 568(582.66) | Grad Norm 10.0061(11.8117) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 15.7694(15.3762) | Bit/dim 3.8425(3.8646) | Xent 1.1574(1.0634) | Loss 9.8152(9.8827) | Error 0.4089(0.3784) Steps 586(583.29) | Grad Norm 11.0426(10.6177) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 81.7898, Epoch Time 949.3444(865.9882), Bit/dim 3.8542(best: 3.8645), Xent 1.0108, Loss 4.3596, Error 0.3642(best: 0.3651)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n",
      "13.892215568862277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2040 | Time 14.9402(15.4473) | Bit/dim 3.8844(3.8608) | Xent 1.0501(1.0597) | Loss 9.8117(10.3859) | Error 0.3878(0.3780) Steps 568(581.50) | Grad Norm 14.2017(10.5875) | Total Time 0.00(0.00)\n",
      "Iter 2050 | Time 14.8651(15.4061) | Bit/dim 3.8585(3.8595) | Xent 1.1447(1.0538) | Loss 9.8223(10.2081) | Error 0.3967(0.3762) Steps 598(582.34) | Grad Norm 10.2276(10.8415) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 15.3272(15.4280) | Bit/dim 3.8094(3.8569) | Xent 1.0278(1.0570) | Loss 9.4836(10.0643) | Error 0.3644(0.3786) Steps 574(582.33) | Grad Norm 14.7318(11.6273) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 15.9075(15.4249) | Bit/dim 3.8749(3.8641) | Xent 1.1080(1.0893) | Loss 9.7691(10.0177) | Error 0.3867(0.3880) Steps 556(580.48) | Grad Norm 10.2591(13.7951) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 14.5991(15.3705) | Bit/dim 3.8739(3.8646) | Xent 1.0629(1.0914) | Loss 9.7283(9.9542) | Error 0.3756(0.3886) Steps 580(580.28) | Grad Norm 13.5825(13.3848) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 15.5555(15.3469) | Bit/dim 3.7902(3.8592) | Xent 1.0188(1.0792) | Loss 9.4360(9.8679) | Error 0.3533(0.3855) Steps 574(581.94) | Grad Norm 8.7693(12.3346) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 82.2854, Epoch Time 946.6896(868.4093), Bit/dim 3.8461(best: 3.8542), Xent 0.9940, Loss 4.3431, Error 0.3573(best: 0.3642)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n",
      "13.862275449101796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2100 | Time 14.6638(15.3463) | Bit/dim 3.8359(3.8566) | Xent 1.0310(1.0707) | Loss 9.6327(10.2582) | Error 0.3522(0.3816) Steps 586(583.78) | Grad Norm 13.1451(11.7065) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 15.4586(15.4085) | Bit/dim 3.8312(3.8547) | Xent 1.0642(1.0584) | Loss 9.6381(10.0943) | Error 0.3767(0.3775) Steps 592(585.36) | Grad Norm 12.8085(11.6887) | Total Time 0.00(0.00)\n",
      "Iter 2120 | Time 15.9645(15.4074) | Bit/dim 3.8500(3.8509) | Xent 1.0075(1.0541) | Loss 9.5671(9.9740) | Error 0.3711(0.3767) Steps 586(583.26) | Grad Norm 8.9729(11.7356) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 15.5014(15.3812) | Bit/dim 3.8301(3.8501) | Xent 1.0198(1.0533) | Loss 9.5518(9.8956) | Error 0.3744(0.3753) Steps 604(583.10) | Grad Norm 11.4361(12.2671) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 15.6522(15.3814) | Bit/dim 3.7966(3.8443) | Xent 1.0202(1.0457) | Loss 9.5649(9.8188) | Error 0.3778(0.3739) Steps 586(579.64) | Grad Norm 11.1856(12.1507) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 87.4639, Epoch Time 952.3550(870.9277), Bit/dim 3.8337(best: 3.8461), Xent 1.0337, Loss 4.3505, Error 0.3702(best: 0.3573)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n",
      "13.832335329341316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2150 | Time 15.2370(15.3624) | Bit/dim 3.8250(3.8421) | Xent 1.0099(1.0397) | Loss 9.6349(10.3227) | Error 0.3689(0.3717) Steps 586(580.41) | Grad Norm 7.8000(11.7057) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 14.9830(15.2678) | Bit/dim 3.8364(3.8409) | Xent 1.0725(1.0413) | Loss 9.6684(10.1494) | Error 0.3911(0.3735) Steps 550(580.00) | Grad Norm 18.5181(12.2021) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 14.5673(15.3381) | Bit/dim 3.8377(3.8437) | Xent 1.1206(1.0426) | Loss 9.6971(10.0262) | Error 0.3967(0.3727) Steps 568(581.02) | Grad Norm 9.6827(12.5437) | Total Time 0.00(0.00)\n",
      "Iter 2180 | Time 15.2443(15.3723) | Bit/dim 3.8313(3.8416) | Xent 1.0188(1.0424) | Loss 9.6292(9.9254) | Error 0.3533(0.3725) Steps 574(581.28) | Grad Norm 9.9380(12.3182) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 15.2809(15.3428) | Bit/dim 3.8177(3.8374) | Xent 1.0209(1.0352) | Loss 9.6126(9.8259) | Error 0.3489(0.3699) Steps 568(580.19) | Grad Norm 12.8760(11.8267) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 15.7885(15.4358) | Bit/dim 3.7988(3.8321) | Xent 1.0348(1.0344) | Loss 9.6414(9.7793) | Error 0.3811(0.3708) Steps 586(581.73) | Grad Norm 10.3788(11.6867) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 83.9009, Epoch Time 951.7660(873.3528), Bit/dim 3.8355(best: 3.8337), Xent 0.9822, Loss 4.3266, Error 0.3462(best: 0.3573)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n",
      "13.802395209580839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2210 | Time 15.5638(15.4228) | Bit/dim 3.8221(3.8287) | Xent 1.0562(1.0251) | Loss 9.6746(10.1703) | Error 0.3611(0.3665) Steps 568(580.23) | Grad Norm 6.3069(11.1505) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 15.8894(15.4571) | Bit/dim 3.8398(3.8292) | Xent 0.9629(1.0136) | Loss 9.6970(10.0247) | Error 0.3433(0.3624) Steps 610(582.60) | Grad Norm 5.9657(10.0898) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 15.4780(15.4606) | Bit/dim 3.7873(3.8270) | Xent 0.9555(1.0166) | Loss 9.5497(9.9129) | Error 0.3389(0.3622) Steps 592(582.65) | Grad Norm 9.3642(10.5300) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 15.0890(15.4799) | Bit/dim 3.7817(3.8249) | Xent 0.9121(1.0085) | Loss 9.4070(9.8130) | Error 0.3289(0.3598) Steps 568(582.15) | Grad Norm 8.0263(9.7867) | Total Time 0.00(0.00)\n",
      "Iter 2250 | Time 15.3512(15.4769) | Bit/dim 3.8250(3.8226) | Xent 0.9917(1.0109) | Loss 9.6786(9.7509) | Error 0.3578(0.3606) Steps 598(584.65) | Grad Norm 15.6562(10.5795) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 83.8573, Epoch Time 955.5947(875.8201), Bit/dim 3.8191(best: 3.8337), Xent 0.9746, Loss 4.3064, Error 0.3435(best: 0.3462)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n",
      "13.77245508982036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2260 | Time 15.2775(15.4704) | Bit/dim 3.8181(3.8234) | Xent 0.9419(1.0117) | Loss 9.6085(10.2761) | Error 0.3156(0.3593) Steps 616(586.35) | Grad Norm 13.2152(11.7712) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 15.5954(15.4467) | Bit/dim 3.8556(3.8270) | Xent 1.0518(1.0197) | Loss 9.5985(10.1092) | Error 0.3911(0.3632) Steps 586(585.83) | Grad Norm 11.6129(11.8247) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 15.4895(15.4742) | Bit/dim 3.8057(3.8272) | Xent 0.9863(1.0163) | Loss 9.4570(9.9797) | Error 0.3478(0.3610) Steps 556(582.92) | Grad Norm 9.1957(11.5313) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 15.5992(15.4633) | Bit/dim 3.8419(3.8274) | Xent 0.9047(1.0168) | Loss 9.5829(9.8894) | Error 0.3300(0.3621) Steps 586(583.51) | Grad Norm 10.9024(12.4955) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 15.6508(15.4390) | Bit/dim 3.8007(3.8244) | Xent 0.9731(1.0130) | Loss 9.5029(9.8043) | Error 0.3433(0.3603) Steps 574(583.93) | Grad Norm 7.8709(11.7322) | Total Time 0.00(0.00)\n",
      "Iter 2310 | Time 15.2676(15.4582) | Bit/dim 3.8483(3.8241) | Xent 0.9506(1.0126) | Loss 9.5113(9.7447) | Error 0.3422(0.3604) Steps 592(583.81) | Grad Norm 14.0600(11.7493) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 82.8651, Epoch Time 953.0179(878.1360), Bit/dim 3.8144(best: 3.8191), Xent 0.9453, Loss 4.2870, Error 0.3362(best: 0.3435)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n",
      "13.74251497005988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2320 | Time 15.9020(15.5308) | Bit/dim 3.8061(3.8195) | Xent 0.9035(1.0010) | Loss 9.4949(10.1482) | Error 0.3233(0.3567) Steps 598(587.13) | Grad Norm 8.3204(11.9180) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 16.3090(15.5424) | Bit/dim 3.8185(3.8185) | Xent 1.0015(1.0028) | Loss 9.6620(10.0055) | Error 0.3600(0.3580) Steps 640(588.72) | Grad Norm 6.7296(11.9569) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 15.8459(15.5304) | Bit/dim 3.7903(3.8167) | Xent 1.0141(1.0045) | Loss 9.5319(9.8828) | Error 0.3678(0.3581) Steps 562(586.10) | Grad Norm 9.8860(11.0739) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 15.0783(15.4941) | Bit/dim 3.8357(3.8169) | Xent 0.9683(0.9942) | Loss 9.4490(9.7917) | Error 0.3467(0.3551) Steps 550(586.67) | Grad Norm 15.0783(10.8709) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 16.5906(15.5394) | Bit/dim 3.8311(3.8147) | Xent 1.0884(0.9955) | Loss 9.8092(9.7425) | Error 0.3944(0.3554) Steps 586(587.31) | Grad Norm 19.1552(11.4352) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 83.0962, Epoch Time 958.6110(880.5502), Bit/dim 3.8164(best: 3.8144), Xent 0.9912, Loss 4.3120, Error 0.3508(best: 0.3362)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n",
      "13.7125748502994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2370 | Time 15.4764(15.5281) | Bit/dim 3.7942(3.8112) | Xent 1.0067(0.9962) | Loss 9.6063(10.2457) | Error 0.3789(0.3552) Steps 592(585.34) | Grad Norm 12.0747(11.9185) | Total Time 0.00(0.00)\n",
      "Iter 2380 | Time 15.7623(15.5567) | Bit/dim 3.8446(3.8118) | Xent 0.9937(0.9845) | Loss 9.5050(10.0592) | Error 0.3744(0.3518) Steps 568(588.20) | Grad Norm 13.9805(11.4502) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 14.5966(15.4390) | Bit/dim 3.8033(3.8069) | Xent 1.0379(0.9866) | Loss 9.5562(9.9156) | Error 0.3722(0.3530) Steps 604(588.50) | Grad Norm 14.0979(11.4740) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 15.8354(15.4209) | Bit/dim 3.8179(3.8062) | Xent 0.8737(0.9783) | Loss 9.2879(9.8040) | Error 0.3411(0.3503) Steps 580(586.04) | Grad Norm 9.0970(10.5843) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 15.9999(15.4776) | Bit/dim 3.8173(3.8032) | Xent 0.9879(0.9745) | Loss 9.6545(9.7369) | Error 0.3567(0.3486) Steps 592(587.38) | Grad Norm 7.2885(9.9770) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 15.4692(15.5059) | Bit/dim 3.7931(3.8064) | Xent 0.9997(0.9821) | Loss 9.5138(9.6918) | Error 0.3567(0.3494) Steps 604(586.38) | Grad Norm 14.3273(11.3984) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 81.5723, Epoch Time 953.9106(882.7511), Bit/dim 3.8028(best: 3.8144), Xent 0.9981, Loss 4.3018, Error 0.3577(best: 0.3362)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n",
      "13.682634730538922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2430 | Time 16.0276(15.5628) | Bit/dim 3.8129(3.8078) | Xent 0.9317(0.9780) | Loss 9.6092(10.1261) | Error 0.3278(0.3483) Steps 622(588.25) | Grad Norm 9.5898(11.0800) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 15.5397(15.5738) | Bit/dim 3.7860(3.8021) | Xent 0.9777(0.9725) | Loss 9.5311(9.9699) | Error 0.3444(0.3458) Steps 604(588.66) | Grad Norm 13.7083(11.0008) | Total Time 0.00(0.00)\n",
      "Iter 2450 | Time 15.1906(15.5409) | Bit/dim 3.8152(3.8021) | Xent 1.1091(0.9792) | Loss 9.7045(9.8568) | Error 0.3956(0.3484) Steps 598(590.18) | Grad Norm 12.0327(11.4829) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 15.4392(15.5681) | Bit/dim 3.8142(3.8008) | Xent 0.9990(0.9814) | Loss 9.5863(9.7726) | Error 0.3611(0.3501) Steps 598(590.05) | Grad Norm 7.7813(11.1427) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 15.7134(15.5746) | Bit/dim 3.8189(3.7996) | Xent 0.9625(0.9789) | Loss 9.5535(9.7213) | Error 0.3422(0.3483) Steps 598(590.30) | Grad Norm 9.9833(11.1956) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 82.6766, Epoch Time 959.2340(885.0455), Bit/dim 3.7891(best: 3.8028), Xent 0.9153, Loss 4.2467, Error 0.3222(best: 0.3362)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n",
      "13.652694610778443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2480 | Time 15.3453(15.5029) | Bit/dim 3.7929(3.7971) | Xent 0.9026(0.9675) | Loss 9.4698(10.2145) | Error 0.3256(0.3430) Steps 610(589.04) | Grad Norm 6.7321(10.6971) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 15.1547(15.4707) | Bit/dim 3.8259(3.7971) | Xent 0.9946(0.9618) | Loss 9.5738(10.0161) | Error 0.3489(0.3422) Steps 604(590.44) | Grad Norm 14.1692(10.8450) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 16.5481(15.4888) | Bit/dim 3.7892(3.7971) | Xent 0.9514(0.9560) | Loss 9.5287(9.8756) | Error 0.3433(0.3395) Steps 580(587.09) | Grad Norm 10.2503(10.4485) | Total Time 0.00(0.00)\n",
      "Iter 2510 | Time 16.0765(15.5560) | Bit/dim 3.7957(3.7954) | Xent 0.9755(0.9597) | Loss 9.6192(9.7811) | Error 0.3444(0.3402) Steps 604(586.72) | Grad Norm 16.1134(11.6781) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 15.2466(15.5445) | Bit/dim 3.7814(3.7961) | Xent 0.9669(0.9617) | Loss 9.5651(9.7182) | Error 0.3389(0.3416) Steps 610(586.73) | Grad Norm 11.6210(11.2292) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 14.8703(15.5144) | Bit/dim 3.7689(3.7949) | Xent 0.9904(0.9622) | Loss 9.4937(9.6612) | Error 0.3511(0.3424) Steps 574(586.26) | Grad Norm 7.6311(11.2718) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 81.3669, Epoch Time 954.9895(887.1439), Bit/dim 3.7974(best: 3.7891), Xent 0.9468, Loss 4.2708, Error 0.3348(best: 0.3222)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n",
      "13.622754491017965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2540 | Time 15.3552(15.5125) | Bit/dim 3.7758(3.7918) | Xent 0.9463(0.9562) | Loss 9.3888(10.0545) | Error 0.3478(0.3408) Steps 574(586.03) | Grad Norm 8.4822(10.4692) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 16.1575(15.4904) | Bit/dim 3.7938(3.7903) | Xent 1.0001(0.9543) | Loss 9.6726(9.9109) | Error 0.3456(0.3394) Steps 592(587.46) | Grad Norm 10.7153(10.0072) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 15.0377(15.4727) | Bit/dim 3.7752(3.7915) | Xent 0.9611(0.9492) | Loss 9.4203(9.7987) | Error 0.3411(0.3368) Steps 598(586.52) | Grad Norm 12.7495(10.4613) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 14.4496(15.4496) | Bit/dim 3.7674(3.7887) | Xent 0.9604(0.9458) | Loss 9.4567(9.7030) | Error 0.3511(0.3366) Steps 592(585.39) | Grad Norm 10.0863(10.2107) | Total Time 0.00(0.00)\n",
      "Iter 2580 | Time 15.9073(15.4991) | Bit/dim 3.7725(3.7874) | Xent 0.9749(0.9442) | Loss 9.6088(9.6449) | Error 0.3267(0.3346) Steps 574(585.52) | Grad Norm 9.7189(9.9478) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 85.2740, Epoch Time 959.3139(889.3090), Bit/dim 3.7844(best: 3.7891), Xent 0.9490, Loss 4.2589, Error 0.3402(best: 0.3222)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n",
      "13.592814371257484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2590 | Time 15.5038(15.5309) | Bit/dim 3.7698(3.7862) | Xent 0.9425(0.9494) | Loss 9.4330(10.1492) | Error 0.3500(0.3374) Steps 604(586.10) | Grad Norm 10.1095(9.9158) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 15.2305(15.5437) | Bit/dim 3.8295(3.7841) | Xent 0.9127(0.9489) | Loss 9.5502(9.9793) | Error 0.3144(0.3394) Steps 610(589.64) | Grad Norm 6.4608(10.0580) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 16.0433(15.5575) | Bit/dim 3.7941(3.7866) | Xent 0.9090(0.9486) | Loss 9.4995(9.8634) | Error 0.3311(0.3399) Steps 568(589.59) | Grad Norm 18.9602(10.0812) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 15.6832(15.5335) | Bit/dim 3.7883(3.7844) | Xent 0.8907(0.9407) | Loss 9.6228(9.7519) | Error 0.3267(0.3357) Steps 616(590.40) | Grad Norm 5.7520(10.2431) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 15.3396(15.5531) | Bit/dim 3.7888(3.7838) | Xent 0.9045(0.9383) | Loss 9.4258(9.6866) | Error 0.3300(0.3350) Steps 604(590.10) | Grad Norm 9.0377(9.8481) | Total Time 0.00(0.00)\n",
      "Iter 2640 | Time 15.7308(15.5203) | Bit/dim 3.7730(3.7787) | Xent 0.9073(0.9308) | Loss 9.3730(9.6185) | Error 0.3356(0.3334) Steps 586(590.47) | Grad Norm 4.8838(9.5685) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 83.8751, Epoch Time 960.6977(891.4506), Bit/dim 3.7785(best: 3.7844), Xent 0.9009, Loss 4.2289, Error 0.3174(best: 0.3222)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n",
      "13.562874251497007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2650 | Time 14.6843(15.5652) | Bit/dim 3.7911(3.7762) | Xent 0.8797(0.9227) | Loss 9.4293(10.0327) | Error 0.3122(0.3309) Steps 598(592.72) | Grad Norm 6.6375(9.1942) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 15.4353(15.5969) | Bit/dim 3.7842(3.7757) | Xent 0.8934(0.9186) | Loss 9.3794(9.8708) | Error 0.3178(0.3287) Steps 580(589.46) | Grad Norm 7.6887(9.1907) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 15.5154(15.5691) | Bit/dim 3.7506(3.7746) | Xent 0.8873(0.9202) | Loss 9.4255(9.7693) | Error 0.3089(0.3298) Steps 604(588.37) | Grad Norm 12.5614(9.5555) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 15.9628(15.5738) | Bit/dim 3.7803(3.7754) | Xent 0.8823(0.9156) | Loss 9.3434(9.6781) | Error 0.3156(0.3267) Steps 550(588.85) | Grad Norm 7.4254(9.8311) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 14.9029(15.5428) | Bit/dim 3.7636(3.7740) | Xent 0.9203(0.9123) | Loss 9.4728(9.6049) | Error 0.3222(0.3273) Steps 598(589.35) | Grad Norm 14.4533(9.6499) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 84.4040, Epoch Time 961.7366(893.5592), Bit/dim 3.7815(best: 3.7785), Xent 0.9592, Loss 4.2610, Error 0.3435(best: 0.3174)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n",
      "13.532934131736527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2700 | Time 15.4684(15.5157) | Bit/dim 3.7552(3.7711) | Xent 0.8483(0.9137) | Loss 9.2322(10.0978) | Error 0.3044(0.3285) Steps 556(588.15) | Grad Norm 6.8523(9.8671) | Total Time 0.00(0.00)\n",
      "Iter 2710 | Time 15.3233(15.5806) | Bit/dim 3.7822(3.7709) | Xent 0.9540(0.9141) | Loss 9.4725(9.9195) | Error 0.3389(0.3279) Steps 574(590.19) | Grad Norm 14.1120(10.5122) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 15.9572(15.6399) | Bit/dim 3.7698(3.7729) | Xent 0.9142(0.9271) | Loss 9.5267(9.8094) | Error 0.3344(0.3314) Steps 586(589.73) | Grad Norm 11.6334(11.4256) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 15.2248(15.6530) | Bit/dim 3.7753(3.7741) | Xent 0.9506(0.9336) | Loss 9.5619(9.7288) | Error 0.3244(0.3332) Steps 574(588.96) | Grad Norm 13.3453(12.1100) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 16.8467(15.6918) | Bit/dim 3.7723(3.7761) | Xent 0.9150(0.9311) | Loss 9.4242(9.6618) | Error 0.3267(0.3309) Steps 580(591.53) | Grad Norm 6.7363(11.7674) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 15.0191(15.6012) | Bit/dim 3.7336(3.7755) | Xent 0.9370(0.9296) | Loss 9.3882(9.6120) | Error 0.3222(0.3297) Steps 574(590.45) | Grad Norm 6.6307(11.1189) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 85.2136, Epoch Time 967.7197(895.7840), Bit/dim 3.7706(best: 3.7785), Xent 0.9333, Loss 4.2373, Error 0.3309(best: 0.3174)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n",
      "13.502994011976048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2760 | Time 16.3428(15.6320) | Bit/dim 3.7622(3.7733) | Xent 0.9147(0.9244) | Loss 9.5669(10.0501) | Error 0.3267(0.3279) Steps 634(591.12) | Grad Norm 14.7396(11.1626) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 15.5618(15.7260) | Bit/dim 3.7857(3.7701) | Xent 0.8497(0.9160) | Loss 9.5295(9.8855) | Error 0.3000(0.3259) Steps 598(590.89) | Grad Norm 10.2289(10.6818) | Total Time 0.00(0.00)\n",
      "Iter 2780 | Time 15.6757(15.7174) | Bit/dim 3.7529(3.7680) | Xent 0.9451(0.9091) | Loss 9.3573(9.7643) | Error 0.3344(0.3235) Steps 604(591.73) | Grad Norm 17.5244(10.4484) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 15.8218(15.6838) | Bit/dim 3.7675(3.7685) | Xent 0.9478(0.9160) | Loss 9.5877(9.6946) | Error 0.3256(0.3259) Steps 580(590.37) | Grad Norm 14.7070(10.8912) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 15.8386(15.6018) | Bit/dim 3.7952(3.7667) | Xent 0.9739(0.9248) | Loss 9.4549(9.6221) | Error 0.3589(0.3298) Steps 598(587.08) | Grad Norm 12.1159(10.8062) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 85.5949, Epoch Time 969.2746(897.9887), Bit/dim 3.7702(best: 3.7706), Xent 0.8921, Loss 4.2163, Error 0.3158(best: 0.3174)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n",
      "13.47305389221557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2810 | Time 16.3140(15.6616) | Bit/dim 3.7594(3.7658) | Xent 0.8562(0.9178) | Loss 9.3688(10.1381) | Error 0.3167(0.3265) Steps 550(589.43) | Grad Norm 8.6101(10.3888) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 15.4081(15.6679) | Bit/dim 3.7881(3.7647) | Xent 0.8975(0.9089) | Loss 9.5385(9.9447) | Error 0.3322(0.3242) Steps 598(591.79) | Grad Norm 12.4561(10.1010) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 15.8630(15.6137) | Bit/dim 3.7396(3.7642) | Xent 0.9007(0.9035) | Loss 9.3239(9.8001) | Error 0.3000(0.3218) Steps 580(589.14) | Grad Norm 9.6064(10.2085) | Total Time 0.00(0.00)\n",
      "Iter 2840 | Time 15.5004(15.6209) | Bit/dim 3.7641(3.7608) | Xent 0.8546(0.8969) | Loss 9.4545(9.6911) | Error 0.3256(0.3197) Steps 592(587.55) | Grad Norm 8.8611(10.0456) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 15.8915(15.6474) | Bit/dim 3.7372(3.7588) | Xent 0.8448(0.8992) | Loss 9.4183(9.6400) | Error 0.3033(0.3195) Steps 556(587.43) | Grad Norm 12.9268(10.6446) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 14.8044(15.5537) | Bit/dim 3.7859(3.7638) | Xent 0.8970(0.9089) | Loss 9.4479(9.6050) | Error 0.3200(0.3223) Steps 592(590.59) | Grad Norm 6.4150(10.8605) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 84.9565, Epoch Time 969.3108(900.1284), Bit/dim 3.7578(best: 3.7702), Xent 0.8921, Loss 4.2039, Error 0.3172(best: 0.3158)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n",
      "13.44311377245509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2870 | Time 15.0784(15.4249) | Bit/dim 3.7421(3.7641) | Xent 0.9804(0.9087) | Loss 9.4873(10.0480) | Error 0.3422(0.3228) Steps 580(588.75) | Grad Norm 13.6068(10.9820) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 15.3571(15.3996) | Bit/dim 3.7624(3.7627) | Xent 0.9000(0.9029) | Loss 9.4267(9.8875) | Error 0.3367(0.3210) Steps 574(590.08) | Grad Norm 9.7515(10.4720) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 15.6257(15.4551) | Bit/dim 3.7621(3.7615) | Xent 0.9221(0.9002) | Loss 9.4744(9.7571) | Error 0.3233(0.3190) Steps 586(589.01) | Grad Norm 7.4530(10.0086) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 15.3630(15.4828) | Bit/dim 3.7526(3.7568) | Xent 0.8561(0.8904) | Loss 9.4788(9.6588) | Error 0.3167(0.3174) Steps 604(591.37) | Grad Norm 8.1289(9.5337) | Total Time 0.00(0.00)\n",
      "Iter 2910 | Time 15.2861(15.4803) | Bit/dim 3.7790(3.7548) | Xent 0.8600(0.8870) | Loss 9.4934(9.5891) | Error 0.3100(0.3155) Steps 616(591.33) | Grad Norm 5.2185(9.2119) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 85.7908, Epoch Time 962.1080(901.9878), Bit/dim 3.7536(best: 3.7578), Xent 0.8858, Loss 4.1965, Error 0.3136(best: 0.3158)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n",
      "13.41317365269461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2920 | Time 16.0073(15.5614) | Bit/dim 3.7355(3.7533) | Xent 0.8350(0.8820) | Loss 9.3147(10.0994) | Error 0.2878(0.3137) Steps 610(590.78) | Grad Norm 6.5673(9.2656) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 15.7862(15.5863) | Bit/dim 3.7783(3.7592) | Xent 1.0144(0.8848) | Loss 9.7071(9.9387) | Error 0.3533(0.3149) Steps 604(592.78) | Grad Norm 14.9826(9.9675) | Total Time 0.00(0.00)\n",
      "Iter 2940 | Time 15.4087(15.5398) | Bit/dim 3.7587(3.7577) | Xent 0.9268(0.8923) | Loss 9.4705(9.8060) | Error 0.3233(0.3181) Steps 604(594.00) | Grad Norm 15.6931(10.7749) | Total Time 0.00(0.00)\n",
      "Iter 2950 | Time 15.5937(15.5430) | Bit/dim 3.7203(3.7557) | Xent 0.8928(0.8964) | Loss 9.2760(9.7050) | Error 0.3078(0.3185) Steps 580(595.06) | Grad Norm 7.4652(10.1631) | Total Time 0.00(0.00)\n",
      "Iter 2960 | Time 16.4981(15.5985) | Bit/dim 3.7622(3.7531) | Xent 0.8746(0.8926) | Loss 9.4568(9.6296) | Error 0.3133(0.3160) Steps 604(594.81) | Grad Norm 6.8570(10.0515) | Total Time 0.00(0.00)\n",
      "Iter 2970 | Time 16.1275(15.5810) | Bit/dim 3.7130(3.7501) | Xent 0.8643(0.8897) | Loss 9.2493(9.5620) | Error 0.2956(0.3159) Steps 604(596.24) | Grad Norm 8.3682(9.9721) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 86.4006, Epoch Time 966.7880(903.9318), Bit/dim 3.7552(best: 3.7536), Xent 0.8921, Loss 4.2013, Error 0.3192(best: 0.3136)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n",
      "13.383233532934133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 2980 | Time 15.7220(15.6188) | Bit/dim 3.7668(3.7489) | Xent 0.8100(0.8824) | Loss 9.3963(10.0136) | Error 0.3000(0.3143) Steps 628(597.01) | Grad Norm 7.6015(9.5031) | Total Time 0.00(0.00)\n",
      "Iter 2990 | Time 15.4068(15.6337) | Bit/dim 3.7638(3.7475) | Xent 0.8664(0.8749) | Loss 9.3423(9.8413) | Error 0.3089(0.3126) Steps 592(596.87) | Grad Norm 8.5280(9.4139) | Total Time 0.00(0.00)\n",
      "Iter 3000 | Time 16.2068(15.6749) | Bit/dim 3.7183(3.7462) | Xent 0.8771(0.8723) | Loss 9.4517(9.7278) | Error 0.3078(0.3110) Steps 616(598.75) | Grad Norm 6.7564(8.9373) | Total Time 0.00(0.00)\n",
      "Iter 3010 | Time 16.0168(15.6706) | Bit/dim 3.7281(3.7430) | Xent 0.8704(0.8687) | Loss 9.2687(9.6312) | Error 0.2844(0.3073) Steps 586(600.14) | Grad Norm 9.6282(8.6429) | Total Time 0.00(0.00)\n",
      "Iter 3020 | Time 16.1893(15.7364) | Bit/dim 3.7499(3.7421) | Xent 0.9182(0.8763) | Loss 9.4495(9.5672) | Error 0.3178(0.3112) Steps 598(598.88) | Grad Norm 8.6796(9.1058) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 87.5446, Epoch Time 979.0932(906.1866), Bit/dim 3.7463(best: 3.7536), Xent 0.8696, Loss 4.1811, Error 0.3094(best: 0.3136)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n",
      "13.353293413173652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3030 | Time 15.6092(15.6852) | Bit/dim 3.7548(3.7450) | Xent 0.8285(0.8725) | Loss 9.3248(10.0900) | Error 0.2956(0.3103) Steps 610(600.02) | Grad Norm 10.1698(8.6685) | Total Time 0.00(0.00)\n",
      "Iter 3040 | Time 15.7227(15.7027) | Bit/dim 3.7148(3.7437) | Xent 0.9060(0.8728) | Loss 9.4292(9.9137) | Error 0.3289(0.3112) Steps 598(600.69) | Grad Norm 11.9231(8.6544) | Total Time 0.00(0.00)\n",
      "Iter 3050 | Time 16.5048(15.7174) | Bit/dim 3.7504(3.7437) | Xent 0.8102(0.8677) | Loss 9.2613(9.7749) | Error 0.2744(0.3084) Steps 640(600.21) | Grad Norm 4.2945(8.8413) | Total Time 0.00(0.00)\n",
      "Iter 3060 | Time 15.7716(15.6584) | Bit/dim 3.7230(3.7443) | Xent 0.8218(0.8613) | Loss 9.2295(9.6712) | Error 0.2867(0.3065) Steps 592(599.10) | Grad Norm 10.1872(8.8201) | Total Time 0.00(0.00)\n",
      "Iter 3070 | Time 16.1167(15.6466) | Bit/dim 3.7601(3.7434) | Xent 0.8664(0.8592) | Loss 9.4763(9.5861) | Error 0.3200(0.3063) Steps 616(600.02) | Grad Norm 10.3980(9.0353) | Total Time 0.00(0.00)\n",
      "Iter 3080 | Time 15.8067(15.6798) | Bit/dim 3.7269(3.7413) | Xent 0.8385(0.8631) | Loss 9.3735(9.5301) | Error 0.2989(0.3076) Steps 610(600.74) | Grad Norm 11.0378(9.3400) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 86.7813, Epoch Time 976.2604(908.2888), Bit/dim 3.7392(best: 3.7463), Xent 0.8699, Loss 4.1742, Error 0.3070(best: 0.3094)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n",
      "13.323353293413174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3090 | Time 15.9360(15.6948) | Bit/dim 3.7566(3.7411) | Xent 0.8913(0.8558) | Loss 9.4751(9.9702) | Error 0.3300(0.3067) Steps 628(601.62) | Grad Norm 11.5462(9.3640) | Total Time 0.00(0.00)\n",
      "Iter 3100 | Time 15.3783(15.7428) | Bit/dim 3.7523(3.7424) | Xent 0.9166(0.8492) | Loss 9.4339(9.8104) | Error 0.3344(0.3049) Steps 634(603.84) | Grad Norm 16.9660(9.1081) | Total Time 0.00(0.00)\n",
      "Iter 3110 | Time 16.2178(15.7885) | Bit/dim 3.7410(3.7416) | Xent 0.8923(0.8491) | Loss 9.4136(9.6944) | Error 0.3167(0.3035) Steps 580(602.76) | Grad Norm 14.5522(9.6135) | Total Time 0.00(0.00)\n",
      "Iter 3120 | Time 15.9792(15.7637) | Bit/dim 3.7181(3.7406) | Xent 0.8669(0.8515) | Loss 9.3143(9.5993) | Error 0.3222(0.3036) Steps 604(603.88) | Grad Norm 5.8808(9.6518) | Total Time 0.00(0.00)\n",
      "Iter 3130 | Time 16.3188(15.8333) | Bit/dim 3.7200(3.7389) | Xent 0.8928(0.8569) | Loss 9.3834(9.5493) | Error 0.3189(0.3058) Steps 610(607.70) | Grad Norm 13.3570(10.2975) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 87.0651, Epoch Time 985.7761(910.6135), Bit/dim 3.7497(best: 3.7392), Xent 0.8674, Loss 4.1834, Error 0.3013(best: 0.3070)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n",
      "13.293413173652695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3140 | Time 15.9991(15.8736) | Bit/dim 3.7249(3.7396) | Xent 0.7817(0.8565) | Loss 9.2431(10.0836) | Error 0.2767(0.3048) Steps 634(608.25) | Grad Norm 10.8842(10.7565) | Total Time 0.00(0.00)\n",
      "Iter 3150 | Time 15.0769(15.8130) | Bit/dim 3.7455(3.7422) | Xent 0.8126(0.8546) | Loss 9.1958(9.8830) | Error 0.2811(0.3036) Steps 586(604.14) | Grad Norm 11.4665(10.3661) | Total Time 0.00(0.00)\n",
      "Iter 3160 | Time 16.6080(15.8579) | Bit/dim 3.7257(3.7377) | Xent 0.8011(0.8516) | Loss 9.3619(9.7442) | Error 0.3067(0.3042) Steps 604(603.49) | Grad Norm 10.0940(9.9055) | Total Time 0.00(0.00)\n",
      "Iter 3170 | Time 16.1721(15.8853) | Bit/dim 3.7135(3.7380) | Xent 0.8752(0.8503) | Loss 9.2981(9.6461) | Error 0.3189(0.3035) Steps 592(604.43) | Grad Norm 9.3546(9.4573) | Total Time 0.00(0.00)\n",
      "Iter 3180 | Time 16.6859(15.9052) | Bit/dim 3.7671(3.7403) | Xent 0.8124(0.8511) | Loss 9.4667(9.5826) | Error 0.2922(0.3038) Steps 616(607.17) | Grad Norm 9.7333(10.1050) | Total Time 0.00(0.00)\n",
      "Iter 3190 | Time 15.5721(15.9399) | Bit/dim 3.7417(3.7418) | Xent 0.8819(0.8490) | Loss 9.4018(9.5319) | Error 0.3067(0.3027) Steps 598(608.94) | Grad Norm 11.2165(10.1292) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 86.9184, Epoch Time 989.6791(912.9854), Bit/dim 3.7334(best: 3.7392), Xent 0.8335, Loss 4.1502, Error 0.2988(best: 0.3013)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n",
      "13.263473053892216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3200 | Time 15.6439(15.9343) | Bit/dim 3.7374(3.7397) | Xent 0.8255(0.8420) | Loss 9.3365(9.9898) | Error 0.2944(0.3012) Steps 616(609.10) | Grad Norm 9.2698(9.7462) | Total Time 0.00(0.00)\n",
      "Iter 3210 | Time 16.1668(15.9076) | Bit/dim 3.7103(3.7384) | Xent 0.7696(0.8421) | Loss 9.2900(9.8114) | Error 0.2756(0.3013) Steps 586(606.17) | Grad Norm 7.2436(9.5089) | Total Time 0.00(0.00)\n",
      "Iter 3220 | Time 15.6598(15.9693) | Bit/dim 3.7042(3.7352) | Xent 0.8334(0.8361) | Loss 9.2918(9.6749) | Error 0.3122(0.2994) Steps 604(608.46) | Grad Norm 7.5823(9.0444) | Total Time 0.00(0.00)\n",
      "Iter 3230 | Time 16.0231(15.9847) | Bit/dim 3.7085(3.7343) | Xent 0.8636(0.8332) | Loss 9.3998(9.5855) | Error 0.3089(0.2976) Steps 622(611.38) | Grad Norm 12.2418(9.0370) | Total Time 0.00(0.00)\n",
      "Iter 3240 | Time 15.4668(15.9573) | Bit/dim 3.7447(3.7319) | Xent 0.8530(0.8310) | Loss 9.4663(9.5177) | Error 0.2889(0.2966) Steps 628(611.23) | Grad Norm 10.9055(9.3738) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 88.6377, Epoch Time 987.0049(915.2060), Bit/dim 3.7304(best: 3.7334), Xent 0.8340, Loss 4.1474, Error 0.2978(best: 0.2988)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n",
      "13.233532934131736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3250 | Time 16.0633(15.9799) | Bit/dim 3.7511(3.7320) | Xent 0.7412(0.8286) | Loss 9.3278(10.0554) | Error 0.2556(0.2952) Steps 616(613.98) | Grad Norm 7.3465(9.2536) | Total Time 0.00(0.00)\n",
      "Iter 3260 | Time 15.1519(16.0260) | Bit/dim 3.7130(3.7318) | Xent 0.9235(0.8283) | Loss 9.3430(9.8739) | Error 0.3289(0.2943) Steps 604(616.03) | Grad Norm 9.3318(8.8351) | Total Time 0.00(0.00)\n",
      "Iter 3270 | Time 16.1089(16.0901) | Bit/dim 3.7199(3.7293) | Xent 0.7510(0.8338) | Loss 9.3361(9.7355) | Error 0.2644(0.2965) Steps 610(616.39) | Grad Norm 6.7938(9.6501) | Total Time 0.00(0.00)\n",
      "Iter 3280 | Time 16.3724(16.1301) | Bit/dim 3.7470(3.7303) | Xent 0.7212(0.8285) | Loss 9.2327(9.6327) | Error 0.2533(0.2960) Steps 616(616.81) | Grad Norm 11.7641(9.8535) | Total Time 0.00(0.00)\n",
      "Iter 3290 | Time 16.1619(16.1542) | Bit/dim 3.7218(3.7327) | Xent 0.8060(0.8319) | Loss 9.3859(9.5603) | Error 0.2989(0.2979) Steps 634(617.46) | Grad Norm 9.3964(10.3596) | Total Time 0.00(0.00)\n",
      "Iter 3300 | Time 16.4337(16.2432) | Bit/dim 3.7058(3.7289) | Xent 0.8781(0.8371) | Loss 9.3128(9.5071) | Error 0.3189(0.3005) Steps 628(619.23) | Grad Norm 11.0006(10.0814) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 87.4214, Epoch Time 1007.9769(917.9891), Bit/dim 3.7249(best: 3.7304), Xent 0.8241, Loss 4.1370, Error 0.2937(best: 0.2978)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n",
      "13.203592814371257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3310 | Time 16.8078(16.2649) | Bit/dim 3.7321(3.7321) | Xent 0.8985(0.8392) | Loss 9.3917(9.9876) | Error 0.3267(0.3028) Steps 616(619.91) | Grad Norm 10.5453(10.7707) | Total Time 0.00(0.00)\n",
      "Iter 3320 | Time 16.4843(16.4076) | Bit/dim 3.7391(3.7327) | Xent 0.9050(0.8370) | Loss 9.4116(9.8199) | Error 0.3422(0.3017) Steps 640(619.03) | Grad Norm 14.5046(10.8805) | Total Time 0.00(0.00)\n",
      "Iter 3330 | Time 16.2881(16.3853) | Bit/dim 3.7083(3.7304) | Xent 0.8175(0.8327) | Loss 9.2650(9.6964) | Error 0.3011(0.2999) Steps 652(621.05) | Grad Norm 7.8397(10.0901) | Total Time 0.00(0.00)\n",
      "Iter 3340 | Time 15.0347(16.3236) | Bit/dim 3.7551(3.7250) | Xent 0.7604(0.8249) | Loss 9.3007(9.5887) | Error 0.2689(0.2970) Steps 598(622.79) | Grad Norm 7.2490(9.4426) | Total Time 0.00(0.00)\n",
      "Iter 3350 | Time 15.6197(16.3210) | Bit/dim 3.7129(3.7233) | Xent 0.7459(0.8253) | Loss 9.2107(9.5200) | Error 0.2500(0.2949) Steps 598(623.17) | Grad Norm 7.2281(9.1244) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 89.5528, Epoch Time 1010.8315(920.7744), Bit/dim 3.7235(best: 3.7249), Xent 0.8418, Loss 4.1444, Error 0.2955(best: 0.2937)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n",
      "13.173652694610778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3360 | Time 16.4778(16.3507) | Bit/dim 3.7139(3.7266) | Xent 0.7583(0.8259) | Loss 9.1819(10.0899) | Error 0.2822(0.2951) Steps 586(624.64) | Grad Norm 11.9285(9.6965) | Total Time 0.00(0.00)\n",
      "Iter 3370 | Time 15.6169(16.2602) | Bit/dim 3.7387(3.7247) | Xent 0.7923(0.8243) | Loss 9.2732(9.8764) | Error 0.2933(0.2952) Steps 610(625.21) | Grad Norm 10.6230(9.7470) | Total Time 0.00(0.00)\n",
      "Iter 3380 | Time 16.1949(16.2652) | Bit/dim 3.7381(3.7235) | Xent 0.8010(0.8200) | Loss 9.2729(9.7256) | Error 0.2878(0.2935) Steps 604(624.39) | Grad Norm 5.8939(9.3971) | Total Time 0.00(0.00)\n",
      "Iter 3390 | Time 16.6514(16.3018) | Bit/dim 3.7081(3.7256) | Xent 0.8237(0.8185) | Loss 9.3072(9.6202) | Error 0.2933(0.2924) Steps 580(624.10) | Grad Norm 8.3264(8.9218) | Total Time 0.00(0.00)\n",
      "Iter 3400 | Time 16.4561(16.3160) | Bit/dim 3.7240(3.7235) | Xent 0.8048(0.8105) | Loss 9.4138(9.5373) | Error 0.2844(0.2894) Steps 628(625.94) | Grad Norm 7.6049(8.7068) | Total Time 0.00(0.00)\n",
      "Iter 3410 | Time 16.0609(16.3113) | Bit/dim 3.6727(3.7222) | Xent 0.8741(0.8166) | Loss 9.2840(9.4852) | Error 0.3033(0.2926) Steps 616(626.78) | Grad Norm 12.8665(8.5626) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 88.4687, Epoch Time 1007.7199(923.3828), Bit/dim 3.7263(best: 3.7235), Xent 0.8809, Loss 4.1668, Error 0.3072(best: 0.2937)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n",
      "13.1437125748503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3420 | Time 16.2262(16.3204) | Bit/dim 3.7201(3.7228) | Xent 0.8368(0.8210) | Loss 9.1361(9.9515) | Error 0.2933(0.2932) Steps 622(627.14) | Grad Norm 7.1801(9.3565) | Total Time 0.00(0.00)\n",
      "Iter 3430 | Time 16.2310(16.3835) | Bit/dim 3.7159(3.7236) | Xent 0.8117(0.8091) | Loss 9.3171(9.7753) | Error 0.3078(0.2910) Steps 616(628.85) | Grad Norm 9.0172(9.1055) | Total Time 0.00(0.00)\n",
      "Iter 3440 | Time 16.9287(16.4345) | Bit/dim 3.6643(3.7217) | Xent 0.7979(0.8071) | Loss 9.1868(9.6517) | Error 0.2678(0.2884) Steps 622(629.35) | Grad Norm 6.8590(8.8476) | Total Time 0.00(0.00)\n",
      "Iter 3450 | Time 15.9501(16.3919) | Bit/dim 3.7187(3.7200) | Xent 0.7781(0.7998) | Loss 9.3013(9.5474) | Error 0.2733(0.2858) Steps 622(629.37) | Grad Norm 7.3966(8.4771) | Total Time 0.00(0.00)\n",
      "Iter 3460 | Time 15.8451(16.3907) | Bit/dim 3.7169(3.7171) | Xent 0.7840(0.7966) | Loss 9.2829(9.4719) | Error 0.2711(0.2844) Steps 634(629.03) | Grad Norm 6.7113(8.5504) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 88.2187, Epoch Time 1013.0792(926.0737), Bit/dim 3.7209(best: 3.7235), Xent 0.8173, Loss 4.1295, Error 0.2944(best: 0.2937)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n",
      "13.113772455089821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3470 | Time 16.6751(16.4676) | Bit/dim 3.7193(3.7177) | Xent 0.7463(0.7982) | Loss 9.1941(10.0492) | Error 0.2767(0.2860) Steps 610(628.68) | Grad Norm 7.2879(9.1657) | Total Time 0.00(0.00)\n",
      "Iter 3480 | Time 15.5382(16.4158) | Bit/dim 3.6754(3.7166) | Xent 0.8289(0.7966) | Loss 9.2694(9.8547) | Error 0.3000(0.2849) Steps 646(630.25) | Grad Norm 11.0154(9.0984) | Total Time 0.00(0.00)\n",
      "Iter 3490 | Time 16.4455(16.5061) | Bit/dim 3.7443(3.7190) | Xent 0.7784(0.7989) | Loss 9.3296(9.7082) | Error 0.2622(0.2851) Steps 616(630.24) | Grad Norm 13.6699(9.6511) | Total Time 0.00(0.00)\n",
      "Iter 3500 | Time 16.1547(16.5091) | Bit/dim 3.7012(3.7174) | Xent 0.8441(0.7936) | Loss 9.2876(9.5864) | Error 0.2867(0.2837) Steps 628(627.41) | Grad Norm 14.5700(9.4303) | Total Time 0.00(0.00)\n",
      "Iter 3510 | Time 16.9779(16.5793) | Bit/dim 3.7167(3.7170) | Xent 0.8031(0.8010) | Loss 9.4362(9.5324) | Error 0.2867(0.2851) Steps 640(629.33) | Grad Norm 12.8285(10.1967) | Total Time 0.00(0.00)\n",
      "Iter 3520 | Time 16.4097(16.5503) | Bit/dim 3.7226(3.7169) | Xent 0.7948(0.8021) | Loss 9.2237(9.4667) | Error 0.2833(0.2858) Steps 616(628.08) | Grad Norm 6.1553(9.2564) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 88.0986, Epoch Time 1026.9855(929.1010), Bit/dim 3.7140(best: 3.7209), Xent 0.7962, Loss 4.1121, Error 0.2837(best: 0.2937)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n",
      "13.08383233532934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3530 | Time 16.1772(16.5601) | Bit/dim 3.7070(3.7148) | Xent 0.7273(0.7943) | Loss 9.2434(9.9310) | Error 0.2689(0.2832) Steps 658(630.79) | Grad Norm 9.2741(8.7452) | Total Time 0.00(0.00)\n",
      "Iter 3540 | Time 17.0504(16.6435) | Bit/dim 3.7383(3.7159) | Xent 0.8374(0.7978) | Loss 9.3557(9.7810) | Error 0.3022(0.2844) Steps 640(635.49) | Grad Norm 12.0624(9.2830) | Total Time 0.00(0.00)\n",
      "Iter 3550 | Time 16.9404(16.6233) | Bit/dim 3.7180(3.7170) | Xent 0.8038(0.8003) | Loss 9.2972(9.6622) | Error 0.2989(0.2862) Steps 622(635.75) | Grad Norm 11.7656(9.8392) | Total Time 0.00(0.00)\n",
      "Iter 3560 | Time 16.3618(16.6245) | Bit/dim 3.6792(3.7151) | Xent 0.7823(0.7926) | Loss 9.2128(9.5570) | Error 0.2756(0.2840) Steps 634(633.77) | Grad Norm 5.3112(8.9965) | Total Time 0.00(0.00)\n",
      "Iter 3570 | Time 16.5596(16.6541) | Bit/dim 3.7201(3.7156) | Xent 0.8017(0.7904) | Loss 9.4057(9.4968) | Error 0.2711(0.2830) Steps 616(632.27) | Grad Norm 5.4096(8.5259) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 89.1678, Epoch Time 1030.9651(932.1569), Bit/dim 3.7112(best: 3.7140), Xent 0.7830, Loss 4.1027, Error 0.2796(best: 0.2837)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n",
      "13.053892215568862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3580 | Time 16.9312(16.6384) | Bit/dim 3.7413(3.7124) | Xent 0.7448(0.7870) | Loss 9.3513(10.0422) | Error 0.2622(0.2819) Steps 646(633.21) | Grad Norm 8.4717(8.2317) | Total Time 0.00(0.00)\n",
      "Iter 3590 | Time 16.5683(16.5683) | Bit/dim 3.6788(3.7129) | Xent 0.8384(0.7849) | Loss 9.3287(9.8460) | Error 0.2956(0.2803) Steps 652(636.48) | Grad Norm 15.0730(9.0551) | Total Time 0.00(0.00)\n",
      "Iter 3600 | Time 15.9520(16.5208) | Bit/dim 3.6975(3.7128) | Xent 0.8066(0.7869) | Loss 9.3387(9.6953) | Error 0.2867(0.2804) Steps 604(634.13) | Grad Norm 11.6449(9.4494) | Total Time 0.00(0.00)\n",
      "Iter 3610 | Time 16.9318(16.5447) | Bit/dim 3.6773(3.7115) | Xent 0.7750(0.7819) | Loss 9.1617(9.5803) | Error 0.2856(0.2791) Steps 658(636.09) | Grad Norm 5.4605(8.8217) | Total Time 0.00(0.00)\n",
      "Iter 3620 | Time 17.3840(16.5923) | Bit/dim 3.6900(3.7094) | Xent 0.8136(0.7876) | Loss 9.2224(9.5097) | Error 0.2967(0.2810) Steps 628(634.16) | Grad Norm 7.9633(8.6902) | Total Time 0.00(0.00)\n",
      "Iter 3630 | Time 16.3863(16.6093) | Bit/dim 3.6896(3.7068) | Xent 0.7549(0.7843) | Loss 9.1648(9.4387) | Error 0.2678(0.2791) Steps 634(632.72) | Grad Norm 9.9997(8.6884) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 89.2112, Epoch Time 1024.9527(934.9408), Bit/dim 3.7111(best: 3.7112), Xent 0.7748, Loss 4.0985, Error 0.2768(best: 0.2796)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n",
      "13.023952095808383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3640 | Time 18.2908(16.6587) | Bit/dim 3.6909(3.7073) | Xent 0.8132(0.7894) | Loss 9.4254(9.9350) | Error 0.2911(0.2805) Steps 658(634.64) | Grad Norm 12.6184(9.6966) | Total Time 0.00(0.00)\n",
      "Iter 3650 | Time 16.0816(16.6514) | Bit/dim 3.7615(3.7071) | Xent 0.8163(0.7965) | Loss 9.4032(9.7754) | Error 0.2922(0.2844) Steps 634(636.02) | Grad Norm 10.4834(9.9122) | Total Time 0.00(0.00)\n",
      "Iter 3660 | Time 17.5454(16.6967) | Bit/dim 3.7083(3.7089) | Xent 0.7343(0.7914) | Loss 9.3533(9.6524) | Error 0.2633(0.2839) Steps 664(635.26) | Grad Norm 6.6243(9.3745) | Total Time 0.00(0.00)\n",
      "Iter 3670 | Time 16.0638(16.6911) | Bit/dim 3.6918(3.7073) | Xent 0.7650(0.7892) | Loss 9.2238(9.5542) | Error 0.2800(0.2839) Steps 616(634.95) | Grad Norm 5.9840(9.1729) | Total Time 0.00(0.00)\n",
      "Iter 3680 | Time 16.6983(16.6561) | Bit/dim 3.7222(3.7110) | Xent 0.7587(0.7816) | Loss 9.3617(9.4827) | Error 0.2700(0.2789) Steps 664(632.56) | Grad Norm 11.2081(8.6896) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 90.0763, Epoch Time 1033.0750(937.8848), Bit/dim 3.7038(best: 3.7111), Xent 0.7751, Loss 4.0914, Error 0.2759(best: 0.2768)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n",
      "12.994011976047904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3690 | Time 16.3199(16.6419) | Bit/dim 3.7284(3.7097) | Xent 0.7828(0.7751) | Loss 9.3963(10.0222) | Error 0.2744(0.2771) Steps 634(633.84) | Grad Norm 8.0629(8.5561) | Total Time 0.00(0.00)\n",
      "Iter 3700 | Time 16.5078(16.6225) | Bit/dim 3.6831(3.7063) | Xent 0.7325(0.7689) | Loss 9.1920(9.8063) | Error 0.2722(0.2754) Steps 646(633.77) | Grad Norm 7.5254(8.6684) | Total Time 0.00(0.00)\n",
      "Iter 3710 | Time 15.5404(16.6112) | Bit/dim 3.7338(3.7072) | Xent 0.8489(0.7742) | Loss 9.3829(9.6676) | Error 0.2933(0.2766) Steps 628(634.48) | Grad Norm 12.5085(9.6637) | Total Time 0.00(0.00)\n",
      "Iter 3720 | Time 16.8732(16.5805) | Bit/dim 3.6991(3.7115) | Xent 0.7512(0.7748) | Loss 9.2002(9.5590) | Error 0.2744(0.2779) Steps 622(635.06) | Grad Norm 5.8663(9.2495) | Total Time 0.00(0.00)\n",
      "Iter 3730 | Time 16.6206(16.5963) | Bit/dim 3.7214(3.7085) | Xent 0.7434(0.7714) | Loss 9.3177(9.4703) | Error 0.2622(0.2758) Steps 628(633.09) | Grad Norm 6.1248(8.4501) | Total Time 0.00(0.00)\n",
      "Iter 3740 | Time 16.6038(16.6023) | Bit/dim 3.7164(3.7058) | Xent 0.8325(0.7753) | Loss 9.4256(9.4190) | Error 0.2944(0.2778) Steps 646(632.74) | Grad Norm 16.3564(9.1672) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 88.7312, Epoch Time 1025.3360(940.5084), Bit/dim 3.7222(best: 3.7038), Xent 0.8705, Loss 4.1575, Error 0.3042(best: 0.2759)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n",
      "12.964071856287426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3750 | Time 16.6067(16.5987) | Bit/dim 3.6811(3.7071) | Xent 0.8494(0.7850) | Loss 9.2916(9.9075) | Error 0.2956(0.2805) Steps 634(634.25) | Grad Norm 11.7377(9.4228) | Total Time 0.00(0.00)\n",
      "Iter 3760 | Time 17.6436(16.6329) | Bit/dim 3.7240(3.7086) | Xent 0.7809(0.7812) | Loss 9.1921(9.7411) | Error 0.2767(0.2804) Steps 634(633.72) | Grad Norm 11.4528(9.2755) | Total Time 0.00(0.00)\n",
      "Iter 3770 | Time 16.6072(16.6217) | Bit/dim 3.7012(3.7059) | Xent 0.7556(0.7807) | Loss 9.2982(9.6109) | Error 0.2667(0.2783) Steps 640(636.03) | Grad Norm 7.0567(9.6280) | Total Time 0.00(0.00)\n",
      "Iter 3780 | Time 16.8401(16.6851) | Bit/dim 3.7116(3.7074) | Xent 0.8060(0.7772) | Loss 9.2948(9.5194) | Error 0.2833(0.2772) Steps 646(635.12) | Grad Norm 7.7954(9.5331) | Total Time 0.00(0.00)\n",
      "Iter 3790 | Time 16.7625(16.6674) | Bit/dim 3.6899(3.7072) | Xent 0.7701(0.7768) | Loss 9.3562(9.4592) | Error 0.2678(0.2761) Steps 652(635.74) | Grad Norm 6.4886(8.9491) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 89.2875, Epoch Time 1032.0713(943.2553), Bit/dim 3.7076(best: 3.7038), Xent 0.7967, Loss 4.1059, Error 0.2775(best: 0.2759)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n",
      "12.934131736526947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3800 | Time 15.6224(16.6252) | Bit/dim 3.7357(3.7089) | Xent 0.6970(0.7674) | Loss 9.2141(9.9941) | Error 0.2367(0.2729) Steps 610(634.79) | Grad Norm 5.9266(8.5673) | Total Time 0.00(0.00)\n",
      "Iter 3810 | Time 16.7214(16.6430) | Bit/dim 3.6957(3.7048) | Xent 0.7955(0.7648) | Loss 9.2708(9.7970) | Error 0.2600(0.2713) Steps 646(632.95) | Grad Norm 8.4527(8.4300) | Total Time 0.00(0.00)\n",
      "Iter 3820 | Time 16.4947(16.7158) | Bit/dim 3.7162(3.7035) | Xent 0.7642(0.7586) | Loss 9.3011(9.6469) | Error 0.2633(0.2703) Steps 628(633.41) | Grad Norm 8.2746(8.3239) | Total Time 0.00(0.00)\n",
      "Iter 3830 | Time 16.7643(16.7367) | Bit/dim 3.7015(3.7022) | Xent 0.7387(0.7534) | Loss 9.2483(9.5297) | Error 0.2656(0.2686) Steps 658(634.19) | Grad Norm 5.4442(8.2068) | Total Time 0.00(0.00)\n",
      "Iter 3840 | Time 16.8743(16.6930) | Bit/dim 3.6974(3.7004) | Xent 0.8064(0.7508) | Loss 9.2630(9.4456) | Error 0.2867(0.2678) Steps 622(633.44) | Grad Norm 5.9261(8.0632) | Total Time 0.00(0.00)\n",
      "Iter 3850 | Time 16.4628(16.7067) | Bit/dim 3.6959(3.6993) | Xent 0.7143(0.7534) | Loss 9.2945(9.3942) | Error 0.2533(0.2683) Steps 634(635.10) | Grad Norm 6.1021(7.9124) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 88.6363, Epoch Time 1034.9883(946.0073), Bit/dim 3.7006(best: 3.7038), Xent 0.7953, Loss 4.0983, Error 0.2847(best: 0.2759)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n",
      "12.904191616766466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3860 | Time 15.9529(16.5918) | Bit/dim 3.7367(3.7028) | Xent 0.7844(0.7515) | Loss 9.3003(9.8869) | Error 0.2767(0.2670) Steps 616(633.42) | Grad Norm 12.7402(8.2604) | Total Time 0.00(0.00)\n",
      "Iter 3870 | Time 17.0282(16.7196) | Bit/dim 3.7336(3.7031) | Xent 0.7950(0.7519) | Loss 9.3516(9.7230) | Error 0.2722(0.2677) Steps 670(635.66) | Grad Norm 14.7244(8.5593) | Total Time 0.00(0.00)\n",
      "Iter 3880 | Time 16.3972(16.7591) | Bit/dim 3.7302(3.7034) | Xent 0.7851(0.7562) | Loss 9.3408(9.6086) | Error 0.2889(0.2683) Steps 658(638.42) | Grad Norm 9.2874(9.1300) | Total Time 0.00(0.00)\n",
      "Iter 3890 | Time 16.9435(16.7640) | Bit/dim 3.6080(3.6975) | Xent 0.7662(0.7581) | Loss 9.0758(9.5005) | Error 0.2689(0.2700) Steps 658(635.09) | Grad Norm 8.0827(8.8441) | Total Time 0.00(0.00)\n",
      "Iter 3900 | Time 17.0336(16.7519) | Bit/dim 3.7107(3.6995) | Xent 0.8297(0.7580) | Loss 9.2959(9.4317) | Error 0.3078(0.2702) Steps 622(634.89) | Grad Norm 10.4575(8.8912) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 89.9432, Epoch Time 1031.5560(948.5737), Bit/dim 3.6979(best: 3.7006), Xent 0.8443, Loss 4.1200, Error 0.2981(best: 0.2759)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n",
      "12.87425149700599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3910 | Time 16.9843(16.7339) | Bit/dim 3.7101(3.7016) | Xent 0.7842(0.7768) | Loss 9.2854(10.0212) | Error 0.2789(0.2752) Steps 646(635.30) | Grad Norm 12.0493(10.3889) | Total Time 0.00(0.00)\n",
      "Iter 3920 | Time 16.3452(16.7811) | Bit/dim 3.7023(3.7052) | Xent 0.6835(0.7709) | Loss 9.2137(9.8342) | Error 0.2589(0.2735) Steps 610(635.91) | Grad Norm 13.0410(10.4434) | Total Time 0.00(0.00)\n",
      "Iter 3930 | Time 16.6822(16.6919) | Bit/dim 3.6874(3.7025) | Xent 0.7135(0.7675) | Loss 9.1547(9.6797) | Error 0.2467(0.2729) Steps 628(634.32) | Grad Norm 9.0390(9.9774) | Total Time 0.00(0.00)\n",
      "Iter 3940 | Time 16.7993(16.6807) | Bit/dim 3.7108(3.7021) | Xent 0.7171(0.7636) | Loss 9.1503(9.5653) | Error 0.2544(0.2710) Steps 628(635.74) | Grad Norm 5.9488(9.2895) | Total Time 0.00(0.00)\n",
      "Iter 3950 | Time 16.5215(16.6897) | Bit/dim 3.6825(3.6980) | Xent 0.7432(0.7565) | Loss 9.2521(9.4735) | Error 0.2578(0.2687) Steps 628(636.17) | Grad Norm 7.0181(8.7535) | Total Time 0.00(0.00)\n",
      "Iter 3960 | Time 16.7952(16.6707) | Bit/dim 3.6904(3.7001) | Xent 0.7319(0.7523) | Loss 9.2219(9.4164) | Error 0.2589(0.2674) Steps 628(636.03) | Grad Norm 8.3357(9.0812) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 88.8881, Epoch Time 1031.2848(951.0551), Bit/dim 3.7003(best: 3.6979), Xent 0.8099, Loss 4.1052, Error 0.2849(best: 0.2759)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n",
      "12.844311377245509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 3970 | Time 16.4105(16.6726) | Bit/dim 3.6848(3.7011) | Xent 0.7057(0.7494) | Loss 9.0458(9.8842) | Error 0.2500(0.2666) Steps 634(634.39) | Grad Norm 10.3199(8.9188) | Total Time 0.00(0.00)\n",
      "Iter 3980 | Time 17.2675(16.6494) | Bit/dim 3.6878(3.6976) | Xent 0.7007(0.7440) | Loss 9.1538(9.7022) | Error 0.2422(0.2644) Steps 652(636.15) | Grad Norm 5.5585(8.9911) | Total Time 0.00(0.00)\n",
      "Iter 3990 | Time 17.2693(16.6923) | Bit/dim 3.6902(3.6977) | Xent 0.7674(0.7399) | Loss 9.1058(9.5697) | Error 0.2700(0.2615) Steps 616(635.42) | Grad Norm 7.4885(8.5879) | Total Time 0.00(0.00)\n",
      "Iter 4000 | Time 15.4626(16.6130) | Bit/dim 3.6937(3.6990) | Xent 0.8185(0.7410) | Loss 9.1165(9.4771) | Error 0.2733(0.2625) Steps 622(634.06) | Grad Norm 13.6481(8.9281) | Total Time 0.00(0.00)\n",
      "Iter 4010 | Time 16.1403(16.6037) | Bit/dim 3.6854(3.6987) | Xent 0.7781(0.7394) | Loss 9.2541(9.4102) | Error 0.2800(0.2616) Steps 622(634.66) | Grad Norm 9.2895(9.3425) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 88.7699, Epoch Time 1027.4850(953.3479), Bit/dim 3.6965(best: 3.6979), Xent 0.7934, Loss 4.0932, Error 0.2847(best: 0.2759)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n",
      "12.81437125748503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4020 | Time 16.5059(16.5964) | Bit/dim 3.6576(3.6945) | Xent 0.7047(0.7351) | Loss 9.1611(9.9571) | Error 0.2689(0.2597) Steps 658(635.01) | Grad Norm 10.1722(9.3183) | Total Time 0.00(0.00)\n",
      "Iter 4030 | Time 16.9630(16.6462) | Bit/dim 3.6903(3.6919) | Xent 0.7557(0.7382) | Loss 9.3951(9.7601) | Error 0.2644(0.2619) Steps 646(635.48) | Grad Norm 11.2267(9.0937) | Total Time 0.00(0.00)\n",
      "Iter 4040 | Time 16.6900(16.6516) | Bit/dim 3.6794(3.6923) | Xent 0.7160(0.7349) | Loss 9.2065(9.6128) | Error 0.2611(0.2623) Steps 652(635.71) | Grad Norm 5.0960(8.8535) | Total Time 0.00(0.00)\n",
      "Iter 4050 | Time 16.2263(16.6534) | Bit/dim 3.7286(3.6926) | Xent 0.6783(0.7336) | Loss 9.2523(9.5108) | Error 0.2567(0.2621) Steps 634(635.56) | Grad Norm 6.1776(8.2616) | Total Time 0.00(0.00)\n",
      "Iter 4060 | Time 16.2916(16.7316) | Bit/dim 3.6651(3.6942) | Xent 0.7650(0.7314) | Loss 9.2266(9.4337) | Error 0.2644(0.2614) Steps 646(639.77) | Grad Norm 13.4658(8.3583) | Total Time 0.00(0.00)\n",
      "Iter 4070 | Time 16.9839(16.6599) | Bit/dim 3.7040(3.6963) | Xent 0.8354(0.7403) | Loss 9.1967(9.3829) | Error 0.2967(0.2637) Steps 634(637.10) | Grad Norm 9.5154(8.7513) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 89.9054, Epoch Time 1032.0380(955.7087), Bit/dim 3.6943(best: 3.6965), Xent 0.7712, Loss 4.0799, Error 0.2739(best: 0.2759)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n",
      "12.784431137724551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4080 | Time 16.1533(16.6724) | Bit/dim 3.7061(3.6959) | Xent 0.6711(0.7343) | Loss 9.1988(9.8469) | Error 0.2444(0.2617) Steps 628(637.09) | Grad Norm 9.6788(8.5307) | Total Time 0.00(0.00)\n",
      "Iter 4090 | Time 16.5569(16.7101) | Bit/dim 3.6982(3.6946) | Xent 0.7655(0.7286) | Loss 9.1385(9.6751) | Error 0.2733(0.2597) Steps 634(637.96) | Grad Norm 7.8753(8.1314) | Total Time 0.00(0.00)\n",
      "Iter 4100 | Time 16.2043(16.7411) | Bit/dim 3.6957(3.6937) | Xent 0.7966(0.7307) | Loss 9.1742(9.5438) | Error 0.2789(0.2600) Steps 628(640.72) | Grad Norm 9.8327(8.4986) | Total Time 0.00(0.00)\n",
      "Iter 4110 | Time 17.0072(16.7763) | Bit/dim 3.7099(3.6938) | Xent 0.7249(0.7344) | Loss 9.2942(9.4625) | Error 0.2456(0.2630) Steps 646(642.00) | Grad Norm 9.2127(8.6437) | Total Time 0.00(0.00)\n",
      "Iter 4120 | Time 15.7726(16.7331) | Bit/dim 3.7134(3.6944) | Xent 0.7103(0.7315) | Loss 9.0851(9.3892) | Error 0.2522(0.2620) Steps 616(638.29) | Grad Norm 7.1035(8.6337) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 90.7566, Epoch Time 1037.5783(958.1647), Bit/dim 3.6929(best: 3.6943), Xent 0.7638, Loss 4.0748, Error 0.2693(best: 0.2739)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n",
      "12.754491017964073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4130 | Time 16.5111(16.7259) | Bit/dim 3.6763(3.6956) | Xent 0.7116(0.7300) | Loss 9.1406(9.9783) | Error 0.2489(0.2615) Steps 640(636.65) | Grad Norm 7.9348(8.5636) | Total Time 0.00(0.00)\n",
      "Iter 4140 | Time 16.4678(16.6682) | Bit/dim 3.6626(3.6914) | Xent 0.7049(0.7220) | Loss 9.2210(9.7695) | Error 0.2467(0.2581) Steps 640(637.22) | Grad Norm 7.2701(8.0736) | Total Time 0.00(0.00)\n",
      "Iter 4150 | Time 16.8038(16.6635) | Bit/dim 3.6772(3.6893) | Xent 0.7752(0.7233) | Loss 9.2001(9.6125) | Error 0.2600(0.2585) Steps 646(637.23) | Grad Norm 11.3109(8.4520) | Total Time 0.00(0.00)\n",
      "Iter 4160 | Time 16.7577(16.6841) | Bit/dim 3.6815(3.6879) | Xent 0.6769(0.7165) | Loss 9.1856(9.5061) | Error 0.2333(0.2561) Steps 652(639.70) | Grad Norm 7.7273(8.0479) | Total Time 0.00(0.00)\n",
      "Iter 4170 | Time 16.7431(16.6533) | Bit/dim 3.6970(3.6891) | Xent 0.6674(0.7198) | Loss 9.0933(9.4233) | Error 0.2367(0.2567) Steps 616(639.71) | Grad Norm 5.7838(7.5458) | Total Time 0.00(0.00)\n",
      "Iter 4180 | Time 17.0888(16.6517) | Bit/dim 3.6832(3.6882) | Xent 0.7456(0.7161) | Loss 9.1431(9.3406) | Error 0.2667(0.2557) Steps 628(638.66) | Grad Norm 12.1374(7.5659) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 90.2769, Epoch Time 1025.4977(960.1847), Bit/dim 3.6890(best: 3.6929), Xent 0.7627, Loss 4.0703, Error 0.2688(best: 0.2693)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n",
      "12.724550898203592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4190 | Time 16.2997(16.6708) | Bit/dim 3.6923(3.6861) | Xent 0.7360(0.7195) | Loss 9.1145(9.8158) | Error 0.2611(0.2568) Steps 652(637.07) | Grad Norm 6.6555(7.8636) | Total Time 0.00(0.00)\n",
      "Iter 4200 | Time 17.6423(16.6651) | Bit/dim 3.7037(3.6847) | Xent 0.6929(0.7062) | Loss 9.2184(9.6361) | Error 0.2411(0.2515) Steps 646(637.24) | Grad Norm 7.2874(7.6147) | Total Time 0.00(0.00)\n",
      "Iter 4210 | Time 17.0341(16.6877) | Bit/dim 3.6807(3.6875) | Xent 0.7093(0.7009) | Loss 9.1593(9.5140) | Error 0.2622(0.2489) Steps 646(635.59) | Grad Norm 7.0543(7.8120) | Total Time 0.00(0.00)\n",
      "Iter 4220 | Time 16.5662(16.7168) | Bit/dim 3.6797(3.6857) | Xent 0.7476(0.7119) | Loss 9.1954(9.4311) | Error 0.2789(0.2534) Steps 646(638.52) | Grad Norm 9.2985(8.1373) | Total Time 0.00(0.00)\n",
      "Iter 4230 | Time 16.2619(16.7691) | Bit/dim 3.6542(3.6875) | Xent 0.6832(0.7142) | Loss 9.0149(9.3599) | Error 0.2311(0.2542) Steps 616(636.93) | Grad Norm 5.4358(8.2086) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 89.3856, Epoch Time 1038.5475(962.5356), Bit/dim 3.6858(best: 3.6890), Xent 0.7532, Loss 4.0624, Error 0.2683(best: 0.2688)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n",
      "12.694610778443113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4240 | Time 16.0678(16.7282) | Bit/dim 3.6627(3.6864) | Xent 0.6434(0.7114) | Loss 8.9403(9.9408) | Error 0.2378(0.2540) Steps 622(635.17) | Grad Norm 6.2322(8.3896) | Total Time 0.00(0.00)\n",
      "Iter 4250 | Time 17.8804(16.7488) | Bit/dim 3.6682(3.6860) | Xent 0.6772(0.7180) | Loss 9.1228(9.7475) | Error 0.2367(0.2566) Steps 622(633.95) | Grad Norm 10.9977(8.6200) | Total Time 0.00(0.00)\n",
      "Iter 4260 | Time 16.8564(16.7705) | Bit/dim 3.6831(3.6872) | Xent 0.6717(0.7146) | Loss 9.1852(9.6041) | Error 0.2367(0.2554) Steps 616(635.42) | Grad Norm 12.0438(8.8525) | Total Time 0.00(0.00)\n",
      "Iter 4270 | Time 16.2824(16.7310) | Bit/dim 3.7042(3.6847) | Xent 0.7281(0.7190) | Loss 9.2929(9.4976) | Error 0.2567(0.2561) Steps 640(636.94) | Grad Norm 7.6788(9.2190) | Total Time 0.00(0.00)\n",
      "Iter 4280 | Time 16.0721(16.6965) | Bit/dim 3.6824(3.6845) | Xent 0.6884(0.7139) | Loss 9.0870(9.4073) | Error 0.2289(0.2543) Steps 646(636.66) | Grad Norm 6.8309(8.6952) | Total Time 0.00(0.00)\n",
      "Iter 4290 | Time 16.2483(16.7374) | Bit/dim 3.6807(3.6844) | Xent 0.6918(0.7077) | Loss 9.0801(9.3323) | Error 0.2567(0.2517) Steps 646(638.40) | Grad Norm 6.4597(8.4163) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 89.8165, Epoch Time 1032.9208(964.6472), Bit/dim 3.6923(best: 3.6858), Xent 0.7392, Loss 4.0619, Error 0.2592(best: 0.2683)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n",
      "12.664670658682635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4300 | Time 16.5881(16.7549) | Bit/dim 3.6681(3.6840) | Xent 0.7346(0.7027) | Loss 9.0950(9.8302) | Error 0.2667(0.2497) Steps 640(640.70) | Grad Norm 9.9390(8.2875) | Total Time 0.00(0.00)\n",
      "Iter 4310 | Time 16.8302(16.7674) | Bit/dim 3.6704(3.6823) | Xent 0.6305(0.6954) | Loss 8.9966(9.6478) | Error 0.2211(0.2471) Steps 670(644.38) | Grad Norm 9.7926(8.1158) | Total Time 0.00(0.00)\n",
      "Iter 4320 | Time 17.2508(16.8591) | Bit/dim 3.6912(3.6814) | Xent 0.7049(0.6954) | Loss 9.1259(9.5139) | Error 0.2444(0.2472) Steps 628(643.05) | Grad Norm 12.8512(8.3529) | Total Time 0.00(0.00)\n",
      "Iter 4330 | Time 16.7361(16.8605) | Bit/dim 3.6784(3.6825) | Xent 0.7548(0.7024) | Loss 9.2439(9.4242) | Error 0.2556(0.2487) Steps 658(641.98) | Grad Norm 12.7587(9.0063) | Total Time 0.00(0.00)\n",
      "Iter 4340 | Time 16.6925(16.9365) | Bit/dim 3.6487(3.6833) | Xent 0.7027(0.7065) | Loss 9.1113(9.3649) | Error 0.2556(0.2516) Steps 628(640.95) | Grad Norm 5.2224(9.0534) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 90.0537, Epoch Time 1041.4295(966.9506), Bit/dim 3.6850(best: 3.6858), Xent 0.7639, Loss 4.0670, Error 0.2682(best: 0.2592)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n",
      "12.634730538922156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4350 | Time 16.1167(16.8240) | Bit/dim 3.7032(3.6845) | Xent 0.6508(0.7069) | Loss 9.1594(9.9309) | Error 0.2333(0.2520) Steps 640(638.91) | Grad Norm 7.0302(8.8073) | Total Time 0.00(0.00)\n",
      "Iter 4360 | Time 16.8096(16.8070) | Bit/dim 3.6800(3.6829) | Xent 0.6708(0.7074) | Loss 8.9799(9.7292) | Error 0.2378(0.2521) Steps 622(638.38) | Grad Norm 9.5790(9.0958) | Total Time 0.00(0.00)\n",
      "Iter 4370 | Time 17.6406(16.8090) | Bit/dim 3.6930(3.6838) | Xent 0.6968(0.7081) | Loss 9.2533(9.5863) | Error 0.2478(0.2526) Steps 640(638.80) | Grad Norm 7.3512(8.8777) | Total Time 0.00(0.00)\n",
      "Iter 4380 | Time 16.6843(16.7771) | Bit/dim 3.7057(3.6843) | Xent 0.7476(0.7030) | Loss 9.2919(9.4870) | Error 0.2600(0.2501) Steps 628(636.44) | Grad Norm 11.5857(8.9029) | Total Time 0.00(0.00)\n",
      "Iter 4390 | Time 16.8200(16.8059) | Bit/dim 3.7011(3.6836) | Xent 0.7417(0.7029) | Loss 9.2102(9.4100) | Error 0.2511(0.2489) Steps 640(636.82) | Grad Norm 9.1680(9.0599) | Total Time 0.00(0.00)\n",
      "Iter 4400 | Time 17.1308(16.8515) | Bit/dim 3.6455(3.6815) | Xent 0.7345(0.7061) | Loss 9.1667(9.3509) | Error 0.2644(0.2506) Steps 658(638.89) | Grad Norm 9.9175(8.9058) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 90.1805, Epoch Time 1039.6776(969.1324), Bit/dim 3.6835(best: 3.6850), Xent 0.7716, Loss 4.0693, Error 0.2708(best: 0.2592)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n",
      "12.604790419161677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4410 | Time 16.6284(16.8691) | Bit/dim 3.6819(3.6828) | Xent 0.7359(0.7067) | Loss 9.2241(9.8297) | Error 0.2567(0.2512) Steps 616(639.00) | Grad Norm 10.0687(8.8180) | Total Time 0.00(0.00)\n",
      "Iter 4420 | Time 17.0080(16.8722) | Bit/dim 3.6765(3.6785) | Xent 0.7048(0.7098) | Loss 9.2533(9.6568) | Error 0.2444(0.2533) Steps 652(641.01) | Grad Norm 5.9153(8.9518) | Total Time 0.00(0.00)\n",
      "Iter 4430 | Time 16.4112(16.8559) | Bit/dim 3.6600(3.6817) | Xent 0.6790(0.7029) | Loss 9.0958(9.5426) | Error 0.2311(0.2499) Steps 640(641.33) | Grad Norm 7.1163(8.6428) | Total Time 0.00(0.00)\n",
      "Iter 4440 | Time 16.9669(16.8072) | Bit/dim 3.6740(3.6814) | Xent 0.7118(0.7001) | Loss 9.1419(9.4423) | Error 0.2522(0.2490) Steps 634(639.22) | Grad Norm 8.5729(8.3088) | Total Time 0.00(0.00)\n",
      "Iter 4450 | Time 17.0647(16.7752) | Bit/dim 3.6467(3.6801) | Xent 0.6785(0.6975) | Loss 9.1502(9.3644) | Error 0.2422(0.2479) Steps 628(639.48) | Grad Norm 5.7200(8.3550) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 91.7664, Epoch Time 1035.8983(971.1354), Bit/dim 3.6743(best: 3.6835), Xent 0.7603, Loss 4.0544, Error 0.2690(best: 0.2592)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n",
      "12.574850299401197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4460 | Time 16.1150(16.7520) | Bit/dim 3.6909(3.6795) | Xent 0.6239(0.6984) | Loss 9.1755(9.9307) | Error 0.2178(0.2469) Steps 634(639.54) | Grad Norm 6.0825(8.4935) | Total Time 0.00(0.00)\n",
      "Iter 4470 | Time 16.8247(16.8375) | Bit/dim 3.6766(3.6779) | Xent 0.7093(0.6912) | Loss 9.1942(9.7200) | Error 0.2467(0.2454) Steps 670(640.97) | Grad Norm 8.3617(8.0093) | Total Time 0.00(0.00)\n",
      "Iter 4480 | Time 17.7515(16.8996) | Bit/dim 3.6300(3.6746) | Xent 0.6661(0.6857) | Loss 9.0216(9.5574) | Error 0.2400(0.2438) Steps 640(641.05) | Grad Norm 5.2296(7.5946) | Total Time 0.00(0.00)\n",
      "Iter 4490 | Time 18.3683(17.0203) | Bit/dim 3.6862(3.6760) | Xent 0.7095(0.6861) | Loss 9.1341(9.4574) | Error 0.2556(0.2439) Steps 652(641.24) | Grad Norm 16.7371(7.6694) | Total Time 0.00(0.00)\n",
      "Iter 4500 | Time 16.9241(17.0687) | Bit/dim 3.6420(3.6761) | Xent 0.6442(0.6907) | Loss 9.0791(9.3729) | Error 0.2467(0.2467) Steps 664(641.32) | Grad Norm 9.5928(8.2267) | Total Time 0.00(0.00)\n",
      "Iter 4510 | Time 16.4825(17.0780) | Bit/dim 3.6749(3.6771) | Xent 0.7138(0.6926) | Loss 9.1647(9.3140) | Error 0.2544(0.2485) Steps 634(641.67) | Grad Norm 8.5094(8.3202) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 90.3681, Epoch Time 1056.1054(973.6845), Bit/dim 3.6789(best: 3.6743), Xent 0.7455, Loss 4.0516, Error 0.2666(best: 0.2592)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n",
      "12.544910179640718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4520 | Time 17.9570(17.0915) | Bit/dim 3.7135(3.6782) | Xent 0.6632(0.6842) | Loss 9.2786(9.7874) | Error 0.2300(0.2446) Steps 664(643.59) | Grad Norm 8.1807(8.1150) | Total Time 0.00(0.00)\n",
      "Iter 4530 | Time 16.0214(17.0489) | Bit/dim 3.6806(3.6759) | Xent 0.6763(0.6870) | Loss 9.0537(9.6159) | Error 0.2300(0.2442) Steps 658(644.95) | Grad Norm 6.3399(8.6098) | Total Time 0.00(0.00)\n",
      "Iter 4540 | Time 16.6737(17.0172) | Bit/dim 3.6701(3.6774) | Xent 0.6653(0.6813) | Loss 9.1651(9.4926) | Error 0.2433(0.2420) Steps 658(644.22) | Grad Norm 7.6475(8.7126) | Total Time 0.00(0.00)\n",
      "Iter 4550 | Time 16.4864(16.9667) | Bit/dim 3.6975(3.6759) | Xent 0.6832(0.6804) | Loss 9.0330(9.3892) | Error 0.2333(0.2426) Steps 604(641.04) | Grad Norm 10.6739(8.9047) | Total Time 0.00(0.00)\n",
      "Iter 4560 | Time 17.8757(16.9727) | Bit/dim 3.6701(3.6787) | Xent 0.6900(0.6820) | Loss 9.1149(9.3341) | Error 0.2344(0.2434) Steps 658(643.86) | Grad Norm 10.9554(9.0312) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 88.9709, Epoch Time 1042.7191(975.7556), Bit/dim 3.6814(best: 3.6743), Xent 0.8732, Loss 4.1180, Error 0.2985(best: 0.2592)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n",
      "12.514970059880241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4570 | Time 17.1905(17.0471) | Bit/dim 3.6820(3.6784) | Xent 0.6821(0.6923) | Loss 9.1838(9.9212) | Error 0.2389(0.2473) Steps 652(646.51) | Grad Norm 8.7513(9.3345) | Total Time 0.00(0.00)\n",
      "Iter 4580 | Time 16.7443(17.0170) | Bit/dim 3.6334(3.6822) | Xent 0.6552(0.6887) | Loss 8.9361(9.7183) | Error 0.2378(0.2446) Steps 670(647.27) | Grad Norm 6.6827(9.0783) | Total Time 0.00(0.00)\n",
      "Iter 4590 | Time 16.7318(17.0208) | Bit/dim 3.6784(3.6812) | Xent 0.6619(0.6802) | Loss 9.1858(9.5697) | Error 0.2256(0.2412) Steps 640(645.73) | Grad Norm 5.6272(8.4428) | Total Time 0.00(0.00)\n",
      "Iter 4600 | Time 17.1262(17.0455) | Bit/dim 3.6771(3.6772) | Xent 0.6590(0.6726) | Loss 9.0521(9.4383) | Error 0.2456(0.2387) Steps 658(646.18) | Grad Norm 5.7600(7.8442) | Total Time 0.00(0.00)\n",
      "Iter 4610 | Time 16.7977(17.0319) | Bit/dim 3.6928(3.6751) | Xent 0.6289(0.6702) | Loss 9.0255(9.3558) | Error 0.2156(0.2378) Steps 616(646.94) | Grad Norm 4.1915(7.7754) | Total Time 0.00(0.00)\n",
      "Iter 4620 | Time 17.3640(17.0619) | Bit/dim 3.7108(3.6716) | Xent 0.6395(0.6686) | Loss 9.2080(9.2861) | Error 0.2200(0.2378) Steps 658(647.25) | Grad Norm 9.8781(7.8952) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 90.1502, Epoch Time 1054.1383(978.1070), Bit/dim 3.6679(best: 3.6743), Xent 0.7312, Loss 4.0335, Error 0.2560(best: 0.2592)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n",
      "12.48502994011976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4630 | Time 16.8873(17.0580) | Bit/dim 3.6756(3.6719) | Xent 0.7142(0.6602) | Loss 9.1754(9.7671) | Error 0.2500(0.2351) Steps 646(647.51) | Grad Norm 9.3875(7.8995) | Total Time 0.00(0.00)\n",
      "Iter 4640 | Time 18.4744(17.1325) | Bit/dim 3.6398(3.6709) | Xent 0.5773(0.6572) | Loss 8.9513(9.5911) | Error 0.2111(0.2349) Steps 700(649.88) | Grad Norm 3.6720(7.8888) | Total Time 0.00(0.00)\n",
      "Iter 4650 | Time 16.4275(17.1349) | Bit/dim 3.6706(3.6686) | Xent 0.6708(0.6522) | Loss 9.1105(9.4638) | Error 0.2267(0.2322) Steps 652(651.47) | Grad Norm 7.9834(7.5440) | Total Time 0.00(0.00)\n",
      "Iter 4660 | Time 17.2886(17.1042) | Bit/dim 3.6582(3.6677) | Xent 0.6872(0.6540) | Loss 9.1991(9.3583) | Error 0.2489(0.2325) Steps 640(651.27) | Grad Norm 7.1478(7.8428) | Total Time 0.00(0.00)\n",
      "Iter 4670 | Time 17.3880(17.1249) | Bit/dim 3.6777(3.6677) | Xent 0.6757(0.6653) | Loss 9.1851(9.3017) | Error 0.2411(0.2359) Steps 640(651.53) | Grad Norm 9.9968(7.8084) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 90.3333, Epoch Time 1053.6867(980.3744), Bit/dim 3.6760(best: 3.6679), Xent 0.7225, Loss 4.0372, Error 0.2548(best: 0.2560)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n",
      "12.45508982035928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4680 | Time 17.2814(17.1210) | Bit/dim 3.6516(3.6678) | Xent 0.6598(0.6607) | Loss 9.0567(9.8657) | Error 0.2333(0.2345) Steps 664(651.29) | Grad Norm 4.5546(7.7710) | Total Time 0.00(0.00)\n",
      "Iter 4690 | Time 17.9742(17.3011) | Bit/dim 3.6631(3.6688) | Xent 0.6461(0.6574) | Loss 9.0929(9.6768) | Error 0.2433(0.2336) Steps 664(656.14) | Grad Norm 8.4170(7.9943) | Total Time 0.00(0.00)\n",
      "Iter 4700 | Time 17.0823(17.1939) | Bit/dim 3.6792(3.6704) | Xent 0.6227(0.6559) | Loss 9.1659(9.5306) | Error 0.2300(0.2342) Steps 664(656.56) | Grad Norm 7.6227(8.5527) | Total Time 0.00(0.00)\n",
      "Iter 4710 | Time 17.0894(17.1774) | Bit/dim 3.6957(3.6707) | Xent 0.7186(0.6573) | Loss 9.2703(9.4295) | Error 0.2556(0.2341) Steps 676(656.92) | Grad Norm 5.4119(8.1458) | Total Time 0.00(0.00)\n",
      "Iter 4720 | Time 17.4193(17.2491) | Bit/dim 3.6444(3.6688) | Xent 0.6742(0.6560) | Loss 9.0672(9.3395) | Error 0.2433(0.2335) Steps 658(658.83) | Grad Norm 7.8601(8.2192) | Total Time 0.00(0.00)\n",
      "Iter 4730 | Time 17.0654(17.1997) | Bit/dim 3.6958(3.6707) | Xent 0.6937(0.6597) | Loss 9.1340(9.2860) | Error 0.2467(0.2345) Steps 652(658.06) | Grad Norm 6.5512(8.4619) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 90.4284, Epoch Time 1060.3729(982.7744), Bit/dim 3.6773(best: 3.6679), Xent 0.7272, Loss 4.0409, Error 0.2563(best: 0.2548)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n",
      "12.425149700598803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4740 | Time 17.4759(17.1961) | Bit/dim 3.6495(3.6707) | Xent 0.6517(0.6528) | Loss 9.0774(9.7631) | Error 0.2333(0.2327) Steps 676(658.12) | Grad Norm 8.2956(8.1136) | Total Time 0.00(0.00)\n",
      "Iter 4750 | Time 16.7586(17.3226) | Bit/dim 3.6548(3.6691) | Xent 0.6481(0.6493) | Loss 9.0311(9.5812) | Error 0.2156(0.2313) Steps 622(657.49) | Grad Norm 6.3776(7.8676) | Total Time 0.00(0.00)\n",
      "Iter 4760 | Time 17.2988(17.2671) | Bit/dim 3.6537(3.6685) | Xent 0.6410(0.6498) | Loss 9.0060(9.4516) | Error 0.2056(0.2316) Steps 682(657.33) | Grad Norm 9.0784(8.3526) | Total Time 0.00(0.00)\n",
      "Iter 4770 | Time 17.4097(17.2682) | Bit/dim 3.6681(3.6688) | Xent 0.6716(0.6576) | Loss 9.1752(9.3766) | Error 0.2344(0.2341) Steps 664(656.91) | Grad Norm 12.8992(8.4896) | Total Time 0.00(0.00)\n",
      "Iter 4780 | Time 17.1557(17.2508) | Bit/dim 3.6667(3.6676) | Xent 0.6574(0.6623) | Loss 9.0289(9.3080) | Error 0.2378(0.2362) Steps 622(656.35) | Grad Norm 6.2465(8.5593) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 92.9544, Epoch Time 1070.9931(985.4209), Bit/dim 3.6658(best: 3.6679), Xent 0.7294, Loss 4.0305, Error 0.2580(best: 0.2548)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n",
      "12.395209580838323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4790 | Time 17.6858(17.2591) | Bit/dim 3.6685(3.6698) | Xent 0.5492(0.6561) | Loss 8.9444(9.8724) | Error 0.1967(0.2345) Steps 664(656.36) | Grad Norm 5.4085(8.4827) | Total Time 0.00(0.00)\n",
      "Iter 4800 | Time 17.1848(17.2816) | Bit/dim 3.6954(3.6728) | Xent 0.7390(0.6574) | Loss 9.2699(9.6813) | Error 0.2522(0.2342) Steps 658(654.33) | Grad Norm 11.2580(8.6107) | Total Time 0.00(0.00)\n",
      "Iter 4810 | Time 17.3538(17.2769) | Bit/dim 3.6441(3.6710) | Xent 0.6305(0.6566) | Loss 9.1194(9.5290) | Error 0.2267(0.2341) Steps 670(653.99) | Grad Norm 6.1383(8.6454) | Total Time 0.00(0.00)\n",
      "Iter 4820 | Time 17.3541(17.3572) | Bit/dim 3.6345(3.6674) | Xent 0.6692(0.6538) | Loss 9.1540(9.4232) | Error 0.2444(0.2327) Steps 664(657.52) | Grad Norm 6.9672(8.0776) | Total Time 0.00(0.00)\n",
      "Iter 4830 | Time 17.4582(17.3326) | Bit/dim 3.6599(3.6669) | Xent 0.7048(0.6513) | Loss 9.1804(9.3379) | Error 0.2378(0.2307) Steps 658(657.11) | Grad Norm 8.9134(7.7348) | Total Time 0.00(0.00)\n",
      "Iter 4840 | Time 16.9503(17.3091) | Bit/dim 3.6724(3.6652) | Xent 0.6860(0.6526) | Loss 9.1052(9.2754) | Error 0.2600(0.2317) Steps 640(656.53) | Grad Norm 8.4976(7.7843) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 90.0610, Epoch Time 1071.5003(988.0033), Bit/dim 3.6620(best: 3.6658), Xent 0.7396, Loss 4.0318, Error 0.2615(best: 0.2548)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n",
      "12.365269461077844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4850 | Time 16.9971(17.3158) | Bit/dim 3.7041(3.6642) | Xent 0.6434(0.6524) | Loss 9.0570(9.7761) | Error 0.2322(0.2324) Steps 664(656.83) | Grad Norm 6.6535(8.0106) | Total Time 0.00(0.00)\n",
      "Iter 4860 | Time 16.7846(17.2830) | Bit/dim 3.6784(3.6655) | Xent 0.6279(0.6470) | Loss 9.0889(9.5884) | Error 0.2156(0.2310) Steps 664(656.93) | Grad Norm 11.6506(7.9962) | Total Time 0.00(0.00)\n",
      "Iter 4870 | Time 16.9991(17.2934) | Bit/dim 3.6838(3.6668) | Xent 0.6015(0.6479) | Loss 9.1410(9.4645) | Error 0.2022(0.2297) Steps 664(657.41) | Grad Norm 8.5011(8.7226) | Total Time 0.00(0.00)\n",
      "Iter 4880 | Time 17.6092(17.3390) | Bit/dim 3.6431(3.6676) | Xent 0.6512(0.6501) | Loss 8.9713(9.3711) | Error 0.2356(0.2305) Steps 682(655.43) | Grad Norm 6.2645(8.6738) | Total Time 0.00(0.00)\n",
      "Iter 4890 | Time 17.4259(17.4137) | Bit/dim 3.6554(3.6655) | Xent 0.6717(0.6491) | Loss 9.1881(9.3022) | Error 0.2500(0.2298) Steps 658(657.38) | Grad Norm 11.2088(8.7174) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 91.9040, Epoch Time 1070.1592(990.4680), Bit/dim 3.6673(best: 3.6620), Xent 0.7308, Loss 4.0327, Error 0.2565(best: 0.2548)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n",
      "12.335329341317365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4900 | Time 17.2208(17.5151) | Bit/dim 3.6780(3.6672) | Xent 0.5742(0.6441) | Loss 9.0686(9.8820) | Error 0.2011(0.2272) Steps 646(661.41) | Grad Norm 9.5452(8.7852) | Total Time 0.00(0.00)\n",
      "Iter 4910 | Time 17.1008(17.4248) | Bit/dim 3.6534(3.6653) | Xent 0.6593(0.6362) | Loss 9.1518(9.6647) | Error 0.2367(0.2258) Steps 694(660.43) | Grad Norm 7.9984(8.3785) | Total Time 0.00(0.00)\n",
      "Iter 4920 | Time 17.7761(17.5048) | Bit/dim 3.6909(3.6656) | Xent 0.6446(0.6356) | Loss 9.2088(9.5076) | Error 0.2211(0.2255) Steps 682(660.78) | Grad Norm 8.0403(8.1858) | Total Time 0.00(0.00)\n",
      "Iter 4930 | Time 17.2523(17.4345) | Bit/dim 3.6766(3.6653) | Xent 0.5966(0.6358) | Loss 9.1055(9.3986) | Error 0.2022(0.2253) Steps 664(659.57) | Grad Norm 5.4898(8.1468) | Total Time 0.00(0.00)\n",
      "Iter 4940 | Time 17.2662(17.4207) | Bit/dim 3.6742(3.6633) | Xent 0.6398(0.6350) | Loss 8.9693(9.3135) | Error 0.2356(0.2258) Steps 682(661.09) | Grad Norm 6.3521(7.8303) | Total Time 0.00(0.00)\n",
      "Iter 4950 | Time 17.2491(17.3435) | Bit/dim 3.6335(3.6592) | Xent 0.7548(0.6398) | Loss 9.1674(9.2477) | Error 0.2522(0.2267) Steps 652(661.08) | Grad Norm 7.3339(7.6446) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 90.0644, Epoch Time 1067.3917(992.7757), Bit/dim 3.6670(best: 3.6620), Xent 0.7140, Loss 4.0240, Error 0.2527(best: 0.2548)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n",
      "12.305389221556887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 4960 | Time 16.6468(17.3717) | Bit/dim 3.6962(3.6630) | Xent 0.6834(0.6361) | Loss 9.1487(9.7407) | Error 0.2311(0.2262) Steps 628(660.58) | Grad Norm 13.6184(8.1958) | Total Time 0.00(0.00)\n",
      "Iter 4970 | Time 17.6262(17.5001) | Bit/dim 3.6566(3.6619) | Xent 0.6565(0.6362) | Loss 9.1247(9.5755) | Error 0.2278(0.2254) Steps 664(664.29) | Grad Norm 8.4038(8.1528) | Total Time 0.00(0.00)\n",
      "Iter 4980 | Time 19.0564(17.5581) | Bit/dim 3.6484(3.6617) | Xent 0.7350(0.6424) | Loss 9.2866(9.4545) | Error 0.2522(0.2272) Steps 652(663.05) | Grad Norm 10.3517(8.5105) | Total Time 0.00(0.00)\n",
      "Iter 4990 | Time 17.9725(17.5481) | Bit/dim 3.6600(3.6616) | Xent 0.6053(0.6496) | Loss 9.0823(9.3690) | Error 0.2133(0.2305) Steps 670(665.00) | Grad Norm 7.2944(8.4011) | Total Time 0.00(0.00)\n",
      "Iter 5000 | Time 17.4034(17.5155) | Bit/dim 3.6645(3.6617) | Xent 0.7130(0.6513) | Loss 9.1958(9.2982) | Error 0.2378(0.2294) Steps 664(662.35) | Grad Norm 14.8049(8.8103) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 90.7838, Epoch Time 1082.1744(995.4577), Bit/dim 3.6761(best: 3.6620), Xent 0.7259, Loss 4.0391, Error 0.2517(best: 0.2527)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n",
      "12.275449101796406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5010 | Time 17.3991(17.4868) | Bit/dim 3.7051(3.6620) | Xent 0.5993(0.6522) | Loss 9.1736(9.8984) | Error 0.2111(0.2289) Steps 670(665.21) | Grad Norm 8.6473(9.4835) | Total Time 0.00(0.00)\n",
      "Iter 5020 | Time 17.3789(17.5517) | Bit/dim 3.6679(3.6635) | Xent 0.5745(0.6451) | Loss 9.0640(9.6994) | Error 0.2022(0.2280) Steps 676(666.24) | Grad Norm 7.2109(9.3084) | Total Time 0.00(0.00)\n",
      "Iter 5030 | Time 17.1561(17.5062) | Bit/dim 3.6333(3.6654) | Xent 0.6216(0.6422) | Loss 8.9628(9.5460) | Error 0.2256(0.2279) Steps 610(662.73) | Grad Norm 7.8074(8.8258) | Total Time 0.00(0.00)\n",
      "Iter 5040 | Time 17.7019(17.5184) | Bit/dim 3.6470(3.6643) | Xent 0.5543(0.6378) | Loss 9.1047(9.4239) | Error 0.1978(0.2261) Steps 706(662.10) | Grad Norm 4.2254(8.4000) | Total Time 0.00(0.00)\n",
      "Iter 5050 | Time 17.7038(17.5235) | Bit/dim 3.6515(3.6615) | Xent 0.6474(0.6389) | Loss 9.0071(9.3285) | Error 0.2444(0.2270) Steps 670(662.02) | Grad Norm 5.2869(8.1648) | Total Time 0.00(0.00)\n",
      "Iter 5060 | Time 17.1540(17.5343) | Bit/dim 3.6617(3.6589) | Xent 0.6160(0.6439) | Loss 9.0553(9.2656) | Error 0.2244(0.2290) Steps 664(661.22) | Grad Norm 6.2285(8.3571) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 91.9922, Epoch Time 1087.4975(998.2189), Bit/dim 3.6733(best: 3.6620), Xent 0.7447, Loss 4.0456, Error 0.2621(best: 0.2517)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n",
      "12.245508982035929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5070 | Time 17.9526(17.5446) | Bit/dim 3.6617(3.6569) | Xent 0.5868(0.6377) | Loss 8.9868(9.7388) | Error 0.2067(0.2264) Steps 640(661.65) | Grad Norm 5.8704(7.9685) | Total Time 0.00(0.00)\n",
      "Iter 5080 | Time 18.0773(17.5611) | Bit/dim 3.6563(3.6575) | Xent 0.6104(0.6281) | Loss 9.1035(9.5677) | Error 0.2167(0.2228) Steps 670(665.28) | Grad Norm 6.9139(7.7689) | Total Time 0.00(0.00)\n",
      "Iter 5090 | Time 17.8633(17.5977) | Bit/dim 3.6104(3.6562) | Xent 0.6368(0.6261) | Loss 9.0152(9.4394) | Error 0.2289(0.2215) Steps 688(667.80) | Grad Norm 7.5948(7.6094) | Total Time 0.00(0.00)\n",
      "Iter 5100 | Time 17.9637(17.5763) | Bit/dim 3.6792(3.6609) | Xent 0.6678(0.6225) | Loss 9.0310(9.3490) | Error 0.2356(0.2205) Steps 682(666.70) | Grad Norm 5.3529(7.2290) | Total Time 0.00(0.00)\n",
      "Iter 5110 | Time 17.7738(17.6130) | Bit/dim 3.6620(3.6567) | Xent 0.5699(0.6222) | Loss 8.9613(9.2667) | Error 0.1856(0.2211) Steps 658(665.88) | Grad Norm 5.9197(7.7183) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 96.1262, Epoch Time 1086.6518(1000.8719), Bit/dim 3.6578(best: 3.6620), Xent 0.7145, Loss 4.0150, Error 0.2501(best: 0.2517)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n",
      "12.215568862275449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5120 | Time 17.4972(17.6183) | Bit/dim 3.6687(3.6583) | Xent 0.6376(0.6182) | Loss 9.1357(9.8458) | Error 0.2100(0.2195) Steps 658(664.49) | Grad Norm 9.1901(7.9273) | Total Time 0.00(0.00)\n",
      "Iter 5130 | Time 18.0108(17.6527) | Bit/dim 3.6824(3.6606) | Xent 0.6657(0.6195) | Loss 9.2116(9.6625) | Error 0.2467(0.2200) Steps 676(664.79) | Grad Norm 7.4905(8.0744) | Total Time 0.00(0.00)\n",
      "Iter 5140 | Time 17.5153(17.6835) | Bit/dim 3.6674(3.6599) | Xent 0.6159(0.6233) | Loss 9.1530(9.5211) | Error 0.2044(0.2221) Steps 664(667.40) | Grad Norm 6.1202(7.9702) | Total Time 0.00(0.00)\n",
      "Iter 5150 | Time 16.2815(17.6736) | Bit/dim 3.6653(3.6585) | Xent 0.6465(0.6263) | Loss 9.2051(9.4058) | Error 0.2333(0.2229) Steps 676(667.08) | Grad Norm 7.7859(8.3543) | Total Time 0.00(0.00)\n",
      "Iter 5160 | Time 17.6482(17.7198) | Bit/dim 3.6584(3.6579) | Xent 0.5982(0.6215) | Loss 8.9764(9.3109) | Error 0.2133(0.2203) Steps 682(668.25) | Grad Norm 7.3301(8.1529) | Total Time 0.00(0.00)\n",
      "Iter 5170 | Time 18.0685(17.7803) | Bit/dim 3.6651(3.6566) | Xent 0.6331(0.6247) | Loss 9.0095(9.2537) | Error 0.2267(0.2223) Steps 652(666.51) | Grad Norm 9.0174(8.2118) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 93.4511, Epoch Time 1091.6089(1003.5940), Bit/dim 3.6592(best: 3.6578), Xent 0.7041, Loss 4.0112, Error 0.2472(best: 0.2501)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n",
      "12.18562874251497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5180 | Time 17.7829(17.7810) | Bit/dim 3.6645(3.6571) | Xent 0.6397(0.6196) | Loss 9.1504(9.7498) | Error 0.2322(0.2221) Steps 664(668.59) | Grad Norm 9.7048(7.9066) | Total Time 0.00(0.00)\n",
      "Iter 5190 | Time 17.4142(17.7696) | Bit/dim 3.6578(3.6595) | Xent 0.5601(0.6177) | Loss 8.9547(9.5834) | Error 0.2000(0.2211) Steps 676(671.01) | Grad Norm 5.5169(8.1318) | Total Time 0.00(0.00)\n",
      "Iter 5200 | Time 17.6576(17.7446) | Bit/dim 3.6737(3.6590) | Xent 0.6282(0.6182) | Loss 9.0954(9.4463) | Error 0.2289(0.2219) Steps 670(670.48) | Grad Norm 5.4615(7.9009) | Total Time 0.00(0.00)\n",
      "Iter 5210 | Time 18.0083(17.7620) | Bit/dim 3.6475(3.6553) | Xent 0.6091(0.6159) | Loss 9.1363(9.3445) | Error 0.2111(0.2193) Steps 634(671.08) | Grad Norm 9.1731(7.7459) | Total Time 0.00(0.00)\n",
      "Iter 5220 | Time 17.7030(17.7851) | Bit/dim 3.6540(3.6514) | Xent 0.6436(0.6210) | Loss 8.9729(9.2705) | Error 0.2278(0.2207) Steps 646(670.14) | Grad Norm 6.7926(8.1653) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 93.2318, Epoch Time 1096.4707(1006.3803), Bit/dim 3.6596(best: 3.6578), Xent 0.7132, Loss 4.0161, Error 0.2508(best: 0.2472)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n",
      "12.155688622754491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5230 | Time 17.0077(17.6992) | Bit/dim 3.6755(3.6539) | Xent 0.6379(0.6213) | Loss 8.8584(9.8382) | Error 0.2289(0.2200) Steps 652(667.94) | Grad Norm 4.2858(7.6967) | Total Time 0.00(0.00)\n",
      "Iter 5240 | Time 17.8301(17.6895) | Bit/dim 3.6855(3.6569) | Xent 0.6400(0.6238) | Loss 9.2931(9.6584) | Error 0.2322(0.2199) Steps 694(670.21) | Grad Norm 10.8141(8.4750) | Total Time 0.00(0.00)\n",
      "Iter 5250 | Time 17.4927(17.7059) | Bit/dim 3.6359(3.6546) | Xent 0.5516(0.6286) | Loss 8.8788(9.5063) | Error 0.2022(0.2220) Steps 670(671.89) | Grad Norm 6.4777(9.0754) | Total Time 0.00(0.00)\n",
      "Iter 5260 | Time 17.4225(17.7603) | Bit/dim 3.6771(3.6574) | Xent 0.5844(0.6204) | Loss 9.1500(9.3973) | Error 0.2033(0.2212) Steps 664(671.71) | Grad Norm 7.8701(8.7655) | Total Time 0.00(0.00)\n",
      "Iter 5270 | Time 17.8571(17.6950) | Bit/dim 3.6546(3.6581) | Xent 0.6271(0.6138) | Loss 9.1510(9.3170) | Error 0.2156(0.2188) Steps 676(673.30) | Grad Norm 8.4197(8.6118) | Total Time 0.00(0.00)\n",
      "Iter 5280 | Time 17.2287(17.7330) | Bit/dim 3.6081(3.6554) | Xent 0.6425(0.6187) | Loss 9.0081(9.2545) | Error 0.2278(0.2202) Steps 658(671.81) | Grad Norm 6.5047(8.5625) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 91.2895, Epoch Time 1094.0169(1009.0094), Bit/dim 3.6570(best: 3.6578), Xent 0.6954, Loss 4.0047, Error 0.2456(best: 0.2472)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n",
      "12.125748502994012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5290 | Time 17.2528(17.7024) | Bit/dim 3.6093(3.6516) | Xent 0.6230(0.6137) | Loss 8.9439(9.7367) | Error 0.2256(0.2190) Steps 658(670.54) | Grad Norm 5.2463(8.1360) | Total Time 0.00(0.00)\n",
      "Iter 5300 | Time 18.4764(17.7306) | Bit/dim 3.6467(3.6545) | Xent 0.5986(0.6114) | Loss 9.0583(9.5643) | Error 0.2233(0.2184) Steps 664(669.97) | Grad Norm 7.1047(7.8140) | Total Time 0.00(0.00)\n",
      "Iter 5310 | Time 18.1501(17.7905) | Bit/dim 3.6418(3.6520) | Xent 0.5816(0.6128) | Loss 9.0252(9.4286) | Error 0.2067(0.2179) Steps 682(671.05) | Grad Norm 7.4996(8.2565) | Total Time 0.00(0.00)\n",
      "Iter 5320 | Time 18.1020(17.8262) | Bit/dim 3.6370(3.6524) | Xent 0.5218(0.6089) | Loss 8.9695(9.3372) | Error 0.1878(0.2157) Steps 682(671.43) | Grad Norm 7.3066(7.9145) | Total Time 0.00(0.00)\n",
      "Iter 5330 | Time 17.7400(17.7994) | Bit/dim 3.6628(3.6555) | Xent 0.6274(0.6099) | Loss 9.2438(9.2768) | Error 0.2200(0.2156) Steps 652(671.58) | Grad Norm 11.7689(8.3593) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 92.4554, Epoch Time 1098.4378(1011.6922), Bit/dim 3.6563(best: 3.6570), Xent 0.7212, Loss 4.0169, Error 0.2485(best: 0.2456)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n",
      "12.095808383233532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5340 | Time 17.3565(17.8409) | Bit/dim 3.6905(3.6547) | Xent 0.5937(0.6118) | Loss 9.1761(9.8583) | Error 0.2033(0.2152) Steps 682(673.85) | Grad Norm 7.0399(8.9359) | Total Time 0.00(0.00)\n",
      "Iter 5350 | Time 18.5367(17.8660) | Bit/dim 3.6573(3.6535) | Xent 0.5419(0.6117) | Loss 8.9818(9.6533) | Error 0.2033(0.2165) Steps 724(675.29) | Grad Norm 6.7145(8.8094) | Total Time 0.00(0.00)\n",
      "Iter 5360 | Time 17.8225(17.8552) | Bit/dim 3.7040(3.6555) | Xent 0.5055(0.6072) | Loss 9.0508(9.5071) | Error 0.1711(0.2147) Steps 670(674.86) | Grad Norm 5.8182(8.8790) | Total Time 0.00(0.00)\n",
      "Iter 5370 | Time 18.4427(17.9044) | Bit/dim 3.6460(3.6553) | Xent 0.5782(0.6054) | Loss 8.9434(9.3908) | Error 0.2022(0.2136) Steps 688(677.38) | Grad Norm 6.4400(8.4234) | Total Time 0.00(0.00)\n",
      "Iter 5380 | Time 17.6967(17.9586) | Bit/dim 3.6653(3.6549) | Xent 0.6315(0.6058) | Loss 9.1126(9.3116) | Error 0.2289(0.2137) Steps 682(678.66) | Grad Norm 12.7406(8.7604) | Total Time 0.00(0.00)\n",
      "Iter 5390 | Time 17.1414(17.9931) | Bit/dim 3.6441(3.6532) | Xent 0.6010(0.6067) | Loss 9.0926(9.2534) | Error 0.1956(0.2138) Steps 646(678.96) | Grad Norm 9.5544(8.5393) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 93.5119, Epoch Time 1109.8911(1014.6382), Bit/dim 3.6534(best: 3.6563), Xent 0.6911, Loss 3.9990, Error 0.2384(best: 0.2456)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n",
      "12.065868263473053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5400 | Time 17.9275(18.0666) | Bit/dim 3.6602(3.6540) | Xent 0.5992(0.5983) | Loss 9.1237(9.7309) | Error 0.2189(0.2103) Steps 694(680.49) | Grad Norm 7.2247(8.3310) | Total Time 0.00(0.00)\n",
      "Iter 5410 | Time 17.7988(18.0166) | Bit/dim 3.6541(3.6549) | Xent 0.5897(0.5966) | Loss 9.0876(9.5586) | Error 0.2044(0.2105) Steps 658(680.53) | Grad Norm 5.7426(8.3412) | Total Time 0.00(0.00)\n",
      "Iter 5420 | Time 17.1181(17.9388) | Bit/dim 3.6524(3.6540) | Xent 0.5246(0.6049) | Loss 8.9586(9.4374) | Error 0.1844(0.2139) Steps 670(679.73) | Grad Norm 7.8292(8.9518) | Total Time 0.00(0.00)\n",
      "Iter 5430 | Time 18.1943(17.9476) | Bit/dim 3.6283(3.6522) | Xent 0.5809(0.6136) | Loss 9.0401(9.3465) | Error 0.2311(0.2182) Steps 700(680.67) | Grad Norm 7.0627(8.9609) | Total Time 0.00(0.00)\n",
      "Iter 5440 | Time 18.7450(18.0581) | Bit/dim 3.6439(3.6541) | Xent 0.6314(0.6200) | Loss 8.9903(9.2972) | Error 0.2122(0.2197) Steps 694(685.35) | Grad Norm 8.4912(9.4891) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 93.6055, Epoch Time 1108.2621(1017.4469), Bit/dim 3.6657(best: 3.6534), Xent 0.6798, Loss 4.0056, Error 0.2378(best: 0.2384)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n",
      "12.035928143712574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5450 | Time 18.5393(18.0738) | Bit/dim 3.6828(3.6565) | Xent 0.5177(0.6104) | Loss 9.1150(9.8910) | Error 0.1689(0.2158) Steps 712(687.31) | Grad Norm 6.8020(8.9487) | Total Time 0.00(0.00)\n",
      "Iter 5460 | Time 17.4954(18.0656) | Bit/dim 3.6581(3.6527) | Xent 0.5566(0.6024) | Loss 9.0188(9.6767) | Error 0.1933(0.2127) Steps 664(687.95) | Grad Norm 6.7077(8.5412) | Total Time 0.00(0.00)\n",
      "Iter 5470 | Time 17.8905(18.0336) | Bit/dim 3.6635(3.6485) | Xent 0.5956(0.5976) | Loss 9.0738(9.4999) | Error 0.2200(0.2117) Steps 712(688.90) | Grad Norm 7.1307(7.8467) | Total Time 0.00(0.00)\n",
      "Iter 5480 | Time 17.9241(17.9811) | Bit/dim 3.6045(3.6494) | Xent 0.5522(0.5963) | Loss 8.8855(9.3922) | Error 0.1833(0.2115) Steps 646(686.35) | Grad Norm 4.1794(7.6302) | Total Time 0.00(0.00)\n",
      "Iter 5490 | Time 17.6552(17.9790) | Bit/dim 3.6517(3.6492) | Xent 0.6835(0.5966) | Loss 9.1511(9.3111) | Error 0.2433(0.2125) Steps 700(685.78) | Grad Norm 13.9728(8.2181) | Total Time 0.00(0.00)\n",
      "Iter 5500 | Time 18.0252(18.0101) | Bit/dim 3.6471(3.6534) | Xent 0.6026(0.5999) | Loss 9.0250(9.2556) | Error 0.2167(0.2127) Steps 688(687.09) | Grad Norm 7.8195(8.4870) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 92.7317, Epoch Time 1115.7854(1020.3971), Bit/dim 3.6556(best: 3.6534), Xent 0.6955, Loss 4.0034, Error 0.2446(best: 0.2378)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n",
      "12.005988023952096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5510 | Time 18.0510(18.0710) | Bit/dim 3.6196(3.6506) | Xent 0.5773(0.5918) | Loss 9.0130(9.7505) | Error 0.1856(0.2094) Steps 682(692.06) | Grad Norm 9.9861(8.3287) | Total Time 0.00(0.00)\n",
      "Iter 5520 | Time 18.5482(18.0508) | Bit/dim 3.6227(3.6486) | Xent 0.6123(0.5913) | Loss 9.0183(9.5602) | Error 0.2167(0.2085) Steps 712(692.09) | Grad Norm 8.9685(8.3954) | Total Time 0.00(0.00)\n",
      "Iter 5530 | Time 17.3459(18.0924) | Bit/dim 3.6618(3.6523) | Xent 0.6057(0.5938) | Loss 9.1740(9.4455) | Error 0.2278(0.2094) Steps 694(690.72) | Grad Norm 9.5794(8.5073) | Total Time 0.00(0.00)\n",
      "Iter 5540 | Time 18.4582(18.1056) | Bit/dim 3.6164(3.6506) | Xent 0.5649(0.5917) | Loss 9.0130(9.3447) | Error 0.2067(0.2096) Steps 724(691.29) | Grad Norm 6.4049(8.2216) | Total Time 0.00(0.00)\n",
      "Iter 5550 | Time 18.0406(18.1741) | Bit/dim 3.6104(3.6489) | Xent 0.6582(0.5907) | Loss 9.1270(9.2674) | Error 0.2411(0.2098) Steps 682(691.93) | Grad Norm 8.5435(8.2932) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 95.8921, Epoch Time 1118.6886(1023.3458), Bit/dim 3.6558(best: 3.6534), Xent 0.6945, Loss 4.0031, Error 0.2385(best: 0.2378)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n",
      "11.976047904191617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5560 | Time 18.7985(18.2524) | Bit/dim 3.6101(3.6492) | Xent 0.5810(0.5943) | Loss 9.0575(9.8815) | Error 0.2111(0.2106) Steps 712(694.08) | Grad Norm 7.5584(8.3914) | Total Time 0.00(0.00)\n",
      "Iter 5570 | Time 18.5129(18.2302) | Bit/dim 3.6533(3.6502) | Xent 0.5873(0.5923) | Loss 9.2310(9.6705) | Error 0.2133(0.2104) Steps 688(693.18) | Grad Norm 5.6698(8.2529) | Total Time 0.00(0.00)\n",
      "Iter 5580 | Time 18.4667(18.3034) | Bit/dim 3.6145(3.6479) | Xent 0.5361(0.5858) | Loss 8.9102(9.5083) | Error 0.1922(0.2084) Steps 706(695.42) | Grad Norm 8.1367(7.8206) | Total Time 0.00(0.00)\n",
      "Iter 5590 | Time 18.0525(18.2872) | Bit/dim 3.6533(3.6489) | Xent 0.5669(0.5797) | Loss 9.1542(9.3872) | Error 0.2189(0.2070) Steps 700(695.35) | Grad Norm 11.2811(7.7294) | Total Time 0.00(0.00)\n",
      "Iter 5600 | Time 17.8863(18.2577) | Bit/dim 3.6480(3.6472) | Xent 0.5463(0.5824) | Loss 9.0127(9.3005) | Error 0.1878(0.2074) Steps 676(693.52) | Grad Norm 7.4847(7.9556) | Total Time 0.00(0.00)\n",
      "Iter 5610 | Time 17.8733(18.2583) | Bit/dim 3.6429(3.6470) | Xent 0.6058(0.5851) | Loss 9.0741(9.2475) | Error 0.2122(0.2084) Steps 700(692.08) | Grad Norm 8.5778(7.9160) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 94.6573, Epoch Time 1122.2307(1026.3124), Bit/dim 3.6513(best: 3.6534), Xent 0.7308, Loss 4.0167, Error 0.2507(best: 0.2378)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n",
      "11.946107784431137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5620 | Time 18.7128(18.2624) | Bit/dim 3.6523(3.6474) | Xent 0.5141(0.5794) | Loss 9.0372(9.7541) | Error 0.1933(0.2066) Steps 706(695.29) | Grad Norm 4.5489(7.5768) | Total Time 0.00(0.00)\n",
      "Iter 5630 | Time 18.9688(18.3006) | Bit/dim 3.6916(3.6471) | Xent 0.5787(0.5753) | Loss 9.2804(9.5722) | Error 0.1933(0.2056) Steps 700(695.12) | Grad Norm 10.9828(7.6419) | Total Time 0.00(0.00)\n",
      "Iter 5640 | Time 18.2844(18.3996) | Bit/dim 3.6514(3.6456) | Xent 0.5036(0.5784) | Loss 9.0548(9.4458) | Error 0.1811(0.2061) Steps 718(700.26) | Grad Norm 8.7642(8.1160) | Total Time 0.00(0.00)\n",
      "Iter 5650 | Time 18.2384(18.3611) | Bit/dim 3.6345(3.6449) | Xent 0.6184(0.5790) | Loss 8.9500(9.3361) | Error 0.2278(0.2055) Steps 676(695.76) | Grad Norm 10.0953(8.1842) | Total Time 0.00(0.00)\n",
      "Iter 5660 | Time 18.0620(18.4085) | Bit/dim 3.6167(3.6457) | Xent 0.6174(0.5877) | Loss 8.9864(9.2822) | Error 0.2333(0.2093) Steps 664(695.24) | Grad Norm 9.0790(8.0173) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 95.1729, Epoch Time 1130.1237(1029.4267), Bit/dim 3.6489(best: 3.6513), Xent 0.7010, Loss 3.9993, Error 0.2413(best: 0.2378)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n",
      "11.91616766467066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5670 | Time 18.4933(18.4450) | Bit/dim 3.6421(3.6479) | Xent 0.6047(0.5813) | Loss 9.0983(9.8842) | Error 0.2144(0.2061) Steps 730(696.72) | Grad Norm 5.4800(7.5689) | Total Time 0.00(0.00)\n",
      "Iter 5680 | Time 18.6484(18.4192) | Bit/dim 3.6582(3.6478) | Xent 0.6094(0.5805) | Loss 9.1973(9.6737) | Error 0.2211(0.2051) Steps 700(698.17) | Grad Norm 9.4622(7.7124) | Total Time 0.00(0.00)\n",
      "Iter 5690 | Time 18.7505(18.4280) | Bit/dim 3.6396(3.6466) | Xent 0.5915(0.5769) | Loss 9.1177(9.5143) | Error 0.2089(0.2045) Steps 718(697.84) | Grad Norm 7.6777(7.7348) | Total Time 0.00(0.00)\n",
      "Iter 5700 | Time 18.8858(18.4470) | Bit/dim 3.6543(3.6454) | Xent 0.5847(0.5781) | Loss 9.1198(9.3976) | Error 0.2078(0.2062) Steps 700(699.16) | Grad Norm 5.1703(7.6036) | Total Time 0.00(0.00)\n",
      "Iter 5710 | Time 17.9922(18.5477) | Bit/dim 3.6669(3.6432) | Xent 0.5474(0.5736) | Loss 8.9244(9.3061) | Error 0.1933(0.2041) Steps 652(699.45) | Grad Norm 9.6632(7.5766) | Total Time 0.00(0.00)\n",
      "Iter 5720 | Time 17.9127(18.5266) | Bit/dim 3.6933(3.6422) | Xent 0.6197(0.5728) | Loss 9.2030(9.2443) | Error 0.2222(0.2044) Steps 706(698.33) | Grad Norm 11.1064(7.7632) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 96.2290, Epoch Time 1137.1518(1032.6584), Bit/dim 3.6455(best: 3.6489), Xent 0.7022, Loss 3.9966, Error 0.2408(best: 0.2378)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n",
      "11.88622754491018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5730 | Time 17.7308(18.5027) | Bit/dim 3.6385(3.6398) | Xent 0.5412(0.5731) | Loss 9.0263(9.7548) | Error 0.1722(0.2038) Steps 682(696.21) | Grad Norm 7.7699(8.1005) | Total Time 0.00(0.00)\n",
      "Iter 5740 | Time 18.2620(18.4368) | Bit/dim 3.6624(3.6404) | Xent 0.5351(0.5680) | Loss 9.1276(9.5767) | Error 0.1922(0.2021) Steps 730(698.40) | Grad Norm 5.2556(7.9343) | Total Time 0.00(0.00)\n",
      "Iter 5750 | Time 18.7583(18.4631) | Bit/dim 3.6311(3.6415) | Xent 0.6303(0.5766) | Loss 9.1923(9.4574) | Error 0.2289(0.2059) Steps 682(698.53) | Grad Norm 8.7070(8.0738) | Total Time 0.00(0.00)\n",
      "Iter 5760 | Time 19.4205(18.6000) | Bit/dim 3.6705(3.6419) | Xent 0.5658(0.5705) | Loss 9.3294(9.3596) | Error 0.2011(0.2033) Steps 718(701.43) | Grad Norm 7.6363(7.9387) | Total Time 0.00(0.00)\n",
      "Iter 5770 | Time 18.2349(18.5160) | Bit/dim 3.6733(3.6441) | Xent 0.5448(0.5729) | Loss 9.1420(9.2880) | Error 0.1967(0.2042) Steps 664(700.39) | Grad Norm 7.3975(8.5430) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 94.8843, Epoch Time 1133.6033(1035.6868), Bit/dim 3.6405(best: 3.6455), Xent 0.7152, Loss 3.9981, Error 0.2443(best: 0.2378)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n",
      "11.8562874251497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5780 | Time 18.4651(18.4395) | Bit/dim 3.6729(3.6433) | Xent 0.5508(0.5735) | Loss 9.1118(9.8734) | Error 0.1911(0.2051) Steps 718(699.89) | Grad Norm 8.2864(8.3848) | Total Time 0.00(0.00)\n",
      "Iter 5790 | Time 17.9078(18.5252) | Bit/dim 3.6478(3.6451) | Xent 0.5100(0.5676) | Loss 8.9646(9.6529) | Error 0.1811(0.2031) Steps 718(702.14) | Grad Norm 5.5038(8.2957) | Total Time 0.00(0.00)\n",
      "Iter 5800 | Time 18.7602(18.5344) | Bit/dim 3.6779(3.6446) | Xent 0.5536(0.5620) | Loss 9.1508(9.5022) | Error 0.1933(0.2017) Steps 694(701.84) | Grad Norm 7.7939(7.8034) | Total Time 0.00(0.00)\n",
      "Iter 5810 | Time 18.5524(18.4450) | Bit/dim 3.6158(3.6429) | Xent 0.5365(0.5660) | Loss 9.1287(9.3977) | Error 0.1878(0.2020) Steps 706(702.53) | Grad Norm 5.9751(7.9571) | Total Time 0.00(0.00)\n",
      "Iter 5820 | Time 18.9777(18.4929) | Bit/dim 3.6160(3.6426) | Xent 0.5609(0.5681) | Loss 9.0662(9.3229) | Error 0.1889(0.2029) Steps 730(707.62) | Grad Norm 11.3670(7.9612) | Total Time 0.00(0.00)\n",
      "Iter 5830 | Time 18.3335(18.5424) | Bit/dim 3.6417(3.6439) | Xent 0.5811(0.5672) | Loss 9.1824(9.2640) | Error 0.1956(0.2022) Steps 712(710.16) | Grad Norm 9.8119(8.0264) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 96.1013, Epoch Time 1140.0797(1038.8186), Bit/dim 3.6450(best: 3.6405), Xent 0.6841, Loss 3.9871, Error 0.2362(best: 0.2378)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n",
      "11.826347305389222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5840 | Time 17.8301(18.5803) | Bit/dim 3.6598(3.6451) | Xent 0.6031(0.5602) | Loss 9.1808(9.7826) | Error 0.2122(0.1998) Steps 676(708.73) | Grad Norm 11.7645(7.8650) | Total Time 0.00(0.00)\n",
      "Iter 5850 | Time 18.7683(18.5485) | Bit/dim 3.6146(3.6414) | Xent 0.5701(0.5580) | Loss 8.9611(9.5919) | Error 0.2156(0.1988) Steps 742(707.48) | Grad Norm 10.2868(8.1986) | Total Time 0.00(0.00)\n",
      "Iter 5860 | Time 18.4245(18.5939) | Bit/dim 3.6220(3.6421) | Xent 0.5426(0.5593) | Loss 9.1268(9.4665) | Error 0.1856(0.1991) Steps 742(711.61) | Grad Norm 9.1526(8.2653) | Total Time 0.00(0.00)\n",
      "Iter 5870 | Time 19.0669(18.6482) | Bit/dim 3.6303(3.6401) | Xent 0.5262(0.5648) | Loss 9.0438(9.3705) | Error 0.1878(0.2016) Steps 718(711.22) | Grad Norm 5.1276(8.3043) | Total Time 0.00(0.00)\n",
      "Iter 5880 | Time 18.6175(18.6703) | Bit/dim 3.6318(3.6400) | Xent 0.5832(0.5645) | Loss 9.1106(9.2820) | Error 0.1878(0.2004) Steps 688(707.99) | Grad Norm 8.8747(7.8054) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 96.1371, Epoch Time 1144.7351(1041.9961), Bit/dim 3.6444(best: 3.6405), Xent 0.7303, Loss 4.0096, Error 0.2533(best: 0.2362)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n",
      "11.796407185628743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5890 | Time 19.0370(18.7250) | Bit/dim 3.6252(3.6378) | Xent 0.5282(0.5621) | Loss 9.1603(9.8851) | Error 0.1822(0.1987) Steps 724(709.62) | Grad Norm 12.7646(8.2225) | Total Time 0.00(0.00)\n",
      "Iter 5900 | Time 18.1477(18.7474) | Bit/dim 3.6356(3.6371) | Xent 0.5985(0.5629) | Loss 9.0881(9.6668) | Error 0.2044(0.1982) Steps 706(709.78) | Grad Norm 7.5274(8.1941) | Total Time 0.00(0.00)\n",
      "Iter 5910 | Time 18.5218(18.7250) | Bit/dim 3.6806(3.6386) | Xent 0.5740(0.5605) | Loss 9.2558(9.5054) | Error 0.2156(0.1972) Steps 694(711.11) | Grad Norm 5.9277(7.9771) | Total Time 0.00(0.00)\n",
      "Iter 5920 | Time 20.0735(18.7529) | Bit/dim 3.6605(3.6396) | Xent 0.5283(0.5578) | Loss 9.2126(9.3977) | Error 0.1678(0.1954) Steps 790(715.70) | Grad Norm 4.9303(7.7726) | Total Time 0.00(0.00)\n",
      "Iter 5930 | Time 18.5607(18.8086) | Bit/dim 3.6187(3.6385) | Xent 0.5428(0.5467) | Loss 9.0107(9.3036) | Error 0.2011(0.1936) Steps 724(719.04) | Grad Norm 7.4349(7.4901) | Total Time 0.00(0.00)\n",
      "Iter 5940 | Time 18.7760(18.7691) | Bit/dim 3.6416(3.6390) | Xent 0.5815(0.5603) | Loss 9.1728(9.2579) | Error 0.2144(0.1975) Steps 706(716.66) | Grad Norm 8.2433(8.1818) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 96.1913, Epoch Time 1156.5027(1045.4313), Bit/dim 3.6439(best: 3.6405), Xent 0.6975, Loss 3.9927, Error 0.2428(best: 0.2362)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n",
      "11.766467065868262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 5950 | Time 17.6201(18.7673) | Bit/dim 3.6354(3.6401) | Xent 0.6098(0.5600) | Loss 9.1183(9.7721) | Error 0.2189(0.1983) Steps 688(715.71) | Grad Norm 7.4934(8.1535) | Total Time 0.00(0.00)\n",
      "Iter 5960 | Time 18.4284(18.7859) | Bit/dim 3.6207(3.6401) | Xent 0.5612(0.5566) | Loss 9.1549(9.5904) | Error 0.2044(0.1973) Steps 712(716.81) | Grad Norm 8.5490(7.9380) | Total Time 0.00(0.00)\n",
      "Iter 5970 | Time 18.2237(18.8384) | Bit/dim 3.6425(3.6376) | Xent 0.5370(0.5547) | Loss 8.9857(9.4501) | Error 0.1811(0.1967) Steps 712(715.96) | Grad Norm 5.7518(7.8577) | Total Time 0.00(0.00)\n",
      "Iter 5980 | Time 18.4859(18.8457) | Bit/dim 3.6619(3.6404) | Xent 0.5498(0.5522) | Loss 9.0986(9.3595) | Error 0.1933(0.1962) Steps 712(716.16) | Grad Norm 4.8325(7.7302) | Total Time 0.00(0.00)\n",
      "Iter 5990 | Time 17.5864(18.7509) | Bit/dim 3.6545(3.6392) | Xent 0.5775(0.5536) | Loss 8.9932(9.2722) | Error 0.1967(0.1966) Steps 682(713.25) | Grad Norm 10.7208(7.7281) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 96.6548, Epoch Time 1155.7204(1048.7399), Bit/dim 3.6415(best: 3.6405), Xent 0.7033, Loss 3.9931, Error 0.2424(best: 0.2362)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n",
      "11.736526946107785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6000 | Time 19.0669(18.7620) | Bit/dim 3.6530(3.6400) | Xent 0.5657(0.5516) | Loss 9.1918(9.8959) | Error 0.2078(0.1956) Steps 718(715.53) | Grad Norm 8.4884(7.6141) | Total Time 0.00(0.00)\n",
      "Iter 6010 | Time 18.4920(18.7676) | Bit/dim 3.6540(3.6416) | Xent 0.5915(0.5575) | Loss 9.1620(9.6911) | Error 0.2111(0.1972) Steps 724(718.05) | Grad Norm 14.9687(8.4680) | Total Time 0.00(0.00)\n",
      "Iter 6020 | Time 17.4866(18.7887) | Bit/dim 3.6292(3.6402) | Xent 0.6348(0.5665) | Loss 9.2376(9.5440) | Error 0.2211(0.1997) Steps 724(721.51) | Grad Norm 10.1471(8.9249) | Total Time 0.00(0.00)\n",
      "Iter 6030 | Time 19.3571(18.8174) | Bit/dim 3.5978(3.6362) | Xent 0.5331(0.5668) | Loss 9.0377(9.4200) | Error 0.1833(0.2002) Steps 772(719.83) | Grad Norm 4.7772(8.5250) | Total Time 0.00(0.00)\n",
      "Iter 6040 | Time 20.1743(18.8797) | Bit/dim 3.6279(3.6364) | Xent 0.5392(0.5645) | Loss 8.9873(9.3364) | Error 0.1856(0.1995) Steps 682(719.02) | Grad Norm 5.7829(8.2339) | Total Time 0.00(0.00)\n",
      "Iter 6050 | Time 18.5887(18.8546) | Bit/dim 3.6311(3.6397) | Xent 0.5646(0.5626) | Loss 9.1286(9.2840) | Error 0.2144(0.1999) Steps 682(717.62) | Grad Norm 7.0369(7.7542) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 96.5515, Epoch Time 1159.8306(1052.0727), Bit/dim 3.6428(best: 3.6405), Xent 0.6523, Loss 3.9690, Error 0.2251(best: 0.2362)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n",
      "11.706586826347305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6060 | Time 19.3437(18.9749) | Bit/dim 3.6255(3.6393) | Xent 0.5406(0.5551) | Loss 9.1356(9.8118) | Error 0.1867(0.1969) Steps 730(717.78) | Grad Norm 8.2018(7.7127) | Total Time 0.00(0.00)\n",
      "Iter 6070 | Time 19.0743(19.0007) | Bit/dim 3.6622(3.6408) | Xent 0.5284(0.5562) | Loss 9.1549(9.6242) | Error 0.1900(0.1967) Steps 688(717.32) | Grad Norm 10.7770(8.1073) | Total Time 0.00(0.00)\n",
      "Iter 6080 | Time 18.3777(19.0026) | Bit/dim 3.6336(3.6412) | Xent 0.5407(0.5521) | Loss 9.1433(9.4834) | Error 0.1944(0.1948) Steps 712(718.06) | Grad Norm 7.6310(7.9317) | Total Time 0.00(0.00)\n",
      "Iter 6090 | Time 18.9145(19.0134) | Bit/dim 3.6274(3.6391) | Xent 0.5606(0.5504) | Loss 9.1538(9.3657) | Error 0.2056(0.1948) Steps 724(718.57) | Grad Norm 8.0517(7.8964) | Total Time 0.00(0.00)\n",
      "Iter 6100 | Time 19.8754(19.0033) | Bit/dim 3.6601(3.6360) | Xent 0.5379(0.5468) | Loss 9.1616(9.2817) | Error 0.1989(0.1935) Steps 706(719.17) | Grad Norm 6.0419(7.6795) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 96.8577, Epoch Time 1164.8271(1055.4553), Bit/dim 3.6410(best: 3.6405), Xent 0.6809, Loss 3.9814, Error 0.2319(best: 0.2251)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n",
      "11.676646706586826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6110 | Time 18.8119(18.9325) | Bit/dim 3.5993(3.6343) | Xent 0.5307(0.5432) | Loss 9.0468(9.9042) | Error 0.2044(0.1944) Steps 724(720.13) | Grad Norm 7.6930(7.4137) | Total Time 0.00(0.00)\n",
      "Iter 6120 | Time 18.7119(18.9409) | Bit/dim 3.6193(3.6332) | Xent 0.5240(0.5372) | Loss 9.1073(9.6752) | Error 0.1833(0.1912) Steps 712(721.02) | Grad Norm 5.4961(7.2297) | Total Time 0.00(0.00)\n",
      "Iter 6130 | Time 18.6673(18.9303) | Bit/dim 3.6264(3.6322) | Xent 0.5502(0.5339) | Loss 9.0207(9.5082) | Error 0.1956(0.1907) Steps 724(720.14) | Grad Norm 8.8591(7.0263) | Total Time 0.00(0.00)\n",
      "Iter 6140 | Time 18.1409(18.9593) | Bit/dim 3.6721(3.6346) | Xent 0.5460(0.5390) | Loss 9.1009(9.3977) | Error 0.1800(0.1913) Steps 700(718.95) | Grad Norm 9.0668(7.8126) | Total Time 0.00(0.00)\n",
      "Iter 6150 | Time 18.9339(19.0677) | Bit/dim 3.6176(3.6359) | Xent 0.5577(0.5479) | Loss 9.1538(9.3334) | Error 0.1911(0.1941) Steps 760(724.53) | Grad Norm 7.3676(8.8106) | Total Time 0.00(0.00)\n",
      "Iter 6160 | Time 18.6934(18.9553) | Bit/dim 3.6372(3.6384) | Xent 0.5756(0.5525) | Loss 9.1117(9.2681) | Error 0.2044(0.1958) Steps 706(719.76) | Grad Norm 10.1439(8.9399) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 96.4504, Epoch Time 1165.4401(1058.7548), Bit/dim 3.6441(best: 3.6405), Xent 0.6929, Loss 3.9906, Error 0.2367(best: 0.2251)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n",
      "11.646706586826348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6170 | Time 19.8226(19.0025) | Bit/dim 3.6649(3.6433) | Xent 0.5480(0.5470) | Loss 9.1007(9.7955) | Error 0.1944(0.1942) Steps 706(718.31) | Grad Norm 9.0009(8.8704) | Total Time 0.00(0.00)\n",
      "Iter 6180 | Time 18.7433(19.0559) | Bit/dim 3.6185(3.6381) | Xent 0.4916(0.5372) | Loss 8.9943(9.5860) | Error 0.1778(0.1905) Steps 712(721.53) | Grad Norm 7.3119(8.2953) | Total Time 0.00(0.00)\n",
      "Iter 6190 | Time 19.5134(19.0388) | Bit/dim 3.6255(3.6358) | Xent 0.5479(0.5344) | Loss 9.1213(9.4499) | Error 0.1878(0.1894) Steps 730(718.73) | Grad Norm 8.8607(8.0020) | Total Time 0.00(0.00)\n",
      "Iter 6200 | Time 18.7867(19.0264) | Bit/dim 3.6222(3.6374) | Xent 0.5756(0.5378) | Loss 9.1027(9.3684) | Error 0.2011(0.1906) Steps 718(723.13) | Grad Norm 10.5884(8.0325) | Total Time 0.00(0.00)\n",
      "Iter 6210 | Time 18.8250(19.0601) | Bit/dim 3.6494(3.6368) | Xent 0.5957(0.5511) | Loss 9.1400(9.3012) | Error 0.2144(0.1964) Steps 760(727.94) | Grad Norm 6.2530(8.4649) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 96.5148, Epoch Time 1171.0905(1062.1249), Bit/dim 3.6406(best: 3.6405), Xent 0.6826, Loss 3.9818, Error 0.2309(best: 0.2251)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n",
      "11.616766467065869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6220 | Time 18.6101(19.0244) | Bit/dim 3.6172(3.6395) | Xent 0.5129(0.5455) | Loss 8.7974(9.9065) | Error 0.1889(0.1947) Steps 712(727.07) | Grad Norm 8.1593(8.4242) | Total Time 0.00(0.00)\n",
      "Iter 6230 | Time 19.8129(19.1008) | Bit/dim 3.6754(3.6400) | Xent 0.5019(0.5413) | Loss 9.0504(9.6917) | Error 0.1578(0.1928) Steps 724(729.20) | Grad Norm 9.4810(8.4971) | Total Time 0.00(0.00)\n",
      "Iter 6240 | Time 19.4566(19.0680) | Bit/dim 3.6302(3.6404) | Xent 0.5396(0.5435) | Loss 9.0598(9.5339) | Error 0.1878(0.1932) Steps 724(729.93) | Grad Norm 5.3623(8.4729) | Total Time 0.00(0.00)\n",
      "Iter 6250 | Time 18.5164(19.0539) | Bit/dim 3.6112(3.6399) | Xent 0.5194(0.5359) | Loss 8.9606(9.4084) | Error 0.1833(0.1897) Steps 730(729.95) | Grad Norm 6.0461(8.0350) | Total Time 0.00(0.00)\n",
      "Iter 6260 | Time 18.7695(19.0745) | Bit/dim 3.6190(3.6375) | Xent 0.5633(0.5365) | Loss 9.1064(9.3158) | Error 0.2000(0.1899) Steps 754(730.25) | Grad Norm 7.7731(7.9422) | Total Time 0.00(0.00)\n",
      "Iter 6270 | Time 18.1973(19.0107) | Bit/dim 3.6418(3.6375) | Xent 0.6068(0.5459) | Loss 9.1807(9.2606) | Error 0.2111(0.1941) Steps 706(729.80) | Grad Norm 9.8795(8.4565) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 97.7251, Epoch Time 1165.4675(1065.2252), Bit/dim 3.6422(best: 3.6405), Xent 0.6679, Loss 3.9761, Error 0.2293(best: 0.2251)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n",
      "11.586826347305388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6280 | Time 19.4525(19.1075) | Bit/dim 3.6549(3.6378) | Xent 0.5530(0.5396) | Loss 9.1784(9.7905) | Error 0.1989(0.1913) Steps 724(730.13) | Grad Norm 9.5941(8.5071) | Total Time 0.00(0.00)\n",
      "Iter 6290 | Time 18.0384(19.0652) | Bit/dim 3.6075(3.6345) | Xent 0.5242(0.5370) | Loss 8.9264(9.5890) | Error 0.1844(0.1900) Steps 706(728.41) | Grad Norm 12.9676(8.6284) | Total Time 0.00(0.00)\n",
      "Iter 6300 | Time 20.2557(19.0976) | Bit/dim 3.6541(3.6354) | Xent 0.5308(0.5342) | Loss 9.0027(9.4580) | Error 0.1922(0.1901) Steps 760(732.32) | Grad Norm 8.0685(8.3616) | Total Time 0.00(0.00)\n",
      "Iter 6310 | Time 19.9606(19.1514) | Bit/dim 3.6402(3.6345) | Xent 0.5670(0.5362) | Loss 9.1320(9.3612) | Error 0.2000(0.1904) Steps 730(734.11) | Grad Norm 8.6069(8.8358) | Total Time 0.00(0.00)\n",
      "Iter 6320 | Time 19.3494(19.1927) | Bit/dim 3.6645(3.6369) | Xent 0.5207(0.5384) | Loss 9.1422(9.2944) | Error 0.1833(0.1915) Steps 742(735.30) | Grad Norm 5.2849(8.5756) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 97.8489, Epoch Time 1182.4290(1068.7413), Bit/dim 3.6298(best: 3.6405), Xent 0.6743, Loss 3.9669, Error 0.2301(best: 0.2251)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n",
      "11.556886227544911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6330 | Time 20.0486(19.3399) | Bit/dim 3.6295(3.6368) | Xent 0.4803(0.5316) | Loss 9.0785(9.9220) | Error 0.1700(0.1897) Steps 730(737.54) | Grad Norm 5.6966(8.0155) | Total Time 0.00(0.00)\n",
      "Iter 6340 | Time 18.8135(19.2474) | Bit/dim 3.6570(3.6354) | Xent 0.5445(0.5296) | Loss 9.0574(9.6970) | Error 0.2067(0.1880) Steps 694(732.51) | Grad Norm 9.6393(8.4882) | Total Time 0.00(0.00)\n",
      "Iter 6350 | Time 19.1090(19.2656) | Bit/dim 3.6662(3.6384) | Xent 0.5126(0.5323) | Loss 9.0845(9.5448) | Error 0.1856(0.1896) Steps 724(735.66) | Grad Norm 9.8756(8.9269) | Total Time 0.00(0.00)\n",
      "Iter 6360 | Time 18.8841(19.2617) | Bit/dim 3.6455(3.6393) | Xent 0.5618(0.5318) | Loss 9.1342(9.4290) | Error 0.2044(0.1898) Steps 718(735.27) | Grad Norm 8.8579(8.4714) | Total Time 0.00(0.00)\n",
      "Iter 6370 | Time 19.7352(19.3805) | Bit/dim 3.6342(3.6354) | Xent 0.5414(0.5343) | Loss 9.0134(9.3367) | Error 0.1933(0.1894) Steps 772(735.43) | Grad Norm 7.7058(8.5148) | Total Time 0.00(0.00)\n",
      "Iter 6380 | Time 18.8899(19.3316) | Bit/dim 3.6454(3.6358) | Xent 0.5567(0.5333) | Loss 9.2463(9.2685) | Error 0.2011(0.1908) Steps 778(737.42) | Grad Norm 7.3786(8.2891) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 96.7284, Epoch Time 1188.1615(1072.3239), Bit/dim 3.6388(best: 3.6298), Xent 0.7188, Loss 3.9982, Error 0.2351(best: 0.2251)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n",
      "11.52694610778443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6390 | Time 18.9729(19.3605) | Bit/dim 3.6136(3.6316) | Xent 0.4752(0.5276) | Loss 8.9543(9.7624) | Error 0.1700(0.1875) Steps 760(737.90) | Grad Norm 6.4882(8.1830) | Total Time 0.00(0.00)\n",
      "Iter 6400 | Time 19.3640(19.3566) | Bit/dim 3.6611(3.6326) | Xent 0.4887(0.5231) | Loss 9.1227(9.5775) | Error 0.1844(0.1880) Steps 718(737.23) | Grad Norm 8.2368(8.1215) | Total Time 0.00(0.00)\n",
      "Iter 6410 | Time 18.3281(19.2507) | Bit/dim 3.6666(3.6330) | Xent 0.5344(0.5191) | Loss 9.0730(9.4402) | Error 0.1889(0.1854) Steps 718(735.59) | Grad Norm 11.9235(8.0552) | Total Time 0.00(0.00)\n",
      "Iter 6420 | Time 18.7803(19.3110) | Bit/dim 3.6654(3.6314) | Xent 0.5903(0.5182) | Loss 9.0709(9.3375) | Error 0.2133(0.1837) Steps 724(734.86) | Grad Norm 9.8358(8.1373) | Total Time 0.00(0.00)\n",
      "Iter 6430 | Time 19.0589(19.2908) | Bit/dim 3.6413(3.6330) | Xent 0.5523(0.5275) | Loss 9.1795(9.2706) | Error 0.1856(0.1870) Steps 748(735.53) | Grad Norm 7.7794(8.1172) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 97.4967, Epoch Time 1178.2595(1075.5020), Bit/dim 3.6406(best: 3.6298), Xent 0.6655, Loss 3.9734, Error 0.2247(best: 0.2251)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n",
      "11.497005988023952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6440 | Time 19.5936(19.2855) | Bit/dim 3.6677(3.6373) | Xent 0.4593(0.5206) | Loss 9.0810(9.8962) | Error 0.1722(0.1855) Steps 754(736.21) | Grad Norm 4.8307(7.5833) | Total Time 0.00(0.00)\n",
      "Iter 6450 | Time 19.0065(19.2831) | Bit/dim 3.6299(3.6348) | Xent 0.4853(0.5145) | Loss 8.8994(9.6662) | Error 0.1689(0.1833) Steps 742(736.10) | Grad Norm 3.9384(7.3631) | Total Time 0.00(0.00)\n",
      "Iter 6460 | Time 19.3032(19.2369) | Bit/dim 3.6322(3.6325) | Xent 0.5089(0.5130) | Loss 8.9456(9.4852) | Error 0.1867(0.1834) Steps 712(730.93) | Grad Norm 7.0461(7.4711) | Total Time 0.00(0.00)\n",
      "Iter 6470 | Time 19.2048(19.2496) | Bit/dim 3.5932(3.6290) | Xent 0.5290(0.5161) | Loss 9.1356(9.3792) | Error 0.1878(0.1837) Steps 754(730.16) | Grad Norm 8.1432(7.6135) | Total Time 0.00(0.00)\n",
      "Iter 6480 | Time 18.9964(19.2647) | Bit/dim 3.6362(3.6304) | Xent 0.5453(0.5229) | Loss 9.1513(9.3089) | Error 0.2022(0.1858) Steps 736(732.30) | Grad Norm 13.7296(7.8929) | Total Time 0.00(0.00)\n",
      "Iter 6490 | Time 19.7204(19.2873) | Bit/dim 3.6855(3.6324) | Xent 0.5338(0.5254) | Loss 9.2010(9.2533) | Error 0.1867(0.1858) Steps 730(731.59) | Grad Norm 15.0472(8.7084) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 96.5147, Epoch Time 1177.6382(1078.5661), Bit/dim 3.6402(best: 3.6298), Xent 0.6748, Loss 3.9776, Error 0.2291(best: 0.2247)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n",
      "11.467065868263473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6500 | Time 18.6005(19.1776) | Bit/dim 3.6825(3.6365) | Xent 0.5222(0.5240) | Loss 9.1731(9.8016) | Error 0.1822(0.1855) Steps 748(732.73) | Grad Norm 8.8063(8.9182) | Total Time 0.00(0.00)\n",
      "Iter 6510 | Time 19.0649(19.3133) | Bit/dim 3.6432(3.6363) | Xent 0.5069(0.5210) | Loss 9.1650(9.6195) | Error 0.1833(0.1866) Steps 760(741.28) | Grad Norm 10.6738(8.5631) | Total Time 0.00(0.00)\n",
      "Iter 6520 | Time 19.6102(19.3462) | Bit/dim 3.6126(3.6365) | Xent 0.5568(0.5215) | Loss 9.0325(9.4800) | Error 0.1989(0.1860) Steps 736(740.98) | Grad Norm 11.0246(8.5416) | Total Time 0.00(0.00)\n",
      "Iter 6530 | Time 19.7264(19.4591) | Bit/dim 3.6107(3.6356) | Xent 0.5289(0.5237) | Loss 9.1795(9.3814) | Error 0.1867(0.1865) Steps 778(743.92) | Grad Norm 8.1357(8.6271) | Total Time 0.00(0.00)\n",
      "Iter 6540 | Time 19.4345(19.5564) | Bit/dim 3.6249(3.6349) | Xent 0.5052(0.5188) | Loss 9.0578(9.2994) | Error 0.1767(0.1843) Steps 772(746.78) | Grad Norm 10.9464(8.5109) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 98.3919, Epoch Time 1204.6111(1082.3474), Bit/dim 3.6354(best: 3.6298), Xent 0.6886, Loss 3.9797, Error 0.2347(best: 0.2247)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n",
      "11.437125748502993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6550 | Time 19.0970(19.5775) | Bit/dim 3.6521(3.6379) | Xent 0.5390(0.5174) | Loss 9.2375(9.9405) | Error 0.1867(0.1834) Steps 754(749.56) | Grad Norm 7.3459(8.6245) | Total Time 0.00(0.00)\n",
      "Iter 6560 | Time 19.6208(19.4647) | Bit/dim 3.6287(3.6335) | Xent 0.5072(0.5183) | Loss 8.9557(9.7032) | Error 0.1700(0.1831) Steps 748(748.48) | Grad Norm 6.3422(8.4424) | Total Time 0.00(0.00)\n",
      "Iter 6570 | Time 19.5923(19.4295) | Bit/dim 3.6642(3.6341) | Xent 0.5442(0.5294) | Loss 9.1901(9.5488) | Error 0.1911(0.1876) Steps 748(745.69) | Grad Norm 12.0676(8.8730) | Total Time 0.00(0.00)\n",
      "Iter 6580 | Time 18.8818(19.4747) | Bit/dim 3.6306(3.6337) | Xent 0.5479(0.5233) | Loss 9.2015(9.4230) | Error 0.1933(0.1855) Steps 766(748.96) | Grad Norm 8.8075(8.5258) | Total Time 0.00(0.00)\n",
      "Iter 6590 | Time 19.0238(19.3911) | Bit/dim 3.6293(3.6325) | Xent 0.5039(0.5177) | Loss 8.9661(9.3188) | Error 0.1789(0.1836) Steps 748(748.42) | Grad Norm 4.8395(8.1413) | Total Time 0.00(0.00)\n",
      "Iter 6600 | Time 19.2992(19.3677) | Bit/dim 3.6199(3.6313) | Xent 0.4994(0.5179) | Loss 9.0038(9.2519) | Error 0.1656(0.1841) Steps 772(749.54) | Grad Norm 9.5300(7.7072) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 98.5867, Epoch Time 1195.9395(1085.7552), Bit/dim 3.6340(best: 3.6298), Xent 0.6466, Loss 3.9573, Error 0.2234(best: 0.2247)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n",
      "11.407185628742514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6610 | Time 19.1235(19.4414) | Bit/dim 3.6234(3.6337) | Xent 0.4795(0.5094) | Loss 8.8571(9.8077) | Error 0.1789(0.1821) Steps 724(748.83) | Grad Norm 6.4634(7.8046) | Total Time 0.00(0.00)\n",
      "Iter 6620 | Time 19.7028(19.4403) | Bit/dim 3.5994(3.6320) | Xent 0.4447(0.5097) | Loss 8.9352(9.6115) | Error 0.1644(0.1822) Steps 730(748.76) | Grad Norm 6.5023(7.7606) | Total Time 0.00(0.00)\n",
      "Iter 6630 | Time 20.0417(19.4834) | Bit/dim 3.5919(3.6309) | Xent 0.4706(0.5059) | Loss 8.8910(9.4570) | Error 0.1733(0.1801) Steps 748(747.60) | Grad Norm 7.0153(7.3870) | Total Time 0.00(0.00)\n",
      "Iter 6640 | Time 20.1041(19.5042) | Bit/dim 3.6478(3.6276) | Xent 0.4827(0.5042) | Loss 9.1583(9.3387) | Error 0.1733(0.1790) Steps 754(748.28) | Grad Norm 5.1845(7.3395) | Total Time 0.00(0.00)\n",
      "Iter 6650 | Time 19.7920(19.4547) | Bit/dim 3.5850(3.6257) | Xent 0.4820(0.5030) | Loss 8.9712(9.2597) | Error 0.1811(0.1787) Steps 730(747.94) | Grad Norm 7.7067(7.7825) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 97.6919, Epoch Time 1197.2591(1089.1003), Bit/dim 3.6313(best: 3.6298), Xent 0.6515, Loss 3.9571, Error 0.2225(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n",
      "11.377245508982037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6660 | Time 20.0560(19.5323) | Bit/dim 3.6234(3.6279) | Xent 0.5490(0.5026) | Loss 9.1589(9.9025) | Error 0.2078(0.1787) Steps 760(749.13) | Grad Norm 7.6281(7.8911) | Total Time 0.00(0.00)\n",
      "Iter 6670 | Time 19.8777(19.5664) | Bit/dim 3.6108(3.6272) | Xent 0.4857(0.4964) | Loss 8.9713(9.6760) | Error 0.1644(0.1766) Steps 766(751.49) | Grad Norm 4.1802(7.5303) | Total Time 0.00(0.00)\n",
      "Iter 6680 | Time 19.6712(19.6328) | Bit/dim 3.6320(3.6298) | Xent 0.5008(0.4999) | Loss 9.0286(9.5186) | Error 0.1733(0.1783) Steps 772(755.90) | Grad Norm 8.3649(7.6463) | Total Time 0.00(0.00)\n",
      "Iter 6690 | Time 19.6539(19.6461) | Bit/dim 3.6340(3.6308) | Xent 0.4870(0.4963) | Loss 8.9827(9.3991) | Error 0.1689(0.1762) Steps 712(754.46) | Grad Norm 7.4052(7.5814) | Total Time 0.00(0.00)\n",
      "Iter 6700 | Time 18.9690(19.6079) | Bit/dim 3.6192(3.6288) | Xent 0.5877(0.5020) | Loss 9.1110(9.3020) | Error 0.2078(0.1777) Steps 760(751.21) | Grad Norm 7.9140(7.9686) | Total Time 0.00(0.00)\n",
      "Iter 6710 | Time 19.2746(19.5594) | Bit/dim 3.6145(3.6296) | Xent 0.5603(0.5126) | Loss 8.9388(9.2588) | Error 0.1989(0.1815) Steps 736(752.53) | Grad Norm 9.2856(8.3885) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 99.3450, Epoch Time 1199.5729(1092.4145), Bit/dim 3.6218(best: 3.6298), Xent 0.6568, Loss 3.9502, Error 0.2244(best: 0.2225)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n",
      "11.347305389221557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6720 | Time 19.6606(19.6701) | Bit/dim 3.6362(3.6267) | Xent 0.5005(0.5043) | Loss 9.2128(9.7999) | Error 0.1844(0.1798) Steps 760(754.35) | Grad Norm 6.4774(7.8935) | Total Time 0.00(0.00)\n",
      "Iter 6730 | Time 18.8537(19.6594) | Bit/dim 3.6186(3.6249) | Xent 0.4659(0.4913) | Loss 8.9381(9.5814) | Error 0.1511(0.1738) Steps 754(756.94) | Grad Norm 9.2602(7.4909) | Total Time 0.00(0.00)\n",
      "Iter 6740 | Time 20.8848(19.6904) | Bit/dim 3.6119(3.6233) | Xent 0.4939(0.4950) | Loss 9.1259(9.4560) | Error 0.1900(0.1761) Steps 712(754.54) | Grad Norm 4.0973(7.8142) | Total Time 0.00(0.00)\n",
      "Iter 6750 | Time 19.9571(19.7155) | Bit/dim 3.6195(3.6245) | Xent 0.4434(0.4924) | Loss 9.0162(9.3396) | Error 0.1578(0.1750) Steps 760(754.24) | Grad Norm 6.6971(8.0642) | Total Time 0.00(0.00)\n",
      "Iter 6760 | Time 19.0397(19.6148) | Bit/dim 3.6489(3.6272) | Xent 0.4677(0.4984) | Loss 9.0087(9.2644) | Error 0.1644(0.1775) Steps 730(752.10) | Grad Norm 9.0317(8.3605) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 98.1966, Epoch Time 1200.6909(1095.6628), Bit/dim 3.6401(best: 3.6218), Xent 0.6806, Loss 3.9804, Error 0.2293(best: 0.2225)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n",
      "11.317365269461078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6770 | Time 20.0060(19.6075) | Bit/dim 3.6169(3.6273) | Xent 0.5305(0.5050) | Loss 9.1473(9.9017) | Error 0.1922(0.1796) Steps 730(753.26) | Grad Norm 12.1683(8.9461) | Total Time 0.00(0.00)\n",
      "Iter 6780 | Time 20.4246(19.6194) | Bit/dim 3.6267(3.6296) | Xent 0.5934(0.5091) | Loss 9.2257(9.6958) | Error 0.2044(0.1799) Steps 748(752.01) | Grad Norm 17.4034(9.5726) | Total Time 0.00(0.00)\n",
      "Iter 6790 | Time 19.7315(19.6489) | Bit/dim 3.6260(3.6313) | Xent 0.4681(0.5054) | Loss 9.1265(9.5366) | Error 0.1711(0.1793) Steps 772(753.27) | Grad Norm 7.4764(9.2392) | Total Time 0.00(0.00)\n",
      "Iter 6800 | Time 20.3562(19.6704) | Bit/dim 3.5973(3.6319) | Xent 0.5024(0.5020) | Loss 8.9815(9.4063) | Error 0.1711(0.1777) Steps 778(753.30) | Grad Norm 4.5518(8.5323) | Total Time 0.00(0.00)\n",
      "Iter 6810 | Time 19.8659(19.6467) | Bit/dim 3.6649(3.6310) | Xent 0.4918(0.4943) | Loss 9.2012(9.3143) | Error 0.1733(0.1755) Steps 730(750.04) | Grad Norm 11.9036(8.1582) | Total Time 0.00(0.00)\n",
      "Iter 6820 | Time 20.8585(19.7616) | Bit/dim 3.6191(3.6276) | Xent 0.5116(0.4939) | Loss 9.0225(9.2418) | Error 0.1756(0.1752) Steps 748(754.69) | Grad Norm 8.0121(8.1942) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 100.4466, Epoch Time 1210.1048(1099.0960), Bit/dim 3.6276(best: 3.6218), Xent 0.6827, Loss 3.9689, Error 0.2378(best: 0.2225)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n",
      "11.2874251497006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6830 | Time 18.7369(19.7714) | Bit/dim 3.6368(3.6289) | Xent 0.4791(0.4962) | Loss 9.0217(9.7857) | Error 0.1567(0.1754) Steps 742(754.21) | Grad Norm 10.0675(8.1144) | Total Time 0.00(0.00)\n",
      "Iter 6840 | Time 19.3938(19.8969) | Bit/dim 3.6476(3.6261) | Xent 0.4822(0.4869) | Loss 8.9481(9.5731) | Error 0.1678(0.1719) Steps 748(757.78) | Grad Norm 8.2791(7.7737) | Total Time 0.00(0.00)\n",
      "Iter 6850 | Time 20.1908(19.9039) | Bit/dim 3.6530(3.6259) | Xent 0.4216(0.4846) | Loss 8.9951(9.4450) | Error 0.1456(0.1715) Steps 730(758.02) | Grad Norm 6.4516(7.5714) | Total Time 0.00(0.00)\n",
      "Iter 6860 | Time 19.8502(19.8453) | Bit/dim 3.6023(3.6269) | Xent 0.5028(0.4837) | Loss 8.9827(9.3430) | Error 0.1811(0.1724) Steps 766(760.00) | Grad Norm 5.5543(7.6030) | Total Time 0.00(0.00)\n",
      "Iter 6870 | Time 19.6140(19.7442) | Bit/dim 3.6158(3.6268) | Xent 0.5393(0.4895) | Loss 9.0772(9.2712) | Error 0.1900(0.1741) Steps 760(758.38) | Grad Norm 9.0492(7.6531) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 100.0330, Epoch Time 1210.9020(1102.4502), Bit/dim 3.6251(best: 3.6218), Xent 0.6491, Loss 3.9497, Error 0.2193(best: 0.2225)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n",
      "11.25748502994012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter 6880 | Time 19.2789(19.7681) | Bit/dim 3.6122(3.6257) | Xent 0.4579(0.4896) | Loss 8.9948(9.9264) | Error 0.1633(0.1737) Steps 766(759.78) | Grad Norm 7.6395(7.7792) | Total Time 0.00(0.00)\n",
      "Iter 6890 | Time 20.8399(19.8542) | Bit/dim 3.6147(3.6237) | Xent 0.5242(0.4839) | Loss 9.0381(9.6869) | Error 0.1856(0.1721) Steps 778(762.59) | Grad Norm 10.5983(7.9977) | Total Time 0.00(0.00)\n",
      "Iter 6900 | Time 19.4741(19.9020) | Bit/dim 3.6386(3.6231) | Xent 0.4555(0.4849) | Loss 8.9962(9.5166) | Error 0.1567(0.1721) Steps 730(762.80) | Grad Norm 7.1127(8.1390) | Total Time 0.00(0.00)\n",
      "Iter 6910 | Time 20.1182(19.8185) | Bit/dim 3.6202(3.6247) | Xent 0.4370(0.4846) | Loss 9.0698(9.3985) | Error 0.1544(0.1721) Steps 760(761.58) | Grad Norm 7.4670(8.1138) | Total Time 0.00(0.00)\n",
      "Iter 6920 | Time 20.3007(19.8958) | Bit/dim 3.6074(3.6276) | Xent 0.4473(0.4803) | Loss 9.0390(9.3162) | Error 0.1667(0.1707) Steps 748(763.38) | Grad Norm 6.1129(7.7636) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_15_annealing_run3 --seed 3 --lr 0.001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5 --scale_fac 1.0 --scale_std 15.0 --annealing_std True\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
