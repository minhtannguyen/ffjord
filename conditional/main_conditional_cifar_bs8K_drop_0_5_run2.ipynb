{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_drop_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        z = model.module.dropout(z)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=0.0001, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, conditional=True, controlled_tol=True, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_cifar10_8K_drop_0_5_run2/epoch_370_checkpt.pth', rtol=0.0001, save='../experiments_published/cnf_conditional_cifar10_8K_drop_0_5_run2', seed=2, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000.0, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=6144, bias=True)\n",
      "  (project_class): LinearZeros(in_features=3072, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1469494\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 2221 | Time 118.2698(63.5067) | Bit/dim 3.7096(3.7116) | Xent 0.1799(0.2139) | Loss 3.7996(3.8186) | Error 0.0646(0.0738) Steps 706(679.84) | Grad Norm 3.8046(4.3376) | Total Time 14.00(14.00)\n",
      "Iter 2222 | Time 62.7362(63.4836) | Bit/dim 3.6988(3.7112) | Xent 0.1818(0.2129) | Loss 3.7896(3.8177) | Error 0.0645(0.0735) Steps 676(679.73) | Grad Norm 2.9325(4.2954) | Total Time 14.00(14.00)\n",
      "Iter 2223 | Time 62.4566(63.4528) | Bit/dim 3.7071(3.7111) | Xent 0.1918(0.2123) | Loss 3.8031(3.8173) | Error 0.0661(0.0733) Steps 682(679.80) | Grad Norm 2.1257(4.2303) | Total Time 14.00(14.00)\n",
      "Iter 2224 | Time 64.7340(63.4912) | Bit/dim 3.7054(3.7109) | Xent 0.1750(0.2112) | Loss 3.7929(3.8165) | Error 0.0590(0.0729) Steps 688(680.04) | Grad Norm 1.1387(4.1376) | Total Time 14.00(14.00)\n",
      "Iter 2225 | Time 59.6889(63.3772) | Bit/dim 3.7197(3.7112) | Xent 0.1829(0.2103) | Loss 3.8111(3.8164) | Error 0.0624(0.0726) Steps 670(679.74) | Grad Norm 1.6588(4.0632) | Total Time 14.00(14.00)\n",
      "Iter 2226 | Time 63.0376(63.3670) | Bit/dim 3.6956(3.7107) | Xent 0.1740(0.2092) | Loss 3.7826(3.8154) | Error 0.0595(0.0722) Steps 676(679.63) | Grad Norm 2.5247(4.0171) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 38.5276, Epoch Time 488.6820(413.7109), Bit/dim 3.7233(best: inf), Xent 2.0273, Loss 4.7370, Error 0.3999(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2227 | Time 72.7236(63.6477) | Bit/dim 3.6995(3.7104) | Xent 0.1745(0.2082) | Loss 3.7867(3.8145) | Error 0.0606(0.0718) Steps 676(679.52) | Grad Norm 2.7857(3.9801) | Total Time 14.00(14.00)\n",
      "Iter 2228 | Time 65.7790(63.7116) | Bit/dim 3.7028(3.7102) | Xent 0.1779(0.2073) | Loss 3.7917(3.8138) | Error 0.0606(0.0715) Steps 664(679.05) | Grad Norm 2.1080(3.9240) | Total Time 14.00(14.00)\n",
      "Iter 2229 | Time 61.1775(63.6356) | Bit/dim 3.7136(3.7103) | Xent 0.1709(0.2062) | Loss 3.7991(3.8134) | Error 0.0583(0.0711) Steps 676(678.96) | Grad Norm 1.1856(3.8418) | Total Time 14.00(14.00)\n",
      "Iter 2230 | Time 62.2158(63.5930) | Bit/dim 3.6978(3.7099) | Xent 0.1696(0.2051) | Loss 3.7826(3.8124) | Error 0.0556(0.0706) Steps 688(679.23) | Grad Norm 1.0893(3.7592) | Total Time 14.00(14.00)\n",
      "Iter 2231 | Time 67.6115(63.7136) | Bit/dim 3.7148(3.7101) | Xent 0.1638(0.2038) | Loss 3.7967(3.8120) | Error 0.0570(0.0702) Steps 670(678.96) | Grad Norm 1.8544(3.7021) | Total Time 14.00(14.00)\n",
      "Iter 2232 | Time 63.3652(63.7031) | Bit/dim 3.7036(3.7099) | Xent 0.1655(0.2027) | Loss 3.7864(3.8112) | Error 0.0574(0.0698) Steps 676(678.87) | Grad Norm 2.1857(3.6566) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 25.4381, Epoch Time 438.9454(414.4680), Bit/dim 3.7218(best: 3.7233), Xent 2.0751, Loss 4.7593, Error 0.4009(best: 0.3999)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2233 | Time 62.7513(63.6746) | Bit/dim 3.7074(3.7098) | Xent 0.1758(0.2019) | Loss 3.7953(3.8107) | Error 0.0596(0.0695) Steps 682(678.96) | Grad Norm 2.5352(3.6230) | Total Time 14.00(14.00)\n",
      "Iter 2234 | Time 62.1308(63.6282) | Bit/dim 3.7034(3.7096) | Xent 0.1742(0.2011) | Loss 3.7905(3.8101) | Error 0.0576(0.0692) Steps 688(679.23) | Grad Norm 1.6410(3.5635) | Total Time 14.00(14.00)\n",
      "Iter 2235 | Time 61.1288(63.5533) | Bit/dim 3.7120(3.7097) | Xent 0.1588(0.1998) | Loss 3.7914(3.8096) | Error 0.0531(0.0687) Steps 676(679.14) | Grad Norm 1.1175(3.4901) | Total Time 14.00(14.00)\n",
      "Iter 2236 | Time 63.3243(63.5464) | Bit/dim 3.7082(3.7096) | Xent 0.1720(0.1990) | Loss 3.7942(3.8091) | Error 0.0579(0.0684) Steps 664(678.68) | Grad Norm 1.3733(3.4266) | Total Time 14.00(14.00)\n",
      "Iter 2237 | Time 62.3814(63.5114) | Bit/dim 3.7003(3.7093) | Xent 0.1711(0.1981) | Loss 3.7858(3.8084) | Error 0.0601(0.0681) Steps 682(678.78) | Grad Norm 1.3866(3.3654) | Total Time 14.00(14.00)\n",
      "Iter 2238 | Time 60.8563(63.4318) | Bit/dim 3.6994(3.7090) | Xent 0.1653(0.1971) | Loss 3.7821(3.8076) | Error 0.0563(0.0678) Steps 682(678.88) | Grad Norm 1.7272(3.3163) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 25.4142, Epoch Time 417.6165(414.5624), Bit/dim 3.7206(best: 3.7218), Xent 2.0888, Loss 4.7650, Error 0.4023(best: 0.3999)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2239 | Time 61.3543(63.3695) | Bit/dim 3.7002(3.7088) | Xent 0.1526(0.1958) | Loss 3.7766(3.8067) | Error 0.0519(0.0673) Steps 682(678.97) | Grad Norm 1.5350(3.2628) | Total Time 14.00(14.00)\n",
      "Iter 2240 | Time 62.4296(63.3413) | Bit/dim 3.7038(3.7086) | Xent 0.1586(0.1947) | Loss 3.7831(3.8060) | Error 0.0543(0.0669) Steps 682(679.06) | Grad Norm 1.2214(3.2016) | Total Time 14.00(14.00)\n",
      "Iter 2241 | Time 59.9456(63.2394) | Bit/dim 3.7117(3.7087) | Xent 0.1578(0.1936) | Loss 3.7906(3.8055) | Error 0.0543(0.0665) Steps 682(679.15) | Grad Norm 1.3643(3.1465) | Total Time 14.00(14.00)\n",
      "Iter 2242 | Time 60.4571(63.1559) | Bit/dim 3.7090(3.7087) | Xent 0.1722(0.1929) | Loss 3.7951(3.8052) | Error 0.0567(0.0662) Steps 676(679.06) | Grad Norm 1.2130(3.0885) | Total Time 14.00(14.00)\n",
      "Iter 2243 | Time 60.3537(63.0719) | Bit/dim 3.7033(3.7086) | Xent 0.1626(0.1920) | Loss 3.7846(3.8046) | Error 0.0543(0.0659) Steps 688(679.32) | Grad Norm 1.6251(3.0446) | Total Time 14.00(14.00)\n",
      "Iter 2244 | Time 64.4713(63.1138) | Bit/dim 3.7042(3.7084) | Xent 0.1616(0.1911) | Loss 3.7851(3.8040) | Error 0.0553(0.0655) Steps 682(679.40) | Grad Norm 1.8814(3.0097) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 25.5420, Epoch Time 410.3456(414.4359), Bit/dim 3.7218(best: 3.7206), Xent 2.0871, Loss 4.7653, Error 0.4009(best: 0.3999)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2245 | Time 63.3802(63.1218) | Bit/dim 3.7108(3.7085) | Xent 0.1494(0.1899) | Loss 3.7855(3.8034) | Error 0.0505(0.0651) Steps 688(679.66) | Grad Norm 1.3751(2.9606) | Total Time 14.00(14.00)\n",
      "Iter 2246 | Time 62.3792(63.0996) | Bit/dim 3.6972(3.7082) | Xent 0.1575(0.1889) | Loss 3.7759(3.8026) | Error 0.0530(0.0647) Steps 682(679.73) | Grad Norm 0.9050(2.8990) | Total Time 14.00(14.00)\n",
      "Iter 2247 | Time 60.4462(63.0200) | Bit/dim 3.7029(3.7080) | Xent 0.1621(0.1881) | Loss 3.7839(3.8021) | Error 0.0560(0.0645) Steps 682(679.80) | Grad Norm 1.1399(2.8462) | Total Time 14.00(14.00)\n",
      "Iter 2248 | Time 62.0141(62.9898) | Bit/dim 3.7021(3.7078) | Xent 0.1705(0.1876) | Loss 3.7873(3.8016) | Error 0.0560(0.0642) Steps 682(679.87) | Grad Norm 1.6960(2.8117) | Total Time 14.00(14.00)\n",
      "Iter 2249 | Time 59.9865(62.8997) | Bit/dim 3.7072(3.7078) | Xent 0.1694(0.1870) | Loss 3.7919(3.8013) | Error 0.0576(0.0640) Steps 694(680.29) | Grad Norm 1.2190(2.7639) | Total Time 14.00(14.00)\n",
      "Iter 2250 | Time 61.0731(62.8449) | Bit/dim 3.7046(3.7077) | Xent 0.1586(0.1862) | Loss 3.7839(3.8008) | Error 0.0553(0.0637) Steps 676(680.16) | Grad Norm 0.9814(2.7104) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 25.6061, Epoch Time 411.0092(414.3331), Bit/dim 3.7220(best: 3.7206), Xent 2.1305, Loss 4.7872, Error 0.4023(best: 0.3999)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2251 | Time 62.2336(62.8265) | Bit/dim 3.7002(3.7075) | Xent 0.1628(0.1855) | Loss 3.7816(3.8002) | Error 0.0543(0.0635) Steps 682(680.22) | Grad Norm 0.6898(2.6498) | Total Time 14.00(14.00)\n",
      "Iter 2252 | Time 60.8274(62.7666) | Bit/dim 3.7065(3.7075) | Xent 0.1566(0.1846) | Loss 3.7847(3.7998) | Error 0.0531(0.0632) Steps 676(680.09) | Grad Norm 0.9647(2.5993) | Total Time 14.00(14.00)\n",
      "Iter 2253 | Time 60.3578(62.6943) | Bit/dim 3.7094(3.7075) | Xent 0.1695(0.1841) | Loss 3.7942(3.7996) | Error 0.0575(0.0630) Steps 682(680.15) | Grad Norm 1.5205(2.5669) | Total Time 14.00(14.00)\n",
      "Iter 2254 | Time 60.6856(62.6340) | Bit/dim 3.7011(3.7073) | Xent 0.1561(0.1833) | Loss 3.7792(3.7990) | Error 0.0539(0.0627) Steps 682(680.20) | Grad Norm 0.8747(2.5161) | Total Time 14.00(14.00)\n",
      "Iter 2255 | Time 62.7105(62.6363) | Bit/dim 3.7045(3.7072) | Xent 0.1617(0.1827) | Loss 3.7853(3.7986) | Error 0.0540(0.0624) Steps 682(680.26) | Grad Norm 1.1644(2.4756) | Total Time 14.00(14.00)\n",
      "Iter 2256 | Time 62.6835(62.6378) | Bit/dim 3.6980(3.7070) | Xent 0.1578(0.1819) | Loss 3.7769(3.7979) | Error 0.0553(0.0622) Steps 682(680.31) | Grad Norm 0.8784(2.4277) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 25.0454, Epoch Time 410.0299(414.2040), Bit/dim 3.7204(best: 3.7206), Xent 2.0647, Loss 4.7527, Error 0.3960(best: 0.3999)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2257 | Time 61.0555(62.5903) | Bit/dim 3.7108(3.7071) | Xent 0.1492(0.1809) | Loss 3.7854(3.7975) | Error 0.0516(0.0619) Steps 670(680.00) | Grad Norm 0.6702(2.3749) | Total Time 14.00(14.00)\n",
      "Iter 2258 | Time 63.7596(62.6254) | Bit/dim 3.7029(3.7070) | Xent 0.1549(0.1801) | Loss 3.7803(3.7970) | Error 0.0509(0.0616) Steps 664(679.52) | Grad Norm 0.9392(2.3319) | Total Time 14.00(14.00)\n",
      "Iter 2259 | Time 59.8963(62.5435) | Bit/dim 3.7023(3.7068) | Xent 0.1688(0.1798) | Loss 3.7867(3.7967) | Error 0.0579(0.0615) Steps 694(679.95) | Grad Norm 1.1674(2.2969) | Total Time 14.00(14.00)\n",
      "Iter 2260 | Time 62.9423(62.5555) | Bit/dim 3.6881(3.7063) | Xent 0.1533(0.1790) | Loss 3.7647(3.7958) | Error 0.0506(0.0611) Steps 688(680.20) | Grad Norm 0.8133(2.2524) | Total Time 14.00(14.00)\n",
      "Iter 2261 | Time 63.9745(62.5980) | Bit/dim 3.7072(3.7063) | Xent 0.1612(0.1785) | Loss 3.7878(3.7955) | Error 0.0554(0.0610) Steps 682(680.25) | Grad Norm 1.1071(2.2181) | Total Time 14.00(14.00)\n",
      "Iter 2262 | Time 62.3312(62.5900) | Bit/dim 3.7084(3.7063) | Xent 0.1546(0.1778) | Loss 3.7857(3.7952) | Error 0.0501(0.0606) Steps 682(680.30) | Grad Norm 1.0399(2.1827) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 25.5907, Epoch Time 415.4595(414.2417), Bit/dim 3.7202(best: 3.7204), Xent 2.1017, Loss 4.7711, Error 0.3969(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2263 | Time 59.7091(62.5036) | Bit/dim 3.7118(3.7065) | Xent 0.1513(0.1770) | Loss 3.7875(3.7950) | Error 0.0506(0.0603) Steps 688(680.53) | Grad Norm 1.0245(2.1480) | Total Time 14.00(14.00)\n",
      "Iter 2264 | Time 60.4135(62.4409) | Bit/dim 3.7158(3.7068) | Xent 0.1542(0.1763) | Loss 3.7930(3.7949) | Error 0.0535(0.0601) Steps 676(680.40) | Grad Norm 0.8083(2.1078) | Total Time 14.00(14.00)\n",
      "Iter 2265 | Time 62.8553(62.4533) | Bit/dim 3.7008(3.7066) | Xent 0.1562(0.1757) | Loss 3.7789(3.7944) | Error 0.0550(0.0600) Steps 688(680.63) | Grad Norm 0.9518(2.0731) | Total Time 14.00(14.00)\n",
      "Iter 2266 | Time 60.2432(62.3870) | Bit/dim 3.6922(3.7062) | Xent 0.1498(0.1749) | Loss 3.7671(3.7936) | Error 0.0513(0.0597) Steps 694(681.03) | Grad Norm 0.9833(2.0404) | Total Time 14.00(14.00)\n",
      "Iter 2267 | Time 61.3219(62.3551) | Bit/dim 3.7100(3.7063) | Xent 0.1526(0.1742) | Loss 3.7863(3.7934) | Error 0.0510(0.0595) Steps 682(681.06) | Grad Norm 0.8302(2.0041) | Total Time 14.00(14.00)\n",
      "Iter 2268 | Time 61.9890(62.3441) | Bit/dim 3.6939(3.7059) | Xent 0.1611(0.1738) | Loss 3.7745(3.7928) | Error 0.0587(0.0594) Steps 700(681.62) | Grad Norm 1.6888(1.9946) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 25.1546, Epoch Time 407.9492(414.0529), Bit/dim 3.7218(best: 3.7202), Xent 2.1397, Loss 4.7916, Error 0.3996(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2269 | Time 62.4499(62.3473) | Bit/dim 3.7072(3.7060) | Xent 0.1570(0.1733) | Loss 3.7857(3.7926) | Error 0.0557(0.0593) Steps 676(681.46) | Grad Norm 0.9235(1.9625) | Total Time 14.00(14.00)\n",
      "Iter 2270 | Time 62.7718(62.3600) | Bit/dim 3.7034(3.7059) | Xent 0.1559(0.1728) | Loss 3.7814(3.7923) | Error 0.0536(0.0592) Steps 682(681.47) | Grad Norm 1.2557(1.9413) | Total Time 14.00(14.00)\n",
      "Iter 2271 | Time 60.6815(62.3096) | Bit/dim 3.7016(3.7058) | Xent 0.1551(0.1723) | Loss 3.7792(3.7919) | Error 0.0556(0.0591) Steps 688(681.67) | Grad Norm 0.8448(1.9084) | Total Time 14.00(14.00)\n",
      "Iter 2272 | Time 63.1308(62.3343) | Bit/dim 3.6920(3.7053) | Xent 0.1584(0.1719) | Loss 3.7712(3.7913) | Error 0.0544(0.0589) Steps 688(681.86) | Grad Norm 0.9990(1.8811) | Total Time 14.00(14.00)\n",
      "Iter 2273 | Time 60.1111(62.2676) | Bit/dim 3.7048(3.7053) | Xent 0.1428(0.1710) | Loss 3.7762(3.7908) | Error 0.0486(0.0586) Steps 682(681.86) | Grad Norm 1.0229(1.8554) | Total Time 14.00(14.00)\n",
      "Iter 2274 | Time 60.0684(62.2016) | Bit/dim 3.7072(3.7054) | Xent 0.1580(0.1706) | Loss 3.7862(3.7907) | Error 0.0545(0.0585) Steps 676(681.69) | Grad Norm 0.8818(1.8262) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 25.5189, Epoch Time 410.6821(413.9518), Bit/dim 3.7215(best: 3.7202), Xent 2.1382, Loss 4.7906, Error 0.3987(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2275 | Time 60.2956(62.1444) | Bit/dim 3.7080(3.7055) | Xent 0.1620(0.1703) | Loss 3.7889(3.7906) | Error 0.0561(0.0584) Steps 688(681.88) | Grad Norm 0.9804(1.8008) | Total Time 14.00(14.00)\n",
      "Iter 2276 | Time 61.3289(62.1200) | Bit/dim 3.7020(3.7054) | Xent 0.1565(0.1699) | Loss 3.7802(3.7903) | Error 0.0550(0.0583) Steps 670(681.52) | Grad Norm 0.9539(1.7754) | Total Time 14.00(14.00)\n",
      "Iter 2277 | Time 61.2137(62.0928) | Bit/dim 3.6993(3.7052) | Xent 0.1623(0.1697) | Loss 3.7804(3.7900) | Error 0.0560(0.0582) Steps 682(681.53) | Grad Norm 0.7526(1.7447) | Total Time 14.00(14.00)\n",
      "Iter 2278 | Time 63.5748(62.1372) | Bit/dim 3.6963(3.7049) | Xent 0.1620(0.1695) | Loss 3.7773(3.7896) | Error 0.0576(0.0582) Steps 694(681.91) | Grad Norm 1.3687(1.7334) | Total Time 14.00(14.00)\n",
      "Iter 2279 | Time 61.6805(62.1235) | Bit/dim 3.7016(3.7048) | Xent 0.1491(0.1689) | Loss 3.7762(3.7892) | Error 0.0507(0.0580) Steps 688(682.09) | Grad Norm 1.1096(1.7147) | Total Time 14.00(14.00)\n",
      "Iter 2280 | Time 59.7326(62.0518) | Bit/dim 3.7071(3.7049) | Xent 0.1548(0.1684) | Loss 3.7845(3.7891) | Error 0.0536(0.0579) Steps 682(682.09) | Grad Norm 1.0119(1.6936) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 25.4633, Epoch Time 409.0477(413.8047), Bit/dim 3.7210(best: 3.7202), Xent 2.1185, Loss 4.7802, Error 0.3985(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2281 | Time 62.8257(62.0750) | Bit/dim 3.7045(3.7049) | Xent 0.1568(0.1681) | Loss 3.7829(3.7889) | Error 0.0551(0.0578) Steps 700(682.63) | Grad Norm 1.1805(1.6782) | Total Time 14.00(14.00)\n",
      "Iter 2282 | Time 61.4290(62.0556) | Bit/dim 3.6962(3.7046) | Xent 0.1494(0.1675) | Loss 3.7709(3.7884) | Error 0.0523(0.0576) Steps 682(682.61) | Grad Norm 0.9536(1.6565) | Total Time 14.00(14.00)\n",
      "Iter 2283 | Time 62.0274(62.0548) | Bit/dim 3.7001(3.7045) | Xent 0.1622(0.1674) | Loss 3.7812(3.7882) | Error 0.0531(0.0575) Steps 694(682.95) | Grad Norm 0.7066(1.6280) | Total Time 14.00(14.00)\n",
      "Iter 2284 | Time 61.1084(62.0264) | Bit/dim 3.7133(3.7047) | Xent 0.1515(0.1669) | Loss 3.7891(3.7882) | Error 0.0529(0.0573) Steps 688(683.10) | Grad Norm 0.7884(1.6028) | Total Time 14.00(14.00)\n",
      "Iter 2285 | Time 59.2434(61.9429) | Bit/dim 3.7117(3.7049) | Xent 0.1592(0.1667) | Loss 3.7913(3.7883) | Error 0.0539(0.0572) Steps 688(683.25) | Grad Norm 0.7577(1.5775) | Total Time 14.00(14.00)\n",
      "Iter 2286 | Time 62.7148(61.9661) | Bit/dim 3.6993(3.7048) | Xent 0.1586(0.1664) | Loss 3.7786(3.7880) | Error 0.0517(0.0571) Steps 676(683.03) | Grad Norm 0.9118(1.5575) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 25.3216, Epoch Time 410.4034(413.7026), Bit/dim 3.7220(best: 3.7202), Xent 2.1149, Loss 4.7795, Error 0.3962(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2287 | Time 62.3094(61.9764) | Bit/dim 3.7116(3.7050) | Xent 0.1526(0.1660) | Loss 3.7880(3.7880) | Error 0.0535(0.0570) Steps 694(683.36) | Grad Norm 0.8394(1.5359) | Total Time 14.00(14.00)\n",
      "Iter 2288 | Time 58.2595(61.8649) | Bit/dim 3.7056(3.7050) | Xent 0.1555(0.1657) | Loss 3.7833(3.7878) | Error 0.0521(0.0568) Steps 688(683.50) | Grad Norm 0.7835(1.5134) | Total Time 14.00(14.00)\n",
      "Iter 2289 | Time 61.9164(61.8664) | Bit/dim 3.6987(3.7048) | Xent 0.1546(0.1654) | Loss 3.7760(3.7875) | Error 0.0513(0.0567) Steps 682(683.45) | Grad Norm 0.9908(1.4977) | Total Time 14.00(14.00)\n",
      "Iter 2290 | Time 62.3489(61.8809) | Bit/dim 3.6992(3.7046) | Xent 0.1652(0.1654) | Loss 3.7818(3.7873) | Error 0.0585(0.0567) Steps 688(683.59) | Grad Norm 0.8256(1.4775) | Total Time 14.00(14.00)\n",
      "Iter 2291 | Time 64.3529(61.9550) | Bit/dim 3.7132(3.7049) | Xent 0.1491(0.1649) | Loss 3.7878(3.7873) | Error 0.0506(0.0565) Steps 688(683.72) | Grad Norm 0.8601(1.4590) | Total Time 14.00(14.00)\n",
      "Iter 2292 | Time 62.1528(61.9610) | Bit/dim 3.6884(3.7044) | Xent 0.1554(0.1646) | Loss 3.7661(3.7867) | Error 0.0496(0.0563) Steps 676(683.49) | Grad Norm 0.6649(1.4352) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 25.2333, Epoch Time 412.0670(413.6536), Bit/dim 3.7202(best: 3.7202), Xent 2.1257, Loss 4.7830, Error 0.3976(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2293 | Time 62.8921(61.9889) | Bit/dim 3.7060(3.7044) | Xent 0.1616(0.1645) | Loss 3.7868(3.7867) | Error 0.0533(0.0562) Steps 682(683.45) | Grad Norm 1.1437(1.4264) | Total Time 14.00(14.00)\n",
      "Iter 2294 | Time 60.5599(61.9460) | Bit/dim 3.7032(3.7044) | Xent 0.1491(0.1640) | Loss 3.7777(3.7864) | Error 0.0497(0.0560) Steps 676(683.22) | Grad Norm 1.4402(1.4269) | Total Time 14.00(14.00)\n",
      "Iter 2295 | Time 63.5171(61.9932) | Bit/dim 3.6952(3.7041) | Xent 0.1554(0.1638) | Loss 3.7729(3.7860) | Error 0.0521(0.0559) Steps 682(683.19) | Grad Norm 0.8938(1.4109) | Total Time 14.00(14.00)\n",
      "Iter 2296 | Time 64.7698(62.0765) | Bit/dim 3.7082(3.7043) | Xent 0.1473(0.1633) | Loss 3.7819(3.7859) | Error 0.0499(0.0557) Steps 682(683.15) | Grad Norm 0.9142(1.3960) | Total Time 14.00(14.00)\n",
      "Iter 2297 | Time 60.0052(62.0143) | Bit/dim 3.6991(3.7041) | Xent 0.1508(0.1629) | Loss 3.7745(3.7856) | Error 0.0501(0.0556) Steps 682(683.12) | Grad Norm 0.9633(1.3830) | Total Time 14.00(14.00)\n",
      "Iter 2298 | Time 61.6772(62.0042) | Bit/dim 3.7081(3.7042) | Xent 0.1573(0.1627) | Loss 3.7867(3.7856) | Error 0.0513(0.0554) Steps 682(683.08) | Grad Norm 1.3669(1.3825) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 25.0346, Epoch Time 414.0913(413.6667), Bit/dim 3.7214(best: 3.7202), Xent 2.1535, Loss 4.7981, Error 0.4054(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2299 | Time 61.5002(61.9891) | Bit/dim 3.7021(3.7042) | Xent 0.1532(0.1625) | Loss 3.7787(3.7854) | Error 0.0506(0.0553) Steps 688(683.23) | Grad Norm 1.7832(1.3945) | Total Time 14.00(14.00)\n",
      "Iter 2300 | Time 62.5103(62.0047) | Bit/dim 3.7034(3.7041) | Xent 0.1620(0.1624) | Loss 3.7844(3.7854) | Error 0.0580(0.0554) Steps 682(683.19) | Grad Norm 0.8573(1.3784) | Total Time 14.00(14.00)\n",
      "Iter 2301 | Time 61.6099(61.9929) | Bit/dim 3.7048(3.7042) | Xent 0.1519(0.1621) | Loss 3.7808(3.7852) | Error 0.0506(0.0552) Steps 682(683.16) | Grad Norm 1.1614(1.3719) | Total Time 14.00(14.00)\n",
      "Iter 2302 | Time 61.4634(61.9770) | Bit/dim 3.7127(3.7044) | Xent 0.1491(0.1617) | Loss 3.7872(3.7853) | Error 0.0524(0.0551) Steps 700(683.66) | Grad Norm 1.4402(1.3739) | Total Time 14.00(14.00)\n",
      "Iter 2303 | Time 62.7784(62.0010) | Bit/dim 3.6991(3.7043) | Xent 0.1521(0.1614) | Loss 3.7751(3.7850) | Error 0.0526(0.0551) Steps 676(683.43) | Grad Norm 0.8748(1.3590) | Total Time 14.00(14.00)\n",
      "Iter 2304 | Time 64.7184(62.0826) | Bit/dim 3.6958(3.7040) | Xent 0.1509(0.1611) | Loss 3.7713(3.7846) | Error 0.0529(0.0550) Steps 676(683.21) | Grad Norm 0.7917(1.3420) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 24.7559, Epoch Time 415.1206(413.7103), Bit/dim 3.7204(best: 3.7202), Xent 2.1418, Loss 4.7913, Error 0.4007(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2305 | Time 61.0953(62.0529) | Bit/dim 3.7050(3.7040) | Xent 0.1506(0.1608) | Loss 3.7804(3.7844) | Error 0.0513(0.0549) Steps 682(683.17) | Grad Norm 0.7305(1.3236) | Total Time 14.00(14.00)\n",
      "Iter 2306 | Time 61.1097(62.0246) | Bit/dim 3.6955(3.7038) | Xent 0.1566(0.1607) | Loss 3.7738(3.7841) | Error 0.0529(0.0548) Steps 682(683.14) | Grad Norm 1.1416(1.3181) | Total Time 14.00(14.00)\n",
      "Iter 2307 | Time 60.6221(61.9826) | Bit/dim 3.7122(3.7040) | Xent 0.1421(0.1601) | Loss 3.7832(3.7841) | Error 0.0493(0.0547) Steps 688(683.28) | Grad Norm 0.7624(1.3015) | Total Time 14.00(14.00)\n",
      "Iter 2308 | Time 61.6617(61.9729) | Bit/dim 3.7044(3.7040) | Xent 0.1579(0.1601) | Loss 3.7834(3.7841) | Error 0.0506(0.0545) Steps 682(683.24) | Grad Norm 0.8271(1.2872) | Total Time 14.00(14.00)\n",
      "Iter 2309 | Time 58.5433(61.8701) | Bit/dim 3.6990(3.7039) | Xent 0.1522(0.1598) | Loss 3.7751(3.7838) | Error 0.0515(0.0545) Steps 682(683.21) | Grad Norm 0.8608(1.2745) | Total Time 14.00(14.00)\n",
      "Iter 2310 | Time 63.3358(61.9140) | Bit/dim 3.7068(3.7040) | Xent 0.1463(0.1594) | Loss 3.7799(3.7837) | Error 0.0485(0.0543) Steps 682(683.17) | Grad Norm 0.9169(1.2637) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 25.5681, Epoch Time 407.5982(413.5269), Bit/dim 3.7206(best: 3.7202), Xent 2.1322, Loss 4.7867, Error 0.3965(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2311 | Time 61.2227(61.8933) | Bit/dim 3.7054(3.7040) | Xent 0.1523(0.1592) | Loss 3.7815(3.7836) | Error 0.0517(0.0542) Steps 676(682.96) | Grad Norm 0.8932(1.2526) | Total Time 14.00(14.00)\n",
      "Iter 2312 | Time 61.8943(61.8933) | Bit/dim 3.6918(3.7037) | Xent 0.1463(0.1588) | Loss 3.7650(3.7831) | Error 0.0493(0.0540) Steps 676(682.75) | Grad Norm 0.9980(1.2450) | Total Time 14.00(14.00)\n",
      "Iter 2313 | Time 63.6446(61.9459) | Bit/dim 3.7059(3.7037) | Xent 0.1463(0.1584) | Loss 3.7791(3.7829) | Error 0.0491(0.0539) Steps 664(682.19) | Grad Norm 0.8854(1.2342) | Total Time 14.00(14.00)\n",
      "Iter 2314 | Time 64.6667(62.0275) | Bit/dim 3.7062(3.7038) | Xent 0.1503(0.1582) | Loss 3.7814(3.7829) | Error 0.0530(0.0539) Steps 682(682.18) | Grad Norm 1.2383(1.2343) | Total Time 14.00(14.00)\n",
      "Iter 2315 | Time 65.3182(62.1262) | Bit/dim 3.7159(3.7042) | Xent 0.1436(0.1578) | Loss 3.7877(3.7830) | Error 0.0484(0.0537) Steps 682(682.17) | Grad Norm 1.0447(1.2286) | Total Time 14.00(14.00)\n",
      "Iter 2316 | Time 59.9969(62.0623) | Bit/dim 3.6966(3.7039) | Xent 0.1580(0.1578) | Loss 3.7756(3.7828) | Error 0.0566(0.0538) Steps 688(682.35) | Grad Norm 0.9313(1.2197) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 25.4005, Epoch Time 417.9406(413.6593), Bit/dim 3.7213(best: 3.7202), Xent 2.1520, Loss 4.7973, Error 0.3961(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2317 | Time 62.6028(62.0785) | Bit/dim 3.6982(3.7038) | Xent 0.1542(0.1577) | Loss 3.7753(3.7826) | Error 0.0516(0.0537) Steps 694(682.70) | Grad Norm 1.6382(1.2323) | Total Time 14.00(14.00)\n",
      "Iter 2318 | Time 60.0474(62.0176) | Bit/dim 3.6972(3.7036) | Xent 0.1519(0.1575) | Loss 3.7731(3.7823) | Error 0.0493(0.0536) Steps 676(682.50) | Grad Norm 1.0053(1.2254) | Total Time 14.00(14.00)\n",
      "Iter 2319 | Time 60.7892(61.9808) | Bit/dim 3.7085(3.7037) | Xent 0.1493(0.1572) | Loss 3.7831(3.7823) | Error 0.0515(0.0535) Steps 682(682.48) | Grad Norm 0.9505(1.2172) | Total Time 14.00(14.00)\n",
      "Iter 2320 | Time 61.4393(61.9645) | Bit/dim 3.7105(3.7039) | Xent 0.1439(0.1568) | Loss 3.7825(3.7823) | Error 0.0506(0.0534) Steps 682(682.47) | Grad Norm 0.9174(1.2082) | Total Time 14.00(14.00)\n",
      "Iter 2321 | Time 60.2093(61.9119) | Bit/dim 3.6960(3.7037) | Xent 0.1567(0.1568) | Loss 3.7744(3.7821) | Error 0.0533(0.0534) Steps 670(682.09) | Grad Norm 0.8225(1.1966) | Total Time 14.00(14.00)\n",
      "Iter 2322 | Time 60.2398(61.8617) | Bit/dim 3.7069(3.7038) | Xent 0.1505(0.1566) | Loss 3.7822(3.7821) | Error 0.0527(0.0534) Steps 688(682.27) | Grad Norm 1.0461(1.1921) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 24.8910, Epoch Time 405.8415(413.4248), Bit/dim 3.7213(best: 3.7202), Xent 2.1686, Loss 4.8056, Error 0.3989(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2323 | Time 58.5472(61.7623) | Bit/dim 3.7006(3.7037) | Xent 0.1444(0.1563) | Loss 3.7728(3.7818) | Error 0.0503(0.0533) Steps 682(682.26) | Grad Norm 0.6898(1.1770) | Total Time 14.00(14.00)\n",
      "Iter 2324 | Time 61.6663(61.7594) | Bit/dim 3.7002(3.7036) | Xent 0.1505(0.1561) | Loss 3.7754(3.7816) | Error 0.0534(0.0533) Steps 682(682.26) | Grad Norm 0.8355(1.1668) | Total Time 14.00(14.00)\n",
      "Iter 2325 | Time 61.1398(61.7408) | Bit/dim 3.7105(3.7038) | Xent 0.1533(0.1560) | Loss 3.7872(3.7818) | Error 0.0530(0.0533) Steps 682(682.25) | Grad Norm 1.3668(1.1728) | Total Time 14.00(14.00)\n",
      "Iter 2326 | Time 61.9491(61.7470) | Bit/dim 3.7055(3.7038) | Xent 0.1577(0.1561) | Loss 3.7843(3.7819) | Error 0.0540(0.0533) Steps 682(682.24) | Grad Norm 1.0240(1.1683) | Total Time 14.00(14.00)\n",
      "Iter 2327 | Time 61.1451(61.7290) | Bit/dim 3.6981(3.7037) | Xent 0.1537(0.1560) | Loss 3.7749(3.7817) | Error 0.0497(0.0532) Steps 688(682.41) | Grad Norm 0.8446(1.1586) | Total Time 14.00(14.00)\n",
      "Iter 2328 | Time 62.4058(61.7493) | Bit/dim 3.7020(3.7036) | Xent 0.1468(0.1557) | Loss 3.7754(3.7815) | Error 0.0504(0.0531) Steps 688(682.58) | Grad Norm 1.1165(1.1574) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 25.2715, Epoch Time 408.1955(413.2679), Bit/dim 3.7207(best: 3.7202), Xent 2.1749, Loss 4.8082, Error 0.3981(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2329 | Time 59.1072(61.6700) | Bit/dim 3.6990(3.7035) | Xent 0.1503(0.1556) | Loss 3.7742(3.7813) | Error 0.0503(0.0531) Steps 694(682.92) | Grad Norm 1.3009(1.1617) | Total Time 14.00(14.00)\n",
      "Iter 2330 | Time 59.3020(61.5990) | Bit/dim 3.7070(3.7036) | Xent 0.1411(0.1551) | Loss 3.7775(3.7811) | Error 0.0470(0.0529) Steps 676(682.72) | Grad Norm 1.0216(1.1575) | Total Time 14.00(14.00)\n",
      "Iter 2331 | Time 60.5720(61.5682) | Bit/dim 3.7054(3.7036) | Xent 0.1438(0.1548) | Loss 3.7773(3.7810) | Error 0.0447(0.0526) Steps 676(682.51) | Grad Norm 0.7330(1.1447) | Total Time 14.00(14.00)\n",
      "Iter 2332 | Time 62.8626(61.6070) | Bit/dim 3.7035(3.7036) | Xent 0.1546(0.1548) | Loss 3.7809(3.7810) | Error 0.0535(0.0527) Steps 676(682.32) | Grad Norm 0.8757(1.1367) | Total Time 14.00(14.00)\n",
      "Iter 2333 | Time 60.9921(61.5886) | Bit/dim 3.6899(3.7032) | Xent 0.1527(0.1547) | Loss 3.7663(3.7806) | Error 0.0503(0.0526) Steps 688(682.49) | Grad Norm 1.1194(1.1361) | Total Time 14.00(14.00)\n",
      "Iter 2334 | Time 62.7060(61.6221) | Bit/dim 3.7139(3.7035) | Xent 0.1412(0.1543) | Loss 3.7845(3.7807) | Error 0.0495(0.0525) Steps 676(682.29) | Grad Norm 1.1639(1.1370) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 25.1167, Epoch Time 406.2560(413.0576), Bit/dim 3.7210(best: 3.7202), Xent 2.1597, Loss 4.8009, Error 0.4006(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2335 | Time 61.2097(61.6097) | Bit/dim 3.7015(3.7035) | Xent 0.1408(0.1539) | Loss 3.7719(3.7804) | Error 0.0493(0.0524) Steps 682(682.29) | Grad Norm 1.0497(1.1344) | Total Time 14.00(14.00)\n",
      "Iter 2336 | Time 61.2079(61.5977) | Bit/dim 3.7111(3.7037) | Xent 0.1439(0.1536) | Loss 3.7830(3.7805) | Error 0.0519(0.0524) Steps 688(682.46) | Grad Norm 1.1589(1.1351) | Total Time 14.00(14.00)\n",
      "Iter 2337 | Time 61.0812(61.5822) | Bit/dim 3.7117(3.7039) | Xent 0.1487(0.1535) | Loss 3.7861(3.7807) | Error 0.0480(0.0522) Steps 682(682.44) | Grad Norm 0.8027(1.1251) | Total Time 14.00(14.00)\n",
      "Iter 2338 | Time 60.9458(61.5631) | Bit/dim 3.6875(3.7034) | Xent 0.1474(0.1533) | Loss 3.7612(3.7801) | Error 0.0533(0.0523) Steps 694(682.79) | Grad Norm 0.8636(1.1173) | Total Time 14.00(14.00)\n",
      "Iter 2339 | Time 59.9481(61.5146) | Bit/dim 3.6942(3.7032) | Xent 0.1620(0.1535) | Loss 3.7751(3.7799) | Error 0.0549(0.0524) Steps 688(682.95) | Grad Norm 1.0645(1.1157) | Total Time 14.00(14.00)\n",
      "Iter 2340 | Time 60.8092(61.4935) | Bit/dim 3.7074(3.7033) | Xent 0.1440(0.1533) | Loss 3.7794(3.7799) | Error 0.0505(0.0523) Steps 676(682.74) | Grad Norm 1.1306(1.1161) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 25.3162, Epoch Time 406.4541(412.8595), Bit/dim 3.7203(best: 3.7202), Xent 2.1464, Loss 4.7934, Error 0.3986(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2341 | Time 61.7055(61.4998) | Bit/dim 3.7054(3.7034) | Xent 0.1450(0.1530) | Loss 3.7779(3.7799) | Error 0.0485(0.0522) Steps 700(683.26) | Grad Norm 0.8608(1.1085) | Total Time 14.00(14.00)\n",
      "Iter 2342 | Time 62.2953(61.5237) | Bit/dim 3.7024(3.7033) | Xent 0.1451(0.1528) | Loss 3.7749(3.7797) | Error 0.0470(0.0520) Steps 688(683.40) | Grad Norm 1.0525(1.1068) | Total Time 14.00(14.00)\n",
      "Iter 2343 | Time 59.6207(61.4666) | Bit/dim 3.6940(3.7031) | Xent 0.1494(0.1527) | Loss 3.7687(3.7794) | Error 0.0520(0.0520) Steps 688(683.54) | Grad Norm 1.2778(1.1119) | Total Time 14.00(14.00)\n",
      "Iter 2344 | Time 63.6983(61.5336) | Bit/dim 3.7016(3.7030) | Xent 0.1425(0.1524) | Loss 3.7729(3.7792) | Error 0.0505(0.0520) Steps 682(683.49) | Grad Norm 1.2827(1.1171) | Total Time 14.00(14.00)\n",
      "Iter 2345 | Time 60.2804(61.4960) | Bit/dim 3.7113(3.7033) | Xent 0.1422(0.1521) | Loss 3.7825(3.7793) | Error 0.0467(0.0518) Steps 676(683.27) | Grad Norm 1.1934(1.1193) | Total Time 14.00(14.00)\n",
      "Iter 2346 | Time 61.1239(61.4848) | Bit/dim 3.7035(3.7033) | Xent 0.1497(0.1520) | Loss 3.7783(3.7793) | Error 0.0510(0.0518) Steps 682(683.23) | Grad Norm 0.9284(1.1136) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 25.3687, Epoch Time 409.6663(412.7637), Bit/dim 3.7207(best: 3.7202), Xent 2.1674, Loss 4.8044, Error 0.4001(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2347 | Time 61.3906(61.4820) | Bit/dim 3.7105(3.7035) | Xent 0.1530(0.1520) | Loss 3.7869(3.7795) | Error 0.0527(0.0518) Steps 670(682.83) | Grad Norm 1.0606(1.1120) | Total Time 14.00(14.00)\n",
      "Iter 2348 | Time 61.7122(61.4889) | Bit/dim 3.6858(3.7029) | Xent 0.1361(0.1515) | Loss 3.7538(3.7787) | Error 0.0456(0.0516) Steps 694(683.17) | Grad Norm 0.6567(1.0984) | Total Time 14.00(14.00)\n",
      "Iter 2349 | Time 61.4938(61.4890) | Bit/dim 3.6988(3.7028) | Xent 0.1529(0.1516) | Loss 3.7753(3.7786) | Error 0.0497(0.0516) Steps 676(682.95) | Grad Norm 1.0792(1.0978) | Total Time 14.00(14.00)\n",
      "Iter 2350 | Time 60.9327(61.4723) | Bit/dim 3.7081(3.7030) | Xent 0.1451(0.1514) | Loss 3.7806(3.7787) | Error 0.0505(0.0516) Steps 688(683.10) | Grad Norm 1.1017(1.0979) | Total Time 14.00(14.00)\n",
      "Iter 2351 | Time 59.8289(61.4230) | Bit/dim 3.7053(3.7031) | Xent 0.1439(0.1512) | Loss 3.7772(3.7786) | Error 0.0476(0.0514) Steps 688(683.25) | Grad Norm 1.1723(1.1001) | Total Time 14.00(14.00)\n",
      "Iter 2352 | Time 62.7432(61.4626) | Bit/dim 3.7070(3.7032) | Xent 0.1444(0.1510) | Loss 3.7792(3.7787) | Error 0.0515(0.0514) Steps 700(683.75) | Grad Norm 0.8248(1.0919) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 25.2230, Epoch Time 408.9388(412.6489), Bit/dim 3.7210(best: 3.7202), Xent 2.1855, Loss 4.8137, Error 0.4014(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2353 | Time 60.3887(61.4304) | Bit/dim 3.7172(3.7036) | Xent 0.1448(0.1508) | Loss 3.7896(3.7790) | Error 0.0487(0.0514) Steps 676(683.52) | Grad Norm 0.8597(1.0849) | Total Time 14.00(14.00)\n",
      "Iter 2354 | Time 59.8686(61.3836) | Bit/dim 3.7039(3.7036) | Xent 0.1385(0.1504) | Loss 3.7732(3.7788) | Error 0.0463(0.0512) Steps 694(683.83) | Grad Norm 0.9420(1.0806) | Total Time 14.00(14.00)\n",
      "Iter 2355 | Time 62.8837(61.4286) | Bit/dim 3.6975(3.7034) | Xent 0.1543(0.1505) | Loss 3.7746(3.7787) | Error 0.0534(0.0513) Steps 688(683.96) | Grad Norm 1.2566(1.0859) | Total Time 14.00(14.00)\n",
      "Iter 2356 | Time 61.2576(61.4234) | Bit/dim 3.7000(3.7033) | Xent 0.1523(0.1506) | Loss 3.7761(3.7786) | Error 0.0504(0.0512) Steps 688(684.08) | Grad Norm 1.1678(1.0884) | Total Time 14.00(14.00)\n",
      "Iter 2357 | Time 60.7882(61.4044) | Bit/dim 3.6950(3.7031) | Xent 0.1467(0.1505) | Loss 3.7684(3.7783) | Error 0.0485(0.0512) Steps 688(684.20) | Grad Norm 1.1387(1.0899) | Total Time 14.00(14.00)\n",
      "Iter 2358 | Time 62.2087(61.4285) | Bit/dim 3.7031(3.7031) | Xent 0.1472(0.1504) | Loss 3.7766(3.7782) | Error 0.0529(0.0512) Steps 688(684.31) | Grad Norm 0.9879(1.0868) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 25.7447, Epoch Time 408.9509(412.5380), Bit/dim 3.7208(best: 3.7202), Xent 2.1552, Loss 4.7984, Error 0.3992(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2359 | Time 58.1980(61.3316) | Bit/dim 3.6973(3.7029) | Xent 0.1527(0.1504) | Loss 3.7737(3.7781) | Error 0.0510(0.0512) Steps 676(684.06) | Grad Norm 0.8187(1.0788) | Total Time 14.00(14.00)\n",
      "Iter 2360 | Time 62.0147(61.3521) | Bit/dim 3.7025(3.7029) | Xent 0.1415(0.1502) | Loss 3.7733(3.7780) | Error 0.0477(0.0511) Steps 688(684.18) | Grad Norm 0.9148(1.0739) | Total Time 14.00(14.00)\n",
      "Iter 2361 | Time 59.4854(61.2961) | Bit/dim 3.7037(3.7029) | Xent 0.1512(0.1502) | Loss 3.7793(3.7780) | Error 0.0510(0.0511) Steps 682(684.11) | Grad Norm 0.8193(1.0662) | Total Time 14.00(14.00)\n",
      "Iter 2362 | Time 61.3087(61.2965) | Bit/dim 3.7130(3.7032) | Xent 0.1520(0.1503) | Loss 3.7890(3.7783) | Error 0.0506(0.0511) Steps 682(684.05) | Grad Norm 0.9650(1.0632) | Total Time 14.00(14.00)\n",
      "Iter 2363 | Time 60.1099(61.2609) | Bit/dim 3.6973(3.7030) | Xent 0.1405(0.1500) | Loss 3.7675(3.7780) | Error 0.0473(0.0510) Steps 670(683.63) | Grad Norm 1.0488(1.0627) | Total Time 14.00(14.00)\n",
      "Iter 2364 | Time 63.0269(61.3138) | Bit/dim 3.7033(3.7030) | Xent 0.1397(0.1497) | Loss 3.7732(3.7779) | Error 0.0484(0.0509) Steps 694(683.94) | Grad Norm 0.9073(1.0581) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 25.0663, Epoch Time 405.0274(412.3127), Bit/dim 3.7209(best: 3.7202), Xent 2.1546, Loss 4.7982, Error 0.3979(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2365 | Time 60.8575(61.3002) | Bit/dim 3.7037(3.7031) | Xent 0.1508(0.1497) | Loss 3.7791(3.7779) | Error 0.0527(0.0509) Steps 682(683.88) | Grad Norm 1.0092(1.0566) | Total Time 14.00(14.00)\n",
      "Iter 2366 | Time 61.3330(61.3011) | Bit/dim 3.6926(3.7027) | Xent 0.1428(0.1495) | Loss 3.7639(3.7775) | Error 0.0494(0.0509) Steps 676(683.65) | Grad Norm 1.1662(1.0599) | Total Time 14.00(14.00)\n",
      "Iter 2367 | Time 60.6873(61.2827) | Bit/dim 3.6966(3.7026) | Xent 0.1473(0.1494) | Loss 3.7702(3.7773) | Error 0.0501(0.0509) Steps 676(683.42) | Grad Norm 0.9002(1.0551) | Total Time 14.00(14.00)\n",
      "Iter 2368 | Time 61.3787(61.2856) | Bit/dim 3.6964(3.7024) | Xent 0.1452(0.1493) | Loss 3.7690(3.7770) | Error 0.0476(0.0508) Steps 676(683.19) | Grad Norm 1.1542(1.0581) | Total Time 14.00(14.00)\n",
      "Iter 2369 | Time 60.1322(61.2510) | Bit/dim 3.7175(3.7028) | Xent 0.1480(0.1492) | Loss 3.7915(3.7775) | Error 0.0525(0.0508) Steps 682(683.16) | Grad Norm 0.7805(1.0498) | Total Time 14.00(14.00)\n",
      "Iter 2370 | Time 60.9045(61.2406) | Bit/dim 3.7079(3.7030) | Xent 0.1342(0.1488) | Loss 3.7750(3.7774) | Error 0.0451(0.0507) Steps 676(682.94) | Grad Norm 0.6921(1.0390) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 25.1940, Epoch Time 406.2483(412.1307), Bit/dim 3.7212(best: 3.7202), Xent 2.1795, Loss 4.8109, Error 0.3994(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2371 | Time 61.4688(61.2475) | Bit/dim 3.7020(3.7030) | Xent 0.1353(0.1484) | Loss 3.7697(3.7771) | Error 0.0460(0.0505) Steps 682(682.92) | Grad Norm 0.9017(1.0349) | Total Time 14.00(14.00)\n",
      "Iter 2372 | Time 60.9005(61.2370) | Bit/dim 3.6992(3.7028) | Xent 0.1526(0.1485) | Loss 3.7755(3.7771) | Error 0.0520(0.0506) Steps 688(683.07) | Grad Norm 1.1230(1.0375) | Total Time 14.00(14.00)\n",
      "Iter 2373 | Time 63.7105(61.3112) | Bit/dim 3.7019(3.7028) | Xent 0.1354(0.1481) | Loss 3.7696(3.7769) | Error 0.0435(0.0504) Steps 682(683.04) | Grad Norm 1.2059(1.0426) | Total Time 14.00(14.00)\n",
      "Iter 2374 | Time 60.4421(61.2852) | Bit/dim 3.7083(3.7030) | Xent 0.1462(0.1481) | Loss 3.7813(3.7770) | Error 0.0494(0.0503) Steps 676(682.82) | Grad Norm 0.9478(1.0398) | Total Time 14.00(14.00)\n",
      "Iter 2375 | Time 61.6395(61.2958) | Bit/dim 3.7126(3.7033) | Xent 0.1475(0.1480) | Loss 3.7864(3.7773) | Error 0.0497(0.0503) Steps 676(682.62) | Grad Norm 0.9692(1.0376) | Total Time 14.00(14.00)\n",
      "Iter 2376 | Time 60.7660(61.2799) | Bit/dim 3.6927(3.7029) | Xent 0.1480(0.1480) | Loss 3.7667(3.7770) | Error 0.0530(0.0504) Steps 682(682.60) | Grad Norm 0.9664(1.0355) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 25.5412, Epoch Time 410.1285(412.0707), Bit/dim 3.7209(best: 3.7202), Xent 2.2081, Loss 4.8249, Error 0.4015(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2377 | Time 59.7220(61.2332) | Bit/dim 3.6912(3.7026) | Xent 0.1390(0.1478) | Loss 3.7607(3.7765) | Error 0.0484(0.0503) Steps 688(682.76) | Grad Norm 0.7014(1.0255) | Total Time 14.00(14.00)\n",
      "Iter 2378 | Time 61.2417(61.2334) | Bit/dim 3.7074(3.7027) | Xent 0.1433(0.1476) | Loss 3.7790(3.7766) | Error 0.0483(0.0503) Steps 682(682.74) | Grad Norm 0.7402(1.0169) | Total Time 14.00(14.00)\n",
      "Iter 2379 | Time 63.2933(61.2952) | Bit/dim 3.7047(3.7028) | Xent 0.1414(0.1475) | Loss 3.7754(3.7765) | Error 0.0513(0.0503) Steps 694(683.08) | Grad Norm 0.8967(1.0133) | Total Time 14.00(14.00)\n",
      "Iter 2380 | Time 59.6800(61.2468) | Bit/dim 3.7013(3.7028) | Xent 0.1414(0.1473) | Loss 3.7720(3.7764) | Error 0.0487(0.0502) Steps 688(683.23) | Grad Norm 0.7955(1.0068) | Total Time 14.00(14.00)\n",
      "Iter 2381 | Time 61.1751(61.2446) | Bit/dim 3.7017(3.7027) | Xent 0.1458(0.1472) | Loss 3.7747(3.7763) | Error 0.0463(0.0501) Steps 682(683.19) | Grad Norm 0.6608(0.9964) | Total Time 14.00(14.00)\n",
      "Iter 2382 | Time 61.0040(61.2374) | Bit/dim 3.7028(3.7027) | Xent 0.1432(0.1471) | Loss 3.7744(3.7763) | Error 0.0477(0.0501) Steps 676(682.97) | Grad Norm 0.9161(0.9940) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 25.2043, Epoch Time 406.8527(411.9141), Bit/dim 3.7216(best: 3.7202), Xent 2.2023, Loss 4.8227, Error 0.4005(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2383 | Time 61.4096(61.2426) | Bit/dim 3.7018(3.7027) | Xent 0.1516(0.1472) | Loss 3.7777(3.7763) | Error 0.0496(0.0500) Steps 682(682.94) | Grad Norm 0.9935(0.9940) | Total Time 14.00(14.00)\n",
      "Iter 2384 | Time 61.7729(61.2585) | Bit/dim 3.7146(3.7031) | Xent 0.1367(0.1469) | Loss 3.7830(3.7765) | Error 0.0476(0.0500) Steps 676(682.74) | Grad Norm 0.7867(0.9878) | Total Time 14.00(14.00)\n",
      "Iter 2385 | Time 60.5155(61.2362) | Bit/dim 3.6969(3.7029) | Xent 0.1561(0.1472) | Loss 3.7750(3.7765) | Error 0.0534(0.0501) Steps 682(682.71) | Grad Norm 0.8925(0.9849) | Total Time 14.00(14.00)\n",
      "Iter 2386 | Time 60.9068(61.2263) | Bit/dim 3.6948(3.7026) | Xent 0.1364(0.1469) | Loss 3.7630(3.7761) | Error 0.0469(0.0500) Steps 670(682.33) | Grad Norm 0.8710(0.9815) | Total Time 14.00(14.00)\n",
      "Iter 2387 | Time 61.2544(61.2272) | Bit/dim 3.7012(3.7026) | Xent 0.1445(0.1468) | Loss 3.7734(3.7760) | Error 0.0483(0.0499) Steps 688(682.50) | Grad Norm 0.8298(0.9769) | Total Time 14.00(14.00)\n",
      "Iter 2388 | Time 62.1433(61.2546) | Bit/dim 3.6989(3.7025) | Xent 0.1399(0.1466) | Loss 3.7689(3.7758) | Error 0.0443(0.0498) Steps 682(682.49) | Grad Norm 0.7765(0.9709) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 25.3284, Epoch Time 409.4219(411.8394), Bit/dim 3.7203(best: 3.7202), Xent 2.1753, Loss 4.8079, Error 0.3996(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2389 | Time 61.3140(61.2564) | Bit/dim 3.7032(3.7025) | Xent 0.1423(0.1465) | Loss 3.7744(3.7757) | Error 0.0499(0.0498) Steps 700(683.01) | Grad Norm 0.9081(0.9690) | Total Time 14.00(14.00)\n",
      "Iter 2390 | Time 60.8821(61.2452) | Bit/dim 3.7084(3.7027) | Xent 0.1504(0.1466) | Loss 3.7836(3.7760) | Error 0.0507(0.0498) Steps 676(682.80) | Grad Norm 0.9428(0.9682) | Total Time 14.00(14.00)\n",
      "Iter 2391 | Time 62.6005(61.2858) | Bit/dim 3.6983(3.7025) | Xent 0.1525(0.1468) | Loss 3.7745(3.7759) | Error 0.0516(0.0498) Steps 688(682.96) | Grad Norm 0.7814(0.9626) | Total Time 14.00(14.00)\n",
      "Iter 2392 | Time 62.9063(61.3345) | Bit/dim 3.7004(3.7025) | Xent 0.1427(0.1466) | Loss 3.7718(3.7758) | Error 0.0495(0.0498) Steps 688(683.11) | Grad Norm 1.0543(0.9654) | Total Time 14.00(14.00)\n",
      "Iter 2393 | Time 61.7523(61.3470) | Bit/dim 3.6846(3.7019) | Xent 0.1531(0.1468) | Loss 3.7612(3.7754) | Error 0.0520(0.0499) Steps 694(683.44) | Grad Norm 1.2965(0.9753) | Total Time 14.00(14.00)\n",
      "Iter 2394 | Time 63.7111(61.4179) | Bit/dim 3.7143(3.7023) | Xent 0.1548(0.1471) | Loss 3.7917(3.7759) | Error 0.0554(0.0501) Steps 676(683.21) | Grad Norm 1.1805(0.9815) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 25.3806, Epoch Time 414.1969(411.9101), Bit/dim 3.7214(best: 3.7202), Xent 2.1816, Loss 4.8122, Error 0.4009(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2395 | Time 62.4994(61.4504) | Bit/dim 3.7080(3.7025) | Xent 0.1509(0.1472) | Loss 3.7834(3.7761) | Error 0.0531(0.0502) Steps 682(683.18) | Grad Norm 0.7833(0.9755) | Total Time 14.00(14.00)\n",
      "Iter 2396 | Time 61.9022(61.4639) | Bit/dim 3.7071(3.7026) | Xent 0.1439(0.1471) | Loss 3.7791(3.7762) | Error 0.0483(0.0501) Steps 676(682.96) | Grad Norm 1.0973(0.9792) | Total Time 14.00(14.00)\n",
      "Iter 2397 | Time 61.1054(61.4532) | Bit/dim 3.6909(3.7023) | Xent 0.1388(0.1468) | Loss 3.7602(3.7757) | Error 0.0490(0.0501) Steps 670(682.57) | Grad Norm 1.5467(0.9962) | Total Time 14.00(14.00)\n",
      "Iter 2398 | Time 63.0671(61.5016) | Bit/dim 3.6990(3.7022) | Xent 0.1464(0.1468) | Loss 3.7723(3.7756) | Error 0.0506(0.0501) Steps 694(682.92) | Grad Norm 1.4437(1.0096) | Total Time 14.00(14.00)\n",
      "Iter 2399 | Time 62.8428(61.5418) | Bit/dim 3.7005(3.7021) | Xent 0.1466(0.1468) | Loss 3.7738(3.7755) | Error 0.0514(0.0501) Steps 694(683.25) | Grad Norm 0.8137(1.0038) | Total Time 14.00(14.00)\n",
      "Iter 2400 | Time 62.0826(61.5580) | Bit/dim 3.7070(3.7023) | Xent 0.1497(0.1469) | Loss 3.7818(3.7757) | Error 0.0507(0.0501) Steps 676(683.03) | Grad Norm 1.2165(1.0101) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 25.6662, Epoch Time 414.9254(412.0006), Bit/dim 3.7198(best: 3.7202), Xent 2.1987, Loss 4.8192, Error 0.4029(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2401 | Time 59.3213(61.4909) | Bit/dim 3.7032(3.7023) | Xent 0.1369(0.1466) | Loss 3.7717(3.7756) | Error 0.0451(0.0500) Steps 682(683.00) | Grad Norm 1.4064(1.0220) | Total Time 14.00(14.00)\n",
      "Iter 2402 | Time 62.4705(61.5203) | Bit/dim 3.6964(3.7021) | Xent 0.1511(0.1467) | Loss 3.7719(3.7755) | Error 0.0481(0.0499) Steps 682(682.97) | Grad Norm 1.4278(1.0342) | Total Time 14.00(14.00)\n",
      "Iter 2403 | Time 60.4118(61.4871) | Bit/dim 3.7068(3.7023) | Xent 0.1462(0.1467) | Loss 3.7799(3.7756) | Error 0.0514(0.0500) Steps 682(682.94) | Grad Norm 1.0141(1.0336) | Total Time 14.00(14.00)\n",
      "Iter 2404 | Time 63.0835(61.5350) | Bit/dim 3.6986(3.7021) | Xent 0.1433(0.1466) | Loss 3.7702(3.7755) | Error 0.0486(0.0499) Steps 694(683.27) | Grad Norm 1.0176(1.0331) | Total Time 14.00(14.00)\n",
      "Iter 2405 | Time 60.5108(61.5042) | Bit/dim 3.7053(3.7022) | Xent 0.1450(0.1466) | Loss 3.7779(3.7755) | Error 0.0483(0.0499) Steps 688(683.41) | Grad Norm 0.9251(1.0299) | Total Time 14.00(14.00)\n",
      "Iter 2406 | Time 64.3022(61.5882) | Bit/dim 3.7009(3.7022) | Xent 0.1423(0.1464) | Loss 3.7721(3.7754) | Error 0.0473(0.0498) Steps 694(683.73) | Grad Norm 1.2801(1.0374) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 25.5160, Epoch Time 411.7098(411.9918), Bit/dim 3.7196(best: 3.7198), Xent 2.1946, Loss 4.8169, Error 0.4032(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2407 | Time 62.5119(61.6159) | Bit/dim 3.7100(3.7024) | Xent 0.1487(0.1465) | Loss 3.7844(3.7757) | Error 0.0507(0.0498) Steps 682(683.68) | Grad Norm 1.2429(1.0436) | Total Time 14.00(14.00)\n",
      "Iter 2408 | Time 62.0915(61.6302) | Bit/dim 3.6944(3.7022) | Xent 0.1464(0.1465) | Loss 3.7675(3.7755) | Error 0.0494(0.0498) Steps 676(683.45) | Grad Norm 0.9671(1.0413) | Total Time 14.00(14.00)\n",
      "Iter 2409 | Time 60.6794(61.6016) | Bit/dim 3.6922(3.7019) | Xent 0.1487(0.1466) | Loss 3.7665(3.7752) | Error 0.0500(0.0498) Steps 688(683.59) | Grad Norm 1.1811(1.0455) | Total Time 14.00(14.00)\n",
      "Iter 2410 | Time 60.9876(61.5832) | Bit/dim 3.7115(3.7022) | Xent 0.1454(0.1465) | Loss 3.7842(3.7755) | Error 0.0506(0.0498) Steps 676(683.36) | Grad Norm 1.1953(1.0500) | Total Time 14.00(14.00)\n",
      "Iter 2411 | Time 61.4155(61.5782) | Bit/dim 3.7027(3.7022) | Xent 0.1416(0.1464) | Loss 3.7734(3.7754) | Error 0.0475(0.0498) Steps 688(683.50) | Grad Norm 1.7414(1.0707) | Total Time 14.00(14.00)\n",
      "Iter 2412 | Time 63.1695(61.6259) | Bit/dim 3.7017(3.7022) | Xent 0.1441(0.1463) | Loss 3.7738(3.7753) | Error 0.0481(0.0497) Steps 682(683.45) | Grad Norm 1.2353(1.0756) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 25.1239, Epoch Time 411.9073(411.9893), Bit/dim 3.7214(best: 3.7196), Xent 2.2079, Loss 4.8254, Error 0.3967(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2413 | Time 57.3173(61.4967) | Bit/dim 3.7036(3.7022) | Xent 0.1390(0.1461) | Loss 3.7731(3.7753) | Error 0.0466(0.0496) Steps 676(683.23) | Grad Norm 0.8038(1.0675) | Total Time 14.00(14.00)\n",
      "Iter 2414 | Time 62.0608(61.5136) | Bit/dim 3.6971(3.7021) | Xent 0.1515(0.1463) | Loss 3.7729(3.7752) | Error 0.0507(0.0497) Steps 682(683.19) | Grad Norm 0.7965(1.0593) | Total Time 14.00(14.00)\n",
      "Iter 2415 | Time 61.1135(61.5016) | Bit/dim 3.7081(3.7023) | Xent 0.1415(0.1461) | Loss 3.7789(3.7753) | Error 0.0493(0.0497) Steps 688(683.34) | Grad Norm 0.9108(1.0549) | Total Time 14.00(14.00)\n",
      "Iter 2416 | Time 62.4976(61.5315) | Bit/dim 3.6990(3.7022) | Xent 0.1406(0.1460) | Loss 3.7693(3.7751) | Error 0.0484(0.0496) Steps 682(683.30) | Grad Norm 0.9465(1.0516) | Total Time 14.00(14.00)\n",
      "Iter 2417 | Time 60.3180(61.4951) | Bit/dim 3.7015(3.7021) | Xent 0.1368(0.1457) | Loss 3.7699(3.7750) | Error 0.0471(0.0495) Steps 688(683.44) | Grad Norm 1.4996(1.0651) | Total Time 14.00(14.00)\n",
      "Iter 2418 | Time 63.2854(61.5488) | Bit/dim 3.6971(3.7020) | Xent 0.1362(0.1454) | Loss 3.7652(3.7747) | Error 0.0477(0.0495) Steps 676(683.21) | Grad Norm 1.1186(1.0667) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 25.1103, Epoch Time 407.7678(411.8626), Bit/dim 3.7216(best: 3.7196), Xent 2.2279, Loss 4.8356, Error 0.4020(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2419 | Time 60.0586(61.5041) | Bit/dim 3.7075(3.7022) | Xent 0.1415(0.1453) | Loss 3.7782(3.7748) | Error 0.0476(0.0494) Steps 688(683.36) | Grad Norm 1.0619(1.0665) | Total Time 14.00(14.00)\n",
      "Iter 2420 | Time 61.7007(61.5100) | Bit/dim 3.6955(3.7020) | Xent 0.1367(0.1450) | Loss 3.7638(3.7745) | Error 0.0457(0.0493) Steps 688(683.50) | Grad Norm 0.7245(1.0563) | Total Time 14.00(14.00)\n",
      "Iter 2421 | Time 61.8087(61.5189) | Bit/dim 3.7002(3.7019) | Xent 0.1330(0.1447) | Loss 3.7667(3.7742) | Error 0.0431(0.0491) Steps 688(683.63) | Grad Norm 1.2335(1.0616) | Total Time 14.00(14.00)\n",
      "Iter 2422 | Time 63.8979(61.5903) | Bit/dim 3.7019(3.7019) | Xent 0.1382(0.1445) | Loss 3.7710(3.7741) | Error 0.0476(0.0491) Steps 694(683.94) | Grad Norm 1.0886(1.0624) | Total Time 14.00(14.00)\n",
      "Iter 2423 | Time 61.4170(61.5851) | Bit/dim 3.6940(3.7017) | Xent 0.1483(0.1446) | Loss 3.7681(3.7740) | Error 0.0534(0.0492) Steps 694(684.25) | Grad Norm 0.9904(1.0602) | Total Time 14.00(14.00)\n",
      "Iter 2424 | Time 63.3806(61.6390) | Bit/dim 3.7115(3.7020) | Xent 0.1489(0.1447) | Loss 3.7860(3.7743) | Error 0.0491(0.0492) Steps 706(684.90) | Grad Norm 1.1427(1.0627) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 25.3224, Epoch Time 413.3294(411.9067), Bit/dim 3.7208(best: 3.7196), Xent 2.2020, Loss 4.8218, Error 0.4029(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2425 | Time 59.9917(61.5895) | Bit/dim 3.7153(3.7024) | Xent 0.1374(0.1445) | Loss 3.7840(3.7746) | Error 0.0449(0.0491) Steps 682(684.81) | Grad Norm 0.8177(1.0554) | Total Time 14.00(14.00)\n",
      "Iter 2426 | Time 60.4617(61.5557) | Bit/dim 3.6917(3.7020) | Xent 0.1359(0.1442) | Loss 3.7597(3.7742) | Error 0.0454(0.0490) Steps 694(685.09) | Grad Norm 1.3495(1.0642) | Total Time 14.00(14.00)\n",
      "Iter 2427 | Time 61.4915(61.5538) | Bit/dim 3.6984(3.7019) | Xent 0.1510(0.1444) | Loss 3.7739(3.7741) | Error 0.0526(0.0491) Steps 682(684.99) | Grad Norm 1.1218(1.0659) | Total Time 14.00(14.00)\n",
      "Iter 2428 | Time 62.7245(61.5889) | Bit/dim 3.6978(3.7018) | Xent 0.1475(0.1445) | Loss 3.7715(3.7741) | Error 0.0496(0.0491) Steps 688(685.08) | Grad Norm 0.8510(1.0595) | Total Time 14.00(14.00)\n",
      "Iter 2429 | Time 60.9904(61.5709) | Bit/dim 3.7140(3.7022) | Xent 0.1456(0.1446) | Loss 3.7868(3.7744) | Error 0.0493(0.0491) Steps 706(685.71) | Grad Norm 0.9531(1.0563) | Total Time 14.00(14.00)\n",
      "Iter 2430 | Time 59.9470(61.5222) | Bit/dim 3.6963(3.7020) | Xent 0.1427(0.1445) | Loss 3.7676(3.7742) | Error 0.0496(0.0491) Steps 682(685.60) | Grad Norm 1.2416(1.0618) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 25.6989, Epoch Time 407.1567(411.7642), Bit/dim 3.7209(best: 3.7196), Xent 2.2080, Loss 4.8249, Error 0.3998(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2431 | Time 61.9697(61.5357) | Bit/dim 3.7084(3.7022) | Xent 0.1391(0.1443) | Loss 3.7779(3.7744) | Error 0.0500(0.0491) Steps 688(685.67) | Grad Norm 1.2084(1.0662) | Total Time 14.00(14.00)\n",
      "Iter 2432 | Time 60.0325(61.4906) | Bit/dim 3.6960(3.7020) | Xent 0.1452(0.1444) | Loss 3.7685(3.7742) | Error 0.0497(0.0492) Steps 682(685.56) | Grad Norm 1.0295(1.0651) | Total Time 14.00(14.00)\n",
      "Iter 2433 | Time 63.8435(61.5611) | Bit/dim 3.7063(3.7021) | Xent 0.1379(0.1442) | Loss 3.7753(3.7742) | Error 0.0476(0.0491) Steps 676(685.28) | Grad Norm 1.0937(1.0660) | Total Time 14.00(14.00)\n",
      "Iter 2434 | Time 59.7468(61.5067) | Bit/dim 3.7027(3.7021) | Xent 0.1513(0.1444) | Loss 3.7783(3.7743) | Error 0.0505(0.0492) Steps 676(685.00) | Grad Norm 1.3145(1.0734) | Total Time 14.00(14.00)\n",
      "Iter 2435 | Time 60.1114(61.4649) | Bit/dim 3.6917(3.7018) | Xent 0.1480(0.1445) | Loss 3.7657(3.7741) | Error 0.0493(0.0492) Steps 676(684.73) | Grad Norm 1.0567(1.0729) | Total Time 14.00(14.00)\n",
      "Iter 2436 | Time 60.6306(61.4398) | Bit/dim 3.7068(3.7020) | Xent 0.1485(0.1446) | Loss 3.7811(3.7743) | Error 0.0506(0.0492) Steps 676(684.47) | Grad Norm 0.8904(1.0675) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 25.4636, Epoch Time 407.5850(411.6388), Bit/dim 3.7196(best: 3.7196), Xent 2.2248, Loss 4.8320, Error 0.4021(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2437 | Time 59.4873(61.3813) | Bit/dim 3.7026(3.7020) | Xent 0.1363(0.1444) | Loss 3.7707(3.7742) | Error 0.0451(0.0491) Steps 688(684.57) | Grad Norm 0.7870(1.0591) | Total Time 14.00(14.00)\n",
      "Iter 2438 | Time 60.7586(61.3626) | Bit/dim 3.7023(3.7020) | Xent 0.1531(0.1446) | Loss 3.7788(3.7743) | Error 0.0503(0.0491) Steps 682(684.49) | Grad Norm 1.6276(1.0761) | Total Time 14.00(14.00)\n",
      "Iter 2439 | Time 61.7604(61.3745) | Bit/dim 3.6964(3.7018) | Xent 0.1356(0.1444) | Loss 3.7642(3.7740) | Error 0.0451(0.0490) Steps 676(684.24) | Grad Norm 0.7961(1.0677) | Total Time 14.00(14.00)\n",
      "Iter 2440 | Time 62.7354(61.4153) | Bit/dim 3.6912(3.7015) | Xent 0.1410(0.1443) | Loss 3.7617(3.7736) | Error 0.0469(0.0489) Steps 682(684.17) | Grad Norm 0.7426(1.0580) | Total Time 14.00(14.00)\n",
      "Iter 2441 | Time 62.5716(61.4500) | Bit/dim 3.7157(3.7019) | Xent 0.1384(0.1441) | Loss 3.7849(3.7740) | Error 0.0455(0.0488) Steps 682(684.11) | Grad Norm 1.2851(1.0648) | Total Time 14.00(14.00)\n",
      "Iter 2442 | Time 61.8425(61.4618) | Bit/dim 3.6976(3.7018) | Xent 0.1367(0.1439) | Loss 3.7660(3.7737) | Error 0.0463(0.0488) Steps 694(684.40) | Grad Norm 0.8148(1.0573) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 25.2974, Epoch Time 410.4034(411.6017), Bit/dim 3.7205(best: 3.7196), Xent 2.2443, Loss 4.8426, Error 0.4020(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2443 | Time 60.9778(61.4473) | Bit/dim 3.6960(3.7016) | Xent 0.1430(0.1438) | Loss 3.7675(3.7736) | Error 0.0474(0.0487) Steps 682(684.33) | Grad Norm 0.9239(1.0533) | Total Time 14.00(14.00)\n",
      "Iter 2444 | Time 64.4542(61.5375) | Bit/dim 3.7091(3.7019) | Xent 0.1382(0.1437) | Loss 3.7782(3.7737) | Error 0.0441(0.0486) Steps 688(684.44) | Grad Norm 0.9714(1.0508) | Total Time 14.00(14.00)\n",
      "Iter 2445 | Time 62.0729(61.5535) | Bit/dim 3.7033(3.7019) | Xent 0.1432(0.1436) | Loss 3.7749(3.7737) | Error 0.0484(0.0486) Steps 676(684.19) | Grad Norm 0.8475(1.0447) | Total Time 14.00(14.00)\n",
      "Iter 2446 | Time 60.3998(61.5189) | Bit/dim 3.7017(3.7019) | Xent 0.1407(0.1436) | Loss 3.7721(3.7737) | Error 0.0471(0.0485) Steps 682(684.12) | Grad Norm 1.1022(1.0464) | Total Time 14.00(14.00)\n",
      "Iter 2447 | Time 62.3491(61.5438) | Bit/dim 3.6992(3.7018) | Xent 0.1424(0.1435) | Loss 3.7704(3.7736) | Error 0.0485(0.0485) Steps 682(684.06) | Grad Norm 1.2940(1.0539) | Total Time 14.00(14.00)\n",
      "Iter 2448 | Time 58.5136(61.4529) | Bit/dim 3.7034(3.7019) | Xent 0.1427(0.1435) | Loss 3.7747(3.7736) | Error 0.0481(0.0485) Steps 682(684.00) | Grad Norm 1.1968(1.0582) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 25.5718, Epoch Time 410.0151(411.5541), Bit/dim 3.7207(best: 3.7196), Xent 2.2184, Loss 4.8299, Error 0.4014(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2449 | Time 59.8920(61.4061) | Bit/dim 3.6988(3.7018) | Xent 0.1467(0.1436) | Loss 3.7721(3.7736) | Error 0.0509(0.0486) Steps 694(684.30) | Grad Norm 1.0343(1.0574) | Total Time 14.00(14.00)\n",
      "Iter 2450 | Time 61.2654(61.4019) | Bit/dim 3.7078(3.7020) | Xent 0.1341(0.1433) | Loss 3.7749(3.7736) | Error 0.0450(0.0485) Steps 688(684.41) | Grad Norm 0.8738(1.0519) | Total Time 14.00(14.00)\n",
      "Iter 2451 | Time 62.8863(61.4464) | Bit/dim 3.6949(3.7017) | Xent 0.1428(0.1433) | Loss 3.7663(3.7734) | Error 0.0477(0.0485) Steps 676(684.16) | Grad Norm 0.9842(1.0499) | Total Time 14.00(14.00)\n",
      "Iter 2452 | Time 61.7564(61.4557) | Bit/dim 3.7059(3.7019) | Xent 0.1411(0.1432) | Loss 3.7764(3.7735) | Error 0.0463(0.0484) Steps 688(684.27) | Grad Norm 0.8272(1.0432) | Total Time 14.00(14.00)\n",
      "Iter 2453 | Time 62.5100(61.4873) | Bit/dim 3.6950(3.7017) | Xent 0.1370(0.1430) | Loss 3.7635(3.7732) | Error 0.0467(0.0483) Steps 688(684.38) | Grad Norm 0.9426(1.0402) | Total Time 14.00(14.00)\n",
      "Iter 2454 | Time 61.3458(61.4831) | Bit/dim 3.7042(3.7017) | Xent 0.1388(0.1429) | Loss 3.7737(3.7732) | Error 0.0473(0.0483) Steps 694(684.67) | Grad Norm 0.8066(1.0332) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 25.5875, Epoch Time 411.1696(411.5426), Bit/dim 3.7216(best: 3.7196), Xent 2.2113, Loss 4.8272, Error 0.3990(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2455 | Time 59.4214(61.4212) | Bit/dim 3.7080(3.7019) | Xent 0.1355(0.1427) | Loss 3.7758(3.7733) | Error 0.0453(0.0482) Steps 676(684.41) | Grad Norm 1.0821(1.0347) | Total Time 14.00(14.00)\n",
      "Iter 2456 | Time 61.7322(61.4306) | Bit/dim 3.6966(3.7018) | Xent 0.1440(0.1427) | Loss 3.7686(3.7731) | Error 0.0484(0.0482) Steps 670(683.98) | Grad Norm 0.8009(1.0276) | Total Time 14.00(14.00)\n",
      "Iter 2457 | Time 63.5555(61.4943) | Bit/dim 3.7023(3.7018) | Xent 0.1370(0.1426) | Loss 3.7708(3.7731) | Error 0.0434(0.0481) Steps 682(683.92) | Grad Norm 0.9638(1.0257) | Total Time 14.00(14.00)\n",
      "Iter 2458 | Time 60.6458(61.4689) | Bit/dim 3.7021(3.7018) | Xent 0.1366(0.1424) | Loss 3.7704(3.7730) | Error 0.0463(0.0480) Steps 688(684.04) | Grad Norm 1.6061(1.0431) | Total Time 14.00(14.00)\n",
      "Iter 2459 | Time 61.5827(61.4723) | Bit/dim 3.7007(3.7018) | Xent 0.1494(0.1426) | Loss 3.7754(3.7731) | Error 0.0481(0.0480) Steps 682(683.98) | Grad Norm 1.1975(1.0478) | Total Time 14.00(14.00)\n",
      "Iter 2460 | Time 62.2886(61.4968) | Bit/dim 3.6946(3.7015) | Xent 0.1418(0.1426) | Loss 3.7655(3.7728) | Error 0.0485(0.0480) Steps 688(684.10) | Grad Norm 0.7197(1.0379) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 25.4418, Epoch Time 410.3063(411.5055), Bit/dim 3.7206(best: 3.7196), Xent 2.2302, Loss 4.8357, Error 0.4015(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2461 | Time 60.2552(61.4595) | Bit/dim 3.7138(3.7019) | Xent 0.1522(0.1429) | Loss 3.7899(3.7733) | Error 0.0529(0.0482) Steps 676(683.86) | Grad Norm 0.8598(1.0326) | Total Time 14.00(14.00)\n",
      "Iter 2462 | Time 63.6768(61.5260) | Bit/dim 3.7007(3.7019) | Xent 0.1483(0.1430) | Loss 3.7748(3.7734) | Error 0.0507(0.0483) Steps 682(683.80) | Grad Norm 1.5574(1.0483) | Total Time 14.00(14.00)\n",
      "Iter 2463 | Time 60.4063(61.4924) | Bit/dim 3.6943(3.7016) | Xent 0.1397(0.1429) | Loss 3.7642(3.7731) | Error 0.0479(0.0482) Steps 694(684.11) | Grad Norm 1.4486(1.0603) | Total Time 14.00(14.00)\n",
      "Iter 2464 | Time 60.7590(61.4704) | Bit/dim 3.6919(3.7014) | Xent 0.1415(0.1429) | Loss 3.7626(3.7728) | Error 0.0481(0.0482) Steps 676(683.87) | Grad Norm 0.7147(1.0500) | Total Time 14.00(14.00)\n",
      "Iter 2465 | Time 60.9646(61.4553) | Bit/dim 3.7032(3.7014) | Xent 0.1465(0.1430) | Loss 3.7764(3.7729) | Error 0.0491(0.0483) Steps 688(683.99) | Grad Norm 1.1085(1.0517) | Total Time 14.00(14.00)\n",
      "Iter 2466 | Time 60.4996(61.4266) | Bit/dim 3.7002(3.7014) | Xent 0.1338(0.1427) | Loss 3.7671(3.7727) | Error 0.0457(0.0482) Steps 688(684.11) | Grad Norm 0.9165(1.0477) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 25.3377, Epoch Time 407.6596(411.3901), Bit/dim 3.7206(best: 3.7196), Xent 2.2106, Loss 4.8259, Error 0.4006(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2467 | Time 59.4099(61.3661) | Bit/dim 3.6928(3.7011) | Xent 0.1554(0.1431) | Loss 3.7705(3.7727) | Error 0.0505(0.0483) Steps 676(683.87) | Grad Norm 0.7783(1.0396) | Total Time 14.00(14.00)\n",
      "Iter 2468 | Time 61.9898(61.3848) | Bit/dim 3.6954(3.7009) | Xent 0.1484(0.1433) | Loss 3.7696(3.7726) | Error 0.0504(0.0483) Steps 688(683.99) | Grad Norm 1.6501(1.0579) | Total Time 14.00(14.00)\n",
      "Iter 2469 | Time 60.4241(61.3560) | Bit/dim 3.7139(3.7013) | Xent 0.1393(0.1431) | Loss 3.7835(3.7729) | Error 0.0466(0.0483) Steps 688(684.11) | Grad Norm 1.0698(1.0583) | Total Time 14.00(14.00)\n",
      "Iter 2470 | Time 62.0465(61.3767) | Bit/dim 3.6939(3.7011) | Xent 0.1374(0.1430) | Loss 3.7626(3.7726) | Error 0.0491(0.0483) Steps 682(684.05) | Grad Norm 1.0724(1.0587) | Total Time 14.00(14.00)\n",
      "Iter 2471 | Time 60.8103(61.3597) | Bit/dim 3.7115(3.7014) | Xent 0.1345(0.1427) | Loss 3.7788(3.7728) | Error 0.0461(0.0482) Steps 688(684.17) | Grad Norm 0.9881(1.0566) | Total Time 14.00(14.00)\n",
      "Iter 2472 | Time 62.5330(61.3949) | Bit/dim 3.6968(3.7013) | Xent 0.1318(0.1424) | Loss 3.7627(3.7725) | Error 0.0440(0.0481) Steps 688(684.28) | Grad Norm 0.8684(1.0509) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 25.3335, Epoch Time 408.1628(411.2933), Bit/dim 3.7203(best: 3.7196), Xent 2.2477, Loss 4.8442, Error 0.4037(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2473 | Time 58.3756(61.3043) | Bit/dim 3.7086(3.7015) | Xent 0.1342(0.1421) | Loss 3.7757(3.7726) | Error 0.0451(0.0480) Steps 700(684.75) | Grad Norm 1.2170(1.0559) | Total Time 14.00(14.00)\n",
      "Iter 2474 | Time 59.0256(61.2360) | Bit/dim 3.6984(3.7014) | Xent 0.1279(0.1417) | Loss 3.7624(3.7723) | Error 0.0431(0.0479) Steps 682(684.67) | Grad Norm 1.4026(1.0663) | Total Time 14.00(14.00)\n",
      "Iter 2475 | Time 62.6177(61.2774) | Bit/dim 3.6981(3.7013) | Xent 0.1498(0.1419) | Loss 3.7730(3.7723) | Error 0.0527(0.0480) Steps 676(684.41) | Grad Norm 1.0000(1.0643) | Total Time 14.00(14.00)\n",
      "Iter 2476 | Time 61.2409(61.2763) | Bit/dim 3.7070(3.7015) | Xent 0.1419(0.1419) | Loss 3.7779(3.7725) | Error 0.0491(0.0481) Steps 682(684.34) | Grad Norm 1.0699(1.0645) | Total Time 14.00(14.00)\n",
      "Iter 2477 | Time 62.4913(61.3128) | Bit/dim 3.6875(3.7011) | Xent 0.1444(0.1420) | Loss 3.7596(3.7721) | Error 0.0496(0.0481) Steps 670(683.91) | Grad Norm 0.7959(1.0564) | Total Time 14.00(14.00)\n",
      "Iter 2478 | Time 64.0660(61.3954) | Bit/dim 3.7024(3.7011) | Xent 0.1407(0.1420) | Loss 3.7727(3.7721) | Error 0.0484(0.0481) Steps 688(684.03) | Grad Norm 1.0733(1.0569) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 25.5703, Epoch Time 416.6433(411.4538), Bit/dim 3.7208(best: 3.7196), Xent 2.2347, Loss 4.8381, Error 0.4006(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2479 | Time 59.7683(61.3466) | Bit/dim 3.6916(3.7008) | Xent 0.1374(0.1418) | Loss 3.7602(3.7717) | Error 0.0456(0.0480) Steps 694(684.33) | Grad Norm 0.8573(1.0509) | Total Time 14.00(14.00)\n",
      "Iter 2480 | Time 60.7554(61.3288) | Bit/dim 3.7094(3.7011) | Xent 0.1372(0.1417) | Loss 3.7780(3.7719) | Error 0.0433(0.0479) Steps 676(684.08) | Grad Norm 0.7012(1.0404) | Total Time 14.00(14.00)\n",
      "Iter 2481 | Time 62.3244(61.3587) | Bit/dim 3.6971(3.7010) | Xent 0.1359(0.1415) | Loss 3.7651(3.7717) | Error 0.0461(0.0478) Steps 682(684.02) | Grad Norm 1.0952(1.0421) | Total Time 14.00(14.00)\n",
      "Iter 2482 | Time 60.4411(61.3312) | Bit/dim 3.6988(3.7009) | Xent 0.1347(0.1413) | Loss 3.7661(3.7715) | Error 0.0469(0.0478) Steps 682(683.96) | Grad Norm 0.9518(1.0394) | Total Time 14.00(14.00)\n",
      "Iter 2483 | Time 59.4323(61.2742) | Bit/dim 3.7060(3.7010) | Xent 0.1457(0.1415) | Loss 3.7789(3.7718) | Error 0.0499(0.0479) Steps 682(683.90) | Grad Norm 1.1794(1.0436) | Total Time 14.00(14.00)\n",
      "Iter 2484 | Time 61.0023(61.2660) | Bit/dim 3.7095(3.7013) | Xent 0.1446(0.1415) | Loss 3.7818(3.7721) | Error 0.0499(0.0479) Steps 694(684.20) | Grad Norm 0.9627(1.0412) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 25.6478, Epoch Time 405.1278(411.2640), Bit/dim 3.7215(best: 3.7196), Xent 2.2636, Loss 4.8533, Error 0.4027(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2485 | Time 62.4658(61.3020) | Bit/dim 3.7019(3.7013) | Xent 0.1347(0.1413) | Loss 3.7693(3.7720) | Error 0.0447(0.0478) Steps 664(683.59) | Grad Norm 1.0388(1.0411) | Total Time 14.00(14.00)\n",
      "Iter 2486 | Time 60.8764(61.2893) | Bit/dim 3.7057(3.7014) | Xent 0.1408(0.1413) | Loss 3.7761(3.7721) | Error 0.0494(0.0479) Steps 688(683.73) | Grad Norm 0.9834(1.0394) | Total Time 14.00(14.00)\n",
      "Iter 2487 | Time 60.0187(61.2511) | Bit/dim 3.7078(3.7016) | Xent 0.1420(0.1413) | Loss 3.7788(3.7723) | Error 0.0460(0.0478) Steps 694(684.04) | Grad Norm 1.4209(1.0508) | Total Time 14.00(14.00)\n",
      "Iter 2488 | Time 60.7431(61.2359) | Bit/dim 3.6923(3.7014) | Xent 0.1421(0.1414) | Loss 3.7634(3.7720) | Error 0.0460(0.0478) Steps 682(683.97) | Grad Norm 0.9028(1.0464) | Total Time 14.00(14.00)\n",
      "Iter 2489 | Time 61.7282(61.2507) | Bit/dim 3.6990(3.7013) | Xent 0.1446(0.1415) | Loss 3.7713(3.7720) | Error 0.0479(0.0478) Steps 682(683.92) | Grad Norm 0.9774(1.0443) | Total Time 14.00(14.00)\n",
      "Iter 2490 | Time 58.8750(61.1794) | Bit/dim 3.7036(3.7014) | Xent 0.1286(0.1411) | Loss 3.7679(3.7719) | Error 0.0437(0.0477) Steps 676(683.68) | Grad Norm 0.9575(1.0417) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 25.3734, Epoch Time 406.2383(411.1132), Bit/dim 3.7194(best: 3.7196), Xent 2.2320, Loss 4.8354, Error 0.4010(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2491 | Time 62.9982(61.2340) | Bit/dim 3.7000(3.7013) | Xent 0.1344(0.1409) | Loss 3.7673(3.7718) | Error 0.0446(0.0476) Steps 688(683.81) | Grad Norm 1.1486(1.0449) | Total Time 14.00(14.00)\n",
      "Iter 2492 | Time 61.0449(61.2283) | Bit/dim 3.6989(3.7012) | Xent 0.1433(0.1410) | Loss 3.7705(3.7717) | Error 0.0484(0.0476) Steps 682(683.75) | Grad Norm 0.9381(1.0417) | Total Time 14.00(14.00)\n",
      "Iter 2493 | Time 63.4324(61.2944) | Bit/dim 3.7002(3.7012) | Xent 0.1382(0.1409) | Loss 3.7693(3.7716) | Error 0.0470(0.0476) Steps 670(683.34) | Grad Norm 0.7895(1.0341) | Total Time 14.00(14.00)\n",
      "Iter 2494 | Time 61.5182(61.3011) | Bit/dim 3.7026(3.7013) | Xent 0.1399(0.1408) | Loss 3.7726(3.7717) | Error 0.0460(0.0475) Steps 676(683.12) | Grad Norm 0.8062(1.0273) | Total Time 14.00(14.00)\n",
      "Iter 2495 | Time 60.4137(61.2745) | Bit/dim 3.7014(3.7013) | Xent 0.1331(0.1406) | Loss 3.7680(3.7716) | Error 0.0459(0.0475) Steps 682(683.09) | Grad Norm 0.8112(1.0208) | Total Time 14.00(14.00)\n",
      "Iter 2496 | Time 59.0231(61.2070) | Bit/dim 3.7013(3.7013) | Xent 0.1395(0.1406) | Loss 3.7710(3.7715) | Error 0.0486(0.0475) Steps 664(682.51) | Grad Norm 0.9496(1.0187) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 25.5954, Epoch Time 410.0839(411.0824), Bit/dim 3.7191(best: 3.7194), Xent 2.2265, Loss 4.8323, Error 0.4000(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2497 | Time 60.2062(61.1769) | Bit/dim 3.7083(3.7015) | Xent 0.1328(0.1403) | Loss 3.7747(3.7716) | Error 0.0445(0.0474) Steps 676(682.32) | Grad Norm 0.9669(1.0171) | Total Time 14.00(14.00)\n",
      "Iter 2498 | Time 58.5763(61.0989) | Bit/dim 3.6931(3.7012) | Xent 0.1432(0.1404) | Loss 3.7647(3.7714) | Error 0.0486(0.0475) Steps 682(682.31) | Grad Norm 0.8859(1.0132) | Total Time 14.00(14.00)\n",
      "Iter 2499 | Time 61.1265(61.0997) | Bit/dim 3.6951(3.7010) | Xent 0.1367(0.1403) | Loss 3.7634(3.7712) | Error 0.0467(0.0474) Steps 688(682.48) | Grad Norm 0.8791(1.0092) | Total Time 14.00(14.00)\n",
      "Iter 2500 | Time 60.5905(61.0845) | Bit/dim 3.7039(3.7011) | Xent 0.1343(0.1401) | Loss 3.7711(3.7712) | Error 0.0440(0.0473) Steps 682(682.47) | Grad Norm 1.1364(1.0130) | Total Time 14.00(14.00)\n",
      "Iter 2501 | Time 62.4770(61.1262) | Bit/dim 3.6947(3.7009) | Xent 0.1384(0.1401) | Loss 3.7639(3.7710) | Error 0.0461(0.0473) Steps 694(682.81) | Grad Norm 1.4320(1.0255) | Total Time 14.00(14.00)\n",
      "Iter 2502 | Time 60.4576(61.1062) | Bit/dim 3.7067(3.7011) | Xent 0.1430(0.1402) | Loss 3.7782(3.7712) | Error 0.0457(0.0472) Steps 682(682.79) | Grad Norm 0.8798(1.0212) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 25.1752, Epoch Time 404.6504(410.8894), Bit/dim 3.7202(best: 3.7191), Xent 2.2519, Loss 4.8462, Error 0.3996(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2503 | Time 60.9524(61.1016) | Bit/dim 3.6862(3.7007) | Xent 0.1304(0.1399) | Loss 3.7514(3.7706) | Error 0.0461(0.0472) Steps 688(682.94) | Grad Norm 0.9260(1.0183) | Total Time 14.00(14.00)\n",
      "Iter 2504 | Time 60.6934(61.0893) | Bit/dim 3.7135(3.7010) | Xent 0.1417(0.1399) | Loss 3.7844(3.7710) | Error 0.0471(0.0472) Steps 688(683.10) | Grad Norm 1.6477(1.0372) | Total Time 14.00(14.00)\n",
      "Iter 2505 | Time 61.1360(61.0907) | Bit/dim 3.7076(3.7012) | Xent 0.1383(0.1399) | Loss 3.7767(3.7712) | Error 0.0453(0.0472) Steps 688(683.24) | Grad Norm 1.0098(1.0364) | Total Time 14.00(14.00)\n",
      "Iter 2506 | Time 60.7609(61.0808) | Bit/dim 3.6984(3.7012) | Xent 0.1298(0.1396) | Loss 3.7633(3.7709) | Error 0.0443(0.0471) Steps 682(683.21) | Grad Norm 0.8435(1.0306) | Total Time 14.00(14.00)\n",
      "Iter 2507 | Time 61.4024(61.0905) | Bit/dim 3.6983(3.7011) | Xent 0.1362(0.1395) | Loss 3.7664(3.7708) | Error 0.0459(0.0470) Steps 670(682.81) | Grad Norm 0.9221(1.0273) | Total Time 14.00(14.00)\n",
      "Iter 2508 | Time 60.8382(61.0829) | Bit/dim 3.7005(3.7011) | Xent 0.1317(0.1392) | Loss 3.7664(3.7707) | Error 0.0465(0.0470) Steps 682(682.78) | Grad Norm 1.0050(1.0267) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 25.3038, Epoch Time 406.6412(410.7620), Bit/dim 3.7195(best: 3.7191), Xent 2.2625, Loss 4.8507, Error 0.4052(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2509 | Time 60.3862(61.0620) | Bit/dim 3.7032(3.7011) | Xent 0.1320(0.1390) | Loss 3.7692(3.7706) | Error 0.0470(0.0470) Steps 676(682.58) | Grad Norm 0.8577(1.0216) | Total Time 14.00(14.00)\n",
      "Iter 2510 | Time 60.8727(61.0563) | Bit/dim 3.7078(3.7013) | Xent 0.1431(0.1392) | Loss 3.7794(3.7709) | Error 0.0505(0.0471) Steps 682(682.56) | Grad Norm 1.2801(1.0294) | Total Time 14.00(14.00)\n",
      "Iter 2511 | Time 60.6919(61.0454) | Bit/dim 3.6934(3.7011) | Xent 0.1287(0.1388) | Loss 3.7578(3.7705) | Error 0.0435(0.0470) Steps 682(682.55) | Grad Norm 0.8590(1.0242) | Total Time 14.00(14.00)\n",
      "Iter 2512 | Time 58.8005(60.9780) | Bit/dim 3.6959(3.7009) | Xent 0.1387(0.1388) | Loss 3.7653(3.7703) | Error 0.0454(0.0470) Steps 694(682.89) | Grad Norm 1.0181(1.0241) | Total Time 14.00(14.00)\n",
      "Iter 2513 | Time 60.1470(60.9531) | Bit/dim 3.7000(3.7009) | Xent 0.1393(0.1388) | Loss 3.7696(3.7703) | Error 0.0449(0.0469) Steps 682(682.86) | Grad Norm 1.1471(1.0277) | Total Time 14.00(14.00)\n",
      "Iter 2514 | Time 58.0178(60.8651) | Bit/dim 3.7004(3.7009) | Xent 0.1271(0.1385) | Loss 3.7640(3.7701) | Error 0.0430(0.0468) Steps 670(682.48) | Grad Norm 1.0650(1.0289) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 25.5993, Epoch Time 400.3610(410.4499), Bit/dim 3.7202(best: 3.7191), Xent 2.2608, Loss 4.8506, Error 0.4003(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2515 | Time 60.8448(60.8644) | Bit/dim 3.7046(3.7010) | Xent 0.1294(0.1382) | Loss 3.7693(3.7701) | Error 0.0457(0.0467) Steps 694(682.82) | Grad Norm 0.8777(1.0243) | Total Time 14.00(14.00)\n",
      "Iter 2516 | Time 59.9282(60.8364) | Bit/dim 3.7015(3.7010) | Xent 0.1381(0.1382) | Loss 3.7706(3.7701) | Error 0.0459(0.0467) Steps 670(682.44) | Grad Norm 1.0464(1.0250) | Total Time 14.00(14.00)\n",
      "Iter 2517 | Time 60.4211(60.8239) | Bit/dim 3.7008(3.7010) | Xent 0.1421(0.1383) | Loss 3.7718(3.7702) | Error 0.0475(0.0467) Steps 682(682.43) | Grad Norm 0.8464(1.0196) | Total Time 14.00(14.00)\n",
      "Iter 2518 | Time 62.6051(60.8773) | Bit/dim 3.7021(3.7010) | Xent 0.1310(0.1381) | Loss 3.7676(3.7701) | Error 0.0470(0.0468) Steps 694(682.77) | Grad Norm 1.4705(1.0332) | Total Time 14.00(14.00)\n",
      "Iter 2519 | Time 61.5535(60.8976) | Bit/dim 3.6879(3.7006) | Xent 0.1358(0.1380) | Loss 3.7558(3.7697) | Error 0.0481(0.0468) Steps 694(683.11) | Grad Norm 0.6880(1.0228) | Total Time 14.00(14.00)\n",
      "Iter 2520 | Time 61.9382(60.9288) | Bit/dim 3.6966(3.7005) | Xent 0.1363(0.1380) | Loss 3.7648(3.7695) | Error 0.0466(0.0468) Steps 676(682.90) | Grad Norm 0.7057(1.0133) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 25.1198, Epoch Time 408.2817(410.3849), Bit/dim 3.7206(best: 3.7191), Xent 2.2456, Loss 4.8434, Error 0.3989(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2521 | Time 61.9737(60.9602) | Bit/dim 3.7027(3.7006) | Xent 0.1185(0.1374) | Loss 3.7620(3.7693) | Error 0.0399(0.0466) Steps 676(682.69) | Grad Norm 1.2050(1.0190) | Total Time 14.00(14.00)\n",
      "Iter 2522 | Time 60.1512(60.9359) | Bit/dim 3.7042(3.7007) | Xent 0.1364(0.1374) | Loss 3.7725(3.7694) | Error 0.0489(0.0467) Steps 694(683.03) | Grad Norm 0.7690(1.0115) | Total Time 14.00(14.00)\n",
      "Iter 2523 | Time 63.7021(61.0189) | Bit/dim 3.7005(3.7007) | Xent 0.1400(0.1375) | Loss 3.7705(3.7694) | Error 0.0483(0.0467) Steps 676(682.82) | Grad Norm 1.5982(1.0291) | Total Time 14.00(14.00)\n",
      "Iter 2524 | Time 63.9972(61.1083) | Bit/dim 3.7018(3.7007) | Xent 0.1445(0.1377) | Loss 3.7740(3.7696) | Error 0.0479(0.0467) Steps 682(682.79) | Grad Norm 0.9921(1.0280) | Total Time 14.00(14.00)\n",
      "Iter 2525 | Time 59.2384(61.0522) | Bit/dim 3.6900(3.7004) | Xent 0.1305(0.1375) | Loss 3.7553(3.7691) | Error 0.0426(0.0466) Steps 670(682.41) | Grad Norm 1.0947(1.0300) | Total Time 14.00(14.00)\n",
      "Iter 2526 | Time 61.4172(61.0631) | Bit/dim 3.7045(3.7005) | Xent 0.1371(0.1374) | Loss 3.7731(3.7692) | Error 0.0456(0.0466) Steps 682(682.40) | Grad Norm 0.8215(1.0238) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 25.4715, Epoch Time 411.5361(410.4194), Bit/dim 3.7199(best: 3.7191), Xent 2.2324, Loss 4.8361, Error 0.3999(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2527 | Time 59.6680(61.0213) | Bit/dim 3.7098(3.7008) | Xent 0.1359(0.1374) | Loss 3.7778(3.7695) | Error 0.0489(0.0467) Steps 676(682.21) | Grad Norm 0.8394(1.0182) | Total Time 14.00(14.00)\n",
      "Iter 2528 | Time 62.8247(61.0754) | Bit/dim 3.7026(3.7009) | Xent 0.1357(0.1373) | Loss 3.7704(3.7695) | Error 0.0453(0.0466) Steps 688(682.38) | Grad Norm 1.2160(1.0242) | Total Time 14.00(14.00)\n",
      "Iter 2529 | Time 62.7215(61.1247) | Bit/dim 3.7014(3.7009) | Xent 0.1371(0.1373) | Loss 3.7700(3.7695) | Error 0.0456(0.0466) Steps 682(682.37) | Grad Norm 1.3595(1.0342) | Total Time 14.00(14.00)\n",
      "Iter 2530 | Time 62.4403(61.1642) | Bit/dim 3.6911(3.7006) | Xent 0.1391(0.1374) | Loss 3.7607(3.7693) | Error 0.0470(0.0466) Steps 682(682.36) | Grad Norm 0.8091(1.0275) | Total Time 14.00(14.00)\n",
      "Iter 2531 | Time 60.8994(61.1563) | Bit/dim 3.6984(3.7005) | Xent 0.1322(0.1372) | Loss 3.7645(3.7691) | Error 0.0439(0.0465) Steps 670(681.99) | Grad Norm 1.2200(1.0333) | Total Time 14.00(14.00)\n",
      "Iter 2532 | Time 62.2799(61.1900) | Bit/dim 3.7021(3.7006) | Xent 0.1471(0.1375) | Loss 3.7757(3.7693) | Error 0.0486(0.0466) Steps 676(681.81) | Grad Norm 1.0665(1.0343) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 24.9282, Epoch Time 411.3997(410.4488), Bit/dim 3.7209(best: 3.7191), Xent 2.2470, Loss 4.8444, Error 0.4002(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2533 | Time 61.9256(61.2120) | Bit/dim 3.6943(3.7004) | Xent 0.1338(0.1374) | Loss 3.7612(3.7691) | Error 0.0451(0.0465) Steps 688(681.99) | Grad Norm 1.1847(1.0388) | Total Time 14.00(14.00)\n",
      "Iter 2534 | Time 61.8181(61.2302) | Bit/dim 3.7049(3.7005) | Xent 0.1338(0.1373) | Loss 3.7718(3.7692) | Error 0.0445(0.0465) Steps 682(681.99) | Grad Norm 1.4027(1.0497) | Total Time 14.00(14.00)\n",
      "Iter 2535 | Time 62.6772(61.2736) | Bit/dim 3.7039(3.7006) | Xent 0.1331(0.1372) | Loss 3.7705(3.7692) | Error 0.0455(0.0464) Steps 688(682.17) | Grad Norm 1.2074(1.0544) | Total Time 14.00(14.00)\n",
      "Iter 2536 | Time 61.1637(61.2703) | Bit/dim 3.7022(3.7007) | Xent 0.1332(0.1371) | Loss 3.7688(3.7692) | Error 0.0464(0.0464) Steps 682(682.17) | Grad Norm 1.4867(1.0674) | Total Time 14.00(14.00)\n",
      "Iter 2537 | Time 61.8887(61.2889) | Bit/dim 3.6989(3.7006) | Xent 0.1327(0.1369) | Loss 3.7652(3.7691) | Error 0.0456(0.0464) Steps 682(682.16) | Grad Norm 0.7011(1.0564) | Total Time 14.00(14.00)\n",
      "Iter 2538 | Time 61.9700(61.3093) | Bit/dim 3.6934(3.7004) | Xent 0.1367(0.1369) | Loss 3.7617(3.7689) | Error 0.0439(0.0463) Steps 676(681.98) | Grad Norm 1.1405(1.0589) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 25.2011, Epoch Time 412.3119(410.5047), Bit/dim 3.7193(best: 3.7191), Xent 2.2903, Loss 4.8645, Error 0.4033(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2539 | Time 60.9720(61.2992) | Bit/dim 3.6966(3.7003) | Xent 0.1364(0.1369) | Loss 3.7648(3.7687) | Error 0.0469(0.0464) Steps 682(681.98) | Grad Norm 0.9946(1.0570) | Total Time 14.00(14.00)\n",
      "Iter 2540 | Time 60.4160(61.2727) | Bit/dim 3.6987(3.7002) | Xent 0.1427(0.1371) | Loss 3.7701(3.7688) | Error 0.0484(0.0464) Steps 688(682.16) | Grad Norm 0.8274(1.0501) | Total Time 14.00(14.00)\n",
      "Iter 2541 | Time 60.7288(61.2564) | Bit/dim 3.6994(3.7002) | Xent 0.1431(0.1373) | Loss 3.7710(3.7688) | Error 0.0497(0.0465) Steps 682(682.15) | Grad Norm 1.0787(1.0510) | Total Time 14.00(14.00)\n",
      "Iter 2542 | Time 61.8470(61.2741) | Bit/dim 3.6970(3.7001) | Xent 0.1341(0.1372) | Loss 3.7641(3.7687) | Error 0.0480(0.0466) Steps 676(681.97) | Grad Norm 1.8367(1.0745) | Total Time 14.00(14.00)\n",
      "Iter 2543 | Time 61.0951(61.2687) | Bit/dim 3.7146(3.7005) | Xent 0.1308(0.1370) | Loss 3.7800(3.7690) | Error 0.0447(0.0465) Steps 676(681.79) | Grad Norm 0.8653(1.0683) | Total Time 14.00(14.00)\n",
      "Iter 2544 | Time 62.7533(61.3133) | Bit/dim 3.6968(3.7004) | Xent 0.1381(0.1370) | Loss 3.7658(3.7689) | Error 0.0467(0.0465) Steps 676(681.62) | Grad Norm 1.0296(1.0671) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 25.3402, Epoch Time 409.0160(410.4601), Bit/dim 3.7201(best: 3.7191), Xent 2.2743, Loss 4.8572, Error 0.4035(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2545 | Time 60.3556(61.2845) | Bit/dim 3.7065(3.7006) | Xent 0.1273(0.1367) | Loss 3.7701(3.7690) | Error 0.0434(0.0464) Steps 688(681.81) | Grad Norm 1.1491(1.0696) | Total Time 14.00(14.00)\n",
      "Iter 2546 | Time 61.5079(61.2912) | Bit/dim 3.6954(3.7005) | Xent 0.1416(0.1369) | Loss 3.7662(3.7689) | Error 0.0494(0.0465) Steps 688(681.99) | Grad Norm 1.7098(1.0888) | Total Time 14.00(14.00)\n",
      "Iter 2547 | Time 61.4736(61.2967) | Bit/dim 3.7077(3.7007) | Xent 0.1264(0.1366) | Loss 3.7708(3.7690) | Error 0.0421(0.0464) Steps 676(681.81) | Grad Norm 0.7098(1.0774) | Total Time 14.00(14.00)\n",
      "Iter 2548 | Time 60.9660(61.2868) | Bit/dim 3.6993(3.7006) | Xent 0.1297(0.1363) | Loss 3.7641(3.7688) | Error 0.0455(0.0463) Steps 682(681.82) | Grad Norm 1.0572(1.0768) | Total Time 14.00(14.00)\n",
      "Iter 2549 | Time 62.2939(61.3170) | Bit/dim 3.7039(3.7007) | Xent 0.1402(0.1365) | Loss 3.7740(3.7690) | Error 0.0476(0.0464) Steps 682(681.83) | Grad Norm 1.1831(1.0800) | Total Time 14.00(14.00)\n",
      "Iter 2550 | Time 59.9061(61.2747) | Bit/dim 3.6850(3.7003) | Xent 0.1351(0.1364) | Loss 3.7525(3.7685) | Error 0.0457(0.0464) Steps 694(682.19) | Grad Norm 1.4156(1.0901) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 25.4563, Epoch Time 408.1039(410.3894), Bit/dim 3.7192(best: 3.7191), Xent 2.2886, Loss 4.8636, Error 0.4038(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2551 | Time 62.8226(61.3211) | Bit/dim 3.6976(3.7002) | Xent 0.1346(0.1364) | Loss 3.7649(3.7684) | Error 0.0473(0.0464) Steps 682(682.18) | Grad Norm 1.2790(1.0957) | Total Time 14.00(14.00)\n",
      "Iter 2552 | Time 60.0811(61.2839) | Bit/dim 3.6957(3.7000) | Xent 0.1311(0.1362) | Loss 3.7613(3.7681) | Error 0.0420(0.0463) Steps 682(682.18) | Grad Norm 1.4105(1.1052) | Total Time 14.00(14.00)\n",
      "Iter 2553 | Time 60.3257(61.2552) | Bit/dim 3.6878(3.6997) | Xent 0.1418(0.1364) | Loss 3.7588(3.7679) | Error 0.0460(0.0463) Steps 676(681.99) | Grad Norm 1.3362(1.1121) | Total Time 14.00(14.00)\n",
      "Iter 2554 | Time 61.5444(61.2638) | Bit/dim 3.7192(3.7003) | Xent 0.1333(0.1363) | Loss 3.7859(3.7684) | Error 0.0454(0.0462) Steps 682(681.99) | Grad Norm 1.1830(1.1142) | Total Time 14.00(14.00)\n",
      "Iter 2555 | Time 61.1942(61.2618) | Bit/dim 3.7004(3.7003) | Xent 0.1242(0.1359) | Loss 3.7625(3.7682) | Error 0.0415(0.0461) Steps 694(682.35) | Grad Norm 0.9383(1.1089) | Total Time 14.00(14.00)\n",
      "Iter 2556 | Time 61.2655(61.2619) | Bit/dim 3.7016(3.7003) | Xent 0.1323(0.1358) | Loss 3.7677(3.7682) | Error 0.0449(0.0461) Steps 682(682.34) | Grad Norm 1.5401(1.1219) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 25.2133, Epoch Time 408.2577(410.3254), Bit/dim 3.7206(best: 3.7191), Xent 2.2742, Loss 4.8577, Error 0.4033(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2557 | Time 60.0046(61.2242) | Bit/dim 3.6989(3.7003) | Xent 0.1337(0.1357) | Loss 3.7657(3.7681) | Error 0.0455(0.0460) Steps 682(682.33) | Grad Norm 1.1515(1.1228) | Total Time 14.00(14.00)\n",
      "Iter 2558 | Time 60.5115(61.2028) | Bit/dim 3.7013(3.7003) | Xent 0.1341(0.1357) | Loss 3.7683(3.7681) | Error 0.0460(0.0460) Steps 676(682.14) | Grad Norm 0.8086(1.1133) | Total Time 14.00(14.00)\n",
      "Iter 2559 | Time 60.3023(61.1758) | Bit/dim 3.6992(3.7003) | Xent 0.1244(0.1354) | Loss 3.7614(3.7679) | Error 0.0439(0.0460) Steps 670(681.78) | Grad Norm 1.1775(1.1153) | Total Time 14.00(14.00)\n",
      "Iter 2560 | Time 58.4162(61.0930) | Bit/dim 3.6912(3.7000) | Xent 0.1321(0.1353) | Loss 3.7573(3.7676) | Error 0.0441(0.0459) Steps 682(681.79) | Grad Norm 1.2472(1.1192) | Total Time 14.00(14.00)\n",
      "Iter 2561 | Time 59.4623(61.0440) | Bit/dim 3.7051(3.7001) | Xent 0.1437(0.1355) | Loss 3.7770(3.7679) | Error 0.0479(0.0460) Steps 688(681.97) | Grad Norm 0.9002(1.1127) | Total Time 14.00(14.00)\n",
      "Iter 2562 | Time 62.3863(61.0843) | Bit/dim 3.7014(3.7002) | Xent 0.1471(0.1359) | Loss 3.7750(3.7681) | Error 0.0477(0.0460) Steps 670(681.61) | Grad Norm 1.0486(1.1107) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 25.2830, Epoch Time 402.3489(410.0861), Bit/dim 3.7196(best: 3.7191), Xent 2.2603, Loss 4.8497, Error 0.3981(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2563 | Time 62.9245(61.1395) | Bit/dim 3.6952(3.7000) | Xent 0.1222(0.1354) | Loss 3.7563(3.7678) | Error 0.0413(0.0459) Steps 676(681.44) | Grad Norm 1.1479(1.1118) | Total Time 14.00(14.00)\n",
      "Iter 2564 | Time 59.8763(61.1016) | Bit/dim 3.6946(3.6999) | Xent 0.1306(0.1353) | Loss 3.7599(3.7675) | Error 0.0453(0.0459) Steps 688(681.64) | Grad Norm 1.0862(1.1111) | Total Time 14.00(14.00)\n",
      "Iter 2565 | Time 64.5874(61.2062) | Bit/dim 3.6963(3.6998) | Xent 0.1260(0.1350) | Loss 3.7593(3.7673) | Error 0.0395(0.0457) Steps 682(681.65) | Grad Norm 1.0968(1.1106) | Total Time 14.00(14.00)\n",
      "Iter 2566 | Time 62.4715(61.2442) | Bit/dim 3.7083(3.7000) | Xent 0.1308(0.1349) | Loss 3.7737(3.7675) | Error 0.0449(0.0456) Steps 670(681.30) | Grad Norm 1.0129(1.1077) | Total Time 14.00(14.00)\n",
      "Iter 2567 | Time 60.8657(61.2328) | Bit/dim 3.7011(3.7001) | Xent 0.1271(0.1347) | Loss 3.7646(3.7674) | Error 0.0427(0.0456) Steps 682(681.32) | Grad Norm 1.0227(1.1052) | Total Time 14.00(14.00)\n",
      "Iter 2568 | Time 59.7278(61.1877) | Bit/dim 3.7035(3.7002) | Xent 0.1410(0.1349) | Loss 3.7740(3.7676) | Error 0.0455(0.0456) Steps 682(681.34) | Grad Norm 0.8097(1.0963) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 25.5416, Epoch Time 411.8265(410.1383), Bit/dim 3.7205(best: 3.7191), Xent 2.2913, Loss 4.8661, Error 0.4016(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2569 | Time 60.9954(61.1819) | Bit/dim 3.6921(3.6999) | Xent 0.1388(0.1350) | Loss 3.7615(3.7674) | Error 0.0475(0.0456) Steps 682(681.36) | Grad Norm 0.8803(1.0898) | Total Time 14.00(14.00)\n",
      "Iter 2570 | Time 61.3144(61.1859) | Bit/dim 3.6969(3.6998) | Xent 0.1421(0.1352) | Loss 3.7679(3.7674) | Error 0.0465(0.0456) Steps 682(681.38) | Grad Norm 1.2935(1.0959) | Total Time 14.00(14.00)\n",
      "Iter 2571 | Time 62.3782(61.2216) | Bit/dim 3.7083(3.7001) | Xent 0.1355(0.1352) | Loss 3.7761(3.7677) | Error 0.0425(0.0455) Steps 682(681.40) | Grad Norm 0.8831(1.0895) | Total Time 14.00(14.00)\n",
      "Iter 2572 | Time 61.9143(61.2424) | Bit/dim 3.6943(3.6999) | Xent 0.1273(0.1350) | Loss 3.7579(3.7674) | Error 0.0421(0.0454) Steps 670(681.06) | Grad Norm 0.9383(1.0850) | Total Time 14.00(14.00)\n",
      "Iter 2573 | Time 60.9182(61.2327) | Bit/dim 3.7098(3.7002) | Xent 0.1147(0.1343) | Loss 3.7671(3.7674) | Error 0.0366(0.0452) Steps 688(681.27) | Grad Norm 0.9443(1.0808) | Total Time 14.00(14.00)\n",
      "Iter 2574 | Time 61.8612(61.2515) | Bit/dim 3.6984(3.7002) | Xent 0.1416(0.1346) | Loss 3.7693(3.7674) | Error 0.0496(0.0453) Steps 682(681.29) | Grad Norm 1.3798(1.0898) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 25.4534, Epoch Time 411.0108(410.1645), Bit/dim 3.7205(best: 3.7191), Xent 2.2744, Loss 4.8577, Error 0.4041(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2575 | Time 61.4306(61.2569) | Bit/dim 3.7049(3.7003) | Xent 0.1348(0.1346) | Loss 3.7723(3.7676) | Error 0.0454(0.0453) Steps 688(681.49) | Grad Norm 1.6424(1.1063) | Total Time 14.00(14.00)\n",
      "Iter 2576 | Time 62.8639(61.3051) | Bit/dim 3.6941(3.7001) | Xent 0.1390(0.1347) | Loss 3.7636(3.7675) | Error 0.0489(0.0454) Steps 694(681.87) | Grad Norm 1.3937(1.1150) | Total Time 14.00(14.00)\n",
      "Iter 2577 | Time 61.2177(61.3025) | Bit/dim 3.6904(3.6998) | Xent 0.1309(0.1346) | Loss 3.7558(3.7671) | Error 0.0454(0.0454) Steps 670(681.51) | Grad Norm 1.6032(1.1296) | Total Time 14.00(14.00)\n",
      "Iter 2578 | Time 59.2356(61.2405) | Bit/dim 3.6949(3.6997) | Xent 0.1346(0.1346) | Loss 3.7622(3.7670) | Error 0.0441(0.0454) Steps 682(681.52) | Grad Norm 1.2264(1.1325) | Total Time 14.00(14.00)\n",
      "Iter 2579 | Time 61.7287(61.2551) | Bit/dim 3.7061(3.6999) | Xent 0.1254(0.1343) | Loss 3.7688(3.7670) | Error 0.0423(0.0453) Steps 682(681.54) | Grad Norm 1.2137(1.1349) | Total Time 14.00(14.00)\n",
      "Iter 2580 | Time 59.3306(61.1974) | Bit/dim 3.7031(3.7000) | Xent 0.1363(0.1344) | Loss 3.7713(3.7671) | Error 0.0459(0.0453) Steps 682(681.55) | Grad Norm 1.4060(1.1431) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 25.3397, Epoch Time 406.9796(410.0690), Bit/dim 3.7192(best: 3.7191), Xent 2.2753, Loss 4.8568, Error 0.4055(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2581 | Time 62.4969(61.2364) | Bit/dim 3.7105(3.7003) | Xent 0.1288(0.1342) | Loss 3.7749(3.7674) | Error 0.0455(0.0453) Steps 688(681.75) | Grad Norm 1.1984(1.1447) | Total Time 14.00(14.00)\n",
      "Iter 2582 | Time 58.8399(61.1645) | Bit/dim 3.6928(3.7000) | Xent 0.1312(0.1341) | Loss 3.7584(3.7671) | Error 0.0435(0.0453) Steps 688(681.93) | Grad Norm 0.7536(1.1330) | Total Time 14.00(14.00)\n",
      "Iter 2583 | Time 61.4642(61.1735) | Bit/dim 3.6963(3.6999) | Xent 0.1327(0.1341) | Loss 3.7626(3.7670) | Error 0.0469(0.0453) Steps 676(681.76) | Grad Norm 1.4216(1.1417) | Total Time 14.00(14.00)\n",
      "Iter 2584 | Time 62.4221(61.2109) | Bit/dim 3.6953(3.6998) | Xent 0.1367(0.1342) | Loss 3.7637(3.7669) | Error 0.0444(0.0453) Steps 688(681.94) | Grad Norm 1.3844(1.1489) | Total Time 14.00(14.00)\n",
      "Iter 2585 | Time 59.7843(61.1681) | Bit/dim 3.7054(3.7000) | Xent 0.1233(0.1338) | Loss 3.7670(3.7669) | Error 0.0426(0.0452) Steps 676(681.76) | Grad Norm 1.1851(1.1500) | Total Time 14.00(14.00)\n",
      "Iter 2586 | Time 59.6485(61.1226) | Bit/dim 3.6992(3.6999) | Xent 0.1332(0.1338) | Loss 3.7658(3.7668) | Error 0.0440(0.0452) Steps 682(681.77) | Grad Norm 1.2420(1.1528) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 25.1919, Epoch Time 405.6500(409.9364), Bit/dim 3.7207(best: 3.7191), Xent 2.3282, Loss 4.8847, Error 0.4030(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2587 | Time 60.3801(61.1003) | Bit/dim 3.6959(3.6998) | Xent 0.1318(0.1337) | Loss 3.7618(3.7667) | Error 0.0444(0.0451) Steps 694(682.14) | Grad Norm 1.2170(1.1547) | Total Time 14.00(14.00)\n",
      "Iter 2588 | Time 59.6434(61.0566) | Bit/dim 3.6914(3.6996) | Xent 0.1270(0.1335) | Loss 3.7548(3.7663) | Error 0.0414(0.0450) Steps 688(682.31) | Grad Norm 1.8532(1.1757) | Total Time 14.00(14.00)\n",
      "Iter 2589 | Time 59.5242(61.0106) | Bit/dim 3.7091(3.6999) | Xent 0.1248(0.1333) | Loss 3.7715(3.7665) | Error 0.0449(0.0450) Steps 688(682.48) | Grad Norm 1.3308(1.1803) | Total Time 14.00(14.00)\n",
      "Iter 2590 | Time 61.5871(61.0279) | Bit/dim 3.6964(3.6998) | Xent 0.1401(0.1335) | Loss 3.7665(3.7665) | Error 0.0475(0.0451) Steps 682(682.47) | Grad Norm 1.1704(1.1800) | Total Time 14.00(14.00)\n",
      "Iter 2591 | Time 60.6291(61.0159) | Bit/dim 3.7001(3.6998) | Xent 0.1305(0.1334) | Loss 3.7653(3.7665) | Error 0.0439(0.0451) Steps 670(682.10) | Grad Norm 0.8995(1.1716) | Total Time 14.00(14.00)\n",
      "Iter 2592 | Time 63.3198(61.0850) | Bit/dim 3.7061(3.7000) | Xent 0.1324(0.1334) | Loss 3.7723(3.7666) | Error 0.0454(0.0451) Steps 682(682.09) | Grad Norm 1.7445(1.1888) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 25.5053, Epoch Time 406.1097(409.8216), Bit/dim 3.7204(best: 3.7191), Xent 2.2661, Loss 4.8535, Error 0.4026(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2593 | Time 60.5465(61.0689) | Bit/dim 3.6996(3.6999) | Xent 0.1334(0.1334) | Loss 3.7663(3.7666) | Error 0.0439(0.0450) Steps 670(681.73) | Grad Norm 1.4800(1.1975) | Total Time 14.00(14.00)\n",
      "Iter 2594 | Time 61.6497(61.0863) | Bit/dim 3.7065(3.7001) | Xent 0.1312(0.1333) | Loss 3.7721(3.7668) | Error 0.0433(0.0450) Steps 682(681.74) | Grad Norm 1.1092(1.1949) | Total Time 14.00(14.00)\n",
      "Iter 2595 | Time 60.9605(61.0825) | Bit/dim 3.6914(3.6999) | Xent 0.1327(0.1333) | Loss 3.7578(3.7665) | Error 0.0461(0.0450) Steps 682(681.75) | Grad Norm 1.0803(1.1914) | Total Time 14.00(14.00)\n",
      "Iter 2596 | Time 64.3224(61.1797) | Bit/dim 3.7088(3.7001) | Xent 0.1373(0.1334) | Loss 3.7774(3.7668) | Error 0.0424(0.0449) Steps 688(681.93) | Grad Norm 1.4007(1.1977) | Total Time 14.00(14.00)\n",
      "Iter 2597 | Time 60.9026(61.1714) | Bit/dim 3.7014(3.7002) | Xent 0.1328(0.1334) | Loss 3.7678(3.7669) | Error 0.0464(0.0450) Steps 676(681.76) | Grad Norm 1.4113(1.2041) | Total Time 14.00(14.00)\n",
      "Iter 2598 | Time 61.2551(61.1739) | Bit/dim 3.6936(3.7000) | Xent 0.1308(0.1333) | Loss 3.7590(3.7666) | Error 0.0446(0.0450) Steps 670(681.40) | Grad Norm 1.7914(1.2217) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 24.8631, Epoch Time 410.3378(409.8371), Bit/dim 3.7196(best: 3.7191), Xent 2.2976, Loss 4.8684, Error 0.4024(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2599 | Time 62.6115(61.2171) | Bit/dim 3.6983(3.6999) | Xent 0.1367(0.1334) | Loss 3.7667(3.7666) | Error 0.0467(0.0450) Steps 670(681.06) | Grad Norm 1.1133(1.2185) | Total Time 14.00(14.00)\n",
      "Iter 2600 | Time 61.3362(61.2206) | Bit/dim 3.6998(3.6999) | Xent 0.1335(0.1334) | Loss 3.7666(3.7666) | Error 0.0465(0.0451) Steps 694(681.45) | Grad Norm 0.8240(1.2067) | Total Time 14.00(14.00)\n",
      "Iter 2601 | Time 60.8453(61.2094) | Bit/dim 3.6986(3.6999) | Xent 0.1413(0.1336) | Loss 3.7692(3.7667) | Error 0.0454(0.0451) Steps 682(681.47) | Grad Norm 1.7375(1.2226) | Total Time 14.00(14.00)\n",
      "Iter 2602 | Time 62.2157(61.2396) | Bit/dim 3.6951(3.6997) | Xent 0.1235(0.1333) | Loss 3.7569(3.7664) | Error 0.0414(0.0450) Steps 676(681.30) | Grad Norm 2.7408(1.2681) | Total Time 14.00(14.00)\n",
      "Iter 2603 | Time 61.5830(61.2499) | Bit/dim 3.7031(3.6998) | Xent 0.1290(0.1332) | Loss 3.7676(3.7665) | Error 0.0421(0.0449) Steps 688(681.50) | Grad Norm 0.8704(1.2562) | Total Time 14.00(14.00)\n",
      "Iter 2604 | Time 61.4538(61.2560) | Bit/dim 3.7006(3.6999) | Xent 0.1308(0.1331) | Loss 3.7660(3.7664) | Error 0.0441(0.0449) Steps 670(681.16) | Grad Norm 0.7989(1.2425) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 25.5150, Epoch Time 411.3642(409.8829), Bit/dim 3.7203(best: 3.7191), Xent 2.2848, Loss 4.8627, Error 0.4020(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2605 | Time 62.1771(61.2836) | Bit/dim 3.6996(3.6999) | Xent 0.1296(0.1330) | Loss 3.7644(3.7664) | Error 0.0451(0.0449) Steps 688(681.36) | Grad Norm 1.1547(1.2398) | Total Time 14.00(14.00)\n",
      "Iter 2606 | Time 61.0523(61.2767) | Bit/dim 3.6989(3.6998) | Xent 0.1321(0.1330) | Loss 3.7650(3.7663) | Error 0.0436(0.0448) Steps 700(681.92) | Grad Norm 0.9559(1.2313) | Total Time 14.00(14.00)\n",
      "Iter 2607 | Time 60.5294(61.2543) | Bit/dim 3.6924(3.6996) | Xent 0.1400(0.1332) | Loss 3.7624(3.7662) | Error 0.0471(0.0449) Steps 682(681.92) | Grad Norm 1.3958(1.2363) | Total Time 14.00(14.00)\n",
      "Iter 2608 | Time 61.3265(61.2564) | Bit/dim 3.7067(3.6998) | Xent 0.1287(0.1331) | Loss 3.7711(3.7664) | Error 0.0417(0.0448) Steps 682(681.93) | Grad Norm 1.1329(1.2332) | Total Time 14.00(14.00)\n",
      "Iter 2609 | Time 61.4748(61.2630) | Bit/dim 3.7056(3.7000) | Xent 0.1295(0.1330) | Loss 3.7703(3.7665) | Error 0.0430(0.0447) Steps 676(681.75) | Grad Norm 1.3591(1.2369) | Total Time 14.00(14.00)\n",
      "Iter 2610 | Time 61.9930(61.2849) | Bit/dim 3.6966(3.6999) | Xent 0.1230(0.1327) | Loss 3.7581(3.7662) | Error 0.0394(0.0446) Steps 670(681.40) | Grad Norm 1.0575(1.2315) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 25.1430, Epoch Time 409.6027(409.8745), Bit/dim 3.7200(best: 3.7191), Xent 2.2970, Loss 4.8685, Error 0.4031(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2611 | Time 61.6693(61.2964) | Bit/dim 3.7035(3.7000) | Xent 0.1210(0.1323) | Loss 3.7640(3.7662) | Error 0.0410(0.0445) Steps 670(681.05) | Grad Norm 0.8253(1.2194) | Total Time 14.00(14.00)\n",
      "Iter 2612 | Time 59.5252(61.2433) | Bit/dim 3.6970(3.6999) | Xent 0.1282(0.1322) | Loss 3.7611(3.7660) | Error 0.0440(0.0445) Steps 682(681.08) | Grad Norm 1.2664(1.2208) | Total Time 14.00(14.00)\n",
      "Iter 2613 | Time 61.7798(61.2594) | Bit/dim 3.7055(3.7001) | Xent 0.1294(0.1321) | Loss 3.7702(3.7661) | Error 0.0445(0.0445) Steps 688(681.29) | Grad Norm 0.9316(1.2121) | Total Time 14.00(14.00)\n",
      "Iter 2614 | Time 62.7934(61.3054) | Bit/dim 3.7025(3.7002) | Xent 0.1282(0.1320) | Loss 3.7666(3.7662) | Error 0.0435(0.0444) Steps 688(681.49) | Grad Norm 1.0322(1.2067) | Total Time 14.00(14.00)\n",
      "Iter 2615 | Time 64.6448(61.4056) | Bit/dim 3.6962(3.7000) | Xent 0.1333(0.1320) | Loss 3.7629(3.7661) | Error 0.0433(0.0444) Steps 682(681.51) | Grad Norm 0.9157(1.1980) | Total Time 14.00(14.00)\n",
      "Iter 2616 | Time 61.3090(61.4027) | Bit/dim 3.6916(3.6998) | Xent 0.1332(0.1321) | Loss 3.7582(3.7658) | Error 0.0444(0.0444) Steps 676(681.34) | Grad Norm 0.9889(1.1917) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 25.1616, Epoch Time 412.4641(409.9522), Bit/dim 3.7200(best: 3.7191), Xent 2.2729, Loss 4.8565, Error 0.3985(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2617 | Time 59.3688(61.3417) | Bit/dim 3.7067(3.7000) | Xent 0.1245(0.1318) | Loss 3.7689(3.7659) | Error 0.0423(0.0443) Steps 682(681.36) | Grad Norm 0.9020(1.1830) | Total Time 14.00(14.00)\n",
      "Iter 2618 | Time 60.7478(61.3238) | Bit/dim 3.7043(3.7001) | Xent 0.1283(0.1317) | Loss 3.7684(3.7660) | Error 0.0424(0.0443) Steps 676(681.20) | Grad Norm 1.2202(1.1841) | Total Time 14.00(14.00)\n",
      "Iter 2619 | Time 63.1605(61.3789) | Bit/dim 3.6972(3.7000) | Xent 0.1312(0.1317) | Loss 3.7628(3.7659) | Error 0.0423(0.0442) Steps 682(681.22) | Grad Norm 0.9204(1.1762) | Total Time 14.00(14.00)\n",
      "Iter 2620 | Time 62.7363(61.4197) | Bit/dim 3.6946(3.6999) | Xent 0.1353(0.1318) | Loss 3.7622(3.7658) | Error 0.0479(0.0443) Steps 682(681.25) | Grad Norm 0.6982(1.1619) | Total Time 14.00(14.00)\n",
      "Iter 2621 | Time 61.1461(61.4115) | Bit/dim 3.7011(3.6999) | Xent 0.1338(0.1319) | Loss 3.7681(3.7658) | Error 0.0451(0.0443) Steps 688(681.45) | Grad Norm 1.2006(1.1630) | Total Time 14.00(14.00)\n",
      "Iter 2622 | Time 60.8757(61.3954) | Bit/dim 3.6936(3.6997) | Xent 0.1352(0.1320) | Loss 3.7612(3.7657) | Error 0.0480(0.0445) Steps 676(681.29) | Grad Norm 0.9465(1.1565) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 25.3814, Epoch Time 409.1917(409.9294), Bit/dim 3.7205(best: 3.7191), Xent 2.3410, Loss 4.8910, Error 0.4030(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2623 | Time 62.1001(61.4165) | Bit/dim 3.6901(3.6994) | Xent 0.1371(0.1321) | Loss 3.7587(3.7655) | Error 0.0463(0.0445) Steps 682(681.31) | Grad Norm 1.4283(1.1647) | Total Time 14.00(14.00)\n",
      "Iter 2624 | Time 60.4292(61.3869) | Bit/dim 3.7032(3.6995) | Xent 0.1360(0.1323) | Loss 3.7712(3.7657) | Error 0.0465(0.0446) Steps 670(680.97) | Grad Norm 0.8682(1.1558) | Total Time 14.00(14.00)\n",
      "Iter 2625 | Time 59.6819(61.3358) | Bit/dim 3.6993(3.6995) | Xent 0.1340(0.1323) | Loss 3.7663(3.7657) | Error 0.0469(0.0446) Steps 670(680.64) | Grad Norm 1.2962(1.1600) | Total Time 14.00(14.00)\n",
      "Iter 2626 | Time 60.5309(61.3116) | Bit/dim 3.7012(3.6996) | Xent 0.1236(0.1320) | Loss 3.7630(3.7656) | Error 0.0401(0.0445) Steps 676(680.50) | Grad Norm 0.8841(1.1517) | Total Time 14.00(14.00)\n",
      "Iter 2627 | Time 61.8527(61.3278) | Bit/dim 3.6984(3.6995) | Xent 0.1265(0.1319) | Loss 3.7617(3.7655) | Error 0.0425(0.0444) Steps 682(680.55) | Grad Norm 1.0566(1.1489) | Total Time 14.00(14.00)\n",
      "Iter 2628 | Time 60.7241(61.3097) | Bit/dim 3.7071(3.6998) | Xent 0.1272(0.1317) | Loss 3.7708(3.7656) | Error 0.0441(0.0444) Steps 676(680.41) | Grad Norm 1.2978(1.1533) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 25.3990, Epoch Time 406.2365(409.8186), Bit/dim 3.7198(best: 3.7191), Xent 2.3138, Loss 4.8767, Error 0.4062(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2629 | Time 61.0227(61.3011) | Bit/dim 3.7027(3.6999) | Xent 0.1314(0.1317) | Loss 3.7684(3.7657) | Error 0.0446(0.0444) Steps 688(680.64) | Grad Norm 1.0596(1.1505) | Total Time 14.00(14.00)\n",
      "Iter 2630 | Time 59.4530(61.2457) | Bit/dim 3.6975(3.6998) | Xent 0.1399(0.1320) | Loss 3.7674(3.7658) | Error 0.0464(0.0445) Steps 676(680.50) | Grad Norm 0.8405(1.1412) | Total Time 14.00(14.00)\n",
      "Iter 2631 | Time 61.4556(61.2520) | Bit/dim 3.6899(3.6995) | Xent 0.1342(0.1320) | Loss 3.7570(3.7655) | Error 0.0466(0.0446) Steps 688(680.72) | Grad Norm 1.5338(1.1530) | Total Time 14.00(14.00)\n",
      "Iter 2632 | Time 63.3106(61.3137) | Bit/dim 3.6938(3.6993) | Xent 0.1234(0.1318) | Loss 3.7556(3.7652) | Error 0.0419(0.0445) Steps 676(680.58) | Grad Norm 0.9454(1.1468) | Total Time 14.00(14.00)\n",
      "Iter 2633 | Time 59.3530(61.2549) | Bit/dim 3.7078(3.6996) | Xent 0.1323(0.1318) | Loss 3.7739(3.7655) | Error 0.0466(0.0445) Steps 682(680.62) | Grad Norm 1.5003(1.1574) | Total Time 14.00(14.00)\n",
      "Iter 2634 | Time 62.6848(61.2978) | Bit/dim 3.7018(3.6996) | Xent 0.1327(0.1318) | Loss 3.7681(3.7656) | Error 0.0454(0.0446) Steps 676(680.49) | Grad Norm 1.6479(1.1721) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 25.0163, Epoch Time 408.0957(409.7669), Bit/dim 3.7203(best: 3.7191), Xent 2.3242, Loss 4.8824, Error 0.4029(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2635 | Time 61.2797(61.2973) | Bit/dim 3.6954(3.6995) | Xent 0.1286(0.1317) | Loss 3.7597(3.7654) | Error 0.0426(0.0445) Steps 694(680.89) | Grad Norm 0.9487(1.1654) | Total Time 14.00(14.00)\n",
      "Iter 2636 | Time 62.6176(61.3369) | Bit/dim 3.7026(3.6996) | Xent 0.1269(0.1316) | Loss 3.7660(3.7654) | Error 0.0413(0.0444) Steps 688(681.10) | Grad Norm 1.1729(1.1656) | Total Time 14.00(14.00)\n",
      "Iter 2637 | Time 60.0659(61.2987) | Bit/dim 3.6956(3.6995) | Xent 0.1286(0.1315) | Loss 3.7599(3.7652) | Error 0.0451(0.0444) Steps 676(680.95) | Grad Norm 1.0278(1.1615) | Total Time 14.00(14.00)\n",
      "Iter 2638 | Time 61.0721(61.2919) | Bit/dim 3.6995(3.6995) | Xent 0.1288(0.1314) | Loss 3.7639(3.7652) | Error 0.0433(0.0444) Steps 688(681.16) | Grad Norm 1.7912(1.1804) | Total Time 14.00(14.00)\n",
      "Iter 2639 | Time 62.9694(61.3423) | Bit/dim 3.7077(3.6997) | Xent 0.1278(0.1313) | Loss 3.7717(3.7654) | Error 0.0411(0.0443) Steps 694(681.55) | Grad Norm 1.1788(1.1803) | Total Time 14.00(14.00)\n",
      "Iter 2640 | Time 61.7504(61.3545) | Bit/dim 3.6980(3.6997) | Xent 0.1291(0.1312) | Loss 3.7626(3.7653) | Error 0.0447(0.0443) Steps 682(681.56) | Grad Norm 0.9510(1.1735) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 25.4718, Epoch Time 411.0962(409.8068), Bit/dim 3.7185(best: 3.7191), Xent 2.3129, Loss 4.8749, Error 0.4021(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2641 | Time 60.3835(61.3254) | Bit/dim 3.6979(3.6996) | Xent 0.1238(0.1310) | Loss 3.7597(3.7651) | Error 0.0415(0.0442) Steps 682(681.57) | Grad Norm 1.1011(1.1713) | Total Time 14.00(14.00)\n",
      "Iter 2642 | Time 57.8580(61.2214) | Bit/dim 3.6987(3.6996) | Xent 0.1278(0.1309) | Loss 3.7626(3.7651) | Error 0.0447(0.0442) Steps 682(681.59) | Grad Norm 0.9338(1.1642) | Total Time 14.00(14.00)\n",
      "Iter 2643 | Time 61.1745(61.2200) | Bit/dim 3.6951(3.6995) | Xent 0.1283(0.1308) | Loss 3.7592(3.7649) | Error 0.0414(0.0442) Steps 676(681.42) | Grad Norm 1.1497(1.1637) | Total Time 14.00(14.00)\n",
      "Iter 2644 | Time 60.9121(61.2107) | Bit/dim 3.6990(3.6995) | Xent 0.1303(0.1308) | Loss 3.7641(3.7649) | Error 0.0454(0.0442) Steps 682(681.44) | Grad Norm 0.8811(1.1552) | Total Time 14.00(14.00)\n",
      "Iter 2645 | Time 58.4102(61.1267) | Bit/dim 3.6907(3.6992) | Xent 0.1405(0.1311) | Loss 3.7610(3.7648) | Error 0.0464(0.0443) Steps 676(681.27) | Grad Norm 1.5073(1.1658) | Total Time 14.00(14.00)\n",
      "Iter 2646 | Time 59.3399(61.0731) | Bit/dim 3.7136(3.6996) | Xent 0.1233(0.1309) | Loss 3.7752(3.7651) | Error 0.0403(0.0441) Steps 682(681.30) | Grad Norm 1.3209(1.1705) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 25.3020, Epoch Time 399.3686(409.4936), Bit/dim 3.7190(best: 3.7185), Xent 2.3093, Loss 4.8737, Error 0.3995(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2647 | Time 59.4618(61.0248) | Bit/dim 3.6876(3.6993) | Xent 0.1375(0.1311) | Loss 3.7564(3.7648) | Error 0.0456(0.0442) Steps 682(681.32) | Grad Norm 1.3120(1.1747) | Total Time 14.00(14.00)\n",
      "Iter 2648 | Time 61.7216(61.0457) | Bit/dim 3.7082(3.6995) | Xent 0.1322(0.1311) | Loss 3.7743(3.7651) | Error 0.0465(0.0443) Steps 688(681.52) | Grad Norm 0.7887(1.1631) | Total Time 14.00(14.00)\n",
      "Iter 2649 | Time 62.3340(61.0843) | Bit/dim 3.7019(3.6996) | Xent 0.1276(0.1310) | Loss 3.7657(3.7651) | Error 0.0426(0.0442) Steps 682(681.53) | Grad Norm 1.4706(1.1723) | Total Time 14.00(14.00)\n",
      "Iter 2650 | Time 60.4117(61.0641) | Bit/dim 3.6948(3.6995) | Xent 0.1317(0.1310) | Loss 3.7607(3.7650) | Error 0.0434(0.0442) Steps 676(681.37) | Grad Norm 0.9793(1.1666) | Total Time 14.00(14.00)\n",
      "Iter 2651 | Time 63.0197(61.1228) | Bit/dim 3.6992(3.6994) | Xent 0.1306(0.1310) | Loss 3.7645(3.7650) | Error 0.0420(0.0441) Steps 682(681.38) | Grad Norm 0.9000(1.1586) | Total Time 14.00(14.00)\n",
      "Iter 2652 | Time 62.7035(61.1702) | Bit/dim 3.7041(3.6996) | Xent 0.1316(0.1310) | Loss 3.7699(3.7651) | Error 0.0450(0.0441) Steps 676(681.22) | Grad Norm 0.9211(1.1514) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 25.5621, Epoch Time 410.8736(409.5350), Bit/dim 3.7196(best: 3.7185), Xent 2.3154, Loss 4.8773, Error 0.4072(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2653 | Time 61.4069(61.1773) | Bit/dim 3.7058(3.6998) | Xent 0.1225(0.1308) | Loss 3.7671(3.7652) | Error 0.0423(0.0441) Steps 682(681.25) | Grad Norm 0.9183(1.1444) | Total Time 14.00(14.00)\n",
      "Iter 2654 | Time 62.0150(61.2025) | Bit/dim 3.7090(3.7001) | Xent 0.1316(0.1308) | Loss 3.7748(3.7655) | Error 0.0441(0.0441) Steps 682(681.27) | Grad Norm 0.8770(1.1364) | Total Time 14.00(14.00)\n",
      "Iter 2655 | Time 60.4506(61.1799) | Bit/dim 3.6904(3.6998) | Xent 0.1339(0.1309) | Loss 3.7573(3.7652) | Error 0.0449(0.0441) Steps 682(681.29) | Grad Norm 0.9480(1.1308) | Total Time 14.00(14.00)\n",
      "Iter 2656 | Time 64.0229(61.2652) | Bit/dim 3.6901(3.6995) | Xent 0.1223(0.1306) | Loss 3.7513(3.7648) | Error 0.0394(0.0440) Steps 670(680.95) | Grad Norm 1.0736(1.1291) | Total Time 14.00(14.00)\n",
      "Iter 2657 | Time 60.3482(61.2377) | Bit/dim 3.6965(3.6994) | Xent 0.1325(0.1307) | Loss 3.7628(3.7647) | Error 0.0430(0.0439) Steps 688(681.16) | Grad Norm 1.2190(1.1318) | Total Time 14.00(14.00)\n",
      "Iter 2658 | Time 61.6439(61.2499) | Bit/dim 3.7020(3.6995) | Xent 0.1236(0.1305) | Loss 3.7638(3.7647) | Error 0.0413(0.0439) Steps 688(681.37) | Grad Norm 0.7320(1.1198) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 25.1489, Epoch Time 410.8326(409.5740), Bit/dim 3.7202(best: 3.7185), Xent 2.3097, Loss 4.8750, Error 0.4034(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2659 | Time 60.8305(61.2373) | Bit/dim 3.7008(3.6995) | Xent 0.1252(0.1303) | Loss 3.7633(3.7647) | Error 0.0419(0.0438) Steps 682(681.39) | Grad Norm 0.8622(1.1120) | Total Time 14.00(14.00)\n",
      "Iter 2660 | Time 58.2754(61.1484) | Bit/dim 3.6970(3.6994) | Xent 0.1353(0.1305) | Loss 3.7646(3.7647) | Error 0.0456(0.0439) Steps 682(681.41) | Grad Norm 1.1800(1.1141) | Total Time 14.00(14.00)\n",
      "Iter 2661 | Time 59.7714(61.1071) | Bit/dim 3.7062(3.6996) | Xent 0.1167(0.1301) | Loss 3.7646(3.7647) | Error 0.0381(0.0437) Steps 688(681.60) | Grad Norm 0.9307(1.1086) | Total Time 14.00(14.00)\n",
      "Iter 2662 | Time 60.5702(61.0910) | Bit/dim 3.7076(3.6999) | Xent 0.1276(0.1300) | Loss 3.7714(3.7649) | Error 0.0426(0.0437) Steps 688(681.80) | Grad Norm 0.9006(1.1023) | Total Time 14.00(14.00)\n",
      "Iter 2663 | Time 60.7310(61.0802) | Bit/dim 3.6979(3.6998) | Xent 0.1190(0.1297) | Loss 3.7574(3.7646) | Error 0.0406(0.0436) Steps 700(682.34) | Grad Norm 0.9071(1.0965) | Total Time 14.00(14.00)\n",
      "Iter 2664 | Time 63.0760(61.1401) | Bit/dim 3.6883(3.6995) | Xent 0.1254(0.1295) | Loss 3.7511(3.7642) | Error 0.0433(0.0436) Steps 706(683.05) | Grad Norm 1.0068(1.0938) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 25.2442, Epoch Time 404.2769(409.4150), Bit/dim 3.7189(best: 3.7185), Xent 2.3313, Loss 4.8846, Error 0.4040(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2665 | Time 58.9911(61.0756) | Bit/dim 3.6970(3.6994) | Xent 0.1305(0.1296) | Loss 3.7623(3.7642) | Error 0.0415(0.0435) Steps 676(682.84) | Grad Norm 1.0643(1.0929) | Total Time 14.00(14.00)\n",
      "Iter 2666 | Time 60.8137(61.0678) | Bit/dim 3.6988(3.6994) | Xent 0.1248(0.1294) | Loss 3.7612(3.7641) | Error 0.0411(0.0434) Steps 682(682.81) | Grad Norm 1.0396(1.0913) | Total Time 14.00(14.00)\n",
      "Iter 2667 | Time 61.0140(61.0662) | Bit/dim 3.6958(3.6993) | Xent 0.1244(0.1293) | Loss 3.7580(3.7639) | Error 0.0403(0.0433) Steps 688(682.97) | Grad Norm 0.8627(1.0844) | Total Time 14.00(14.00)\n",
      "Iter 2668 | Time 63.0144(61.1246) | Bit/dim 3.6989(3.6993) | Xent 0.1261(0.1292) | Loss 3.7619(3.7638) | Error 0.0447(0.0434) Steps 658(682.22) | Grad Norm 1.3243(1.0916) | Total Time 14.00(14.00)\n",
      "Iter 2669 | Time 63.6649(61.2008) | Bit/dim 3.6983(3.6992) | Xent 0.1190(0.1289) | Loss 3.7578(3.7637) | Error 0.0405(0.0433) Steps 676(682.03) | Grad Norm 0.8254(1.0836) | Total Time 14.00(14.00)\n",
      "Iter 2670 | Time 61.8427(61.2201) | Bit/dim 3.7086(3.6995) | Xent 0.1273(0.1288) | Loss 3.7722(3.7639) | Error 0.0446(0.0433) Steps 676(681.85) | Grad Norm 0.8462(1.0765) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 25.4263, Epoch Time 410.5382(409.4487), Bit/dim 3.7200(best: 3.7185), Xent 2.2997, Loss 4.8698, Error 0.3972(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2671 | Time 59.1787(61.1588) | Bit/dim 3.7014(3.6996) | Xent 0.1180(0.1285) | Loss 3.7604(3.7638) | Error 0.0387(0.0432) Steps 670(681.50) | Grad Norm 1.0086(1.0745) | Total Time 14.00(14.00)\n",
      "Iter 2672 | Time 63.2384(61.2212) | Bit/dim 3.6968(3.6995) | Xent 0.1240(0.1284) | Loss 3.7589(3.7637) | Error 0.0423(0.0432) Steps 682(681.51) | Grad Norm 1.2587(1.0800) | Total Time 14.00(14.00)\n",
      "Iter 2673 | Time 62.2109(61.2509) | Bit/dim 3.7021(3.6996) | Xent 0.1319(0.1285) | Loss 3.7680(3.7638) | Error 0.0447(0.0432) Steps 688(681.71) | Grad Norm 1.2980(1.0866) | Total Time 14.00(14.00)\n",
      "Iter 2674 | Time 62.5302(61.2893) | Bit/dim 3.7007(3.6996) | Xent 0.1258(0.1284) | Loss 3.7636(3.7638) | Error 0.0414(0.0431) Steps 676(681.54) | Grad Norm 0.9685(1.0830) | Total Time 14.00(14.00)\n",
      "Iter 2675 | Time 60.8645(61.2765) | Bit/dim 3.6921(3.6994) | Xent 0.1245(0.1283) | Loss 3.7544(3.7635) | Error 0.0417(0.0431) Steps 688(681.73) | Grad Norm 1.2444(1.0879) | Total Time 14.00(14.00)\n",
      "Iter 2676 | Time 62.0726(61.3004) | Bit/dim 3.7018(3.6994) | Xent 0.1233(0.1281) | Loss 3.7635(3.7635) | Error 0.0393(0.0430) Steps 688(681.92) | Grad Norm 1.3176(1.0947) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 25.2127, Epoch Time 411.0876(409.4979), Bit/dim 3.7197(best: 3.7185), Xent 2.3565, Loss 4.8979, Error 0.4002(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2677 | Time 60.9466(61.2898) | Bit/dim 3.7016(3.6995) | Xent 0.1303(0.1282) | Loss 3.7668(3.7636) | Error 0.0440(0.0430) Steps 676(681.74) | Grad Norm 1.4698(1.1060) | Total Time 14.00(14.00)\n",
      "Iter 2678 | Time 61.6793(61.3015) | Bit/dim 3.7025(3.6996) | Xent 0.1254(0.1281) | Loss 3.7653(3.7637) | Error 0.0410(0.0430) Steps 688(681.93) | Grad Norm 0.8219(1.0975) | Total Time 14.00(14.00)\n",
      "Iter 2679 | Time 61.0478(61.2939) | Bit/dim 3.6957(3.6995) | Xent 0.1209(0.1279) | Loss 3.7562(3.7634) | Error 0.0414(0.0429) Steps 676(681.75) | Grad Norm 1.0910(1.0973) | Total Time 14.00(14.00)\n",
      "Iter 2680 | Time 62.0855(61.3176) | Bit/dim 3.6994(3.6995) | Xent 0.1310(0.1280) | Loss 3.7649(3.7635) | Error 0.0433(0.0429) Steps 676(681.58) | Grad Norm 2.0163(1.1248) | Total Time 14.00(14.00)\n",
      "Iter 2681 | Time 61.3446(61.3184) | Bit/dim 3.7045(3.6996) | Xent 0.1308(0.1281) | Loss 3.7699(3.7637) | Error 0.0433(0.0429) Steps 694(681.95) | Grad Norm 1.4006(1.1331) | Total Time 14.00(14.00)\n",
      "Iter 2682 | Time 58.9024(61.2460) | Bit/dim 3.6900(3.6993) | Xent 0.1301(0.1281) | Loss 3.7550(3.7634) | Error 0.0426(0.0429) Steps 676(681.77) | Grad Norm 0.9259(1.1269) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 25.2412, Epoch Time 406.8869(409.4196), Bit/dim 3.7199(best: 3.7185), Xent 2.3196, Loss 4.8797, Error 0.4007(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2683 | Time 59.9898(61.2083) | Bit/dim 3.6880(3.6990) | Xent 0.1280(0.1281) | Loss 3.7520(3.7631) | Error 0.0424(0.0429) Steps 682(681.78) | Grad Norm 1.1158(1.1266) | Total Time 14.00(14.00)\n",
      "Iter 2684 | Time 62.7749(61.2553) | Bit/dim 3.7097(3.6993) | Xent 0.1221(0.1279) | Loss 3.7708(3.7633) | Error 0.0430(0.0429) Steps 676(681.61) | Grad Norm 1.6258(1.1415) | Total Time 14.00(14.00)\n",
      "Iter 2685 | Time 61.3706(61.2587) | Bit/dim 3.6966(3.6992) | Xent 0.1261(0.1279) | Loss 3.7596(3.7632) | Error 0.0471(0.0430) Steps 688(681.80) | Grad Norm 1.1803(1.1427) | Total Time 14.00(14.00)\n",
      "Iter 2686 | Time 60.4688(61.2350) | Bit/dim 3.6909(3.6990) | Xent 0.1291(0.1279) | Loss 3.7555(3.7630) | Error 0.0445(0.0431) Steps 670(681.44) | Grad Norm 0.9082(1.1357) | Total Time 14.00(14.00)\n",
      "Iter 2687 | Time 63.0885(61.2906) | Bit/dim 3.7011(3.6991) | Xent 0.1173(0.1276) | Loss 3.7598(3.7629) | Error 0.0404(0.0430) Steps 676(681.28) | Grad Norm 0.9368(1.1297) | Total Time 14.00(14.00)\n",
      "Iter 2688 | Time 62.2299(61.3188) | Bit/dim 3.7061(3.6993) | Xent 0.1268(0.1276) | Loss 3.7695(3.7631) | Error 0.0439(0.0430) Steps 664(680.76) | Grad Norm 1.2502(1.1333) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 25.3603, Epoch Time 411.2533(409.4746), Bit/dim 3.7196(best: 3.7185), Xent 2.3633, Loss 4.9013, Error 0.4076(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2689 | Time 64.1864(61.4048) | Bit/dim 3.6966(3.6992) | Xent 0.1271(0.1276) | Loss 3.7601(3.7630) | Error 0.0417(0.0430) Steps 688(680.98) | Grad Norm 0.8806(1.1257) | Total Time 14.00(14.00)\n",
      "Iter 2690 | Time 60.2083(61.3689) | Bit/dim 3.7102(3.6995) | Xent 0.1207(0.1274) | Loss 3.7705(3.7632) | Error 0.0404(0.0429) Steps 682(681.01) | Grad Norm 1.0237(1.1227) | Total Time 14.00(14.00)\n",
      "Iter 2691 | Time 59.9254(61.3256) | Bit/dim 3.6937(3.6993) | Xent 0.1279(0.1274) | Loss 3.7577(3.7630) | Error 0.0421(0.0429) Steps 682(681.04) | Grad Norm 1.1980(1.1249) | Total Time 14.00(14.00)\n",
      "Iter 2692 | Time 61.6366(61.3350) | Bit/dim 3.6900(3.6991) | Xent 0.1255(0.1273) | Loss 3.7528(3.7627) | Error 0.0445(0.0429) Steps 682(681.07) | Grad Norm 1.3752(1.1324) | Total Time 14.00(14.00)\n",
      "Iter 2693 | Time 59.5102(61.2802) | Bit/dim 3.7007(3.6991) | Xent 0.1297(0.1274) | Loss 3.7656(3.7628) | Error 0.0440(0.0430) Steps 682(681.10) | Grad Norm 1.0424(1.1297) | Total Time 14.00(14.00)\n",
      "Iter 2694 | Time 59.8679(61.2379) | Bit/dim 3.6988(3.6991) | Xent 0.1345(0.1276) | Loss 3.7661(3.7629) | Error 0.0450(0.0430) Steps 676(680.94) | Grad Norm 1.4454(1.1392) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 25.2730, Epoch Time 406.3889(409.3820), Bit/dim 3.7190(best: 3.7185), Xent 2.3518, Loss 4.8949, Error 0.4009(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2695 | Time 60.5821(61.2182) | Bit/dim 3.6976(3.6991) | Xent 0.1282(0.1276) | Loss 3.7617(3.7629) | Error 0.0445(0.0431) Steps 670(680.62) | Grad Norm 1.3206(1.1447) | Total Time 14.00(14.00)\n",
      "Iter 2696 | Time 62.8958(61.2685) | Bit/dim 3.6963(3.6990) | Xent 0.1334(0.1278) | Loss 3.7630(3.7629) | Error 0.0447(0.0431) Steps 682(680.66) | Grad Norm 0.9107(1.1376) | Total Time 14.00(14.00)\n",
      "Iter 2697 | Time 62.8691(61.3165) | Bit/dim 3.6972(3.6989) | Xent 0.1256(0.1277) | Loss 3.7600(3.7628) | Error 0.0430(0.0431) Steps 688(680.88) | Grad Norm 1.0028(1.1336) | Total Time 14.00(14.00)\n",
      "Iter 2698 | Time 60.0161(61.2775) | Bit/dim 3.7060(3.6991) | Xent 0.1250(0.1276) | Loss 3.7685(3.7630) | Error 0.0424(0.0431) Steps 682(680.91) | Grad Norm 1.1963(1.1355) | Total Time 14.00(14.00)\n",
      "Iter 2699 | Time 60.9387(61.2674) | Bit/dim 3.7027(3.6992) | Xent 0.1180(0.1274) | Loss 3.7617(3.7629) | Error 0.0387(0.0430) Steps 688(681.12) | Grad Norm 0.9448(1.1298) | Total Time 14.00(14.00)\n",
      "Iter 2700 | Time 60.6491(61.2488) | Bit/dim 3.6940(3.6991) | Xent 0.1348(0.1276) | Loss 3.7614(3.7629) | Error 0.0454(0.0430) Steps 670(680.79) | Grad Norm 0.9441(1.1242) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 25.1433, Epoch Time 408.8958(409.3674), Bit/dim 3.7183(best: 3.7185), Xent 2.3493, Loss 4.8929, Error 0.4038(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2701 | Time 61.9791(61.2707) | Bit/dim 3.7138(3.6995) | Xent 0.1272(0.1276) | Loss 3.7774(3.7633) | Error 0.0425(0.0430) Steps 682(680.83) | Grad Norm 0.9904(1.1202) | Total Time 14.00(14.00)\n",
      "Iter 2702 | Time 63.5578(61.3393) | Bit/dim 3.6939(3.6994) | Xent 0.1271(0.1276) | Loss 3.7574(3.7631) | Error 0.0431(0.0430) Steps 688(681.04) | Grad Norm 1.2798(1.1250) | Total Time 14.00(14.00)\n",
      "Iter 2703 | Time 63.2368(61.3962) | Bit/dim 3.6819(3.6988) | Xent 0.1284(0.1276) | Loss 3.7461(3.7626) | Error 0.0427(0.0430) Steps 682(681.07) | Grad Norm 0.9230(1.1189) | Total Time 14.00(14.00)\n",
      "Iter 2704 | Time 62.9324(61.4423) | Bit/dim 3.7048(3.6990) | Xent 0.1172(0.1273) | Loss 3.7635(3.7626) | Error 0.0399(0.0429) Steps 682(681.10) | Grad Norm 1.1895(1.1210) | Total Time 14.00(14.00)\n",
      "Iter 2705 | Time 61.3873(61.4407) | Bit/dim 3.7029(3.6991) | Xent 0.1195(0.1270) | Loss 3.7626(3.7626) | Error 0.0399(0.0428) Steps 688(681.30) | Grad Norm 1.3385(1.1275) | Total Time 14.00(14.00)\n",
      "Iter 2706 | Time 62.1358(61.4615) | Bit/dim 3.6943(3.6990) | Xent 0.1368(0.1273) | Loss 3.7627(3.7626) | Error 0.0459(0.0429) Steps 694(681.69) | Grad Norm 1.0584(1.1255) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 25.1824, Epoch Time 416.0722(409.5686), Bit/dim 3.7192(best: 3.7183), Xent 2.3562, Loss 4.8972, Error 0.4015(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2707 | Time 61.3635(61.4586) | Bit/dim 3.6971(3.6989) | Xent 0.1200(0.1271) | Loss 3.7571(3.7625) | Error 0.0387(0.0428) Steps 682(681.70) | Grad Norm 0.9968(1.1216) | Total Time 14.00(14.00)\n",
      "Iter 2708 | Time 61.2043(61.4510) | Bit/dim 3.7019(3.6990) | Xent 0.1206(0.1269) | Loss 3.7622(3.7625) | Error 0.0415(0.0428) Steps 664(681.16) | Grad Norm 0.8960(1.1148) | Total Time 14.00(14.00)\n",
      "Iter 2709 | Time 60.5932(61.4252) | Bit/dim 3.6989(3.6990) | Xent 0.1183(0.1267) | Loss 3.7581(3.7623) | Error 0.0389(0.0426) Steps 670(680.83) | Grad Norm 0.8790(1.1078) | Total Time 14.00(14.00)\n",
      "Iter 2710 | Time 61.9202(61.4401) | Bit/dim 3.6932(3.6988) | Xent 0.1301(0.1268) | Loss 3.7583(3.7622) | Error 0.0431(0.0427) Steps 688(681.04) | Grad Norm 1.4372(1.1176) | Total Time 14.00(14.00)\n",
      "Iter 2711 | Time 61.9336(61.4549) | Bit/dim 3.7006(3.6989) | Xent 0.1262(0.1267) | Loss 3.7637(3.7623) | Error 0.0427(0.0427) Steps 682(681.07) | Grad Norm 1.1021(1.1172) | Total Time 14.00(14.00)\n",
      "Iter 2712 | Time 58.7539(61.3739) | Bit/dim 3.6950(3.6988) | Xent 0.1211(0.1266) | Loss 3.7556(3.7621) | Error 0.0420(0.0426) Steps 682(681.10) | Grad Norm 1.3495(1.1241) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 25.4143, Epoch Time 406.8024(409.4856), Bit/dim 3.7191(best: 3.7183), Xent 2.3262, Loss 4.8822, Error 0.4035(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2713 | Time 59.1157(61.3061) | Bit/dim 3.6970(3.6987) | Xent 0.1279(0.1266) | Loss 3.7609(3.7620) | Error 0.0427(0.0426) Steps 682(681.13) | Grad Norm 2.5237(1.1661) | Total Time 14.00(14.00)\n",
      "Iter 2714 | Time 58.4895(61.2216) | Bit/dim 3.7016(3.6988) | Xent 0.1165(0.1263) | Loss 3.7598(3.7620) | Error 0.0377(0.0425) Steps 676(680.97) | Grad Norm 1.4331(1.1741) | Total Time 14.00(14.00)\n",
      "Iter 2715 | Time 61.5136(61.2304) | Bit/dim 3.7051(3.6990) | Xent 0.1246(0.1263) | Loss 3.7674(3.7621) | Error 0.0407(0.0424) Steps 670(680.64) | Grad Norm 0.8754(1.1652) | Total Time 14.00(14.00)\n",
      "Iter 2716 | Time 61.2699(61.2316) | Bit/dim 3.6972(3.6989) | Xent 0.1232(0.1262) | Loss 3.7588(3.7620) | Error 0.0436(0.0425) Steps 670(680.33) | Grad Norm 2.0342(1.1912) | Total Time 14.00(14.00)\n",
      "Iter 2717 | Time 62.3099(61.2639) | Bit/dim 3.7065(3.6992) | Xent 0.1315(0.1263) | Loss 3.7723(3.7623) | Error 0.0434(0.0425) Steps 688(680.56) | Grad Norm 2.0833(1.2180) | Total Time 14.00(14.00)\n",
      "Iter 2718 | Time 60.8933(61.2528) | Bit/dim 3.6878(3.6988) | Xent 0.1195(0.1261) | Loss 3.7475(3.7619) | Error 0.0407(0.0425) Steps 670(680.24) | Grad Norm 1.0111(1.2118) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 25.2374, Epoch Time 404.7021(409.3421), Bit/dim 3.7198(best: 3.7183), Xent 2.3325, Loss 4.8860, Error 0.4003(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2719 | Time 59.4399(61.1984) | Bit/dim 3.7021(3.6989) | Xent 0.1297(0.1262) | Loss 3.7669(3.7620) | Error 0.0459(0.0426) Steps 676(680.11) | Grad Norm 1.8787(1.2318) | Total Time 14.00(14.00)\n",
      "Iter 2720 | Time 60.6201(61.1811) | Bit/dim 3.7028(3.6990) | Xent 0.1191(0.1260) | Loss 3.7623(3.7620) | Error 0.0383(0.0424) Steps 682(680.17) | Grad Norm 1.0045(1.2250) | Total Time 14.00(14.00)\n",
      "Iter 2721 | Time 62.3645(61.2166) | Bit/dim 3.6982(3.6990) | Xent 0.1257(0.1260) | Loss 3.7611(3.7620) | Error 0.0426(0.0424) Steps 682(680.22) | Grad Norm 1.1605(1.2231) | Total Time 14.00(14.00)\n",
      "Iter 2722 | Time 61.4268(61.2229) | Bit/dim 3.6982(3.6990) | Xent 0.1181(0.1258) | Loss 3.7573(3.7619) | Error 0.0395(0.0423) Steps 676(680.10) | Grad Norm 1.2102(1.2227) | Total Time 14.00(14.00)\n",
      "Iter 2723 | Time 59.5635(61.1731) | Bit/dim 3.6973(3.6989) | Xent 0.1356(0.1261) | Loss 3.7651(3.7620) | Error 0.0436(0.0424) Steps 688(680.33) | Grad Norm 1.3397(1.2262) | Total Time 14.00(14.00)\n",
      "Iter 2724 | Time 61.1606(61.1727) | Bit/dim 3.6969(3.6989) | Xent 0.1241(0.1260) | Loss 3.7589(3.7619) | Error 0.0410(0.0423) Steps 682(680.38) | Grad Norm 1.3450(1.2297) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 25.3714, Epoch Time 405.7060(409.2330), Bit/dim 3.7199(best: 3.7183), Xent 2.3545, Loss 4.8972, Error 0.4070(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2725 | Time 62.2676(61.2056) | Bit/dim 3.6976(3.6988) | Xent 0.1215(0.1259) | Loss 3.7583(3.7618) | Error 0.0383(0.0422) Steps 676(680.25) | Grad Norm 1.4682(1.2369) | Total Time 14.00(14.00)\n",
      "Iter 2726 | Time 61.8668(61.2254) | Bit/dim 3.6974(3.6988) | Xent 0.1286(0.1259) | Loss 3.7618(3.7618) | Error 0.0463(0.0423) Steps 694(680.66) | Grad Norm 1.2211(1.2364) | Total Time 14.00(14.00)\n",
      "Iter 2727 | Time 61.4007(61.2307) | Bit/dim 3.6978(3.6988) | Xent 0.1249(0.1259) | Loss 3.7603(3.7617) | Error 0.0421(0.0423) Steps 676(680.52) | Grad Norm 1.1485(1.2338) | Total Time 14.00(14.00)\n",
      "Iter 2728 | Time 59.3808(61.1752) | Bit/dim 3.6938(3.6986) | Xent 0.1196(0.1257) | Loss 3.7536(3.7615) | Error 0.0400(0.0423) Steps 676(680.39) | Grad Norm 1.4125(1.2391) | Total Time 14.00(14.00)\n",
      "Iter 2729 | Time 61.1234(61.1736) | Bit/dim 3.7027(3.6987) | Xent 0.1212(0.1256) | Loss 3.7633(3.7615) | Error 0.0414(0.0422) Steps 688(680.62) | Grad Norm 1.2474(1.2394) | Total Time 14.00(14.00)\n",
      "Iter 2730 | Time 64.0410(61.2596) | Bit/dim 3.6974(3.6987) | Xent 0.1210(0.1255) | Loss 3.7580(3.7614) | Error 0.0397(0.0422) Steps 682(680.66) | Grad Norm 1.4661(1.2462) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 25.4802, Epoch Time 411.0508(409.2875), Bit/dim 3.7191(best: 3.7183), Xent 2.3595, Loss 4.8988, Error 0.4011(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2731 | Time 61.3650(61.2628) | Bit/dim 3.6973(3.6987) | Xent 0.1228(0.1254) | Loss 3.7587(3.7614) | Error 0.0443(0.0422) Steps 694(681.06) | Grad Norm 1.1413(1.2430) | Total Time 14.00(14.00)\n",
      "Iter 2732 | Time 63.1495(61.3194) | Bit/dim 3.7014(3.6987) | Xent 0.1233(0.1253) | Loss 3.7631(3.7614) | Error 0.0421(0.0422) Steps 688(681.27) | Grad Norm 0.7720(1.2289) | Total Time 14.00(14.00)\n",
      "Iter 2733 | Time 60.6640(61.2997) | Bit/dim 3.6908(3.6985) | Xent 0.1195(0.1251) | Loss 3.7505(3.7611) | Error 0.0394(0.0421) Steps 682(681.29) | Grad Norm 1.3450(1.2324) | Total Time 14.00(14.00)\n",
      "Iter 2734 | Time 60.8267(61.2855) | Bit/dim 3.7024(3.6986) | Xent 0.1084(0.1246) | Loss 3.7566(3.7609) | Error 0.0364(0.0420) Steps 700(681.85) | Grad Norm 0.8715(1.2216) | Total Time 14.00(14.00)\n",
      "Iter 2735 | Time 60.8349(61.2720) | Bit/dim 3.6922(3.6984) | Xent 0.1144(0.1243) | Loss 3.7494(3.7606) | Error 0.0399(0.0419) Steps 694(682.22) | Grad Norm 1.5454(1.2313) | Total Time 14.00(14.00)\n",
      "Iter 2736 | Time 62.6194(61.3124) | Bit/dim 3.7039(3.6986) | Xent 0.1304(0.1245) | Loss 3.7691(3.7608) | Error 0.0436(0.0420) Steps 700(682.75) | Grad Norm 1.3762(1.2356) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 25.2618, Epoch Time 410.4447(409.3223), Bit/dim 3.7191(best: 3.7183), Xent 2.3977, Loss 4.9180, Error 0.4037(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2737 | Time 61.0084(61.3033) | Bit/dim 3.7020(3.6987) | Xent 0.1206(0.1244) | Loss 3.7623(3.7609) | Error 0.0399(0.0419) Steps 682(682.73) | Grad Norm 0.9894(1.2282) | Total Time 14.00(14.00)\n",
      "Iter 2738 | Time 61.1945(61.3000) | Bit/dim 3.6872(3.6984) | Xent 0.1197(0.1243) | Loss 3.7470(3.7605) | Error 0.0406(0.0419) Steps 688(682.88) | Grad Norm 1.0803(1.2238) | Total Time 14.00(14.00)\n",
      "Iter 2739 | Time 60.0208(61.2617) | Bit/dim 3.7020(3.6985) | Xent 0.1308(0.1244) | Loss 3.7674(3.7607) | Error 0.0446(0.0419) Steps 676(682.68) | Grad Norm 1.7622(1.2400) | Total Time 14.00(14.00)\n",
      "Iter 2740 | Time 63.4149(61.3263) | Bit/dim 3.6942(3.6983) | Xent 0.1195(0.1243) | Loss 3.7540(3.7605) | Error 0.0403(0.0419) Steps 682(682.66) | Grad Norm 1.3590(1.2435) | Total Time 14.00(14.00)\n",
      "Iter 2741 | Time 63.2071(61.3827) | Bit/dim 3.6982(3.6983) | Xent 0.1323(0.1245) | Loss 3.7643(3.7606) | Error 0.0461(0.0420) Steps 688(682.82) | Grad Norm 0.9336(1.2342) | Total Time 14.00(14.00)\n",
      "Iter 2742 | Time 60.8466(61.3666) | Bit/dim 3.6978(3.6983) | Xent 0.1209(0.1244) | Loss 3.7583(3.7605) | Error 0.0400(0.0420) Steps 682(682.79) | Grad Norm 1.0633(1.2291) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 25.3718, Epoch Time 410.8462(409.3680), Bit/dim 3.7192(best: 3.7183), Xent 2.3347, Loss 4.8866, Error 0.4024(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2743 | Time 59.8494(61.3211) | Bit/dim 3.6980(3.6983) | Xent 0.1186(0.1243) | Loss 3.7573(3.7604) | Error 0.0434(0.0420) Steps 688(682.95) | Grad Norm 1.7202(1.2438) | Total Time 14.00(14.00)\n",
      "Iter 2744 | Time 64.0185(61.4020) | Bit/dim 3.6996(3.6983) | Xent 0.1266(0.1243) | Loss 3.7629(3.7605) | Error 0.0406(0.0420) Steps 682(682.92) | Grad Norm 1.3338(1.2465) | Total Time 14.00(14.00)\n",
      "Iter 2745 | Time 63.6106(61.4683) | Bit/dim 3.6904(3.6981) | Xent 0.1141(0.1240) | Loss 3.7475(3.7601) | Error 0.0385(0.0418) Steps 676(682.71) | Grad Norm 1.0325(1.2401) | Total Time 14.00(14.00)\n",
      "Iter 2746 | Time 59.5773(61.4115) | Bit/dim 3.7063(3.6984) | Xent 0.1356(0.1244) | Loss 3.7741(3.7605) | Error 0.0469(0.0420) Steps 676(682.51) | Grad Norm 1.0529(1.2345) | Total Time 14.00(14.00)\n",
      "Iter 2747 | Time 60.5603(61.3860) | Bit/dim 3.7024(3.6985) | Xent 0.1263(0.1244) | Loss 3.7655(3.7607) | Error 0.0431(0.0420) Steps 676(682.32) | Grad Norm 1.4019(1.2395) | Total Time 14.00(14.00)\n",
      "Iter 2748 | Time 59.5401(61.3306) | Bit/dim 3.6928(3.6983) | Xent 0.1188(0.1243) | Loss 3.7522(3.7604) | Error 0.0415(0.0420) Steps 682(682.31) | Grad Norm 1.3544(1.2430) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 25.5156, Epoch Time 408.2987(409.3359), Bit/dim 3.7183(best: 3.7183), Xent 2.3510, Loss 4.8938, Error 0.4017(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2749 | Time 63.3833(61.3922) | Bit/dim 3.6932(3.6982) | Xent 0.1233(0.1242) | Loss 3.7549(3.7603) | Error 0.0430(0.0420) Steps 694(682.66) | Grad Norm 1.1216(1.2393) | Total Time 14.00(14.00)\n",
      "Iter 2750 | Time 60.8307(61.3754) | Bit/dim 3.7108(3.6985) | Xent 0.1171(0.1240) | Loss 3.7694(3.7605) | Error 0.0380(0.0419) Steps 688(682.82) | Grad Norm 0.9227(1.2298) | Total Time 14.00(14.00)\n",
      "Iter 2751 | Time 61.6626(61.3840) | Bit/dim 3.6961(3.6985) | Xent 0.1204(0.1239) | Loss 3.7563(3.7604) | Error 0.0396(0.0419) Steps 682(682.79) | Grad Norm 1.7195(1.2445) | Total Time 14.00(14.00)\n",
      "Iter 2752 | Time 60.4865(61.3571) | Bit/dim 3.6950(3.6984) | Xent 0.1184(0.1237) | Loss 3.7542(3.7602) | Error 0.0403(0.0418) Steps 694(683.13) | Grad Norm 1.3213(1.2468) | Total Time 14.00(14.00)\n",
      "Iter 2753 | Time 61.2967(61.3552) | Bit/dim 3.6957(3.6983) | Xent 0.1219(0.1237) | Loss 3.7567(3.7601) | Error 0.0415(0.0418) Steps 688(683.28) | Grad Norm 1.1084(1.2427) | Total Time 14.00(14.00)\n",
      "Iter 2754 | Time 62.6089(61.3929) | Bit/dim 3.7014(3.6984) | Xent 0.1158(0.1234) | Loss 3.7593(3.7601) | Error 0.0396(0.0417) Steps 682(683.24) | Grad Norm 0.8749(1.2316) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 25.1454, Epoch Time 410.7873(409.3794), Bit/dim 3.7198(best: 3.7183), Xent 2.3782, Loss 4.9089, Error 0.4035(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2755 | Time 60.0741(61.3533) | Bit/dim 3.7040(3.6985) | Xent 0.1219(0.1234) | Loss 3.7649(3.7602) | Error 0.0419(0.0417) Steps 682(683.20) | Grad Norm 1.4244(1.2374) | Total Time 14.00(14.00)\n",
      "Iter 2756 | Time 62.4714(61.3868) | Bit/dim 3.7060(3.6988) | Xent 0.1151(0.1232) | Loss 3.7635(3.7603) | Error 0.0395(0.0417) Steps 682(683.16) | Grad Norm 0.9550(1.2289) | Total Time 14.00(14.00)\n",
      "Iter 2757 | Time 59.8675(61.3413) | Bit/dim 3.7054(3.6990) | Xent 0.1209(0.1231) | Loss 3.7659(3.7605) | Error 0.0406(0.0416) Steps 682(683.13) | Grad Norm 0.9165(1.2196) | Total Time 14.00(14.00)\n",
      "Iter 2758 | Time 59.7531(61.2936) | Bit/dim 3.6924(3.6988) | Xent 0.1146(0.1228) | Loss 3.7497(3.7602) | Error 0.0390(0.0416) Steps 688(683.28) | Grad Norm 0.9743(1.2122) | Total Time 14.00(14.00)\n",
      "Iter 2759 | Time 63.7902(61.3685) | Bit/dim 3.7015(3.6988) | Xent 0.1301(0.1230) | Loss 3.7665(3.7604) | Error 0.0461(0.0417) Steps 694(683.60) | Grad Norm 1.4584(1.2196) | Total Time 14.00(14.00)\n",
      "Iter 2760 | Time 65.8424(61.5027) | Bit/dim 3.6810(3.6983) | Xent 0.1226(0.1230) | Loss 3.7423(3.7598) | Error 0.0416(0.0417) Steps 694(683.91) | Grad Norm 1.6010(1.2310) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 25.5556, Epoch Time 413.1768(409.4934), Bit/dim 3.7187(best: 3.7183), Xent 2.3910, Loss 4.9141, Error 0.4000(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2761 | Time 62.1839(61.5232) | Bit/dim 3.6882(3.6980) | Xent 0.1278(0.1232) | Loss 3.7521(3.7596) | Error 0.0433(0.0417) Steps 688(684.03) | Grad Norm 0.8640(1.2200) | Total Time 14.00(14.00)\n",
      "Iter 2762 | Time 62.8629(61.5634) | Bit/dim 3.7016(3.6981) | Xent 0.1272(0.1233) | Loss 3.7652(3.7598) | Error 0.0420(0.0417) Steps 682(683.97) | Grad Norm 0.9080(1.2107) | Total Time 14.00(14.00)\n",
      "Iter 2763 | Time 61.5795(61.5638) | Bit/dim 3.6993(3.6982) | Xent 0.1234(0.1233) | Loss 3.7611(3.7598) | Error 0.0435(0.0418) Steps 682(683.91) | Grad Norm 1.4148(1.2168) | Total Time 14.00(14.00)\n",
      "Iter 2764 | Time 61.0961(61.5498) | Bit/dim 3.7050(3.6984) | Xent 0.1289(0.1235) | Loss 3.7694(3.7601) | Error 0.0425(0.0418) Steps 670(683.49) | Grad Norm 1.4963(1.2252) | Total Time 14.00(14.00)\n",
      "Iter 2765 | Time 64.2690(61.6314) | Bit/dim 3.6981(3.6984) | Xent 0.1115(0.1231) | Loss 3.7538(3.7599) | Error 0.0370(0.0417) Steps 676(683.27) | Grad Norm 0.9155(1.2159) | Total Time 14.00(14.00)\n",
      "Iter 2766 | Time 62.5271(61.6582) | Bit/dim 3.6959(3.6983) | Xent 0.1173(0.1229) | Loss 3.7545(3.7597) | Error 0.0373(0.0415) Steps 682(683.23) | Grad Norm 1.2529(1.2170) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 25.5452, Epoch Time 416.0035(409.6887), Bit/dim 3.7185(best: 3.7183), Xent 2.3598, Loss 4.8983, Error 0.4020(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2767 | Time 60.0839(61.6110) | Bit/dim 3.7006(3.6983) | Xent 0.1179(0.1228) | Loss 3.7596(3.7597) | Error 0.0411(0.0415) Steps 688(683.37) | Grad Norm 1.1326(1.2145) | Total Time 14.00(14.00)\n",
      "Iter 2768 | Time 58.7504(61.5252) | Bit/dim 3.7059(3.6986) | Xent 0.1226(0.1228) | Loss 3.7673(3.7600) | Error 0.0415(0.0415) Steps 682(683.33) | Grad Norm 1.5877(1.2257) | Total Time 14.00(14.00)\n",
      "Iter 2769 | Time 61.4017(61.5215) | Bit/dim 3.6910(3.6983) | Xent 0.1184(0.1226) | Loss 3.7502(3.7597) | Error 0.0409(0.0415) Steps 682(683.29) | Grad Norm 0.9846(1.2184) | Total Time 14.00(14.00)\n",
      "Iter 2770 | Time 61.7453(61.5282) | Bit/dim 3.7016(3.6984) | Xent 0.1221(0.1226) | Loss 3.7626(3.7598) | Error 0.0411(0.0415) Steps 670(682.89) | Grad Norm 1.3319(1.2218) | Total Time 14.00(14.00)\n",
      "Iter 2771 | Time 62.6218(61.5610) | Bit/dim 3.6902(3.6982) | Xent 0.1261(0.1227) | Loss 3.7533(3.7596) | Error 0.0446(0.0416) Steps 676(682.69) | Grad Norm 0.9849(1.2147) | Total Time 14.00(14.00)\n",
      "Iter 2772 | Time 58.4706(61.4683) | Bit/dim 3.6995(3.6982) | Xent 0.1210(0.1227) | Loss 3.7600(3.7596) | Error 0.0386(0.0415) Steps 682(682.67) | Grad Norm 1.5022(1.2234) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 25.3056, Epoch Time 404.5946(409.5358), Bit/dim 3.7185(best: 3.7183), Xent 2.3478, Loss 4.8924, Error 0.4009(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2773 | Time 64.0537(61.5459) | Bit/dim 3.6971(3.6982) | Xent 0.1230(0.1227) | Loss 3.7586(3.7596) | Error 0.0420(0.0415) Steps 676(682.47) | Grad Norm 1.1495(1.2211) | Total Time 14.00(14.00)\n",
      "Iter 2774 | Time 63.5392(61.6057) | Bit/dim 3.7029(3.6983) | Xent 0.1195(0.1226) | Loss 3.7626(3.7596) | Error 0.0389(0.0414) Steps 682(682.45) | Grad Norm 1.1625(1.2194) | Total Time 14.00(14.00)\n",
      "Iter 2775 | Time 61.7067(61.6087) | Bit/dim 3.7003(3.6984) | Xent 0.1197(0.1225) | Loss 3.7602(3.7597) | Error 0.0396(0.0414) Steps 682(682.44) | Grad Norm 0.9886(1.2125) | Total Time 14.00(14.00)\n",
      "Iter 2776 | Time 61.6012(61.6085) | Bit/dim 3.6950(3.6983) | Xent 0.1236(0.1225) | Loss 3.7568(3.7596) | Error 0.0410(0.0414) Steps 676(682.25) | Grad Norm 1.1884(1.2117) | Total Time 14.00(14.00)\n",
      "Iter 2777 | Time 61.1410(61.5944) | Bit/dim 3.6989(3.6983) | Xent 0.1188(0.1224) | Loss 3.7583(3.7595) | Error 0.0383(0.0413) Steps 676(682.06) | Grad Norm 1.3586(1.2161) | Total Time 14.00(14.00)\n",
      "Iter 2778 | Time 60.2906(61.5553) | Bit/dim 3.6937(3.6982) | Xent 0.1149(0.1222) | Loss 3.7512(3.7593) | Error 0.0407(0.0413) Steps 676(681.88) | Grad Norm 0.9982(1.2096) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 25.3006, Epoch Time 413.4197(409.6524), Bit/dim 3.7194(best: 3.7183), Xent 2.4082, Loss 4.9234, Error 0.4067(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2779 | Time 61.1866(61.5443) | Bit/dim 3.7056(3.6984) | Xent 0.1245(0.1223) | Loss 3.7679(3.7595) | Error 0.0429(0.0413) Steps 688(682.06) | Grad Norm 1.3242(1.2130) | Total Time 14.00(14.00)\n",
      "Iter 2780 | Time 61.9434(61.5562) | Bit/dim 3.6950(3.6983) | Xent 0.1158(0.1221) | Loss 3.7529(3.7593) | Error 0.0381(0.0412) Steps 688(682.24) | Grad Norm 1.1001(1.2097) | Total Time 14.00(14.00)\n",
      "Iter 2781 | Time 62.1427(61.5738) | Bit/dim 3.6924(3.6981) | Xent 0.1234(0.1221) | Loss 3.7541(3.7592) | Error 0.0427(0.0413) Steps 670(681.87) | Grad Norm 1.3430(1.2137) | Total Time 14.00(14.00)\n",
      "Iter 2782 | Time 62.7938(61.6104) | Bit/dim 3.7002(3.6982) | Xent 0.1226(0.1221) | Loss 3.7615(3.7593) | Error 0.0411(0.0413) Steps 688(682.06) | Grad Norm 0.9357(1.2053) | Total Time 14.00(14.00)\n",
      "Iter 2783 | Time 59.4415(61.5454) | Bit/dim 3.6937(3.6981) | Xent 0.1344(0.1225) | Loss 3.7609(3.7593) | Error 0.0489(0.0415) Steps 682(682.05) | Grad Norm 1.0354(1.2002) | Total Time 14.00(14.00)\n",
      "Iter 2784 | Time 62.2487(61.5665) | Bit/dim 3.7023(3.6982) | Xent 0.1164(0.1223) | Loss 3.7605(3.7593) | Error 0.0390(0.0414) Steps 688(682.23) | Grad Norm 1.3938(1.2060) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 25.0456, Epoch Time 410.7743(409.6860), Bit/dim 3.7194(best: 3.7183), Xent 2.3814, Loss 4.9101, Error 0.4014(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2785 | Time 62.3541(61.5901) | Bit/dim 3.7006(3.6983) | Xent 0.1206(0.1223) | Loss 3.7609(3.7594) | Error 0.0413(0.0414) Steps 700(682.77) | Grad Norm 1.9671(1.2289) | Total Time 14.00(14.00)\n",
      "Iter 2786 | Time 58.9595(61.5112) | Bit/dim 3.6985(3.6983) | Xent 0.1262(0.1224) | Loss 3.7616(3.7595) | Error 0.0451(0.0415) Steps 670(682.38) | Grad Norm 1.1511(1.2265) | Total Time 14.00(14.00)\n",
      "Iter 2787 | Time 58.8801(61.4322) | Bit/dim 3.7012(3.6984) | Xent 0.1089(0.1220) | Loss 3.7556(3.7593) | Error 0.0381(0.0414) Steps 676(682.19) | Grad Norm 1.0001(1.2197) | Total Time 14.00(14.00)\n",
      "Iter 2788 | Time 61.1843(61.4248) | Bit/dim 3.6903(3.6981) | Xent 0.1179(0.1219) | Loss 3.7493(3.7590) | Error 0.0384(0.0413) Steps 694(682.55) | Grad Norm 2.1454(1.2475) | Total Time 14.00(14.00)\n",
      "Iter 2789 | Time 60.1576(61.3868) | Bit/dim 3.6961(3.6980) | Xent 0.1202(0.1218) | Loss 3.7562(3.7590) | Error 0.0410(0.0413) Steps 694(682.89) | Grad Norm 2.1762(1.2754) | Total Time 14.00(14.00)\n",
      "Iter 2790 | Time 59.8925(61.3420) | Bit/dim 3.6959(3.6980) | Xent 0.1265(0.1220) | Loss 3.7592(3.7590) | Error 0.0453(0.0414) Steps 670(682.50) | Grad Norm 1.0022(1.2672) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 24.8877, Epoch Time 402.2087(409.4617), Bit/dim 3.7192(best: 3.7183), Xent 2.3991, Loss 4.9187, Error 0.4043(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2791 | Time 62.0739(61.3639) | Bit/dim 3.6893(3.6977) | Xent 0.1161(0.1218) | Loss 3.7473(3.7586) | Error 0.0380(0.0413) Steps 700(683.03) | Grad Norm 1.5937(1.2770) | Total Time 14.00(14.00)\n",
      "Iter 2792 | Time 60.6679(61.3430) | Bit/dim 3.7108(3.6981) | Xent 0.1194(0.1217) | Loss 3.7705(3.7590) | Error 0.0401(0.0413) Steps 670(682.64) | Grad Norm 1.4014(1.2807) | Total Time 14.00(14.00)\n",
      "Iter 2793 | Time 62.8068(61.3870) | Bit/dim 3.6962(3.6981) | Xent 0.1224(0.1217) | Loss 3.7574(3.7589) | Error 0.0425(0.0413) Steps 664(682.08) | Grad Norm 2.6124(1.3206) | Total Time 14.00(14.00)\n",
      "Iter 2794 | Time 62.7274(61.4272) | Bit/dim 3.6865(3.6977) | Xent 0.1225(0.1217) | Loss 3.7477(3.7586) | Error 0.0394(0.0413) Steps 688(682.26) | Grad Norm 2.2676(1.3491) | Total Time 14.00(14.00)\n",
      "Iter 2795 | Time 58.9400(61.3526) | Bit/dim 3.6995(3.6978) | Xent 0.1298(0.1220) | Loss 3.7644(3.7588) | Error 0.0443(0.0414) Steps 688(682.43) | Grad Norm 1.3528(1.3492) | Total Time 14.00(14.00)\n",
      "Iter 2796 | Time 61.7459(61.3644) | Bit/dim 3.6984(3.6978) | Xent 0.1188(0.1219) | Loss 3.7578(3.7587) | Error 0.0405(0.0413) Steps 676(682.23) | Grad Norm 2.0319(1.3697) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 25.3139, Epoch Time 409.9294(409.4757), Bit/dim 3.7185(best: 3.7183), Xent 2.3597, Loss 4.8984, Error 0.4051(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2797 | Time 59.0136(61.2938) | Bit/dim 3.6982(3.6978) | Xent 0.1220(0.1219) | Loss 3.7592(3.7587) | Error 0.0400(0.0413) Steps 682(682.23) | Grad Norm 3.4344(1.4316) | Total Time 14.00(14.00)\n",
      "Iter 2798 | Time 61.9263(61.3128) | Bit/dim 3.7126(3.6982) | Xent 0.1295(0.1221) | Loss 3.7774(3.7593) | Error 0.0416(0.0413) Steps 676(682.04) | Grad Norm 1.8664(1.4446) | Total Time 14.00(14.00)\n",
      "Iter 2799 | Time 60.6492(61.2929) | Bit/dim 3.7007(3.6983) | Xent 0.1190(0.1220) | Loss 3.7602(3.7593) | Error 0.0413(0.0413) Steps 688(682.22) | Grad Norm 1.0567(1.4330) | Total Time 14.00(14.00)\n",
      "Iter 2800 | Time 61.2985(61.2931) | Bit/dim 3.6881(3.6980) | Xent 0.1157(0.1218) | Loss 3.7460(3.7589) | Error 0.0400(0.0413) Steps 682(682.21) | Grad Norm 1.8686(1.4461) | Total Time 14.00(14.00)\n",
      "Iter 2801 | Time 60.7512(61.2768) | Bit/dim 3.6992(3.6980) | Xent 0.1229(0.1219) | Loss 3.7607(3.7590) | Error 0.0415(0.0413) Steps 688(682.39) | Grad Norm 2.4493(1.4762) | Total Time 14.00(14.00)\n",
      "Iter 2802 | Time 62.6734(61.3187) | Bit/dim 3.6924(3.6979) | Xent 0.1117(0.1216) | Loss 3.7482(3.7587) | Error 0.0390(0.0412) Steps 694(682.73) | Grad Norm 1.6202(1.4805) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 25.4957, Epoch Time 407.5839(409.4190), Bit/dim 3.7191(best: 3.7183), Xent 2.3816, Loss 4.9099, Error 0.4060(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2803 | Time 62.5228(61.3548) | Bit/dim 3.6924(3.6977) | Xent 0.1134(0.1213) | Loss 3.7491(3.7584) | Error 0.0359(0.0410) Steps 682(682.71) | Grad Norm 0.8900(1.4628) | Total Time 14.00(14.00)\n",
      "Iter 2804 | Time 60.5691(61.3313) | Bit/dim 3.6990(3.6978) | Xent 0.1241(0.1214) | Loss 3.7611(3.7585) | Error 0.0413(0.0411) Steps 688(682.87) | Grad Norm 1.8211(1.4735) | Total Time 14.00(14.00)\n",
      "Iter 2805 | Time 61.4889(61.3360) | Bit/dim 3.6977(3.6977) | Xent 0.1197(0.1214) | Loss 3.7576(3.7584) | Error 0.0390(0.0410) Steps 676(682.67) | Grad Norm 1.3299(1.4692) | Total Time 14.00(14.00)\n",
      "Iter 2806 | Time 58.6296(61.2548) | Bit/dim 3.6965(3.6977) | Xent 0.1165(0.1212) | Loss 3.7548(3.7583) | Error 0.0383(0.0409) Steps 682(682.65) | Grad Norm 1.1341(1.4592) | Total Time 14.00(14.00)\n",
      "Iter 2807 | Time 60.4670(61.2312) | Bit/dim 3.7025(3.6979) | Xent 0.1179(0.1211) | Loss 3.7614(3.7584) | Error 0.0404(0.0409) Steps 688(682.81) | Grad Norm 0.8700(1.4415) | Total Time 14.00(14.00)\n",
      "Iter 2808 | Time 61.3616(61.2351) | Bit/dim 3.6890(3.6976) | Xent 0.1241(0.1212) | Loss 3.7511(3.7582) | Error 0.0427(0.0409) Steps 676(682.60) | Grad Norm 1.0739(1.4305) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 24.9350, Epoch Time 406.0598(409.3182), Bit/dim 3.7188(best: 3.7183), Xent 2.3955, Loss 4.9165, Error 0.4058(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2809 | Time 61.8988(61.2550) | Bit/dim 3.7110(3.6980) | Xent 0.1260(0.1213) | Loss 3.7740(3.7587) | Error 0.0424(0.0410) Steps 676(682.40) | Grad Norm 1.6794(1.4379) | Total Time 14.00(14.00)\n",
      "Iter 2810 | Time 58.2261(61.1641) | Bit/dim 3.6953(3.6979) | Xent 0.1253(0.1215) | Loss 3.7579(3.7586) | Error 0.0420(0.0410) Steps 676(682.21) | Grad Norm 0.8838(1.4213) | Total Time 14.00(14.00)\n",
      "Iter 2811 | Time 59.8335(61.1242) | Bit/dim 3.6953(3.6978) | Xent 0.1177(0.1214) | Loss 3.7542(3.7585) | Error 0.0396(0.0410) Steps 676(682.03) | Grad Norm 0.9054(1.4058) | Total Time 14.00(14.00)\n",
      "Iter 2812 | Time 62.7150(61.1719) | Bit/dim 3.7039(3.6980) | Xent 0.1153(0.1212) | Loss 3.7615(3.7586) | Error 0.0391(0.0409) Steps 682(682.02) | Grad Norm 0.9269(1.3915) | Total Time 14.00(14.00)\n",
      "Iter 2813 | Time 63.3397(61.2370) | Bit/dim 3.6983(3.6980) | Xent 0.1153(0.1210) | Loss 3.7559(3.7585) | Error 0.0401(0.0409) Steps 676(681.84) | Grad Norm 1.0475(1.3811) | Total Time 14.00(14.00)\n",
      "Iter 2814 | Time 60.0995(61.2028) | Bit/dim 3.6854(3.6976) | Xent 0.1332(0.1214) | Loss 3.7520(3.7583) | Error 0.0456(0.0410) Steps 682(681.85) | Grad Norm 0.9592(1.3685) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 24.9185, Epoch Time 407.0211(409.2493), Bit/dim 3.7187(best: 3.7183), Xent 2.3783, Loss 4.9079, Error 0.4019(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2815 | Time 60.9359(61.1948) | Bit/dim 3.6966(3.6976) | Xent 0.1142(0.1211) | Loss 3.7537(3.7582) | Error 0.0361(0.0409) Steps 676(681.67) | Grad Norm 0.9572(1.3561) | Total Time 14.00(14.00)\n",
      "Iter 2816 | Time 62.7223(61.2407) | Bit/dim 3.7029(3.6978) | Xent 0.1170(0.1210) | Loss 3.7614(3.7583) | Error 0.0389(0.0408) Steps 688(681.86) | Grad Norm 1.3674(1.3565) | Total Time 14.00(14.00)\n",
      "Iter 2817 | Time 60.9708(61.2326) | Bit/dim 3.6992(3.6978) | Xent 0.1260(0.1212) | Loss 3.7622(3.7584) | Error 0.0446(0.0409) Steps 688(682.05) | Grad Norm 1.1218(1.3494) | Total Time 14.00(14.00)\n",
      "Iter 2818 | Time 61.5565(61.2423) | Bit/dim 3.6926(3.6977) | Xent 0.1239(0.1212) | Loss 3.7546(3.7583) | Error 0.0437(0.0410) Steps 676(681.87) | Grad Norm 1.5007(1.3540) | Total Time 14.00(14.00)\n",
      "Iter 2819 | Time 61.6812(61.2554) | Bit/dim 3.7083(3.6980) | Xent 0.1272(0.1214) | Loss 3.7719(3.7587) | Error 0.0443(0.0411) Steps 688(682.05) | Grad Norm 1.1958(1.3492) | Total Time 14.00(14.00)\n",
      "Iter 2820 | Time 61.0417(61.2490) | Bit/dim 3.6899(3.6977) | Xent 0.1128(0.1212) | Loss 3.7463(3.7583) | Error 0.0386(0.0411) Steps 688(682.23) | Grad Norm 1.5548(1.3554) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 25.3121, Epoch Time 410.2944(409.2806), Bit/dim 3.7184(best: 3.7183), Xent 2.3575, Loss 4.8972, Error 0.4060(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2821 | Time 62.3474(61.2820) | Bit/dim 3.7002(3.6978) | Xent 0.1211(0.1212) | Loss 3.7608(3.7584) | Error 0.0419(0.0411) Steps 676(682.04) | Grad Norm 1.2970(1.3537) | Total Time 14.00(14.00)\n",
      "Iter 2822 | Time 63.0507(61.3350) | Bit/dim 3.6979(3.6978) | Xent 0.1216(0.1212) | Loss 3.7587(3.7584) | Error 0.0404(0.0411) Steps 676(681.86) | Grad Norm 1.3172(1.3526) | Total Time 14.00(14.00)\n",
      "Iter 2823 | Time 61.3544(61.3356) | Bit/dim 3.7073(3.6981) | Xent 0.1255(0.1213) | Loss 3.7700(3.7588) | Error 0.0419(0.0411) Steps 688(682.04) | Grad Norm 2.1976(1.3779) | Total Time 14.00(14.00)\n",
      "Iter 2824 | Time 59.8403(61.2908) | Bit/dim 3.6980(3.6981) | Xent 0.1135(0.1211) | Loss 3.7547(3.7586) | Error 0.0375(0.0410) Steps 688(682.22) | Grad Norm 1.2716(1.3747) | Total Time 14.00(14.00)\n",
      "Iter 2825 | Time 59.9623(61.2509) | Bit/dim 3.6924(3.6979) | Xent 0.1183(0.1210) | Loss 3.7516(3.7584) | Error 0.0396(0.0409) Steps 700(682.76) | Grad Norm 1.5813(1.3809) | Total Time 14.00(14.00)\n",
      "Iter 2826 | Time 63.5587(61.3201) | Bit/dim 3.6926(3.6978) | Xent 0.1173(0.1209) | Loss 3.7512(3.7582) | Error 0.0421(0.0410) Steps 682(682.73) | Grad Norm 1.0306(1.3704) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 25.1686, Epoch Time 411.0441(409.3335), Bit/dim 3.7188(best: 3.7183), Xent 2.3956, Loss 4.9167, Error 0.4082(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2827 | Time 58.7767(61.2438) | Bit/dim 3.6972(3.6978) | Xent 0.1182(0.1208) | Loss 3.7563(3.7581) | Error 0.0415(0.0410) Steps 694(683.07) | Grad Norm 2.0113(1.3896) | Total Time 14.00(14.00)\n",
      "Iter 2828 | Time 62.1930(61.2723) | Bit/dim 3.6964(3.6977) | Xent 0.1149(0.1206) | Loss 3.7538(3.7580) | Error 0.0393(0.0409) Steps 688(683.22) | Grad Norm 1.0554(1.3796) | Total Time 14.00(14.00)\n",
      "Iter 2829 | Time 61.3561(61.2748) | Bit/dim 3.7004(3.6978) | Xent 0.1143(0.1204) | Loss 3.7576(3.7580) | Error 0.0365(0.0408) Steps 682(683.18) | Grad Norm 0.8590(1.3640) | Total Time 14.00(14.00)\n",
      "Iter 2830 | Time 59.8698(61.2327) | Bit/dim 3.6954(3.6977) | Xent 0.1158(0.1203) | Loss 3.7533(3.7579) | Error 0.0369(0.0407) Steps 682(683.15) | Grad Norm 1.4584(1.3668) | Total Time 14.00(14.00)\n",
      "Iter 2831 | Time 62.2305(61.2626) | Bit/dim 3.6993(3.6978) | Xent 0.1173(0.1202) | Loss 3.7580(3.7579) | Error 0.0386(0.0406) Steps 688(683.29) | Grad Norm 1.4460(1.3692) | Total Time 14.00(14.00)\n",
      "Iter 2832 | Time 62.8286(61.3096) | Bit/dim 3.6948(3.6977) | Xent 0.1267(0.1204) | Loss 3.7581(3.7579) | Error 0.0435(0.0407) Steps 682(683.25) | Grad Norm 1.2720(1.3663) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 25.1208, Epoch Time 408.4342(409.3066), Bit/dim 3.7191(best: 3.7183), Xent 2.3722, Loss 4.9051, Error 0.4017(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2833 | Time 59.9969(61.2702) | Bit/dim 3.6946(3.6976) | Xent 0.1160(0.1203) | Loss 3.7526(3.7577) | Error 0.0394(0.0407) Steps 682(683.22) | Grad Norm 1.1469(1.3597) | Total Time 14.00(14.00)\n",
      "Iter 2834 | Time 62.0360(61.2932) | Bit/dim 3.7029(3.6977) | Xent 0.1129(0.1200) | Loss 3.7593(3.7578) | Error 0.0379(0.0406) Steps 682(683.18) | Grad Norm 0.8797(1.3453) | Total Time 14.00(14.00)\n",
      "Iter 2835 | Time 63.7195(61.3660) | Bit/dim 3.6947(3.6977) | Xent 0.1195(0.1200) | Loss 3.7544(3.7577) | Error 0.0399(0.0406) Steps 688(683.32) | Grad Norm 1.3561(1.3456) | Total Time 14.00(14.00)\n",
      "Iter 2836 | Time 61.4501(61.3685) | Bit/dim 3.7031(3.6978) | Xent 0.1202(0.1200) | Loss 3.7632(3.7578) | Error 0.0441(0.0407) Steps 676(683.10) | Grad Norm 0.9471(1.3337) | Total Time 14.00(14.00)\n",
      "Iter 2837 | Time 61.3257(61.3672) | Bit/dim 3.6931(3.6977) | Xent 0.1136(0.1198) | Loss 3.7499(3.7576) | Error 0.0400(0.0406) Steps 682(683.07) | Grad Norm 1.5258(1.3394) | Total Time 14.00(14.00)\n",
      "Iter 2838 | Time 62.4916(61.4009) | Bit/dim 3.6960(3.6976) | Xent 0.1330(0.1202) | Loss 3.7625(3.7577) | Error 0.0455(0.0408) Steps 688(683.22) | Grad Norm 1.4641(1.3432) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 25.4594, Epoch Time 412.0222(409.3880), Bit/dim 3.7195(best: 3.7183), Xent 2.4002, Loss 4.9196, Error 0.4020(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2839 | Time 62.2177(61.4254) | Bit/dim 3.7041(3.6978) | Xent 0.1253(0.1204) | Loss 3.7668(3.7580) | Error 0.0430(0.0409) Steps 682(683.18) | Grad Norm 1.3360(1.3430) | Total Time 14.00(14.00)\n",
      "Iter 2840 | Time 61.0399(61.4139) | Bit/dim 3.7023(3.6980) | Xent 0.1157(0.1202) | Loss 3.7602(3.7581) | Error 0.0384(0.0408) Steps 682(683.15) | Grad Norm 0.8249(1.3274) | Total Time 14.00(14.00)\n",
      "Iter 2841 | Time 60.8149(61.3959) | Bit/dim 3.6980(3.6980) | Xent 0.1216(0.1203) | Loss 3.7588(3.7581) | Error 0.0404(0.0408) Steps 688(683.29) | Grad Norm 1.7294(1.3395) | Total Time 14.00(14.00)\n",
      "Iter 2842 | Time 59.4361(61.3371) | Bit/dim 3.6934(3.6978) | Xent 0.1184(0.1202) | Loss 3.7526(3.7579) | Error 0.0381(0.0407) Steps 694(683.61) | Grad Norm 1.4394(1.3425) | Total Time 14.00(14.00)\n",
      "Iter 2843 | Time 60.1029(61.3001) | Bit/dim 3.7009(3.6979) | Xent 0.1255(0.1204) | Loss 3.7636(3.7581) | Error 0.0439(0.0408) Steps 682(683.57) | Grad Norm 0.8384(1.3274) | Total Time 14.00(14.00)\n",
      "Iter 2844 | Time 63.2544(61.3587) | Bit/dim 3.6840(3.6975) | Xent 0.1188(0.1203) | Loss 3.7434(3.7577) | Error 0.0406(0.0408) Steps 676(683.34) | Grad Norm 0.7336(1.3095) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 25.3702, Epoch Time 407.8330(409.3414), Bit/dim 3.7181(best: 3.7183), Xent 2.3971, Loss 4.9167, Error 0.4034(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2845 | Time 61.5826(61.3654) | Bit/dim 3.6890(3.6972) | Xent 0.1183(0.1203) | Loss 3.7482(3.7574) | Error 0.0393(0.0407) Steps 682(683.30) | Grad Norm 1.6976(1.3212) | Total Time 14.00(14.00)\n",
      "Iter 2846 | Time 59.8002(61.3185) | Bit/dim 3.7047(3.6975) | Xent 0.1215(0.1203) | Loss 3.7654(3.7576) | Error 0.0401(0.0407) Steps 676(683.08) | Grad Norm 0.9435(1.3099) | Total Time 14.00(14.00)\n",
      "Iter 2847 | Time 59.9714(61.2781) | Bit/dim 3.7026(3.6976) | Xent 0.1195(0.1203) | Loss 3.7624(3.7578) | Error 0.0417(0.0408) Steps 676(682.87) | Grad Norm 1.2394(1.3077) | Total Time 14.00(14.00)\n",
      "Iter 2848 | Time 60.5750(61.2570) | Bit/dim 3.6926(3.6975) | Xent 0.1182(0.1202) | Loss 3.7517(3.7576) | Error 0.0399(0.0407) Steps 670(682.48) | Grad Norm 1.1123(1.3019) | Total Time 14.00(14.00)\n",
      "Iter 2849 | Time 63.1943(61.3151) | Bit/dim 3.6910(3.6973) | Xent 0.1165(0.1201) | Loss 3.7493(3.7573) | Error 0.0389(0.0407) Steps 676(682.29) | Grad Norm 1.1392(1.2970) | Total Time 14.00(14.00)\n",
      "Iter 2850 | Time 61.6448(61.3250) | Bit/dim 3.6980(3.6973) | Xent 0.1262(0.1203) | Loss 3.7611(3.7574) | Error 0.0416(0.0407) Steps 670(681.92) | Grad Norm 0.9847(1.2876) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 24.9507, Epoch Time 407.1508(409.2757), Bit/dim 3.7178(best: 3.7181), Xent 2.3875, Loss 4.9116, Error 0.3994(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2851 | Time 60.0951(61.2881) | Bit/dim 3.6847(3.6969) | Xent 0.1166(0.1202) | Loss 3.7430(3.7570) | Error 0.0406(0.0407) Steps 688(682.10) | Grad Norm 1.4300(1.2919) | Total Time 14.00(14.00)\n",
      "Iter 2852 | Time 59.3504(61.2300) | Bit/dim 3.7019(3.6971) | Xent 0.1107(0.1199) | Loss 3.7573(3.7570) | Error 0.0366(0.0406) Steps 694(682.46) | Grad Norm 0.9094(1.2804) | Total Time 14.00(14.00)\n",
      "Iter 2853 | Time 63.9461(61.3114) | Bit/dim 3.7004(3.6972) | Xent 0.1164(0.1198) | Loss 3.7587(3.7571) | Error 0.0413(0.0406) Steps 682(682.44) | Grad Norm 1.0482(1.2735) | Total Time 14.00(14.00)\n",
      "Iter 2854 | Time 61.3422(61.3124) | Bit/dim 3.7094(3.6975) | Xent 0.1172(0.1197) | Loss 3.7680(3.7574) | Error 0.0386(0.0405) Steps 676(682.25) | Grad Norm 1.1841(1.2708) | Total Time 14.00(14.00)\n",
      "Iter 2855 | Time 57.7524(61.2056) | Bit/dim 3.6938(3.6974) | Xent 0.1151(0.1196) | Loss 3.7514(3.7572) | Error 0.0369(0.0404) Steps 676(682.06) | Grad Norm 1.1029(1.2657) | Total Time 14.00(14.00)\n",
      "Iter 2856 | Time 60.3711(61.1805) | Bit/dim 3.6982(3.6974) | Xent 0.1173(0.1195) | Loss 3.7568(3.7572) | Error 0.0393(0.0404) Steps 688(682.24) | Grad Norm 1.5043(1.2729) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 25.1038, Epoch Time 403.8809(409.1138), Bit/dim 3.7196(best: 3.7178), Xent 2.4114, Loss 4.9253, Error 0.4053(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2857 | Time 62.2800(61.2135) | Bit/dim 3.6871(3.6971) | Xent 0.1272(0.1197) | Loss 3.7507(3.7570) | Error 0.0404(0.0404) Steps 676(682.05) | Grad Norm 1.2619(1.2726) | Total Time 14.00(14.00)\n",
      "Iter 2858 | Time 61.5829(61.2246) | Bit/dim 3.6936(3.6970) | Xent 0.1110(0.1195) | Loss 3.7491(3.7568) | Error 0.0401(0.0404) Steps 676(681.87) | Grad Norm 1.0664(1.2664) | Total Time 14.00(14.00)\n",
      "Iter 2859 | Time 60.8349(61.2129) | Bit/dim 3.6966(3.6970) | Xent 0.1186(0.1195) | Loss 3.7559(3.7567) | Error 0.0384(0.0403) Steps 676(681.70) | Grad Norm 1.0152(1.2588) | Total Time 14.00(14.00)\n",
      "Iter 2860 | Time 63.5186(61.2821) | Bit/dim 3.7022(3.6972) | Xent 0.1182(0.1194) | Loss 3.7613(3.7569) | Error 0.0385(0.0403) Steps 676(681.53) | Grad Norm 0.9953(1.2509) | Total Time 14.00(14.00)\n",
      "Iter 2861 | Time 61.8466(61.2990) | Bit/dim 3.6891(3.6969) | Xent 0.1114(0.1192) | Loss 3.7447(3.7565) | Error 0.0390(0.0402) Steps 688(681.72) | Grad Norm 1.1737(1.2486) | Total Time 14.00(14.00)\n",
      "Iter 2862 | Time 57.5374(61.1862) | Bit/dim 3.7092(3.6973) | Xent 0.1169(0.1191) | Loss 3.7677(3.7569) | Error 0.0391(0.0402) Steps 682(681.73) | Grad Norm 0.9389(1.2393) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 25.3574, Epoch Time 409.3451(409.1208), Bit/dim 3.7188(best: 3.7178), Xent 2.3911, Loss 4.9143, Error 0.4035(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2863 | Time 59.2133(61.1270) | Bit/dim 3.7094(3.6977) | Xent 0.1247(0.1193) | Loss 3.7718(3.7573) | Error 0.0417(0.0402) Steps 688(681.92) | Grad Norm 0.8439(1.2275) | Total Time 14.00(14.00)\n",
      "Iter 2864 | Time 62.0304(61.1541) | Bit/dim 3.7043(3.6979) | Xent 0.1178(0.1192) | Loss 3.7632(3.7575) | Error 0.0381(0.0402) Steps 682(681.92) | Grad Norm 1.2336(1.2277) | Total Time 14.00(14.00)\n",
      "Iter 2865 | Time 62.9080(61.2067) | Bit/dim 3.6959(3.6978) | Xent 0.1198(0.1193) | Loss 3.7558(3.7574) | Error 0.0419(0.0402) Steps 670(681.56) | Grad Norm 1.0930(1.2236) | Total Time 14.00(14.00)\n",
      "Iter 2866 | Time 61.2510(61.2080) | Bit/dim 3.6872(3.6975) | Xent 0.1207(0.1193) | Loss 3.7475(3.7571) | Error 0.0405(0.0402) Steps 682(681.57) | Grad Norm 1.1260(1.2207) | Total Time 14.00(14.00)\n",
      "Iter 2867 | Time 58.4504(61.1253) | Bit/dim 3.6935(3.6974) | Xent 0.1123(0.1191) | Loss 3.7496(3.7569) | Error 0.0396(0.0402) Steps 688(681.77) | Grad Norm 1.3715(1.2252) | Total Time 14.00(14.00)\n",
      "Iter 2868 | Time 59.2268(61.0683) | Bit/dim 3.6966(3.6973) | Xent 0.1123(0.1189) | Loss 3.7527(3.7568) | Error 0.0370(0.0401) Steps 664(681.23) | Grad Norm 1.0911(1.2212) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 25.6555, Epoch Time 404.8300(408.9920), Bit/dim 3.7191(best: 3.7178), Xent 2.4438, Loss 4.9410, Error 0.4043(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2869 | Time 59.7195(61.0279) | Bit/dim 3.7032(3.6975) | Xent 0.1240(0.1190) | Loss 3.7652(3.7570) | Error 0.0415(0.0402) Steps 664(680.72) | Grad Norm 1.3905(1.2263) | Total Time 14.00(14.00)\n",
      "Iter 2870 | Time 60.9630(61.0259) | Bit/dim 3.6964(3.6975) | Xent 0.1174(0.1190) | Loss 3.7551(3.7570) | Error 0.0430(0.0402) Steps 688(680.94) | Grad Norm 0.9888(1.2191) | Total Time 14.00(14.00)\n",
      "Iter 2871 | Time 60.3139(61.0046) | Bit/dim 3.6985(3.6975) | Xent 0.1098(0.1187) | Loss 3.7534(3.7569) | Error 0.0367(0.0401) Steps 676(680.79) | Grad Norm 0.8566(1.2083) | Total Time 14.00(14.00)\n",
      "Iter 2872 | Time 61.0233(61.0051) | Bit/dim 3.6980(3.6975) | Xent 0.1053(0.1183) | Loss 3.7506(3.7567) | Error 0.0349(0.0400) Steps 676(680.64) | Grad Norm 0.8717(1.1982) | Total Time 14.00(14.00)\n",
      "Iter 2873 | Time 59.5248(60.9607) | Bit/dim 3.6936(3.6974) | Xent 0.1212(0.1184) | Loss 3.7542(3.7566) | Error 0.0405(0.0400) Steps 670(680.32) | Grad Norm 1.5742(1.2094) | Total Time 14.00(14.00)\n",
      "Iter 2874 | Time 60.0725(60.9341) | Bit/dim 3.6912(3.6972) | Xent 0.1152(0.1183) | Loss 3.7487(3.7564) | Error 0.0393(0.0400) Steps 694(680.73) | Grad Norm 0.9198(1.2008) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 25.3191, Epoch Time 402.7002(408.8033), Bit/dim 3.7186(best: 3.7178), Xent 2.3817, Loss 4.9095, Error 0.4036(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2875 | Time 58.8042(60.8702) | Bit/dim 3.7038(3.6974) | Xent 0.1117(0.1181) | Loss 3.7596(3.7565) | Error 0.0381(0.0399) Steps 688(680.95) | Grad Norm 1.5671(1.2117) | Total Time 14.00(14.00)\n",
      "Iter 2876 | Time 61.1494(60.8786) | Bit/dim 3.7039(3.6976) | Xent 0.1198(0.1181) | Loss 3.7638(3.7567) | Error 0.0397(0.0399) Steps 688(681.16) | Grad Norm 1.4852(1.2199) | Total Time 14.00(14.00)\n",
      "Iter 2877 | Time 61.2811(60.8906) | Bit/dim 3.6806(3.6971) | Xent 0.1181(0.1181) | Loss 3.7396(3.7562) | Error 0.0400(0.0399) Steps 676(681.01) | Grad Norm 1.0907(1.2161) | Total Time 14.00(14.00)\n",
      "Iter 2878 | Time 62.2264(60.9307) | Bit/dim 3.6941(3.6970) | Xent 0.1055(0.1178) | Loss 3.7469(3.7559) | Error 0.0339(0.0397) Steps 682(681.04) | Grad Norm 1.1943(1.2154) | Total Time 14.00(14.00)\n",
      "Iter 2879 | Time 61.0724(60.9350) | Bit/dim 3.6940(3.6969) | Xent 0.1163(0.1177) | Loss 3.7521(3.7558) | Error 0.0383(0.0397) Steps 688(681.25) | Grad Norm 1.5756(1.2262) | Total Time 14.00(14.00)\n",
      "Iter 2880 | Time 60.1956(60.9128) | Bit/dim 3.7046(3.6972) | Xent 0.1199(0.1178) | Loss 3.7645(3.7560) | Error 0.0401(0.0397) Steps 682(681.27) | Grad Norm 1.6121(1.2378) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 25.5537, Epoch Time 406.0464(408.7206), Bit/dim 3.7178(best: 3.7178), Xent 2.4143, Loss 4.9249, Error 0.4030(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2881 | Time 58.3645(60.8363) | Bit/dim 3.6976(3.6972) | Xent 0.1191(0.1178) | Loss 3.7571(3.7561) | Error 0.0395(0.0397) Steps 676(681.11) | Grad Norm 1.2051(1.2368) | Total Time 14.00(14.00)\n",
      "Iter 2882 | Time 61.1856(60.8468) | Bit/dim 3.6837(3.6968) | Xent 0.1122(0.1177) | Loss 3.7398(3.7556) | Error 0.0356(0.0396) Steps 688(681.32) | Grad Norm 1.0725(1.2319) | Total Time 14.00(14.00)\n",
      "Iter 2883 | Time 58.5233(60.7771) | Bit/dim 3.6989(3.6968) | Xent 0.1182(0.1177) | Loss 3.7580(3.7557) | Error 0.0396(0.0396) Steps 670(680.98) | Grad Norm 1.7377(1.2471) | Total Time 14.00(14.00)\n",
      "Iter 2884 | Time 60.1108(60.7571) | Bit/dim 3.7024(3.6970) | Xent 0.1074(0.1174) | Loss 3.7561(3.7557) | Error 0.0360(0.0395) Steps 670(680.65) | Grad Norm 0.9481(1.2381) | Total Time 14.00(14.00)\n",
      "Iter 2885 | Time 61.8592(60.7902) | Bit/dim 3.6980(3.6970) | Xent 0.1224(0.1175) | Loss 3.7592(3.7558) | Error 0.0425(0.0396) Steps 688(680.87) | Grad Norm 1.3881(1.2426) | Total Time 14.00(14.00)\n",
      "Iter 2886 | Time 57.8483(60.7019) | Bit/dim 3.6994(3.6971) | Xent 0.1178(0.1175) | Loss 3.7583(3.7559) | Error 0.0407(0.0396) Steps 676(680.72) | Grad Norm 1.7152(1.2568) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 25.1826, Epoch Time 399.1215(408.4326), Bit/dim 3.7190(best: 3.7178), Xent 2.3920, Loss 4.9150, Error 0.3995(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2887 | Time 61.2470(60.7183) | Bit/dim 3.6957(3.6971) | Xent 0.1090(0.1173) | Loss 3.7502(3.7557) | Error 0.0360(0.0395) Steps 682(680.76) | Grad Norm 1.0835(1.2516) | Total Time 14.00(14.00)\n",
      "Iter 2888 | Time 61.4524(60.7403) | Bit/dim 3.6953(3.6970) | Xent 0.1138(0.1172) | Loss 3.7522(3.7556) | Error 0.0364(0.0394) Steps 670(680.44) | Grad Norm 1.0131(1.2444) | Total Time 14.00(14.00)\n",
      "Iter 2889 | Time 60.5319(60.7340) | Bit/dim 3.6955(3.6970) | Xent 0.1122(0.1170) | Loss 3.7516(3.7555) | Error 0.0361(0.0393) Steps 670(680.13) | Grad Norm 1.3937(1.2489) | Total Time 14.00(14.00)\n",
      "Iter 2890 | Time 63.5758(60.8193) | Bit/dim 3.7028(3.6971) | Xent 0.1091(0.1168) | Loss 3.7573(3.7555) | Error 0.0369(0.0392) Steps 700(680.72) | Grad Norm 1.2392(1.2486) | Total Time 14.00(14.00)\n",
      "Iter 2891 | Time 61.2996(60.8337) | Bit/dim 3.6935(3.6970) | Xent 0.1216(0.1169) | Loss 3.7543(3.7555) | Error 0.0423(0.0393) Steps 676(680.58) | Grad Norm 1.0878(1.2438) | Total Time 14.00(14.00)\n",
      "Iter 2892 | Time 64.0079(60.9289) | Bit/dim 3.6981(3.6971) | Xent 0.1147(0.1169) | Loss 3.7554(3.7555) | Error 0.0387(0.0393) Steps 682(680.62) | Grad Norm 0.8105(1.2308) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 25.1879, Epoch Time 413.0326(408.5706), Bit/dim 3.7174(best: 3.7178), Xent 2.4363, Loss 4.9355, Error 0.4054(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2893 | Time 62.5871(60.9787) | Bit/dim 3.6891(3.6968) | Xent 0.1135(0.1168) | Loss 3.7459(3.7552) | Error 0.0377(0.0393) Steps 694(681.02) | Grad Norm 1.5764(1.2412) | Total Time 14.00(14.00)\n",
      "Iter 2894 | Time 63.3433(61.0496) | Bit/dim 3.7042(3.6970) | Xent 0.1092(0.1165) | Loss 3.7588(3.7553) | Error 0.0373(0.0392) Steps 676(680.87) | Grad Norm 0.9840(1.2334) | Total Time 14.00(14.00)\n",
      "Iter 2895 | Time 59.8231(61.0128) | Bit/dim 3.6963(3.6970) | Xent 0.1186(0.1166) | Loss 3.7556(3.7553) | Error 0.0416(0.0393) Steps 688(681.09) | Grad Norm 1.1533(1.2310) | Total Time 14.00(14.00)\n",
      "Iter 2896 | Time 62.1935(61.0482) | Bit/dim 3.6905(3.6968) | Xent 0.1199(0.1167) | Loss 3.7504(3.7552) | Error 0.0396(0.0393) Steps 682(681.12) | Grad Norm 0.7696(1.2172) | Total Time 14.00(14.00)\n",
      "Iter 2897 | Time 63.0406(61.1080) | Bit/dim 3.6904(3.6966) | Xent 0.1143(0.1166) | Loss 3.7475(3.7549) | Error 0.0383(0.0392) Steps 682(681.14) | Grad Norm 0.9552(1.2093) | Total Time 14.00(14.00)\n",
      "Iter 2898 | Time 61.5148(61.1202) | Bit/dim 3.7058(3.6969) | Xent 0.1135(0.1165) | Loss 3.7625(3.7552) | Error 0.0381(0.0392) Steps 694(681.53) | Grad Norm 1.4837(1.2176) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 25.2249, Epoch Time 413.2534(408.7111), Bit/dim 3.7193(best: 3.7174), Xent 2.4252, Loss 4.9319, Error 0.3993(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2899 | Time 61.2584(61.1244) | Bit/dim 3.6952(3.6969) | Xent 0.1124(0.1164) | Loss 3.7514(3.7551) | Error 0.0395(0.0392) Steps 682(681.54) | Grad Norm 1.0058(1.2112) | Total Time 14.00(14.00)\n",
      "Iter 2900 | Time 62.7424(61.1729) | Bit/dim 3.7036(3.6971) | Xent 0.1080(0.1162) | Loss 3.7575(3.7551) | Error 0.0375(0.0392) Steps 682(681.56) | Grad Norm 1.4901(1.2196) | Total Time 14.00(14.00)\n",
      "Iter 2901 | Time 60.9152(61.1652) | Bit/dim 3.6948(3.6970) | Xent 0.1103(0.1160) | Loss 3.7500(3.7550) | Error 0.0365(0.0391) Steps 664(681.03) | Grad Norm 1.4411(1.2262) | Total Time 14.00(14.00)\n",
      "Iter 2902 | Time 61.2486(61.1677) | Bit/dim 3.6898(3.6968) | Xent 0.1181(0.1160) | Loss 3.7488(3.7548) | Error 0.0400(0.0391) Steps 676(680.88) | Grad Norm 1.9448(1.2478) | Total Time 14.00(14.00)\n",
      "Iter 2903 | Time 61.8584(61.1884) | Bit/dim 3.6895(3.6965) | Xent 0.1151(0.1160) | Loss 3.7470(3.7546) | Error 0.0397(0.0391) Steps 676(680.73) | Grad Norm 1.3321(1.2503) | Total Time 14.00(14.00)\n",
      "Iter 2904 | Time 62.6267(61.2316) | Bit/dim 3.7036(3.6968) | Xent 0.1115(0.1159) | Loss 3.7594(3.7547) | Error 0.0369(0.0391) Steps 676(680.59) | Grad Norm 1.3470(1.2532) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 25.0418, Epoch Time 411.4230(408.7924), Bit/dim 3.7190(best: 3.7174), Xent 2.4272, Loss 4.9326, Error 0.4046(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2905 | Time 60.1434(61.1989) | Bit/dim 3.6860(3.6964) | Xent 0.1168(0.1159) | Loss 3.7444(3.7544) | Error 0.0391(0.0391) Steps 676(680.45) | Grad Norm 1.7127(1.2670) | Total Time 14.00(14.00)\n",
      "Iter 2906 | Time 58.1038(61.1061) | Bit/dim 3.6893(3.6962) | Xent 0.1161(0.1159) | Loss 3.7473(3.7542) | Error 0.0396(0.0391) Steps 682(680.50) | Grad Norm 1.8983(1.2859) | Total Time 14.00(14.00)\n",
      "Iter 2907 | Time 61.4916(61.1176) | Bit/dim 3.7100(3.6966) | Xent 0.1112(0.1158) | Loss 3.7656(3.7545) | Error 0.0364(0.0390) Steps 682(680.54) | Grad Norm 0.8454(1.2727) | Total Time 14.00(14.00)\n",
      "Iter 2908 | Time 59.9147(61.0815) | Bit/dim 3.6940(3.6966) | Xent 0.1195(0.1159) | Loss 3.7537(3.7545) | Error 0.0396(0.0390) Steps 676(680.41) | Grad Norm 1.0392(1.2657) | Total Time 14.00(14.00)\n",
      "Iter 2909 | Time 59.8929(61.0459) | Bit/dim 3.6835(3.6962) | Xent 0.1132(0.1158) | Loss 3.7401(3.7541) | Error 0.0369(0.0390) Steps 676(680.27) | Grad Norm 1.6135(1.2762) | Total Time 14.00(14.00)\n",
      "Iter 2910 | Time 60.5890(61.0322) | Bit/dim 3.7090(3.6966) | Xent 0.1147(0.1158) | Loss 3.7664(3.7544) | Error 0.0386(0.0389) Steps 682(680.33) | Grad Norm 1.4044(1.2800) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 25.2400, Epoch Time 401.1855(408.5642), Bit/dim 3.7179(best: 3.7174), Xent 2.4262, Loss 4.9310, Error 0.4033(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2911 | Time 59.8183(60.9958) | Bit/dim 3.7032(3.6967) | Xent 0.1117(0.1156) | Loss 3.7590(3.7546) | Error 0.0394(0.0390) Steps 682(680.38) | Grad Norm 1.0636(1.2735) | Total Time 14.00(14.00)\n",
      "Iter 2912 | Time 63.0239(61.0566) | Bit/dim 3.6836(3.6964) | Xent 0.1197(0.1158) | Loss 3.7435(3.7542) | Error 0.0404(0.0390) Steps 694(680.79) | Grad Norm 1.5942(1.2831) | Total Time 14.00(14.00)\n",
      "Iter 2913 | Time 62.5900(61.1026) | Bit/dim 3.6983(3.6964) | Xent 0.1147(0.1157) | Loss 3.7557(3.7543) | Error 0.0354(0.0389) Steps 670(680.46) | Grad Norm 1.4225(1.2873) | Total Time 14.00(14.00)\n",
      "Iter 2914 | Time 60.3190(61.0791) | Bit/dim 3.7033(3.6966) | Xent 0.1175(0.1158) | Loss 3.7621(3.7545) | Error 0.0390(0.0389) Steps 682(680.51) | Grad Norm 1.1663(1.2837) | Total Time 14.00(14.00)\n",
      "Iter 2915 | Time 64.0989(61.1697) | Bit/dim 3.6925(3.6965) | Xent 0.1123(0.1157) | Loss 3.7486(3.7543) | Error 0.0387(0.0389) Steps 670(680.19) | Grad Norm 0.9928(1.2750) | Total Time 14.00(14.00)\n",
      "Iter 2916 | Time 63.7050(61.2457) | Bit/dim 3.6979(3.6965) | Xent 0.1103(0.1155) | Loss 3.7531(3.7543) | Error 0.0371(0.0388) Steps 670(679.89) | Grad Norm 1.2541(1.2743) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 25.1558, Epoch Time 414.4467(408.7407), Bit/dim 3.7185(best: 3.7174), Xent 2.4448, Loss 4.9409, Error 0.4062(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2917 | Time 60.8661(61.2344) | Bit/dim 3.6935(3.6964) | Xent 0.1112(0.1154) | Loss 3.7491(3.7541) | Error 0.0369(0.0388) Steps 676(679.77) | Grad Norm 1.1698(1.2712) | Total Time 14.00(14.00)\n",
      "Iter 2918 | Time 59.0791(61.1697) | Bit/dim 3.6949(3.6964) | Xent 0.1254(0.1157) | Loss 3.7576(3.7542) | Error 0.0441(0.0389) Steps 682(679.84) | Grad Norm 1.0419(1.2643) | Total Time 14.00(14.00)\n",
      "Iter 2919 | Time 63.6576(61.2443) | Bit/dim 3.6940(3.6963) | Xent 0.1190(0.1158) | Loss 3.7534(3.7542) | Error 0.0411(0.0390) Steps 676(679.72) | Grad Norm 1.3219(1.2660) | Total Time 14.00(14.00)\n",
      "Iter 2920 | Time 61.4839(61.2515) | Bit/dim 3.7006(3.6965) | Xent 0.1168(0.1158) | Loss 3.7590(3.7544) | Error 0.0414(0.0391) Steps 688(679.97) | Grad Norm 0.9006(1.2551) | Total Time 14.00(14.00)\n",
      "Iter 2921 | Time 60.6126(61.2324) | Bit/dim 3.7032(3.6967) | Xent 0.1149(0.1158) | Loss 3.7606(3.7546) | Error 0.0391(0.0391) Steps 694(680.39) | Grad Norm 1.1748(1.2527) | Total Time 14.00(14.00)\n",
      "Iter 2922 | Time 62.7046(61.2765) | Bit/dim 3.6917(3.6965) | Xent 0.1172(0.1158) | Loss 3.7503(3.7544) | Error 0.0419(0.0392) Steps 688(680.62) | Grad Norm 1.0414(1.2463) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 25.1011, Epoch Time 409.3009(408.7575), Bit/dim 3.7177(best: 3.7174), Xent 2.4335, Loss 4.9345, Error 0.4058(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2923 | Time 62.5249(61.3140) | Bit/dim 3.7007(3.6966) | Xent 0.1064(0.1156) | Loss 3.7539(3.7544) | Error 0.0353(0.0390) Steps 670(680.30) | Grad Norm 0.9625(1.2378) | Total Time 14.00(14.00)\n",
      "Iter 2924 | Time 62.3267(61.3444) | Bit/dim 3.6938(3.6965) | Xent 0.1071(0.1153) | Loss 3.7473(3.7542) | Error 0.0355(0.0389) Steps 682(680.35) | Grad Norm 1.0811(1.2331) | Total Time 14.00(14.00)\n",
      "Iter 2925 | Time 64.0917(61.4268) | Bit/dim 3.6900(3.6964) | Xent 0.1193(0.1154) | Loss 3.7497(3.7541) | Error 0.0404(0.0390) Steps 676(680.22) | Grad Norm 1.8506(1.2516) | Total Time 14.00(14.00)\n",
      "Iter 2926 | Time 62.9338(61.4720) | Bit/dim 3.6904(3.6962) | Xent 0.1164(0.1155) | Loss 3.7486(3.7539) | Error 0.0404(0.0390) Steps 676(680.09) | Grad Norm 0.9408(1.2423) | Total Time 14.00(14.00)\n",
      "Iter 2927 | Time 59.8627(61.4237) | Bit/dim 3.7061(3.6965) | Xent 0.1070(0.1152) | Loss 3.7596(3.7541) | Error 0.0353(0.0389) Steps 670(679.79) | Grad Norm 1.0496(1.2365) | Total Time 14.00(14.00)\n",
      "Iter 2928 | Time 61.8205(61.4356) | Bit/dim 3.6920(3.6963) | Xent 0.1192(0.1153) | Loss 3.7516(3.7540) | Error 0.0405(0.0390) Steps 676(679.68) | Grad Norm 2.0287(1.2603) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 25.3713, Epoch Time 414.6403(408.9340), Bit/dim 3.7185(best: 3.7174), Xent 2.4698, Loss 4.9534, Error 0.4045(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2929 | Time 59.8917(61.3893) | Bit/dim 3.7011(3.6965) | Xent 0.1065(0.1151) | Loss 3.7544(3.7540) | Error 0.0360(0.0389) Steps 676(679.57) | Grad Norm 1.6135(1.2709) | Total Time 14.00(14.00)\n",
      "Iter 2930 | Time 63.0139(61.4380) | Bit/dim 3.6995(3.6966) | Xent 0.1127(0.1150) | Loss 3.7558(3.7541) | Error 0.0399(0.0389) Steps 688(679.82) | Grad Norm 0.9459(1.2611) | Total Time 14.00(14.00)\n",
      "Iter 2931 | Time 61.8010(61.4489) | Bit/dim 3.7021(3.6967) | Xent 0.1139(0.1150) | Loss 3.7591(3.7542) | Error 0.0397(0.0389) Steps 676(679.71) | Grad Norm 1.4767(1.2676) | Total Time 14.00(14.00)\n",
      "Iter 2932 | Time 61.2445(61.4428) | Bit/dim 3.6960(3.6967) | Xent 0.1091(0.1148) | Loss 3.7505(3.7541) | Error 0.0375(0.0389) Steps 688(679.96) | Grad Norm 1.9512(1.2881) | Total Time 14.00(14.00)\n",
      "Iter 2933 | Time 60.9195(61.4271) | Bit/dim 3.6927(3.6966) | Xent 0.1075(0.1146) | Loss 3.7465(3.7539) | Error 0.0365(0.0388) Steps 682(680.02) | Grad Norm 1.5599(1.2963) | Total Time 14.00(14.00)\n",
      "Iter 2934 | Time 62.2909(61.4530) | Bit/dim 3.6916(3.6964) | Xent 0.1083(0.1144) | Loss 3.7457(3.7536) | Error 0.0364(0.0387) Steps 682(680.08) | Grad Norm 1.2213(1.2940) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0489 | Time 25.5167, Epoch Time 410.1883(408.9716), Bit/dim 3.7185(best: 3.7174), Xent 2.4569, Loss 4.9469, Error 0.4062(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2935 | Time 60.8718(61.4356) | Bit/dim 3.6900(3.6963) | Xent 0.1142(0.1144) | Loss 3.7471(3.7534) | Error 0.0379(0.0387) Steps 670(679.77) | Grad Norm 1.7930(1.3090) | Total Time 14.00(14.00)\n",
      "Iter 2936 | Time 63.6385(61.5017) | Bit/dim 3.6928(3.6961) | Xent 0.1046(0.1141) | Loss 3.7451(3.7532) | Error 0.0353(0.0386) Steps 700(680.38) | Grad Norm 1.0439(1.3010) | Total Time 14.00(14.00)\n",
      "Iter 2937 | Time 60.5943(61.4744) | Bit/dim 3.7015(3.6963) | Xent 0.1172(0.1142) | Loss 3.7601(3.7534) | Error 0.0376(0.0386) Steps 682(680.43) | Grad Norm 1.3752(1.3033) | Total Time 14.00(14.00)\n",
      "Iter 2938 | Time 60.0671(61.4322) | Bit/dim 3.6956(3.6963) | Xent 0.1144(0.1142) | Loss 3.7528(3.7534) | Error 0.0391(0.0386) Steps 664(679.94) | Grad Norm 1.1818(1.2996) | Total Time 14.00(14.00)\n",
      "Iter 2939 | Time 59.2192(61.3658) | Bit/dim 3.7084(3.6967) | Xent 0.1025(0.1138) | Loss 3.7596(3.7536) | Error 0.0359(0.0385) Steps 670(679.64) | Grad Norm 1.3984(1.3026) | Total Time 14.00(14.00)\n",
      "Iter 2940 | Time 62.1486(61.3893) | Bit/dim 3.6934(3.6966) | Xent 0.1109(0.1137) | Loss 3.7489(3.7534) | Error 0.0364(0.0385) Steps 676(679.53) | Grad Norm 1.0687(1.2956) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0490 | Time 25.3024, Epoch Time 407.6630(408.9324), Bit/dim 3.7171(best: 3.7174), Xent 2.4718, Loss 4.9530, Error 0.4023(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2941 | Time 60.7209(61.3693) | Bit/dim 3.6972(3.6966) | Xent 0.1092(0.1136) | Loss 3.7518(3.7534) | Error 0.0365(0.0384) Steps 688(679.78) | Grad Norm 1.2929(1.2955) | Total Time 14.00(14.00)\n",
      "Iter 2942 | Time 62.6035(61.4063) | Bit/dim 3.6949(3.6965) | Xent 0.1137(0.1136) | Loss 3.7517(3.7533) | Error 0.0369(0.0383) Steps 682(679.85) | Grad Norm 1.6942(1.3074) | Total Time 14.00(14.00)\n",
      "Iter 2943 | Time 59.7605(61.3569) | Bit/dim 3.6892(3.6963) | Xent 0.1119(0.1136) | Loss 3.7451(3.7531) | Error 0.0371(0.0383) Steps 676(679.73) | Grad Norm 1.0500(1.2997) | Total Time 14.00(14.00)\n",
      "Iter 2944 | Time 63.7520(61.4288) | Bit/dim 3.7033(3.6965) | Xent 0.1154(0.1136) | Loss 3.7610(3.7533) | Error 0.0400(0.0384) Steps 700(680.34) | Grad Norm 2.3675(1.3318) | Total Time 14.00(14.00)\n",
      "Iter 2945 | Time 62.9824(61.4754) | Bit/dim 3.7023(3.6967) | Xent 0.1089(0.1135) | Loss 3.7567(3.7534) | Error 0.0381(0.0384) Steps 688(680.57) | Grad Norm 0.8129(1.3162) | Total Time 14.00(14.00)\n",
      "Iter 2946 | Time 60.2401(61.4383) | Bit/dim 3.6866(3.6964) | Xent 0.1218(0.1137) | Loss 3.7475(3.7532) | Error 0.0410(0.0384) Steps 682(680.61) | Grad Norm 1.5427(1.3230) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0491 | Time 25.2065, Epoch Time 411.3473(409.0048), Bit/dim 3.7182(best: 3.7171), Xent 2.4295, Loss 4.9329, Error 0.4006(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2947 | Time 60.5437(61.4115) | Bit/dim 3.6890(3.6962) | Xent 0.1048(0.1135) | Loss 3.7414(3.7529) | Error 0.0365(0.0384) Steps 682(680.66) | Grad Norm 1.0599(1.3151) | Total Time 14.00(14.00)\n",
      "Iter 2948 | Time 59.9743(61.3684) | Bit/dim 3.7031(3.6964) | Xent 0.1089(0.1133) | Loss 3.7575(3.7530) | Error 0.0366(0.0383) Steps 694(681.06) | Grad Norm 1.6888(1.3263) | Total Time 14.00(14.00)\n",
      "Iter 2949 | Time 59.6057(61.3155) | Bit/dim 3.6887(3.6961) | Xent 0.1080(0.1132) | Loss 3.7427(3.7527) | Error 0.0351(0.0382) Steps 676(680.90) | Grad Norm 1.2669(1.3245) | Total Time 14.00(14.00)\n",
      "Iter 2950 | Time 61.2553(61.3137) | Bit/dim 3.7015(3.6963) | Xent 0.1086(0.1130) | Loss 3.7558(3.7528) | Error 0.0357(0.0382) Steps 676(680.76) | Grad Norm 1.0198(1.3154) | Total Time 14.00(14.00)\n",
      "Iter 2951 | Time 60.6697(61.2944) | Bit/dim 3.6987(3.6964) | Xent 0.1119(0.1130) | Loss 3.7546(3.7529) | Error 0.0377(0.0381) Steps 682(680.79) | Grad Norm 1.0896(1.3086) | Total Time 14.00(14.00)\n",
      "Iter 2952 | Time 64.5343(61.3916) | Bit/dim 3.6966(3.6964) | Xent 0.1163(0.1131) | Loss 3.7547(3.7529) | Error 0.0400(0.0382) Steps 682(680.83) | Grad Norm 1.0567(1.3011) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0492 | Time 25.0977, Epoch Time 407.7174(408.9662), Bit/dim 3.7182(best: 3.7171), Xent 2.4596, Loss 4.9480, Error 0.4036(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2953 | Time 61.7011(61.4008) | Bit/dim 3.6963(3.6964) | Xent 0.1095(0.1130) | Loss 3.7511(3.7529) | Error 0.0393(0.0382) Steps 676(680.69) | Grad Norm 1.1824(1.2975) | Total Time 14.00(14.00)\n",
      "Iter 2954 | Time 60.2946(61.3677) | Bit/dim 3.6970(3.6964) | Xent 0.1085(0.1128) | Loss 3.7513(3.7528) | Error 0.0373(0.0382) Steps 670(680.37) | Grad Norm 1.4057(1.3007) | Total Time 14.00(14.00)\n",
      "Iter 2955 | Time 59.8864(61.3232) | Bit/dim 3.7067(3.6967) | Xent 0.1072(0.1127) | Loss 3.7603(3.7530) | Error 0.0359(0.0381) Steps 676(680.23) | Grad Norm 1.7718(1.3149) | Total Time 14.00(14.00)\n",
      "Iter 2956 | Time 63.7328(61.3955) | Bit/dim 3.6895(3.6965) | Xent 0.1159(0.1128) | Loss 3.7474(3.7529) | Error 0.0387(0.0381) Steps 694(680.65) | Grad Norm 1.0315(1.3064) | Total Time 14.00(14.00)\n",
      "Iter 2957 | Time 62.0474(61.4151) | Bit/dim 3.7043(3.6967) | Xent 0.1154(0.1128) | Loss 3.7620(3.7531) | Error 0.0387(0.0382) Steps 682(680.69) | Grad Norm 1.6288(1.3160) | Total Time 14.00(14.00)\n",
      "Iter 2958 | Time 61.5477(61.4190) | Bit/dim 3.6859(3.6964) | Xent 0.1185(0.1130) | Loss 3.7451(3.7529) | Error 0.0389(0.0382) Steps 688(680.91) | Grad Norm 1.9186(1.3341) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0493 | Time 25.1155, Epoch Time 410.3956(409.0091), Bit/dim 3.7189(best: 3.7171), Xent 2.4129, Loss 4.9253, Error 0.4007(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2959 | Time 61.7390(61.4286) | Bit/dim 3.6859(3.6961) | Xent 0.1056(0.1128) | Loss 3.7387(3.7525) | Error 0.0367(0.0381) Steps 676(680.76) | Grad Norm 1.3717(1.3352) | Total Time 14.00(14.00)\n",
      "Iter 2960 | Time 60.4567(61.3995) | Bit/dim 3.7033(3.6963) | Xent 0.1165(0.1129) | Loss 3.7615(3.7527) | Error 0.0404(0.0382) Steps 670(680.44) | Grad Norm 1.0919(1.3279) | Total Time 14.00(14.00)\n",
      "Iter 2961 | Time 63.2401(61.4547) | Bit/dim 3.7030(3.6965) | Xent 0.1000(0.1125) | Loss 3.7529(3.7528) | Error 0.0325(0.0380) Steps 688(680.66) | Grad Norm 2.0242(1.3488) | Total Time 14.00(14.00)\n",
      "Iter 2962 | Time 60.8826(61.4375) | Bit/dim 3.6875(3.6962) | Xent 0.1066(0.1123) | Loss 3.7408(3.7524) | Error 0.0343(0.0379) Steps 682(680.70) | Grad Norm 1.0783(1.3407) | Total Time 14.00(14.00)\n",
      "Iter 2963 | Time 63.1367(61.4885) | Bit/dim 3.7012(3.6964) | Xent 0.1072(0.1122) | Loss 3.7549(3.7525) | Error 0.0351(0.0378) Steps 682(680.74) | Grad Norm 1.1856(1.3361) | Total Time 14.00(14.00)\n",
      "Iter 2964 | Time 59.6861(61.4344) | Bit/dim 3.6969(3.6964) | Xent 0.1161(0.1123) | Loss 3.7550(3.7525) | Error 0.0394(0.0379) Steps 688(680.96) | Grad Norm 0.8848(1.3225) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0494 | Time 25.3085, Epoch Time 410.3044(409.0479), Bit/dim 3.7176(best: 3.7171), Xent 2.4793, Loss 4.9573, Error 0.4066(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2965 | Time 62.3764(61.4627) | Bit/dim 3.6920(3.6963) | Xent 0.1158(0.1124) | Loss 3.7499(3.7525) | Error 0.0371(0.0379) Steps 670(680.63) | Grad Norm 1.1591(1.3176) | Total Time 14.00(14.00)\n",
      "Iter 2966 | Time 59.9250(61.4166) | Bit/dim 3.6933(3.6962) | Xent 0.1131(0.1124) | Loss 3.7499(3.7524) | Error 0.0396(0.0379) Steps 682(680.67) | Grad Norm 1.0237(1.3088) | Total Time 14.00(14.00)\n",
      "Iter 2967 | Time 60.3780(61.3854) | Bit/dim 3.6924(3.6961) | Xent 0.1092(0.1123) | Loss 3.7470(3.7522) | Error 0.0360(0.0379) Steps 682(680.71) | Grad Norm 0.8266(1.2943) | Total Time 14.00(14.00)\n",
      "Iter 2968 | Time 60.4806(61.3583) | Bit/dim 3.7031(3.6963) | Xent 0.1112(0.1123) | Loss 3.7586(3.7524) | Error 0.0375(0.0378) Steps 700(681.29) | Grad Norm 1.0027(1.2856) | Total Time 14.00(14.00)\n",
      "Iter 2969 | Time 59.5701(61.3046) | Bit/dim 3.6969(3.6963) | Xent 0.1169(0.1124) | Loss 3.7553(3.7525) | Error 0.0367(0.0378) Steps 688(681.49) | Grad Norm 1.2299(1.2839) | Total Time 14.00(14.00)\n",
      "Iter 2970 | Time 60.3157(61.2749) | Bit/dim 3.6963(3.6963) | Xent 0.1132(0.1125) | Loss 3.7529(3.7525) | Error 0.0384(0.0378) Steps 670(681.15) | Grad Norm 1.9837(1.3049) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0495 | Time 25.5847, Epoch Time 404.4470(408.9099), Bit/dim 3.7176(best: 3.7171), Xent 2.4527, Loss 4.9440, Error 0.3972(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2971 | Time 62.0715(61.2988) | Bit/dim 3.6961(3.6963) | Xent 0.1105(0.1124) | Loss 3.7513(3.7525) | Error 0.0381(0.0378) Steps 682(681.17) | Grad Norm 1.3944(1.3076) | Total Time 14.00(14.00)\n",
      "Iter 2972 | Time 60.0599(61.2617) | Bit/dim 3.6820(3.6959) | Xent 0.1129(0.1124) | Loss 3.7385(3.7521) | Error 0.0379(0.0378) Steps 688(681.38) | Grad Norm 1.3111(1.3077) | Total Time 14.00(14.00)\n",
      "Iter 2973 | Time 62.0550(61.2855) | Bit/dim 3.6953(3.6958) | Xent 0.1120(0.1124) | Loss 3.7513(3.7520) | Error 0.0367(0.0378) Steps 682(681.40) | Grad Norm 1.1537(1.3031) | Total Time 14.00(14.00)\n",
      "Iter 2974 | Time 61.5206(61.2925) | Bit/dim 3.7016(3.6960) | Xent 0.1078(0.1123) | Loss 3.7554(3.7521) | Error 0.0361(0.0378) Steps 700(681.96) | Grad Norm 1.3372(1.3041) | Total Time 14.00(14.00)\n",
      "Iter 2975 | Time 63.1296(61.3476) | Bit/dim 3.6912(3.6959) | Xent 0.1060(0.1121) | Loss 3.7442(3.7519) | Error 0.0366(0.0377) Steps 682(681.96) | Grad Norm 1.3778(1.3063) | Total Time 14.00(14.00)\n",
      "Iter 2976 | Time 64.5577(61.4439) | Bit/dim 3.7016(3.6960) | Xent 0.1098(0.1120) | Loss 3.7565(3.7520) | Error 0.0373(0.0377) Steps 682(681.96) | Grad Norm 1.9680(1.3262) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0496 | Time 24.9547, Epoch Time 414.8197(409.0872), Bit/dim 3.7182(best: 3.7171), Xent 2.4618, Loss 4.9491, Error 0.4054(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2977 | Time 59.0903(61.3733) | Bit/dim 3.6948(3.6960) | Xent 0.1106(0.1120) | Loss 3.7501(3.7520) | Error 0.0355(0.0376) Steps 670(681.60) | Grad Norm 1.1526(1.3210) | Total Time 14.00(14.00)\n",
      "Iter 2978 | Time 59.0330(61.3031) | Bit/dim 3.7072(3.6963) | Xent 0.1130(0.1120) | Loss 3.7636(3.7523) | Error 0.0383(0.0377) Steps 676(681.43) | Grad Norm 1.4232(1.3240) | Total Time 14.00(14.00)\n",
      "Iter 2979 | Time 59.5466(61.2504) | Bit/dim 3.6927(3.6962) | Xent 0.1052(0.1118) | Loss 3.7453(3.7521) | Error 0.0367(0.0376) Steps 682(681.45) | Grad Norm 1.2601(1.3221) | Total Time 14.00(14.00)\n",
      "Iter 2980 | Time 60.3337(61.2229) | Bit/dim 3.6941(3.6962) | Xent 0.1056(0.1116) | Loss 3.7469(3.7520) | Error 0.0344(0.0375) Steps 694(681.82) | Grad Norm 1.1350(1.3165) | Total Time 14.00(14.00)\n",
      "Iter 2981 | Time 62.2277(61.2531) | Bit/dim 3.6810(3.6957) | Xent 0.1002(0.1113) | Loss 3.7311(3.7513) | Error 0.0329(0.0374) Steps 670(681.47) | Grad Norm 1.7600(1.3298) | Total Time 14.00(14.00)\n",
      "Iter 2982 | Time 62.5992(61.2935) | Bit/dim 3.7040(3.6960) | Xent 0.1061(0.1111) | Loss 3.7571(3.7515) | Error 0.0361(0.0374) Steps 670(681.13) | Grad Norm 1.2591(1.3277) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0497 | Time 24.8333, Epoch Time 403.6378(408.9237), Bit/dim 3.7174(best: 3.7171), Xent 2.4504, Loss 4.9426, Error 0.4020(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2983 | Time 62.8145(61.3391) | Bit/dim 3.6917(3.6958) | Xent 0.1057(0.1109) | Loss 3.7445(3.7513) | Error 0.0371(0.0374) Steps 664(680.61) | Grad Norm 1.4580(1.3316) | Total Time 14.00(14.00)\n",
      "Iter 2984 | Time 59.6110(61.2872) | Bit/dim 3.6928(3.6957) | Xent 0.1100(0.1109) | Loss 3.7477(3.7512) | Error 0.0366(0.0373) Steps 688(680.83) | Grad Norm 1.2464(1.3290) | Total Time 14.00(14.00)\n",
      "Iter 2985 | Time 60.1929(61.2544) | Bit/dim 3.7068(3.6961) | Xent 0.1058(0.1108) | Loss 3.7597(3.7514) | Error 0.0357(0.0373) Steps 670(680.51) | Grad Norm 0.8070(1.3134) | Total Time 14.00(14.00)\n",
      "Iter 2986 | Time 62.5042(61.2919) | Bit/dim 3.6979(3.6961) | Xent 0.1134(0.1108) | Loss 3.7546(3.7515) | Error 0.0373(0.0373) Steps 688(680.73) | Grad Norm 1.9229(1.3317) | Total Time 14.00(14.00)\n",
      "Iter 2987 | Time 61.2197(61.2897) | Bit/dim 3.6945(3.6961) | Xent 0.1057(0.1107) | Loss 3.7474(3.7514) | Error 0.0360(0.0372) Steps 670(680.41) | Grad Norm 1.3936(1.3335) | Total Time 14.00(14.00)\n",
      "Iter 2988 | Time 62.4370(61.3242) | Bit/dim 3.6918(3.6959) | Xent 0.1079(0.1106) | Loss 3.7457(3.7512) | Error 0.0359(0.0372) Steps 694(680.82) | Grad Norm 0.9061(1.3207) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0498 | Time 24.9082, Epoch Time 409.9041(408.9531), Bit/dim 3.7180(best: 3.7171), Xent 2.4819, Loss 4.9590, Error 0.4052(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2989 | Time 62.0297(61.3453) | Bit/dim 3.6994(3.6960) | Xent 0.1127(0.1107) | Loss 3.7558(3.7514) | Error 0.0361(0.0372) Steps 676(680.67) | Grad Norm 1.2999(1.3201) | Total Time 14.00(14.00)\n",
      "Iter 2990 | Time 61.4032(61.3471) | Bit/dim 3.6860(3.6957) | Xent 0.1064(0.1105) | Loss 3.7392(3.7510) | Error 0.0369(0.0372) Steps 670(680.35) | Grad Norm 1.5923(1.3282) | Total Time 14.00(14.00)\n",
      "Iter 2991 | Time 61.9091(61.3639) | Bit/dim 3.7050(3.6960) | Xent 0.1170(0.1107) | Loss 3.7635(3.7514) | Error 0.0381(0.0372) Steps 688(680.58) | Grad Norm 1.4345(1.3314) | Total Time 14.00(14.00)\n",
      "Iter 2992 | Time 62.9242(61.4107) | Bit/dim 3.6856(3.6957) | Xent 0.1116(0.1108) | Loss 3.7414(3.7511) | Error 0.0394(0.0373) Steps 682(680.63) | Grad Norm 1.5040(1.3366) | Total Time 14.00(14.00)\n",
      "Iter 2993 | Time 63.5524(61.4750) | Bit/dim 3.6965(3.6957) | Xent 0.1118(0.1108) | Loss 3.7523(3.7511) | Error 0.0371(0.0373) Steps 676(680.49) | Grad Norm 1.5570(1.3432) | Total Time 14.00(14.00)\n",
      "Iter 2994 | Time 60.7178(61.4523) | Bit/dim 3.7025(3.6959) | Xent 0.1108(0.1108) | Loss 3.7579(3.7513) | Error 0.0356(0.0372) Steps 682(680.53) | Grad Norm 1.4672(1.3469) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0499 | Time 25.1971, Epoch Time 413.4099(409.0868), Bit/dim 3.7166(best: 3.7171), Xent 2.4688, Loss 4.9510, Error 0.4045(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2995 | Time 60.1369(61.4128) | Bit/dim 3.6956(3.6959) | Xent 0.1084(0.1107) | Loss 3.7498(3.7513) | Error 0.0365(0.0372) Steps 664(680.04) | Grad Norm 1.0492(1.3380) | Total Time 14.00(14.00)\n",
      "Iter 2996 | Time 59.7101(61.3617) | Bit/dim 3.6961(3.6959) | Xent 0.1091(0.1107) | Loss 3.7506(3.7513) | Error 0.0359(0.0371) Steps 682(680.10) | Grad Norm 1.5937(1.3457) | Total Time 14.00(14.00)\n",
      "Iter 2997 | Time 60.7277(61.3427) | Bit/dim 3.7051(3.6962) | Xent 0.1118(0.1107) | Loss 3.7610(3.7516) | Error 0.0394(0.0372) Steps 682(680.15) | Grad Norm 1.4530(1.3489) | Total Time 14.00(14.00)\n",
      "Iter 2998 | Time 60.5853(61.3200) | Bit/dim 3.6989(3.6963) | Xent 0.1042(0.1105) | Loss 3.7510(3.7515) | Error 0.0354(0.0372) Steps 676(680.03) | Grad Norm 0.9656(1.3374) | Total Time 14.00(14.00)\n",
      "Iter 2999 | Time 62.9411(61.3686) | Bit/dim 3.6884(3.6960) | Xent 0.1092(0.1105) | Loss 3.7430(3.7513) | Error 0.0375(0.0372) Steps 676(679.91) | Grad Norm 0.9342(1.3253) | Total Time 14.00(14.00)\n",
      "Iter 3000 | Time 61.9224(61.3852) | Bit/dim 3.6864(3.6958) | Xent 0.1064(0.1103) | Loss 3.7396(3.7509) | Error 0.0346(0.0371) Steps 676(679.79) | Grad Norm 1.0350(1.3166) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0500 | Time 25.0849, Epoch Time 407.1157(409.0277), Bit/dim 3.7170(best: 3.7166), Xent 2.4704, Loss 4.9522, Error 0.4045(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3001 | Time 61.0576(61.3754) | Bit/dim 3.6983(3.6958) | Xent 0.1077(0.1103) | Loss 3.7522(3.7510) | Error 0.0384(0.0371) Steps 676(679.68) | Grad Norm 1.7082(1.3283) | Total Time 14.00(14.00)\n",
      "Iter 3002 | Time 61.6140(61.3826) | Bit/dim 3.6978(3.6959) | Xent 0.1061(0.1101) | Loss 3.7509(3.7510) | Error 0.0366(0.0371) Steps 676(679.57) | Grad Norm 1.2325(1.3255) | Total Time 14.00(14.00)\n",
      "Iter 3003 | Time 59.8357(61.3361) | Bit/dim 3.7030(3.6961) | Xent 0.1019(0.1099) | Loss 3.7540(3.7511) | Error 0.0367(0.0371) Steps 664(679.10) | Grad Norm 0.9976(1.3156) | Total Time 14.00(14.00)\n",
      "Iter 3004 | Time 59.6533(61.2857) | Bit/dim 3.6914(3.6960) | Xent 0.0984(0.1096) | Loss 3.7406(3.7507) | Error 0.0317(0.0369) Steps 670(678.83) | Grad Norm 0.9818(1.3056) | Total Time 14.00(14.00)\n",
      "Iter 3005 | Time 61.3413(61.2873) | Bit/dim 3.6940(3.6959) | Xent 0.1156(0.1097) | Loss 3.7518(3.7508) | Error 0.0400(0.0370) Steps 676(678.74) | Grad Norm 1.1220(1.3001) | Total Time 14.00(14.00)\n",
      "Iter 3006 | Time 62.8440(61.3340) | Bit/dim 3.6957(3.6959) | Xent 0.1106(0.1098) | Loss 3.7511(3.7508) | Error 0.0377(0.0371) Steps 694(679.20) | Grad Norm 1.0655(1.2931) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0501 | Time 25.3890, Epoch Time 407.7257(408.9886), Bit/dim 3.7185(best: 3.7166), Xent 2.4833, Loss 4.9601, Error 0.4086(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3007 | Time 58.0188(61.2346) | Bit/dim 3.6990(3.6960) | Xent 0.1090(0.1097) | Loss 3.7535(3.7509) | Error 0.0375(0.0371) Steps 676(679.10) | Grad Norm 1.9649(1.3132) | Total Time 14.00(14.00)\n",
      "Iter 3008 | Time 62.8357(61.2826) | Bit/dim 3.6999(3.6961) | Xent 0.1081(0.1097) | Loss 3.7540(3.7510) | Error 0.0375(0.0371) Steps 676(679.01) | Grad Norm 1.2724(1.3120) | Total Time 14.00(14.00)\n",
      "Iter 3009 | Time 60.9432(61.2724) | Bit/dim 3.6949(3.6961) | Xent 0.1008(0.1094) | Loss 3.7453(3.7508) | Error 0.0366(0.0371) Steps 676(678.92) | Grad Norm 0.7425(1.2949) | Total Time 14.00(14.00)\n",
      "Iter 3010 | Time 62.9612(61.3231) | Bit/dim 3.6967(3.6961) | Xent 0.1177(0.1097) | Loss 3.7555(3.7509) | Error 0.0379(0.0371) Steps 670(678.65) | Grad Norm 1.2058(1.2922) | Total Time 14.00(14.00)\n",
      "Iter 3011 | Time 60.4451(61.2968) | Bit/dim 3.6878(3.6958) | Xent 0.1135(0.1098) | Loss 3.7445(3.7507) | Error 0.0365(0.0371) Steps 688(678.93) | Grad Norm 1.4375(1.2966) | Total Time 14.00(14.00)\n",
      "Iter 3012 | Time 63.9347(61.3759) | Bit/dim 3.6939(3.6958) | Xent 0.1065(0.1097) | Loss 3.7471(3.7506) | Error 0.0347(0.0370) Steps 676(678.84) | Grad Norm 1.3925(1.2995) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0502 | Time 24.9189, Epoch Time 409.6401(409.0082), Bit/dim 3.7182(best: 3.7166), Xent 2.4650, Loss 4.9507, Error 0.4004(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3013 | Time 59.7005(61.3256) | Bit/dim 3.6934(3.6957) | Xent 0.1122(0.1098) | Loss 3.7495(3.7506) | Error 0.0383(0.0370) Steps 682(678.94) | Grad Norm 0.8650(1.2864) | Total Time 14.00(14.00)\n",
      "Iter 3014 | Time 60.3300(61.2958) | Bit/dim 3.6910(3.6956) | Xent 0.1100(0.1098) | Loss 3.7460(3.7505) | Error 0.0346(0.0370) Steps 694(679.39) | Grad Norm 1.6422(1.2971) | Total Time 14.00(14.00)\n",
      "Iter 3015 | Time 62.6340(61.3359) | Bit/dim 3.7014(3.6958) | Xent 0.1052(0.1096) | Loss 3.7540(3.7506) | Error 0.0355(0.0369) Steps 688(679.65) | Grad Norm 0.9645(1.2871) | Total Time 14.00(14.00)\n",
      "Iter 3016 | Time 59.8373(61.2909) | Bit/dim 3.6941(3.6957) | Xent 0.1095(0.1096) | Loss 3.7488(3.7505) | Error 0.0370(0.0369) Steps 682(679.72) | Grad Norm 1.1381(1.2827) | Total Time 14.00(14.00)\n",
      "Iter 3017 | Time 61.7058(61.3034) | Bit/dim 3.7015(3.6959) | Xent 0.1094(0.1096) | Loss 3.7562(3.7507) | Error 0.0374(0.0369) Steps 682(679.79) | Grad Norm 1.2784(1.2825) | Total Time 14.00(14.00)\n",
      "Iter 3018 | Time 59.9425(61.2626) | Bit/dim 3.6918(3.6958) | Xent 0.1126(0.1097) | Loss 3.7481(3.7506) | Error 0.0375(0.0370) Steps 682(679.85) | Grad Norm 0.8619(1.2699) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0503 | Time 25.0573, Epoch Time 405.2044(408.8941), Bit/dim 3.7168(best: 3.7166), Xent 2.4602, Loss 4.9469, Error 0.4032(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3019 | Time 60.4347(61.2377) | Bit/dim 3.6917(3.6956) | Xent 0.1077(0.1096) | Loss 3.7455(3.7505) | Error 0.0371(0.0370) Steps 682(679.92) | Grad Norm 1.3379(1.2720) | Total Time 14.00(14.00)\n",
      "Iter 3020 | Time 61.4175(61.2431) | Bit/dim 3.6835(3.6953) | Xent 0.1066(0.1096) | Loss 3.7368(3.7500) | Error 0.0366(0.0370) Steps 688(680.16) | Grad Norm 0.7417(1.2561) | Total Time 14.00(14.00)\n",
      "Iter 3021 | Time 61.0092(61.2361) | Bit/dim 3.6984(3.6954) | Xent 0.1015(0.1093) | Loss 3.7492(3.7500) | Error 0.0360(0.0369) Steps 694(680.58) | Grad Norm 0.8197(1.2430) | Total Time 14.00(14.00)\n",
      "Iter 3022 | Time 61.7940(61.2528) | Bit/dim 3.6946(3.6953) | Xent 0.1156(0.1095) | Loss 3.7523(3.7501) | Error 0.0369(0.0369) Steps 682(680.62) | Grad Norm 1.2756(1.2439) | Total Time 14.00(14.00)\n",
      "Iter 3023 | Time 60.7581(61.2380) | Bit/dim 3.7027(3.6956) | Xent 0.1062(0.1094) | Loss 3.7558(3.7503) | Error 0.0381(0.0370) Steps 694(681.02) | Grad Norm 1.2262(1.2434) | Total Time 14.00(14.00)\n",
      "Iter 3024 | Time 61.7873(61.2545) | Bit/dim 3.6958(3.6956) | Xent 0.1079(0.1094) | Loss 3.7497(3.7502) | Error 0.0359(0.0369) Steps 676(680.87) | Grad Norm 1.7175(1.2576) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0504 | Time 24.9144, Epoch Time 407.8447(408.8626), Bit/dim 3.7176(best: 3.7166), Xent 2.4496, Loss 4.9424, Error 0.4043(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3025 | Time 62.3711(61.2880) | Bit/dim 3.6896(3.6954) | Xent 0.1101(0.1094) | Loss 3.7447(3.7501) | Error 0.0347(0.0369) Steps 676(680.72) | Grad Norm 1.1842(1.2554) | Total Time 14.00(14.00)\n",
      "Iter 3026 | Time 59.0352(61.2204) | Bit/dim 3.7033(3.6956) | Xent 0.1083(0.1093) | Loss 3.7574(3.7503) | Error 0.0365(0.0368) Steps 688(680.94) | Grad Norm 1.1478(1.2522) | Total Time 14.00(14.00)\n",
      "Iter 3027 | Time 60.5832(61.2013) | Bit/dim 3.6965(3.6956) | Xent 0.1196(0.1097) | Loss 3.7563(3.7505) | Error 0.0400(0.0369) Steps 682(680.97) | Grad Norm 1.6657(1.2646) | Total Time 14.00(14.00)\n",
      "Iter 3028 | Time 59.5055(61.1504) | Bit/dim 3.6936(3.6956) | Xent 0.0953(0.1092) | Loss 3.7413(3.7502) | Error 0.0330(0.0368) Steps 664(680.46) | Grad Norm 1.2145(1.2631) | Total Time 14.00(14.00)\n",
      "Iter 3029 | Time 59.4031(61.0980) | Bit/dim 3.6944(3.6956) | Xent 0.0987(0.1089) | Loss 3.7437(3.7500) | Error 0.0311(0.0367) Steps 682(680.51) | Grad Norm 1.0431(1.2565) | Total Time 14.00(14.00)\n",
      "Iter 3030 | Time 64.1008(61.1881) | Bit/dim 3.6963(3.6956) | Xent 0.1089(0.1089) | Loss 3.7508(3.7500) | Error 0.0345(0.0366) Steps 670(680.20) | Grad Norm 0.9951(1.2487) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0505 | Time 25.0680, Epoch Time 411.1674(408.9317), Bit/dim 3.7167(best: 3.7166), Xent 2.4959, Loss 4.9647, Error 0.4024(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3031 | Time 61.9648(61.2114) | Bit/dim 3.7062(3.6959) | Xent 0.1036(0.1087) | Loss 3.7580(3.7503) | Error 0.0349(0.0365) Steps 682(680.25) | Grad Norm 1.5031(1.2563) | Total Time 14.00(14.00)\n",
      "Iter 3032 | Time 60.8950(61.2019) | Bit/dim 3.6837(3.6955) | Xent 0.1163(0.1090) | Loss 3.7418(3.7500) | Error 0.0384(0.0366) Steps 682(680.30) | Grad Norm 1.7569(1.2713) | Total Time 14.00(14.00)\n",
      "Iter 3033 | Time 62.6238(61.2445) | Bit/dim 3.6925(3.6954) | Xent 0.1037(0.1088) | Loss 3.7443(3.7498) | Error 0.0334(0.0365) Steps 682(680.35) | Grad Norm 1.9578(1.2919) | Total Time 14.00(14.00)\n",
      "Iter 3034 | Time 61.4333(61.2502) | Bit/dim 3.6925(3.6953) | Xent 0.1219(0.1092) | Loss 3.7535(3.7500) | Error 0.0389(0.0366) Steps 682(680.40) | Grad Norm 1.3731(1.2943) | Total Time 14.00(14.00)\n",
      "Iter 3035 | Time 60.0996(61.2157) | Bit/dim 3.7063(3.6957) | Xent 0.1017(0.1090) | Loss 3.7572(3.7502) | Error 0.0339(0.0365) Steps 682(680.45) | Grad Norm 1.4863(1.3001) | Total Time 14.00(14.00)\n",
      "Iter 3036 | Time 62.7378(61.2614) | Bit/dim 3.6903(3.6955) | Xent 0.1071(0.1089) | Loss 3.7438(3.7500) | Error 0.0367(0.0365) Steps 682(680.50) | Grad Norm 2.3508(1.3316) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0506 | Time 25.0865, Epoch Time 410.5310(408.9797), Bit/dim 3.7183(best: 3.7166), Xent 2.4733, Loss 4.9550, Error 0.4045(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3037 | Time 62.1947(61.2893) | Bit/dim 3.6932(3.6954) | Xent 0.1120(0.1090) | Loss 3.7492(3.7500) | Error 0.0389(0.0366) Steps 676(680.36) | Grad Norm 1.4339(1.3347) | Total Time 14.00(14.00)\n",
      "Iter 3038 | Time 63.4884(61.3553) | Bit/dim 3.6986(3.6955) | Xent 0.1124(0.1091) | Loss 3.7548(3.7501) | Error 0.0380(0.0366) Steps 670(680.05) | Grad Norm 1.0959(1.3275) | Total Time 14.00(14.00)\n",
      "Iter 3039 | Time 61.6343(61.3637) | Bit/dim 3.6946(3.6955) | Xent 0.1062(0.1090) | Loss 3.7477(3.7500) | Error 0.0345(0.0365) Steps 676(679.93) | Grad Norm 1.3517(1.3283) | Total Time 14.00(14.00)\n",
      "Iter 3040 | Time 60.1242(61.3265) | Bit/dim 3.6985(3.6956) | Xent 0.1009(0.1088) | Loss 3.7489(3.7500) | Error 0.0339(0.0365) Steps 682(679.99) | Grad Norm 1.3472(1.3288) | Total Time 14.00(14.00)\n",
      "Iter 3041 | Time 62.4025(61.3588) | Bit/dim 3.6965(3.6956) | Xent 0.1061(0.1087) | Loss 3.7495(3.7500) | Error 0.0355(0.0364) Steps 676(679.87) | Grad Norm 1.1165(1.3225) | Total Time 14.00(14.00)\n",
      "Iter 3042 | Time 60.5300(61.3339) | Bit/dim 3.6959(3.6956) | Xent 0.1076(0.1087) | Loss 3.7496(3.7500) | Error 0.0339(0.0364) Steps 676(679.76) | Grad Norm 1.8237(1.3375) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0507 | Time 24.8790, Epoch Time 410.5790(409.0277), Bit/dim 3.7169(best: 3.7166), Xent 2.4187, Loss 4.9262, Error 0.4006(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3043 | Time 58.8731(61.2601) | Bit/dim 3.6931(3.6956) | Xent 0.1019(0.1085) | Loss 3.7440(3.7498) | Error 0.0325(0.0362) Steps 676(679.64) | Grad Norm 1.6195(1.3460) | Total Time 14.00(14.00)\n",
      "Iter 3044 | Time 61.8866(61.2789) | Bit/dim 3.7076(3.6959) | Xent 0.1116(0.1086) | Loss 3.7634(3.7502) | Error 0.0356(0.0362) Steps 676(679.53) | Grad Norm 1.7734(1.3588) | Total Time 14.00(14.00)\n",
      "Iter 3045 | Time 61.8501(61.2960) | Bit/dim 3.7008(3.6961) | Xent 0.1166(0.1088) | Loss 3.7591(3.7505) | Error 0.0370(0.0362) Steps 670(679.25) | Grad Norm 2.1875(1.3836) | Total Time 14.00(14.00)\n",
      "Iter 3046 | Time 62.5222(61.3328) | Bit/dim 3.6950(3.6960) | Xent 0.1050(0.1087) | Loss 3.7475(3.7504) | Error 0.0366(0.0363) Steps 694(679.69) | Grad Norm 1.6244(1.3909) | Total Time 14.00(14.00)\n",
      "Iter 3047 | Time 57.7104(61.2241) | Bit/dim 3.6867(3.6958) | Xent 0.1064(0.1086) | Loss 3.7399(3.7501) | Error 0.0356(0.0362) Steps 694(680.12) | Grad Norm 2.1229(1.4128) | Total Time 14.00(14.00)\n",
      "Iter 3048 | Time 62.6770(61.2677) | Bit/dim 3.6874(3.6955) | Xent 0.1080(0.1086) | Loss 3.7414(3.7498) | Error 0.0355(0.0362) Steps 682(680.18) | Grad Norm 0.9382(1.3986) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0508 | Time 25.3560, Epoch Time 406.2977(408.9458), Bit/dim 3.7171(best: 3.7166), Xent 2.4661, Loss 4.9502, Error 0.4040(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3049 | Time 59.3994(61.2117) | Bit/dim 3.7026(3.6957) | Xent 0.1126(0.1087) | Loss 3.7589(3.7501) | Error 0.0384(0.0363) Steps 682(680.23) | Grad Norm 2.6837(1.4371) | Total Time 14.00(14.00)\n",
      "Iter 3050 | Time 59.4639(61.1592) | Bit/dim 3.7049(3.6960) | Xent 0.1059(0.1086) | Loss 3.7579(3.7503) | Error 0.0351(0.0362) Steps 664(679.74) | Grad Norm 1.2832(1.4325) | Total Time 14.00(14.00)\n",
      "Iter 3051 | Time 61.6538(61.1741) | Bit/dim 3.6933(3.6959) | Xent 0.1072(0.1086) | Loss 3.7469(3.7502) | Error 0.0366(0.0363) Steps 676(679.63) | Grad Norm 1.5938(1.4374) | Total Time 14.00(14.00)\n",
      "Iter 3052 | Time 60.7635(61.1618) | Bit/dim 3.6988(3.6960) | Xent 0.1026(0.1084) | Loss 3.7501(3.7502) | Error 0.0337(0.0362) Steps 682(679.70) | Grad Norm 1.9105(1.4516) | Total Time 14.00(14.00)\n",
      "Iter 3053 | Time 59.1445(61.1012) | Bit/dim 3.6898(3.6958) | Xent 0.1010(0.1082) | Loss 3.7403(3.7499) | Error 0.0339(0.0361) Steps 670(679.41) | Grad Norm 1.1323(1.4420) | Total Time 14.00(14.00)\n",
      "Iter 3054 | Time 65.6501(61.2377) | Bit/dim 3.6882(3.6956) | Xent 0.1095(0.1082) | Loss 3.7430(3.7497) | Error 0.0367(0.0361) Steps 688(679.67) | Grad Norm 1.0000(1.4287) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0509 | Time 24.8235, Epoch Time 406.4721(408.8716), Bit/dim 3.7162(best: 3.7166), Xent 2.4832, Loss 4.9578, Error 0.4061(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3055 | Time 57.9438(61.1389) | Bit/dim 3.7016(3.6958) | Xent 0.0982(0.1079) | Loss 3.7507(3.7497) | Error 0.0340(0.0361) Steps 682(679.74) | Grad Norm 1.3517(1.4264) | Total Time 14.00(14.00)\n",
      "Iter 3056 | Time 58.9489(61.0732) | Bit/dim 3.6890(3.6956) | Xent 0.1020(0.1078) | Loss 3.7400(3.7494) | Error 0.0317(0.0359) Steps 694(680.17) | Grad Norm 1.2467(1.4210) | Total Time 14.00(14.00)\n",
      "Iter 3057 | Time 61.5932(61.0888) | Bit/dim 3.7005(3.6957) | Xent 0.1147(0.1080) | Loss 3.7579(3.7497) | Error 0.0363(0.0360) Steps 670(679.86) | Grad Norm 1.2140(1.4148) | Total Time 14.00(14.00)\n",
      "Iter 3058 | Time 57.6469(60.9855) | Bit/dim 3.6936(3.6956) | Xent 0.1069(0.1079) | Loss 3.7471(3.7496) | Error 0.0371(0.0360) Steps 676(679.75) | Grad Norm 0.9860(1.4019) | Total Time 14.00(14.00)\n",
      "Iter 3059 | Time 59.9323(60.9539) | Bit/dim 3.6969(3.6957) | Xent 0.1071(0.1079) | Loss 3.7505(3.7496) | Error 0.0356(0.0360) Steps 682(679.81) | Grad Norm 1.7967(1.4138) | Total Time 14.00(14.00)\n",
      "Iter 3060 | Time 60.9301(60.9532) | Bit/dim 3.6931(3.6956) | Xent 0.1113(0.1080) | Loss 3.7488(3.7496) | Error 0.0396(0.0361) Steps 676(679.70) | Grad Norm 1.0671(1.4034) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0510 | Time 25.4312, Epoch Time 398.0440(408.5468), Bit/dim 3.7165(best: 3.7162), Xent 2.4769, Loss 4.9550, Error 0.4057(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3061 | Time 59.9752(60.9239) | Bit/dim 3.6867(3.6953) | Xent 0.1103(0.1081) | Loss 3.7419(3.7494) | Error 0.0385(0.0362) Steps 676(679.59) | Grad Norm 1.2444(1.3986) | Total Time 14.00(14.00)\n",
      "Iter 3062 | Time 62.3422(60.9664) | Bit/dim 3.6910(3.6952) | Xent 0.1062(0.1080) | Loss 3.7441(3.7492) | Error 0.0345(0.0361) Steps 688(679.84) | Grad Norm 2.0722(1.4188) | Total Time 14.00(14.00)\n",
      "Iter 3063 | Time 59.6201(60.9260) | Bit/dim 3.6969(3.6953) | Xent 0.1092(0.1081) | Loss 3.7515(3.7493) | Error 0.0359(0.0361) Steps 682(679.91) | Grad Norm 1.8924(1.4330) | Total Time 14.00(14.00)\n",
      "Iter 3064 | Time 61.7915(60.9520) | Bit/dim 3.6902(3.6951) | Xent 0.1063(0.1080) | Loss 3.7433(3.7491) | Error 0.0350(0.0361) Steps 694(680.33) | Grad Norm 0.8263(1.4148) | Total Time 14.00(14.00)\n",
      "Iter 3065 | Time 61.9519(60.9820) | Bit/dim 3.6974(3.6952) | Xent 0.1148(0.1082) | Loss 3.7548(3.7493) | Error 0.0367(0.0361) Steps 676(680.20) | Grad Norm 3.4961(1.4773) | Total Time 14.00(14.00)\n",
      "Iter 3066 | Time 59.0659(60.9245) | Bit/dim 3.7019(3.6954) | Xent 0.1045(0.1081) | Loss 3.7542(3.7494) | Error 0.0340(0.0360) Steps 682(680.25) | Grad Norm 1.5487(1.4794) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0511 | Time 25.3624, Epoch Time 405.9804(408.4698), Bit/dim 3.7178(best: 3.7162), Xent 2.4704, Loss 4.9530, Error 0.4065(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3067 | Time 59.8099(60.8911) | Bit/dim 3.6835(3.6950) | Xent 0.1094(0.1081) | Loss 3.7382(3.7491) | Error 0.0350(0.0360) Steps 676(680.12) | Grad Norm 0.9671(1.4640) | Total Time 14.00(14.00)\n",
      "Iter 3068 | Time 63.1102(60.9577) | Bit/dim 3.6990(3.6951) | Xent 0.1076(0.1081) | Loss 3.7528(3.7492) | Error 0.0364(0.0360) Steps 670(679.82) | Grad Norm 1.6161(1.4686) | Total Time 14.00(14.00)\n",
      "Iter 3069 | Time 58.4344(60.8820) | Bit/dim 3.6971(3.6952) | Xent 0.0970(0.1078) | Loss 3.7455(3.7491) | Error 0.0319(0.0359) Steps 682(679.89) | Grad Norm 1.4627(1.4684) | Total Time 14.00(14.00)\n",
      "Iter 3070 | Time 63.8596(60.9713) | Bit/dim 3.6958(3.6952) | Xent 0.1056(0.1077) | Loss 3.7486(3.7491) | Error 0.0330(0.0358) Steps 670(679.59) | Grad Norm 1.3819(1.4658) | Total Time 14.00(14.00)\n",
      "Iter 3071 | Time 60.4227(60.9548) | Bit/dim 3.6960(3.6952) | Xent 0.1068(0.1077) | Loss 3.7494(3.7491) | Error 0.0370(0.0358) Steps 676(679.48) | Grad Norm 1.1517(1.4564) | Total Time 14.00(14.00)\n",
      "Iter 3072 | Time 62.8386(61.0113) | Bit/dim 3.6977(3.6953) | Xent 0.1038(0.1076) | Loss 3.7496(3.7491) | Error 0.0347(0.0358) Steps 664(679.02) | Grad Norm 1.0388(1.4439) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0512 | Time 25.0341, Epoch Time 409.4469(408.4991), Bit/dim 3.7173(best: 3.7162), Xent 2.5174, Loss 4.9760, Error 0.4044(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3073 | Time 61.0186(61.0116) | Bit/dim 3.6981(3.6954) | Xent 0.1057(0.1075) | Loss 3.7509(3.7492) | Error 0.0349(0.0358) Steps 682(679.11) | Grad Norm 1.0852(1.4331) | Total Time 14.00(14.00)\n",
      "Iter 3074 | Time 60.2044(60.9873) | Bit/dim 3.6958(3.6954) | Xent 0.1068(0.1075) | Loss 3.7492(3.7492) | Error 0.0341(0.0357) Steps 676(679.01) | Grad Norm 1.7825(1.4436) | Total Time 14.00(14.00)\n",
      "Iter 3075 | Time 61.8043(61.0119) | Bit/dim 3.6949(3.6954) | Xent 0.0959(0.1072) | Loss 3.7428(3.7490) | Error 0.0312(0.0356) Steps 670(678.74) | Grad Norm 1.7397(1.4525) | Total Time 14.00(14.00)\n",
      "Iter 3076 | Time 61.3785(61.0229) | Bit/dim 3.6968(3.6954) | Xent 0.1008(0.1070) | Loss 3.7472(3.7489) | Error 0.0337(0.0355) Steps 682(678.84) | Grad Norm 1.2991(1.4479) | Total Time 14.00(14.00)\n",
      "Iter 3077 | Time 61.3709(61.0333) | Bit/dim 3.6959(3.6954) | Xent 0.1034(0.1069) | Loss 3.7476(3.7489) | Error 0.0336(0.0355) Steps 694(679.30) | Grad Norm 2.0433(1.4657) | Total Time 14.00(14.00)\n",
      "Iter 3078 | Time 58.7512(60.9648) | Bit/dim 3.6899(3.6953) | Xent 0.1149(0.1071) | Loss 3.7474(3.7488) | Error 0.0375(0.0355) Steps 682(679.38) | Grad Norm 2.3969(1.4937) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0513 | Time 25.0862, Epoch Time 405.6807(408.4145), Bit/dim 3.7164(best: 3.7162), Xent 2.5167, Loss 4.9747, Error 0.4089(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3079 | Time 64.0137(61.0563) | Bit/dim 3.6854(3.6950) | Xent 0.1118(0.1072) | Loss 3.7413(3.7486) | Error 0.0366(0.0356) Steps 688(679.64) | Grad Norm 0.8524(1.4744) | Total Time 14.00(14.00)\n",
      "Iter 3080 | Time 61.5541(61.0712) | Bit/dim 3.6963(3.6950) | Xent 0.1127(0.1074) | Loss 3.7526(3.7487) | Error 0.0390(0.0357) Steps 676(679.53) | Grad Norm 1.3419(1.4705) | Total Time 14.00(14.00)\n",
      "Iter 3081 | Time 60.8302(61.0640) | Bit/dim 3.6969(3.6951) | Xent 0.1059(0.1074) | Loss 3.7499(3.7488) | Error 0.0353(0.0357) Steps 688(679.78) | Grad Norm 1.5929(1.4741) | Total Time 14.00(14.00)\n",
      "Iter 3082 | Time 61.3707(61.0732) | Bit/dim 3.6976(3.6952) | Xent 0.1106(0.1075) | Loss 3.7529(3.7489) | Error 0.0353(0.0356) Steps 670(679.49) | Grad Norm 1.0158(1.4604) | Total Time 14.00(14.00)\n",
      "Iter 3083 | Time 62.6183(61.1196) | Bit/dim 3.6840(3.6948) | Xent 0.1050(0.1074) | Loss 3.7365(3.7485) | Error 0.0325(0.0356) Steps 664(679.02) | Grad Norm 1.3929(1.4584) | Total Time 14.00(14.00)\n",
      "Iter 3084 | Time 61.0951(61.1188) | Bit/dim 3.7022(3.6950) | Xent 0.1084(0.1074) | Loss 3.7563(3.7487) | Error 0.0349(0.0355) Steps 682(679.11) | Grad Norm 1.1609(1.4494) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0514 | Time 24.8278, Epoch Time 412.0051(408.5222), Bit/dim 3.7172(best: 3.7162), Xent 2.4848, Loss 4.9595, Error 0.4046(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3085 | Time 63.1945(61.1811) | Bit/dim 3.6923(3.6950) | Xent 0.1016(0.1072) | Loss 3.7431(3.7486) | Error 0.0347(0.0355) Steps 676(679.02) | Grad Norm 1.5158(1.4514) | Total Time 14.00(14.00)\n",
      "Iter 3086 | Time 61.0157(61.1761) | Bit/dim 3.6988(3.6951) | Xent 0.1016(0.1071) | Loss 3.7496(3.7486) | Error 0.0324(0.0354) Steps 682(679.11) | Grad Norm 1.3030(1.4470) | Total Time 14.00(14.00)\n",
      "Iter 3087 | Time 62.2981(61.2098) | Bit/dim 3.7008(3.6952) | Xent 0.1036(0.1070) | Loss 3.7526(3.7487) | Error 0.0337(0.0354) Steps 682(679.20) | Grad Norm 1.1121(1.4369) | Total Time 14.00(14.00)\n",
      "Iter 3088 | Time 61.6583(61.2232) | Bit/dim 3.6969(3.6953) | Xent 0.1092(0.1070) | Loss 3.7515(3.7488) | Error 0.0370(0.0354) Steps 682(679.28) | Grad Norm 1.9707(1.4529) | Total Time 14.00(14.00)\n",
      "Iter 3089 | Time 59.8953(61.1834) | Bit/dim 3.6899(3.6951) | Xent 0.0994(0.1068) | Loss 3.7396(3.7485) | Error 0.0329(0.0353) Steps 682(679.36) | Grad Norm 1.0469(1.4408) | Total Time 14.00(14.00)\n",
      "Iter 3090 | Time 59.5590(61.1347) | Bit/dim 3.6889(3.6949) | Xent 0.1123(0.1070) | Loss 3.7451(3.7484) | Error 0.0386(0.0354) Steps 694(679.80) | Grad Norm 1.1755(1.4328) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0515 | Time 25.2017, Epoch Time 408.8837(408.5331), Bit/dim 3.7179(best: 3.7162), Xent 2.5117, Loss 4.9738, Error 0.4033(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3091 | Time 58.7412(61.0629) | Bit/dim 3.6999(3.6951) | Xent 0.1038(0.1069) | Loss 3.7518(3.7485) | Error 0.0340(0.0354) Steps 670(679.51) | Grad Norm 1.3064(1.4290) | Total Time 14.00(14.00)\n",
      "Iter 3092 | Time 62.0209(61.0916) | Bit/dim 3.6784(3.6946) | Xent 0.1052(0.1068) | Loss 3.7310(3.7480) | Error 0.0363(0.0354) Steps 682(679.58) | Grad Norm 1.3326(1.4261) | Total Time 14.00(14.00)\n",
      "Iter 3093 | Time 60.4267(61.0717) | Bit/dim 3.6911(3.6945) | Xent 0.1007(0.1066) | Loss 3.7415(3.7478) | Error 0.0344(0.0354) Steps 670(679.29) | Grad Norm 1.1297(1.4172) | Total Time 14.00(14.00)\n",
      "Iter 3094 | Time 61.3476(61.0799) | Bit/dim 3.7001(3.6947) | Xent 0.1101(0.1067) | Loss 3.7551(3.7480) | Error 0.0366(0.0354) Steps 676(679.19) | Grad Norm 1.5485(1.4212) | Total Time 14.00(14.00)\n",
      "Iter 3095 | Time 61.1509(61.0821) | Bit/dim 3.6940(3.6946) | Xent 0.1021(0.1066) | Loss 3.7450(3.7479) | Error 0.0350(0.0354) Steps 688(679.46) | Grad Norm 0.8037(1.4026) | Total Time 14.00(14.00)\n",
      "Iter 3096 | Time 61.8746(61.1058) | Bit/dim 3.7069(3.6950) | Xent 0.1088(0.1067) | Loss 3.7613(3.7483) | Error 0.0371(0.0355) Steps 676(679.35) | Grad Norm 1.4658(1.4045) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0516 | Time 24.9334, Epoch Time 406.0813(408.4595), Bit/dim 3.7166(best: 3.7162), Xent 2.4843, Loss 4.9588, Error 0.4004(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3097 | Time 60.1530(61.0773) | Bit/dim 3.7009(3.6952) | Xent 0.1025(0.1065) | Loss 3.7522(3.7485) | Error 0.0346(0.0354) Steps 682(679.43) | Grad Norm 1.1052(1.3956) | Total Time 14.00(14.00)\n",
      "Iter 3098 | Time 61.6078(61.0932) | Bit/dim 3.7039(3.6954) | Xent 0.0981(0.1063) | Loss 3.7530(3.7486) | Error 0.0326(0.0354) Steps 694(679.87) | Grad Norm 1.5444(1.4000) | Total Time 14.00(14.00)\n",
      "Iter 3099 | Time 61.4426(61.1037) | Bit/dim 3.6873(3.6952) | Xent 0.1150(0.1066) | Loss 3.7448(3.7485) | Error 0.0370(0.0354) Steps 676(679.76) | Grad Norm 1.5102(1.4033) | Total Time 14.00(14.00)\n",
      "Iter 3100 | Time 62.8219(61.1552) | Bit/dim 3.6901(3.6951) | Xent 0.0987(0.1063) | Loss 3.7395(3.7482) | Error 0.0349(0.0354) Steps 682(679.82) | Grad Norm 1.6253(1.4100) | Total Time 14.00(14.00)\n",
      "Iter 3101 | Time 63.2382(61.2177) | Bit/dim 3.6910(3.6949) | Xent 0.1025(0.1062) | Loss 3.7422(3.7480) | Error 0.0365(0.0354) Steps 688(680.07) | Grad Norm 1.0801(1.4001) | Total Time 14.00(14.00)\n",
      "Iter 3102 | Time 60.5530(61.1978) | Bit/dim 3.6965(3.6950) | Xent 0.1058(0.1062) | Loss 3.7494(3.7481) | Error 0.0349(0.0354) Steps 688(680.31) | Grad Norm 1.6485(1.4075) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0517 | Time 25.3814, Epoch Time 411.0226(408.5364), Bit/dim 3.7165(best: 3.7162), Xent 2.4893, Loss 4.9612, Error 0.4026(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3103 | Time 61.7350(61.2139) | Bit/dim 3.6997(3.6951) | Xent 0.1134(0.1064) | Loss 3.7564(3.7483) | Error 0.0393(0.0355) Steps 682(680.36) | Grad Norm 1.4781(1.4097) | Total Time 14.00(14.00)\n",
      "Iter 3104 | Time 57.6427(61.1067) | Bit/dim 3.6930(3.6951) | Xent 0.1049(0.1064) | Loss 3.7455(3.7482) | Error 0.0329(0.0354) Steps 682(680.41) | Grad Norm 2.0011(1.4274) | Total Time 14.00(14.00)\n",
      "Iter 3105 | Time 61.7659(61.1265) | Bit/dim 3.6909(3.6949) | Xent 0.1053(0.1063) | Loss 3.7435(3.7481) | Error 0.0384(0.0355) Steps 694(680.81) | Grad Norm 2.1682(1.4496) | Total Time 14.00(14.00)\n",
      "Iter 3106 | Time 57.9318(61.0307) | Bit/dim 3.6936(3.6949) | Xent 0.1054(0.1063) | Loss 3.7463(3.7480) | Error 0.0315(0.0354) Steps 676(680.67) | Grad Norm 0.8693(1.4322) | Total Time 14.00(14.00)\n",
      "Iter 3107 | Time 61.3024(61.0388) | Bit/dim 3.6894(3.6947) | Xent 0.1084(0.1064) | Loss 3.7436(3.7479) | Error 0.0354(0.0354) Steps 676(680.53) | Grad Norm 1.8008(1.4433) | Total Time 14.00(14.00)\n",
      "Iter 3108 | Time 58.5323(60.9636) | Bit/dim 3.6999(3.6949) | Xent 0.1146(0.1066) | Loss 3.7572(3.7482) | Error 0.0363(0.0354) Steps 670(680.21) | Grad Norm 3.1339(1.4940) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0518 | Time 25.1278, Epoch Time 400.2660(408.2883), Bit/dim 3.7169(best: 3.7162), Xent 2.5096, Loss 4.9717, Error 0.4063(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3109 | Time 60.1116(60.9381) | Bit/dim 3.6932(3.6948) | Xent 0.1047(0.1066) | Loss 3.7455(3.7481) | Error 0.0366(0.0355) Steps 688(680.45) | Grad Norm 1.1044(1.4823) | Total Time 14.00(14.00)\n",
      "Iter 3110 | Time 59.7819(60.9034) | Bit/dim 3.6934(3.6948) | Xent 0.0977(0.1063) | Loss 3.7422(3.7479) | Error 0.0327(0.0354) Steps 676(680.31) | Grad Norm 1.6931(1.4886) | Total Time 14.00(14.00)\n",
      "Iter 3111 | Time 60.5099(60.8916) | Bit/dim 3.6960(3.6948) | Xent 0.1101(0.1064) | Loss 3.7511(3.7480) | Error 0.0354(0.0354) Steps 664(679.82) | Grad Norm 2.4639(1.5179) | Total Time 14.00(14.00)\n",
      "Iter 3112 | Time 60.3070(60.8740) | Bit/dim 3.6821(3.6944) | Xent 0.1109(0.1065) | Loss 3.7375(3.7477) | Error 0.0385(0.0355) Steps 670(679.53) | Grad Norm 1.1681(1.5074) | Total Time 14.00(14.00)\n",
      "Iter 3113 | Time 61.5388(60.8940) | Bit/dim 3.6946(3.6944) | Xent 0.1039(0.1065) | Loss 3.7465(3.7477) | Error 0.0353(0.0355) Steps 676(679.42) | Grad Norm 0.7640(1.4851) | Total Time 14.00(14.00)\n",
      "Iter 3114 | Time 61.0758(60.8994) | Bit/dim 3.7013(3.6947) | Xent 0.1201(0.1069) | Loss 3.7614(3.7481) | Error 0.0399(0.0356) Steps 664(678.96) | Grad Norm 2.5073(1.5158) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0519 | Time 24.9742, Epoch Time 403.9616(408.1585), Bit/dim 3.7158(best: 3.7162), Xent 2.5193, Loss 4.9755, Error 0.4066(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3115 | Time 61.2647(60.9104) | Bit/dim 3.6953(3.6947) | Xent 0.1076(0.1069) | Loss 3.7491(3.7481) | Error 0.0356(0.0356) Steps 670(678.69) | Grad Norm 2.9393(1.5585) | Total Time 14.00(14.00)\n",
      "Iter 3116 | Time 60.1261(60.8869) | Bit/dim 3.6967(3.6947) | Xent 0.1079(0.1069) | Loss 3.7506(3.7482) | Error 0.0371(0.0357) Steps 688(678.97) | Grad Norm 1.4296(1.5546) | Total Time 14.00(14.00)\n",
      "Iter 3117 | Time 61.4495(60.9037) | Bit/dim 3.6945(3.6947) | Xent 0.1046(0.1069) | Loss 3.7468(3.7482) | Error 0.0351(0.0356) Steps 676(678.88) | Grad Norm 1.5830(1.5555) | Total Time 14.00(14.00)\n",
      "Iter 3118 | Time 64.2631(61.0045) | Bit/dim 3.6821(3.6943) | Xent 0.1110(0.1070) | Loss 3.7376(3.7478) | Error 0.0374(0.0357) Steps 676(678.80) | Grad Norm 2.9245(1.5965) | Total Time 14.00(14.00)\n",
      "Iter 3119 | Time 60.3719(60.9855) | Bit/dim 3.7014(3.6946) | Xent 0.0983(0.1067) | Loss 3.7505(3.7479) | Error 0.0345(0.0357) Steps 676(678.71) | Grad Norm 1.4839(1.5931) | Total Time 14.00(14.00)\n",
      "Iter 3120 | Time 60.9189(60.9835) | Bit/dim 3.7032(3.6948) | Xent 0.1052(0.1067) | Loss 3.7558(3.7482) | Error 0.0345(0.0356) Steps 682(678.81) | Grad Norm 1.1341(1.5794) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0520 | Time 25.1599, Epoch Time 409.4769(408.1981), Bit/dim 3.7164(best: 3.7158), Xent 2.4689, Loss 4.9509, Error 0.4012(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3121 | Time 60.4926(60.9688) | Bit/dim 3.6856(3.6945) | Xent 0.1006(0.1065) | Loss 3.7359(3.7478) | Error 0.0330(0.0355) Steps 682(678.91) | Grad Norm 2.5049(1.6071) | Total Time 14.00(14.00)\n",
      "Iter 3122 | Time 62.1975(61.0057) | Bit/dim 3.6926(3.6945) | Xent 0.1071(0.1065) | Loss 3.7461(3.7477) | Error 0.0363(0.0356) Steps 688(679.18) | Grad Norm 1.8602(1.6147) | Total Time 14.00(14.00)\n",
      "Iter 3123 | Time 61.6682(61.0256) | Bit/dim 3.6970(3.6946) | Xent 0.1116(0.1067) | Loss 3.7528(3.7479) | Error 0.0347(0.0355) Steps 688(679.44) | Grad Norm 1.2046(1.6024) | Total Time 14.00(14.00)\n",
      "Iter 3124 | Time 60.7865(61.0184) | Bit/dim 3.6979(3.6947) | Xent 0.1128(0.1068) | Loss 3.7543(3.7481) | Error 0.0371(0.0356) Steps 682(679.52) | Grad Norm 2.3119(1.6237) | Total Time 14.00(14.00)\n",
      "Iter 3125 | Time 59.8872(60.9844) | Bit/dim 3.6928(3.6946) | Xent 0.1097(0.1069) | Loss 3.7476(3.7481) | Error 0.0376(0.0356) Steps 676(679.41) | Grad Norm 3.0607(1.6668) | Total Time 14.00(14.00)\n",
      "Iter 3126 | Time 60.0893(60.9576) | Bit/dim 3.6972(3.6947) | Xent 0.1033(0.1068) | Loss 3.7488(3.7481) | Error 0.0347(0.0356) Steps 682(679.49) | Grad Norm 1.1055(1.6500) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0521 | Time 24.9008, Epoch Time 405.9388(408.1303), Bit/dim 3.7157(best: 3.7158), Xent 2.4902, Loss 4.9608, Error 0.4043(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3127 | Time 63.5970(61.0368) | Bit/dim 3.6967(3.6947) | Xent 0.1009(0.1066) | Loss 3.7472(3.7481) | Error 0.0335(0.0356) Steps 682(679.57) | Grad Norm 1.5622(1.6474) | Total Time 14.00(14.00)\n",
      "Iter 3128 | Time 60.7040(61.0268) | Bit/dim 3.7059(3.6951) | Xent 0.1077(0.1067) | Loss 3.7597(3.7484) | Error 0.0353(0.0355) Steps 682(679.64) | Grad Norm 2.0994(1.6609) | Total Time 14.00(14.00)\n",
      "Iter 3129 | Time 59.7416(60.9882) | Bit/dim 3.6948(3.6951) | Xent 0.1095(0.1068) | Loss 3.7496(3.7484) | Error 0.0359(0.0356) Steps 670(679.35) | Grad Norm 1.0331(1.6421) | Total Time 14.00(14.00)\n",
      "Iter 3130 | Time 60.1343(60.9626) | Bit/dim 3.6929(3.6950) | Xent 0.0981(0.1065) | Loss 3.7420(3.7483) | Error 0.0309(0.0354) Steps 682(679.43) | Grad Norm 1.2932(1.6316) | Total Time 14.00(14.00)\n",
      "Iter 3131 | Time 61.9755(60.9930) | Bit/dim 3.6843(3.6947) | Xent 0.1084(0.1066) | Loss 3.7385(3.7480) | Error 0.0394(0.0355) Steps 682(679.51) | Grad Norm 1.2425(1.6199) | Total Time 14.00(14.00)\n",
      "Iter 3132 | Time 62.1632(61.0281) | Bit/dim 3.6915(3.6946) | Xent 0.1081(0.1066) | Loss 3.7456(3.7479) | Error 0.0347(0.0355) Steps 670(679.22) | Grad Norm 1.3076(1.6106) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0522 | Time 25.1305, Epoch Time 409.0292(408.1573), Bit/dim 3.7167(best: 3.7157), Xent 2.4667, Loss 4.9500, Error 0.4004(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3133 | Time 63.9511(61.1158) | Bit/dim 3.6924(3.6945) | Xent 0.0943(0.1062) | Loss 3.7395(3.7476) | Error 0.0311(0.0354) Steps 682(679.31) | Grad Norm 1.0064(1.5924) | Total Time 14.00(14.00)\n",
      "Iter 3134 | Time 60.2840(61.0908) | Bit/dim 3.6953(3.6945) | Xent 0.1060(0.1062) | Loss 3.7483(3.7477) | Error 0.0363(0.0354) Steps 682(679.39) | Grad Norm 1.5265(1.5905) | Total Time 14.00(14.00)\n",
      "Iter 3135 | Time 61.1365(61.0922) | Bit/dim 3.7007(3.6947) | Xent 0.1041(0.1062) | Loss 3.7527(3.7478) | Error 0.0344(0.0354) Steps 670(679.11) | Grad Norm 1.4267(1.5855) | Total Time 14.00(14.00)\n",
      "Iter 3136 | Time 62.2351(61.1265) | Bit/dim 3.6977(3.6948) | Xent 0.1037(0.1061) | Loss 3.7495(3.7479) | Error 0.0353(0.0354) Steps 706(679.91) | Grad Norm 1.0484(1.5694) | Total Time 14.00(14.00)\n",
      "Iter 3137 | Time 63.1570(61.1874) | Bit/dim 3.6939(3.6948) | Xent 0.1018(0.1060) | Loss 3.7448(3.7478) | Error 0.0331(0.0353) Steps 700(680.51) | Grad Norm 1.4178(1.5649) | Total Time 14.00(14.00)\n",
      "Iter 3138 | Time 63.5888(61.2595) | Bit/dim 3.6874(3.6946) | Xent 0.1023(0.1059) | Loss 3.7386(3.7475) | Error 0.0353(0.0353) Steps 682(680.56) | Grad Norm 1.0355(1.5490) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0523 | Time 25.0776, Epoch Time 415.2733(408.3707), Bit/dim 3.7169(best: 3.7157), Xent 2.5164, Loss 4.9751, Error 0.4053(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3139 | Time 60.9769(61.2510) | Bit/dim 3.6908(3.6945) | Xent 0.1017(0.1057) | Loss 3.7417(3.7473) | Error 0.0339(0.0353) Steps 682(680.60) | Grad Norm 1.1147(1.5360) | Total Time 14.00(14.00)\n",
      "Iter 3140 | Time 59.2425(61.1907) | Bit/dim 3.6867(3.6942) | Xent 0.0962(0.1054) | Loss 3.7348(3.7469) | Error 0.0319(0.0352) Steps 682(680.64) | Grad Norm 0.9916(1.5196) | Total Time 14.00(14.00)\n",
      "Iter 3141 | Time 60.3903(61.1667) | Bit/dim 3.7040(3.6945) | Xent 0.1020(0.1053) | Loss 3.7550(3.7472) | Error 0.0354(0.0352) Steps 682(680.68) | Grad Norm 0.8805(1.5005) | Total Time 14.00(14.00)\n",
      "Iter 3142 | Time 61.6038(61.1798) | Bit/dim 3.6992(3.6947) | Xent 0.0954(0.1050) | Loss 3.7469(3.7472) | Error 0.0306(0.0350) Steps 682(680.72) | Grad Norm 1.0290(1.4863) | Total Time 14.00(14.00)\n",
      "Iter 3143 | Time 63.3622(61.2453) | Bit/dim 3.6918(3.6946) | Xent 0.1070(0.1051) | Loss 3.7453(3.7471) | Error 0.0360(0.0351) Steps 682(680.76) | Grad Norm 1.6342(1.4908) | Total Time 14.00(14.00)\n",
      "Iter 3144 | Time 59.8073(61.2022) | Bit/dim 3.6896(3.6944) | Xent 0.1049(0.1051) | Loss 3.7421(3.7470) | Error 0.0343(0.0350) Steps 682(680.80) | Grad Norm 1.0609(1.4779) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0524 | Time 25.0950, Epoch Time 406.1447(408.3040), Bit/dim 3.7168(best: 3.7157), Xent 2.5419, Loss 4.9877, Error 0.4077(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3145 | Time 61.6134(61.2145) | Bit/dim 3.6782(3.6939) | Xent 0.1080(0.1052) | Loss 3.7322(3.7465) | Error 0.0371(0.0351) Steps 682(680.84) | Grad Norm 1.4675(1.4776) | Total Time 14.00(14.00)\n",
      "Iter 3146 | Time 60.5243(61.1938) | Bit/dim 3.6847(3.6937) | Xent 0.1063(0.1052) | Loss 3.7379(3.7463) | Error 0.0363(0.0351) Steps 676(680.69) | Grad Norm 1.5222(1.4789) | Total Time 14.00(14.00)\n",
      "Iter 3147 | Time 62.5016(61.2330) | Bit/dim 3.7014(3.6939) | Xent 0.0993(0.1050) | Loss 3.7510(3.7464) | Error 0.0334(0.0351) Steps 676(680.55) | Grad Norm 0.9095(1.4618) | Total Time 14.00(14.00)\n",
      "Iter 3148 | Time 61.5651(61.2430) | Bit/dim 3.7025(3.6942) | Xent 0.0982(0.1048) | Loss 3.7516(3.7466) | Error 0.0301(0.0349) Steps 682(680.59) | Grad Norm 0.8876(1.4446) | Total Time 14.00(14.00)\n",
      "Iter 3149 | Time 61.1528(61.2403) | Bit/dim 3.6908(3.6941) | Xent 0.1056(0.1048) | Loss 3.7436(3.7465) | Error 0.0353(0.0349) Steps 682(680.64) | Grad Norm 1.4773(1.4456) | Total Time 14.00(14.00)\n",
      "Iter 3150 | Time 59.8433(61.1984) | Bit/dim 3.7037(3.6943) | Xent 0.1015(0.1047) | Loss 3.7545(3.7467) | Error 0.0316(0.0348) Steps 676(680.50) | Grad Norm 2.2136(1.4686) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0525 | Time 24.8605, Epoch Time 407.5256(408.2806), Bit/dim 3.7163(best: 3.7157), Xent 2.4953, Loss 4.9639, Error 0.4040(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3151 | Time 58.5387(61.1186) | Bit/dim 3.6967(3.6944) | Xent 0.1017(0.1047) | Loss 3.7475(3.7467) | Error 0.0333(0.0348) Steps 676(680.36) | Grad Norm 0.7845(1.4481) | Total Time 14.00(14.00)\n",
      "Iter 3152 | Time 61.1112(61.1184) | Bit/dim 3.6985(3.6945) | Xent 0.0997(0.1045) | Loss 3.7484(3.7468) | Error 0.0339(0.0348) Steps 676(680.23) | Grad Norm 1.2929(1.4434) | Total Time 14.00(14.00)\n",
      "Iter 3153 | Time 62.4285(61.1577) | Bit/dim 3.6902(3.6944) | Xent 0.1006(0.1044) | Loss 3.7405(3.7466) | Error 0.0343(0.0347) Steps 676(680.10) | Grad Norm 1.2262(1.4369) | Total Time 14.00(14.00)\n",
      "Iter 3154 | Time 62.3744(61.1942) | Bit/dim 3.6922(3.6943) | Xent 0.0976(0.1042) | Loss 3.7410(3.7464) | Error 0.0321(0.0347) Steps 682(680.16) | Grad Norm 1.3491(1.4343) | Total Time 14.00(14.00)\n",
      "Iter 3155 | Time 61.7783(61.2117) | Bit/dim 3.6959(3.6944) | Xent 0.0961(0.1039) | Loss 3.7439(3.7464) | Error 0.0315(0.0346) Steps 682(680.22) | Grad Norm 1.7805(1.4447) | Total Time 14.00(14.00)\n",
      "Iter 3156 | Time 60.7931(61.1991) | Bit/dim 3.6870(3.6942) | Xent 0.1065(0.1040) | Loss 3.7403(3.7462) | Error 0.0353(0.0346) Steps 676(680.09) | Grad Norm 2.1921(1.4671) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0526 | Time 24.7441, Epoch Time 407.4707(408.2563), Bit/dim 3.7163(best: 3.7157), Xent 2.5218, Loss 4.9772, Error 0.4038(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3157 | Time 60.2928(61.1719) | Bit/dim 3.6838(3.6939) | Xent 0.1046(0.1040) | Loss 3.7362(3.7459) | Error 0.0357(0.0346) Steps 682(680.15) | Grad Norm 1.4874(1.4677) | Total Time 14.00(14.00)\n",
      "Iter 3158 | Time 58.0346(61.0778) | Bit/dim 3.6958(3.6939) | Xent 0.1022(0.1040) | Loss 3.7469(3.7459) | Error 0.0336(0.0346) Steps 676(680.02) | Grad Norm 1.6098(1.4720) | Total Time 14.00(14.00)\n",
      "Iter 3159 | Time 59.4079(61.0277) | Bit/dim 3.7012(3.6941) | Xent 0.0937(0.1037) | Loss 3.7480(3.7460) | Error 0.0310(0.0345) Steps 664(679.54) | Grad Norm 1.0841(1.4603) | Total Time 14.00(14.00)\n",
      "Iter 3160 | Time 60.8004(61.0209) | Bit/dim 3.6901(3.6940) | Xent 0.1021(0.1036) | Loss 3.7412(3.7458) | Error 0.0350(0.0345) Steps 670(679.26) | Grad Norm 1.2869(1.4551) | Total Time 14.00(14.00)\n",
      "Iter 3161 | Time 60.9565(61.0190) | Bit/dim 3.6905(3.6939) | Xent 0.0985(0.1035) | Loss 3.7398(3.7456) | Error 0.0309(0.0344) Steps 682(679.34) | Grad Norm 1.3520(1.4520) | Total Time 14.00(14.00)\n",
      "Iter 3162 | Time 63.1349(61.0825) | Bit/dim 3.7011(3.6941) | Xent 0.1018(0.1034) | Loss 3.7521(3.7458) | Error 0.0340(0.0344) Steps 688(679.60) | Grad Norm 1.0129(1.4389) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0527 | Time 24.8306, Epoch Time 403.4203(408.1112), Bit/dim 3.7161(best: 3.7157), Xent 2.5125, Loss 4.9723, Error 0.4054(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3163 | Time 63.4754(61.1542) | Bit/dim 3.6952(3.6942) | Xent 0.0974(0.1032) | Loss 3.7439(3.7458) | Error 0.0329(0.0343) Steps 682(679.67) | Grad Norm 0.9930(1.4255) | Total Time 14.00(14.00)\n",
      "Iter 3164 | Time 58.3736(61.0708) | Bit/dim 3.6937(3.6941) | Xent 0.0895(0.1028) | Loss 3.7385(3.7456) | Error 0.0290(0.0342) Steps 694(680.10) | Grad Norm 0.9168(1.4102) | Total Time 14.00(14.00)\n",
      "Iter 3165 | Time 60.8748(61.0649) | Bit/dim 3.6964(3.6942) | Xent 0.1043(0.1029) | Loss 3.7485(3.7456) | Error 0.0336(0.0342) Steps 670(679.80) | Grad Norm 0.9401(1.3961) | Total Time 14.00(14.00)\n",
      "Iter 3166 | Time 60.5296(61.0489) | Bit/dim 3.6908(3.6941) | Xent 0.1085(0.1030) | Loss 3.7450(3.7456) | Error 0.0373(0.0343) Steps 676(679.68) | Grad Norm 1.2902(1.3929) | Total Time 14.00(14.00)\n",
      "Iter 3167 | Time 59.7049(61.0086) | Bit/dim 3.6998(3.6943) | Xent 0.1009(0.1030) | Loss 3.7503(3.7458) | Error 0.0355(0.0343) Steps 682(679.75) | Grad Norm 1.0916(1.3839) | Total Time 14.00(14.00)\n",
      "Iter 3168 | Time 61.4137(61.0207) | Bit/dim 3.6890(3.6941) | Xent 0.1051(0.1030) | Loss 3.7416(3.7456) | Error 0.0346(0.0343) Steps 676(679.64) | Grad Norm 1.3264(1.3822) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0528 | Time 25.0766, Epoch Time 405.2570(408.0256), Bit/dim 3.7160(best: 3.7157), Xent 2.4992, Loss 4.9656, Error 0.4041(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3169 | Time 61.9684(61.0491) | Bit/dim 3.7065(3.6945) | Xent 0.0958(0.1028) | Loss 3.7544(3.7459) | Error 0.0315(0.0342) Steps 694(680.07) | Grad Norm 1.0380(1.3718) | Total Time 14.00(14.00)\n",
      "Iter 3170 | Time 59.8483(61.0131) | Bit/dim 3.7022(3.6947) | Xent 0.0991(0.1027) | Loss 3.7518(3.7461) | Error 0.0330(0.0342) Steps 676(679.95) | Grad Norm 0.8170(1.3552) | Total Time 14.00(14.00)\n",
      "Iter 3171 | Time 63.6225(61.0914) | Bit/dim 3.6823(3.6943) | Xent 0.0995(0.1026) | Loss 3.7321(3.7457) | Error 0.0320(0.0341) Steps 676(679.83) | Grad Norm 1.0978(1.3475) | Total Time 14.00(14.00)\n",
      "Iter 3172 | Time 59.0131(61.0291) | Bit/dim 3.6916(3.6943) | Xent 0.1013(0.1026) | Loss 3.7422(3.7456) | Error 0.0329(0.0341) Steps 682(679.90) | Grad Norm 0.8982(1.3340) | Total Time 14.00(14.00)\n",
      "Iter 3173 | Time 60.6467(61.0176) | Bit/dim 3.6922(3.6942) | Xent 0.1069(0.1027) | Loss 3.7457(3.7456) | Error 0.0349(0.0341) Steps 670(679.60) | Grad Norm 1.1073(1.3272) | Total Time 14.00(14.00)\n",
      "Iter 3174 | Time 60.0026(60.9871) | Bit/dim 3.6891(3.6940) | Xent 0.0998(0.1026) | Loss 3.7390(3.7454) | Error 0.0364(0.0342) Steps 676(679.49) | Grad Norm 1.5996(1.3354) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0529 | Time 25.3604, Epoch Time 406.1199(407.9684), Bit/dim 3.7165(best: 3.7157), Xent 2.5336, Loss 4.9832, Error 0.4028(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3175 | Time 62.2262(61.0243) | Bit/dim 3.6885(3.6939) | Xent 0.0982(0.1025) | Loss 3.7376(3.7451) | Error 0.0327(0.0341) Steps 670(679.21) | Grad Norm 1.1235(1.3290) | Total Time 14.00(14.00)\n",
      "Iter 3176 | Time 62.3983(61.0655) | Bit/dim 3.7061(3.6942) | Xent 0.0997(0.1024) | Loss 3.7560(3.7455) | Error 0.0308(0.0340) Steps 688(679.47) | Grad Norm 1.0119(1.3195) | Total Time 14.00(14.00)\n",
      "Iter 3177 | Time 59.5950(61.0214) | Bit/dim 3.6861(3.6940) | Xent 0.1087(0.1026) | Loss 3.7404(3.7453) | Error 0.0370(0.0341) Steps 670(679.19) | Grad Norm 1.5367(1.3260) | Total Time 14.00(14.00)\n",
      "Iter 3178 | Time 58.2038(60.9369) | Bit/dim 3.6822(3.6936) | Xent 0.0994(0.1025) | Loss 3.7319(3.7449) | Error 0.0330(0.0341) Steps 682(679.27) | Grad Norm 1.6572(1.3359) | Total Time 14.00(14.00)\n",
      "Iter 3179 | Time 62.4816(60.9832) | Bit/dim 3.7007(3.6939) | Xent 0.1113(0.1028) | Loss 3.7563(3.7452) | Error 0.0364(0.0342) Steps 688(679.53) | Grad Norm 0.9535(1.3245) | Total Time 14.00(14.00)\n",
      "Iter 3180 | Time 60.9158(60.9812) | Bit/dim 3.7023(3.6941) | Xent 0.1017(0.1027) | Loss 3.7532(3.7455) | Error 0.0344(0.0342) Steps 670(679.25) | Grad Norm 1.6925(1.3355) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0530 | Time 25.1365, Epoch Time 406.6525(407.9290), Bit/dim 3.7156(best: 3.7157), Xent 2.5187, Loss 4.9749, Error 0.4041(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3181 | Time 60.6433(60.9711) | Bit/dim 3.6903(3.6940) | Xent 0.1066(0.1029) | Loss 3.7436(3.7454) | Error 0.0364(0.0342) Steps 676(679.15) | Grad Norm 2.0162(1.3559) | Total Time 14.00(14.00)\n",
      "Iter 3182 | Time 63.1885(61.0376) | Bit/dim 3.7033(3.6943) | Xent 0.1038(0.1029) | Loss 3.7552(3.7457) | Error 0.0350(0.0342) Steps 694(679.59) | Grad Norm 1.6710(1.3654) | Total Time 14.00(14.00)\n",
      "Iter 3183 | Time 61.3339(61.0465) | Bit/dim 3.6864(3.6940) | Xent 0.0938(0.1026) | Loss 3.7333(3.7453) | Error 0.0330(0.0342) Steps 676(679.49) | Grad Norm 1.1308(1.3584) | Total Time 14.00(14.00)\n",
      "Iter 3184 | Time 61.1688(61.0501) | Bit/dim 3.6883(3.6939) | Xent 0.1035(0.1026) | Loss 3.7400(3.7452) | Error 0.0353(0.0342) Steps 682(679.56) | Grad Norm 2.2160(1.3841) | Total Time 14.00(14.00)\n",
      "Iter 3185 | Time 61.5131(61.0640) | Bit/dim 3.6980(3.6940) | Xent 0.0975(0.1025) | Loss 3.7467(3.7452) | Error 0.0347(0.0343) Steps 700(680.17) | Grad Norm 2.1194(1.4061) | Total Time 14.00(14.00)\n",
      "Iter 3186 | Time 61.5227(61.0778) | Bit/dim 3.6943(3.6940) | Xent 0.1067(0.1026) | Loss 3.7476(3.7453) | Error 0.0333(0.0342) Steps 688(680.41) | Grad Norm 1.5717(1.4111) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0531 | Time 24.9252, Epoch Time 410.1619(407.9959), Bit/dim 3.7159(best: 3.7156), Xent 2.5386, Loss 4.9852, Error 0.4028(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3187 | Time 60.2576(61.0532) | Bit/dim 3.6915(3.6939) | Xent 0.1058(0.1027) | Loss 3.7444(3.7453) | Error 0.0340(0.0342) Steps 670(680.10) | Grad Norm 1.7854(1.4223) | Total Time 14.00(14.00)\n",
      "Iter 3188 | Time 59.8973(61.0185) | Bit/dim 3.6930(3.6939) | Xent 0.1015(0.1027) | Loss 3.7438(3.7452) | Error 0.0354(0.0343) Steps 682(680.15) | Grad Norm 1.5590(1.4264) | Total Time 14.00(14.00)\n",
      "Iter 3189 | Time 61.0146(61.0184) | Bit/dim 3.6977(3.6940) | Xent 0.1000(0.1026) | Loss 3.7477(3.7453) | Error 0.0334(0.0342) Steps 682(680.21) | Grad Norm 1.2708(1.4218) | Total Time 14.00(14.00)\n",
      "Iter 3190 | Time 58.5355(60.9439) | Bit/dim 3.6896(3.6939) | Xent 0.0987(0.1025) | Loss 3.7390(3.7451) | Error 0.0326(0.0342) Steps 676(680.08) | Grad Norm 1.3388(1.4193) | Total Time 14.00(14.00)\n",
      "Iter 3191 | Time 60.3944(60.9274) | Bit/dim 3.6949(3.6939) | Xent 0.0975(0.1023) | Loss 3.7437(3.7451) | Error 0.0335(0.0342) Steps 676(679.96) | Grad Norm 1.1140(1.4101) | Total Time 14.00(14.00)\n",
      "Iter 3192 | Time 61.8553(60.9553) | Bit/dim 3.6911(3.6938) | Xent 0.0959(0.1021) | Loss 3.7391(3.7449) | Error 0.0329(0.0341) Steps 682(680.02) | Grad Norm 1.1639(1.4027) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0532 | Time 24.9066, Epoch Time 402.9110(407.8434), Bit/dim 3.7156(best: 3.7156), Xent 2.5621, Loss 4.9967, Error 0.4101(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3193 | Time 62.3847(60.9981) | Bit/dim 3.6894(3.6937) | Xent 0.1049(0.1022) | Loss 3.7418(3.7448) | Error 0.0347(0.0341) Steps 676(679.90) | Grad Norm 1.1836(1.3962) | Total Time 14.00(14.00)\n",
      "Iter 3194 | Time 61.7243(61.0199) | Bit/dim 3.6906(3.6936) | Xent 0.1049(0.1023) | Loss 3.7430(3.7447) | Error 0.0357(0.0342) Steps 682(679.96) | Grad Norm 1.2760(1.3926) | Total Time 14.00(14.00)\n",
      "Iter 3195 | Time 60.9381(61.0175) | Bit/dim 3.6977(3.6937) | Xent 0.0972(0.1021) | Loss 3.7463(3.7448) | Error 0.0321(0.0341) Steps 676(679.85) | Grad Norm 1.2346(1.3878) | Total Time 14.00(14.00)\n",
      "Iter 3196 | Time 64.6311(61.1259) | Bit/dim 3.7064(3.6941) | Xent 0.1068(0.1023) | Loss 3.7597(3.7452) | Error 0.0371(0.0342) Steps 676(679.73) | Grad Norm 1.2809(1.3846) | Total Time 14.00(14.00)\n",
      "Iter 3197 | Time 62.0340(61.1531) | Bit/dim 3.6922(3.6940) | Xent 0.1010(0.1022) | Loss 3.7427(3.7452) | Error 0.0344(0.0342) Steps 670(679.44) | Grad Norm 1.3641(1.3840) | Total Time 14.00(14.00)\n",
      "Iter 3198 | Time 62.9521(61.2071) | Bit/dim 3.6792(3.6936) | Xent 0.0996(0.1022) | Loss 3.7290(3.7447) | Error 0.0316(0.0341) Steps 682(679.51) | Grad Norm 0.9513(1.3710) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0533 | Time 25.2683, Epoch Time 415.7285(408.0799), Bit/dim 3.7152(best: 3.7156), Xent 2.5316, Loss 4.9811, Error 0.4019(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3199 | Time 60.3400(61.1811) | Bit/dim 3.6886(3.6935) | Xent 0.0990(0.1021) | Loss 3.7381(3.7445) | Error 0.0340(0.0341) Steps 676(679.41) | Grad Norm 1.6513(1.3794) | Total Time 14.00(14.00)\n",
      "Iter 3200 | Time 63.2410(61.2429) | Bit/dim 3.6859(3.6932) | Xent 0.1046(0.1021) | Loss 3.7381(3.7443) | Error 0.0344(0.0341) Steps 688(679.67) | Grad Norm 1.1973(1.3740) | Total Time 14.00(14.00)\n",
      "Iter 3201 | Time 61.7817(61.2590) | Bit/dim 3.6966(3.6933) | Xent 0.1038(0.1022) | Loss 3.7485(3.7444) | Error 0.0350(0.0342) Steps 676(679.56) | Grad Norm 1.4365(1.3758) | Total Time 14.00(14.00)\n",
      "Iter 3202 | Time 60.9124(61.2486) | Bit/dim 3.6953(3.6934) | Xent 0.0967(0.1020) | Loss 3.7437(3.7444) | Error 0.0339(0.0342) Steps 670(679.27) | Grad Norm 0.9768(1.3639) | Total Time 14.00(14.00)\n",
      "Iter 3203 | Time 62.0370(61.2723) | Bit/dim 3.6989(3.6935) | Xent 0.1001(0.1020) | Loss 3.7489(3.7445) | Error 0.0344(0.0342) Steps 670(678.99) | Grad Norm 1.5513(1.3695) | Total Time 14.00(14.00)\n",
      "Iter 3204 | Time 62.6979(61.3151) | Bit/dim 3.6947(3.6936) | Xent 0.1030(0.1020) | Loss 3.7462(3.7446) | Error 0.0320(0.0341) Steps 688(679.26) | Grad Norm 1.4116(1.3708) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0534 | Time 25.2852, Epoch Time 411.7781(408.1909), Bit/dim 3.7159(best: 3.7152), Xent 2.5188, Loss 4.9753, Error 0.4043(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3205 | Time 58.8761(61.2419) | Bit/dim 3.6924(3.6935) | Xent 0.0958(0.1018) | Loss 3.7403(3.7445) | Error 0.0314(0.0340) Steps 664(678.80) | Grad Norm 0.9769(1.3589) | Total Time 14.00(14.00)\n",
      "Iter 3206 | Time 62.2670(61.2726) | Bit/dim 3.6932(3.6935) | Xent 0.0988(0.1017) | Loss 3.7425(3.7444) | Error 0.0333(0.0340) Steps 688(679.08) | Grad Norm 1.1590(1.3529) | Total Time 14.00(14.00)\n",
      "Iter 3207 | Time 62.9620(61.3233) | Bit/dim 3.6903(3.6934) | Xent 0.1010(0.1017) | Loss 3.7408(3.7443) | Error 0.0345(0.0340) Steps 694(679.53) | Grad Norm 1.1606(1.3472) | Total Time 14.00(14.00)\n",
      "Iter 3208 | Time 62.2666(61.3516) | Bit/dim 3.7006(3.6937) | Xent 0.1003(0.1017) | Loss 3.7507(3.7445) | Error 0.0312(0.0339) Steps 682(679.60) | Grad Norm 1.2054(1.3429) | Total Time 14.00(14.00)\n",
      "Iter 3209 | Time 62.4129(61.3835) | Bit/dim 3.6833(3.6933) | Xent 0.1016(0.1017) | Loss 3.7341(3.7442) | Error 0.0356(0.0340) Steps 682(679.67) | Grad Norm 1.3313(1.3426) | Total Time 14.00(14.00)\n",
      "Iter 3210 | Time 63.7162(61.4534) | Bit/dim 3.6964(3.6934) | Xent 0.0999(0.1016) | Loss 3.7464(3.7442) | Error 0.0360(0.0340) Steps 670(679.38) | Grad Norm 1.8086(1.3565) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0535 | Time 24.4525, Epoch Time 412.7649(408.3281), Bit/dim 3.7155(best: 3.7152), Xent 2.5260, Loss 4.9785, Error 0.4028(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3211 | Time 58.6645(61.3698) | Bit/dim 3.6956(3.6935) | Xent 0.1068(0.1018) | Loss 3.7490(3.7444) | Error 0.0374(0.0341) Steps 676(679.28) | Grad Norm 1.9740(1.3751) | Total Time 14.00(14.00)\n",
      "Iter 3212 | Time 60.8837(61.3552) | Bit/dim 3.6895(3.6934) | Xent 0.1010(0.1017) | Loss 3.7400(3.7442) | Error 0.0331(0.0341) Steps 688(679.54) | Grad Norm 1.3626(1.3747) | Total Time 14.00(14.00)\n",
      "Iter 3213 | Time 60.6120(61.3329) | Bit/dim 3.6984(3.6935) | Xent 0.1025(0.1018) | Loss 3.7496(3.7444) | Error 0.0366(0.0342) Steps 676(679.44) | Grad Norm 1.6198(1.3821) | Total Time 14.00(14.00)\n",
      "Iter 3214 | Time 62.5390(61.3691) | Bit/dim 3.6957(3.6936) | Xent 0.1024(0.1018) | Loss 3.7469(3.7445) | Error 0.0326(0.0341) Steps 676(679.33) | Grad Norm 1.4773(1.3849) | Total Time 14.00(14.00)\n",
      "Iter 3215 | Time 64.3062(61.4572) | Bit/dim 3.6978(3.6937) | Xent 0.0862(0.1013) | Loss 3.7409(3.7444) | Error 0.0302(0.0340) Steps 670(679.05) | Grad Norm 1.1789(1.3787) | Total Time 14.00(14.00)\n",
      "Iter 3216 | Time 60.7072(61.4347) | Bit/dim 3.6831(3.6934) | Xent 0.0923(0.1010) | Loss 3.7293(3.7439) | Error 0.0304(0.0339) Steps 670(678.78) | Grad Norm 1.7598(1.3902) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0536 | Time 25.2748, Epoch Time 408.7032(408.3394), Bit/dim 3.7149(best: 3.7152), Xent 2.5385, Loss 4.9842, Error 0.4046(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3217 | Time 57.7997(61.3256) | Bit/dim 3.7047(3.6937) | Xent 0.0950(0.1009) | Loss 3.7523(3.7442) | Error 0.0306(0.0338) Steps 664(678.34) | Grad Norm 1.0468(1.3799) | Total Time 14.00(14.00)\n",
      "Iter 3218 | Time 63.1068(61.3791) | Bit/dim 3.6938(3.6937) | Xent 0.0950(0.1007) | Loss 3.7413(3.7441) | Error 0.0321(0.0338) Steps 676(678.27) | Grad Norm 1.5678(1.3855) | Total Time 14.00(14.00)\n",
      "Iter 3219 | Time 61.1229(61.3714) | Bit/dim 3.6908(3.6937) | Xent 0.0957(0.1005) | Loss 3.7386(3.7439) | Error 0.0331(0.0337) Steps 694(678.74) | Grad Norm 1.0836(1.3764) | Total Time 14.00(14.00)\n",
      "Iter 3220 | Time 60.7104(61.3516) | Bit/dim 3.6964(3.6937) | Xent 0.1025(0.1006) | Loss 3.7476(3.7440) | Error 0.0339(0.0337) Steps 676(678.66) | Grad Norm 1.4786(1.3795) | Total Time 14.00(14.00)\n",
      "Iter 3221 | Time 62.0462(61.3724) | Bit/dim 3.6925(3.6937) | Xent 0.0960(0.1005) | Loss 3.7405(3.7439) | Error 0.0331(0.0337) Steps 682(678.76) | Grad Norm 1.1983(1.3741) | Total Time 14.00(14.00)\n",
      "Iter 3222 | Time 61.9008(61.3883) | Bit/dim 3.6854(3.6935) | Xent 0.1054(0.1006) | Loss 3.7381(3.7438) | Error 0.0346(0.0338) Steps 682(678.86) | Grad Norm 1.3970(1.3748) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0537 | Time 25.0056, Epoch Time 407.3661(408.3102), Bit/dim 3.7162(best: 3.7149), Xent 2.5539, Loss 4.9932, Error 0.4023(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3223 | Time 58.6956(61.3075) | Bit/dim 3.6919(3.6934) | Xent 0.0919(0.1003) | Loss 3.7379(3.7436) | Error 0.0295(0.0336) Steps 670(678.59) | Grad Norm 1.1369(1.3676) | Total Time 14.00(14.00)\n",
      "Iter 3224 | Time 61.4324(61.3112) | Bit/dim 3.6890(3.6933) | Xent 0.1005(0.1003) | Loss 3.7392(3.7434) | Error 0.0314(0.0336) Steps 658(677.97) | Grad Norm 2.3723(1.3978) | Total Time 14.00(14.00)\n",
      "Iter 3225 | Time 58.8454(61.2372) | Bit/dim 3.6958(3.6933) | Xent 0.0924(0.1001) | Loss 3.7420(3.7434) | Error 0.0314(0.0335) Steps 682(678.09) | Grad Norm 1.6466(1.4052) | Total Time 14.00(14.00)\n",
      "Iter 3226 | Time 63.2454(61.2975) | Bit/dim 3.7032(3.6936) | Xent 0.0956(0.1000) | Loss 3.7510(3.7436) | Error 0.0325(0.0335) Steps 670(677.85) | Grad Norm 1.2913(1.4018) | Total Time 14.00(14.00)\n",
      "Iter 3227 | Time 60.9719(61.2877) | Bit/dim 3.6872(3.6934) | Xent 0.1108(0.1003) | Loss 3.7426(3.7436) | Error 0.0387(0.0336) Steps 670(677.62) | Grad Norm 2.2687(1.4278) | Total Time 14.00(14.00)\n",
      "Iter 3228 | Time 60.1280(61.2529) | Bit/dim 3.6902(3.6934) | Xent 0.1033(0.1004) | Loss 3.7419(3.7435) | Error 0.0325(0.0336) Steps 676(677.57) | Grad Norm 1.5231(1.4307) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0538 | Time 25.1469, Epoch Time 404.0595(408.1826), Bit/dim 3.7156(best: 3.7149), Xent 2.5302, Loss 4.9807, Error 0.4073(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3229 | Time 62.2779(61.2837) | Bit/dim 3.7062(3.6937) | Xent 0.0956(0.1002) | Loss 3.7540(3.7439) | Error 0.0323(0.0336) Steps 676(677.52) | Grad Norm 1.3260(1.4275) | Total Time 14.00(14.00)\n",
      "Iter 3230 | Time 61.0522(61.2767) | Bit/dim 3.7002(3.6939) | Xent 0.0966(0.1001) | Loss 3.7485(3.7440) | Error 0.0325(0.0335) Steps 688(677.83) | Grad Norm 2.3718(1.4559) | Total Time 14.00(14.00)\n",
      "Iter 3231 | Time 61.7960(61.2923) | Bit/dim 3.6861(3.6937) | Xent 0.1005(0.1001) | Loss 3.7363(3.7438) | Error 0.0320(0.0335) Steps 676(677.78) | Grad Norm 1.6623(1.4621) | Total Time 14.00(14.00)\n",
      "Iter 3232 | Time 59.7852(61.2471) | Bit/dim 3.6929(3.6937) | Xent 0.1000(0.1001) | Loss 3.7429(3.7437) | Error 0.0317(0.0334) Steps 676(677.73) | Grad Norm 1.5849(1.4657) | Total Time 14.00(14.00)\n",
      "Iter 3233 | Time 62.7720(61.2928) | Bit/dim 3.6868(3.6935) | Xent 0.0977(0.1001) | Loss 3.7356(3.7435) | Error 0.0319(0.0334) Steps 670(677.49) | Grad Norm 1.7895(1.4755) | Total Time 14.00(14.00)\n",
      "Iter 3234 | Time 61.9626(61.3129) | Bit/dim 3.6920(3.6934) | Xent 0.0913(0.0998) | Loss 3.7376(3.7433) | Error 0.0315(0.0333) Steps 676(677.45) | Grad Norm 1.8139(1.4856) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0539 | Time 25.0771, Epoch Time 410.6293(408.2560), Bit/dim 3.7151(best: 3.7149), Xent 2.5451, Loss 4.9877, Error 0.4015(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3235 | Time 60.8376(61.2987) | Bit/dim 3.6921(3.6934) | Xent 0.1004(0.0998) | Loss 3.7423(3.7433) | Error 0.0312(0.0333) Steps 676(677.41) | Grad Norm 1.6684(1.4911) | Total Time 14.00(14.00)\n",
      "Iter 3236 | Time 58.2029(61.2058) | Bit/dim 3.6966(3.6935) | Xent 0.1035(0.0999) | Loss 3.7483(3.7434) | Error 0.0361(0.0333) Steps 682(677.54) | Grad Norm 2.1574(1.5111) | Total Time 14.00(14.00)\n",
      "Iter 3237 | Time 65.0033(61.3197) | Bit/dim 3.6934(3.6935) | Xent 0.1044(0.1001) | Loss 3.7456(3.7435) | Error 0.0370(0.0335) Steps 670(677.32) | Grad Norm 2.0673(1.5278) | Total Time 14.00(14.00)\n",
      "Iter 3238 | Time 61.8075(61.3344) | Bit/dim 3.6991(3.6936) | Xent 0.0967(0.1000) | Loss 3.7475(3.7436) | Error 0.0327(0.0334) Steps 664(676.92) | Grad Norm 1.8911(1.5387) | Total Time 14.00(14.00)\n",
      "Iter 3239 | Time 60.1998(61.3003) | Bit/dim 3.6904(3.6935) | Xent 0.1032(0.1001) | Loss 3.7420(3.7436) | Error 0.0346(0.0335) Steps 664(676.53) | Grad Norm 2.5334(1.5685) | Total Time 14.00(14.00)\n",
      "Iter 3240 | Time 59.1471(61.2357) | Bit/dim 3.6839(3.6933) | Xent 0.1057(0.1002) | Loss 3.7368(3.7434) | Error 0.0359(0.0335) Steps 670(676.33) | Grad Norm 1.5478(1.5679) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0540 | Time 24.7084, Epoch Time 405.5413(408.1746), Bit/dim 3.7162(best: 3.7149), Xent 2.5574, Loss 4.9950, Error 0.4078(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3241 | Time 62.2762(61.2669) | Bit/dim 3.6867(3.6931) | Xent 0.1062(0.1004) | Loss 3.7398(3.7433) | Error 0.0343(0.0336) Steps 688(676.68) | Grad Norm 2.6652(1.6008) | Total Time 14.00(14.00)\n",
      "Iter 3242 | Time 63.4397(61.3321) | Bit/dim 3.6979(3.6932) | Xent 0.0939(0.1002) | Loss 3.7449(3.7433) | Error 0.0316(0.0335) Steps 676(676.66) | Grad Norm 1.2741(1.5910) | Total Time 14.00(14.00)\n",
      "Iter 3243 | Time 59.0266(61.2630) | Bit/dim 3.6931(3.6932) | Xent 0.1028(0.1003) | Loss 3.7445(3.7434) | Error 0.0357(0.0336) Steps 682(676.82) | Grad Norm 1.6820(1.5937) | Total Time 14.00(14.00)\n",
      "Iter 3244 | Time 61.8254(61.2798) | Bit/dim 3.6936(3.6932) | Xent 0.1039(0.1004) | Loss 3.7456(3.7434) | Error 0.0337(0.0336) Steps 670(676.62) | Grad Norm 1.1747(1.5812) | Total Time 14.00(14.00)\n",
      "Iter 3245 | Time 60.7695(61.2645) | Bit/dim 3.6888(3.6931) | Xent 0.0931(0.1002) | Loss 3.7354(3.7432) | Error 0.0306(0.0335) Steps 676(676.60) | Grad Norm 1.3742(1.5750) | Total Time 14.00(14.00)\n",
      "Iter 3246 | Time 62.8808(61.3130) | Bit/dim 3.6968(3.6932) | Xent 0.0981(0.1001) | Loss 3.7459(3.7433) | Error 0.0329(0.0335) Steps 676(676.58) | Grad Norm 1.2860(1.5663) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0541 | Time 24.9370, Epoch Time 411.0610(408.2612), Bit/dim 3.7151(best: 3.7149), Xent 2.5706, Loss 5.0004, Error 0.4047(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3247 | Time 59.3143(61.2531) | Bit/dim 3.6992(3.6934) | Xent 0.0941(0.0999) | Loss 3.7463(3.7434) | Error 0.0299(0.0334) Steps 682(676.75) | Grad Norm 1.0962(1.5522) | Total Time 14.00(14.00)\n",
      "Iter 3248 | Time 62.4851(61.2900) | Bit/dim 3.6937(3.6934) | Xent 0.0945(0.0998) | Loss 3.7409(3.7433) | Error 0.0301(0.0333) Steps 676(676.72) | Grad Norm 1.5577(1.5523) | Total Time 14.00(14.00)\n",
      "Iter 3249 | Time 60.9773(61.2806) | Bit/dim 3.6939(3.6934) | Xent 0.1055(0.0999) | Loss 3.7467(3.7434) | Error 0.0351(0.0333) Steps 688(677.06) | Grad Norm 1.5054(1.5509) | Total Time 14.00(14.00)\n",
      "Iter 3250 | Time 61.9813(61.3017) | Bit/dim 3.6820(3.6931) | Xent 0.0990(0.0999) | Loss 3.7316(3.7430) | Error 0.0320(0.0333) Steps 688(677.39) | Grad Norm 1.3645(1.5453) | Total Time 14.00(14.00)\n",
      "Iter 3251 | Time 62.4889(61.3373) | Bit/dim 3.6923(3.6930) | Xent 0.1051(0.1001) | Loss 3.7449(3.7431) | Error 0.0331(0.0333) Steps 682(677.53) | Grad Norm 2.0007(1.5590) | Total Time 14.00(14.00)\n",
      "Iter 3252 | Time 60.2088(61.3034) | Bit/dim 3.6883(3.6929) | Xent 0.0969(0.1000) | Loss 3.7368(3.7429) | Error 0.0316(0.0332) Steps 682(677.66) | Grad Norm 0.9408(1.5405) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0542 | Time 25.4814, Epoch Time 408.5873(408.2710), Bit/dim 3.7139(best: 3.7149), Xent 2.5608, Loss 4.9944, Error 0.4069(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3253 | Time 60.5434(61.2806) | Bit/dim 3.6838(3.6926) | Xent 0.1019(0.1000) | Loss 3.7348(3.7426) | Error 0.0341(0.0333) Steps 676(677.61) | Grad Norm 1.5055(1.5394) | Total Time 14.00(14.00)\n",
      "Iter 3254 | Time 57.9671(61.1812) | Bit/dim 3.6930(3.6926) | Xent 0.0950(0.0999) | Loss 3.7405(3.7426) | Error 0.0331(0.0332) Steps 676(677.56) | Grad Norm 1.0788(1.5256) | Total Time 14.00(14.00)\n",
      "Iter 3255 | Time 59.4845(61.1303) | Bit/dim 3.6962(3.6927) | Xent 0.1000(0.0999) | Loss 3.7462(3.7427) | Error 0.0350(0.0333) Steps 676(677.52) | Grad Norm 1.3064(1.5190) | Total Time 14.00(14.00)\n",
      "Iter 3256 | Time 61.6513(61.1459) | Bit/dim 3.6967(3.6929) | Xent 0.0978(0.0998) | Loss 3.7456(3.7428) | Error 0.0329(0.0333) Steps 670(677.29) | Grad Norm 0.9684(1.5025) | Total Time 14.00(14.00)\n",
      "Iter 3257 | Time 59.5149(61.0970) | Bit/dim 3.7020(3.6931) | Xent 0.1007(0.0999) | Loss 3.7524(3.7431) | Error 0.0353(0.0333) Steps 688(677.61) | Grad Norm 1.5861(1.5050) | Total Time 14.00(14.00)\n",
      "Iter 3258 | Time 58.8303(61.0290) | Bit/dim 3.6855(3.6929) | Xent 0.0967(0.0998) | Loss 3.7338(3.7428) | Error 0.0335(0.0334) Steps 664(677.20) | Grad Norm 1.1654(1.4948) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0543 | Time 24.9573, Epoch Time 398.7521(407.9854), Bit/dim 3.7166(best: 3.7139), Xent 2.5680, Loss 5.0006, Error 0.4050(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3259 | Time 59.5792(60.9855) | Bit/dim 3.6912(3.6929) | Xent 0.1017(0.0998) | Loss 3.7420(3.7428) | Error 0.0361(0.0334) Steps 670(676.99) | Grad Norm 1.2500(1.4875) | Total Time 14.00(14.00)\n",
      "Iter 3260 | Time 61.3062(60.9951) | Bit/dim 3.6918(3.6928) | Xent 0.1009(0.0999) | Loss 3.7422(3.7428) | Error 0.0341(0.0335) Steps 670(676.78) | Grad Norm 2.2386(1.5100) | Total Time 14.00(14.00)\n",
      "Iter 3261 | Time 61.5797(61.0127) | Bit/dim 3.6936(3.6928) | Xent 0.1026(0.0999) | Loss 3.7449(3.7428) | Error 0.0344(0.0335) Steps 682(676.93) | Grad Norm 1.4515(1.5083) | Total Time 14.00(14.00)\n",
      "Iter 3262 | Time 57.6675(60.9123) | Bit/dim 3.6911(3.6928) | Xent 0.1036(0.1000) | Loss 3.7429(3.7428) | Error 0.0364(0.0336) Steps 676(676.91) | Grad Norm 0.9546(1.4916) | Total Time 14.00(14.00)\n",
      "Iter 3263 | Time 61.7189(60.9365) | Bit/dim 3.6954(3.6929) | Xent 0.1034(0.1001) | Loss 3.7471(3.7429) | Error 0.0337(0.0336) Steps 676(676.88) | Grad Norm 1.4083(1.4891) | Total Time 14.00(14.00)\n",
      "Iter 3264 | Time 61.7488(60.9609) | Bit/dim 3.6878(3.6927) | Xent 0.1015(0.1002) | Loss 3.7386(3.7428) | Error 0.0339(0.0336) Steps 688(677.21) | Grad Norm 1.8569(1.5002) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0544 | Time 24.8997, Epoch Time 404.4661(407.8798), Bit/dim 3.7148(best: 3.7139), Xent 2.5483, Loss 4.9889, Error 0.4052(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3265 | Time 59.7513(60.9246) | Bit/dim 3.6964(3.6928) | Xent 0.0942(0.1000) | Loss 3.7435(3.7428) | Error 0.0311(0.0335) Steps 670(677.00) | Grad Norm 1.5442(1.5015) | Total Time 14.00(14.00)\n",
      "Iter 3266 | Time 60.4529(60.9104) | Bit/dim 3.6905(3.6928) | Xent 0.0916(0.0998) | Loss 3.7363(3.7426) | Error 0.0312(0.0334) Steps 682(677.15) | Grad Norm 1.0811(1.4889) | Total Time 14.00(14.00)\n",
      "Iter 3267 | Time 61.0556(60.9148) | Bit/dim 3.6908(3.6927) | Xent 0.0935(0.0996) | Loss 3.7375(3.7425) | Error 0.0300(0.0333) Steps 664(676.75) | Grad Norm 0.9058(1.4714) | Total Time 14.00(14.00)\n",
      "Iter 3268 | Time 60.4697(60.9014) | Bit/dim 3.6850(3.6925) | Xent 0.1062(0.0998) | Loss 3.7381(3.7424) | Error 0.0350(0.0334) Steps 682(676.91) | Grad Norm 1.5230(1.4729) | Total Time 14.00(14.00)\n",
      "Iter 3269 | Time 61.9513(60.9329) | Bit/dim 3.6945(3.6925) | Xent 0.0944(0.0996) | Loss 3.7417(3.7423) | Error 0.0305(0.0333) Steps 682(677.06) | Grad Norm 0.8796(1.4551) | Total Time 14.00(14.00)\n",
      "Iter 3270 | Time 63.0623(60.9968) | Bit/dim 3.6889(3.6924) | Xent 0.0964(0.0995) | Loss 3.7371(3.7422) | Error 0.0320(0.0333) Steps 682(677.21) | Grad Norm 1.3504(1.4520) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0545 | Time 25.0080, Epoch Time 407.8481(407.8789), Bit/dim 3.7149(best: 3.7139), Xent 2.5765, Loss 5.0031, Error 0.4044(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3271 | Time 61.5163(61.0124) | Bit/dim 3.6957(3.6925) | Xent 0.0972(0.0994) | Loss 3.7443(3.7422) | Error 0.0333(0.0333) Steps 670(676.99) | Grad Norm 1.3183(1.4480) | Total Time 14.00(14.00)\n",
      "Iter 3272 | Time 61.6343(61.0311) | Bit/dim 3.6973(3.6927) | Xent 0.0916(0.0992) | Loss 3.7431(3.7423) | Error 0.0296(0.0332) Steps 676(676.96) | Grad Norm 1.1065(1.4377) | Total Time 14.00(14.00)\n",
      "Iter 3273 | Time 59.7585(60.9929) | Bit/dim 3.6995(3.6929) | Xent 0.0987(0.0992) | Loss 3.7488(3.7425) | Error 0.0354(0.0332) Steps 670(676.76) | Grad Norm 1.1338(1.4286) | Total Time 14.00(14.00)\n",
      "Iter 3274 | Time 59.3539(60.9437) | Bit/dim 3.6929(3.6929) | Xent 0.0991(0.0992) | Loss 3.7424(3.7425) | Error 0.0343(0.0333) Steps 682(676.91) | Grad Norm 1.3616(1.4266) | Total Time 14.00(14.00)\n",
      "Iter 3275 | Time 62.8691(61.0015) | Bit/dim 3.6870(3.6927) | Xent 0.1006(0.0992) | Loss 3.7373(3.7423) | Error 0.0346(0.0333) Steps 676(676.89) | Grad Norm 1.4345(1.4269) | Total Time 14.00(14.00)\n",
      "Iter 3276 | Time 59.1094(60.9447) | Bit/dim 3.6844(3.6924) | Xent 0.0978(0.0992) | Loss 3.7333(3.7420) | Error 0.0321(0.0333) Steps 682(677.04) | Grad Norm 1.2005(1.4201) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0546 | Time 25.1623, Epoch Time 405.3003(407.8015), Bit/dim 3.7156(best: 3.7139), Xent 2.5905, Loss 5.0109, Error 0.4053(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3277 | Time 59.8568(60.9121) | Bit/dim 3.6974(3.6926) | Xent 0.1017(0.0993) | Loss 3.7482(3.7422) | Error 0.0357(0.0333) Steps 682(677.19) | Grad Norm 2.1437(1.4418) | Total Time 14.00(14.00)\n",
      "Iter 3278 | Time 58.5787(60.8421) | Bit/dim 3.6974(3.6927) | Xent 0.0940(0.0991) | Loss 3.7444(3.7423) | Error 0.0330(0.0333) Steps 670(676.97) | Grad Norm 1.2730(1.4367) | Total Time 14.00(14.00)\n",
      "Iter 3279 | Time 60.7670(60.8398) | Bit/dim 3.6937(3.6928) | Xent 0.0989(0.0991) | Loss 3.7432(3.7423) | Error 0.0330(0.0333) Steps 670(676.76) | Grad Norm 1.8633(1.4495) | Total Time 14.00(14.00)\n",
      "Iter 3280 | Time 59.9037(60.8117) | Bit/dim 3.6977(3.6929) | Xent 0.0942(0.0990) | Loss 3.7448(3.7424) | Error 0.0321(0.0333) Steps 682(676.92) | Grad Norm 1.8637(1.4619) | Total Time 14.00(14.00)\n",
      "Iter 3281 | Time 60.4362(60.8005) | Bit/dim 3.6880(3.6928) | Xent 0.0908(0.0987) | Loss 3.7334(3.7421) | Error 0.0290(0.0331) Steps 670(676.71) | Grad Norm 1.1394(1.4523) | Total Time 14.00(14.00)\n",
      "Iter 3282 | Time 61.3539(60.8171) | Bit/dim 3.6887(3.6926) | Xent 0.1015(0.0988) | Loss 3.7395(3.7420) | Error 0.0347(0.0332) Steps 676(676.69) | Grad Norm 2.7182(1.4902) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0547 | Time 25.0780, Epoch Time 401.4318(407.6104), Bit/dim 3.7143(best: 3.7139), Xent 2.5490, Loss 4.9888, Error 0.4034(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3283 | Time 62.8323(60.8775) | Bit/dim 3.6998(3.6929) | Xent 0.0922(0.0986) | Loss 3.7459(3.7422) | Error 0.0289(0.0331) Steps 682(676.85) | Grad Norm 1.4242(1.4882) | Total Time 14.00(14.00)\n",
      "Iter 3284 | Time 61.8464(60.9066) | Bit/dim 3.6953(3.6929) | Xent 0.1060(0.0988) | Loss 3.7483(3.7423) | Error 0.0336(0.0331) Steps 682(677.00) | Grad Norm 1.0884(1.4763) | Total Time 14.00(14.00)\n",
      "Iter 3285 | Time 59.8139(60.8738) | Bit/dim 3.6889(3.6928) | Xent 0.0880(0.0985) | Loss 3.7329(3.7421) | Error 0.0275(0.0329) Steps 682(677.15) | Grad Norm 1.8495(1.4875) | Total Time 14.00(14.00)\n",
      "Iter 3286 | Time 61.9199(60.9052) | Bit/dim 3.6956(3.6929) | Xent 0.0919(0.0983) | Loss 3.7416(3.7420) | Error 0.0327(0.0329) Steps 682(677.30) | Grad Norm 1.4345(1.4859) | Total Time 14.00(14.00)\n",
      "Iter 3287 | Time 61.3978(60.9200) | Bit/dim 3.6875(3.6927) | Xent 0.0976(0.0983) | Loss 3.7364(3.7419) | Error 0.0333(0.0329) Steps 676(677.26) | Grad Norm 1.2337(1.4783) | Total Time 14.00(14.00)\n",
      "Iter 3288 | Time 59.9684(60.8914) | Bit/dim 3.6877(3.6926) | Xent 0.0985(0.0983) | Loss 3.7369(3.7417) | Error 0.0333(0.0329) Steps 670(677.04) | Grad Norm 1.4437(1.4773) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0548 | Time 24.7154, Epoch Time 408.1059(407.6253), Bit/dim 3.7156(best: 3.7139), Xent 2.5783, Loss 5.0047, Error 0.4049(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3289 | Time 60.5555(60.8814) | Bit/dim 3.6951(3.6927) | Xent 0.1006(0.0984) | Loss 3.7455(3.7418) | Error 0.0329(0.0329) Steps 688(677.37) | Grad Norm 1.2365(1.4700) | Total Time 14.00(14.00)\n",
      "Iter 3290 | Time 60.3220(60.8646) | Bit/dim 3.6879(3.6925) | Xent 0.0972(0.0983) | Loss 3.7365(3.7417) | Error 0.0339(0.0330) Steps 670(677.15) | Grad Norm 1.8921(1.4827) | Total Time 14.00(14.00)\n",
      "Iter 3291 | Time 59.5430(60.8249) | Bit/dim 3.6879(3.6924) | Xent 0.0969(0.0983) | Loss 3.7364(3.7415) | Error 0.0323(0.0329) Steps 664(676.76) | Grad Norm 1.0900(1.4709) | Total Time 14.00(14.00)\n",
      "Iter 3292 | Time 59.5721(60.7873) | Bit/dim 3.6959(3.6925) | Xent 0.0977(0.0983) | Loss 3.7447(3.7416) | Error 0.0347(0.0330) Steps 670(676.55) | Grad Norm 1.2097(1.4631) | Total Time 14.00(14.00)\n",
      "Iter 3293 | Time 63.3848(60.8653) | Bit/dim 3.6879(3.6924) | Xent 0.0994(0.0983) | Loss 3.7376(3.7415) | Error 0.0321(0.0330) Steps 700(677.26) | Grad Norm 2.0468(1.4806) | Total Time 14.00(14.00)\n",
      "Iter 3294 | Time 60.6649(60.8593) | Bit/dim 3.6925(3.6924) | Xent 0.0960(0.0982) | Loss 3.7405(3.7415) | Error 0.0343(0.0330) Steps 664(676.86) | Grad Norm 1.1103(1.4695) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0549 | Time 25.1228, Epoch Time 410.5863(407.7141), Bit/dim 3.7145(best: 3.7139), Xent 2.5959, Loss 5.0124, Error 0.4085(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3295 | Time 59.3957(60.8154) | Bit/dim 3.7001(3.6926) | Xent 0.0951(0.0981) | Loss 3.7477(3.7417) | Error 0.0315(0.0330) Steps 670(676.65) | Grad Norm 2.1452(1.4898) | Total Time 14.00(14.00)\n",
      "Iter 3296 | Time 59.6950(60.7817) | Bit/dim 3.6788(3.6922) | Xent 0.1011(0.0982) | Loss 3.7293(3.7413) | Error 0.0343(0.0330) Steps 676(676.63) | Grad Norm 1.4327(1.4880) | Total Time 14.00(14.00)\n",
      "Iter 3297 | Time 61.2520(60.7958) | Bit/dim 3.6971(3.6923) | Xent 0.1029(0.0984) | Loss 3.7485(3.7415) | Error 0.0349(0.0331) Steps 688(676.97) | Grad Norm 1.1377(1.4775) | Total Time 14.00(14.00)\n",
      "Iter 3298 | Time 61.1010(60.8050) | Bit/dim 3.6986(3.6925) | Xent 0.0899(0.0981) | Loss 3.7436(3.7416) | Error 0.0298(0.0330) Steps 676(676.95) | Grad Norm 1.6464(1.4826) | Total Time 14.00(14.00)\n",
      "Iter 3299 | Time 59.1775(60.7562) | Bit/dim 3.6922(3.6925) | Xent 0.0947(0.0980) | Loss 3.7396(3.7415) | Error 0.0306(0.0329) Steps 676(676.92) | Grad Norm 1.3026(1.4772) | Total Time 14.00(14.00)\n",
      "Iter 3300 | Time 61.8066(60.7877) | Bit/dim 3.6850(3.6923) | Xent 0.0894(0.0977) | Loss 3.7297(3.7411) | Error 0.0284(0.0327) Steps 676(676.89) | Grad Norm 1.0907(1.4656) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0550 | Time 24.8982, Epoch Time 403.4176(407.5852), Bit/dim 3.7149(best: 3.7139), Xent 2.5679, Loss 4.9988, Error 0.4048(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3301 | Time 60.1007(60.7671) | Bit/dim 3.6885(3.6922) | Xent 0.0991(0.0978) | Loss 3.7381(3.7411) | Error 0.0320(0.0327) Steps 682(677.04) | Grad Norm 1.3208(1.4613) | Total Time 14.00(14.00)\n",
      "Iter 3302 | Time 62.8293(60.8289) | Bit/dim 3.6867(3.6920) | Xent 0.0941(0.0977) | Loss 3.7338(3.7408) | Error 0.0294(0.0326) Steps 688(677.37) | Grad Norm 1.5841(1.4650) | Total Time 14.00(14.00)\n",
      "Iter 3303 | Time 62.1919(60.8698) | Bit/dim 3.6878(3.6919) | Xent 0.0968(0.0976) | Loss 3.7362(3.7407) | Error 0.0320(0.0326) Steps 676(677.33) | Grad Norm 1.0363(1.4521) | Total Time 14.00(14.00)\n",
      "Iter 3304 | Time 61.3863(60.8853) | Bit/dim 3.6898(3.6918) | Xent 0.0896(0.0974) | Loss 3.7345(3.7405) | Error 0.0312(0.0326) Steps 688(677.65) | Grad Norm 1.8585(1.4643) | Total Time 14.00(14.00)\n",
      "Iter 3305 | Time 60.7602(60.8816) | Bit/dim 3.7003(3.6921) | Xent 0.0968(0.0974) | Loss 3.7487(3.7408) | Error 0.0314(0.0325) Steps 688(677.96) | Grad Norm 1.5023(1.4654) | Total Time 14.00(14.00)\n",
      "Iter 3306 | Time 57.5592(60.7819) | Bit/dim 3.6990(3.6923) | Xent 0.0882(0.0971) | Loss 3.7431(3.7408) | Error 0.0311(0.0325) Steps 682(678.08) | Grad Norm 1.0174(1.4520) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0551 | Time 24.8170, Epoch Time 405.2299(407.5146), Bit/dim 3.7148(best: 3.7139), Xent 2.5982, Loss 5.0139, Error 0.4079(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3307 | Time 61.5748(60.8057) | Bit/dim 3.6823(3.6920) | Xent 0.0968(0.0971) | Loss 3.7307(3.7405) | Error 0.0314(0.0325) Steps 664(677.66) | Grad Norm 0.9343(1.4365) | Total Time 14.00(14.00)\n",
      "Iter 3308 | Time 61.8728(60.8377) | Bit/dim 3.6909(3.6919) | Xent 0.1016(0.0972) | Loss 3.7416(3.7406) | Error 0.0337(0.0325) Steps 688(677.97) | Grad Norm 1.2818(1.4318) | Total Time 14.00(14.00)\n",
      "Iter 3309 | Time 61.8822(60.8690) | Bit/dim 3.6950(3.6920) | Xent 0.0968(0.0972) | Loss 3.7434(3.7406) | Error 0.0312(0.0325) Steps 670(677.73) | Grad Norm 1.4610(1.4327) | Total Time 14.00(14.00)\n",
      "Iter 3310 | Time 61.1756(60.8782) | Bit/dim 3.6922(3.6920) | Xent 0.0939(0.0971) | Loss 3.7391(3.7406) | Error 0.0316(0.0324) Steps 676(677.68) | Grad Norm 0.8961(1.4166) | Total Time 14.00(14.00)\n",
      "Iter 3311 | Time 59.5813(60.8393) | Bit/dim 3.6942(3.6921) | Xent 0.1006(0.0972) | Loss 3.7445(3.7407) | Error 0.0333(0.0325) Steps 676(677.63) | Grad Norm 1.4506(1.4176) | Total Time 14.00(14.00)\n",
      "Iter 3312 | Time 60.6145(60.8326) | Bit/dim 3.6951(3.6922) | Xent 0.0886(0.0970) | Loss 3.7394(3.7407) | Error 0.0288(0.0323) Steps 676(677.58) | Grad Norm 0.9102(1.4024) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0552 | Time 24.9352, Epoch Time 407.6638(407.5190), Bit/dim 3.7148(best: 3.7139), Xent 2.6091, Loss 5.0193, Error 0.4045(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3313 | Time 61.0232(60.8383) | Bit/dim 3.6893(3.6921) | Xent 0.0952(0.0969) | Loss 3.7369(3.7406) | Error 0.0310(0.0323) Steps 676(677.53) | Grad Norm 1.1675(1.3953) | Total Time 14.00(14.00)\n",
      "Iter 3314 | Time 59.6000(60.8012) | Bit/dim 3.6852(3.6919) | Xent 0.1025(0.0971) | Loss 3.7364(3.7404) | Error 0.0326(0.0323) Steps 676(677.49) | Grad Norm 1.1366(1.3876) | Total Time 14.00(14.00)\n",
      "Iter 3315 | Time 62.8880(60.8638) | Bit/dim 3.6997(3.6921) | Xent 0.0979(0.0971) | Loss 3.7486(3.7407) | Error 0.0316(0.0323) Steps 682(677.62) | Grad Norm 1.5755(1.3932) | Total Time 14.00(14.00)\n",
      "Iter 3316 | Time 62.0384(60.8990) | Bit/dim 3.6921(3.6921) | Xent 0.1059(0.0974) | Loss 3.7450(3.7408) | Error 0.0339(0.0323) Steps 676(677.57) | Grad Norm 1.1718(1.3866) | Total Time 14.00(14.00)\n",
      "Iter 3317 | Time 57.8494(60.8075) | Bit/dim 3.6896(3.6921) | Xent 0.0914(0.0972) | Loss 3.7353(3.7407) | Error 0.0288(0.0322) Steps 664(677.17) | Grad Norm 1.5580(1.3917) | Total Time 14.00(14.00)\n",
      "Iter 3318 | Time 60.6331(60.8023) | Bit/dim 3.6918(3.6920) | Xent 0.0971(0.0972) | Loss 3.7403(3.7406) | Error 0.0327(0.0322) Steps 682(677.31) | Grad Norm 0.9948(1.3798) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0553 | Time 25.3480, Epoch Time 404.7682(407.4365), Bit/dim 3.7153(best: 3.7139), Xent 2.5921, Loss 5.0114, Error 0.4085(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3319 | Time 59.6606(60.7680) | Bit/dim 3.6949(3.6921) | Xent 0.0957(0.0971) | Loss 3.7428(3.7407) | Error 0.0306(0.0322) Steps 670(677.09) | Grad Norm 1.3507(1.3789) | Total Time 14.00(14.00)\n",
      "Iter 3320 | Time 61.1973(60.7809) | Bit/dim 3.6944(3.6922) | Xent 0.0967(0.0971) | Loss 3.7427(3.7408) | Error 0.0327(0.0322) Steps 676(677.06) | Grad Norm 1.0621(1.3694) | Total Time 14.00(14.00)\n",
      "Iter 3321 | Time 64.8699(60.9036) | Bit/dim 3.6854(3.6920) | Xent 0.0848(0.0968) | Loss 3.7278(3.7404) | Error 0.0251(0.0320) Steps 694(677.57) | Grad Norm 0.8965(1.3552) | Total Time 14.00(14.00)\n",
      "Iter 3322 | Time 62.6416(60.9557) | Bit/dim 3.6894(3.6919) | Xent 0.0905(0.0966) | Loss 3.7346(3.7402) | Error 0.0290(0.0319) Steps 682(677.70) | Grad Norm 1.2478(1.3520) | Total Time 14.00(14.00)\n",
      "Iter 3323 | Time 61.3878(60.9687) | Bit/dim 3.7011(3.6922) | Xent 0.0963(0.0966) | Loss 3.7493(3.7405) | Error 0.0319(0.0319) Steps 676(677.65) | Grad Norm 1.8289(1.3663) | Total Time 14.00(14.00)\n",
      "Iter 3324 | Time 57.3459(60.8600) | Bit/dim 3.6851(3.6920) | Xent 0.0929(0.0965) | Loss 3.7316(3.7402) | Error 0.0315(0.0319) Steps 670(677.42) | Grad Norm 1.4334(1.3683) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0554 | Time 24.9595, Epoch Time 407.9128(407.4508), Bit/dim 3.7152(best: 3.7139), Xent 2.5985, Loss 5.0144, Error 0.4062(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3325 | Time 59.0747(60.8064) | Bit/dim 3.6891(3.6919) | Xent 0.1029(0.0967) | Loss 3.7405(3.7402) | Error 0.0346(0.0320) Steps 682(677.56) | Grad Norm 1.8801(1.3837) | Total Time 14.00(14.00)\n",
      "Iter 3326 | Time 60.5467(60.7986) | Bit/dim 3.6967(3.6920) | Xent 0.0975(0.0967) | Loss 3.7454(3.7404) | Error 0.0315(0.0320) Steps 676(677.51) | Grad Norm 1.8230(1.3969) | Total Time 14.00(14.00)\n",
      "Iter 3327 | Time 60.1672(60.7797) | Bit/dim 3.6822(3.6917) | Xent 0.0973(0.0967) | Loss 3.7309(3.7401) | Error 0.0304(0.0319) Steps 664(677.11) | Grad Norm 1.9046(1.4121) | Total Time 14.00(14.00)\n",
      "Iter 3328 | Time 59.6257(60.7451) | Bit/dim 3.6931(3.6918) | Xent 0.0868(0.0964) | Loss 3.7365(3.7400) | Error 0.0281(0.0318) Steps 664(676.71) | Grad Norm 1.0143(1.4002) | Total Time 14.00(14.00)\n",
      "Iter 3329 | Time 61.4750(60.7670) | Bit/dim 3.6946(3.6919) | Xent 0.0976(0.0964) | Loss 3.7434(3.7401) | Error 0.0321(0.0318) Steps 682(676.87) | Grad Norm 2.5101(1.4335) | Total Time 14.00(14.00)\n",
      "Iter 3330 | Time 61.3014(60.7830) | Bit/dim 3.6949(3.6920) | Xent 0.0964(0.0964) | Loss 3.7432(3.7402) | Error 0.0302(0.0318) Steps 676(676.84) | Grad Norm 2.2543(1.4581) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0555 | Time 24.8919, Epoch Time 403.0827(407.3198), Bit/dim 3.7149(best: 3.7139), Xent 2.5899, Loss 5.0098, Error 0.4053(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3331 | Time 60.1330(60.7635) | Bit/dim 3.6963(3.6921) | Xent 0.1007(0.0966) | Loss 3.7466(3.7404) | Error 0.0344(0.0318) Steps 676(676.82) | Grad Norm 1.2227(1.4510) | Total Time 14.00(14.00)\n",
      "Iter 3332 | Time 60.4657(60.7546) | Bit/dim 3.6866(3.6919) | Xent 0.0938(0.0965) | Loss 3.7335(3.7402) | Error 0.0316(0.0318) Steps 682(676.97) | Grad Norm 1.9309(1.4654) | Total Time 14.00(14.00)\n",
      "Iter 3333 | Time 59.5342(60.7180) | Bit/dim 3.6924(3.6919) | Xent 0.0907(0.0963) | Loss 3.7378(3.7401) | Error 0.0312(0.0318) Steps 676(676.95) | Grad Norm 2.0152(1.4819) | Total Time 14.00(14.00)\n",
      "Iter 3334 | Time 62.0715(60.7586) | Bit/dim 3.6951(3.6920) | Xent 0.0965(0.0963) | Loss 3.7433(3.7402) | Error 0.0319(0.0318) Steps 670(676.74) | Grad Norm 1.2737(1.4757) | Total Time 14.00(14.00)\n",
      "Iter 3335 | Time 59.7664(60.7288) | Bit/dim 3.6841(3.6918) | Xent 0.0942(0.0962) | Loss 3.7312(3.7399) | Error 0.0312(0.0318) Steps 676(676.71) | Grad Norm 2.0979(1.4943) | Total Time 14.00(14.00)\n",
      "Iter 3336 | Time 58.4950(60.6618) | Bit/dim 3.6913(3.6918) | Xent 0.0882(0.0960) | Loss 3.7354(3.7398) | Error 0.0290(0.0317) Steps 682(676.87) | Grad Norm 1.1878(1.4851) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0556 | Time 25.0542, Epoch Time 401.2665(407.1382), Bit/dim 3.7148(best: 3.7139), Xent 2.5555, Loss 4.9925, Error 0.4035(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3337 | Time 61.0591(60.6737) | Bit/dim 3.6936(3.6918) | Xent 0.0977(0.0961) | Loss 3.7424(3.7399) | Error 0.0333(0.0318) Steps 688(677.21) | Grad Norm 1.3312(1.4805) | Total Time 14.00(14.00)\n",
      "Iter 3338 | Time 60.4211(60.6661) | Bit/dim 3.6889(3.6918) | Xent 0.0952(0.0960) | Loss 3.7365(3.7398) | Error 0.0310(0.0317) Steps 676(677.17) | Grad Norm 1.3320(1.4761) | Total Time 14.00(14.00)\n",
      "Iter 3339 | Time 60.1849(60.6517) | Bit/dim 3.6912(3.6917) | Xent 0.0953(0.0960) | Loss 3.7389(3.7397) | Error 0.0324(0.0318) Steps 688(677.50) | Grad Norm 0.9158(1.4593) | Total Time 14.00(14.00)\n",
      "Iter 3340 | Time 61.1633(60.6670) | Bit/dim 3.6933(3.6918) | Xent 0.0918(0.0959) | Loss 3.7392(3.7397) | Error 0.0296(0.0317) Steps 682(677.63) | Grad Norm 1.2039(1.4516) | Total Time 14.00(14.00)\n",
      "Iter 3341 | Time 61.7046(60.6982) | Bit/dim 3.6926(3.6918) | Xent 0.0934(0.0958) | Loss 3.7393(3.7397) | Error 0.0312(0.0317) Steps 676(677.58) | Grad Norm 1.3040(1.4472) | Total Time 14.00(14.00)\n",
      "Iter 3342 | Time 59.4650(60.6612) | Bit/dim 3.6901(3.6918) | Xent 0.0882(0.0956) | Loss 3.7342(3.7395) | Error 0.0301(0.0316) Steps 670(677.35) | Grad Norm 1.0923(1.4365) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0557 | Time 24.6582, Epoch Time 404.5425(407.0603), Bit/dim 3.7147(best: 3.7139), Xent 2.6464, Loss 5.0379, Error 0.4098(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3343 | Time 60.9393(60.6695) | Bit/dim 3.6970(3.6919) | Xent 0.0941(0.0955) | Loss 3.7441(3.7397) | Error 0.0309(0.0316) Steps 670(677.13) | Grad Norm 1.3501(1.4339) | Total Time 14.00(14.00)\n",
      "Iter 3344 | Time 60.4867(60.6640) | Bit/dim 3.6819(3.6916) | Xent 0.0964(0.0956) | Loss 3.7301(3.7394) | Error 0.0325(0.0316) Steps 676(677.10) | Grad Norm 2.0446(1.4523) | Total Time 14.00(14.00)\n",
      "Iter 3345 | Time 59.1304(60.6180) | Bit/dim 3.6857(3.6914) | Xent 0.0929(0.0955) | Loss 3.7321(3.7392) | Error 0.0310(0.0316) Steps 670(676.89) | Grad Norm 1.8928(1.4655) | Total Time 14.00(14.00)\n",
      "Iter 3346 | Time 59.7406(60.5917) | Bit/dim 3.7058(3.6919) | Xent 0.0931(0.0954) | Loss 3.7524(3.7396) | Error 0.0301(0.0316) Steps 682(677.04) | Grad Norm 1.0510(1.4530) | Total Time 14.00(14.00)\n",
      "Iter 3347 | Time 61.6339(60.6230) | Bit/dim 3.6859(3.6917) | Xent 0.1046(0.0957) | Loss 3.7382(3.7395) | Error 0.0340(0.0317) Steps 658(676.47) | Grad Norm 2.1846(1.4750) | Total Time 14.00(14.00)\n",
      "Iter 3348 | Time 60.5511(60.6208) | Bit/dim 3.6972(3.6919) | Xent 0.0956(0.0957) | Loss 3.7450(3.7397) | Error 0.0325(0.0317) Steps 676(676.46) | Grad Norm 1.8190(1.4853) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0558 | Time 25.1114, Epoch Time 403.1509(406.9430), Bit/dim 3.7161(best: 3.7139), Xent 2.6095, Loss 5.0208, Error 0.4025(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3349 | Time 62.5863(60.6798) | Bit/dim 3.6849(3.6916) | Xent 0.0893(0.0955) | Loss 3.7295(3.7394) | Error 0.0314(0.0317) Steps 676(676.44) | Grad Norm 1.1574(1.4755) | Total Time 14.00(14.00)\n",
      "Iter 3350 | Time 60.1321(60.6633) | Bit/dim 3.6936(3.6917) | Xent 0.0982(0.0956) | Loss 3.7427(3.7395) | Error 0.0305(0.0316) Steps 676(676.43) | Grad Norm 1.5724(1.4784) | Total Time 14.00(14.00)\n",
      "Iter 3351 | Time 59.0383(60.6146) | Bit/dim 3.6888(3.6916) | Xent 0.0883(0.0954) | Loss 3.7330(3.7393) | Error 0.0296(0.0316) Steps 676(676.42) | Grad Norm 1.4593(1.4778) | Total Time 14.00(14.00)\n",
      "Iter 3352 | Time 59.4307(60.5791) | Bit/dim 3.7054(3.6920) | Xent 0.0970(0.0954) | Loss 3.7539(3.7397) | Error 0.0304(0.0315) Steps 676(676.40) | Grad Norm 1.2510(1.4710) | Total Time 14.00(14.00)\n",
      "Iter 3353 | Time 63.5064(60.6669) | Bit/dim 3.6896(3.6920) | Xent 0.0865(0.0951) | Loss 3.7328(3.7395) | Error 0.0260(0.0314) Steps 682(676.57) | Grad Norm 1.1688(1.4619) | Total Time 14.00(14.00)\n",
      "Iter 3354 | Time 62.2405(60.7141) | Bit/dim 3.6902(3.6919) | Xent 0.0922(0.0951) | Loss 3.7363(3.7394) | Error 0.0320(0.0314) Steps 670(676.37) | Grad Norm 1.0493(1.4495) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0559 | Time 25.1807, Epoch Time 407.7799(406.9681), Bit/dim 3.7148(best: 3.7139), Xent 2.5652, Loss 4.9975, Error 0.4046(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3355 | Time 61.9615(60.7515) | Bit/dim 3.6977(3.6921) | Xent 0.0982(0.0951) | Loss 3.7467(3.7396) | Error 0.0326(0.0314) Steps 682(676.54) | Grad Norm 1.7074(1.4573) | Total Time 14.00(14.00)\n",
      "Iter 3356 | Time 62.3268(60.7988) | Bit/dim 3.6849(3.6919) | Xent 0.0905(0.0950) | Loss 3.7302(3.7394) | Error 0.0314(0.0314) Steps 664(676.17) | Grad Norm 1.2936(1.4524) | Total Time 14.00(14.00)\n",
      "Iter 3357 | Time 59.9352(60.7729) | Bit/dim 3.6912(3.6918) | Xent 0.0950(0.0950) | Loss 3.7387(3.7393) | Error 0.0315(0.0314) Steps 682(676.34) | Grad Norm 1.5900(1.4565) | Total Time 14.00(14.00)\n",
      "Iter 3358 | Time 60.1129(60.7531) | Bit/dim 3.7029(3.6922) | Xent 0.0900(0.0949) | Loss 3.7479(3.7396) | Error 0.0302(0.0314) Steps 682(676.51) | Grad Norm 1.4789(1.4572) | Total Time 14.00(14.00)\n",
      "Iter 3359 | Time 60.1745(60.7357) | Bit/dim 3.6916(3.6922) | Xent 0.0949(0.0949) | Loss 3.7390(3.7396) | Error 0.0311(0.0314) Steps 676(676.50) | Grad Norm 2.0040(1.4736) | Total Time 14.00(14.00)\n",
      "Iter 3360 | Time 60.1071(60.7169) | Bit/dim 3.6771(3.6917) | Xent 0.1033(0.0951) | Loss 3.7287(3.7393) | Error 0.0337(0.0315) Steps 670(676.30) | Grad Norm 1.7864(1.4830) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0560 | Time 25.3110, Epoch Time 405.9255(406.9368), Bit/dim 3.7148(best: 3.7139), Xent 2.6091, Loss 5.0194, Error 0.4087(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3361 | Time 61.0897(60.7280) | Bit/dim 3.6783(3.6913) | Xent 0.1030(0.0953) | Loss 3.7298(3.7390) | Error 0.0337(0.0315) Steps 670(676.11) | Grad Norm 2.7434(1.5208) | Total Time 14.00(14.00)\n",
      "Iter 3362 | Time 59.6337(60.6952) | Bit/dim 3.6980(3.6915) | Xent 0.0919(0.0952) | Loss 3.7439(3.7391) | Error 0.0325(0.0316) Steps 682(676.29) | Grad Norm 3.0056(1.5653) | Total Time 14.00(14.00)\n",
      "Iter 3363 | Time 59.7255(60.6661) | Bit/dim 3.6862(3.6913) | Xent 0.0962(0.0953) | Loss 3.7343(3.7390) | Error 0.0330(0.0316) Steps 682(676.46) | Grad Norm 2.7766(1.6017) | Total Time 14.00(14.00)\n",
      "Iter 3364 | Time 61.6928(60.6969) | Bit/dim 3.6908(3.6913) | Xent 0.0941(0.0952) | Loss 3.7379(3.7389) | Error 0.0296(0.0315) Steps 670(676.27) | Grad Norm 1.1410(1.5878) | Total Time 14.00(14.00)\n",
      "Iter 3365 | Time 61.5919(60.7238) | Bit/dim 3.6948(3.6914) | Xent 0.0932(0.0952) | Loss 3.7414(3.7390) | Error 0.0312(0.0315) Steps 676(676.26) | Grad Norm 1.2424(1.5775) | Total Time 14.00(14.00)\n",
      "Iter 3366 | Time 61.2817(60.7405) | Bit/dim 3.7006(3.6917) | Xent 0.0945(0.0952) | Loss 3.7479(3.7393) | Error 0.0319(0.0315) Steps 670(676.07) | Grad Norm 1.4436(1.5735) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0561 | Time 25.4092, Epoch Time 406.3023(406.9178), Bit/dim 3.7153(best: 3.7139), Xent 2.5982, Loss 5.0144, Error 0.4017(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3367 | Time 61.0924(60.7511) | Bit/dim 3.6904(3.6917) | Xent 0.0917(0.0950) | Loss 3.7362(3.7392) | Error 0.0286(0.0315) Steps 670(675.89) | Grad Norm 2.2981(1.5952) | Total Time 14.00(14.00)\n",
      "Iter 3368 | Time 61.9382(60.7867) | Bit/dim 3.6911(3.6917) | Xent 0.0883(0.0948) | Loss 3.7353(3.7391) | Error 0.0292(0.0314) Steps 676(675.89) | Grad Norm 1.3300(1.5872) | Total Time 14.00(14.00)\n",
      "Iter 3369 | Time 60.2948(60.7719) | Bit/dim 3.7008(3.6919) | Xent 0.0944(0.0948) | Loss 3.7480(3.7393) | Error 0.0311(0.0314) Steps 688(676.25) | Grad Norm 1.4752(1.5839) | Total Time 14.00(14.00)\n",
      "Iter 3370 | Time 60.9985(60.7787) | Bit/dim 3.6998(3.6922) | Xent 0.0983(0.0949) | Loss 3.7490(3.7396) | Error 0.0341(0.0315) Steps 676(676.25) | Grad Norm 2.4387(1.6095) | Total Time 14.00(14.00)\n",
      "Iter 3371 | Time 59.2113(60.7317) | Bit/dim 3.6839(3.6919) | Xent 0.0972(0.0950) | Loss 3.7325(3.7394) | Error 0.0326(0.0315) Steps 676(676.24) | Grad Norm 1.1856(1.5968) | Total Time 14.00(14.00)\n",
      "Iter 3372 | Time 61.6336(60.7588) | Bit/dim 3.6808(3.6916) | Xent 0.0912(0.0949) | Loss 3.7264(3.7390) | Error 0.0320(0.0315) Steps 670(676.05) | Grad Norm 1.1530(1.5835) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0562 | Time 25.2906, Epoch Time 406.3028(406.8994), Bit/dim 3.7145(best: 3.7139), Xent 2.5925, Loss 5.0107, Error 0.4077(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3373 | Time 60.6086(60.7543) | Bit/dim 3.6879(3.6915) | Xent 0.0982(0.0950) | Loss 3.7369(3.7390) | Error 0.0334(0.0316) Steps 682(676.23) | Grad Norm 3.1330(1.6300) | Total Time 14.00(14.00)\n",
      "Iter 3374 | Time 60.7454(60.7540) | Bit/dim 3.7012(3.6918) | Xent 0.0911(0.0949) | Loss 3.7467(3.7392) | Error 0.0315(0.0316) Steps 670(676.04) | Grad Norm 1.7278(1.6329) | Total Time 14.00(14.00)\n",
      "Iter 3375 | Time 60.8871(60.7580) | Bit/dim 3.6943(3.6918) | Xent 0.0909(0.0948) | Loss 3.7397(3.7392) | Error 0.0305(0.0315) Steps 682(676.22) | Grad Norm 1.7841(1.6374) | Total Time 14.00(14.00)\n",
      "Iter 3376 | Time 60.2037(60.7414) | Bit/dim 3.6882(3.6917) | Xent 0.0921(0.0947) | Loss 3.7342(3.7391) | Error 0.0314(0.0315) Steps 682(676.40) | Grad Norm 2.9705(1.6774) | Total Time 14.00(14.00)\n",
      "Iter 3377 | Time 62.4763(60.7934) | Bit/dim 3.6867(3.6916) | Xent 0.0946(0.0947) | Loss 3.7340(3.7389) | Error 0.0315(0.0315) Steps 670(676.20) | Grad Norm 1.7864(1.6807) | Total Time 14.00(14.00)\n",
      "Iter 3378 | Time 60.0696(60.7717) | Bit/dim 3.6910(3.6916) | Xent 0.0886(0.0945) | Loss 3.7352(3.7388) | Error 0.0286(0.0314) Steps 676(676.20) | Grad Norm 1.5484(1.6767) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0563 | Time 25.2774, Epoch Time 405.9337(406.8704), Bit/dim 3.7135(best: 3.7139), Xent 2.6445, Loss 5.0357, Error 0.4103(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3379 | Time 59.9588(60.7473) | Bit/dim 3.6933(3.6916) | Xent 0.1022(0.0947) | Loss 3.7445(3.7390) | Error 0.0345(0.0315) Steps 682(676.37) | Grad Norm 3.4717(1.7306) | Total Time 14.00(14.00)\n",
      "Iter 3380 | Time 60.7425(60.7472) | Bit/dim 3.6993(3.6918) | Xent 0.0841(0.0944) | Loss 3.7414(3.7390) | Error 0.0272(0.0314) Steps 682(676.54) | Grad Norm 1.0767(1.7110) | Total Time 14.00(14.00)\n",
      "Iter 3381 | Time 60.5705(60.7419) | Bit/dim 3.6799(3.6915) | Xent 0.0925(0.0943) | Loss 3.7262(3.7387) | Error 0.0306(0.0314) Steps 694(677.06) | Grad Norm 1.3905(1.7014) | Total Time 14.00(14.00)\n",
      "Iter 3382 | Time 59.7305(60.7115) | Bit/dim 3.6878(3.6914) | Xent 0.0996(0.0945) | Loss 3.7377(3.7386) | Error 0.0330(0.0314) Steps 676(677.03) | Grad Norm 1.4499(1.6938) | Total Time 14.00(14.00)\n",
      "Iter 3383 | Time 62.5664(60.7672) | Bit/dim 3.6891(3.6913) | Xent 0.0961(0.0946) | Loss 3.7372(3.7386) | Error 0.0323(0.0315) Steps 682(677.18) | Grad Norm 2.0169(1.7035) | Total Time 14.00(14.00)\n",
      "Iter 3384 | Time 59.8066(60.7383) | Bit/dim 3.6924(3.6913) | Xent 0.0916(0.0945) | Loss 3.7382(3.7386) | Error 0.0304(0.0314) Steps 676(677.15) | Grad Norm 1.1235(1.6861) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0564 | Time 25.0553, Epoch Time 403.9922(406.7840), Bit/dim 3.7134(best: 3.7135), Xent 2.5954, Loss 5.0111, Error 0.4049(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3385 | Time 62.4745(60.7904) | Bit/dim 3.7034(3.6917) | Xent 0.0943(0.0945) | Loss 3.7506(3.7389) | Error 0.0325(0.0315) Steps 664(676.75) | Grad Norm 0.9325(1.6635) | Total Time 14.00(14.00)\n",
      "Iter 3386 | Time 59.9975(60.7666) | Bit/dim 3.6915(3.6917) | Xent 0.0982(0.0946) | Loss 3.7406(3.7390) | Error 0.0331(0.0315) Steps 682(676.91) | Grad Norm 3.6372(1.7227) | Total Time 14.00(14.00)\n",
      "Iter 3387 | Time 60.4209(60.7563) | Bit/dim 3.6896(3.6916) | Xent 0.0957(0.0946) | Loss 3.7375(3.7389) | Error 0.0317(0.0315) Steps 682(677.06) | Grad Norm 1.2818(1.7095) | Total Time 14.00(14.00)\n",
      "Iter 3388 | Time 60.9463(60.7620) | Bit/dim 3.6873(3.6915) | Xent 0.0915(0.0945) | Loss 3.7331(3.7388) | Error 0.0310(0.0315) Steps 664(676.67) | Grad Norm 2.0274(1.7190) | Total Time 14.00(14.00)\n",
      "Iter 3389 | Time 63.2414(60.8364) | Bit/dim 3.6845(3.6913) | Xent 0.0901(0.0944) | Loss 3.7296(3.7385) | Error 0.0317(0.0315) Steps 688(677.01) | Grad Norm 2.3887(1.7391) | Total Time 14.00(14.00)\n",
      "Iter 3390 | Time 63.1312(60.9052) | Bit/dim 3.6813(3.6910) | Xent 0.0891(0.0942) | Loss 3.7258(3.7381) | Error 0.0302(0.0315) Steps 676(676.98) | Grad Norm 1.9397(1.7451) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0565 | Time 24.7777, Epoch Time 410.9072(406.9077), Bit/dim 3.7139(best: 3.7134), Xent 2.6173, Loss 5.0225, Error 0.4080(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3391 | Time 60.9486(60.9065) | Bit/dim 3.6903(3.6910) | Xent 0.0913(0.0941) | Loss 3.7360(3.7380) | Error 0.0291(0.0314) Steps 682(677.13) | Grad Norm 1.8982(1.7497) | Total Time 14.00(14.00)\n",
      "Iter 3392 | Time 60.4771(60.8936) | Bit/dim 3.6895(3.6909) | Xent 0.0973(0.0942) | Loss 3.7382(3.7380) | Error 0.0336(0.0315) Steps 676(677.10) | Grad Norm 2.6918(1.7780) | Total Time 14.00(14.00)\n",
      "Iter 3393 | Time 58.9197(60.8344) | Bit/dim 3.6854(3.6908) | Xent 0.0924(0.0942) | Loss 3.7316(3.7379) | Error 0.0298(0.0314) Steps 694(677.60) | Grad Norm 1.7672(1.7777) | Total Time 14.00(14.00)\n",
      "Iter 3394 | Time 65.1438(60.9637) | Bit/dim 3.6983(3.6910) | Xent 0.0859(0.0939) | Loss 3.7412(3.7380) | Error 0.0301(0.0314) Steps 688(677.92) | Grad Norm 1.1978(1.7603) | Total Time 14.00(14.00)\n",
      "Iter 3395 | Time 62.5274(61.0106) | Bit/dim 3.7020(3.6913) | Xent 0.0926(0.0939) | Loss 3.7483(3.7383) | Error 0.0292(0.0313) Steps 676(677.86) | Grad Norm 2.2493(1.7749) | Total Time 14.00(14.00)\n",
      "Iter 3396 | Time 64.1753(61.1055) | Bit/dim 3.6868(3.6912) | Xent 0.0935(0.0939) | Loss 3.7335(3.7381) | Error 0.0296(0.0313) Steps 694(678.34) | Grad Norm 1.9814(1.7811) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0566 | Time 25.3531, Epoch Time 413.4793(407.1049), Bit/dim 3.7146(best: 3.7134), Xent 2.6356, Loss 5.0324, Error 0.4066(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3397 | Time 62.0835(61.1349) | Bit/dim 3.6962(3.6913) | Xent 0.0894(0.0937) | Loss 3.7410(3.7382) | Error 0.0300(0.0312) Steps 676(678.27) | Grad Norm 0.9722(1.7569) | Total Time 14.00(14.00)\n",
      "Iter 3398 | Time 59.2137(61.0772) | Bit/dim 3.6921(3.6914) | Xent 0.0893(0.0936) | Loss 3.7368(3.7382) | Error 0.0306(0.0312) Steps 670(678.02) | Grad Norm 1.2103(1.7405) | Total Time 14.00(14.00)\n",
      "Iter 3399 | Time 62.5942(61.1227) | Bit/dim 3.6882(3.6913) | Xent 0.0861(0.0934) | Loss 3.7312(3.7380) | Error 0.0266(0.0311) Steps 676(677.96) | Grad Norm 1.7143(1.7397) | Total Time 14.00(14.00)\n",
      "Iter 3400 | Time 63.2209(61.1857) | Bit/dim 3.6925(3.6913) | Xent 0.0891(0.0933) | Loss 3.7370(3.7379) | Error 0.0290(0.0310) Steps 694(678.44) | Grad Norm 1.2324(1.7245) | Total Time 14.00(14.00)\n",
      "Iter 3401 | Time 61.5108(61.1954) | Bit/dim 3.6916(3.6913) | Xent 0.0916(0.0932) | Loss 3.7374(3.7379) | Error 0.0288(0.0309) Steps 682(678.55) | Grad Norm 1.4464(1.7161) | Total Time 14.00(14.00)\n",
      "Iter 3402 | Time 60.5302(61.1755) | Bit/dim 3.6821(3.6910) | Xent 0.0801(0.0928) | Loss 3.7221(3.7374) | Error 0.0262(0.0308) Steps 682(678.65) | Grad Norm 1.5100(1.7099) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0567 | Time 24.8581, Epoch Time 409.8802(407.1881), Bit/dim 3.7135(best: 3.7134), Xent 2.6456, Loss 5.0363, Error 0.4052(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3403 | Time 60.2836(61.1487) | Bit/dim 3.6945(3.6911) | Xent 0.0934(0.0928) | Loss 3.7412(3.7376) | Error 0.0319(0.0308) Steps 676(678.57) | Grad Norm 1.8905(1.7153) | Total Time 14.00(14.00)\n",
      "Iter 3404 | Time 60.7013(61.1353) | Bit/dim 3.6952(3.6913) | Xent 0.0830(0.0925) | Loss 3.7367(3.7375) | Error 0.0275(0.0307) Steps 676(678.50) | Grad Norm 0.8558(1.6896) | Total Time 14.00(14.00)\n",
      "Iter 3405 | Time 63.9562(61.2199) | Bit/dim 3.6878(3.6912) | Xent 0.0847(0.0923) | Loss 3.7301(3.7373) | Error 0.0275(0.0306) Steps 676(678.42) | Grad Norm 0.9701(1.6680) | Total Time 14.00(14.00)\n",
      "Iter 3406 | Time 61.4116(61.2257) | Bit/dim 3.6898(3.6911) | Xent 0.0921(0.0923) | Loss 3.7358(3.7373) | Error 0.0309(0.0306) Steps 688(678.71) | Grad Norm 1.2471(1.6553) | Total Time 14.00(14.00)\n",
      "Iter 3407 | Time 62.7281(61.2708) | Bit/dim 3.6889(3.6910) | Xent 0.0967(0.0924) | Loss 3.7373(3.7373) | Error 0.0323(0.0307) Steps 700(679.35) | Grad Norm 2.0947(1.6685) | Total Time 14.00(14.00)\n",
      "Iter 3408 | Time 61.8446(61.2880) | Bit/dim 3.6853(3.6909) | Xent 0.0932(0.0925) | Loss 3.7319(3.7371) | Error 0.0312(0.0307) Steps 670(679.07) | Grad Norm 1.6767(1.6688) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0568 | Time 25.1594, Epoch Time 411.5933(407.3203), Bit/dim 3.7119(best: 3.7134), Xent 2.6349, Loss 5.0293, Error 0.4086(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3409 | Time 61.6396(61.2985) | Bit/dim 3.7041(3.6913) | Xent 0.0926(0.0925) | Loss 3.7504(3.7375) | Error 0.0310(0.0307) Steps 676(678.98) | Grad Norm 1.6400(1.6679) | Total Time 14.00(14.00)\n",
      "Iter 3410 | Time 61.7662(61.3125) | Bit/dim 3.6899(3.6912) | Xent 0.0873(0.0923) | Loss 3.7336(3.7374) | Error 0.0286(0.0306) Steps 688(679.25) | Grad Norm 0.9521(1.6464) | Total Time 14.00(14.00)\n",
      "Iter 3411 | Time 60.6991(61.2941) | Bit/dim 3.6931(3.6913) | Xent 0.0857(0.0921) | Loss 3.7359(3.7373) | Error 0.0279(0.0306) Steps 670(678.97) | Grad Norm 1.1332(1.6310) | Total Time 14.00(14.00)\n",
      "Iter 3412 | Time 61.3696(61.2964) | Bit/dim 3.6934(3.6913) | Xent 0.0921(0.0921) | Loss 3.7395(3.7374) | Error 0.0300(0.0305) Steps 676(678.88) | Grad Norm 1.2532(1.6197) | Total Time 14.00(14.00)\n",
      "Iter 3413 | Time 63.3624(61.3584) | Bit/dim 3.6803(3.6910) | Xent 0.0889(0.0920) | Loss 3.7247(3.7370) | Error 0.0302(0.0305) Steps 682(678.97) | Grad Norm 1.1750(1.6064) | Total Time 14.00(14.00)\n",
      "Iter 3414 | Time 58.1103(61.2609) | Bit/dim 3.6833(3.6908) | Xent 0.0873(0.0919) | Loss 3.7269(3.7367) | Error 0.0305(0.0305) Steps 682(679.06) | Grad Norm 1.6681(1.6082) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0569 | Time 25.2533, Epoch Time 408.0077(407.3409), Bit/dim 3.7143(best: 3.7119), Xent 2.6118, Loss 5.0202, Error 0.4010(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3415 | Time 60.1185(61.2267) | Bit/dim 3.6934(3.6909) | Xent 0.0854(0.0917) | Loss 3.7361(3.7367) | Error 0.0275(0.0304) Steps 688(679.33) | Grad Norm 1.5353(1.6060) | Total Time 14.00(14.00)\n",
      "Iter 3416 | Time 61.9449(61.2482) | Bit/dim 3.6953(3.6910) | Xent 0.0815(0.0914) | Loss 3.7361(3.7367) | Error 0.0250(0.0303) Steps 682(679.41) | Grad Norm 1.7162(1.6093) | Total Time 14.00(14.00)\n",
      "Iter 3417 | Time 60.4858(61.2253) | Bit/dim 3.6916(3.6910) | Xent 0.0837(0.0911) | Loss 3.7334(3.7366) | Error 0.0276(0.0302) Steps 694(679.85) | Grad Norm 2.3237(1.6308) | Total Time 14.00(14.00)\n",
      "Iter 3418 | Time 60.7834(61.2121) | Bit/dim 3.6833(3.6908) | Xent 0.0926(0.0912) | Loss 3.7296(3.7364) | Error 0.0305(0.0302) Steps 676(679.73) | Grad Norm 1.1029(1.6149) | Total Time 14.00(14.00)\n",
      "Iter 3419 | Time 62.1578(61.2405) | Bit/dim 3.6931(3.6909) | Xent 0.0921(0.0912) | Loss 3.7392(3.7365) | Error 0.0315(0.0303) Steps 670(679.44) | Grad Norm 1.0923(1.5992) | Total Time 14.00(14.00)\n",
      "Iter 3420 | Time 60.1944(61.2091) | Bit/dim 3.6840(3.6906) | Xent 0.1003(0.0915) | Loss 3.7341(3.7364) | Error 0.0311(0.0303) Steps 670(679.16) | Grad Norm 1.8972(1.6082) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0570 | Time 25.3316, Epoch Time 406.5603(407.3175), Bit/dim 3.7137(best: 3.7119), Xent 2.6232, Loss 5.0253, Error 0.4091(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3421 | Time 59.9235(61.1705) | Bit/dim 3.7002(3.6909) | Xent 0.0866(0.0913) | Loss 3.7435(3.7366) | Error 0.0275(0.0302) Steps 670(678.88) | Grad Norm 1.4466(1.6033) | Total Time 14.00(14.00)\n",
      "Iter 3422 | Time 61.8030(61.1895) | Bit/dim 3.6898(3.6909) | Xent 0.0831(0.0911) | Loss 3.7314(3.7364) | Error 0.0276(0.0301) Steps 694(679.34) | Grad Norm 0.9497(1.5837) | Total Time 14.00(14.00)\n",
      "Iter 3423 | Time 63.4414(61.2570) | Bit/dim 3.6927(3.6910) | Xent 0.0828(0.0908) | Loss 3.7341(3.7364) | Error 0.0274(0.0300) Steps 670(679.06) | Grad Norm 2.9339(1.6242) | Total Time 14.00(14.00)\n",
      "Iter 3424 | Time 61.5409(61.2656) | Bit/dim 3.6792(3.6906) | Xent 0.0951(0.0910) | Loss 3.7267(3.7361) | Error 0.0309(0.0301) Steps 688(679.33) | Grad Norm 1.5949(1.6234) | Total Time 14.00(14.00)\n",
      "Iter 3425 | Time 62.0751(61.2898) | Bit/dim 3.6910(3.6906) | Xent 0.0925(0.0910) | Loss 3.7373(3.7361) | Error 0.0310(0.0301) Steps 694(679.77) | Grad Norm 1.2040(1.6108) | Total Time 14.00(14.00)\n",
      "Iter 3426 | Time 58.6085(61.2094) | Bit/dim 3.6932(3.6907) | Xent 0.0979(0.0912) | Loss 3.7421(3.7363) | Error 0.0321(0.0302) Steps 670(679.47) | Grad Norm 1.6113(1.6108) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0571 | Time 25.3066, Epoch Time 409.2303(407.3749), Bit/dim 3.7135(best: 3.7119), Xent 2.6324, Loss 5.0297, Error 0.4060(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3427 | Time 61.4818(61.2176) | Bit/dim 3.6914(3.6907) | Xent 0.0932(0.0913) | Loss 3.7380(3.7364) | Error 0.0316(0.0302) Steps 676(679.37) | Grad Norm 2.0022(1.6225) | Total Time 14.00(14.00)\n",
      "Iter 3428 | Time 61.2172(61.2176) | Bit/dim 3.6896(3.6907) | Xent 0.0904(0.0913) | Loss 3.7348(3.7363) | Error 0.0292(0.0302) Steps 670(679.09) | Grad Norm 1.2950(1.6127) | Total Time 14.00(14.00)\n",
      "Iter 3429 | Time 59.2588(61.1588) | Bit/dim 3.6993(3.6909) | Xent 0.0888(0.0912) | Loss 3.7437(3.7365) | Error 0.0310(0.0302) Steps 670(678.82) | Grad Norm 1.6239(1.6130) | Total Time 14.00(14.00)\n",
      "Iter 3430 | Time 60.1012(61.1271) | Bit/dim 3.6893(3.6909) | Xent 0.0866(0.0910) | Loss 3.7326(3.7364) | Error 0.0269(0.0301) Steps 676(678.73) | Grad Norm 1.1023(1.5977) | Total Time 14.00(14.00)\n",
      "Iter 3431 | Time 62.5895(61.1710) | Bit/dim 3.6865(3.6908) | Xent 0.0901(0.0910) | Loss 3.7316(3.7363) | Error 0.0292(0.0301) Steps 664(678.29) | Grad Norm 1.9759(1.6091) | Total Time 14.00(14.00)\n",
      "Iter 3432 | Time 61.5361(61.1819) | Bit/dim 3.6868(3.6906) | Xent 0.0898(0.0910) | Loss 3.7318(3.7361) | Error 0.0296(0.0301) Steps 670(678.04) | Grad Norm 1.2452(1.5982) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0572 | Time 25.1533, Epoch Time 407.3126(407.3730), Bit/dim 3.7129(best: 3.7119), Xent 2.6011, Loss 5.0135, Error 0.4054(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3433 | Time 61.8093(61.2007) | Bit/dim 3.6896(3.6906) | Xent 0.0869(0.0909) | Loss 3.7330(3.7360) | Error 0.0296(0.0300) Steps 676(677.98) | Grad Norm 1.2470(1.5876) | Total Time 14.00(14.00)\n",
      "Iter 3434 | Time 63.2961(61.2636) | Bit/dim 3.6906(3.6906) | Xent 0.0918(0.0909) | Loss 3.7366(3.7361) | Error 0.0304(0.0301) Steps 694(678.46) | Grad Norm 1.4846(1.5845) | Total Time 14.00(14.00)\n",
      "Iter 3435 | Time 62.3032(61.2948) | Bit/dim 3.6899(3.6906) | Xent 0.0933(0.0910) | Loss 3.7366(3.7361) | Error 0.0302(0.0301) Steps 676(678.39) | Grad Norm 1.0892(1.5697) | Total Time 14.00(14.00)\n",
      "Iter 3436 | Time 64.7171(61.3974) | Bit/dim 3.6853(3.6904) | Xent 0.0968(0.0911) | Loss 3.7337(3.7360) | Error 0.0329(0.0301) Steps 670(678.13) | Grad Norm 2.0142(1.5830) | Total Time 14.00(14.00)\n",
      "Iter 3437 | Time 62.3511(61.4261) | Bit/dim 3.6940(3.6905) | Xent 0.0957(0.0913) | Loss 3.7419(3.7362) | Error 0.0333(0.0302) Steps 682(678.25) | Grad Norm 1.2471(1.5729) | Total Time 14.00(14.00)\n",
      "Iter 3438 | Time 61.4414(61.4265) | Bit/dim 3.6862(3.6904) | Xent 0.0935(0.0913) | Loss 3.7330(3.7361) | Error 0.0316(0.0303) Steps 676(678.18) | Grad Norm 1.0940(1.5586) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0573 | Time 25.1405, Epoch Time 416.8943(407.6587), Bit/dim 3.7148(best: 3.7119), Xent 2.6577, Loss 5.0436, Error 0.4060(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3439 | Time 59.3524(61.3643) | Bit/dim 3.6934(3.6905) | Xent 0.0861(0.0912) | Loss 3.7365(3.7361) | Error 0.0279(0.0302) Steps 688(678.48) | Grad Norm 1.7294(1.5637) | Total Time 14.00(14.00)\n",
      "Iter 3440 | Time 61.8913(61.3801) | Bit/dim 3.6886(3.6904) | Xent 0.0989(0.0914) | Loss 3.7380(3.7361) | Error 0.0323(0.0303) Steps 688(678.76) | Grad Norm 1.5969(1.5647) | Total Time 14.00(14.00)\n",
      "Iter 3441 | Time 59.9203(61.3363) | Bit/dim 3.6931(3.6905) | Xent 0.0936(0.0915) | Loss 3.7400(3.7363) | Error 0.0317(0.0303) Steps 676(678.68) | Grad Norm 1.1914(1.5535) | Total Time 14.00(14.00)\n",
      "Iter 3442 | Time 61.6914(61.3470) | Bit/dim 3.6971(3.6907) | Xent 0.0884(0.0914) | Loss 3.7413(3.7364) | Error 0.0290(0.0303) Steps 676(678.60) | Grad Norm 1.0353(1.5379) | Total Time 14.00(14.00)\n",
      "Iter 3443 | Time 60.3829(61.3180) | Bit/dim 3.6868(3.6906) | Xent 0.0953(0.0915) | Loss 3.7345(3.7364) | Error 0.0319(0.0303) Steps 682(678.70) | Grad Norm 2.3512(1.5623) | Total Time 14.00(14.00)\n",
      "Iter 3444 | Time 60.6597(61.2983) | Bit/dim 3.6865(3.6905) | Xent 0.0969(0.0917) | Loss 3.7349(3.7363) | Error 0.0336(0.0304) Steps 682(678.80) | Grad Norm 1.7225(1.5671) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0574 | Time 24.9277, Epoch Time 404.4900(407.5636), Bit/dim 3.7139(best: 3.7119), Xent 2.5923, Loss 5.0101, Error 0.4088(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3445 | Time 62.3058(61.3285) | Bit/dim 3.6986(3.6907) | Xent 0.0938(0.0917) | Loss 3.7454(3.7366) | Error 0.0324(0.0305) Steps 676(678.72) | Grad Norm 1.5472(1.5665) | Total Time 14.00(14.00)\n",
      "Iter 3446 | Time 61.2099(61.3250) | Bit/dim 3.6843(3.6905) | Xent 0.0934(0.0918) | Loss 3.7310(3.7364) | Error 0.0302(0.0305) Steps 676(678.64) | Grad Norm 1.6108(1.5679) | Total Time 14.00(14.00)\n",
      "Iter 3447 | Time 59.5599(61.2720) | Bit/dim 3.6884(3.6905) | Xent 0.0940(0.0918) | Loss 3.7353(3.7364) | Error 0.0311(0.0305) Steps 682(678.74) | Grad Norm 1.4620(1.5647) | Total Time 14.00(14.00)\n",
      "Iter 3448 | Time 59.8339(61.2289) | Bit/dim 3.6901(3.6905) | Xent 0.0866(0.0917) | Loss 3.7334(3.7363) | Error 0.0296(0.0305) Steps 682(678.83) | Grad Norm 1.4262(1.5605) | Total Time 14.00(14.00)\n",
      "Iter 3449 | Time 59.7418(61.1842) | Bit/dim 3.6864(3.6903) | Xent 0.0930(0.0917) | Loss 3.7330(3.7362) | Error 0.0319(0.0305) Steps 688(679.11) | Grad Norm 1.6429(1.5630) | Total Time 14.00(14.00)\n",
      "Iter 3450 | Time 61.2290(61.1856) | Bit/dim 3.6927(3.6904) | Xent 0.0914(0.0917) | Loss 3.7384(3.7363) | Error 0.0278(0.0304) Steps 670(678.84) | Grad Norm 1.8718(1.5723) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0575 | Time 25.0740, Epoch Time 405.1080(407.4899), Bit/dim 3.7115(best: 3.7119), Xent 2.6256, Loss 5.0243, Error 0.4034(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3451 | Time 62.7284(61.2319) | Bit/dim 3.6903(3.6904) | Xent 0.0901(0.0917) | Loss 3.7354(3.7362) | Error 0.0294(0.0304) Steps 676(678.75) | Grad Norm 1.4755(1.5694) | Total Time 14.00(14.00)\n",
      "Iter 3452 | Time 63.9431(61.3132) | Bit/dim 3.6788(3.6901) | Xent 0.0929(0.0917) | Loss 3.7252(3.7359) | Error 0.0301(0.0304) Steps 682(678.85) | Grad Norm 1.3761(1.5636) | Total Time 14.00(14.00)\n",
      "Iter 3453 | Time 63.1598(61.3686) | Bit/dim 3.6966(3.6903) | Xent 0.0878(0.0916) | Loss 3.7404(3.7360) | Error 0.0295(0.0304) Steps 676(678.76) | Grad Norm 1.7535(1.5693) | Total Time 14.00(14.00)\n",
      "Iter 3454 | Time 62.8014(61.4116) | Bit/dim 3.6914(3.6903) | Xent 0.0896(0.0915) | Loss 3.7362(3.7360) | Error 0.0299(0.0303) Steps 682(678.86) | Grad Norm 1.3205(1.5618) | Total Time 14.00(14.00)\n",
      "Iter 3455 | Time 60.6959(61.3901) | Bit/dim 3.6924(3.6903) | Xent 0.0877(0.0914) | Loss 3.7363(3.7361) | Error 0.0304(0.0303) Steps 688(679.13) | Grad Norm 1.2286(1.5518) | Total Time 14.00(14.00)\n",
      "Iter 3456 | Time 59.8372(61.3435) | Bit/dim 3.6982(3.6906) | Xent 0.0876(0.0913) | Loss 3.7420(3.7362) | Error 0.0289(0.0303) Steps 682(679.22) | Grad Norm 1.0148(1.5357) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0576 | Time 25.2017, Epoch Time 414.6337(407.7042), Bit/dim 3.7143(best: 3.7115), Xent 2.6672, Loss 5.0479, Error 0.4059(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3457 | Time 59.9559(61.3019) | Bit/dim 3.6748(3.6901) | Xent 0.0932(0.0914) | Loss 3.7214(3.7358) | Error 0.0306(0.0303) Steps 682(679.30) | Grad Norm 2.3091(1.5589) | Total Time 14.00(14.00)\n",
      "Iter 3458 | Time 60.5282(61.2787) | Bit/dim 3.6885(3.6901) | Xent 0.0896(0.0913) | Loss 3.7333(3.7357) | Error 0.0304(0.0303) Steps 688(679.56) | Grad Norm 1.1828(1.5476) | Total Time 14.00(14.00)\n",
      "Iter 3459 | Time 60.2137(61.2467) | Bit/dim 3.6993(3.6903) | Xent 0.0973(0.0915) | Loss 3.7479(3.7361) | Error 0.0320(0.0304) Steps 682(679.64) | Grad Norm 2.3152(1.5706) | Total Time 14.00(14.00)\n",
      "Iter 3460 | Time 58.7558(61.1720) | Bit/dim 3.6939(3.6904) | Xent 0.0935(0.0915) | Loss 3.7407(3.7362) | Error 0.0309(0.0304) Steps 658(678.99) | Grad Norm 1.8522(1.5791) | Total Time 14.00(14.00)\n",
      "Iter 3461 | Time 60.1167(61.1404) | Bit/dim 3.6905(3.6904) | Xent 0.0933(0.0916) | Loss 3.7372(3.7362) | Error 0.0311(0.0304) Steps 676(678.90) | Grad Norm 1.1948(1.5676) | Total Time 14.00(14.00)\n",
      "Iter 3462 | Time 61.5973(61.1541) | Bit/dim 3.6919(3.6905) | Xent 0.0952(0.0917) | Loss 3.7395(3.7363) | Error 0.0304(0.0304) Steps 676(678.81) | Grad Norm 1.6545(1.5702) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0577 | Time 25.1127, Epoch Time 402.4264(407.5459), Bit/dim 3.7145(best: 3.7115), Xent 2.6084, Loss 5.0187, Error 0.4066(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3463 | Time 61.3610(61.1603) | Bit/dim 3.6949(3.6906) | Xent 0.0955(0.0918) | Loss 3.7426(3.7365) | Error 0.0305(0.0304) Steps 670(678.55) | Grad Norm 1.5562(1.5697) | Total Time 14.00(14.00)\n",
      "Iter 3464 | Time 61.4579(61.1692) | Bit/dim 3.6820(3.6904) | Xent 0.0910(0.0918) | Loss 3.7275(3.7363) | Error 0.0299(0.0304) Steps 682(678.65) | Grad Norm 1.8517(1.5782) | Total Time 14.00(14.00)\n",
      "Iter 3465 | Time 61.1998(61.1701) | Bit/dim 3.6870(3.6903) | Xent 0.0919(0.0918) | Loss 3.7329(3.7362) | Error 0.0290(0.0303) Steps 670(678.39) | Grad Norm 1.1559(1.5655) | Total Time 14.00(14.00)\n",
      "Iter 3466 | Time 60.9967(61.1649) | Bit/dim 3.6977(3.6905) | Xent 0.0811(0.0915) | Loss 3.7382(3.7362) | Error 0.0262(0.0302) Steps 670(678.14) | Grad Norm 1.8025(1.5726) | Total Time 14.00(14.00)\n",
      "Iter 3467 | Time 64.3492(61.2604) | Bit/dim 3.6905(3.6905) | Xent 0.0882(0.0914) | Loss 3.7347(3.7362) | Error 0.0298(0.0302) Steps 682(678.26) | Grad Norm 1.4639(1.5694) | Total Time 14.00(14.00)\n",
      "Iter 3468 | Time 61.7602(61.2754) | Bit/dim 3.6865(3.6904) | Xent 0.0964(0.0915) | Loss 3.7347(3.7361) | Error 0.0339(0.0303) Steps 682(678.37) | Grad Norm 1.3142(1.5617) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0578 | Time 25.0152, Epoch Time 411.7496(407.6720), Bit/dim 3.7132(best: 3.7115), Xent 2.6535, Loss 5.0399, Error 0.4046(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3469 | Time 63.3305(61.3371) | Bit/dim 3.6899(3.6904) | Xent 0.0860(0.0914) | Loss 3.7329(3.7360) | Error 0.0281(0.0303) Steps 676(678.30) | Grad Norm 1.4865(1.5595) | Total Time 14.00(14.00)\n",
      "Iter 3470 | Time 60.4811(61.3114) | Bit/dim 3.6943(3.6905) | Xent 0.0862(0.0912) | Loss 3.7375(3.7361) | Error 0.0286(0.0302) Steps 676(678.23) | Grad Norm 1.3200(1.5523) | Total Time 14.00(14.00)\n",
      "Iter 3471 | Time 58.6357(61.2311) | Bit/dim 3.6909(3.6905) | Xent 0.0845(0.0910) | Loss 3.7331(3.7360) | Error 0.0270(0.0301) Steps 670(677.98) | Grad Norm 1.2381(1.5429) | Total Time 14.00(14.00)\n",
      "Iter 3472 | Time 61.0695(61.2263) | Bit/dim 3.6937(3.6906) | Xent 0.0933(0.0911) | Loss 3.7404(3.7361) | Error 0.0319(0.0302) Steps 670(677.74) | Grad Norm 1.0567(1.5283) | Total Time 14.00(14.00)\n",
      "Iter 3473 | Time 60.1776(61.1948) | Bit/dim 3.6863(3.6905) | Xent 0.0880(0.0910) | Loss 3.7303(3.7360) | Error 0.0290(0.0301) Steps 676(677.69) | Grad Norm 1.6771(1.5327) | Total Time 14.00(14.00)\n",
      "Iter 3474 | Time 63.6108(61.2673) | Bit/dim 3.6844(3.6903) | Xent 0.0875(0.0909) | Loss 3.7282(3.7357) | Error 0.0294(0.0301) Steps 676(677.64) | Grad Norm 1.4537(1.5304) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0579 | Time 25.0453, Epoch Time 408.3185(407.6914), Bit/dim 3.7131(best: 3.7115), Xent 2.6379, Loss 5.0320, Error 0.4037(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3475 | Time 57.8952(61.1661) | Bit/dim 3.6923(3.6903) | Xent 0.0849(0.0907) | Loss 3.7347(3.7357) | Error 0.0286(0.0301) Steps 676(677.59) | Grad Norm 1.0964(1.5174) | Total Time 14.00(14.00)\n",
      "Iter 3476 | Time 60.4197(61.1438) | Bit/dim 3.7002(3.6906) | Xent 0.0900(0.0907) | Loss 3.7452(3.7360) | Error 0.0309(0.0301) Steps 670(677.36) | Grad Norm 1.2340(1.5089) | Total Time 14.00(14.00)\n",
      "Iter 3477 | Time 61.3740(61.1507) | Bit/dim 3.6845(3.6904) | Xent 0.0883(0.0906) | Loss 3.7287(3.7358) | Error 0.0285(0.0300) Steps 682(677.50) | Grad Norm 1.3767(1.5049) | Total Time 14.00(14.00)\n",
      "Iter 3478 | Time 59.3081(61.0954) | Bit/dim 3.6901(3.6904) | Xent 0.0833(0.0904) | Loss 3.7317(3.7356) | Error 0.0268(0.0299) Steps 682(677.64) | Grad Norm 1.1358(1.4938) | Total Time 14.00(14.00)\n",
      "Iter 3479 | Time 58.6968(61.0234) | Bit/dim 3.6862(3.6903) | Xent 0.0890(0.0903) | Loss 3.7307(3.7355) | Error 0.0298(0.0299) Steps 682(677.77) | Grad Norm 1.8174(1.5035) | Total Time 14.00(14.00)\n",
      "Iter 3480 | Time 60.5789(61.0101) | Bit/dim 3.6887(3.6903) | Xent 0.0815(0.0901) | Loss 3.7294(3.7353) | Error 0.0269(0.0298) Steps 676(677.71) | Grad Norm 1.3932(1.5002) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0580 | Time 25.1557, Epoch Time 399.1376(407.4348), Bit/dim 3.7140(best: 3.7115), Xent 2.6520, Loss 5.0400, Error 0.4064(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3481 | Time 61.8858(61.0364) | Bit/dim 3.6979(3.6905) | Xent 0.0920(0.0901) | Loss 3.7439(3.7356) | Error 0.0306(0.0299) Steps 676(677.66) | Grad Norm 1.4237(1.4979) | Total Time 14.00(14.00)\n",
      "Iter 3482 | Time 59.3721(60.9864) | Bit/dim 3.6988(3.6907) | Xent 0.0871(0.0900) | Loss 3.7423(3.7358) | Error 0.0291(0.0298) Steps 664(677.25) | Grad Norm 1.0121(1.4833) | Total Time 14.00(14.00)\n",
      "Iter 3483 | Time 61.8420(61.0121) | Bit/dim 3.6900(3.6907) | Xent 0.0816(0.0898) | Loss 3.7308(3.7356) | Error 0.0249(0.0297) Steps 670(677.04) | Grad Norm 0.9725(1.4680) | Total Time 14.00(14.00)\n",
      "Iter 3484 | Time 59.7034(60.9728) | Bit/dim 3.6826(3.6905) | Xent 0.0910(0.0898) | Loss 3.7281(3.7354) | Error 0.0289(0.0297) Steps 676(677.00) | Grad Norm 1.4085(1.4662) | Total Time 14.00(14.00)\n",
      "Iter 3485 | Time 62.4331(61.0166) | Bit/dim 3.6789(3.6901) | Xent 0.0855(0.0897) | Loss 3.7216(3.7350) | Error 0.0266(0.0296) Steps 682(677.15) | Grad Norm 1.1133(1.4556) | Total Time 14.00(14.00)\n",
      "Iter 3486 | Time 61.2645(61.0241) | Bit/dim 3.6875(3.6900) | Xent 0.0887(0.0897) | Loss 3.7318(3.7349) | Error 0.0289(0.0296) Steps 682(677.30) | Grad Norm 1.1458(1.4463) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0581 | Time 25.1680, Epoch Time 407.4660(407.4357), Bit/dim 3.7134(best: 3.7115), Xent 2.6396, Loss 5.0332, Error 0.4013(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3487 | Time 61.7044(61.0445) | Bit/dim 3.6948(3.6902) | Xent 0.0867(0.0896) | Loss 3.7381(3.7350) | Error 0.0264(0.0295) Steps 676(677.26) | Grad Norm 1.2409(1.4402) | Total Time 14.00(14.00)\n",
      "Iter 3488 | Time 59.3607(60.9940) | Bit/dim 3.6848(3.6900) | Xent 0.0867(0.0895) | Loss 3.7281(3.7348) | Error 0.0285(0.0294) Steps 670(677.04) | Grad Norm 0.9273(1.4248) | Total Time 14.00(14.00)\n",
      "Iter 3489 | Time 59.6359(60.9532) | Bit/dim 3.6829(3.6898) | Xent 0.0851(0.0894) | Loss 3.7255(3.7345) | Error 0.0286(0.0294) Steps 676(677.01) | Grad Norm 1.3268(1.4219) | Total Time 14.00(14.00)\n",
      "Iter 3490 | Time 60.4381(60.9378) | Bit/dim 3.6867(3.6897) | Xent 0.0848(0.0892) | Loss 3.7291(3.7343) | Error 0.0278(0.0294) Steps 676(676.98) | Grad Norm 0.9714(1.4083) | Total Time 14.00(14.00)\n",
      "Iter 3491 | Time 64.3952(61.0415) | Bit/dim 3.6964(3.6899) | Xent 0.0851(0.0891) | Loss 3.7390(3.7345) | Error 0.0291(0.0294) Steps 694(677.49) | Grad Norm 1.3246(1.4058) | Total Time 14.00(14.00)\n",
      "Iter 3492 | Time 59.4161(60.9927) | Bit/dim 3.6948(3.6901) | Xent 0.0874(0.0891) | Loss 3.7385(3.7346) | Error 0.0289(0.0293) Steps 688(677.81) | Grad Norm 1.7607(1.4165) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0582 | Time 24.8511, Epoch Time 405.5680(407.3797), Bit/dim 3.7124(best: 3.7115), Xent 2.6639, Loss 5.0444, Error 0.4085(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3493 | Time 61.6736(61.0132) | Bit/dim 3.6894(3.6900) | Xent 0.0831(0.0889) | Loss 3.7310(3.7345) | Error 0.0272(0.0293) Steps 670(677.57) | Grad Norm 1.1570(1.4087) | Total Time 14.00(14.00)\n",
      "Iter 3494 | Time 60.9699(61.0119) | Bit/dim 3.6926(3.6901) | Xent 0.0922(0.0890) | Loss 3.7388(3.7346) | Error 0.0288(0.0293) Steps 688(677.89) | Grad Norm 2.0881(1.4291) | Total Time 14.00(14.00)\n",
      "Iter 3495 | Time 61.8538(61.0371) | Bit/dim 3.6824(3.6899) | Xent 0.0935(0.0891) | Loss 3.7291(3.7344) | Error 0.0295(0.0293) Steps 682(678.01) | Grad Norm 1.7321(1.4382) | Total Time 14.00(14.00)\n",
      "Iter 3496 | Time 61.7076(61.0572) | Bit/dim 3.6907(3.6899) | Xent 0.0850(0.0890) | Loss 3.7332(3.7344) | Error 0.0306(0.0293) Steps 676(677.95) | Grad Norm 1.9960(1.4549) | Total Time 14.00(14.00)\n",
      "Iter 3497 | Time 60.9845(61.0551) | Bit/dim 3.6911(3.6900) | Xent 0.0948(0.0892) | Loss 3.7385(3.7345) | Error 0.0321(0.0294) Steps 676(677.89) | Grad Norm 1.4377(1.4544) | Total Time 14.00(14.00)\n",
      "Iter 3498 | Time 63.2720(61.1216) | Bit/dim 3.6914(3.6900) | Xent 0.0914(0.0892) | Loss 3.7371(3.7346) | Error 0.0308(0.0294) Steps 688(678.19) | Grad Norm 2.9028(1.4978) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0583 | Time 25.2078, Epoch Time 411.3511(407.4988), Bit/dim 3.7127(best: 3.7115), Xent 2.6631, Loss 5.0442, Error 0.4088(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3499 | Time 61.2051(61.1241) | Bit/dim 3.6873(3.6899) | Xent 0.0962(0.0894) | Loss 3.7354(3.7346) | Error 0.0325(0.0295) Steps 682(678.31) | Grad Norm 2.1998(1.5189) | Total Time 14.00(14.00)\n",
      "Iter 3500 | Time 61.9875(61.1500) | Bit/dim 3.6811(3.6897) | Xent 0.0832(0.0893) | Loss 3.7228(3.7343) | Error 0.0272(0.0295) Steps 682(678.42) | Grad Norm 1.5813(1.5208) | Total Time 14.00(14.00)\n",
      "Iter 3501 | Time 62.4688(61.1895) | Bit/dim 3.6944(3.6898) | Xent 0.0848(0.0891) | Loss 3.7368(3.7344) | Error 0.0276(0.0294) Steps 676(678.35) | Grad Norm 2.0027(1.5352) | Total Time 14.00(14.00)\n",
      "Iter 3502 | Time 62.0757(61.2161) | Bit/dim 3.6932(3.6899) | Xent 0.0892(0.0891) | Loss 3.7378(3.7345) | Error 0.0305(0.0294) Steps 682(678.46) | Grad Norm 1.2406(1.5264) | Total Time 14.00(14.00)\n",
      "Iter 3503 | Time 61.9986(61.2396) | Bit/dim 3.6924(3.6900) | Xent 0.0832(0.0889) | Loss 3.7340(3.7344) | Error 0.0295(0.0294) Steps 688(678.74) | Grad Norm 1.8172(1.5351) | Total Time 14.00(14.00)\n",
      "Iter 3504 | Time 62.1828(61.2679) | Bit/dim 3.6876(3.6899) | Xent 0.0859(0.0889) | Loss 3.7305(3.7343) | Error 0.0282(0.0294) Steps 664(678.30) | Grad Norm 1.9653(1.5480) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0584 | Time 24.7480, Epoch Time 412.8077(407.6581), Bit/dim 3.7117(best: 3.7115), Xent 2.6281, Loss 5.0258, Error 0.4055(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3505 | Time 60.4032(61.2420) | Bit/dim 3.6877(3.6898) | Xent 0.0850(0.0887) | Loss 3.7302(3.7342) | Error 0.0272(0.0293) Steps 676(678.23) | Grad Norm 2.1538(1.5662) | Total Time 14.00(14.00)\n",
      "Iter 3506 | Time 61.4132(61.2471) | Bit/dim 3.6895(3.6898) | Xent 0.0863(0.0887) | Loss 3.7327(3.7342) | Error 0.0290(0.0293) Steps 676(678.16) | Grad Norm 2.3351(1.5893) | Total Time 14.00(14.00)\n",
      "Iter 3507 | Time 62.8053(61.2938) | Bit/dim 3.6880(3.6898) | Xent 0.0869(0.0886) | Loss 3.7314(3.7341) | Error 0.0291(0.0293) Steps 676(678.10) | Grad Norm 1.6606(1.5914) | Total Time 14.00(14.00)\n",
      "Iter 3508 | Time 62.9777(61.3444) | Bit/dim 3.6950(3.6899) | Xent 0.0856(0.0885) | Loss 3.7378(3.7342) | Error 0.0290(0.0293) Steps 682(678.22) | Grad Norm 1.8191(1.5982) | Total Time 14.00(14.00)\n",
      "Iter 3509 | Time 60.7829(61.3275) | Bit/dim 3.6930(3.6900) | Xent 0.0911(0.0886) | Loss 3.7385(3.7343) | Error 0.0292(0.0293) Steps 676(678.15) | Grad Norm 2.8522(1.6359) | Total Time 14.00(14.00)\n",
      "Iter 3510 | Time 61.9196(61.3453) | Bit/dim 3.6825(3.6898) | Xent 0.0882(0.0886) | Loss 3.7266(3.7341) | Error 0.0300(0.0293) Steps 682(678.26) | Grad Norm 1.1339(1.6208) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0585 | Time 24.8721, Epoch Time 411.0086(407.7586), Bit/dim 3.7129(best: 3.7115), Xent 2.6385, Loss 5.0322, Error 0.4069(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3511 | Time 59.2013(61.2810) | Bit/dim 3.6890(3.6898) | Xent 0.0829(0.0884) | Loss 3.7304(3.7340) | Error 0.0282(0.0293) Steps 682(678.38) | Grad Norm 1.7062(1.6234) | Total Time 14.00(14.00)\n",
      "Iter 3512 | Time 60.9225(61.2702) | Bit/dim 3.6914(3.6898) | Xent 0.0854(0.0883) | Loss 3.7340(3.7340) | Error 0.0276(0.0292) Steps 676(678.31) | Grad Norm 2.1165(1.6382) | Total Time 14.00(14.00)\n",
      "Iter 3513 | Time 59.2879(61.2107) | Bit/dim 3.6926(3.6899) | Xent 0.0904(0.0884) | Loss 3.7378(3.7341) | Error 0.0302(0.0293) Steps 670(678.06) | Grad Norm 1.4482(1.6325) | Total Time 14.00(14.00)\n",
      "Iter 3514 | Time 60.7586(61.1972) | Bit/dim 3.6846(3.6897) | Xent 0.0907(0.0885) | Loss 3.7299(3.7340) | Error 0.0289(0.0293) Steps 670(677.81) | Grad Norm 1.2212(1.6201) | Total Time 14.00(14.00)\n",
      "Iter 3515 | Time 58.5411(61.1175) | Bit/dim 3.6890(3.6897) | Xent 0.0791(0.0882) | Loss 3.7286(3.7338) | Error 0.0259(0.0292) Steps 676(677.76) | Grad Norm 1.4160(1.6140) | Total Time 14.00(14.00)\n",
      "Iter 3516 | Time 59.9979(61.0839) | Bit/dim 3.6898(3.6897) | Xent 0.0822(0.0880) | Loss 3.7309(3.7337) | Error 0.0298(0.0292) Steps 694(678.25) | Grad Norm 1.4682(1.6096) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0586 | Time 25.0687, Epoch Time 399.7171(407.5174), Bit/dim 3.7132(best: 3.7115), Xent 2.6546, Loss 5.0404, Error 0.4040(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3517 | Time 61.9776(61.1107) | Bit/dim 3.6843(3.6896) | Xent 0.0871(0.0880) | Loss 3.7278(3.7335) | Error 0.0299(0.0292) Steps 664(677.82) | Grad Norm 1.2277(1.5982) | Total Time 14.00(14.00)\n",
      "Iter 3518 | Time 61.1391(61.1116) | Bit/dim 3.6963(3.6898) | Xent 0.0855(0.0879) | Loss 3.7390(3.7337) | Error 0.0281(0.0292) Steps 682(677.95) | Grad Norm 1.5390(1.5964) | Total Time 14.00(14.00)\n",
      "Iter 3519 | Time 59.6063(61.0664) | Bit/dim 3.6879(3.6897) | Xent 0.0889(0.0879) | Loss 3.7323(3.7337) | Error 0.0282(0.0291) Steps 682(678.07) | Grad Norm 1.3271(1.5883) | Total Time 14.00(14.00)\n",
      "Iter 3520 | Time 61.3796(61.0758) | Bit/dim 3.6918(3.6898) | Xent 0.0828(0.0878) | Loss 3.7332(3.7337) | Error 0.0272(0.0291) Steps 676(678.01) | Grad Norm 1.0954(1.5735) | Total Time 14.00(14.00)\n",
      "Iter 3521 | Time 62.0533(61.1051) | Bit/dim 3.6828(3.6896) | Xent 0.0856(0.0877) | Loss 3.7256(3.7334) | Error 0.0284(0.0291) Steps 670(677.76) | Grad Norm 1.1946(1.5621) | Total Time 14.00(14.00)\n",
      "Iter 3522 | Time 59.9543(61.0706) | Bit/dim 3.6910(3.6896) | Xent 0.0812(0.0875) | Loss 3.7316(3.7334) | Error 0.0266(0.0290) Steps 676(677.71) | Grad Norm 1.2101(1.5516) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0587 | Time 25.2690, Epoch Time 407.2146(407.5083), Bit/dim 3.7123(best: 3.7115), Xent 2.6743, Loss 5.0494, Error 0.4077(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3523 | Time 61.2964(61.0774) | Bit/dim 3.6833(3.6894) | Xent 0.0865(0.0875) | Loss 3.7265(3.7331) | Error 0.0280(0.0290) Steps 670(677.48) | Grad Norm 0.9861(1.5346) | Total Time 14.00(14.00)\n",
      "Iter 3524 | Time 62.4783(61.1194) | Bit/dim 3.6843(3.6893) | Xent 0.0904(0.0876) | Loss 3.7295(3.7330) | Error 0.0314(0.0290) Steps 682(677.62) | Grad Norm 1.2181(1.5251) | Total Time 14.00(14.00)\n",
      "Iter 3525 | Time 63.3482(61.1863) | Bit/dim 3.6968(3.6895) | Xent 0.0858(0.0875) | Loss 3.7397(3.7332) | Error 0.0288(0.0290) Steps 676(677.57) | Grad Norm 1.1326(1.5133) | Total Time 14.00(14.00)\n",
      "Iter 3526 | Time 61.8936(61.2075) | Bit/dim 3.6904(3.6895) | Xent 0.0813(0.0873) | Loss 3.7310(3.7332) | Error 0.0269(0.0290) Steps 682(677.70) | Grad Norm 1.1040(1.5011) | Total Time 14.00(14.00)\n",
      "Iter 3527 | Time 63.7382(61.2834) | Bit/dim 3.6821(3.6893) | Xent 0.0901(0.0874) | Loss 3.7272(3.7330) | Error 0.0308(0.0290) Steps 682(677.83) | Grad Norm 2.4307(1.5290) | Total Time 14.00(14.00)\n",
      "Iter 3528 | Time 65.0531(61.3965) | Bit/dim 3.6930(3.6894) | Xent 0.0923(0.0876) | Loss 3.7391(3.7332) | Error 0.0321(0.0291) Steps 664(677.41) | Grad Norm 1.2690(1.5212) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0588 | Time 25.4608, Epoch Time 419.1181(407.8566), Bit/dim 3.7130(best: 3.7115), Xent 2.6274, Loss 5.0267, Error 0.4054(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3529 | Time 59.4622(61.3385) | Bit/dim 3.6955(3.6896) | Xent 0.0917(0.0877) | Loss 3.7414(3.7334) | Error 0.0308(0.0292) Steps 682(677.55) | Grad Norm 1.3216(1.5152) | Total Time 14.00(14.00)\n",
      "Iter 3530 | Time 60.8274(61.3231) | Bit/dim 3.7003(3.6899) | Xent 0.0832(0.0875) | Loss 3.7419(3.7337) | Error 0.0256(0.0291) Steps 676(677.51) | Grad Norm 2.1350(1.5338) | Total Time 14.00(14.00)\n",
      "Iter 3531 | Time 63.1849(61.3790) | Bit/dim 3.6891(3.6899) | Xent 0.0902(0.0876) | Loss 3.7342(3.7337) | Error 0.0290(0.0290) Steps 676(677.46) | Grad Norm 1.3536(1.5284) | Total Time 14.00(14.00)\n",
      "Iter 3532 | Time 61.8211(61.3922) | Bit/dim 3.6848(3.6897) | Xent 0.0915(0.0877) | Loss 3.7306(3.7336) | Error 0.0296(0.0291) Steps 664(677.06) | Grad Norm 1.5040(1.5276) | Total Time 14.00(14.00)\n",
      "Iter 3533 | Time 59.8219(61.3451) | Bit/dim 3.6772(3.6894) | Xent 0.0794(0.0875) | Loss 3.7169(3.7331) | Error 0.0280(0.0290) Steps 682(677.21) | Grad Norm 2.1077(1.5450) | Total Time 14.00(14.00)\n",
      "Iter 3534 | Time 60.0261(61.3056) | Bit/dim 3.6889(3.6893) | Xent 0.0983(0.0878) | Loss 3.7380(3.7332) | Error 0.0321(0.0291) Steps 664(676.81) | Grad Norm 1.4815(1.5431) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0589 | Time 25.6847, Epoch Time 406.5769(407.8182), Bit/dim 3.7121(best: 3.7115), Xent 2.6629, Loss 5.0435, Error 0.4090(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3535 | Time 61.4175(61.3089) | Bit/dim 3.6740(3.6889) | Xent 0.0901(0.0879) | Loss 3.7190(3.7328) | Error 0.0308(0.0292) Steps 664(676.42) | Grad Norm 2.9851(1.5864) | Total Time 14.00(14.00)\n",
      "Iter 3536 | Time 59.0527(61.2412) | Bit/dim 3.6958(3.6891) | Xent 0.0830(0.0877) | Loss 3.7373(3.7330) | Error 0.0298(0.0292) Steps 676(676.41) | Grad Norm 1.9694(1.5979) | Total Time 14.00(14.00)\n",
      "Iter 3537 | Time 62.2608(61.2718) | Bit/dim 3.7004(3.6894) | Xent 0.0927(0.0879) | Loss 3.7467(3.7334) | Error 0.0296(0.0292) Steps 682(676.58) | Grad Norm 1.6619(1.5998) | Total Time 14.00(14.00)\n",
      "Iter 3538 | Time 62.3613(61.3045) | Bit/dim 3.6946(3.6896) | Xent 0.0852(0.0878) | Loss 3.7372(3.7335) | Error 0.0294(0.0292) Steps 676(676.56) | Grad Norm 2.3933(1.6236) | Total Time 14.00(14.00)\n",
      "Iter 3539 | Time 63.4512(61.3689) | Bit/dim 3.6936(3.6897) | Xent 0.0834(0.0877) | Loss 3.7353(3.7335) | Error 0.0279(0.0292) Steps 676(676.55) | Grad Norm 2.9763(1.6642) | Total Time 14.00(14.00)\n",
      "Iter 3540 | Time 63.5014(61.4329) | Bit/dim 3.6829(3.6895) | Xent 0.0806(0.0875) | Loss 3.7232(3.7332) | Error 0.0278(0.0291) Steps 664(676.17) | Grad Norm 1.5205(1.6599) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0590 | Time 25.4526, Epoch Time 413.2102(407.9800), Bit/dim 3.7119(best: 3.7115), Xent 2.6555, Loss 5.0397, Error 0.4033(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3541 | Time 66.0456(61.5713) | Bit/dim 3.6924(3.6896) | Xent 0.0859(0.0874) | Loss 3.7354(3.7333) | Error 0.0292(0.0291) Steps 676(676.16) | Grad Norm 1.5962(1.6580) | Total Time 14.00(14.00)\n",
      "Iter 3542 | Time 59.8023(61.5182) | Bit/dim 3.6853(3.6895) | Xent 0.0838(0.0873) | Loss 3.7272(3.7331) | Error 0.0284(0.0291) Steps 676(676.16) | Grad Norm 1.6843(1.6588) | Total Time 14.00(14.00)\n",
      "Iter 3543 | Time 60.1418(61.4769) | Bit/dim 3.6935(3.6896) | Xent 0.0854(0.0873) | Loss 3.7362(3.7332) | Error 0.0288(0.0291) Steps 670(675.97) | Grad Norm 1.7744(1.6622) | Total Time 14.00(14.00)\n",
      "Iter 3544 | Time 64.1032(61.5557) | Bit/dim 3.6857(3.6895) | Xent 0.0829(0.0871) | Loss 3.7271(3.7330) | Error 0.0262(0.0290) Steps 670(675.79) | Grad Norm 1.0593(1.6441) | Total Time 14.00(14.00)\n",
      "Iter 3545 | Time 66.0762(61.6913) | Bit/dim 3.6941(3.6896) | Xent 0.0903(0.0872) | Loss 3.7393(3.7332) | Error 0.0310(0.0291) Steps 664(675.44) | Grad Norm 3.2346(1.6918) | Total Time 14.00(14.00)\n",
      "Iter 3546 | Time 62.3090(61.7098) | Bit/dim 3.6867(3.6895) | Xent 0.0851(0.0872) | Loss 3.7293(3.7331) | Error 0.0300(0.0291) Steps 670(675.28) | Grad Norm 1.2301(1.6780) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0591 | Time 25.2129, Epoch Time 419.6005(408.3286), Bit/dim 3.7125(best: 3.7115), Xent 2.7158, Loss 5.0704, Error 0.4066(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3547 | Time 62.2786(61.7269) | Bit/dim 3.6843(3.6894) | Xent 0.0841(0.0871) | Loss 3.7263(3.7329) | Error 0.0292(0.0291) Steps 664(674.94) | Grad Norm 1.7501(1.6802) | Total Time 14.00(14.00)\n",
      "Iter 3548 | Time 60.4751(61.6893) | Bit/dim 3.6919(3.6894) | Xent 0.0765(0.0867) | Loss 3.7301(3.7328) | Error 0.0261(0.0290) Steps 670(674.79) | Grad Norm 2.1797(1.6951) | Total Time 14.00(14.00)\n",
      "Iter 3549 | Time 59.7744(61.6319) | Bit/dim 3.6920(3.6895) | Xent 0.0826(0.0866) | Loss 3.7333(3.7328) | Error 0.0271(0.0290) Steps 676(674.83) | Grad Norm 1.3873(1.6859) | Total Time 14.00(14.00)\n",
      "Iter 3550 | Time 61.1722(61.6181) | Bit/dim 3.6935(3.6896) | Xent 0.0809(0.0864) | Loss 3.7339(3.7329) | Error 0.0264(0.0289) Steps 682(675.04) | Grad Norm 1.9418(1.6936) | Total Time 14.00(14.00)\n",
      "Iter 3551 | Time 59.4645(61.5535) | Bit/dim 3.6904(3.6897) | Xent 0.0842(0.0864) | Loss 3.7325(3.7328) | Error 0.0271(0.0288) Steps 676(675.07) | Grad Norm 1.7567(1.6955) | Total Time 14.00(14.00)\n",
      "Iter 3552 | Time 61.4348(61.5499) | Bit/dim 3.6836(3.6895) | Xent 0.0950(0.0866) | Loss 3.7311(3.7328) | Error 0.0310(0.0289) Steps 658(674.56) | Grad Norm 1.4629(1.6885) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0592 | Time 24.8734, Epoch Time 405.0783(408.2311), Bit/dim 3.7142(best: 3.7115), Xent 2.6862, Loss 5.0573, Error 0.4024(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3553 | Time 61.8250(61.5582) | Bit/dim 3.6877(3.6894) | Xent 0.0775(0.0864) | Loss 3.7264(3.7326) | Error 0.0242(0.0288) Steps 694(675.14) | Grad Norm 1.5477(1.6843) | Total Time 14.00(14.00)\n",
      "Iter 3554 | Time 59.5222(61.4971) | Bit/dim 3.6949(3.6896) | Xent 0.0782(0.0861) | Loss 3.7340(3.7326) | Error 0.0260(0.0287) Steps 676(675.17) | Grad Norm 3.0927(1.7265) | Total Time 14.00(14.00)\n",
      "Iter 3555 | Time 59.9582(61.4509) | Bit/dim 3.7031(3.6900) | Xent 0.0865(0.0861) | Loss 3.7463(3.7331) | Error 0.0302(0.0287) Steps 694(675.73) | Grad Norm 1.4908(1.7195) | Total Time 14.00(14.00)\n",
      "Iter 3556 | Time 62.5526(61.4840) | Bit/dim 3.6905(3.6900) | Xent 0.0849(0.0861) | Loss 3.7330(3.7331) | Error 0.0301(0.0288) Steps 676(675.74) | Grad Norm 1.4311(1.7108) | Total Time 14.00(14.00)\n",
      "Iter 3557 | Time 62.6937(61.5203) | Bit/dim 3.6804(3.6897) | Xent 0.0900(0.0862) | Loss 3.7254(3.7328) | Error 0.0312(0.0288) Steps 664(675.39) | Grad Norm 4.0532(1.7811) | Total Time 14.00(14.00)\n",
      "Iter 3558 | Time 63.4359(61.5778) | Bit/dim 3.6834(3.6895) | Xent 0.0917(0.0864) | Loss 3.7292(3.7327) | Error 0.0316(0.0289) Steps 682(675.59) | Grad Norm 1.3097(1.7669) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0593 | Time 25.3706, Epoch Time 411.3935(408.3259), Bit/dim 3.7113(best: 3.7115), Xent 2.6669, Loss 5.0447, Error 0.4049(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3559 | Time 60.6757(61.5507) | Bit/dim 3.6880(3.6895) | Xent 0.0786(0.0861) | Loss 3.7273(3.7326) | Error 0.0272(0.0289) Steps 676(675.60) | Grad Norm 1.3974(1.7559) | Total Time 14.00(14.00)\n",
      "Iter 3560 | Time 63.8530(61.6198) | Bit/dim 3.6921(3.6896) | Xent 0.0867(0.0862) | Loss 3.7354(3.7326) | Error 0.0279(0.0288) Steps 658(675.07) | Grad Norm 2.4574(1.7769) | Total Time 14.00(14.00)\n",
      "Iter 3561 | Time 60.9858(61.6007) | Bit/dim 3.6867(3.6895) | Xent 0.0989(0.0865) | Loss 3.7361(3.7327) | Error 0.0310(0.0289) Steps 676(675.10) | Grad Norm 2.0886(1.7863) | Total Time 14.00(14.00)\n",
      "Iter 3562 | Time 58.7858(61.5163) | Bit/dim 3.6958(3.6897) | Xent 0.0840(0.0865) | Loss 3.7378(3.7329) | Error 0.0271(0.0289) Steps 670(674.95) | Grad Norm 1.5310(1.7786) | Total Time 14.00(14.00)\n",
      "Iter 3563 | Time 61.0035(61.5009) | Bit/dim 3.6868(3.6896) | Xent 0.0859(0.0864) | Loss 3.7297(3.7328) | Error 0.0286(0.0288) Steps 682(675.16) | Grad Norm 2.2421(1.7925) | Total Time 14.00(14.00)\n",
      "Iter 3564 | Time 60.4639(61.4698) | Bit/dim 3.6839(3.6894) | Xent 0.0884(0.0865) | Loss 3.7281(3.7327) | Error 0.0289(0.0288) Steps 676(675.18) | Grad Norm 1.6534(1.7883) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0594 | Time 24.8629, Epoch Time 406.5506(408.2727), Bit/dim 3.7126(best: 3.7113), Xent 2.6555, Loss 5.0404, Error 0.4054(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3565 | Time 63.2023(61.5218) | Bit/dim 3.6877(3.6894) | Xent 0.0910(0.0866) | Loss 3.7332(3.7327) | Error 0.0296(0.0289) Steps 670(675.03) | Grad Norm 1.3795(1.7761) | Total Time 14.00(14.00)\n",
      "Iter 3566 | Time 60.8576(61.5018) | Bit/dim 3.6860(3.6893) | Xent 0.0816(0.0865) | Loss 3.7268(3.7325) | Error 0.0262(0.0288) Steps 682(675.24) | Grad Norm 1.5396(1.7690) | Total Time 14.00(14.00)\n",
      "Iter 3567 | Time 59.4868(61.4414) | Bit/dim 3.6909(3.6893) | Xent 0.0817(0.0863) | Loss 3.7318(3.7325) | Error 0.0279(0.0288) Steps 670(675.08) | Grad Norm 1.3326(1.7559) | Total Time 14.00(14.00)\n",
      "Iter 3568 | Time 62.0736(61.4604) | Bit/dim 3.6939(3.6894) | Xent 0.0878(0.0864) | Loss 3.7378(3.7326) | Error 0.0319(0.0289) Steps 670(674.93) | Grad Norm 1.0453(1.7346) | Total Time 14.00(14.00)\n",
      "Iter 3569 | Time 59.9994(61.4165) | Bit/dim 3.6869(3.6894) | Xent 0.0902(0.0865) | Loss 3.7320(3.7326) | Error 0.0301(0.0289) Steps 688(675.32) | Grad Norm 1.0041(1.7126) | Total Time 14.00(14.00)\n",
      "Iter 3570 | Time 58.6885(61.3347) | Bit/dim 3.6847(3.6892) | Xent 0.0846(0.0864) | Loss 3.7270(3.7324) | Error 0.0284(0.0289) Steps 682(675.52) | Grad Norm 1.7068(1.7125) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0595 | Time 25.0090, Epoch Time 404.8202(408.1691), Bit/dim 3.7126(best: 3.7113), Xent 2.6618, Loss 5.0435, Error 0.4031(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3571 | Time 62.9642(61.3836) | Bit/dim 3.6880(3.6892) | Xent 0.0836(0.0864) | Loss 3.7298(3.7324) | Error 0.0295(0.0289) Steps 682(675.71) | Grad Norm 1.0235(1.6918) | Total Time 14.00(14.00)\n",
      "Iter 3572 | Time 59.2999(61.3211) | Bit/dim 3.6899(3.6892) | Xent 0.0865(0.0864) | Loss 3.7331(3.7324) | Error 0.0278(0.0289) Steps 682(675.90) | Grad Norm 1.0280(1.6719) | Total Time 14.00(14.00)\n",
      "Iter 3573 | Time 64.6006(61.4195) | Bit/dim 3.6822(3.6890) | Xent 0.0912(0.0865) | Loss 3.7278(3.7323) | Error 0.0304(0.0289) Steps 670(675.73) | Grad Norm 1.3359(1.6618) | Total Time 14.00(14.00)\n",
      "Iter 3574 | Time 62.1219(61.4405) | Bit/dim 3.6923(3.6891) | Xent 0.0806(0.0863) | Loss 3.7326(3.7323) | Error 0.0280(0.0289) Steps 682(675.91) | Grad Norm 1.4606(1.6558) | Total Time 14.00(14.00)\n",
      "Iter 3575 | Time 60.0589(61.3991) | Bit/dim 3.7003(3.6894) | Xent 0.0838(0.0863) | Loss 3.7422(3.7326) | Error 0.0280(0.0289) Steps 676(675.92) | Grad Norm 1.0611(1.6379) | Total Time 14.00(14.00)\n",
      "Iter 3576 | Time 61.4040(61.3992) | Bit/dim 3.6873(3.6894) | Xent 0.0834(0.0862) | Loss 3.7290(3.7325) | Error 0.0276(0.0288) Steps 682(676.10) | Grad Norm 0.8989(1.6158) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0596 | Time 25.0965, Epoch Time 411.0382(408.2552), Bit/dim 3.7128(best: 3.7113), Xent 2.6752, Loss 5.0504, Error 0.4089(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3577 | Time 57.8958(61.2941) | Bit/dim 3.6826(3.6892) | Xent 0.0857(0.0862) | Loss 3.7255(3.7322) | Error 0.0281(0.0288) Steps 688(676.46) | Grad Norm 1.2099(1.6036) | Total Time 14.00(14.00)\n",
      "Iter 3578 | Time 63.0042(61.3454) | Bit/dim 3.6830(3.6890) | Xent 0.0728(0.0858) | Loss 3.7193(3.7319) | Error 0.0245(0.0287) Steps 664(676.08) | Grad Norm 1.2351(1.5925) | Total Time 14.00(14.00)\n",
      "Iter 3579 | Time 61.6318(61.3540) | Bit/dim 3.6948(3.6892) | Xent 0.0806(0.0856) | Loss 3.7351(3.7320) | Error 0.0266(0.0286) Steps 682(676.26) | Grad Norm 1.0022(1.5748) | Total Time 14.00(14.00)\n",
      "Iter 3580 | Time 60.3407(61.3236) | Bit/dim 3.6964(3.6894) | Xent 0.0830(0.0855) | Loss 3.7379(3.7321) | Error 0.0276(0.0286) Steps 670(676.07) | Grad Norm 1.3028(1.5667) | Total Time 14.00(14.00)\n",
      "Iter 3581 | Time 59.9572(61.2826) | Bit/dim 3.6806(3.6891) | Xent 0.0859(0.0855) | Loss 3.7235(3.7319) | Error 0.0291(0.0286) Steps 670(675.89) | Grad Norm 1.0036(1.5498) | Total Time 14.00(14.00)\n",
      "Iter 3582 | Time 61.7564(61.2968) | Bit/dim 3.6919(3.6892) | Xent 0.0752(0.0852) | Loss 3.7295(3.7318) | Error 0.0268(0.0285) Steps 676(675.89) | Grad Norm 1.5251(1.5490) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0597 | Time 25.1612, Epoch Time 405.5240(408.1732), Bit/dim 3.7123(best: 3.7113), Xent 2.6851, Loss 5.0548, Error 0.4072(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3583 | Time 58.7922(61.2217) | Bit/dim 3.6865(3.6891) | Xent 0.0812(0.0851) | Loss 3.7271(3.7317) | Error 0.0262(0.0285) Steps 676(675.90) | Grad Norm 1.3882(1.5442) | Total Time 14.00(14.00)\n",
      "Iter 3584 | Time 61.9808(61.2445) | Bit/dim 3.6892(3.6891) | Xent 0.0852(0.0851) | Loss 3.7318(3.7317) | Error 0.0280(0.0285) Steps 670(675.72) | Grad Norm 1.4454(1.5412) | Total Time 14.00(14.00)\n",
      "Iter 3585 | Time 59.6762(61.1974) | Bit/dim 3.6901(3.6891) | Xent 0.0932(0.0853) | Loss 3.7368(3.7318) | Error 0.0316(0.0286) Steps 682(675.91) | Grad Norm 1.8494(1.5505) | Total Time 14.00(14.00)\n",
      "Iter 3586 | Time 61.2504(61.1990) | Bit/dim 3.6844(3.6890) | Xent 0.0851(0.0853) | Loss 3.7270(3.7317) | Error 0.0279(0.0285) Steps 682(676.09) | Grad Norm 2.0691(1.5660) | Total Time 14.00(14.00)\n",
      "Iter 3587 | Time 63.1045(61.2562) | Bit/dim 3.6909(3.6891) | Xent 0.0772(0.0851) | Loss 3.7295(3.7316) | Error 0.0254(0.0284) Steps 670(675.91) | Grad Norm 1.1214(1.5527) | Total Time 14.00(14.00)\n",
      "Iter 3588 | Time 60.2468(61.2259) | Bit/dim 3.6860(3.6890) | Xent 0.0788(0.0849) | Loss 3.7255(3.7314) | Error 0.0265(0.0284) Steps 676(675.91) | Grad Norm 1.1742(1.5413) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0598 | Time 24.9924, Epoch Time 405.5334(408.0940), Bit/dim 3.7119(best: 3.7113), Xent 2.6701, Loss 5.0469, Error 0.4031(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3589 | Time 61.0405(61.2203) | Bit/dim 3.6767(3.6886) | Xent 0.0785(0.0847) | Loss 3.7160(3.7310) | Error 0.0260(0.0283) Steps 676(675.91) | Grad Norm 1.1195(1.5287) | Total Time 14.00(14.00)\n",
      "Iter 3590 | Time 61.0997(61.2167) | Bit/dim 3.6761(3.6882) | Xent 0.0944(0.0850) | Loss 3.7233(3.7307) | Error 0.0309(0.0284) Steps 670(675.74) | Grad Norm 1.3169(1.5223) | Total Time 14.00(14.00)\n",
      "Iter 3591 | Time 62.0937(61.2430) | Bit/dim 3.6931(3.6884) | Xent 0.0759(0.0847) | Loss 3.7310(3.7307) | Error 0.0258(0.0283) Steps 664(675.38) | Grad Norm 1.1355(1.5107) | Total Time 14.00(14.00)\n",
      "Iter 3592 | Time 60.3561(61.2164) | Bit/dim 3.6901(3.6884) | Xent 0.0846(0.0847) | Loss 3.7324(3.7308) | Error 0.0280(0.0283) Steps 670(675.22) | Grad Norm 1.3679(1.5064) | Total Time 14.00(14.00)\n",
      "Iter 3593 | Time 60.2477(61.1874) | Bit/dim 3.6878(3.6884) | Xent 0.0804(0.0846) | Loss 3.7280(3.7307) | Error 0.0250(0.0282) Steps 688(675.61) | Grad Norm 1.3552(1.5019) | Total Time 14.00(14.00)\n",
      "Iter 3594 | Time 60.7504(61.1742) | Bit/dim 3.6993(3.6887) | Xent 0.0785(0.0844) | Loss 3.7386(3.7309) | Error 0.0251(0.0281) Steps 694(676.16) | Grad Norm 1.3882(1.4985) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0599 | Time 25.2185, Epoch Time 406.2293(408.0381), Bit/dim 3.7130(best: 3.7113), Xent 2.7276, Loss 5.0768, Error 0.4096(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3595 | Time 59.8280(61.1339) | Bit/dim 3.6913(3.6888) | Xent 0.0876(0.0845) | Loss 3.7351(3.7311) | Error 0.0281(0.0281) Steps 670(675.97) | Grad Norm 1.2629(1.4914) | Total Time 14.00(14.00)\n",
      "Iter 3596 | Time 63.2438(61.1972) | Bit/dim 3.6771(3.6885) | Xent 0.0888(0.0846) | Loss 3.7215(3.7308) | Error 0.0312(0.0282) Steps 676(675.97) | Grad Norm 1.1791(1.4821) | Total Time 14.00(14.00)\n",
      "Iter 3597 | Time 61.5220(61.2069) | Bit/dim 3.6970(3.6887) | Xent 0.0849(0.0846) | Loss 3.7394(3.7310) | Error 0.0286(0.0282) Steps 676(675.97) | Grad Norm 1.3744(1.4788) | Total Time 14.00(14.00)\n",
      "Iter 3598 | Time 59.7164(61.1622) | Bit/dim 3.6891(3.6887) | Xent 0.0862(0.0847) | Loss 3.7322(3.7311) | Error 0.0301(0.0283) Steps 676(675.98) | Grad Norm 1.4023(1.4765) | Total Time 14.00(14.00)\n",
      "Iter 3599 | Time 60.5429(61.1436) | Bit/dim 3.6978(3.6890) | Xent 0.0756(0.0844) | Loss 3.7356(3.7312) | Error 0.0231(0.0281) Steps 676(675.98) | Grad Norm 1.5565(1.4789) | Total Time 14.00(14.00)\n",
      "Iter 3600 | Time 64.6336(61.2483) | Bit/dim 3.6809(3.6888) | Xent 0.0831(0.0844) | Loss 3.7225(3.7309) | Error 0.0272(0.0281) Steps 670(675.80) | Grad Norm 1.1370(1.4687) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0600 | Time 24.9232, Epoch Time 410.2144(408.1034), Bit/dim 3.7120(best: 3.7113), Xent 2.6943, Loss 5.0592, Error 0.4027(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3601 | Time 60.2732(61.2191) | Bit/dim 3.6953(3.6890) | Xent 0.0821(0.0843) | Loss 3.7364(3.7311) | Error 0.0285(0.0281) Steps 664(675.44) | Grad Norm 1.3249(1.4644) | Total Time 14.00(14.00)\n",
      "Iter 3602 | Time 59.9530(61.1811) | Bit/dim 3.6934(3.6891) | Xent 0.0893(0.0845) | Loss 3.7380(3.7313) | Error 0.0279(0.0281) Steps 664(675.10) | Grad Norm 1.5745(1.4677) | Total Time 14.00(14.00)\n",
      "Iter 3603 | Time 62.3060(61.2148) | Bit/dim 3.6860(3.6890) | Xent 0.0848(0.0845) | Loss 3.7284(3.7312) | Error 0.0302(0.0282) Steps 682(675.31) | Grad Norm 1.6265(1.4724) | Total Time 14.00(14.00)\n",
      "Iter 3604 | Time 60.9343(61.2064) | Bit/dim 3.6870(3.6889) | Xent 0.0855(0.0845) | Loss 3.7297(3.7312) | Error 0.0286(0.0282) Steps 676(675.33) | Grad Norm 1.8544(1.4839) | Total Time 14.00(14.00)\n",
      "Iter 3605 | Time 60.5566(61.1869) | Bit/dim 3.6843(3.6888) | Xent 0.0874(0.0846) | Loss 3.7280(3.7311) | Error 0.0295(0.0282) Steps 676(675.35) | Grad Norm 1.1759(1.4746) | Total Time 14.00(14.00)\n",
      "Iter 3606 | Time 58.5847(61.1088) | Bit/dim 3.6807(3.6886) | Xent 0.0870(0.0847) | Loss 3.7243(3.7309) | Error 0.0298(0.0283) Steps 676(675.37) | Grad Norm 1.4827(1.4749) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0601 | Time 25.0426, Epoch Time 403.6645(407.9702), Bit/dim 3.7125(best: 3.7113), Xent 2.6964, Loss 5.0607, Error 0.4064(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3607 | Time 58.5164(61.0311) | Bit/dim 3.6981(3.6888) | Xent 0.0808(0.0845) | Loss 3.7385(3.7311) | Error 0.0239(0.0281) Steps 670(675.21) | Grad Norm 1.8859(1.4872) | Total Time 14.00(14.00)\n",
      "Iter 3608 | Time 64.5102(61.1354) | Bit/dim 3.6833(3.6887) | Xent 0.0870(0.0846) | Loss 3.7268(3.7310) | Error 0.0295(0.0282) Steps 676(675.23) | Grad Norm 1.2471(1.4800) | Total Time 14.00(14.00)\n",
      "Iter 3609 | Time 63.7998(61.2154) | Bit/dim 3.6886(3.6887) | Xent 0.0843(0.0846) | Loss 3.7307(3.7310) | Error 0.0261(0.0281) Steps 670(675.07) | Grad Norm 1.8510(1.4911) | Total Time 14.00(14.00)\n",
      "Iter 3610 | Time 61.1137(61.2123) | Bit/dim 3.6773(3.6883) | Xent 0.0769(0.0844) | Loss 3.7157(3.7305) | Error 0.0259(0.0280) Steps 664(674.74) | Grad Norm 1.8034(1.5005) | Total Time 14.00(14.00)\n",
      "Iter 3611 | Time 58.8307(61.1409) | Bit/dim 3.7042(3.6888) | Xent 0.0753(0.0841) | Loss 3.7418(3.7309) | Error 0.0245(0.0279) Steps 682(674.96) | Grad Norm 2.3685(1.5266) | Total Time 14.00(14.00)\n",
      "Iter 3612 | Time 58.5163(61.0621) | Bit/dim 3.6785(3.6885) | Xent 0.0832(0.0841) | Loss 3.7201(3.7305) | Error 0.0284(0.0279) Steps 682(675.17) | Grad Norm 1.1775(1.5161) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0602 | Time 24.8845, Epoch Time 405.9673(407.9101), Bit/dim 3.7115(best: 3.7113), Xent 2.6583, Loss 5.0407, Error 0.4037(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3613 | Time 60.4892(61.0450) | Bit/dim 3.6815(3.6883) | Xent 0.0764(0.0838) | Loss 3.7198(3.7302) | Error 0.0249(0.0279) Steps 676(675.19) | Grad Norm 1.5596(1.5174) | Total Time 14.00(14.00)\n",
      "Iter 3614 | Time 61.2793(61.0520) | Bit/dim 3.6924(3.6884) | Xent 0.0761(0.0836) | Loss 3.7304(3.7302) | Error 0.0258(0.0278) Steps 676(675.22) | Grad Norm 1.7631(1.5248) | Total Time 14.00(14.00)\n",
      "Iter 3615 | Time 59.0655(60.9924) | Bit/dim 3.6804(3.6882) | Xent 0.0870(0.0837) | Loss 3.7239(3.7300) | Error 0.0294(0.0278) Steps 670(675.06) | Grad Norm 1.1408(1.5132) | Total Time 14.00(14.00)\n",
      "Iter 3616 | Time 61.5228(61.0083) | Bit/dim 3.6871(3.6881) | Xent 0.0876(0.0838) | Loss 3.7309(3.7301) | Error 0.0279(0.0278) Steps 682(675.27) | Grad Norm 1.6196(1.5164) | Total Time 14.00(14.00)\n",
      "Iter 3617 | Time 60.1034(60.9812) | Bit/dim 3.6943(3.6883) | Xent 0.0852(0.0839) | Loss 3.7369(3.7303) | Error 0.0270(0.0278) Steps 676(675.29) | Grad Norm 1.5006(1.5160) | Total Time 14.00(14.00)\n",
      "Iter 3618 | Time 60.8293(60.9766) | Bit/dim 3.6929(3.6885) | Xent 0.0890(0.0840) | Loss 3.7374(3.7305) | Error 0.0282(0.0278) Steps 670(675.13) | Grad Norm 1.9796(1.5299) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0603 | Time 24.9027, Epoch Time 404.0877(407.7955), Bit/dim 3.7124(best: 3.7113), Xent 2.7031, Loss 5.0640, Error 0.4082(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3619 | Time 58.9117(60.9147) | Bit/dim 3.6953(3.6887) | Xent 0.0803(0.0839) | Loss 3.7355(3.7306) | Error 0.0254(0.0278) Steps 682(675.34) | Grad Norm 1.4722(1.5281) | Total Time 14.00(14.00)\n",
      "Iter 3620 | Time 61.4801(60.9316) | Bit/dim 3.6848(3.6885) | Xent 0.0823(0.0839) | Loss 3.7259(3.7305) | Error 0.0265(0.0277) Steps 670(675.18) | Grad Norm 1.5158(1.5278) | Total Time 14.00(14.00)\n",
      "Iter 3621 | Time 59.0134(60.8741) | Bit/dim 3.6886(3.6886) | Xent 0.0761(0.0836) | Loss 3.7267(3.7304) | Error 0.0252(0.0276) Steps 682(675.38) | Grad Norm 1.2449(1.5193) | Total Time 14.00(14.00)\n",
      "Iter 3622 | Time 61.3428(60.8881) | Bit/dim 3.6868(3.6885) | Xent 0.0943(0.0840) | Loss 3.7339(3.7305) | Error 0.0300(0.0277) Steps 682(675.58) | Grad Norm 1.5542(1.5203) | Total Time 14.00(14.00)\n",
      "Iter 3623 | Time 59.1963(60.8374) | Bit/dim 3.6911(3.6886) | Xent 0.0787(0.0838) | Loss 3.7305(3.7305) | Error 0.0262(0.0277) Steps 676(675.60) | Grad Norm 1.1097(1.5080) | Total Time 14.00(14.00)\n",
      "Iter 3624 | Time 59.3768(60.7936) | Bit/dim 3.6806(3.6883) | Xent 0.0809(0.0837) | Loss 3.7211(3.7302) | Error 0.0275(0.0277) Steps 676(675.61) | Grad Norm 1.2320(1.4997) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0604 | Time 25.0041, Epoch Time 400.4116(407.5740), Bit/dim 3.7132(best: 3.7113), Xent 2.7010, Loss 5.0637, Error 0.4100(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3625 | Time 62.0356(60.8308) | Bit/dim 3.6924(3.6885) | Xent 0.0843(0.0837) | Loss 3.7346(3.7303) | Error 0.0300(0.0277) Steps 670(675.44) | Grad Norm 1.7781(1.5081) | Total Time 14.00(14.00)\n",
      "Iter 3626 | Time 60.2273(60.8127) | Bit/dim 3.6894(3.6885) | Xent 0.0795(0.0836) | Loss 3.7291(3.7303) | Error 0.0275(0.0277) Steps 682(675.64) | Grad Norm 1.9401(1.5210) | Total Time 14.00(14.00)\n",
      "Iter 3627 | Time 61.9760(60.8476) | Bit/dim 3.6824(3.6883) | Xent 0.0891(0.0838) | Loss 3.7269(3.7302) | Error 0.0286(0.0278) Steps 670(675.47) | Grad Norm 1.7315(1.5274) | Total Time 14.00(14.00)\n",
      "Iter 3628 | Time 60.4880(60.8368) | Bit/dim 3.6882(3.6883) | Xent 0.0837(0.0838) | Loss 3.7301(3.7302) | Error 0.0272(0.0277) Steps 670(675.30) | Grad Norm 1.7418(1.5338) | Total Time 14.00(14.00)\n",
      "Iter 3629 | Time 60.4265(60.8245) | Bit/dim 3.6943(3.6885) | Xent 0.0800(0.0837) | Loss 3.7343(3.7303) | Error 0.0249(0.0277) Steps 676(675.32) | Grad Norm 1.5359(1.5339) | Total Time 14.00(14.00)\n",
      "Iter 3630 | Time 60.4762(60.8141) | Bit/dim 3.6819(3.6883) | Xent 0.0856(0.0837) | Loss 3.7246(3.7301) | Error 0.0272(0.0276) Steps 670(675.16) | Grad Norm 2.0705(1.5499) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0605 | Time 24.9002, Epoch Time 406.5549(407.5434), Bit/dim 3.7129(best: 3.7113), Xent 2.6866, Loss 5.0562, Error 0.4043(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3631 | Time 60.5934(60.8074) | Bit/dim 3.6934(3.6884) | Xent 0.0774(0.0835) | Loss 3.7321(3.7302) | Error 0.0254(0.0276) Steps 682(675.37) | Grad Norm 1.1421(1.5377) | Total Time 14.00(14.00)\n",
      "Iter 3632 | Time 58.3917(60.7350) | Bit/dim 3.6971(3.6887) | Xent 0.0880(0.0837) | Loss 3.7411(3.7305) | Error 0.0304(0.0277) Steps 676(675.39) | Grad Norm 1.8978(1.5485) | Total Time 14.00(14.00)\n",
      "Iter 3633 | Time 61.5330(60.7589) | Bit/dim 3.6845(3.6886) | Xent 0.0828(0.0836) | Loss 3.7260(3.7304) | Error 0.0278(0.0277) Steps 682(675.59) | Grad Norm 2.0609(1.5639) | Total Time 14.00(14.00)\n",
      "Iter 3634 | Time 59.7343(60.7282) | Bit/dim 3.6869(3.6885) | Xent 0.0870(0.0837) | Loss 3.7304(3.7304) | Error 0.0282(0.0277) Steps 676(675.60) | Grad Norm 2.8503(1.6025) | Total Time 14.00(14.00)\n",
      "Iter 3635 | Time 60.9552(60.7350) | Bit/dim 3.6867(3.6885) | Xent 0.0857(0.0838) | Loss 3.7295(3.7304) | Error 0.0279(0.0277) Steps 682(675.79) | Grad Norm 1.4331(1.5974) | Total Time 14.00(14.00)\n",
      "Iter 3636 | Time 59.5754(60.7002) | Bit/dim 3.6843(3.6883) | Xent 0.0810(0.0837) | Loss 3.7248(3.7302) | Error 0.0272(0.0277) Steps 670(675.62) | Grad Norm 2.9779(1.6388) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0606 | Time 25.1444, Epoch Time 401.6535(407.3667), Bit/dim 3.7119(best: 3.7113), Xent 2.6349, Loss 5.0294, Error 0.4010(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3637 | Time 59.8003(60.6732) | Bit/dim 3.6874(3.6883) | Xent 0.0889(0.0839) | Loss 3.7319(3.7302) | Error 0.0284(0.0277) Steps 682(675.81) | Grad Norm 3.7864(1.7032) | Total Time 14.00(14.00)\n",
      "Iter 3638 | Time 61.3121(60.6924) | Bit/dim 3.6881(3.6883) | Xent 0.0834(0.0838) | Loss 3.7299(3.7302) | Error 0.0264(0.0277) Steps 694(676.35) | Grad Norm 1.5432(1.6984) | Total Time 14.00(14.00)\n",
      "Iter 3639 | Time 59.1362(60.6457) | Bit/dim 3.6915(3.6884) | Xent 0.0735(0.0835) | Loss 3.7282(3.7302) | Error 0.0254(0.0276) Steps 676(676.34) | Grad Norm 1.8146(1.7019) | Total Time 14.00(14.00)\n",
      "Iter 3640 | Time 59.8824(60.6228) | Bit/dim 3.6860(3.6883) | Xent 0.0839(0.0835) | Loss 3.7279(3.7301) | Error 0.0286(0.0276) Steps 670(676.15) | Grad Norm 1.7223(1.7025) | Total Time 14.00(14.00)\n",
      "Iter 3641 | Time 61.1079(60.6373) | Bit/dim 3.6858(3.6883) | Xent 0.0757(0.0833) | Loss 3.7236(3.7299) | Error 0.0260(0.0276) Steps 670(675.97) | Grad Norm 1.4948(1.6963) | Total Time 14.00(14.00)\n",
      "Iter 3642 | Time 61.0824(60.6507) | Bit/dim 3.6869(3.6882) | Xent 0.0856(0.0834) | Loss 3.7297(3.7299) | Error 0.0281(0.0276) Steps 676(675.97) | Grad Norm 1.1734(1.6806) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0607 | Time 25.2374, Epoch Time 403.2657(407.2437), Bit/dim 3.7117(best: 3.7113), Xent 2.7347, Loss 5.0791, Error 0.4115(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3643 | Time 60.6780(60.6515) | Bit/dim 3.6859(3.6881) | Xent 0.0837(0.0834) | Loss 3.7277(3.7298) | Error 0.0268(0.0276) Steps 682(676.15) | Grad Norm 1.1723(1.6654) | Total Time 14.00(14.00)\n",
      "Iter 3644 | Time 60.3739(60.6432) | Bit/dim 3.6906(3.6882) | Xent 0.0739(0.0831) | Loss 3.7275(3.7298) | Error 0.0255(0.0275) Steps 670(675.97) | Grad Norm 1.3609(1.6562) | Total Time 14.00(14.00)\n",
      "Iter 3645 | Time 61.6366(60.6730) | Bit/dim 3.6791(3.6879) | Xent 0.0882(0.0833) | Loss 3.7232(3.7296) | Error 0.0285(0.0275) Steps 676(675.97) | Grad Norm 1.7499(1.6590) | Total Time 14.00(14.00)\n",
      "Iter 3646 | Time 61.7112(60.7041) | Bit/dim 3.6916(3.6881) | Xent 0.0826(0.0832) | Loss 3.7330(3.7297) | Error 0.0275(0.0275) Steps 682(676.15) | Grad Norm 1.4328(1.6523) | Total Time 14.00(14.00)\n",
      "Iter 3647 | Time 62.5150(60.7585) | Bit/dim 3.6868(3.6880) | Xent 0.0798(0.0831) | Loss 3.7267(3.7296) | Error 0.0285(0.0276) Steps 664(675.78) | Grad Norm 1.6549(1.6523) | Total Time 14.00(14.00)\n",
      "Iter 3648 | Time 60.9150(60.7632) | Bit/dim 3.6901(3.6881) | Xent 0.0853(0.0832) | Loss 3.7328(3.7297) | Error 0.0291(0.0276) Steps 682(675.97) | Grad Norm 1.2487(1.6402) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0608 | Time 24.9025, Epoch Time 408.4891(407.2810), Bit/dim 3.7114(best: 3.7113), Xent 2.7119, Loss 5.0673, Error 0.4066(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3649 | Time 62.3070(60.8095) | Bit/dim 3.6841(3.6880) | Xent 0.0787(0.0831) | Loss 3.7234(3.7295) | Error 0.0260(0.0276) Steps 682(676.15) | Grad Norm 1.4640(1.6349) | Total Time 14.00(14.00)\n",
      "Iter 3650 | Time 59.7116(60.7765) | Bit/dim 3.6947(3.6882) | Xent 0.0817(0.0830) | Loss 3.7355(3.7297) | Error 0.0280(0.0276) Steps 676(676.15) | Grad Norm 1.0388(1.6171) | Total Time 14.00(14.00)\n",
      "Iter 3651 | Time 59.9819(60.7527) | Bit/dim 3.6903(3.6882) | Xent 0.0747(0.0828) | Loss 3.7277(3.7296) | Error 0.0264(0.0275) Steps 688(676.50) | Grad Norm 1.6806(1.6190) | Total Time 14.00(14.00)\n",
      "Iter 3652 | Time 59.8053(60.7243) | Bit/dim 3.6857(3.6881) | Xent 0.0847(0.0828) | Loss 3.7280(3.7296) | Error 0.0264(0.0275) Steps 700(677.21) | Grad Norm 1.2741(1.6086) | Total Time 14.00(14.00)\n",
      "Iter 3653 | Time 61.4116(60.7449) | Bit/dim 3.6913(3.6882) | Xent 0.0793(0.0827) | Loss 3.7309(3.7296) | Error 0.0261(0.0275) Steps 670(676.99) | Grad Norm 1.8782(1.6167) | Total Time 14.00(14.00)\n",
      "Iter 3654 | Time 62.9099(60.8098) | Bit/dim 3.6771(3.6879) | Xent 0.0820(0.0827) | Loss 3.7181(3.7293) | Error 0.0269(0.0274) Steps 664(676.60) | Grad Norm 1.0838(1.6007) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0609 | Time 24.6829, Epoch Time 406.9634(407.2715), Bit/dim 3.7110(best: 3.7113), Xent 2.7184, Loss 5.0702, Error 0.4052(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3655 | Time 59.0225(60.7562) | Bit/dim 3.7067(3.6885) | Xent 0.0837(0.0827) | Loss 3.7485(3.7298) | Error 0.0286(0.0275) Steps 670(676.40) | Grad Norm 1.4486(1.5962) | Total Time 14.00(14.00)\n",
      "Iter 3656 | Time 60.8531(60.7591) | Bit/dim 3.6797(3.6882) | Xent 0.0817(0.0827) | Loss 3.7206(3.7296) | Error 0.0266(0.0274) Steps 676(676.39) | Grad Norm 1.2192(1.5848) | Total Time 14.00(14.00)\n",
      "Iter 3657 | Time 60.2343(60.7434) | Bit/dim 3.6802(3.6880) | Xent 0.0843(0.0828) | Loss 3.7224(3.7293) | Error 0.0275(0.0275) Steps 676(676.38) | Grad Norm 1.1647(1.5722) | Total Time 14.00(14.00)\n",
      "Iter 3658 | Time 59.7341(60.7131) | Bit/dim 3.6920(3.6881) | Xent 0.0794(0.0827) | Loss 3.7317(3.7294) | Error 0.0259(0.0274) Steps 670(676.19) | Grad Norm 1.5442(1.5714) | Total Time 14.00(14.00)\n",
      "Iter 3659 | Time 60.3166(60.7012) | Bit/dim 3.6835(3.6880) | Xent 0.0830(0.0827) | Loss 3.7250(3.7293) | Error 0.0260(0.0274) Steps 670(676.00) | Grad Norm 1.6310(1.5732) | Total Time 14.00(14.00)\n",
      "Iter 3660 | Time 57.8662(60.6162) | Bit/dim 3.6891(3.6880) | Xent 0.0801(0.0826) | Loss 3.7291(3.7293) | Error 0.0249(0.0273) Steps 664(675.64) | Grad Norm 1.2668(1.5640) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0610 | Time 25.0706, Epoch Time 398.9692(407.0224), Bit/dim 3.7123(best: 3.7110), Xent 2.6687, Loss 5.0467, Error 0.4019(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3661 | Time 61.8907(60.6544) | Bit/dim 3.6927(3.6881) | Xent 0.0826(0.0826) | Loss 3.7340(3.7294) | Error 0.0272(0.0273) Steps 664(675.29) | Grad Norm 1.0498(1.5486) | Total Time 14.00(14.00)\n",
      "Iter 3662 | Time 58.7134(60.5962) | Bit/dim 3.6965(3.6884) | Xent 0.0848(0.0827) | Loss 3.7389(3.7297) | Error 0.0280(0.0273) Steps 670(675.13) | Grad Norm 1.6108(1.5504) | Total Time 14.00(14.00)\n",
      "Iter 3663 | Time 63.6179(60.6868) | Bit/dim 3.6846(3.6883) | Xent 0.0819(0.0826) | Loss 3.7255(3.7296) | Error 0.0279(0.0273) Steps 682(675.34) | Grad Norm 1.3461(1.5443) | Total Time 14.00(14.00)\n",
      "Iter 3664 | Time 57.5974(60.5941) | Bit/dim 3.6818(3.6881) | Xent 0.0735(0.0824) | Loss 3.7186(3.7293) | Error 0.0236(0.0272) Steps 676(675.36) | Grad Norm 1.2797(1.5364) | Total Time 14.00(14.00)\n",
      "Iter 3665 | Time 60.5987(60.5943) | Bit/dim 3.6935(3.6882) | Xent 0.0893(0.0826) | Loss 3.7382(3.7295) | Error 0.0278(0.0272) Steps 688(675.74) | Grad Norm 1.0918(1.5230) | Total Time 14.00(14.00)\n",
      "Iter 3666 | Time 60.6660(60.5964) | Bit/dim 3.6790(3.6880) | Xent 0.0753(0.0823) | Loss 3.7167(3.7291) | Error 0.0245(0.0271) Steps 682(675.93) | Grad Norm 1.3874(1.5190) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0611 | Time 25.0035, Epoch Time 403.6622(406.9216), Bit/dim 3.7115(best: 3.7110), Xent 2.7195, Loss 5.0713, Error 0.4071(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3667 | Time 61.5974(60.6265) | Bit/dim 3.6933(3.6881) | Xent 0.0853(0.0824) | Loss 3.7360(3.7293) | Error 0.0291(0.0272) Steps 688(676.29) | Grad Norm 1.7131(1.5248) | Total Time 14.00(14.00)\n",
      "Iter 3668 | Time 62.2879(60.6763) | Bit/dim 3.6867(3.6881) | Xent 0.0869(0.0826) | Loss 3.7302(3.7294) | Error 0.0285(0.0272) Steps 676(676.28) | Grad Norm 2.6224(1.5577) | Total Time 14.00(14.00)\n",
      "Iter 3669 | Time 62.3005(60.7250) | Bit/dim 3.6893(3.6881) | Xent 0.0853(0.0827) | Loss 3.7320(3.7294) | Error 0.0281(0.0273) Steps 676(676.27) | Grad Norm 2.2367(1.5781) | Total Time 14.00(14.00)\n",
      "Iter 3670 | Time 60.8272(60.7281) | Bit/dim 3.6812(3.6879) | Xent 0.0814(0.0826) | Loss 3.7219(3.7292) | Error 0.0258(0.0272) Steps 682(676.44) | Grad Norm 1.5037(1.5759) | Total Time 14.00(14.00)\n",
      "Iter 3671 | Time 64.4913(60.8410) | Bit/dim 3.6880(3.6879) | Xent 0.0814(0.0826) | Loss 3.7287(3.7292) | Error 0.0291(0.0273) Steps 670(676.25) | Grad Norm 2.9936(1.6184) | Total Time 14.00(14.00)\n",
      "Iter 3672 | Time 63.2657(60.9137) | Bit/dim 3.6869(3.6879) | Xent 0.0721(0.0823) | Loss 3.7230(3.7290) | Error 0.0238(0.0272) Steps 664(675.88) | Grad Norm 1.2670(1.6078) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0612 | Time 25.2869, Epoch Time 415.6513(407.1835), Bit/dim 3.7121(best: 3.7110), Xent 2.6850, Loss 5.0546, Error 0.4020(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3673 | Time 61.3258(60.9261) | Bit/dim 3.6867(3.6878) | Xent 0.0752(0.0821) | Loss 3.7243(3.7289) | Error 0.0238(0.0271) Steps 676(675.89) | Grad Norm 1.6457(1.6090) | Total Time 14.00(14.00)\n",
      "Iter 3674 | Time 63.2607(60.9961) | Bit/dim 3.6844(3.6877) | Xent 0.0841(0.0821) | Loss 3.7264(3.7288) | Error 0.0291(0.0271) Steps 676(675.89) | Grad Norm 2.2155(1.6272) | Total Time 14.00(14.00)\n",
      "Iter 3675 | Time 61.9648(61.0252) | Bit/dim 3.6870(3.6877) | Xent 0.0828(0.0821) | Loss 3.7284(3.7288) | Error 0.0289(0.0272) Steps 664(675.53) | Grad Norm 1.3789(1.6197) | Total Time 14.00(14.00)\n",
      "Iter 3676 | Time 61.0529(61.0260) | Bit/dim 3.6879(3.6877) | Xent 0.0831(0.0822) | Loss 3.7294(3.7288) | Error 0.0282(0.0272) Steps 670(675.37) | Grad Norm 1.3906(1.6128) | Total Time 14.00(14.00)\n",
      "Iter 3677 | Time 57.7001(60.9262) | Bit/dim 3.6908(3.6878) | Xent 0.0901(0.0824) | Loss 3.7359(3.7290) | Error 0.0291(0.0273) Steps 682(675.57) | Grad Norm 1.7674(1.6175) | Total Time 14.00(14.00)\n",
      "Iter 3678 | Time 61.9737(60.9577) | Bit/dim 3.6874(3.6878) | Xent 0.0789(0.0823) | Loss 3.7268(3.7290) | Error 0.0262(0.0272) Steps 670(675.40) | Grad Norm 1.3783(1.6103) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0613 | Time 25.2614, Epoch Time 408.2641(407.2159), Bit/dim 3.7111(best: 3.7110), Xent 2.7151, Loss 5.0686, Error 0.4109(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3679 | Time 61.8575(60.9847) | Bit/dim 3.6917(3.6879) | Xent 0.0873(0.0824) | Loss 3.7354(3.7291) | Error 0.0270(0.0272) Steps 682(675.60) | Grad Norm 1.4639(1.6059) | Total Time 14.00(14.00)\n",
      "Iter 3680 | Time 61.8017(61.0092) | Bit/dim 3.6874(3.6879) | Xent 0.0775(0.0823) | Loss 3.7262(3.7291) | Error 0.0251(0.0272) Steps 670(675.43) | Grad Norm 1.2139(1.5942) | Total Time 14.00(14.00)\n",
      "Iter 3681 | Time 60.6300(60.9978) | Bit/dim 3.6871(3.6879) | Xent 0.0738(0.0820) | Loss 3.7240(3.7289) | Error 0.0230(0.0271) Steps 682(675.63) | Grad Norm 1.2748(1.5846) | Total Time 14.00(14.00)\n",
      "Iter 3682 | Time 60.0304(60.9688) | Bit/dim 3.6843(3.6878) | Xent 0.0765(0.0819) | Loss 3.7226(3.7287) | Error 0.0254(0.0270) Steps 670(675.46) | Grad Norm 1.1363(1.5711) | Total Time 14.00(14.00)\n",
      "Iter 3683 | Time 59.9603(60.9385) | Bit/dim 3.6828(3.6876) | Xent 0.0743(0.0816) | Loss 3.7199(3.7285) | Error 0.0235(0.0269) Steps 676(675.47) | Grad Norm 0.9553(1.5527) | Total Time 14.00(14.00)\n",
      "Iter 3684 | Time 62.0859(60.9729) | Bit/dim 3.6863(3.6876) | Xent 0.0746(0.0814) | Loss 3.7236(3.7283) | Error 0.0265(0.0269) Steps 676(675.49) | Grad Norm 1.6606(1.5559) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0614 | Time 25.1326, Epoch Time 406.9978(407.2094), Bit/dim 3.7111(best: 3.7110), Xent 2.7537, Loss 5.0879, Error 0.4110(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3685 | Time 60.7033(60.9649) | Bit/dim 3.6781(3.6873) | Xent 0.0774(0.0813) | Loss 3.7168(3.7280) | Error 0.0256(0.0268) Steps 670(675.33) | Grad Norm 1.1938(1.5450) | Total Time 14.00(14.00)\n",
      "Iter 3686 | Time 61.7678(60.9889) | Bit/dim 3.6927(3.6875) | Xent 0.0787(0.0812) | Loss 3.7320(3.7281) | Error 0.0266(0.0268) Steps 676(675.35) | Grad Norm 1.4112(1.5410) | Total Time 14.00(14.00)\n",
      "Iter 3687 | Time 60.3415(60.9695) | Bit/dim 3.6894(3.6875) | Xent 0.0810(0.0812) | Loss 3.7300(3.7281) | Error 0.0246(0.0268) Steps 676(675.36) | Grad Norm 2.3330(1.5648) | Total Time 14.00(14.00)\n",
      "Iter 3688 | Time 60.8664(60.9664) | Bit/dim 3.6906(3.6876) | Xent 0.0817(0.0812) | Loss 3.7314(3.7282) | Error 0.0261(0.0268) Steps 676(675.38) | Grad Norm 1.0920(1.5506) | Total Time 14.00(14.00)\n",
      "Iter 3689 | Time 61.9097(60.9947) | Bit/dim 3.6926(3.6878) | Xent 0.0757(0.0811) | Loss 3.7304(3.7283) | Error 0.0258(0.0267) Steps 676(675.40) | Grad Norm 2.3736(1.5753) | Total Time 14.00(14.00)\n",
      "Iter 3690 | Time 60.0852(60.9674) | Bit/dim 3.6810(3.6876) | Xent 0.0831(0.0811) | Loss 3.7226(3.7281) | Error 0.0279(0.0268) Steps 670(675.24) | Grad Norm 2.3619(1.5989) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0615 | Time 25.1412, Epoch Time 406.5002(407.1881), Bit/dim 3.7108(best: 3.7110), Xent 2.7289, Loss 5.0753, Error 0.4071(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3691 | Time 59.3182(60.9180) | Bit/dim 3.6893(3.6876) | Xent 0.0763(0.0810) | Loss 3.7275(3.7281) | Error 0.0270(0.0268) Steps 670(675.08) | Grad Norm 1.1594(1.5857) | Total Time 14.00(14.00)\n",
      "Iter 3692 | Time 59.7676(60.8834) | Bit/dim 3.6883(3.6876) | Xent 0.0795(0.0809) | Loss 3.7280(3.7281) | Error 0.0268(0.0268) Steps 676(675.11) | Grad Norm 1.7395(1.5903) | Total Time 14.00(14.00)\n",
      "Iter 3693 | Time 58.8737(60.8232) | Bit/dim 3.6946(3.6878) | Xent 0.0819(0.0810) | Loss 3.7356(3.7283) | Error 0.0278(0.0268) Steps 676(675.14) | Grad Norm 3.0643(1.6345) | Total Time 14.00(14.00)\n",
      "Iter 3694 | Time 63.0726(60.8906) | Bit/dim 3.6831(3.6877) | Xent 0.0756(0.0808) | Loss 3.7209(3.7281) | Error 0.0254(0.0268) Steps 676(675.16) | Grad Norm 1.3847(1.6270) | Total Time 14.00(14.00)\n",
      "Iter 3695 | Time 60.0467(60.8653) | Bit/dim 3.6880(3.6877) | Xent 0.0768(0.0807) | Loss 3.7264(3.7281) | Error 0.0266(0.0267) Steps 670(675.01) | Grad Norm 1.5723(1.6254) | Total Time 14.00(14.00)\n",
      "Iter 3696 | Time 63.8480(60.9548) | Bit/dim 3.6809(3.6875) | Xent 0.0845(0.0808) | Loss 3.7232(3.7279) | Error 0.0261(0.0267) Steps 682(675.22) | Grad Norm 2.7504(1.6591) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0616 | Time 25.0360, Epoch Time 405.7384(407.1446), Bit/dim 3.7104(best: 3.7108), Xent 2.7216, Loss 5.0712, Error 0.4045(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3697 | Time 59.6635(60.9161) | Bit/dim 3.6803(3.6873) | Xent 0.0816(0.0808) | Loss 3.7211(3.7277) | Error 0.0292(0.0268) Steps 676(675.24) | Grad Norm 1.2684(1.6474) | Total Time 14.00(14.00)\n",
      "Iter 3698 | Time 60.7870(60.9122) | Bit/dim 3.6956(3.6875) | Xent 0.0680(0.0804) | Loss 3.7296(3.7278) | Error 0.0209(0.0266) Steps 682(675.44) | Grad Norm 1.2003(1.6340) | Total Time 14.00(14.00)\n",
      "Iter 3699 | Time 60.2137(60.8912) | Bit/dim 3.6847(3.6875) | Xent 0.0764(0.0803) | Loss 3.7229(3.7276) | Error 0.0245(0.0266) Steps 676(675.46) | Grad Norm 2.0637(1.6469) | Total Time 14.00(14.00)\n",
      "Iter 3700 | Time 60.2698(60.8726) | Bit/dim 3.6966(3.6877) | Xent 0.0810(0.0803) | Loss 3.7371(3.7279) | Error 0.0262(0.0266) Steps 670(675.30) | Grad Norm 2.2999(1.6665) | Total Time 14.00(14.00)\n",
      "Iter 3701 | Time 59.1938(60.8222) | Bit/dim 3.6795(3.6875) | Xent 0.0742(0.0802) | Loss 3.7166(3.7276) | Error 0.0238(0.0265) Steps 676(675.32) | Grad Norm 0.8236(1.6412) | Total Time 14.00(14.00)\n",
      "Iter 3702 | Time 61.4773(60.8419) | Bit/dim 3.6867(3.6875) | Xent 0.0834(0.0803) | Loss 3.7284(3.7276) | Error 0.0270(0.0265) Steps 670(675.16) | Grad Norm 2.5697(1.6691) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0617 | Time 24.6557, Epoch Time 401.9535(406.9889), Bit/dim 3.7108(best: 3.7104), Xent 2.7390, Loss 5.0803, Error 0.4055(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3703 | Time 59.3110(60.7960) | Bit/dim 3.6843(3.6874) | Xent 0.0812(0.0803) | Loss 3.7249(3.7275) | Error 0.0276(0.0265) Steps 688(675.54) | Grad Norm 1.7147(1.6704) | Total Time 14.00(14.00)\n",
      "Iter 3704 | Time 62.1960(60.8380) | Bit/dim 3.6908(3.6875) | Xent 0.0729(0.0801) | Loss 3.7272(3.7275) | Error 0.0239(0.0264) Steps 670(675.38) | Grad Norm 1.3715(1.6615) | Total Time 14.00(14.00)\n",
      "Iter 3705 | Time 60.3845(60.8244) | Bit/dim 3.6953(3.6877) | Xent 0.0755(0.0799) | Loss 3.7330(3.7277) | Error 0.0238(0.0264) Steps 676(675.40) | Grad Norm 1.3527(1.6522) | Total Time 14.00(14.00)\n",
      "Iter 3706 | Time 61.1028(60.8327) | Bit/dim 3.6918(3.6878) | Xent 0.0754(0.0798) | Loss 3.7295(3.7277) | Error 0.0245(0.0263) Steps 682(675.59) | Grad Norm 1.9042(1.6598) | Total Time 14.00(14.00)\n",
      "Iter 3707 | Time 63.3561(60.9084) | Bit/dim 3.6800(3.6876) | Xent 0.0792(0.0798) | Loss 3.7196(3.7275) | Error 0.0266(0.0263) Steps 676(675.61) | Grad Norm 2.2076(1.6762) | Total Time 14.00(14.00)\n",
      "Iter 3708 | Time 59.3335(60.8612) | Bit/dim 3.6819(3.6874) | Xent 0.0796(0.0798) | Loss 3.7217(3.7273) | Error 0.0270(0.0263) Steps 688(675.98) | Grad Norm 1.3981(1.6678) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0618 | Time 25.0678, Epoch Time 406.3474(406.9696), Bit/dim 3.7113(best: 3.7104), Xent 2.7756, Loss 5.0991, Error 0.4108(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3709 | Time 58.1781(60.7807) | Bit/dim 3.6777(3.6871) | Xent 0.0773(0.0797) | Loss 3.7164(3.7270) | Error 0.0244(0.0263) Steps 676(675.98) | Grad Norm 1.5145(1.6632) | Total Time 14.00(14.00)\n",
      "Iter 3710 | Time 59.3452(60.7376) | Bit/dim 3.6846(3.6871) | Xent 0.0878(0.0799) | Loss 3.7285(3.7270) | Error 0.0309(0.0264) Steps 670(675.80) | Grad Norm 2.8066(1.6975) | Total Time 14.00(14.00)\n",
      "Iter 3711 | Time 61.2446(60.7528) | Bit/dim 3.6917(3.6872) | Xent 0.0764(0.0798) | Loss 3.7299(3.7271) | Error 0.0252(0.0264) Steps 664(675.45) | Grad Norm 1.1179(1.6802) | Total Time 14.00(14.00)\n",
      "Iter 3712 | Time 59.8930(60.7270) | Bit/dim 3.6885(3.6872) | Xent 0.0790(0.0798) | Loss 3.7280(3.7271) | Error 0.0266(0.0264) Steps 676(675.46) | Grad Norm 1.3061(1.6689) | Total Time 14.00(14.00)\n",
      "Iter 3713 | Time 63.0587(60.7970) | Bit/dim 3.6812(3.6870) | Xent 0.0792(0.0798) | Loss 3.7208(3.7269) | Error 0.0245(0.0263) Steps 676(675.48) | Grad Norm 1.9170(1.6764) | Total Time 14.00(14.00)\n",
      "Iter 3714 | Time 62.2587(60.8408) | Bit/dim 3.6954(3.6873) | Xent 0.0779(0.0797) | Loss 3.7343(3.7272) | Error 0.0261(0.0263) Steps 682(675.67) | Grad Norm 2.5415(1.7023) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0619 | Time 24.9820, Epoch Time 404.9980(406.9105), Bit/dim 3.7100(best: 3.7104), Xent 2.6972, Loss 5.0586, Error 0.4079(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3715 | Time 61.2212(60.8522) | Bit/dim 3.6806(3.6871) | Xent 0.0803(0.0798) | Loss 3.7207(3.7270) | Error 0.0260(0.0263) Steps 676(675.68) | Grad Norm 1.4667(1.6953) | Total Time 14.00(14.00)\n",
      "Iter 3716 | Time 59.3630(60.8076) | Bit/dim 3.6925(3.6873) | Xent 0.0738(0.0796) | Loss 3.7294(3.7270) | Error 0.0226(0.0262) Steps 682(675.87) | Grad Norm 1.9231(1.7021) | Total Time 14.00(14.00)\n",
      "Iter 3717 | Time 59.4985(60.7683) | Bit/dim 3.6866(3.6872) | Xent 0.0810(0.0796) | Loss 3.7272(3.7271) | Error 0.0255(0.0262) Steps 670(675.70) | Grad Norm 2.0596(1.7128) | Total Time 14.00(14.00)\n",
      "Iter 3718 | Time 62.1859(60.8108) | Bit/dim 3.6889(3.6873) | Xent 0.0776(0.0796) | Loss 3.7276(3.7271) | Error 0.0246(0.0261) Steps 670(675.53) | Grad Norm 1.0948(1.6943) | Total Time 14.00(14.00)\n",
      "Iter 3719 | Time 60.1365(60.7906) | Bit/dim 3.6854(3.6872) | Xent 0.0736(0.0794) | Loss 3.7222(3.7269) | Error 0.0236(0.0261) Steps 682(675.72) | Grad Norm 1.3832(1.6849) | Total Time 14.00(14.00)\n",
      "Iter 3720 | Time 60.4595(60.7807) | Bit/dim 3.6829(3.6871) | Xent 0.0781(0.0793) | Loss 3.7220(3.7268) | Error 0.0262(0.0261) Steps 670(675.55) | Grad Norm 1.7433(1.6867) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0620 | Time 25.2558, Epoch Time 403.9342(406.8212), Bit/dim 3.7104(best: 3.7100), Xent 2.7077, Loss 5.0643, Error 0.4082(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3721 | Time 59.3179(60.7368) | Bit/dim 3.6851(3.6870) | Xent 0.0731(0.0792) | Loss 3.7217(3.7266) | Error 0.0236(0.0260) Steps 676(675.56) | Grad Norm 1.7121(1.6875) | Total Time 14.00(14.00)\n",
      "Iter 3722 | Time 61.7899(60.7684) | Bit/dim 3.6882(3.6871) | Xent 0.0796(0.0792) | Loss 3.7280(3.7267) | Error 0.0230(0.0259) Steps 670(675.40) | Grad Norm 1.2387(1.6740) | Total Time 14.00(14.00)\n",
      "Iter 3723 | Time 61.9036(60.8024) | Bit/dim 3.6793(3.6868) | Xent 0.0819(0.0792) | Loss 3.7202(3.7265) | Error 0.0259(0.0259) Steps 658(674.87) | Grad Norm 2.2666(1.6918) | Total Time 14.00(14.00)\n",
      "Iter 3724 | Time 58.4290(60.7312) | Bit/dim 3.6852(3.6868) | Xent 0.0719(0.0790) | Loss 3.7211(3.7263) | Error 0.0226(0.0258) Steps 676(674.91) | Grad Norm 1.3430(1.6813) | Total Time 14.00(14.00)\n",
      "Iter 3725 | Time 58.7795(60.6727) | Bit/dim 3.6833(3.6867) | Xent 0.0887(0.0793) | Loss 3.7277(3.7264) | Error 0.0299(0.0259) Steps 670(674.76) | Grad Norm 3.3426(1.7311) | Total Time 14.00(14.00)\n",
      "Iter 3726 | Time 60.7571(60.6752) | Bit/dim 3.6931(3.6869) | Xent 0.0787(0.0793) | Loss 3.7325(3.7265) | Error 0.0264(0.0259) Steps 664(674.44) | Grad Norm 1.5835(1.7267) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0621 | Time 25.4538, Epoch Time 402.5330(406.6926), Bit/dim 3.7106(best: 3.7100), Xent 2.7299, Loss 5.0755, Error 0.4060(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3727 | Time 59.7108(60.6463) | Bit/dim 3.6843(3.6868) | Xent 0.0773(0.0792) | Loss 3.7229(3.7264) | Error 0.0250(0.0259) Steps 676(674.48) | Grad Norm 1.5235(1.7206) | Total Time 14.00(14.00)\n",
      "Iter 3728 | Time 60.8883(60.6535) | Bit/dim 3.6846(3.6867) | Xent 0.0844(0.0794) | Loss 3.7268(3.7264) | Error 0.0281(0.0260) Steps 676(674.53) | Grad Norm 2.0701(1.7311) | Total Time 14.00(14.00)\n",
      "Iter 3729 | Time 62.6177(60.7125) | Bit/dim 3.6840(3.6867) | Xent 0.0784(0.0794) | Loss 3.7232(3.7263) | Error 0.0245(0.0259) Steps 682(674.75) | Grad Norm 1.9184(1.7367) | Total Time 14.00(14.00)\n",
      "Iter 3730 | Time 60.9974(60.7210) | Bit/dim 3.6850(3.6866) | Xent 0.0696(0.0791) | Loss 3.7198(3.7261) | Error 0.0234(0.0259) Steps 670(674.61) | Grad Norm 1.5481(1.7311) | Total Time 14.00(14.00)\n",
      "Iter 3731 | Time 61.3057(60.7385) | Bit/dim 3.6858(3.6866) | Xent 0.0780(0.0790) | Loss 3.7248(3.7261) | Error 0.0258(0.0259) Steps 676(674.65) | Grad Norm 1.5895(1.7268) | Total Time 14.00(14.00)\n",
      "Iter 3732 | Time 62.0823(60.7789) | Bit/dim 3.6961(3.6869) | Xent 0.0811(0.0791) | Loss 3.7366(3.7264) | Error 0.0280(0.0259) Steps 664(674.33) | Grad Norm 1.5667(1.7220) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0622 | Time 24.8032, Epoch Time 408.1081(406.7350), Bit/dim 3.7116(best: 3.7100), Xent 2.7964, Loss 5.1098, Error 0.4097(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3733 | Time 61.6103(60.8038) | Bit/dim 3.6775(3.6866) | Xent 0.0862(0.0793) | Loss 3.7206(3.7262) | Error 0.0272(0.0260) Steps 682(674.56) | Grad Norm 1.4834(1.7149) | Total Time 14.00(14.00)\n",
      "Iter 3734 | Time 60.1774(60.7850) | Bit/dim 3.6921(3.6868) | Xent 0.0790(0.0793) | Loss 3.7316(3.7264) | Error 0.0269(0.0260) Steps 682(674.79) | Grad Norm 1.3680(1.7045) | Total Time 14.00(14.00)\n",
      "Iter 3735 | Time 59.3392(60.7416) | Bit/dim 3.6853(3.6867) | Xent 0.0768(0.0792) | Loss 3.7237(3.7263) | Error 0.0241(0.0259) Steps 694(675.36) | Grad Norm 1.2174(1.6898) | Total Time 14.00(14.00)\n",
      "Iter 3736 | Time 61.1924(60.7552) | Bit/dim 3.6883(3.6868) | Xent 0.0812(0.0793) | Loss 3.7289(3.7264) | Error 0.0286(0.0260) Steps 682(675.56) | Grad Norm 1.2810(1.6776) | Total Time 14.00(14.00)\n",
      "Iter 3737 | Time 59.3126(60.7119) | Bit/dim 3.6809(3.6866) | Xent 0.0734(0.0791) | Loss 3.7177(3.7261) | Error 0.0234(0.0259) Steps 676(675.58) | Grad Norm 1.7480(1.6797) | Total Time 14.00(14.00)\n",
      "Iter 3738 | Time 60.8266(60.7153) | Bit/dim 3.6964(3.6869) | Xent 0.0721(0.0789) | Loss 3.7324(3.7263) | Error 0.0229(0.0258) Steps 670(675.41) | Grad Norm 1.7704(1.6824) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0623 | Time 25.3051, Epoch Time 403.5181(406.6385), Bit/dim 3.7117(best: 3.7100), Xent 2.7600, Loss 5.0917, Error 0.4056(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3739 | Time 62.4719(60.7680) | Bit/dim 3.6890(3.6869) | Xent 0.0766(0.0788) | Loss 3.7273(3.7264) | Error 0.0258(0.0258) Steps 670(675.25) | Grad Norm 1.6295(1.6808) | Total Time 14.00(14.00)\n",
      "Iter 3740 | Time 59.0351(60.7160) | Bit/dim 3.6859(3.6869) | Xent 0.0783(0.0788) | Loss 3.7251(3.7263) | Error 0.0262(0.0258) Steps 682(675.45) | Grad Norm 1.4596(1.6742) | Total Time 14.00(14.00)\n",
      "Iter 3741 | Time 61.4630(60.7384) | Bit/dim 3.6876(3.6869) | Xent 0.0768(0.0788) | Loss 3.7260(3.7263) | Error 0.0246(0.0258) Steps 676(675.46) | Grad Norm 1.3221(1.6636) | Total Time 14.00(14.00)\n",
      "Iter 3742 | Time 58.7076(60.6775) | Bit/dim 3.6830(3.6868) | Xent 0.0748(0.0786) | Loss 3.7205(3.7261) | Error 0.0254(0.0258) Steps 682(675.66) | Grad Norm 1.6126(1.6621) | Total Time 14.00(14.00)\n",
      "Iter 3743 | Time 61.5307(60.7031) | Bit/dim 3.6880(3.6869) | Xent 0.0768(0.0786) | Loss 3.7264(3.7261) | Error 0.0255(0.0258) Steps 688(676.03) | Grad Norm 1.2638(1.6501) | Total Time 14.00(14.00)\n",
      "Iter 3744 | Time 62.6087(60.7603) | Bit/dim 3.6899(3.6869) | Xent 0.0719(0.0784) | Loss 3.7259(3.7261) | Error 0.0240(0.0257) Steps 670(675.85) | Grad Norm 1.4301(1.6435) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0624 | Time 25.1106, Epoch Time 406.8168(406.6439), Bit/dim 3.7098(best: 3.7100), Xent 2.7530, Loss 5.0863, Error 0.4065(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3745 | Time 61.9469(60.7959) | Bit/dim 3.6939(3.6872) | Xent 0.0779(0.0784) | Loss 3.7329(3.7263) | Error 0.0252(0.0257) Steps 670(675.67) | Grad Norm 1.3799(1.6356) | Total Time 14.00(14.00)\n",
      "Iter 3746 | Time 58.1780(60.7173) | Bit/dim 3.6757(3.6868) | Xent 0.0794(0.0784) | Loss 3.7154(3.7260) | Error 0.0251(0.0257) Steps 676(675.68) | Grad Norm 1.3197(1.6262) | Total Time 14.00(14.00)\n",
      "Iter 3747 | Time 61.6938(60.7466) | Bit/dim 3.6925(3.6870) | Xent 0.0802(0.0785) | Loss 3.7326(3.7262) | Error 0.0256(0.0257) Steps 682(675.87) | Grad Norm 1.4813(1.6218) | Total Time 14.00(14.00)\n",
      "Iter 3748 | Time 62.3047(60.7934) | Bit/dim 3.6966(3.6873) | Xent 0.0766(0.0784) | Loss 3.7349(3.7265) | Error 0.0256(0.0257) Steps 676(675.88) | Grad Norm 1.6245(1.6219) | Total Time 14.00(14.00)\n",
      "Iter 3749 | Time 59.6370(60.7587) | Bit/dim 3.6869(3.6873) | Xent 0.0759(0.0783) | Loss 3.7249(3.7264) | Error 0.0272(0.0257) Steps 676(675.88) | Grad Norm 2.0735(1.6354) | Total Time 14.00(14.00)\n",
      "Iter 3750 | Time 63.1149(60.8294) | Bit/dim 3.6767(3.6869) | Xent 0.0749(0.0782) | Loss 3.7142(3.7261) | Error 0.0241(0.0257) Steps 676(675.88) | Grad Norm 1.3361(1.6265) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0625 | Time 24.6683, Epoch Time 407.3065(406.6637), Bit/dim 3.7103(best: 3.7098), Xent 2.7317, Loss 5.0762, Error 0.4051(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3751 | Time 61.1600(60.8393) | Bit/dim 3.6900(3.6870) | Xent 0.0700(0.0780) | Loss 3.7250(3.7260) | Error 0.0222(0.0256) Steps 676(675.89) | Grad Norm 1.5113(1.6230) | Total Time 14.00(14.00)\n",
      "Iter 3752 | Time 61.7010(60.8651) | Bit/dim 3.6816(3.6869) | Xent 0.0777(0.0780) | Loss 3.7205(3.7259) | Error 0.0264(0.0256) Steps 676(675.89) | Grad Norm 1.4152(1.6168) | Total Time 14.00(14.00)\n",
      "Iter 3753 | Time 61.3232(60.8789) | Bit/dim 3.6858(3.6868) | Xent 0.0733(0.0778) | Loss 3.7225(3.7258) | Error 0.0241(0.0256) Steps 664(675.53) | Grad Norm 1.2355(1.6053) | Total Time 14.00(14.00)\n",
      "Iter 3754 | Time 59.0956(60.8254) | Bit/dim 3.6864(3.6868) | Xent 0.0837(0.0780) | Loss 3.7282(3.7258) | Error 0.0284(0.0257) Steps 658(675.01) | Grad Norm 2.0290(1.6180) | Total Time 14.00(14.00)\n",
      "Iter 3755 | Time 58.3125(60.7500) | Bit/dim 3.6801(3.6866) | Xent 0.0791(0.0780) | Loss 3.7196(3.7256) | Error 0.0278(0.0257) Steps 670(674.86) | Grad Norm 1.9208(1.6271) | Total Time 14.00(14.00)\n",
      "Iter 3756 | Time 63.4380(60.8306) | Bit/dim 3.6933(3.6868) | Xent 0.0706(0.0778) | Loss 3.7286(3.7257) | Error 0.0245(0.0257) Steps 682(675.07) | Grad Norm 1.9494(1.6368) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0626 | Time 24.9217, Epoch Time 406.1065(406.6470), Bit/dim 3.7095(best: 3.7098), Xent 2.7058, Loss 5.0624, Error 0.4062(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3757 | Time 59.0572(60.7774) | Bit/dim 3.7011(3.6873) | Xent 0.0810(0.0779) | Loss 3.7416(3.7262) | Error 0.0266(0.0257) Steps 670(674.92) | Grad Norm 2.1741(1.6529) | Total Time 14.00(14.00)\n",
      "Iter 3758 | Time 60.3979(60.7661) | Bit/dim 3.6871(3.6873) | Xent 0.0769(0.0779) | Loss 3.7256(3.7262) | Error 0.0242(0.0257) Steps 670(674.77) | Grad Norm 1.2913(1.6421) | Total Time 14.00(14.00)\n",
      "Iter 3759 | Time 59.4832(60.7276) | Bit/dim 3.6846(3.6872) | Xent 0.0767(0.0778) | Loss 3.7230(3.7261) | Error 0.0254(0.0257) Steps 682(674.99) | Grad Norm 1.2795(1.6312) | Total Time 14.00(14.00)\n",
      "Iter 3760 | Time 60.2192(60.7123) | Bit/dim 3.6790(3.6869) | Xent 0.0661(0.0775) | Loss 3.7120(3.7257) | Error 0.0231(0.0256) Steps 676(675.02) | Grad Norm 1.7151(1.6337) | Total Time 14.00(14.00)\n",
      "Iter 3761 | Time 59.7400(60.6831) | Bit/dim 3.6811(3.6868) | Xent 0.0842(0.0777) | Loss 3.7233(3.7256) | Error 0.0285(0.0257) Steps 664(674.69) | Grad Norm 1.6578(1.6344) | Total Time 14.00(14.00)\n",
      "Iter 3762 | Time 63.2447(60.7600) | Bit/dim 3.6873(3.6868) | Xent 0.0784(0.0777) | Loss 3.7265(3.7256) | Error 0.0261(0.0257) Steps 688(675.09) | Grad Norm 1.8652(1.6414) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0627 | Time 25.1060, Epoch Time 403.5689(406.5547), Bit/dim 3.7102(best: 3.7095), Xent 2.7809, Loss 5.1007, Error 0.4101(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3763 | Time 62.0047(60.7973) | Bit/dim 3.6885(3.6868) | Xent 0.0777(0.0777) | Loss 3.7274(3.7257) | Error 0.0244(0.0256) Steps 664(674.76) | Grad Norm 1.5626(1.6390) | Total Time 14.00(14.00)\n",
      "Iter 3764 | Time 60.0874(60.7760) | Bit/dim 3.6960(3.6871) | Xent 0.0801(0.0778) | Loss 3.7361(3.7260) | Error 0.0269(0.0257) Steps 676(674.79) | Grad Norm 1.5697(1.6369) | Total Time 14.00(14.00)\n",
      "Iter 3765 | Time 61.6544(60.8024) | Bit/dim 3.6895(3.6872) | Xent 0.0775(0.0778) | Loss 3.7283(3.7261) | Error 0.0256(0.0257) Steps 670(674.65) | Grad Norm 1.9224(1.6455) | Total Time 14.00(14.00)\n",
      "Iter 3766 | Time 63.6833(60.8888) | Bit/dim 3.6775(3.6869) | Xent 0.0795(0.0778) | Loss 3.7173(3.7258) | Error 0.0241(0.0256) Steps 682(674.87) | Grad Norm 1.1560(1.6308) | Total Time 14.00(14.00)\n",
      "Iter 3767 | Time 57.8147(60.7966) | Bit/dim 3.6776(3.6866) | Xent 0.0747(0.0777) | Loss 3.7150(3.7255) | Error 0.0264(0.0257) Steps 670(674.72) | Grad Norm 1.4208(1.6245) | Total Time 14.00(14.00)\n",
      "Iter 3768 | Time 61.2664(60.8107) | Bit/dim 3.6877(3.6866) | Xent 0.0785(0.0778) | Loss 3.7269(3.7255) | Error 0.0259(0.0257) Steps 676(674.76) | Grad Norm 1.3799(1.6172) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0628 | Time 24.7714, Epoch Time 406.7815(406.5615), Bit/dim 3.7106(best: 3.7095), Xent 2.7168, Loss 5.0691, Error 0.4037(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3769 | Time 63.0009(60.8764) | Bit/dim 3.6975(3.6870) | Xent 0.0786(0.0778) | Loss 3.7369(3.7259) | Error 0.0265(0.0257) Steps 688(675.16) | Grad Norm 1.1498(1.6031) | Total Time 14.00(14.00)\n",
      "Iter 3770 | Time 62.8843(60.9366) | Bit/dim 3.6830(3.6868) | Xent 0.0712(0.0776) | Loss 3.7186(3.7256) | Error 0.0230(0.0256) Steps 688(675.54) | Grad Norm 1.5767(1.6023) | Total Time 14.00(14.00)\n",
      "Iter 3771 | Time 60.0725(60.9107) | Bit/dim 3.6861(3.6868) | Xent 0.0841(0.0778) | Loss 3.7282(3.7257) | Error 0.0276(0.0257) Steps 682(675.74) | Grad Norm 2.4573(1.6280) | Total Time 14.00(14.00)\n",
      "Iter 3772 | Time 61.1470(60.9178) | Bit/dim 3.6744(3.6864) | Xent 0.0792(0.0778) | Loss 3.7140(3.7254) | Error 0.0249(0.0256) Steps 682(675.93) | Grad Norm 2.5990(1.6571) | Total Time 14.00(14.00)\n",
      "Iter 3773 | Time 60.6479(60.9097) | Bit/dim 3.6920(3.6866) | Xent 0.0766(0.0778) | Loss 3.7303(3.7255) | Error 0.0259(0.0257) Steps 676(675.93) | Grad Norm 1.7339(1.6594) | Total Time 14.00(14.00)\n",
      "Iter 3774 | Time 60.4626(60.8963) | Bit/dim 3.6857(3.6866) | Xent 0.0785(0.0778) | Loss 3.7250(3.7255) | Error 0.0256(0.0256) Steps 670(675.75) | Grad Norm 1.9658(1.6686) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0629 | Time 24.9504, Epoch Time 408.5026(406.6197), Bit/dim 3.7112(best: 3.7095), Xent 2.7967, Loss 5.1096, Error 0.4083(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3775 | Time 61.2471(60.9068) | Bit/dim 3.6882(3.6866) | Xent 0.0750(0.0777) | Loss 3.7257(3.7255) | Error 0.0244(0.0256) Steps 670(675.58) | Grad Norm 1.5816(1.6660) | Total Time 14.00(14.00)\n",
      "Iter 3776 | Time 59.5262(60.8654) | Bit/dim 3.6812(3.6865) | Xent 0.0771(0.0777) | Loss 3.7198(3.7253) | Error 0.0249(0.0256) Steps 670(675.41) | Grad Norm 1.3237(1.6557) | Total Time 14.00(14.00)\n",
      "Iter 3777 | Time 60.8366(60.8645) | Bit/dim 3.6835(3.6864) | Xent 0.0815(0.0778) | Loss 3.7242(3.7253) | Error 0.0255(0.0256) Steps 682(675.61) | Grad Norm 1.0947(1.6389) | Total Time 14.00(14.00)\n",
      "Iter 3778 | Time 59.1226(60.8123) | Bit/dim 3.6909(3.6865) | Xent 0.0785(0.0778) | Loss 3.7302(3.7254) | Error 0.0260(0.0256) Steps 676(675.62) | Grad Norm 1.3465(1.6301) | Total Time 14.00(14.00)\n",
      "Iter 3779 | Time 62.2846(60.8564) | Bit/dim 3.6942(3.6867) | Xent 0.0792(0.0779) | Loss 3.7338(3.7257) | Error 0.0262(0.0256) Steps 682(675.81) | Grad Norm 1.5710(1.6284) | Total Time 14.00(14.00)\n",
      "Iter 3780 | Time 60.0275(60.8316) | Bit/dim 3.6836(3.6867) | Xent 0.0802(0.0780) | Loss 3.7236(3.7256) | Error 0.0275(0.0257) Steps 688(676.18) | Grad Norm 1.2826(1.6180) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0630 | Time 25.3056, Epoch Time 404.1211(406.5448), Bit/dim 3.7093(best: 3.7095), Xent 2.7392, Loss 5.0789, Error 0.4084(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3781 | Time 57.7888(60.7403) | Bit/dim 3.6845(3.6866) | Xent 0.0793(0.0780) | Loss 3.7242(3.7256) | Error 0.0255(0.0257) Steps 676(676.17) | Grad Norm 1.7417(1.6217) | Total Time 14.00(14.00)\n",
      "Iter 3782 | Time 60.3016(60.7271) | Bit/dim 3.6897(3.6867) | Xent 0.0826(0.0781) | Loss 3.7310(3.7258) | Error 0.0276(0.0257) Steps 676(676.17) | Grad Norm 1.2558(1.6107) | Total Time 14.00(14.00)\n",
      "Iter 3783 | Time 60.8958(60.7322) | Bit/dim 3.6864(3.6867) | Xent 0.0821(0.0783) | Loss 3.7275(3.7258) | Error 0.0275(0.0258) Steps 676(676.16) | Grad Norm 1.7703(1.6155) | Total Time 14.00(14.00)\n",
      "Iter 3784 | Time 61.7501(60.7627) | Bit/dim 3.6816(3.6865) | Xent 0.0824(0.0784) | Loss 3.7229(3.7257) | Error 0.0288(0.0259) Steps 682(676.34) | Grad Norm 2.1290(1.6309) | Total Time 14.00(14.00)\n",
      "Iter 3785 | Time 61.0555(60.7715) | Bit/dim 3.6894(3.6866) | Xent 0.0753(0.0783) | Loss 3.7270(3.7258) | Error 0.0239(0.0258) Steps 682(676.51) | Grad Norm 1.6172(1.6305) | Total Time 14.00(14.00)\n",
      "Iter 3786 | Time 59.6760(60.7386) | Bit/dim 3.6837(3.6865) | Xent 0.0814(0.0784) | Loss 3.7244(3.7257) | Error 0.0282(0.0259) Steps 676(676.49) | Grad Norm 1.3469(1.6220) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0631 | Time 25.3076, Epoch Time 402.1220(406.4121), Bit/dim 3.7108(best: 3.7093), Xent 2.7048, Loss 5.0632, Error 0.4048(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3787 | Time 60.9342(60.7445) | Bit/dim 3.6903(3.6866) | Xent 0.0736(0.0782) | Loss 3.7271(3.7258) | Error 0.0238(0.0258) Steps 676(676.48) | Grad Norm 2.1515(1.6379) | Total Time 14.00(14.00)\n",
      "Iter 3788 | Time 60.6702(60.7423) | Bit/dim 3.6830(3.6865) | Xent 0.0793(0.0783) | Loss 3.7226(3.7257) | Error 0.0271(0.0259) Steps 676(676.46) | Grad Norm 2.0673(1.6508) | Total Time 14.00(14.00)\n",
      "Iter 3789 | Time 61.0623(60.7519) | Bit/dim 3.6699(3.6860) | Xent 0.0821(0.0784) | Loss 3.7109(3.7252) | Error 0.0275(0.0259) Steps 664(676.09) | Grad Norm 1.7015(1.6523) | Total Time 14.00(14.00)\n",
      "Iter 3790 | Time 61.0533(60.7609) | Bit/dim 3.6914(3.6862) | Xent 0.0820(0.0785) | Loss 3.7324(3.7254) | Error 0.0271(0.0259) Steps 688(676.45) | Grad Norm 2.5490(1.6792) | Total Time 14.00(14.00)\n",
      "Iter 3791 | Time 60.8232(60.7628) | Bit/dim 3.6866(3.6862) | Xent 0.0805(0.0786) | Loss 3.7269(3.7255) | Error 0.0286(0.0260) Steps 676(676.43) | Grad Norm 2.8266(1.7136) | Total Time 14.00(14.00)\n",
      "Iter 3792 | Time 61.9123(60.7973) | Bit/dim 3.6914(3.6864) | Xent 0.0800(0.0786) | Loss 3.7314(3.7257) | Error 0.0268(0.0260) Steps 670(676.24) | Grad Norm 2.5567(1.7389) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0632 | Time 24.9291, Epoch Time 406.9527(406.4283), Bit/dim 3.7103(best: 3.7093), Xent 2.7628, Loss 5.0917, Error 0.4071(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3793 | Time 59.1638(60.7483) | Bit/dim 3.6864(3.6864) | Xent 0.0794(0.0786) | Loss 3.7261(3.7257) | Error 0.0260(0.0260) Steps 682(676.41) | Grad Norm 2.6900(1.7674) | Total Time 14.00(14.00)\n",
      "Iter 3794 | Time 61.2851(60.7644) | Bit/dim 3.6862(3.6864) | Xent 0.0770(0.0786) | Loss 3.7247(3.7256) | Error 0.0258(0.0260) Steps 676(676.40) | Grad Norm 1.1966(1.7503) | Total Time 14.00(14.00)\n",
      "Iter 3795 | Time 59.3513(60.7220) | Bit/dim 3.6951(3.6866) | Xent 0.0849(0.0788) | Loss 3.7376(3.7260) | Error 0.0275(0.0261) Steps 676(676.39) | Grad Norm 1.8094(1.7521) | Total Time 14.00(14.00)\n",
      "Iter 3796 | Time 61.1799(60.7357) | Bit/dim 3.6795(3.6864) | Xent 0.0759(0.0787) | Loss 3.7174(3.7257) | Error 0.0240(0.0260) Steps 664(676.02) | Grad Norm 1.5402(1.7457) | Total Time 14.00(14.00)\n",
      "Iter 3797 | Time 61.0528(60.7452) | Bit/dim 3.6816(3.6863) | Xent 0.0780(0.0787) | Loss 3.7205(3.7256) | Error 0.0261(0.0260) Steps 670(675.84) | Grad Norm 2.5134(1.7688) | Total Time 14.00(14.00)\n",
      "Iter 3798 | Time 59.5520(60.7094) | Bit/dim 3.6900(3.6864) | Xent 0.0809(0.0787) | Loss 3.7305(3.7257) | Error 0.0264(0.0260) Steps 670(675.66) | Grad Norm 0.9841(1.7452) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0633 | Time 25.0284, Epoch Time 402.5559(406.3121), Bit/dim 3.7103(best: 3.7093), Xent 2.7779, Loss 5.0992, Error 0.4105(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3799 | Time 59.8608(60.6840) | Bit/dim 3.6770(3.6861) | Xent 0.0841(0.0789) | Loss 3.7190(3.7255) | Error 0.0272(0.0261) Steps 676(675.67) | Grad Norm 1.5460(1.7392) | Total Time 14.00(14.00)\n",
      "Iter 3800 | Time 59.6247(60.6522) | Bit/dim 3.6795(3.6859) | Xent 0.0779(0.0789) | Loss 3.7185(3.7253) | Error 0.0246(0.0260) Steps 664(675.32) | Grad Norm 1.7008(1.7381) | Total Time 14.00(14.00)\n",
      "Iter 3801 | Time 59.7768(60.6259) | Bit/dim 3.6862(3.6859) | Xent 0.0750(0.0787) | Loss 3.7237(3.7253) | Error 0.0248(0.0260) Steps 676(675.34) | Grad Norm 1.8566(1.7416) | Total Time 14.00(14.00)\n",
      "Iter 3802 | Time 63.0928(60.6999) | Bit/dim 3.6840(3.6858) | Xent 0.0744(0.0786) | Loss 3.7212(3.7251) | Error 0.0240(0.0259) Steps 676(675.36) | Grad Norm 1.3311(1.7293) | Total Time 14.00(14.00)\n",
      "Iter 3803 | Time 61.4680(60.7230) | Bit/dim 3.6952(3.6861) | Xent 0.0829(0.0787) | Loss 3.7366(3.7255) | Error 0.0288(0.0260) Steps 688(675.74) | Grad Norm 1.5986(1.7254) | Total Time 14.00(14.00)\n",
      "Iter 3804 | Time 60.6885(60.7219) | Bit/dim 3.6936(3.6863) | Xent 0.0756(0.0786) | Loss 3.7314(3.7257) | Error 0.0255(0.0260) Steps 670(675.57) | Grad Norm 2.4399(1.7468) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0634 | Time 25.0264, Epoch Time 405.1966(406.2787), Bit/dim 3.7092(best: 3.7093), Xent 2.7440, Loss 5.0812, Error 0.4079(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3805 | Time 63.6788(60.8107) | Bit/dim 3.6797(3.6861) | Xent 0.0770(0.0786) | Loss 3.7182(3.7254) | Error 0.0255(0.0260) Steps 676(675.58) | Grad Norm 2.0505(1.7559) | Total Time 14.00(14.00)\n",
      "Iter 3806 | Time 58.3578(60.7371) | Bit/dim 3.6861(3.6861) | Xent 0.0806(0.0787) | Loss 3.7264(3.7255) | Error 0.0275(0.0260) Steps 664(675.23) | Grad Norm 1.4378(1.7464) | Total Time 14.00(14.00)\n",
      "Iter 3807 | Time 61.0955(60.7478) | Bit/dim 3.6815(3.6860) | Xent 0.0843(0.0788) | Loss 3.7236(3.7254) | Error 0.0295(0.0261) Steps 664(674.90) | Grad Norm 2.9343(1.7820) | Total Time 14.00(14.00)\n",
      "Iter 3808 | Time 61.5851(60.7729) | Bit/dim 3.6897(3.6861) | Xent 0.0833(0.0790) | Loss 3.7313(3.7256) | Error 0.0278(0.0262) Steps 676(674.93) | Grad Norm 1.9680(1.7876) | Total Time 14.00(14.00)\n",
      "Iter 3809 | Time 61.2014(60.7858) | Bit/dim 3.6881(3.6862) | Xent 0.0810(0.0790) | Loss 3.7286(3.7257) | Error 0.0260(0.0262) Steps 676(674.96) | Grad Norm 1.0924(1.7668) | Total Time 14.00(14.00)\n",
      "Iter 3810 | Time 61.8259(60.8170) | Bit/dim 3.6937(3.6864) | Xent 0.0709(0.0788) | Loss 3.7292(3.7258) | Error 0.0236(0.0261) Steps 688(675.35) | Grad Norm 2.1822(1.7792) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0635 | Time 25.0322, Epoch Time 408.5164(406.3458), Bit/dim 3.7101(best: 3.7092), Xent 2.7339, Loss 5.0771, Error 0.4052(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3811 | Time 60.5011(60.8075) | Bit/dim 3.6909(3.6865) | Xent 0.0835(0.0789) | Loss 3.7326(3.7260) | Error 0.0280(0.0262) Steps 682(675.55) | Grad Norm 2.7080(1.8071) | Total Time 14.00(14.00)\n",
      "Iter 3812 | Time 60.4269(60.7961) | Bit/dim 3.6886(3.6866) | Xent 0.0785(0.0789) | Loss 3.7279(3.7261) | Error 0.0261(0.0262) Steps 682(675.75) | Grad Norm 1.0710(1.7850) | Total Time 14.00(14.00)\n",
      "Iter 3813 | Time 60.2360(60.7793) | Bit/dim 3.6834(3.6865) | Xent 0.0823(0.0790) | Loss 3.7245(3.7260) | Error 0.0276(0.0262) Steps 670(675.57) | Grad Norm 1.8371(1.7866) | Total Time 14.00(14.00)\n",
      "Iter 3814 | Time 61.2411(60.7932) | Bit/dim 3.6731(3.6861) | Xent 0.0783(0.0790) | Loss 3.7122(3.7256) | Error 0.0278(0.0262) Steps 670(675.41) | Grad Norm 3.2522(1.8305) | Total Time 14.00(14.00)\n",
      "Iter 3815 | Time 57.4696(60.6934) | Bit/dim 3.6788(3.6859) | Xent 0.0786(0.0790) | Loss 3.7181(3.7254) | Error 0.0259(0.0262) Steps 682(675.60) | Grad Norm 1.3006(1.8146) | Total Time 14.00(14.00)\n",
      "Iter 3816 | Time 61.0576(60.7044) | Bit/dim 3.6947(3.6861) | Xent 0.0781(0.0789) | Loss 3.7338(3.7256) | Error 0.0274(0.0263) Steps 676(675.62) | Grad Norm 2.3413(1.8304) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0636 | Time 24.7174, Epoch Time 401.3990(406.1974), Bit/dim 3.7102(best: 3.7092), Xent 2.7681, Loss 5.0943, Error 0.4036(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3817 | Time 57.5593(60.6100) | Bit/dim 3.6911(3.6863) | Xent 0.0784(0.0789) | Loss 3.7302(3.7258) | Error 0.0289(0.0263) Steps 676(675.63) | Grad Norm 2.0346(1.8366) | Total Time 14.00(14.00)\n",
      "Iter 3818 | Time 60.4108(60.6040) | Bit/dim 3.6770(3.6860) | Xent 0.0764(0.0789) | Loss 3.7152(3.7254) | Error 0.0246(0.0263) Steps 688(676.00) | Grad Norm 1.1401(1.8157) | Total Time 14.00(14.00)\n",
      "Iter 3819 | Time 61.8533(60.6415) | Bit/dim 3.6880(3.6861) | Xent 0.0733(0.0787) | Loss 3.7246(3.7254) | Error 0.0248(0.0262) Steps 676(676.00) | Grad Norm 2.0158(1.8217) | Total Time 14.00(14.00)\n",
      "Iter 3820 | Time 60.0301(60.6232) | Bit/dim 3.6781(3.6858) | Xent 0.0731(0.0785) | Loss 3.7147(3.7251) | Error 0.0222(0.0261) Steps 682(676.18) | Grad Norm 2.4035(1.8391) | Total Time 14.00(14.00)\n",
      "Iter 3821 | Time 60.7093(60.6258) | Bit/dim 3.6869(3.6859) | Xent 0.0831(0.0787) | Loss 3.7284(3.7252) | Error 0.0280(0.0262) Steps 682(676.35) | Grad Norm 1.1447(1.8183) | Total Time 14.00(14.00)\n",
      "Iter 3822 | Time 62.4184(60.6795) | Bit/dim 3.6953(3.6861) | Xent 0.0814(0.0787) | Loss 3.7360(3.7255) | Error 0.0264(0.0262) Steps 670(676.16) | Grad Norm 2.9790(1.8531) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0637 | Time 25.0769, Epoch Time 403.8378(406.1266), Bit/dim 3.7095(best: 3.7092), Xent 2.7652, Loss 5.0921, Error 0.4083(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3823 | Time 60.4231(60.6718) | Bit/dim 3.6811(3.6860) | Xent 0.0806(0.0788) | Loss 3.7214(3.7254) | Error 0.0266(0.0262) Steps 682(676.34) | Grad Norm 1.8458(1.8529) | Total Time 14.00(14.00)\n",
      "Iter 3824 | Time 63.2817(60.7501) | Bit/dim 3.6852(3.6860) | Xent 0.0763(0.0787) | Loss 3.7233(3.7253) | Error 0.0264(0.0262) Steps 676(676.33) | Grad Norm 1.5530(1.8439) | Total Time 14.00(14.00)\n",
      "Iter 3825 | Time 61.7905(60.7814) | Bit/dim 3.6900(3.6861) | Xent 0.0852(0.0789) | Loss 3.7327(3.7256) | Error 0.0279(0.0263) Steps 676(676.32) | Grad Norm 3.9275(1.9064) | Total Time 14.00(14.00)\n",
      "Iter 3826 | Time 61.4757(60.8022) | Bit/dim 3.6865(3.6861) | Xent 0.0788(0.0789) | Loss 3.7259(3.7256) | Error 0.0241(0.0262) Steps 676(676.31) | Grad Norm 1.7304(1.9011) | Total Time 14.00(14.00)\n",
      "Iter 3827 | Time 59.5807(60.7655) | Bit/dim 3.6748(3.6858) | Xent 0.0804(0.0790) | Loss 3.7150(3.7252) | Error 0.0261(0.0262) Steps 664(675.94) | Grad Norm 3.6514(1.9536) | Total Time 14.00(14.00)\n",
      "Iter 3828 | Time 62.1576(60.8073) | Bit/dim 3.6928(3.6860) | Xent 0.0789(0.0790) | Loss 3.7322(3.7255) | Error 0.0271(0.0262) Steps 676(675.94) | Grad Norm 2.5636(1.9719) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0638 | Time 24.9877, Epoch Time 409.3450(406.2231), Bit/dim 3.7097(best: 3.7092), Xent 2.7782, Loss 5.0987, Error 0.4072(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3829 | Time 60.8756(60.8093) | Bit/dim 3.6837(3.6859) | Xent 0.0832(0.0791) | Loss 3.7253(3.7255) | Error 0.0275(0.0263) Steps 670(675.76) | Grad Norm 1.3839(1.9543) | Total Time 14.00(14.00)\n",
      "Iter 3830 | Time 59.5448(60.7714) | Bit/dim 3.6864(3.6859) | Xent 0.0829(0.0792) | Loss 3.7279(3.7255) | Error 0.0262(0.0263) Steps 670(675.59) | Grad Norm 2.2236(1.9624) | Total Time 14.00(14.00)\n",
      "Iter 3831 | Time 58.7341(60.7103) | Bit/dim 3.6864(3.6859) | Xent 0.0756(0.0791) | Loss 3.7242(3.7255) | Error 0.0229(0.0262) Steps 670(675.42) | Grad Norm 1.8093(1.9578) | Total Time 14.00(14.00)\n",
      "Iter 3832 | Time 60.0053(60.6891) | Bit/dim 3.6925(3.6861) | Xent 0.0751(0.0790) | Loss 3.7301(3.7256) | Error 0.0242(0.0261) Steps 670(675.26) | Grad Norm 2.2793(1.9674) | Total Time 14.00(14.00)\n",
      "Iter 3833 | Time 61.4152(60.7109) | Bit/dim 3.6845(3.6861) | Xent 0.0781(0.0789) | Loss 3.7235(3.7256) | Error 0.0266(0.0261) Steps 694(675.82) | Grad Norm 1.3989(1.9504) | Total Time 14.00(14.00)\n",
      "Iter 3834 | Time 59.6269(60.6784) | Bit/dim 3.6879(3.6861) | Xent 0.0741(0.0788) | Loss 3.7249(3.7255) | Error 0.0245(0.0261) Steps 676(675.83) | Grad Norm 1.8534(1.9475) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0639 | Time 25.1188, Epoch Time 401.5089(406.0817), Bit/dim 3.7092(best: 3.7092), Xent 2.7525, Loss 5.0854, Error 0.4024(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3835 | Time 60.9024(60.6851) | Bit/dim 3.6907(3.6863) | Xent 0.0817(0.0789) | Loss 3.7316(3.7257) | Error 0.0271(0.0261) Steps 676(675.83) | Grad Norm 1.1155(1.9225) | Total Time 14.00(14.00)\n",
      "Iter 3836 | Time 61.8605(60.7204) | Bit/dim 3.6864(3.6863) | Xent 0.0752(0.0788) | Loss 3.7240(3.7257) | Error 0.0270(0.0261) Steps 664(675.48) | Grad Norm 1.2985(1.9038) | Total Time 14.00(14.00)\n",
      "Iter 3837 | Time 59.7393(60.6910) | Bit/dim 3.6958(3.6866) | Xent 0.0788(0.0788) | Loss 3.7352(3.7260) | Error 0.0258(0.0261) Steps 676(675.49) | Grad Norm 1.6972(1.8976) | Total Time 14.00(14.00)\n",
      "Iter 3838 | Time 59.7944(60.6641) | Bit/dim 3.6747(3.6862) | Xent 0.0769(0.0787) | Loss 3.7131(3.7256) | Error 0.0244(0.0261) Steps 670(675.33) | Grad Norm 1.5284(1.8865) | Total Time 14.00(14.00)\n",
      "Iter 3839 | Time 59.1382(60.6183) | Bit/dim 3.6818(3.6861) | Xent 0.0757(0.0786) | Loss 3.7196(3.7254) | Error 0.0265(0.0261) Steps 676(675.35) | Grad Norm 1.1771(1.8652) | Total Time 14.00(14.00)\n",
      "Iter 3840 | Time 61.1685(60.6348) | Bit/dim 3.6830(3.6860) | Xent 0.0818(0.0787) | Loss 3.7239(3.7253) | Error 0.0280(0.0261) Steps 664(675.01) | Grad Norm 1.4402(1.8525) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0640 | Time 25.0512, Epoch Time 403.4003(406.0013), Bit/dim 3.7098(best: 3.7092), Xent 2.7833, Loss 5.1014, Error 0.4070(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3841 | Time 59.9063(60.6129) | Bit/dim 3.6830(3.6859) | Xent 0.0750(0.0786) | Loss 3.7205(3.7252) | Error 0.0254(0.0261) Steps 670(674.86) | Grad Norm 1.5483(1.8433) | Total Time 14.00(14.00)\n",
      "Iter 3842 | Time 58.8767(60.5608) | Bit/dim 3.6853(3.6859) | Xent 0.0770(0.0786) | Loss 3.7238(3.7252) | Error 0.0240(0.0260) Steps 664(674.53) | Grad Norm 1.1046(1.8212) | Total Time 14.00(14.00)\n",
      "Iter 3843 | Time 60.9019(60.5711) | Bit/dim 3.6848(3.6858) | Xent 0.0709(0.0783) | Loss 3.7202(3.7250) | Error 0.0240(0.0260) Steps 676(674.58) | Grad Norm 1.7029(1.8176) | Total Time 14.00(14.00)\n",
      "Iter 3844 | Time 62.8389(60.6391) | Bit/dim 3.6850(3.6858) | Xent 0.0810(0.0784) | Loss 3.7255(3.7250) | Error 0.0259(0.0260) Steps 670(674.44) | Grad Norm 1.1214(1.7967) | Total Time 14.00(14.00)\n",
      "Iter 3845 | Time 60.9022(60.6470) | Bit/dim 3.6877(3.6859) | Xent 0.0810(0.0785) | Loss 3.7282(3.7251) | Error 0.0268(0.0260) Steps 676(674.49) | Grad Norm 1.9405(1.8011) | Total Time 14.00(14.00)\n",
      "Iter 3846 | Time 61.2663(60.6656) | Bit/dim 3.6818(3.6858) | Xent 0.0724(0.0783) | Loss 3.7180(3.7249) | Error 0.0244(0.0260) Steps 676(674.53) | Grad Norm 2.0432(1.8083) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0641 | Time 25.3734, Epoch Time 406.5184(406.0168), Bit/dim 3.7101(best: 3.7092), Xent 2.7996, Loss 5.1099, Error 0.4088(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3847 | Time 61.0890(60.6783) | Bit/dim 3.6910(3.6859) | Xent 0.0789(0.0783) | Loss 3.7305(3.7251) | Error 0.0270(0.0260) Steps 670(674.39) | Grad Norm 1.8873(1.8107) | Total Time 14.00(14.00)\n",
      "Iter 3848 | Time 59.6159(60.6464) | Bit/dim 3.6898(3.6860) | Xent 0.0764(0.0783) | Loss 3.7280(3.7252) | Error 0.0240(0.0259) Steps 676(674.44) | Grad Norm 1.9940(1.8162) | Total Time 14.00(14.00)\n",
      "Iter 3849 | Time 63.8395(60.7422) | Bit/dim 3.6832(3.6859) | Xent 0.0836(0.0784) | Loss 3.7250(3.7252) | Error 0.0282(0.0260) Steps 682(674.67) | Grad Norm 1.5940(1.8095) | Total Time 14.00(14.00)\n",
      "Iter 3850 | Time 60.3521(60.7305) | Bit/dim 3.6834(3.6859) | Xent 0.0775(0.0784) | Loss 3.7222(3.7251) | Error 0.0254(0.0260) Steps 670(674.53) | Grad Norm 2.0685(1.8173) | Total Time 14.00(14.00)\n",
      "Iter 3851 | Time 62.0993(60.7716) | Bit/dim 3.6905(3.6860) | Xent 0.0718(0.0782) | Loss 3.7264(3.7251) | Error 0.0232(0.0259) Steps 682(674.75) | Grad Norm 1.5821(1.8102) | Total Time 14.00(14.00)\n",
      "Iter 3852 | Time 60.4239(60.7611) | Bit/dim 3.6790(3.6858) | Xent 0.0835(0.0784) | Loss 3.7208(3.7250) | Error 0.0276(0.0259) Steps 688(675.15) | Grad Norm 1.6432(1.8052) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0642 | Time 25.0618, Epoch Time 408.0648(406.0782), Bit/dim 3.7095(best: 3.7092), Xent 2.7765, Loss 5.0978, Error 0.4092(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3853 | Time 59.4372(60.7214) | Bit/dim 3.6850(3.6858) | Xent 0.0741(0.0782) | Loss 3.7220(3.7249) | Error 0.0241(0.0259) Steps 664(674.82) | Grad Norm 1.7725(1.8042) | Total Time 14.00(14.00)\n",
      "Iter 3854 | Time 60.0359(60.7008) | Bit/dim 3.6902(3.6859) | Xent 0.0841(0.0784) | Loss 3.7323(3.7251) | Error 0.0271(0.0259) Steps 664(674.49) | Grad Norm 1.8593(1.8059) | Total Time 14.00(14.00)\n",
      "Iter 3855 | Time 60.4961(60.6947) | Bit/dim 3.6770(3.6856) | Xent 0.0804(0.0785) | Loss 3.7173(3.7249) | Error 0.0284(0.0260) Steps 670(674.36) | Grad Norm 1.6330(1.8007) | Total Time 14.00(14.00)\n",
      "Iter 3856 | Time 61.1090(60.7071) | Bit/dim 3.6926(3.6858) | Xent 0.0838(0.0786) | Loss 3.7345(3.7252) | Error 0.0264(0.0260) Steps 694(674.95) | Grad Norm 2.2925(1.8155) | Total Time 14.00(14.00)\n",
      "Iter 3857 | Time 59.4854(60.6705) | Bit/dim 3.6762(3.6856) | Xent 0.0695(0.0784) | Loss 3.7110(3.7247) | Error 0.0240(0.0260) Steps 682(675.16) | Grad Norm 1.0936(1.7938) | Total Time 14.00(14.00)\n",
      "Iter 3858 | Time 62.7144(60.7318) | Bit/dim 3.6966(3.6859) | Xent 0.0830(0.0785) | Loss 3.7381(3.7251) | Error 0.0286(0.0260) Steps 658(674.64) | Grad Norm 2.0659(1.8020) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0643 | Time 25.0937, Epoch Time 404.0825(406.0184), Bit/dim 3.7103(best: 3.7092), Xent 2.7653, Loss 5.0929, Error 0.4048(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3859 | Time 59.0785(60.6822) | Bit/dim 3.6862(3.6859) | Xent 0.0814(0.0786) | Loss 3.7269(3.7252) | Error 0.0261(0.0260) Steps 676(674.68) | Grad Norm 2.0466(1.8093) | Total Time 14.00(14.00)\n",
      "Iter 3860 | Time 60.1936(60.6675) | Bit/dim 3.6860(3.6859) | Xent 0.0782(0.0786) | Loss 3.7251(3.7252) | Error 0.0264(0.0260) Steps 688(675.08) | Grad Norm 1.3119(1.7944) | Total Time 14.00(14.00)\n",
      "Iter 3861 | Time 58.3000(60.5965) | Bit/dim 3.6876(3.6860) | Xent 0.0740(0.0784) | Loss 3.7246(3.7252) | Error 0.0250(0.0260) Steps 676(675.11) | Grad Norm 1.3962(1.7824) | Total Time 14.00(14.00)\n",
      "Iter 3862 | Time 62.2841(60.6471) | Bit/dim 3.6811(3.6858) | Xent 0.0726(0.0783) | Loss 3.7174(3.7249) | Error 0.0236(0.0259) Steps 676(675.14) | Grad Norm 1.6143(1.7774) | Total Time 14.00(14.00)\n",
      "Iter 3863 | Time 58.9053(60.5949) | Bit/dim 3.6926(3.6860) | Xent 0.0748(0.0782) | Loss 3.7300(3.7251) | Error 0.0241(0.0259) Steps 676(675.16) | Grad Norm 1.4812(1.7685) | Total Time 14.00(14.00)\n",
      "Iter 3864 | Time 58.8909(60.5438) | Bit/dim 3.6840(3.6860) | Xent 0.0814(0.0783) | Loss 3.7247(3.7251) | Error 0.0271(0.0259) Steps 664(674.83) | Grad Norm 1.2518(1.7530) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0644 | Time 24.8282, Epoch Time 398.2456(405.7852), Bit/dim 3.7091(best: 3.7092), Xent 2.7561, Loss 5.0871, Error 0.4063(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3865 | Time 59.3757(60.5087) | Bit/dim 3.6858(3.6859) | Xent 0.0859(0.0785) | Loss 3.7288(3.7252) | Error 0.0281(0.0260) Steps 682(675.04) | Grad Norm 1.2884(1.7391) | Total Time 14.00(14.00)\n",
      "Iter 3866 | Time 61.8738(60.5497) | Bit/dim 3.6856(3.6859) | Xent 0.0808(0.0786) | Loss 3.7259(3.7252) | Error 0.0260(0.0260) Steps 676(675.07) | Grad Norm 1.7384(1.7391) | Total Time 14.00(14.00)\n",
      "Iter 3867 | Time 60.6691(60.5533) | Bit/dim 3.6817(3.6858) | Xent 0.0742(0.0784) | Loss 3.7188(3.7250) | Error 0.0244(0.0259) Steps 676(675.10) | Grad Norm 0.9559(1.7156) | Total Time 14.00(14.00)\n",
      "Iter 3868 | Time 60.7715(60.5598) | Bit/dim 3.6758(3.6855) | Xent 0.0769(0.0784) | Loss 3.7142(3.7247) | Error 0.0238(0.0259) Steps 676(675.13) | Grad Norm 1.1944(1.6999) | Total Time 14.00(14.00)\n",
      "Iter 3869 | Time 61.9221(60.6007) | Bit/dim 3.6955(3.6858) | Xent 0.0766(0.0783) | Loss 3.7338(3.7250) | Error 0.0244(0.0258) Steps 670(674.97) | Grad Norm 1.3590(1.6897) | Total Time 14.00(14.00)\n",
      "Iter 3870 | Time 63.0119(60.6730) | Bit/dim 3.6851(3.6858) | Xent 0.0761(0.0783) | Loss 3.7232(3.7249) | Error 0.0241(0.0258) Steps 682(675.18) | Grad Norm 1.2328(1.6760) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0645 | Time 24.8959, Epoch Time 408.3394(405.8618), Bit/dim 3.7099(best: 3.7091), Xent 2.7752, Loss 5.0974, Error 0.4049(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3871 | Time 62.1467(60.7172) | Bit/dim 3.6879(3.6858) | Xent 0.0736(0.0781) | Loss 3.7247(3.7249) | Error 0.0262(0.0258) Steps 688(675.57) | Grad Norm 1.1965(1.6616) | Total Time 14.00(14.00)\n",
      "Iter 3872 | Time 60.0841(60.6982) | Bit/dim 3.6859(3.6858) | Xent 0.0825(0.0782) | Loss 3.7272(3.7250) | Error 0.0258(0.0258) Steps 670(675.40) | Grad Norm 1.2931(1.6505) | Total Time 14.00(14.00)\n",
      "Iter 3873 | Time 60.0531(60.6789) | Bit/dim 3.6853(3.6858) | Xent 0.0722(0.0781) | Loss 3.7214(3.7249) | Error 0.0230(0.0257) Steps 670(675.24) | Grad Norm 1.5352(1.6471) | Total Time 14.00(14.00)\n",
      "Iter 3874 | Time 61.3464(60.6989) | Bit/dim 3.6847(3.6858) | Xent 0.0693(0.0778) | Loss 3.7193(3.7247) | Error 0.0214(0.0256) Steps 676(675.26) | Grad Norm 1.1975(1.6336) | Total Time 14.00(14.00)\n",
      "Iter 3875 | Time 62.2055(60.7441) | Bit/dim 3.6837(3.6857) | Xent 0.0800(0.0779) | Loss 3.7238(3.7247) | Error 0.0262(0.0256) Steps 682(675.46) | Grad Norm 1.8587(1.6404) | Total Time 14.00(14.00)\n",
      "Iter 3876 | Time 62.2916(60.7905) | Bit/dim 3.6797(3.6856) | Xent 0.0698(0.0776) | Loss 3.7147(3.7244) | Error 0.0250(0.0256) Steps 670(675.30) | Grad Norm 1.5169(1.6366) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0646 | Time 25.1259, Epoch Time 408.5317(405.9419), Bit/dim 3.7095(best: 3.7091), Xent 2.8254, Loss 5.1222, Error 0.4127(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3877 | Time 61.6904(60.8175) | Bit/dim 3.6887(3.6857) | Xent 0.0768(0.0776) | Loss 3.7271(3.7245) | Error 0.0256(0.0256) Steps 670(675.14) | Grad Norm 1.9380(1.6457) | Total Time 14.00(14.00)\n",
      "Iter 3878 | Time 62.3102(60.8623) | Bit/dim 3.6816(3.6855) | Xent 0.0770(0.0776) | Loss 3.7201(3.7243) | Error 0.0261(0.0256) Steps 664(674.81) | Grad Norm 2.0591(1.6581) | Total Time 14.00(14.00)\n",
      "Iter 3879 | Time 61.0230(60.8671) | Bit/dim 3.6887(3.6856) | Xent 0.0777(0.0776) | Loss 3.7275(3.7244) | Error 0.0271(0.0256) Steps 688(675.20) | Grad Norm 2.6144(1.6868) | Total Time 14.00(14.00)\n",
      "Iter 3880 | Time 57.8265(60.7759) | Bit/dim 3.6863(3.6856) | Xent 0.0771(0.0776) | Loss 3.7248(3.7244) | Error 0.0294(0.0258) Steps 676(675.23) | Grad Norm 2.0864(1.6988) | Total Time 14.00(14.00)\n",
      "Iter 3881 | Time 62.7133(60.8340) | Bit/dim 3.6808(3.6855) | Xent 0.0727(0.0774) | Loss 3.7172(3.7242) | Error 0.0231(0.0257) Steps 688(675.61) | Grad Norm 1.5749(1.6951) | Total Time 14.00(14.00)\n",
      "Iter 3882 | Time 60.5421(60.8253) | Bit/dim 3.6821(3.6854) | Xent 0.0732(0.0773) | Loss 3.7187(3.7240) | Error 0.0250(0.0257) Steps 676(675.62) | Grad Norm 1.5747(1.6914) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0647 | Time 24.9119, Epoch Time 406.7599(405.9664), Bit/dim 3.7091(best: 3.7091), Xent 2.7517, Loss 5.0849, Error 0.4070(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3883 | Time 59.8472(60.7959) | Bit/dim 3.6910(3.6856) | Xent 0.0723(0.0772) | Loss 3.7271(3.7241) | Error 0.0225(0.0256) Steps 676(675.63) | Grad Norm 1.3307(1.6806) | Total Time 14.00(14.00)\n",
      "Iter 3884 | Time 61.2810(60.8105) | Bit/dim 3.6827(3.6855) | Xent 0.0801(0.0772) | Loss 3.7227(3.7241) | Error 0.0279(0.0256) Steps 682(675.82) | Grad Norm 1.8839(1.6867) | Total Time 14.00(14.00)\n",
      "Iter 3885 | Time 59.7480(60.7786) | Bit/dim 3.6818(3.6854) | Xent 0.0922(0.0777) | Loss 3.7279(3.7242) | Error 0.0298(0.0258) Steps 682(676.01) | Grad Norm 2.1867(1.7017) | Total Time 14.00(14.00)\n",
      "Iter 3886 | Time 59.7695(60.7483) | Bit/dim 3.6912(3.6855) | Xent 0.0742(0.0776) | Loss 3.7283(3.7243) | Error 0.0244(0.0257) Steps 682(676.19) | Grad Norm 1.1062(1.6838) | Total Time 14.00(14.00)\n",
      "Iter 3887 | Time 59.5522(60.7125) | Bit/dim 3.6876(3.6856) | Xent 0.0663(0.0772) | Loss 3.7207(3.7242) | Error 0.0211(0.0256) Steps 670(676.00) | Grad Norm 3.1023(1.7264) | Total Time 14.00(14.00)\n",
      "Iter 3888 | Time 61.8316(60.7460) | Bit/dim 3.6736(3.6852) | Xent 0.0812(0.0774) | Loss 3.7143(3.7239) | Error 0.0270(0.0256) Steps 682(676.18) | Grad Norm 2.6446(1.7540) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0648 | Time 25.0163, Epoch Time 402.8645(405.8734), Bit/dim 3.7097(best: 3.7091), Xent 2.8203, Loss 5.1199, Error 0.4040(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3889 | Time 63.0156(60.8141) | Bit/dim 3.6913(3.6854) | Xent 0.0790(0.0774) | Loss 3.7308(3.7241) | Error 0.0262(0.0256) Steps 676(676.18) | Grad Norm 2.6088(1.7796) | Total Time 14.00(14.00)\n",
      "Iter 3890 | Time 64.4605(60.9235) | Bit/dim 3.6833(3.6854) | Xent 0.0734(0.0773) | Loss 3.7200(3.7240) | Error 0.0221(0.0255) Steps 676(676.17) | Grad Norm 3.2058(1.8224) | Total Time 14.00(14.00)\n",
      "Iter 3891 | Time 59.3579(60.8765) | Bit/dim 3.6777(3.6851) | Xent 0.0806(0.0774) | Loss 3.7180(3.7238) | Error 0.0250(0.0255) Steps 676(676.17) | Grad Norm 1.8391(1.8229) | Total Time 14.00(14.00)\n",
      "Iter 3892 | Time 61.5648(60.8972) | Bit/dim 3.6811(3.6850) | Xent 0.0831(0.0776) | Loss 3.7227(3.7238) | Error 0.0276(0.0256) Steps 682(676.34) | Grad Norm 2.5796(1.8456) | Total Time 14.00(14.00)\n",
      "Iter 3893 | Time 61.5167(60.9158) | Bit/dim 3.6887(3.6851) | Xent 0.0736(0.0774) | Loss 3.7255(3.7238) | Error 0.0228(0.0255) Steps 676(676.33) | Grad Norm 1.9976(1.8501) | Total Time 14.00(14.00)\n",
      "Iter 3894 | Time 63.2642(60.9862) | Bit/dim 3.6926(3.6854) | Xent 0.0742(0.0773) | Loss 3.7297(3.7240) | Error 0.0265(0.0255) Steps 676(676.32) | Grad Norm 1.9280(1.8525) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0649 | Time 25.0213, Epoch Time 414.1181(406.1207), Bit/dim 3.7081(best: 3.7091), Xent 2.7614, Loss 5.0888, Error 0.4053(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3895 | Time 59.8527(60.9522) | Bit/dim 3.6861(3.6854) | Xent 0.0815(0.0775) | Loss 3.7269(3.7241) | Error 0.0274(0.0256) Steps 676(676.31) | Grad Norm 2.9208(1.8845) | Total Time 14.00(14.00)\n",
      "Iter 3896 | Time 59.1715(60.8988) | Bit/dim 3.6859(3.6854) | Xent 0.0648(0.0771) | Loss 3.7183(3.7239) | Error 0.0210(0.0254) Steps 664(675.94) | Grad Norm 1.4372(1.8711) | Total Time 14.00(14.00)\n",
      "Iter 3897 | Time 62.0057(60.9320) | Bit/dim 3.6840(3.6853) | Xent 0.0789(0.0771) | Loss 3.7235(3.7239) | Error 0.0244(0.0254) Steps 676(675.94) | Grad Norm 2.4800(1.8894) | Total Time 14.00(14.00)\n",
      "Iter 3898 | Time 59.6230(60.8927) | Bit/dim 3.6826(3.6853) | Xent 0.0765(0.0771) | Loss 3.7209(3.7238) | Error 0.0236(0.0254) Steps 670(675.77) | Grad Norm 2.4815(1.9071) | Total Time 14.00(14.00)\n",
      "Iter 3899 | Time 62.9576(60.9547) | Bit/dim 3.6878(3.6853) | Xent 0.0697(0.0769) | Loss 3.7226(3.7238) | Error 0.0264(0.0254) Steps 682(675.95) | Grad Norm 1.7859(1.9035) | Total Time 14.00(14.00)\n",
      "Iter 3900 | Time 60.0428(60.9273) | Bit/dim 3.6844(3.6853) | Xent 0.0773(0.0769) | Loss 3.7231(3.7238) | Error 0.0252(0.0254) Steps 664(675.59) | Grad Norm 3.5420(1.9527) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0650 | Time 25.4197, Epoch Time 404.8048(406.0813), Bit/dim 3.7083(best: 3.7081), Xent 2.7943, Loss 5.1054, Error 0.4101(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3901 | Time 61.8524(60.9551) | Bit/dim 3.6795(3.6851) | Xent 0.0730(0.0768) | Loss 3.7160(3.7235) | Error 0.0246(0.0254) Steps 676(675.61) | Grad Norm 2.2904(1.9628) | Total Time 14.00(14.00)\n",
      "Iter 3902 | Time 62.3837(60.9979) | Bit/dim 3.6923(3.6854) | Xent 0.0830(0.0770) | Loss 3.7338(3.7238) | Error 0.0285(0.0255) Steps 682(675.80) | Grad Norm 1.6795(1.9543) | Total Time 14.00(14.00)\n",
      "Iter 3903 | Time 60.7665(60.9910) | Bit/dim 3.6877(3.6854) | Xent 0.0803(0.0771) | Loss 3.7278(3.7240) | Error 0.0265(0.0255) Steps 676(675.80) | Grad Norm 3.1306(1.9896) | Total Time 14.00(14.00)\n",
      "Iter 3904 | Time 59.0971(60.9342) | Bit/dim 3.6851(3.6854) | Xent 0.0769(0.0771) | Loss 3.7236(3.7240) | Error 0.0251(0.0255) Steps 676(675.81) | Grad Norm 1.9689(1.9890) | Total Time 14.00(14.00)\n",
      "Iter 3905 | Time 60.6971(60.9271) | Bit/dim 3.6824(3.6853) | Xent 0.0774(0.0771) | Loss 3.7211(3.7239) | Error 0.0259(0.0255) Steps 676(675.82) | Grad Norm 1.4457(1.9727) | Total Time 14.00(14.00)\n",
      "Iter 3906 | Time 60.3439(60.9096) | Bit/dim 3.6776(3.6851) | Xent 0.0722(0.0769) | Loss 3.7138(3.7236) | Error 0.0251(0.0255) Steps 670(675.64) | Grad Norm 2.5273(1.9893) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0651 | Time 25.0308, Epoch Time 405.8338(406.0738), Bit/dim 3.7076(best: 3.7081), Xent 2.8073, Loss 5.1112, Error 0.4104(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3907 | Time 61.7941(60.9361) | Bit/dim 3.6874(3.6852) | Xent 0.0789(0.0770) | Loss 3.7268(3.7237) | Error 0.0268(0.0255) Steps 664(675.29) | Grad Norm 1.3627(1.9705) | Total Time 14.00(14.00)\n",
      "Iter 3908 | Time 61.3465(60.9484) | Bit/dim 3.6803(3.6850) | Xent 0.0735(0.0769) | Loss 3.7170(3.7235) | Error 0.0245(0.0255) Steps 670(675.13) | Grad Norm 1.0712(1.9435) | Total Time 14.00(14.00)\n",
      "Iter 3909 | Time 61.1160(60.9534) | Bit/dim 3.6965(3.6854) | Xent 0.0717(0.0767) | Loss 3.7324(3.7237) | Error 0.0242(0.0254) Steps 676(675.16) | Grad Norm 1.1277(1.9190) | Total Time 14.00(14.00)\n",
      "Iter 3910 | Time 63.0935(61.0176) | Bit/dim 3.6866(3.6854) | Xent 0.0722(0.0766) | Loss 3.7227(3.7237) | Error 0.0231(0.0254) Steps 664(674.83) | Grad Norm 1.5456(1.9078) | Total Time 14.00(14.00)\n",
      "Iter 3911 | Time 60.5552(61.0038) | Bit/dim 3.6795(3.6852) | Xent 0.0685(0.0764) | Loss 3.7137(3.7234) | Error 0.0228(0.0253) Steps 676(674.86) | Grad Norm 1.6344(1.8996) | Total Time 14.00(14.00)\n",
      "Iter 3912 | Time 62.2644(61.0416) | Bit/dim 3.6811(3.6851) | Xent 0.0787(0.0764) | Loss 3.7205(3.7233) | Error 0.0266(0.0253) Steps 670(674.71) | Grad Norm 1.5969(1.8906) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0652 | Time 25.2397, Epoch Time 411.2306(406.2285), Bit/dim 3.7083(best: 3.7076), Xent 2.7995, Loss 5.1081, Error 0.4065(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3913 | Time 60.1944(61.0162) | Bit/dim 3.6877(3.6852) | Xent 0.0755(0.0764) | Loss 3.7254(3.7234) | Error 0.0282(0.0254) Steps 670(674.57) | Grad Norm 1.1473(1.8683) | Total Time 14.00(14.00)\n",
      "Iter 3914 | Time 63.1589(61.0805) | Bit/dim 3.6903(3.6853) | Xent 0.0798(0.0765) | Loss 3.7302(3.7236) | Error 0.0271(0.0255) Steps 670(674.44) | Grad Norm 1.6463(1.8616) | Total Time 14.00(14.00)\n",
      "Iter 3915 | Time 60.3745(61.0593) | Bit/dim 3.6793(3.6851) | Xent 0.0694(0.0763) | Loss 3.7141(3.7233) | Error 0.0242(0.0254) Steps 676(674.48) | Grad Norm 1.1335(1.8398) | Total Time 14.00(14.00)\n",
      "Iter 3916 | Time 59.6573(61.0172) | Bit/dim 3.6915(3.6853) | Xent 0.0688(0.0761) | Loss 3.7259(3.7234) | Error 0.0222(0.0253) Steps 670(674.35) | Grad Norm 1.7470(1.8370) | Total Time 14.00(14.00)\n",
      "Iter 3917 | Time 61.7983(61.0406) | Bit/dim 3.6776(3.6851) | Xent 0.0688(0.0759) | Loss 3.7120(3.7230) | Error 0.0228(0.0253) Steps 688(674.76) | Grad Norm 1.4557(1.8255) | Total Time 14.00(14.00)\n",
      "Iter 3918 | Time 63.7405(61.1216) | Bit/dim 3.6793(3.6849) | Xent 0.0752(0.0758) | Loss 3.7170(3.7229) | Error 0.0249(0.0253) Steps 670(674.62) | Grad Norm 1.1191(1.8043) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0653 | Time 25.2040, Epoch Time 410.0633(406.3436), Bit/dim 3.7083(best: 3.7076), Xent 2.7785, Loss 5.0976, Error 0.4036(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3919 | Time 60.8769(61.1143) | Bit/dim 3.6847(3.6849) | Xent 0.0744(0.0758) | Loss 3.7219(3.7228) | Error 0.0252(0.0253) Steps 676(674.66) | Grad Norm 2.0717(1.8124) | Total Time 14.00(14.00)\n",
      "Iter 3920 | Time 62.8530(61.1665) | Bit/dim 3.6861(3.6850) | Xent 0.0773(0.0758) | Loss 3.7247(3.7229) | Error 0.0274(0.0253) Steps 664(674.34) | Grad Norm 1.5431(1.8043) | Total Time 14.00(14.00)\n",
      "Iter 3921 | Time 61.7103(61.1828) | Bit/dim 3.6906(3.6851) | Xent 0.0696(0.0756) | Loss 3.7254(3.7230) | Error 0.0214(0.0252) Steps 664(674.03) | Grad Norm 1.8187(1.8047) | Total Time 14.00(14.00)\n",
      "Iter 3922 | Time 59.1525(61.1219) | Bit/dim 3.6862(3.6852) | Xent 0.0746(0.0756) | Loss 3.7235(3.7230) | Error 0.0251(0.0252) Steps 670(673.91) | Grad Norm 2.7105(1.8319) | Total Time 14.00(14.00)\n",
      "Iter 3923 | Time 60.6233(61.1069) | Bit/dim 3.6745(3.6848) | Xent 0.0755(0.0756) | Loss 3.7122(3.7226) | Error 0.0251(0.0252) Steps 676(673.97) | Grad Norm 1.2495(1.8144) | Total Time 14.00(14.00)\n",
      "Iter 3924 | Time 60.5309(61.0896) | Bit/dim 3.6873(3.6849) | Xent 0.0731(0.0755) | Loss 3.7239(3.7227) | Error 0.0230(0.0251) Steps 670(673.85) | Grad Norm 2.6708(1.8401) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0654 | Time 25.2059, Epoch Time 406.5455(406.3496), Bit/dim 3.7079(best: 3.7076), Xent 2.8210, Loss 5.1184, Error 0.4069(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3925 | Time 57.3901(60.9786) | Bit/dim 3.6911(3.6851) | Xent 0.0753(0.0755) | Loss 3.7287(3.7229) | Error 0.0230(0.0251) Steps 670(673.73) | Grad Norm 2.7787(1.8683) | Total Time 14.00(14.00)\n",
      "Iter 3926 | Time 62.0040(61.0094) | Bit/dim 3.6867(3.6851) | Xent 0.0742(0.0755) | Loss 3.7237(3.7229) | Error 0.0248(0.0251) Steps 670(673.62) | Grad Norm 2.6596(1.8920) | Total Time 14.00(14.00)\n",
      "Iter 3927 | Time 58.7433(60.9414) | Bit/dim 3.6842(3.6851) | Xent 0.0796(0.0756) | Loss 3.7240(3.7229) | Error 0.0254(0.0251) Steps 670(673.51) | Grad Norm 2.1217(1.8989) | Total Time 14.00(14.00)\n",
      "Iter 3928 | Time 63.1163(61.0067) | Bit/dim 3.6907(3.6853) | Xent 0.0775(0.0757) | Loss 3.7294(3.7231) | Error 0.0241(0.0250) Steps 676(673.59) | Grad Norm 1.7502(1.8944) | Total Time 14.00(14.00)\n",
      "Iter 3929 | Time 58.6167(60.9350) | Bit/dim 3.6713(3.6849) | Xent 0.0757(0.0757) | Loss 3.7092(3.7227) | Error 0.0244(0.0250) Steps 682(673.84) | Grad Norm 2.1424(1.9019) | Total Time 14.00(14.00)\n",
      "Iter 3930 | Time 60.8679(60.9330) | Bit/dim 3.6886(3.6850) | Xent 0.0744(0.0756) | Loss 3.7258(3.7228) | Error 0.0258(0.0250) Steps 682(674.09) | Grad Norm 1.5788(1.8922) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0655 | Time 24.5493, Epoch Time 401.1018(406.1922), Bit/dim 3.7093(best: 3.7076), Xent 2.8137, Loss 5.1162, Error 0.4031(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3931 | Time 60.9625(60.9338) | Bit/dim 3.6893(3.6851) | Xent 0.0781(0.0757) | Loss 3.7283(3.7230) | Error 0.0244(0.0250) Steps 670(673.96) | Grad Norm 2.5598(1.9122) | Total Time 14.00(14.00)\n",
      "Iter 3932 | Time 62.0825(60.9683) | Bit/dim 3.6810(3.6850) | Xent 0.0773(0.0758) | Loss 3.7196(3.7229) | Error 0.0229(0.0250) Steps 682(674.20) | Grad Norm 2.0549(1.9165) | Total Time 14.00(14.00)\n",
      "Iter 3933 | Time 57.4962(60.8641) | Bit/dim 3.6907(3.6852) | Xent 0.0790(0.0759) | Loss 3.7302(3.7231) | Error 0.0271(0.0250) Steps 676(674.26) | Grad Norm 2.3165(1.9285) | Total Time 14.00(14.00)\n",
      "Iter 3934 | Time 61.7923(60.8920) | Bit/dim 3.6814(3.6850) | Xent 0.0764(0.0759) | Loss 3.7196(3.7230) | Error 0.0231(0.0250) Steps 670(674.13) | Grad Norm 1.3377(1.9108) | Total Time 14.00(14.00)\n",
      "Iter 3935 | Time 59.6787(60.8556) | Bit/dim 3.6789(3.6849) | Xent 0.0762(0.0759) | Loss 3.7170(3.7228) | Error 0.0271(0.0250) Steps 676(674.19) | Grad Norm 1.5873(1.9011) | Total Time 14.00(14.00)\n",
      "Iter 3936 | Time 58.9430(60.7982) | Bit/dim 3.6838(3.6848) | Xent 0.0731(0.0758) | Loss 3.7204(3.7227) | Error 0.0242(0.0250) Steps 658(673.70) | Grad Norm 1.6219(1.8927) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0656 | Time 25.0852, Epoch Time 402.2774(406.0748), Bit/dim 3.7076(best: 3.7076), Xent 2.7792, Loss 5.0972, Error 0.4068(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3937 | Time 59.7947(60.7681) | Bit/dim 3.6852(3.6848) | Xent 0.0746(0.0758) | Loss 3.7225(3.7227) | Error 0.0238(0.0250) Steps 676(673.77) | Grad Norm 1.5144(1.8814) | Total Time 14.00(14.00)\n",
      "Iter 3938 | Time 60.8876(60.7717) | Bit/dim 3.6852(3.6849) | Xent 0.0701(0.0756) | Loss 3.7202(3.7226) | Error 0.0232(0.0249) Steps 676(673.84) | Grad Norm 2.0559(1.8866) | Total Time 14.00(14.00)\n",
      "Iter 3939 | Time 60.4978(60.7635) | Bit/dim 3.6688(3.6844) | Xent 0.0686(0.0754) | Loss 3.7031(3.7221) | Error 0.0219(0.0248) Steps 676(673.90) | Grad Norm 1.6361(1.8791) | Total Time 14.00(14.00)\n",
      "Iter 3940 | Time 60.8617(60.7664) | Bit/dim 3.6925(3.6846) | Xent 0.0814(0.0756) | Loss 3.7333(3.7224) | Error 0.0278(0.0249) Steps 682(674.14) | Grad Norm 2.0645(1.8846) | Total Time 14.00(14.00)\n",
      "Iter 3941 | Time 61.2728(60.7816) | Bit/dim 3.6973(3.6850) | Xent 0.0731(0.0755) | Loss 3.7338(3.7227) | Error 0.0251(0.0249) Steps 676(674.20) | Grad Norm 2.0741(1.8903) | Total Time 14.00(14.00)\n",
      "Iter 3942 | Time 59.8072(60.7524) | Bit/dim 3.6741(3.6847) | Xent 0.0743(0.0755) | Loss 3.7113(3.7224) | Error 0.0244(0.0249) Steps 676(674.25) | Grad Norm 2.1204(1.8972) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0657 | Time 24.8394, Epoch Time 404.3568(406.0232), Bit/dim 3.7078(best: 3.7076), Xent 2.8116, Loss 5.1135, Error 0.4083(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3943 | Time 60.8131(60.7542) | Bit/dim 3.6809(3.6846) | Xent 0.0759(0.0755) | Loss 3.7189(3.7223) | Error 0.0240(0.0249) Steps 682(674.49) | Grad Norm 2.0565(1.9020) | Total Time 14.00(14.00)\n",
      "Iter 3944 | Time 60.9475(60.7600) | Bit/dim 3.6838(3.6845) | Xent 0.0683(0.0752) | Loss 3.7179(3.7222) | Error 0.0218(0.0248) Steps 670(674.35) | Grad Norm 1.2715(1.8831) | Total Time 14.00(14.00)\n",
      "Iter 3945 | Time 61.7061(60.7884) | Bit/dim 3.6799(3.6844) | Xent 0.0725(0.0752) | Loss 3.7162(3.7220) | Error 0.0241(0.0248) Steps 688(674.76) | Grad Norm 1.9349(1.8846) | Total Time 14.00(14.00)\n",
      "Iter 3946 | Time 63.1034(60.8578) | Bit/dim 3.6968(3.6848) | Xent 0.0705(0.0750) | Loss 3.7320(3.7223) | Error 0.0242(0.0247) Steps 676(674.80) | Grad Norm 2.3160(1.8976) | Total Time 14.00(14.00)\n",
      "Iter 3947 | Time 63.1600(60.9269) | Bit/dim 3.6917(3.6850) | Xent 0.0698(0.0749) | Loss 3.7266(3.7224) | Error 0.0219(0.0247) Steps 676(674.83) | Grad Norm 1.1649(1.8756) | Total Time 14.00(14.00)\n",
      "Iter 3948 | Time 60.1237(60.9028) | Bit/dim 3.6771(3.6847) | Xent 0.0785(0.0750) | Loss 3.7164(3.7222) | Error 0.0250(0.0247) Steps 670(674.69) | Grad Norm 1.6349(1.8684) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0658 | Time 25.0544, Epoch Time 410.9762(406.1718), Bit/dim 3.7087(best: 3.7076), Xent 2.8262, Loss 5.1218, Error 0.4103(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3949 | Time 60.9256(60.9035) | Bit/dim 3.6898(3.6849) | Xent 0.0752(0.0750) | Loss 3.7274(3.7224) | Error 0.0265(0.0247) Steps 676(674.73) | Grad Norm 2.9372(1.9004) | Total Time 14.00(14.00)\n",
      "Iter 3950 | Time 59.2899(60.8551) | Bit/dim 3.6863(3.6849) | Xent 0.0741(0.0750) | Loss 3.7234(3.7224) | Error 0.0248(0.0247) Steps 676(674.77) | Grad Norm 2.3646(1.9144) | Total Time 14.00(14.00)\n",
      "Iter 3951 | Time 60.9206(60.8570) | Bit/dim 3.6835(3.6849) | Xent 0.0733(0.0749) | Loss 3.7201(3.7223) | Error 0.0245(0.0247) Steps 676(674.80) | Grad Norm 2.0869(1.9195) | Total Time 14.00(14.00)\n",
      "Iter 3952 | Time 60.0641(60.8333) | Bit/dim 3.6863(3.6849) | Xent 0.0740(0.0749) | Loss 3.7233(3.7224) | Error 0.0250(0.0247) Steps 682(675.02) | Grad Norm 2.2838(1.9305) | Total Time 14.00(14.00)\n",
      "Iter 3953 | Time 62.7173(60.8898) | Bit/dim 3.6733(3.6846) | Xent 0.0837(0.0751) | Loss 3.7152(3.7222) | Error 0.0281(0.0248) Steps 682(675.23) | Grad Norm 1.4641(1.9165) | Total Time 14.00(14.00)\n",
      "Iter 3954 | Time 59.1973(60.8390) | Bit/dim 3.6798(3.6844) | Xent 0.0768(0.0752) | Loss 3.7182(3.7220) | Error 0.0244(0.0248) Steps 670(675.07) | Grad Norm 1.7089(1.9103) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0659 | Time 24.9585, Epoch Time 404.0408(406.1079), Bit/dim 3.7091(best: 3.7076), Xent 2.7679, Loss 5.0930, Error 0.4026(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3955 | Time 61.4475(60.8573) | Bit/dim 3.6856(3.6845) | Xent 0.0776(0.0753) | Loss 3.7244(3.7221) | Error 0.0259(0.0248) Steps 682(675.28) | Grad Norm 2.2019(1.9190) | Total Time 14.00(14.00)\n",
      "Iter 3956 | Time 63.7158(60.9430) | Bit/dim 3.6720(3.6841) | Xent 0.0710(0.0751) | Loss 3.7075(3.7217) | Error 0.0238(0.0248) Steps 676(675.30) | Grad Norm 1.1521(1.8960) | Total Time 14.00(14.00)\n",
      "Iter 3957 | Time 60.3669(60.9257) | Bit/dim 3.6919(3.6843) | Xent 0.0695(0.0750) | Loss 3.7267(3.7218) | Error 0.0234(0.0248) Steps 676(675.32) | Grad Norm 2.4678(1.9131) | Total Time 14.00(14.00)\n",
      "Iter 3958 | Time 58.7398(60.8601) | Bit/dim 3.6757(3.6841) | Xent 0.0732(0.0749) | Loss 3.7123(3.7215) | Error 0.0241(0.0248) Steps 676(675.34) | Grad Norm 1.3812(1.8972) | Total Time 14.00(14.00)\n",
      "Iter 3959 | Time 60.4764(60.8486) | Bit/dim 3.6944(3.6844) | Xent 0.0656(0.0746) | Loss 3.7272(3.7217) | Error 0.0191(0.0246) Steps 688(675.72) | Grad Norm 2.5594(1.9171) | Total Time 14.00(14.00)\n",
      "Iter 3960 | Time 59.1414(60.7974) | Bit/dim 3.6807(3.6843) | Xent 0.0753(0.0747) | Loss 3.7184(3.7216) | Error 0.0232(0.0245) Steps 676(675.73) | Grad Norm 1.3389(1.8997) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0660 | Time 24.6354, Epoch Time 404.2816(406.0531), Bit/dim 3.7083(best: 3.7076), Xent 2.8187, Loss 5.1176, Error 0.4110(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3961 | Time 58.6378(60.7326) | Bit/dim 3.6876(3.6844) | Xent 0.0754(0.0747) | Loss 3.7253(3.7217) | Error 0.0264(0.0246) Steps 682(675.92) | Grad Norm 2.5075(1.9179) | Total Time 14.00(14.00)\n",
      "Iter 3962 | Time 59.6340(60.6997) | Bit/dim 3.6827(3.6843) | Xent 0.0698(0.0745) | Loss 3.7176(3.7216) | Error 0.0234(0.0246) Steps 670(675.74) | Grad Norm 1.2234(1.8971) | Total Time 14.00(14.00)\n",
      "Iter 3963 | Time 60.8511(60.7042) | Bit/dim 3.6803(3.6842) | Xent 0.0739(0.0745) | Loss 3.7172(3.7215) | Error 0.0252(0.0246) Steps 688(676.11) | Grad Norm 1.9258(1.8980) | Total Time 14.00(14.00)\n",
      "Iter 3964 | Time 64.1215(60.8067) | Bit/dim 3.6752(3.6839) | Xent 0.0700(0.0744) | Loss 3.7102(3.7211) | Error 0.0234(0.0245) Steps 670(675.93) | Grad Norm 1.9299(1.8989) | Total Time 14.00(14.00)\n",
      "Iter 3965 | Time 59.9298(60.7804) | Bit/dim 3.6862(3.6840) | Xent 0.0786(0.0745) | Loss 3.7255(3.7213) | Error 0.0258(0.0246) Steps 676(675.93) | Grad Norm 1.1847(1.8775) | Total Time 14.00(14.00)\n",
      "Iter 3966 | Time 63.2991(60.8560) | Bit/dim 3.6911(3.6842) | Xent 0.0722(0.0744) | Loss 3.7271(3.7214) | Error 0.0249(0.0246) Steps 664(675.57) | Grad Norm 1.9375(1.8793) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0661 | Time 24.9950, Epoch Time 407.2961(406.0904), Bit/dim 3.7090(best: 3.7076), Xent 2.8521, Loss 5.1350, Error 0.4118(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3967 | Time 61.1666(60.8653) | Bit/dim 3.6926(3.6845) | Xent 0.0769(0.0745) | Loss 3.7310(3.7217) | Error 0.0275(0.0247) Steps 670(675.40) | Grad Norm 2.5478(1.8994) | Total Time 14.00(14.00)\n",
      "Iter 3968 | Time 59.5685(60.8264) | Bit/dim 3.6858(3.6845) | Xent 0.0730(0.0745) | Loss 3.7223(3.7217) | Error 0.0244(0.0247) Steps 682(675.60) | Grad Norm 1.3999(1.8844) | Total Time 14.00(14.00)\n",
      "Iter 3969 | Time 61.9576(60.8603) | Bit/dim 3.6895(3.6847) | Xent 0.0790(0.0746) | Loss 3.7291(3.7220) | Error 0.0254(0.0247) Steps 688(675.97) | Grad Norm 2.8596(1.9136) | Total Time 14.00(14.00)\n",
      "Iter 3970 | Time 61.7785(60.8879) | Bit/dim 3.6767(3.6844) | Xent 0.0727(0.0745) | Loss 3.7130(3.7217) | Error 0.0234(0.0247) Steps 676(675.97) | Grad Norm 1.8832(1.9127) | Total Time 14.00(14.00)\n",
      "Iter 3971 | Time 61.8996(60.9182) | Bit/dim 3.6797(3.6843) | Xent 0.0746(0.0745) | Loss 3.7170(3.7215) | Error 0.0252(0.0247) Steps 682(676.15) | Grad Norm 2.2801(1.9237) | Total Time 14.00(14.00)\n",
      "Iter 3972 | Time 62.5700(60.9678) | Bit/dim 3.6871(3.6844) | Xent 0.0768(0.0746) | Loss 3.7255(3.7217) | Error 0.0269(0.0247) Steps 676(676.15) | Grad Norm 2.2691(1.9341) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0662 | Time 24.7013, Epoch Time 409.5303(406.1936), Bit/dim 3.7080(best: 3.7076), Xent 2.7694, Loss 5.0927, Error 0.4037(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3973 | Time 61.5417(60.9850) | Bit/dim 3.6903(3.6845) | Xent 0.0677(0.0744) | Loss 3.7241(3.7217) | Error 0.0229(0.0247) Steps 670(675.97) | Grad Norm 1.6573(1.9258) | Total Time 14.00(14.00)\n",
      "Iter 3974 | Time 59.8863(60.9520) | Bit/dim 3.6823(3.6845) | Xent 0.0733(0.0744) | Loss 3.7189(3.7217) | Error 0.0241(0.0247) Steps 670(675.79) | Grad Norm 2.3780(1.9394) | Total Time 14.00(14.00)\n",
      "Iter 3975 | Time 62.4827(60.9980) | Bit/dim 3.6796(3.6843) | Xent 0.0731(0.0743) | Loss 3.7161(3.7215) | Error 0.0225(0.0246) Steps 670(675.61) | Grad Norm 2.2415(1.9484) | Total Time 14.00(14.00)\n",
      "Iter 3976 | Time 60.6043(60.9861) | Bit/dim 3.6840(3.6843) | Xent 0.0824(0.0746) | Loss 3.7252(3.7216) | Error 0.0270(0.0247) Steps 670(675.44) | Grad Norm 2.1282(1.9538) | Total Time 14.00(14.00)\n",
      "Iter 3977 | Time 61.8616(61.0124) | Bit/dim 3.6865(3.6844) | Xent 0.0765(0.0746) | Loss 3.7248(3.7217) | Error 0.0252(0.0247) Steps 670(675.28) | Grad Norm 2.4917(1.9700) | Total Time 14.00(14.00)\n",
      "Iter 3978 | Time 61.7621(61.0349) | Bit/dim 3.6809(3.6843) | Xent 0.0791(0.0748) | Loss 3.7205(3.7217) | Error 0.0249(0.0247) Steps 682(675.48) | Grad Norm 3.0974(2.0038) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0663 | Time 24.8104, Epoch Time 408.8195(406.2724), Bit/dim 3.7078(best: 3.7076), Xent 2.8181, Loss 5.1168, Error 0.4087(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3979 | Time 60.0081(61.0041) | Bit/dim 3.6874(3.6844) | Xent 0.0672(0.0745) | Loss 3.7210(3.7216) | Error 0.0224(0.0246) Steps 670(675.32) | Grad Norm 1.1264(1.9775) | Total Time 14.00(14.00)\n",
      "Iter 3980 | Time 59.6148(60.9624) | Bit/dim 3.6855(3.6844) | Xent 0.0828(0.0748) | Loss 3.7269(3.7218) | Error 0.0288(0.0247) Steps 670(675.16) | Grad Norm 2.1451(1.9825) | Total Time 14.00(14.00)\n",
      "Iter 3981 | Time 59.4795(60.9179) | Bit/dim 3.6769(3.6842) | Xent 0.0743(0.0748) | Loss 3.7141(3.7216) | Error 0.0248(0.0247) Steps 664(674.82) | Grad Norm 2.9635(2.0119) | Total Time 14.00(14.00)\n",
      "Iter 3982 | Time 58.4791(60.8448) | Bit/dim 3.6906(3.6844) | Xent 0.0841(0.0751) | Loss 3.7327(3.7219) | Error 0.0275(0.0248) Steps 676(674.86) | Grad Norm 2.2225(2.0182) | Total Time 14.00(14.00)\n",
      "Iter 3983 | Time 61.3095(60.8587) | Bit/dim 3.6825(3.6843) | Xent 0.0735(0.0750) | Loss 3.7192(3.7218) | Error 0.0260(0.0249) Steps 682(675.07) | Grad Norm 2.0451(2.0190) | Total Time 14.00(14.00)\n",
      "Iter 3984 | Time 62.1633(60.8978) | Bit/dim 3.6835(3.6843) | Xent 0.0728(0.0749) | Loss 3.7199(3.7218) | Error 0.0216(0.0248) Steps 688(675.46) | Grad Norm 2.1268(2.0223) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0664 | Time 25.0556, Epoch Time 402.2405(406.1514), Bit/dim 3.7078(best: 3.7076), Xent 2.7530, Loss 5.0843, Error 0.4035(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3985 | Time 60.4533(60.8845) | Bit/dim 3.6820(3.6842) | Xent 0.0710(0.0748) | Loss 3.7175(3.7216) | Error 0.0239(0.0247) Steps 676(675.48) | Grad Norm 2.1779(2.0269) | Total Time 14.00(14.00)\n",
      "Iter 3986 | Time 60.2946(60.8668) | Bit/dim 3.6808(3.6841) | Xent 0.0768(0.0749) | Loss 3.7192(3.7216) | Error 0.0250(0.0247) Steps 682(675.67) | Grad Norm 3.4743(2.0704) | Total Time 14.00(14.00)\n",
      "Iter 3987 | Time 61.6038(60.8889) | Bit/dim 3.6823(3.6841) | Xent 0.0754(0.0749) | Loss 3.7200(3.7215) | Error 0.0251(0.0248) Steps 682(675.86) | Grad Norm 1.3016(2.0473) | Total Time 14.00(14.00)\n",
      "Iter 3988 | Time 61.6044(60.9104) | Bit/dim 3.6827(3.6840) | Xent 0.0734(0.0749) | Loss 3.7194(3.7215) | Error 0.0255(0.0248) Steps 670(675.69) | Grad Norm 4.0677(2.1079) | Total Time 14.00(14.00)\n",
      "Iter 3989 | Time 61.9187(60.9406) | Bit/dim 3.6841(3.6840) | Xent 0.0830(0.0751) | Loss 3.7256(3.7216) | Error 0.0264(0.0248) Steps 670(675.52) | Grad Norm 3.6534(2.1543) | Total Time 14.00(14.00)\n",
      "Iter 3990 | Time 61.9711(60.9715) | Bit/dim 3.6895(3.6842) | Xent 0.0666(0.0748) | Loss 3.7228(3.7216) | Error 0.0218(0.0247) Steps 676(675.53) | Grad Norm 1.2811(2.1281) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0665 | Time 25.1052, Epoch Time 408.5393(406.2230), Bit/dim 3.7083(best: 3.7076), Xent 2.8182, Loss 5.1173, Error 0.4106(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3991 | Time 60.5767(60.9597) | Bit/dim 3.6930(3.6845) | Xent 0.0773(0.0749) | Loss 3.7316(3.7219) | Error 0.0246(0.0247) Steps 682(675.73) | Grad Norm 4.2751(2.1925) | Total Time 14.00(14.00)\n",
      "Iter 3992 | Time 62.1770(60.9962) | Bit/dim 3.6913(3.6847) | Xent 0.0679(0.0747) | Loss 3.7253(3.7220) | Error 0.0224(0.0247) Steps 676(675.73) | Grad Norm 2.1838(2.1922) | Total Time 14.00(14.00)\n",
      "Iter 3993 | Time 61.0409(60.9976) | Bit/dim 3.6748(3.6844) | Xent 0.0722(0.0746) | Loss 3.7109(3.7217) | Error 0.0248(0.0247) Steps 682(675.92) | Grad Norm 1.5378(2.1726) | Total Time 14.00(14.00)\n",
      "Iter 3994 | Time 61.2377(61.0048) | Bit/dim 3.6847(3.6844) | Xent 0.0735(0.0746) | Loss 3.7214(3.7217) | Error 0.0235(0.0246) Steps 682(676.10) | Grad Norm 1.8496(2.1629) | Total Time 14.00(14.00)\n",
      "Iter 3995 | Time 59.6215(60.9633) | Bit/dim 3.6763(3.6841) | Xent 0.0725(0.0745) | Loss 3.7125(3.7214) | Error 0.0251(0.0246) Steps 664(675.74) | Grad Norm 3.6027(2.2061) | Total Time 14.00(14.00)\n",
      "Iter 3996 | Time 57.2283(60.8512) | Bit/dim 3.6855(3.6842) | Xent 0.0727(0.0745) | Loss 3.7219(3.7214) | Error 0.0232(0.0246) Steps 658(675.21) | Grad Norm 1.4296(2.1828) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0666 | Time 25.3763, Epoch Time 403.0485(406.1278), Bit/dim 3.7082(best: 3.7076), Xent 2.8353, Loss 5.1258, Error 0.4104(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3997 | Time 60.0457(60.8270) | Bit/dim 3.6881(3.6843) | Xent 0.0777(0.0746) | Loss 3.7270(3.7216) | Error 0.0260(0.0246) Steps 682(675.41) | Grad Norm 1.8804(2.1737) | Total Time 14.00(14.00)\n",
      "Iter 3998 | Time 60.8712(60.8284) | Bit/dim 3.6834(3.6843) | Xent 0.0734(0.0745) | Loss 3.7201(3.7215) | Error 0.0235(0.0246) Steps 670(675.25) | Grad Norm 2.3621(2.1794) | Total Time 14.00(14.00)\n",
      "Iter 3999 | Time 59.1520(60.7781) | Bit/dim 3.6902(3.6844) | Xent 0.0733(0.0745) | Loss 3.7268(3.7217) | Error 0.0238(0.0246) Steps 676(675.27) | Grad Norm 3.8524(2.2296) | Total Time 14.00(14.00)\n",
      "Iter 4000 | Time 62.3239(60.8245) | Bit/dim 3.6846(3.6844) | Xent 0.0704(0.0744) | Loss 3.7198(3.7216) | Error 0.0222(0.0245) Steps 676(675.29) | Grad Norm 2.0203(2.2233) | Total Time 14.00(14.00)\n",
      "Iter 4001 | Time 59.6004(60.7877) | Bit/dim 3.6708(3.6840) | Xent 0.0705(0.0743) | Loss 3.7061(3.7212) | Error 0.0241(0.0245) Steps 676(675.32) | Grad Norm 3.0562(2.2483) | Total Time 14.00(14.00)\n",
      "Iter 4002 | Time 60.1665(60.7691) | Bit/dim 3.6887(3.6842) | Xent 0.0706(0.0742) | Loss 3.7240(3.7213) | Error 0.0245(0.0245) Steps 664(674.98) | Grad Norm 1.9125(2.2382) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0667 | Time 25.3528, Epoch Time 403.4253(406.0467), Bit/dim 3.7072(best: 3.7076), Xent 2.8222, Loss 5.1184, Error 0.4055(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4003 | Time 59.3707(60.7271) | Bit/dim 3.6930(3.6844) | Xent 0.0695(0.0740) | Loss 3.7278(3.7215) | Error 0.0229(0.0245) Steps 664(674.65) | Grad Norm 2.7740(2.2543) | Total Time 14.00(14.00)\n",
      "Iter 4004 | Time 60.4786(60.7197) | Bit/dim 3.6783(3.6843) | Xent 0.0738(0.0740) | Loss 3.7152(3.7213) | Error 0.0268(0.0245) Steps 670(674.51) | Grad Norm 1.8911(2.2434) | Total Time 14.00(14.00)\n",
      "Iter 4005 | Time 63.5382(60.8042) | Bit/dim 3.6868(3.6843) | Xent 0.0747(0.0740) | Loss 3.7241(3.7213) | Error 0.0244(0.0245) Steps 670(674.37) | Grad Norm 1.3305(2.2160) | Total Time 14.00(14.00)\n",
      "Iter 4006 | Time 59.6503(60.7696) | Bit/dim 3.6864(3.6844) | Xent 0.0720(0.0740) | Loss 3.7224(3.7214) | Error 0.0240(0.0245) Steps 682(674.60) | Grad Norm 3.0881(2.2422) | Total Time 14.00(14.00)\n",
      "Iter 4007 | Time 59.8204(60.7411) | Bit/dim 3.6823(3.6843) | Xent 0.0706(0.0739) | Loss 3.7176(3.7213) | Error 0.0232(0.0245) Steps 670(674.46) | Grad Norm 1.3278(2.2147) | Total Time 14.00(14.00)\n",
      "Iter 4008 | Time 60.3622(60.7298) | Bit/dim 3.6762(3.6841) | Xent 0.0792(0.0740) | Loss 3.7158(3.7211) | Error 0.0265(0.0245) Steps 676(674.51) | Grad Norm 1.8848(2.2048) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0668 | Time 25.1547, Epoch Time 404.2555(405.9930), Bit/dim 3.7079(best: 3.7072), Xent 2.8566, Loss 5.1362, Error 0.4086(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4009 | Time 61.2815(60.7463) | Bit/dim 3.6706(3.6837) | Xent 0.0751(0.0741) | Loss 3.7081(3.7207) | Error 0.0251(0.0245) Steps 682(674.73) | Grad Norm 2.2292(2.2056) | Total Time 14.00(14.00)\n",
      "Iter 4010 | Time 59.0315(60.6949) | Bit/dim 3.6850(3.6837) | Xent 0.0653(0.0738) | Loss 3.7177(3.7206) | Error 0.0221(0.0245) Steps 688(675.13) | Grad Norm 2.0592(2.2012) | Total Time 14.00(14.00)\n",
      "Iter 4011 | Time 58.4932(60.6288) | Bit/dim 3.6837(3.6837) | Xent 0.0629(0.0735) | Loss 3.7152(3.7205) | Error 0.0190(0.0243) Steps 676(675.16) | Grad Norm 1.8305(2.1901) | Total Time 14.00(14.00)\n",
      "Iter 4012 | Time 59.8118(60.6043) | Bit/dim 3.6834(3.6837) | Xent 0.0627(0.0732) | Loss 3.7148(3.7203) | Error 0.0199(0.0242) Steps 676(675.18) | Grad Norm 1.8291(2.1792) | Total Time 14.00(14.00)\n",
      "Iter 4013 | Time 60.9483(60.6146) | Bit/dim 3.6877(3.6838) | Xent 0.0764(0.0732) | Loss 3.7259(3.7205) | Error 0.0249(0.0242) Steps 682(675.39) | Grad Norm 2.2654(2.1818) | Total Time 14.00(14.00)\n",
      "Iter 4014 | Time 58.9576(60.5649) | Bit/dim 3.6880(3.6840) | Xent 0.0691(0.0731) | Loss 3.7225(3.7205) | Error 0.0222(0.0241) Steps 676(675.41) | Grad Norm 1.3524(2.1569) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0669 | Time 24.8153, Epoch Time 399.1313(405.7871), Bit/dim 3.7074(best: 3.7072), Xent 2.8462, Loss 5.1306, Error 0.4075(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4015 | Time 60.2806(60.5564) | Bit/dim 3.6817(3.6839) | Xent 0.0686(0.0730) | Loss 3.7160(3.7204) | Error 0.0235(0.0241) Steps 670(675.24) | Grad Norm 2.0153(2.1527) | Total Time 14.00(14.00)\n",
      "Iter 4016 | Time 58.0716(60.4819) | Bit/dim 3.6885(3.6840) | Xent 0.0793(0.0732) | Loss 3.7281(3.7206) | Error 0.0286(0.0243) Steps 682(675.45) | Grad Norm 1.8262(2.1429) | Total Time 14.00(14.00)\n",
      "Iter 4017 | Time 58.1860(60.4130) | Bit/dim 3.6901(3.6842) | Xent 0.0784(0.0733) | Loss 3.7294(3.7209) | Error 0.0242(0.0243) Steps 664(675.10) | Grad Norm 1.5536(2.1252) | Total Time 14.00(14.00)\n",
      "Iter 4018 | Time 63.7808(60.5140) | Bit/dim 3.6725(3.6839) | Xent 0.0710(0.0733) | Loss 3.7080(3.7205) | Error 0.0224(0.0242) Steps 670(674.95) | Grad Norm 1.7283(2.1133) | Total Time 14.00(14.00)\n",
      "Iter 4019 | Time 62.2328(60.5656) | Bit/dim 3.6741(3.6836) | Xent 0.0724(0.0732) | Loss 3.7103(3.7202) | Error 0.0236(0.0242) Steps 694(675.52) | Grad Norm 1.8006(2.1039) | Total Time 14.00(14.00)\n",
      "Iter 4020 | Time 59.3562(60.5293) | Bit/dim 3.6864(3.6837) | Xent 0.0813(0.0735) | Loss 3.7270(3.7204) | Error 0.0268(0.0243) Steps 682(675.72) | Grad Norm 1.6637(2.0907) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0670 | Time 24.9491, Epoch Time 402.7350(405.6956), Bit/dim 3.7073(best: 3.7072), Xent 2.8065, Loss 5.1105, Error 0.4047(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4021 | Time 59.6524(60.5030) | Bit/dim 3.6858(3.6837) | Xent 0.0733(0.0735) | Loss 3.7224(3.7205) | Error 0.0221(0.0242) Steps 670(675.54) | Grad Norm 1.4953(2.0729) | Total Time 14.00(14.00)\n",
      "Iter 4022 | Time 60.0874(60.4905) | Bit/dim 3.6771(3.6835) | Xent 0.0648(0.0732) | Loss 3.7095(3.7201) | Error 0.0192(0.0240) Steps 676(675.56) | Grad Norm 1.0701(2.0428) | Total Time 14.00(14.00)\n",
      "Iter 4023 | Time 61.9489(60.5343) | Bit/dim 3.6819(3.6835) | Xent 0.0785(0.0734) | Loss 3.7212(3.7202) | Error 0.0259(0.0241) Steps 676(675.57) | Grad Norm 2.5704(2.0586) | Total Time 14.00(14.00)\n",
      "Iter 4024 | Time 59.8398(60.5134) | Bit/dim 3.6767(3.6833) | Xent 0.0711(0.0733) | Loss 3.7122(3.7199) | Error 0.0228(0.0241) Steps 676(675.58) | Grad Norm 1.8951(2.0537) | Total Time 14.00(14.00)\n",
      "Iter 4025 | Time 59.8089(60.4923) | Bit/dim 3.6825(3.6832) | Xent 0.0696(0.0732) | Loss 3.7173(3.7198) | Error 0.0231(0.0240) Steps 670(675.42) | Grad Norm 2.3203(2.0617) | Total Time 14.00(14.00)\n",
      "Iter 4026 | Time 58.9010(60.4446) | Bit/dim 3.6916(3.6835) | Xent 0.0695(0.0731) | Loss 3.7263(3.7200) | Error 0.0245(0.0240) Steps 682(675.61) | Grad Norm 2.1743(2.0651) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0671 | Time 24.9255, Epoch Time 400.5522(405.5413), Bit/dim 3.7077(best: 3.7072), Xent 2.8670, Loss 5.1412, Error 0.4058(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4027 | Time 61.1448(60.4656) | Bit/dim 3.6737(3.6832) | Xent 0.0817(0.0733) | Loss 3.7146(3.7199) | Error 0.0261(0.0241) Steps 688(675.99) | Grad Norm 1.8669(2.0591) | Total Time 14.00(14.00)\n",
      "Iter 4028 | Time 60.1903(60.4573) | Bit/dim 3.6901(3.6834) | Xent 0.0816(0.0736) | Loss 3.7309(3.7202) | Error 0.0271(0.0242) Steps 676(675.99) | Grad Norm 1.8179(2.0519) | Total Time 14.00(14.00)\n",
      "Iter 4029 | Time 59.4227(60.4263) | Bit/dim 3.6832(3.6834) | Xent 0.0716(0.0735) | Loss 3.7190(3.7202) | Error 0.0225(0.0241) Steps 682(676.17) | Grad Norm 1.1623(2.0252) | Total Time 14.00(14.00)\n",
      "Iter 4030 | Time 59.5559(60.4002) | Bit/dim 3.6873(3.6835) | Xent 0.0681(0.0734) | Loss 3.7214(3.7202) | Error 0.0228(0.0241) Steps 670(675.98) | Grad Norm 1.5504(2.0110) | Total Time 14.00(14.00)\n",
      "Iter 4031 | Time 63.3999(60.4902) | Bit/dim 3.6845(3.6835) | Xent 0.0768(0.0735) | Loss 3.7229(3.7203) | Error 0.0238(0.0241) Steps 652(675.26) | Grad Norm 2.1722(2.0158) | Total Time 14.00(14.00)\n",
      "Iter 4032 | Time 59.0323(60.4464) | Bit/dim 3.6855(3.6836) | Xent 0.0655(0.0732) | Loss 3.7183(3.7202) | Error 0.0224(0.0240) Steps 676(675.28) | Grad Norm 2.2679(2.0234) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0672 | Time 25.0963, Epoch Time 403.5833(405.4825), Bit/dim 3.7077(best: 3.7072), Xent 2.8137, Loss 5.1145, Error 0.4073(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4033 | Time 62.7926(60.5168) | Bit/dim 3.6771(3.6834) | Xent 0.0692(0.0731) | Loss 3.7116(3.7200) | Error 0.0205(0.0239) Steps 688(675.67) | Grad Norm 1.5227(2.0083) | Total Time 14.00(14.00)\n",
      "Iter 4034 | Time 62.7991(60.5853) | Bit/dim 3.6858(3.6835) | Xent 0.0704(0.0730) | Loss 3.7209(3.7200) | Error 0.0225(0.0239) Steps 670(675.50) | Grad Norm 1.8326(2.0031) | Total Time 14.00(14.00)\n",
      "Iter 4035 | Time 62.0729(60.6299) | Bit/dim 3.6855(3.6835) | Xent 0.0717(0.0730) | Loss 3.7213(3.7200) | Error 0.0240(0.0239) Steps 670(675.33) | Grad Norm 1.9975(2.0029) | Total Time 14.00(14.00)\n",
      "Iter 4036 | Time 62.4926(60.6858) | Bit/dim 3.6889(3.6837) | Xent 0.0711(0.0729) | Loss 3.7245(3.7202) | Error 0.0249(0.0239) Steps 676(675.35) | Grad Norm 1.5031(1.9879) | Total Time 14.00(14.00)\n",
      "Iter 4037 | Time 62.6950(60.7461) | Bit/dim 3.6786(3.6835) | Xent 0.0680(0.0728) | Loss 3.7125(3.7199) | Error 0.0231(0.0239) Steps 682(675.55) | Grad Norm 2.3771(1.9996) | Total Time 14.00(14.00)\n",
      "Iter 4038 | Time 62.6550(60.8033) | Bit/dim 3.6847(3.6836) | Xent 0.0807(0.0730) | Loss 3.7250(3.7201) | Error 0.0258(0.0240) Steps 676(675.56) | Grad Norm 2.2818(2.0081) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0673 | Time 24.8962, Epoch Time 416.1494(405.8025), Bit/dim 3.7081(best: 3.7072), Xent 2.8113, Loss 5.1137, Error 0.4093(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4039 | Time 59.8697(60.7753) | Bit/dim 3.6738(3.6833) | Xent 0.0761(0.0731) | Loss 3.7118(3.7198) | Error 0.0254(0.0240) Steps 670(675.40) | Grad Norm 2.0879(2.0104) | Total Time 14.00(14.00)\n",
      "Iter 4040 | Time 60.5196(60.7677) | Bit/dim 3.6839(3.6833) | Xent 0.0705(0.0730) | Loss 3.7192(3.7198) | Error 0.0241(0.0240) Steps 676(675.41) | Grad Norm 2.2156(2.0166) | Total Time 14.00(14.00)\n",
      "Iter 4041 | Time 59.8100(60.7389) | Bit/dim 3.6905(3.6835) | Xent 0.0692(0.0729) | Loss 3.7251(3.7200) | Error 0.0228(0.0240) Steps 682(675.61) | Grad Norm 1.1834(1.9916) | Total Time 14.00(14.00)\n",
      "Iter 4042 | Time 62.1661(60.7817) | Bit/dim 3.6841(3.6835) | Xent 0.0729(0.0729) | Loss 3.7206(3.7200) | Error 0.0236(0.0240) Steps 658(675.08) | Grad Norm 2.4335(2.0049) | Total Time 14.00(14.00)\n",
      "Iter 4043 | Time 59.8259(60.7531) | Bit/dim 3.6845(3.6836) | Xent 0.0714(0.0729) | Loss 3.7202(3.7200) | Error 0.0231(0.0239) Steps 670(674.93) | Grad Norm 2.1481(2.0092) | Total Time 14.00(14.00)\n",
      "Iter 4044 | Time 62.6863(60.8111) | Bit/dim 3.6799(3.6835) | Xent 0.0732(0.0729) | Loss 3.7165(3.7199) | Error 0.0245(0.0239) Steps 676(674.96) | Grad Norm 1.8658(2.0049) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0674 | Time 25.3660, Epoch Time 406.0809(405.8109), Bit/dim 3.7071(best: 3.7072), Xent 2.8440, Loss 5.1291, Error 0.4041(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4045 | Time 63.3364(60.8868) | Bit/dim 3.6828(3.6834) | Xent 0.0742(0.0729) | Loss 3.7199(3.7199) | Error 0.0261(0.0240) Steps 670(674.81) | Grad Norm 2.1620(2.0096) | Total Time 14.00(14.00)\n",
      "Iter 4046 | Time 61.4927(60.9050) | Bit/dim 3.6866(3.6835) | Xent 0.0743(0.0730) | Loss 3.7237(3.7200) | Error 0.0264(0.0241) Steps 670(674.67) | Grad Norm 3.2087(2.0455) | Total Time 14.00(14.00)\n",
      "Iter 4047 | Time 62.1529(60.9424) | Bit/dim 3.6832(3.6835) | Xent 0.0671(0.0728) | Loss 3.7167(3.7199) | Error 0.0202(0.0240) Steps 676(674.71) | Grad Norm 1.5677(2.0312) | Total Time 14.00(14.00)\n",
      "Iter 4048 | Time 62.3275(60.9840) | Bit/dim 3.6789(3.6834) | Xent 0.0730(0.0728) | Loss 3.7154(3.7198) | Error 0.0251(0.0240) Steps 676(674.75) | Grad Norm 2.0896(2.0330) | Total Time 14.00(14.00)\n",
      "Iter 4049 | Time 63.2072(61.0507) | Bit/dim 3.6801(3.6833) | Xent 0.0738(0.0728) | Loss 3.7170(3.7197) | Error 0.0255(0.0240) Steps 682(674.97) | Grad Norm 2.1024(2.0350) | Total Time 14.00(14.00)\n",
      "Iter 4050 | Time 63.9809(61.1386) | Bit/dim 3.6883(3.6834) | Xent 0.0629(0.0725) | Loss 3.7197(3.7197) | Error 0.0220(0.0240) Steps 676(675.00) | Grad Norm 1.1001(2.0070) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0675 | Time 25.1836, Epoch Time 417.8746(406.1728), Bit/dim 3.7075(best: 3.7071), Xent 2.8548, Loss 5.1350, Error 0.4044(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4051 | Time 59.0174(61.0749) | Bit/dim 3.6741(3.6832) | Xent 0.0767(0.0727) | Loss 3.7124(3.7195) | Error 0.0245(0.0240) Steps 682(675.21) | Grad Norm 1.6213(1.9954) | Total Time 14.00(14.00)\n",
      "Iter 4052 | Time 60.7720(61.0659) | Bit/dim 3.6855(3.6832) | Xent 0.0696(0.0726) | Loss 3.7203(3.7195) | Error 0.0228(0.0240) Steps 676(675.23) | Grad Norm 1.5279(1.9814) | Total Time 14.00(14.00)\n",
      "Iter 4053 | Time 62.2793(61.1023) | Bit/dim 3.6823(3.6832) | Xent 0.0688(0.0724) | Loss 3.7167(3.7194) | Error 0.0212(0.0239) Steps 664(674.89) | Grad Norm 1.5175(1.9675) | Total Time 14.00(14.00)\n",
      "Iter 4054 | Time 58.3082(61.0184) | Bit/dim 3.6857(3.6833) | Xent 0.0702(0.0724) | Loss 3.7208(3.7195) | Error 0.0232(0.0239) Steps 676(674.93) | Grad Norm 1.7826(1.9619) | Total Time 14.00(14.00)\n",
      "Iter 4055 | Time 57.7870(60.9215) | Bit/dim 3.6889(3.6834) | Xent 0.0687(0.0723) | Loss 3.7233(3.7196) | Error 0.0215(0.0238) Steps 676(674.96) | Grad Norm 1.5044(1.9482) | Total Time 14.00(14.00)\n",
      "Iter 4056 | Time 60.5172(60.9094) | Bit/dim 3.6846(3.6835) | Xent 0.0688(0.0722) | Loss 3.7191(3.7196) | Error 0.0235(0.0238) Steps 676(674.99) | Grad Norm 2.3920(1.9615) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0676 | Time 25.1044, Epoch Time 399.6044(405.9758), Bit/dim 3.7088(best: 3.7071), Xent 2.8374, Loss 5.1275, Error 0.4062(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4057 | Time 60.6014(60.9001) | Bit/dim 3.6872(3.6836) | Xent 0.0624(0.0719) | Loss 3.7183(3.7195) | Error 0.0200(0.0237) Steps 682(675.20) | Grad Norm 1.5429(1.9490) | Total Time 14.00(14.00)\n",
      "Iter 4058 | Time 60.2227(60.8798) | Bit/dim 3.6830(3.6836) | Xent 0.0767(0.0720) | Loss 3.7213(3.7196) | Error 0.0261(0.0237) Steps 688(675.59) | Grad Norm 1.3292(1.9304) | Total Time 14.00(14.00)\n",
      "Iter 4059 | Time 63.7314(60.9654) | Bit/dim 3.6835(3.6836) | Xent 0.0665(0.0719) | Loss 3.7168(3.7195) | Error 0.0229(0.0237) Steps 676(675.60) | Grad Norm 1.8225(1.9271) | Total Time 14.00(14.00)\n",
      "Iter 4060 | Time 62.1067(60.9996) | Bit/dim 3.6860(3.6836) | Xent 0.0694(0.0718) | Loss 3.7207(3.7195) | Error 0.0232(0.0237) Steps 694(676.15) | Grad Norm 1.7177(1.9209) | Total Time 14.00(14.00)\n",
      "Iter 4061 | Time 60.1889(60.9753) | Bit/dim 3.6849(3.6837) | Xent 0.0672(0.0716) | Loss 3.7185(3.7195) | Error 0.0216(0.0236) Steps 688(676.51) | Grad Norm 1.8106(1.9175) | Total Time 14.00(14.00)\n",
      "Iter 4062 | Time 60.0757(60.9483) | Bit/dim 3.6751(3.6834) | Xent 0.0703(0.0716) | Loss 3.7103(3.7192) | Error 0.0221(0.0236) Steps 682(676.67) | Grad Norm 1.4671(1.9040) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0677 | Time 24.7826, Epoch Time 407.6323(406.0254), Bit/dim 3.7074(best: 3.7071), Xent 2.8646, Loss 5.1397, Error 0.4059(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4063 | Time 58.4466(60.8732) | Bit/dim 3.6795(3.6833) | Xent 0.0743(0.0717) | Loss 3.7167(3.7191) | Error 0.0256(0.0237) Steps 676(676.65) | Grad Norm 1.4986(1.8919) | Total Time 14.00(14.00)\n",
      "Iter 4064 | Time 62.2126(60.9134) | Bit/dim 3.6821(3.6833) | Xent 0.0644(0.0715) | Loss 3.7143(3.7190) | Error 0.0210(0.0236) Steps 676(676.63) | Grad Norm 1.3287(1.8750) | Total Time 14.00(14.00)\n",
      "Iter 4065 | Time 58.9351(60.8541) | Bit/dim 3.6932(3.6836) | Xent 0.0663(0.0713) | Loss 3.7263(3.7192) | Error 0.0205(0.0235) Steps 670(676.43) | Grad Norm 1.2093(1.8550) | Total Time 14.00(14.00)\n",
      "Iter 4066 | Time 59.6857(60.8190) | Bit/dim 3.6815(3.6835) | Xent 0.0672(0.0712) | Loss 3.7151(3.7191) | Error 0.0212(0.0234) Steps 682(676.60) | Grad Norm 2.2572(1.8671) | Total Time 14.00(14.00)\n",
      "Iter 4067 | Time 64.3548(60.9251) | Bit/dim 3.6817(3.6834) | Xent 0.0760(0.0713) | Loss 3.7197(3.7191) | Error 0.0240(0.0234) Steps 682(676.76) | Grad Norm 1.5348(1.8571) | Total Time 14.00(14.00)\n",
      "Iter 4068 | Time 58.9787(60.8667) | Bit/dim 3.6811(3.6834) | Xent 0.0702(0.0713) | Loss 3.7162(3.7190) | Error 0.0225(0.0234) Steps 676(676.74) | Grad Norm 1.3140(1.8408) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0678 | Time 24.9071, Epoch Time 403.4088(405.9469), Bit/dim 3.7065(best: 3.7071), Xent 2.8758, Loss 5.1444, Error 0.4101(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4069 | Time 59.3022(60.8198) | Bit/dim 3.6924(3.6836) | Xent 0.0729(0.0713) | Loss 3.7288(3.7193) | Error 0.0258(0.0235) Steps 676(676.72) | Grad Norm 2.6756(1.8659) | Total Time 14.00(14.00)\n",
      "Iter 4070 | Time 60.8417(60.8204) | Bit/dim 3.6713(3.6833) | Xent 0.0729(0.0714) | Loss 3.7078(3.7190) | Error 0.0246(0.0235) Steps 676(676.69) | Grad Norm 1.7555(1.8625) | Total Time 14.00(14.00)\n",
      "Iter 4071 | Time 58.6858(60.7564) | Bit/dim 3.6771(3.6831) | Xent 0.0674(0.0713) | Loss 3.7108(3.7187) | Error 0.0221(0.0235) Steps 682(676.85) | Grad Norm 2.3722(1.8778) | Total Time 14.00(14.00)\n",
      "Iter 4072 | Time 61.2135(60.7701) | Bit/dim 3.6907(3.6833) | Xent 0.0697(0.0712) | Loss 3.7256(3.7189) | Error 0.0238(0.0235) Steps 676(676.83) | Grad Norm 2.0165(1.8820) | Total Time 14.00(14.00)\n",
      "Iter 4073 | Time 61.4218(60.7897) | Bit/dim 3.6865(3.6834) | Xent 0.0680(0.0711) | Loss 3.7205(3.7190) | Error 0.0238(0.0235) Steps 688(677.16) | Grad Norm 1.7228(1.8772) | Total Time 14.00(14.00)\n",
      "Iter 4074 | Time 59.9366(60.7641) | Bit/dim 3.6735(3.6831) | Xent 0.0661(0.0710) | Loss 3.7065(3.7186) | Error 0.0226(0.0235) Steps 694(677.67) | Grad Norm 2.1899(1.8866) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0679 | Time 24.8825, Epoch Time 402.4140(405.8410), Bit/dim 3.7077(best: 3.7065), Xent 2.8526, Loss 5.1340, Error 0.4083(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4075 | Time 57.6277(60.6700) | Bit/dim 3.6874(3.6832) | Xent 0.0684(0.0709) | Loss 3.7216(3.7187) | Error 0.0220(0.0234) Steps 682(677.80) | Grad Norm 1.5512(1.8765) | Total Time 14.00(14.00)\n",
      "Iter 4076 | Time 61.6914(60.7006) | Bit/dim 3.6817(3.6832) | Xent 0.0798(0.0712) | Loss 3.7216(3.7188) | Error 0.0260(0.0235) Steps 682(677.92) | Grad Norm 1.6256(1.8690) | Total Time 14.00(14.00)\n",
      "Iter 4077 | Time 61.6151(60.7280) | Bit/dim 3.6821(3.6832) | Xent 0.0668(0.0710) | Loss 3.7155(3.7187) | Error 0.0220(0.0235) Steps 694(678.41) | Grad Norm 1.2528(1.8505) | Total Time 14.00(14.00)\n",
      "Iter 4078 | Time 60.6925(60.7270) | Bit/dim 3.6847(3.6832) | Xent 0.0704(0.0710) | Loss 3.7199(3.7187) | Error 0.0232(0.0234) Steps 688(678.69) | Grad Norm 1.6305(1.8439) | Total Time 14.00(14.00)\n",
      "Iter 4079 | Time 61.9950(60.7650) | Bit/dim 3.6871(3.6833) | Xent 0.0776(0.0712) | Loss 3.7259(3.7189) | Error 0.0255(0.0235) Steps 670(678.43) | Grad Norm 1.6389(1.8378) | Total Time 14.00(14.00)\n",
      "Iter 4080 | Time 59.3546(60.7227) | Bit/dim 3.6732(3.6830) | Xent 0.0755(0.0713) | Loss 3.7109(3.7187) | Error 0.0252(0.0236) Steps 676(678.36) | Grad Norm 1.7924(1.8364) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0680 | Time 24.7546, Epoch Time 403.5144(405.7712), Bit/dim 3.7069(best: 3.7065), Xent 2.8837, Loss 5.1487, Error 0.4106(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4081 | Time 60.2962(60.7099) | Bit/dim 3.6783(3.6829) | Xent 0.0757(0.0715) | Loss 3.7161(3.7186) | Error 0.0234(0.0236) Steps 676(678.29) | Grad Norm 1.5411(1.8275) | Total Time 14.00(14.00)\n",
      "Iter 4082 | Time 59.9404(60.6868) | Bit/dim 3.6885(3.6830) | Xent 0.0748(0.0716) | Loss 3.7259(3.7188) | Error 0.0259(0.0236) Steps 670(678.04) | Grad Norm 1.9050(1.8299) | Total Time 14.00(14.00)\n",
      "Iter 4083 | Time 60.9304(60.6941) | Bit/dim 3.6856(3.6831) | Xent 0.0679(0.0715) | Loss 3.7195(3.7189) | Error 0.0229(0.0236) Steps 670(677.80) | Grad Norm 3.1722(1.8701) | Total Time 14.00(14.00)\n",
      "Iter 4084 | Time 61.0475(60.7047) | Bit/dim 3.6771(3.6829) | Xent 0.0673(0.0713) | Loss 3.7107(3.7186) | Error 0.0234(0.0236) Steps 664(677.39) | Grad Norm 1.7821(1.8675) | Total Time 14.00(14.00)\n",
      "Iter 4085 | Time 59.0463(60.6550) | Bit/dim 3.6847(3.6830) | Xent 0.0706(0.0713) | Loss 3.7200(3.7187) | Error 0.0229(0.0236) Steps 664(676.98) | Grad Norm 1.7954(1.8653) | Total Time 14.00(14.00)\n",
      "Iter 4086 | Time 59.5010(60.6204) | Bit/dim 3.6800(3.6829) | Xent 0.0764(0.0715) | Loss 3.7183(3.7186) | Error 0.0258(0.0236) Steps 670(676.77) | Grad Norm 4.0581(1.9311) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0681 | Time 25.0546, Epoch Time 401.5512(405.6446), Bit/dim 3.7062(best: 3.7065), Xent 2.8208, Loss 5.1166, Error 0.4065(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4087 | Time 58.2268(60.5486) | Bit/dim 3.6901(3.6831) | Xent 0.0625(0.0712) | Loss 3.7214(3.7187) | Error 0.0220(0.0236) Steps 670(676.57) | Grad Norm 2.3225(1.9429) | Total Time 14.00(14.00)\n",
      "Iter 4088 | Time 58.8659(60.4981) | Bit/dim 3.6755(3.6829) | Xent 0.0762(0.0714) | Loss 3.7136(3.7186) | Error 0.0241(0.0236) Steps 670(676.37) | Grad Norm 1.8016(1.9386) | Total Time 14.00(14.00)\n",
      "Iter 4089 | Time 60.2388(60.4903) | Bit/dim 3.6900(3.6831) | Xent 0.0740(0.0714) | Loss 3.7270(3.7188) | Error 0.0255(0.0237) Steps 664(676.00) | Grad Norm 3.4965(1.9854) | Total Time 14.00(14.00)\n",
      "Iter 4090 | Time 60.6887(60.4963) | Bit/dim 3.6798(3.6830) | Xent 0.0739(0.0715) | Loss 3.7168(3.7188) | Error 0.0239(0.0237) Steps 676(676.00) | Grad Norm 2.1241(1.9895) | Total Time 14.00(14.00)\n",
      "Iter 4091 | Time 60.4988(60.4963) | Bit/dim 3.6780(3.6829) | Xent 0.0714(0.0715) | Loss 3.7137(3.7186) | Error 0.0235(0.0237) Steps 670(675.82) | Grad Norm 2.1456(1.9942) | Total Time 14.00(14.00)\n",
      "Iter 4092 | Time 61.9573(60.5402) | Bit/dim 3.6873(3.6830) | Xent 0.0710(0.0715) | Loss 3.7227(3.7187) | Error 0.0229(0.0236) Steps 676(675.83) | Grad Norm 2.8796(2.0208) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0682 | Time 25.4663, Epoch Time 401.6438(405.5245), Bit/dim 3.7065(best: 3.7062), Xent 2.8107, Loss 5.1118, Error 0.4068(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4093 | Time 59.2558(60.5016) | Bit/dim 3.6898(3.6832) | Xent 0.0608(0.0712) | Loss 3.7202(3.7188) | Error 0.0194(0.0235) Steps 664(675.47) | Grad Norm 1.2520(1.9977) | Total Time 14.00(14.00)\n",
      "Iter 4094 | Time 61.7663(60.5396) | Bit/dim 3.6831(3.6832) | Xent 0.0781(0.0714) | Loss 3.7221(3.7189) | Error 0.0256(0.0236) Steps 682(675.67) | Grad Norm 1.9260(1.9956) | Total Time 14.00(14.00)\n",
      "Iter 4095 | Time 59.2454(60.5007) | Bit/dim 3.6836(3.6832) | Xent 0.0642(0.0712) | Loss 3.7157(3.7188) | Error 0.0215(0.0235) Steps 682(675.86) | Grad Norm 1.2895(1.9744) | Total Time 14.00(14.00)\n",
      "Iter 4096 | Time 60.8197(60.5103) | Bit/dim 3.6666(3.6827) | Xent 0.0706(0.0711) | Loss 3.7019(3.7183) | Error 0.0248(0.0235) Steps 676(675.86) | Grad Norm 1.3100(1.9544) | Total Time 14.00(14.00)\n",
      "Iter 4097 | Time 61.0960(60.5279) | Bit/dim 3.6835(3.6827) | Xent 0.0654(0.0710) | Loss 3.7162(3.7182) | Error 0.0210(0.0235) Steps 676(675.87) | Grad Norm 1.9309(1.9537) | Total Time 14.00(14.00)\n",
      "Iter 4098 | Time 60.5255(60.5278) | Bit/dim 3.6849(3.6828) | Xent 0.0748(0.0711) | Loss 3.7223(3.7183) | Error 0.0238(0.0235) Steps 670(675.69) | Grad Norm 2.3404(1.9653) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0683 | Time 24.9679, Epoch Time 403.3129(405.4582), Bit/dim 3.7062(best: 3.7062), Xent 2.8746, Loss 5.1435, Error 0.4055(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4099 | Time 58.6753(60.4722) | Bit/dim 3.6940(3.6831) | Xent 0.0695(0.0710) | Loss 3.7287(3.7187) | Error 0.0232(0.0235) Steps 688(676.06) | Grad Norm 1.8634(1.9623) | Total Time 14.00(14.00)\n",
      "Iter 4100 | Time 57.7804(60.3915) | Bit/dim 3.6719(3.6828) | Xent 0.0761(0.0712) | Loss 3.7100(3.7184) | Error 0.0262(0.0236) Steps 676(676.06) | Grad Norm 3.2354(2.0005) | Total Time 14.00(14.00)\n",
      "Iter 4101 | Time 59.8275(60.3746) | Bit/dim 3.6777(3.6826) | Xent 0.0720(0.0712) | Loss 3.7137(3.7183) | Error 0.0252(0.0236) Steps 676(676.06) | Grad Norm 1.5231(1.9861) | Total Time 14.00(14.00)\n",
      "Iter 4102 | Time 61.0132(60.3937) | Bit/dim 3.6835(3.6827) | Xent 0.0736(0.0713) | Loss 3.7203(3.7183) | Error 0.0216(0.0235) Steps 694(676.60) | Grad Norm 2.5350(2.0026) | Total Time 14.00(14.00)\n",
      "Iter 4103 | Time 61.5229(60.4276) | Bit/dim 3.6844(3.6827) | Xent 0.0671(0.0712) | Loss 3.7180(3.7183) | Error 0.0231(0.0235) Steps 682(676.76) | Grad Norm 2.4940(2.0174) | Total Time 14.00(14.00)\n",
      "Iter 4104 | Time 61.2387(60.4519) | Bit/dim 3.6795(3.6826) | Xent 0.0674(0.0710) | Loss 3.7131(3.7181) | Error 0.0225(0.0235) Steps 676(676.73) | Grad Norm 1.8949(2.0137) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0684 | Time 25.1911, Epoch Time 401.1434(405.3287), Bit/dim 3.7069(best: 3.7062), Xent 2.8716, Loss 5.1427, Error 0.4108(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4105 | Time 62.0804(60.5008) | Bit/dim 3.6784(3.6825) | Xent 0.0679(0.0710) | Loss 3.7124(3.7180) | Error 0.0241(0.0235) Steps 676(676.71) | Grad Norm 2.3269(2.0231) | Total Time 14.00(14.00)\n",
      "Iter 4106 | Time 60.1092(60.4890) | Bit/dim 3.6762(3.6823) | Xent 0.0687(0.0709) | Loss 3.7106(3.7178) | Error 0.0221(0.0235) Steps 682(676.87) | Grad Norm 2.3457(2.0328) | Total Time 14.00(14.00)\n",
      "Iter 4107 | Time 60.3885(60.4860) | Bit/dim 3.6956(3.6827) | Xent 0.0678(0.0708) | Loss 3.7295(3.7181) | Error 0.0225(0.0235) Steps 670(676.67) | Grad Norm 2.1157(2.0352) | Total Time 14.00(14.00)\n",
      "Iter 4108 | Time 60.8942(60.4983) | Bit/dim 3.6873(3.6828) | Xent 0.0701(0.0708) | Loss 3.7223(3.7182) | Error 0.0216(0.0234) Steps 694(677.19) | Grad Norm 1.2447(2.0115) | Total Time 14.00(14.00)\n",
      "Iter 4109 | Time 59.7949(60.4772) | Bit/dim 3.6803(3.6828) | Xent 0.0654(0.0706) | Loss 3.7130(3.7181) | Error 0.0236(0.0234) Steps 676(677.15) | Grad Norm 1.5600(1.9980) | Total Time 14.00(14.00)\n",
      "Iter 4110 | Time 60.8024(60.4869) | Bit/dim 3.6765(3.6826) | Xent 0.0728(0.0707) | Loss 3.7129(3.7179) | Error 0.0248(0.0234) Steps 688(677.48) | Grad Norm 1.7432(1.9903) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0685 | Time 25.1377, Epoch Time 405.0194(405.3195), Bit/dim 3.7075(best: 3.7062), Xent 2.8715, Loss 5.1432, Error 0.4046(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4111 | Time 61.6238(60.5210) | Bit/dim 3.6822(3.6826) | Xent 0.0706(0.0707) | Loss 3.7175(3.7179) | Error 0.0234(0.0234) Steps 676(677.43) | Grad Norm 1.9381(1.9888) | Total Time 14.00(14.00)\n",
      "Iter 4112 | Time 61.0046(60.5355) | Bit/dim 3.6875(3.6827) | Xent 0.0624(0.0704) | Loss 3.7187(3.7179) | Error 0.0221(0.0234) Steps 676(677.39) | Grad Norm 1.4461(1.9725) | Total Time 14.00(14.00)\n",
      "Iter 4113 | Time 59.7635(60.5124) | Bit/dim 3.6828(3.6827) | Xent 0.0682(0.0704) | Loss 3.7169(3.7179) | Error 0.0225(0.0234) Steps 670(677.17) | Grad Norm 1.4513(1.9569) | Total Time 14.00(14.00)\n",
      "Iter 4114 | Time 62.5419(60.5733) | Bit/dim 3.6764(3.6825) | Xent 0.0662(0.0702) | Loss 3.7095(3.7177) | Error 0.0201(0.0233) Steps 682(677.31) | Grad Norm 1.2227(1.9348) | Total Time 14.00(14.00)\n",
      "Iter 4115 | Time 63.9196(60.6736) | Bit/dim 3.6888(3.6827) | Xent 0.0677(0.0702) | Loss 3.7226(3.7178) | Error 0.0225(0.0233) Steps 682(677.45) | Grad Norm 1.7607(1.9296) | Total Time 14.00(14.00)\n",
      "Iter 4116 | Time 58.9555(60.6221) | Bit/dim 3.6754(3.6825) | Xent 0.0660(0.0700) | Loss 3.7084(3.7175) | Error 0.0216(0.0232) Steps 688(677.77) | Grad Norm 1.3226(1.9114) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0686 | Time 25.2974, Epoch Time 408.7932(405.4237), Bit/dim 3.7063(best: 3.7062), Xent 2.8510, Loss 5.1318, Error 0.4091(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4117 | Time 62.8175(60.6880) | Bit/dim 3.6799(3.6824) | Xent 0.0692(0.0700) | Loss 3.7145(3.7174) | Error 0.0230(0.0232) Steps 682(677.90) | Grad Norm 1.7621(1.9069) | Total Time 14.00(14.00)\n",
      "Iter 4118 | Time 59.0897(60.6400) | Bit/dim 3.6855(3.6825) | Xent 0.0687(0.0700) | Loss 3.7198(3.7175) | Error 0.0214(0.0231) Steps 670(677.66) | Grad Norm 1.4003(1.8917) | Total Time 14.00(14.00)\n",
      "Iter 4119 | Time 61.8064(60.6750) | Bit/dim 3.6732(3.6822) | Xent 0.0674(0.0699) | Loss 3.7068(3.7172) | Error 0.0220(0.0231) Steps 664(677.25) | Grad Norm 1.3461(1.8754) | Total Time 14.00(14.00)\n",
      "Iter 4120 | Time 62.0559(60.7164) | Bit/dim 3.6744(3.6820) | Xent 0.0615(0.0696) | Loss 3.7052(3.7168) | Error 0.0194(0.0230) Steps 676(677.21) | Grad Norm 1.4128(1.8615) | Total Time 14.00(14.00)\n",
      "Iter 4121 | Time 63.7828(60.8084) | Bit/dim 3.6879(3.6822) | Xent 0.0695(0.0696) | Loss 3.7226(3.7170) | Error 0.0230(0.0230) Steps 670(676.99) | Grad Norm 1.0021(1.8357) | Total Time 14.00(14.00)\n",
      "Iter 4122 | Time 60.9007(60.8112) | Bit/dim 3.6834(3.6822) | Xent 0.0661(0.0695) | Loss 3.7165(3.7170) | Error 0.0201(0.0229) Steps 670(676.79) | Grad Norm 1.6680(1.8307) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0687 | Time 24.7533, Epoch Time 411.3960(405.6028), Bit/dim 3.7074(best: 3.7062), Xent 2.8822, Loss 5.1486, Error 0.4074(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4123 | Time 58.9003(60.7539) | Bit/dim 3.6898(3.6824) | Xent 0.0740(0.0697) | Loss 3.7268(3.7173) | Error 0.0235(0.0229) Steps 676(676.76) | Grad Norm 2.4423(1.8490) | Total Time 14.00(14.00)\n",
      "Iter 4124 | Time 58.4499(60.6847) | Bit/dim 3.6875(3.6826) | Xent 0.0632(0.0695) | Loss 3.7191(3.7173) | Error 0.0215(0.0229) Steps 670(676.56) | Grad Norm 1.9983(1.8535) | Total Time 14.00(14.00)\n",
      "Iter 4125 | Time 60.2854(60.6728) | Bit/dim 3.6780(3.6825) | Xent 0.0646(0.0693) | Loss 3.7103(3.7171) | Error 0.0216(0.0228) Steps 676(676.54) | Grad Norm 2.1498(1.8624) | Total Time 14.00(14.00)\n",
      "Iter 4126 | Time 57.9214(60.5902) | Bit/dim 3.6742(3.6822) | Xent 0.0714(0.0694) | Loss 3.7099(3.7169) | Error 0.0236(0.0229) Steps 676(676.53) | Grad Norm 1.1874(1.8421) | Total Time 14.00(14.00)\n",
      "Iter 4127 | Time 61.2922(60.6113) | Bit/dim 3.6789(3.6821) | Xent 0.0726(0.0695) | Loss 3.7152(3.7168) | Error 0.0249(0.0229) Steps 670(676.33) | Grad Norm 2.4477(1.8603) | Total Time 14.00(14.00)\n",
      "Iter 4128 | Time 60.9630(60.6218) | Bit/dim 3.6807(3.6821) | Xent 0.0633(0.0693) | Loss 3.7123(3.7167) | Error 0.0209(0.0229) Steps 670(676.14) | Grad Norm 1.9697(1.8636) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0688 | Time 25.2019, Epoch Time 398.6759(405.3950), Bit/dim 3.7066(best: 3.7062), Xent 2.8720, Loss 5.1426, Error 0.4092(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4129 | Time 62.2386(60.6703) | Bit/dim 3.6876(3.6822) | Xent 0.0640(0.0691) | Loss 3.7196(3.7168) | Error 0.0222(0.0229) Steps 676(676.14) | Grad Norm 1.2699(1.8458) | Total Time 14.00(14.00)\n",
      "Iter 4130 | Time 60.4689(60.6643) | Bit/dim 3.6931(3.6826) | Xent 0.0731(0.0693) | Loss 3.7297(3.7172) | Error 0.0244(0.0229) Steps 670(675.95) | Grad Norm 2.7860(1.8740) | Total Time 14.00(14.00)\n",
      "Iter 4131 | Time 59.4480(60.6278) | Bit/dim 3.6715(3.6822) | Xent 0.0760(0.0695) | Loss 3.7095(3.7170) | Error 0.0258(0.0230) Steps 670(675.77) | Grad Norm 1.2856(1.8563) | Total Time 14.00(14.00)\n",
      "Iter 4132 | Time 57.9278(60.5468) | Bit/dim 3.6755(3.6820) | Xent 0.0727(0.0696) | Loss 3.7118(3.7168) | Error 0.0249(0.0230) Steps 664(675.42) | Grad Norm 2.2134(1.8670) | Total Time 14.00(14.00)\n",
      "Iter 4133 | Time 61.9242(60.5881) | Bit/dim 3.6869(3.6822) | Xent 0.0750(0.0697) | Loss 3.7244(3.7170) | Error 0.0230(0.0230) Steps 664(675.08) | Grad Norm 1.9883(1.8707) | Total Time 14.00(14.00)\n",
      "Iter 4134 | Time 61.4090(60.6128) | Bit/dim 3.6748(3.6819) | Xent 0.0706(0.0697) | Loss 3.7101(3.7168) | Error 0.0230(0.0230) Steps 676(675.11) | Grad Norm 1.5027(1.8596) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0689 | Time 24.9882, Epoch Time 403.9195(405.3508), Bit/dim 3.7076(best: 3.7062), Xent 2.8650, Loss 5.1401, Error 0.4063(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4135 | Time 59.4290(60.5772) | Bit/dim 3.6816(3.6819) | Xent 0.0706(0.0698) | Loss 3.7169(3.7168) | Error 0.0240(0.0231) Steps 682(675.31) | Grad Norm 2.2780(1.8722) | Total Time 14.00(14.00)\n",
      "Iter 4136 | Time 60.9412(60.5882) | Bit/dim 3.6767(3.6818) | Xent 0.0721(0.0698) | Loss 3.7128(3.7167) | Error 0.0230(0.0231) Steps 676(675.33) | Grad Norm 1.5938(1.8638) | Total Time 14.00(14.00)\n",
      "Iter 4137 | Time 61.3500(60.6110) | Bit/dim 3.6800(3.6817) | Xent 0.0648(0.0697) | Loss 3.7124(3.7166) | Error 0.0221(0.0230) Steps 664(674.99) | Grad Norm 1.0309(1.8388) | Total Time 14.00(14.00)\n",
      "Iter 4138 | Time 59.3799(60.5741) | Bit/dim 3.6840(3.6818) | Xent 0.0684(0.0697) | Loss 3.7182(3.7166) | Error 0.0238(0.0231) Steps 682(675.20) | Grad Norm 1.9766(1.8430) | Total Time 14.00(14.00)\n",
      "Iter 4139 | Time 58.6834(60.5174) | Bit/dim 3.6852(3.6819) | Xent 0.0772(0.0699) | Loss 3.7238(3.7168) | Error 0.0262(0.0232) Steps 682(675.41) | Grad Norm 1.7701(1.8408) | Total Time 14.00(14.00)\n",
      "Iter 4140 | Time 58.3534(60.4524) | Bit/dim 3.6820(3.6819) | Xent 0.0783(0.0701) | Loss 3.7212(3.7170) | Error 0.0256(0.0232) Steps 670(675.24) | Grad Norm 1.4945(1.8304) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0690 | Time 24.8875, Epoch Time 398.8972(405.1572), Bit/dim 3.7057(best: 3.7062), Xent 2.8206, Loss 5.1160, Error 0.4053(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4141 | Time 58.9912(60.4086) | Bit/dim 3.6883(3.6821) | Xent 0.0758(0.0703) | Loss 3.7262(3.7172) | Error 0.0242(0.0233) Steps 664(674.91) | Grad Norm 1.0840(1.8080) | Total Time 14.00(14.00)\n",
      "Iter 4142 | Time 59.9837(60.3959) | Bit/dim 3.6764(3.6819) | Xent 0.0650(0.0701) | Loss 3.7089(3.7170) | Error 0.0215(0.0232) Steps 664(674.58) | Grad Norm 2.0487(1.8152) | Total Time 14.00(14.00)\n",
      "Iter 4143 | Time 58.9821(60.3534) | Bit/dim 3.6787(3.6818) | Xent 0.0618(0.0699) | Loss 3.7096(3.7168) | Error 0.0212(0.0231) Steps 670(674.44) | Grad Norm 0.9742(1.7900) | Total Time 14.00(14.00)\n",
      "Iter 4144 | Time 61.0673(60.3749) | Bit/dim 3.6863(3.6820) | Xent 0.0709(0.0699) | Loss 3.7217(3.7169) | Error 0.0235(0.0232) Steps 688(674.85) | Grad Norm 2.0152(1.7968) | Total Time 14.00(14.00)\n",
      "Iter 4145 | Time 61.7045(60.4147) | Bit/dim 3.6800(3.6819) | Xent 0.0613(0.0697) | Loss 3.7106(3.7167) | Error 0.0214(0.0231) Steps 682(675.06) | Grad Norm 1.5102(1.7882) | Total Time 14.00(14.00)\n",
      "Iter 4146 | Time 61.2714(60.4404) | Bit/dim 3.6783(3.6818) | Xent 0.0687(0.0696) | Loss 3.7127(3.7166) | Error 0.0218(0.0231) Steps 664(674.73) | Grad Norm 1.4497(1.7780) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0691 | Time 25.0596, Epoch Time 402.9194(405.0900), Bit/dim 3.7061(best: 3.7057), Xent 2.8763, Loss 5.1443, Error 0.4064(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4147 | Time 60.6368(60.4463) | Bit/dim 3.6809(3.6818) | Xent 0.0712(0.0697) | Loss 3.7165(3.7166) | Error 0.0232(0.0231) Steps 670(674.59) | Grad Norm 1.2668(1.7627) | Total Time 14.00(14.00)\n",
      "Iter 4148 | Time 59.6433(60.4222) | Bit/dim 3.6774(3.6816) | Xent 0.0680(0.0696) | Loss 3.7114(3.7165) | Error 0.0224(0.0230) Steps 670(674.45) | Grad Norm 1.1914(1.7455) | Total Time 14.00(14.00)\n",
      "Iter 4149 | Time 62.7738(60.4928) | Bit/dim 3.6724(3.6814) | Xent 0.0637(0.0695) | Loss 3.7042(3.7161) | Error 0.0229(0.0230) Steps 676(674.50) | Grad Norm 2.0630(1.7551) | Total Time 14.00(14.00)\n",
      "Iter 4150 | Time 62.0967(60.5409) | Bit/dim 3.6945(3.6817) | Xent 0.0625(0.0692) | Loss 3.7257(3.7164) | Error 0.0216(0.0230) Steps 670(674.36) | Grad Norm 1.6533(1.7520) | Total Time 14.00(14.00)\n",
      "Iter 4151 | Time 59.2446(60.5020) | Bit/dim 3.6815(3.6817) | Xent 0.0747(0.0694) | Loss 3.7189(3.7164) | Error 0.0251(0.0231) Steps 676(674.41) | Grad Norm 1.8322(1.7544) | Total Time 14.00(14.00)\n",
      "Iter 4152 | Time 60.4755(60.5012) | Bit/dim 3.6837(3.6818) | Xent 0.0731(0.0695) | Loss 3.7202(3.7166) | Error 0.0240(0.0231) Steps 682(674.64) | Grad Norm 3.2034(1.7979) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0692 | Time 25.3046, Epoch Time 406.0567(405.1190), Bit/dim 3.7063(best: 3.7057), Xent 2.8659, Loss 5.1392, Error 0.4009(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4153 | Time 61.1316(60.5201) | Bit/dim 3.6820(3.6818) | Xent 0.0685(0.0695) | Loss 3.7163(3.7166) | Error 0.0220(0.0231) Steps 682(674.86) | Grad Norm 1.8237(1.7987) | Total Time 14.00(14.00)\n",
      "Iter 4154 | Time 60.6472(60.5239) | Bit/dim 3.6750(3.6816) | Xent 0.0714(0.0695) | Loss 3.7107(3.7164) | Error 0.0219(0.0230) Steps 694(675.44) | Grad Norm 3.3034(1.8438) | Total Time 14.00(14.00)\n",
      "Iter 4155 | Time 62.9662(60.5972) | Bit/dim 3.6886(3.6818) | Xent 0.0690(0.0695) | Loss 3.7231(3.7166) | Error 0.0221(0.0230) Steps 670(675.27) | Grad Norm 1.3281(1.8283) | Total Time 14.00(14.00)\n",
      "Iter 4156 | Time 59.8899(60.5760) | Bit/dim 3.6858(3.6819) | Xent 0.0661(0.0694) | Loss 3.7189(3.7167) | Error 0.0211(0.0229) Steps 670(675.11) | Grad Norm 1.4909(1.8182) | Total Time 14.00(14.00)\n",
      "Iter 4157 | Time 61.1860(60.5943) | Bit/dim 3.6840(3.6820) | Xent 0.0766(0.0696) | Loss 3.7223(3.7168) | Error 0.0241(0.0230) Steps 676(675.14) | Grad Norm 3.7379(1.8758) | Total Time 14.00(14.00)\n",
      "Iter 4158 | Time 61.6706(60.6266) | Bit/dim 3.6747(3.6818) | Xent 0.0722(0.0697) | Loss 3.7108(3.7166) | Error 0.0215(0.0229) Steps 700(675.89) | Grad Norm 1.6541(1.8691) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0693 | Time 25.2434, Epoch Time 408.6282(405.2243), Bit/dim 3.7055(best: 3.7057), Xent 2.8584, Loss 5.1347, Error 0.4053(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4159 | Time 60.5002(60.6228) | Bit/dim 3.6634(3.6812) | Xent 0.0699(0.0697) | Loss 3.6983(3.7161) | Error 0.0245(0.0230) Steps 676(675.89) | Grad Norm 2.3959(1.8849) | Total Time 14.00(14.00)\n",
      "Iter 4160 | Time 60.5334(60.6201) | Bit/dim 3.6871(3.6814) | Xent 0.0600(0.0694) | Loss 3.7171(3.7161) | Error 0.0186(0.0228) Steps 682(676.07) | Grad Norm 1.3788(1.8698) | Total Time 14.00(14.00)\n",
      "Iter 4161 | Time 61.8201(60.6561) | Bit/dim 3.6793(3.6813) | Xent 0.0721(0.0695) | Loss 3.7153(3.7161) | Error 0.0231(0.0229) Steps 676(676.07) | Grad Norm 1.8729(1.8699) | Total Time 14.00(14.00)\n",
      "Iter 4162 | Time 61.2640(60.6744) | Bit/dim 3.6889(3.6816) | Xent 0.0712(0.0696) | Loss 3.7245(3.7163) | Error 0.0230(0.0229) Steps 676(676.07) | Grad Norm 1.7123(1.8651) | Total Time 14.00(14.00)\n",
      "Iter 4163 | Time 62.0502(60.7156) | Bit/dim 3.6851(3.6817) | Xent 0.0644(0.0694) | Loss 3.7174(3.7164) | Error 0.0236(0.0229) Steps 676(676.07) | Grad Norm 0.9724(1.8384) | Total Time 14.00(14.00)\n",
      "Iter 4164 | Time 61.5019(60.7392) | Bit/dim 3.6836(3.6817) | Xent 0.0693(0.0694) | Loss 3.7183(3.7164) | Error 0.0236(0.0229) Steps 688(676.42) | Grad Norm 2.0879(1.8458) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0694 | Time 25.1522, Epoch Time 408.6812(405.3280), Bit/dim 3.7065(best: 3.7055), Xent 2.8883, Loss 5.1506, Error 0.4090(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4165 | Time 62.7022(60.7981) | Bit/dim 3.6722(3.6814) | Xent 0.0654(0.0693) | Loss 3.7049(3.7161) | Error 0.0222(0.0229) Steps 682(676.59) | Grad Norm 1.5254(1.8362) | Total Time 14.00(14.00)\n",
      "Iter 4166 | Time 61.3845(60.8157) | Bit/dim 3.6833(3.6815) | Xent 0.0638(0.0691) | Loss 3.7152(3.7161) | Error 0.0205(0.0228) Steps 682(676.75) | Grad Norm 1.3556(1.8218) | Total Time 14.00(14.00)\n",
      "Iter 4167 | Time 59.6422(60.7805) | Bit/dim 3.6878(3.6817) | Xent 0.0665(0.0690) | Loss 3.7210(3.7162) | Error 0.0221(0.0228) Steps 676(676.73) | Grad Norm 1.7488(1.8196) | Total Time 14.00(14.00)\n",
      "Iter 4168 | Time 58.5031(60.7122) | Bit/dim 3.6737(3.6814) | Xent 0.0672(0.0690) | Loss 3.7073(3.7159) | Error 0.0221(0.0228) Steps 664(676.35) | Grad Norm 1.9119(1.8224) | Total Time 14.00(14.00)\n",
      "Iter 4169 | Time 60.6331(60.7098) | Bit/dim 3.6785(3.6814) | Xent 0.0701(0.0690) | Loss 3.7136(3.7159) | Error 0.0215(0.0227) Steps 670(676.16) | Grad Norm 1.9757(1.8270) | Total Time 14.00(14.00)\n",
      "Iter 4170 | Time 62.1641(60.7534) | Bit/dim 3.6945(3.6818) | Xent 0.0661(0.0689) | Loss 3.7275(3.7162) | Error 0.0221(0.0227) Steps 688(676.51) | Grad Norm 1.7547(1.8248) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0695 | Time 25.1496, Epoch Time 405.9783(405.3475), Bit/dim 3.7059(best: 3.7055), Xent 2.8721, Loss 5.1419, Error 0.4077(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4171 | Time 62.1945(60.7967) | Bit/dim 3.6926(3.6821) | Xent 0.0691(0.0689) | Loss 3.7271(3.7166) | Error 0.0211(0.0227) Steps 670(676.32) | Grad Norm 2.3165(1.8396) | Total Time 14.00(14.00)\n",
      "Iter 4172 | Time 61.5558(60.8194) | Bit/dim 3.6728(3.6818) | Xent 0.0796(0.0693) | Loss 3.7126(3.7164) | Error 0.0250(0.0227) Steps 670(676.13) | Grad Norm 3.1769(1.8797) | Total Time 14.00(14.00)\n",
      "Iter 4173 | Time 60.9373(60.8230) | Bit/dim 3.6816(3.6818) | Xent 0.0706(0.0693) | Loss 3.7169(3.7164) | Error 0.0229(0.0227) Steps 664(675.77) | Grad Norm 2.7951(1.9072) | Total Time 14.00(14.00)\n",
      "Iter 4174 | Time 62.4183(60.8708) | Bit/dim 3.6779(3.6817) | Xent 0.0611(0.0691) | Loss 3.7085(3.7162) | Error 0.0216(0.0227) Steps 676(675.77) | Grad Norm 2.3764(1.9212) | Total Time 14.00(14.00)\n",
      "Iter 4175 | Time 60.6171(60.8632) | Bit/dim 3.6768(3.6815) | Xent 0.0656(0.0690) | Loss 3.7096(3.7160) | Error 0.0229(0.0227) Steps 676(675.78) | Grad Norm 2.2237(1.9303) | Total Time 14.00(14.00)\n",
      "Iter 4176 | Time 59.7805(60.8307) | Bit/dim 3.6868(3.6817) | Xent 0.0749(0.0691) | Loss 3.7243(3.7163) | Error 0.0245(0.0228) Steps 664(675.43) | Grad Norm 1.7068(1.9236) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0696 | Time 24.8808, Epoch Time 408.1025(405.4302), Bit/dim 3.7069(best: 3.7055), Xent 2.8577, Loss 5.1357, Error 0.4056(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4177 | Time 61.6111(60.8541) | Bit/dim 3.6814(3.6817) | Xent 0.0703(0.0692) | Loss 3.7166(3.7163) | Error 0.0232(0.0228) Steps 670(675.26) | Grad Norm 1.8873(1.9225) | Total Time 14.00(14.00)\n",
      "Iter 4178 | Time 60.0894(60.8312) | Bit/dim 3.6744(3.6815) | Xent 0.0701(0.0692) | Loss 3.7094(3.7161) | Error 0.0231(0.0228) Steps 670(675.11) | Grad Norm 1.8245(1.9196) | Total Time 14.00(14.00)\n",
      "Iter 4179 | Time 59.1324(60.7802) | Bit/dim 3.6821(3.6815) | Xent 0.0836(0.0696) | Loss 3.7239(3.7163) | Error 0.0279(0.0229) Steps 682(675.31) | Grad Norm 2.0432(1.9233) | Total Time 14.00(14.00)\n",
      "Iter 4180 | Time 61.3266(60.7966) | Bit/dim 3.6885(3.6817) | Xent 0.0697(0.0696) | Loss 3.7234(3.7165) | Error 0.0239(0.0230) Steps 664(674.97) | Grad Norm 1.3420(1.9058) | Total Time 14.00(14.00)\n",
      "Iter 4181 | Time 60.6932(60.7935) | Bit/dim 3.6716(3.6814) | Xent 0.0678(0.0696) | Loss 3.7056(3.7162) | Error 0.0231(0.0230) Steps 670(674.82) | Grad Norm 2.0119(1.9090) | Total Time 14.00(14.00)\n",
      "Iter 4182 | Time 60.8924(60.7965) | Bit/dim 3.6832(3.6814) | Xent 0.0662(0.0695) | Loss 3.7163(3.7162) | Error 0.0208(0.0229) Steps 670(674.68) | Grad Norm 1.2742(1.8900) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0697 | Time 25.0271, Epoch Time 404.2762(405.3955), Bit/dim 3.7056(best: 3.7055), Xent 2.8483, Loss 5.1298, Error 0.4049(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4183 | Time 60.1331(60.7766) | Bit/dim 3.6852(3.6816) | Xent 0.0642(0.0693) | Loss 3.7173(3.7162) | Error 0.0228(0.0229) Steps 664(674.36) | Grad Norm 1.1389(1.8674) | Total Time 14.00(14.00)\n",
      "Iter 4184 | Time 61.2277(60.7901) | Bit/dim 3.6718(3.6813) | Xent 0.0626(0.0691) | Loss 3.7031(3.7158) | Error 0.0212(0.0229) Steps 670(674.23) | Grad Norm 1.0497(1.8429) | Total Time 14.00(14.00)\n",
      "Iter 4185 | Time 64.2479(60.8939) | Bit/dim 3.6744(3.6811) | Xent 0.0649(0.0690) | Loss 3.7069(3.7156) | Error 0.0225(0.0228) Steps 682(674.46) | Grad Norm 1.7491(1.8401) | Total Time 14.00(14.00)\n",
      "Iter 4186 | Time 59.4321(60.8500) | Bit/dim 3.6916(3.6814) | Xent 0.0696(0.0690) | Loss 3.7265(3.7159) | Error 0.0246(0.0229) Steps 676(674.51) | Grad Norm 1.6652(1.8348) | Total Time 14.00(14.00)\n",
      "Iter 4187 | Time 61.3724(60.8657) | Bit/dim 3.6850(3.6815) | Xent 0.0659(0.0689) | Loss 3.7179(3.7159) | Error 0.0219(0.0229) Steps 670(674.37) | Grad Norm 2.3790(1.8512) | Total Time 14.00(14.00)\n",
      "Iter 4188 | Time 61.9520(60.8983) | Bit/dim 3.6827(3.6815) | Xent 0.0685(0.0689) | Loss 3.7169(3.7160) | Error 0.0221(0.0228) Steps 676(674.42) | Grad Norm 1.4591(1.8394) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0698 | Time 24.9089, Epoch Time 408.8482(405.4991), Bit/dim 3.7051(best: 3.7055), Xent 2.8684, Loss 5.1393, Error 0.4051(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4189 | Time 59.6205(60.8599) | Bit/dim 3.6832(3.6816) | Xent 0.0651(0.0688) | Loss 3.7158(3.7160) | Error 0.0208(0.0228) Steps 664(674.11) | Grad Norm 1.4949(1.8291) | Total Time 14.00(14.00)\n",
      "Iter 4190 | Time 61.0557(60.8658) | Bit/dim 3.6790(3.6815) | Xent 0.0683(0.0688) | Loss 3.7131(3.7159) | Error 0.0234(0.0228) Steps 658(673.62) | Grad Norm 1.6168(1.8227) | Total Time 14.00(14.00)\n",
      "Iter 4191 | Time 61.9081(60.8971) | Bit/dim 3.6702(3.6812) | Xent 0.0699(0.0688) | Loss 3.7051(3.7156) | Error 0.0235(0.0228) Steps 676(673.70) | Grad Norm 2.0199(1.8286) | Total Time 14.00(14.00)\n",
      "Iter 4192 | Time 59.1121(60.8435) | Bit/dim 3.6767(3.6810) | Xent 0.0616(0.0686) | Loss 3.7075(3.7153) | Error 0.0216(0.0228) Steps 670(673.59) | Grad Norm 1.4675(1.8178) | Total Time 14.00(14.00)\n",
      "Iter 4193 | Time 59.2383(60.7954) | Bit/dim 3.6867(3.6812) | Xent 0.0694(0.0686) | Loss 3.7214(3.7155) | Error 0.0225(0.0228) Steps 670(673.48) | Grad Norm 2.8564(1.8489) | Total Time 14.00(14.00)\n",
      "Iter 4194 | Time 59.4669(60.7555) | Bit/dim 3.6883(3.6814) | Xent 0.0698(0.0686) | Loss 3.7232(3.7157) | Error 0.0244(0.0228) Steps 670(673.37) | Grad Norm 1.6182(1.8420) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0699 | Time 24.7699, Epoch Time 400.6093(405.3524), Bit/dim 3.7069(best: 3.7051), Xent 2.9129, Loss 5.1633, Error 0.4096(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4195 | Time 61.6843(60.7834) | Bit/dim 3.6808(3.6814) | Xent 0.0606(0.0684) | Loss 3.7111(3.7156) | Error 0.0191(0.0227) Steps 664(673.09) | Grad Norm 2.1435(1.8511) | Total Time 14.00(14.00)\n",
      "Iter 4196 | Time 63.5294(60.8658) | Bit/dim 3.6814(3.6814) | Xent 0.0726(0.0685) | Loss 3.7177(3.7157) | Error 0.0224(0.0227) Steps 670(673.00) | Grad Norm 2.7076(1.8768) | Total Time 14.00(14.00)\n",
      "Iter 4197 | Time 59.8795(60.8362) | Bit/dim 3.6868(3.6815) | Xent 0.0679(0.0685) | Loss 3.7207(3.7158) | Error 0.0214(0.0227) Steps 664(672.73) | Grad Norm 1.5551(1.8671) | Total Time 14.00(14.00)\n",
      "Iter 4198 | Time 62.0961(60.8740) | Bit/dim 3.6911(3.6818) | Xent 0.0650(0.0684) | Loss 3.7236(3.7160) | Error 0.0210(0.0226) Steps 676(672.83) | Grad Norm 2.4225(1.8838) | Total Time 14.00(14.00)\n",
      "Iter 4199 | Time 61.0537(60.8794) | Bit/dim 3.6873(3.6820) | Xent 0.0651(0.0683) | Loss 3.7198(3.7162) | Error 0.0212(0.0226) Steps 682(673.10) | Grad Norm 3.1295(1.9211) | Total Time 14.00(14.00)\n",
      "Iter 4200 | Time 60.5666(60.8700) | Bit/dim 3.6683(3.6816) | Xent 0.0713(0.0684) | Loss 3.7040(3.7158) | Error 0.0226(0.0226) Steps 664(672.83) | Grad Norm 1.0741(1.8957) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0700 | Time 25.2370, Epoch Time 409.8011(405.4859), Bit/dim 3.7047(best: 3.7051), Xent 2.8509, Loss 5.1302, Error 0.4049(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4201 | Time 60.2420(60.8511) | Bit/dim 3.6825(3.6816) | Xent 0.0718(0.0685) | Loss 3.7184(3.7159) | Error 0.0232(0.0226) Steps 664(672.56) | Grad Norm 3.7881(1.9525) | Total Time 14.00(14.00)\n",
      "Iter 4202 | Time 59.2826(60.8041) | Bit/dim 3.6755(3.6814) | Xent 0.0697(0.0685) | Loss 3.7104(3.7157) | Error 0.0221(0.0226) Steps 670(672.49) | Grad Norm 1.5736(1.9411) | Total Time 14.00(14.00)\n",
      "Iter 4203 | Time 60.1543(60.7846) | Bit/dim 3.6768(3.6813) | Xent 0.0694(0.0686) | Loss 3.7115(3.7156) | Error 0.0209(0.0225) Steps 670(672.41) | Grad Norm 2.1575(1.9476) | Total Time 14.00(14.00)\n",
      "Iter 4204 | Time 59.8266(60.7559) | Bit/dim 3.6881(3.6815) | Xent 0.0691(0.0686) | Loss 3.7226(3.7158) | Error 0.0218(0.0225) Steps 664(672.16) | Grad Norm 1.8337(1.9442) | Total Time 14.00(14.00)\n",
      "Iter 4205 | Time 58.9484(60.7016) | Bit/dim 3.6803(3.6815) | Xent 0.0693(0.0686) | Loss 3.7149(3.7158) | Error 0.0222(0.0225) Steps 682(672.46) | Grad Norm 2.2312(1.9528) | Total Time 14.00(14.00)\n",
      "Iter 4206 | Time 61.5733(60.7278) | Bit/dim 3.6774(3.6813) | Xent 0.0643(0.0685) | Loss 3.7096(3.7156) | Error 0.0209(0.0225) Steps 670(672.38) | Grad Norm 2.5625(1.9711) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0701 | Time 24.9665, Epoch Time 400.6959(405.3422), Bit/dim 3.7048(best: 3.7047), Xent 2.8963, Loss 5.1529, Error 0.4081(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4207 | Time 60.3607(60.7168) | Bit/dim 3.6739(3.6811) | Xent 0.0656(0.0684) | Loss 3.7067(3.7153) | Error 0.0202(0.0224) Steps 670(672.31) | Grad Norm 1.9831(1.9715) | Total Time 14.00(14.00)\n",
      "Iter 4208 | Time 60.1951(60.7011) | Bit/dim 3.6803(3.6811) | Xent 0.0605(0.0681) | Loss 3.7106(3.7152) | Error 0.0204(0.0223) Steps 664(672.06) | Grad Norm 1.8827(1.9688) | Total Time 14.00(14.00)\n",
      "Iter 4209 | Time 63.3292(60.7800) | Bit/dim 3.6873(3.6813) | Xent 0.0683(0.0682) | Loss 3.7214(3.7154) | Error 0.0232(0.0224) Steps 682(672.36) | Grad Norm 2.7646(1.9927) | Total Time 14.00(14.00)\n",
      "Iter 4210 | Time 59.3091(60.7358) | Bit/dim 3.6790(3.6812) | Xent 0.0653(0.0681) | Loss 3.7117(3.7152) | Error 0.0206(0.0223) Steps 670(672.29) | Grad Norm 1.4670(1.9769) | Total Time 14.00(14.00)\n",
      "Iter 4211 | Time 61.1293(60.7476) | Bit/dim 3.6839(3.6813) | Xent 0.0675(0.0680) | Loss 3.7176(3.7153) | Error 0.0225(0.0223) Steps 664(672.04) | Grad Norm 0.9400(1.9458) | Total Time 14.00(14.00)\n",
      "Iter 4212 | Time 62.3294(60.7951) | Bit/dim 3.6846(3.6814) | Xent 0.0697(0.0681) | Loss 3.7195(3.7154) | Error 0.0226(0.0223) Steps 670(671.98) | Grad Norm 3.2880(1.9861) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0702 | Time 24.6681, Epoch Time 406.8617(405.3878), Bit/dim 3.7049(best: 3.7047), Xent 2.8516, Loss 5.1307, Error 0.4069(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4213 | Time 59.3918(60.7530) | Bit/dim 3.6899(3.6816) | Xent 0.0680(0.0681) | Loss 3.7239(3.7157) | Error 0.0228(0.0223) Steps 664(671.74) | Grad Norm 1.4916(1.9712) | Total Time 14.00(14.00)\n",
      "Iter 4214 | Time 56.5407(60.6266) | Bit/dim 3.6793(3.6816) | Xent 0.0679(0.0681) | Loss 3.7133(3.7156) | Error 0.0224(0.0223) Steps 682(672.05) | Grad Norm 3.1635(2.0070) | Total Time 14.00(14.00)\n",
      "Iter 4215 | Time 61.2669(60.6458) | Bit/dim 3.6868(3.6817) | Xent 0.0632(0.0679) | Loss 3.7184(3.7157) | Error 0.0209(0.0223) Steps 682(672.35) | Grad Norm 1.7489(1.9993) | Total Time 14.00(14.00)\n",
      "Iter 4217 | Time 60.2857(60.5488) | Bit/dim 3.6731(3.6812) | Xent 0.0662(0.0679) | Loss 3.7062(3.7152) | Error 0.0218(0.0223) Steps 688(672.92) | Grad Norm 1.8510(2.0050) | Total Time 14.00(14.00)\n",
      "Iter 4218 | Time 61.9184(60.5899) | Bit/dim 3.6765(3.6811) | Xent 0.0710(0.0680) | Loss 3.7120(3.7151) | Error 0.0230(0.0223) Steps 670(672.83) | Grad Norm 1.6883(1.9955) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0703 | Time 24.8787, Epoch Time 397.7198(405.1577), Bit/dim 3.7049(best: 3.7047), Xent 2.9181, Loss 5.1640, Error 0.4088(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4219 | Time 61.8572(60.6279) | Bit/dim 3.6668(3.6806) | Xent 0.0637(0.0679) | Loss 3.6986(3.7146) | Error 0.0204(0.0222) Steps 670(672.75) | Grad Norm 1.4133(1.9781) | Total Time 14.00(14.00)\n",
      "Iter 4220 | Time 60.1608(60.6139) | Bit/dim 3.6881(3.6809) | Xent 0.0722(0.0680) | Loss 3.7242(3.7149) | Error 0.0229(0.0222) Steps 670(672.67) | Grad Norm 2.5342(1.9947) | Total Time 14.00(14.00)\n",
      "Iter 4221 | Time 61.4374(60.6386) | Bit/dim 3.6822(3.6809) | Xent 0.0641(0.0679) | Loss 3.7143(3.7149) | Error 0.0194(0.0222) Steps 682(672.95) | Grad Norm 1.4587(1.9787) | Total Time 14.00(14.00)\n",
      "Iter 4222 | Time 58.8199(60.5840) | Bit/dim 3.6799(3.6809) | Xent 0.0752(0.0681) | Loss 3.7174(3.7149) | Error 0.0236(0.0222) Steps 676(673.04) | Grad Norm 3.0746(2.0115) | Total Time 14.00(14.00)\n",
      "Iter 4223 | Time 57.5217(60.4921) | Bit/dim 3.6799(3.6809) | Xent 0.0614(0.0679) | Loss 3.7106(3.7148) | Error 0.0196(0.0221) Steps 676(673.13) | Grad Norm 1.9422(2.0095) | Total Time 14.00(14.00)\n",
      "Iter 4224 | Time 57.1339(60.3914) | Bit/dim 3.6838(3.6809) | Xent 0.0726(0.0680) | Loss 3.7201(3.7150) | Error 0.0244(0.0222) Steps 670(673.03) | Grad Norm 1.5876(1.9968) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0704 | Time 24.8560, Epoch Time 397.5218(404.9287), Bit/dim 3.7050(best: 3.7047), Xent 2.8437, Loss 5.1269, Error 0.4035(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4225 | Time 62.0820(60.4421) | Bit/dim 3.6955(3.6814) | Xent 0.0626(0.0679) | Loss 3.7268(3.7153) | Error 0.0205(0.0221) Steps 682(673.30) | Grad Norm 3.7511(2.0494) | Total Time 14.00(14.00)\n",
      "Iter 4226 | Time 59.4953(60.4137) | Bit/dim 3.6780(3.6813) | Xent 0.0661(0.0678) | Loss 3.7111(3.7152) | Error 0.0232(0.0222) Steps 670(673.20) | Grad Norm 1.5585(2.0347) | Total Time 14.00(14.00)\n",
      "Iter 4227 | Time 57.7065(60.3325) | Bit/dim 3.6807(3.6813) | Xent 0.0690(0.0679) | Loss 3.7152(3.7152) | Error 0.0245(0.0222) Steps 670(673.11) | Grad Norm 2.0682(2.0357) | Total Time 14.00(14.00)\n",
      "Iter 4228 | Time 60.1029(60.3256) | Bit/dim 3.6777(3.6812) | Xent 0.0746(0.0681) | Loss 3.7150(3.7152) | Error 0.0232(0.0223) Steps 664(672.83) | Grad Norm 2.3339(2.0447) | Total Time 14.00(14.00)\n",
      "Iter 4229 | Time 60.7583(60.3386) | Bit/dim 3.6788(3.6811) | Xent 0.0686(0.0681) | Loss 3.7131(3.7151) | Error 0.0236(0.0223) Steps 676(672.93) | Grad Norm 2.2064(2.0495) | Total Time 14.00(14.00)\n",
      "Iter 4230 | Time 61.6067(60.3766) | Bit/dim 3.6722(3.6808) | Xent 0.0638(0.0680) | Loss 3.7041(3.7148) | Error 0.0201(0.0222) Steps 688(673.38) | Grad Norm 2.4496(2.0615) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0705 | Time 25.2552, Epoch Time 403.2686(404.8789), Bit/dim 3.7048(best: 3.7047), Xent 2.8702, Loss 5.1399, Error 0.4066(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4231 | Time 60.2763(60.3736) | Bit/dim 3.6803(3.6808) | Xent 0.0668(0.0679) | Loss 3.7137(3.7148) | Error 0.0221(0.0222) Steps 682(673.64) | Grad Norm 1.4297(2.0426) | Total Time 14.00(14.00)\n",
      "Iter 4232 | Time 59.0453(60.3338) | Bit/dim 3.6740(3.6806) | Xent 0.0662(0.0679) | Loss 3.7071(3.7145) | Error 0.0224(0.0222) Steps 670(673.53) | Grad Norm 2.9429(2.0696) | Total Time 14.00(14.00)\n",
      "Iter 4233 | Time 59.4881(60.3084) | Bit/dim 3.6771(3.6805) | Xent 0.0700(0.0679) | Loss 3.7121(3.7145) | Error 0.0234(0.0223) Steps 664(673.24) | Grad Norm 2.1977(2.0734) | Total Time 14.00(14.00)\n",
      "Iter 4234 | Time 62.7203(60.3808) | Bit/dim 3.6693(3.6802) | Xent 0.0689(0.0680) | Loss 3.7038(3.7141) | Error 0.0206(0.0222) Steps 682(673.51) | Grad Norm 1.1866(2.0468) | Total Time 14.00(14.00)\n",
      "Iter 4235 | Time 61.8367(60.4244) | Bit/dim 3.6938(3.6806) | Xent 0.0755(0.0682) | Loss 3.7315(3.7147) | Error 0.0244(0.0223) Steps 670(673.40) | Grad Norm 3.8351(2.1004) | Total Time 14.00(14.00)\n",
      "Iter 4236 | Time 58.4772(60.3660) | Bit/dim 3.6884(3.6808) | Xent 0.0738(0.0684) | Loss 3.7253(3.7150) | Error 0.0235(0.0223) Steps 676(673.48) | Grad Norm 2.2769(2.1057) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0706 | Time 24.9340, Epoch Time 402.6703(404.8126), Bit/dim 3.7041(best: 3.7047), Xent 2.8778, Loss 5.1430, Error 0.4038(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4237 | Time 59.7756(60.3483) | Bit/dim 3.6826(3.6809) | Xent 0.0650(0.0683) | Loss 3.7151(3.7150) | Error 0.0218(0.0223) Steps 676(673.56) | Grad Norm 1.7251(2.0943) | Total Time 14.00(14.00)\n",
      "Iter 4238 | Time 60.1974(60.3438) | Bit/dim 3.6789(3.6808) | Xent 0.0688(0.0683) | Loss 3.7133(3.7149) | Error 0.0239(0.0224) Steps 670(673.45) | Grad Norm 3.4918(2.1362) | Total Time 14.00(14.00)\n",
      "Iter 4239 | Time 60.2861(60.3421) | Bit/dim 3.6846(3.6809) | Xent 0.0680(0.0683) | Loss 3.7186(3.7150) | Error 0.0234(0.0224) Steps 682(673.71) | Grad Norm 2.2778(2.1405) | Total Time 14.00(14.00)\n",
      "Iter 4240 | Time 58.8153(60.2962) | Bit/dim 3.6856(3.6811) | Xent 0.0689(0.0683) | Loss 3.7201(3.7152) | Error 0.0231(0.0224) Steps 676(673.77) | Grad Norm 1.8231(2.1310) | Total Time 14.00(14.00)\n",
      "Iter 4241 | Time 61.8751(60.3436) | Bit/dim 3.6805(3.6810) | Xent 0.0697(0.0683) | Loss 3.7154(3.7152) | Error 0.0214(0.0224) Steps 670(673.66) | Grad Norm 3.2247(2.1638) | Total Time 14.00(14.00)\n",
      "Iter 4242 | Time 61.3709(60.3744) | Bit/dim 3.6681(3.6806) | Xent 0.0625(0.0681) | Loss 3.6993(3.7147) | Error 0.0210(0.0223) Steps 676(673.73) | Grad Norm 1.2885(2.1375) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0707 | Time 25.3528, Epoch Time 403.7226(404.7799), Bit/dim 3.7061(best: 3.7041), Xent 2.9001, Loss 5.1562, Error 0.4066(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4243 | Time 62.6813(60.4436) | Bit/dim 3.6712(3.6804) | Xent 0.0628(0.0680) | Loss 3.7026(3.7144) | Error 0.0206(0.0223) Steps 682(673.98) | Grad Norm 1.3802(2.1148) | Total Time 14.00(14.00)\n",
      "Iter 4244 | Time 59.9016(60.4274) | Bit/dim 3.6851(3.6805) | Xent 0.0678(0.0680) | Loss 3.7190(3.7145) | Error 0.0228(0.0223) Steps 670(673.86) | Grad Norm 2.8013(2.1354) | Total Time 14.00(14.00)\n",
      "Iter 4245 | Time 61.2768(60.4529) | Bit/dim 3.6804(3.6805) | Xent 0.0655(0.0679) | Loss 3.7131(3.7145) | Error 0.0212(0.0223) Steps 682(674.10) | Grad Norm 1.5892(2.1190) | Total Time 14.00(14.00)\n",
      "Iter 4246 | Time 60.0107(60.4396) | Bit/dim 3.6920(3.6809) | Xent 0.0655(0.0678) | Loss 3.7248(3.7148) | Error 0.0214(0.0222) Steps 676(674.16) | Grad Norm 2.0141(2.1159) | Total Time 14.00(14.00)\n",
      "Iter 4247 | Time 61.4044(60.4685) | Bit/dim 3.6817(3.6809) | Xent 0.0726(0.0680) | Loss 3.7180(3.7149) | Error 0.0220(0.0222) Steps 682(674.40) | Grad Norm 1.8601(2.1082) | Total Time 14.00(14.00)\n",
      "Iter 4248 | Time 61.1523(60.4891) | Bit/dim 3.6745(3.6807) | Xent 0.0708(0.0681) | Loss 3.7099(3.7147) | Error 0.0214(0.0222) Steps 670(674.26) | Grad Norm 1.3906(2.0867) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0708 | Time 25.3839, Epoch Time 407.7292(404.8684), Bit/dim 3.7047(best: 3.7041), Xent 2.8462, Loss 5.1278, Error 0.4042(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4249 | Time 59.5557(60.4611) | Bit/dim 3.6677(3.6803) | Xent 0.0609(0.0678) | Loss 3.6982(3.7142) | Error 0.0196(0.0221) Steps 670(674.14) | Grad Norm 1.2955(2.0629) | Total Time 14.00(14.00)\n",
      "Iter 4250 | Time 58.4240(60.3999) | Bit/dim 3.6797(3.6803) | Xent 0.0660(0.0678) | Loss 3.7127(3.7142) | Error 0.0208(0.0221) Steps 670(674.01) | Grad Norm 1.0589(2.0328) | Total Time 14.00(14.00)\n",
      "Iter 4251 | Time 59.4233(60.3706) | Bit/dim 3.6883(3.6805) | Xent 0.0730(0.0679) | Loss 3.7248(3.7145) | Error 0.0245(0.0222) Steps 688(674.43) | Grad Norm 1.6851(2.0224) | Total Time 14.00(14.00)\n",
      "Iter 4252 | Time 62.5339(60.4355) | Bit/dim 3.6770(3.6804) | Xent 0.0709(0.0680) | Loss 3.7124(3.7144) | Error 0.0248(0.0222) Steps 670(674.30) | Grad Norm 2.0120(2.0221) | Total Time 14.00(14.00)\n",
      "Iter 4253 | Time 62.6605(60.5023) | Bit/dim 3.6887(3.6807) | Xent 0.0646(0.0679) | Loss 3.7210(3.7146) | Error 0.0220(0.0222) Steps 664(673.99) | Grad Norm 1.7402(2.0136) | Total Time 14.00(14.00)\n",
      "Iter 4254 | Time 59.8995(60.4842) | Bit/dim 3.6834(3.6807) | Xent 0.0647(0.0678) | Loss 3.7157(3.7147) | Error 0.0202(0.0222) Steps 688(674.41) | Grad Norm 1.4525(1.9968) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0709 | Time 25.2773, Epoch Time 403.7413(404.8346), Bit/dim 3.7061(best: 3.7041), Xent 2.9081, Loss 5.1601, Error 0.4093(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4255 | Time 62.6056(60.5478) | Bit/dim 3.6735(3.6805) | Xent 0.0628(0.0677) | Loss 3.7050(3.7144) | Error 0.0200(0.0221) Steps 700(675.18) | Grad Norm 2.1049(2.0000) | Total Time 14.00(14.00)\n",
      "Iter 4256 | Time 60.2461(60.5388) | Bit/dim 3.6928(3.6809) | Xent 0.0644(0.0676) | Loss 3.7250(3.7147) | Error 0.0205(0.0221) Steps 676(675.20) | Grad Norm 2.7835(2.0235) | Total Time 14.00(14.00)\n",
      "Iter 4257 | Time 62.5255(60.5984) | Bit/dim 3.6768(3.6808) | Xent 0.0659(0.0675) | Loss 3.7097(3.7145) | Error 0.0206(0.0220) Steps 676(675.23) | Grad Norm 2.2671(2.0308) | Total Time 14.00(14.00)\n",
      "Iter 4258 | Time 60.2322(60.5874) | Bit/dim 3.6799(3.6807) | Xent 0.0652(0.0675) | Loss 3.7125(3.7145) | Error 0.0220(0.0220) Steps 652(674.53) | Grad Norm 2.3757(2.0412) | Total Time 14.00(14.00)\n",
      "Iter 4259 | Time 61.6839(60.6203) | Bit/dim 3.6757(3.6806) | Xent 0.0680(0.0675) | Loss 3.7098(3.7143) | Error 0.0232(0.0221) Steps 688(674.93) | Grad Norm 4.1847(2.1055) | Total Time 14.00(14.00)\n",
      "Iter 4260 | Time 62.6134(60.6801) | Bit/dim 3.6834(3.6807) | Xent 0.0599(0.0673) | Loss 3.7134(3.7143) | Error 0.0184(0.0219) Steps 682(675.15) | Grad Norm 2.0235(2.1030) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0710 | Time 25.3292, Epoch Time 411.0812(405.0220), Bit/dim 3.7039(best: 3.7041), Xent 2.9034, Loss 5.1557, Error 0.4103(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4261 | Time 64.0731(60.7819) | Bit/dim 3.6851(3.6808) | Xent 0.0620(0.0671) | Loss 3.7161(3.7144) | Error 0.0202(0.0219) Steps 670(674.99) | Grad Norm 1.9901(2.0996) | Total Time 14.00(14.00)\n",
      "Iter 4262 | Time 62.7115(60.8398) | Bit/dim 3.6888(3.6810) | Xent 0.0653(0.0670) | Loss 3.7214(3.7146) | Error 0.0228(0.0219) Steps 682(675.20) | Grad Norm 3.8853(2.1532) | Total Time 14.00(14.00)\n",
      "Iter 4263 | Time 61.9964(60.8745) | Bit/dim 3.6842(3.6811) | Xent 0.0713(0.0672) | Loss 3.7199(3.7147) | Error 0.0245(0.0220) Steps 676(675.23) | Grad Norm 1.6341(2.1376) | Total Time 14.00(14.00)\n",
      "Iter 4264 | Time 61.4485(60.8917) | Bit/dim 3.6700(3.6808) | Xent 0.0642(0.0671) | Loss 3.7021(3.7144) | Error 0.0219(0.0220) Steps 682(675.43) | Grad Norm 2.7595(2.1563) | Total Time 14.00(14.00)\n",
      "Iter 4265 | Time 65.1771(61.0203) | Bit/dim 3.6864(3.6810) | Xent 0.0692(0.0671) | Loss 3.7210(3.7146) | Error 0.0220(0.0220) Steps 676(675.45) | Grad Norm 2.2557(2.1593) | Total Time 14.00(14.00)\n",
      "Iter 4266 | Time 61.6601(61.0395) | Bit/dim 3.6735(3.6808) | Xent 0.0715(0.0673) | Loss 3.7093(3.7144) | Error 0.0228(0.0220) Steps 670(675.28) | Grad Norm 2.3896(2.1662) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0711 | Time 25.1642, Epoch Time 417.9391(405.4095), Bit/dim 3.7054(best: 3.7039), Xent 2.9018, Loss 5.1563, Error 0.4077(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4267 | Time 59.9299(61.0062) | Bit/dim 3.6872(3.6809) | Xent 0.0609(0.0671) | Loss 3.7177(3.7145) | Error 0.0194(0.0219) Steps 664(674.94) | Grad Norm 1.7941(2.1550) | Total Time 14.00(14.00)\n",
      "Iter 4268 | Time 63.0777(61.0683) | Bit/dim 3.6775(3.6808) | Xent 0.0645(0.0670) | Loss 3.7098(3.7143) | Error 0.0210(0.0219) Steps 676(674.98) | Grad Norm 1.3650(2.1313) | Total Time 14.00(14.00)\n",
      "Iter 4269 | Time 60.4229(61.0490) | Bit/dim 3.6779(3.6808) | Xent 0.0729(0.0672) | Loss 3.7144(3.7144) | Error 0.0228(0.0219) Steps 670(674.83) | Grad Norm 2.6423(2.1467) | Total Time 14.00(14.00)\n",
      "Iter 4270 | Time 59.2557(60.9952) | Bit/dim 3.6764(3.6806) | Xent 0.0656(0.0671) | Loss 3.7092(3.7142) | Error 0.0192(0.0219) Steps 658(674.32) | Grad Norm 2.2421(2.1495) | Total Time 14.00(14.00)\n",
      "Iter 4271 | Time 59.1397(60.9395) | Bit/dim 3.6832(3.6807) | Xent 0.0678(0.0672) | Loss 3.7171(3.7143) | Error 0.0219(0.0219) Steps 682(674.55) | Grad Norm 1.7476(2.1375) | Total Time 14.00(14.00)\n",
      "Iter 4272 | Time 62.0314(60.9722) | Bit/dim 3.6850(3.6808) | Xent 0.0715(0.0673) | Loss 3.7208(3.7145) | Error 0.0254(0.0220) Steps 670(674.42) | Grad Norm 2.6860(2.1539) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0712 | Time 24.9709, Epoch Time 405.1931(405.4030), Bit/dim 3.7047(best: 3.7039), Xent 2.8718, Loss 5.1406, Error 0.4043(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4273 | Time 61.2799(60.9815) | Bit/dim 3.6809(3.6808) | Xent 0.0723(0.0674) | Loss 3.7171(3.7146) | Error 0.0245(0.0220) Steps 682(674.64) | Grad Norm 1.8886(2.1460) | Total Time 14.00(14.00)\n",
      "Iter 4274 | Time 60.3433(60.9623) | Bit/dim 3.6827(3.6809) | Xent 0.0741(0.0676) | Loss 3.7198(3.7147) | Error 0.0251(0.0221) Steps 682(674.86) | Grad Norm 2.8398(2.1668) | Total Time 14.00(14.00)\n",
      "Iter 4275 | Time 61.2059(60.9696) | Bit/dim 3.6815(3.6809) | Xent 0.0631(0.0675) | Loss 3.7130(3.7147) | Error 0.0225(0.0221) Steps 688(675.26) | Grad Norm 1.9982(2.1617) | Total Time 14.00(14.00)\n",
      "Iter 4276 | Time 64.1911(61.0663) | Bit/dim 3.6856(3.6811) | Xent 0.0648(0.0674) | Loss 3.7180(3.7148) | Error 0.0196(0.0221) Steps 676(675.28) | Grad Norm 2.7321(2.1788) | Total Time 14.00(14.00)\n",
      "Iter 4277 | Time 60.9726(61.0635) | Bit/dim 3.6693(3.6807) | Xent 0.0597(0.0672) | Loss 3.6991(3.7143) | Error 0.0194(0.0220) Steps 682(675.48) | Grad Norm 2.2605(2.1813) | Total Time 14.00(14.00)\n",
      "Iter 4278 | Time 61.6003(61.0796) | Bit/dim 3.6791(3.6807) | Xent 0.0716(0.0673) | Loss 3.7149(3.7143) | Error 0.0246(0.0221) Steps 664(675.14) | Grad Norm 2.1253(2.1796) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0713 | Time 25.4582, Epoch Time 411.1197(405.5745), Bit/dim 3.7052(best: 3.7039), Xent 2.8927, Loss 5.1515, Error 0.4041(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4279 | Time 60.7680(61.0702) | Bit/dim 3.6844(3.6808) | Xent 0.0678(0.0673) | Loss 3.7183(3.7144) | Error 0.0229(0.0221) Steps 682(675.34) | Grad Norm 2.1452(2.1786) | Total Time 14.00(14.00)\n",
      "Iter 4280 | Time 61.9472(61.0965) | Bit/dim 3.6888(3.6810) | Xent 0.0641(0.0672) | Loss 3.7209(3.7146) | Error 0.0208(0.0220) Steps 664(675.00) | Grad Norm 2.6541(2.1928) | Total Time 14.00(14.00)\n",
      "Iter 4281 | Time 61.1776(61.0990) | Bit/dim 3.6769(3.6809) | Xent 0.0725(0.0674) | Loss 3.7132(3.7146) | Error 0.0230(0.0221) Steps 676(675.03) | Grad Norm 2.8673(2.2131) | Total Time 14.00(14.00)\n",
      "Iter 4282 | Time 57.5864(60.9936) | Bit/dim 3.6661(3.6804) | Xent 0.0606(0.0672) | Loss 3.6964(3.7140) | Error 0.0205(0.0220) Steps 670(674.88) | Grad Norm 1.6818(2.1971) | Total Time 14.00(14.00)\n",
      "Iter 4283 | Time 59.4927(60.9486) | Bit/dim 3.6813(3.6805) | Xent 0.0676(0.0672) | Loss 3.7151(3.7141) | Error 0.0225(0.0220) Steps 670(674.74) | Grad Norm 3.0522(2.2228) | Total Time 14.00(14.00)\n",
      "Iter 4284 | Time 59.4069(60.9023) | Bit/dim 3.6852(3.6806) | Xent 0.0683(0.0672) | Loss 3.7193(3.7142) | Error 0.0228(0.0221) Steps 664(674.41) | Grad Norm 1.9840(2.2156) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0714 | Time 24.9918, Epoch Time 401.0343(405.4383), Bit/dim 3.7049(best: 3.7039), Xent 2.8879, Loss 5.1488, Error 0.4056(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4285 | Time 58.5148(60.8307) | Bit/dim 3.6763(3.6805) | Xent 0.0690(0.0673) | Loss 3.7107(3.7141) | Error 0.0225(0.0221) Steps 676(674.46) | Grad Norm 2.3240(2.2189) | Total Time 14.00(14.00)\n",
      "Iter 4286 | Time 61.8496(60.8613) | Bit/dim 3.6768(3.6804) | Xent 0.0651(0.0672) | Loss 3.7093(3.7140) | Error 0.0206(0.0220) Steps 676(674.51) | Grad Norm 2.2056(2.2185) | Total Time 14.00(14.00)\n",
      "Iter 4287 | Time 60.0612(60.8373) | Bit/dim 3.6878(3.6806) | Xent 0.0633(0.0671) | Loss 3.7194(3.7141) | Error 0.0201(0.0220) Steps 670(674.37) | Grad Norm 1.7360(2.2040) | Total Time 14.00(14.00)\n",
      "Iter 4288 | Time 59.8387(60.8073) | Bit/dim 3.6811(3.6806) | Xent 0.0686(0.0672) | Loss 3.7154(3.7142) | Error 0.0231(0.0220) Steps 658(673.88) | Grad Norm 2.1083(2.2011) | Total Time 14.00(14.00)\n",
      "Iter 4289 | Time 61.3879(60.8247) | Bit/dim 3.6734(3.6804) | Xent 0.0726(0.0673) | Loss 3.7097(3.7140) | Error 0.0248(0.0221) Steps 676(673.94) | Grad Norm 2.6467(2.2145) | Total Time 14.00(14.00)\n",
      "Iter 4290 | Time 57.9178(60.7375) | Bit/dim 3.6855(3.6805) | Xent 0.0624(0.0672) | Loss 3.7167(3.7141) | Error 0.0196(0.0220) Steps 670(673.83) | Grad Norm 2.1883(2.2137) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0715 | Time 25.0869, Epoch Time 400.4235(405.2878), Bit/dim 3.7049(best: 3.7039), Xent 2.9078, Loss 5.1588, Error 0.4089(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4291 | Time 57.8471(60.6508) | Bit/dim 3.6746(3.6804) | Xent 0.0648(0.0671) | Loss 3.7070(3.7139) | Error 0.0211(0.0220) Steps 682(674.07) | Grad Norm 2.0182(2.2078) | Total Time 14.00(14.00)\n",
      "Iter 4292 | Time 61.5963(60.6792) | Bit/dim 3.6810(3.6804) | Xent 0.0663(0.0671) | Loss 3.7142(3.7139) | Error 0.0210(0.0220) Steps 670(673.95) | Grad Norm 1.4367(2.1847) | Total Time 14.00(14.00)\n",
      "Iter 4293 | Time 60.5522(60.6754) | Bit/dim 3.6787(3.6803) | Xent 0.0728(0.0672) | Loss 3.7151(3.7140) | Error 0.0268(0.0221) Steps 670(673.83) | Grad Norm 2.8367(2.2043) | Total Time 14.00(14.00)\n",
      "Iter 4294 | Time 60.4252(60.6679) | Bit/dim 3.6743(3.6802) | Xent 0.0605(0.0670) | Loss 3.7046(3.7137) | Error 0.0202(0.0220) Steps 670(673.72) | Grad Norm 1.6855(2.1887) | Total Time 14.00(14.00)\n",
      "Iter 4295 | Time 61.7424(60.7001) | Bit/dim 3.6876(3.6804) | Xent 0.0681(0.0671) | Loss 3.7217(3.7139) | Error 0.0211(0.0220) Steps 676(673.78) | Grad Norm 2.3977(2.1950) | Total Time 14.00(14.00)\n",
      "Iter 4296 | Time 58.1006(60.6221) | Bit/dim 3.6841(3.6805) | Xent 0.0600(0.0669) | Loss 3.7141(3.7139) | Error 0.0195(0.0219) Steps 688(674.21) | Grad Norm 3.5086(2.2344) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0716 | Time 25.5382, Epoch Time 401.9512(405.1877), Bit/dim 3.7050(best: 3.7039), Xent 2.9192, Loss 5.1646, Error 0.4111(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4297 | Time 58.9075(60.5707) | Bit/dim 3.6821(3.6805) | Xent 0.0627(0.0667) | Loss 3.7134(3.7139) | Error 0.0202(0.0219) Steps 670(674.08) | Grad Norm 1.1541(2.2020) | Total Time 14.00(14.00)\n",
      "Iter 4298 | Time 61.0434(60.5848) | Bit/dim 3.6750(3.6804) | Xent 0.0660(0.0667) | Loss 3.7080(3.7137) | Error 0.0214(0.0219) Steps 676(674.14) | Grad Norm 2.3265(2.2057) | Total Time 14.00(14.00)\n",
      "Iter 4299 | Time 60.1426(60.5716) | Bit/dim 3.6846(3.6805) | Xent 0.0655(0.0667) | Loss 3.7173(3.7138) | Error 0.0220(0.0219) Steps 676(674.20) | Grad Norm 1.9867(2.1991) | Total Time 14.00(14.00)\n",
      "Iter 4300 | Time 60.3291(60.5643) | Bit/dim 3.6873(3.6807) | Xent 0.0719(0.0668) | Loss 3.7233(3.7141) | Error 0.0218(0.0219) Steps 664(673.89) | Grad Norm 2.1023(2.1962) | Total Time 14.00(14.00)\n",
      "Iter 4301 | Time 57.2414(60.4646) | Bit/dim 3.6736(3.6805) | Xent 0.0591(0.0666) | Loss 3.7032(3.7138) | Error 0.0189(0.0218) Steps 676(673.95) | Grad Norm 1.8566(2.1860) | Total Time 14.00(14.00)\n",
      "Iter 4302 | Time 62.7495(60.5332) | Bit/dim 3.6808(3.6805) | Xent 0.0644(0.0665) | Loss 3.7130(3.7138) | Error 0.0220(0.0218) Steps 670(673.84) | Grad Norm 1.3030(2.1596) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0717 | Time 24.7150, Epoch Time 400.8781(405.0585), Bit/dim 3.7051(best: 3.7039), Xent 2.9136, Loss 5.1619, Error 0.4052(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4303 | Time 61.0316(60.5481) | Bit/dim 3.6792(3.6805) | Xent 0.0622(0.0664) | Loss 3.7103(3.7137) | Error 0.0199(0.0217) Steps 670(673.72) | Grad Norm 2.0838(2.1573) | Total Time 14.00(14.00)\n",
      "Iter 4304 | Time 57.7690(60.4647) | Bit/dim 3.6714(3.6802) | Xent 0.0653(0.0664) | Loss 3.7041(3.7134) | Error 0.0218(0.0217) Steps 670(673.61) | Grad Norm 1.7202(2.1442) | Total Time 14.00(14.00)\n",
      "Iter 4305 | Time 59.2669(60.4288) | Bit/dim 3.6760(3.6801) | Xent 0.0708(0.0665) | Loss 3.7114(3.7133) | Error 0.0224(0.0218) Steps 676(673.68) | Grad Norm 1.6824(2.1303) | Total Time 14.00(14.00)\n",
      "Iter 4306 | Time 61.1000(60.4489) | Bit/dim 3.6794(3.6800) | Xent 0.0694(0.0666) | Loss 3.7141(3.7133) | Error 0.0208(0.0217) Steps 670(673.57) | Grad Norm 1.4079(2.1086) | Total Time 14.00(14.00)\n",
      "Iter 4307 | Time 59.2718(60.4136) | Bit/dim 3.6798(3.6800) | Xent 0.0656(0.0666) | Loss 3.7126(3.7133) | Error 0.0219(0.0217) Steps 670(673.46) | Grad Norm 1.9605(2.1042) | Total Time 14.00(14.00)\n",
      "Iter 4308 | Time 60.1708(60.4063) | Bit/dim 3.6975(3.6806) | Xent 0.0582(0.0663) | Loss 3.7266(3.7137) | Error 0.0196(0.0217) Steps 670(673.36) | Grad Norm 1.3962(2.0830) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0718 | Time 24.7964, Epoch Time 399.3017(404.8858), Bit/dim 3.7044(best: 3.7039), Xent 2.9277, Loss 5.1682, Error 0.4067(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4309 | Time 59.7131(60.3855) | Bit/dim 3.6804(3.6806) | Xent 0.0664(0.0663) | Loss 3.7136(3.7137) | Error 0.0216(0.0217) Steps 676(673.44) | Grad Norm 1.1649(2.0554) | Total Time 14.00(14.00)\n",
      "Iter 4310 | Time 60.7911(60.3977) | Bit/dim 3.6744(3.6804) | Xent 0.0551(0.0660) | Loss 3.7020(3.7134) | Error 0.0188(0.0216) Steps 682(673.70) | Grad Norm 2.1430(2.0580) | Total Time 14.00(14.00)\n",
      "Iter 4311 | Time 60.0466(60.3872) | Bit/dim 3.6813(3.6804) | Xent 0.0631(0.0659) | Loss 3.7129(3.7133) | Error 0.0208(0.0216) Steps 676(673.76) | Grad Norm 2.5502(2.0728) | Total Time 14.00(14.00)\n",
      "Iter 4312 | Time 60.0063(60.3758) | Bit/dim 3.6820(3.6804) | Xent 0.0570(0.0656) | Loss 3.7105(3.7133) | Error 0.0182(0.0215) Steps 670(673.65) | Grad Norm 1.3305(2.0505) | Total Time 14.00(14.00)\n",
      "Iter 4313 | Time 61.3161(60.4040) | Bit/dim 3.6887(3.6807) | Xent 0.0588(0.0654) | Loss 3.7181(3.7134) | Error 0.0188(0.0214) Steps 676(673.72) | Grad Norm 2.0661(2.0510) | Total Time 14.00(14.00)\n",
      "Iter 4314 | Time 61.7100(60.4431) | Bit/dim 3.6809(3.6807) | Xent 0.0603(0.0653) | Loss 3.7111(3.7133) | Error 0.0199(0.0213) Steps 688(674.15) | Grad Norm 2.0776(2.0518) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0719 | Time 25.0045, Epoch Time 404.0158(404.8597), Bit/dim 3.7039(best: 3.7039), Xent 2.9155, Loss 5.1616, Error 0.4071(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4315 | Time 59.2597(60.4076) | Bit/dim 3.6738(3.6805) | Xent 0.0587(0.0651) | Loss 3.7032(3.7130) | Error 0.0189(0.0213) Steps 682(674.39) | Grad Norm 1.4777(2.0346) | Total Time 14.00(14.00)\n",
      "Iter 4316 | Time 61.5849(60.4430) | Bit/dim 3.6855(3.6806) | Xent 0.0666(0.0651) | Loss 3.7188(3.7132) | Error 0.0224(0.0213) Steps 670(674.25) | Grad Norm 1.9934(2.0334) | Total Time 14.00(14.00)\n",
      "Iter 4317 | Time 60.7549(60.4523) | Bit/dim 3.6813(3.6807) | Xent 0.0600(0.0650) | Loss 3.7112(3.7131) | Error 0.0190(0.0212) Steps 676(674.31) | Grad Norm 2.1779(2.0377) | Total Time 14.00(14.00)\n",
      "Iter 4318 | Time 58.6346(60.3978) | Bit/dim 3.6721(3.6804) | Xent 0.0638(0.0649) | Loss 3.7040(3.7129) | Error 0.0215(0.0212) Steps 676(674.36) | Grad Norm 1.5116(2.0219) | Total Time 14.00(14.00)\n",
      "Iter 4319 | Time 60.6919(60.4066) | Bit/dim 3.6806(3.6804) | Xent 0.0672(0.0650) | Loss 3.7142(3.7129) | Error 0.0208(0.0212) Steps 670(674.23) | Grad Norm 1.6421(2.0105) | Total Time 14.00(14.00)\n",
      "Iter 4320 | Time 60.9628(60.4233) | Bit/dim 3.6841(3.6805) | Xent 0.0652(0.0650) | Loss 3.7167(3.7130) | Error 0.0215(0.0212) Steps 670(674.10) | Grad Norm 1.8454(2.0056) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0720 | Time 25.1226, Epoch Time 403.1532(404.8085), Bit/dim 3.7055(best: 3.7039), Xent 2.9127, Loss 5.1618, Error 0.4099(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4321 | Time 59.2563(60.3883) | Bit/dim 3.6714(3.6802) | Xent 0.0643(0.0650) | Loss 3.7036(3.7127) | Error 0.0204(0.0212) Steps 676(674.16) | Grad Norm 1.6489(1.9949) | Total Time 14.00(14.00)\n",
      "Iter 4322 | Time 59.1657(60.3516) | Bit/dim 3.6712(3.6800) | Xent 0.0682(0.0651) | Loss 3.7053(3.7125) | Error 0.0221(0.0212) Steps 670(674.03) | Grad Norm 1.7266(1.9868) | Total Time 14.00(14.00)\n",
      "Iter 4323 | Time 61.1304(60.3750) | Bit/dim 3.6893(3.6803) | Xent 0.0708(0.0652) | Loss 3.7247(3.7129) | Error 0.0214(0.0212) Steps 664(673.73) | Grad Norm 1.5743(1.9744) | Total Time 14.00(14.00)\n",
      "Iter 4324 | Time 60.0413(60.3650) | Bit/dim 3.6715(3.6800) | Xent 0.0649(0.0652) | Loss 3.7039(3.7126) | Error 0.0212(0.0212) Steps 670(673.62) | Grad Norm 1.8276(1.9700) | Total Time 14.00(14.00)\n",
      "Iter 4325 | Time 61.0529(60.3856) | Bit/dim 3.6922(3.6804) | Xent 0.0658(0.0653) | Loss 3.7251(3.7130) | Error 0.0224(0.0213) Steps 676(673.69) | Grad Norm 1.6620(1.9608) | Total Time 14.00(14.00)\n",
      "Iter 4326 | Time 59.2328(60.3510) | Bit/dim 3.6834(3.6805) | Xent 0.0651(0.0652) | Loss 3.7159(3.7131) | Error 0.0204(0.0212) Steps 664(673.40) | Grad Norm 1.6181(1.9505) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0721 | Time 25.3326, Epoch Time 401.4089(404.7065), Bit/dim 3.7036(best: 3.7039), Xent 2.9120, Loss 5.1596, Error 0.4050(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4327 | Time 59.5386(60.3266) | Bit/dim 3.6690(3.6801) | Xent 0.0680(0.0653) | Loss 3.7031(3.7128) | Error 0.0205(0.0212) Steps 670(673.30) | Grad Norm 1.6117(1.9403) | Total Time 14.00(14.00)\n",
      "Iter 4328 | Time 61.4450(60.3602) | Bit/dim 3.6850(3.6803) | Xent 0.0657(0.0653) | Loss 3.7179(3.7129) | Error 0.0204(0.0212) Steps 676(673.38) | Grad Norm 2.4833(1.9566) | Total Time 14.00(14.00)\n",
      "Iter 4329 | Time 60.5206(60.3650) | Bit/dim 3.6803(3.6803) | Xent 0.0599(0.0652) | Loss 3.7103(3.7128) | Error 0.0180(0.0211) Steps 670(673.28) | Grad Norm 1.4024(1.9400) | Total Time 14.00(14.00)\n",
      "Iter 4330 | Time 60.4320(60.3670) | Bit/dim 3.6712(3.6800) | Xent 0.0673(0.0652) | Loss 3.7049(3.7126) | Error 0.0212(0.0211) Steps 676(673.36) | Grad Norm 1.7576(1.9345) | Total Time 14.00(14.00)\n",
      "Iter 4331 | Time 60.5282(60.3719) | Bit/dim 3.6919(3.6803) | Xent 0.0640(0.0652) | Loss 3.7239(3.7129) | Error 0.0192(0.0210) Steps 676(673.44) | Grad Norm 2.0247(1.9372) | Total Time 14.00(14.00)\n",
      "Iter 4332 | Time 60.6484(60.3801) | Bit/dim 3.6778(3.6803) | Xent 0.0672(0.0653) | Loss 3.7114(3.7129) | Error 0.0221(0.0211) Steps 676(673.52) | Grad Norm 1.8775(1.9354) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0722 | Time 24.9170, Epoch Time 403.8894(404.6820), Bit/dim 3.7045(best: 3.7036), Xent 2.9147, Loss 5.1618, Error 0.4090(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4333 | Time 57.4752(60.2930) | Bit/dim 3.6794(3.6802) | Xent 0.0631(0.0652) | Loss 3.7109(3.7128) | Error 0.0194(0.0210) Steps 682(673.77) | Grad Norm 1.4902(1.9221) | Total Time 14.00(14.00)\n",
      "Iter 4334 | Time 61.4695(60.3283) | Bit/dim 3.6885(3.6805) | Xent 0.0631(0.0651) | Loss 3.7201(3.7131) | Error 0.0204(0.0210) Steps 670(673.66) | Grad Norm 3.2406(1.9616) | Total Time 14.00(14.00)\n",
      "Iter 4335 | Time 64.7255(60.4602) | Bit/dim 3.6768(3.6804) | Xent 0.0610(0.0650) | Loss 3.7073(3.7129) | Error 0.0196(0.0210) Steps 682(673.91) | Grad Norm 2.2430(1.9701) | Total Time 14.00(14.00)\n",
      "Iter 4336 | Time 59.7871(60.4400) | Bit/dim 3.6745(3.6802) | Xent 0.0672(0.0651) | Loss 3.7082(3.7127) | Error 0.0232(0.0210) Steps 670(673.79) | Grad Norm 2.1336(1.9750) | Total Time 14.00(14.00)\n",
      "Iter 4337 | Time 61.6995(60.4778) | Bit/dim 3.6824(3.6803) | Xent 0.0660(0.0651) | Loss 3.7154(3.7128) | Error 0.0215(0.0210) Steps 676(673.86) | Grad Norm 3.1271(2.0096) | Total Time 14.00(14.00)\n",
      "Iter 4338 | Time 61.4422(60.5067) | Bit/dim 3.6756(3.6801) | Xent 0.0570(0.0649) | Loss 3.7041(3.7126) | Error 0.0179(0.0210) Steps 664(673.56) | Grad Norm 2.0624(2.0111) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0723 | Time 24.7706, Epoch Time 407.1378(404.7556), Bit/dim 3.7047(best: 3.7036), Xent 2.8755, Loss 5.1425, Error 0.4054(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4339 | Time 58.9368(60.4596) | Bit/dim 3.6725(3.6799) | Xent 0.0675(0.0649) | Loss 3.7063(3.7124) | Error 0.0222(0.0210) Steps 676(673.63) | Grad Norm 1.3625(1.9917) | Total Time 14.00(14.00)\n",
      "Iter 4340 | Time 61.2323(60.4828) | Bit/dim 3.6842(3.6800) | Xent 0.0650(0.0649) | Loss 3.7168(3.7125) | Error 0.0220(0.0210) Steps 670(673.52) | Grad Norm 1.8778(1.9883) | Total Time 14.00(14.00)\n",
      "Iter 4341 | Time 62.6291(60.5472) | Bit/dim 3.6818(3.6801) | Xent 0.0567(0.0647) | Loss 3.7102(3.7124) | Error 0.0195(0.0210) Steps 664(673.24) | Grad Norm 1.7250(1.9804) | Total Time 14.00(14.00)\n",
      "Iter 4342 | Time 61.8829(60.5873) | Bit/dim 3.6865(3.6803) | Xent 0.0556(0.0644) | Loss 3.7143(3.7125) | Error 0.0180(0.0209) Steps 670(673.14) | Grad Norm 1.7140(1.9724) | Total Time 14.00(14.00)\n",
      "Iter 4343 | Time 60.9418(60.5979) | Bit/dim 3.6848(3.6804) | Xent 0.0621(0.0644) | Loss 3.7158(3.7126) | Error 0.0206(0.0209) Steps 676(673.23) | Grad Norm 1.7752(1.9665) | Total Time 14.00(14.00)\n",
      "Iter 4344 | Time 61.2176(60.6165) | Bit/dim 3.6677(3.6800) | Xent 0.0693(0.0645) | Loss 3.7024(3.7123) | Error 0.0232(0.0209) Steps 682(673.49) | Grad Norm 1.3250(1.9472) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0724 | Time 25.0445, Epoch Time 407.7758(404.8462), Bit/dim 3.7052(best: 3.7036), Xent 2.9315, Loss 5.1709, Error 0.4057(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4345 | Time 62.1733(60.6632) | Bit/dim 3.6890(3.6803) | Xent 0.0648(0.0645) | Loss 3.7214(3.7126) | Error 0.0222(0.0210) Steps 664(673.21) | Grad Norm 2.2880(1.9574) | Total Time 14.00(14.00)\n",
      "Iter 4346 | Time 58.6115(60.6017) | Bit/dim 3.6868(3.6805) | Xent 0.0620(0.0644) | Loss 3.7178(3.7127) | Error 0.0196(0.0209) Steps 670(673.11) | Grad Norm 1.6430(1.9480) | Total Time 14.00(14.00)\n",
      "Iter 4347 | Time 61.5148(60.6290) | Bit/dim 3.6749(3.6803) | Xent 0.0573(0.0642) | Loss 3.7035(3.7124) | Error 0.0170(0.0208) Steps 670(673.02) | Grad Norm 0.9640(1.9185) | Total Time 14.00(14.00)\n",
      "Iter 4348 | Time 60.6960(60.6311) | Bit/dim 3.6768(3.6802) | Xent 0.0684(0.0644) | Loss 3.7110(3.7124) | Error 0.0216(0.0209) Steps 676(673.11) | Grad Norm 1.5692(1.9080) | Total Time 14.00(14.00)\n",
      "Iter 4349 | Time 61.3018(60.6512) | Bit/dim 3.6741(3.6800) | Xent 0.0701(0.0645) | Loss 3.7092(3.7123) | Error 0.0238(0.0209) Steps 670(673.01) | Grad Norm 2.0518(1.9123) | Total Time 14.00(14.00)\n",
      "Iter 4350 | Time 59.5243(60.6174) | Bit/dim 3.6705(3.6798) | Xent 0.0606(0.0644) | Loss 3.7008(3.7120) | Error 0.0214(0.0210) Steps 676(673.10) | Grad Norm 1.7718(1.9081) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0725 | Time 24.9644, Epoch Time 404.6566(404.8406), Bit/dim 3.7042(best: 3.7036), Xent 2.9077, Loss 5.1581, Error 0.4042(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4351 | Time 61.4544(60.6425) | Bit/dim 3.6773(3.6797) | Xent 0.0688(0.0645) | Loss 3.7117(3.7120) | Error 0.0208(0.0209) Steps 676(673.19) | Grad Norm 1.2419(1.8881) | Total Time 14.00(14.00)\n",
      "Iter 4352 | Time 59.0842(60.5957) | Bit/dim 3.6742(3.6795) | Xent 0.0568(0.0643) | Loss 3.7026(3.7117) | Error 0.0186(0.0209) Steps 664(672.91) | Grad Norm 1.2081(1.8677) | Total Time 14.00(14.00)\n",
      "Iter 4353 | Time 61.9924(60.6376) | Bit/dim 3.6863(3.6797) | Xent 0.0636(0.0643) | Loss 3.7181(3.7119) | Error 0.0202(0.0209) Steps 664(672.65) | Grad Norm 1.3887(1.8533) | Total Time 14.00(14.00)\n",
      "Iter 4354 | Time 62.3690(60.6896) | Bit/dim 3.6800(3.6797) | Xent 0.0698(0.0645) | Loss 3.7149(3.7120) | Error 0.0206(0.0209) Steps 676(672.75) | Grad Norm 1.5934(1.8455) | Total Time 14.00(14.00)\n",
      "Iter 4355 | Time 60.8104(60.6932) | Bit/dim 3.6772(3.6797) | Xent 0.0645(0.0645) | Loss 3.7095(3.7119) | Error 0.0218(0.0209) Steps 664(672.48) | Grad Norm 1.9709(1.8493) | Total Time 14.00(14.00)\n",
      "Iter 4356 | Time 59.2976(60.6513) | Bit/dim 3.6813(3.6797) | Xent 0.0612(0.0644) | Loss 3.7119(3.7119) | Error 0.0190(0.0208) Steps 676(672.59) | Grad Norm 1.2512(1.8314) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0726 | Time 24.7773, Epoch Time 405.2812(404.8538), Bit/dim 3.7036(best: 3.7036), Xent 2.9537, Loss 5.1804, Error 0.4096(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4357 | Time 60.3270(60.6416) | Bit/dim 3.6922(3.6801) | Xent 0.0630(0.0643) | Loss 3.7237(3.7122) | Error 0.0216(0.0208) Steps 676(672.69) | Grad Norm 1.6841(1.8269) | Total Time 14.00(14.00)\n",
      "Iter 4358 | Time 60.1202(60.6260) | Bit/dim 3.6845(3.6802) | Xent 0.0618(0.0642) | Loss 3.7154(3.7123) | Error 0.0205(0.0208) Steps 670(672.61) | Grad Norm 1.3380(1.8123) | Total Time 14.00(14.00)\n",
      "Iter 4359 | Time 61.0826(60.6397) | Bit/dim 3.6726(3.6800) | Xent 0.0692(0.0644) | Loss 3.7072(3.7122) | Error 0.0218(0.0209) Steps 670(672.53) | Grad Norm 1.6465(1.8073) | Total Time 14.00(14.00)\n",
      "Iter 4360 | Time 63.0559(60.7121) | Bit/dim 3.6726(3.6798) | Xent 0.0546(0.0641) | Loss 3.6999(3.7118) | Error 0.0180(0.0208) Steps 676(672.64) | Grad Norm 1.5546(1.7997) | Total Time 14.00(14.00)\n",
      "Iter 4361 | Time 61.1965(60.7267) | Bit/dim 3.6757(3.6796) | Xent 0.0597(0.0640) | Loss 3.7056(3.7116) | Error 0.0198(0.0207) Steps 682(672.92) | Grad Norm 1.7300(1.7976) | Total Time 14.00(14.00)\n",
      "Iter 4362 | Time 62.4492(60.7784) | Bit/dim 3.6788(3.6796) | Xent 0.0689(0.0641) | Loss 3.7133(3.7117) | Error 0.0229(0.0208) Steps 676(673.01) | Grad Norm 1.3407(1.7839) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0727 | Time 24.7289, Epoch Time 408.6348(404.9672), Bit/dim 3.7044(best: 3.7036), Xent 2.9633, Loss 5.1861, Error 0.4063(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4363 | Time 58.6725(60.7152) | Bit/dim 3.6860(3.6798) | Xent 0.0675(0.0642) | Loss 3.7197(3.7119) | Error 0.0226(0.0209) Steps 670(672.92) | Grad Norm 1.9134(1.7878) | Total Time 14.00(14.00)\n",
      "Iter 4364 | Time 61.8845(60.7503) | Bit/dim 3.6772(3.6797) | Xent 0.0601(0.0641) | Loss 3.7072(3.7118) | Error 0.0196(0.0208) Steps 670(672.83) | Grad Norm 1.5022(1.7792) | Total Time 14.00(14.00)\n",
      "Iter 4365 | Time 60.5612(60.7446) | Bit/dim 3.6716(3.6795) | Xent 0.0622(0.0640) | Loss 3.7027(3.7115) | Error 0.0212(0.0208) Steps 670(672.75) | Grad Norm 1.4086(1.7681) | Total Time 14.00(14.00)\n",
      "Iter 4366 | Time 59.5365(60.7083) | Bit/dim 3.6779(3.6794) | Xent 0.0603(0.0639) | Loss 3.7080(3.7114) | Error 0.0189(0.0208) Steps 670(672.67) | Grad Norm 1.7145(1.7665) | Total Time 14.00(14.00)\n",
      "Iter 4367 | Time 58.1887(60.6328) | Bit/dim 3.6857(3.6796) | Xent 0.0607(0.0638) | Loss 3.7161(3.7115) | Error 0.0192(0.0207) Steps 670(672.59) | Grad Norm 1.8371(1.7686) | Total Time 14.00(14.00)\n",
      "Iter 4368 | Time 59.6073(60.6020) | Bit/dim 3.6735(3.6794) | Xent 0.0654(0.0639) | Loss 3.7062(3.7114) | Error 0.0222(0.0208) Steps 676(672.69) | Grad Norm 2.2641(1.7835) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0728 | Time 24.7696, Epoch Time 399.1143(404.7916), Bit/dim 3.7049(best: 3.7036), Xent 2.9617, Loss 5.1857, Error 0.4074(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4369 | Time 59.2293(60.5608) | Bit/dim 3.6794(3.6794) | Xent 0.0610(0.0638) | Loss 3.7099(3.7113) | Error 0.0212(0.0208) Steps 664(672.43) | Grad Norm 1.5233(1.7757) | Total Time 14.00(14.00)\n",
      "Iter 4370 | Time 58.3023(60.4931) | Bit/dim 3.6882(3.6797) | Xent 0.0693(0.0639) | Loss 3.7229(3.7117) | Error 0.0225(0.0208) Steps 676(672.53) | Grad Norm 3.1775(1.8177) | Total Time 14.00(14.00)\n",
      "Iter 4371 | Time 58.3264(60.4281) | Bit/dim 3.6833(3.6798) | Xent 0.0573(0.0637) | Loss 3.7120(3.7117) | Error 0.0188(0.0208) Steps 658(672.10) | Grad Norm 1.5328(1.8092) | Total Time 14.00(14.00)\n",
      "Iter 4372 | Time 58.2894(60.3639) | Bit/dim 3.6656(3.6794) | Xent 0.0691(0.0639) | Loss 3.7001(3.7113) | Error 0.0242(0.0209) Steps 676(672.22) | Grad Norm 3.3520(1.8555) | Total Time 14.00(14.00)\n",
      "Iter 4373 | Time 58.8261(60.3178) | Bit/dim 3.6813(3.6794) | Xent 0.0608(0.0638) | Loss 3.7117(3.7114) | Error 0.0214(0.0209) Steps 676(672.33) | Grad Norm 2.4997(1.8748) | Total Time 14.00(14.00)\n",
      "Iter 4374 | Time 61.5412(60.3545) | Bit/dim 3.6780(3.6794) | Xent 0.0567(0.0636) | Loss 3.7063(3.7112) | Error 0.0191(0.0208) Steps 664(672.08) | Grad Norm 2.3762(1.8898) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0729 | Time 25.0558, Epoch Time 395.7465(404.5203), Bit/dim 3.7036(best: 3.7036), Xent 2.9069, Loss 5.1570, Error 0.4079(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4375 | Time 60.1212(60.3475) | Bit/dim 3.6773(3.6793) | Xent 0.0705(0.0638) | Loss 3.7125(3.7112) | Error 0.0240(0.0209) Steps 664(671.84) | Grad Norm 5.6671(2.0032) | Total Time 14.00(14.00)\n",
      "Iter 4376 | Time 58.9803(60.3064) | Bit/dim 3.6753(3.6792) | Xent 0.0650(0.0638) | Loss 3.7078(3.7111) | Error 0.0224(0.0210) Steps 682(672.14) | Grad Norm 1.6792(1.9934) | Total Time 14.00(14.00)\n",
      "Iter 4377 | Time 59.1479(60.2717) | Bit/dim 3.6841(3.6794) | Xent 0.0680(0.0640) | Loss 3.7181(3.7113) | Error 0.0211(0.0210) Steps 670(672.08) | Grad Norm 5.5801(2.1010) | Total Time 14.00(14.00)\n",
      "Iter 4378 | Time 60.4358(60.2766) | Bit/dim 3.6762(3.6793) | Xent 0.0643(0.0640) | Loss 3.7084(3.7113) | Error 0.0202(0.0210) Steps 676(672.19) | Grad Norm 4.2739(2.1662) | Total Time 14.00(14.00)\n",
      "Iter 4379 | Time 60.4863(60.2829) | Bit/dim 3.6788(3.6793) | Xent 0.0628(0.0639) | Loss 3.7102(3.7112) | Error 0.0209(0.0210) Steps 664(671.95) | Grad Norm 1.5181(2.1468) | Total Time 14.00(14.00)\n",
      "Iter 4380 | Time 60.4061(60.2866) | Bit/dim 3.6842(3.6794) | Xent 0.0598(0.0638) | Loss 3.7141(3.7113) | Error 0.0194(0.0209) Steps 670(671.89) | Grad Norm 4.9371(2.2305) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0730 | Time 25.0187, Epoch Time 400.2091(404.3909), Bit/dim 3.7028(best: 3.7036), Xent 2.9089, Loss 5.1572, Error 0.4119(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4381 | Time 60.2620(60.2859) | Bit/dim 3.6844(3.6796) | Xent 0.0616(0.0638) | Loss 3.7152(3.7114) | Error 0.0204(0.0209) Steps 670(671.83) | Grad Norm 3.3760(2.2649) | Total Time 14.00(14.00)\n",
      "Iter 4382 | Time 61.9934(60.3371) | Bit/dim 3.6789(3.6795) | Xent 0.0630(0.0637) | Loss 3.7103(3.7114) | Error 0.0190(0.0208) Steps 664(671.60) | Grad Norm 2.2769(2.2652) | Total Time 14.00(14.00)\n",
      "Iter 4383 | Time 60.9246(60.3547) | Bit/dim 3.6707(3.6793) | Xent 0.0666(0.0638) | Loss 3.7040(3.7112) | Error 0.0204(0.0208) Steps 682(671.91) | Grad Norm 2.6652(2.2772) | Total Time 14.00(14.00)\n",
      "Iter 4384 | Time 60.7254(60.3658) | Bit/dim 3.6692(3.6790) | Xent 0.0645(0.0638) | Loss 3.7014(3.7109) | Error 0.0198(0.0208) Steps 676(672.03) | Grad Norm 2.8202(2.2935) | Total Time 14.00(14.00)\n",
      "Iter 4385 | Time 58.6528(60.3144) | Bit/dim 3.6930(3.6794) | Xent 0.0696(0.0640) | Loss 3.7278(3.7114) | Error 0.0229(0.0209) Steps 664(671.79) | Grad Norm 2.3279(2.2945) | Total Time 14.00(14.00)\n",
      "Iter 4386 | Time 61.0929(60.3378) | Bit/dim 3.6719(3.6792) | Xent 0.0716(0.0642) | Loss 3.7077(3.7113) | Error 0.0239(0.0210) Steps 688(672.28) | Grad Norm 2.5594(2.3025) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0731 | Time 24.8906, Epoch Time 404.2836(404.3877), Bit/dim 3.7028(best: 3.7028), Xent 2.9276, Loss 5.1666, Error 0.4085(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4387 | Time 59.1458(60.3020) | Bit/dim 3.6934(3.6796) | Xent 0.0690(0.0644) | Loss 3.7279(3.7118) | Error 0.0212(0.0210) Steps 676(672.39) | Grad Norm 2.0302(2.2943) | Total Time 14.00(14.00)\n",
      "Iter 4388 | Time 59.5190(60.2785) | Bit/dim 3.6794(3.6796) | Xent 0.0637(0.0644) | Loss 3.7113(3.7118) | Error 0.0190(0.0209) Steps 676(672.50) | Grad Norm 2.8758(2.3118) | Total Time 14.00(14.00)\n",
      "Iter 4389 | Time 59.2746(60.2484) | Bit/dim 3.6840(3.6797) | Xent 0.0668(0.0644) | Loss 3.7174(3.7119) | Error 0.0211(0.0209) Steps 676(672.60) | Grad Norm 3.5546(2.3490) | Total Time 14.00(14.00)\n",
      "Iter 4390 | Time 61.4308(60.2839) | Bit/dim 3.6792(3.6797) | Xent 0.0624(0.0644) | Loss 3.7104(3.7119) | Error 0.0219(0.0209) Steps 670(672.53) | Grad Norm 1.9143(2.3360) | Total Time 14.00(14.00)\n",
      "Iter 4391 | Time 60.5625(60.2923) | Bit/dim 3.6677(3.6793) | Xent 0.0647(0.0644) | Loss 3.7000(3.7115) | Error 0.0206(0.0209) Steps 676(672.63) | Grad Norm 3.7088(2.3772) | Total Time 14.00(14.00)\n",
      "Iter 4392 | Time 64.5214(60.4191) | Bit/dim 3.6705(3.6791) | Xent 0.0627(0.0643) | Loss 3.7019(3.7112) | Error 0.0196(0.0209) Steps 670(672.55) | Grad Norm 2.2804(2.3743) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0732 | Time 24.8421, Epoch Time 405.0182(404.4066), Bit/dim 3.7032(best: 3.7028), Xent 2.9483, Loss 5.1774, Error 0.4033(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4393 | Time 60.4548(60.4202) | Bit/dim 3.6712(3.6788) | Xent 0.0581(0.0641) | Loss 3.7003(3.7109) | Error 0.0192(0.0208) Steps 664(672.29) | Grad Norm 1.2607(2.3409) | Total Time 14.00(14.00)\n",
      "Iter 4394 | Time 60.9910(60.4373) | Bit/dim 3.6768(3.6788) | Xent 0.0681(0.0643) | Loss 3.7109(3.7109) | Error 0.0219(0.0209) Steps 682(672.59) | Grad Norm 4.0940(2.3935) | Total Time 14.00(14.00)\n",
      "Iter 4395 | Time 60.9926(60.4540) | Bit/dim 3.6784(3.6788) | Xent 0.0613(0.0642) | Loss 3.7091(3.7109) | Error 0.0198(0.0208) Steps 670(672.51) | Grad Norm 2.3255(2.3914) | Total Time 14.00(14.00)\n",
      "Iter 4396 | Time 59.1623(60.4152) | Bit/dim 3.6829(3.6789) | Xent 0.0582(0.0640) | Loss 3.7120(3.7109) | Error 0.0200(0.0208) Steps 670(672.43) | Grad Norm 2.7535(2.4023) | Total Time 14.00(14.00)\n",
      "Iter 4397 | Time 60.3057(60.4119) | Bit/dim 3.6793(3.6789) | Xent 0.0694(0.0642) | Loss 3.7140(3.7110) | Error 0.0242(0.0209) Steps 688(672.90) | Grad Norm 3.1755(2.4255) | Total Time 14.00(14.00)\n",
      "Iter 4398 | Time 61.3360(60.4397) | Bit/dim 3.6858(3.6791) | Xent 0.0695(0.0643) | Loss 3.7205(3.7113) | Error 0.0208(0.0209) Steps 658(672.45) | Grad Norm 1.6120(2.4011) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0733 | Time 24.6511, Epoch Time 403.4802(404.3788), Bit/dim 3.7048(best: 3.7028), Xent 2.9168, Loss 5.1632, Error 0.4110(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4399 | Time 58.9975(60.3964) | Bit/dim 3.6783(3.6791) | Xent 0.0731(0.0646) | Loss 3.7149(3.7114) | Error 0.0244(0.0210) Steps 676(672.56) | Grad Norm 3.5721(2.4362) | Total Time 14.00(14.00)\n",
      "Iter 4400 | Time 59.6469(60.3739) | Bit/dim 3.6858(3.6793) | Xent 0.0602(0.0645) | Loss 3.7158(3.7115) | Error 0.0205(0.0210) Steps 670(672.48) | Grad Norm 1.8516(2.4187) | Total Time 14.00(14.00)\n",
      "Iter 4401 | Time 59.3103(60.3420) | Bit/dim 3.6780(3.6792) | Xent 0.0651(0.0645) | Loss 3.7106(3.7115) | Error 0.0195(0.0210) Steps 658(672.05) | Grad Norm 2.7283(2.4280) | Total Time 14.00(14.00)\n",
      "Iter 4402 | Time 62.4376(60.4049) | Bit/dim 3.6810(3.6793) | Xent 0.0639(0.0645) | Loss 3.7129(3.7115) | Error 0.0195(0.0209) Steps 682(672.35) | Grad Norm 2.6114(2.4335) | Total Time 14.00(14.00)\n",
      "Iter 4403 | Time 59.3673(60.3737) | Bit/dim 3.6726(3.6791) | Xent 0.0654(0.0645) | Loss 3.7052(3.7113) | Error 0.0211(0.0209) Steps 670(672.28) | Grad Norm 3.2132(2.4569) | Total Time 14.00(14.00)\n",
      "Iter 4404 | Time 61.6022(60.4106) | Bit/dim 3.6773(3.6790) | Xent 0.0597(0.0643) | Loss 3.7072(3.7112) | Error 0.0200(0.0209) Steps 688(672.75) | Grad Norm 1.9407(2.4414) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0734 | Time 24.8312, Epoch Time 401.8422(404.3027), Bit/dim 3.7047(best: 3.7028), Xent 2.9431, Loss 5.1763, Error 0.4069(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4405 | Time 56.9521(60.3068) | Bit/dim 3.6754(3.6789) | Xent 0.0581(0.0641) | Loss 3.7044(3.7110) | Error 0.0181(0.0208) Steps 670(672.67) | Grad Norm 3.5664(2.4751) | Total Time 14.00(14.00)\n",
      "Iter 4406 | Time 60.0634(60.2995) | Bit/dim 3.6841(3.6791) | Xent 0.0586(0.0640) | Loss 3.7134(3.7111) | Error 0.0192(0.0208) Steps 664(672.41) | Grad Norm 2.0253(2.4616) | Total Time 14.00(14.00)\n",
      "Iter 4407 | Time 60.4066(60.3028) | Bit/dim 3.6835(3.6792) | Xent 0.0606(0.0639) | Loss 3.7138(3.7112) | Error 0.0198(0.0207) Steps 676(672.51) | Grad Norm 1.3639(2.4287) | Total Time 14.00(14.00)\n",
      "Iter 4408 | Time 61.3654(60.3346) | Bit/dim 3.6781(3.6792) | Xent 0.0615(0.0638) | Loss 3.7088(3.7111) | Error 0.0206(0.0207) Steps 664(672.26) | Grad Norm 1.7591(2.4086) | Total Time 14.00(14.00)\n",
      "Iter 4409 | Time 61.6010(60.3726) | Bit/dim 3.6800(3.6792) | Xent 0.0630(0.0638) | Loss 3.7115(3.7111) | Error 0.0202(0.0207) Steps 664(672.01) | Grad Norm 2.5315(2.4123) | Total Time 14.00(14.00)\n",
      "Iter 4410 | Time 61.9973(60.4214) | Bit/dim 3.6753(3.6791) | Xent 0.0710(0.0640) | Loss 3.7107(3.7111) | Error 0.0236(0.0208) Steps 670(671.95) | Grad Norm 1.9118(2.3973) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0735 | Time 24.7959, Epoch Time 402.8740(404.2599), Bit/dim 3.7031(best: 3.7028), Xent 2.9978, Loss 5.2020, Error 0.4080(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4411 | Time 57.1476(60.3232) | Bit/dim 3.6859(3.6793) | Xent 0.0554(0.0637) | Loss 3.7136(3.7112) | Error 0.0191(0.0207) Steps 664(671.71) | Grad Norm 1.9075(2.3826) | Total Time 14.00(14.00)\n",
      "Iter 4412 | Time 62.4498(60.3870) | Bit/dim 3.6894(3.6796) | Xent 0.0617(0.0637) | Loss 3.7203(3.7114) | Error 0.0189(0.0207) Steps 682(672.02) | Grad Norm 2.1661(2.3761) | Total Time 14.00(14.00)\n",
      "Iter 4413 | Time 59.2220(60.3520) | Bit/dim 3.6758(3.6795) | Xent 0.0679(0.0638) | Loss 3.7097(3.7114) | Error 0.0230(0.0208) Steps 664(671.78) | Grad Norm 2.4002(2.3768) | Total Time 14.00(14.00)\n",
      "Iter 4414 | Time 61.9880(60.4011) | Bit/dim 3.6769(3.6794) | Xent 0.0579(0.0636) | Loss 3.7058(3.7112) | Error 0.0192(0.0207) Steps 682(672.09) | Grad Norm 1.6170(2.3540) | Total Time 14.00(14.00)\n",
      "Iter 4415 | Time 61.4425(60.4323) | Bit/dim 3.6734(3.6792) | Xent 0.0604(0.0635) | Loss 3.7036(3.7110) | Error 0.0195(0.0207) Steps 670(672.02) | Grad Norm 1.9818(2.3429) | Total Time 14.00(14.00)\n",
      "Iter 4416 | Time 59.3218(60.3990) | Bit/dim 3.6725(3.6790) | Xent 0.0657(0.0636) | Loss 3.7053(3.7108) | Error 0.0235(0.0208) Steps 676(672.14) | Grad Norm 1.6191(2.3211) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0736 | Time 24.9637, Epoch Time 402.3625(404.2029), Bit/dim 3.7049(best: 3.7028), Xent 2.9800, Loss 5.1949, Error 0.4124(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4417 | Time 59.8077(60.3813) | Bit/dim 3.6777(3.6790) | Xent 0.0694(0.0638) | Loss 3.7124(3.7109) | Error 0.0224(0.0208) Steps 664(671.90) | Grad Norm 1.8135(2.3059) | Total Time 14.00(14.00)\n",
      "Iter 4418 | Time 59.6160(60.3583) | Bit/dim 3.6796(3.6790) | Xent 0.0654(0.0638) | Loss 3.7123(3.7109) | Error 0.0226(0.0209) Steps 682(672.20) | Grad Norm 1.9182(2.2943) | Total Time 14.00(14.00)\n",
      "Iter 4419 | Time 61.1951(60.3834) | Bit/dim 3.6854(3.6792) | Xent 0.0561(0.0636) | Loss 3.7134(3.7110) | Error 0.0188(0.0208) Steps 676(672.32) | Grad Norm 1.4485(2.2689) | Total Time 14.00(14.00)\n",
      "Iter 4420 | Time 59.8052(60.3661) | Bit/dim 3.6820(3.6793) | Xent 0.0584(0.0634) | Loss 3.7112(3.7110) | Error 0.0184(0.0207) Steps 670(672.25) | Grad Norm 2.2599(2.2686) | Total Time 14.00(14.00)\n",
      "Iter 4421 | Time 61.0991(60.3881) | Bit/dim 3.6698(3.6790) | Xent 0.0670(0.0635) | Loss 3.7033(3.7108) | Error 0.0231(0.0208) Steps 682(672.54) | Grad Norm 1.6524(2.2502) | Total Time 14.00(14.00)\n",
      "Iter 4422 | Time 58.4598(60.3302) | Bit/dim 3.6820(3.6791) | Xent 0.0579(0.0634) | Loss 3.7110(3.7108) | Error 0.0178(0.0207) Steps 670(672.46) | Grad Norm 1.3764(2.2239) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0737 | Time 25.2404, Epoch Time 400.9816(404.1063), Bit/dim 3.7026(best: 3.7028), Xent 2.8914, Loss 5.1483, Error 0.4074(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4423 | Time 61.6885(60.3710) | Bit/dim 3.6847(3.6793) | Xent 0.0655(0.0634) | Loss 3.7174(3.7110) | Error 0.0216(0.0207) Steps 670(672.39) | Grad Norm 1.6202(2.2058) | Total Time 14.00(14.00)\n",
      "Iter 4424 | Time 62.8407(60.4450) | Bit/dim 3.6687(3.6789) | Xent 0.0615(0.0634) | Loss 3.6994(3.7106) | Error 0.0200(0.0207) Steps 688(672.86) | Grad Norm 1.5663(2.1866) | Total Time 14.00(14.00)\n",
      "Iter 4425 | Time 60.7941(60.4555) | Bit/dim 3.6772(3.6789) | Xent 0.0635(0.0634) | Loss 3.7089(3.7106) | Error 0.0215(0.0207) Steps 670(672.77) | Grad Norm 2.6987(2.2020) | Total Time 14.00(14.00)\n",
      "Iter 4426 | Time 60.7257(60.4636) | Bit/dim 3.6836(3.6790) | Xent 0.0567(0.0632) | Loss 3.7119(3.7106) | Error 0.0192(0.0207) Steps 682(673.05) | Grad Norm 1.2159(2.1724) | Total Time 14.00(14.00)\n",
      "Iter 4427 | Time 60.0892(60.4524) | Bit/dim 3.6805(3.6791) | Xent 0.0589(0.0631) | Loss 3.7099(3.7106) | Error 0.0200(0.0207) Steps 664(672.78) | Grad Norm 1.6099(2.1555) | Total Time 14.00(14.00)\n",
      "Iter 4428 | Time 60.4697(60.4529) | Bit/dim 3.6730(3.6789) | Xent 0.0658(0.0631) | Loss 3.7059(3.7105) | Error 0.0220(0.0207) Steps 670(672.69) | Grad Norm 2.1573(2.1556) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0738 | Time 24.8433, Epoch Time 407.4059(404.2053), Bit/dim 3.7033(best: 3.7026), Xent 2.9564, Loss 5.1815, Error 0.4077(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4429 | Time 60.3264(60.4491) | Bit/dim 3.6847(3.6791) | Xent 0.0674(0.0633) | Loss 3.7184(3.7107) | Error 0.0218(0.0207) Steps 670(672.61) | Grad Norm 1.7114(2.1423) | Total Time 14.00(14.00)\n",
      "Iter 4430 | Time 63.7992(60.5496) | Bit/dim 3.6668(3.6787) | Xent 0.0643(0.0633) | Loss 3.6989(3.7103) | Error 0.0216(0.0208) Steps 682(672.89) | Grad Norm 1.9668(2.1370) | Total Time 14.00(14.00)\n",
      "Iter 4431 | Time 60.2534(60.5407) | Bit/dim 3.6774(3.6787) | Xent 0.0598(0.0632) | Loss 3.7073(3.7102) | Error 0.0208(0.0208) Steps 688(673.35) | Grad Norm 1.5908(2.1206) | Total Time 14.00(14.00)\n",
      "Iter 4432 | Time 60.0586(60.5263) | Bit/dim 3.6804(3.6787) | Xent 0.0658(0.0633) | Loss 3.7133(3.7103) | Error 0.0208(0.0208) Steps 670(673.25) | Grad Norm 1.5099(2.1023) | Total Time 14.00(14.00)\n",
      "Iter 4433 | Time 60.5475(60.5269) | Bit/dim 3.6846(3.6789) | Xent 0.0659(0.0633) | Loss 3.7176(3.7106) | Error 0.0210(0.0208) Steps 670(673.15) | Grad Norm 2.3404(2.1094) | Total Time 14.00(14.00)\n",
      "Iter 4434 | Time 62.2243(60.5778) | Bit/dim 3.6800(3.6789) | Xent 0.0568(0.0631) | Loss 3.7084(3.7105) | Error 0.0199(0.0207) Steps 676(673.24) | Grad Norm 1.1388(2.0803) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0739 | Time 24.5540, Epoch Time 407.4681(404.3032), Bit/dim 3.7030(best: 3.7026), Xent 2.9401, Loss 5.1731, Error 0.4059(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4435 | Time 60.3216(60.5701) | Bit/dim 3.6684(3.6786) | Xent 0.0630(0.0631) | Loss 3.6999(3.7102) | Error 0.0206(0.0207) Steps 676(673.32) | Grad Norm 1.2328(2.0549) | Total Time 14.00(14.00)\n",
      "Iter 4436 | Time 59.9402(60.5512) | Bit/dim 3.6873(3.6789) | Xent 0.0615(0.0631) | Loss 3.7181(3.7104) | Error 0.0198(0.0207) Steps 676(673.40) | Grad Norm 2.0656(2.0552) | Total Time 14.00(14.00)\n",
      "Iter 4437 | Time 59.8308(60.5296) | Bit/dim 3.6693(3.6786) | Xent 0.0637(0.0631) | Loss 3.7012(3.7101) | Error 0.0210(0.0207) Steps 676(673.48) | Grad Norm 1.2960(2.0324) | Total Time 14.00(14.00)\n",
      "Iter 4438 | Time 58.9820(60.4832) | Bit/dim 3.6704(3.6783) | Xent 0.0610(0.0630) | Loss 3.7009(3.7099) | Error 0.0211(0.0207) Steps 676(673.55) | Grad Norm 1.9183(2.0290) | Total Time 14.00(14.00)\n",
      "Iter 4439 | Time 59.2184(60.4453) | Bit/dim 3.6861(3.6786) | Xent 0.0560(0.0628) | Loss 3.7140(3.7100) | Error 0.0188(0.0207) Steps 670(673.45) | Grad Norm 1.8370(2.0233) | Total Time 14.00(14.00)\n",
      "Iter 4440 | Time 59.9920(60.4317) | Bit/dim 3.6823(3.6787) | Xent 0.0601(0.0628) | Loss 3.7123(3.7101) | Error 0.0189(0.0206) Steps 670(673.34) | Grad Norm 1.3479(2.0030) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0740 | Time 25.0362, Epoch Time 398.9357(404.1422), Bit/dim 3.7016(best: 3.7026), Xent 2.9559, Loss 5.1796, Error 0.4052(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4441 | Time 57.6217(60.3474) | Bit/dim 3.6752(3.6786) | Xent 0.0630(0.0628) | Loss 3.7067(3.7100) | Error 0.0204(0.0206) Steps 664(673.06) | Grad Norm 1.5312(1.9888) | Total Time 14.00(14.00)\n",
      "Iter 4442 | Time 60.6483(60.3564) | Bit/dim 3.6782(3.6786) | Xent 0.0585(0.0626) | Loss 3.7074(3.7099) | Error 0.0191(0.0206) Steps 670(672.97) | Grad Norm 1.9273(1.9870) | Total Time 14.00(14.00)\n",
      "Iter 4443 | Time 61.4423(60.3890) | Bit/dim 3.6698(3.6783) | Xent 0.0587(0.0625) | Loss 3.6991(3.7096) | Error 0.0186(0.0205) Steps 676(673.06) | Grad Norm 1.7279(1.9792) | Total Time 14.00(14.00)\n",
      "Iter 4444 | Time 60.9220(60.4050) | Bit/dim 3.6869(3.6786) | Xent 0.0637(0.0625) | Loss 3.7188(3.7098) | Error 0.0196(0.0205) Steps 682(673.33) | Grad Norm 1.8755(1.9761) | Total Time 14.00(14.00)\n",
      "Iter 4445 | Time 61.8934(60.4496) | Bit/dim 3.6768(3.6785) | Xent 0.0616(0.0625) | Loss 3.7076(3.7098) | Error 0.0191(0.0204) Steps 670(673.23) | Grad Norm 2.3069(1.9860) | Total Time 14.00(14.00)\n",
      "Iter 4446 | Time 58.4383(60.3893) | Bit/dim 3.6833(3.6786) | Xent 0.0575(0.0624) | Loss 3.7121(3.7098) | Error 0.0184(0.0204) Steps 676(673.31) | Grad Norm 1.3861(1.9680) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0741 | Time 24.9506, Epoch Time 401.8199(404.0725), Bit/dim 3.7033(best: 3.7016), Xent 2.9681, Loss 5.1874, Error 0.4085(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4447 | Time 59.8319(60.3726) | Bit/dim 3.6734(3.6785) | Xent 0.0597(0.0623) | Loss 3.7033(3.7096) | Error 0.0205(0.0204) Steps 670(673.21) | Grad Norm 2.6525(1.9886) | Total Time 14.00(14.00)\n",
      "Iter 4448 | Time 60.9962(60.3913) | Bit/dim 3.6849(3.6787) | Xent 0.0568(0.0621) | Loss 3.7133(3.7097) | Error 0.0189(0.0203) Steps 664(672.94) | Grad Norm 1.2282(1.9658) | Total Time 14.00(14.00)\n",
      "Iter 4449 | Time 62.4009(60.4516) | Bit/dim 3.6666(3.6783) | Xent 0.0670(0.0623) | Loss 3.7000(3.7095) | Error 0.0230(0.0204) Steps 670(672.85) | Grad Norm 1.4488(1.9502) | Total Time 14.00(14.00)\n",
      "Iter 4450 | Time 59.9493(60.4365) | Bit/dim 3.6737(3.6782) | Xent 0.0563(0.0621) | Loss 3.7018(3.7092) | Error 0.0191(0.0204) Steps 664(672.58) | Grad Norm 1.2505(1.9293) | Total Time 14.00(14.00)\n",
      "Iter 4451 | Time 61.2119(60.4597) | Bit/dim 3.6892(3.6785) | Xent 0.0677(0.0623) | Loss 3.7231(3.7096) | Error 0.0219(0.0204) Steps 676(672.69) | Grad Norm 1.9399(1.9296) | Total Time 14.00(14.00)\n",
      "Iter 4452 | Time 61.3059(60.4851) | Bit/dim 3.6816(3.6786) | Xent 0.0635(0.0623) | Loss 3.7133(3.7098) | Error 0.0196(0.0204) Steps 676(672.79) | Grad Norm 1.7405(1.9239) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0742 | Time 25.2086, Epoch Time 406.9958(404.1602), Bit/dim 3.7033(best: 3.7016), Xent 2.9928, Loss 5.1997, Error 0.4059(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4453 | Time 61.6989(60.5215) | Bit/dim 3.6743(3.6785) | Xent 0.0685(0.0625) | Loss 3.7085(3.7097) | Error 0.0222(0.0205) Steps 682(673.06) | Grad Norm 1.7191(1.9178) | Total Time 14.00(14.00)\n",
      "Iter 4454 | Time 59.5951(60.4938) | Bit/dim 3.6756(3.6784) | Xent 0.0625(0.0625) | Loss 3.7068(3.7096) | Error 0.0195(0.0204) Steps 664(672.79) | Grad Norm 1.4848(1.9048) | Total Time 14.00(14.00)\n",
      "Iter 4455 | Time 58.0781(60.4213) | Bit/dim 3.6788(3.6784) | Xent 0.0633(0.0625) | Loss 3.7105(3.7097) | Error 0.0201(0.0204) Steps 676(672.89) | Grad Norm 1.5928(1.8954) | Total Time 14.00(14.00)\n",
      "Iter 4456 | Time 60.8613(60.4345) | Bit/dim 3.6823(3.6785) | Xent 0.0548(0.0623) | Loss 3.7097(3.7097) | Error 0.0174(0.0203) Steps 676(672.98) | Grad Norm 1.2747(1.8768) | Total Time 14.00(14.00)\n",
      "Iter 4457 | Time 61.4828(60.4659) | Bit/dim 3.6788(3.6785) | Xent 0.0628(0.0623) | Loss 3.7102(3.7097) | Error 0.0201(0.0203) Steps 676(673.07) | Grad Norm 1.7103(1.8718) | Total Time 14.00(14.00)\n",
      "Iter 4458 | Time 59.7643(60.4449) | Bit/dim 3.6674(3.6782) | Xent 0.0564(0.0621) | Loss 3.6956(3.7092) | Error 0.0194(0.0203) Steps 676(673.16) | Grad Norm 2.0762(1.8779) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0743 | Time 25.2354, Epoch Time 402.8313(404.1203), Bit/dim 3.7018(best: 3.7016), Xent 2.9334, Loss 5.1685, Error 0.4069(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4459 | Time 65.2395(60.5887) | Bit/dim 3.6874(3.6785) | Xent 0.0638(0.0622) | Loss 3.7193(3.7095) | Error 0.0191(0.0203) Steps 688(673.60) | Grad Norm 1.0821(1.8541) | Total Time 14.00(14.00)\n",
      "Iter 4460 | Time 58.0197(60.5117) | Bit/dim 3.6734(3.6783) | Xent 0.0642(0.0622) | Loss 3.7054(3.7094) | Error 0.0205(0.0203) Steps 670(673.50) | Grad Norm 2.1006(1.8614) | Total Time 14.00(14.00)\n",
      "Iter 4461 | Time 60.6728(60.5165) | Bit/dim 3.6882(3.6786) | Xent 0.0603(0.0622) | Loss 3.7183(3.7097) | Error 0.0204(0.0203) Steps 676(673.57) | Grad Norm 1.5508(1.8521) | Total Time 14.00(14.00)\n",
      "Iter 4462 | Time 59.5745(60.4882) | Bit/dim 3.6678(3.6783) | Xent 0.0599(0.0621) | Loss 3.6978(3.7093) | Error 0.0188(0.0202) Steps 676(673.64) | Grad Norm 2.2978(1.8655) | Total Time 14.00(14.00)\n",
      "Iter 4463 | Time 63.1023(60.5667) | Bit/dim 3.6703(3.6780) | Xent 0.0658(0.0622) | Loss 3.7032(3.7092) | Error 0.0195(0.0202) Steps 676(673.71) | Grad Norm 1.8446(1.8649) | Total Time 14.00(14.00)\n",
      "Iter 4464 | Time 61.4929(60.5944) | Bit/dim 3.6785(3.6781) | Xent 0.0569(0.0621) | Loss 3.7069(3.7091) | Error 0.0182(0.0201) Steps 688(674.14) | Grad Norm 2.0725(1.8711) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0744 | Time 24.7877, Epoch Time 408.8415(404.2620), Bit/dim 3.7027(best: 3.7016), Xent 2.9694, Loss 5.1874, Error 0.4093(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4465 | Time 62.0519(60.6382) | Bit/dim 3.6678(3.6777) | Xent 0.0614(0.0620) | Loss 3.6985(3.7088) | Error 0.0205(0.0202) Steps 676(674.20) | Grad Norm 2.4207(1.8876) | Total Time 14.00(14.00)\n",
      "Iter 4466 | Time 59.8377(60.6142) | Bit/dim 3.6879(3.6781) | Xent 0.0555(0.0618) | Loss 3.7157(3.7090) | Error 0.0188(0.0201) Steps 670(674.07) | Grad Norm 1.9131(1.8884) | Total Time 14.00(14.00)\n",
      "Iter 4467 | Time 62.0998(60.6587) | Bit/dim 3.6744(3.6779) | Xent 0.0639(0.0619) | Loss 3.7064(3.7089) | Error 0.0200(0.0201) Steps 676(674.13) | Grad Norm 1.5162(1.8772) | Total Time 14.00(14.00)\n",
      "Iter 4468 | Time 61.1255(60.6727) | Bit/dim 3.6824(3.6781) | Xent 0.0664(0.0620) | Loss 3.7156(3.7091) | Error 0.0229(0.0202) Steps 676(674.19) | Grad Norm 2.4371(1.8940) | Total Time 14.00(14.00)\n",
      "Iter 4469 | Time 60.0845(60.6551) | Bit/dim 3.6692(3.6778) | Xent 0.0605(0.0620) | Loss 3.6994(3.7088) | Error 0.0206(0.0202) Steps 670(674.06) | Grad Norm 1.2486(1.8746) | Total Time 14.00(14.00)\n",
      "Iter 4470 | Time 61.8368(60.6905) | Bit/dim 3.6834(3.6780) | Xent 0.0601(0.0619) | Loss 3.7135(3.7089) | Error 0.0196(0.0202) Steps 676(674.12) | Grad Norm 1.0373(1.8495) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0745 | Time 25.0302, Epoch Time 407.5543(404.3607), Bit/dim 3.7027(best: 3.7016), Xent 2.9510, Loss 5.1782, Error 0.4081(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4471 | Time 57.6883(60.6005) | Bit/dim 3.6779(3.6780) | Xent 0.0563(0.0618) | Loss 3.7061(3.7089) | Error 0.0189(0.0201) Steps 664(673.82) | Grad Norm 1.1272(1.8278) | Total Time 14.00(14.00)\n",
      "Iter 4472 | Time 61.1675(60.6175) | Bit/dim 3.6878(3.6783) | Xent 0.0593(0.0617) | Loss 3.7175(3.7091) | Error 0.0185(0.0201) Steps 670(673.70) | Grad Norm 1.8302(1.8279) | Total Time 14.00(14.00)\n",
      "Iter 4473 | Time 60.1905(60.6047) | Bit/dim 3.6757(3.6782) | Xent 0.0586(0.0616) | Loss 3.7050(3.7090) | Error 0.0201(0.0201) Steps 670(673.59) | Grad Norm 1.5849(1.8206) | Total Time 14.00(14.00)\n",
      "Iter 4474 | Time 59.6425(60.5758) | Bit/dim 3.6820(3.6783) | Xent 0.0524(0.0613) | Loss 3.7082(3.7090) | Error 0.0181(0.0200) Steps 670(673.48) | Grad Norm 1.9201(1.8236) | Total Time 14.00(14.00)\n",
      "Iter 4475 | Time 62.1544(60.6232) | Bit/dim 3.6698(3.6781) | Xent 0.0609(0.0613) | Loss 3.7003(3.7087) | Error 0.0199(0.0200) Steps 682(673.74) | Grad Norm 1.2662(1.8069) | Total Time 14.00(14.00)\n",
      "Iter 4476 | Time 61.5391(60.6506) | Bit/dim 3.6761(3.6780) | Xent 0.0527(0.0610) | Loss 3.7025(3.7085) | Error 0.0194(0.0200) Steps 670(673.63) | Grad Norm 1.5333(1.7987) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0746 | Time 25.0877, Epoch Time 407.4263(404.4527), Bit/dim 3.7021(best: 3.7016), Xent 2.9698, Loss 5.1870, Error 0.4077(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4477 | Time 58.4313(60.5841) | Bit/dim 3.6783(3.6780) | Xent 0.0594(0.0610) | Loss 3.7080(3.7085) | Error 0.0188(0.0200) Steps 670(673.52) | Grad Norm 1.3768(1.7860) | Total Time 14.00(14.00)\n",
      "Iter 4478 | Time 60.7113(60.5879) | Bit/dim 3.6807(3.6781) | Xent 0.0518(0.0607) | Loss 3.7066(3.7085) | Error 0.0161(0.0199) Steps 676(673.59) | Grad Norm 1.1305(1.7664) | Total Time 14.00(14.00)\n",
      "Iter 4479 | Time 59.8020(60.5643) | Bit/dim 3.6702(3.6779) | Xent 0.0620(0.0608) | Loss 3.7012(3.7082) | Error 0.0204(0.0199) Steps 670(673.48) | Grad Norm 1.7196(1.7649) | Total Time 14.00(14.00)\n",
      "Iter 4480 | Time 62.0868(60.6100) | Bit/dim 3.6793(3.6779) | Xent 0.0536(0.0605) | Loss 3.7061(3.7082) | Error 0.0174(0.0198) Steps 676(673.56) | Grad Norm 1.4593(1.7558) | Total Time 14.00(14.00)\n",
      "Iter 4481 | Time 59.2434(60.5690) | Bit/dim 3.6830(3.6780) | Xent 0.0636(0.0606) | Loss 3.7148(3.7084) | Error 0.0195(0.0198) Steps 670(673.45) | Grad Norm 1.2758(1.7414) | Total Time 14.00(14.00)\n",
      "Iter 4482 | Time 60.3837(60.5634) | Bit/dim 3.6759(3.6780) | Xent 0.0593(0.0606) | Loss 3.7055(3.7083) | Error 0.0202(0.0198) Steps 670(673.35) | Grad Norm 1.7574(1.7419) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0747 | Time 24.9903, Epoch Time 401.3964(404.3610), Bit/dim 3.7020(best: 3.7016), Xent 2.9676, Loss 5.1858, Error 0.4059(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4483 | Time 60.5032(60.5616) | Bit/dim 3.6769(3.6779) | Xent 0.0606(0.0606) | Loss 3.7072(3.7082) | Error 0.0208(0.0198) Steps 664(673.07) | Grad Norm 1.3285(1.7295) | Total Time 14.00(14.00)\n",
      "Iter 4484 | Time 61.8183(60.5993) | Bit/dim 3.6724(3.6778) | Xent 0.0560(0.0605) | Loss 3.7004(3.7080) | Error 0.0209(0.0199) Steps 670(672.98) | Grad Norm 2.6143(1.7560) | Total Time 14.00(14.00)\n",
      "Iter 4485 | Time 61.7494(60.6338) | Bit/dim 3.6786(3.6778) | Xent 0.0592(0.0604) | Loss 3.7083(3.7080) | Error 0.0190(0.0198) Steps 670(672.89) | Grad Norm 1.1991(1.7393) | Total Time 14.00(14.00)\n",
      "Iter 4486 | Time 60.9978(60.6447) | Bit/dim 3.6816(3.6779) | Xent 0.0666(0.0606) | Loss 3.7149(3.7082) | Error 0.0220(0.0199) Steps 670(672.80) | Grad Norm 2.9929(1.7769) | Total Time 14.00(14.00)\n",
      "Iter 4487 | Time 60.8891(60.6521) | Bit/dim 3.6774(3.6779) | Xent 0.0626(0.0607) | Loss 3.7087(3.7082) | Error 0.0201(0.0199) Steps 676(672.90) | Grad Norm 1.5687(1.7707) | Total Time 14.00(14.00)\n",
      "Iter 4488 | Time 61.2963(60.6714) | Bit/dim 3.6787(3.6779) | Xent 0.0588(0.0606) | Loss 3.7081(3.7082) | Error 0.0185(0.0199) Steps 664(672.63) | Grad Norm 1.1677(1.7526) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0748 | Time 24.9598, Epoch Time 408.0854(404.4727), Bit/dim 3.7028(best: 3.7016), Xent 2.9625, Loss 5.1840, Error 0.4071(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4489 | Time 60.3797(60.6626) | Bit/dim 3.6785(3.6779) | Xent 0.0641(0.0607) | Loss 3.7105(3.7083) | Error 0.0206(0.0199) Steps 676(672.73) | Grad Norm 3.1302(1.7939) | Total Time 14.00(14.00)\n",
      "Iter 4490 | Time 59.4422(60.6260) | Bit/dim 3.6881(3.6782) | Xent 0.0540(0.0605) | Loss 3.7151(3.7085) | Error 0.0198(0.0199) Steps 664(672.47) | Grad Norm 1.9398(1.7983) | Total Time 14.00(14.00)\n",
      "Iter 4491 | Time 63.7032(60.7183) | Bit/dim 3.6717(3.6781) | Xent 0.0610(0.0605) | Loss 3.7022(3.7083) | Error 0.0200(0.0199) Steps 670(672.39) | Grad Norm 3.6293(1.8532) | Total Time 14.00(14.00)\n",
      "Iter 4492 | Time 59.6662(60.6868) | Bit/dim 3.6736(3.6779) | Xent 0.0651(0.0607) | Loss 3.7061(3.7083) | Error 0.0231(0.0200) Steps 682(672.68) | Grad Norm 2.4603(1.8714) | Total Time 14.00(14.00)\n",
      "Iter 4493 | Time 61.2425(60.7034) | Bit/dim 3.6747(3.6778) | Xent 0.0525(0.0604) | Loss 3.7009(3.7080) | Error 0.0168(0.0199) Steps 676(672.78) | Grad Norm 1.3293(1.8552) | Total Time 14.00(14.00)\n",
      "Iter 4494 | Time 61.3777(60.7237) | Bit/dim 3.6752(3.6777) | Xent 0.0610(0.0604) | Loss 3.7057(3.7080) | Error 0.0199(0.0199) Steps 664(672.52) | Grad Norm 1.7537(1.8521) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0749 | Time 25.0183, Epoch Time 406.8090(404.5428), Bit/dim 3.7029(best: 3.7016), Xent 2.9855, Loss 5.1957, Error 0.4082(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4495 | Time 61.8968(60.7589) | Bit/dim 3.6750(3.6777) | Xent 0.0662(0.0606) | Loss 3.7081(3.7080) | Error 0.0198(0.0199) Steps 682(672.80) | Grad Norm 2.2469(1.8640) | Total Time 14.00(14.00)\n",
      "Iter 4496 | Time 60.1715(60.7412) | Bit/dim 3.6923(3.6781) | Xent 0.0585(0.0605) | Loss 3.7215(3.7084) | Error 0.0176(0.0198) Steps 664(672.54) | Grad Norm 1.1681(1.8431) | Total Time 14.00(14.00)\n",
      "Iter 4497 | Time 59.3389(60.6992) | Bit/dim 3.6837(3.6783) | Xent 0.0666(0.0607) | Loss 3.7170(3.7086) | Error 0.0211(0.0199) Steps 664(672.28) | Grad Norm 2.3918(1.8595) | Total Time 14.00(14.00)\n",
      "Iter 4498 | Time 58.8548(60.6438) | Bit/dim 3.6619(3.6778) | Xent 0.0529(0.0605) | Loss 3.6884(3.7080) | Error 0.0164(0.0198) Steps 670(672.21) | Grad Norm 0.8854(1.8303) | Total Time 14.00(14.00)\n",
      "Iter 4499 | Time 60.5414(60.6408) | Bit/dim 3.6803(3.6779) | Xent 0.0640(0.0606) | Loss 3.7123(3.7082) | Error 0.0214(0.0198) Steps 670(672.15) | Grad Norm 1.6468(1.8248) | Total Time 14.00(14.00)\n",
      "Iter 4500 | Time 61.0857(60.6541) | Bit/dim 3.6680(3.6776) | Xent 0.0576(0.0605) | Loss 3.6968(3.7078) | Error 0.0198(0.0198) Steps 676(672.26) | Grad Norm 1.2058(1.8062) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0750 | Time 24.9979, Epoch Time 402.6332(404.4855), Bit/dim 3.7020(best: 3.7016), Xent 2.9636, Loss 5.1838, Error 0.4088(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4501 | Time 61.3926(60.6763) | Bit/dim 3.6902(3.6779) | Xent 0.0565(0.0604) | Loss 3.7185(3.7081) | Error 0.0192(0.0198) Steps 676(672.38) | Grad Norm 1.8942(1.8089) | Total Time 14.00(14.00)\n",
      "Iter 4502 | Time 58.3715(60.6071) | Bit/dim 3.6703(3.6777) | Xent 0.0580(0.0603) | Loss 3.6993(3.7079) | Error 0.0192(0.0198) Steps 676(672.48) | Grad Norm 1.9653(1.8136) | Total Time 14.00(14.00)\n",
      "Iter 4503 | Time 62.7095(60.6702) | Bit/dim 3.6768(3.6777) | Xent 0.0585(0.0603) | Loss 3.7061(3.7078) | Error 0.0194(0.0198) Steps 670(672.41) | Grad Norm 1.4844(1.8037) | Total Time 14.00(14.00)\n",
      "Iter 4504 | Time 60.4140(60.6625) | Bit/dim 3.6747(3.6776) | Xent 0.0678(0.0605) | Loss 3.7086(3.7078) | Error 0.0206(0.0198) Steps 682(672.70) | Grad Norm 1.5506(1.7961) | Total Time 14.00(14.00)\n",
      "Iter 4505 | Time 60.3280(60.6525) | Bit/dim 3.6821(3.6777) | Xent 0.0588(0.0604) | Loss 3.7114(3.7079) | Error 0.0192(0.0198) Steps 676(672.80) | Grad Norm 1.8703(1.7983) | Total Time 14.00(14.00)\n",
      "Iter 4506 | Time 57.3288(60.5528) | Bit/dim 3.6726(3.6776) | Xent 0.0625(0.0605) | Loss 3.7039(3.7078) | Error 0.0196(0.0198) Steps 676(672.89) | Grad Norm 1.2633(1.7823) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0751 | Time 25.0840, Epoch Time 401.1629(404.3859), Bit/dim 3.7027(best: 3.7016), Xent 2.9630, Loss 5.1842, Error 0.4068(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4507 | Time 57.8052(60.4703) | Bit/dim 3.6765(3.6775) | Xent 0.0624(0.0606) | Loss 3.7077(3.7078) | Error 0.0192(0.0197) Steps 670(672.81) | Grad Norm 1.0933(1.7616) | Total Time 14.00(14.00)\n",
      "Iter 4508 | Time 60.6757(60.4765) | Bit/dim 3.6740(3.6774) | Xent 0.0677(0.0608) | Loss 3.7079(3.7078) | Error 0.0221(0.0198) Steps 670(672.72) | Grad Norm 1.8923(1.7655) | Total Time 14.00(14.00)\n",
      "Iter 4509 | Time 61.7201(60.5138) | Bit/dim 3.6762(3.6774) | Xent 0.0569(0.0607) | Loss 3.7046(3.7077) | Error 0.0190(0.0198) Steps 670(672.64) | Grad Norm 2.3432(1.7829) | Total Time 14.00(14.00)\n",
      "Iter 4510 | Time 61.8354(60.5535) | Bit/dim 3.6797(3.6775) | Xent 0.0588(0.0606) | Loss 3.7091(3.7078) | Error 0.0179(0.0197) Steps 670(672.56) | Grad Norm 1.3085(1.7686) | Total Time 14.00(14.00)\n",
      "Iter 4511 | Time 61.1960(60.5727) | Bit/dim 3.6805(3.6776) | Xent 0.0613(0.0606) | Loss 3.7111(3.7079) | Error 0.0201(0.0197) Steps 676(672.66) | Grad Norm 2.2588(1.7833) | Total Time 14.00(14.00)\n",
      "Iter 4512 | Time 62.7356(60.6376) | Bit/dim 3.6726(3.6774) | Xent 0.0532(0.0604) | Loss 3.6992(3.7076) | Error 0.0169(0.0197) Steps 670(672.58) | Grad Norm 1.2101(1.7661) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0752 | Time 24.9858, Epoch Time 406.6109(404.4526), Bit/dim 3.7021(best: 3.7016), Xent 2.9608, Loss 5.1826, Error 0.4063(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4513 | Time 60.7847(60.6420) | Bit/dim 3.6712(3.6772) | Xent 0.0521(0.0602) | Loss 3.6972(3.7073) | Error 0.0170(0.0196) Steps 676(672.69) | Grad Norm 1.2895(1.7518) | Total Time 14.00(14.00)\n",
      "Iter 4514 | Time 60.4012(60.6348) | Bit/dim 3.6758(3.6772) | Xent 0.0584(0.0601) | Loss 3.7050(3.7072) | Error 0.0169(0.0195) Steps 658(672.25) | Grad Norm 1.4964(1.7442) | Total Time 14.00(14.00)\n",
      "Iter 4515 | Time 60.7960(60.6396) | Bit/dim 3.6716(3.6770) | Xent 0.0573(0.0600) | Loss 3.7002(3.7070) | Error 0.0170(0.0194) Steps 706(673.26) | Grad Norm 1.5768(1.7392) | Total Time 14.00(14.00)\n",
      "Iter 4516 | Time 61.9631(60.6793) | Bit/dim 3.6774(3.6770) | Xent 0.0522(0.0598) | Loss 3.7035(3.7069) | Error 0.0174(0.0194) Steps 676(673.34) | Grad Norm 1.3553(1.7276) | Total Time 14.00(14.00)\n",
      "Iter 4517 | Time 60.1853(60.6645) | Bit/dim 3.6747(3.6770) | Xent 0.0536(0.0596) | Loss 3.7015(3.7067) | Error 0.0168(0.0193) Steps 658(672.88) | Grad Norm 1.7990(1.7298) | Total Time 14.00(14.00)\n",
      "Iter 4518 | Time 61.6594(60.6944) | Bit/dim 3.6891(3.6773) | Xent 0.0577(0.0595) | Loss 3.7179(3.7071) | Error 0.0195(0.0193) Steps 682(673.15) | Grad Norm 2.1491(1.7424) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0753 | Time 24.6316, Epoch Time 412.5061(404.6942), Bit/dim 3.7024(best: 3.7016), Xent 2.9547, Loss 5.1798, Error 0.4070(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4519 | Time 60.0369(60.6746) | Bit/dim 3.6727(3.6772) | Xent 0.0615(0.0596) | Loss 3.7034(3.7070) | Error 0.0180(0.0193) Steps 682(673.42) | Grad Norm 2.1506(1.7546) | Total Time 14.00(14.00)\n",
      "Iter 4520 | Time 60.0038(60.6545) | Bit/dim 3.6790(3.6772) | Xent 0.0627(0.0597) | Loss 3.7103(3.7071) | Error 0.0190(0.0192) Steps 682(673.68) | Grad Norm 1.5697(1.7491) | Total Time 14.00(14.00)\n",
      "Iter 4521 | Time 59.1495(60.6094) | Bit/dim 3.6847(3.6775) | Xent 0.0595(0.0597) | Loss 3.7145(3.7073) | Error 0.0181(0.0192) Steps 670(673.57) | Grad Norm 1.8275(1.7514) | Total Time 14.00(14.00)\n",
      "Iter 4522 | Time 60.0364(60.5922) | Bit/dim 3.6794(3.6775) | Xent 0.0601(0.0597) | Loss 3.7095(3.7074) | Error 0.0198(0.0192) Steps 688(674.00) | Grad Norm 2.8065(1.7831) | Total Time 14.00(14.00)\n",
      "Iter 4523 | Time 61.8161(60.6289) | Bit/dim 3.6679(3.6772) | Xent 0.0551(0.0596) | Loss 3.6954(3.7070) | Error 0.0172(0.0192) Steps 664(673.70) | Grad Norm 1.5862(1.7772) | Total Time 14.00(14.00)\n",
      "Iter 4524 | Time 59.4140(60.5925) | Bit/dim 3.6728(3.6771) | Xent 0.0693(0.0598) | Loss 3.7075(3.7070) | Error 0.0215(0.0192) Steps 676(673.77) | Grad Norm 2.4263(1.7966) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0754 | Time 24.8334, Epoch Time 401.4283(404.5962), Bit/dim 3.7020(best: 3.7016), Xent 2.9927, Loss 5.1984, Error 0.4153(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4525 | Time 59.1137(60.5481) | Bit/dim 3.6756(3.6770) | Xent 0.0598(0.0598) | Loss 3.7055(3.7070) | Error 0.0185(0.0192) Steps 664(673.48) | Grad Norm 1.7437(1.7950) | Total Time 14.00(14.00)\n",
      "Iter 4526 | Time 58.5279(60.4875) | Bit/dim 3.6734(3.6769) | Xent 0.0582(0.0598) | Loss 3.7025(3.7068) | Error 0.0185(0.0192) Steps 664(673.19) | Grad Norm 1.5300(1.7871) | Total Time 14.00(14.00)\n",
      "Iter 4527 | Time 57.5840(60.4004) | Bit/dim 3.6880(3.6773) | Xent 0.0676(0.0600) | Loss 3.7218(3.7073) | Error 0.0214(0.0193) Steps 664(672.92) | Grad Norm 1.4032(1.7756) | Total Time 14.00(14.00)\n",
      "Iter 4528 | Time 60.0998(60.3914) | Bit/dim 3.6789(3.6773) | Xent 0.0700(0.0603) | Loss 3.7139(3.7075) | Error 0.0229(0.0194) Steps 676(673.01) | Grad Norm 2.9359(1.8104) | Total Time 14.00(14.00)\n",
      "Iter 4529 | Time 60.1851(60.3852) | Bit/dim 3.6819(3.6775) | Xent 0.0534(0.0601) | Loss 3.7086(3.7075) | Error 0.0184(0.0193) Steps 664(672.74) | Grad Norm 2.0154(1.8165) | Total Time 14.00(14.00)\n",
      "Iter 4530 | Time 59.8681(60.3697) | Bit/dim 3.6692(3.6772) | Xent 0.0604(0.0601) | Loss 3.6994(3.7073) | Error 0.0174(0.0193) Steps 676(672.84) | Grad Norm 1.8156(1.8165) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0755 | Time 24.9213, Epoch Time 398.5499(404.4148), Bit/dim 3.7022(best: 3.7016), Xent 2.8981, Loss 5.1512, Error 0.4036(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4531 | Time 60.2757(60.3668) | Bit/dim 3.6748(3.6771) | Xent 0.0539(0.0599) | Loss 3.7017(3.7071) | Error 0.0192(0.0193) Steps 676(672.93) | Grad Norm 2.1531(1.8266) | Total Time 14.00(14.00)\n",
      "Iter 4532 | Time 60.2702(60.3639) | Bit/dim 3.6836(3.6773) | Xent 0.0665(0.0601) | Loss 3.7168(3.7074) | Error 0.0226(0.0194) Steps 658(672.48) | Grad Norm 2.1548(1.8365) | Total Time 14.00(14.00)\n",
      "Iter 4533 | Time 58.6838(60.3135) | Bit/dim 3.6730(3.6772) | Xent 0.0659(0.0603) | Loss 3.7059(3.7074) | Error 0.0222(0.0195) Steps 676(672.59) | Grad Norm 2.1494(1.8458) | Total Time 14.00(14.00)\n",
      "Iter 4534 | Time 62.5287(60.3800) | Bit/dim 3.6772(3.6772) | Xent 0.0593(0.0603) | Loss 3.7068(3.7073) | Error 0.0192(0.0195) Steps 682(672.87) | Grad Norm 2.2073(1.8567) | Total Time 14.00(14.00)\n",
      "Iter 4535 | Time 60.2800(60.3770) | Bit/dim 3.6865(3.6775) | Xent 0.0594(0.0603) | Loss 3.7162(3.7076) | Error 0.0189(0.0194) Steps 670(672.78) | Grad Norm 1.9527(1.8596) | Total Time 14.00(14.00)\n",
      "Iter 4536 | Time 60.2560(60.3734) | Bit/dim 3.6704(3.6773) | Xent 0.0504(0.0600) | Loss 3.6956(3.7072) | Error 0.0169(0.0194) Steps 676(672.88) | Grad Norm 1.7676(1.8568) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0756 | Time 24.9139, Epoch Time 402.9404(404.3706), Bit/dim 3.7007(best: 3.7016), Xent 2.9692, Loss 5.1853, Error 0.4091(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4537 | Time 62.0142(60.4226) | Bit/dim 3.6820(3.6774) | Xent 0.0534(0.0598) | Loss 3.7086(3.7073) | Error 0.0169(0.0193) Steps 670(672.79) | Grad Norm 1.6191(1.8497) | Total Time 14.00(14.00)\n",
      "Iter 4538 | Time 59.9437(60.4082) | Bit/dim 3.6723(3.6773) | Xent 0.0640(0.0599) | Loss 3.7043(3.7072) | Error 0.0211(0.0193) Steps 676(672.89) | Grad Norm 1.0674(1.8262) | Total Time 14.00(14.00)\n",
      "Iter 4539 | Time 57.6722(60.3261) | Bit/dim 3.6824(3.6774) | Xent 0.0542(0.0597) | Loss 3.7095(3.7073) | Error 0.0180(0.0193) Steps 658(672.44) | Grad Norm 1.0727(1.8036) | Total Time 14.00(14.00)\n",
      "Iter 4540 | Time 62.0886(60.3790) | Bit/dim 3.6666(3.6771) | Xent 0.0607(0.0597) | Loss 3.6970(3.7070) | Error 0.0200(0.0193) Steps 682(672.73) | Grad Norm 2.3598(1.8203) | Total Time 14.00(14.00)\n",
      "Iter 4541 | Time 59.1974(60.3436) | Bit/dim 3.6741(3.6770) | Xent 0.0528(0.0595) | Loss 3.7005(3.7068) | Error 0.0176(0.0193) Steps 682(673.01) | Grad Norm 1.2664(1.8037) | Total Time 14.00(14.00)\n",
      "Iter 4542 | Time 59.9508(60.3318) | Bit/dim 3.6847(3.6772) | Xent 0.0556(0.0594) | Loss 3.7125(3.7069) | Error 0.0192(0.0193) Steps 676(673.10) | Grad Norm 2.6795(1.8299) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0757 | Time 24.5846, Epoch Time 401.9973(404.2994), Bit/dim 3.7020(best: 3.7007), Xent 2.9835, Loss 5.1937, Error 0.4054(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4543 | Time 60.8411(60.3471) | Bit/dim 3.6791(3.6773) | Xent 0.0552(0.0593) | Loss 3.7067(3.7069) | Error 0.0175(0.0192) Steps 670(673.01) | Grad Norm 1.4475(1.8185) | Total Time 14.00(14.00)\n",
      "Iter 4544 | Time 60.4527(60.3502) | Bit/dim 3.6740(3.6772) | Xent 0.0646(0.0595) | Loss 3.7063(3.7069) | Error 0.0219(0.0193) Steps 682(673.28) | Grad Norm 1.6273(1.8127) | Total Time 14.00(14.00)\n",
      "Iter 4545 | Time 60.6063(60.3579) | Bit/dim 3.6749(3.6771) | Xent 0.0577(0.0594) | Loss 3.7038(3.7068) | Error 0.0189(0.0193) Steps 676(673.36) | Grad Norm 1.9829(1.8178) | Total Time 14.00(14.00)\n",
      "Iter 4546 | Time 60.3836(60.3587) | Bit/dim 3.6702(3.6769) | Xent 0.0631(0.0595) | Loss 3.7017(3.7067) | Error 0.0195(0.0193) Steps 676(673.44) | Grad Norm 1.8870(1.8199) | Total Time 14.00(14.00)\n",
      "Iter 4547 | Time 59.3753(60.3292) | Bit/dim 3.6813(3.6770) | Xent 0.0660(0.0597) | Loss 3.7143(3.7069) | Error 0.0230(0.0194) Steps 670(673.33) | Grad Norm 2.3864(1.8369) | Total Time 14.00(14.00)\n",
      "Iter 4548 | Time 60.9104(60.3466) | Bit/dim 3.6743(3.6770) | Xent 0.0629(0.0598) | Loss 3.7058(3.7069) | Error 0.0204(0.0194) Steps 670(673.23) | Grad Norm 2.1390(1.8460) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0758 | Time 24.8636, Epoch Time 403.2650(404.2684), Bit/dim 3.7018(best: 3.7007), Xent 3.0202, Loss 5.2119, Error 0.4097(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4549 | Time 61.4670(60.3802) | Bit/dim 3.6764(3.6769) | Xent 0.0549(0.0597) | Loss 3.7039(3.7068) | Error 0.0194(0.0194) Steps 670(673.14) | Grad Norm 0.9465(1.8190) | Total Time 14.00(14.00)\n",
      "Iter 4550 | Time 62.5906(60.4465) | Bit/dim 3.6816(3.6771) | Xent 0.0597(0.0597) | Loss 3.7115(3.7069) | Error 0.0194(0.0194) Steps 670(673.04) | Grad Norm 2.4069(1.8366) | Total Time 14.00(14.00)\n",
      "Iter 4551 | Time 60.0372(60.4343) | Bit/dim 3.6787(3.6771) | Xent 0.0568(0.0596) | Loss 3.7071(3.7069) | Error 0.0184(0.0194) Steps 682(673.31) | Grad Norm 1.7576(1.8343) | Total Time 14.00(14.00)\n",
      "Iter 4552 | Time 58.4733(60.3754) | Bit/dim 3.6769(3.6771) | Xent 0.0575(0.0595) | Loss 3.7056(3.7069) | Error 0.0182(0.0194) Steps 670(673.21) | Grad Norm 1.9045(1.8364) | Total Time 14.00(14.00)\n",
      "Iter 4553 | Time 62.5168(60.4397) | Bit/dim 3.6688(3.6769) | Xent 0.0586(0.0595) | Loss 3.6981(3.7066) | Error 0.0194(0.0194) Steps 676(673.30) | Grad Norm 1.9953(1.8411) | Total Time 14.00(14.00)\n",
      "Iter 4554 | Time 61.0322(60.4574) | Bit/dim 3.6839(3.6771) | Xent 0.0574(0.0594) | Loss 3.7126(3.7068) | Error 0.0168(0.0193) Steps 670(673.20) | Grad Norm 1.4215(1.8285) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0759 | Time 24.5303, Epoch Time 406.2039(404.3264), Bit/dim 3.7014(best: 3.7007), Xent 2.9921, Loss 5.1975, Error 0.4027(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4555 | Time 62.6541(60.5233) | Bit/dim 3.6758(3.6770) | Xent 0.0563(0.0593) | Loss 3.7039(3.7067) | Error 0.0182(0.0193) Steps 676(673.28) | Grad Norm 1.8674(1.8297) | Total Time 14.00(14.00)\n",
      "Iter 4556 | Time 59.6844(60.4982) | Bit/dim 3.6751(3.6770) | Xent 0.0598(0.0593) | Loss 3.7049(3.7067) | Error 0.0199(0.0193) Steps 670(673.18) | Grad Norm 1.2786(1.8132) | Total Time 14.00(14.00)\n",
      "Iter 4557 | Time 60.1529(60.4878) | Bit/dim 3.6711(3.6768) | Xent 0.0576(0.0593) | Loss 3.6999(3.7064) | Error 0.0182(0.0192) Steps 670(673.09) | Grad Norm 2.1870(1.8244) | Total Time 14.00(14.00)\n",
      "Iter 4558 | Time 62.3735(60.5444) | Bit/dim 3.6811(3.6769) | Xent 0.0622(0.0594) | Loss 3.7122(3.7066) | Error 0.0192(0.0192) Steps 670(672.99) | Grad Norm 2.2810(1.8381) | Total Time 14.00(14.00)\n",
      "Iter 4559 | Time 62.6174(60.6066) | Bit/dim 3.6791(3.6770) | Xent 0.0611(0.0594) | Loss 3.7096(3.7067) | Error 0.0182(0.0192) Steps 670(672.90) | Grad Norm 1.1167(1.8164) | Total Time 14.00(14.00)\n",
      "Iter 4560 | Time 60.3192(60.5980) | Bit/dim 3.6782(3.6770) | Xent 0.0547(0.0593) | Loss 3.7056(3.7067) | Error 0.0175(0.0192) Steps 682(673.18) | Grad Norm 2.1127(1.8253) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0760 | Time 24.2238, Epoch Time 408.2147(404.4431), Bit/dim 3.7028(best: 3.7007), Xent 2.9672, Loss 5.1864, Error 0.4083(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4561 | Time 58.0072(60.5202) | Bit/dim 3.6835(3.6772) | Xent 0.0529(0.0591) | Loss 3.7099(3.7068) | Error 0.0172(0.0191) Steps 670(673.08) | Grad Norm 1.6165(1.8191) | Total Time 14.00(14.00)\n",
      "Iter 4562 | Time 63.0488(60.5961) | Bit/dim 3.6822(3.6774) | Xent 0.0616(0.0592) | Loss 3.7130(3.7070) | Error 0.0210(0.0192) Steps 670(672.99) | Grad Norm 2.1519(1.8291) | Total Time 14.00(14.00)\n",
      "Iter 4563 | Time 62.1924(60.6440) | Bit/dim 3.6784(3.6774) | Xent 0.0555(0.0591) | Loss 3.7062(3.7069) | Error 0.0169(0.0191) Steps 676(673.08) | Grad Norm 1.2678(1.8122) | Total Time 14.00(14.00)\n",
      "Iter 4564 | Time 59.2097(60.6010) | Bit/dim 3.6712(3.6772) | Xent 0.0571(0.0590) | Loss 3.6997(3.7067) | Error 0.0176(0.0190) Steps 670(672.99) | Grad Norm 1.9157(1.8153) | Total Time 14.00(14.00)\n",
      "Iter 4565 | Time 60.6020(60.6010) | Bit/dim 3.6831(3.6774) | Xent 0.0580(0.0590) | Loss 3.7121(3.7069) | Error 0.0200(0.0191) Steps 670(672.90) | Grad Norm 1.5373(1.8070) | Total Time 14.00(14.00)\n",
      "Iter 4566 | Time 62.1244(60.6467) | Bit/dim 3.6693(3.6772) | Xent 0.0581(0.0589) | Loss 3.6983(3.7066) | Error 0.0172(0.0190) Steps 688(673.35) | Grad Norm 1.3172(1.7923) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0761 | Time 24.9282, Epoch Time 410.5957(404.6277), Bit/dim 3.7012(best: 3.7007), Xent 2.9950, Loss 5.1987, Error 0.4156(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4567 | Time 61.2575(60.6650) | Bit/dim 3.6765(3.6771) | Xent 0.0557(0.0588) | Loss 3.7043(3.7066) | Error 0.0195(0.0190) Steps 664(673.07) | Grad Norm 1.2613(1.7764) | Total Time 14.00(14.00)\n",
      "Iter 4568 | Time 61.0402(60.6763) | Bit/dim 3.6740(3.6770) | Xent 0.0579(0.0588) | Loss 3.7030(3.7064) | Error 0.0188(0.0190) Steps 670(672.98) | Grad Norm 1.4256(1.7658) | Total Time 14.00(14.00)\n",
      "Iter 4569 | Time 61.4231(60.6987) | Bit/dim 3.6698(3.6768) | Xent 0.0626(0.0589) | Loss 3.7010(3.7063) | Error 0.0186(0.0190) Steps 670(672.89) | Grad Norm 1.3572(1.7536) | Total Time 14.00(14.00)\n",
      "Iter 4570 | Time 60.6332(60.6967) | Bit/dim 3.6720(3.6767) | Xent 0.0552(0.0588) | Loss 3.6996(3.7061) | Error 0.0184(0.0190) Steps 676(672.98) | Grad Norm 1.6318(1.7499) | Total Time 14.00(14.00)\n",
      "Iter 4571 | Time 60.9546(60.7044) | Bit/dim 3.6974(3.6773) | Xent 0.0532(0.0586) | Loss 3.7239(3.7066) | Error 0.0188(0.0190) Steps 682(673.25) | Grad Norm 1.4335(1.7404) | Total Time 14.00(14.00)\n",
      "Iter 4572 | Time 58.3064(60.6325) | Bit/dim 3.6658(3.6770) | Xent 0.0571(0.0586) | Loss 3.6943(3.7063) | Error 0.0185(0.0190) Steps 670(673.16) | Grad Norm 1.5297(1.7341) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0762 | Time 24.7252, Epoch Time 405.1973(404.6448), Bit/dim 3.7020(best: 3.7007), Xent 2.9950, Loss 5.1995, Error 0.4064(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 4573 | Time 59.3932(60.5953) | Bit/dim 3.6739(3.6769) | Xent 0.0583(0.0586) | Loss 3.7031(3.7062) | Error 0.0185(0.0190) Steps 670(673.06) | Grad Norm 1.4160(1.7246) | Total Time 14.00(14.00)\n",
      "Iter 4574 | Time 62.8047(60.6616) | Bit/dim 3.6810(3.6770) | Xent 0.0534(0.0584) | Loss 3.7077(3.7062) | Error 0.0172(0.0189) Steps 670(672.97) | Grad Norm 2.7174(1.7544) | Total Time 14.00(14.00)\n",
      "Iter 4575 | Time 60.8519(60.6673) | Bit/dim 3.6784(3.6770) | Xent 0.0487(0.0581) | Loss 3.7028(3.7061) | Error 0.0146(0.0188) Steps 670(672.88) | Grad Norm 2.4328(1.7747) | Total Time 14.00(14.00)\n",
      "Iter 4576 | Time 61.2854(60.6859) | Bit/dim 3.6781(3.6771) | Xent 0.0602(0.0582) | Loss 3.7082(3.7062) | Error 0.0195(0.0188) Steps 658(672.43) | Grad Norm 1.7138(1.7729) | Total Time 14.00(14.00)\n",
      "Iter 4577 | Time 59.6297(60.6542) | Bit/dim 3.6772(3.6771) | Xent 0.0586(0.0582) | Loss 3.7065(3.7062) | Error 0.0199(0.0188) Steps 670(672.36) | Grad Norm 2.0779(1.7820) | Total Time 14.00(14.00)\n",
      "Iter 4578 | Time 60.7124(60.6559) | Bit/dim 3.6741(3.6770) | Xent 0.0613(0.0583) | Loss 3.7048(3.7061) | Error 0.0196(0.0189) Steps 664(672.11) | Grad Norm 1.5491(1.7750) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0763 | Time 24.9102, Epoch Time 407.6664(404.7354), Bit/dim 3.7025(best: 3.7007), Xent 3.0452, Loss 5.2251, Error 0.4092(best: 0.3960)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_drop_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_conditional_cifar10_8K_drop_0_5_run2 --resume ../experiments_published/cnf_conditional_cifar10_8K_drop_0_5_run2/epoch_370_checkpt.pth --seed 2 --conditional True --controlled_tol True --train_mode semisup --lr 0.0001 --warmup_iters 1000 --atol 1e-4  --rtol 1e-4 --weight_y 0.5 --dropout_rate 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
