{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, eta=0.1, gamma=0.99, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume=None, rl_weight=0.5, rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_rlw_0_5_run1', scale=1.0, scale_fac=1.0, scale_std=6.0, seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1450732\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 0010 | Time 12.4189(31.7765) | Bit/dim 8.6896(8.9528) | Xent 2.2806(2.3001) | Loss 564.6960(571.4283) | Error 0.7989(0.8603) Steps 0(0.00) | Grad Norm 570.9552(722.6073) | Total Time 0.00(0.00)\n",
      "Iter 0020 | Time 12.3175(26.7413) | Bit/dim 8.4866(8.8635) | Xent 2.2262(2.2874) | Loss 552.5426(565.7313) | Error 0.7256(0.8327) Steps 0(0.00) | Grad Norm 237.6638(625.1853) | Total Time 0.00(0.00)\n",
      "Iter 0030 | Time 13.3221(23.0915) | Bit/dim 8.3930(8.7517) | Xent 2.1747(2.2634) | Loss 560.9949(559.8149) | Error 0.7600(0.8097) Steps 0(0.00) | Grad Norm 241.0650(513.6632) | Total Time 0.00(0.00)\n",
      "Iter 0040 | Time 13.1096(20.3486) | Bit/dim 8.1917(8.6236) | Xent 2.1135(2.2347) | Loss 532.7792(553.1558) | Error 0.7211(0.7918) Steps 0(0.00) | Grad Norm 145.6561(421.7888) | Total Time 0.00(0.00)\n",
      "Iter 0050 | Time 11.8406(18.3370) | Bit/dim 7.9734(8.4739) | Xent 2.1021(2.2021) | Loss 511.2245(544.8349) | Error 0.7122(0.7759) Steps 0(0.00) | Grad Norm 140.0487(350.4532) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 76.8745, Epoch Time 823.6083(823.6083), Bit/dim 7.7694(best: inf), Xent 2.0786, Loss 8.8087, Error 0.7003(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0060 | Time 13.1695(16.9532) | Bit/dim 7.6766(8.2913) | Xent 2.0796(2.1721) | Loss 493.9247(562.0301) | Error 0.7056(0.7592) Steps 0(0.00) | Grad Norm 145.7245(295.7516) | Total Time 0.00(0.00)\n",
      "Iter 0070 | Time 13.1928(15.9377) | Bit/dim 7.3714(8.0805) | Xent 2.0559(2.1463) | Loss 492.1942(544.0343) | Error 0.6744(0.7421) Steps 0(0.00) | Grad Norm 106.5333(250.0871) | Total Time 0.00(0.00)\n",
      "Iter 0080 | Time 13.0881(15.1896) | Bit/dim 7.1865(7.8637) | Xent 2.0706(2.1260) | Loss 480.1969(526.6537) | Error 0.6656(0.7271) Steps 0(0.00) | Grad Norm 87.0510(209.0227) | Total Time 0.00(0.00)\n",
      "Iter 0090 | Time 12.9539(14.6646) | Bit/dim 7.0826(7.6690) | Xent 2.0840(2.1131) | Loss 477.8034(512.1023) | Error 0.7267(0.7188) Steps 0(0.00) | Grad Norm 55.0530(172.1065) | Total Time 0.00(0.00)\n",
      "Iter 0100 | Time 14.4278(14.3658) | Bit/dim 7.0014(7.5062) | Xent 2.0616(2.1034) | Loss 476.1585(500.8393) | Error 0.6867(0.7128) Steps 0(0.00) | Grad Norm 88.2502(147.4970) | Total Time 0.00(0.00)\n",
      "Iter 0110 | Time 14.1692(14.2483) | Bit/dim 7.0034(7.3754) | Xent 2.0602(2.0948) | Loss 480.9733(492.5501) | Error 0.7278(0.7129) Steps 0(0.00) | Grad Norm 59.8169(124.4460) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 76.7012, Epoch Time 827.0860(823.7126), Bit/dim 6.9922(best: 7.7694), Xent 2.0585, Loss 8.0215, Error 0.6956(best: 0.7003)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0120 | Time 14.4673(14.3222) | Bit/dim 6.9408(7.2696) | Xent 2.0540(2.0853) | Loss 459.7209(512.7725) | Error 0.7033(0.7110) Steps 0(0.00) | Grad Norm 45.6316(109.1841) | Total Time 0.00(0.00)\n",
      "Iter 0130 | Time 14.5391(14.3614) | Bit/dim 6.9196(7.1828) | Xent 2.0418(2.0745) | Loss 468.0229(499.5171) | Error 0.6867(0.7057) Steps 0(0.00) | Grad Norm 76.4711(97.0531) | Total Time 0.00(0.00)\n",
      "Iter 0140 | Time 16.8334(14.4115) | Bit/dim 6.8946(7.1070) | Xent 2.0480(2.0646) | Loss 462.7523(489.0507) | Error 0.6922(0.7022) Steps 0(0.00) | Grad Norm 212.6401(100.8884) | Total Time 0.00(0.00)\n",
      "Iter 0150 | Time 15.7233(14.5145) | Bit/dim 6.7860(7.0356) | Xent 2.0152(2.0564) | Loss 443.2015(479.5873) | Error 0.7056(0.6995) Steps 0(0.00) | Grad Norm 112.9994(128.2721) | Total Time 0.00(0.00)\n",
      "Iter 0160 | Time 15.1692(14.5993) | Bit/dim 6.7047(6.9610) | Xent 2.0375(2.0516) | Loss 460.5154(473.5493) | Error 0.7144(0.6981) Steps 0(0.00) | Grad Norm 525.6893(195.3744) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 79.8070, Epoch Time 903.9718(826.1204), Bit/dim 6.6374(best: 6.9922), Xent 2.0269, Loss 7.6508, Error 0.6925(best: 0.6956)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0170 | Time 15.0303(14.6758) | Bit/dim 6.6118(6.8784) | Xent 2.0519(2.0523) | Loss 458.7086(499.0732) | Error 0.7256(0.7031) Steps 0(0.00) | Grad Norm 1210.1466(376.0130) | Total Time 0.00(0.00)\n",
      "Iter 0180 | Time 16.4403(14.8734) | Bit/dim 6.4493(6.7771) | Xent 2.2135(2.0544) | Loss 440.7607(484.3030) | Error 0.8000(0.7111) Steps 0(0.00) | Grad Norm 2979.7642(591.8011) | Total Time 0.00(0.00)\n",
      "Iter 0190 | Time 13.8025(14.7996) | Bit/dim 6.2668(6.6631) | Xent 2.0622(2.0636) | Loss 430.7480(472.2605) | Error 0.7056(0.7190) Steps 0(0.00) | Grad Norm 1674.5698(884.6399) | Total Time 0.00(0.00)\n",
      "Iter 0200 | Time 13.6928(14.8469) | Bit/dim 6.1093(6.5322) | Xent 2.0592(2.0640) | Loss 421.0393(460.4181) | Error 0.7089(0.7230) Steps 0(0.00) | Grad Norm 1532.3974(1000.9717) | Total Time 0.00(0.00)\n",
      "Iter 0210 | Time 14.6679(14.9841) | Bit/dim 5.9172(6.3925) | Xent 2.0753(2.0615) | Loss 417.4667(448.3866) | Error 0.7078(0.7205) Steps 0(0.00) | Grad Norm 1719.6487(1111.2665) | Total Time 0.00(0.00)\n",
      "Iter 0220 | Time 14.1702(14.9851) | Bit/dim 5.8258(6.2598) | Xent 2.0111(2.0594) | Loss 414.0837(438.5119) | Error 0.6567(0.7193) Steps 0(0.00) | Grad Norm 602.9525(1284.6678) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 78.9399, Epoch Time 924.9415(829.0850), Bit/dim 5.8198(best: 6.6374), Xent 2.0303, Loss 6.8350, Error 0.6938(best: 0.6925)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0230 | Time 14.3530(14.9857) | Bit/dim 5.7962(6.1368) | Xent 2.0553(2.0480) | Loss 400.0811(455.4678) | Error 0.7233(0.7112) Steps 0(0.00) | Grad Norm 1016.2044(1157.3448) | Total Time 0.00(0.00)\n",
      "Iter 0240 | Time 15.2134(14.8609) | Bit/dim 5.7321(6.0306) | Xent 2.0126(2.0379) | Loss 409.8397(439.7662) | Error 0.7133(0.7076) Steps 0(0.00) | Grad Norm 1111.3188(1182.4858) | Total Time 0.00(0.00)\n",
      "Iter 0250 | Time 13.4160(14.6794) | Bit/dim 5.6747(5.9432) | Xent 1.9678(2.0256) | Loss 393.5830(429.0872) | Error 0.6489(0.6984) Steps 0(0.00) | Grad Norm 453.7832(1036.2539) | Total Time 0.00(0.00)\n",
      "Iter 0260 | Time 13.2609(14.4987) | Bit/dim 5.6783(5.8662) | Xent 2.1659(2.0189) | Loss 399.2275(421.3874) | Error 0.8011(0.6960) Steps 0(0.00) | Grad Norm 3887.4077(1076.4146) | Total Time 0.00(0.00)\n",
      "Iter 0270 | Time 12.9886(14.4535) | Bit/dim 5.6367(5.8215) | Xent 1.9949(2.0239) | Loss 369.3558(415.9803) | Error 0.6756(0.6982) Steps 0(0.00) | Grad Norm 802.7487(1216.3639) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 78.9238, Epoch Time 887.5636(830.8394), Bit/dim 5.6222(best: 5.8198), Xent 1.9748, Loss 6.6096, Error 0.6662(best: 0.6925)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0280 | Time 14.5130(14.3833) | Bit/dim 5.5424(5.7647) | Xent 1.9754(2.0172) | Loss 398.9291(439.0876) | Error 0.6756(0.6957) Steps 0(0.00) | Grad Norm 161.9321(1041.4514) | Total Time 0.00(0.00)\n",
      "Iter 0290 | Time 13.5551(14.2233) | Bit/dim 5.5939(5.7208) | Xent 1.9260(2.0038) | Loss 396.1852(426.7681) | Error 0.6456(0.6882) Steps 0(0.00) | Grad Norm 230.4325(841.0638) | Total Time 0.00(0.00)\n",
      "Iter 0300 | Time 13.8671(14.1476) | Bit/dim 5.5212(5.6802) | Xent 1.9444(1.9902) | Loss 386.1197(417.8392) | Error 0.6800(0.6834) Steps 0(0.00) | Grad Norm 704.7372(755.9701) | Total Time 0.00(0.00)\n",
      "Iter 0310 | Time 13.2726(14.1062) | Bit/dim 5.4816(5.6383) | Xent 1.9552(1.9773) | Loss 366.8889(410.2533) | Error 0.6778(0.6786) Steps 0(0.00) | Grad Norm 245.2514(642.4736) | Total Time 0.00(0.00)\n",
      "Iter 0320 | Time 14.4370(14.1457) | Bit/dim 5.4907(5.6022) | Xent 1.9768(1.9764) | Loss 386.1796(404.0628) | Error 0.6989(0.6809) Steps 0(0.00) | Grad Norm 1055.4167(706.4972) | Total Time 0.00(0.00)\n",
      "Iter 0330 | Time 14.9799(14.2371) | Bit/dim 5.4925(5.5714) | Xent 1.9269(1.9704) | Loss 389.2760(399.3768) | Error 0.6833(0.6776) Steps 0(0.00) | Grad Norm 680.6462(665.9802) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 79.5050, Epoch Time 873.2308(832.1111), Bit/dim 5.4543(best: 5.6222), Xent 1.9077, Loss 6.4081, Error 0.6489(best: 0.6662)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0340 | Time 14.6605(14.2749) | Bit/dim 5.4497(5.5430) | Xent 1.9598(1.9612) | Loss 390.6831(422.8667) | Error 0.6578(0.6766) Steps 0(0.00) | Grad Norm 1095.5781(767.8847) | Total Time 0.00(0.00)\n",
      "Iter 0350 | Time 15.1263(14.3684) | Bit/dim 5.4746(5.5137) | Xent 2.1429(1.9699) | Loss 398.1245(413.8119) | Error 0.7467(0.6836) Steps 0(0.00) | Grad Norm 2123.1316(915.2974) | Total Time 0.00(0.00)\n",
      "Iter 0360 | Time 14.7720(14.3728) | Bit/dim 5.3453(5.4830) | Xent 2.0225(1.9901) | Loss 376.0388(405.6988) | Error 0.7167(0.6973) Steps 0(0.00) | Grad Norm 682.1319(933.6776) | Total Time 0.00(0.00)\n",
      "Iter 0370 | Time 14.7067(14.4913) | Bit/dim 5.3538(5.4471) | Xent 1.9581(1.9918) | Loss 375.6043(399.3291) | Error 0.7089(0.6963) Steps 0(0.00) | Grad Norm 783.3764(873.6124) | Total Time 0.00(0.00)\n",
      "Iter 0380 | Time 13.5993(14.5624) | Bit/dim 5.3010(5.4098) | Xent 1.9457(1.9834) | Loss 369.8069(393.8459) | Error 0.6711(0.6910) Steps 0(0.00) | Grad Norm 483.0336(769.6505) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 80.3554, Epoch Time 901.1410(834.1820), Bit/dim 5.2586(best: 5.4543), Xent 1.9167, Loss 6.2170, Error 0.6451(best: 0.6489)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0390 | Time 15.3078(14.6043) | Bit/dim 5.2093(5.3775) | Xent 1.8968(1.9713) | Loss 377.3766(419.7593) | Error 0.6667(0.6858) Steps 0(0.00) | Grad Norm 273.6062(664.9678) | Total Time 0.00(0.00)\n",
      "Iter 0400 | Time 15.1233(14.7082) | Bit/dim 5.2627(5.3385) | Xent 1.9043(1.9534) | Loss 387.2370(407.9253) | Error 0.6644(0.6773) Steps 0(0.00) | Grad Norm 354.3140(587.4062) | Total Time 0.00(0.00)\n",
      "Iter 0410 | Time 15.8267(14.8419) | Bit/dim 5.2899(5.3037) | Xent 1.9032(1.9361) | Loss 370.3779(399.1548) | Error 0.6800(0.6713) Steps 0(0.00) | Grad Norm 474.9076(546.8167) | Total Time 0.00(0.00)\n",
      "Iter 0420 | Time 17.9982(15.0264) | Bit/dim 5.1902(5.2707) | Xent 1.8653(1.9273) | Loss 377.7176(392.2553) | Error 0.6744(0.6696) Steps 0(0.00) | Grad Norm 782.6315(589.2202) | Total Time 0.00(0.00)\n",
      "Iter 0430 | Time 14.9729(15.1959) | Bit/dim 5.1967(5.2388) | Xent 1.9705(1.9246) | Loss 378.4949(385.8276) | Error 0.7100(0.6705) Steps 0(0.00) | Grad Norm 1228.0580(622.2977) | Total Time 0.00(0.00)\n",
      "Iter 0440 | Time 14.5116(15.2059) | Bit/dim 5.1830(5.2153) | Xent 2.0092(1.9391) | Loss 371.5775(381.8450) | Error 0.7211(0.6787) Steps 0(0.00) | Grad Norm 1097.2644(761.4490) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 82.4650, Epoch Time 940.7224(837.3782), Bit/dim 5.1450(best: 5.2586), Xent 1.9810, Loss 6.1355, Error 0.6993(best: 0.6451)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0450 | Time 15.5825(15.1119) | Bit/dim 5.1122(5.1926) | Xent 1.9244(1.9388) | Loss 353.3453(405.6898) | Error 0.6956(0.6799) Steps 0(0.00) | Grad Norm 419.6984(726.4124) | Total Time 0.00(0.00)\n",
      "Iter 0460 | Time 15.7819(15.2603) | Bit/dim 5.0560(5.1586) | Xent 1.8927(1.9268) | Loss 368.9808(395.5778) | Error 0.6789(0.6761) Steps 0(0.00) | Grad Norm 220.0911(689.5822) | Total Time 0.00(0.00)\n",
      "Iter 0470 | Time 15.1814(15.3207) | Bit/dim 5.0521(5.1292) | Xent 1.8756(1.9177) | Loss 355.9868(387.4972) | Error 0.6711(0.6722) Steps 0(0.00) | Grad Norm 638.1788(643.1338) | Total Time 0.00(0.00)\n",
      "Iter 0480 | Time 16.4679(15.3810) | Bit/dim 5.0096(5.1001) | Xent 1.8611(1.9104) | Loss 366.5943(380.6394) | Error 0.6522(0.6699) Steps 0(0.00) | Grad Norm 708.3532(664.4382) | Total Time 0.00(0.00)\n",
      "Iter 0490 | Time 15.7517(15.4661) | Bit/dim 5.0084(5.0724) | Xent 1.8489(1.8980) | Loss 367.8710(375.9919) | Error 0.6456(0.6655) Steps 0(0.00) | Grad Norm 284.8016(654.8511) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 84.1987, Epoch Time 953.0423(840.8482), Bit/dim 4.9515(best: 5.1450), Xent 1.8121, Loss 5.8576, Error 0.6194(best: 0.6451)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0500 | Time 15.0938(15.5038) | Bit/dim 4.9303(5.0396) | Xent 1.8514(1.8844) | Loss 347.2449(399.2711) | Error 0.6444(0.6603) Steps 0(0.00) | Grad Norm 866.3657(660.7575) | Total Time 0.00(0.00)\n",
      "Iter 0510 | Time 15.3717(15.5848) | Bit/dim 4.9244(5.0120) | Xent 1.8522(1.8780) | Loss 360.7339(388.2258) | Error 0.6533(0.6595) Steps 0(0.00) | Grad Norm 919.6607(735.9928) | Total Time 0.00(0.00)\n",
      "Iter 0520 | Time 16.6380(15.8137) | Bit/dim 4.8979(4.9835) | Xent 1.7615(1.8715) | Loss 362.8243(380.4616) | Error 0.6200(0.6572) Steps 0(0.00) | Grad Norm 317.7502(733.9844) | Total Time 0.00(0.00)\n",
      "Iter 0530 | Time 15.1545(16.1075) | Bit/dim 4.8593(4.9595) | Xent 1.9553(1.8722) | Loss 343.2027(374.8188) | Error 0.7033(0.6585) Steps 0(0.00) | Grad Norm 976.0721(789.7513) | Total Time 0.00(0.00)\n",
      "Iter 0540 | Time 17.1256(16.2750) | Bit/dim 4.8557(4.9373) | Xent 1.8286(1.8669) | Loss 359.8650(369.0743) | Error 0.6533(0.6564) Steps 0(0.00) | Grad Norm 717.4648(755.6672) | Total Time 0.00(0.00)\n",
      "Iter 0550 | Time 17.1360(16.3456) | Bit/dim 4.9216(4.9460) | Xent 1.9404(1.8745) | Loss 361.5121(366.9920) | Error 0.6811(0.6592) Steps 0(0.00) | Grad Norm 563.1041(862.8103) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 83.6663, Epoch Time 1005.9212(845.8004), Bit/dim 4.8797(best: 4.9515), Xent 1.8177, Loss 5.7885, Error 0.6320(best: 0.6194)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0560 | Time 15.7395(16.2379) | Bit/dim 4.8431(4.9280) | Xent 1.8997(1.8697) | Loss 350.7964(390.7250) | Error 0.6678(0.6580) Steps 0(0.00) | Grad Norm 918.6892(779.1843) | Total Time 0.00(0.00)\n",
      "Iter 0570 | Time 15.0517(16.1564) | Bit/dim 4.8131(4.9005) | Xent 1.8264(1.8612) | Loss 343.6839(379.3627) | Error 0.6456(0.6568) Steps 0(0.00) | Grad Norm 370.8738(704.8993) | Total Time 0.00(0.00)\n",
      "Iter 0580 | Time 17.1331(16.1713) | Bit/dim 4.8814(4.8854) | Xent 1.9126(1.8606) | Loss 355.1528(373.8175) | Error 0.6844(0.6559) Steps 0(0.00) | Grad Norm 1078.7977(798.6046) | Total Time 0.00(0.00)\n",
      "Iter 0590 | Time 16.6160(16.1898) | Bit/dim 4.8334(4.8673) | Xent 1.8382(1.8646) | Loss 336.7419(367.9255) | Error 0.6633(0.6593) Steps 0(0.00) | Grad Norm 849.0699(816.3334) | Total Time 0.00(0.00)\n",
      "Iter 0600 | Time 16.7669(16.2655) | Bit/dim 4.7810(4.8433) | Xent 1.7702(1.8521) | Loss 341.8179(362.5775) | Error 0.6222(0.6552) Steps 0(0.00) | Grad Norm 506.0104(744.3559) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 86.5627, Epoch Time 991.9996(850.1863), Bit/dim 4.7480(best: 4.8797), Xent 1.7051, Loss 5.6006, Error 0.5875(best: 0.6194)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0610 | Time 15.1130(16.2306) | Bit/dim 4.8107(4.8198) | Xent 1.8852(1.8347) | Loss 332.2240(390.3862) | Error 0.6689(0.6505) Steps 0(0.00) | Grad Norm 1842.4674(698.8541) | Total Time 0.00(0.00)\n",
      "Iter 0620 | Time 16.2623(16.2758) | Bit/dim 4.7425(4.8185) | Xent 1.9297(1.8533) | Loss 354.3953(380.9656) | Error 0.6856(0.6568) Steps 0(0.00) | Grad Norm 1021.6529(828.9198) | Total Time 0.00(0.00)\n",
      "Iter 0630 | Time 22.8699(16.4760) | Bit/dim 4.7276(4.8006) | Xent 1.7626(1.8437) | Loss 366.0017(372.2545) | Error 0.6333(0.6534) Steps 0(0.00) | Grad Norm 362.2469(716.8966) | Total Time 0.00(0.00)\n",
      "Iter 0640 | Time 17.1409(16.5571) | Bit/dim 4.7131(4.7762) | Xent 1.7305(1.8262) | Loss 351.4981(365.3332) | Error 0.5933(0.6445) Steps 0(0.00) | Grad Norm 239.0502(613.7274) | Total Time 0.00(0.00)\n",
      "Iter 0650 | Time 16.4665(16.4356) | Bit/dim 4.6796(4.7578) | Xent 1.7875(1.8011) | Loss 338.6671(359.5184) | Error 0.6411(0.6363) Steps 0(0.00) | Grad Norm 527.9616(592.1615) | Total Time 0.00(0.00)\n",
      "Iter 0660 | Time 16.5194(16.4666) | Bit/dim 4.6742(4.7401) | Xent 1.8181(1.7903) | Loss 349.3714(355.8114) | Error 0.6511(0.6325) Steps 0(0.00) | Grad Norm 1173.8134(590.8893) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 89.8109, Epoch Time 1017.2729(855.1989), Bit/dim 4.6873(best: 4.7480), Xent 1.7182, Loss 5.5464, Error 0.6102(best: 0.5875)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0670 | Time 16.3114(16.5618) | Bit/dim 4.7619(4.7389) | Xent 1.8841(1.8128) | Loss 352.8768(380.3005) | Error 0.6900(0.6414) Steps 0(0.00) | Grad Norm 964.9009(754.5474) | Total Time 0.00(0.00)\n",
      "Iter 0680 | Time 16.0268(16.6559) | Bit/dim 4.6409(4.7265) | Xent 1.7260(1.8078) | Loss 340.0007(370.8849) | Error 0.6078(0.6414) Steps 0(0.00) | Grad Norm 211.4134(695.8150) | Total Time 0.00(0.00)\n",
      "Iter 0690 | Time 16.2971(16.6862) | Bit/dim 4.6837(4.7129) | Xent 1.7480(1.7908) | Loss 332.3551(363.0091) | Error 0.6311(0.6355) Steps 0(0.00) | Grad Norm 414.8281(624.4846) | Total Time 0.00(0.00)\n",
      "Iter 0700 | Time 17.5312(16.5971) | Bit/dim 4.6517(4.6964) | Xent 1.7852(1.7799) | Loss 340.5308(356.7443) | Error 0.6611(0.6313) Steps 0(0.00) | Grad Norm 730.1831(647.5801) | Total Time 0.00(0.00)\n",
      "Iter 0710 | Time 17.1748(16.7116) | Bit/dim 4.6201(4.6781) | Xent 1.6615(1.7666) | Loss 345.0164(353.1031) | Error 0.5878(0.6290) Steps 0(0.00) | Grad Norm 415.8568(638.0497) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 90.0056, Epoch Time 1029.2260(860.4197), Bit/dim 4.6152(best: 4.6873), Xent 1.6267, Loss 5.4286, Error 0.5720(best: 0.5875)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0720 | Time 17.8782(16.7156) | Bit/dim 4.5975(4.6631) | Xent 1.6550(1.7538) | Loss 336.0118(381.4481) | Error 0.6022(0.6229) Steps 0(0.00) | Grad Norm 388.8721(620.6399) | Total Time 0.00(0.00)\n",
      "Iter 0730 | Time 15.4753(16.7208) | Bit/dim 4.5857(4.6461) | Xent 1.6614(1.7328) | Loss 318.9385(368.8368) | Error 0.6011(0.6156) Steps 0(0.00) | Grad Norm 630.8792(577.4898) | Total Time 0.00(0.00)\n",
      "Iter 0740 | Time 16.0529(16.9561) | Bit/dim 4.5419(4.6337) | Xent 1.7098(1.7262) | Loss 341.7456(361.5555) | Error 0.6178(0.6131) Steps 0(0.00) | Grad Norm 1034.7295(633.4323) | Total Time 0.00(0.00)\n",
      "Iter 0750 | Time 15.7047(17.1763) | Bit/dim 4.5625(4.6186) | Xent 1.6483(1.7192) | Loss 333.6580(354.5602) | Error 0.6056(0.6127) Steps 0(0.00) | Grad Norm 704.5464(647.2433) | Total Time 0.00(0.00)\n",
      "Iter 0760 | Time 17.4790(17.1504) | Bit/dim 4.6047(4.6103) | Xent 1.6782(1.7084) | Loss 349.6041(350.4591) | Error 0.6056(0.6102) Steps 0(0.00) | Grad Norm 864.8774(652.3546) | Total Time 0.00(0.00)\n",
      "Iter 0770 | Time 17.3208(17.1322) | Bit/dim 4.5371(4.5979) | Xent 1.6402(1.7021) | Loss 336.1531(346.5319) | Error 0.5856(0.6082) Steps 0(0.00) | Grad Norm 305.8084(632.5246) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 91.1958, Epoch Time 1059.3417(866.3874), Bit/dim 4.5662(best: 4.6152), Xent 1.6432, Loss 5.3878, Error 0.5855(best: 0.5720)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0780 | Time 17.8460(17.3344) | Bit/dim 4.6095(4.5953) | Xent 1.6775(1.6992) | Loss 324.2404(372.7768) | Error 0.6100(0.6063) Steps 0(0.00) | Grad Norm 943.1335(667.1338) | Total Time 0.00(0.00)\n",
      "Iter 0790 | Time 16.8604(17.2678) | Bit/dim 4.5243(4.5847) | Xent 1.6480(1.7031) | Loss 340.2224(363.6185) | Error 0.5944(0.6073) Steps 0(0.00) | Grad Norm 247.6750(696.3370) | Total Time 0.00(0.00)\n",
      "Iter 0800 | Time 17.2560(17.2942) | Bit/dim 4.5332(4.5688) | Xent 1.6959(1.6939) | Loss 330.3695(355.7763) | Error 0.5911(0.6021) Steps 0(0.00) | Grad Norm 411.1015(618.7094) | Total Time 0.00(0.00)\n",
      "Iter 0810 | Time 17.7193(17.3620) | Bit/dim 4.4920(4.5567) | Xent 1.8534(1.7079) | Loss 334.5367(350.8787) | Error 0.6578(0.6075) Steps 0(0.00) | Grad Norm 816.1086(685.0448) | Total Time 0.00(0.00)\n",
      "Iter 0820 | Time 19.5755(17.3455) | Bit/dim 4.5207(4.5437) | Xent 1.6936(1.7101) | Loss 328.2782(345.7155) | Error 0.6067(0.6096) Steps 0(0.00) | Grad Norm 447.5840(640.8298) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 89.0179, Epoch Time 1067.1981(872.4117), Bit/dim 4.5946(best: 4.5662), Xent 1.6196, Loss 5.4045, Error 0.5720(best: 0.5720)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0830 | Time 16.6969(17.3512) | Bit/dim 4.5549(4.5432) | Xent 1.6660(1.6990) | Loss 329.6015(376.4815) | Error 0.6156(0.6082) Steps 0(0.00) | Grad Norm 608.6712(646.2504) | Total Time 0.00(0.00)\n",
      "Iter 0840 | Time 17.2779(17.3685) | Bit/dim 4.5158(4.5320) | Xent 1.6985(1.6896) | Loss 329.4380(364.5750) | Error 0.5944(0.6044) Steps 0(0.00) | Grad Norm 440.3481(587.9454) | Total Time 0.00(0.00)\n",
      "Iter 0850 | Time 16.9312(17.2320) | Bit/dim 4.4495(4.5172) | Xent 1.5681(1.6715) | Loss 328.8560(355.6591) | Error 0.5789(0.6000) Steps 0(0.00) | Grad Norm 190.6175(525.8183) | Total Time 0.00(0.00)\n",
      "Iter 0860 | Time 15.8624(17.2208) | Bit/dim 4.4502(4.5010) | Xent 1.6450(1.6572) | Loss 319.6463(348.1181) | Error 0.5944(0.5958) Steps 0(0.00) | Grad Norm 279.3788(500.0924) | Total Time 0.00(0.00)\n",
      "Iter 0870 | Time 17.0851(17.3116) | Bit/dim 4.4641(4.4892) | Xent 1.7020(1.6554) | Loss 335.7846(345.2539) | Error 0.5856(0.5936) Steps 0(0.00) | Grad Norm 644.8905(537.6095) | Total Time 0.00(0.00)\n",
      "Iter 0880 | Time 19.0848(17.5081) | Bit/dim 4.4002(4.4723) | Xent 1.6332(1.6467) | Loss 328.6902(341.5451) | Error 0.6022(0.5920) Steps 0(0.00) | Grad Norm 619.8858(482.0422) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 91.3955, Epoch Time 1064.5064(878.1746), Bit/dim 4.4337(best: 4.5662), Xent 1.5577, Loss 5.2126, Error 0.5573(best: 0.5720)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0890 | Time 17.2863(17.5641) | Bit/dim 4.4441(4.4614) | Xent 1.6291(1.6362) | Loss 329.0520(366.4755) | Error 0.5944(0.5888) Steps 0(0.00) | Grad Norm 766.9452(493.8458) | Total Time 0.00(0.00)\n",
      "Iter 0900 | Time 17.5543(17.6453) | Bit/dim 4.4104(4.4447) | Xent 1.5474(1.6307) | Loss 315.4879(356.0580) | Error 0.5467(0.5874) Steps 0(0.00) | Grad Norm 455.1697(514.8281) | Total Time 0.00(0.00)\n",
      "Iter 0910 | Time 19.7865(17.8334) | Bit/dim 4.3765(4.4344) | Xent 1.5756(1.6248) | Loss 330.2960(349.8613) | Error 0.5656(0.5844) Steps 0(0.00) | Grad Norm 245.6104(513.2973) | Total Time 0.00(0.00)\n",
      "Iter 0920 | Time 16.4180(17.7235) | Bit/dim 4.3950(4.4266) | Xent 1.6395(1.6232) | Loss 311.8367(343.0847) | Error 0.6156(0.5843) Steps 0(0.00) | Grad Norm 745.2920(517.6562) | Total Time 0.00(0.00)\n",
      "Iter 0930 | Time 17.0359(17.6098) | Bit/dim 4.3695(4.4145) | Xent 1.5942(1.6230) | Loss 322.4136(338.6674) | Error 0.5633(0.5841) Steps 0(0.00) | Grad Norm 321.4517(499.9830) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 92.4890, Epoch Time 1085.3707(884.3904), Bit/dim 4.3594(best: 4.4337), Xent 1.4905, Loss 5.1047, Error 0.5406(best: 0.5573)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0940 | Time 19.0471(17.5978) | Bit/dim 4.3744(4.3998) | Xent 1.4918(1.6076) | Loss 324.9822(366.8839) | Error 0.5233(0.5804) Steps 0(0.00) | Grad Norm 226.3952(450.5301) | Total Time 0.00(0.00)\n",
      "Iter 0950 | Time 18.0930(17.5370) | Bit/dim 4.3143(4.3854) | Xent 1.4776(1.5915) | Loss 327.1616(354.8389) | Error 0.5267(0.5746) Steps 0(0.00) | Grad Norm 281.3596(450.3521) | Total Time 0.00(0.00)\n",
      "Iter 0960 | Time 16.3986(17.4508) | Bit/dim 4.3512(4.3742) | Xent 1.6072(1.5868) | Loss 309.0911(345.0801) | Error 0.5811(0.5732) Steps 0(0.00) | Grad Norm 177.1623(443.1000) | Total Time 0.00(0.00)\n",
      "Iter 0970 | Time 16.7285(17.6436) | Bit/dim 4.3098(4.3684) | Xent 1.6373(1.5854) | Loss 322.6866(339.9729) | Error 0.5900(0.5712) Steps 0(0.00) | Grad Norm 616.9679(483.1502) | Total Time 0.00(0.00)\n",
      "Iter 0980 | Time 16.4736(17.5584) | Bit/dim 4.3501(4.3582) | Xent 1.5991(1.5831) | Loss 319.7585(335.5074) | Error 0.5789(0.5712) Steps 0(0.00) | Grad Norm 408.6885(465.5822) | Total Time 0.00(0.00)\n",
      "Iter 0990 | Time 20.9383(17.6513) | Bit/dim 4.3238(4.3505) | Xent 1.5814(1.5824) | Loss 326.3057(331.9543) | Error 0.5944(0.5720) Steps 0(0.00) | Grad Norm 444.0007(458.9504) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 93.4819, Epoch Time 1078.6015(890.2168), Bit/dim 4.3124(best: 4.3594), Xent 1.4958, Loss 5.0603, Error 0.5399(best: 0.5406)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1000 | Time 18.4070(17.6713) | Bit/dim 4.3125(4.3402) | Xent 1.5398(1.5692) | Loss 332.5169(358.2027) | Error 0.5678(0.5676) Steps 0(0.00) | Grad Norm 520.0797(458.0473) | Total Time 0.00(0.00)\n",
      "Iter 1010 | Time 16.5773(17.6512) | Bit/dim 4.3234(4.3338) | Xent 1.5254(1.5695) | Loss 313.8007(347.8276) | Error 0.5622(0.5677) Steps 0(0.00) | Grad Norm 302.9883(451.1823) | Total Time 0.00(0.00)\n",
      "Iter 1020 | Time 18.7663(17.6774) | Bit/dim 4.2603(4.3211) | Xent 1.5483(1.5555) | Loss 321.1310(340.5202) | Error 0.5567(0.5624) Steps 0(0.00) | Grad Norm 424.9316(418.3301) | Total Time 0.00(0.00)\n",
      "Iter 1030 | Time 16.1873(17.5743) | Bit/dim 4.2726(4.3066) | Xent 1.5559(1.5495) | Loss 315.9337(334.8843) | Error 0.5456(0.5604) Steps 0(0.00) | Grad Norm 602.6167(434.5223) | Total Time 0.00(0.00)\n",
      "Iter 1040 | Time 16.8634(17.5604) | Bit/dim 4.2690(4.2972) | Xent 1.6245(1.5546) | Loss 312.5238(330.4137) | Error 0.5944(0.5621) Steps 0(0.00) | Grad Norm 616.8370(460.8080) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 92.3818, Epoch Time 1080.5064(895.9255), Bit/dim 4.2472(best: 4.3124), Xent 1.4312, Loss 4.9628, Error 0.5166(best: 0.5399)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1050 | Time 17.9234(17.7373) | Bit/dim 4.2460(4.2867) | Xent 1.5054(1.5463) | Loss 314.9872(358.2025) | Error 0.5578(0.5606) Steps 0(0.00) | Grad Norm 502.8404(464.4321) | Total Time 0.00(0.00)\n",
      "Iter 1060 | Time 18.7646(18.0269) | Bit/dim 4.2745(4.2803) | Xent 1.4977(1.5554) | Loss 328.0777(348.8265) | Error 0.5378(0.5610) Steps 0(0.00) | Grad Norm 462.8711(514.3295) | Total Time 0.00(0.00)\n",
      "Iter 1070 | Time 17.4957(18.0384) | Bit/dim 4.2375(4.2714) | Xent 1.4619(1.5461) | Loss 313.2617(340.6493) | Error 0.5189(0.5585) Steps 0(0.00) | Grad Norm 299.9613(489.6885) | Total Time 0.00(0.00)\n",
      "Iter 1080 | Time 19.9995(18.0952) | Bit/dim 4.2117(4.2594) | Xent 1.5245(1.5326) | Loss 320.3138(334.2171) | Error 0.5600(0.5558) Steps 0(0.00) | Grad Norm 200.6438(424.3709) | Total Time 0.00(0.00)\n",
      "Iter 1090 | Time 18.9694(18.0314) | Bit/dim 4.1920(4.2476) | Xent 1.5108(1.5199) | Loss 319.3542(328.2790) | Error 0.5478(0.5513) Steps 0(0.00) | Grad Norm 353.4259(395.2630) | Total Time 0.00(0.00)\n",
      "Iter 1100 | Time 17.3245(18.0397) | Bit/dim 4.1937(4.2377) | Xent 1.4808(1.5111) | Loss 311.9134(324.2197) | Error 0.5256(0.5472) Steps 0(0.00) | Grad Norm 303.6692(396.4650) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 90.7617, Epoch Time 1109.8722(902.3439), Bit/dim 4.2045(best: 4.2472), Xent 1.4079, Loss 4.9084, Error 0.5086(best: 0.5166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1110 | Time 17.8140(18.0761) | Bit/dim 4.2053(4.2242) | Xent 1.4581(1.4961) | Loss 309.4710(349.0095) | Error 0.5356(0.5407) Steps 0(0.00) | Grad Norm 242.4195(356.6753) | Total Time 0.00(0.00)\n",
      "Iter 1120 | Time 19.4626(17.8810) | Bit/dim 4.1888(4.2110) | Xent 1.3525(1.4797) | Loss 309.4344(339.0229) | Error 0.4967(0.5345) Steps 0(0.00) | Grad Norm 559.1063(356.9965) | Total Time 0.00(0.00)\n",
      "Iter 1130 | Time 19.5891(17.8675) | Bit/dim 4.1828(4.2050) | Xent 1.4168(1.4673) | Loss 305.7353(331.6764) | Error 0.4989(0.5308) Steps 0(0.00) | Grad Norm 391.4723(366.8971) | Total Time 0.00(0.00)\n",
      "Iter 1140 | Time 17.3042(17.8559) | Bit/dim 4.1782(4.1971) | Xent 1.4499(1.4612) | Loss 302.1624(326.3396) | Error 0.5300(0.5285) Steps 0(0.00) | Grad Norm 509.0053(367.0705) | Total Time 0.00(0.00)\n",
      "Iter 1150 | Time 16.5116(17.7556) | Bit/dim 4.1314(4.1896) | Xent 1.4266(1.4612) | Loss 307.7910(320.7880) | Error 0.5189(0.5283) Steps 0(0.00) | Grad Norm 207.5739(383.4644) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 91.3027, Epoch Time 1085.0113(907.8239), Bit/dim 4.2034(best: 4.2045), Xent 1.4203, Loss 4.9136, Error 0.5236(best: 0.5086)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1160 | Time 17.9762(17.8698) | Bit/dim 4.1441(4.1901) | Xent 1.4748(1.4666) | Loss 310.3323(352.0118) | Error 0.5378(0.5315) Steps 0(0.00) | Grad Norm 293.2044(423.3079) | Total Time 0.00(0.00)\n",
      "Iter 1170 | Time 17.2318(17.7956) | Bit/dim 4.1259(4.1834) | Xent 1.3665(1.4609) | Loss 310.6082(341.3141) | Error 0.4922(0.5299) Steps 0(0.00) | Grad Norm 155.2729(406.6386) | Total Time 0.00(0.00)\n",
      "Iter 1180 | Time 16.5292(17.8755) | Bit/dim 4.1371(4.1743) | Xent 1.3923(1.4450) | Loss 291.7399(332.2113) | Error 0.5222(0.5246) Steps 0(0.00) | Grad Norm 273.7228(357.5896) | Total Time 0.00(0.00)\n",
      "Iter 1190 | Time 18.6074(17.8166) | Bit/dim 4.1282(4.1601) | Xent 1.4694(1.4294) | Loss 307.8858(325.0691) | Error 0.5411(0.5187) Steps 0(0.00) | Grad Norm 177.5387(342.3788) | Total Time 0.00(0.00)\n",
      "Iter 1200 | Time 17.0992(17.6917) | Bit/dim 4.1844(4.1591) | Xent 1.5448(1.4464) | Loss 315.4049(322.1116) | Error 0.5833(0.5246) Steps 0(0.00) | Grad Norm 733.7910(415.3427) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 17.9141(17.6782) | Bit/dim 4.1362(4.1564) | Xent 1.3919(1.4491) | Loss 306.7042(317.9365) | Error 0.5022(0.5262) Steps 0(0.00) | Grad Norm 377.9464(409.7742) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 90.2011, Epoch Time 1083.1822(913.0846), Bit/dim 4.1314(best: 4.2034), Xent 1.3516, Loss 4.8072, Error 0.4928(best: 0.5086)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1220 | Time 17.1255(17.7081) | Bit/dim 4.0981(4.1437) | Xent 1.4179(1.4298) | Loss 308.8113(342.6668) | Error 0.4933(0.5193) Steps 0(0.00) | Grad Norm 190.4023(357.2836) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 17.5249(17.6095) | Bit/dim 4.1254(4.1374) | Xent 1.3695(1.4208) | Loss 294.2870(331.8630) | Error 0.5033(0.5154) Steps 0(0.00) | Grad Norm 434.5311(373.8304) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 18.3085(17.6175) | Bit/dim 4.1057(4.1287) | Xent 1.3524(1.4152) | Loss 306.6295(323.5980) | Error 0.4944(0.5147) Steps 0(0.00) | Grad Norm 279.3270(361.5573) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 19.9328(17.6697) | Bit/dim 4.0950(4.1241) | Xent 1.3390(1.4026) | Loss 312.7737(319.5206) | Error 0.4656(0.5102) Steps 0(0.00) | Grad Norm 325.8995(339.9891) | Total Time 0.00(0.00)\n",
      "Iter 1260 | Time 16.3151(17.5919) | Bit/dim 4.1060(4.1161) | Xent 1.3613(1.3931) | Loss 294.3961(314.5094) | Error 0.4978(0.5070) Steps 0(0.00) | Grad Norm 362.2469(340.9822) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 89.3034, Epoch Time 1075.0883(917.9447), Bit/dim 4.0945(best: 4.1314), Xent 1.3165, Loss 4.7528, Error 0.4739(best: 0.4928)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1270 | Time 19.0736(17.6499) | Bit/dim 4.0690(4.1105) | Xent 1.3912(1.3886) | Loss 313.4621(344.4912) | Error 0.5089(0.5039) Steps 0(0.00) | Grad Norm 462.4834(362.5924) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 16.4827(17.5635) | Bit/dim 4.1025(4.1014) | Xent 1.3670(1.3760) | Loss 292.6462(333.4422) | Error 0.4944(0.4987) Steps 0(0.00) | Grad Norm 467.1474(328.6953) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 18.5075(17.5198) | Bit/dim 4.0634(4.0945) | Xent 1.3650(1.3704) | Loss 309.3465(326.2976) | Error 0.4711(0.4969) Steps 0(0.00) | Grad Norm 242.6625(329.6068) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 15.7850(17.3840) | Bit/dim 4.0674(4.0847) | Xent 1.4063(1.3706) | Loss 299.7282(319.6039) | Error 0.5178(0.4973) Steps 0(0.00) | Grad Norm 307.1684(328.2047) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 21.4703(17.6016) | Bit/dim 4.0856(4.0813) | Xent 1.3617(1.3646) | Loss 320.5518(315.2704) | Error 0.4844(0.4955) Steps 0(0.00) | Grad Norm 320.8996(332.8917) | Total Time 0.00(0.00)\n",
      "Iter 1320 | Time 17.0480(17.5315) | Bit/dim 4.0723(4.0743) | Xent 1.3676(1.3595) | Loss 307.0601(310.7563) | Error 0.4989(0.4941) Steps 0(0.00) | Grad Norm 591.6729(316.5179) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 91.8371, Epoch Time 1072.6046(922.5845), Bit/dim 4.0928(best: 4.0945), Xent 1.3890, Loss 4.7873, Error 0.4997(best: 0.4739)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1330 | Time 17.7107(17.5243) | Bit/dim 4.0784(4.0751) | Xent 1.3060(1.3573) | Loss 307.8599(338.1378) | Error 0.4889(0.4937) Steps 0(0.00) | Grad Norm 528.2656(363.5481) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 16.8530(17.5751) | Bit/dim 4.0582(4.0693) | Xent 1.3355(1.3483) | Loss 288.0552(327.9466) | Error 0.4922(0.4892) Steps 0(0.00) | Grad Norm 264.4243(357.8371) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 17.3905(17.5320) | Bit/dim 4.0509(4.0629) | Xent 1.3367(1.3371) | Loss 297.4481(320.8458) | Error 0.4833(0.4854) Steps 0(0.00) | Grad Norm 120.2699(315.5466) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 16.6755(17.5883) | Bit/dim 4.0584(4.0568) | Xent 1.3152(1.3295) | Loss 303.2501(315.6397) | Error 0.4667(0.4822) Steps 0(0.00) | Grad Norm 252.1201(285.7447) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 18.1243(17.5587) | Bit/dim 4.0044(4.0469) | Xent 1.2998(1.3248) | Loss 301.5411(311.6451) | Error 0.4867(0.4796) Steps 0(0.00) | Grad Norm 255.2761(270.1487) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 90.4498, Epoch Time 1076.3394(927.1972), Bit/dim 4.0187(best: 4.0928), Xent 1.2367, Loss 4.6371, Error 0.4504(best: 0.4739)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1380 | Time 17.8994(17.5595) | Bit/dim 3.9943(4.0400) | Xent 1.3486(1.3212) | Loss 303.6942(340.3527) | Error 0.4978(0.4767) Steps 0(0.00) | Grad Norm 273.2533(279.3553) | Total Time 0.00(0.00)\n",
      "Iter 1390 | Time 18.0250(17.5405) | Bit/dim 4.0411(4.0362) | Xent 1.4271(1.3284) | Loss 310.3853(329.4924) | Error 0.5233(0.4783) Steps 0(0.00) | Grad Norm 689.3206(346.3720) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 17.3759(17.5170) | Bit/dim 4.0381(4.0337) | Xent 1.2564(1.3222) | Loss 298.5493(321.2628) | Error 0.4678(0.4766) Steps 0(0.00) | Grad Norm 169.0924(321.9600) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 17.4932(17.4616) | Bit/dim 4.0354(4.0316) | Xent 1.2368(1.3206) | Loss 296.3348(315.1876) | Error 0.4633(0.4775) Steps 0(0.00) | Grad Norm 241.0856(320.0539) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 17.1832(17.6437) | Bit/dim 4.0089(4.0277) | Xent 1.2596(1.3105) | Loss 304.0836(311.1894) | Error 0.4278(0.4739) Steps 0(0.00) | Grad Norm 329.7837(317.4393) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 19.1197(17.6726) | Bit/dim 3.9919(4.0259) | Xent 1.2595(1.3074) | Loss 301.2425(308.2197) | Error 0.4544(0.4732) Steps 0(0.00) | Grad Norm 314.0093(312.0565) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 88.1667, Epoch Time 1073.1902(931.5770), Bit/dim 4.0109(best: 4.0187), Xent 1.2238, Loss 4.6228, Error 0.4434(best: 0.4504)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1440 | Time 15.5617(17.6614) | Bit/dim 4.0364(4.0202) | Xent 1.2155(1.2990) | Loss 292.8031(332.0252) | Error 0.4211(0.4684) Steps 0(0.00) | Grad Norm 543.0845(309.2958) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 16.1883(17.5007) | Bit/dim 3.9895(4.0166) | Xent 1.2225(1.2891) | Loss 284.5313(321.9310) | Error 0.4611(0.4663) Steps 0(0.00) | Grad Norm 179.5228(300.4881) | Total Time 0.00(0.00)\n",
      "Iter 1460 | Time 17.5694(17.8406) | Bit/dim 3.9391(4.0079) | Xent 1.2723(1.2831) | Loss 286.0376(315.0690) | Error 0.4544(0.4644) Steps 0(0.00) | Grad Norm 281.9995(278.3059) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 18.3804(17.8507) | Bit/dim 3.9871(4.0047) | Xent 1.2353(1.2762) | Loss 310.1231(311.3411) | Error 0.4500(0.4632) Steps 0(0.00) | Grad Norm 277.2174(276.5210) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 15.3028(17.6671) | Bit/dim 3.9954(4.0015) | Xent 1.3474(1.2797) | Loss 277.5153(306.7963) | Error 0.4989(0.4636) Steps 0(0.00) | Grad Norm 464.3902(283.5084) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 88.3932, Epoch Time 1078.9671(935.9987), Bit/dim 3.9840(best: 4.0109), Xent 1.2020, Loss 4.5851, Error 0.4353(best: 0.4434)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1490 | Time 17.2510(17.6088) | Bit/dim 3.9533(3.9966) | Xent 1.3002(1.2753) | Loss 298.4399(335.3592) | Error 0.4689(0.4617) Steps 0(0.00) | Grad Norm 311.1172(295.3960) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 17.7476(17.4778) | Bit/dim 3.9683(3.9918) | Xent 1.2538(1.2709) | Loss 290.1876(324.5871) | Error 0.4444(0.4592) Steps 0(0.00) | Grad Norm 234.2207(270.6617) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 17.4890(17.5591) | Bit/dim 3.9621(3.9846) | Xent 1.2288(1.2600) | Loss 296.1966(317.0945) | Error 0.4544(0.4541) Steps 0(0.00) | Grad Norm 345.7899(267.5538) | Total Time 0.00(0.00)\n",
      "Iter 1520 | Time 17.5932(17.6075) | Bit/dim 3.9843(3.9807) | Xent 1.2929(1.2614) | Loss 294.3574(310.9652) | Error 0.4700(0.4568) Steps 0(0.00) | Grad Norm 295.1465(282.6557) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 18.0082(17.6705) | Bit/dim 3.9866(3.9768) | Xent 1.1969(1.2541) | Loss 302.8004(306.3767) | Error 0.4222(0.4542) Steps 0(0.00) | Grad Norm 181.3543(278.8957) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 16.2333(17.6304) | Bit/dim 3.9774(3.9748) | Xent 1.2240(1.2498) | Loss 279.6465(301.9774) | Error 0.4478(0.4533) Steps 0(0.00) | Grad Norm 193.0683(278.3477) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 88.8760, Epoch Time 1074.6921(940.1595), Bit/dim 3.9621(best: 3.9840), Xent 1.1626, Loss 4.5434, Error 0.4198(best: 0.4353)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1550 | Time 18.6263(17.5815) | Bit/dim 3.9750(3.9727) | Xent 1.2012(1.2424) | Loss 296.1000(328.7373) | Error 0.4122(0.4489) Steps 0(0.00) | Grad Norm 411.9065(306.8606) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 17.7821(17.6446) | Bit/dim 3.9348(3.9681) | Xent 1.2216(1.2454) | Loss 280.1793(318.4809) | Error 0.4300(0.4494) Steps 0(0.00) | Grad Norm 406.7922(317.2711) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 16.8573(17.5307) | Bit/dim 3.9363(3.9644) | Xent 1.1468(1.2326) | Loss 291.8696(311.9833) | Error 0.4133(0.4451) Steps 0(0.00) | Grad Norm 278.3924(297.3484) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 16.1100(17.5185) | Bit/dim 3.9393(3.9604) | Xent 1.2926(1.2339) | Loss 291.4462(307.4037) | Error 0.4456(0.4450) Steps 0(0.00) | Grad Norm 306.6705(305.4373) | Total Time 0.00(0.00)\n",
      "Iter 1590 | Time 17.3079(17.4442) | Bit/dim 3.9899(3.9584) | Xent 1.1824(1.2291) | Loss 288.9982(302.7538) | Error 0.4300(0.4430) Steps 0(0.00) | Grad Norm 354.0135(318.8543) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 87.6885, Epoch Time 1064.5757(943.8920), Bit/dim 3.9511(best: 3.9621), Xent 1.1464, Loss 4.5243, Error 0.4158(best: 0.4198)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1600 | Time 15.7858(17.3875) | Bit/dim 3.9600(3.9573) | Xent 1.2623(1.2294) | Loss 284.9301(331.1485) | Error 0.4611(0.4443) Steps 0(0.00) | Grad Norm 447.9454(320.2943) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 16.8188(17.3237) | Bit/dim 3.9393(3.9526) | Xent 1.1524(1.2158) | Loss 272.0625(319.1820) | Error 0.4078(0.4396) Steps 0(0.00) | Grad Norm 179.2588(297.3771) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 18.4288(17.4019) | Bit/dim 3.9500(3.9512) | Xent 1.2133(1.2111) | Loss 290.0136(311.8089) | Error 0.4456(0.4375) Steps 0(0.00) | Grad Norm 262.3534(301.1639) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 16.0087(17.3711) | Bit/dim 3.9204(3.9489) | Xent 1.2349(1.2111) | Loss 283.9532(306.3264) | Error 0.4389(0.4361) Steps 0(0.00) | Grad Norm 482.1704(309.4699) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 16.3939(17.2521) | Bit/dim 3.9638(3.9483) | Xent 1.2538(1.2166) | Loss 285.4358(301.9389) | Error 0.4667(0.4375) Steps 0(0.00) | Grad Norm 363.5033(324.5656) | Total Time 0.00(0.00)\n",
      "Iter 1650 | Time 16.9581(17.2563) | Bit/dim 3.9287(3.9447) | Xent 1.1787(1.2229) | Loss 289.9128(299.0768) | Error 0.4256(0.4394) Steps 0(0.00) | Grad Norm 265.9551(335.5881) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 87.0968, Epoch Time 1052.7306(947.1571), Bit/dim 3.9493(best: 3.9511), Xent 1.1533, Loss 4.5259, Error 0.4161(best: 0.4158)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1660 | Time 17.6126(17.2506) | Bit/dim 3.9285(3.9422) | Xent 1.2071(1.2171) | Loss 289.2414(322.5212) | Error 0.4511(0.4372) Steps 0(0.00) | Grad Norm 321.8262(335.0156) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 16.7792(17.0978) | Bit/dim 3.9131(3.9411) | Xent 1.1184(1.2074) | Loss 287.7255(312.5928) | Error 0.4089(0.4347) Steps 0(0.00) | Grad Norm 323.4035(328.3915) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 20.4177(17.2937) | Bit/dim 3.9219(3.9381) | Xent 1.1697(1.1911) | Loss 281.5440(306.5064) | Error 0.4378(0.4273) Steps 0(0.00) | Grad Norm 291.0924(306.5876) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 16.5824(17.1862) | Bit/dim 3.9573(3.9367) | Xent 1.1290(1.1805) | Loss 290.7643(301.5620) | Error 0.4122(0.4232) Steps 0(0.00) | Grad Norm 289.5764(286.5024) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 16.7541(17.0819) | Bit/dim 3.9097(3.9306) | Xent 1.1607(1.1764) | Loss 281.1320(297.2256) | Error 0.4100(0.4212) Steps 0(0.00) | Grad Norm 218.0912(260.0336) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 87.2721, Epoch Time 1046.6774(950.1427), Bit/dim 3.9243(best: 3.9493), Xent 1.1192, Loss 4.4839, Error 0.4006(best: 0.4158)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1710 | Time 17.6190(17.0537) | Bit/dim 3.9198(3.9252) | Xent 1.1399(1.1707) | Loss 292.9616(325.7177) | Error 0.4022(0.4199) Steps 0(0.00) | Grad Norm 386.3382(288.7503) | Total Time 0.00(0.00)\n",
      "Iter 1720 | Time 16.6578(17.0435) | Bit/dim 3.9439(3.9253) | Xent 1.1948(1.1664) | Loss 288.7677(315.6651) | Error 0.4244(0.4166) Steps 0(0.00) | Grad Norm 393.4335(306.5363) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 17.2870(17.1304) | Bit/dim 3.9177(3.9230) | Xent 1.1002(1.1655) | Loss 292.8695(308.5124) | Error 0.3922(0.4163) Steps 0(0.00) | Grad Norm 186.5210(312.2731) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 17.0626(17.1564) | Bit/dim 3.9620(3.9232) | Xent 1.2687(1.1740) | Loss 287.8223(303.6715) | Error 0.4644(0.4198) Steps 0(0.00) | Grad Norm 462.3058(346.9137) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 16.5809(17.2321) | Bit/dim 3.9599(3.9221) | Xent 1.1549(1.1812) | Loss 293.9271(300.0720) | Error 0.4078(0.4225) Steps 0(0.00) | Grad Norm 300.3307(342.7741) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 15.8199(17.2839) | Bit/dim 3.8888(3.9180) | Xent 1.1414(1.1800) | Loss 277.1229(297.0169) | Error 0.4211(0.4219) Steps 0(0.00) | Grad Norm 282.7259(333.4893) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 87.3670, Epoch Time 1052.9520(953.2270), Bit/dim 3.9063(best: 3.9243), Xent 1.0837, Loss 4.4482, Error 0.3844(best: 0.4006)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1770 | Time 17.7918(17.3790) | Bit/dim 3.8939(3.9153) | Xent 1.0584(1.1654) | Loss 283.4291(322.3646) | Error 0.3911(0.4162) Steps 0(0.00) | Grad Norm 211.6132(306.8207) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 16.2775(17.2312) | Bit/dim 3.9309(3.9138) | Xent 1.2123(1.1584) | Loss 286.6042(313.1400) | Error 0.4189(0.4135) Steps 0(0.00) | Grad Norm 401.9745(297.4172) | Total Time 0.00(0.00)\n",
      "Iter 1790 | Time 17.0442(17.2733) | Bit/dim 3.9149(3.9094) | Xent 1.1582(1.1612) | Loss 278.7972(305.5525) | Error 0.4233(0.4154) Steps 0(0.00) | Grad Norm 372.7622(318.7689) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 16.9264(17.3124) | Bit/dim 3.9040(3.9096) | Xent 1.2011(1.1645) | Loss 284.1816(301.0066) | Error 0.4344(0.4173) Steps 0(0.00) | Grad Norm 473.2242(327.7045) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 17.1987(17.2260) | Bit/dim 3.9084(3.9063) | Xent 1.1093(1.1553) | Loss 289.6818(295.7767) | Error 0.3689(0.4144) Steps 0(0.00) | Grad Norm 241.2761(302.4401) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 88.6027, Epoch Time 1062.1072(956.4934), Bit/dim 3.8983(best: 3.9063), Xent 1.0759, Loss 4.4363, Error 0.3786(best: 0.3844)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1820 | Time 16.8908(17.3980) | Bit/dim 3.9175(3.9050) | Xent 1.1076(1.1421) | Loss 294.8123(324.5181) | Error 0.3967(0.4100) Steps 0(0.00) | Grad Norm 251.7342(274.9905) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 17.0315(17.3114) | Bit/dim 3.8567(3.9006) | Xent 1.0691(1.1261) | Loss 280.1230(313.8418) | Error 0.3822(0.4038) Steps 0(0.00) | Grad Norm 346.1786(263.0729) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 16.7318(17.2702) | Bit/dim 3.8488(3.8965) | Xent 1.2169(1.1213) | Loss 260.7605(305.3439) | Error 0.4322(0.4015) Steps 0(0.00) | Grad Norm 414.5689(277.9542) | Total Time 0.00(0.00)\n",
      "Iter 1850 | Time 17.2516(17.1617) | Bit/dim 3.8758(3.8973) | Xent 1.1051(1.1241) | Loss 291.5435(300.0210) | Error 0.4011(0.4029) Steps 0(0.00) | Grad Norm 292.7380(281.9996) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 16.1113(17.0463) | Bit/dim 3.8644(3.8918) | Xent 1.0401(1.1169) | Loss 274.3390(294.9478) | Error 0.3733(0.3989) Steps 0(0.00) | Grad Norm 304.7593(281.9508) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 17.0201(17.0122) | Bit/dim 3.8895(3.8903) | Xent 1.1056(1.1174) | Loss 278.7217(292.7063) | Error 0.3900(0.3990) Steps 0(0.00) | Grad Norm 344.4349(271.3859) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 87.6130, Epoch Time 1038.8295(958.9635), Bit/dim 3.8756(best: 3.8983), Xent 1.0350, Loss 4.3931, Error 0.3706(best: 0.3786)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1880 | Time 17.4769(17.0310) | Bit/dim 3.9152(3.8892) | Xent 0.9936(1.1044) | Loss 285.9070(316.6341) | Error 0.3500(0.3942) Steps 0(0.00) | Grad Norm 373.6151(270.5214) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 15.9151(17.0648) | Bit/dim 3.8774(3.8873) | Xent 1.0301(1.0964) | Loss 272.1066(307.4641) | Error 0.3800(0.3917) Steps 0(0.00) | Grad Norm 195.8392(257.9625) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 16.7120(17.1391) | Bit/dim 3.8664(3.8883) | Xent 1.1028(1.0997) | Loss 271.5864(301.5996) | Error 0.3989(0.3917) Steps 0(0.00) | Grad Norm 335.0412(299.5890) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 16.4993(16.9871) | Bit/dim 3.8782(3.8870) | Xent 1.1142(1.1030) | Loss 292.1772(297.2636) | Error 0.3933(0.3940) Steps 0(0.00) | Grad Norm 311.8837(300.4290) | Total Time 0.00(0.00)\n",
      "Iter 1920 | Time 17.8940(17.0466) | Bit/dim 3.8801(3.8809) | Xent 1.1323(1.0998) | Loss 285.0678(293.6650) | Error 0.4111(0.3940) Steps 0(0.00) | Grad Norm 206.1982(284.3147) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 87.1116, Epoch Time 1047.6419(961.6239), Bit/dim 3.8929(best: 3.8756), Xent 1.0643, Loss 4.4251, Error 0.3768(best: 0.3706)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1930 | Time 17.6481(17.2645) | Bit/dim 3.8653(3.8827) | Xent 1.1577(1.0988) | Loss 287.3255(323.5249) | Error 0.4078(0.3928) Steps 0(0.00) | Grad Norm 205.1640(289.4283) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 18.3127(17.2415) | Bit/dim 3.8617(3.8776) | Xent 1.0862(1.0955) | Loss 274.7973(312.4810) | Error 0.3944(0.3917) Steps 0(0.00) | Grad Norm 379.2780(296.0063) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 18.2662(17.3148) | Bit/dim 3.9065(3.8788) | Xent 1.0892(1.0938) | Loss 290.4598(304.7535) | Error 0.3944(0.3928) Steps 0(0.00) | Grad Norm 392.4773(303.1929) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 18.3652(17.3942) | Bit/dim 3.8546(3.8753) | Xent 1.0863(1.0899) | Loss 281.8412(298.8116) | Error 0.3933(0.3913) Steps 0(0.00) | Grad Norm 303.3249(292.2235) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 17.8980(17.3062) | Bit/dim 3.8620(3.8699) | Xent 1.0752(1.0860) | Loss 278.4675(294.0832) | Error 0.3844(0.3883) Steps 0(0.00) | Grad Norm 277.7856(276.7461) | Total Time 0.00(0.00)\n",
      "Iter 1980 | Time 16.4317(17.2139) | Bit/dim 3.8716(3.8722) | Xent 1.0568(1.0831) | Loss 286.6889(290.1626) | Error 0.3878(0.3879) Steps 0(0.00) | Grad Norm 296.6774(285.3446) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 88.0253, Epoch Time 1057.7277(964.5070), Bit/dim 3.8771(best: 3.8756), Xent 1.0658, Loss 4.4100, Error 0.3845(best: 0.3706)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1990 | Time 17.4337(17.1999) | Bit/dim 3.8710(3.8700) | Xent 1.0839(1.0814) | Loss 297.5869(315.4475) | Error 0.3911(0.3862) Steps 0(0.00) | Grad Norm 218.4395(276.4916) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 19.3543(17.2865) | Bit/dim 3.8595(3.8698) | Xent 1.1140(1.0762) | Loss 287.0308(307.6016) | Error 0.4067(0.3853) Steps 0(0.00) | Grad Norm 347.1857(280.7048) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 16.9684(17.2718) | Bit/dim 3.8791(3.8686) | Xent 1.0513(1.0710) | Loss 284.4158(301.0935) | Error 0.3856(0.3852) Steps 0(0.00) | Grad Norm 302.5576(269.7800) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 15.9976(17.2937) | Bit/dim 3.8661(3.8652) | Xent 1.1277(1.0698) | Loss 283.8934(295.9377) | Error 0.3911(0.3842) Steps 0(0.00) | Grad Norm 249.1916(279.0355) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 17.3082(17.4170) | Bit/dim 3.9243(3.8654) | Xent 1.1026(1.0798) | Loss 273.4530(292.6479) | Error 0.3911(0.3870) Steps 0(0.00) | Grad Norm 202.8129(312.1496) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 88.0485, Epoch Time 1066.6226(967.5704), Bit/dim 3.8761(best: 3.8756), Xent 1.0570, Loss 4.4047, Error 0.3795(best: 0.3706)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2040 | Time 17.7795(17.4716) | Bit/dim 3.8765(3.8662) | Xent 1.0373(1.0776) | Loss 283.7277(322.0835) | Error 0.3711(0.3853) Steps 0(0.00) | Grad Norm 158.1611(300.3896) | Total Time 0.00(0.00)\n",
      "Iter 2050 | Time 17.6051(17.4378) | Bit/dim 3.8709(3.8662) | Xent 0.9891(1.0726) | Loss 285.5288(311.5235) | Error 0.3489(0.3824) Steps 0(0.00) | Grad Norm 234.3140(306.0742) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 16.5492(17.4064) | Bit/dim 3.8552(3.8640) | Xent 1.0657(1.0695) | Loss 279.2637(304.8003) | Error 0.3722(0.3801) Steps 0(0.00) | Grad Norm 225.6377(297.9290) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 17.2259(17.3845) | Bit/dim 3.8340(3.8601) | Xent 1.0374(1.0515) | Loss 275.3089(298.0824) | Error 0.3478(0.3734) Steps 0(0.00) | Grad Norm 177.6860(270.3982) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 17.3547(17.4261) | Bit/dim 3.8610(3.8598) | Xent 1.0238(1.0508) | Loss 279.3073(294.4425) | Error 0.3656(0.3752) Steps 0(0.00) | Grad Norm 299.6119(271.4272) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 17.4513(17.4217) | Bit/dim 3.7986(3.8531) | Xent 1.1109(1.0530) | Loss 287.3372(291.8199) | Error 0.4100(0.3764) Steps 0(0.00) | Grad Norm 447.2231(288.0419) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 86.9680, Epoch Time 1061.3468(970.3837), Bit/dim 3.8580(best: 3.8756), Xent 1.0577, Loss 4.3868, Error 0.3741(best: 0.3706)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2100 | Time 17.6006(17.3933) | Bit/dim 3.8629(3.8538) | Xent 1.0272(1.0523) | Loss 282.1469(317.5761) | Error 0.3756(0.3758) Steps 0(0.00) | Grad Norm 406.3725(331.9116) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 18.6979(17.4268) | Bit/dim 3.8475(3.8554) | Xent 1.0529(1.0487) | Loss 279.3758(307.1368) | Error 0.3756(0.3750) Steps 0(0.00) | Grad Norm 200.3705(315.0511) | Total Time 0.00(0.00)\n",
      "Iter 2120 | Time 16.8401(17.3165) | Bit/dim 3.8222(3.8503) | Xent 1.0240(1.0373) | Loss 284.0639(300.3175) | Error 0.3600(0.3714) Steps 0(0.00) | Grad Norm 203.4915(272.9105) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 16.9079(17.2203) | Bit/dim 3.8246(3.8479) | Xent 1.0225(1.0440) | Loss 277.8849(295.7924) | Error 0.3689(0.3737) Steps 0(0.00) | Grad Norm 226.1637(276.7280) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 16.6120(17.1911) | Bit/dim 3.8654(3.8459) | Xent 1.0434(1.0438) | Loss 272.6464(291.6705) | Error 0.3956(0.3734) Steps 0(0.00) | Grad Norm 251.6790(266.7186) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 87.8724, Epoch Time 1056.1768(972.9575), Bit/dim 3.8441(best: 3.8580), Xent 0.9703, Loss 4.3293, Error 0.3453(best: 0.3706)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2150 | Time 16.9562(17.2729) | Bit/dim 3.8294(3.8436) | Xent 1.0500(1.0405) | Loss 281.4550(321.5315) | Error 0.3700(0.3725) Steps 0(0.00) | Grad Norm 207.1616(249.0820) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 17.0474(17.2961) | Bit/dim 3.8523(3.8443) | Xent 0.9801(1.0306) | Loss 282.4459(312.0094) | Error 0.3644(0.3688) Steps 0(0.00) | Grad Norm 205.8865(249.2837) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 16.7239(17.3290) | Bit/dim 3.8416(3.8473) | Xent 1.0403(1.0317) | Loss 283.8507(304.1384) | Error 0.3567(0.3674) Steps 0(0.00) | Grad Norm 472.0375(281.7805) | Total Time 0.00(0.00)\n",
      "Iter 2180 | Time 16.8637(17.2710) | Bit/dim 3.8267(3.8456) | Xent 1.0036(1.0292) | Loss 282.3586(297.8920) | Error 0.3633(0.3681) Steps 0(0.00) | Grad Norm 387.0805(270.9394) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 18.2312(17.3938) | Bit/dim 3.8070(3.8417) | Xent 1.0716(1.0279) | Loss 291.4483(294.5630) | Error 0.3867(0.3677) Steps 0(0.00) | Grad Norm 234.8330(268.7840) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 17.1063(17.3701) | Bit/dim 3.8144(3.8380) | Xent 0.9950(1.0271) | Loss 276.9095(290.9658) | Error 0.3522(0.3667) Steps 0(0.00) | Grad Norm 250.1040(259.3976) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 88.3884, Epoch Time 1059.5639(975.5557), Bit/dim 3.8357(best: 3.8441), Xent 1.0097, Loss 4.3405, Error 0.3655(best: 0.3453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2210 | Time 17.1322(17.2401) | Bit/dim 3.8356(3.8338) | Xent 0.9726(1.0160) | Loss 275.6079(313.4809) | Error 0.3511(0.3624) Steps 0(0.00) | Grad Norm 133.1316(243.2915) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 16.7970(17.3218) | Bit/dim 3.8209(3.8313) | Xent 1.0656(1.0132) | Loss 271.5164(304.1273) | Error 0.3811(0.3614) Steps 0(0.00) | Grad Norm 226.7168(250.4132) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 17.6931(17.3417) | Bit/dim 3.8283(3.8312) | Xent 1.0354(1.0098) | Loss 282.6557(298.4236) | Error 0.3633(0.3582) Steps 0(0.00) | Grad Norm 106.0107(245.0613) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 17.7625(17.2112) | Bit/dim 3.8199(3.8301) | Xent 1.0505(1.0195) | Loss 266.5953(292.2962) | Error 0.3711(0.3628) Steps 0(0.00) | Grad Norm 372.6833(260.7290) | Total Time 0.00(0.00)\n",
      "Iter 2250 | Time 16.6847(17.1664) | Bit/dim 3.8408(3.8337) | Xent 1.0817(1.0283) | Loss 285.2726(290.6743) | Error 0.3878(0.3664) Steps 0(0.00) | Grad Norm 373.0146(283.7963) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 88.6557, Epoch Time 1050.0232(977.7897), Bit/dim 3.8331(best: 3.8357), Xent 0.9728, Loss 4.3195, Error 0.3466(best: 0.3453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2260 | Time 16.8732(17.1741) | Bit/dim 3.8301(3.8358) | Xent 0.9480(1.0177) | Loss 271.9176(319.6797) | Error 0.3356(0.3618) Steps 0(0.00) | Grad Norm 355.6307(281.9970) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 16.7191(17.2410) | Bit/dim 3.8284(3.8339) | Xent 1.0166(1.0095) | Loss 270.5237(308.8852) | Error 0.3644(0.3569) Steps 0(0.00) | Grad Norm 241.8760(267.6174) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 17.8470(17.2155) | Bit/dim 3.8190(3.8321) | Xent 0.9427(1.0001) | Loss 277.4724(300.5824) | Error 0.3378(0.3544) Steps 0(0.00) | Grad Norm 179.0361(249.8549) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 17.6127(17.3796) | Bit/dim 3.7906(3.8276) | Xent 0.9840(0.9982) | Loss 275.4970(295.0775) | Error 0.3467(0.3548) Steps 0(0.00) | Grad Norm 170.3244(258.5251) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 19.0968(17.5166) | Bit/dim 3.8277(3.8240) | Xent 0.9912(1.0102) | Loss 274.4754(291.2038) | Error 0.3544(0.3588) Steps 0(0.00) | Grad Norm 329.6474(266.0755) | Total Time 0.00(0.00)\n",
      "Iter 2310 | Time 20.0276(17.7146) | Bit/dim 3.8115(3.8212) | Xent 1.0362(1.0039) | Loss 285.5825(289.0265) | Error 0.3622(0.3576) Steps 0(0.00) | Grad Norm 329.9061(251.7327) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 88.1137, Epoch Time 1077.7033(980.7872), Bit/dim 3.8154(best: 3.8331), Xent 0.9584, Loss 4.2946, Error 0.3433(best: 0.3453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2320 | Time 17.6288(17.7856) | Bit/dim 3.8233(3.8210) | Xent 0.9569(1.0091) | Loss 279.6465(314.2422) | Error 0.3489(0.3587) Steps 0(0.00) | Grad Norm 348.3654(262.9144) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 18.4985(17.6772) | Bit/dim 3.8126(3.8212) | Xent 0.9976(1.0016) | Loss 293.0238(304.8992) | Error 0.3433(0.3555) Steps 0(0.00) | Grad Norm 347.0385(267.9921) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 17.8605(17.6099) | Bit/dim 3.8197(3.8225) | Xent 0.9518(0.9972) | Loss 283.4836(298.8082) | Error 0.3233(0.3539) Steps 0(0.00) | Grad Norm 265.3879(281.6302) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 17.4261(17.4950) | Bit/dim 3.8164(3.8200) | Xent 0.9777(0.9951) | Loss 286.2862(294.0424) | Error 0.3433(0.3539) Steps 0(0.00) | Grad Norm 223.9375(267.1429) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 15.9109(17.4931) | Bit/dim 3.7725(3.8172) | Xent 0.9757(0.9906) | Loss 273.9468(290.4500) | Error 0.3400(0.3517) Steps 0(0.00) | Grad Norm 168.6905(251.3468) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 87.9822, Epoch Time 1066.9758(983.3728), Bit/dim 3.8136(best: 3.8154), Xent 0.9424, Loss 4.2848, Error 0.3353(best: 0.3433)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2370 | Time 18.2968(17.5083) | Bit/dim 3.8242(3.8169) | Xent 0.8810(0.9850) | Loss 285.5825(319.6706) | Error 0.3122(0.3490) Steps 0(0.00) | Grad Norm 343.8352(266.6064) | Total Time 0.00(0.00)\n",
      "Iter 2380 | Time 17.5219(17.3983) | Bit/dim 3.8431(3.8184) | Xent 0.9519(0.9803) | Loss 287.7669(308.9623) | Error 0.3222(0.3485) Steps 0(0.00) | Grad Norm 169.0793(272.9704) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 17.2607(17.4031) | Bit/dim 3.7850(3.8149) | Xent 1.0161(0.9842) | Loss 278.3995(301.7398) | Error 0.3711(0.3512) Steps 0(0.00) | Grad Norm 296.7565(260.5478) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 16.3344(17.3142) | Bit/dim 3.7982(3.8123) | Xent 0.9761(0.9850) | Loss 282.3282(295.5839) | Error 0.3422(0.3501) Steps 0(0.00) | Grad Norm 161.1403(250.8964) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 17.8688(17.2461) | Bit/dim 3.8093(3.8101) | Xent 1.0129(0.9864) | Loss 282.6131(290.1316) | Error 0.3589(0.3505) Steps 0(0.00) | Grad Norm 365.9084(282.1099) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 16.2414(17.3245) | Bit/dim 3.8031(3.8101) | Xent 0.9032(0.9864) | Loss 281.5379(288.0069) | Error 0.3300(0.3516) Steps 0(0.00) | Grad Norm 249.6770(285.7306) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 87.3313, Epoch Time 1054.0855(985.4942), Bit/dim 3.8126(best: 3.8136), Xent 0.9338, Loss 4.2794, Error 0.3320(best: 0.3353)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2430 | Time 22.0100(17.5326) | Bit/dim 3.8102(3.8110) | Xent 0.9481(0.9767) | Loss 287.2763(313.5169) | Error 0.3400(0.3476) Steps 0(0.00) | Grad Norm 218.9841(271.5430) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 19.0944(17.4752) | Bit/dim 3.8118(3.8079) | Xent 0.9752(0.9745) | Loss 281.7998(304.5341) | Error 0.3600(0.3464) Steps 0(0.00) | Grad Norm 225.7565(260.0422) | Total Time 0.00(0.00)\n",
      "Iter 2450 | Time 16.0472(17.2825) | Bit/dim 3.7976(3.8056) | Xent 0.9101(0.9683) | Loss 276.0960(297.4253) | Error 0.3056(0.3449) Steps 0(0.00) | Grad Norm 150.3464(251.1006) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 17.2568(17.2754) | Bit/dim 3.8130(3.8063) | Xent 1.0109(0.9772) | Loss 286.4580(293.5135) | Error 0.3656(0.3488) Steps 0(0.00) | Grad Norm 284.5430(269.1170) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 18.7744(17.2356) | Bit/dim 3.8130(3.8070) | Xent 0.9632(0.9785) | Loss 278.5777(288.9459) | Error 0.3233(0.3482) Steps 0(0.00) | Grad Norm 364.8701(281.8706) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 88.1113, Epoch Time 1056.0782(987.6117), Bit/dim 3.8129(best: 3.8126), Xent 0.9678, Loss 4.2968, Error 0.3394(best: 0.3320)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2480 | Time 15.7751(17.3257) | Bit/dim 3.7690(3.8068) | Xent 1.0257(0.9806) | Loss 259.7772(318.3167) | Error 0.3611(0.3492) Steps 0(0.00) | Grad Norm 329.9396(283.8791) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 17.0776(17.2740) | Bit/dim 3.8207(3.8063) | Xent 1.0451(0.9775) | Loss 281.4135(307.3415) | Error 0.3778(0.3476) Steps 0(0.00) | Grad Norm 383.6778(285.4039) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 17.7398(17.3151) | Bit/dim 3.7935(3.8075) | Xent 0.9974(0.9828) | Loss 278.9127(299.5036) | Error 0.3356(0.3500) Steps 0(0.00) | Grad Norm 433.7701(304.3860) | Total Time 0.00(0.00)\n",
      "Iter 2510 | Time 20.1151(17.4914) | Bit/dim 3.8020(3.8086) | Xent 0.9824(0.9783) | Loss 291.7481(294.8726) | Error 0.3644(0.3473) Steps 0(0.00) | Grad Norm 213.6813(288.1358) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 16.7833(17.3195) | Bit/dim 3.7996(3.8057) | Xent 0.9575(0.9682) | Loss 270.2057(289.5337) | Error 0.3311(0.3435) Steps 0(0.00) | Grad Norm 274.1349(279.7849) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 17.2967(17.2900) | Bit/dim 3.7794(3.8029) | Xent 0.8996(0.9625) | Loss 277.3095(286.2659) | Error 0.3244(0.3405) Steps 0(0.00) | Grad Norm 332.2270(280.3765) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 85.8814, Epoch Time 1059.3378(989.7635), Bit/dim 3.7962(best: 3.8126), Xent 0.9154, Loss 4.2539, Error 0.3272(best: 0.3320)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2540 | Time 17.1239(17.2440) | Bit/dim 3.7923(3.8012) | Xent 0.9435(0.9590) | Loss 265.3649(310.6728) | Error 0.3367(0.3400) Steps 0(0.00) | Grad Norm 158.6348(270.1915) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 18.5814(17.3937) | Bit/dim 3.7876(3.8020) | Xent 0.9599(0.9635) | Loss 286.0468(302.3346) | Error 0.3544(0.3429) Steps 0(0.00) | Grad Norm 340.5242(288.3687) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 17.0787(17.4832) | Bit/dim 3.8196(3.8001) | Xent 0.9446(0.9620) | Loss 277.2339(295.0797) | Error 0.3422(0.3429) Steps 0(0.00) | Grad Norm 245.8491(288.9478) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 17.6318(17.5195) | Bit/dim 3.8164(3.7996) | Xent 0.9641(0.9552) | Loss 271.2358(290.4572) | Error 0.3444(0.3406) Steps 0(0.00) | Grad Norm 130.5510(272.5218) | Total Time 0.00(0.00)\n",
      "Iter 2580 | Time 19.7145(17.5368) | Bit/dim 3.7912(3.7973) | Xent 0.9151(0.9493) | Loss 282.9899(287.4607) | Error 0.3222(0.3394) Steps 0(0.00) | Grad Norm 172.0573(260.2873) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 87.2816, Epoch Time 1078.6039(992.4287), Bit/dim 3.7914(best: 3.7962), Xent 0.9108, Loss 4.2468, Error 0.3264(best: 0.3272)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2590 | Time 18.5729(17.6073) | Bit/dim 3.7479(3.7901) | Xent 0.7938(0.9413) | Loss 272.1431(317.2709) | Error 0.2833(0.3360) Steps 0(0.00) | Grad Norm 224.8745(236.2427) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 17.2072(17.5888) | Bit/dim 3.7802(3.7898) | Xent 0.8699(0.9328) | Loss 263.2495(305.0045) | Error 0.2989(0.3318) Steps 0(0.00) | Grad Norm 327.0009(240.6673) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 17.6873(17.6156) | Bit/dim 3.7993(3.7910) | Xent 0.9389(0.9509) | Loss 285.7580(298.2106) | Error 0.3233(0.3370) Steps 0(0.00) | Grad Norm 230.4666(273.4199) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 17.4411(17.6027) | Bit/dim 3.7698(3.7901) | Xent 0.9385(0.9522) | Loss 272.1856(292.8051) | Error 0.3489(0.3378) Steps 0(0.00) | Grad Norm 191.7909(261.8251) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 17.5220(17.4932) | Bit/dim 3.7633(3.7898) | Xent 0.9667(0.9449) | Loss 276.4922(287.4430) | Error 0.3478(0.3358) Steps 0(0.00) | Grad Norm 126.0883(240.6253) | Total Time 0.00(0.00)\n",
      "Iter 2640 | Time 17.3052(17.6039) | Bit/dim 3.8169(3.7894) | Xent 0.9469(0.9438) | Loss 267.8842(283.6358) | Error 0.3422(0.3358) Steps 0(0.00) | Grad Norm 261.0857(251.2071) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 87.9411, Epoch Time 1070.5960(994.7737), Bit/dim 3.7888(best: 3.7914), Xent 0.9161, Loss 4.2469, Error 0.3235(best: 0.3264)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2650 | Time 16.4728(17.3819) | Bit/dim 3.7427(3.7853) | Xent 0.9736(0.9401) | Loss 285.2621(308.5801) | Error 0.3444(0.3346) Steps 0(0.00) | Grad Norm 259.9185(244.2011) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 17.7789(17.5288) | Bit/dim 3.7772(3.7845) | Xent 0.9194(0.9371) | Loss 280.7605(300.1553) | Error 0.3344(0.3344) Steps 0(0.00) | Grad Norm 266.2638(242.0854) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 17.3774(17.4795) | Bit/dim 3.7997(3.7850) | Xent 0.9725(0.9308) | Loss 277.6082(293.6572) | Error 0.3378(0.3320) Steps 0(0.00) | Grad Norm 176.0550(234.6851) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 18.1199(17.5803) | Bit/dim 3.7881(3.7859) | Xent 0.8512(0.9222) | Loss 275.8446(288.9933) | Error 0.3044(0.3294) Steps 0(0.00) | Grad Norm 227.1385(225.1793) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 16.6520(17.4709) | Bit/dim 3.7489(3.7838) | Xent 0.9952(0.9342) | Loss 281.1073(285.9095) | Error 0.3500(0.3350) Steps 0(0.00) | Grad Norm 426.6243(263.2765) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 89.8540, Epoch Time 1068.1164(996.9740), Bit/dim 3.7791(best: 3.7888), Xent 0.8883, Loss 4.2232, Error 0.3170(best: 0.3235)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2700 | Time 17.5407(17.5141) | Bit/dim 3.7865(3.7845) | Xent 1.0059(0.9364) | Loss 282.3854(317.5970) | Error 0.3667(0.3368) Steps 0(0.00) | Grad Norm 414.5181(273.8774) | Total Time 0.00(0.00)\n",
      "Iter 2710 | Time 18.4778(17.5104) | Bit/dim 3.7693(3.7846) | Xent 0.9408(0.9471) | Loss 279.4360(306.8517) | Error 0.3322(0.3388) Steps 0(0.00) | Grad Norm 353.8776(296.8673) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 18.0943(17.5910) | Bit/dim 3.7725(3.7861) | Xent 0.8858(0.9408) | Loss 279.4832(299.0019) | Error 0.3000(0.3346) Steps 0(0.00) | Grad Norm 206.5122(287.6998) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 16.4139(17.4012) | Bit/dim 3.7649(3.7825) | Xent 0.8732(0.9301) | Loss 273.9655(292.4086) | Error 0.3044(0.3307) Steps 0(0.00) | Grad Norm 214.1120(268.6450) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 17.0016(17.4226) | Bit/dim 3.7888(3.7800) | Xent 0.9606(0.9359) | Loss 275.4225(288.7218) | Error 0.3444(0.3331) Steps 0(0.00) | Grad Norm 122.4714(261.9294) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 16.6053(17.4060) | Bit/dim 3.8128(3.7807) | Xent 1.0283(0.9388) | Loss 267.5995(284.7921) | Error 0.3722(0.3339) Steps 0(0.00) | Grad Norm 365.5431(278.1336) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 88.4390, Epoch Time 1063.3111(998.9641), Bit/dim 3.7829(best: 3.7791), Xent 0.9048, Loss 4.2353, Error 0.3220(best: 0.3170)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2760 | Time 17.1053(17.4384) | Bit/dim 3.7735(3.7777) | Xent 0.8945(0.9336) | Loss 277.7414(310.3089) | Error 0.3278(0.3333) Steps 0(0.00) | Grad Norm 235.2525(272.3751) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 17.4120(17.5231) | Bit/dim 3.7756(3.7766) | Xent 0.9159(0.9312) | Loss 275.3042(299.8184) | Error 0.3244(0.3330) Steps 0(0.00) | Grad Norm 313.5349(258.4833) | Total Time 0.00(0.00)\n",
      "Iter 2780 | Time 17.2269(17.5407) | Bit/dim 3.7740(3.7764) | Xent 0.9016(0.9250) | Loss 269.1944(293.7581) | Error 0.3044(0.3297) Steps 0(0.00) | Grad Norm 205.5698(253.7652) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 17.3105(17.4015) | Bit/dim 3.7688(3.7769) | Xent 0.9072(0.9224) | Loss 283.3636(289.7626) | Error 0.3044(0.3283) Steps 0(0.00) | Grad Norm 228.2125(260.9234) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 17.0858(17.3891) | Bit/dim 3.7771(3.7769) | Xent 0.8831(0.9185) | Loss 266.7791(286.5782) | Error 0.3178(0.3279) Steps 0(0.00) | Grad Norm 353.9626(265.6790) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 88.2379, Epoch Time 1065.2150(1000.9516), Bit/dim 3.7776(best: 3.7791), Xent 0.8718, Loss 4.2135, Error 0.3111(best: 0.3170)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2810 | Time 16.5980(17.3037) | Bit/dim 3.7864(3.7788) | Xent 0.9411(0.9220) | Loss 281.7248(316.3302) | Error 0.3289(0.3290) Steps 0(0.00) | Grad Norm 186.9793(259.7564) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 16.2561(17.3054) | Bit/dim 3.7685(3.7790) | Xent 0.9033(0.9192) | Loss 272.0618(304.6017) | Error 0.3278(0.3275) Steps 0(0.00) | Grad Norm 354.1883(274.9042) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 16.2014(17.2506) | Bit/dim 3.7553(3.7786) | Xent 0.8689(0.9182) | Loss 269.2809(296.3555) | Error 0.3000(0.3263) Steps 0(0.00) | Grad Norm 247.1949(278.5475) | Total Time 0.00(0.00)\n",
      "Iter 2840 | Time 17.3085(17.2745) | Bit/dim 3.7563(3.7759) | Xent 0.8868(0.9076) | Loss 274.9509(290.4996) | Error 0.3189(0.3224) Steps 0(0.00) | Grad Norm 231.2697(254.6855) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 16.2624(17.2002) | Bit/dim 3.7656(3.7760) | Xent 0.9575(0.9032) | Loss 272.6139(285.8756) | Error 0.3356(0.3206) Steps 0(0.00) | Grad Norm 316.4133(254.3344) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 17.3964(17.3863) | Bit/dim 3.7912(3.7736) | Xent 0.9106(0.9113) | Loss 283.6644(283.3624) | Error 0.3422(0.3245) Steps 0(0.00) | Grad Norm 273.1672(266.1577) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 90.1404, Epoch Time 1061.7167(1002.7746), Bit/dim 3.7924(best: 3.7776), Xent 0.9530, Loss 4.2689, Error 0.3347(best: 0.3111)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2870 | Time 17.4872(17.3869) | Bit/dim 3.7675(3.7750) | Xent 0.9652(0.9206) | Loss 283.1792(310.9101) | Error 0.3267(0.3280) Steps 0(0.00) | Grad Norm 615.7835(300.2552) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 17.2819(17.3245) | Bit/dim 3.7499(3.7769) | Xent 0.8583(0.9162) | Loss 281.9701(301.6649) | Error 0.3033(0.3255) Steps 0(0.00) | Grad Norm 167.4299(277.0439) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 16.5170(17.3035) | Bit/dim 3.7454(3.7753) | Xent 0.8498(0.9042) | Loss 278.8039(294.9766) | Error 0.2911(0.3205) Steps 0(0.00) | Grad Norm 112.5922(240.6516) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 15.5425(17.3132) | Bit/dim 3.7607(3.7726) | Xent 0.9231(0.9017) | Loss 276.1886(289.6547) | Error 0.3333(0.3206) Steps 0(0.00) | Grad Norm 212.3001(240.6491) | Total Time 0.00(0.00)\n",
      "Iter 2910 | Time 16.1070(17.5305) | Bit/dim 3.7507(3.7702) | Xent 0.8989(0.8967) | Loss 277.7709(284.7558) | Error 0.3022(0.3179) Steps 0(0.00) | Grad Norm 174.3281(239.6469) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 87.3787, Epoch Time 1063.0969(1004.5843), Bit/dim 3.7649(best: 3.7776), Xent 0.8775, Loss 4.2036, Error 0.3149(best: 0.3111)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2920 | Time 19.4580(17.4355) | Bit/dim 3.7737(3.7708) | Xent 0.8880(0.8966) | Loss 277.5125(313.7080) | Error 0.3100(0.3192) Steps 0(0.00) | Grad Norm 253.6173(257.0006) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 16.8857(17.3687) | Bit/dim 3.7508(3.7694) | Xent 0.8348(0.8916) | Loss 271.3846(303.9025) | Error 0.2989(0.3180) Steps 0(0.00) | Grad Norm 233.7850(262.4380) | Total Time 0.00(0.00)\n",
      "Iter 2940 | Time 17.9352(17.3531) | Bit/dim 3.7652(3.7667) | Xent 0.8905(0.8791) | Loss 276.7071(295.8876) | Error 0.3111(0.3116) Steps 0(0.00) | Grad Norm 292.4225(251.5228) | Total Time 0.00(0.00)\n",
      "Iter 2950 | Time 16.7097(17.3062) | Bit/dim 3.7476(3.7654) | Xent 0.8682(0.8816) | Loss 257.3784(289.7143) | Error 0.3233(0.3127) Steps 0(0.00) | Grad Norm 208.3463(250.2208) | Total Time 0.00(0.00)\n",
      "Iter 2960 | Time 19.3416(17.4014) | Bit/dim 3.7395(3.7620) | Xent 0.8487(0.8830) | Loss 280.1440(285.3929) | Error 0.3067(0.3134) Steps 0(0.00) | Grad Norm 234.7867(257.3366) | Total Time 0.00(0.00)\n",
      "Iter 2970 | Time 18.9328(17.5371) | Bit/dim 3.7629(3.7628) | Xent 0.9325(0.8860) | Loss 281.0898(282.5567) | Error 0.3256(0.3149) Steps 0(0.00) | Grad Norm 399.2832(259.8603) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 88.6735, Epoch Time 1065.5032(1006.4118), Bit/dim 3.7628(best: 3.7649), Xent 0.8496, Loss 4.1876, Error 0.3045(best: 0.3111)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2980 | Time 15.8609(17.5579) | Bit/dim 3.7444(3.7639) | Xent 0.9262(0.8833) | Loss 271.9658(308.6030) | Error 0.3500(0.3138) Steps 0(0.00) | Grad Norm 304.5985(264.9838) | Total Time 0.00(0.00)\n",
      "Iter 2990 | Time 18.4014(17.6490) | Bit/dim 3.7562(3.7639) | Xent 0.8224(0.8743) | Loss 273.8330(298.8331) | Error 0.2878(0.3105) Steps 0(0.00) | Grad Norm 151.4782(260.5191) | Total Time 0.00(0.00)\n",
      "Iter 3000 | Time 16.6328(17.5584) | Bit/dim 3.8088(3.7668) | Xent 0.8899(0.8710) | Loss 269.3131(291.6406) | Error 0.3256(0.3087) Steps 0(0.00) | Grad Norm 305.1143(256.8044) | Total Time 0.00(0.00)\n",
      "Iter 3010 | Time 18.2825(17.4668) | Bit/dim 3.7584(3.7612) | Xent 0.8531(0.8720) | Loss 282.0309(287.4672) | Error 0.3056(0.3099) Steps 0(0.00) | Grad Norm 232.4363(242.7218) | Total Time 0.00(0.00)\n",
      "Iter 3020 | Time 19.0019(17.4098) | Bit/dim 3.7570(3.7594) | Xent 0.8876(0.8705) | Loss 279.1221(284.0933) | Error 0.3278(0.3095) Steps 0(0.00) | Grad Norm 297.5348(242.7251) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 90.1245, Epoch Time 1064.9881(1008.1691), Bit/dim 3.7566(best: 3.7628), Xent 0.8922, Loss 4.2027, Error 0.3181(best: 0.3045)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3030 | Time 18.0150(17.2970) | Bit/dim 3.7711(3.7588) | Xent 0.9714(0.8866) | Loss 285.1858(314.2288) | Error 0.3367(0.3153) Steps 0(0.00) | Grad Norm 365.3354(276.6088) | Total Time 0.00(0.00)\n",
      "Iter 3040 | Time 17.6490(17.2662) | Bit/dim 3.7730(3.7600) | Xent 0.8164(0.8827) | Loss 270.8871(303.7546) | Error 0.3078(0.3146) Steps 0(0.00) | Grad Norm 181.7467(275.3418) | Total Time 0.00(0.00)\n",
      "Iter 3050 | Time 17.8717(17.2760) | Bit/dim 3.7807(3.7590) | Xent 0.8150(0.8823) | Loss 271.0602(295.7997) | Error 0.3011(0.3161) Steps 0(0.00) | Grad Norm 449.6671(280.8791) | Total Time 0.00(0.00)\n",
      "Iter 3060 | Time 18.9741(17.4364) | Bit/dim 3.7704(3.7589) | Xent 0.8887(0.8767) | Loss 292.3573(290.5679) | Error 0.3244(0.3137) Steps 0(0.00) | Grad Norm 208.3438(265.7528) | Total Time 0.00(0.00)\n",
      "Iter 3070 | Time 16.7758(17.4133) | Bit/dim 3.7788(3.7557) | Xent 0.8778(0.8733) | Loss 269.2627(285.4938) | Error 0.3189(0.3126) Steps 0(0.00) | Grad Norm 236.2566(255.9845) | Total Time 0.00(0.00)\n",
      "Iter 3080 | Time 18.9898(17.5416) | Bit/dim 3.7605(3.7540) | Xent 0.8444(0.8687) | Loss 274.9890(282.0829) | Error 0.3089(0.3104) Steps 0(0.00) | Grad Norm 269.6871(244.3099) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 90.0469, Epoch Time 1067.6508(1009.9536), Bit/dim 3.7494(best: 3.7566), Xent 0.8428, Loss 4.1708, Error 0.2942(best: 0.3045)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3090 | Time 17.5821(17.6777) | Bit/dim 3.7556(3.7547) | Xent 0.9400(0.8669) | Loss 280.8841(308.2631) | Error 0.3333(0.3097) Steps 0(0.00) | Grad Norm 386.7026(247.6281) | Total Time 0.00(0.00)\n",
      "Iter 3100 | Time 18.1801(17.6085) | Bit/dim 3.7254(3.7538) | Xent 0.9365(0.8750) | Loss 269.3663(299.2224) | Error 0.3200(0.3116) Steps 0(0.00) | Grad Norm 298.1627(266.2609) | Total Time 0.00(0.00)\n",
      "Iter 3110 | Time 17.0070(17.5627) | Bit/dim 3.7871(3.7520) | Xent 0.8918(0.8654) | Loss 277.2563(292.6375) | Error 0.3100(0.3073) Steps 0(0.00) | Grad Norm 286.9705(259.3650) | Total Time 0.00(0.00)\n",
      "Iter 3120 | Time 16.1300(17.6016) | Bit/dim 3.7264(3.7521) | Xent 0.9594(0.8705) | Loss 273.1826(287.8716) | Error 0.3456(0.3094) Steps 0(0.00) | Grad Norm 254.1350(262.3598) | Total Time 0.00(0.00)\n",
      "Iter 3130 | Time 17.9500(17.4919) | Bit/dim 3.7518(3.7514) | Xent 0.7947(0.8677) | Loss 271.0032(283.4566) | Error 0.2711(0.3085) Steps 0(0.00) | Grad Norm 132.0447(254.5743) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 87.0390, Epoch Time 1071.9086(1011.8122), Bit/dim 3.7555(best: 3.7494), Xent 0.8499, Loss 4.1804, Error 0.2994(best: 0.2942)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3140 | Time 17.7989(17.5649) | Bit/dim 3.7407(3.7495) | Xent 0.8545(0.8596) | Loss 281.8570(311.7958) | Error 0.3156(0.3054) Steps 0(0.00) | Grad Norm 243.8460(247.3392) | Total Time 0.00(0.00)\n",
      "Iter 3150 | Time 16.8985(17.7208) | Bit/dim 3.7443(3.7469) | Xent 0.7936(0.8545) | Loss 264.8767(301.8690) | Error 0.2867(0.3041) Steps 0(0.00) | Grad Norm 239.4313(243.8954) | Total Time 0.00(0.00)\n",
      "Iter 3160 | Time 17.1674(17.6725) | Bit/dim 3.7831(3.7498) | Xent 0.8556(0.8498) | Loss 278.1159(294.4182) | Error 0.3167(0.3037) Steps 0(0.00) | Grad Norm 368.2569(250.5155) | Total Time 0.00(0.00)\n",
      "Iter 3170 | Time 19.5487(17.5604) | Bit/dim 3.7640(3.7520) | Xent 0.9406(0.8652) | Loss 279.9326(289.7697) | Error 0.3289(0.3088) Steps 0(0.00) | Grad Norm 329.7459(280.9950) | Total Time 0.00(0.00)\n",
      "Iter 3180 | Time 17.1437(17.6272) | Bit/dim 3.7488(3.7542) | Xent 0.8657(0.8638) | Loss 279.8351(286.2547) | Error 0.3078(0.3066) Steps 0(0.00) | Grad Norm 152.6151(266.0269) | Total Time 0.00(0.00)\n",
      "Iter 3190 | Time 16.4386(17.5251) | Bit/dim 3.7606(3.7530) | Xent 0.8126(0.8592) | Loss 276.7232(282.1737) | Error 0.2878(0.3054) Steps 0(0.00) | Grad Norm 151.6159(247.6503) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 88.7561, Epoch Time 1075.4566(1013.7216), Bit/dim 3.7458(best: 3.7494), Xent 0.8503, Loss 4.1709, Error 0.3003(best: 0.2942)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3200 | Time 17.3864(17.4399) | Bit/dim 3.7448(3.7516) | Xent 0.8414(0.8517) | Loss 267.2554(308.0159) | Error 0.3122(0.3035) Steps 0(0.00) | Grad Norm 189.5426(238.0381) | Total Time 0.00(0.00)\n",
      "Iter 3210 | Time 18.4464(17.5855) | Bit/dim 3.7356(3.7471) | Xent 0.8016(0.8456) | Loss 273.5238(298.7430) | Error 0.2944(0.3011) Steps 0(0.00) | Grad Norm 189.0129(245.3538) | Total Time 0.00(0.00)\n",
      "Iter 3220 | Time 19.4823(17.7931) | Bit/dim 3.7600(3.7467) | Xent 0.8490(0.8432) | Loss 269.5057(292.1836) | Error 0.3089(0.2997) Steps 0(0.00) | Grad Norm 311.5583(241.9387) | Total Time 0.00(0.00)\n",
      "Iter 3230 | Time 18.8929(17.7601) | Bit/dim 3.7619(3.7481) | Xent 0.8646(0.8537) | Loss 279.1409(287.2346) | Error 0.2978(0.3025) Steps 0(0.00) | Grad Norm 274.7876(255.8595) | Total Time 0.00(0.00)\n",
      "Iter 3240 | Time 17.3565(17.7605) | Bit/dim 3.7465(3.7484) | Xent 0.8900(0.8553) | Loss 278.3039(283.7296) | Error 0.3111(0.3026) Steps 0(0.00) | Grad Norm 188.6558(248.7750) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 91.2085, Epoch Time 1086.5137(1015.9053), Bit/dim 3.7524(best: 3.7458), Xent 0.8526, Loss 4.1787, Error 0.3036(best: 0.2942)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3250 | Time 16.2456(17.6577) | Bit/dim 3.7652(3.7484) | Xent 0.7970(0.8504) | Loss 265.6928(312.5081) | Error 0.2878(0.3021) Steps 0(0.00) | Grad Norm 259.1648(253.6392) | Total Time 0.00(0.00)\n",
      "Iter 3260 | Time 16.8572(17.6633) | Bit/dim 3.7310(3.7471) | Xent 0.8221(0.8440) | Loss 260.4530(301.2337) | Error 0.2811(0.2990) Steps 0(0.00) | Grad Norm 302.8515(254.6841) | Total Time 0.00(0.00)\n",
      "Iter 3270 | Time 17.4829(17.7043) | Bit/dim 3.7312(3.7455) | Xent 0.8577(0.8442) | Loss 270.7409(294.2362) | Error 0.2911(0.2994) Steps 0(0.00) | Grad Norm 175.1954(256.8727) | Total Time 0.00(0.00)\n",
      "Iter 3280 | Time 18.3177(17.7644) | Bit/dim 3.7620(3.7484) | Xent 0.7660(0.8334) | Loss 269.2209(289.1450) | Error 0.2500(0.2961) Steps 0(0.00) | Grad Norm 215.1752(246.3070) | Total Time 0.00(0.00)\n",
      "Iter 3290 | Time 17.1752(17.6524) | Bit/dim 3.7188(3.7423) | Xent 0.8729(0.8424) | Loss 273.6935(284.7094) | Error 0.3144(0.2986) Steps 0(0.00) | Grad Norm 333.4687(257.4933) | Total Time 0.00(0.00)\n",
      "Iter 3300 | Time 17.1105(17.6076) | Bit/dim 3.7664(3.7454) | Xent 0.8136(0.8423) | Loss 272.5816(281.5131) | Error 0.3100(0.2993) Steps 0(0.00) | Grad Norm 183.1188(247.5674) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 89.9540, Epoch Time 1078.0961(1017.7710), Bit/dim 3.7379(best: 3.7458), Xent 0.8371, Loss 4.1565, Error 0.2975(best: 0.2942)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3310 | Time 16.6370(17.7230) | Bit/dim 3.7122(3.7428) | Xent 0.8407(0.8381) | Loss 265.7635(307.6942) | Error 0.2833(0.2986) Steps 0(0.00) | Grad Norm 174.4221(250.0652) | Total Time 0.00(0.00)\n",
      "Iter 3320 | Time 17.2425(17.7644) | Bit/dim 3.7476(3.7404) | Xent 0.7955(0.8286) | Loss 267.5889(298.1737) | Error 0.2878(0.2955) Steps 0(0.00) | Grad Norm 278.5471(245.6402) | Total Time 0.00(0.00)\n",
      "Iter 3330 | Time 16.6931(17.5766) | Bit/dim 3.7166(3.7363) | Xent 0.7620(0.8301) | Loss 279.0518(290.9602) | Error 0.2689(0.2961) Steps 0(0.00) | Grad Norm 257.9580(251.5583) | Total Time 0.00(0.00)\n",
      "Iter 3340 | Time 16.7860(17.6847) | Bit/dim 3.7547(3.7378) | Xent 0.8002(0.8317) | Loss 272.0993(285.9926) | Error 0.2800(0.2960) Steps 0(0.00) | Grad Norm 198.3025(245.4983) | Total Time 0.00(0.00)\n",
      "Iter 3350 | Time 17.8250(17.5825) | Bit/dim 3.7095(3.7419) | Xent 0.8581(0.8401) | Loss 270.5429(282.2604) | Error 0.2822(0.2993) Steps 0(0.00) | Grad Norm 176.9069(257.3695) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 91.1863, Epoch Time 1076.2630(1019.5258), Bit/dim 3.7393(best: 3.7379), Xent 0.8311, Loss 4.1548, Error 0.2968(best: 0.2942)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3360 | Time 16.2682(17.4880) | Bit/dim 3.7558(3.7397) | Xent 0.8217(0.8348) | Loss 273.2439(312.0626) | Error 0.2867(0.2955) Steps 0(0.00) | Grad Norm 217.9631(247.4000) | Total Time 0.00(0.00)\n",
      "Iter 3370 | Time 15.5963(17.4759) | Bit/dim 3.7377(3.7375) | Xent 0.8000(0.8219) | Loss 267.0127(301.2654) | Error 0.2911(0.2920) Steps 0(0.00) | Grad Norm 201.9135(232.3008) | Total Time 0.00(0.00)\n",
      "Iter 3380 | Time 17.2183(17.6935) | Bit/dim 3.7129(3.7324) | Xent 0.8358(0.8187) | Loss 264.7108(294.2186) | Error 0.3067(0.2929) Steps 0(0.00) | Grad Norm 354.7542(237.8514) | Total Time 0.00(0.00)\n",
      "Iter 3390 | Time 17.7867(17.5791) | Bit/dim 3.7545(3.7344) | Xent 0.8312(0.8213) | Loss 281.5367(288.6039) | Error 0.2944(0.2935) Steps 0(0.00) | Grad Norm 203.1559(238.0868) | Total Time 0.00(0.00)\n",
      "Iter 3400 | Time 17.3833(17.5308) | Bit/dim 3.7368(3.7367) | Xent 0.7909(0.8190) | Loss 267.2050(283.0739) | Error 0.2822(0.2929) Steps 0(0.00) | Grad Norm 231.2881(237.5075) | Total Time 0.00(0.00)\n",
      "Iter 3410 | Time 18.0958(17.3784) | Bit/dim 3.7314(3.7385) | Xent 0.8379(0.8154) | Loss 270.3132(279.6412) | Error 0.2900(0.2918) Steps 0(0.00) | Grad Norm 226.4147(231.0493) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 91.4850, Epoch Time 1070.6203(1021.0586), Bit/dim 3.7372(best: 3.7379), Xent 0.8118, Loss 4.1431, Error 0.2865(best: 0.2942)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3420 | Time 17.6614(17.4373) | Bit/dim 3.7431(3.7357) | Xent 0.8159(0.8123) | Loss 278.1295(306.6764) | Error 0.3044(0.2925) Steps 0(0.00) | Grad Norm 252.4885(233.7138) | Total Time 0.00(0.00)\n",
      "Iter 3430 | Time 15.4396(17.2499) | Bit/dim 3.7013(3.7357) | Xent 0.7839(0.8054) | Loss 268.5825(297.4591) | Error 0.2667(0.2891) Steps 0(0.00) | Grad Norm 175.2296(235.2004) | Total Time 0.00(0.00)\n",
      "Iter 3440 | Time 17.5458(17.2874) | Bit/dim 3.7457(3.7345) | Xent 0.8190(0.8055) | Loss 265.1070(289.6101) | Error 0.3078(0.2889) Steps 0(0.00) | Grad Norm 195.6602(233.2633) | Total Time 0.00(0.00)\n",
      "Iter 3450 | Time 16.3819(17.4076) | Bit/dim 3.7297(3.7325) | Xent 0.7548(0.8016) | Loss 270.2664(284.0764) | Error 0.2611(0.2861) Steps 0(0.00) | Grad Norm 223.7630(231.1634) | Total Time 0.00(0.00)\n",
      "Iter 3460 | Time 19.6585(17.5500) | Bit/dim 3.7538(3.7331) | Xent 0.8047(0.8054) | Loss 276.4590(280.8445) | Error 0.2789(0.2873) Steps 0(0.00) | Grad Norm 184.9111(229.1390) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 91.8894, Epoch Time 1072.1372(1022.5910), Bit/dim 3.7314(best: 3.7372), Xent 0.8091, Loss 4.1360, Error 0.2874(best: 0.2865)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3470 | Time 18.3207(17.5176) | Bit/dim 3.7212(3.7318) | Xent 0.7945(0.7985) | Loss 273.0116(310.8130) | Error 0.2844(0.2869) Steps 0(0.00) | Grad Norm 284.5774(230.6343) | Total Time 0.00(0.00)\n",
      "Iter 3480 | Time 17.6895(17.4785) | Bit/dim 3.6747(3.7314) | Xent 0.9186(0.8008) | Loss 266.7612(300.9286) | Error 0.3211(0.2878) Steps 0(0.00) | Grad Norm 391.2654(228.8664) | Total Time 0.00(0.00)\n",
      "Iter 3490 | Time 17.0322(17.5123) | Bit/dim 3.7391(3.7293) | Xent 0.7753(0.8090) | Loss 267.7921(292.4490) | Error 0.2722(0.2892) Steps 0(0.00) | Grad Norm 211.1483(250.0129) | Total Time 0.00(0.00)\n",
      "Iter 3500 | Time 16.9133(17.5881) | Bit/dim 3.6968(3.7293) | Xent 0.8645(0.8068) | Loss 272.1021(287.2896) | Error 0.3078(0.2888) Steps 0(0.00) | Grad Norm 251.9969(243.2159) | Total Time 0.00(0.00)\n",
      "Iter 3510 | Time 17.6397(17.6627) | Bit/dim 3.7555(3.7292) | Xent 0.7824(0.8066) | Loss 258.0857(283.2773) | Error 0.2911(0.2886) Steps 0(0.00) | Grad Norm 261.9131(238.6518) | Total Time 0.00(0.00)\n",
      "Iter 3520 | Time 17.7782(17.5547) | Bit/dim 3.7250(3.7298) | Xent 0.8317(0.8060) | Loss 269.5321(280.8974) | Error 0.2822(0.2879) Steps 0(0.00) | Grad Norm 215.0592(233.6864) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 90.7161, Epoch Time 1075.3679(1024.1743), Bit/dim 3.7286(best: 3.7314), Xent 0.8118, Loss 4.1344, Error 0.2919(best: 0.2865)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3530 | Time 17.2824(17.5300) | Bit/dim 3.7538(3.7273) | Xent 0.7775(0.8013) | Loss 273.1457(307.5082) | Error 0.2656(0.2855) Steps 0(0.00) | Grad Norm 170.1668(228.8503) | Total Time 0.00(0.00)\n",
      "Iter 3540 | Time 17.5030(17.5767) | Bit/dim 3.7623(3.7314) | Xent 0.8279(0.7906) | Loss 266.1563(298.2206) | Error 0.3000(0.2814) Steps 0(0.00) | Grad Norm 236.6119(226.0911) | Total Time 0.00(0.00)\n",
      "Iter 3550 | Time 16.2641(17.5591) | Bit/dim 3.7479(3.7288) | Xent 0.7796(0.7990) | Loss 268.1609(291.1136) | Error 0.2856(0.2858) Steps 0(0.00) | Grad Norm 318.8119(241.5079) | Total Time 0.00(0.00)\n",
      "Iter 3560 | Time 16.2736(17.5200) | Bit/dim 3.7084(3.7257) | Xent 0.8316(0.8040) | Loss 269.2135(285.7459) | Error 0.3111(0.2862) Steps 0(0.00) | Grad Norm 278.2514(239.7051) | Total Time 0.00(0.00)\n",
      "Iter 3570 | Time 18.8225(17.6128) | Bit/dim 3.7175(3.7236) | Xent 0.8125(0.8126) | Loss 280.0867(282.2853) | Error 0.2822(0.2893) Steps 0(0.00) | Grad Norm 197.3231(255.4966) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 90.0717, Epoch Time 1074.5278(1025.6849), Bit/dim 3.7250(best: 3.7286), Xent 0.8770, Loss 4.1635, Error 0.3118(best: 0.2865)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3580 | Time 16.8801(17.4421) | Bit/dim 3.7144(3.7232) | Xent 0.7584(0.8108) | Loss 266.9463(310.5516) | Error 0.2856(0.2901) Steps 0(0.00) | Grad Norm 164.1231(243.9820) | Total Time 0.00(0.00)\n",
      "Iter 3590 | Time 17.7462(17.3214) | Bit/dim 3.7376(3.7224) | Xent 0.7087(0.8003) | Loss 273.7680(300.0250) | Error 0.2522(0.2864) Steps 0(0.00) | Grad Norm 121.6125(227.2269) | Total Time 0.00(0.00)\n",
      "Iter 3600 | Time 21.8611(17.4969) | Bit/dim 3.7120(3.7215) | Xent 0.7860(0.7897) | Loss 276.5202(292.9157) | Error 0.2822(0.2834) Steps 0(0.00) | Grad Norm 298.7827(218.4029) | Total Time 0.00(0.00)\n",
      "Iter 3610 | Time 17.2346(17.5203) | Bit/dim 3.7560(3.7207) | Xent 0.7719(0.7893) | Loss 274.4073(287.7130) | Error 0.2744(0.2824) Steps 0(0.00) | Grad Norm 278.1214(225.5536) | Total Time 0.00(0.00)\n",
      "Iter 3620 | Time 17.5538(17.4138) | Bit/dim 3.7271(3.7221) | Xent 0.7912(0.7853) | Loss 272.9867(283.5428) | Error 0.2878(0.2813) Steps 0(0.00) | Grad Norm 156.5487(221.0290) | Total Time 0.00(0.00)\n",
      "Iter 3630 | Time 17.1443(17.2479) | Bit/dim 3.7416(3.7235) | Xent 0.7798(0.7868) | Loss 267.9898(279.8870) | Error 0.2611(0.2805) Steps 0(0.00) | Grad Norm 158.2883(218.4226) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 90.8570, Epoch Time 1055.8728(1026.5905), Bit/dim 3.7237(best: 3.7250), Xent 0.7755, Loss 4.1114, Error 0.2745(best: 0.2865)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3640 | Time 17.3627(17.2519) | Bit/dim 3.7676(3.7257) | Xent 0.8059(0.7865) | Loss 272.6735(305.0191) | Error 0.2811(0.2804) Steps 0(0.00) | Grad Norm 259.7426(239.2967) | Total Time 0.00(0.00)\n",
      "Iter 3650 | Time 17.5141(17.3792) | Bit/dim 3.7134(3.7218) | Xent 0.8065(0.7885) | Loss 277.9433(296.3500) | Error 0.3011(0.2816) Steps 0(0.00) | Grad Norm 167.4018(252.7664) | Total Time 0.00(0.00)\n",
      "Iter 3660 | Time 18.6233(17.3306) | Bit/dim 3.7200(3.7256) | Xent 0.7990(0.7882) | Loss 278.9801(289.2233) | Error 0.2811(0.2810) Steps 0(0.00) | Grad Norm 225.5943(248.0214) | Total Time 0.00(0.00)\n",
      "Iter 3670 | Time 15.7160(17.2894) | Bit/dim 3.7007(3.7262) | Xent 0.7841(0.7869) | Loss 271.2766(284.5306) | Error 0.2922(0.2813) Steps 0(0.00) | Grad Norm 193.8476(239.8796) | Total Time 0.00(0.00)\n",
      "Iter 3680 | Time 18.7845(17.3360) | Bit/dim 3.7077(3.7213) | Xent 0.7849(0.7834) | Loss 269.4964(281.3140) | Error 0.2767(0.2796) Steps 0(0.00) | Grad Norm 242.1207(231.6714) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 92.4512, Epoch Time 1067.4110(1027.8152), Bit/dim 3.7185(best: 3.7237), Xent 0.7959, Loss 4.1165, Error 0.2817(best: 0.2745)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3690 | Time 16.6973(17.4367) | Bit/dim 3.7419(3.7231) | Xent 0.7391(0.7788) | Loss 270.8616(310.7526) | Error 0.2456(0.2785) Steps 0(0.00) | Grad Norm 218.2953(234.3094) | Total Time 0.00(0.00)\n",
      "Iter 3700 | Time 16.5333(17.3519) | Bit/dim 3.7132(3.7222) | Xent 0.7436(0.7703) | Loss 275.8156(300.0755) | Error 0.2633(0.2756) Steps 0(0.00) | Grad Norm 263.5309(229.2424) | Total Time 0.00(0.00)\n",
      "Iter 3710 | Time 15.9358(17.2748) | Bit/dim 3.7142(3.7196) | Xent 0.7372(0.7740) | Loss 255.0104(291.8655) | Error 0.2600(0.2771) Steps 0(0.00) | Grad Norm 125.3292(227.0156) | Total Time 0.00(0.00)\n",
      "Iter 3720 | Time 20.4607(17.4287) | Bit/dim 3.7463(3.7184) | Xent 0.7755(0.7720) | Loss 273.9347(286.4575) | Error 0.2878(0.2776) Steps 0(0.00) | Grad Norm 171.5268(219.1067) | Total Time 0.00(0.00)\n",
      "Iter 3730 | Time 17.0818(17.4334) | Bit/dim 3.6878(3.7176) | Xent 0.8178(0.7715) | Loss 270.4015(282.7316) | Error 0.3056(0.2776) Steps 0(0.00) | Grad Norm 219.3444(225.3519) | Total Time 0.00(0.00)\n",
      "Iter 3740 | Time 17.6400(17.3870) | Bit/dim 3.7132(3.7181) | Xent 0.7850(0.7694) | Loss 278.2381(279.6698) | Error 0.2656(0.2760) Steps 0(0.00) | Grad Norm 361.9789(224.5494) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 90.4381, Epoch Time 1063.4944(1028.8855), Bit/dim 3.7220(best: 3.7185), Xent 0.7993, Loss 4.1217, Error 0.2864(best: 0.2745)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3750 | Time 17.6729(17.3361) | Bit/dim 3.7327(3.7161) | Xent 0.6863(0.7671) | Loss 276.1226(305.4211) | Error 0.2411(0.2746) Steps 0(0.00) | Grad Norm 183.1990(224.4906) | Total Time 0.00(0.00)\n",
      "Iter 3760 | Time 17.3483(17.4415) | Bit/dim 3.7246(3.7144) | Xent 0.7709(0.7760) | Loss 285.2292(296.4621) | Error 0.2767(0.2769) Steps 0(0.00) | Grad Norm 436.0536(256.1277) | Total Time 0.00(0.00)\n",
      "Iter 3770 | Time 18.0246(17.3586) | Bit/dim 3.7364(3.7129) | Xent 0.7752(0.7794) | Loss 276.9752(289.1761) | Error 0.2711(0.2775) Steps 0(0.00) | Grad Norm 101.6706(251.8032) | Total Time 0.00(0.00)\n",
      "Iter 3780 | Time 17.7411(17.4216) | Bit/dim 3.7502(3.7177) | Xent 0.7172(0.7807) | Loss 271.7709(284.5906) | Error 0.2511(0.2778) Steps 0(0.00) | Grad Norm 292.7423(254.9019) | Total Time 0.00(0.00)\n",
      "Iter 3790 | Time 18.3437(17.4592) | Bit/dim 3.7156(3.7183) | Xent 0.8431(0.7805) | Loss 285.7760(281.3534) | Error 0.2900(0.2780) Steps 0(0.00) | Grad Norm 157.5464(242.3495) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 91.9644, Epoch Time 1072.6119(1030.1973), Bit/dim 3.7155(best: 3.7185), Xent 0.7871, Loss 4.1090, Error 0.2807(best: 0.2745)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3800 | Time 17.8693(17.5767) | Bit/dim 3.7207(3.7186) | Xent 0.7331(0.7767) | Loss 271.6978(312.1179) | Error 0.2644(0.2758) Steps 0(0.00) | Grad Norm 231.5882(229.4734) | Total Time 0.00(0.00)\n",
      "Iter 3810 | Time 16.5542(17.5558) | Bit/dim 3.7219(3.7175) | Xent 0.7553(0.7748) | Loss 259.6050(300.4585) | Error 0.2733(0.2749) Steps 0(0.00) | Grad Norm 219.1432(244.3428) | Total Time 0.00(0.00)\n",
      "Iter 3820 | Time 17.6772(17.6625) | Bit/dim 3.7349(3.7201) | Xent 0.7763(0.7859) | Loss 272.7117(293.8272) | Error 0.2733(0.2787) Steps 0(0.00) | Grad Norm 176.2866(254.6264) | Total Time 0.00(0.00)\n",
      "Iter 3830 | Time 15.5559(17.5658) | Bit/dim 3.7297(3.7220) | Xent 0.7881(0.7852) | Loss 264.4987(288.0538) | Error 0.2711(0.2790) Steps 0(0.00) | Grad Norm 177.6105(236.7695) | Total Time 0.00(0.00)\n",
      "Iter 3840 | Time 16.6122(17.4338) | Bit/dim 3.6931(3.7168) | Xent 0.8181(0.7834) | Loss 278.1482(283.7463) | Error 0.2911(0.2788) Steps 0(0.00) | Grad Norm 189.6928(230.8003) | Total Time 0.00(0.00)\n",
      "Iter 3850 | Time 16.9965(17.4028) | Bit/dim 3.7039(3.7137) | Xent 0.6947(0.7763) | Loss 257.8230(279.2305) | Error 0.2400(0.2768) Steps 0(0.00) | Grad Norm 233.1760(231.6610) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 91.4875, Epoch Time 1069.7270(1031.3832), Bit/dim 3.7165(best: 3.7155), Xent 0.7803, Loss 4.1067, Error 0.2767(best: 0.2745)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3860 | Time 17.8592(17.3930) | Bit/dim 3.7550(3.7164) | Xent 0.7519(0.7761) | Loss 265.8752(305.5420) | Error 0.2544(0.2766) Steps 0(0.00) | Grad Norm 186.5021(242.3467) | Total Time 0.00(0.00)\n",
      "Iter 3870 | Time 17.5301(17.4299) | Bit/dim 3.7249(3.7168) | Xent 0.7710(0.7658) | Loss 271.7208(295.9798) | Error 0.2822(0.2739) Steps 0(0.00) | Grad Norm 191.4015(227.8843) | Total Time 0.00(0.00)\n",
      "Iter 3880 | Time 16.4432(17.4615) | Bit/dim 3.6925(3.7115) | Xent 0.7060(0.7597) | Loss 264.8408(289.4453) | Error 0.2456(0.2722) Steps 0(0.00) | Grad Norm 173.1252(216.6123) | Total Time 0.00(0.00)\n",
      "Iter 3890 | Time 17.2784(17.3843) | Bit/dim 3.6955(3.7131) | Xent 0.7370(0.7541) | Loss 267.8645(284.1493) | Error 0.2667(0.2696) Steps 0(0.00) | Grad Norm 214.9745(214.2550) | Total Time 0.00(0.00)\n",
      "Iter 3900 | Time 16.5777(17.4041) | Bit/dim 3.7046(3.7103) | Xent 0.7694(0.7541) | Loss 269.0795(281.1104) | Error 0.2844(0.2697) Steps 0(0.00) | Grad Norm 236.3333(218.8987) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 92.1206, Epoch Time 1064.4689(1032.3758), Bit/dim 3.7136(best: 3.7155), Xent 0.7788, Loss 4.1030, Error 0.2723(best: 0.2745)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3910 | Time 17.3754(17.3596) | Bit/dim 3.7064(3.7089) | Xent 0.7497(0.7511) | Loss 266.8080(311.1236) | Error 0.2544(0.2683) Steps 0(0.00) | Grad Norm 170.8301(207.8614) | Total Time 0.00(0.00)\n",
      "Iter 3920 | Time 17.4228(17.4936) | Bit/dim 3.7274(3.7048) | Xent 0.7591(0.7441) | Loss 270.4468(299.2468) | Error 0.2556(0.2651) Steps 0(0.00) | Grad Norm 173.6851(200.2065) | Total Time 0.00(0.00)\n",
      "Iter 3930 | Time 18.2134(17.4416) | Bit/dim 3.7133(3.7054) | Xent 0.7005(0.7445) | Loss 266.4828(291.0912) | Error 0.2467(0.2650) Steps 0(0.00) | Grad Norm 195.7155(220.4505) | Total Time 0.00(0.00)\n",
      "Iter 3940 | Time 18.0295(17.4167) | Bit/dim 3.6821(3.7012) | Xent 0.8019(0.7533) | Loss 264.7480(284.8461) | Error 0.2956(0.2691) Steps 0(0.00) | Grad Norm 220.4345(219.1730) | Total Time 0.00(0.00)\n",
      "Iter 3950 | Time 16.7103(17.3254) | Bit/dim 3.7496(3.7061) | Xent 0.7442(0.7486) | Loss 274.1839(279.6904) | Error 0.2733(0.2673) Steps 0(0.00) | Grad Norm 324.3734(215.8739) | Total Time 0.00(0.00)\n",
      "Iter 3960 | Time 15.8406(17.3908) | Bit/dim 3.7284(3.7078) | Xent 0.7501(0.7474) | Loss 270.7216(277.8915) | Error 0.2678(0.2659) Steps 0(0.00) | Grad Norm 158.6301(205.6366) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 90.5214, Epoch Time 1067.9902(1033.4442), Bit/dim 3.7080(best: 3.7136), Xent 0.7509, Loss 4.0835, Error 0.2692(best: 0.2723)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3970 | Time 17.7425(17.3038) | Bit/dim 3.7307(3.7107) | Xent 0.8066(0.7531) | Loss 277.8208(304.7404) | Error 0.3022(0.2676) Steps 0(0.00) | Grad Norm 390.9802(239.7061) | Total Time 0.00(0.00)\n",
      "Iter 3980 | Time 15.4086(17.2776) | Bit/dim 3.7406(3.7142) | Xent 0.6857(0.7591) | Loss 251.6263(295.1666) | Error 0.2567(0.2711) Steps 0(0.00) | Grad Norm 126.2075(240.1345) | Total Time 0.00(0.00)\n",
      "Iter 3990 | Time 19.2887(17.3571) | Bit/dim 3.7166(3.7127) | Xent 0.7410(0.7556) | Loss 267.0101(288.4858) | Error 0.2700(0.2701) Steps 0(0.00) | Grad Norm 137.7679(234.0358) | Total Time 0.00(0.00)\n",
      "Iter 4000 | Time 18.0537(17.5055) | Bit/dim 3.7043(3.7101) | Xent 0.7233(0.7521) | Loss 278.9692(283.4667) | Error 0.2633(0.2698) Steps 0(0.00) | Grad Norm 216.2748(234.3525) | Total Time 0.00(0.00)\n",
      "Iter 4010 | Time 18.2758(17.5236) | Bit/dim 3.7205(3.7079) | Xent 0.8258(0.7459) | Loss 282.3773(279.3210) | Error 0.3100(0.2679) Steps 0(0.00) | Grad Norm 150.2072(213.5704) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 92.3196, Epoch Time 1072.1199(1034.6045), Bit/dim 3.7001(best: 3.7080), Xent 0.7780, Loss 4.0891, Error 0.2733(best: 0.2692)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4020 | Time 16.9218(17.4352) | Bit/dim 3.7064(3.7052) | Xent 0.7024(0.7378) | Loss 274.0729(309.5384) | Error 0.2533(0.2646) Steps 0(0.00) | Grad Norm 208.9341(206.2356) | Total Time 0.00(0.00)\n",
      "Iter 4030 | Time 18.3773(17.4231) | Bit/dim 3.7338(3.7057) | Xent 0.7127(0.7332) | Loss 279.6252(299.8702) | Error 0.2500(0.2622) Steps 0(0.00) | Grad Norm 227.8845(209.3732) | Total Time 0.00(0.00)\n",
      "Iter 4040 | Time 17.8977(17.4598) | Bit/dim 3.7187(3.7029) | Xent 0.7557(0.7339) | Loss 273.2487(291.5878) | Error 0.2633(0.2621) Steps 0(0.00) | Grad Norm 283.3044(218.5106) | Total Time 0.00(0.00)\n",
      "Iter 4050 | Time 17.0684(17.4966) | Bit/dim 3.6741(3.7035) | Xent 0.7641(0.7351) | Loss 264.2761(285.3847) | Error 0.2644(0.2621) Steps 0(0.00) | Grad Norm 289.3550(218.7890) | Total Time 0.00(0.00)\n",
      "Iter 4060 | Time 16.2055(17.5946) | Bit/dim 3.6992(3.7025) | Xent 0.6823(0.7356) | Loss 265.3749(281.7036) | Error 0.2522(0.2630) Steps 0(0.00) | Grad Norm 120.3045(214.3347) | Total Time 0.00(0.00)\n",
      "Iter 4070 | Time 20.0648(17.7247) | Bit/dim 3.7064(3.7020) | Xent 0.6930(0.7289) | Loss 276.0702(278.5477) | Error 0.2389(0.2603) Steps 0(0.00) | Grad Norm 141.3499(208.5875) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 92.7755, Epoch Time 1079.3738(1035.9476), Bit/dim 3.7029(best: 3.7001), Xent 0.7505, Loss 4.0781, Error 0.2692(best: 0.2692)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4080 | Time 15.8338(17.8214) | Bit/dim 3.6780(3.7005) | Xent 0.7006(0.7233) | Loss 252.7569(304.4241) | Error 0.2433(0.2577) Steps 0(0.00) | Grad Norm 209.9767(200.7950) | Total Time 0.00(0.00)\n",
      "Iter 4090 | Time 17.6190(17.8203) | Bit/dim 3.6771(3.7004) | Xent 0.7566(0.7245) | Loss 271.3883(295.0534) | Error 0.2733(0.2592) Steps 0(0.00) | Grad Norm 354.5110(215.9004) | Total Time 0.00(0.00)\n",
      "Iter 4100 | Time 16.7509(17.9271) | Bit/dim 3.7331(3.7055) | Xent 0.7145(0.7314) | Loss 261.7856(288.5874) | Error 0.2578(0.2608) Steps 0(0.00) | Grad Norm 299.3874(251.7777) | Total Time 0.00(0.00)\n",
      "Iter 4110 | Time 18.0304(17.9735) | Bit/dim 3.7151(3.7064) | Xent 0.7643(0.7348) | Loss 267.9046(283.7622) | Error 0.2789(0.2614) Steps 0(0.00) | Grad Norm 241.7710(246.2471) | Total Time 0.00(0.00)\n",
      "Iter 4120 | Time 16.6074(17.8989) | Bit/dim 3.6857(3.7075) | Xent 0.6841(0.7396) | Loss 257.0285(279.5070) | Error 0.2611(0.2637) Steps 0(0.00) | Grad Norm 265.8637(248.2315) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 93.1011, Epoch Time 1102.4989(1037.9441), Bit/dim 3.7005(best: 3.7001), Xent 0.7595, Loss 4.0802, Error 0.2677(best: 0.2692)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4130 | Time 19.1753(18.1423) | Bit/dim 3.7262(3.7088) | Xent 0.7542(0.7389) | Loss 279.7728(310.9051) | Error 0.2633(0.2632) Steps 0(0.00) | Grad Norm 217.5012(237.8160) | Total Time 0.00(0.00)\n",
      "Iter 4140 | Time 19.5729(18.0125) | Bit/dim 3.6836(3.7078) | Xent 0.6877(0.7343) | Loss 271.8666(298.9095) | Error 0.2478(0.2626) Steps 0(0.00) | Grad Norm 125.5606(230.1396) | Total Time 0.00(0.00)\n",
      "Iter 4150 | Time 17.0391(17.8438) | Bit/dim 3.7251(3.7076) | Xent 0.6957(0.7300) | Loss 266.6397(291.5328) | Error 0.2400(0.2609) Steps 0(0.00) | Grad Norm 216.3942(223.4544) | Total Time 0.00(0.00)\n",
      "Iter 4160 | Time 16.9343(17.6701) | Bit/dim 3.7117(3.7053) | Xent 0.7752(0.7293) | Loss 270.4873(285.7312) | Error 0.2567(0.2595) Steps 0(0.00) | Grad Norm 239.9383(223.2184) | Total Time 0.00(0.00)\n",
      "Iter 4170 | Time 18.2972(17.5853) | Bit/dim 3.7029(3.7034) | Xent 0.8189(0.7315) | Loss 277.2741(281.6237) | Error 0.2900(0.2604) Steps 0(0.00) | Grad Norm 358.2361(224.8847) | Total Time 0.00(0.00)\n",
      "Iter 4180 | Time 17.1551(17.4930) | Bit/dim 3.6771(3.6978) | Xent 0.7180(0.7306) | Loss 257.8466(277.5021) | Error 0.2589(0.2602) Steps 0(0.00) | Grad Norm 296.3818(232.4115) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 94.6210, Epoch Time 1075.0498(1039.0573), Bit/dim 3.6950(best: 3.7001), Xent 0.7695, Loss 4.0797, Error 0.2718(best: 0.2677)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4190 | Time 17.2203(17.5296) | Bit/dim 3.6844(3.6953) | Xent 0.7285(0.7291) | Loss 258.6750(302.7272) | Error 0.2589(0.2596) Steps 0(0.00) | Grad Norm 161.9507(232.4482) | Total Time 0.00(0.00)\n",
      "Iter 4200 | Time 17.2401(17.4499) | Bit/dim 3.6796(3.6945) | Xent 0.7335(0.7261) | Loss 271.5959(293.7474) | Error 0.2622(0.2583) Steps 0(0.00) | Grad Norm 202.4582(230.2152) | Total Time 0.00(0.00)\n",
      "Iter 4210 | Time 18.2177(17.4734) | Bit/dim 3.6881(3.6947) | Xent 0.6867(0.7311) | Loss 271.5287(287.8384) | Error 0.2500(0.2615) Steps 0(0.00) | Grad Norm 164.2734(225.2655) | Total Time 0.00(0.00)\n",
      "Iter 4220 | Time 16.2647(17.4665) | Bit/dim 3.6704(3.6942) | Xent 0.7205(0.7289) | Loss 259.5125(281.8252) | Error 0.2678(0.2601) Steps 0(0.00) | Grad Norm 183.7583(227.3850) | Total Time 0.00(0.00)\n",
      "Iter 4230 | Time 17.5951(17.6797) | Bit/dim 3.6900(3.6980) | Xent 0.7168(0.7202) | Loss 271.4748(278.2274) | Error 0.2444(0.2571) Steps 0(0.00) | Grad Norm 166.9085(218.7778) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 93.7305, Epoch Time 1083.8016(1040.3996), Bit/dim 3.7020(best: 3.6950), Xent 0.7890, Loss 4.0965, Error 0.2804(best: 0.2677)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4240 | Time 17.4712(17.6896) | Bit/dim 3.7142(3.6933) | Xent 0.7718(0.7234) | Loss 266.3606(307.8826) | Error 0.2533(0.2569) Steps 0(0.00) | Grad Norm 281.9487(221.1955) | Total Time 0.00(0.00)\n",
      "Iter 4250 | Time 17.3663(17.6312) | Bit/dim 3.7316(3.6975) | Xent 0.6901(0.7176) | Loss 268.4696(297.5402) | Error 0.2522(0.2560) Steps 0(0.00) | Grad Norm 260.2325(225.0798) | Total Time 0.00(0.00)\n",
      "Iter 4260 | Time 17.4050(17.4417) | Bit/dim 3.6873(3.6974) | Xent 0.7492(0.7212) | Loss 270.5347(289.4540) | Error 0.2744(0.2577) Steps 0(0.00) | Grad Norm 202.5444(222.4879) | Total Time 0.00(0.00)\n",
      "Iter 4270 | Time 16.7290(17.3986) | Bit/dim 3.7119(3.6984) | Xent 0.7218(0.7187) | Loss 265.2134(283.2301) | Error 0.2611(0.2558) Steps 0(0.00) | Grad Norm 142.1506(210.9254) | Total Time 0.00(0.00)\n",
      "Iter 4280 | Time 17.3464(17.4074) | Bit/dim 3.6799(3.6970) | Xent 0.7794(0.7109) | Loss 272.3845(279.3658) | Error 0.2878(0.2536) Steps 0(0.00) | Grad Norm 285.5040(202.6808) | Total Time 0.00(0.00)\n",
      "Iter 4290 | Time 17.3662(17.4277) | Bit/dim 3.6911(3.6953) | Xent 0.6659(0.7059) | Loss 259.6811(275.8936) | Error 0.2467(0.2531) Steps 0(0.00) | Grad Norm 137.7493(199.4605) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 93.8150, Epoch Time 1064.0876(1041.1102), Bit/dim 3.6903(best: 3.6950), Xent 0.7565, Loss 4.0685, Error 0.2685(best: 0.2677)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4300 | Time 16.4945(17.5033) | Bit/dim 3.7031(3.6931) | Xent 0.6659(0.7066) | Loss 245.9005(303.6244) | Error 0.2411(0.2525) Steps 0(0.00) | Grad Norm 222.6270(205.4120) | Total Time 0.00(0.00)\n",
      "Iter 4310 | Time 17.6356(17.4703) | Bit/dim 3.6638(3.6928) | Xent 0.6357(0.7055) | Loss 265.6403(294.6858) | Error 0.2211(0.2528) Steps 0(0.00) | Grad Norm 257.5750(218.9732) | Total Time 0.00(0.00)\n",
      "Iter 4320 | Time 17.3202(17.5500) | Bit/dim 3.6930(3.6951) | Xent 0.6816(0.7093) | Loss 267.1675(286.9527) | Error 0.2333(0.2523) Steps 0(0.00) | Grad Norm 107.5102(212.6110) | Total Time 0.00(0.00)\n",
      "Iter 4330 | Time 18.8449(17.5073) | Bit/dim 3.7067(3.6971) | Xent 0.7835(0.7237) | Loss 270.9542(281.9067) | Error 0.2811(0.2585) Steps 0(0.00) | Grad Norm 477.7436(244.8468) | Total Time 0.00(0.00)\n",
      "Iter 4340 | Time 17.2179(17.5651) | Bit/dim 3.6739(3.7001) | Xent 0.7143(0.7306) | Loss 267.7734(279.4326) | Error 0.2578(0.2607) Steps 0(0.00) | Grad Norm 163.4601(239.2107) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 93.0302, Epoch Time 1082.5341(1042.3530), Bit/dim 3.7058(best: 3.6903), Xent 0.7418, Loss 4.0767, Error 0.2592(best: 0.2677)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4350 | Time 18.4341(17.6793) | Bit/dim 3.6755(3.6977) | Xent 0.6615(0.7204) | Loss 260.8272(309.8510) | Error 0.2489(0.2584) Steps 0(0.00) | Grad Norm 123.5068(218.5785) | Total Time 0.00(0.00)\n",
      "Iter 4360 | Time 16.9878(17.6771) | Bit/dim 3.6883(3.6967) | Xent 0.7172(0.7130) | Loss 277.0270(299.1578) | Error 0.2633(0.2565) Steps 0(0.00) | Grad Norm 227.5237(213.4956) | Total Time 0.00(0.00)\n",
      "Iter 4370 | Time 16.3648(17.5721) | Bit/dim 3.7191(3.6969) | Xent 0.7039(0.7084) | Loss 259.9639(290.4713) | Error 0.2589(0.2539) Steps 0(0.00) | Grad Norm 237.7991(210.5663) | Total Time 0.00(0.00)\n",
      "Iter 4380 | Time 16.4833(17.6279) | Bit/dim 3.6863(3.6929) | Xent 0.7529(0.7086) | Loss 256.6172(283.9861) | Error 0.2733(0.2528) Steps 0(0.00) | Grad Norm 187.6750(229.0367) | Total Time 0.00(0.00)\n",
      "Iter 4390 | Time 18.1783(17.7746) | Bit/dim 3.7419(3.6922) | Xent 0.7067(0.7061) | Loss 270.5697(280.2469) | Error 0.2489(0.2519) Steps 0(0.00) | Grad Norm 232.2809(216.2715) | Total Time 0.00(0.00)\n",
      "Iter 4400 | Time 17.3245(17.7504) | Bit/dim 3.6548(3.6938) | Xent 0.7628(0.7075) | Loss 265.2348(277.1924) | Error 0.2544(0.2520) Steps 0(0.00) | Grad Norm 186.1250(210.5948) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 92.3968, Epoch Time 1085.6579(1043.6521), Bit/dim 3.6893(best: 3.6903), Xent 0.7389, Loss 4.0588, Error 0.2610(best: 0.2592)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4410 | Time 17.3468(17.7570) | Bit/dim 3.7059(3.6907) | Xent 0.6956(0.7078) | Loss 262.4261(303.9403) | Error 0.2478(0.2526) Steps 0(0.00) | Grad Norm 214.8229(224.3292) | Total Time 0.00(0.00)\n",
      "Iter 4420 | Time 20.6027(17.8308) | Bit/dim 3.6949(3.6941) | Xent 0.6734(0.7001) | Loss 272.0418(294.1569) | Error 0.2322(0.2493) Steps 0(0.00) | Grad Norm 223.1684(212.6316) | Total Time 0.00(0.00)\n",
      "Iter 4430 | Time 17.6859(17.9350) | Bit/dim 3.7135(3.6949) | Xent 0.7124(0.6992) | Loss 278.7834(288.1044) | Error 0.2611(0.2490) Steps 0(0.00) | Grad Norm 440.0680(214.5680) | Total Time 0.00(0.00)\n",
      "Iter 4440 | Time 17.6123(17.9641) | Bit/dim 3.6519(3.6907) | Xent 0.6844(0.6973) | Loss 274.6575(283.1498) | Error 0.2411(0.2479) Steps 0(0.00) | Grad Norm 152.3802(213.8838) | Total Time 0.00(0.00)\n",
      "Iter 4450 | Time 17.2778(17.7681) | Bit/dim 3.6853(3.6882) | Xent 0.6598(0.6911) | Loss 273.1200(277.8763) | Error 0.2356(0.2466) Steps 0(0.00) | Grad Norm 253.8075(212.2505) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 95.3881, Epoch Time 1091.7450(1045.0949), Bit/dim 3.6919(best: 3.6893), Xent 0.7566, Loss 4.0702, Error 0.2645(best: 0.2592)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4460 | Time 15.7503(17.6735) | Bit/dim 3.6900(3.6863) | Xent 0.6949(0.6910) | Loss 276.7233(307.8494) | Error 0.2511(0.2467) Steps 0(0.00) | Grad Norm 175.9537(209.2741) | Total Time 0.00(0.00)\n",
      "Iter 4470 | Time 17.5286(17.9188) | Bit/dim 3.6577(3.6825) | Xent 0.6509(0.6830) | Loss 264.9245(297.5695) | Error 0.2233(0.2446) Steps 0(0.00) | Grad Norm 144.6890(192.7311) | Total Time 0.00(0.00)\n",
      "Iter 4480 | Time 17.4640(17.8951) | Bit/dim 3.6710(3.6828) | Xent 0.7280(0.6817) | Loss 264.6078(290.0892) | Error 0.2567(0.2435) Steps 0(0.00) | Grad Norm 152.9092(188.8875) | Total Time 0.00(0.00)\n",
      "Iter 4490 | Time 16.8647(17.7533) | Bit/dim 3.6805(3.6829) | Xent 0.6950(0.6864) | Loss 269.6765(284.1005) | Error 0.2467(0.2469) Steps 0(0.00) | Grad Norm 219.2592(207.4789) | Total Time 0.00(0.00)\n",
      "Iter 4500 | Time 16.4213(17.8440) | Bit/dim 3.7006(3.6845) | Xent 0.6528(0.6980) | Loss 273.0677(279.9185) | Error 0.2289(0.2493) Steps 0(0.00) | Grad Norm 211.2870(232.3082) | Total Time 0.00(0.00)\n",
      "Iter 4510 | Time 17.6280(17.8745) | Bit/dim 3.6876(3.6874) | Xent 0.6803(0.6965) | Loss 266.2655(275.7428) | Error 0.2422(0.2480) Steps 0(0.00) | Grad Norm 177.9134(219.8185) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 91.3584, Epoch Time 1097.8357(1046.6771), Bit/dim 3.6953(best: 3.6893), Xent 0.7683, Loss 4.0795, Error 0.2672(best: 0.2592)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4520 | Time 16.5170(17.8827) | Bit/dim 3.6555(3.6871) | Xent 0.7516(0.6999) | Loss 268.4314(302.5867) | Error 0.2656(0.2498) Steps 0(0.00) | Grad Norm 203.5131(232.6726) | Total Time 0.00(0.00)\n",
      "Iter 4530 | Time 18.2898(17.8307) | Bit/dim 3.6799(3.6875) | Xent 0.7119(0.6980) | Loss 266.4787(293.3669) | Error 0.2511(0.2495) Steps 0(0.00) | Grad Norm 222.5748(231.9545) | Total Time 0.00(0.00)\n",
      "Iter 4540 | Time 16.7686(17.7940) | Bit/dim 3.7213(3.6865) | Xent 0.6896(0.7000) | Loss 266.2319(287.2190) | Error 0.2489(0.2506) Steps 0(0.00) | Grad Norm 224.7084(235.4191) | Total Time 0.00(0.00)\n",
      "Iter 4550 | Time 17.0319(17.8488) | Bit/dim 3.6719(3.6871) | Xent 0.7131(0.6928) | Loss 262.8552(282.4315) | Error 0.2578(0.2477) Steps 0(0.00) | Grad Norm 165.4774(223.7319) | Total Time 0.00(0.00)\n",
      "Iter 4560 | Time 17.3797(17.9052) | Bit/dim 3.6791(3.6884) | Xent 0.6327(0.6889) | Loss 251.9763(278.0220) | Error 0.2367(0.2466) Steps 0(0.00) | Grad Norm 162.7414(211.0544) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 93.2018, Epoch Time 1093.4241(1048.0795), Bit/dim 3.6873(best: 3.6893), Xent 0.7532, Loss 4.0639, Error 0.2603(best: 0.2592)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4570 | Time 16.3247(17.8128) | Bit/dim 3.6621(3.6901) | Xent 0.6427(0.6826) | Loss 267.6633(308.9430) | Error 0.2344(0.2440) Steps 0(0.00) | Grad Norm 221.8664(207.0331) | Total Time 0.00(0.00)\n",
      "Iter 4580 | Time 16.4507(17.7749) | Bit/dim 3.7247(3.6895) | Xent 0.6694(0.6807) | Loss 251.0878(297.5802) | Error 0.2367(0.2433) Steps 0(0.00) | Grad Norm 169.1953(209.2166) | Total Time 0.00(0.00)\n",
      "Iter 4590 | Time 17.8153(17.9042) | Bit/dim 3.6888(3.6848) | Xent 0.6987(0.6831) | Loss 272.7791(289.7066) | Error 0.2456(0.2456) Steps 0(0.00) | Grad Norm 275.8535(211.8688) | Total Time 0.00(0.00)\n",
      "Iter 4600 | Time 16.4533(17.8974) | Bit/dim 3.6706(3.6845) | Xent 0.6212(0.6779) | Loss 263.2504(283.8250) | Error 0.2178(0.2438) Steps 0(0.00) | Grad Norm 159.6219(205.3322) | Total Time 0.00(0.00)\n",
      "Iter 4610 | Time 16.6556(17.7493) | Bit/dim 3.6627(3.6811) | Xent 0.6886(0.6848) | Loss 268.9216(279.7623) | Error 0.2456(0.2469) Steps 0(0.00) | Grad Norm 252.0921(224.5192) | Total Time 0.00(0.00)\n",
      "Iter 4620 | Time 15.7436(17.6673) | Bit/dim 3.7110(3.6829) | Xent 0.7474(0.6853) | Loss 271.4403(276.1897) | Error 0.2700(0.2478) Steps 0(0.00) | Grad Norm 184.1361(215.3205) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 91.4326, Epoch Time 1083.9423(1049.1554), Bit/dim 3.6827(best: 3.6873), Xent 0.7182, Loss 4.0418, Error 0.2528(best: 0.2592)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4630 | Time 17.3670(17.6944) | Bit/dim 3.6829(3.6820) | Xent 0.6487(0.6774) | Loss 267.5413(302.6294) | Error 0.2300(0.2437) Steps 0(0.00) | Grad Norm 166.2567(209.1319) | Total Time 0.00(0.00)\n",
      "Iter 4640 | Time 16.7842(17.6987) | Bit/dim 3.6544(3.6801) | Xent 0.6365(0.6730) | Loss 265.3009(293.5418) | Error 0.2222(0.2415) Steps 0(0.00) | Grad Norm 124.4752(194.3994) | Total Time 0.00(0.00)\n",
      "Iter 4650 | Time 15.9849(17.6240) | Bit/dim 3.6549(3.6777) | Xent 0.6593(0.6756) | Loss 265.1185(286.4096) | Error 0.2511(0.2431) Steps 0(0.00) | Grad Norm 127.5039(189.4241) | Total Time 0.00(0.00)\n",
      "Iter 4660 | Time 17.9488(17.7132) | Bit/dim 3.7034(3.6784) | Xent 0.6821(0.6680) | Loss 281.0240(281.4673) | Error 0.2411(0.2410) Steps 0(0.00) | Grad Norm 186.0926(189.3941) | Total Time 0.00(0.00)\n",
      "Iter 4670 | Time 15.5566(17.4590) | Bit/dim 3.6677(3.6809) | Xent 0.6635(0.6699) | Loss 266.6875(277.3231) | Error 0.2522(0.2416) Steps 0(0.00) | Grad Norm 194.0220(196.6197) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 93.7382, Epoch Time 1077.3573(1050.0015), Bit/dim 3.6740(best: 3.6827), Xent 0.7256, Loss 4.0368, Error 0.2557(best: 0.2528)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4680 | Time 16.6804(17.5512) | Bit/dim 3.6882(3.6799) | Xent 0.6221(0.6660) | Loss 269.7606(309.0565) | Error 0.2144(0.2382) Steps 0(0.00) | Grad Norm 149.6815(193.4328) | Total Time 0.00(0.00)\n",
      "Iter 4690 | Time 17.2299(17.5892) | Bit/dim 3.6773(3.6797) | Xent 0.6662(0.6637) | Loss 257.3852(297.5946) | Error 0.2322(0.2388) Steps 0(0.00) | Grad Norm 257.9953(194.2790) | Total Time 0.00(0.00)\n",
      "Iter 4700 | Time 17.6080(17.7501) | Bit/dim 3.6622(3.6786) | Xent 0.6338(0.6624) | Loss 266.0955(289.5023) | Error 0.2289(0.2373) Steps 0(0.00) | Grad Norm 201.7913(195.6626) | Total Time 0.00(0.00)\n",
      "Iter 4710 | Time 20.6336(17.9190) | Bit/dim 3.7077(3.6813) | Xent 0.7881(0.6753) | Loss 281.1665(285.0593) | Error 0.2867(0.2416) Steps 0(0.00) | Grad Norm 397.5364(228.3193) | Total Time 0.00(0.00)\n",
      "Iter 4720 | Time 17.8772(17.7945) | Bit/dim 3.6702(3.6825) | Xent 0.6772(0.6812) | Loss 266.3561(280.1226) | Error 0.2478(0.2432) Steps 0(0.00) | Grad Norm 173.2934(228.0377) | Total Time 0.00(0.00)\n",
      "Iter 4730 | Time 18.5265(17.8285) | Bit/dim 3.6813(3.6811) | Xent 0.7614(0.6846) | Loss 276.4866(277.4195) | Error 0.2722(0.2446) Steps 0(0.00) | Grad Norm 362.2024(233.2590) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 94.3744, Epoch Time 1098.3500(1051.4519), Bit/dim 3.6825(best: 3.6740), Xent 0.8386, Loss 4.1018, Error 0.2993(best: 0.2528)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4740 | Time 18.7669(17.9449) | Bit/dim 3.7314(3.6871) | Xent 0.6878(0.6862) | Loss 279.6513(305.3335) | Error 0.2511(0.2466) Steps 0(0.00) | Grad Norm 223.8489(239.5989) | Total Time 0.00(0.00)\n",
      "Iter 4750 | Time 16.0213(17.8917) | Bit/dim 3.6601(3.6858) | Xent 0.6978(0.6837) | Loss 266.6070(296.1413) | Error 0.2533(0.2448) Steps 0(0.00) | Grad Norm 179.6700(230.7618) | Total Time 0.00(0.00)\n",
      "Iter 4760 | Time 17.9905(18.0146) | Bit/dim 3.6397(3.6829) | Xent 0.7015(0.6799) | Loss 253.7183(288.6356) | Error 0.2500(0.2428) Steps 0(0.00) | Grad Norm 280.9472(229.5612) | Total Time 0.00(0.00)\n",
      "Iter 4770 | Time 19.2151(18.0111) | Bit/dim 3.6443(3.6797) | Xent 0.6366(0.6857) | Loss 271.5087(282.9173) | Error 0.2222(0.2450) Steps 0(0.00) | Grad Norm 319.4727(233.7279) | Total Time 0.00(0.00)\n",
      "Iter 4780 | Time 16.7175(18.0345) | Bit/dim 3.7233(3.6828) | Xent 0.7126(0.6898) | Loss 259.2596(278.9592) | Error 0.2611(0.2469) Steps 0(0.00) | Grad Norm 203.5684(235.0091) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 93.3053, Epoch Time 1109.4964(1053.1933), Bit/dim 3.6832(best: 3.6740), Xent 0.7223, Loss 4.0444, Error 0.2522(best: 0.2528)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4790 | Time 19.2928(18.1339) | Bit/dim 3.6551(3.6812) | Xent 0.6555(0.6861) | Loss 280.4535(311.0336) | Error 0.2200(0.2461) Steps 0(0.00) | Grad Norm 245.9969(230.8382) | Total Time 0.00(0.00)\n",
      "Iter 4800 | Time 17.6244(18.0634) | Bit/dim 3.6989(3.6794) | Xent 0.5515(0.6793) | Loss 257.5306(298.9580) | Error 0.1844(0.2433) Steps 0(0.00) | Grad Norm 150.7920(231.3617) | Total Time 0.00(0.00)\n",
      "Iter 4810 | Time 16.9218(17.8922) | Bit/dim 3.6405(3.6805) | Xent 0.6814(0.6718) | Loss 263.4412(290.5528) | Error 0.2444(0.2402) Steps 0(0.00) | Grad Norm 233.9679(215.3745) | Total Time 0.00(0.00)\n",
      "Iter 4820 | Time 19.4120(17.9620) | Bit/dim 3.6717(3.6811) | Xent 0.6807(0.6675) | Loss 251.9936(284.2745) | Error 0.2478(0.2393) Steps 0(0.00) | Grad Norm 164.2683(216.5207) | Total Time 0.00(0.00)\n",
      "Iter 4830 | Time 18.5426(17.9807) | Bit/dim 3.6829(3.6798) | Xent 0.6951(0.6673) | Loss 263.9388(279.5472) | Error 0.2467(0.2381) Steps 0(0.00) | Grad Norm 190.7296(220.4438) | Total Time 0.00(0.00)\n",
      "Iter 4840 | Time 17.7253(17.8872) | Bit/dim 3.7031(3.6798) | Xent 0.6911(0.6688) | Loss 267.0212(275.6638) | Error 0.2456(0.2378) Steps 0(0.00) | Grad Norm 257.9871(219.5260) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 93.5285, Epoch Time 1093.6597(1054.4073), Bit/dim 3.6757(best: 3.6740), Xent 0.7233, Loss 4.0373, Error 0.2519(best: 0.2522)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4850 | Time 17.6811(17.8960) | Bit/dim 3.6983(3.6773) | Xent 0.6904(0.6659) | Loss 262.7557(301.2076) | Error 0.2400(0.2364) Steps 0(0.00) | Grad Norm 230.2505(217.8289) | Total Time 0.00(0.00)\n",
      "Iter 4860 | Time 17.2606(17.8814) | Bit/dim 3.6489(3.6738) | Xent 0.6618(0.6636) | Loss 264.7072(292.2483) | Error 0.2511(0.2371) Steps 0(0.00) | Grad Norm 220.8640(213.1871) | Total Time 0.00(0.00)\n",
      "Iter 4870 | Time 17.7918(17.7487) | Bit/dim 3.6795(3.6739) | Xent 0.7388(0.6749) | Loss 272.4638(286.4354) | Error 0.2433(0.2394) Steps 0(0.00) | Grad Norm 225.2853(229.8420) | Total Time 0.00(0.00)\n",
      "Iter 4880 | Time 16.4432(17.5813) | Bit/dim 3.7043(3.6745) | Xent 0.6776(0.6780) | Loss 263.9684(281.2040) | Error 0.2544(0.2424) Steps 0(0.00) | Grad Norm 133.8970(226.5819) | Total Time 0.00(0.00)\n",
      "Iter 4890 | Time 16.6480(17.5496) | Bit/dim 3.7436(3.6790) | Xent 0.6072(0.6719) | Loss 269.4466(277.9026) | Error 0.2256(0.2407) Steps 0(0.00) | Grad Norm 191.3116(226.1688) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 92.0954, Epoch Time 1077.8624(1055.1109), Bit/dim 3.6845(best: 3.6740), Xent 0.7217, Loss 4.0454, Error 0.2562(best: 0.2519)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4900 | Time 16.2592(17.6135) | Bit/dim 3.6302(3.6799) | Xent 0.6131(0.6653) | Loss 261.0143(307.8916) | Error 0.2278(0.2378) Steps 0(0.00) | Grad Norm 115.6818(213.7691) | Total Time 0.00(0.00)\n",
      "Iter 4910 | Time 17.0770(17.7377) | Bit/dim 3.6885(3.6761) | Xent 0.5803(0.6528) | Loss 261.0078(297.2482) | Error 0.1967(0.2324) Steps 0(0.00) | Grad Norm 144.9317(204.8475) | Total Time 0.00(0.00)\n",
      "Iter 4920 | Time 18.6886(17.7343) | Bit/dim 3.6855(3.6768) | Xent 0.6540(0.6499) | Loss 276.5091(289.6549) | Error 0.2300(0.2317) Steps 0(0.00) | Grad Norm 288.6099(217.9009) | Total Time 0.00(0.00)\n",
      "Iter 4930 | Time 17.0310(17.7968) | Bit/dim 3.7068(3.6788) | Xent 0.6755(0.6521) | Loss 262.7208(283.4284) | Error 0.2400(0.2326) Steps 0(0.00) | Grad Norm 183.4159(219.1384) | Total Time 0.00(0.00)\n",
      "Iter 4940 | Time 18.4845(17.8133) | Bit/dim 3.6474(3.6777) | Xent 0.5900(0.6482) | Loss 258.4391(278.7946) | Error 0.2178(0.2317) Steps 0(0.00) | Grad Norm 120.6115(211.2254) | Total Time 0.00(0.00)\n",
      "Iter 4950 | Time 17.9793(17.9719) | Bit/dim 3.6683(3.6737) | Xent 0.6474(0.6493) | Loss 270.4066(275.7013) | Error 0.2200(0.2316) Steps 0(0.00) | Grad Norm 127.7010(199.4773) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 93.0541, Epoch Time 1099.3580(1056.4383), Bit/dim 3.6683(best: 3.6740), Xent 0.7309, Loss 4.0338, Error 0.2575(best: 0.2519)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4960 | Time 19.0351(17.9182) | Bit/dim 3.6743(3.6721) | Xent 0.6368(0.6456) | Loss 270.2163(301.4706) | Error 0.2222(0.2305) Steps 0(0.00) | Grad Norm 232.2883(192.7606) | Total Time 0.00(0.00)\n",
      "Iter 4970 | Time 17.5119(17.8449) | Bit/dim 3.6996(3.6724) | Xent 0.6333(0.6464) | Loss 268.6019(291.6116) | Error 0.2233(0.2320) Steps 0(0.00) | Grad Norm 256.1494(200.8983) | Total Time 0.00(0.00)\n",
      "Iter 4980 | Time 22.8321(17.9687) | Bit/dim 3.6741(3.6733) | Xent 0.6561(0.6538) | Loss 272.6497(285.9046) | Error 0.2244(0.2349) Steps 0(0.00) | Grad Norm 172.0702(211.7116) | Total Time 0.00(0.00)\n",
      "Iter 4990 | Time 19.6530(17.8502) | Bit/dim 3.6547(3.6730) | Xent 0.6307(0.6513) | Loss 266.5316(280.3663) | Error 0.2133(0.2324) Steps 0(0.00) | Grad Norm 152.7701(207.4854) | Total Time 0.00(0.00)\n",
      "Iter 5000 | Time 17.6115(17.8298) | Bit/dim 3.6656(3.6714) | Xent 0.6274(0.6498) | Loss 268.3238(276.8444) | Error 0.2167(0.2320) Steps 0(0.00) | Grad Norm 137.7919(198.2908) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 92.5843, Epoch Time 1085.6431(1057.3145), Bit/dim 3.6706(best: 3.6683), Xent 0.7060, Loss 4.0236, Error 0.2473(best: 0.2519)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5010 | Time 15.9584(17.7318) | Bit/dim 3.6311(3.6710) | Xent 0.6278(0.6383) | Loss 252.5014(308.5165) | Error 0.2089(0.2278) Steps 0(0.00) | Grad Norm 116.8705(186.5374) | Total Time 0.00(0.00)\n",
      "Iter 5020 | Time 17.3879(17.6694) | Bit/dim 3.6558(3.6691) | Xent 0.6482(0.6321) | Loss 264.9350(296.9899) | Error 0.2189(0.2261) Steps 0(0.00) | Grad Norm 216.7936(195.3147) | Total Time 0.00(0.00)\n",
      "Iter 5030 | Time 19.8128(17.7106) | Bit/dim 3.6186(3.6686) | Xent 0.7574(0.6365) | Loss 260.2403(287.7455) | Error 0.2789(0.2282) Steps 0(0.00) | Grad Norm 250.4178(197.1551) | Total Time 0.00(0.00)\n",
      "Iter 5040 | Time 18.9049(17.6500) | Bit/dim 3.6522(3.6686) | Xent 0.6056(0.6331) | Loss 268.8893(281.5416) | Error 0.2289(0.2270) Steps 0(0.00) | Grad Norm 178.0971(200.7423) | Total Time 0.00(0.00)\n",
      "Iter 5050 | Time 19.5804(17.7700) | Bit/dim 3.6725(3.6690) | Xent 0.7077(0.6336) | Loss 265.1587(277.5901) | Error 0.2511(0.2256) Steps 0(0.00) | Grad Norm 185.2413(194.1404) | Total Time 0.00(0.00)\n",
      "Iter 5060 | Time 19.5177(18.0209) | Bit/dim 3.6371(3.6665) | Xent 0.5868(0.6303) | Loss 256.0271(273.9823) | Error 0.2144(0.2245) Steps 0(0.00) | Grad Norm 118.6284(178.8079) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 94.5751, Epoch Time 1095.4172(1058.4575), Bit/dim 3.6684(best: 3.6683), Xent 0.7146, Loss 4.0258, Error 0.2485(best: 0.2473)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5070 | Time 17.3023(17.8967) | Bit/dim 3.6904(3.6690) | Xent 0.6418(0.6266) | Loss 274.1045(301.1659) | Error 0.2289(0.2229) Steps 0(0.00) | Grad Norm 185.1529(182.3520) | Total Time 0.00(0.00)\n",
      "Iter 5080 | Time 19.2914(17.7867) | Bit/dim 3.6504(3.6667) | Xent 0.6478(0.6223) | Loss 263.8539(291.9497) | Error 0.2356(0.2215) Steps 0(0.00) | Grad Norm 285.3251(181.6384) | Total Time 0.00(0.00)\n",
      "Iter 5090 | Time 18.5933(17.8131) | Bit/dim 3.6720(3.6678) | Xent 0.6875(0.6213) | Loss 276.9713(284.8957) | Error 0.2400(0.2221) Steps 0(0.00) | Grad Norm 250.0729(192.2710) | Total Time 0.00(0.00)\n",
      "Iter 5100 | Time 18.4506(17.8151) | Bit/dim 3.6634(3.6653) | Xent 0.6871(0.6372) | Loss 264.0930(279.5025) | Error 0.2344(0.2274) Steps 0(0.00) | Grad Norm 316.8372(219.8879) | Total Time 0.00(0.00)\n",
      "Iter 5110 | Time 17.7821(17.8558) | Bit/dim 3.7017(3.6680) | Xent 0.6339(0.6340) | Loss 264.5394(276.1027) | Error 0.2333(0.2271) Steps 0(0.00) | Grad Norm 116.1122(209.5915) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 93.2082, Epoch Time 1087.1477(1059.3183), Bit/dim 3.6734(best: 3.6683), Xent 0.6958, Loss 4.0213, Error 0.2449(best: 0.2473)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5120 | Time 18.3496(17.8231) | Bit/dim 3.6877(3.6671) | Xent 0.6350(0.6265) | Loss 273.2029(305.8473) | Error 0.2222(0.2240) Steps 0(0.00) | Grad Norm 230.2293(196.5349) | Total Time 0.00(0.00)\n",
      "Iter 5130 | Time 17.5859(17.8377) | Bit/dim 3.6159(3.6677) | Xent 0.6021(0.6233) | Loss 261.6223(295.0943) | Error 0.2111(0.2228) Steps 0(0.00) | Grad Norm 226.6902(193.3101) | Total Time 0.00(0.00)\n",
      "Iter 5140 | Time 16.7870(17.8167) | Bit/dim 3.6596(3.6674) | Xent 0.5721(0.6273) | Loss 254.4108(287.7236) | Error 0.1922(0.2245) Steps 0(0.00) | Grad Norm 117.3695(194.1486) | Total Time 0.00(0.00)\n",
      "Iter 5150 | Time 19.7636(17.8125) | Bit/dim 3.6595(3.6682) | Xent 0.5959(0.6236) | Loss 269.1447(281.1583) | Error 0.2056(0.2226) Steps 0(0.00) | Grad Norm 218.9693(200.8571) | Total Time 0.00(0.00)\n",
      "Iter 5160 | Time 17.2328(17.7729) | Bit/dim 3.6677(3.6670) | Xent 0.5541(0.6243) | Loss 253.8804(276.7782) | Error 0.2011(0.2238) Steps 0(0.00) | Grad Norm 235.7754(214.5025) | Total Time 0.00(0.00)\n",
      "Iter 5170 | Time 17.7896(17.8471) | Bit/dim 3.6762(3.6649) | Xent 0.6202(0.6276) | Loss 268.4651(274.2704) | Error 0.2256(0.2244) Steps 0(0.00) | Grad Norm 232.0652(213.8683) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 92.8749, Epoch Time 1090.5592(1060.2555), Bit/dim 3.6649(best: 3.6683), Xent 0.7021, Loss 4.0160, Error 0.2490(best: 0.2449)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5180 | Time 17.5470(17.9322) | Bit/dim 3.6469(3.6626) | Xent 0.5418(0.6173) | Loss 264.0927(299.8031) | Error 0.1944(0.2205) Steps 0(0.00) | Grad Norm 131.7615(206.4923) | Total Time 0.00(0.00)\n",
      "Iter 5190 | Time 19.2607(17.9718) | Bit/dim 3.6878(3.6634) | Xent 0.5951(0.6167) | Loss 261.0932(290.4872) | Error 0.2067(0.2197) Steps 0(0.00) | Grad Norm 176.9524(204.8360) | Total Time 0.00(0.00)\n",
      "Iter 5200 | Time 18.4938(17.9581) | Bit/dim 3.6922(3.6645) | Xent 0.6024(0.6141) | Loss 258.2958(283.0046) | Error 0.2156(0.2200) Steps 0(0.00) | Grad Norm 178.6974(204.5109) | Total Time 0.00(0.00)\n",
      "Iter 5210 | Time 20.8919(18.2776) | Bit/dim 3.6852(3.6629) | Xent 0.6531(0.6151) | Loss 271.1689(278.6030) | Error 0.2244(0.2203) Steps 0(0.00) | Grad Norm 129.9884(187.8991) | Total Time 0.00(0.00)\n",
      "Iter 5220 | Time 17.6101(18.3046) | Bit/dim 3.6596(3.6622) | Xent 0.6618(0.6227) | Loss 263.1373(275.3135) | Error 0.2300(0.2231) Steps 0(0.00) | Grad Norm 184.8418(196.3707) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 93.2779, Epoch Time 1120.7503(1062.0703), Bit/dim 3.6646(best: 3.6649), Xent 0.7137, Loss 4.0214, Error 0.2497(best: 0.2449)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5230 | Time 16.0046(18.1194) | Bit/dim 3.6851(3.6647) | Xent 0.7003(0.6201) | Loss 254.6541(306.1860) | Error 0.2567(0.2227) Steps 0(0.00) | Grad Norm 358.3612(196.5540) | Total Time 0.00(0.00)\n",
      "Iter 5240 | Time 16.9904(18.0960) | Bit/dim 3.6959(3.6638) | Xent 0.5875(0.6188) | Loss 252.5289(295.5123) | Error 0.2144(0.2215) Steps 0(0.00) | Grad Norm 267.9885(213.9116) | Total Time 0.00(0.00)\n",
      "Iter 5250 | Time 17.3853(18.0086) | Bit/dim 3.6861(3.6651) | Xent 0.5582(0.6142) | Loss 264.0564(287.4832) | Error 0.2067(0.2200) Steps 0(0.00) | Grad Norm 232.1140(204.6730) | Total Time 0.00(0.00)\n",
      "Iter 5260 | Time 19.3456(18.1371) | Bit/dim 3.6687(3.6671) | Xent 0.5715(0.6130) | Loss 275.1542(281.9370) | Error 0.2000(0.2191) Steps 0(0.00) | Grad Norm 161.8428(198.7830) | Total Time 0.00(0.00)\n",
      "Iter 5270 | Time 16.7172(18.0408) | Bit/dim 3.6794(3.6649) | Xent 0.6125(0.6172) | Loss 260.1844(277.2361) | Error 0.2133(0.2192) Steps 0(0.00) | Grad Norm 186.4646(196.7447) | Total Time 0.00(0.00)\n",
      "Iter 5280 | Time 16.9250(18.0113) | Bit/dim 3.7136(3.6673) | Xent 0.6296(0.6187) | Loss 269.6371(273.9031) | Error 0.2256(0.2207) Steps 0(0.00) | Grad Norm 257.8681(203.5094) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 94.0340, Epoch Time 1098.7776(1063.1715), Bit/dim 3.6660(best: 3.6646), Xent 0.6754, Loss 4.0037, Error 0.2367(best: 0.2449)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5290 | Time 18.0053(17.9089) | Bit/dim 3.6363(3.6658) | Xent 0.6447(0.6118) | Loss 262.5776(300.0240) | Error 0.2200(0.2178) Steps 0(0.00) | Grad Norm 235.7772(207.1891) | Total Time 0.00(0.00)\n",
      "Iter 5300 | Time 17.0336(17.9658) | Bit/dim 3.6299(3.6634) | Xent 0.6257(0.6108) | Loss 255.5908(289.9122) | Error 0.2311(0.2179) Steps 0(0.00) | Grad Norm 96.3311(200.6004) | Total Time 0.00(0.00)\n",
      "Iter 5310 | Time 17.5854(17.9794) | Bit/dim 3.6706(3.6615) | Xent 0.5509(0.6102) | Loss 265.3478(283.0429) | Error 0.2011(0.2178) Steps 0(0.00) | Grad Norm 166.3899(201.0693) | Total Time 0.00(0.00)\n",
      "Iter 5320 | Time 21.2933(18.2449) | Bit/dim 3.6659(3.6625) | Xent 0.6564(0.6159) | Loss 271.9685(278.9864) | Error 0.2389(0.2202) Steps 0(0.00) | Grad Norm 217.9775(208.0976) | Total Time 0.00(0.00)\n",
      "Iter 5330 | Time 18.8370(18.2472) | Bit/dim 3.6965(3.6645) | Xent 0.6300(0.6185) | Loss 272.3939(275.9895) | Error 0.2278(0.2210) Steps 0(0.00) | Grad Norm 233.9064(214.1928) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 95.7304, Epoch Time 1114.9627(1064.7253), Bit/dim 3.6661(best: 3.6646), Xent 0.6941, Loss 4.0131, Error 0.2422(best: 0.2367)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5340 | Time 22.8785(18.4234) | Bit/dim 3.6759(3.6659) | Xent 0.5758(0.6125) | Loss 267.4243(307.4797) | Error 0.2022(0.2199) Steps 0(0.00) | Grad Norm 129.9513(203.3055) | Total Time 0.00(0.00)\n",
      "Iter 5350 | Time 17.0585(18.3309) | Bit/dim 3.6705(3.6663) | Xent 0.5900(0.6172) | Loss 272.4051(296.6159) | Error 0.2122(0.2205) Steps 0(0.00) | Grad Norm 170.8054(215.1479) | Total Time 0.00(0.00)\n",
      "Iter 5360 | Time 18.5825(18.3849) | Bit/dim 3.6675(3.6644) | Xent 0.6217(0.6144) | Loss 274.2460(288.5297) | Error 0.2133(0.2182) Steps 0(0.00) | Grad Norm 179.9999(206.0830) | Total Time 0.00(0.00)\n",
      "Iter 5370 | Time 16.7923(18.3815) | Bit/dim 3.6416(3.6643) | Xent 0.5968(0.6080) | Loss 261.7206(282.3445) | Error 0.2111(0.2158) Steps 0(0.00) | Grad Norm 156.5149(197.4428) | Total Time 0.00(0.00)\n",
      "Iter 5380 | Time 18.4081(18.3451) | Bit/dim 3.6530(3.6641) | Xent 0.5993(0.6121) | Loss 264.6887(277.7632) | Error 0.2000(0.2161) Steps 0(0.00) | Grad Norm 198.7098(195.7537) | Total Time 0.00(0.00)\n",
      "Iter 5390 | Time 18.8285(18.3339) | Bit/dim 3.7018(3.6637) | Xent 0.6036(0.6167) | Loss 273.2738(274.6266) | Error 0.2100(0.2180) Steps 0(0.00) | Grad Norm 290.2162(215.6780) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 94.8677, Epoch Time 1125.7075(1066.5547), Bit/dim 3.6618(best: 3.6646), Xent 0.7222, Loss 4.0229, Error 0.2512(best: 0.2367)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5400 | Time 18.7411(18.4475) | Bit/dim 3.6271(3.6608) | Xent 0.5663(0.6106) | Loss 274.2870(301.1874) | Error 0.2022(0.2164) Steps 0(0.00) | Grad Norm 186.2419(210.2770) | Total Time 0.00(0.00)\n",
      "Iter 5410 | Time 17.6079(18.4980) | Bit/dim 3.6574(3.6638) | Xent 0.5916(0.6041) | Loss 260.2255(291.8535) | Error 0.2156(0.2145) Steps 0(0.00) | Grad Norm 154.2139(197.6578) | Total Time 0.00(0.00)\n",
      "Iter 5420 | Time 18.3969(18.5183) | Bit/dim 3.6830(3.6628) | Xent 0.5829(0.5989) | Loss 268.7967(285.1215) | Error 0.2011(0.2123) Steps 0(0.00) | Grad Norm 175.9287(190.8412) | Total Time 0.00(0.00)\n",
      "Iter 5430 | Time 17.9399(18.2913) | Bit/dim 3.6714(3.6608) | Xent 0.6478(0.6052) | Loss 248.1168(279.7141) | Error 0.2356(0.2156) Steps 0(0.00) | Grad Norm 253.4732(197.8654) | Total Time 0.00(0.00)\n",
      "Iter 5440 | Time 18.6442(18.3628) | Bit/dim 3.6474(3.6593) | Xent 0.5843(0.6048) | Loss 268.6584(276.5643) | Error 0.2056(0.2157) Steps 0(0.00) | Grad Norm 196.9949(188.9900) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 95.9454, Epoch Time 1125.5223(1068.3238), Bit/dim 3.6616(best: 3.6618), Xent 0.7741, Loss 4.0486, Error 0.2624(best: 0.2367)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5450 | Time 17.9018(18.3655) | Bit/dim 3.6627(3.6623) | Xent 0.6007(0.6046) | Loss 265.7001(308.4524) | Error 0.2156(0.2134) Steps 0(0.00) | Grad Norm 225.4247(196.8352) | Total Time 0.00(0.00)\n",
      "Iter 5460 | Time 17.5492(18.2564) | Bit/dim 3.6511(3.6585) | Xent 0.6115(0.6015) | Loss 262.8166(296.2583) | Error 0.2322(0.2127) Steps 0(0.00) | Grad Norm 233.1313(196.7525) | Total Time 0.00(0.00)\n",
      "Iter 5470 | Time 16.3115(18.2372) | Bit/dim 3.6544(3.6601) | Xent 0.5629(0.5959) | Loss 268.5954(287.2354) | Error 0.2167(0.2112) Steps 0(0.00) | Grad Norm 207.8210(190.5351) | Total Time 0.00(0.00)\n",
      "Iter 5480 | Time 18.3938(18.2286) | Bit/dim 3.6734(3.6616) | Xent 0.5728(0.5997) | Loss 255.4938(280.8175) | Error 0.1889(0.2118) Steps 0(0.00) | Grad Norm 273.0123(204.9957) | Total Time 0.00(0.00)\n",
      "Iter 5490 | Time 19.1585(18.1602) | Bit/dim 3.6544(3.6614) | Xent 0.5783(0.6030) | Loss 271.5719(276.5151) | Error 0.2044(0.2125) Steps 0(0.00) | Grad Norm 157.1782(210.4288) | Total Time 0.00(0.00)\n",
      "Iter 5500 | Time 17.8260(18.0965) | Bit/dim 3.6765(3.6620) | Xent 0.6362(0.6049) | Loss 269.6901(273.9283) | Error 0.2422(0.2135) Steps 0(0.00) | Grad Norm 289.5753(218.5336) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 95.9663, Epoch Time 1110.2037(1069.5802), Bit/dim 3.6609(best: 3.6616), Xent 0.6808, Loss 4.0013, Error 0.2367(best: 0.2367)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5510 | Time 16.3359(18.1415) | Bit/dim 3.6712(3.6644) | Xent 0.5378(0.5993) | Loss 252.3456(300.8800) | Error 0.1900(0.2118) Steps 0(0.00) | Grad Norm 190.2013(215.3492) | Total Time 0.00(0.00)\n",
      "Iter 5520 | Time 19.0871(18.1955) | Bit/dim 3.6596(3.6652) | Xent 0.5566(0.6024) | Loss 267.5126(291.2297) | Error 0.1911(0.2128) Steps 0(0.00) | Grad Norm 121.1865(217.5553) | Total Time 0.00(0.00)\n",
      "Iter 5530 | Time 18.1560(18.4374) | Bit/dim 3.6665(3.6631) | Xent 0.5390(0.5964) | Loss 265.9019(284.4059) | Error 0.2000(0.2124) Steps 0(0.00) | Grad Norm 138.1663(199.7055) | Total Time 0.00(0.00)\n",
      "Iter 5540 | Time 18.5991(18.4802) | Bit/dim 3.6464(3.6622) | Xent 0.5732(0.5878) | Loss 269.8804(279.8455) | Error 0.1911(0.2101) Steps 0(0.00) | Grad Norm 155.9363(187.2087) | Total Time 0.00(0.00)\n",
      "Iter 5550 | Time 18.9050(18.5205) | Bit/dim 3.6758(3.6584) | Xent 0.5766(0.5818) | Loss 253.1976(274.6328) | Error 0.2133(0.2073) Steps 0(0.00) | Grad Norm 303.4181(187.1635) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 93.5716, Epoch Time 1137.0673(1071.6048), Bit/dim 3.6569(best: 3.6609), Xent 0.6785, Loss 3.9962, Error 0.2364(best: 0.2367)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5560 | Time 17.9187(18.5455) | Bit/dim 3.6723(3.6563) | Xent 0.5344(0.5830) | Loss 263.8619(306.3699) | Error 0.1911(0.2081) Steps 0(0.00) | Grad Norm 178.8965(188.3890) | Total Time 0.00(0.00)\n",
      "Iter 5570 | Time 18.9273(18.4708) | Bit/dim 3.6507(3.6548) | Xent 0.5935(0.5860) | Loss 271.7445(294.5404) | Error 0.2311(0.2105) Steps 0(0.00) | Grad Norm 370.5603(201.6191) | Total Time 0.00(0.00)\n",
      "Iter 5580 | Time 17.4014(18.6153) | Bit/dim 3.6489(3.6558) | Xent 0.5338(0.5888) | Loss 261.2746(286.2675) | Error 0.1856(0.2094) Steps 0(0.00) | Grad Norm 140.7713(204.3159) | Total Time 0.00(0.00)\n",
      "Iter 5590 | Time 17.2073(18.5167) | Bit/dim 3.6731(3.6568) | Xent 0.5884(0.5848) | Loss 251.4206(280.7289) | Error 0.2189(0.2075) Steps 0(0.00) | Grad Norm 127.7977(195.6891) | Total Time 0.00(0.00)\n",
      "Iter 5600 | Time 19.6882(18.6264) | Bit/dim 3.6566(3.6561) | Xent 0.5581(0.5801) | Loss 276.0013(276.9491) | Error 0.2056(0.2059) Steps 0(0.00) | Grad Norm 219.3206(191.5459) | Total Time 0.00(0.00)\n",
      "Iter 5610 | Time 18.7546(18.5487) | Bit/dim 3.6424(3.6567) | Xent 0.6689(0.5902) | Loss 254.2109(273.8262) | Error 0.2400(0.2104) Steps 0(0.00) | Grad Norm 411.7055(210.2031) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 95.9864, Epoch Time 1132.6518(1073.4362), Bit/dim 3.6626(best: 3.6569), Xent 0.7110, Loss 4.0181, Error 0.2426(best: 0.2364)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5620 | Time 18.0445(18.4793) | Bit/dim 3.6374(3.6601) | Xent 0.5471(0.5965) | Loss 270.3871(301.9129) | Error 0.1933(0.2129) Steps 0(0.00) | Grad Norm 182.0331(226.5678) | Total Time 0.00(0.00)\n",
      "Iter 5630 | Time 18.9326(18.4983) | Bit/dim 3.6514(3.6609) | Xent 0.5745(0.5914) | Loss 253.1925(291.4149) | Error 0.1900(0.2101) Steps 0(0.00) | Grad Norm 196.5599(211.1870) | Total Time 0.00(0.00)\n",
      "Iter 5640 | Time 17.5208(18.4105) | Bit/dim 3.6460(3.6570) | Xent 0.5764(0.5910) | Loss 269.3485(284.3046) | Error 0.2067(0.2103) Steps 0(0.00) | Grad Norm 198.5238(209.5293) | Total Time 0.00(0.00)\n",
      "Iter 5650 | Time 19.4004(18.4669) | Bit/dim 3.6463(3.6602) | Xent 0.5664(0.5903) | Loss 261.6617(280.0159) | Error 0.1900(0.2098) Steps 0(0.00) | Grad Norm 140.9488(200.0631) | Total Time 0.00(0.00)\n",
      "Iter 5660 | Time 18.3319(18.4553) | Bit/dim 3.6208(3.6576) | Xent 0.5918(0.5878) | Loss 267.5708(275.8707) | Error 0.2178(0.2090) Steps 0(0.00) | Grad Norm 201.9071(192.5841) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 95.1715, Epoch Time 1126.3442(1075.0234), Bit/dim 3.6566(best: 3.6569), Xent 0.6979, Loss 4.0055, Error 0.2431(best: 0.2364)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5670 | Time 19.9561(18.7416) | Bit/dim 3.6457(3.6549) | Xent 0.5462(0.5849) | Loss 269.6884(307.6259) | Error 0.2011(0.2087) Steps 0(0.00) | Grad Norm 270.1869(201.9711) | Total Time 0.00(0.00)\n",
      "Iter 5680 | Time 22.4004(18.8422) | Bit/dim 3.6603(3.6553) | Xent 0.5645(0.5743) | Loss 269.7374(296.0473) | Error 0.2056(0.2044) Steps 0(0.00) | Grad Norm 183.5225(191.7159) | Total Time 0.00(0.00)\n",
      "Iter 5690 | Time 19.7037(18.8265) | Bit/dim 3.6778(3.6570) | Xent 0.6707(0.5809) | Loss 271.4536(287.9740) | Error 0.2500(0.2070) Steps 0(0.00) | Grad Norm 253.9918(196.8553) | Total Time 0.00(0.00)\n",
      "Iter 5700 | Time 17.7000(18.7713) | Bit/dim 3.6662(3.6533) | Xent 0.5345(0.5793) | Loss 250.6052(280.8086) | Error 0.1844(0.2066) Steps 0(0.00) | Grad Norm 146.0967(186.3561) | Total Time 0.00(0.00)\n",
      "Iter 5710 | Time 17.2635(18.5797) | Bit/dim 3.6574(3.6567) | Xent 0.6023(0.5872) | Loss 261.6645(276.3660) | Error 0.2122(0.2079) Steps 0(0.00) | Grad Norm 209.6717(198.4955) | Total Time 0.00(0.00)\n",
      "Iter 5720 | Time 17.7722(18.4823) | Bit/dim 3.6730(3.6570) | Xent 0.6100(0.5873) | Loss 259.3602(273.3774) | Error 0.2267(0.2082) Steps 0(0.00) | Grad Norm 265.8066(208.5021) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 94.4929, Epoch Time 1141.5026(1077.0178), Bit/dim 3.6561(best: 3.6566), Xent 0.6911, Loss 4.0017, Error 0.2402(best: 0.2364)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5730 | Time 18.9353(18.4567) | Bit/dim 3.6534(3.6549) | Xent 0.6245(0.5909) | Loss 271.2156(299.6193) | Error 0.2344(0.2110) Steps 0(0.00) | Grad Norm 343.8515(216.7853) | Total Time 0.00(0.00)\n",
      "Iter 5740 | Time 18.1477(18.4693) | Bit/dim 3.6248(3.6520) | Xent 0.5170(0.5862) | Loss 249.2066(289.5898) | Error 0.1878(0.2078) Steps 0(0.00) | Grad Norm 203.1049(211.7270) | Total Time 0.00(0.00)\n",
      "Iter 5750 | Time 16.6647(18.4861) | Bit/dim 3.6597(3.6499) | Xent 0.6262(0.5870) | Loss 263.6862(282.8829) | Error 0.2256(0.2082) Steps 0(0.00) | Grad Norm 206.7531(212.7706) | Total Time 0.00(0.00)\n",
      "Iter 5760 | Time 17.8124(18.5873) | Bit/dim 3.6724(3.6515) | Xent 0.5289(0.5808) | Loss 260.6372(277.5454) | Error 0.1878(0.2063) Steps 0(0.00) | Grad Norm 197.5097(198.8031) | Total Time 0.00(0.00)\n",
      "Iter 5770 | Time 17.5121(18.7798) | Bit/dim 3.6549(3.6543) | Xent 0.5388(0.5771) | Loss 268.5249(274.8453) | Error 0.1944(0.2060) Steps 0(0.00) | Grad Norm 196.1575(195.9604) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 95.9527, Epoch Time 1136.4963(1078.8022), Bit/dim 3.6568(best: 3.6561), Xent 0.6959, Loss 4.0048, Error 0.2377(best: 0.2364)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5780 | Time 18.4772(18.5152) | Bit/dim 3.6663(3.6551) | Xent 0.5143(0.5697) | Loss 271.9070(306.1352) | Error 0.1878(0.2041) Steps 0(0.00) | Grad Norm 162.1449(200.3826) | Total Time 0.00(0.00)\n",
      "Iter 5790 | Time 18.5715(18.5233) | Bit/dim 3.6149(3.6541) | Xent 0.5937(0.5733) | Loss 267.1935(295.8950) | Error 0.2111(0.2045) Steps 0(0.00) | Grad Norm 221.0536(208.3380) | Total Time 0.00(0.00)\n",
      "Iter 5800 | Time 19.6744(18.4728) | Bit/dim 3.6507(3.6545) | Xent 0.5276(0.5639) | Loss 263.8226(286.4720) | Error 0.1833(0.2008) Steps 0(0.00) | Grad Norm 174.1991(202.2629) | Total Time 0.00(0.00)\n",
      "Iter 5810 | Time 18.7093(18.5526) | Bit/dim 3.6196(3.6523) | Xent 0.5956(0.5681) | Loss 254.8641(279.5074) | Error 0.2044(0.2026) Steps 0(0.00) | Grad Norm 113.2699(193.1399) | Total Time 0.00(0.00)\n",
      "Iter 5820 | Time 19.6473(18.6131) | Bit/dim 3.6336(3.6516) | Xent 0.5980(0.5660) | Loss 264.2122(275.0531) | Error 0.2078(0.2012) Steps 0(0.00) | Grad Norm 143.0609(184.0491) | Total Time 0.00(0.00)\n",
      "Iter 5830 | Time 18.0610(18.6284) | Bit/dim 3.6266(3.6486) | Xent 0.5441(0.5724) | Loss 261.8274(271.2815) | Error 0.1878(0.2056) Steps 0(0.00) | Grad Norm 202.8438(195.1942) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 96.0263, Epoch Time 1135.8283(1080.5130), Bit/dim 3.6514(best: 3.6561), Xent 0.7725, Loss 4.0377, Error 0.2652(best: 0.2364)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5840 | Time 18.2219(18.8551) | Bit/dim 3.6586(3.6527) | Xent 0.7023(0.5871) | Loss 267.8394(299.6052) | Error 0.2422(0.2111) Steps 0(0.00) | Grad Norm 290.0336(224.6154) | Total Time 0.00(0.00)\n",
      "Iter 5850 | Time 16.8072(18.7762) | Bit/dim 3.6755(3.6542) | Xent 0.5595(0.5822) | Loss 266.3128(290.3326) | Error 0.1933(0.2097) Steps 0(0.00) | Grad Norm 140.4343(208.7115) | Total Time 0.00(0.00)\n",
      "Iter 5860 | Time 17.3696(18.7602) | Bit/dim 3.6599(3.6534) | Xent 0.5550(0.5748) | Loss 260.7476(284.3252) | Error 0.1900(0.2068) Steps 0(0.00) | Grad Norm 160.0197(204.4850) | Total Time 0.00(0.00)\n",
      "Iter 5870 | Time 21.9340(18.7676) | Bit/dim 3.6485(3.6528) | Xent 0.5052(0.5697) | Loss 266.3428(278.6083) | Error 0.1889(0.2041) Steps 0(0.00) | Grad Norm 196.9099(198.3350) | Total Time 0.00(0.00)\n",
      "Iter 5880 | Time 20.2681(18.6813) | Bit/dim 3.6245(3.6520) | Xent 0.5878(0.5714) | Loss 264.6132(275.0018) | Error 0.2211(0.2055) Steps 0(0.00) | Grad Norm 172.1832(198.5912) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 95.9286, Epoch Time 1147.6963(1082.5285), Bit/dim 3.6574(best: 3.6514), Xent 0.7285, Loss 4.0217, Error 0.2505(best: 0.2364)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5890 | Time 18.3354(18.6563) | Bit/dim 3.6664(3.6552) | Xent 0.5830(0.5680) | Loss 258.0504(306.4537) | Error 0.2000(0.2031) Steps 0(0.00) | Grad Norm 190.2899(197.5341) | Total Time 0.00(0.00)\n",
      "Iter 5900 | Time 18.1714(18.6785) | Bit/dim 3.6993(3.6575) | Xent 0.5892(0.5636) | Loss 259.9764(295.2535) | Error 0.2089(0.2007) Steps 0(0.00) | Grad Norm 150.3744(188.2776) | Total Time 0.00(0.00)\n",
      "Iter 5910 | Time 19.4192(18.6661) | Bit/dim 3.5990(3.6536) | Xent 0.5573(0.5637) | Loss 253.3292(287.0894) | Error 0.2078(0.2004) Steps 0(0.00) | Grad Norm 142.6898(187.6291) | Total Time 0.00(0.00)\n",
      "Iter 5920 | Time 19.7370(18.8378) | Bit/dim 3.5989(3.6495) | Xent 0.5271(0.5653) | Loss 259.7953(281.2414) | Error 0.1856(0.2004) Steps 0(0.00) | Grad Norm 115.9349(203.8734) | Total Time 0.00(0.00)\n",
      "Iter 5930 | Time 18.5565(18.6910) | Bit/dim 3.6521(3.6473) | Xent 0.6061(0.5695) | Loss 272.6922(277.0551) | Error 0.2222(0.2023) Steps 0(0.00) | Grad Norm 309.0257(206.2487) | Total Time 0.00(0.00)\n",
      "Iter 5940 | Time 18.9758(18.6591) | Bit/dim 3.6371(3.6474) | Xent 0.5689(0.5673) | Loss 260.9304(273.9114) | Error 0.1967(0.2024) Steps 0(0.00) | Grad Norm 219.1681(198.7589) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 96.6079, Epoch Time 1140.8101(1084.2769), Bit/dim 3.6595(best: 3.6514), Xent 0.6988, Loss 4.0089, Error 0.2386(best: 0.2364)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5950 | Time 19.7745(18.5879) | Bit/dim 3.6702(3.6475) | Xent 0.4636(0.5540) | Loss 265.1657(300.3480) | Error 0.1722(0.1970) Steps 0(0.00) | Grad Norm 128.9937(191.5375) | Total Time 0.00(0.00)\n",
      "Iter 5960 | Time 19.0687(18.6132) | Bit/dim 3.6685(3.6478) | Xent 0.5311(0.5554) | Loss 266.7080(291.3540) | Error 0.2022(0.1985) Steps 0(0.00) | Grad Norm 223.3280(187.9072) | Total Time 0.00(0.00)\n",
      "Iter 5970 | Time 18.6165(18.6902) | Bit/dim 3.6276(3.6479) | Xent 0.5408(0.5506) | Loss 261.1430(284.0943) | Error 0.1778(0.1967) Steps 0(0.00) | Grad Norm 137.6418(197.2077) | Total Time 0.00(0.00)\n",
      "Iter 5980 | Time 18.6227(18.4920) | Bit/dim 3.6491(3.6463) | Xent 0.5361(0.5560) | Loss 264.5487(278.1473) | Error 0.1811(0.1991) Steps 0(0.00) | Grad Norm 224.3376(198.0663) | Total Time 0.00(0.00)\n",
      "Iter 5990 | Time 19.4480(18.6102) | Bit/dim 3.6422(3.6488) | Xent 0.5358(0.5522) | Loss 265.1018(274.3569) | Error 0.1844(0.1978) Steps 0(0.00) | Grad Norm 212.2883(190.5396) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 95.4459, Epoch Time 1133.6758(1085.7589), Bit/dim 3.6490(best: 3.6514), Xent 0.6803, Loss 3.9892, Error 0.2358(best: 0.2364)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6000 | Time 18.8957(18.6267) | Bit/dim 3.6552(3.6498) | Xent 0.5740(0.5560) | Loss 272.9723(304.9976) | Error 0.2011(0.1978) Steps 0(0.00) | Grad Norm 144.0247(192.8924) | Total Time 0.00(0.00)\n",
      "Iter 6010 | Time 19.1670(18.6764) | Bit/dim 3.6221(3.6467) | Xent 0.5063(0.5478) | Loss 256.2519(293.9053) | Error 0.1689(0.1945) Steps 0(0.00) | Grad Norm 221.2449(197.5589) | Total Time 0.00(0.00)\n",
      "Iter 6020 | Time 20.3575(18.6834) | Bit/dim 3.6547(3.6459) | Xent 0.4778(0.5443) | Loss 265.6642(285.8536) | Error 0.1633(0.1935) Steps 0(0.00) | Grad Norm 141.1709(198.5407) | Total Time 0.00(0.00)\n",
      "Iter 6030 | Time 20.7920(18.8690) | Bit/dim 3.6511(3.6449) | Xent 0.5750(0.5430) | Loss 255.2618(278.8857) | Error 0.1844(0.1932) Steps 0(0.00) | Grad Norm 219.9094(192.2696) | Total Time 0.00(0.00)\n",
      "Iter 6040 | Time 18.2836(18.7715) | Bit/dim 3.6602(3.6461) | Xent 0.5503(0.5543) | Loss 264.6560(275.2136) | Error 0.2144(0.1988) Steps 0(0.00) | Grad Norm 207.1794(200.1116) | Total Time 0.00(0.00)\n",
      "Iter 6050 | Time 19.6229(18.7827) | Bit/dim 3.6514(3.6474) | Xent 0.5109(0.5510) | Loss 266.6816(272.3982) | Error 0.1700(0.1973) Steps 0(0.00) | Grad Norm 197.0268(201.7764) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 94.8523, Epoch Time 1149.5241(1087.6718), Bit/dim 3.6557(best: 3.6490), Xent 0.6898, Loss 4.0006, Error 0.2399(best: 0.2358)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6060 | Time 19.8026(18.7290) | Bit/dim 3.6473(3.6474) | Xent 0.5088(0.5428) | Loss 264.6880(298.5829) | Error 0.1844(0.1940) Steps 0(0.00) | Grad Norm 133.8499(201.0460) | Total Time 0.00(0.00)\n",
      "Iter 6070 | Time 17.6493(18.7648) | Bit/dim 3.6363(3.6486) | Xent 0.4944(0.5442) | Loss 253.9235(288.8532) | Error 0.1789(0.1947) Steps 0(0.00) | Grad Norm 213.1739(205.8736) | Total Time 0.00(0.00)\n",
      "Iter 6080 | Time 17.7843(18.7372) | Bit/dim 3.6825(3.6499) | Xent 0.5804(0.5463) | Loss 262.4633(282.0565) | Error 0.2211(0.1957) Steps 0(0.00) | Grad Norm 137.2823(202.7258) | Total Time 0.00(0.00)\n",
      "Iter 6090 | Time 18.8228(18.7261) | Bit/dim 3.6535(3.6530) | Xent 0.6657(0.5567) | Loss 270.5654(277.3824) | Error 0.2367(0.1993) Steps 0(0.00) | Grad Norm 287.5997(213.7048) | Total Time 0.00(0.00)\n",
      "Iter 6100 | Time 18.0420(18.7478) | Bit/dim 3.6346(3.6498) | Xent 0.5120(0.5574) | Loss 255.4985(273.4066) | Error 0.1833(0.1995) Steps 0(0.00) | Grad Norm 228.2074(212.6772) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 93.8639, Epoch Time 1144.0896(1089.3644), Bit/dim 3.6578(best: 3.6490), Xent 0.6774, Loss 3.9965, Error 0.2348(best: 0.2358)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6110 | Time 18.8595(19.0310) | Bit/dim 3.6510(3.6477) | Xent 0.4967(0.5602) | Loss 264.5757(307.2191) | Error 0.1789(0.2006) Steps 0(0.00) | Grad Norm 181.8488(220.3780) | Total Time 0.00(0.00)\n",
      "Iter 6120 | Time 19.4288(18.9721) | Bit/dim 3.6647(3.6484) | Xent 0.6763(0.5640) | Loss 263.6334(295.8262) | Error 0.2167(0.2005) Steps 0(0.00) | Grad Norm 209.2628(226.3470) | Total Time 0.00(0.00)\n",
      "Iter 6130 | Time 17.5204(18.9494) | Bit/dim 3.6252(3.6466) | Xent 0.5714(0.5602) | Loss 265.9203(287.3927) | Error 0.2144(0.1995) Steps 0(0.00) | Grad Norm 296.8289(220.0082) | Total Time 0.00(0.00)\n",
      "Iter 6140 | Time 18.3112(19.0933) | Bit/dim 3.6532(3.6459) | Xent 0.5008(0.5519) | Loss 258.6828(281.3116) | Error 0.1633(0.1963) Steps 0(0.00) | Grad Norm 123.9551(204.7778) | Total Time 0.00(0.00)\n",
      "Iter 6150 | Time 18.4487(19.0632) | Bit/dim 3.6294(3.6444) | Xent 0.5691(0.5474) | Loss 262.2200(276.4956) | Error 0.2122(0.1948) Steps 0(0.00) | Grad Norm 190.7845(193.5932) | Total Time 0.00(0.00)\n",
      "Iter 6160 | Time 18.6335(19.1442) | Bit/dim 3.6081(3.6448) | Xent 0.5339(0.5446) | Loss 264.3593(273.3745) | Error 0.1922(0.1942) Steps 0(0.00) | Grad Norm 121.4365(185.2820) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 94.0825, Epoch Time 1170.0219(1091.7841), Bit/dim 3.6508(best: 3.6490), Xent 0.6647, Loss 3.9831, Error 0.2314(best: 0.2348)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6170 | Time 20.3709(19.1152) | Bit/dim 3.6463(3.6428) | Xent 0.5799(0.5415) | Loss 247.4170(299.9259) | Error 0.2100(0.1924) Steps 0(0.00) | Grad Norm 347.8417(183.6981) | Total Time 0.00(0.00)\n",
      "Iter 6180 | Time 19.5703(19.0496) | Bit/dim 3.6224(3.6435) | Xent 0.5262(0.5375) | Loss 259.5035(291.0525) | Error 0.2011(0.1917) Steps 0(0.00) | Grad Norm 201.6430(192.8226) | Total Time 0.00(0.00)\n",
      "Iter 6190 | Time 18.7458(18.9162) | Bit/dim 3.6342(3.6450) | Xent 0.5817(0.5384) | Loss 251.5435(282.4183) | Error 0.2078(0.1922) Steps 0(0.00) | Grad Norm 212.8838(199.5546) | Total Time 0.00(0.00)\n",
      "Iter 6200 | Time 19.7667(18.9805) | Bit/dim 3.6665(3.6473) | Xent 0.5045(0.5349) | Loss 266.6191(277.4621) | Error 0.1911(0.1917) Steps 0(0.00) | Grad Norm 166.7038(197.9853) | Total Time 0.00(0.00)\n",
      "Iter 6210 | Time 20.3271(19.0312) | Bit/dim 3.6298(3.6442) | Xent 0.5584(0.5355) | Loss 271.3957(274.0388) | Error 0.2056(0.1921) Steps 0(0.00) | Grad Norm 233.8607(197.7694) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 95.2789, Epoch Time 1153.3774(1093.6319), Bit/dim 3.6499(best: 3.6490), Xent 0.6716, Loss 3.9857, Error 0.2318(best: 0.2314)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6220 | Time 19.1121(18.9888) | Bit/dim 3.6785(3.6463) | Xent 0.5377(0.5412) | Loss 266.3318(306.6976) | Error 0.1922(0.1942) Steps 0(0.00) | Grad Norm 245.6247(201.3047) | Total Time 0.00(0.00)\n",
      "Iter 6230 | Time 19.5037(19.0169) | Bit/dim 3.6657(3.6460) | Xent 0.5613(0.5391) | Loss 264.7838(295.4252) | Error 0.1844(0.1930) Steps 0(0.00) | Grad Norm 142.2833(199.6803) | Total Time 0.00(0.00)\n",
      "Iter 6240 | Time 18.4243(19.1002) | Bit/dim 3.6647(3.6455) | Xent 0.5244(0.5364) | Loss 255.3099(287.1644) | Error 0.1967(0.1923) Steps 0(0.00) | Grad Norm 130.8837(193.0467) | Total Time 0.00(0.00)\n",
      "Iter 6250 | Time 19.4791(18.9571) | Bit/dim 3.6477(3.6463) | Xent 0.5479(0.5381) | Loss 262.3695(280.8129) | Error 0.1844(0.1925) Steps 0(0.00) | Grad Norm 312.3391(188.0267) | Total Time 0.00(0.00)\n",
      "Iter 6260 | Time 19.0738(18.9219) | Bit/dim 3.6420(3.6441) | Xent 0.5550(0.5330) | Loss 256.5670(276.1436) | Error 0.1978(0.1905) Steps 0(0.00) | Grad Norm 202.0307(184.9416) | Total Time 0.00(0.00)\n",
      "Iter 6270 | Time 22.1146(19.0551) | Bit/dim 3.6591(3.6433) | Xent 0.5388(0.5385) | Loss 256.3041(273.0415) | Error 0.1989(0.1936) Steps 0(0.00) | Grad Norm 186.6284(192.0075) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 97.1820, Epoch Time 1161.8894(1095.6796), Bit/dim 3.6506(best: 3.6490), Xent 0.6825, Loss 3.9918, Error 0.2341(best: 0.2314)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6280 | Time 20.2436(18.9979) | Bit/dim 3.6443(3.6434) | Xent 0.5430(0.5319) | Loss 268.0677(299.9158) | Error 0.1878(0.1904) Steps 0(0.00) | Grad Norm 264.8492(186.0406) | Total Time 0.00(0.00)\n",
      "Iter 6290 | Time 16.7679(18.8974) | Bit/dim 3.6586(3.6453) | Xent 0.6303(0.5441) | Loss 263.9748(291.0225) | Error 0.2256(0.1937) Steps 0(0.00) | Grad Norm 338.6799(211.7461) | Total Time 0.00(0.00)\n",
      "Iter 6300 | Time 18.3961(18.8945) | Bit/dim 3.6722(3.6455) | Xent 0.5476(0.5448) | Loss 271.3157(284.2092) | Error 0.1767(0.1943) Steps 0(0.00) | Grad Norm 213.6806(214.1438) | Total Time 0.00(0.00)\n",
      "Iter 6310 | Time 19.0408(18.8083) | Bit/dim 3.6284(3.6466) | Xent 0.5835(0.5461) | Loss 268.8994(278.6201) | Error 0.2033(0.1943) Steps 0(0.00) | Grad Norm 237.3742(210.8739) | Total Time 0.00(0.00)\n",
      "Iter 6320 | Time 18.9259(19.0363) | Bit/dim 3.6115(3.6445) | Xent 0.5508(0.5415) | Loss 261.9166(274.8963) | Error 0.1889(0.1925) Steps 0(0.00) | Grad Norm 262.4983(203.0089) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 94.0384, Epoch Time 1151.7536(1097.3618), Bit/dim 3.6440(best: 3.6490), Xent 0.7080, Loss 3.9980, Error 0.2364(best: 0.2314)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6330 | Time 18.1682(18.8952) | Bit/dim 3.6728(3.6447) | Xent 0.4727(0.5336) | Loss 263.7594(305.5598) | Error 0.1744(0.1903) Steps 0(0.00) | Grad Norm 149.4789(195.1906) | Total Time 0.00(0.00)\n",
      "Iter 6340 | Time 21.2536(19.0419) | Bit/dim 3.6349(3.6447) | Xent 0.5382(0.5364) | Loss 260.7495(294.5651) | Error 0.1922(0.1918) Steps 0(0.00) | Grad Norm 214.4615(199.7475) | Total Time 0.00(0.00)\n",
      "Iter 6350 | Time 17.6653(18.9136) | Bit/dim 3.6817(3.6460) | Xent 0.5789(0.5479) | Loss 258.7041(286.2932) | Error 0.2044(0.1954) Steps 0(0.00) | Grad Norm 200.6849(228.1368) | Total Time 0.00(0.00)\n",
      "Iter 6360 | Time 19.3990(18.8031) | Bit/dim 3.7000(3.6459) | Xent 0.5339(0.5409) | Loss 267.7394(279.9675) | Error 0.1822(0.1928) Steps 0(0.00) | Grad Norm 166.1088(211.8680) | Total Time 0.00(0.00)\n",
      "Iter 6370 | Time 16.9790(18.9850) | Bit/dim 3.5764(3.6442) | Xent 0.5450(0.5385) | Loss 260.2882(276.4192) | Error 0.1944(0.1907) Steps 0(0.00) | Grad Norm 206.6447(199.2453) | Total Time 0.00(0.00)\n",
      "Iter 6380 | Time 16.9100(18.9834) | Bit/dim 3.6258(3.6439) | Xent 0.5527(0.5333) | Loss 252.8100(273.3526) | Error 0.1956(0.1890) Steps 0(0.00) | Grad Norm 203.3901(190.5531) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 95.4077, Epoch Time 1154.2837(1099.0695), Bit/dim 3.6406(best: 3.6440), Xent 0.6837, Loss 3.9825, Error 0.2336(best: 0.2314)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6390 | Time 18.2623(18.8807) | Bit/dim 3.6408(3.6443) | Xent 0.5260(0.5292) | Loss 268.4007(299.9097) | Error 0.1911(0.1881) Steps 0(0.00) | Grad Norm 289.5014(204.1183) | Total Time 0.00(0.00)\n",
      "Iter 6400 | Time 18.9398(18.7775) | Bit/dim 3.6306(3.6452) | Xent 0.4773(0.5281) | Loss 247.7290(289.4138) | Error 0.1811(0.1882) Steps 0(0.00) | Grad Norm 165.6927(199.5519) | Total Time 0.00(0.00)\n",
      "Iter 6410 | Time 17.9041(18.6309) | Bit/dim 3.6526(3.6466) | Xent 0.5576(0.5298) | Loss 256.3058(281.8424) | Error 0.2122(0.1888) Steps 0(0.00) | Grad Norm 157.0122(196.1492) | Total Time 0.00(0.00)\n",
      "Iter 6420 | Time 19.5676(18.5084) | Bit/dim 3.6237(3.6441) | Xent 0.5697(0.5291) | Loss 263.5212(276.0218) | Error 0.1989(0.1894) Steps 0(0.00) | Grad Norm 133.6959(191.5943) | Total Time 0.00(0.00)\n",
      "Iter 6430 | Time 18.8443(18.7845) | Bit/dim 3.6375(3.6405) | Xent 0.5597(0.5244) | Loss 256.7389(271.9672) | Error 0.2089(0.1890) Steps 0(0.00) | Grad Norm 233.3358(186.5467) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 95.5083, Epoch Time 1139.7557(1100.2901), Bit/dim 3.6382(best: 3.6406), Xent 0.6728, Loss 3.9746, Error 0.2313(best: 0.2314)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6440 | Time 18.0243(18.8530) | Bit/dim 3.6454(3.6390) | Xent 0.4990(0.5231) | Loss 250.9202(304.6870) | Error 0.1811(0.1883) Steps 0(0.00) | Grad Norm 102.5222(177.1959) | Total Time 0.00(0.00)\n",
      "Iter 6450 | Time 18.8130(18.8732) | Bit/dim 3.6331(3.6394) | Xent 0.5086(0.5166) | Loss 262.6581(292.5496) | Error 0.1911(0.1854) Steps 0(0.00) | Grad Norm 181.1656(181.9241) | Total Time 0.00(0.00)\n",
      "Iter 6460 | Time 17.9255(18.9076) | Bit/dim 3.6227(3.6384) | Xent 0.5293(0.5122) | Loss 260.9403(284.5785) | Error 0.1900(0.1837) Steps 0(0.00) | Grad Norm 245.1362(187.2925) | Total Time 0.00(0.00)\n",
      "Iter 6470 | Time 18.8876(18.9538) | Bit/dim 3.6311(3.6375) | Xent 0.4787(0.5123) | Loss 258.0843(278.3484) | Error 0.1822(0.1833) Steps 0(0.00) | Grad Norm 182.1402(188.4756) | Total Time 0.00(0.00)\n",
      "Iter 6480 | Time 19.0946(19.0488) | Bit/dim 3.6199(3.6371) | Xent 0.5259(0.5125) | Loss 256.8757(273.7109) | Error 0.1833(0.1839) Steps 0(0.00) | Grad Norm 230.6210(190.1683) | Total Time 0.00(0.00)\n",
      "Iter 6490 | Time 17.7219(18.9728) | Bit/dim 3.6682(3.6388) | Xent 0.5369(0.5188) | Loss 255.1620(270.8213) | Error 0.1833(0.1860) Steps 0(0.00) | Grad Norm 226.6128(200.1692) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 97.0176, Epoch Time 1160.6022(1102.0994), Bit/dim 3.6381(best: 3.6382), Xent 0.6692, Loss 3.9727, Error 0.2290(best: 0.2313)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6500 | Time 19.7288(18.9098) | Bit/dim 3.6464(3.6372) | Xent 0.4379(0.5100) | Loss 261.7809(297.8879) | Error 0.1489(0.1828) Steps 0(0.00) | Grad Norm 151.4356(187.5080) | Total Time 0.00(0.00)\n",
      "Iter 6510 | Time 19.3558(19.0144) | Bit/dim 3.6388(3.6387) | Xent 0.5087(0.5095) | Loss 263.0511(288.5452) | Error 0.1933(0.1835) Steps 0(0.00) | Grad Norm 299.5119(199.9270) | Total Time 0.00(0.00)\n",
      "Iter 6520 | Time 18.7227(18.9952) | Bit/dim 3.6621(3.6406) | Xent 0.5466(0.5119) | Loss 263.1266(282.0738) | Error 0.1889(0.1843) Steps 0(0.00) | Grad Norm 283.5657(206.0335) | Total Time 0.00(0.00)\n",
      "Iter 6530 | Time 16.9891(18.8799) | Bit/dim 3.5915(3.6387) | Xent 0.5156(0.5169) | Loss 256.9513(276.9725) | Error 0.1844(0.1850) Steps 0(0.00) | Grad Norm 230.8831(202.6828) | Total Time 0.00(0.00)\n",
      "Iter 6540 | Time 20.0442(19.0356) | Bit/dim 3.6345(3.6396) | Xent 0.5126(0.5154) | Loss 270.7148(273.5215) | Error 0.1844(0.1845) Steps 0(0.00) | Grad Norm 130.1198(197.4089) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 94.4386, Epoch Time 1153.6392(1103.6456), Bit/dim 3.6468(best: 3.6381), Xent 0.7032, Loss 3.9984, Error 0.2343(best: 0.2290)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6550 | Time 18.6405(18.9012) | Bit/dim 3.6328(3.6416) | Xent 0.5370(0.5185) | Loss 258.8217(304.3574) | Error 0.1856(0.1839) Steps 0(0.00) | Grad Norm 315.0711(202.6807) | Total Time 0.00(0.00)\n",
      "Iter 6560 | Time 18.7890(18.8315) | Bit/dim 3.6842(3.6422) | Xent 0.5219(0.5179) | Loss 270.3007(293.2113) | Error 0.1822(0.1849) Steps 0(0.00) | Grad Norm 179.9995(200.0139) | Total Time 0.00(0.00)\n",
      "Iter 6570 | Time 17.1963(18.7970) | Bit/dim 3.6570(3.6404) | Xent 0.4690(0.5150) | Loss 254.4803(284.1510) | Error 0.1600(0.1839) Steps 0(0.00) | Grad Norm 147.0726(189.6248) | Total Time 0.00(0.00)\n",
      "Iter 6580 | Time 20.2470(19.0858) | Bit/dim 3.6497(3.6382) | Xent 0.4696(0.5092) | Loss 264.7969(278.7111) | Error 0.1556(0.1810) Steps 0(0.00) | Grad Norm 102.2027(178.9760) | Total Time 0.00(0.00)\n",
      "Iter 6590 | Time 20.4037(19.1336) | Bit/dim 3.6267(3.6362) | Xent 0.4993(0.5001) | Loss 267.8606(274.8202) | Error 0.1822(0.1783) Steps 0(0.00) | Grad Norm 147.2917(168.9963) | Total Time 0.00(0.00)\n",
      "Iter 6600 | Time 19.1385(19.0387) | Bit/dim 3.6514(3.6367) | Xent 0.5115(0.4986) | Loss 261.4913(271.3944) | Error 0.1767(0.1780) Steps 0(0.00) | Grad Norm 202.5337(185.7320) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 94.8603, Epoch Time 1159.5600(1105.3231), Bit/dim 3.6389(best: 3.6381), Xent 0.6881, Loss 3.9829, Error 0.2271(best: 0.2290)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6610 | Time 17.5175(18.9710) | Bit/dim 3.6610(3.6358) | Xent 0.4909(0.5024) | Loss 261.2685(297.8519) | Error 0.1811(0.1796) Steps 0(0.00) | Grad Norm 212.1309(205.5184) | Total Time 0.00(0.00)\n",
      "Iter 6620 | Time 17.5277(18.7971) | Bit/dim 3.6850(3.6366) | Xent 0.4647(0.5001) | Loss 261.9043(287.7078) | Error 0.1644(0.1777) Steps 0(0.00) | Grad Norm 192.4102(205.3215) | Total Time 0.00(0.00)\n",
      "Iter 6630 | Time 20.3099(18.9059) | Bit/dim 3.6183(3.6398) | Xent 0.4985(0.5034) | Loss 268.3057(281.9227) | Error 0.1644(0.1789) Steps 0(0.00) | Grad Norm 163.8387(198.6404) | Total Time 0.00(0.00)\n",
      "Iter 6640 | Time 18.8370(18.9143) | Bit/dim 3.6374(3.6405) | Xent 0.5531(0.5112) | Loss 264.7578(277.9029) | Error 0.2000(0.1816) Steps 0(0.00) | Grad Norm 230.4067(201.7370) | Total Time 0.00(0.00)\n",
      "Iter 6650 | Time 19.8303(18.9678) | Bit/dim 3.6530(3.6405) | Xent 0.4545(0.5119) | Loss 255.1451(273.8402) | Error 0.1800(0.1836) Steps 0(0.00) | Grad Norm 250.2623(213.2962) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 96.2505, Epoch Time 1151.8864(1106.7200), Bit/dim 3.6413(best: 3.6381), Xent 0.6685, Loss 3.9756, Error 0.2270(best: 0.2271)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6660 | Time 20.3340(18.9263) | Bit/dim 3.6148(3.6381) | Xent 0.4895(0.5092) | Loss 268.9667(305.4184) | Error 0.1733(0.1818) Steps 0(0.00) | Grad Norm 197.5835(203.0155) | Total Time 0.00(0.00)\n",
      "Iter 6670 | Time 19.9257(19.1528) | Bit/dim 3.6537(3.6403) | Xent 0.5139(0.5016) | Loss 261.1243(293.7361) | Error 0.1800(0.1767) Steps 0(0.00) | Grad Norm 237.7201(195.3753) | Total Time 0.00(0.00)\n",
      "Iter 6680 | Time 18.2027(19.1963) | Bit/dim 3.6358(3.6379) | Xent 0.4703(0.4950) | Loss 262.0197(285.2548) | Error 0.1656(0.1752) Steps 0(0.00) | Grad Norm 122.0241(185.0790) | Total Time 0.00(0.00)\n",
      "Iter 6690 | Time 18.9740(19.1126) | Bit/dim 3.6236(3.6343) | Xent 0.5035(0.4966) | Loss 260.4539(279.0473) | Error 0.1833(0.1769) Steps 0(0.00) | Grad Norm 281.3403(188.0757) | Total Time 0.00(0.00)\n",
      "Iter 6700 | Time 19.1463(18.9816) | Bit/dim 3.6763(3.6366) | Xent 0.5356(0.4994) | Loss 271.5461(274.2962) | Error 0.1978(0.1786) Steps 0(0.00) | Grad Norm 164.0342(191.9266) | Total Time 0.00(0.00)\n",
      "Iter 6710 | Time 20.4306(19.0909) | Bit/dim 3.6290(3.6351) | Xent 0.4939(0.5012) | Loss 259.0604(271.0160) | Error 0.1844(0.1796) Steps 0(0.00) | Grad Norm 296.7245(194.0749) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 98.0755, Epoch Time 1170.8347(1108.6434), Bit/dim 3.6410(best: 3.6381), Xent 0.7158, Loss 3.9988, Error 0.2381(best: 0.2270)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6720 | Time 18.7588(19.3050) | Bit/dim 3.6669(3.6357) | Xent 0.4928(0.4974) | Loss 260.3624(300.4505) | Error 0.1700(0.1776) Steps 0(0.00) | Grad Norm 150.0240(197.9776) | Total Time 0.00(0.00)\n",
      "Iter 6730 | Time 20.0010(19.3363) | Bit/dim 3.6122(3.6356) | Xent 0.5615(0.5028) | Loss 268.4408(291.5967) | Error 0.2022(0.1793) Steps 0(0.00) | Grad Norm 190.3444(206.3236) | Total Time 0.00(0.00)\n",
      "Iter 6740 | Time 19.7378(19.2689) | Bit/dim 3.6180(3.6349) | Xent 0.4966(0.5081) | Loss 260.6941(283.4105) | Error 0.1856(0.1801) Steps 0(0.00) | Grad Norm 177.0423(210.2483) | Total Time 0.00(0.00)\n",
      "Iter 6750 | Time 18.4071(19.1627) | Bit/dim 3.6251(3.6361) | Xent 0.4865(0.5040) | Loss 256.8079(277.6999) | Error 0.1878(0.1796) Steps 0(0.00) | Grad Norm 181.0171(207.9257) | Total Time 0.00(0.00)\n",
      "Iter 6760 | Time 19.3667(19.3986) | Bit/dim 3.6182(3.6362) | Xent 0.4792(0.5010) | Loss 264.3090(273.9561) | Error 0.1833(0.1790) Steps 0(0.00) | Grad Norm 171.6048(197.9186) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 94.8092, Epoch Time 1177.9377(1110.7222), Bit/dim 3.6388(best: 3.6381), Xent 0.6954, Loss 3.9866, Error 0.2346(best: 0.2270)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6770 | Time 20.0567(19.3270) | Bit/dim 3.6128(3.6359) | Xent 0.4977(0.5045) | Loss 270.9541(305.4431) | Error 0.1778(0.1799) Steps 0(0.00) | Grad Norm 190.1653(201.7883) | Total Time 0.00(0.00)\n",
      "Iter 6780 | Time 18.3477(19.4342) | Bit/dim 3.6274(3.6321) | Xent 0.5196(0.5004) | Loss 258.1308(293.6474) | Error 0.1811(0.1792) Steps 0(0.00) | Grad Norm 189.3227(189.2997) | Total Time 0.00(0.00)\n",
      "Iter 6790 | Time 18.2051(19.1984) | Bit/dim 3.6094(3.6333) | Xent 0.4180(0.4952) | Loss 257.9119(285.1675) | Error 0.1456(0.1764) Steps 0(0.00) | Grad Norm 179.3690(196.7127) | Total Time 0.00(0.00)\n",
      "Iter 6800 | Time 18.3494(19.1717) | Bit/dim 3.6241(3.6357) | Xent 0.5075(0.4964) | Loss 264.4866(279.5359) | Error 0.1811(0.1765) Steps 0(0.00) | Grad Norm 212.1908(189.7076) | Total Time 0.00(0.00)\n",
      "Iter 6810 | Time 19.1147(19.3370) | Bit/dim 3.6500(3.6352) | Xent 0.5298(0.4980) | Loss 271.1691(275.3454) | Error 0.1900(0.1772) Steps 0(0.00) | Grad Norm 194.4179(187.6555) | Total Time 0.00(0.00)\n",
      "Iter 6820 | Time 19.7509(19.1677) | Bit/dim 3.6161(3.6339) | Xent 0.4794(0.4972) | Loss 271.9035(270.7236) | Error 0.1678(0.1770) Steps 0(0.00) | Grad Norm 195.1430(186.2571) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 96.4789, Epoch Time 1172.4859(1112.5751), Bit/dim 3.6340(best: 3.6381), Xent 0.6880, Loss 3.9780, Error 0.2286(best: 0.2270)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6830 | Time 18.6956(19.2387) | Bit/dim 3.6193(3.6350) | Xent 0.4374(0.4909) | Loss 266.1043(298.1900) | Error 0.1578(0.1750) Steps 0(0.00) | Grad Norm 183.6089(187.5463) | Total Time 0.00(0.00)\n",
      "Iter 6840 | Time 19.5394(19.3159) | Bit/dim 3.6313(3.6337) | Xent 0.4402(0.4843) | Loss 261.9145(288.9103) | Error 0.1578(0.1733) Steps 0(0.00) | Grad Norm 144.2132(183.5130) | Total Time 0.00(0.00)\n",
      "Iter 6850 | Time 20.3239(19.2836) | Bit/dim 3.6314(3.6340) | Xent 0.5454(0.4855) | Loss 272.0165(281.5067) | Error 0.1978(0.1722) Steps 0(0.00) | Grad Norm 208.1910(184.9714) | Total Time 0.00(0.00)\n",
      "Iter 6860 | Time 18.6405(19.2347) | Bit/dim 3.6213(3.6336) | Xent 0.4422(0.4836) | Loss 256.5398(277.0239) | Error 0.1722(0.1722) Steps 0(0.00) | Grad Norm 195.0328(184.5001) | Total Time 0.00(0.00)\n",
      "Iter 6870 | Time 18.6667(19.2125) | Bit/dim 3.6391(3.6319) | Xent 0.4860(0.4866) | Loss 270.1744(273.0639) | Error 0.1800(0.1743) Steps 0(0.00) | Grad Norm 199.3796(184.7037) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 94.4971, Epoch Time 1169.6229(1114.2866), Bit/dim 3.6374(best: 3.6340), Xent 0.6658, Loss 3.9702, Error 0.2254(best: 0.2270)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6880 | Time 18.7005(19.1094) | Bit/dim 3.6185(3.6342) | Xent 0.4883(0.4915) | Loss 258.5103(304.0936) | Error 0.1800(0.1764) Steps 0(0.00) | Grad Norm 179.1886(184.2212) | Total Time 0.00(0.00)\n",
      "Iter 6890 | Time 19.0115(19.1429) | Bit/dim 3.6399(3.6348) | Xent 0.4530(0.4823) | Loss 265.2165(292.7360) | Error 0.1700(0.1733) Steps 0(0.00) | Grad Norm 155.3851(181.9264) | Total Time 0.00(0.00)\n",
      "Iter 6900 | Time 19.8286(19.2100) | Bit/dim 3.6413(3.6324) | Xent 0.4357(0.4791) | Loss 264.5872(284.4430) | Error 0.1522(0.1720) Steps 0(0.00) | Grad Norm 184.2192(184.7730) | Total Time 0.00(0.00)\n",
      "Iter 6910 | Time 18.5014(19.2077) | Bit/dim 3.6376(3.6339) | Xent 0.4792(0.4794) | Loss 254.9842(279.0898) | Error 0.1689(0.1728) Steps 0(0.00) | Grad Norm 166.7047(191.4674) | Total Time 0.00(0.00)\n",
      "Iter 6920 | Time 19.2352(19.2063) | Bit/dim 3.6353(3.6337) | Xent 0.4948(0.4802) | Loss 269.4158(274.3825) | Error 0.1689(0.1716) Steps 0(0.00) | Grad Norm 150.5396(179.2514) | Total Time 0.00(0.00)\n",
      "Iter 6930 | Time 20.1193(19.3552) | Bit/dim 3.6406(3.6325) | Xent 0.5413(0.4881) | Loss 266.0204(271.8124) | Error 0.1922(0.1740) Steps 0(0.00) | Grad Norm 171.7265(181.4340) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 96.5378, Epoch Time 1177.2966(1116.1769), Bit/dim 3.6336(best: 3.6340), Xent 0.6546, Loss 3.9609, Error 0.2201(best: 0.2254)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6940 | Time 20.8400(19.2676) | Bit/dim 3.6364(3.6325) | Xent 0.4517(0.4863) | Loss 268.5586(300.9091) | Error 0.1678(0.1748) Steps 0(0.00) | Grad Norm 210.0138(201.9059) | Total Time 0.00(0.00)\n",
      "Iter 6950 | Time 19.5840(19.1393) | Bit/dim 3.6766(3.6360) | Xent 0.5868(0.4884) | Loss 273.6985(290.5137) | Error 0.2111(0.1760) Steps 0(0.00) | Grad Norm 250.4863(206.7781) | Total Time 0.00(0.00)\n",
      "Iter 6960 | Time 19.1514(19.0321) | Bit/dim 3.6175(3.6368) | Xent 0.4531(0.4862) | Loss 265.3097(283.4241) | Error 0.1778(0.1753) Steps 0(0.00) | Grad Norm 132.3984(204.5912) | Total Time 0.00(0.00)\n",
      "Iter 6970 | Time 20.7585(19.2761) | Bit/dim 3.6449(3.6351) | Xent 0.5483(0.4868) | Loss 275.4090(278.1581) | Error 0.1989(0.1734) Steps 0(0.00) | Grad Norm 351.4440(204.6159) | Total Time 0.00(0.00)\n",
      "Iter 6980 | Time 17.8361(19.2271) | Bit/dim 3.6259(3.6369) | Xent 0.4439(0.4933) | Loss 248.5055(274.1025) | Error 0.1467(0.1742) Steps 0(0.00) | Grad Norm 106.2790(213.1144) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 94.5523, Epoch Time 1157.2943(1117.4104), Bit/dim 3.6451(best: 3.6336), Xent 0.6657, Loss 3.9779, Error 0.2269(best: 0.2201)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6990 | Time 20.7398(19.0621) | Bit/dim 3.6196(3.6319) | Xent 0.4590(0.4874) | Loss 260.6300(305.0855) | Error 0.1722(0.1726) Steps 0(0.00) | Grad Norm 153.4628(196.6733) | Total Time 0.00(0.00)\n",
      "Iter 7000 | Time 18.2361(19.3901) | Bit/dim 3.6371(3.6320) | Xent 0.4362(0.4732) | Loss 251.2835(293.9761) | Error 0.1733(0.1680) Steps 0(0.00) | Grad Norm 235.1282(193.3713) | Total Time 0.00(0.00)\n",
      "Iter 7010 | Time 19.5854(19.3058) | Bit/dim 3.6478(3.6343) | Xent 0.5185(0.4728) | Loss 267.6446(285.9281) | Error 0.1889(0.1687) Steps 0(0.00) | Grad Norm 189.2914(193.6710) | Total Time 0.00(0.00)\n",
      "Iter 7020 | Time 19.1586(19.2262) | Bit/dim 3.6407(3.6336) | Xent 0.5037(0.4773) | Loss 267.0803(279.1938) | Error 0.1733(0.1704) Steps 0(0.00) | Grad Norm 274.4042(204.0202) | Total Time 0.00(0.00)\n",
      "Iter 7030 | Time 21.1984(19.2280) | Bit/dim 3.5950(3.6318) | Xent 0.4798(0.4763) | Loss 266.9070(274.0823) | Error 0.1656(0.1702) Steps 0(0.00) | Grad Norm 141.2900(197.2947) | Total Time 0.00(0.00)\n",
      "Iter 7040 | Time 22.1728(19.3496) | Bit/dim 3.6361(3.6301) | Xent 0.5083(0.4757) | Loss 270.4827(270.7726) | Error 0.1767(0.1705) Steps 0(0.00) | Grad Norm 244.5622(191.5603) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 98.1988, Epoch Time 1184.3534(1119.4187), Bit/dim 3.6311(best: 3.6336), Xent 0.6774, Loss 3.9698, Error 0.2293(best: 0.2201)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7050 | Time 21.8470(19.3421) | Bit/dim 3.5957(3.6299) | Xent 0.4044(0.4748) | Loss 255.7988(299.6837) | Error 0.1522(0.1693) Steps 0(0.00) | Grad Norm 198.4923(199.1139) | Total Time 0.00(0.00)\n",
      "Iter 7060 | Time 21.2527(19.5343) | Bit/dim 3.6186(3.6309) | Xent 0.4718(0.4766) | Loss 265.2073(290.3271) | Error 0.1667(0.1706) Steps 0(0.00) | Grad Norm 142.3432(198.9007) | Total Time 0.00(0.00)\n",
      "Iter 7070 | Time 20.1927(19.3729) | Bit/dim 3.6396(3.6316) | Xent 0.4697(0.4873) | Loss 268.6539(283.3047) | Error 0.1733(0.1747) Steps 0(0.00) | Grad Norm 185.9173(208.1328) | Total Time 0.00(0.00)\n",
      "Iter 7080 | Time 20.1698(19.3956) | Bit/dim 3.6872(3.6339) | Xent 0.5519(0.4948) | Loss 270.8761(278.0965) | Error 0.1967(0.1774) Steps 0(0.00) | Grad Norm 177.1568(202.9709) | Total Time 0.00(0.00)\n",
      "Iter 7090 | Time 20.3769(19.5906) | Bit/dim 3.6019(3.6305) | Xent 0.4815(0.4926) | Loss 269.2193(274.7028) | Error 0.1822(0.1770) Steps 0(0.00) | Grad Norm 179.9145(188.1022) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 97.5518, Epoch Time 1190.6774(1121.5564), Bit/dim 3.6341(best: 3.6311), Xent 0.6627, Loss 3.9654, Error 0.2215(best: 0.2201)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7100 | Time 22.7699(19.7275) | Bit/dim 3.6521(3.6318) | Xent 0.4772(0.4862) | Loss 259.7336(308.9155) | Error 0.1567(0.1735) Steps 0(0.00) | Grad Norm 156.7635(182.2850) | Total Time 0.00(0.00)\n",
      "Iter 7110 | Time 18.3052(19.6049) | Bit/dim 3.6553(3.6302) | Xent 0.5112(0.4915) | Loss 262.7174(296.7677) | Error 0.1878(0.1752) Steps 0(0.00) | Grad Norm 146.5408(188.3995) | Total Time 0.00(0.00)\n",
      "Iter 7120 | Time 19.8744(19.5375) | Bit/dim 3.6406(3.6298) | Xent 0.4625(0.4880) | Loss 266.6631(287.1839) | Error 0.1578(0.1740) Steps 0(0.00) | Grad Norm 230.9124(187.4074) | Total Time 0.00(0.00)\n",
      "Iter 7130 | Time 19.0624(19.4553) | Bit/dim 3.6696(3.6293) | Xent 0.4711(0.4845) | Loss 258.4233(280.4970) | Error 0.1822(0.1730) Steps 0(0.00) | Grad Norm 128.4133(184.8730) | Total Time 0.00(0.00)\n",
      "Iter 7140 | Time 20.2064(19.4482) | Bit/dim 3.6116(3.6308) | Xent 0.5163(0.4809) | Loss 272.0430(276.6383) | Error 0.1856(0.1730) Steps 0(0.00) | Grad Norm 224.3371(185.7825) | Total Time 0.00(0.00)\n",
      "Iter 7150 | Time 20.4399(19.5909) | Bit/dim 3.6259(3.6291) | Xent 0.4390(0.4736) | Loss 273.2699(273.0247) | Error 0.1544(0.1697) Steps 0(0.00) | Grad Norm 182.3593(186.6922) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 98.9003, Epoch Time 1199.2376(1123.8869), Bit/dim 3.6263(best: 3.6311), Xent 0.6910, Loss 3.9719, Error 0.2252(best: 0.2201)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7160 | Time 19.4664(19.4760) | Bit/dim 3.6425(3.6290) | Xent 0.4541(0.4692) | Loss 274.2607(302.1842) | Error 0.1678(0.1686) Steps 0(0.00) | Grad Norm 154.5949(185.0310) | Total Time 0.00(0.00)\n",
      "Iter 7170 | Time 19.7310(19.5005) | Bit/dim 3.6494(3.6286) | Xent 0.4794(0.4722) | Loss 263.0227(292.2102) | Error 0.1722(0.1680) Steps 0(0.00) | Grad Norm 138.6828(197.5658) | Total Time 0.00(0.00)\n",
      "Iter 7180 | Time 18.3892(19.5545) | Bit/dim 3.6271(3.6290) | Xent 0.4746(0.4710) | Loss 264.6834(284.7417) | Error 0.1756(0.1683) Steps 0(0.00) | Grad Norm 180.6318(198.2923) | Total Time 0.00(0.00)\n",
      "Iter 7190 | Time 20.4581(19.6043) | Bit/dim 3.6503(3.6286) | Xent 0.4559(0.4727) | Loss 254.3669(278.6897) | Error 0.1733(0.1695) Steps 0(0.00) | Grad Norm 184.2004(199.8386) | Total Time 0.00(0.00)\n",
      "Iter 7200 | Time 19.6294(19.5287) | Bit/dim 3.6372(3.6258) | Xent 0.5024(0.4719) | Loss 268.7612(274.7844) | Error 0.1778(0.1678) Steps 0(0.00) | Grad Norm 156.6461(188.6178) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 96.2076, Epoch Time 1183.7450(1125.6826), Bit/dim 3.6334(best: 3.6263), Xent 0.6592, Loss 3.9630, Error 0.2251(best: 0.2201)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7210 | Time 19.1960(19.3693) | Bit/dim 3.6405(3.6283) | Xent 0.4708(0.4775) | Loss 264.5144(304.5411) | Error 0.1478(0.1690) Steps 0(0.00) | Grad Norm 244.7815(199.1068) | Total Time 0.00(0.00)\n",
      "Iter 7220 | Time 21.3691(19.5186) | Bit/dim 3.6152(3.6277) | Xent 0.5382(0.4768) | Loss 267.3920(293.7953) | Error 0.2022(0.1698) Steps 0(0.00) | Grad Norm 173.9582(207.6270) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_rlw_0_5_run1 --seed 1 --lr 0.001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5 --scale_fac 1.0 --scale_std 6.0 --rl-weight 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
