{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, eta=0.1, gamma=0.99, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume=None, rl_weight=5.0, rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_rlw_5_0_run1', scale=1.0, scale_fac=1.0, scale_std=6.0, seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1450732\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 0010 | Time 12.6688(27.4233) | Bit/dim 8.6899(8.9523) | Xent 2.2805(2.3001) | Loss 5558.6494(5622.9941) | Error 0.7989(0.8603) Steps 0(0.00) | Grad Norm 5611.9624(7099.0090) | Total Time 0.00(0.00)\n",
      "Iter 0020 | Time 12.4773(23.5320) | Bit/dim 8.4867(8.8631) | Xent 2.2264(2.2873) | Loss 5439.1323(5566.9614) | Error 0.7300(0.8327) Steps 0(0.00) | Grad Norm 2333.1248(6141.9165) | Total Time 0.00(0.00)\n",
      "Iter 0030 | Time 12.5886(20.6737) | Bit/dim 8.3929(8.7515) | Xent 2.1744(2.2634) | Loss 5524.4507(5508.9014) | Error 0.7567(0.8098) Steps 0(0.00) | Grad Norm 2367.2626(5046.3962) | Total Time 0.00(0.00)\n",
      "Iter 0040 | Time 13.2257(18.5425) | Bit/dim 8.1913(8.6234) | Xent 2.1128(2.2346) | Loss 5244.1768(5443.6419) | Error 0.7244(0.7921) Steps 0(0.00) | Grad Norm 1436.2824(4143.9581) | Total Time 0.00(0.00)\n",
      "Iter 0050 | Time 12.6452(16.9774) | Bit/dim 7.9737(8.4737) | Xent 2.1032(2.2020) | Loss 5031.4795(5362.0042) | Error 0.7056(0.7762) Steps 0(0.00) | Grad Norm 1376.9291(3443.0498) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 77.3499, Epoch Time 812.3923(812.3923), Bit/dim 7.7693(best: inf), Xent 2.0786, Loss 8.8086, Error 0.7007(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0060 | Time 12.9696(15.9151) | Bit/dim 7.6772(8.2912) | Xent 2.0786(2.1721) | Loss 4860.8530(5536.8166) | Error 0.7056(0.7591) Steps 0(0.00) | Grad Norm 1429.6143(2905.6827) | Total Time 0.00(0.00)\n",
      "Iter 0070 | Time 12.6314(15.1143) | Bit/dim 7.3718(8.0804) | Xent 2.0573(2.1464) | Loss 4846.8833(5358.6433) | Error 0.6778(0.7420) Steps 0(0.00) | Grad Norm 1046.3012(2456.8249) | Total Time 0.00(0.00)\n",
      "Iter 0080 | Time 12.9096(14.5492) | Bit/dim 7.1864(7.8636) | Xent 2.0711(2.1259) | Loss 4728.0503(5186.6726) | Error 0.6700(0.7274) Steps 0(0.00) | Grad Norm 852.3122(2053.0441) | Total Time 0.00(0.00)\n",
      "Iter 0090 | Time 12.5511(14.1364) | Bit/dim 7.0825(7.6689) | Xent 2.0855(2.1131) | Loss 4705.2476(5042.8508) | Error 0.7333(0.7188) Steps 0(0.00) | Grad Norm 540.3870(1690.1339) | Total Time 0.00(0.00)\n",
      "Iter 0100 | Time 14.0367(13.8913) | Bit/dim 7.0015(7.5061) | Xent 2.0640(2.1034) | Loss 4689.9390(4931.6361) | Error 0.6922(0.7126) Steps 0(0.00) | Grad Norm 869.5384(1448.5949) | Total Time 0.00(0.00)\n",
      "Iter 0110 | Time 13.4285(13.7731) | Bit/dim 7.0037(7.3754) | Xent 2.0619(2.0950) | Loss 4738.0200(4849.9457) | Error 0.7333(0.7121) Steps 0(0.00) | Grad Norm 593.7220(1222.8578) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 76.2372, Epoch Time 812.3725(812.3917), Bit/dim 6.9921(best: 7.7693), Xent 2.0585, Loss 8.0214, Error 0.6951(best: 0.7007)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0120 | Time 14.1776(13.9368) | Bit/dim 6.9410(7.2695) | Xent 2.0541(2.0856) | Loss 4525.5923(5053.5444) | Error 0.7122(0.7101) Steps 0(0.00) | Grad Norm 444.1951(1073.0440) | Total Time 0.00(0.00)\n",
      "Iter 0130 | Time 13.5254(14.0191) | Bit/dim 6.9197(7.1828) | Xent 2.0397(2.0747) | Loss 4608.2910(4921.6843) | Error 0.6889(0.7050) Steps 0(0.00) | Grad Norm 741.5891(951.5011) | Total Time 0.00(0.00)\n",
      "Iter 0140 | Time 16.2775(14.1003) | Bit/dim 6.8948(7.1069) | Xent 2.0481(2.0650) | Loss 4556.8003(4817.6655) | Error 0.6933(0.7020) Steps 0(0.00) | Grad Norm 2142.9212(989.8210) | Total Time 0.00(0.00)\n",
      "Iter 0150 | Time 14.9873(14.2037) | Bit/dim 6.7856(7.0356) | Xent 2.0138(2.0566) | Loss 4361.2773(4723.6885) | Error 0.7056(0.7000) Steps 0(0.00) | Grad Norm 1060.5733(1262.0160) | Total Time 0.00(0.00)\n",
      "Iter 0160 | Time 15.7551(14.3131) | Bit/dim 6.7046(6.9609) | Xent 2.0382(2.0520) | Loss 4531.0332(4663.8356) | Error 0.7156(0.6986) Steps 0(0.00) | Grad Norm 5707.1771(1924.5069) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 78.4241, Epoch Time 890.7561(814.7426), Bit/dim 6.6372(best: 6.9921), Xent 2.0356, Loss 7.6550, Error 0.7025(best: 0.6951)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0170 | Time 14.9398(14.4693) | Bit/dim 6.6127(6.8783) | Xent 2.0517(2.0528) | Loss 4518.7520(4919.7938) | Error 0.7311(0.7041) Steps 0(0.00) | Grad Norm 12122.3475(3717.4942) | Total Time 0.00(0.00)\n",
      "Iter 0180 | Time 15.8584(14.6188) | Bit/dim 6.4371(6.7766) | Xent 2.1665(2.0532) | Loss 4321.6475(4772.3060) | Error 0.7967(0.7126) Steps 0(0.00) | Grad Norm 25346.4817(5684.2249) | Total Time 0.00(0.00)\n",
      "Iter 0190 | Time 13.4078(14.5543) | Bit/dim 6.2421(6.6600) | Xent 2.0647(2.0592) | Loss 4229.8408(4650.6522) | Error 0.7156(0.7197) Steps 0(0.00) | Grad Norm 16072.0154(8205.6496) | Total Time 0.00(0.00)\n",
      "Iter 0200 | Time 13.8277(14.5742) | Bit/dim 6.0629(6.5269) | Xent 2.0552(2.0586) | Loss 4121.7856(4532.1440) | Error 0.6933(0.7188) Steps 0(0.00) | Grad Norm 11286.7755(9617.9723) | Total Time 0.00(0.00)\n",
      "Iter 0210 | Time 14.2067(14.6830) | Bit/dim 5.9620(6.3973) | Xent 2.0651(2.0763) | Loss 4130.3853(4422.6627) | Error 0.7122(0.7301) Steps 0(0.00) | Grad Norm 6719.5283(13053.3089) | Total Time 0.00(0.00)\n",
      "Iter 0220 | Time 13.9838(14.5907) | Bit/dim 5.8256(6.2610) | Xent 2.0349(2.0682) | Loss 4085.4377(4320.4879) | Error 0.6733(0.7209) Steps 0(0.00) | Grad Norm 7460.8492(11469.3294) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 77.5756, Epoch Time 903.6278(817.4092), Bit/dim 5.8237(best: 6.6372), Xent 2.0239, Loss 6.8357, Error 0.6740(best: 0.6951)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0230 | Time 14.6918(14.7271) | Bit/dim 5.8330(6.1405) | Xent 2.1262(2.0573) | Loss 3975.3918(4491.7429) | Error 0.7556(0.7135) Steps 0(0.00) | Grad Norm 22770.4001(10492.3288) | Total Time 0.00(0.00)\n",
      "Iter 0240 | Time 14.5704(14.5879) | Bit/dim 5.7554(6.0390) | Xent 2.0123(2.0530) | Loss 4049.6335(4340.2637) | Error 0.7044(0.7140) Steps 0(0.00) | Grad Norm 7673.9739(10615.0536) | Total Time 0.00(0.00)\n",
      "Iter 0250 | Time 13.6798(14.3938) | Bit/dim 5.6760(5.9523) | Xent 1.9758(2.0405) | Loss 3869.5513(4233.9470) | Error 0.6567(0.7038) Steps 0(0.00) | Grad Norm 1413.1112(9081.0528) | Total Time 0.00(0.00)\n",
      "Iter 0260 | Time 13.7092(14.2376) | Bit/dim 5.7172(5.8770) | Xent 2.3125(2.0391) | Loss 3988.1418(4159.5149) | Error 0.8300(0.7032) Steps 0(0.00) | Grad Norm 50172.7459(10865.2014) | Total Time 0.00(0.00)\n",
      "Iter 0270 | Time 13.3198(14.2144) | Bit/dim 5.6361(5.8249) | Xent 1.9971(2.0372) | Loss 3630.0806(4100.5510) | Error 0.6767(0.7005) Steps 0(0.00) | Grad Norm 6871.6708(11466.4992) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 76.1038, Epoch Time 873.5907(819.0946), Bit/dim 5.6257(best: 5.8237), Xent 1.9774, Loss 6.6144, Error 0.6702(best: 0.6740)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0280 | Time 14.0485(14.1349) | Bit/dim 5.5536(5.7678) | Xent 1.9808(2.0251) | Loss 3938.5449(4328.6671) | Error 0.6844(0.6953) Steps 0(0.00) | Grad Norm 3916.3841(9790.2592) | Total Time 0.00(0.00)\n",
      "Iter 0290 | Time 13.3465(13.9293) | Bit/dim 5.6004(5.7239) | Xent 1.9303(2.0088) | Loss 3904.7871(4206.1410) | Error 0.6567(0.6880) Steps 0(0.00) | Grad Norm 3633.2265(7817.0640) | Total Time 0.00(0.00)\n",
      "Iter 0300 | Time 13.1106(13.8451) | Bit/dim 5.5380(5.6859) | Xent 1.9732(2.0014) | Loss 3814.1333(4120.6646) | Error 0.7111(0.6874) Steps 0(0.00) | Grad Norm 10368.3678(8306.4076) | Total Time 0.00(0.00)\n",
      "Iter 0310 | Time 13.2990(13.7921) | Bit/dim 5.4960(5.6452) | Xent 1.9632(1.9910) | Loss 3619.6670(4046.6871) | Error 0.6600(0.6844) Steps 0(0.00) | Grad Norm 2792.9659(7482.8468) | Total Time 0.00(0.00)\n",
      "Iter 0320 | Time 14.2488(13.8689) | Bit/dim 5.5037(5.6087) | Xent 1.9208(1.9805) | Loss 3795.9895(3982.6727) | Error 0.6556(0.6805) Steps 0(0.00) | Grad Norm 4428.3078(6843.8772) | Total Time 0.00(0.00)\n",
      "Iter 0330 | Time 14.7234(13.9950) | Bit/dim 5.5166(5.5810) | Xent 1.9118(1.9688) | Loss 3839.2161(3936.2862) | Error 0.6511(0.6753) Steps 0(0.00) | Grad Norm 6962.1173(6607.9218) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 77.4209, Epoch Time 855.4356(820.1849), Bit/dim 5.4760(best: 5.6257), Xent 1.8995, Loss 6.4258, Error 0.6395(best: 0.6702)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0340 | Time 14.3672(14.0215) | Bit/dim 5.4552(5.5517) | Xent 1.9293(1.9558) | Loss 3842.8699(4166.6520) | Error 0.6444(0.6707) Steps 0(0.00) | Grad Norm 3197.7607(6416.8454) | Total Time 0.00(0.00)\n",
      "Iter 0350 | Time 13.9620(14.0657) | Bit/dim 5.3705(5.5117) | Xent 1.8906(1.9412) | Loss 3782.7363(4065.3661) | Error 0.6456(0.6677) Steps 0(0.00) | Grad Norm 9260.2974(7081.5230) | Total Time 0.00(0.00)\n",
      "Iter 0360 | Time 14.4972(14.1418) | Bit/dim 5.3544(5.4765) | Xent 2.0098(1.9374) | Loss 3706.4678(3979.0791) | Error 0.7200(0.6700) Steps 0(0.00) | Grad Norm 12064.9195(7791.6609) | Total Time 0.00(0.00)\n",
      "Iter 0370 | Time 14.3323(14.2939) | Bit/dim 5.3431(5.4464) | Xent 1.9269(1.9460) | Loss 3693.3083(3921.9770) | Error 0.6744(0.6757) Steps 0(0.00) | Grad Norm 8980.5644(8963.0019) | Total Time 0.00(0.00)\n",
      "Iter 0380 | Time 14.2467(14.4407) | Bit/dim 5.3195(5.4154) | Xent 1.9179(1.9414) | Loss 3646.3137(3873.6765) | Error 0.6844(0.6744) Steps 0(0.00) | Grad Norm 5441.1303(8434.5676) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 79.6053, Epoch Time 892.8183(822.3639), Bit/dim 5.2768(best: 5.4760), Xent 1.8826, Loss 6.2181, Error 0.6284(best: 0.6395)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0390 | Time 15.6888(14.5445) | Bit/dim 5.2309(5.3855) | Xent 1.8853(1.9362) | Loss 3725.3940(4139.4757) | Error 0.6522(0.6726) Steps 0(0.00) | Grad Norm 4786.5525(7401.5388) | Total Time 0.00(0.00)\n",
      "Iter 0400 | Time 15.1325(14.5847) | Bit/dim 5.2777(5.3498) | Xent 1.8927(1.9250) | Loss 3819.7017(4024.2744) | Error 0.6589(0.6680) Steps 0(0.00) | Grad Norm 5182.3945(6932.4256) | Total Time 0.00(0.00)\n",
      "Iter 0410 | Time 15.0687(14.6443) | Bit/dim 5.3616(5.3293) | Xent 2.0500(1.9500) | Loss 3717.6733(3954.1726) | Error 0.7322(0.6814) Steps 0(0.00) | Grad Norm 13903.5745(8325.7050) | Total Time 0.00(0.00)\n",
      "Iter 0420 | Time 16.4971(14.6842) | Bit/dim 5.2276(5.3009) | Xent 1.8713(1.9482) | Loss 3744.3176(3886.5389) | Error 0.6722(0.6811) Steps 0(0.00) | Grad Norm 3292.9370(7462.8589) | Total Time 0.00(0.00)\n",
      "Iter 0430 | Time 14.9455(14.8159) | Bit/dim 5.2144(5.2681) | Xent 1.9579(1.9395) | Loss 3727.3755(3820.5843) | Error 0.6900(0.6765) Steps 0(0.00) | Grad Norm 11841.2110(6649.4200) | Total Time 0.00(0.00)\n",
      "Iter 0440 | Time 15.0511(14.8874) | Bit/dim 5.2300(5.2377) | Xent 1.9030(1.9340) | Loss 3635.3083(3772.3357) | Error 0.6656(0.6755) Steps 0(0.00) | Grad Norm 7303.9239(6822.2894) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 79.2454, Epoch Time 916.5366(825.1890), Bit/dim 5.1164(best: 5.2768), Xent 1.8591, Loss 6.0460, Error 0.6318(best: 0.6284)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0450 | Time 15.0780(14.8039) | Bit/dim 5.1221(5.2080) | Xent 1.9060(1.9218) | Loss 3478.2656(4007.1083) | Error 0.6656(0.6696) Steps 0(0.00) | Grad Norm 5748.0544(5871.9349) | Total Time 0.00(0.00)\n",
      "Iter 0460 | Time 16.2380(15.0080) | Bit/dim 5.0883(5.1745) | Xent 1.9328(1.9084) | Loss 3666.8472(3906.2377) | Error 0.7089(0.6645) Steps 0(0.00) | Grad Norm 8206.6632(5943.9923) | Total Time 0.00(0.00)\n",
      "Iter 0470 | Time 15.7510(15.1147) | Bit/dim 5.0591(5.1451) | Xent 1.8650(1.8960) | Loss 3506.8066(3823.7100) | Error 0.6578(0.6605) Steps 0(0.00) | Grad Norm 5879.9166(5798.7231) | Total Time 0.00(0.00)\n",
      "Iter 0480 | Time 16.3115(15.1869) | Bit/dim 5.0144(5.1131) | Xent 1.8514(1.8910) | Loss 3612.4348(3754.2257) | Error 0.6422(0.6602) Steps 0(0.00) | Grad Norm 5494.3560(6143.3569) | Total Time 0.00(0.00)\n",
      "Iter 0490 | Time 14.7858(15.2352) | Bit/dim 5.0627(5.0930) | Xent 2.0042(1.8944) | Loss 3684.1130(3714.3485) | Error 0.6944(0.6631) Steps 0(0.00) | Grad Norm 13754.1623(7412.2240) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 82.7053, Epoch Time 939.3113(828.6127), Bit/dim 5.0048(best: 5.1164), Xent 1.8910, Loss 5.9503, Error 0.6866(best: 0.6284)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0500 | Time 15.0745(15.2179) | Bit/dim 4.9465(5.0641) | Xent 1.8894(1.9010) | Loss 3433.9390(3952.0074) | Error 0.6667(0.6668) Steps 0(0.00) | Grad Norm 5068.5334(7626.4391) | Total Time 0.00(0.00)\n",
      "Iter 0510 | Time 15.4034(15.2593) | Bit/dim 4.9560(5.0344) | Xent 1.8583(1.8904) | Loss 3574.9824(3840.4144) | Error 0.6411(0.6637) Steps 0(0.00) | Grad Norm 11251.7909(7506.7024) | Total Time 0.00(0.00)\n",
      "Iter 0520 | Time 15.7006(15.4397) | Bit/dim 4.9540(5.0072) | Xent 1.8613(1.8768) | Loss 3633.0488(3762.9595) | Error 0.6578(0.6586) Steps 0(0.00) | Grad Norm 18691.5531(7890.8677) | Total Time 0.00(0.00)\n",
      "Iter 0530 | Time 15.0770(15.6283) | Bit/dim 4.8763(4.9836) | Xent 1.8860(1.8758) | Loss 3372.3750(3707.0814) | Error 0.6733(0.6582) Steps 0(0.00) | Grad Norm 2506.5837(8013.6478) | Total Time 0.00(0.00)\n",
      "Iter 0540 | Time 16.3675(15.8206) | Bit/dim 4.8577(4.9570) | Xent 1.8451(1.8663) | Loss 3548.7402(3646.6767) | Error 0.6556(0.6557) Steps 0(0.00) | Grad Norm 9467.3569(7246.6134) | Total Time 0.00(0.00)\n",
      "Iter 0550 | Time 17.4002(15.9554) | Bit/dim 4.9627(4.9574) | Xent 2.0527(1.8892) | Loss 3623.4280(3627.3362) | Error 0.7122(0.6628) Steps 0(0.00) | Grad Norm 12319.4648(9106.1604) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 82.8586, Epoch Time 978.6470(833.1137), Bit/dim 4.8856(best: 5.0048), Xent 1.8576, Loss 5.8144, Error 0.6422(best: 0.6284)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0560 | Time 15.5425(15.9153) | Bit/dim 4.8790(4.9432) | Xent 1.9125(1.8974) | Loss 3483.3474(3874.5368) | Error 0.6722(0.6665) Steps 0(0.00) | Grad Norm 5570.9236(7973.0459) | Total Time 0.00(0.00)\n",
      "Iter 0570 | Time 14.9319(15.8890) | Bit/dim 4.8505(4.9208) | Xent 1.9054(1.8958) | Loss 3427.7688(3764.9445) | Error 0.6656(0.6665) Steps 0(0.00) | Grad Norm 5013.7910(6731.4761) | Total Time 0.00(0.00)\n",
      "Iter 0580 | Time 16.7892(15.9164) | Bit/dim 4.8409(4.8924) | Xent 1.8464(1.8843) | Loss 3455.5642(3698.5922) | Error 0.6378(0.6613) Steps 0(0.00) | Grad Norm 3239.9387(5856.8322) | Total Time 0.00(0.00)\n",
      "Iter 0590 | Time 16.4387(16.0200) | Bit/dim 4.7985(4.8661) | Xent 1.7782(1.8609) | Loss 3284.1162(3628.5246) | Error 0.6211(0.6539) Steps 0(0.00) | Grad Norm 4498.6496(5609.4963) | Total Time 0.00(0.00)\n",
      "Iter 0600 | Time 16.3356(15.9800) | Bit/dim 4.9545(4.8794) | Xent 1.8452(1.8702) | Loss 3468.9077(3599.4022) | Error 0.6611(0.6581) Steps 0(0.00) | Grad Norm 5821.4894(7242.9048) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 84.4729, Epoch Time 977.3764(837.4416), Bit/dim 4.8780(best: 4.8856), Xent 1.8130, Loss 5.7845, Error 0.6225(best: 0.6284)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0610 | Time 14.5246(15.9041) | Bit/dim 4.8099(4.8707) | Xent 1.8999(1.8706) | Loss 3269.2239(3880.8145) | Error 0.6689(0.6592) Steps 0(0.00) | Grad Norm 3296.0972(6486.7091) | Total Time 0.00(0.00)\n",
      "Iter 0620 | Time 16.0960(16.0255) | Bit/dim 4.7376(4.8442) | Xent 1.7532(1.8531) | Loss 3452.7620(3766.4542) | Error 0.6144(0.6532) Steps 0(0.00) | Grad Norm 4403.0318(5771.3106) | Total Time 0.00(0.00)\n",
      "Iter 0630 | Time 16.9204(16.0686) | Bit/dim 4.7376(4.8203) | Xent 1.6773(1.8241) | Loss 3303.2546(3663.6736) | Error 0.6078(0.6449) Steps 0(0.00) | Grad Norm 5137.0951(5492.6520) | Total Time 0.00(0.00)\n",
      "Iter 0640 | Time 15.8579(16.1181) | Bit/dim 4.7802(4.8090) | Xent 2.0286(1.8530) | Loss 3577.0264(3616.6388) | Error 0.7156(0.6534) Steps 0(0.00) | Grad Norm 11068.4315(7711.2792) | Total Time 0.00(0.00)\n",
      "Iter 0650 | Time 15.5188(16.0724) | Bit/dim 4.6985(4.7882) | Xent 1.8846(1.8558) | Loss 3360.1416(3565.8044) | Error 0.6800(0.6554) Steps 0(0.00) | Grad Norm 3609.2469(6858.4066) | Total Time 0.00(0.00)\n",
      "Iter 0660 | Time 15.7083(16.0211) | Bit/dim 4.7010(4.7648) | Xent 1.8402(1.8454) | Loss 3474.3066(3526.6136) | Error 0.6556(0.6525) Steps 0(0.00) | Grad Norm 5562.6837(5896.7553) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 87.0444, Epoch Time 990.7518(842.0409), Bit/dim 4.6824(best: 4.8780), Xent 1.7261, Loss 5.5454, Error 0.5981(best: 0.6225)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0670 | Time 15.5729(16.1063) | Bit/dim 4.6725(4.7455) | Xent 1.6894(1.8182) | Loss 3379.9265(3752.4209) | Error 0.6178(0.6428) Steps 0(0.00) | Grad Norm 2115.7420(5712.3698) | Total Time 0.00(0.00)\n",
      "Iter 0680 | Time 16.1675(16.2949) | Bit/dim 4.6441(4.7278) | Xent 1.6970(1.7939) | Loss 3359.7622(3651.8343) | Error 0.6044(0.6365) Steps 0(0.00) | Grad Norm 5540.2375(5828.7155) | Total Time 0.00(0.00)\n",
      "Iter 0690 | Time 17.2470(16.4527) | Bit/dim 4.6780(4.7093) | Xent 1.7551(1.7779) | Loss 3260.8960(3574.1836) | Error 0.6167(0.6303) Steps 0(0.00) | Grad Norm 5903.6065(5870.5283) | Total Time 0.00(0.00)\n",
      "Iter 0700 | Time 16.8176(16.3940) | Bit/dim 4.6559(4.6896) | Xent 1.7114(1.7653) | Loss 3359.0857(3515.1102) | Error 0.6256(0.6260) Steps 0(0.00) | Grad Norm 4913.0003(6194.6744) | Total Time 0.00(0.00)\n",
      "Iter 0710 | Time 17.1951(16.5153) | Bit/dim 4.6330(4.6747) | Xent 1.7680(1.7557) | Loss 3468.4109(3487.3638) | Error 0.6111(0.6245) Steps 0(0.00) | Grad Norm 9373.3573(6494.7110) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 89.8694, Epoch Time 1021.3183(847.4192), Bit/dim 4.6524(best: 4.6824), Xent 1.7183, Loss 5.5115, Error 0.6182(best: 0.5981)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0720 | Time 17.8017(16.5598) | Bit/dim 4.5973(4.6619) | Xent 1.6873(1.7549) | Loss 3332.3015(3784.4184) | Error 0.5789(0.6244) Steps 0(0.00) | Grad Norm 6394.6548(6919.9431) | Total Time 0.00(0.00)\n",
      "Iter 0730 | Time 16.1532(16.5598) | Bit/dim 4.7157(4.6521) | Xent 1.9217(1.7460) | Loss 3289.0452(3663.9706) | Error 0.6944(0.6214) Steps 0(0.00) | Grad Norm 15725.1032(7079.1348) | Total Time 0.00(0.00)\n",
      "Iter 0740 | Time 16.3675(16.8389) | Bit/dim 4.5811(4.6443) | Xent 1.6963(1.7479) | Loss 3384.5498(3593.0390) | Error 0.6100(0.6208) Steps 0(0.00) | Grad Norm 6495.9655(7314.0199) | Total Time 0.00(0.00)\n",
      "Iter 0750 | Time 14.9198(16.9589) | Bit/dim 4.5907(4.6292) | Xent 1.6541(1.7357) | Loss 3299.0371(3519.6001) | Error 0.6078(0.6177) Steps 0(0.00) | Grad Norm 5200.0627(6470.9735) | Total Time 0.00(0.00)\n",
      "Iter 0760 | Time 16.6961(16.8481) | Bit/dim 4.6076(4.6189) | Xent 1.7205(1.7198) | Loss 3446.4910(3472.6589) | Error 0.6256(0.6145) Steps 0(0.00) | Grad Norm 11090.4033(6238.1704) | Total Time 0.00(0.00)\n",
      "Iter 0770 | Time 16.8684(16.9750) | Bit/dim 4.5414(4.6035) | Xent 1.6071(1.7064) | Loss 3312.1167(3429.0236) | Error 0.5789(0.6096) Steps 0(0.00) | Grad Norm 2150.4035(5832.1968) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 89.7062, Epoch Time 1047.1666(853.4117), Bit/dim 4.5502(best: 4.6524), Xent 1.6273, Loss 5.3638, Error 0.5863(best: 0.5981)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0780 | Time 16.9991(17.0656) | Bit/dim 4.5372(4.5879) | Xent 1.6151(1.6898) | Loss 3149.4277(3681.6302) | Error 0.5822(0.6036) Steps 0(0.00) | Grad Norm 7121.0012(5526.1093) | Total Time 0.00(0.00)\n",
      "Iter 0790 | Time 16.6310(17.0254) | Bit/dim 4.5386(4.5865) | Xent 1.8406(1.7325) | Loss 3426.2051(3605.6711) | Error 0.6833(0.6160) Steps 0(0.00) | Grad Norm 4353.3189(7134.0290) | Total Time 0.00(0.00)\n",
      "Iter 0800 | Time 17.7598(17.1023) | Bit/dim 4.5616(4.5805) | Xent 1.7484(1.7425) | Loss 3297.8762(3535.7750) | Error 0.6111(0.6189) Steps 0(0.00) | Grad Norm 4835.1848(6542.4307) | Total Time 0.00(0.00)\n",
      "Iter 0810 | Time 17.2277(17.0945) | Bit/dim 4.4897(4.5631) | Xent 1.7286(1.7292) | Loss 3262.3206(3475.3394) | Error 0.6289(0.6148) Steps 0(0.00) | Grad Norm 1738.8590(5577.0091) | Total Time 0.00(0.00)\n",
      "Iter 0820 | Time 20.2056(17.0549) | Bit/dim 4.5011(4.5487) | Xent 1.6618(1.7154) | Loss 3222.8604(3415.4452) | Error 0.5944(0.6121) Steps 0(0.00) | Grad Norm 2443.1949(5153.9914) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 88.2974, Epoch Time 1047.9600(859.2481), Bit/dim 4.5087(best: 4.5502), Xent 1.5959, Loss 5.3067, Error 0.5654(best: 0.5863)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0830 | Time 16.4396(17.0747) | Bit/dim 4.4637(4.5360) | Xent 1.6564(1.6969) | Loss 3202.9675(3719.4031) | Error 0.5933(0.6057) Steps 0(0.00) | Grad Norm 3629.3653(5066.8663) | Total Time 0.00(0.00)\n",
      "Iter 0840 | Time 17.0075(17.1707) | Bit/dim 4.4766(4.5187) | Xent 1.6866(1.6839) | Loss 3231.2622(3598.7606) | Error 0.6089(0.6023) Steps 0(0.00) | Grad Norm 2875.1783(4650.0038) | Total Time 0.00(0.00)\n",
      "Iter 0850 | Time 17.6153(17.0572) | Bit/dim 4.4654(4.5155) | Xent 1.6199(1.6781) | Loss 3268.7842(3519.2776) | Error 0.5867(0.6013) Steps 0(0.00) | Grad Norm 2847.8614(5231.9598) | Total Time 0.00(0.00)\n",
      "Iter 0860 | Time 15.4064(17.0392) | Bit/dim 4.4626(4.5046) | Xent 1.6114(1.6625) | Loss 3143.3796(3442.8943) | Error 0.5733(0.5958) Steps 0(0.00) | Grad Norm 2372.7114(5023.0041) | Total Time 0.00(0.00)\n",
      "Iter 0870 | Time 17.2844(17.1634) | Bit/dim 4.4658(4.4874) | Xent 1.6165(1.6500) | Loss 3288.8813(3406.7596) | Error 0.5811(0.5929) Steps 0(0.00) | Grad Norm 4813.1615(4697.4119) | Total Time 0.00(0.00)\n",
      "Iter 0880 | Time 19.2144(17.3490) | Bit/dim 4.4033(4.4731) | Xent 1.6002(1.6435) | Loss 3229.6858(3372.5431) | Error 0.5600(0.5902) Steps 0(0.00) | Grad Norm 4011.5643(4631.1400) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 90.2543, Epoch Time 1057.8633(865.2066), Bit/dim 4.4175(best: 4.5087), Xent 1.5299, Loss 5.1825, Error 0.5515(best: 0.5654)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0890 | Time 16.9206(17.4434) | Bit/dim 4.4239(4.4607) | Xent 1.6291(1.6340) | Loss 3232.6804(3628.6105) | Error 0.5856(0.5885) Steps 0(0.00) | Grad Norm 7075.7287(4703.6901) | Total Time 0.00(0.00)\n",
      "Iter 0900 | Time 17.0996(17.4581) | Bit/dim 4.4058(4.4525) | Xent 1.5953(1.6329) | Loss 3121.3477(3528.5213) | Error 0.5811(0.5890) Steps 0(0.00) | Grad Norm 7698.3399(5387.5043) | Total Time 0.00(0.00)\n",
      "Iter 0910 | Time 19.5573(17.6108) | Bit/dim 4.3883(4.4393) | Xent 1.5668(1.6230) | Loss 3278.5588(3462.8784) | Error 0.5744(0.5843) Steps 0(0.00) | Grad Norm 2303.6637(4854.9120) | Total Time 0.00(0.00)\n",
      "Iter 0920 | Time 16.5015(17.5492) | Bit/dim 4.3691(4.4235) | Xent 1.6584(1.6172) | Loss 3074.2866(3390.0778) | Error 0.6022(0.5818) Steps 0(0.00) | Grad Norm 5941.5295(4671.2010) | Total Time 0.00(0.00)\n",
      "Iter 0930 | Time 17.2008(17.5079) | Bit/dim 4.3638(4.4104) | Xent 1.5993(1.6095) | Loss 3198.4097(3346.0735) | Error 0.5733(0.5803) Steps 0(0.00) | Grad Norm 4249.7438(4375.2580) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 91.3345, Epoch Time 1074.9695(871.4995), Bit/dim 4.3897(best: 4.4175), Xent 1.5224, Loss 5.1509, Error 0.5436(best: 0.5515)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0940 | Time 18.6086(17.4709) | Bit/dim 4.3889(4.4008) | Xent 1.5576(1.6089) | Loss 3227.2483(3634.7499) | Error 0.5700(0.5806) Steps 0(0.00) | Grad Norm 5397.3555(4821.4273) | Total Time 0.00(0.00)\n",
      "Iter 0950 | Time 18.0148(17.4227) | Bit/dim 4.3417(4.3888) | Xent 1.5372(1.5989) | Loss 3257.9290(3515.1871) | Error 0.5456(0.5753) Steps 0(0.00) | Grad Norm 5376.2215(4935.1992) | Total Time 0.00(0.00)\n",
      "Iter 0960 | Time 16.1235(17.3442) | Bit/dim 4.4048(4.3800) | Xent 1.6117(1.5971) | Loss 3053.1953(3416.7198) | Error 0.5822(0.5763) Steps 0(0.00) | Grad Norm 5016.2903(4986.8084) | Total Time 0.00(0.00)\n",
      "Iter 0970 | Time 16.6870(17.4467) | Bit/dim 4.3809(4.3866) | Xent 1.6365(1.5969) | Loss 3216.3923(3370.2473) | Error 0.5856(0.5761) Steps 0(0.00) | Grad Norm 4830.0980(5269.5089) | Total Time 0.00(0.00)\n",
      "Iter 0980 | Time 17.7091(17.3783) | Bit/dim 4.3529(4.3845) | Xent 1.6676(1.6106) | Loss 3167.9622(3329.2937) | Error 0.5900(0.5805) Steps 0(0.00) | Grad Norm 3630.3902(5438.7222) | Total Time 0.00(0.00)\n",
      "Iter 0990 | Time 20.4050(17.4240) | Bit/dim 4.2933(4.3703) | Xent 1.6193(1.6079) | Loss 3209.8955(3287.6844) | Error 0.6122(0.5816) Steps 0(0.00) | Grad Norm 2381.9757(4761.4473) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 91.0905, Epoch Time 1064.5971(877.2924), Bit/dim 4.3048(best: 4.3897), Xent 1.4815, Loss 5.0456, Error 0.5289(best: 0.5436)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1000 | Time 18.2526(17.4846) | Bit/dim 4.2759(4.3493) | Xent 1.4900(1.5852) | Loss 3260.8818(3548.9333) | Error 0.5578(0.5746) Steps 0(0.00) | Grad Norm 1884.9541(4118.6094) | Total Time 0.00(0.00)\n",
      "Iter 1010 | Time 16.1507(17.4086) | Bit/dim 4.3071(4.3331) | Xent 1.5474(1.5729) | Loss 3104.9641(3442.4066) | Error 0.5644(0.5699) Steps 0(0.00) | Grad Norm 4944.6403(3853.1111) | Total Time 0.00(0.00)\n",
      "Iter 1020 | Time 18.4997(17.4498) | Bit/dim 4.2751(4.3200) | Xent 1.5475(1.5637) | Loss 3200.7134(3372.9638) | Error 0.5656(0.5662) Steps 0(0.00) | Grad Norm 5023.9979(3845.3854) | Total Time 0.00(0.00)\n",
      "Iter 1030 | Time 16.4712(17.3922) | Bit/dim 4.2371(4.3047) | Xent 1.5698(1.5562) | Loss 3100.3911(3315.7188) | Error 0.5589(0.5635) Steps 0(0.00) | Grad Norm 4454.9806(3955.8478) | Total Time 0.00(0.00)\n",
      "Iter 1040 | Time 15.9969(17.3227) | Bit/dim 4.5552(4.3271) | Xent 1.7619(1.5777) | Loss 3254.6409(3289.8335) | Error 0.6411(0.5722) Steps 0(0.00) | Grad Norm 8378.8211(4881.6297) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 89.8390, Epoch Time 1065.4331(882.9366), Bit/dim 4.5012(best: 4.3048), Xent 1.7062, Loss 5.3543, Error 0.6179(best: 0.5289)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1050 | Time 18.2184(17.4790) | Bit/dim 4.3555(4.3623) | Xent 1.6998(1.6501) | Loss 3205.0093(3608.8728) | Error 0.6111(0.5934) Steps 0(0.00) | Grad Norm 2448.3261(5354.8911) | Total Time 0.00(0.00)\n",
      "Iter 1060 | Time 17.9134(17.6250) | Bit/dim 4.3057(4.3582) | Xent 1.5375(1.6392) | Loss 3234.9919(3502.6026) | Error 0.5467(0.5897) Steps 0(0.00) | Grad Norm 2932.6217(4647.7386) | Total Time 0.00(0.00)\n",
      "Iter 1070 | Time 16.9756(17.5612) | Bit/dim 4.2470(4.3340) | Xent 1.5586(1.6211) | Loss 3097.4443(3409.6184) | Error 0.5622(0.5834) Steps 0(0.00) | Grad Norm 3036.6346(4010.0811) | Total Time 0.00(0.00)\n",
      "Iter 1080 | Time 19.1443(17.4832) | Bit/dim 4.2247(4.3112) | Xent 1.6165(1.6016) | Loss 3189.2971(3337.7866) | Error 0.5878(0.5785) Steps 0(0.00) | Grad Norm 4229.2343(3606.3688) | Total Time 0.00(0.00)\n",
      "Iter 1090 | Time 17.8569(17.4479) | Bit/dim 4.2017(4.2893) | Xent 1.5269(1.5823) | Loss 3162.4226(3274.2986) | Error 0.5400(0.5745) Steps 0(0.00) | Grad Norm 2037.9739(3215.3524) | Total Time 0.00(0.00)\n",
      "Iter 1100 | Time 17.4327(17.6097) | Bit/dim 4.2041(4.2696) | Xent 1.5439(1.5598) | Loss 3097.5945(3229.3689) | Error 0.5667(0.5671) Steps 0(0.00) | Grad Norm 3081.2660(2929.1892) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 89.0655, Epoch Time 1075.9342(888.7265), Bit/dim 4.2136(best: 4.3048), Xent 1.4278, Loss 4.9275, Error 0.5153(best: 0.5289)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1110 | Time 17.1664(17.6206) | Bit/dim 4.2197(4.2525) | Xent 1.4733(1.5404) | Loss 3066.5149(3477.5529) | Error 0.5444(0.5596) Steps 0(0.00) | Grad Norm 1212.8356(2930.0151) | Total Time 0.00(0.00)\n",
      "Iter 1120 | Time 19.6666(17.5206) | Bit/dim 4.1879(4.2338) | Xent 1.3441(1.5171) | Loss 3053.8721(3371.3616) | Error 0.4611(0.5492) Steps 0(0.00) | Grad Norm 2963.8283(2833.9818) | Total Time 0.00(0.00)\n",
      "Iter 1130 | Time 19.0030(17.5192) | Bit/dim 4.1758(4.2210) | Xent 1.4329(1.4924) | Loss 3020.6790(3291.2719) | Error 0.5033(0.5423) Steps 0(0.00) | Grad Norm 2082.3163(2687.1813) | Total Time 0.00(0.00)\n",
      "Iter 1140 | Time 17.0456(17.4433) | Bit/dim 4.1934(4.2099) | Xent 1.4658(1.4847) | Loss 2988.1689(3235.5474) | Error 0.5178(0.5397) Steps 0(0.00) | Grad Norm 6111.5746(2751.2439) | Total Time 0.00(0.00)\n",
      "Iter 1150 | Time 16.2463(17.2825) | Bit/dim 4.1789(4.2023) | Xent 1.7191(1.5101) | Loss 3133.6399(3185.0254) | Error 0.5689(0.5449) Steps 0(0.00) | Grad Norm 8913.9961(3729.8712) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 89.8179, Epoch Time 1060.8862(893.8913), Bit/dim 4.1922(best: 4.2136), Xent 1.3857, Loss 4.8851, Error 0.4983(best: 0.5153)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1160 | Time 17.7309(17.5400) | Bit/dim 4.1501(4.1995) | Xent 1.4816(1.5178) | Loss 3056.2883(3503.1812) | Error 0.5278(0.5486) Steps 0(0.00) | Grad Norm 4316.5358(3928.7874) | Total Time 0.00(0.00)\n",
      "Iter 1170 | Time 17.5769(17.4793) | Bit/dim 4.1603(4.1934) | Xent 1.4524(1.5019) | Loss 3087.7527(3390.6697) | Error 0.5178(0.5419) Steps 0(0.00) | Grad Norm 5028.5589(3571.4686) | Total Time 0.00(0.00)\n",
      "Iter 1180 | Time 16.4332(17.4705) | Bit/dim 4.1439(4.1905) | Xent 1.4176(1.4872) | Loss 2889.5217(3299.6873) | Error 0.5300(0.5392) Steps 0(0.00) | Grad Norm 817.9026(3746.0447) | Total Time 0.00(0.00)\n",
      "Iter 1190 | Time 18.1513(17.4195) | Bit/dim 4.1441(4.1761) | Xent 1.5668(1.4732) | Loss 3062.2561(3227.0378) | Error 0.5500(0.5342) Steps 0(0.00) | Grad Norm 4422.9649(3569.4071) | Total Time 0.00(0.00)\n",
      "Iter 1200 | Time 16.8579(17.3304) | Bit/dim 4.1431(4.1620) | Xent 1.4287(1.4613) | Loss 3066.2097(3181.5831) | Error 0.5200(0.5302) Steps 0(0.00) | Grad Norm 2643.7320(3396.8989) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 17.8750(17.3850) | Bit/dim 4.1160(4.1497) | Xent 1.3384(1.4502) | Loss 3005.3828(3133.5247) | Error 0.4944(0.5265) Steps 0(0.00) | Grad Norm 1762.3136(3024.2711) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 88.3792, Epoch Time 1064.9840(899.0241), Bit/dim 4.1166(best: 4.1922), Xent 1.3338, Loss 4.7835, Error 0.4842(best: 0.4983)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1220 | Time 16.0459(17.4450) | Bit/dim 4.1005(4.1417) | Xent 1.4291(1.4398) | Loss 3028.0981(3386.4402) | Error 0.5022(0.5214) Steps 0(0.00) | Grad Norm 3730.9950(3396.8185) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 17.2933(17.3195) | Bit/dim 4.1305(4.1386) | Xent 1.4135(1.4402) | Loss 2929.1536(3284.7746) | Error 0.5100(0.5223) Steps 0(0.00) | Grad Norm 3573.6187(3773.8037) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 17.8825(17.3238) | Bit/dim 4.1065(4.1303) | Xent 1.3751(1.4343) | Loss 3015.2866(3201.8247) | Error 0.4956(0.5212) Steps 0(0.00) | Grad Norm 2505.9698(3514.2055) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 19.2433(17.3253) | Bit/dim 4.1001(4.1250) | Xent 1.3418(1.4242) | Loss 3050.6509(3158.0205) | Error 0.4700(0.5169) Steps 0(0.00) | Grad Norm 3777.8891(3369.7272) | Total Time 0.00(0.00)\n",
      "Iter 1260 | Time 15.9168(17.2980) | Bit/dim 4.1029(4.1160) | Xent 1.4027(1.4114) | Loss 2912.5532(3108.8760) | Error 0.5167(0.5132) Steps 0(0.00) | Grad Norm 3244.8345(3238.3757) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 87.2554, Epoch Time 1057.9201(903.7910), Bit/dim 4.0960(best: 4.1166), Xent 1.3073, Loss 4.7497, Error 0.4731(best: 0.4842)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1270 | Time 19.2989(17.4330) | Bit/dim 4.0677(4.1086) | Xent 1.4128(1.4019) | Loss 3108.1331(3411.4197) | Error 0.5122(0.5089) Steps 0(0.00) | Grad Norm 4504.5801(3246.9541) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 15.8808(17.3324) | Bit/dim 4.1157(4.1024) | Xent 1.4289(1.3987) | Loss 2919.1570(3303.5100) | Error 0.5100(0.5088) Steps 0(0.00) | Grad Norm 4846.4554(3368.1403) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 18.8091(17.3447) | Bit/dim 4.0813(4.0981) | Xent 1.3877(1.3912) | Loss 3063.6780(3233.7128) | Error 0.5067(0.5066) Steps 0(0.00) | Grad Norm 2870.3033(3348.4362) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 15.8558(17.0722) | Bit/dim 4.0702(4.0884) | Xent 1.3932(1.3879) | Loss 2960.6194(3166.0369) | Error 0.5233(0.5058) Steps 0(0.00) | Grad Norm 2118.5532(3201.6849) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 17.6121(17.2072) | Bit/dim 4.0868(4.0842) | Xent 1.3751(1.3787) | Loss 3139.9297(3120.5491) | Error 0.4978(0.5033) Steps 0(0.00) | Grad Norm 4439.0893(3289.7951) | Total Time 0.00(0.00)\n",
      "Iter 1320 | Time 15.6075(17.0483) | Bit/dim 4.0839(4.0796) | Xent 1.3648(1.3771) | Loss 3046.8533(3077.4549) | Error 0.5011(0.5014) Steps 0(0.00) | Grad Norm 5482.5251(3612.4409) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 85.2567, Epoch Time 1040.6593(907.8970), Bit/dim 4.0868(best: 4.0960), Xent 1.3848, Loss 4.7792, Error 0.5088(best: 0.4731)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1330 | Time 16.6639(16.9813) | Bit/dim 4.0678(4.0770) | Xent 1.3068(1.3686) | Loss 3035.5823(3352.6205) | Error 0.4811(0.4968) Steps 0(0.00) | Grad Norm 3922.7432(3553.7608) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 15.8008(16.9669) | Bit/dim 4.0536(4.0710) | Xent 1.3124(1.3577) | Loss 2824.7285(3247.6972) | Error 0.4756(0.4918) Steps 0(0.00) | Grad Norm 1628.9833(3406.2866) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 18.0869(16.9088) | Bit/dim 4.0650(4.0659) | Xent 1.3604(1.3531) | Loss 2960.8242(3179.9328) | Error 0.4700(0.4904) Steps 0(0.00) | Grad Norm 2847.3250(3256.5303) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 15.8781(16.9079) | Bit/dim 4.0707(4.0615) | Xent 1.3840(1.3474) | Loss 3015.5859(3127.4557) | Error 0.4933(0.4879) Steps 0(0.00) | Grad Norm 4473.4481(3166.0381) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 17.1357(16.8088) | Bit/dim 4.0099(4.0520) | Xent 1.3586(1.3490) | Loss 2991.3616(3088.8415) | Error 0.5078(0.4902) Steps 0(0.00) | Grad Norm 3069.3551(3119.0035) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 84.1881, Epoch Time 1023.0472(911.3515), Bit/dim 4.0353(best: 4.0868), Xent 1.2367, Loss 4.6536, Error 0.4518(best: 0.4731)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1380 | Time 17.7711(16.7727) | Bit/dim 3.9936(4.0451) | Xent 1.3600(1.3448) | Loss 3021.1411(3382.8609) | Error 0.4989(0.4876) Steps 0(0.00) | Grad Norm 2215.1443(3050.0123) | Total Time 0.00(0.00)\n",
      "Iter 1390 | Time 17.0360(16.7879) | Bit/dim 4.0395(4.0377) | Xent 1.4059(1.3377) | Loss 3057.8904(3268.7032) | Error 0.5111(0.4838) Steps 0(0.00) | Grad Norm 6539.9945(3315.4531) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 16.6574(16.7528) | Bit/dim 4.0423(4.0348) | Xent 1.2659(1.3334) | Loss 2950.5232(3185.3012) | Error 0.4733(0.4824) Steps 0(0.00) | Grad Norm 3744.8230(3308.7401) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 16.8642(16.6861) | Bit/dim 4.0298(4.0327) | Xent 1.2431(1.3301) | Loss 2904.5769(3121.9496) | Error 0.4567(0.4816) Steps 0(0.00) | Grad Norm 1646.5651(3158.6501) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 15.7897(16.7315) | Bit/dim 4.0256(4.0288) | Xent 1.2792(1.3248) | Loss 2996.7209(3081.4864) | Error 0.4633(0.4817) Steps 0(0.00) | Grad Norm 2594.3225(3039.0576) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 18.1227(16.7709) | Bit/dim 3.9994(4.0292) | Xent 1.3076(1.3239) | Loss 2984.9583(3050.8933) | Error 0.4744(0.4821) Steps 0(0.00) | Grad Norm 3171.1581(3201.5840) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 83.3606, Epoch Time 1018.9785(914.5804), Bit/dim 4.0245(best: 4.0353), Xent 1.2593, Loss 4.6542, Error 0.4550(best: 0.4518)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1440 | Time 15.7697(16.7768) | Bit/dim 4.0375(4.0245) | Xent 1.2178(1.3151) | Loss 2892.4766(3288.0141) | Error 0.4344(0.4777) Steps 0(0.00) | Grad Norm 3850.7515(3077.6216) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 15.7994(16.6896) | Bit/dim 3.9902(4.0210) | Xent 1.2613(1.3055) | Loss 2813.8040(3186.1945) | Error 0.4622(0.4730) Steps 0(0.00) | Grad Norm 1682.5171(3126.4161) | Total Time 0.00(0.00)\n",
      "Iter 1460 | Time 15.4878(16.7462) | Bit/dim 3.9391(4.0123) | Xent 1.2958(1.3033) | Loss 2852.3782(3119.1685) | Error 0.4767(0.4717) Steps 0(0.00) | Grad Norm 3227.8760(3179.4895) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 17.1722(16.7415) | Bit/dim 3.9896(4.0098) | Xent 1.2508(1.3015) | Loss 3059.3298(3082.2991) | Error 0.4533(0.4739) Steps 0(0.00) | Grad Norm 1520.1571(3199.6318) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 15.6080(16.5862) | Bit/dim 3.9859(4.0065) | Xent 1.3788(1.3037) | Loss 2743.3000(3034.8334) | Error 0.4833(0.4738) Steps 0(0.00) | Grad Norm 2261.2739(3122.2048) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 82.2981, Epoch Time 1010.1976(917.4489), Bit/dim 3.9888(best: 4.0245), Xent 1.2069, Loss 4.5922, Error 0.4352(best: 0.4518)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1490 | Time 17.4026(16.5526) | Bit/dim 3.9611(4.0017) | Xent 1.3465(1.2987) | Loss 2956.3252(3329.9079) | Error 0.4889(0.4698) Steps 0(0.00) | Grad Norm 3194.5270(3319.6657) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 16.9286(16.4720) | Bit/dim 3.9682(3.9970) | Xent 1.2851(1.2942) | Loss 2864.9783(3219.5029) | Error 0.4689(0.4680) Steps 0(0.00) | Grad Norm 2392.4769(3036.8637) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 16.4906(16.6588) | Bit/dim 3.9631(3.9889) | Xent 1.2215(1.2798) | Loss 2913.2732(3142.2912) | Error 0.4300(0.4628) Steps 0(0.00) | Grad Norm 1723.7739(2770.5269) | Total Time 0.00(0.00)\n",
      "Iter 1520 | Time 17.1689(16.6800) | Bit/dim 3.9870(3.9856) | Xent 1.3766(1.2854) | Loss 2921.8862(3081.4265) | Error 0.4889(0.4653) Steps 0(0.00) | Grad Norm 5725.5506(3216.7972) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 17.2545(16.6831) | Bit/dim 3.9957(3.9814) | Xent 1.2199(1.2858) | Loss 3001.5222(3036.6114) | Error 0.4356(0.4658) Steps 0(0.00) | Grad Norm 4125.1817(3307.1155) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 15.4517(16.6121) | Bit/dim 3.9917(3.9803) | Xent 1.3172(1.2894) | Loss 2784.2957(2993.6866) | Error 0.4656(0.4652) Steps 0(0.00) | Grad Norm 3093.9654(3339.9563) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 82.8194, Epoch Time 1014.2006(920.3514), Bit/dim 3.9724(best: 3.9888), Xent 1.1838, Loss 4.5643, Error 0.4266(best: 0.4352)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1550 | Time 17.9478(16.7136) | Bit/dim 3.9740(3.9779) | Xent 1.1864(1.2763) | Loss 2912.3074(3259.5345) | Error 0.4333(0.4608) Steps 0(0.00) | Grad Norm 1946.8333(3222.4660) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 16.7632(16.7404) | Bit/dim 3.9402(3.9735) | Xent 1.2439(1.2715) | Loss 2786.7229(3157.1214) | Error 0.4478(0.4593) Steps 0(0.00) | Grad Norm 2387.0776(3127.4029) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 16.0758(16.6118) | Bit/dim 3.9395(3.9703) | Xent 1.1578(1.2558) | Loss 2885.0532(3089.4728) | Error 0.4244(0.4531) Steps 0(0.00) | Grad Norm 1436.8858(3026.9929) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 17.1675(16.5443) | Bit/dim 3.9459(3.9685) | Xent 1.2734(1.2546) | Loss 2875.9001(3041.3762) | Error 0.4567(0.4524) Steps 0(0.00) | Grad Norm 2799.1445(3290.6580) | Total Time 0.00(0.00)\n",
      "Iter 1590 | Time 15.8396(16.4412) | Bit/dim 3.9858(3.9648) | Xent 1.1796(1.2491) | Loss 2843.3599(2993.4895) | Error 0.4256(0.4497) Steps 0(0.00) | Grad Norm 1599.3292(3063.2549) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 81.9236, Epoch Time 1004.8562(922.8866), Bit/dim 3.9523(best: 3.9724), Xent 1.1482, Loss 4.5264, Error 0.4170(best: 0.4266)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1600 | Time 15.7993(16.4317) | Bit/dim 3.9565(3.9620) | Xent 1.2132(1.2398) | Loss 2797.4126(3283.3534) | Error 0.4278(0.4471) Steps 0(0.00) | Grad Norm 2373.6923(2846.7148) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 15.6177(16.4056) | Bit/dim 3.9404(3.9570) | Xent 1.1654(1.2272) | Loss 2706.4602(3162.9817) | Error 0.4056(0.4424) Steps 0(0.00) | Grad Norm 1662.0860(2817.0766) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 17.0609(16.4206) | Bit/dim 3.9465(3.9545) | Xent 1.2285(1.2276) | Loss 2861.7395(3088.3953) | Error 0.4456(0.4433) Steps 0(0.00) | Grad Norm 1956.1332(3030.0871) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 15.8395(16.4597) | Bit/dim 3.9298(3.9525) | Xent 1.2936(1.2278) | Loss 2817.0442(3031.5395) | Error 0.4700(0.4424) Steps 0(0.00) | Grad Norm 6398.8932(3147.6666) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 15.3122(16.3320) | Bit/dim 3.9635(3.9510) | Xent 1.2312(1.2306) | Loss 2817.0083(2985.5373) | Error 0.4544(0.4444) Steps 0(0.00) | Grad Norm 3299.2074(3319.9002) | Total Time 0.00(0.00)\n",
      "Iter 1650 | Time 16.9158(16.4590) | Bit/dim 3.9241(3.9456) | Xent 1.1530(1.2279) | Loss 2843.6116(2953.1400) | Error 0.4089(0.4433) Steps 0(0.00) | Grad Norm 2255.8762(3148.1323) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 81.2555, Epoch Time 1000.4063(925.2122), Bit/dim 3.9476(best: 3.9523), Xent 1.1353, Loss 4.5152, Error 0.4078(best: 0.4170)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1660 | Time 16.5920(16.3907) | Bit/dim 3.9291(3.9421) | Xent 1.2025(1.2226) | Loss 2836.6919(3190.0399) | Error 0.4467(0.4409) Steps 0(0.00) | Grad Norm 2819.9237(3071.2783) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 15.3237(16.3264) | Bit/dim 3.9206(3.9422) | Xent 1.1348(1.2107) | Loss 2822.2981(3089.2952) | Error 0.4211(0.4372) Steps 0(0.00) | Grad Norm 3209.2360(3132.4171) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 19.8552(16.3839) | Bit/dim 3.9328(3.9410) | Xent 1.2230(1.2070) | Loss 2783.3032(3029.9231) | Error 0.4644(0.4346) Steps 0(0.00) | Grad Norm 3198.7545(3236.5738) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 15.3721(16.2781) | Bit/dim 3.9614(3.9408) | Xent 1.1580(1.2021) | Loss 2878.5305(2983.4797) | Error 0.4111(0.4329) Steps 0(0.00) | Grad Norm 2513.6946(3173.7143) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 16.1540(16.2371) | Bit/dim 3.9061(3.9349) | Xent 1.1921(1.1990) | Loss 2784.3416(2939.4291) | Error 0.4089(0.4309) Steps 0(0.00) | Grad Norm 2272.8269(2915.6207) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 81.5519, Epoch Time 990.5111(927.1711), Bit/dim 3.9191(best: 3.9476), Xent 1.0965, Loss 4.4673, Error 0.3946(best: 0.4078)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1710 | Time 16.7782(16.2457) | Bit/dim 3.9322(3.9287) | Xent 1.1550(1.1928) | Loss 2902.4180(3227.7265) | Error 0.4200(0.4280) Steps 0(0.00) | Grad Norm 4121.8808(2999.0600) | Total Time 0.00(0.00)\n",
      "Iter 1720 | Time 14.9329(16.2094) | Bit/dim 3.9287(3.9283) | Xent 1.1514(1.1893) | Loss 2834.3435(3125.1748) | Error 0.4211(0.4258) Steps 0(0.00) | Grad Norm 1609.3122(3009.2079) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 16.9925(16.3150) | Bit/dim 3.9191(3.9250) | Xent 1.1245(1.1886) | Loss 2900.8728(3053.9402) | Error 0.4011(0.4262) Steps 0(0.00) | Grad Norm 1437.3490(2865.8627) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 15.6509(16.3598) | Bit/dim 3.9512(3.9218) | Xent 1.1913(1.1936) | Loss 2798.3142(3002.1620) | Error 0.4389(0.4292) Steps 0(0.00) | Grad Norm 3453.5118(2913.2811) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 15.7545(16.4246) | Bit/dim 3.9425(3.9184) | Xent 1.1329(1.1912) | Loss 2878.7151(2963.2276) | Error 0.4278(0.4290) Steps 0(0.00) | Grad Norm 1201.3620(2686.5406) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 15.5022(16.5320) | Bit/dim 3.8899(3.9141) | Xent 1.1284(1.1850) | Loss 2719.6943(2930.8121) | Error 0.4222(0.4274) Steps 0(0.00) | Grad Norm 2400.5061(2710.7861) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 81.1196, Epoch Time 1002.8308(929.4409), Bit/dim 3.9028(best: 3.9191), Xent 1.0972, Loss 4.4514, Error 0.3913(best: 0.3946)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1770 | Time 16.8442(16.5731) | Bit/dim 3.8934(3.9131) | Xent 1.0732(1.1698) | Loss 2806.9597(3179.8757) | Error 0.4044(0.4201) Steps 0(0.00) | Grad Norm 2204.1732(2698.6299) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 14.8804(16.3647) | Bit/dim 3.9369(3.9127) | Xent 1.2309(1.1701) | Loss 2817.0071(3091.0035) | Error 0.4278(0.4198) Steps 0(0.00) | Grad Norm 3923.5933(2775.2395) | Total Time 0.00(0.00)\n",
      "Iter 1790 | Time 15.7526(16.4220) | Bit/dim 3.9085(3.9084) | Xent 1.2034(1.1789) | Loss 2751.0024(3017.3625) | Error 0.4367(0.4234) Steps 0(0.00) | Grad Norm 1910.7020(3040.4875) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 16.1090(16.4226) | Bit/dim 3.9091(3.9087) | Xent 1.1210(1.1759) | Loss 2775.9131(2969.1483) | Error 0.3944(0.4226) Steps 0(0.00) | Grad Norm 2215.7741(2939.6141) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 16.4699(16.3104) | Bit/dim 3.9005(3.9050) | Xent 1.0970(1.1609) | Loss 2857.6414(2914.4582) | Error 0.3667(0.4164) Steps 0(0.00) | Grad Norm 2326.0564(2732.8446) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 81.9580, Epoch Time 999.2876(931.5363), Bit/dim 3.8977(best: 3.9028), Xent 1.0734, Loss 4.4344, Error 0.3842(best: 0.3913)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1820 | Time 15.4990(16.4404) | Bit/dim 3.9131(3.9043) | Xent 1.1116(1.1476) | Loss 2906.6060(3204.7581) | Error 0.4044(0.4112) Steps 0(0.00) | Grad Norm 2029.2274(2553.2572) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 16.3810(16.3619) | Bit/dim 3.8493(3.9009) | Xent 1.1332(1.1416) | Loss 2795.4973(3103.1431) | Error 0.4011(0.4096) Steps 0(0.00) | Grad Norm 2408.9397(2702.7899) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 16.1945(16.3780) | Bit/dim 3.8523(3.8970) | Xent 1.2807(1.1426) | Loss 2593.0366(3021.2375) | Error 0.4367(0.4101) Steps 0(0.00) | Grad Norm 5331.3701(2897.2212) | Total Time 0.00(0.00)\n",
      "Iter 1850 | Time 16.2961(16.2256) | Bit/dim 3.8785(3.8976) | Xent 1.1359(1.1463) | Loss 2875.5225(2968.3959) | Error 0.3933(0.4115) Steps 0(0.00) | Grad Norm 2784.4014(2827.9864) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 15.1576(16.1524) | Bit/dim 3.8599(3.8918) | Xent 1.0558(1.1367) | Loss 2703.8467(2916.7676) | Error 0.3889(0.4081) Steps 0(0.00) | Grad Norm 1480.7647(2700.2313) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 16.1357(16.2615) | Bit/dim 3.8902(3.8909) | Xent 1.1166(1.1328) | Loss 2749.6643(2894.5982) | Error 0.4067(0.4064) Steps 0(0.00) | Grad Norm 1669.7393(2630.6706) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 81.0748, Epoch Time 986.9254(933.1980), Bit/dim 3.8815(best: 3.8977), Xent 1.0774, Loss 4.4202, Error 0.3902(best: 0.3842)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1880 | Time 16.3013(16.2869) | Bit/dim 3.9108(3.8901) | Xent 1.0188(1.1266) | Loss 2812.4426(3134.3144) | Error 0.3600(0.4034) Steps 0(0.00) | Grad Norm 3252.4839(2666.1096) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 15.3464(16.2930) | Bit/dim 3.8767(3.8884) | Xent 1.0538(1.1186) | Loss 2703.3269(3043.3537) | Error 0.3689(0.3994) Steps 0(0.00) | Grad Norm 3173.6179(2684.2936) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 15.8814(16.3398) | Bit/dim 3.8644(3.8876) | Xent 1.1617(1.1169) | Loss 2684.5698(2981.2231) | Error 0.4011(0.3990) Steps 0(0.00) | Grad Norm 4043.3590(3042.7985) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 16.1854(16.2212) | Bit/dim 3.8775(3.8852) | Xent 1.1368(1.1195) | Loss 2887.8821(2934.8024) | Error 0.4144(0.4014) Steps 0(0.00) | Grad Norm 3689.0041(3034.7467) | Total Time 0.00(0.00)\n",
      "Iter 1920 | Time 16.6963(16.2921) | Bit/dim 3.8854(3.8801) | Xent 1.1572(1.1187) | Loss 2823.2551(2901.0275) | Error 0.4300(0.4014) Steps 0(0.00) | Grad Norm 3273.5926(3068.5583) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 79.5788, Epoch Time 993.3730(935.0032), Bit/dim 3.8782(best: 3.8815), Xent 1.0612, Loss 4.4088, Error 0.3819(best: 0.3842)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1930 | Time 16.6945(16.4127) | Bit/dim 3.8763(3.8815) | Xent 1.1675(1.1193) | Loss 2849.4229(3199.5470) | Error 0.4289(0.3997) Steps 0(0.00) | Grad Norm 2743.7180(2929.7495) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 17.5319(16.4254) | Bit/dim 3.8619(3.8768) | Xent 1.0457(1.1096) | Loss 2700.0542(3086.7149) | Error 0.3689(0.3962) Steps 0(0.00) | Grad Norm 3528.6650(2993.2490) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 17.2842(16.5037) | Bit/dim 3.8989(3.8777) | Xent 1.0527(1.1030) | Loss 2853.3342(3006.3069) | Error 0.3744(0.3947) Steps 0(0.00) | Grad Norm 2813.7543(2961.0826) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 17.1007(16.6360) | Bit/dim 3.8664(3.8754) | Xent 1.1181(1.1066) | Loss 2796.5066(2949.4842) | Error 0.4067(0.3957) Steps 0(0.00) | Grad Norm 4187.2883(3003.2686) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 17.2492(16.5514) | Bit/dim 3.8644(3.8705) | Xent 1.0953(1.1065) | Loss 2747.7144(2903.9508) | Error 0.3922(0.3942) Steps 0(0.00) | Grad Norm 2236.3487(3094.3776) | Total Time 0.00(0.00)\n",
      "Iter 1980 | Time 15.4992(16.5100) | Bit/dim 3.8633(3.8718) | Xent 1.0946(1.0969) | Loss 2842.7100(2863.3790) | Error 0.3978(0.3920) Steps 0(0.00) | Grad Norm 2823.1033(2856.6699) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 81.3016, Epoch Time 1009.6781(937.2435), Bit/dim 3.8624(best: 3.8782), Xent 1.0390, Loss 4.3819, Error 0.3709(best: 0.3819)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1990 | Time 16.0849(16.4552) | Bit/dim 3.8722(3.8694) | Xent 1.0477(1.0916) | Loss 2913.4854(3117.3975) | Error 0.3700(0.3894) Steps 0(0.00) | Grad Norm 1840.0406(2873.1089) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 18.5474(16.6006) | Bit/dim 3.8490(3.8680) | Xent 1.0778(1.0822) | Loss 2823.2241(3035.8393) | Error 0.3956(0.3863) Steps 0(0.00) | Grad Norm 2077.6824(2794.5598) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 16.4980(16.5387) | Bit/dim 3.8867(3.8665) | Xent 1.1159(1.0824) | Loss 2808.4895(2970.7071) | Error 0.4078(0.3880) Steps 0(0.00) | Grad Norm 4401.5260(2851.6296) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 15.6594(16.5554) | Bit/dim 3.8685(3.8637) | Xent 1.1264(1.0840) | Loss 2799.6653(2919.9940) | Error 0.4089(0.3882) Steps 0(0.00) | Grad Norm 1681.8455(2886.3480) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 16.3683(16.6168) | Bit/dim 3.9295(3.8625) | Xent 1.1228(1.0894) | Loss 2688.1689(2884.3258) | Error 0.3944(0.3905) Steps 0(0.00) | Grad Norm 4931.4144(2957.7837) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 81.5088, Epoch Time 1013.2650(939.5241), Bit/dim 3.8737(best: 3.8624), Xent 1.0858, Loss 4.4166, Error 0.3857(best: 0.3709)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2040 | Time 16.4811(16.6357) | Bit/dim 3.8683(3.8622) | Xent 1.0749(1.0899) | Loss 2808.7964(3181.5160) | Error 0.3756(0.3900) Steps 0(0.00) | Grad Norm 2749.5843(2923.8760) | Total Time 0.00(0.00)\n",
      "Iter 2050 | Time 15.3844(16.5396) | Bit/dim 3.8672(3.8620) | Xent 1.0194(1.0833) | Loss 2813.0999(3073.9141) | Error 0.3567(0.3869) Steps 0(0.00) | Grad Norm 1822.7800(2975.4545) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 15.9934(16.5611) | Bit/dim 3.8604(3.8616) | Xent 1.1072(1.0862) | Loss 2766.0405(3008.4482) | Error 0.4033(0.3876) Steps 0(0.00) | Grad Norm 2343.9044(2974.3981) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 16.1370(16.5521) | Bit/dim 3.8383(3.8589) | Xent 1.0546(1.0716) | Loss 2726.1213(2943.0235) | Error 0.3789(0.3822) Steps 0(0.00) | Grad Norm 1836.4086(2772.2634) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 16.8958(16.6145) | Bit/dim 3.8627(3.8600) | Xent 1.0520(1.0674) | Loss 2763.0552(2907.1202) | Error 0.3656(0.3812) Steps 0(0.00) | Grad Norm 2664.6155(2783.2981) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 16.7839(16.7033) | Bit/dim 3.8050(3.8547) | Xent 1.0870(1.0724) | Loss 2831.2703(2883.7085) | Error 0.3967(0.3821) Steps 0(0.00) | Grad Norm 3393.0799(2934.0308) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 80.9541, Epoch Time 1010.1996(941.6444), Bit/dim 3.8541(best: 3.8624), Xent 1.0673, Loss 4.3877, Error 0.3840(best: 0.3709)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2100 | Time 16.1976(16.5840) | Bit/dim 3.8672(3.8542) | Xent 1.1686(1.0751) | Loss 2809.8899(3135.0256) | Error 0.4122(0.3834) Steps 0(0.00) | Grad Norm 5781.1456(3188.9904) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 17.6230(16.6195) | Bit/dim 3.8429(3.8556) | Xent 1.1300(1.0803) | Loss 2778.1638(3033.7599) | Error 0.4089(0.3858) Steps 0(0.00) | Grad Norm 3103.0087(3114.2815) | Total Time 0.00(0.00)\n",
      "Iter 2120 | Time 17.0404(16.5307) | Bit/dim 3.8336(3.8527) | Xent 1.1063(1.0753) | Loss 2846.6118(2970.0059) | Error 0.4000(0.3855) Steps 0(0.00) | Grad Norm 1837.9311(2952.8224) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 15.5568(16.3220) | Bit/dim 3.8236(3.8508) | Xent 1.0237(1.0768) | Loss 2729.6882(2922.3932) | Error 0.3633(0.3859) Steps 0(0.00) | Grad Norm 2161.1426(2894.8018) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 16.3362(16.2644) | Bit/dim 3.8650(3.8492) | Xent 1.0795(1.0758) | Loss 2685.6965(2882.6872) | Error 0.3967(0.3859) Steps 0(0.00) | Grad Norm 2338.6824(2860.0157) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 81.3519, Epoch Time 995.6431(943.2644), Bit/dim 3.8396(best: 3.8541), Xent 0.9825, Loss 4.3309, Error 0.3506(best: 0.3709)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2150 | Time 16.3766(16.4272) | Bit/dim 3.8322(3.8456) | Xent 1.0519(1.0659) | Loss 2766.0303(3173.6976) | Error 0.3756(0.3833) Steps 0(0.00) | Grad Norm 1710.4761(2537.2058) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 16.9202(16.4726) | Bit/dim 3.8472(3.8449) | Xent 0.9900(1.0513) | Loss 2787.9590(3078.3422) | Error 0.3544(0.3764) Steps 0(0.00) | Grad Norm 1321.1201(2323.4458) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 16.3050(16.5212) | Bit/dim 3.8255(3.8468) | Xent 1.0582(1.0487) | Loss 2793.4573(3000.5027) | Error 0.3578(0.3741) Steps 0(0.00) | Grad Norm 2522.4921(2463.0884) | Total Time 0.00(0.00)\n",
      "Iter 2180 | Time 17.0087(16.5430) | Bit/dim 3.8099(3.8434) | Xent 1.0229(1.0498) | Loss 2778.3394(2939.5424) | Error 0.3611(0.3758) Steps 0(0.00) | Grad Norm 2285.7227(2455.0324) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 16.9885(16.6329) | Bit/dim 3.8028(3.8389) | Xent 1.0456(1.0429) | Loss 2858.3687(2905.6011) | Error 0.3811(0.3743) Steps 0(0.00) | Grad Norm 2256.5091(2398.6090) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 16.7533(16.6708) | Bit/dim 3.8204(3.8356) | Xent 1.0175(1.0372) | Loss 2741.1826(2870.5989) | Error 0.3511(0.3710) Steps 0(0.00) | Grad Norm 3062.8587(2296.6702) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 82.2268, Epoch Time 1014.6053(945.4046), Bit/dim 3.8413(best: 3.8396), Xent 1.0122, Loss 4.3474, Error 0.3576(best: 0.3506)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2210 | Time 16.3621(16.6050) | Bit/dim 3.8312(3.8331) | Xent 0.9600(1.0279) | Loss 2711.0972(3099.3480) | Error 0.3411(0.3686) Steps 0(0.00) | Grad Norm 1030.1244(2398.4285) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 15.6155(16.6969) | Bit/dim 3.8280(3.8317) | Xent 1.0697(1.0276) | Loss 2670.1499(3005.8780) | Error 0.3800(0.3689) Steps 0(0.00) | Grad Norm 2643.4996(2622.9039) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 16.8881(16.6350) | Bit/dim 3.8357(3.8323) | Xent 1.0341(1.0242) | Loss 2778.9934(2947.3139) | Error 0.3600(0.3661) Steps 0(0.00) | Grad Norm 1674.8360(2600.8154) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 16.2355(16.4942) | Bit/dim 3.8161(3.8317) | Xent 1.0199(1.0290) | Loss 2616.7603(2885.7658) | Error 0.3667(0.3682) Steps 0(0.00) | Grad Norm 2790.6797(2631.0411) | Total Time 0.00(0.00)\n",
      "Iter 2250 | Time 15.9010(16.3997) | Bit/dim 3.8312(3.8329) | Xent 1.1151(1.0328) | Loss 2811.8406(2865.9969) | Error 0.3811(0.3686) Steps 0(0.00) | Grad Norm 4251.8499(2827.3690) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 81.6826, Epoch Time 1002.3936(947.1143), Bit/dim 3.8304(best: 3.8396), Xent 1.0333, Loss 4.3470, Error 0.3616(best: 0.3506)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2260 | Time 16.1035(16.4325) | Bit/dim 3.8176(3.8321) | Xent 0.9726(1.0272) | Loss 2692.0623(3156.6746) | Error 0.3389(0.3655) Steps 0(0.00) | Grad Norm 1800.1404(2882.8442) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 16.0068(16.5296) | Bit/dim 3.8203(3.8298) | Xent 0.9988(1.0203) | Loss 2653.2559(3047.7938) | Error 0.3533(0.3633) Steps 0(0.00) | Grad Norm 907.4841(2705.1141) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 17.2050(16.5011) | Bit/dim 3.8238(3.8284) | Xent 1.0148(1.0142) | Loss 2774.6375(2967.1313) | Error 0.3556(0.3609) Steps 0(0.00) | Grad Norm 3544.0808(2582.5260) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 15.8625(16.6537) | Bit/dim 3.7889(3.8248) | Xent 1.1312(1.0219) | Loss 2747.5249(2916.1321) | Error 0.4111(0.3656) Steps 0(0.00) | Grad Norm 3263.4019(2725.2526) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 17.6128(16.6776) | Bit/dim 3.8323(3.8231) | Xent 1.0455(1.0350) | Loss 2740.5596(2878.5325) | Error 0.3711(0.3712) Steps 0(0.00) | Grad Norm 2402.3772(2725.5869) | Total Time 0.00(0.00)\n",
      "Iter 2310 | Time 18.0887(16.7669) | Bit/dim 3.8113(3.8218) | Xent 0.9909(1.0251) | Loss 2803.5557(2854.8626) | Error 0.3500(0.3677) Steps 0(0.00) | Grad Norm 3271.4828(2564.5795) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 82.3080, Epoch Time 1020.0247(949.3016), Bit/dim 3.8273(best: 3.8304), Xent 0.9900, Loss 4.3223, Error 0.3534(best: 0.3506)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2320 | Time 16.5778(16.8225) | Bit/dim 3.8202(3.8208) | Xent 0.9592(1.0216) | Loss 2760.9492(3108.1813) | Error 0.3322(0.3663) Steps 0(0.00) | Grad Norm 1709.1823(2419.6504) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 17.2357(16.7595) | Bit/dim 3.8003(3.8192) | Xent 0.9542(1.0135) | Loss 2891.2456(3013.5049) | Error 0.3344(0.3623) Steps 0(0.00) | Grad Norm 2385.7118(2515.8441) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 16.9118(16.7044) | Bit/dim 3.8077(3.8179) | Xent 0.9714(1.0110) | Loss 2816.5676(2952.8701) | Error 0.3389(0.3615) Steps 0(0.00) | Grad Norm 1853.6713(2531.2214) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 16.4285(16.6867) | Bit/dim 3.8073(3.8162) | Xent 1.0116(1.0084) | Loss 2849.1270(2906.5506) | Error 0.3644(0.3608) Steps 0(0.00) | Grad Norm 1552.5021(2531.2766) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 15.8869(16.6747) | Bit/dim 3.7746(3.8141) | Xent 0.9930(1.0015) | Loss 2707.5317(2870.2717) | Error 0.3544(0.3574) Steps 0(0.00) | Grad Norm 4057.7049(2576.6407) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 82.2492, Epoch Time 1014.8046(951.2667), Bit/dim 3.8117(best: 3.8273), Xent 0.9992, Loss 4.3113, Error 0.3534(best: 0.3506)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2370 | Time 17.6200(16.7409) | Bit/dim 3.8241(3.8144) | Xent 0.9186(0.9976) | Loss 2829.7649(3162.6596) | Error 0.3256(0.3561) Steps 0(0.00) | Grad Norm 3233.5958(2664.3108) | Total Time 0.00(0.00)\n",
      "Iter 2380 | Time 16.5479(16.6083) | Bit/dim 3.8481(3.8182) | Xent 0.9826(0.9880) | Loss 2849.4600(3054.2773) | Error 0.3544(0.3525) Steps 0(0.00) | Grad Norm 2339.5638(2633.6666) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 16.8642(16.6526) | Bit/dim 3.7873(3.8159) | Xent 1.0884(1.0021) | Loss 2761.0515(2984.8337) | Error 0.3922(0.3562) Steps 0(0.00) | Grad Norm 4321.7983(2914.7140) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 15.6884(16.5721) | Bit/dim 3.8011(3.8136) | Xent 1.0088(1.0094) | Loss 2798.3333(2922.7995) | Error 0.3556(0.3590) Steps 0(0.00) | Grad Norm 2257.0899(2869.7207) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 17.0046(16.5171) | Bit/dim 3.7848(3.8092) | Xent 1.0192(1.0054) | Loss 2776.7114(2865.2265) | Error 0.3622(0.3575) Steps 0(0.00) | Grad Norm 2496.5036(2734.2226) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 15.3382(16.5331) | Bit/dim 3.7911(3.8067) | Xent 0.9058(1.0002) | Loss 2751.5808(2839.8382) | Error 0.3256(0.3571) Steps 0(0.00) | Grad Norm 1336.8354(2646.3407) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 81.0988, Epoch Time 1005.0807(952.8811), Bit/dim 3.8109(best: 3.8117), Xent 0.9816, Loss 4.3017, Error 0.3538(best: 0.3506)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2430 | Time 20.0576(16.6994) | Bit/dim 3.8011(3.8069) | Xent 0.9556(0.9941) | Loss 2831.3411(3096.6212) | Error 0.3489(0.3554) Steps 0(0.00) | Grad Norm 2599.5061(2583.7318) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 18.8736(16.6835) | Bit/dim 3.8134(3.8056) | Xent 0.9596(0.9937) | Loss 2787.7229(3009.0184) | Error 0.3456(0.3536) Steps 0(0.00) | Grad Norm 2163.8932(2691.5513) | Total Time 0.00(0.00)\n",
      "Iter 2450 | Time 16.0994(16.5902) | Bit/dim 3.8038(3.8044) | Xent 0.9320(0.9912) | Loss 2732.7263(2940.6771) | Error 0.3189(0.3533) Steps 0(0.00) | Grad Norm 2742.2925(2618.8006) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 16.4170(16.5886) | Bit/dim 3.8317(3.8073) | Xent 1.0356(0.9986) | Loss 2847.4539(2900.5046) | Error 0.3656(0.3559) Steps 0(0.00) | Grad Norm 4289.6969(2908.8037) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 18.3932(16.5702) | Bit/dim 3.8201(3.8086) | Xent 1.0335(1.0044) | Loss 2753.9954(2857.3505) | Error 0.3778(0.3588) Steps 0(0.00) | Grad Norm 3376.1139(2905.8275) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 82.0518, Epoch Time 1010.4768(954.6090), Bit/dim 3.8064(best: 3.8109), Xent 0.9403, Loss 4.2765, Error 0.3310(best: 0.3506)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2480 | Time 14.9446(16.6840) | Bit/dim 3.7789(3.8082) | Xent 0.9969(1.0041) | Loss 2569.2756(3152.6058) | Error 0.3378(0.3584) Steps 0(0.00) | Grad Norm 3461.3989(2932.5938) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 15.8736(16.5755) | Bit/dim 3.8079(3.8061) | Xent 0.9816(0.9923) | Loss 2757.0342(3038.3867) | Error 0.3567(0.3539) Steps 0(0.00) | Grad Norm 1662.1663(2746.5578) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 15.6253(16.5294) | Bit/dim 3.7886(3.8057) | Xent 0.9889(0.9851) | Loss 2751.2664(2957.2347) | Error 0.3411(0.3506) Steps 0(0.00) | Grad Norm 1952.5265(2722.3324) | Total Time 0.00(0.00)\n",
      "Iter 2510 | Time 19.1427(16.6437) | Bit/dim 3.7996(3.8059) | Xent 1.0270(0.9823) | Loss 2889.3000(2910.1928) | Error 0.3678(0.3498) Steps 0(0.00) | Grad Norm 3967.6824(2667.4117) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 16.2220(16.6220) | Bit/dim 3.8001(3.8026) | Xent 0.9790(0.9768) | Loss 2672.3022(2858.6211) | Error 0.3389(0.3473) Steps 0(0.00) | Grad Norm 3190.3813(2611.9643) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 16.7536(16.5253) | Bit/dim 3.7755(3.8006) | Xent 0.8693(0.9713) | Loss 2719.3254(2826.6532) | Error 0.3033(0.3440) Steps 0(0.00) | Grad Norm 1939.8801(2648.8576) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 80.1306, Epoch Time 1008.6269(956.2295), Bit/dim 3.7936(best: 3.8064), Xent 0.9197, Loss 4.2535, Error 0.3221(best: 0.3310)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2540 | Time 16.8458(16.4609) | Bit/dim 3.7929(3.7993) | Xent 0.9558(0.9698) | Loss 2616.1506(3077.9434) | Error 0.3333(0.3431) Steps 0(0.00) | Grad Norm 2445.4190(2668.8326) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 18.6323(16.5874) | Bit/dim 3.7902(3.8006) | Xent 0.9416(0.9628) | Loss 2837.7781(2992.5384) | Error 0.3367(0.3416) Steps 0(0.00) | Grad Norm 1742.5221(2560.8343) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 16.0140(16.6049) | Bit/dim 3.8142(3.7962) | Xent 0.9152(0.9550) | Loss 2738.3396(2916.5922) | Error 0.3367(0.3391) Steps 0(0.00) | Grad Norm 2572.1573(2466.8692) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 16.4687(16.5929) | Bit/dim 3.8182(3.7967) | Xent 0.9953(0.9553) | Loss 2690.5098(2870.8623) | Error 0.3533(0.3392) Steps 0(0.00) | Grad Norm 1860.1748(2552.6638) | Total Time 0.00(0.00)\n",
      "Iter 2580 | Time 17.9055(16.5909) | Bit/dim 3.7901(3.7946) | Xent 0.9749(0.9602) | Loss 2821.1799(2843.5460) | Error 0.3544(0.3422) Steps 0(0.00) | Grad Norm 3737.8641(2630.0400) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 80.9787, Epoch Time 1014.5464(957.9790), Bit/dim 3.7955(best: 3.7936), Xent 0.9343, Loss 4.2627, Error 0.3328(best: 0.3221)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2590 | Time 17.9877(16.5855) | Bit/dim 3.7549(3.7895) | Xent 0.8942(0.9688) | Loss 2725.9858(3148.9718) | Error 0.3000(0.3446) Steps 0(0.00) | Grad Norm 3357.9857(2767.8317) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 17.3092(16.6135) | Bit/dim 3.7843(3.7913) | Xent 0.9251(0.9686) | Loss 2604.3352(3028.3760) | Error 0.3211(0.3437) Steps 0(0.00) | Grad Norm 4651.5488(2850.7676) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 16.1075(16.5469) | Bit/dim 3.8064(3.7928) | Xent 0.9816(0.9740) | Loss 2838.1833(2956.6929) | Error 0.3467(0.3475) Steps 0(0.00) | Grad Norm 2561.7424(2814.1301) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 16.6603(16.5545) | Bit/dim 3.7777(3.7913) | Xent 0.9895(0.9720) | Loss 2703.9878(2900.6833) | Error 0.3700(0.3478) Steps 0(0.00) | Grad Norm 2283.4633(2640.0388) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 16.1426(16.4567) | Bit/dim 3.7737(3.7914) | Xent 1.0453(0.9691) | Loss 2760.4219(2848.0785) | Error 0.3622(0.3466) Steps 0(0.00) | Grad Norm 4163.1479(2672.7970) | Total Time 0.00(0.00)\n",
      "Iter 2640 | Time 15.7335(16.5307) | Bit/dim 3.8266(3.7910) | Xent 0.9253(0.9644) | Loss 2661.5398(2809.7503) | Error 0.3211(0.3453) Steps 0(0.00) | Grad Norm 2445.2938(2679.6491) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 80.5962, Epoch Time 1001.5332(959.2856), Bit/dim 3.7887(best: 3.7936), Xent 0.9277, Loss 4.2526, Error 0.3279(best: 0.3221)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2650 | Time 16.4631(16.3763) | Bit/dim 3.7485(3.7880) | Xent 0.9464(0.9571) | Loss 2827.1187(3055.3623) | Error 0.3500(0.3428) Steps 0(0.00) | Grad Norm 1812.2828(2617.4870) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 17.3425(16.5023) | Bit/dim 3.7694(3.7866) | Xent 0.8909(0.9456) | Loss 2782.0986(2970.6335) | Error 0.3089(0.3366) Steps 0(0.00) | Grad Norm 2013.7610(2421.6551) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 16.3855(16.5850) | Bit/dim 3.7981(3.7859) | Xent 0.9887(0.9402) | Loss 2755.7656(2905.7637) | Error 0.3400(0.3342) Steps 0(0.00) | Grad Norm 2850.5802(2316.6239) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 17.0795(16.6674) | Bit/dim 3.7884(3.7867) | Xent 0.9207(0.9391) | Loss 2758.7542(2862.6398) | Error 0.3167(0.3347) Steps 0(0.00) | Grad Norm 2130.1613(2335.1225) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 15.9393(16.5628) | Bit/dim 3.7504(3.7858) | Xent 1.0211(0.9473) | Loss 2792.4966(2828.1660) | Error 0.3689(0.3365) Steps 0(0.00) | Grad Norm 3665.3382(2592.1408) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 83.0854, Epoch Time 1012.4322(960.8800), Bit/dim 3.7755(best: 3.7887), Xent 0.9038, Loss 4.2274, Error 0.3208(best: 0.3221)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2700 | Time 16.1663(16.6860) | Bit/dim 3.7916(3.7847) | Xent 0.9176(0.9471) | Loss 2752.5942(3148.8322) | Error 0.3322(0.3383) Steps 0(0.00) | Grad Norm 3638.7210(2577.0756) | Total Time 0.00(0.00)\n",
      "Iter 2710 | Time 17.1155(16.6709) | Bit/dim 3.7605(3.7850) | Xent 0.9808(0.9508) | Loss 2778.6426(3038.4164) | Error 0.3556(0.3399) Steps 0(0.00) | Grad Norm 3407.4206(2803.6688) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 16.4713(16.7243) | Bit/dim 3.7654(3.7851) | Xent 0.8655(0.9494) | Loss 2747.2610(2958.7781) | Error 0.3111(0.3381) Steps 0(0.00) | Grad Norm 2111.5152(2708.3029) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 15.2279(16.5670) | Bit/dim 3.7642(3.7817) | Xent 0.8586(0.9360) | Loss 2698.2368(2890.9060) | Error 0.2978(0.3334) Steps 0(0.00) | Grad Norm 2189.0226(2538.3568) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 16.8257(16.6344) | Bit/dim 3.7876(3.7787) | Xent 0.9940(0.9443) | Loss 2717.5583(2855.6744) | Error 0.3711(0.3373) Steps 0(0.00) | Grad Norm 2169.5716(2531.5141) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 15.5152(16.5440) | Bit/dim 3.8135(3.7792) | Xent 0.9716(0.9425) | Loss 2628.5249(2813.7161) | Error 0.3589(0.3370) Steps 0(0.00) | Grad Norm 3418.2540(2634.5704) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 81.7542, Epoch Time 1009.1274(962.3274), Bit/dim 3.7728(best: 3.7755), Xent 0.8850, Loss 4.2152, Error 0.3145(best: 0.3208)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2760 | Time 15.6751(16.6603) | Bit/dim 3.7789(3.7764) | Xent 0.9228(0.9385) | Loss 2762.2759(3067.5755) | Error 0.3322(0.3348) Steps 0(0.00) | Grad Norm 2615.4478(2596.7970) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 15.9906(16.6319) | Bit/dim 3.7765(3.7767) | Xent 0.9203(0.9423) | Loss 2710.6597(2965.7232) | Error 0.3300(0.3369) Steps 0(0.00) | Grad Norm 1502.8576(2579.8178) | Total Time 0.00(0.00)\n",
      "Iter 2780 | Time 16.0069(16.6203) | Bit/dim 3.7748(3.7768) | Xent 0.9457(0.9359) | Loss 2680.7410(2906.3835) | Error 0.3289(0.3340) Steps 0(0.00) | Grad Norm 2171.5962(2530.8865) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 16.7582(16.4831) | Bit/dim 3.7771(3.7772) | Xent 0.9979(0.9345) | Loss 2817.5608(2866.8817) | Error 0.3300(0.3339) Steps 0(0.00) | Grad Norm 3966.3808(2659.8097) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 16.1925(16.5473) | Bit/dim 3.7786(3.7774) | Xent 0.8391(0.9303) | Loss 2643.0454(2834.1564) | Error 0.3011(0.3332) Steps 0(0.00) | Grad Norm 2632.3948(2570.1612) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 81.7905, Epoch Time 1008.7123(963.7190), Bit/dim 3.7798(best: 3.7728), Xent 0.8980, Loss 4.2288, Error 0.3173(best: 0.3145)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2810 | Time 15.7178(16.4717) | Bit/dim 3.7911(3.7792) | Xent 0.9673(0.9279) | Loss 2789.9475(3135.5040) | Error 0.3567(0.3327) Steps 0(0.00) | Grad Norm 1728.4049(2403.8631) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 15.3113(16.4234) | Bit/dim 3.7666(3.7788) | Xent 0.9218(0.9210) | Loss 2710.7749(3015.0831) | Error 0.3411(0.3298) Steps 0(0.00) | Grad Norm 3474.3974(2423.5733) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 15.1769(16.4066) | Bit/dim 3.7631(3.7778) | Xent 0.8821(0.9231) | Loss 2670.4492(2932.0805) | Error 0.3222(0.3306) Steps 0(0.00) | Grad Norm 3793.2053(2663.3669) | Total Time 0.00(0.00)\n",
      "Iter 2840 | Time 15.8034(16.4569) | Bit/dim 3.7647(3.7764) | Xent 0.8947(0.9193) | Loss 2724.8657(2875.9209) | Error 0.3378(0.3287) Steps 0(0.00) | Grad Norm 1894.5043(2695.2796) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 15.3128(16.3374) | Bit/dim 3.7605(3.7776) | Xent 0.9739(0.9159) | Loss 2686.9905(2829.4189) | Error 0.3211(0.3273) Steps 0(0.00) | Grad Norm 2369.6381(2582.0894) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 17.2458(16.4864) | Bit/dim 3.7863(3.7736) | Xent 0.9167(0.9286) | Loss 2816.8555(2804.9543) | Error 0.3233(0.3313) Steps 0(0.00) | Grad Norm 2504.6481(2664.5301) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 82.5359, Epoch Time 1004.2413(964.9347), Bit/dim 3.7737(best: 3.7728), Xent 0.9281, Loss 4.2377, Error 0.3292(best: 0.3145)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2870 | Time 16.4826(16.5162) | Bit/dim 3.7544(3.7722) | Xent 0.9367(0.9246) | Loss 2775.4541(3075.1707) | Error 0.3244(0.3312) Steps 0(0.00) | Grad Norm 3934.1734(2603.9436) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 16.4366(16.4624) | Bit/dim 3.7411(3.7718) | Xent 0.8623(0.9169) | Loss 2772.9475(2979.5431) | Error 0.3178(0.3269) Steps 0(0.00) | Grad Norm 1823.9386(2443.7018) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 15.7125(16.4529) | Bit/dim 3.7458(3.7706) | Xent 0.8667(0.9106) | Loss 2771.6033(2915.4796) | Error 0.3078(0.3262) Steps 0(0.00) | Grad Norm 2130.0936(2301.8627) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 15.1703(16.6264) | Bit/dim 3.7619(3.7695) | Xent 0.9693(0.9124) | Loss 2742.9788(2865.5530) | Error 0.3444(0.3271) Steps 0(0.00) | Grad Norm 1988.4563(2332.7880) | Total Time 0.00(0.00)\n",
      "Iter 2910 | Time 14.9930(16.8688) | Bit/dim 3.7515(3.7672) | Xent 0.8913(0.9060) | Loss 2753.7097(2815.4455) | Error 0.3144(0.3251) Steps 0(0.00) | Grad Norm 2279.1311(2307.7189) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 81.8690, Epoch Time 1017.5909(966.5143), Bit/dim 3.7633(best: 3.7728), Xent 0.8725, Loss 4.1996, Error 0.3108(best: 0.3145)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2920 | Time 19.9400(16.7631) | Bit/dim 3.7743(3.7680) | Xent 0.9497(0.9029) | Loss 2748.1829(3105.9025) | Error 0.3256(0.3230) Steps 0(0.00) | Grad Norm 2500.9694(2286.2403) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 17.0336(16.6475) | Bit/dim 3.7495(3.7668) | Xent 0.8454(0.9017) | Loss 2693.2266(3009.3022) | Error 0.3056(0.3227) Steps 0(0.00) | Grad Norm 1840.5353(2396.0836) | Total Time 0.00(0.00)\n",
      "Iter 2940 | Time 17.4719(16.5491) | Bit/dim 3.7690(3.7650) | Xent 0.9125(0.8945) | Loss 2743.2400(2930.0909) | Error 0.3233(0.3204) Steps 0(0.00) | Grad Norm 4140.6010(2453.6960) | Total Time 0.00(0.00)\n",
      "Iter 2950 | Time 16.3914(16.5382) | Bit/dim 3.7466(3.7635) | Xent 0.8939(0.8993) | Loss 2553.0945(2868.6432) | Error 0.3267(0.3211) Steps 0(0.00) | Grad Norm 1378.2706(2331.4557) | Total Time 0.00(0.00)\n",
      "Iter 2960 | Time 18.5015(16.7506) | Bit/dim 3.7440(3.7613) | Xent 0.8401(0.9002) | Loss 2759.3513(2826.8699) | Error 0.2922(0.3206) Steps 0(0.00) | Grad Norm 2362.5473(2502.4334) | Total Time 0.00(0.00)\n",
      "Iter 2970 | Time 17.4637(16.8384) | Bit/dim 3.7662(3.7628) | Xent 0.9957(0.9044) | Loss 2807.1929(2799.1586) | Error 0.3544(0.3217) Steps 0(0.00) | Grad Norm 4900.3550(2598.5428) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 84.5619, Epoch Time 1019.3926(968.1007), Bit/dim 3.7700(best: 3.7633), Xent 0.8842, Loss 4.2121, Error 0.3148(best: 0.3108)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2980 | Time 15.9961(16.7841) | Bit/dim 3.7444(3.7651) | Xent 0.9512(0.9009) | Loss 2696.8726(3066.0015) | Error 0.3311(0.3200) Steps 0(0.00) | Grad Norm 1758.4935(2573.6207) | Total Time 0.00(0.00)\n",
      "Iter 2990 | Time 16.8731(16.7452) | Bit/dim 3.7591(3.7652) | Xent 0.8658(0.8916) | Loss 2725.9509(2965.1041) | Error 0.2989(0.3184) Steps 0(0.00) | Grad Norm 3945.0337(2646.6286) | Total Time 0.00(0.00)\n",
      "Iter 3000 | Time 15.2629(16.6506) | Bit/dim 3.8083(3.7689) | Xent 0.9172(0.8959) | Loss 2663.3501(2894.0260) | Error 0.3178(0.3199) Steps 0(0.00) | Grad Norm 2268.5493(2733.7225) | Total Time 0.00(0.00)\n",
      "Iter 3010 | Time 16.6511(16.5413) | Bit/dim 3.7612(3.7635) | Xent 0.8795(0.8963) | Loss 2784.9207(2849.6093) | Error 0.3178(0.3195) Steps 0(0.00) | Grad Norm 2659.2099(2610.6431) | Total Time 0.00(0.00)\n",
      "Iter 3020 | Time 18.6886(16.5400) | Bit/dim 3.7597(3.7624) | Xent 0.9272(0.8981) | Loss 2754.5864(2814.5640) | Error 0.3322(0.3188) Steps 0(0.00) | Grad Norm 3217.8892(2689.9541) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 83.3217, Epoch Time 1006.1956(969.2435), Bit/dim 3.7609(best: 3.7633), Xent 0.8563, Loss 4.1891, Error 0.3038(best: 0.3108)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3030 | Time 17.7080(16.5035) | Bit/dim 3.7588(3.7588) | Xent 0.8814(0.8929) | Loss 2790.5378(3105.7292) | Error 0.3256(0.3190) Steps 0(0.00) | Grad Norm 1335.3580(2464.2693) | Total Time 0.00(0.00)\n",
      "Iter 3040 | Time 17.0005(16.5356) | Bit/dim 3.7689(3.7581) | Xent 0.8602(0.8810) | Loss 2686.5281(2999.8346) | Error 0.3156(0.3150) Steps 0(0.00) | Grad Norm 2374.8064(2457.0687) | Total Time 0.00(0.00)\n",
      "Iter 3050 | Time 16.9903(16.5699) | Bit/dim 3.7666(3.7557) | Xent 0.8132(0.8786) | Loss 2670.9080(2918.0910) | Error 0.2856(0.3134) Steps 0(0.00) | Grad Norm 3483.6985(2499.8752) | Total Time 0.00(0.00)\n",
      "Iter 3060 | Time 18.5972(16.7228) | Bit/dim 3.7699(3.7560) | Xent 0.9207(0.8809) | Loss 2897.6584(2868.2801) | Error 0.3344(0.3144) Steps 0(0.00) | Grad Norm 2880.2718(2605.1866) | Total Time 0.00(0.00)\n",
      "Iter 3070 | Time 15.9818(16.6479) | Bit/dim 3.7793(3.7544) | Xent 0.9274(0.8826) | Loss 2666.4546(2821.1630) | Error 0.3244(0.3139) Steps 0(0.00) | Grad Norm 3175.1327(2569.6473) | Total Time 0.00(0.00)\n",
      "Iter 3080 | Time 17.3177(16.7090) | Bit/dim 3.7634(3.7536) | Xent 0.8430(0.8798) | Loss 2714.6619(2788.3399) | Error 0.2889(0.3124) Steps 0(0.00) | Grad Norm 2238.2110(2327.3190) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 85.0013, Epoch Time 1018.5157(970.7217), Bit/dim 3.7519(best: 3.7609), Xent 0.8380, Loss 4.1709, Error 0.2945(best: 0.3038)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3090 | Time 16.8106(16.7841) | Bit/dim 3.7664(3.7561) | Xent 0.9519(0.8838) | Loss 2768.8992(3054.2056) | Error 0.3644(0.3144) Steps 0(0.00) | Grad Norm 3700.6234(2471.4272) | Total Time 0.00(0.00)\n",
      "Iter 3100 | Time 18.2419(16.8036) | Bit/dim 3.7336(3.7559) | Xent 0.8868(0.8926) | Loss 2643.6321(2963.5544) | Error 0.3189(0.3183) Steps 0(0.00) | Grad Norm 2971.6901(2639.1039) | Total Time 0.00(0.00)\n",
      "Iter 3110 | Time 16.9519(16.7649) | Bit/dim 3.7892(3.7549) | Xent 0.8644(0.8797) | Loss 2737.5657(2897.1106) | Error 0.3211(0.3132) Steps 0(0.00) | Grad Norm 1791.3247(2559.1898) | Total Time 0.00(0.00)\n",
      "Iter 3120 | Time 15.1040(16.7279) | Bit/dim 3.7303(3.7529) | Xent 0.9381(0.8802) | Loss 2682.7661(2845.3280) | Error 0.3422(0.3146) Steps 0(0.00) | Grad Norm 2635.9972(2465.6689) | Total Time 0.00(0.00)\n",
      "Iter 3130 | Time 17.1945(16.6914) | Bit/dim 3.7522(3.7520) | Xent 0.8768(0.8806) | Loss 2692.3005(2802.9253) | Error 0.3233(0.3153) Steps 0(0.00) | Grad Norm 2125.0323(2472.4135) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 81.7375, Epoch Time 1020.7157(972.2215), Bit/dim 3.7509(best: 3.7519), Xent 0.8467, Loss 4.1742, Error 0.2996(best: 0.2945)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3140 | Time 16.4247(16.6961) | Bit/dim 3.7430(3.7498) | Xent 0.8838(0.8739) | Loss 2809.8486(3087.6134) | Error 0.3022(0.3110) Steps 0(0.00) | Grad Norm 2529.8452(2440.4160) | Total Time 0.00(0.00)\n",
      "Iter 3150 | Time 15.5502(16.7705) | Bit/dim 3.7479(3.7472) | Xent 0.8064(0.8681) | Loss 2619.1370(2988.0492) | Error 0.2944(0.3089) Steps 0(0.00) | Grad Norm 2199.6147(2368.2663) | Total Time 0.00(0.00)\n",
      "Iter 3160 | Time 16.6929(16.6750) | Bit/dim 3.7776(3.7495) | Xent 0.8749(0.8629) | Loss 2765.2695(2914.1703) | Error 0.3067(0.3071) Steps 0(0.00) | Grad Norm 2155.3289(2308.3811) | Total Time 0.00(0.00)\n",
      "Iter 3170 | Time 19.3848(16.6146) | Bit/dim 3.7376(3.7479) | Xent 0.9141(0.8621) | Loss 2747.8621(2861.4013) | Error 0.3300(0.3080) Steps 0(0.00) | Grad Norm 2117.2153(2269.7374) | Total Time 0.00(0.00)\n",
      "Iter 3180 | Time 15.8474(16.6366) | Bit/dim 3.7419(3.7483) | Xent 0.8695(0.8636) | Loss 2758.1985(2824.2762) | Error 0.3144(0.3089) Steps 0(0.00) | Grad Norm 1494.8575(2279.9348) | Total Time 0.00(0.00)\n",
      "Iter 3190 | Time 16.2191(16.5200) | Bit/dim 3.7620(3.7482) | Xent 0.8676(0.8613) | Loss 2769.0068(2785.1760) | Error 0.3078(0.3081) Steps 0(0.00) | Grad Norm 1738.1719(2259.5727) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 83.6904, Epoch Time 1008.1233(973.2986), Bit/dim 3.7477(best: 3.7509), Xent 0.8578, Loss 4.1766, Error 0.3007(best: 0.2945)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3200 | Time 16.5390(16.3866) | Bit/dim 3.7450(3.7487) | Xent 0.9014(0.8595) | Loss 2634.4639(3051.2809) | Error 0.3278(0.3076) Steps 0(0.00) | Grad Norm 2875.2754(2324.8515) | Total Time 0.00(0.00)\n",
      "Iter 3210 | Time 18.9800(16.6249) | Bit/dim 3.7391(3.7445) | Xent 0.8131(0.8566) | Loss 2687.0022(2956.6978) | Error 0.3078(0.3062) Steps 0(0.00) | Grad Norm 2408.4171(2307.4507) | Total Time 0.00(0.00)\n",
      "Iter 3220 | Time 17.9441(17.0092) | Bit/dim 3.7455(3.7440) | Xent 0.8779(0.8533) | Loss 2667.5823(2890.2434) | Error 0.3167(0.3060) Steps 0(0.00) | Grad Norm 2235.1219(2208.3506) | Total Time 0.00(0.00)\n",
      "Iter 3230 | Time 18.4136(16.9951) | Bit/dim 3.7437(3.7456) | Xent 0.8936(0.8600) | Loss 2759.3672(2838.1376) | Error 0.3133(0.3082) Steps 0(0.00) | Grad Norm 1868.5835(2327.2429) | Total Time 0.00(0.00)\n",
      "Iter 3240 | Time 16.7237(16.8716) | Bit/dim 3.7449(3.7463) | Xent 0.9218(0.8639) | Loss 2717.8047(2801.6661) | Error 0.3289(0.3084) Steps 0(0.00) | Grad Norm 2499.8799(2266.4831) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 84.9296, Epoch Time 1033.0850(975.0922), Bit/dim 3.7530(best: 3.7477), Xent 0.8831, Loss 4.1946, Error 0.3093(best: 0.2945)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3250 | Time 15.3826(16.7630) | Bit/dim 3.7657(3.7468) | Xent 0.8442(0.8608) | Loss 2644.4121(3097.8871) | Error 0.3144(0.3075) Steps 0(0.00) | Grad Norm 2616.5328(2382.9209) | Total Time 0.00(0.00)\n",
      "Iter 3260 | Time 17.0526(16.7293) | Bit/dim 3.7219(3.7445) | Xent 0.8589(0.8584) | Loss 2589.7661(2985.6197) | Error 0.2933(0.3058) Steps 0(0.00) | Grad Norm 3128.0142(2415.2613) | Total Time 0.00(0.00)\n",
      "Iter 3270 | Time 17.1567(16.7528) | Bit/dim 3.7323(3.7422) | Xent 0.8483(0.8546) | Loss 2705.2390(2912.7470) | Error 0.3089(0.3043) Steps 0(0.00) | Grad Norm 1368.1805(2311.1659) | Total Time 0.00(0.00)\n",
      "Iter 3280 | Time 16.8999(16.8044) | Bit/dim 3.7609(3.7446) | Xent 0.7679(0.8423) | Loss 2666.3899(2859.6046) | Error 0.2756(0.3000) Steps 0(0.00) | Grad Norm 2123.3200(2126.1628) | Total Time 0.00(0.00)\n",
      "Iter 3290 | Time 16.5199(16.7902) | Bit/dim 3.7157(3.7404) | Xent 0.9334(0.8593) | Loss 2714.4998(2817.5171) | Error 0.3211(0.3043) Steps 0(0.00) | Grad Norm 3658.5189(2545.4051) | Total Time 0.00(0.00)\n",
      "Iter 3300 | Time 17.0034(16.7980) | Bit/dim 3.7720(3.7434) | Xent 0.8650(0.8640) | Loss 2706.8149(2785.1830) | Error 0.3211(0.3076) Steps 0(0.00) | Grad Norm 3099.8886(2448.5920) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 83.5145, Epoch Time 1020.6718(976.4596), Bit/dim 3.7402(best: 3.7477), Xent 0.8519, Loss 4.1661, Error 0.3000(best: 0.2945)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3310 | Time 15.3284(16.8242) | Bit/dim 3.7172(3.7419) | Xent 0.8167(0.8591) | Loss 2593.7839(3046.7767) | Error 0.2911(0.3067) Steps 0(0.00) | Grad Norm 1538.2966(2427.7391) | Total Time 0.00(0.00)\n",
      "Iter 3320 | Time 15.4307(16.8040) | Bit/dim 3.7491(3.7399) | Xent 0.8135(0.8454) | Loss 2657.3533(2952.0582) | Error 0.2767(0.3028) Steps 0(0.00) | Grad Norm 1811.9415(2272.0830) | Total Time 0.00(0.00)\n",
      "Iter 3330 | Time 16.3331(16.6901) | Bit/dim 3.7192(3.7358) | Xent 0.7646(0.8386) | Loss 2761.8508(2880.0250) | Error 0.2856(0.3002) Steps 0(0.00) | Grad Norm 2551.1333(2243.5870) | Total Time 0.00(0.00)\n",
      "Iter 3340 | Time 15.3780(16.6943) | Bit/dim 3.7558(3.7374) | Xent 0.7943(0.8452) | Loss 2679.5537(2831.8577) | Error 0.2656(0.3003) Steps 0(0.00) | Grad Norm 2315.4899(2419.0928) | Total Time 0.00(0.00)\n",
      "Iter 3350 | Time 16.4464(16.6340) | Bit/dim 3.7122(3.7404) | Xent 0.8909(0.8523) | Loss 2671.5269(2792.9251) | Error 0.3100(0.3036) Steps 0(0.00) | Grad Norm 2621.6828(2521.4542) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 84.4763, Epoch Time 1012.5315(977.5417), Bit/dim 3.7285(best: 3.7402), Xent 0.8485, Loss 4.1528, Error 0.3019(best: 0.2945)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3360 | Time 15.5740(16.5711) | Bit/dim 3.7505(3.7388) | Xent 0.8348(0.8493) | Loss 2695.0256(3087.7767) | Error 0.2911(0.3017) Steps 0(0.00) | Grad Norm 2675.8057(2543.9996) | Total Time 0.00(0.00)\n",
      "Iter 3370 | Time 15.5832(16.5357) | Bit/dim 3.7357(3.7364) | Xent 0.8315(0.8380) | Loss 2617.1682(2976.4683) | Error 0.3033(0.2990) Steps 0(0.00) | Grad Norm 2944.4871(2441.0263) | Total Time 0.00(0.00)\n",
      "Iter 3380 | Time 16.5988(16.6232) | Bit/dim 3.7129(3.7324) | Xent 0.8841(0.8399) | Loss 2630.6089(2906.8758) | Error 0.3178(0.3010) Steps 0(0.00) | Grad Norm 1941.8004(2522.0197) | Total Time 0.00(0.00)\n",
      "Iter 3390 | Time 17.1135(16.6639) | Bit/dim 3.7465(3.7337) | Xent 0.8678(0.8416) | Loss 2784.7292(2850.6066) | Error 0.3089(0.3021) Steps 0(0.00) | Grad Norm 2720.2684(2491.8806) | Total Time 0.00(0.00)\n",
      "Iter 3400 | Time 16.5495(16.6401) | Bit/dim 3.7429(3.7375) | Xent 0.8442(0.8435) | Loss 2652.3506(2796.0109) | Error 0.2978(0.3016) Steps 0(0.00) | Grad Norm 1707.9109(2586.3783) | Total Time 0.00(0.00)\n",
      "Iter 3410 | Time 16.7939(16.4774) | Bit/dim 3.7373(3.7395) | Xent 0.8218(0.8392) | Loss 2661.1345(2762.0381) | Error 0.2911(0.3005) Steps 0(0.00) | Grad Norm 1986.5185(2460.9728) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 85.5918, Epoch Time 1011.1448(978.5498), Bit/dim 3.7419(best: 3.7285), Xent 0.8340, Loss 4.1589, Error 0.2932(best: 0.2945)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3420 | Time 16.2883(16.5965) | Bit/dim 3.7345(3.7363) | Xent 0.8221(0.8320) | Loss 2730.8721(3036.1968) | Error 0.3000(0.2984) Steps 0(0.00) | Grad Norm 1723.8410(2326.9810) | Total Time 0.00(0.00)\n",
      "Iter 3430 | Time 15.1583(16.3787) | Bit/dim 3.7021(3.7366) | Xent 0.7895(0.8227) | Loss 2641.0024(2943.6921) | Error 0.2822(0.2949) Steps 0(0.00) | Grad Norm 1680.2537(2395.3965) | Total Time 0.00(0.00)\n",
      "Iter 3440 | Time 15.9635(16.3595) | Bit/dim 3.7508(3.7355) | Xent 0.7974(0.8279) | Loss 2625.8320(2867.7061) | Error 0.2878(0.2967) Steps 0(0.00) | Grad Norm 2222.7233(2432.7156) | Total Time 0.00(0.00)\n",
      "Iter 3450 | Time 15.8280(16.5022) | Bit/dim 3.7207(3.7327) | Xent 0.8010(0.8207) | Loss 2668.1096(2811.1357) | Error 0.2778(0.2931) Steps 0(0.00) | Grad Norm 1321.4663(2307.0666) | Total Time 0.00(0.00)\n",
      "Iter 3460 | Time 18.0358(16.6432) | Bit/dim 3.7556(3.7337) | Xent 0.7982(0.8240) | Loss 2726.4829(2778.3288) | Error 0.2800(0.2936) Steps 0(0.00) | Grad Norm 2610.5590(2372.5611) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 86.3935, Epoch Time 1014.4130(979.6257), Bit/dim 3.7321(best: 3.7285), Xent 0.8145, Loss 4.1393, Error 0.2917(best: 0.2932)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3470 | Time 17.0252(16.5826) | Bit/dim 3.7219(3.7331) | Xent 0.8163(0.8164) | Loss 2708.8091(3079.2207) | Error 0.2867(0.2912) Steps 0(0.00) | Grad Norm 2393.5840(2369.6405) | Total Time 0.00(0.00)\n",
      "Iter 3480 | Time 16.6733(16.5699) | Bit/dim 3.6780(3.7332) | Xent 0.8888(0.8160) | Loss 2639.6448(2979.6918) | Error 0.3200(0.2909) Steps 0(0.00) | Grad Norm 3036.2659(2377.1426) | Total Time 0.00(0.00)\n",
      "Iter 3490 | Time 16.8153(16.6390) | Bit/dim 3.7259(3.7306) | Xent 0.8081(0.8213) | Loss 2673.4526(2894.4906) | Error 0.2878(0.2929) Steps 0(0.00) | Grad Norm 2824.4240(2622.6522) | Total Time 0.00(0.00)\n",
      "Iter 3500 | Time 16.0536(16.6229) | Bit/dim 3.7040(3.7294) | Xent 0.8069(0.8235) | Loss 2683.3293(2840.6900) | Error 0.2956(0.2932) Steps 0(0.00) | Grad Norm 2889.0828(2603.0389) | Total Time 0.00(0.00)\n",
      "Iter 3510 | Time 17.6256(16.7042) | Bit/dim 3.7577(3.7294) | Xent 0.8246(0.8215) | Loss 2582.8232(2799.9512) | Error 0.3000(0.2918) Steps 0(0.00) | Grad Norm 3374.2155(2518.4692) | Total Time 0.00(0.00)\n",
      "Iter 3520 | Time 16.8151(16.6412) | Bit/dim 3.7330(3.7308) | Xent 0.8381(0.8218) | Loss 2666.6421(2778.2936) | Error 0.3056(0.2924) Steps 0(0.00) | Grad Norm 2171.3587(2427.1987) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 84.4697, Epoch Time 1016.1435(980.7212), Bit/dim 3.7274(best: 3.7285), Xent 0.8348, Loss 4.1448, Error 0.2963(best: 0.2917)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3530 | Time 16.7837(16.6556) | Bit/dim 3.7503(3.7278) | Xent 0.7954(0.8195) | Loss 2707.0649(3047.2296) | Error 0.2689(0.2919) Steps 0(0.00) | Grad Norm 1685.5334(2376.1191) | Total Time 0.00(0.00)\n",
      "Iter 3540 | Time 16.0483(16.6339) | Bit/dim 3.7737(3.7324) | Xent 0.8310(0.8096) | Loss 2624.5334(2952.8086) | Error 0.2767(0.2884) Steps 0(0.00) | Grad Norm 4271.1104(2374.1556) | Total Time 0.00(0.00)\n",
      "Iter 3550 | Time 16.7685(16.6582) | Bit/dim 3.7512(3.7311) | Xent 0.7435(0.8181) | Loss 2643.1824(2882.7112) | Error 0.2633(0.2909) Steps 0(0.00) | Grad Norm 2373.7472(2460.4251) | Total Time 0.00(0.00)\n",
      "Iter 3560 | Time 15.6872(16.6176) | Bit/dim 3.7147(3.7298) | Xent 0.8668(0.8207) | Loss 2673.0903(2827.8452) | Error 0.3178(0.2916) Steps 0(0.00) | Grad Norm 1813.6867(2423.2542) | Total Time 0.00(0.00)\n",
      "Iter 3570 | Time 17.8279(16.7182) | Bit/dim 3.7212(3.7269) | Xent 0.8244(0.8208) | Loss 2769.2700(2790.8576) | Error 0.2722(0.2907) Steps 0(0.00) | Grad Norm 1657.7508(2420.6633) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 84.2815, Epoch Time 1017.4418(981.8229), Bit/dim 3.7240(best: 3.7274), Xent 0.8512, Loss 4.1496, Error 0.3032(best: 0.2917)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3580 | Time 15.6746(16.5720) | Bit/dim 3.7105(3.7256) | Xent 0.8057(0.8175) | Loss 2660.6692(3074.7841) | Error 0.2867(0.2904) Steps 0(0.00) | Grad Norm 1941.7451(2325.1954) | Total Time 0.00(0.00)\n",
      "Iter 3590 | Time 17.5176(16.5122) | Bit/dim 3.7379(3.7255) | Xent 0.7339(0.8119) | Loss 2710.2166(2972.3515) | Error 0.2633(0.2878) Steps 0(0.00) | Grad Norm 1975.0294(2339.4979) | Total Time 0.00(0.00)\n",
      "Iter 3600 | Time 19.0674(16.6055) | Bit/dim 3.7176(3.7247) | Xent 0.8338(0.8067) | Loss 2742.0549(2903.0041) | Error 0.3133(0.2872) Steps 0(0.00) | Grad Norm 3131.9161(2290.8991) | Total Time 0.00(0.00)\n",
      "Iter 3610 | Time 16.6119(16.6527) | Bit/dim 3.7678(3.7245) | Xent 0.7900(0.8130) | Loss 2718.0464(2852.7618) | Error 0.2800(0.2900) Steps 0(0.00) | Grad Norm 3785.3575(2549.2833) | Total Time 0.00(0.00)\n",
      "Iter 3620 | Time 15.2492(16.5293) | Bit/dim 3.7339(3.7249) | Xent 0.8886(0.8143) | Loss 2713.1831(2811.6391) | Error 0.3211(0.2905) Steps 0(0.00) | Grad Norm 2813.7225(2556.8150) | Total Time 0.00(0.00)\n",
      "Iter 3630 | Time 16.2122(16.3905) | Bit/dim 3.7438(3.7276) | Xent 0.8166(0.8167) | Loss 2644.7356(2775.7790) | Error 0.2867(0.2903) Steps 0(0.00) | Grad Norm 2210.1515(2542.1754) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 83.9991, Epoch Time 999.8645(982.3641), Bit/dim 3.7201(best: 3.7240), Xent 0.8157, Loss 4.1279, Error 0.2833(best: 0.2917)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3640 | Time 16.1051(16.3579) | Bit/dim 3.7746(3.7299) | Xent 0.8147(0.8104) | Loss 2689.3059(3026.4056) | Error 0.3000(0.2883) Steps 0(0.00) | Grad Norm 2713.0009(2509.1122) | Total Time 0.00(0.00)\n",
      "Iter 3650 | Time 15.3388(16.4528) | Bit/dim 3.7171(3.7258) | Xent 0.8532(0.8117) | Loss 2742.7051(2938.7814) | Error 0.3078(0.2896) Steps 0(0.00) | Grad Norm 1734.6794(2553.2670) | Total Time 0.00(0.00)\n",
      "Iter 3660 | Time 16.5801(16.3799) | Bit/dim 3.7095(3.7281) | Xent 0.8059(0.8048) | Loss 2748.9893(2864.8495) | Error 0.2756(0.2870) Steps 0(0.00) | Grad Norm 2801.3935(2380.2836) | Total Time 0.00(0.00)\n",
      "Iter 3670 | Time 15.0151(16.3377) | Bit/dim 3.6930(3.7270) | Xent 0.7364(0.7985) | Loss 2658.4573(2813.2982) | Error 0.2711(0.2844) Steps 0(0.00) | Grad Norm 1160.4949(2223.5881) | Total Time 0.00(0.00)\n",
      "Iter 3680 | Time 17.1603(16.4266) | Bit/dim 3.7041(3.7208) | Xent 0.8018(0.7958) | Loss 2662.3374(2779.2813) | Error 0.2867(0.2849) Steps 0(0.00) | Grad Norm 1709.9254(2143.8196) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 85.7291, Epoch Time 1006.0856(983.0757), Bit/dim 3.7184(best: 3.7201), Xent 0.7769, Loss 4.1068, Error 0.2758(best: 0.2833)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3690 | Time 15.9698(16.5210) | Bit/dim 3.7374(3.7216) | Xent 0.8131(0.7887) | Loss 2701.4778(3077.2544) | Error 0.2689(0.2812) Steps 0(0.00) | Grad Norm 2247.5088(2020.2423) | Total Time 0.00(0.00)\n",
      "Iter 3700 | Time 15.7050(16.4458) | Bit/dim 3.7082(3.7205) | Xent 0.7828(0.7785) | Loss 2742.4458(2969.9087) | Error 0.2722(0.2775) Steps 0(0.00) | Grad Norm 2012.3261(2088.0200) | Total Time 0.00(0.00)\n",
      "Iter 3710 | Time 15.2954(16.3881) | Bit/dim 3.7133(3.7186) | Xent 0.7467(0.7831) | Loss 2511.0022(2887.9251) | Error 0.2733(0.2796) Steps 0(0.00) | Grad Norm 1587.7202(2135.0053) | Total Time 0.00(0.00)\n",
      "Iter 3720 | Time 17.6645(16.4743) | Bit/dim 3.7488(3.7176) | Xent 0.8237(0.7841) | Loss 2669.4517(2833.0732) | Error 0.3044(0.2806) Steps 0(0.00) | Grad Norm 3624.9502(2119.5056) | Total Time 0.00(0.00)\n",
      "Iter 3730 | Time 16.1155(16.4421) | Bit/dim 3.6913(3.7163) | Xent 0.8405(0.7879) | Loss 2675.0452(2795.7068) | Error 0.3111(0.2818) Steps 0(0.00) | Grad Norm 2030.7329(2217.8081) | Total Time 0.00(0.00)\n",
      "Iter 3740 | Time 16.8511(16.5273) | Bit/dim 3.7113(3.7175) | Xent 0.7928(0.7898) | Loss 2751.4131(2768.1237) | Error 0.2822(0.2828) Steps 0(0.00) | Grad Norm 2849.8036(2157.2605) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 85.5028, Epoch Time 1008.0676(983.8255), Bit/dim 3.7237(best: 3.7184), Xent 0.7948, Loss 4.1211, Error 0.2783(best: 0.2758)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3750 | Time 16.8283(16.5470) | Bit/dim 3.7361(3.7167) | Xent 0.7801(0.7931) | Loss 2751.1936(3031.3708) | Error 0.2900(0.2841) Steps 0(0.00) | Grad Norm 2611.6880(2376.9962) | Total Time 0.00(0.00)\n",
      "Iter 3760 | Time 16.8057(16.6738) | Bit/dim 3.7230(3.7168) | Xent 0.7470(0.7937) | Loss 2827.0344(2939.7060) | Error 0.2778(0.2833) Steps 0(0.00) | Grad Norm 3341.0877(2483.9912) | Total Time 0.00(0.00)\n",
      "Iter 3770 | Time 16.9837(16.5935) | Bit/dim 3.7458(3.7161) | Xent 0.8253(0.7865) | Loss 2752.9104(2862.6049) | Error 0.2800(0.2814) Steps 0(0.00) | Grad Norm 3536.4692(2446.0114) | Total Time 0.00(0.00)\n",
      "Iter 3780 | Time 16.3381(16.6998) | Bit/dim 3.7357(3.7196) | Xent 0.7419(0.7821) | Loss 2690.1809(2816.3854) | Error 0.2678(0.2809) Steps 0(0.00) | Grad Norm 1379.0097(2241.8553) | Total Time 0.00(0.00)\n",
      "Iter 3790 | Time 18.1055(16.7182) | Bit/dim 3.7061(3.7183) | Xent 0.8601(0.7763) | Loss 2806.2710(2778.7812) | Error 0.2900(0.2786) Steps 0(0.00) | Grad Norm 2130.2716(2128.6874) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 85.4842, Epoch Time 1022.3648(984.9817), Bit/dim 3.7074(best: 3.7184), Xent 0.7898, Loss 4.1023, Error 0.2801(best: 0.2758)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3800 | Time 17.7022(16.7882) | Bit/dim 3.7165(3.7176) | Xent 0.7634(0.7752) | Loss 2715.2661(3088.5220) | Error 0.2900(0.2774) Steps 0(0.00) | Grad Norm 2433.3646(2237.0239) | Total Time 0.00(0.00)\n",
      "Iter 3810 | Time 16.2901(16.7469) | Bit/dim 3.7110(3.7151) | Xent 0.7701(0.7781) | Loss 2563.5925(2970.4898) | Error 0.2822(0.2795) Steps 0(0.00) | Grad Norm 1871.2700(2199.5171) | Total Time 0.00(0.00)\n",
      "Iter 3820 | Time 15.8185(16.8180) | Bit/dim 3.7292(3.7172) | Xent 0.8091(0.7788) | Loss 2707.0923(2902.8787) | Error 0.2811(0.2782) Steps 0(0.00) | Grad Norm 1908.0228(2237.2843) | Total Time 0.00(0.00)\n",
      "Iter 3830 | Time 15.4897(16.7715) | Bit/dim 3.7212(3.7170) | Xent 0.7875(0.7777) | Loss 2620.6262(2843.2712) | Error 0.2833(0.2785) Steps 0(0.00) | Grad Norm 1954.7706(2157.2717) | Total Time 0.00(0.00)\n",
      "Iter 3840 | Time 16.4496(16.7459) | Bit/dim 3.6903(3.7114) | Xent 0.7876(0.7723) | Loss 2753.1094(2799.7999) | Error 0.2789(0.2762) Steps 0(0.00) | Grad Norm 1665.1027(2007.4963) | Total Time 0.00(0.00)\n",
      "Iter 3850 | Time 15.8239(16.7295) | Bit/dim 3.6986(3.7073) | Xent 0.6669(0.7637) | Loss 2548.0442(2753.6466) | Error 0.2322(0.2738) Steps 0(0.00) | Grad Norm 1077.8400(2028.2608) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 83.5566, Epoch Time 1022.1598(986.0970), Bit/dim 3.7131(best: 3.7074), Xent 0.8077, Loss 4.1170, Error 0.2859(best: 0.2758)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3860 | Time 17.3313(16.7933) | Bit/dim 3.7410(3.7086) | Xent 0.7998(0.7725) | Loss 2628.6487(3017.9438) | Error 0.2756(0.2761) Steps 0(0.00) | Grad Norm 2658.3260(2089.4648) | Total Time 0.00(0.00)\n",
      "Iter 3870 | Time 16.5162(16.7991) | Bit/dim 3.7216(3.7098) | Xent 0.7473(0.7647) | Loss 2677.7483(2924.9377) | Error 0.2667(0.2737) Steps 0(0.00) | Grad Norm 1752.4274(2059.0667) | Total Time 0.00(0.00)\n",
      "Iter 3880 | Time 15.5136(16.7602) | Bit/dim 3.6930(3.7078) | Xent 0.7974(0.7777) | Loss 2659.5344(2866.4318) | Error 0.2956(0.2782) Steps 0(0.00) | Grad Norm 2287.7200(2288.5277) | Total Time 0.00(0.00)\n",
      "Iter 3890 | Time 16.6041(16.6762) | Bit/dim 3.7115(3.7129) | Xent 0.8200(0.7789) | Loss 2677.7476(2818.1886) | Error 0.2922(0.2777) Steps 0(0.00) | Grad Norm 3932.3849(2360.6545) | Total Time 0.00(0.00)\n",
      "Iter 3900 | Time 15.9446(16.6563) | Bit/dim 3.6974(3.7125) | Xent 0.7465(0.7773) | Loss 2654.8870(2788.4193) | Error 0.2789(0.2785) Steps 0(0.00) | Grad Norm 1239.4295(2413.4418) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 86.0746, Epoch Time 1016.5597(987.0109), Bit/dim 3.7147(best: 3.7074), Xent 0.8096, Loss 4.1195, Error 0.2899(best: 0.2758)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3910 | Time 15.6821(16.5319) | Bit/dim 3.7056(3.7108) | Xent 0.7850(0.7738) | Loss 2620.1943(3081.6975) | Error 0.2622(0.2756) Steps 0(0.00) | Grad Norm 2429.9926(2289.1683) | Total Time 0.00(0.00)\n",
      "Iter 3920 | Time 16.4311(16.5394) | Bit/dim 3.7362(3.7072) | Xent 0.7229(0.7635) | Loss 2666.8135(2961.5524) | Error 0.2511(0.2714) Steps 0(0.00) | Grad Norm 1910.5036(2229.9629) | Total Time 0.00(0.00)\n",
      "Iter 3930 | Time 16.8340(16.5591) | Bit/dim 3.7089(3.7068) | Xent 0.6706(0.7606) | Loss 2641.8923(2882.3290) | Error 0.2478(0.2723) Steps 0(0.00) | Grad Norm 1481.7600(2348.1155) | Total Time 0.00(0.00)\n",
      "Iter 3940 | Time 17.2188(16.6160) | Bit/dim 3.6865(3.7021) | Xent 0.7883(0.7641) | Loss 2614.8076(2817.0899) | Error 0.2678(0.2728) Steps 0(0.00) | Grad Norm 1985.7265(2315.5377) | Total Time 0.00(0.00)\n",
      "Iter 3950 | Time 15.5306(16.5291) | Bit/dim 3.7400(3.7070) | Xent 0.7990(0.7667) | Loss 2728.6924(2767.2894) | Error 0.2978(0.2735) Steps 0(0.00) | Grad Norm 2646.4521(2359.9430) | Total Time 0.00(0.00)\n",
      "Iter 3960 | Time 15.6829(16.5300) | Bit/dim 3.7353(3.7097) | Xent 0.7852(0.7773) | Loss 2711.6206(2750.6700) | Error 0.2744(0.2775) Steps 0(0.00) | Grad Norm 1845.0578(2354.6966) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 83.9378, Epoch Time 1009.3054(987.6797), Bit/dim 3.7116(best: 3.7074), Xent 0.7850, Loss 4.1041, Error 0.2784(best: 0.2758)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3970 | Time 17.8716(16.4887) | Bit/dim 3.7090(3.7112) | Xent 0.8146(0.7750) | Loss 2741.2183(3020.1008) | Error 0.3211(0.2770) Steps 0(0.00) | Grad Norm 2529.1829(2383.7806) | Total Time 0.00(0.00)\n",
      "Iter 3980 | Time 15.1379(16.4409) | Bit/dim 3.7420(3.7128) | Xent 0.7234(0.7738) | Loss 2469.7549(2921.6980) | Error 0.2544(0.2763) Steps 0(0.00) | Grad Norm 1389.2526(2247.3582) | Total Time 0.00(0.00)\n",
      "Iter 3990 | Time 19.9813(16.5722) | Bit/dim 3.7116(3.7103) | Xent 0.7761(0.7641) | Loss 2612.9604(2853.8324) | Error 0.2611(0.2725) Steps 0(0.00) | Grad Norm 1603.2818(2078.6398) | Total Time 0.00(0.00)\n",
      "Iter 4000 | Time 17.2363(16.7004) | Bit/dim 3.6982(3.7067) | Xent 0.7053(0.7552) | Loss 2748.9126(2799.7223) | Error 0.2489(0.2696) Steps 0(0.00) | Grad Norm 1621.8065(2054.3519) | Total Time 0.00(0.00)\n",
      "Iter 4010 | Time 17.1660(16.7392) | Bit/dim 3.7205(3.7054) | Xent 0.8004(0.7449) | Loss 2776.9233(2757.0125) | Error 0.2900(0.2665) Steps 0(0.00) | Grad Norm 1122.6152(1935.6252) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 85.8045, Epoch Time 1019.9347(988.6474), Bit/dim 3.7049(best: 3.7074), Xent 0.8011, Loss 4.1054, Error 0.2785(best: 0.2758)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4020 | Time 15.2721(16.6440) | Bit/dim 3.7105(3.7041) | Xent 0.8297(0.7564) | Loss 2723.4573(3066.9097) | Error 0.3056(0.2709) Steps 0(0.00) | Grad Norm 2825.2667(2228.9580) | Total Time 0.00(0.00)\n",
      "Iter 4030 | Time 17.3701(16.6126) | Bit/dim 3.7526(3.7076) | Xent 0.7768(0.7658) | Loss 2781.4751(2972.3510) | Error 0.2733(0.2726) Steps 0(0.00) | Grad Norm 3777.2644(2470.9169) | Total Time 0.00(0.00)\n",
      "Iter 4040 | Time 16.4091(16.5594) | Bit/dim 3.7112(3.7047) | Xent 0.7527(0.7635) | Loss 2724.2371(2890.1485) | Error 0.2767(0.2722) Steps 0(0.00) | Grad Norm 2421.4343(2436.5507) | Total Time 0.00(0.00)\n",
      "Iter 4050 | Time 15.8450(16.5449) | Bit/dim 3.6805(3.7056) | Xent 0.7248(0.7551) | Loss 2597.8901(2825.0332) | Error 0.2633(0.2694) Steps 0(0.00) | Grad Norm 1853.0059(2262.4016) | Total Time 0.00(0.00)\n",
      "Iter 4060 | Time 15.8114(16.6880) | Bit/dim 3.6956(3.7038) | Xent 0.7229(0.7557) | Loss 2646.7456(2787.4792) | Error 0.2600(0.2695) Steps 0(0.00) | Grad Norm 2172.0829(2190.3085) | Total Time 0.00(0.00)\n",
      "Iter 4070 | Time 19.2792(16.7629) | Bit/dim 3.6996(3.7030) | Xent 0.7111(0.7465) | Loss 2731.4175(2755.0230) | Error 0.2656(0.2657) Steps 0(0.00) | Grad Norm 1761.4747(2100.1259) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 86.1390, Epoch Time 1017.4177(989.5105), Bit/dim 3.6961(best: 3.7049), Xent 0.7578, Loss 4.0750, Error 0.2638(best: 0.2758)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4080 | Time 15.1005(16.7076) | Bit/dim 3.6830(3.7005) | Xent 0.6908(0.7382) | Loss 2489.7253(3013.8487) | Error 0.2467(0.2623) Steps 0(0.00) | Grad Norm 2252.9976(2039.4822) | Total Time 0.00(0.00)\n",
      "Iter 4090 | Time 16.6379(16.8039) | Bit/dim 3.6724(3.6998) | Xent 0.7358(0.7378) | Loss 2671.7598(2918.2549) | Error 0.2578(0.2623) Steps 0(0.00) | Grad Norm 2581.2141(2179.4279) | Total Time 0.00(0.00)\n",
      "Iter 4100 | Time 15.4140(16.9744) | Bit/dim 3.7126(3.7012) | Xent 0.7001(0.7384) | Loss 2572.4768(2852.6522) | Error 0.2511(0.2628) Steps 0(0.00) | Grad Norm 1759.0277(2243.0615) | Total Time 0.00(0.00)\n",
      "Iter 4110 | Time 17.4755(17.0470) | Bit/dim 3.7104(3.7005) | Xent 0.8198(0.7430) | Loss 2661.7078(2801.1804) | Error 0.2989(0.2643) Steps 0(0.00) | Grad Norm 3075.7953(2261.3075) | Total Time 0.00(0.00)\n",
      "Iter 4120 | Time 15.7205(16.9883) | Bit/dim 3.6754(3.7001) | Xent 0.7382(0.7464) | Loss 2539.5415(2757.1768) | Error 0.2756(0.2659) Steps 0(0.00) | Grad Norm 1995.0962(2102.3191) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 84.6903, Epoch Time 1038.9183(990.9927), Bit/dim 3.7006(best: 3.6961), Xent 0.7663, Loss 4.0838, Error 0.2677(best: 0.2638)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4130 | Time 18.4078(17.1641) | Bit/dim 3.7131(3.7003) | Xent 0.8010(0.7413) | Loss 2776.8318(3067.4052) | Error 0.2911(0.2649) Steps 0(0.00) | Grad Norm 2853.0983(2039.1583) | Total Time 0.00(0.00)\n",
      "Iter 4140 | Time 18.2312(17.0131) | Bit/dim 3.6806(3.7007) | Xent 0.7679(0.7400) | Loss 2720.5188(2948.6007) | Error 0.2811(0.2643) Steps 0(0.00) | Grad Norm 2238.3575(2126.1309) | Total Time 0.00(0.00)\n",
      "Iter 4150 | Time 16.2835(16.8409) | Bit/dim 3.7214(3.7019) | Xent 0.7513(0.7343) | Loss 2644.9258(2875.3269) | Error 0.2667(0.2627) Steps 0(0.00) | Grad Norm 2628.0885(2114.8339) | Total Time 0.00(0.00)\n",
      "Iter 4160 | Time 16.8749(16.7286) | Bit/dim 3.7054(3.7008) | Xent 0.7592(0.7308) | Loss 2676.5317(2817.3101) | Error 0.2689(0.2609) Steps 0(0.00) | Grad Norm 2135.6407(2055.6381) | Total Time 0.00(0.00)\n",
      "Iter 4170 | Time 16.7555(16.6608) | Bit/dim 3.7072(3.7006) | Xent 0.7994(0.7299) | Loss 2732.0066(2778.1595) | Error 0.2933(0.2608) Steps 0(0.00) | Grad Norm 3969.3336(2152.1306) | Total Time 0.00(0.00)\n",
      "Iter 4180 | Time 16.7443(16.6436) | Bit/dim 3.6867(3.6964) | Xent 0.7418(0.7413) | Loss 2535.0532(2741.6240) | Error 0.2789(0.2660) Steps 0(0.00) | Grad Norm 3036.8533(2316.2754) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 87.5364, Epoch Time 1016.2790(991.7513), Bit/dim 3.7057(best: 3.6961), Xent 0.8161, Loss 4.1137, Error 0.2874(best: 0.2638)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4190 | Time 16.2352(16.6148) | Bit/dim 3.6863(3.6955) | Xent 0.7289(0.7382) | Loss 2548.4685(2991.6929) | Error 0.2622(0.2643) Steps 0(0.00) | Grad Norm 2185.4882(2287.0490) | Total Time 0.00(0.00)\n",
      "Iter 4200 | Time 17.3014(16.5723) | Bit/dim 3.6787(3.6947) | Xent 0.6800(0.7297) | Loss 2626.5957(2901.9570) | Error 0.2289(0.2601) Steps 0(0.00) | Grad Norm 1374.5538(2177.4480) | Total Time 0.00(0.00)\n",
      "Iter 4210 | Time 16.8425(16.5807) | Bit/dim 3.6872(3.6946) | Xent 0.6935(0.7306) | Loss 2692.5901(2842.1487) | Error 0.2567(0.2622) Steps 0(0.00) | Grad Norm 1859.7456(2138.2352) | Total Time 0.00(0.00)\n",
      "Iter 4220 | Time 15.1510(16.5280) | Bit/dim 3.6743(3.6948) | Xent 0.7589(0.7312) | Loss 2585.8992(2784.0339) | Error 0.2722(0.2624) Steps 0(0.00) | Grad Norm 2348.2530(2137.7551) | Total Time 0.00(0.00)\n",
      "Iter 4230 | Time 15.4346(16.6240) | Bit/dim 3.6932(3.6979) | Xent 0.6941(0.7258) | Loss 2662.7595(2747.7196) | Error 0.2522(0.2607) Steps 0(0.00) | Grad Norm 1516.0708(2104.3169) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 86.2926, Epoch Time 1014.5239(992.4345), Bit/dim 3.7051(best: 3.6961), Xent 0.8529, Loss 4.1316, Error 0.2918(best: 0.2638)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4240 | Time 16.1759(16.6105) | Bit/dim 3.7070(3.6934) | Xent 0.7675(0.7319) | Loss 2625.4370(3045.9510) | Error 0.2811(0.2608) Steps 0(0.00) | Grad Norm 2461.7837(2262.2004) | Total Time 0.00(0.00)\n",
      "Iter 4250 | Time 15.9499(16.6129) | Bit/dim 3.7246(3.6974) | Xent 0.7209(0.7319) | Loss 2657.0469(2943.9930) | Error 0.2633(0.2606) Steps 0(0.00) | Grad Norm 3359.5373(2384.7252) | Total Time 0.00(0.00)\n",
      "Iter 4260 | Time 15.8301(16.3447) | Bit/dim 3.6851(3.6981) | Xent 0.7015(0.7249) | Loss 2636.3391(2861.9876) | Error 0.2644(0.2588) Steps 0(0.00) | Grad Norm 1332.5328(2186.5537) | Total Time 0.00(0.00)\n",
      "Iter 4270 | Time 16.6448(16.3608) | Bit/dim 3.7099(3.6984) | Xent 0.7709(0.7230) | Loss 2631.8755(2799.7342) | Error 0.2722(0.2584) Steps 0(0.00) | Grad Norm 1532.4465(2032.6149) | Total Time 0.00(0.00)\n",
      "Iter 4280 | Time 16.3520(16.3943) | Bit/dim 3.6876(3.6974) | Xent 0.7734(0.7218) | Loss 2698.1963(2764.7342) | Error 0.2711(0.2578) Steps 0(0.00) | Grad Norm 2463.1915(2110.6541) | Total Time 0.00(0.00)\n",
      "Iter 4290 | Time 15.9539(16.3940) | Bit/dim 3.6923(3.6962) | Xent 0.6987(0.7208) | Loss 2568.6013(2731.2202) | Error 0.2578(0.2575) Steps 0(0.00) | Grad Norm 1001.2228(2107.8517) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 86.7743, Epoch Time 999.1306(992.6354), Bit/dim 3.6924(best: 3.6961), Xent 0.7737, Loss 4.0793, Error 0.2698(best: 0.2638)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4300 | Time 14.8689(16.5139) | Bit/dim 3.7034(3.6948) | Xent 0.6557(0.7172) | Loss 2431.1191(3010.1387) | Error 0.2322(0.2560) Steps 0(0.00) | Grad Norm 1895.8218(2106.1661) | Total Time 0.00(0.00)\n",
      "Iter 4310 | Time 17.2116(16.5120) | Bit/dim 3.6620(3.6943) | Xent 0.7016(0.7149) | Loss 2650.4460(2919.0889) | Error 0.2656(0.2557) Steps 0(0.00) | Grad Norm 2671.6666(2120.3686) | Total Time 0.00(0.00)\n",
      "Iter 4320 | Time 16.6834(16.5739) | Bit/dim 3.7001(3.6968) | Xent 0.6963(0.7136) | Loss 2623.4204(2840.3144) | Error 0.2556(0.2551) Steps 0(0.00) | Grad Norm 1518.0811(2032.2542) | Total Time 0.00(0.00)\n",
      "Iter 4330 | Time 17.5735(16.5987) | Bit/dim 3.6722(3.6943) | Xent 0.6922(0.7073) | Loss 2635.5420(2782.8359) | Error 0.2500(0.2535) Steps 0(0.00) | Grad Norm 2434.4375(2006.4863) | Total Time 0.00(0.00)\n",
      "Iter 4340 | Time 16.7015(16.7323) | Bit/dim 3.6620(3.6943) | Xent 0.7311(0.7129) | Loss 2654.1631(2755.8134) | Error 0.2578(0.2540) Steps 0(0.00) | Grad Norm 2415.6272(2101.0584) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 87.3255, Epoch Time 1029.8750(993.7526), Bit/dim 3.6867(best: 3.6924), Xent 0.7514, Loss 4.0624, Error 0.2650(best: 0.2638)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4350 | Time 17.5270(16.8567) | Bit/dim 3.6711(3.6904) | Xent 0.6813(0.7087) | Loss 2556.1697(3066.4094) | Error 0.2500(0.2543) Steps 0(0.00) | Grad Norm 1583.1329(2046.1838) | Total Time 0.00(0.00)\n",
      "Iter 4360 | Time 16.8379(16.8506) | Bit/dim 3.6834(3.6904) | Xent 0.7285(0.7068) | Loss 2752.2424(2958.2939) | Error 0.2656(0.2536) Steps 0(0.00) | Grad Norm 2434.1844(2059.4928) | Total Time 0.00(0.00)\n",
      "Iter 4370 | Time 15.9904(16.8298) | Bit/dim 3.7128(3.6922) | Xent 0.6900(0.7047) | Loss 2582.8889(2872.8728) | Error 0.2356(0.2519) Steps 0(0.00) | Grad Norm 1539.8225(2099.3859) | Total Time 0.00(0.00)\n",
      "Iter 4380 | Time 16.7033(16.8060) | Bit/dim 3.6917(3.6895) | Xent 0.7437(0.7055) | Loss 2539.3877(2808.4832) | Error 0.2600(0.2517) Steps 0(0.00) | Grad Norm 3019.6701(2137.0506) | Total Time 0.00(0.00)\n",
      "Iter 4390 | Time 17.1211(16.8988) | Bit/dim 3.7481(3.6906) | Xent 0.7827(0.7112) | Loss 2694.7927(2774.0220) | Error 0.2800(0.2524) Steps 0(0.00) | Grad Norm 4204.3436(2228.9511) | Total Time 0.00(0.00)\n",
      "Iter 4400 | Time 16.4973(16.8441) | Bit/dim 3.6547(3.6927) | Xent 0.7587(0.7177) | Loss 2622.7471(2743.9009) | Error 0.2767(0.2555) Steps 0(0.00) | Grad Norm 2099.9944(2300.0391) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 86.6204, Epoch Time 1027.6354(994.7691), Bit/dim 3.6895(best: 3.6867), Xent 0.7589, Loss 4.0690, Error 0.2717(best: 0.2638)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4410 | Time 15.8383(16.7682) | Bit/dim 3.6986(3.6885) | Xent 0.6459(0.7121) | Loss 2558.6333(3010.7054) | Error 0.2278(0.2545) Steps 0(0.00) | Grad Norm 1653.8376(2207.7314) | Total Time 0.00(0.00)\n",
      "Iter 4420 | Time 19.6406(16.8703) | Bit/dim 3.6806(3.6903) | Xent 0.6404(0.7059) | Loss 2669.8235(2911.2407) | Error 0.2144(0.2518) Steps 0(0.00) | Grad Norm 1747.3322(2145.0068) | Total Time 0.00(0.00)\n",
      "Iter 4430 | Time 17.2591(17.0687) | Bit/dim 3.7020(3.6915) | Xent 0.6872(0.7018) | Loss 2762.6365(2847.9359) | Error 0.2544(0.2510) Steps 0(0.00) | Grad Norm 2581.0749(2144.0351) | Total Time 0.00(0.00)\n",
      "Iter 4440 | Time 17.2822(17.0786) | Bit/dim 3.6528(3.6882) | Xent 0.7691(0.7015) | Loss 2742.4812(2800.6753) | Error 0.2689(0.2509) Steps 0(0.00) | Grad Norm 3529.4743(2234.6005) | Total Time 0.00(0.00)\n",
      "Iter 4450 | Time 16.6958(16.9194) | Bit/dim 3.6783(3.6865) | Xent 0.6519(0.6993) | Loss 2690.0132(2750.0464) | Error 0.2444(0.2513) Steps 0(0.00) | Grad Norm 1498.3817(2108.4902) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 90.4254, Epoch Time 1038.2034(996.0721), Bit/dim 3.6840(best: 3.6867), Xent 0.7542, Loss 4.0611, Error 0.2661(best: 0.2638)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4460 | Time 15.3234(16.9389) | Bit/dim 3.7022(3.6851) | Xent 0.7418(0.7021) | Loss 2757.2644(3059.0079) | Error 0.2622(0.2525) Steps 0(0.00) | Grad Norm 2612.5693(2148.9508) | Total Time 0.00(0.00)\n",
      "Iter 4470 | Time 16.0298(17.0644) | Bit/dim 3.6633(3.6835) | Xent 0.7414(0.6984) | Loss 2650.8345(2954.5217) | Error 0.2611(0.2509) Steps 0(0.00) | Grad Norm 2846.4304(2143.1612) | Total Time 0.00(0.00)\n",
      "Iter 4480 | Time 16.1615(17.0617) | Bit/dim 3.6733(3.6842) | Xent 0.7643(0.7005) | Loss 2628.3381(2879.6421) | Error 0.2667(0.2511) Steps 0(0.00) | Grad Norm 1826.1115(2135.6074) | Total Time 0.00(0.00)\n",
      "Iter 4490 | Time 16.3842(16.9771) | Bit/dim 3.6826(3.6846) | Xent 0.7284(0.6985) | Loss 2690.1575(2818.0092) | Error 0.2444(0.2494) Steps 0(0.00) | Grad Norm 3256.7423(2142.2270) | Total Time 0.00(0.00)\n",
      "Iter 4500 | Time 16.5258(16.9754) | Bit/dim 3.6842(3.6835) | Xent 0.6654(0.6982) | Loss 2707.0256(2769.6115) | Error 0.2200(0.2491) Steps 0(0.00) | Grad Norm 1947.3489(2098.7978) | Total Time 0.00(0.00)\n",
      "Iter 4510 | Time 17.5117(17.0488) | Bit/dim 3.6786(3.6850) | Xent 0.6825(0.6913) | Loss 2621.2241(2727.7895) | Error 0.2400(0.2469) Steps 0(0.00) | Grad Norm 1905.7329(1990.9064) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 85.8370, Epoch Time 1044.3132(997.5193), Bit/dim 3.6799(best: 3.6840), Xent 0.7752, Loss 4.0675, Error 0.2719(best: 0.2638)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4520 | Time 15.6804(17.0928) | Bit/dim 3.6512(3.6831) | Xent 0.6664(0.6892) | Loss 2633.9963(3003.3139) | Error 0.2400(0.2470) Steps 0(0.00) | Grad Norm 1474.5646(2067.8309) | Total Time 0.00(0.00)\n",
      "Iter 4530 | Time 17.4365(17.0808) | Bit/dim 3.6800(3.6833) | Xent 0.7595(0.6860) | Loss 2624.5691(2905.7286) | Error 0.2578(0.2450) Steps 0(0.00) | Grad Norm 2710.3217(2004.8810) | Total Time 0.00(0.00)\n",
      "Iter 4540 | Time 15.8372(17.0596) | Bit/dim 3.7205(3.6820) | Xent 0.7255(0.6929) | Loss 2634.1367(2841.9677) | Error 0.2433(0.2469) Steps 0(0.00) | Grad Norm 2617.8734(2162.5238) | Total Time 0.00(0.00)\n",
      "Iter 4550 | Time 16.1495(17.0475) | Bit/dim 3.6757(3.6839) | Xent 0.7582(0.6925) | Loss 2623.5315(2796.8889) | Error 0.2533(0.2468) Steps 0(0.00) | Grad Norm 1725.8127(2150.1880) | Total Time 0.00(0.00)\n",
      "Iter 4560 | Time 15.9133(17.0509) | Bit/dim 3.6757(3.6860) | Xent 0.6647(0.6920) | Loss 2502.1050(2754.5703) | Error 0.2400(0.2465) Steps 0(0.00) | Grad Norm 2378.4704(2129.6028) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 86.4128, Epoch Time 1041.2738(998.8320), Bit/dim 3.6880(best: 3.6799), Xent 0.7445, Loss 4.0603, Error 0.2602(best: 0.2638)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4570 | Time 16.4089(17.0239) | Bit/dim 3.6648(3.6878) | Xent 0.6172(0.6814) | Loss 2666.2500(3063.1871) | Error 0.2311(0.2431) Steps 0(0.00) | Grad Norm 2147.7570(2006.8691) | Total Time 0.00(0.00)\n",
      "Iter 4580 | Time 15.5152(16.9776) | Bit/dim 3.7174(3.6868) | Xent 0.7033(0.6829) | Loss 2512.7112(2949.5229) | Error 0.2500(0.2436) Steps 0(0.00) | Grad Norm 2231.2901(2042.2014) | Total Time 0.00(0.00)\n",
      "Iter 4590 | Time 17.3761(17.0598) | Bit/dim 3.6862(3.6819) | Xent 0.6634(0.6824) | Loss 2675.0691(2867.5586) | Error 0.2256(0.2431) Steps 0(0.00) | Grad Norm 2395.6766(2093.2034) | Total Time 0.00(0.00)\n",
      "Iter 4600 | Time 15.3610(17.1077) | Bit/dim 3.6683(3.6821) | Xent 0.6001(0.6783) | Loss 2581.5332(2807.2106) | Error 0.2011(0.2418) Steps 0(0.00) | Grad Norm 1365.3550(2046.2087) | Total Time 0.00(0.00)\n",
      "Iter 4610 | Time 16.1808(16.9696) | Bit/dim 3.6579(3.6787) | Xent 0.7005(0.6795) | Loss 2663.7688(2764.9445) | Error 0.2556(0.2413) Steps 0(0.00) | Grad Norm 1791.0592(2043.5180) | Total Time 0.00(0.00)\n",
      "Iter 4620 | Time 15.5845(16.9419) | Bit/dim 3.7153(3.6799) | Xent 0.7257(0.6846) | Loss 2670.7305(2729.0248) | Error 0.2756(0.2439) Steps 0(0.00) | Grad Norm 1742.4963(1987.1683) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 86.1143, Epoch Time 1036.0115(999.9473), Bit/dim 3.6802(best: 3.6799), Xent 0.7459, Loss 4.0532, Error 0.2610(best: 0.2602)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4630 | Time 16.9721(16.9119) | Bit/dim 3.6842(3.6792) | Xent 0.6406(0.6794) | Loss 2629.1055(3004.5184) | Error 0.2189(0.2410) Steps 0(0.00) | Grad Norm 1589.0919(2051.0179) | Total Time 0.00(0.00)\n",
      "Iter 4640 | Time 16.2274(16.9723) | Bit/dim 3.6533(3.6772) | Xent 0.6603(0.6722) | Loss 2638.6294(2910.8547) | Error 0.2322(0.2385) Steps 0(0.00) | Grad Norm 1666.1556(1893.1312) | Total Time 0.00(0.00)\n",
      "Iter 4650 | Time 15.8256(16.8677) | Bit/dim 3.6549(3.6755) | Xent 0.6937(0.6772) | Loss 2613.1243(2837.5462) | Error 0.2467(0.2405) Steps 0(0.00) | Grad Norm 1640.9848(1931.4351) | Total Time 0.00(0.00)\n",
      "Iter 4660 | Time 16.4903(16.9380) | Bit/dim 3.7046(3.6780) | Xent 0.7077(0.6767) | Loss 2791.0579(2790.4222) | Error 0.2378(0.2407) Steps 0(0.00) | Grad Norm 2343.0142(1946.0452) | Total Time 0.00(0.00)\n",
      "Iter 4670 | Time 15.4455(16.7558) | Bit/dim 3.6631(3.6813) | Xent 0.6770(0.6785) | Loss 2614.9971(2748.1146) | Error 0.2344(0.2417) Steps 0(0.00) | Grad Norm 1917.4768(2103.8105) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 87.5522, Epoch Time 1025.6313(1000.7179), Bit/dim 3.6805(best: 3.6799), Xent 0.7099, Loss 4.0355, Error 0.2495(best: 0.2602)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4680 | Time 16.0289(16.7743) | Bit/dim 3.6869(3.6811) | Xent 0.5926(0.6705) | Loss 2668.7419(3056.2541) | Error 0.2022(0.2390) Steps 0(0.00) | Grad Norm 1555.7319(1993.4652) | Total Time 0.00(0.00)\n",
      "Iter 4690 | Time 16.6184(16.9448) | Bit/dim 3.6738(3.6795) | Xent 0.7269(0.6738) | Loss 2567.9497(2943.1658) | Error 0.2544(0.2405) Steps 0(0.00) | Grad Norm 2889.2608(2084.5206) | Total Time 0.00(0.00)\n",
      "Iter 4700 | Time 16.8698(17.0133) | Bit/dim 3.6654(3.6782) | Xent 0.6661(0.6838) | Loss 2635.2266(2866.8134) | Error 0.2311(0.2427) Steps 0(0.00) | Grad Norm 2499.6171(2226.7902) | Total Time 0.00(0.00)\n",
      "Iter 4710 | Time 20.4616(17.2116) | Bit/dim 3.6974(3.6797) | Xent 0.7467(0.6883) | Loss 2773.0562(2820.3455) | Error 0.2678(0.2446) Steps 0(0.00) | Grad Norm 1880.3756(2233.6446) | Total Time 0.00(0.00)\n",
      "Iter 4720 | Time 16.7664(17.0653) | Bit/dim 3.6638(3.6807) | Xent 0.6692(0.6854) | Loss 2631.0930(2767.2406) | Error 0.2433(0.2435) Steps 0(0.00) | Grad Norm 1611.1995(2196.9213) | Total Time 0.00(0.00)\n",
      "Iter 4730 | Time 17.8213(17.1155) | Bit/dim 3.6711(3.6776) | Xent 0.7008(0.6817) | Loss 2715.8208(2739.9221) | Error 0.2578(0.2429) Steps 0(0.00) | Grad Norm 4269.0674(2193.2369) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 89.2218, Epoch Time 1053.7951(1002.3102), Bit/dim 3.6821(best: 3.6799), Xent 0.7692, Loss 4.0667, Error 0.2664(best: 0.2495)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4740 | Time 17.8353(17.2124) | Bit/dim 3.7177(3.6802) | Xent 0.6409(0.6756) | Loss 2747.6116(3014.1548) | Error 0.2244(0.2411) Steps 0(0.00) | Grad Norm 2331.9011(2196.1357) | Total Time 0.00(0.00)\n",
      "Iter 4750 | Time 15.6612(17.1560) | Bit/dim 3.6512(3.6772) | Xent 0.6922(0.6731) | Loss 2633.1033(2922.6250) | Error 0.2611(0.2409) Steps 0(0.00) | Grad Norm 1773.6286(2125.5453) | Total Time 0.00(0.00)\n",
      "Iter 4760 | Time 16.7365(17.2689) | Bit/dim 3.6421(3.6753) | Xent 0.6356(0.6679) | Loss 2478.8596(2847.2078) | Error 0.2322(0.2372) Steps 0(0.00) | Grad Norm 1814.0899(2089.1128) | Total Time 0.00(0.00)\n",
      "Iter 4770 | Time 18.3739(17.2689) | Bit/dim 3.6384(3.6742) | Xent 0.6453(0.6779) | Loss 2676.9783(2792.0477) | Error 0.2444(0.2411) Steps 0(0.00) | Grad Norm 1840.9117(2239.1847) | Total Time 0.00(0.00)\n",
      "Iter 4780 | Time 15.3909(17.1656) | Bit/dim 3.7179(3.6782) | Xent 0.6502(0.6757) | Loss 2537.7761(2751.5654) | Error 0.2322(0.2400) Steps 0(0.00) | Grad Norm 1632.6266(2154.2758) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 88.0656, Epoch Time 1054.9031(1003.8880), Bit/dim 3.6800(best: 3.6799), Xent 0.7351, Loss 4.0475, Error 0.2570(best: 0.2495)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4790 | Time 19.0279(17.2815) | Bit/dim 3.6476(3.6763) | Xent 0.6793(0.6707) | Loss 2759.3313(3073.2722) | Error 0.2367(0.2387) Steps 0(0.00) | Grad Norm 2855.9320(2160.7860) | Total Time 0.00(0.00)\n",
      "Iter 4800 | Time 16.9591(17.3605) | Bit/dim 3.7024(3.6759) | Xent 0.5799(0.6725) | Loss 2571.6279(2958.2530) | Error 0.2133(0.2402) Steps 0(0.00) | Grad Norm 1995.2403(2357.7874) | Total Time 0.00(0.00)\n",
      "Iter 4810 | Time 17.6424(17.2336) | Bit/dim 3.6413(3.6792) | Xent 0.7238(0.6785) | Loss 2598.9758(2877.9910) | Error 0.2511(0.2423) Steps 0(0.00) | Grad Norm 3300.9054(2388.2099) | Total Time 0.00(0.00)\n",
      "Iter 4820 | Time 18.2861(17.2358) | Bit/dim 3.6721(3.6812) | Xent 0.6762(0.6750) | Loss 2480.5024(2815.2735) | Error 0.2422(0.2405) Steps 0(0.00) | Grad Norm 2058.5326(2324.5147) | Total Time 0.00(0.00)\n",
      "Iter 4830 | Time 18.0302(17.3192) | Bit/dim 3.6854(3.6788) | Xent 0.6865(0.6664) | Loss 2597.2737(2765.8085) | Error 0.2567(0.2372) Steps 0(0.00) | Grad Norm 2699.8661(2176.4712) | Total Time 0.00(0.00)\n",
      "Iter 4840 | Time 16.6986(17.2574) | Bit/dim 3.7048(3.6787) | Xent 0.7265(0.6672) | Loss 2644.3955(2727.4127) | Error 0.2611(0.2361) Steps 0(0.00) | Grad Norm 3294.2360(2164.8919) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 87.4464, Epoch Time 1053.7034(1005.3824), Bit/dim 3.6799(best: 3.6799), Xent 0.7116, Loss 4.0357, Error 0.2514(best: 0.2495)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4850 | Time 15.9124(17.1830) | Bit/dim 3.7013(3.6774) | Xent 0.6971(0.6614) | Loss 2555.1836(2977.3824) | Error 0.2478(0.2353) Steps 0(0.00) | Grad Norm 2297.4772(2164.3836) | Total Time 0.00(0.00)\n",
      "Iter 4860 | Time 16.6005(17.1893) | Bit/dim 3.6440(3.6741) | Xent 0.6394(0.6594) | Loss 2619.6633(2889.4357) | Error 0.2311(0.2359) Steps 0(0.00) | Grad Norm 1462.5644(2165.7394) | Total Time 0.00(0.00)\n",
      "Iter 4870 | Time 17.7054(17.1462) | Bit/dim 3.6611(3.6726) | Xent 0.5931(0.6501) | Loss 2686.7156(2827.3630) | Error 0.1967(0.2306) Steps 0(0.00) | Grad Norm 1248.1115(1936.3305) | Total Time 0.00(0.00)\n",
      "Iter 4880 | Time 16.0201(16.8861) | Bit/dim 3.7090(3.6728) | Xent 0.7339(0.6578) | Loss 2622.1453(2775.1388) | Error 0.2578(0.2334) Steps 0(0.00) | Grad Norm 3715.1174(2187.0091) | Total Time 0.00(0.00)\n",
      "Iter 4890 | Time 15.5176(16.9000) | Bit/dim 3.7449(3.6781) | Xent 0.6166(0.6643) | Loss 2656.3464(2746.2640) | Error 0.2244(0.2357) Steps 0(0.00) | Grad Norm 1296.3503(2122.1096) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 86.5669, Epoch Time 1032.6624(1006.2008), Bit/dim 3.6862(best: 3.6799), Xent 0.7292, Loss 4.0508, Error 0.2561(best: 0.2495)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4900 | Time 16.8849(17.0261) | Bit/dim 3.6327(3.6789) | Xent 0.6057(0.6609) | Loss 2599.6753(3051.8621) | Error 0.2189(0.2352) Steps 0(0.00) | Grad Norm 1543.6407(2053.5879) | Total Time 0.00(0.00)\n",
      "Iter 4910 | Time 16.1723(17.0779) | Bit/dim 3.6876(3.6753) | Xent 0.6470(0.6545) | Loss 2597.5330(2947.3488) | Error 0.2256(0.2332) Steps 0(0.00) | Grad Norm 1981.8870(2052.3645) | Total Time 0.00(0.00)\n",
      "Iter 4920 | Time 18.2873(17.0903) | Bit/dim 3.6823(3.6765) | Xent 0.6433(0.6513) | Loss 2724.1587(2870.4443) | Error 0.2289(0.2330) Steps 0(0.00) | Grad Norm 2053.2691(2101.5839) | Total Time 0.00(0.00)\n",
      "Iter 4930 | Time 16.9354(17.1121) | Bit/dim 3.7050(3.6783) | Xent 0.6576(0.6462) | Loss 2584.5535(2807.3732) | Error 0.2356(0.2320) Steps 0(0.00) | Grad Norm 1441.0453(1971.3907) | Total Time 0.00(0.00)\n",
      "Iter 4940 | Time 16.6745(17.0251) | Bit/dim 3.6427(3.6760) | Xent 0.5810(0.6442) | Loss 2581.1663(2760.4904) | Error 0.1978(0.2305) Steps 0(0.00) | Grad Norm 1447.4850(1932.9585) | Total Time 0.00(0.00)\n",
      "Iter 4950 | Time 17.4869(17.2097) | Bit/dim 3.6699(3.6721) | Xent 0.6327(0.6487) | Loss 2674.6794(2730.5749) | Error 0.2167(0.2315) Steps 0(0.00) | Grad Norm 2298.1521(1938.1868) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 87.6543, Epoch Time 1051.4987(1007.5598), Bit/dim 3.6698(best: 3.6799), Xent 0.7133, Loss 4.0265, Error 0.2511(best: 0.2495)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4960 | Time 17.5048(17.2281) | Bit/dim 3.6757(3.6709) | Xent 0.6512(0.6463) | Loss 2670.6743(2995.1310) | Error 0.2244(0.2316) Steps 0(0.00) | Grad Norm 2287.0863(1999.6329) | Total Time 0.00(0.00)\n",
      "Iter 4970 | Time 16.6109(17.2197) | Bit/dim 3.6963(3.6713) | Xent 0.6508(0.6569) | Loss 2643.3459(2898.0546) | Error 0.2356(0.2370) Steps 0(0.00) | Grad Norm 2353.7343(2163.8906) | Total Time 0.00(0.00)\n",
      "Iter 4980 | Time 19.6171(17.2607) | Bit/dim 3.6745(3.6730) | Xent 0.6419(0.6618) | Loss 2704.0208(2839.7689) | Error 0.2433(0.2379) Steps 0(0.00) | Grad Norm 1420.3645(2119.2473) | Total Time 0.00(0.00)\n",
      "Iter 4990 | Time 19.1801(17.2148) | Bit/dim 3.6530(3.6726) | Xent 0.6438(0.6596) | Loss 2642.4915(2783.4396) | Error 0.2233(0.2357) Steps 0(0.00) | Grad Norm 1459.8383(2025.9770) | Total Time 0.00(0.00)\n",
      "Iter 5000 | Time 17.2222(17.2260) | Bit/dim 3.6638(3.6710) | Xent 0.6573(0.6562) | Loss 2673.9548(2745.9673) | Error 0.2333(0.2344) Steps 0(0.00) | Grad Norm 1809.9164(1895.4181) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 86.9771, Epoch Time 1049.6173(1008.8215), Bit/dim 3.6652(best: 3.6698), Xent 0.6959, Loss 4.0131, Error 0.2453(best: 0.2495)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5010 | Time 16.5974(17.1529) | Bit/dim 3.6217(3.6701) | Xent 0.6861(0.6452) | Loss 2507.4409(3067.2777) | Error 0.2300(0.2297) Steps 0(0.00) | Grad Norm 2245.0795(1859.3771) | Total Time 0.00(0.00)\n",
      "Iter 5020 | Time 16.2417(17.0144) | Bit/dim 3.6546(3.6678) | Xent 0.6540(0.6400) | Loss 2608.4463(2948.2306) | Error 0.2278(0.2271) Steps 0(0.00) | Grad Norm 2824.3851(2012.3618) | Total Time 0.00(0.00)\n",
      "Iter 5030 | Time 19.0565(17.1173) | Bit/dim 3.6303(3.6687) | Xent 0.7730(0.6486) | Loss 2570.1287(2857.1943) | Error 0.2756(0.2308) Steps 0(0.00) | Grad Norm 2533.7655(2116.5068) | Total Time 0.00(0.00)\n",
      "Iter 5040 | Time 17.8583(17.0639) | Bit/dim 3.6621(3.6696) | Xent 0.6304(0.6479) | Loss 2666.1340(2795.2914) | Error 0.2222(0.2302) Steps 0(0.00) | Grad Norm 2360.2371(2196.8512) | Total Time 0.00(0.00)\n",
      "Iter 5050 | Time 19.2894(17.1798) | Bit/dim 3.6797(3.6709) | Xent 0.7402(0.6564) | Loss 2644.4138(2756.4447) | Error 0.2678(0.2329) Steps 0(0.00) | Grad Norm 3447.1734(2275.7851) | Total Time 0.00(0.00)\n",
      "Iter 5060 | Time 19.6560(17.3979) | Bit/dim 3.6476(3.6723) | Xent 0.6792(0.6625) | Loss 2538.4692(2724.0178) | Error 0.2467(0.2360) Steps 0(0.00) | Grad Norm 2739.2543(2400.9049) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 89.9204, Epoch Time 1053.0044(1010.1470), Bit/dim 3.6866(best: 3.6652), Xent 0.7142, Loss 4.0437, Error 0.2505(best: 0.2453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5070 | Time 16.8778(17.3482) | Bit/dim 3.7046(3.6757) | Xent 0.6852(0.6568) | Loss 2733.2878(3001.3232) | Error 0.2400(0.2343) Steps 0(0.00) | Grad Norm 2768.0744(2316.7372) | Total Time 0.00(0.00)\n",
      "Iter 5080 | Time 18.4560(17.2769) | Bit/dim 3.6588(3.6731) | Xent 0.6732(0.6455) | Loss 2636.7681(2904.6574) | Error 0.2233(0.2298) Steps 0(0.00) | Grad Norm 2129.5110(2234.7856) | Total Time 0.00(0.00)\n",
      "Iter 5090 | Time 16.7633(17.1822) | Bit/dim 3.6721(3.6715) | Xent 0.6405(0.6387) | Loss 2723.2573(2828.2230) | Error 0.2200(0.2265) Steps 0(0.00) | Grad Norm 1760.7309(2073.6225) | Total Time 0.00(0.00)\n",
      "Iter 5100 | Time 17.5888(17.2977) | Bit/dim 3.6536(3.6669) | Xent 0.6453(0.6427) | Loss 2598.5630(2768.7802) | Error 0.2233(0.2282) Steps 0(0.00) | Grad Norm 2086.5204(2044.1800) | Total Time 0.00(0.00)\n",
      "Iter 5110 | Time 16.3103(17.2745) | Bit/dim 3.7025(3.6683) | Xent 0.7089(0.6404) | Loss 2654.3027(2734.4604) | Error 0.2544(0.2282) Steps 0(0.00) | Grad Norm 3572.6382(2070.8947) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 87.6248, Epoch Time 1050.2319(1011.3495), Bit/dim 3.6692(best: 3.6652), Xent 0.7381, Loss 4.0383, Error 0.2584(best: 0.2453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5120 | Time 17.6103(17.2274) | Bit/dim 3.6877(3.6682) | Xent 0.5953(0.6346) | Loss 2690.7390(3033.5530) | Error 0.2144(0.2258) Steps 0(0.00) | Grad Norm 1582.5768(2102.6356) | Total Time 0.00(0.00)\n",
      "Iter 5130 | Time 17.2246(17.1647) | Bit/dim 3.6234(3.6703) | Xent 0.6382(0.6399) | Loss 2605.4502(2927.5576) | Error 0.2389(0.2284) Steps 0(0.00) | Grad Norm 2992.8505(2256.8309) | Total Time 0.00(0.00)\n",
      "Iter 5140 | Time 15.8392(17.1524) | Bit/dim 3.6653(3.6700) | Xent 0.6182(0.6391) | Loss 2526.6433(2853.1575) | Error 0.2278(0.2278) Steps 0(0.00) | Grad Norm 1311.2828(2138.2412) | Total Time 0.00(0.00)\n",
      "Iter 5150 | Time 18.5238(17.2060) | Bit/dim 3.6623(3.6701) | Xent 0.6451(0.6293) | Loss 2679.3640(2785.0157) | Error 0.2356(0.2257) Steps 0(0.00) | Grad Norm 3016.8138(2063.0879) | Total Time 0.00(0.00)\n",
      "Iter 5160 | Time 16.3329(17.1926) | Bit/dim 3.6626(3.6673) | Xent 0.5688(0.6228) | Loss 2486.4561(2736.7840) | Error 0.2156(0.2235) Steps 0(0.00) | Grad Norm 2069.8819(1978.7452) | Total Time 0.00(0.00)\n",
      "Iter 5170 | Time 17.5725(17.2747) | Bit/dim 3.6845(3.6652) | Xent 0.6299(0.6280) | Loss 2661.3403(2712.1836) | Error 0.2356(0.2246) Steps 0(0.00) | Grad Norm 3827.6514(2013.2552) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 87.7761, Epoch Time 1049.6058(1012.4972), Bit/dim 3.6690(best: 3.6652), Xent 0.7354, Loss 4.0367, Error 0.2586(best: 0.2453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5180 | Time 16.6081(17.3265) | Bit/dim 3.6485(3.6632) | Xent 0.5500(0.6216) | Loss 2619.1643(2971.1193) | Error 0.2033(0.2208) Steps 0(0.00) | Grad Norm 1029.2712(1972.1210) | Total Time 0.00(0.00)\n",
      "Iter 5190 | Time 17.8025(17.3563) | Bit/dim 3.6898(3.6641) | Xent 0.6065(0.6196) | Loss 2571.5774(2877.3084) | Error 0.2122(0.2207) Steps 0(0.00) | Grad Norm 1745.4855(1911.8493) | Total Time 0.00(0.00)\n",
      "Iter 5200 | Time 16.5816(17.2677) | Bit/dim 3.6902(3.6643) | Xent 0.6181(0.6168) | Loss 2560.4270(2803.2951) | Error 0.2222(0.2206) Steps 0(0.00) | Grad Norm 1571.4249(1898.5536) | Total Time 0.00(0.00)\n",
      "Iter 5210 | Time 19.2021(17.5240) | Bit/dim 3.6859(3.6631) | Xent 0.6123(0.6158) | Loss 2675.7188(2760.2070) | Error 0.2111(0.2193) Steps 0(0.00) | Grad Norm 1406.2245(1835.6639) | Total Time 0.00(0.00)\n",
      "Iter 5220 | Time 17.0414(17.5758) | Bit/dim 3.6632(3.6628) | Xent 0.6651(0.6226) | Loss 2619.5330(2727.6291) | Error 0.2367(0.2216) Steps 0(0.00) | Grad Norm 1999.9889(1898.8724) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 89.4732, Epoch Time 1071.0657(1014.2543), Bit/dim 3.6642(best: 3.6652), Xent 0.7376, Loss 4.0330, Error 0.2509(best: 0.2453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5230 | Time 16.0721(17.3877) | Bit/dim 3.6867(3.6658) | Xent 0.6183(0.6231) | Loss 2486.8210(3038.9148) | Error 0.2222(0.2218) Steps 0(0.00) | Grad Norm 2284.0303(1937.4901) | Total Time 0.00(0.00)\n",
      "Iter 5240 | Time 16.2099(17.4126) | Bit/dim 3.6958(3.6646) | Xent 0.5941(0.6234) | Loss 2503.9470(2931.1601) | Error 0.2233(0.2223) Steps 0(0.00) | Grad Norm 1149.7747(2132.2142) | Total Time 0.00(0.00)\n",
      "Iter 5250 | Time 16.5343(17.3530) | Bit/dim 3.6737(3.6645) | Xent 0.5925(0.6250) | Loss 2628.5925(2850.9026) | Error 0.2178(0.2233) Steps 0(0.00) | Grad Norm 1935.3962(2045.9788) | Total Time 0.00(0.00)\n",
      "Iter 5260 | Time 18.5277(17.4108) | Bit/dim 3.6694(3.6658) | Xent 0.5794(0.6238) | Loss 2728.2825(2794.1006) | Error 0.2111(0.2229) Steps 0(0.00) | Grad Norm 2014.9622(1992.5011) | Total Time 0.00(0.00)\n",
      "Iter 5270 | Time 16.2668(17.3069) | Bit/dim 3.6744(3.6636) | Xent 0.6117(0.6290) | Loss 2572.0574(2748.7195) | Error 0.2244(0.2247) Steps 0(0.00) | Grad Norm 1617.0714(2040.7856) | Total Time 0.00(0.00)\n",
      "Iter 5280 | Time 16.7458(17.4332) | Bit/dim 3.7091(3.6656) | Xent 0.6544(0.6295) | Loss 2678.7097(2715.9983) | Error 0.2467(0.2235) Steps 0(0.00) | Grad Norm 2994.9911(2007.5628) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 93.8355, Epoch Time 1064.4256(1015.7594), Bit/dim 3.6677(best: 3.6642), Xent 0.7053, Loss 4.0203, Error 0.2490(best: 0.2453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5290 | Time 18.1405(17.4933) | Bit/dim 3.6377(3.6645) | Xent 0.6278(0.6220) | Loss 2595.6152(2982.7540) | Error 0.2200(0.2196) Steps 0(0.00) | Grad Norm 2208.5412(2006.9516) | Total Time 0.00(0.00)\n",
      "Iter 5300 | Time 16.9566(17.6495) | Bit/dim 3.6310(3.6632) | Xent 0.6790(0.6253) | Loss 2543.2395(2881.4607) | Error 0.2511(0.2199) Steps 0(0.00) | Grad Norm 2192.2988(2075.0135) | Total Time 0.00(0.00)\n",
      "Iter 5310 | Time 17.3173(17.6506) | Bit/dim 3.6670(3.6628) | Xent 0.5842(0.6280) | Loss 2640.3223(2813.1082) | Error 0.2133(0.2217) Steps 0(0.00) | Grad Norm 1523.6770(2175.9213) | Total Time 0.00(0.00)\n",
      "Iter 5320 | Time 21.0125(17.8778) | Bit/dim 3.6703(3.6646) | Xent 0.6264(0.6300) | Loss 2683.4333(2768.3395) | Error 0.2311(0.2230) Steps 0(0.00) | Grad Norm 1273.4504(2228.8161) | Total Time 0.00(0.00)\n",
      "Iter 5330 | Time 18.7566(17.9367) | Bit/dim 3.6881(3.6657) | Xent 0.5948(0.6231) | Loss 2700.5315(2736.3325) | Error 0.2278(0.2225) Steps 0(0.00) | Grad Norm 1781.2297(2119.5981) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 94.6897, Epoch Time 1103.5628(1018.3935), Bit/dim 3.6621(best: 3.6642), Xent 0.7180, Loss 4.0211, Error 0.2517(best: 0.2453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5340 | Time 20.7154(18.1186) | Bit/dim 3.6690(3.6654) | Xent 0.6266(0.6186) | Loss 2655.5115(3054.4680) | Error 0.2289(0.2222) Steps 0(0.00) | Grad Norm 1665.2668(2013.4737) | Total Time 0.00(0.00)\n",
      "Iter 5350 | Time 17.9337(17.9652) | Bit/dim 3.6674(3.6654) | Xent 0.6261(0.6156) | Loss 2715.0000(2942.1069) | Error 0.2367(0.2222) Steps 0(0.00) | Grad Norm 3166.3892(2077.6807) | Total Time 0.00(0.00)\n",
      "Iter 5360 | Time 17.8656(18.0248) | Bit/dim 3.6617(3.6636) | Xent 0.5856(0.6171) | Loss 2703.2227(2860.8170) | Error 0.2011(0.2217) Steps 0(0.00) | Grad Norm 1309.8796(2144.5675) | Total Time 0.00(0.00)\n",
      "Iter 5370 | Time 16.6940(17.9772) | Bit/dim 3.6417(3.6641) | Xent 0.5585(0.6149) | Loss 2577.8901(2800.7835) | Error 0.2067(0.2210) Steps 0(0.00) | Grad Norm 1758.0787(2095.9184) | Total Time 0.00(0.00)\n",
      "Iter 5380 | Time 17.5823(17.9799) | Bit/dim 3.6543(3.6644) | Xent 0.6190(0.6134) | Loss 2625.8530(2753.8716) | Error 0.2178(0.2203) Steps 0(0.00) | Grad Norm 1876.9544(1987.9204) | Total Time 0.00(0.00)\n",
      "Iter 5390 | Time 18.4431(18.0204) | Bit/dim 3.6886(3.6627) | Xent 0.6333(0.6172) | Loss 2697.5012(2719.6606) | Error 0.2367(0.2214) Steps 0(0.00) | Grad Norm 1774.3841(2027.4815) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 93.2993, Epoch Time 1102.5121(1020.9171), Bit/dim 3.6561(best: 3.6621), Xent 0.6815, Loss 3.9969, Error 0.2387(best: 0.2453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5400 | Time 18.1796(18.0656) | Bit/dim 3.6210(3.6595) | Xent 0.5325(0.6059) | Loss 2706.4668(2990.0522) | Error 0.1867(0.2166) Steps 0(0.00) | Grad Norm 1417.4057(1906.9722) | Total Time 0.00(0.00)\n",
      "Iter 5410 | Time 17.3420(18.1850) | Bit/dim 3.6710(3.6626) | Xent 0.6015(0.6009) | Loss 2598.6055(2896.5412) | Error 0.1989(0.2143) Steps 0(0.00) | Grad Norm 3093.6687(1911.0764) | Total Time 0.00(0.00)\n",
      "Iter 5420 | Time 17.8028(18.1878) | Bit/dim 3.6829(3.6629) | Xent 0.6256(0.5989) | Loss 2655.0217(2828.0829) | Error 0.2100(0.2121) Steps 0(0.00) | Grad Norm 1870.1531(1903.7444) | Total Time 0.00(0.00)\n",
      "Iter 5430 | Time 18.2046(18.0207) | Bit/dim 3.6693(3.6612) | Xent 0.7012(0.6086) | Loss 2468.5356(2773.0094) | Error 0.2489(0.2152) Steps 0(0.00) | Grad Norm 2871.6610(1929.3700) | Total Time 0.00(0.00)\n",
      "Iter 5440 | Time 17.6865(18.1254) | Bit/dim 3.6545(3.6601) | Xent 0.5747(0.6133) | Loss 2660.7341(2744.0920) | Error 0.2056(0.2170) Steps 0(0.00) | Grad Norm 1832.5391(2053.8277) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 93.5068, Epoch Time 1106.1161(1023.4730), Bit/dim 3.6656(best: 3.6561), Xent 0.7553, Loss 4.0433, Error 0.2619(best: 0.2387)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5450 | Time 17.7483(18.1014) | Bit/dim 3.6569(3.6632) | Xent 0.6248(0.6157) | Loss 2643.4116(3066.5561) | Error 0.2189(0.2169) Steps 0(0.00) | Grad Norm 2922.8959(2124.4645) | Total Time 0.00(0.00)\n",
      "Iter 5460 | Time 18.2255(18.0081) | Bit/dim 3.6395(3.6580) | Xent 0.6243(0.6075) | Loss 2599.9419(2942.6382) | Error 0.2178(0.2143) Steps 0(0.00) | Grad Norm 2001.9515(1967.2010) | Total Time 0.00(0.00)\n",
      "Iter 5470 | Time 18.6400(18.0356) | Bit/dim 3.6560(3.6595) | Xent 0.6217(0.6067) | Loss 2696.4470(2852.4391) | Error 0.2278(0.2140) Steps 0(0.00) | Grad Norm 2034.9836(1997.3778) | Total Time 0.00(0.00)\n",
      "Iter 5480 | Time 18.0866(17.9524) | Bit/dim 3.6613(3.6601) | Xent 0.6326(0.6086) | Loss 2546.1199(2786.4939) | Error 0.2311(0.2147) Steps 0(0.00) | Grad Norm 2902.7673(2002.6276) | Total Time 0.00(0.00)\n",
      "Iter 5490 | Time 18.3802(17.8723) | Bit/dim 3.6541(3.6594) | Xent 0.5812(0.6091) | Loss 2697.8445(2741.0872) | Error 0.1989(0.2155) Steps 0(0.00) | Grad Norm 1790.5139(2003.5894) | Total Time 0.00(0.00)\n",
      "Iter 5500 | Time 17.1530(17.7937) | Bit/dim 3.6620(3.6589) | Xent 0.6086(0.6056) | Loss 2655.4014(2714.9490) | Error 0.2233(0.2153) Steps 0(0.00) | Grad Norm 1877.0232(1946.5403) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 94.0447, Epoch Time 1093.3254(1025.5686), Bit/dim 3.6516(best: 3.6561), Xent 0.6977, Loss 4.0004, Error 0.2461(best: 0.2387)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5510 | Time 16.4080(17.7530) | Bit/dim 3.6638(3.6599) | Xent 0.5138(0.5959) | Loss 2492.8347(2983.5766) | Error 0.1811(0.2130) Steps 0(0.00) | Grad Norm 1232.1154(1845.1731) | Total Time 0.00(0.00)\n",
      "Iter 5520 | Time 18.9404(17.9118) | Bit/dim 3.6479(3.6592) | Xent 0.6059(0.6010) | Loss 2647.0593(2887.3154) | Error 0.2411(0.2159) Steps 0(0.00) | Grad Norm 1436.4044(1908.7381) | Total Time 0.00(0.00)\n",
      "Iter 5530 | Time 18.3962(18.1027) | Bit/dim 3.6627(3.6577) | Xent 0.5359(0.5934) | Loss 2650.1309(2817.3988) | Error 0.1900(0.2135) Steps 0(0.00) | Grad Norm 2708.7499(1921.9712) | Total Time 0.00(0.00)\n",
      "Iter 5540 | Time 18.6890(18.1898) | Bit/dim 3.6417(3.6575) | Xent 0.5772(0.5906) | Loss 2681.4048(2773.0994) | Error 0.2144(0.2127) Steps 0(0.00) | Grad Norm 1137.9417(1894.5451) | Total Time 0.00(0.00)\n",
      "Iter 5550 | Time 18.6635(18.2420) | Bit/dim 3.6762(3.6546) | Xent 0.5539(0.5833) | Loss 2512.9714(2721.2419) | Error 0.1978(0.2089) Steps 0(0.00) | Grad Norm 1957.5217(1836.2805) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 92.9714, Epoch Time 1118.5648(1028.3585), Bit/dim 3.6542(best: 3.6516), Xent 0.7011, Loss 4.0048, Error 0.2436(best: 0.2387)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5560 | Time 18.0419(18.2828) | Bit/dim 3.6712(3.6529) | Xent 0.5333(0.5829) | Loss 2603.9880(3050.0542) | Error 0.1844(0.2089) Steps 0(0.00) | Grad Norm 1396.3702(1804.9566) | Total Time 0.00(0.00)\n",
      "Iter 5570 | Time 18.5136(18.2425) | Bit/dim 3.6464(3.6513) | Xent 0.5388(0.5794) | Loss 2672.2004(2926.7912) | Error 0.1967(0.2065) Steps 0(0.00) | Grad Norm 1785.7923(1750.1746) | Total Time 0.00(0.00)\n",
      "Iter 5580 | Time 18.3653(18.3058) | Bit/dim 3.6366(3.6515) | Xent 0.5844(0.5878) | Loss 2590.5200(2841.5459) | Error 0.2056(0.2096) Steps 0(0.00) | Grad Norm 1943.5523(1881.0518) | Total Time 0.00(0.00)\n",
      "Iter 5590 | Time 16.7767(18.2460) | Bit/dim 3.6825(3.6548) | Xent 0.6149(0.5888) | Loss 2499.5613(2787.7391) | Error 0.2222(0.2093) Steps 0(0.00) | Grad Norm 1937.0858(1879.6337) | Total Time 0.00(0.00)\n",
      "Iter 5600 | Time 19.5873(18.3696) | Bit/dim 3.6533(3.6547) | Xent 0.5635(0.5890) | Loss 2741.5386(2750.2342) | Error 0.1967(0.2092) Steps 0(0.00) | Grad Norm 1451.7297(1941.5604) | Total Time 0.00(0.00)\n",
      "Iter 5610 | Time 17.7242(18.2694) | Bit/dim 3.6319(3.6565) | Xent 0.6104(0.5950) | Loss 2481.7349(2717.8682) | Error 0.2200(0.2126) Steps 0(0.00) | Grad Norm 1978.2966(1998.6472) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 94.4242, Epoch Time 1116.4536(1031.0013), Bit/dim 3.6650(best: 3.6516), Xent 0.6934, Loss 4.0117, Error 0.2406(best: 0.2387)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5620 | Time 19.2203(18.3126) | Bit/dim 3.6279(3.6580) | Xent 0.5619(0.5955) | Loss 2672.7593(3004.0393) | Error 0.2111(0.2125) Steps 0(0.00) | Grad Norm 2389.0951(2052.9659) | Total Time 0.00(0.00)\n",
      "Iter 5630 | Time 17.7780(18.2646) | Bit/dim 3.6516(3.6583) | Xent 0.5252(0.5881) | Loss 2489.7412(2893.9175) | Error 0.1767(0.2089) Steps 0(0.00) | Grad Norm 1932.5692(2012.6462) | Total Time 0.00(0.00)\n",
      "Iter 5640 | Time 17.7883(18.2948) | Bit/dim 3.6327(3.6535) | Xent 0.5166(0.5803) | Loss 2659.6399(2821.7839) | Error 0.1733(0.2066) Steps 0(0.00) | Grad Norm 1065.1120(1873.1107) | Total Time 0.00(0.00)\n",
      "Iter 5650 | Time 19.8315(18.4572) | Bit/dim 3.6400(3.6560) | Xent 0.6073(0.5813) | Loss 2608.8953(2777.4304) | Error 0.2044(0.2075) Steps 0(0.00) | Grad Norm 2001.0161(1817.9957) | Total Time 0.00(0.00)\n",
      "Iter 5660 | Time 18.2806(18.5108) | Bit/dim 3.6232(3.6548) | Xent 0.6308(0.5855) | Loss 2683.6592(2737.5658) | Error 0.2156(0.2090) Steps 0(0.00) | Grad Norm 2418.4414(1894.3500) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 94.0283, Epoch Time 1126.2047(1033.8574), Bit/dim 3.6590(best: 3.6516), Xent 0.6868, Loss 4.0024, Error 0.2414(best: 0.2387)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5670 | Time 20.1991(18.6545) | Bit/dim 3.6542(3.6543) | Xent 0.5615(0.5877) | Loss 2676.8079(3061.0091) | Error 0.1900(0.2092) Steps 0(0.00) | Grad Norm 2230.1148(2051.2567) | Total Time 0.00(0.00)\n",
      "Iter 5680 | Time 21.7449(18.7582) | Bit/dim 3.6594(3.6564) | Xent 0.5674(0.5792) | Loss 2673.4260(2945.1765) | Error 0.2078(0.2065) Steps 0(0.00) | Grad Norm 1382.7442(2007.6266) | Total Time 0.00(0.00)\n",
      "Iter 5690 | Time 19.2864(18.7066) | Bit/dim 3.6700(3.6576) | Xent 0.5966(0.5803) | Loss 2680.9839(2861.1912) | Error 0.2111(0.2062) Steps 0(0.00) | Grad Norm 2624.0674(1945.2790) | Total Time 0.00(0.00)\n",
      "Iter 5700 | Time 17.8324(18.6667) | Bit/dim 3.6678(3.6535) | Xent 0.5158(0.5794) | Loss 2468.6899(2787.9473) | Error 0.1944(0.2076) Steps 0(0.00) | Grad Norm 1912.5708(1899.7265) | Total Time 0.00(0.00)\n",
      "Iter 5710 | Time 16.8342(18.4595) | Bit/dim 3.6708(3.6567) | Xent 0.6441(0.5910) | Loss 2631.4421(2742.5552) | Error 0.2322(0.2113) Steps 0(0.00) | Grad Norm 4029.9739(2032.8016) | Total Time 0.00(0.00)\n",
      "Iter 5720 | Time 18.4474(18.4864) | Bit/dim 3.6780(3.6587) | Xent 0.6062(0.5944) | Loss 2575.6965(2714.9892) | Error 0.1933(0.2126) Steps 0(0.00) | Grad Norm 1659.3315(2138.3033) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 94.9881, Epoch Time 1138.1454(1036.9861), Bit/dim 3.6622(best: 3.6516), Xent 0.6991, Loss 4.0117, Error 0.2416(best: 0.2387)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5730 | Time 18.6029(18.5059) | Bit/dim 3.6448(3.6567) | Xent 0.5628(0.5866) | Loss 2669.2649(2985.2613) | Error 0.2067(0.2105) Steps 0(0.00) | Grad Norm 1019.0910(2009.9489) | Total Time 0.00(0.00)\n",
      "Iter 5740 | Time 19.1819(18.5989) | Bit/dim 3.6181(3.6517) | Xent 0.4993(0.5737) | Loss 2483.2297(2879.6036) | Error 0.1789(0.2046) Steps 0(0.00) | Grad Norm 1963.7660(1911.6195) | Total Time 0.00(0.00)\n",
      "Iter 5750 | Time 16.9675(18.5585) | Bit/dim 3.6641(3.6492) | Xent 0.6363(0.5801) | Loss 2594.9209(2810.5278) | Error 0.2056(0.2064) Steps 0(0.00) | Grad Norm 2289.3826(2047.4754) | Total Time 0.00(0.00)\n",
      "Iter 5760 | Time 17.7945(18.5293) | Bit/dim 3.6723(3.6524) | Xent 0.5862(0.5850) | Loss 2606.4976(2758.1375) | Error 0.2056(0.2084) Steps 0(0.00) | Grad Norm 1963.7351(2017.5199) | Total Time 0.00(0.00)\n",
      "Iter 5770 | Time 17.6960(18.7036) | Bit/dim 3.6498(3.6543) | Xent 0.5423(0.5811) | Loss 2667.2761(2730.0601) | Error 0.1889(0.2067) Steps 0(0.00) | Grad Norm 1074.9614(1895.5420) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 96.1527, Epoch Time 1137.5515(1040.0031), Bit/dim 3.6531(best: 3.6516), Xent 0.7175, Loss 4.0119, Error 0.2476(best: 0.2387)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5780 | Time 18.6388(18.4651) | Bit/dim 3.6656(3.6540) | Xent 0.5437(0.5804) | Loss 2722.7896(3049.2492) | Error 0.1867(0.2068) Steps 0(0.00) | Grad Norm 1387.9755(1911.3454) | Total Time 0.00(0.00)\n",
      "Iter 5790 | Time 19.1420(18.4697) | Bit/dim 3.6124(3.6531) | Xent 0.6055(0.5756) | Loss 2643.7405(2942.2108) | Error 0.2156(0.2046) Steps 0(0.00) | Grad Norm 2371.1167(1910.3767) | Total Time 0.00(0.00)\n",
      "Iter 5800 | Time 19.3920(18.3954) | Bit/dim 3.6513(3.6540) | Xent 0.5312(0.5630) | Loss 2635.7883(2846.8394) | Error 0.1989(0.2004) Steps 0(0.00) | Grad Norm 2738.9203(1904.3724) | Total Time 0.00(0.00)\n",
      "Iter 5810 | Time 18.9487(18.4341) | Bit/dim 3.6205(3.6520) | Xent 0.5918(0.5666) | Loss 2534.7131(2777.2083) | Error 0.2156(0.2029) Steps 0(0.00) | Grad Norm 1730.8214(1895.7099) | Total Time 0.00(0.00)\n",
      "Iter 5820 | Time 20.5471(18.5058) | Bit/dim 3.6339(3.6514) | Xent 0.6083(0.5705) | Loss 2652.6260(2733.4713) | Error 0.2156(0.2040) Steps 0(0.00) | Grad Norm 1485.1462(1855.5705) | Total Time 0.00(0.00)\n",
      "Iter 5830 | Time 17.6263(18.4763) | Bit/dim 3.6277(3.6484) | Xent 0.5349(0.5699) | Loss 2593.6499(2692.8158) | Error 0.1744(0.2028) Steps 0(0.00) | Grad Norm 1360.3269(1849.9641) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 96.2537, Epoch Time 1126.8512(1042.6085), Bit/dim 3.6491(best: 3.6516), Xent 0.6976, Loss 3.9979, Error 0.2416(best: 0.2387)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5840 | Time 18.2761(18.7384) | Bit/dim 3.6500(3.6499) | Xent 0.5980(0.5628) | Loss 2643.2170(2974.1004) | Error 0.2089(0.2011) Steps 0(0.00) | Grad Norm 2578.1490(1828.9250) | Total Time 0.00(0.00)\n",
      "Iter 5850 | Time 16.6703(18.6904) | Bit/dim 3.6733(3.6505) | Xent 0.5387(0.5589) | Loss 2642.1045(2882.0362) | Error 0.2044(0.1993) Steps 0(0.00) | Grad Norm 1885.5651(1804.7890) | Total Time 0.00(0.00)\n",
      "Iter 5860 | Time 17.6144(18.7706) | Bit/dim 3.6469(3.6480) | Xent 0.6339(0.5628) | Loss 2621.7507(2822.8517) | Error 0.2333(0.2004) Steps 0(0.00) | Grad Norm 3879.4827(1936.6292) | Total Time 0.00(0.00)\n",
      "Iter 5870 | Time 22.0123(18.7490) | Bit/dim 3.6529(3.6501) | Xent 0.5084(0.5631) | Loss 2646.6028(2766.2266) | Error 0.1744(0.2009) Steps 0(0.00) | Grad Norm 2298.3529(2007.5664) | Total Time 0.00(0.00)\n",
      "Iter 5880 | Time 18.5526(18.6452) | Bit/dim 3.6278(3.6504) | Xent 0.5563(0.5668) | Loss 2604.8782(2729.3869) | Error 0.2000(0.2021) Steps 0(0.00) | Grad Norm 1339.3278(2013.6792) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 95.8366, Epoch Time 1149.3240(1045.8100), Bit/dim 3.6541(best: 3.6491), Xent 0.6885, Loss 3.9984, Error 0.2361(best: 0.2387)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5890 | Time 17.5643(18.6523) | Bit/dim 3.6672(3.6540) | Xent 0.6004(0.5605) | Loss 2579.2944(3050.4636) | Error 0.2189(0.2002) Steps 0(0.00) | Grad Norm 2204.0794(1956.3263) | Total Time 0.00(0.00)\n",
      "Iter 5900 | Time 18.0955(18.6543) | Bit/dim 3.7047(3.6578) | Xent 0.6479(0.5651) | Loss 2592.2979(2940.0217) | Error 0.2322(0.2005) Steps 0(0.00) | Grad Norm 1782.0901(2034.7544) | Total Time 0.00(0.00)\n",
      "Iter 5910 | Time 19.5823(18.6345) | Bit/dim 3.6032(3.6548) | Xent 0.5734(0.5664) | Loss 2489.5347(2857.0616) | Error 0.2100(0.2012) Steps 0(0.00) | Grad Norm 1804.3264(1941.6716) | Total Time 0.00(0.00)\n",
      "Iter 5920 | Time 18.7487(18.6668) | Bit/dim 3.5990(3.6497) | Xent 0.6024(0.5628) | Loss 2595.0974(2791.5455) | Error 0.2244(0.1995) Steps 0(0.00) | Grad Norm 2264.9497(1898.2270) | Total Time 0.00(0.00)\n",
      "Iter 5930 | Time 18.9675(18.5153) | Bit/dim 3.6464(3.6462) | Xent 0.6270(0.5655) | Loss 2712.6519(2749.7946) | Error 0.2389(0.2003) Steps 0(0.00) | Grad Norm 3339.4403(1862.6003) | Total Time 0.00(0.00)\n",
      "Iter 5940 | Time 18.2862(18.4874) | Bit/dim 3.6402(3.6475) | Xent 0.5678(0.5661) | Loss 2587.3762(2719.7299) | Error 0.2000(0.2008) Steps 0(0.00) | Grad Norm 2958.2329(1972.2305) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 96.3093, Epoch Time 1129.0729(1048.3078), Bit/dim 3.6633(best: 3.6491), Xent 0.7128, Loss 4.0197, Error 0.2433(best: 0.2361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5950 | Time 19.1686(18.4067) | Bit/dim 3.6719(3.6477) | Xent 0.4699(0.5550) | Loss 2612.6133(2990.1183) | Error 0.1656(0.1967) Steps 0(0.00) | Grad Norm 1921.1133(1956.6787) | Total Time 0.00(0.00)\n",
      "Iter 5960 | Time 18.5671(18.4952) | Bit/dim 3.6738(3.6479) | Xent 0.5662(0.5571) | Loss 2651.0195(2897.8801) | Error 0.2067(0.1976) Steps 0(0.00) | Grad Norm 3183.2280(1901.3507) | Total Time 0.00(0.00)\n",
      "Iter 5970 | Time 18.9045(18.5860) | Bit/dim 3.6260(3.6469) | Xent 0.4780(0.5489) | Loss 2557.7556(2820.0742) | Error 0.1556(0.1940) Steps 0(0.00) | Grad Norm 963.3933(1858.5245) | Total Time 0.00(0.00)\n",
      "Iter 5980 | Time 18.0717(18.3549) | Bit/dim 3.6416(3.6459) | Xent 0.5313(0.5580) | Loss 2619.5132(2762.1804) | Error 0.1789(0.1971) Steps 0(0.00) | Grad Norm 2100.0665(1952.1364) | Total Time 0.00(0.00)\n",
      "Iter 5990 | Time 18.6661(18.4624) | Bit/dim 3.6541(3.6494) | Xent 0.5074(0.5626) | Loss 2608.0015(2726.5268) | Error 0.1878(0.1989) Steps 0(0.00) | Grad Norm 2155.4055(1991.0812) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 93.2103, Epoch Time 1122.6930(1050.5394), Bit/dim 3.6558(best: 3.6491), Xent 0.6824, Loss 3.9969, Error 0.2317(best: 0.2361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6000 | Time 18.3155(18.4297) | Bit/dim 3.6642(3.6509) | Xent 0.5809(0.5640) | Loss 2722.0220(3042.1866) | Error 0.1978(0.1987) Steps 0(0.00) | Grad Norm 2304.7177(2043.8780) | Total Time 0.00(0.00)\n",
      "Iter 6010 | Time 19.5282(18.5186) | Bit/dim 3.6130(3.6468) | Xent 0.5117(0.5555) | Loss 2514.1697(2928.2099) | Error 0.1778(0.1958) Steps 0(0.00) | Grad Norm 1833.0655(1951.1804) | Total Time 0.00(0.00)\n",
      "Iter 6020 | Time 19.6083(18.6096) | Bit/dim 3.6586(3.6465) | Xent 0.4817(0.5511) | Loss 2628.3125(2844.5239) | Error 0.1689(0.1950) Steps 0(0.00) | Grad Norm 1481.9920(1913.7617) | Total Time 0.00(0.00)\n",
      "Iter 6030 | Time 21.1283(18.7990) | Bit/dim 3.6604(3.6459) | Xent 0.5754(0.5455) | Loss 2536.0789(2773.0022) | Error 0.1856(0.1926) Steps 0(0.00) | Grad Norm 1391.1369(1797.2983) | Total Time 0.00(0.00)\n",
      "Iter 6040 | Time 18.1853(18.7545) | Bit/dim 3.6651(3.6465) | Xent 0.5813(0.5524) | Loss 2645.3975(2734.1487) | Error 0.1978(0.1952) Steps 0(0.00) | Grad Norm 1808.6355(1747.3728) | Total Time 0.00(0.00)\n",
      "Iter 6050 | Time 19.1281(18.8101) | Bit/dim 3.6451(3.6477) | Xent 0.5145(0.5576) | Loss 2643.4028(2707.3131) | Error 0.2000(0.1970) Steps 0(0.00) | Grad Norm 2029.5562(1951.1368) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 94.9949, Epoch Time 1151.2562(1053.5609), Bit/dim 3.6608(best: 3.6491), Xent 0.7327, Loss 4.0271, Error 0.2471(best: 0.2317)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6060 | Time 18.8741(18.6726) | Bit/dim 3.6581(3.6482) | Xent 0.4654(0.5476) | Loss 2611.4136(2972.7140) | Error 0.1511(0.1926) Steps 0(0.00) | Grad Norm 1539.6176(1923.8342) | Total Time 0.00(0.00)\n",
      "Iter 6070 | Time 17.9820(18.7965) | Bit/dim 3.6299(3.6488) | Xent 0.4787(0.5420) | Loss 2512.8047(2872.2673) | Error 0.1622(0.1910) Steps 0(0.00) | Grad Norm 1605.0921(1903.2864) | Total Time 0.00(0.00)\n",
      "Iter 6080 | Time 17.7119(18.6967) | Bit/dim 3.6815(3.6491) | Xent 0.5530(0.5458) | Loss 2608.9155(2802.9207) | Error 0.1889(0.1923) Steps 0(0.00) | Grad Norm 1613.8478(1852.6210) | Total Time 0.00(0.00)\n",
      "Iter 6090 | Time 18.9356(18.6998) | Bit/dim 3.6563(3.6518) | Xent 0.5973(0.5514) | Loss 2671.0361(2752.8097) | Error 0.2011(0.1937) Steps 0(0.00) | Grad Norm 1198.6503(1805.9598) | Total Time 0.00(0.00)\n",
      "Iter 6100 | Time 18.8728(18.7575) | Bit/dim 3.6380(3.6495) | Xent 0.5878(0.5572) | Loss 2560.5623(2714.3281) | Error 0.2178(0.1965) Steps 0(0.00) | Grad Norm 2640.4986(1965.4298) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 93.1073, Epoch Time 1143.4980(1056.2590), Bit/dim 3.6587(best: 3.6491), Xent 0.6979, Loss 4.0076, Error 0.2403(best: 0.2317)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6110 | Time 19.1820(18.8844) | Bit/dim 3.6411(3.6471) | Xent 0.5331(0.5547) | Loss 2629.8291(3049.4109) | Error 0.2022(0.1962) Steps 0(0.00) | Grad Norm 2202.0236(1980.3429) | Total Time 0.00(0.00)\n",
      "Iter 6120 | Time 18.3551(18.9338) | Bit/dim 3.6618(3.6474) | Xent 0.6438(0.5551) | Loss 2602.1541(2936.1880) | Error 0.2189(0.1970) Steps 0(0.00) | Grad Norm 3698.8238(2081.5091) | Total Time 0.00(0.00)\n",
      "Iter 6130 | Time 18.4303(19.0103) | Bit/dim 3.6248(3.6458) | Xent 0.5792(0.5554) | Loss 2643.3147(2853.6317) | Error 0.2056(0.1967) Steps 0(0.00) | Grad Norm 2413.7209(2061.5430) | Total Time 0.00(0.00)\n",
      "Iter 6140 | Time 18.1164(18.9840) | Bit/dim 3.6501(3.6441) | Xent 0.5351(0.5518) | Loss 2570.4844(2792.5731) | Error 0.2000(0.1955) Steps 0(0.00) | Grad Norm 1648.6228(1943.1698) | Total Time 0.00(0.00)\n",
      "Iter 6150 | Time 18.2788(18.9855) | Bit/dim 3.6269(3.6423) | Xent 0.5397(0.5443) | Loss 2587.6091(2742.9538) | Error 0.1944(0.1932) Steps 0(0.00) | Grad Norm 1029.4940(1794.2803) | Total Time 0.00(0.00)\n",
      "Iter 6160 | Time 19.1983(19.1134) | Bit/dim 3.6091(3.6424) | Xent 0.5182(0.5391) | Loss 2633.4683(2712.4373) | Error 0.1756(0.1911) Steps 0(0.00) | Grad Norm 2113.3740(1772.2510) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 95.4952, Epoch Time 1164.4832(1059.5057), Bit/dim 3.6461(best: 3.6491), Xent 0.6794, Loss 3.9858, Error 0.2352(best: 0.2317)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6170 | Time 19.2592(19.0668) | Bit/dim 3.6521(3.6419) | Xent 0.5682(0.5426) | Loss 2450.7161(2994.5119) | Error 0.2033(0.1933) Steps 0(0.00) | Grad Norm 2641.5585(1906.4082) | Total Time 0.00(0.00)\n",
      "Iter 6180 | Time 19.3064(18.9783) | Bit/dim 3.6175(3.6427) | Xent 0.4710(0.5410) | Loss 2569.1338(2902.6422) | Error 0.1744(0.1935) Steps 0(0.00) | Grad Norm 1980.9661(2003.0719) | Total Time 0.00(0.00)\n",
      "Iter 6190 | Time 19.8316(18.9154) | Bit/dim 3.6274(3.6433) | Xent 0.5460(0.5369) | Loss 2472.4998(2812.1411) | Error 0.1844(0.1919) Steps 0(0.00) | Grad Norm 1473.8230(1917.9414) | Total Time 0.00(0.00)\n",
      "Iter 6200 | Time 18.5282(18.9749) | Bit/dim 3.6639(3.6454) | Xent 0.5206(0.5310) | Loss 2668.9458(2758.6038) | Error 0.1822(0.1885) Steps 0(0.00) | Grad Norm 1525.2339(1811.2289) | Total Time 0.00(0.00)\n",
      "Iter 6210 | Time 19.7361(19.0943) | Bit/dim 3.6355(3.6427) | Xent 0.5420(0.5376) | Loss 2685.5862(2724.8512) | Error 0.1933(0.1908) Steps 0(0.00) | Grad Norm 1904.9928(1874.8256) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 94.9924, Epoch Time 1154.2640(1062.3485), Bit/dim 3.6518(best: 3.6461), Xent 0.7180, Loss 4.0108, Error 0.2435(best: 0.2317)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6220 | Time 18.4844(18.9313) | Bit/dim 3.6802(3.6462) | Xent 0.5429(0.5481) | Loss 2640.9678(3054.2800) | Error 0.1889(0.1946) Steps 0(0.00) | Grad Norm 1830.2277(2057.0052) | Total Time 0.00(0.00)\n",
      "Iter 6230 | Time 18.9793(18.9028) | Bit/dim 3.6708(3.6459) | Xent 0.5122(0.5403) | Loss 2615.5486(2937.8228) | Error 0.1844(0.1916) Steps 0(0.00) | Grad Norm 1679.6691(1967.1790) | Total Time 0.00(0.00)\n",
      "Iter 6240 | Time 18.4811(19.0313) | Bit/dim 3.6662(3.6458) | Xent 0.5885(0.5370) | Loss 2549.2705(2851.9276) | Error 0.2067(0.1909) Steps 0(0.00) | Grad Norm 2231.5577(1947.1242) | Total Time 0.00(0.00)\n",
      "Iter 6250 | Time 18.8834(18.9619) | Bit/dim 3.6418(3.6465) | Xent 0.5135(0.5390) | Loss 2581.3018(2787.1417) | Error 0.1867(0.1912) Steps 0(0.00) | Grad Norm 2184.7555(1821.2950) | Total Time 0.00(0.00)\n",
      "Iter 6260 | Time 18.5659(18.9416) | Bit/dim 3.6437(3.6445) | Xent 0.4864(0.5316) | Loss 2538.9980(2741.8993) | Error 0.1722(0.1882) Steps 0(0.00) | Grad Norm 1572.5215(1834.7177) | Total Time 0.00(0.00)\n",
      "Iter 6270 | Time 23.0132(19.1103) | Bit/dim 3.6562(3.6434) | Xent 0.5807(0.5369) | Loss 2549.9890(2709.5717) | Error 0.2100(0.1908) Steps 0(0.00) | Grad Norm 2610.5745(1897.7718) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 95.3609, Epoch Time 1159.2593(1065.2558), Bit/dim 3.6462(best: 3.6461), Xent 0.6889, Loss 3.9907, Error 0.2374(best: 0.2317)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6280 | Time 19.8098(19.0268) | Bit/dim 3.6391(3.6424) | Xent 0.4963(0.5293) | Loss 2650.9939(2976.8079) | Error 0.1789(0.1883) Steps 0(0.00) | Grad Norm 1808.8614(1905.8802) | Total Time 0.00(0.00)\n",
      "Iter 6290 | Time 16.8134(18.9503) | Bit/dim 3.6553(3.6437) | Xent 0.5333(0.5394) | Loss 2602.8779(2888.8622) | Error 0.1867(0.1915) Steps 0(0.00) | Grad Norm 1771.0067(2020.8113) | Total Time 0.00(0.00)\n",
      "Iter 6300 | Time 17.6205(18.9137) | Bit/dim 3.6621(3.6433) | Xent 0.5176(0.5353) | Loss 2657.4988(2817.4551) | Error 0.1811(0.1913) Steps 0(0.00) | Grad Norm 1591.3174(1960.3683) | Total Time 0.00(0.00)\n",
      "Iter 6310 | Time 19.2741(18.8689) | Bit/dim 3.6209(3.6436) | Xent 0.5004(0.5345) | Loss 2627.3281(2757.5995) | Error 0.1867(0.1916) Steps 0(0.00) | Grad Norm 1036.9823(1863.4532) | Total Time 0.00(0.00)\n",
      "Iter 6320 | Time 18.4508(19.0893) | Bit/dim 3.6124(3.6412) | Xent 0.5975(0.5393) | Loss 2592.4973(2723.8704) | Error 0.2156(0.1927) Steps 0(0.00) | Grad Norm 2193.2594(1911.7100) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 96.0703, Epoch Time 1154.8154(1067.9426), Bit/dim 3.6442(best: 3.6461), Xent 0.6836, Loss 3.9860, Error 0.2342(best: 0.2317)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6330 | Time 18.5731(19.0118) | Bit/dim 3.6698(3.6416) | Xent 0.5032(0.5347) | Loss 2628.4368(3051.5213) | Error 0.1822(0.1918) Steps 0(0.00) | Grad Norm 1479.6095(1869.7259) | Total Time 0.00(0.00)\n",
      "Iter 6340 | Time 21.0985(19.1096) | Bit/dim 3.6326(3.6417) | Xent 0.5148(0.5299) | Loss 2588.0916(2934.4235) | Error 0.1822(0.1898) Steps 0(0.00) | Grad Norm 1833.3828(1874.2464) | Total Time 0.00(0.00)\n",
      "Iter 6350 | Time 17.0506(18.9693) | Bit/dim 3.6757(3.6414) | Xent 0.4943(0.5335) | Loss 2544.8984(2843.9136) | Error 0.1856(0.1900) Steps 0(0.00) | Grad Norm 1231.3195(1967.2207) | Total Time 0.00(0.00)\n",
      "Iter 6360 | Time 19.8555(19.0011) | Bit/dim 3.7074(3.6414) | Xent 0.5939(0.5347) | Loss 2663.8008(2782.3571) | Error 0.2200(0.1902) Steps 0(0.00) | Grad Norm 2523.2026(2012.5118) | Total Time 0.00(0.00)\n",
      "Iter 6370 | Time 17.7629(19.1986) | Bit/dim 3.5786(3.6405) | Xent 0.5568(0.5409) | Loss 2582.7380(2748.0085) | Error 0.2111(0.1922) Steps 0(0.00) | Grad Norm 2789.5703(1949.5595) | Total Time 0.00(0.00)\n",
      "Iter 6380 | Time 18.4129(19.1972) | Bit/dim 3.6233(3.6409) | Xent 0.5309(0.5402) | Loss 2505.6951(2716.9450) | Error 0.2011(0.1926) Steps 0(0.00) | Grad Norm 2189.3920(1910.5990) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 95.8680, Epoch Time 1167.8369(1070.9394), Bit/dim 3.6374(best: 3.6442), Xent 0.6753, Loss 3.9750, Error 0.2311(best: 0.2317)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6390 | Time 18.7475(19.0718) | Bit/dim 3.6345(3.6413) | Xent 0.4908(0.5316) | Loss 2661.9207(2992.5876) | Error 0.1767(0.1888) Steps 0(0.00) | Grad Norm 2714.6132(1953.1840) | Total Time 0.00(0.00)\n",
      "Iter 6400 | Time 18.5877(18.9561) | Bit/dim 3.6182(3.6413) | Xent 0.5309(0.5377) | Loss 2484.3669(2886.4433) | Error 0.1900(0.1916) Steps 0(0.00) | Grad Norm 1265.8079(1975.6178) | Total Time 0.00(0.00)\n",
      "Iter 6410 | Time 17.7115(18.8761) | Bit/dim 3.6536(3.6434) | Xent 0.5388(0.5421) | Loss 2545.3032(2809.3006) | Error 0.1989(0.1924) Steps 0(0.00) | Grad Norm 1103.9089(1923.8957) | Total Time 0.00(0.00)\n",
      "Iter 6420 | Time 19.9656(18.7338) | Bit/dim 3.6273(3.6418) | Xent 0.5559(0.5358) | Loss 2623.7825(2747.9464) | Error 0.1922(0.1898) Steps 0(0.00) | Grad Norm 1007.4654(1787.5434) | Total Time 0.00(0.00)\n",
      "Iter 6430 | Time 19.1578(18.9584) | Bit/dim 3.6347(3.6395) | Xent 0.5205(0.5327) | Loss 2560.8457(2707.3413) | Error 0.1822(0.1885) Steps 0(0.00) | Grad Norm 1539.6763(1787.3484) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 95.9549, Epoch Time 1146.4930(1073.2060), Bit/dim 3.6384(best: 3.6374), Xent 0.6489, Loss 3.9629, Error 0.2234(best: 0.2311)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6440 | Time 17.5835(18.9149) | Bit/dim 3.6485(3.6393) | Xent 0.5493(0.5397) | Loss 2505.5613(3045.1846) | Error 0.2022(0.1920) Steps 0(0.00) | Grad Norm 2167.3174(1865.4111) | Total Time 0.00(0.00)\n",
      "Iter 6450 | Time 18.8407(18.8532) | Bit/dim 3.6257(3.6387) | Xent 0.5036(0.5270) | Loss 2597.5352(2918.2475) | Error 0.1922(0.1874) Steps 0(0.00) | Grad Norm 931.8265(1742.2655) | Total Time 0.00(0.00)\n",
      "Iter 6460 | Time 18.4257(18.8967) | Bit/dim 3.6129(3.6373) | Xent 0.4426(0.5141) | Loss 2568.0315(2836.0731) | Error 0.1667(0.1827) Steps 0(0.00) | Grad Norm 1868.2584(1704.2791) | Total Time 0.00(0.00)\n",
      "Iter 6470 | Time 19.4026(18.9573) | Bit/dim 3.6251(3.6351) | Xent 0.5205(0.5132) | Loss 2562.7544(2769.2373) | Error 0.1867(0.1827) Steps 0(0.00) | Grad Norm 2606.7113(1671.4699) | Total Time 0.00(0.00)\n",
      "Iter 6480 | Time 18.9321(19.0564) | Bit/dim 3.6173(3.6357) | Xent 0.5423(0.5165) | Loss 2551.7371(2721.7165) | Error 0.2011(0.1840) Steps 0(0.00) | Grad Norm 1981.2602(1812.3361) | Total Time 0.00(0.00)\n",
      "Iter 6490 | Time 18.3073(18.9553) | Bit/dim 3.6660(3.6372) | Xent 0.5282(0.5239) | Loss 2539.3396(2691.6351) | Error 0.1756(0.1871) Steps 0(0.00) | Grad Norm 1983.0307(1912.8449) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 97.4224, Epoch Time 1156.5817(1075.7073), Bit/dim 3.6343(best: 3.6374), Xent 0.6726, Loss 3.9706, Error 0.2313(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6500 | Time 19.7732(18.9033) | Bit/dim 3.6448(3.6356) | Xent 0.4498(0.5128) | Loss 2594.9355(2967.9744) | Error 0.1567(0.1827) Steps 0(0.00) | Grad Norm 1550.6128(1837.1050) | Total Time 0.00(0.00)\n",
      "Iter 6510 | Time 20.0255(19.0714) | Bit/dim 3.6460(3.6379) | Xent 0.4809(0.5081) | Loss 2600.5408(2872.2755) | Error 0.1633(0.1813) Steps 0(0.00) | Grad Norm 2685.5038(1897.7388) | Total Time 0.00(0.00)\n",
      "Iter 6520 | Time 18.7911(19.0029) | Bit/dim 3.6608(3.6399) | Xent 0.4718(0.5072) | Loss 2587.7476(2803.5871) | Error 0.1789(0.1809) Steps 0(0.00) | Grad Norm 2532.1071(1887.2734) | Total Time 0.00(0.00)\n",
      "Iter 6530 | Time 17.6027(18.8634) | Bit/dim 3.5929(3.6379) | Xent 0.5967(0.5139) | Loss 2560.5852(2750.6155) | Error 0.2100(0.1831) Steps 0(0.00) | Grad Norm 2196.6456(1876.3176) | Total Time 0.00(0.00)\n",
      "Iter 6540 | Time 19.2957(18.9195) | Bit/dim 3.6263(3.6382) | Xent 0.5359(0.5132) | Loss 2694.4436(2714.2829) | Error 0.1989(0.1832) Steps 0(0.00) | Grad Norm 1309.9309(1870.7478) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 94.4278, Epoch Time 1150.7334(1077.9581), Bit/dim 3.6445(best: 3.6343), Xent 0.6770, Loss 3.9830, Error 0.2289(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6550 | Time 19.1042(18.8291) | Bit/dim 3.6272(3.6404) | Xent 0.5550(0.5155) | Loss 2574.9526(3031.6769) | Error 0.1889(0.1833) Steps 0(0.00) | Grad Norm 1971.7554(1886.6416) | Total Time 0.00(0.00)\n",
      "Iter 6560 | Time 19.5849(18.8621) | Bit/dim 3.6881(3.6404) | Xent 0.5139(0.5136) | Loss 2673.9644(2915.9252) | Error 0.1744(0.1825) Steps 0(0.00) | Grad Norm 1572.6728(1975.1258) | Total Time 0.00(0.00)\n",
      "Iter 6570 | Time 16.9551(18.8173) | Bit/dim 3.6645(3.6406) | Xent 0.4732(0.5144) | Loss 2521.5286(2826.4172) | Error 0.1689(0.1831) Steps 0(0.00) | Grad Norm 2507.7028(2062.5393) | Total Time 0.00(0.00)\n",
      "Iter 6580 | Time 18.4053(19.0274) | Bit/dim 3.6501(3.6394) | Xent 0.5228(0.5161) | Loss 2664.9731(2773.2190) | Error 0.1844(0.1824) Steps 0(0.00) | Grad Norm 1522.4317(2000.3121) | Total Time 0.00(0.00)\n",
      "Iter 6590 | Time 20.4549(19.1035) | Bit/dim 3.6307(3.6387) | Xent 0.4752(0.5142) | Loss 2650.8259(2734.4000) | Error 0.1711(0.1826) Steps 0(0.00) | Grad Norm 1592.9639(1964.4956) | Total Time 0.00(0.00)\n",
      "Iter 6600 | Time 19.6905(19.0877) | Bit/dim 3.6500(3.6385) | Xent 0.4851(0.5103) | Loss 2584.2915(2699.1098) | Error 0.1711(0.1814) Steps 0(0.00) | Grad Norm 1272.0248(1871.1401) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 94.8581, Epoch Time 1162.2956(1080.4882), Bit/dim 3.6437(best: 3.6343), Xent 0.6561, Loss 3.9717, Error 0.2238(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6610 | Time 18.3577(19.0527) | Bit/dim 3.6454(3.6352) | Xent 0.4727(0.5017) | Loss 2585.2761(2971.6040) | Error 0.1600(0.1780) Steps 0(0.00) | Grad Norm 1861.4372(1816.2215) | Total Time 0.00(0.00)\n",
      "Iter 6620 | Time 17.2957(18.8193) | Bit/dim 3.6823(3.6350) | Xent 0.4523(0.4945) | Loss 2596.7366(2865.3453) | Error 0.1589(0.1754) Steps 0(0.00) | Grad Norm 1461.8296(1741.8800) | Total Time 0.00(0.00)\n",
      "Iter 6630 | Time 20.0452(18.8794) | Bit/dim 3.6163(3.6380) | Xent 0.5474(0.5056) | Loss 2656.0024(2807.7958) | Error 0.1967(0.1794) Steps 0(0.00) | Grad Norm 2153.4588(1835.8838) | Total Time 0.00(0.00)\n",
      "Iter 6640 | Time 19.2160(18.9224) | Bit/dim 3.6409(3.6399) | Xent 0.6068(0.5213) | Loss 2634.5466(2765.9817) | Error 0.2100(0.1846) Steps 0(0.00) | Grad Norm 1903.9858(1999.6976) | Total Time 0.00(0.00)\n",
      "Iter 6650 | Time 19.3948(18.9891) | Bit/dim 3.6546(3.6408) | Xent 0.5818(0.5282) | Loss 2559.9722(2725.0968) | Error 0.1978(0.1868) Steps 0(0.00) | Grad Norm 2970.9547(2074.5555) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 95.7606, Epoch Time 1150.9582(1082.6023), Bit/dim 3.6429(best: 3.6343), Xent 0.6665, Loss 3.9761, Error 0.2292(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6660 | Time 20.6049(18.9133) | Bit/dim 3.6267(3.6392) | Xent 0.4659(0.5227) | Loss 2663.1741(3043.2262) | Error 0.1611(0.1845) Steps 0(0.00) | Grad Norm 2059.3591(1992.0052) | Total Time 0.00(0.00)\n",
      "Iter 6670 | Time 18.9488(19.0677) | Bit/dim 3.6601(3.6424) | Xent 0.4498(0.5140) | Loss 2589.0598(2926.7151) | Error 0.1589(0.1816) Steps 0(0.00) | Grad Norm 1277.3160(1935.0432) | Total Time 0.00(0.00)\n",
      "Iter 6680 | Time 18.4906(19.0837) | Bit/dim 3.6371(3.6414) | Xent 0.4976(0.5120) | Loss 2591.0457(2841.8339) | Error 0.1778(0.1809) Steps 0(0.00) | Grad Norm 1336.2435(1968.4058) | Total Time 0.00(0.00)\n",
      "Iter 6690 | Time 18.8822(18.9977) | Bit/dim 3.6171(3.6377) | Xent 0.4782(0.5102) | Loss 2565.8142(2775.4255) | Error 0.1722(0.1810) Steps 0(0.00) | Grad Norm 988.1464(1911.4316) | Total Time 0.00(0.00)\n",
      "Iter 6700 | Time 19.7182(18.9020) | Bit/dim 3.6735(3.6388) | Xent 0.5123(0.5078) | Loss 2652.8149(2723.3708) | Error 0.1867(0.1802) Steps 0(0.00) | Grad Norm 1223.0901(1838.5938) | Total Time 0.00(0.00)\n",
      "Iter 6710 | Time 18.9279(18.9859) | Bit/dim 3.6392(3.6364) | Xent 0.4846(0.5037) | Loss 2533.5686(2687.5700) | Error 0.1667(0.1792) Steps 0(0.00) | Grad Norm 2529.3523(1844.2696) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 97.6333, Epoch Time 1162.0557(1084.9859), Bit/dim 3.6369(best: 3.6343), Xent 0.6772, Loss 3.9755, Error 0.2280(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6720 | Time 19.3609(19.1309) | Bit/dim 3.6606(3.6356) | Xent 0.5279(0.5001) | Loss 2579.1409(2985.4610) | Error 0.1933(0.1775) Steps 0(0.00) | Grad Norm 1873.8389(1822.1861) | Total Time 0.00(0.00)\n",
      "Iter 6730 | Time 20.0306(19.2160) | Bit/dim 3.6067(3.6344) | Xent 0.4961(0.4948) | Loss 2638.4197(2891.0441) | Error 0.1778(0.1756) Steps 0(0.00) | Grad Norm 1327.5043(1745.3635) | Total Time 0.00(0.00)\n",
      "Iter 6740 | Time 20.0928(19.1807) | Bit/dim 3.6011(3.6319) | Xent 0.5202(0.4956) | Loss 2597.9846(2806.5466) | Error 0.1833(0.1758) Steps 0(0.00) | Grad Norm 1560.8523(1768.2608) | Total Time 0.00(0.00)\n",
      "Iter 6750 | Time 18.1238(19.0849) | Bit/dim 3.6214(3.6318) | Xent 0.4612(0.4937) | Loss 2536.9812(2748.6312) | Error 0.1544(0.1753) Steps 0(0.00) | Grad Norm 1509.2294(1781.1521) | Total Time 0.00(0.00)\n",
      "Iter 6760 | Time 19.3893(19.3462) | Bit/dim 3.6182(3.6318) | Xent 0.5472(0.4962) | Loss 2644.8772(2711.0132) | Error 0.1911(0.1751) Steps 0(0.00) | Grad Norm 2908.4663(1822.5696) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 95.0532, Epoch Time 1173.6325(1087.6453), Bit/dim 3.6364(best: 3.6343), Xent 0.6720, Loss 3.9724, Error 0.2322(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6770 | Time 19.9654(19.1789) | Bit/dim 3.6102(3.6326) | Xent 0.4972(0.4951) | Loss 2683.0769(3032.9020) | Error 0.1844(0.1742) Steps 0(0.00) | Grad Norm 1108.1917(1788.6034) | Total Time 0.00(0.00)\n",
      "Iter 6780 | Time 17.8748(19.1875) | Bit/dim 3.6140(3.6286) | Xent 0.5221(0.4904) | Loss 2557.3940(2911.4562) | Error 0.1867(0.1731) Steps 0(0.00) | Grad Norm 2330.1915(1800.3222) | Total Time 0.00(0.00)\n",
      "Iter 6790 | Time 17.5066(18.9563) | Bit/dim 3.6107(3.6296) | Xent 0.4315(0.4870) | Loss 2556.6067(2826.5563) | Error 0.1567(0.1727) Steps 0(0.00) | Grad Norm 1035.7412(1726.6628) | Total Time 0.00(0.00)\n",
      "Iter 6800 | Time 17.6599(18.9342) | Bit/dim 3.6284(3.6325) | Xent 0.4644(0.4832) | Loss 2592.1294(2768.3028) | Error 0.1689(0.1718) Steps 0(0.00) | Grad Norm 1377.5428(1691.9204) | Total Time 0.00(0.00)\n",
      "Iter 6810 | Time 18.3120(19.0580) | Bit/dim 3.6590(3.6342) | Xent 0.5072(0.5107) | Loss 2671.3491(2733.0053) | Error 0.1789(0.1805) Steps 0(0.00) | Grad Norm 2127.9560(1999.7233) | Total Time 0.00(0.00)\n",
      "Iter 6820 | Time 19.7073(18.9371) | Bit/dim 3.6223(3.6352) | Xent 0.5069(0.5173) | Loss 2692.0530(2688.0427) | Error 0.1844(0.1840) Steps 0(0.00) | Grad Norm 2457.9904(1994.2637) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 96.2184, Epoch Time 1153.9572(1089.6347), Bit/dim 3.6410(best: 3.6343), Xent 0.6814, Loss 3.9817, Error 0.2342(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6830 | Time 18.5063(19.0071) | Bit/dim 3.6180(3.6364) | Xent 0.4536(0.5106) | Loss 2647.5024(2965.8348) | Error 0.1556(0.1808) Steps 0(0.00) | Grad Norm 943.4909(1905.2509) | Total Time 0.00(0.00)\n",
      "Iter 6840 | Time 19.0783(19.0606) | Bit/dim 3.6276(3.6338) | Xent 0.4448(0.4991) | Loss 2571.6343(2870.6107) | Error 0.1578(0.1764) Steps 0(0.00) | Grad Norm 1204.6087(1832.6649) | Total Time 0.00(0.00)\n",
      "Iter 6850 | Time 20.1980(19.0479) | Bit/dim 3.6307(3.6338) | Xent 0.5293(0.4964) | Loss 2679.4512(2793.6006) | Error 0.1856(0.1756) Steps 0(0.00) | Grad Norm 2015.5338(1783.6694) | Total Time 0.00(0.00)\n",
      "Iter 6860 | Time 19.2013(19.0707) | Bit/dim 3.6097(3.6329) | Xent 0.4791(0.4929) | Loss 2533.5564(2745.7804) | Error 0.1756(0.1742) Steps 0(0.00) | Grad Norm 1741.3698(1793.8529) | Total Time 0.00(0.00)\n",
      "Iter 6870 | Time 18.6387(19.1038) | Bit/dim 3.6389(3.6314) | Xent 0.4817(0.4930) | Loss 2673.8987(2704.9223) | Error 0.1756(0.1755) Steps 0(0.00) | Grad Norm 2432.2204(1844.1393) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 95.3394, Epoch Time 1161.3585(1091.7864), Bit/dim 3.6359(best: 3.6343), Xent 0.6784, Loss 3.9751, Error 0.2292(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6880 | Time 18.9850(18.9867) | Bit/dim 3.6183(3.6337) | Xent 0.5266(0.5004) | Loss 2550.7341(3016.5294) | Error 0.1756(0.1774) Steps 0(0.00) | Grad Norm 2482.1406(1854.0126) | Total Time 0.00(0.00)\n",
      "Iter 6890 | Time 18.3467(18.9754) | Bit/dim 3.6439(3.6343) | Xent 0.4436(0.4938) | Loss 2615.6968(2902.2453) | Error 0.1600(0.1743) Steps 0(0.00) | Grad Norm 2108.0400(1909.1419) | Total Time 0.00(0.00)\n",
      "Iter 6900 | Time 19.6255(18.9739) | Bit/dim 3.6320(3.6328) | Xent 0.4546(0.4932) | Loss 2616.5076(2820.9430) | Error 0.1600(0.1749) Steps 0(0.00) | Grad Norm 1282.6514(1991.3370) | Total Time 0.00(0.00)\n",
      "Iter 6910 | Time 18.2298(18.8784) | Bit/dim 3.6309(3.6334) | Xent 0.4251(0.4880) | Loss 2503.0808(2762.3722) | Error 0.1556(0.1733) Steps 0(0.00) | Grad Norm 1196.3013(1888.9474) | Total Time 0.00(0.00)\n",
      "Iter 6920 | Time 19.6174(18.8887) | Bit/dim 3.6328(3.6325) | Xent 0.5004(0.4867) | Loss 2657.3523(2713.6967) | Error 0.1711(0.1730) Steps 0(0.00) | Grad Norm 2013.4569(1773.7388) | Total Time 0.00(0.00)\n",
      "Iter 6930 | Time 20.1731(19.0090) | Bit/dim 3.6375(3.6312) | Xent 0.5489(0.4944) | Loss 2620.3694(2688.8405) | Error 0.2022(0.1771) Steps 0(0.00) | Grad Norm 2358.3848(1860.0989) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 94.9430, Epoch Time 1155.2709(1093.6909), Bit/dim 3.6398(best: 3.6343), Xent 0.7334, Loss 4.0065, Error 0.2433(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6940 | Time 20.7323(18.9806) | Bit/dim 3.6401(3.6316) | Xent 0.4929(0.5016) | Loss 2683.5452(2987.0867) | Error 0.1822(0.1792) Steps 0(0.00) | Grad Norm 3810.1033(1983.5078) | Total Time 0.00(0.00)\n",
      "Iter 6950 | Time 19.6394(19.0337) | Bit/dim 3.6782(3.6356) | Xent 0.5905(0.5041) | Loss 2706.7170(2882.4709) | Error 0.2122(0.1801) Steps 0(0.00) | Grad Norm 1810.2778(1953.8716) | Total Time 0.00(0.00)\n",
      "Iter 6960 | Time 19.0994(18.9699) | Bit/dim 3.6200(3.6355) | Xent 0.4923(0.5003) | Loss 2639.9060(2811.9069) | Error 0.1778(0.1796) Steps 0(0.00) | Grad Norm 2094.5546(1956.8571) | Total Time 0.00(0.00)\n",
      "Iter 6970 | Time 20.3391(19.2149) | Bit/dim 3.6410(3.6334) | Xent 0.5207(0.5019) | Loss 2701.4087(2756.8717) | Error 0.1933(0.1799) Steps 0(0.00) | Grad Norm 1541.3720(1889.8816) | Total Time 0.00(0.00)\n",
      "Iter 6980 | Time 18.5096(19.2309) | Bit/dim 3.6253(3.6332) | Xent 0.4561(0.5012) | Loss 2436.6926(2712.4988) | Error 0.1756(0.1803) Steps 0(0.00) | Grad Norm 1183.5127(1843.5658) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 94.1302, Epoch Time 1163.4458(1095.7836), Bit/dim 3.6374(best: 3.6343), Xent 0.6718, Loss 3.9733, Error 0.2278(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6990 | Time 20.4858(19.0817) | Bit/dim 3.6193(3.6272) | Xent 0.4650(0.4970) | Loss 2596.8870(3026.2284) | Error 0.1678(0.1779) Steps 0(0.00) | Grad Norm 2198.2276(1831.5572) | Total Time 0.00(0.00)\n",
      "Iter 7000 | Time 18.9789(19.2588) | Bit/dim 3.6281(3.6271) | Xent 0.4646(0.4878) | Loss 2481.7485(2914.1410) | Error 0.1600(0.1730) Steps 0(0.00) | Grad Norm 2407.0531(1812.3371) | Total Time 0.00(0.00)\n",
      "Iter 7010 | Time 19.4960(19.1596) | Bit/dim 3.6429(3.6301) | Xent 0.4614(0.4854) | Loss 2636.7610(2831.0808) | Error 0.1667(0.1718) Steps 0(0.00) | Grad Norm 1351.7057(1816.9539) | Total Time 0.00(0.00)\n",
      "Iter 7020 | Time 17.8278(19.0892) | Bit/dim 3.6345(3.6296) | Xent 0.4613(0.4795) | Loss 2648.3394(2760.0613) | Error 0.1611(0.1696) Steps 0(0.00) | Grad Norm 1936.1334(1782.6515) | Total Time 0.00(0.00)\n",
      "Iter 7030 | Time 20.4786(19.1039) | Bit/dim 3.5908(3.6278) | Xent 0.4998(0.4794) | Loss 2657.8027(2711.2552) | Error 0.1644(0.1698) Steps 0(0.00) | Grad Norm 1358.3694(1744.3175) | Total Time 0.00(0.00)\n",
      "Iter 7040 | Time 22.4433(19.2684) | Bit/dim 3.6354(3.6274) | Xent 0.4744(0.4756) | Loss 2663.8511(2676.8054) | Error 0.1811(0.1697) Steps 0(0.00) | Grad Norm 1346.6798(1655.1700) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 96.1967, Epoch Time 1172.7114(1098.0914), Bit/dim 3.6290(best: 3.6343), Xent 0.6608, Loss 3.9594, Error 0.2228(best: 0.2234)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7050 | Time 20.3490(19.2386) | Bit/dim 3.5927(3.6272) | Xent 0.4049(0.4710) | Loss 2538.8723(2964.1863) | Error 0.1411(0.1668) Steps 0(0.00) | Grad Norm 1493.3812(1657.4005) | Total Time 0.00(0.00)\n",
      "Iter 7060 | Time 19.0246(19.3498) | Bit/dim 3.6315(3.6294) | Xent 0.4980(0.4707) | Loss 2585.3650(2869.8449) | Error 0.1844(0.1679) Steps 0(0.00) | Grad Norm 2011.5378(1744.9480) | Total Time 0.00(0.00)\n",
      "Iter 7070 | Time 19.3994(19.0886) | Bit/dim 3.6443(3.6303) | Xent 0.5317(0.4792) | Loss 2683.9517(2797.5161) | Error 0.1800(0.1704) Steps 0(0.00) | Grad Norm 2628.9084(1892.1560) | Total Time 0.00(0.00)\n",
      "Iter 7080 | Time 20.0719(19.1822) | Bit/dim 3.6882(3.6314) | Xent 0.5413(0.4867) | Loss 2678.5955(2744.1961) | Error 0.1922(0.1722) Steps 0(0.00) | Grad Norm 1572.1483(1821.6509) | Total Time 0.00(0.00)\n",
      "Iter 7090 | Time 20.4855(19.3696) | Bit/dim 3.5920(3.6284) | Xent 0.5017(0.4897) | Loss 2636.3611(2710.9274) | Error 0.1744(0.1728) Steps 0(0.00) | Grad Norm 2286.9982(1817.1550) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 95.9477, Epoch Time 1172.1992(1100.3146), Bit/dim 3.6318(best: 3.6290), Xent 0.6616, Loss 3.9626, Error 0.2271(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7100 | Time 21.9268(19.4653) | Bit/dim 3.6515(3.6295) | Xent 0.4589(0.4819) | Loss 2558.6768(3053.0923) | Error 0.1511(0.1693) Steps 0(0.00) | Grad Norm 1619.6322(1791.0175) | Total Time 0.00(0.00)\n",
      "Iter 7110 | Time 18.2465(19.4081) | Bit/dim 3.6511(3.6277) | Xent 0.4403(0.4768) | Loss 2564.0012(2928.3008) | Error 0.1544(0.1687) Steps 0(0.00) | Grad Norm 1126.0127(1759.7454) | Total Time 0.00(0.00)\n",
      "Iter 7120 | Time 19.3268(19.3380) | Bit/dim 3.6334(3.6271) | Xent 0.4808(0.4729) | Loss 2647.2878(2834.3167) | Error 0.1711(0.1681) Steps 0(0.00) | Grad Norm 1679.3392(1705.9898) | Total Time 0.00(0.00)\n",
      "Iter 7130 | Time 19.0551(19.3171) | Bit/dim 3.6666(3.6267) | Xent 0.4975(0.4733) | Loss 2563.4329(2769.5968) | Error 0.1822(0.1679) Steps 0(0.00) | Grad Norm 2022.7538(1796.1893) | Total Time 0.00(0.00)\n",
      "Iter 7140 | Time 19.7499(19.3614) | Bit/dim 3.6116(3.6301) | Xent 0.5404(0.4804) | Loss 2701.8506(2732.8216) | Error 0.1900(0.1693) Steps 0(0.00) | Grad Norm 2026.9225(1910.4099) | Total Time 0.00(0.00)\n",
      "Iter 7150 | Time 18.8332(19.3964) | Bit/dim 3.6251(3.6293) | Xent 0.4672(0.4812) | Loss 2678.7375(2698.0660) | Error 0.1522(0.1699) Steps 0(0.00) | Grad Norm 1500.2797(1891.9949) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 95.6265, Epoch Time 1183.2603(1102.8030), Bit/dim 3.6349(best: 3.6290), Xent 0.6583, Loss 3.9641, Error 0.2223(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7160 | Time 20.5281(19.3306) | Bit/dim 3.6380(3.6297) | Xent 0.4394(0.4697) | Loss 2710.1282(2983.8691) | Error 0.1522(0.1653) Steps 0(0.00) | Grad Norm 1629.6714(1779.4969) | Total Time 0.00(0.00)\n",
      "Iter 7170 | Time 18.5364(19.3006) | Bit/dim 3.6516(3.6283) | Xent 0.4838(0.4696) | Loss 2582.7749(2881.7762) | Error 0.1567(0.1653) Steps 0(0.00) | Grad Norm 2471.5078(1838.7725) | Total Time 0.00(0.00)\n",
      "Iter 7180 | Time 18.0951(19.3414) | Bit/dim 3.6245(3.6281) | Xent 0.4780(0.4666) | Loss 2624.0066(2807.9097) | Error 0.1711(0.1650) Steps 0(0.00) | Grad Norm 2100.5868(1843.2668) | Total Time 0.00(0.00)\n",
      "Iter 7190 | Time 19.6146(19.3636) | Bit/dim 3.6431(3.6265) | Xent 0.4696(0.4638) | Loss 2512.0354(2747.2288) | Error 0.1656(0.1646) Steps 0(0.00) | Grad Norm 1595.5969(1745.6772) | Total Time 0.00(0.00)\n",
      "Iter 7200 | Time 19.5870(19.3524) | Bit/dim 3.6372(3.6225) | Xent 0.4837(0.4653) | Loss 2653.0227(2708.8400) | Error 0.1800(0.1644) Steps 0(0.00) | Grad Norm 1767.9610(1782.0466) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 94.8675, Epoch Time 1174.9960(1104.9688), Bit/dim 3.6340(best: 3.6290), Xent 0.6819, Loss 3.9750, Error 0.2291(best: 0.2223)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7210 | Time 20.6818(19.2939) | Bit/dim 3.6362(3.6249) | Xent 0.4274(0.4658) | Loss 2591.8513(3003.0722) | Error 0.1222(0.1637) Steps 0(0.00) | Grad Norm 1511.4144(1747.3108) | Total Time 0.00(0.00)\n",
      "Iter 7220 | Time 19.6103(19.3386) | Bit/dim 3.6142(3.6239) | Xent 0.5154(0.4592) | Loss 2635.5979(2894.4921) | Error 0.1878(0.1619) Steps 0(0.00) | Grad Norm 2567.0216(1681.7112) | Total Time 0.00(0.00)\n",
      "Iter 7230 | Time 18.9354(19.3253) | Bit/dim 3.6449(3.6255) | Xent 0.5076(0.4598) | Loss 2526.0134(2810.7841) | Error 0.1711(0.1621) Steps 0(0.00) | Grad Norm 3047.1562(1813.7488) | Total Time 0.00(0.00)\n",
      "Iter 7240 | Time 18.9811(19.3580) | Bit/dim 3.5905(3.6265) | Xent 0.4758(0.4704) | Loss 2548.7061(2746.9128) | Error 0.1689(0.1663) Steps 0(0.00) | Grad Norm 1868.4089(1872.3441) | Total Time 0.00(0.00)\n",
      "Iter 7250 | Time 19.6029(19.3262) | Bit/dim 3.6528(3.6282) | Xent 0.4941(0.4763) | Loss 2634.0527(2712.5468) | Error 0.1611(0.1674) Steps 0(0.00) | Grad Norm 2826.1028(1876.5131) | Total Time 0.00(0.00)\n",
      "Iter 7260 | Time 20.7890(19.4348) | Bit/dim 3.6237(3.6283) | Xent 0.4708(0.4744) | Loss 2663.3279(2681.8870) | Error 0.1678(0.1662) Steps 0(0.00) | Grad Norm 1629.2724(1851.2394) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 97.7654, Epoch Time 1180.7305(1107.2417), Bit/dim 3.6302(best: 3.6290), Xent 0.6550, Loss 3.9577, Error 0.2212(best: 0.2223)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7270 | Time 18.8710(19.2186) | Bit/dim 3.6361(3.6275) | Xent 0.4259(0.4658) | Loss 2584.6418(2953.7443) | Error 0.1433(0.1639) Steps 0(0.00) | Grad Norm 1576.9141(1812.2798) | Total Time 0.00(0.00)\n",
      "Iter 7280 | Time 19.4143(19.4754) | Bit/dim 3.6297(3.6264) | Xent 0.4663(0.4611) | Loss 2599.8242(2857.5620) | Error 0.1644(0.1621) Steps 0(0.00) | Grad Norm 1674.6109(1785.6515) | Total Time 0.00(0.00)\n",
      "Iter 7290 | Time 18.0638(19.2200) | Bit/dim 3.6093(3.6259) | Xent 0.4321(0.4617) | Loss 2474.3289(2778.3853) | Error 0.1589(0.1635) Steps 0(0.00) | Grad Norm 1641.2990(1797.3955) | Total Time 0.00(0.00)\n",
      "Iter 7300 | Time 17.6110(19.2963) | Bit/dim 3.6065(3.6245) | Xent 0.4533(0.4644) | Loss 2514.7490(2731.1877) | Error 0.1711(0.1653) Steps 0(0.00) | Grad Norm 1539.7976(1784.9565) | Total Time 0.00(0.00)\n",
      "Iter 7310 | Time 19.7823(19.3097) | Bit/dim 3.6119(3.6234) | Xent 0.4920(0.4628) | Loss 2588.2388(2694.0107) | Error 0.1633(0.1644) Steps 0(0.00) | Grad Norm 1533.7302(1842.7688) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 96.0047, Epoch Time 1172.4732(1109.1986), Bit/dim 3.6303(best: 3.6290), Xent 0.6701, Loss 3.9653, Error 0.2257(best: 0.2212)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7320 | Time 18.0291(19.2222) | Bit/dim 3.6408(3.6256) | Xent 0.4023(0.4704) | Loss 2517.7385(2999.7742) | Error 0.1533(0.1672) Steps 0(0.00) | Grad Norm 1820.6624(1949.6290) | Total Time 0.00(0.00)\n",
      "Iter 7330 | Time 17.9637(19.1790) | Bit/dim 3.6594(3.6272) | Xent 0.5342(0.4741) | Loss 2574.1179(2895.2294) | Error 0.1889(0.1684) Steps 0(0.00) | Grad Norm 3582.5694(1991.5692) | Total Time 0.00(0.00)\n",
      "Iter 7340 | Time 20.1751(19.2203) | Bit/dim 3.6427(3.6277) | Xent 0.4675(0.4767) | Loss 2590.7512(2812.8894) | Error 0.1556(0.1693) Steps 0(0.00) | Grad Norm 2308.8438(2131.7548) | Total Time 0.00(0.00)\n",
      "Iter 7350 | Time 17.6357(19.0306) | Bit/dim 3.6010(3.6294) | Xent 0.4581(0.4724) | Loss 2538.6309(2754.2812) | Error 0.1633(0.1689) Steps 0(0.00) | Grad Norm 1489.5093(2028.6033) | Total Time 0.00(0.00)\n",
      "Iter 7360 | Time 19.5186(19.1158) | Bit/dim 3.6588(3.6312) | Xent 0.5604(0.4744) | Loss 2606.5786(2713.7318) | Error 0.2011(0.1694) Steps 0(0.00) | Grad Norm 1800.3567(1941.2596) | Total Time 0.00(0.00)\n",
      "Iter 7370 | Time 18.8039(19.1463) | Bit/dim 3.6577(3.6302) | Xent 0.4360(0.4807) | Loss 2550.0034(2685.9469) | Error 0.1578(0.1713) Steps 0(0.00) | Grad Norm 1163.8284(1922.0398) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 96.9930, Epoch Time 1162.1314(1110.7866), Bit/dim 3.6359(best: 3.6290), Xent 0.7149, Loss 3.9934, Error 0.2357(best: 0.2212)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7380 | Time 19.4893(19.2690) | Bit/dim 3.6061(3.6284) | Xent 0.3749(0.4719) | Loss 2585.2844(2987.4949) | Error 0.1333(0.1680) Steps 0(0.00) | Grad Norm 1292.7258(1918.1673) | Total Time 0.00(0.00)\n",
      "Iter 7390 | Time 19.2430(19.2315) | Bit/dim 3.6276(3.6272) | Xent 0.5311(0.4686) | Loss 2642.2935(2882.7879) | Error 0.1978(0.1671) Steps 0(0.00) | Grad Norm 2691.8509(1867.2377) | Total Time 0.00(0.00)\n",
      "Iter 7400 | Time 19.4422(19.3176) | Bit/dim 3.6255(3.6284) | Xent 0.4130(0.4597) | Loss 2514.8132(2810.8240) | Error 0.1522(0.1633) Steps 0(0.00) | Grad Norm 1302.2185(1798.6233) | Total Time 0.00(0.00)\n",
      "Iter 7410 | Time 19.7120(19.2485) | Bit/dim 3.6228(3.6286) | Xent 0.4952(0.4628) | Loss 2628.5037(2746.3614) | Error 0.1833(0.1644) Steps 0(0.00) | Grad Norm 2773.3550(1853.8404) | Total Time 0.00(0.00)\n",
      "Iter 7420 | Time 19.9897(19.3721) | Bit/dim 3.6333(3.6288) | Xent 0.4397(0.4644) | Loss 2557.7805(2708.7771) | Error 0.1600(0.1653) Steps 0(0.00) | Grad Norm 1099.7124(1843.9161) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 97.8336, Epoch Time 1178.9832(1112.8325), Bit/dim 3.6311(best: 3.6290), Xent 0.6588, Loss 3.9605, Error 0.2205(best: 0.2212)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7430 | Time 21.3221(19.3997) | Bit/dim 3.6039(3.6275) | Xent 0.4361(0.4545) | Loss 2581.5559(3019.5782) | Error 0.1567(0.1615) Steps 0(0.00) | Grad Norm 2206.1336(1775.7657) | Total Time 0.00(0.00)\n",
      "Iter 7440 | Time 19.1803(19.2375) | Bit/dim 3.6341(3.6247) | Xent 0.4248(0.4486) | Loss 2592.7295(2895.4454) | Error 0.1500(0.1593) Steps 0(0.00) | Grad Norm 1169.7013(1718.4289) | Total Time 0.00(0.00)\n",
      "Iter 7450 | Time 17.1386(19.1751) | Bit/dim 3.6465(3.6280) | Xent 0.4160(0.4442) | Loss 2507.7427(2817.4477) | Error 0.1467(0.1574) Steps 0(0.00) | Grad Norm 1313.9795(1697.0273) | Total Time 0.00(0.00)\n",
      "Iter 7460 | Time 18.5377(19.1877) | Bit/dim 3.5737(3.6256) | Xent 0.4052(0.4412) | Loss 2584.2769(2755.6990) | Error 0.1489(0.1562) Steps 0(0.00) | Grad Norm 1404.1733(1695.8721) | Total Time 0.00(0.00)\n",
      "Iter 7470 | Time 19.1361(19.0858) | Bit/dim 3.6258(3.6225) | Xent 0.4074(0.4439) | Loss 2629.1528(2708.1308) | Error 0.1378(0.1578) Steps 0(0.00) | Grad Norm 1593.6418(1704.6325) | Total Time 0.00(0.00)\n",
      "Iter 7480 | Time 19.5152(19.1765) | Bit/dim 3.6043(3.6238) | Xent 0.4878(0.4483) | Loss 2643.7534(2676.8474) | Error 0.1778(0.1598) Steps 0(0.00) | Grad Norm 2972.6914(1749.5538) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 96.8259, Epoch Time 1166.8754(1114.4538), Bit/dim 3.6236(best: 3.6290), Xent 0.6935, Loss 3.9703, Error 0.2327(best: 0.2205)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7490 | Time 20.2745(19.1923) | Bit/dim 3.6477(3.6236) | Xent 0.4274(0.4445) | Loss 2548.8152(2957.6305) | Error 0.1500(0.1583) Steps 0(0.00) | Grad Norm 1707.4816(1688.6672) | Total Time 0.00(0.00)\n",
      "Iter 7500 | Time 19.0642(19.1698) | Bit/dim 3.5827(3.6212) | Xent 0.4577(0.4402) | Loss 2529.6567(2865.1683) | Error 0.1556(0.1574) Steps 0(0.00) | Grad Norm 1775.7523(1684.4398) | Total Time 0.00(0.00)\n",
      "Iter 7510 | Time 20.0230(19.3336) | Bit/dim 3.6310(3.6202) | Xent 0.4886(0.4460) | Loss 2655.3816(2792.6509) | Error 0.1700(0.1596) Steps 0(0.00) | Grad Norm 2972.3944(1845.3315) | Total Time 0.00(0.00)\n",
      "Iter 7520 | Time 19.0448(19.5397) | Bit/dim 3.6768(3.6231) | Xent 0.5085(0.4618) | Loss 2675.1816(2757.7452) | Error 0.1767(0.1647) Steps 0(0.00) | Grad Norm 2411.3267(2053.3224) | Total Time 0.00(0.00)\n",
      "Iter 7530 | Time 19.1110(19.5442) | Bit/dim 3.6309(3.6263) | Xent 0.4500(0.4687) | Loss 2672.5547(2729.0806) | Error 0.1622(0.1680) Steps 0(0.00) | Grad Norm 1443.3566(2051.3333) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 97.8390, Epoch Time 1190.2713(1116.7283), Bit/dim 3.6295(best: 3.6236), Xent 0.6694, Loss 3.9642, Error 0.2238(best: 0.2205)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7540 | Time 21.4554(19.5109) | Bit/dim 3.6207(3.6266) | Xent 0.4260(0.4641) | Loss 2635.7397(3073.5076) | Error 0.1533(0.1659) Steps 0(0.00) | Grad Norm 1980.1177(2000.4756) | Total Time 0.00(0.00)\n",
      "Iter 7550 | Time 18.2020(19.3791) | Bit/dim 3.5656(3.6243) | Xent 0.4267(0.4618) | Loss 2510.7322(2950.6516) | Error 0.1556(0.1651) Steps 0(0.00) | Grad Norm 1907.9493(1906.5521) | Total Time 0.00(0.00)\n",
      "Iter 7560 | Time 18.7466(19.3614) | Bit/dim 3.5956(3.6221) | Xent 0.3995(0.4561) | Loss 2447.6553(2855.1330) | Error 0.1422(0.1639) Steps 0(0.00) | Grad Norm 1092.7608(1869.2652) | Total Time 0.00(0.00)\n",
      "Iter 7570 | Time 20.0158(19.3526) | Bit/dim 3.6284(3.6229) | Xent 0.4527(0.4550) | Loss 2669.6121(2785.7166) | Error 0.1656(0.1637) Steps 0(0.00) | Grad Norm 1595.0685(1877.4445) | Total Time 0.00(0.00)\n",
      "Iter 7580 | Time 19.3265(19.3905) | Bit/dim 3.6243(3.6244) | Xent 0.5284(0.4603) | Loss 2584.6765(2735.8681) | Error 0.1656(0.1640) Steps 0(0.00) | Grad Norm 2957.8635(1871.2797) | Total Time 0.00(0.00)\n",
      "Iter 7590 | Time 19.3859(19.4144) | Bit/dim 3.6401(3.6238) | Xent 0.4961(0.4620) | Loss 2678.9871(2708.9797) | Error 0.1911(0.1644) Steps 0(0.00) | Grad Norm 1330.8920(1853.7731) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 97.3486, Epoch Time 1177.9129(1118.5638), Bit/dim 3.6264(best: 3.6236), Xent 0.6932, Loss 3.9730, Error 0.2315(best: 0.2205)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7600 | Time 18.1707(19.2935) | Bit/dim 3.6141(3.6214) | Xent 0.4450(0.4613) | Loss 2520.5623(2993.6127) | Error 0.1600(0.1643) Steps 0(0.00) | Grad Norm 2088.6446(1931.6813) | Total Time 0.00(0.00)\n",
      "Iter 7610 | Time 19.1212(19.3979) | Bit/dim 3.6119(3.6215) | Xent 0.4830(0.4534) | Loss 2532.7507(2884.0174) | Error 0.1844(0.1624) Steps 0(0.00) | Grad Norm 2101.4465(1868.6833) | Total Time 0.00(0.00)\n",
      "Iter 7620 | Time 19.4799(19.4226) | Bit/dim 3.6427(3.6229) | Xent 0.4470(0.4500) | Loss 2627.4585(2816.7683) | Error 0.1456(0.1603) Steps 0(0.00) | Grad Norm 1827.6199(1880.3650) | Total Time 0.00(0.00)\n",
      "Iter 7630 | Time 19.5847(19.4307) | Bit/dim 3.5942(3.6210) | Xent 0.4569(0.4518) | Loss 2507.3848(2761.4314) | Error 0.1600(0.1617) Steps 0(0.00) | Grad Norm 1683.9285(1879.3283) | Total Time 0.00(0.00)\n",
      "Iter 7640 | Time 19.6586(19.4667) | Bit/dim 3.6559(3.6205) | Xent 0.4462(0.4548) | Loss 2657.0996(2727.1021) | Error 0.1522(0.1625) Steps 0(0.00) | Grad Norm 1895.9167(1876.6088) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 95.9477, Epoch Time 1182.1703(1120.4720), Bit/dim 3.6218(best: 3.6236), Xent 0.6588, Loss 3.9512, Error 0.2203(best: 0.2205)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7650 | Time 18.9237(19.3822) | Bit/dim 3.6180(3.6205) | Xent 0.3926(0.4427) | Loss 2560.0789(3050.2348) | Error 0.1456(0.1574) Steps 0(0.00) | Grad Norm 1675.9766(1768.8649) | Total Time 0.00(0.00)\n",
      "Iter 7660 | Time 19.0899(19.3384) | Bit/dim 3.6237(3.6200) | Xent 0.4963(0.4410) | Loss 2504.3740(2921.7588) | Error 0.1733(0.1564) Steps 0(0.00) | Grad Norm 2508.8212(1775.4603) | Total Time 0.00(0.00)\n",
      "Iter 7670 | Time 18.3644(19.4303) | Bit/dim 3.6139(3.6206) | Xent 0.3884(0.4358) | Loss 2608.9951(2836.9489) | Error 0.1444(0.1548) Steps 0(0.00) | Grad Norm 1790.1193(1745.6687) | Total Time 0.00(0.00)\n",
      "Iter 7680 | Time 19.5954(19.3858) | Bit/dim 3.6677(3.6241) | Xent 0.4003(0.4362) | Loss 2611.6055(2772.3030) | Error 0.1433(0.1558) Steps 0(0.00) | Grad Norm 1286.0694(1724.3401) | Total Time 0.00(0.00)\n",
      "Iter 7690 | Time 19.8579(19.3744) | Bit/dim 3.6064(3.6193) | Xent 0.4428(0.4338) | Loss 2486.7830(2718.6173) | Error 0.1500(0.1548) Steps 0(0.00) | Grad Norm 1029.4502(1643.4447) | Total Time 0.00(0.00)\n",
      "Iter 7700 | Time 18.9917(19.4309) | Bit/dim 3.5859(3.6167) | Xent 0.3853(0.4389) | Loss 2587.3921(2687.0056) | Error 0.1478(0.1577) Steps 0(0.00) | Grad Norm 1300.8003(1646.5553) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 96.6399, Epoch Time 1182.4303(1122.3308), Bit/dim 3.6206(best: 3.6218), Xent 0.6718, Loss 3.9565, Error 0.2213(best: 0.2203)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7710 | Time 19.0085(19.4444) | Bit/dim 3.6077(3.6206) | Xent 0.4276(0.4354) | Loss 2574.1873(2978.2946) | Error 0.1444(0.1571) Steps 0(0.00) | Grad Norm 2027.7440(1704.1029) | Total Time 0.00(0.00)\n",
      "Iter 7720 | Time 18.5969(19.2811) | Bit/dim 3.6591(3.6203) | Xent 0.4407(0.4365) | Loss 2636.9321(2873.6366) | Error 0.1611(0.1569) Steps 0(0.00) | Grad Norm 2800.9120(1746.4697) | Total Time 0.00(0.00)\n",
      "Iter 7730 | Time 20.0648(19.3467) | Bit/dim 3.6100(3.6217) | Xent 0.4478(0.4398) | Loss 2642.9246(2801.5370) | Error 0.1644(0.1580) Steps 0(0.00) | Grad Norm 1794.1990(1845.5915) | Total Time 0.00(0.00)\n",
      "Iter 7740 | Time 18.3850(19.4380) | Bit/dim 3.6332(3.6214) | Xent 0.4688(0.4440) | Loss 2541.2529(2749.4622) | Error 0.1711(0.1589) Steps 0(0.00) | Grad Norm 2074.0194(1828.3821) | Total Time 0.00(0.00)\n",
      "Iter 7750 | Time 18.7191(19.3394) | Bit/dim 3.6132(3.6208) | Xent 0.4664(0.4397) | Loss 2657.4031(2702.8402) | Error 0.1700(0.1570) Steps 0(0.00) | Grad Norm 2177.5225(1725.3900) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0141 | Time 96.3719, Epoch Time 1178.5350(1124.0169), Bit/dim 3.6188(best: 3.6206), Xent 0.6714, Loss 3.9545, Error 0.2204(best: 0.2203)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7760 | Time 18.0491(19.3017) | Bit/dim 3.6502(3.6193) | Xent 0.4095(0.4332) | Loss 2568.7153(3041.7284) | Error 0.1467(0.1549) Steps 0(0.00) | Grad Norm 1996.7619(1749.2119) | Total Time 0.00(0.00)\n",
      "Iter 7770 | Time 20.5758(19.3282) | Bit/dim 3.5904(3.6190) | Xent 0.3787(0.4305) | Loss 2595.6304(2921.6633) | Error 0.1333(0.1535) Steps 0(0.00) | Grad Norm 1505.3620(1769.1244) | Total Time 0.00(0.00)\n",
      "Iter 7780 | Time 19.9174(19.4097) | Bit/dim 3.5890(3.6187) | Xent 0.4447(0.4329) | Loss 2599.1409(2839.6920) | Error 0.1544(0.1546) Steps 0(0.00) | Grad Norm 1422.5829(1784.9813) | Total Time 0.00(0.00)\n",
      "Iter 7790 | Time 19.4241(19.4873) | Bit/dim 3.6371(3.6192) | Xent 0.4561(0.4289) | Loss 2507.8411(2766.1650) | Error 0.1556(0.1528) Steps 0(0.00) | Grad Norm 1783.7887(1673.7941) | Total Time 0.00(0.00)\n",
      "Iter 7800 | Time 20.1830(19.5934) | Bit/dim 3.6184(3.6204) | Xent 0.4624(0.4369) | Loss 2678.9746(2725.6971) | Error 0.1533(0.1542) Steps 0(0.00) | Grad Norm 1847.7678(1796.4296) | Total Time 0.00(0.00)\n",
      "Iter 7810 | Time 22.3248(19.5360) | Bit/dim 3.6458(3.6207) | Xent 0.4332(0.4542) | Loss 2617.7300(2697.6182) | Error 0.1600(0.1608) Steps 0(0.00) | Grad Norm 3064.0770(2090.5957) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0142 | Time 98.7659, Epoch Time 1189.6496(1125.9859), Bit/dim 3.6295(best: 3.6188), Xent 0.6745, Loss 3.9667, Error 0.2274(best: 0.2203)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7820 | Time 18.6711(19.5874) | Bit/dim 3.6307(3.6216) | Xent 0.4218(0.4463) | Loss 2558.4819(2975.5623) | Error 0.1378(0.1585) Steps 0(0.00) | Grad Norm 1535.6977(2043.3215) | Total Time 0.00(0.00)\n",
      "Iter 7830 | Time 19.1420(19.5579) | Bit/dim 3.5951(3.6196) | Xent 0.3983(0.4366) | Loss 2595.6228(2878.4725) | Error 0.1489(0.1555) Steps 0(0.00) | Grad Norm 1401.3774(1862.8432) | Total Time 0.00(0.00)\n",
      "Iter 7840 | Time 19.5580(19.6598) | Bit/dim 3.6291(3.6201) | Xent 0.4199(0.4278) | Loss 2555.6606(2798.0647) | Error 0.1567(0.1521) Steps 0(0.00) | Grad Norm 1225.2833(1762.7642) | Total Time 0.00(0.00)\n",
      "Iter 7850 | Time 19.7187(19.5313) | Bit/dim 3.6098(3.6212) | Xent 0.4262(0.4277) | Loss 2620.8547(2738.4535) | Error 0.1378(0.1512) Steps 0(0.00) | Grad Norm 1639.2502(1748.3734) | Total Time 0.00(0.00)\n",
      "Iter 7860 | Time 20.4452(19.6714) | Bit/dim 3.6034(3.6217) | Xent 0.4677(0.4317) | Loss 2607.2480(2701.1395) | Error 0.1656(0.1515) Steps 0(0.00) | Grad Norm 1807.4121(1747.5053) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0143 | Time 98.3904, Epoch Time 1206.5689(1128.4034), Bit/dim 3.6192(best: 3.6188), Xent 0.6803, Loss 3.9593, Error 0.2267(best: 0.2203)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7870 | Time 19.7480(20.1389) | Bit/dim 3.6303(3.6215) | Xent 0.3671(0.4303) | Loss 2669.9351(3033.9447) | Error 0.1289(0.1515) Steps 0(0.00) | Grad Norm 1634.8682(1751.4806) | Total Time 0.00(0.00)\n",
      "Iter 7880 | Time 20.4113(20.0812) | Bit/dim 3.5786(3.6214) | Xent 0.4284(0.4265) | Loss 2480.1194(2913.9172) | Error 0.1533(0.1511) Steps 0(0.00) | Grad Norm 1608.0330(1772.8534) | Total Time 0.00(0.00)\n",
      "Iter 7890 | Time 19.5582(19.9273) | Bit/dim 3.6194(3.6190) | Xent 0.4369(0.4220) | Loss 2612.9412(2827.5392) | Error 0.1422(0.1487) Steps 0(0.00) | Grad Norm 1072.7190(1757.3601) | Total Time 0.00(0.00)\n",
      "Iter 7900 | Time 19.3027(19.7473) | Bit/dim 3.6102(3.6160) | Xent 0.5056(0.4292) | Loss 2642.1094(2763.0305) | Error 0.1667(0.1513) Steps 0(0.00) | Grad Norm 2390.6516(1786.4728) | Total Time 0.00(0.00)\n",
      "Iter 7910 | Time 21.5899(19.9411) | Bit/dim 3.6009(3.6171) | Xent 0.4435(0.4344) | Loss 2653.2659(2721.0467) | Error 0.1656(0.1541) Steps 0(0.00) | Grad Norm 1951.1543(1748.5865) | Total Time 0.00(0.00)\n",
      "Iter 7920 | Time 19.2790(19.8734) | Bit/dim 3.6377(3.6213) | Xent 0.4025(0.4323) | Loss 2568.1294(2687.3981) | Error 0.1567(0.1529) Steps 0(0.00) | Grad Norm 1887.6123(1754.6541) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0144 | Time 95.2049, Epoch Time 1209.6945(1130.8421), Bit/dim 3.6251(best: 3.6188), Xent 0.6674, Loss 3.9588, Error 0.2229(best: 0.2203)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7930 | Time 19.2420(19.7093) | Bit/dim 3.6231(3.6209) | Xent 0.4287(0.4266) | Loss 2567.6265(2977.3631) | Error 0.1533(0.1516) Steps 0(0.00) | Grad Norm 1486.5234(1683.1510) | Total Time 0.00(0.00)\n",
      "Iter 7940 | Time 19.0047(19.6502) | Bit/dim 3.6047(3.6181) | Xent 0.3869(0.4193) | Loss 2578.3718(2863.1269) | Error 0.1311(0.1487) Steps 0(0.00) | Grad Norm 2072.1595(1653.0211) | Total Time 0.00(0.00)\n",
      "Iter 7950 | Time 18.9218(19.7141) | Bit/dim 3.6302(3.6201) | Xent 0.4505(0.4200) | Loss 2540.7734(2792.6994) | Error 0.1622(0.1489) Steps 0(0.00) | Grad Norm 2754.1140(1790.6399) | Total Time 0.00(0.00)\n",
      "Iter 7960 | Time 20.1553(19.6573) | Bit/dim 3.5980(3.6180) | Xent 0.4085(0.4208) | Loss 2420.9883(2726.2408) | Error 0.1522(0.1479) Steps 0(0.00) | Grad Norm 1139.3572(1748.9086) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_rlw_5_0_run1 --seed 1 --lr 0.001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5 --scale_fac 1.0 --scale_std 6.0 --rl-weight 5.0\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
