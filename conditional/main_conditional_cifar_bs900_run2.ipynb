{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_cifar10_bs900_run2/current_checkpt.pth', rtol=1e-05, save='../experiments_published/cnf_conditional_cifar10_bs900_run2', seed=2, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=6144, bias=True)\n",
      "  (project_class): LinearZeros(in_features=3072, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1469494\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 18270 | Time 23.2842(23.2893) | Bit/dim 3.4705(3.4622) | Xent 0.0025(0.0030) | Loss 3.4717(3.4637) | Error 0.0000(0.0005) Steps 964(957.46) | Grad Norm 0.8208(0.5728) | Total Time 14.00(14.00)\n",
      "Iter 18280 | Time 24.0971(23.4717) | Bit/dim 3.4687(3.4599) | Xent 0.0023(0.0029) | Loss 3.4698(3.4613) | Error 0.0000(0.0005) Steps 976(963.15) | Grad Norm 0.7154(0.5892) | Total Time 14.00(14.00)\n",
      "Iter 18290 | Time 23.7368(23.6212) | Bit/dim 3.4680(3.4594) | Xent 0.0036(0.0029) | Loss 3.4698(3.4608) | Error 0.0011(0.0005) Steps 976(967.52) | Grad Norm 0.6554(0.6135) | Total Time 14.00(14.00)\n",
      "Iter 18300 | Time 23.5434(23.7259) | Bit/dim 3.4728(3.4625) | Xent 0.0095(0.0031) | Loss 3.4775(3.4641) | Error 0.0022(0.0006) Steps 976(970.48) | Grad Norm 0.7897(0.6322) | Total Time 14.00(14.00)\n",
      "Iter 18310 | Time 23.3759(23.8026) | Bit/dim 3.4195(3.4599) | Xent 0.0029(0.0032) | Loss 3.4210(3.4615) | Error 0.0011(0.0007) Steps 958(971.28) | Grad Norm 0.6886(0.6453) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 121.1042, Epoch Time 1478.3299(1381.9340), Bit/dim 3.4654(best: inf), Xent 3.3808, Loss 5.1557, Error 0.4023(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18320 | Time 24.4521(23.9413) | Bit/dim 3.4659(3.4623) | Xent 0.0029(0.0029) | Loss 3.4673(3.4637) | Error 0.0011(0.0005) Steps 976(972.20) | Grad Norm 0.4131(0.5998) | Total Time 14.00(14.00)\n",
      "Iter 18330 | Time 24.7252(23.9450) | Bit/dim 3.4537(3.4601) | Xent 0.0023(0.0029) | Loss 3.4548(3.4616) | Error 0.0000(0.0005) Steps 994(972.79) | Grad Norm 0.8383(0.5869) | Total Time 14.00(14.00)\n",
      "Iter 18340 | Time 24.7121(24.0336) | Bit/dim 3.4149(3.4610) | Xent 0.0026(0.0027) | Loss 3.4162(3.4623) | Error 0.0000(0.0004) Steps 1000(975.40) | Grad Norm 0.3701(0.5642) | Total Time 14.00(14.00)\n",
      "Iter 18350 | Time 23.8242(24.0282) | Bit/dim 3.4785(3.4597) | Xent 0.0022(0.0028) | Loss 3.4796(3.4611) | Error 0.0000(0.0004) Steps 982(975.35) | Grad Norm 0.4496(0.5529) | Total Time 14.00(14.00)\n",
      "Iter 18360 | Time 23.7447(24.0381) | Bit/dim 3.4639(3.4609) | Xent 0.0026(0.0027) | Loss 3.4652(3.4622) | Error 0.0000(0.0004) Steps 982(976.93) | Grad Norm 0.3837(0.5133) | Total Time 14.00(14.00)\n",
      "Iter 18370 | Time 23.3773(24.0119) | Bit/dim 3.4766(3.4606) | Xent 0.0030(0.0025) | Loss 3.4781(3.4618) | Error 0.0011(0.0003) Steps 970(976.35) | Grad Norm 0.5056(0.4902) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 115.5922, Epoch Time 1458.8742(1384.2422), Bit/dim 3.4631(best: 3.4654), Xent 3.3336, Loss 5.1299, Error 0.3968(best: 0.4023)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18380 | Time 23.3367(24.0378) | Bit/dim 3.4792(3.4583) | Xent 0.0018(0.0025) | Loss 3.4802(3.4595) | Error 0.0000(0.0003) Steps 964(976.43) | Grad Norm 0.2602(0.4469) | Total Time 14.00(14.00)\n",
      "Iter 18390 | Time 24.2526(24.0241) | Bit/dim 3.4938(3.4594) | Xent 0.0045(0.0025) | Loss 3.4961(3.4606) | Error 0.0011(0.0003) Steps 994(975.91) | Grad Norm 0.7764(0.4537) | Total Time 14.00(14.00)\n",
      "Iter 18400 | Time 24.2859(24.0408) | Bit/dim 3.4491(3.4597) | Xent 0.0032(0.0025) | Loss 3.4507(3.4609) | Error 0.0000(0.0003) Steps 994(977.22) | Grad Norm 0.4142(0.4541) | Total Time 14.00(14.00)\n",
      "Iter 18410 | Time 23.9750(24.0387) | Bit/dim 3.4759(3.4598) | Xent 0.0028(0.0029) | Loss 3.4773(3.4613) | Error 0.0011(0.0004) Steps 970(975.78) | Grad Norm 0.4732(0.4641) | Total Time 14.00(14.00)\n",
      "Iter 18420 | Time 23.8028(24.0282) | Bit/dim 3.4914(3.4620) | Xent 0.0014(0.0028) | Loss 3.4921(3.4634) | Error 0.0000(0.0004) Steps 976(977.27) | Grad Norm 0.2852(0.4417) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 115.0849, Epoch Time 1456.5681(1386.4120), Bit/dim 3.4624(best: 3.4631), Xent 3.3135, Loss 5.1192, Error 0.3976(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18430 | Time 23.9210(24.0764) | Bit/dim 3.4560(3.4605) | Xent 0.0025(0.0027) | Loss 3.4572(3.4619) | Error 0.0000(0.0003) Steps 988(977.52) | Grad Norm 0.4864(0.4297) | Total Time 14.00(14.00)\n",
      "Iter 18440 | Time 24.0903(24.1086) | Bit/dim 3.4689(3.4627) | Xent 0.0022(0.0027) | Loss 3.4700(3.4641) | Error 0.0000(0.0003) Steps 970(976.78) | Grad Norm 0.5190(0.4196) | Total Time 14.00(14.00)\n",
      "Iter 18450 | Time 23.6257(24.1046) | Bit/dim 3.4573(3.4630) | Xent 0.0020(0.0026) | Loss 3.4583(3.4643) | Error 0.0000(0.0003) Steps 982(977.87) | Grad Norm 0.3368(0.4022) | Total Time 14.00(14.00)\n",
      "Iter 18460 | Time 24.1315(24.0880) | Bit/dim 3.4460(3.4607) | Xent 0.0029(0.0027) | Loss 3.4475(3.4620) | Error 0.0011(0.0003) Steps 970(977.13) | Grad Norm 0.6170(0.4259) | Total Time 14.00(14.00)\n",
      "Iter 18470 | Time 23.9306(24.0732) | Bit/dim 3.4374(3.4619) | Xent 0.0063(0.0028) | Loss 3.4406(3.4633) | Error 0.0011(0.0004) Steps 946(976.20) | Grad Norm 0.9501(0.4538) | Total Time 14.00(14.00)\n",
      "Iter 18480 | Time 24.1135(24.0922) | Bit/dim 3.4294(3.4586) | Xent 0.0025(0.0028) | Loss 3.4307(3.4600) | Error 0.0000(0.0004) Steps 988(976.89) | Grad Norm 0.7120(0.5053) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 114.8079, Epoch Time 1459.1814(1388.5950), Bit/dim 3.4647(best: 3.4624), Xent 3.3992, Loss 5.1643, Error 0.4040(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18490 | Time 24.2457(24.0853) | Bit/dim 3.4613(3.4607) | Xent 0.0026(0.0030) | Loss 3.4626(3.4622) | Error 0.0000(0.0004) Steps 976(977.12) | Grad Norm 0.4363(0.5118) | Total Time 14.00(14.00)\n",
      "Iter 18500 | Time 25.1824(24.1950) | Bit/dim 3.4653(3.4605) | Xent 0.0016(0.0029) | Loss 3.4661(3.4619) | Error 0.0000(0.0004) Steps 976(977.49) | Grad Norm 0.3470(0.4978) | Total Time 14.00(14.00)\n",
      "Iter 18510 | Time 24.2675(24.2582) | Bit/dim 3.4667(3.4599) | Xent 0.0015(0.0026) | Loss 3.4675(3.4612) | Error 0.0000(0.0003) Steps 958(977.02) | Grad Norm 0.2886(0.4659) | Total Time 14.00(14.00)\n",
      "Iter 18520 | Time 24.1316(24.2523) | Bit/dim 3.4732(3.4602) | Xent 0.0015(0.0025) | Loss 3.4740(3.4614) | Error 0.0000(0.0002) Steps 976(977.19) | Grad Norm 0.3183(0.4538) | Total Time 14.00(14.00)\n",
      "Iter 18530 | Time 24.9218(24.1979) | Bit/dim 3.4513(3.4604) | Xent 0.0014(0.0029) | Loss 3.4520(3.4618) | Error 0.0000(0.0004) Steps 976(975.50) | Grad Norm 0.4248(0.4762) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 115.7891, Epoch Time 1467.2258(1390.9540), Bit/dim 3.4629(best: 3.4624), Xent 3.3613, Loss 5.1436, Error 0.4007(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18540 | Time 23.2806(24.1434) | Bit/dim 3.4835(3.4584) | Xent 0.0021(0.0029) | Loss 3.4846(3.4598) | Error 0.0000(0.0004) Steps 976(975.19) | Grad Norm 0.3647(0.4755) | Total Time 14.00(14.00)\n",
      "Iter 18550 | Time 24.3429(24.0922) | Bit/dim 3.4408(3.4558) | Xent 0.0022(0.0028) | Loss 3.4419(3.4572) | Error 0.0000(0.0004) Steps 994(976.30) | Grad Norm 0.2621(0.4543) | Total Time 14.00(14.00)\n",
      "Iter 18560 | Time 23.4830(24.0274) | Bit/dim 3.4894(3.4581) | Xent 0.0010(0.0027) | Loss 3.4900(3.4595) | Error 0.0000(0.0004) Steps 970(974.04) | Grad Norm 0.4087(0.4708) | Total Time 14.00(14.00)\n",
      "Iter 18570 | Time 23.9395(24.0859) | Bit/dim 3.4467(3.4565) | Xent 0.0024(0.0027) | Loss 3.4479(3.4578) | Error 0.0011(0.0004) Steps 976(974.08) | Grad Norm 0.6011(0.5084) | Total Time 14.00(14.00)\n",
      "Iter 18580 | Time 23.9953(24.0933) | Bit/dim 3.4658(3.4593) | Xent 0.0019(0.0026) | Loss 3.4668(3.4606) | Error 0.0000(0.0003) Steps 982(975.39) | Grad Norm 0.2783(0.4885) | Total Time 14.00(14.00)\n",
      "Iter 18590 | Time 24.0684(24.1921) | Bit/dim 3.4515(3.4622) | Xent 0.0024(0.0026) | Loss 3.4528(3.4635) | Error 0.0000(0.0003) Steps 982(975.04) | Grad Norm 0.4773(0.4928) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 114.6910, Epoch Time 1458.1417(1392.9696), Bit/dim 3.4629(best: 3.4624), Xent 3.3801, Loss 5.1529, Error 0.4022(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18600 | Time 23.8866(24.1676) | Bit/dim 3.4361(3.4607) | Xent 0.0040(0.0027) | Loss 3.4381(3.4621) | Error 0.0011(0.0004) Steps 982(974.94) | Grad Norm 0.5462(0.4810) | Total Time 14.00(14.00)\n",
      "Iter 18610 | Time 23.4658(24.1559) | Bit/dim 3.4756(3.4609) | Xent 0.0027(0.0027) | Loss 3.4770(3.4622) | Error 0.0000(0.0004) Steps 970(973.85) | Grad Norm 0.4565(0.4646) | Total Time 14.00(14.00)\n",
      "Iter 18620 | Time 23.5089(24.1571) | Bit/dim 3.4471(3.4605) | Xent 0.0046(0.0025) | Loss 3.4494(3.4618) | Error 0.0011(0.0003) Steps 982(975.64) | Grad Norm 0.6258(0.4370) | Total Time 14.00(14.00)\n",
      "Iter 18630 | Time 24.0480(24.1162) | Bit/dim 3.4433(3.4607) | Xent 0.0014(0.0026) | Loss 3.4441(3.4621) | Error 0.0000(0.0003) Steps 976(976.04) | Grad Norm 0.3362(0.4234) | Total Time 14.00(14.00)\n",
      "Iter 18640 | Time 24.3890(24.0976) | Bit/dim 3.4600(3.4605) | Xent 0.0026(0.0025) | Loss 3.4613(3.4617) | Error 0.0000(0.0003) Steps 976(975.68) | Grad Norm 0.6819(0.4344) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 114.5321, Epoch Time 1458.7496(1394.9430), Bit/dim 3.4626(best: 3.4624), Xent 3.3914, Loss 5.1582, Error 0.3999(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18650 | Time 24.2240(24.1756) | Bit/dim 3.4499(3.4562) | Xent 0.0086(0.0026) | Loss 3.4542(3.4575) | Error 0.0011(0.0003) Steps 970(976.03) | Grad Norm 0.6484(0.4480) | Total Time 14.00(14.00)\n",
      "Iter 18660 | Time 24.8050(24.2272) | Bit/dim 3.4575(3.4585) | Xent 0.0015(0.0025) | Loss 3.4583(3.4598) | Error 0.0000(0.0003) Steps 964(978.14) | Grad Norm 0.3018(0.4353) | Total Time 14.00(14.00)\n",
      "Iter 18670 | Time 23.7291(24.1983) | Bit/dim 3.4399(3.4581) | Xent 0.0013(0.0026) | Loss 3.4406(3.4594) | Error 0.0000(0.0003) Steps 976(976.93) | Grad Norm 0.4131(0.4408) | Total Time 14.00(14.00)\n",
      "Iter 18680 | Time 24.1049(24.1778) | Bit/dim 3.4866(3.4608) | Xent 0.0021(0.0025) | Loss 3.4877(3.4621) | Error 0.0000(0.0003) Steps 976(978.65) | Grad Norm 0.4743(0.4722) | Total Time 14.00(14.00)\n",
      "Iter 18690 | Time 24.0124(24.0609) | Bit/dim 3.4651(3.4603) | Xent 0.0042(0.0026) | Loss 3.4672(3.4616) | Error 0.0000(0.0003) Steps 976(976.51) | Grad Norm 0.4537(0.5295) | Total Time 14.00(14.00)\n",
      "Iter 18700 | Time 24.8828(24.0820) | Bit/dim 3.4936(3.4594) | Xent 0.0018(0.0026) | Loss 3.4945(3.4607) | Error 0.0000(0.0003) Steps 958(975.55) | Grad Norm 0.6555(0.5610) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 114.6785, Epoch Time 1460.1384(1396.8989), Bit/dim 3.4632(best: 3.4624), Xent 3.3767, Loss 5.1515, Error 0.3987(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18710 | Time 25.1558(24.0886) | Bit/dim 3.4624(3.4597) | Xent 0.0026(0.0026) | Loss 3.4637(3.4610) | Error 0.0011(0.0004) Steps 994(976.15) | Grad Norm 0.5968(0.5673) | Total Time 14.00(14.00)\n",
      "Iter 18720 | Time 24.1112(24.0414) | Bit/dim 3.4537(3.4592) | Xent 0.0022(0.0025) | Loss 3.4548(3.4605) | Error 0.0000(0.0003) Steps 982(975.70) | Grad Norm 0.4842(0.5430) | Total Time 14.00(14.00)\n",
      "Iter 18730 | Time 23.0408(23.9831) | Bit/dim 3.4383(3.4573) | Xent 0.0033(0.0026) | Loss 3.4400(3.4586) | Error 0.0011(0.0004) Steps 970(975.82) | Grad Norm 0.4206(0.5266) | Total Time 14.00(14.00)\n",
      "Iter 18740 | Time 24.1591(24.0724) | Bit/dim 3.4477(3.4567) | Xent 0.0013(0.0025) | Loss 3.4484(3.4579) | Error 0.0000(0.0004) Steps 970(976.23) | Grad Norm 0.4030(0.5169) | Total Time 14.00(14.00)\n",
      "Iter 18750 | Time 23.7466(24.0674) | Bit/dim 3.4678(3.4591) | Xent 0.0026(0.0025) | Loss 3.4691(3.4604) | Error 0.0000(0.0003) Steps 976(977.08) | Grad Norm 0.5421(0.5124) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 114.9799, Epoch Time 1455.5124(1398.6573), Bit/dim 3.4618(best: 3.4624), Xent 3.3443, Loss 5.1340, Error 0.3975(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18760 | Time 23.8407(24.0777) | Bit/dim 3.4562(3.4592) | Xent 0.0012(0.0025) | Loss 3.4568(3.4604) | Error 0.0000(0.0003) Steps 988(977.37) | Grad Norm 0.2784(0.4881) | Total Time 14.00(14.00)\n",
      "Iter 18770 | Time 24.5890(24.0809) | Bit/dim 3.4825(3.4594) | Xent 0.0023(0.0024) | Loss 3.4837(3.4606) | Error 0.0000(0.0003) Steps 988(978.48) | Grad Norm 0.3280(0.4740) | Total Time 14.00(14.00)\n",
      "Iter 18780 | Time 23.7910(24.0450) | Bit/dim 3.4594(3.4590) | Xent 0.0037(0.0024) | Loss 3.4612(3.4602) | Error 0.0011(0.0003) Steps 988(977.03) | Grad Norm 0.4957(0.4403) | Total Time 14.00(14.00)\n",
      "Iter 18790 | Time 24.2152(24.1178) | Bit/dim 3.4366(3.4585) | Xent 0.0026(0.0023) | Loss 3.4379(3.4596) | Error 0.0011(0.0003) Steps 976(975.73) | Grad Norm 0.3021(0.4019) | Total Time 14.00(14.00)\n",
      "Iter 18800 | Time 23.6914(24.0894) | Bit/dim 3.4493(3.4588) | Xent 0.0049(0.0024) | Loss 3.4517(3.4601) | Error 0.0011(0.0004) Steps 970(976.24) | Grad Norm 0.7598(0.4060) | Total Time 14.00(14.00)\n",
      "Iter 18810 | Time 24.4089(24.1635) | Bit/dim 3.4456(3.4588) | Xent 0.0034(0.0028) | Loss 3.4473(3.4602) | Error 0.0000(0.0005) Steps 976(975.60) | Grad Norm 0.6718(0.5515) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 114.4589, Epoch Time 1460.5171(1400.5131), Bit/dim 3.4635(best: 3.4618), Xent 3.4118, Loss 5.1694, Error 0.3989(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18820 | Time 24.6162(24.1856) | Bit/dim 3.4583(3.4597) | Xent 0.0032(0.0027) | Loss 3.4599(3.4611) | Error 0.0011(0.0004) Steps 988(976.74) | Grad Norm 1.0770(0.6972) | Total Time 14.00(14.00)\n",
      "Iter 18830 | Time 23.7240(24.2151) | Bit/dim 3.4436(3.4579) | Xent 0.0032(0.0027) | Loss 3.4452(3.4592) | Error 0.0011(0.0005) Steps 982(976.54) | Grad Norm 1.0613(0.7505) | Total Time 14.00(14.00)\n",
      "Iter 18840 | Time 24.4795(24.2018) | Bit/dim 3.4569(3.4564) | Xent 0.0029(0.0027) | Loss 3.4584(3.4578) | Error 0.0011(0.0005) Steps 1000(978.08) | Grad Norm 0.8093(0.7285) | Total Time 14.00(14.00)\n",
      "Iter 18850 | Time 23.4181(24.2056) | Bit/dim 3.4791(3.4574) | Xent 0.0014(0.0026) | Loss 3.4798(3.4587) | Error 0.0000(0.0004) Steps 964(978.00) | Grad Norm 0.5550(0.6941) | Total Time 14.00(14.00)\n",
      "Iter 18860 | Time 24.9687(24.2054) | Bit/dim 3.4601(3.4596) | Xent 0.0017(0.0027) | Loss 3.4609(3.4609) | Error 0.0000(0.0004) Steps 982(977.17) | Grad Norm 0.5733(0.6808) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 113.9680, Epoch Time 1463.8858(1402.4142), Bit/dim 3.4635(best: 3.4618), Xent 3.3653, Loss 5.1461, Error 0.4000(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18870 | Time 24.0281(24.1551) | Bit/dim 3.4388(3.4604) | Xent 0.0016(0.0029) | Loss 3.4397(3.4619) | Error 0.0000(0.0004) Steps 976(976.16) | Grad Norm 0.5069(0.6767) | Total Time 14.00(14.00)\n",
      "Iter 18880 | Time 24.0207(24.1762) | Bit/dim 3.4732(3.4583) | Xent 0.0060(0.0030) | Loss 3.4762(3.4598) | Error 0.0022(0.0005) Steps 994(976.41) | Grad Norm 0.8518(0.6808) | Total Time 14.00(14.00)\n",
      "Iter 18890 | Time 23.9700(24.0732) | Bit/dim 3.4800(3.4582) | Xent 0.0018(0.0031) | Loss 3.4808(3.4598) | Error 0.0000(0.0004) Steps 970(975.65) | Grad Norm 0.9105(0.7084) | Total Time 14.00(14.00)\n",
      "Iter 18900 | Time 23.2337(23.9826) | Bit/dim 3.4509(3.4597) | Xent 0.0015(0.0030) | Loss 3.4516(3.4612) | Error 0.0000(0.0004) Steps 982(975.40) | Grad Norm 0.6547(0.7898) | Total Time 14.00(14.00)\n",
      "Iter 18910 | Time 23.4669(23.9527) | Bit/dim 3.4698(3.4617) | Xent 0.0015(0.0027) | Loss 3.4705(3.4631) | Error 0.0000(0.0005) Steps 982(976.35) | Grad Norm 0.3040(0.7792) | Total Time 14.00(14.00)\n",
      "Iter 18920 | Time 24.2857(23.9516) | Bit/dim 3.4865(3.4609) | Xent 0.0026(0.0026) | Loss 3.4878(3.4622) | Error 0.0000(0.0003) Steps 988(976.64) | Grad Norm 0.5825(0.6979) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 114.3022, Epoch Time 1448.5002(1403.7968), Bit/dim 3.4623(best: 3.4618), Xent 3.3653, Loss 5.1450, Error 0.4022(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18930 | Time 23.9007(23.9169) | Bit/dim 3.4429(3.4600) | Xent 0.0019(0.0025) | Loss 3.4439(3.4613) | Error 0.0000(0.0003) Steps 970(975.16) | Grad Norm 0.7330(0.6533) | Total Time 14.00(14.00)\n",
      "Iter 18940 | Time 24.0535(23.9991) | Bit/dim 3.4624(3.4597) | Xent 0.0025(0.0027) | Loss 3.4636(3.4611) | Error 0.0011(0.0005) Steps 970(977.36) | Grad Norm 0.8288(0.6711) | Total Time 14.00(14.00)\n",
      "Iter 18950 | Time 23.7438(24.0286) | Bit/dim 3.4497(3.4584) | Xent 0.0013(0.0028) | Loss 3.4504(3.4598) | Error 0.0000(0.0004) Steps 982(978.15) | Grad Norm 0.3984(0.6366) | Total Time 14.00(14.00)\n",
      "Iter 18960 | Time 25.1227(24.0875) | Bit/dim 3.4319(3.4586) | Xent 0.0012(0.0026) | Loss 3.4325(3.4599) | Error 0.0000(0.0004) Steps 958(977.02) | Grad Norm 0.6369(0.6076) | Total Time 14.00(14.00)\n",
      "Iter 18970 | Time 24.2100(24.1916) | Bit/dim 3.4283(3.4600) | Xent 0.0035(0.0026) | Loss 3.4300(3.4614) | Error 0.0011(0.0005) Steps 994(977.67) | Grad Norm 0.4673(0.5908) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 113.1578, Epoch Time 1460.5308(1405.4988), Bit/dim 3.4620(best: 3.4618), Xent 3.4017, Loss 5.1628, Error 0.4036(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18980 | Time 25.3189(24.1543) | Bit/dim 3.4510(3.4586) | Xent 0.0024(0.0026) | Loss 3.4522(3.4599) | Error 0.0011(0.0005) Steps 970(975.67) | Grad Norm 0.4850(0.5825) | Total Time 14.00(14.00)\n",
      "Iter 18990 | Time 23.4569(24.0928) | Bit/dim 3.4412(3.4590) | Xent 0.0015(0.0026) | Loss 3.4419(3.4603) | Error 0.0000(0.0005) Steps 976(974.73) | Grad Norm 0.4658(0.5732) | Total Time 14.00(14.00)\n",
      "Iter 19000 | Time 24.5837(24.1167) | Bit/dim 3.4401(3.4587) | Xent 0.0017(0.0024) | Loss 3.4410(3.4600) | Error 0.0000(0.0004) Steps 982(975.15) | Grad Norm 0.3015(0.5408) | Total Time 14.00(14.00)\n",
      "Iter 19010 | Time 24.3122(24.1348) | Bit/dim 3.4716(3.4570) | Xent 0.0013(0.0023) | Loss 3.4722(3.4582) | Error 0.0000(0.0004) Steps 976(976.27) | Grad Norm 0.3594(0.5089) | Total Time 14.00(14.00)\n",
      "Iter 19020 | Time 24.4263(24.1107) | Bit/dim 3.4739(3.4578) | Xent 0.0019(0.0024) | Loss 3.4749(3.4589) | Error 0.0000(0.0003) Steps 970(974.93) | Grad Norm 0.4132(0.4644) | Total Time 14.00(14.00)\n",
      "Iter 19030 | Time 23.6659(24.0759) | Bit/dim 3.4539(3.4579) | Xent 0.0031(0.0026) | Loss 3.4554(3.4592) | Error 0.0000(0.0003) Steps 964(975.08) | Grad Norm 0.5450(0.4774) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 115.2243, Epoch Time 1456.3750(1407.0251), Bit/dim 3.4610(best: 3.4618), Xent 3.4395, Loss 5.1808, Error 0.4014(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19040 | Time 23.8104(24.0676) | Bit/dim 3.4457(3.4565) | Xent 0.0024(0.0025) | Loss 3.4469(3.4578) | Error 0.0000(0.0003) Steps 982(976.03) | Grad Norm 0.5137(0.4795) | Total Time 14.00(14.00)\n",
      "Iter 19050 | Time 24.2397(24.0595) | Bit/dim 3.4638(3.4566) | Xent 0.0023(0.0024) | Loss 3.4650(3.4578) | Error 0.0000(0.0003) Steps 976(975.08) | Grad Norm 0.4786(0.4683) | Total Time 14.00(14.00)\n",
      "Iter 19060 | Time 24.8575(24.1180) | Bit/dim 3.4736(3.4573) | Xent 0.0016(0.0024) | Loss 3.4744(3.4585) | Error 0.0000(0.0003) Steps 964(975.38) | Grad Norm 0.4742(0.4628) | Total Time 14.00(14.00)\n",
      "Iter 19070 | Time 24.1136(24.0988) | Bit/dim 3.4928(3.4553) | Xent 0.0023(0.0023) | Loss 3.4940(3.4564) | Error 0.0000(0.0002) Steps 964(973.55) | Grad Norm 0.2838(0.4470) | Total Time 14.00(14.00)\n",
      "Iter 19080 | Time 23.6008(24.0746) | Bit/dim 3.4507(3.4565) | Xent 0.0015(0.0025) | Loss 3.4515(3.4578) | Error 0.0000(0.0004) Steps 982(974.15) | Grad Norm 0.8236(0.5069) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 113.4969, Epoch Time 1455.0167(1408.4649), Bit/dim 3.4613(best: 3.4610), Xent 3.4182, Loss 5.1703, Error 0.4015(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19090 | Time 23.4161(24.0168) | Bit/dim 3.4679(3.4577) | Xent 0.0020(0.0024) | Loss 3.4689(3.4589) | Error 0.0000(0.0004) Steps 976(973.83) | Grad Norm 0.4210(0.5335) | Total Time 14.00(14.00)\n",
      "Iter 19100 | Time 23.8574(23.9727) | Bit/dim 3.4476(3.4583) | Xent 0.0042(0.0025) | Loss 3.4497(3.4596) | Error 0.0011(0.0004) Steps 958(973.71) | Grad Norm 0.6551(0.5234) | Total Time 14.00(14.00)\n",
      "Iter 19110 | Time 23.9580(23.9666) | Bit/dim 3.4583(3.4588) | Xent 0.0022(0.0025) | Loss 3.4594(3.4601) | Error 0.0000(0.0004) Steps 958(970.37) | Grad Norm 0.3469(0.4923) | Total Time 14.00(14.00)\n",
      "Iter 19120 | Time 23.9667(23.9525) | Bit/dim 3.4645(3.4579) | Xent 0.0012(0.0023) | Loss 3.4651(3.4590) | Error 0.0000(0.0003) Steps 976(973.47) | Grad Norm 0.3017(0.4524) | Total Time 14.00(14.00)\n",
      "Iter 19130 | Time 23.6035(23.9315) | Bit/dim 3.4221(3.4564) | Xent 0.0027(0.0023) | Loss 3.4235(3.4575) | Error 0.0000(0.0003) Steps 970(972.86) | Grad Norm 0.4725(0.4304) | Total Time 14.00(14.00)\n",
      "Iter 19140 | Time 24.0158(23.8980) | Bit/dim 3.4562(3.4571) | Xent 0.0015(0.0025) | Loss 3.4569(3.4583) | Error 0.0000(0.0004) Steps 976(972.93) | Grad Norm 0.3232(0.4458) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 114.3266, Epoch Time 1444.9409(1409.5592), Bit/dim 3.4615(best: 3.4610), Xent 3.4116, Loss 5.1673, Error 0.4026(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19150 | Time 24.1025(23.8823) | Bit/dim 3.4519(3.4582) | Xent 0.0033(0.0025) | Loss 3.4536(3.4595) | Error 0.0011(0.0004) Steps 994(972.37) | Grad Norm 0.8055(0.5046) | Total Time 14.00(14.00)\n",
      "Iter 19160 | Time 24.2424(23.9259) | Bit/dim 3.4673(3.4564) | Xent 0.0035(0.0027) | Loss 3.4691(3.4577) | Error 0.0011(0.0005) Steps 982(972.72) | Grad Norm 0.7544(0.5390) | Total Time 14.00(14.00)\n",
      "Iter 19170 | Time 23.5988(23.9089) | Bit/dim 3.4585(3.4580) | Xent 0.0019(0.0027) | Loss 3.4595(3.4594) | Error 0.0000(0.0005) Steps 976(971.22) | Grad Norm 0.6992(0.5874) | Total Time 14.00(14.00)\n",
      "Iter 19180 | Time 23.5645(23.9464) | Bit/dim 3.4963(3.4564) | Xent 0.0023(0.0028) | Loss 3.4974(3.4578) | Error 0.0000(0.0005) Steps 982(970.85) | Grad Norm 0.4122(0.5934) | Total Time 14.00(14.00)\n",
      "Iter 19190 | Time 24.0738(23.9346) | Bit/dim 3.4710(3.4587) | Xent 0.0030(0.0028) | Loss 3.4725(3.4601) | Error 0.0011(0.0005) Steps 964(970.86) | Grad Norm 0.3812(0.5815) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 112.5651, Epoch Time 1446.7098(1410.6737), Bit/dim 3.4614(best: 3.4610), Xent 3.4756, Loss 5.1992, Error 0.3977(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19200 | Time 23.8629(23.9237) | Bit/dim 3.4492(3.4578) | Xent 0.0013(0.0026) | Loss 3.4498(3.4591) | Error 0.0000(0.0005) Steps 970(972.05) | Grad Norm 0.3825(0.5446) | Total Time 14.00(14.00)\n",
      "Iter 19210 | Time 23.9907(23.9288) | Bit/dim 3.4494(3.4565) | Xent 0.0015(0.0026) | Loss 3.4501(3.4578) | Error 0.0000(0.0006) Steps 994(971.51) | Grad Norm 0.3392(0.5318) | Total Time 14.00(14.00)\n",
      "Iter 19220 | Time 23.9768(23.9817) | Bit/dim 3.4929(3.4579) | Xent 0.0031(0.0026) | Loss 3.4945(3.4592) | Error 0.0000(0.0005) Steps 970(972.71) | Grad Norm 0.3420(0.5192) | Total Time 14.00(14.00)\n",
      "Iter 19230 | Time 23.6420(24.0227) | Bit/dim 3.4322(3.4592) | Xent 0.0017(0.0026) | Loss 3.4330(3.4605) | Error 0.0000(0.0005) Steps 976(972.20) | Grad Norm 0.4501(0.5173) | Total Time 14.00(14.00)\n",
      "Iter 19240 | Time 24.5985(24.0599) | Bit/dim 3.4658(3.4593) | Xent 0.0028(0.0025) | Loss 3.4673(3.4605) | Error 0.0000(0.0004) Steps 988(973.70) | Grad Norm 0.5169(0.4974) | Total Time 14.00(14.00)\n",
      "Iter 19250 | Time 24.1807(24.0978) | Bit/dim 3.4636(3.4571) | Xent 0.0027(0.0024) | Loss 3.4649(3.4583) | Error 0.0000(0.0003) Steps 964(973.63) | Grad Norm 0.5440(0.4756) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 114.2238, Epoch Time 1457.9992(1412.0934), Bit/dim 3.4601(best: 3.4610), Xent 3.4649, Loss 5.1926, Error 0.4047(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19260 | Time 24.1885(24.0180) | Bit/dim 3.4420(3.4567) | Xent 0.0010(0.0024) | Loss 3.4425(3.4579) | Error 0.0000(0.0003) Steps 988(973.32) | Grad Norm 0.3468(0.4512) | Total Time 14.00(14.00)\n",
      "Iter 19270 | Time 24.4144(23.9814) | Bit/dim 3.4643(3.4590) | Xent 0.0015(0.0025) | Loss 3.4651(3.4603) | Error 0.0000(0.0003) Steps 964(970.86) | Grad Norm 0.4039(0.4331) | Total Time 14.00(14.00)\n",
      "Iter 19280 | Time 22.7192(23.9122) | Bit/dim 3.4684(3.4588) | Xent 0.0015(0.0025) | Loss 3.4692(3.4600) | Error 0.0000(0.0004) Steps 970(972.17) | Grad Norm 0.3096(0.4411) | Total Time 14.00(14.00)\n",
      "Iter 19290 | Time 23.3031(23.8957) | Bit/dim 3.4717(3.4554) | Xent 0.0015(0.0025) | Loss 3.4725(3.4567) | Error 0.0000(0.0004) Steps 970(972.04) | Grad Norm 0.6043(0.4579) | Total Time 14.00(14.00)\n",
      "Iter 19300 | Time 23.7830(23.8954) | Bit/dim 3.4313(3.4544) | Xent 0.0014(0.0025) | Loss 3.4320(3.4556) | Error 0.0000(0.0004) Steps 982(970.96) | Grad Norm 0.6714(0.4822) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 113.5847, Epoch Time 1445.1567(1413.0853), Bit/dim 3.4616(best: 3.4601), Xent 3.4790, Loss 5.2012, Error 0.3986(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19310 | Time 24.3023(23.9683) | Bit/dim 3.4551(3.4573) | Xent 0.0013(0.0025) | Loss 3.4557(3.4585) | Error 0.0000(0.0004) Steps 970(970.52) | Grad Norm 0.6197(0.5096) | Total Time 14.00(14.00)\n",
      "Iter 19320 | Time 24.4441(24.0004) | Bit/dim 3.4746(3.4563) | Xent 0.0037(0.0026) | Loss 3.4764(3.4576) | Error 0.0011(0.0005) Steps 976(971.03) | Grad Norm 0.5413(0.5282) | Total Time 14.00(14.00)\n",
      "Iter 19330 | Time 23.7526(24.0094) | Bit/dim 3.4583(3.4565) | Xent 0.0021(0.0027) | Loss 3.4594(3.4578) | Error 0.0000(0.0005) Steps 976(970.65) | Grad Norm 0.5869(0.5203) | Total Time 14.00(14.00)\n",
      "Iter 19340 | Time 23.8484(23.9831) | Bit/dim 3.4885(3.4556) | Xent 0.0014(0.0025) | Loss 3.4892(3.4569) | Error 0.0000(0.0004) Steps 970(971.51) | Grad Norm 0.3561(0.5127) | Total Time 14.00(14.00)\n",
      "Iter 19350 | Time 24.4445(24.0392) | Bit/dim 3.4557(3.4574) | Xent 0.0079(0.0027) | Loss 3.4597(3.4588) | Error 0.0022(0.0005) Steps 964(972.06) | Grad Norm 1.0927(0.5776) | Total Time 14.00(14.00)\n",
      "Iter 19360 | Time 23.4108(23.9729) | Bit/dim 3.4715(3.4570) | Xent 0.0023(0.0029) | Loss 3.4726(3.4584) | Error 0.0000(0.0005) Steps 970(972.60) | Grad Norm 0.4653(0.6040) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 112.8053, Epoch Time 1450.9695(1414.2219), Bit/dim 3.4601(best: 3.4601), Xent 3.4168, Loss 5.1685, Error 0.3968(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19370 | Time 24.0153(23.9706) | Bit/dim 3.4368(3.4564) | Xent 0.0033(0.0030) | Loss 3.4384(3.4579) | Error 0.0022(0.0006) Steps 958(972.50) | Grad Norm 0.7685(0.6204) | Total Time 14.00(14.00)\n",
      "Iter 19380 | Time 24.1209(23.9098) | Bit/dim 3.4746(3.4599) | Xent 0.0039(0.0030) | Loss 3.4765(3.4614) | Error 0.0011(0.0006) Steps 970(972.07) | Grad Norm 0.6694(0.6010) | Total Time 14.00(14.00)\n",
      "Iter 19390 | Time 24.0841(23.9229) | Bit/dim 3.4217(3.4580) | Xent 0.0015(0.0028) | Loss 3.4225(3.4594) | Error 0.0000(0.0005) Steps 976(972.56) | Grad Norm 0.3667(0.5656) | Total Time 14.00(14.00)\n",
      "Iter 19400 | Time 23.6906(23.9558) | Bit/dim 3.4870(3.4601) | Xent 0.0022(0.0026) | Loss 3.4881(3.4614) | Error 0.0011(0.0005) Steps 982(971.90) | Grad Norm 0.3729(0.5424) | Total Time 14.00(14.00)\n",
      "Iter 19410 | Time 24.0022(23.9342) | Bit/dim 3.4531(3.4575) | Xent 0.0017(0.0026) | Loss 3.4540(3.4588) | Error 0.0000(0.0005) Steps 952(970.89) | Grad Norm 0.3719(0.5428) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 113.8656, Epoch Time 1447.5423(1415.2215), Bit/dim 3.4597(best: 3.4601), Xent 3.4603, Loss 5.1898, Error 0.3999(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19420 | Time 24.2098(23.9503) | Bit/dim 3.4678(3.4567) | Xent 0.0022(0.0026) | Loss 3.4689(3.4580) | Error 0.0000(0.0005) Steps 964(970.59) | Grad Norm 0.4855(0.5217) | Total Time 14.00(14.00)\n",
      "Iter 19430 | Time 23.4248(23.9329) | Bit/dim 3.4737(3.4570) | Xent 0.0012(0.0024) | Loss 3.4743(3.4582) | Error 0.0000(0.0004) Steps 958(969.93) | Grad Norm 0.2843(0.4802) | Total Time 14.00(14.00)\n",
      "Iter 19440 | Time 24.2084(24.0463) | Bit/dim 3.4443(3.4547) | Xent 0.0055(0.0026) | Loss 3.4471(3.4560) | Error 0.0033(0.0005) Steps 976(969.55) | Grad Norm 0.5586(0.4641) | Total Time 14.00(14.00)\n",
      "Iter 19450 | Time 23.0354(23.9825) | Bit/dim 3.4805(3.4556) | Xent 0.0028(0.0025) | Loss 3.4819(3.4568) | Error 0.0000(0.0004) Steps 958(969.85) | Grad Norm 0.5589(0.4551) | Total Time 14.00(14.00)\n",
      "Iter 19460 | Time 23.8616(23.9002) | Bit/dim 3.4344(3.4548) | Xent 0.0016(0.0024) | Loss 3.4352(3.4560) | Error 0.0000(0.0004) Steps 976(970.01) | Grad Norm 0.5130(0.4506) | Total Time 14.00(14.00)\n",
      "Iter 19470 | Time 24.3997(23.9019) | Bit/dim 3.4488(3.4556) | Xent 0.0012(0.0023) | Loss 3.4494(3.4567) | Error 0.0000(0.0003) Steps 964(969.73) | Grad Norm 0.3110(0.4304) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 112.9221, Epoch Time 1447.1382(1416.1790), Bit/dim 3.4601(best: 3.4597), Xent 3.4641, Loss 5.1921, Error 0.4011(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19480 | Time 24.1952(23.9109) | Bit/dim 3.4397(3.4545) | Xent 0.0021(0.0023) | Loss 3.4408(3.4556) | Error 0.0000(0.0003) Steps 970(968.63) | Grad Norm 0.4202(0.4509) | Total Time 14.00(14.00)\n",
      "Iter 19490 | Time 23.9336(23.9136) | Bit/dim 3.4814(3.4562) | Xent 0.0020(0.0024) | Loss 3.4824(3.4574) | Error 0.0011(0.0004) Steps 964(968.80) | Grad Norm 0.3625(0.4724) | Total Time 14.00(14.00)\n",
      "Iter 19500 | Time 24.2303(23.9235) | Bit/dim 3.4751(3.4562) | Xent 0.0022(0.0025) | Loss 3.4762(3.4575) | Error 0.0011(0.0005) Steps 982(970.07) | Grad Norm 0.4053(0.4803) | Total Time 14.00(14.00)\n",
      "Iter 19510 | Time 23.5515(23.8913) | Bit/dim 3.4623(3.4548) | Xent 0.0021(0.0024) | Loss 3.4633(3.4560) | Error 0.0000(0.0004) Steps 964(970.21) | Grad Norm 0.5605(0.4766) | Total Time 14.00(14.00)\n",
      "Iter 19520 | Time 23.8699(23.8081) | Bit/dim 3.4684(3.4560) | Xent 0.0015(0.0024) | Loss 3.4692(3.4572) | Error 0.0000(0.0003) Steps 964(968.04) | Grad Norm 0.4030(0.4650) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 112.7026, Epoch Time 1441.9257(1416.9514), Bit/dim 3.4601(best: 3.4597), Xent 3.5057, Loss 5.2129, Error 0.4015(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19530 | Time 23.5521(23.7917) | Bit/dim 3.4447(3.4553) | Xent 0.0015(0.0025) | Loss 3.4454(3.4565) | Error 0.0000(0.0004) Steps 964(967.29) | Grad Norm 0.4569(0.4841) | Total Time 14.00(14.00)\n",
      "Iter 19540 | Time 23.7202(23.7763) | Bit/dim 3.4366(3.4557) | Xent 0.0062(0.0026) | Loss 3.4397(3.4570) | Error 0.0033(0.0005) Steps 982(968.25) | Grad Norm 0.6122(0.4946) | Total Time 14.00(14.00)\n",
      "Iter 19550 | Time 23.7860(23.7802) | Bit/dim 3.4741(3.4556) | Xent 0.0017(0.0026) | Loss 3.4749(3.4569) | Error 0.0000(0.0005) Steps 976(969.19) | Grad Norm 0.7259(0.5306) | Total Time 14.00(14.00)\n",
      "Iter 19560 | Time 24.4769(23.8121) | Bit/dim 3.5041(3.4576) | Xent 0.0021(0.0026) | Loss 3.5051(3.4589) | Error 0.0000(0.0004) Steps 1000(970.90) | Grad Norm 0.6793(0.5601) | Total Time 14.00(14.00)\n",
      "Iter 19570 | Time 23.5567(23.8228) | Bit/dim 3.4762(3.4560) | Xent 0.0018(0.0025) | Loss 3.4771(3.4573) | Error 0.0000(0.0004) Steps 964(970.65) | Grad Norm 0.4615(0.5506) | Total Time 14.00(14.00)\n",
      "Iter 19580 | Time 23.1320(23.8220) | Bit/dim 3.4410(3.4553) | Xent 0.0019(0.0025) | Loss 3.4419(3.4565) | Error 0.0000(0.0004) Steps 976(971.15) | Grad Norm 0.4275(0.5545) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 113.6043, Epoch Time 1440.6747(1417.6631), Bit/dim 3.4599(best: 3.4597), Xent 3.5448, Loss 5.2323, Error 0.4086(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19590 | Time 23.5201(23.8339) | Bit/dim 3.4502(3.4526) | Xent 0.0029(0.0025) | Loss 3.4517(3.4538) | Error 0.0011(0.0004) Steps 952(969.91) | Grad Norm 0.3666(0.5305) | Total Time 14.00(14.00)\n",
      "Iter 19600 | Time 24.3888(23.8879) | Bit/dim 3.4536(3.4539) | Xent 0.0018(0.0025) | Loss 3.4545(3.4552) | Error 0.0000(0.0004) Steps 970(970.04) | Grad Norm 0.3518(0.5182) | Total Time 14.00(14.00)\n",
      "Iter 19610 | Time 23.5647(23.8841) | Bit/dim 3.4441(3.4544) | Xent 0.0068(0.0026) | Loss 3.4475(3.4557) | Error 0.0022(0.0004) Steps 982(970.65) | Grad Norm 0.6456(0.5084) | Total Time 14.00(14.00)\n",
      "Iter 19620 | Time 24.5464(23.9182) | Bit/dim 3.4411(3.4573) | Xent 0.0017(0.0024) | Loss 3.4420(3.4586) | Error 0.0000(0.0003) Steps 964(970.45) | Grad Norm 0.3486(0.4850) | Total Time 14.00(14.00)\n",
      "Iter 19630 | Time 23.8249(23.9584) | Bit/dim 3.4524(3.4579) | Xent 0.0015(0.0023) | Loss 3.4532(3.4591) | Error 0.0000(0.0003) Steps 964(968.93) | Grad Norm 0.4517(0.4733) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 113.7670, Epoch Time 1449.7949(1418.6270), Bit/dim 3.4593(best: 3.4597), Xent 3.4861, Loss 5.2024, Error 0.4002(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19640 | Time 24.7917(24.0170) | Bit/dim 3.4361(3.4560) | Xent 0.0011(0.0025) | Loss 3.4367(3.4573) | Error 0.0000(0.0003) Steps 970(969.13) | Grad Norm 0.9374(0.5005) | Total Time 14.00(14.00)\n",
      "Iter 19650 | Time 24.3801(23.9679) | Bit/dim 3.4461(3.4546) | Xent 0.0050(0.0026) | Loss 3.4486(3.4559) | Error 0.0011(0.0003) Steps 952(968.82) | Grad Norm 0.8018(0.5391) | Total Time 14.00(14.00)\n",
      "Iter 19660 | Time 23.5676(23.9331) | Bit/dim 3.4545(3.4529) | Xent 0.0030(0.0024) | Loss 3.4560(3.4541) | Error 0.0000(0.0003) Steps 982(969.74) | Grad Norm 0.7698(0.5423) | Total Time 14.00(14.00)\n",
      "Iter 19670 | Time 23.7993(23.9476) | Bit/dim 3.4826(3.4561) | Xent 0.0014(0.0024) | Loss 3.4833(3.4573) | Error 0.0000(0.0003) Steps 982(970.73) | Grad Norm 0.3410(0.5199) | Total Time 14.00(14.00)\n",
      "Iter 19680 | Time 24.0867(23.9276) | Bit/dim 3.4334(3.4556) | Xent 0.0021(0.0025) | Loss 3.4345(3.4568) | Error 0.0000(0.0003) Steps 964(969.99) | Grad Norm 0.5558(0.5061) | Total Time 14.00(14.00)\n",
      "Iter 19690 | Time 24.0133(23.9323) | Bit/dim 3.4551(3.4563) | Xent 0.0068(0.0025) | Loss 3.4585(3.4576) | Error 0.0033(0.0003) Steps 976(970.59) | Grad Norm 0.8146(0.5263) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 112.1559, Epoch Time 1447.1709(1419.4833), Bit/dim 3.4589(best: 3.4593), Xent 3.5321, Loss 5.2250, Error 0.4026(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19700 | Time 23.9986(23.9385) | Bit/dim 3.4301(3.4531) | Xent 0.0016(0.0023) | Loss 3.4309(3.4542) | Error 0.0000(0.0003) Steps 976(970.51) | Grad Norm 0.3654(0.5158) | Total Time 14.00(14.00)\n",
      "Iter 19710 | Time 24.1602(23.9361) | Bit/dim 3.4740(3.4554) | Xent 0.0022(0.0024) | Loss 3.4751(3.4566) | Error 0.0011(0.0004) Steps 988(969.77) | Grad Norm 0.4144(0.5159) | Total Time 14.00(14.00)\n",
      "Iter 19720 | Time 24.0325(23.9323) | Bit/dim 3.4434(3.4538) | Xent 0.0030(0.0025) | Loss 3.4449(3.4551) | Error 0.0000(0.0004) Steps 952(968.37) | Grad Norm 0.3853(0.5110) | Total Time 14.00(14.00)\n",
      "Iter 19730 | Time 23.9847(23.9016) | Bit/dim 3.4489(3.4542) | Xent 0.0028(0.0025) | Loss 3.4503(3.4554) | Error 0.0011(0.0004) Steps 976(967.04) | Grad Norm 0.4963(0.5125) | Total Time 14.00(14.00)\n",
      "Iter 19740 | Time 24.3373(23.7848) | Bit/dim 3.4408(3.4565) | Xent 0.0026(0.0024) | Loss 3.4421(3.4577) | Error 0.0000(0.0004) Steps 964(966.30) | Grad Norm 0.3573(0.5038) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 113.4968, Epoch Time 1442.5510(1420.1754), Bit/dim 3.4588(best: 3.4589), Xent 3.5078, Loss 5.2127, Error 0.4015(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19750 | Time 24.3184(23.8141) | Bit/dim 3.4319(3.4563) | Xent 0.0011(0.0025) | Loss 3.4325(3.4575) | Error 0.0000(0.0003) Steps 958(965.81) | Grad Norm 0.2825(0.5002) | Total Time 14.00(14.00)\n",
      "Iter 19760 | Time 23.3468(23.7986) | Bit/dim 3.4139(3.4558) | Xent 0.0015(0.0024) | Loss 3.4147(3.4570) | Error 0.0000(0.0003) Steps 970(966.45) | Grad Norm 0.3511(0.5017) | Total Time 14.00(14.00)\n",
      "Iter 19770 | Time 24.0140(23.8071) | Bit/dim 3.4591(3.4569) | Xent 0.0022(0.0026) | Loss 3.4602(3.4582) | Error 0.0000(0.0003) Steps 952(967.56) | Grad Norm 0.4969(0.5262) | Total Time 14.00(14.00)\n",
      "Iter 19780 | Time 24.3149(23.8531) | Bit/dim 3.4961(3.4601) | Xent 0.0025(0.0024) | Loss 3.4973(3.4613) | Error 0.0000(0.0002) Steps 994(968.71) | Grad Norm 0.4530(0.5008) | Total Time 14.00(14.00)\n",
      "Iter 19790 | Time 23.9520(23.8800) | Bit/dim 3.4207(3.4571) | Xent 0.0020(0.0025) | Loss 3.4217(3.4584) | Error 0.0000(0.0003) Steps 970(968.70) | Grad Norm 0.3305(0.4774) | Total Time 14.00(14.00)\n",
      "Iter 19800 | Time 23.9329(23.8467) | Bit/dim 3.4855(3.4555) | Xent 0.0023(0.0025) | Loss 3.4867(3.4568) | Error 0.0000(0.0004) Steps 982(968.48) | Grad Norm 0.4390(0.4742) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 113.8242, Epoch Time 1443.6356(1420.8792), Bit/dim 3.4592(best: 3.4588), Xent 3.5041, Loss 5.2113, Error 0.3986(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19810 | Time 23.3803(23.8838) | Bit/dim 3.4161(3.4536) | Xent 0.0032(0.0027) | Loss 3.4177(3.4550) | Error 0.0011(0.0004) Steps 970(968.97) | Grad Norm 0.4295(0.4823) | Total Time 14.00(14.00)\n",
      "Iter 19820 | Time 23.3058(23.8376) | Bit/dim 3.4092(3.4542) | Xent 0.0051(0.0028) | Loss 3.4117(3.4556) | Error 0.0022(0.0005) Steps 970(968.66) | Grad Norm 0.6106(0.5378) | Total Time 14.00(14.00)\n",
      "Iter 19830 | Time 24.2086(23.7854) | Bit/dim 3.4567(3.4542) | Xent 0.0011(0.0029) | Loss 3.4573(3.4556) | Error 0.0000(0.0006) Steps 946(969.13) | Grad Norm 0.5731(0.5559) | Total Time 14.00(14.00)\n",
      "Iter 19840 | Time 23.6313(23.7835) | Bit/dim 3.4309(3.4548) | Xent 0.0016(0.0027) | Loss 3.4317(3.4562) | Error 0.0000(0.0005) Steps 982(968.99) | Grad Norm 0.4579(0.5634) | Total Time 14.00(14.00)\n",
      "Iter 19850 | Time 23.4894(23.8115) | Bit/dim 3.4838(3.4559) | Xent 0.0012(0.0024) | Loss 3.4844(3.4571) | Error 0.0000(0.0005) Steps 976(969.83) | Grad Norm 0.3782(0.5476) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 113.1380, Epoch Time 1442.5790(1421.5302), Bit/dim 3.4591(best: 3.4588), Xent 3.5452, Loss 5.2317, Error 0.4000(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19860 | Time 23.7922(23.8981) | Bit/dim 3.4672(3.4580) | Xent 0.0016(0.0023) | Loss 3.4680(3.4591) | Error 0.0000(0.0003) Steps 976(969.64) | Grad Norm 0.3527(0.5303) | Total Time 14.00(14.00)\n",
      "Iter 19870 | Time 24.7226(23.9035) | Bit/dim 3.4845(3.4571) | Xent 0.0030(0.0023) | Loss 3.4860(3.4582) | Error 0.0011(0.0003) Steps 994(968.00) | Grad Norm 0.4864(0.5037) | Total Time 14.00(14.00)\n",
      "Iter 19880 | Time 23.7431(23.8857) | Bit/dim 3.4742(3.4558) | Xent 0.0047(0.0025) | Loss 3.4765(3.4570) | Error 0.0022(0.0004) Steps 970(968.10) | Grad Norm 0.9030(0.5086) | Total Time 14.00(14.00)\n",
      "Iter 19890 | Time 24.4246(23.8991) | Bit/dim 3.4388(3.4562) | Xent 0.0022(0.0025) | Loss 3.4399(3.4575) | Error 0.0000(0.0004) Steps 988(967.90) | Grad Norm 0.5144(0.5230) | Total Time 14.00(14.00)\n",
      "Iter 19900 | Time 23.6553(23.9608) | Bit/dim 3.4415(3.4545) | Xent 0.0015(0.0024) | Loss 3.4422(3.4557) | Error 0.0000(0.0003) Steps 994(969.90) | Grad Norm 0.3083(0.5082) | Total Time 14.00(14.00)\n",
      "Iter 19910 | Time 24.1575(24.0193) | Bit/dim 3.4717(3.4552) | Xent 0.0049(0.0024) | Loss 3.4742(3.4564) | Error 0.0011(0.0004) Steps 964(970.47) | Grad Norm 0.7242(0.5212) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 113.2901, Epoch Time 1452.2070(1422.4505), Bit/dim 3.4591(best: 3.4588), Xent 3.5370, Loss 5.2276, Error 0.4014(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19920 | Time 24.0961(24.0392) | Bit/dim 3.4605(3.4557) | Xent 0.0015(0.0023) | Loss 3.4612(3.4569) | Error 0.0000(0.0003) Steps 946(970.09) | Grad Norm 0.6080(0.5747) | Total Time 14.00(14.00)\n",
      "Iter 19930 | Time 23.9644(24.0091) | Bit/dim 3.4547(3.4559) | Xent 0.0016(0.0022) | Loss 3.4555(3.4570) | Error 0.0000(0.0003) Steps 964(969.38) | Grad Norm 0.6254(0.5647) | Total Time 14.00(14.00)\n",
      "Iter 19940 | Time 24.1048(24.0462) | Bit/dim 3.4603(3.4547) | Xent 0.0033(0.0024) | Loss 3.4620(3.4559) | Error 0.0011(0.0004) Steps 982(969.61) | Grad Norm 0.6799(0.6168) | Total Time 14.00(14.00)\n",
      "Iter 19950 | Time 23.6090(24.0585) | Bit/dim 3.4312(3.4519) | Xent 0.0037(0.0023) | Loss 3.4330(3.4530) | Error 0.0011(0.0003) Steps 982(969.67) | Grad Norm 0.5117(0.5985) | Total Time 14.00(14.00)\n",
      "Iter 19960 | Time 24.2004(24.0655) | Bit/dim 3.4500(3.4545) | Xent 0.0020(0.0021) | Loss 3.4510(3.4555) | Error 0.0000(0.0002) Steps 982(970.54) | Grad Norm 0.3903(0.5602) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 113.3626, Epoch Time 1454.3228(1423.4067), Bit/dim 3.4575(best: 3.4588), Xent 3.5594, Loss 5.2372, Error 0.4049(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19970 | Time 24.1493(23.9546) | Bit/dim 3.4537(3.4537) | Xent 0.0079(0.0023) | Loss 3.4576(3.4549) | Error 0.0033(0.0003) Steps 970(970.05) | Grad Norm 0.7877(0.5522) | Total Time 14.00(14.00)\n",
      "Iter 19980 | Time 23.8260(23.9957) | Bit/dim 3.4464(3.4528) | Xent 0.0016(0.0023) | Loss 3.4471(3.4539) | Error 0.0000(0.0003) Steps 976(970.07) | Grad Norm 0.5903(0.5496) | Total Time 14.00(14.00)\n",
      "Iter 19990 | Time 24.2381(23.9423) | Bit/dim 3.4695(3.4555) | Xent 0.0024(0.0024) | Loss 3.4707(3.4567) | Error 0.0000(0.0003) Steps 952(968.67) | Grad Norm 0.3399(0.5437) | Total Time 14.00(14.00)\n",
      "Iter 20000 | Time 24.2985(23.9574) | Bit/dim 3.4589(3.4542) | Xent 0.0010(0.0024) | Loss 3.4594(3.4554) | Error 0.0000(0.0004) Steps 970(967.50) | Grad Norm 0.6132(0.5648) | Total Time 14.00(14.00)\n",
      "Iter 20010 | Time 23.8332(23.9711) | Bit/dim 3.4542(3.4527) | Xent 0.0045(0.0027) | Loss 3.4565(3.4540) | Error 0.0011(0.0005) Steps 982(968.22) | Grad Norm 0.9550(0.6041) | Total Time 14.00(14.00)\n",
      "Iter 20020 | Time 23.8498(23.9208) | Bit/dim 3.4409(3.4549) | Xent 0.0019(0.0025) | Loss 3.4418(3.4562) | Error 0.0000(0.0003) Steps 958(967.35) | Grad Norm 0.4542(0.5885) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 113.3271, Epoch Time 1446.0078(1424.0847), Bit/dim 3.4592(best: 3.4575), Xent 3.5351, Loss 5.2267, Error 0.4017(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20030 | Time 23.5172(23.9068) | Bit/dim 3.4539(3.4547) | Xent 0.0019(0.0024) | Loss 3.4549(3.4559) | Error 0.0011(0.0004) Steps 946(966.67) | Grad Norm 0.3785(0.5682) | Total Time 14.00(14.00)\n",
      "Iter 20040 | Time 24.7369(23.9166) | Bit/dim 3.4592(3.4543) | Xent 0.0016(0.0025) | Loss 3.4601(3.4555) | Error 0.0000(0.0004) Steps 970(966.24) | Grad Norm 0.4047(0.5467) | Total Time 14.00(14.00)\n",
      "Iter 20050 | Time 23.9492(23.9211) | Bit/dim 3.4555(3.4543) | Xent 0.0018(0.0023) | Loss 3.4564(3.4554) | Error 0.0000(0.0003) Steps 952(965.80) | Grad Norm 0.3361(0.4959) | Total Time 14.00(14.00)\n",
      "Iter 20060 | Time 23.6970(23.9506) | Bit/dim 3.4565(3.4548) | Xent 0.0018(0.0025) | Loss 3.4574(3.4561) | Error 0.0000(0.0004) Steps 982(967.39) | Grad Norm 0.4329(0.5049) | Total Time 14.00(14.00)\n",
      "Iter 20070 | Time 23.3327(23.9342) | Bit/dim 3.4604(3.4561) | Xent 0.0022(0.0025) | Loss 3.4615(3.4574) | Error 0.0011(0.0004) Steps 958(966.71) | Grad Norm 0.5684(0.5014) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 112.2616, Epoch Time 1444.7154(1424.7036), Bit/dim 3.4579(best: 3.4575), Xent 3.5105, Loss 5.2132, Error 0.3997(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20080 | Time 24.7406(23.9018) | Bit/dim 3.4211(3.4537) | Xent 0.0012(0.0024) | Loss 3.4217(3.4550) | Error 0.0000(0.0004) Steps 982(967.53) | Grad Norm 0.4140(0.4950) | Total Time 14.00(14.00)\n",
      "Iter 20090 | Time 24.3726(23.9252) | Bit/dim 3.4184(3.4533) | Xent 0.0015(0.0022) | Loss 3.4192(3.4544) | Error 0.0000(0.0003) Steps 964(967.08) | Grad Norm 0.5567(0.4847) | Total Time 14.00(14.00)\n",
      "Iter 20100 | Time 23.8174(23.9102) | Bit/dim 3.4696(3.4529) | Xent 0.0073(0.0024) | Loss 3.4732(3.4541) | Error 0.0022(0.0004) Steps 946(966.75) | Grad Norm 0.7039(0.4848) | Total Time 14.00(14.00)\n",
      "Iter 20110 | Time 23.2679(23.8560) | Bit/dim 3.4581(3.4531) | Xent 0.0031(0.0025) | Loss 3.4597(3.4543) | Error 0.0011(0.0005) Steps 958(967.89) | Grad Norm 0.5848(0.5077) | Total Time 14.00(14.00)\n",
      "Iter 20120 | Time 23.9386(23.9052) | Bit/dim 3.4479(3.4546) | Xent 0.0054(0.0026) | Loss 3.4506(3.4559) | Error 0.0011(0.0005) Steps 976(967.36) | Grad Norm 0.9877(0.5450) | Total Time 14.00(14.00)\n",
      "Iter 20130 | Time 23.7703(23.9302) | Bit/dim 3.4315(3.4561) | Xent 0.0023(0.0027) | Loss 3.4326(3.4575) | Error 0.0000(0.0005) Steps 952(965.89) | Grad Norm 0.7896(0.5950) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 113.2287, Epoch Time 1447.7233(1425.3942), Bit/dim 3.4600(best: 3.4575), Xent 3.5437, Loss 5.2319, Error 0.4049(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20140 | Time 23.2457(23.8940) | Bit/dim 3.4417(3.4549) | Xent 0.0018(0.0026) | Loss 3.4426(3.4562) | Error 0.0000(0.0005) Steps 964(967.12) | Grad Norm 0.5278(0.5932) | Total Time 14.00(14.00)\n",
      "Iter 20150 | Time 23.7418(23.9063) | Bit/dim 3.4760(3.4579) | Xent 0.0016(0.0026) | Loss 3.4768(3.4592) | Error 0.0000(0.0004) Steps 970(967.24) | Grad Norm 0.3156(0.5481) | Total Time 14.00(14.00)\n",
      "Iter 20160 | Time 23.4000(23.9258) | Bit/dim 3.4344(3.4563) | Xent 0.0019(0.0025) | Loss 3.4354(3.4575) | Error 0.0011(0.0004) Steps 940(968.43) | Grad Norm 0.5799(0.5377) | Total Time 14.00(14.00)\n",
      "Iter 20170 | Time 24.2786(23.9986) | Bit/dim 3.4561(3.4545) | Xent 0.0020(0.0024) | Loss 3.4571(3.4558) | Error 0.0000(0.0005) Steps 970(968.56) | Grad Norm 0.3827(0.5276) | Total Time 14.00(14.00)\n",
      "Iter 20180 | Time 23.6075(24.0176) | Bit/dim 3.4380(3.4539) | Xent 0.0020(0.0024) | Loss 3.4389(3.4551) | Error 0.0000(0.0004) Steps 970(969.16) | Grad Norm 0.4715(0.5173) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 113.7679, Epoch Time 1453.8803(1426.2488), Bit/dim 3.4574(best: 3.4575), Xent 3.5557, Loss 5.2353, Error 0.4031(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20190 | Time 24.0874(24.0264) | Bit/dim 3.4723(3.4552) | Xent 0.0014(0.0023) | Loss 3.4730(3.4564) | Error 0.0000(0.0004) Steps 970(969.17) | Grad Norm 0.3088(0.4851) | Total Time 14.00(14.00)\n",
      "Iter 20200 | Time 24.2468(24.0091) | Bit/dim 3.4630(3.4583) | Xent 0.0019(0.0024) | Loss 3.4640(3.4595) | Error 0.0000(0.0004) Steps 964(967.47) | Grad Norm 0.4797(0.5421) | Total Time 14.00(14.00)\n",
      "Iter 20210 | Time 24.2141(23.9723) | Bit/dim 3.4131(3.4554) | Xent 0.0033(0.0024) | Loss 3.4147(3.4566) | Error 0.0011(0.0004) Steps 970(966.98) | Grad Norm 0.5967(0.5378) | Total Time 14.00(14.00)\n",
      "Iter 20220 | Time 24.0655(23.9539) | Bit/dim 3.4521(3.4554) | Xent 0.0011(0.0023) | Loss 3.4526(3.4566) | Error 0.0000(0.0003) Steps 982(966.59) | Grad Norm 0.3646(0.5016) | Total Time 14.00(14.00)\n",
      "Iter 20230 | Time 23.7597(23.8868) | Bit/dim 3.4800(3.4525) | Xent 0.0011(0.0023) | Loss 3.4805(3.4536) | Error 0.0000(0.0003) Steps 964(965.44) | Grad Norm 0.3351(0.4806) | Total Time 14.00(14.00)\n",
      "Iter 20240 | Time 24.0586(23.8871) | Bit/dim 3.4376(3.4524) | Xent 0.0009(0.0023) | Loss 3.4380(3.4535) | Error 0.0000(0.0003) Steps 982(965.66) | Grad Norm 0.4403(0.4551) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 115.0933, Epoch Time 1445.4748(1426.8256), Bit/dim 3.4576(best: 3.4574), Xent 3.5501, Loss 5.2326, Error 0.3982(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20250 | Time 24.5723(23.9542) | Bit/dim 3.4884(3.4540) | Xent 0.0011(0.0021) | Loss 3.4890(3.4550) | Error 0.0000(0.0002) Steps 946(965.56) | Grad Norm 0.4415(0.4297) | Total Time 14.00(14.00)\n",
      "Iter 20260 | Time 22.8477(23.9209) | Bit/dim 3.4712(3.4526) | Xent 0.0019(0.0022) | Loss 3.4722(3.4537) | Error 0.0000(0.0003) Steps 958(965.99) | Grad Norm 0.3617(0.4286) | Total Time 14.00(14.00)\n",
      "Iter 20270 | Time 24.1227(23.9539) | Bit/dim 3.4487(3.4546) | Xent 0.0022(0.0022) | Loss 3.4498(3.4557) | Error 0.0000(0.0003) Steps 970(965.86) | Grad Norm 0.5220(0.4323) | Total Time 14.00(14.00)\n",
      "Iter 20280 | Time 23.9054(23.9108) | Bit/dim 3.4571(3.4534) | Xent 0.0013(0.0021) | Loss 3.4577(3.4545) | Error 0.0000(0.0003) Steps 964(966.71) | Grad Norm 0.3714(0.4436) | Total Time 14.00(14.00)\n",
      "Iter 20290 | Time 24.5050(23.9617) | Bit/dim 3.4486(3.4539) | Xent 0.0040(0.0021) | Loss 3.4506(3.4550) | Error 0.0000(0.0002) Steps 970(968.19) | Grad Norm 0.4341(0.4447) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 113.2249, Epoch Time 1450.4601(1427.5346), Bit/dim 3.4579(best: 3.4574), Xent 3.5922, Loss 5.2540, Error 0.4003(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20300 | Time 24.0083(23.9389) | Bit/dim 3.4430(3.4529) | Xent 0.0024(0.0022) | Loss 3.4442(3.4540) | Error 0.0000(0.0003) Steps 982(967.94) | Grad Norm 0.4486(0.4781) | Total Time 14.00(14.00)\n",
      "Iter 20310 | Time 24.5942(23.9388) | Bit/dim 3.4772(3.4536) | Xent 0.0010(0.0021) | Loss 3.4777(3.4547) | Error 0.0000(0.0002) Steps 952(966.56) | Grad Norm 0.3243(0.4906) | Total Time 14.00(14.00)\n",
      "Iter 20320 | Time 23.6998(23.9695) | Bit/dim 3.4465(3.4545) | Xent 0.0023(0.0022) | Loss 3.4476(3.4556) | Error 0.0000(0.0003) Steps 970(967.85) | Grad Norm 0.7629(0.5112) | Total Time 14.00(14.00)\n",
      "Iter 20330 | Time 24.3346(23.9207) | Bit/dim 3.4483(3.4526) | Xent 0.0033(0.0022) | Loss 3.4499(3.4537) | Error 0.0022(0.0003) Steps 982(967.49) | Grad Norm 0.6419(0.5193) | Total Time 14.00(14.00)\n",
      "Iter 20340 | Time 24.0133(23.9021) | Bit/dim 3.4891(3.4527) | Xent 0.0019(0.0021) | Loss 3.4901(3.4538) | Error 0.0000(0.0003) Steps 970(968.87) | Grad Norm 0.3822(0.4833) | Total Time 14.00(14.00)\n",
      "Iter 20350 | Time 23.6688(23.8865) | Bit/dim 3.4556(3.4539) | Xent 0.0019(0.0019) | Loss 3.4566(3.4548) | Error 0.0000(0.0002) Steps 946(966.05) | Grad Norm 0.4375(0.4446) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 113.3812, Epoch Time 1445.0103(1428.0589), Bit/dim 3.4573(best: 3.4574), Xent 3.6094, Loss 5.2621, Error 0.4085(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20360 | Time 23.5239(23.9395) | Bit/dim 3.4344(3.4518) | Xent 0.0019(0.0019) | Loss 3.4353(3.4527) | Error 0.0000(0.0002) Steps 958(966.78) | Grad Norm 0.4341(0.4249) | Total Time 14.00(14.00)\n",
      "Iter 20370 | Time 24.5451(23.9703) | Bit/dim 3.4492(3.4526) | Xent 0.0032(0.0021) | Loss 3.4508(3.4536) | Error 0.0011(0.0003) Steps 976(966.97) | Grad Norm 0.9651(0.4790) | Total Time 14.00(14.00)\n",
      "Iter 20380 | Time 23.8177(23.9640) | Bit/dim 3.4910(3.4545) | Xent 0.0021(0.0021) | Loss 3.4920(3.4556) | Error 0.0000(0.0003) Steps 952(965.42) | Grad Norm 0.6318(0.5282) | Total Time 14.00(14.00)\n",
      "Iter 20390 | Time 23.2658(23.9239) | Bit/dim 3.4563(3.4537) | Xent 0.0025(0.0021) | Loss 3.4576(3.4548) | Error 0.0000(0.0003) Steps 952(964.82) | Grad Norm 0.6676(0.5308) | Total Time 14.00(14.00)\n",
      "Iter 20400 | Time 24.0372(23.9558) | Bit/dim 3.4831(3.4525) | Xent 0.0024(0.0020) | Loss 3.4843(3.4536) | Error 0.0000(0.0002) Steps 964(968.24) | Grad Norm 0.4685(0.5187) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 112.7104, Epoch Time 1450.1477(1428.7215), Bit/dim 3.4570(best: 3.4573), Xent 3.5895, Loss 5.2517, Error 0.4040(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20410 | Time 23.5870(23.8959) | Bit/dim 3.4591(3.4528) | Xent 0.0012(0.0020) | Loss 3.4597(3.4538) | Error 0.0000(0.0002) Steps 976(967.43) | Grad Norm 0.2785(0.4784) | Total Time 14.00(14.00)\n",
      "Iter 20420 | Time 24.3233(23.8296) | Bit/dim 3.4662(3.4510) | Xent 0.0019(0.0020) | Loss 3.4671(3.4519) | Error 0.0000(0.0002) Steps 976(966.45) | Grad Norm 0.3651(0.4620) | Total Time 14.00(14.00)\n",
      "Iter 20430 | Time 23.6489(23.8400) | Bit/dim 3.4578(3.4521) | Xent 0.0016(0.0019) | Loss 3.4586(3.4531) | Error 0.0000(0.0002) Steps 952(965.51) | Grad Norm 0.2776(0.4512) | Total Time 14.00(14.00)\n",
      "Iter 20440 | Time 23.8982(23.8357) | Bit/dim 3.4693(3.4526) | Xent 0.0016(0.0019) | Loss 3.4701(3.4536) | Error 0.0000(0.0002) Steps 958(965.36) | Grad Norm 0.3742(0.4433) | Total Time 14.00(14.00)\n",
      "Iter 20450 | Time 24.0718(23.7962) | Bit/dim 3.4802(3.4549) | Xent 0.0016(0.0019) | Loss 3.4809(3.4558) | Error 0.0000(0.0001) Steps 964(965.25) | Grad Norm 0.2956(0.4359) | Total Time 14.00(14.00)\n",
      "Iter 20460 | Time 24.6840(23.8510) | Bit/dim 3.4288(3.4543) | Xent 0.0020(0.0020) | Loss 3.4298(3.4553) | Error 0.0000(0.0001) Steps 958(965.31) | Grad Norm 0.3434(0.4374) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 113.0867, Epoch Time 1438.8332(1429.0249), Bit/dim 3.4564(best: 3.4570), Xent 3.6037, Loss 5.2582, Error 0.4039(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20470 | Time 23.7602(23.8250) | Bit/dim 3.4476(3.4524) | Xent 0.0029(0.0021) | Loss 3.4490(3.4535) | Error 0.0000(0.0002) Steps 976(965.40) | Grad Norm 0.8936(0.4912) | Total Time 14.00(14.00)\n",
      "Iter 20480 | Time 23.8356(23.8639) | Bit/dim 3.4602(3.4518) | Xent 0.0018(0.0022) | Loss 3.4611(3.4529) | Error 0.0000(0.0002) Steps 964(965.02) | Grad Norm 0.6018(0.5278) | Total Time 14.00(14.00)\n",
      "Iter 20490 | Time 24.1795(23.8799) | Bit/dim 3.4531(3.4529) | Xent 0.0014(0.0022) | Loss 3.4537(3.4540) | Error 0.0000(0.0003) Steps 970(965.19) | Grad Norm 0.4603(0.5350) | Total Time 14.00(14.00)\n",
      "Iter 20500 | Time 24.1104(23.9334) | Bit/dim 3.4566(3.4540) | Xent 0.0007(0.0022) | Loss 3.4570(3.4551) | Error 0.0000(0.0002) Steps 964(965.83) | Grad Norm 0.5344(0.5347) | Total Time 14.00(14.00)\n",
      "Iter 20510 | Time 24.6786(23.9781) | Bit/dim 3.4491(3.4521) | Xent 0.0014(0.0020) | Loss 3.4498(3.4531) | Error 0.0000(0.0002) Steps 982(967.53) | Grad Norm 0.2968(0.4973) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 113.0738, Epoch Time 1450.1990(1429.6601), Bit/dim 3.4562(best: 3.4564), Xent 3.6376, Loss 5.2750, Error 0.4080(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20520 | Time 23.4305(24.0019) | Bit/dim 3.4153(3.4512) | Xent 0.0018(0.0021) | Loss 3.4162(3.4523) | Error 0.0000(0.0003) Steps 964(966.36) | Grad Norm 0.3643(0.4958) | Total Time 14.00(14.00)\n",
      "Iter 20530 | Time 23.6960(23.9383) | Bit/dim 3.4209(3.4526) | Xent 0.0016(0.0020) | Loss 3.4217(3.4536) | Error 0.0000(0.0003) Steps 982(967.81) | Grad Norm 0.2955(0.4567) | Total Time 14.00(14.00)\n",
      "Iter 20540 | Time 23.5996(23.9174) | Bit/dim 3.4595(3.4536) | Xent 0.0014(0.0025) | Loss 3.4602(3.4549) | Error 0.0000(0.0004) Steps 982(968.17) | Grad Norm 0.3746(0.4790) | Total Time 14.00(14.00)\n",
      "Iter 20550 | Time 24.6924(23.9534) | Bit/dim 3.4928(3.4559) | Xent 0.0038(0.0025) | Loss 3.4947(3.4572) | Error 0.0011(0.0004) Steps 988(968.22) | Grad Norm 0.4915(0.4725) | Total Time 14.00(14.00)\n",
      "Iter 20560 | Time 22.9752(23.8958) | Bit/dim 3.4637(3.4554) | Xent 0.0014(0.0025) | Loss 3.4644(3.4567) | Error 0.0000(0.0004) Steps 958(967.17) | Grad Norm 0.4115(0.4926) | Total Time 14.00(14.00)\n",
      "Iter 20570 | Time 24.4588(23.9250) | Bit/dim 3.4331(3.4517) | Xent 0.0013(0.0024) | Loss 3.4337(3.4529) | Error 0.0000(0.0004) Steps 964(966.71) | Grad Norm 0.5338(0.5059) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 112.3067, Epoch Time 1444.2677(1430.0983), Bit/dim 3.4571(best: 3.4562), Xent 3.6258, Loss 5.2700, Error 0.4048(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20580 | Time 23.3051(23.8929) | Bit/dim 3.4307(3.4527) | Xent 0.0016(0.0024) | Loss 3.4315(3.4539) | Error 0.0000(0.0004) Steps 964(966.03) | Grad Norm 0.6241(0.5267) | Total Time 14.00(14.00)\n",
      "Iter 20590 | Time 23.8565(23.8152) | Bit/dim 3.4439(3.4540) | Xent 0.0019(0.0024) | Loss 3.4448(3.4552) | Error 0.0000(0.0004) Steps 976(965.83) | Grad Norm 0.5699(0.5401) | Total Time 14.00(14.00)\n",
      "Iter 20600 | Time 24.1286(23.8641) | Bit/dim 3.4461(3.4530) | Xent 0.0019(0.0025) | Loss 3.4470(3.4542) | Error 0.0000(0.0005) Steps 940(964.30) | Grad Norm 0.7771(0.5773) | Total Time 14.00(14.00)\n",
      "Iter 20610 | Time 24.2307(23.8818) | Bit/dim 3.3928(3.4495) | Xent 0.0019(0.0023) | Loss 3.3938(3.4506) | Error 0.0000(0.0004) Steps 982(964.21) | Grad Norm 0.3420(0.5380) | Total Time 14.00(14.00)\n",
      "Iter 20620 | Time 23.9391(23.9353) | Bit/dim 3.4676(3.4500) | Xent 0.0015(0.0022) | Loss 3.4683(3.4511) | Error 0.0000(0.0003) Steps 952(963.54) | Grad Norm 0.3919(0.5112) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 112.7991, Epoch Time 1445.7839(1430.5689), Bit/dim 3.4583(best: 3.4562), Xent 3.6563, Loss 5.2864, Error 0.4018(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20630 | Time 23.9324(23.9552) | Bit/dim 3.4731(3.4541) | Xent 0.0037(0.0023) | Loss 3.4750(3.4552) | Error 0.0011(0.0004) Steps 946(962.93) | Grad Norm 0.5286(0.5456) | Total Time 14.00(14.00)\n",
      "Iter 20640 | Time 23.2390(23.8744) | Bit/dim 3.4404(3.4523) | Xent 0.0022(0.0022) | Loss 3.4415(3.4534) | Error 0.0000(0.0003) Steps 952(963.46) | Grad Norm 0.6513(0.5568) | Total Time 14.00(14.00)\n",
      "Iter 20650 | Time 23.5183(23.8788) | Bit/dim 3.4556(3.4559) | Xent 0.0031(0.0023) | Loss 3.4571(3.4571) | Error 0.0011(0.0004) Steps 958(963.68) | Grad Norm 0.5758(0.5642) | Total Time 14.00(14.00)\n",
      "Iter 20660 | Time 24.1238(23.8399) | Bit/dim 3.4373(3.4534) | Xent 0.0016(0.0024) | Loss 3.4381(3.4546) | Error 0.0000(0.0004) Steps 982(962.80) | Grad Norm 0.3409(0.5382) | Total Time 14.00(14.00)\n",
      "Iter 20670 | Time 23.4688(23.7607) | Bit/dim 3.4264(3.4525) | Xent 0.0020(0.0026) | Loss 3.4274(3.4537) | Error 0.0000(0.0004) Steps 952(964.15) | Grad Norm 0.7472(0.5610) | Total Time 14.00(14.00)\n",
      "Iter 20680 | Time 23.6266(23.7962) | Bit/dim 3.4336(3.4508) | Xent 0.0019(0.0025) | Loss 3.4345(3.4520) | Error 0.0000(0.0004) Steps 952(964.54) | Grad Norm 0.4203(0.6041) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 112.7844, Epoch Time 1437.5496(1430.7783), Bit/dim 3.4577(best: 3.4562), Xent 3.6750, Loss 5.2952, Error 0.4021(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20690 | Time 23.7391(23.7896) | Bit/dim 3.4562(3.4491) | Xent 0.0031(0.0027) | Loss 3.4577(3.4504) | Error 0.0000(0.0005) Steps 964(964.02) | Grad Norm 0.5914(0.7210) | Total Time 14.00(14.00)\n",
      "Iter 20700 | Time 24.2084(23.8845) | Bit/dim 3.4422(3.4496) | Xent 0.0042(0.0025) | Loss 3.4443(3.4509) | Error 0.0022(0.0005) Steps 958(965.54) | Grad Norm 0.5042(0.7196) | Total Time 14.00(14.00)\n",
      "Iter 20710 | Time 23.5474(23.8865) | Bit/dim 3.4739(3.4507) | Xent 0.0023(0.0028) | Loss 3.4750(3.4521) | Error 0.0011(0.0005) Steps 952(966.19) | Grad Norm 0.6165(0.7836) | Total Time 14.00(14.00)\n",
      "Iter 20720 | Time 23.1220(23.8356) | Bit/dim 3.5061(3.4545) | Xent 0.0021(0.0028) | Loss 3.5071(3.4559) | Error 0.0011(0.0006) Steps 964(964.09) | Grad Norm 0.6334(0.7378) | Total Time 14.00(14.00)\n",
      "Iter 20730 | Time 23.4776(23.8109) | Bit/dim 3.4448(3.4553) | Xent 0.0015(0.0026) | Loss 3.4455(3.4566) | Error 0.0000(0.0005) Steps 958(962.80) | Grad Norm 0.6342(0.6829) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 113.0994, Epoch Time 1442.1556(1431.1196), Bit/dim 3.4560(best: 3.4562), Xent 3.6763, Loss 5.2941, Error 0.4055(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20740 | Time 23.9263(23.7916) | Bit/dim 3.4695(3.4540) | Xent 0.0009(0.0024) | Loss 3.4700(3.4552) | Error 0.0000(0.0005) Steps 982(962.88) | Grad Norm 0.4947(0.6135) | Total Time 14.00(14.00)\n",
      "Iter 20750 | Time 23.8474(23.7464) | Bit/dim 3.4710(3.4532) | Xent 0.0034(0.0023) | Loss 3.4727(3.4544) | Error 0.0011(0.0004) Steps 964(962.84) | Grad Norm 0.7912(0.5852) | Total Time 14.00(14.00)\n",
      "Iter 20760 | Time 23.7854(23.7472) | Bit/dim 3.4255(3.4511) | Xent 0.0014(0.0023) | Loss 3.4262(3.4523) | Error 0.0000(0.0004) Steps 952(961.02) | Grad Norm 0.4083(0.5485) | Total Time 14.00(14.00)\n",
      "Iter 20770 | Time 23.5558(23.7697) | Bit/dim 3.4852(3.4516) | Xent 0.0012(0.0024) | Loss 3.4858(3.4528) | Error 0.0000(0.0004) Steps 976(962.12) | Grad Norm 0.4824(0.6206) | Total Time 14.00(14.00)\n",
      "Iter 20780 | Time 24.0694(23.8039) | Bit/dim 3.4870(3.4544) | Xent 0.0020(0.0023) | Loss 3.4880(3.4556) | Error 0.0000(0.0004) Steps 970(963.47) | Grad Norm 0.7484(0.6321) | Total Time 14.00(14.00)\n",
      "Iter 20790 | Time 24.0038(23.7880) | Bit/dim 3.4517(3.4537) | Xent 0.0018(0.0023) | Loss 3.4526(3.4548) | Error 0.0000(0.0005) Steps 970(963.11) | Grad Norm 0.5307(0.6039) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 114.0887, Epoch Time 1439.6679(1431.3761), Bit/dim 3.4562(best: 3.4560), Xent 3.6366, Loss 5.2745, Error 0.3991(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20800 | Time 23.7867(23.7583) | Bit/dim 3.4390(3.4546) | Xent 0.0022(0.0024) | Loss 3.4401(3.4558) | Error 0.0000(0.0005) Steps 976(964.09) | Grad Norm 0.8473(0.6665) | Total Time 14.00(14.00)\n",
      "Iter 20810 | Time 23.5522(23.8135) | Bit/dim 3.4283(3.4527) | Xent 0.0028(0.0023) | Loss 3.4297(3.4539) | Error 0.0000(0.0004) Steps 946(964.71) | Grad Norm 0.7413(0.6684) | Total Time 14.00(14.00)\n",
      "Iter 20820 | Time 23.4656(23.7917) | Bit/dim 3.4553(3.4540) | Xent 0.0015(0.0023) | Loss 3.4560(3.4552) | Error 0.0000(0.0004) Steps 970(963.39) | Grad Norm 0.4511(0.6480) | Total Time 14.00(14.00)\n",
      "Iter 20830 | Time 23.7233(23.8114) | Bit/dim 3.4686(3.4526) | Xent 0.0011(0.0023) | Loss 3.4692(3.4537) | Error 0.0000(0.0005) Steps 952(962.48) | Grad Norm 0.5925(0.6395) | Total Time 14.00(14.00)\n",
      "Iter 20840 | Time 23.4526(23.8653) | Bit/dim 3.4542(3.4536) | Xent 0.0058(0.0025) | Loss 3.4572(3.4549) | Error 0.0011(0.0005) Steps 958(962.86) | Grad Norm 0.5372(0.6415) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 113.5614, Epoch Time 1443.8821(1431.7513), Bit/dim 3.4569(best: 3.4560), Xent 3.6554, Loss 5.2846, Error 0.4040(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20850 | Time 23.2065(23.8504) | Bit/dim 3.4529(3.4527) | Xent 0.0021(0.0024) | Loss 3.4539(3.4539) | Error 0.0000(0.0004) Steps 952(962.16) | Grad Norm 0.3607(0.6337) | Total Time 14.00(14.00)\n",
      "Iter 20860 | Time 23.7774(23.9138) | Bit/dim 3.4502(3.4516) | Xent 0.0013(0.0023) | Loss 3.4508(3.4528) | Error 0.0000(0.0004) Steps 964(962.45) | Grad Norm 0.9531(0.6513) | Total Time 14.00(14.00)\n",
      "Iter 20870 | Time 23.5884(23.8973) | Bit/dim 3.4456(3.4519) | Xent 0.0013(0.0022) | Loss 3.4463(3.4530) | Error 0.0000(0.0003) Steps 976(962.97) | Grad Norm 0.6028(0.6588) | Total Time 14.00(14.00)\n",
      "Iter 20880 | Time 23.1395(23.8951) | Bit/dim 3.4327(3.4531) | Xent 0.0012(0.0022) | Loss 3.4333(3.4542) | Error 0.0000(0.0004) Steps 958(962.91) | Grad Norm 0.5593(0.6367) | Total Time 14.00(14.00)\n",
      "Iter 20890 | Time 23.6746(23.8901) | Bit/dim 3.4088(3.4507) | Xent 0.0030(0.0023) | Loss 3.4103(3.4518) | Error 0.0000(0.0004) Steps 952(960.38) | Grad Norm 0.8621(0.6453) | Total Time 14.00(14.00)\n",
      "Iter 20900 | Time 24.3622(23.8912) | Bit/dim 3.4393(3.4516) | Xent 0.0033(0.0023) | Loss 3.4410(3.4528) | Error 0.0011(0.0004) Steps 964(959.35) | Grad Norm 0.6864(0.6566) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 113.1148, Epoch Time 1446.2713(1432.1869), Bit/dim 3.4571(best: 3.4560), Xent 3.6561, Loss 5.2851, Error 0.4007(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20910 | Time 23.1769(23.8716) | Bit/dim 3.4174(3.4535) | Xent 0.0018(0.0026) | Loss 3.4183(3.4547) | Error 0.0000(0.0005) Steps 940(959.82) | Grad Norm 0.7835(0.6963) | Total Time 14.00(14.00)\n",
      "Iter 20920 | Time 23.6265(23.8497) | Bit/dim 3.4838(3.4511) | Xent 0.0010(0.0027) | Loss 3.4843(3.4524) | Error 0.0000(0.0005) Steps 952(959.70) | Grad Norm 0.4645(0.6983) | Total Time 14.00(14.00)\n",
      "Iter 20930 | Time 23.9673(23.8586) | Bit/dim 3.4651(3.4550) | Xent 0.0052(0.0028) | Loss 3.4677(3.4563) | Error 0.0022(0.0006) Steps 976(960.63) | Grad Norm 1.5704(0.7575) | Total Time 14.00(14.00)\n",
      "Iter 20940 | Time 23.9095(23.8847) | Bit/dim 3.4404(3.4555) | Xent 0.0016(0.0027) | Loss 3.4412(3.4568) | Error 0.0000(0.0005) Steps 976(962.49) | Grad Norm 0.6275(0.7530) | Total Time 14.00(14.00)\n",
      "Iter 20950 | Time 24.3265(23.8675) | Bit/dim 3.4424(3.4523) | Xent 0.0012(0.0025) | Loss 3.4430(3.4536) | Error 0.0000(0.0004) Steps 964(962.71) | Grad Norm 0.3914(0.6860) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 113.3725, Epoch Time 1443.1332(1432.5153), Bit/dim 3.4563(best: 3.4560), Xent 3.6811, Loss 5.2968, Error 0.4047(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20960 | Time 23.9422(23.8740) | Bit/dim 3.4574(3.4505) | Xent 0.0041(0.0025) | Loss 3.4595(3.4518) | Error 0.0011(0.0004) Steps 958(962.63) | Grad Norm 0.6327(0.6530) | Total Time 14.00(14.00)\n",
      "Iter 20970 | Time 23.8021(23.8790) | Bit/dim 3.4430(3.4496) | Xent 0.0011(0.0024) | Loss 3.4436(3.4508) | Error 0.0000(0.0004) Steps 946(965.16) | Grad Norm 0.3792(0.6297) | Total Time 14.00(14.00)\n",
      "Iter 20980 | Time 23.7036(23.8586) | Bit/dim 3.4491(3.4499) | Xent 0.0025(0.0022) | Loss 3.4504(3.4510) | Error 0.0011(0.0004) Steps 958(964.24) | Grad Norm 0.4309(0.5648) | Total Time 14.00(14.00)\n",
      "Iter 20990 | Time 24.0753(23.8585) | Bit/dim 3.4387(3.4502) | Xent 0.0023(0.0021) | Loss 3.4399(3.4513) | Error 0.0000(0.0003) Steps 964(964.87) | Grad Norm 0.5507(0.5571) | Total Time 14.00(14.00)\n",
      "Iter 21000 | Time 23.7432(23.8541) | Bit/dim 3.4385(3.4523) | Xent 0.0013(0.0020) | Loss 3.4391(3.4533) | Error 0.0000(0.0003) Steps 964(963.53) | Grad Norm 0.7530(0.5704) | Total Time 14.00(14.00)\n",
      "Iter 21010 | Time 24.1682(23.8373) | Bit/dim 3.4622(3.4524) | Xent 0.0017(0.0022) | Loss 3.4631(3.4535) | Error 0.0000(0.0003) Steps 970(962.98) | Grad Norm 0.4236(0.5908) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 112.6815, Epoch Time 1441.8777(1432.7961), Bit/dim 3.4557(best: 3.4560), Xent 3.6941, Loss 5.3028, Error 0.4053(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21020 | Time 23.5983(23.8493) | Bit/dim 3.4655(3.4529) | Xent 0.0013(0.0020) | Loss 3.4662(3.4539) | Error 0.0000(0.0003) Steps 934(961.53) | Grad Norm 0.4204(0.5472) | Total Time 14.00(14.00)\n",
      "Iter 21030 | Time 24.7756(23.8678) | Bit/dim 3.4132(3.4503) | Xent 0.0018(0.0020) | Loss 3.4141(3.4513) | Error 0.0000(0.0003) Steps 982(961.36) | Grad Norm 0.2920(0.5141) | Total Time 14.00(14.00)\n",
      "Iter 21040 | Time 23.8919(23.8715) | Bit/dim 3.4543(3.4505) | Xent 0.0011(0.0020) | Loss 3.4549(3.4515) | Error 0.0000(0.0003) Steps 964(962.07) | Grad Norm 0.5136(0.5154) | Total Time 14.00(14.00)\n",
      "Iter 21050 | Time 24.4370(23.9045) | Bit/dim 3.4527(3.4531) | Xent 0.0011(0.0020) | Loss 3.4532(3.4541) | Error 0.0000(0.0003) Steps 976(962.15) | Grad Norm 0.4274(0.5089) | Total Time 14.00(14.00)\n",
      "Iter 21060 | Time 24.2561(23.8815) | Bit/dim 3.4518(3.4519) | Xent 0.0012(0.0019) | Loss 3.4524(3.4528) | Error 0.0000(0.0002) Steps 982(962.70) | Grad Norm 0.6044(0.5291) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 113.3529, Epoch Time 1446.4318(1433.2052), Bit/dim 3.4560(best: 3.4557), Xent 3.7260, Loss 5.3190, Error 0.4063(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21070 | Time 23.6091(23.8692) | Bit/dim 3.4795(3.4546) | Xent 0.0011(0.0019) | Loss 3.4801(3.4555) | Error 0.0000(0.0003) Steps 946(962.31) | Grad Norm 0.4643(0.5619) | Total Time 14.00(14.00)\n",
      "Iter 21080 | Time 23.7636(23.8031) | Bit/dim 3.4363(3.4552) | Xent 0.0022(0.0021) | Loss 3.4374(3.4562) | Error 0.0000(0.0003) Steps 976(963.45) | Grad Norm 1.0994(0.6869) | Total Time 14.00(14.00)\n",
      "Iter 21090 | Time 22.9662(23.8082) | Bit/dim 3.4314(3.4527) | Xent 0.0029(0.0024) | Loss 3.4328(3.4539) | Error 0.0000(0.0005) Steps 964(962.76) | Grad Norm 1.0099(0.8070) | Total Time 14.00(14.00)\n",
      "Iter 21100 | Time 24.2346(23.7887) | Bit/dim 3.4335(3.4512) | Xent 0.0013(0.0023) | Loss 3.4341(3.4523) | Error 0.0000(0.0005) Steps 964(963.29) | Grad Norm 0.7665(0.8057) | Total Time 14.00(14.00)\n",
      "Iter 21110 | Time 23.9160(23.8126) | Bit/dim 3.4240(3.4504) | Xent 0.0043(0.0023) | Loss 3.4261(3.4515) | Error 0.0011(0.0005) Steps 964(962.38) | Grad Norm 0.7965(0.7623) | Total Time 14.00(14.00)\n",
      "Iter 21120 | Time 24.0423(23.7904) | Bit/dim 3.4675(3.4504) | Xent 0.0060(0.0025) | Loss 3.4705(3.4517) | Error 0.0022(0.0005) Steps 976(964.29) | Grad Norm 0.5464(0.7075) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 114.2073, Epoch Time 1438.4485(1433.3625), Bit/dim 3.4561(best: 3.4557), Xent 3.7167, Loss 5.3145, Error 0.4027(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21130 | Time 24.3604(23.8543) | Bit/dim 3.4334(3.4497) | Xent 0.0021(0.0023) | Loss 3.4344(3.4509) | Error 0.0000(0.0004) Steps 964(965.37) | Grad Norm 0.3755(0.6547) | Total Time 14.00(14.00)\n",
      "Iter 21140 | Time 24.7051(23.9506) | Bit/dim 3.4311(3.4496) | Xent 0.0017(0.0022) | Loss 3.4320(3.4507) | Error 0.0000(0.0004) Steps 964(964.02) | Grad Norm 0.4365(0.6152) | Total Time 14.00(14.00)\n",
      "Iter 21150 | Time 23.7295(23.9871) | Bit/dim 3.5052(3.4520) | Xent 0.0013(0.0021) | Loss 3.5059(3.4530) | Error 0.0000(0.0003) Steps 958(964.56) | Grad Norm 0.2624(0.5734) | Total Time 14.00(14.00)\n",
      "Iter 21160 | Time 23.2592(23.9103) | Bit/dim 3.4440(3.4502) | Xent 0.0015(0.0021) | Loss 3.4448(3.4513) | Error 0.0000(0.0003) Steps 976(962.70) | Grad Norm 0.4698(0.5727) | Total Time 14.00(14.00)\n",
      "Iter 21170 | Time 24.3645(23.9776) | Bit/dim 3.4375(3.4508) | Xent 0.0016(0.0023) | Loss 3.4383(3.4519) | Error 0.0011(0.0005) Steps 946(963.03) | Grad Norm 0.6750(0.5926) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 115.3553, Epoch Time 1454.3640(1433.9925), Bit/dim 3.4554(best: 3.4557), Xent 3.7158, Loss 5.3133, Error 0.4012(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21180 | Time 23.7179(23.9785) | Bit/dim 3.4855(3.4503) | Xent 0.0016(0.0021) | Loss 3.4863(3.4514) | Error 0.0000(0.0004) Steps 964(964.57) | Grad Norm 0.3196(0.5656) | Total Time 14.00(14.00)\n",
      "Iter 21190 | Time 24.6272(23.9559) | Bit/dim 3.4658(3.4501) | Xent 0.0021(0.0023) | Loss 3.4669(3.4513) | Error 0.0000(0.0005) Steps 988(965.68) | Grad Norm 0.9340(0.6423) | Total Time 14.00(14.00)\n",
      "Iter 21200 | Time 23.4754(23.9320) | Bit/dim 3.5007(3.4512) | Xent 0.0061(0.0025) | Loss 3.5038(3.4524) | Error 0.0011(0.0005) Steps 958(966.35) | Grad Norm 0.7323(0.6799) | Total Time 14.00(14.00)\n",
      "Iter 21210 | Time 23.7156(23.9381) | Bit/dim 3.4500(3.4509) | Xent 0.0043(0.0025) | Loss 3.4521(3.4521) | Error 0.0011(0.0005) Steps 976(966.13) | Grad Norm 0.8739(0.6409) | Total Time 14.00(14.00)\n",
      "Iter 21220 | Time 23.8668(23.9152) | Bit/dim 3.4644(3.4511) | Xent 0.0014(0.0024) | Loss 3.4652(3.4523) | Error 0.0000(0.0005) Steps 958(965.70) | Grad Norm 0.3956(0.5979) | Total Time 14.00(14.00)\n",
      "Iter 21230 | Time 23.6166(23.8880) | Bit/dim 3.4903(3.4524) | Xent 0.0013(0.0025) | Loss 3.4909(3.4537) | Error 0.0000(0.0005) Steps 952(965.09) | Grad Norm 0.3011(0.6127) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 112.4206, Epoch Time 1445.0892(1434.3254), Bit/dim 3.4557(best: 3.4554), Xent 3.7888, Loss 5.3501, Error 0.4078(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21240 | Time 23.1790(23.8711) | Bit/dim 3.4411(3.4522) | Xent 0.0018(0.0025) | Loss 3.4420(3.4535) | Error 0.0000(0.0005) Steps 970(964.84) | Grad Norm 0.8135(0.6812) | Total Time 14.00(14.00)\n",
      "Iter 21250 | Time 23.4902(23.8779) | Bit/dim 3.4400(3.4519) | Xent 0.0037(0.0024) | Loss 3.4418(3.4531) | Error 0.0022(0.0005) Steps 958(964.57) | Grad Norm 0.8274(0.6726) | Total Time 14.00(14.00)\n",
      "Iter 21260 | Time 23.5161(23.8115) | Bit/dim 3.4677(3.4515) | Xent 0.0011(0.0025) | Loss 3.4682(3.4527) | Error 0.0000(0.0005) Steps 964(964.87) | Grad Norm 0.4246(0.6772) | Total Time 14.00(14.00)\n",
      "Iter 21270 | Time 23.9411(23.8575) | Bit/dim 3.4603(3.4531) | Xent 0.0017(0.0023) | Loss 3.4611(3.4542) | Error 0.0000(0.0004) Steps 982(964.54) | Grad Norm 0.7285(0.6561) | Total Time 14.00(14.00)\n",
      "Iter 21280 | Time 23.2721(23.8998) | Bit/dim 3.4376(3.4511) | Xent 0.0062(0.0022) | Loss 3.4407(3.4522) | Error 0.0011(0.0003) Steps 958(963.38) | Grad Norm 1.1476(0.6201) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 113.3331, Epoch Time 1444.2800(1434.6241), Bit/dim 3.4550(best: 3.4554), Xent 3.7106, Loss 5.3103, Error 0.4044(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21290 | Time 23.6320(23.8760) | Bit/dim 3.4751(3.4506) | Xent 0.0036(0.0023) | Loss 3.4769(3.4518) | Error 0.0022(0.0004) Steps 958(962.43) | Grad Norm 0.6360(0.5868) | Total Time 14.00(14.00)\n",
      "Iter 21300 | Time 23.8522(23.8745) | Bit/dim 3.4664(3.4526) | Xent 0.0018(0.0022) | Loss 3.4673(3.4537) | Error 0.0000(0.0003) Steps 946(961.09) | Grad Norm 0.4591(0.6103) | Total Time 14.00(14.00)\n",
      "Iter 21310 | Time 24.2132(23.8322) | Bit/dim 3.4744(3.4538) | Xent 0.0016(0.0023) | Loss 3.4752(3.4549) | Error 0.0000(0.0003) Steps 982(962.05) | Grad Norm 0.4628(0.6223) | Total Time 14.00(14.00)\n",
      "Iter 21320 | Time 23.6357(23.8552) | Bit/dim 3.4537(3.4533) | Xent 0.0016(0.0022) | Loss 3.4545(3.4544) | Error 0.0000(0.0003) Steps 958(962.30) | Grad Norm 0.5642(0.6018) | Total Time 14.00(14.00)\n",
      "Iter 21330 | Time 24.4001(23.8718) | Bit/dim 3.4444(3.4502) | Xent 0.0052(0.0021) | Loss 3.4470(3.4512) | Error 0.0022(0.0003) Steps 970(962.10) | Grad Norm 0.5971(0.5732) | Total Time 14.00(14.00)\n",
      "Iter 21340 | Time 23.4045(23.8165) | Bit/dim 3.4739(3.4487) | Xent 0.0056(0.0023) | Loss 3.4767(3.4498) | Error 0.0033(0.0004) Steps 946(961.11) | Grad Norm 1.0122(0.5597) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 113.3046, Epoch Time 1441.4423(1434.8286), Bit/dim 3.4541(best: 3.4550), Xent 3.7265, Loss 5.3174, Error 0.4067(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21350 | Time 23.6163(23.8235) | Bit/dim 3.4680(3.4493) | Xent 0.0023(0.0023) | Loss 3.4692(3.4505) | Error 0.0000(0.0003) Steps 976(961.97) | Grad Norm 0.4011(0.5541) | Total Time 14.00(14.00)\n",
      "Iter 21360 | Time 24.0479(23.8413) | Bit/dim 3.3842(3.4502) | Xent 0.0043(0.0024) | Loss 3.3864(3.4514) | Error 0.0022(0.0004) Steps 988(961.35) | Grad Norm 0.6521(0.5793) | Total Time 14.00(14.00)\n",
      "Iter 21370 | Time 23.9471(23.9017) | Bit/dim 3.4599(3.4519) | Xent 0.0037(0.0024) | Loss 3.4618(3.4531) | Error 0.0011(0.0004) Steps 970(962.39) | Grad Norm 0.5754(0.5428) | Total Time 14.00(14.00)\n",
      "Iter 21380 | Time 23.7388(23.8889) | Bit/dim 3.4491(3.4495) | Xent 0.0012(0.0024) | Loss 3.4497(3.4507) | Error 0.0000(0.0005) Steps 964(962.13) | Grad Norm 0.4234(0.5669) | Total Time 14.00(14.00)\n",
      "Iter 21390 | Time 23.8245(23.9275) | Bit/dim 3.4534(3.4504) | Xent 0.0009(0.0023) | Loss 3.4538(3.4515) | Error 0.0000(0.0005) Steps 964(961.07) | Grad Norm 0.3900(0.5374) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 111.7403, Epoch Time 1446.2181(1435.1703), Bit/dim 3.4556(best: 3.4541), Xent 3.7386, Loss 5.3249, Error 0.4080(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21400 | Time 24.5403(23.9180) | Bit/dim 3.4951(3.4480) | Xent 0.0030(0.0023) | Loss 3.4966(3.4491) | Error 0.0011(0.0005) Steps 958(961.14) | Grad Norm 0.6551(0.5664) | Total Time 14.00(14.00)\n",
      "Iter 21410 | Time 23.5628(23.8149) | Bit/dim 3.4603(3.4484) | Xent 0.0036(0.0023) | Loss 3.4621(3.4496) | Error 0.0011(0.0005) Steps 958(961.56) | Grad Norm 0.6299(0.5468) | Total Time 14.00(14.00)\n",
      "Iter 21420 | Time 24.0329(23.8298) | Bit/dim 3.4691(3.4487) | Xent 0.0008(0.0021) | Loss 3.4695(3.4498) | Error 0.0000(0.0004) Steps 970(962.35) | Grad Norm 0.3132(0.5208) | Total Time 14.00(14.00)\n",
      "Iter 21430 | Time 24.2796(23.7711) | Bit/dim 3.4452(3.4501) | Xent 0.0014(0.0021) | Loss 3.4459(3.4511) | Error 0.0000(0.0004) Steps 970(960.70) | Grad Norm 0.6527(0.5382) | Total Time 14.00(14.00)\n",
      "Iter 21440 | Time 24.2984(23.7928) | Bit/dim 3.4281(3.4501) | Xent 0.0011(0.0021) | Loss 3.4287(3.4511) | Error 0.0000(0.0003) Steps 964(961.33) | Grad Norm 0.2931(0.5012) | Total Time 14.00(14.00)\n",
      "Iter 21450 | Time 24.2145(23.7937) | Bit/dim 3.4747(3.4527) | Xent 0.0017(0.0022) | Loss 3.4756(3.4539) | Error 0.0000(0.0004) Steps 970(960.05) | Grad Norm 0.3285(0.5017) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 113.1902, Epoch Time 1436.8036(1435.2193), Bit/dim 3.4551(best: 3.4541), Xent 3.7765, Loss 5.3433, Error 0.4072(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21460 | Time 23.9449(23.8272) | Bit/dim 3.4269(3.4510) | Xent 0.0019(0.0021) | Loss 3.4278(3.4521) | Error 0.0000(0.0004) Steps 958(960.53) | Grad Norm 0.5060(0.4789) | Total Time 14.00(14.00)\n",
      "Iter 21470 | Time 24.6944(23.9053) | Bit/dim 3.4702(3.4486) | Xent 0.0014(0.0020) | Loss 3.4709(3.4496) | Error 0.0000(0.0003) Steps 976(962.90) | Grad Norm 0.2717(0.4582) | Total Time 14.00(14.00)\n",
      "Iter 21480 | Time 23.5893(23.8692) | Bit/dim 3.4585(3.4500) | Xent 0.0020(0.0020) | Loss 3.4595(3.4510) | Error 0.0000(0.0002) Steps 970(964.13) | Grad Norm 0.3994(0.4565) | Total Time 14.00(14.00)\n",
      "Iter 21490 | Time 23.5792(23.8435) | Bit/dim 3.4526(3.4512) | Xent 0.0021(0.0021) | Loss 3.4536(3.4522) | Error 0.0000(0.0003) Steps 970(963.37) | Grad Norm 0.3494(0.4783) | Total Time 14.00(14.00)\n",
      "Iter 21500 | Time 23.6258(23.8660) | Bit/dim 3.4669(3.4517) | Xent 0.0041(0.0022) | Loss 3.4690(3.4527) | Error 0.0022(0.0003) Steps 958(961.97) | Grad Norm 0.5695(0.4779) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 113.4358, Epoch Time 1446.8332(1435.5677), Bit/dim 3.4543(best: 3.4541), Xent 3.7702, Loss 5.3394, Error 0.4032(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21510 | Time 24.4195(23.9315) | Bit/dim 3.5033(3.4549) | Xent 0.0025(0.0022) | Loss 3.5045(3.4560) | Error 0.0011(0.0003) Steps 958(960.91) | Grad Norm 0.5914(0.4909) | Total Time 14.00(14.00)\n",
      "Iter 21520 | Time 23.6107(23.9103) | Bit/dim 3.4531(3.4529) | Xent 0.0015(0.0022) | Loss 3.4539(3.4540) | Error 0.0000(0.0004) Steps 940(959.83) | Grad Norm 0.7070(0.5152) | Total Time 14.00(14.00)\n",
      "Iter 21530 | Time 24.2019(23.9055) | Bit/dim 3.4114(3.4496) | Xent 0.0021(0.0022) | Loss 3.4124(3.4507) | Error 0.0000(0.0004) Steps 946(959.92) | Grad Norm 0.6045(0.5475) | Total Time 14.00(14.00)\n",
      "Iter 21540 | Time 23.7031(23.9054) | Bit/dim 3.4506(3.4485) | Xent 0.0032(0.0024) | Loss 3.4523(3.4497) | Error 0.0011(0.0004) Steps 958(960.28) | Grad Norm 0.8623(0.5975) | Total Time 14.00(14.00)\n",
      "Iter 21550 | Time 24.0953(23.9048) | Bit/dim 3.4553(3.4500) | Xent 0.0032(0.0025) | Loss 3.4569(3.4512) | Error 0.0011(0.0004) Steps 946(960.76) | Grad Norm 0.6633(0.6124) | Total Time 14.00(14.00)\n",
      "Iter 21560 | Time 24.2070(23.8984) | Bit/dim 3.4593(3.4518) | Xent 0.0021(0.0023) | Loss 3.4603(3.4529) | Error 0.0000(0.0003) Steps 946(960.08) | Grad Norm 0.3923(0.5812) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 113.2127, Epoch Time 1446.1743(1435.8859), Bit/dim 3.4543(best: 3.4541), Xent 3.7753, Loss 5.3419, Error 0.4011(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21570 | Time 23.6290(23.8294) | Bit/dim 3.4679(3.4511) | Xent 0.0020(0.0021) | Loss 3.4689(3.4521) | Error 0.0000(0.0003) Steps 964(960.04) | Grad Norm 0.3859(0.5293) | Total Time 14.00(14.00)\n",
      "Iter 21580 | Time 24.0744(23.8438) | Bit/dim 3.4365(3.4499) | Xent 0.0036(0.0022) | Loss 3.4383(3.4510) | Error 0.0011(0.0004) Steps 982(962.26) | Grad Norm 0.5181(0.5218) | Total Time 14.00(14.00)\n",
      "Iter 21590 | Time 24.1769(23.9009) | Bit/dim 3.4562(3.4514) | Xent 0.0026(0.0024) | Loss 3.4575(3.4526) | Error 0.0011(0.0005) Steps 982(962.02) | Grad Norm 0.6321(0.6111) | Total Time 14.00(14.00)\n",
      "Iter 21600 | Time 23.2381(23.8391) | Bit/dim 3.4572(3.4527) | Xent 0.0009(0.0023) | Loss 3.4576(3.4539) | Error 0.0000(0.0005) Steps 958(961.50) | Grad Norm 0.5104(0.6026) | Total Time 14.00(14.00)\n",
      "Iter 21610 | Time 23.5325(23.8070) | Bit/dim 3.4480(3.4517) | Xent 0.0016(0.0023) | Loss 3.4488(3.4529) | Error 0.0000(0.0004) Steps 976(962.85) | Grad Norm 0.4512(0.5745) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 112.6736, Epoch Time 1438.1376(1435.9535), Bit/dim 3.4534(best: 3.4541), Xent 3.7789, Loss 5.3429, Error 0.4045(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21620 | Time 23.6509(23.7990) | Bit/dim 3.4178(3.4476) | Xent 0.0012(0.0021) | Loss 3.4184(3.4487) | Error 0.0000(0.0004) Steps 952(961.34) | Grad Norm 0.2954(0.5325) | Total Time 14.00(14.00)\n",
      "Iter 21630 | Time 23.4324(23.7645) | Bit/dim 3.4220(3.4480) | Xent 0.0017(0.0021) | Loss 3.4229(3.4491) | Error 0.0000(0.0003) Steps 946(959.30) | Grad Norm 0.3403(0.5353) | Total Time 14.00(14.00)\n",
      "Iter 21640 | Time 23.9434(23.7318) | Bit/dim 3.4551(3.4484) | Xent 0.0016(0.0021) | Loss 3.4559(3.4494) | Error 0.0000(0.0003) Steps 964(960.90) | Grad Norm 0.3909(0.5300) | Total Time 14.00(14.00)\n",
      "Iter 21650 | Time 23.3866(23.7124) | Bit/dim 3.4517(3.4493) | Xent 0.0010(0.0023) | Loss 3.4522(3.4505) | Error 0.0000(0.0004) Steps 970(961.15) | Grad Norm 0.3199(0.5052) | Total Time 14.00(14.00)\n",
      "Iter 21660 | Time 24.2499(23.7807) | Bit/dim 3.4587(3.4486) | Xent 0.0015(0.0024) | Loss 3.4594(3.4498) | Error 0.0000(0.0004) Steps 970(961.63) | Grad Norm 0.5471(0.5346) | Total Time 14.00(14.00)\n",
      "Iter 21670 | Time 23.3411(23.7709) | Bit/dim 3.4775(3.4515) | Xent 0.0022(0.0023) | Loss 3.4786(3.4526) | Error 0.0011(0.0004) Steps 946(961.62) | Grad Norm 0.5873(0.5083) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 113.4273, Epoch Time 1438.6575(1436.0346), Bit/dim 3.4542(best: 3.4534), Xent 3.7638, Loss 5.3361, Error 0.4083(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21680 | Time 23.2036(23.7528) | Bit/dim 3.4626(3.4496) | Xent 0.0050(0.0024) | Loss 3.4651(3.4508) | Error 0.0011(0.0004) Steps 952(963.64) | Grad Norm 0.9696(0.5439) | Total Time 14.00(14.00)\n",
      "Iter 21690 | Time 24.4924(23.8054) | Bit/dim 3.4593(3.4498) | Xent 0.0021(0.0023) | Loss 3.4603(3.4510) | Error 0.0000(0.0004) Steps 964(962.69) | Grad Norm 0.9569(0.6240) | Total Time 14.00(14.00)\n",
      "Iter 21700 | Time 24.2029(23.8389) | Bit/dim 3.4598(3.4499) | Xent 0.0011(0.0021) | Loss 3.4603(3.4509) | Error 0.0000(0.0003) Steps 958(961.52) | Grad Norm 0.5715(0.6115) | Total Time 14.00(14.00)\n",
      "Iter 21710 | Time 23.7967(23.8603) | Bit/dim 3.4369(3.4498) | Xent 0.0025(0.0020) | Loss 3.4382(3.4508) | Error 0.0011(0.0003) Steps 964(961.14) | Grad Norm 0.4882(0.5801) | Total Time 14.00(14.00)\n",
      "Iter 21720 | Time 23.9334(23.8429) | Bit/dim 3.4571(3.4517) | Xent 0.0012(0.0021) | Loss 3.4577(3.4528) | Error 0.0000(0.0003) Steps 970(960.06) | Grad Norm 0.4484(0.5785) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 112.8379, Epoch Time 1443.9476(1436.2720), Bit/dim 3.4535(best: 3.4534), Xent 3.7777, Loss 5.3424, Error 0.4028(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21730 | Time 23.8060(23.8207) | Bit/dim 3.4405(3.4494) | Xent 0.0022(0.0020) | Loss 3.4416(3.4505) | Error 0.0000(0.0002) Steps 970(962.26) | Grad Norm 0.4968(0.5455) | Total Time 14.00(14.00)\n",
      "Iter 21740 | Time 23.8340(23.8325) | Bit/dim 3.4461(3.4505) | Xent 0.0015(0.0020) | Loss 3.4468(3.4515) | Error 0.0000(0.0003) Steps 952(961.48) | Grad Norm 0.6480(0.5424) | Total Time 14.00(14.00)\n",
      "Iter 21750 | Time 24.3573(23.8251) | Bit/dim 3.4455(3.4502) | Xent 0.0016(0.0022) | Loss 3.4463(3.4513) | Error 0.0000(0.0004) Steps 976(961.92) | Grad Norm 0.8114(0.6069) | Total Time 14.00(14.00)\n",
      "Iter 21760 | Time 24.1296(23.7572) | Bit/dim 3.4605(3.4506) | Xent 0.0028(0.0022) | Loss 3.4619(3.4517) | Error 0.0000(0.0004) Steps 964(960.73) | Grad Norm 1.0361(0.6443) | Total Time 14.00(14.00)\n",
      "Iter 21770 | Time 23.2769(23.6680) | Bit/dim 3.4563(3.4492) | Xent 0.0012(0.0021) | Loss 3.4569(3.4503) | Error 0.0000(0.0003) Steps 946(960.15) | Grad Norm 0.4058(0.6597) | Total Time 14.00(14.00)\n",
      "Iter 21780 | Time 23.7195(23.7423) | Bit/dim 3.4637(3.4505) | Xent 0.0037(0.0020) | Loss 3.4656(3.4515) | Error 0.0011(0.0003) Steps 946(959.12) | Grad Norm 0.6401(0.5925) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 114.2861, Epoch Time 1436.2390(1436.2710), Bit/dim 3.4533(best: 3.4534), Xent 3.7778, Loss 5.3422, Error 0.4091(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21790 | Time 23.6073(23.7293) | Bit/dim 3.5001(3.4481) | Xent 0.0022(0.0021) | Loss 3.5012(3.4491) | Error 0.0000(0.0004) Steps 958(957.97) | Grad Norm 0.3471(0.5883) | Total Time 14.00(14.00)\n",
      "Iter 21800 | Time 23.7024(23.7488) | Bit/dim 3.4354(3.4504) | Xent 0.0013(0.0021) | Loss 3.4360(3.4514) | Error 0.0000(0.0004) Steps 976(961.05) | Grad Norm 0.6010(0.5948) | Total Time 14.00(14.00)\n",
      "Iter 21810 | Time 23.8766(23.7212) | Bit/dim 3.4747(3.4500) | Xent 0.0028(0.0021) | Loss 3.4761(3.4511) | Error 0.0011(0.0004) Steps 964(961.64) | Grad Norm 0.6289(0.5926) | Total Time 14.00(14.00)\n",
      "Iter 21820 | Time 23.5968(23.7589) | Bit/dim 3.4651(3.4507) | Xent 0.0013(0.0021) | Loss 3.4657(3.4517) | Error 0.0000(0.0004) Steps 952(962.79) | Grad Norm 0.7211(0.5865) | Total Time 14.00(14.00)\n",
      "Iter 21830 | Time 23.4742(23.7544) | Bit/dim 3.4203(3.4498) | Xent 0.0018(0.0020) | Loss 3.4212(3.4509) | Error 0.0000(0.0004) Steps 970(961.95) | Grad Norm 0.7778(0.6051) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 112.7966, Epoch Time 1438.3927(1436.3346), Bit/dim 3.4535(best: 3.4533), Xent 3.8074, Loss 5.3572, Error 0.4053(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21840 | Time 24.2031(23.7659) | Bit/dim 3.4179(3.4490) | Xent 0.0013(0.0022) | Loss 3.4185(3.4501) | Error 0.0000(0.0004) Steps 940(962.29) | Grad Norm 0.3742(0.6033) | Total Time 14.00(14.00)\n",
      "Iter 21850 | Time 23.7399(23.7838) | Bit/dim 3.4495(3.4486) | Xent 0.0043(0.0021) | Loss 3.4516(3.4496) | Error 0.0011(0.0004) Steps 964(961.27) | Grad Norm 0.7513(0.5809) | Total Time 14.00(14.00)\n",
      "Iter 21860 | Time 23.8962(23.7199) | Bit/dim 3.4524(3.4492) | Xent 0.0030(0.0020) | Loss 3.4539(3.4503) | Error 0.0011(0.0004) Steps 946(960.77) | Grad Norm 0.7232(0.5638) | Total Time 14.00(14.00)\n",
      "Iter 21870 | Time 23.5350(23.7577) | Bit/dim 3.4474(3.4483) | Xent 0.0015(0.0020) | Loss 3.4482(3.4493) | Error 0.0000(0.0003) Steps 946(959.58) | Grad Norm 0.4709(0.5255) | Total Time 14.00(14.00)\n",
      "Iter 21880 | Time 23.5817(23.7679) | Bit/dim 3.4644(3.4481) | Xent 0.0015(0.0020) | Loss 3.4652(3.4491) | Error 0.0000(0.0003) Steps 970(959.95) | Grad Norm 0.2813(0.5172) | Total Time 14.00(14.00)\n",
      "Iter 21890 | Time 23.3841(23.7775) | Bit/dim 3.4696(3.4500) | Xent 0.0010(0.0019) | Loss 3.4701(3.4510) | Error 0.0000(0.0003) Steps 958(960.16) | Grad Norm 0.5684(0.5325) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 112.3373, Epoch Time 1437.8604(1436.3804), Bit/dim 3.4538(best: 3.4533), Xent 3.8098, Loss 5.3587, Error 0.4078(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21900 | Time 23.6625(23.7602) | Bit/dim 3.4439(3.4505) | Xent 0.0013(0.0021) | Loss 3.4445(3.4515) | Error 0.0000(0.0004) Steps 976(960.94) | Grad Norm 0.8600(0.5844) | Total Time 14.00(14.00)\n",
      "Iter 21910 | Time 22.9383(23.7729) | Bit/dim 3.4246(3.4499) | Xent 0.0019(0.0020) | Loss 3.4255(3.4509) | Error 0.0000(0.0004) Steps 970(961.67) | Grad Norm 0.6251(0.5896) | Total Time 14.00(14.00)\n",
      "Iter 21920 | Time 24.6979(23.8164) | Bit/dim 3.4522(3.4503) | Xent 0.0027(0.0022) | Loss 3.4535(3.4514) | Error 0.0000(0.0005) Steps 958(962.11) | Grad Norm 0.8260(0.5948) | Total Time 14.00(14.00)\n",
      "Iter 21930 | Time 23.6799(23.8776) | Bit/dim 3.3990(3.4498) | Xent 0.0010(0.0020) | Loss 3.3995(3.4508) | Error 0.0000(0.0004) Steps 970(963.01) | Grad Norm 0.3142(0.5547) | Total Time 14.00(14.00)\n",
      "Iter 21940 | Time 23.4129(23.8567) | Bit/dim 3.4793(3.4509) | Xent 0.0011(0.0021) | Loss 3.4799(3.4520) | Error 0.0000(0.0004) Steps 952(962.47) | Grad Norm 0.4004(0.5467) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 113.3799, Epoch Time 1441.6407(1436.5382), Bit/dim 3.4536(best: 3.4533), Xent 3.8284, Loss 5.3678, Error 0.4057(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21950 | Time 23.8038(23.7991) | Bit/dim 3.4312(3.4501) | Xent 0.0018(0.0021) | Loss 3.4321(3.4512) | Error 0.0000(0.0003) Steps 964(961.09) | Grad Norm 0.3123(0.5080) | Total Time 14.00(14.00)\n",
      "Iter 21960 | Time 24.0296(23.7573) | Bit/dim 3.4627(3.4499) | Xent 0.0013(0.0019) | Loss 3.4633(3.4509) | Error 0.0000(0.0003) Steps 976(961.49) | Grad Norm 0.2824(0.4747) | Total Time 14.00(14.00)\n",
      "Iter 21970 | Time 23.6485(23.7989) | Bit/dim 3.4381(3.4479) | Xent 0.0025(0.0022) | Loss 3.4393(3.4489) | Error 0.0000(0.0003) Steps 952(963.76) | Grad Norm 0.4485(0.4818) | Total Time 14.00(14.00)\n",
      "Iter 21980 | Time 23.4832(23.8008) | Bit/dim 3.4803(3.4469) | Xent 0.0012(0.0022) | Loss 3.4809(3.4480) | Error 0.0000(0.0004) Steps 970(963.33) | Grad Norm 0.3457(0.4958) | Total Time 14.00(14.00)\n",
      "Iter 21990 | Time 23.0874(23.7512) | Bit/dim 3.4802(3.4489) | Xent 0.0014(0.0022) | Loss 3.4809(3.4500) | Error 0.0000(0.0003) Steps 958(962.98) | Grad Norm 0.3142(0.4867) | Total Time 14.00(14.00)\n",
      "Iter 22000 | Time 24.0064(23.8021) | Bit/dim 3.4144(3.4492) | Xent 0.0014(0.0020) | Loss 3.4151(3.4502) | Error 0.0000(0.0003) Steps 964(964.19) | Grad Norm 0.3797(0.4730) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 113.4472, Epoch Time 1440.1428(1436.6464), Bit/dim 3.4531(best: 3.4533), Xent 3.8164, Loss 5.3613, Error 0.4032(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22010 | Time 23.1270(23.7612) | Bit/dim 3.4614(3.4479) | Xent 0.0011(0.0019) | Loss 3.4619(3.4489) | Error 0.0000(0.0003) Steps 970(963.80) | Grad Norm 0.3232(0.4528) | Total Time 14.00(14.00)\n",
      "Iter 22020 | Time 23.9695(23.7851) | Bit/dim 3.4340(3.4477) | Xent 0.0019(0.0019) | Loss 3.4349(3.4487) | Error 0.0000(0.0002) Steps 952(962.94) | Grad Norm 0.3428(0.4396) | Total Time 14.00(14.00)\n",
      "Iter 22030 | Time 23.5419(23.8210) | Bit/dim 3.4637(3.4503) | Xent 0.0025(0.0019) | Loss 3.4649(3.4512) | Error 0.0011(0.0003) Steps 946(961.49) | Grad Norm 0.4593(0.4647) | Total Time 14.00(14.00)\n",
      "Iter 22040 | Time 23.5038(23.7977) | Bit/dim 3.4286(3.4523) | Xent 0.0011(0.0017) | Loss 3.4292(3.4531) | Error 0.0000(0.0002) Steps 958(962.22) | Grad Norm 0.2900(0.4521) | Total Time 14.00(14.00)\n",
      "Iter 22050 | Time 23.4336(23.7664) | Bit/dim 3.4863(3.4497) | Xent 0.0044(0.0019) | Loss 3.4885(3.4507) | Error 0.0011(0.0003) Steps 964(961.81) | Grad Norm 0.6580(0.4919) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 112.9304, Epoch Time 1436.0643(1436.6289), Bit/dim 3.4529(best: 3.4531), Xent 3.8045, Loss 5.3551, Error 0.4050(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22060 | Time 23.3128(23.6999) | Bit/dim 3.4607(3.4488) | Xent 0.0012(0.0019) | Loss 3.4613(3.4498) | Error 0.0000(0.0002) Steps 964(961.07) | Grad Norm 0.3475(0.4901) | Total Time 14.00(14.00)\n",
      "Iter 22070 | Time 23.7596(23.7103) | Bit/dim 3.4328(3.4498) | Xent 0.0032(0.0020) | Loss 3.4344(3.4508) | Error 0.0011(0.0004) Steps 964(960.20) | Grad Norm 0.7351(0.4914) | Total Time 14.00(14.00)\n",
      "Iter 22080 | Time 23.8914(23.7402) | Bit/dim 3.4429(3.4511) | Xent 0.0035(0.0021) | Loss 3.4446(3.4522) | Error 0.0011(0.0004) Steps 958(962.73) | Grad Norm 0.6429(0.5229) | Total Time 14.00(14.00)\n",
      "Iter 22090 | Time 23.9340(23.7129) | Bit/dim 3.4698(3.4493) | Xent 0.0014(0.0020) | Loss 3.4705(3.4503) | Error 0.0000(0.0004) Steps 970(961.59) | Grad Norm 0.3061(0.5263) | Total Time 14.00(14.00)\n",
      "Iter 22100 | Time 23.8291(23.7003) | Bit/dim 3.4253(3.4491) | Xent 0.0033(0.0021) | Loss 3.4269(3.4502) | Error 0.0011(0.0005) Steps 952(960.32) | Grad Norm 0.7047(0.5341) | Total Time 14.00(14.00)\n",
      "Iter 22110 | Time 23.8887(23.7021) | Bit/dim 3.4366(3.4475) | Xent 0.0017(0.0022) | Loss 3.4374(3.4485) | Error 0.0000(0.0005) Steps 958(960.20) | Grad Norm 0.6682(0.5541) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 113.7842, Epoch Time 1435.9685(1436.6091), Bit/dim 3.4540(best: 3.4529), Xent 3.7816, Loss 5.3449, Error 0.4041(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22120 | Time 24.2964(23.7324) | Bit/dim 3.4811(3.4480) | Xent 0.0020(0.0022) | Loss 3.4821(3.4491) | Error 0.0000(0.0005) Steps 976(959.73) | Grad Norm 0.7061(0.6002) | Total Time 14.00(14.00)\n",
      "Iter 22130 | Time 23.9132(23.7337) | Bit/dim 3.4315(3.4499) | Xent 0.0043(0.0021) | Loss 3.4337(3.4509) | Error 0.0011(0.0004) Steps 958(958.65) | Grad Norm 0.8426(0.6139) | Total Time 14.00(14.00)\n",
      "Iter 22140 | Time 24.0825(23.7970) | Bit/dim 3.4439(3.4478) | Xent 0.0023(0.0020) | Loss 3.4451(3.4489) | Error 0.0000(0.0004) Steps 970(957.89) | Grad Norm 0.4995(0.5838) | Total Time 14.00(14.00)\n",
      "Iter 22150 | Time 23.9875(23.8391) | Bit/dim 3.4356(3.4454) | Xent 0.0021(0.0020) | Loss 3.4367(3.4464) | Error 0.0000(0.0003) Steps 958(957.82) | Grad Norm 0.3220(0.5589) | Total Time 14.00(14.00)\n",
      "Iter 22160 | Time 23.5098(23.7595) | Bit/dim 3.4358(3.4467) | Xent 0.0007(0.0018) | Loss 3.4362(3.4476) | Error 0.0000(0.0003) Steps 964(958.09) | Grad Norm 0.3693(0.5234) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 110.8477, Epoch Time 1438.9331(1436.6788), Bit/dim 3.4520(best: 3.4529), Xent 3.7929, Loss 5.3485, Error 0.4034(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22170 | Time 23.4895(23.7557) | Bit/dim 3.4327(3.4486) | Xent 0.0020(0.0018) | Loss 3.4337(3.4495) | Error 0.0000(0.0003) Steps 970(957.86) | Grad Norm 0.3817(0.5123) | Total Time 14.00(14.00)\n",
      "Iter 22180 | Time 23.4767(23.6721) | Bit/dim 3.4302(3.4482) | Xent 0.0025(0.0021) | Loss 3.4315(3.4492) | Error 0.0000(0.0004) Steps 946(958.38) | Grad Norm 0.4642(0.5403) | Total Time 14.00(14.00)\n",
      "Iter 22190 | Time 23.5658(23.6786) | Bit/dim 3.4655(3.4503) | Xent 0.0011(0.0019) | Loss 3.4661(3.4513) | Error 0.0000(0.0003) Steps 946(958.43) | Grad Norm 0.4689(0.5062) | Total Time 14.00(14.00)\n",
      "Iter 22200 | Time 23.5561(23.7120) | Bit/dim 3.4623(3.4508) | Xent 0.0039(0.0020) | Loss 3.4642(3.4518) | Error 0.0011(0.0003) Steps 952(958.06) | Grad Norm 0.9019(0.5281) | Total Time 14.00(14.00)\n",
      "Iter 22210 | Time 23.2993(23.6823) | Bit/dim 3.4325(3.4503) | Xent 0.0051(0.0022) | Loss 3.4350(3.4514) | Error 0.0022(0.0004) Steps 958(958.34) | Grad Norm 0.7705(0.5355) | Total Time 14.00(14.00)\n",
      "Iter 22220 | Time 24.3844(23.7392) | Bit/dim 3.4236(3.4468) | Xent 0.0043(0.0023) | Loss 3.4258(3.4479) | Error 0.0022(0.0005) Steps 946(957.55) | Grad Norm 1.4003(0.5639) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 112.4248, Epoch Time 1432.1160(1436.5419), Bit/dim 3.4531(best: 3.4520), Xent 3.8765, Loss 5.3913, Error 0.4071(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22230 | Time 24.3476(23.8305) | Bit/dim 3.4678(3.4496) | Xent 0.0012(0.0026) | Loss 3.4684(3.4509) | Error 0.0000(0.0005) Steps 946(957.89) | Grad Norm 0.7156(0.6295) | Total Time 14.00(14.00)\n",
      "Iter 22240 | Time 23.6461(23.8413) | Bit/dim 3.4761(3.4491) | Xent 0.0012(0.0024) | Loss 3.4767(3.4503) | Error 0.0000(0.0005) Steps 952(958.14) | Grad Norm 0.3702(0.6261) | Total Time 14.00(14.00)\n",
      "Iter 22250 | Time 24.4228(23.8503) | Bit/dim 3.4590(3.4490) | Xent 0.0016(0.0022) | Loss 3.4598(3.4501) | Error 0.0000(0.0004) Steps 946(958.72) | Grad Norm 0.4640(0.5830) | Total Time 14.00(14.00)\n",
      "Iter 22260 | Time 24.1773(23.8898) | Bit/dim 3.4464(3.4484) | Xent 0.0011(0.0021) | Loss 3.4470(3.4494) | Error 0.0000(0.0003) Steps 958(959.32) | Grad Norm 0.3395(0.5238) | Total Time 14.00(14.00)\n",
      "Iter 22270 | Time 23.4377(23.9097) | Bit/dim 3.4621(3.4468) | Xent 0.0021(0.0020) | Loss 3.4631(3.4478) | Error 0.0000(0.0003) Steps 958(960.44) | Grad Norm 0.3860(0.4854) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 112.4640, Epoch Time 1446.0815(1436.8281), Bit/dim 3.4522(best: 3.4520), Xent 3.8096, Loss 5.3570, Error 0.4042(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22280 | Time 24.3775(23.8441) | Bit/dim 3.4366(3.4450) | Xent 0.0026(0.0019) | Loss 3.4379(3.4459) | Error 0.0011(0.0003) Steps 946(958.96) | Grad Norm 0.4525(0.4793) | Total Time 14.00(14.00)\n",
      "Iter 22290 | Time 24.1985(23.8480) | Bit/dim 3.4440(3.4447) | Xent 0.0017(0.0018) | Loss 3.4448(3.4456) | Error 0.0000(0.0002) Steps 952(959.32) | Grad Norm 0.4407(0.4860) | Total Time 14.00(14.00)\n",
      "Iter 22300 | Time 23.8478(23.7975) | Bit/dim 3.4835(3.4464) | Xent 0.0013(0.0018) | Loss 3.4841(3.4473) | Error 0.0000(0.0003) Steps 976(959.61) | Grad Norm 0.5380(0.5059) | Total Time 14.00(14.00)\n",
      "Iter 22310 | Time 23.9008(23.7561) | Bit/dim 3.4621(3.4471) | Xent 0.0063(0.0021) | Loss 3.4652(3.4482) | Error 0.0011(0.0003) Steps 988(959.99) | Grad Norm 0.7541(0.5466) | Total Time 14.00(14.00)\n",
      "Iter 22320 | Time 24.1092(23.7093) | Bit/dim 3.4114(3.4473) | Xent 0.0014(0.0021) | Loss 3.4121(3.4483) | Error 0.0000(0.0003) Steps 964(959.45) | Grad Norm 0.4197(0.5446) | Total Time 14.00(14.00)\n",
      "Iter 22330 | Time 23.7701(23.6641) | Bit/dim 3.4581(3.4490) | Xent 0.0014(0.0021) | Loss 3.4588(3.4500) | Error 0.0000(0.0003) Steps 982(959.25) | Grad Norm 0.4953(0.5365) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 111.9680, Epoch Time 1431.7242(1436.6750), Bit/dim 3.4527(best: 3.4520), Xent 3.8951, Loss 5.4003, Error 0.4094(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22340 | Time 23.0341(23.5924) | Bit/dim 3.4454(3.4478) | Xent 0.0009(0.0021) | Loss 3.4458(3.4489) | Error 0.0000(0.0003) Steps 952(957.59) | Grad Norm 0.3200(0.5399) | Total Time 14.00(14.00)\n",
      "Iter 22350 | Time 24.2596(23.6507) | Bit/dim 3.4321(3.4485) | Xent 0.0011(0.0019) | Loss 3.4326(3.4495) | Error 0.0000(0.0002) Steps 946(958.90) | Grad Norm 0.2512(0.5068) | Total Time 14.00(14.00)\n",
      "Iter 22360 | Time 23.4654(23.7143) | Bit/dim 3.4809(3.4504) | Xent 0.0012(0.0018) | Loss 3.4816(3.4513) | Error 0.0000(0.0002) Steps 952(958.04) | Grad Norm 0.6343(0.5001) | Total Time 14.00(14.00)\n",
      "Iter 22370 | Time 23.0001(23.7439) | Bit/dim 3.4485(3.4473) | Xent 0.0023(0.0019) | Loss 3.4497(3.4483) | Error 0.0011(0.0002) Steps 946(957.25) | Grad Norm 0.6690(0.5402) | Total Time 14.00(14.00)\n",
      "Iter 22380 | Time 24.0967(23.7118) | Bit/dim 3.4655(3.4492) | Xent 0.0018(0.0021) | Loss 3.4664(3.4503) | Error 0.0000(0.0002) Steps 976(958.35) | Grad Norm 0.5549(0.5473) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 113.2586, Epoch Time 1438.2033(1436.7209), Bit/dim 3.4526(best: 3.4520), Xent 3.8958, Loss 5.4005, Error 0.4037(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22390 | Time 23.8071(23.7431) | Bit/dim 3.4561(3.4494) | Xent 0.0009(0.0019) | Loss 3.4566(3.4504) | Error 0.0000(0.0002) Steps 946(957.92) | Grad Norm 0.2791(0.5326) | Total Time 14.00(14.00)\n",
      "Iter 22400 | Time 24.6789(23.7472) | Bit/dim 3.4515(3.4508) | Xent 0.0016(0.0020) | Loss 3.4523(3.4518) | Error 0.0000(0.0002) Steps 970(959.25) | Grad Norm 0.4993(0.5616) | Total Time 14.00(14.00)\n",
      "Iter 22410 | Time 22.8284(23.7288) | Bit/dim 3.4261(3.4493) | Xent 0.0017(0.0021) | Loss 3.4269(3.4503) | Error 0.0000(0.0002) Steps 964(959.60) | Grad Norm 0.3639(0.5523) | Total Time 14.00(14.00)\n",
      "Iter 22420 | Time 23.8160(23.6764) | Bit/dim 3.4516(3.4481) | Xent 0.0031(0.0023) | Loss 3.4531(3.4493) | Error 0.0011(0.0003) Steps 952(959.07) | Grad Norm 1.0695(0.6620) | Total Time 14.00(14.00)\n",
      "Iter 22430 | Time 23.7819(23.6423) | Bit/dim 3.4187(3.4495) | Xent 0.0019(0.0025) | Loss 3.4197(3.4508) | Error 0.0011(0.0005) Steps 946(957.84) | Grad Norm 0.7808(0.7045) | Total Time 14.00(14.00)\n",
      "Iter 22440 | Time 23.4733(23.7312) | Bit/dim 3.4454(3.4480) | Xent 0.0039(0.0023) | Loss 3.4474(3.4492) | Error 0.0011(0.0004) Steps 952(959.82) | Grad Norm 0.6208(0.6926) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 112.6204, Epoch Time 1433.8673(1436.6352), Bit/dim 3.4523(best: 3.4520), Xent 3.8617, Loss 5.3831, Error 0.4074(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22450 | Time 23.5719(23.6630) | Bit/dim 3.4573(3.4499) | Xent 0.0014(0.0023) | Loss 3.4580(3.4511) | Error 0.0000(0.0004) Steps 964(958.93) | Grad Norm 0.4726(0.6533) | Total Time 14.00(14.00)\n",
      "Iter 22460 | Time 23.4240(23.6625) | Bit/dim 3.4740(3.4501) | Xent 0.0008(0.0022) | Loss 3.4744(3.4512) | Error 0.0000(0.0004) Steps 952(957.73) | Grad Norm 0.5852(0.6300) | Total Time 14.00(14.00)\n",
      "Iter 22470 | Time 24.0869(23.6623) | Bit/dim 3.4314(3.4480) | Xent 0.0019(0.0022) | Loss 3.4323(3.4492) | Error 0.0000(0.0004) Steps 958(958.71) | Grad Norm 0.6063(0.6346) | Total Time 14.00(14.00)\n",
      "Iter 22480 | Time 23.3383(23.6781) | Bit/dim 3.4498(3.4480) | Xent 0.0016(0.0022) | Loss 3.4506(3.4491) | Error 0.0000(0.0004) Steps 964(960.08) | Grad Norm 0.5827(0.6283) | Total Time 14.00(14.00)\n",
      "Iter 22490 | Time 23.6043(23.6883) | Bit/dim 3.4236(3.4476) | Xent 0.0040(0.0022) | Loss 3.4256(3.4487) | Error 0.0011(0.0004) Steps 964(959.47) | Grad Norm 0.5314(0.5746) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 112.4781, Epoch Time 1432.6672(1436.5162), Bit/dim 3.4519(best: 3.4520), Xent 3.8839, Loss 5.3938, Error 0.4101(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22500 | Time 24.7158(23.7319) | Bit/dim 3.4621(3.4478) | Xent 0.0009(0.0020) | Loss 3.4625(3.4487) | Error 0.0000(0.0003) Steps 958(959.36) | Grad Norm 0.2771(0.5275) | Total Time 14.00(14.00)\n",
      "Iter 22510 | Time 24.3716(23.7993) | Bit/dim 3.4523(3.4465) | Xent 0.0032(0.0021) | Loss 3.4539(3.4475) | Error 0.0000(0.0003) Steps 952(957.38) | Grad Norm 1.1997(0.5728) | Total Time 14.00(14.00)\n",
      "Iter 22520 | Time 23.7504(23.7776) | Bit/dim 3.4567(3.4499) | Xent 0.0083(0.0022) | Loss 3.4609(3.4510) | Error 0.0022(0.0003) Steps 970(958.93) | Grad Norm 1.2892(0.6334) | Total Time 14.00(14.00)\n",
      "Iter 22530 | Time 22.4081(23.7035) | Bit/dim 3.4448(3.4467) | Xent 0.0014(0.0022) | Loss 3.4455(3.4478) | Error 0.0000(0.0004) Steps 946(958.37) | Grad Norm 0.8124(0.6748) | Total Time 14.00(14.00)\n",
      "Iter 22540 | Time 23.1974(23.7642) | Bit/dim 3.4797(3.4484) | Xent 0.0018(0.0024) | Loss 3.4806(3.4496) | Error 0.0000(0.0005) Steps 964(959.89) | Grad Norm 0.5718(0.7032) | Total Time 14.00(14.00)\n",
      "Iter 22550 | Time 23.7391(23.7957) | Bit/dim 3.5004(3.4494) | Xent 0.0018(0.0027) | Loss 3.5013(3.4508) | Error 0.0000(0.0006) Steps 964(961.24) | Grad Norm 0.5162(0.7113) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 113.7892, Epoch Time 1441.0591(1436.6525), Bit/dim 3.4525(best: 3.4519), Xent 3.9948, Loss 5.4499, Error 0.4061(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22560 | Time 24.0130(23.7813) | Bit/dim 3.4456(3.4490) | Xent 0.0015(0.0024) | Loss 3.4463(3.4502) | Error 0.0000(0.0004) Steps 958(960.62) | Grad Norm 0.3416(0.6457) | Total Time 14.00(14.00)\n",
      "Iter 22570 | Time 23.6077(23.7797) | Bit/dim 3.4838(3.4495) | Xent 0.0013(0.0024) | Loss 3.4844(3.4507) | Error 0.0000(0.0004) Steps 952(961.13) | Grad Norm 0.4621(0.6052) | Total Time 14.00(14.00)\n",
      "Iter 22580 | Time 24.1106(23.7651) | Bit/dim 3.4257(3.4466) | Xent 0.0025(0.0024) | Loss 3.4269(3.4478) | Error 0.0011(0.0004) Steps 964(962.17) | Grad Norm 0.8614(0.6410) | Total Time 14.00(14.00)\n",
      "Iter 22590 | Time 23.7653(23.7636) | Bit/dim 3.4342(3.4463) | Xent 0.0019(0.0022) | Loss 3.4352(3.4474) | Error 0.0000(0.0003) Steps 964(960.31) | Grad Norm 0.4435(0.6048) | Total Time 14.00(14.00)\n",
      "Iter 22600 | Time 23.8471(23.7709) | Bit/dim 3.4194(3.4474) | Xent 0.0022(0.0022) | Loss 3.4205(3.4485) | Error 0.0000(0.0003) Steps 964(960.54) | Grad Norm 0.3933(0.5741) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 112.6683, Epoch Time 1438.5266(1436.7087), Bit/dim 3.4513(best: 3.4519), Xent 3.9113, Loss 5.4069, Error 0.4069(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22610 | Time 23.7938(23.7955) | Bit/dim 3.4145(3.4482) | Xent 0.0044(0.0024) | Loss 3.4167(3.4494) | Error 0.0011(0.0004) Steps 976(960.49) | Grad Norm 0.7406(0.5755) | Total Time 14.00(14.00)\n",
      "Iter 22620 | Time 23.5472(23.7770) | Bit/dim 3.4636(3.4497) | Xent 0.0014(0.0023) | Loss 3.4643(3.4508) | Error 0.0000(0.0004) Steps 976(958.67) | Grad Norm 0.4284(0.5971) | Total Time 14.00(14.00)\n",
      "Iter 22630 | Time 23.6142(23.7909) | Bit/dim 3.4701(3.4501) | Xent 0.0016(0.0022) | Loss 3.4709(3.4512) | Error 0.0000(0.0003) Steps 964(960.13) | Grad Norm 0.5012(0.5827) | Total Time 14.00(14.00)\n",
      "Iter 22640 | Time 23.8455(23.8066) | Bit/dim 3.4587(3.4514) | Xent 0.0011(0.0020) | Loss 3.4592(3.4524) | Error 0.0000(0.0003) Steps 976(961.69) | Grad Norm 0.3895(0.5414) | Total Time 14.00(14.00)\n",
      "Iter 22650 | Time 23.2489(23.7375) | Bit/dim 3.4676(3.4472) | Xent 0.0017(0.0021) | Loss 3.4684(3.4483) | Error 0.0000(0.0003) Steps 946(959.64) | Grad Norm 0.7297(0.5427) | Total Time 14.00(14.00)\n",
      "Iter 22660 | Time 23.9392(23.7294) | Bit/dim 3.4560(3.4464) | Xent 0.0009(0.0021) | Loss 3.4565(3.4475) | Error 0.0000(0.0003) Steps 958(961.51) | Grad Norm 0.6999(0.5735) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 111.9926, Epoch Time 1435.8144(1436.6819), Bit/dim 3.4519(best: 3.4513), Xent 3.8685, Loss 5.3861, Error 0.4060(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22670 | Time 24.5817(23.7549) | Bit/dim 3.4454(3.4475) | Xent 0.0020(0.0020) | Loss 3.4463(3.4485) | Error 0.0000(0.0002) Steps 958(960.73) | Grad Norm 0.3599(0.5394) | Total Time 14.00(14.00)\n",
      "Iter 22680 | Time 23.3136(23.6576) | Bit/dim 3.4442(3.4451) | Xent 0.0010(0.0019) | Loss 3.4447(3.4460) | Error 0.0000(0.0002) Steps 952(958.16) | Grad Norm 0.2352(0.4996) | Total Time 14.00(14.00)\n",
      "Iter 22690 | Time 23.4362(23.5863) | Bit/dim 3.3901(3.4446) | Xent 0.0013(0.0018) | Loss 3.3908(3.4455) | Error 0.0000(0.0002) Steps 946(957.35) | Grad Norm 0.2900(0.4752) | Total Time 14.00(14.00)\n",
      "Iter 22700 | Time 23.3096(23.5634) | Bit/dim 3.4640(3.4471) | Xent 0.0012(0.0020) | Loss 3.4646(3.4481) | Error 0.0000(0.0002) Steps 964(957.36) | Grad Norm 0.3729(0.4769) | Total Time 14.00(14.00)\n",
      "Iter 22710 | Time 23.1663(23.5758) | Bit/dim 3.4460(3.4472) | Xent 0.0016(0.0022) | Loss 3.4468(3.4483) | Error 0.0000(0.0003) Steps 958(956.91) | Grad Norm 0.5008(0.5570) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 112.8225, Epoch Time 1424.6871(1436.3220), Bit/dim 3.4532(best: 3.4513), Xent 3.8993, Loss 5.4028, Error 0.4045(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22720 | Time 23.9147(23.5818) | Bit/dim 3.4241(3.4469) | Xent 0.0019(0.0022) | Loss 3.4251(3.4479) | Error 0.0000(0.0004) Steps 982(958.34) | Grad Norm 1.2091(0.5975) | Total Time 14.00(14.00)\n",
      "Iter 22730 | Time 23.1786(23.6209) | Bit/dim 3.4437(3.4472) | Xent 0.0013(0.0020) | Loss 3.4443(3.4482) | Error 0.0000(0.0003) Steps 970(958.06) | Grad Norm 0.8813(0.6499) | Total Time 14.00(14.00)\n",
      "Iter 22740 | Time 23.6251(23.6699) | Bit/dim 3.3980(3.4470) | Xent 0.0010(0.0019) | Loss 3.3985(3.4480) | Error 0.0000(0.0003) Steps 964(958.23) | Grad Norm 0.5011(0.6339) | Total Time 14.00(14.00)\n",
      "Iter 22750 | Time 23.9199(23.6519) | Bit/dim 3.4587(3.4462) | Xent 0.0016(0.0019) | Loss 3.4595(3.4471) | Error 0.0000(0.0003) Steps 952(958.78) | Grad Norm 0.4671(0.6129) | Total Time 14.00(14.00)\n",
      "Iter 22760 | Time 23.0003(23.6403) | Bit/dim 3.4498(3.4473) | Xent 0.0018(0.0021) | Loss 3.4507(3.4484) | Error 0.0011(0.0004) Steps 946(959.76) | Grad Norm 0.5617(0.5951) | Total Time 14.00(14.00)\n",
      "Iter 22770 | Time 24.1986(23.6368) | Bit/dim 3.4274(3.4476) | Xent 0.0013(0.0020) | Loss 3.4280(3.4486) | Error 0.0000(0.0003) Steps 982(960.37) | Grad Norm 0.3333(0.5407) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 111.5374, Epoch Time 1432.7297(1436.2143), Bit/dim 3.4509(best: 3.4513), Xent 3.9125, Loss 5.4072, Error 0.4092(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22780 | Time 23.8657(23.6458) | Bit/dim 3.4545(3.4475) | Xent 0.0013(0.0020) | Loss 3.4552(3.4485) | Error 0.0000(0.0004) Steps 946(959.04) | Grad Norm 0.5402(0.5227) | Total Time 14.00(14.00)\n",
      "Iter 22790 | Time 23.9040(23.6901) | Bit/dim 3.4844(3.4476) | Xent 0.0008(0.0018) | Loss 3.4848(3.4485) | Error 0.0000(0.0003) Steps 964(960.04) | Grad Norm 0.3532(0.4831) | Total Time 14.00(14.00)\n",
      "Iter 22800 | Time 23.3184(23.6527) | Bit/dim 3.4243(3.4482) | Xent 0.0041(0.0020) | Loss 3.4264(3.4492) | Error 0.0011(0.0004) Steps 964(959.41) | Grad Norm 0.8384(0.5490) | Total Time 14.00(14.00)\n",
      "Iter 22810 | Time 23.0925(23.6079) | Bit/dim 3.4614(3.4479) | Xent 0.0010(0.0021) | Loss 3.4619(3.4489) | Error 0.0000(0.0005) Steps 946(960.32) | Grad Norm 0.5132(0.6136) | Total Time 14.00(14.00)\n",
      "Iter 22820 | Time 23.1263(23.5689) | Bit/dim 3.4152(3.4470) | Xent 0.0024(0.0023) | Loss 3.4164(3.4481) | Error 0.0011(0.0005) Steps 946(957.46) | Grad Norm 0.6963(0.6439) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 112.6859, Epoch Time 1428.8430(1435.9931), Bit/dim 3.4522(best: 3.4509), Xent 3.9562, Loss 5.4304, Error 0.4045(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22830 | Time 23.2975(23.6002) | Bit/dim 3.4629(3.4473) | Xent 0.0022(0.0026) | Loss 3.4640(3.4486) | Error 0.0000(0.0006) Steps 952(957.95) | Grad Norm 0.7158(0.7796) | Total Time 14.00(14.00)\n",
      "Iter 22840 | Time 24.0021(23.6815) | Bit/dim 3.4721(3.4484) | Xent 0.0040(0.0025) | Loss 3.4741(3.4497) | Error 0.0022(0.0006) Steps 952(958.12) | Grad Norm 0.8164(0.8256) | Total Time 14.00(14.00)\n",
      "Iter 22850 | Time 24.0694(23.6390) | Bit/dim 3.4574(3.4499) | Xent 0.0015(0.0024) | Loss 3.4581(3.4511) | Error 0.0000(0.0005) Steps 958(957.26) | Grad Norm 0.5519(0.7759) | Total Time 14.00(14.00)\n",
      "Iter 22860 | Time 24.3149(23.6208) | Bit/dim 3.4601(3.4497) | Xent 0.0021(0.0024) | Loss 3.4612(3.4509) | Error 0.0000(0.0005) Steps 952(956.34) | Grad Norm 0.3710(0.7174) | Total Time 14.00(14.00)\n",
      "Iter 22870 | Time 23.4050(23.6390) | Bit/dim 3.4393(3.4470) | Xent 0.0019(0.0024) | Loss 3.4402(3.4481) | Error 0.0000(0.0005) Steps 958(956.65) | Grad Norm 0.5221(0.6758) | Total Time 14.00(14.00)\n",
      "Iter 22880 | Time 23.6588(23.6027) | Bit/dim 3.4374(3.4462) | Xent 0.0031(0.0024) | Loss 3.4390(3.4473) | Error 0.0011(0.0005) Steps 934(954.83) | Grad Norm 0.5974(0.6394) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 112.0930, Epoch Time 1430.1736(1435.8185), Bit/dim 3.4524(best: 3.4509), Xent 3.9308, Loss 5.4178, Error 0.4100(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22890 | Time 23.2406(23.6101) | Bit/dim 3.4710(3.4476) | Xent 0.0039(0.0024) | Loss 3.4729(3.4488) | Error 0.0022(0.0005) Steps 940(954.14) | Grad Norm 0.8823(0.6195) | Total Time 14.00(14.00)\n",
      "Iter 22900 | Time 23.6727(23.6239) | Bit/dim 3.4661(3.4462) | Xent 0.0027(0.0022) | Loss 3.4674(3.4473) | Error 0.0011(0.0005) Steps 940(953.42) | Grad Norm 0.4902(0.5875) | Total Time 14.00(14.00)\n",
      "Iter 22910 | Time 23.6199(23.6105) | Bit/dim 3.4337(3.4462) | Xent 0.0022(0.0022) | Loss 3.4348(3.4473) | Error 0.0000(0.0004) Steps 970(954.01) | Grad Norm 0.4764(0.5782) | Total Time 14.00(14.00)\n",
      "Iter 22920 | Time 22.9784(23.5170) | Bit/dim 3.4629(3.4477) | Xent 0.0011(0.0021) | Loss 3.4634(3.4488) | Error 0.0000(0.0004) Steps 952(956.00) | Grad Norm 0.6389(0.5999) | Total Time 14.00(14.00)\n",
      "Iter 22930 | Time 23.4632(23.5519) | Bit/dim 3.4785(3.4473) | Xent 0.0031(0.0020) | Loss 3.4801(3.4484) | Error 0.0011(0.0004) Steps 964(957.30) | Grad Norm 0.5787(0.5934) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 111.4003, Epoch Time 1425.1496(1435.4985), Bit/dim 3.4507(best: 3.4509), Xent 3.9353, Loss 5.4183, Error 0.4047(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22940 | Time 22.9986(23.5137) | Bit/dim 3.4475(3.4470) | Xent 0.0013(0.0020) | Loss 3.4481(3.4480) | Error 0.0000(0.0004) Steps 946(956.91) | Grad Norm 0.6180(0.5717) | Total Time 14.00(14.00)\n",
      "Iter 22950 | Time 23.2141(23.5324) | Bit/dim 3.4418(3.4458) | Xent 0.0017(0.0023) | Loss 3.4427(3.4469) | Error 0.0000(0.0005) Steps 964(956.63) | Grad Norm 0.7038(0.5871) | Total Time 14.00(14.00)\n",
      "Iter 22960 | Time 23.4603(23.5627) | Bit/dim 3.4558(3.4476) | Xent 0.0019(0.0021) | Loss 3.4567(3.4487) | Error 0.0011(0.0005) Steps 964(959.13) | Grad Norm 0.5353(0.5718) | Total Time 14.00(14.00)\n",
      "Iter 22970 | Time 23.7485(23.6414) | Bit/dim 3.4073(3.4464) | Xent 0.0016(0.0020) | Loss 3.4081(3.4474) | Error 0.0000(0.0004) Steps 958(959.71) | Grad Norm 0.4348(0.5248) | Total Time 14.00(14.00)\n",
      "Iter 22980 | Time 23.5985(23.6353) | Bit/dim 3.3991(3.4459) | Xent 0.0028(0.0023) | Loss 3.4006(3.4470) | Error 0.0011(0.0005) Steps 964(960.71) | Grad Norm 0.9614(0.6116) | Total Time 14.00(14.00)\n",
      "Iter 22990 | Time 23.5332(23.6699) | Bit/dim 3.4576(3.4473) | Xent 0.0018(0.0024) | Loss 3.4585(3.4485) | Error 0.0000(0.0005) Steps 952(961.34) | Grad Norm 0.5819(0.6212) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 112.0501, Epoch Time 1431.3119(1435.3729), Bit/dim 3.4521(best: 3.4507), Xent 3.9594, Loss 5.4318, Error 0.4034(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23000 | Time 23.5243(23.7103) | Bit/dim 3.4258(3.4460) | Xent 0.0021(0.0023) | Loss 3.4269(3.4472) | Error 0.0000(0.0005) Steps 958(961.91) | Grad Norm 0.6390(0.6332) | Total Time 14.00(14.00)\n",
      "Iter 23010 | Time 23.5916(23.7691) | Bit/dim 3.4355(3.4437) | Xent 0.0021(0.0025) | Loss 3.4366(3.4449) | Error 0.0000(0.0006) Steps 952(962.78) | Grad Norm 0.6768(0.6939) | Total Time 14.00(14.00)\n",
      "Iter 23020 | Time 24.0298(23.8280) | Bit/dim 3.4225(3.4446) | Xent 0.0051(0.0025) | Loss 3.4251(3.4458) | Error 0.0011(0.0005) Steps 970(963.06) | Grad Norm 0.8630(0.6735) | Total Time 14.00(14.00)\n",
      "Iter 23030 | Time 24.0713(23.7702) | Bit/dim 3.4475(3.4438) | Xent 0.0010(0.0024) | Loss 3.4480(3.4450) | Error 0.0000(0.0005) Steps 964(959.43) | Grad Norm 0.5265(0.6525) | Total Time 14.00(14.00)\n",
      "Iter 23040 | Time 23.4968(23.7426) | Bit/dim 3.4834(3.4483) | Xent 0.0011(0.0022) | Loss 3.4839(3.4494) | Error 0.0000(0.0004) Steps 940(958.19) | Grad Norm 0.2964(0.5982) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 112.0201, Epoch Time 1437.2264(1435.4285), Bit/dim 3.4516(best: 3.4507), Xent 3.9607, Loss 5.4320, Error 0.4061(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23050 | Time 23.4409(23.6364) | Bit/dim 3.4492(3.4496) | Xent 0.0022(0.0022) | Loss 3.4503(3.4507) | Error 0.0000(0.0004) Steps 970(957.48) | Grad Norm 0.5533(0.6069) | Total Time 14.00(14.00)\n",
      "Iter 23060 | Time 23.8232(23.6327) | Bit/dim 3.4814(3.4500) | Xent 0.0074(0.0021) | Loss 3.4852(3.4511) | Error 0.0011(0.0004) Steps 958(958.24) | Grad Norm 0.6747(0.5644) | Total Time 14.00(14.00)\n",
      "Iter 23070 | Time 24.2123(23.6114) | Bit/dim 3.4387(3.4499) | Xent 0.0022(0.0021) | Loss 3.4398(3.4510) | Error 0.0011(0.0004) Steps 952(956.83) | Grad Norm 0.9493(0.5853) | Total Time 14.00(14.00)\n",
      "Iter 23080 | Time 23.4685(23.6503) | Bit/dim 3.4056(3.4480) | Xent 0.0024(0.0020) | Loss 3.4068(3.4490) | Error 0.0000(0.0003) Steps 964(956.98) | Grad Norm 0.6992(0.5981) | Total Time 14.00(14.00)\n",
      "Iter 23090 | Time 23.5481(23.6778) | Bit/dim 3.4422(3.4488) | Xent 0.0022(0.0023) | Loss 3.4433(3.4499) | Error 0.0000(0.0003) Steps 946(958.41) | Grad Norm 0.5002(0.6228) | Total Time 14.00(14.00)\n",
      "Iter 23100 | Time 23.5863(23.6598) | Bit/dim 3.4187(3.4473) | Xent 0.0014(0.0023) | Loss 3.4194(3.4484) | Error 0.0000(0.0003) Steps 964(957.60) | Grad Norm 0.5028(0.6741) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 112.6633, Epoch Time 1430.3561(1435.2763), Bit/dim 3.4502(best: 3.4507), Xent 3.9555, Loss 5.4280, Error 0.4019(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23110 | Time 23.6955(23.7199) | Bit/dim 3.4214(3.4501) | Xent 0.0012(0.0022) | Loss 3.4220(3.4512) | Error 0.0000(0.0003) Steps 952(959.04) | Grad Norm 0.6006(0.6637) | Total Time 14.00(14.00)\n",
      "Iter 23120 | Time 23.2819(23.6780) | Bit/dim 3.4522(3.4490) | Xent 0.0011(0.0023) | Loss 3.4528(3.4501) | Error 0.0000(0.0004) Steps 958(957.54) | Grad Norm 0.4519(0.6866) | Total Time 14.00(14.00)\n",
      "Iter 23130 | Time 24.2833(23.8331) | Bit/dim 3.4484(3.4476) | Xent 0.0015(0.0023) | Loss 3.4492(3.4487) | Error 0.0000(0.0003) Steps 952(957.30) | Grad Norm 0.6625(0.6608) | Total Time 14.00(14.00)\n",
      "Iter 23140 | Time 23.1563(23.7818) | Bit/dim 3.4432(3.4477) | Xent 0.0037(0.0022) | Loss 3.4451(3.4488) | Error 0.0011(0.0003) Steps 958(958.57) | Grad Norm 0.6118(0.6378) | Total Time 14.00(14.00)\n",
      "Iter 23150 | Time 23.5344(23.7787) | Bit/dim 3.4537(3.4455) | Xent 0.0016(0.0022) | Loss 3.4545(3.4465) | Error 0.0000(0.0003) Steps 964(960.12) | Grad Norm 0.3557(0.6175) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 113.6324, Epoch Time 1442.2854(1435.4866), Bit/dim 3.4505(best: 3.4502), Xent 3.9471, Loss 5.4240, Error 0.4045(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23160 | Time 23.6461(23.7785) | Bit/dim 3.4206(3.4453) | Xent 0.0024(0.0022) | Loss 3.4218(3.4464) | Error 0.0000(0.0004) Steps 946(959.06) | Grad Norm 0.4324(0.6078) | Total Time 14.00(14.00)\n",
      "Iter 23170 | Time 23.6477(23.7608) | Bit/dim 3.4902(3.4495) | Xent 0.0013(0.0021) | Loss 3.4909(3.4505) | Error 0.0000(0.0004) Steps 946(959.46) | Grad Norm 0.4357(0.5704) | Total Time 14.00(14.00)\n",
      "Iter 23180 | Time 24.6944(23.7775) | Bit/dim 3.4795(3.4499) | Xent 0.0016(0.0021) | Loss 3.4803(3.4509) | Error 0.0000(0.0004) Steps 988(960.36) | Grad Norm 0.3761(0.5573) | Total Time 14.00(14.00)\n",
      "Iter 23190 | Time 23.8134(23.7725) | Bit/dim 3.4458(3.4464) | Xent 0.0016(0.0024) | Loss 3.4466(3.4476) | Error 0.0000(0.0005) Steps 970(958.91) | Grad Norm 0.7748(0.5720) | Total Time 14.00(14.00)\n",
      "Iter 23200 | Time 23.3804(23.7247) | Bit/dim 3.4491(3.4456) | Xent 0.0016(0.0024) | Loss 3.4499(3.4468) | Error 0.0000(0.0005) Steps 946(957.13) | Grad Norm 0.4560(0.5807) | Total Time 14.00(14.00)\n",
      "Iter 23210 | Time 24.2017(23.7004) | Bit/dim 3.4345(3.4448) | Xent 0.0011(0.0026) | Loss 3.4350(3.4461) | Error 0.0000(0.0006) Steps 982(957.17) | Grad Norm 0.6216(0.6417) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 112.8737, Epoch Time 1434.3618(1435.4528), Bit/dim 3.4520(best: 3.4502), Xent 4.0161, Loss 5.4600, Error 0.4059(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23220 | Time 23.6626(23.6928) | Bit/dim 3.4451(3.4446) | Xent 0.0021(0.0024) | Loss 3.4462(3.4458) | Error 0.0011(0.0005) Steps 952(957.17) | Grad Norm 0.7739(0.6471) | Total Time 14.00(14.00)\n",
      "Iter 23230 | Time 24.3249(23.7185) | Bit/dim 3.4492(3.4457) | Xent 0.0022(0.0024) | Loss 3.4503(3.4470) | Error 0.0000(0.0005) Steps 982(958.33) | Grad Norm 0.5633(0.6449) | Total Time 14.00(14.00)\n",
      "Iter 23240 | Time 24.1281(23.7239) | Bit/dim 3.4755(3.4462) | Xent 0.0010(0.0024) | Loss 3.4759(3.4474) | Error 0.0000(0.0005) Steps 946(959.75) | Grad Norm 0.3262(0.6196) | Total Time 14.00(14.00)\n",
      "Iter 23250 | Time 23.8608(23.6964) | Bit/dim 3.4275(3.4454) | Xent 0.0044(0.0024) | Loss 3.4297(3.4466) | Error 0.0022(0.0005) Steps 958(958.23) | Grad Norm 0.7212(0.5994) | Total Time 14.00(14.00)\n",
      "Iter 23260 | Time 23.1737(23.6239) | Bit/dim 3.4356(3.4460) | Xent 0.0059(0.0024) | Loss 3.4385(3.4472) | Error 0.0022(0.0005) Steps 958(957.03) | Grad Norm 1.6496(0.6122) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 112.1993, Epoch Time 1430.9038(1435.3164), Bit/dim 3.4515(best: 3.4502), Xent 3.9311, Loss 5.4170, Error 0.4094(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23270 | Time 23.6897(23.6230) | Bit/dim 3.4660(3.4489) | Xent 0.0011(0.0024) | Loss 3.4665(3.4501) | Error 0.0000(0.0005) Steps 952(957.04) | Grad Norm 1.1405(0.7039) | Total Time 14.00(14.00)\n",
      "Iter 23280 | Time 24.0136(23.6629) | Bit/dim 3.4331(3.4459) | Xent 0.0013(0.0023) | Loss 3.4338(3.4471) | Error 0.0000(0.0004) Steps 952(958.07) | Grad Norm 0.3951(0.6983) | Total Time 14.00(14.00)\n",
      "Iter 23290 | Time 24.2632(23.7910) | Bit/dim 3.4207(3.4472) | Xent 0.0016(0.0023) | Loss 3.4215(3.4483) | Error 0.0000(0.0004) Steps 964(957.15) | Grad Norm 0.4651(0.6803) | Total Time 14.00(14.00)\n",
      "Iter 23300 | Time 23.9132(23.7942) | Bit/dim 3.4349(3.4482) | Xent 0.0012(0.0023) | Loss 3.4355(3.4493) | Error 0.0000(0.0004) Steps 964(957.64) | Grad Norm 0.4458(0.6414) | Total Time 14.00(14.00)\n",
      "Iter 23310 | Time 24.4625(23.8117) | Bit/dim 3.4540(3.4490) | Xent 0.0010(0.0023) | Loss 3.4545(3.4501) | Error 0.0000(0.0003) Steps 964(958.10) | Grad Norm 0.4671(0.6109) | Total Time 14.00(14.00)\n",
      "Iter 23320 | Time 24.5002(23.7954) | Bit/dim 3.4378(3.4452) | Xent 0.0029(0.0021) | Loss 3.4392(3.4463) | Error 0.0011(0.0003) Steps 946(957.12) | Grad Norm 0.4729(0.5544) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 112.7219, Epoch Time 1441.4629(1435.5008), Bit/dim 3.4498(best: 3.4502), Xent 3.9739, Loss 5.4368, Error 0.4048(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23330 | Time 24.0287(23.7504) | Bit/dim 3.4538(3.4446) | Xent 0.0024(0.0020) | Loss 3.4550(3.4456) | Error 0.0011(0.0003) Steps 976(957.91) | Grad Norm 0.6556(0.5378) | Total Time 14.00(14.00)\n",
      "Iter 23340 | Time 23.7134(23.7207) | Bit/dim 3.4363(3.4424) | Xent 0.0015(0.0019) | Loss 3.4370(3.4434) | Error 0.0000(0.0003) Steps 964(957.53) | Grad Norm 0.3947(0.5164) | Total Time 14.00(14.00)\n",
      "Iter 23350 | Time 24.1274(23.6826) | Bit/dim 3.4628(3.4442) | Xent 0.0023(0.0018) | Loss 3.4640(3.4451) | Error 0.0000(0.0002) Steps 964(958.96) | Grad Norm 0.4032(0.5173) | Total Time 14.00(14.00)\n",
      "Iter 23360 | Time 23.5410(23.6984) | Bit/dim 3.4692(3.4457) | Xent 0.0007(0.0019) | Loss 3.4695(3.4466) | Error 0.0000(0.0003) Steps 946(957.35) | Grad Norm 0.3729(0.5263) | Total Time 14.00(14.00)\n",
      "Iter 23370 | Time 23.6965(23.7528) | Bit/dim 3.4731(3.4456) | Xent 0.0034(0.0019) | Loss 3.4748(3.4465) | Error 0.0011(0.0003) Steps 958(957.36) | Grad Norm 0.6097(0.5667) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 110.9690, Epoch Time 1433.5667(1435.4428), Bit/dim 3.4506(best: 3.4498), Xent 3.9520, Loss 5.4266, Error 0.4037(best: 0.3968)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_cifar10_bs900_run2 --resume ../experiments_published/cnf_conditional_cifar10_bs900_run2/current_checkpt.pth --seed 2 --lr 0.0001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
