{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl_multiscale.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import torch.utils.data as data\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "plt.rcParams['figure.dpi'] = 300\n",
      "\n",
      "from PIL import Image\n",
      "import os.path\n",
      "import errno\n",
      "import codecs\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"colormnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--y_class\", type=int, default=10)\n",
      "parser.add_argument(\"--y_color\", type=int, default=10)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl_multiscale as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "class ColorMNIST(data.Dataset):\n",
      "    \"\"\"\n",
      "    ColorMNIST\n",
      "    \"\"\"\n",
      "    urls = [\n",
      "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
      "    ]\n",
      "    raw_folder = 'raw'\n",
      "    processed_folder = 'processed'\n",
      "    training_file = 'training.pt'\n",
      "    test_file = 'test.pt'\n",
      "\n",
      "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
      "        self.root = os.path.expanduser(root)\n",
      "        self.transform = transform\n",
      "        self.target_transform = target_transform\n",
      "        self.train = train  # training set or test set\n",
      "\n",
      "        if download:\n",
      "            self.download()\n",
      "\n",
      "        if not self._check_exists():\n",
      "            raise RuntimeError('Dataset not found.' +\n",
      "                               ' You can use download=True to download it')\n",
      "\n",
      "        if self.train:\n",
      "            self.train_data, self.train_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
      "            \n",
      "            self.train_data = np.tile(self.train_data[:, :, :, np.newaxis], 3)\n",
      "        else:\n",
      "            self.test_data, self.test_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "            \n",
      "            self.test_data = np.tile(self.test_data[:, :, :, np.newaxis], 3)\n",
      "        \n",
      "        self.pallette = [[31, 119, 180],\n",
      "                         [255, 127, 14],\n",
      "                         [44, 160, 44],\n",
      "                         [214, 39, 40],\n",
      "                         [148, 103, 189],\n",
      "                         [140, 86, 75],\n",
      "                         [227, 119, 194],\n",
      "                         [127, 127, 127],\n",
      "                         [188, 189, 34],\n",
      "                         [23, 190, 207]]\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            index (int): Index\n",
      "\n",
      "        Returns:\n",
      "            tuple: (image, target) where target is index of the target class.\n",
      "        \"\"\"\n",
      "        if self.train:\n",
      "            img, target = self.train_data[index].copy(), self.train_labels[index]\n",
      "        else:\n",
      "            img, target = self.test_data[index].copy(), self.test_labels[index]\n",
      "        \n",
      "        # doing this so that it is consistent with all other datasets\n",
      "        # to return a PIL Image\n",
      "        y_color_digit = np.random.randint(0, args.y_color)\n",
      "        c_digit = self.pallette[y_color_digit]\n",
      "        \n",
      "        img[:, :, 0] = img[:, :, 0] / 255 * c_digit[0]\n",
      "        img[:, :, 1] = img[:, :, 1] / 255 * c_digit[1]\n",
      "        img[:, :, 2] = img[:, :, 2] / 255 * c_digit[2]\n",
      "        \n",
      "        img = Image.fromarray(img)\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "\n",
      "        return img, [target,torch.from_numpy(np.array(y_color_digit))]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.train:\n",
      "            return len(self.train_data)\n",
      "        else:\n",
      "            return len(self.test_data)\n",
      "\n",
      "    def _check_exists(self):\n",
      "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
      "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "\n",
      "    def download(self):\n",
      "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
      "        from six.moves import urllib\n",
      "        import gzip\n",
      "\n",
      "        if self._check_exists():\n",
      "            return\n",
      "\n",
      "        # download files\n",
      "        try:\n",
      "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
      "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
      "        except OSError as e:\n",
      "            if e.errno == errno.EEXIST:\n",
      "                pass\n",
      "            else:\n",
      "                raise\n",
      "\n",
      "        for url in self.urls:\n",
      "            print('Downloading ' + url)\n",
      "            data = urllib.request.urlopen(url)\n",
      "            filename = url.rpartition('/')[2]\n",
      "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
      "            with open(file_path, 'wb') as f:\n",
      "                f.write(data.read())\n",
      "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
      "                    gzip.GzipFile(file_path) as zip_f:\n",
      "                out_f.write(zip_f.read())\n",
      "            os.unlink(file_path)\n",
      "\n",
      "        # process and save as torch files\n",
      "        print('Processing...')\n",
      "\n",
      "        training_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
      "        )\n",
      "        test_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
      "        )\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
      "            torch.save(training_set, f)\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
      "            torch.save(test_set, f)\n",
      "\n",
      "        print('Done!')\n",
      "\n",
      "    def __repr__(self):\n",
      "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
      "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
      "        tmp = 'train' if self.train is True else 'test'\n",
      "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
      "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
      "        tmp = '    Transforms (if any): '\n",
      "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        tmp = '    Target Transforms (if any): '\n",
      "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        return fmt_str\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"colormnist\":\n",
      "        im_dim = 3\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = ColorMNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = ColorMNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z_sup, z_unsup, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    z_sup = torch.cat(z_sup, 1)\n",
      "    z_unsup = torch.cat(z_unsup, 1)\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z_sup).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z_unsup).view(z_unsup.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        z_sup = model.module.dropout(z_sup)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z_sup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,\n",
      "            y_class = args.y_class)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            dim_unsup = np.prod(data_shape) - np.prod(fixed_z_sup.shape[1:])\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            \n",
      "            a_sup = fixed_z_sup.shape[1] // (2**(model.module.n_scale - 1))\n",
      "            a_unsup = fixed_z_unsup.shape[1] // (2**(model.module.n_scale - 1))\n",
      "            \n",
      "            fixed_z = []\n",
      "            start_sup = 0; start_unsup = 0\n",
      "            for ns in range(model.module.n_scale, 1, -1):\n",
      "                end_sup = start_sup + (2**(ns-2))*a_sup\n",
      "                end_unsup = start_unsup + (2**(ns-2))*a_unsup\n",
      "                \n",
      "                fixed_z.append(fixed_z_sup[:,start_sup:end_sup])\n",
      "                fixed_z.append(fixed_z_unsup[:,start_unsup:end_unsup])\n",
      "                \n",
      "                start_sup = end_sup; start_unsup = end_unsup\n",
      "            \n",
      "            end_sup = start_sup + a_sup\n",
      "            end_unsup = start_unsup + a_unsup\n",
      "            \n",
      "            fixed_z.append(fixed_z_sup[:,start_sup:end_sup])\n",
      "            fixed_z.append(fixed_z_unsup[:,start_unsup:end_unsup])\n",
      "            \n",
      "            # for i_z in range(len(fixed_z)): print(fixed_z[i_z].shape)\n",
      "            \n",
      "            fixed_z = torch.cat(fixed_z,1)\n",
      "            \n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            if args.data == \"colormnist\":\n",
      "                y = y[0]\n",
      "            \n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "            \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if args.data == \"colormnist\":\n",
      "                        y = y[0]\n",
      "                        \n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                    \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=False, atol=0.0001, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=True, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, eta=0.1, gamma=0.99, gate='cnn2', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.001, max_grad_norm=20.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_disentangle_cifar10_bs8K_sratio_0_5_drop_0_5_rl_stdlearnscale_15_multiscale_run1/epoch_120_checkpt.pth', rl_weight=0.01, rtol=0.0001, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs8K_sratio_0_5_drop_0_5_rl_stdlearnscale_15_multiscale_run1', scale=1.0, scale_fac=1.0, scale_std=15.0, seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000.0, weight_decay=0.0, weight_y=0.5, y_class=10, y_color=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1450886\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 0721 | Time 126.9826(60.7770) | Bit/dim 3.8233(3.8296) | Xent 1.1676(1.1191) | Loss 12.9545(11.1526) | Error 0.4226(0.3998) Steps 670(678.52) | Grad Norm 8.2215(7.7401) | Total Time 0.00(0.00)\n",
      "Iter 0722 | Time 61.7163(60.8052) | Bit/dim 3.8253(3.8295) | Xent 1.1454(1.1199) | Loss 10.4588(11.1318) | Error 0.4040(0.3999) Steps 682(678.62) | Grad Norm 7.5261(7.7337) | Total Time 0.00(0.00)\n",
      "Iter 0723 | Time 58.6642(60.7409) | Bit/dim 3.7914(3.8283) | Xent 1.1149(1.1198) | Loss 10.3271(11.1076) | Error 0.4005(0.4000) Steps 724(679.98) | Grad Norm 5.7536(7.6743) | Total Time 0.00(0.00)\n",
      "Iter 0724 | Time 63.8560(60.8344) | Bit/dim 3.8001(3.8275) | Xent 1.0850(1.1187) | Loss 10.0384(11.0755) | Error 0.3889(0.3996) Steps 676(679.86) | Grad Norm 3.5170(7.5496) | Total Time 0.00(0.00)\n",
      "Iter 0725 | Time 59.8474(60.8048) | Bit/dim 3.7797(3.8260) | Xent 1.0537(1.1168) | Loss 10.1839(11.0488) | Error 0.3730(0.3988) Steps 706(680.65) | Grad Norm 2.5560(7.3998) | Total Time 0.00(0.00)\n",
      "Iter 0726 | Time 61.0527(60.8122) | Bit/dim 3.7903(3.8250) | Xent 1.0689(1.1153) | Loss 10.1388(11.0215) | Error 0.3806(0.3983) Steps 700(681.23) | Grad Norm 3.6314(7.2867) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 40.6919, Epoch Time 492.3696(390.7681), Bit/dim 3.7867(best: inf), Xent 1.1818, Loss 4.3776, Error 0.4269(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0727 | Time 69.2757(61.0661) | Bit/dim 3.7917(3.8240) | Xent 1.0575(1.1136) | Loss 15.6711(11.1610) | Error 0.3836(0.3978) Steps 694(681.61) | Grad Norm 4.4130(7.2005) | Total Time 0.00(0.00)\n",
      "Iter 0728 | Time 63.4586(61.1379) | Bit/dim 3.7860(3.8228) | Xent 1.0448(1.1115) | Loss 10.2394(11.1333) | Error 0.3786(0.3973) Steps 694(681.98) | Grad Norm 4.4176(7.1170) | Total Time 0.00(0.00)\n",
      "Iter 0729 | Time 59.4364(61.0868) | Bit/dim 3.7873(3.8218) | Xent 1.0192(1.1088) | Loss 9.9855(11.0989) | Error 0.3646(0.3963) Steps 706(682.70) | Grad Norm 4.2956(7.0324) | Total Time 0.00(0.00)\n",
      "Iter 0730 | Time 61.4755(61.0985) | Bit/dim 3.7862(3.8207) | Xent 0.9924(1.1053) | Loss 10.1466(11.0703) | Error 0.3534(0.3950) Steps 706(683.40) | Grad Norm 3.4937(6.9262) | Total Time 0.00(0.00)\n",
      "Iter 0731 | Time 62.8181(61.1501) | Bit/dim 3.7833(3.8196) | Xent 0.9903(1.1018) | Loss 10.1218(11.0419) | Error 0.3531(0.3937) Steps 664(682.82) | Grad Norm 2.7880(6.8021) | Total Time 0.00(0.00)\n",
      "Iter 0732 | Time 59.9305(61.1135) | Bit/dim 3.7746(3.8182) | Xent 0.9934(1.0986) | Loss 10.1852(11.0162) | Error 0.3536(0.3925) Steps 694(683.16) | Grad Norm 3.4617(6.7019) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 25.8199, Epoch Time 420.7181(391.6666), Bit/dim 3.7861(best: 3.7867), Xent 1.1375, Loss 4.3549, Error 0.3992(best: 0.4269)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0733 | Time 59.7337(61.0721) | Bit/dim 3.7711(3.8168) | Xent 0.9827(1.0951) | Loss 16.0432(11.1670) | Error 0.3465(0.3912) Steps 688(683.30) | Grad Norm 3.4388(6.6040) | Total Time 0.00(0.00)\n",
      "Iter 0734 | Time 53.6064(60.8481) | Bit/dim 3.7765(3.8156) | Xent 0.9718(1.0914) | Loss 9.9439(11.1303) | Error 0.3498(0.3899) Steps 694(683.62) | Grad Norm 3.4351(6.5089) | Total Time 0.00(0.00)\n",
      "Iter 0735 | Time 61.2663(60.8607) | Bit/dim 3.7807(3.8146) | Xent 0.9956(1.0885) | Loss 9.8400(11.0916) | Error 0.3555(0.3889) Steps 712(684.47) | Grad Norm 2.7497(6.3961) | Total Time 0.00(0.00)\n",
      "Iter 0736 | Time 58.9754(60.8041) | Bit/dim 3.7715(3.8133) | Xent 0.9634(1.0848) | Loss 10.1505(11.0634) | Error 0.3498(0.3877) Steps 694(684.76) | Grad Norm 1.8936(6.2611) | Total Time 0.00(0.00)\n",
      "Iter 0737 | Time 59.3452(60.7604) | Bit/dim 3.7664(3.8119) | Xent 0.9729(1.0814) | Loss 9.9776(11.0308) | Error 0.3524(0.3867) Steps 706(685.40) | Grad Norm 1.9371(6.1313) | Total Time 0.00(0.00)\n",
      "Iter 0738 | Time 59.5398(60.7237) | Bit/dim 3.7701(3.8106) | Xent 0.9936(1.0788) | Loss 10.2510(11.0074) | Error 0.3540(0.3857) Steps 670(684.93) | Grad Norm 2.7439(6.0297) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 25.2989, Epoch Time 396.2189(391.8032), Bit/dim 3.7665(best: 3.7861), Xent 1.1313, Loss 4.3321, Error 0.3997(best: 0.3992)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0739 | Time 61.5519(60.7486) | Bit/dim 3.7653(3.8093) | Xent 0.9714(1.0756) | Loss 17.1207(11.1908) | Error 0.3454(0.3845) Steps 694(685.21) | Grad Norm 2.5702(5.9259) | Total Time 0.00(0.00)\n",
      "Iter 0740 | Time 57.9142(60.6636) | Bit/dim 3.7655(3.8079) | Xent 0.9573(1.0720) | Loss 10.0773(11.1574) | Error 0.3459(0.3833) Steps 658(684.39) | Grad Norm 2.6873(5.8288) | Total Time 0.00(0.00)\n",
      "Iter 0741 | Time 58.2649(60.5916) | Bit/dim 3.7634(3.8066) | Xent 0.9551(1.0685) | Loss 9.7743(11.1159) | Error 0.3491(0.3823) Steps 670(683.96) | Grad Norm 1.9719(5.7131) | Total Time 0.00(0.00)\n",
      "Iter 0742 | Time 60.2903(60.5826) | Bit/dim 3.7648(3.8053) | Xent 0.9279(1.0643) | Loss 10.0353(11.0835) | Error 0.3305(0.3807) Steps 694(684.26) | Grad Norm 1.6930(5.5925) | Total Time 0.00(0.00)\n",
      "Iter 0743 | Time 59.0632(60.5370) | Bit/dim 3.7715(3.8043) | Xent 0.9748(1.0616) | Loss 9.7781(11.0443) | Error 0.3481(0.3797) Steps 688(684.37) | Grad Norm 1.8682(5.4807) | Total Time 0.00(0.00)\n",
      "Iter 0744 | Time 56.7880(60.4245) | Bit/dim 3.7577(3.8029) | Xent 0.9557(1.0584) | Loss 10.1083(11.0162) | Error 0.3436(0.3787) Steps 682(684.30) | Grad Norm 2.3114(5.3857) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 25.2814, Epoch Time 396.9905(391.9588), Bit/dim 3.7583(best: 3.7665), Xent 1.1328, Loss 4.3247, Error 0.4003(best: 0.3992)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0745 | Time 60.4226(60.4244) | Bit/dim 3.7493(3.8013) | Xent 0.9511(1.0552) | Loss 16.1400(11.1699) | Error 0.3409(0.3775) Steps 664(683.69) | Grad Norm 1.7488(5.2766) | Total Time 0.00(0.00)\n",
      "Iter 0746 | Time 59.3453(60.3921) | Bit/dim 3.7566(3.8000) | Xent 0.9552(1.0522) | Loss 10.0740(11.1371) | Error 0.3323(0.3762) Steps 712(684.54) | Grad Norm 1.6243(5.1670) | Total Time 0.00(0.00)\n",
      "Iter 0747 | Time 62.4140(60.4527) | Bit/dim 3.7618(3.7988) | Xent 0.9320(1.0486) | Loss 10.1022(11.1060) | Error 0.3325(0.3749) Steps 658(683.75) | Grad Norm 1.2310(5.0489) | Total Time 0.00(0.00)\n",
      "Iter 0748 | Time 57.4122(60.3615) | Bit/dim 3.7611(3.7977) | Xent 0.9542(1.0458) | Loss 10.0356(11.0739) | Error 0.3366(0.3737) Steps 664(683.15) | Grad Norm 1.8615(4.9533) | Total Time 0.00(0.00)\n",
      "Iter 0749 | Time 60.1715(60.3558) | Bit/dim 3.7675(3.7968) | Xent 0.9200(1.0420) | Loss 10.1679(11.0467) | Error 0.3286(0.3724) Steps 688(683.30) | Grad Norm 2.0450(4.8660) | Total Time 0.00(0.00)\n",
      "Iter 0750 | Time 56.7157(60.2466) | Bit/dim 3.7448(3.7952) | Xent 0.9292(1.0386) | Loss 9.9471(11.0137) | Error 0.3330(0.3712) Steps 682(683.26) | Grad Norm 1.4193(4.7626) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 25.3648, Epoch Time 400.7090(392.2213), Bit/dim 3.7603(best: 3.7583), Xent 1.1416, Loss 4.3311, Error 0.3996(best: 0.3992)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0751 | Time 59.5226(60.2249) | Bit/dim 3.7526(3.7940) | Xent 0.9325(1.0354) | Loss 17.4393(11.2065) | Error 0.3281(0.3699) Steps 706(683.94) | Grad Norm 1.2596(4.6575) | Total Time 0.00(0.00)\n",
      "Iter 0752 | Time 61.7271(60.2700) | Bit/dim 3.7634(3.7930) | Xent 0.9049(1.0315) | Loss 9.9696(11.1694) | Error 0.3260(0.3686) Steps 670(683.52) | Grad Norm 1.0637(4.5497) | Total Time 0.00(0.00)\n",
      "Iter 0753 | Time 56.7506(60.1644) | Bit/dim 3.7569(3.7920) | Xent 0.9194(1.0281) | Loss 9.8112(11.1286) | Error 0.3311(0.3674) Steps 652(682.58) | Grad Norm 1.9643(4.4722) | Total Time 0.00(0.00)\n",
      "Iter 0754 | Time 56.5811(60.0569) | Bit/dim 3.7492(3.7907) | Xent 0.9118(1.0247) | Loss 9.8845(11.0913) | Error 0.3254(0.3662) Steps 664(682.02) | Grad Norm 1.6982(4.3890) | Total Time 0.00(0.00)\n",
      "Iter 0755 | Time 57.3897(59.9769) | Bit/dim 3.7612(3.7898) | Xent 0.9109(1.0212) | Loss 10.1023(11.0617) | Error 0.3254(0.3650) Steps 682(682.02) | Grad Norm 1.5357(4.3034) | Total Time 0.00(0.00)\n",
      "Iter 0756 | Time 62.6155(60.0560) | Bit/dim 3.7634(3.7890) | Xent 0.8952(1.0175) | Loss 9.9229(11.0275) | Error 0.3207(0.3636) Steps 646(680.94) | Grad Norm 1.5003(4.2193) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 25.9792, Epoch Time 398.7819(392.4181), Bit/dim 3.7605(best: 3.7583), Xent 1.1434, Loss 4.3322, Error 0.4028(best: 0.3992)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0757 | Time 58.9581(60.0231) | Bit/dim 3.7476(3.7878) | Xent 0.9081(1.0142) | Loss 14.4701(11.1308) | Error 0.3249(0.3625) Steps 682(680.97) | Grad Norm 1.1774(4.1280) | Total Time 0.00(0.00)\n",
      "Iter 0758 | Time 58.2335(59.9694) | Bit/dim 3.7451(3.7865) | Xent 0.8997(1.0107) | Loss 9.8927(11.0936) | Error 0.3266(0.3614) Steps 676(680.82) | Grad Norm 1.5657(4.0511) | Total Time 0.00(0.00)\n",
      "Iter 0759 | Time 56.2197(59.8569) | Bit/dim 3.7637(3.7858) | Xent 0.8800(1.0068) | Loss 9.6584(11.0506) | Error 0.3097(0.3598) Steps 682(680.86) | Grad Norm 1.3810(3.9710) | Total Time 0.00(0.00)\n",
      "Iter 0760 | Time 60.9626(59.8901) | Bit/dim 3.7511(3.7848) | Xent 0.9068(1.0038) | Loss 9.8952(11.0159) | Error 0.3267(0.3589) Steps 676(680.71) | Grad Norm 0.9918(3.8817) | Total Time 0.00(0.00)\n",
      "Iter 0761 | Time 59.2062(59.8696) | Bit/dim 3.7622(3.7841) | Xent 0.9170(1.0012) | Loss 10.1114(10.9888) | Error 0.3296(0.3580) Steps 664(680.21) | Grad Norm 1.0204(3.7958) | Total Time 0.00(0.00)\n",
      "Iter 0762 | Time 55.8155(59.7479) | Bit/dim 3.7522(3.7831) | Xent 0.8924(0.9980) | Loss 9.8100(10.9534) | Error 0.3269(0.3570) Steps 682(680.26) | Grad Norm 1.3178(3.7215) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 24.8701, Epoch Time 391.8304(392.4005), Bit/dim 3.7565(best: 3.7583), Xent 1.1485, Loss 4.3307, Error 0.4004(best: 0.3992)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0763 | Time 58.6995(59.7165) | Bit/dim 3.7603(3.7824) | Xent 0.9104(0.9953) | Loss 15.0865(11.0774) | Error 0.3269(0.3561) Steps 682(680.32) | Grad Norm 1.4753(3.6541) | Total Time 0.00(0.00)\n",
      "Iter 0764 | Time 59.6328(59.7140) | Bit/dim 3.7464(3.7814) | Xent 0.8816(0.9919) | Loss 9.8836(11.0416) | Error 0.3151(0.3549) Steps 682(680.37) | Grad Norm 1.2446(3.5818) | Total Time 0.00(0.00)\n",
      "Iter 0765 | Time 61.4359(59.7656) | Bit/dim 3.7543(3.7805) | Xent 0.8849(0.9887) | Loss 10.1112(11.0137) | Error 0.3214(0.3539) Steps 682(680.42) | Grad Norm 0.8647(3.5003) | Total Time 0.00(0.00)\n",
      "Iter 0766 | Time 58.6975(59.7336) | Bit/dim 3.7631(3.7800) | Xent 0.8961(0.9859) | Loss 9.8196(10.9779) | Error 0.3234(0.3530) Steps 688(680.64) | Grad Norm 1.1515(3.4298) | Total Time 0.00(0.00)\n",
      "Iter 0767 | Time 58.8501(59.7071) | Bit/dim 3.7577(3.7794) | Xent 0.8917(0.9831) | Loss 9.9720(10.9477) | Error 0.3211(0.3520) Steps 670(680.32) | Grad Norm 1.3161(3.3664) | Total Time 0.00(0.00)\n",
      "Iter 0768 | Time 62.7811(59.7993) | Bit/dim 3.7522(3.7785) | Xent 0.8720(0.9798) | Loss 10.0178(10.9198) | Error 0.3095(0.3508) Steps 676(680.19) | Grad Norm 1.1951(3.3013) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 25.2179, Epoch Time 403.3656(392.7294), Bit/dim 3.7569(best: 3.7565), Xent 1.1475, Loss 4.3306, Error 0.4000(best: 0.3992)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0769 | Time 57.8640(59.7412) | Bit/dim 3.7575(3.7779) | Xent 0.8796(0.9768) | Loss 15.5041(11.0573) | Error 0.3156(0.3497) Steps 682(680.25) | Grad Norm 1.3203(3.2419) | Total Time 0.00(0.00)\n",
      "Iter 0770 | Time 59.5117(59.7344) | Bit/dim 3.7435(3.7769) | Xent 0.8874(0.9741) | Loss 9.8946(11.0224) | Error 0.3190(0.3488) Steps 682(680.30) | Grad Norm 0.7454(3.1670) | Total Time 0.00(0.00)\n",
      "Iter 0771 | Time 58.7367(59.7044) | Bit/dim 3.7525(3.7761) | Xent 0.8733(0.9711) | Loss 9.8344(10.9868) | Error 0.3151(0.3478) Steps 682(680.35) | Grad Norm 1.3614(3.1128) | Total Time 0.00(0.00)\n",
      "Iter 0772 | Time 56.7321(59.6153) | Bit/dim 3.7540(3.7755) | Xent 0.8816(0.9684) | Loss 9.4102(10.9395) | Error 0.3157(0.3468) Steps 658(679.68) | Grad Norm 1.6838(3.0699) | Total Time 0.00(0.00)\n",
      "Iter 0773 | Time 60.9134(59.6542) | Bit/dim 3.7473(3.7746) | Xent 0.8704(0.9654) | Loss 9.9070(10.9085) | Error 0.3084(0.3457) Steps 700(680.29) | Grad Norm 1.6182(3.0264) | Total Time 0.00(0.00)\n",
      "Iter 0774 | Time 56.2030(59.5507) | Bit/dim 3.7537(3.7740) | Xent 0.8660(0.9625) | Loss 9.7940(10.8751) | Error 0.3103(0.3446) Steps 676(680.16) | Grad Norm 0.7832(2.9591) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 25.3312, Epoch Time 393.6618(392.7574), Bit/dim 3.7552(best: 3.7565), Xent 1.1545, Loss 4.3325, Error 0.4006(best: 0.3992)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0775 | Time 61.3619(59.6050) | Bit/dim 3.7573(3.7735) | Xent 0.8563(0.9593) | Loss 15.3751(11.0101) | Error 0.3043(0.3434) Steps 682(680.22) | Grad Norm 0.9430(2.8986) | Total Time 0.00(0.00)\n",
      "Iter 0776 | Time 59.2571(59.5946) | Bit/dim 3.7545(3.7729) | Xent 0.8655(0.9565) | Loss 9.9641(10.9787) | Error 0.3127(0.3425) Steps 676(680.09) | Grad Norm 1.3433(2.8519) | Total Time 0.00(0.00)\n",
      "Iter 0777 | Time 60.3975(59.6187) | Bit/dim 3.7492(3.7722) | Xent 0.8595(0.9535) | Loss 9.6609(10.9392) | Error 0.3006(0.3412) Steps 682(680.15) | Grad Norm 1.1058(2.7995) | Total Time 0.00(0.00)\n",
      "Iter 0778 | Time 57.8747(59.5663) | Bit/dim 3.7530(3.7716) | Xent 0.8581(0.9507) | Loss 9.8158(10.9055) | Error 0.3057(0.3401) Steps 676(680.02) | Grad Norm 0.8887(2.7422) | Total Time 0.00(0.00)\n",
      "Iter 0779 | Time 58.5097(59.5346) | Bit/dim 3.7394(3.7707) | Xent 0.8582(0.9479) | Loss 9.8842(10.8748) | Error 0.3101(0.3392) Steps 664(679.54) | Grad Norm 0.9324(2.6879) | Total Time 0.00(0.00)\n",
      "Iter 0780 | Time 56.2684(59.4367) | Bit/dim 3.7466(3.7700) | Xent 0.8775(0.9458) | Loss 9.9003(10.8456) | Error 0.3197(0.3387) Steps 658(678.90) | Grad Norm 0.8371(2.6324) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 25.3537, Epoch Time 397.9363(392.9128), Bit/dim 3.7523(best: 3.7552), Xent 1.1620, Loss 4.3333, Error 0.3990(best: 0.3992)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0781 | Time 56.4312(59.3465) | Bit/dim 3.7485(3.7693) | Xent 0.8446(0.9428) | Loss 15.9502(10.9987) | Error 0.3020(0.3376) Steps 670(678.63) | Grad Norm 0.8721(2.5796) | Total Time 0.00(0.00)\n",
      "Iter 0782 | Time 60.6391(59.3853) | Bit/dim 3.7431(3.7685) | Xent 0.8644(0.9404) | Loss 9.6985(10.9597) | Error 0.3127(0.3368) Steps 688(678.91) | Grad Norm 1.0799(2.5346) | Total Time 0.00(0.00)\n",
      "Iter 0783 | Time 57.1808(59.3191) | Bit/dim 3.7436(3.7678) | Xent 0.8461(0.9376) | Loss 9.5472(10.9174) | Error 0.3031(0.3358) Steps 670(678.64) | Grad Norm 0.9533(2.4872) | Total Time 0.00(0.00)\n",
      "Iter 0784 | Time 59.1084(59.3128) | Bit/dim 3.7522(3.7673) | Xent 0.8548(0.9351) | Loss 9.9324(10.8878) | Error 0.3071(0.3349) Steps 670(678.38) | Grad Norm 1.0410(2.4438) | Total Time 0.00(0.00)\n",
      "Iter 0785 | Time 58.8299(59.2983) | Bit/dim 3.7529(3.7669) | Xent 0.8502(0.9326) | Loss 9.8715(10.8573) | Error 0.3040(0.3340) Steps 646(677.41) | Grad Norm 1.1100(2.4038) | Total Time 0.00(0.00)\n",
      "Iter 0786 | Time 62.2610(59.3872) | Bit/dim 3.7596(3.7667) | Xent 0.8419(0.9298) | Loss 9.9500(10.8301) | Error 0.3026(0.3331) Steps 670(677.19) | Grad Norm 1.1645(2.3666) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 25.2742, Epoch Time 399.0342(393.0964), Bit/dim 3.7545(best: 3.7523), Xent 1.1665, Loss 4.3377, Error 0.3997(best: 0.3990)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0787 | Time 59.6215(59.3942) | Bit/dim 3.7532(3.7663) | Xent 0.8664(0.9279) | Loss 14.7710(10.9483) | Error 0.3077(0.3323) Steps 682(677.33) | Grad Norm 0.9594(2.3244) | Total Time 0.00(0.00)\n",
      "Iter 0788 | Time 63.8712(59.5285) | Bit/dim 3.7433(3.7656) | Xent 0.8342(0.9251) | Loss 9.9799(10.9193) | Error 0.3015(0.3314) Steps 688(677.65) | Grad Norm 1.1407(2.2889) | Total Time 0.00(0.00)\n",
      "Iter 0789 | Time 56.2299(59.4296) | Bit/dim 3.7439(3.7649) | Xent 0.8542(0.9230) | Loss 9.8962(10.8886) | Error 0.3049(0.3306) Steps 700(678.32) | Grad Norm 1.4221(2.2629) | Total Time 0.00(0.00)\n",
      "Iter 0790 | Time 63.4175(59.5492) | Bit/dim 3.7524(3.7645) | Xent 0.8237(0.9200) | Loss 10.0349(10.8630) | Error 0.3007(0.3297) Steps 670(678.08) | Grad Norm 0.7641(2.2179) | Total Time 0.00(0.00)\n",
      "Iter 0791 | Time 60.4421(59.5760) | Bit/dim 3.7509(3.7641) | Xent 0.8488(0.9179) | Loss 9.8123(10.8314) | Error 0.2980(0.3287) Steps 682(678.19) | Grad Norm 1.0182(2.1819) | Total Time 0.00(0.00)\n",
      "Iter 0792 | Time 56.8934(59.4955) | Bit/dim 3.7629(3.7641) | Xent 0.8520(0.9159) | Loss 9.9363(10.8046) | Error 0.3020(0.3279) Steps 670(677.95) | Grad Norm 0.9198(2.1440) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 25.3907, Epoch Time 404.4642(393.4375), Bit/dim 3.7484(best: 3.7523), Xent 1.1666, Loss 4.3318, Error 0.3993(best: 0.3990)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0793 | Time 61.8793(59.5670) | Bit/dim 3.7508(3.7637) | Xent 0.8396(0.9136) | Loss 14.9940(10.9303) | Error 0.3043(0.3272) Steps 688(678.25) | Grad Norm 1.5771(2.1270) | Total Time 0.00(0.00)\n",
      "Iter 0794 | Time 61.0451(59.6114) | Bit/dim 3.7413(3.7630) | Xent 0.8336(0.9112) | Loss 9.9152(10.8998) | Error 0.2977(0.3264) Steps 682(678.36) | Grad Norm 1.0720(2.0954) | Total Time 0.00(0.00)\n",
      "Iter 0795 | Time 60.8025(59.6471) | Bit/dim 3.7350(3.7622) | Xent 0.8225(0.9085) | Loss 9.5330(10.8588) | Error 0.2970(0.3255) Steps 664(677.93) | Grad Norm 0.8585(2.0583) | Total Time 0.00(0.00)\n",
      "Iter 0796 | Time 62.5599(59.7345) | Bit/dim 3.7558(3.7620) | Xent 0.8326(0.9063) | Loss 9.9060(10.8302) | Error 0.2966(0.3246) Steps 664(677.51) | Grad Norm 0.8924(2.0233) | Total Time 0.00(0.00)\n",
      "Iter 0797 | Time 61.7084(59.7937) | Bit/dim 3.7523(3.7617) | Xent 0.8336(0.9041) | Loss 9.8106(10.7996) | Error 0.2976(0.3238) Steps 712(678.55) | Grad Norm 0.9326(1.9906) | Total Time 0.00(0.00)\n",
      "Iter 0798 | Time 60.4287(59.8128) | Bit/dim 3.7384(3.7610) | Xent 0.8497(0.9025) | Loss 9.9112(10.7730) | Error 0.3083(0.3233) Steps 652(677.75) | Grad Norm 0.8317(1.9558) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 24.9947, Epoch Time 411.4966(393.9792), Bit/dim 3.7481(best: 3.7484), Xent 1.1711, Loss 4.3336, Error 0.3963(best: 0.3990)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0799 | Time 58.4777(59.7727) | Bit/dim 3.7508(3.7607) | Xent 0.8272(0.9002) | Loss 15.6133(10.9182) | Error 0.2963(0.3225) Steps 682(677.88) | Grad Norm 0.7518(1.9197) | Total Time 0.00(0.00)\n",
      "Iter 0800 | Time 63.0930(59.8723) | Bit/dim 3.7582(3.7606) | Xent 0.8583(0.8989) | Loss 10.0601(10.8925) | Error 0.3110(0.3222) Steps 688(678.18) | Grad Norm 1.1792(1.8975) | Total Time 0.00(0.00)\n",
      "Iter 0801 | Time 58.1944(59.8220) | Bit/dim 3.7479(3.7602) | Xent 0.8139(0.8964) | Loss 9.8558(10.8614) | Error 0.2949(0.3214) Steps 670(677.94) | Grad Norm 1.3596(1.8813) | Total Time 0.00(0.00)\n",
      "Iter 0802 | Time 58.5696(59.7844) | Bit/dim 3.7491(3.7599) | Xent 0.8478(0.8949) | Loss 9.8142(10.8299) | Error 0.3039(0.3208) Steps 670(677.70) | Grad Norm 0.7588(1.8477) | Total Time 0.00(0.00)\n",
      "Iter 0803 | Time 59.1660(59.7659) | Bit/dim 3.7449(3.7595) | Xent 0.8473(0.8935) | Loss 9.7832(10.7985) | Error 0.3045(0.3203) Steps 634(676.39) | Grad Norm 0.8269(1.8170) | Total Time 0.00(0.00)\n",
      "Iter 0804 | Time 59.9186(59.7704) | Bit/dim 3.7380(3.7588) | Xent 0.8628(0.8926) | Loss 9.8179(10.7691) | Error 0.3064(0.3199) Steps 664(676.02) | Grad Norm 1.3225(1.8022) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 25.0645, Epoch Time 401.3407(394.2001), Bit/dim 3.7488(best: 3.7481), Xent 1.1730, Loss 4.3353, Error 0.4023(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0805 | Time 59.6203(59.7659) | Bit/dim 3.7417(3.7583) | Xent 0.8328(0.8908) | Loss 14.7719(10.8892) | Error 0.2975(0.3192) Steps 682(676.20) | Grad Norm 0.8855(1.7747) | Total Time 0.00(0.00)\n",
      "Iter 0806 | Time 62.9061(59.8601) | Bit/dim 3.7453(3.7579) | Xent 0.8240(0.8888) | Loss 9.7837(10.8560) | Error 0.2977(0.3186) Steps 694(676.73) | Grad Norm 1.1726(1.7566) | Total Time 0.00(0.00)\n",
      "Iter 0807 | Time 61.3269(59.9041) | Bit/dim 3.7546(3.7578) | Xent 0.8499(0.8876) | Loss 10.0084(10.8306) | Error 0.3035(0.3181) Steps 688(677.07) | Grad Norm 0.9783(1.7333) | Total Time 0.00(0.00)\n",
      "Iter 0808 | Time 57.0164(59.8175) | Bit/dim 3.7392(3.7572) | Xent 0.8638(0.8869) | Loss 9.8322(10.8007) | Error 0.3185(0.3182) Steps 664(676.68) | Grad Norm 1.0685(1.7133) | Total Time 0.00(0.00)\n",
      "Iter 0809 | Time 58.4136(59.7754) | Bit/dim 3.7471(3.7569) | Xent 0.8436(0.8856) | Loss 9.7373(10.7688) | Error 0.3029(0.3177) Steps 688(677.02) | Grad Norm 1.1841(1.6975) | Total Time 0.00(0.00)\n",
      "Iter 0810 | Time 61.5979(59.8301) | Bit/dim 3.7520(3.7568) | Xent 0.8442(0.8844) | Loss 9.8265(10.7405) | Error 0.2996(0.3172) Steps 724(678.42) | Grad Norm 1.1453(1.6809) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 25.0023, Epoch Time 404.9057(394.5212), Bit/dim 3.7466(best: 3.7481), Xent 1.1744, Loss 4.3337, Error 0.3981(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0811 | Time 62.5716(59.9123) | Bit/dim 3.7505(3.7566) | Xent 0.8517(0.8834) | Loss 14.5893(10.8560) | Error 0.3090(0.3169) Steps 658(677.81) | Grad Norm 1.2241(1.6672) | Total Time 0.00(0.00)\n",
      "Iter 0812 | Time 59.4747(59.8992) | Bit/dim 3.7453(3.7563) | Xent 0.8394(0.8821) | Loss 9.6511(10.8198) | Error 0.2974(0.3163) Steps 670(677.58) | Grad Norm 0.9018(1.6442) | Total Time 0.00(0.00)\n",
      "Iter 0813 | Time 62.4662(59.9762) | Bit/dim 3.7570(3.7563) | Xent 0.8424(0.8809) | Loss 9.9166(10.7927) | Error 0.3069(0.3160) Steps 664(677.17) | Grad Norm 1.6300(1.6438) | Total Time 0.00(0.00)\n",
      "Iter 0814 | Time 57.2711(59.8950) | Bit/dim 3.7449(3.7559) | Xent 0.8338(0.8795) | Loss 9.8227(10.7636) | Error 0.3000(0.3156) Steps 664(676.78) | Grad Norm 1.2890(1.6332) | Total Time 0.00(0.00)\n",
      "Iter 0815 | Time 59.3221(59.8779) | Bit/dim 3.7490(3.7557) | Xent 0.8186(0.8776) | Loss 9.8693(10.7368) | Error 0.2945(0.3149) Steps 664(676.39) | Grad Norm 1.3634(1.6251) | Total Time 0.00(0.00)\n",
      "Iter 0816 | Time 60.1691(59.8866) | Bit/dim 3.7260(3.7548) | Xent 0.8335(0.8763) | Loss 9.7730(10.7079) | Error 0.2994(0.3145) Steps 664(676.02) | Grad Norm 1.3764(1.6176) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 25.0926, Epoch Time 404.8738(394.8318), Bit/dim 3.7506(best: 3.7466), Xent 1.1777, Loss 4.3394, Error 0.4000(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0817 | Time 59.0862(59.8626) | Bit/dim 3.7544(3.7548) | Xent 0.8328(0.8750) | Loss 14.6042(10.8248) | Error 0.3049(0.3142) Steps 652(675.30) | Grad Norm 1.5225(1.6148) | Total Time 0.00(0.00)\n",
      "Iter 0818 | Time 57.3642(59.7876) | Bit/dim 3.7390(3.7544) | Xent 0.8383(0.8739) | Loss 9.6775(10.7903) | Error 0.3007(0.3138) Steps 694(675.86) | Grad Norm 1.4960(1.6112) | Total Time 0.00(0.00)\n",
      "Iter 0819 | Time 61.3556(59.8347) | Bit/dim 3.7502(3.7542) | Xent 0.8150(0.8721) | Loss 9.8493(10.7621) | Error 0.2977(0.3133) Steps 676(675.86) | Grad Norm 0.9278(1.5907) | Total Time 0.00(0.00)\n",
      "Iter 0820 | Time 59.3515(59.8202) | Bit/dim 3.7372(3.7537) | Xent 0.8163(0.8705) | Loss 9.7988(10.7332) | Error 0.2941(0.3127) Steps 676(675.87) | Grad Norm 1.8291(1.5978) | Total Time 0.00(0.00)\n",
      "Iter 0821 | Time 58.3789(59.7769) | Bit/dim 3.7368(3.7532) | Xent 0.8283(0.8692) | Loss 9.9198(10.7088) | Error 0.3003(0.3123) Steps 676(675.87) | Grad Norm 1.7826(1.6034) | Total Time 0.00(0.00)\n",
      "Iter 0822 | Time 58.1208(59.7273) | Bit/dim 3.7539(3.7532) | Xent 0.8497(0.8686) | Loss 9.6599(10.6773) | Error 0.3059(0.3122) Steps 694(676.42) | Grad Norm 1.1484(1.5897) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 25.2570, Epoch Time 398.0693(394.9289), Bit/dim 3.7421(best: 3.7466), Xent 1.1777, Loss 4.3310, Error 0.3984(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0823 | Time 57.8800(59.6718) | Bit/dim 3.7537(3.7533) | Xent 0.8315(0.8675) | Loss 14.5389(10.7932) | Error 0.2997(0.3118) Steps 676(676.40) | Grad Norm 0.8016(1.5661) | Total Time 0.00(0.00)\n",
      "Iter 0824 | Time 61.6902(59.7324) | Bit/dim 3.7379(3.7528) | Xent 0.8220(0.8661) | Loss 9.6652(10.7593) | Error 0.2961(0.3113) Steps 646(675.49) | Grad Norm 1.4458(1.5625) | Total Time 0.00(0.00)\n",
      "Iter 0825 | Time 59.4506(59.7239) | Bit/dim 3.7417(3.7525) | Xent 0.8372(0.8653) | Loss 9.8310(10.7315) | Error 0.3004(0.3110) Steps 688(675.87) | Grad Norm 0.8024(1.5397) | Total Time 0.00(0.00)\n",
      "Iter 0826 | Time 60.5548(59.7489) | Bit/dim 3.7394(3.7521) | Xent 0.8385(0.8645) | Loss 9.7919(10.7033) | Error 0.3017(0.3107) Steps 682(676.05) | Grad Norm 0.8323(1.5185) | Total Time 0.00(0.00)\n",
      "Iter 0827 | Time 60.5229(59.7721) | Bit/dim 3.7425(3.7518) | Xent 0.8205(0.8631) | Loss 9.8869(10.6788) | Error 0.2934(0.3102) Steps 670(675.87) | Grad Norm 1.2390(1.5101) | Total Time 0.00(0.00)\n",
      "Iter 0828 | Time 63.5853(59.8865) | Bit/dim 3.7472(3.7516) | Xent 0.8267(0.8621) | Loss 9.9315(10.6564) | Error 0.2984(0.3098) Steps 688(676.23) | Grad Norm 1.0531(1.4964) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 25.3102, Epoch Time 407.1648(395.2960), Bit/dim 3.7468(best: 3.7421), Xent 1.1831, Loss 4.3384, Error 0.3992(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0829 | Time 60.1900(59.8956) | Bit/dim 3.7429(3.7514) | Xent 0.8319(0.8611) | Loss 14.8096(10.7810) | Error 0.3033(0.3096) Steps 676(676.23) | Grad Norm 0.8016(1.4755) | Total Time 0.00(0.00)\n",
      "Iter 0830 | Time 61.0581(59.9305) | Bit/dim 3.7454(3.7512) | Xent 0.8200(0.8599) | Loss 9.5073(10.7428) | Error 0.2921(0.3091) Steps 646(675.32) | Grad Norm 0.9203(1.4589) | Total Time 0.00(0.00)\n",
      "Iter 0831 | Time 65.4497(60.0960) | Bit/dim 3.7465(3.7511) | Xent 0.8125(0.8585) | Loss 9.9293(10.7184) | Error 0.2939(0.3087) Steps 646(674.44) | Grad Norm 0.9886(1.4448) | Total Time 0.00(0.00)\n",
      "Iter 0832 | Time 63.3906(60.1949) | Bit/dim 3.7399(3.7507) | Xent 0.8266(0.8575) | Loss 9.9836(10.6963) | Error 0.2974(0.3083) Steps 664(674.13) | Grad Norm 1.1216(1.4351) | Total Time 0.00(0.00)\n",
      "Iter 0833 | Time 61.1877(60.2247) | Bit/dim 3.7473(3.7506) | Xent 0.8406(0.8570) | Loss 9.8238(10.6702) | Error 0.2987(0.3080) Steps 700(674.90) | Grad Norm 1.3173(1.4315) | Total Time 0.00(0.00)\n",
      "Iter 0834 | Time 62.4210(60.2905) | Bit/dim 3.7394(3.7503) | Xent 0.8175(0.8558) | Loss 9.8336(10.6451) | Error 0.2936(0.3076) Steps 652(674.22) | Grad Norm 0.9238(1.4163) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 24.7276, Epoch Time 416.8909(395.9439), Bit/dim 3.7464(best: 3.7421), Xent 1.1827, Loss 4.3378, Error 0.3976(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0835 | Time 61.4400(60.3250) | Bit/dim 3.7390(3.7499) | Xent 0.8204(0.8548) | Loss 15.3214(10.7854) | Error 0.2991(0.3073) Steps 676(674.27) | Grad Norm 0.7394(1.3960) | Total Time 0.00(0.00)\n",
      "Iter 0836 | Time 62.0732(60.3775) | Bit/dim 3.7422(3.7497) | Xent 0.8138(0.8535) | Loss 9.6737(10.7520) | Error 0.2925(0.3069) Steps 688(674.68) | Grad Norm 0.9592(1.3829) | Total Time 0.00(0.00)\n",
      "Iter 0837 | Time 60.9310(60.3941) | Bit/dim 3.7338(3.7492) | Xent 0.8113(0.8523) | Loss 9.7095(10.7207) | Error 0.2897(0.3064) Steps 688(675.08) | Grad Norm 1.3089(1.3807) | Total Time 0.00(0.00)\n",
      "Iter 0838 | Time 60.1050(60.3854) | Bit/dim 3.7449(3.7491) | Xent 0.8169(0.8512) | Loss 9.7307(10.6910) | Error 0.2941(0.3060) Steps 676(675.11) | Grad Norm 1.0226(1.3699) | Total Time 0.00(0.00)\n",
      "Iter 0839 | Time 59.9455(60.3722) | Bit/dim 3.7444(3.7490) | Xent 0.8017(0.8497) | Loss 9.8788(10.6667) | Error 0.2894(0.3055) Steps 646(674.24) | Grad Norm 0.9987(1.3588) | Total Time 0.00(0.00)\n",
      "Iter 0840 | Time 60.0466(60.3624) | Bit/dim 3.7469(3.7489) | Xent 0.8245(0.8490) | Loss 9.9649(10.6456) | Error 0.2965(0.3052) Steps 664(673.93) | Grad Norm 1.1512(1.3526) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 24.5784, Epoch Time 407.7383(396.2977), Bit/dim 3.7460(best: 3.7421), Xent 1.1929, Loss 4.3425, Error 0.4013(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0841 | Time 59.2193(60.3281) | Bit/dim 3.7407(3.7487) | Xent 0.8141(0.8479) | Loss 14.5060(10.7614) | Error 0.2954(0.3049) Steps 682(674.17) | Grad Norm 1.0773(1.3443) | Total Time 0.00(0.00)\n",
      "Iter 0842 | Time 59.6047(60.3064) | Bit/dim 3.7506(3.7487) | Xent 0.8050(0.8466) | Loss 9.9600(10.7374) | Error 0.2923(0.3046) Steps 706(675.13) | Grad Norm 1.1142(1.3374) | Total Time 0.00(0.00)\n",
      "Iter 0843 | Time 59.5524(60.2838) | Bit/dim 3.7434(3.7486) | Xent 0.7943(0.8451) | Loss 9.9383(10.7134) | Error 0.2875(0.3041) Steps 676(675.15) | Grad Norm 1.2640(1.3352) | Total Time 0.00(0.00)\n",
      "Iter 0844 | Time 62.4687(60.3494) | Bit/dim 3.7412(3.7483) | Xent 0.8112(0.8441) | Loss 9.7742(10.6852) | Error 0.2945(0.3038) Steps 664(674.82) | Grad Norm 1.1954(1.3310) | Total Time 0.00(0.00)\n",
      "Iter 0845 | Time 59.9431(60.3372) | Bit/dim 3.7386(3.7480) | Xent 0.8124(0.8431) | Loss 9.4139(10.6471) | Error 0.2945(0.3035) Steps 670(674.67) | Grad Norm 1.2911(1.3298) | Total Time 0.00(0.00)\n",
      "Iter 0846 | Time 59.1275(60.3009) | Bit/dim 3.7429(3.7479) | Xent 0.7837(0.8413) | Loss 9.8116(10.6220) | Error 0.2801(0.3028) Steps 658(674.17) | Grad Norm 1.1056(1.3231) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0141 | Time 25.0559, Epoch Time 403.2934(396.5076), Bit/dim 3.7444(best: 3.7421), Xent 1.1992, Loss 4.3440, Error 0.4014(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0847 | Time 58.5947(60.2497) | Bit/dim 3.7433(3.7478) | Xent 0.7948(0.8399) | Loss 14.7957(10.7472) | Error 0.2835(0.3022) Steps 670(674.05) | Grad Norm 0.8158(1.3079) | Total Time 0.00(0.00)\n",
      "Iter 0848 | Time 58.5366(60.1983) | Bit/dim 3.7409(3.7475) | Xent 0.7991(0.8387) | Loss 9.8022(10.7189) | Error 0.2849(0.3017) Steps 670(673.93) | Grad Norm 1.9649(1.3276) | Total Time 0.00(0.00)\n",
      "Iter 0849 | Time 59.6776(60.1827) | Bit/dim 3.7561(3.7478) | Xent 0.8311(0.8385) | Loss 9.8532(10.6929) | Error 0.2964(0.3015) Steps 682(674.17) | Grad Norm 0.8569(1.3135) | Total Time 0.00(0.00)\n",
      "Iter 0850 | Time 54.8137(60.0216) | Bit/dim 3.7405(3.7476) | Xent 0.8030(0.8374) | Loss 9.6050(10.6603) | Error 0.2921(0.3012) Steps 640(673.14) | Grad Norm 0.9853(1.3036) | Total Time 0.00(0.00)\n",
      "Iter 0851 | Time 59.0226(59.9916) | Bit/dim 3.7373(3.7473) | Xent 0.7954(0.8361) | Loss 9.9559(10.6391) | Error 0.2825(0.3007) Steps 682(673.41) | Grad Norm 0.9499(1.2930) | Total Time 0.00(0.00)\n",
      "Iter 0852 | Time 59.2083(59.9681) | Bit/dim 3.7315(3.7468) | Xent 0.7932(0.8349) | Loss 9.8697(10.6161) | Error 0.2915(0.3004) Steps 688(673.85) | Grad Norm 0.8890(1.2809) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0142 | Time 24.8153, Epoch Time 393.1641(396.4073), Bit/dim 3.7499(best: 3.7421), Xent 1.1902, Loss 4.3450, Error 0.3954(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0853 | Time 61.7702(60.0222) | Bit/dim 3.7447(3.7467) | Xent 0.7863(0.8334) | Loss 15.0639(10.7495) | Error 0.2877(0.3000) Steps 670(673.73) | Grad Norm 1.0620(1.2743) | Total Time 0.00(0.00)\n",
      "Iter 0854 | Time 59.7161(60.0130) | Bit/dim 3.7417(3.7466) | Xent 0.8143(0.8328) | Loss 9.8749(10.7233) | Error 0.2890(0.2997) Steps 700(674.52) | Grad Norm 0.9956(1.2660) | Total Time 0.00(0.00)\n",
      "Iter 0855 | Time 57.6832(59.9431) | Bit/dim 3.7370(3.7463) | Xent 0.8154(0.8323) | Loss 9.7832(10.6951) | Error 0.2947(0.2996) Steps 640(673.48) | Grad Norm 0.9500(1.2565) | Total Time 0.00(0.00)\n",
      "Iter 0856 | Time 56.5362(59.8409) | Bit/dim 3.7358(3.7460) | Xent 0.7911(0.8311) | Loss 9.8043(10.6683) | Error 0.2880(0.2992) Steps 670(673.38) | Grad Norm 1.3371(1.2589) | Total Time 0.00(0.00)\n",
      "Iter 0857 | Time 58.2105(59.7920) | Bit/dim 3.7426(3.7459) | Xent 0.7993(0.8301) | Loss 9.7853(10.6418) | Error 0.2865(0.2988) Steps 682(673.64) | Grad Norm 1.6662(1.2711) | Total Time 0.00(0.00)\n",
      "Iter 0858 | Time 59.2607(59.7761) | Bit/dim 3.7330(3.7455) | Xent 0.7886(0.8289) | Loss 9.8302(10.6175) | Error 0.2863(0.2984) Steps 694(674.25) | Grad Norm 1.2328(1.2700) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0143 | Time 24.7299, Epoch Time 395.6007(396.3831), Bit/dim 3.7440(best: 3.7421), Xent 1.1950, Loss 4.3414, Error 0.3965(best: 0.3954)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0859 | Time 59.6990(59.7738) | Bit/dim 3.7418(3.7454) | Xent 0.7808(0.8274) | Loss 14.9844(10.7485) | Error 0.2860(0.2981) Steps 682(674.48) | Grad Norm 0.9427(1.2601) | Total Time 0.00(0.00)\n",
      "Iter 0860 | Time 62.8227(59.8652) | Bit/dim 3.7392(3.7452) | Xent 0.7785(0.8260) | Loss 9.9670(10.7250) | Error 0.2779(0.2975) Steps 664(674.17) | Grad Norm 1.0131(1.2527) | Total Time 0.00(0.00)\n",
      "Iter 0861 | Time 62.1747(59.9345) | Bit/dim 3.7377(3.7450) | Xent 0.8106(0.8255) | Loss 9.6760(10.6936) | Error 0.2954(0.2974) Steps 676(674.22) | Grad Norm 1.3111(1.2545) | Total Time 0.00(0.00)\n",
      "Iter 0862 | Time 56.1995(59.8225) | Bit/dim 3.7458(3.7450) | Xent 0.7901(0.8244) | Loss 9.4492(10.6562) | Error 0.2856(0.2971) Steps 658(673.73) | Grad Norm 1.1727(1.2520) | Total Time 0.00(0.00)\n",
      "Iter 0863 | Time 63.4610(59.9316) | Bit/dim 3.7294(3.7445) | Xent 0.8087(0.8240) | Loss 9.9996(10.6365) | Error 0.2966(0.2970) Steps 688(674.16) | Grad Norm 1.2075(1.2507) | Total Time 0.00(0.00)\n",
      "Iter 0864 | Time 59.1684(59.9087) | Bit/dim 3.7427(3.7445) | Xent 0.7898(0.8229) | Loss 9.8065(10.6116) | Error 0.2833(0.2966) Steps 664(673.86) | Grad Norm 1.1979(1.2491) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0144 | Time 24.7003, Epoch Time 406.8290(396.6965), Bit/dim 3.7472(best: 3.7421), Xent 1.1989, Loss 4.3466, Error 0.3956(best: 0.3954)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0865 | Time 58.7135(59.8729) | Bit/dim 3.7554(3.7448) | Xent 0.7964(0.8221) | Loss 14.5411(10.7295) | Error 0.2855(0.2963) Steps 658(673.38) | Grad Norm 1.8809(1.2681) | Total Time 0.00(0.00)\n",
      "Iter 0866 | Time 53.3744(59.6779) | Bit/dim 3.7442(3.7448) | Xent 0.8127(0.8219) | Loss 9.5808(10.6951) | Error 0.2951(0.2963) Steps 652(672.74) | Grad Norm 1.5790(1.2774) | Total Time 0.00(0.00)\n",
      "Iter 0867 | Time 63.0282(59.7784) | Bit/dim 3.7414(3.7447) | Xent 0.7880(0.8208) | Loss 9.6752(10.6645) | Error 0.2804(0.2958) Steps 688(673.20) | Grad Norm 1.5304(1.2850) | Total Time 0.00(0.00)\n",
      "Iter 0868 | Time 59.9521(59.7836) | Bit/dim 3.7240(3.7441) | Xent 0.8074(0.8204) | Loss 9.9107(10.6419) | Error 0.2914(0.2956) Steps 688(673.64) | Grad Norm 0.9765(1.2757) | Total Time 0.00(0.00)\n",
      "Iter 0869 | Time 60.0271(59.7909) | Bit/dim 3.7301(3.7436) | Xent 0.7670(0.8188) | Loss 9.8368(10.6177) | Error 0.2772(0.2951) Steps 682(673.89) | Grad Norm 1.2709(1.2756) | Total Time 0.00(0.00)\n",
      "Iter 0870 | Time 60.6131(59.8156) | Bit/dim 3.7397(3.7435) | Xent 0.7736(0.8175) | Loss 9.7261(10.5910) | Error 0.2780(0.2946) Steps 694(674.50) | Grad Norm 1.1571(1.2720) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0145 | Time 25.1346, Epoch Time 399.1667(396.7706), Bit/dim 3.7404(best: 3.7421), Xent 1.2002, Loss 4.3405, Error 0.3972(best: 0.3954)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0871 | Time 60.7119(59.8425) | Bit/dim 3.7323(3.7432) | Xent 0.7816(0.8164) | Loss 15.3325(10.7332) | Error 0.2815(0.2942) Steps 700(675.26) | Grad Norm 0.9289(1.2617) | Total Time 0.00(0.00)\n",
      "Iter 0872 | Time 60.3068(59.8564) | Bit/dim 3.7339(3.7429) | Xent 0.7727(0.8151) | Loss 9.5717(10.6984) | Error 0.2748(0.2936) Steps 664(674.92) | Grad Norm 1.0072(1.2541) | Total Time 0.00(0.00)\n",
      "Iter 0873 | Time 60.8371(59.8858) | Bit/dim 3.7424(3.7429) | Xent 0.7804(0.8141) | Loss 9.7595(10.6702) | Error 0.2792(0.2932) Steps 676(674.96) | Grad Norm 1.4399(1.2597) | Total Time 0.00(0.00)\n",
      "Iter 0874 | Time 57.5437(59.8156) | Bit/dim 3.7382(3.7428) | Xent 0.7780(0.8130) | Loss 9.5644(10.6370) | Error 0.2764(0.2927) Steps 664(674.63) | Grad Norm 0.9345(1.2499) | Total Time 0.00(0.00)\n",
      "Iter 0875 | Time 59.6145(59.8095) | Bit/dim 3.7447(3.7428) | Xent 0.7986(0.8125) | Loss 9.5039(10.6030) | Error 0.2923(0.2927) Steps 658(674.13) | Grad Norm 1.5357(1.2585) | Total Time 0.00(0.00)\n",
      "Iter 0876 | Time 58.9475(59.7837) | Bit/dim 3.7369(3.7426) | Xent 0.7761(0.8114) | Loss 9.7456(10.5773) | Error 0.2837(0.2924) Steps 676(674.18) | Grad Norm 0.8655(1.2467) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0146 | Time 24.6959, Epoch Time 401.2972(396.9064), Bit/dim 3.7434(best: 3.7404), Xent 1.2138, Loss 4.3504, Error 0.3963(best: 0.3954)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0877 | Time 63.4230(59.8929) | Bit/dim 3.7426(3.7426) | Xent 0.7718(0.8103) | Loss 14.5749(10.6972) | Error 0.2768(0.2919) Steps 688(674.60) | Grad Norm 1.2950(1.2481) | Total Time 0.00(0.00)\n",
      "Iter 0878 | Time 61.3174(59.9356) | Bit/dim 3.7472(3.7428) | Xent 0.7640(0.8089) | Loss 9.8430(10.6716) | Error 0.2739(0.2914) Steps 658(674.10) | Grad Norm 1.9218(1.2684) | Total Time 0.00(0.00)\n",
      "Iter 0879 | Time 59.8447(59.9329) | Bit/dim 3.7382(3.7426) | Xent 0.7831(0.8081) | Loss 9.8201(10.6461) | Error 0.2844(0.2912) Steps 670(673.98) | Grad Norm 1.9470(1.2887) | Total Time 0.00(0.00)\n",
      "Iter 0880 | Time 61.1231(59.9686) | Bit/dim 3.7422(3.7426) | Xent 0.7882(0.8075) | Loss 9.6193(10.6153) | Error 0.2887(0.2911) Steps 706(674.94) | Grad Norm 1.8376(1.3052) | Total Time 0.00(0.00)\n",
      "Iter 0881 | Time 61.8458(60.0249) | Bit/dim 3.7333(3.7423) | Xent 0.7806(0.8067) | Loss 10.0214(10.5974) | Error 0.2758(0.2906) Steps 676(674.97) | Grad Norm 2.0599(1.3278) | Total Time 0.00(0.00)\n",
      "Iter 0882 | Time 61.0826(60.0566) | Bit/dim 3.7295(3.7420) | Xent 0.7834(0.8060) | Loss 9.4738(10.5637) | Error 0.2906(0.2906) Steps 670(674.82) | Grad Norm 1.7710(1.3411) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0147 | Time 25.0242, Epoch Time 412.3397(397.3694), Bit/dim 3.7467(best: 3.7404), Xent 1.2040, Loss 4.3487, Error 0.3997(best: 0.3954)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0883 | Time 59.2225(60.0316) | Bit/dim 3.7350(3.7417) | Xent 0.7671(0.8048) | Loss 14.5621(10.6837) | Error 0.2776(0.2902) Steps 676(674.86) | Grad Norm 1.1408(1.3351) | Total Time 0.00(0.00)\n",
      "Iter 0884 | Time 59.3111(60.0100) | Bit/dim 3.7372(3.7416) | Xent 0.7526(0.8033) | Loss 9.7791(10.6565) | Error 0.2711(0.2897) Steps 688(675.25) | Grad Norm 2.4738(1.3693) | Total Time 0.00(0.00)\n",
      "Iter 0885 | Time 58.0987(59.9526) | Bit/dim 3.7371(3.7415) | Xent 0.7751(0.8024) | Loss 9.7199(10.6284) | Error 0.2764(0.2893) Steps 682(675.45) | Grad Norm 3.2792(1.4266) | Total Time 0.00(0.00)\n",
      "Iter 0886 | Time 59.5541(59.9407) | Bit/dim 3.7469(3.7416) | Xent 0.7840(0.8019) | Loss 9.7548(10.6022) | Error 0.2901(0.2893) Steps 670(675.29) | Grad Norm 1.4595(1.4276) | Total Time 0.00(0.00)\n",
      "Iter 0887 | Time 58.3765(59.8938) | Bit/dim 3.7408(3.7416) | Xent 0.7679(0.8008) | Loss 9.8530(10.5798) | Error 0.2772(0.2889) Steps 664(674.95) | Grad Norm 2.9939(1.4745) | Total Time 0.00(0.00)\n",
      "Iter 0888 | Time 60.5652(59.9139) | Bit/dim 3.7263(3.7411) | Xent 0.7639(0.7997) | Loss 9.6314(10.5513) | Error 0.2755(0.2885) Steps 646(674.08) | Grad Norm 2.0522(1.4919) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0148 | Time 25.1884, Epoch Time 398.8339(397.4133), Bit/dim 3.7416(best: 3.7404), Xent 1.2199, Loss 4.3515, Error 0.4011(best: 0.3954)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0889 | Time 61.8300(59.9714) | Bit/dim 3.7464(3.7413) | Xent 0.7700(0.7988) | Loss 14.9964(10.6847) | Error 0.2756(0.2881) Steps 706(675.04) | Grad Norm 2.1433(1.5114) | Total Time 0.00(0.00)\n",
      "Iter 0890 | Time 58.7988(59.9362) | Bit/dim 3.7330(3.7411) | Xent 0.7632(0.7978) | Loss 9.7112(10.6555) | Error 0.2781(0.2878) Steps 682(675.25) | Grad Norm 2.3197(1.5357) | Total Time 0.00(0.00)\n",
      "Iter 0891 | Time 58.6428(59.8974) | Bit/dim 3.7275(3.7407) | Xent 0.7621(0.7967) | Loss 9.7675(10.6288) | Error 0.2771(0.2875) Steps 670(675.09) | Grad Norm 1.1796(1.5250) | Total Time 0.00(0.00)\n",
      "Iter 0892 | Time 61.0032(59.9306) | Bit/dim 3.7421(3.7407) | Xent 0.7611(0.7956) | Loss 9.9546(10.6086) | Error 0.2749(0.2871) Steps 664(674.76) | Grad Norm 2.9070(1.5664) | Total Time 0.00(0.00)\n",
      "Iter 0893 | Time 57.6600(59.8625) | Bit/dim 3.7322(3.7404) | Xent 0.7560(0.7944) | Loss 9.5221(10.5760) | Error 0.2712(0.2867) Steps 670(674.62) | Grad Norm 1.6803(1.5699) | Total Time 0.00(0.00)\n",
      "Iter 0894 | Time 57.1745(59.7818) | Bit/dim 3.7433(3.7405) | Xent 0.7690(0.7937) | Loss 9.6980(10.5497) | Error 0.2760(0.2863) Steps 670(674.48) | Grad Norm 2.7626(1.6056) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0149 | Time 25.1069, Epoch Time 398.8974(397.4578), Bit/dim 3.7458(best: 3.7404), Xent 1.2198, Loss 4.3557, Error 0.4005(best: 0.3954)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0895 | Time 62.6664(59.8684) | Bit/dim 3.7399(3.7405) | Xent 0.7652(0.7928) | Loss 14.6709(10.6733) | Error 0.2756(0.2860) Steps 682(674.70) | Grad Norm 2.7214(1.6391) | Total Time 0.00(0.00)\n",
      "Iter 0896 | Time 61.1892(59.9080) | Bit/dim 3.7361(3.7404) | Xent 0.7525(0.7916) | Loss 9.8180(10.6476) | Error 0.2695(0.2855) Steps 700(675.46) | Grad Norm 2.3024(1.6590) | Total Time 0.00(0.00)\n",
      "Iter 0897 | Time 64.3010(60.0398) | Bit/dim 3.7346(3.7402) | Xent 0.7814(0.7913) | Loss 9.8581(10.6239) | Error 0.2850(0.2855) Steps 652(674.76) | Grad Norm 3.1519(1.7038) | Total Time 0.00(0.00)\n",
      "Iter 0898 | Time 61.7652(60.0915) | Bit/dim 3.7415(3.7402) | Xent 0.7689(0.7906) | Loss 9.6157(10.5937) | Error 0.2768(0.2853) Steps 694(675.34) | Grad Norm 1.4537(1.6963) | Total Time 0.00(0.00)\n",
      "Iter 0899 | Time 58.8459(60.0542) | Bit/dim 3.7321(3.7400) | Xent 0.7494(0.7894) | Loss 9.5769(10.5632) | Error 0.2711(0.2848) Steps 664(675.00) | Grad Norm 2.7476(1.7278) | Total Time 0.00(0.00)\n",
      "Iter 0900 | Time 62.0315(60.1135) | Bit/dim 3.7385(3.7400) | Xent 0.7661(0.7887) | Loss 9.6024(10.5344) | Error 0.2808(0.2847) Steps 670(674.85) | Grad Norm 1.0736(1.7082) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0150 | Time 25.1368, Epoch Time 414.4938(397.9689), Bit/dim 3.7413(best: 3.7404), Xent 1.2342, Loss 4.3584, Error 0.4019(best: 0.3954)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0901 | Time 57.7066(60.0413) | Bit/dim 3.7300(3.7397) | Xent 0.7291(0.7869) | Loss 14.7770(10.6617) | Error 0.2591(0.2839) Steps 664(674.52) | Grad Norm 1.5481(1.7034) | Total Time 0.00(0.00)\n",
      "Iter 0902 | Time 60.4610(60.0539) | Bit/dim 3.7383(3.7396) | Xent 0.7493(0.7858) | Loss 9.9445(10.6401) | Error 0.2689(0.2835) Steps 682(674.74) | Grad Norm 1.2086(1.6886) | Total Time 0.00(0.00)\n",
      "Iter 0903 | Time 60.4080(60.0645) | Bit/dim 3.7423(3.7397) | Xent 0.7560(0.7849) | Loss 9.6834(10.6114) | Error 0.2701(0.2831) Steps 664(674.42) | Grad Norm 1.2169(1.6744) | Total Time 0.00(0.00)\n",
      "Iter 0904 | Time 61.4543(60.1062) | Bit/dim 3.7381(3.7396) | Xent 0.7392(0.7835) | Loss 9.7895(10.5868) | Error 0.2721(0.2828) Steps 676(674.47) | Grad Norm 1.4139(1.6666) | Total Time 0.00(0.00)\n",
      "Iter 0905 | Time 60.7866(60.1266) | Bit/dim 3.7290(3.7393) | Xent 0.7709(0.7831) | Loss 9.8284(10.5640) | Error 0.2792(0.2827) Steps 664(674.16) | Grad Norm 1.1557(1.6513) | Total Time 0.00(0.00)\n",
      "Iter 0906 | Time 61.9567(60.1815) | Bit/dim 3.7376(3.7393) | Xent 0.7498(0.7821) | Loss 9.8028(10.5412) | Error 0.2676(0.2822) Steps 676(674.21) | Grad Norm 1.2504(1.6392) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0151 | Time 25.6743, Epoch Time 407.4021(398.2519), Bit/dim 3.7438(best: 3.7404), Xent 1.2408, Loss 4.3642, Error 0.4016(best: 0.3954)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0907 | Time 57.7390(60.1082) | Bit/dim 3.7471(3.7395) | Xent 0.7503(0.7812) | Loss 14.4400(10.6581) | Error 0.2692(0.2818) Steps 646(673.36) | Grad Norm 1.4027(1.6321) | Total Time 0.00(0.00)\n",
      "Iter 0908 | Time 63.2148(60.2014) | Bit/dim 3.7332(3.7393) | Xent 0.7456(0.7801) | Loss 9.8106(10.6327) | Error 0.2658(0.2813) Steps 700(674.16) | Grad Norm 1.5009(1.6282) | Total Time 0.00(0.00)\n",
      "Iter 0909 | Time 65.0663(60.3474) | Bit/dim 3.7268(3.7389) | Xent 0.7294(0.7786) | Loss 9.8816(10.6102) | Error 0.2641(0.2808) Steps 646(673.32) | Grad Norm 1.8739(1.6356) | Total Time 0.00(0.00)\n",
      "Iter 0910 | Time 58.6295(60.2958) | Bit/dim 3.7266(3.7386) | Xent 0.7402(0.7774) | Loss 9.4623(10.5758) | Error 0.2749(0.2806) Steps 670(673.22) | Grad Norm 1.1186(1.6201) | Total Time 0.00(0.00)\n",
      "Iter 0911 | Time 61.9005(60.3440) | Bit/dim 3.7406(3.7386) | Xent 0.7603(0.7769) | Loss 9.6075(10.5467) | Error 0.2761(0.2805) Steps 688(673.66) | Grad Norm 2.3608(1.6423) | Total Time 0.00(0.00)\n",
      "Iter 0912 | Time 56.4969(60.2286) | Bit/dim 3.7413(3.7387) | Xent 0.7242(0.7753) | Loss 9.8837(10.5268) | Error 0.2621(0.2799) Steps 682(673.91) | Grad Norm 1.1795(1.6284) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0152 | Time 24.6714, Epoch Time 406.1849(398.4899), Bit/dim 3.7455(best: 3.7404), Xent 1.2368, Loss 4.3639, Error 0.3949(best: 0.3954)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0913 | Time 57.6984(60.1527) | Bit/dim 3.7356(3.7386) | Xent 0.7597(0.7749) | Loss 14.9778(10.6603) | Error 0.2770(0.2799) Steps 670(673.80) | Grad Norm 1.7227(1.6312) | Total Time 0.00(0.00)\n",
      "Iter 0914 | Time 61.1434(60.1824) | Bit/dim 3.7385(3.7386) | Xent 0.7364(0.7737) | Loss 9.8851(10.6371) | Error 0.2662(0.2795) Steps 670(673.68) | Grad Norm 1.4043(1.6244) | Total Time 0.00(0.00)\n",
      "Iter 0915 | Time 64.8499(60.3224) | Bit/dim 3.7416(3.7387) | Xent 0.7237(0.7722) | Loss 9.8602(10.6138) | Error 0.2602(0.2789) Steps 670(673.57) | Grad Norm 2.2982(1.6446) | Total Time 0.00(0.00)\n",
      "Iter 0916 | Time 60.1950(60.3186) | Bit/dim 3.7290(3.7384) | Xent 0.7357(0.7711) | Loss 9.7886(10.5890) | Error 0.2676(0.2785) Steps 670(673.46) | Grad Norm 1.4495(1.6388) | Total Time 0.00(0.00)\n",
      "Iter 0917 | Time 59.4197(60.2916) | Bit/dim 3.7476(3.7387) | Xent 0.7316(0.7699) | Loss 9.6293(10.5602) | Error 0.2616(0.2780) Steps 664(673.18) | Grad Norm 2.7886(1.6733) | Total Time 0.00(0.00)\n",
      "Iter 0918 | Time 61.7196(60.3345) | Bit/dim 3.7312(3.7385) | Xent 0.7535(0.7694) | Loss 9.7841(10.5370) | Error 0.2762(0.2780) Steps 688(673.62) | Grad Norm 1.4022(1.6652) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0153 | Time 25.4365, Epoch Time 408.8900(398.8019), Bit/dim 3.7410(best: 3.7404), Xent 1.2338, Loss 4.3579, Error 0.3976(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0919 | Time 57.4575(60.2482) | Bit/dim 3.7335(3.7383) | Xent 0.7401(0.7686) | Loss 14.7257(10.6626) | Error 0.2669(0.2776) Steps 682(673.88) | Grad Norm 2.7187(1.6968) | Total Time 0.00(0.00)\n",
      "Iter 0920 | Time 57.3005(60.1597) | Bit/dim 3.7259(3.7379) | Xent 0.7361(0.7676) | Loss 9.6638(10.6327) | Error 0.2622(0.2772) Steps 670(673.76) | Grad Norm 2.2187(1.7124) | Total Time 0.00(0.00)\n",
      "Iter 0921 | Time 58.4406(60.1082) | Bit/dim 3.7421(3.7381) | Xent 0.7420(0.7668) | Loss 9.7948(10.6075) | Error 0.2715(0.2770) Steps 658(673.29) | Grad Norm 3.0779(1.7534) | Total Time 0.00(0.00)\n",
      "Iter 0922 | Time 58.8730(60.0711) | Bit/dim 3.7325(3.7379) | Xent 0.7250(0.7656) | Loss 9.8896(10.5860) | Error 0.2664(0.2767) Steps 676(673.37) | Grad Norm 2.0056(1.7609) | Total Time 0.00(0.00)\n",
      "Iter 0923 | Time 56.7621(59.9718) | Bit/dim 3.7455(3.7381) | Xent 0.7324(0.7646) | Loss 9.6532(10.5580) | Error 0.2660(0.2764) Steps 664(673.09) | Grad Norm 2.4819(1.7826) | Total Time 0.00(0.00)\n",
      "Iter 0924 | Time 59.7221(59.9643) | Bit/dim 3.7306(3.7379) | Xent 0.7338(0.7637) | Loss 9.7515(10.5338) | Error 0.2696(0.2762) Steps 688(673.53) | Grad Norm 2.0992(1.7921) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0154 | Time 24.8360, Epoch Time 391.1408(398.5721), Bit/dim 3.7400(best: 3.7404), Xent 1.2420, Loss 4.3610, Error 0.4021(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0925 | Time 59.9731(59.9646) | Bit/dim 3.7294(3.7377) | Xent 0.7335(0.7627) | Loss 14.5320(10.6537) | Error 0.2644(0.2758) Steps 694(674.15) | Grad Norm 2.4638(1.8122) | Total Time 0.00(0.00)\n",
      "Iter 0926 | Time 61.2836(60.0042) | Bit/dim 3.7305(3.7374) | Xent 0.7344(0.7619) | Loss 9.8355(10.6292) | Error 0.2680(0.2756) Steps 682(674.38) | Grad Norm 1.1546(1.7925) | Total Time 0.00(0.00)\n",
      "Iter 0927 | Time 61.1398(60.0382) | Bit/dim 3.7232(3.7370) | Xent 0.7350(0.7611) | Loss 9.7035(10.6014) | Error 0.2715(0.2755) Steps 670(674.25) | Grad Norm 1.4352(1.7818) | Total Time 0.00(0.00)\n",
      "Iter 0928 | Time 61.2633(60.0750) | Bit/dim 3.7462(3.7373) | Xent 0.7248(0.7600) | Loss 9.7155(10.5749) | Error 0.2634(0.2751) Steps 670(674.12) | Grad Norm 2.0383(1.7895) | Total Time 0.00(0.00)\n",
      "Iter 0929 | Time 61.3423(60.1130) | Bit/dim 3.7444(3.7375) | Xent 0.7130(0.7586) | Loss 9.5591(10.5444) | Error 0.2554(0.2745) Steps 676(674.18) | Grad Norm 2.3615(1.8066) | Total Time 0.00(0.00)\n",
      "Iter 0930 | Time 59.2544(60.0873) | Bit/dim 3.7323(3.7373) | Xent 0.7317(0.7578) | Loss 9.6730(10.5182) | Error 0.2615(0.2741) Steps 700(674.96) | Grad Norm 1.7486(1.8049) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0155 | Time 24.6599, Epoch Time 408.0772(398.8572), Bit/dim 3.7419(best: 3.7400), Xent 1.2514, Loss 4.3676, Error 0.4009(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0931 | Time 62.0010(60.1447) | Bit/dim 3.7246(3.7370) | Xent 0.7281(0.7569) | Loss 15.1672(10.6577) | Error 0.2664(0.2739) Steps 700(675.71) | Grad Norm 2.1063(1.8139) | Total Time 0.00(0.00)\n",
      "Iter 0932 | Time 58.4804(60.0947) | Bit/dim 3.7436(3.7372) | Xent 0.7241(0.7559) | Loss 9.7315(10.6299) | Error 0.2614(0.2735) Steps 688(676.08) | Grad Norm 2.1133(1.8229) | Total Time 0.00(0.00)\n",
      "Iter 0933 | Time 60.2382(60.0990) | Bit/dim 3.7362(3.7371) | Xent 0.7156(0.7547) | Loss 9.6738(10.6012) | Error 0.2611(0.2731) Steps 700(676.79) | Grad Norm 1.3229(1.8079) | Total Time 0.00(0.00)\n",
      "Iter 0934 | Time 57.5428(60.0224) | Bit/dim 3.7304(3.7369) | Xent 0.7274(0.7539) | Loss 9.7342(10.5752) | Error 0.2580(0.2727) Steps 682(676.95) | Grad Norm 2.5274(1.8295) | Total Time 0.00(0.00)\n",
      "Iter 0935 | Time 58.7992(59.9857) | Bit/dim 3.7407(3.7370) | Xent 0.7209(0.7529) | Loss 9.7950(10.5518) | Error 0.2556(0.2722) Steps 688(677.28) | Grad Norm 2.4178(1.8472) | Total Time 0.00(0.00)\n",
      "Iter 0936 | Time 58.3597(59.9369) | Bit/dim 3.7421(3.7372) | Xent 0.7260(0.7521) | Loss 9.7731(10.5285) | Error 0.2628(0.2719) Steps 658(676.70) | Grad Norm 2.3942(1.8636) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0156 | Time 25.2118, Epoch Time 399.0854(398.8641), Bit/dim 3.7403(best: 3.7400), Xent 1.2668, Loss 4.3737, Error 0.4027(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0937 | Time 60.5744(59.9560) | Bit/dim 3.7405(3.7373) | Xent 0.7314(0.7515) | Loss 14.3650(10.6436) | Error 0.2718(0.2719) Steps 664(676.32) | Grad Norm 2.3107(1.8770) | Total Time 0.00(0.00)\n",
      "Iter 0938 | Time 61.6579(60.0071) | Bit/dim 3.7258(3.7369) | Xent 0.7126(0.7503) | Loss 9.5676(10.6113) | Error 0.2600(0.2715) Steps 688(676.67) | Grad Norm 1.7650(1.8736) | Total Time 0.00(0.00)\n",
      "Iter 0939 | Time 58.7410(59.9691) | Bit/dim 3.7316(3.7368) | Xent 0.7154(0.7493) | Loss 9.8669(10.5889) | Error 0.2590(0.2712) Steps 688(677.01) | Grad Norm 2.7155(1.8989) | Total Time 0.00(0.00)\n",
      "Iter 0940 | Time 60.6542(59.9896) | Bit/dim 3.7304(3.7366) | Xent 0.7175(0.7483) | Loss 9.8231(10.5660) | Error 0.2528(0.2706) Steps 682(677.16) | Grad Norm 2.6923(1.9227) | Total Time 0.00(0.00)\n",
      "Iter 0941 | Time 62.4669(60.0639) | Bit/dim 3.7361(3.7366) | Xent 0.6878(0.7465) | Loss 9.8116(10.5433) | Error 0.2431(0.2698) Steps 706(678.03) | Grad Norm 2.1419(1.9293) | Total Time 0.00(0.00)\n",
      "Iter 0942 | Time 60.1221(60.0657) | Bit/dim 3.7296(3.7364) | Xent 0.7266(0.7459) | Loss 9.5787(10.5144) | Error 0.2626(0.2696) Steps 682(678.15) | Grad Norm 1.8892(1.9281) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0157 | Time 24.7659, Epoch Time 407.8271(399.1329), Bit/dim 3.7415(best: 3.7400), Xent 1.2752, Loss 4.3791, Error 0.4049(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0943 | Time 60.9867(60.0933) | Bit/dim 3.7404(3.7365) | Xent 0.7006(0.7445) | Loss 14.0985(10.6219) | Error 0.2545(0.2691) Steps 694(678.62) | Grad Norm 2.8714(1.9564) | Total Time 0.00(0.00)\n",
      "Iter 0944 | Time 59.1467(60.0649) | Bit/dim 3.7309(3.7363) | Xent 0.7012(0.7432) | Loss 9.6486(10.5927) | Error 0.2504(0.2685) Steps 664(678.18) | Grad Norm 1.3691(1.9387) | Total Time 0.00(0.00)\n",
      "Iter 0945 | Time 60.3953(60.0748) | Bit/dim 3.7266(3.7360) | Xent 0.7174(0.7424) | Loss 9.5235(10.5606) | Error 0.2639(0.2684) Steps 676(678.12) | Grad Norm 1.9832(1.9401) | Total Time 0.00(0.00)\n",
      "Iter 0946 | Time 61.3907(60.1143) | Bit/dim 3.7283(3.7358) | Xent 0.7294(0.7421) | Loss 9.7843(10.5374) | Error 0.2630(0.2682) Steps 664(677.69) | Grad Norm 1.7578(1.9346) | Total Time 0.00(0.00)\n",
      "Iter 0947 | Time 56.7524(60.0135) | Bit/dim 3.7321(3.7357) | Xent 0.6947(0.7406) | Loss 9.7023(10.5123) | Error 0.2518(0.2677) Steps 652(676.92) | Grad Norm 2.8201(1.9612) | Total Time 0.00(0.00)\n",
      "Iter 0948 | Time 59.6049(60.0012) | Bit/dim 3.7344(3.7356) | Xent 0.7070(0.7396) | Loss 9.7583(10.4897) | Error 0.2556(0.2674) Steps 664(676.54) | Grad Norm 2.7519(1.9849) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0158 | Time 25.1039, Epoch Time 402.1384(399.2231), Bit/dim 3.7376(best: 3.7400), Xent 1.2767, Loss 4.3759, Error 0.3981(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0949 | Time 58.9027(59.9682) | Bit/dim 3.7288(3.7354) | Xent 0.7121(0.7388) | Loss 14.7829(10.6185) | Error 0.2530(0.2670) Steps 682(676.70) | Grad Norm 1.8149(1.9798) | Total Time 0.00(0.00)\n",
      "Iter 0950 | Time 62.8611(60.0550) | Bit/dim 3.7234(3.7351) | Xent 0.7077(0.7379) | Loss 9.6707(10.5900) | Error 0.2631(0.2668) Steps 700(677.40) | Grad Norm 2.1116(1.9837) | Total Time 0.00(0.00)\n",
      "Iter 0951 | Time 65.0266(60.2042) | Bit/dim 3.7399(3.7352) | Xent 0.7169(0.7372) | Loss 9.7738(10.5656) | Error 0.2552(0.2665) Steps 688(677.72) | Grad Norm 2.9396(2.0124) | Total Time 0.00(0.00)\n",
      "Iter 0952 | Time 59.6491(60.1875) | Bit/dim 3.7244(3.7349) | Xent 0.7058(0.7363) | Loss 9.7147(10.5400) | Error 0.2551(0.2662) Steps 700(678.38) | Grad Norm 2.7666(2.0350) | Total Time 0.00(0.00)\n",
      "Iter 0953 | Time 57.5162(60.1074) | Bit/dim 3.7336(3.7349) | Xent 0.6918(0.7350) | Loss 9.7316(10.5158) | Error 0.2535(0.2658) Steps 676(678.31) | Grad Norm 3.0370(2.0651) | Total Time 0.00(0.00)\n",
      "Iter 0954 | Time 57.0090(60.0144) | Bit/dim 3.7379(3.7350) | Xent 0.7011(0.7339) | Loss 9.6911(10.4910) | Error 0.2535(0.2654) Steps 664(677.88) | Grad Norm 3.7547(2.1158) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0159 | Time 24.7382, Epoch Time 404.2028(399.3725), Bit/dim 3.7430(best: 3.7376), Xent 1.2606, Loss 4.3733, Error 0.3975(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0955 | Time 57.5338(59.9400) | Bit/dim 3.7317(3.7349) | Xent 0.7015(0.7330) | Loss 14.7496(10.6188) | Error 0.2525(0.2650) Steps 664(677.47) | Grad Norm 1.8119(2.1067) | Total Time 0.00(0.00)\n",
      "Iter 0956 | Time 58.8234(59.9065) | Bit/dim 3.7457(3.7352) | Xent 0.6791(0.7314) | Loss 9.7858(10.5938) | Error 0.2479(0.2645) Steps 688(677.78) | Grad Norm 2.2392(2.1107) | Total Time 0.00(0.00)\n",
      "Iter 0957 | Time 64.5071(60.0445) | Bit/dim 3.7253(3.7349) | Xent 0.7028(0.7305) | Loss 9.8327(10.5710) | Error 0.2522(0.2641) Steps 676(677.73) | Grad Norm 1.0927(2.0801) | Total Time 0.00(0.00)\n",
      "Iter 0958 | Time 62.9359(60.1313) | Bit/dim 3.7347(3.7349) | Xent 0.7146(0.7300) | Loss 9.9542(10.5525) | Error 0.2605(0.2640) Steps 700(678.40) | Grad Norm 1.7674(2.0707) | Total Time 0.00(0.00)\n",
      "Iter 0959 | Time 59.9014(60.1244) | Bit/dim 3.7287(3.7347) | Xent 0.6871(0.7287) | Loss 9.3266(10.5157) | Error 0.2494(0.2636) Steps 694(678.87) | Grad Norm 2.3091(2.0779) | Total Time 0.00(0.00)\n",
      "Iter 0960 | Time 56.9681(60.0297) | Bit/dim 3.7226(3.7343) | Xent 0.6890(0.7275) | Loss 9.3715(10.4814) | Error 0.2502(0.2632) Steps 676(678.78) | Grad Norm 2.0640(2.0775) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0160 | Time 25.1525, Epoch Time 403.7333(399.5033), Bit/dim 3.7409(best: 3.7376), Xent 1.2995, Loss 4.3907, Error 0.4040(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0961 | Time 59.9343(60.0268) | Bit/dim 3.7357(3.7344) | Xent 0.6992(0.7267) | Loss 14.0317(10.5879) | Error 0.2596(0.2631) Steps 676(678.70) | Grad Norm 1.9752(2.0744) | Total Time 0.00(0.00)\n",
      "Iter 0962 | Time 59.1890(60.0017) | Bit/dim 3.7296(3.7342) | Xent 0.6699(0.7250) | Loss 9.5401(10.5564) | Error 0.2390(0.2624) Steps 670(678.44) | Grad Norm 1.7604(2.0650) | Total Time 0.00(0.00)\n",
      "Iter 0963 | Time 63.9952(60.1215) | Bit/dim 3.7346(3.7342) | Xent 0.6893(0.7239) | Loss 9.6437(10.5291) | Error 0.2505(0.2620) Steps 670(678.18) | Grad Norm 1.4230(2.0457) | Total Time 0.00(0.00)\n",
      "Iter 0964 | Time 60.4349(60.1309) | Bit/dim 3.7327(3.7342) | Xent 0.6959(0.7231) | Loss 9.4836(10.4977) | Error 0.2504(0.2617) Steps 688(678.48) | Grad Norm 1.6978(2.0353) | Total Time 0.00(0.00)\n",
      "Iter 0965 | Time 63.8596(60.2428) | Bit/dim 3.7388(3.7343) | Xent 0.7099(0.7227) | Loss 9.7783(10.4761) | Error 0.2568(0.2615) Steps 652(677.68) | Grad Norm 2.4091(2.0465) | Total Time 0.00(0.00)\n",
      "Iter 0966 | Time 59.1394(60.2097) | Bit/dim 3.7300(3.7342) | Xent 0.6925(0.7218) | Loss 9.6549(10.4515) | Error 0.2529(0.2612) Steps 676(677.63) | Grad Norm 2.0988(2.0481) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0161 | Time 25.0800, Epoch Time 410.0466(399.8196), Bit/dim 3.7401(best: 3.7376), Xent 1.2958, Loss 4.3880, Error 0.4010(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0967 | Time 58.9466(60.1718) | Bit/dim 3.7347(3.7342) | Xent 0.6856(0.7207) | Loss 14.8019(10.5820) | Error 0.2438(0.2607) Steps 682(677.76) | Grad Norm 1.9535(2.0452) | Total Time 0.00(0.00)\n",
      "Iter 0968 | Time 60.4642(60.1805) | Bit/dim 3.7301(3.7341) | Xent 0.6930(0.7199) | Loss 9.7093(10.5558) | Error 0.2496(0.2604) Steps 664(677.35) | Grad Norm 1.9462(2.0423) | Total Time 0.00(0.00)\n",
      "Iter 0969 | Time 61.5097(60.2204) | Bit/dim 3.7418(3.7343) | Xent 0.6950(0.7191) | Loss 9.6109(10.5275) | Error 0.2472(0.2600) Steps 664(676.95) | Grad Norm 2.1311(2.0449) | Total Time 0.00(0.00)\n",
      "Iter 0970 | Time 61.4224(60.2565) | Bit/dim 3.7316(3.7342) | Xent 0.6903(0.7182) | Loss 9.5803(10.4990) | Error 0.2574(0.2599) Steps 670(676.74) | Grad Norm 1.3980(2.0255) | Total Time 0.00(0.00)\n",
      "Iter 0971 | Time 59.5614(60.2356) | Bit/dim 3.7220(3.7339) | Xent 0.6787(0.7171) | Loss 9.5632(10.4710) | Error 0.2496(0.2596) Steps 676(676.72) | Grad Norm 1.9876(2.0244) | Total Time 0.00(0.00)\n",
      "Iter 0972 | Time 61.5015(60.2736) | Bit/dim 3.7291(3.7337) | Xent 0.6809(0.7160) | Loss 9.4864(10.4414) | Error 0.2496(0.2593) Steps 682(676.88) | Grad Norm 1.5344(2.0097) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0162 | Time 24.8510, Epoch Time 406.7173(400.0266), Bit/dim 3.7370(best: 3.7376), Xent 1.2979, Loss 4.3859, Error 0.4014(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0973 | Time 58.3786(60.2167) | Bit/dim 3.7323(3.7337) | Xent 0.6994(0.7155) | Loss 14.5898(10.5659) | Error 0.2561(0.2592) Steps 682(677.03) | Grad Norm 2.0626(2.0113) | Total Time 0.00(0.00)\n",
      "Iter 0974 | Time 58.7497(60.1727) | Bit/dim 3.7436(3.7340) | Xent 0.6728(0.7142) | Loss 9.5519(10.5355) | Error 0.2440(0.2588) Steps 676(677.00) | Grad Norm 1.7793(2.0043) | Total Time 0.00(0.00)\n",
      "Iter 0975 | Time 57.8956(60.1044) | Bit/dim 3.7352(3.7340) | Xent 0.6884(0.7134) | Loss 9.5890(10.5071) | Error 0.2522(0.2586) Steps 658(676.43) | Grad Norm 1.7704(1.9973) | Total Time 0.00(0.00)\n",
      "Iter 0976 | Time 61.9343(60.1593) | Bit/dim 3.7297(3.7339) | Xent 0.6842(0.7126) | Loss 9.4856(10.4764) | Error 0.2468(0.2582) Steps 676(676.42) | Grad Norm 2.0841(1.9999) | Total Time 0.00(0.00)\n",
      "Iter 0977 | Time 58.7678(60.1176) | Bit/dim 3.7294(3.7338) | Xent 0.6598(0.7110) | Loss 9.4452(10.4455) | Error 0.2432(0.2578) Steps 640(675.32) | Grad Norm 2.2024(2.0060) | Total Time 0.00(0.00)\n",
      "Iter 0978 | Time 59.1419(60.0883) | Bit/dim 3.7315(3.7337) | Xent 0.6725(0.7098) | Loss 9.7792(10.4255) | Error 0.2411(0.2573) Steps 676(675.35) | Grad Norm 1.6562(1.9955) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0163 | Time 25.6383, Epoch Time 399.1797(400.0011), Bit/dim 3.7396(best: 3.7370), Xent 1.3130, Loss 4.3961, Error 0.4035(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0979 | Time 58.0893(60.0283) | Bit/dim 3.7217(3.7333) | Xent 0.6761(0.7088) | Loss 14.5325(10.5487) | Error 0.2481(0.2570) Steps 652(674.64) | Grad Norm 1.2154(1.9721) | Total Time 0.00(0.00)\n",
      "Iter 0980 | Time 57.9426(59.9658) | Bit/dim 3.7449(3.7337) | Xent 0.6705(0.7077) | Loss 9.6706(10.5224) | Error 0.2445(0.2566) Steps 688(675.05) | Grad Norm 1.2144(1.9493) | Total Time 0.00(0.00)\n",
      "Iter 0981 | Time 60.1329(59.9708) | Bit/dim 3.7392(3.7338) | Xent 0.6559(0.7061) | Loss 9.7116(10.4980) | Error 0.2402(0.2561) Steps 664(674.71) | Grad Norm 2.2196(1.9575) | Total Time 0.00(0.00)\n",
      "Iter 0982 | Time 60.9138(59.9991) | Bit/dim 3.7235(3.7335) | Xent 0.6747(0.7052) | Loss 9.8014(10.4771) | Error 0.2492(0.2559) Steps 682(674.93) | Grad Norm 2.3399(1.9689) | Total Time 0.00(0.00)\n",
      "Iter 0983 | Time 65.6567(60.1688) | Bit/dim 3.7258(3.7333) | Xent 0.6711(0.7041) | Loss 9.7789(10.4562) | Error 0.2455(0.2556) Steps 694(675.50) | Grad Norm 1.9136(1.9673) | Total Time 0.00(0.00)\n",
      "Iter 0984 | Time 67.2332(60.3807) | Bit/dim 3.7286(3.7332) | Xent 0.6815(0.7035) | Loss 9.5525(10.4291) | Error 0.2486(0.2554) Steps 706(676.42) | Grad Norm 2.4580(1.9820) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0164 | Time 25.5356, Epoch Time 414.2121(400.4275), Bit/dim 3.7341(best: 3.7370), Xent 1.3042, Loss 4.3862, Error 0.4055(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0985 | Time 64.5259(60.5051) | Bit/dim 3.7361(3.7333) | Xent 0.6712(0.7025) | Loss 14.5954(10.5541) | Error 0.2480(0.2552) Steps 670(676.23) | Grad Norm 2.8344(2.0076) | Total Time 0.00(0.00)\n",
      "Iter 0986 | Time 66.9551(60.6986) | Bit/dim 3.7242(3.7330) | Xent 0.6497(0.7009) | Loss 9.8367(10.5326) | Error 0.2396(0.2547) Steps 670(676.04) | Grad Norm 1.5306(1.9933) | Total Time 0.00(0.00)\n",
      "Iter 0987 | Time 70.2176(60.9841) | Bit/dim 3.7354(3.7331) | Xent 0.6762(0.7002) | Loss 9.7302(10.5085) | Error 0.2465(0.2545) Steps 682(676.22) | Grad Norm 4.3731(2.0647) | Total Time 0.00(0.00)\n",
      "Iter 0988 | Time 67.6085(61.1829) | Bit/dim 3.7417(3.7333) | Xent 0.7050(0.7003) | Loss 9.7275(10.4851) | Error 0.2549(0.2545) Steps 640(675.13) | Grad Norm 6.8147(2.2072) | Total Time 0.00(0.00)\n",
      "Iter 0989 | Time 68.6765(61.4077) | Bit/dim 3.7303(3.7332) | Xent 0.6774(0.6996) | Loss 9.7549(10.4632) | Error 0.2488(0.2543) Steps 658(674.62) | Grad Norm 3.8089(2.2552) | Total Time 0.00(0.00)\n",
      "Iter 0990 | Time 65.2856(61.5240) | Bit/dim 3.7321(3.7332) | Xent 0.6831(0.6991) | Loss 9.6937(10.4401) | Error 0.2501(0.2542) Steps 700(675.38) | Grad Norm 5.3902(2.3493) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0165 | Time 24.9222, Epoch Time 446.9722(401.8238), Bit/dim 3.7371(best: 3.7341), Xent 1.3333, Loss 4.4037, Error 0.4113(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0991 | Time 67.2318(61.6953) | Bit/dim 3.7412(3.7334) | Xent 0.6970(0.6991) | Loss 15.0809(10.5793) | Error 0.2586(0.2543) Steps 682(675.58) | Grad Norm 8.4496(2.5323) | Total Time 0.00(0.00)\n",
      "Iter 0992 | Time 66.6058(61.8426) | Bit/dim 3.7283(3.7333) | Xent 0.6734(0.6983) | Loss 9.7346(10.5540) | Error 0.2470(0.2541) Steps 658(675.05) | Grad Norm 3.8380(2.5714) | Total Time 0.00(0.00)\n",
      "Iter 0993 | Time 62.3508(61.8578) | Bit/dim 3.7264(3.7331) | Xent 0.6786(0.6977) | Loss 9.5193(10.5229) | Error 0.2552(0.2541) Steps 688(675.44) | Grad Norm 7.5986(2.7223) | Total Time 0.00(0.00)\n",
      "Iter 0994 | Time 64.9746(61.9513) | Bit/dim 3.7425(3.7333) | Xent 0.6832(0.6973) | Loss 9.6695(10.4973) | Error 0.2462(0.2539) Steps 670(675.28) | Grad Norm 3.9928(2.7604) | Total Time 0.00(0.00)\n",
      "Iter 0995 | Time 74.0017(62.3128) | Bit/dim 3.7288(3.7332) | Xent 0.6698(0.6964) | Loss 9.7461(10.4748) | Error 0.2438(0.2536) Steps 682(675.48) | Grad Norm 6.2072(2.8638) | Total Time 0.00(0.00)\n",
      "Iter 0996 | Time 64.1512(62.3680) | Bit/dim 3.7180(3.7328) | Xent 0.7008(0.6966) | Loss 9.7629(10.4534) | Error 0.2581(0.2537) Steps 670(675.31) | Grad Norm 4.4624(2.9117) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0166 | Time 25.1367, Epoch Time 442.9081(403.0563), Bit/dim 3.7367(best: 3.7341), Xent 1.3334, Loss 4.4034, Error 0.4056(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 0997 | Time 64.3501(62.4274) | Bit/dim 3.7227(3.7325) | Xent 0.6724(0.6958) | Loss 14.6671(10.5798) | Error 0.2471(0.2535) Steps 664(674.97) | Grad Norm 5.5560(2.9911) | Total Time 0.00(0.00)\n",
      "Iter 0998 | Time 66.3053(62.5438) | Bit/dim 3.7382(3.7326) | Xent 0.6712(0.6951) | Loss 9.5191(10.5480) | Error 0.2496(0.2534) Steps 670(674.83) | Grad Norm 5.1026(3.0544) | Total Time 0.00(0.00)\n",
      "Iter 0999 | Time 70.3097(62.7768) | Bit/dim 3.7447(3.7330) | Xent 0.6583(0.6940) | Loss 9.7090(10.5228) | Error 0.2419(0.2531) Steps 688(675.22) | Grad Norm 3.6757(3.0730) | Total Time 0.00(0.00)\n",
      "Iter 1000 | Time 67.7704(62.9266) | Bit/dim 3.7252(3.7328) | Xent 0.6747(0.6934) | Loss 9.6111(10.4955) | Error 0.2474(0.2529) Steps 682(675.42) | Grad Norm 6.6456(3.1802) | Total Time 0.00(0.00)\n",
      "Iter 1001 | Time 63.0787(62.9311) | Bit/dim 3.7275(3.7326) | Xent 0.6591(0.6924) | Loss 9.6615(10.4705) | Error 0.2420(0.2526) Steps 652(674.72) | Grad Norm 1.7609(3.1376) | Total Time 0.00(0.00)\n",
      "Iter 1002 | Time 65.8132(63.0176) | Bit/dim 3.7361(3.7327) | Xent 0.6712(0.6918) | Loss 9.7418(10.4486) | Error 0.2474(0.2524) Steps 682(674.94) | Grad Norm 5.1764(3.1988) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0167 | Time 25.4208, Epoch Time 442.1139(404.2281), Bit/dim 3.7362(best: 3.7341), Xent 1.3413, Loss 4.4069, Error 0.4097(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1003 | Time 66.5668(63.1241) | Bit/dim 3.7328(3.7327) | Xent 0.6542(0.6906) | Loss 14.0714(10.5573) | Error 0.2339(0.2518) Steps 664(674.61) | Grad Norm 3.5745(3.2101) | Total Time 0.00(0.00)\n",
      "Iter 1004 | Time 66.5270(63.2262) | Bit/dim 3.7351(3.7328) | Xent 0.6521(0.6895) | Loss 9.5258(10.5263) | Error 0.2400(0.2515) Steps 634(673.39) | Grad Norm 3.5186(3.2193) | Total Time 0.00(0.00)\n",
      "Iter 1005 | Time 65.5295(63.2953) | Bit/dim 3.7244(3.7325) | Xent 0.6277(0.6876) | Loss 9.6322(10.4995) | Error 0.2268(0.2508) Steps 688(673.83) | Grad Norm 4.2535(3.2504) | Total Time 0.00(0.00)\n",
      "Iter 1006 | Time 69.7602(63.4892) | Bit/dim 3.7286(3.7324) | Xent 0.6625(0.6869) | Loss 9.5662(10.4715) | Error 0.2406(0.2504) Steps 688(674.26) | Grad Norm 1.8953(3.2097) | Total Time 0.00(0.00)\n",
      "Iter 1007 | Time 62.2223(63.4512) | Bit/dim 3.7397(3.7326) | Xent 0.6427(0.6855) | Loss 9.6521(10.4469) | Error 0.2311(0.2499) Steps 670(674.13) | Grad Norm 3.1397(3.2076) | Total Time 0.00(0.00)\n",
      "Iter 1008 | Time 66.4970(63.5426) | Bit/dim 3.7222(3.7323) | Xent 0.6288(0.6838) | Loss 9.3354(10.4136) | Error 0.2318(0.2493) Steps 658(673.64) | Grad Norm 2.3808(3.1828) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0168 | Time 25.2001, Epoch Time 440.6592(405.3210), Bit/dim 3.7376(best: 3.7341), Xent 1.3363, Loss 4.4058, Error 0.4028(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1009 | Time 65.0451(63.5877) | Bit/dim 3.7228(3.7320) | Xent 0.6535(0.6829) | Loss 14.6859(10.5418) | Error 0.2355(0.2489) Steps 688(674.08) | Grad Norm 3.1551(3.1820) | Total Time 0.00(0.00)\n",
      "Iter 1010 | Time 68.7164(63.7415) | Bit/dim 3.7272(3.7319) | Xent 0.6288(0.6813) | Loss 9.7257(10.5173) | Error 0.2278(0.2483) Steps 664(673.77) | Grad Norm 2.4493(3.1600) | Total Time 0.00(0.00)\n",
      "Iter 1011 | Time 68.6091(63.8875) | Bit/dim 3.7406(3.7322) | Xent 0.6330(0.6799) | Loss 9.6626(10.4916) | Error 0.2331(0.2478) Steps 682(674.02) | Grad Norm 3.1963(3.1611) | Total Time 0.00(0.00)\n",
      "Iter 1012 | Time 70.0086(64.0712) | Bit/dim 3.7352(3.7322) | Xent 0.6473(0.6789) | Loss 9.6124(10.4653) | Error 0.2350(0.2474) Steps 700(674.80) | Grad Norm 2.5651(3.1432) | Total Time 0.00(0.00)\n",
      "Iter 1013 | Time 70.8252(64.2738) | Bit/dim 3.7258(3.7320) | Xent 0.6483(0.6780) | Loss 9.5739(10.4385) | Error 0.2352(0.2471) Steps 706(675.74) | Grad Norm 4.1647(3.1738) | Total Time 0.00(0.00)\n",
      "Iter 1014 | Time 69.8296(64.4405) | Bit/dim 3.7250(3.7318) | Xent 0.6335(0.6766) | Loss 9.5089(10.4106) | Error 0.2350(0.2467) Steps 682(675.92) | Grad Norm 3.7367(3.1907) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0169 | Time 25.3970, Epoch Time 457.0892(406.8741), Bit/dim 3.7324(best: 3.7341), Xent 1.3696, Loss 4.4172, Error 0.4061(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1015 | Time 67.7255(64.5390) | Bit/dim 3.7280(3.7317) | Xent 0.6356(0.6754) | Loss 14.0362(10.5194) | Error 0.2335(0.2463) Steps 676(675.93) | Grad Norm 2.4269(3.1678) | Total Time 0.00(0.00)\n",
      "Iter 1016 | Time 64.5513(64.5394) | Bit/dim 3.7278(3.7316) | Xent 0.6119(0.6735) | Loss 9.6244(10.4925) | Error 0.2256(0.2457) Steps 658(675.39) | Grad Norm 2.5255(3.1485) | Total Time 0.00(0.00)\n",
      "Iter 1017 | Time 69.9548(64.7019) | Bit/dim 3.7170(3.7312) | Xent 0.6381(0.6724) | Loss 9.7196(10.4694) | Error 0.2364(0.2454) Steps 676(675.41) | Grad Norm 2.0329(3.1151) | Total Time 0.00(0.00)\n",
      "Iter 1018 | Time 65.4182(64.7233) | Bit/dim 3.7295(3.7311) | Xent 0.6422(0.6715) | Loss 9.4584(10.4390) | Error 0.2370(0.2452) Steps 658(674.88) | Grad Norm 2.8717(3.1078) | Total Time 0.00(0.00)\n",
      "Iter 1019 | Time 66.4353(64.7747) | Bit/dim 3.7341(3.7312) | Xent 0.6174(0.6699) | Loss 9.4487(10.4093) | Error 0.2299(0.2447) Steps 670(674.74) | Grad Norm 2.1540(3.0792) | Total Time 0.00(0.00)\n",
      "Iter 1020 | Time 70.3888(64.9431) | Bit/dim 3.7336(3.7313) | Xent 0.6528(0.6694) | Loss 9.7454(10.3894) | Error 0.2366(0.2445) Steps 676(674.78) | Grad Norm 3.7568(3.0995) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0170 | Time 24.8204, Epoch Time 448.2819(408.1163), Bit/dim 3.7366(best: 3.7324), Xent 1.3598, Loss 4.4165, Error 0.4054(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1021 | Time 64.7600(64.9376) | Bit/dim 3.7234(3.7310) | Xent 0.6271(0.6681) | Loss 13.5953(10.4856) | Error 0.2312(0.2441) Steps 676(674.81) | Grad Norm 1.8851(3.0631) | Total Time 0.00(0.00)\n",
      "Iter 1022 | Time 65.9325(64.9675) | Bit/dim 3.7247(3.7309) | Xent 0.6240(0.6668) | Loss 9.5706(10.4581) | Error 0.2258(0.2435) Steps 664(674.49) | Grad Norm 3.4990(3.0761) | Total Time 0.00(0.00)\n",
      "Iter 1023 | Time 68.9238(65.0862) | Bit/dim 3.7313(3.7309) | Xent 0.6443(0.6661) | Loss 9.6242(10.4331) | Error 0.2381(0.2434) Steps 646(673.63) | Grad Norm 2.5834(3.0614) | Total Time 0.00(0.00)\n",
      "Iter 1024 | Time 67.9613(65.1724) | Bit/dim 3.7226(3.7306) | Xent 0.6232(0.6648) | Loss 9.6288(10.4090) | Error 0.2270(0.2429) Steps 688(674.06) | Grad Norm 3.7844(3.0830) | Total Time 0.00(0.00)\n",
      "Iter 1025 | Time 70.1344(65.3213) | Bit/dim 3.7344(3.7307) | Xent 0.6221(0.6636) | Loss 9.8119(10.3911) | Error 0.2274(0.2424) Steps 676(674.12) | Grad Norm 2.9643(3.0795) | Total Time 0.00(0.00)\n",
      "Iter 1026 | Time 72.4662(65.5356) | Bit/dim 3.7339(3.7308) | Xent 0.6361(0.6627) | Loss 9.5884(10.3670) | Error 0.2366(0.2422) Steps 664(673.82) | Grad Norm 1.6645(3.0370) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0171 | Time 24.5933, Epoch Time 452.7486(409.4553), Bit/dim 3.7343(best: 3.7324), Xent 1.3619, Loss 4.4152, Error 0.4043(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1027 | Time 67.6780(65.5999) | Bit/dim 3.7388(3.7311) | Xent 0.6244(0.6616) | Loss 13.9553(10.4746) | Error 0.2272(0.2418) Steps 658(673.34) | Grad Norm 1.7483(2.9984) | Total Time 0.00(0.00)\n",
      "Iter 1028 | Time 65.0987(65.5849) | Bit/dim 3.7115(3.7305) | Xent 0.6050(0.6599) | Loss 9.5803(10.4478) | Error 0.2196(0.2411) Steps 664(673.06) | Grad Norm 2.2216(2.9751) | Total Time 0.00(0.00)\n",
      "Iter 1029 | Time 65.5349(65.5834) | Bit/dim 3.7231(3.7303) | Xent 0.6134(0.6585) | Loss 9.4795(10.4188) | Error 0.2180(0.2404) Steps 676(673.15) | Grad Norm 1.9103(2.9431) | Total Time 0.00(0.00)\n",
      "Iter 1030 | Time 63.3750(65.5171) | Bit/dim 3.7283(3.7302) | Xent 0.6127(0.6571) | Loss 9.5977(10.3941) | Error 0.2216(0.2399) Steps 664(672.88) | Grad Norm 3.1370(2.9489) | Total Time 0.00(0.00)\n",
      "Iter 1031 | Time 71.2724(65.6898) | Bit/dim 3.7335(3.7303) | Xent 0.6244(0.6561) | Loss 9.6488(10.3718) | Error 0.2324(0.2396) Steps 688(673.33) | Grad Norm 3.3352(2.9605) | Total Time 0.00(0.00)\n",
      "Iter 1032 | Time 64.7452(65.6614) | Bit/dim 3.7311(3.7303) | Xent 0.5996(0.6544) | Loss 9.5574(10.3473) | Error 0.2180(0.2390) Steps 664(673.05) | Grad Norm 2.5415(2.9480) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0172 | Time 24.9150, Epoch Time 440.4476(410.3850), Bit/dim 3.7349(best: 3.7324), Xent 1.3863, Loss 4.4280, Error 0.4063(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1033 | Time 64.6309(65.6305) | Bit/dim 3.7262(3.7302) | Xent 0.6211(0.6534) | Loss 14.5044(10.4721) | Error 0.2250(0.2386) Steps 670(672.96) | Grad Norm 2.5395(2.9357) | Total Time 0.00(0.00)\n",
      "Iter 1034 | Time 66.3725(65.6528) | Bit/dim 3.7319(3.7303) | Xent 0.5939(0.6517) | Loss 9.3998(10.4399) | Error 0.2135(0.2378) Steps 670(672.87) | Grad Norm 2.5236(2.9233) | Total Time 0.00(0.00)\n",
      "Iter 1035 | Time 69.2849(65.7617) | Bit/dim 3.7352(3.7304) | Xent 0.6124(0.6505) | Loss 9.6926(10.4175) | Error 0.2228(0.2374) Steps 694(673.50) | Grad Norm 2.7299(2.9175) | Total Time 0.00(0.00)\n",
      "Iter 1036 | Time 65.6891(65.7596) | Bit/dim 3.7189(3.7301) | Xent 0.6118(0.6493) | Loss 9.7096(10.3962) | Error 0.2226(0.2369) Steps 688(673.94) | Grad Norm 2.6819(2.9105) | Total Time 0.00(0.00)\n",
      "Iter 1037 | Time 65.6981(65.7577) | Bit/dim 3.7319(3.7301) | Xent 0.6032(0.6479) | Loss 9.7288(10.3762) | Error 0.2242(0.2365) Steps 658(673.46) | Grad Norm 2.2552(2.8908) | Total Time 0.00(0.00)\n",
      "Iter 1038 | Time 61.9974(65.6449) | Bit/dim 3.7331(3.7302) | Xent 0.6188(0.6471) | Loss 9.4238(10.3476) | Error 0.2288(0.2363) Steps 652(672.82) | Grad Norm 5.5618(2.9709) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0173 | Time 25.4228, Epoch Time 437.5156(411.1989), Bit/dim 3.7285(best: 3.7324), Xent 1.4190, Loss 4.4380, Error 0.4108(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1039 | Time 68.2930(65.7244) | Bit/dim 3.7363(3.7304) | Xent 0.6082(0.6459) | Loss 14.1642(10.4621) | Error 0.2220(0.2359) Steps 688(673.27) | Grad Norm 6.0116(3.0622) | Total Time 0.00(0.00)\n",
      "Iter 1040 | Time 67.7851(65.7862) | Bit/dim 3.7210(3.7301) | Xent 0.6245(0.6453) | Loss 9.5641(10.4352) | Error 0.2266(0.2356) Steps 688(673.71) | Grad Norm 4.4004(3.1023) | Total Time 0.00(0.00)\n",
      "Iter 1041 | Time 72.0688(65.9747) | Bit/dim 3.7321(3.7302) | Xent 0.6136(0.6443) | Loss 9.7667(10.4151) | Error 0.2190(0.2351) Steps 664(673.42) | Grad Norm 2.1695(3.0743) | Total Time 0.00(0.00)\n",
      "Iter 1042 | Time 70.4697(66.1095) | Bit/dim 3.7314(3.7302) | Xent 0.6139(0.6434) | Loss 9.7207(10.3943) | Error 0.2254(0.2348) Steps 688(673.86) | Grad Norm 2.9376(3.0702) | Total Time 0.00(0.00)\n",
      "Iter 1043 | Time 65.0838(66.0787) | Bit/dim 3.7316(3.7302) | Xent 0.6186(0.6426) | Loss 9.4851(10.3670) | Error 0.2276(0.2346) Steps 670(673.74) | Grad Norm 6.8556(3.1838) | Total Time 0.00(0.00)\n",
      "Iter 1044 | Time 70.6715(66.2165) | Bit/dim 3.7175(3.7299) | Xent 0.6072(0.6416) | Loss 9.5166(10.3415) | Error 0.2262(0.2343) Steps 676(673.81) | Grad Norm 4.3498(3.2188) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0174 | Time 24.0879, Epoch Time 457.1130(412.5764), Bit/dim 3.7376(best: 3.7285), Xent 1.3954, Loss 4.4353, Error 0.4056(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1045 | Time 65.3887(66.1917) | Bit/dim 3.7255(3.7297) | Xent 0.6003(0.6403) | Loss 14.0359(10.4523) | Error 0.2195(0.2339) Steps 670(673.70) | Grad Norm 2.8706(3.2083) | Total Time 0.00(0.00)\n",
      "Iter 1046 | Time 69.4786(66.2903) | Bit/dim 3.7295(3.7297) | Xent 0.6192(0.6397) | Loss 9.1983(10.4147) | Error 0.2229(0.2336) Steps 670(673.59) | Grad Norm 3.1274(3.2059) | Total Time 0.00(0.00)\n",
      "Iter 1047 | Time 69.3004(66.3806) | Bit/dim 3.7207(3.7295) | Xent 0.5973(0.6384) | Loss 9.4169(10.3848) | Error 0.2220(0.2332) Steps 682(673.84) | Grad Norm 2.4139(3.1821) | Total Time 0.00(0.00)\n",
      "Iter 1048 | Time 67.4268(66.4120) | Bit/dim 3.7323(3.7295) | Xent 0.6018(0.6373) | Loss 9.5796(10.3606) | Error 0.2159(0.2327) Steps 670(673.72) | Grad Norm 2.3854(3.1582) | Total Time 0.00(0.00)\n",
      "Iter 1049 | Time 64.2647(66.3476) | Bit/dim 3.7239(3.7294) | Xent 0.5888(0.6359) | Loss 9.5177(10.3353) | Error 0.2126(0.2321) Steps 664(673.43) | Grad Norm 1.9618(3.1223) | Total Time 0.00(0.00)\n",
      "Iter 1050 | Time 62.7977(66.2411) | Bit/dim 3.7189(3.7291) | Xent 0.6011(0.6348) | Loss 9.3643(10.3062) | Error 0.2210(0.2318) Steps 664(673.15) | Grad Norm 3.3301(3.1286) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0175 | Time 25.2337, Epoch Time 442.6554(413.4787), Bit/dim 3.7378(best: 3.7285), Xent 1.4107, Loss 4.4431, Error 0.4089(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1051 | Time 67.3460(66.2742) | Bit/dim 3.7224(3.7289) | Xent 0.5955(0.6337) | Loss 14.3365(10.4271) | Error 0.2177(0.2313) Steps 670(673.06) | Grad Norm 3.2186(3.1313) | Total Time 0.00(0.00)\n",
      "Iter 1052 | Time 67.7050(66.3171) | Bit/dim 3.7390(3.7292) | Xent 0.5777(0.6320) | Loss 9.6418(10.4036) | Error 0.2131(0.2308) Steps 694(673.68) | Grad Norm 2.0624(3.0992) | Total Time 0.00(0.00)\n",
      "Iter 1053 | Time 66.0936(66.3104) | Bit/dim 3.7224(3.7290) | Xent 0.5919(0.6308) | Loss 9.5218(10.3771) | Error 0.2145(0.2303) Steps 694(674.29) | Grad Norm 2.0079(3.0665) | Total Time 0.00(0.00)\n",
      "Iter 1054 | Time 65.5097(66.2864) | Bit/dim 3.7297(3.7290) | Xent 0.5891(0.6295) | Loss 9.4030(10.3479) | Error 0.2124(0.2298) Steps 682(674.52) | Grad Norm 2.9324(3.0624) | Total Time 0.00(0.00)\n",
      "Iter 1055 | Time 66.3372(66.2879) | Bit/dim 3.7187(3.7287) | Xent 0.5951(0.6285) | Loss 9.5961(10.3253) | Error 0.2169(0.2294) Steps 652(673.85) | Grad Norm 3.5139(3.0760) | Total Time 0.00(0.00)\n",
      "Iter 1056 | Time 65.9469(66.2777) | Bit/dim 3.7287(3.7287) | Xent 0.5985(0.6276) | Loss 9.5155(10.3010) | Error 0.2139(0.2289) Steps 682(674.09) | Grad Norm 4.1595(3.1085) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0176 | Time 25.3836, Epoch Time 443.6130(414.3828), Bit/dim 3.7348(best: 3.7285), Xent 1.4215, Loss 4.4456, Error 0.4019(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1057 | Time 69.2138(66.3658) | Bit/dim 3.7174(3.7283) | Xent 0.5788(0.6261) | Loss 13.3385(10.3922) | Error 0.2115(0.2284) Steps 670(673.97) | Grad Norm 2.1553(3.0799) | Total Time 0.00(0.00)\n",
      "Iter 1058 | Time 64.5914(66.3126) | Bit/dim 3.7325(3.7285) | Xent 0.5949(0.6252) | Loss 9.5742(10.3676) | Error 0.2179(0.2281) Steps 652(673.31) | Grad Norm 3.5635(3.0944) | Total Time 0.00(0.00)\n",
      "Iter 1059 | Time 73.2057(66.5193) | Bit/dim 3.7202(3.7282) | Xent 0.5776(0.6238) | Loss 9.4131(10.3390) | Error 0.2115(0.2276) Steps 700(674.11) | Grad Norm 1.7448(3.0539) | Total Time 0.00(0.00)\n",
      "Iter 1060 | Time 69.3453(66.6041) | Bit/dim 3.7275(3.7282) | Xent 0.5721(0.6222) | Loss 9.7769(10.3221) | Error 0.2130(0.2271) Steps 694(674.71) | Grad Norm 3.3361(3.0624) | Total Time 0.00(0.00)\n",
      "Iter 1061 | Time 69.0904(66.6787) | Bit/dim 3.7292(3.7282) | Xent 0.6033(0.6217) | Loss 9.7960(10.3063) | Error 0.2279(0.2272) Steps 694(675.29) | Grad Norm 4.7334(3.1125) | Total Time 0.00(0.00)\n",
      "Iter 1062 | Time 66.7343(66.6804) | Bit/dim 3.7266(3.7282) | Xent 0.6148(0.6214) | Loss 9.0882(10.2698) | Error 0.2234(0.2271) Steps 646(674.41) | Grad Norm 6.8250(3.2239) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0177 | Time 25.0066, Epoch Time 455.7431(415.6236), Bit/dim 3.7387(best: 3.7285), Xent 1.4099, Loss 4.4437, Error 0.4095(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1063 | Time 64.3093(66.6093) | Bit/dim 3.7377(3.7285) | Xent 0.6250(0.6216) | Loss 14.8363(10.4068) | Error 0.2292(0.2271) Steps 664(674.10) | Grad Norm 8.7760(3.3904) | Total Time 0.00(0.00)\n",
      "Iter 1064 | Time 70.9504(66.7395) | Bit/dim 3.7314(3.7285) | Xent 0.6129(0.6213) | Loss 9.5974(10.3825) | Error 0.2225(0.2270) Steps 664(673.79) | Grad Norm 8.6909(3.5495) | Total Time 0.00(0.00)\n",
      "Iter 1065 | Time 67.1429(66.7516) | Bit/dim 3.7248(3.7284) | Xent 0.5879(0.6203) | Loss 9.5090(10.3563) | Error 0.2194(0.2268) Steps 646(672.96) | Grad Norm 2.6352(3.5220) | Total Time 0.00(0.00)\n",
      "Iter 1066 | Time 70.6630(66.8689) | Bit/dim 3.7182(3.7281) | Xent 0.6034(0.6198) | Loss 9.5909(10.3333) | Error 0.2183(0.2265) Steps 688(673.41) | Grad Norm 6.1815(3.6018) | Total Time 0.00(0.00)\n",
      "Iter 1067 | Time 69.1051(66.9360) | Bit/dim 3.7242(3.7280) | Xent 0.6107(0.6195) | Loss 9.5114(10.3087) | Error 0.2239(0.2264) Steps 682(673.67) | Grad Norm 7.6410(3.7230) | Total Time 0.00(0.00)\n",
      "Iter 1068 | Time 70.3662(67.0389) | Bit/dim 3.7219(3.7278) | Xent 0.6165(0.6194) | Loss 9.7585(10.2922) | Error 0.2241(0.2263) Steps 664(673.38) | Grad Norm 4.4456(3.7447) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0178 | Time 25.0182, Epoch Time 455.9433(416.8332), Bit/dim 3.7336(best: 3.7285), Xent 1.4042, Loss 4.4357, Error 0.4089(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1069 | Time 65.7420(67.0000) | Bit/dim 3.7233(3.7277) | Xent 0.5956(0.6187) | Loss 14.2813(10.4119) | Error 0.2173(0.2261) Steps 688(673.82) | Grad Norm 5.1822(3.7878) | Total Time 0.00(0.00)\n",
      "Iter 1070 | Time 66.3305(66.9799) | Bit/dim 3.7241(3.7276) | Xent 0.5877(0.6178) | Loss 9.5735(10.3867) | Error 0.2230(0.2260) Steps 670(673.70) | Grad Norm 4.6557(3.8138) | Total Time 0.00(0.00)\n",
      "Iter 1071 | Time 67.1884(66.9862) | Bit/dim 3.7334(3.7278) | Xent 0.5966(0.6171) | Loss 9.5188(10.3607) | Error 0.2224(0.2259) Steps 664(673.41) | Grad Norm 4.8053(3.8436) | Total Time 0.00(0.00)\n",
      "Iter 1072 | Time 65.9510(66.9551) | Bit/dim 3.7240(3.7276) | Xent 0.5922(0.6164) | Loss 9.4797(10.3342) | Error 0.2184(0.2256) Steps 664(673.13) | Grad Norm 5.6231(3.8970) | Total Time 0.00(0.00)\n",
      "Iter 1073 | Time 66.2874(66.9351) | Bit/dim 3.7333(3.7278) | Xent 0.6259(0.6167) | Loss 9.4549(10.3079) | Error 0.2269(0.2257) Steps 658(672.68) | Grad Norm 7.3906(4.0018) | Total Time 0.00(0.00)\n",
      "Iter 1074 | Time 67.9071(66.9643) | Bit/dim 3.7251(3.7277) | Xent 0.6222(0.6168) | Loss 9.4202(10.2812) | Error 0.2299(0.2258) Steps 664(672.41) | Grad Norm 9.8817(4.1782) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0179 | Time 24.5972, Epoch Time 442.8858(417.6147), Bit/dim 3.7316(best: 3.7285), Xent 1.4773, Loss 4.4702, Error 0.4124(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1075 | Time 68.4894(67.0100) | Bit/dim 3.7380(3.7280) | Xent 0.6046(0.6165) | Loss 14.4585(10.4065) | Error 0.2270(0.2258) Steps 688(672.88) | Grad Norm 5.7645(4.2258) | Total Time 0.00(0.00)\n",
      "Iter 1076 | Time 65.8342(66.9747) | Bit/dim 3.7313(3.7281) | Xent 0.6362(0.6171) | Loss 9.7367(10.3864) | Error 0.2254(0.2258) Steps 700(673.70) | Grad Norm 9.5915(4.3867) | Total Time 0.00(0.00)\n",
      "Iter 1077 | Time 65.0319(66.9165) | Bit/dim 3.7268(3.7281) | Xent 0.5967(0.6165) | Loss 9.4763(10.3591) | Error 0.2189(0.2256) Steps 664(673.41) | Grad Norm 10.8017(4.5792) | Total Time 0.00(0.00)\n",
      "Iter 1078 | Time 63.6381(66.8181) | Bit/dim 3.7176(3.7278) | Xent 0.6205(0.6166) | Loss 9.4232(10.3311) | Error 0.2266(0.2257) Steps 694(674.02) | Grad Norm 6.3338(4.6318) | Total Time 0.00(0.00)\n",
      "Iter 1079 | Time 62.1239(66.6773) | Bit/dim 3.7282(3.7278) | Xent 0.5810(0.6155) | Loss 9.4037(10.3032) | Error 0.2114(0.2252) Steps 664(673.72) | Grad Norm 7.5192(4.7184) | Total Time 0.00(0.00)\n",
      "Iter 1080 | Time 65.8286(66.6518) | Bit/dim 3.7183(3.7275) | Xent 0.5971(0.6150) | Loss 9.5105(10.2795) | Error 0.2208(0.2251) Steps 676(673.79) | Grad Norm 4.3707(4.7080) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0180 | Time 24.6366, Epoch Time 433.9310(418.1042), Bit/dim 3.7310(best: 3.7285), Xent 1.4069, Loss 4.4344, Error 0.4051(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1081 | Time 67.9565(66.6910) | Bit/dim 3.7325(3.7277) | Xent 0.5695(0.6136) | Loss 14.2933(10.3999) | Error 0.2054(0.2245) Steps 694(674.40) | Grad Norm 3.9209(4.6844) | Total Time 0.00(0.00)\n",
      "Iter 1082 | Time 66.5537(66.6868) | Bit/dim 3.7284(3.7277) | Xent 0.5925(0.6130) | Loss 9.5160(10.3734) | Error 0.2180(0.2243) Steps 664(674.09) | Grad Norm 4.3235(4.6736) | Total Time 0.00(0.00)\n",
      "Iter 1083 | Time 67.8932(66.7230) | Bit/dim 3.7159(3.7273) | Xent 0.5577(0.6113) | Loss 9.4411(10.3454) | Error 0.2047(0.2237) Steps 652(673.42) | Grad Norm 2.3164(4.6029) | Total Time 0.00(0.00)\n",
      "Iter 1084 | Time 63.6974(66.6323) | Bit/dim 3.7203(3.7271) | Xent 0.5897(0.6107) | Loss 9.0489(10.3065) | Error 0.2157(0.2235) Steps 688(673.86) | Grad Norm 4.9922(4.6145) | Total Time 0.00(0.00)\n",
      "Iter 1085 | Time 65.3208(66.5929) | Bit/dim 3.7312(3.7272) | Xent 0.5523(0.6089) | Loss 9.6323(10.2863) | Error 0.2014(0.2228) Steps 652(673.20) | Grad Norm 2.8191(4.5607) | Total Time 0.00(0.00)\n",
      "Iter 1086 | Time 71.2963(66.7340) | Bit/dim 3.7244(3.7272) | Xent 0.5934(0.6084) | Loss 9.6777(10.2680) | Error 0.2156(0.2226) Steps 658(672.75) | Grad Norm 6.4348(4.6169) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0181 | Time 24.3504, Epoch Time 445.1492(418.9156), Bit/dim 3.7356(best: 3.7285), Xent 1.4824, Loss 4.4768, Error 0.4108(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1087 | Time 68.1283(66.7758) | Bit/dim 3.7184(3.7269) | Xent 0.5678(0.6072) | Loss 14.2111(10.3863) | Error 0.2071(0.2221) Steps 676(672.85) | Grad Norm 3.4684(4.5824) | Total Time 0.00(0.00)\n",
      "Iter 1088 | Time 67.8778(66.8089) | Bit/dim 3.7227(3.7268) | Xent 0.5737(0.6062) | Loss 9.4775(10.3590) | Error 0.2109(0.2218) Steps 670(672.76) | Grad Norm 6.2131(4.6314) | Total Time 0.00(0.00)\n",
      "Iter 1089 | Time 70.8176(66.9292) | Bit/dim 3.7282(3.7268) | Xent 0.5593(0.6048) | Loss 9.5579(10.3350) | Error 0.2055(0.2213) Steps 670(672.68) | Grad Norm 4.3888(4.6241) | Total Time 0.00(0.00)\n",
      "Iter 1090 | Time 66.8248(66.9260) | Bit/dim 3.7215(3.7266) | Xent 0.5654(0.6036) | Loss 9.6506(10.3145) | Error 0.2019(0.2207) Steps 688(673.14) | Grad Norm 5.3815(4.6468) | Total Time 0.00(0.00)\n",
      "Iter 1091 | Time 69.1685(66.9933) | Bit/dim 3.7281(3.7267) | Xent 0.5614(0.6024) | Loss 9.5118(10.2904) | Error 0.2100(0.2204) Steps 688(673.58) | Grad Norm 5.6984(4.6784) | Total Time 0.00(0.00)\n",
      "Iter 1092 | Time 66.6592(66.9833) | Bit/dim 3.7209(3.7265) | Xent 0.5600(0.6011) | Loss 9.5534(10.2683) | Error 0.2031(0.2199) Steps 646(672.76) | Grad Norm 5.4939(4.7028) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0182 | Time 24.9674, Epoch Time 452.5720(419.9253), Bit/dim 3.7335(best: 3.7285), Xent 1.4922, Loss 4.4796, Error 0.4153(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1093 | Time 66.7645(66.9767) | Bit/dim 3.7255(3.7265) | Xent 0.5653(0.6000) | Loss 13.6556(10.3699) | Error 0.2126(0.2197) Steps 670(672.67) | Grad Norm 3.9414(4.6800) | Total Time 0.00(0.00)\n",
      "Iter 1094 | Time 66.7921(66.9712) | Bit/dim 3.7317(3.7266) | Xent 0.5467(0.5984) | Loss 9.6090(10.3471) | Error 0.2025(0.2192) Steps 688(673.13) | Grad Norm 5.5201(4.7052) | Total Time 0.00(0.00)\n",
      "Iter 1095 | Time 67.3065(66.9812) | Bit/dim 3.7310(3.7268) | Xent 0.5586(0.5972) | Loss 9.6095(10.3249) | Error 0.2044(0.2187) Steps 664(672.86) | Grad Norm 3.9777(4.6834) | Total Time 0.00(0.00)\n",
      "Iter 1096 | Time 66.4291(66.9647) | Bit/dim 3.7188(3.7265) | Xent 0.5735(0.5965) | Loss 9.4026(10.2973) | Error 0.2085(0.2184) Steps 658(672.41) | Grad Norm 5.8582(4.7186) | Total Time 0.00(0.00)\n",
      "Iter 1097 | Time 65.3593(66.9165) | Bit/dim 3.7177(3.7263) | Xent 0.5651(0.5956) | Loss 9.4402(10.2716) | Error 0.2027(0.2179) Steps 676(672.52) | Grad Norm 6.7113(4.7784) | Total Time 0.00(0.00)\n",
      "Iter 1098 | Time 65.7320(66.8810) | Bit/dim 3.7119(3.7258) | Xent 0.5552(0.5944) | Loss 9.5295(10.2493) | Error 0.2080(0.2176) Steps 670(672.44) | Grad Norm 4.0850(4.7576) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0183 | Time 24.9380, Epoch Time 441.4146(420.5700), Bit/dim 3.7320(best: 3.7285), Xent 1.5047, Loss 4.4843, Error 0.4152(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1099 | Time 66.5956(66.8724) | Bit/dim 3.7271(3.7259) | Xent 0.5654(0.5935) | Loss 14.4512(10.3754) | Error 0.2067(0.2173) Steps 682(672.73) | Grad Norm 7.0385(4.8260) | Total Time 0.00(0.00)\n",
      "Iter 1100 | Time 70.4748(66.9805) | Bit/dim 3.7084(3.7253) | Xent 0.5410(0.5919) | Loss 9.5644(10.3510) | Error 0.2016(0.2168) Steps 688(673.19) | Grad Norm 6.1564(4.8659) | Total Time 0.00(0.00)\n",
      "Iter 1101 | Time 68.2406(67.0183) | Bit/dim 3.7155(3.7251) | Xent 0.5582(0.5909) | Loss 9.1957(10.3164) | Error 0.2045(0.2165) Steps 688(673.63) | Grad Norm 8.4830(4.9744) | Total Time 0.00(0.00)\n",
      "Iter 1102 | Time 69.0219(67.0784) | Bit/dim 3.7266(3.7251) | Xent 0.5453(0.5895) | Loss 9.4033(10.2890) | Error 0.2009(0.2160) Steps 688(674.06) | Grad Norm 4.0284(4.9461) | Total Time 0.00(0.00)\n",
      "Iter 1103 | Time 69.9647(67.1650) | Bit/dim 3.7245(3.7251) | Xent 0.5638(0.5888) | Loss 9.5028(10.2654) | Error 0.2063(0.2157) Steps 706(675.02) | Grad Norm 5.8032(4.9718) | Total Time 0.00(0.00)\n",
      "Iter 1104 | Time 66.9571(67.1587) | Bit/dim 3.7407(3.7256) | Xent 0.5477(0.5875) | Loss 9.5018(10.2425) | Error 0.2015(0.2153) Steps 682(675.23) | Grad Norm 2.0826(4.8851) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0184 | Time 24.9790, Epoch Time 454.4045(421.5850), Bit/dim 3.7371(best: 3.7285), Xent 1.5576, Loss 4.5159, Error 0.4195(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1105 | Time 65.2767(67.1023) | Bit/dim 3.7307(3.7257) | Xent 0.5514(0.5865) | Loss 14.2823(10.3637) | Error 0.2056(0.2150) Steps 682(675.44) | Grad Norm 5.4631(4.9024) | Total Time 0.00(0.00)\n",
      "Iter 1106 | Time 67.1697(67.1043) | Bit/dim 3.7232(3.7256) | Xent 0.5564(0.5855) | Loss 9.5416(10.3390) | Error 0.2044(0.2147) Steps 664(675.09) | Grad Norm 4.3068(4.8846) | Total Time 0.00(0.00)\n",
      "Iter 1107 | Time 63.8307(67.0061) | Bit/dim 3.7279(3.7257) | Xent 0.5505(0.5845) | Loss 9.5380(10.3150) | Error 0.2016(0.2143) Steps 670(674.94) | Grad Norm 4.5532(4.8746) | Total Time 0.00(0.00)\n",
      "Iter 1108 | Time 66.6987(66.9969) | Bit/dim 3.7239(3.7256) | Xent 0.5384(0.5831) | Loss 9.2721(10.2837) | Error 0.2004(0.2139) Steps 676(674.97) | Grad Norm 3.2685(4.8264) | Total Time 0.00(0.00)\n",
      "Iter 1109 | Time 67.4562(67.0107) | Bit/dim 3.7196(3.7255) | Xent 0.5282(0.5815) | Loss 9.6184(10.2637) | Error 0.1970(0.2134) Steps 676(675.00) | Grad Norm 3.3509(4.7822) | Total Time 0.00(0.00)\n",
      "Iter 1110 | Time 70.8500(67.1258) | Bit/dim 3.7256(3.7255) | Xent 0.5204(0.5796) | Loss 9.5366(10.2419) | Error 0.1897(0.2127) Steps 694(675.57) | Grad Norm 4.7887(4.7824) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0185 | Time 24.6278, Epoch Time 444.2672(422.2655), Bit/dim 3.7371(best: 3.7285), Xent 1.5735, Loss 4.5239, Error 0.4168(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1111 | Time 70.2135(67.2185) | Bit/dim 3.7224(3.7254) | Xent 0.5229(0.5779) | Loss 14.4954(10.3695) | Error 0.1921(0.2120) Steps 688(675.94) | Grad Norm 4.5566(4.7756) | Total Time 0.00(0.00)\n",
      "Iter 1112 | Time 61.6363(67.0510) | Bit/dim 3.7282(3.7255) | Xent 0.5288(0.5765) | Loss 9.5155(10.3439) | Error 0.1909(0.2114) Steps 652(675.23) | Grad Norm 2.4829(4.7068) | Total Time 0.00(0.00)\n",
      "Iter 1113 | Time 67.6376(67.0686) | Bit/dim 3.7276(3.7255) | Xent 0.5261(0.5750) | Loss 9.4835(10.3181) | Error 0.1940(0.2109) Steps 688(675.61) | Grad Norm 3.4595(4.6694) | Total Time 0.00(0.00)\n",
      "Iter 1114 | Time 65.8781(67.0329) | Bit/dim 3.7191(3.7253) | Xent 0.5450(0.5741) | Loss 9.5056(10.2937) | Error 0.2025(0.2106) Steps 622(674.00) | Grad Norm 2.6312(4.6082) | Total Time 0.00(0.00)\n",
      "Iter 1115 | Time 66.3115(67.0112) | Bit/dim 3.7249(3.7253) | Xent 0.5305(0.5727) | Loss 9.4518(10.2685) | Error 0.1931(0.2101) Steps 670(673.88) | Grad Norm 3.5386(4.5762) | Total Time 0.00(0.00)\n",
      "Iter 1116 | Time 70.4527(67.1145) | Bit/dim 3.7245(3.7253) | Xent 0.5426(0.5718) | Loss 9.4903(10.2451) | Error 0.1986(0.2098) Steps 688(674.30) | Grad Norm 4.2390(4.5660) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0186 | Time 24.8490, Epoch Time 445.3971(422.9594), Bit/dim 3.7318(best: 3.7285), Xent 1.5409, Loss 4.5023, Error 0.4152(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1117 | Time 68.9386(67.1692) | Bit/dim 3.7217(3.7252) | Xent 0.5374(0.5708) | Loss 14.1300(10.3617) | Error 0.1986(0.2094) Steps 646(673.46) | Grad Norm 6.3885(4.6207) | Total Time 0.00(0.00)\n",
      "Iter 1118 | Time 65.5049(67.1193) | Bit/dim 3.7268(3.7252) | Xent 0.5319(0.5696) | Loss 9.3551(10.3315) | Error 0.1993(0.2091) Steps 670(673.35) | Grad Norm 5.0859(4.6347) | Total Time 0.00(0.00)\n",
      "Iter 1119 | Time 68.2020(67.1518) | Bit/dim 3.7311(3.7254) | Xent 0.5338(0.5686) | Loss 9.5711(10.3087) | Error 0.1941(0.2087) Steps 652(672.71) | Grad Norm 3.8465(4.6110) | Total Time 0.00(0.00)\n",
      "Iter 1120 | Time 67.5961(67.1651) | Bit/dim 3.7316(3.7256) | Xent 0.5333(0.5675) | Loss 9.3646(10.2803) | Error 0.1950(0.2083) Steps 694(673.35) | Grad Norm 2.7930(4.5565) | Total Time 0.00(0.00)\n",
      "Iter 1121 | Time 63.8224(67.0648) | Bit/dim 3.7164(3.7253) | Xent 0.5363(0.5666) | Loss 9.4341(10.2549) | Error 0.1959(0.2079) Steps 658(672.89) | Grad Norm 4.2692(4.5479) | Total Time 0.00(0.00)\n",
      "Iter 1122 | Time 67.8226(67.0875) | Bit/dim 3.7216(3.7252) | Xent 0.5350(0.5656) | Loss 9.4759(10.2316) | Error 0.1936(0.2075) Steps 640(671.90) | Grad Norm 3.7068(4.5226) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0187 | Time 24.8972, Epoch Time 446.6380(423.6698), Bit/dim 3.7304(best: 3.7285), Xent 1.5393, Loss 4.5000, Error 0.4116(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1123 | Time 69.7362(67.1670) | Bit/dim 3.7323(3.7254) | Xent 0.5225(0.5643) | Loss 14.2801(10.3530) | Error 0.1929(0.2070) Steps 646(671.13) | Grad Norm 2.9667(4.4760) | Total Time 0.00(0.00)\n",
      "Iter 1124 | Time 70.4241(67.2647) | Bit/dim 3.7212(3.7253) | Xent 0.5162(0.5629) | Loss 9.4847(10.3270) | Error 0.1905(0.2065) Steps 670(671.09) | Grad Norm 3.0140(4.4321) | Total Time 0.00(0.00)\n",
      "Iter 1125 | Time 66.8097(67.2511) | Bit/dim 3.7250(3.7253) | Xent 0.5155(0.5615) | Loss 9.5887(10.3048) | Error 0.1896(0.2060) Steps 664(670.88) | Grad Norm 2.5558(4.3758) | Total Time 0.00(0.00)\n",
      "Iter 1126 | Time 68.9507(67.3021) | Bit/dim 3.7263(3.7253) | Xent 0.5129(0.5600) | Loss 9.5837(10.2832) | Error 0.1890(0.2055) Steps 658(670.49) | Grad Norm 3.1859(4.3401) | Total Time 0.00(0.00)\n",
      "Iter 1127 | Time 66.3617(67.2738) | Bit/dim 3.7236(3.7253) | Xent 0.5307(0.5591) | Loss 9.5953(10.2626) | Error 0.1934(0.2051) Steps 676(670.66) | Grad Norm 3.5102(4.3152) | Total Time 0.00(0.00)\n",
      "Iter 1128 | Time 68.0722(67.2978) | Bit/dim 3.7158(3.7250) | Xent 0.5349(0.5584) | Loss 9.6290(10.2436) | Error 0.1995(0.2050) Steps 670(670.64) | Grad Norm 4.8192(4.3303) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0188 | Time 25.4127, Epoch Time 454.1951(424.5855), Bit/dim 3.7308(best: 3.7285), Xent 1.5601, Loss 4.5109, Error 0.4139(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1129 | Time 65.9171(67.2564) | Bit/dim 3.7286(3.7251) | Xent 0.5337(0.5577) | Loss 14.1705(10.3614) | Error 0.1960(0.2047) Steps 682(670.98) | Grad Norm 8.6259(4.4592) | Total Time 0.00(0.00)\n",
      "Iter 1130 | Time 71.1499(67.3732) | Bit/dim 3.7144(3.7248) | Xent 0.5360(0.5570) | Loss 9.2594(10.3283) | Error 0.2000(0.2046) Steps 700(671.85) | Grad Norm 8.7693(4.5885) | Total Time 0.00(0.00)\n",
      "Iter 1131 | Time 65.2743(67.3102) | Bit/dim 3.7195(3.7246) | Xent 0.5258(0.5561) | Loss 9.4238(10.3012) | Error 0.1934(0.2042) Steps 676(671.97) | Grad Norm 7.0010(4.6609) | Total Time 0.00(0.00)\n",
      "Iter 1132 | Time 69.5382(67.3771) | Bit/dim 3.7239(3.7246) | Xent 0.5125(0.5548) | Loss 9.5435(10.2784) | Error 0.1894(0.2038) Steps 664(671.74) | Grad Norm 4.4257(4.6538) | Total Time 0.00(0.00)\n",
      "Iter 1133 | Time 69.7242(67.4475) | Bit/dim 3.7275(3.7247) | Xent 0.5320(0.5541) | Loss 9.5664(10.2571) | Error 0.1964(0.2036) Steps 670(671.68) | Grad Norm 6.0477(4.6956) | Total Time 0.00(0.00)\n",
      "Iter 1134 | Time 72.4007(67.5961) | Bit/dim 3.7221(3.7246) | Xent 0.5275(0.5533) | Loss 9.5014(10.2344) | Error 0.1917(0.2032) Steps 712(672.89) | Grad Norm 6.0038(4.7349) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0189 | Time 24.1021, Epoch Time 455.9641(425.5269), Bit/dim 3.7323(best: 3.7285), Xent 1.5477, Loss 4.5062, Error 0.4127(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1135 | Time 67.1587(67.5829) | Bit/dim 3.7251(3.7246) | Xent 0.4999(0.5517) | Loss 14.5854(10.3649) | Error 0.1836(0.2026) Steps 682(673.17) | Grad Norm 3.1671(4.6879) | Total Time 0.00(0.00)\n",
      "Iter 1136 | Time 70.2888(67.6641) | Bit/dim 3.7171(3.7244) | Xent 0.5024(0.5502) | Loss 9.4887(10.3387) | Error 0.1816(0.2020) Steps 640(672.17) | Grad Norm 2.5677(4.6242) | Total Time 0.00(0.00)\n",
      "Iter 1137 | Time 71.4326(67.7772) | Bit/dim 3.7220(3.7243) | Xent 0.5307(0.5496) | Loss 9.7294(10.3204) | Error 0.1941(0.2018) Steps 676(672.29) | Grad Norm 3.5390(4.5917) | Total Time 0.00(0.00)\n",
      "Iter 1138 | Time 67.9586(67.7826) | Bit/dim 3.7340(3.7246) | Xent 0.5202(0.5487) | Loss 9.2414(10.2880) | Error 0.1905(0.2014) Steps 700(673.12) | Grad Norm 3.7458(4.5663) | Total Time 0.00(0.00)\n",
      "Iter 1139 | Time 67.0902(67.7618) | Bit/dim 3.7127(3.7242) | Xent 0.5067(0.5475) | Loss 9.4444(10.2627) | Error 0.1886(0.2010) Steps 676(673.20) | Grad Norm 4.0425(4.5506) | Total Time 0.00(0.00)\n",
      "Iter 1140 | Time 69.7399(67.8212) | Bit/dim 3.7106(3.7238) | Xent 0.4900(0.5458) | Loss 9.4967(10.2397) | Error 0.1817(0.2005) Steps 670(673.11) | Grad Norm 3.2312(4.5110) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0190 | Time 23.9954, Epoch Time 455.9909(426.4408), Bit/dim 3.7394(best: 3.7285), Xent 1.5880, Loss 4.5334, Error 0.4162(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1141 | Time 63.0188(67.6771) | Bit/dim 3.7224(3.7238) | Xent 0.5028(0.5445) | Loss 14.9422(10.3808) | Error 0.1819(0.1999) Steps 670(673.01) | Grad Norm 7.1288(4.5895) | Total Time 0.00(0.00)\n",
      "Iter 1142 | Time 66.7474(67.6492) | Bit/dim 3.7207(3.7237) | Xent 0.5266(0.5439) | Loss 9.5255(10.3551) | Error 0.1957(0.1998) Steps 676(673.10) | Grad Norm 5.8798(4.6283) | Total Time 0.00(0.00)\n",
      "Iter 1143 | Time 65.1170(67.5733) | Bit/dim 3.7178(3.7235) | Xent 0.5567(0.5443) | Loss 9.7059(10.3357) | Error 0.2051(0.1999) Steps 676(673.19) | Grad Norm 9.7198(4.7810) | Total Time 0.00(0.00)\n",
      "Iter 1144 | Time 65.6254(67.5148) | Bit/dim 3.7378(3.7240) | Xent 0.5631(0.5449) | Loss 9.5348(10.3116) | Error 0.2035(0.2000) Steps 676(673.28) | Grad Norm 10.2762(4.9459) | Total Time 0.00(0.00)\n",
      "Iter 1145 | Time 65.4502(67.4529) | Bit/dim 3.7243(3.7240) | Xent 0.5416(0.5448) | Loss 9.6789(10.2927) | Error 0.2053(0.2002) Steps 676(673.36) | Grad Norm 14.4597(5.2313) | Total Time 0.00(0.00)\n",
      "Iter 1146 | Time 67.9940(67.4691) | Bit/dim 3.7190(3.7238) | Xent 0.5077(0.5437) | Loss 9.5431(10.2702) | Error 0.1900(0.1999) Steps 664(673.08) | Grad Norm 7.5566(5.3010) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0191 | Time 25.0732, Epoch Time 436.7956(426.7514), Bit/dim 3.7356(best: 3.7285), Xent 1.5710, Loss 4.5211, Error 0.4169(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1147 | Time 66.4426(67.4383) | Bit/dim 3.7177(3.7236) | Xent 0.5236(0.5431) | Loss 13.8738(10.3783) | Error 0.1914(0.1996) Steps 676(673.16) | Grad Norm 8.6996(5.4030) | Total Time 0.00(0.00)\n",
      "Iter 1148 | Time 66.2479(67.4026) | Bit/dim 3.7279(3.7238) | Xent 0.5302(0.5427) | Loss 9.5624(10.3538) | Error 0.1913(0.1994) Steps 682(673.43) | Grad Norm 9.7087(5.5322) | Total Time 0.00(0.00)\n",
      "Iter 1149 | Time 70.7022(67.5016) | Bit/dim 3.7273(3.7239) | Xent 0.5154(0.5419) | Loss 9.6506(10.3327) | Error 0.1929(0.1992) Steps 670(673.33) | Grad Norm 4.5531(5.5028) | Total Time 0.00(0.00)\n",
      "Iter 1150 | Time 68.9491(67.5450) | Bit/dim 3.7162(3.7236) | Xent 0.5105(0.5409) | Loss 9.4379(10.3059) | Error 0.1895(0.1989) Steps 658(672.87) | Grad Norm 5.7764(5.5110) | Total Time 0.00(0.00)\n",
      "Iter 1151 | Time 70.3144(67.6281) | Bit/dim 3.7134(3.7233) | Xent 0.5395(0.5409) | Loss 9.4599(10.2805) | Error 0.2004(0.1989) Steps 694(673.50) | Grad Norm 5.4387(5.5088) | Total Time 0.00(0.00)\n",
      "Iter 1152 | Time 67.1422(67.6135) | Bit/dim 3.7206(3.7232) | Xent 0.4895(0.5393) | Loss 9.5930(10.2599) | Error 0.1840(0.1985) Steps 688(673.94) | Grad Norm 1.7612(5.3964) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0192 | Time 25.0682, Epoch Time 453.2312(427.5458), Bit/dim 3.7321(best: 3.7285), Xent 1.6832, Loss 4.5737, Error 0.4217(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1153 | Time 66.9217(67.5928) | Bit/dim 3.7213(3.7232) | Xent 0.5214(0.5388) | Loss 14.5780(10.3894) | Error 0.1935(0.1983) Steps 670(673.82) | Grad Norm 6.3244(5.4242) | Total Time 0.00(0.00)\n",
      "Iter 1154 | Time 74.2529(67.7926) | Bit/dim 3.7231(3.7232) | Xent 0.5100(0.5379) | Loss 9.6760(10.3680) | Error 0.1883(0.1980) Steps 682(674.06) | Grad Norm 10.1195(5.5651) | Total Time 0.00(0.00)\n",
      "Iter 1155 | Time 67.3563(67.7795) | Bit/dim 3.7207(3.7231) | Xent 0.5044(0.5369) | Loss 9.5036(10.3421) | Error 0.1877(0.1977) Steps 664(673.76) | Grad Norm 5.2986(5.5571) | Total Time 0.00(0.00)\n",
      "Iter 1156 | Time 67.8850(67.7827) | Bit/dim 3.7228(3.7231) | Xent 0.5251(0.5366) | Loss 9.8250(10.3266) | Error 0.1891(0.1975) Steps 682(674.01) | Grad Norm 7.9270(5.6282) | Total Time 0.00(0.00)\n",
      "Iter 1157 | Time 67.0235(67.7599) | Bit/dim 3.7173(3.7229) | Xent 0.4860(0.5351) | Loss 9.3917(10.2985) | Error 0.1776(0.1969) Steps 670(673.89) | Grad Norm 4.3685(5.5904) | Total Time 0.00(0.00)\n",
      "Iter 1158 | Time 72.2819(67.8955) | Bit/dim 3.7223(3.7229) | Xent 0.5014(0.5341) | Loss 9.4152(10.2720) | Error 0.1835(0.1965) Steps 688(674.31) | Grad Norm 4.4364(5.5558) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0193 | Time 24.9571, Epoch Time 458.7175(428.4810), Bit/dim 3.7317(best: 3.7285), Xent 1.6136, Loss 4.5385, Error 0.4175(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1159 | Time 63.0665(67.7507) | Bit/dim 3.7220(3.7229) | Xent 0.4864(0.5326) | Loss 13.7965(10.3777) | Error 0.1815(0.1960) Steps 670(674.18) | Grad Norm 3.9680(5.5082) | Total Time 0.00(0.00)\n",
      "Iter 1160 | Time 66.9044(67.7253) | Bit/dim 3.7320(3.7232) | Xent 0.4926(0.5314) | Loss 9.4666(10.3504) | Error 0.1853(0.1957) Steps 646(673.34) | Grad Norm 4.7236(5.4846) | Total Time 0.00(0.00)\n",
      "Iter 1161 | Time 67.9342(67.7315) | Bit/dim 3.7223(3.7231) | Xent 0.5044(0.5306) | Loss 9.4409(10.3231) | Error 0.1856(0.1954) Steps 682(673.60) | Grad Norm 2.5728(5.3973) | Total Time 0.00(0.00)\n",
      "Iter 1162 | Time 66.8496(67.7051) | Bit/dim 3.7183(3.7230) | Xent 0.4776(0.5290) | Loss 9.4020(10.2955) | Error 0.1746(0.1948) Steps 670(673.49) | Grad Norm 4.6180(5.3739) | Total Time 0.00(0.00)\n",
      "Iter 1163 | Time 65.3463(67.6343) | Bit/dim 3.7112(3.7226) | Xent 0.4866(0.5277) | Loss 9.5031(10.2717) | Error 0.1777(0.1943) Steps 670(673.38) | Grad Norm 2.7965(5.2966) | Total Time 0.00(0.00)\n",
      "Iter 1164 | Time 65.2136(67.5617) | Bit/dim 3.7204(3.7226) | Xent 0.4864(0.5265) | Loss 9.3646(10.2445) | Error 0.1747(0.1937) Steps 676(673.46) | Grad Norm 3.3380(5.2378) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0194 | Time 25.0072, Epoch Time 439.0360(428.7976), Bit/dim 3.7353(best: 3.7285), Xent 1.6728, Loss 4.5717, Error 0.4167(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1165 | Time 65.8369(67.5100) | Bit/dim 3.7321(3.7228) | Xent 0.4789(0.5251) | Loss 14.5453(10.3735) | Error 0.1757(0.1931) Steps 670(673.36) | Grad Norm 2.7923(5.1644) | Total Time 0.00(0.00)\n",
      "Iter 1166 | Time 68.7893(67.5483) | Bit/dim 3.7207(3.7228) | Xent 0.4748(0.5236) | Loss 9.3223(10.3420) | Error 0.1724(0.1925) Steps 652(672.72) | Grad Norm 2.5409(5.0857) | Total Time 0.00(0.00)\n",
      "Iter 1167 | Time 66.9464(67.5303) | Bit/dim 3.7199(3.7227) | Xent 0.4775(0.5222) | Loss 9.3853(10.3133) | Error 0.1769(0.1921) Steps 688(673.18) | Grad Norm 2.2173(4.9997) | Total Time 0.00(0.00)\n",
      "Iter 1168 | Time 64.1855(67.4299) | Bit/dim 3.7222(3.7227) | Xent 0.4957(0.5214) | Loss 9.4920(10.2887) | Error 0.1810(0.1917) Steps 664(672.90) | Grad Norm 6.0739(5.0319) | Total Time 0.00(0.00)\n",
      "Iter 1169 | Time 67.9018(67.4441) | Bit/dim 3.7148(3.7224) | Xent 0.4978(0.5207) | Loss 9.4899(10.2647) | Error 0.1871(0.1916) Steps 676(672.99) | Grad Norm 9.2126(5.1573) | Total Time 0.00(0.00)\n",
      "Iter 1170 | Time 64.6740(67.3610) | Bit/dim 3.7113(3.7221) | Xent 0.5228(0.5207) | Loss 9.5547(10.2434) | Error 0.1927(0.1916) Steps 664(672.72) | Grad Norm 7.7904(5.2363) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0195 | Time 24.2609, Epoch Time 441.3019(429.1728), Bit/dim 3.7356(best: 3.7285), Xent 1.6605, Loss 4.5658, Error 0.4238(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1171 | Time 65.3806(67.3016) | Bit/dim 3.7304(3.7224) | Xent 0.5104(0.5204) | Loss 14.8023(10.3802) | Error 0.1881(0.1915) Steps 634(671.56) | Grad Norm 8.7576(5.3420) | Total Time 0.00(0.00)\n",
      "Iter 1172 | Time 68.3379(67.3327) | Bit/dim 3.7182(3.7222) | Xent 0.4838(0.5193) | Loss 9.3480(10.3492) | Error 0.1771(0.1911) Steps 676(671.70) | Grad Norm 10.1683(5.4868) | Total Time 0.00(0.00)\n",
      "Iter 1173 | Time 63.4811(67.2171) | Bit/dim 3.7281(3.7224) | Xent 0.4756(0.5180) | Loss 9.3764(10.3200) | Error 0.1699(0.1904) Steps 658(671.28) | Grad Norm 6.2245(5.5089) | Total Time 0.00(0.00)\n",
      "Iter 1174 | Time 66.0447(67.1819) | Bit/dim 3.7164(3.7222) | Xent 0.5025(0.5176) | Loss 9.5153(10.2959) | Error 0.1865(0.1903) Steps 682(671.61) | Grad Norm 5.9020(5.5207) | Total Time 0.00(0.00)\n",
      "Iter 1175 | Time 69.0939(67.2393) | Bit/dim 3.7127(3.7219) | Xent 0.5050(0.5172) | Loss 9.4747(10.2712) | Error 0.1856(0.1902) Steps 664(671.38) | Grad Norm 10.1570(5.6598) | Total Time 0.00(0.00)\n",
      "Iter 1176 | Time 68.3928(67.2739) | Bit/dim 3.7189(3.7219) | Xent 0.4971(0.5166) | Loss 9.3526(10.2437) | Error 0.1861(0.1901) Steps 700(672.24) | Grad Norm 7.3929(5.7118) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0196 | Time 25.0941, Epoch Time 444.2468(429.6250), Bit/dim 3.7312(best: 3.7285), Xent 1.6286, Loss 4.5455, Error 0.4160(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1177 | Time 63.6389(67.1649) | Bit/dim 3.7263(3.7220) | Xent 0.4711(0.5152) | Loss 13.0889(10.3290) | Error 0.1744(0.1896) Steps 670(672.17) | Grad Norm 2.9377(5.6285) | Total Time 0.00(0.00)\n",
      "Iter 1178 | Time 66.7337(67.1519) | Bit/dim 3.7283(3.7222) | Xent 0.5067(0.5150) | Loss 9.4609(10.3030) | Error 0.1880(0.1895) Steps 694(672.82) | Grad Norm 7.6834(5.6902) | Total Time 0.00(0.00)\n",
      "Iter 1179 | Time 65.0158(67.0878) | Bit/dim 3.7200(3.7221) | Xent 0.5403(0.5157) | Loss 9.6434(10.2832) | Error 0.1986(0.1898) Steps 670(672.74) | Grad Norm 9.8644(5.8154) | Total Time 0.00(0.00)\n",
      "Iter 1180 | Time 68.0453(67.1166) | Bit/dim 3.7225(3.7221) | Xent 0.5021(0.5153) | Loss 9.6793(10.2651) | Error 0.1850(0.1897) Steps 676(672.84) | Grad Norm 9.5374(5.9271) | Total Time 0.00(0.00)\n",
      "Iter 1181 | Time 60.8740(66.9293) | Bit/dim 3.7149(3.7219) | Xent 0.4804(0.5143) | Loss 9.3437(10.2374) | Error 0.1761(0.1893) Steps 640(671.85) | Grad Norm 3.9452(5.8676) | Total Time 0.00(0.00)\n",
      "Iter 1182 | Time 69.6454(67.0108) | Bit/dim 3.7120(3.7216) | Xent 0.4783(0.5132) | Loss 9.5032(10.2154) | Error 0.1734(0.1888) Steps 688(672.34) | Grad Norm 7.5297(5.9175) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0197 | Time 24.7943, Epoch Time 437.1434(429.8505), Bit/dim 3.7323(best: 3.7285), Xent 1.6835, Loss 4.5740, Error 0.4227(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1183 | Time 66.7229(67.0021) | Bit/dim 3.7174(3.7215) | Xent 0.4922(0.5126) | Loss 14.0332(10.3299) | Error 0.1859(0.1887) Steps 688(672.81) | Grad Norm 5.9430(5.9182) | Total Time 0.00(0.00)\n",
      "Iter 1184 | Time 70.4893(67.1068) | Bit/dim 3.7138(3.7213) | Xent 0.4960(0.5121) | Loss 9.5122(10.3054) | Error 0.1829(0.1885) Steps 694(673.44) | Grad Norm 8.1674(5.9857) | Total Time 0.00(0.00)\n",
      "Iter 1185 | Time 69.1895(67.1692) | Bit/dim 3.7097(3.7209) | Xent 0.4913(0.5114) | Loss 9.6032(10.2844) | Error 0.1803(0.1883) Steps 682(673.70) | Grad Norm 7.3707(6.0273) | Total Time 0.00(0.00)\n",
      "Iter 1186 | Time 68.7534(67.2168) | Bit/dim 3.7225(3.7210) | Xent 0.5099(0.5114) | Loss 9.6258(10.2646) | Error 0.1903(0.1883) Steps 664(673.41) | Grad Norm 4.6273(5.9853) | Total Time 0.00(0.00)\n",
      "Iter 1187 | Time 72.2537(67.3679) | Bit/dim 3.7237(3.7210) | Xent 0.4839(0.5106) | Loss 9.3017(10.2357) | Error 0.1804(0.1881) Steps 688(673.85) | Grad Norm 4.5747(5.9430) | Total Time 0.00(0.00)\n",
      "Iter 1188 | Time 71.3447(67.4872) | Bit/dim 3.7149(3.7208) | Xent 0.4590(0.5090) | Loss 9.4370(10.2117) | Error 0.1704(0.1876) Steps 670(673.73) | Grad Norm 3.3950(5.8665) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0198 | Time 24.6271, Epoch Time 461.7689(430.8081), Bit/dim 3.7303(best: 3.7285), Xent 1.6656, Loss 4.5631, Error 0.4205(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1189 | Time 68.3010(67.5116) | Bit/dim 3.7292(3.7211) | Xent 0.4573(0.5075) | Loss 14.1737(10.3306) | Error 0.1684(0.1870) Steps 646(672.90) | Grad Norm 3.3941(5.7923) | Total Time 0.00(0.00)\n",
      "Iter 1190 | Time 64.9801(67.4356) | Bit/dim 3.7061(3.7207) | Xent 0.4655(0.5062) | Loss 9.4149(10.3031) | Error 0.1701(0.1865) Steps 670(672.81) | Grad Norm 2.6891(5.6992) | Total Time 0.00(0.00)\n",
      "Iter 1191 | Time 66.7139(67.4140) | Bit/dim 3.7066(3.7202) | Xent 0.4777(0.5054) | Loss 9.3323(10.2740) | Error 0.1765(0.1862) Steps 664(672.55) | Grad Norm 4.3341(5.6583) | Total Time 0.00(0.00)\n",
      "Iter 1192 | Time 66.8964(67.3985) | Bit/dim 3.7286(3.7205) | Xent 0.4858(0.5048) | Loss 9.5149(10.2512) | Error 0.1797(0.1860) Steps 652(671.93) | Grad Norm 3.7735(5.6017) | Total Time 0.00(0.00)\n",
      "Iter 1193 | Time 63.3375(67.2766) | Bit/dim 3.7113(3.7202) | Xent 0.4763(0.5039) | Loss 9.4717(10.2279) | Error 0.1771(0.1857) Steps 670(671.87) | Grad Norm 4.6603(5.5735) | Total Time 0.00(0.00)\n",
      "Iter 1194 | Time 68.8438(67.3237) | Bit/dim 3.7262(3.7204) | Xent 0.4440(0.5021) | Loss 9.4117(10.2034) | Error 0.1654(0.1851) Steps 664(671.64) | Grad Norm 2.1579(5.4710) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0199 | Time 24.9552, Epoch Time 442.5023(431.1589), Bit/dim 3.7294(best: 3.7285), Xent 1.7280, Loss 4.5934, Error 0.4263(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1195 | Time 62.2082(67.1702) | Bit/dim 3.7205(3.7204) | Xent 0.4762(0.5013) | Loss 13.9866(10.3169) | Error 0.1755(0.1848) Steps 664(671.41) | Grad Norm 4.8823(5.4534) | Total Time 0.00(0.00)\n",
      "Iter 1196 | Time 70.4266(67.2679) | Bit/dim 3.7251(3.7205) | Xent 0.4519(0.4999) | Loss 9.1945(10.2832) | Error 0.1661(0.1843) Steps 670(671.37) | Grad Norm 4.3849(5.4213) | Total Time 0.00(0.00)\n",
      "Iter 1197 | Time 67.0814(67.2623) | Bit/dim 3.7216(3.7206) | Xent 0.4843(0.4994) | Loss 9.4646(10.2586) | Error 0.1747(0.1840) Steps 658(670.96) | Grad Norm 8.1263(5.5025) | Total Time 0.00(0.00)\n",
      "Iter 1198 | Time 67.4564(67.2681) | Bit/dim 3.7157(3.7204) | Xent 0.4828(0.4989) | Loss 9.4968(10.2358) | Error 0.1759(0.1837) Steps 688(671.48) | Grad Norm 9.2724(5.6156) | Total Time 0.00(0.00)\n",
      "Iter 1199 | Time 70.0158(67.3505) | Bit/dim 3.7120(3.7202) | Xent 0.5129(0.4993) | Loss 9.5510(10.2152) | Error 0.1941(0.1840) Steps 688(671.97) | Grad Norm 9.3450(5.7274) | Total Time 0.00(0.00)\n",
      "Iter 1200 | Time 62.9399(67.2182) | Bit/dim 3.7089(3.7198) | Xent 0.4827(0.4988) | Loss 9.1106(10.1821) | Error 0.1759(0.1838) Steps 646(671.19) | Grad Norm 5.4463(5.7190) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0200 | Time 24.3827, Epoch Time 444.1513(431.5487), Bit/dim 3.7335(best: 3.7285), Xent 1.6936, Loss 4.5803, Error 0.4253(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1201 | Time 64.6972(67.1426) | Bit/dim 3.7102(3.7195) | Xent 0.4813(0.4983) | Loss 15.0795(10.3290) | Error 0.1820(0.1838) Steps 688(671.70) | Grad Norm 5.6393(5.7166) | Total Time 0.00(0.00)\n",
      "Iter 1202 | Time 70.4035(67.2404) | Bit/dim 3.7151(3.7194) | Xent 0.4816(0.4978) | Loss 9.3388(10.2993) | Error 0.1806(0.1837) Steps 700(672.55) | Grad Norm 4.7320(5.6871) | Total Time 0.00(0.00)\n",
      "Iter 1203 | Time 68.2015(67.2693) | Bit/dim 3.7041(3.7189) | Xent 0.4658(0.4968) | Loss 9.5054(10.2755) | Error 0.1710(0.1833) Steps 682(672.83) | Grad Norm 6.7288(5.7183) | Total Time 0.00(0.00)\n",
      "Iter 1204 | Time 69.2972(67.3301) | Bit/dim 3.7253(3.7191) | Xent 0.4448(0.4953) | Loss 9.3994(10.2492) | Error 0.1650(0.1827) Steps 658(672.38) | Grad Norm 3.9677(5.6658) | Total Time 0.00(0.00)\n",
      "Iter 1205 | Time 68.5136(67.3656) | Bit/dim 3.7246(3.7193) | Xent 0.4600(0.4942) | Loss 9.3842(10.2233) | Error 0.1680(0.1823) Steps 658(671.95) | Grad Norm 5.1672(5.6509) | Total Time 0.00(0.00)\n",
      "Iter 1206 | Time 70.6227(67.4633) | Bit/dim 3.7306(3.7196) | Xent 0.4638(0.4933) | Loss 9.3880(10.1982) | Error 0.1679(0.1819) Steps 670(671.89) | Grad Norm 3.3412(5.5816) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0201 | Time 25.1641, Epoch Time 456.4874(432.2969), Bit/dim 3.7349(best: 3.7285), Xent 1.7367, Loss 4.6032, Error 0.4223(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1207 | Time 64.5956(67.3773) | Bit/dim 3.7115(3.7194) | Xent 0.4677(0.4925) | Loss 14.3314(10.3222) | Error 0.1729(0.1816) Steps 658(671.48) | Grad Norm 4.5095(5.5494) | Total Time 0.00(0.00)\n",
      "Iter 1208 | Time 61.8382(67.2111) | Bit/dim 3.7281(3.7197) | Xent 0.4629(0.4916) | Loss 9.4243(10.2953) | Error 0.1716(0.1813) Steps 670(671.43) | Grad Norm 5.1142(5.5363) | Total Time 0.00(0.00)\n",
      "Iter 1209 | Time 69.1549(67.2694) | Bit/dim 3.7213(3.7197) | Xent 0.4615(0.4907) | Loss 9.3195(10.2660) | Error 0.1676(0.1809) Steps 652(670.85) | Grad Norm 3.1953(5.4661) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 68.8022(67.3154) | Bit/dim 3.7122(3.7195) | Xent 0.4537(0.4896) | Loss 9.5108(10.2433) | Error 0.1646(0.1804) Steps 646(670.10) | Grad Norm 5.9458(5.4805) | Total Time 0.00(0.00)\n",
      "Iter 1211 | Time 70.5291(67.4118) | Bit/dim 3.7194(3.7195) | Xent 0.4571(0.4886) | Loss 9.2646(10.2140) | Error 0.1715(0.1801) Steps 682(670.46) | Grad Norm 7.7610(5.5489) | Total Time 0.00(0.00)\n",
      "Iter 1212 | Time 68.3195(67.4390) | Bit/dim 3.7102(3.7192) | Xent 0.4586(0.4877) | Loss 9.4724(10.1917) | Error 0.1715(0.1799) Steps 688(670.99) | Grad Norm 8.5927(5.6402) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0202 | Time 24.9867, Epoch Time 446.6171(432.7265), Bit/dim 3.7334(best: 3.7285), Xent 1.7321, Loss 4.5995, Error 0.4260(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1213 | Time 65.8856(67.3924) | Bit/dim 3.7196(3.7192) | Xent 0.4841(0.4876) | Loss 14.1821(10.3114) | Error 0.1749(0.1797) Steps 664(670.78) | Grad Norm 11.5728(5.8182) | Total Time 0.00(0.00)\n",
      "Iter 1214 | Time 68.8606(67.4365) | Bit/dim 3.7391(3.7198) | Xent 0.4718(0.4872) | Loss 9.4483(10.2855) | Error 0.1767(0.1796) Steps 694(671.47) | Grad Norm 8.8127(5.9080) | Total Time 0.00(0.00)\n",
      "Iter 1215 | Time 66.0451(67.3947) | Bit/dim 3.7059(3.7194) | Xent 0.4710(0.4867) | Loss 9.4647(10.2609) | Error 0.1756(0.1795) Steps 670(671.43) | Grad Norm 6.6020(5.9289) | Total Time 0.00(0.00)\n",
      "Iter 1216 | Time 69.8376(67.4680) | Bit/dim 3.7231(3.7195) | Xent 0.4468(0.4855) | Loss 9.3429(10.2334) | Error 0.1635(0.1790) Steps 652(670.85) | Grad Norm 6.3175(5.9405) | Total Time 0.00(0.00)\n",
      "Iter 1217 | Time 62.8564(67.3297) | Bit/dim 3.7180(3.7195) | Xent 0.4603(0.4847) | Loss 9.3213(10.2060) | Error 0.1721(0.1788) Steps 646(670.10) | Grad Norm 2.9316(5.8503) | Total Time 0.00(0.00)\n",
      "Iter 1218 | Time 70.7030(67.4309) | Bit/dim 3.7172(3.7194) | Xent 0.4420(0.4834) | Loss 9.4677(10.1839) | Error 0.1636(0.1784) Steps 664(669.92) | Grad Norm 6.0056(5.8549) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0203 | Time 24.4315, Epoch Time 447.1268(433.1585), Bit/dim 3.7299(best: 3.7285), Xent 1.7300, Loss 4.5948, Error 0.4199(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1219 | Time 68.0669(67.4500) | Bit/dim 3.7135(3.7192) | Xent 0.4441(0.4823) | Loss 13.6660(10.2883) | Error 0.1603(0.1778) Steps 682(670.28) | Grad Norm 6.1311(5.8632) | Total Time 0.00(0.00)\n",
      "Iter 1220 | Time 67.7606(67.4593) | Bit/dim 3.7359(3.7197) | Xent 0.4428(0.4811) | Loss 9.3963(10.2616) | Error 0.1607(0.1773) Steps 670(670.27) | Grad Norm 3.3481(5.7878) | Total Time 0.00(0.00)\n",
      "Iter 1221 | Time 66.9149(67.4429) | Bit/dim 3.7294(3.7200) | Xent 0.4283(0.4795) | Loss 9.6076(10.2420) | Error 0.1567(0.1767) Steps 658(669.90) | Grad Norm 5.7598(5.7869) | Total Time 0.00(0.00)\n",
      "Iter 1222 | Time 65.7505(67.3922) | Bit/dim 3.7035(3.7195) | Xent 0.4480(0.4785) | Loss 9.2122(10.2111) | Error 0.1641(0.1763) Steps 646(669.19) | Grad Norm 4.5506(5.7498) | Total Time 0.00(0.00)\n",
      "Iter 1223 | Time 67.8548(67.4060) | Bit/dim 3.7181(3.7195) | Xent 0.4406(0.4774) | Loss 9.1632(10.1796) | Error 0.1637(0.1759) Steps 694(669.93) | Grad Norm 4.9007(5.7243) | Total Time 0.00(0.00)\n",
      "Iter 1224 | Time 66.5635(67.3808) | Bit/dim 3.7105(3.7192) | Xent 0.4518(0.4766) | Loss 9.5526(10.1608) | Error 0.1665(0.1757) Steps 688(670.47) | Grad Norm 5.6051(5.7208) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0204 | Time 24.9714, Epoch Time 446.6430(433.5630), Bit/dim 3.7295(best: 3.7285), Xent 1.7385, Loss 4.5988, Error 0.4232(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1225 | Time 67.9588(67.3981) | Bit/dim 3.7173(3.7191) | Xent 0.4246(0.4751) | Loss 14.7510(10.2985) | Error 0.1580(0.1751) Steps 688(671.00) | Grad Norm 3.0326(5.6401) | Total Time 0.00(0.00)\n",
      "Iter 1226 | Time 63.4285(67.2790) | Bit/dim 3.7261(3.7193) | Xent 0.4366(0.4739) | Loss 9.2235(10.2663) | Error 0.1613(0.1747) Steps 658(670.61) | Grad Norm 4.3547(5.6016) | Total Time 0.00(0.00)\n",
      "Iter 1227 | Time 66.1804(67.2461) | Bit/dim 3.7181(3.7193) | Xent 0.4173(0.4722) | Loss 9.3082(10.2375) | Error 0.1544(0.1741) Steps 658(670.23) | Grad Norm 2.6884(5.5142) | Total Time 0.00(0.00)\n",
      "Iter 1228 | Time 63.8542(67.1443) | Bit/dim 3.7122(3.7191) | Xent 0.4273(0.4709) | Loss 9.3438(10.2107) | Error 0.1575(0.1736) Steps 664(670.04) | Grad Norm 3.8093(5.4630) | Total Time 0.00(0.00)\n",
      "Iter 1229 | Time 66.1900(67.1157) | Bit/dim 3.7165(3.7190) | Xent 0.4162(0.4692) | Loss 9.4712(10.1885) | Error 0.1564(0.1731) Steps 682(670.40) | Grad Norm 3.8086(5.4134) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 72.3694(67.2733) | Bit/dim 3.7131(3.7188) | Xent 0.4563(0.4689) | Loss 9.4183(10.1654) | Error 0.1675(0.1729) Steps 664(670.21) | Grad Norm 7.4245(5.4737) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0205 | Time 25.1560, Epoch Time 443.8393(433.8713), Bit/dim 3.7272(best: 3.7285), Xent 1.7649, Loss 4.6097, Error 0.4194(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1231 | Time 71.4274(67.3979) | Bit/dim 3.7072(3.7185) | Xent 0.4310(0.4677) | Loss 15.2585(10.3182) | Error 0.1620(0.1726) Steps 676(670.38) | Grad Norm 7.1780(5.5249) | Total Time 0.00(0.00)\n",
      "Iter 1232 | Time 69.4117(67.4583) | Bit/dim 3.7131(3.7183) | Xent 0.4326(0.4667) | Loss 9.2847(10.2872) | Error 0.1665(0.1724) Steps 688(670.91) | Grad Norm 7.2364(5.5762) | Total Time 0.00(0.00)\n",
      "Iter 1233 | Time 68.3087(67.4838) | Bit/dim 3.7335(3.7188) | Xent 0.4705(0.4668) | Loss 9.5557(10.2653) | Error 0.1765(0.1725) Steps 676(671.07) | Grad Norm 10.9987(5.7389) | Total Time 0.00(0.00)\n",
      "Iter 1234 | Time 65.1792(67.4147) | Bit/dim 3.7109(3.7185) | Xent 0.4711(0.4669) | Loss 9.4255(10.2401) | Error 0.1740(0.1726) Steps 670(671.03) | Grad Norm 12.7839(5.9502) | Total Time 0.00(0.00)\n",
      "Iter 1235 | Time 67.6205(67.4209) | Bit/dim 3.7195(3.7186) | Xent 0.4965(0.4678) | Loss 9.5964(10.2208) | Error 0.1831(0.1729) Steps 700(671.90) | Grad Norm 12.4033(6.1438) | Total Time 0.00(0.00)\n",
      "Iter 1236 | Time 74.0876(67.6209) | Bit/dim 3.7079(3.7183) | Xent 0.4496(0.4672) | Loss 9.5933(10.2019) | Error 0.1669(0.1727) Steps 652(671.31) | Grad Norm 6.6689(6.1596) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0206 | Time 24.9501, Epoch Time 459.6190(434.6437), Bit/dim 3.7284(best: 3.7272), Xent 1.6884, Loss 4.5726, Error 0.4155(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1237 | Time 66.4823(67.5867) | Bit/dim 3.7134(3.7181) | Xent 0.4396(0.4664) | Loss 14.9204(10.3435) | Error 0.1623(0.1724) Steps 682(671.63) | Grad Norm 3.3253(6.0745) | Total Time 0.00(0.00)\n",
      "Iter 1238 | Time 65.9887(67.5388) | Bit/dim 3.7250(3.7183) | Xent 0.4368(0.4655) | Loss 9.3224(10.3128) | Error 0.1656(0.1722) Steps 682(671.94) | Grad Norm 6.7105(6.0936) | Total Time 0.00(0.00)\n",
      "Iter 1239 | Time 66.6000(67.5106) | Bit/dim 3.7156(3.7182) | Xent 0.4432(0.4649) | Loss 9.4110(10.2858) | Error 0.1616(0.1719) Steps 658(671.52) | Grad Norm 6.0747(6.0931) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 68.1904(67.5310) | Bit/dim 3.7212(3.7183) | Xent 0.4210(0.4635) | Loss 9.3604(10.2580) | Error 0.1539(0.1713) Steps 670(671.47) | Grad Norm 2.6103(5.9886) | Total Time 0.00(0.00)\n",
      "Iter 1241 | Time 70.5210(67.6207) | Bit/dim 3.7206(3.7184) | Xent 0.4554(0.4633) | Loss 9.5790(10.2377) | Error 0.1664(0.1712) Steps 670(671.43) | Grad Norm 10.0630(6.1108) | Total Time 0.00(0.00)\n",
      "Iter 1242 | Time 64.9562(67.5408) | Bit/dim 3.7151(3.7183) | Xent 0.4654(0.4634) | Loss 9.2580(10.2083) | Error 0.1709(0.1712) Steps 676(671.57) | Grad Norm 9.7440(6.2198) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0207 | Time 24.8018, Epoch Time 445.0967(434.9573), Bit/dim 3.7290(best: 3.7272), Xent 1.7364, Loss 4.5972, Error 0.4176(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1243 | Time 68.2350(67.5616) | Bit/dim 3.7140(3.7182) | Xent 0.4087(0.4617) | Loss 15.3323(10.3620) | Error 0.1529(0.1706) Steps 694(672.24) | Grad Norm 3.8138(6.1476) | Total Time 0.00(0.00)\n",
      "Iter 1244 | Time 68.3206(67.5844) | Bit/dim 3.7199(3.7182) | Xent 0.4509(0.4614) | Loss 9.3297(10.3310) | Error 0.1677(0.1705) Steps 664(671.99) | Grad Norm 13.9344(6.3812) | Total Time 0.00(0.00)\n",
      "Iter 1245 | Time 68.8961(67.6237) | Bit/dim 3.7256(3.7184) | Xent 0.4698(0.4616) | Loss 9.4576(10.3048) | Error 0.1755(0.1707) Steps 664(671.75) | Grad Norm 12.9320(6.5777) | Total Time 0.00(0.00)\n",
      "Iter 1246 | Time 65.5808(67.5624) | Bit/dim 3.7278(3.7187) | Xent 0.4547(0.4614) | Loss 9.4004(10.2777) | Error 0.1676(0.1706) Steps 682(672.06) | Grad Norm 6.6414(6.5797) | Total Time 0.00(0.00)\n",
      "Iter 1247 | Time 66.3760(67.5268) | Bit/dim 3.7256(3.7189) | Xent 0.4765(0.4619) | Loss 9.0123(10.2397) | Error 0.1794(0.1709) Steps 670(672.00) | Grad Norm 10.3605(6.6931) | Total Time 0.00(0.00)\n",
      "Iter 1248 | Time 70.6134(67.6194) | Bit/dim 3.7057(3.7185) | Xent 0.4893(0.4627) | Loss 9.4584(10.2163) | Error 0.1866(0.1713) Steps 640(671.04) | Grad Norm 6.9712(6.7014) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0208 | Time 24.8182, Epoch Time 451.1846(435.4441), Bit/dim 3.7277(best: 3.7272), Xent 1.7156, Loss 4.5855, Error 0.4216(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1249 | Time 69.6189(67.6794) | Bit/dim 3.7052(3.7181) | Xent 0.4238(0.4615) | Loss 14.2763(10.3381) | Error 0.1579(0.1709) Steps 652(670.47) | Grad Norm 4.9348(6.6484) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 66.0940(67.6319) | Bit/dim 3.7070(3.7178) | Xent 0.4673(0.4617) | Loss 9.3686(10.3090) | Error 0.1736(0.1710) Steps 688(670.99) | Grad Norm 6.6197(6.6476) | Total Time 0.00(0.00)\n",
      "Iter 1251 | Time 63.6202(67.5115) | Bit/dim 3.7325(3.7182) | Xent 0.4417(0.4611) | Loss 9.5434(10.2860) | Error 0.1646(0.1708) Steps 676(671.14) | Grad Norm 7.3107(6.6675) | Total Time 0.00(0.00)\n",
      "Iter 1252 | Time 69.4640(67.5701) | Bit/dim 3.7131(3.7181) | Xent 0.4364(0.4604) | Loss 9.4312(10.2604) | Error 0.1645(0.1706) Steps 652(670.57) | Grad Norm 4.4319(6.6004) | Total Time 0.00(0.00)\n",
      "Iter 1253 | Time 73.1697(67.7381) | Bit/dim 3.7192(3.7181) | Xent 0.4347(0.4596) | Loss 9.4610(10.2364) | Error 0.1573(0.1702) Steps 694(671.27) | Grad Norm 6.5047(6.5975) | Total Time 0.00(0.00)\n",
      "Iter 1254 | Time 67.1783(67.7213) | Bit/dim 3.7176(3.7181) | Xent 0.4388(0.4590) | Loss 9.2003(10.2053) | Error 0.1611(0.1700) Steps 676(671.41) | Grad Norm 7.1956(6.6155) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0209 | Time 24.8399, Epoch Time 452.1135(435.9442), Bit/dim 3.7327(best: 3.7272), Xent 1.7988, Loss 4.6321, Error 0.4291(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1255 | Time 72.6086(67.8679) | Bit/dim 3.7150(3.7180) | Xent 0.4109(0.4575) | Loss 13.8432(10.3145) | Error 0.1526(0.1694) Steps 652(670.83) | Grad Norm 3.8701(6.5331) | Total Time 0.00(0.00)\n",
      "Iter 1256 | Time 69.2081(67.9081) | Bit/dim 3.7122(3.7178) | Xent 0.4239(0.4565) | Loss 9.3804(10.2864) | Error 0.1583(0.1691) Steps 688(671.35) | Grad Norm 6.7708(6.5402) | Total Time 0.00(0.00)\n",
      "Iter 1257 | Time 66.3344(67.8609) | Bit/dim 3.7219(3.7180) | Xent 0.4099(0.4551) | Loss 9.2709(10.2560) | Error 0.1475(0.1685) Steps 670(671.31) | Grad Norm 3.7040(6.4551) | Total Time 0.00(0.00)\n",
      "Iter 1258 | Time 64.4994(67.7600) | Bit/dim 3.7249(3.7182) | Xent 0.4198(0.4541) | Loss 9.3563(10.2290) | Error 0.1516(0.1679) Steps 676(671.45) | Grad Norm 3.1169(6.3550) | Total Time 0.00(0.00)\n",
      "Iter 1259 | Time 66.9588(67.7360) | Bit/dim 3.7250(3.7184) | Xent 0.4198(0.4530) | Loss 9.3250(10.2019) | Error 0.1558(0.1676) Steps 670(671.40) | Grad Norm 6.2902(6.3531) | Total Time 0.00(0.00)\n",
      "Iter 1260 | Time 70.6295(67.8228) | Bit/dim 3.7080(3.7181) | Xent 0.4085(0.4517) | Loss 9.3011(10.1748) | Error 0.1484(0.1670) Steps 640(670.46) | Grad Norm 4.9632(6.3114) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0210 | Time 24.9792, Epoch Time 453.3790(436.4673), Bit/dim 3.7344(best: 3.7272), Xent 1.7856, Loss 4.6272, Error 0.4223(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1261 | Time 69.8390(67.8833) | Bit/dim 3.7150(3.7180) | Xent 0.4071(0.4504) | Loss 14.4652(10.3036) | Error 0.1534(0.1666) Steps 652(669.91) | Grad Norm 3.9598(6.2408) | Total Time 0.00(0.00)\n",
      "Iter 1262 | Time 63.7796(67.7602) | Bit/dim 3.7221(3.7181) | Xent 0.4012(0.4489) | Loss 9.4673(10.2785) | Error 0.1468(0.1660) Steps 664(669.73) | Grad Norm 4.2768(6.1819) | Total Time 0.00(0.00)\n",
      "Iter 1263 | Time 66.2182(67.7139) | Bit/dim 3.7061(3.7177) | Xent 0.4043(0.4476) | Loss 9.3295(10.2500) | Error 0.1495(0.1655) Steps 652(669.20) | Grad Norm 4.4908(6.1312) | Total Time 0.00(0.00)\n",
      "Iter 1264 | Time 66.1173(67.6660) | Bit/dim 3.7285(3.7181) | Xent 0.4070(0.4463) | Loss 9.3605(10.2233) | Error 0.1509(0.1651) Steps 682(669.58) | Grad Norm 3.5669(6.0542) | Total Time 0.00(0.00)\n",
      "Iter 1265 | Time 70.0854(67.7386) | Bit/dim 3.7116(3.7179) | Xent 0.4110(0.4453) | Loss 9.2497(10.1941) | Error 0.1556(0.1648) Steps 694(670.32) | Grad Norm 6.9573(6.0813) | Total Time 0.00(0.00)\n",
      "Iter 1266 | Time 68.7083(67.7677) | Bit/dim 3.7104(3.7176) | Xent 0.4196(0.4445) | Loss 9.3120(10.1676) | Error 0.1545(0.1645) Steps 664(670.13) | Grad Norm 4.9237(6.0466) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0211 | Time 25.0434, Epoch Time 448.4175(436.8258), Bit/dim 3.7300(best: 3.7272), Xent 1.8451, Loss 4.6525, Error 0.4197(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1267 | Time 66.9355(67.7427) | Bit/dim 3.7105(3.7174) | Xent 0.3976(0.4431) | Loss 14.0827(10.2851) | Error 0.1460(0.1639) Steps 664(669.94) | Grad Norm 4.7663(6.0082) | Total Time 0.00(0.00)\n",
      "Iter 1268 | Time 66.1422(67.6947) | Bit/dim 3.7153(3.7174) | Xent 0.4040(0.4419) | Loss 9.4377(10.2597) | Error 0.1520(0.1636) Steps 664(669.76) | Grad Norm 4.4644(5.9619) | Total Time 0.00(0.00)\n",
      "Iter 1269 | Time 69.5441(67.7502) | Bit/dim 3.7117(3.7172) | Xent 0.4198(0.4413) | Loss 9.3860(10.2335) | Error 0.1540(0.1633) Steps 718(671.21) | Grad Norm 6.8936(5.9898) | Total Time 0.00(0.00)\n",
      "Iter 1270 | Time 68.5404(67.7739) | Bit/dim 3.7199(3.7173) | Xent 0.4049(0.4402) | Loss 9.2813(10.2049) | Error 0.1485(0.1628) Steps 664(670.99) | Grad Norm 5.0839(5.9626) | Total Time 0.00(0.00)\n",
      "Iter 1271 | Time 68.7434(67.8030) | Bit/dim 3.7082(3.7170) | Xent 0.4198(0.4396) | Loss 9.4626(10.1826) | Error 0.1580(0.1627) Steps 658(670.60) | Grad Norm 8.2030(6.0299) | Total Time 0.00(0.00)\n",
      "Iter 1272 | Time 72.8805(67.9553) | Bit/dim 3.7172(3.7170) | Xent 0.4133(0.4388) | Loss 9.3883(10.1588) | Error 0.1530(0.1624) Steps 676(670.77) | Grad Norm 5.4332(6.0120) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0212 | Time 24.6671, Epoch Time 455.8963(437.3979), Bit/dim 3.7315(best: 3.7272), Xent 1.8714, Loss 4.6672, Error 0.4271(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1273 | Time 67.3506(67.9372) | Bit/dim 3.7167(3.7170) | Xent 0.3936(0.4374) | Loss 14.4157(10.2865) | Error 0.1431(0.1618) Steps 682(671.10) | Grad Norm 6.7396(6.0338) | Total Time 0.00(0.00)\n",
      "Iter 1274 | Time 65.5333(67.8651) | Bit/dim 3.7165(3.7170) | Xent 0.3950(0.4361) | Loss 9.3349(10.2580) | Error 0.1492(0.1614) Steps 688(671.61) | Grad Norm 7.0183(6.0633) | Total Time 0.00(0.00)\n",
      "Iter 1275 | Time 62.6208(67.7077) | Bit/dim 3.7201(3.7171) | Xent 0.3884(0.4347) | Loss 9.4089(10.2325) | Error 0.1432(0.1609) Steps 682(671.92) | Grad Norm 3.3383(5.9816) | Total Time 0.00(0.00)\n",
      "Iter 1276 | Time 69.8187(67.7711) | Bit/dim 3.7082(3.7168) | Xent 0.3935(0.4335) | Loss 9.2488(10.2030) | Error 0.1481(0.1605) Steps 670(671.86) | Grad Norm 3.5415(5.9084) | Total Time 0.00(0.00)\n",
      "Iter 1277 | Time 68.6779(67.7983) | Bit/dim 3.7057(3.7165) | Xent 0.3959(0.4323) | Loss 9.3687(10.1779) | Error 0.1466(0.1601) Steps 658(671.45) | Grad Norm 3.4798(5.8355) | Total Time 0.00(0.00)\n",
      "Iter 1278 | Time 65.7860(67.7379) | Bit/dim 3.7080(3.7162) | Xent 0.4179(0.4319) | Loss 9.4063(10.1548) | Error 0.1551(0.1599) Steps 658(671.05) | Grad Norm 4.0075(5.7807) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0213 | Time 25.3567, Epoch Time 443.6482(437.5854), Bit/dim 3.7290(best: 3.7272), Xent 1.8585, Loss 4.6582, Error 0.4277(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1279 | Time 67.8536(67.7414) | Bit/dim 3.7060(3.7159) | Xent 0.3969(0.4309) | Loss 14.5135(10.2856) | Error 0.1496(0.1596) Steps 646(670.29) | Grad Norm 7.3706(5.8284) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 64.5607(67.6459) | Bit/dim 3.7084(3.7157) | Xent 0.4290(0.4308) | Loss 8.9786(10.2464) | Error 0.1552(0.1595) Steps 676(670.46) | Grad Norm 11.2441(5.9908) | Total Time 0.00(0.00)\n",
      "Iter 1281 | Time 64.0726(67.5387) | Bit/dim 3.7128(3.7156) | Xent 0.4510(0.4314) | Loss 9.2821(10.2174) | Error 0.1655(0.1597) Steps 670(670.45) | Grad Norm 12.4719(6.1853) | Total Time 0.00(0.00)\n",
      "Iter 1282 | Time 68.1098(67.5559) | Bit/dim 3.7241(3.7158) | Xent 0.4328(0.4315) | Loss 9.3618(10.1918) | Error 0.1645(0.1598) Steps 652(669.90) | Grad Norm 12.1814(6.3652) | Total Time 0.00(0.00)\n",
      "Iter 1283 | Time 64.7095(67.4705) | Bit/dim 3.7250(3.7161) | Xent 0.4323(0.4315) | Loss 9.2009(10.1620) | Error 0.1599(0.1598) Steps 682(670.26) | Grad Norm 8.3059(6.4234) | Total Time 0.00(0.00)\n",
      "Iter 1284 | Time 67.0903(67.4591) | Bit/dim 3.7175(3.7162) | Xent 0.4042(0.4307) | Loss 9.3873(10.1388) | Error 0.1510(0.1596) Steps 682(670.61) | Grad Norm 4.4463(6.3641) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0214 | Time 24.6231, Epoch Time 439.8176(437.6524), Bit/dim 3.7263(best: 3.7272), Xent 1.8258, Loss 4.6392, Error 0.4282(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1285 | Time 68.1027(67.4784) | Bit/dim 3.7039(3.7158) | Xent 0.4497(0.4312) | Loss 14.1437(10.2589) | Error 0.1683(0.1598) Steps 676(670.77) | Grad Norm 10.7544(6.4958) | Total Time 0.00(0.00)\n",
      "Iter 1286 | Time 68.9928(67.5238) | Bit/dim 3.7217(3.7160) | Xent 0.4498(0.4318) | Loss 9.5789(10.2385) | Error 0.1666(0.1600) Steps 676(670.93) | Grad Norm 11.2826(6.6394) | Total Time 0.00(0.00)\n",
      "Iter 1287 | Time 70.1953(67.6040) | Bit/dim 3.7119(3.7159) | Xent 0.3997(0.4308) | Loss 9.5231(10.2171) | Error 0.1450(0.1596) Steps 688(671.44) | Grad Norm 5.4694(6.6043) | Total Time 0.00(0.00)\n",
      "Iter 1288 | Time 70.7539(67.6985) | Bit/dim 3.7090(3.7156) | Xent 0.4220(0.4306) | Loss 9.2668(10.1886) | Error 0.1560(0.1595) Steps 676(671.58) | Grad Norm 6.9141(6.6136) | Total Time 0.00(0.00)\n",
      "Iter 1289 | Time 68.6610(67.7273) | Bit/dim 3.7135(3.7156) | Xent 0.4172(0.4302) | Loss 9.4151(10.1654) | Error 0.1555(0.1594) Steps 682(671.89) | Grad Norm 7.6412(6.6444) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 64.0480(67.6170) | Bit/dim 3.7230(3.7158) | Xent 0.3979(0.4292) | Loss 9.4707(10.1445) | Error 0.1430(0.1589) Steps 664(671.66) | Grad Norm 5.1625(6.6000) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0215 | Time 24.1833, Epoch Time 453.6996(438.1338), Bit/dim 3.7261(best: 3.7263), Xent 1.8740, Loss 4.6631, Error 0.4279(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1291 | Time 68.7538(67.6511) | Bit/dim 3.7202(3.7159) | Xent 0.4220(0.4290) | Loss 14.7511(10.2827) | Error 0.1589(0.1589) Steps 694(672.33) | Grad Norm 8.3119(6.6513) | Total Time 0.00(0.00)\n",
      "Iter 1292 | Time 66.5016(67.6166) | Bit/dim 3.7164(3.7159) | Xent 0.4257(0.4289) | Loss 9.5538(10.2608) | Error 0.1623(0.1590) Steps 670(672.26) | Grad Norm 10.0314(6.7527) | Total Time 0.00(0.00)\n",
      "Iter 1293 | Time 71.6402(67.7373) | Bit/dim 3.7192(3.7160) | Xent 0.3696(0.4271) | Loss 9.0444(10.2244) | Error 0.1318(0.1581) Steps 652(671.65) | Grad Norm 5.3801(6.7115) | Total Time 0.00(0.00)\n",
      "Iter 1294 | Time 68.6744(67.7654) | Bit/dim 3.7211(3.7162) | Xent 0.4135(0.4267) | Loss 9.4125(10.2000) | Error 0.1559(0.1581) Steps 646(670.88) | Grad Norm 6.0611(6.6920) | Total Time 0.00(0.00)\n",
      "Iter 1295 | Time 71.7271(67.8843) | Bit/dim 3.7067(3.7159) | Xent 0.4212(0.4265) | Loss 9.3318(10.1740) | Error 0.1576(0.1581) Steps 688(671.39) | Grad Norm 9.2786(6.7696) | Total Time 0.00(0.00)\n",
      "Iter 1296 | Time 70.8741(67.9740) | Bit/dim 3.7007(3.7155) | Xent 0.3845(0.4253) | Loss 9.2954(10.1476) | Error 0.1450(0.1577) Steps 682(671.71) | Grad Norm 4.7790(6.7099) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0216 | Time 24.3020, Epoch Time 460.6239(438.8085), Bit/dim 3.7312(best: 3.7261), Xent 1.8543, Loss 4.6584, Error 0.4298(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1297 | Time 69.0612(68.0066) | Bit/dim 3.7184(3.7155) | Xent 0.4075(0.4247) | Loss 15.5818(10.3106) | Error 0.1470(0.1574) Steps 640(670.76) | Grad Norm 6.8377(6.7137) | Total Time 0.00(0.00)\n",
      "Iter 1298 | Time 62.3220(67.8360) | Bit/dim 3.7119(3.7154) | Xent 0.4047(0.4241) | Loss 9.2765(10.2796) | Error 0.1531(0.1572) Steps 688(671.28) | Grad Norm 8.2597(6.7601) | Total Time 0.00(0.00)\n",
      "Iter 1299 | Time 69.0720(67.8731) | Bit/dim 3.7167(3.7155) | Xent 0.3775(0.4227) | Loss 9.4293(10.2541) | Error 0.1371(0.1566) Steps 676(671.42) | Grad Norm 3.8508(6.6728) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 66.1060(67.8201) | Bit/dim 3.7104(3.7153) | Xent 0.4042(0.4222) | Loss 9.4408(10.2297) | Error 0.1465(0.1563) Steps 700(672.28) | Grad Norm 6.0561(6.6543) | Total Time 0.00(0.00)\n",
      "Iter 1301 | Time 62.5796(67.6629) | Bit/dim 3.7184(3.7154) | Xent 0.3933(0.4213) | Loss 9.3981(10.2047) | Error 0.1470(0.1560) Steps 664(672.03) | Grad Norm 6.7034(6.6558) | Total Time 0.00(0.00)\n",
      "Iter 1302 | Time 63.3718(67.5342) | Bit/dim 3.7113(3.7153) | Xent 0.3891(0.4203) | Loss 9.4184(10.1812) | Error 0.1446(0.1557) Steps 688(672.51) | Grad Norm 3.1684(6.5512) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0217 | Time 24.9577, Epoch Time 435.7980(438.7182), Bit/dim 3.7261(best: 3.7261), Xent 1.8310, Loss 4.6416, Error 0.4240(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1303 | Time 67.6878(67.5388) | Bit/dim 3.7161(3.7153) | Xent 0.3942(0.4196) | Loss 14.6691(10.3158) | Error 0.1471(0.1554) Steps 658(672.07) | Grad Norm 5.1136(6.5081) | Total Time 0.00(0.00)\n",
      "Iter 1304 | Time 65.7548(67.4852) | Bit/dim 3.7028(3.7149) | Xent 0.3641(0.4179) | Loss 9.1529(10.2809) | Error 0.1351(0.1548) Steps 670(672.01) | Grad Norm 4.6113(6.4512) | Total Time 0.00(0.00)\n",
      "Iter 1305 | Time 73.0737(67.6529) | Bit/dim 3.7238(3.7152) | Xent 0.3762(0.4166) | Loss 9.3863(10.2541) | Error 0.1371(0.1543) Steps 706(673.03) | Grad Norm 5.3290(6.4175) | Total Time 0.00(0.00)\n",
      "Iter 1306 | Time 67.8351(67.6584) | Bit/dim 3.7029(3.7148) | Xent 0.4006(0.4162) | Loss 9.1273(10.2203) | Error 0.1445(0.1540) Steps 688(673.48) | Grad Norm 6.1287(6.4088) | Total Time 0.00(0.00)\n",
      "Iter 1307 | Time 65.7563(67.6013) | Bit/dim 3.7140(3.7148) | Xent 0.3877(0.4153) | Loss 9.2476(10.1911) | Error 0.1435(0.1537) Steps 646(672.65) | Grad Norm 3.9181(6.3341) | Total Time 0.00(0.00)\n",
      "Iter 1308 | Time 68.1866(67.6189) | Bit/dim 3.7048(3.7145) | Xent 0.3942(0.4147) | Loss 9.3764(10.1666) | Error 0.1415(0.1533) Steps 628(671.31) | Grad Norm 5.0379(6.2952) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0218 | Time 24.7196, Epoch Time 451.5553(439.1033), Bit/dim 3.7286(best: 3.7261), Xent 1.9533, Loss 4.7052, Error 0.4293(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1309 | Time 69.7428(67.6826) | Bit/dim 3.7137(3.7145) | Xent 0.3864(0.4138) | Loss 14.4921(10.2964) | Error 0.1435(0.1530) Steps 658(670.91) | Grad Norm 6.1004(6.2894) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 66.9433(67.6604) | Bit/dim 3.7085(3.7143) | Xent 0.3715(0.4126) | Loss 9.3206(10.2671) | Error 0.1381(0.1526) Steps 682(671.25) | Grad Norm 3.3664(6.2017) | Total Time 0.00(0.00)\n",
      "Iter 1311 | Time 71.8159(67.7851) | Bit/dim 3.7137(3.7143) | Xent 0.3858(0.4118) | Loss 9.3601(10.2399) | Error 0.1361(0.1521) Steps 664(671.03) | Grad Norm 4.5593(6.1524) | Total Time 0.00(0.00)\n",
      "Iter 1312 | Time 65.8968(67.7284) | Bit/dim 3.7204(3.7145) | Xent 0.3863(0.4110) | Loss 9.3137(10.2121) | Error 0.1462(0.1519) Steps 688(671.54) | Grad Norm 5.0616(6.1197) | Total Time 0.00(0.00)\n",
      "Iter 1313 | Time 68.0810(67.7390) | Bit/dim 3.7068(3.7142) | Xent 0.3688(0.4097) | Loss 9.3425(10.1860) | Error 0.1424(0.1516) Steps 688(672.03) | Grad Norm 3.3970(6.0380) | Total Time 0.00(0.00)\n",
      "Iter 1314 | Time 65.9517(67.6854) | Bit/dim 3.7061(3.7140) | Xent 0.3961(0.4093) | Loss 9.1019(10.1535) | Error 0.1465(0.1515) Steps 664(671.79) | Grad Norm 10.4216(6.1695) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0219 | Time 24.9961, Epoch Time 451.9685(439.4892), Bit/dim 3.7304(best: 3.7261), Xent 1.9522, Loss 4.7065, Error 0.4320(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1315 | Time 67.7386(67.6870) | Bit/dim 3.7177(3.7141) | Xent 0.3828(0.4085) | Loss 15.0906(10.3016) | Error 0.1416(0.1512) Steps 700(672.64) | Grad Norm 11.0245(6.3152) | Total Time 0.00(0.00)\n",
      "Iter 1316 | Time 70.2083(67.7626) | Bit/dim 3.7016(3.7137) | Xent 0.3815(0.4077) | Loss 9.4416(10.2758) | Error 0.1411(0.1509) Steps 658(672.20) | Grad Norm 3.4335(6.2287) | Total Time 0.00(0.00)\n",
      "Iter 1317 | Time 70.1536(67.8343) | Bit/dim 3.7190(3.7139) | Xent 0.3733(0.4067) | Loss 9.4949(10.2524) | Error 0.1331(0.1503) Steps 652(671.59) | Grad Norm 10.0551(6.3435) | Total Time 0.00(0.00)\n",
      "Iter 1318 | Time 70.7472(67.9217) | Bit/dim 3.7119(3.7138) | Xent 0.3692(0.4056) | Loss 9.2157(10.2213) | Error 0.1398(0.1500) Steps 688(672.09) | Grad Norm 4.7273(6.2950) | Total Time 0.00(0.00)\n",
      "Iter 1319 | Time 65.9450(67.8624) | Bit/dim 3.6999(3.7134) | Xent 0.3769(0.4047) | Loss 9.4158(10.1971) | Error 0.1384(0.1497) Steps 658(671.66) | Grad Norm 4.9703(6.2553) | Total Time 0.00(0.00)\n",
      "Iter 1320 | Time 68.4661(67.8805) | Bit/dim 3.7155(3.7135) | Xent 0.3923(0.4043) | Loss 9.5455(10.1776) | Error 0.1442(0.1495) Steps 670(671.61) | Grad Norm 7.7739(6.3008) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0220 | Time 25.6081, Epoch Time 457.5580(440.0313), Bit/dim 3.7279(best: 3.7261), Xent 1.9660, Loss 4.7109, Error 0.4324(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1321 | Time 64.8130(67.7885) | Bit/dim 3.7162(3.7136) | Xent 0.4202(0.4048) | Loss 15.1710(10.3274) | Error 0.1616(0.1499) Steps 694(672.28) | Grad Norm 11.2458(6.4492) | Total Time 0.00(0.00)\n",
      "Iter 1322 | Time 64.2252(67.6816) | Bit/dim 3.7251(3.7139) | Xent 0.3891(0.4043) | Loss 9.4332(10.3006) | Error 0.1398(0.1496) Steps 664(672.04) | Grad Norm 8.1651(6.5007) | Total Time 0.00(0.00)\n",
      "Iter 1323 | Time 68.1556(67.6958) | Bit/dim 3.7045(3.7136) | Xent 0.3744(0.4034) | Loss 9.2268(10.2684) | Error 0.1380(0.1492) Steps 658(671.61) | Grad Norm 5.4170(6.4682) | Total Time 0.00(0.00)\n",
      "Iter 1324 | Time 66.4612(67.6588) | Bit/dim 3.7102(3.7135) | Xent 0.3741(0.4025) | Loss 9.2150(10.2368) | Error 0.1361(0.1488) Steps 682(671.93) | Grad Norm 4.1688(6.3992) | Total Time 0.00(0.00)\n",
      "Iter 1325 | Time 63.3964(67.5309) | Bit/dim 3.7092(3.7134) | Xent 0.3588(0.4012) | Loss 9.2734(10.2079) | Error 0.1306(0.1483) Steps 676(672.05) | Grad Norm 4.2895(6.3359) | Total Time 0.00(0.00)\n",
      "Iter 1326 | Time 66.9242(67.5127) | Bit/dim 3.7067(3.7132) | Xent 0.3883(0.4008) | Loss 9.1466(10.1760) | Error 0.1471(0.1483) Steps 688(672.53) | Grad Norm 6.3863(6.3374) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0221 | Time 24.9265, Epoch Time 438.2787(439.9787), Bit/dim 3.7258(best: 3.7261), Xent 1.9890, Loss 4.7203, Error 0.4353(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1327 | Time 68.9075(67.5546) | Bit/dim 3.7102(3.7131) | Xent 0.4134(0.4012) | Loss 14.7355(10.3128) | Error 0.1544(0.1484) Steps 682(672.81) | Grad Norm 13.6080(6.5555) | Total Time 0.00(0.00)\n",
      "Iter 1328 | Time 64.9088(67.4752) | Bit/dim 3.7177(3.7132) | Xent 0.4052(0.4013) | Loss 9.4434(10.2867) | Error 0.1494(0.1485) Steps 682(673.09) | Grad Norm 13.5647(6.7658) | Total Time 0.00(0.00)\n",
      "Iter 1329 | Time 62.9584(67.3397) | Bit/dim 3.7094(3.7131) | Xent 0.4033(0.4014) | Loss 9.2420(10.2554) | Error 0.1469(0.1484) Steps 688(673.53) | Grad Norm 10.5015(6.8779) | Total Time 0.00(0.00)\n",
      "Iter 1330 | Time 66.3329(67.3095) | Bit/dim 3.7009(3.7128) | Xent 0.3715(0.4005) | Loss 9.2362(10.2248) | Error 0.1339(0.1480) Steps 664(673.25) | Grad Norm 5.7863(6.8451) | Total Time 0.00(0.00)\n",
      "Iter 1331 | Time 66.7356(67.2923) | Bit/dim 3.7090(3.7126) | Xent 0.3734(0.3997) | Loss 9.3301(10.1980) | Error 0.1415(0.1478) Steps 664(672.97) | Grad Norm 7.6708(6.8699) | Total Time 0.00(0.00)\n",
      "Iter 1332 | Time 73.2379(67.4706) | Bit/dim 3.7182(3.7128) | Xent 0.3938(0.3995) | Loss 9.2697(10.1701) | Error 0.1450(0.1477) Steps 706(673.96) | Grad Norm 10.6380(6.9829) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0222 | Time 24.5760, Epoch Time 446.2584(440.1671), Bit/dim 3.7273(best: 3.7258), Xent 1.8982, Loss 4.6764, Error 0.4241(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1333 | Time 67.2236(67.4632) | Bit/dim 3.7090(3.7127) | Xent 0.3735(0.3987) | Loss 14.7069(10.3062) | Error 0.1396(0.1475) Steps 664(673.66) | Grad Norm 4.4735(6.9076) | Total Time 0.00(0.00)\n",
      "Iter 1334 | Time 66.2001(67.4253) | Bit/dim 3.7124(3.7127) | Xent 0.3855(0.3983) | Loss 9.2686(10.2751) | Error 0.1412(0.1473) Steps 670(673.55) | Grad Norm 6.9915(6.9102) | Total Time 0.00(0.00)\n",
      "Iter 1335 | Time 72.0697(67.5647) | Bit/dim 3.7076(3.7125) | Xent 0.3863(0.3980) | Loss 9.3429(10.2471) | Error 0.1432(0.1472) Steps 670(673.45) | Grad Norm 6.9863(6.9124) | Total Time 0.00(0.00)\n",
      "Iter 1336 | Time 66.1786(67.5231) | Bit/dim 3.7181(3.7127) | Xent 0.3502(0.3965) | Loss 9.1693(10.2148) | Error 0.1314(0.1467) Steps 658(672.98) | Grad Norm 4.8137(6.8495) | Total Time 0.00(0.00)\n",
      "Iter 1337 | Time 65.5846(67.4649) | Bit/dim 3.7048(3.7125) | Xent 0.3767(0.3959) | Loss 9.2780(10.1867) | Error 0.1442(0.1466) Steps 700(673.79) | Grad Norm 5.3159(6.8035) | Total Time 0.00(0.00)\n",
      "Iter 1338 | Time 69.4363(67.5241) | Bit/dim 3.7218(3.7127) | Xent 0.3927(0.3958) | Loss 9.1985(10.1570) | Error 0.1461(0.1466) Steps 700(674.58) | Grad Norm 14.2383(7.0265) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0223 | Time 24.8264, Epoch Time 450.2408(440.4693), Bit/dim 3.7272(best: 3.7258), Xent 2.0391, Loss 4.7468, Error 0.4394(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1339 | Time 62.2218(67.3650) | Bit/dim 3.7125(3.7127) | Xent 0.4134(0.3964) | Loss 13.7027(10.2634) | Error 0.1575(0.1469) Steps 652(673.90) | Grad Norm 12.7181(7.1973) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 63.9600(67.2628) | Bit/dim 3.7031(3.7124) | Xent 0.3582(0.3952) | Loss 9.2584(10.2333) | Error 0.1339(0.1465) Steps 640(672.89) | Grad Norm 2.9358(7.0694) | Total Time 0.00(0.00)\n",
      "Iter 1341 | Time 69.1165(67.3185) | Bit/dim 3.7178(3.7126) | Xent 0.3900(0.3951) | Loss 9.3047(10.2054) | Error 0.1420(0.1464) Steps 700(673.70) | Grad Norm 7.5729(7.0845) | Total Time 0.00(0.00)\n",
      "Iter 1342 | Time 66.0755(67.2812) | Bit/dim 3.7048(3.7124) | Xent 0.3994(0.3952) | Loss 9.1889(10.1749) | Error 0.1456(0.1464) Steps 658(673.23) | Grad Norm 8.7704(7.1351) | Total Time 0.00(0.00)\n",
      "Iter 1343 | Time 64.5431(67.1990) | Bit/dim 3.7102(3.7123) | Xent 0.3601(0.3941) | Loss 9.2070(10.1459) | Error 0.1325(0.1460) Steps 676(673.31) | Grad Norm 5.2302(7.0780) | Total Time 0.00(0.00)\n",
      "Iter 1344 | Time 70.3493(67.2935) | Bit/dim 3.7204(3.7125) | Xent 0.3562(0.3930) | Loss 9.2962(10.1204) | Error 0.1286(0.1454) Steps 682(673.57) | Grad Norm 4.9221(7.0133) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0224 | Time 24.8014, Epoch Time 439.6032(440.4433), Bit/dim 3.7228(best: 3.7258), Xent 1.8959, Loss 4.6707, Error 0.4250(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1345 | Time 71.1949(67.4106) | Bit/dim 3.7101(3.7125) | Xent 0.3537(0.3918) | Loss 14.3473(10.2472) | Error 0.1311(0.1450) Steps 652(672.92) | Grad Norm 5.4461(6.9663) | Total Time 0.00(0.00)\n",
      "Iter 1346 | Time 64.6720(67.3284) | Bit/dim 3.7097(3.7124) | Xent 0.3729(0.3913) | Loss 9.1815(10.2152) | Error 0.1371(0.1448) Steps 670(672.84) | Grad Norm 5.0481(6.9087) | Total Time 0.00(0.00)\n",
      "Iter 1347 | Time 70.0228(67.4092) | Bit/dim 3.7096(3.7123) | Xent 0.3407(0.3897) | Loss 9.3638(10.1897) | Error 0.1268(0.1442) Steps 646(672.03) | Grad Norm 3.4458(6.8048) | Total Time 0.00(0.00)\n",
      "Iter 1348 | Time 63.8502(67.3025) | Bit/dim 3.7111(3.7123) | Xent 0.3637(0.3890) | Loss 9.0972(10.1569) | Error 0.1345(0.1439) Steps 670(671.97) | Grad Norm 5.3292(6.7606) | Total Time 0.00(0.00)\n",
      "Iter 1349 | Time 72.4796(67.4578) | Bit/dim 3.7091(3.7122) | Xent 0.3587(0.3881) | Loss 9.0981(10.1251) | Error 0.1304(0.1435) Steps 652(671.37) | Grad Norm 5.4035(6.7199) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 63.1659(67.3290) | Bit/dim 3.7128(3.7122) | Xent 0.3658(0.3874) | Loss 9.0822(10.0938) | Error 0.1381(0.1434) Steps 670(671.33) | Grad Norm 3.5526(6.6248) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0225 | Time 24.9900, Epoch Time 448.6731(440.6902), Bit/dim 3.7254(best: 3.7228), Xent 2.0062, Loss 4.7285, Error 0.4314(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1351 | Time 71.7371(67.4613) | Bit/dim 3.7013(3.7119) | Xent 0.3491(0.3862) | Loss 13.9977(10.2110) | Error 0.1339(0.1431) Steps 640(670.39) | Grad Norm 6.1314(6.6100) | Total Time 0.00(0.00)\n",
      "Iter 1352 | Time 67.8614(67.4733) | Bit/dim 3.7314(3.7125) | Xent 0.3537(0.3853) | Loss 9.2687(10.1827) | Error 0.1300(0.1427) Steps 646(669.66) | Grad Norm 6.3385(6.6019) | Total Time 0.00(0.00)\n",
      "Iter 1353 | Time 71.1712(67.5842) | Bit/dim 3.7076(3.7123) | Xent 0.3490(0.3842) | Loss 9.3312(10.1572) | Error 0.1266(0.1422) Steps 688(670.21) | Grad Norm 6.5275(6.5997) | Total Time 0.00(0.00)\n",
      "Iter 1354 | Time 72.1571(67.7214) | Bit/dim 3.7130(3.7123) | Xent 0.3459(0.3830) | Loss 9.3520(10.1330) | Error 0.1260(0.1417) Steps 652(669.66) | Grad Norm 8.1168(6.6452) | Total Time 0.00(0.00)\n",
      "Iter 1355 | Time 69.1349(67.7638) | Bit/dim 3.7035(3.7121) | Xent 0.3410(0.3818) | Loss 9.2425(10.1063) | Error 0.1249(0.1412) Steps 688(670.21) | Grad Norm 4.8451(6.5912) | Total Time 0.00(0.00)\n",
      "Iter 1356 | Time 69.8669(67.8269) | Bit/dim 3.7069(3.7119) | Xent 0.3481(0.3808) | Loss 9.3874(10.0847) | Error 0.1289(0.1408) Steps 676(670.39) | Grad Norm 5.0610(6.5453) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0226 | Time 24.4266, Epoch Time 465.0379(441.4207), Bit/dim 3.7243(best: 3.7228), Xent 2.0020, Loss 4.7253, Error 0.4328(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1357 | Time 67.7203(67.8237) | Bit/dim 3.7139(3.7120) | Xent 0.3227(0.3790) | Loss 13.4990(10.1871) | Error 0.1194(0.1402) Steps 682(670.73) | Grad Norm 3.5390(6.4551) | Total Time 0.00(0.00)\n",
      "Iter 1358 | Time 70.4716(67.9031) | Bit/dim 3.7063(3.7118) | Xent 0.3253(0.3774) | Loss 9.0487(10.1530) | Error 0.1234(0.1397) Steps 694(671.43) | Grad Norm 4.4377(6.3946) | Total Time 0.00(0.00)\n",
      "Iter 1359 | Time 62.4722(67.7402) | Bit/dim 3.7100(3.7117) | Xent 0.3519(0.3766) | Loss 9.1802(10.1238) | Error 0.1271(0.1393) Steps 646(670.67) | Grad Norm 4.0648(6.3247) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 66.7297(67.7099) | Bit/dim 3.7088(3.7117) | Xent 0.3529(0.3759) | Loss 9.1561(10.0948) | Error 0.1314(0.1391) Steps 694(671.37) | Grad Norm 3.1310(6.2289) | Total Time 0.00(0.00)\n",
      "Iter 1361 | Time 66.1079(67.6618) | Bit/dim 3.7130(3.7117) | Xent 0.3496(0.3751) | Loss 9.2824(10.0704) | Error 0.1305(0.1388) Steps 676(671.51) | Grad Norm 2.7313(6.1239) | Total Time 0.00(0.00)\n",
      "Iter 1362 | Time 70.1342(67.7360) | Bit/dim 3.7137(3.7118) | Xent 0.3416(0.3741) | Loss 9.0627(10.0402) | Error 0.1252(0.1384) Steps 694(672.18) | Grad Norm 3.7501(6.0527) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0227 | Time 24.7659, Epoch Time 446.7972(441.5820), Bit/dim 3.7271(best: 3.7228), Xent 2.0615, Loss 4.7579, Error 0.4317(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1363 | Time 70.2694(67.8120) | Bit/dim 3.7139(3.7118) | Xent 0.3374(0.3730) | Loss 13.9356(10.1570) | Error 0.1242(0.1380) Steps 658(671.76) | Grad Norm 3.1388(5.9653) | Total Time 0.00(0.00)\n",
      "Iter 1364 | Time 63.6724(67.6878) | Bit/dim 3.7060(3.7116) | Xent 0.3349(0.3719) | Loss 9.1910(10.1281) | Error 0.1228(0.1375) Steps 664(671.53) | Grad Norm 3.4337(5.8893) | Total Time 0.00(0.00)\n",
      "Iter 1365 | Time 66.9378(67.6653) | Bit/dim 3.7004(3.7113) | Xent 0.3252(0.3705) | Loss 9.0701(10.0963) | Error 0.1234(0.1371) Steps 658(671.12) | Grad Norm 4.4044(5.8448) | Total Time 0.00(0.00)\n",
      "Iter 1366 | Time 66.3815(67.6268) | Bit/dim 3.7078(3.7112) | Xent 0.3349(0.3694) | Loss 8.9166(10.0609) | Error 0.1240(0.1367) Steps 664(670.91) | Grad Norm 4.7088(5.8107) | Total Time 0.00(0.00)\n",
      "Iter 1367 | Time 66.2858(67.5866) | Bit/dim 3.7170(3.7114) | Xent 0.3339(0.3684) | Loss 9.3544(10.0397) | Error 0.1225(0.1363) Steps 700(671.78) | Grad Norm 3.6156(5.7449) | Total Time 0.00(0.00)\n",
      "Iter 1368 | Time 62.0208(67.4196) | Bit/dim 3.7135(3.7114) | Xent 0.3409(0.3675) | Loss 9.0673(10.0106) | Error 0.1272(0.1360) Steps 640(670.83) | Grad Norm 3.9392(5.6907) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0228 | Time 24.9622, Epoch Time 439.1500(441.5090), Bit/dim 3.7232(best: 3.7228), Xent 2.0442, Loss 4.7453, Error 0.4274(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1369 | Time 70.3029(67.5061) | Bit/dim 3.7190(3.7117) | Xent 0.3344(0.3665) | Loss 14.2278(10.1371) | Error 0.1274(0.1358) Steps 700(671.70) | Grad Norm 4.9224(5.6676) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 70.4034(67.5930) | Bit/dim 3.7117(3.7117) | Xent 0.3540(0.3662) | Loss 9.3983(10.1149) | Error 0.1330(0.1357) Steps 652(671.11) | Grad Norm 10.5235(5.8133) | Total Time 0.00(0.00)\n",
      "Iter 1371 | Time 67.8676(67.6013) | Bit/dim 3.7108(3.7116) | Xent 0.4101(0.3675) | Loss 9.5035(10.0966) | Error 0.1576(0.1363) Steps 670(671.08) | Grad Norm 15.3112(6.0983) | Total Time 0.00(0.00)\n",
      "Iter 1372 | Time 73.1930(67.7690) | Bit/dim 3.7062(3.7115) | Xent 0.4439(0.3698) | Loss 9.5544(10.0803) | Error 0.1661(0.1372) Steps 652(670.50) | Grad Norm 16.8657(6.4213) | Total Time 0.00(0.00)\n",
      "Iter 1373 | Time 71.6444(67.8853) | Bit/dim 3.7051(3.7113) | Xent 0.3974(0.3706) | Loss 9.5018(10.0629) | Error 0.1471(0.1375) Steps 652(669.95) | Grad Norm 14.2838(6.6572) | Total Time 0.00(0.00)\n",
      "Iter 1374 | Time 71.2134(67.9851) | Bit/dim 3.7077(3.7112) | Xent 0.3510(0.3700) | Loss 9.1406(10.0353) | Error 0.1294(0.1373) Steps 694(670.67) | Grad Norm 3.5764(6.5647) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0229 | Time 24.2435, Epoch Time 467.3614(442.2846), Bit/dim 3.7261(best: 3.7228), Xent 1.9815, Loss 4.7169, Error 0.4374(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1375 | Time 69.8259(68.0403) | Bit/dim 3.7198(3.7114) | Xent 0.3846(0.3704) | Loss 14.3707(10.1653) | Error 0.1449(0.1375) Steps 658(670.29) | Grad Norm 14.8900(6.8145) | Total Time 0.00(0.00)\n",
      "Iter 1376 | Time 62.1568(67.8638) | Bit/dim 3.7216(3.7117) | Xent 0.3632(0.3702) | Loss 9.2589(10.1381) | Error 0.1342(0.1374) Steps 646(669.56) | Grad Norm 11.2661(6.9480) | Total Time 0.00(0.00)\n",
      "Iter 1377 | Time 67.7975(67.8618) | Bit/dim 3.6956(3.7113) | Xent 0.3584(0.3699) | Loss 9.3779(10.1153) | Error 0.1351(0.1373) Steps 676(669.75) | Grad Norm 6.5087(6.9349) | Total Time 0.00(0.00)\n",
      "Iter 1378 | Time 63.7444(67.7383) | Bit/dim 3.7069(3.7111) | Xent 0.3772(0.3701) | Loss 9.3125(10.0913) | Error 0.1415(0.1375) Steps 682(670.12) | Grad Norm 11.4430(7.0701) | Total Time 0.00(0.00)\n",
      "Iter 1379 | Time 71.2951(67.8450) | Bit/dim 3.7117(3.7111) | Xent 0.3260(0.3688) | Loss 9.0270(10.0593) | Error 0.1235(0.1370) Steps 682(670.48) | Grad Norm 3.0056(6.9482) | Total Time 0.00(0.00)\n",
      "Iter 1380 | Time 68.3621(67.8605) | Bit/dim 3.7096(3.7111) | Xent 0.3751(0.3690) | Loss 9.2808(10.0360) | Error 0.1374(0.1371) Steps 670(670.46) | Grad Norm 11.3334(7.0797) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0230 | Time 24.3673, Epoch Time 445.5035(442.3811), Bit/dim 3.7235(best: 3.7228), Xent 2.0667, Loss 4.7569, Error 0.4360(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1381 | Time 66.9459(67.8331) | Bit/dim 3.7014(3.7108) | Xent 0.3409(0.3681) | Loss 14.5271(10.1707) | Error 0.1252(0.1367) Steps 658(670.09) | Grad Norm 8.1416(7.1116) | Total Time 0.00(0.00)\n",
      "Iter 1382 | Time 68.0879(67.8407) | Bit/dim 3.6972(3.7104) | Xent 0.3366(0.3672) | Loss 9.3170(10.1451) | Error 0.1175(0.1361) Steps 694(670.81) | Grad Norm 7.6702(7.1283) | Total Time 0.00(0.00)\n",
      "Iter 1383 | Time 63.0851(67.6981) | Bit/dim 3.7237(3.7108) | Xent 0.3470(0.3666) | Loss 9.1806(10.1162) | Error 0.1281(0.1359) Steps 670(670.78) | Grad Norm 9.5662(7.2015) | Total Time 0.00(0.00)\n",
      "Iter 1384 | Time 65.9545(67.6458) | Bit/dim 3.7107(3.7108) | Xent 0.3429(0.3659) | Loss 9.1894(10.0884) | Error 0.1248(0.1356) Steps 682(671.12) | Grad Norm 5.4248(7.1482) | Total Time 0.00(0.00)\n",
      "Iter 1385 | Time 70.5501(67.7329) | Bit/dim 3.7160(3.7110) | Xent 0.3466(0.3653) | Loss 9.4318(10.0687) | Error 0.1350(0.1355) Steps 682(671.45) | Grad Norm 9.0416(7.2050) | Total Time 0.00(0.00)\n",
      "Iter 1386 | Time 69.2669(67.7789) | Bit/dim 3.7046(3.7108) | Xent 0.3583(0.3651) | Loss 9.4886(10.0513) | Error 0.1305(0.1354) Steps 658(671.04) | Grad Norm 6.2484(7.1763) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0231 | Time 24.4139, Epoch Time 446.3744(442.5009), Bit/dim 3.7244(best: 3.7228), Xent 2.0553, Loss 4.7521, Error 0.4297(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1387 | Time 67.8312(67.7805) | Bit/dim 3.7043(3.7106) | Xent 0.3364(0.3642) | Loss 14.3966(10.1816) | Error 0.1219(0.1350) Steps 706(672.09) | Grad Norm 5.2949(7.1198) | Total Time 0.00(0.00)\n",
      "Iter 1388 | Time 69.2976(67.8260) | Bit/dim 3.7136(3.7107) | Xent 0.3416(0.3635) | Loss 9.3838(10.1577) | Error 0.1276(0.1348) Steps 664(671.85) | Grad Norm 5.5559(7.0729) | Total Time 0.00(0.00)\n",
      "Iter 1389 | Time 72.4515(67.9648) | Bit/dim 3.7073(3.7106) | Xent 0.3209(0.3623) | Loss 9.0232(10.1236) | Error 0.1208(0.1343) Steps 694(672.51) | Grad Norm 5.1560(7.0154) | Total Time 0.00(0.00)\n",
      "Iter 1390 | Time 68.8824(67.9923) | Bit/dim 3.7027(3.7103) | Xent 0.3290(0.3613) | Loss 9.2848(10.0985) | Error 0.1228(0.1340) Steps 652(671.90) | Grad Norm 6.5433(7.0013) | Total Time 0.00(0.00)\n",
      "Iter 1391 | Time 72.7088(68.1338) | Bit/dim 3.7110(3.7103) | Xent 0.3345(0.3605) | Loss 9.3848(10.0771) | Error 0.1209(0.1336) Steps 706(672.92) | Grad Norm 4.0465(6.9126) | Total Time 0.00(0.00)\n",
      "Iter 1392 | Time 65.7360(68.0619) | Bit/dim 3.7082(3.7103) | Xent 0.3315(0.3596) | Loss 9.3190(10.0543) | Error 0.1250(0.1333) Steps 664(672.65) | Grad Norm 5.3711(6.8664) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0232 | Time 24.8599, Epoch Time 461.4274(443.0687), Bit/dim 3.7219(best: 3.7228), Xent 2.0580, Loss 4.7510, Error 0.4268(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1393 | Time 71.4166(68.1625) | Bit/dim 3.7074(3.7102) | Xent 0.3101(0.3581) | Loss 14.4774(10.1870) | Error 0.1116(0.1327) Steps 688(673.11) | Grad Norm 3.6836(6.7709) | Total Time 0.00(0.00)\n",
      "Iter 1394 | Time 70.7284(68.2395) | Bit/dim 3.7049(3.7100) | Xent 0.3068(0.3566) | Loss 9.4019(10.1635) | Error 0.1120(0.1321) Steps 700(673.92) | Grad Norm 4.4941(6.7026) | Total Time 0.00(0.00)\n",
      "Iter 1395 | Time 63.9808(68.1117) | Bit/dim 3.7079(3.7100) | Xent 0.3226(0.3555) | Loss 9.2463(10.1360) | Error 0.1206(0.1317) Steps 664(673.62) | Grad Norm 4.4779(6.6358) | Total Time 0.00(0.00)\n",
      "Iter 1396 | Time 62.8374(67.9535) | Bit/dim 3.7070(3.7099) | Xent 0.3350(0.3549) | Loss 9.2994(10.1109) | Error 0.1246(0.1315) Steps 670(673.51) | Grad Norm 6.1225(6.6204) | Total Time 0.00(0.00)\n",
      "Iter 1397 | Time 64.2505(67.8424) | Bit/dim 3.7083(3.7098) | Xent 0.3150(0.3537) | Loss 9.1809(10.0830) | Error 0.1178(0.1311) Steps 700(674.31) | Grad Norm 3.8595(6.5376) | Total Time 0.00(0.00)\n",
      "Iter 1398 | Time 68.7993(67.8711) | Bit/dim 3.7092(3.7098) | Xent 0.3224(0.3528) | Loss 9.5315(10.0664) | Error 0.1181(0.1307) Steps 688(674.72) | Grad Norm 5.1047(6.4946) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0233 | Time 24.8496, Epoch Time 445.6259(443.1454), Bit/dim 3.7268(best: 3.7219), Xent 2.0940, Loss 4.7738, Error 0.4319(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1399 | Time 67.6406(67.8642) | Bit/dim 3.7072(3.7097) | Xent 0.3145(0.3516) | Loss 14.6004(10.2024) | Error 0.1205(0.1304) Steps 676(674.76) | Grad Norm 6.6232(6.4985) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 65.5474(67.7947) | Bit/dim 3.7113(3.7098) | Xent 0.3234(0.3508) | Loss 9.2077(10.1726) | Error 0.1152(0.1299) Steps 652(674.07) | Grad Norm 9.3854(6.5851) | Total Time 0.00(0.00)\n",
      "Iter 1401 | Time 68.5354(67.8169) | Bit/dim 3.7172(3.7100) | Xent 0.3564(0.3510) | Loss 9.3720(10.1486) | Error 0.1349(0.1301) Steps 700(674.85) | Grad Norm 10.6651(6.7075) | Total Time 0.00(0.00)\n",
      "Iter 1402 | Time 66.4605(67.7762) | Bit/dim 3.7079(3.7099) | Xent 0.3673(0.3515) | Loss 9.3622(10.1250) | Error 0.1399(0.1304) Steps 670(674.71) | Grad Norm 10.5386(6.8224) | Total Time 0.00(0.00)\n",
      "Iter 1403 | Time 70.0098(67.8432) | Bit/dim 3.7093(3.7099) | Xent 0.3733(0.3521) | Loss 9.4370(10.1043) | Error 0.1386(0.1306) Steps 682(674.93) | Grad Norm 10.0544(6.9194) | Total Time 0.00(0.00)\n",
      "Iter 1404 | Time 68.1694(67.8530) | Bit/dim 3.7087(3.7099) | Xent 0.3568(0.3523) | Loss 9.4146(10.0836) | Error 0.1321(0.1307) Steps 676(674.96) | Grad Norm 7.6328(6.9408) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0234 | Time 24.9722, Epoch Time 449.7463(443.3435), Bit/dim 3.7287(best: 3.7219), Xent 2.0562, Loss 4.7568, Error 0.4329(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1405 | Time 67.5397(67.8436) | Bit/dim 3.7014(3.7096) | Xent 0.3255(0.3514) | Loss 14.0999(10.2041) | Error 0.1169(0.1303) Steps 640(673.91) | Grad Norm 7.0007(6.9426) | Total Time 0.00(0.00)\n",
      "Iter 1406 | Time 69.0137(67.8787) | Bit/dim 3.7208(3.7100) | Xent 0.3315(0.3509) | Loss 9.3326(10.1780) | Error 0.1218(0.1300) Steps 676(673.97) | Grad Norm 8.1588(6.9791) | Total Time 0.00(0.00)\n",
      "Iter 1407 | Time 72.6704(68.0225) | Bit/dim 3.7146(3.7101) | Xent 0.3201(0.3499) | Loss 9.0348(10.1437) | Error 0.1169(0.1296) Steps 652(673.31) | Grad Norm 5.6848(6.9402) | Total Time 0.00(0.00)\n",
      "Iter 1408 | Time 67.2722(68.0000) | Bit/dim 3.7009(3.7098) | Xent 0.3252(0.3492) | Loss 9.2157(10.1159) | Error 0.1191(0.1293) Steps 640(672.31) | Grad Norm 7.0779(6.9444) | Total Time 0.00(0.00)\n",
      "Iter 1409 | Time 67.8048(67.9941) | Bit/dim 3.7149(3.7100) | Xent 0.3492(0.3492) | Loss 9.0943(10.0852) | Error 0.1290(0.1293) Steps 658(671.88) | Grad Norm 6.5132(6.9314) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 68.3637(68.0052) | Bit/dim 3.7017(3.7097) | Xent 0.3160(0.3482) | Loss 9.2798(10.0610) | Error 0.1190(0.1290) Steps 652(671.29) | Grad Norm 4.6890(6.8642) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0235 | Time 24.8504, Epoch Time 455.7665(443.7162), Bit/dim 3.7296(best: 3.7219), Xent 2.1209, Loss 4.7901, Error 0.4365(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1411 | Time 68.0455(68.0064) | Bit/dim 3.7122(3.7098) | Xent 0.3263(0.3475) | Loss 14.6387(10.1984) | Error 0.1184(0.1287) Steps 658(670.89) | Grad Norm 7.1218(6.8719) | Total Time 0.00(0.00)\n",
      "Iter 1412 | Time 64.1873(67.8918) | Bit/dim 3.7107(3.7098) | Xent 0.3178(0.3466) | Loss 9.1045(10.1656) | Error 0.1148(0.1282) Steps 658(670.50) | Grad Norm 4.4787(6.8001) | Total Time 0.00(0.00)\n",
      "Iter 1413 | Time 67.0673(67.8671) | Bit/dim 3.7078(3.7098) | Xent 0.2947(0.3451) | Loss 9.1634(10.1355) | Error 0.1088(0.1277) Steps 664(670.31) | Grad Norm 4.2755(6.7244) | Total Time 0.00(0.00)\n",
      "Iter 1414 | Time 73.2196(68.0277) | Bit/dim 3.7115(3.7098) | Xent 0.3092(0.3440) | Loss 9.2000(10.1074) | Error 0.1148(0.1273) Steps 652(669.76) | Grad Norm 5.4742(6.6869) | Total Time 0.00(0.00)\n",
      "Iter 1415 | Time 70.8930(68.1136) | Bit/dim 3.6983(3.7095) | Xent 0.3211(0.3433) | Loss 9.2401(10.0814) | Error 0.1208(0.1271) Steps 658(669.41) | Grad Norm 7.8108(6.7206) | Total Time 0.00(0.00)\n",
      "Iter 1416 | Time 68.8369(68.1353) | Bit/dim 3.6997(3.7092) | Xent 0.3091(0.3423) | Loss 9.1231(10.0527) | Error 0.1118(0.1266) Steps 688(669.96) | Grad Norm 6.2748(6.7072) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0236 | Time 25.2794, Epoch Time 456.3225(444.0944), Bit/dim 3.7269(best: 3.7219), Xent 2.1521, Loss 4.8030, Error 0.4334(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1417 | Time 64.4969(68.0262) | Bit/dim 3.7057(3.7091) | Xent 0.3192(0.3416) | Loss 14.2304(10.1780) | Error 0.1185(0.1264) Steps 664(669.78) | Grad Norm 6.9195(6.7136) | Total Time 0.00(0.00)\n",
      "Iter 1418 | Time 65.1721(67.9405) | Bit/dim 3.7063(3.7090) | Xent 0.3005(0.3404) | Loss 9.2070(10.1489) | Error 0.1112(0.1259) Steps 664(669.61) | Grad Norm 5.0801(6.6646) | Total Time 0.00(0.00)\n",
      "Iter 1419 | Time 66.7446(67.9047) | Bit/dim 3.7057(3.7089) | Xent 0.3167(0.3397) | Loss 9.3541(10.1250) | Error 0.1155(0.1256) Steps 688(670.16) | Grad Norm 3.9237(6.5823) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 69.0342(67.9385) | Bit/dim 3.7155(3.7091) | Xent 0.3027(0.3386) | Loss 9.1762(10.0966) | Error 0.1140(0.1253) Steps 676(670.34) | Grad Norm 3.1253(6.4786) | Total Time 0.00(0.00)\n",
      "Iter 1421 | Time 65.7119(67.8717) | Bit/dim 3.7129(3.7092) | Xent 0.2918(0.3371) | Loss 9.2184(10.0702) | Error 0.1066(0.1247) Steps 682(670.69) | Grad Norm 4.2472(6.4117) | Total Time 0.00(0.00)\n",
      "Iter 1422 | Time 70.6787(67.9560) | Bit/dim 3.6999(3.7089) | Xent 0.3120(0.3364) | Loss 9.2278(10.0449) | Error 0.1178(0.1245) Steps 706(671.75) | Grad Norm 4.4204(6.3519) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0237 | Time 24.7173, Epoch Time 445.3602(444.1323), Bit/dim 3.7276(best: 3.7219), Xent 2.0902, Loss 4.7727, Error 0.4306(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1423 | Time 67.1321(67.9312) | Bit/dim 3.7074(3.7089) | Xent 0.3045(0.3354) | Loss 13.8766(10.1599) | Error 0.1114(0.1241) Steps 682(672.05) | Grad Norm 6.3120(6.3507) | Total Time 0.00(0.00)\n",
      "Iter 1424 | Time 70.3874(68.0049) | Bit/dim 3.6987(3.7086) | Xent 0.3009(0.3344) | Loss 9.3041(10.1342) | Error 0.1094(0.1237) Steps 694(672.71) | Grad Norm 3.5462(6.2666) | Total Time 0.00(0.00)\n",
      "Iter 1425 | Time 65.3524(67.9254) | Bit/dim 3.7037(3.7084) | Xent 0.3189(0.3339) | Loss 9.3274(10.1100) | Error 0.1192(0.1235) Steps 670(672.63) | Grad Norm 7.6530(6.3082) | Total Time 0.00(0.00)\n",
      "Iter 1426 | Time 70.0109(67.9879) | Bit/dim 3.6922(3.7079) | Xent 0.3122(0.3333) | Loss 9.2263(10.0835) | Error 0.1168(0.1233) Steps 676(672.73) | Grad Norm 7.8415(6.3542) | Total Time 0.00(0.00)\n",
      "Iter 1427 | Time 68.5253(68.0040) | Bit/dim 3.7075(3.7079) | Xent 0.3040(0.3324) | Loss 9.2581(10.0587) | Error 0.1118(0.1230) Steps 676(672.83) | Grad Norm 4.5223(6.2992) | Total Time 0.00(0.00)\n",
      "Iter 1428 | Time 74.5057(68.1991) | Bit/dim 3.7172(3.7082) | Xent 0.3108(0.3318) | Loss 9.3485(10.0374) | Error 0.1164(0.1228) Steps 664(672.57) | Grad Norm 6.4300(6.3032) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0238 | Time 24.7690, Epoch Time 459.5914(444.5961), Bit/dim 3.7211(best: 3.7219), Xent 2.2055, Loss 4.8239, Error 0.4453(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1429 | Time 70.0749(68.2554) | Bit/dim 3.6966(3.7079) | Xent 0.3318(0.3318) | Loss 14.3085(10.1656) | Error 0.1230(0.1228) Steps 688(673.03) | Grad Norm 14.3068(6.5433) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 63.8551(68.1234) | Bit/dim 3.7127(3.7080) | Xent 0.3276(0.3316) | Loss 9.1839(10.1361) | Error 0.1222(0.1228) Steps 676(673.12) | Grad Norm 15.1942(6.8028) | Total Time 0.00(0.00)\n",
      "Iter 1431 | Time 65.7359(68.0517) | Bit/dim 3.7081(3.7080) | Xent 0.3159(0.3312) | Loss 9.2754(10.1103) | Error 0.1200(0.1227) Steps 658(672.66) | Grad Norm 6.0176(6.7792) | Total Time 0.00(0.00)\n",
      "Iter 1432 | Time 71.6754(68.1604) | Bit/dim 3.7130(3.7082) | Xent 0.3114(0.3306) | Loss 9.1732(10.0822) | Error 0.1170(0.1225) Steps 640(671.68) | Grad Norm 8.7955(6.8397) | Total Time 0.00(0.00)\n",
      "Iter 1433 | Time 60.8265(67.9404) | Bit/dim 3.7206(3.7085) | Xent 0.3268(0.3305) | Loss 9.3337(10.0597) | Error 0.1205(0.1225) Steps 658(671.27) | Grad Norm 10.6155(6.9530) | Total Time 0.00(0.00)\n",
      "Iter 1434 | Time 68.1700(67.9473) | Bit/dim 3.6971(3.7082) | Xent 0.3365(0.3306) | Loss 9.3838(10.0394) | Error 0.1266(0.1226) Steps 712(672.50) | Grad Norm 9.3856(7.0260) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0239 | Time 24.2458, Epoch Time 443.4652(444.5622), Bit/dim 3.7230(best: 3.7211), Xent 2.2092, Loss 4.8276, Error 0.4431(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1435 | Time 62.0303(67.7698) | Bit/dim 3.7066(3.7081) | Xent 0.3240(0.3304) | Loss 14.2492(10.1657) | Error 0.1186(0.1225) Steps 646(671.70) | Grad Norm 10.7546(7.1378) | Total Time 0.00(0.00)\n",
      "Iter 1436 | Time 67.4997(67.7617) | Bit/dim 3.7072(3.7081) | Xent 0.3444(0.3309) | Loss 9.3377(10.1409) | Error 0.1248(0.1225) Steps 664(671.47) | Grad Norm 8.2933(7.1725) | Total Time 0.00(0.00)\n",
      "Iter 1437 | Time 67.5069(67.7541) | Bit/dim 3.7066(3.7081) | Xent 0.3023(0.3300) | Loss 8.9770(10.1060) | Error 0.1118(0.1222) Steps 664(671.25) | Grad Norm 5.0200(7.1079) | Total Time 0.00(0.00)\n",
      "Iter 1438 | Time 65.2926(67.6802) | Bit/dim 3.7021(3.7079) | Xent 0.3209(0.3297) | Loss 9.2984(10.0818) | Error 0.1175(0.1221) Steps 676(671.39) | Grad Norm 7.0075(7.1049) | Total Time 0.00(0.00)\n",
      "Iter 1439 | Time 75.5253(67.9156) | Bit/dim 3.7032(3.7077) | Xent 0.3288(0.3297) | Loss 9.3093(10.0586) | Error 0.1196(0.1220) Steps 718(672.79) | Grad Norm 6.9833(7.1013) | Total Time 0.00(0.00)\n",
      "Iter 1440 | Time 71.2976(68.0170) | Bit/dim 3.7068(3.7077) | Xent 0.3097(0.3291) | Loss 9.2497(10.0343) | Error 0.1129(0.1217) Steps 688(673.24) | Grad Norm 4.3806(7.0197) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0240 | Time 24.6836, Epoch Time 452.6591(444.8051), Bit/dim 3.7172(best: 3.7211), Xent 2.0725, Loss 4.7534, Error 0.4373(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1441 | Time 65.1888(67.9322) | Bit/dim 3.6989(3.7075) | Xent 0.2988(0.3282) | Loss 14.4989(10.1683) | Error 0.1086(0.1213) Steps 694(673.87) | Grad Norm 4.8937(6.9559) | Total Time 0.00(0.00)\n",
      "Iter 1442 | Time 66.0117(67.8746) | Bit/dim 3.7170(3.7077) | Xent 0.3069(0.3276) | Loss 9.3731(10.1444) | Error 0.1124(0.1211) Steps 682(674.11) | Grad Norm 6.1223(6.9309) | Total Time 0.00(0.00)\n",
      "Iter 1443 | Time 70.8278(67.9632) | Bit/dim 3.7108(3.7078) | Xent 0.3158(0.3272) | Loss 9.3908(10.1218) | Error 0.1145(0.1209) Steps 682(674.35) | Grad Norm 5.3113(6.8823) | Total Time 0.00(0.00)\n",
      "Iter 1444 | Time 68.9052(67.9914) | Bit/dim 3.6999(3.7076) | Xent 0.3059(0.3266) | Loss 9.0898(10.0908) | Error 0.1162(0.1207) Steps 652(673.68) | Grad Norm 11.9683(7.0349) | Total Time 0.00(0.00)\n",
      "Iter 1445 | Time 69.4223(68.0344) | Bit/dim 3.7040(3.7075) | Xent 0.3167(0.3263) | Loss 9.0676(10.0601) | Error 0.1158(0.1206) Steps 688(674.11) | Grad Norm 12.9130(7.2112) | Total Time 0.00(0.00)\n",
      "Iter 1446 | Time 67.4031(68.0154) | Bit/dim 3.7073(3.7075) | Xent 0.3064(0.3257) | Loss 9.2732(10.0365) | Error 0.1126(0.1203) Steps 658(673.62) | Grad Norm 6.4339(7.1879) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0241 | Time 24.8078, Epoch Time 451.3094(445.0002), Bit/dim 3.7297(best: 3.7172), Xent 2.2391, Loss 4.8493, Error 0.4412(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1447 | Time 61.9645(67.8339) | Bit/dim 3.7211(3.7079) | Xent 0.3058(0.3251) | Loss 14.6668(10.1754) | Error 0.1110(0.1201) Steps 658(673.15) | Grad Norm 13.7571(7.3850) | Total Time 0.00(0.00)\n",
      "Iter 1448 | Time 64.7922(67.7426) | Bit/dim 3.6944(3.7075) | Xent 0.3389(0.3255) | Loss 9.1853(10.1457) | Error 0.1250(0.1202) Steps 652(672.52) | Grad Norm 15.3970(7.6253) | Total Time 0.00(0.00)\n",
      "Iter 1449 | Time 67.7443(67.7427) | Bit/dim 3.7099(3.7076) | Xent 0.3772(0.3270) | Loss 9.4406(10.1246) | Error 0.1384(0.1207) Steps 670(672.44) | Grad Norm 16.5553(7.8932) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 68.7615(67.7733) | Bit/dim 3.7117(3.7077) | Xent 0.3833(0.3287) | Loss 9.4973(10.1058) | Error 0.1380(0.1213) Steps 640(671.47) | Grad Norm 17.5808(8.1838) | Total Time 0.00(0.00)\n",
      "Iter 1451 | Time 69.2710(67.8182) | Bit/dim 3.7104(3.7078) | Xent 0.3361(0.3290) | Loss 9.3480(10.0830) | Error 0.1281(0.1215) Steps 670(671.43) | Grad Norm 8.9459(8.2067) | Total Time 0.00(0.00)\n",
      "Iter 1452 | Time 68.2952(67.8325) | Bit/dim 3.7089(3.7078) | Xent 0.3227(0.3288) | Loss 9.3093(10.0598) | Error 0.1189(0.1214) Steps 670(671.38) | Grad Norm 10.1709(8.2656) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0242 | Time 25.1402, Epoch Time 445.0163(445.0007), Bit/dim 3.7210(best: 3.7172), Xent 2.0930, Loss 4.7675, Error 0.4410(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1453 | Time 66.8236(67.8022) | Bit/dim 3.7083(3.7078) | Xent 0.3381(0.3290) | Loss 14.2286(10.1849) | Error 0.1244(0.1215) Steps 676(671.52) | Grad Norm 7.7619(8.2505) | Total Time 0.00(0.00)\n",
      "Iter 1454 | Time 69.3005(67.8472) | Bit/dim 3.7062(3.7078) | Xent 0.2885(0.3278) | Loss 9.2426(10.1566) | Error 0.1012(0.1209) Steps 700(672.38) | Grad Norm 5.7717(8.1762) | Total Time 0.00(0.00)\n",
      "Iter 1455 | Time 65.1461(67.7661) | Bit/dim 3.7166(3.7080) | Xent 0.3379(0.3281) | Loss 9.2037(10.1280) | Error 0.1209(0.1209) Steps 664(672.13) | Grad Norm 8.4758(8.1851) | Total Time 0.00(0.00)\n",
      "Iter 1456 | Time 69.6331(67.8222) | Bit/dim 3.7044(3.7079) | Xent 0.2921(0.3271) | Loss 9.0130(10.0946) | Error 0.1081(0.1205) Steps 664(671.88) | Grad Norm 5.0871(8.0922) | Total Time 0.00(0.00)\n",
      "Iter 1457 | Time 65.3303(67.7474) | Bit/dim 3.7067(3.7079) | Xent 0.3291(0.3271) | Loss 9.1753(10.0670) | Error 0.1215(0.1205) Steps 640(670.92) | Grad Norm 7.4918(8.0742) | Total Time 0.00(0.00)\n",
      "Iter 1458 | Time 64.5169(67.6505) | Bit/dim 3.7010(3.7077) | Xent 0.2901(0.3260) | Loss 9.1717(10.0401) | Error 0.1092(0.1202) Steps 652(670.36) | Grad Norm 7.5121(8.0573) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0243 | Time 24.1091, Epoch Time 443.5390(444.9568), Bit/dim 3.7309(best: 3.7172), Xent 2.2193, Loss 4.8406, Error 0.4394(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1459 | Time 64.3096(67.5503) | Bit/dim 3.7068(3.7076) | Xent 0.3188(0.3258) | Loss 13.9563(10.1576) | Error 0.1188(0.1201) Steps 664(670.17) | Grad Norm 13.7633(8.2285) | Total Time 0.00(0.00)\n",
      "Iter 1460 | Time 67.0906(67.5365) | Bit/dim 3.7051(3.7076) | Xent 0.3374(0.3261) | Loss 9.1778(10.1282) | Error 0.1240(0.1203) Steps 658(669.80) | Grad Norm 13.2909(8.3804) | Total Time 0.00(0.00)\n",
      "Iter 1461 | Time 66.5424(67.5066) | Bit/dim 3.7066(3.7075) | Xent 0.3153(0.3258) | Loss 9.2655(10.1023) | Error 0.1200(0.1203) Steps 670(669.81) | Grad Norm 6.4547(8.3226) | Total Time 0.00(0.00)\n",
      "Iter 1462 | Time 67.2623(67.4993) | Bit/dim 3.7141(3.7077) | Xent 0.2972(0.3249) | Loss 9.2066(10.0755) | Error 0.1095(0.1199) Steps 694(670.53) | Grad Norm 6.4664(8.2669) | Total Time 0.00(0.00)\n",
      "Iter 1463 | Time 69.6193(67.5629) | Bit/dim 3.7012(3.7075) | Xent 0.3091(0.3245) | Loss 9.2578(10.0509) | Error 0.1128(0.1197) Steps 694(671.24) | Grad Norm 7.0482(8.2304) | Total Time 0.00(0.00)\n",
      "Iter 1464 | Time 66.4891(67.5307) | Bit/dim 3.7124(3.7077) | Xent 0.2839(0.3233) | Loss 9.0882(10.0221) | Error 0.1059(0.1193) Steps 688(671.74) | Grad Norm 5.9941(8.1633) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0244 | Time 24.6940, Epoch Time 444.5973(444.9461), Bit/dim 3.7230(best: 3.7172), Xent 2.0605, Loss 4.7533, Error 0.4347(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1465 | Time 63.8628(67.4207) | Bit/dim 3.7004(3.7075) | Xent 0.3230(0.3232) | Loss 13.5978(10.1293) | Error 0.1225(0.1194) Steps 634(670.61) | Grad Norm 7.1725(8.1336) | Total Time 0.00(0.00)\n",
      "Iter 1466 | Time 67.0041(67.4082) | Bit/dim 3.6964(3.7071) | Xent 0.3120(0.3229) | Loss 9.1013(10.0985) | Error 0.1145(0.1192) Steps 652(670.05) | Grad Norm 7.7468(8.1220) | Total Time 0.00(0.00)\n",
      "Iter 1467 | Time 66.9605(67.3947) | Bit/dim 3.7006(3.7069) | Xent 0.3001(0.3222) | Loss 9.2495(10.0730) | Error 0.1080(0.1189) Steps 664(669.87) | Grad Norm 6.9964(8.0882) | Total Time 0.00(0.00)\n",
      "Iter 1468 | Time 71.8580(67.5286) | Bit/dim 3.7099(3.7070) | Xent 0.2784(0.3209) | Loss 9.2230(10.0475) | Error 0.1021(0.1184) Steps 694(670.59) | Grad Norm 5.3883(8.0072) | Total Time 0.00(0.00)\n",
      "Iter 1469 | Time 71.7472(67.6552) | Bit/dim 3.7069(3.7070) | Xent 0.2878(0.3199) | Loss 9.2777(10.0244) | Error 0.1058(0.1180) Steps 700(671.47) | Grad Norm 6.2049(7.9531) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 64.8293(67.5704) | Bit/dim 3.7082(3.7071) | Xent 0.2788(0.3187) | Loss 9.0278(9.9945) | Error 0.1030(0.1176) Steps 664(671.25) | Grad Norm 8.2864(7.9631) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0245 | Time 24.1772, Epoch Time 449.3161(445.0772), Bit/dim 3.7261(best: 3.7172), Xent 2.2760, Loss 4.8641, Error 0.4405(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1471 | Time 63.8070(67.4575) | Bit/dim 3.7069(3.7071) | Xent 0.2851(0.3177) | Loss 14.2230(10.1214) | Error 0.1032(0.1171) Steps 670(671.21) | Grad Norm 10.5600(8.0410) | Total Time 0.00(0.00)\n",
      "Iter 1472 | Time 65.7632(67.4067) | Bit/dim 3.7118(3.7072) | Xent 0.2972(0.3171) | Loss 9.2424(10.0950) | Error 0.1090(0.1169) Steps 640(670.28) | Grad Norm 8.1420(8.0441) | Total Time 0.00(0.00)\n",
      "Iter 1473 | Time 63.4457(67.2879) | Bit/dim 3.7037(3.7071) | Xent 0.3019(0.3166) | Loss 9.1861(10.0677) | Error 0.1090(0.1167) Steps 682(670.63) | Grad Norm 7.5819(8.0302) | Total Time 0.00(0.00)\n",
      "Iter 1474 | Time 69.8318(67.3642) | Bit/dim 3.7104(3.7072) | Xent 0.2857(0.3157) | Loss 9.3940(10.0475) | Error 0.1059(0.1163) Steps 670(670.61) | Grad Norm 7.9002(8.0263) | Total Time 0.00(0.00)\n",
      "Iter 1475 | Time 68.1019(67.3863) | Bit/dim 3.6988(3.7069) | Xent 0.2597(0.3140) | Loss 9.0291(10.0170) | Error 0.0978(0.1158) Steps 682(670.95) | Grad Norm 2.8168(7.8700) | Total Time 0.00(0.00)\n",
      "Iter 1476 | Time 62.8935(67.2515) | Bit/dim 3.7094(3.7070) | Xent 0.2684(0.3126) | Loss 9.2360(9.9936) | Error 0.0951(0.1152) Steps 658(670.56) | Grad Norm 6.8029(7.8380) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0246 | Time 24.7213, Epoch Time 437.1360(444.8389), Bit/dim 3.7201(best: 3.7172), Xent 2.2327, Loss 4.8364, Error 0.4375(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1477 | Time 67.1267(67.2478) | Bit/dim 3.7044(3.7069) | Xent 0.2817(0.3117) | Loss 13.9805(10.1132) | Error 0.1032(0.1148) Steps 682(670.91) | Grad Norm 5.0471(7.7543) | Total Time 0.00(0.00)\n",
      "Iter 1478 | Time 68.1150(67.2738) | Bit/dim 3.6973(3.7066) | Xent 0.2791(0.3107) | Loss 9.0934(10.0826) | Error 0.1040(0.1145) Steps 700(671.78) | Grad Norm 4.8303(7.6665) | Total Time 0.00(0.00)\n",
      "Iter 1479 | Time 67.9507(67.2941) | Bit/dim 3.7009(3.7065) | Xent 0.2814(0.3098) | Loss 9.1926(10.0559) | Error 0.1029(0.1141) Steps 634(670.64) | Grad Norm 5.7191(7.6081) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 64.5685(67.2123) | Bit/dim 3.7022(3.7063) | Xent 0.2746(0.3088) | Loss 9.2798(10.0326) | Error 0.0998(0.1137) Steps 646(669.91) | Grad Norm 5.6100(7.5482) | Total Time 0.00(0.00)\n",
      "Iter 1481 | Time 67.7686(67.2290) | Bit/dim 3.7161(3.7066) | Xent 0.2830(0.3080) | Loss 9.1922(10.0074) | Error 0.1052(0.1134) Steps 658(669.55) | Grad Norm 6.1692(7.5068) | Total Time 0.00(0.00)\n",
      "Iter 1482 | Time 65.4105(67.1745) | Bit/dim 3.7065(3.7066) | Xent 0.2658(0.3067) | Loss 9.0578(9.9789) | Error 0.0982(0.1130) Steps 646(668.84) | Grad Norm 2.8169(7.3661) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0247 | Time 24.1540, Epoch Time 443.6711(444.8039), Bit/dim 3.7300(best: 3.7172), Xent 2.2695, Loss 4.8648, Error 0.4370(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1483 | Time 63.2944(67.0581) | Bit/dim 3.6988(3.7064) | Xent 0.2654(0.3055) | Loss 14.0349(10.1006) | Error 0.0956(0.1125) Steps 640(667.98) | Grad Norm 4.3744(7.2764) | Total Time 0.00(0.00)\n",
      "Iter 1484 | Time 67.5911(67.0741) | Bit/dim 3.6950(3.7061) | Xent 0.2591(0.3041) | Loss 9.1940(10.0734) | Error 0.0938(0.1119) Steps 682(668.40) | Grad Norm 4.0030(7.1782) | Total Time 0.00(0.00)\n",
      "Iter 1485 | Time 66.9341(67.0699) | Bit/dim 3.7093(3.7062) | Xent 0.2743(0.3032) | Loss 9.2642(10.0491) | Error 0.1008(0.1116) Steps 682(668.81) | Grad Norm 7.3810(7.1842) | Total Time 0.00(0.00)\n",
      "Iter 1486 | Time 61.3457(66.8981) | Bit/dim 3.7063(3.7062) | Xent 0.2826(0.3026) | Loss 9.2622(10.0255) | Error 0.1041(0.1114) Steps 664(668.66) | Grad Norm 8.7937(7.2325) | Total Time 0.00(0.00)\n",
      "Iter 1487 | Time 70.4564(67.0049) | Bit/dim 3.7127(3.7064) | Xent 0.2936(0.3023) | Loss 9.2479(10.0022) | Error 0.1035(0.1111) Steps 670(668.70) | Grad Norm 9.0746(7.2878) | Total Time 0.00(0.00)\n",
      "Iter 1488 | Time 72.5994(67.1727) | Bit/dim 3.6964(3.7061) | Xent 0.2915(0.3020) | Loss 9.3021(9.9812) | Error 0.1080(0.1110) Steps 658(668.38) | Grad Norm 11.4346(7.4122) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0248 | Time 24.3813, Epoch Time 445.3025(444.8188), Bit/dim 3.7236(best: 3.7172), Xent 2.2436, Loss 4.8454, Error 0.4381(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1489 | Time 68.4478(67.2110) | Bit/dim 3.6925(3.7057) | Xent 0.3027(0.3020) | Loss 14.1643(10.1067) | Error 0.1094(0.1110) Steps 664(668.25) | Grad Norm 11.6528(7.5394) | Total Time 0.00(0.00)\n",
      "Iter 1490 | Time 64.1168(67.1181) | Bit/dim 3.7126(3.7059) | Xent 0.2842(0.3015) | Loss 9.2496(10.0809) | Error 0.1060(0.1108) Steps 670(668.30) | Grad Norm 10.2039(7.6193) | Total Time 0.00(0.00)\n",
      "Iter 1491 | Time 65.9477(67.0830) | Bit/dim 3.6983(3.7056) | Xent 0.2546(0.3001) | Loss 9.1686(10.0536) | Error 0.0930(0.1103) Steps 670(668.35) | Grad Norm 2.7425(7.4730) | Total Time 0.00(0.00)\n",
      "Iter 1492 | Time 65.4648(67.0345) | Bit/dim 3.6958(3.7053) | Xent 0.2744(0.2993) | Loss 9.1564(10.0267) | Error 0.0975(0.1099) Steps 646(667.68) | Grad Norm 7.2028(7.4649) | Total Time 0.00(0.00)\n",
      "Iter 1493 | Time 68.5031(67.0785) | Bit/dim 3.6967(3.7051) | Xent 0.2875(0.2990) | Loss 9.2311(10.0028) | Error 0.1068(0.1098) Steps 682(668.11) | Grad Norm 8.7464(7.5034) | Total Time 0.00(0.00)\n",
      "Iter 1494 | Time 66.4441(67.0595) | Bit/dim 3.7135(3.7053) | Xent 0.2790(0.2984) | Loss 9.2809(9.9811) | Error 0.1034(0.1096) Steps 688(668.71) | Grad Norm 8.7537(7.5409) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0249 | Time 24.3694, Epoch Time 442.5808(444.7517), Bit/dim 3.7229(best: 3.7172), Xent 2.2769, Loss 4.8613, Error 0.4370(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1495 | Time 65.6148(67.0162) | Bit/dim 3.6943(3.7050) | Xent 0.2610(0.2972) | Loss 14.7313(10.1236) | Error 0.0964(0.1092) Steps 658(668.39) | Grad Norm 3.8247(7.4294) | Total Time 0.00(0.00)\n",
      "Iter 1496 | Time 70.9759(67.1350) | Bit/dim 3.7038(3.7050) | Xent 0.2612(0.2962) | Loss 9.2505(10.0974) | Error 0.0972(0.1089) Steps 694(669.16) | Grad Norm 6.2323(7.3935) | Total Time 0.00(0.00)\n",
      "Iter 1497 | Time 66.3757(67.1122) | Bit/dim 3.6941(3.7046) | Xent 0.2963(0.2962) | Loss 9.1138(10.0679) | Error 0.1120(0.1090) Steps 682(669.54) | Grad Norm 10.5042(7.4868) | Total Time 0.00(0.00)\n",
      "Iter 1498 | Time 66.1250(67.0826) | Bit/dim 3.7176(3.7050) | Xent 0.2832(0.2958) | Loss 9.1993(10.0419) | Error 0.1004(0.1087) Steps 664(669.37) | Grad Norm 8.0223(7.5029) | Total Time 0.00(0.00)\n",
      "Iter 1499 | Time 66.7872(67.0737) | Bit/dim 3.7014(3.7049) | Xent 0.2510(0.2944) | Loss 9.1105(10.0139) | Error 0.0949(0.1083) Steps 640(668.49) | Grad Norm 3.3179(7.3773) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 63.1889(66.9572) | Bit/dim 3.7045(3.7049) | Xent 0.2687(0.2937) | Loss 9.1850(9.9891) | Error 0.0971(0.1079) Steps 676(668.72) | Grad Norm 6.0395(7.3372) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0250 | Time 24.5968, Epoch Time 442.0320(444.6701), Bit/dim 3.7238(best: 3.7172), Xent 2.3290, Loss 4.8883, Error 0.4379(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1501 | Time 64.4625(66.8823) | Bit/dim 3.7037(3.7049) | Xent 0.2644(0.2928) | Loss 13.9039(10.1065) | Error 0.0978(0.1076) Steps 670(668.76) | Grad Norm 7.9234(7.3548) | Total Time 0.00(0.00)\n",
      "Iter 1502 | Time 72.3199(67.0454) | Bit/dim 3.7109(3.7050) | Xent 0.2374(0.2911) | Loss 9.2996(10.0823) | Error 0.0846(0.1070) Steps 628(667.53) | Grad Norm 3.7437(7.2465) | Total Time 0.00(0.00)\n",
      "Iter 1503 | Time 68.7089(67.0954) | Bit/dim 3.7094(3.7052) | Xent 0.2669(0.2904) | Loss 9.2680(10.0579) | Error 0.0971(0.1067) Steps 670(667.61) | Grad Norm 5.6929(7.1998) | Total Time 0.00(0.00)\n",
      "Iter 1504 | Time 61.7450(66.9348) | Bit/dim 3.6952(3.7049) | Xent 0.2811(0.2901) | Loss 8.8875(10.0228) | Error 0.1038(0.1066) Steps 652(667.14) | Grad Norm 7.9204(7.2215) | Total Time 0.00(0.00)\n",
      "Iter 1505 | Time 71.2361(67.0639) | Bit/dim 3.6956(3.7046) | Xent 0.3085(0.2907) | Loss 9.1718(9.9972) | Error 0.1144(0.1068) Steps 676(667.41) | Grad Norm 8.1481(7.2493) | Total Time 0.00(0.00)\n",
      "Iter 1506 | Time 71.3709(67.1931) | Bit/dim 3.7000(3.7045) | Xent 0.2667(0.2899) | Loss 9.2917(9.9761) | Error 0.0991(0.1066) Steps 652(666.94) | Grad Norm 5.4867(7.1964) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 24.3390, Epoch Time 452.8809(444.9164), Bit/dim 3.7222(best: 3.7172), Xent 2.3106, Loss 4.8775, Error 0.4407(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1507 | Time 65.0614(67.1291) | Bit/dim 3.7081(3.7046) | Xent 0.2436(0.2886) | Loss 13.3213(10.0764) | Error 0.0910(0.1061) Steps 682(667.40) | Grad Norm 4.5586(7.1173) | Total Time 0.00(0.00)\n",
      "Iter 1508 | Time 65.2417(67.0725) | Bit/dim 3.7062(3.7046) | Xent 0.2479(0.2873) | Loss 9.1008(10.0472) | Error 0.0934(0.1057) Steps 640(666.57) | Grad Norm 5.9951(7.0836) | Total Time 0.00(0.00)\n",
      "Iter 1509 | Time 67.9418(67.0986) | Bit/dim 3.7026(3.7046) | Xent 0.2825(0.2872) | Loss 9.2238(10.0225) | Error 0.1038(0.1057) Steps 670(666.68) | Grad Norm 11.3437(7.2114) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 68.6626(67.1455) | Bit/dim 3.7039(3.7045) | Xent 0.2870(0.2872) | Loss 9.2722(9.9999) | Error 0.1024(0.1056) Steps 676(666.96) | Grad Norm 14.1330(7.4190) | Total Time 0.00(0.00)\n",
      "Iter 1511 | Time 63.3845(67.0327) | Bit/dim 3.6998(3.7044) | Xent 0.2895(0.2873) | Loss 9.0072(9.9702) | Error 0.1071(0.1056) Steps 682(667.41) | Grad Norm 11.2208(7.5331) | Total Time 0.00(0.00)\n",
      "Iter 1512 | Time 64.5191(66.9573) | Bit/dim 3.7088(3.7045) | Xent 0.2563(0.2863) | Loss 9.2423(9.9483) | Error 0.0901(0.1051) Steps 664(667.30) | Grad Norm 4.3945(7.4389) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 24.3539, Epoch Time 437.0278(444.6798), Bit/dim 3.7215(best: 3.7172), Xent 2.3335, Loss 4.8882, Error 0.4443(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1513 | Time 64.7087(66.8898) | Bit/dim 3.6942(3.7042) | Xent 0.2614(0.2856) | Loss 14.0344(10.0709) | Error 0.0940(0.1048) Steps 658(667.03) | Grad Norm 8.5073(7.4710) | Total Time 0.00(0.00)\n",
      "Iter 1514 | Time 61.7377(66.7353) | Bit/dim 3.7002(3.7041) | Xent 0.2865(0.2856) | Loss 9.0919(10.0415) | Error 0.1041(0.1048) Steps 658(666.76) | Grad Norm 12.4161(7.6193) | Total Time 0.00(0.00)\n",
      "Iter 1515 | Time 65.0511(66.6847) | Bit/dim 3.7054(3.7041) | Xent 0.2545(0.2847) | Loss 9.2422(10.0176) | Error 0.0956(0.1045) Steps 658(666.49) | Grad Norm 6.5121(7.5861) | Total Time 0.00(0.00)\n",
      "Iter 1516 | Time 64.4577(66.6179) | Bit/dim 3.6992(3.7040) | Xent 0.2705(0.2843) | Loss 9.1398(9.9912) | Error 0.0991(0.1044) Steps 676(666.78) | Grad Norm 6.9022(7.5656) | Total Time 0.00(0.00)\n",
      "Iter 1517 | Time 66.8932(66.6262) | Bit/dim 3.7065(3.7041) | Xent 0.2696(0.2838) | Loss 9.2033(9.9676) | Error 0.0984(0.1042) Steps 652(666.33) | Grad Norm 10.2617(7.6465) | Total Time 0.00(0.00)\n",
      "Iter 1518 | Time 66.6685(66.6274) | Bit/dim 3.6970(3.7039) | Xent 0.2835(0.2838) | Loss 9.1208(9.9422) | Error 0.1034(0.1042) Steps 658(666.08) | Grad Norm 9.4721(7.7013) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 25.1659, Epoch Time 432.7245(444.3211), Bit/dim 3.7245(best: 3.7172), Xent 2.3280, Loss 4.8886, Error 0.4480(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1519 | Time 67.6719(66.6588) | Bit/dim 3.7059(3.7039) | Xent 0.2883(0.2839) | Loss 14.2047(10.0701) | Error 0.1036(0.1041) Steps 658(665.84) | Grad Norm 8.8713(7.7364) | Total Time 0.00(0.00)\n",
      "Iter 1520 | Time 67.3500(66.6795) | Bit/dim 3.7074(3.7040) | Xent 0.3292(0.2853) | Loss 9.3400(10.0482) | Error 0.1214(0.1047) Steps 676(666.15) | Grad Norm 14.9088(7.9515) | Total Time 0.00(0.00)\n",
      "Iter 1521 | Time 65.4281(66.6420) | Bit/dim 3.7028(3.7040) | Xent 0.3303(0.2866) | Loss 9.2102(10.0230) | Error 0.1164(0.1050) Steps 682(666.62) | Grad Norm 16.7419(8.2152) | Total Time 0.00(0.00)\n",
      "Iter 1522 | Time 73.6778(66.8531) | Bit/dim 3.6964(3.7038) | Xent 0.2779(0.2864) | Loss 9.1794(9.9977) | Error 0.1028(0.1049) Steps 664(666.54) | Grad Norm 8.0448(8.2101) | Total Time 0.00(0.00)\n",
      "Iter 1523 | Time 66.9532(66.8561) | Bit/dim 3.6983(3.7036) | Xent 0.2755(0.2861) | Loss 9.1662(9.9728) | Error 0.1000(0.1048) Steps 664(666.47) | Grad Norm 9.4611(8.2477) | Total Time 0.00(0.00)\n",
      "Iter 1524 | Time 65.2620(66.8082) | Bit/dim 3.7035(3.7036) | Xent 0.2699(0.2856) | Loss 9.1029(9.9467) | Error 0.0962(0.1045) Steps 670(666.57) | Grad Norm 7.5164(8.2257) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 24.3173, Epoch Time 449.2860(444.4701), Bit/dim 3.7249(best: 3.7172), Xent 2.2274, Loss 4.8386, Error 0.4399(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1525 | Time 65.7686(66.7770) | Bit/dim 3.6979(3.7034) | Xent 0.2654(0.2850) | Loss 14.0921(10.0710) | Error 0.0974(0.1043) Steps 682(667.04) | Grad Norm 6.0295(8.1598) | Total Time 0.00(0.00)\n",
      "Iter 1526 | Time 67.1200(66.7873) | Bit/dim 3.6902(3.7030) | Xent 0.2548(0.2841) | Loss 9.1682(10.0439) | Error 0.0939(0.1040) Steps 670(667.12) | Grad Norm 7.9730(8.1542) | Total Time 0.00(0.00)\n",
      "Iter 1527 | Time 69.8111(66.8780) | Bit/dim 3.7107(3.7033) | Xent 0.2700(0.2836) | Loss 9.2316(10.0196) | Error 0.0961(0.1038) Steps 664(667.03) | Grad Norm 6.4553(8.1033) | Total Time 0.00(0.00)\n",
      "Iter 1528 | Time 65.3970(66.8336) | Bit/dim 3.7043(3.7033) | Xent 0.2581(0.2829) | Loss 9.1610(9.9938) | Error 0.0952(0.1035) Steps 670(667.12) | Grad Norm 6.6148(8.0586) | Total Time 0.00(0.00)\n",
      "Iter 1529 | Time 64.0049(66.7488) | Bit/dim 3.7097(3.7035) | Xent 0.2522(0.2820) | Loss 9.1324(9.9680) | Error 0.0913(0.1031) Steps 664(667.03) | Grad Norm 7.7245(8.0486) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 66.7747(66.7495) | Bit/dim 3.7063(3.7036) | Xent 0.2496(0.2810) | Loss 9.3007(9.9480) | Error 0.0877(0.1027) Steps 664(666.94) | Grad Norm 4.7590(7.9499) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 24.6510, Epoch Time 442.4459(444.4093), Bit/dim 3.7196(best: 3.7172), Xent 2.4247, Loss 4.9319, Error 0.4422(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1531 | Time 65.3277(66.7069) | Bit/dim 3.6993(3.7034) | Xent 0.2628(0.2804) | Loss 13.9747(10.0688) | Error 0.0930(0.1024) Steps 670(667.03) | Grad Norm 5.0552(7.8631) | Total Time 0.00(0.00)\n",
      "Iter 1532 | Time 69.4183(66.7882) | Bit/dim 3.6980(3.7033) | Xent 0.2637(0.2799) | Loss 9.1488(10.0412) | Error 0.0938(0.1021) Steps 670(667.12) | Grad Norm 6.1071(7.8104) | Total Time 0.00(0.00)\n",
      "Iter 1533 | Time 63.1999(66.6806) | Bit/dim 3.6996(3.7032) | Xent 0.2548(0.2792) | Loss 9.0617(10.0118) | Error 0.0933(0.1019) Steps 652(666.66) | Grad Norm 6.3080(7.7653) | Total Time 0.00(0.00)\n",
      "Iter 1534 | Time 66.1775(66.6655) | Bit/dim 3.7108(3.7034) | Xent 0.2498(0.2783) | Loss 9.2569(9.9891) | Error 0.0925(0.1016) Steps 664(666.58) | Grad Norm 3.2584(7.6301) | Total Time 0.00(0.00)\n",
      "Iter 1535 | Time 64.1222(66.5892) | Bit/dim 3.7000(3.7033) | Xent 0.2352(0.2770) | Loss 9.1742(9.9647) | Error 0.0801(0.1009) Steps 670(666.69) | Grad Norm 3.7286(7.5131) | Total Time 0.00(0.00)\n",
      "Iter 1536 | Time 70.0980(66.6944) | Bit/dim 3.6974(3.7031) | Xent 0.2492(0.2762) | Loss 9.1883(9.9414) | Error 0.0949(0.1008) Steps 670(666.79) | Grad Norm 5.2883(7.4463) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 25.0248, Epoch Time 442.6062(444.3552), Bit/dim 3.7235(best: 3.7172), Xent 2.3624, Loss 4.9047, Error 0.4440(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1537 | Time 71.0990(66.8266) | Bit/dim 3.7101(3.7033) | Xent 0.2492(0.2754) | Loss 14.5670(10.0802) | Error 0.0914(0.1005) Steps 700(667.78) | Grad Norm 5.3932(7.3847) | Total Time 0.00(0.00)\n",
      "Iter 1538 | Time 67.0152(66.8322) | Bit/dim 3.6951(3.7031) | Xent 0.2436(0.2744) | Loss 9.0938(10.0506) | Error 0.0887(0.1001) Steps 640(666.95) | Grad Norm 4.7184(7.3047) | Total Time 0.00(0.00)\n",
      "Iter 1539 | Time 65.2843(66.7858) | Bit/dim 3.6954(3.7028) | Xent 0.2523(0.2738) | Loss 9.2629(10.0269) | Error 0.0913(0.0999) Steps 670(667.04) | Grad Norm 7.0589(7.2973) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 71.0807(66.9146) | Bit/dim 3.7051(3.7029) | Xent 0.2686(0.2736) | Loss 9.3398(10.0063) | Error 0.0966(0.0998) Steps 676(667.31) | Grad Norm 15.7214(7.5501) | Total Time 0.00(0.00)\n",
      "Iter 1541 | Time 69.0318(66.9782) | Bit/dim 3.6973(3.7027) | Xent 0.3096(0.2747) | Loss 9.1507(9.9807) | Error 0.1172(0.1003) Steps 652(666.85) | Grad Norm 17.7582(7.8563) | Total Time 0.00(0.00)\n",
      "Iter 1542 | Time 64.8507(66.9143) | Bit/dim 3.7084(3.7029) | Xent 0.3853(0.2780) | Loss 9.2919(9.9600) | Error 0.1399(0.1015) Steps 676(667.12) | Grad Norm 12.0850(7.9832) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 24.4775, Epoch Time 451.3284(444.5644), Bit/dim 3.7283(best: 3.7172), Xent 2.2135, Loss 4.8351, Error 0.4430(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1543 | Time 63.7763(66.8202) | Bit/dim 3.7222(3.7035) | Xent 0.3427(0.2799) | Loss 13.2244(10.0579) | Error 0.1269(0.1022) Steps 658(666.85) | Grad Norm 9.6032(8.0318) | Total Time 0.00(0.00)\n",
      "Iter 1544 | Time 67.7622(66.8485) | Bit/dim 3.6923(3.7032) | Xent 0.2972(0.2805) | Loss 9.1568(10.0309) | Error 0.1069(0.1024) Steps 634(665.86) | Grad Norm 8.5354(8.0469) | Total Time 0.00(0.00)\n",
      "Iter 1545 | Time 69.1125(66.9164) | Bit/dim 3.6948(3.7029) | Xent 0.3020(0.2811) | Loss 9.2268(10.0068) | Error 0.1125(0.1027) Steps 688(666.53) | Grad Norm 8.7186(8.0670) | Total Time 0.00(0.00)\n",
      "Iter 1546 | Time 65.0469(66.8603) | Bit/dim 3.7012(3.7029) | Xent 0.2757(0.2809) | Loss 9.0976(9.9795) | Error 0.1004(0.1026) Steps 652(666.09) | Grad Norm 5.9267(8.0028) | Total Time 0.00(0.00)\n",
      "Iter 1547 | Time 60.6848(66.6750) | Bit/dim 3.7130(3.7032) | Xent 0.2688(0.2806) | Loss 9.2768(9.9584) | Error 0.0942(0.1024) Steps 634(665.13) | Grad Norm 5.0983(7.9157) | Total Time 0.00(0.00)\n",
      "Iter 1548 | Time 64.5617(66.6116) | Bit/dim 3.7131(3.7035) | Xent 0.2947(0.2810) | Loss 9.0815(9.9321) | Error 0.1099(0.1026) Steps 652(664.74) | Grad Norm 9.0563(7.9499) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 24.4531, Epoch Time 433.9696(444.2466), Bit/dim 3.7217(best: 3.7172), Xent 2.1957, Loss 4.8196, Error 0.4337(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1549 | Time 69.8322(66.7082) | Bit/dim 3.7059(3.7035) | Xent 0.2510(0.2801) | Loss 14.4718(10.0683) | Error 0.0871(0.1021) Steps 658(664.53) | Grad Norm 3.3518(7.8120) | Total Time 0.00(0.00)\n",
      "Iter 1550 | Time 61.1002(66.5400) | Bit/dim 3.6929(3.7032) | Xent 0.2673(0.2797) | Loss 9.1835(10.0418) | Error 0.0968(0.1020) Steps 640(663.80) | Grad Norm 8.4265(7.8304) | Total Time 0.00(0.00)\n",
      "Iter 1551 | Time 65.6401(66.5130) | Bit/dim 3.6967(3.7030) | Xent 0.2699(0.2794) | Loss 8.9923(10.0103) | Error 0.0996(0.1019) Steps 640(663.08) | Grad Norm 7.0077(7.8057) | Total Time 0.00(0.00)\n",
      "Iter 1552 | Time 68.7365(66.5797) | Bit/dim 3.7022(3.7030) | Xent 0.2421(0.2783) | Loss 9.3222(9.9896) | Error 0.0867(0.1014) Steps 646(662.57) | Grad Norm 4.7976(7.7155) | Total Time 0.00(0.00)\n",
      "Iter 1553 | Time 65.0085(66.5326) | Bit/dim 3.6959(3.7028) | Xent 0.2757(0.2782) | Loss 9.0199(9.9605) | Error 0.1006(0.1014) Steps 688(663.33) | Grad Norm 6.5184(7.6796) | Total Time 0.00(0.00)\n",
      "Iter 1554 | Time 62.3455(66.4070) | Bit/dim 3.7006(3.7027) | Xent 0.2471(0.2773) | Loss 9.0756(9.9340) | Error 0.0889(0.1010) Steps 646(662.81) | Grad Norm 6.8726(7.6554) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 24.5756, Epoch Time 435.7334(443.9912), Bit/dim 3.7214(best: 3.7172), Xent 2.4210, Loss 4.9319, Error 0.4494(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1555 | Time 68.2795(66.4631) | Bit/dim 3.7054(3.7028) | Xent 0.2562(0.2767) | Loss 14.4049(10.0681) | Error 0.0951(0.1009) Steps 712(664.29) | Grad Norm 8.3819(7.6772) | Total Time 0.00(0.00)\n",
      "Iter 1556 | Time 66.5854(66.4668) | Bit/dim 3.7002(3.7027) | Xent 0.2323(0.2753) | Loss 9.2055(10.0422) | Error 0.0864(0.1004) Steps 664(664.28) | Grad Norm 6.7572(7.6496) | Total Time 0.00(0.00)\n",
      "Iter 1557 | Time 63.0656(66.3648) | Bit/dim 3.6954(3.7025) | Xent 0.2398(0.2743) | Loss 8.9953(10.0108) | Error 0.0836(0.0999) Steps 646(663.73) | Grad Norm 3.3539(7.5207) | Total Time 0.00(0.00)\n",
      "Iter 1558 | Time 68.4136(66.4262) | Bit/dim 3.7014(3.7025) | Xent 0.2462(0.2734) | Loss 9.1604(9.9853) | Error 0.0880(0.0996) Steps 694(664.64) | Grad Norm 5.0823(7.4475) | Total Time 0.00(0.00)\n",
      "Iter 1559 | Time 69.1767(66.5087) | Bit/dim 3.7088(3.7027) | Xent 0.2528(0.2728) | Loss 9.1764(9.9611) | Error 0.0952(0.0994) Steps 706(665.88) | Grad Norm 7.0739(7.4363) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 68.7256(66.5753) | Bit/dim 3.7015(3.7026) | Xent 0.2507(0.2721) | Loss 9.2704(9.9403) | Error 0.0948(0.0993) Steps 658(665.65) | Grad Norm 9.7401(7.5054) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 24.7980, Epoch Time 447.6978(444.1024), Bit/dim 3.7194(best: 3.7172), Xent 2.3478, Loss 4.8933, Error 0.4435(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1561 | Time 67.1466(66.5924) | Bit/dim 3.6978(3.7025) | Xent 0.2318(0.2709) | Loss 14.2343(10.0692) | Error 0.0849(0.0989) Steps 682(666.14) | Grad Norm 7.2562(7.4980) | Total Time 0.00(0.00)\n",
      "Iter 1562 | Time 62.2716(66.4628) | Bit/dim 3.7026(3.7025) | Xent 0.2273(0.2696) | Loss 8.9323(10.0350) | Error 0.0843(0.0984) Steps 682(666.61) | Grad Norm 4.4075(7.4052) | Total Time 0.00(0.00)\n",
      "Iter 1563 | Time 66.6696(66.4690) | Bit/dim 3.7056(3.7026) | Xent 0.2263(0.2683) | Loss 9.0520(10.0056) | Error 0.0865(0.0981) Steps 694(667.43) | Grad Norm 4.2194(7.3097) | Total Time 0.00(0.00)\n",
      "Iter 1564 | Time 63.6569(66.3846) | Bit/dim 3.6901(3.7022) | Xent 0.2383(0.2674) | Loss 9.1055(9.9786) | Error 0.0889(0.0978) Steps 682(667.87) | Grad Norm 4.5597(7.2272) | Total Time 0.00(0.00)\n",
      "Iter 1565 | Time 64.5647(66.3300) | Bit/dim 3.6992(3.7021) | Xent 0.2247(0.2661) | Loss 9.2076(9.9554) | Error 0.0820(0.0973) Steps 658(667.57) | Grad Norm 4.8343(7.1554) | Total Time 0.00(0.00)\n",
      "Iter 1566 | Time 68.5580(66.3969) | Bit/dim 3.7013(3.7021) | Xent 0.2383(0.2653) | Loss 9.2664(9.9348) | Error 0.0883(0.0970) Steps 658(667.29) | Grad Norm 6.4334(7.1337) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 24.7561, Epoch Time 436.4225(443.8720), Bit/dim 3.7154(best: 3.7172), Xent 2.4248, Loss 4.9278, Error 0.4378(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1567 | Time 60.0259(66.2057) | Bit/dim 3.7034(3.7021) | Xent 0.2421(0.2646) | Loss 13.5262(10.0425) | Error 0.0850(0.0967) Steps 658(667.01) | Grad Norm 4.7552(7.0624) | Total Time 0.00(0.00)\n",
      "Iter 1568 | Time 61.6414(66.0688) | Bit/dim 3.7016(3.7021) | Xent 0.2127(0.2631) | Loss 9.0522(10.0128) | Error 0.0797(0.0962) Steps 658(666.74) | Grad Norm 5.1902(7.0062) | Total Time 0.00(0.00)\n",
      "Iter 1569 | Time 62.0457(65.9481) | Bit/dim 3.6898(3.7017) | Xent 0.2348(0.2622) | Loss 9.1943(9.9882) | Error 0.0870(0.0959) Steps 664(666.66) | Grad Norm 6.9511(7.0045) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 67.6290(65.9985) | Bit/dim 3.6924(3.7015) | Xent 0.2264(0.2611) | Loss 9.1353(9.9626) | Error 0.0835(0.0955) Steps 670(666.76) | Grad Norm 4.0799(6.9168) | Total Time 0.00(0.00)\n",
      "Iter 1571 | Time 61.6880(65.8692) | Bit/dim 3.7067(3.7016) | Xent 0.2224(0.2600) | Loss 9.2070(9.9400) | Error 0.0781(0.0950) Steps 652(666.31) | Grad Norm 6.6132(6.9077) | Total Time 0.00(0.00)\n",
      "Iter 1572 | Time 61.4510(65.7367) | Bit/dim 3.6958(3.7014) | Xent 0.2233(0.2589) | Loss 9.0911(9.9145) | Error 0.0819(0.0946) Steps 652(665.88) | Grad Norm 5.9535(6.8791) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 24.8954, Epoch Time 417.9448(443.0942), Bit/dim 3.7224(best: 3.7154), Xent 2.4566, Loss 4.9507, Error 0.4436(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1573 | Time 63.7359(65.6766) | Bit/dim 3.7022(3.7015) | Xent 0.2277(0.2579) | Loss 14.5519(10.0536) | Error 0.0863(0.0944) Steps 676(666.19) | Grad Norm 6.9249(6.8804) | Total Time 0.00(0.00)\n",
      "Iter 1574 | Time 63.5980(65.6143) | Bit/dim 3.6968(3.7013) | Xent 0.2203(0.2568) | Loss 9.1618(10.0269) | Error 0.0806(0.0939) Steps 664(666.12) | Grad Norm 8.8225(6.9387) | Total Time 0.00(0.00)\n",
      "Iter 1575 | Time 63.5939(65.5537) | Bit/dim 3.6957(3.7012) | Xent 0.2509(0.2566) | Loss 9.1158(9.9995) | Error 0.0889(0.0938) Steps 646(665.52) | Grad Norm 9.8829(7.0270) | Total Time 0.00(0.00)\n",
      "Iter 1576 | Time 65.7795(65.5604) | Bit/dim 3.6927(3.7009) | Xent 0.2546(0.2566) | Loss 9.2013(9.9756) | Error 0.0952(0.0938) Steps 670(665.65) | Grad Norm 11.9897(7.1759) | Total Time 0.00(0.00)\n",
      "Iter 1577 | Time 68.4390(65.6468) | Bit/dim 3.7048(3.7010) | Xent 0.2907(0.2576) | Loss 9.2383(9.9535) | Error 0.1091(0.0943) Steps 658(665.42) | Grad Norm 13.3297(7.3605) | Total Time 0.00(0.00)\n",
      "Iter 1578 | Time 64.4010(65.6094) | Bit/dim 3.6964(3.7009) | Xent 0.2751(0.2581) | Loss 9.3135(9.9343) | Error 0.1020(0.0945) Steps 646(664.84) | Grad Norm 12.7477(7.5221) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 24.9534, Epoch Time 433.5130(442.8068), Bit/dim 3.7227(best: 3.7154), Xent 2.3423, Loss 4.8938, Error 0.4421(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1579 | Time 67.1950(65.6570) | Bit/dim 3.7076(3.7011) | Xent 0.2227(0.2571) | Loss 14.3038(10.0654) | Error 0.0807(0.0941) Steps 664(664.82) | Grad Norm 5.2625(7.4544) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 69.2111(65.7636) | Bit/dim 3.6810(3.7005) | Xent 0.2564(0.2570) | Loss 9.1505(10.0379) | Error 0.0903(0.0940) Steps 676(665.15) | Grad Norm 7.7908(7.4644) | Total Time 0.00(0.00)\n",
      "Iter 1581 | Time 69.9999(65.8907) | Bit/dim 3.6993(3.7004) | Xent 0.2647(0.2573) | Loss 8.9747(10.0060) | Error 0.1001(0.0942) Steps 688(665.84) | Grad Norm 8.4028(7.4926) | Total Time 0.00(0.00)\n",
      "Iter 1582 | Time 63.1340(65.8080) | Bit/dim 3.7021(3.7005) | Xent 0.2423(0.2568) | Loss 9.2524(9.9834) | Error 0.0879(0.0940) Steps 658(665.60) | Grad Norm 9.6584(7.5576) | Total Time 0.00(0.00)\n",
      "Iter 1583 | Time 66.9351(65.8418) | Bit/dim 3.6968(3.7004) | Xent 0.2518(0.2567) | Loss 9.0905(9.9566) | Error 0.0930(0.0940) Steps 634(664.65) | Grad Norm 7.8117(7.5652) | Total Time 0.00(0.00)\n",
      "Iter 1584 | Time 69.4211(65.9492) | Bit/dim 3.7028(3.7005) | Xent 0.2478(0.2564) | Loss 9.2016(9.9340) | Error 0.0915(0.0939) Steps 706(665.89) | Grad Norm 6.2637(7.5262) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 24.6122, Epoch Time 449.6384(443.0117), Bit/dim 3.7219(best: 3.7154), Xent 2.4760, Loss 4.9599, Error 0.4477(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1585 | Time 65.0728(65.9229) | Bit/dim 3.7025(3.7005) | Xent 0.2367(0.2558) | Loss 13.8791(10.0523) | Error 0.0879(0.0937) Steps 664(665.84) | Grad Norm 6.8585(7.5061) | Total Time 0.00(0.00)\n",
      "Iter 1586 | Time 60.9930(65.7750) | Bit/dim 3.6937(3.7003) | Xent 0.2624(0.2560) | Loss 9.1202(10.0244) | Error 0.0950(0.0937) Steps 670(665.96) | Grad Norm 12.2215(7.6476) | Total Time 0.00(0.00)\n",
      "Iter 1587 | Time 67.7873(65.8354) | Bit/dim 3.6990(3.7003) | Xent 0.3156(0.2578) | Loss 9.2417(10.0009) | Error 0.1166(0.0944) Steps 670(666.08) | Grad Norm 16.7231(7.9198) | Total Time 0.00(0.00)\n",
      "Iter 1588 | Time 67.9478(65.8988) | Bit/dim 3.6993(3.7002) | Xent 0.2482(0.2575) | Loss 9.1468(9.9753) | Error 0.0941(0.0944) Steps 676(666.38) | Grad Norm 10.0813(7.9847) | Total Time 0.00(0.00)\n",
      "Iter 1589 | Time 65.8483(65.8972) | Bit/dim 3.6943(3.7001) | Xent 0.2643(0.2577) | Loss 9.1000(9.9490) | Error 0.0982(0.0945) Steps 676(666.67) | Grad Norm 5.7622(7.9180) | Total Time 0.00(0.00)\n",
      "Iter 1590 | Time 67.7335(65.9523) | Bit/dim 3.6990(3.7000) | Xent 0.2752(0.2582) | Loss 9.2590(9.9283) | Error 0.1028(0.0948) Steps 676(666.95) | Grad Norm 10.7581(8.0032) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 24.5328, Epoch Time 438.4479(442.8748), Bit/dim 3.7222(best: 3.7154), Xent 2.3044, Loss 4.8744, Error 0.4417(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1591 | Time 68.1539(66.0184) | Bit/dim 3.7071(3.7002) | Xent 0.2513(0.2580) | Loss 14.3746(10.0617) | Error 0.0955(0.0948) Steps 658(666.68) | Grad Norm 7.6276(7.9919) | Total Time 0.00(0.00)\n",
      "Iter 1592 | Time 62.0480(65.8993) | Bit/dim 3.6924(3.7000) | Xent 0.2522(0.2579) | Loss 8.9261(10.0276) | Error 0.0924(0.0947) Steps 664(666.60) | Grad Norm 8.0591(7.9940) | Total Time 0.00(0.00)\n",
      "Iter 1593 | Time 64.1801(65.8477) | Bit/dim 3.6989(3.7000) | Xent 0.3016(0.2592) | Loss 9.3619(10.0077) | Error 0.1114(0.0952) Steps 652(666.16) | Grad Norm 14.2757(8.1824) | Total Time 0.00(0.00)\n",
      "Iter 1594 | Time 66.9838(65.8818) | Bit/dim 3.6945(3.6998) | Xent 0.2676(0.2594) | Loss 9.3634(9.9883) | Error 0.0972(0.0953) Steps 682(666.64) | Grad Norm 9.8611(8.2328) | Total Time 0.00(0.00)\n",
      "Iter 1595 | Time 68.1949(65.9512) | Bit/dim 3.6951(3.6997) | Xent 0.2720(0.2598) | Loss 8.8934(9.9555) | Error 0.0976(0.0954) Steps 652(666.20) | Grad Norm 9.4674(8.2698) | Total Time 0.00(0.00)\n",
      "Iter 1596 | Time 65.7870(65.9462) | Bit/dim 3.6979(3.6996) | Xent 0.2538(0.2596) | Loss 8.9854(9.9264) | Error 0.0956(0.0954) Steps 664(666.13) | Grad Norm 10.1574(8.3264) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 24.7928, Epoch Time 439.0081(442.7588), Bit/dim 3.7245(best: 3.7154), Xent 2.4497, Loss 4.9493, Error 0.4524(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1597 | Time 60.8530(65.7934) | Bit/dim 3.6950(3.6995) | Xent 0.2713(0.2600) | Loss 14.2550(10.0562) | Error 0.0964(0.0954) Steps 652(665.71) | Grad Norm 11.2741(8.4149) | Total Time 0.00(0.00)\n",
      "Iter 1598 | Time 68.1724(65.8648) | Bit/dim 3.7091(3.6998) | Xent 0.2449(0.2595) | Loss 9.3398(10.0347) | Error 0.0880(0.0952) Steps 682(666.20) | Grad Norm 8.6936(8.4232) | Total Time 0.00(0.00)\n",
      "Iter 1599 | Time 66.4139(65.8813) | Bit/dim 3.6979(3.6997) | Xent 0.2484(0.2592) | Loss 9.0984(10.0066) | Error 0.0915(0.0951) Steps 658(665.95) | Grad Norm 7.1173(8.3841) | Total Time 0.00(0.00)\n",
      "Iter 1600 | Time 69.9933(66.0046) | Bit/dim 3.6986(3.6997) | Xent 0.2442(0.2587) | Loss 9.1485(9.9809) | Error 0.0850(0.0948) Steps 676(666.25) | Grad Norm 9.4590(8.4163) | Total Time 0.00(0.00)\n",
      "Iter 1601 | Time 61.6420(65.8738) | Bit/dim 3.7100(3.7000) | Xent 0.2285(0.2578) | Loss 9.1818(9.9569) | Error 0.0817(0.0944) Steps 670(666.36) | Grad Norm 5.8766(8.3401) | Total Time 0.00(0.00)\n",
      "Iter 1602 | Time 64.0427(65.8188) | Bit/dim 3.7074(3.7002) | Xent 0.2352(0.2571) | Loss 9.1421(9.9325) | Error 0.0859(0.0941) Steps 670(666.47) | Grad Norm 6.6376(8.2890) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0267 | Time 24.8167, Epoch Time 434.7081(442.5173), Bit/dim 3.7184(best: 3.7154), Xent 2.3892, Loss 4.9130, Error 0.4370(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1603 | Time 64.8857(65.7908) | Bit/dim 3.6901(3.6999) | Xent 0.2297(0.2563) | Loss 14.2119(10.0609) | Error 0.0834(0.0938) Steps 670(666.58) | Grad Norm 8.9794(8.3097) | Total Time 0.00(0.00)\n",
      "Iter 1604 | Time 71.7194(65.9687) | Bit/dim 3.6991(3.6999) | Xent 0.2386(0.2558) | Loss 9.0917(10.0318) | Error 0.0885(0.0936) Steps 634(665.60) | Grad Norm 12.9104(8.4478) | Total Time 0.00(0.00)\n",
      "Iter 1605 | Time 62.5173(65.8652) | Bit/dim 3.6942(3.6997) | Xent 0.2326(0.2551) | Loss 9.1594(10.0056) | Error 0.0821(0.0933) Steps 658(665.37) | Grad Norm 5.9469(8.3727) | Total Time 0.00(0.00)\n",
      "Iter 1606 | Time 68.0670(65.9312) | Bit/dim 3.7115(3.7001) | Xent 0.2247(0.2542) | Loss 9.0187(9.9760) | Error 0.0765(0.0928) Steps 658(665.15) | Grad Norm 10.5506(8.4381) | Total Time 0.00(0.00)\n",
      "Iter 1607 | Time 65.7183(65.9248) | Bit/dim 3.6958(3.6999) | Xent 0.2385(0.2537) | Loss 9.0265(9.9475) | Error 0.0854(0.0926) Steps 658(664.94) | Grad Norm 9.5612(8.4718) | Total Time 0.00(0.00)\n",
      "Iter 1608 | Time 64.7295(65.8890) | Bit/dim 3.7109(3.7003) | Xent 0.2185(0.2527) | Loss 9.0106(9.9194) | Error 0.0780(0.0921) Steps 676(665.27) | Grad Norm 8.4466(8.4710) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0268 | Time 24.5385, Epoch Time 440.3327(442.4517), Bit/dim 3.7189(best: 3.7154), Xent 2.4589, Loss 4.9484, Error 0.4410(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1609 | Time 65.5492(65.8788) | Bit/dim 3.6843(3.6998) | Xent 0.2358(0.2521) | Loss 13.8714(10.0380) | Error 0.0829(0.0919) Steps 652(664.87) | Grad Norm 8.4981(8.4718) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 68.3686(65.9535) | Bit/dim 3.6953(3.6997) | Xent 0.2606(0.2524) | Loss 9.1312(10.0108) | Error 0.0936(0.0919) Steps 676(665.21) | Grad Norm 10.8960(8.5446) | Total Time 0.00(0.00)\n",
      "Iter 1611 | Time 69.0045(66.0450) | Bit/dim 3.7036(3.6998) | Xent 0.2151(0.2513) | Loss 8.9206(9.9781) | Error 0.0761(0.0914) Steps 700(666.25) | Grad Norm 5.5624(8.4551) | Total Time 0.00(0.00)\n",
      "Iter 1612 | Time 63.1593(65.9584) | Bit/dim 3.7042(3.6999) | Xent 0.2562(0.2514) | Loss 9.1841(9.9543) | Error 0.0919(0.0914) Steps 664(666.18) | Grad Norm 8.1511(8.4460) | Total Time 0.00(0.00)\n",
      "Iter 1613 | Time 66.1125(65.9631) | Bit/dim 3.7068(3.7001) | Xent 0.2691(0.2520) | Loss 9.2918(9.9344) | Error 0.0991(0.0917) Steps 640(665.40) | Grad Norm 11.2398(8.5298) | Total Time 0.00(0.00)\n",
      "Iter 1614 | Time 65.8124(65.9585) | Bit/dim 3.6882(3.6998) | Xent 0.2581(0.2521) | Loss 9.0944(9.9092) | Error 0.0996(0.0919) Steps 688(666.07) | Grad Norm 9.4224(8.5566) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0269 | Time 24.8308, Epoch Time 441.9016(442.4352), Bit/dim 3.7218(best: 3.7154), Xent 2.3738, Loss 4.9087, Error 0.4387(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1615 | Time 65.8793(65.9562) | Bit/dim 3.6845(3.6993) | Xent 0.2282(0.2514) | Loss 13.9104(10.0292) | Error 0.0859(0.0917) Steps 634(665.11) | Grad Norm 8.8008(8.5639) | Total Time 0.00(0.00)\n",
      "Iter 1616 | Time 66.1726(65.9626) | Bit/dim 3.7030(3.6994) | Xent 0.2227(0.2506) | Loss 9.0371(9.9995) | Error 0.0820(0.0914) Steps 646(664.54) | Grad Norm 6.2389(8.4941) | Total Time 0.00(0.00)\n",
      "Iter 1617 | Time 70.5772(66.1011) | Bit/dim 3.6982(3.6994) | Xent 0.2456(0.2504) | Loss 9.1557(9.9741) | Error 0.0917(0.0915) Steps 658(664.34) | Grad Norm 12.3303(8.6092) | Total Time 0.00(0.00)\n",
      "Iter 1618 | Time 68.4094(66.1703) | Bit/dim 3.6974(3.6993) | Xent 0.2284(0.2498) | Loss 9.0344(9.9460) | Error 0.0799(0.0911) Steps 640(663.61) | Grad Norm 5.4096(8.5132) | Total Time 0.00(0.00)\n",
      "Iter 1619 | Time 62.1076(66.0485) | Bit/dim 3.7027(3.6994) | Xent 0.2221(0.2489) | Loss 9.0640(9.9195) | Error 0.0773(0.0907) Steps 646(663.08) | Grad Norm 7.5888(8.4855) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 62.5036(65.9421) | Bit/dim 3.6983(3.6994) | Xent 0.2308(0.2484) | Loss 9.2652(9.8999) | Error 0.0805(0.0904) Steps 682(663.65) | Grad Norm 5.3743(8.3922) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0270 | Time 24.9252, Epoch Time 439.1253(442.3359), Bit/dim 3.7186(best: 3.7154), Xent 2.4703, Loss 4.9537, Error 0.4410(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1621 | Time 63.3298(65.8637) | Bit/dim 3.6932(3.6992) | Xent 0.2215(0.2476) | Loss 14.1029(10.0260) | Error 0.0771(0.0900) Steps 670(663.84) | Grad Norm 7.8949(8.3772) | Total Time 0.00(0.00)\n",
      "Iter 1622 | Time 64.9492(65.8363) | Bit/dim 3.6992(3.6992) | Xent 0.2293(0.2470) | Loss 9.1274(9.9990) | Error 0.0841(0.0898) Steps 658(663.67) | Grad Norm 8.2558(8.3736) | Total Time 0.00(0.00)\n",
      "Iter 1623 | Time 62.0786(65.7236) | Bit/dim 3.7133(3.6996) | Xent 0.2208(0.2462) | Loss 9.0822(9.9715) | Error 0.0793(0.0895) Steps 658(663.50) | Grad Norm 6.2349(8.3094) | Total Time 0.00(0.00)\n",
      "Iter 1624 | Time 63.8023(65.6659) | Bit/dim 3.6993(3.6996) | Xent 0.2287(0.2457) | Loss 9.1517(9.9469) | Error 0.0784(0.0892) Steps 646(662.97) | Grad Norm 5.6790(8.2305) | Total Time 0.00(0.00)\n",
      "Iter 1625 | Time 65.0336(65.6470) | Bit/dim 3.6955(3.6995) | Xent 0.2182(0.2449) | Loss 9.0538(9.9201) | Error 0.0775(0.0888) Steps 676(663.36) | Grad Norm 6.6287(8.1825) | Total Time 0.00(0.00)\n",
      "Iter 1626 | Time 65.9825(65.6570) | Bit/dim 3.6917(3.6993) | Xent 0.2017(0.2436) | Loss 9.1374(9.8966) | Error 0.0709(0.0883) Steps 688(664.10) | Grad Norm 6.0169(8.1175) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0271 | Time 25.1510, Epoch Time 428.8852(441.9324), Bit/dim 3.7225(best: 3.7154), Xent 2.5167, Loss 4.9809, Error 0.4422(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1627 | Time 61.1474(65.5217) | Bit/dim 3.7065(3.6995) | Xent 0.2342(0.2433) | Loss 14.1278(10.0236) | Error 0.0859(0.0882) Steps 664(664.10) | Grad Norm 9.6551(8.1636) | Total Time 0.00(0.00)\n",
      "Iter 1628 | Time 64.4818(65.4905) | Bit/dim 3.6826(3.6990) | Xent 0.2014(0.2421) | Loss 8.8997(9.9898) | Error 0.0720(0.0877) Steps 658(663.92) | Grad Norm 4.4568(8.0524) | Total Time 0.00(0.00)\n",
      "Iter 1629 | Time 65.0991(65.4788) | Bit/dim 3.6987(3.6990) | Xent 0.2206(0.2414) | Loss 9.0555(9.9618) | Error 0.0785(0.0874) Steps 652(663.56) | Grad Norm 5.6424(7.9801) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 65.4104(65.4768) | Bit/dim 3.6890(3.6987) | Xent 0.2017(0.2402) | Loss 9.1800(9.9384) | Error 0.0716(0.0870) Steps 676(663.93) | Grad Norm 5.4424(7.9040) | Total Time 0.00(0.00)\n",
      "Iter 1631 | Time 63.6893(65.4231) | Bit/dim 3.6868(3.6983) | Xent 0.2115(0.2394) | Loss 9.0374(9.9113) | Error 0.0750(0.0866) Steps 670(664.11) | Grad Norm 5.7500(7.8394) | Total Time 0.00(0.00)\n",
      "Iter 1632 | Time 68.4550(65.5141) | Bit/dim 3.7036(3.6985) | Xent 0.1943(0.2380) | Loss 8.9800(9.8834) | Error 0.0716(0.0862) Steps 652(663.75) | Grad Norm 4.0259(7.7250) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0272 | Time 25.0684, Epoch Time 432.0486(441.6359), Bit/dim 3.7194(best: 3.7154), Xent 2.5045, Loss 4.9717, Error 0.4424(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1633 | Time 68.9159(65.6161) | Bit/dim 3.6926(3.6983) | Xent 0.2092(0.2371) | Loss 15.0197(10.0375) | Error 0.0735(0.0858) Steps 706(665.02) | Grad Norm 4.2413(7.6205) | Total Time 0.00(0.00)\n",
      "Iter 1634 | Time 69.4687(65.7317) | Bit/dim 3.6874(3.6980) | Xent 0.1985(0.2360) | Loss 9.1515(10.0109) | Error 0.0711(0.0853) Steps 664(664.99) | Grad Norm 6.2009(7.5779) | Total Time 0.00(0.00)\n",
      "Iter 1635 | Time 63.1526(65.6543) | Bit/dim 3.6938(3.6978) | Xent 0.2227(0.2356) | Loss 9.0752(9.9828) | Error 0.0804(0.0852) Steps 664(664.96) | Grad Norm 8.6595(7.6103) | Total Time 0.00(0.00)\n",
      "Iter 1636 | Time 63.1209(65.5783) | Bit/dim 3.6986(3.6979) | Xent 0.2328(0.2355) | Loss 9.2228(9.9600) | Error 0.0856(0.0852) Steps 664(664.93) | Grad Norm 9.7451(7.6744) | Total Time 0.00(0.00)\n",
      "Iter 1637 | Time 66.0247(65.5917) | Bit/dim 3.6943(3.6978) | Xent 0.2430(0.2357) | Loss 9.3125(9.9406) | Error 0.0930(0.0854) Steps 688(665.62) | Grad Norm 12.6839(7.8246) | Total Time 0.00(0.00)\n",
      "Iter 1638 | Time 67.0229(65.6347) | Bit/dim 3.7043(3.6979) | Xent 0.2158(0.2351) | Loss 9.1187(9.9160) | Error 0.0763(0.0852) Steps 664(665.57) | Grad Norm 7.1160(7.8034) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0273 | Time 25.0886, Epoch Time 441.3262(441.6266), Bit/dim 3.7192(best: 3.7154), Xent 2.4469, Loss 4.9426, Error 0.4413(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1639 | Time 67.2357(65.6827) | Bit/dim 3.6844(3.6975) | Xent 0.2092(0.2343) | Loss 14.3161(10.0480) | Error 0.0744(0.0848) Steps 676(665.89) | Grad Norm 8.2997(7.8183) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 69.0203(65.7828) | Bit/dim 3.6859(3.6972) | Xent 0.2162(0.2338) | Loss 9.3489(10.0270) | Error 0.0719(0.0844) Steps 682(666.37) | Grad Norm 6.0080(7.7640) | Total Time 0.00(0.00)\n",
      "Iter 1641 | Time 65.7418(65.7816) | Bit/dim 3.6910(3.6970) | Xent 0.2141(0.2332) | Loss 8.9839(9.9957) | Error 0.0756(0.0842) Steps 658(666.12) | Grad Norm 5.6759(7.7013) | Total Time 0.00(0.00)\n",
      "Iter 1642 | Time 67.1597(65.8229) | Bit/dim 3.6960(3.6970) | Xent 0.1839(0.2317) | Loss 9.2610(9.9737) | Error 0.0666(0.0837) Steps 664(666.05) | Grad Norm 4.0774(7.5926) | Total Time 0.00(0.00)\n",
      "Iter 1643 | Time 66.0641(65.8302) | Bit/dim 3.6993(3.6970) | Xent 0.2026(0.2309) | Loss 9.2395(9.9516) | Error 0.0717(0.0833) Steps 634(665.09) | Grad Norm 6.3796(7.5562) | Total Time 0.00(0.00)\n",
      "Iter 1644 | Time 66.6604(65.8551) | Bit/dim 3.6958(3.6970) | Xent 0.1875(0.2296) | Loss 9.0151(9.9235) | Error 0.0670(0.0828) Steps 676(665.42) | Grad Norm 3.8306(7.4445) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0274 | Time 24.5672, Epoch Time 444.9681(441.7268), Bit/dim 3.7143(best: 3.7154), Xent 2.5249, Loss 4.9767, Error 0.4415(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1645 | Time 63.6863(65.7900) | Bit/dim 3.6978(3.6970) | Xent 0.1884(0.2283) | Loss 14.3261(10.0556) | Error 0.0656(0.0823) Steps 688(666.10) | Grad Norm 4.2445(7.3485) | Total Time 0.00(0.00)\n",
      "Iter 1646 | Time 68.3850(65.8679) | Bit/dim 3.6893(3.6968) | Xent 0.1940(0.2273) | Loss 9.2064(10.0301) | Error 0.0709(0.0820) Steps 670(666.21) | Grad Norm 4.9738(7.2772) | Total Time 0.00(0.00)\n",
      "Iter 1647 | Time 66.0056(65.8720) | Bit/dim 3.7062(3.6971) | Xent 0.1850(0.2260) | Loss 8.8410(9.9945) | Error 0.0671(0.0815) Steps 658(665.97) | Grad Norm 3.7900(7.1726) | Total Time 0.00(0.00)\n",
      "Iter 1648 | Time 63.6359(65.8049) | Bit/dim 3.6901(3.6969) | Xent 0.2057(0.2254) | Loss 9.0280(9.9655) | Error 0.0747(0.0813) Steps 652(665.55) | Grad Norm 6.7208(7.1590) | Total Time 0.00(0.00)\n",
      "Iter 1649 | Time 64.1693(65.7558) | Bit/dim 3.6908(3.6967) | Xent 0.2028(0.2247) | Loss 9.1291(9.9404) | Error 0.0754(0.0811) Steps 634(664.60) | Grad Norm 8.0423(7.1855) | Total Time 0.00(0.00)\n",
      "Iter 1650 | Time 70.0205(65.8838) | Bit/dim 3.6810(3.6962) | Xent 0.2131(0.2244) | Loss 9.1292(9.9160) | Error 0.0764(0.0810) Steps 658(664.40) | Grad Norm 13.4473(7.3734) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0275 | Time 24.9894, Epoch Time 440.0484(441.6765), Bit/dim 3.7183(best: 3.7143), Xent 2.6080, Loss 5.0223, Error 0.4502(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1651 | Time 63.0914(65.8000) | Bit/dim 3.6958(3.6962) | Xent 0.2164(0.2241) | Loss 15.0575(10.0703) | Error 0.0785(0.0809) Steps 646(663.85) | Grad Norm 11.5186(7.4977) | Total Time 0.00(0.00)\n",
      "Iter 1652 | Time 65.3768(65.7873) | Bit/dim 3.6806(3.6957) | Xent 0.2076(0.2236) | Loss 9.0168(10.0387) | Error 0.0735(0.0807) Steps 652(663.50) | Grad Norm 6.6106(7.4711) | Total Time 0.00(0.00)\n",
      "Iter 1653 | Time 70.1761(65.9190) | Bit/dim 3.6863(3.6955) | Xent 0.1899(0.2226) | Loss 9.1479(10.0120) | Error 0.0650(0.0802) Steps 670(663.69) | Grad Norm 3.8091(7.3613) | Total Time 0.00(0.00)\n",
      "Iter 1654 | Time 64.2678(65.8694) | Bit/dim 3.6943(3.6954) | Xent 0.2076(0.2222) | Loss 9.1134(9.9850) | Error 0.0736(0.0800) Steps 676(664.06) | Grad Norm 5.7975(7.3144) | Total Time 0.00(0.00)\n",
      "Iter 1655 | Time 60.2902(65.7021) | Bit/dim 3.7012(3.6956) | Xent 0.2052(0.2217) | Loss 9.1413(9.9597) | Error 0.0750(0.0799) Steps 646(663.52) | Grad Norm 7.8701(7.3310) | Total Time 0.00(0.00)\n",
      "Iter 1656 | Time 67.5185(65.7566) | Bit/dim 3.6942(3.6956) | Xent 0.1936(0.2208) | Loss 9.2165(9.9374) | Error 0.0694(0.0796) Steps 676(663.89) | Grad Norm 5.9396(7.2893) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0276 | Time 24.8207, Epoch Time 434.8269(441.4710), Bit/dim 3.7153(best: 3.7143), Xent 2.5486, Loss 4.9896, Error 0.4464(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1657 | Time 62.6419(65.6631) | Bit/dim 3.6888(3.6954) | Xent 0.1856(0.2198) | Loss 13.7678(10.0523) | Error 0.0641(0.0791) Steps 658(663.72) | Grad Norm 2.9405(7.1588) | Total Time 0.00(0.00)\n",
      "Iter 1658 | Time 66.7366(65.6953) | Bit/dim 3.6974(3.6954) | Xent 0.1961(0.2191) | Loss 9.2135(10.0271) | Error 0.0699(0.0788) Steps 646(663.19) | Grad Norm 7.1994(7.1600) | Total Time 0.00(0.00)\n",
      "Iter 1659 | Time 66.4406(65.7177) | Bit/dim 3.6953(3.6954) | Xent 0.1816(0.2179) | Loss 9.1221(10.0000) | Error 0.0661(0.0784) Steps 682(663.75) | Grad Norm 3.4908(7.0500) | Total Time 0.00(0.00)\n",
      "Iter 1660 | Time 72.3352(65.9162) | Bit/dim 3.6946(3.6954) | Xent 0.1804(0.2168) | Loss 9.0898(9.9727) | Error 0.0613(0.0779) Steps 700(664.84) | Grad Norm 4.9263(6.9863) | Total Time 0.00(0.00)\n",
      "Iter 1661 | Time 71.0559(66.0704) | Bit/dim 3.6824(3.6950) | Xent 0.2008(0.2163) | Loss 9.0395(9.9447) | Error 0.0700(0.0777) Steps 640(664.09) | Grad Norm 5.1101(6.9300) | Total Time 0.00(0.00)\n",
      "Iter 1662 | Time 71.5468(66.2347) | Bit/dim 3.6992(3.6951) | Xent 0.1789(0.2152) | Loss 9.1776(9.9217) | Error 0.0637(0.0773) Steps 670(664.27) | Grad Norm 4.0312(6.8430) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0277 | Time 24.4910, Epoch Time 453.5714(441.8340), Bit/dim 3.7182(best: 3.7143), Xent 2.5977, Loss 5.0171, Error 0.4486(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1663 | Time 64.8085(66.1919) | Bit/dim 3.6934(3.6951) | Xent 0.1874(0.2144) | Loss 13.6608(10.0338) | Error 0.0670(0.0770) Steps 670(664.44) | Grad Norm 4.2306(6.7646) | Total Time 0.00(0.00)\n",
      "Iter 1664 | Time 66.4640(66.2001) | Bit/dim 3.6968(3.6951) | Xent 0.1886(0.2136) | Loss 9.0233(10.0035) | Error 0.0689(0.0767) Steps 652(664.07) | Grad Norm 7.2314(6.7786) | Total Time 0.00(0.00)\n",
      "Iter 1665 | Time 63.6681(66.1241) | Bit/dim 3.7103(3.6956) | Xent 0.1860(0.2128) | Loss 9.0945(9.9763) | Error 0.0677(0.0764) Steps 670(664.25) | Grad Norm 4.8600(6.7211) | Total Time 0.00(0.00)\n",
      "Iter 1666 | Time 65.1162(66.0939) | Bit/dim 3.6991(3.6957) | Xent 0.1926(0.2122) | Loss 9.2429(9.9543) | Error 0.0655(0.0761) Steps 688(664.96) | Grad Norm 3.7221(6.6311) | Total Time 0.00(0.00)\n",
      "Iter 1667 | Time 69.4760(66.1953) | Bit/dim 3.6757(3.6951) | Xent 0.1822(0.2113) | Loss 8.8162(9.9201) | Error 0.0643(0.0758) Steps 652(664.57) | Grad Norm 3.1387(6.5263) | Total Time 0.00(0.00)\n",
      "Iter 1668 | Time 71.5304(66.3554) | Bit/dim 3.6833(3.6947) | Xent 0.1770(0.2102) | Loss 9.0805(9.8949) | Error 0.0609(0.0753) Steps 670(664.73) | Grad Norm 3.8230(6.4452) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0278 | Time 24.3915, Epoch Time 443.8393(441.8942), Bit/dim 3.7166(best: 3.7143), Xent 2.5851, Loss 5.0091, Error 0.4474(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1669 | Time 61.7338(66.2167) | Bit/dim 3.6985(3.6948) | Xent 0.1900(0.2096) | Loss 13.7784(10.0114) | Error 0.0676(0.0751) Steps 634(663.81) | Grad Norm 3.3871(6.3535) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 63.4225(66.1329) | Bit/dim 3.7039(3.6951) | Xent 0.1824(0.2088) | Loss 9.2474(9.9885) | Error 0.0660(0.0748) Steps 664(663.82) | Grad Norm 5.8455(6.3383) | Total Time 0.00(0.00)\n",
      "Iter 1671 | Time 59.3714(65.9301) | Bit/dim 3.7028(3.6953) | Xent 0.1835(0.2081) | Loss 8.9661(9.9578) | Error 0.0644(0.0745) Steps 640(663.10) | Grad Norm 5.4374(6.3112) | Total Time 0.00(0.00)\n",
      "Iter 1672 | Time 66.4270(65.9450) | Bit/dim 3.6920(3.6953) | Xent 0.1838(0.2073) | Loss 9.2553(9.9368) | Error 0.0650(0.0742) Steps 640(662.41) | Grad Norm 4.5264(6.2577) | Total Time 0.00(0.00)\n",
      "Iter 1673 | Time 63.1025(65.8597) | Bit/dim 3.6872(3.6950) | Xent 0.2025(0.2072) | Loss 8.9811(9.9081) | Error 0.0703(0.0741) Steps 664(662.46) | Grad Norm 10.7956(6.3938) | Total Time 0.00(0.00)\n",
      "Iter 1674 | Time 63.5557(65.7906) | Bit/dim 3.6797(3.6945) | Xent 0.1945(0.2068) | Loss 9.0044(9.8810) | Error 0.0719(0.0740) Steps 670(662.68) | Grad Norm 8.2624(6.4499) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0279 | Time 24.3987, Epoch Time 421.0536(441.2690), Bit/dim 3.7156(best: 3.7143), Xent 2.6342, Loss 5.0327, Error 0.4443(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1675 | Time 63.7711(65.7300) | Bit/dim 3.6978(3.6946) | Xent 0.1766(0.2059) | Loss 14.3132(10.0139) | Error 0.0639(0.0737) Steps 676(663.08) | Grad Norm 6.2445(6.4437) | Total Time 0.00(0.00)\n",
      "Iter 1676 | Time 66.5672(65.7551) | Bit/dim 3.6766(3.6941) | Xent 0.1981(0.2057) | Loss 9.1397(9.9877) | Error 0.0701(0.0736) Steps 676(663.47) | Grad Norm 8.7215(6.5121) | Total Time 0.00(0.00)\n",
      "Iter 1677 | Time 66.6668(65.7825) | Bit/dim 3.6977(3.6942) | Xent 0.2435(0.2068) | Loss 9.1514(9.9626) | Error 0.0885(0.0741) Steps 676(663.85) | Grad Norm 12.7311(6.6986) | Total Time 0.00(0.00)\n",
      "Iter 1678 | Time 70.4446(65.9223) | Bit/dim 3.6921(3.6941) | Xent 0.3045(0.2097) | Loss 9.2315(9.9407) | Error 0.1099(0.0751) Steps 688(664.57) | Grad Norm 16.8307(7.0026) | Total Time 0.00(0.00)\n",
      "Iter 1679 | Time 67.3198(65.9643) | Bit/dim 3.6980(3.6943) | Xent 0.3425(0.2137) | Loss 9.1918(9.9182) | Error 0.1192(0.0765) Steps 664(664.55) | Grad Norm 16.3772(7.2838) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 70.2119(66.0917) | Bit/dim 3.7143(3.6949) | Xent 0.2658(0.2153) | Loss 9.1549(9.8953) | Error 0.0982(0.0771) Steps 688(665.26) | Grad Norm 12.9227(7.4530) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0280 | Time 24.3576, Epoch Time 447.9370(441.4690), Bit/dim 3.7156(best: 3.7143), Xent 2.3842, Loss 4.9077, Error 0.4422(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1681 | Time 63.5170(66.0144) | Bit/dim 3.6924(3.6948) | Xent 0.2557(0.2165) | Loss 13.9068(10.0157) | Error 0.0970(0.0777) Steps 664(665.22) | Grad Norm 15.0893(7.6821) | Total Time 0.00(0.00)\n",
      "Iter 1682 | Time 67.7486(66.0665) | Bit/dim 3.7094(3.6952) | Xent 0.2745(0.2182) | Loss 9.1970(9.9911) | Error 0.1040(0.0785) Steps 664(665.18) | Grad Norm 10.7472(7.7740) | Total Time 0.00(0.00)\n",
      "Iter 1683 | Time 69.6936(66.1753) | Bit/dim 3.6862(3.6950) | Xent 0.2219(0.2183) | Loss 9.2194(9.9680) | Error 0.0797(0.0785) Steps 670(665.33) | Grad Norm 11.1942(7.8766) | Total Time 0.00(0.00)\n",
      "Iter 1684 | Time 66.3613(66.1809) | Bit/dim 3.6989(3.6951) | Xent 0.2954(0.2206) | Loss 9.2897(9.9476) | Error 0.1070(0.0794) Steps 658(665.11) | Grad Norm 16.1176(8.1239) | Total Time 0.00(0.00)\n",
      "Iter 1685 | Time 66.0678(66.1775) | Bit/dim 3.6941(3.6950) | Xent 0.2384(0.2212) | Loss 9.1746(9.9244) | Error 0.0805(0.0794) Steps 664(665.07) | Grad Norm 5.5703(8.0473) | Total Time 0.00(0.00)\n",
      "Iter 1686 | Time 63.7772(66.1055) | Bit/dim 3.7058(3.6954) | Xent 0.2445(0.2219) | Loss 9.1284(9.9005) | Error 0.0876(0.0797) Steps 670(665.22) | Grad Norm 8.7104(8.0672) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0281 | Time 24.8304, Epoch Time 440.4051(441.4371), Bit/dim 3.7150(best: 3.7143), Xent 2.4495, Loss 4.9397, Error 0.4452(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1687 | Time 66.3489(66.1128) | Bit/dim 3.6860(3.6951) | Xent 0.2207(0.2218) | Loss 14.8181(10.0481) | Error 0.0754(0.0795) Steps 652(664.83) | Grad Norm 5.1322(7.9791) | Total Time 0.00(0.00)\n",
      "Iter 1688 | Time 67.8039(66.1635) | Bit/dim 3.6939(3.6951) | Xent 0.2381(0.2223) | Loss 9.1706(10.0217) | Error 0.0850(0.0797) Steps 664(664.80) | Grad Norm 9.1057(8.0129) | Total Time 0.00(0.00)\n",
      "Iter 1689 | Time 65.7004(66.1496) | Bit/dim 3.6977(3.6951) | Xent 0.2103(0.2220) | Loss 8.9303(9.9890) | Error 0.0781(0.0797) Steps 664(664.78) | Grad Norm 7.9472(8.0109) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 66.1984(66.1511) | Bit/dim 3.7000(3.6953) | Xent 0.1940(0.2211) | Loss 9.1713(9.9645) | Error 0.0700(0.0794) Steps 676(665.11) | Grad Norm 8.0554(8.0123) | Total Time 0.00(0.00)\n",
      "Iter 1691 | Time 65.4882(66.1312) | Bit/dim 3.7061(3.6956) | Xent 0.2145(0.2209) | Loss 9.2017(9.9416) | Error 0.0784(0.0793) Steps 688(665.80) | Grad Norm 7.1507(7.9864) | Total Time 0.00(0.00)\n",
      "Iter 1692 | Time 64.1657(66.0722) | Bit/dim 3.6817(3.6952) | Xent 0.2066(0.2205) | Loss 8.7695(9.9064) | Error 0.0700(0.0791) Steps 664(665.75) | Grad Norm 7.1232(7.9605) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0282 | Time 24.5355, Epoch Time 438.9552(441.3626), Bit/dim 3.7176(best: 3.7143), Xent 2.6439, Loss 5.0395, Error 0.4488(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1693 | Time 63.3865(65.9916) | Bit/dim 3.6984(3.6953) | Xent 0.1798(0.2193) | Loss 13.8579(10.0250) | Error 0.0637(0.0786) Steps 670(665.87) | Grad Norm 4.3567(7.8524) | Total Time 0.00(0.00)\n",
      "Iter 1694 | Time 64.3013(65.9409) | Bit/dim 3.6921(3.6952) | Xent 0.1992(0.2187) | Loss 9.0971(9.9971) | Error 0.0730(0.0784) Steps 670(666.00) | Grad Norm 4.3260(7.7466) | Total Time 0.00(0.00)\n",
      "Iter 1695 | Time 65.0349(65.9138) | Bit/dim 3.6928(3.6951) | Xent 0.2033(0.2182) | Loss 9.1975(9.9731) | Error 0.0731(0.0783) Steps 652(665.58) | Grad Norm 6.0904(7.6969) | Total Time 0.00(0.00)\n",
      "Iter 1696 | Time 63.0804(65.8288) | Bit/dim 3.6899(3.6950) | Xent 0.1992(0.2176) | Loss 9.0933(9.9467) | Error 0.0711(0.0781) Steps 652(665.17) | Grad Norm 6.8005(7.6700) | Total Time 0.00(0.00)\n",
      "Iter 1697 | Time 63.1481(65.7483) | Bit/dim 3.6948(3.6950) | Xent 0.1998(0.2171) | Loss 9.0514(9.9199) | Error 0.0706(0.0778) Steps 670(665.31) | Grad Norm 6.8092(7.6442) | Total Time 0.00(0.00)\n",
      "Iter 1698 | Time 63.2353(65.6729) | Bit/dim 3.6932(3.6949) | Xent 0.1707(0.2157) | Loss 9.1624(9.8972) | Error 0.0595(0.0773) Steps 646(664.74) | Grad Norm 5.5073(7.5801) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0283 | Time 24.9696, Epoch Time 426.0030(440.9018), Bit/dim 3.7150(best: 3.7143), Xent 2.5283, Loss 4.9791, Error 0.4444(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1699 | Time 63.8656(65.6187) | Bit/dim 3.6863(3.6946) | Xent 0.1931(0.2150) | Loss 13.9235(10.0180) | Error 0.0671(0.0770) Steps 664(664.71) | Grad Norm 5.3684(7.5138) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 65.9769(65.6295) | Bit/dim 3.6960(3.6947) | Xent 0.1711(0.2137) | Loss 8.9167(9.9849) | Error 0.0620(0.0765) Steps 694(665.59) | Grad Norm 3.0074(7.3786) | Total Time 0.00(0.00)\n",
      "Iter 1701 | Time 63.5917(65.5683) | Bit/dim 3.6953(3.6947) | Xent 0.1919(0.2131) | Loss 9.0875(9.9580) | Error 0.0689(0.0763) Steps 652(665.18) | Grad Norm 6.5505(7.3537) | Total Time 0.00(0.00)\n",
      "Iter 1702 | Time 64.4450(65.5346) | Bit/dim 3.7009(3.6949) | Xent 0.1777(0.2120) | Loss 9.1005(9.9323) | Error 0.0626(0.0759) Steps 658(664.97) | Grad Norm 8.1041(7.3762) | Total Time 0.00(0.00)\n",
      "Iter 1703 | Time 66.5312(65.5645) | Bit/dim 3.6875(3.6947) | Xent 0.1786(0.2110) | Loss 9.1327(9.9083) | Error 0.0611(0.0754) Steps 646(664.40) | Grad Norm 4.5698(7.2920) | Total Time 0.00(0.00)\n",
      "Iter 1704 | Time 67.0786(65.6099) | Bit/dim 3.6851(3.6944) | Xent 0.1784(0.2100) | Loss 9.1579(9.8858) | Error 0.0624(0.0751) Steps 658(664.21) | Grad Norm 5.5353(7.2393) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0284 | Time 24.5047, Epoch Time 434.6654(440.7147), Bit/dim 3.7184(best: 3.7143), Xent 2.6626, Loss 5.0497, Error 0.4442(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1705 | Time 61.6474(65.4911) | Bit/dim 3.6975(3.6945) | Xent 0.1805(0.2091) | Loss 14.2442(10.0165) | Error 0.0621(0.0747) Steps 652(663.84) | Grad Norm 5.7148(7.1936) | Total Time 0.00(0.00)\n",
      "Iter 1706 | Time 65.9643(65.5053) | Bit/dim 3.6836(3.6941) | Xent 0.1703(0.2080) | Loss 9.1247(9.9898) | Error 0.0587(0.0742) Steps 658(663.67) | Grad Norm 3.2831(7.0763) | Total Time 0.00(0.00)\n",
      "Iter 1707 | Time 60.9720(65.3693) | Bit/dim 3.6930(3.6941) | Xent 0.1850(0.2073) | Loss 9.0391(9.9612) | Error 0.0650(0.0739) Steps 670(663.86) | Grad Norm 5.0678(7.0160) | Total Time 0.00(0.00)\n",
      "Iter 1708 | Time 67.9147(65.4456) | Bit/dim 3.6822(3.6938) | Xent 0.1781(0.2064) | Loss 9.0181(9.9329) | Error 0.0659(0.0737) Steps 664(663.86) | Grad Norm 8.1211(7.0492) | Total Time 0.00(0.00)\n",
      "Iter 1709 | Time 63.7040(65.3934) | Bit/dim 3.6897(3.6936) | Xent 0.1836(0.2057) | Loss 9.2248(9.9117) | Error 0.0656(0.0734) Steps 676(664.22) | Grad Norm 11.1127(7.1711) | Total Time 0.00(0.00)\n",
      "Iter 1710 | Time 66.4919(65.4263) | Bit/dim 3.7027(3.6939) | Xent 0.1733(0.2048) | Loss 9.1569(9.8891) | Error 0.0605(0.0730) Steps 664(664.22) | Grad Norm 10.7229(7.2776) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0285 | Time 24.7232, Epoch Time 429.5279(440.3791), Bit/dim 3.7150(best: 3.7143), Xent 2.6773, Loss 5.0537, Error 0.4483(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1711 | Time 63.6609(65.3734) | Bit/dim 3.6935(3.6939) | Xent 0.1821(0.2041) | Loss 13.6543(10.0020) | Error 0.0679(0.0729) Steps 646(663.67) | Grad Norm 6.4207(7.2519) | Total Time 0.00(0.00)\n",
      "Iter 1712 | Time 63.4244(65.3149) | Bit/dim 3.6998(3.6941) | Xent 0.1658(0.2029) | Loss 9.1435(9.9763) | Error 0.0594(0.0725) Steps 670(663.86) | Grad Norm 3.8935(7.1512) | Total Time 0.00(0.00)\n",
      "Iter 1713 | Time 66.2678(65.3435) | Bit/dim 3.6947(3.6941) | Xent 0.1737(0.2020) | Loss 9.1469(9.9514) | Error 0.0626(0.0722) Steps 670(664.05) | Grad Norm 6.9688(7.1457) | Total Time 0.00(0.00)\n",
      "Iter 1714 | Time 67.3243(65.4029) | Bit/dim 3.6851(3.6938) | Xent 0.2343(0.2030) | Loss 9.2249(9.9296) | Error 0.0896(0.0727) Steps 676(664.40) | Grad Norm 15.4293(7.3942) | Total Time 0.00(0.00)\n",
      "Iter 1715 | Time 61.5824(65.2883) | Bit/dim 3.7029(3.6941) | Xent 0.2736(0.2051) | Loss 9.1939(9.9075) | Error 0.0995(0.0735) Steps 670(664.57) | Grad Norm 23.8747(7.8886) | Total Time 0.00(0.00)\n",
      "Iter 1716 | Time 66.4703(65.3238) | Bit/dim 3.6800(3.6937) | Xent 0.2203(0.2056) | Loss 9.0744(9.8825) | Error 0.0795(0.0737) Steps 664(664.55) | Grad Norm 12.9037(8.0391) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0286 | Time 24.7999, Epoch Time 432.5314(440.1437), Bit/dim 3.7133(best: 3.7143), Xent 2.4920, Loss 4.9592, Error 0.4446(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1717 | Time 67.6526(65.3936) | Bit/dim 3.6938(3.6937) | Xent 0.1847(0.2050) | Loss 14.2647(10.0140) | Error 0.0650(0.0734) Steps 676(664.90) | Grad Norm 6.2488(7.9854) | Total Time 0.00(0.00)\n",
      "Iter 1718 | Time 65.1734(65.3870) | Bit/dim 3.6971(3.6938) | Xent 0.2124(0.2052) | Loss 9.0385(9.9847) | Error 0.0755(0.0735) Steps 658(664.69) | Grad Norm 9.8782(8.0422) | Total Time 0.00(0.00)\n",
      "Iter 1719 | Time 62.9661(65.3144) | Bit/dim 3.6750(3.6932) | Xent 0.1869(0.2046) | Loss 9.0823(9.9576) | Error 0.0685(0.0733) Steps 664(664.67) | Grad Norm 6.2819(7.9893) | Total Time 0.00(0.00)\n",
      "Iter 1720 | Time 65.3406(65.3152) | Bit/dim 3.6867(3.6930) | Xent 0.2060(0.2047) | Loss 8.9379(9.9271) | Error 0.0753(0.0734) Steps 682(665.19) | Grad Norm 7.0971(7.9626) | Total Time 0.00(0.00)\n",
      "Iter 1721 | Time 65.1686(65.3108) | Bit/dim 3.6940(3.6930) | Xent 0.1825(0.2040) | Loss 9.1558(9.9039) | Error 0.0619(0.0731) Steps 670(665.33) | Grad Norm 8.3368(7.9738) | Total Time 0.00(0.00)\n",
      "Iter 1722 | Time 67.0984(65.3644) | Bit/dim 3.7002(3.6933) | Xent 0.1847(0.2034) | Loss 9.1523(9.8814) | Error 0.0626(0.0727) Steps 676(665.65) | Grad Norm 5.6724(7.9048) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0287 | Time 24.3981, Epoch Time 436.6787(440.0398), Bit/dim 3.7184(best: 3.7133), Xent 2.5718, Loss 5.0043, Error 0.4475(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1723 | Time 61.0700(65.2356) | Bit/dim 3.6886(3.6931) | Xent 0.1791(0.2027) | Loss 14.4328(10.0179) | Error 0.0623(0.0724) Steps 640(664.88) | Grad Norm 12.2283(8.0345) | Total Time 0.00(0.00)\n",
      "Iter 1724 | Time 63.4846(65.1830) | Bit/dim 3.6990(3.6933) | Xent 0.1902(0.2023) | Loss 9.1991(9.9933) | Error 0.0659(0.0722) Steps 634(663.96) | Grad Norm 8.8578(8.0592) | Total Time 0.00(0.00)\n",
      "Iter 1725 | Time 65.0470(65.1790) | Bit/dim 3.7062(3.6937) | Xent 0.1604(0.2011) | Loss 9.0217(9.9642) | Error 0.0573(0.0718) Steps 640(663.24) | Grad Norm 6.1993(8.0034) | Total Time 0.00(0.00)\n",
      "Iter 1726 | Time 66.1822(65.2091) | Bit/dim 3.6874(3.6935) | Xent 0.1922(0.2008) | Loss 9.0937(9.9381) | Error 0.0700(0.0717) Steps 688(663.98) | Grad Norm 8.8952(8.0301) | Total Time 0.00(0.00)\n",
      "Iter 1727 | Time 68.3197(65.3024) | Bit/dim 3.6842(3.6932) | Xent 0.1791(0.2002) | Loss 9.1351(9.9140) | Error 0.0646(0.0715) Steps 688(664.70) | Grad Norm 5.4123(7.9516) | Total Time 0.00(0.00)\n",
      "Iter 1728 | Time 65.9613(65.3221) | Bit/dim 3.6921(3.6932) | Xent 0.1659(0.1991) | Loss 9.2583(9.8943) | Error 0.0566(0.0711) Steps 682(665.22) | Grad Norm 4.7314(7.8550) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0288 | Time 24.5925, Epoch Time 433.3218(439.8382), Bit/dim 3.7173(best: 3.7133), Xent 2.6825, Loss 5.0585, Error 0.4424(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1729 | Time 62.6968(65.2434) | Bit/dim 3.6909(3.6931) | Xent 0.1714(0.1983) | Loss 14.2353(10.0246) | Error 0.0610(0.0708) Steps 652(664.83) | Grad Norm 4.8628(7.7652) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 69.7865(65.3797) | Bit/dim 3.6905(3.6930) | Xent 0.1743(0.1976) | Loss 9.1880(9.9995) | Error 0.0609(0.0705) Steps 682(665.34) | Grad Norm 6.1699(7.7174) | Total Time 0.00(0.00)\n",
      "Iter 1731 | Time 64.9880(65.3679) | Bit/dim 3.7015(3.6933) | Xent 0.1447(0.1960) | Loss 9.0769(9.9718) | Error 0.0515(0.0699) Steps 640(664.58) | Grad Norm 3.8388(7.6010) | Total Time 0.00(0.00)\n",
      "Iter 1732 | Time 75.2255(65.6637) | Bit/dim 3.6969(3.6934) | Xent 0.1577(0.1948) | Loss 9.1776(9.9480) | Error 0.0539(0.0694) Steps 700(665.64) | Grad Norm 4.1228(7.4967) | Total Time 0.00(0.00)\n",
      "Iter 1733 | Time 63.9984(65.6137) | Bit/dim 3.6875(3.6932) | Xent 0.1756(0.1943) | Loss 9.0242(9.9202) | Error 0.0604(0.0691) Steps 640(664.87) | Grad Norm 7.1791(7.4871) | Total Time 0.00(0.00)\n",
      "Iter 1734 | Time 65.8062(65.6195) | Bit/dim 3.6727(3.6926) | Xent 0.1725(0.1936) | Loss 8.9359(9.8907) | Error 0.0617(0.0689) Steps 664(664.85) | Grad Norm 5.5256(7.4283) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0289 | Time 25.1621, Epoch Time 446.8290(440.0479), Bit/dim 3.7122(best: 3.7133), Xent 2.6974, Loss 5.0609, Error 0.4505(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1735 | Time 62.0099(65.5112) | Bit/dim 3.6907(3.6926) | Xent 0.1746(0.1930) | Loss 13.8331(10.0090) | Error 0.0615(0.0687) Steps 658(664.64) | Grad Norm 4.6327(7.3444) | Total Time 0.00(0.00)\n",
      "Iter 1736 | Time 61.0238(65.3766) | Bit/dim 3.6860(3.6924) | Xent 0.1714(0.1924) | Loss 9.0545(9.9803) | Error 0.0556(0.0683) Steps 670(664.80) | Grad Norm 3.8668(7.2401) | Total Time 0.00(0.00)\n",
      "Iter 1737 | Time 64.0365(65.3364) | Bit/dim 3.6874(3.6922) | Xent 0.1586(0.1914) | Loss 8.8190(9.9455) | Error 0.0541(0.0679) Steps 688(665.50) | Grad Norm 6.7359(7.2250) | Total Time 0.00(0.00)\n",
      "Iter 1738 | Time 68.1068(65.4195) | Bit/dim 3.6866(3.6920) | Xent 0.1628(0.1905) | Loss 9.1412(9.9214) | Error 0.0585(0.0676) Steps 646(664.91) | Grad Norm 4.5599(7.1450) | Total Time 0.00(0.00)\n",
      "Iter 1739 | Time 63.6255(65.3657) | Bit/dim 3.6916(3.6920) | Xent 0.1452(0.1892) | Loss 8.8976(9.8907) | Error 0.0526(0.0672) Steps 670(665.07) | Grad Norm 2.9413(7.0189) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 63.5133(65.3101) | Bit/dim 3.6892(3.6919) | Xent 0.1581(0.1882) | Loss 8.7549(9.8566) | Error 0.0550(0.0668) Steps 658(664.85) | Grad Norm 4.5160(6.9438) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0290 | Time 24.3817, Epoch Time 425.8503(439.6220), Bit/dim 3.7106(best: 3.7122), Xent 2.7605, Loss 5.0909, Error 0.4547(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1741 | Time 65.7720(65.3239) | Bit/dim 3.6884(3.6918) | Xent 0.1521(0.1871) | Loss 14.0278(9.9817) | Error 0.0531(0.0664) Steps 670(665.01) | Grad Norm 5.6376(6.9046) | Total Time 0.00(0.00)\n",
      "Iter 1742 | Time 63.5833(65.2717) | Bit/dim 3.6793(3.6915) | Xent 0.1570(0.1862) | Loss 8.8595(9.9481) | Error 0.0559(0.0661) Steps 664(664.98) | Grad Norm 6.6301(6.8964) | Total Time 0.00(0.00)\n",
      "Iter 1743 | Time 70.4244(65.4263) | Bit/dim 3.6911(3.6914) | Xent 0.1905(0.1864) | Loss 9.2155(9.9261) | Error 0.0710(0.0662) Steps 652(664.59) | Grad Norm 11.0805(7.0219) | Total Time 0.00(0.00)\n",
      "Iter 1744 | Time 67.8648(65.4995) | Bit/dim 3.6918(3.6915) | Xent 0.2327(0.1878) | Loss 9.2370(9.9054) | Error 0.0829(0.0667) Steps 658(664.39) | Grad Norm 18.0226(7.3519) | Total Time 0.00(0.00)\n",
      "Iter 1745 | Time 61.0925(65.3672) | Bit/dim 3.7090(3.6920) | Xent 0.2766(0.1904) | Loss 8.9459(9.8766) | Error 0.0989(0.0677) Steps 664(664.38) | Grad Norm 21.3899(7.7731) | Total Time 0.00(0.00)\n",
      "Iter 1746 | Time 65.1565(65.3609) | Bit/dim 3.6935(3.6920) | Xent 0.2606(0.1925) | Loss 9.0977(9.8533) | Error 0.0891(0.0683) Steps 622(663.11) | Grad Norm 18.5701(8.0970) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0291 | Time 25.1733, Epoch Time 438.2321(439.5803), Bit/dim 3.7138(best: 3.7106), Xent 2.5922, Loss 5.0099, Error 0.4447(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1747 | Time 64.1680(65.3251) | Bit/dim 3.6851(3.6918) | Xent 0.2123(0.1931) | Loss 13.7114(9.9690) | Error 0.0765(0.0686) Steps 682(663.67) | Grad Norm 14.0976(8.2770) | Total Time 0.00(0.00)\n",
      "Iter 1748 | Time 62.7203(65.2470) | Bit/dim 3.6912(3.6918) | Xent 0.1953(0.1932) | Loss 9.1125(9.9433) | Error 0.0675(0.0685) Steps 670(663.86) | Grad Norm 7.1073(8.2419) | Total Time 0.00(0.00)\n",
      "Iter 1749 | Time 60.9551(65.1182) | Bit/dim 3.7003(3.6921) | Xent 0.1808(0.1928) | Loss 9.1436(9.9193) | Error 0.0635(0.0684) Steps 664(663.87) | Grad Norm 7.5038(8.2198) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 60.4748(64.9789) | Bit/dim 3.6925(3.6921) | Xent 0.1901(0.1927) | Loss 9.0097(9.8920) | Error 0.0713(0.0685) Steps 652(663.51) | Grad Norm 6.1365(8.1573) | Total Time 0.00(0.00)\n",
      "Iter 1751 | Time 67.5054(65.0547) | Bit/dim 3.6793(3.6917) | Xent 0.1893(0.1926) | Loss 8.8346(9.8603) | Error 0.0633(0.0683) Steps 652(663.17) | Grad Norm 4.9008(8.0596) | Total Time 0.00(0.00)\n",
      "Iter 1752 | Time 61.3276(64.9429) | Bit/dim 3.7015(3.6920) | Xent 0.1897(0.1925) | Loss 9.1712(9.8396) | Error 0.0675(0.0683) Steps 658(663.01) | Grad Norm 6.9003(8.0248) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0292 | Time 24.7787, Epoch Time 420.4637(439.0068), Bit/dim 3.7134(best: 3.7106), Xent 2.5975, Loss 5.0121, Error 0.4464(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1753 | Time 63.3819(64.8961) | Bit/dim 3.6916(3.6920) | Xent 0.1700(0.1919) | Loss 14.0054(9.9646) | Error 0.0604(0.0681) Steps 658(662.86) | Grad Norm 8.4393(8.0372) | Total Time 0.00(0.00)\n",
      "Iter 1754 | Time 67.6972(64.9801) | Bit/dim 3.6871(3.6918) | Xent 0.1682(0.1912) | Loss 9.0970(9.9386) | Error 0.0579(0.0677) Steps 688(663.62) | Grad Norm 7.5032(8.0212) | Total Time 0.00(0.00)\n",
      "Iter 1755 | Time 66.5797(65.0281) | Bit/dim 3.6948(3.6919) | Xent 0.1654(0.1904) | Loss 8.9982(9.9104) | Error 0.0571(0.0674) Steps 664(663.63) | Grad Norm 4.8756(7.9268) | Total Time 0.00(0.00)\n",
      "Iter 1756 | Time 65.0024(65.0273) | Bit/dim 3.6965(3.6921) | Xent 0.1774(0.1900) | Loss 9.0352(9.8841) | Error 0.0604(0.0672) Steps 682(664.18) | Grad Norm 5.5092(7.8543) | Total Time 0.00(0.00)\n",
      "Iter 1757 | Time 67.6083(65.1048) | Bit/dim 3.6846(3.6918) | Xent 0.1539(0.1889) | Loss 8.9423(9.8559) | Error 0.0540(0.0668) Steps 646(663.63) | Grad Norm 4.7019(7.7597) | Total Time 0.00(0.00)\n",
      "Iter 1758 | Time 68.7902(65.2153) | Bit/dim 3.6830(3.6916) | Xent 0.1560(0.1879) | Loss 8.8700(9.8263) | Error 0.0553(0.0665) Steps 670(663.82) | Grad Norm 5.7631(7.6998) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0293 | Time 24.2620, Epoch Time 441.4307(439.0795), Bit/dim 3.7206(best: 3.7106), Xent 2.9144, Loss 5.1778, Error 0.4562(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1759 | Time 66.1541(65.2435) | Bit/dim 3.6875(3.6914) | Xent 0.1591(0.1871) | Loss 13.4945(9.9363) | Error 0.0530(0.0661) Steps 676(664.19) | Grad Norm 5.4473(7.6323) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 65.5775(65.2535) | Bit/dim 3.6893(3.6914) | Xent 0.1425(0.1857) | Loss 8.7267(9.9000) | Error 0.0515(0.0656) Steps 658(664.00) | Grad Norm 4.1830(7.5288) | Total Time 0.00(0.00)\n",
      "Iter 1761 | Time 61.5087(65.1412) | Bit/dim 3.6819(3.6911) | Xent 0.1612(0.1850) | Loss 9.1030(9.8761) | Error 0.0546(0.0653) Steps 658(663.82) | Grad Norm 5.9739(7.4821) | Total Time 0.00(0.00)\n",
      "Iter 1762 | Time 61.9933(65.0467) | Bit/dim 3.6923(3.6911) | Xent 0.1549(0.1841) | Loss 9.1593(9.8546) | Error 0.0505(0.0649) Steps 658(663.65) | Grad Norm 6.8751(7.4639) | Total Time 0.00(0.00)\n",
      "Iter 1763 | Time 62.8377(64.9805) | Bit/dim 3.6896(3.6911) | Xent 0.1604(0.1834) | Loss 9.1067(9.8322) | Error 0.0553(0.0646) Steps 658(663.48) | Grad Norm 5.8098(7.4143) | Total Time 0.00(0.00)\n",
      "Iter 1764 | Time 66.8907(65.0378) | Bit/dim 3.6887(3.6910) | Xent 0.1586(0.1826) | Loss 9.0694(9.8093) | Error 0.0544(0.0643) Steps 652(663.14) | Grad Norm 6.1649(7.3768) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0294 | Time 24.7631, Epoch Time 428.9550(438.7758), Bit/dim 3.7081(best: 3.7106), Xent 2.7192, Loss 5.0677, Error 0.4525(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1765 | Time 64.5289(65.0225) | Bit/dim 3.6873(3.6909) | Xent 0.1569(0.1819) | Loss 13.3505(9.9155) | Error 0.0545(0.0640) Steps 652(662.80) | Grad Norm 5.9306(7.3334) | Total Time 0.00(0.00)\n",
      "Iter 1766 | Time 60.0978(64.8748) | Bit/dim 3.6890(3.6908) | Xent 0.1482(0.1808) | Loss 8.9102(9.8854) | Error 0.0521(0.0636) Steps 676(663.20) | Grad Norm 4.3460(7.2438) | Total Time 0.00(0.00)\n",
      "Iter 1767 | Time 58.2439(64.6758) | Bit/dim 3.6875(3.6907) | Xent 0.1474(0.1798) | Loss 8.9337(9.8568) | Error 0.0511(0.0632) Steps 646(662.68) | Grad Norm 5.1563(7.1812) | Total Time 0.00(0.00)\n",
      "Iter 1768 | Time 66.4452(64.7289) | Bit/dim 3.6865(3.6906) | Xent 0.1544(0.1791) | Loss 9.1936(9.8369) | Error 0.0544(0.0630) Steps 682(663.26) | Grad Norm 3.0335(7.0568) | Total Time 0.00(0.00)\n",
      "Iter 1769 | Time 62.6145(64.6655) | Bit/dim 3.6954(3.6908) | Xent 0.1516(0.1783) | Loss 9.0838(9.8143) | Error 0.0536(0.0627) Steps 658(663.10) | Grad Norm 6.0907(7.0278) | Total Time 0.00(0.00)\n",
      "Iter 1770 | Time 60.3746(64.5368) | Bit/dim 3.6807(3.6905) | Xent 0.1484(0.1774) | Loss 8.8675(9.7859) | Error 0.0539(0.0624) Steps 652(662.77) | Grad Norm 3.4354(6.9200) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0295 | Time 24.7037, Epoch Time 416.1561(438.0972), Bit/dim 3.7139(best: 3.7081), Xent 2.7896, Loss 5.1087, Error 0.4493(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1771 | Time 60.5425(64.4169) | Bit/dim 3.6889(3.6904) | Xent 0.1512(0.1766) | Loss 14.0830(9.9148) | Error 0.0500(0.0621) Steps 676(663.17) | Grad Norm 4.7689(6.8555) | Total Time 0.00(0.00)\n",
      "Iter 1772 | Time 65.1409(64.4386) | Bit/dim 3.6841(3.6902) | Xent 0.1488(0.1757) | Loss 8.9399(9.8856) | Error 0.0517(0.0617) Steps 676(663.55) | Grad Norm 4.1878(6.7754) | Total Time 0.00(0.00)\n",
      "Iter 1773 | Time 64.9992(64.4555) | Bit/dim 3.6819(3.6900) | Xent 0.1371(0.1746) | Loss 9.0548(9.8607) | Error 0.0469(0.0613) Steps 646(663.03) | Grad Norm 3.9256(6.6900) | Total Time 0.00(0.00)\n",
      "Iter 1774 | Time 68.7636(64.5847) | Bit/dim 3.6874(3.6899) | Xent 0.1492(0.1738) | Loss 9.0944(9.8377) | Error 0.0525(0.0610) Steps 682(663.59) | Grad Norm 3.8674(6.6053) | Total Time 0.00(0.00)\n",
      "Iter 1775 | Time 61.2412(64.4844) | Bit/dim 3.6931(3.6900) | Xent 0.1427(0.1729) | Loss 8.9279(9.8104) | Error 0.0509(0.0607) Steps 646(663.07) | Grad Norm 3.1952(6.5030) | Total Time 0.00(0.00)\n",
      "Iter 1776 | Time 70.7905(64.6736) | Bit/dim 3.6924(3.6901) | Xent 0.1433(0.1720) | Loss 9.0618(9.7879) | Error 0.0486(0.0604) Steps 676(663.45) | Grad Norm 3.3109(6.4072) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0296 | Time 25.1400, Epoch Time 435.6181(438.0228), Bit/dim 3.7133(best: 3.7081), Xent 2.8355, Loss 5.1310, Error 0.4522(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1777 | Time 63.9870(64.6530) | Bit/dim 3.6932(3.6902) | Xent 0.1389(0.1710) | Loss 13.7922(9.9081) | Error 0.0456(0.0599) Steps 664(663.47) | Grad Norm 5.0882(6.3676) | Total Time 0.00(0.00)\n",
      "Iter 1778 | Time 63.3521(64.6140) | Bit/dim 3.6720(3.6896) | Xent 0.1454(0.1702) | Loss 8.8216(9.8755) | Error 0.0521(0.0597) Steps 670(663.67) | Grad Norm 5.6288(6.3455) | Total Time 0.00(0.00)\n",
      "Iter 1779 | Time 67.3823(64.6970) | Bit/dim 3.6812(3.6894) | Xent 0.1531(0.1697) | Loss 9.1215(9.8529) | Error 0.0520(0.0595) Steps 676(664.04) | Grad Norm 5.2793(6.3135) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 66.7290(64.7580) | Bit/dim 3.6919(3.6894) | Xent 0.1370(0.1687) | Loss 9.0604(9.8291) | Error 0.0474(0.0591) Steps 628(662.96) | Grad Norm 3.6123(6.2325) | Total Time 0.00(0.00)\n",
      "Iter 1781 | Time 67.1963(64.8311) | Bit/dim 3.6880(3.6894) | Xent 0.1432(0.1680) | Loss 8.9726(9.8034) | Error 0.0511(0.0589) Steps 664(662.99) | Grad Norm 3.5877(6.1531) | Total Time 0.00(0.00)\n",
      "Iter 1782 | Time 64.1708(64.8113) | Bit/dim 3.6895(3.6894) | Xent 0.1506(0.1675) | Loss 8.9985(9.7792) | Error 0.0539(0.0587) Steps 658(662.84) | Grad Norm 4.5853(6.1061) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0297 | Time 24.8508, Epoch Time 436.7295(437.9840), Bit/dim 3.7104(best: 3.7081), Xent 2.8205, Loss 5.1207, Error 0.4573(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1783 | Time 61.6869(64.7176) | Bit/dim 3.6819(3.6892) | Xent 0.1604(0.1672) | Loss 13.5769(9.8932) | Error 0.0577(0.0587) Steps 646(662.33) | Grad Norm 6.9073(6.1301) | Total Time 0.00(0.00)\n",
      "Iter 1784 | Time 65.6600(64.7459) | Bit/dim 3.6850(3.6890) | Xent 0.1921(0.1680) | Loss 9.1554(9.8710) | Error 0.0696(0.0590) Steps 688(663.10) | Grad Norm 14.9687(6.3953) | Total Time 0.00(0.00)\n",
      "Iter 1785 | Time 62.2868(64.6721) | Bit/dim 3.6895(3.6891) | Xent 0.2448(0.1703) | Loss 9.0185(9.8455) | Error 0.0885(0.0599) Steps 682(663.67) | Grad Norm 26.6058(7.0016) | Total Time 0.00(0.00)\n",
      "Iter 1786 | Time 64.5550(64.6686) | Bit/dim 3.6842(3.6889) | Xent 0.1728(0.1704) | Loss 9.1563(9.8248) | Error 0.0617(0.0600) Steps 676(664.04) | Grad Norm 11.6064(7.1397) | Total Time 0.00(0.00)\n",
      "Iter 1787 | Time 63.8603(64.6443) | Bit/dim 3.6936(3.6891) | Xent 0.1391(0.1694) | Loss 8.8855(9.7966) | Error 0.0480(0.0596) Steps 670(664.22) | Grad Norm 3.7118(7.0369) | Total Time 0.00(0.00)\n",
      "Iter 1788 | Time 66.6613(64.7048) | Bit/dim 3.6931(3.6892) | Xent 0.1605(0.1692) | Loss 9.1630(9.7776) | Error 0.0556(0.0595) Steps 670(664.39) | Grad Norm 8.1198(7.0694) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0298 | Time 24.6158, Epoch Time 428.2196(437.6911), Bit/dim 3.7130(best: 3.7081), Xent 2.7026, Loss 5.0643, Error 0.4521(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1789 | Time 64.6749(64.7039) | Bit/dim 3.6959(3.6894) | Xent 0.1652(0.1690) | Loss 14.0291(9.9051) | Error 0.0590(0.0595) Steps 682(664.92) | Grad Norm 6.0712(7.0394) | Total Time 0.00(0.00)\n",
      "Iter 1790 | Time 65.9489(64.7413) | Bit/dim 3.6887(3.6894) | Xent 0.1456(0.1683) | Loss 9.0506(9.8795) | Error 0.0507(0.0592) Steps 682(665.43) | Grad Norm 4.5147(6.9637) | Total Time 0.00(0.00)\n",
      "Iter 1791 | Time 70.6465(64.9184) | Bit/dim 3.6838(3.6892) | Xent 0.1605(0.1681) | Loss 9.1216(9.8568) | Error 0.0544(0.0591) Steps 652(665.03) | Grad Norm 7.6776(6.9851) | Total Time 0.00(0.00)\n",
      "Iter 1792 | Time 63.3875(64.8725) | Bit/dim 3.6803(3.6889) | Xent 0.1478(0.1675) | Loss 8.6999(9.8221) | Error 0.0524(0.0589) Steps 670(665.18) | Grad Norm 5.7631(6.9485) | Total Time 0.00(0.00)\n",
      "Iter 1793 | Time 62.9199(64.8139) | Bit/dim 3.6848(3.6888) | Xent 0.1429(0.1668) | Loss 9.0090(9.7977) | Error 0.0490(0.0586) Steps 658(664.96) | Grad Norm 6.2268(6.9268) | Total Time 0.00(0.00)\n",
      "Iter 1794 | Time 62.9950(64.7594) | Bit/dim 3.6783(3.6885) | Xent 0.1633(0.1667) | Loss 9.2114(9.7801) | Error 0.0561(0.0585) Steps 676(665.29) | Grad Norm 9.8740(7.0152) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0299 | Time 25.1320, Epoch Time 434.5999(437.5984), Bit/dim 3.7108(best: 3.7081), Xent 2.9470, Loss 5.1842, Error 0.4499(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1795 | Time 60.7735(64.6398) | Bit/dim 3.6833(3.6883) | Xent 0.1407(0.1659) | Loss 13.3919(9.8884) | Error 0.0505(0.0582) Steps 664(665.26) | Grad Norm 5.8564(6.9805) | Total Time 0.00(0.00)\n",
      "Iter 1796 | Time 63.8531(64.6162) | Bit/dim 3.6901(3.6884) | Xent 0.1514(0.1654) | Loss 8.9953(9.8616) | Error 0.0524(0.0581) Steps 676(665.58) | Grad Norm 7.1357(6.9851) | Total Time 0.00(0.00)\n",
      "Iter 1797 | Time 63.6512(64.5872) | Bit/dim 3.6847(3.6883) | Xent 0.1842(0.1660) | Loss 9.0883(9.8384) | Error 0.0649(0.0583) Steps 658(665.35) | Grad Norm 10.4011(7.0876) | Total Time 0.00(0.00)\n",
      "Iter 1798 | Time 60.8428(64.4749) | Bit/dim 3.6905(3.6883) | Xent 0.2294(0.1679) | Loss 9.1203(9.8169) | Error 0.0834(0.0590) Steps 646(664.77) | Grad Norm 13.5301(7.2809) | Total Time 0.00(0.00)\n",
      "Iter 1799 | Time 67.7303(64.5726) | Bit/dim 3.6978(3.6886) | Xent 0.2571(0.1706) | Loss 9.2104(9.7987) | Error 0.0924(0.0600) Steps 652(664.39) | Grad Norm 18.6488(7.6219) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 69.2661(64.7134) | Bit/dim 3.6826(3.6884) | Xent 0.2717(0.1736) | Loss 9.1682(9.7798) | Error 0.0951(0.0611) Steps 670(664.56) | Grad Norm 16.3097(7.8825) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0300 | Time 25.3423, Epoch Time 430.1947(437.3762), Bit/dim 3.7124(best: 3.7081), Xent 2.5200, Loss 4.9724, Error 0.4502(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1801 | Time 70.6419(64.8912) | Bit/dim 3.7032(3.6889) | Xent 0.1835(0.1739) | Loss 14.0778(9.9087) | Error 0.0635(0.0612) Steps 682(665.08) | Grad Norm 8.0612(7.8879) | Total Time 0.00(0.00)\n",
      "Iter 1802 | Time 67.2595(64.9623) | Bit/dim 3.6787(3.6886) | Xent 0.2133(0.1751) | Loss 9.0094(9.8818) | Error 0.0771(0.0616) Steps 646(664.51) | Grad Norm 9.0923(7.9240) | Total Time 0.00(0.00)\n",
      "Iter 1803 | Time 66.0915(64.9962) | Bit/dim 3.6867(3.6885) | Xent 0.2148(0.1763) | Loss 9.1133(9.8587) | Error 0.0826(0.0623) Steps 682(665.03) | Grad Norm 8.7378(7.9484) | Total Time 0.00(0.00)\n",
      "Iter 1804 | Time 63.9318(64.9642) | Bit/dim 3.6887(3.6885) | Xent 0.1775(0.1763) | Loss 8.8023(9.8270) | Error 0.0624(0.0623) Steps 670(665.18) | Grad Norm 4.6424(7.8493) | Total Time 0.00(0.00)\n",
      "Iter 1805 | Time 65.9395(64.9935) | Bit/dim 3.6870(3.6885) | Xent 0.1965(0.1769) | Loss 9.0300(9.8031) | Error 0.0726(0.0626) Steps 652(664.78) | Grad Norm 7.2773(7.8321) | Total Time 0.00(0.00)\n",
      "Iter 1806 | Time 63.7676(64.9567) | Bit/dim 3.6908(3.6886) | Xent 0.1810(0.1771) | Loss 9.0992(9.7820) | Error 0.0607(0.0625) Steps 652(664.40) | Grad Norm 6.0385(7.7783) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0301 | Time 24.7324, Epoch Time 441.4372(437.4981), Bit/dim 3.7098(best: 3.7081), Xent 2.6032, Loss 5.0114, Error 0.4486(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1807 | Time 64.9473(64.9564) | Bit/dim 3.6916(3.6886) | Xent 0.1856(0.1773) | Loss 13.6633(9.8984) | Error 0.0670(0.0627) Steps 670(664.57) | Grad Norm 7.8064(7.7791) | Total Time 0.00(0.00)\n",
      "Iter 1808 | Time 60.4663(64.8217) | Bit/dim 3.6820(3.6884) | Xent 0.1697(0.1771) | Loss 9.0048(9.8716) | Error 0.0607(0.0626) Steps 652(664.19) | Grad Norm 4.8966(7.6927) | Total Time 0.00(0.00)\n",
      "Iter 1809 | Time 69.7500(64.9696) | Bit/dim 3.6814(3.6882) | Xent 0.1382(0.1759) | Loss 9.0775(9.8478) | Error 0.0461(0.0621) Steps 646(663.65) | Grad Norm 7.2037(7.6780) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 63.2591(64.9183) | Bit/dim 3.6883(3.6882) | Xent 0.1604(0.1754) | Loss 9.1284(9.8262) | Error 0.0555(0.0619) Steps 652(663.30) | Grad Norm 6.9052(7.6548) | Total Time 0.00(0.00)\n",
      "Iter 1811 | Time 67.1047(64.9838) | Bit/dim 3.6919(3.6883) | Xent 0.1583(0.1749) | Loss 9.0168(9.8019) | Error 0.0553(0.0617) Steps 646(662.78) | Grad Norm 7.8735(7.6614) | Total Time 0.00(0.00)\n",
      "Iter 1812 | Time 60.7189(64.8559) | Bit/dim 3.6855(3.6883) | Xent 0.1653(0.1746) | Loss 9.0912(9.7806) | Error 0.0577(0.0616) Steps 640(662.09) | Grad Norm 7.6964(7.6624) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0302 | Time 24.9658, Epoch Time 430.5286(437.2890), Bit/dim 3.7136(best: 3.7081), Xent 2.8380, Loss 5.1327, Error 0.4514(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1813 | Time 66.5847(64.9078) | Bit/dim 3.6815(3.6881) | Xent 0.1569(0.1741) | Loss 13.8269(9.9020) | Error 0.0534(0.0613) Steps 664(662.15) | Grad Norm 10.5039(7.7477) | Total Time 0.00(0.00)\n",
      "Iter 1814 | Time 68.1870(65.0061) | Bit/dim 3.6868(3.6880) | Xent 0.1533(0.1735) | Loss 9.0340(9.8760) | Error 0.0537(0.0611) Steps 694(663.11) | Grad Norm 8.8110(7.7796) | Total Time 0.00(0.00)\n",
      "Iter 1815 | Time 66.9553(65.0646) | Bit/dim 3.6887(3.6880) | Xent 0.1575(0.1730) | Loss 9.0648(9.8516) | Error 0.0523(0.0608) Steps 670(663.31) | Grad Norm 6.3669(7.7372) | Total Time 0.00(0.00)\n",
      "Iter 1816 | Time 68.1567(65.1574) | Bit/dim 3.6874(3.6880) | Xent 0.1476(0.1722) | Loss 9.0261(9.8269) | Error 0.0500(0.0605) Steps 676(663.69) | Grad Norm 5.1910(7.6608) | Total Time 0.00(0.00)\n",
      "Iter 1817 | Time 61.8100(65.0570) | Bit/dim 3.6887(3.6880) | Xent 0.1517(0.1716) | Loss 8.7921(9.7958) | Error 0.0529(0.0603) Steps 652(663.34) | Grad Norm 4.1239(7.5547) | Total Time 0.00(0.00)\n",
      "Iter 1818 | Time 66.1120(65.0886) | Bit/dim 3.6821(3.6879) | Xent 0.1418(0.1707) | Loss 9.0241(9.7727) | Error 0.0476(0.0599) Steps 658(663.18) | Grad Norm 5.0882(7.4807) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0303 | Time 24.5118, Epoch Time 441.3403(437.4105), Bit/dim 3.7095(best: 3.7081), Xent 2.7975, Loss 5.1082, Error 0.4483(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1819 | Time 64.0435(65.0573) | Bit/dim 3.6866(3.6878) | Xent 0.1432(0.1699) | Loss 14.0516(9.9010) | Error 0.0465(0.0595) Steps 652(662.85) | Grad Norm 5.4662(7.4203) | Total Time 0.00(0.00)\n",
      "Iter 1820 | Time 65.2798(65.0639) | Bit/dim 3.6914(3.6879) | Xent 0.1413(0.1691) | Loss 9.0569(9.8757) | Error 0.0504(0.0592) Steps 676(663.24) | Grad Norm 5.3938(7.3595) | Total Time 0.00(0.00)\n",
      "Iter 1821 | Time 64.7416(65.0543) | Bit/dim 3.6820(3.6878) | Xent 0.1299(0.1679) | Loss 8.9862(9.8490) | Error 0.0430(0.0587) Steps 676(663.63) | Grad Norm 4.3069(7.2679) | Total Time 0.00(0.00)\n",
      "Iter 1822 | Time 66.2632(65.0905) | Bit/dim 3.6838(3.6876) | Xent 0.1401(0.1670) | Loss 8.9120(9.8209) | Error 0.0495(0.0585) Steps 688(664.36) | Grad Norm 3.8472(7.1653) | Total Time 0.00(0.00)\n",
      "Iter 1823 | Time 67.0400(65.1490) | Bit/dim 3.6749(3.6873) | Xent 0.1385(0.1662) | Loss 9.0443(9.7976) | Error 0.0479(0.0582) Steps 688(665.07) | Grad Norm 4.7097(7.0916) | Total Time 0.00(0.00)\n",
      "Iter 1824 | Time 62.4535(65.0681) | Bit/dim 3.6820(3.6871) | Xent 0.1336(0.1652) | Loss 8.9565(9.7724) | Error 0.0434(0.0577) Steps 640(664.31) | Grad Norm 3.5517(6.9854) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0304 | Time 24.6908, Epoch Time 433.4586(437.2920), Bit/dim 3.7118(best: 3.7081), Xent 2.8338, Loss 5.1287, Error 0.4480(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1825 | Time 60.6914(64.9368) | Bit/dim 3.6790(3.6869) | Xent 0.1278(0.1641) | Loss 13.7063(9.8904) | Error 0.0436(0.0573) Steps 640(663.58) | Grad Norm 3.1901(6.8715) | Total Time 0.00(0.00)\n",
      "Iter 1826 | Time 68.3867(65.0403) | Bit/dim 3.6899(3.6869) | Xent 0.1361(0.1632) | Loss 9.2117(9.8700) | Error 0.0443(0.0569) Steps 646(663.06) | Grad Norm 3.2962(6.7643) | Total Time 0.00(0.00)\n",
      "Iter 1827 | Time 64.4889(65.0238) | Bit/dim 3.6825(3.6868) | Xent 0.1284(0.1622) | Loss 8.9494(9.8424) | Error 0.0429(0.0565) Steps 694(663.99) | Grad Norm 4.0727(6.6835) | Total Time 0.00(0.00)\n",
      "Iter 1828 | Time 66.6775(65.0734) | Bit/dim 3.6695(3.6863) | Xent 0.1305(0.1613) | Loss 9.0723(9.8193) | Error 0.0436(0.0561) Steps 676(664.35) | Grad Norm 4.5274(6.6189) | Total Time 0.00(0.00)\n",
      "Iter 1829 | Time 67.4349(65.1442) | Bit/dim 3.6877(3.6863) | Xent 0.1388(0.1606) | Loss 9.0161(9.7952) | Error 0.0487(0.0559) Steps 670(664.52) | Grad Norm 4.9449(6.5686) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 66.3189(65.1795) | Bit/dim 3.6861(3.6863) | Xent 0.1350(0.1598) | Loss 9.0958(9.7742) | Error 0.0485(0.0556) Steps 682(665.04) | Grad Norm 3.8117(6.4859) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0305 | Time 24.4348, Epoch Time 436.8204(437.2778), Bit/dim 3.7118(best: 3.7081), Xent 2.8354, Loss 5.1295, Error 0.4486(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1831 | Time 67.9595(65.2629) | Bit/dim 3.6880(3.6864) | Xent 0.1476(0.1594) | Loss 13.3505(9.8815) | Error 0.0539(0.0556) Steps 682(665.55) | Grad Norm 3.5588(6.3981) | Total Time 0.00(0.00)\n",
      "Iter 1832 | Time 66.0147(65.2854) | Bit/dim 3.6771(3.6861) | Xent 0.1260(0.1584) | Loss 9.1568(9.8598) | Error 0.0443(0.0553) Steps 646(664.96) | Grad Norm 4.1228(6.3299) | Total Time 0.00(0.00)\n",
      "Iter 1833 | Time 67.8858(65.3635) | Bit/dim 3.6786(3.6859) | Xent 0.1289(0.1576) | Loss 9.1089(9.8372) | Error 0.0471(0.0550) Steps 664(664.93) | Grad Norm 3.4446(6.2433) | Total Time 0.00(0.00)\n",
      "Iter 1834 | Time 64.7054(65.3437) | Bit/dim 3.6915(3.6860) | Xent 0.1200(0.1564) | Loss 8.8346(9.8072) | Error 0.0394(0.0545) Steps 676(665.27) | Grad Norm 2.6567(6.1357) | Total Time 0.00(0.00)\n",
      "Iter 1835 | Time 58.9953(65.1533) | Bit/dim 3.6889(3.6861) | Xent 0.1315(0.1557) | Loss 9.0208(9.7836) | Error 0.0461(0.0543) Steps 658(665.05) | Grad Norm 4.8724(6.0978) | Total Time 0.00(0.00)\n",
      "Iter 1836 | Time 65.3923(65.1604) | Bit/dim 3.6838(3.6861) | Xent 0.1440(0.1553) | Loss 9.0040(9.7602) | Error 0.0504(0.0542) Steps 664(665.02) | Grad Norm 6.3738(6.1061) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0306 | Time 24.8163, Epoch Time 434.7298(437.2014), Bit/dim 3.7083(best: 3.7081), Xent 2.9077, Loss 5.1621, Error 0.4526(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1837 | Time 63.4872(65.1102) | Bit/dim 3.6721(3.6856) | Xent 0.1331(0.1547) | Loss 13.7064(9.8786) | Error 0.0436(0.0539) Steps 682(665.53) | Grad Norm 6.1444(6.1072) | Total Time 0.00(0.00)\n",
      "Iter 1838 | Time 67.8437(65.1922) | Bit/dim 3.6766(3.6854) | Xent 0.1331(0.1540) | Loss 8.8610(9.8480) | Error 0.0481(0.0537) Steps 670(665.66) | Grad Norm 3.8243(6.0387) | Total Time 0.00(0.00)\n",
      "Iter 1839 | Time 64.8977(65.1834) | Bit/dim 3.6928(3.6856) | Xent 0.1185(0.1530) | Loss 9.0280(9.8234) | Error 0.0380(0.0532) Steps 634(664.71) | Grad Norm 3.7727(5.9708) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 64.1825(65.1534) | Bit/dim 3.6879(3.6857) | Xent 0.1312(0.1523) | Loss 9.0020(9.7988) | Error 0.0464(0.0530) Steps 676(665.05) | Grad Norm 6.3272(5.9815) | Total Time 0.00(0.00)\n",
      "Iter 1841 | Time 60.2626(65.0067) | Bit/dim 3.6727(3.6853) | Xent 0.1220(0.1514) | Loss 9.0634(9.7767) | Error 0.0424(0.0527) Steps 676(665.38) | Grad Norm 4.2040(5.9281) | Total Time 0.00(0.00)\n",
      "Iter 1842 | Time 67.7432(65.0888) | Bit/dim 3.6798(3.6851) | Xent 0.1255(0.1506) | Loss 9.1690(9.7585) | Error 0.0437(0.0524) Steps 664(665.34) | Grad Norm 5.3105(5.9096) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0307 | Time 23.8149, Epoch Time 430.6941(437.0062), Bit/dim 3.7142(best: 3.7081), Xent 2.9529, Loss 5.1907, Error 0.4533(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1843 | Time 66.1947(65.1219) | Bit/dim 3.6790(3.6849) | Xent 0.1286(0.1500) | Loss 13.5706(9.8729) | Error 0.0443(0.0522) Steps 646(664.76) | Grad Norm 6.9385(5.9405) | Total Time 0.00(0.00)\n",
      "Iter 1844 | Time 68.4532(65.2219) | Bit/dim 3.6880(3.6850) | Xent 0.1302(0.1494) | Loss 9.0835(9.8492) | Error 0.0439(0.0519) Steps 694(665.63) | Grad Norm 5.8804(5.9387) | Total Time 0.00(0.00)\n",
      "Iter 1845 | Time 68.0500(65.3067) | Bit/dim 3.6800(3.6849) | Xent 0.1272(0.1487) | Loss 8.9461(9.8221) | Error 0.0430(0.0517) Steps 688(666.30) | Grad Norm 6.1109(5.9438) | Total Time 0.00(0.00)\n",
      "Iter 1846 | Time 69.4745(65.4317) | Bit/dim 3.6903(3.6850) | Xent 0.1370(0.1484) | Loss 8.8971(9.7943) | Error 0.0467(0.0515) Steps 676(666.59) | Grad Norm 8.5018(6.0206) | Total Time 0.00(0.00)\n",
      "Iter 1847 | Time 69.9067(65.5660) | Bit/dim 3.6800(3.6849) | Xent 0.1360(0.1480) | Loss 9.0452(9.7719) | Error 0.0444(0.0513) Steps 652(666.16) | Grad Norm 8.0150(6.0804) | Total Time 0.00(0.00)\n",
      "Iter 1848 | Time 62.3679(65.4701) | Bit/dim 3.6824(3.6848) | Xent 0.1377(0.1477) | Loss 9.1237(9.7524) | Error 0.0460(0.0511) Steps 658(665.91) | Grad Norm 6.8057(6.1022) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0308 | Time 24.3457, Epoch Time 447.0810(437.3084), Bit/dim 3.7109(best: 3.7081), Xent 2.8859, Loss 5.1538, Error 0.4599(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1849 | Time 60.6564(65.3256) | Bit/dim 3.6902(3.6850) | Xent 0.1292(0.1471) | Loss 13.7389(9.8720) | Error 0.0464(0.0510) Steps 652(665.49) | Grad Norm 4.9754(6.0684) | Total Time 0.00(0.00)\n",
      "Iter 1850 | Time 61.4225(65.2085) | Bit/dim 3.6707(3.6845) | Xent 0.1347(0.1467) | Loss 8.9405(9.8441) | Error 0.0465(0.0509) Steps 646(664.91) | Grad Norm 5.5201(6.0519) | Total Time 0.00(0.00)\n",
      "Iter 1851 | Time 63.6994(65.1633) | Bit/dim 3.6904(3.6847) | Xent 0.1348(0.1464) | Loss 9.1656(9.8237) | Error 0.0466(0.0507) Steps 664(664.88) | Grad Norm 5.3228(6.0300) | Total Time 0.00(0.00)\n",
      "Iter 1852 | Time 68.1374(65.2525) | Bit/dim 3.6818(3.6846) | Xent 0.1287(0.1459) | Loss 8.9550(9.7977) | Error 0.0459(0.0506) Steps 688(665.58) | Grad Norm 5.7731(6.0223) | Total Time 0.00(0.00)\n",
      "Iter 1853 | Time 62.9163(65.1824) | Bit/dim 3.6819(3.6845) | Xent 0.1246(0.1452) | Loss 8.9178(9.7713) | Error 0.0451(0.0504) Steps 640(664.81) | Grad Norm 4.4179(5.9742) | Total Time 0.00(0.00)\n",
      "Iter 1854 | Time 64.7599(65.1697) | Bit/dim 3.6822(3.6845) | Xent 0.1106(0.1442) | Loss 8.8207(9.7427) | Error 0.0384(0.0501) Steps 646(664.24) | Grad Norm 4.4853(5.9295) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0309 | Time 24.2771, Epoch Time 424.1843(436.9147), Bit/dim 3.7106(best: 3.7081), Xent 3.0105, Loss 5.2158, Error 0.4543(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1855 | Time 62.5520(65.0912) | Bit/dim 3.6895(3.6846) | Xent 0.1295(0.1437) | Loss 13.7878(9.8641) | Error 0.0435(0.0499) Steps 664(664.24) | Grad Norm 5.3620(5.9125) | Total Time 0.00(0.00)\n",
      "Iter 1856 | Time 61.7888(64.9921) | Bit/dim 3.6789(3.6845) | Xent 0.1341(0.1435) | Loss 9.0596(9.8400) | Error 0.0475(0.0498) Steps 646(663.69) | Grad Norm 7.1674(5.9502) | Total Time 0.00(0.00)\n",
      "Iter 1857 | Time 65.7803(65.0158) | Bit/dim 3.6798(3.6843) | Xent 0.1345(0.1432) | Loss 8.8950(9.8116) | Error 0.0461(0.0497) Steps 688(664.42) | Grad Norm 7.1065(5.9848) | Total Time 0.00(0.00)\n",
      "Iter 1858 | Time 67.6032(65.0934) | Bit/dim 3.6758(3.6841) | Xent 0.1118(0.1422) | Loss 8.9615(9.7861) | Error 0.0380(0.0493) Steps 664(664.41) | Grad Norm 3.7981(5.9192) | Total Time 0.00(0.00)\n",
      "Iter 1859 | Time 69.9688(65.2397) | Bit/dim 3.6741(3.6838) | Xent 0.1432(0.1423) | Loss 8.9466(9.7609) | Error 0.0485(0.0493) Steps 700(665.47) | Grad Norm 11.3707(6.0828) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 65.8841(65.2590) | Bit/dim 3.6961(3.6841) | Xent 0.1590(0.1428) | Loss 9.2231(9.7448) | Error 0.0567(0.0495) Steps 664(665.43) | Grad Norm 14.0560(6.3220) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0310 | Time 25.0256, Epoch Time 437.6204(436.9359), Bit/dim 3.7088(best: 3.7081), Xent 2.8657, Loss 5.1416, Error 0.4496(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1861 | Time 68.6260(65.3600) | Bit/dim 3.6821(3.6841) | Xent 0.1955(0.1444) | Loss 13.6793(9.8628) | Error 0.0705(0.0502) Steps 688(666.11) | Grad Norm 14.3906(6.5640) | Total Time 0.00(0.00)\n",
      "Iter 1862 | Time 64.7790(65.3426) | Bit/dim 3.6876(3.6842) | Xent 0.1815(0.1455) | Loss 9.0098(9.8372) | Error 0.0650(0.0506) Steps 652(665.68) | Grad Norm 14.7651(6.8101) | Total Time 0.00(0.00)\n",
      "Iter 1863 | Time 69.9775(65.4816) | Bit/dim 3.6869(3.6843) | Xent 0.1594(0.1459) | Loss 9.0974(9.8150) | Error 0.0533(0.0507) Steps 700(666.71) | Grad Norm 13.1920(7.0015) | Total Time 0.00(0.00)\n",
      "Iter 1864 | Time 66.1034(65.5003) | Bit/dim 3.6830(3.6842) | Xent 0.1814(0.1470) | Loss 9.0115(9.7909) | Error 0.0604(0.0510) Steps 676(666.99) | Grad Norm 13.3082(7.1907) | Total Time 0.00(0.00)\n",
      "Iter 1865 | Time 60.9282(65.3631) | Bit/dim 3.6819(3.6841) | Xent 0.1865(0.1481) | Loss 9.0724(9.7694) | Error 0.0681(0.0515) Steps 658(666.72) | Grad Norm 10.7184(7.2966) | Total Time 0.00(0.00)\n",
      "Iter 1866 | Time 63.6116(65.3106) | Bit/dim 3.6846(3.6842) | Xent 0.1810(0.1491) | Loss 9.1148(9.7497) | Error 0.0655(0.0519) Steps 676(667.00) | Grad Norm 12.4313(7.4506) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0311 | Time 24.6755, Epoch Time 437.5127(436.9532), Bit/dim 3.7125(best: 3.7081), Xent 2.8736, Loss 5.1493, Error 0.4573(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1867 | Time 63.1100(65.2445) | Bit/dim 3.6892(3.6843) | Xent 0.1762(0.1499) | Loss 14.2053(9.8834) | Error 0.0617(0.0522) Steps 664(666.91) | Grad Norm 16.4758(7.7214) | Total Time 0.00(0.00)\n",
      "Iter 1868 | Time 64.9014(65.2343) | Bit/dim 3.6856(3.6843) | Xent 0.1881(0.1511) | Loss 8.9458(9.8553) | Error 0.0684(0.0527) Steps 664(666.82) | Grad Norm 9.8195(7.7843) | Total Time 0.00(0.00)\n",
      "Iter 1869 | Time 64.4041(65.2093) | Bit/dim 3.6810(3.6842) | Xent 0.2434(0.1539) | Loss 9.0552(9.8313) | Error 0.0879(0.0537) Steps 670(666.92) | Grad Norm 19.1952(8.1266) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 61.3782(65.0944) | Bit/dim 3.6884(3.6844) | Xent 0.2603(0.1570) | Loss 9.2516(9.8139) | Error 0.0891(0.0548) Steps 670(667.01) | Grad Norm 23.2164(8.5793) | Total Time 0.00(0.00)\n",
      "Iter 1871 | Time 68.3908(65.1933) | Bit/dim 3.6933(3.6846) | Xent 0.2221(0.1590) | Loss 9.2650(9.7974) | Error 0.0815(0.0556) Steps 646(666.38) | Grad Norm 9.0828(8.5944) | Total Time 0.00(0.00)\n",
      "Iter 1872 | Time 66.4407(65.2307) | Bit/dim 3.6857(3.6847) | Xent 0.3171(0.1637) | Loss 9.2463(9.7809) | Error 0.1109(0.0573) Steps 676(666.67) | Grad Norm 25.6888(9.1073) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0312 | Time 24.7873, Epoch Time 432.0264(436.8054), Bit/dim 3.7083(best: 3.7081), Xent 2.6803, Loss 5.0485, Error 0.4522(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1873 | Time 64.2347(65.2008) | Bit/dim 3.6928(3.6849) | Xent 0.2210(0.1655) | Loss 13.5313(9.8934) | Error 0.0781(0.0579) Steps 670(666.77) | Grad Norm 12.9035(9.2211) | Total Time 0.00(0.00)\n",
      "Iter 1874 | Time 65.4571(65.2085) | Bit/dim 3.6835(3.6849) | Xent 0.2334(0.1675) | Loss 8.9890(9.8663) | Error 0.0837(0.0587) Steps 640(665.97) | Grad Norm 12.0999(9.3075) | Total Time 0.00(0.00)\n",
      "Iter 1875 | Time 62.6794(65.1327) | Bit/dim 3.6929(3.6851) | Xent 0.2534(0.1701) | Loss 8.9508(9.8388) | Error 0.0894(0.0596) Steps 646(665.37) | Grad Norm 20.7310(9.6502) | Total Time 0.00(0.00)\n",
      "Iter 1876 | Time 62.4532(65.0523) | Bit/dim 3.6928(3.6853) | Xent 0.2548(0.1726) | Loss 9.1251(9.8174) | Error 0.0853(0.0604) Steps 646(664.79) | Grad Norm 20.4422(9.9740) | Total Time 0.00(0.00)\n",
      "Iter 1877 | Time 66.6170(65.0992) | Bit/dim 3.6858(3.6854) | Xent 0.2312(0.1744) | Loss 9.0732(9.7951) | Error 0.0803(0.0610) Steps 664(664.76) | Grad Norm 13.9004(10.0918) | Total Time 0.00(0.00)\n",
      "Iter 1878 | Time 61.8811(65.0027) | Bit/dim 3.7020(3.6859) | Xent 0.2563(0.1768) | Loss 9.1837(9.7767) | Error 0.0887(0.0618) Steps 646(664.20) | Grad Norm 20.7595(10.4118) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0313 | Time 24.4412, Epoch Time 426.3986(436.4932), Bit/dim 3.7160(best: 3.7081), Xent 2.5457, Loss 4.9888, Error 0.4526(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1879 | Time 63.0672(64.9446) | Bit/dim 3.6892(3.6860) | Xent 0.2130(0.1779) | Loss 13.4529(9.8870) | Error 0.0770(0.0622) Steps 646(663.65) | Grad Norm 12.4206(10.4721) | Total Time 0.00(0.00)\n",
      "Iter 1880 | Time 61.4013(64.8383) | Bit/dim 3.6964(3.6863) | Xent 0.1945(0.1784) | Loss 9.2053(9.8666) | Error 0.0676(0.0624) Steps 682(664.20) | Grad Norm 9.8999(10.4549) | Total Time 0.00(0.00)\n",
      "Iter 1881 | Time 63.7545(64.8058) | Bit/dim 3.6861(3.6863) | Xent 0.2667(0.1811) | Loss 9.0922(9.8433) | Error 0.0941(0.0634) Steps 670(664.38) | Grad Norm 13.8390(10.5564) | Total Time 0.00(0.00)\n",
      "Iter 1882 | Time 64.7796(64.8050) | Bit/dim 3.6873(3.6863) | Xent 0.2145(0.1821) | Loss 8.9341(9.8161) | Error 0.0769(0.0638) Steps 664(664.37) | Grad Norm 11.5463(10.5861) | Total Time 0.00(0.00)\n",
      "Iter 1883 | Time 63.2444(64.7582) | Bit/dim 3.6987(3.6867) | Xent 0.1903(0.1823) | Loss 9.1238(9.7953) | Error 0.0646(0.0638) Steps 658(664.18) | Grad Norm 7.3656(10.4895) | Total Time 0.00(0.00)\n",
      "Iter 1884 | Time 65.9669(64.7945) | Bit/dim 3.6963(3.6870) | Xent 0.1962(0.1827) | Loss 9.1176(9.7750) | Error 0.0737(0.0641) Steps 670(664.35) | Grad Norm 12.0612(10.5367) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0314 | Time 24.6647, Epoch Time 425.3959(436.1602), Bit/dim 3.7124(best: 3.7081), Xent 2.6507, Loss 5.0377, Error 0.4464(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1885 | Time 61.4207(64.6932) | Bit/dim 3.6951(3.6872) | Xent 0.1863(0.1828) | Loss 13.5914(9.8894) | Error 0.0653(0.0641) Steps 652(663.98) | Grad Norm 12.4135(10.5930) | Total Time 0.00(0.00)\n",
      "Iter 1886 | Time 64.4465(64.6858) | Bit/dim 3.6839(3.6871) | Xent 0.1994(0.1833) | Loss 9.0751(9.8650) | Error 0.0694(0.0643) Steps 664(663.98) | Grad Norm 10.9732(10.6044) | Total Time 0.00(0.00)\n",
      "Iter 1887 | Time 64.6738(64.6855) | Bit/dim 3.6987(3.6875) | Xent 0.2165(0.1843) | Loss 9.0984(9.8420) | Error 0.0784(0.0647) Steps 670(664.16) | Grad Norm 20.6564(10.9059) | Total Time 0.00(0.00)\n",
      "Iter 1888 | Time 66.2702(64.7330) | Bit/dim 3.6899(3.6875) | Xent 0.2049(0.1849) | Loss 9.1516(9.8213) | Error 0.0720(0.0649) Steps 682(664.70) | Grad Norm 13.6136(10.9872) | Total Time 0.00(0.00)\n",
      "Iter 1889 | Time 65.7337(64.7630) | Bit/dim 3.6857(3.6875) | Xent 0.1540(0.1840) | Loss 9.1238(9.8004) | Error 0.0515(0.0645) Steps 640(663.96) | Grad Norm 6.0235(10.8382) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 65.0710(64.7723) | Bit/dim 3.6992(3.6878) | Xent 0.1995(0.1845) | Loss 8.9862(9.7760) | Error 0.0723(0.0648) Steps 658(663.78) | Grad Norm 10.1702(10.8182) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0315 | Time 24.5032, Epoch Time 430.8499(436.0009), Bit/dim 3.7129(best: 3.7081), Xent 2.5807, Loss 5.0033, Error 0.4452(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1891 | Time 57.8840(64.5656) | Bit/dim 3.7010(3.6882) | Xent 0.1409(0.1832) | Loss 13.2554(9.8803) | Error 0.0493(0.0643) Steps 646(663.24) | Grad Norm 5.2735(10.6519) | Total Time 0.00(0.00)\n",
      "Iter 1892 | Time 65.3171(64.5882) | Bit/dim 3.6902(3.6883) | Xent 0.1713(0.1828) | Loss 9.1463(9.8583) | Error 0.0601(0.0642) Steps 646(662.73) | Grad Norm 8.8517(10.5979) | Total Time 0.00(0.00)\n",
      "Iter 1893 | Time 64.7856(64.5941) | Bit/dim 3.6909(3.6884) | Xent 0.1640(0.1823) | Loss 9.0724(9.8347) | Error 0.0549(0.0639) Steps 658(662.58) | Grad Norm 6.5049(10.4751) | Total Time 0.00(0.00)\n",
      "Iter 1894 | Time 72.7959(64.8401) | Bit/dim 3.6828(3.6882) | Xent 0.1553(0.1814) | Loss 9.1446(9.8140) | Error 0.0534(0.0636) Steps 688(663.35) | Grad Norm 6.3340(10.3508) | Total Time 0.00(0.00)\n",
      "Iter 1895 | Time 63.5900(64.8026) | Bit/dim 3.6832(3.6880) | Xent 0.1738(0.1812) | Loss 9.1154(9.7931) | Error 0.0585(0.0634) Steps 658(663.19) | Grad Norm 8.8730(10.3065) | Total Time 0.00(0.00)\n",
      "Iter 1896 | Time 63.0004(64.7486) | Bit/dim 3.6919(3.6882) | Xent 0.1338(0.1798) | Loss 8.9809(9.7687) | Error 0.0447(0.0629) Steps 646(662.67) | Grad Norm 5.8998(10.1743) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0316 | Time 24.8072, Epoch Time 430.7756(435.8442), Bit/dim 3.7107(best: 3.7081), Xent 2.7273, Loss 5.0743, Error 0.4485(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1897 | Time 63.0292(64.6970) | Bit/dim 3.6823(3.6880) | Xent 0.1283(0.1782) | Loss 14.1635(9.9006) | Error 0.0457(0.0623) Steps 658(662.53) | Grad Norm 5.4124(10.0314) | Total Time 0.00(0.00)\n",
      "Iter 1898 | Time 67.3515(64.7766) | Bit/dim 3.6929(3.6881) | Xent 0.1444(0.1772) | Loss 9.0505(9.8751) | Error 0.0484(0.0619) Steps 640(661.85) | Grad Norm 5.9437(9.9088) | Total Time 0.00(0.00)\n",
      "Iter 1899 | Time 62.7388(64.7155) | Bit/dim 3.6850(3.6880) | Xent 0.1215(0.1756) | Loss 8.8335(9.8438) | Error 0.0429(0.0614) Steps 622(660.66) | Grad Norm 4.0362(9.7326) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 65.8280(64.7489) | Bit/dim 3.6871(3.6880) | Xent 0.1265(0.1741) | Loss 8.9347(9.8165) | Error 0.0443(0.0608) Steps 670(660.94) | Grad Norm 4.8159(9.5851) | Total Time 0.00(0.00)\n",
      "Iter 1901 | Time 61.0488(64.6379) | Bit/dim 3.6885(3.6880) | Xent 0.1161(0.1723) | Loss 8.8898(9.7887) | Error 0.0379(0.0602) Steps 652(660.67) | Grad Norm 3.1618(9.3924) | Total Time 0.00(0.00)\n",
      "Iter 1902 | Time 65.0728(64.6509) | Bit/dim 3.6836(3.6879) | Xent 0.1156(0.1706) | Loss 8.9493(9.7635) | Error 0.0389(0.0595) Steps 682(661.31) | Grad Norm 4.4624(9.2445) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0317 | Time 24.8764, Epoch Time 428.5675(435.6259), Bit/dim 3.7027(best: 3.7081), Xent 2.8656, Loss 5.1355, Error 0.4482(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1903 | Time 62.2736(64.5796) | Bit/dim 3.6817(3.6877) | Xent 0.1205(0.1691) | Loss 13.8683(9.8867) | Error 0.0415(0.0590) Steps 676(661.75) | Grad Norm 2.5065(9.0424) | Total Time 0.00(0.00)\n",
      "Iter 1904 | Time 64.6957(64.5831) | Bit/dim 3.6851(3.6876) | Xent 0.1213(0.1677) | Loss 9.1819(9.8655) | Error 0.0407(0.0584) Steps 664(661.82) | Grad Norm 3.9059(8.8883) | Total Time 0.00(0.00)\n",
      "Iter 1905 | Time 64.7053(64.5867) | Bit/dim 3.6864(3.6876) | Xent 0.1069(0.1659) | Loss 8.7819(9.8330) | Error 0.0377(0.0578) Steps 670(662.06) | Grad Norm 2.5071(8.6969) | Total Time 0.00(0.00)\n",
      "Iter 1906 | Time 64.8303(64.5941) | Bit/dim 3.6778(3.6873) | Xent 0.1105(0.1642) | Loss 8.9732(9.8072) | Error 0.0356(0.0571) Steps 670(662.30) | Grad Norm 2.8306(8.5209) | Total Time 0.00(0.00)\n",
      "Iter 1907 | Time 65.8073(64.6305) | Bit/dim 3.6786(3.6870) | Xent 0.1133(0.1627) | Loss 9.0636(9.7849) | Error 0.0375(0.0566) Steps 652(661.99) | Grad Norm 3.3497(8.3657) | Total Time 0.00(0.00)\n",
      "Iter 1908 | Time 59.6190(64.4801) | Bit/dim 3.6892(3.6871) | Xent 0.1086(0.1611) | Loss 8.8904(9.7581) | Error 0.0365(0.0559) Steps 634(661.15) | Grad Norm 3.7039(8.2259) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0318 | Time 24.9764, Epoch Time 425.3442(435.3174), Bit/dim 3.7060(best: 3.7027), Xent 2.8607, Loss 5.1363, Error 0.4517(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1909 | Time 64.3363(64.4758) | Bit/dim 3.6831(3.6870) | Xent 0.1105(0.1596) | Loss 13.7044(9.8765) | Error 0.0385(0.0554) Steps 664(661.24) | Grad Norm 2.9812(8.0685) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 68.3227(64.5912) | Bit/dim 3.6827(3.6869) | Xent 0.1110(0.1581) | Loss 8.9437(9.8485) | Error 0.0377(0.0549) Steps 670(661.50) | Grad Norm 3.3017(7.9255) | Total Time 0.00(0.00)\n",
      "Iter 1911 | Time 67.0840(64.6660) | Bit/dim 3.6893(3.6869) | Xent 0.1094(0.1566) | Loss 8.7957(9.8169) | Error 0.0365(0.0543) Steps 670(661.76) | Grad Norm 3.1191(7.7813) | Total Time 0.00(0.00)\n",
      "Iter 1912 | Time 63.2290(64.6229) | Bit/dim 3.6669(3.6863) | Xent 0.1211(0.1556) | Loss 8.9182(9.7900) | Error 0.0400(0.0539) Steps 682(662.36) | Grad Norm 5.7931(7.7217) | Total Time 0.00(0.00)\n",
      "Iter 1913 | Time 62.8221(64.5689) | Bit/dim 3.6905(3.6865) | Xent 0.1187(0.1545) | Loss 9.0123(9.7666) | Error 0.0416(0.0535) Steps 700(663.49) | Grad Norm 4.7979(7.6340) | Total Time 0.00(0.00)\n",
      "Iter 1914 | Time 62.4891(64.5065) | Bit/dim 3.6689(3.6859) | Xent 0.1124(0.1532) | Loss 8.8862(9.7402) | Error 0.0381(0.0531) Steps 682(664.05) | Grad Norm 3.5761(7.5122) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0319 | Time 24.6141, Epoch Time 431.4422(435.2012), Bit/dim 3.7083(best: 3.7027), Xent 2.8732, Loss 5.1449, Error 0.4510(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1915 | Time 63.1558(64.4659) | Bit/dim 3.6798(3.6857) | Xent 0.1039(0.1517) | Loss 13.5999(9.8560) | Error 0.0343(0.0525) Steps 664(664.05) | Grad Norm 4.0814(7.4093) | Total Time 0.00(0.00)\n",
      "Iter 1916 | Time 63.9321(64.4499) | Bit/dim 3.6737(3.6854) | Xent 0.1075(0.1504) | Loss 8.8946(9.8272) | Error 0.0367(0.0520) Steps 646(663.51) | Grad Norm 3.0654(7.2790) | Total Time 0.00(0.00)\n",
      "Iter 1917 | Time 68.7953(64.5803) | Bit/dim 3.6746(3.6851) | Xent 0.1089(0.1492) | Loss 9.0751(9.8046) | Error 0.0346(0.0515) Steps 670(663.70) | Grad Norm 4.6836(7.2011) | Total Time 0.00(0.00)\n",
      "Iter 1918 | Time 66.7082(64.6441) | Bit/dim 3.6797(3.6849) | Xent 0.1045(0.1478) | Loss 9.0234(9.7812) | Error 0.0367(0.0511) Steps 646(663.17) | Grad Norm 3.9151(7.1026) | Total Time 0.00(0.00)\n",
      "Iter 1919 | Time 64.9603(64.6536) | Bit/dim 3.6659(3.6843) | Xent 0.0997(0.1464) | Loss 8.9001(9.7547) | Error 0.0337(0.0506) Steps 670(663.37) | Grad Norm 4.0968(7.0124) | Total Time 0.00(0.00)\n",
      "Iter 1920 | Time 65.4215(64.6766) | Bit/dim 3.6896(3.6845) | Xent 0.1139(0.1454) | Loss 8.8097(9.7264) | Error 0.0384(0.0502) Steps 694(664.29) | Grad Norm 5.7915(6.9758) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0320 | Time 24.7915, Epoch Time 436.8130(435.2495), Bit/dim 3.7048(best: 3.7027), Xent 2.9496, Loss 5.1796, Error 0.4553(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1921 | Time 62.5396(64.6125) | Bit/dim 3.6696(3.6840) | Xent 0.1068(0.1442) | Loss 13.9591(9.8534) | Error 0.0355(0.0498) Steps 664(664.28) | Grad Norm 2.5682(6.8435) | Total Time 0.00(0.00)\n",
      "Iter 1922 | Time 66.9845(64.6837) | Bit/dim 3.6728(3.6837) | Xent 0.1089(0.1432) | Loss 9.0105(9.8281) | Error 0.0363(0.0493) Steps 670(664.46) | Grad Norm 4.3202(6.7678) | Total Time 0.00(0.00)\n",
      "Iter 1923 | Time 64.3351(64.6732) | Bit/dim 3.6887(3.6839) | Xent 0.0923(0.1416) | Loss 8.6701(9.7933) | Error 0.0305(0.0488) Steps 682(664.98) | Grad Norm 2.7809(6.6482) | Total Time 0.00(0.00)\n",
      "Iter 1924 | Time 65.7836(64.7065) | Bit/dim 3.6932(3.6841) | Xent 0.1149(0.1408) | Loss 8.8935(9.7663) | Error 0.0361(0.0484) Steps 682(665.49) | Grad Norm 4.4716(6.5829) | Total Time 0.00(0.00)\n",
      "Iter 1925 | Time 68.1320(64.8093) | Bit/dim 3.6741(3.6838) | Xent 0.1034(0.1397) | Loss 8.9300(9.7413) | Error 0.0337(0.0480) Steps 688(666.17) | Grad Norm 3.1520(6.4800) | Total Time 0.00(0.00)\n",
      "Iter 1926 | Time 68.6942(64.9259) | Bit/dim 3.6762(3.6836) | Xent 0.1056(0.1387) | Loss 8.9253(9.7168) | Error 0.0371(0.0476) Steps 664(666.10) | Grad Norm 5.6116(6.4539) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0321 | Time 24.8516, Epoch Time 439.7566(435.3847), Bit/dim 3.7074(best: 3.7027), Xent 2.9788, Loss 5.1967, Error 0.4478(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1927 | Time 70.0976(65.0810) | Bit/dim 3.6782(3.6834) | Xent 0.1099(0.1378) | Loss 14.4331(9.8583) | Error 0.0383(0.0474) Steps 694(666.94) | Grad Norm 4.4402(6.3935) | Total Time 0.00(0.00)\n",
      "Iter 1928 | Time 65.8239(65.1033) | Bit/dim 3.6734(3.6831) | Xent 0.1011(0.1367) | Loss 8.9032(9.8296) | Error 0.0357(0.0470) Steps 676(667.21) | Grad Norm 5.3608(6.3625) | Total Time 0.00(0.00)\n",
      "Iter 1929 | Time 61.5280(64.9960) | Bit/dim 3.6805(3.6831) | Xent 0.0988(0.1356) | Loss 8.9328(9.8027) | Error 0.0315(0.0465) Steps 634(666.22) | Grad Norm 3.5322(6.2776) | Total Time 0.00(0.00)\n",
      "Iter 1930 | Time 64.5601(64.9830) | Bit/dim 3.6786(3.6829) | Xent 0.1042(0.1347) | Loss 9.0766(9.7809) | Error 0.0330(0.0461) Steps 658(665.97) | Grad Norm 5.8571(6.2650) | Total Time 0.00(0.00)\n",
      "Iter 1931 | Time 62.7642(64.9164) | Bit/dim 3.6785(3.6828) | Xent 0.1055(0.1338) | Loss 8.9417(9.7557) | Error 0.0360(0.0458) Steps 664(665.91) | Grad Norm 5.4513(6.2406) | Total Time 0.00(0.00)\n",
      "Iter 1932 | Time 64.8408(64.9141) | Bit/dim 3.6835(3.6828) | Xent 0.0965(0.1327) | Loss 8.7432(9.7254) | Error 0.0319(0.0454) Steps 676(666.21) | Grad Norm 2.5826(6.1309) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0322 | Time 24.7104, Epoch Time 432.8211(435.3078), Bit/dim 3.7076(best: 3.7027), Xent 2.9624, Loss 5.1888, Error 0.4510(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1933 | Time 61.7416(64.8190) | Bit/dim 3.6790(3.6827) | Xent 0.1028(0.1318) | Loss 13.3866(9.8352) | Error 0.0370(0.0452) Steps 670(666.33) | Grad Norm 4.2749(6.0752) | Total Time 0.00(0.00)\n",
      "Iter 1934 | Time 63.7346(64.7864) | Bit/dim 3.6744(3.6825) | Xent 0.0942(0.1306) | Loss 9.0100(9.8105) | Error 0.0323(0.0448) Steps 676(666.62) | Grad Norm 2.7828(5.9764) | Total Time 0.00(0.00)\n",
      "Iter 1935 | Time 64.0469(64.7642) | Bit/dim 3.6739(3.6822) | Xent 0.0967(0.1296) | Loss 9.0848(9.7887) | Error 0.0310(0.0444) Steps 670(666.72) | Grad Norm 4.0266(5.9179) | Total Time 0.00(0.00)\n",
      "Iter 1936 | Time 68.8313(64.8862) | Bit/dim 3.6830(3.6822) | Xent 0.0927(0.1285) | Loss 8.8201(9.7596) | Error 0.0312(0.0440) Steps 628(665.56) | Grad Norm 4.2596(5.8682) | Total Time 0.00(0.00)\n",
      "Iter 1937 | Time 66.5487(64.9361) | Bit/dim 3.6740(3.6820) | Xent 0.1061(0.1278) | Loss 9.0997(9.7398) | Error 0.0355(0.0437) Steps 670(665.69) | Grad Norm 5.8698(5.8682) | Total Time 0.00(0.00)\n",
      "Iter 1938 | Time 63.5947(64.8959) | Bit/dim 3.6779(3.6819) | Xent 0.1020(0.1271) | Loss 8.8111(9.7120) | Error 0.0334(0.0434) Steps 682(666.18) | Grad Norm 3.2893(5.7909) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0323 | Time 24.7277, Epoch Time 432.4403(435.2218), Bit/dim 3.7031(best: 3.7027), Xent 3.0046, Loss 5.2054, Error 0.4493(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1939 | Time 71.2165(65.0855) | Bit/dim 3.6794(3.6818) | Xent 0.1132(0.1266) | Loss 13.7038(9.8317) | Error 0.0376(0.0432) Steps 646(665.57) | Grad Norm 6.3999(5.8091) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 63.9364(65.0510) | Bit/dim 3.6819(3.6818) | Xent 0.1051(0.1260) | Loss 8.7506(9.7993) | Error 0.0349(0.0430) Steps 652(665.17) | Grad Norm 4.9018(5.7819) | Total Time 0.00(0.00)\n",
      "Iter 1941 | Time 65.4134(65.0619) | Bit/dim 3.6822(3.6818) | Xent 0.0972(0.1251) | Loss 8.7352(9.7674) | Error 0.0329(0.0427) Steps 664(665.13) | Grad Norm 4.2869(5.7371) | Total Time 0.00(0.00)\n",
      "Iter 1942 | Time 72.4076(65.2823) | Bit/dim 3.6719(3.6815) | Xent 0.1197(0.1250) | Loss 8.8854(9.7409) | Error 0.0389(0.0426) Steps 700(666.18) | Grad Norm 6.5455(5.7613) | Total Time 0.00(0.00)\n",
      "Iter 1943 | Time 58.8985(65.0908) | Bit/dim 3.6853(3.6816) | Xent 0.1140(0.1246) | Loss 8.9220(9.7163) | Error 0.0390(0.0425) Steps 658(665.93) | Grad Norm 6.9253(5.7962) | Total Time 0.00(0.00)\n",
      "Iter 1944 | Time 62.9941(65.0279) | Bit/dim 3.6696(3.6813) | Xent 0.1127(0.1243) | Loss 8.8866(9.6914) | Error 0.0370(0.0423) Steps 646(665.33) | Grad Norm 6.2679(5.8104) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0324 | Time 24.9828, Epoch Time 438.3528(435.3157), Bit/dim 3.7030(best: 3.7027), Xent 2.9670, Loss 5.1865, Error 0.4495(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1945 | Time 68.4752(65.1313) | Bit/dim 3.6847(3.6814) | Xent 0.1006(0.1236) | Loss 14.2144(9.8271) | Error 0.0333(0.0420) Steps 646(664.75) | Grad Norm 5.1870(5.7917) | Total Time 0.00(0.00)\n",
      "Iter 1946 | Time 63.9278(65.0952) | Bit/dim 3.6742(3.6811) | Xent 0.1042(0.1230) | Loss 9.0464(9.8037) | Error 0.0333(0.0418) Steps 658(664.55) | Grad Norm 4.4544(5.7516) | Total Time 0.00(0.00)\n",
      "Iter 1947 | Time 65.9452(65.1207) | Bit/dim 3.6729(3.6809) | Xent 0.1026(0.1224) | Loss 9.1029(9.7827) | Error 0.0330(0.0415) Steps 682(665.07) | Grad Norm 3.8403(5.6942) | Total Time 0.00(0.00)\n",
      "Iter 1948 | Time 65.8270(65.1419) | Bit/dim 3.6721(3.6806) | Xent 0.1006(0.1217) | Loss 8.9223(9.7569) | Error 0.0347(0.0413) Steps 682(665.58) | Grad Norm 6.8860(5.7300) | Total Time 0.00(0.00)\n",
      "Iter 1949 | Time 63.8917(65.1044) | Bit/dim 3.6624(3.6801) | Xent 0.0937(0.1209) | Loss 9.0799(9.7366) | Error 0.0300(0.0410) Steps 694(666.44) | Grad Norm 5.3265(5.7179) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 64.4505(65.0847) | Bit/dim 3.6804(3.6801) | Xent 0.1000(0.1203) | Loss 8.8672(9.7105) | Error 0.0331(0.0407) Steps 670(666.54) | Grad Norm 3.2951(5.6452) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0325 | Time 25.2827, Epoch Time 436.5757(435.3535), Bit/dim 3.7074(best: 3.7027), Xent 3.1442, Loss 5.2795, Error 0.4564(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1951 | Time 61.2092(64.9685) | Bit/dim 3.6745(3.6799) | Xent 0.0972(0.1196) | Loss 13.8516(9.8347) | Error 0.0355(0.0406) Steps 670(666.65) | Grad Norm 4.9548(5.6245) | Total Time 0.00(0.00)\n",
      "Iter 1952 | Time 62.0416(64.8807) | Bit/dim 3.6896(3.6802) | Xent 0.0939(0.1188) | Loss 8.9555(9.8083) | Error 0.0316(0.0403) Steps 646(666.03) | Grad Norm 5.0801(5.6081) | Total Time 0.00(0.00)\n",
      "Iter 1953 | Time 65.5646(64.9012) | Bit/dim 3.6887(3.6805) | Xent 0.0853(0.1178) | Loss 8.9254(9.7819) | Error 0.0285(0.0399) Steps 628(664.89) | Grad Norm 3.0433(5.5312) | Total Time 0.00(0.00)\n",
      "Iter 1954 | Time 64.3892(64.8858) | Bit/dim 3.6681(3.6801) | Xent 0.0976(0.1172) | Loss 8.9251(9.7561) | Error 0.0330(0.0397) Steps 670(665.04) | Grad Norm 5.2244(5.5220) | Total Time 0.00(0.00)\n",
      "Iter 1955 | Time 64.8128(64.8836) | Bit/dim 3.6713(3.6798) | Xent 0.1017(0.1167) | Loss 8.8710(9.7296) | Error 0.0346(0.0396) Steps 670(665.19) | Grad Norm 5.1146(5.5098) | Total Time 0.00(0.00)\n",
      "Iter 1956 | Time 64.1223(64.8608) | Bit/dim 3.6760(3.6797) | Xent 0.0999(0.1162) | Loss 8.9277(9.7055) | Error 0.0319(0.0393) Steps 640(664.43) | Grad Norm 3.4652(5.4484) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0326 | Time 24.7581, Epoch Time 425.6161(435.0614), Bit/dim 3.7038(best: 3.7027), Xent 3.0744, Loss 5.2410, Error 0.4537(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1957 | Time 67.5243(64.9407) | Bit/dim 3.6735(3.6795) | Xent 0.0947(0.1156) | Loss 13.7218(9.8260) | Error 0.0316(0.0391) Steps 664(664.42) | Grad Norm 4.1784(5.4103) | Total Time 0.00(0.00)\n",
      "Iter 1958 | Time 63.7675(64.9055) | Bit/dim 3.6657(3.6791) | Xent 0.1032(0.1152) | Loss 8.7143(9.7927) | Error 0.0361(0.0390) Steps 646(663.87) | Grad Norm 3.6431(5.3573) | Total Time 0.00(0.00)\n",
      "Iter 1959 | Time 62.7556(64.8410) | Bit/dim 3.6903(3.6795) | Xent 0.0997(0.1147) | Loss 9.0867(9.7715) | Error 0.0363(0.0389) Steps 670(664.05) | Grad Norm 6.3537(5.3872) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 65.2275(64.8526) | Bit/dim 3.6745(3.6793) | Xent 0.1048(0.1144) | Loss 9.0691(9.7504) | Error 0.0339(0.0388) Steps 694(664.95) | Grad Norm 8.5786(5.4830) | Total Time 0.00(0.00)\n",
      "Iter 1961 | Time 65.1094(64.8603) | Bit/dim 3.6783(3.6793) | Xent 0.1055(0.1142) | Loss 9.0401(9.7291) | Error 0.0359(0.0387) Steps 658(664.74) | Grad Norm 7.2538(5.5361) | Total Time 0.00(0.00)\n",
      "Iter 1962 | Time 66.1766(64.8998) | Bit/dim 3.6765(3.6792) | Xent 0.0996(0.1137) | Loss 9.0508(9.7088) | Error 0.0314(0.0385) Steps 664(664.72) | Grad Norm 4.2184(5.4965) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0327 | Time 24.5726, Epoch Time 434.0107(435.0299), Bit/dim 3.7030(best: 3.7027), Xent 3.0188, Loss 5.2124, Error 0.4543(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1963 | Time 65.9971(64.9327) | Bit/dim 3.6661(3.6788) | Xent 0.1193(0.1139) | Loss 14.0004(9.8375) | Error 0.0414(0.0386) Steps 664(664.70) | Grad Norm 12.1208(5.6953) | Total Time 0.00(0.00)\n",
      "Iter 1964 | Time 63.4651(64.8887) | Bit/dim 3.6701(3.6785) | Xent 0.1610(0.1153) | Loss 9.0571(9.8141) | Error 0.0541(0.0390) Steps 658(664.50) | Grad Norm 15.8523(6.0000) | Total Time 0.00(0.00)\n",
      "Iter 1965 | Time 67.9148(64.9795) | Bit/dim 3.6773(3.6785) | Xent 0.1636(0.1168) | Loss 9.1584(9.7944) | Error 0.0577(0.0396) Steps 682(665.02) | Grad Norm 14.5582(6.2567) | Total Time 0.00(0.00)\n",
      "Iter 1966 | Time 58.8233(64.7948) | Bit/dim 3.6726(3.6783) | Xent 0.1489(0.1177) | Loss 9.0812(9.7730) | Error 0.0535(0.0400) Steps 634(664.09) | Grad Norm 11.6055(6.4172) | Total Time 0.00(0.00)\n",
      "Iter 1967 | Time 66.3526(64.8415) | Bit/dim 3.6907(3.6787) | Xent 0.1879(0.1198) | Loss 9.0300(9.7507) | Error 0.0655(0.0408) Steps 670(664.27) | Grad Norm 15.7961(6.6986) | Total Time 0.00(0.00)\n",
      "Iter 1968 | Time 62.9539(64.7849) | Bit/dim 3.6918(3.6791) | Xent 0.1617(0.1211) | Loss 8.8988(9.7252) | Error 0.0570(0.0413) Steps 676(664.62) | Grad Norm 14.1337(6.9216) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0328 | Time 24.6209, Epoch Time 429.0339(434.8500), Bit/dim 3.7074(best: 3.7027), Xent 2.8868, Loss 5.1508, Error 0.4533(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1969 | Time 64.0334(64.7623) | Bit/dim 3.6686(3.6788) | Xent 0.1274(0.1213) | Loss 12.9891(9.8231) | Error 0.0413(0.0413) Steps 682(665.14) | Grad Norm 6.2981(6.9029) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 66.1191(64.8031) | Bit/dim 3.6840(3.6789) | Xent 0.1234(0.1213) | Loss 8.7426(9.7907) | Error 0.0410(0.0413) Steps 664(665.11) | Grad Norm 5.8993(6.8728) | Total Time 0.00(0.00)\n",
      "Iter 1971 | Time 61.2595(64.6967) | Bit/dim 3.6787(3.6789) | Xent 0.1402(0.1219) | Loss 9.0370(9.7681) | Error 0.0466(0.0414) Steps 670(665.25) | Grad Norm 9.7504(6.9591) | Total Time 0.00(0.00)\n",
      "Iter 1972 | Time 67.1977(64.7718) | Bit/dim 3.6832(3.6791) | Xent 0.1259(0.1220) | Loss 8.8183(9.7396) | Error 0.0439(0.0415) Steps 658(665.04) | Grad Norm 7.8720(6.9865) | Total Time 0.00(0.00)\n",
      "Iter 1973 | Time 68.0589(64.8704) | Bit/dim 3.6742(3.6789) | Xent 0.1324(0.1223) | Loss 9.0389(9.7186) | Error 0.0436(0.0416) Steps 676(665.37) | Grad Norm 7.7122(7.0083) | Total Time 0.00(0.00)\n",
      "Iter 1974 | Time 64.9705(64.8734) | Bit/dim 3.6887(3.6792) | Xent 0.1138(0.1221) | Loss 8.9499(9.6955) | Error 0.0391(0.0415) Steps 670(665.50) | Grad Norm 8.5755(7.0553) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0329 | Time 25.2760, Epoch Time 435.5420(434.8708), Bit/dim 3.7081(best: 3.7027), Xent 3.0137, Loss 5.2149, Error 0.4521(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1975 | Time 64.2780(64.8555) | Bit/dim 3.6850(3.6794) | Xent 0.1194(0.1220) | Loss 13.5661(9.8116) | Error 0.0396(0.0414) Steps 646(664.92) | Grad Norm 6.4073(7.0359) | Total Time 0.00(0.00)\n",
      "Iter 1976 | Time 68.5813(64.9673) | Bit/dim 3.6785(3.6794) | Xent 0.1088(0.1216) | Loss 9.0921(9.7900) | Error 0.0344(0.0412) Steps 646(664.35) | Grad Norm 4.2075(6.9510) | Total Time 0.00(0.00)\n",
      "Iter 1977 | Time 67.0241(65.0290) | Bit/dim 3.6648(3.6789) | Xent 0.1230(0.1216) | Loss 8.9994(9.7663) | Error 0.0417(0.0412) Steps 646(663.80) | Grad Norm 6.4675(6.9365) | Total Time 0.00(0.00)\n",
      "Iter 1978 | Time 66.4693(65.0722) | Bit/dim 3.6893(3.6792) | Xent 0.1106(0.1213) | Loss 9.0061(9.7435) | Error 0.0371(0.0411) Steps 664(663.81) | Grad Norm 6.2327(6.9154) | Total Time 0.00(0.00)\n",
      "Iter 1979 | Time 62.7509(65.0026) | Bit/dim 3.6764(3.6791) | Xent 0.1097(0.1210) | Loss 8.5894(9.7089) | Error 0.0370(0.0410) Steps 658(663.63) | Grad Norm 5.5012(6.8730) | Total Time 0.00(0.00)\n",
      "Iter 1980 | Time 66.7006(65.0535) | Bit/dim 3.6684(3.6788) | Xent 0.1112(0.1207) | Loss 8.8869(9.6842) | Error 0.0387(0.0409) Steps 682(664.18) | Grad Norm 6.4194(6.8594) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0330 | Time 24.7077, Epoch Time 439.6984(435.0156), Bit/dim 3.7012(best: 3.7027), Xent 2.9984, Loss 5.2003, Error 0.4472(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1981 | Time 63.1929(64.9977) | Bit/dim 3.6706(3.6786) | Xent 0.1097(0.1203) | Loss 13.1828(9.7892) | Error 0.0336(0.0407) Steps 664(664.18) | Grad Norm 4.7243(6.7953) | Total Time 0.00(0.00)\n",
      "Iter 1982 | Time 69.9028(65.1449) | Bit/dim 3.6836(3.6787) | Xent 0.1210(0.1204) | Loss 8.9402(9.7637) | Error 0.0415(0.0407) Steps 688(664.89) | Grad Norm 6.0677(6.7735) | Total Time 0.00(0.00)\n",
      "Iter 1983 | Time 58.9380(64.9586) | Bit/dim 3.6876(3.6790) | Xent 0.0997(0.1197) | Loss 8.9692(9.7399) | Error 0.0333(0.0405) Steps 634(663.97) | Grad Norm 4.0074(6.6905) | Total Time 0.00(0.00)\n",
      "Iter 1984 | Time 65.1197(64.9635) | Bit/dim 3.6802(3.6790) | Xent 0.1198(0.1197) | Loss 8.9903(9.7174) | Error 0.0430(0.0406) Steps 676(664.33) | Grad Norm 5.4085(6.6520) | Total Time 0.00(0.00)\n",
      "Iter 1985 | Time 69.1602(65.0894) | Bit/dim 3.6653(3.6786) | Xent 0.1055(0.1193) | Loss 8.8628(9.6918) | Error 0.0353(0.0404) Steps 688(665.04) | Grad Norm 5.5530(6.6191) | Total Time 0.00(0.00)\n",
      "Iter 1986 | Time 67.8647(65.1726) | Bit/dim 3.6761(3.6785) | Xent 0.1076(0.1190) | Loss 8.8597(9.6668) | Error 0.0377(0.0403) Steps 658(664.83) | Grad Norm 6.1569(6.6052) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0331 | Time 24.7921, Epoch Time 437.5703(435.0922), Bit/dim 3.7023(best: 3.7012), Xent 2.9962, Loss 5.2004, Error 0.4525(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1987 | Time 66.5422(65.2137) | Bit/dim 3.6689(3.6782) | Xent 0.1077(0.1186) | Loss 13.9608(9.7956) | Error 0.0355(0.0402) Steps 658(664.62) | Grad Norm 3.7272(6.5189) | Total Time 0.00(0.00)\n",
      "Iter 1988 | Time 67.8481(65.2928) | Bit/dim 3.6702(3.6780) | Xent 0.1102(0.1184) | Loss 8.9047(9.7689) | Error 0.0371(0.0401) Steps 676(664.96) | Grad Norm 5.8165(6.4978) | Total Time 0.00(0.00)\n",
      "Iter 1989 | Time 62.0044(65.1941) | Bit/dim 3.6744(3.6779) | Xent 0.1054(0.1180) | Loss 8.8355(9.7409) | Error 0.0344(0.0399) Steps 688(665.65) | Grad Norm 5.7474(6.4753) | Total Time 0.00(0.00)\n",
      "Iter 1990 | Time 62.4616(65.1121) | Bit/dim 3.6859(3.6781) | Xent 0.0970(0.1174) | Loss 8.9703(9.7178) | Error 0.0330(0.0397) Steps 646(665.06) | Grad Norm 3.7957(6.3949) | Total Time 0.00(0.00)\n",
      "Iter 1991 | Time 65.4447(65.1221) | Bit/dim 3.6752(3.6780) | Xent 0.0964(0.1167) | Loss 8.9590(9.6950) | Error 0.0329(0.0395) Steps 652(664.67) | Grad Norm 5.1826(6.3585) | Total Time 0.00(0.00)\n",
      "Iter 1992 | Time 63.5879(65.0761) | Bit/dim 3.6851(3.6783) | Xent 0.1075(0.1165) | Loss 9.0207(9.6748) | Error 0.0357(0.0394) Steps 640(663.93) | Grad Norm 4.7368(6.3099) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0332 | Time 24.4955, Epoch Time 431.1034(434.9726), Bit/dim 3.7091(best: 3.7012), Xent 3.0725, Loss 5.2453, Error 0.4558(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1993 | Time 58.8116(64.8881) | Bit/dim 3.6889(3.6786) | Xent 0.1093(0.1162) | Loss 13.9522(9.8031) | Error 0.0351(0.0393) Steps 664(663.93) | Grad Norm 5.6564(6.2903) | Total Time 0.00(0.00)\n",
      "Iter 1994 | Time 65.8341(64.9165) | Bit/dim 3.6802(3.6786) | Xent 0.0889(0.1154) | Loss 8.8362(9.7741) | Error 0.0302(0.0390) Steps 664(663.94) | Grad Norm 3.1976(6.1975) | Total Time 0.00(0.00)\n",
      "Iter 1995 | Time 68.7327(65.0310) | Bit/dim 3.6635(3.6782) | Xent 0.1172(0.1155) | Loss 9.0912(9.7536) | Error 0.0396(0.0390) Steps 694(664.84) | Grad Norm 8.0915(6.2543) | Total Time 0.00(0.00)\n",
      "Iter 1996 | Time 67.3830(65.1016) | Bit/dim 3.6882(3.6785) | Xent 0.1540(0.1166) | Loss 9.0142(9.7314) | Error 0.0541(0.0395) Steps 652(664.45) | Grad Norm 15.4960(6.5316) | Total Time 0.00(0.00)\n",
      "Iter 1997 | Time 60.2121(64.9549) | Bit/dim 3.6683(3.6782) | Xent 0.2243(0.1199) | Loss 9.0544(9.7111) | Error 0.0765(0.0406) Steps 658(664.26) | Grad Norm 21.0836(6.9681) | Total Time 0.00(0.00)\n",
      "Iter 1998 | Time 65.5067(64.9714) | Bit/dim 3.6786(3.6782) | Xent 0.3138(0.1257) | Loss 9.0909(9.6925) | Error 0.1086(0.0426) Steps 688(664.97) | Grad Norm 23.7662(7.4721) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 24.6542, Epoch Time 430.2178(434.8299), Bit/dim 3.7070(best: 3.7012), Xent 2.6839, Loss 5.0490, Error 0.4486(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1999 | Time 60.2381(64.8294) | Bit/dim 3.6816(3.6783) | Xent 0.1399(0.1261) | Loss 13.5532(9.8083) | Error 0.0471(0.0428) Steps 646(664.40) | Grad Norm 7.3587(7.4687) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 68.1808(64.9300) | Bit/dim 3.6775(3.6783) | Xent 0.2217(0.1290) | Loss 9.0483(9.7855) | Error 0.0780(0.0438) Steps 694(665.29) | Grad Norm 13.3752(7.6459) | Total Time 0.00(0.00)\n",
      "Iter 2001 | Time 70.7358(65.1042) | Bit/dim 3.6907(3.6786) | Xent 0.2777(0.1334) | Loss 9.1625(9.7668) | Error 0.0920(0.0453) Steps 670(665.43) | Grad Norm 15.3721(7.8776) | Total Time 0.00(0.00)\n",
      "Iter 2002 | Time 66.0516(65.1326) | Bit/dim 3.6834(3.6788) | Xent 0.1855(0.1350) | Loss 8.8526(9.7394) | Error 0.0631(0.0458) Steps 652(665.03) | Grad Norm 14.9534(8.0899) | Total Time 0.00(0.00)\n",
      "Iter 2003 | Time 62.7293(65.0605) | Bit/dim 3.6967(3.6793) | Xent 0.3189(0.1405) | Loss 9.2279(9.7241) | Error 0.1134(0.0478) Steps 658(664.82) | Grad Norm 16.8183(8.3518) | Total Time 0.00(0.00)\n",
      "Iter 2004 | Time 63.3668(65.0097) | Bit/dim 3.6820(3.6794) | Xent 0.1945(0.1421) | Loss 8.9898(9.7020) | Error 0.0695(0.0485) Steps 658(664.61) | Grad Norm 14.3016(8.5303) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 24.8369, Epoch Time 434.6079(434.8233), Bit/dim 3.7164(best: 3.7012), Xent 2.7146, Loss 5.0737, Error 0.4556(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2005 | Time 64.7103(65.0007) | Bit/dim 3.6827(3.6795) | Xent 0.2140(0.1443) | Loss 13.6363(9.8201) | Error 0.0754(0.0493) Steps 682(665.13) | Grad Norm 15.2065(8.7305) | Total Time 0.00(0.00)\n",
      "Iter 2006 | Time 60.8565(64.8764) | Bit/dim 3.6797(3.6795) | Xent 0.1791(0.1453) | Loss 9.0500(9.7970) | Error 0.0620(0.0497) Steps 640(664.38) | Grad Norm 7.3707(8.6898) | Total Time 0.00(0.00)\n",
      "Iter 2007 | Time 63.3288(64.8299) | Bit/dim 3.6850(3.6797) | Xent 0.2040(0.1471) | Loss 8.8958(9.7699) | Error 0.0735(0.0504) Steps 664(664.37) | Grad Norm 11.8235(8.7838) | Total Time 0.00(0.00)\n",
      "Iter 2008 | Time 67.0654(64.8970) | Bit/dim 3.6816(3.6797) | Xent 0.1849(0.1482) | Loss 8.9002(9.7438) | Error 0.0635(0.0508) Steps 688(665.08) | Grad Norm 12.3050(8.8894) | Total Time 0.00(0.00)\n",
      "Iter 2009 | Time 62.6083(64.8283) | Bit/dim 3.6881(3.6800) | Xent 0.1655(0.1487) | Loss 9.0357(9.7226) | Error 0.0556(0.0509) Steps 646(664.51) | Grad Norm 9.5053(8.9079) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 62.6188(64.7621) | Bit/dim 3.6833(3.6801) | Xent 0.1650(0.1492) | Loss 8.7886(9.6946) | Error 0.0581(0.0511) Steps 658(664.31) | Grad Norm 10.6684(8.9607) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 24.3245, Epoch Time 424.3608(434.5094), Bit/dim 3.7166(best: 3.7012), Xent 2.9405, Loss 5.1869, Error 0.4646(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2011 | Time 68.9873(64.8888) | Bit/dim 3.6977(3.6806) | Xent 0.1535(0.1494) | Loss 13.6180(9.8123) | Error 0.0540(0.0512) Steps 694(665.20) | Grad Norm 10.4706(9.0060) | Total Time 0.00(0.00)\n",
      "Iter 2012 | Time 63.7636(64.8551) | Bit/dim 3.6624(3.6801) | Xent 0.1430(0.1492) | Loss 9.0839(9.7904) | Error 0.0483(0.0511) Steps 640(664.45) | Grad Norm 8.1208(8.9794) | Total Time 0.00(0.00)\n",
      "Iter 2013 | Time 63.3814(64.8108) | Bit/dim 3.6889(3.6803) | Xent 0.1346(0.1487) | Loss 8.8076(9.7609) | Error 0.0453(0.0510) Steps 676(664.79) | Grad Norm 6.5044(8.9052) | Total Time 0.00(0.00)\n",
      "Iter 2014 | Time 60.7349(64.6886) | Bit/dim 3.6849(3.6805) | Xent 0.1498(0.1488) | Loss 9.0112(9.7384) | Error 0.0527(0.0510) Steps 664(664.77) | Grad Norm 8.1827(8.8835) | Total Time 0.00(0.00)\n",
      "Iter 2015 | Time 70.2395(64.8551) | Bit/dim 3.6831(3.6805) | Xent 0.1285(0.1482) | Loss 9.0763(9.7186) | Error 0.0423(0.0507) Steps 664(664.75) | Grad Norm 8.2268(8.8638) | Total Time 0.00(0.00)\n",
      "Iter 2016 | Time 61.9848(64.7690) | Bit/dim 3.6913(3.6809) | Xent 0.1232(0.1474) | Loss 8.6682(9.6871) | Error 0.0389(0.0504) Steps 640(664.00) | Grad Norm 9.1260(8.8717) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 24.4203, Epoch Time 432.5612(434.4509), Bit/dim 3.7122(best: 3.7012), Xent 2.9461, Loss 5.1852, Error 0.4528(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2017 | Time 62.1820(64.6914) | Bit/dim 3.6860(3.6810) | Xent 0.1190(0.1466) | Loss 13.2833(9.7950) | Error 0.0376(0.0500) Steps 640(663.28) | Grad Norm 5.6359(8.7746) | Total Time 0.00(0.00)\n",
      "Iter 2018 | Time 58.3537(64.5012) | Bit/dim 3.6850(3.6811) | Xent 0.1177(0.1457) | Loss 8.9082(9.7684) | Error 0.0386(0.0497) Steps 664(663.30) | Grad Norm 6.4206(8.7040) | Total Time 0.00(0.00)\n",
      "Iter 2019 | Time 61.9731(64.4254) | Bit/dim 3.6753(3.6810) | Xent 0.1225(0.1450) | Loss 8.8978(9.7422) | Error 0.0401(0.0494) Steps 664(663.33) | Grad Norm 4.8669(8.5889) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 69.0748(64.5649) | Bit/dim 3.6942(3.6814) | Xent 0.1076(0.1439) | Loss 8.9859(9.7195) | Error 0.0360(0.0490) Steps 652(662.99) | Grad Norm 4.5168(8.4667) | Total Time 0.00(0.00)\n",
      "Iter 2021 | Time 70.1939(64.7338) | Bit/dim 3.6780(3.6813) | Xent 0.0997(0.1425) | Loss 9.1236(9.7017) | Error 0.0340(0.0485) Steps 658(662.84) | Grad Norm 4.3483(8.3432) | Total Time 0.00(0.00)\n",
      "Iter 2022 | Time 61.0677(64.6238) | Bit/dim 3.6769(3.6811) | Xent 0.1112(0.1416) | Loss 8.9546(9.6793) | Error 0.0381(0.0482) Steps 652(662.51) | Grad Norm 6.2864(8.2815) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 24.1718, Epoch Time 425.7903(434.1911), Bit/dim 3.7047(best: 3.7012), Xent 2.9449, Loss 5.1772, Error 0.4533(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2023 | Time 64.2249(64.6118) | Bit/dim 3.6757(3.6810) | Xent 0.1076(0.1406) | Loss 13.9647(9.8078) | Error 0.0336(0.0478) Steps 676(662.92) | Grad Norm 4.4776(8.1673) | Total Time 0.00(0.00)\n",
      "Iter 2024 | Time 61.6195(64.5220) | Bit/dim 3.6821(3.6810) | Xent 0.1143(0.1398) | Loss 8.9085(9.7808) | Error 0.0379(0.0475) Steps 628(661.87) | Grad Norm 5.2274(8.0791) | Total Time 0.00(0.00)\n",
      "Iter 2025 | Time 58.6986(64.3473) | Bit/dim 3.6776(3.6809) | Xent 0.0953(0.1385) | Loss 9.0313(9.7584) | Error 0.0331(0.0471) Steps 670(662.11) | Grad Norm 4.0750(7.9590) | Total Time 0.00(0.00)\n",
      "Iter 2026 | Time 61.6035(64.2650) | Bit/dim 3.6707(3.6806) | Xent 0.1028(0.1374) | Loss 8.8714(9.7317) | Error 0.0339(0.0467) Steps 646(661.63) | Grad Norm 4.9827(7.8697) | Total Time 0.00(0.00)\n",
      "Iter 2027 | Time 61.9856(64.1966) | Bit/dim 3.6854(3.6807) | Xent 0.0898(0.1360) | Loss 8.9443(9.7081) | Error 0.0289(0.0461) Steps 664(661.70) | Grad Norm 2.9574(7.7224) | Total Time 0.00(0.00)\n",
      "Iter 2028 | Time 63.7000(64.1817) | Bit/dim 3.6846(3.6809) | Xent 0.0948(0.1347) | Loss 8.7995(9.6809) | Error 0.0336(0.0457) Steps 688(662.49) | Grad Norm 3.9259(7.6085) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 24.5277, Epoch Time 415.1569(433.6201), Bit/dim 3.6969(best: 3.7012), Xent 2.9891, Loss 5.1915, Error 0.4531(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2029 | Time 62.5324(64.1323) | Bit/dim 3.6881(3.6811) | Xent 0.0944(0.1335) | Loss 13.7907(9.8042) | Error 0.0304(0.0453) Steps 658(662.35) | Grad Norm 3.0062(7.4704) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 63.1623(64.1032) | Bit/dim 3.6538(3.6803) | Xent 0.0882(0.1322) | Loss 8.9008(9.7771) | Error 0.0294(0.0448) Steps 682(662.94) | Grad Norm 3.9295(7.3642) | Total Time 0.00(0.00)\n",
      "Iter 2031 | Time 64.9357(64.1281) | Bit/dim 3.6655(3.6798) | Xent 0.0991(0.1312) | Loss 8.9465(9.7521) | Error 0.0336(0.0445) Steps 682(663.52) | Grad Norm 3.5404(7.2495) | Total Time 0.00(0.00)\n",
      "Iter 2032 | Time 66.0973(64.1872) | Bit/dim 3.6797(3.6798) | Xent 0.0857(0.1298) | Loss 8.9810(9.7290) | Error 0.0276(0.0440) Steps 652(663.17) | Grad Norm 3.4074(7.1342) | Total Time 0.00(0.00)\n",
      "Iter 2033 | Time 64.4548(64.1952) | Bit/dim 3.6784(3.6798) | Xent 0.1015(0.1290) | Loss 8.8565(9.7028) | Error 0.0335(0.0437) Steps 640(662.47) | Grad Norm 5.1755(7.0754) | Total Time 0.00(0.00)\n",
      "Iter 2034 | Time 64.5531(64.2060) | Bit/dim 3.6728(3.6796) | Xent 0.0879(0.1277) | Loss 8.9956(9.6816) | Error 0.0296(0.0432) Steps 664(662.52) | Grad Norm 3.9552(6.9818) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 25.3758, Epoch Time 429.8238(433.5062), Bit/dim 3.7047(best: 3.6969), Xent 3.0768, Loss 5.2431, Error 0.4519(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2035 | Time 59.2958(64.0587) | Bit/dim 3.6649(3.6791) | Xent 0.0883(0.1265) | Loss 13.8280(9.8060) | Error 0.0292(0.0428) Steps 652(662.20) | Grad Norm 6.5545(6.9690) | Total Time 0.00(0.00)\n",
      "Iter 2036 | Time 64.6526(64.0765) | Bit/dim 3.6701(3.6788) | Xent 0.0894(0.1254) | Loss 9.0914(9.7846) | Error 0.0289(0.0424) Steps 676(662.62) | Grad Norm 4.7595(6.9027) | Total Time 0.00(0.00)\n",
      "Iter 2037 | Time 62.0972(64.0171) | Bit/dim 3.6744(3.6787) | Xent 0.0937(0.1245) | Loss 9.0207(9.7617) | Error 0.0337(0.0421) Steps 688(663.38) | Grad Norm 5.4515(6.8592) | Total Time 0.00(0.00)\n",
      "Iter 2038 | Time 63.8134(64.0110) | Bit/dim 3.6706(3.6785) | Xent 0.0870(0.1233) | Loss 9.0088(9.7391) | Error 0.0282(0.0417) Steps 640(662.68) | Grad Norm 5.8334(6.8284) | Total Time 0.00(0.00)\n",
      "Iter 2039 | Time 63.4447(63.9940) | Bit/dim 3.6858(3.6787) | Xent 0.0858(0.1222) | Loss 8.9740(9.7161) | Error 0.0270(0.0413) Steps 670(662.90) | Grad Norm 3.3746(6.7248) | Total Time 0.00(0.00)\n",
      "Iter 2040 | Time 61.6071(63.9224) | Bit/dim 3.6763(3.6786) | Xent 0.0979(0.1215) | Loss 8.9621(9.6935) | Error 0.0329(0.0410) Steps 664(662.93) | Grad Norm 8.0762(6.7653) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 24.8826, Epoch Time 418.8238(433.0657), Bit/dim 3.7004(best: 3.6969), Xent 3.0859, Loss 5.2434, Error 0.4549(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2041 | Time 62.0051(63.8649) | Bit/dim 3.6797(3.6786) | Xent 0.0875(0.1205) | Loss 13.6427(9.8120) | Error 0.0284(0.0406) Steps 676(663.32) | Grad Norm 6.5470(6.7588) | Total Time 0.00(0.00)\n",
      "Iter 2042 | Time 61.1859(63.7845) | Bit/dim 3.6823(3.6788) | Xent 0.0855(0.1194) | Loss 8.9635(9.7865) | Error 0.0282(0.0403) Steps 658(663.16) | Grad Norm 4.1269(6.6798) | Total Time 0.00(0.00)\n",
      "Iter 2043 | Time 59.4792(63.6554) | Bit/dim 3.6751(3.6786) | Xent 0.0911(0.1186) | Loss 8.6854(9.7535) | Error 0.0296(0.0400) Steps 664(663.19) | Grad Norm 3.3746(6.5807) | Total Time 0.00(0.00)\n",
      "Iter 2044 | Time 64.2202(63.6723) | Bit/dim 3.6642(3.6782) | Xent 0.0793(0.1174) | Loss 9.0001(9.7309) | Error 0.0235(0.0395) Steps 658(663.03) | Grad Norm 3.1664(6.4782) | Total Time 0.00(0.00)\n",
      "Iter 2045 | Time 65.1293(63.7160) | Bit/dim 3.6618(3.6777) | Xent 0.0926(0.1167) | Loss 8.9077(9.7062) | Error 0.0311(0.0392) Steps 688(663.78) | Grad Norm 5.2809(6.4423) | Total Time 0.00(0.00)\n",
      "Iter 2046 | Time 57.0115(63.5149) | Bit/dim 3.6708(3.6775) | Xent 0.0926(0.1159) | Loss 9.0585(9.6868) | Error 0.0296(0.0389) Steps 664(663.79) | Grad Norm 5.4097(6.4113) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 24.8769, Epoch Time 412.0653(432.4357), Bit/dim 3.7037(best: 3.6969), Xent 3.0776, Loss 5.2425, Error 0.4547(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2047 | Time 63.0152(63.4999) | Bit/dim 3.6692(3.6773) | Xent 0.0864(0.1150) | Loss 13.8600(9.8120) | Error 0.0304(0.0387) Steps 664(663.80) | Grad Norm 5.5464(6.3854) | Total Time 0.00(0.00)\n",
      "Iter 2048 | Time 62.8230(63.4796) | Bit/dim 3.6796(3.6773) | Xent 0.0830(0.1141) | Loss 8.7169(9.7791) | Error 0.0285(0.0384) Steps 670(663.98) | Grad Norm 3.9231(6.3115) | Total Time 0.00(0.00)\n",
      "Iter 2049 | Time 62.5350(63.4512) | Bit/dim 3.6803(3.6774) | Xent 0.0909(0.1134) | Loss 9.0591(9.7575) | Error 0.0285(0.0381) Steps 664(663.98) | Grad Norm 4.6233(6.2609) | Total Time 0.00(0.00)\n",
      "Iter 2050 | Time 65.3932(63.5095) | Bit/dim 3.6645(3.6770) | Xent 0.0710(0.1121) | Loss 8.9653(9.7337) | Error 0.0239(0.0376) Steps 664(663.98) | Grad Norm 4.4933(6.2079) | Total Time 0.00(0.00)\n",
      "Iter 2051 | Time 63.7910(63.5179) | Bit/dim 3.6687(3.6768) | Xent 0.0825(0.1112) | Loss 9.0109(9.7121) | Error 0.0280(0.0374) Steps 670(664.16) | Grad Norm 3.4238(6.1243) | Total Time 0.00(0.00)\n",
      "Iter 2052 | Time 67.4633(63.6363) | Bit/dim 3.6740(3.6767) | Xent 0.0778(0.1102) | Loss 8.9923(9.6905) | Error 0.0251(0.0370) Steps 682(664.70) | Grad Norm 6.0049(6.1207) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 24.5435, Epoch Time 428.3216(432.3123), Bit/dim 3.7049(best: 3.6969), Xent 3.1385, Loss 5.2742, Error 0.4541(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2053 | Time 60.6662(63.5472) | Bit/dim 3.6608(3.6762) | Xent 0.0799(0.1093) | Loss 13.6241(9.8085) | Error 0.0272(0.0367) Steps 664(664.68) | Grad Norm 5.4380(6.1003) | Total Time 0.00(0.00)\n",
      "Iter 2054 | Time 61.5867(63.4884) | Bit/dim 3.6804(3.6763) | Xent 0.0810(0.1085) | Loss 8.8346(9.7793) | Error 0.0269(0.0364) Steps 658(664.48) | Grad Norm 3.3602(6.0181) | Total Time 0.00(0.00)\n",
      "Iter 2055 | Time 64.2186(63.5103) | Bit/dim 3.6695(3.6761) | Xent 0.0724(0.1074) | Loss 8.9207(9.7535) | Error 0.0229(0.0360) Steps 664(664.46) | Grad Norm 3.1241(5.9312) | Total Time 0.00(0.00)\n",
      "Iter 2056 | Time 63.4187(63.5075) | Bit/dim 3.6796(3.6762) | Xent 0.0801(0.1066) | Loss 8.7780(9.7242) | Error 0.0252(0.0357) Steps 652(664.09) | Grad Norm 3.1142(5.8467) | Total Time 0.00(0.00)\n",
      "Iter 2057 | Time 65.3772(63.5636) | Bit/dim 3.6655(3.6759) | Xent 0.0727(0.1055) | Loss 8.8046(9.6966) | Error 0.0235(0.0353) Steps 682(664.63) | Grad Norm 3.5246(5.7771) | Total Time 0.00(0.00)\n",
      "Iter 2058 | Time 68.2328(63.7037) | Bit/dim 3.6731(3.6758) | Xent 0.0830(0.1049) | Loss 9.1037(9.6789) | Error 0.0281(0.0351) Steps 646(664.07) | Grad Norm 3.4147(5.7062) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 24.6679, Epoch Time 426.8384(432.1481), Bit/dim 3.7030(best: 3.6969), Xent 3.1849, Loss 5.2955, Error 0.4532(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2059 | Time 66.3296(63.7825) | Bit/dim 3.6701(3.6757) | Xent 0.0824(0.1042) | Loss 13.6789(9.7989) | Error 0.0271(0.0349) Steps 652(663.71) | Grad Norm 3.4013(5.6371) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 62.6221(63.7477) | Bit/dim 3.6587(3.6752) | Xent 0.0798(0.1035) | Loss 8.8414(9.7701) | Error 0.0266(0.0346) Steps 664(663.71) | Grad Norm 3.3089(5.5672) | Total Time 0.00(0.00)\n",
      "Iter 2061 | Time 64.6472(63.7747) | Bit/dim 3.6776(3.6752) | Xent 0.0920(0.1031) | Loss 8.8717(9.7432) | Error 0.0319(0.0345) Steps 688(664.44) | Grad Norm 3.5090(5.5055) | Total Time 0.00(0.00)\n",
      "Iter 2062 | Time 58.1649(63.6064) | Bit/dim 3.6579(3.6747) | Xent 0.0845(0.1026) | Loss 8.9020(9.7179) | Error 0.0295(0.0344) Steps 658(664.25) | Grad Norm 4.5307(5.4762) | Total Time 0.00(0.00)\n",
      "Iter 2063 | Time 62.0350(63.5592) | Bit/dim 3.6805(3.6749) | Xent 0.0793(0.1019) | Loss 8.8057(9.6906) | Error 0.0254(0.0341) Steps 664(664.24) | Grad Norm 7.0541(5.5236) | Total Time 0.00(0.00)\n",
      "Iter 2064 | Time 62.5693(63.5295) | Bit/dim 3.6788(3.6750) | Xent 0.0844(0.1013) | Loss 8.7980(9.6638) | Error 0.0291(0.0340) Steps 658(664.05) | Grad Norm 4.4646(5.4918) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 24.7424, Epoch Time 419.4908(431.7684), Bit/dim 3.7029(best: 3.6969), Xent 3.1634, Loss 5.2846, Error 0.4530(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2065 | Time 64.0845(63.5462) | Bit/dim 3.6746(3.6750) | Xent 0.0737(0.1005) | Loss 13.6487(9.7833) | Error 0.0226(0.0336) Steps 670(664.23) | Grad Norm 3.2460(5.4244) | Total Time 0.00(0.00)\n",
      "Iter 2066 | Time 64.0972(63.5627) | Bit/dim 3.6605(3.6746) | Xent 0.0823(0.1000) | Loss 9.0839(9.7624) | Error 0.0250(0.0334) Steps 682(664.77) | Grad Norm 2.6644(5.3416) | Total Time 0.00(0.00)\n",
      "Iter 2067 | Time 61.7528(63.5084) | Bit/dim 3.6631(3.6742) | Xent 0.0860(0.0995) | Loss 8.9273(9.7373) | Error 0.0295(0.0332) Steps 670(664.92) | Grad Norm 5.5236(5.3471) | Total Time 0.00(0.00)\n",
      "Iter 2068 | Time 65.1250(63.5569) | Bit/dim 3.6845(3.6745) | Xent 0.0955(0.0994) | Loss 8.8067(9.7094) | Error 0.0304(0.0332) Steps 658(664.72) | Grad Norm 7.5636(5.4136) | Total Time 0.00(0.00)\n",
      "Iter 2069 | Time 63.8175(63.5647) | Bit/dim 3.6774(3.6746) | Xent 0.0795(0.0988) | Loss 9.1257(9.6919) | Error 0.0254(0.0329) Steps 634(663.79) | Grad Norm 4.1677(5.3762) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 64.1777(63.5831) | Bit/dim 3.6649(3.6743) | Xent 0.0838(0.0984) | Loss 8.8519(9.6667) | Error 0.0274(0.0328) Steps 664(663.80) | Grad Norm 4.3761(5.3462) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 24.8868, Epoch Time 426.5132(431.6107), Bit/dim 3.7001(best: 3.6969), Xent 3.1341, Loss 5.2671, Error 0.4571(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2071 | Time 67.4754(63.6999) | Bit/dim 3.6896(3.6748) | Xent 0.0897(0.0981) | Loss 13.3701(9.7778) | Error 0.0304(0.0327) Steps 646(663.27) | Grad Norm 7.5187(5.4114) | Total Time 0.00(0.00)\n",
      "Iter 2072 | Time 61.2065(63.6251) | Bit/dim 3.6642(3.6745) | Xent 0.0889(0.0978) | Loss 8.9211(9.7521) | Error 0.0316(0.0326) Steps 634(662.39) | Grad Norm 5.5728(5.4162) | Total Time 0.00(0.00)\n",
      "Iter 2073 | Time 67.0583(63.7281) | Bit/dim 3.6753(3.6745) | Xent 0.0814(0.0973) | Loss 8.9674(9.7285) | Error 0.0261(0.0325) Steps 664(662.44) | Grad Norm 4.8422(5.3990) | Total Time 0.00(0.00)\n",
      "Iter 2074 | Time 61.0170(63.6468) | Bit/dim 3.6568(3.6739) | Xent 0.0856(0.0970) | Loss 8.8331(9.7017) | Error 0.0275(0.0323) Steps 670(662.66) | Grad Norm 3.9652(5.3560) | Total Time 0.00(0.00)\n",
      "Iter 2075 | Time 64.1463(63.6617) | Bit/dim 3.6793(3.6741) | Xent 0.0835(0.0966) | Loss 8.9543(9.6793) | Error 0.0270(0.0321) Steps 676(663.06) | Grad Norm 4.4553(5.3290) | Total Time 0.00(0.00)\n",
      "Iter 2076 | Time 66.3707(63.7430) | Bit/dim 3.6727(3.6741) | Xent 0.0822(0.0962) | Loss 8.9875(9.6585) | Error 0.0264(0.0320) Steps 670(663.27) | Grad Norm 4.7563(5.3118) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 24.4234, Epoch Time 430.4053(431.5745), Bit/dim 3.7013(best: 3.6969), Xent 3.2492, Loss 5.3259, Error 0.4599(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2077 | Time 64.6636(63.7706) | Bit/dim 3.6625(3.6737) | Xent 0.0826(0.0958) | Loss 14.0307(9.7897) | Error 0.0285(0.0319) Steps 676(663.65) | Grad Norm 4.0433(5.2737) | Total Time 0.00(0.00)\n",
      "Iter 2078 | Time 61.9957(63.7174) | Bit/dim 3.6639(3.6734) | Xent 0.0852(0.0954) | Loss 8.8407(9.7612) | Error 0.0268(0.0317) Steps 652(663.30) | Grad Norm 4.1085(5.2388) | Total Time 0.00(0.00)\n",
      "Iter 2079 | Time 62.8943(63.6927) | Bit/dim 3.6726(3.6734) | Xent 0.0795(0.0950) | Loss 8.9000(9.7354) | Error 0.0269(0.0316) Steps 664(663.32) | Grad Norm 2.5654(5.1586) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 61.7301(63.6338) | Bit/dim 3.6744(3.6734) | Xent 0.0713(0.0942) | Loss 9.0040(9.7134) | Error 0.0239(0.0313) Steps 682(663.88) | Grad Norm 5.8256(5.1786) | Total Time 0.00(0.00)\n",
      "Iter 2081 | Time 61.6968(63.5757) | Bit/dim 3.6752(3.6735) | Xent 0.0748(0.0937) | Loss 8.7609(9.6849) | Error 0.0265(0.0312) Steps 646(663.35) | Grad Norm 4.7307(5.1651) | Total Time 0.00(0.00)\n",
      "Iter 2082 | Time 59.9287(63.4663) | Bit/dim 3.6856(3.6738) | Xent 0.0760(0.0931) | Loss 8.9882(9.6640) | Error 0.0242(0.0310) Steps 652(663.01) | Grad Norm 5.3825(5.1717) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 23.9753, Epoch Time 415.3022(431.0864), Bit/dim 3.6993(best: 3.6969), Xent 3.2483, Loss 5.3235, Error 0.4550(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2083 | Time 63.2179(63.4588) | Bit/dim 3.6597(3.6734) | Xent 0.0995(0.0933) | Loss 13.6244(9.7828) | Error 0.0346(0.0311) Steps 628(661.96) | Grad Norm 8.8252(5.2813) | Total Time 0.00(0.00)\n",
      "Iter 2084 | Time 67.4564(63.5788) | Bit/dim 3.6670(3.6732) | Xent 0.0947(0.0934) | Loss 8.8593(9.7551) | Error 0.0336(0.0312) Steps 688(662.74) | Grad Norm 6.7493(5.3253) | Total Time 0.00(0.00)\n",
      "Iter 2085 | Time 63.6972(63.5823) | Bit/dim 3.6765(3.6733) | Xent 0.0740(0.0928) | Loss 9.0755(9.7347) | Error 0.0252(0.0310) Steps 652(662.42) | Grad Norm 4.0821(5.2880) | Total Time 0.00(0.00)\n",
      "Iter 2086 | Time 65.2371(63.6320) | Bit/dim 3.6639(3.6730) | Xent 0.0841(0.0925) | Loss 8.7865(9.7062) | Error 0.0261(0.0308) Steps 670(662.64) | Grad Norm 5.2664(5.2874) | Total Time 0.00(0.00)\n",
      "Iter 2087 | Time 67.8952(63.7599) | Bit/dim 3.6782(3.6732) | Xent 0.0974(0.0927) | Loss 9.1782(9.6904) | Error 0.0331(0.0309) Steps 694(663.58) | Grad Norm 9.4179(5.4113) | Total Time 0.00(0.00)\n",
      "Iter 2088 | Time 64.3197(63.7767) | Bit/dim 3.6748(3.6732) | Xent 0.0993(0.0929) | Loss 8.8605(9.6655) | Error 0.0339(0.0310) Steps 664(663.60) | Grad Norm 7.8084(5.4832) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 24.2606, Epoch Time 434.5370(431.1899), Bit/dim 3.7011(best: 3.6969), Xent 3.1005, Loss 5.2513, Error 0.4527(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2089 | Time 67.0223(63.8740) | Bit/dim 3.6684(3.6731) | Xent 0.0757(0.0924) | Loss 13.6568(9.7852) | Error 0.0231(0.0308) Steps 652(663.25) | Grad Norm 3.5391(5.4249) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 66.4056(63.9500) | Bit/dim 3.6673(3.6729) | Xent 0.0859(0.0922) | Loss 9.1002(9.7647) | Error 0.0285(0.0307) Steps 670(663.45) | Grad Norm 6.4373(5.4552) | Total Time 0.00(0.00)\n",
      "Iter 2091 | Time 67.2328(64.0485) | Bit/dim 3.6660(3.6727) | Xent 0.0911(0.0921) | Loss 9.0691(9.7438) | Error 0.0308(0.0307) Steps 694(664.37) | Grad Norm 6.0242(5.4723) | Total Time 0.00(0.00)\n",
      "Iter 2092 | Time 64.4522(64.0606) | Bit/dim 3.6725(3.6727) | Xent 0.0848(0.0919) | Loss 8.9874(9.7211) | Error 0.0275(0.0306) Steps 688(665.08) | Grad Norm 8.7385(5.5703) | Total Time 0.00(0.00)\n",
      "Iter 2093 | Time 65.1132(64.0921) | Bit/dim 3.6764(3.6728) | Xent 0.0761(0.0914) | Loss 9.0760(9.7018) | Error 0.0251(0.0304) Steps 682(665.59) | Grad Norm 6.4662(5.5972) | Total Time 0.00(0.00)\n",
      "Iter 2094 | Time 66.0317(64.1503) | Bit/dim 3.6697(3.6727) | Xent 0.1010(0.0917) | Loss 9.0993(9.6837) | Error 0.0347(0.0306) Steps 646(665.00) | Grad Norm 8.6908(5.6900) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 25.1870, Epoch Time 439.7619(431.4471), Bit/dim 3.7031(best: 3.6969), Xent 3.2656, Loss 5.3359, Error 0.4603(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2095 | Time 69.9741(64.3250) | Bit/dim 3.6592(3.6723) | Xent 0.1055(0.0921) | Loss 13.6068(9.8014) | Error 0.0353(0.0307) Steps 652(664.61) | Grad Norm 11.5376(5.8654) | Total Time 0.00(0.00)\n",
      "Iter 2096 | Time 64.7661(64.3383) | Bit/dim 3.6725(3.6723) | Xent 0.0899(0.0921) | Loss 8.8646(9.7733) | Error 0.0304(0.0307) Steps 664(664.59) | Grad Norm 7.8410(5.9247) | Total Time 0.00(0.00)\n",
      "Iter 2097 | Time 67.7018(64.4392) | Bit/dim 3.6842(3.6727) | Xent 0.0921(0.0921) | Loss 9.0743(9.7523) | Error 0.0306(0.0307) Steps 652(664.21) | Grad Norm 6.1314(5.9309) | Total Time 0.00(0.00)\n",
      "Iter 2098 | Time 64.5512(64.4425) | Bit/dim 3.6628(3.6724) | Xent 0.0871(0.0919) | Loss 8.9237(9.7275) | Error 0.0289(0.0306) Steps 658(664.03) | Grad Norm 8.1120(5.9963) | Total Time 0.00(0.00)\n",
      "Iter 2099 | Time 67.4720(64.5334) | Bit/dim 3.6692(3.6723) | Xent 0.0815(0.0916) | Loss 8.8960(9.7025) | Error 0.0269(0.0305) Steps 670(664.20) | Grad Norm 4.4875(5.9511) | Total Time 0.00(0.00)\n",
      "Iter 2100 | Time 62.3074(64.4666) | Bit/dim 3.6761(3.6724) | Xent 0.0798(0.0913) | Loss 8.9336(9.6794) | Error 0.0249(0.0304) Steps 688(664.92) | Grad Norm 5.5806(5.9399) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 24.5493, Epoch Time 439.9302(431.7015), Bit/dim 3.7002(best: 3.6969), Xent 3.2395, Loss 5.3200, Error 0.4581(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2101 | Time 58.7219(64.2943) | Bit/dim 3.6744(3.6725) | Xent 0.0883(0.0912) | Loss 13.4140(9.7915) | Error 0.0292(0.0303) Steps 652(664.53) | Grad Norm 6.3849(5.9533) | Total Time 0.00(0.00)\n",
      "Iter 2102 | Time 62.6912(64.2462) | Bit/dim 3.6608(3.6721) | Xent 0.0789(0.0908) | Loss 8.8836(9.7642) | Error 0.0252(0.0302) Steps 676(664.87) | Grad Norm 3.5205(5.8803) | Total Time 0.00(0.00)\n",
      "Iter 2103 | Time 64.7267(64.2606) | Bit/dim 3.6572(3.6717) | Xent 0.0877(0.0907) | Loss 9.0056(9.7415) | Error 0.0285(0.0301) Steps 682(665.39) | Grad Norm 5.7080(5.8751) | Total Time 0.00(0.00)\n",
      "Iter 2104 | Time 67.1611(64.3476) | Bit/dim 3.6757(3.6718) | Xent 0.0851(0.0905) | Loss 8.9817(9.7187) | Error 0.0296(0.0301) Steps 670(665.53) | Grad Norm 6.0614(5.8807) | Total Time 0.00(0.00)\n",
      "Iter 2105 | Time 62.1850(64.2828) | Bit/dim 3.6693(3.6717) | Xent 0.0863(0.0904) | Loss 8.9882(9.6968) | Error 0.0290(0.0301) Steps 652(665.12) | Grad Norm 5.3127(5.8637) | Total Time 0.00(0.00)\n",
      "Iter 2106 | Time 63.9797(64.2737) | Bit/dim 3.6671(3.6716) | Xent 0.0692(0.0898) | Loss 8.9756(9.6751) | Error 0.0230(0.0299) Steps 664(665.09) | Grad Norm 2.2134(5.7542) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 24.8296, Epoch Time 422.6015(431.4285), Bit/dim 3.6979(best: 3.6969), Xent 3.2006, Loss 5.2982, Error 0.4544(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2107 | Time 65.1654(64.3004) | Bit/dim 3.6602(3.6712) | Xent 0.0765(0.0894) | Loss 13.7348(9.7969) | Error 0.0249(0.0297) Steps 682(665.59) | Grad Norm 4.9568(5.7303) | Total Time 0.00(0.00)\n",
      "Iter 2108 | Time 68.6993(64.4324) | Bit/dim 3.6722(3.6713) | Xent 0.0723(0.0889) | Loss 8.8801(9.7694) | Error 0.0241(0.0295) Steps 658(665.37) | Grad Norm 5.8975(5.7353) | Total Time 0.00(0.00)\n",
      "Iter 2109 | Time 64.2110(64.4257) | Bit/dim 3.6689(3.6712) | Xent 0.0802(0.0886) | Loss 8.7778(9.7397) | Error 0.0261(0.0294) Steps 640(664.61) | Grad Norm 5.9899(5.7429) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 64.4165(64.4255) | Bit/dim 3.6706(3.6712) | Xent 0.0767(0.0882) | Loss 8.8444(9.7128) | Error 0.0254(0.0293) Steps 676(664.95) | Grad Norm 5.8347(5.7457) | Total Time 0.00(0.00)\n",
      "Iter 2111 | Time 65.8944(64.4695) | Bit/dim 3.6688(3.6711) | Xent 0.0735(0.0878) | Loss 8.6936(9.6822) | Error 0.0240(0.0292) Steps 658(664.74) | Grad Norm 4.5913(5.7110) | Total Time 0.00(0.00)\n",
      "Iter 2112 | Time 70.0014(64.6355) | Bit/dim 3.6715(3.6711) | Xent 0.0873(0.0878) | Loss 8.9940(9.6616) | Error 0.0292(0.0292) Steps 676(665.08) | Grad Norm 9.1830(5.8152) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 24.7142, Epoch Time 441.4616(431.7295), Bit/dim 3.6991(best: 3.6969), Xent 3.2757, Loss 5.3370, Error 0.4568(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2113 | Time 71.5152(64.8419) | Bit/dim 3.6586(3.6707) | Xent 0.0687(0.0872) | Loss 14.0353(9.7928) | Error 0.0230(0.0290) Steps 670(665.22) | Grad Norm 4.6120(5.7791) | Total Time 0.00(0.00)\n",
      "Iter 2114 | Time 71.3227(65.0363) | Bit/dim 3.6698(3.6707) | Xent 0.0762(0.0869) | Loss 8.9371(9.7671) | Error 0.0254(0.0289) Steps 652(664.83) | Grad Norm 7.5631(5.8326) | Total Time 0.00(0.00)\n",
      "Iter 2115 | Time 64.1700(65.0103) | Bit/dim 3.6689(3.6707) | Xent 0.0930(0.0871) | Loss 8.8627(9.7400) | Error 0.0315(0.0290) Steps 676(665.16) | Grad Norm 9.4679(5.9417) | Total Time 0.00(0.00)\n",
      "Iter 2116 | Time 74.0148(65.2804) | Bit/dim 3.6656(3.6705) | Xent 0.0741(0.0867) | Loss 8.9996(9.7178) | Error 0.0240(0.0288) Steps 652(664.77) | Grad Norm 5.0937(5.9162) | Total Time 0.00(0.00)\n",
      "Iter 2117 | Time 63.4721(65.2262) | Bit/dim 3.6709(3.6705) | Xent 0.1040(0.0872) | Loss 8.9682(9.6953) | Error 0.0345(0.0290) Steps 664(664.75) | Grad Norm 11.5236(6.0845) | Total Time 0.00(0.00)\n",
      "Iter 2118 | Time 67.8133(65.3038) | Bit/dim 3.6704(3.6705) | Xent 0.0792(0.0870) | Loss 8.8877(9.6711) | Error 0.0269(0.0289) Steps 676(665.08) | Grad Norm 7.5458(6.1283) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 24.4271, Epoch Time 455.1861(432.4332), Bit/dim 3.7026(best: 3.6969), Xent 3.1964, Loss 5.3008, Error 0.4525(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2119 | Time 60.9577(65.1734) | Bit/dim 3.6652(3.6704) | Xent 0.0752(0.0866) | Loss 14.2089(9.8072) | Error 0.0246(0.0288) Steps 676(665.41) | Grad Norm 5.7896(6.1181) | Total Time 0.00(0.00)\n",
      "Iter 2120 | Time 65.6599(65.1880) | Bit/dim 3.6764(3.6705) | Xent 0.0876(0.0866) | Loss 8.7012(9.7740) | Error 0.0281(0.0288) Steps 670(665.55) | Grad Norm 9.5721(6.2218) | Total Time 0.00(0.00)\n",
      "Iter 2121 | Time 63.8176(65.1469) | Bit/dim 3.6658(3.6704) | Xent 0.0644(0.0860) | Loss 8.8927(9.7476) | Error 0.0218(0.0286) Steps 670(665.68) | Grad Norm 2.6783(6.1155) | Total Time 0.00(0.00)\n",
      "Iter 2122 | Time 67.5315(65.2184) | Bit/dim 3.6646(3.6702) | Xent 0.0872(0.0860) | Loss 9.0244(9.7259) | Error 0.0292(0.0286) Steps 670(665.81) | Grad Norm 11.7966(6.2859) | Total Time 0.00(0.00)\n",
      "Iter 2123 | Time 63.0274(65.1527) | Bit/dim 3.6717(3.6703) | Xent 0.1036(0.0865) | Loss 8.9414(9.7024) | Error 0.0331(0.0287) Steps 658(665.58) | Grad Norm 11.9478(6.4557) | Total Time 0.00(0.00)\n",
      "Iter 2124 | Time 64.7922(65.1419) | Bit/dim 3.6663(3.6701) | Xent 0.0826(0.0864) | Loss 8.9725(9.6805) | Error 0.0251(0.0286) Steps 652(665.17) | Grad Norm 3.7852(6.3756) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 24.6962, Epoch Time 429.2132(432.3366), Bit/dim 3.7053(best: 3.6969), Xent 3.2292, Loss 5.3199, Error 0.4545(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2125 | Time 68.9807(65.2571) | Bit/dim 3.6685(3.6701) | Xent 0.0813(0.0863) | Loss 13.6042(9.7982) | Error 0.0262(0.0285) Steps 682(665.67) | Grad Norm 8.6880(6.4450) | Total Time 0.00(0.00)\n",
      "Iter 2126 | Time 68.4739(65.3536) | Bit/dim 3.6545(3.6696) | Xent 0.0848(0.0862) | Loss 8.9921(9.7740) | Error 0.0245(0.0284) Steps 688(666.34) | Grad Norm 4.8821(6.3981) | Total Time 0.00(0.00)\n",
      "Iter 2127 | Time 68.0781(65.4353) | Bit/dim 3.6676(3.6696) | Xent 0.1007(0.0867) | Loss 8.8925(9.7476) | Error 0.0337(0.0286) Steps 682(666.81) | Grad Norm 9.1481(6.4806) | Total Time 0.00(0.00)\n",
      "Iter 2128 | Time 70.2146(65.5787) | Bit/dim 3.6769(3.6698) | Xent 0.1023(0.0871) | Loss 9.0671(9.7271) | Error 0.0366(0.0288) Steps 658(666.55) | Grad Norm 11.8562(6.6419) | Total Time 0.00(0.00)\n",
      "Iter 2129 | Time 68.4970(65.6662) | Bit/dim 3.6777(3.6700) | Xent 0.0777(0.0868) | Loss 8.8440(9.7006) | Error 0.0235(0.0287) Steps 688(667.19) | Grad Norm 7.8258(6.6774) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 65.7719(65.6694) | Bit/dim 3.6697(3.6700) | Xent 0.1002(0.0872) | Loss 9.0720(9.6818) | Error 0.0356(0.0289) Steps 682(667.64) | Grad Norm 9.5910(6.7648) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 24.9523, Epoch Time 453.3805(432.9680), Bit/dim 3.6963(best: 3.6969), Xent 3.1064, Loss 5.2495, Error 0.4542(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2131 | Time 62.3988(65.5713) | Bit/dim 3.6673(3.6699) | Xent 0.0868(0.0872) | Loss 13.2257(9.7881) | Error 0.0279(0.0288) Steps 664(667.53) | Grad Norm 7.9882(6.8015) | Total Time 0.00(0.00)\n",
      "Iter 2132 | Time 68.3155(65.6536) | Bit/dim 3.6673(3.6698) | Xent 0.0888(0.0873) | Loss 8.8232(9.7592) | Error 0.0306(0.0289) Steps 688(668.14) | Grad Norm 9.8028(6.8915) | Total Time 0.00(0.00)\n",
      "Iter 2133 | Time 73.0341(65.8750) | Bit/dim 3.6695(3.6698) | Xent 0.0999(0.0877) | Loss 8.7848(9.7299) | Error 0.0334(0.0290) Steps 700(669.10) | Grad Norm 8.8974(6.9517) | Total Time 0.00(0.00)\n",
      "Iter 2134 | Time 62.0285(65.7596) | Bit/dim 3.6752(3.6700) | Xent 0.0876(0.0877) | Loss 9.0559(9.7097) | Error 0.0285(0.0290) Steps 652(668.59) | Grad Norm 7.3860(6.9647) | Total Time 0.00(0.00)\n",
      "Iter 2135 | Time 68.4735(65.8410) | Bit/dim 3.6550(3.6696) | Xent 0.0825(0.0875) | Loss 8.7770(9.6817) | Error 0.0275(0.0290) Steps 652(668.09) | Grad Norm 8.8878(7.0224) | Total Time 0.00(0.00)\n",
      "Iter 2136 | Time 71.4741(66.0100) | Bit/dim 3.6822(3.6699) | Xent 0.0749(0.0871) | Loss 8.7727(9.6544) | Error 0.0242(0.0288) Steps 694(668.86) | Grad Norm 3.8779(6.9281) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 24.6585, Epoch Time 448.1173(433.4224), Bit/dim 3.6991(best: 3.6963), Xent 3.1984, Loss 5.2982, Error 0.4552(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2137 | Time 67.0535(66.0413) | Bit/dim 3.6647(3.6698) | Xent 0.0912(0.0872) | Loss 13.9827(9.7843) | Error 0.0299(0.0289) Steps 670(668.90) | Grad Norm 10.4382(7.0334) | Total Time 0.00(0.00)\n",
      "Iter 2138 | Time 66.7550(66.0628) | Bit/dim 3.6699(3.6698) | Xent 0.0798(0.0870) | Loss 8.5443(9.7471) | Error 0.0246(0.0287) Steps 658(668.57) | Grad Norm 7.4840(7.0469) | Total Time 0.00(0.00)\n",
      "Iter 2139 | Time 60.2530(65.8885) | Bit/dim 3.6780(3.6700) | Xent 0.0934(0.0872) | Loss 8.9967(9.7246) | Error 0.0311(0.0288) Steps 646(667.89) | Grad Norm 11.5782(7.1829) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 65.3542(65.8724) | Bit/dim 3.6679(3.6700) | Xent 0.1390(0.0888) | Loss 9.1310(9.7068) | Error 0.0445(0.0293) Steps 670(667.96) | Grad Norm 14.2056(7.3935) | Total Time 0.00(0.00)\n",
      "Iter 2141 | Time 68.6216(65.9549) | Bit/dim 3.6689(3.6699) | Xent 0.1508(0.0906) | Loss 8.8002(9.6796) | Error 0.0479(0.0298) Steps 676(668.20) | Grad Norm 11.9831(7.5312) | Total Time 0.00(0.00)\n",
      "Iter 2142 | Time 66.8867(65.9829) | Bit/dim 3.6792(3.6702) | Xent 0.1141(0.0913) | Loss 9.1435(9.6635) | Error 0.0366(0.0300) Steps 670(668.25) | Grad Norm 11.9047(7.6624) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 24.7603, Epoch Time 438.2068(433.5660), Bit/dim 3.6984(best: 3.6963), Xent 3.0136, Loss 5.2052, Error 0.4513(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2143 | Time 66.8690(66.0094) | Bit/dim 3.6701(3.6702) | Xent 0.0943(0.0914) | Loss 13.9763(9.7929) | Error 0.0304(0.0300) Steps 664(668.13) | Grad Norm 6.1754(7.6178) | Total Time 0.00(0.00)\n",
      "Iter 2144 | Time 64.1661(65.9541) | Bit/dim 3.6779(3.6704) | Xent 0.1078(0.0919) | Loss 8.8051(9.7632) | Error 0.0371(0.0303) Steps 670(668.18) | Grad Norm 9.6086(7.6775) | Total Time 0.00(0.00)\n",
      "Iter 2145 | Time 64.9653(65.9245) | Bit/dim 3.6708(3.6704) | Xent 0.1111(0.0925) | Loss 8.9003(9.7374) | Error 0.0370(0.0305) Steps 670(668.24) | Grad Norm 9.6503(7.7367) | Total Time 0.00(0.00)\n",
      "Iter 2146 | Time 65.4087(65.9090) | Bit/dim 3.6724(3.6705) | Xent 0.0852(0.0923) | Loss 8.9260(9.7130) | Error 0.0256(0.0303) Steps 676(668.47) | Grad Norm 5.1960(7.6605) | Total Time 0.00(0.00)\n",
      "Iter 2147 | Time 67.9788(65.9711) | Bit/dim 3.6699(3.6705) | Xent 0.0869(0.0921) | Loss 8.8142(9.6861) | Error 0.0280(0.0302) Steps 682(668.88) | Grad Norm 5.8841(7.6072) | Total Time 0.00(0.00)\n",
      "Iter 2148 | Time 65.1402(65.9462) | Bit/dim 3.6603(3.6702) | Xent 0.1069(0.0926) | Loss 8.9182(9.6630) | Error 0.0367(0.0304) Steps 688(669.45) | Grad Norm 9.2334(7.6560) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 25.0649, Epoch Time 437.8676(433.6950), Bit/dim 3.7004(best: 3.6963), Xent 3.1068, Loss 5.2538, Error 0.4579(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2149 | Time 70.3639(66.0787) | Bit/dim 3.6748(3.6703) | Xent 0.1065(0.0930) | Loss 13.9034(9.7902) | Error 0.0340(0.0305) Steps 670(669.47) | Grad Norm 11.6143(7.7747) | Total Time 0.00(0.00)\n",
      "Iter 2150 | Time 67.4424(66.1196) | Bit/dim 3.6722(3.6704) | Xent 0.0920(0.0929) | Loss 8.7829(9.7600) | Error 0.0288(0.0305) Steps 640(668.58) | Grad Norm 9.6891(7.8322) | Total Time 0.00(0.00)\n",
      "Iter 2151 | Time 62.7186(66.0176) | Bit/dim 3.6787(3.6706) | Xent 0.0941(0.0930) | Loss 9.0043(9.7373) | Error 0.0314(0.0305) Steps 676(668.80) | Grad Norm 9.0297(7.8681) | Total Time 0.00(0.00)\n",
      "Iter 2152 | Time 70.2595(66.1448) | Bit/dim 3.6640(3.6704) | Xent 0.0858(0.0928) | Loss 8.9944(9.7150) | Error 0.0280(0.0304) Steps 676(669.02) | Grad Norm 6.2621(7.8199) | Total Time 0.00(0.00)\n",
      "Iter 2153 | Time 67.8744(66.1967) | Bit/dim 3.6769(3.6706) | Xent 0.0899(0.0927) | Loss 8.9298(9.6915) | Error 0.0306(0.0304) Steps 664(668.87) | Grad Norm 8.6967(7.8462) | Total Time 0.00(0.00)\n",
      "Iter 2154 | Time 67.8217(66.2455) | Bit/dim 3.6609(3.6703) | Xent 0.0739(0.0921) | Loss 8.8686(9.6668) | Error 0.0241(0.0303) Steps 652(668.36) | Grad Norm 4.2307(7.7378) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 25.2748, Epoch Time 450.5095(434.1995), Bit/dim 3.6991(best: 3.6963), Xent 3.2821, Loss 5.3401, Error 0.4534(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2155 | Time 64.5554(66.1948) | Bit/dim 3.6640(3.6701) | Xent 0.0929(0.0921) | Loss 13.4011(9.7788) | Error 0.0312(0.0303) Steps 664(668.23) | Grad Norm 7.8395(7.7408) | Total Time 0.00(0.00)\n",
      "Iter 2156 | Time 60.0407(66.0102) | Bit/dim 3.6704(3.6701) | Xent 0.0680(0.0914) | Loss 8.8734(9.7517) | Error 0.0220(0.0300) Steps 646(667.57) | Grad Norm 4.5212(7.6442) | Total Time 0.00(0.00)\n",
      "Iter 2157 | Time 68.2400(66.0770) | Bit/dim 3.6543(3.6697) | Xent 0.0814(0.0911) | Loss 8.6733(9.7193) | Error 0.0278(0.0300) Steps 676(667.82) | Grad Norm 7.4033(7.6370) | Total Time 0.00(0.00)\n",
      "Iter 2158 | Time 64.4044(66.0269) | Bit/dim 3.6685(3.6696) | Xent 0.0910(0.0911) | Loss 8.8264(9.6925) | Error 0.0310(0.0300) Steps 670(667.88) | Grad Norm 9.6921(7.6986) | Total Time 0.00(0.00)\n",
      "Iter 2159 | Time 67.6888(66.0767) | Bit/dim 3.6737(3.6698) | Xent 0.0845(0.0909) | Loss 8.9971(9.6717) | Error 0.0289(0.0300) Steps 670(667.95) | Grad Norm 10.7910(7.7914) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 67.9052(66.1316) | Bit/dim 3.6755(3.6699) | Xent 0.0856(0.0907) | Loss 8.9948(9.6514) | Error 0.0275(0.0299) Steps 676(668.19) | Grad Norm 7.5883(7.7853) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 24.8118, Epoch Time 435.8571(434.2492), Bit/dim 3.7016(best: 3.6963), Xent 3.1426, Loss 5.2729, Error 0.4535(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2161 | Time 67.8749(66.1839) | Bit/dim 3.6650(3.6698) | Xent 0.0722(0.0902) | Loss 13.8320(9.7768) | Error 0.0232(0.0297) Steps 670(668.24) | Grad Norm 5.8306(7.7267) | Total Time 0.00(0.00)\n",
      "Iter 2162 | Time 65.8629(66.1743) | Bit/dim 3.6792(3.6701) | Xent 0.1023(0.0906) | Loss 9.1157(9.7570) | Error 0.0353(0.0299) Steps 652(667.76) | Grad Norm 10.6054(7.8130) | Total Time 0.00(0.00)\n",
      "Iter 2163 | Time 71.7812(66.3425) | Bit/dim 3.6582(3.6697) | Xent 0.1425(0.0921) | Loss 9.1412(9.7385) | Error 0.0496(0.0305) Steps 664(667.64) | Grad Norm 14.1554(8.0033) | Total Time 0.00(0.00)\n",
      "Iter 2164 | Time 67.1240(66.3659) | Bit/dim 3.6712(3.6698) | Xent 0.1697(0.0944) | Loss 9.0851(9.7189) | Error 0.0587(0.0313) Steps 664(667.53) | Grad Norm 19.7136(8.3546) | Total Time 0.00(0.00)\n",
      "Iter 2165 | Time 63.3533(66.2755) | Bit/dim 3.6741(3.6699) | Xent 0.2136(0.0980) | Loss 9.0519(9.6989) | Error 0.0753(0.0326) Steps 664(667.43) | Grad Norm 27.5959(8.9319) | Total Time 0.00(0.00)\n",
      "Iter 2166 | Time 69.2106(66.3636) | Bit/dim 3.6782(3.6701) | Xent 0.1357(0.0991) | Loss 9.0976(9.6808) | Error 0.0477(0.0331) Steps 652(666.97) | Grad Norm 15.1482(9.1183) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 24.9254, Epoch Time 448.0360(434.6628), Bit/dim 3.6937(best: 3.6963), Xent 2.8925, Loss 5.1399, Error 0.4503(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2167 | Time 71.5469(66.5191) | Bit/dim 3.6718(3.6702) | Xent 0.1137(0.0996) | Loss 13.6298(9.7993) | Error 0.0369(0.0332) Steps 670(667.06) | Grad Norm 10.6479(9.1642) | Total Time 0.00(0.00)\n",
      "Iter 2168 | Time 62.0083(66.3838) | Bit/dim 3.6904(3.6708) | Xent 0.1212(0.1002) | Loss 8.6296(9.7642) | Error 0.0406(0.0334) Steps 658(666.78) | Grad Norm 11.8260(9.2441) | Total Time 0.00(0.00)\n",
      "Iter 2169 | Time 67.9228(66.4299) | Bit/dim 3.6730(3.6709) | Xent 0.0959(0.1001) | Loss 8.8352(9.7363) | Error 0.0295(0.0333) Steps 670(666.88) | Grad Norm 4.1543(9.0914) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 69.4408(66.5203) | Bit/dim 3.6840(3.6712) | Xent 0.1209(0.1007) | Loss 9.1350(9.7183) | Error 0.0407(0.0335) Steps 664(666.79) | Grad Norm 10.8303(9.1436) | Total Time 0.00(0.00)\n",
      "Iter 2171 | Time 64.8865(66.4712) | Bit/dim 3.6637(3.6710) | Xent 0.1109(0.1010) | Loss 8.7642(9.6897) | Error 0.0361(0.0336) Steps 646(666.17) | Grad Norm 7.7529(9.1018) | Total Time 0.00(0.00)\n",
      "Iter 2172 | Time 68.6306(66.5360) | Bit/dim 3.6523(3.6705) | Xent 0.1176(0.1015) | Loss 8.9832(9.6685) | Error 0.0367(0.0337) Steps 670(666.29) | Grad Norm 8.1684(9.0738) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 25.0274, Epoch Time 448.1940(435.0687), Bit/dim 3.7000(best: 3.6937), Xent 3.0294, Loss 5.2147, Error 0.4552(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2173 | Time 64.4086(66.4722) | Bit/dim 3.6581(3.6701) | Xent 0.1111(0.1018) | Loss 13.8248(9.7932) | Error 0.0387(0.0338) Steps 664(666.22) | Grad Norm 11.2868(9.1402) | Total Time 0.00(0.00)\n",
      "Iter 2174 | Time 63.3879(66.3797) | Bit/dim 3.6629(3.6699) | Xent 0.0853(0.1013) | Loss 8.8857(9.7659) | Error 0.0292(0.0337) Steps 658(665.97) | Grad Norm 4.5033(9.0011) | Total Time 0.00(0.00)\n",
      "Iter 2175 | Time 65.2136(66.3447) | Bit/dim 3.6833(3.6703) | Xent 0.0971(0.1012) | Loss 8.8497(9.7385) | Error 0.0327(0.0337) Steps 658(665.73) | Grad Norm 7.8950(8.9679) | Total Time 0.00(0.00)\n",
      "Iter 2176 | Time 65.3885(66.3160) | Bit/dim 3.6611(3.6700) | Xent 0.0827(0.1006) | Loss 8.6816(9.7068) | Error 0.0269(0.0335) Steps 676(666.04) | Grad Norm 3.5898(8.8066) | Total Time 0.00(0.00)\n",
      "Iter 2177 | Time 63.7131(66.2379) | Bit/dim 3.6773(3.6702) | Xent 0.0862(0.1002) | Loss 8.9332(9.6835) | Error 0.0282(0.0333) Steps 676(666.34) | Grad Norm 7.1327(8.7564) | Total Time 0.00(0.00)\n",
      "Iter 2178 | Time 64.6824(66.1912) | Bit/dim 3.6668(3.6701) | Xent 0.1034(0.1003) | Loss 8.9718(9.6622) | Error 0.0353(0.0334) Steps 676(666.63) | Grad Norm 6.1985(8.6796) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 24.4388, Epoch Time 429.4561(434.9003), Bit/dim 3.6963(best: 3.6937), Xent 3.1877, Loss 5.2901, Error 0.4532(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2179 | Time 64.9191(66.1531) | Bit/dim 3.6607(3.6698) | Xent 0.0779(0.0996) | Loss 13.6590(9.7821) | Error 0.0248(0.0331) Steps 688(667.27) | Grad Norm 4.5520(8.5558) | Total Time 0.00(0.00)\n",
      "Iter 2180 | Time 65.2606(66.1263) | Bit/dim 3.6772(3.6701) | Xent 0.0742(0.0989) | Loss 8.9480(9.7571) | Error 0.0245(0.0329) Steps 664(667.17) | Grad Norm 4.7547(8.4418) | Total Time 0.00(0.00)\n",
      "Iter 2181 | Time 69.2528(66.2201) | Bit/dim 3.6793(3.6703) | Xent 0.0916(0.0986) | Loss 8.8196(9.7289) | Error 0.0301(0.0328) Steps 682(667.62) | Grad Norm 6.5991(8.3865) | Total Time 0.00(0.00)\n",
      "Iter 2182 | Time 64.7554(66.1762) | Bit/dim 3.6549(3.6699) | Xent 0.0826(0.0982) | Loss 8.8226(9.7018) | Error 0.0281(0.0326) Steps 670(667.69) | Grad Norm 4.9263(8.2827) | Total Time 0.00(0.00)\n",
      "Iter 2183 | Time 65.7880(66.1645) | Bit/dim 3.6751(3.6700) | Xent 0.0784(0.0976) | Loss 9.0299(9.6816) | Error 0.0265(0.0325) Steps 694(668.48) | Grad Norm 5.0938(8.1870) | Total Time 0.00(0.00)\n",
      "Iter 2184 | Time 68.8123(66.2440) | Bit/dim 3.6660(3.6699) | Xent 0.0898(0.0973) | Loss 8.8989(9.6581) | Error 0.0325(0.0325) Steps 694(669.24) | Grad Norm 6.5733(8.1386) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 24.9724, Epoch Time 441.5450(435.0997), Bit/dim 3.7062(best: 3.6937), Xent 3.1404, Loss 5.2763, Error 0.4583(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2185 | Time 65.8660(66.2326) | Bit/dim 3.6684(3.6699) | Xent 0.0755(0.0967) | Loss 13.3489(9.7688) | Error 0.0246(0.0322) Steps 694(669.99) | Grad Norm 5.7336(8.0665) | Total Time 0.00(0.00)\n",
      "Iter 2186 | Time 67.7521(66.2782) | Bit/dim 3.6756(3.6700) | Xent 0.0772(0.0961) | Loss 8.9968(9.7457) | Error 0.0256(0.0320) Steps 682(670.35) | Grad Norm 4.8336(7.9695) | Total Time 0.00(0.00)\n",
      "Iter 2187 | Time 68.9475(66.3583) | Bit/dim 3.6784(3.6703) | Xent 0.1155(0.0967) | Loss 8.9331(9.7213) | Error 0.0379(0.0322) Steps 670(670.34) | Grad Norm 9.7698(8.0235) | Total Time 0.00(0.00)\n",
      "Iter 2188 | Time 69.0979(66.4405) | Bit/dim 3.6675(3.6702) | Xent 0.0933(0.0966) | Loss 8.9040(9.6968) | Error 0.0299(0.0321) Steps 682(670.69) | Grad Norm 7.6767(8.0131) | Total Time 0.00(0.00)\n",
      "Iter 2189 | Time 64.8005(66.3913) | Bit/dim 3.6657(3.6701) | Xent 0.0867(0.0963) | Loss 9.0055(9.6761) | Error 0.0288(0.0320) Steps 676(670.84) | Grad Norm 6.8228(7.9774) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 68.8936(66.4663) | Bit/dim 3.6703(3.6701) | Xent 0.0985(0.0964) | Loss 9.0628(9.6577) | Error 0.0324(0.0320) Steps 658(670.46) | Grad Norm 7.5389(7.9642) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 24.6339, Epoch Time 447.6774(435.4770), Bit/dim 3.6977(best: 3.6937), Xent 3.1890, Loss 5.2922, Error 0.4542(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2191 | Time 66.4508(66.4659) | Bit/dim 3.6660(3.6699) | Xent 0.0871(0.0961) | Loss 13.4102(9.7702) | Error 0.0276(0.0319) Steps 670(670.45) | Grad Norm 7.0279(7.9361) | Total Time 0.00(0.00)\n",
      "Iter 2192 | Time 67.5231(66.4976) | Bit/dim 3.6627(3.6697) | Xent 0.0843(0.0957) | Loss 8.9212(9.7448) | Error 0.0264(0.0317) Steps 682(670.79) | Grad Norm 5.6916(7.8688) | Total Time 0.00(0.00)\n",
      "Iter 2193 | Time 69.7690(66.5957) | Bit/dim 3.6728(3.6698) | Xent 0.0969(0.0958) | Loss 8.8001(9.7164) | Error 0.0329(0.0318) Steps 658(670.41) | Grad Norm 8.8724(7.8989) | Total Time 0.00(0.00)\n",
      "Iter 2194 | Time 70.5112(66.7132) | Bit/dim 3.6691(3.6698) | Xent 0.0881(0.0955) | Loss 8.8176(9.6895) | Error 0.0274(0.0316) Steps 676(670.58) | Grad Norm 5.6542(7.8316) | Total Time 0.00(0.00)\n",
      "Iter 2195 | Time 65.1768(66.6671) | Bit/dim 3.6693(3.6698) | Xent 0.0825(0.0951) | Loss 9.1056(9.6719) | Error 0.0271(0.0315) Steps 670(670.56) | Grad Norm 6.2685(7.7847) | Total Time 0.00(0.00)\n",
      "Iter 2196 | Time 66.2446(66.6544) | Bit/dim 3.6747(3.6699) | Xent 0.0951(0.0951) | Loss 9.0171(9.6523) | Error 0.0321(0.0315) Steps 676(670.72) | Grad Norm 8.6380(7.8103) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 24.6501, Epoch Time 448.1337(435.8567), Bit/dim 3.6992(best: 3.6937), Xent 3.1524, Loss 5.2753, Error 0.4553(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2197 | Time 68.1739(66.7000) | Bit/dim 3.6726(3.6700) | Xent 0.0749(0.0945) | Loss 13.5853(9.7703) | Error 0.0246(0.0313) Steps 658(670.34) | Grad Norm 5.6231(7.7447) | Total Time 0.00(0.00)\n",
      "Iter 2198 | Time 70.1346(66.8030) | Bit/dim 3.6598(3.6697) | Xent 0.0800(0.0941) | Loss 8.9478(9.7456) | Error 0.0265(0.0312) Steps 676(670.51) | Grad Norm 8.3193(7.7619) | Total Time 0.00(0.00)\n",
      "Iter 2199 | Time 64.1744(66.7242) | Bit/dim 3.6614(3.6695) | Xent 0.0650(0.0932) | Loss 8.9835(9.7228) | Error 0.0222(0.0309) Steps 682(670.86) | Grad Norm 3.5233(7.6347) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 67.0613(66.7343) | Bit/dim 3.6692(3.6695) | Xent 0.0769(0.0927) | Loss 9.0531(9.7027) | Error 0.0252(0.0307) Steps 676(671.01) | Grad Norm 6.0174(7.5862) | Total Time 0.00(0.00)\n",
      "Iter 2201 | Time 67.2125(66.7486) | Bit/dim 3.6713(3.6695) | Xent 0.0682(0.0920) | Loss 9.0612(9.6834) | Error 0.0229(0.0305) Steps 658(670.62) | Grad Norm 2.8260(7.4434) | Total Time 0.00(0.00)\n",
      "Iter 2202 | Time 62.2609(66.6140) | Bit/dim 3.6658(3.6694) | Xent 0.0663(0.0912) | Loss 9.0030(9.6630) | Error 0.0216(0.0302) Steps 682(670.96) | Grad Norm 4.9371(7.3682) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 24.4873, Epoch Time 441.5938(436.0288), Bit/dim 3.6976(best: 3.6937), Xent 3.2005, Loss 5.2979, Error 0.4569(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2203 | Time 68.2363(66.6627) | Bit/dim 3.6585(3.6691) | Xent 0.0595(0.0903) | Loss 13.6302(9.7820) | Error 0.0181(0.0299) Steps 682(671.29) | Grad Norm 2.4676(7.2212) | Total Time 0.00(0.00)\n",
      "Iter 2204 | Time 64.8572(66.6085) | Bit/dim 3.6654(3.6690) | Xent 0.0556(0.0892) | Loss 8.8373(9.7537) | Error 0.0195(0.0296) Steps 670(671.25) | Grad Norm 3.5266(7.1104) | Total Time 0.00(0.00)\n",
      "Iter 2205 | Time 70.3719(66.7214) | Bit/dim 3.6632(3.6688) | Xent 0.0644(0.0885) | Loss 8.8982(9.7280) | Error 0.0201(0.0293) Steps 682(671.58) | Grad Norm 3.2803(6.9955) | Total Time 0.00(0.00)\n",
      "Iter 2206 | Time 67.3059(66.7390) | Bit/dim 3.6643(3.6686) | Xent 0.0720(0.0880) | Loss 9.0343(9.7072) | Error 0.0230(0.0291) Steps 694(672.25) | Grad Norm 4.3499(6.9161) | Total Time 0.00(0.00)\n",
      "Iter 2207 | Time 66.5394(66.7330) | Bit/dim 3.6678(3.6686) | Xent 0.0653(0.0873) | Loss 8.8743(9.6822) | Error 0.0212(0.0289) Steps 694(672.90) | Grad Norm 3.5471(6.8150) | Total Time 0.00(0.00)\n",
      "Iter 2208 | Time 63.3294(66.6309) | Bit/dim 3.6595(3.6683) | Xent 0.0629(0.0866) | Loss 8.6668(9.6518) | Error 0.0211(0.0286) Steps 676(672.99) | Grad Norm 4.7690(6.7536) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 25.2702, Epoch Time 444.3969(436.2799), Bit/dim 3.6948(best: 3.6937), Xent 3.3370, Loss 5.3633, Error 0.4532(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2209 | Time 67.5329(66.6579) | Bit/dim 3.6709(3.6684) | Xent 0.0498(0.0855) | Loss 13.6020(9.7703) | Error 0.0165(0.0283) Steps 676(673.08) | Grad Norm 2.2885(6.6197) | Total Time 0.00(0.00)\n",
      "Iter 2210 | Time 68.3964(66.7101) | Bit/dim 3.6802(3.6688) | Xent 0.0562(0.0846) | Loss 8.9877(9.7468) | Error 0.0191(0.0280) Steps 682(673.35) | Grad Norm 5.3032(6.5802) | Total Time 0.00(0.00)\n",
      "Iter 2211 | Time 64.4261(66.6416) | Bit/dim 3.6601(3.6685) | Xent 0.0613(0.0839) | Loss 8.8616(9.7202) | Error 0.0192(0.0277) Steps 682(673.61) | Grad Norm 4.0408(6.5040) | Total Time 0.00(0.00)\n",
      "Iter 2212 | Time 67.4316(66.6653) | Bit/dim 3.6636(3.6684) | Xent 0.0846(0.0839) | Loss 8.9655(9.6976) | Error 0.0275(0.0277) Steps 676(673.68) | Grad Norm 8.4649(6.5628) | Total Time 0.00(0.00)\n",
      "Iter 2213 | Time 66.9685(66.6744) | Bit/dim 3.6593(3.6681) | Xent 0.0753(0.0837) | Loss 8.9923(9.6764) | Error 0.0251(0.0276) Steps 688(674.11) | Grad Norm 7.6998(6.5969) | Total Time 0.00(0.00)\n",
      "Iter 2214 | Time 68.2486(66.7216) | Bit/dim 3.6501(3.6676) | Xent 0.0788(0.0835) | Loss 9.0064(9.6563) | Error 0.0271(0.0276) Steps 694(674.71) | Grad Norm 5.2599(6.5568) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 24.9879, Epoch Time 446.2253(436.5782), Bit/dim 3.6877(best: 3.6937), Xent 3.2331, Loss 5.3042, Error 0.4486(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2215 | Time 69.0517(66.7915) | Bit/dim 3.6676(3.6676) | Xent 0.0708(0.0831) | Loss 13.2775(9.7650) | Error 0.0242(0.0275) Steps 664(674.39) | Grad Norm 4.8749(6.5064) | Total Time 0.00(0.00)\n",
      "Iter 2216 | Time 71.0846(66.9203) | Bit/dim 3.6635(3.6674) | Xent 0.0767(0.0829) | Loss 9.0300(9.7429) | Error 0.0266(0.0275) Steps 706(675.34) | Grad Norm 6.3297(6.5011) | Total Time 0.00(0.00)\n",
      "Iter 2217 | Time 70.7921(67.0364) | Bit/dim 3.6534(3.6670) | Xent 0.0704(0.0826) | Loss 9.0006(9.7206) | Error 0.0236(0.0274) Steps 694(675.90) | Grad Norm 5.8548(6.4817) | Total Time 0.00(0.00)\n",
      "Iter 2218 | Time 64.9650(66.9743) | Bit/dim 3.6546(3.6666) | Xent 0.0648(0.0820) | Loss 8.8624(9.6949) | Error 0.0191(0.0271) Steps 682(676.08) | Grad Norm 4.1400(6.4114) | Total Time 0.00(0.00)\n",
      "Iter 2219 | Time 67.3164(66.9846) | Bit/dim 3.6665(3.6666) | Xent 0.0769(0.0819) | Loss 8.9515(9.6726) | Error 0.0261(0.0271) Steps 634(674.82) | Grad Norm 6.9279(6.4269) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 65.8483(66.9505) | Bit/dim 3.6679(3.6667) | Xent 0.0816(0.0819) | Loss 8.7540(9.6450) | Error 0.0258(0.0271) Steps 658(674.31) | Grad Norm 9.2327(6.5111) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 24.2453, Epoch Time 451.5176(437.0264), Bit/dim 3.7005(best: 3.6877), Xent 3.2949, Loss 5.3479, Error 0.4563(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2221 | Time 67.3016(66.9610) | Bit/dim 3.6601(3.6665) | Xent 0.0745(0.0816) | Loss 13.9588(9.7744) | Error 0.0240(0.0270) Steps 664(674.00) | Grad Norm 6.2693(6.5039) | Total Time 0.00(0.00)\n",
      "Iter 2222 | Time 61.6347(66.8012) | Bit/dim 3.6654(3.6664) | Xent 0.0712(0.0813) | Loss 8.8701(9.7473) | Error 0.0242(0.0269) Steps 658(673.52) | Grad Norm 4.2173(6.4353) | Total Time 0.00(0.00)\n",
      "Iter 2223 | Time 68.5466(66.8536) | Bit/dim 3.6600(3.6663) | Xent 0.0689(0.0810) | Loss 8.8537(9.7205) | Error 0.0226(0.0268) Steps 658(673.06) | Grad Norm 6.5558(6.4389) | Total Time 0.00(0.00)\n",
      "Iter 2224 | Time 65.1150(66.8014) | Bit/dim 3.6631(3.6662) | Xent 0.0713(0.0807) | Loss 8.6129(9.6873) | Error 0.0240(0.0267) Steps 646(672.25) | Grad Norm 6.1872(6.4313) | Total Time 0.00(0.00)\n",
      "Iter 2225 | Time 67.0822(66.8098) | Bit/dim 3.6663(3.6662) | Xent 0.0755(0.0805) | Loss 8.5799(9.6541) | Error 0.0242(0.0266) Steps 682(672.54) | Grad Norm 7.5815(6.4658) | Total Time 0.00(0.00)\n",
      "Iter 2226 | Time 61.1371(66.6397) | Bit/dim 3.6603(3.6660) | Xent 0.0678(0.0801) | Loss 8.9187(9.6320) | Error 0.0210(0.0264) Steps 634(671.38) | Grad Norm 3.6125(6.3802) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 24.9113, Epoch Time 434.0136(436.9360), Bit/dim 3.6964(best: 3.6877), Xent 3.4049, Loss 5.3988, Error 0.4579(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2227 | Time 64.1570(66.5652) | Bit/dim 3.6733(3.6662) | Xent 0.0709(0.0799) | Loss 13.3033(9.7421) | Error 0.0229(0.0263) Steps 640(670.44) | Grad Norm 6.6935(6.3896) | Total Time 0.00(0.00)\n",
      "Iter 2228 | Time 68.4978(66.6232) | Bit/dim 3.6534(3.6658) | Xent 0.0708(0.0796) | Loss 9.0897(9.7226) | Error 0.0218(0.0262) Steps 676(670.61) | Grad Norm 6.5661(6.3949) | Total Time 0.00(0.00)\n",
      "Iter 2229 | Time 65.5230(66.5902) | Bit/dim 3.6632(3.6657) | Xent 0.0835(0.0797) | Loss 8.9223(9.6986) | Error 0.0279(0.0262) Steps 682(670.95) | Grad Norm 5.9829(6.3826) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 68.6070(66.6507) | Bit/dim 3.6606(3.6656) | Xent 0.0679(0.0793) | Loss 8.9257(9.6754) | Error 0.0206(0.0261) Steps 676(671.10) | Grad Norm 3.7252(6.3028) | Total Time 0.00(0.00)\n",
      "Iter 2231 | Time 70.0327(66.7521) | Bit/dim 3.6654(3.6656) | Xent 0.0867(0.0796) | Loss 8.9522(9.6537) | Error 0.0285(0.0261) Steps 664(670.89) | Grad Norm 9.6527(6.4033) | Total Time 0.00(0.00)\n",
      "Iter 2232 | Time 65.7522(66.7221) | Bit/dim 3.6669(3.6656) | Xent 0.0868(0.0798) | Loss 8.8599(9.6299) | Error 0.0280(0.0262) Steps 658(670.50) | Grad Norm 10.7245(6.5330) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 25.0322, Epoch Time 446.2821(437.2164), Bit/dim 3.6952(best: 3.6877), Xent 3.3003, Loss 5.3453, Error 0.4528(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2233 | Time 62.3015(66.5895) | Bit/dim 3.6642(3.6656) | Xent 0.0778(0.0797) | Loss 13.4634(9.7449) | Error 0.0246(0.0262) Steps 676(670.67) | Grad Norm 4.1679(6.4620) | Total Time 0.00(0.00)\n",
      "Iter 2234 | Time 64.9997(66.5418) | Bit/dim 3.6716(3.6658) | Xent 0.0821(0.0798) | Loss 9.0223(9.7232) | Error 0.0271(0.0262) Steps 658(670.29) | Grad Norm 9.3089(6.5474) | Total Time 0.00(0.00)\n",
      "Iter 2235 | Time 63.3712(66.4467) | Bit/dim 3.6717(3.6659) | Xent 0.0875(0.0800) | Loss 9.0272(9.7023) | Error 0.0280(0.0262) Steps 652(669.74) | Grad Norm 11.8620(6.7069) | Total Time 0.00(0.00)\n",
      "Iter 2236 | Time 75.0273(66.7041) | Bit/dim 3.6539(3.6656) | Xent 0.0663(0.0796) | Loss 8.9466(9.6796) | Error 0.0224(0.0261) Steps 700(670.65) | Grad Norm 4.4829(6.6401) | Total Time 0.00(0.00)\n",
      "Iter 2237 | Time 68.6956(66.7639) | Bit/dim 3.6600(3.6654) | Xent 0.0778(0.0796) | Loss 9.0805(9.6617) | Error 0.0269(0.0261) Steps 658(670.27) | Grad Norm 8.9025(6.7080) | Total Time 0.00(0.00)\n",
      "Iter 2238 | Time 63.1242(66.6547) | Bit/dim 3.6692(3.6655) | Xent 0.0747(0.0794) | Loss 8.8855(9.6384) | Error 0.0242(0.0261) Steps 670(670.26) | Grad Norm 7.7289(6.7386) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 24.1989, Epoch Time 440.5339(437.3159), Bit/dim 3.6975(best: 3.6877), Xent 3.3056, Loss 5.3503, Error 0.4554(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2239 | Time 66.0300(66.6359) | Bit/dim 3.6645(3.6655) | Xent 0.0685(0.0791) | Loss 13.1627(9.7441) | Error 0.0208(0.0259) Steps 670(670.25) | Grad Norm 3.3405(6.6367) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 64.6000(66.5748) | Bit/dim 3.6655(3.6655) | Xent 0.0700(0.0788) | Loss 8.9849(9.7213) | Error 0.0220(0.0258) Steps 664(670.06) | Grad Norm 5.7793(6.6110) | Total Time 0.00(0.00)\n",
      "Iter 2241 | Time 67.1414(66.5918) | Bit/dim 3.6684(3.6656) | Xent 0.0868(0.0791) | Loss 8.8905(9.6964) | Error 0.0305(0.0259) Steps 664(669.88) | Grad Norm 6.2463(6.6000) | Total Time 0.00(0.00)\n",
      "Iter 2242 | Time 68.3572(66.6448) | Bit/dim 3.6550(3.6653) | Xent 0.0581(0.0784) | Loss 8.9445(9.6739) | Error 0.0198(0.0258) Steps 682(670.24) | Grad Norm 4.3145(6.5315) | Total Time 0.00(0.00)\n",
      "Iter 2243 | Time 68.3436(66.6958) | Bit/dim 3.6639(3.6652) | Xent 0.0697(0.0782) | Loss 8.9303(9.6515) | Error 0.0241(0.0257) Steps 664(670.06) | Grad Norm 5.3653(6.4965) | Total Time 0.00(0.00)\n",
      "Iter 2244 | Time 64.7095(66.6362) | Bit/dim 3.6674(3.6653) | Xent 0.0620(0.0777) | Loss 8.9752(9.6313) | Error 0.0212(0.0256) Steps 646(669.34) | Grad Norm 7.5550(6.5282) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 24.6280, Epoch Time 441.9223(437.4541), Bit/dim 3.6957(best: 3.6877), Xent 3.2352, Loss 5.3133, Error 0.4564(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2245 | Time 63.6975(66.5480) | Bit/dim 3.6515(3.6649) | Xent 0.0726(0.0775) | Loss 13.3116(9.7417) | Error 0.0248(0.0256) Steps 664(669.18) | Grad Norm 5.4344(6.4954) | Total Time 0.00(0.00)\n",
      "Iter 2246 | Time 64.8728(66.4978) | Bit/dim 3.6700(3.6650) | Xent 0.0642(0.0771) | Loss 8.9056(9.7166) | Error 0.0215(0.0254) Steps 652(668.66) | Grad Norm 5.0963(6.4535) | Total Time 0.00(0.00)\n",
      "Iter 2247 | Time 71.6186(66.6514) | Bit/dim 3.6538(3.6647) | Xent 0.0621(0.0767) | Loss 8.6828(9.6856) | Error 0.0195(0.0253) Steps 694(669.42) | Grad Norm 3.5716(6.3670) | Total Time 0.00(0.00)\n",
      "Iter 2248 | Time 61.0141(66.4823) | Bit/dim 3.6643(3.6647) | Xent 0.0720(0.0765) | Loss 8.6587(9.6548) | Error 0.0256(0.0253) Steps 676(669.62) | Grad Norm 6.9288(6.3838) | Total Time 0.00(0.00)\n",
      "Iter 2249 | Time 65.3083(66.4470) | Bit/dim 3.6610(3.6646) | Xent 0.0776(0.0766) | Loss 8.9726(9.6343) | Error 0.0269(0.0253) Steps 676(669.81) | Grad Norm 6.2771(6.3806) | Total Time 0.00(0.00)\n",
      "Iter 2250 | Time 64.6229(66.3923) | Bit/dim 3.6698(3.6647) | Xent 0.0656(0.0762) | Loss 9.0242(9.6160) | Error 0.0212(0.0252) Steps 688(670.35) | Grad Norm 4.1703(6.3143) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 25.1965, Epoch Time 434.9865(437.3801), Bit/dim 3.6918(best: 3.6877), Xent 3.3196, Loss 5.3516, Error 0.4578(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2251 | Time 64.6094(66.3388) | Bit/dim 3.6686(3.6648) | Xent 0.0597(0.0758) | Loss 13.5307(9.7334) | Error 0.0216(0.0251) Steps 676(670.52) | Grad Norm 4.1649(6.2499) | Total Time 0.00(0.00)\n",
      "Iter 2252 | Time 67.2878(66.3673) | Bit/dim 3.6726(3.6651) | Xent 0.0766(0.0758) | Loss 8.9055(9.7086) | Error 0.0239(0.0250) Steps 688(671.05) | Grad Norm 5.6019(6.2304) | Total Time 0.00(0.00)\n",
      "Iter 2253 | Time 68.3166(66.4258) | Bit/dim 3.6614(3.6650) | Xent 0.0693(0.0756) | Loss 8.9616(9.6862) | Error 0.0234(0.0250) Steps 682(671.38) | Grad Norm 5.3818(6.2050) | Total Time 0.00(0.00)\n",
      "Iter 2254 | Time 64.4798(66.3674) | Bit/dim 3.6558(3.6647) | Xent 0.0749(0.0756) | Loss 8.9772(9.6649) | Error 0.0254(0.0250) Steps 658(670.98) | Grad Norm 5.1319(6.1728) | Total Time 0.00(0.00)\n",
      "Iter 2255 | Time 68.5078(66.4316) | Bit/dim 3.6522(3.6643) | Xent 0.0850(0.0758) | Loss 8.9589(9.6437) | Error 0.0282(0.0251) Steps 664(670.77) | Grad Norm 10.9788(6.3169) | Total Time 0.00(0.00)\n",
      "Iter 2256 | Time 63.9713(66.3578) | Bit/dim 3.6737(3.6646) | Xent 0.1125(0.0769) | Loss 9.0389(9.6256) | Error 0.0361(0.0254) Steps 658(670.38) | Grad Norm 12.8396(6.5126) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 24.5764, Epoch Time 440.0589(437.4605), Bit/dim 3.6974(best: 3.6877), Xent 3.4245, Loss 5.4097, Error 0.4623(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2257 | Time 69.0102(66.4374) | Bit/dim 3.6634(3.6646) | Xent 0.1499(0.0791) | Loss 13.2609(9.7347) | Error 0.0476(0.0261) Steps 664(670.19) | Grad Norm 14.1575(6.7420) | Total Time 0.00(0.00)\n",
      "Iter 2258 | Time 70.6579(66.5640) | Bit/dim 3.6589(3.6644) | Xent 0.1816(0.0822) | Loss 9.0131(9.7130) | Error 0.0587(0.0271) Steps 682(670.55) | Grad Norm 20.6699(7.1598) | Total Time 0.00(0.00)\n",
      "Iter 2259 | Time 61.3878(66.4087) | Bit/dim 3.6859(3.6650) | Xent 0.1842(0.0853) | Loss 8.8766(9.6879) | Error 0.0615(0.0281) Steps 664(670.35) | Grad Norm 19.9205(7.5426) | Total Time 0.00(0.00)\n",
      "Iter 2260 | Time 68.6633(66.4763) | Bit/dim 3.6749(3.6653) | Xent 0.0920(0.0855) | Loss 9.0450(9.6686) | Error 0.0315(0.0282) Steps 670(670.34) | Grad Norm 9.0062(7.5865) | Total Time 0.00(0.00)\n",
      "Iter 2261 | Time 66.5753(66.4793) | Bit/dim 3.6682(3.6654) | Xent 0.1355(0.0870) | Loss 8.9352(9.6466) | Error 0.0471(0.0288) Steps 670(670.33) | Grad Norm 13.9582(7.7777) | Total Time 0.00(0.00)\n",
      "Iter 2262 | Time 64.3751(66.4162) | Bit/dim 3.6649(3.6654) | Xent 0.1321(0.0883) | Loss 8.8020(9.6213) | Error 0.0437(0.0292) Steps 670(670.32) | Grad Norm 12.3827(7.9158) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 24.9092, Epoch Time 444.0692(437.6587), Bit/dim 3.6943(best: 3.6877), Xent 2.9234, Loss 5.1560, Error 0.4508(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2263 | Time 69.4429(66.5070) | Bit/dim 3.6586(3.6652) | Xent 0.1029(0.0888) | Loss 13.5842(9.7402) | Error 0.0349(0.0294) Steps 658(669.95) | Grad Norm 6.5895(7.8760) | Total Time 0.00(0.00)\n",
      "Iter 2264 | Time 65.7656(66.4847) | Bit/dim 3.6639(3.6652) | Xent 0.1213(0.0897) | Loss 9.0757(9.7202) | Error 0.0394(0.0297) Steps 676(670.13) | Grad Norm 11.8489(7.9952) | Total Time 0.00(0.00)\n",
      "Iter 2265 | Time 65.2783(66.4486) | Bit/dim 3.6682(3.6652) | Xent 0.0935(0.0899) | Loss 9.0085(9.6989) | Error 0.0325(0.0298) Steps 682(670.49) | Grad Norm 7.8005(7.9894) | Total Time 0.00(0.00)\n",
      "Iter 2266 | Time 68.8201(66.5197) | Bit/dim 3.6655(3.6653) | Xent 0.1081(0.0904) | Loss 9.0050(9.6781) | Error 0.0377(0.0300) Steps 682(670.83) | Grad Norm 9.0895(8.0224) | Total Time 0.00(0.00)\n",
      "Iter 2267 | Time 61.6476(66.3735) | Bit/dim 3.6734(3.6655) | Xent 0.0850(0.0902) | Loss 9.0187(9.6583) | Error 0.0270(0.0299) Steps 682(671.17) | Grad Norm 5.2320(7.9387) | Total Time 0.00(0.00)\n",
      "Iter 2268 | Time 68.6467(66.4417) | Bit/dim 3.6663(3.6655) | Xent 0.0977(0.0905) | Loss 8.7559(9.6312) | Error 0.0326(0.0300) Steps 670(671.13) | Grad Norm 6.7389(7.9027) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 24.9000, Epoch Time 442.4787(437.8033), Bit/dim 3.6932(best: 3.6877), Xent 3.2312, Loss 5.3088, Error 0.4614(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2269 | Time 69.3695(66.5296) | Bit/dim 3.6515(3.6651) | Xent 0.0751(0.0900) | Loss 13.5651(9.7492) | Error 0.0252(0.0299) Steps 706(672.18) | Grad Norm 5.4919(7.8304) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 70.2343(66.6407) | Bit/dim 3.6731(3.6653) | Xent 0.0745(0.0895) | Loss 9.0223(9.7274) | Error 0.0254(0.0297) Steps 700(673.01) | Grad Norm 5.9563(7.7741) | Total Time 0.00(0.00)\n",
      "Iter 2271 | Time 68.0842(66.6840) | Bit/dim 3.6585(3.6651) | Xent 0.0813(0.0893) | Loss 8.8572(9.7013) | Error 0.0252(0.0296) Steps 694(673.64) | Grad Norm 5.1219(7.6946) | Total Time 0.00(0.00)\n",
      "Iter 2272 | Time 66.7891(66.6872) | Bit/dim 3.6578(3.6649) | Xent 0.0933(0.0894) | Loss 9.0052(9.6804) | Error 0.0302(0.0296) Steps 676(673.71) | Grad Norm 10.5824(7.7812) | Total Time 0.00(0.00)\n",
      "Iter 2273 | Time 69.4576(66.7703) | Bit/dim 3.6795(3.6654) | Xent 0.0675(0.0888) | Loss 8.9825(9.6595) | Error 0.0228(0.0294) Steps 664(673.42) | Grad Norm 7.4911(7.7725) | Total Time 0.00(0.00)\n",
      "Iter 2274 | Time 67.8084(66.8014) | Bit/dim 3.6646(3.6653) | Xent 0.0786(0.0885) | Loss 9.0935(9.6425) | Error 0.0254(0.0293) Steps 664(673.14) | Grad Norm 5.6751(7.7096) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 24.5721, Epoch Time 455.0085(438.3195), Bit/dim 3.6971(best: 3.6877), Xent 3.2829, Loss 5.3385, Error 0.4550(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2275 | Time 65.8455(66.7727) | Bit/dim 3.6684(3.6654) | Xent 0.0835(0.0883) | Loss 13.5924(9.7610) | Error 0.0300(0.0293) Steps 664(672.87) | Grad Norm 11.9508(7.8368) | Total Time 0.00(0.00)\n",
      "Iter 2276 | Time 66.9701(66.7787) | Bit/dim 3.6686(3.6655) | Xent 0.0912(0.0884) | Loss 8.8435(9.7335) | Error 0.0309(0.0294) Steps 670(672.78) | Grad Norm 12.3197(7.9713) | Total Time 0.00(0.00)\n",
      "Iter 2277 | Time 66.7903(66.7790) | Bit/dim 3.6576(3.6653) | Xent 0.0847(0.0883) | Loss 8.8896(9.7082) | Error 0.0281(0.0293) Steps 676(672.88) | Grad Norm 10.2047(8.0383) | Total Time 0.00(0.00)\n",
      "Iter 2278 | Time 66.7258(66.7774) | Bit/dim 3.6537(3.6649) | Xent 0.0853(0.0882) | Loss 8.9142(9.6843) | Error 0.0278(0.0293) Steps 676(672.97) | Grad Norm 11.8853(8.1537) | Total Time 0.00(0.00)\n",
      "Iter 2279 | Time 64.0475(66.6955) | Bit/dim 3.6714(3.6651) | Xent 0.0830(0.0880) | Loss 8.9409(9.6620) | Error 0.0284(0.0293) Steps 652(672.34) | Grad Norm 6.9049(8.1163) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 61.5112(66.5400) | Bit/dim 3.6753(3.6654) | Xent 0.1075(0.0886) | Loss 8.9231(9.6399) | Error 0.0367(0.0295) Steps 646(671.55) | Grad Norm 12.8558(8.2584) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 24.6239, Epoch Time 434.8349(438.2149), Bit/dim 3.6879(best: 3.6877), Xent 3.0966, Loss 5.2362, Error 0.4568(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2281 | Time 69.0930(66.6166) | Bit/dim 3.6610(3.6653) | Xent 0.0640(0.0879) | Loss 13.9065(9.7679) | Error 0.0202(0.0292) Steps 676(671.68) | Grad Norm 4.3388(8.1409) | Total Time 0.00(0.00)\n",
      "Iter 2282 | Time 70.4528(66.7317) | Bit/dim 3.6611(3.6652) | Xent 0.0837(0.0878) | Loss 8.8512(9.7404) | Error 0.0279(0.0292) Steps 706(672.71) | Grad Norm 8.2131(8.1430) | Total Time 0.00(0.00)\n",
      "Iter 2283 | Time 62.0689(66.5918) | Bit/dim 3.6623(3.6651) | Xent 0.0706(0.0872) | Loss 8.7746(9.7114) | Error 0.0224(0.0290) Steps 646(671.91) | Grad Norm 4.9836(8.0482) | Total Time 0.00(0.00)\n",
      "Iter 2284 | Time 68.5892(66.6517) | Bit/dim 3.6655(3.6651) | Xent 0.0798(0.0870) | Loss 9.0017(9.6901) | Error 0.0236(0.0288) Steps 658(671.49) | Grad Norm 7.3818(8.0282) | Total Time 0.00(0.00)\n",
      "Iter 2285 | Time 66.0764(66.6344) | Bit/dim 3.6718(3.6653) | Xent 0.0799(0.0868) | Loss 8.7945(9.6632) | Error 0.0280(0.0288) Steps 688(671.99) | Grad Norm 6.4696(7.9815) | Total Time 0.00(0.00)\n",
      "Iter 2286 | Time 68.8682(66.7015) | Bit/dim 3.6735(3.6656) | Xent 0.0871(0.0868) | Loss 9.0437(9.6447) | Error 0.0286(0.0288) Steps 640(671.03) | Grad Norm 11.9382(8.1002) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 24.7973, Epoch Time 447.8828(438.5050), Bit/dim 3.6951(best: 3.6877), Xent 3.2633, Loss 5.3268, Error 0.4545(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2287 | Time 70.2130(66.8068) | Bit/dim 3.6581(3.6653) | Xent 0.0779(0.0865) | Loss 13.8729(9.7715) | Error 0.0260(0.0287) Steps 682(671.36) | Grad Norm 9.5565(8.1439) | Total Time 0.00(0.00)\n",
      "Iter 2288 | Time 69.9060(66.8998) | Bit/dim 3.6642(3.6653) | Xent 0.0888(0.0866) | Loss 8.7058(9.7395) | Error 0.0286(0.0287) Steps 682(671.68) | Grad Norm 9.1165(8.1731) | Total Time 0.00(0.00)\n",
      "Iter 2289 | Time 61.5574(66.7395) | Bit/dim 3.6594(3.6651) | Xent 0.0676(0.0860) | Loss 8.7409(9.7096) | Error 0.0212(0.0285) Steps 664(671.45) | Grad Norm 5.3495(8.0883) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 66.0146(66.7178) | Bit/dim 3.6639(3.6651) | Xent 0.1102(0.0868) | Loss 9.0594(9.6901) | Error 0.0366(0.0287) Steps 670(671.40) | Grad Norm 13.8296(8.2606) | Total Time 0.00(0.00)\n",
      "Iter 2291 | Time 70.9314(66.8442) | Bit/dim 3.6640(3.6651) | Xent 0.1207(0.0878) | Loss 8.8672(9.6654) | Error 0.0417(0.0291) Steps 664(671.18) | Grad Norm 15.3084(8.4720) | Total Time 0.00(0.00)\n",
      "Iter 2292 | Time 63.5365(66.7449) | Bit/dim 3.6662(3.6651) | Xent 0.0760(0.0874) | Loss 8.8244(9.6402) | Error 0.0260(0.0290) Steps 670(671.15) | Grad Norm 5.2045(8.3740) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 24.8745, Epoch Time 445.4160(438.7123), Bit/dim 3.6945(best: 3.6877), Xent 3.2466, Loss 5.3178, Error 0.4564(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2293 | Time 63.0130(66.6330) | Bit/dim 3.6565(3.6648) | Xent 0.0917(0.0876) | Loss 13.5440(9.7573) | Error 0.0289(0.0290) Steps 652(670.57) | Grad Norm 9.8496(8.4183) | Total Time 0.00(0.00)\n",
      "Iter 2294 | Time 66.2280(66.6208) | Bit/dim 3.6580(3.6646) | Xent 0.0998(0.0879) | Loss 8.6379(9.7237) | Error 0.0326(0.0291) Steps 688(671.10) | Grad Norm 9.9431(8.4640) | Total Time 0.00(0.00)\n",
      "Iter 2295 | Time 71.5970(66.7701) | Bit/dim 3.6636(3.6646) | Xent 0.0777(0.0876) | Loss 8.8594(9.6978) | Error 0.0250(0.0290) Steps 670(671.06) | Grad Norm 9.8001(8.5041) | Total Time 0.00(0.00)\n",
      "Iter 2296 | Time 70.2529(66.8746) | Bit/dim 3.6682(3.6647) | Xent 0.1004(0.0880) | Loss 9.0046(9.6770) | Error 0.0344(0.0291) Steps 658(670.67) | Grad Norm 8.6045(8.5071) | Total Time 0.00(0.00)\n",
      "Iter 2297 | Time 62.1109(66.7317) | Bit/dim 3.6633(3.6647) | Xent 0.0943(0.0882) | Loss 8.7874(9.6503) | Error 0.0299(0.0292) Steps 670(670.65) | Grad Norm 6.9323(8.4599) | Total Time 0.00(0.00)\n",
      "Iter 2298 | Time 67.4077(66.7520) | Bit/dim 3.6685(3.6648) | Xent 0.0921(0.0883) | Loss 8.8303(9.6257) | Error 0.0308(0.0292) Steps 664(670.45) | Grad Norm 9.1979(8.4820) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 24.8775, Epoch Time 443.8320(438.8659), Bit/dim 3.6905(best: 3.6877), Xent 3.1727, Loss 5.2768, Error 0.4592(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2299 | Time 63.3672(66.6504) | Bit/dim 3.6646(3.6648) | Xent 0.0805(0.0881) | Loss 13.8202(9.7515) | Error 0.0288(0.0292) Steps 664(670.26) | Grad Norm 10.5257(8.5433) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 61.9304(66.5088) | Bit/dim 3.6645(3.6648) | Xent 0.0958(0.0883) | Loss 8.8730(9.7252) | Error 0.0340(0.0293) Steps 664(670.07) | Grad Norm 8.3731(8.5382) | Total Time 0.00(0.00)\n",
      "Iter 2301 | Time 67.3504(66.5341) | Bit/dim 3.6612(3.6647) | Xent 0.1159(0.0891) | Loss 9.0174(9.7039) | Error 0.0389(0.0296) Steps 688(670.61) | Grad Norm 17.1007(8.7951) | Total Time 0.00(0.00)\n",
      "Iter 2302 | Time 70.6171(66.6566) | Bit/dim 3.6632(3.6646) | Xent 0.0897(0.0892) | Loss 8.8785(9.6792) | Error 0.0285(0.0296) Steps 658(670.23) | Grad Norm 9.7539(8.8238) | Total Time 0.00(0.00)\n",
      "Iter 2303 | Time 69.5341(66.7429) | Bit/dim 3.6655(3.6646) | Xent 0.0882(0.0891) | Loss 8.8685(9.6548) | Error 0.0289(0.0296) Steps 652(669.68) | Grad Norm 11.9716(8.9183) | Total Time 0.00(0.00)\n",
      "Iter 2304 | Time 62.9972(66.6305) | Bit/dim 3.6766(3.6650) | Xent 0.0930(0.0892) | Loss 9.0762(9.6375) | Error 0.0295(0.0296) Steps 652(669.15) | Grad Norm 13.7853(9.0643) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 24.9823, Epoch Time 438.8855(438.8665), Bit/dim 3.6960(best: 3.6877), Xent 3.1747, Loss 5.2833, Error 0.4514(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2305 | Time 67.1351(66.6457) | Bit/dim 3.6632(3.6649) | Xent 0.0744(0.0888) | Loss 13.6570(9.7581) | Error 0.0231(0.0294) Steps 682(669.54) | Grad Norm 6.3737(8.9836) | Total Time 0.00(0.00)\n",
      "Iter 2306 | Time 67.4915(66.6710) | Bit/dim 3.6680(3.6650) | Xent 0.0718(0.0883) | Loss 9.0249(9.7361) | Error 0.0230(0.0292) Steps 658(669.19) | Grad Norm 6.5099(8.9094) | Total Time 0.00(0.00)\n",
      "Iter 2307 | Time 62.6828(66.5514) | Bit/dim 3.6783(3.6654) | Xent 0.0754(0.0879) | Loss 8.9475(9.7124) | Error 0.0256(0.0291) Steps 676(669.40) | Grad Norm 7.4818(8.8665) | Total Time 0.00(0.00)\n",
      "Iter 2308 | Time 68.1038(66.5980) | Bit/dim 3.6663(3.6655) | Xent 0.0710(0.0874) | Loss 8.9083(9.6883) | Error 0.0219(0.0289) Steps 700(670.31) | Grad Norm 3.4733(8.7047) | Total Time 0.00(0.00)\n",
      "Iter 2309 | Time 64.7675(66.5430) | Bit/dim 3.6519(3.6650) | Xent 0.0838(0.0873) | Loss 8.8991(9.6646) | Error 0.0275(0.0288) Steps 634(669.22) | Grad Norm 7.2497(8.6611) | Total Time 0.00(0.00)\n",
      "Iter 2310 | Time 69.8073(66.6410) | Bit/dim 3.6527(3.6647) | Xent 0.0803(0.0871) | Loss 9.1115(9.6480) | Error 0.0262(0.0287) Steps 670(669.25) | Grad Norm 7.9840(8.6408) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 24.5543, Epoch Time 442.7291(438.9824), Bit/dim 3.7001(best: 3.6877), Xent 3.2722, Loss 5.3362, Error 0.4555(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2311 | Time 68.0968(66.6846) | Bit/dim 3.6534(3.6643) | Xent 0.0648(0.0864) | Loss 13.2370(9.7557) | Error 0.0219(0.0285) Steps 682(669.63) | Grad Norm 4.4577(8.5153) | Total Time 0.00(0.00)\n",
      "Iter 2312 | Time 64.9700(66.6332) | Bit/dim 3.6686(3.6645) | Xent 0.0619(0.0857) | Loss 8.9015(9.7301) | Error 0.0199(0.0283) Steps 682(670.00) | Grad Norm 4.7114(8.4012) | Total Time 0.00(0.00)\n",
      "Iter 2313 | Time 68.7113(66.6955) | Bit/dim 3.6572(3.6642) | Xent 0.0610(0.0849) | Loss 8.7933(9.7020) | Error 0.0191(0.0280) Steps 658(669.64) | Grad Norm 5.2256(8.3059) | Total Time 0.00(0.00)\n",
      "Iter 2314 | Time 60.9676(66.5237) | Bit/dim 3.6646(3.6643) | Xent 0.0693(0.0845) | Loss 8.8369(9.6760) | Error 0.0219(0.0278) Steps 664(669.47) | Grad Norm 3.7897(8.1704) | Total Time 0.00(0.00)\n",
      "Iter 2315 | Time 67.3169(66.5475) | Bit/dim 3.6696(3.6644) | Xent 0.0705(0.0840) | Loss 9.0828(9.6582) | Error 0.0240(0.0277) Steps 688(670.03) | Grad Norm 5.0883(8.0780) | Total Time 0.00(0.00)\n",
      "Iter 2316 | Time 67.2489(66.5685) | Bit/dim 3.6694(3.6646) | Xent 0.0540(0.0831) | Loss 8.9715(9.6376) | Error 0.0180(0.0274) Steps 682(670.39) | Grad Norm 2.9507(7.9241) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 24.9958, Epoch Time 440.3417(439.0231), Bit/dim 3.6902(best: 3.6877), Xent 3.2317, Loss 5.3060, Error 0.4532(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2317 | Time 64.0535(66.4931) | Bit/dim 3.6670(3.6646) | Xent 0.0603(0.0825) | Loss 13.4741(9.7527) | Error 0.0201(0.0272) Steps 664(670.20) | Grad Norm 3.9751(7.8057) | Total Time 0.00(0.00)\n",
      "Iter 2318 | Time 66.3660(66.4893) | Bit/dim 3.6534(3.6643) | Xent 0.0601(0.0818) | Loss 8.9315(9.7281) | Error 0.0201(0.0270) Steps 658(669.83) | Grad Norm 5.7409(7.7437) | Total Time 0.00(0.00)\n",
      "Iter 2319 | Time 67.5520(66.5212) | Bit/dim 3.6524(3.6639) | Xent 0.0559(0.0810) | Loss 8.8244(9.7010) | Error 0.0182(0.0267) Steps 652(669.29) | Grad Norm 2.5323(7.5874) | Total Time 0.00(0.00)\n",
      "Iter 2320 | Time 64.3473(66.4559) | Bit/dim 3.6477(3.6635) | Xent 0.0661(0.0806) | Loss 8.8794(9.6763) | Error 0.0215(0.0266) Steps 676(669.50) | Grad Norm 4.9138(7.5072) | Total Time 0.00(0.00)\n",
      "Iter 2321 | Time 66.3516(66.4528) | Bit/dim 3.6671(3.6636) | Xent 0.0627(0.0800) | Loss 8.8204(9.6506) | Error 0.0198(0.0264) Steps 670(669.51) | Grad Norm 3.2576(7.3797) | Total Time 0.00(0.00)\n",
      "Iter 2322 | Time 66.5611(66.4561) | Bit/dim 3.6609(3.6635) | Xent 0.0615(0.0795) | Loss 8.8760(9.6274) | Error 0.0210(0.0262) Steps 670(669.53) | Grad Norm 3.7274(7.2701) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 25.3621, Epoch Time 438.6495(439.0119), Bit/dim 3.6879(best: 3.6877), Xent 3.2645, Loss 5.3201, Error 0.4531(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2323 | Time 66.8677(66.4684) | Bit/dim 3.6570(3.6633) | Xent 0.0552(0.0787) | Loss 13.8328(9.7536) | Error 0.0179(0.0260) Steps 676(669.72) | Grad Norm 5.5613(7.2188) | Total Time 0.00(0.00)\n",
      "Iter 2324 | Time 66.0082(66.4546) | Bit/dim 3.6694(3.6635) | Xent 0.0600(0.0782) | Loss 8.9249(9.7287) | Error 0.0182(0.0257) Steps 688(670.27) | Grad Norm 2.8193(7.0869) | Total Time 0.00(0.00)\n",
      "Iter 2325 | Time 63.7463(66.3734) | Bit/dim 3.6630(3.6635) | Xent 0.0754(0.0781) | Loss 8.6683(9.6969) | Error 0.0258(0.0257) Steps 664(670.08) | Grad Norm 8.9546(7.1429) | Total Time 0.00(0.00)\n",
      "Iter 2326 | Time 67.0515(66.3937) | Bit/dim 3.6578(3.6633) | Xent 0.0886(0.0784) | Loss 9.0219(9.6766) | Error 0.0292(0.0258) Steps 664(669.90) | Grad Norm 8.0858(7.1712) | Total Time 0.00(0.00)\n",
      "Iter 2327 | Time 65.0419(66.3532) | Bit/dim 3.6554(3.6631) | Xent 0.0611(0.0779) | Loss 9.0460(9.6577) | Error 0.0208(0.0257) Steps 694(670.62) | Grad Norm 5.5621(7.1229) | Total Time 0.00(0.00)\n",
      "Iter 2328 | Time 61.3475(66.2030) | Bit/dim 3.6482(3.6626) | Xent 0.0582(0.0773) | Loss 8.7714(9.6311) | Error 0.0181(0.0254) Steps 676(670.78) | Grad Norm 4.0064(7.0294) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 24.9900, Epoch Time 432.9142(438.8290), Bit/dim 3.6921(best: 3.6877), Xent 3.3514, Loss 5.3678, Error 0.4536(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2329 | Time 63.0858(66.1095) | Bit/dim 3.6654(3.6627) | Xent 0.0698(0.0771) | Loss 13.5484(9.7486) | Error 0.0231(0.0254) Steps 664(670.58) | Grad Norm 5.8505(6.9940) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 63.0716(66.0183) | Bit/dim 3.6631(3.6627) | Xent 0.0573(0.0765) | Loss 8.9661(9.7252) | Error 0.0180(0.0252) Steps 688(671.10) | Grad Norm 5.6448(6.9536) | Total Time 0.00(0.00)\n",
      "Iter 2331 | Time 67.3796(66.0592) | Bit/dim 3.6641(3.6628) | Xent 0.0579(0.0759) | Loss 8.9995(9.7034) | Error 0.0188(0.0250) Steps 676(671.25) | Grad Norm 5.5652(6.9119) | Total Time 0.00(0.00)\n",
      "Iter 2332 | Time 69.2612(66.1552) | Bit/dim 3.6578(3.6626) | Xent 0.0638(0.0756) | Loss 8.8243(9.6770) | Error 0.0199(0.0248) Steps 664(671.03) | Grad Norm 5.1139(6.8580) | Total Time 0.00(0.00)\n",
      "Iter 2333 | Time 69.7837(66.2641) | Bit/dim 3.6476(3.6622) | Xent 0.0610(0.0751) | Loss 8.7386(9.6489) | Error 0.0185(0.0246) Steps 658(670.64) | Grad Norm 3.0214(6.7429) | Total Time 0.00(0.00)\n",
      "Iter 2334 | Time 60.6878(66.0968) | Bit/dim 3.6545(3.6619) | Xent 0.0747(0.0751) | Loss 8.7303(9.6213) | Error 0.0255(0.0246) Steps 658(670.26) | Grad Norm 6.2407(6.7278) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 24.4284, Epoch Time 436.3816(438.7556), Bit/dim 3.6889(best: 3.6877), Xent 3.3503, Loss 5.3641, Error 0.4578(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2335 | Time 62.7943(65.9977) | Bit/dim 3.6544(3.6617) | Xent 0.0516(0.0744) | Loss 13.2538(9.7303) | Error 0.0168(0.0244) Steps 670(670.25) | Grad Norm 4.9100(6.6733) | Total Time 0.00(0.00)\n",
      "Iter 2336 | Time 70.6406(66.1370) | Bit/dim 3.6533(3.6614) | Xent 0.0600(0.0740) | Loss 9.0180(9.7089) | Error 0.0192(0.0243) Steps 694(670.97) | Grad Norm 4.4254(6.6058) | Total Time 0.00(0.00)\n",
      "Iter 2337 | Time 64.2164(66.0794) | Bit/dim 3.6513(3.6611) | Xent 0.0565(0.0734) | Loss 8.7712(9.6808) | Error 0.0168(0.0240) Steps 664(670.76) | Grad Norm 5.3081(6.5669) | Total Time 0.00(0.00)\n",
      "Iter 2338 | Time 68.0944(66.1398) | Bit/dim 3.6638(3.6612) | Xent 0.0611(0.0731) | Loss 8.8898(9.6571) | Error 0.0174(0.0238) Steps 700(671.63) | Grad Norm 4.4930(6.5047) | Total Time 0.00(0.00)\n",
      "Iter 2339 | Time 66.1038(66.1388) | Bit/dim 3.6594(3.6612) | Xent 0.0663(0.0729) | Loss 8.9195(9.6349) | Error 0.0210(0.0237) Steps 688(672.12) | Grad Norm 6.2671(6.4976) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 69.7883(66.2482) | Bit/dim 3.6591(3.6611) | Xent 0.0643(0.0726) | Loss 8.8084(9.6101) | Error 0.0210(0.0237) Steps 694(672.78) | Grad Norm 6.2393(6.4898) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 24.9076, Epoch Time 444.9421(438.9412), Bit/dim 3.6924(best: 3.6877), Xent 3.4110, Loss 5.3979, Error 0.4558(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2341 | Time 64.4600(66.1946) | Bit/dim 3.6617(3.6611) | Xent 0.0617(0.0723) | Loss 13.5330(9.7278) | Error 0.0186(0.0235) Steps 694(673.42) | Grad Norm 5.7483(6.4676) | Total Time 0.00(0.00)\n",
      "Iter 2342 | Time 63.0288(66.0996) | Bit/dim 3.6569(3.6610) | Xent 0.0660(0.0721) | Loss 8.7568(9.6987) | Error 0.0221(0.0235) Steps 658(672.96) | Grad Norm 8.3220(6.5232) | Total Time 0.00(0.00)\n",
      "Iter 2343 | Time 67.2349(66.1337) | Bit/dim 3.6631(3.6611) | Xent 0.0656(0.0719) | Loss 8.9925(9.6775) | Error 0.0201(0.0234) Steps 670(672.87) | Grad Norm 4.7074(6.4687) | Total Time 0.00(0.00)\n",
      "Iter 2344 | Time 65.7122(66.1210) | Bit/dim 3.6600(3.6610) | Xent 0.0625(0.0716) | Loss 8.7421(9.6494) | Error 0.0220(0.0233) Steps 676(672.96) | Grad Norm 8.6936(6.5355) | Total Time 0.00(0.00)\n",
      "Iter 2345 | Time 63.6188(66.0460) | Bit/dim 3.6557(3.6609) | Xent 0.0604(0.0713) | Loss 8.8913(9.6267) | Error 0.0190(0.0232) Steps 676(673.05) | Grad Norm 4.0594(6.4612) | Total Time 0.00(0.00)\n",
      "Iter 2346 | Time 62.1460(65.9290) | Bit/dim 3.6668(3.6610) | Xent 0.0713(0.0713) | Loss 8.8222(9.6026) | Error 0.0231(0.0232) Steps 658(672.60) | Grad Norm 8.7198(6.5290) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 25.2410, Epoch Time 430.2249(438.6797), Bit/dim 3.6960(best: 3.6877), Xent 3.4276, Loss 5.4098, Error 0.4605(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2347 | Time 66.1040(65.9342) | Bit/dim 3.6611(3.6610) | Xent 0.0644(0.0711) | Loss 13.0005(9.7045) | Error 0.0214(0.0231) Steps 652(671.98) | Grad Norm 6.9952(6.5429) | Total Time 0.00(0.00)\n",
      "Iter 2348 | Time 67.0706(65.9683) | Bit/dim 3.6565(3.6609) | Xent 0.0582(0.0707) | Loss 8.9058(9.6805) | Error 0.0196(0.0230) Steps 682(672.28) | Grad Norm 4.3014(6.4757) | Total Time 0.00(0.00)\n",
      "Iter 2349 | Time 69.2308(66.0662) | Bit/dim 3.6631(3.6610) | Xent 0.0688(0.0706) | Loss 8.9909(9.6599) | Error 0.0222(0.0230) Steps 688(672.75) | Grad Norm 7.0943(6.4943) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 72.3060(66.2534) | Bit/dim 3.6583(3.6609) | Xent 0.0535(0.0701) | Loss 8.8307(9.6350) | Error 0.0158(0.0228) Steps 694(673.39) | Grad Norm 4.7593(6.4422) | Total Time 0.00(0.00)\n",
      "Iter 2351 | Time 67.5949(66.2936) | Bit/dim 3.6618(3.6609) | Xent 0.0541(0.0696) | Loss 8.9104(9.6132) | Error 0.0165(0.0226) Steps 670(673.29) | Grad Norm 5.4593(6.4127) | Total Time 0.00(0.00)\n",
      "Iter 2352 | Time 65.1027(66.2579) | Bit/dim 3.6540(3.6607) | Xent 0.0779(0.0699) | Loss 8.8780(9.5912) | Error 0.0276(0.0228) Steps 640(672.29) | Grad Norm 9.1478(6.4948) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 25.2475, Epoch Time 451.2475(439.0567), Bit/dim 3.6897(best: 3.6877), Xent 3.4136, Loss 5.3965, Error 0.4635(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2353 | Time 65.0145(66.2206) | Bit/dim 3.6637(3.6608) | Xent 0.0702(0.0699) | Loss 13.4325(9.7064) | Error 0.0225(0.0228) Steps 658(671.86) | Grad Norm 5.9049(6.4771) | Total Time 0.00(0.00)\n",
      "Iter 2354 | Time 68.3279(66.2838) | Bit/dim 3.6566(3.6607) | Xent 0.0565(0.0695) | Loss 8.5336(9.6712) | Error 0.0169(0.0226) Steps 688(672.35) | Grad Norm 3.8027(6.3968) | Total Time 0.00(0.00)\n",
      "Iter 2355 | Time 62.7444(66.1776) | Bit/dim 3.6557(3.6605) | Xent 0.0575(0.0691) | Loss 8.6954(9.6420) | Error 0.0188(0.0225) Steps 688(672.82) | Grad Norm 4.6298(6.3438) | Total Time 0.00(0.00)\n",
      "Iter 2356 | Time 70.5789(66.3097) | Bit/dim 3.6668(3.6607) | Xent 0.0584(0.0688) | Loss 9.0169(9.6232) | Error 0.0190(0.0224) Steps 658(672.37) | Grad Norm 4.3094(6.2828) | Total Time 0.00(0.00)\n",
      "Iter 2357 | Time 65.6408(66.2896) | Bit/dim 3.6645(3.6608) | Xent 0.0744(0.0690) | Loss 8.9010(9.6015) | Error 0.0250(0.0224) Steps 664(672.12) | Grad Norm 8.7182(6.3559) | Total Time 0.00(0.00)\n",
      "Iter 2358 | Time 64.6142(66.2393) | Bit/dim 3.6472(3.6604) | Xent 0.0868(0.0695) | Loss 8.8692(9.5796) | Error 0.0291(0.0226) Steps 670(672.06) | Grad Norm 11.5484(6.5116) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 25.4090, Epoch Time 440.4895(439.0997), Bit/dim 3.6973(best: 3.6877), Xent 3.3466, Loss 5.3706, Error 0.4567(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2359 | Time 66.2243(66.2389) | Bit/dim 3.6614(3.6605) | Xent 0.0714(0.0696) | Loss 13.8656(9.7082) | Error 0.0234(0.0227) Steps 658(671.64) | Grad Norm 8.0682(6.5583) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 62.7840(66.1352) | Bit/dim 3.6572(3.6604) | Xent 0.0665(0.0695) | Loss 8.7862(9.6805) | Error 0.0216(0.0226) Steps 664(671.41) | Grad Norm 5.9285(6.5394) | Total Time 0.00(0.00)\n",
      "Iter 2361 | Time 65.4388(66.1144) | Bit/dim 3.6579(3.6603) | Xent 0.0798(0.0698) | Loss 8.8712(9.6562) | Error 0.0270(0.0228) Steps 670(671.36) | Grad Norm 9.2506(6.6208) | Total Time 0.00(0.00)\n",
      "Iter 2362 | Time 68.0636(66.1728) | Bit/dim 3.6644(3.6604) | Xent 0.0706(0.0698) | Loss 8.9996(9.6365) | Error 0.0242(0.0228) Steps 700(672.22) | Grad Norm 9.6804(6.7126) | Total Time 0.00(0.00)\n",
      "Iter 2363 | Time 65.6239(66.1564) | Bit/dim 3.6694(3.6607) | Xent 0.0555(0.0694) | Loss 9.0091(9.6177) | Error 0.0169(0.0226) Steps 652(671.62) | Grad Norm 5.2779(6.6695) | Total Time 0.00(0.00)\n",
      "Iter 2364 | Time 68.8946(66.2385) | Bit/dim 3.6664(3.6608) | Xent 0.0750(0.0696) | Loss 9.0243(9.5999) | Error 0.0246(0.0227) Steps 688(672.11) | Grad Norm 8.0368(6.7105) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 24.6610, Epoch Time 439.9348(439.1248), Bit/dim 3.6954(best: 3.6877), Xent 3.2751, Loss 5.3329, Error 0.4587(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2365 | Time 67.7420(66.2836) | Bit/dim 3.6596(3.6608) | Xent 0.0564(0.0692) | Loss 13.0810(9.7043) | Error 0.0208(0.0226) Steps 676(672.22) | Grad Norm 5.5881(6.6769) | Total Time 0.00(0.00)\n",
      "Iter 2366 | Time 61.8662(66.1511) | Bit/dim 3.6659(3.6610) | Xent 0.0575(0.0688) | Loss 8.8330(9.6782) | Error 0.0185(0.0225) Steps 652(671.62) | Grad Norm 4.3267(6.6064) | Total Time 0.00(0.00)\n",
      "Iter 2367 | Time 68.1242(66.2103) | Bit/dim 3.6631(3.6610) | Xent 0.0644(0.0687) | Loss 8.8873(9.6545) | Error 0.0206(0.0224) Steps 682(671.93) | Grad Norm 5.9152(6.5856) | Total Time 0.00(0.00)\n",
      "Iter 2368 | Time 70.1918(66.3297) | Bit/dim 3.6547(3.6608) | Xent 0.0618(0.0685) | Loss 8.9872(9.6344) | Error 0.0202(0.0224) Steps 688(672.41) | Grad Norm 4.3031(6.5172) | Total Time 0.00(0.00)\n",
      "Iter 2369 | Time 62.9036(66.2269) | Bit/dim 3.6569(3.6607) | Xent 0.0639(0.0683) | Loss 8.9998(9.6154) | Error 0.0209(0.0223) Steps 676(672.52) | Grad Norm 4.9018(6.4687) | Total Time 0.00(0.00)\n",
      "Iter 2370 | Time 66.8546(66.2458) | Bit/dim 3.6584(3.6606) | Xent 0.0592(0.0681) | Loss 8.9215(9.5946) | Error 0.0195(0.0223) Steps 694(673.16) | Grad Norm 4.4244(6.4074) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 24.9414, Epoch Time 441.2890(439.1897), Bit/dim 3.6938(best: 3.6877), Xent 3.4629, Loss 5.4253, Error 0.4553(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2371 | Time 73.4307(66.4613) | Bit/dim 3.6652(3.6608) | Xent 0.0695(0.0681) | Loss 13.8093(9.7210) | Error 0.0216(0.0222) Steps 676(673.25) | Grad Norm 7.8685(6.4512) | Total Time 0.00(0.00)\n",
      "Iter 2372 | Time 67.2091(66.4838) | Bit/dim 3.6581(3.6607) | Xent 0.0495(0.0675) | Loss 8.8010(9.6934) | Error 0.0150(0.0220) Steps 664(672.97) | Grad Norm 3.3690(6.3587) | Total Time 0.00(0.00)\n",
      "Iter 2373 | Time 62.1741(66.3545) | Bit/dim 3.6563(3.6606) | Xent 0.0678(0.0676) | Loss 8.7430(9.6649) | Error 0.0209(0.0220) Steps 676(673.06) | Grad Norm 9.0100(6.4383) | Total Time 0.00(0.00)\n",
      "Iter 2374 | Time 72.9553(66.5525) | Bit/dim 3.6609(3.6606) | Xent 0.0594(0.0673) | Loss 8.8585(9.6407) | Error 0.0191(0.0219) Steps 670(672.97) | Grad Norm 4.5703(6.3822) | Total Time 0.00(0.00)\n",
      "Iter 2375 | Time 70.3028(66.6650) | Bit/dim 3.6582(3.6605) | Xent 0.0687(0.0674) | Loss 8.9658(9.6205) | Error 0.0225(0.0219) Steps 682(673.24) | Grad Norm 7.2221(6.4074) | Total Time 0.00(0.00)\n",
      "Iter 2376 | Time 65.7721(66.6382) | Bit/dim 3.6799(3.6611) | Xent 0.0540(0.0669) | Loss 9.0021(9.6019) | Error 0.0164(0.0217) Steps 688(673.68) | Grad Norm 4.8212(6.3598) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 25.2754, Epoch Time 455.9121(439.6914), Bit/dim 3.6987(best: 3.6877), Xent 3.4462, Loss 5.4218, Error 0.4588(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2377 | Time 67.4943(66.6639) | Bit/dim 3.6618(3.6611) | Xent 0.0714(0.0671) | Loss 13.2351(9.7109) | Error 0.0231(0.0218) Steps 676(673.75) | Grad Norm 5.6125(6.3374) | Total Time 0.00(0.00)\n",
      "Iter 2378 | Time 72.4298(66.8369) | Bit/dim 3.6681(3.6613) | Xent 0.0552(0.0667) | Loss 8.9464(9.6880) | Error 0.0158(0.0216) Steps 688(674.18) | Grad Norm 3.0600(6.2391) | Total Time 0.00(0.00)\n",
      "Iter 2379 | Time 65.9833(66.8113) | Bit/dim 3.6568(3.6612) | Xent 0.0678(0.0668) | Loss 8.8660(9.6633) | Error 0.0234(0.0217) Steps 682(674.42) | Grad Norm 5.7260(6.2237) | Total Time 0.00(0.00)\n",
      "Iter 2380 | Time 70.3629(66.9178) | Bit/dim 3.6659(3.6613) | Xent 0.0643(0.0667) | Loss 8.7940(9.6372) | Error 0.0210(0.0216) Steps 688(674.82) | Grad Norm 3.4961(6.1419) | Total Time 0.00(0.00)\n",
      "Iter 2381 | Time 66.7977(66.9142) | Bit/dim 3.6652(3.6614) | Xent 0.0596(0.0665) | Loss 8.9263(9.6159) | Error 0.0191(0.0216) Steps 676(674.86) | Grad Norm 5.5153(6.1231) | Total Time 0.00(0.00)\n",
      "Iter 2382 | Time 71.0222(67.0375) | Bit/dim 3.6543(3.6612) | Xent 0.0573(0.0662) | Loss 9.0314(9.5984) | Error 0.0175(0.0214) Steps 664(674.53) | Grad Norm 3.0628(6.0313) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 24.9575, Epoch Time 456.8832(440.2071), Bit/dim 3.6946(best: 3.6877), Xent 3.3056, Loss 5.3473, Error 0.4576(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2383 | Time 65.7311(66.9983) | Bit/dim 3.6509(3.6609) | Xent 0.0648(0.0662) | Loss 13.6144(9.7189) | Error 0.0206(0.0214) Steps 658(674.04) | Grad Norm 4.5051(5.9855) | Total Time 0.00(0.00)\n",
      "Iter 2384 | Time 65.4584(66.9521) | Bit/dim 3.6653(3.6611) | Xent 0.0688(0.0662) | Loss 8.7284(9.6892) | Error 0.0222(0.0214) Steps 664(673.74) | Grad Norm 4.5370(5.9420) | Total Time 0.00(0.00)\n",
      "Iter 2385 | Time 70.3389(67.0537) | Bit/dim 3.6544(3.6609) | Xent 0.0585(0.0660) | Loss 8.9934(9.6683) | Error 0.0196(0.0214) Steps 682(673.98) | Grad Norm 4.5504(5.9003) | Total Time 0.00(0.00)\n",
      "Iter 2386 | Time 60.8483(66.8675) | Bit/dim 3.6555(3.6607) | Xent 0.0568(0.0657) | Loss 8.7103(9.6395) | Error 0.0178(0.0213) Steps 670(673.86) | Grad Norm 4.0408(5.8445) | Total Time 0.00(0.00)\n",
      "Iter 2387 | Time 71.9071(67.0187) | Bit/dim 3.6598(3.6607) | Xent 0.0586(0.0655) | Loss 8.9806(9.6198) | Error 0.0181(0.0212) Steps 676(673.93) | Grad Norm 3.2715(5.7673) | Total Time 0.00(0.00)\n",
      "Iter 2388 | Time 66.3975(67.0001) | Bit/dim 3.6718(3.6610) | Xent 0.0732(0.0657) | Loss 9.0585(9.6029) | Error 0.0212(0.0212) Steps 688(674.35) | Grad Norm 5.2270(5.7511) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 25.2760, Epoch Time 444.0949(440.3237), Bit/dim 3.6911(best: 3.6877), Xent 3.4152, Loss 5.3987, Error 0.4532(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2389 | Time 70.0036(67.0902) | Bit/dim 3.6627(3.6610) | Xent 0.0510(0.0653) | Loss 13.6396(9.7240) | Error 0.0139(0.0210) Steps 676(674.40) | Grad Norm 3.9401(5.6968) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 66.3128(67.0669) | Bit/dim 3.6605(3.6610) | Xent 0.0651(0.0653) | Loss 8.8620(9.6982) | Error 0.0199(0.0209) Steps 682(674.63) | Grad Norm 6.3789(5.7172) | Total Time 0.00(0.00)\n",
      "Iter 2391 | Time 71.0649(67.1868) | Bit/dim 3.6612(3.6610) | Xent 0.0602(0.0651) | Loss 8.9083(9.6745) | Error 0.0192(0.0209) Steps 664(674.31) | Grad Norm 4.8351(5.6908) | Total Time 0.00(0.00)\n",
      "Iter 2392 | Time 69.4465(67.2546) | Bit/dim 3.6575(3.6609) | Xent 0.0602(0.0650) | Loss 8.7256(9.6460) | Error 0.0189(0.0208) Steps 676(674.36) | Grad Norm 7.2941(5.7389) | Total Time 0.00(0.00)\n",
      "Iter 2393 | Time 68.5314(67.2929) | Bit/dim 3.6539(3.6607) | Xent 0.0621(0.0649) | Loss 8.9025(9.6237) | Error 0.0188(0.0208) Steps 676(674.41) | Grad Norm 3.6771(5.6770) | Total Time 0.00(0.00)\n",
      "Iter 2394 | Time 66.1659(67.2591) | Bit/dim 3.6582(3.6606) | Xent 0.0649(0.0649) | Loss 8.8515(9.6005) | Error 0.0201(0.0207) Steps 652(673.74) | Grad Norm 5.1813(5.6621) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 25.0745, Epoch Time 454.7609(440.7569), Bit/dim 3.6917(best: 3.6877), Xent 3.4486, Loss 5.4160, Error 0.4488(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2395 | Time 66.9822(67.2508) | Bit/dim 3.6373(3.6599) | Xent 0.0579(0.0647) | Loss 13.5599(9.7193) | Error 0.0195(0.0207) Steps 694(674.34) | Grad Norm 3.8194(5.6069) | Total Time 0.00(0.00)\n",
      "Iter 2396 | Time 70.2322(67.3402) | Bit/dim 3.6601(3.6599) | Xent 0.0463(0.0641) | Loss 8.9797(9.6971) | Error 0.0156(0.0206) Steps 682(674.57) | Grad Norm 3.6555(5.5483) | Total Time 0.00(0.00)\n",
      "Iter 2397 | Time 70.8000(67.4440) | Bit/dim 3.6647(3.6601) | Xent 0.0602(0.0640) | Loss 8.9261(9.6740) | Error 0.0182(0.0205) Steps 682(674.80) | Grad Norm 4.1810(5.5073) | Total Time 0.00(0.00)\n",
      "Iter 2398 | Time 70.2799(67.5291) | Bit/dim 3.6625(3.6602) | Xent 0.0643(0.0640) | Loss 8.8670(9.6498) | Error 0.0206(0.0205) Steps 694(675.37) | Grad Norm 6.2603(5.5299) | Total Time 0.00(0.00)\n",
      "Iter 2399 | Time 68.9415(67.5715) | Bit/dim 3.6528(3.6599) | Xent 0.0533(0.0637) | Loss 9.0337(9.6313) | Error 0.0178(0.0204) Steps 682(675.57) | Grad Norm 3.9976(5.4839) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 63.5787(67.4517) | Bit/dim 3.6611(3.6600) | Xent 0.0623(0.0637) | Loss 8.8644(9.6083) | Error 0.0189(0.0204) Steps 682(675.76) | Grad Norm 4.3527(5.4500) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 24.8202, Epoch Time 453.7165(441.1456), Bit/dim 3.6840(best: 3.6877), Xent 3.4149, Loss 5.3914, Error 0.4643(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2401 | Time 71.1418(67.5624) | Bit/dim 3.6589(3.6599) | Xent 0.0682(0.0638) | Loss 13.4625(9.7239) | Error 0.0239(0.0205) Steps 688(676.13) | Grad Norm 6.6775(5.4868) | Total Time 0.00(0.00)\n",
      "Iter 2402 | Time 60.8713(67.3616) | Bit/dim 3.6583(3.6599) | Xent 0.0713(0.0640) | Loss 8.8210(9.6968) | Error 0.0225(0.0205) Steps 664(675.77) | Grad Norm 8.2792(5.5706) | Total Time 0.00(0.00)\n",
      "Iter 2403 | Time 71.4698(67.4849) | Bit/dim 3.6504(3.6596) | Xent 0.0638(0.0640) | Loss 8.9064(9.6731) | Error 0.0205(0.0205) Steps 658(675.23) | Grad Norm 5.3036(5.5626) | Total Time 0.00(0.00)\n",
      "Iter 2404 | Time 68.2431(67.5076) | Bit/dim 3.6490(3.6593) | Xent 0.0520(0.0637) | Loss 8.7122(9.6443) | Error 0.0162(0.0204) Steps 676(675.26) | Grad Norm 5.4265(5.5585) | Total Time 0.00(0.00)\n",
      "Iter 2405 | Time 69.3150(67.5619) | Bit/dim 3.6747(3.6598) | Xent 0.0605(0.0636) | Loss 8.9178(9.6225) | Error 0.0220(0.0204) Steps 652(674.56) | Grad Norm 6.3722(5.5829) | Total Time 0.00(0.00)\n",
      "Iter 2406 | Time 72.0018(67.6951) | Bit/dim 3.6563(3.6597) | Xent 0.0728(0.0638) | Loss 8.8528(9.5994) | Error 0.0239(0.0205) Steps 682(674.78) | Grad Norm 9.3463(5.6958) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 24.9083, Epoch Time 456.7260(441.6131), Bit/dim 3.6887(best: 3.6840), Xent 3.3501, Loss 5.3637, Error 0.4586(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2407 | Time 59.2263(67.4410) | Bit/dim 3.6615(3.6597) | Xent 0.0658(0.0639) | Loss 13.7670(9.7244) | Error 0.0205(0.0205) Steps 682(675.00) | Grad Norm 8.7386(5.7871) | Total Time 0.00(0.00)\n",
      "Iter 2408 | Time 66.8515(67.4233) | Bit/dim 3.6655(3.6599) | Xent 0.0648(0.0639) | Loss 8.8011(9.6967) | Error 0.0215(0.0206) Steps 688(675.39) | Grad Norm 6.4167(5.8060) | Total Time 0.00(0.00)\n",
      "Iter 2409 | Time 76.2264(67.6874) | Bit/dim 3.6505(3.6596) | Xent 0.0606(0.0638) | Loss 8.8270(9.6706) | Error 0.0208(0.0206) Steps 718(676.67) | Grad Norm 5.6506(5.8013) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 70.6549(67.7764) | Bit/dim 3.6520(3.6594) | Xent 0.0625(0.0638) | Loss 8.8825(9.6470) | Error 0.0208(0.0206) Steps 706(677.55) | Grad Norm 7.5643(5.8542) | Total Time 0.00(0.00)\n",
      "Iter 2411 | Time 73.4489(67.9466) | Bit/dim 3.6516(3.6591) | Xent 0.0624(0.0637) | Loss 8.8983(9.6245) | Error 0.0189(0.0205) Steps 688(677.86) | Grad Norm 7.4190(5.9012) | Total Time 0.00(0.00)\n",
      "Iter 2412 | Time 63.9265(67.8260) | Bit/dim 3.6616(3.6592) | Xent 0.0552(0.0635) | Loss 8.9291(9.6037) | Error 0.0185(0.0205) Steps 682(677.99) | Grad Norm 3.7901(5.8378) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 25.6705, Epoch Time 455.2762(442.0229), Bit/dim 3.6899(best: 3.6840), Xent 3.4253, Loss 5.4026, Error 0.4482(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2413 | Time 67.8969(67.8281) | Bit/dim 3.6546(3.6591) | Xent 0.0501(0.0631) | Loss 13.2768(9.7139) | Error 0.0160(0.0203) Steps 700(678.65) | Grad Norm 4.3060(5.7919) | Total Time 0.00(0.00)\n",
      "Iter 2414 | Time 75.6152(68.0617) | Bit/dim 3.6494(3.6588) | Xent 0.0560(0.0629) | Loss 8.7635(9.6854) | Error 0.0169(0.0202) Steps 718(679.83) | Grad Norm 4.6797(5.7585) | Total Time 0.00(0.00)\n",
      "Iter 2415 | Time 71.1347(68.1539) | Bit/dim 3.6541(3.6586) | Xent 0.0508(0.0625) | Loss 8.8340(9.6598) | Error 0.0174(0.0201) Steps 682(679.89) | Grad Norm 5.6507(5.7553) | Total Time 0.00(0.00)\n",
      "Iter 2416 | Time 71.0221(68.2400) | Bit/dim 3.6628(3.6588) | Xent 0.0461(0.0620) | Loss 9.0579(9.6418) | Error 0.0134(0.0199) Steps 694(680.32) | Grad Norm 3.6729(5.6928) | Total Time 0.00(0.00)\n",
      "Iter 2417 | Time 77.4443(68.5161) | Bit/dim 3.6618(3.6589) | Xent 0.0709(0.0623) | Loss 9.0039(9.6226) | Error 0.0208(0.0200) Steps 676(680.19) | Grad Norm 11.5948(5.8699) | Total Time 0.00(0.00)\n",
      "Iter 2418 | Time 62.3623(68.3315) | Bit/dim 3.6693(3.6592) | Xent 0.1192(0.0640) | Loss 8.7737(9.5972) | Error 0.0379(0.0205) Steps 664(679.70) | Grad Norm 15.5389(6.1599) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 24.7967, Epoch Time 468.3152(442.8117), Bit/dim 3.6922(best: 3.6840), Xent 3.5881, Loss 5.4862, Error 0.4742(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2419 | Time 73.8123(68.4959) | Bit/dim 3.6528(3.6590) | Xent 0.3622(0.0729) | Loss 14.0793(9.7316) | Error 0.1066(0.0231) Steps 700(680.31) | Grad Norm 25.3058(6.7343) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 69.9592(68.5398) | Bit/dim 3.6651(3.6592) | Xent 0.5351(0.0868) | Loss 9.2610(9.7175) | Error 0.1509(0.0269) Steps 706(681.08) | Grad Norm 32.3989(7.5042) | Total Time 0.00(0.00)\n",
      "Iter 2421 | Time 74.9389(68.7318) | Bit/dim 3.6564(3.6591) | Xent 0.1255(0.0880) | Loss 9.0492(9.6975) | Error 0.0417(0.0274) Steps 676(680.93) | Grad Norm 11.9598(7.6379) | Total Time 0.00(0.00)\n",
      "Iter 2422 | Time 71.8037(68.8239) | Bit/dim 3.6835(3.6598) | Xent 0.2549(0.0930) | Loss 9.0833(9.6790) | Error 0.0900(0.0292) Steps 646(679.88) | Grad Norm 17.9251(7.9465) | Total Time 0.00(0.00)\n",
      "Iter 2423 | Time 64.3028(68.6883) | Bit/dim 3.6835(3.6605) | Xent 0.1784(0.0955) | Loss 9.0031(9.6587) | Error 0.0603(0.0302) Steps 670(679.58) | Grad Norm 10.1326(8.0121) | Total Time 0.00(0.00)\n",
      "Iter 2424 | Time 69.8112(68.7220) | Bit/dim 3.6779(3.6610) | Xent 0.2161(0.0991) | Loss 9.1178(9.6425) | Error 0.0757(0.0315) Steps 652(678.76) | Grad Norm 8.7850(8.0353) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 24.4923, Epoch Time 467.2448(443.5447), Bit/dim 3.6950(best: 3.6840), Xent 2.5823, Loss 4.9861, Error 0.4515(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2425 | Time 69.6812(68.7508) | Bit/dim 3.6604(3.6610) | Xent 0.1799(0.1016) | Loss 13.5989(9.7612) | Error 0.0637(0.0325) Steps 694(679.21) | Grad Norm 8.7634(8.0571) | Total Time 0.00(0.00)\n",
      "Iter 2426 | Time 61.4155(68.5307) | Bit/dim 3.6831(3.6617) | Xent 0.1850(0.1041) | Loss 8.8852(9.7349) | Error 0.0664(0.0335) Steps 640(678.04) | Grad Norm 7.9548(8.0541) | Total Time 0.00(0.00)\n",
      "Iter 2427 | Time 68.0758(68.5171) | Bit/dim 3.6675(3.6619) | Xent 0.1377(0.1051) | Loss 8.9463(9.7113) | Error 0.0499(0.0340) Steps 634(676.72) | Grad Norm 6.3931(8.0042) | Total Time 0.00(0.00)\n",
      "Iter 2428 | Time 62.9516(68.3501) | Bit/dim 3.6694(3.6621) | Xent 0.1620(0.1068) | Loss 9.1260(9.6937) | Error 0.0597(0.0348) Steps 658(676.15) | Grad Norm 6.6283(7.9630) | Total Time 0.00(0.00)\n",
      "Iter 2429 | Time 74.3139(68.5290) | Bit/dim 3.6738(3.6624) | Xent 0.1198(0.1072) | Loss 9.1526(9.6775) | Error 0.0386(0.0349) Steps 658(675.61) | Grad Norm 8.1461(7.9685) | Total Time 0.00(0.00)\n",
      "Iter 2430 | Time 69.1058(68.5463) | Bit/dim 3.6683(3.6626) | Xent 0.1491(0.1084) | Loss 8.8820(9.6536) | Error 0.0511(0.0354) Steps 640(674.54) | Grad Norm 6.6839(7.9299) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 24.8539, Epoch Time 448.5211(443.6940), Bit/dim 3.6921(best: 3.6840), Xent 2.9308, Loss 5.1575, Error 0.4604(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2431 | Time 72.4674(68.6639) | Bit/dim 3.6713(3.6629) | Xent 0.0975(0.1081) | Loss 13.7225(9.7757) | Error 0.0290(0.0352) Steps 676(674.58) | Grad Norm 7.6171(7.9205) | Total Time 0.00(0.00)\n",
      "Iter 2432 | Time 67.8275(68.6389) | Bit/dim 3.6666(3.6630) | Xent 0.1102(0.1082) | Loss 9.1526(9.7570) | Error 0.0379(0.0353) Steps 664(674.27) | Grad Norm 6.2650(7.8709) | Total Time 0.00(0.00)\n",
      "Iter 2433 | Time 73.8301(68.7946) | Bit/dim 3.6693(3.6632) | Xent 0.1141(0.1083) | Loss 9.0323(9.7353) | Error 0.0374(0.0353) Steps 652(673.60) | Grad Norm 12.8577(8.0205) | Total Time 0.00(0.00)\n",
      "Iter 2434 | Time 66.2390(68.7179) | Bit/dim 3.6677(3.6633) | Xent 0.1072(0.1083) | Loss 9.0115(9.7135) | Error 0.0337(0.0353) Steps 670(673.49) | Grad Norm 12.9057(8.1670) | Total Time 0.00(0.00)\n",
      "Iter 2435 | Time 69.3010(68.7354) | Bit/dim 3.6693(3.6635) | Xent 0.1028(0.1081) | Loss 8.7102(9.6834) | Error 0.0345(0.0353) Steps 676(673.57) | Grad Norm 7.7842(8.1555) | Total Time 0.00(0.00)\n",
      "Iter 2436 | Time 67.6632(68.7033) | Bit/dim 3.6821(3.6640) | Xent 0.0903(0.1076) | Loss 9.0306(9.6639) | Error 0.0304(0.0351) Steps 670(673.46) | Grad Norm 8.7463(8.1733) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 25.0055, Epoch Time 460.5103(444.1985), Bit/dim 3.6852(best: 3.6840), Xent 3.1635, Loss 5.2670, Error 0.4489(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2437 | Time 67.3347(68.6622) | Bit/dim 3.6616(3.6640) | Xent 0.0857(0.1070) | Loss 13.7298(9.7858) | Error 0.0296(0.0350) Steps 682(673.72) | Grad Norm 6.0148(8.1085) | Total Time 0.00(0.00)\n",
      "Iter 2438 | Time 68.8608(68.6682) | Bit/dim 3.6717(3.6642) | Xent 0.0880(0.1064) | Loss 8.9615(9.7611) | Error 0.0271(0.0347) Steps 670(673.60) | Grad Norm 5.9461(8.0436) | Total Time 0.00(0.00)\n",
      "Iter 2439 | Time 68.8355(68.6732) | Bit/dim 3.6668(3.6643) | Xent 0.0815(0.1056) | Loss 9.0638(9.7402) | Error 0.0269(0.0345) Steps 664(673.32) | Grad Norm 5.1103(7.9556) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 68.5514(68.6695) | Bit/dim 3.6709(3.6645) | Xent 0.0669(0.1045) | Loss 8.8197(9.7126) | Error 0.0201(0.0341) Steps 676(673.40) | Grad Norm 4.4687(7.8510) | Total Time 0.00(0.00)\n",
      "Iter 2441 | Time 67.2641(68.6274) | Bit/dim 3.6619(3.6644) | Xent 0.0855(0.1039) | Loss 8.8348(9.6862) | Error 0.0278(0.0339) Steps 688(673.83) | Grad Norm 5.3555(7.7762) | Total Time 0.00(0.00)\n",
      "Iter 2442 | Time 68.3376(68.6187) | Bit/dim 3.6689(3.6645) | Xent 0.0793(0.1032) | Loss 9.0445(9.6670) | Error 0.0265(0.0336) Steps 658(673.36) | Grad Norm 5.3453(7.7032) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 25.2677, Epoch Time 452.7274(444.4544), Bit/dim 3.6848(best: 3.6840), Xent 3.0786, Loss 5.2241, Error 0.4529(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2443 | Time 71.0091(68.6904) | Bit/dim 3.6616(3.6644) | Xent 0.0812(0.1025) | Loss 13.5915(9.7847) | Error 0.0250(0.0334) Steps 658(672.90) | Grad Norm 5.4196(7.6347) | Total Time 0.00(0.00)\n",
      "Iter 2444 | Time 67.9831(68.6692) | Bit/dim 3.6566(3.6642) | Xent 0.0746(0.1017) | Loss 8.8020(9.7552) | Error 0.0238(0.0331) Steps 664(672.63) | Grad Norm 6.2801(7.5941) | Total Time 0.00(0.00)\n",
      "Iter 2445 | Time 69.8155(68.7035) | Bit/dim 3.6720(3.6644) | Xent 0.0578(0.1004) | Loss 8.9033(9.7297) | Error 0.0170(0.0326) Steps 676(672.73) | Grad Norm 4.5906(7.5040) | Total Time 0.00(0.00)\n",
      "Iter 2446 | Time 69.7225(68.7341) | Bit/dim 3.6702(3.6646) | Xent 0.0737(0.0996) | Loss 8.9702(9.7069) | Error 0.0234(0.0323) Steps 664(672.47) | Grad Norm 7.6246(7.5076) | Total Time 0.00(0.00)\n",
      "Iter 2447 | Time 71.4843(68.8166) | Bit/dim 3.6623(3.6646) | Xent 0.0610(0.0984) | Loss 8.6661(9.6757) | Error 0.0186(0.0319) Steps 676(672.58) | Grad Norm 4.7285(7.4242) | Total Time 0.00(0.00)\n",
      "Iter 2448 | Time 71.2767(68.8904) | Bit/dim 3.6582(3.6644) | Xent 0.0796(0.0978) | Loss 9.0524(9.6570) | Error 0.0239(0.0317) Steps 658(672.14) | Grad Norm 8.8120(7.4659) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 24.8161, Epoch Time 464.9578(445.0695), Bit/dim 3.6865(best: 3.6840), Xent 3.2395, Loss 5.3063, Error 0.4541(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2449 | Time 64.7282(68.7656) | Bit/dim 3.6671(3.6644) | Xent 0.0815(0.0973) | Loss 13.7079(9.7785) | Error 0.0270(0.0315) Steps 652(671.54) | Grad Norm 10.3439(7.5522) | Total Time 0.00(0.00)\n",
      "Iter 2450 | Time 71.0867(68.8352) | Bit/dim 3.6641(3.6644) | Xent 0.0552(0.0961) | Loss 8.7534(9.7477) | Error 0.0161(0.0311) Steps 718(672.93) | Grad Norm 3.4553(7.4293) | Total Time 0.00(0.00)\n",
      "Iter 2451 | Time 69.2497(68.8476) | Bit/dim 3.6636(3.6644) | Xent 0.0762(0.0955) | Loss 8.8726(9.7215) | Error 0.0238(0.0309) Steps 670(672.84) | Grad Norm 7.6186(7.4350) | Total Time 0.00(0.00)\n",
      "Iter 2452 | Time 72.1660(68.9472) | Bit/dim 3.6529(3.6641) | Xent 0.0677(0.0947) | Loss 8.7930(9.6936) | Error 0.0211(0.0306) Steps 688(673.30) | Grad Norm 6.5297(7.4078) | Total Time 0.00(0.00)\n",
      "Iter 2453 | Time 60.6550(68.6984) | Bit/dim 3.6611(3.6640) | Xent 0.0500(0.0933) | Loss 8.7610(9.6657) | Error 0.0165(0.0301) Steps 664(673.02) | Grad Norm 3.3131(7.2850) | Total Time 0.00(0.00)\n",
      "Iter 2454 | Time 74.9156(68.8849) | Bit/dim 3.6580(3.6638) | Xent 0.0592(0.0923) | Loss 8.9161(9.6432) | Error 0.0186(0.0298) Steps 676(673.11) | Grad Norm 5.5136(7.2318) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 24.9936, Epoch Time 455.9067(445.3946), Bit/dim 3.6821(best: 3.6840), Xent 3.2054, Loss 5.2848, Error 0.4571(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2455 | Time 72.4374(68.9915) | Bit/dim 3.6620(3.6637) | Xent 0.0479(0.0910) | Loss 13.5799(9.7613) | Error 0.0149(0.0294) Steps 646(672.29) | Grad Norm 2.7640(7.0978) | Total Time 0.00(0.00)\n",
      "Iter 2456 | Time 62.7382(68.8039) | Bit/dim 3.6612(3.6637) | Xent 0.0548(0.0899) | Loss 8.7420(9.7307) | Error 0.0175(0.0290) Steps 640(671.32) | Grad Norm 5.9044(7.0620) | Total Time 0.00(0.00)\n",
      "Iter 2457 | Time 61.7858(68.5934) | Bit/dim 3.6611(3.6636) | Xent 0.0614(0.0890) | Loss 8.9118(9.7061) | Error 0.0192(0.0287) Steps 658(670.93) | Grad Norm 5.3969(7.0120) | Total Time 0.00(0.00)\n",
      "Iter 2458 | Time 69.9654(68.6345) | Bit/dim 3.6583(3.6634) | Xent 0.0583(0.0881) | Loss 8.9253(9.6827) | Error 0.0179(0.0284) Steps 694(671.62) | Grad Norm 4.3417(6.9319) | Total Time 0.00(0.00)\n",
      "Iter 2459 | Time 72.7023(68.7566) | Bit/dim 3.6612(3.6634) | Xent 0.0606(0.0873) | Loss 8.8286(9.6571) | Error 0.0191(0.0281) Steps 694(672.29) | Grad Norm 7.7233(6.9557) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 69.3206(68.7735) | Bit/dim 3.6551(3.6631) | Xent 0.0581(0.0864) | Loss 8.9170(9.6349) | Error 0.0165(0.0278) Steps 670(672.22) | Grad Norm 6.1520(6.9316) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 25.7541, Epoch Time 453.4371(445.6359), Bit/dim 3.6856(best: 3.6821), Xent 3.3107, Loss 5.3409, Error 0.4582(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2461 | Time 68.8806(68.7767) | Bit/dim 3.6455(3.6626) | Xent 0.0430(0.0851) | Loss 13.6026(9.7539) | Error 0.0142(0.0274) Steps 652(671.61) | Grad Norm 2.9483(6.8121) | Total Time 0.00(0.00)\n",
      "Iter 2462 | Time 67.1940(68.7292) | Bit/dim 3.6612(3.6625) | Xent 0.0492(0.0840) | Loss 8.9209(9.7289) | Error 0.0150(0.0270) Steps 670(671.57) | Grad Norm 3.9280(6.7255) | Total Time 0.00(0.00)\n",
      "Iter 2463 | Time 76.1774(68.9527) | Bit/dim 3.6472(3.6621) | Xent 0.0561(0.0832) | Loss 8.9071(9.7043) | Error 0.0171(0.0267) Steps 688(672.06) | Grad Norm 4.9183(6.6713) | Total Time 0.00(0.00)\n",
      "Iter 2464 | Time 66.6090(68.8823) | Bit/dim 3.6481(3.6617) | Xent 0.0556(0.0824) | Loss 8.9421(9.6814) | Error 0.0185(0.0264) Steps 664(671.82) | Grad Norm 3.6323(6.5802) | Total Time 0.00(0.00)\n",
      "Iter 2465 | Time 71.8398(68.9711) | Bit/dim 3.6605(3.6616) | Xent 0.0603(0.0817) | Loss 8.8077(9.6552) | Error 0.0198(0.0262) Steps 694(672.48) | Grad Norm 5.4495(6.5462) | Total Time 0.00(0.00)\n",
      "Iter 2466 | Time 70.7372(69.0240) | Bit/dim 3.6624(3.6616) | Xent 0.0562(0.0809) | Loss 8.7958(9.6294) | Error 0.0170(0.0260) Steps 694(673.13) | Grad Norm 5.1473(6.5043) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 24.7440, Epoch Time 464.4237(446.1995), Bit/dim 3.6875(best: 3.6821), Xent 3.3744, Loss 5.3747, Error 0.4579(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2467 | Time 62.8164(68.8378) | Bit/dim 3.6607(3.6616) | Xent 0.0398(0.0797) | Loss 13.8831(9.7570) | Error 0.0120(0.0255) Steps 658(672.67) | Grad Norm 3.4966(6.4140) | Total Time 0.00(0.00)\n",
      "Iter 2468 | Time 66.0664(68.7547) | Bit/dim 3.6598(3.6616) | Xent 0.0487(0.0788) | Loss 8.7155(9.7258) | Error 0.0161(0.0253) Steps 670(672.59) | Grad Norm 4.9825(6.3711) | Total Time 0.00(0.00)\n",
      "Iter 2469 | Time 72.0936(68.8548) | Bit/dim 3.6610(3.6616) | Xent 0.0436(0.0777) | Loss 8.9849(9.7035) | Error 0.0138(0.0249) Steps 676(672.70) | Grad Norm 3.3985(6.2819) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 70.4999(68.9042) | Bit/dim 3.6488(3.6612) | Xent 0.0553(0.0770) | Loss 8.6188(9.6710) | Error 0.0174(0.0247) Steps 700(673.51) | Grad Norm 4.5085(6.2287) | Total Time 0.00(0.00)\n",
      "Iter 2471 | Time 70.0711(68.9392) | Bit/dim 3.6605(3.6611) | Xent 0.0447(0.0761) | Loss 8.9668(9.6499) | Error 0.0129(0.0243) Steps 694(674.13) | Grad Norm 3.9919(6.1616) | Total Time 0.00(0.00)\n",
      "Iter 2472 | Time 71.3569(69.0117) | Bit/dim 3.6517(3.6609) | Xent 0.0462(0.0752) | Loss 8.9110(9.6277) | Error 0.0151(0.0241) Steps 676(674.19) | Grad Norm 4.1816(6.1022) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 24.5722, Epoch Time 456.1914(446.4992), Bit/dim 3.6837(best: 3.6821), Xent 3.4350, Loss 5.4012, Error 0.4603(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2473 | Time 68.3404(68.9916) | Bit/dim 3.6474(3.6605) | Xent 0.0438(0.0742) | Loss 13.3144(9.7383) | Error 0.0140(0.0238) Steps 676(674.24) | Grad Norm 2.8846(6.0057) | Total Time 0.00(0.00)\n",
      "Iter 2474 | Time 72.9338(69.1099) | Bit/dim 3.6524(3.6602) | Xent 0.0529(0.0736) | Loss 8.8491(9.7116) | Error 0.0166(0.0235) Steps 700(675.01) | Grad Norm 6.8304(6.0304) | Total Time 0.00(0.00)\n",
      "Iter 2475 | Time 71.8962(69.1935) | Bit/dim 3.6506(3.6599) | Xent 0.0458(0.0728) | Loss 8.8045(9.6844) | Error 0.0146(0.0233) Steps 676(675.04) | Grad Norm 3.9796(5.9689) | Total Time 0.00(0.00)\n",
      "Iter 2476 | Time 77.1628(69.4325) | Bit/dim 3.6551(3.6598) | Xent 0.0478(0.0720) | Loss 8.8197(9.6585) | Error 0.0166(0.0231) Steps 694(675.61) | Grad Norm 4.9873(5.9394) | Total Time 0.00(0.00)\n",
      "Iter 2477 | Time 64.4893(69.2842) | Bit/dim 3.6598(3.6598) | Xent 0.0503(0.0714) | Loss 8.8432(9.6340) | Error 0.0161(0.0229) Steps 670(675.44) | Grad Norm 5.0928(5.9140) | Total Time 0.00(0.00)\n",
      "Iter 2478 | Time 72.7953(69.3896) | Bit/dim 3.6646(3.6599) | Xent 0.0476(0.0706) | Loss 8.9482(9.6134) | Error 0.0148(0.0226) Steps 688(675.82) | Grad Norm 4.4351(5.8697) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 25.1311, Epoch Time 471.4251(447.2470), Bit/dim 3.6880(best: 3.6821), Xent 3.4742, Loss 5.4251, Error 0.4539(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2479 | Time 68.2871(69.3565) | Bit/dim 3.6582(3.6599) | Xent 0.0519(0.0701) | Loss 13.5235(9.7307) | Error 0.0160(0.0224) Steps 682(676.00) | Grad Norm 5.1391(5.8478) | Total Time 0.00(0.00)\n",
      "Iter 2480 | Time 69.1515(69.3503) | Bit/dim 3.6355(3.6591) | Xent 0.0410(0.0692) | Loss 8.7769(9.7021) | Error 0.0132(0.0221) Steps 694(676.54) | Grad Norm 2.4206(5.7449) | Total Time 0.00(0.00)\n",
      "Iter 2481 | Time 79.0308(69.6408) | Bit/dim 3.6572(3.6591) | Xent 0.0504(0.0686) | Loss 8.7886(9.6747) | Error 0.0168(0.0220) Steps 712(677.61) | Grad Norm 4.1044(5.6957) | Total Time 0.00(0.00)\n",
      "Iter 2482 | Time 72.2796(69.7199) | Bit/dim 3.6581(3.6591) | Xent 0.0431(0.0679) | Loss 8.8043(9.6486) | Error 0.0129(0.0217) Steps 688(677.92) | Grad Norm 4.2839(5.6534) | Total Time 0.00(0.00)\n",
      "Iter 2483 | Time 72.3230(69.7980) | Bit/dim 3.6655(3.6592) | Xent 0.0463(0.0672) | Loss 8.7780(9.6225) | Error 0.0146(0.0215) Steps 676(677.86) | Grad Norm 3.6160(5.5922) | Total Time 0.00(0.00)\n",
      "Iter 2484 | Time 66.1301(69.6880) | Bit/dim 3.6544(3.6591) | Xent 0.0414(0.0665) | Loss 8.7154(9.5953) | Error 0.0132(0.0213) Steps 706(678.71) | Grad Norm 2.7760(5.5078) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 24.8640, Epoch Time 470.9075(447.9568), Bit/dim 3.6903(best: 3.6821), Xent 3.5108, Loss 5.4457, Error 0.4632(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2485 | Time 69.5010(69.6824) | Bit/dim 3.6566(3.6590) | Xent 0.0487(0.0659) | Loss 13.3647(9.7084) | Error 0.0140(0.0210) Steps 694(679.17) | Grad Norm 3.5082(5.4478) | Total Time 0.00(0.00)\n",
      "Iter 2486 | Time 73.2088(69.7882) | Bit/dim 3.6582(3.6590) | Xent 0.0415(0.0652) | Loss 8.8378(9.6822) | Error 0.0126(0.0208) Steps 688(679.43) | Grad Norm 3.6343(5.3934) | Total Time 0.00(0.00)\n",
      "Iter 2487 | Time 73.8842(69.9110) | Bit/dim 3.6428(3.6585) | Xent 0.0466(0.0646) | Loss 8.8890(9.6584) | Error 0.0138(0.0206) Steps 706(680.23) | Grad Norm 2.6882(5.3122) | Total Time 0.00(0.00)\n",
      "Iter 2488 | Time 71.8720(69.9699) | Bit/dim 3.6539(3.6584) | Xent 0.0452(0.0640) | Loss 8.8445(9.6340) | Error 0.0144(0.0204) Steps 676(680.10) | Grad Norm 2.6706(5.2330) | Total Time 0.00(0.00)\n",
      "Iter 2489 | Time 65.5961(69.8387) | Bit/dim 3.6519(3.6582) | Xent 0.0454(0.0635) | Loss 8.8368(9.6101) | Error 0.0140(0.0202) Steps 682(680.16) | Grad Norm 2.6987(5.1569) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 72.3402(69.9137) | Bit/dim 3.6553(3.6581) | Xent 0.0445(0.0629) | Loss 8.9506(9.5903) | Error 0.0131(0.0200) Steps 688(680.39) | Grad Norm 3.2346(5.0993) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 25.2299, Epoch Time 470.7306(448.6400), Bit/dim 3.6873(best: 3.6821), Xent 3.5334, Loss 5.4539, Error 0.4581(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2491 | Time 74.1668(70.0413) | Bit/dim 3.6455(3.6577) | Xent 0.0474(0.0625) | Loss 13.3588(9.7034) | Error 0.0152(0.0198) Steps 718(681.52) | Grad Norm 3.5081(5.0515) | Total Time 0.00(0.00)\n",
      "Iter 2492 | Time 72.0980(70.1030) | Bit/dim 3.6535(3.6576) | Xent 0.0448(0.0619) | Loss 8.9282(9.6801) | Error 0.0141(0.0197) Steps 688(681.72) | Grad Norm 3.1926(4.9958) | Total Time 0.00(0.00)\n",
      "Iter 2493 | Time 70.7803(70.1233) | Bit/dim 3.6547(3.6575) | Xent 0.0432(0.0614) | Loss 8.6774(9.6500) | Error 0.0145(0.0195) Steps 694(682.08) | Grad Norm 3.6066(4.9541) | Total Time 0.00(0.00)\n",
      "Iter 2494 | Time 73.8324(70.2346) | Bit/dim 3.6573(3.6575) | Xent 0.0480(0.0610) | Loss 8.7929(9.6243) | Error 0.0148(0.0194) Steps 688(682.26) | Grad Norm 2.7559(4.8881) | Total Time 0.00(0.00)\n",
      "Iter 2495 | Time 76.8825(70.4340) | Bit/dim 3.6501(3.6573) | Xent 0.0503(0.0606) | Loss 8.6191(9.5942) | Error 0.0150(0.0192) Steps 712(683.15) | Grad Norm 3.5670(4.8485) | Total Time 0.00(0.00)\n",
      "Iter 2496 | Time 69.8186(70.4156) | Bit/dim 3.6614(3.6574) | Xent 0.0424(0.0601) | Loss 8.9676(9.5754) | Error 0.0135(0.0191) Steps 664(682.58) | Grad Norm 2.7086(4.7843) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 25.1204, Epoch Time 481.6661(449.6308), Bit/dim 3.6827(best: 3.6821), Xent 3.4132, Loss 5.3893, Error 0.4497(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2497 | Time 64.3738(70.2343) | Bit/dim 3.6554(3.6573) | Xent 0.0511(0.0598) | Loss 13.4472(9.6915) | Error 0.0168(0.0190) Steps 682(682.56) | Grad Norm 3.8578(4.7565) | Total Time 0.00(0.00)\n",
      "Iter 2498 | Time 73.6017(70.3353) | Bit/dim 3.6548(3.6573) | Xent 0.0460(0.0594) | Loss 8.7874(9.6644) | Error 0.0152(0.0189) Steps 700(683.08) | Grad Norm 3.3335(4.7138) | Total Time 0.00(0.00)\n",
      "Iter 2499 | Time 72.7330(70.4073) | Bit/dim 3.6685(3.6576) | Xent 0.0533(0.0592) | Loss 9.1145(9.6479) | Error 0.0166(0.0188) Steps 700(683.59) | Grad Norm 3.9223(4.6901) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 69.4897(70.3797) | Bit/dim 3.6422(3.6571) | Xent 0.0397(0.0586) | Loss 8.7647(9.6214) | Error 0.0119(0.0186) Steps 700(684.08) | Grad Norm 2.6857(4.6300) | Total Time 0.00(0.00)\n",
      "Iter 2501 | Time 71.6672(70.4184) | Bit/dim 3.6492(3.6569) | Xent 0.0522(0.0584) | Loss 8.8302(9.5977) | Error 0.0160(0.0185) Steps 652(683.12) | Grad Norm 4.3563(4.6217) | Total Time 0.00(0.00)\n",
      "Iter 2502 | Time 75.4929(70.5706) | Bit/dim 3.6596(3.6570) | Xent 0.0408(0.0579) | Loss 8.8786(9.5761) | Error 0.0122(0.0183) Steps 676(682.91) | Grad Norm 3.9850(4.6026) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 25.2865, Epoch Time 471.0319(450.2729), Bit/dim 3.6852(best: 3.6821), Xent 3.4865, Loss 5.4285, Error 0.4520(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2503 | Time 74.0893(70.6762) | Bit/dim 3.6523(3.6568) | Xent 0.0394(0.0574) | Loss 13.8104(9.7031) | Error 0.0120(0.0182) Steps 676(682.70) | Grad Norm 4.0639(4.5865) | Total Time 0.00(0.00)\n",
      "Iter 2504 | Time 72.0729(70.7181) | Bit/dim 3.6519(3.6567) | Xent 0.0395(0.0568) | Loss 8.6091(9.6703) | Error 0.0121(0.0180) Steps 682(682.68) | Grad Norm 3.4749(4.5531) | Total Time 0.00(0.00)\n",
      "Iter 2505 | Time 66.3868(70.5881) | Bit/dim 3.6497(3.6565) | Xent 0.0520(0.0567) | Loss 8.4926(9.6350) | Error 0.0185(0.0180) Steps 676(682.48) | Grad Norm 4.1608(4.5414) | Total Time 0.00(0.00)\n",
      "Iter 2506 | Time 71.5931(70.6183) | Bit/dim 3.6544(3.6564) | Xent 0.0402(0.0562) | Loss 8.7859(9.6095) | Error 0.0129(0.0178) Steps 694(682.83) | Grad Norm 3.2978(4.5041) | Total Time 0.00(0.00)\n",
      "Iter 2507 | Time 73.9858(70.7193) | Bit/dim 3.6564(3.6564) | Xent 0.0475(0.0559) | Loss 8.8469(9.5866) | Error 0.0144(0.0177) Steps 676(682.62) | Grad Norm 3.6784(4.4793) | Total Time 0.00(0.00)\n",
      "Iter 2508 | Time 73.7778(70.8111) | Bit/dim 3.6578(3.6565) | Xent 0.0465(0.0556) | Loss 8.7430(9.5613) | Error 0.0146(0.0176) Steps 700(683.14) | Grad Norm 4.1588(4.4697) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 25.0722, Epoch Time 475.8342(451.0397), Bit/dim 3.6897(best: 3.6821), Xent 3.5611, Loss 5.4702, Error 0.4565(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2509 | Time 74.6172(70.9252) | Bit/dim 3.6537(3.6564) | Xent 0.0358(0.0550) | Loss 13.2051(9.6706) | Error 0.0112(0.0174) Steps 682(683.11) | Grad Norm 2.6363(4.4147) | Total Time 0.00(0.00)\n",
      "Iter 2510 | Time 76.8991(71.1045) | Bit/dim 3.6426(3.6560) | Xent 0.0453(0.0548) | Loss 8.8990(9.6475) | Error 0.0149(0.0174) Steps 682(683.07) | Grad Norm 3.7418(4.3945) | Total Time 0.00(0.00)\n",
      "Iter 2511 | Time 76.8996(71.2783) | Bit/dim 3.6582(3.6560) | Xent 0.0466(0.0545) | Loss 8.8624(9.6239) | Error 0.0145(0.0173) Steps 706(683.76) | Grad Norm 3.6568(4.3724) | Total Time 0.00(0.00)\n",
      "Iter 2512 | Time 73.5988(71.3479) | Bit/dim 3.6438(3.6557) | Xent 0.0434(0.0542) | Loss 8.8990(9.6022) | Error 0.0138(0.0172) Steps 694(684.07) | Grad Norm 2.6858(4.3218) | Total Time 0.00(0.00)\n",
      "Iter 2513 | Time 71.0959(71.3404) | Bit/dim 3.6578(3.6557) | Xent 0.0445(0.0539) | Loss 8.7088(9.5754) | Error 0.0140(0.0171) Steps 712(684.91) | Grad Norm 4.0878(4.3147) | Total Time 0.00(0.00)\n",
      "Iter 2514 | Time 69.7116(71.2915) | Bit/dim 3.6518(3.6556) | Xent 0.0463(0.0537) | Loss 8.8080(9.5524) | Error 0.0162(0.0171) Steps 670(684.46) | Grad Norm 6.1569(4.3700) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 25.2925, Epoch Time 487.2500(452.1260), Bit/dim 3.6863(best: 3.6821), Xent 3.5625, Loss 5.4675, Error 0.4574(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2515 | Time 74.9281(71.4006) | Bit/dim 3.6517(3.6555) | Xent 0.0437(0.0534) | Loss 13.5938(9.6736) | Error 0.0145(0.0170) Steps 694(684.75) | Grad Norm 4.6092(4.3772) | Total Time 0.00(0.00)\n",
      "Iter 2516 | Time 76.7440(71.5609) | Bit/dim 3.6436(3.6551) | Xent 0.0398(0.0530) | Loss 8.7985(9.6474) | Error 0.0108(0.0168) Steps 718(685.74) | Grad Norm 3.1763(4.3412) | Total Time 0.00(0.00)\n",
      "Iter 2517 | Time 74.6241(71.6528) | Bit/dim 3.6537(3.6551) | Xent 0.0434(0.0527) | Loss 8.9717(9.6271) | Error 0.0144(0.0167) Steps 694(685.99) | Grad Norm 3.7048(4.3221) | Total Time 0.00(0.00)\n",
      "Iter 2518 | Time 74.5859(71.7408) | Bit/dim 3.6604(3.6553) | Xent 0.0405(0.0523) | Loss 8.8537(9.6039) | Error 0.0115(0.0166) Steps 682(685.87) | Grad Norm 3.8409(4.3076) | Total Time 0.00(0.00)\n",
      "Iter 2519 | Time 67.8387(71.6237) | Bit/dim 3.6497(3.6551) | Xent 0.0568(0.0524) | Loss 8.7151(9.5772) | Error 0.0181(0.0166) Steps 700(686.30) | Grad Norm 4.8396(4.3236) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 69.8088(71.5693) | Bit/dim 3.6612(3.6553) | Xent 0.0392(0.0520) | Loss 8.8979(9.5568) | Error 0.0128(0.0165) Steps 658(685.45) | Grad Norm 3.6023(4.3019) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 24.6195, Epoch Time 481.5160(453.0077), Bit/dim 3.6870(best: 3.6821), Xent 3.5236, Loss 5.4488, Error 0.4600(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2521 | Time 71.3530(71.5628) | Bit/dim 3.6520(3.6552) | Xent 0.0395(0.0517) | Loss 13.3023(9.6692) | Error 0.0139(0.0164) Steps 652(684.44) | Grad Norm 4.5506(4.3094) | Total Time 0.00(0.00)\n",
      "Iter 2522 | Time 74.1794(71.6413) | Bit/dim 3.6435(3.6548) | Xent 0.0461(0.0515) | Loss 8.7504(9.6416) | Error 0.0159(0.0164) Steps 694(684.73) | Grad Norm 6.4962(4.3750) | Total Time 0.00(0.00)\n",
      "Iter 2523 | Time 75.4675(71.7561) | Bit/dim 3.6491(3.6547) | Xent 0.0446(0.0513) | Loss 8.8603(9.6182) | Error 0.0134(0.0163) Steps 688(684.83) | Grad Norm 2.5900(4.3215) | Total Time 0.00(0.00)\n",
      "Iter 2524 | Time 69.4423(71.6867) | Bit/dim 3.6505(3.6545) | Xent 0.0543(0.0514) | Loss 8.8571(9.5954) | Error 0.0184(0.0164) Steps 694(685.10) | Grad Norm 6.4406(4.3850) | Total Time 0.00(0.00)\n",
      "Iter 2525 | Time 74.9476(71.7845) | Bit/dim 3.6574(3.6546) | Xent 0.0474(0.0513) | Loss 8.7184(9.5691) | Error 0.0156(0.0163) Steps 676(684.83) | Grad Norm 6.4169(4.4460) | Total Time 0.00(0.00)\n",
      "Iter 2526 | Time 75.1456(71.8853) | Bit/dim 3.6645(3.6549) | Xent 0.0466(0.0511) | Loss 8.6139(9.5404) | Error 0.0149(0.0163) Steps 718(685.83) | Grad Norm 4.5678(4.4496) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 25.2001, Epoch Time 484.4455(453.9508), Bit/dim 3.6869(best: 3.6821), Xent 3.5470, Loss 5.4604, Error 0.4565(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2527 | Time 69.2100(71.8051) | Bit/dim 3.6489(3.6547) | Xent 0.0486(0.0510) | Loss 13.4695(9.6583) | Error 0.0155(0.0163) Steps 688(685.89) | Grad Norm 6.1440(4.5005) | Total Time 0.00(0.00)\n",
      "Iter 2528 | Time 72.8293(71.8358) | Bit/dim 3.6519(3.6546) | Xent 0.0629(0.0514) | Loss 8.7220(9.6302) | Error 0.0202(0.0164) Steps 694(686.13) | Grad Norm 9.7406(4.6577) | Total Time 0.00(0.00)\n",
      "Iter 2529 | Time 70.4458(71.7941) | Bit/dim 3.6591(3.6548) | Xent 0.0606(0.0517) | Loss 8.7077(9.6025) | Error 0.0209(0.0165) Steps 676(685.83) | Grad Norm 9.6450(4.8073) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 73.6366(71.8494) | Bit/dim 3.6470(3.6545) | Xent 0.0444(0.0515) | Loss 8.7552(9.5771) | Error 0.0144(0.0165) Steps 688(685.89) | Grad Norm 3.7909(4.7768) | Total Time 0.00(0.00)\n",
      "Iter 2531 | Time 72.1724(71.8591) | Bit/dim 3.6617(3.6548) | Xent 0.0676(0.0519) | Loss 8.9149(9.5572) | Error 0.0218(0.0166) Steps 688(685.96) | Grad Norm 8.0216(4.8741) | Total Time 0.00(0.00)\n",
      "Iter 2532 | Time 71.2781(71.8416) | Bit/dim 3.6463(3.6545) | Xent 0.0778(0.0527) | Loss 8.8703(9.5366) | Error 0.0239(0.0168) Steps 718(686.92) | Grad Norm 11.0016(5.0580) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 25.2273, Epoch Time 473.0267(454.5231), Bit/dim 3.6884(best: 3.6821), Xent 3.4835, Loss 5.4301, Error 0.4584(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2533 | Time 73.2463(71.8838) | Bit/dim 3.6505(3.6544) | Xent 0.0635(0.0530) | Loss 13.2313(9.6475) | Error 0.0215(0.0170) Steps 712(687.67) | Grad Norm 10.7032(5.2273) | Total Time 0.00(0.00)\n",
      "Iter 2534 | Time 73.7689(71.9403) | Bit/dim 3.6575(3.6545) | Xent 0.0556(0.0531) | Loss 8.9609(9.6269) | Error 0.0172(0.0170) Steps 688(687.68) | Grad Norm 7.1439(5.2848) | Total Time 0.00(0.00)\n",
      "Iter 2535 | Time 78.1345(72.1262) | Bit/dim 3.6585(3.6546) | Xent 0.0505(0.0530) | Loss 9.0009(9.6081) | Error 0.0171(0.0170) Steps 706(688.23) | Grad Norm 6.4946(5.3211) | Total Time 0.00(0.00)\n",
      "Iter 2536 | Time 72.0620(72.1242) | Bit/dim 3.6576(3.6547) | Xent 0.0633(0.0533) | Loss 8.9923(9.5896) | Error 0.0205(0.0171) Steps 682(688.04) | Grad Norm 9.3920(5.4432) | Total Time 0.00(0.00)\n",
      "Iter 2537 | Time 72.0227(72.1212) | Bit/dim 3.6525(3.6546) | Xent 0.0503(0.0533) | Loss 8.8114(9.5663) | Error 0.0161(0.0171) Steps 688(688.04) | Grad Norm 5.6616(5.4498) | Total Time 0.00(0.00)\n",
      "Iter 2538 | Time 71.2151(72.0940) | Bit/dim 3.6483(3.6544) | Xent 0.0508(0.0532) | Loss 8.8914(9.5460) | Error 0.0155(0.0170) Steps 700(688.40) | Grad Norm 6.3563(5.4770) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 25.2864, Epoch Time 484.6395(455.4266), Bit/dim 3.6836(best: 3.6821), Xent 3.4235, Loss 5.3953, Error 0.4613(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2539 | Time 70.3772(72.0425) | Bit/dim 3.6472(3.6542) | Xent 0.0483(0.0530) | Loss 13.3306(9.6596) | Error 0.0159(0.0170) Steps 712(689.11) | Grad Norm 6.9572(5.5214) | Total Time 0.00(0.00)\n",
      "Iter 2540 | Time 72.0570(72.0429) | Bit/dim 3.6533(3.6542) | Xent 0.0517(0.0530) | Loss 8.8658(9.6357) | Error 0.0151(0.0169) Steps 712(689.80) | Grad Norm 5.6428(5.5250) | Total Time 0.00(0.00)\n",
      "Iter 2541 | Time 72.2310(72.0486) | Bit/dim 3.6598(3.6544) | Xent 0.0549(0.0531) | Loss 8.9273(9.6145) | Error 0.0158(0.0169) Steps 694(689.92) | Grad Norm 6.8784(5.5656) | Total Time 0.00(0.00)\n",
      "Iter 2542 | Time 70.3528(71.9977) | Bit/dim 3.6514(3.6543) | Xent 0.0422(0.0527) | Loss 8.6825(9.5865) | Error 0.0120(0.0168) Steps 682(689.68) | Grad Norm 3.1659(5.4936) | Total Time 0.00(0.00)\n",
      "Iter 2543 | Time 72.5112(72.0131) | Bit/dim 3.6448(3.6540) | Xent 0.0540(0.0528) | Loss 8.7359(9.5610) | Error 0.0179(0.0168) Steps 688(689.63) | Grad Norm 8.4255(5.5816) | Total Time 0.00(0.00)\n",
      "Iter 2544 | Time 70.9474(71.9811) | Bit/dim 3.6565(3.6541) | Xent 0.0525(0.0528) | Loss 8.8954(9.5410) | Error 0.0166(0.0168) Steps 700(689.95) | Grad Norm 6.1956(5.6000) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 24.5499, Epoch Time 471.9680(455.9229), Bit/dim 3.6879(best: 3.6821), Xent 3.5107, Loss 5.4433, Error 0.4532(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2545 | Time 70.8514(71.9472) | Bit/dim 3.6572(3.6542) | Xent 0.0515(0.0527) | Loss 12.8807(9.6412) | Error 0.0165(0.0168) Steps 676(689.53) | Grad Norm 5.9588(5.6108) | Total Time 0.00(0.00)\n",
      "Iter 2546 | Time 71.8503(71.9443) | Bit/dim 3.6553(3.6542) | Xent 0.0528(0.0527) | Loss 8.8682(9.6180) | Error 0.0180(0.0168) Steps 700(689.84) | Grad Norm 6.8766(5.6488) | Total Time 0.00(0.00)\n",
      "Iter 2547 | Time 71.4746(71.9302) | Bit/dim 3.6507(3.6541) | Xent 0.0419(0.0524) | Loss 8.8431(9.5948) | Error 0.0134(0.0167) Steps 682(689.61) | Grad Norm 2.8173(5.5638) | Total Time 0.00(0.00)\n",
      "Iter 2548 | Time 72.6454(71.9517) | Bit/dim 3.6565(3.6542) | Xent 0.0568(0.0525) | Loss 8.7875(9.5706) | Error 0.0172(0.0167) Steps 658(688.66) | Grad Norm 7.4287(5.6198) | Total Time 0.00(0.00)\n",
      "Iter 2549 | Time 67.8859(71.8297) | Bit/dim 3.6465(3.6539) | Xent 0.0508(0.0525) | Loss 8.8972(9.5504) | Error 0.0158(0.0167) Steps 676(688.28) | Grad Norm 4.6551(5.5908) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 72.4955(71.8497) | Bit/dim 3.6564(3.6540) | Xent 0.0501(0.0524) | Loss 8.7464(9.5263) | Error 0.0174(0.0167) Steps 676(687.91) | Grad Norm 7.0182(5.6336) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 24.9245, Epoch Time 470.5448(456.3615), Bit/dim 3.6859(best: 3.6821), Xent 3.5059, Loss 5.4388, Error 0.4614(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2551 | Time 69.8523(71.7898) | Bit/dim 3.6538(3.6540) | Xent 0.0573(0.0526) | Loss 13.5883(9.6481) | Error 0.0175(0.0167) Steps 700(688.27) | Grad Norm 4.9584(5.6134) | Total Time 0.00(0.00)\n",
      "Iter 2552 | Time 74.4633(71.8700) | Bit/dim 3.6441(3.6537) | Xent 0.0476(0.0524) | Loss 8.6565(9.6184) | Error 0.0158(0.0167) Steps 700(688.62) | Grad Norm 5.5575(5.6117) | Total Time 0.00(0.00)\n",
      "Iter 2553 | Time 71.2238(71.8506) | Bit/dim 3.6489(3.6536) | Xent 0.0493(0.0523) | Loss 8.8149(9.5943) | Error 0.0161(0.0167) Steps 694(688.79) | Grad Norm 3.8681(5.5594) | Total Time 0.00(0.00)\n",
      "Iter 2554 | Time 78.3641(72.0460) | Bit/dim 3.6574(3.6537) | Xent 0.0459(0.0521) | Loss 8.9503(9.5749) | Error 0.0141(0.0166) Steps 682(688.58) | Grad Norm 6.3688(5.5837) | Total Time 0.00(0.00)\n",
      "Iter 2555 | Time 70.1622(71.9895) | Bit/dim 3.6528(3.6536) | Xent 0.0586(0.0523) | Loss 8.8358(9.5528) | Error 0.0178(0.0166) Steps 694(688.74) | Grad Norm 5.7500(5.5887) | Total Time 0.00(0.00)\n",
      "Iter 2556 | Time 75.8103(72.1041) | Bit/dim 3.6541(3.6537) | Xent 0.0473(0.0522) | Loss 8.9350(9.5342) | Error 0.0149(0.0166) Steps 706(689.26) | Grad Norm 4.1667(5.5460) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 24.7241, Epoch Time 483.4131(457.1731), Bit/dim 3.6838(best: 3.6821), Xent 3.5197, Loss 5.4437, Error 0.4561(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2557 | Time 74.7503(72.1835) | Bit/dim 3.6492(3.6535) | Xent 0.0447(0.0519) | Loss 13.7880(9.6619) | Error 0.0134(0.0165) Steps 700(689.58) | Grad Norm 4.3822(5.5111) | Total Time 0.00(0.00)\n",
      "Iter 2558 | Time 74.6205(72.2566) | Bit/dim 3.6396(3.6531) | Xent 0.0524(0.0520) | Loss 8.9286(9.6399) | Error 0.0154(0.0165) Steps 706(690.08) | Grad Norm 4.4208(5.4784) | Total Time 0.00(0.00)\n",
      "Iter 2559 | Time 72.9100(72.2762) | Bit/dim 3.6503(3.6530) | Xent 0.0450(0.0517) | Loss 8.7992(9.6146) | Error 0.0141(0.0164) Steps 688(690.01) | Grad Norm 3.6633(5.4239) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 69.5653(72.1949) | Bit/dim 3.6461(3.6528) | Xent 0.0474(0.0516) | Loss 8.9611(9.5950) | Error 0.0154(0.0164) Steps 688(689.95) | Grad Norm 3.4956(5.3661) | Total Time 0.00(0.00)\n",
      "Iter 2561 | Time 70.3387(72.1392) | Bit/dim 3.6627(3.6531) | Xent 0.0492(0.0515) | Loss 8.8997(9.5742) | Error 0.0160(0.0164) Steps 694(690.08) | Grad Norm 3.7230(5.3168) | Total Time 0.00(0.00)\n",
      "Iter 2562 | Time 79.6813(72.3655) | Bit/dim 3.6612(3.6534) | Xent 0.0455(0.0514) | Loss 8.7490(9.5494) | Error 0.0150(0.0163) Steps 724(691.09) | Grad Norm 4.1423(5.2816) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 25.2293, Epoch Time 485.0311(458.0088), Bit/dim 3.6854(best: 3.6821), Xent 3.4658, Loss 5.4183, Error 0.4514(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2563 | Time 71.9375(72.3526) | Bit/dim 3.6502(3.6533) | Xent 0.0466(0.0512) | Loss 13.0466(9.6543) | Error 0.0141(0.0162) Steps 694(691.18) | Grad Norm 3.5918(5.2309) | Total Time 0.00(0.00)\n",
      "Iter 2564 | Time 72.6131(72.3604) | Bit/dim 3.6608(3.6535) | Xent 0.0398(0.0509) | Loss 8.7325(9.6267) | Error 0.0129(0.0161) Steps 694(691.26) | Grad Norm 3.9288(5.1918) | Total Time 0.00(0.00)\n",
      "Iter 2565 | Time 71.7486(72.3421) | Bit/dim 3.6484(3.6533) | Xent 0.0553(0.0510) | Loss 8.7867(9.6015) | Error 0.0176(0.0162) Steps 700(691.53) | Grad Norm 3.9504(5.1546) | Total Time 0.00(0.00)\n",
      "Iter 2566 | Time 71.3044(72.3109) | Bit/dim 3.6552(3.6534) | Xent 0.0487(0.0509) | Loss 8.8445(9.5788) | Error 0.0158(0.0162) Steps 694(691.60) | Grad Norm 3.8029(5.1140) | Total Time 0.00(0.00)\n",
      "Iter 2567 | Time 78.0079(72.4819) | Bit/dim 3.6524(3.6534) | Xent 0.0478(0.0508) | Loss 8.8670(9.5574) | Error 0.0160(0.0162) Steps 706(692.03) | Grad Norm 4.8135(5.1050) | Total Time 0.00(0.00)\n",
      "Iter 2568 | Time 74.5891(72.5451) | Bit/dim 3.6512(3.6533) | Xent 0.0559(0.0510) | Loss 8.9700(9.5398) | Error 0.0168(0.0162) Steps 676(691.55) | Grad Norm 5.4452(5.1152) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 25.1326, Epoch Time 484.0066(458.7887), Bit/dim 3.6866(best: 3.6821), Xent 3.4931, Loss 5.4331, Error 0.4602(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2569 | Time 76.7242(72.6704) | Bit/dim 3.6479(3.6531) | Xent 0.0486(0.0509) | Loss 13.2708(9.6517) | Error 0.0146(0.0161) Steps 688(691.45) | Grad Norm 4.0224(5.0824) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 74.7199(72.7319) | Bit/dim 3.6480(3.6530) | Xent 0.0447(0.0507) | Loss 8.9438(9.6305) | Error 0.0135(0.0161) Steps 694(691.52) | Grad Norm 3.8067(5.0441) | Total Time 0.00(0.00)\n",
      "Iter 2571 | Time 70.4445(72.6633) | Bit/dim 3.6565(3.6531) | Xent 0.0447(0.0506) | Loss 8.8808(9.6080) | Error 0.0130(0.0160) Steps 688(691.42) | Grad Norm 5.2782(5.0512) | Total Time 0.00(0.00)\n",
      "Iter 2572 | Time 72.7967(72.6673) | Bit/dim 3.6428(3.6528) | Xent 0.0420(0.0503) | Loss 8.7454(9.5821) | Error 0.0136(0.0159) Steps 688(691.31) | Grad Norm 3.3361(4.9997) | Total Time 0.00(0.00)\n",
      "Iter 2573 | Time 71.1849(72.6228) | Bit/dim 3.6492(3.6527) | Xent 0.0425(0.0501) | Loss 8.7393(9.5568) | Error 0.0141(0.0158) Steps 706(691.75) | Grad Norm 4.7899(4.9934) | Total Time 0.00(0.00)\n",
      "Iter 2574 | Time 75.2590(72.7019) | Bit/dim 3.6568(3.6528) | Xent 0.0591(0.0503) | Loss 9.0025(9.5402) | Error 0.0180(0.0159) Steps 694(691.82) | Grad Norm 7.7126(5.0750) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 25.2871, Epoch Time 484.6992(459.5660), Bit/dim 3.6859(best: 3.6821), Xent 3.5468, Loss 5.4593, Error 0.4565(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2575 | Time 68.8645(72.5868) | Bit/dim 3.6491(3.6527) | Xent 0.0626(0.0507) | Loss 13.4004(9.6560) | Error 0.0170(0.0159) Steps 664(690.99) | Grad Norm 8.0983(5.1657) | Total Time 0.00(0.00)\n",
      "Iter 2576 | Time 77.6935(72.7400) | Bit/dim 3.6595(3.6529) | Xent 0.0492(0.0507) | Loss 8.7094(9.6276) | Error 0.0149(0.0159) Steps 682(690.72) | Grad Norm 4.2445(5.1381) | Total Time 0.00(0.00)\n",
      "Iter 2577 | Time 73.3843(72.7593) | Bit/dim 3.6535(3.6529) | Xent 0.0510(0.0507) | Loss 8.8838(9.6053) | Error 0.0160(0.0159) Steps 682(690.46) | Grad Norm 5.7708(5.1570) | Total Time 0.00(0.00)\n",
      "Iter 2578 | Time 74.5397(72.8127) | Bit/dim 3.6576(3.6530) | Xent 0.0708(0.0513) | Loss 8.9858(9.5867) | Error 0.0225(0.0161) Steps 688(690.38) | Grad Norm 7.3698(5.2234) | Total Time 0.00(0.00)\n",
      "Iter 2579 | Time 70.6478(72.7478) | Bit/dim 3.6387(3.6526) | Xent 0.0707(0.0519) | Loss 8.7664(9.5621) | Error 0.0238(0.0163) Steps 700(690.67) | Grad Norm 8.8612(5.3326) | Total Time 0.00(0.00)\n",
      "Iter 2580 | Time 71.2057(72.7015) | Bit/dim 3.6568(3.6527) | Xent 0.0587(0.0521) | Loss 8.7077(9.5365) | Error 0.0195(0.0164) Steps 688(690.59) | Grad Norm 7.5818(5.4000) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 25.3118, Epoch Time 480.2865(460.1877), Bit/dim 3.6803(best: 3.6821), Xent 3.3023, Loss 5.3315, Error 0.4496(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2581 | Time 73.5215(72.7261) | Bit/dim 3.6603(3.6530) | Xent 0.0511(0.0520) | Loss 13.7616(9.6632) | Error 0.0174(0.0165) Steps 688(690.51) | Grad Norm 5.4868(5.4026) | Total Time 0.00(0.00)\n",
      "Iter 2582 | Time 72.9873(72.7340) | Bit/dim 3.6488(3.6528) | Xent 0.0749(0.0527) | Loss 8.8506(9.6388) | Error 0.0255(0.0167) Steps 682(690.26) | Grad Norm 9.2559(5.5182) | Total Time 0.00(0.00)\n",
      "Iter 2583 | Time 71.8276(72.7068) | Bit/dim 3.6400(3.6525) | Xent 0.0891(0.0538) | Loss 8.9660(9.6187) | Error 0.0285(0.0171) Steps 706(690.73) | Grad Norm 11.4180(5.6952) | Total Time 0.00(0.00)\n",
      "Iter 2584 | Time 68.7471(72.5880) | Bit/dim 3.6522(3.6524) | Xent 0.0716(0.0543) | Loss 8.7643(9.5930) | Error 0.0225(0.0173) Steps 700(691.01) | Grad Norm 9.8390(5.8195) | Total Time 0.00(0.00)\n",
      "Iter 2585 | Time 77.2752(72.7286) | Bit/dim 3.6462(3.6523) | Xent 0.0520(0.0543) | Loss 8.8714(9.5714) | Error 0.0169(0.0172) Steps 664(690.20) | Grad Norm 4.3136(5.7744) | Total Time 0.00(0.00)\n",
      "Iter 2586 | Time 74.1287(72.7706) | Bit/dim 3.6522(3.6523) | Xent 0.0725(0.0548) | Loss 8.8616(9.5501) | Error 0.0231(0.0174) Steps 676(689.77) | Grad Norm 9.1569(5.8758) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 25.2228, Epoch Time 482.5422(460.8583), Bit/dim 3.6856(best: 3.6803), Xent 3.3563, Loss 5.3637, Error 0.4583(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2587 | Time 72.6410(72.7667) | Bit/dim 3.6516(3.6522) | Xent 0.0577(0.0549) | Loss 13.7349(9.6756) | Error 0.0188(0.0175) Steps 694(689.90) | Grad Norm 8.8735(5.9658) | Total Time 0.00(0.00)\n",
      "Iter 2588 | Time 73.2567(72.7814) | Bit/dim 3.6539(3.6523) | Xent 0.0633(0.0552) | Loss 8.9684(9.6544) | Error 0.0205(0.0175) Steps 712(690.56) | Grad Norm 4.8840(5.9333) | Total Time 0.00(0.00)\n",
      "Iter 2589 | Time 71.1153(72.7314) | Bit/dim 3.6479(3.6522) | Xent 0.0569(0.0552) | Loss 8.8310(9.6297) | Error 0.0171(0.0175) Steps 664(689.76) | Grad Norm 7.4169(5.9778) | Total Time 0.00(0.00)\n",
      "Iter 2590 | Time 73.2012(72.7455) | Bit/dim 3.6590(3.6524) | Xent 0.0544(0.0552) | Loss 8.9694(9.6099) | Error 0.0165(0.0175) Steps 694(689.89) | Grad Norm 4.7686(5.9415) | Total Time 0.00(0.00)\n",
      "Iter 2591 | Time 74.3322(72.7931) | Bit/dim 3.6458(3.6522) | Xent 0.0481(0.0550) | Loss 8.8469(9.5870) | Error 0.0144(0.0174) Steps 706(690.38) | Grad Norm 6.6192(5.9619) | Total Time 0.00(0.00)\n",
      "Iter 2592 | Time 71.3914(72.7511) | Bit/dim 3.6498(3.6521) | Xent 0.0449(0.0547) | Loss 8.9245(9.5671) | Error 0.0146(0.0173) Steps 682(690.12) | Grad Norm 6.2858(5.9716) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 25.6071, Epoch Time 481.0853(461.4651), Bit/dim 3.6890(best: 3.6803), Xent 3.5175, Loss 5.4478, Error 0.4557(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2593 | Time 74.8087(72.8128) | Bit/dim 3.6540(3.6522) | Xent 0.0592(0.0548) | Loss 13.8246(9.6949) | Error 0.0204(0.0174) Steps 682(689.88) | Grad Norm 9.2900(6.0711) | Total Time 0.00(0.00)\n",
      "Iter 2594 | Time 75.2346(72.8855) | Bit/dim 3.6537(3.6522) | Xent 0.0532(0.0548) | Loss 8.7682(9.6671) | Error 0.0164(0.0174) Steps 700(690.18) | Grad Norm 3.9748(6.0083) | Total Time 0.00(0.00)\n",
      "Iter 2595 | Time 74.0625(72.9208) | Bit/dim 3.6548(3.6523) | Xent 0.0537(0.0547) | Loss 8.8475(9.6425) | Error 0.0172(0.0174) Steps 700(690.48) | Grad Norm 4.8200(5.9726) | Total Time 0.00(0.00)\n",
      "Iter 2596 | Time 72.5517(72.9097) | Bit/dim 3.6590(3.6525) | Xent 0.0547(0.0547) | Loss 8.9275(9.6210) | Error 0.0176(0.0174) Steps 664(689.68) | Grad Norm 4.6564(5.9331) | Total Time 0.00(0.00)\n",
      "Iter 2597 | Time 71.3375(72.8625) | Bit/dim 3.6475(3.6523) | Xent 0.0494(0.0546) | Loss 8.7409(9.5946) | Error 0.0156(0.0173) Steps 694(689.81) | Grad Norm 4.3114(5.8845) | Total Time 0.00(0.00)\n",
      "Iter 2598 | Time 79.6795(73.0670) | Bit/dim 3.6454(3.6521) | Xent 0.0531(0.0545) | Loss 8.8227(9.5715) | Error 0.0164(0.0173) Steps 676(689.40) | Grad Norm 5.5684(5.8750) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 24.9977, Epoch Time 491.3854(462.3627), Bit/dim 3.6784(best: 3.6803), Xent 3.4747, Loss 5.4157, Error 0.4538(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2599 | Time 73.4951(73.0799) | Bit/dim 3.6485(3.6520) | Xent 0.0457(0.0543) | Loss 13.3791(9.6857) | Error 0.0142(0.0172) Steps 682(689.18) | Grad Norm 3.0454(5.7901) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 69.4630(72.9714) | Bit/dim 3.6477(3.6519) | Xent 0.0497(0.0541) | Loss 8.9328(9.6631) | Error 0.0159(0.0172) Steps 688(689.14) | Grad Norm 3.6112(5.7247) | Total Time 0.00(0.00)\n",
      "Iter 2601 | Time 74.9856(73.0318) | Bit/dim 3.6350(3.6514) | Xent 0.0484(0.0539) | Loss 8.7189(9.6348) | Error 0.0141(0.0171) Steps 670(688.57) | Grad Norm 4.4078(5.6852) | Total Time 0.00(0.00)\n",
      "Iter 2602 | Time 72.2774(73.0092) | Bit/dim 3.6412(3.6511) | Xent 0.0595(0.0541) | Loss 8.9007(9.6128) | Error 0.0175(0.0171) Steps 706(689.09) | Grad Norm 5.0041(5.6648) | Total Time 0.00(0.00)\n",
      "Iter 2603 | Time 76.0795(73.1013) | Bit/dim 3.6534(3.6511) | Xent 0.0460(0.0539) | Loss 8.9461(9.5928) | Error 0.0146(0.0170) Steps 706(689.60) | Grad Norm 3.1952(5.5907) | Total Time 0.00(0.00)\n",
      "Iter 2604 | Time 74.6481(73.1477) | Bit/dim 3.6594(3.6514) | Xent 0.0454(0.0536) | Loss 8.8948(9.5718) | Error 0.0138(0.0169) Steps 694(689.73) | Grad Norm 4.9776(5.5723) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 24.7347, Epoch Time 484.2939(463.0207), Bit/dim 3.6842(best: 3.6784), Xent 3.4040, Loss 5.3861, Error 0.4520(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2605 | Time 72.3557(73.1239) | Bit/dim 3.6481(3.6513) | Xent 0.0452(0.0534) | Loss 13.0235(9.6754) | Error 0.0136(0.0168) Steps 700(690.04) | Grad Norm 5.0042(5.5553) | Total Time 0.00(0.00)\n",
      "Iter 2606 | Time 79.8091(73.3245) | Bit/dim 3.6552(3.6514) | Xent 0.0486(0.0532) | Loss 8.9280(9.6529) | Error 0.0161(0.0168) Steps 670(689.44) | Grad Norm 3.9154(5.5061) | Total Time 0.00(0.00)\n",
      "Iter 2607 | Time 74.9284(73.3726) | Bit/dim 3.6564(3.6516) | Xent 0.0608(0.0535) | Loss 8.8667(9.6294) | Error 0.0198(0.0169) Steps 706(689.93) | Grad Norm 6.5790(5.5383) | Total Time 0.00(0.00)\n",
      "Iter 2608 | Time 75.3169(73.4309) | Bit/dim 3.6392(3.6512) | Xent 0.0507(0.0534) | Loss 8.9331(9.6085) | Error 0.0156(0.0169) Steps 700(690.24) | Grad Norm 4.6046(5.5102) | Total Time 0.00(0.00)\n",
      "Iter 2609 | Time 69.1435(73.3023) | Bit/dim 3.6487(3.6511) | Xent 0.0467(0.0532) | Loss 8.7139(9.5816) | Error 0.0161(0.0168) Steps 664(689.45) | Grad Norm 5.5397(5.5111) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 75.1347(73.3573) | Bit/dim 3.6460(3.6510) | Xent 0.0512(0.0531) | Loss 8.8835(9.5607) | Error 0.0158(0.0168) Steps 688(689.41) | Grad Norm 4.3462(5.4762) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 24.9783, Epoch Time 490.3485(463.8405), Bit/dim 3.6800(best: 3.6784), Xent 3.4291, Loss 5.3946, Error 0.4545(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2611 | Time 72.4809(73.3310) | Bit/dim 3.6523(3.6510) | Xent 0.0487(0.0530) | Loss 13.5432(9.6802) | Error 0.0148(0.0167) Steps 694(689.54) | Grad Norm 7.6462(5.5413) | Total Time 0.00(0.00)\n",
      "Iter 2612 | Time 69.6658(73.2210) | Bit/dim 3.6565(3.6512) | Xent 0.0396(0.0526) | Loss 8.8432(9.6551) | Error 0.0124(0.0166) Steps 688(689.50) | Grad Norm 3.1697(5.4701) | Total Time 0.00(0.00)\n",
      "Iter 2613 | Time 71.4082(73.1666) | Bit/dim 3.6407(3.6508) | Xent 0.0589(0.0528) | Loss 8.9152(9.6329) | Error 0.0184(0.0167) Steps 682(689.27) | Grad Norm 8.7431(5.5683) | Total Time 0.00(0.00)\n",
      "Iter 2614 | Time 74.7589(73.2144) | Bit/dim 3.6450(3.6507) | Xent 0.0512(0.0527) | Loss 8.9924(9.6137) | Error 0.0158(0.0166) Steps 706(689.77) | Grad Norm 6.9346(5.6093) | Total Time 0.00(0.00)\n",
      "Iter 2615 | Time 74.7517(73.2605) | Bit/dim 3.6424(3.6504) | Xent 0.0425(0.0524) | Loss 8.7567(9.5879) | Error 0.0129(0.0165) Steps 694(689.90) | Grad Norm 4.7521(5.5836) | Total Time 0.00(0.00)\n",
      "Iter 2616 | Time 74.9386(73.3109) | Bit/dim 3.6554(3.6506) | Xent 0.0653(0.0528) | Loss 8.7956(9.5642) | Error 0.0196(0.0166) Steps 700(690.20) | Grad Norm 7.8080(5.6503) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 25.4123, Epoch Time 481.6804(464.3757), Bit/dim 3.6816(best: 3.6784), Xent 3.5395, Loss 5.4514, Error 0.4633(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2617 | Time 78.0026(73.4516) | Bit/dim 3.6602(3.6509) | Xent 0.0577(0.0529) | Loss 13.7635(9.6902) | Error 0.0186(0.0167) Steps 706(690.68) | Grad Norm 7.4168(5.7033) | Total Time 0.00(0.00)\n",
      "Iter 2618 | Time 77.7035(73.5792) | Bit/dim 3.6410(3.6506) | Xent 0.0632(0.0532) | Loss 8.8961(9.6663) | Error 0.0189(0.0167) Steps 706(691.14) | Grad Norm 9.1257(5.8060) | Total Time 0.00(0.00)\n",
      "Iter 2619 | Time 72.8688(73.5579) | Bit/dim 3.6364(3.6501) | Xent 0.0379(0.0528) | Loss 8.8329(9.6413) | Error 0.0121(0.0166) Steps 724(692.12) | Grad Norm 4.7368(5.7739) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 76.3620(73.6420) | Bit/dim 3.6336(3.6496) | Xent 0.0679(0.0532) | Loss 8.7524(9.6147) | Error 0.0219(0.0168) Steps 706(692.54) | Grad Norm 8.0377(5.8418) | Total Time 0.00(0.00)\n",
      "Iter 2621 | Time 68.8596(73.4985) | Bit/dim 3.6521(3.6497) | Xent 0.0664(0.0536) | Loss 9.0392(9.5974) | Error 0.0219(0.0169) Steps 700(692.76) | Grad Norm 10.0242(5.9673) | Total Time 0.00(0.00)\n",
      "Iter 2622 | Time 71.9113(73.4509) | Bit/dim 3.6635(3.6501) | Xent 0.0622(0.0539) | Loss 8.9926(9.5793) | Error 0.0191(0.0170) Steps 682(692.44) | Grad Norm 10.2606(6.0961) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 25.0793, Epoch Time 489.2042(465.1205), Bit/dim 3.6811(best: 3.6784), Xent 3.4013, Loss 5.3818, Error 0.4653(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2623 | Time 74.6238(73.4861) | Bit/dim 3.6446(3.6500) | Xent 0.0747(0.0545) | Loss 13.5255(9.6976) | Error 0.0228(0.0172) Steps 700(692.67) | Grad Norm 8.6539(6.1728) | Total Time 0.00(0.00)\n",
      "Iter 2624 | Time 74.1554(73.5062) | Bit/dim 3.6372(3.6496) | Xent 0.0420(0.0541) | Loss 8.7917(9.6705) | Error 0.0132(0.0170) Steps 712(693.25) | Grad Norm 6.4220(6.1803) | Total Time 0.00(0.00)\n",
      "Iter 2625 | Time 77.1137(73.6144) | Bit/dim 3.6527(3.6497) | Xent 0.0819(0.0550) | Loss 8.9387(9.6485) | Error 0.0264(0.0173) Steps 700(693.45) | Grad Norm 13.6361(6.4040) | Total Time 0.00(0.00)\n",
      "Iter 2626 | Time 76.0420(73.6872) | Bit/dim 3.6520(3.6497) | Xent 0.1805(0.0587) | Loss 8.9263(9.6268) | Error 0.0563(0.0185) Steps 682(693.11) | Grad Norm 33.6698(7.2220) | Total Time 0.00(0.00)\n",
      "Iter 2627 | Time 70.6486(73.5961) | Bit/dim 3.6552(3.6499) | Xent 0.0712(0.0591) | Loss 8.8378(9.6032) | Error 0.0229(0.0186) Steps 682(692.77) | Grad Norm 12.8207(7.3899) | Total Time 0.00(0.00)\n",
      "Iter 2628 | Time 69.8095(73.4825) | Bit/dim 3.6513(3.6499) | Xent 0.0919(0.0601) | Loss 8.9723(9.5842) | Error 0.0282(0.0189) Steps 688(692.63) | Grad Norm 12.9103(7.5555) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 25.3769, Epoch Time 486.3791(465.7583), Bit/dim 3.6807(best: 3.6784), Xent 3.3139, Loss 5.3376, Error 0.4694(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2629 | Time 72.4649(73.4519) | Bit/dim 3.6546(3.6501) | Xent 0.1537(0.0629) | Loss 13.5580(9.7035) | Error 0.0494(0.0198) Steps 694(692.67) | Grad Norm 27.1980(8.1448) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 75.7163(73.5199) | Bit/dim 3.6577(3.6503) | Xent 0.1957(0.0669) | Loss 8.8742(9.6786) | Error 0.0601(0.0210) Steps 700(692.89) | Grad Norm 27.4122(8.7228) | Total Time 0.00(0.00)\n",
      "Iter 2631 | Time 76.3517(73.6048) | Bit/dim 3.6574(3.6505) | Xent 0.1528(0.0695) | Loss 9.0575(9.6599) | Error 0.0486(0.0219) Steps 706(693.28) | Grad Norm 17.3041(8.9803) | Total Time 0.00(0.00)\n",
      "Iter 2632 | Time 70.9249(73.5244) | Bit/dim 3.6617(3.6509) | Xent 0.3355(0.0774) | Loss 9.3005(9.6492) | Error 0.0968(0.0241) Steps 718(694.03) | Grad Norm 33.8277(9.7257) | Total Time 0.00(0.00)\n",
      "Iter 2633 | Time 69.2603(73.3965) | Bit/dim 3.6549(3.6510) | Xent 0.1092(0.0784) | Loss 8.8984(9.6266) | Error 0.0349(0.0244) Steps 700(694.20) | Grad Norm 9.3675(9.7149) | Total Time 0.00(0.00)\n",
      "Iter 2634 | Time 77.4444(73.5179) | Bit/dim 3.6687(3.6515) | Xent 0.2813(0.0845) | Loss 9.2088(9.6141) | Error 0.0851(0.0262) Steps 724(695.10) | Grad Norm 25.7132(10.1949) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 25.2475, Epoch Time 485.9719(466.3647), Bit/dim 3.6852(best: 3.6784), Xent 2.9581, Loss 5.1643, Error 0.4603(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2635 | Time 70.6615(73.4323) | Bit/dim 3.6645(3.6519) | Xent 0.1784(0.0873) | Loss 14.1022(9.7487) | Error 0.0603(0.0273) Steps 682(694.71) | Grad Norm 18.5128(10.4444) | Total Time 0.00(0.00)\n",
      "Iter 2636 | Time 76.8840(73.5358) | Bit/dim 3.6676(3.6524) | Xent 0.1937(0.0905) | Loss 9.0270(9.7271) | Error 0.0657(0.0284) Steps 712(695.22) | Grad Norm 29.2922(11.0099) | Total Time 0.00(0.00)\n",
      "Iter 2637 | Time 75.1709(73.5849) | Bit/dim 3.6680(3.6528) | Xent 0.1105(0.0911) | Loss 8.9516(9.7038) | Error 0.0384(0.0287) Steps 676(694.65) | Grad Norm 10.3415(10.9898) | Total Time 0.00(0.00)\n",
      "Iter 2638 | Time 75.5915(73.6451) | Bit/dim 3.6622(3.6531) | Xent 0.1698(0.0935) | Loss 8.9908(9.6824) | Error 0.0551(0.0295) Steps 706(694.99) | Grad Norm 19.0802(11.2325) | Total Time 0.00(0.00)\n",
      "Iter 2639 | Time 78.7958(73.7996) | Bit/dim 3.6533(3.6531) | Xent 0.0958(0.0935) | Loss 8.9023(9.6590) | Error 0.0324(0.0296) Steps 670(694.24) | Grad Norm 7.7561(11.1282) | Total Time 0.00(0.00)\n",
      "Iter 2640 | Time 75.3533(73.8462) | Bit/dim 3.6638(3.6535) | Xent 0.1138(0.0941) | Loss 8.8815(9.6357) | Error 0.0394(0.0299) Steps 682(693.87) | Grad Norm 11.6401(11.1436) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 25.3490, Epoch Time 496.3334(467.2638), Bit/dim 3.6830(best: 3.6784), Xent 2.8954, Loss 5.1307, Error 0.4534(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2641 | Time 75.9596(73.9096) | Bit/dim 3.6543(3.6535) | Xent 0.0720(0.0935) | Loss 13.4454(9.7500) | Error 0.0221(0.0297) Steps 706(694.24) | Grad Norm 4.0445(10.9306) | Total Time 0.00(0.00)\n",
      "Iter 2642 | Time 73.6738(73.9025) | Bit/dim 3.6629(3.6538) | Xent 0.0959(0.0935) | Loss 8.9598(9.7263) | Error 0.0300(0.0297) Steps 706(694.59) | Grad Norm 9.5238(10.8884) | Total Time 0.00(0.00)\n",
      "Iter 2643 | Time 69.8869(73.7821) | Bit/dim 3.6593(3.6539) | Xent 0.0935(0.0935) | Loss 8.9755(9.7038) | Error 0.0310(0.0297) Steps 694(694.57) | Grad Norm 5.9631(10.7407) | Total Time 0.00(0.00)\n",
      "Iter 2644 | Time 74.4736(73.8028) | Bit/dim 3.6521(3.6539) | Xent 0.0928(0.0935) | Loss 8.7974(9.6766) | Error 0.0302(0.0297) Steps 682(694.19) | Grad Norm 9.0570(10.6901) | Total Time 0.00(0.00)\n",
      "Iter 2645 | Time 71.1069(73.7219) | Bit/dim 3.6629(3.6541) | Xent 0.0807(0.0931) | Loss 8.8582(9.6520) | Error 0.0265(0.0296) Steps 706(694.55) | Grad Norm 7.3969(10.5913) | Total Time 0.00(0.00)\n",
      "Iter 2646 | Time 77.2640(73.8282) | Bit/dim 3.6632(3.6544) | Xent 0.0683(0.0924) | Loss 8.9421(9.6307) | Error 0.0241(0.0295) Steps 694(694.53) | Grad Norm 6.1957(10.4595) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 25.2927, Epoch Time 485.8878(467.8225), Bit/dim 3.6883(best: 3.6784), Xent 3.3233, Loss 5.3500, Error 0.4611(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2647 | Time 76.5503(73.9098) | Bit/dim 3.6661(3.6548) | Xent 0.0754(0.0919) | Loss 13.8564(9.7575) | Error 0.0249(0.0293) Steps 682(694.16) | Grad Norm 7.7258(10.3775) | Total Time 0.00(0.00)\n",
      "Iter 2648 | Time 72.8805(73.8790) | Bit/dim 3.6564(3.6548) | Xent 0.0625(0.0910) | Loss 8.8745(9.7310) | Error 0.0202(0.0291) Steps 640(692.53) | Grad Norm 5.6109(10.2345) | Total Time 0.00(0.00)\n",
      "Iter 2649 | Time 73.7179(73.8741) | Bit/dim 3.6518(3.6547) | Xent 0.0560(0.0899) | Loss 8.7552(9.7017) | Error 0.0190(0.0288) Steps 664(691.67) | Grad Norm 5.2804(10.0859) | Total Time 0.00(0.00)\n",
      "Iter 2650 | Time 73.8212(73.8725) | Bit/dim 3.6578(3.6548) | Xent 0.0654(0.0892) | Loss 8.7864(9.6743) | Error 0.0221(0.0286) Steps 700(691.92) | Grad Norm 4.6823(9.9237) | Total Time 0.00(0.00)\n",
      "Iter 2651 | Time 73.8199(73.8710) | Bit/dim 3.6511(3.6547) | Xent 0.0625(0.0884) | Loss 8.9805(9.6535) | Error 0.0198(0.0283) Steps 694(691.99) | Grad Norm 5.6975(9.7970) | Total Time 0.00(0.00)\n",
      "Iter 2652 | Time 75.8261(73.9296) | Bit/dim 3.6537(3.6547) | Xent 0.0667(0.0878) | Loss 8.7670(9.6269) | Error 0.0220(0.0281) Steps 700(692.23) | Grad Norm 6.1671(9.6881) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 25.4396, Epoch Time 490.8754(468.5141), Bit/dim 3.6767(best: 3.6784), Xent 3.2550, Loss 5.3042, Error 0.4570(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2653 | Time 75.8372(73.9868) | Bit/dim 3.6563(3.6547) | Xent 0.0580(0.0869) | Loss 13.1276(9.7319) | Error 0.0176(0.0278) Steps 688(692.10) | Grad Norm 4.4878(9.5321) | Total Time 0.00(0.00)\n",
      "Iter 2654 | Time 75.1077(74.0205) | Bit/dim 3.6515(3.6546) | Xent 0.0627(0.0861) | Loss 8.8306(9.7048) | Error 0.0196(0.0275) Steps 694(692.16) | Grad Norm 4.4623(9.3800) | Total Time 0.00(0.00)\n",
      "Iter 2655 | Time 77.3913(74.1216) | Bit/dim 3.6421(3.6542) | Xent 0.0461(0.0849) | Loss 8.8568(9.6794) | Error 0.0150(0.0272) Steps 652(690.95) | Grad Norm 2.9405(9.1868) | Total Time 0.00(0.00)\n",
      "Iter 2656 | Time 73.3278(74.0978) | Bit/dim 3.6495(3.6541) | Xent 0.0741(0.0846) | Loss 8.7881(9.6527) | Error 0.0265(0.0271) Steps 688(690.86) | Grad Norm 5.4796(9.0756) | Total Time 0.00(0.00)\n",
      "Iter 2657 | Time 69.4702(73.9590) | Bit/dim 3.6504(3.6540) | Xent 0.0409(0.0833) | Loss 8.9884(9.6327) | Error 0.0119(0.0267) Steps 682(690.60) | Grad Norm 2.6073(8.8815) | Total Time 0.00(0.00)\n",
      "Iter 2658 | Time 69.9498(73.8387) | Bit/dim 3.6587(3.6541) | Xent 0.0754(0.0831) | Loss 8.9748(9.6130) | Error 0.0260(0.0267) Steps 688(690.52) | Grad Norm 5.2954(8.7739) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 25.0692, Epoch Time 485.7642(469.0316), Bit/dim 3.6746(best: 3.6767), Xent 3.1739, Loss 5.2616, Error 0.4525(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2659 | Time 77.2526(73.9411) | Bit/dim 3.6337(3.6535) | Xent 0.0469(0.0820) | Loss 12.8754(9.7109) | Error 0.0138(0.0263) Steps 700(690.80) | Grad Norm 3.4657(8.6147) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 80.2013(74.1289) | Bit/dim 3.6446(3.6533) | Xent 0.0564(0.0812) | Loss 8.9002(9.6866) | Error 0.0179(0.0260) Steps 676(690.36) | Grad Norm 5.2676(8.5143) | Total Time 0.00(0.00)\n",
      "Iter 2661 | Time 71.1591(74.0398) | Bit/dim 3.6674(3.6537) | Xent 0.0511(0.0803) | Loss 8.8969(9.6629) | Error 0.0162(0.0257) Steps 688(690.29) | Grad Norm 3.9777(8.3782) | Total Time 0.00(0.00)\n",
      "Iter 2662 | Time 77.4108(74.1409) | Bit/dim 3.6429(3.6534) | Xent 0.0562(0.0796) | Loss 8.7230(9.6347) | Error 0.0185(0.0255) Steps 712(690.94) | Grad Norm 6.6919(8.3276) | Total Time 0.00(0.00)\n",
      "Iter 2663 | Time 78.0532(74.2583) | Bit/dim 3.6508(3.6533) | Xent 0.0367(0.0783) | Loss 8.8668(9.6116) | Error 0.0102(0.0251) Steps 688(690.85) | Grad Norm 4.5188(8.2133) | Total Time 0.00(0.00)\n",
      "Iter 2664 | Time 77.5742(74.3578) | Bit/dim 3.6596(3.6535) | Xent 0.0516(0.0775) | Loss 8.9619(9.5921) | Error 0.0171(0.0248) Steps 724(691.85) | Grad Norm 6.1052(8.1501) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 24.6750, Epoch Time 504.7051(470.1018), Bit/dim 3.6758(best: 3.6746), Xent 3.3408, Loss 5.3462, Error 0.4518(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2665 | Time 78.0050(74.4672) | Bit/dim 3.6548(3.6535) | Xent 0.0448(0.0765) | Loss 13.5158(9.7098) | Error 0.0118(0.0244) Steps 712(692.45) | Grad Norm 6.0586(8.0873) | Total Time 0.00(0.00)\n",
      "Iter 2666 | Time 71.9698(74.3923) | Bit/dim 3.6533(3.6535) | Xent 0.0446(0.0756) | Loss 9.0724(9.6907) | Error 0.0141(0.0241) Steps 688(692.32) | Grad Norm 4.2553(7.9724) | Total Time 0.00(0.00)\n",
      "Iter 2667 | Time 75.7462(74.4329) | Bit/dim 3.6473(3.6533) | Xent 0.0439(0.0746) | Loss 8.5640(9.6569) | Error 0.0145(0.0238) Steps 700(692.55) | Grad Norm 6.0910(7.9159) | Total Time 0.00(0.00)\n",
      "Iter 2668 | Time 77.6250(74.5287) | Bit/dim 3.6411(3.6529) | Xent 0.0420(0.0736) | Loss 8.6415(9.6265) | Error 0.0129(0.0235) Steps 712(693.13) | Grad Norm 2.9927(7.7682) | Total Time 0.00(0.00)\n",
      "Iter 2669 | Time 76.3537(74.5834) | Bit/dim 3.6473(3.6528) | Xent 0.0531(0.0730) | Loss 8.9354(9.6057) | Error 0.0165(0.0233) Steps 706(693.52) | Grad Norm 6.3632(7.7261) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 80.5496(74.7624) | Bit/dim 3.6452(3.6525) | Xent 0.0709(0.0729) | Loss 8.8222(9.5822) | Error 0.0242(0.0233) Steps 706(693.89) | Grad Norm 6.1442(7.6786) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 24.5845, Epoch Time 503.2942(471.0976), Bit/dim 3.6766(best: 3.6746), Xent 3.3777, Loss 5.3654, Error 0.4555(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2671 | Time 76.7045(74.8207) | Bit/dim 3.6424(3.6522) | Xent 0.0429(0.0720) | Loss 13.4482(9.6982) | Error 0.0138(0.0230) Steps 694(693.90) | Grad Norm 3.3941(7.5501) | Total Time 0.00(0.00)\n",
      "Iter 2672 | Time 74.9102(74.8233) | Bit/dim 3.6476(3.6521) | Xent 0.0642(0.0718) | Loss 8.7700(9.6704) | Error 0.0215(0.0230) Steps 724(694.80) | Grad Norm 5.8003(7.4976) | Total Time 0.00(0.00)\n",
      "Iter 2673 | Time 76.4193(74.8712) | Bit/dim 3.6371(3.6517) | Xent 0.0556(0.0713) | Loss 8.9695(9.6493) | Error 0.0186(0.0229) Steps 688(694.60) | Grad Norm 5.3744(7.4339) | Total Time 0.00(0.00)\n",
      "Iter 2674 | Time 77.1925(74.9409) | Bit/dim 3.6619(3.6520) | Xent 0.0519(0.0707) | Loss 8.8008(9.6239) | Error 0.0156(0.0226) Steps 724(695.48) | Grad Norm 4.2111(7.3372) | Total Time 0.00(0.00)\n",
      "Iter 2675 | Time 74.7954(74.9365) | Bit/dim 3.6439(3.6517) | Xent 0.0427(0.0699) | Loss 8.8485(9.6006) | Error 0.0124(0.0223) Steps 706(695.79) | Grad Norm 3.4200(7.2197) | Total Time 0.00(0.00)\n",
      "Iter 2676 | Time 74.2556(74.9161) | Bit/dim 3.6514(3.6517) | Xent 0.0552(0.0695) | Loss 8.8601(9.5784) | Error 0.0185(0.0222) Steps 694(695.74) | Grad Norm 5.4188(7.1657) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 25.3569, Epoch Time 497.8077(471.8989), Bit/dim 3.6761(best: 3.6746), Xent 3.3504, Loss 5.3513, Error 0.4570(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2677 | Time 73.7130(74.8800) | Bit/dim 3.6402(3.6514) | Xent 0.0338(0.0684) | Loss 13.7081(9.7023) | Error 0.0105(0.0219) Steps 706(696.05) | Grad Norm 2.5143(7.0261) | Total Time 0.00(0.00)\n",
      "Iter 2678 | Time 77.6079(74.9618) | Bit/dim 3.6499(3.6513) | Xent 0.0603(0.0681) | Loss 8.6517(9.6708) | Error 0.0178(0.0217) Steps 688(695.81) | Grad Norm 5.0797(6.9677) | Total Time 0.00(0.00)\n",
      "Iter 2679 | Time 73.6623(74.9228) | Bit/dim 3.6569(3.6515) | Xent 0.0425(0.0674) | Loss 8.5881(9.6383) | Error 0.0136(0.0215) Steps 664(694.85) | Grad Norm 4.0810(6.8811) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 72.7491(74.8576) | Bit/dim 3.6491(3.6514) | Xent 0.0489(0.0668) | Loss 8.8239(9.6139) | Error 0.0154(0.0213) Steps 700(695.01) | Grad Norm 4.2417(6.8020) | Total Time 0.00(0.00)\n",
      "Iter 2681 | Time 67.4419(74.6351) | Bit/dim 3.6396(3.6511) | Xent 0.0392(0.0660) | Loss 8.8433(9.5907) | Error 0.0121(0.0210) Steps 682(694.62) | Grad Norm 4.6830(6.7384) | Total Time 0.00(0.00)\n",
      "Iter 2682 | Time 76.5103(74.6914) | Bit/dim 3.6347(3.6506) | Xent 0.0494(0.0655) | Loss 8.8173(9.5675) | Error 0.0158(0.0209) Steps 694(694.60) | Grad Norm 4.9095(6.6835) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 25.3900, Epoch Time 485.5727(472.3091), Bit/dim 3.6743(best: 3.6746), Xent 3.3912, Loss 5.3699, Error 0.4547(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2683 | Time 73.0513(74.6422) | Bit/dim 3.6420(3.6503) | Xent 0.0361(0.0646) | Loss 13.3356(9.6806) | Error 0.0116(0.0206) Steps 688(694.40) | Grad Norm 5.0375(6.6341) | Total Time 0.00(0.00)\n",
      "Iter 2684 | Time 70.1940(74.5088) | Bit/dim 3.6523(3.6504) | Xent 0.0500(0.0642) | Loss 8.8552(9.6558) | Error 0.0156(0.0205) Steps 682(694.03) | Grad Norm 5.2322(6.5921) | Total Time 0.00(0.00)\n",
      "Iter 2685 | Time 70.1460(74.3779) | Bit/dim 3.6462(3.6502) | Xent 0.0380(0.0634) | Loss 9.0188(9.6367) | Error 0.0109(0.0202) Steps 700(694.21) | Grad Norm 5.9975(6.5742) | Total Time 0.00(0.00)\n",
      "Iter 2686 | Time 71.9331(74.3045) | Bit/dim 3.6437(3.6500) | Xent 0.0416(0.0627) | Loss 8.9929(9.6174) | Error 0.0138(0.0200) Steps 694(694.20) | Grad Norm 4.5550(6.5137) | Total Time 0.00(0.00)\n",
      "Iter 2687 | Time 75.4220(74.3380) | Bit/dim 3.6448(3.6499) | Xent 0.0517(0.0624) | Loss 8.9063(9.5961) | Error 0.0158(0.0198) Steps 712(694.73) | Grad Norm 6.5826(6.5157) | Total Time 0.00(0.00)\n",
      "Iter 2688 | Time 72.4987(74.2829) | Bit/dim 3.6365(3.6495) | Xent 0.0336(0.0615) | Loss 8.7941(9.5720) | Error 0.0102(0.0196) Steps 676(694.17) | Grad Norm 2.6144(6.3987) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 24.6595, Epoch Time 476.5343(472.4358), Bit/dim 3.6818(best: 3.6743), Xent 3.5204, Loss 5.4420, Error 0.4565(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2689 | Time 76.3416(74.3446) | Bit/dim 3.6643(3.6499) | Xent 0.0483(0.0611) | Loss 13.6482(9.6943) | Error 0.0155(0.0194) Steps 700(694.35) | Grad Norm 8.7157(6.4682) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 76.4857(74.4089) | Bit/dim 3.6490(3.6499) | Xent 0.0597(0.0611) | Loss 9.0077(9.6737) | Error 0.0194(0.0194) Steps 670(693.62) | Grad Norm 8.3395(6.5243) | Total Time 0.00(0.00)\n",
      "Iter 2691 | Time 72.1835(74.3421) | Bit/dim 3.6528(3.6500) | Xent 0.0481(0.0607) | Loss 8.7438(9.6458) | Error 0.0151(0.0193) Steps 682(693.27) | Grad Norm 6.8477(6.5340) | Total Time 0.00(0.00)\n",
      "Iter 2692 | Time 74.5053(74.3470) | Bit/dim 3.6371(3.6496) | Xent 0.0476(0.0603) | Loss 8.8800(9.6228) | Error 0.0146(0.0192) Steps 688(693.11) | Grad Norm 4.8350(6.4831) | Total Time 0.00(0.00)\n",
      "Iter 2693 | Time 71.0694(74.2487) | Bit/dim 3.6441(3.6494) | Xent 0.0538(0.0601) | Loss 8.9503(9.6026) | Error 0.0176(0.0191) Steps 706(693.50) | Grad Norm 7.4100(6.5109) | Total Time 0.00(0.00)\n",
      "Iter 2694 | Time 75.2853(74.2798) | Bit/dim 3.6509(3.6495) | Xent 0.0592(0.0601) | Loss 8.9804(9.5840) | Error 0.0186(0.0191) Steps 694(693.51) | Grad Norm 12.5473(6.6920) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 25.4500, Epoch Time 489.9919(472.9625), Bit/dim 3.6801(best: 3.6743), Xent 3.5620, Loss 5.4611, Error 0.4688(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2695 | Time 73.7231(74.2631) | Bit/dim 3.6550(3.6497) | Xent 0.0555(0.0600) | Loss 13.9075(9.7137) | Error 0.0178(0.0191) Steps 688(693.35) | Grad Norm 7.6346(6.7202) | Total Time 0.00(0.00)\n",
      "Iter 2696 | Time 69.3063(74.1144) | Bit/dim 3.6434(3.6495) | Xent 0.0461(0.0595) | Loss 8.9255(9.6900) | Error 0.0132(0.0189) Steps 694(693.37) | Grad Norm 6.4287(6.7115) | Total Time 0.00(0.00)\n",
      "Iter 2697 | Time 78.4138(74.2433) | Bit/dim 3.6408(3.6492) | Xent 0.0414(0.0590) | Loss 8.7491(9.6618) | Error 0.0134(0.0187) Steps 688(693.21) | Grad Norm 4.0708(6.6323) | Total Time 0.00(0.00)\n",
      "Iter 2698 | Time 76.2100(74.3023) | Bit/dim 3.6490(3.6492) | Xent 0.0424(0.0585) | Loss 8.7431(9.6342) | Error 0.0140(0.0186) Steps 718(693.95) | Grad Norm 5.1551(6.5880) | Total Time 0.00(0.00)\n",
      "Iter 2699 | Time 72.3971(74.2452) | Bit/dim 3.6413(3.6490) | Xent 0.0545(0.0584) | Loss 8.8161(9.6097) | Error 0.0172(0.0185) Steps 688(693.77) | Grad Norm 4.5733(6.5275) | Total Time 0.00(0.00)\n",
      "Iter 2700 | Time 76.1391(74.3020) | Bit/dim 3.6423(3.6488) | Xent 0.0544(0.0583) | Loss 8.7121(9.5828) | Error 0.0168(0.0185) Steps 694(693.78) | Grad Norm 3.4773(6.4360) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 25.3115, Epoch Time 490.8497(473.4991), Bit/dim 3.6783(best: 3.6743), Xent 3.4504, Loss 5.4035, Error 0.4547(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2701 | Time 69.7123(74.1643) | Bit/dim 3.6484(3.6488) | Xent 0.0381(0.0577) | Loss 13.9602(9.7141) | Error 0.0121(0.0183) Steps 664(692.88) | Grad Norm 3.4378(6.3461) | Total Time 0.00(0.00)\n",
      "Iter 2702 | Time 73.3977(74.1413) | Bit/dim 3.6391(3.6485) | Xent 0.0520(0.0575) | Loss 8.7319(9.6846) | Error 0.0168(0.0183) Steps 688(692.74) | Grad Norm 3.0234(6.2464) | Total Time 0.00(0.00)\n",
      "Iter 2703 | Time 71.2393(74.0543) | Bit/dim 3.6540(3.6486) | Xent 0.0354(0.0568) | Loss 8.8636(9.6600) | Error 0.0092(0.0180) Steps 682(692.42) | Grad Norm 2.7972(6.1429) | Total Time 0.00(0.00)\n",
      "Iter 2704 | Time 78.0281(74.1735) | Bit/dim 3.6495(3.6487) | Xent 0.0413(0.0564) | Loss 8.6203(9.6288) | Error 0.0120(0.0178) Steps 694(692.46) | Grad Norm 3.1179(6.0522) | Total Time 0.00(0.00)\n",
      "Iter 2705 | Time 75.5099(74.2136) | Bit/dim 3.6372(3.6483) | Xent 0.0476(0.0561) | Loss 8.8403(9.6052) | Error 0.0150(0.0177) Steps 706(692.87) | Grad Norm 3.2105(5.9669) | Total Time 0.00(0.00)\n",
      "Iter 2706 | Time 74.7356(74.2292) | Bit/dim 3.6333(3.6479) | Xent 0.0457(0.0558) | Loss 8.9916(9.5867) | Error 0.0138(0.0176) Steps 718(693.62) | Grad Norm 4.2336(5.9149) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 24.6667, Epoch Time 485.8988(473.8711), Bit/dim 3.6763(best: 3.6743), Xent 3.5073, Loss 5.4299, Error 0.4561(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2707 | Time 71.0420(74.1336) | Bit/dim 3.6475(3.6479) | Xent 0.0443(0.0554) | Loss 13.6122(9.7075) | Error 0.0150(0.0175) Steps 670(692.91) | Grad Norm 4.0836(5.8600) | Total Time 0.00(0.00)\n",
      "Iter 2708 | Time 71.0881(74.0422) | Bit/dim 3.6465(3.6478) | Xent 0.0362(0.0549) | Loss 8.3713(9.6674) | Error 0.0115(0.0173) Steps 682(692.59) | Grad Norm 2.0745(5.7464) | Total Time 0.00(0.00)\n",
      "Iter 2709 | Time 71.5536(73.9676) | Bit/dim 3.6375(3.6475) | Xent 0.0473(0.0546) | Loss 8.8638(9.6433) | Error 0.0149(0.0173) Steps 712(693.17) | Grad Norm 4.3794(5.7054) | Total Time 0.00(0.00)\n",
      "Iter 2710 | Time 74.5407(73.9848) | Bit/dim 3.6483(3.6475) | Xent 0.0388(0.0542) | Loss 8.7677(9.6171) | Error 0.0120(0.0171) Steps 682(692.83) | Grad Norm 3.8424(5.6495) | Total Time 0.00(0.00)\n",
      "Iter 2711 | Time 75.8055(74.0394) | Bit/dim 3.6345(3.6471) | Xent 0.0318(0.0535) | Loss 8.7298(9.5904) | Error 0.0105(0.0169) Steps 676(692.33) | Grad Norm 3.5428(5.5863) | Total Time 0.00(0.00)\n",
      "Iter 2712 | Time 74.6823(74.0587) | Bit/dim 3.6472(3.6471) | Xent 0.0370(0.0530) | Loss 8.8620(9.5686) | Error 0.0119(0.0168) Steps 694(692.38) | Grad Norm 3.0038(5.5088) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 24.7134, Epoch Time 482.0672(474.1170), Bit/dim 3.6746(best: 3.6743), Xent 3.5566, Loss 5.4529, Error 0.4590(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2713 | Time 75.8390(74.1121) | Bit/dim 3.6430(3.6470) | Xent 0.0396(0.0526) | Loss 13.9191(9.6991) | Error 0.0114(0.0166) Steps 688(692.25) | Grad Norm 2.9779(5.4329) | Total Time 0.00(0.00)\n",
      "Iter 2714 | Time 71.7732(74.0419) | Bit/dim 3.6453(3.6470) | Xent 0.0353(0.0521) | Loss 8.9074(9.6753) | Error 0.0105(0.0164) Steps 694(692.30) | Grad Norm 3.6109(5.3783) | Total Time 0.00(0.00)\n",
      "Iter 2715 | Time 74.7243(74.0624) | Bit/dim 3.6362(3.6466) | Xent 0.0481(0.0520) | Loss 8.8492(9.6506) | Error 0.0142(0.0163) Steps 670(691.63) | Grad Norm 4.2215(5.3435) | Total Time 0.00(0.00)\n",
      "Iter 2716 | Time 71.3381(73.9807) | Bit/dim 3.6396(3.6464) | Xent 0.0375(0.0515) | Loss 8.9798(9.6304) | Error 0.0111(0.0162) Steps 694(691.70) | Grad Norm 3.5600(5.2900) | Total Time 0.00(0.00)\n",
      "Iter 2717 | Time 68.3081(73.8105) | Bit/dim 3.6490(3.6465) | Xent 0.0330(0.0510) | Loss 8.8642(9.6075) | Error 0.0091(0.0160) Steps 694(691.77) | Grad Norm 3.3646(5.2323) | Total Time 0.00(0.00)\n",
      "Iter 2718 | Time 74.7998(73.8402) | Bit/dim 3.6379(3.6462) | Xent 0.0382(0.0506) | Loss 8.9267(9.5870) | Error 0.0135(0.0159) Steps 682(691.48) | Grad Norm 3.4853(5.1799) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 24.8526, Epoch Time 479.7255(474.2853), Bit/dim 3.6810(best: 3.6743), Xent 3.5790, Loss 5.4705, Error 0.4586(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2719 | Time 75.6374(73.8941) | Bit/dim 3.6377(3.6460) | Xent 0.0432(0.0504) | Loss 13.6195(9.7080) | Error 0.0128(0.0158) Steps 706(691.91) | Grad Norm 4.1575(5.1492) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 75.6768(73.9476) | Bit/dim 3.6481(3.6461) | Xent 0.0352(0.0499) | Loss 8.8209(9.6814) | Error 0.0112(0.0157) Steps 682(691.62) | Grad Norm 3.1813(5.0902) | Total Time 0.00(0.00)\n",
      "Iter 2721 | Time 74.2622(73.9570) | Bit/dim 3.6441(3.6460) | Xent 0.0343(0.0494) | Loss 8.8755(9.6572) | Error 0.0109(0.0155) Steps 694(691.69) | Grad Norm 4.7432(5.0798) | Total Time 0.00(0.00)\n",
      "Iter 2722 | Time 72.3023(73.9074) | Bit/dim 3.6430(3.6459) | Xent 0.0394(0.0491) | Loss 8.8981(9.6344) | Error 0.0118(0.0154) Steps 682(691.40) | Grad Norm 3.5438(5.0337) | Total Time 0.00(0.00)\n",
      "Iter 2723 | Time 74.5042(73.9253) | Bit/dim 3.6424(3.6458) | Xent 0.0358(0.0487) | Loss 8.7723(9.6086) | Error 0.0106(0.0153) Steps 688(691.30) | Grad Norm 4.5810(5.0201) | Total Time 0.00(0.00)\n",
      "Iter 2724 | Time 74.3747(73.9388) | Bit/dim 3.6420(3.6457) | Xent 0.0396(0.0485) | Loss 8.6893(9.5810) | Error 0.0126(0.0152) Steps 688(691.20) | Grad Norm 4.5585(5.0062) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 25.6391, Epoch Time 490.4054(474.7689), Bit/dim 3.6741(best: 3.6743), Xent 3.6095, Loss 5.4789, Error 0.4586(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2725 | Time 71.4825(73.8651) | Bit/dim 3.6365(3.6454) | Xent 0.0333(0.0480) | Loss 13.8478(9.7090) | Error 0.0102(0.0150) Steps 688(691.10) | Grad Norm 3.9816(4.9755) | Total Time 0.00(0.00)\n",
      "Iter 2726 | Time 75.2013(73.9052) | Bit/dim 3.6339(3.6451) | Xent 0.0441(0.0479) | Loss 8.8376(9.6829) | Error 0.0128(0.0150) Steps 688(691.01) | Grad Norm 4.8434(4.9715) | Total Time 0.00(0.00)\n",
      "Iter 2727 | Time 79.7090(74.0793) | Bit/dim 3.6417(3.6450) | Xent 0.0378(0.0476) | Loss 8.9299(9.6603) | Error 0.0114(0.0149) Steps 706(691.46) | Grad Norm 4.9623(4.9713) | Total Time 0.00(0.00)\n",
      "Iter 2728 | Time 73.3920(74.0587) | Bit/dim 3.6491(3.6451) | Xent 0.0398(0.0474) | Loss 8.5446(9.6268) | Error 0.0126(0.0148) Steps 706(691.89) | Grad Norm 3.2933(4.9209) | Total Time 0.00(0.00)\n",
      "Iter 2729 | Time 72.0705(73.9990) | Bit/dim 3.6473(3.6452) | Xent 0.0425(0.0472) | Loss 8.7700(9.6011) | Error 0.0130(0.0147) Steps 688(691.78) | Grad Norm 4.6724(4.9135) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 77.6886(74.1097) | Bit/dim 3.6437(3.6451) | Xent 0.0449(0.0471) | Loss 8.8634(9.5790) | Error 0.0139(0.0147) Steps 706(692.20) | Grad Norm 4.2154(4.8925) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 25.2409, Epoch Time 492.8706(475.3119), Bit/dim 3.6751(best: 3.6741), Xent 3.5385, Loss 5.4443, Error 0.4569(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2731 | Time 72.2314(74.0533) | Bit/dim 3.6382(3.6449) | Xent 0.0300(0.0466) | Loss 12.5357(9.6677) | Error 0.0094(0.0146) Steps 676(691.72) | Grad Norm 2.7457(4.8281) | Total Time 0.00(0.00)\n",
      "Iter 2732 | Time 75.0715(74.0839) | Bit/dim 3.6440(3.6449) | Xent 0.0387(0.0464) | Loss 8.8482(9.6431) | Error 0.0111(0.0145) Steps 718(692.51) | Grad Norm 3.7846(4.7968) | Total Time 0.00(0.00)\n",
      "Iter 2733 | Time 78.3418(74.2116) | Bit/dim 3.6397(3.6447) | Xent 0.0312(0.0459) | Loss 8.8657(9.6198) | Error 0.0095(0.0143) Steps 706(692.91) | Grad Norm 3.2502(4.7504) | Total Time 0.00(0.00)\n",
      "Iter 2734 | Time 74.8140(74.2297) | Bit/dim 3.6456(3.6447) | Xent 0.0389(0.0457) | Loss 8.9164(9.5987) | Error 0.0116(0.0142) Steps 700(693.12) | Grad Norm 3.4865(4.7125) | Total Time 0.00(0.00)\n",
      "Iter 2735 | Time 72.9591(74.1916) | Bit/dim 3.6444(3.6447) | Xent 0.0441(0.0457) | Loss 8.7911(9.5744) | Error 0.0128(0.0142) Steps 688(692.97) | Grad Norm 3.4686(4.6752) | Total Time 0.00(0.00)\n",
      "Iter 2736 | Time 69.8129(74.0602) | Bit/dim 3.6429(3.6447) | Xent 0.0450(0.0457) | Loss 8.8062(9.5514) | Error 0.0148(0.0142) Steps 682(692.64) | Grad Norm 6.2753(4.7232) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 25.1081, Epoch Time 486.6820(475.6530), Bit/dim 3.6773(best: 3.6741), Xent 3.6079, Loss 5.4813, Error 0.4558(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2737 | Time 71.2118(73.9748) | Bit/dim 3.6381(3.6445) | Xent 0.0372(0.0454) | Loss 13.8022(9.6789) | Error 0.0111(0.0141) Steps 682(692.32) | Grad Norm 5.3999(4.7435) | Total Time 0.00(0.00)\n",
      "Iter 2738 | Time 66.9455(73.7639) | Bit/dim 3.6420(3.6444) | Xent 0.0376(0.0452) | Loss 8.7945(9.6524) | Error 0.0108(0.0140) Steps 682(692.01) | Grad Norm 5.4613(4.7650) | Total Time 0.00(0.00)\n",
      "Iter 2739 | Time 75.9836(73.8305) | Bit/dim 3.6473(3.6445) | Xent 0.0402(0.0450) | Loss 8.6218(9.6215) | Error 0.0132(0.0140) Steps 688(691.89) | Grad Norm 8.4410(4.8753) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 74.4655(73.8495) | Bit/dim 3.6416(3.6444) | Xent 0.0276(0.0445) | Loss 8.8597(9.5986) | Error 0.0085(0.0138) Steps 694(691.95) | Grad Norm 2.0570(4.7908) | Total Time 0.00(0.00)\n",
      "Iter 2741 | Time 77.7186(73.9656) | Bit/dim 3.6390(3.6442) | Xent 0.0399(0.0444) | Loss 8.7316(9.5726) | Error 0.0124(0.0138) Steps 700(692.20) | Grad Norm 6.3426(4.8373) | Total Time 0.00(0.00)\n",
      "Iter 2742 | Time 75.9181(74.0242) | Bit/dim 3.6443(3.6443) | Xent 0.0322(0.0440) | Loss 8.7734(9.5486) | Error 0.0099(0.0137) Steps 694(692.25) | Grad Norm 3.1245(4.7859) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 25.2641, Epoch Time 486.1405(475.9676), Bit/dim 3.6801(best: 3.6741), Xent 3.5848, Loss 5.4725, Error 0.4652(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2743 | Time 75.7006(74.0745) | Bit/dim 3.6445(3.6443) | Xent 0.0459(0.0440) | Loss 14.0108(9.6825) | Error 0.0152(0.0137) Steps 670(691.58) | Grad Norm 9.6036(4.9305) | Total Time 0.00(0.00)\n",
      "Iter 2744 | Time 73.8852(74.0688) | Bit/dim 3.6523(3.6445) | Xent 0.0510(0.0443) | Loss 8.4476(9.6454) | Error 0.0159(0.0138) Steps 706(692.02) | Grad Norm 8.7053(5.0437) | Total Time 0.00(0.00)\n",
      "Iter 2745 | Time 70.8532(73.9723) | Bit/dim 3.6428(3.6444) | Xent 0.0420(0.0442) | Loss 8.8531(9.6217) | Error 0.0144(0.0138) Steps 688(691.89) | Grad Norm 6.0845(5.0749) | Total Time 0.00(0.00)\n",
      "Iter 2746 | Time 71.2444(73.8905) | Bit/dim 3.6462(3.6445) | Xent 0.0459(0.0442) | Loss 8.3353(9.5831) | Error 0.0141(0.0138) Steps 670(691.24) | Grad Norm 8.7616(5.1855) | Total Time 0.00(0.00)\n",
      "Iter 2747 | Time 76.6112(73.9721) | Bit/dim 3.6393(3.6443) | Xent 0.0340(0.0439) | Loss 8.6481(9.5550) | Error 0.0105(0.0137) Steps 700(691.50) | Grad Norm 3.8170(5.1445) | Total Time 0.00(0.00)\n",
      "Iter 2748 | Time 75.9867(74.0325) | Bit/dim 3.6316(3.6440) | Xent 0.0359(0.0437) | Loss 8.8895(9.5351) | Error 0.0106(0.0136) Steps 670(690.86) | Grad Norm 4.8625(5.1360) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 25.7049, Epoch Time 487.8961(476.3255), Bit/dim 3.6772(best: 3.6741), Xent 3.6112, Loss 5.4828, Error 0.4589(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2749 | Time 75.4604(74.0754) | Bit/dim 3.6361(3.6437) | Xent 0.0367(0.0435) | Loss 13.5612(9.6558) | Error 0.0104(0.0135) Steps 664(690.05) | Grad Norm 4.1145(5.1054) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 75.8722(74.1293) | Bit/dim 3.6515(3.6440) | Xent 0.0417(0.0434) | Loss 8.9422(9.6344) | Error 0.0138(0.0135) Steps 688(689.99) | Grad Norm 5.9239(5.1299) | Total Time 0.00(0.00)\n",
      "Iter 2751 | Time 74.2878(74.1340) | Bit/dim 3.6473(3.6441) | Xent 0.0338(0.0431) | Loss 8.7139(9.6068) | Error 0.0105(0.0134) Steps 682(689.75) | Grad Norm 3.4884(5.0807) | Total Time 0.00(0.00)\n",
      "Iter 2752 | Time 75.2196(74.1666) | Bit/dim 3.6331(3.6437) | Xent 0.0391(0.0430) | Loss 8.7798(9.5820) | Error 0.0114(0.0134) Steps 700(690.06) | Grad Norm 5.0419(5.0795) | Total Time 0.00(0.00)\n",
      "Iter 2753 | Time 76.1817(74.2271) | Bit/dim 3.6408(3.6436) | Xent 0.0462(0.0431) | Loss 8.7426(9.5568) | Error 0.0136(0.0134) Steps 688(689.99) | Grad Norm 6.9496(5.1356) | Total Time 0.00(0.00)\n",
      "Iter 2754 | Time 75.3668(74.2613) | Bit/dim 3.6433(3.6436) | Xent 0.0415(0.0431) | Loss 8.7666(9.5331) | Error 0.0129(0.0134) Steps 688(689.93) | Grad Norm 6.5545(5.1782) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 24.8843, Epoch Time 495.2054(476.8919), Bit/dim 3.6748(best: 3.6741), Xent 3.5646, Loss 5.4571, Error 0.4571(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2755 | Time 75.5961(74.3013) | Bit/dim 3.6394(3.6435) | Xent 0.0332(0.0428) | Loss 13.5633(9.6540) | Error 0.0105(0.0133) Steps 700(690.24) | Grad Norm 4.3602(5.1536) | Total Time 0.00(0.00)\n",
      "Iter 2756 | Time 83.6976(74.5832) | Bit/dim 3.6316(3.6431) | Xent 0.0475(0.0429) | Loss 8.8959(9.6313) | Error 0.0141(0.0133) Steps 718(691.07) | Grad Norm 7.6703(5.2291) | Total Time 0.00(0.00)\n",
      "Iter 2757 | Time 72.3364(74.5158) | Bit/dim 3.6473(3.6433) | Xent 0.0409(0.0429) | Loss 8.8189(9.6069) | Error 0.0131(0.0133) Steps 712(691.70) | Grad Norm 4.4666(5.2063) | Total Time 0.00(0.00)\n",
      "Iter 2758 | Time 72.9003(74.4673) | Bit/dim 3.6430(3.6433) | Xent 0.0483(0.0430) | Loss 9.0066(9.5889) | Error 0.0154(0.0134) Steps 700(691.95) | Grad Norm 6.5138(5.2455) | Total Time 0.00(0.00)\n",
      "Iter 2759 | Time 75.8455(74.5087) | Bit/dim 3.6327(3.6429) | Xent 0.0853(0.0443) | Loss 8.9452(9.5696) | Error 0.0255(0.0137) Steps 700(692.19) | Grad Norm 9.8725(5.3843) | Total Time 0.00(0.00)\n",
      "Iter 2760 | Time 75.3894(74.5351) | Bit/dim 3.6408(3.6429) | Xent 0.0989(0.0459) | Loss 8.9261(9.5503) | Error 0.0343(0.0143) Steps 706(692.60) | Grad Norm 18.8344(5.7878) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 24.9576, Epoch Time 498.5131(477.5405), Bit/dim 3.6918(best: 3.6741), Xent 3.6163, Loss 5.4999, Error 0.4753(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2761 | Time 72.1544(74.4637) | Bit/dim 3.6575(3.6433) | Xent 0.2955(0.0534) | Loss 14.1387(9.6879) | Error 0.0820(0.0164) Steps 694(692.64) | Grad Norm 43.0986(6.9071) | Total Time 0.00(0.00)\n",
      "Iter 2762 | Time 71.3570(74.3705) | Bit/dim 3.6605(3.6438) | Xent 0.0428(0.0531) | Loss 9.0205(9.6679) | Error 0.0132(0.0163) Steps 700(692.87) | Grad Norm 6.3500(6.8904) | Total Time 0.00(0.00)\n",
      "Iter 2763 | Time 76.5049(74.4345) | Bit/dim 3.6582(3.6443) | Xent 0.2036(0.0576) | Loss 9.0304(9.6488) | Error 0.0629(0.0177) Steps 700(693.08) | Grad Norm 28.6854(7.5443) | Total Time 0.00(0.00)\n",
      "Iter 2764 | Time 74.0391(74.4226) | Bit/dim 3.6466(3.6443) | Xent 0.1019(0.0589) | Loss 8.9654(9.6283) | Error 0.0325(0.0181) Steps 700(693.29) | Grad Norm 10.7622(7.6408) | Total Time 0.00(0.00)\n",
      "Iter 2765 | Time 70.5296(74.3058) | Bit/dim 3.6409(3.6442) | Xent 0.1195(0.0608) | Loss 8.9422(9.6077) | Error 0.0396(0.0188) Steps 700(693.49) | Grad Norm 15.9447(7.8899) | Total Time 0.00(0.00)\n",
      "Iter 2766 | Time 71.1645(74.2116) | Bit/dim 3.6498(3.6444) | Xent 0.1355(0.0630) | Loss 9.0726(9.5916) | Error 0.0434(0.0195) Steps 676(692.96) | Grad Norm 11.7910(8.0070) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 25.0865, Epoch Time 478.8945(477.5811), Bit/dim 3.6894(best: 3.6741), Xent 3.1258, Loss 5.2523, Error 0.4600(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2767 | Time 78.1726(74.3304) | Bit/dim 3.6646(3.6450) | Xent 0.1353(0.0652) | Loss 13.5554(9.7106) | Error 0.0417(0.0202) Steps 706(693.35) | Grad Norm 18.3518(8.3173) | Total Time 0.00(0.00)\n",
      "Iter 2768 | Time 79.3757(74.4818) | Bit/dim 3.6492(3.6451) | Xent 0.0948(0.0661) | Loss 9.0680(9.6913) | Error 0.0312(0.0205) Steps 706(693.73) | Grad Norm 12.2271(8.4346) | Total Time 0.00(0.00)\n",
      "Iter 2769 | Time 79.9331(74.6453) | Bit/dim 3.6412(3.6450) | Xent 0.1236(0.0678) | Loss 8.9869(9.6702) | Error 0.0407(0.0211) Steps 712(694.28) | Grad Norm 11.3089(8.5208) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 77.3234(74.7257) | Bit/dim 3.6519(3.6452) | Xent 0.0575(0.0675) | Loss 8.9737(9.6493) | Error 0.0184(0.0210) Steps 694(694.27) | Grad Norm 7.3267(8.4850) | Total Time 0.00(0.00)\n",
      "Iter 2771 | Time 75.1266(74.7377) | Bit/dim 3.6628(3.6457) | Xent 0.1212(0.0691) | Loss 9.0236(9.6305) | Error 0.0411(0.0216) Steps 706(694.63) | Grad Norm 9.2022(8.5065) | Total Time 0.00(0.00)\n",
      "Iter 2772 | Time 72.5264(74.6714) | Bit/dim 3.6509(3.6459) | Xent 0.0583(0.0688) | Loss 8.7393(9.6038) | Error 0.0186(0.0215) Steps 688(694.43) | Grad Norm 3.6110(8.3596) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 25.5005, Epoch Time 506.4213(478.4464), Bit/dim 3.6798(best: 3.6741), Xent 3.1202, Loss 5.2400, Error 0.4576(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2773 | Time 76.6444(74.7306) | Bit/dim 3.6407(3.6457) | Xent 0.1015(0.0697) | Loss 13.4373(9.7188) | Error 0.0341(0.0219) Steps 718(695.13) | Grad Norm 7.8026(8.3429) | Total Time 0.00(0.00)\n",
      "Iter 2774 | Time 73.2990(74.6876) | Bit/dim 3.6450(3.6457) | Xent 0.0740(0.0699) | Loss 8.8329(9.6922) | Error 0.0229(0.0219) Steps 682(694.74) | Grad Norm 5.3621(8.2535) | Total Time 0.00(0.00)\n",
      "Iter 2775 | Time 74.7616(74.6898) | Bit/dim 3.6610(3.6462) | Xent 0.0714(0.0699) | Loss 8.9311(9.6694) | Error 0.0221(0.0220) Steps 688(694.54) | Grad Norm 5.7635(8.1788) | Total Time 0.00(0.00)\n",
      "Iter 2776 | Time 78.1154(74.7926) | Bit/dim 3.6481(3.6462) | Xent 0.0662(0.0698) | Loss 8.9866(9.6489) | Error 0.0219(0.0219) Steps 718(695.24) | Grad Norm 8.3729(8.1846) | Total Time 0.00(0.00)\n",
      "Iter 2777 | Time 73.1454(74.7432) | Bit/dim 3.6428(3.6461) | Xent 0.0597(0.0695) | Loss 8.9464(9.6278) | Error 0.0188(0.0219) Steps 694(695.20) | Grad Norm 6.9707(8.1482) | Total Time 0.00(0.00)\n",
      "Iter 2778 | Time 73.9698(74.7200) | Bit/dim 3.6588(3.6465) | Xent 0.0541(0.0690) | Loss 8.9629(9.6078) | Error 0.0184(0.0217) Steps 700(695.35) | Grad Norm 6.8310(8.1087) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 25.1908, Epoch Time 493.0794(478.8853), Bit/dim 3.6787(best: 3.6741), Xent 3.4120, Loss 5.3847, Error 0.4585(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2779 | Time 74.5551(74.7150) | Bit/dim 3.6553(3.6468) | Xent 0.0546(0.0686) | Loss 13.5190(9.7252) | Error 0.0188(0.0217) Steps 688(695.13) | Grad Norm 6.6677(8.0655) | Total Time 0.00(0.00)\n",
      "Iter 2780 | Time 70.6488(74.5930) | Bit/dim 3.6461(3.6468) | Xent 0.0511(0.0681) | Loss 8.7161(9.6949) | Error 0.0152(0.0215) Steps 658(694.01) | Grad Norm 4.8152(7.9680) | Total Time 0.00(0.00)\n",
      "Iter 2781 | Time 75.8768(74.6316) | Bit/dim 3.6462(3.6467) | Xent 0.0625(0.0679) | Loss 8.6434(9.6634) | Error 0.0189(0.0214) Steps 682(693.65) | Grad Norm 7.2796(7.9473) | Total Time 0.00(0.00)\n",
      "Iter 2782 | Time 72.0836(74.5551) | Bit/dim 3.6471(3.6468) | Xent 0.0410(0.0671) | Loss 8.8161(9.6379) | Error 0.0131(0.0211) Steps 700(693.84) | Grad Norm 3.8957(7.8258) | Total Time 0.00(0.00)\n",
      "Iter 2783 | Time 74.7157(74.5599) | Bit/dim 3.6453(3.6467) | Xent 0.0504(0.0666) | Loss 8.8162(9.6133) | Error 0.0156(0.0210) Steps 688(693.67) | Grad Norm 6.1211(7.7746) | Total Time 0.00(0.00)\n",
      "Iter 2784 | Time 73.7626(74.5360) | Bit/dim 3.6458(3.6467) | Xent 0.0460(0.0660) | Loss 9.0173(9.5954) | Error 0.0138(0.0208) Steps 688(693.50) | Grad Norm 3.6305(7.6503) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 25.1728, Epoch Time 485.3718(479.0799), Bit/dim 3.6720(best: 3.6741), Xent 3.4628, Loss 5.4034, Error 0.4587(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2785 | Time 74.6853(74.5405) | Bit/dim 3.6387(3.6464) | Xent 0.0442(0.0653) | Loss 13.1514(9.7021) | Error 0.0149(0.0206) Steps 700(693.69) | Grad Norm 5.8275(7.5956) | Total Time 0.00(0.00)\n",
      "Iter 2786 | Time 74.1846(74.5298) | Bit/dim 3.6384(3.6462) | Xent 0.0562(0.0651) | Loss 8.9031(9.6781) | Error 0.0154(0.0204) Steps 688(693.52) | Grad Norm 3.9154(7.4852) | Total Time 0.00(0.00)\n",
      "Iter 2787 | Time 73.1501(74.4884) | Bit/dim 3.6431(3.6461) | Xent 0.0477(0.0645) | Loss 8.9656(9.6567) | Error 0.0155(0.0203) Steps 682(693.18) | Grad Norm 4.2817(7.3891) | Total Time 0.00(0.00)\n",
      "Iter 2788 | Time 71.3319(74.3937) | Bit/dim 3.6436(3.6460) | Xent 0.0401(0.0638) | Loss 8.8737(9.6333) | Error 0.0116(0.0200) Steps 700(693.38) | Grad Norm 3.4063(7.2696) | Total Time 0.00(0.00)\n",
      "Iter 2789 | Time 73.1861(74.3575) | Bit/dim 3.6436(3.6460) | Xent 0.0496(0.0634) | Loss 8.9520(9.6128) | Error 0.0166(0.0199) Steps 718(694.12) | Grad Norm 4.4126(7.1839) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 80.4838(74.5413) | Bit/dim 3.6437(3.6459) | Xent 0.0390(0.0626) | Loss 8.8081(9.5887) | Error 0.0124(0.0197) Steps 718(694.84) | Grad Norm 3.2781(7.0667) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 24.9015, Epoch Time 490.1946(479.4134), Bit/dim 3.6739(best: 3.6720), Xent 3.4423, Loss 5.3950, Error 0.4587(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2791 | Time 78.2368(74.6522) | Bit/dim 3.6464(3.6459) | Xent 0.0451(0.0621) | Loss 13.5359(9.7071) | Error 0.0129(0.0195) Steps 730(695.89) | Grad Norm 5.0844(7.0073) | Total Time 0.00(0.00)\n",
      "Iter 2792 | Time 70.8016(74.5366) | Bit/dim 3.6486(3.6460) | Xent 0.0407(0.0615) | Loss 8.6612(9.6757) | Error 0.0132(0.0193) Steps 694(695.83) | Grad Norm 3.4026(6.8991) | Total Time 0.00(0.00)\n",
      "Iter 2793 | Time 77.2367(74.6176) | Bit/dim 3.6372(3.6457) | Xent 0.0402(0.0608) | Loss 8.9001(9.6524) | Error 0.0130(0.0191) Steps 712(696.32) | Grad Norm 3.8198(6.8067) | Total Time 0.00(0.00)\n",
      "Iter 2794 | Time 73.5981(74.5871) | Bit/dim 3.6315(3.6453) | Xent 0.0437(0.0603) | Loss 8.9320(9.6308) | Error 0.0130(0.0189) Steps 724(697.15) | Grad Norm 3.7731(6.7157) | Total Time 0.00(0.00)\n",
      "Iter 2795 | Time 79.8435(74.7447) | Bit/dim 3.6482(3.6454) | Xent 0.0381(0.0597) | Loss 8.8721(9.6081) | Error 0.0122(0.0187) Steps 700(697.24) | Grad Norm 3.3802(6.6157) | Total Time 0.00(0.00)\n",
      "Iter 2796 | Time 76.9268(74.8102) | Bit/dim 3.6385(3.6452) | Xent 0.0434(0.0592) | Loss 8.7835(9.5833) | Error 0.0128(0.0185) Steps 694(697.14) | Grad Norm 4.0886(6.5399) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 25.0870, Epoch Time 500.2782(480.0393), Bit/dim 3.6721(best: 3.6720), Xent 3.4943, Loss 5.4193, Error 0.4657(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2797 | Time 70.2110(74.6722) | Bit/dim 3.6555(3.6455) | Xent 0.0320(0.0584) | Loss 13.3096(9.6951) | Error 0.0092(0.0183) Steps 676(696.50) | Grad Norm 3.8653(6.4596) | Total Time 0.00(0.00)\n",
      "Iter 2798 | Time 73.1162(74.6255) | Bit/dim 3.6299(3.6450) | Xent 0.0404(0.0578) | Loss 8.7850(9.6678) | Error 0.0126(0.0181) Steps 670(695.71) | Grad Norm 4.1069(6.3890) | Total Time 0.00(0.00)\n",
      "Iter 2799 | Time 75.1736(74.6420) | Bit/dim 3.6451(3.6450) | Xent 0.0381(0.0572) | Loss 8.5148(9.6332) | Error 0.0122(0.0179) Steps 688(695.48) | Grad Norm 3.5488(6.3038) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 80.6057(74.8209) | Bit/dim 3.6497(3.6452) | Xent 0.0444(0.0568) | Loss 8.8541(9.6099) | Error 0.0139(0.0178) Steps 730(696.51) | Grad Norm 4.1553(6.2394) | Total Time 0.00(0.00)\n",
      "Iter 2801 | Time 74.9424(74.8245) | Bit/dim 3.6193(3.6444) | Xent 0.0311(0.0561) | Loss 8.8092(9.5858) | Error 0.0091(0.0175) Steps 688(696.26) | Grad Norm 2.3939(6.1240) | Total Time 0.00(0.00)\n",
      "Iter 2802 | Time 77.4893(74.9045) | Bit/dim 3.6461(3.6444) | Xent 0.0346(0.0554) | Loss 8.7776(9.5616) | Error 0.0104(0.0173) Steps 730(697.27) | Grad Norm 4.5711(6.0774) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 25.7968, Epoch Time 496.1411(480.5224), Bit/dim 3.6737(best: 3.6720), Xent 3.5082, Loss 5.4278, Error 0.4562(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2803 | Time 74.3924(74.8891) | Bit/dim 3.6513(3.6446) | Xent 0.0358(0.0548) | Loss 13.7403(9.6869) | Error 0.0105(0.0171) Steps 694(697.17) | Grad Norm 2.5005(5.9701) | Total Time 0.00(0.00)\n",
      "Iter 2804 | Time 80.8345(75.0675) | Bit/dim 3.6387(3.6445) | Xent 0.0349(0.0542) | Loss 8.9132(9.6637) | Error 0.0110(0.0169) Steps 688(696.90) | Grad Norm 2.1093(5.8543) | Total Time 0.00(0.00)\n",
      "Iter 2805 | Time 77.4451(75.1388) | Bit/dim 3.6327(3.6441) | Xent 0.0371(0.0537) | Loss 8.7786(9.6372) | Error 0.0101(0.0167) Steps 712(697.35) | Grad Norm 3.2919(5.7774) | Total Time 0.00(0.00)\n",
      "Iter 2806 | Time 80.5644(75.3016) | Bit/dim 3.6333(3.6438) | Xent 0.0410(0.0533) | Loss 8.7408(9.6103) | Error 0.0126(0.0166) Steps 700(697.43) | Grad Norm 3.0708(5.6962) | Total Time 0.00(0.00)\n",
      "Iter 2807 | Time 76.8422(75.3478) | Bit/dim 3.6321(3.6434) | Xent 0.0307(0.0527) | Loss 8.6432(9.5813) | Error 0.0088(0.0164) Steps 682(696.97) | Grad Norm 2.1709(5.5905) | Total Time 0.00(0.00)\n",
      "Iter 2808 | Time 82.0039(75.5475) | Bit/dim 3.6377(3.6433) | Xent 0.0357(0.0522) | Loss 8.8103(9.5581) | Error 0.0111(0.0162) Steps 706(697.24) | Grad Norm 2.4505(5.4963) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 25.5555, Epoch Time 516.1207(481.5903), Bit/dim 3.6728(best: 3.6720), Xent 3.4631, Loss 5.4044, Error 0.4526(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2809 | Time 72.2203(75.4477) | Bit/dim 3.6558(3.6436) | Xent 0.0290(0.0515) | Loss 13.8612(9.6872) | Error 0.0098(0.0160) Steps 700(697.32) | Grad Norm 2.1259(5.3951) | Total Time 0.00(0.00)\n",
      "Iter 2810 | Time 73.1555(75.3789) | Bit/dim 3.6377(3.6435) | Xent 0.0306(0.0508) | Loss 8.9689(9.6657) | Error 0.0090(0.0158) Steps 688(697.04) | Grad Norm 2.7195(5.3149) | Total Time 0.00(0.00)\n",
      "Iter 2811 | Time 74.7466(75.3599) | Bit/dim 3.6448(3.6435) | Xent 0.0373(0.0504) | Loss 8.6854(9.6363) | Error 0.0118(0.0157) Steps 700(697.13) | Grad Norm 2.3577(5.2262) | Total Time 0.00(0.00)\n",
      "Iter 2812 | Time 75.4019(75.3612) | Bit/dim 3.6298(3.6431) | Xent 0.0317(0.0499) | Loss 8.8103(9.6115) | Error 0.0091(0.0155) Steps 676(696.50) | Grad Norm 2.1335(5.1334) | Total Time 0.00(0.00)\n",
      "Iter 2813 | Time 76.5788(75.3977) | Bit/dim 3.6272(3.6426) | Xent 0.0334(0.0494) | Loss 8.8238(9.5879) | Error 0.0100(0.0153) Steps 682(696.06) | Grad Norm 2.7056(5.0605) | Total Time 0.00(0.00)\n",
      "Iter 2814 | Time 76.6927(75.4366) | Bit/dim 3.6309(3.6423) | Xent 0.0322(0.0489) | Loss 8.8470(9.5656) | Error 0.0102(0.0152) Steps 706(696.36) | Grad Norm 2.5940(4.9866) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 25.4351, Epoch Time 492.2637(481.9105), Bit/dim 3.6704(best: 3.6720), Xent 3.5341, Loss 5.4374, Error 0.4542(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2815 | Time 71.5159(75.3190) | Bit/dim 3.6422(3.6423) | Xent 0.0301(0.0483) | Loss 13.1283(9.6725) | Error 0.0091(0.0150) Steps 700(696.47) | Grad Norm 2.8486(4.9224) | Total Time 0.00(0.00)\n",
      "Iter 2816 | Time 77.3792(75.3808) | Bit/dim 3.6333(3.6420) | Xent 0.0302(0.0478) | Loss 8.7729(9.6455) | Error 0.0095(0.0148) Steps 688(696.21) | Grad Norm 2.2355(4.8418) | Total Time 0.00(0.00)\n",
      "Iter 2817 | Time 71.8910(75.2761) | Bit/dim 3.6494(3.6422) | Xent 0.0385(0.0475) | Loss 8.8086(9.6204) | Error 0.0120(0.0147) Steps 676(695.61) | Grad Norm 3.9678(4.8156) | Total Time 0.00(0.00)\n",
      "Iter 2818 | Time 70.4800(75.1322) | Bit/dim 3.6348(3.6420) | Xent 0.0352(0.0471) | Loss 8.8215(9.5965) | Error 0.0109(0.0146) Steps 694(695.56) | Grad Norm 2.9849(4.7607) | Total Time 0.00(0.00)\n",
      "Iter 2819 | Time 76.4772(75.1725) | Bit/dim 3.6297(3.6416) | Xent 0.0424(0.0470) | Loss 8.7509(9.5711) | Error 0.0134(0.0146) Steps 694(695.51) | Grad Norm 6.4462(4.8112) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 76.0787(75.1997) | Bit/dim 3.6328(3.6414) | Xent 0.0372(0.0467) | Loss 8.7227(9.5456) | Error 0.0096(0.0144) Steps 700(695.65) | Grad Norm 3.1620(4.7618) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 24.7753, Epoch Time 487.3337(482.0732), Bit/dim 3.6678(best: 3.6704), Xent 3.5109, Loss 5.4233, Error 0.4491(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2821 | Time 68.8771(75.0100) | Bit/dim 3.6324(3.6411) | Xent 0.0337(0.0463) | Loss 13.8885(9.6759) | Error 0.0091(0.0143) Steps 694(695.60) | Grad Norm 3.4542(4.7225) | Total Time 0.00(0.00)\n",
      "Iter 2822 | Time 68.9825(74.8292) | Bit/dim 3.6389(3.6410) | Xent 0.0396(0.0461) | Loss 8.6784(9.6460) | Error 0.0121(0.0142) Steps 700(695.73) | Grad Norm 2.4437(4.6542) | Total Time 0.00(0.00)\n",
      "Iter 2823 | Time 70.5050(74.6995) | Bit/dim 3.6473(3.6412) | Xent 0.0267(0.0455) | Loss 8.5430(9.6129) | Error 0.0084(0.0140) Steps 688(695.50) | Grad Norm 2.9334(4.6025) | Total Time 0.00(0.00)\n",
      "Iter 2824 | Time 74.0357(74.6796) | Bit/dim 3.6326(3.6410) | Xent 0.0392(0.0453) | Loss 8.7042(9.5856) | Error 0.0146(0.0141) Steps 700(695.63) | Grad Norm 3.0981(4.5574) | Total Time 0.00(0.00)\n",
      "Iter 2825 | Time 74.4497(74.6727) | Bit/dim 3.6348(3.6408) | Xent 0.0365(0.0451) | Loss 8.8949(9.5649) | Error 0.0102(0.0139) Steps 688(695.40) | Grad Norm 3.0958(4.5136) | Total Time 0.00(0.00)\n",
      "Iter 2826 | Time 79.3116(74.8118) | Bit/dim 3.6295(3.6404) | Xent 0.0376(0.0448) | Loss 8.9194(9.5456) | Error 0.0119(0.0139) Steps 688(695.18) | Grad Norm 2.2870(4.4468) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 25.4194, Epoch Time 479.9115(482.0084), Bit/dim 3.6724(best: 3.6678), Xent 3.5559, Loss 5.4504, Error 0.4534(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2827 | Time 76.8758(74.8738) | Bit/dim 3.6426(3.6405) | Xent 0.0337(0.0445) | Loss 13.5393(9.6654) | Error 0.0121(0.0138) Steps 706(695.51) | Grad Norm 3.8069(4.4276) | Total Time 0.00(0.00)\n",
      "Iter 2828 | Time 75.8360(74.9026) | Bit/dim 3.6305(3.6402) | Xent 0.0299(0.0441) | Loss 8.9234(9.6431) | Error 0.0099(0.0137) Steps 712(696.00) | Grad Norm 2.5461(4.3711) | Total Time 0.00(0.00)\n",
      "Iter 2829 | Time 75.2336(74.9126) | Bit/dim 3.6397(3.6402) | Xent 0.0315(0.0437) | Loss 8.6598(9.6136) | Error 0.0108(0.0136) Steps 652(694.68) | Grad Norm 2.4811(4.3144) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 72.7191(74.8468) | Bit/dim 3.6370(3.6401) | Xent 0.0413(0.0436) | Loss 8.9202(9.5928) | Error 0.0134(0.0136) Steps 712(695.20) | Grad Norm 4.4432(4.3183) | Total Time 0.00(0.00)\n",
      "Iter 2831 | Time 74.6103(74.8397) | Bit/dim 3.6325(3.6399) | Xent 0.0349(0.0433) | Loss 8.8177(9.5696) | Error 0.0115(0.0136) Steps 682(694.81) | Grad Norm 5.0720(4.3409) | Total Time 0.00(0.00)\n",
      "Iter 2832 | Time 77.2963(74.9134) | Bit/dim 3.6515(3.6402) | Xent 0.0444(0.0434) | Loss 8.9145(9.5499) | Error 0.0141(0.0136) Steps 706(695.14) | Grad Norm 6.8591(4.4164) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 25.0849, Epoch Time 496.4422(482.4414), Bit/dim 3.6707(best: 3.6678), Xent 3.6451, Loss 5.4932, Error 0.4565(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2833 | Time 71.8451(74.8213) | Bit/dim 3.6304(3.6399) | Xent 0.0323(0.0430) | Loss 13.5062(9.6686) | Error 0.0090(0.0134) Steps 670(694.39) | Grad Norm 3.4616(4.3878) | Total Time 0.00(0.00)\n",
      "Iter 2834 | Time 75.1677(74.8317) | Bit/dim 3.6402(3.6399) | Xent 0.0381(0.0429) | Loss 8.7832(9.6420) | Error 0.0114(0.0134) Steps 706(694.74) | Grad Norm 3.7857(4.3697) | Total Time 0.00(0.00)\n",
      "Iter 2835 | Time 74.8308(74.8317) | Bit/dim 3.6411(3.6400) | Xent 0.0344(0.0426) | Loss 8.7515(9.6153) | Error 0.0119(0.0133) Steps 712(695.25) | Grad Norm 4.0259(4.3594) | Total Time 0.00(0.00)\n",
      "Iter 2836 | Time 78.6132(74.9451) | Bit/dim 3.6293(3.6396) | Xent 0.0326(0.0423) | Loss 8.8684(9.5929) | Error 0.0090(0.0132) Steps 694(695.22) | Grad Norm 2.9252(4.3164) | Total Time 0.00(0.00)\n",
      "Iter 2837 | Time 76.2821(74.9852) | Bit/dim 3.6398(3.6397) | Xent 0.0353(0.0421) | Loss 8.6815(9.5656) | Error 0.0105(0.0131) Steps 718(695.90) | Grad Norm 5.1619(4.3418) | Total Time 0.00(0.00)\n",
      "Iter 2838 | Time 71.3361(74.8758) | Bit/dim 3.6421(3.6397) | Xent 0.0299(0.0418) | Loss 8.6483(9.5380) | Error 0.0100(0.0130) Steps 682(695.48) | Grad Norm 4.5373(4.3476) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 25.3611, Epoch Time 491.7610(482.7210), Bit/dim 3.6742(best: 3.6678), Xent 3.5851, Loss 5.4667, Error 0.4595(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2839 | Time 74.1172(74.8530) | Bit/dim 3.6219(3.6392) | Xent 0.0347(0.0416) | Loss 13.2837(9.6504) | Error 0.0101(0.0129) Steps 700(695.62) | Grad Norm 4.1465(4.3416) | Total Time 0.00(0.00)\n",
      "Iter 2840 | Time 76.7664(74.9104) | Bit/dim 3.6405(3.6392) | Xent 0.0386(0.0415) | Loss 9.0126(9.6313) | Error 0.0118(0.0129) Steps 712(696.11) | Grad Norm 6.7521(4.4139) | Total Time 0.00(0.00)\n",
      "Iter 2841 | Time 73.7607(74.8759) | Bit/dim 3.6368(3.6392) | Xent 0.0343(0.0412) | Loss 8.7966(9.6062) | Error 0.0114(0.0129) Steps 712(696.59) | Grad Norm 3.5277(4.3873) | Total Time 0.00(0.00)\n",
      "Iter 2842 | Time 76.1661(74.9146) | Bit/dim 3.6479(3.6394) | Xent 0.0349(0.0411) | Loss 8.8365(9.5831) | Error 0.0114(0.0128) Steps 700(696.69) | Grad Norm 5.0634(4.4076) | Total Time 0.00(0.00)\n",
      "Iter 2843 | Time 77.8474(75.0026) | Bit/dim 3.6345(3.6393) | Xent 0.0329(0.0408) | Loss 8.9274(9.5635) | Error 0.0109(0.0128) Steps 694(696.61) | Grad Norm 4.1595(4.4002) | Total Time 0.00(0.00)\n",
      "Iter 2844 | Time 71.0320(74.8835) | Bit/dim 3.6356(3.6392) | Xent 0.0494(0.0411) | Loss 8.7263(9.5384) | Error 0.0166(0.0129) Steps 694(696.53) | Grad Norm 8.9927(4.5379) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 24.8782, Epoch Time 493.0431(483.0306), Bit/dim 3.6726(best: 3.6678), Xent 3.5871, Loss 5.4662, Error 0.4581(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2845 | Time 71.6680(74.7870) | Bit/dim 3.6344(3.6390) | Xent 0.0372(0.0410) | Loss 13.3201(9.6518) | Error 0.0132(0.0129) Steps 682(696.09) | Grad Norm 6.6705(4.6019) | Total Time 0.00(0.00)\n",
      "Iter 2846 | Time 74.2032(74.7695) | Bit/dim 3.6360(3.6389) | Xent 0.0380(0.0409) | Loss 8.6866(9.6229) | Error 0.0114(0.0128) Steps 694(696.03) | Grad Norm 5.8851(4.6404) | Total Time 0.00(0.00)\n",
      "Iter 2847 | Time 75.6465(74.7958) | Bit/dim 3.6288(3.6386) | Xent 0.0397(0.0408) | Loss 8.7703(9.5973) | Error 0.0126(0.0128) Steps 688(695.79) | Grad Norm 8.0278(4.7420) | Total Time 0.00(0.00)\n",
      "Iter 2848 | Time 78.8591(74.9177) | Bit/dim 3.6373(3.6386) | Xent 0.0318(0.0406) | Loss 8.7382(9.5715) | Error 0.0100(0.0127) Steps 706(696.10) | Grad Norm 3.0617(4.6916) | Total Time 0.00(0.00)\n",
      "Iter 2849 | Time 74.9675(74.9192) | Bit/dim 3.6427(3.6387) | Xent 0.0601(0.0412) | Loss 8.8891(9.5510) | Error 0.0186(0.0129) Steps 682(695.67) | Grad Norm 10.9385(4.8790) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 73.9869(74.8912) | Bit/dim 3.6405(3.6388) | Xent 0.0825(0.0424) | Loss 8.8901(9.5312) | Error 0.0255(0.0133) Steps 694(695.62) | Grad Norm 15.5203(5.1983) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 25.4677, Epoch Time 493.5768(483.3470), Bit/dim 3.6754(best: 3.6678), Xent 3.6244, Loss 5.4876, Error 0.4624(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2851 | Time 76.0582(74.9263) | Bit/dim 3.6280(3.6384) | Xent 0.0697(0.0432) | Loss 13.6277(9.6541) | Error 0.0228(0.0136) Steps 664(694.67) | Grad Norm 11.4880(5.3870) | Total Time 0.00(0.00)\n",
      "Iter 2852 | Time 71.7161(74.8299) | Bit/dim 3.6439(3.6386) | Xent 0.0482(0.0434) | Loss 8.7050(9.6256) | Error 0.0148(0.0136) Steps 682(694.29) | Grad Norm 6.8178(5.4299) | Total Time 0.00(0.00)\n",
      "Iter 2853 | Time 73.3594(74.7858) | Bit/dim 3.6469(3.6389) | Xent 0.0468(0.0435) | Loss 8.9589(9.6056) | Error 0.0136(0.0136) Steps 700(694.47) | Grad Norm 5.7019(5.4380) | Total Time 0.00(0.00)\n",
      "Iter 2854 | Time 71.8584(74.6980) | Bit/dim 3.6382(3.6388) | Xent 0.0772(0.0445) | Loss 8.8705(9.5836) | Error 0.0239(0.0139) Steps 694(694.45) | Grad Norm 12.0733(5.6371) | Total Time 0.00(0.00)\n",
      "Iter 2855 | Time 69.9732(74.5563) | Bit/dim 3.6407(3.6389) | Xent 0.1122(0.0465) | Loss 9.0014(9.5661) | Error 0.0379(0.0146) Steps 670(693.72) | Grad Norm 16.3866(5.9596) | Total Time 0.00(0.00)\n",
      "Iter 2856 | Time 76.5252(74.6153) | Bit/dim 3.6454(3.6391) | Xent 0.1627(0.0500) | Loss 9.0579(9.5509) | Error 0.0520(0.0158) Steps 694(693.73) | Grad Norm 18.2124(6.3272) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 25.2665, Epoch Time 483.2009(483.3426), Bit/dim 3.6778(best: 3.6678), Xent 3.4289, Loss 5.3922, Error 0.4704(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2857 | Time 74.5528(74.6135) | Bit/dim 3.6586(3.6397) | Xent 0.1418(0.0527) | Loss 13.0209(9.6550) | Error 0.0464(0.0167) Steps 712(694.27) | Grad Norm 14.1919(6.5631) | Total Time 0.00(0.00)\n",
      "Iter 2858 | Time 76.5892(74.6727) | Bit/dim 3.6321(3.6394) | Xent 0.1078(0.0544) | Loss 8.8359(9.6304) | Error 0.0334(0.0172) Steps 676(693.73) | Grad Norm 19.0507(6.9377) | Total Time 0.00(0.00)\n",
      "Iter 2859 | Time 75.6391(74.7017) | Bit/dim 3.6684(3.6403) | Xent 0.1438(0.0571) | Loss 8.9430(9.6098) | Error 0.0447(0.0180) Steps 682(693.37) | Grad Norm 27.4634(7.5535) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 77.2046(74.7768) | Bit/dim 3.6456(3.6405) | Xent 0.0664(0.0574) | Loss 8.9982(9.5914) | Error 0.0215(0.0181) Steps 682(693.03) | Grad Norm 5.2694(7.4850) | Total Time 0.00(0.00)\n",
      "Iter 2861 | Time 76.0792(74.8159) | Bit/dim 3.6514(3.6408) | Xent 0.1479(0.0601) | Loss 9.0013(9.5737) | Error 0.0477(0.0190) Steps 700(693.24) | Grad Norm 22.1191(7.9240) | Total Time 0.00(0.00)\n",
      "Iter 2862 | Time 68.6849(74.6319) | Bit/dim 3.6399(3.6408) | Xent 0.0780(0.0606) | Loss 8.9857(9.5561) | Error 0.0249(0.0192) Steps 694(693.26) | Grad Norm 5.5771(7.8536) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 25.0373, Epoch Time 492.5414(483.6186), Bit/dim 3.6778(best: 3.6678), Xent 3.1610, Loss 5.2583, Error 0.4665(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2863 | Time 72.3586(74.5637) | Bit/dim 3.6499(3.6410) | Xent 0.1155(0.0623) | Loss 12.8363(9.6545) | Error 0.0376(0.0197) Steps 664(692.39) | Grad Norm 14.7973(8.0619) | Total Time 0.00(0.00)\n",
      "Iter 2864 | Time 73.4836(74.5313) | Bit/dim 3.6539(3.6414) | Xent 0.0862(0.0630) | Loss 8.9357(9.6329) | Error 0.0268(0.0199) Steps 688(692.26) | Grad Norm 6.9445(8.0284) | Total Time 0.00(0.00)\n",
      "Iter 2865 | Time 72.1842(74.4609) | Bit/dim 3.6526(3.6418) | Xent 0.0913(0.0638) | Loss 8.9739(9.6132) | Error 0.0302(0.0203) Steps 688(692.13) | Grad Norm 11.2359(8.1246) | Total Time 0.00(0.00)\n",
      "Iter 2866 | Time 75.8149(74.5015) | Bit/dim 3.6461(3.6419) | Xent 0.0714(0.0641) | Loss 8.8851(9.5913) | Error 0.0249(0.0204) Steps 670(691.46) | Grad Norm 7.0343(8.0919) | Total Time 0.00(0.00)\n",
      "Iter 2867 | Time 74.3067(74.4957) | Bit/dim 3.6431(3.6419) | Xent 0.0731(0.0643) | Loss 9.0125(9.5739) | Error 0.0239(0.0205) Steps 694(691.54) | Grad Norm 8.4734(8.1034) | Total Time 0.00(0.00)\n",
      "Iter 2868 | Time 80.4855(74.6754) | Bit/dim 3.6422(3.6419) | Xent 0.0684(0.0644) | Loss 8.9637(9.5556) | Error 0.0204(0.0205) Steps 730(692.69) | Grad Norm 8.1386(8.1044) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 25.1995, Epoch Time 491.6166(483.8585), Bit/dim 3.6718(best: 3.6678), Xent 3.3814, Loss 5.3625, Error 0.4633(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2869 | Time 71.4034(74.5772) | Bit/dim 3.6503(3.6422) | Xent 0.0590(0.0643) | Loss 13.4808(9.6734) | Error 0.0206(0.0205) Steps 700(692.91) | Grad Norm 7.0136(8.0717) | Total Time 0.00(0.00)\n",
      "Iter 2870 | Time 75.4570(74.6036) | Bit/dim 3.6386(3.6421) | Xent 0.0611(0.0642) | Loss 8.8948(9.6500) | Error 0.0210(0.0205) Steps 676(692.41) | Grad Norm 6.3814(8.0210) | Total Time 0.00(0.00)\n",
      "Iter 2871 | Time 75.1708(74.6206) | Bit/dim 3.6466(3.6422) | Xent 0.0575(0.0640) | Loss 8.8196(9.6251) | Error 0.0169(0.0204) Steps 712(692.99) | Grad Norm 6.2728(7.9685) | Total Time 0.00(0.00)\n",
      "Iter 2872 | Time 72.6324(74.5610) | Bit/dim 3.6499(3.6424) | Xent 0.0509(0.0636) | Loss 8.8656(9.6023) | Error 0.0156(0.0203) Steps 682(692.66) | Grad Norm 5.6459(7.8989) | Total Time 0.00(0.00)\n",
      "Iter 2873 | Time 73.7094(74.5354) | Bit/dim 3.6372(3.6423) | Xent 0.0592(0.0635) | Loss 8.9713(9.5834) | Error 0.0188(0.0202) Steps 712(693.24) | Grad Norm 5.8631(7.8378) | Total Time 0.00(0.00)\n",
      "Iter 2874 | Time 71.9399(74.4576) | Bit/dim 3.6444(3.6424) | Xent 0.0422(0.0628) | Loss 8.5968(9.5538) | Error 0.0132(0.0200) Steps 688(693.09) | Grad Norm 3.4174(7.7052) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 25.0774, Epoch Time 483.9391(483.8610), Bit/dim 3.6724(best: 3.6678), Xent 3.5282, Loss 5.4365, Error 0.4626(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2875 | Time 73.5750(74.4311) | Bit/dim 3.6364(3.6422) | Xent 0.0717(0.0631) | Loss 13.7553(9.6799) | Error 0.0238(0.0201) Steps 706(693.47) | Grad Norm 9.0139(7.7444) | Total Time 0.00(0.00)\n",
      "Iter 2876 | Time 75.9289(74.4760) | Bit/dim 3.6494(3.6424) | Xent 0.0450(0.0626) | Loss 8.7053(9.6506) | Error 0.0145(0.0199) Steps 682(693.13) | Grad Norm 4.7113(7.6534) | Total Time 0.00(0.00)\n",
      "Iter 2877 | Time 74.3362(74.4718) | Bit/dim 3.6486(3.6426) | Xent 0.0905(0.0634) | Loss 8.8445(9.6264) | Error 0.0309(0.0203) Steps 700(693.34) | Grad Norm 8.7076(7.6851) | Total Time 0.00(0.00)\n",
      "Iter 2878 | Time 69.6213(74.3263) | Bit/dim 3.6523(3.6429) | Xent 0.0618(0.0633) | Loss 8.8591(9.6034) | Error 0.0200(0.0203) Steps 682(693.00) | Grad Norm 6.3925(7.6463) | Total Time 0.00(0.00)\n",
      "Iter 2879 | Time 73.2053(74.2927) | Bit/dim 3.6439(3.6429) | Xent 0.0778(0.0638) | Loss 8.8922(9.5821) | Error 0.0232(0.0204) Steps 700(693.21) | Grad Norm 10.5155(7.7324) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 70.6331(74.1829) | Bit/dim 3.6535(3.6432) | Xent 0.0574(0.0636) | Loss 8.7776(9.5579) | Error 0.0190(0.0203) Steps 670(692.51) | Grad Norm 5.8085(7.6746) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 25.4893, Epoch Time 481.4922(483.7899), Bit/dim 3.6685(best: 3.6678), Xent 3.3607, Loss 5.3488, Error 0.4617(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2881 | Time 68.3082(74.0067) | Bit/dim 3.6335(3.6429) | Xent 0.0724(0.0638) | Loss 13.7860(9.6848) | Error 0.0221(0.0204) Steps 688(692.37) | Grad Norm 9.4766(7.7287) | Total Time 0.00(0.00)\n",
      "Iter 2882 | Time 71.4563(73.9302) | Bit/dim 3.6336(3.6427) | Xent 0.0420(0.0632) | Loss 8.6805(9.6547) | Error 0.0130(0.0201) Steps 682(692.06) | Grad Norm 4.8783(7.6432) | Total Time 0.00(0.00)\n",
      "Iter 2883 | Time 68.2330(73.7592) | Bit/dim 3.6462(3.6428) | Xent 0.0601(0.0631) | Loss 8.9313(9.6330) | Error 0.0201(0.0201) Steps 670(691.40) | Grad Norm 7.2542(7.6315) | Total Time 0.00(0.00)\n",
      "Iter 2884 | Time 73.4968(73.7514) | Bit/dim 3.6462(3.6429) | Xent 0.0530(0.0628) | Loss 8.8182(9.6085) | Error 0.0165(0.0200) Steps 682(691.12) | Grad Norm 4.7844(7.5461) | Total Time 0.00(0.00)\n",
      "Iter 2885 | Time 73.9705(73.7579) | Bit/dim 3.6442(3.6429) | Xent 0.0471(0.0623) | Loss 8.7149(9.5817) | Error 0.0151(0.0199) Steps 706(691.57) | Grad Norm 5.6133(7.4881) | Total Time 0.00(0.00)\n",
      "Iter 2886 | Time 71.7614(73.6980) | Bit/dim 3.6360(3.6427) | Xent 0.0512(0.0620) | Loss 8.8651(9.5602) | Error 0.0166(0.0198) Steps 682(691.28) | Grad Norm 4.2253(7.3902) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 24.8116, Epoch Time 470.0529(483.3778), Bit/dim 3.6702(best: 3.6678), Xent 3.3013, Loss 5.3208, Error 0.4529(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2887 | Time 73.1894(73.6828) | Bit/dim 3.6557(3.6431) | Xent 0.0453(0.0615) | Loss 13.7987(9.6874) | Error 0.0138(0.0196) Steps 694(691.36) | Grad Norm 6.1803(7.3539) | Total Time 0.00(0.00)\n",
      "Iter 2888 | Time 70.3904(73.5840) | Bit/dim 3.6443(3.6431) | Xent 0.0397(0.0608) | Loss 8.8079(9.6610) | Error 0.0126(0.0194) Steps 664(690.54) | Grad Norm 2.9529(7.2219) | Total Time 0.00(0.00)\n",
      "Iter 2889 | Time 74.6622(73.6164) | Bit/dim 3.6333(3.6428) | Xent 0.0392(0.0602) | Loss 8.8836(9.6377) | Error 0.0136(0.0192) Steps 712(691.18) | Grad Norm 5.2767(7.1636) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 72.4715(73.5820) | Bit/dim 3.6515(3.6431) | Xent 0.0364(0.0595) | Loss 8.8293(9.6134) | Error 0.0111(0.0190) Steps 694(691.27) | Grad Norm 3.3894(7.0503) | Total Time 0.00(0.00)\n",
      "Iter 2891 | Time 77.8533(73.7102) | Bit/dim 3.6408(3.6430) | Xent 0.0461(0.0591) | Loss 8.8354(9.5901) | Error 0.0144(0.0188) Steps 706(691.71) | Grad Norm 5.8836(7.0153) | Total Time 0.00(0.00)\n",
      "Iter 2892 | Time 74.8278(73.7437) | Bit/dim 3.6252(3.6425) | Xent 0.0400(0.0585) | Loss 8.6760(9.5626) | Error 0.0129(0.0187) Steps 706(692.14) | Grad Norm 2.7950(6.8887) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 24.9593, Epoch Time 486.9137(483.4839), Bit/dim 3.6671(best: 3.6678), Xent 3.4945, Loss 5.4144, Error 0.4582(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2893 | Time 75.8224(73.8060) | Bit/dim 3.6269(3.6420) | Xent 0.0340(0.0578) | Loss 13.3187(9.6753) | Error 0.0106(0.0184) Steps 706(692.55) | Grad Norm 3.5781(6.7894) | Total Time 0.00(0.00)\n",
      "Iter 2894 | Time 74.4823(73.8263) | Bit/dim 3.6360(3.6418) | Xent 0.0383(0.0572) | Loss 8.7424(9.6473) | Error 0.0116(0.0182) Steps 682(692.24) | Grad Norm 3.9630(6.7046) | Total Time 0.00(0.00)\n",
      "Iter 2895 | Time 72.4186(73.7841) | Bit/dim 3.6512(3.6421) | Xent 0.0319(0.0564) | Loss 8.9263(9.6257) | Error 0.0102(0.0180) Steps 682(691.93) | Grad Norm 3.5378(6.6096) | Total Time 0.00(0.00)\n",
      "Iter 2896 | Time 76.2733(73.8588) | Bit/dim 3.6319(3.6418) | Xent 0.0396(0.0559) | Loss 8.9217(9.6046) | Error 0.0118(0.0178) Steps 694(691.99) | Grad Norm 4.9253(6.5591) | Total Time 0.00(0.00)\n",
      "Iter 2897 | Time 73.6682(73.8531) | Bit/dim 3.6313(3.6415) | Xent 0.0376(0.0554) | Loss 8.6747(9.5767) | Error 0.0120(0.0176) Steps 700(692.23) | Grad Norm 3.5974(6.4702) | Total Time 0.00(0.00)\n",
      "Iter 2898 | Time 72.4863(73.8121) | Bit/dim 3.6380(3.6414) | Xent 0.0300(0.0546) | Loss 8.8706(9.5555) | Error 0.0095(0.0174) Steps 688(692.11) | Grad Norm 3.7877(6.3898) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 25.3040, Epoch Time 488.7573(483.6421), Bit/dim 3.6669(best: 3.6671), Xent 3.4648, Loss 5.3994, Error 0.4567(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2899 | Time 74.6634(73.8376) | Bit/dim 3.6420(3.6414) | Xent 0.0258(0.0537) | Loss 13.0675(9.6609) | Error 0.0079(0.0171) Steps 706(692.52) | Grad Norm 2.2953(6.2669) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 66.2873(73.6111) | Bit/dim 3.6427(3.6414) | Xent 0.0415(0.0534) | Loss 8.9806(9.6405) | Error 0.0131(0.0170) Steps 682(692.21) | Grad Norm 4.2688(6.2070) | Total Time 0.00(0.00)\n",
      "Iter 2901 | Time 75.2464(73.6601) | Bit/dim 3.6362(3.6413) | Xent 0.0328(0.0528) | Loss 8.9348(9.6193) | Error 0.0095(0.0168) Steps 706(692.62) | Grad Norm 2.5809(6.0982) | Total Time 0.00(0.00)\n",
      "Iter 2902 | Time 73.6038(73.6585) | Bit/dim 3.6384(3.6412) | Xent 0.0397(0.0524) | Loss 8.7011(9.5917) | Error 0.0106(0.0166) Steps 682(692.30) | Grad Norm 5.1981(6.0712) | Total Time 0.00(0.00)\n",
      "Iter 2903 | Time 75.4407(73.7119) | Bit/dim 3.6214(3.6406) | Xent 0.0389(0.0520) | Loss 8.9121(9.5714) | Error 0.0116(0.0164) Steps 682(691.99) | Grad Norm 4.1541(6.0137) | Total Time 0.00(0.00)\n",
      "Iter 2904 | Time 74.5175(73.7361) | Bit/dim 3.6373(3.6405) | Xent 0.0358(0.0515) | Loss 8.8415(9.5495) | Error 0.0105(0.0162) Steps 688(691.87) | Grad Norm 3.9640(5.9522) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 25.0713, Epoch Time 482.9088(483.6201), Bit/dim 3.6681(best: 3.6669), Xent 3.4914, Loss 5.4138, Error 0.4531(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2905 | Time 72.4174(73.6965) | Bit/dim 3.6375(3.6404) | Xent 0.0273(0.0508) | Loss 13.0336(9.6540) | Error 0.0099(0.0161) Steps 700(692.12) | Grad Norm 2.4631(5.8475) | Total Time 0.00(0.00)\n",
      "Iter 2906 | Time 72.3728(73.6568) | Bit/dim 3.6378(3.6403) | Xent 0.0362(0.0503) | Loss 8.7994(9.6283) | Error 0.0119(0.0159) Steps 712(692.71) | Grad Norm 4.1332(5.7961) | Total Time 0.00(0.00)\n",
      "Iter 2907 | Time 75.3355(73.7072) | Bit/dim 3.6508(3.6407) | Xent 0.0319(0.0498) | Loss 8.7872(9.6031) | Error 0.0100(0.0157) Steps 670(692.03) | Grad Norm 3.0197(5.7128) | Total Time 0.00(0.00)\n",
      "Iter 2908 | Time 70.3163(73.6055) | Bit/dim 3.6310(3.6404) | Xent 0.0367(0.0494) | Loss 8.8277(9.5799) | Error 0.0110(0.0156) Steps 694(692.09) | Grad Norm 4.4756(5.6757) | Total Time 0.00(0.00)\n",
      "Iter 2909 | Time 73.7372(73.6094) | Bit/dim 3.6278(3.6400) | Xent 0.0287(0.0488) | Loss 8.7349(9.5545) | Error 0.0078(0.0154) Steps 676(691.61) | Grad Norm 2.5449(5.5818) | Total Time 0.00(0.00)\n",
      "Iter 2910 | Time 72.1364(73.5652) | Bit/dim 3.6400(3.6400) | Xent 0.0389(0.0485) | Loss 8.6990(9.5288) | Error 0.0115(0.0153) Steps 682(691.32) | Grad Norm 4.1343(5.5383) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 25.2687, Epoch Time 480.2944(483.5203), Bit/dim 3.6672(best: 3.6669), Xent 3.6150, Loss 5.4747, Error 0.4566(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2911 | Time 70.2823(73.4667) | Bit/dim 3.6396(3.6400) | Xent 0.0299(0.0479) | Loss 13.5556(9.6496) | Error 0.0094(0.0151) Steps 700(691.58) | Grad Norm 3.1639(5.4671) | Total Time 0.00(0.00)\n",
      "Iter 2912 | Time 67.9706(73.3018) | Bit/dim 3.6333(3.6398) | Xent 0.0381(0.0476) | Loss 8.6457(9.6195) | Error 0.0120(0.0150) Steps 664(690.75) | Grad Norm 4.0328(5.4241) | Total Time 0.00(0.00)\n",
      "Iter 2913 | Time 78.2469(73.4502) | Bit/dim 3.6380(3.6397) | Xent 0.0318(0.0471) | Loss 8.7899(9.5946) | Error 0.0092(0.0148) Steps 688(690.67) | Grad Norm 2.9195(5.3489) | Total Time 0.00(0.00)\n",
      "Iter 2914 | Time 73.5661(73.4537) | Bit/dim 3.6479(3.6400) | Xent 0.0348(0.0468) | Loss 8.7329(9.5688) | Error 0.0111(0.0147) Steps 694(690.77) | Grad Norm 3.8216(5.3031) | Total Time 0.00(0.00)\n",
      "Iter 2915 | Time 75.5909(73.5178) | Bit/dim 3.6240(3.6395) | Xent 0.0366(0.0465) | Loss 8.5976(9.5396) | Error 0.0114(0.0146) Steps 682(690.51) | Grad Norm 3.7850(5.2576) | Total Time 0.00(0.00)\n",
      "Iter 2916 | Time 71.5363(73.4583) | Bit/dim 3.6258(3.6391) | Xent 0.0351(0.0461) | Loss 9.0286(9.5243) | Error 0.0105(0.0145) Steps 706(690.97) | Grad Norm 3.3311(5.1998) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 25.2375, Epoch Time 481.3283(483.4545), Bit/dim 3.6688(best: 3.6669), Xent 3.5568, Loss 5.4472, Error 0.4598(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2917 | Time 73.6263(73.4634) | Bit/dim 3.6358(3.6390) | Xent 0.0334(0.0457) | Loss 13.2971(9.6375) | Error 0.0111(0.0144) Steps 682(690.70) | Grad Norm 3.0752(5.1360) | Total Time 0.00(0.00)\n",
      "Iter 2918 | Time 67.7429(73.2918) | Bit/dim 3.6423(3.6391) | Xent 0.0275(0.0452) | Loss 8.8159(9.6129) | Error 0.0089(0.0142) Steps 676(690.26) | Grad Norm 3.3486(5.0824) | Total Time 0.00(0.00)\n",
      "Iter 2919 | Time 75.3467(73.3534) | Bit/dim 3.6336(3.6389) | Xent 0.0299(0.0447) | Loss 8.9180(9.5920) | Error 0.0091(0.0141) Steps 706(690.73) | Grad Norm 3.4721(5.0341) | Total Time 0.00(0.00)\n",
      "Iter 2920 | Time 75.5267(73.4186) | Bit/dim 3.6312(3.6387) | Xent 0.0332(0.0444) | Loss 8.9359(9.5723) | Error 0.0100(0.0139) Steps 712(691.37) | Grad Norm 3.7001(4.9941) | Total Time 0.00(0.00)\n",
      "Iter 2921 | Time 71.2326(73.3530) | Bit/dim 3.6431(3.6388) | Xent 0.0370(0.0442) | Loss 8.9092(9.5524) | Error 0.0124(0.0139) Steps 700(691.63) | Grad Norm 7.0214(5.0549) | Total Time 0.00(0.00)\n",
      "Iter 2922 | Time 74.4659(73.3864) | Bit/dim 3.6298(3.6385) | Xent 0.0351(0.0439) | Loss 8.6945(9.5267) | Error 0.0108(0.0138) Steps 700(691.88) | Grad Norm 6.4744(5.0975) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 25.0818, Epoch Time 480.4607(483.3647), Bit/dim 3.6643(best: 3.6669), Xent 3.6832, Loss 5.5058, Error 0.4578(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2923 | Time 72.5080(73.3601) | Bit/dim 3.6372(3.6385) | Xent 0.0319(0.0435) | Loss 13.6044(9.6490) | Error 0.0100(0.0137) Steps 706(692.31) | Grad Norm 3.4147(5.0470) | Total Time 0.00(0.00)\n",
      "Iter 2924 | Time 73.7481(73.3717) | Bit/dim 3.6374(3.6385) | Xent 0.0313(0.0432) | Loss 8.7139(9.6210) | Error 0.0096(0.0136) Steps 682(692.00) | Grad Norm 5.9510(5.0741) | Total Time 0.00(0.00)\n",
      "Iter 2925 | Time 73.8639(73.3865) | Bit/dim 3.6282(3.6382) | Xent 0.0241(0.0426) | Loss 8.8745(9.5986) | Error 0.0075(0.0134) Steps 694(692.06) | Grad Norm 2.1767(4.9872) | Total Time 0.00(0.00)\n",
      "Iter 2926 | Time 74.4518(73.4184) | Bit/dim 3.6416(3.6383) | Xent 0.0339(0.0423) | Loss 8.7429(9.5729) | Error 0.0100(0.0133) Steps 706(692.47) | Grad Norm 5.1341(4.9916) | Total Time 0.00(0.00)\n",
      "Iter 2927 | Time 68.7671(73.2789) | Bit/dim 3.6341(3.6381) | Xent 0.0335(0.0421) | Loss 8.6541(9.5453) | Error 0.0105(0.0132) Steps 670(691.80) | Grad Norm 3.6089(4.9501) | Total Time 0.00(0.00)\n",
      "Iter 2928 | Time 71.8369(73.2356) | Bit/dim 3.6256(3.6378) | Xent 0.0294(0.0417) | Loss 8.8056(9.5231) | Error 0.0096(0.0131) Steps 694(691.87) | Grad Norm 3.1580(4.8964) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 25.4854, Epoch Time 478.1274(483.2076), Bit/dim 3.6708(best: 3.6643), Xent 3.7415, Loss 5.5415, Error 0.4613(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2929 | Time 72.2643(73.2065) | Bit/dim 3.6354(3.6377) | Xent 0.0349(0.0415) | Loss 13.8520(9.6530) | Error 0.0098(0.0130) Steps 700(692.11) | Grad Norm 3.9592(4.8683) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 70.2429(73.1176) | Bit/dim 3.6353(3.6376) | Xent 0.0259(0.0410) | Loss 8.9044(9.6306) | Error 0.0082(0.0128) Steps 688(691.99) | Grad Norm 2.9436(4.8105) | Total Time 0.00(0.00)\n",
      "Iter 2931 | Time 77.0568(73.2358) | Bit/dim 3.6442(3.6378) | Xent 0.0386(0.0409) | Loss 8.6896(9.6023) | Error 0.0112(0.0128) Steps 676(691.51) | Grad Norm 3.6937(4.7770) | Total Time 0.00(0.00)\n",
      "Iter 2932 | Time 70.2420(73.1459) | Bit/dim 3.6204(3.6373) | Xent 0.0334(0.0407) | Loss 8.7992(9.5782) | Error 0.0104(0.0127) Steps 682(691.22) | Grad Norm 2.8549(4.7193) | Total Time 0.00(0.00)\n",
      "Iter 2933 | Time 69.7898(73.0453) | Bit/dim 3.6329(3.6372) | Xent 0.0321(0.0405) | Loss 8.6290(9.5498) | Error 0.0088(0.0126) Steps 676(690.77) | Grad Norm 2.8751(4.6640) | Total Time 0.00(0.00)\n",
      "Iter 2934 | Time 73.8761(73.0702) | Bit/dim 3.6359(3.6371) | Xent 0.0324(0.0402) | Loss 8.8070(9.5275) | Error 0.0101(0.0125) Steps 700(691.04) | Grad Norm 3.9150(4.6415) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0489 | Time 25.4826, Epoch Time 477.1895(483.0271), Bit/dim 3.6671(best: 3.6643), Xent 3.6707, Loss 5.5024, Error 0.4570(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2935 | Time 71.0424(73.0094) | Bit/dim 3.6302(3.6369) | Xent 0.0281(0.0399) | Loss 13.9397(9.6598) | Error 0.0082(0.0124) Steps 700(691.31) | Grad Norm 2.2425(4.5696) | Total Time 0.00(0.00)\n",
      "Iter 2936 | Time 74.5375(73.0552) | Bit/dim 3.6287(3.6367) | Xent 0.0331(0.0396) | Loss 8.8808(9.6365) | Error 0.0109(0.0124) Steps 652(690.13) | Grad Norm 4.6719(4.5726) | Total Time 0.00(0.00)\n",
      "Iter 2937 | Time 71.8676(73.0196) | Bit/dim 3.6477(3.6370) | Xent 0.0255(0.0392) | Loss 8.7165(9.6089) | Error 0.0069(0.0122) Steps 682(689.89) | Grad Norm 2.4384(4.5086) | Total Time 0.00(0.00)\n",
      "Iter 2938 | Time 72.0858(72.9916) | Bit/dim 3.6402(3.6371) | Xent 0.0375(0.0392) | Loss 8.8287(9.5855) | Error 0.0118(0.0122) Steps 652(688.75) | Grad Norm 4.8381(4.5185) | Total Time 0.00(0.00)\n",
      "Iter 2939 | Time 76.1564(73.0865) | Bit/dim 3.6303(3.6369) | Xent 0.0319(0.0390) | Loss 8.6523(9.5575) | Error 0.0090(0.0121) Steps 670(688.19) | Grad Norm 2.3511(4.4535) | Total Time 0.00(0.00)\n",
      "Iter 2940 | Time 74.1954(73.1198) | Bit/dim 3.6265(3.6366) | Xent 0.0374(0.0389) | Loss 8.8189(9.5353) | Error 0.0110(0.0121) Steps 676(687.82) | Grad Norm 4.7840(4.4634) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0490 | Time 25.1020, Epoch Time 483.0172(483.0268), Bit/dim 3.6656(best: 3.6643), Xent 3.6115, Loss 5.4713, Error 0.4585(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2941 | Time 69.0850(72.9987) | Bit/dim 3.6348(3.6365) | Xent 0.0235(0.0384) | Loss 13.3628(9.6501) | Error 0.0066(0.0119) Steps 700(688.19) | Grad Norm 2.2223(4.3962) | Total Time 0.00(0.00)\n",
      "Iter 2942 | Time 72.1844(72.9743) | Bit/dim 3.6277(3.6363) | Xent 0.0320(0.0383) | Loss 8.8105(9.6249) | Error 0.0094(0.0118) Steps 694(688.36) | Grad Norm 4.9879(4.4139) | Total Time 0.00(0.00)\n",
      "Iter 2943 | Time 71.1811(72.9205) | Bit/dim 3.6257(3.6360) | Xent 0.0231(0.0378) | Loss 8.6178(9.5947) | Error 0.0068(0.0117) Steps 694(688.53) | Grad Norm 2.3832(4.3530) | Total Time 0.00(0.00)\n",
      "Iter 2944 | Time 70.9134(72.8603) | Bit/dim 3.6395(3.6361) | Xent 0.0328(0.0377) | Loss 8.7427(9.5692) | Error 0.0095(0.0116) Steps 706(689.06) | Grad Norm 4.5372(4.3585) | Total Time 0.00(0.00)\n",
      "Iter 2945 | Time 73.3757(72.8758) | Bit/dim 3.6102(3.6353) | Xent 0.0261(0.0373) | Loss 8.6958(9.5430) | Error 0.0080(0.0115) Steps 682(688.84) | Grad Norm 2.7424(4.3100) | Total Time 0.00(0.00)\n",
      "Iter 2946 | Time 71.1059(72.8227) | Bit/dim 3.6417(3.6355) | Xent 0.0337(0.0372) | Loss 8.5606(9.5135) | Error 0.0106(0.0115) Steps 700(689.18) | Grad Norm 4.1364(4.3048) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0491 | Time 24.6426, Epoch Time 470.8383(482.6611), Bit/dim 3.6658(best: 3.6643), Xent 3.6707, Loss 5.5011, Error 0.4598(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2947 | Time 78.3180(72.9875) | Bit/dim 3.6367(3.6355) | Xent 0.0319(0.0370) | Loss 13.4123(9.6305) | Error 0.0088(0.0114) Steps 724(690.22) | Grad Norm 2.3922(4.2475) | Total Time 0.00(0.00)\n",
      "Iter 2948 | Time 72.6490(72.9774) | Bit/dim 3.6367(3.6355) | Xent 0.0339(0.0369) | Loss 8.8902(9.6083) | Error 0.0109(0.0114) Steps 670(689.62) | Grad Norm 4.7768(4.2633) | Total Time 0.00(0.00)\n",
      "Iter 2949 | Time 72.0323(72.9490) | Bit/dim 3.6315(3.6354) | Xent 0.0249(0.0366) | Loss 8.6603(9.5798) | Error 0.0079(0.0113) Steps 688(689.57) | Grad Norm 3.4605(4.2392) | Total Time 0.00(0.00)\n",
      "Iter 2950 | Time 74.3323(72.9905) | Bit/dim 3.6279(3.6352) | Xent 0.0401(0.0367) | Loss 8.7789(9.5558) | Error 0.0136(0.0113) Steps 694(689.70) | Grad Norm 5.7848(4.2856) | Total Time 0.00(0.00)\n",
      "Iter 2951 | Time 72.1266(72.9646) | Bit/dim 3.6251(3.6349) | Xent 0.0490(0.0371) | Loss 8.8228(9.5338) | Error 0.0152(0.0115) Steps 682(689.47) | Grad Norm 7.2301(4.3739) | Total Time 0.00(0.00)\n",
      "Iter 2952 | Time 67.0469(72.7871) | Bit/dim 3.6407(3.6351) | Xent 0.0346(0.0370) | Loss 8.8432(9.5131) | Error 0.0109(0.0114) Steps 688(689.43) | Grad Norm 4.7009(4.3838) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0492 | Time 25.0919, Epoch Time 479.7761(482.5746), Bit/dim 3.6657(best: 3.6643), Xent 3.7244, Loss 5.5279, Error 0.4629(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2953 | Time 76.8542(72.9091) | Bit/dim 3.6255(3.6348) | Xent 0.0486(0.0373) | Loss 13.8257(9.6425) | Error 0.0140(0.0115) Steps 682(689.20) | Grad Norm 4.8076(4.3965) | Total Time 0.00(0.00)\n",
      "Iter 2954 | Time 73.0395(72.9130) | Bit/dim 3.6440(3.6351) | Xent 0.0413(0.0375) | Loss 8.9256(9.6210) | Error 0.0129(0.0116) Steps 688(689.17) | Grad Norm 4.8815(4.4110) | Total Time 0.00(0.00)\n",
      "Iter 2955 | Time 72.2397(72.8928) | Bit/dim 3.6271(3.6348) | Xent 0.0479(0.0378) | Loss 8.8056(9.5965) | Error 0.0129(0.0116) Steps 682(688.95) | Grad Norm 3.6974(4.3896) | Total Time 0.00(0.00)\n",
      "Iter 2956 | Time 72.5833(72.8835) | Bit/dim 3.6255(3.6345) | Xent 0.0309(0.0376) | Loss 8.7462(9.5710) | Error 0.0122(0.0116) Steps 670(688.38) | Grad Norm 2.8631(4.3438) | Total Time 0.00(0.00)\n",
      "Iter 2957 | Time 75.1271(72.9508) | Bit/dim 3.6309(3.6344) | Xent 0.0429(0.0377) | Loss 8.3605(9.5347) | Error 0.0136(0.0117) Steps 700(688.73) | Grad Norm 5.8866(4.3901) | Total Time 0.00(0.00)\n",
      "Iter 2958 | Time 74.3406(72.9925) | Bit/dim 3.6386(3.6346) | Xent 0.0360(0.0377) | Loss 8.9784(9.5180) | Error 0.0111(0.0117) Steps 658(687.81) | Grad Norm 4.2947(4.3872) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0493 | Time 24.8393, Epoch Time 487.3976(482.7192), Bit/dim 3.6653(best: 3.6643), Xent 3.5954, Loss 5.4631, Error 0.4577(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2959 | Time 74.2085(73.0290) | Bit/dim 3.6300(3.6344) | Xent 0.0284(0.0374) | Loss 13.4530(9.6360) | Error 0.0081(0.0115) Steps 700(688.18) | Grad Norm 2.5789(4.3330) | Total Time 0.00(0.00)\n",
      "Iter 2960 | Time 72.0556(72.9998) | Bit/dim 3.6327(3.6344) | Xent 0.0276(0.0371) | Loss 8.6338(9.6060) | Error 0.0079(0.0114) Steps 676(687.81) | Grad Norm 3.2197(4.2996) | Total Time 0.00(0.00)\n",
      "Iter 2961 | Time 72.1445(72.9741) | Bit/dim 3.6345(3.6344) | Xent 0.0350(0.0370) | Loss 8.8673(9.5838) | Error 0.0114(0.0114) Steps 688(687.82) | Grad Norm 3.2586(4.2684) | Total Time 0.00(0.00)\n",
      "Iter 2962 | Time 77.9398(73.1231) | Bit/dim 3.6394(3.6345) | Xent 0.0348(0.0370) | Loss 8.8474(9.5617) | Error 0.0092(0.0114) Steps 682(687.64) | Grad Norm 3.6120(4.2487) | Total Time 0.00(0.00)\n",
      "Iter 2963 | Time 71.6773(73.0797) | Bit/dim 3.6274(3.6343) | Xent 0.0317(0.0368) | Loss 8.8573(9.5406) | Error 0.0080(0.0113) Steps 688(687.65) | Grad Norm 3.1088(4.2145) | Total Time 0.00(0.00)\n",
      "Iter 2964 | Time 75.0020(73.1374) | Bit/dim 3.6352(3.6343) | Xent 0.0327(0.0367) | Loss 8.7092(9.5156) | Error 0.0089(0.0112) Steps 694(687.84) | Grad Norm 3.6683(4.1981) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0494 | Time 25.3940, Epoch Time 487.5209(482.8633), Bit/dim 3.6625(best: 3.6643), Xent 3.7272, Loss 5.5261, Error 0.4613(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2965 | Time 74.1753(73.1685) | Bit/dim 3.6394(3.6345) | Xent 0.0314(0.0365) | Loss 13.1934(9.6260) | Error 0.0096(0.0112) Steps 694(688.03) | Grad Norm 2.7167(4.1536) | Total Time 0.00(0.00)\n",
      "Iter 2966 | Time 69.0222(73.0441) | Bit/dim 3.6327(3.6344) | Xent 0.0332(0.0364) | Loss 8.7543(9.5998) | Error 0.0098(0.0111) Steps 682(687.85) | Grad Norm 3.3608(4.1299) | Total Time 0.00(0.00)\n",
      "Iter 2967 | Time 76.1984(73.1388) | Bit/dim 3.6182(3.6339) | Xent 0.0294(0.0362) | Loss 8.6433(9.5711) | Error 0.0091(0.0110) Steps 700(688.21) | Grad Norm 2.4582(4.0797) | Total Time 0.00(0.00)\n",
      "Iter 2968 | Time 69.2488(73.0221) | Bit/dim 3.6341(3.6340) | Xent 0.0265(0.0359) | Loss 8.7073(9.5452) | Error 0.0079(0.0110) Steps 694(688.39) | Grad Norm 2.9688(4.0464) | Total Time 0.00(0.00)\n",
      "Iter 2969 | Time 76.1722(73.1166) | Bit/dim 3.6355(3.6340) | Xent 0.0317(0.0358) | Loss 8.8341(9.5239) | Error 0.0096(0.0109) Steps 670(687.83) | Grad Norm 3.5814(4.0324) | Total Time 0.00(0.00)\n",
      "Iter 2970 | Time 76.8471(73.2285) | Bit/dim 3.6310(3.6339) | Xent 0.0260(0.0355) | Loss 8.8528(9.5037) | Error 0.0085(0.0108) Steps 682(687.66) | Grad Norm 2.8813(3.9979) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0495 | Time 25.1845, Epoch Time 484.8090(482.9217), Bit/dim 3.6675(best: 3.6625), Xent 3.7918, Loss 5.5634, Error 0.4611(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2971 | Time 74.4979(73.2666) | Bit/dim 3.6353(3.6340) | Xent 0.0386(0.0356) | Loss 13.3299(9.6185) | Error 0.0112(0.0109) Steps 700(688.03) | Grad Norm 5.8690(4.0540) | Total Time 0.00(0.00)\n",
      "Iter 2972 | Time 69.8233(73.1633) | Bit/dim 3.6272(3.6338) | Xent 0.0292(0.0354) | Loss 8.9053(9.5971) | Error 0.0090(0.0108) Steps 682(687.85) | Grad Norm 3.6658(4.0424) | Total Time 0.00(0.00)\n",
      "Iter 2973 | Time 70.4416(73.0816) | Bit/dim 3.6285(3.6336) | Xent 0.0326(0.0353) | Loss 8.7592(9.5720) | Error 0.0086(0.0107) Steps 676(687.49) | Grad Norm 3.6086(4.0294) | Total Time 0.00(0.00)\n",
      "Iter 2974 | Time 70.2407(72.9964) | Bit/dim 3.6291(3.6335) | Xent 0.0300(0.0352) | Loss 8.8200(9.5494) | Error 0.0096(0.0107) Steps 676(687.15) | Grad Norm 3.0033(3.9986) | Total Time 0.00(0.00)\n",
      "Iter 2975 | Time 74.0253(73.0273) | Bit/dim 3.6421(3.6337) | Xent 0.0283(0.0350) | Loss 8.7821(9.5264) | Error 0.0090(0.0106) Steps 700(687.53) | Grad Norm 2.9040(3.9658) | Total Time 0.00(0.00)\n",
      "Iter 2976 | Time 77.7447(73.1688) | Bit/dim 3.6240(3.6334) | Xent 0.0318(0.0349) | Loss 8.8105(9.5049) | Error 0.0096(0.0106) Steps 712(688.27) | Grad Norm 3.9447(3.9651) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0496 | Time 24.9793, Epoch Time 480.2689(482.8421), Bit/dim 3.6674(best: 3.6625), Xent 3.7152, Loss 5.5250, Error 0.4584(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2977 | Time 76.4969(73.2686) | Bit/dim 3.6431(3.6337) | Xent 0.0345(0.0349) | Loss 13.6882(9.6304) | Error 0.0111(0.0106) Steps 682(688.08) | Grad Norm 4.4537(3.9798) | Total Time 0.00(0.00)\n",
      "Iter 2978 | Time 73.8964(73.2875) | Bit/dim 3.6309(3.6336) | Xent 0.0280(0.0346) | Loss 8.7510(9.6041) | Error 0.0091(0.0106) Steps 694(688.26) | Grad Norm 3.0887(3.9530) | Total Time 0.00(0.00)\n",
      "Iter 2979 | Time 70.9539(73.2175) | Bit/dim 3.6253(3.6334) | Xent 0.0267(0.0344) | Loss 8.7931(9.5797) | Error 0.0090(0.0105) Steps 682(688.07) | Grad Norm 1.9840(3.8940) | Total Time 0.00(0.00)\n",
      "Iter 2980 | Time 69.4626(73.1048) | Bit/dim 3.6159(3.6329) | Xent 0.0298(0.0343) | Loss 8.7856(9.5559) | Error 0.0089(0.0105) Steps 694(688.25) | Grad Norm 2.3909(3.8489) | Total Time 0.00(0.00)\n",
      "Iter 2981 | Time 77.4442(73.2350) | Bit/dim 3.6326(3.6329) | Xent 0.0338(0.0343) | Loss 8.8734(9.5354) | Error 0.0092(0.0105) Steps 688(688.24) | Grad Norm 3.2558(3.8311) | Total Time 0.00(0.00)\n",
      "Iter 2982 | Time 72.8243(73.2227) | Bit/dim 3.6283(3.6327) | Xent 0.0378(0.0344) | Loss 8.8400(9.5146) | Error 0.0109(0.0105) Steps 712(688.95) | Grad Norm 5.4524(3.8797) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0497 | Time 25.4650, Epoch Time 484.7047(482.8980), Bit/dim 3.6663(best: 3.6625), Xent 3.7644, Loss 5.5485, Error 0.4598(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2983 | Time 68.3270(73.0758) | Bit/dim 3.6291(3.6326) | Xent 0.0340(0.0344) | Loss 13.1086(9.6224) | Error 0.0110(0.0105) Steps 664(688.20) | Grad Norm 4.2546(3.8910) | Total Time 0.00(0.00)\n",
      "Iter 2984 | Time 75.4622(73.1474) | Bit/dim 3.6238(3.6323) | Xent 0.0268(0.0341) | Loss 8.7563(9.5964) | Error 0.0094(0.0104) Steps 694(688.38) | Grad Norm 3.0006(3.8643) | Total Time 0.00(0.00)\n",
      "Iter 2985 | Time 72.7427(73.1353) | Bit/dim 3.6385(3.6325) | Xent 0.0282(0.0339) | Loss 8.8743(9.5747) | Error 0.0086(0.0104) Steps 694(688.55) | Grad Norm 4.1319(3.8723) | Total Time 0.00(0.00)\n",
      "Iter 2986 | Time 74.3920(73.1730) | Bit/dim 3.6320(3.6325) | Xent 0.0293(0.0338) | Loss 8.8028(9.5516) | Error 0.0092(0.0104) Steps 694(688.71) | Grad Norm 2.5072(3.8313) | Total Time 0.00(0.00)\n",
      "Iter 2987 | Time 75.1335(73.2318) | Bit/dim 3.6329(3.6325) | Xent 0.0312(0.0337) | Loss 8.9396(9.5332) | Error 0.0101(0.0104) Steps 724(689.77) | Grad Norm 4.6548(3.8560) | Total Time 0.00(0.00)\n",
      "Iter 2988 | Time 70.3579(73.1456) | Bit/dim 3.6334(3.6326) | Xent 0.0306(0.0336) | Loss 8.7981(9.5112) | Error 0.0100(0.0103) Steps 694(689.90) | Grad Norm 3.0961(3.8332) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0498 | Time 25.3023, Epoch Time 480.4334(482.8240), Bit/dim 3.6676(best: 3.6625), Xent 3.6788, Loss 5.5070, Error 0.4546(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2989 | Time 72.7059(73.1324) | Bit/dim 3.6290(3.6324) | Xent 0.0284(0.0335) | Loss 13.2166(9.6223) | Error 0.0082(0.0103) Steps 676(689.48) | Grad Norm 3.3367(3.8183) | Total Time 0.00(0.00)\n",
      "Iter 2990 | Time 73.3523(73.1390) | Bit/dim 3.6341(3.6325) | Xent 0.0333(0.0335) | Loss 8.8144(9.5981) | Error 0.0098(0.0103) Steps 676(689.07) | Grad Norm 3.1062(3.7970) | Total Time 0.00(0.00)\n",
      "Iter 2991 | Time 71.3018(73.0838) | Bit/dim 3.6234(3.6322) | Xent 0.0345(0.0335) | Loss 8.8635(9.5761) | Error 0.0101(0.0103) Steps 694(689.22) | Grad Norm 3.6543(3.7927) | Total Time 0.00(0.00)\n",
      "Iter 2992 | Time 75.1938(73.1471) | Bit/dim 3.6272(3.6321) | Xent 0.0395(0.0337) | Loss 8.8250(9.5535) | Error 0.0109(0.0103) Steps 712(689.91) | Grad Norm 4.4221(3.8116) | Total Time 0.00(0.00)\n",
      "Iter 2993 | Time 76.4204(73.2453) | Bit/dim 3.6216(3.6318) | Xent 0.0281(0.0335) | Loss 8.7831(9.5304) | Error 0.0091(0.0102) Steps 694(690.03) | Grad Norm 3.6563(3.8069) | Total Time 0.00(0.00)\n",
      "Iter 2994 | Time 68.7771(73.1113) | Bit/dim 3.6421(3.6321) | Xent 0.0350(0.0336) | Loss 8.7329(9.5065) | Error 0.0118(0.0103) Steps 688(689.97) | Grad Norm 4.7997(3.8367) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0499 | Time 25.8020, Epoch Time 481.9420(482.7976), Bit/dim 3.6637(best: 3.6625), Xent 3.6775, Loss 5.5025, Error 0.4605(best: 0.3949)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2995 | Time 70.3053(73.0271) | Bit/dim 3.6264(3.6319) | Xent 0.0291(0.0334) | Loss 12.9933(9.6111) | Error 0.0086(0.0102) Steps 670(689.37) | Grad Norm 2.5422(3.7979) | Total Time 0.00(0.00)\n",
      "Iter 2996 | Time 80.5608(73.2531) | Bit/dim 3.6280(3.6318) | Xent 0.0341(0.0334) | Loss 8.6933(9.5836) | Error 0.0092(0.0102) Steps 742(690.95) | Grad Norm 2.7795(3.7673) | Total Time 0.00(0.00)\n",
      "Iter 2997 | Time 72.9637(73.2444) | Bit/dim 3.6337(3.6318) | Xent 0.0347(0.0335) | Loss 8.8190(9.5606) | Error 0.0109(0.0102) Steps 712(691.58) | Grad Norm 3.3557(3.7550) | Total Time 0.00(0.00)\n",
      "Iter 2998 | Time 78.0075(73.3873) | Bit/dim 3.6400(3.6321) | Xent 0.0344(0.0335) | Loss 8.7875(9.5374) | Error 0.0108(0.0102) Steps 694(691.65) | Grad Norm 2.8262(3.7271) | Total Time 0.00(0.00)\n",
      "Iter 2999 | Time 72.3157(73.3552) | Bit/dim 3.6316(3.6321) | Xent 0.0295(0.0334) | Loss 8.7416(9.5136) | Error 0.0082(0.0102) Steps 688(691.54) | Grad Norm 2.3104(3.6846) | Total Time 0.00(0.00)\n",
      "Iter 3000 | Time 70.7686(73.2776) | Bit/dim 3.6277(3.6319) | Xent 0.0320(0.0334) | Loss 8.8347(9.4932) | Error 0.0096(0.0102) Steps 694(691.62) | Grad Norm 2.8598(3.6599) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0500 | Time 25.4368, Epoch Time 489.2493(482.9911), Bit/dim 3.6644(best: 3.6625), Xent 3.6795, Loss 5.5041, Error 0.4605(best: 0.3949)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         2547188718 function calls (2505080592 primitive calls) in 178682.461 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "     2280 119740.703   52.518 119740.703   52.518 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
       "   648347 48718.354    0.075 48718.354    0.075 {method 'acquire' of '_thread.lock' objects}\n",
       " 22040000 1094.169    0.000 1856.931    0.000 train_cnf_disentangle_rl_multiscale.py:307(add_noise)\n",
       " 22040380  696.047    0.000  696.047    0.000 {method 'tobytes' of 'numpy.ndarray' objects}\n",
       " 22040200  613.670    0.000  613.670    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
       " 22040000  585.137    0.000 2666.724    0.000 functional.py:32(to_tensor)\n",
       "   671580  479.059    0.001  479.059    0.001 {method '_write_file' of 'torch._C.CudaFloatStorageBase' objects}\n",
       " 22040000  437.917    0.000  437.917    0.000 {method 'div' of 'torch._C._TensorBase' objects}\n",
       " 22040000  300.631    0.000  300.631    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
       " 22040760  293.785    0.000 2331.087    0.000 Image.py:2457(fromarray)\n",
       " 22040000  274.944    0.000  274.944    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
       "421644123/421472995  245.476    0.000  246.985    0.000 {built-in method builtins.isinstance}\n",
       " 22040000  234.071    0.000 7842.991    0.000 cifar.py:103(__getitem__)\n",
       "     3040  228.353    0.075  228.353    0.075 {built-in method stack}\n",
       " 40606586  202.945    0.000  298.799    0.000 module.py:537(__setattr__)\n",
       " 22040000  192.263    0.000  579.977    0.000 Image.py:711(tobytes)\n",
       " 22040000  181.650    0.000 5194.343    0.000 transforms.py:47(__call__)\n",
       " 44080000  159.288    0.000  159.288    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}\n",
       " 23642460  153.468    0.000  153.468    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
       " 22040760  144.333    0.000  556.087    0.000 Image.py:2322(new)\n",
       " 66122280  124.096    0.000  196.253    0.000 Image.py:2304(_check_size)\n",
       " 22040760  113.287    0.000  183.990    0.000 Image.py:430(_getdecoder)\n",
       "222406103/222381543  112.700    0.000  112.732    0.000 {built-in method builtins.len}\n",
       " 22040760  107.362    0.000 1125.875    0.000 Image.py:2353(frombytes)\n",
       " 22040760  107.242    0.000  107.242    0.000 {built-in method PIL._imaging.fill}\n",
       "75435445/75435436  107.023    0.000  107.113    0.000 {built-in method builtins.hasattr}\n",
       " 31163780  106.393    0.000  171.267    0.000 Image.py:553(_new)\n",
       " 22041153  106.308    0.000  106.308    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
       " 22040760  105.142    0.000  384.083    0.000 Image.py:779(frombytes)\n",
       "     3420   83.544    0.024  544.133    0.159 replicate.py:5(replicate)\n",
       " 22040760   83.257    0.000  143.447    0.000 Image.py:451(_getencoder)\n",
       " 22040000   82.130    0.000  153.780    0.000 functional.py:172(resize)\n",
       " 22040000   81.045    0.000   81.045    0.000 {method 'resize_as_' of 'torch._C._TensorBase' objects}\n",
       " 22040760   79.243    0.000 1296.321    0.000 Image.py:2396(frombuffer)\n",
       " 53204540   78.702    0.000  170.450    0.000 Image.py:601(__del__)\n",
       " 53204540   77.795    0.000   77.795    0.000 Image.py:529(__init__)\n",
       "     4560   71.975    0.016   71.975    0.016 {method 'pin_memory' of 'torch._C._TensorBase' objects}\n",
       "143897983   69.652    0.000   69.652    0.000 {method 'get' of 'dict' objects}\n",
       " 22040870   68.069    0.000   68.069    0.000 {method 'new' of 'torch._C._TensorBase' objects}\n",
       "   219260   61.447    0.000   61.447    0.000 {built-in method torch._C._gather}\n",
       " 22040000   61.206    0.000   61.206    0.000 {built-in method from_buffer}\n",
       " 53202640   60.389    0.000   86.256    0.000 functional.py:17(_is_pil_image)\n",
       "     1539   55.408    0.036   55.409    0.036 {built-in method io.open}\n",
       " 31164540   53.291    0.000   75.563    0.000 Image.py:809(load)\n",
       "     3040   53.006    0.017 7895.998    2.597 dataloader.py:615(<listcomp>)\n",
       " 22040760   52.266    0.000   52.266    0.000 {method 'decode' of 'ImagingDecoder' objects}\n",
       "     6840   51.254    0.007   51.254    0.007 {built-in method torch._C._broadcast_coalesced}\n",
       "    93100   51.104    0.001   51.104    0.001 {method 'sort' of 'numpy.ndarray' objects}\n",
       "44043636/4771247   50.269    0.000   56.260    0.000 module.py:938(named_modules)\n",
       " 88163420   46.112    0.000   46.112    0.000 Image.py:549(size)\n",
       "    93100   45.623    0.000  154.714    0.002 summary.py:150(make_histogram)\n",
       " 44803229   45.508    0.000   45.508    0.000 {built-in method builtins.getattr}\n",
       " 22040000   43.615    0.000 2710.339    0.000 transforms.py:68(__call__)\n",
       "        1   39.630   39.630 178682.447 178682.447 train_cnf_disentangle_rl_multiscale.py:1(<module>)\n",
       " 22040000   39.502    0.000  193.282    0.000 transforms.py:167(__call__)\n",
       " 18240000   38.998    0.000  218.245    0.000 transforms.py:439(__call__)\n",
       "    16673   37.690    0.002   37.706    0.002 {method 'to' of 'torch._C._TensorBase' objects}\n",
       " 22040760   36.658    0.000   36.658    0.000 {built-in method PIL._imaging.raw_decoder}\n",
       "     3800   36.401    0.010 8311.320    2.187 dataloader.py:612(__next__)\n",
       " 17772948   35.802    0.000   63.762    0.000 serialization.py:234(persistent_id)\n",
       "  9122640   33.467    0.000   33.467    0.000 {method 'transpose' of 'ImagingCore' objects}\n",
       " 41232267   29.343    0.000   29.343    0.000 {method 'copy' of 'dict' objects}\n",
       "  9122640   28.642    0.000  132.579    0.000 Image.py:2241(transpose)\n",
       " 22137234   28.240    0.000   28.240    0.000 {built-in method builtins.max}\n",
       " 55098567   28.078    0.000   28.078    0.000 {method 'append' of 'list' objects}\n",
       "     3800   27.932    0.007   50.046    0.013 sampler.py:158(__iter__)\n",
       "   269420   27.073    0.000   27.073    0.000 {method 'cpu' of 'torch._C._TensorBase' objects}\n",
       " 22040000   26.810    0.000   26.810    0.000 {built-in method PIL._imaging.raw_encoder}\n",
       "9120/3040   26.694    0.003  256.711    0.084 dataloader.py:196(default_collate)\n",
       "   558600   25.977    0.000   25.977    0.000 {built-in method norm}\n",
       " 22041140   25.549    0.000   37.238    0.000 _util.py:7(isStringType)\n",
       "   609643   24.467    0.000   24.467    0.000 {built-in method numpy.core.multiarray.array}\n",
       " 30205447   22.696    0.000   22.696    0.000 {method 'copy' of 'collections.OrderedDict' objects}\n",
       " 31164540   22.271    0.000   22.271    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
       " 22040760   21.820    0.000   21.820    0.000 {method 'setimage' of 'ImagingDecoder' objects}\n",
       "  1123325   21.447    0.000   21.447    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n",
       "  9122640   20.702    0.000  166.860    0.000 functional.py:335(hflip)\n",
       "    15581   20.526    0.001 48831.973    3.134 module.py:483(__call__)\n",
       "     6460   20.325    0.003   20.325    0.003 {built-in method torch._C._scatter}\n",
       "  1117200   19.038    0.000   19.038    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
       " 22040760   18.598    0.000   18.598    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
       "      820   16.588    0.020   88.433    0.108 {method 'dump' of '_pickle.Pickler' objects}\n",
       "   598120   13.821    0.000   13.821    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
       "     2280   12.557    0.006   79.964    0.035 adam.py:49(step)\n",
       " 17772948   12.419    0.000   12.419    0.000 __init__.py:128(is_storage)\n",
       " 18240000   12.387    0.000   12.387    0.000 {method 'random' of '_random.Random' objects}\n",
       " 22041914   12.350    0.000   12.350    0.000 {method 'join' of 'bytes' objects}\n",
       "    22960   12.176    0.001   12.176    0.001 {method '_write_file' of 'torch._C.CudaLongStorageBase' objects}\n",
       "   229140    9.937    0.000  157.955    0.001 {built-in method apply}\n",
       "     3425    9.890    0.003    9.890    0.003 {method 'flush' of '_io.TextIOWrapper' objects}\n",
       "      927    9.719    0.010    9.719    0.010 {method 'flush' of '_io.BufferedWriter' objects}\n",
       "    87400    9.314    0.000    9.314    0.000 {method 'mean' of 'torch._C._TensorBase' objects}\n",
       "  1882878    9.195    0.000   64.866    0.000 module.py:771(_named_members)\n",
       "   558600    9.097    0.000    9.097    0.000 {method 'sqrt' of 'torch._C._TensorBase' objects}\n",
       "    96141    8.913    0.000    8.913    0.000 {method 'clone' of 'torch._C._TensorBase' objects}\n",
       "    93100    8.419    0.000  165.660    0.002 summary.py:126(histogram)\n",
       "   558600    8.139    0.000    8.139    0.000 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n",
       "   558600    7.935    0.000    7.935    0.000 {method 'addcmul_' of 'torch._C._TensorBase' objects}\n",
       "   376602    7.459    0.000    7.459    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "    93101    7.284    0.000    7.284    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
       " 15075815    7.257    0.000    7.257    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
       "  8688474    6.658    0.000    9.246    0.000 {method 'add' of 'set' objects}\n",
       "  6747720    6.476    0.000    9.634    0.000 tensor.py:416(__hash__)\n",
       "  4060684    6.396    0.000    8.293    0.000 module.py:891(named_children)\n",
       "    17133    6.174    0.000    6.174    0.000 socket.py:334(send)\n",
       "   219260    6.041    0.000   89.281    0.000 _functions.py:52(forward)\n",
       "1742301/4561    5.770    0.000   20.460    0.004 module.py:203(apply)\n",
       "      380    5.431    0.014    5.431    0.014 {method 'encode_to_file' of 'ImagingEncoder' objects}\n",
       " 10071348    5.310    0.000    5.310    0.000 {built-in method __new__ of type object at 0x5558a5dd0d60}\n",
       "   694540    5.288    0.000    8.083    0.000 tensor.py:33(__reduce_ex__)\n",
       "  4060684    4.909    0.000   13.202    0.000 module.py:882(children)\n",
       "   205201    4.768    0.000  587.064    0.003 writer.py:82(add_summary)\n",
       "     2280    4.440    0.002   65.613    0.029 clip_grad.py:6(clip_grad_norm_)\n",
       "   186200    3.822    0.000    3.822    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
       "335380/820    3.522    0.000    4.170    0.005 module.py:602(state_dict)\n",
       "  7154824    3.344    0.000    3.344    0.000 {built-in method builtins.id}\n",
       "   558443    3.333    0.000    3.333    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
       "  2241204    3.069    0.000    4.094    0.000 module.py:829(<lambda>)\n",
       "   108680    2.776    0.000   12.546    0.000 summary.py:105(scalar)\n",
       "      820    2.682    0.003  597.090    0.728 serialization.py:221(_save)\n",
       "   205201    2.551    0.000  579.869    0.003 queue.py:115(put)\n",
       "   442307    2.538    0.000    6.554    0.000 {built-in method builtins.all}\n",
       "   694541    2.399    0.000    2.399    0.000 serialization.py:149(_is_compressed_file)\n",
       "   108680    2.311    0.000   45.726    0.000 writer.py:344(add_scalars)\n",
       "    93100    2.306    0.000   92.564    0.001 histograms.py:597(histogram)\n",
       "  2469597    1.944    0.000    1.944    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
       "  1723680    1.899    0.000    7.820    0.000 _functions.py:60(<genexpr>)\n",
       "242440/3420    1.895    0.000   95.632    0.028 scatter_gather.py:51(gather_map)\n",
       "      380    1.809    0.005   11.966    0.031 summary.py:184(image)\n",
       "    27467    1.798    0.000    1.798    0.000 {built-in method _thread.start_new_thread}\n",
       "  1754080    1.794    0.000    3.040    0.000 _functions.py:67(<lambda>)\n",
       "   238193    1.783    0.000    1.783    0.000 {method 'release' of '_thread.lock' objects}\n",
       "  1754080    1.764    0.000    3.084    0.000 _functions.py:58(<lambda>)\n",
       "  1779160    1.730    0.000    2.485    0.000 _functions.py:59(<genexpr>)\n",
       "   694541    1.705    0.000    4.776    0.000 serialization.py:157(_should_read_directly)\n",
       "    97213    1.704    0.000    1.704    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "   310840    1.673    0.000   27.997    0.000 x2num.py:10(make_np)\n",
       "    93100    1.668    0.000   28.906    0.000 histograms.py:297(_get_bin_edges)\n",
       "   694540    1.651    0.000    3.922    0.000 serialization.py:102(location_tag)\n",
       "   170620    1.634    0.000   23.287    0.000 x2num.py:27(prepare_pytorch)\n",
       "  1496418    1.603    0.000   47.190    0.000 module.py:808(named_parameters)\n",
       "   108680    1.587    0.000   21.584    0.000 writer.py:303(__append_to_scalar_dict)\n",
       "   558600    1.577    0.000   27.884    0.000 functional.py:607(norm)\n",
       "     3040    1.559    0.001  230.434    0.076 dataloader.py:232(<listcomp>)\n",
       "     6880    1.557    0.000    1.557    0.000 {built-in method posix.stat}\n",
       "     3041    1.546    0.001    1.546    0.001 {method 'scatter_' of 'torch._C._TensorBase' objects}\n",
       "290320/760    1.534    0.000    7.220    0.010 module.py:976(train)\n",
       "  1258560    1.525    0.000    2.081    0.000 module.py:877(<lambda>)\n",
       "  1402938    1.410    0.000   44.364    0.000 module.py:784(parameters)\n",
       "    93100    1.373    0.000    1.685    0.000 function_base.py:1079(diff)\n",
       "     2280    1.370    0.001    5.208    0.002 optimizer.py:157(zero_grad)\n",
       "      720    1.361    0.002    1.361    0.002 {method 'update' of '_hashlib.HASH' objects}\n",
       "  1767000    1.334    0.000    1.334    0.000 {method 'get_device' of 'torch._C._TensorBase' objects}\n",
       "   694540    1.329    0.000    1.724    0.000 serialization.py:57(_cuda_tag)\n",
       "   186200    1.325    0.000    1.325    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
       "      380    1.314    0.003    1.314    0.003 {built-in method randperm}\n",
       "    93100    1.299    0.000  746.863    0.008 writer.py:390(add_histogram)\n",
       "   205201    1.289    0.000  581.949    0.003 writer.py:137(_add_event)\n",
       "    93140    1.270    0.000    1.270    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "   205201    1.238    0.000    3.571    0.000 threading.py:334(notify)\n",
       "     3040    1.225    0.000 41847.519   13.766 train_cnf_disentangle_rl_multiscale.py:464(compute_bits_per_dim_conditional)\n",
       "  1261980    1.181    0.000   15.529    0.000 module.py:911(modules)\n",
       "   272460    1.121    0.000    1.121    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
       "    98807    1.119    0.000  599.699    0.006 threading.py:263(wait)\n",
       "  2128929    1.094    0.000    1.094    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
       "  1754080    1.072    0.000    1.072    0.000 _functions.py:54(<lambda>)\n",
       "   558600    1.015    0.000   28.899    0.000 tensor.py:250(norm)\n",
       "    93482    1.002    0.000    1.002    0.000 {built-in method numpy.core.multiarray.zeros}\n",
       "      820    0.966    0.001  598.056    0.729 serialization.py:218(<lambda>)\n",
       "   870960    0.952    0.000    2.670    0.000 train_misc.py:76(__call__)\n",
       "      760    0.916    0.001    0.916    0.001 {method 'random_' of 'torch._C._TensorBase' objects}\n",
       "   186200    0.876    0.000   17.433    0.000 fromnumeric.py:2651(ndim)\n",
       "   870960    0.875    0.000    1.375    0.000 train_misc.py:96(__call__)\n",
       "   694540    0.851    0.000    1.242    0.000 serialization.py:121(normalize_storage_type)\n",
       "     3040    0.820    0.000    0.891    0.000 modules.py:268(likelihood)\n",
       "   353551    0.811    0.000    1.233    0.000 _utils.py:5(_get_device_index)\n",
       "   217800    0.806    0.000    2.519    0.000 numeric.py:1927(isscalar)\n",
       "   202875    0.802    0.000    0.802    0.000 {method 'sub' of '_sre.SRE_Pattern' objects}\n",
       "   695030    0.776    0.000    0.776    0.000 {method 'storage' of 'torch._C._TensorBase' objects}\n",
       "     6081    0.773    0.000    0.773    0.000 {built-in method addmm}\n",
       "   182550    0.766    0.000    1.261    0.000 abc.py:180(__instancecheck__)\n",
       "   191813    0.760    0.000    0.761    0.000 {built-in method _warnings.warn}\n",
       "1401074/1399708    0.760    0.000    0.775    0.000 {built-in method builtins.issubclass}\n",
       "    93101    0.753    0.000    0.753    0.000 {built-in method numpy.core.multiarray.concatenate}\n",
       "      380    0.733    0.002    0.733    0.002 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
       "     3040    0.732    0.000    0.732    0.000 {method 'argmax' of 'numpy.ndarray' objects}\n",
       "        1    0.723    0.723    0.723    0.723 {built-in method caffe2.python.caffe2_pybind11_state_gpu.num_cuda_devices}\n",
       "      819    0.720    0.001    0.720    0.001 {method '_set_from_file' of 'torch._C.FloatStorageBase' objects}\n",
       "     6112    0.716    0.000    0.716    0.000 {built-in method zeros}\n",
       "   202160    0.695    0.000    1.755    0.000 summary.py:64(_clean_tag)\n",
       "     3041    0.684    0.000    2.213    0.001 odenvp_conditional_rl_multiscale.py:133(_prior)\n",
       "   694540    0.672    0.000    0.672    0.000 {method 'fileno' of '_io.BufferedWriter' objects}\n",
       "   205201    0.639    0.000  580.509    0.003 event_file_writer.py:131(add_event)\n",
       "   558600    0.623    0.000    0.623    0.000 clip_grad.py:24(<lambda>)\n",
       "     3420    0.606    0.000    1.669    0.000 replicate.py:12(<dictcomp>)\n",
       "     6081    0.583    0.000    1.731    0.000 modules.py:105(forward)\n",
       "    38357    0.550    0.000    0.550    0.000 {method 'copy_' of 'torch._C._TensorBase' objects}\n",
       "   694540    0.548    0.000    0.548    0.000 serialization.py:52(_cpu_tag)\n",
       "    93100    0.539    0.000    4.987    0.000 histograms.py:391(_search_sorted_inclusive)\n",
       "   372431    0.536    0.000   24.643    0.000 numeric.py:433(asarray)\n",
       "   219260    0.535    0.000   61.981    0.000 comm.py:151(gather)\n",
       "   289688    0.524    0.000    0.547    0.000 module.py:521(__getattr__)\n",
       "      868    0.512    0.001    0.512    0.001 {method 'read' of '_io.BufferedReader' objects}\n",
       "   558355    0.505    0.000    0.505    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}\n",
       "    93863    0.501    0.000    1.677    0.000 fromnumeric.py:64(_wrapreduction)\n",
       "   304008    0.500    0.000    0.853    0.000 threading.py:254(_is_owned)\n",
       "   695030    0.496    0.000    0.496    0.000 {method 'stride' of 'torch._C._TensorBase' objects}\n",
       "   236093    0.490    0.000    0.734    0.000 threading.py:239(__enter__)\n",
       "   360254    0.489    0.000    0.489    0.000 _weakrefset.py:70(__contains__)\n",
       "   841320    0.487    0.000    0.487    0.000 _functions.py:13(<genexpr>)\n",
       "   273140    0.483    0.000    0.712    0.000 queue.py:202(_qsize)\n",
       "   694540    0.447    0.000    0.447    0.000 hooks.py:51(warn_if_has_hooks)\n",
       "   202160    0.447    0.000    0.725    0.000 writer.py:314(_check_caffe2)\n",
       "   559072    0.427    0.000    0.427    0.000 {built-in method math.sqrt}\n",
       "   695030    0.425    0.000    0.425    0.000 {method 'storage_offset' of 'torch._C._TensorBase' objects}\n",
       "    93102    0.409    0.000    0.409    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "    32328    0.402    0.000    0.402    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}\n",
       "     6081    0.398    0.000    0.398    0.000 {built-in method cat}\n",
       "   386460    0.398    0.000   19.677    0.000 module.py:856(named_buffers)\n",
       "    93100    0.398    0.000    0.783    0.000 histograms.py:220(_ravel_and_check_weights)\n",
       "    93100    0.394    0.000   52.992    0.001 fromnumeric.py:760(sort)\n",
       "   386460    0.392    0.000   20.069    0.000 module.py:834(buffers)\n",
       "   671580    0.390    0.000    0.390    0.000 {method 'size' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "   236093    0.381    0.000    0.542    0.000 threading.py:242(__exit__)\n",
       "   671580    0.378    0.000    0.378    0.000 {method 'get_device' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "   215300    0.350    0.000    0.350    0.000 {built-in method time.time}\n",
       "     3420    0.332    0.000    0.332    0.000 _functions.py:28(<listcomp>)\n",
       "   205201    0.331    0.000    0.498    0.000 queue.py:206(_put)\n",
       "       12    0.326    0.027    0.326    0.027 {built-in method _pickle.load}\n",
       "     3420    0.320    0.000 48147.690   14.078 parallel_apply.py:21(parallel_apply)\n",
       "   114050    0.299    0.000    0.476    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "     3041    0.295    0.000    0.317    0.000 summary.py:380(text)\n",
       "    76000    0.288    0.000    0.288    0.000 {method 'narrow' of 'torch._C._TensorBase' objects}\n",
       "    93100    0.283    0.000    1.927    0.000 fromnumeric.py:1933(any)\n",
       "     3420    0.276    0.000    0.766    0.000 replicate.py:19(<dictcomp>)\n",
       "      380    0.271    0.001    1.142    0.003 utils.py:6(make_grid)\n",
       "    30892    0.268    0.000   28.706    0.001 threading.py:533(wait)\n",
       "   189740    0.263    0.000    0.463    0.000 numeric.py:504(asanyarray)\n",
       "   203061    0.262    0.000    0.262    0.000 {method 'lstrip' of 'str' objects}\n",
       "    93100    0.258    0.000    4.469    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
       "   321141    0.256    0.000    0.256    0.000 {method 'append' of 'collections.deque' objects}\n",
       "      820    0.255    0.000    0.446    0.001 optimizer.py:88(<dictcomp>)\n",
       "   170620    0.248    0.000    0.355    0.000 variable.py:6(__instancecheck__)\n",
       "    27467    0.248    0.000    0.676    0.000 threading.py:757(__init__)\n",
       "   236093    0.244    0.000    0.244    0.000 {method '__enter__' of '_thread.lock' objects}\n",
       "   108681    0.244    0.000    0.331    0.000 writer.py:204(get_logdir)\n",
       "    27467    0.241    0.000   25.559    0.001 threading.py:828(start)\n",
       "      380    0.241    0.001    0.414    0.001 utils.py:70(make_grid)\n",
       "     9122    0.239    0.000    0.239    0.000 {built-in method exp}\n",
       "      760    0.236    0.000    1.614    0.002 dataloader.py:518(__init__)\n",
       "6884/6817    0.227    0.000    0.401    0.000 {built-in method builtins.__build_class__}\n",
       "     5320    0.220    0.000    0.220    0.000 {built-in method rsub}\n",
       "    98807    0.213    0.000    0.333    0.000 threading.py:251(_acquire_restore)\n",
       "115934/114050    0.209    0.000    2.187    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
       "    93100    0.206    0.000    4.211    0.000 _methods.py:30(_amin)\n",
       "     3420    0.204    0.000   38.035    0.011 _functions.py:11(forward)\n",
       "     6081    0.201    0.000    0.201    0.000 {built-in method sum}\n",
       "   376453    0.196    0.000    0.196    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
       "    47918    0.195    0.000 48120.646    1.004 threading.py:1062(_wait_for_tstate_lock)\n",
       "    37/34    0.192    0.005    0.199    0.006 {built-in method _imp.create_dynamic}\n",
       "     3929    0.191    0.000    0.250    0.000 {built-in method builtins.sorted}\n",
       "    27360    0.184    0.000 48120.896    1.759 threading.py:1024(join)\n",
       "     6080    0.182    0.000    0.182    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
       "   119765    0.181    0.000    0.181    0.000 {method 'rpartition' of 'str' objects}\n",
       "     3040    0.174    0.000    0.410    0.000 train_misc.py:10(standard_normal_logprob)\n",
       "   206682    0.169    0.000    0.169    0.000 {method 'items' of 'dict' objects}\n",
       "   218243    0.163    0.000    0.163    0.000 {method 'keys' of 'dict' objects}\n",
       "    31920    0.163    0.000    1.197    0.000 cnf_gate.py:142(num_evals)\n",
       "    93100    0.163    0.000    1.347    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "    93100    0.162    0.000    1.490    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
       "   236093    0.161    0.000    0.161    0.000 {method '__exit__' of '_thread.lock' objects}\n",
       "   138324    0.159    0.000    0.159    0.000 {built-in method _thread.allocate_lock}\n",
       "    31213    0.158    0.000    0.158    0.000 threading.py:215(__init__)\n",
       "     3420    0.150    0.000 48147.919   14.078 data_parallel.py:152(parallel_apply)\n",
       "     3040    0.148    0.000    0.148    0.000 {built-in method torch._C._nn.nll_loss}\n",
       "     3420    0.143    0.000  544.276    0.159 data_parallel.py:146(replicate)\n",
       "     3425    0.139    0.000    0.283    0.000 __init__.py:251(__init__)\n",
       "    98807    0.136    0.000    0.204    0.000 threading.py:248(_release_save)\n",
       "    93100    0.134    0.000    1.328    0.000 _methods.py:26(_amax)\n",
       "    93100    0.128    0.000    1.184    0.000 _methods.py:34(_sum)\n",
       "      820    0.125    0.000    0.217    0.000 optimizer.py:84(<listcomp>)\n",
       "    58252    0.123    0.000    0.169    0.000 threading.py:1230(current_thread)\n",
       "   108680    0.121    0.000    0.121    0.000 {method 'squeeze' of 'numpy.ndarray' objects}\n",
       "      820    0.119    0.000    0.119    0.000 {method 'close' of '_io.BufferedWriter' objects}\n",
       "    17133    0.116    0.000    6.445    0.000 iostream.py:195(schedule)\n",
       "     6460    0.116    0.000   20.703    0.003 _functions.py:80(forward)\n",
       "     3040    0.115    0.000    0.115    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}\n",
       "     3040    0.110    0.000    0.110    0.000 {built-in method dropout}\n",
       "11400/3800    0.106    0.000   20.973    0.006 scatter_gather.py:11(scatter_map)\n",
       "      785    0.105    0.000    0.196    0.000 <frozen importlib._bootstrap_external>:830(get_data)\n",
       "   188502    0.103    0.000    0.103    0.000 {method 'startswith' of 'str' objects}\n",
       "     3280    0.102    0.000    0.102    0.000 {built-in method _pickle.dump}\n",
       "    93100    0.101    0.000    0.101    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "    19168    0.101    0.000    0.101    0.000 {method 'format' of 'str' objects}\n",
       "    30892    0.100    0.000    0.284    0.000 threading.py:498(__init__)\n",
       "     3420    0.099    0.000 48809.064   14.272 data_parallel.py:136(forward)\n",
       "    31920    0.097    0.000    0.203    0.000 cnf_regularization_rl.py:33(_num_evals)\n",
       "    93100    0.097    0.000    0.097    0.000 {built-in method numpy.core.multiarray.normalize_axis_index}\n",
       "    31920    0.093    0.000    0.634    0.000 cnf_regularization_rl.py:14(after_odeint)\n",
       "     3420    0.092    0.000    0.258    0.000 _methods.py:58(_mean)\n",
       "      785    0.091    0.000    0.091    0.000 {method 'read' of '_io.FileIO' objects}\n",
       "    31920    0.090    0.000    0.503    0.000 odefunc_rl.py:278(after_odeint)\n",
       "      409    0.088    0.000    0.179    0.000 module.py:647(_load_from_state_dict)\n",
       "   108681    0.088    0.000    0.088    0.000 event_file_writer.py:118(get_logdir)\n",
       "   112026    0.085    0.000    0.085    0.000 {method 'remove' of 'collections.deque' objects}\n",
       "     3420    0.084    0.000    0.097    0.000 replicate.py:15(<listcomp>)\n",
       "     2280    0.081    0.000 119740.911   52.518 tensor.py:74(backward)\n",
       "     3420    0.080    0.000    0.751    0.000 parallel_apply.py:67(<listcomp>)\n",
       "     3040    0.077    0.000    0.077    0.000 {method 'pow' of 'torch._C._TensorBase' objects}\n",
       "    27360    0.076    0.000    0.095    0.000 threading.py:966(_stop)\n",
       "      785    0.075    0.000    0.075    0.000 {built-in method marshal.loads}\n",
       "     3826    0.074    0.000    0.074    0.000 {built-in method zlib.crc32}\n",
       "     6855    0.072    0.000    6.237    0.001 iostream.py:382(write)\n",
       "6840/2280    0.070    0.000   72.146    0.032 dataloader.py:237(pin_memory_batch)\n",
       "    51680    0.068    0.000    0.225    0.000 _functions.py:82(<lambda>)\n",
       "     3041    0.068    0.000    0.075    0.000 thops.py:47(split_feature)\n",
       "     6850    0.068    0.000   22.140    0.003 __init__.py:982(emit)\n",
       "    20558    0.066    0.000    0.137    0.000 threading.py:1104(is_alive)\n",
       "     6081    0.065    0.000    0.913    0.000 functional.py:1335(linear)\n",
       "    75492    0.063    0.000    0.063    0.000 threading.py:506(is_set)\n",
       "     6081    0.063    0.000    0.063    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
       "     3041    0.061    0.000    1.880    0.001 thops.py:4(onehot)\n",
       "    18620    0.060    0.000    0.060    0.000 utils.py:74(update)\n",
       "     3422    0.058    0.000    0.324    0.000 module.py:62(__init__)\n",
       "     6850    0.057    0.000   15.654    0.002 __init__.py:971(flush)\n",
       "    15581    0.057    0.000    0.057    0.000 {built-in method torch._C._get_tracing_state}\n",
       "    28041    0.056    0.000    0.078    0.000 _weakrefset.py:81(add)\n",
       "    27360    0.055    0.000    0.076    0.000 _weakrefset.py:38(_remove)\n",
       "     2281    0.055    0.000    0.055    0.000 {built-in method ones_like}\n",
       "     3425    0.054    0.000    0.100    0.000 __init__.py:1376(findCaller)\n",
       "    68035    0.052    0.000    0.052    0.000 {built-in method _thread.get_ident}\n",
       "     3420    0.052    0.000   21.073    0.006 scatter_gather.py:33(scatter_kwargs)\n",
       "     3041    0.051    0.000    0.051    0.000 {method 'unsqueeze' of 'torch._C._TensorBase' objects}\n",
       "    32290    0.050    0.000    0.050    0.000 {method 'insert' of 'list' objects}\n",
       "     3040    0.049    0.000    1.130    0.000 modules.py:277(logp)\n",
       "     9120    0.048    0.000    0.106    0.000 container.py:124(_get_abs_string_index)\n",
       "      380    0.047    0.000    0.047    0.000 {method 'close' of '_io.BufferedRandom' objects}\n",
       "     3425    0.046    0.000    5.662    0.002 iostream.py:334(flush)\n",
       "    27467    0.044    0.000    0.044    0.000 threading.py:727(_newname)\n",
       "     3040    0.043    0.000    0.939    0.000 odenvp_conditional_rl_multiscale.py:171(loss_class)\n",
       "     6850    0.043    0.000   22.247    0.003 __init__.py:852(handle)\n",
       "     6081    0.042    0.000    0.970    0.000 linear.py:65(forward)\n",
       "     2280    0.042    0.000    0.055    0.000 train_cnf_disentangle_rl_multiscale.py:318(update_lr)\n",
       "     3041    0.041    0.000    0.572    0.000 writer.py:523(add_text)\n",
       "     3425    0.041    0.000   22.288    0.007 __init__.py:1500(callHandlers)\n",
       "     6850    0.040    0.000    0.146    0.000 __init__.py:564(format)\n",
       "     3040    0.037    0.000    0.176    0.000 thops.py:15(sum)\n",
       "    27360    0.037    0.000    0.122    0.000 parallel_apply.py:45(<lambda>)\n",
       "     3040    0.036    0.000    0.200    0.000 functional.py:1734(nll_loss)\n",
       "     3420    0.036    0.000    0.294    0.000 fromnumeric.py:2817(mean)\n",
       "     3425    0.036    0.000   22.753    0.007 __init__.py:1421(_log)\n",
       "    27360    0.034    0.000    0.111    0.000 replicate.py:8(<lambda>)\n",
       "        3    0.033    0.011    0.098    0.033 utils.py:70(parse_header)\n",
       "     2280    0.032    0.000 119740.830   52.518 __init__.py:38(backward)\n",
       "    27360    0.032    0.000    0.112    0.000 _functions.py:15(<lambda>)\n",
       "        1    0.031    0.031    2.198    2.198 train_cnf_disentangle_rl_multiscale.py:345(get_dataset)\n",
       "     3425    0.031    0.000   22.812    0.007 __init__.py:1298(info)\n",
       "     3040    0.031    0.000    0.156    0.000 functional.py:728(dropout)\n",
       "     1230    0.030    0.000    0.030    0.000 {built-in method torch._C._cuda_isDriverSufficient}\n",
       "     6460    0.030    0.000   20.355    0.003 comm.py:131(scatter)\n",
       "        1    0.030    0.030    0.030    0.030 visdom_writer.py:23(VisdomWriter)\n",
       "      381    0.030    0.000    0.030    0.000 {method 'repeat' of 'torch._C._TensorBase' objects}\n",
       "     3531    0.029    0.000   10.195    0.003 train_cnf_disentangle_rl_multiscale.py:585(<lambda>)\n",
       "     9120    0.029    0.000    0.142    0.000 container.py:133(__getitem__)\n",
       "    13700    0.029    0.000    0.044    0.000 __init__.py:809(acquire)\n",
       "      421    0.028    0.000    0.028    0.000 {built-in method posix.listdir}\n",
       "     2292    0.028    0.000    0.043    0.000 posixpath.py:75(join)\n",
       "     2280    0.028    0.000   10.895    0.005 train_misc.py:69(count_nfe_gate)\n",
       "     3420    0.028    0.000    0.030    0.000 _methods.py:48(_count_reduce_items)\n",
       "     2280    0.027    0.000    0.091    0.000 __init__.py:20(_make_grads)\n",
       "  955/231    0.027    0.000    0.092    0.000 sre_parse.py:470(_parse)\n",
       "     3040    0.027    0.000    0.027    0.000 {method 'squeeze_' of 'torch._C._TensorBase' objects}\n",
       "     5320    0.026    0.000    0.246    0.000 tensor.py:348(__rsub__)\n",
       "      380    0.025    0.000    9.438    0.025 summary.py:248(make_image)\n",
       "      380    0.025    0.000    0.025    0.000 {method 'copy' of 'ImagingCore' objects}\n",
       "    17133    0.025    0.000    0.025    0.000 iostream.py:93(_event_pipe)\n",
       "    20553    0.025    0.000    0.035    0.000 container.py:153(__len__)\n",
       "     6840    0.024    0.000   51.279    0.007 comm.py:24(broadcast_coalesced)\n",
       "     4821    0.024    0.000    0.058    0.000 posixpath.py:121(splitext)\n",
       "     6119    0.024    0.000    0.024    0.000 {method 'write' of '_io.BytesIO' objects}\n",
       "    13700    0.024    0.000    0.034    0.000 __init__.py:816(release)\n",
       "     3772    0.023    0.000    0.041    0.000 posixpath.py:144(basename)\n",
       "     6850    0.023    0.000    0.169    0.000 __init__.py:829(format)\n",
       "      760    0.023    0.000   13.480    0.018 ImageFile.py:463(_save)\n",
       "     3532    0.023    0.000    0.023    0.000 {method 'type' of 'torch._C._TensorBase' objects}\n",
       "     6081    0.023    0.000    0.023    0.000 {method 'detach' of 'torch._C._TensorBase' objects}\n",
       "     9120    0.023    0.000    0.036    0.000 container.py:156(__iter__)\n",
       "     2280    0.022    0.000    9.816    0.004 train_misc.py:89(count_total_time)\n",
       "     1387    0.022    0.000    0.222    0.000 <frozen importlib._bootstrap_external>:1233(find_spec)\n",
       "    27467    0.022    0.000    0.022    0.000 threading.py:1120(daemon)\n",
       "     2280    0.022    0.000   72.043    0.032 dataloader.py:245(<listcomp>)\n",
       "     3040    0.021    0.000    0.356    0.000 functional.py:1923(cross_entropy)\n",
       "    27360    0.021    0.000    0.021    0.000 {method 'discard' of 'set' objects}\n",
       "     3420    0.021    0.000   95.669    0.028 data_parallel.py:155(gather)\n",
       "     3040    0.021    0.000    0.418    0.000 loss.py:22(__init__)\n",
       "     3425    0.021    0.000   22.315    0.007 __init__.py:1446(handle)\n",
       "      760    0.021    0.000   33.131    0.044 Image.py:1892(save)\n",
       "      380    0.020    0.000    0.020    0.000 {method 'mul' of 'torch._C._TensorBase' objects}\n",
       "     3040    0.020    0.000    0.460    0.000 loss.py:896(__init__)\n",
       "     3436    0.020    0.000    0.028    0.000 __init__.py:1544(isEnabledFor)\n",
       "     3999    0.020    0.000   50.083    0.013 {built-in method builtins.next}\n",
       "     6850    0.020    0.000    0.047    0.000 __init__.py:542(usesTime)\n",
       "     3425    0.019    0.000    0.302    0.000 __init__.py:1406(makeRecord)\n",
       "     3040    0.019    0.000    0.379    0.000 loss.py:901(forward)\n",
       "     1913    0.019    0.000    0.135    0.000 PngImagePlugin.py:667(putchunk)\n",
       " 1888/222    0.019    0.000    0.077    0.000 sre_compile.py:64(_compile)\n",
       "    27360    0.019    0.000    0.019    0.000 {method 'locked' of '_thread.lock' objects}\n",
       "     4821    0.019    0.000    0.027    0.000 genericpath.py:117(_splitext)\n",
       "     3040    0.019    0.000    0.175    0.000 dropout.py:56(forward)\n",
       "     3040    0.018    0.000    0.338    0.000 loss.py:13(__init__)\n",
       "     6855    0.018    0.000    0.024    0.000 iostream.py:307(_is_master_process)\n",
       "     3040    0.018    0.000    0.135    0.000 functional.py:1271(log_softmax)\n",
       "     3800    0.018    0.000   20.990    0.006 scatter_gather.py:5(scatter)\n",
       "     6850    0.017    0.000    0.028    0.000 __init__.py:387(usesTime)\n",
       "     6855    0.017    0.000    1.887    0.000 iostream.py:320(_schedule_flush)\n",
       "     3040    0.017    0.000    0.017    0.000 scatter_gather.py:40(<listcomp>)\n",
       "     6850    0.017    0.000    0.017    0.000 __init__.py:390(format)\n",
       "      380    0.017    0.000   26.520    0.070 utils.py:90(save_image)\n",
       "    10275    0.017    0.000    0.017    0.000 __init__.py:705(filter)\n",
       "     9416    0.017    0.000    0.048    0.000 <frozen importlib._bootstrap_external>:57(_path_join)\n",
       "     3152    0.017    0.000    0.060    0.000 module.py:87(register_buffer)\n",
       "    14343    0.017    0.000    0.017    0.000 {method 'rfind' of 'str' objects}\n",
       "    22960    0.016    0.000    0.016    0.000 {method 'get_device' of 'torch._C.CudaLongStorageBase' objects}\n",
       "    17916    0.016    0.000    0.016    0.000 {built-in method posix.fspath}\n",
       "        1    0.016    0.016    0.016    0.016 {built-in method torch._C._cuda_init}\n",
       "     9416    0.016    0.000    0.025    0.000 <frozen importlib._bootstrap_external>:59(<listcomp>)\n",
       "     3420    0.016    0.000   21.089    0.006 data_parallel.py:149(scatter)\n",
       "     3420    0.016    0.000   95.648    0.028 scatter_gather.py:46(gather)\n",
       "     3040    0.015    0.000    0.768    0.000 fromnumeric.py:976(argmax)\n",
       "    22960    0.015    0.000    0.015    0.000 {method 'size' of 'torch._C.CudaLongStorageBase' objects}\n",
       "      357    0.015    0.000    0.015    0.000 {method 'cuda' of 'torch._C._TensorBase' objects}\n",
       "    13741    0.015    0.000    0.015    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "    28243    0.015    0.000    0.015    0.000 {method 'rstrip' of 'str' objects}\n",
       "    16412    0.015    0.000    0.025    0.000 sre_parse.py:253(get)\n",
       "     3425    0.015    0.000   10.100    0.003 __init__.py:1063(emit)\n",
       "      380    0.015    0.000    5.483    0.014 JpegImagePlugin.py:617(_save)\n",
       "     3448    0.014    0.000    0.023    0.000 posixpath.py:52(normcase)\n",
       "     3040    0.014    0.000    0.752    0.000 fromnumeric.py:49(_wrapfunc)\n",
       "     1528    0.014    0.000    0.033    0.000 version.py:198(__init__)\n",
       "     6850    0.013    0.000    0.028    0.000 __init__.py:329(getMessage)\n",
       "     3425    0.013    0.000    0.019    0.000 __init__.py:157(<lambda>)\n",
       "     6850    0.013    0.000    0.030    0.000 __init__.py:548(formatMessage)\n",
       "      380    0.013    0.000    8.061    0.021 PngImagePlugin.py:689(_save)\n",
       "    11921    0.013    0.000    0.023    0.000 enum.py:267(__call__)\n",
       "    816/1    0.013    0.000 178682.463 178682.463 {built-in method builtins.exec}\n",
       " 1706/866    0.013    0.000    2.636    0.003 <frozen importlib._bootstrap>:966(_find_and_load)\n",
       "      380    0.012    0.000    0.012    0.000 {method 'byte' of 'torch._C._TensorBase' objects}\n",
       "     6850    0.012    0.000    0.012    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
       "     3148    0.012    0.000    0.012    0.000 {method 'SerializeToString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "      820    0.012    0.000    0.688    0.001 optimizer.py:72(state_dict)\n",
       "    18455    0.012    0.000    0.012    0.000 sre_parse.py:232(__next)\n",
       "     3179    0.012    0.000    0.023    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\n",
       "      380    0.012    0.000    0.012    0.000 {method 'clamp' of 'torch._C._TensorBase' objects}\n",
       "     8391    0.012    0.000    0.012    0.000 {method 'find' of 'str' objects}\n",
       "     3040    0.012    0.000    0.012    0.000 {method 'long' of 'torch._C._TensorBase' objects}\n",
       "     6378    0.012    0.000    0.012    0.000 {built-in method torch._C.is_grad_enabled}\n",
       "    16691    0.012    0.000    0.012    0.000 {method 'split' of 'str' objects}\n",
       "     7086    0.011    0.000    0.017    0.000 posixpath.py:41(_get_sep)\n",
       "     4403    0.011    0.000    0.030    0.000 enum.py:803(__and__)\n",
       "      820    0.011    0.000  633.425    0.772 serialization.py:131(_with_file_like)\n",
       "     3042    0.011    0.000    0.011    0.000 {built-in method math.log}\n",
       "    10926    0.011    0.000    0.011    0.000 {built-in method builtins.iter}\n",
       "     3319    0.010    0.000    0.010    0.000 {method 'encode' of 'str' objects}\n",
       "      969    0.010    0.000    0.035    0.000 inspect.py:2100(_signature_from_function)\n",
       "13390/13314    0.010    0.000    0.014    0.000 {method 'join' of 'str' objects}\n",
       "     1229    0.010    0.000    0.044    0.000 __init__.py:45(is_available)\n",
       "    10284    0.010    0.000    0.010    0.000 {built-in method posix.getpid}\n",
       "     3420    0.010    0.000    0.010    0.000 replicate.py:23(<listcomp>)\n",
       "    13741    0.010    0.000    0.010    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "      380    0.010    0.000    0.430    0.001 utils.py:95(convert_to_HWC)\n",
       "      785    0.009    0.000    0.013    0.000 <frozen importlib._bootstrap_external>:430(_validate_bytecode_header)\n",
       "     3041    0.009    0.000    0.016    0.000 _VF.py:11(__getattr__)\n",
       "      848    0.009    0.000    0.223    0.000 <frozen importlib._bootstrap>:870(_find_spec)\n",
       "    11919    0.009    0.000    0.009    0.000 enum.py:517(__new__)\n",
       "     3420    0.008    0.000    0.008    0.000 replicate.py:69(<listcomp>)\n",
       "     1570    0.008    0.000    0.026    0.000 <frozen importlib._bootstrap_external>:263(cache_from_source)\n",
       "     3425    0.008    0.000    0.013    0.000 __init__.py:120(getLevelName)\n",
       "      381    0.008    0.000    0.025    0.000 dataloader.py:768(__init__)\n",
       "     3040    0.008    0.000    0.008    0.000 {method 'nelement' of 'torch._C._TensorBase' objects}\n",
       "     7648    0.008    0.000    0.013    0.000 sre_parse.py:163(__getitem__)\n",
       "     3798    0.008    0.000    0.022    0.000 {built-in method builtins.any}\n",
       "   2225/1    0.008    0.000    0.045    0.045 copy.py:132(deepcopy)\n",
       "      785    0.008    0.000    0.347    0.000 <frozen importlib._bootstrap_external>:743(get_code)\n",
       "      380    0.008    0.000   13.342    0.035 train_cnf_disentangle_rl_multiscale.py:331(get_train_loader)\n",
       "    17209    0.008    0.000    0.008    0.000 {method 'strip' of 'str' objects}\n",
       "     3436    0.008    0.000    0.008    0.000 __init__.py:1530(getEffectiveLevel)\n",
       "     3179    0.008    0.000    0.009    0.000 <frozen importlib._bootstrap>:78(acquire)\n",
       "     2938    0.008    0.000    0.008    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
       "     9121    0.008    0.000    0.008    0.000 __init__.py:1408(_unwrap_optional)\n",
       "     1479    0.008    0.000    0.018    0.000 grad_mode.py:35(__exit__)\n",
       "     3425    0.008    0.000    0.008    0.000 threading.py:1076(name)\n",
       "     2414    0.007    0.000    0.007    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n",
       "    10769    0.007    0.000    0.011    0.000 mathtext.py:2739(<genexpr>)\n",
       "     7536    0.007    0.000    0.007    0.000 {built-in method builtins.min}\n",
       "     3420    0.007    0.000    0.007    0.000 function.py:45(mark_non_differentiable)\n",
       "        1    0.007    0.007    0.007    0.007 {built-in method builtins.compile}\n",
       "      820    0.007    0.000  633.432    0.772 serialization.py:191(save)\n",
       "     1479    0.007    0.000    0.010    0.000 grad_mode.py:122(__init__)\n",
       "     4191    0.007    0.000    0.007    0.000 dataloader.py:811(__setattr__)\n",
       "      824    0.007    0.000    0.033    0.000 <frozen importlib._bootstrap>:504(_init_module_attrs)\n",
       "     3826    0.007    0.000    0.081    0.000 PngImagePlugin.py:90(_crc32)\n",
       "      636    0.007    0.000    0.012    0.000 sre_compile.py:250(_optimize_charset)\n",
       "     3179    0.007    0.000    0.008    0.000 <frozen importlib._bootstrap>:103(release)\n",
       "     4586    0.007    0.000    0.012    0.000 _binary.py:93(o32be)\n",
       "      760    0.007    0.000    0.042    0.000 fromnumeric.py:1821(sum)\n",
       "      865    0.007    0.000    0.012    0.000 posixpath.py:154(dirname)\n",
       "      820    0.007    0.000    0.227    0.000 optimizer.py:82(pack_group)\n",
       "2991/1344    0.007    0.000    0.009    0.000 sre_parse.py:173(getwidth)\n",
       "     2569    0.007    0.000    0.013    0.000 inspect.py:2450(__init__)\n",
       "      576    0.006    0.000    0.034    0.000 inspect.py:1087(getfullargspec)\n",
       "   837/21    0.006    0.000    2.565    0.122 <frozen importlib._bootstrap>:651(_load_unlocked)\n",
       "     9180    0.006    0.000    0.006    0.000 {built-in method _operator.index}\n",
       "     2542    0.006    0.000    0.010    0.000 <frozen importlib._bootstrap>:176(cb)\n",
       "      821    0.006    0.000    1.191    0.001 utils.py:8(makedirs)\n",
       "     2280    0.006    0.000    0.006    0.000 train_misc.py:71(AccNumEvals)\n",
       "     5178    0.006    0.000    0.161    0.000 <frozen importlib._bootstrap_external>:75(_path_stat)\n",
       "     3860    0.006    0.000    0.006    0.000 {built-in method sys._getframe}\n",
       "     3814    0.006    0.000    0.009    0.000 utils.py:51(add_argument)\n",
       "      380    0.006    0.000   12.001    0.032 writer.py:429(add_images)\n",
       "     3734    0.006    0.000    0.006    0.000 {method 'extend' of 'list' objects}\n",
       "  587/175    0.006    0.000    0.016    0.000 abc.py:196(__subclasscheck__)\n",
       "      490    0.006    0.000    0.027    0.000 tensor.py:16(__deepcopy__)\n",
       "   859/19    0.006    0.000    2.597    0.137 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)\n",
       "     3488    0.005    0.000    0.009    0.000 utils.py:81(<lambda>)\n",
       "     3488    0.005    0.000    0.009    0.000 utils.py:79(<lambda>)\n",
       "      760    0.005    0.000    0.017    0.000 version.py:131(_legacy_cmpkey)\n",
       "       24    0.005    0.000    1.710    0.071 utils.py:16(check_integrity)\n",
       "     3312    0.005    0.000    0.009    0.000 version.py:114(_parse_version_parts)\n",
       "     8294    0.005    0.000    0.005    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\n",
       "        1    0.005    0.005 178682.461 178682.461 py3compat.py:184(execfile)\n",
       "      380    0.005    0.000    2.056    0.005 sampler.py:69(__iter__)\n",
       "     1008    0.005    0.000    0.010    0.000 inspect.py:2730(__init__)\n",
       "     2542    0.005    0.000    0.008    0.000 <frozen importlib._bootstrap>:58(__init__)\n",
       "      957    0.005    0.000    0.016    0.000 copy.py:66(copy)\n",
       "     1900    0.005    0.000    0.007    0.000 cifar.py:128(__len__)\n",
       "       27    0.005    0.000    0.028    0.001 __init__.py:978(_rc_params_in_file)\n",
       "     1479    0.005    0.000    0.007    0.000 grad_mode.py:31(__enter__)\n",
       "     4907    0.005    0.000    0.005    0.000 {built-in method _struct.pack}\n",
       "     3740    0.005    0.000    0.008    0.000 version.py:65(_compare)\n",
       "     1231    0.005    0.000    1.352    0.001 genericpath.py:16(exists)\n",
       "      847    0.005    0.000    0.052    0.000 _utils.py:127(_rebuild_tensor)\n",
       "       26    0.005    0.000    0.006    0.000 {method 'readlines' of '_io._IOBase' objects}\n",
       "        1    0.005    0.005    0.068    0.068 {method 'load' of '_pickle.Unpickler' objects}\n",
       "     3040    0.005    0.000    0.005    0.000 _reduction.py:8(get_enum)\n",
       "     2280    0.005    0.000    0.005    0.000 train_misc.py:91(Accumulator)\n",
       "    818/2    0.005    0.000    0.014    0.007 module.py:1024(__repr__)\n",
       "      969    0.005    0.000    0.044    0.000 inspect.py:2181(_signature_from_callable)\n",
       "     3425    0.005    0.000    0.005    0.000 process.py:146(name)\n",
       "     2623    0.005    0.000    0.195    0.000 re.py:286(_compile)\n",
       "  849/848    0.005    0.000    0.203    0.000 <frozen importlib._bootstrap_external>:1117(_get_spec)\n",
       "     3006    0.005    0.000    0.068    0.000 <frozen importlib._bootstrap_external>:85(_path_is_mode_type)\n",
       "      760    0.005    0.000    1.618    0.002 dataloader.py:818(__iter__)\n",
       "      490    0.005    0.000    0.005    0.000 {method 'copy_' of 'torch._C.FloatStorageBase' objects}\n",
       "     8714    0.004    0.000    0.004    0.000 {method 'group' of '_sre.SRE_Match' objects}\n",
       "       12    0.004    0.000    0.040    0.003 artist.py:1179(_get_setters_and_targets)\n",
       "     3040    0.004    0.000    0.004    0.000 modules.py:280(<listcomp>)\n",
       "     4226    0.004    0.000    0.006    0.000 utils.py:92(<lambda>)\n",
       "     5428    0.004    0.000    0.005    0.000 {built-in method builtins.setattr}\n",
       "     8491    0.004    0.000    0.004    0.000 {built-in method _imp.release_lock}\n",
       "      768    0.004    0.000    0.005    0.000 version.py:343(_cmpkey)\n",
       "  702/222    0.004    0.000    0.093    0.000 sre_parse.py:407(_parse_sub)\n",
       "     1337    0.004    0.000    0.004    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
       "     2280    0.004    0.000    0.004    0.000 train_misc.py:73(__init__)\n",
       "      380    0.004    0.000    0.036    0.000 Image.py:1738(resize)\n",
       "     8491    0.004    0.000    0.004    0.000 {built-in method _imp.acquire_lock}\n",
       "     3426    0.004    0.000    0.004    0.000 process.py:35(current_process)\n",
       "      105    0.004    0.000    0.011    0.000 <frozen importlib._bootstrap_external>:1067(_path_hooks)\n",
       "     1473    0.004    0.000    0.019    0.000 <frozen importlib._bootstrap>:194(_lock_unlock_module)\n",
       "        1    0.004    0.004    0.004    0.004 {built-in method posix.read}\n",
       "      847    0.004    0.000    0.009    0.000 serialization.py:513(persistent_load)\n",
       "     2280    0.004    0.000    0.004    0.000 train_misc.py:93(__init__)\n",
       "      760    0.004    0.000    0.004    0.000 dataloader.py:715(__del__)\n",
       "     3830    0.004    0.000    0.006    0.000 utils.py:75(<lambda>)\n",
       "     1706    0.004    0.000    0.024    0.000 <frozen importlib._bootstrap>:147(__enter__)\n",
       "     3425    0.004    0.000    0.004    0.000 {built-in method _imp.lock_held}\n",
       "       14    0.004    0.000    0.004    0.000 {built-in method sqrt}\n",
       "      785    0.004    0.000    0.081    0.000 <frozen importlib._bootstrap_external>:485(_compile_bytecode)\n",
       "     3488    0.004    0.000    0.005    0.000 utils.py:77(<lambda>)\n",
       "     3488    0.003    0.000    0.005    0.000 utils.py:83(<lambda>)\n",
       "     2080    0.003    0.000    0.006    0.000 __init__.py:1972(dist_factory)\n",
       "    382/1    0.003    0.000    0.023    0.023 module.py:185(_apply)\n",
       "      824    0.003    0.000    0.008    0.000 <frozen importlib._bootstrap>:318(__exit__)\n",
       "        1    0.003    0.003    0.017    0.017 {built-in method torch._C._initExtension}\n",
       "     6330    0.003    0.000    0.003    0.000 {method 'lower' of 'str' objects}\n",
       "      824    0.003    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:524(spec_from_file_location)\n",
       "      776    0.003    0.000    0.004    0.000 {method 'sort' of 'list' objects}\n",
       "      380    0.003    0.000    0.003    0.000 {method 'permute' of 'torch._C._TensorBase' objects}\n",
       "      320    0.003    0.000    0.055    0.000 __init__.py:2481(from_location)\n",
       "        1    0.003    0.003    0.003    0.003 {built-in method _posixsubprocess.fork_exec}\n",
       "     4956    0.003    0.000    0.004    0.000 sre_parse.py:248(match)\n",
       "     2612    0.003    0.000    0.063    0.000 <frozen importlib._bootstrap_external>:94(_path_isfile)\n",
       "  824/818    0.003    0.000    0.237    0.000 <frozen importlib._bootstrap>:564(module_from_spec)\n",
       "      490    0.003    0.000    0.011    0.000 storage.py:40(clone)\n",
       "     1570    0.003    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:63(_path_split)\n",
       "      628    0.003    0.000    0.073    0.000 __init__.py:2027(distributions_from_metadata)\n",
       "   785/20    0.003    0.000    2.563    0.128 <frozen importlib._bootstrap_external>:672(exec_module)\n",
       "     1799    0.003    0.000    0.027    0.000 __init__.py:829(__setitem__)\n",
       "     3814    0.003    0.000    0.003    0.000 utils.py:61(__init__)\n",
       "      760    0.003    0.000    0.003    0.000 {method 'flush' of '_io.BufferedRandom' objects}\n",
       "     3775    0.003    0.000    0.003    0.000 {method 'endswith' of 'str' objects}\n",
       "     3185    0.003    0.000    0.004    0.000 sre_parse.py:171(append)\n",
       "      107    0.003    0.000    0.705    0.007 event_file_writer.py:35(__init__)\n",
       "      380    0.003    0.000    0.007    0.000 sampler.py:50(__init__)\n",
       "     3499    0.003    0.000    0.004    0.000 inspect.py:2779(<genexpr>)\n",
       "     1153    0.003    0.000    0.119    0.000 PngImagePlugin.py:685(write)\n",
       "      900    0.003    0.000    0.006    0.000 copy.py:268(_reconstruct)\n",
       "      380    0.003    0.000    0.003    0.000 summary.py:59(_calc_scale_factor)\n",
       "      820    0.003    0.000    0.003    0.000 optimizer.py:83(<dictcomp>)\n",
       "     2603    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap>:847(__exit__)\n",
       "      380    0.003    0.000    0.003    0.000 {built-in method PIL._imaging.jpeg_encoder}\n",
       "     2952    0.003    0.000    0.004    0.000 sre_parse.py:159(__len__)\n",
       "     2297    0.003    0.000    0.003    0.000 {method 'match' of '_sre.SRE_Pattern' objects}\n",
       "     2603    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap>:843(__enter__)\n",
       "      636    0.003    0.000    0.017    0.000 sre_compile.py:223(_compile_charset)\n",
       "  980/245    0.003    0.000    0.007    0.000 optimizer.py:122(cast)\n",
       "      320    0.002    0.000    0.006    0.000 __init__.py:683(add)\n",
       "      373    0.002    0.000    0.006    0.000 colors.py:184(_to_rgba_no_colorcycle)\n",
       "      172    0.002    0.000    0.003    0.000 init.py:178(_calculate_fan_in_and_fan_out)\n",
       "      822    0.002    0.000    0.017    0.000 <frozen importlib._bootstrap_external>:361(_get_cached)\n",
       "     1706    0.002    0.000    0.008    0.000 <frozen importlib._bootstrap>:151(__exit__)\n",
       "      824    0.002    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:1228(_get_spec)\n",
       "      380    0.002    0.000    0.007    0.000 sampler.py:33(__iter__)\n",
       "      820    0.002    0.000    0.229    0.000 optimizer.py:86(<listcomp>)\n",
       "     2458    0.002    0.000    0.003    0.000 sre_parse.py:285(tell)\n",
       "      313    0.002    0.000    0.004    0.000 functools.py:44(update_wrapper)\n",
       "       98    0.002    0.000    0.035    0.000 conv.py:17(__init__)\n",
       "      381    0.002    0.000    0.003    0.000 sampler.py:142(__init__)\n",
       "      352    0.002    0.000    0.005    0.000 inspect.py:2832(_hash_basis)\n",
       "    248/1    0.002    0.000    0.045    0.045 copy.py:236(_deepcopy_dict)\n",
       "       64    0.002    0.000    0.011    0.000 colors.py:713(from_list)\n",
       "    409/1    0.002    0.000    0.182    0.182 module.py:746(load)\n",
       "       33    0.002    0.000    0.002    0.000 {built-in method builtins.dir}\n",
       "      410    0.002    0.000    0.031    0.000 artist.py:1142(get_valid_values)\n",
       "     2992    0.002    0.000    0.002    0.000 version.py:207(<genexpr>)\n",
       "     1076    0.002    0.000    0.034    0.000 version.py:24(parse)\n",
       "     1607    0.002    0.000    0.019    0.000 <frozen importlib._bootstrap>:403(cached)\n",
       "      380    0.002    0.000    0.032    0.000 Image.py:1083(copy)\n",
       "      214    0.002    0.000    0.002    0.000 crc32c.py:77(crc_update)\n",
       "     4696    0.002    0.000    0.002    0.000 inspect.py:2500(name)\n",
       "     3828    0.002    0.000    0.002    0.000 {method 'partition' of 'str' objects}\n",
       "     2958    0.002    0.000    0.002    0.000 {built-in method torch._C.set_grad_enabled}\n",
       "       12    0.002    0.000    0.004    0.000 artist.py:1125(<listcomp>)\n",
       "      762    0.002    0.000    0.002    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "      107    0.002    0.000    0.908    0.008 event_file_writer.py:90(__init__)\n",
       "      326    0.002    0.000    0.048    0.000 __init__.py:2094(_handle_ns)\n",
       "     1694    0.002    0.000    0.003    0.000 serialization.py:502(maybe_decode_ascii)\n",
       "     4226    0.002    0.000    0.002    0.000 utils.py:94(<lambda>)\n",
       "      691    0.002    0.000    0.020    0.000 __init__.py:2647(_get_metadata)\n",
       "       16    0.002    0.000    0.002    0.000 {method 'AddSerializedFile' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "     1870    0.002    0.000    0.006    0.000 version.py:53(__eq__)\n",
       "        1    0.002    0.002    0.003    0.003 packages.py:1(<module>)\n",
       "      380    0.002    0.000    0.003    0.000 JpegImagePlugin.py:626(<listcomp>)\n",
       "     3296    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:321(<genexpr>)\n",
       "      222    0.002    0.000    0.008    0.000 sre_compile.py:482(_compile_info)\n",
       "      848    0.002    0.000    0.047    0.000 __init__.py:108(import_module)\n",
       "        1    0.002    0.002    0.030    0.030 binding.py:81(build_conditional_library)\n",
       "      144    0.002    0.000    0.002    0.000 {method 'splitlines' of 'str' objects}\n",
       "     1870    0.002    0.000    0.006    0.000 version.py:47(__lt__)\n",
       "     1536    0.002    0.000    0.005    0.000 colors.py:116(_is_nth_color)\n",
       "      380    0.002    0.000    0.003    0.000 utils.py:102(<listcomp>)\n",
       "     2210    0.002    0.000    0.003    0.000 inspect.py:159(isfunction)\n",
       "     2049    0.002    0.000    0.002    0.000 {method 'upper' of 'str' objects}\n",
       "     1045    0.002    0.000    0.011    0.000 colors.py:150(to_rgba)\n",
       "     1570    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:52(_r_long)\n",
       "       94    0.002    0.000    0.002    0.000 function.py:89(__init__)\n",
       "      330    0.002    0.000    0.007    0.000 __init__.py:1958(<genexpr>)\n",
       "      816    0.002    0.000    0.004    0.000 module.py:11(_addindent)\n",
       "      452    0.002    0.000    0.026    0.000 __init__.py:1323(safe_version)\n",
       "      222    0.002    0.000    0.186    0.001 sre_compile.py:557(compile)\n",
       "      452    0.002    0.000    0.005    0.000 version.py:236(__str__)\n",
       "        1    0.002    0.002    0.002    0.002 {built-in method normal}\n",
       "     1195    0.002    0.000    0.004    0.000 _weakrefset.py:58(__iter__)\n",
       "     1152    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:369(__init__)\n",
       "     1380    0.002    0.000    0.004    0.000 re.py:169(match)\n",
       "      785    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:393(_check_name_wrapper)\n",
       "      760    0.002    0.000    0.002    0.000 {built-in method builtins.round}\n",
       "     1115    0.002    0.000    0.002    0.000 __init__.py:119(is_tensor)\n",
       "      956    0.002    0.000    0.003    0.000 __init__.py:2540(key)\n",
       "      107    0.002    0.000    0.043    0.000 record_writer.py:114(write)\n",
       "     4076    0.002    0.000    0.002    0.000 inspect.py:2512(kind)\n",
       "       12    0.002    0.000    0.009    0.001 artist.py:1114(get_aliases)\n",
       "      785    0.002    0.000    0.034    0.000 <frozen importlib._bootstrap_external>:840(path_stats)\n",
       "     1888    0.002    0.000    0.002    0.000 sre_parse.py:111(__init__)\n",
       "     2303    0.002    0.000    0.002    0.000 {method 'replace' of 'str' objects}\n",
       "       57    0.002    0.000    1.552    0.027 __init__.py:1(<module>)\n",
       "      342    0.002    0.000    0.147    0.000 __init__.py:1940(find_on_path)\n",
       "      740    0.002    0.000    0.002    0.000 copy.py:252(_keep_alive)\n",
       "  1093/21    0.002    0.000    2.491    0.119 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
       "      816    0.001    0.000    0.003    0.000 sre_compile.py:388(_simple)\n",
       "      150    0.001    0.000    0.025    0.000 utils.py:89(verify_interface)\n",
       "  849/848    0.001    0.000    0.045    0.000 <frozen importlib._bootstrap>:982(_gcd_import)\n",
       "   550/61    0.001    0.000    1.861    0.031 {built-in method builtins.__import__}\n",
       "     1586    0.001    0.000    0.002    0.000 {method 'update' of 'dict' objects}\n",
       "        1    0.001    0.001    1.031    1.031 serialization.py:385(_load)\n",
       "     1255    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
       "      785    0.001    0.000    0.001    0.000 {built-in method _imp._fix_co_filename}\n",
       "        2    0.001    0.001    2.167    1.084 cifar.py:49(__init__)\n",
       "     1592    0.001    0.000    0.002    0.000 artist.py:1225(is_alias)\n",
       "      492    0.001    0.000    0.010    0.000 rcsetup.py:358(validate_color)\n",
       "     1111    0.001    0.000    0.013    0.000 <frozen importlib._bootstrap_external>:1080(_path_importer_cache)\n",
       "      335    0.001    0.000    0.001    0.000 pyparsing.py:1144(__init__)\n",
       "     1706    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:143(__init__)\n",
       "      781    0.001    0.000    0.001    0.000 {method 'split' of '_sre.SRE_Pattern' objects}\n",
       "      380    0.001    0.000    2.617    0.007 module.py:992(eval)\n",
       "       50    0.001    0.000    0.015    0.000 traceback.py:319(extract)\n",
       "     3383    0.001    0.000    0.001    0.000 {built-in method builtins.ord}\n",
       "      490    0.001    0.000    0.012    0.000 storage.py:24(__deepcopy__)\n",
       "     1570    0.001    0.000    0.001    0.000 {built-in method from_bytes}\n",
       "     2899    0.001    0.000    0.001    0.000 {method 'isidentifier' of 'str' objects}\n",
       "      744    0.001    0.000    0.271    0.000 utils.py:22(<lambda>)\n",
       "      760    0.001    0.000    0.003    0.000 _util.py:10(isPath)\n",
       "      847    0.001    0.000    0.054    0.000 _utils.py:134(_rebuild_tensor_v2)\n",
       "      222    0.001    0.000    0.098    0.000 sre_parse.py:844(parse)\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method randn}\n",
       "       39    0.001    0.000    0.010    0.000 __init__.py:1638(param)\n",
       "       31    0.001    0.000    0.003    0.000 auto.py:107(_make_function_class)\n",
       "      848    0.001    0.000    0.204    0.000 <frozen importlib._bootstrap_external>:1149(find_spec)\n",
       "      748    0.001    0.000    0.002    0.000 __init__.py:2688(__getattr__)\n",
       "      787    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:35(_new_module)\n",
       "     3512    0.001    0.000    0.001    0.000 {built-in method builtins.callable}\n",
       "      537    0.001    0.000    0.004    0.000 __init__.py:2281(yield_lines)\n",
       "      380    0.001    0.000    0.001    0.000 {built-in method math.ceil}\n",
       "      106    0.001    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:1196(__init__)\n",
       "      282    0.001    0.000    0.004    0.000 function_base.py:3895(add_newdoc)\n",
       "     1758    0.001    0.000    0.001    0.000 version.py:244(<genexpr>)\n",
       "      760    0.001    0.000    0.018    0.000 version.py:74(__init__)\n",
       "      107    0.001    0.000    0.656    0.006 record_writer.py:46(open_file)\n",
       "     2304    0.001    0.000    0.001    0.000 version.py:298(_parse_letter_version)\n",
       "      326    0.001    0.000    0.001    0.000 module.py:17(<listcomp>)\n",
       "      147    0.001    0.000    0.001    0.000 enum.py:353(__setattr__)\n",
       "   260/11    0.001    0.000    0.005    0.000 pyparsing.py:1380(_parseNoCache)\n",
       "       60    0.001    0.000    0.002    0.000 function_base.py:25(linspace)\n",
       "     1890    0.001    0.000    0.001    0.000 {method 'find' of 'bytearray' objects}\n",
       "  960/152    0.001    0.000    0.014    0.000 {built-in method builtins.repr}\n",
       "      380    0.001    0.000    0.001    0.000 {built-in method PIL._imaging.zip_encoder}\n",
       "      847    0.001    0.000    0.002    0.000 serialization.py:401(restore_location)\n",
       "      451    0.001    0.000    0.002    0.000 artist.py:1204(_replace_path)\n",
       "       88    0.001    0.000    0.005    0.000 abc.py:132(__new__)\n",
       "      323    0.001    0.000    0.041    0.000 <frozen importlib._bootstrap_external>:413(_find_module_shim)\n",
       "      900    0.001    0.000    0.001    0.000 {method '__reduce_ex__' of 'object' objects}\n",
       "      531    0.001    0.000    0.001    0.000 _weakrefset.py:36(__init__)\n",
       "      314    0.001    0.000    0.035    0.000 __init__.py:1935(<listcomp>)\n",
       "      900    0.001    0.000    0.002    0.000 copyreg.py:87(__newobj__)\n",
       "      214    0.001    0.000    0.004    0.000 record_writer.py:127(masked_crc32c)\n",
       "      121    0.001    0.000    0.004    0.000 __init__.py:1521(_get)\n",
       "      159    0.001    0.000    0.002    0.000 __init__.py:2772(<listcomp>)\n",
       "        1    0.001    0.001    0.002    0.002 descriptor_pb2.py:4(<module>)\n",
       "      849    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:917(_sanity_check)\n",
       "      393    0.001    0.000    0.002    0.000 inspect.py:485(unwrap)\n",
       "      760    0.001    0.000    0.001    0.000 scatter_gather.py:20(<listcomp>)\n",
       "      848    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap>:780(find_spec)\n",
       "      107    0.001    0.000    0.003    0.000 queue.py:27(__init__)\n",
       "      388    0.001    0.000    0.004    0.000 __init__.py:1468(_fn)\n",
       "     1049    0.001    0.000    0.001    0.000 sre_parse.py:81(groups)\n",
       "      341    0.001    0.000    0.002    0.000 warnings.py:159(_add_filter)\n",
       "       11    0.001    0.000    0.068    0.006 artist.py:1268(pprint_setters)\n",
       "      824    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:311(__enter__)\n",
       "      314    0.001    0.000    0.039    0.000 __init__.py:1929(_by_version)\n",
       "      126    0.001    0.000    0.006    0.000 deprecation.py:178(deprecate)\n",
       "      320    0.001    0.000    0.022    0.000 __init__.py:2468(__init__)\n",
       "     1015    0.001    0.000    0.002    0.000 sre_compile.py:102(fixup)\n",
       "     1940    0.001    0.000    0.003    0.000 __init__.py:2248(_normalize_cached)\n",
       "       25    0.001    0.000    0.014    0.001 __init__.py:357(namedtuple)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:48(<lambda>)\n",
       "      438    0.001    0.000    0.003    0.000 re.py:184(sub)\n",
       "     1176    0.001    0.000    0.001    0.000 {method 'pop' of 'dict' objects}\n",
       "       68    0.001    0.000    0.001    0.000 {built-in method posix.lstat}\n",
       "        8    0.001    0.000    0.001    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method torch._C._c10d_init}\n",
       "     1260    0.001    0.000    0.001    0.000 colors.py:236(<genexpr>)\n",
       "       98    0.001    0.000    0.019    0.000 conv.py:45(reset_parameters)\n",
       "     1499    0.001    0.000    0.001    0.000 {built-in method _sre.getlower}\n",
       "        3    0.001    0.000    0.388    0.129 __init__.py:9(<module>)\n",
       "      760    0.001    0.000    0.019    0.000 Image.py:370(preinit)\n",
       "      380    0.001    0.000    0.004    0.000 sampler.py:168(__len__)\n",
       "      471    0.001    0.000    0.009    0.000 pyparsing.py:1167(copy)\n",
       "      107    0.001    0.000    0.165    0.002 record_writer.py:35(directory_check)\n",
       "       16    0.001    0.000    0.004    0.000 enum.py:124(__new__)\n",
       "     1096    0.001    0.000    0.001    0.000 inspect.py:2833(<genexpr>)\n",
       "      760    0.001    0.000    0.001    0.000 ImageFile.py:65(_tilesort)\n",
       "      106    0.001    0.000    0.016    0.000 <frozen importlib._bootstrap_external>:1281(_fill_cache)\n",
       "        1    0.001    0.001    0.797    0.797 writer.py:246(__init__)\n",
       "      129    0.001    0.000    0.001    0.000 inspect.py:614(cleandoc)\n",
       "      196    0.001    0.000    0.002    0.000 conv.py:53(extra_repr)\n",
       "      787    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:800(__init__)\n",
       "     1329    0.001    0.000    0.001    0.000 {method 'setdefault' of 'dict' objects}\n",
       "      159    0.001    0.000    0.004    0.000 __init__.py:2746(insert_on)\n",
       "      100    0.001    0.000    0.017    0.000 init.py:261(kaiming_uniform_)\n",
       "      275    0.001    0.000    0.002    0.000 module.py:122(register_parameter)\n",
       "      490    0.001    0.000    0.002    0.000 __init__.py:219(__init__)\n",
       "      848    0.001    0.000    0.001    0.000 {built-in method _imp.is_frozen}\n",
       "      355    0.001    0.000    0.001    0.000 warnings.py:449(__enter__)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:54(<lambda>)\n",
       "      490    0.001    0.000    0.006    0.000 utils.py:6(parse)\n",
       "      380    0.001    0.000    0.001    0.000 PngImagePlugin.py:681(__init__)\n",
       "     1526    0.001    0.000    0.001    0.000 _structures.py:33(__neg__)\n",
       "      409    0.001    0.000    0.001    0.000 module.py:684(<dictcomp>)\n",
       "      407    0.001    0.000    0.001    0.000 _weakrefset.py:26(__exit__)\n",
       "      159    0.001    0.000    0.043    0.000 __init__.py:2193(fixup_namespace_packages)\n",
       "      491    0.001    0.000    0.008    0.000 colors.py:121(is_color_like)\n",
       "      492    0.001    0.000    0.016    0.000 train_misc.py:86(<genexpr>)\n",
       "       31    0.001    0.000    0.006    0.000 {built-in method builtins.eval}\n",
       "        2    0.001    0.000    0.002    0.001 __init__.py:1420(register_all)\n",
       "      245    0.001    0.000    0.006    0.000 optimizer.py:132(<dictcomp>)\n",
       "      272    0.001    0.000    0.002    0.000 enum.py:797(__or__)\n",
       "      429    0.001    0.000    0.009    0.000 pyparsing.py:1177(copy)\n",
       "        1    0.001    0.001    0.005    0.005 pyplot.py:2043(_setup_pyplot_info_docstrings)\n",
       "      297    0.001    0.000    0.002    0.000 sre_parse.py:84(opengroup)\n",
       "        3    0.001    0.000    0.002    0.001 six.py:1(<module>)\n",
       "     1828    0.001    0.000    0.001    0.000 inspect.py:2504(default)\n",
       "       31    0.001    0.000    0.011    0.000 _collections_abc.py:824(update)\n",
       "      479    0.001    0.000    0.027    0.000 re.py:179(search)\n",
       "      335    0.001    0.000    0.003    0.000 warnings.py:143(simplefilter)\n",
       "      380    0.001    0.000    0.001    0.000 {method 'fileno' of '_io.BufferedRandom' objects}\n",
       "       24    0.001    0.000    0.154    0.006 __init__.py:609(add_entry)\n",
       "      275    0.001    0.000    0.001    0.000 {built-in method _codecs.utf_8_decode}\n",
       "      212    0.001    0.000    0.004    0.000 __init__.py:540(dedent)\n",
       "     1484    0.001    0.000    0.001    0.000 copy.py:190(_deepcopy_atomic)\n",
       "      400    0.001    0.000    0.001    0.000 sre_parse.py:342(_escape)\n",
       "      760    0.001    0.000    0.001    0.000 {method 'cleanup' of 'ImagingEncoder' objects}\n",
       "      316    0.001    0.000    0.003    0.000 genericpath.py:39(isdir)\n",
       "        1    0.001    0.001    0.004    0.004 caffe2_pb2.py:4(<module>)\n",
       "     1387    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:41(_relax_case)\n",
       "      222    0.001    0.000    0.085    0.000 sre_compile.py:542(_code)\n",
       "       28    0.001    0.000    0.007    0.000 batchnorm.py:19(__init__)\n",
       "      824    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:307(__init__)\n",
       "      130    0.001    0.000    0.001    0.000 {method 'findall' of '_sre.SRE_Pattern' objects}\n",
       "       14    0.001    0.000    0.040    0.003 odefunc.py:99(__init__)\n",
       "      159    0.001    0.000    0.058    0.000 __init__.py:2652(activate)\n",
       "      232    0.001    0.000    0.001    0.000 pyparsing.py:1154(__init__)\n",
       "      132    0.001    0.000    0.025    0.000 __init__.py:2451(_version_from_file)\n",
       "     1321    0.001    0.000    0.001    0.000 {method 'values' of 'mappingproxy' objects}\n",
       "      107    0.001    0.000    0.909    0.008 writer.py:162(__init__)\n",
       "      454    0.001    0.000    0.011    0.000 traceback.py:283(line)\n",
       "      133    0.001    0.000    0.002    0.000 pyparsing.py:3260(__init__)\n",
       "     1452    0.001    0.000    0.001    0.000 __init__.py:1997(__bool__)\n",
       "      355    0.001    0.000    0.001    0.000 warnings.py:468(__exit__)\n",
       "      176    0.001    0.000    0.006    0.000 inspect.py:2846(__eq__)\n",
       "      223    0.001    0.000    0.001    0.000 sre_parse.py:223(__init__)\n",
       "      267    0.001    0.000    0.006    0.000 __init__.py:1404(has_metadata)\n",
       "      365    0.001    0.000    0.001    0.000 {method 'remove' of 'list' objects}\n",
       "      576    0.001    0.000    0.001    0.000 <string>:12(__new__)\n",
       "       88    0.001    0.000    0.001    0.000 abc.py:135(<setcomp>)\n",
       "     1321    0.001    0.000    0.001    0.000 inspect.py:2809(parameters)\n",
       "      214    0.001    0.000    0.003    0.000 crc32c.py:114(crc32c)\n",
       "      243    0.001    0.000    0.001    0.000 sre_parse.py:294(_class_escape)\n",
       "       72    0.001    0.000    0.001    0.000 {built-in method tensor}\n",
       "      352    0.001    0.000    0.001    0.000 inspect.py:2836(<dictcomp>)\n",
       "      374    0.001    0.000    0.001    0.000 descriptor.py:524(__new__)\n",
       "      254    0.001    0.000    0.007    0.000 rcsetup.py:342(validate_color_for_prop_cycle)\n",
       "      396    0.001    0.000    0.001    0.000 __init__.py:2456(is_version_line)\n",
       "      266    0.001    0.000    0.001    0.000 {method 'decode' of 'bytes' objects}\n",
       "        1    0.001    0.001    0.001    0.001 case.py:297(_AssertLogsContext)\n",
       "      107    0.001    0.000    0.045    0.000 event_file_writer.py:54(write_event)\n",
       "        2    0.001    0.000    0.001    0.000 traceback.py:386(format)\n",
       "      357    0.001    0.000    0.016    0.000 module.py:260(<lambda>)\n",
       "      380    0.001    0.000    0.002    0.000 sampler.py:75(__len__)\n",
       "     1398    0.001    0.000    0.001    0.000 inspect.py:2508(annotation)\n",
       "      130    0.001    0.000    0.003    0.000 textwrap.py:414(dedent)\n",
       "        1    0.001    0.001    0.053    0.053 optimizer.py:95(load_state_dict)\n",
       "        2    0.001    0.000    0.001    0.000 {built-in method _openssl.SSL_library_init}\n",
       "      380    0.001    0.000    0.005    0.000 dataloader.py:821(__len__)\n",
       "      107    0.001    0.000    0.005    0.000 event_file_writer.py:159(__init__)\n",
       "      407    0.001    0.000    0.001    0.000 _weakrefset.py:20(__enter__)\n",
       "      121    0.001    0.000    0.006    0.000 __init__.py:1407(get_metadata)\n",
       "       59    0.001    0.000    0.001    0.000 posixpath.py:331(normpath)\n",
       "      162    0.001    0.000    0.010    0.000 abc.py:151(register)\n",
       "       21    0.001    0.000    0.001    0.000 {method 'read' of '_io.TextIOWrapper' objects}\n",
       "       66    0.001    0.000    0.004    0.000 argparse.py:1307(add_argument)\n",
       "        1    0.001    0.001    0.001    0.001 binding.py:96(Binding)\n",
       "       98    0.001    0.000    0.042    0.000 conv.py:307(__init__)\n",
       "      275    0.001    0.000    0.001    0.000 codecs.py:318(decode)\n",
       "      848    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:707(find_spec)\n",
       "       40    0.001    0.000    0.009    0.000 linecache.py:82(updatecache)\n",
       "      100    0.001    0.000    0.001    0.000 sre_compile.py:376(_mk_bitmap)\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method gc.collect}\n",
       "       75    0.001    0.000    0.001    0.000 cm.py:65(_reverse_cmap_spec)\n",
       "    102/2    0.001    0.000    0.002    0.001 pyparsing.py:1370(_parseNoCache)\n",
       "      237    0.001    0.000    0.010    0.000 linecache.py:15(getline)\n",
       "   268/71    0.001    0.000    0.008    0.000 typing.py:1145(__subclasscheck__)\n",
       "      125    0.001    0.000    0.001    0.000 enum.py:70(__setitem__)\n",
       "      100    0.001    0.000    0.001    0.000 sre_compile.py:378(<listcomp>)\n",
       "      320    0.001    0.000    0.003    0.000 __init__.py:1315(safe_name)\n",
       "      946    0.001    0.000    0.001    0.000 {built-in method builtins.chr}\n",
       "      107    0.001    0.000    0.657    0.006 record_writer.py:105(__init__)\n",
       "      132    0.000    0.000    0.001    0.000 deprecation.py:23(_generate_deprecation_message)\n",
       "      222    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
       "      100    0.000    0.000    0.001    0.000 init.py:8(calculate_gain)\n",
       "      323    0.000    0.000    0.039    0.000 <frozen importlib._bootstrap_external>:1216(find_loader)\n",
       "     1024    0.000    0.000    0.000    0.000 version.py:352(<lambda>)\n",
       "       66    0.000    0.000    0.001    0.000 argparse.py:157(__init__)\n",
       "       37    0.000    0.000    0.001    0.000 {built-in method _imp.exec_dynamic}\n",
       "      561    0.000    0.000    0.000    0.000 {method 'mro' of 'type' objects}\n",
       "      394    0.000    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:99(_path_isdir)\n",
       "       14    0.000    0.000    0.026    0.002 gate.py:49(__init__)\n",
       "       86    0.000    0.000    0.001    0.000 _oid.py:11(__init__)\n",
       "      393    0.000    0.000    0.022    0.000 inspect.py:3055(signature)\n",
       "      428    0.000    0.000    0.000    0.000 {method 'write' of '_io.BufferedWriter' objects}\n",
       "      490    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
       "      380    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
       "      177    0.000    0.000    0.010    0.000 rcsetup.py:69(f)\n",
       "      286    0.000    0.000    0.001    0.000 _tensor_docs.py:8(add_docstr_all)\n",
       "      366    0.000    0.000    0.001    0.000 rcsetup.py:118(validate_bool)\n",
       "        1    0.000    0.000    1.032    1.032 serialization.py:300(load)\n",
       "      381    0.000    0.000    0.001    0.000 train_misc.py:17(_set)\n",
       "       19    0.000    0.000    0.010    0.001 rcsetup.py:825(validate_cycler)\n",
       "      816    0.000    0.000    0.000    0.000 sre_parse.py:167(__setitem__)\n",
       "       82    0.000    0.000    0.001    0.000 pyparsing.py:3719(__init__)\n",
       "      393    0.000    0.000    0.021    0.000 inspect.py:2803(from_callable)\n",
       "      106    0.000    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:1322(path_hook_for_FileFinder)\n",
       "       83    0.000    0.000    0.001    0.000 pyparsing.py:3326(__init__)\n",
       "      444    0.000    0.000    0.001    0.000 sre_compile.py:539(isstring)\n",
       "      372    0.000    0.000    0.001    0.000 inspect.py:2559(__eq__)\n",
       "      222    0.000    0.000    0.001    0.000 sre_parse.py:828(fix_flags)\n",
       "     1051    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
       "      495    0.000    0.000    0.000    0.000 {built-in method torch._C._add_docstr}\n",
       "      848    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1202(<genexpr>)\n",
       "      101    0.000    0.000    0.002    0.000 font_manager.py:850(_json_decode)\n",
       "      132    0.000    0.000    0.026    0.000 __init__.py:2858(_reload_version)\n",
       "      149    0.000    0.000    0.031    0.000 utils.py:38(register_decorator)\n",
       "      519    0.000    0.000    0.000    0.000 module.py:538(remove_from)\n",
       "      297    0.000    0.000    0.006    0.000 sre_parse.py:96(closegroup)\n",
       "      824    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:424(has_location)\n",
       "      847    0.000    0.000    0.000    0.000 train_cnf_disentangle_rl_multiscale.py:621(<lambda>)\n",
       "      117    0.000    0.000    0.007    0.000 rcsetup.py:90(<listcomp>)\n",
       "      130    0.000    0.000    0.001    0.000 pyplot.py:1795(<genexpr>)\n",
       "      768    0.000    0.000    0.000    0.000 version.py:332(_parse_local_version)\n",
       "      267    0.000    0.000    0.003    0.000 __init__.py:1509(_has)\n",
       "       16    0.000    0.000    0.001    0.000 enum.py:160(<setcomp>)\n",
       "      785    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:669(create_module)\n",
       "       66    0.000    0.000    0.001    0.000 argparse.py:1444(_get_optional_kwargs)\n",
       "      785    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:825(get_filename)\n",
       "      884    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
       "        9    0.000    0.000    0.001    0.000 auto.py:14(_make_function_class_criterion)\n",
       "        1    0.000    0.000    0.033    0.033 auto.py:268(_generate_function_classes)\n",
       "  263/261    0.000    0.000    0.001    0.000 pyparsing.py:382(__init__)\n",
       "      642    0.000    0.000    0.000    0.000 record_writer.py:132(u32)\n",
       "      237    0.000    0.000    0.010    0.000 linecache.py:37(getlines)\n",
       "        1    0.000    0.000    0.001    0.001 step_stats_pb2.py:4(<module>)\n",
       "      374    0.000    0.000    0.000    0.000 {method 'FindFieldByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "      322    0.000    0.000    0.167    0.001 re.py:231(compile)\n",
       "      928    0.000    0.000    0.000    0.000 inspect.py:2813(return_annotation)\n",
       "      380    0.000    0.000    0.000    0.000 JpegImagePlugin.py:665(validate_qtables)\n",
       "       19    0.000    0.000    0.001    0.000 cycler.py:349(by_key)\n",
       "       14    0.000    0.000    0.033    0.002 cnf_gate.py:21(__init__)\n",
       "        1    0.000    0.000    0.728    0.728 _import_c_extension.py:3(<module>)\n",
       "      236    0.000    0.000    0.001    0.000 linecache.py:147(lazycache)\n",
       "       56    0.000    0.000    0.035    0.001 basic.py:152(__init__)\n",
       "       50    0.000    0.000    0.016    0.000 traceback.py:200(extract_stack)\n",
       "   114/58    0.000    0.000    0.001    0.000 typing.py:1164(__setattr__)\n",
       "      100    0.000    0.000    0.001    0.000 init.py:50(uniform_)\n",
       "  230/199    0.000    0.000    0.000    0.000 sre_compile.py:414(_get_literal_prefix)\n",
       "      818    0.000    0.000    0.000    0.000 module.py:1012(_get_name)\n",
       "        4    0.000    0.000    1.711    0.428 cifar.py:134(_check_integrity)\n",
       "       39    0.000    0.000    0.001    0.000 _inspect.py:142(formatargspec)\n",
       "      107    0.000    0.000    0.043    0.000 event_file_writer.py:63(_write_serialized_event)\n",
       "        1    0.000    0.000    0.015    0.015 mathtext.py:2738(<listcomp>)\n",
       "       60    0.000    0.000    0.003    0.000 six.py:837(wrapper)\n",
       "       26    0.000    0.000    0.002    0.000 tokenize.py:448(open)\n",
       "        6    0.000    0.000    0.006    0.001 patches.py:1830(_pprint_styles)\n",
       "   121/59    0.000    0.000    0.006    0.000 pyparsing.py:3431(<listcomp>)\n",
       "      355    0.000    0.000    0.000    0.000 warnings.py:428(__init__)\n",
       "      263    0.000    0.000    0.001    0.000 pyparsing.py:373(__new__)\n",
       "      178    0.000    0.000    0.001    0.000 _jit_internal.py:34(createResolutionCallback)\n",
       "      247    0.000    0.000    0.001    0.000 parameter.py:23(__new__)\n",
       "      247    0.000    0.000    0.000    0.000 {built-in method _make_subclass}\n",
       "       84    0.000    0.000    0.002    0.000 pyparsing.py:3390(__init__)\n",
       "   131/65    0.000    0.000    0.007    0.000 pyparsing.py:3363(copy)\n",
       "      490    0.000    0.000    0.000    0.000 __init__.py:231(__exit__)\n",
       "      160    0.000    0.000    0.059    0.000 __init__.py:3153(<genexpr>)\n",
       "       54    0.000    0.000    0.001    0.000 __init__.py:961(_open_file_or_url)\n",
       "        1    0.000    0.000    0.005    0.005 summary_pb2.py:4(<module>)\n",
       "      393    0.000    0.000    0.001    0.000 inspect.py:505(_is_wrapper)\n",
       "    40/39    0.000    0.000    0.003    0.000 typing.py:875(__extrahook__)\n",
       "       84    0.000    0.000    0.000    0.000 docstring.py:40(__call__)\n",
       "   121/59    0.000    0.000    0.007    0.000 pyparsing.py:3429(copy)\n",
       "      407    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)\n",
       "      107    0.000    0.000    0.001    0.000 os.py:664(__getitem__)\n",
       "      380    0.000    0.000    0.000    0.000 {method 'flush' of '_io.BytesIO' objects}\n",
       "      304    0.000    0.000    0.000    0.000 __init__.py:1837(__init__)\n",
       "      178    0.000    0.000    0.000    0.000 inspect.py:1493(currentframe)\n",
       "      432    0.000    0.000    0.000    0.000 colors.py:204(<genexpr>)\n",
       "      409    0.000    0.000    0.000    0.000 utils.py:47(__init__)\n",
       "      2/1    0.000    0.000    0.002    0.002 copy.py:210(_deepcopy_list)\n",
       "       30    0.000    0.000    0.000    0.000 {method 'readline' of '_io.BufferedReader' objects}\n",
       "   131/65    0.000    0.000    0.006    0.000 pyparsing.py:3365(<listcomp>)\n",
       "     72/4    0.000    0.000    0.002    0.001 pyparsing.py:1564(_parseCache)\n",
       "       66    0.000    0.000    0.001    0.000 pyparsing.py:3785(__init__)\n",
       "        1    0.000    0.000    0.022    0.022 pyparsing.py:75(<module>)\n",
       "      296    0.000    0.000    0.000    0.000 weakref.py:406(__setitem__)\n",
       "      100    0.000    0.000    0.003    0.000 init.py:251(_calculate_correct_fan)\n",
       "      350    0.000    0.000    0.001    0.000 pkgutil.py:402(get_importer)\n",
       "      490    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.FloatStorageBase' objects}\n",
       "      120    0.000    0.000    0.001    0.000 module.py:161(add_module)\n",
       "      582    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "      150    0.000    0.000    0.012    0.000 cm.py:81(_generate_cmap)\n",
       "        1    0.000    0.000    0.002    0.002 numerictypes.py:81(<module>)\n",
       "        1    0.000    0.000    0.246    0.246 pyplot.py:19(<module>)\n",
       "      145    0.000    0.000    0.001    0.000 inspect.py:714(getmodule)\n",
       "       33    0.000    0.000    0.001    0.000 __init__.py:1161(getLogger)\n",
       "        1    0.000    0.000    0.000    0.000 _cm_listed.py:1(<module>)\n",
       "      286    0.000    0.000    0.000    0.000 traceback.py:290(walk_stack)\n",
       "      445    0.000    0.000    0.000    0.000 {method '__subclasses__' of 'type' objects}\n",
       "        2    0.000    0.000    0.002    0.001 decoder.py:345(raw_decode)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.SSL_load_error_strings}\n",
       "       66    0.000    0.000    0.002    0.000 pyparsing.py:1843(__add__)\n",
       "        1    0.000    0.000    0.001    0.001 attr_value_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.037    0.037 pyparsing.py:76(<module>)\n",
       "      222    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
       "      276    0.000    0.000    0.000    0.000 functools.py:74(wraps)\n",
       "        1    0.000    0.000    0.004    0.004 core.py:21(<module>)\n",
       "      157    0.000    0.000    0.001    0.000 posixpath.py:64(isabs)\n",
       "      108    0.000    0.000    0.002    0.000 deprecation.py:237(finalize)\n",
       "      107    0.000    0.000    0.000    0.000 {built-in method _socket.gethostname}\n",
       "      490    0.000    0.000    0.000    0.000 __init__.py:223(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._autograd_init}\n",
       "        1    0.000    0.000    0.361    0.361 event_pb2.py:4(<module>)\n",
       "      407    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)\n",
       "       67    0.000    0.000    0.001    0.000 pyparsing.py:3456(__init__)\n",
       "      586    0.000    0.000    0.000    0.000 {built-in method _CheckCalledFromGeneratedFile}\n",
       "    63/11    0.000    0.000    0.005    0.000 pyparsing.py:3463(parseImpl)\n",
       "      168    0.000    0.000    0.000    0.000 typing.py:1089(__eq__)\n",
       "        2    0.000    0.000    0.016    0.008 {built-in method builtins.sum}\n",
       "     33/5    0.000    0.000    0.001    0.000 pyparsing.py:3385(streamline)\n",
       "       91    0.000    0.000    0.001    0.000 _jit_internal.py:105(weak_script_method)\n",
       "       57    0.000    0.000    0.000    0.000 sre_parse.py:266(getuntil)\n",
       "        1    0.000    0.000    0.006    0.006 mlab.py:155(<module>)\n",
       "       83    0.000    0.000    0.003    0.000 pyparsing.py:1821(__add__)\n",
       "      322    0.000    0.000    0.000    0.000 rcsetup.py:144(validate_float)\n",
       "        1    0.000    0.000    0.001    0.001 optimizer.py:174(add_param_group)\n",
       "      101    0.000    0.000    0.002    0.000 compilerop.py:137(check_linecache_ipython)\n",
       "    61/11    0.000    0.000    0.007    0.001 pyparsing.py:3288(leaveWhitespace)\n",
       "      107    0.000    0.000    0.000    0.000 writer.py:53(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:118(__repr__)\n",
       "      121    0.000    0.000    0.006    0.000 __init__.py:1413(get_metadata_lines)\n",
       "       87    0.000    0.000    0.001    0.000 _jit_internal.py:83(weak_script)\n",
       "      410    0.000    0.000    0.000    0.000 artist.py:1235(aliased_name)\n",
       "      101    0.000    0.000    0.001    0.000 linecache.py:53(checkcache)\n",
       "       33    0.000    0.000    0.001    0.000 container.py:187(extend)\n",
       "      168    0.000    0.000    0.003    0.000 docstring.py:90(dedent)\n",
       "        1    0.000    0.000 178682.463 178682.463 interactiveshell.py:2637(safe_execfile)\n",
       "        1    0.000    0.000    0.007    0.007 subprocess.py:1208(_execute_child)\n",
       "      160    0.000    0.000    0.000    0.000 __init__.py:666(__iter__)\n",
       "    58/10    0.000    0.000    0.007    0.001 pyparsing.py:3354(leaveWhitespace)\n",
       "      164    0.000    0.000    0.000    0.000 sre_compile.py:441(_get_charset_prefix)\n",
       "      380    0.000    0.000    0.000    0.000 {method 'close' of '_io.BytesIO' objects}\n",
       "      164    0.000    0.000    0.000    0.000 colors.py:439(__init__)\n",
       "      148    0.000    0.000    0.000    0.000 _oid.py:58(__hash__)\n",
       "      274    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "      166    0.000    0.000    0.000    0.000 six.py:141(__init__)\n",
       "        1    0.000    0.000    0.012    0.012 _axes.py:119(Axes)\n",
       "        4    0.000    0.000    0.000    0.000 numeric.py:2916(extend_all)\n",
       "      414    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
       "      321    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
       "       80    0.000    0.000    0.003    0.000 docstring.py:109(dedent_interpd)\n",
       "        1    0.000    0.000    0.044    0.044 extensions.py:5(<module>)\n",
       "       27    0.000    0.000    0.012    0.000 pyparsing.py:2816(__init__)\n",
       "       69    0.000    0.000    0.001    0.000 pyparsing.py:2412(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:104(_init)\n",
       "       60    0.000    0.000    0.000    0.000 rcsetup.py:72(<listcomp>)\n",
       "      168    0.000    0.000    0.000    0.000 typing.py:1019(_abc_negative_cache)\n",
       "      162    0.000    0.000    0.000    0.000 argparse.py:1282(_registry_get)\n",
       "       39    0.000    0.000    0.001    0.000 __init__.py:1563(_add_data_doc)\n",
       "       25    0.000    0.000    0.004    0.000 pyparsing.py:1250(setParseAction)\n",
       "        1    0.000    0.000    0.029    0.029 core.py:182(read_style_directory)\n",
       "       14    0.000    0.000    0.002    0.000 posixpath.py:393(_joinrealpath)\n",
       "        1    0.000    0.000    0.010    0.010 pyparsing.py:5399(pyparsing_common)\n",
       "      108    0.000    0.000    0.000    0.000 utils.py:33(read_only_property)\n",
       "        1    0.000    0.000    0.086    0.086 __init__.py:106(<module>)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:1364(_add_action)\n",
       "       28    0.000    0.000    0.001    0.000 batchnorm.py:43(reset_running_stats)\n",
       "        1    0.000    0.000    0.071    0.071 __init__.py:101(<module>)\n",
       "       61    0.000    0.000    0.005    0.000 pyparsing.py:3292(<listcomp>)\n",
       "      252    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.can_cast}\n",
       "        1    0.000    0.000    0.001    0.001 TiffTags.py:349(_populate)\n",
       "        1    0.000    0.000    0.000    0.000 layout_pb2.py:4(<module>)\n",
       "      107    0.000    0.000    0.000    0.000 threading.py:1136(daemon)\n",
       "        1    0.000    0.000    0.334    0.334 __init__.py:16(<module>)\n",
       "      266    0.000    0.000    0.000    0.000 pyparsing.py:3270(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 getlimits.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:933(<dictcomp>)\n",
       "        1    0.000    0.000    0.003    0.003 pyparsing.py:5028(_makeTags)\n",
       "      113    0.000    0.000    0.000    0.000 typing.py:1033(_abc_negative_cache_version)\n",
       "        3    0.000    0.000    0.152    0.051 functional.py:1(<module>)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:67(getargs)\n",
       "    37/34    0.000    0.000    0.199    0.006 <frozen importlib._bootstrap_external>:919(create_module)\n",
       "        1    0.000    0.000    0.000    0.000 _color_data.py:992(<dictcomp>)\n",
       "      168    0.000    0.000    0.000    0.000 rcsetup.py:59(__call__)\n",
       "      107    0.000    0.000    0.000    0.000 queue.py:199(_init)\n",
       "       32    0.000    0.000    0.000    0.000 __init__.py:1212(_fixupParents)\n",
       "       26    0.000    0.000    0.001    0.000 tokenize.py:355(detect_encoding)\n",
       "        1    0.000    0.000    0.051    0.051 add_newdocs.py:10(<module>)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1796(get_metadata)\n",
       "      126    0.000    0.000    0.000    0.000 colors.py:639(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:1896(_define_aliases)\n",
       "      393    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
       "       26    0.000    0.000    0.030    0.001 pyparsing.py:2779(__init__)\n",
       "       28    0.000    0.000    0.000    0.000 {built-in method ones}\n",
       "       12    0.000    0.000    0.001    0.000 pyparsing.py:2653(__init__)\n",
       "        1    0.000    0.000    0.003    0.003 kl.py:1(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 visdom_writer.py:13(_check_connection)\n",
       "      166    0.000    0.000    0.000    0.000 pyparsing.py:3336(<genexpr>)\n",
       "       75    0.000    0.000    0.000    0.000 codecs.py:308(__init__)\n",
       "        2    0.000    0.000    0.234    0.117 __init__.py:41(<module>)\n",
       "       79    0.000    0.000    0.000    0.000 sre_parse.py:784(_parse_flags)\n",
       "      364    0.000    0.000    0.000    0.000 module.py:1015(extra_repr)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1775(_parse_known_args)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:37(<listcomp>)\n",
       "      224    0.000    0.000    0.000    0.000 patches.py:1822(<genexpr>)\n",
       "      149    0.000    0.000    0.000    0.000 utils.py:37(register_interface)\n",
       "      111    0.000    0.000    0.000    0.000 _jit_internal.py:98(weak_module)\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:24(GimpPaletteFile)\n",
       "      120    0.000    0.000    0.001    0.000 pyparsing.py:2368(__init__)\n",
       "       28    0.000    0.000    0.002    0.000 batchnorm.py:49(reset_parameters)\n",
       "      236    0.000    0.000    0.000    0.000 traceback.py:243(__init__)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:580(_format_args)\n",
       "        1    0.000    0.000    0.001    0.001 _tensor_docs.py:1(<module>)\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:765(copy)\n",
       "       37    0.000    0.000    0.000    0.000 pyparsing.py:2852(parseImpl)\n",
       "      144    0.000    0.000    0.000    0.000 pyparsing.py:2226(__hash__)\n",
       "       10    0.000    0.000    0.005    0.001 pyparsing.py:2675(__init__)\n",
       "      113    0.000    0.000    0.000    0.000 os.py:742(encode)\n",
       "       48    0.000    0.000    0.050    0.001 genericpath.py:27(isfile)\n",
       "      282    0.000    0.000    0.000    0.000 {method 'zfill' of 'str' objects}\n",
       "        1    0.000    0.000    0.782    0.782 workspace.py:3(<module>)\n",
       "       19    0.000    0.000    0.001    0.000 path.py:96(__init__)\n",
       "       88    0.000    0.000    0.001    0.000 docstring.py:122(<lambda>)\n",
       "       27    0.000    0.000    0.001    0.000 core.py:172(iter_style_files)\n",
       "        1    0.000    0.000    0.048    0.048 rcsetup.py:15(<module>)\n",
       "        2    0.000    0.000    0.015    0.007 __init__.py:7(<module>)\n",
       "        1    0.000    0.000    0.007    0.007 utils.py:13(get_logger)\n",
       "       67    0.000    0.000    0.000    0.000 auto.py:95(_find_buffers)\n",
       "       54    0.000    0.000    0.000    0.000 pyparsing.py:2870(__str__)\n",
       "      164    0.000    0.000    0.000    0.000 abc.py:9(abstractmethod)\n",
       "       53    0.000    0.000    0.000    0.000 core.py:893(__init__)\n",
       "      100    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
       "      159    0.000    0.000    0.000    0.000 __init__.py:919(_added_new)\n",
       "      143    0.000    0.000    0.000    0.000 __init__.py:422(<genexpr>)\n",
       "     19/4    0.000    0.000    0.001    0.000 pyparsing.py:3319(streamline)\n",
       "        1    0.000    0.000    0.014    0.014 cm.py:19(<module>)\n",
       "       61    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.arange}\n",
       "       58    0.000    0.000    0.005    0.000 pyparsing.py:3358(<listcomp>)\n",
       "       41    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "       23    0.000    0.000    0.003    0.000 pyparsing.py:1049(_trim_arity)\n",
       "       65    0.000    0.000    0.000    0.000 enum.py:20(_is_descriptor)\n",
       "        1    0.000    0.000    0.003    0.003 markers.py:4(<module>)\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:2826(__str__)\n",
       "        1    0.000    0.000    0.018    0.018 pyparsing.py:5558(pyparsing_common)\n",
       "        6    0.000    0.000    0.000    0.000 getlimits.py:65(__init__)\n",
       "      121    0.000    0.000    0.000    0.000 pyparsing.py:1361(preParse)\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:68(RegisterMessage)\n",
       "      125    0.000    0.000    0.000    0.000 enum.py:28(_is_dunder)\n",
       "      143    0.000    0.000    0.000    0.000 __init__.py:420(<genexpr>)\n",
       "      312    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
       "        1    0.000    0.000    0.003    0.003 numeric.py:1(<module>)\n",
       "       27    0.000    0.000    0.004    0.000 pyparsing.py:1039(_trim_arity)\n",
       "      258    0.000    0.000    0.000    0.000 {method 'end' of '_sre.SRE_Match' objects}\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:299(_add_aliases)\n",
       "       37    0.000    0.000    0.001    0.000 contextlib.py:129(contextmanager)\n",
       "       27    0.000    0.000    0.035    0.001 __init__.py:1056(rc_params_from_file)\n",
       "       65    0.000    0.000    0.000    0.000 argparse.py:835(__init__)\n",
       "      170    0.000    0.000    0.000    0.000 pyparsing.py:2061(setWhitespaceChars)\n",
       "      204    0.000    0.000    0.000    0.000 patches.py:1815(<genexpr>)\n",
       "       48    0.000    0.000    0.001    0.000 pyparsing.py:3540(__init__)\n",
       "      277    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.add_docstring}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _ctypes.dlopen}\n",
       "       11    0.000    0.000    0.107    0.010 __init__.py:5(<module>)\n",
       "      103    0.000    0.000    0.000    0.000 TiffTags.py:26(__new__)\n",
       "        1    0.000    0.000    0.060    0.060 requirements.py:4(<module>)\n",
       "       63    0.000    0.000    0.000    0.000 rcsetup.py:429(validate_fontsize)\n",
       "       60    0.000    0.000    0.000    0.000 cm.py:60(<listcomp>)\n",
       "       66    0.000    0.000    0.001    0.000 argparse.py:1555(_add_action)\n",
       "       68    0.000    0.000    0.001    0.000 posixpath.py:168(islink)\n",
       "      148    0.000    0.000    0.000    0.000 utils.py:34(<lambda>)\n",
       "       59    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:861(_find_spec_legacy)\n",
       "       82    0.000    0.000    0.000    0.000 descriptor.py:281(__new__)\n",
       "        1    0.000    0.000    0.002    0.002 lapack.py:461(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 __init__.py:57(<module>)\n",
       "        4    0.000    0.000    0.025    0.006 __init__.py:3(<module>)\n",
       "       28    0.000    0.000    0.013    0.000 batchnorm.py:82(_load_from_state_dict)\n",
       "      164    0.000    0.000    0.000    0.000 rcsetup.py:399(validate_string)\n",
       "       34    0.000    0.000    0.000    0.000 enum.py:419(_get_mixins_)\n",
       "       35    0.000    0.000    0.000    0.000 sre_compile.py:393(_generate_overlap_table)\n",
       "       48    0.000    0.000    0.001    0.000 pyparsing.py:1948(__or__)\n",
       "       26    0.000    0.000    0.001    0.000 argparse.py:1822(take_action)\n",
       "        1    0.000    0.000    0.008    0.008 TiffImagePlugin.py:42(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3037(_find_adapter)\n",
       "        1    0.000    0.000    0.213    0.213 __init__.py:3126(_initialize_master_working_set)\n",
       "       30    0.000    0.000    0.000    0.000 tokenize.py:385(find_cookie)\n",
       "       31    0.000    0.000    0.000    0.000 cm.py:48(revcmap)\n",
       "        1    0.000    0.000    0.001    0.001 _torch_docs.py:1(<module>)\n",
       "       45    0.000    0.000    0.001    0.000 posixpath.py:369(abspath)\n",
       "      195    0.000    0.000    0.000    0.000 pyparsing.py:3392(<genexpr>)\n",
       "        1    0.000    0.000    0.019    0.019 __init__.py:72(<module>)\n",
       "      188    0.000    0.000    0.000    0.000 __init__.py:2498(_reload_version)\n",
       "       44    0.000    0.000    0.001    0.000 _inspect.py:98(getargspec)\n",
       "       83    0.000    0.000    0.000    0.000 pyparsing.py:2390(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 inspect.py:317(getmembers)\n",
       "       26    0.000    0.000    0.004    0.000 pyparsing.py:1047(extract_stack)\n",
       "      214    0.000    0.000    0.000    0.000 crc32c.py:100(crc_finalize)\n",
       "       72    0.000    0.000    0.000    0.000 pyparsing.py:1509(set)\n",
       "       19    0.000    0.000    0.000    0.000 path.py:193(_update_values)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2710(MaskedArray)\n",
       "       14    0.000    0.000    0.002    0.000 odefunc_rl.py:257(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:286(Verbose)\n",
       "    82/80    0.000    0.000    0.000    0.000 pyparsing.py:372(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 markers.py:165(MarkerStyle)\n",
       "       17    0.000    0.000    0.000    0.000 cycler.py:191(_from_iter)\n",
       "        1    0.000    0.000    0.003    0.003 core.py:47(<module>)\n",
       "       36    0.000    0.000    0.000    0.000 pyparsing.py:2434(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 argparse.py:1740(parse_known_args)\n",
       "       16    0.000    0.000    0.000    0.000 enum.py:464(_find_new_)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}\n",
       "        1    0.000    0.000    0.003    0.003 modules.py:283(sample)\n",
       "        1    0.000    0.000    0.003    0.003 graph_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:8(Categorical)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:120(<listcomp>)\n",
       "       26    0.000    0.000    0.000    0.000 argparse.py:2234(_get_values)\n",
       "        8    0.000    0.000    0.002    0.000 utils.py:1(<module>)\n",
       "        2    0.000    0.000    0.061    0.031 base.py:5(<module>)\n",
       "       16    0.000    0.000    0.005    0.000 rcsetup.py:740(cycler)\n",
       "        1    0.000    0.000    0.004    0.004 tensor_pb2.py:4(<module>)\n",
       "      125    0.000    0.000    0.000    0.000 enum.py:36(_is_sunder)\n",
       "      252    0.000    0.000    0.000    0.000 six.py:88(__init__)\n",
       "        2    0.000    0.000    0.005    0.002 ec.py:5(<module>)\n",
       "        1    0.000    0.000    0.099    0.099 crypto.py:1(<module>)\n",
       "        1    0.000    0.000    0.007    0.007 optimizer.py:32(__init__)\n",
       "       97    0.000    0.000    0.000    0.000 pyparsing.py:4781(<genexpr>)\n",
       "        1    0.000    0.000    0.016    0.016 __init__.py:184(<module>)\n",
       "       11    0.000    0.000    0.077    0.007 artist.py:1511(kwdoc)\n",
       "       30    0.000    0.000    0.002    0.000 activation.py:41(__init__)\n",
       "       32    0.000    0.000    0.000    0.000 __init__.py:1268(__init__)\n",
       "      160    0.000    0.000    0.000    0.000 cycler.py:227(<genexpr>)\n",
       "      145    0.000    0.000    0.000    0.000 inspect.py:64(ismodule)\n",
       "      302    0.000    0.000    0.000    0.000 __init__.py:907(__iter__)\n",
       "       32    0.000    0.000    0.000    0.000 copyreg.py:96(_slotnames)\n",
       "        1    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 oid.py:5(<module>)\n",
       "      211    0.000    0.000    0.000    0.000 {method 'start' of '_sre.SRE_Match' objects}\n",
       "        4    0.000    0.000    0.077    0.019 odenvp_conditional_rl_multiscale.py:200(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 types_pb2.py:4(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:930(__init__)\n",
       "    24/12    0.000    0.000    0.002    0.000 pyparsing.py:3613(parseImpl)\n",
       "       37    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:927(exec_module)\n",
       "        1    0.000    0.000    0.042    0.042 backend.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 figure.py:250(Figure)\n",
       "       66    0.000    0.000    0.001    0.000 argparse.py:2352(_get_formatter)\n",
       "       16    0.000    0.000    0.000    0.000 enum.py:114(__prepare__)\n",
       "      113    0.000    0.000    0.000    0.000 descriptor.py:690(__new__)\n",
       "       51    0.000    0.000    0.000    0.000 _internal.py:715(_ufunc_doc_signature_formatter)\n",
       "      163    0.000    0.000    0.000    0.000 _collections_abc.py:392(__subclasshook__)\n",
       "        1    0.000    0.000    0.024    0.024 keys.py:15(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 activation.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 node_def_pb2.py:4(<module>)\n",
       "       23    0.000    0.000    0.000    0.000 pyparsing.py:2742(__str__)\n",
       "       86    0.000    0.000    0.000    0.000 six.py:105(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 encode_asn1.py:5(<module>)\n",
       "       29    0.000    0.000    0.000    0.000 contextlib.py:59(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 case.py:1(<module>)\n",
       "       86    0.000    0.000    0.000    0.000 pyparsing.py:3505(<genexpr>)\n",
       "       55    0.000    0.000    0.000    0.000 rcsetup.py:939(_validate_linestyle)\n",
       "        3    0.000    0.000    0.111    0.037 __init__.py:6(<module>)\n",
       "       21    0.000    0.000    0.003    0.000 pyparsing.py:1260(setParseAction)\n",
       "       33    0.000    0.000    0.003    0.000 container.py:119(__init__)\n",
       "       24    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:1480(_pop_action_class)\n",
       "        2    0.000    0.000    0.000    0.000 traceback.py:367(from_list)\n",
       "       29    0.000    0.000    0.000    0.000 contextlib.py:85(__exit__)\n",
       "        1    0.000    0.000    0.014    0.014 connectionpool.py:1(<module>)\n",
       "      115    0.000    0.000    0.000    0.000 pyparsing.py:2175(__str__)\n",
       "      148    0.000    0.000    0.000    0.000 rcsetup.py:52(func)\n",
       "        1    0.000    0.000    0.004    0.004 plistlib.py:47(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _mathtext_data.py:1751(<dictcomp>)\n",
       "       60    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.result_type}\n",
       "        1    0.000    0.000    0.002    0.002 utils.py:4(<module>)\n",
       "       22    0.000    0.000    0.003    0.000 pyparsing.py:1057(extract_stack)\n",
       "       79    0.000    0.000    0.000    0.000 __init__.py:870(__getitem__)\n",
       "      172    0.000    0.000    0.000    0.000 {method 'ndimension' of 'torch._C._TensorBase' objects}\n",
       "       96    0.000    0.000    0.000    0.000 pyparsing.py:2153(__str__)\n",
       "       84    0.000    0.000    0.000    0.000 activation.py:617(extra_repr)\n",
       "       23    0.000    0.000    0.000    0.000 rcsetup.py:57(<dictcomp>)\n",
       "       30    0.000    0.000    0.000    0.000 rcsetup.py:288(__call__)\n",
       "      188    0.000    0.000    0.000    0.000 pyparsing.py:2656(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:79(Certificate)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:118(<dictcomp>)\n",
       "       92    0.000    0.000    0.000    0.000 textwrap.py:479(prefixed_lines)\n",
       "       36    0.000    0.000    0.001    0.000 __init__.py:1838(getLogger)\n",
       "      100    0.000    0.000    0.000    0.000 six.py:177(_add_module)\n",
       "      188    0.000    0.000    0.000    0.000 pyparsing.py:2678(<genexpr>)\n",
       "       82    0.000    0.000    0.000    0.000 pyparsing.py:363(__new__)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1813(get_metadata_lines)\n",
       "      189    0.000    0.000    0.000    0.000 status_codes.py:112(<genexpr>)\n",
       "        2    0.000    0.000    0.001    0.001 tensor.py:1(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 backend.py:13(register_function)\n",
       "        1    0.000    0.000    0.000    0.000 nanfunctions.py:22(<module>)\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:466(find)\n",
       "       14    0.000    0.000    0.043    0.003 odenvp_conditional_rl_multiscale.py:215(_make_odefunc)\n",
       "      8/6    0.000    0.000    0.007    0.001 __init__.py:2159(declare_namespace)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:573(format)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2474(CompositeAffine2D)\n",
       "        2    0.000    0.000    0.002    0.001 hashes.py:5(<module>)\n",
       "        1    0.000    0.000    0.148    0.148 pyopenssl.py:43(<module>)\n",
       "       45    0.000    0.000    0.000    0.000 pyparsing.py:1200(setName)\n",
       "       86    0.000    0.000    0.000    0.000 textwrap.py:476(predicate)\n",
       "      143    0.000    0.000    0.000    0.000 {method '__contains__' of 'frozenset' objects}\n",
       "        1    0.000    0.000    0.025    0.025 tokenize.py:26(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:663(__iadd__)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:50(__init__)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:15(ismethod)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:793(__init__)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:1493(_check_conflict)\n",
       "        2    0.000    0.000    0.001    0.001 function_base.py:1(<module>)\n",
       "        3    0.000    0.000    0.003    0.001 distributed.py:1(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 general_name.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 stringprep.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:308(init_reductions)\n",
       "       76    0.000    0.000    0.000    0.000 __init__.py:329(iterable)\n",
       "       26    0.000    0.000    0.001    0.000 argparse.py:1843(consume_optional)\n",
       "        1    0.000    0.000    0.030    0.030 utils.py:9(<module>)\n",
       "       28    0.000    0.000    0.000    0.000 pooling.py:24(extra_repr)\n",
       "       44    0.000    0.000    0.001    0.000 core.py:149(get_object_signature)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:564(_metavar_formatter)\n",
       "       30    0.000    0.000    0.000    0.000 sre_parse.py:257(getwhile)\n",
       "        1    0.000    0.000    0.026    0.026 grammar.py:13(<module>)\n",
       "        1    0.000    0.000    0.042    0.042 _axes.py:1(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 numerictypes.py:229(bitname)\n",
       "       15    0.000    0.000    0.000    0.000 pathlib.py:51(parse_parts)\n",
       "        1    0.000    0.000    0.002    0.002 resource_handle_pb2.py:4(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 {method 'FindMessageTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _mathtext_data.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method zeros_like}\n",
       "       26    0.000    0.000    0.000    0.000 argparse.py:2050(_match_argument)\n",
       "       48    0.000    0.000    0.000    0.000 traceback.py:273(__getitem__)\n",
       "      186    0.000    0.000    0.000    0.000 {method 'ljust' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:7(<module>)\n",
       "       38    0.000    0.000    0.000    0.000 colors.py:788(__init__)\n",
       "       97    0.000    0.000    0.000    0.000 pyparsing.py:4934(<genexpr>)\n",
       "       93    0.000    0.000    0.000    0.000 pyparsing.py:219(__init__)\n",
       "       60    0.000    0.000    0.000    0.000 pyparsing.py:1351(preParse)\n",
       "     10/2    0.000    0.000    0.002    0.001 pyparsing.py:3397(parseImpl)\n",
       "    36/11    0.000    0.000    0.009    0.001 pyparsing.py:3743(leaveWhitespace)\n",
       "        1    0.000    0.000    0.001    0.001 SSL.py:1(<module>)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:38(register_kl)\n",
       "       69    0.000    0.000    0.000    0.000 __init__.py:1265(<lambda>)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:61(__new__)\n",
       "       60    0.000    0.000    0.000    0.000 function_base.py:13(_index_deprecate)\n",
       "        1    0.000    0.000    0.079    0.079 odenvp_conditional_rl_multiscale.py:21(__init__)\n",
       "       28    0.000    0.000    0.007    0.000 gate.py:115(conv3x3)\n",
       "      137    0.000    0.000    0.000    0.000 pyparsing.py:2083(setWhitespaceChars)\n",
       "       66    0.000    0.000    0.001    0.000 argparse.py:1713(_add_action)\n",
       "        2    0.000    0.000    0.011    0.005 traceback.py:193(format_stack)\n",
       "       31    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _pylab_helpers.py:10(Gcf)\n",
       "        1    0.000    0.000    0.012    0.012 patches.py:1(<module>)\n",
       "       14    0.000    0.000    0.001    0.000 pooling.py:14(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:5(<module>)\n",
       "      126    0.000    0.000    0.000    0.000 deprecation.py:115(deprecated)\n",
       "       34    0.000    0.000    0.000    0.000 argparse.py:1278(register)\n",
       "        2    0.000    0.000    0.003    0.002 dh.py:5(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:85(RegisterMessageDescriptor)\n",
       "       14    0.000    0.000    0.002    0.000 __init__.py:2232(normalize_path)\n",
       "        1    0.000    0.000    0.000    0.000 dviread.py:173(Dvi)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:272(<setcomp>)\n",
       "       82    0.000    0.000    0.000    0.000 types.py:135(__get__)\n",
       "        2    0.000    0.000    0.007    0.003 rsa.py:5(<module>)\n",
       "      163    0.000    0.000    0.000    0.000 {method '__subclasshook__' of 'object' objects}\n",
       "        1    0.000    0.000    0.001    0.001 loss.py:1(<module>)\n",
       "        1    0.000    0.000    0.011    0.011 util.py:150(_get_soname)\n",
       "     20/8    0.000    0.000    0.001    0.000 pyparsing.py:3547(parseImpl)\n",
       "       68    0.000    0.000    0.000    0.000 status_codes.py:111(doc)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Url)\n",
       "      158    0.000    0.000    0.000    0.000 pyparsing.py:3458(<genexpr>)\n",
       "       29    0.000    0.000    0.000    0.000 typing.py:1039(_abc_negative_cache_version)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:5(<module>)\n",
       "       30    0.000    0.000    0.003    0.000 activation.py:81(__init__)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6573(getdoc)\n",
       "       21    0.000    0.000    0.000    0.000 pyparsing.py:2764(__str__)\n",
       "       30    0.000    0.000    0.011    0.000 __init__.py:826(__init__)\n",
       "       94    0.000    0.000    0.000    0.000 pyparsing.py:5043(<genexpr>)\n",
       "      101    0.000    0.000    0.000    0.000 _inspect.py:133(strseq)\n",
       "       39    0.000    0.000    0.001    0.000 inspect.py:2817(replace)\n",
       "      142    0.000    0.000    0.000    0.000 {method 'expandtabs' of 'str' objects}\n",
       "        1    0.000    0.000    0.017    0.017 mathtext.py:16(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 serialization.py:1(<module>)\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:1079(wrapper)\n",
       "    33/10    0.000    0.000    0.009    0.001 pyparsing.py:3809(leaveWhitespace)\n",
       "    13/12    0.000    0.000    0.028    0.002 <frozen importlib._bootstrap>:622(_load_backward_compatible)\n",
       "       45    0.000    0.000    0.000    0.000 pyparsing.py:1190(setName)\n",
       "       24    0.000    0.000    0.000    0.000 dviread.py:155(decorate)\n",
       "        1    0.000    0.000    0.012    0.012 lines.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _color_data.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:89(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:112(tqdm)\n",
       "        1    0.000    0.000    0.011    0.011 _big_num_ctypes.py:20(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 __init__.py:296(get_device_properties)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:71(Op)\n",
       "        1    0.000    0.000    0.002    0.002 dates.py:134(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 artist.py:32(allow_rasterization)\n",
       "       12    0.000    0.000    0.009    0.001 artist.py:1094(__init__)\n",
       "       47    0.000    0.000    0.000    0.000 pyparsing.py:2453(parseImpl)\n",
       "       28    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.putenv}\n",
       "      139    0.000    0.000    0.000    0.000 pyparsing.py:3543(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 poolmanager.py:1(<module>)\n",
       "       28    0.000    0.000    0.000    0.000 init.py:113(zeros_)\n",
       "       75    0.000    0.000    0.000    0.000 codecs.py:259(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tritools.py:10(TriAnalyzer)\n",
       "       29    0.000    0.000    0.000    0.000 typing.py:1025(_abc_negative_cache)\n",
       "       34    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
       "        1    0.000    0.000    0.373    0.373 writer.py:15(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 normalization.py:1(<module>)\n",
       "        1    0.000    0.000    0.007    0.007 Image.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:87(LookupDict)\n",
       "       38    0.000    0.000    0.000    0.000 constraint_registry.py:86(register)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:365(__getitem__)\n",
       "        1    0.000    0.000    0.001    0.001 TiffTags.py:20(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1569(FigureCanvasBase)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:74(__call__)\n",
       "       62    0.000    0.000    0.000    0.000 _inspect.py:146(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 versions_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(<listcomp>)\n",
       "        1    0.000    0.000    0.009    0.009 mbcsgroupprober.py:30(<module>)\n",
       "       44    0.000    0.000    0.000    0.000 pyparsing.py:3647(<genexpr>)\n",
       "       14    0.000    0.000    0.000    0.000 pathlib.py:631(_parse_args)\n",
       "       41    0.000    0.000    0.000    0.000 __init__.py:228(_releaseLock)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method torch.cuda._get_device_properties}\n",
       "       56    0.000    0.000    0.000    0.000 patches.py:1919(_register_style)\n",
       "      138    0.000    0.000    0.000    0.000 cycler.py:212(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:30(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 extras.py:10(<module>)\n",
       "      138    0.000    0.000    0.000    0.000 pyparsing.py:1376(postParse)\n",
       "       72    0.000    0.000    0.000    0.000 pyparsing.py:1506(get)\n",
       "      102    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 pygram.py:22(__init__)\n",
       "        2    0.000    0.000    0.372    0.186 __init__.py:33(<module>)\n",
       "        1    0.000    0.000    0.006    0.006 font_manager.py:21(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:409(_init)\n",
       "       20    0.000    0.000    0.003    0.000 pyparsing.py:4012(parseImpl)\n",
       "       55    0.000    0.000    0.000    0.000 rcsetup.py:667(__call__)\n",
       "        6    0.000    0.000    0.002    0.000 warnings.py:119(filterwarnings)\n",
       "       13    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:433(spec_from_loader)\n",
       "       28    0.000    0.000    0.000    0.000 {method '_set_from_file' of 'torch._C.LongStorageBase' objects}\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:83(<listcomp>)\n",
       "       15    0.000    0.000    0.000    0.000 pyparsing.py:4565(_escapeRegexRangeChars)\n",
       "       20    0.000    0.000    0.000    0.000 pyparsing.py:2813(parseImpl)\n",
       "       28    0.000    0.000    0.000    0.000 pyparsing.py:3997(__init__)\n",
       "        2    0.000    0.000    0.008    0.004 connection.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:7(Independent)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:69(decorator)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:7(OneHotCategorical)\n",
       "       44    0.000    0.000    0.000    0.000 typing.py:889(__extrahook__)\n",
       "        3    0.000    0.000    0.007    0.002 __init__.py:15(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 argparse.py:2190(_get_nargs_pattern)\n",
       "       60    0.000    0.000    0.000    0.000 {method 'copy' of 'mappingproxy' objects}\n",
       "       56    0.000    0.000    0.000    0.000 {method 'setter' of 'property' objects}\n",
       "        2    0.000    0.000    0.004    0.002 dsa.py:5(<module>)\n",
       "        2    0.000    0.000    0.006    0.003 transforms.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:88(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2923(<listcomp>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:1970(__or__)\n",
       "       30    0.000    0.000    0.000    0.000 argparse.py:2286(_get_value)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.unsetenv}\n",
       "        1    0.000    0.000    0.003    0.003 summary.py:30(<module>)\n",
       "        6    0.000    0.000    0.001    0.000 patches.py:1811(_pprint_table)\n",
       "       89    0.000    0.000    0.000    0.000 docstring.py:98(do_copy)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.Cryptography_add_osrandom_engine}\n",
       "        2    0.000    0.000    0.001    0.000 enum.py:366(_create_)\n",
       "       34    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
       "        1    0.000    0.000    0.001    0.001 matfuncs.py:5(<module>)\n",
       "        1    0.000    0.000    0.052    0.052 text.py:3(<module>)\n",
       "       17    0.000    0.000    0.000    0.000 cycler.py:55(_process_keys)\n",
       "        2    0.000    0.000    0.007    0.003 ocsp.py:5(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 rcsetup.py:906(validate_animation_writer_path)\n",
       "       27    0.000    0.000    0.000    0.000 locale.py:631(getpreferredencoding)\n",
       "       48    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
       "        1    0.000    0.000    0.077    0.077 odenvp_conditional_rl_multiscale.py:66(_build_net)\n",
       "       82    0.000    0.000    0.000    0.000 {method 'AddDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       78    0.000    0.000    0.000    0.000 pyparsing.py:2052(leaveWhitespace)\n",
       "        4    0.000    0.000    0.005    0.001 container.py:1(<module>)\n",
       "        1    0.000    0.000    0.016    0.016 cookiejar.py:26(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 chardistribution.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:1(<module>)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6568(__init__)\n",
       "       49    0.000    0.000    0.000    0.000 pyparsing.py:421(__getitem__)\n",
       "    34/26    0.000    0.000    0.000    0.000 pyparsing.py:3500(__str__)\n",
       "       86    0.000    0.000    0.000    0.000 rcsetup.py:201(validate_int)\n",
       "       26    0.000    0.000    0.000    0.000 argparse.py:1950(<listcomp>)\n",
       "       12    0.000    0.000    0.000    0.000 six.py:91(__get__)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2707(parseImpl)\n",
       "        1    0.000    0.000    0.002    0.002 modes.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 distributed_c10d.py:1(<module>)\n",
       "       33    0.000    0.000    0.001    0.000 container.py:159(__iadd__)\n",
       "       56    0.000    0.000    0.000    0.000 batchnorm.py:78(extra_repr)\n",
       "        1    0.000    0.000    0.007    0.007 subprocess.py:588(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:857(<listcomp>)\n",
       "       38    0.000    0.000    0.000    0.000 pyparsing.py:4230(__init__)\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3439(<genexpr>)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2263(_is_unpacked_egg)\n",
       "        1    0.000    0.000    0.000    0.000 _base.py:396(_AxesBase)\n",
       "        1    0.000    0.000    0.009    0.009 _base.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 texmanager.py:48(TexManager)\n",
       "        1    0.000    0.000    0.000    0.000 pyplot.py:2078(<listcomp>)\n",
       "       69    0.000    0.000    0.000    0.000 status_codes.py:117(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:94(_check_capability)\n",
       "        2    0.000    0.000    0.009    0.004 __init__.py:45(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2729(parseImpl)\n",
       "  109/105    0.000    0.000    0.001    0.000 __init__.py:409(wrapper)\n",
       "       28    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
       "        1    0.000    0.000    0.002    0.002 type_checkers.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 token.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:4(<module>)\n",
       "       24    0.000    0.000    0.001    0.000 __init__.py:1870(find_distributions)\n",
       "        1    0.000    0.000    0.032    0.032 odefunc.py:1(<module>)\n",
       "       17    0.000    0.000    0.000    0.000 cycler.py:112(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 interfaces.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:285(_add_types)\n",
       "        2    0.000    0.000    0.000    0.000 util.py:301(_findLib_prefix)\n",
       "       98    0.000    0.000    0.000    0.000 pyparsing.py:2181(streamline)\n",
       "        1    0.000    0.000    0.003    0.003 fontconfig_pattern.py:65(__init__)\n",
       "       39    0.000    0.000    0.000    0.000 __init__.py:1598(_preprocess_data)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
       "        1    0.000    0.000    0.041    0.041 collections.py:10(<module>)\n",
       "       89    0.000    0.000    0.000    0.000 docstring.py:96(copy)\n",
       "        1    0.000    0.000    0.005    0.005 cookies.py:127(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 exceptions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:1(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _hashlib.openssl_md5}\n",
       "       40    0.000    0.000    0.000    0.000 __init__.py:190(_checkLevel)\n",
       "       41    0.000    0.000    0.000    0.000 __init__.py:219(_acquireLock)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:52(__new__)\n",
       "        1    0.000    0.000    0.001    0.001 scale.py:1(<module>)\n",
       "       17    0.000    0.000    0.000    0.000 cycler.py:468(cycler)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:113(__init__)\n",
       "       29    0.000    0.000    0.000    0.000 contextlib.py:157(helper)\n",
       "        2    0.000    0.000    0.001    0.001 request.py:1(<module>)\n",
       "       94    0.000    0.000    0.000    0.000 pyparsing.py:4890(<genexpr>)\n",
       "        2    0.000    0.000    0.001    0.000 modules.py:96(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 cm.py:99(<dictcomp>)\n",
       "        1    0.000    0.000    0.130    0.130 colorbar.py:20(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 path.py:21(Path)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:109(has_argument)\n",
       "       78    0.000    0.000    0.000    0.000 _internal.py:726(<genexpr>)\n",
       "        1    0.000    0.000    0.005    0.005 _internal.py:6(<module>)\n",
       "       40    0.000    0.000    0.000    0.000 numerictypes.py:154(english_upper)\n",
       "       20    0.000    0.000    0.000    0.000 pyparsing.py:1589(resetCache)\n",
       "       11    0.000    0.000    0.006    0.001 pyparsing.py:1630(parseString)\n",
       "       18    0.000    0.000    0.001    0.000 pyparsing.py:4092(parseImpl)\n",
       "        3    0.000    0.000    0.000    0.000 util.py:136(register_after_fork)\n",
       "       66    0.000    0.000    0.000    0.000 argparse.py:202(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:48(<listcomp>)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:3120(<genexpr>)\n",
       "        1    0.000    0.000    0.072    0.072 figure.py:12(<module>)\n",
       "       45    0.000    0.000    0.000    0.000 docstring.py:44(update)\n",
       "       15    0.000    0.000    0.000    0.000 pyparsing.py:4170(__str__)\n",
       "        2    0.000    0.000    0.000    0.000 response.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 pooling.py:1(<module>)\n",
       "        1    0.000    0.000    0.114    0.114 thnn.py:21(_initialize_backend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:86(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 gettext.py:205(_expand_lang)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _struct.calcsize}\n",
       "        1    0.000    0.000    0.002    0.002 pytorch_graph.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:594(_ReducedHCT_Element)\n",
       "        6    0.000    0.000    0.000    0.000 patches.py:1822(<listcomp>)\n",
       "       95    0.000    0.000    0.000    0.000 cycler.py:138(keys)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:73(__init__)\n",
       "        1    0.000    0.000    0.005    0.005 algos.py:19(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:3606(__init__)\n",
       "        6    0.000    0.000    0.001    0.000 __init__.py:2707(from_filename)\n",
       "       27    0.000    0.000    0.000    0.000 pyparsing.py:4383(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 models.py:8(<module>)\n",
       "       62    0.000    0.000    0.000    0.000 numerictypes.py:127(english_lower)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1226(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 functools.py:479(decorating_function)\n",
       "        1    0.000    0.000    0.001    0.001 pyparsing.py:4875(_makeTags)\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3581(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 legend.py:307(Legend)\n",
       "       11    0.000    0.000    0.000    0.000 pyparsing.py:4718(_escapeRegexRangeChars)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:225(_register_default_ciphers)\n",
       "     23/7    0.000    0.000    0.001    0.000 pyparsing.py:3828(streamline)\n",
       "       52    0.000    0.000    0.000    0.000 argparse.py:2087(_parse_optional)\n",
       "        2    0.000    0.000    0.001    0.000 _distributor_init.py:10(<module>)\n",
       "        4    0.000    0.000    0.409    0.102 __init__.py:2(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 blas.py:202(<module>)\n",
       "        3    0.000    0.000    0.037    0.012 _util.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:126(EventHandle)\n",
       "       49    0.000    0.000    0.000    0.000 reduction.py:43(register)\n",
       "       95    0.000    0.000    0.000    0.000 pyparsing.py:203(<genexpr>)\n",
       "       16    0.000    0.000    0.006    0.000 __init__.py:2006(safe_listdir)\n",
       "        1    0.000    0.000    0.001    0.001 serialization.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1078(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:771(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 sre_compile.py:381(_bytes_to_codes)\n",
       "       37    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:908(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 six.py:126(__init__)\n",
       "       49    0.000    0.000    0.000    0.000 six.py:184(find_module)\n",
       "        1    0.000    0.000    0.001    0.001 PngImagePlugin.py:34(<module>)\n",
       "       43    0.000    0.000    0.000    0.000 caffe2_pb2.py:5(<lambda>)\n",
       "        3    0.000    0.000    0.029    0.010 odenvp_conditional_rl_multiscale.py:227(<listcomp>)\n",
       "       11    0.000    0.000    0.000    0.000 pyparsing.py:3851(__init__)\n",
       "        1    0.000    0.000    0.015    0.015 mathtext.py:2202(Parser)\n",
       "        1    0.000    0.000    0.002    0.002 patches.py:3102(ArrowStyle)\n",
       "        1    0.000    0.000    0.001    0.001 colors.py:61(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 sessions.py:9(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:1(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.empty}\n",
       "       23    0.000    0.000    0.000    0.000 numerictypes.py:216(_evalname)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:70(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:2853(_bind)\n",
       "        1    0.000    0.000    0.000    0.000 shutil.py:1093(which)\n",
       "       11    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:980(_recalculate)\n",
       "       24    0.000    0.000    0.000    0.000 __init__.py:1793(has_metadata)\n",
       "        1    0.000    0.000    0.362    0.362 event_file_writer.py:15(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 image.py:4(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 patches.py:1820(<genexpr>)\n",
       "        1    0.000    0.000    0.006    0.006 index_tricks.py:1(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 rcsetup.py:291(<listcomp>)\n",
       "       60    0.000    0.000    0.000    0.000 six.py:835(add_metaclass)\n",
       "       14    0.000    0.000    0.002    0.000 posixpath.py:384(realpath)\n",
       "       10    0.000    0.000    0.000    0.000 {method 'tolist' of 'memoryview' objects}\n",
       "        1    0.000    0.000    0.011    0.011 JpegImagePlugin.py:35(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 grammar.py:105(load)\n",
       "       25    0.000    0.000    0.000    0.000 pyparsing.py:4150(__init__)\n",
       "       20    0.000    0.000    0.002    0.000 pyparsing.py:4156(parseImpl)\n",
       "       12    0.000    0.000    0.000    0.000 Image.py:2810(register_extension)\n",
       "        1    0.000    0.000    0.003    0.003 adapters.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:170(<dictcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 exceptions.py:8(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 sbcsgroupprober.py:29(<module>)\n",
       "       27    0.000    0.000    0.000    0.000 core.py:920(__init__)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:26(_fr1)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:71(<lambda>)\n",
       "       30    0.000    0.000    0.000    0.000 tokenize.py:379(read_or_stop)\n",
       "        3    0.000    0.000    0.004    0.001 misc.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 extension_loader.py:16(DlopenGuard)\n",
       "        1    0.000    0.000    0.007    0.007 text_format.py:41(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 well_known_types.py:39(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 pyparsing.py:3164(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_svd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:55(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 mixins.py:30(_reflected_binary_method)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:28(isfunction)\n",
       "       36    0.000    0.000    0.000    0.000 __init__.py:685(__init__)\n",
       "        3    0.000    0.000    0.003    0.001 __init__.py:10(<module>)\n",
       "       14    0.000    0.000    0.001    0.000 cnf_regularization_rl.py:6(__init__)\n",
       "        1    0.000    0.000    0.003    0.003 backend_bases.py:33(<module>)\n",
       "       88    0.000    0.000    0.000    0.000 docstring.py:115(copy_dedent)\n",
       "        1    0.000    0.000    0.002    0.002 _tqdm.py:9(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 algorithms.py:5(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 _jit_internal.py:113(boolean_dispatch)\n",
       "        2    0.000    0.000    0.000    0.000 shape_base.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 npyio.py:1(<module>)\n",
       "       95    0.000    0.000    0.000    0.000 pyparsing.py:213(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 _utils.py:1(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 {built-in method _functools.reduce}\n",
       "     15/4    0.000    0.000    0.000    0.000 pyparsing.py:3762(streamline)\n",
       "        6    0.000    0.000    0.000    0.000 _elliptic_curve.py:97(__init__)\n",
       "        2    0.000    0.000    0.001    0.000 linear.py:47(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 profiler.py:1(<module>)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:118(<listcomp>)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:331(device_count)\n",
       "       36    0.000    0.000    0.000    0.000 getlimits.py:69(<lambda>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:673(__iadd__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:792(<dictcomp>)\n",
       "       41    0.000    0.000    0.000    0.000 enum.py:874(_power_of_two)\n",
       "       16    0.000    0.000    0.002    0.000 descriptor.py:869(__new__)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2256(_is_egg_path)\n",
       "        1    0.000    0.000    0.007    0.007 axis.py:3(<module>)\n",
       "        1    0.000    0.000    0.008    0.008 legend.py:22(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:4910(<lambda>)\n",
       "       17    0.000    0.000    0.000    0.000 ocsp.py:25(_requires_successful_response)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 constraint_registry.py:66(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:88(<module>)\n",
       "     12/2    0.000    0.000    0.000    0.000 pyparsing.py:1948(makeOptionalList)\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:31(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 decoder.py:79(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 basic.py:7(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 dviread.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:5(<module>)\n",
       "        2    0.000    0.000    0.003    0.002 rnn.py:1(<module>)\n",
       "       14    0.000    0.000    0.001    0.000 pooling.py:940(__init__)\n",
       "        1    0.000    0.000    0.111    0.111 auto.py:1(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:242(getdoc)\n",
       "       23    0.000    0.000    0.000    0.000 rcsetup.py:47(__init__)\n",
       "       30    0.000    0.000    0.004    0.000 rcsetup.py:446(validate_font_properties)\n",
       "       32    0.000    0.000    0.000    0.000 rcsetup.py:822(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 encoder.py:65(<module>)\n",
       "        1    0.000    0.000    0.011    0.011 api_implementation.py:32(<module>)\n",
       "       12    0.000    0.000    0.009    0.001 pyparsing.py:4251(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:420(__setitem__)\n",
       "       16    0.000    0.000    0.001    0.000 pyparsing.py:1204(setResultsName)\n",
       "        1    0.000    0.000    0.028    0.028 modules.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 ticker.py:165(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 pyplot.py:2363(<lambda>)\n",
       "        1    0.000    0.000    0.004    0.004 pyplot.py:177(switch_backend)\n",
       "        1    0.000    0.000    0.001    0.001 certificate_transparency.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 linalg.py:10(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:118(deprecate)\n",
       "        1    0.000    0.000    0.012    0.012 descriptor.py:33(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 pyparsing.py:411(__getitem__)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:2863(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3841(__str__)\n",
       "        7    0.000    0.000    0.000    0.000 six.py:159(_resolve)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:687(Axis)\n",
       "       17    0.000    0.000    0.000    0.000 cycler.py:529(_cycler)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4934(<lambda>)\n",
       "        1    0.000    0.000    0.003    0.003 constant_time.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1120(<listcomp>)\n",
       "       16    0.000    0.000    0.000    0.000 enum.py:65(__init__)\n",
       "       13    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:976(_get_parent_path)\n",
       "       49    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISREG}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method posix.mkdir}\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:4757(<lambda>)\n",
       "     12/2    0.000    0.000    0.001    0.000 pyparsing.py:1926(makeOptionalList)\n",
       "        1    0.000    0.000    0.001    0.001 odefunc_rl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text.py:1980(Annotation)\n",
       "        1    0.000    0.000    0.064    0.064 contour.py:3(<module>)\n",
       "       10    0.000    0.000    0.009    0.001 pyparsing.py:4404(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:83(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.000    0.000 einsumfunc.py:4(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:358(__getattr__)\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:516(haskeys)\n",
       "       61    0.000    0.000    0.000    0.000 __init__.py:1916(make_alias)\n",
       "        4    0.000    0.000    0.000    0.000 weakref.py:102(__init__)\n",
       "    13/12    0.000    0.000    0.000    0.000 pyparsing.py:3434(__str__)\n",
       "       14    0.000    0.000    0.000    0.000 pyparsing.py:3576(__str__)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1805(_warn_on_replacement)\n",
       "        1    0.000    0.000    0.000    0.000 quiver.py:15(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 core.py:55(is_style_file)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:12(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 utils.py:5(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 name.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ssl_.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 polynomial.py:4(<module>)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:43(iscode)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:766(_construct_lookups)\n",
       "       19    0.000    0.000    0.000    0.000 __init__.py:1357(_to_unmasked_float_array)\n",
       "       12    0.000    0.000    0.000    0.000 pathlib.py:651(_from_parts)\n",
       "       12    0.000    0.000    0.000    0.000 pathlib.py:998(__new__)\n",
       "       32    0.000    0.000    0.000    0.000 inspect.py:73(isclass)\n",
       "       29    0.000    0.000    0.001    0.000 contextlib.py:79(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 proto_graph.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 backend_agg.py:21(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:833(PolarAxes)\n",
       "        1    0.000    0.000    0.003    0.003 gridspec.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _cm.py:7(<module>)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:4916(srange)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:1(<module>)\n",
       "        1    0.000    0.000    0.018    0.018 _elliptic_curve.py:47(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 util.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2931(__array_finalize__)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:17(<module>)\n",
       "        1    0.000    0.000    0.079    0.079 train_cnf_disentangle_rl_multiscale.py:499(create_model)\n",
       "        1    0.000    0.000    0.000    0.000 pylabtools.py:302(activate_matplotlib)\n",
       "       25    0.000    0.000    0.000    0.000 rcsetup.py:300(<listcomp>)\n",
       "       27    0.000    0.000    0.000    0.000 __init__.py:956(is_url)\n",
       "        2    0.000    0.000    0.916    0.458 cifar.py:143(download)\n",
       "       86    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "       72    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:411(ImageFileDirectory_v2)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:84(<listcomp>)\n",
       "       11    0.000    0.000    0.000    0.000 attr_value_pb2.py:5(<lambda>)\n",
       "       13    0.000    0.000    0.000    0.000 enum_type_wrapper.py:46(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:4017(__str__)\n",
       "        1    0.000    0.000    0.003    0.003 x509.py:5(<module>)\n",
       "        1    0.000    0.000    0.017    0.017 _int.py:32(<module>)\n",
       "       56    0.000    0.000    0.000    0.000 activation.py:84(extra_repr)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method from_numpy}\n",
       "       13    0.000    0.000    0.000    0.000 pyparsing.py:3847(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:146(rng)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1456(addHandler)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:165(__setitem__)\n",
       "       11    0.000    0.000    0.000    0.000 _collections_abc.py:664(__contains__)\n",
       "        7    0.000    0.000    0.000    0.000 TiffImagePlugin.py:635(_register_basic)\n",
       "        1    0.000    0.000    0.031    0.031 refactor.py:9(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 descriptor_pool.py:56(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:49(<listcomp>)\n",
       "       14    0.000    0.000    0.000    0.000 descriptor.py:919(_ParseOptions)\n",
       "       61    0.000    0.000    0.000    0.000 pyparsing.py:2159(streamline)\n",
       "       10    0.000    0.000    0.000    0.000 event_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.006    0.006 offsetbox.py:15(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 pyplot.py:1782(get_plot_commands)\n",
       "        2    0.000    0.000    0.001    0.001 x25519.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:11(ExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:332(<dictcomp>)\n",
       "       18    0.000    0.000    0.000    0.000 core.py:996(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.copyto}\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:63(NDArrayOperatorsMixin)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:1(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 enum.py:135(<dictcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 sparse.py:1(<module>)\n",
       "       67    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_manualSeedAll}\n",
       "       25    0.000    0.000    0.000    0.000 {method 'append' of 'DescriptorSequence' objects}\n",
       "       32    0.000    0.000    0.000    0.000 pyparsing.py:209(__init__)\n",
       "        6    0.000    0.000    0.028    0.005 __init__.py:35(load_module)\n",
       "        1    0.000    0.000    0.042    0.042 odeint.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 patches.py:1927(BoxStyle)\n",
       "        1    0.000    0.000    0.001    0.001 transforms.py:30(<module>)\n",
       "        1    0.000    0.000    0.011    0.011 artist.py:1(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 cycler.py:225(__iter__)\n",
       "        1    0.000    0.000    0.013    0.013 lsun.py:1(<module>)\n",
       "        1    0.000    0.000    0.036    0.036 binding.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 core.py:1(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:147(deprecated)\n",
       "       23    0.000    0.000    0.000    0.000 utils.py:112(__init__)\n",
       "       28    0.000    0.000    0.000    0.000 pooling.py:944(extra_repr)\n",
       "        1    0.000    0.000    0.017    0.017 __init__.py:147(_lazy_init)\n",
       "        1    0.000    0.000    0.239    0.239 tarfile.py:1411(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 numerictypes.py:181(english_capitalize)\n",
       "       19    0.000    0.000    0.000    0.000 pathlib.py:691(__str__)\n",
       "       15    0.000    0.000    0.000    0.000 _collections_abc.py:72(_check_methods)\n",
       "       41    0.000    0.000    0.000    0.000 {method 'groupdict' of '_sre.SRE_Match' objects}\n",
       "       61    0.000    0.000    0.000    0.000 {built-in method builtins.vars}\n",
       "        1    0.000    0.000    0.000    0.000 JpegPresets.py:67(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:171(RefactoringTool)\n",
       "        2    0.000    0.000    0.005    0.003 resnet.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:9(parse_kwargs)\n",
       "        4    0.000    0.000    0.000    0.000 getlimits.py:376(__new__)\n",
       "        1    0.000    0.000    0.006    0.006 __init__.py:206(_sanity_check)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:3642(__str__)\n",
       "     20/6    0.000    0.000    0.001    0.000 pyparsing.py:3803(parseImpl)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:390(_logged_cached)\n",
       "        6    0.000    0.000    0.000    0.000 version.py:307(parse)\n",
       "       16    0.000    0.000    0.000    0.000 pathlib.py:282(splitroot)\n",
       "       26    0.000    0.000    0.000    0.000 argparse.py:864(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:48(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 pygram.py:4(<module>)\n",
       "     16/2    0.000    0.000    0.001    0.001 pyparsing.py:3737(parseImpl)\n",
       "        1    0.000    0.000    0.030    0.030 specifiers.py:4(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 record_writer.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_schur.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 config.py:39(InlineBackend)\n",
       "        1    0.000    0.000    0.062    0.062 _subplots.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 afm.py:38(<module>)\n",
       "       33    0.000    0.000    0.000    0.000 cm.py:40(_reverser)\n",
       "        1    0.000    0.000    0.024    0.024 compat.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:7(<module>)\n",
       "       21    0.000    0.000    0.000    0.000 utils.py:126(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:383(PyOpenSSLContext)\n",
       "        1    0.000    0.000    0.001    0.001 constraints.py:19(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 random.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 polynomial.py:56(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defmatrix.py:70(matrix)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:48(_numeric_methods)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:440(_set_array_types)\n",
       "        1    0.000    0.000    0.001    0.001 fromnumeric.py:3(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:73(CFUNCTYPE)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:332(__init__)\n",
       "       74    0.000    0.000    0.000    0.000 pyparsing.py:2074(leaveWhitespace)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:4(<module>)\n",
       "       35    0.000    0.000    0.000    0.000 enum.py:822(_high_bit)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:71(search_function)\n",
       "        5    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
       "        1    0.000    0.000    0.001    0.001 GifImagePlugin.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:32(Base)\n",
       "       16    0.000    0.000    0.060    0.004 __init__.py:1914(_by_version_descending)\n",
       "        4    0.000    0.000    0.001    0.000 container_gate.py:8(__init__)\n",
       "        1    0.000    0.000    0.010    0.010 cnf_gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 rk_common.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _subplots.py:203(subplot_class_factory)\n",
       "        1    0.000    0.000    0.029    0.029 core.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:89(_OCSPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:217(PKey)\n",
       "        1    0.000    0.000    0.016    0.016 universaldetector.py:36(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mbcssm.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 url.py:14(Url)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:49(check_compatibility)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:271(<dictcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:126(doc_note)\n",
       "        1    0.000    0.000    0.001    0.001 fftpack.py:32(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 mixins.py:20(_binary_method)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:40(_inplace_binary_method)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:418(_construct_char_code_lookup)\n",
       "       58    0.000    0.000    0.000    0.000 pyparsing.py:468(__bool__)\n",
       "       12    0.000    0.000    0.000    0.000 rcsetup.py:68(_listify_validator)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:468(validate_whiskers)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:265(_parse_commandline)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:409(_real_close)\n",
       "       20    0.000    0.000    0.000    0.000 argparse.py:568(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1604(__init__)\n",
       "       59    0.000    0.000    0.000    0.000 enum.py:594(name)\n",
       "       14    0.000    0.000    0.000    0.000 functools.py:448(lru_cache)\n",
       "       49    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:621(decorator)\n",
       "        1    0.000    0.000    0.009    0.009 utils.py:3(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 fixer_util.py:1(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'FindEnumTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       13    0.000    0.000    0.000    0.000 descriptor.py:635(__new__)\n",
       "        1    0.000    0.000    0.404    0.404 torchvis.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 backend_inline.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:582(get_scale_docs)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:10(<module>)\n",
       "        1    0.000    0.000    0.021    0.021 textpath.py:1(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 pyplot.py:2358(_autogen_docstring)\n",
       "        1    0.000    0.000    0.002    0.002 socks.py:23(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:1529(Connection)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PoolKey)\n",
       "        1    0.000    0.000    0.235    0.235 model_zoo.py:1(<module>)\n",
       "        1    0.000    0.000    0.115    0.115 module.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:59(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:59(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:51(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:19(ABCPolyBase)\n",
       "       10    0.000    0.000    0.000    0.000 pytesttester.py:72(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:340(_add_integer_aliases)\n",
       "       30    0.000    0.000    0.000    0.000 numerictypes.py:432(_add_array_type)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:36(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 pyparsing.py:4004(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 fontconfig_pattern.py:144(_families)\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:1059(system)\n",
       "        5    0.000    0.000    0.000    0.000 re.py:249(escape)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:294(IFDRational)\n",
       "        1    0.000    0.000    0.005    0.005 fractions.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scope.py:3(<module>)\n",
       "       34    0.000    0.000    0.000    0.000 descriptor_pb2.py:5(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:668(<listcomp>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2751(charsAsStr)\n",
       "       10    0.000    0.000    0.000    0.000 __init__.py:23(find_module)\n",
       "        1    0.000    0.000    0.004    0.004 train_misc.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _solvers.py:1(<module>)\n",
       "        1    0.000    0.000    0.015    0.015 tsit5.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:25(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lines.py:208(Line2D)\n",
       "       38    0.000    0.000    0.000    0.000 cycler.py:371(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:109(_register_osrandom_engine)\n",
       "        1    0.000    0.000    0.003    0.003 _iri.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:872(X509Req)\n",
       "        1    0.000    0.000    0.001    0.001 retry.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:9(Uniform)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1414(_get_builtin_table)\n",
       "        1    0.000    0.000    0.000    0.000 grad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:59(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:25(register_func)\n",
       "        1    0.000    0.000    0.000    0.000 twodim_base.py:140(eye)\n",
       "        3    0.000    0.000    0.000    0.000 numerictypes.py:565(obj2sctype)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2491(seterr)\n",
       "       19    0.000    0.000    0.000    0.000 _methods.py:45(_all)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:18(_fr0)\n",
       "        2    0.000    0.000    0.000    0.000 rcsetup.py:78(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 ImageFilter.py:18(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _socket.inet_aton}\n",
       "        7    0.000    0.000    0.000    0.000 tokenize.py:344(_get_normal_name)\n",
       "       26    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}\n",
       "       43    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
       "        1    0.000    0.000    0.003    0.003 BmpImagePlugin.py:27(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 decoder.py:263(_StructPackDecoder)\n",
       "        1    0.000    0.000    0.010    0.010 version.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp.py:15(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:55(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend_inline.py:151(_enable_matplotlib_integration)\n",
       "        1    0.000    0.000    0.001    0.001 markers.py:146(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 artist.py:69(Artist)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:52(NameOID)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:128(HebrewProber)\n",
       "        1    0.000    0.000    0.005    0.005 sjisprober.py:28(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:23(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:9(Exponential)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ScriptMethodStub)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:1(<module>)\n",
       "        1    0.000    0.000    0.182    0.182 module.py:723(load_state_dict)\n",
       "        1    0.000    0.000    0.043    0.043 fontconfig_pattern.py:7(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 pyparsing.py:2773(charsAsStr)\n",
       "       10    0.000    0.000    0.000    0.000 rcsetup.py:221(validate_fonttype)\n",
       "        9    0.000    0.000    0.004    0.000 fontconfig_pattern.py:113(parse)\n",
       "        4    0.000    0.000    0.000    0.000 fontconfig_pattern.py:152(_property)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1236(_fixupChildren)\n",
       "       11    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:993(__iter__)\n",
       "        7    0.000    0.000    0.000    0.000 six.py:195(load_module)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:50(__new__)\n",
       "        1    0.000    0.000    0.038    0.038 __init__.py:85(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:116(RegisterFileDescriptor)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:4681(originalTextFor)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:1069(wrapper)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3523(MatchFirst)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 table.py:21(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 patches.py:1815(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 patches.py:2645(ConnectionStyle)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:684(Context)\n",
       "       36    0.000    0.000    0.000    0.000 backend.py:218(register_cipher_adapter)\n",
       "        5    0.000    0.000    0.031    0.006 binding.py:122(_ensure_ffi_initialized)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:80(DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:104(_has_ipv6)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:11(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 linear.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:15(Tensor)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2775(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2905(_update_from)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:341(TestCase)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:251(_get_machar)\n",
       "        1    0.000    0.000    0.032    0.032 type_check.py:3(<module>)\n",
       "       44    0.000    0.000    0.000    0.000 pyparsing.py:3609(<genexpr>)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:312(__call__)\n",
       "        6    0.000    0.000    0.000    0.000 locale.py:379(normalize)\n",
       "       16    0.000    0.000    0.000    0.000 enum.py:312(__getattr__)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:331(__iter__)\n",
       "       28    0.000    0.000    0.000    0.000 _collections_abc.py:302(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._init_names}\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:294(StubImageFile)\n",
       "        1    0.000    0.000    0.004    0.004 dopri5.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:65(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 csv.py:4(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 docstring.py:84(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:64(register)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:78(contains)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:12(CipherBackend)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:1(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 init.py:403(_make_deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:3(<module>)\n",
       "        1    0.000    0.000    0.011    0.011 util.py:310(find_library)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1113(ParserElement)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:267(LooseVersion)\n",
       "        9    0.000    0.000    0.000    0.000 pathlib.py:385(wrapped)\n",
       "        4    0.000    0.000    0.000    0.000 traitlets.py:1627(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:746(__exit__)\n",
       "        5    0.000    0.000    0.000    0.000 _collections_abc.py:367(__subclasshook__)\n",
       "        2    0.000    0.000    0.000    0.000 __config__.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fractions.py:60(Fraction)\n",
       "       14    0.000    0.000    0.001    0.000 pyparsing.py:2026(__call__)\n",
       "        2    0.000    0.000    0.001    0.001 pyparsing.py:3859(parseImpl)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3027(_always_object)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 contour.py:52(ContourLabeler)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4603(delimitedList)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2761(register_open)\n",
       "        1    0.000    0.000    0.001    0.001 api.py:1(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 name.py:28(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:33(HashBackend)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:23(DSAParametersWithNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1078(X509)\n",
       "        1    0.000    0.000    0.001    0.001 gumbel.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:328(ExprBuilder)\n",
       "        1    0.000    0.000    0.001    0.001 data_parallel.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:444(AvgPool1d)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:6260(__has_singleton)\n",
       "        4    0.000    0.000    0.000    0.000 function_base.py:1912(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:304(recarray)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3269(parseImpl)\n",
       "       18    0.000    0.000    0.000    0.000 deprecation.py:189(finalize)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:602(_get_config_or_cache_dir)\n",
       "       23    0.000    0.000    0.000    0.000 inspect.py:81(ismethod)\n",
       "       13    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:966(_find_parent_path_names)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:9(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 driver.py:117(load_grammar)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl_multiscale.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 text_encoding.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:98(Timestamp)\n",
       "       13    0.000    0.000    0.000    0.000 symbol_database.py:93(RegisterEnumDescriptor)\n",
       "        3    0.000    0.000    0.001    0.000 pyparsing.py:1877(__mul__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1103(ParserElement)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2431(parseImpl)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3781(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate.py:20(CNF_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:81(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 idnadata.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:41(GeneralName)\n",
       "        1    0.000    0.000    0.000    0.000 filepost.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:20(warn_imbalance)\n",
       "        1    0.000    0.000    0.239    0.239 serialization.py:448(legacy_load)\n",
       "        1    0.000    0.000    0.002    0.002 random.py:22(manual_seed)\n",
       "        1    0.000    0.000    0.000    0.000 scimath.py:17(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 loader.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:369(_set_up_aliases)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:1214(setResultsName)\n",
       "       14    0.000    0.000    0.000    0.000 rcsetup.py:178(validate_axisbelow)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:783(RcParams)\n",
       "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7f31b88447b8}\n",
       "        5    0.000    0.000    0.000    0.000 traitlets.py:651(tag)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:2468(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:752(_addHandlerRef)\n",
       "       20    0.000    0.000    0.000    0.000 enum.py:581(__hash__)\n",
       "        6    0.000    0.000    0.000    0.000 weakref.py:354(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 six.py:209(is_package)\n",
       "       28    0.000    0.000    0.000    0.000 {built-in method sys.intern}\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:249(DibImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:11(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 onnx_graph.py:1(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 six.py:80(_import_module)\n",
       "       12    0.000    0.000    0.000    0.000 dual.py:52(register_func)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate_sep.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:450(LogitTransform)\n",
       "        1    0.000    0.000    0.000    0.000 table.py:204(Table)\n",
       "        1    0.000    0.000    0.000    0.000 text.py:109(Text)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:752(Bbox)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:514(Image)\n",
       "        1    0.000    0.000    0.001    0.001 _main.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scrypt.py:5(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 binding.py:54(_openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:135(CertificatePoliciesOID)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:910(DomainParameters)\n",
       "        1    0.000    0.000    0.002    0.002 idna.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:76(Error)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:124(HTTPResponse)\n",
       "        1    0.000    0.000    0.001    0.001 escprober.py:28(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 constraint_registry.py:105(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 adaptive.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:11(_check_balance)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8061(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _methods.py:5(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 fontconfig_pattern.py:132(_family)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:139(__init__)\n",
       "       25    0.000    0.000    0.000    0.000 enum.py:332(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:839(_decompose)\n",
       "        8    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.OrderedDict' objects}\n",
       "       26    0.000    0.000    0.000    0.000 {method 'groups' of '_sre.SRE_Match' objects}\n",
       "       22    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
       "       20    0.000    0.000    0.000    0.000 tokenize.py:48(group)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4450(delimitedList)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2045(suppress)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2606(Word)\n",
       "        7    0.000    0.000    0.000    0.000 specifiers.py:266(_require_version_compare)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:135(_declare_state)\n",
       "        1    0.000    0.000    0.085    0.085 __init__.py:554(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 adams.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:3(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 _layoutbox.py:16(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:244(BboxBase)\n",
       "        1    0.000    0.000    0.001    0.001 path.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:1(<module>)\n",
       "       35    0.000    0.000    0.000    0.000 backend.py:2100(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.X509_new}\n",
       "        1    0.000    0.000    0.000    0.000 parser.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:491(PrivateKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:18(add_docstr_all)\n",
       "        1    0.000    0.000    0.000    0.000 lowrank_multivariate_normal.py:57(LowRankMultivariateNormal)\n",
       "        1    0.000    0.000    0.000    0.000 rendezvous.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 linear.py:58(reset_parameters)\n",
       "        1    0.000    0.000    0.000    0.000 gradcheck.py:1(<module>)\n",
       "       27    0.000    0.000    0.000    0.000 auto.py:339(make_default_double_backwards_fn)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:279(get_device_capability)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:57(_load_cudart)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8066(getdoc)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:156(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 train_cnf_disentangle_rl_multiscale.py:346(<lambda>)\n",
       "        9    0.000    0.000    0.000    0.000 rcsetup.py:249(validate_backend)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1533(__init__)\n",
       "       46    0.000    0.000    0.000    0.000 inspect.py:358(<lambda>)\n",
       "       27    0.000    0.000    0.000    0.000 inspect.py:479(getmro)\n",
       "        6    0.000    0.000    0.000    0.000 traitlets.py:419(__init__)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:1286(debug)\n",
       "        9    0.000    0.000    0.000    0.000 re.py:324(_subx)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:2(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 text_format.py:1006(Tokenizer)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:113(TypeCheckerWithDefault)\n",
       "        1    0.000    0.000    0.001    0.001 btm_matcher.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:115(copy)\n",
       "        1    0.000    0.000    0.030    0.030 visdom_writer.py:1(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 {method 'AddFileDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4781(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:1841(__radd__)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:338(<genexpr>)\n",
       "        1    0.000    0.000    0.026    0.026 specifiers.py:275(Specifier)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_cholesky.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 _version.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:19(Patch)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:302(OCSPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:81(SignatureAlgorithmOID)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 escsm.py:28(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:21(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:8(Binomial)\n",
       "        1    0.000    0.000    0.002    0.002 bernoulli.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:267(get_device_name)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:727(TarInfo)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:493(StringConverter)\n",
       "        1    0.000    0.000    0.000    0.000 twodim_base.py:3(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 defmatrix.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:6(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2592(geterr)\n",
       "        1    0.000    0.000    0.001    0.001 util.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:484(cast)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:1863(__radd__)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:1899(__mul__)\n",
       "        8    0.000    0.000    0.000    0.000 fontconfig_pattern.py:138(_name)\n",
       "        1    0.000    0.000    0.000    0.000 ImageOps.py:20(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 pathlib.py:1057(home)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:742(setup_class)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:767(_create_pseudo_member_)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:35(_formatwarnmsg_impl)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._multiprocessing_init}\n",
       "        1    0.000    0.000    0.002    0.002 noniterators.py:18(<module>)\n",
       "        1    0.000    0.000    0.026    0.026 driver.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dual.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_lu.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_ldl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_qz.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 special_matrices.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:265(GaussianDiag)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 category.py:12(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 legend_handler.py:57(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 font_manager.py:883(json_load)\n",
       "        7    0.000    0.000    0.000    0.000 pyparsing.py:4978(tokenMap)\n",
       "        1    0.000    0.000    0.001    0.001 hmac.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 cmac.py:5(<module>)\n",
       "        1    0.000    0.000    0.006    0.006 ciphers.py:5(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 SSL.py:701(<genexpr>)\n",
       "        1    0.000    0.000    0.017    0.017 __init__.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 module.py:23(Module)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:1024(frombuf)\n",
       "        1    0.000    0.000    0.239    0.239 tarfile.py:2276(next)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:174(nti)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:238(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:45(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:934(poly1d)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:35(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 main.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 getlimits.py:507(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:430(__setitem__)\n",
       "        2    0.000    0.000    0.000    0.000 events.py:42(register)\n",
       "        9    0.000    0.000    0.000    0.000 pathlib.py:674(_format_parsed_parts)\n",
       "        3    0.000    0.000    0.000    0.000 pathlib.py:1241(mkdir)\n",
       "        6    0.000    0.000    0.000    0.000 pathlib.py:1343(is_dir)\n",
       "       26    0.000    0.000    0.000    0.000 argparse.py:2312(_check_value)\n",
       "        2    0.000    0.000    0.000    0.000 getipython.py:17(get_ipython)\n",
       "       14    0.000    0.000    0.000    0.000 weakref.py:428(get)\n",
       "        2    0.000    0.000    0.000    0.000 spectral_norm.py:3(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method posix.access}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
       "        1    0.000    0.000    0.004    0.004 __init__.py:40(<module>)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:4763(srange)\n",
       "        7    0.000    0.000    0.000    0.000 pyparsing.py:4825(tokenMap)\n",
       "       46    0.000    0.000    0.000    0.000 pyparsing.py:1366(postParse)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint_sep.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 dates.py:581(DateFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3270(export)\n",
       "        1    0.000    0.000    0.001    0.001 texmanager.py:29(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 dviread.py:156(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:307(ColorbarBase)\n",
       "        1    0.000    0.000    0.000    0.000 cycler.py:41(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyplot.py:82(install_repl_displayhook)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:259(Morsel)\n",
       "        1    0.000    0.000    0.001    0.001 cookiejar.py:1224(CookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:148(activate_osrandom_engine)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_init}\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:10(_Reasons)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:185(CertificateRevocationList)\n",
       "        1    0.000    0.000    0.001    0.001 charsetgroupprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:29(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 url.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:22(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 lowrank_multivariate_normal.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:29(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
       "        4    0.000    0.000    0.000    0.000 _utils_internal.py:16(get_file_path)\n",
       "        1    0.000    0.000    0.000    0.000 _numpy_fft.py:54(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 histograms.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 py3k.py:4(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3994(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 context.py:69(RLock)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:722(__new__)\n",
       "        8    0.000    0.000    0.000    0.000 shutil.py:1106(_access_check)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:302(loads)\n",
       "        1    0.000    0.000    0.000    0.000 sysconfig.py:612(get_platform)\n",
       "        9    0.000    0.000    0.000    0.000 os.py:746(decode)\n",
       "        9    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "        1    0.000    0.000    0.000    0.000 ImageColor.py:20(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:16(<module>)\n",
       "       28    0.000    0.000    0.000    0.000 TiffImagePlugin.py:368(_delegate)\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:18(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:4(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 node_def_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.001    0.001 containers.py:40(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1790(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:2237(_cygwin_patch)\n",
       "       12    0.000    0.000    0.000    0.000 __init__.py:15(search_path)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:62(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 squeeze.py:7(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_RungeKuttaState)\n",
       "        1    0.000    0.000    0.080    0.080 cnf.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:4(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 legend_handler.py:134(__init__)\n",
       "        1    0.000    0.000    0.008    0.008 _constrained_layout.py:16(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:25(Collection)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2344(CompositeGenericTransform)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:21(FFI)\n",
       "        2    0.000    0.000    0.000    0.000 backend.py:128(_get_osurandom_engine)\n",
       "        1    0.000    0.000    0.002    0.002 exceptions.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:581(ReasonFlags)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:116(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:154(cached_property)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:10(Multinomial)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:8(NegativeBinomial)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:7(Distribution)\n",
       "        1    0.000    0.000    0.001    0.001 beta.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:11(Cauchy)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:21(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 init.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _reduction.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:1(<module>)\n",
       "        2    0.000    0.000    0.011    0.005 __init__.py:120(_lazy_call)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6266(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:8(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _csv.register_dialect}\n",
       "        1    0.000    0.000    0.000    0.000 financial.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:1(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:327(__getitem__)\n",
       "       11    0.000    0.000    0.000    0.000 pyparsing.py:470(__iter__)\n",
       "        6    0.000    0.000    0.000    0.000 deprecation.py:54(warn_deprecated)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:734(gen_candidates)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:703(matplotlib_fname)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 random.py:223(_randbelow)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:826(__new__)\n",
       "        2    0.000    0.000    0.001    0.001 traceback.py:27(format_list)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1414(wait)\n",
       "        2    0.000    0.000    0.002    0.001 decoder.py:334(decode)\n",
       "       23    0.000    0.000    0.000    0.000 enum.py:599(value)\n",
       "        1    0.000    0.000    0.000    0.000 latin_1.py:41(getregentry)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(normalize_encoding)\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup}\n",
       "       10    0.000    0.000    0.000    0.000 {method 'cast' of 'memoryview' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._tracer_warn_use_python}\n",
       "        1    0.000    0.000    0.002    0.002 ImagePalette.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extension_loader.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:12(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 step_stats_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.003    0.003 symbol_database.py:58(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:3032(__str__)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:3098(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3829(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 six.py:189(__get_module)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:2205(file_ns_handler)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2464(Distribution)\n",
       "        1    0.000    0.000    0.001    0.001 expat.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:150(create_regularization_fns)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_VCABMState)\n",
       "        1    0.000    0.000    0.000    0.000 spines.py:13(Spine)\n",
       "        4    0.000    0.000    0.000    0.000 scale.py:592(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 blocking_input.py:20(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 patches.py:1816(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 font_manager.py:939(FontManager)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2787(register_save)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:294(socksocket)\n",
       "        7    0.000    0.000    0.000    0.000 ocsp.py:43(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:26(_Certificate)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:21(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:292(CertificateSigningRequest)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:137(_validate_dependencies_met)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:514(X509Name)\n",
       "        1    0.000    0.000    0.235    0.235 alexnet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 comm.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:79(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 function.py:183(once_differentiable)\n",
       "        1    0.000    0.000    0.114    0.114 thnn.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:1385(TarFile)\n",
       "        1    0.000    0.000    0.000    0.000 _six.py:21(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'seed' of 'mtrand.RandomState' objects}\n",
       "        8    0.000    0.000    0.000    0.000 core.py:2551(_arraymethod)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:4(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ufunclike.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:942(_register_types)\n",
       "        3    0.000    0.000    0.000    0.000 fromnumeric.py:2478(prod)\n",
       "        1    0.000    0.000    0.001    0.001 result.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:1669(chararray)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 train_cnf_disentangle_rl_multiscale.py:155(ColorMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:162(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pathlib.py:814(with_name)\n",
       "        6    0.000    0.000    0.000    0.000 pathlib.py:1153(stat)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:157(__next__)\n",
       "        8    0.000    0.000    0.000    0.000 random.py:255(choice)\n",
       "       14    0.000    0.000    0.000    0.000 copy.py:111(_copy_immutable)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1348(_handle_exitstatus)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:283(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 re.py:204(split)\n",
       "        4    0.000    0.000    0.000    0.000 weakref.py:288(update)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.open}\n",
       "       13    0.000    0.000    0.000    0.000 {built-in method builtins.delattr}\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_TagInfo)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Int8Tensor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:102(DescriptorPool)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:47(<listcomp>)\n",
       "       18    0.000    0.000    0.000    0.000 pyparsing.py:458(__bool__)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:3935(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 six.py:114(_resolve)\n",
       "        2    0.000    0.000    0.016    0.008 train_misc.py:85(count_parameters)\n",
       "        1    0.000    0.000    0.001    0.001 _ccallback.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 spines.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 units.py:43(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 rrule.py:70(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 rrule.py:77(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 _pylab_helpers.py:67(destroy_all)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:3204(MathTextParser)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:634(BakomaFonts)\n",
       "        1    0.000    0.000    0.000    0.000 textpath.py:24(TextToPath)\n",
       "       24    0.000    0.000    0.000    0.000 dviread.py:124(_dispatch)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:625(Rectangle)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2084(IdentityTransform)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5864(pyparsing_unicode)\n",
       "        3    0.000    0.000    0.000    0.000 Image.py:2821(register_extensions)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2932(_apply_env_variables)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:9(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:214(_CertificateRevocationList)\n",
       "        4    0.000    0.000    0.000    0.000 ocsp.py:63(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:15(_ASN1Type)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:275(X509Backend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:114(CRLNumber)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 universaldetector.py:51(UniversalDetector)\n",
       "        1    0.000    0.000    0.000    0.000 utf8prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 half_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:2(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 linear.py:69(extra_repr)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:20(__init__)\n",
       "        1    0.000    0.000    0.239    0.239 tarfile.py:1522(open)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:239(manager_path)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:54(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 arraypad.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:17(__enter__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'newbyteorder' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:265(DataSource)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:388(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:334(ParseResults)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:1517(clear)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3982(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 pyparsing.py:4088(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:175(compare_versions)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'bind' of '_socket.socket' objects}\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:506(translation)\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:921(uname)\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:1014(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:1109(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:876(parse_template)\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:193(total_ordering)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_cudnn_benchmark}\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:17(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 fractions.py:294(_operator_fallbacks)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:24(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:14(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'AddEnumDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        1    0.000    0.000    0.000    0.000 reflection.py:46(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:187(Default)\n",
       "        4    0.000    0.000    0.000    0.000 descriptor.py:729(__new__)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:317(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:324(ParseResults)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1288(addParseAction)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:1608(parseString)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:2963(__str__)\n",
       "        1    0.000    0.000    0.085    0.085 __init__.py:567(_build_master)\n",
       "        1    0.000    0.000    0.000    0.000 flinalg.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_qr.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_ButcherTableau)\n",
       "        1    0.000    0.000    0.000    0.000 backend_agg.py:62(RendererAgg)\n",
       "        1    0.000    0.000    0.001    0.001 triangulation.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 quiver.py:414(Quiver)\n",
       "        4    0.000    0.000    0.000    0.000 legend_handler.py:179(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 bezier.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 docstring.py:1(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 cycler.py:145(change_key)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:4098(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:586(Response)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1063(ZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:34(OCSPResponseStatus)\n",
       "        7    0.000    0.000    0.000    0.000 decode_asn1.py:187(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 aead.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_OpenSSLErrorWithText)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:33(HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:15(EllipticCurveOID)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1082(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(RequestHistory)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:11(StudentT)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:10(Geometric)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 chi2.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:13(Gamma)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(PowerTransform)\n",
       "        1    0.000    0.000    0.000    0.000 bernoulli.py:10(Bernoulli)\n",
       "        1    0.000    0.000    0.001    0.001 adadelta.py:1(<module>)\n",
       "        1    0.000    0.000    0.007    0.007 adam.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:31(<lambda>)\n",
       "        1    0.000    0.000    0.239    0.239 tarfile.py:1087(fromtarfile)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3080(view)\n",
       "        3    0.000    0.000    0.000    0.000 ufunclike.py:14(_deprecate_out_named_y)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:450(decorating_function)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3230(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:268(validate_toolbar)\n",
       "       13    0.000    0.000    0.000    0.000 rcsetup.py:336(validate_color_or_auto)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:890(validate_hist_bins)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:921(validate_webagg_address)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:578(_get_xdg_config_dir)\n",
       "        1    0.000    0.000    0.007    0.007 fakedata.py:1(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 pathlib.py:1008(_init)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:160(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 textwrap.py:467(indent)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1354(add_argument_group)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:2275(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 traitlets.py:181(is_trait)\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:274(load)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:20(_showwarnmsg_impl)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:398(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 _collections_abc.py:252(__subclasshook__)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:672(__setitem__)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:469(Module_six_moves_urllib)\n",
       "       16    0.000    0.000    0.000    0.000 six.py:75(_add_doc)\n",
       "       15    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ImageChops.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:3(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 parse.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:38(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 tensor_pb2.py:5(<lambda>)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'ParseFromString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "        1    0.000    0.000    0.000    0.000 message.py:44(Message)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2991(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 py31compat.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:9(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:248(<genexpr>)\n",
       "        1    0.000    0.000    0.008    0.008 version.py:191(Version)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_Version)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:21(BaseSpecifier)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:78(_IndividualSpecifier)\n",
       "       10    0.000    0.000    0.000    0.000 six.py:181(_get_module)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:237(SummaryWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:551(WorkingSet)\n",
       "        1    0.000    0.000    0.000    0.000 _expm_frechet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ArgSpec)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:65(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:255(ODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 interp.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:38(Tick)\n",
       "        1    0.000    0.000    0.000    0.000 tricontour.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 trifinder.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:1300(rruleset)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:5(Container)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:2436(FigureManagerBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:728(GraphicsContextBase)\n",
       "        1    0.000    0.000    0.000    0.000 tight_layout.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _pylab_helpers.py:3(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 mathtext.py:1853(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Page)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Text)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Font)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2256(SymmetricalLogLocator)\n",
       "        1    0.000    0.000    0.000    0.000 _binary.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3848(SequenceOf)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:764(Void)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:131(DSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:183(EllipticCurveBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:334(DHBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:142(AuthorityKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:488(DistributionPoint)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2111(CRL)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:115(inject_into_urllib3)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:714(X509Extension)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:95(HTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:8(TransformedDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:10(Normal)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:58(MultivariateNormal)\n",
       "        1    0.000    0.000    0.001    0.001 exp_family.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 scatter_gather.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:7(Stream)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 serialization.py:46(register_package)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:173(_check_seekable)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:1145(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:2109(Chebyshev)\n",
       "       14    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.geterrobj}\n",
       "        1    0.000    0.000    0.000    0.000 arraysetops.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 main.py:49(TestProgram)\n",
       "        3    0.000    0.000    0.000    0.000 result.py:12(failfast)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Mismatch)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:342(_FuncPtr)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:678(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1298(addParseAction)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1501(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 rcsetup.py:329(validate_color_or_inherit)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:607(validate_hinting)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:644(validate_sketch)\n",
       "       11    0.000    0.000    0.000    0.000 rcsetup.py:661(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 fontconfig_pattern.py:145(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:555(get_home)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:46(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 backcall.py:49(adapt)\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:572(dgettext)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:133(_get_kwargs)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:586(iteritems)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:2558(class_init)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:349(__subclasshook__)\n",
       "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:960(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method sys.setdlopenflags}\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:110(_generate_pickle_name)\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:138(_newer)\n",
       "        2    0.000    0.000    0.001    0.001 driver.py:147(load_packaged_grammar)\n",
       "        3    0.000    0.000    0.000    0.000 grammar.py:77(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:5(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 layout_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 x2num.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl_multiscale.py:10(ODENVP)\n",
       "        6    0.000    0.000    0.000    0.000 resource_handle_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:392(FieldDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(manifest_mod)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1567(resetCache)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:2020(__invert__)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:2376(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3061(__init__)\n",
       "        1    0.000    0.000    0.003    0.003 specifiers.py:214(LegacySpecifier)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_polar.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:26(LowLevelCallable)\n",
       "        1    0.000    0.000    0.000    0.000 linalg_version.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:70(set)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization_rl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 config.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:33(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:293(CubicTriInterpolator)\n",
       "        1    0.000    0.000    0.000    0.000 trirefine.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Box)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1060(StandardPsFonts)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1105(Arrow)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(CharMetrics)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(CompositePart)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:481(ScalarFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 _cm.py:57(cubehelix)\n",
       "       15    0.000    0.000    0.000    0.000 docstring.py:80(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:20(get_versions)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:114(_make_name)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 api.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:102(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 backend.py:114(openssl_assert)\n",
       "       10    0.000    0.000    0.000    0.000 SSL.py:646(_requires_decorator)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_get_default_RAND}\n",
       "        2    0.000    0.000    0.031    0.016 binding.py:136(init_static_locks)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:120(ExtendedKeyUsageOID)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3050(Sequence)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:613(EncryptionAlgorithm)\n",
       "        3    0.000    0.000    0.000    0.000 extensions.py:915(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:329(NamedCurve)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:170(__mul__)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:202(extended_date)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:694(PolicyInformation)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:268(RSAPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:70(HTTPConnection)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:9(Poisson)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:10(LogitRelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:10(Weibull)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:209(ComposeTransform)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:225(StmtBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:126(StepLR)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:18(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PackedSequence)\n",
       "        2    0.000    0.000    0.000    0.000 activation.py:321(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 vision.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:451(__set__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:459(CudnnModule)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 random.py:77(manual_seed_all)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:7(cudaOutputMode)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:323(_get_typecodes)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.seterrobj}\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:246(_ctypes)\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:74(_determine_error_states)\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _inspect.py:7(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2891(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:24(TestResult)\n",
       "        1    0.000    0.000    0.000    0.000 fontconfig_pattern.py:30(FontconfigPatternParser)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1595(enablePackrat)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3127(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:590(_get_xdg_cache_dir)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:656(_get_data_path)\n",
       "        6    0.000    0.000    0.000    0.000 version.py:312(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:55(__exit__)\n",
       "        3    0.000    0.000    0.000    0.000 pathlib.py:357(gethomedir)\n",
       "       11    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:611(gettext)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:96(seed)\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:219(_deepcopy_tuple)\n",
       "        4    0.000    0.000    0.000    0.000 threading.py:74(RLock)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:339(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:334(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:678(__delitem__)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:947(TiffImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:1552(AppendingTiffWriter)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:504(_StructPackEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 compatibility.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:115(__init__)\n",
       "       13    0.000    0.000    0.000    0.000 decoder.py:190(_SimpleDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:37(<listcomp>)\n",
       "        1    0.000    0.000    0.005    0.005 odenvp_conditional_rl_multiscale.py:232(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 message_factory.py:50(__init__)\n",
       "       13    0.000    0.000    0.000    0.000 summary_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:524(MessageMap)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:222(Descriptor)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:4292(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:4783(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2765(Regex)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3353(setResultsName)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1603(ZipProvider)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:2310(EntryPoint)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3114(_initialize)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:204(Data)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:385(get_build_platform)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:8(MultiscaleParallelCNF)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:6(AdaptiveStepsizeODESolver)\n",
       "        1    0.000    0.000    0.000    0.000 table.py:145(CustomCell)\n",
       "        1    0.000    0.000    0.000    0.000 tritools.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tripcolor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 quiver.py:890(Barbs)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1949(RectangleSelector)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:2522(NavigationToolbar2)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1365(AnnotationBbox)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:180(_ImageBase)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:901(NonUniformImage)\n",
       "        4    0.000    0.000    0.000    0.000 backend_bases.py:92(register_backend)\n",
       "        1    0.000    0.000    0.000    0.000 _layoutbox.py:48(LayoutBox)\n",
       "        1    0.000    0.000    0.000    0.000 blocking_input.py:100(BlockingMouseInput)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:794(RegularPolygon)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1274(YAArrow)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2413(FancyBboxPatch)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_XYPair)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:837(_CollectionWithSizes)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1297(EventCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1713(TriMesh)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1718(AffineBase)\n",
       "        1    0.000    0.000    0.000    0.000 artist.py:1223(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 docstring.py:35(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:427(Colormap)\n",
       "       11    0.000    0.000    0.000    0.000 _color_data.py:31(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:171(RequestsCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_MemoryBIO)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:387(_CertificateSigningRequest)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:29(OCSPResponderEncoding)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:5(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.OpenSSL_add_all_algorithms}\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:18(HashAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:172(Encoding)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2737(ObjectIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 _types.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(Concat)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:949(KeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1044(NameConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:96(RSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:32(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:150(DSAParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:384(EllipticCurvePrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:22(SignedCertificateTimestamp)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(Version)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:375(_EllipticCurve)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:8(is_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:28(Retry)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:102(HTTPHeaderDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:74(_check_cryptography)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:10(ExpRelaxedCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:8(Laplace)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:8(LogisticNormal)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:26(Transform)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:17(Optimizer)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ASMoutput)\n",
       "        1    0.000    0.000    0.000    0.000 parallel_apply.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 nccl.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:17(<lambda>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:128(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:10(Embedding)\n",
       "        1    0.000    0.000    0.000    0.000 clip_grad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1188(CTCLoss)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:341(FormattedTimesMixin)\n",
       "        1    0.000    0.000    0.000    0.000 auto_double_backwards.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6060(mvoid)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:1814(Hermite)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:1764(Laguerre)\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:115(NpzFile)\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:7(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 function_base.py:241(iterable)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_LoggingWatcher)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:69(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2171(identity)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2887(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:1506(set_string_function)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:62(MachArLike)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:99(CFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3057(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:1876(_str_equal)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:110(GzipFile)\n",
       "       10    0.000    0.000    0.000    0.000 rcsetup.py:284(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 rcsetup.py:315(<listcomp>)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:631(validate_bbox)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:93(StrictVersion)\n",
       "        6    0.000    0.000    0.000    0.000 version.py:302(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 ImageEnhance.py:21(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:192(CenterCrop)\n",
       "        3    0.000    0.000    0.000    0.000 pathlib.py:664(_from_parsed_parts)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1484(_get_handler)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:737(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:757(setup_class)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:960(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:1115(append)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:773(_get_devnull)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1154(_get_handles)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1401(_try_wait)\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:196(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:760(getenv)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'title' of 'str' objects}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:854(ImageFileDirectory_v1)\n",
       "        1    0.000    0.000 178682.463 178682.463 <string>:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:629(_register_writer)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:375(EncodeVarint)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:418(TagBytes)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:37(oldstr)\n",
       "        3    0.000    0.000    0.000    0.000 decoder.py:249(_ModifiedDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:252(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:241(Duration)\n",
       "        3    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:5(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4214(copy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1972(__xor__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3015(parseImpl)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4003(parseImpl)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:589(SpecifierSet)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:103(MovedModule)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:2876(DistInfoDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:4(VendorImporter)\n",
       "        1    0.000    0.000    0.000    0.000 _procrustes.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _sketches.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:66(reset)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 odefunc.py:75(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:15(GeoAxes)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:319(HammerAxes)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:368(MollweideAxes)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:1790(XAxis)\n",
       "        1    0.000    0.000    0.000    0.000 triplot.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:34(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 table.py:32(Cell)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:1231(_Sparse_Matrix_coo)\n",
       "        1    0.000    0.000    0.000    0.000 trirefine.py:47(UniformTriRefiner)\n",
       "        1    0.000    0.000    0.000    0.000 quiver.py:235(QuiverKey)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:951(DateLocator)\n",
       "        3    0.000    0.000    0.000    0.000 legend_handler.py:340(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1440(_SelectorWidget)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:35(ToolBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:1024(ToolHelpBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:127(RendererBase)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:554(DrawingArea)\n",
       "        1    0.000    0.000    0.000    0.000 gridspec.py:175(GridSpec)\n",
       "        5    0.000    0.000    0.000    0.000 texmanager.py:96(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:137(MathtextBackendAgg)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:370(Fonts)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:911(Polygon)\n",
       "        1    0.000    0.000    0.000    0.000 afm.py:390(AFM)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:205(_DummyAxis)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1026(RegularPolyCollection)\n",
       "        2    0.000    0.000    0.000    0.000 cm.py:77(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1095(LockableBbox)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1865(Affine2D)\n",
       "        1    0.000    0.000    0.001    0.001 artist.py:1088(ArtistInspector)\n",
       "        1    0.000    0.000    0.000    0.000 cycler.py:77(Cycler)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:4936(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5844(unicode_set)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:264(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:95(SessionRedirectMixin)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:108(HTTPDigestAuth)\n",
       "        1    0.000    0.000    0.024    0.024 _internal_utils.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:863(DefaultCookiePolicy)\n",
       "        1    0.000    0.000    0.000    0.000 makefile.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:264(OCSPRequest)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:76(Blowfish)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:185(DHPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:12(MACContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:35(BlockCipherAlgorithm)\n",
       "        3    0.000    0.000    0.000    0.000 binding.py:106(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 intranges.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:183(PublicFormat)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:115(DNSName)\n",
       "        1    0.000    0.000    0.000    0.000 _ordereddict.py:23(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1129(AnyAlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:168(Asn1Value)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:781(NoticeReference)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1126(Extension)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1421(OCSPNonce)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:964(PublicKeyInfo)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:60(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:92(PrimePoint)\n",
       "        1    0.000    0.000    0.000    0.000 _errors.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:232(SubjectKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:447(FreshestCRL)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:48(EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1941(Revoked)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:13(LogEntryType)\n",
       "        6    0.000    0.000    0.000    0.000 crypto.py:625(_cmp)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:33(EUCTWProber)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:40(CharDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 euctwfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:11(FisherSnedecor)\n",
       "        1    0.000    0.000    0.000    0.000 beta.py:10(Beta)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:164(_InverseTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:514(LowerCholeskyTransform)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:63(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:113(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:44(__setstate__)\n",
       "        1    0.000    0.000    0.001    0.001 replicate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:9(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 activation.py:608(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:13(EmbeddingBag)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:23(THNNBackendBase)\n",
       "        1    0.000    0.000    0.000    0.000 nvtx.py:1(<module>)\n",
       "        1    0.000    0.000    0.239    0.239 tarfile.py:1613(taropen)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:7(RemovableHandle)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:7(_StorageBase)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:166(nts)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:3350(dtype)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6256(MaskedConstant)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6449(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:1811(HermiteE)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:1794(Legendre)\n",
       "        2    0.000    0.000    0.000    0.000 helper.py:245(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:66(TestLoader)\n",
       "        2    0.000    0.000    0.000    0.000 numeric.py:156(ones)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2896(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:532(max)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:455(iinfo)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:63(__new__)\n",
       "        7    0.000    0.000    0.000    0.000 _common.py:9(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:425(LoadLibrary)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:467(__len__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3081(parseImpl)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:3098(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 deprecation.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:324(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 rcsetup.py:596(validate_svg_fonttype)\n",
       "        1    0.000    0.000    0.009    0.009 __init__.py:936(rc_params)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1404(get_backend)\n",
       "        3    0.000    0.000    0.000    0.000 version.py:331(_cmp)\n",
       "        1    0.000    0.000    0.002    0.002 version.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:12(PhotoTour)\n",
       "        2    0.000    0.000    0.000    0.000 pathlib.py:898(__truediv__)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1011(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1726(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1725(_get_positional_actions)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1920(consume_positionals)\n",
       "        6    0.000    0.000    0.000    0.000 traitlets.py:383(class_init)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1280(setLevel)\n",
       "        7    0.000    0.000    0.000    0.000 enum.py:537(_generate_next_value_)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:806(fsdecode)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method atexit.register}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register_error}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.uname}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'isalnum' of 'str' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:561(PyDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:16(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 GifImagePlugin.py:46(GifImageFile)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:630(decorator)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:286(PngStream)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:33(olddict)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:593(_Parser)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:82(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:49(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:208(Node)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:327(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 literals.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl_multiscale.py:114(calc_output_size)\n",
       "        4    0.000    0.000    0.000    0.000 odenvp_conditional_rl_multiscale.py:210(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:68(Any)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:735(Struct)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'FindOneofByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:107(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4141(Forward)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4296(postParse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:314(_ParseResultsWithOffset)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:506(haskeys)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3256(ParseExpression)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3458(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3914(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:407(AppDirs)\n",
       "        8    0.000    0.000    0.000    0.000 version.py:261(<genexpr>)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:389(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:164(_SixMetaPathImporter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:957(Environment)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1381(NullProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1525(_register)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1583(MemoizedZipManifests)\n",
       "        2    0.000    0.000    0.213    0.107 __init__.py:3109(_call_aside)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:104(RecordWriter)\n",
       "        1    0.000    0.000    0.000    0.000 crc32c.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 thops.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:156(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 odefunc_rl.py:75(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:62(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:7(DiffEqWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:13(HyperLinear)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:36(FixedGridODESolver)\n",
       "        1    0.000    0.000    0.000    0.000 backend_agg.py:372(FigureCanvasAgg)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:32(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:230(ThetaLocator)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:705(RadialAxis)\n",
       "        1    0.000    0.000    0.000    0.000 triangulation.py:7(Triangulation)\n",
       "        1    0.000    0.000    0.000    0.000 trifinder.py:25(TrapezoidMapTriFinder)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:302(Grid)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:1308(_genitem)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:1409(_rrulestr)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:130(HandlerNpoints)\n",
       "        3    0.000    0.000    0.000    0.000 legend_handler.py:210(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 legend_handler.py:262(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:553(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:632(HandlerTuple)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:157(iter_user_libraries)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:940(RadioButtons)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:562(ToolViewsPositions)\n",
       "        1    0.000    0.000    0.000    0.000 tight_bbox.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1096(TimerBase)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:138(OffsetBox)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3901(FancyArrowPatch)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:4332(ConnectionPatch)\n",
       "        1    0.000    0.000    0.000    0.000 bezier.py:147(BezierSegment)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:561(Shadow)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1014(Wedge)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1407(Ellipse)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1534(Arc)\n",
       "        1    0.000    0.000    0.000    0.000 text.py:1280(TextWithDash)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1283(PercentFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2057(LogLocator)\n",
       "        1    0.000    0.000    0.000    0.000 font_manager.py:516(FontProperties)\n",
       "        1    0.000    0.000    0.000    0.000 contour.py:738(ContourSet)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:808(LogFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1780(QuadMesh)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1224(Transform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2131(BlendedGenericTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2715(ScaledTranslation)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:248(_ColorbarAutoMinorLocator)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:4445(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 Image.py:2798(register_save_all)\n",
       "        1    0.000    0.000    0.000    0.000 lock.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:102(PrimitiveType)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:210(Condition)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:371(Barrier)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:340(Session)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:84(HTTPAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:91(set_self_blocking)\n",
       "        4    0.000    0.000    0.000    0.000 _utils.py:8(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:25(MockRequest)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(KeyDerivationFunction)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:499(_SignedCertificateTimestamp)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:57(OCSPCertStatus)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:49(DHPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:118(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:126(_EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:14(Mode)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:48(ModeWithNonce)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:197(GCM)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:117(activate_builtin_random)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:269(_CallbackExceptionHelper)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:22(_OpenSSLError)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:40(NameAttribute)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:178(PrivateFormat)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:189(ParameterFormat)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1910(BitString)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:50(_ForceNullParameters)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:220(SignedDigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:561(EncryptionAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:971(Choice)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:862(TLSFeature)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:904(TLSFeatureType)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:918(InhibitAnyPolicy)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:54(OtherPrimeInfo)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:54(PrimeCurve)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:388(extended_datetime)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:231(PEMSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:300(AccessDescription)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:336(BasicConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:594(PolicyConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:103(EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:313(EllipticCurvePublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:10(ObjectIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:69(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1573(X509Store)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1696(X509StoreContext)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2387(PKCS12)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2568(NetscapeSPKI)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2665(_PassphraseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:5(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 utils.py:123(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:122(_ModuleWithDeprecations)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(AsymmetricSignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:247(WrappedSocket)\n",
       "        1    0.000    0.000    0.000    0.000 compat.py:22(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:35(CharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:18(is_local_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:9(Pareto)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:8(LogNormal)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:87(RelaxedOneHotCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 gumbel.py:13(Gumbel)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:11(HalfCauchy)\n",
       "        1    0.000    0.000    0.000    0.000 half_normal.py:11(HalfNormal)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:38(Dirichlet)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:211(_Interval)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:8(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1262(_get_methods)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1450(_register_builtin)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:27(DistributedDataParallel)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:10(DistributedDataParallelCPU)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:58(__setstate__)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:20(StorageWeakRef)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:35(DataParallel)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:19(DistributedDataParallel)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:4(is_available)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:21(RNNBase)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:10(PackedSequence)\n",
       "        1    0.000    0.000    0.000    0.000 convert_parameters.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:202(ModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:6(_InstanceNorm)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:27(L1Loss)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:5(Parameter)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:129(profile)\n",
       "        4    0.000    0.000    0.000    0.000 profiler.py:337(attr_formatter)\n",
       "        1    0.000    0.000    0.001    0.001 auto_symbolic.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:331(NestedIOFunction)\n",
       "        1    0.000    0.000    0.023    0.023 module.py:246(cuda)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:86(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:211(device)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:312(_LowLevelFile)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:218(_fromnxfunction)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:1606(Polynomial)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:184(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'tobytes' of 'numpy.generic' objects}\n",
       "        4    0.000    0.000    0.000    0.000 mixins.py:55(_unary_method)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:98(nd_grid)\n",
       "        3    0.000    0.000    0.000    0.000 index_tricks.py:241(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:52(_set_function_name)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:759(__getitem__)\n",
       "       10    0.000    0.000    0.000    0.000 case.py:1316(_deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1249(StructuredVoidFormat)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:96(_str_xmin)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:83(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1308(addCondition)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:2042(__invert__)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:2048(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2798(Regex)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3112(White)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3434(And)\n",
       "      2/1    0.000    0.000    0.000    0.000 deprecation.py:248(wrapper)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:108(validate_path_exists)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:190(validate_dpi)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:484(update_savefig_format)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:308(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:666(get_candidate_paths)\n",
       "        3    0.000    0.000    0.000    0.000 version.py:69(__ge__)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:903(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:29(Stat)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:24(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:44(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:48(__enter__)\n",
       "        2    0.000    0.000    0.000    0.000 pathlib.py:685(_make_child)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1148(_sys_version)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:824(metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:2984(bind)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:2175(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:800(createLock)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:758(__del__)\n",
       "        1    0.000    0.000    0.000    0.000 re.py:314(_compile_repl)\n",
       "        4    0.000    0.000    0.000    0.000 genericpath.py:53(getmtime)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:93(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'count' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.charmap_build}\n",
       "        1    0.000    0.000    0.000    0.000 JpegImagePlugin.py:300(JpegImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:324(Parser)\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:56(BmpImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:74(ImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:137(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:97(ChunkStream)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:409(_VarintBytes)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:542(_FloatingPointEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:318(Leaf)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:10(ParserGenerator)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:19(LParen)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:22(RParen)\n",
       "        1    0.000    0.000    0.000    0.000 workspace.py:494(_BlobDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(RTs)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl_multiscale.py:105(_calc_n_scale)\n",
       "        2    0.000    0.000    0.000    0.000 types_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:230(RepeatedScalarFieldContainer)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:343(RepeatedCompositeFieldContainer)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:434(ScalarMap)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:4383(postParse)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:644(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1298(addCondition)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3064(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3046(White)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3368(And)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3715(ParseElementEnhance)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:72(LegacyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:28(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:173(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1123(ResourceManager)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2973(Requirement)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:312(_PlistParser)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:10(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:64(install)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:175(get_supported_platform)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(VersionConflict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:301(DistributionNotFound)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:170(Permute2d)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:114(_compare)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:17(NumpyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:166(ConcatConv2d_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:242(GatedConvTranspose)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(MovingBatchNormNd)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:134(MovingBatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization_rl.py:5(RegularizedODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:151(AdamsBashforthMoulton)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:5(RegularizedODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:241(_GeoTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:268(AitoffAxes)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:19(PolarTransform)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:13(register)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:2164(YAxis)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:131(Log10Transform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:191(LogScale)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:600(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 _base.py:131(_process_plot_var_args)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:404(XTick)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:349(StreamMask)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:81(DictReader)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:93(rrulebase)\n",
       "        1    0.000    0.000    0.000    0.000 _subplots.py:11(SubplotBase)\n",
       "        1    0.000    0.000    0.000    0.000 category.py:23(StrCategoryConverter)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1136(AutoDateLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1554(SecondLocator)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:218(reload_library)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:635(TextBox)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1890(ToolHandles)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:2751(Lasso)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3179(_Backend)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:26(Cursors)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:147(ToolToggleBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:237(SetCursorBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:384(ToolQuit)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:958(ToolPan)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:61(Widget)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:256(Slider)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:966(AnchoredOffsetbox)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1324(CloseEvent)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:856(AuxTransformBox)\n",
       "        1    0.000    0.000    0.000    0.000 gridspec.py:30(GridSpecBase)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1909(SsGlue)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:2523(State)\n",
       "        1    0.000    0.000    0.000    0.000 dviread.py:766(PsfontsMap)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:746(UnicodeFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1503(Accent)\n",
       "        1    0.000    0.000    0.000    0.000 textpath.py:412(TextPath)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:880(PathPatch)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1378(CirclePolygon)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1490(Circle)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1498(IndexLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1810(MaxNLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:410(StrMethodFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1169(EngFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 lines.py:1348(VertexSelector)\n",
       "        1    0.000    0.000    0.000    0.000 cm.py:185(ScalarMappable)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1621(TransformWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1725(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1777(Affine2DBase)\n",
       "        1    0.000    0.000    0.004    0.004 artist.py:1217(get_setters)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:55(TransformNode)\n",
       "        1    0.000    0.000    0.001    0.001 pyplot.py:621(close)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:1068(SymLogNorm)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:1510(LightSource)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4076(ZeroOrMore)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4449(postParse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4543(OnlyOnce)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:5833(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5885(Japanese)\n",
       "        5    0.000    0.000    0.000    0.000 Image.py:2776(register_mime)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:12(qualify)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:297(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:127(_DenseLayer)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:5(Sampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:46(ConcatDataset)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:46(SemLock)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_pandas.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:485(BaseCookie)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:90(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:60(RequestEncodingMixin)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:272(PreparedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:989(_ZipWriteFile)\n",
       "        1    0.000    0.000    0.002    0.002 certs.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:13(where)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:318(ZipInfo)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:714(_SharedFile)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:329(_RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:32(_X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:26(AES)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:91(CAST5)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:106(ARC4)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:217(_DHPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:142(DHPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:170(DHPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:108(_DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:228(_EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:325(_OCSPRequest)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:176(_RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:96(Cipher)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:146(CFB)\n",
       "        1    0.000    0.000    0.000    0.000 cmac.py:16(_CMACContext)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ciphers.py:13(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_set_default_RAND}\n",
       "        1    0.000    0.000    0.000    0.000 name.py:142(Name)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:46(CRLEntryExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:130(AuthorityInformationAccessOID)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'new_allocator' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2501(ParsableOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:272(SignedDigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(Any)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:744(UserNotice)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1315(CRLReason)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1449(UnrecognizedExtension)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:86(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:264(CharacteristicTwo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:473(PrivateKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:338(RSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:48(HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:63(ExtensionType)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:406(CRLDistributionPoints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:655(CertificatePolicies)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:24(EllipticCurve)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:88(EllipticCurvePrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:54(RSAPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1550(X509StoreFlags)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:18(Version)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:369(RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:693(RevokedCertificateBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(register_interface_if)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:33(SingleByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 langcyrillicmodel.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langgreekmodel.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:36(EUCJPProber)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:33(GB2312Prober)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:34(EUCKRProber)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:34(Big5Prober)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:122(PoolManager)\n",
       "        1    0.000    0.000    0.000    0.000 charsetgroupprober.py:32(CharSetGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 escprober.py:35(EscCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:96(Latin1Prober)\n",
       "        1    0.000    0.000    0.000    0.000 utf8prober.py:35(UTF8Prober)\n",
       "        1    0.000    0.000    0.000    0.000 sjisprober.py:36(SJISProber)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:29(is_prod_appengine_mvms)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:18(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:28(RecentlyUsedContainer)\n",
       "        1    0.000    0.000    0.000    0.000 request.py:10(RequestMethods)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:117(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:92(RelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:19(cuFFTPlanCache)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:69(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:24(_Dirichlet)\n",
       "        1    0.000    0.000    0.000    0.000 chi2.py:6(Chi2)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:38(_parse_env)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:550(ignore_lib_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:784(OrderedDictWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:198(ExponentialLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:254(ReduceLROnPlateau)\n",
       "        3    0.000    0.000    0.000    0.000 rendezvous.py:13(register_rendezvous_handler)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:8(WeightNorm)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:6(PixelShuffle)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:9(Upsample)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:7(PairwiseDistance)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:6(Fold)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:415(ParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:568(AvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:13(_BatchNorm)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:11(LocalResponseNorm)\n",
       "        2    0.000    0.000    0.000    0.000 dropout.py:17(extra_repr)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:22(Dropout)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:10(Threshold)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:621(Softshrink)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1049(MultiMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:7(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 function.py:273(_iter_filter)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:108(Function)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:131(Event)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:73(_check_driver)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:612(_FileInFile)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:59(metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6348(__setattr__)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:86(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:796(_DomainCheckInterval)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1315(_replace_dtype_fields)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:20(Arrayterator)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:28(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_string_function}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:216(_getintp_ctype)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:270(NameValidator)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:57(_Deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:997(SafeEval)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:16(BaseTestSuite)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:76(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:29(TextTestResult)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1923(suppress_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:845(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2902(_setdef)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:44(_Outcome)\n",
       "        6    0.000    0.000    0.000    0.000 case.py:420(addTypeEqualityFunc)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:17(MachAr)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:88(_str_eps)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:156(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:325(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:654(__getattr__)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:2067(suppress)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2526(CaselessLiteral)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3130(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3246(StringStart)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:3265(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3322(ParseExpression)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3589(MatchFirst)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4067(__str__)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:153(validate_float_or_None)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:209(validate_int_or_None)\n",
       "        5    0.000    0.000    0.000    0.000 rcsetup.py:413(validate_aspect)\n",
       "        6    0.000    0.000    0.000    0.000 rcsetup.py:501(validate_ps_distiller)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:645(get_cachedir)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:687(get_data_path)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:932(copy)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:615(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:629(Stack)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:481(RandomResizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:306(Color3DLUT)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:341(StructOrUnion)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:82(CocoDetection)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:12(STL10)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:10(SVHN)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:232(get_context)\n",
       "        2    0.000    0.000    0.000    0.000 configurable.py:381(instance)\n",
       "        2    0.000    0.000    0.000    0.000 configurable.py:426(initialized)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:87(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 argparse.py:1733(parse_args)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:2071(_match_arguments_partial)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1255(python_implementation)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:819(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:2259(class_init)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:2335(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:1056(_open)\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:220(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 re.py:330(filter)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:12(pickle)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:337(__members__)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:963(expand_template)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:85(_showwarnmsg)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:106(_formatwarnmsg)\n",
       "        2    0.000    0.000    0.000    0.000 _collections_abc.py:271(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rfind' of 'bytes' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method sys.getdlopenflags}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'index' of 'str' objects}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'union' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._jit_init}\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(Iterator)\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ImagePalette.py:23(ImagePalette)\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:22(PaletteFile)\n",
       "        1    0.000    0.000    0.000    0.000 TiffTags.py:23(TagInfo)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:620(_register_loader)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:188(iTXt)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:126(_SimpleSizer)\n",
       "        3    0.000    0.000    0.000    0.000 encoder.py:184(_FixedSizer)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:272(DebugMode)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:77(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:100(TextWriter)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:1022(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:98(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:107(_VarintDecoder)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:134(_SignedVarintDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:288(_FloatDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:26(BottomMatcher)\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:16(MinNode)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:415(BasePattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:606(WildcardPattern)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:38(PatternCompiler)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:17(BMNode)\n",
       "        1    0.000    0.000    0.000    0.000 driver.py:30(Driver)\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:23(Grammar)\n",
       "        2    0.000    0.000    0.000    0.000 tokenize.py:50(maybe)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:197(Untokenizer)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:347(DFAState)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:27(Parser)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:46(DescriptorDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:398(FieldMask)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:788(ListValue)\n",
       "        3    0.000    0.000    0.000    0.000 graph_pb2.py:5(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 versions_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:185(BaseContainer)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:41(EnumTypeWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:36(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 symbol_database.py:65(SymbolDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:94(DescriptorBase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:607(EnumDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:712(OneofDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:748(ServiceDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:803(MethodDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:843(FileDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:44(Node)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:272(Marker)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4335(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 pyparsing.py:4904(makeHTMLTags)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:205(ParseBaseException)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:315(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:460(__iter__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:666(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2439(Keyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3213(WordStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3233(WordEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3962(Optional)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:42(_BaseVersion)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:7(Infinity)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:39(NegativeInfinity)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:20(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:75(Requirement)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:86(_LazyDescr)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:124(_LazyModule)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:139(MovedAttribute)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:320(Module_six_moves_urllib_parse)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:380(Module_six_moves_urllib_request)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:430(Module_six_moves_urllib_response)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1506(DefaultProvider)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1860(register_finder)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1989(NoDists)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:2076(register_namespace_handler)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:79(_InternalDict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:127(Plist)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:454(_PlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:11(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:56(S3RecordWriter)\n",
       "        1    0.000    0.000    0.000    0.000 torchvis.py:19(TorchVis)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:40(SummaryToEventTransformer)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:144(FileWriter)\n",
       "        1    0.000    0.000    0.000    0.000 embedding.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:32(EventsWriter)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:79(EventFileWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:288(ContextualVersionConflict)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:342(register_loader_type)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:500(IMetadataProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:905(subscribe)\n",
       "        1    0.000    0.000    0.003    0.003 train_misc.py:15(set_cnf_options)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:4(SequentialFlow_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:9(_ActNorm)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:110(Conv2d)\n",
       "        3    0.000    0.000    0.000    0.000 _testutils.py:26(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:136(__lt__)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:260(BlendLinear)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:6(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:128(MovingBatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:7(CouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:6(BruteForceLayer)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:7(PlanarFlow)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:6(FeedforwardGateI)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:46(FeedforwardGateII)\n",
       "        1    0.000    0.000    0.000    0.000 dopri5.py:58(Dopri5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:5(Euler)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:7(OdeintAdjointMethod)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint_sep.py:7(OdeintAdjointMethod)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:63(Swish)\n",
       "        1    0.000    0.000    0.000    0.000 cnf.py:11(CNF)\n",
       "        1    0.000    0.000    0.000    0.000 tsit5.py:66(Tsit5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(get_projection_names)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:322(HammerTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:442(LambertAxes)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:86(PolarAffine)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:125(InvertedPolarTransform)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:207(_AxisWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:270(ThetaTick)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:373(ThetaAxis)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:759(_WedgeBbox)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:12(ScaleBase)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:85(LogTransformBase)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:159(NaturalLogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:363(SymmetricalLogScale)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:527(YTick)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:16(TriInterpolator)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:237(LinearTriInterpolator)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3601(GaussianKDE)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:24(Dialect)\n",
       "        1    0.000    0.000    0.000    0.000 stackplot.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:1105(_iterinfo)\n",
       "        1    0.000    0.000    0.000    0.000 units.py:87(ConversionInterface)\n",
       "        1    0.000    0.000    0.000    0.000 units.py:136(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:338(bytespdate2num)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:846(rrulewrapper)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1031(RRuleLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1574(MicrosecondLocator)\n",
       "        1    0.000    0.000    0.000    0.000 figure.py:60(AxesStack)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:440(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:549(HandlerStem)\n",
       "        1    0.000    0.000    0.029    0.029 core.py:151(load_base_library)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:164(update_user_library)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1669(SpanSelector)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:2538(PolygonSelector)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3011(ToolContainerBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:404(ToolEnableAllNavigation)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:492(ToolMinorGrid)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:542(ToolYScale)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:760(SaveFigureBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:768(ZoomPanBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:832(ToolZoom)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:1066(ToolCopyToClipboardBase)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:134(Button)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:481(CheckButtons)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1260(OffsetImage)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1607(DraggableBase)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:781(AxesImage)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:1023(PcolorImage)\n",
       "        1    0.000    0.000    0.000    0.000 legend.py:50(DraggableLegend)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:471(PaddedBox)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:686(TextArea)\n",
       "        1    0.000    0.000    0.000    0.000 blocking_input.py:30(BlockingInput)\n",
       "        1    0.000    0.000    0.000    0.000 blocking_input.py:267(BlockingContourLabeler)\n",
       "        1    0.000    0.000    0.000    0.000 gridspec.py:409(SubplotSpec)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1594(Hlist)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1705(Vlist)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1849(GlueSpec)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:2037(Ship)\n",
       "        1    0.000    0.000    0.015    0.015 mathtext.py:2738(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:3227(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dviread.py:580(Vf)\n",
       "        1    0.000    0.000    0.000    0.000 dviread.py:934(Encoding)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:83(MathtextBackend)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:529(TruetypeFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:934(StixFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1355(Node)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1425(Char)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1532(List)\n",
       "        1    0.000    0.000    0.000    0.000 textpath.py:32(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1172(FancyArrow)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1854(_simpleprint_styles)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1863(_Style)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2687(_Base)\n",
       "        1    0.000    0.000    0.000    0.000 text.py:1682(OffsetFrom)\n",
       "        1    0.000    0.000    0.000    0.000 text.py:1766(_AnnotationBase)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1399(Locator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1591(LinearLocator)\n",
       "        1    0.000    0.000    0.000    0.000 contour.py:1453(QuadContourSet)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:252(Formatter)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:886(PathCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:912(PolyCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:979(BrokenBarHCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1105(LineCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1544(CircleCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1564(EllipseCollection)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:1019(TransformedBbox)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:275(_ColorbarLogLocator)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:1058(Colorbar)\n",
       "        1    0.000    0.000    0.000    0.000 docstring.py:7(Substitution)\n",
       "        1    0.000    0.000    0.000    0.000 docstring.py:61(Appender)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:83(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:218(_ColorbarAutoLocator)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:306(ColorConverter)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:632(LinearSegmentedColormap)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:870(Normalize)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:72(_ColorMapping)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:94(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4488(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:4536(postParse)\n",
       "        1    0.000    0.000    0.003    0.003 pyparsing.py:5057(makeHTMLTags)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:25(BaseTypeByIdentity)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:85(VoidType)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:59(LSUN)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:96(WeightedRandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:300(_DataLoaderIter)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:720(DataLoader)\n",
       "        1    0.000    0.000    0.000    0.000 _utils.py:123(Comparable)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:25(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:24(VGG)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:93(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:86(TqdmDefaultWriteLock)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:97(MockResponse)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:13(CaseInsensitiveDict)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:13(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1819(PyZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:830(CookiePolicy)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1755(FileCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1961(MozillaCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:148(ChaCha20)\n",
       "        1    0.000    0.000    0.000    0.000 __version__.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:760(ZipExtFile)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:76(OCSPRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:175(OCSPResponseBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:418(_RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:17(AsymmetricPadding)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:14(X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:31(X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:42(Camellia)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:57(TripleDES)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:197(_DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:52(Prehashed)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:13(_HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:15(_HMACContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:67(AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:228(_AEADEncryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:39(ModeWithTweak)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:57(ModeWithAuthenticationTag)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:85(CBC)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:100(XTS)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:131(OFB)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:161(CFB8)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:176(CTR)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:106(_DHPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:20(CipherAlgorithm)\n",
       "        3    0.000    0.000    0.000    0.000 SSL.py:636(_make_requires)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:57(make_assert)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:60(Hash)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:146(BLAKE2b)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:167(BLAKE2s)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:50(RFC822Name)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:160(UniformResourceIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:227(DirectoryName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:253(RegisteredID)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:279(IPAddress)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:317(OtherName)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1695(AbstractString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1776(Boolean)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1829(Integer)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2198(OctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2286(IntegerBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2370(OctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2448(IntegerOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4298(Set)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:14(TeletexCodec)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:180(RSASSAPSSParams)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:372(Pbkdf2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:475(RSAESOAEPParams)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:510(DSASignature)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:693(Constructable)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1165(GeneralNames)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1210(SubjectAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1245(IssuerAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1280(CertificateIssuer)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1343(InvalidityDate)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1373(PrecertificateSignedCertificateTimestamps)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:74(RSAPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:116(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:136(_ECPoint)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:252(Pentanomial)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:284(FieldID)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:313(SpecifiedECDomain)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:435(Attribute)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:389(ScryptBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:72(Extensions)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:261(AuthorityInformationAccess)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:378(DeltaCRLIndicator)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:14(DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:65(DSAPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:189(DSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:227(DSAPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:39(EllipticCurveSignatureAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:288(ECDSA)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1682(X509StoreContextError)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2336(PKCS7)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:431(CertificateBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:598(CertificateRevocationListBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:46(register_decorator)\n",
       "        1    0.000    0.000    0.000    0.000 langthaimodel.py:37(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langbulgarianmodel.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:12(RequestException)\n",
       "        2    0.000    0.000    0.000    0.000 exceptions.py:40(SSLError)\n",
       "        4    0.000    0.000    0.000    0.000 pyopenssl.py:102(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 crypto.py:205(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:116(JapaneseContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:183(SJISContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:34(CP949Prober)\n",
       "        1    0.000    0.000    0.000    0.000 euckrfreq.py:41(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312freq.py:42(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:55(GzipDecoderState)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:10(LifoQueue)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:362(ProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:17(LanguageFilter)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:50(SequenceLikelihood)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:33(CodingStateMachine)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:34(MultiByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:223(HTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:50(RequestField)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:55(ConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:736(HTTPSConnectionPool)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:6(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 alexnet.py:13(AlexNet)\n",
       "        2    0.000    0.000    0.000    0.000 constraint_registry.py:83(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:77(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:290(ExpTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:340(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:362(AbsTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:379(AffineTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:446(SoftmaxTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:472(StickBreakingTransform)\n",
       "        1    0.000    0.000    0.000    0.000 exp_family.py:5(ExponentialFamily)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:61(_ResourceSharer)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:7(Warning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:960(ScriptModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1292(TracedModule)\n",
       "        2    0.000    0.000    0.000    0.000 annotations.py:15(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:142(reduce_op)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:111(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:112(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:119(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:120(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:150(update_group)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:154(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:5(Adagrad)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:6(SparseAdam)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:6(ASGD)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:5(SGD)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:6(Rprop)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:5(RMSprop)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:6(LBFGS)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:10(_LRScheduler)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:56(LambdaLR)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:42(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 adaptive.py:15(AdaptiveLogSoftmaxWithLoss)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:35(ReduceAddCoalesced)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:29(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:71(reduce_op)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:10(_ConstantPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:270(_ReplicationPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:169(EmbeddingBag)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:9(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:47(CosineSimilarity)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:22(Sequential)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:96(ModuleList)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:318(ParameterList)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:647(FractionalMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:707(_LPPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:723(LPPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:838(AdaptiveMaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:863(AdaptiveMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:899(AdaptiveMaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:948(AdaptiveAvgPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:971(AdaptiveAvgPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:1005(AdaptiveAvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:98(BatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:58(InstanceNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:165(GroupNorm)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:6(_DropoutNd)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:105(Dropout3d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:12(_ConvNd)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:69(Conv1d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:451(_ConvTransposeMixin)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:509(ConvTranspose1d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:617(ConvTranspose2d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:760(ConvTranspose3d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:89(RReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:146(Hardtanh)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:242(Sigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:295(ELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:335(CELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:380(SELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:501(LeakyReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:551(LogSigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:576(Softplus)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:780(Softmin)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:818(Softmax)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:96(NLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:370(MSELoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:438(BCELoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:507(BCEWithLogitsLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:598(HingeEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:658(MultiLabelMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:713(SmoothL1Loss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:815(CrossEntropyLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:907(MultiLabelSoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:954(CosineEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1001(MarginRankingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1112(TripletMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:11(Linear)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:226(TensorDescriptorArray)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:460(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:464(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:24(EventList)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:377(FunctionEvent)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:7(Type)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:39(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:10(_ContextMethodMixin)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:79(FunctionMeta)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:6(Backends)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:18(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(THNNCudaBackendStateMixin)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:499(_CudaBase)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:336(_Stream)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:582(_StreamProxy)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1443(MAxisConcatenator)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:3366(shape)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6284(__array_finalize__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6440(_extrema_operation)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:177(_ndptr)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:206(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:805(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:845(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:866(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2378(_MaskedPrintOption)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2596(MaskedIterator)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:18(NumpyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:13(RTLD_for_MKL)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:224(_FFTCache)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:162(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:138(_FileOpeners)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:621(Repository)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:170(LineSplitter)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:34(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:115(NoseTester)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:231(AxisConcatenator)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:446(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:476(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:531(ndindex)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:653(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 function_base.py:1760(vectorize)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:92(TestSuite)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:270(_ErrorHolder)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:23(_FailedTest)\n",
       "        7    0.000    0.000    0.000    0.000 _inspect.py:144(<lambda>)\n",
       "        5    0.000    0.000    0.000    0.000 _inspect.py:145(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2824(errstate)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:184(_AssertRaisesContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1338(FunctionTestCase)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1396(_SubTest)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:440(_recursive_guard)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:810(FloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:217(record)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:20(memmap)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:92(_str_epsneg)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:100(_str_xmax)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:104(_str_resolution)\n",
       "        9    0.000    0.000    0.000    0.000 _globals.py:73(__repr__)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:55(_NoValueType)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:9(PackageLoader)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:215(ParseBaseException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2398(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2461(Keyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3217(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3250(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3781(ParseElementEnhance)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1769(Locked)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2020(_OrderedSet)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:69(_PaddedFile)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:377(_GzipReader)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:103(validate_any)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:422(validate_fontsize_None)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:9(Omniglot)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:313(set_level)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:625(get_configdir)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1264(rc_context)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1415(interactive)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:31(Version)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:70(_StrongRef)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:88(CallbackRegistry)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:225(silent_list)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:904(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:867(Grouper)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:436(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:17(SEMEION)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:16(CIFAR10)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:12(MNIST)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:179(EMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 fakedata.py:6(FakeData)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:413(close)\n",
       "        2    0.000    0.000    0.000    0.000 pathlib.py:89(join_parsed_parts)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1211(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:829(__prepare__)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:545(__get__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1982(createLock)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:203(_cleanup)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:22(constructor)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:760(_missing_)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:868(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 sre_parse.py:161(__delitem__)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:287(seek)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:885(addgroup)\n",
       "        1    0.000    0.000    0.000    0.000 _collections_abc.py:406(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:185(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rstrip' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedReader' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
       "        1    0.000    0.000    0.000    0.000 {method '__prepare__' of 'type' objects}\n",
       "        5    0.000    0.000    0.000    0.000 {method 'intersection' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getCompiledVersion}\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:62(GradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:549(PyCodecState)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:103(GimpGradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:48(PpmImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:209(PngInfo)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:540(PngImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:678(_idat)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:155(_ModifiedSizer)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:429(_SimpleEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:80(PackTag)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:14(BaseOldStr)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:73(Error)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:253(_Printer)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:92(TypeChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:125(IntValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:146(EnumValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:166(UnicodeValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:194(Int32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:202(Uint32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:208(Int64ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:323(_DoubleDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:822(_FieldSkipper)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:24(BaseBaseString)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:33(basestring)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:501(LeafPattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:545(NodePattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:794(NegatedPattern)\n",
       "        1    0.000    0.000    0.000    0.000 pygram.py:20(Symbols)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:24(PatternSyntaxError)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:43(_EveryNode)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:167(FixerError)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:688(MultiprocessingUnsupported)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:692(MultiprocessRefactoringTool)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:49(any)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:164(TokenError)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:7(PgenGrammar)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:241(Py2Fixer)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:457(hooks)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:16(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:79(Graph_py)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl_multiscale.py:51(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_rl_multiscale.py:199(StackedCNFLayers)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:1056(Default)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:42(DescriptorDatabaseConflictingDefinitionError)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:47(MessageFactory)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:60(Error)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:64(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:541(_FieldMaskTree)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:19(Node_base)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:38(Node_py)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:63(Node_py_IO)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:39(Error)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:40(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:41(EncodeError)\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:42(GeneratedProtocolMessageType)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:51(Error)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:64(DescriptorMetaclass)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:76(_Lock)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:165(_NestedDescriptorBase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:672(EnumValueDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:25(InvalidMarker)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:59(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:65(Value)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4026(SkipTo)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4163(__lshift__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4226(TokenConverter)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4234(Combine)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4278(Group)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4299(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4364(Suppress)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4390(OnlyOnce)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:261(ParseException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:282(ParseFatalException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:287(ParseSyntaxException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:306(RecursiveGrammarException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1478(_FifoCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2364(Token)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2372(Empty)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2383(NoMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2398(Literal)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2504(CaselessLiteral)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2527(CaselessKeyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2838(QuotedString)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2975(CharsNotIn)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3066(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3097(_PositionToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3104(GoToColumn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3151(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3130(LineStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3160(LineEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3184(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3180(StringStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3199(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3195(StringEnd)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:3461(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3444(Or)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3591(Each)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3792(FollowedBy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3818(NotAny)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3850(_MultipleMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3888(OneOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3923(ZeroOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3954(_NullToken)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:15(InvalidSpecifier)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:27(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:18(InvalidRequirement)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:229(_MovedItems)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:360(Module_six_moves_urllib_error)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:451(Module_six_moves_urllib_robotparser)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1107(ExtractionError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1127(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1484(EggProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1536(EmptyProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1556(ZipManifests)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1778(FileMetadata)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1817(PathMetadata)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1842(EggMetadata)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1907(find_nothing)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2857(EggInfoDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2946(RequirementParseError)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:109(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:416(_DumbXMLWriter)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:595(_BinaryPlistParser)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:764(_BinaryPlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:141(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:29(register_writer_factory)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:89(S3RecordWriterFactory)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:156(_EventLoggerThread)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(PEP440Warning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:249(ResolutionError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:328(UnknownExtra)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:523(IResourceProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:937(_ReqExtras)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:22(SqrtmError)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1044(LstsqLapackError)\n",
       "        1    0.000    0.000    0.000    0.000 misc.py:11(LinAlgWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:138(DeprecatedImport)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:11(CNF_augment)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate_sep.py:20(CNF_Gate_Sep)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:63(Swish)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:73(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:94(ODEnet)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:176(AutoencoderDiffEqNet)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:255(ODEfunc_rl)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc_rl.py:321(AutoencoderODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:40(AverageMeter)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(RunningAverageMeter)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:115(ParallelSumModules)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:126(ParallelCNFLayers)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:83(ActNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:95(LinearZeros)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:152(Conv2dZeros)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:194(InvertibleConv1x1)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:291(Split2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:347(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:361(MultiLinearZeros)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:16(FPUModeChangeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:21(PytestTester)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:78(_compare_version)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:316(AutoencoderODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:7(SequentialDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:21(MixtureODELayer)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:29(ReshapeDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:9(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:38(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:36(IgnoreLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:45(ConcatLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:56(ConcatLinear_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:66(SquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:88(HyperConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:124(IgnoreConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:137(SquashConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:151(ConcatConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:180(ConcatSquashConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:196(ConcatCoordConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:214(GatedLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:226(GatedConv)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:272(BlendConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:89(FeedforwardGateIII)\n",
       "        1    0.000    0.000    0.000    0.000 rk_common.py:8(_RungeKuttaState)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:15(Midpoint)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:26(RK4)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:208(AdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:18(_VCABMState)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:61(VariableCoefficientAdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:73(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:94(ODEnet)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:176(AutoencoderDiffEqNet)\n",
       "        1    0.000    0.000    0.000    0.000 backend_agg.py:592(_BackendAgg)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:8(ZeroMeanTransform)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:25(LogitTransform)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:43(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:4(SequentialFlow)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:6(ProjectionRegistry)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:96(get_projection_names)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:17(ThetaFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:271(AitoffTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:298(InvertedAitoffTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:344(InvertedHammerTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:371(MollweideTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:413(InvertedMollweideTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:445(LambertTransform)\n",
       "        1    0.000    0.000    0.000    0.000 geo.py:488(InvertedLambertTransform)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:184(ThetaFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:418(RadialLocator)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:462(_ThetaShift)\n",
       "        1    0.000    0.000    0.000    0.000 polar.py:521(RadialTick)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:53(LinearScale)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:118(InvertedLogTransformBase)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:138(InvertedLog10Transform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:152(InvertedLog2Transform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:298(SymmetricalLogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:331(InvertedSymmetricalLogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:478(LogisticTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:499(LogitScale)\n",
       "        3    0.000    0.000    0.000    0.000 scale.py:551(get_scale_names)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:650(Ticker)\n",
       "        2    0.000    0.000    0.000    0.000 axis.py:663(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 axis.py:655(_LazyTickList)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:404(TerminateTrajectory)\n",
       "        1    0.000    0.000    0.000    0.000 tricontour.py:8(TriContourSet)\n",
       "        1    0.000    0.000    0.000    0.000 trifinder.py:7(TriFinder)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:1012(_DOF_estimator)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:1089(_DOF_estimator_geom)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:1173(_DOF_estimator_min_E)\n",
       "        1    0.000    0.000    0.000    0.000 trirefine.py:10(TriRefiner)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:55(excel)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:70(unix_dialect)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:131(DictWriter)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:166(Sniffer)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:229(StreamplotSet)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:239(DomainMap)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:304(rrule)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:1557(PCA)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:2943(FormatObj)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:2962(FormatString)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:2980(FormatFloat)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:2999(FormatInt)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3012(FormatBool)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3027(FormatThousands)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3033(FormatMillions)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3039(FormatDate)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3057(FormatDatetime)\n",
       "        1    0.000    0.000    0.000    0.000 _subplots.py:218(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 category.py:109(StrCategoryLocator)\n",
       "        1    0.000    0.000    0.000    0.000 category.py:127(StrCategoryFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 units.py:52(AxisInfo)\n",
       "        1    0.000    0.000    0.000    0.000 units.py:132(Registry)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:322(strpdate2num)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:723(IndexDateFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:747(AutoDateFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1370(YearLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1434(MonthLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1459(WeekdayLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1766(DateConverter)\n",
       "        1    0.000    0.000    0.000    0.000 rrule.py:66(weekday)\n",
       "        4    0.000    0.000    0.000    0.000 rrule.py:80(_invalidates_cache)\n",
       "        1    0.000    0.000    0.000    0.000 figure.py:169(SubplotParams)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:103(BarContainer)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:160(StemContainer)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:41(HandlerBase)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:174(HandlerNpointsYoffsets)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:206(HandlerLine2D)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:258(HandlerPatch)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:304(HandlerLineCollection)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:336(HandlerRegularPolyCollection)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:424(HandlerCircleCollection)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:436(HandlerErrorbar)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:649(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:687(HandlerPolyCollection)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1085(SubplotTool)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1234(Cursor)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:1325(MultiCursor)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:2380(EllipseSelector)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:2451(LassoSelector)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3284(Show)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3292(ShowBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:309(ToolCursorPosition)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:356(RubberbandBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:394(ToolQuitAll)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:420(ToolEnableNavigation)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:437(_ToolGridBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:471(ToolGrid)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:512(ToolFullScreen)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:525(AxisScaleBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:552(ToolXScale)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:714(ViewsPositionsBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:726(ToolHome)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:735(ToolBack)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:744(ToolForward)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:23(LockDraw)\n",
       "        1    0.000    0.000    0.000    0.000 widgets.py:92(AxesWidget)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1214(AnchoredText)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1730(DraggableOffsetBox)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:1155(FigureImage)\n",
       "        1    0.000    0.000    0.000    0.000 image.py:1216(BboxImage)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1251(Event)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1333(LocationEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1428(MouseEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1485(PickEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1529(KeyEvent)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:317(VPacker)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:393(HPacker)\n",
       "        1    0.000    0.000    0.000    0.000 blocking_input.py:326(BlockingKeyMouseInput)\n",
       "        1    0.000    0.000    0.000    0.000 gridspec.py:348(GridSpecFromSubplotSpec)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1779(Rule)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1796(Hrule)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1807(Vrule)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1816(Glue)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1893(Filll)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1901(NegFill)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1905(NegFilll)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1913(HCentered)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1922(VCentered)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1930(Kern)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1959(SubSuperCluster)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1973(AutoHeightChar)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:2010(AutoWidthChar)\n",
       "        1    0.000    0.000    0.000    0.000 dviread.py:490(DviFont)\n",
       "        1    0.000    0.000    0.000    0.000 dviread.py:711(Tfm)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:211(MathtextBackendBitmap)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:217(MathtextBackendPs)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:257(MathtextBackendPdf)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:285(MathtextBackendSvg)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:314(MathtextBackendPath)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:342(MathtextBackendCairo)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:861(DejaVuFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:904(DejaVuSerifFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:919(DejaVuSansFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1053(StixSansFonts)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1244(FontConstantsBase)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1280(ComputerModernFontConstants)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1291(STIXFontConstants)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1307(DejaVuSerifFontConstants)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1311(DejaVuSansFontConstants)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1385(Box)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1411(Vbox)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1418(Hbox)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3747(Fancy)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3846(Wedge)\n",
       "        1    0.000    0.000    0.000    0.000 bezier.py:11(NonIntersectingPathException)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:1963(_Base)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2012(Square)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2041(Circle)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2063(LArrow)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2101(RArrow)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2116(DArrow)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2166(Round)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2228(Round4)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2281(Sawtooth)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2379(Roundtooth)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2779(Arc3)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2815(Angle3)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2853(Angle)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2915(Arc)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3009(Bar)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3141(_Base)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3220(_Curve)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3355(Curve)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3364(CurveA)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3383(CurveB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3402(CurveAB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3421(CurveFilledA)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3441(CurveFilledB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3461(CurveFilledAB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3481(_Bracket)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3558(BracketAB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3592(BracketA)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3614(BracketB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3636(BarAB)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:3664(Simple)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1527(FixedLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1669(Base)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1711(MultipleLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1767(_Edge_integer)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2429(LogitLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2521(AutoLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2541(AutoMinorLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:2604(OldAutoLocator)\n",
       "        1    0.000    0.000    0.000    0.000 font_manager.py:284(FontEntry)\n",
       "        1    0.000    0.000    0.000    0.000 font_manager.py:832(JSONEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 font_manager.py:901(TempCache)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:231(TickHelper)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:305(IndexFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:327(NullFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:338(FixedFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:391(FormatStrFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:431(OldScalarFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1043(LogFormatterExponent)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1059(LogFormatterMathtext)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1124(LogFormatterSciNotation)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1144(LogitFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 contour.py:37(ClabelText)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1091(StarPolygonCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1098(AsteriskPolygonCollection)\n",
       "        1    0.000    0.000    0.000    0.000 collections.py:1658(PatchCollection)\n",
       "        3    0.000    0.000    0.000    0.000 _cm.py:96(get_color_function)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2253(BlendedAffine2D)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2563(BboxTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2611(BboxTransformTo)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2654(BboxTransformToMaxOnly)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2675(BboxTransformFrom)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2747(TransformedPath)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:2821(TransformedPatchPath)\n",
       "        1    0.000    0.000    0.000    0.000 colorbar.py:1485(ColorbarPatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyplot.py:1801(colormaps)\n",
       "        1    0.000    0.000    0.000    0.000 pyplot.py:92(_NotIPython)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:781(ListedColormap)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:997(LogNorm)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:1186(PowerNorm)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:1252(BoundaryNorm)\n",
       "        1    0.000    0.000    0.000    0.000 colors.py:1338(NoNorm)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4107(_NullToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4115(Optional)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4179(SkipTo)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4294(Forward)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4387(Combine)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4431(Group)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4452(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5832(_lazyclassproperty)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5867(Latin1)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5879(Cyrillic)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5891(Hiragana)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5897(Korean)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5900(CJK)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5904(Thai)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5907(Arabic)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2287(ImageTransformHandler)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:25(deferred_error)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:20(ModeDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(FFIError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:5(CDefError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:16(VerificationError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:20(VerificationMissing)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:72(BaseType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:88(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:178(UnknownIntegerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:192(UnknownFloatType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:204(BaseFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:224(RawFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:239(FunctionPtrType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:278(ConstPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:293(ArrayType)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:292(InceptionAux)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:317(BasicConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:147(_DenseBlock)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:165(DenseNet)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:14(LSUNClass)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:23(SequentialSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:40(RandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:79(SubsetRandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:126(BatchSampler)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:7(DistributedSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:8(Dataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:26(TensorDataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:90(Subset)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:39(ExceptionWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:86(ManagerWatchdog)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:40(DecompressionBombWarning)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:44(DecompressionBombError)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:479(_E)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:14(TMonitor)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:123(Semaphore)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:142(BoundedSemaphore)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:186(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:332(Event)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:26(tqdm_gui)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:57(Bottleneck)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:96(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:16(ResNeXtBottleneckC)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:58(ResNeXt)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:17(Fire)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:40(SqueezeNet)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:33(Inception3)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:130(InceptionA)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:162(InceptionB)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:185(InceptionC)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:224(InceptionD)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:250(InceptionE)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:55(BaseAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:59(SOCKSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:129(SOCKSHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:133(SOCKSHTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:141(SOCKSProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:110(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:123(GeneralProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:127(ProxyConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:131(SOCKS5AuthError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:135(SOCKS5Error)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:139(SOCKS4Error)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:267(_BaseSocket)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:40(TqdmKeyError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:44(TqdmWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:57(TqdmExperimentalWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:67(TqdmMonitorWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:95(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:165(CookieConflictError)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:174(RequestHooksMixin)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:198(Request)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:72(AuthBase)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:79(HTTPBasicAuth)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:100(HTTPProxyAuth)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:732(Cookie)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1222(Absent)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1841(LWPCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 scrypt.py:23(Scrypt)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:47(LargeZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:534(_ZipDecrypter)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:595(LZMACompressor)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:740(_Tellable)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:113(_SingleResponse)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:272(_RSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:31(PSS)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:49(OAEP)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:62(MGF1)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:13(_X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:119(IDEA)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:133(SEED)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:18(DHPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:80(DHParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:47(_DSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:68(_DSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:84(_DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:92(_ECDSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:108(_ECDSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:76(AEADDecryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:86(AEADEncryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:141(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:164(_AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:30(ModeWithInitializationVector)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:124(ECB)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:23(_Integers)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:186(_X509ExtensionParser)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:36(_DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2099(GetCipherByName)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:118(_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:249(WantReadError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:257(WantX509LookupError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:297(_VerifyHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:377(_NpnSelectHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:426(_ALPNSelectHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:477(_OCSPServerCallbackHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:549(_OCSPClientCallbackHelper)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ERR_clear_error}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_by_id}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_finish}\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:62(openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:154(_verify_openssl_version)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:46(cryptography_has_ssl3_method)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:135(cryptography_has_ssl_st)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:151(cryptography_has_locking_callbacks)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ASN1_STRING_set_default_mask_asc}\n",
       "        1    0.000    0.000    0.000    0.000 name.py:102(RelativeDistinguishedName)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:42(OCSPExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:104(SHA1)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:111(SHA224)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:118(SHA256)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:132(SHA512)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'gc' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:193(KeySerializationEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:207(NoEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:35(UnsupportedGeneralNameType)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:16(IDNAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:26(InvalidCodepoint)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1572(Primitive)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2706(Null)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2940(ObjectDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2948(InstanceOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2956(Real)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2964(Enumerated)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3032(UTF8String)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4484(SetOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4517(EmbeddedPdv)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4534(PrintableString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4552(VideotexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4560(IA5String)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4569(AbstractTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4615(UTCTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4671(GeneralizedTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4744(GraphicString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4763(GeneralString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4773(UniversalString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:23(TeletexIncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:29(TeletexIncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:40(TeletexStreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:30(LibraryNotFoundError)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:39(FFIEngineError)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:43(AlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:107(HmacAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:120(HmacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:127(DigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:141(DigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:149(DigestInfo)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:156(MaskGenAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:162(MaskGenAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:174(TrailerField)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:387(KdfAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:398(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:411(KeyExchangeAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:417(KeyExchangeAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:428(Rc2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:435(Rc5ParamVersion)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:441(Rc5Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:457(PSourceAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:463(PSourceAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1084(Pbes2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1091(Pbmac1Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1098(Pkcs5MacId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1104(Pkcs5MacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1119(AnyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:622(ValueMap)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:649(Castable)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:817(ExtendedKeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:852(OCSPNoCheck)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:857(PrecertPoison)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:66(OtherPrimeInfos)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:105(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:216(SpecifiedECDomainVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:227(FieldType)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:301(Curve)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:384(ECDomainParameters)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:396(ECPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:407(ECPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:420(DSAParams)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:454(PrivateKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:886(EncryptedPrivateKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:899(ValidationParms)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:924(PublicKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:944(PublicKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:146(Codec)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:24(UnsupportedAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:30(AlreadyFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:34(AlreadyUpdated)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:38(NotYetFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:42(InvalidTag)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:46(InvalidSignature)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(InternalError)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:64(CMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:79(PBKDF2HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:253(DERSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:51(DuplicateExtension)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:57(ExtensionNotFound)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(AsymmetricVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:145(SECT571R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:157(SECT283R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:163(SECT233R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:175(SECT571K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:181(SECT409K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:187(SECT283K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:193(SECT233K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:199(SECT163K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:205(SECP521R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:211(SECP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:217(SECP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:229(SECP224R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:235(SECP192R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:241(BrainpoolP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:247(BrainpoolP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:253(BrainpoolP512R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:420(ECDH)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:16(CryptographyDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:73(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:390(CertificateSigningRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:115(_DeprecatedValue)\n",
       "        1    0.000    0.000    0.000    0.000 langhebrewmodel.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langturkishmodel.py:37(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:28(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:32(ConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:53(ConnectTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:80(InvalidURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:84(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:92(ChunkedEncodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:96(ContentDecodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:104(RetryError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:114(RequestsWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:119(FileModeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:124(RequestsDependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:204(_X509NameInvalidator)\n",
       "        1    0.000    0.000    0.000    0.000 jisfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:212(EUCJPContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 sbcsgroupprober.py:43(SBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:113(EUCTWDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:132(EUCKRDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:170(Big5DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:192(SJISDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:217(EUCJPDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 big5freq.py:43(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:22(DeflateDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:62(GzipDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:93(MultiDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:8(InputState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:32(ProbingState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:41(MachineState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:65(CharacterCategory)\n",
       "        1    0.000    0.000    0.000    0.000 mbcsgroupprober.py:41(MBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:263(VerifiedHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:13(NoWayToWaitForSocketError)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:23(is_prod_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:8(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:13(HTTPWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:18(PoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:29(RequestError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:66(MaxRetryError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:85(HostChangedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(ReadTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:120(NewConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:125(EmptyPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:130(ClosedPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:135(LocationValueError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:171(SystemTimeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:176(InsecurePlatformWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:181(SNIMissingWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:186(DependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:194(ResponseNotChunked)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:199(BodyNotHttplibCompatible)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:207(IncompleteRead)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:223(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:228(ProxySchemeUnknown)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:237(HeaderParsingError)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:65(DummyConnection)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:5(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:28(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(CUDAModule)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:32(_OpNamespace)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:68(_Ops)\n",
       "        1    0.000    0.000    0.000    0.000 kl.py:77(_Match)\n",
       "        1    0.000    0.000    0.000    0.000 constraint_registry.py:79(ConstraintRegistry)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:217(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:49(Constraint)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:67(_Dependent)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:80(_DependentProperty)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:98(_Boolean)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:106(_IntegerInterval)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:123(_IntegerLessThan)\n",
       "        2    0.000    0.000    0.000    0.000 constraints.py:143(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:139(_IntegerGreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:167(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:163(_GreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:183(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:179(_GreaterThanEq)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:195(_LessThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:228(_HalfOpenInterval)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:245(_Simplex)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:263(_LowerCholesky)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:277(_PositiveDefinite)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:105(lazy_property)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:45(DupFd)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:40(SpawnContext)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:13(ExportTypes)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:234(LegacyTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:408(TracingCheckError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:549(TracerWarning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:649(CompilationUnit)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:817(OrderedModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:847(OrderedParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:868(OrderedBufferDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:926(ScriptMeta)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1164(WeakScriptModuleProxy)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:1279(_make_fail)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1349(TopLevelTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1354(_ConstModuleList)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1384(_ConstSequential)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1465(_disable_tracing)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:90(FrontendError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:102(NotSupportedError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:106(UnsupportedNodeError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:119(FrontendTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:152(SourceContext)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:14(Module)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(dist_backend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:149(group)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:153(_DistributedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 adadelta.py:6(Adadelta)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:9(_RequiredParameter)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:6(Adam)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:5(Adamax)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:161(MultiStepLR)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:39(SharedCache)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:9(Broadcast)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:50(Gather)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:78(Scatter)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:93(group)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:97(GroupMember)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(ConstantPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:75(ConstantPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:130(ConstantPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:166(_ReflectionPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:178(ReflectionPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:282(ReplicationPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:321(ReplicationPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:232(RNN)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:333(LSTM)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:441(GRU)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:537(RNNCellBase)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:585(RNNCell)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:658(LSTMCell)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:736(GRUCell)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:147(SpectralNormLoadStateDictPreHook)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:177(SpectralNormStateDictHook)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:143(UpsamplingNearest2d)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:188(UpsamplingBilinear2d)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:110(Unfold)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:9(_MaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:29(MaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:84(MaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:151(MaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:231(MaxUnpool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:371(MaxUnpool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:434(_AvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:766(LPPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:822(_AdaptiveMaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:936(_AdaptiveAvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:172(BatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:134(InstanceNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:210(InstanceNorm3d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:58(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:75(LayerNorm)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:61(Dropout2d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:193(FeatureAlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:190(Conv2d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:59(ReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:210(ReLU6)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:269(Tanh)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:425(GLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:459(Hardshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:663(PReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:728(Softsign)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:754(Tanhshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:868(Softmax2d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:897(LogSoftmax)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:12(_Loss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:21(_WeightedLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:213(NLLLoss2d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:223(PoissonNLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:289(KLDivLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:773(SoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:11(Container)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:75(Bilinear)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:196(BroadcastingListCls)\n",
       "        4    0.000    0.000    0.000    0.000 utils.py:5(_ntuple)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:160(flags_frozen)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:187(CuDNNHandle)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:197(CuDNNError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:204(TensorDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(FilterDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:277(DropoutDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:321(RNNDescriptor)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:444(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:6(VFModule)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:91(set_grad_enabled)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:4(detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:75(set_detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:12(range)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:225(emit_nvtx)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:360(Interval)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:407(FunctionEventAvg)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:431(StringTable)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:497(EnforceUnique)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:25(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:5(no_grad)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:47(enable_grad)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:242(InplaceFunction)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:5(VariableMeta)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:10(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:61(_HookMixin)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:72(BackwardCFunction)\n",
       "        1    0.000    0.000    0.000    0.000 thnn.py:4(THNNFunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:4(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(FunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(Function)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(Argument)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:195(cudaStatus)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:200(CudaError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:237(device_of)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:510(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:514(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:518(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:522(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:534(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:2363(_check)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:8(__PrinterOptions)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:68(_Formatter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:130(DeferredCudaCallError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:275(TarError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:284(CompressionError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:287(StreamError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:290(HeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:293(EmptyHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:296(TruncatedHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:302(InvalidHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:716(ExFileObject)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:291(_fromnxfunction_seq)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:304(_fromnxfunction_args)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:329(_fromnxfunction_allargs)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1489(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1473(mr_class)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:194(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:198(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:202(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:214(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:222(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:28(prepare_multiprocessing_environment)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6557(_frommethod)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:8048(_convert2ma)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:273(_fromnxfunction_single)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:95(MaskedArrayFutureWarning)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:166(MAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:208(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:829(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(_DomainTan)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:839(_DomainSafeDivide)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:860(_DomainGreater)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:882(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:876(_DomainGreaterEqual)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:892(_MaskedUFunc)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:902(_MaskedUnaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:976(_MaskedBinaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1124(_DomainedBinaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(_replace_dtype_fields_recursive)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1329(make_mask_descr)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:1362(getmask)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2384(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:58(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:62(PolyError)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:66(PolyDomainError)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:14(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_typeDict}\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:204(dummy_ctype)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:239(_missing_ctypes)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:686(AxisError)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:22(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:51(BagObj)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:464(ConverterError)\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:44(LinAlgError)\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:15(DummyArray)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:99(skipif)\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:47(PytestTester)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:351(RClass)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:451(CClass)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:481(ndenumerate)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:609(IndexExpression)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:317(_DebugResult)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:13(_WritelnDecorator)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:120(TextTestRunner)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:9(_InterruptHandler)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(KnownFailureException)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1212(_Dummy)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1816(IgnoreException)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1858(clear_and_catch_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:750(_typedict)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:83(ComplexWarning)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2817(_unspecified)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:305(finfo)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:25(SkipTest)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:33(_ShouldStop)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:128(_BaseTestCaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:137(_AssertRaisesBaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:221(_AssertWarnsContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:278(_CapturingHandler)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:953(FloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:960(LongFloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1109(IntegerFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1122(BoolFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1132(ComplexFloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1161(ComplexFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1168(LongComplexFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1176(_TimelikeFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1202(DatetimeFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1234(TimedeltaFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1239(SubArrayFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1286(StructureFormat)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:85(format_parser)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:271(ParseException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:292(ParseFatalException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:324(_ParseResultsWithOffset)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:676(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1477(_UnboundedCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2394(Empty)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2405(NoMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2420(Literal)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2549(CaselessKeyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2567(CloseMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2628(Word)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2787(Char)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2904(QuotedString)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3041(CharsNotIn)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3132(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3170(GoToColumn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3196(LineStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3226(LineEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3261(StringEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3279(WordStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3299(WordEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3419(setResultsName)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3450(_ErrorStop)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3510(Or)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3657(Each)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3858(FollowedBy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3887(PrecededBy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3960(NotAny)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4003(_MultipleMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4041(OneOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1784(TimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 deprecation.py:6(MatplotlibDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 rcsetup.py:46(ValidateInStrings)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:256(validate_qt4)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:262(validate_qt5)\n",
       "        1    0.000    0.000    0.000    0.000 rcsetup.py:283(validate_nseq_float)\n",
       "        1    0.000    0.000    0.000    0.000 rcsetup.py:309(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 rcsetup.py:657(ValidateInterval)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:292(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:525(checkdep_usetex)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1424(is_interactive)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:250(IgnoredKeywordWarning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:505(GetRealpathAndStat)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:609(maxdict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1274(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(RandomApply)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:341(RandomOrder)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:352(RandomChoice)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:360(RandomCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:429(RandomHorizontalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:455(RandomVerticalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:557(RandomSizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:567(FiveCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:606(TenCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:649(LinearTransformation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:695(ColorJitter)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:767(RandomRotation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:834(RandomAffine)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:954(Grayscale)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:984(RandomGrayscale)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:24(_Enhance)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:40(Color)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:74(Brightness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:36(BuiltinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:43(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:71(RankFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:136(ModeFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:153(GaussianBlur)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:167(BoxBlur)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:187(UnsharpMask)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:212(BLUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:250(EDGE_ENHANCE_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:268(FIND_EDGES)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:277(SHARPEN)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:295(SMOOTH_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:324(StructOrUnionOrEnum)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:475(StructType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:479(UnionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:483(EnumType)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:47(DatasetFolder)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:150(ImageFolder)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:7(CocoCaptions)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:174(CIFAR100)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:155(FashionMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:31(Compose)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:61(ToTensor)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:82(ToPILImage)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:120(Normalize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:149(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:182(Scale)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:221(Pad)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:271(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:289(RandomTransforms)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:45(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:39(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:196(get_start_method)\n",
       "        1    0.000    0.000    0.000    0.000 pathlib.py:777(name)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:136(_get_args)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:595(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'pack' of 'Struct' objects}\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:2589(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:526(get)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:823(setLevel)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1366(_internal_poll)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:98(checkgroup)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:101(checklookbehindgroup)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:794(fsencode)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:213(setstate)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:372(_VarintEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:387(_SignedVarintEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:470(_ModifiedEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:28(BaseOldDict)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:214(Uint64ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:166(StopTokenizing)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:337(NFAState)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:477(suspend_hooks)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:38(Error)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:72(Node_py_OP)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:55(TypeTransformationError)\n",
       "        2    0.000    0.000    0.000    0.000 api_implementation.py:136(Type)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:31(UndefinedComparison)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:37(UndefinedEnvironmentName)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4222(_ForwardNoRecurse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:183(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:195(_Constants)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1455(_UnboundedCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2545(CloseMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3384(_ErrorStop)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:36(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1549(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3165(PkgResourcesDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:587(InvalidFileException)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:9(CData)\n",
       "        4    0.000    0.000    0.000    0.000 six.py:67(_add_doc)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:76(ConcatSquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:51(MaskedCouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 config.py:36(InlineBackendConfig)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:145(Log2Transform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:166(InvertedNaturalLogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:173(LogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 scale.py:182(InvertedLogTransform)\n",
       "        1    0.000    0.000    0.000    0.000 streamplot.py:400(InvalidIndexError)\n",
       "        1    0.000    0.000    0.000    0.000 triinterpolate.py:1080(_DOF_estimator_user)\n",
       "        1    0.000    0.000    0.000    0.000 csv.py:65(excel_tab)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:2969(FormatFormatStr)\n",
       "        1    0.000    0.000    0.000    0.000 mlab.py:3021(FormatPercent)\n",
       "        1    0.000    0.000    0.000    0.000 category.py:156(UnitData)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1487(DayLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1514(HourLocator)\n",
       "        1    0.000    0.000    0.000    0.000 dates.py:1534(MinuteLocator)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:128(ErrorbarContainer)\n",
       "        1    0.000    0.000    0.000    0.000 legend_handler.py:411(HandlerPathCollection)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:3156(StatusbarBase)\n",
       "        1    0.000    0.000    0.000    0.000 backend_tools.py:753(ConfigureSubplotsBase)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:1758(DraggableAnnotation)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1275(DrawEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:1303(ResizeEvent)\n",
       "        1    0.000    0.000    0.000    0.000 backend_bases.py:2432(NonGuiException)\n",
       "        1    0.000    0.000    0.000    0.000 offsetbox.py:273(PackerBase)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1885(Fil)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1889(Fill)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1897(NegFil)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1300(STIXSansFontConstants)\n",
       "        1    0.000    0.000    0.000    0.000 mathtext.py:1352(MathTextWarning)\n",
       "        1    0.000    0.000    0.000    0.000 patches.py:2700(SimpleEvent)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:1571(NullLocator)\n",
       "        1    0.000    0.000    0.000    0.000 ticker.py:371(FuncFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4375(_ForwardNoRecurse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4379(TokenConverter)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4517(Suppress)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5872(Greek)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5882(Chinese)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5888(Kanji)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5894(Katakana)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5910(Hebrew)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:5913(Devanagari)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2282(ImagePointHandler)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:97(BasePrimitiveType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:261(PointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:284(NamedPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:155(_Transition)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:48(_imaging_not_installed)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:8(TqdmSynchronisationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:159(Lock)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:184(RLock)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:137(SOCKSHTTPSConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:143(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:36(TqdmTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:62(TqdmDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:625(SimpleCookie)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1753(LoadError)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:150(CookieError)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:43(BadZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:618(LZMADecompressor)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:299(_RSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(PKCS1v15)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:239(Error)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:253(WantWriteError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:261(ZeroReturnError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:265(SysCallError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:336(_NpnAdvertiseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:673(Session)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_free}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.RAND_cleanup}\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:125(SHA384)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:139(MD5)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:198(BestAvailableEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 package_data.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:21(IDNABidiError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:31(InvalidCodepointContext)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2665(ParsableOctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3041(RelativeOid)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4525(NumericString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4543(TeletexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4754(VisibleString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4782(CharacterString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4792(BMPString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:35(TeletexStreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:365(Pbkdf2Salt)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:381(KdfAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:450(Pbes1Params)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:206(ECPoint)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:211(ECPointBitString)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:239(CharacteristicTwoBasis)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:446(Attributes)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:218(IncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:253(IncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:292(StreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:295(StreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:56(InvalidKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:151(SECT409R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:169(SECT163R2)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:223(SECP256K1)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:79(InterfaceNotImplemented)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:36(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:44(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:60(ReadTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:64(URLRequired)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:68(TooManyRedirects)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:72(MissingSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:76(InvalidSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:88(InvalidProxyURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:100(StreamConsumedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:54(UnsupportedExtension)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:151(GB2312DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:14(is_appengine_sandbox)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:45(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:55(ProtocolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:94(TimeoutStateError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:99(TimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:115(ConnectTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:140(LocationParseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:150(ResponseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:156(SecurityWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:161(SubjectAltNameWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:166(InsecureRequestWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:244(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:155(_Real)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:215(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:254(_LowerTriangular)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:291(_RealVector)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:158(Builder)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:217(CosineAnnealingLR)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:220(ReflectionPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:370(ReplicationPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:406(ZeroPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:222(_MaxUnpoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:297(MaxUnpool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:502(AvgPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:246(BatchNorm3d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:149(AlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:323(Conv3d)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:443(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:369(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:249(_nested_map)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:526(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:530(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:538(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:278(ExtractError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:281(ReadError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:299(EOFHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:305(SubsequentHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:206(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:218(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:32(SourceChangeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:174(MaskError)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:79(PolyBase)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:683(TooHardError)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:472(ConverterLockError)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:480(ConversionWarning)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:38(_UnexpectedSuccess)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:33(ModuleDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:45(VisibleDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:339(PackageLoaderDebug)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:196(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:297(ParseSyntaxException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:316(RecursiveGrammarException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1500(_FifoCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2386(Token)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3163(_PositionToken)\n",
       "        3    0.000    0.000    0.000    0.000 rcsetup.py:168(validate_string_or_None)\n",
       "        1    0.000    0.000    0.000    0.000 rcsetup.py:308(validate_nseq_int)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:491(checkdep_ps_distiller)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:315(Bunch)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:58(Contrast)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:89(Sharpness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:28(Filter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:32(MultibandFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:94(MedianFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:108(MinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:122(MaxFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:223(CONTOUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:232(DETAIL)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:241(EDGE_ENHANCE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:259(EMBOSS)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:286(SMOOTH)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'toordinal' of 'datetime.date' objects}\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:743(__enter__)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl_multiscale.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs8K_sratio_0_5_drop_0_5_rl_stdlearnscale_15_multiscale_run1 --resume ../experiments_published/cnf_conditional_disentangle_cifar10_bs8K_sratio_0_5_drop_0_5_rl_stdlearnscale_15_multiscale_run1/epoch_120_checkpt.pth --seed 1 --conditional True --controlled_tol True --train_mode semisup --lr 0.001 --warmup_iters 1000 --atol 1e-4  --rtol 1e-4 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5 --scale_fac 1.0 --gate cnn2 --scale_std 15.0 --max_grad_norm 20.0\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
