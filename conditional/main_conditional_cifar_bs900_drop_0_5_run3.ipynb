{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_drop_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        z = model.module.dropout(z)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_cifar10_bs900_drop_0_5_run3/current_checkpt.pth', rtol=1e-05, save='../experiments_published/cnf_conditional_cifar10_bs900_drop_0_5_run3', seed=3, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=6144, bias=True)\n",
      "  (project_class): LinearZeros(in_features=3072, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1469494\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 20080 | Time 24.2084(25.1866) | Bit/dim 3.4558(3.4891) | Xent 0.0007(0.0047) | Loss 3.4562(3.4915) | Error 0.0000(0.0014) Steps 964(962.40) | Grad Norm 0.7426(1.0603) | Total Time 14.00(14.00)\n",
      "Iter 20090 | Time 23.6535(25.0430) | Bit/dim 3.4779(3.4898) | Xent 0.0032(0.0053) | Loss 3.4794(3.4925) | Error 0.0011(0.0015) Steps 958(962.21) | Grad Norm 0.9861(1.0921) | Total Time 14.00(14.00)\n",
      "Iter 20100 | Time 25.4577(24.9236) | Bit/dim 3.5118(3.4904) | Xent 0.0035(0.0055) | Loss 3.5135(3.4931) | Error 0.0011(0.0015) Steps 964(962.81) | Grad Norm 0.6740(1.0372) | Total Time 14.00(14.00)\n",
      "Iter 20110 | Time 24.4848(24.7262) | Bit/dim 3.4895(3.4895) | Xent 0.0042(0.0063) | Loss 3.4916(3.4926) | Error 0.0011(0.0017) Steps 958(961.61) | Grad Norm 1.0767(1.0859) | Total Time 14.00(14.00)\n",
      "Iter 20120 | Time 24.6055(24.6660) | Bit/dim 3.5239(3.4907) | Xent 0.0015(0.0066) | Loss 3.5247(3.4940) | Error 0.0000(0.0019) Steps 970(960.00) | Grad Norm 0.5489(1.1515) | Total Time 14.00(14.00)\n",
      "Iter 20130 | Time 25.2637(24.6048) | Bit/dim 3.5063(3.4893) | Xent 0.0023(0.0064) | Loss 3.5074(3.4925) | Error 0.0011(0.0019) Steps 964(960.04) | Grad Norm 0.7659(1.1699) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 121.0495, Epoch Time 1510.1930(1467.8604), Bit/dim 3.5200(best: inf), Xent 2.7371, Loss 4.8886, Error 0.3434(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20140 | Time 24.9960(24.6404) | Bit/dim 3.4726(3.4884) | Xent 0.0020(0.0054) | Loss 3.4736(3.4911) | Error 0.0011(0.0016) Steps 982(960.50) | Grad Norm 0.5629(1.0798) | Total Time 14.00(14.00)\n",
      "Iter 20150 | Time 24.0531(24.6107) | Bit/dim 3.4891(3.4884) | Xent 0.0014(0.0046) | Loss 3.4898(3.4907) | Error 0.0000(0.0013) Steps 964(962.15) | Grad Norm 0.3384(0.9608) | Total Time 14.00(14.00)\n",
      "Iter 20160 | Time 24.6504(24.6536) | Bit/dim 3.5026(3.4891) | Xent 0.0011(0.0043) | Loss 3.5031(3.4912) | Error 0.0000(0.0011) Steps 970(962.36) | Grad Norm 0.3272(0.8498) | Total Time 14.00(14.00)\n",
      "Iter 20170 | Time 24.6916(24.6950) | Bit/dim 3.4798(3.4883) | Xent 0.0036(0.0044) | Loss 3.4816(3.4905) | Error 0.0011(0.0012) Steps 964(962.59) | Grad Norm 1.8644(0.8706) | Total Time 14.00(14.00)\n",
      "Iter 20180 | Time 25.4393(24.6751) | Bit/dim 3.4652(3.4873) | Xent 0.0087(0.0048) | Loss 3.4695(3.4896) | Error 0.0022(0.0013) Steps 958(961.62) | Grad Norm 1.1496(0.8755) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 114.0640, Epoch Time 1488.8404(1468.4898), Bit/dim 3.5187(best: 3.5200), Xent 2.6990, Loss 4.8682, Error 0.3405(best: 0.3434)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20190 | Time 24.2820(24.6052) | Bit/dim 3.4705(3.4871) | Xent 0.0127(0.0043) | Loss 3.4768(3.4893) | Error 0.0022(0.0012) Steps 952(961.52) | Grad Norm 1.9917(0.8728) | Total Time 14.00(14.00)\n",
      "Iter 20200 | Time 24.2952(24.5867) | Bit/dim 3.4797(3.4906) | Xent 0.0026(0.0038) | Loss 3.4809(3.4925) | Error 0.0011(0.0010) Steps 964(961.09) | Grad Norm 0.7602(0.8689) | Total Time 14.00(14.00)\n",
      "Iter 20210 | Time 24.4436(24.5764) | Bit/dim 3.4668(3.4889) | Xent 0.0052(0.0039) | Loss 3.4694(3.4909) | Error 0.0011(0.0011) Steps 976(961.79) | Grad Norm 1.0453(0.8676) | Total Time 14.00(14.00)\n",
      "Iter 20220 | Time 24.9722(24.5391) | Bit/dim 3.4653(3.4877) | Xent 0.0015(0.0040) | Loss 3.4660(3.4897) | Error 0.0011(0.0013) Steps 964(962.12) | Grad Norm 0.8731(0.9428) | Total Time 14.00(14.00)\n",
      "Iter 20230 | Time 24.4591(24.5246) | Bit/dim 3.4678(3.4864) | Xent 0.0013(0.0045) | Loss 3.4684(3.4887) | Error 0.0000(0.0013) Steps 970(962.07) | Grad Norm 0.7096(1.0538) | Total Time 14.00(14.00)\n",
      "Iter 20240 | Time 24.7003(24.4300) | Bit/dim 3.5194(3.4873) | Xent 0.0032(0.0048) | Loss 3.5210(3.4897) | Error 0.0011(0.0013) Steps 940(960.00) | Grad Norm 0.9366(1.0401) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 115.0214, Epoch Time 1476.9543(1468.7437), Bit/dim 3.5191(best: 3.5187), Xent 2.7224, Loss 4.8803, Error 0.3452(best: 0.3405)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20250 | Time 23.9212(24.3743) | Bit/dim 3.4940(3.4868) | Xent 0.0066(0.0048) | Loss 3.4973(3.4892) | Error 0.0011(0.0013) Steps 952(959.30) | Grad Norm 1.0920(1.0384) | Total Time 14.00(14.00)\n",
      "Iter 20260 | Time 24.2060(24.3397) | Bit/dim 3.4933(3.4881) | Xent 0.0022(0.0045) | Loss 3.4943(3.4903) | Error 0.0011(0.0013) Steps 958(958.79) | Grad Norm 0.5753(1.0208) | Total Time 14.00(14.00)\n",
      "Iter 20270 | Time 23.6271(24.3147) | Bit/dim 3.4882(3.4862) | Xent 0.0014(0.0050) | Loss 3.4889(3.4887) | Error 0.0000(0.0013) Steps 958(959.91) | Grad Norm 0.6785(1.0384) | Total Time 14.00(14.00)\n",
      "Iter 20280 | Time 24.1373(24.2958) | Bit/dim 3.5127(3.4872) | Xent 0.0023(0.0053) | Loss 3.5139(3.4898) | Error 0.0000(0.0015) Steps 958(960.77) | Grad Norm 0.9288(1.1369) | Total Time 14.00(14.00)\n",
      "Iter 20290 | Time 24.1650(24.3264) | Bit/dim 3.4888(3.4886) | Xent 0.0016(0.0046) | Loss 3.4896(3.4909) | Error 0.0000(0.0012) Steps 964(959.99) | Grad Norm 0.7622(1.0703) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 114.2965, Epoch Time 1466.9880(1468.6911), Bit/dim 3.5187(best: 3.5187), Xent 2.7263, Loss 4.8819, Error 0.3456(best: 0.3405)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20300 | Time 24.6540(24.3254) | Bit/dim 3.5169(3.4903) | Xent 0.0007(0.0046) | Loss 3.5172(3.4926) | Error 0.0000(0.0013) Steps 952(959.24) | Grad Norm 0.6069(1.0716) | Total Time 14.00(14.00)\n",
      "Iter 20310 | Time 24.9614(24.3176) | Bit/dim 3.4687(3.4873) | Xent 0.0009(0.0042) | Loss 3.4692(3.4894) | Error 0.0000(0.0011) Steps 976(959.08) | Grad Norm 0.4667(0.9789) | Total Time 14.00(14.00)\n",
      "Iter 20320 | Time 24.2884(24.3534) | Bit/dim 3.4753(3.4894) | Xent 0.0030(0.0040) | Loss 3.4768(3.4915) | Error 0.0011(0.0010) Steps 958(960.04) | Grad Norm 0.8951(0.8859) | Total Time 14.00(14.00)\n",
      "Iter 20330 | Time 24.0933(24.3159) | Bit/dim 3.4539(3.4886) | Xent 0.0013(0.0037) | Loss 3.4545(3.4904) | Error 0.0000(0.0009) Steps 958(959.97) | Grad Norm 0.5687(0.8460) | Total Time 14.00(14.00)\n",
      "Iter 20340 | Time 24.4850(24.2787) | Bit/dim 3.4616(3.4861) | Xent 0.0004(0.0036) | Loss 3.4618(3.4879) | Error 0.0000(0.0009) Steps 964(960.56) | Grad Norm 0.6108(0.8297) | Total Time 14.00(14.00)\n",
      "Iter 20350 | Time 23.9108(24.2041) | Bit/dim 3.4831(3.4868) | Xent 0.0027(0.0038) | Loss 3.4845(3.4888) | Error 0.0022(0.0009) Steps 940(958.04) | Grad Norm 1.6711(0.8341) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 114.8160, Epoch Time 1467.2494(1468.6478), Bit/dim 3.5174(best: 3.5187), Xent 2.7100, Loss 4.8724, Error 0.3433(best: 0.3405)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20360 | Time 24.0590(24.2456) | Bit/dim 3.5114(3.4866) | Xent 0.0009(0.0037) | Loss 3.5119(3.4885) | Error 0.0000(0.0009) Steps 952(957.83) | Grad Norm 0.4383(0.8186) | Total Time 14.00(14.00)\n",
      "Iter 20370 | Time 24.7319(24.2643) | Bit/dim 3.4645(3.4865) | Xent 0.0072(0.0036) | Loss 3.4681(3.4883) | Error 0.0011(0.0009) Steps 940(958.69) | Grad Norm 1.4190(0.8171) | Total Time 14.00(14.00)\n",
      "Iter 20380 | Time 25.3854(24.3348) | Bit/dim 3.4832(3.4858) | Xent 0.0004(0.0040) | Loss 3.4834(3.4877) | Error 0.0000(0.0009) Steps 964(958.59) | Grad Norm 0.4465(0.8412) | Total Time 14.00(14.00)\n",
      "Iter 20390 | Time 24.5042(24.3577) | Bit/dim 3.5045(3.4878) | Xent 0.0054(0.0040) | Loss 3.5072(3.4898) | Error 0.0022(0.0010) Steps 940(957.66) | Grad Norm 1.1164(0.8666) | Total Time 14.00(14.00)\n",
      "Iter 20400 | Time 24.1129(24.3115) | Bit/dim 3.4580(3.4870) | Xent 0.0036(0.0039) | Loss 3.4598(3.4890) | Error 0.0011(0.0010) Steps 964(956.79) | Grad Norm 0.8118(0.8571) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 115.3989, Epoch Time 1473.4750(1468.7926), Bit/dim 3.5183(best: 3.5174), Xent 2.7291, Loss 4.8828, Error 0.3420(best: 0.3405)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20410 | Time 24.3666(24.3372) | Bit/dim 3.4836(3.4884) | Xent 0.0021(0.0041) | Loss 3.4847(3.4904) | Error 0.0000(0.0011) Steps 964(959.10) | Grad Norm 0.6055(0.9016) | Total Time 14.00(14.00)\n",
      "Iter 20420 | Time 24.2274(24.3017) | Bit/dim 3.4924(3.4881) | Xent 0.0018(0.0039) | Loss 3.4932(3.4901) | Error 0.0000(0.0010) Steps 964(959.09) | Grad Norm 0.6797(0.8882) | Total Time 14.00(14.00)\n",
      "Iter 20430 | Time 24.2900(24.2883) | Bit/dim 3.5075(3.4885) | Xent 0.0018(0.0038) | Loss 3.5084(3.4904) | Error 0.0011(0.0011) Steps 964(960.72) | Grad Norm 0.5947(0.8889) | Total Time 14.00(14.00)\n",
      "Iter 20440 | Time 24.3889(24.3673) | Bit/dim 3.4653(3.4860) | Xent 0.0034(0.0038) | Loss 3.4670(3.4879) | Error 0.0011(0.0010) Steps 964(961.50) | Grad Norm 0.9165(0.8646) | Total Time 14.00(14.00)\n",
      "Iter 20450 | Time 24.8108(24.3828) | Bit/dim 3.4640(3.4847) | Xent 0.0008(0.0039) | Loss 3.4644(3.4867) | Error 0.0000(0.0010) Steps 970(961.09) | Grad Norm 0.3267(0.7994) | Total Time 14.00(14.00)\n",
      "Iter 20460 | Time 25.3407(24.3159) | Bit/dim 3.4839(3.4870) | Xent 0.0018(0.0035) | Loss 3.4848(3.4887) | Error 0.0011(0.0008) Steps 964(959.65) | Grad Norm 0.9408(0.7825) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 115.6845, Epoch Time 1471.6877(1468.8795), Bit/dim 3.5173(best: 3.5174), Xent 2.7301, Loss 4.8823, Error 0.3433(best: 0.3405)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20470 | Time 24.4270(24.3411) | Bit/dim 3.4752(3.4826) | Xent 0.0012(0.0034) | Loss 3.4758(3.4843) | Error 0.0000(0.0008) Steps 976(961.04) | Grad Norm 0.5282(0.7750) | Total Time 14.00(14.00)\n",
      "Iter 20480 | Time 23.8627(24.3565) | Bit/dim 3.4944(3.4859) | Xent 0.0007(0.0041) | Loss 3.4947(3.4880) | Error 0.0000(0.0010) Steps 964(961.07) | Grad Norm 0.5941(0.8547) | Total Time 14.00(14.00)\n",
      "Iter 20490 | Time 24.3642(24.3460) | Bit/dim 3.5090(3.4860) | Xent 0.0026(0.0047) | Loss 3.5104(3.4883) | Error 0.0011(0.0011) Steps 964(962.27) | Grad Norm 1.0483(0.8990) | Total Time 14.00(14.00)\n",
      "Iter 20500 | Time 24.7784(24.3336) | Bit/dim 3.5070(3.4881) | Xent 0.0009(0.0042) | Loss 3.5074(3.4901) | Error 0.0000(0.0010) Steps 958(961.38) | Grad Norm 0.5537(0.9654) | Total Time 14.00(14.00)\n",
      "Iter 20510 | Time 24.1525(24.3324) | Bit/dim 3.4753(3.4871) | Xent 0.0051(0.0042) | Loss 3.4778(3.4892) | Error 0.0011(0.0009) Steps 952(962.97) | Grad Norm 0.4660(0.9283) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 114.5202, Epoch Time 1473.1768(1469.0084), Bit/dim 3.5174(best: 3.5173), Xent 2.7515, Loss 4.8932, Error 0.3450(best: 0.3405)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20520 | Time 24.1898(24.3540) | Bit/dim 3.4883(3.4894) | Xent 0.0016(0.0037) | Loss 3.4891(3.4912) | Error 0.0011(0.0010) Steps 958(962.92) | Grad Norm 0.8154(0.9136) | Total Time 14.00(14.00)\n",
      "Iter 20530 | Time 24.9086(24.3590) | Bit/dim 3.4670(3.4885) | Xent 0.0101(0.0036) | Loss 3.4720(3.4903) | Error 0.0033(0.0009) Steps 958(962.05) | Grad Norm 1.7004(0.8857) | Total Time 14.00(14.00)\n",
      "Iter 20540 | Time 23.8857(24.4383) | Bit/dim 3.5088(3.4890) | Xent 0.0101(0.0036) | Loss 3.5138(3.4908) | Error 0.0022(0.0009) Steps 970(962.24) | Grad Norm 1.2666(0.8674) | Total Time 14.00(14.00)\n",
      "Iter 20550 | Time 23.7048(24.4680) | Bit/dim 3.4725(3.4883) | Xent 0.0043(0.0039) | Loss 3.4747(3.4902) | Error 0.0011(0.0010) Steps 964(961.98) | Grad Norm 1.1580(0.9340) | Total Time 14.00(14.00)\n",
      "Iter 20560 | Time 24.5154(24.4364) | Bit/dim 3.4619(3.4865) | Xent 0.0104(0.0040) | Loss 3.4671(3.4885) | Error 0.0022(0.0011) Steps 970(961.20) | Grad Norm 2.0657(0.9691) | Total Time 14.00(14.00)\n",
      "Iter 20570 | Time 24.7090(24.5312) | Bit/dim 3.4971(3.4864) | Xent 0.0015(0.0039) | Loss 3.4979(3.4883) | Error 0.0000(0.0011) Steps 970(961.96) | Grad Norm 0.4600(0.9723) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 115.5459, Epoch Time 1483.0403(1469.4294), Bit/dim 3.5172(best: 3.5173), Xent 2.7307, Loss 4.8826, Error 0.3423(best: 0.3405)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20580 | Time 24.2686(24.5320) | Bit/dim 3.4802(3.4860) | Xent 0.0023(0.0042) | Loss 3.4814(3.4881) | Error 0.0011(0.0012) Steps 964(962.22) | Grad Norm 2.1574(1.0138) | Total Time 14.00(14.00)\n",
      "Iter 20590 | Time 24.1629(24.4803) | Bit/dim 3.4756(3.4880) | Xent 0.0097(0.0041) | Loss 3.4805(3.4900) | Error 0.0033(0.0011) Steps 940(960.76) | Grad Norm 1.1801(1.0125) | Total Time 14.00(14.00)\n",
      "Iter 20600 | Time 24.0813(24.4139) | Bit/dim 3.4676(3.4870) | Xent 0.0020(0.0040) | Loss 3.4687(3.4890) | Error 0.0011(0.0011) Steps 970(961.94) | Grad Norm 0.8105(0.9763) | Total Time 14.00(14.00)\n",
      "Iter 20610 | Time 24.9212(24.4370) | Bit/dim 3.4575(3.4863) | Xent 0.0136(0.0044) | Loss 3.4643(3.4885) | Error 0.0022(0.0011) Steps 976(962.09) | Grad Norm 0.7445(0.9691) | Total Time 14.00(14.00)\n",
      "Iter 20620 | Time 24.8725(24.4508) | Bit/dim 3.4729(3.4873) | Xent 0.0104(0.0048) | Loss 3.4781(3.4897) | Error 0.0044(0.0013) Steps 964(961.50) | Grad Norm 2.0266(1.0497) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 115.8390, Epoch Time 1478.7488(1469.7089), Bit/dim 3.5195(best: 3.5172), Xent 2.7521, Loss 4.8956, Error 0.3492(best: 0.3405)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20630 | Time 24.7879(24.5187) | Bit/dim 3.4701(3.4862) | Xent 0.0024(0.0057) | Loss 3.4713(3.4890) | Error 0.0011(0.0016) Steps 964(963.20) | Grad Norm 1.4217(1.1391) | Total Time 14.00(14.00)\n",
      "Iter 20640 | Time 24.8507(24.5475) | Bit/dim 3.5082(3.4885) | Xent 0.0007(0.0053) | Loss 3.5085(3.4911) | Error 0.0000(0.0014) Steps 958(962.29) | Grad Norm 0.5397(1.0829) | Total Time 14.00(14.00)\n",
      "Iter 20650 | Time 25.2013(24.5510) | Bit/dim 3.4813(3.4871) | Xent 0.0025(0.0048) | Loss 3.4826(3.4895) | Error 0.0011(0.0013) Steps 976(962.20) | Grad Norm 0.8273(1.0048) | Total Time 14.00(14.00)\n",
      "Iter 20660 | Time 24.5992(24.5822) | Bit/dim 3.4980(3.4879) | Xent 0.0005(0.0050) | Loss 3.4982(3.4904) | Error 0.0000(0.0013) Steps 952(959.82) | Grad Norm 0.6264(1.0019) | Total Time 14.00(14.00)\n",
      "Iter 20670 | Time 24.2952(24.5866) | Bit/dim 3.4578(3.4852) | Xent 0.0015(0.0045) | Loss 3.4585(3.4874) | Error 0.0000(0.0011) Steps 940(959.97) | Grad Norm 0.5547(0.9791) | Total Time 14.00(14.00)\n",
      "Iter 20680 | Time 24.7948(24.5402) | Bit/dim 3.5121(3.4857) | Xent 0.0009(0.0040) | Loss 3.5125(3.4877) | Error 0.0000(0.0009) Steps 958(960.15) | Grad Norm 0.5003(0.9124) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 116.4392, Epoch Time 1486.3146(1470.2071), Bit/dim 3.5169(best: 3.5172), Xent 2.7289, Loss 4.8814, Error 0.3398(best: 0.3405)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20690 | Time 24.6742(24.5226) | Bit/dim 3.4733(3.4874) | Xent 0.0056(0.0037) | Loss 3.4761(3.4893) | Error 0.0011(0.0008) Steps 934(960.82) | Grad Norm 0.7130(0.8583) | Total Time 14.00(14.00)\n",
      "Iter 20700 | Time 25.4272(24.5449) | Bit/dim 3.5170(3.4889) | Xent 0.0054(0.0037) | Loss 3.5197(3.4908) | Error 0.0022(0.0009) Steps 952(960.38) | Grad Norm 1.6456(0.8687) | Total Time 14.00(14.00)\n",
      "Iter 20710 | Time 24.4862(24.6108) | Bit/dim 3.4976(3.4876) | Xent 0.0093(0.0034) | Loss 3.5022(3.4893) | Error 0.0033(0.0008) Steps 964(961.50) | Grad Norm 1.4842(0.8091) | Total Time 14.00(14.00)\n",
      "Iter 20720 | Time 24.2311(24.5805) | Bit/dim 3.4648(3.4845) | Xent 0.0021(0.0033) | Loss 3.4658(3.4861) | Error 0.0000(0.0008) Steps 976(961.97) | Grad Norm 0.7489(0.8028) | Total Time 14.00(14.00)\n",
      "Iter 20730 | Time 23.9634(24.5872) | Bit/dim 3.4656(3.4842) | Xent 0.0008(0.0033) | Loss 3.4660(3.4858) | Error 0.0000(0.0008) Steps 964(962.38) | Grad Norm 0.5518(0.8232) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 115.9016, Epoch Time 1486.0351(1470.6820), Bit/dim 3.5164(best: 3.5169), Xent 2.7686, Loss 4.9007, Error 0.3475(best: 0.3398)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20740 | Time 24.8662(24.5161) | Bit/dim 3.4997(3.4849) | Xent 0.0005(0.0029) | Loss 3.5000(3.4864) | Error 0.0000(0.0008) Steps 958(961.65) | Grad Norm 0.3908(0.7669) | Total Time 14.00(14.00)\n",
      "Iter 20750 | Time 24.3233(24.5201) | Bit/dim 3.4917(3.4855) | Xent 0.0017(0.0032) | Loss 3.4925(3.4871) | Error 0.0011(0.0009) Steps 952(961.36) | Grad Norm 0.6043(0.7710) | Total Time 14.00(14.00)\n",
      "Iter 20760 | Time 24.2456(24.5300) | Bit/dim 3.4799(3.4864) | Xent 0.0010(0.0028) | Loss 3.4804(3.4878) | Error 0.0000(0.0007) Steps 964(961.72) | Grad Norm 0.2620(0.6661) | Total Time 14.00(14.00)\n",
      "Iter 20770 | Time 24.5671(24.5087) | Bit/dim 3.5161(3.4849) | Xent 0.0009(0.0028) | Loss 3.5165(3.4863) | Error 0.0000(0.0008) Steps 958(961.95) | Grad Norm 0.5590(0.6879) | Total Time 14.00(14.00)\n",
      "Iter 20780 | Time 24.4758(24.5864) | Bit/dim 3.4949(3.4862) | Xent 0.0011(0.0025) | Loss 3.4955(3.4875) | Error 0.0000(0.0007) Steps 964(961.70) | Grad Norm 0.3408(0.6339) | Total Time 14.00(14.00)\n",
      "Iter 20790 | Time 25.0255(24.6032) | Bit/dim 3.4871(3.4825) | Xent 0.0007(0.0023) | Loss 3.4874(3.4837) | Error 0.0000(0.0006) Steps 970(960.89) | Grad Norm 0.2945(0.5874) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 115.6688, Epoch Time 1484.9923(1471.1113), Bit/dim 3.5139(best: 3.5164), Xent 2.7785, Loss 4.9032, Error 0.3443(best: 0.3398)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20800 | Time 24.9109(24.5635) | Bit/dim 3.4894(3.4815) | Xent 0.0031(0.0026) | Loss 3.4909(3.4828) | Error 0.0011(0.0007) Steps 970(960.87) | Grad Norm 0.9276(0.6093) | Total Time 14.00(14.00)\n",
      "Iter 20810 | Time 24.1893(24.5033) | Bit/dim 3.5231(3.4834) | Xent 0.0078(0.0028) | Loss 3.5270(3.4848) | Error 0.0011(0.0007) Steps 946(958.98) | Grad Norm 1.0010(0.6767) | Total Time 14.00(14.00)\n",
      "Iter 20820 | Time 24.5636(24.5188) | Bit/dim 3.4845(3.4837) | Xent 0.0005(0.0031) | Loss 3.4847(3.4853) | Error 0.0000(0.0008) Steps 976(959.68) | Grad Norm 0.7822(0.7338) | Total Time 14.00(14.00)\n",
      "Iter 20830 | Time 24.0847(24.4897) | Bit/dim 3.4764(3.4860) | Xent 0.0013(0.0029) | Loss 3.4770(3.4875) | Error 0.0000(0.0008) Steps 958(959.53) | Grad Norm 0.4263(0.7746) | Total Time 14.00(14.00)\n",
      "Iter 20840 | Time 24.1738(24.5168) | Bit/dim 3.4871(3.4846) | Xent 0.0042(0.0028) | Loss 3.4892(3.4860) | Error 0.0022(0.0008) Steps 964(961.27) | Grad Norm 1.3511(0.7847) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 115.6617, Epoch Time 1480.9243(1471.4057), Bit/dim 3.5158(best: 3.5139), Xent 2.7429, Loss 4.8872, Error 0.3411(best: 0.3398)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20850 | Time 24.6164(24.5182) | Bit/dim 3.4702(3.4862) | Xent 0.0076(0.0028) | Loss 3.4740(3.4876) | Error 0.0011(0.0007) Steps 952(961.44) | Grad Norm 1.2728(0.7581) | Total Time 14.00(14.00)\n",
      "Iter 20860 | Time 24.2331(24.4920) | Bit/dim 3.4872(3.4858) | Xent 0.0007(0.0031) | Loss 3.4876(3.4873) | Error 0.0000(0.0008) Steps 952(961.06) | Grad Norm 0.5760(0.8319) | Total Time 14.00(14.00)\n",
      "Iter 20870 | Time 25.0516(24.5498) | Bit/dim 3.4972(3.4851) | Xent 0.0030(0.0029) | Loss 3.4987(3.4865) | Error 0.0011(0.0007) Steps 952(960.57) | Grad Norm 1.1220(0.8001) | Total Time 14.00(14.00)\n",
      "Iter 20880 | Time 24.2476(24.5391) | Bit/dim 3.4900(3.4845) | Xent 0.0037(0.0030) | Loss 3.4919(3.4860) | Error 0.0011(0.0008) Steps 952(960.97) | Grad Norm 1.1453(0.7905) | Total Time 14.00(14.00)\n",
      "Iter 20890 | Time 24.9102(24.4685) | Bit/dim 3.4707(3.4843) | Xent 0.0049(0.0029) | Loss 3.4732(3.4857) | Error 0.0011(0.0007) Steps 970(961.01) | Grad Norm 0.6670(0.7610) | Total Time 14.00(14.00)\n",
      "Iter 20900 | Time 24.2743(24.4891) | Bit/dim 3.4811(3.4856) | Xent 0.0094(0.0038) | Loss 3.4858(3.4875) | Error 0.0033(0.0010) Steps 970(960.65) | Grad Norm 0.9912(0.8918) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 114.1813, Epoch Time 1478.3422(1471.6138), Bit/dim 3.5174(best: 3.5139), Xent 2.7788, Loss 4.9068, Error 0.3441(best: 0.3398)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20910 | Time 24.9691(24.4089) | Bit/dim 3.5031(3.4849) | Xent 0.0055(0.0039) | Loss 3.5059(3.4868) | Error 0.0011(0.0011) Steps 964(961.03) | Grad Norm 1.2792(1.1178) | Total Time 14.00(14.00)\n",
      "Iter 20920 | Time 24.2562(24.3985) | Bit/dim 3.4784(3.4875) | Xent 0.0014(0.0041) | Loss 3.4791(3.4895) | Error 0.0000(0.0011) Steps 958(960.79) | Grad Norm 0.9859(1.2125) | Total Time 14.00(14.00)\n",
      "Iter 20930 | Time 24.2331(24.4222) | Bit/dim 3.4573(3.4870) | Xent 0.0015(0.0045) | Loss 3.4580(3.4892) | Error 0.0000(0.0012) Steps 964(960.48) | Grad Norm 0.7694(1.2227) | Total Time 14.00(14.00)\n",
      "Iter 20940 | Time 24.2352(24.4378) | Bit/dim 3.4814(3.4891) | Xent 0.0041(0.0041) | Loss 3.4834(3.4912) | Error 0.0022(0.0012) Steps 970(960.88) | Grad Norm 0.8936(1.1751) | Total Time 14.00(14.00)\n",
      "Iter 20950 | Time 23.7178(24.3596) | Bit/dim 3.4637(3.4893) | Xent 0.0021(0.0043) | Loss 3.4648(3.4915) | Error 0.0011(0.0013) Steps 952(961.51) | Grad Norm 0.6546(1.1108) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 114.7005, Epoch Time 1470.7611(1471.5882), Bit/dim 3.5178(best: 3.5139), Xent 2.7804, Loss 4.9080, Error 0.3415(best: 0.3398)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20960 | Time 25.4128(24.3451) | Bit/dim 3.4715(3.4887) | Xent 0.0083(0.0049) | Loss 3.4756(3.4911) | Error 0.0044(0.0015) Steps 934(960.44) | Grad Norm 1.5132(1.0813) | Total Time 14.00(14.00)\n",
      "Iter 20970 | Time 24.1519(24.4462) | Bit/dim 3.4826(3.4883) | Xent 0.0040(0.0048) | Loss 3.4846(3.4907) | Error 0.0011(0.0014) Steps 958(960.54) | Grad Norm 0.7707(1.0639) | Total Time 14.00(14.00)\n",
      "Iter 20980 | Time 23.8427(24.4293) | Bit/dim 3.4859(3.4851) | Xent 0.0018(0.0048) | Loss 3.4868(3.4875) | Error 0.0000(0.0013) Steps 970(962.67) | Grad Norm 0.7390(1.0206) | Total Time 14.00(14.00)\n",
      "Iter 20990 | Time 24.4584(24.4682) | Bit/dim 3.5139(3.4875) | Xent 0.0016(0.0045) | Loss 3.5147(3.4897) | Error 0.0000(0.0011) Steps 958(962.82) | Grad Norm 0.5739(0.9605) | Total Time 14.00(14.00)\n",
      "Iter 21000 | Time 24.4946(24.4520) | Bit/dim 3.4805(3.4907) | Xent 0.0005(0.0038) | Loss 3.4808(3.4926) | Error 0.0000(0.0010) Steps 952(962.21) | Grad Norm 0.3094(0.9012) | Total Time 14.00(14.00)\n",
      "Iter 21010 | Time 24.8782(24.4482) | Bit/dim 3.4878(3.4885) | Xent 0.0017(0.0035) | Loss 3.4887(3.4903) | Error 0.0000(0.0009) Steps 958(962.41) | Grad Norm 0.6375(0.8598) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 114.8077, Epoch Time 1480.7604(1471.8633), Bit/dim 3.5154(best: 3.5139), Xent 2.7824, Loss 4.9066, Error 0.3451(best: 0.3398)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21020 | Time 24.9418(24.4418) | Bit/dim 3.4696(3.4864) | Xent 0.0054(0.0036) | Loss 3.4723(3.4882) | Error 0.0022(0.0009) Steps 970(961.53) | Grad Norm 0.9801(0.8596) | Total Time 14.00(14.00)\n",
      "Iter 21030 | Time 24.3901(24.4456) | Bit/dim 3.4464(3.4832) | Xent 0.0007(0.0032) | Loss 3.4467(3.4848) | Error 0.0000(0.0008) Steps 952(962.21) | Grad Norm 0.8228(0.8722) | Total Time 14.00(14.00)\n",
      "Iter 21040 | Time 24.1974(24.4278) | Bit/dim 3.4987(3.4858) | Xent 0.0033(0.0033) | Loss 3.5003(3.4874) | Error 0.0011(0.0009) Steps 946(962.90) | Grad Norm 0.7790(0.9565) | Total Time 14.00(14.00)\n",
      "Iter 21050 | Time 23.8463(24.4101) | Bit/dim 3.4960(3.4867) | Xent 0.0052(0.0031) | Loss 3.4986(3.4882) | Error 0.0011(0.0009) Steps 958(962.60) | Grad Norm 0.5655(0.9345) | Total Time 14.00(14.00)\n",
      "Iter 21060 | Time 25.2961(24.4517) | Bit/dim 3.4745(3.4850) | Xent 0.0013(0.0025) | Loss 3.4751(3.4863) | Error 0.0000(0.0006) Steps 964(964.39) | Grad Norm 0.7930(0.8151) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 115.6265, Epoch Time 1477.8181(1472.0420), Bit/dim 3.5150(best: 3.5139), Xent 2.7922, Loss 4.9111, Error 0.3457(best: 0.3398)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21070 | Time 24.5431(24.5057) | Bit/dim 3.4908(3.4881) | Xent 0.0099(0.0030) | Loss 3.4958(3.4896) | Error 0.0011(0.0007) Steps 964(964.59) | Grad Norm 0.5857(0.7993) | Total Time 14.00(14.00)\n",
      "Iter 21080 | Time 24.5397(24.5310) | Bit/dim 3.4787(3.4886) | Xent 0.0006(0.0032) | Loss 3.4790(3.4902) | Error 0.0000(0.0007) Steps 964(965.45) | Grad Norm 0.4025(0.7574) | Total Time 14.00(14.00)\n",
      "Iter 21090 | Time 24.1434(24.5064) | Bit/dim 3.4756(3.4864) | Xent 0.0096(0.0035) | Loss 3.4804(3.4882) | Error 0.0022(0.0009) Steps 970(965.54) | Grad Norm 1.5503(0.8087) | Total Time 14.00(14.00)\n",
      "Iter 21100 | Time 24.3665(24.5166) | Bit/dim 3.4584(3.4847) | Xent 0.0006(0.0031) | Loss 3.4587(3.4863) | Error 0.0000(0.0008) Steps 970(964.89) | Grad Norm 0.5011(0.7628) | Total Time 14.00(14.00)\n",
      "Iter 21110 | Time 24.0725(24.4896) | Bit/dim 3.4698(3.4835) | Xent 0.0007(0.0030) | Loss 3.4702(3.4851) | Error 0.0000(0.0008) Steps 964(964.80) | Grad Norm 0.3038(0.7306) | Total Time 14.00(14.00)\n",
      "Iter 21120 | Time 24.1039(24.4783) | Bit/dim 3.5251(3.4859) | Xent 0.0054(0.0032) | Loss 3.5278(3.4875) | Error 0.0011(0.0009) Steps 976(964.17) | Grad Norm 0.8719(0.7647) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 116.3414, Epoch Time 1483.5864(1472.3883), Bit/dim 3.5157(best: 3.5139), Xent 2.7690, Loss 4.9002, Error 0.3436(best: 0.3398)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21130 | Time 24.4115(24.4501) | Bit/dim 3.4798(3.4862) | Xent 0.0006(0.0027) | Loss 3.4801(3.4875) | Error 0.0000(0.0007) Steps 946(963.27) | Grad Norm 0.3203(0.7203) | Total Time 14.00(14.00)\n",
      "Iter 21140 | Time 24.7674(24.4872) | Bit/dim 3.4885(3.4854) | Xent 0.0042(0.0027) | Loss 3.4906(3.4867) | Error 0.0011(0.0007) Steps 958(962.63) | Grad Norm 1.0891(0.7917) | Total Time 14.00(14.00)\n",
      "Iter 21150 | Time 24.6233(24.4905) | Bit/dim 3.4698(3.4834) | Xent 0.0007(0.0036) | Loss 3.4701(3.4852) | Error 0.0000(0.0009) Steps 970(962.42) | Grad Norm 0.7788(0.9510) | Total Time 14.00(14.00)\n",
      "Iter 21160 | Time 24.6883(24.4621) | Bit/dim 3.4990(3.4835) | Xent 0.0006(0.0033) | Loss 3.4993(3.4852) | Error 0.0000(0.0009) Steps 976(962.77) | Grad Norm 0.7272(0.9745) | Total Time 14.00(14.00)\n",
      "Iter 21170 | Time 24.1236(24.4310) | Bit/dim 3.4896(3.4853) | Xent 0.0005(0.0033) | Loss 3.4898(3.4869) | Error 0.0000(0.0009) Steps 964(962.15) | Grad Norm 0.4100(0.9508) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 114.4530, Epoch Time 1474.7677(1472.4597), Bit/dim 3.5158(best: 3.5139), Xent 2.7654, Loss 4.8985, Error 0.3418(best: 0.3398)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21180 | Time 23.9085(24.3419) | Bit/dim 3.5046(3.4885) | Xent 0.0005(0.0038) | Loss 3.5049(3.4904) | Error 0.0000(0.0011) Steps 952(962.44) | Grad Norm 0.5274(0.9784) | Total Time 14.00(14.00)\n",
      "Iter 21190 | Time 23.8562(24.3317) | Bit/dim 3.4652(3.4844) | Xent 0.0022(0.0032) | Loss 3.4663(3.4860) | Error 0.0011(0.0009) Steps 952(962.87) | Grad Norm 0.5135(0.8748) | Total Time 14.00(14.00)\n",
      "Iter 21200 | Time 24.2054(24.3773) | Bit/dim 3.4983(3.4850) | Xent 0.0015(0.0030) | Loss 3.4990(3.4866) | Error 0.0000(0.0008) Steps 964(961.72) | Grad Norm 1.0130(0.8557) | Total Time 14.00(14.00)\n",
      "Iter 21210 | Time 23.9066(24.3768) | Bit/dim 3.4888(3.4847) | Xent 0.0006(0.0032) | Loss 3.4891(3.4863) | Error 0.0000(0.0008) Steps 958(962.02) | Grad Norm 0.6146(0.9350) | Total Time 14.00(14.00)\n",
      "Iter 21220 | Time 24.5093(24.4250) | Bit/dim 3.4869(3.4844) | Xent 0.0007(0.0032) | Loss 3.4872(3.4860) | Error 0.0000(0.0009) Steps 970(961.45) | Grad Norm 0.4104(0.9266) | Total Time 14.00(14.00)\n",
      "Iter 21230 | Time 24.3951(24.4272) | Bit/dim 3.5236(3.4872) | Xent 0.0004(0.0032) | Loss 3.5238(3.4888) | Error 0.0000(0.0009) Steps 964(961.34) | Grad Norm 0.6279(0.9474) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 115.2451, Epoch Time 1475.9899(1472.5656), Bit/dim 3.5181(best: 3.5139), Xent 2.8033, Loss 4.9197, Error 0.3456(best: 0.3398)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21240 | Time 24.8413(24.4533) | Bit/dim 3.5133(3.4871) | Xent 0.0013(0.0032) | Loss 3.5139(3.4887) | Error 0.0011(0.0010) Steps 964(962.53) | Grad Norm 0.8277(1.0243) | Total Time 14.00(14.00)\n",
      "Iter 21250 | Time 24.2914(24.3827) | Bit/dim 3.4769(3.4854) | Xent 0.0105(0.0036) | Loss 3.4821(3.4872) | Error 0.0033(0.0010) Steps 964(962.80) | Grad Norm 2.7385(1.1148) | Total Time 14.00(14.00)\n",
      "Iter 21260 | Time 24.2508(24.3850) | Bit/dim 3.4744(3.4839) | Xent 0.0008(0.0036) | Loss 3.4748(3.4857) | Error 0.0000(0.0011) Steps 946(961.74) | Grad Norm 0.6185(1.0627) | Total Time 14.00(14.00)\n",
      "Iter 21270 | Time 24.4071(24.3941) | Bit/dim 3.4621(3.4845) | Xent 0.0014(0.0034) | Loss 3.4628(3.4862) | Error 0.0000(0.0010) Steps 970(961.21) | Grad Norm 0.6358(1.0332) | Total Time 14.00(14.00)\n",
      "Iter 21280 | Time 24.0470(24.3319) | Bit/dim 3.4920(3.4882) | Xent 0.0010(0.0036) | Loss 3.4925(3.4900) | Error 0.0000(0.0011) Steps 958(961.92) | Grad Norm 0.8784(1.0183) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 115.7032, Epoch Time 1472.0915(1472.5514), Bit/dim 3.5175(best: 3.5139), Xent 2.7733, Loss 4.9042, Error 0.3382(best: 0.3398)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21290 | Time 23.8576(24.3434) | Bit/dim 3.4888(3.4870) | Xent 0.0007(0.0043) | Loss 3.4892(3.4891) | Error 0.0000(0.0012) Steps 976(961.63) | Grad Norm 0.4605(1.1189) | Total Time 14.00(14.00)\n",
      "Iter 21300 | Time 24.7047(24.3603) | Bit/dim 3.5109(3.4899) | Xent 0.0038(0.0042) | Loss 3.5128(3.4920) | Error 0.0011(0.0012) Steps 958(961.45) | Grad Norm 0.9592(1.1343) | Total Time 14.00(14.00)\n",
      "Iter 21310 | Time 24.7343(24.3977) | Bit/dim 3.4966(3.4914) | Xent 0.0054(0.0042) | Loss 3.4993(3.4935) | Error 0.0011(0.0012) Steps 964(960.96) | Grad Norm 1.4075(1.0984) | Total Time 14.00(14.00)\n",
      "Iter 21320 | Time 23.6543(24.2753) | Bit/dim 3.5052(3.4884) | Xent 0.0030(0.0041) | Loss 3.5067(3.4905) | Error 0.0011(0.0011) Steps 964(961.02) | Grad Norm 0.7057(1.0574) | Total Time 14.00(14.00)\n",
      "Iter 21330 | Time 24.3314(24.3174) | Bit/dim 3.4778(3.4851) | Xent 0.0015(0.0039) | Loss 3.4785(3.4871) | Error 0.0000(0.0010) Steps 964(960.30) | Grad Norm 0.4525(1.0208) | Total Time 14.00(14.00)\n",
      "Iter 21340 | Time 24.8045(24.3472) | Bit/dim 3.4933(3.4846) | Xent 0.0008(0.0039) | Loss 3.4937(3.4866) | Error 0.0000(0.0010) Steps 970(961.30) | Grad Norm 0.5472(0.9767) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 116.4065, Epoch Time 1474.0721(1472.5970), Bit/dim 3.5152(best: 3.5139), Xent 2.7862, Loss 4.9083, Error 0.3460(best: 0.3382)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21350 | Time 24.3812(24.3529) | Bit/dim 3.4781(3.4855) | Xent 0.0006(0.0037) | Loss 3.4784(3.4874) | Error 0.0000(0.0010) Steps 970(962.61) | Grad Norm 0.3845(0.8981) | Total Time 14.00(14.00)\n",
      "Iter 21360 | Time 24.4152(24.3931) | Bit/dim 3.4875(3.4849) | Xent 0.0020(0.0032) | Loss 3.4885(3.4865) | Error 0.0000(0.0008) Steps 964(962.89) | Grad Norm 0.3982(0.8070) | Total Time 14.00(14.00)\n",
      "Iter 21370 | Time 25.6973(24.4447) | Bit/dim 3.5047(3.4843) | Xent 0.0043(0.0031) | Loss 3.5069(3.4859) | Error 0.0011(0.0008) Steps 970(962.50) | Grad Norm 1.1889(0.8024) | Total Time 14.00(14.00)\n",
      "Iter 21380 | Time 24.4935(24.4856) | Bit/dim 3.4528(3.4819) | Xent 0.0014(0.0034) | Loss 3.4535(3.4836) | Error 0.0000(0.0008) Steps 964(962.98) | Grad Norm 0.7041(0.8702) | Total Time 14.00(14.00)\n",
      "Iter 21390 | Time 24.5748(24.4877) | Bit/dim 3.5099(3.4822) | Xent 0.0011(0.0033) | Loss 3.5105(3.4839) | Error 0.0000(0.0009) Steps 964(962.40) | Grad Norm 0.5792(0.8260) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 116.7875, Epoch Time 1481.9382(1472.8772), Bit/dim 3.5146(best: 3.5139), Xent 2.7805, Loss 4.9049, Error 0.3463(best: 0.3382)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21400 | Time 24.3593(24.4678) | Bit/dim 3.4875(3.4859) | Xent 0.0005(0.0031) | Loss 3.4878(3.4874) | Error 0.0000(0.0008) Steps 970(961.74) | Grad Norm 0.5363(0.8308) | Total Time 14.00(14.00)\n",
      "Iter 21410 | Time 24.7090(24.4766) | Bit/dim 3.4989(3.4869) | Xent 0.0072(0.0036) | Loss 3.5025(3.4887) | Error 0.0011(0.0009) Steps 970(962.65) | Grad Norm 0.9122(0.8463) | Total Time 14.00(14.00)\n",
      "Iter 21420 | Time 24.0631(24.4217) | Bit/dim 3.4717(3.4856) | Xent 0.0004(0.0033) | Loss 3.4719(3.4873) | Error 0.0000(0.0009) Steps 934(961.29) | Grad Norm 0.3136(0.8236) | Total Time 14.00(14.00)\n",
      "Iter 21430 | Time 24.1683(24.4312) | Bit/dim 3.5003(3.4863) | Xent 0.0005(0.0031) | Loss 3.5005(3.4878) | Error 0.0000(0.0008) Steps 970(961.00) | Grad Norm 0.3433(0.7815) | Total Time 14.00(14.00)\n",
      "Iter 21440 | Time 24.2752(24.5536) | Bit/dim 3.4613(3.4852) | Xent 0.0047(0.0029) | Loss 3.4637(3.4867) | Error 0.0011(0.0008) Steps 970(961.39) | Grad Norm 1.1162(0.8142) | Total Time 14.00(14.00)\n",
      "Iter 21450 | Time 24.3808(24.5872) | Bit/dim 3.4792(3.4831) | Xent 0.0080(0.0035) | Loss 3.4832(3.4849) | Error 0.0033(0.0009) Steps 964(963.12) | Grad Norm 1.0643(0.8932) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 115.2881, Epoch Time 1484.1218(1473.2146), Bit/dim 3.5149(best: 3.5139), Xent 2.7360, Loss 4.8829, Error 0.3415(best: 0.3382)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21460 | Time 24.8907(24.5803) | Bit/dim 3.5010(3.4834) | Xent 0.0007(0.0038) | Loss 3.5013(3.4853) | Error 0.0000(0.0010) Steps 952(960.10) | Grad Norm 0.7525(0.9864) | Total Time 14.00(14.00)\n",
      "Iter 21470 | Time 24.8007(24.5903) | Bit/dim 3.4973(3.4826) | Xent 0.0011(0.0041) | Loss 3.4979(3.4846) | Error 0.0000(0.0010) Steps 946(960.27) | Grad Norm 0.6381(0.9792) | Total Time 14.00(14.00)\n",
      "Iter 21480 | Time 24.7561(24.6116) | Bit/dim 3.4887(3.4863) | Xent 0.0017(0.0038) | Loss 3.4895(3.4881) | Error 0.0011(0.0009) Steps 958(960.49) | Grad Norm 0.8727(0.9613) | Total Time 14.00(14.00)\n",
      "Iter 21490 | Time 24.7288(24.6372) | Bit/dim 3.4681(3.4846) | Xent 0.0034(0.0036) | Loss 3.4699(3.4864) | Error 0.0011(0.0010) Steps 970(960.32) | Grad Norm 2.3562(0.9751) | Total Time 14.00(14.00)\n",
      "Iter 21500 | Time 24.8529(24.6360) | Bit/dim 3.4754(3.4847) | Xent 0.0009(0.0037) | Loss 3.4758(3.4866) | Error 0.0000(0.0009) Steps 958(962.22) | Grad Norm 0.4780(0.9228) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 115.9303, Epoch Time 1488.7388(1473.6803), Bit/dim 3.5156(best: 3.5139), Xent 2.7854, Loss 4.9083, Error 0.3432(best: 0.3382)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21510 | Time 24.5125(24.6239) | Bit/dim 3.5094(3.4866) | Xent 0.0056(0.0034) | Loss 3.5122(3.4883) | Error 0.0011(0.0008) Steps 958(962.44) | Grad Norm 0.6658(0.8364) | Total Time 14.00(14.00)\n",
      "Iter 21520 | Time 24.5785(24.6757) | Bit/dim 3.5230(3.4863) | Xent 0.0035(0.0032) | Loss 3.5248(3.4879) | Error 0.0011(0.0008) Steps 964(961.96) | Grad Norm 1.0336(0.7445) | Total Time 14.00(14.00)\n",
      "Iter 21530 | Time 25.1119(24.6074) | Bit/dim 3.4729(3.4849) | Xent 0.0028(0.0031) | Loss 3.4743(3.4864) | Error 0.0011(0.0008) Steps 964(961.73) | Grad Norm 0.6950(0.7266) | Total Time 14.00(14.00)\n",
      "Iter 21540 | Time 24.3985(24.5521) | Bit/dim 3.4566(3.4846) | Xent 0.0012(0.0030) | Loss 3.4573(3.4861) | Error 0.0000(0.0008) Steps 970(961.35) | Grad Norm 0.6674(0.7426) | Total Time 14.00(14.00)\n",
      "Iter 21550 | Time 24.5939(24.5609) | Bit/dim 3.4762(3.4826) | Xent 0.0092(0.0038) | Loss 3.4808(3.4845) | Error 0.0011(0.0009) Steps 952(961.44) | Grad Norm 0.9250(0.8294) | Total Time 14.00(14.00)\n",
      "Iter 21560 | Time 24.1280(24.5456) | Bit/dim 3.5399(3.4835) | Xent 0.0164(0.0043) | Loss 3.5481(3.4856) | Error 0.0056(0.0011) Steps 958(961.69) | Grad Norm 1.5132(0.8815) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 114.6303, Epoch Time 1482.7241(1473.9516), Bit/dim 3.5171(best: 3.5139), Xent 2.7717, Loss 4.9029, Error 0.3428(best: 0.3382)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21570 | Time 24.1881(24.5696) | Bit/dim 3.4652(3.4845) | Xent 0.0113(0.0045) | Loss 3.4709(3.4867) | Error 0.0011(0.0010) Steps 976(961.99) | Grad Norm 0.8012(0.8937) | Total Time 14.00(14.00)\n",
      "Iter 21580 | Time 24.7599(24.5999) | Bit/dim 3.4839(3.4865) | Xent 0.0007(0.0043) | Loss 3.4843(3.4886) | Error 0.0000(0.0011) Steps 976(963.48) | Grad Norm 0.5410(0.8810) | Total Time 14.00(14.00)\n",
      "Iter 21590 | Time 24.1527(24.6837) | Bit/dim 3.5123(3.4853) | Xent 0.0089(0.0043) | Loss 3.5167(3.4874) | Error 0.0022(0.0011) Steps 964(965.14) | Grad Norm 1.4683(1.0519) | Total Time 14.00(14.00)\n",
      "Iter 21600 | Time 24.5592(24.6072) | Bit/dim 3.4663(3.4815) | Xent 0.0090(0.0039) | Loss 3.4708(3.4834) | Error 0.0033(0.0011) Steps 976(966.10) | Grad Norm 1.7407(1.0159) | Total Time 14.00(14.00)\n",
      "Iter 21610 | Time 24.3203(24.5774) | Bit/dim 3.4876(3.4833) | Xent 0.0038(0.0038) | Loss 3.4895(3.4851) | Error 0.0022(0.0010) Steps 970(964.53) | Grad Norm 1.1600(1.0120) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 115.4780, Epoch Time 1487.8009(1474.3671), Bit/dim 3.5165(best: 3.5139), Xent 2.7760, Loss 4.9045, Error 0.3407(best: 0.3382)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21620 | Time 24.9952(24.6025) | Bit/dim 3.4628(3.4845) | Xent 0.0037(0.0038) | Loss 3.4646(3.4864) | Error 0.0011(0.0011) Steps 970(963.99) | Grad Norm 1.1049(1.0557) | Total Time 14.00(14.00)\n",
      "Iter 21630 | Time 24.4323(24.6383) | Bit/dim 3.4769(3.4838) | Xent 0.0018(0.0035) | Loss 3.4778(3.4855) | Error 0.0000(0.0010) Steps 964(964.27) | Grad Norm 0.8120(1.0299) | Total Time 14.00(14.00)\n",
      "Iter 21640 | Time 24.8163(24.6785) | Bit/dim 3.4893(3.4831) | Xent 0.0012(0.0031) | Loss 3.4899(3.4846) | Error 0.0000(0.0009) Steps 964(963.76) | Grad Norm 0.5403(0.9547) | Total Time 14.00(14.00)\n",
      "Iter 21650 | Time 25.3743(24.7453) | Bit/dim 3.4695(3.4835) | Xent 0.0003(0.0030) | Loss 3.4697(3.4850) | Error 0.0000(0.0009) Steps 970(964.35) | Grad Norm 0.4444(0.9341) | Total Time 14.00(14.00)\n",
      "Iter 21660 | Time 24.9879(24.7179) | Bit/dim 3.5010(3.4867) | Xent 0.0019(0.0033) | Loss 3.5019(3.4883) | Error 0.0000(0.0009) Steps 976(963.92) | Grad Norm 0.9199(0.9500) | Total Time 14.00(14.00)\n",
      "Iter 21670 | Time 24.9738(24.7172) | Bit/dim 3.4850(3.4873) | Xent 0.0038(0.0037) | Loss 3.4869(3.4892) | Error 0.0011(0.0011) Steps 964(963.70) | Grad Norm 0.9774(0.9878) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 116.0917, Epoch Time 1496.3226(1475.0258), Bit/dim 3.5151(best: 3.5139), Xent 2.7366, Loss 4.8834, Error 0.3361(best: 0.3382)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21680 | Time 24.7400(24.6630) | Bit/dim 3.5082(3.4869) | Xent 0.0016(0.0032) | Loss 3.5090(3.4885) | Error 0.0011(0.0009) Steps 952(963.91) | Grad Norm 0.5019(0.8670) | Total Time 14.00(14.00)\n",
      "Iter 21690 | Time 25.2717(24.6514) | Bit/dim 3.4891(3.4876) | Xent 0.0009(0.0030) | Loss 3.4895(3.4891) | Error 0.0000(0.0009) Steps 976(963.69) | Grad Norm 1.2250(0.8418) | Total Time 14.00(14.00)\n",
      "Iter 21700 | Time 25.4102(24.6902) | Bit/dim 3.4569(3.4856) | Xent 0.0024(0.0029) | Loss 3.4581(3.4871) | Error 0.0011(0.0008) Steps 982(964.30) | Grad Norm 0.7791(0.8419) | Total Time 14.00(14.00)\n",
      "Iter 21710 | Time 25.1256(24.6773) | Bit/dim 3.4917(3.4847) | Xent 0.0009(0.0031) | Loss 3.4921(3.4863) | Error 0.0000(0.0008) Steps 976(964.57) | Grad Norm 0.5843(0.9385) | Total Time 14.00(14.00)\n",
      "Iter 21720 | Time 24.7662(24.7029) | Bit/dim 3.4694(3.4841) | Xent 0.0024(0.0034) | Loss 3.4707(3.4858) | Error 0.0011(0.0010) Steps 958(963.82) | Grad Norm 1.1133(0.9973) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 115.1476, Epoch Time 1488.1762(1475.4203), Bit/dim 3.5159(best: 3.5139), Xent 2.8209, Loss 4.9264, Error 0.3509(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21730 | Time 23.9144(24.5861) | Bit/dim 3.4766(3.4837) | Xent 0.0082(0.0038) | Loss 3.4807(3.4856) | Error 0.0011(0.0011) Steps 952(964.49) | Grad Norm 0.8008(1.0647) | Total Time 14.00(14.00)\n",
      "Iter 21740 | Time 24.3414(24.5747) | Bit/dim 3.4937(3.4835) | Xent 0.0162(0.0045) | Loss 3.5018(3.4857) | Error 0.0044(0.0012) Steps 976(964.65) | Grad Norm 1.4870(1.1190) | Total Time 14.00(14.00)\n",
      "Iter 21750 | Time 24.7014(24.5921) | Bit/dim 3.4943(3.4852) | Xent 0.0033(0.0045) | Loss 3.4960(3.4874) | Error 0.0011(0.0013) Steps 970(964.69) | Grad Norm 1.4878(1.1085) | Total Time 14.00(14.00)\n",
      "Iter 21760 | Time 24.5309(24.5371) | Bit/dim 3.4774(3.4845) | Xent 0.0012(0.0045) | Loss 3.4780(3.4867) | Error 0.0000(0.0012) Steps 964(962.92) | Grad Norm 0.4878(1.0898) | Total Time 14.00(14.00)\n",
      "Iter 21770 | Time 24.3376(24.5623) | Bit/dim 3.5249(3.4848) | Xent 0.0005(0.0038) | Loss 3.5251(3.4867) | Error 0.0000(0.0010) Steps 958(961.63) | Grad Norm 0.4382(1.0056) | Total Time 14.00(14.00)\n",
      "Iter 21780 | Time 24.6463(24.4957) | Bit/dim 3.4892(3.4851) | Xent 0.0005(0.0033) | Loss 3.4894(3.4867) | Error 0.0000(0.0009) Steps 958(961.91) | Grad Norm 0.3263(0.9267) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 115.4539, Epoch Time 1479.9253(1475.5554), Bit/dim 3.5125(best: 3.5139), Xent 2.7856, Loss 4.9053, Error 0.3463(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21790 | Time 24.6353(24.5124) | Bit/dim 3.4816(3.4840) | Xent 0.0012(0.0032) | Loss 3.4822(3.4856) | Error 0.0000(0.0008) Steps 970(962.35) | Grad Norm 1.8825(0.9132) | Total Time 14.00(14.00)\n",
      "Iter 21800 | Time 24.5483(24.4972) | Bit/dim 3.4851(3.4838) | Xent 0.0141(0.0036) | Loss 3.4922(3.4855) | Error 0.0033(0.0009) Steps 964(962.81) | Grad Norm 1.5535(0.9343) | Total Time 14.00(14.00)\n",
      "Iter 21810 | Time 24.6886(24.5787) | Bit/dim 3.4853(3.4876) | Xent 0.0052(0.0038) | Loss 3.4879(3.4895) | Error 0.0022(0.0010) Steps 982(964.22) | Grad Norm 1.2334(0.9210) | Total Time 14.00(14.00)\n",
      "Iter 21820 | Time 24.9423(24.6791) | Bit/dim 3.4809(3.4844) | Xent 0.0035(0.0037) | Loss 3.4826(3.4862) | Error 0.0011(0.0009) Steps 970(965.78) | Grad Norm 0.8213(0.8810) | Total Time 14.00(14.00)\n",
      "Iter 21830 | Time 25.6356(24.7304) | Bit/dim 3.4965(3.4842) | Xent 0.0015(0.0040) | Loss 3.4973(3.4861) | Error 0.0011(0.0011) Steps 988(967.07) | Grad Norm 0.6589(0.9408) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 115.4019, Epoch Time 1495.0993(1476.1417), Bit/dim 3.5149(best: 3.5125), Xent 2.7628, Loss 4.8963, Error 0.3387(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21840 | Time 24.5168(24.7803) | Bit/dim 3.4811(3.4832) | Xent 0.0021(0.0042) | Loss 3.4822(3.4853) | Error 0.0011(0.0012) Steps 964(967.12) | Grad Norm 0.9004(1.0709) | Total Time 14.00(14.00)\n",
      "Iter 21850 | Time 25.2602(24.7706) | Bit/dim 3.5105(3.4876) | Xent 0.0116(0.0043) | Loss 3.5163(3.4897) | Error 0.0033(0.0012) Steps 952(964.75) | Grad Norm 1.3259(1.0712) | Total Time 14.00(14.00)\n",
      "Iter 21860 | Time 25.7452(24.8714) | Bit/dim 3.4581(3.4863) | Xent 0.0093(0.0045) | Loss 3.4628(3.4886) | Error 0.0011(0.0012) Steps 976(964.70) | Grad Norm 1.3190(1.1570) | Total Time 14.00(14.00)\n",
      "Iter 21870 | Time 25.5333(24.9360) | Bit/dim 3.4858(3.4879) | Xent 0.0175(0.0058) | Loss 3.4946(3.4908) | Error 0.0033(0.0014) Steps 964(964.98) | Grad Norm 2.0532(1.2158) | Total Time 14.00(14.00)\n",
      "Iter 21880 | Time 24.5833(24.9307) | Bit/dim 3.4853(3.4869) | Xent 0.0017(0.0054) | Loss 3.4861(3.4896) | Error 0.0000(0.0014) Steps 970(965.01) | Grad Norm 0.6259(1.2092) | Total Time 14.00(14.00)\n",
      "Iter 21890 | Time 24.2133(24.7924) | Bit/dim 3.4773(3.4845) | Xent 0.0010(0.0051) | Loss 3.4778(3.4870) | Error 0.0000(0.0013) Steps 976(965.48) | Grad Norm 0.6895(1.1464) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 115.2791, Epoch Time 1501.2420(1476.8947), Bit/dim 3.5153(best: 3.5125), Xent 2.6995, Loss 4.8650, Error 0.3399(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21900 | Time 25.5330(24.7268) | Bit/dim 3.4710(3.4857) | Xent 0.0032(0.0045) | Loss 3.4726(3.4880) | Error 0.0011(0.0011) Steps 958(964.27) | Grad Norm 1.1217(1.0733) | Total Time 14.00(14.00)\n",
      "Iter 21910 | Time 24.0699(24.6913) | Bit/dim 3.4746(3.4849) | Xent 0.0011(0.0039) | Loss 3.4751(3.4869) | Error 0.0000(0.0010) Steps 964(962.69) | Grad Norm 0.5196(0.9831) | Total Time 14.00(14.00)\n",
      "Iter 21920 | Time 25.0199(24.6531) | Bit/dim 3.4946(3.4872) | Xent 0.0007(0.0046) | Loss 3.4949(3.4896) | Error 0.0000(0.0012) Steps 958(962.89) | Grad Norm 0.9436(1.1486) | Total Time 14.00(14.00)\n",
      "Iter 21930 | Time 24.6147(24.5910) | Bit/dim 3.5434(3.4884) | Xent 0.0013(0.0044) | Loss 3.5441(3.4906) | Error 0.0000(0.0011) Steps 964(961.53) | Grad Norm 0.6523(1.0987) | Total Time 14.00(14.00)\n",
      "Iter 21940 | Time 24.1545(24.6623) | Bit/dim 3.4637(3.4860) | Xent 0.0011(0.0043) | Loss 3.4643(3.4881) | Error 0.0000(0.0011) Steps 982(961.77) | Grad Norm 0.4157(1.0482) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 115.9567, Epoch Time 1488.2066(1477.2341), Bit/dim 3.5141(best: 3.5125), Xent 2.7634, Loss 4.8958, Error 0.3444(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21950 | Time 24.4581(24.7004) | Bit/dim 3.4941(3.4830) | Xent 0.0006(0.0042) | Loss 3.4944(3.4850) | Error 0.0000(0.0010) Steps 952(962.64) | Grad Norm 0.3968(0.9988) | Total Time 14.00(14.00)\n",
      "Iter 21960 | Time 24.3097(24.6043) | Bit/dim 3.4899(3.4850) | Xent 0.0009(0.0040) | Loss 3.4904(3.4870) | Error 0.0000(0.0010) Steps 964(961.93) | Grad Norm 0.7064(0.9955) | Total Time 14.00(14.00)\n",
      "Iter 21970 | Time 25.1896(24.5758) | Bit/dim 3.5000(3.4857) | Xent 0.0015(0.0033) | Loss 3.5008(3.4874) | Error 0.0011(0.0008) Steps 970(961.40) | Grad Norm 0.6729(0.8825) | Total Time 14.00(14.00)\n",
      "Iter 21980 | Time 24.5447(24.5838) | Bit/dim 3.4706(3.4851) | Xent 0.0009(0.0032) | Loss 3.4710(3.4867) | Error 0.0000(0.0008) Steps 946(961.84) | Grad Norm 0.4558(0.7933) | Total Time 14.00(14.00)\n",
      "Iter 21990 | Time 24.8351(24.6225) | Bit/dim 3.4618(3.4831) | Xent 0.0062(0.0030) | Loss 3.4649(3.4846) | Error 0.0022(0.0008) Steps 964(961.92) | Grad Norm 1.8430(0.7688) | Total Time 14.00(14.00)\n",
      "Iter 22000 | Time 24.4738(24.6481) | Bit/dim 3.5224(3.4829) | Xent 0.0015(0.0037) | Loss 3.5231(3.4848) | Error 0.0000(0.0009) Steps 976(963.08) | Grad Norm 0.7539(0.8965) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 116.3055, Epoch Time 1486.8242(1477.5218), Bit/dim 3.5162(best: 3.5125), Xent 2.7687, Loss 4.9006, Error 0.3478(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22010 | Time 24.8566(24.6564) | Bit/dim 3.4688(3.4841) | Xent 0.0069(0.0040) | Loss 3.4722(3.4860) | Error 0.0022(0.0011) Steps 976(964.65) | Grad Norm 0.6676(0.9163) | Total Time 14.00(14.00)\n",
      "Iter 22020 | Time 24.3683(24.6395) | Bit/dim 3.5120(3.4846) | Xent 0.0014(0.0038) | Loss 3.5127(3.4865) | Error 0.0000(0.0011) Steps 982(965.45) | Grad Norm 0.6044(0.8944) | Total Time 14.00(14.00)\n",
      "Iter 22030 | Time 24.2863(24.6865) | Bit/dim 3.4975(3.4836) | Xent 0.0023(0.0041) | Loss 3.4987(3.4857) | Error 0.0011(0.0010) Steps 970(966.60) | Grad Norm 1.3656(0.9494) | Total Time 14.00(14.00)\n",
      "Iter 22040 | Time 25.3081(24.5695) | Bit/dim 3.4717(3.4852) | Xent 0.0109(0.0043) | Loss 3.4772(3.4873) | Error 0.0011(0.0011) Steps 982(966.48) | Grad Norm 0.9911(1.0269) | Total Time 14.00(14.00)\n",
      "Iter 22050 | Time 23.3147(24.5823) | Bit/dim 3.5249(3.4847) | Xent 0.0028(0.0048) | Loss 3.5263(3.4870) | Error 0.0011(0.0012) Steps 952(966.61) | Grad Norm 1.3193(1.1228) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 114.9516, Epoch Time 1484.5998(1477.7341), Bit/dim 3.5164(best: 3.5125), Xent 2.7744, Loss 4.9036, Error 0.3418(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22060 | Time 24.6976(24.5419) | Bit/dim 3.4542(3.4850) | Xent 0.0009(0.0045) | Loss 3.4546(3.4873) | Error 0.0000(0.0012) Steps 970(965.41) | Grad Norm 0.5008(1.1003) | Total Time 14.00(14.00)\n",
      "Iter 22070 | Time 24.6451(24.6313) | Bit/dim 3.4825(3.4862) | Xent 0.0056(0.0045) | Loss 3.4853(3.4884) | Error 0.0011(0.0011) Steps 958(966.06) | Grad Norm 1.0969(1.0597) | Total Time 14.00(14.00)\n",
      "Iter 22080 | Time 25.6928(24.6743) | Bit/dim 3.4697(3.4852) | Xent 0.0045(0.0043) | Loss 3.4719(3.4873) | Error 0.0022(0.0011) Steps 970(964.46) | Grad Norm 1.9607(1.0511) | Total Time 14.00(14.00)\n",
      "Iter 22090 | Time 25.4046(24.7111) | Bit/dim 3.4965(3.4853) | Xent 0.0034(0.0038) | Loss 3.4982(3.4872) | Error 0.0011(0.0010) Steps 958(963.12) | Grad Norm 0.9647(1.0246) | Total Time 14.00(14.00)\n",
      "Iter 22100 | Time 24.3267(24.7306) | Bit/dim 3.4987(3.4845) | Xent 0.0007(0.0035) | Loss 3.4991(3.4863) | Error 0.0000(0.0009) Steps 964(962.40) | Grad Norm 0.3801(0.9750) | Total Time 14.00(14.00)\n",
      "Iter 22110 | Time 24.3677(24.7126) | Bit/dim 3.4693(3.4840) | Xent 0.0258(0.0040) | Loss 3.4822(3.4860) | Error 0.0044(0.0011) Steps 958(961.52) | Grad Norm 1.7114(1.0462) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 115.7708, Epoch Time 1495.5853(1478.2697), Bit/dim 3.5149(best: 3.5125), Xent 2.8347, Loss 4.9323, Error 0.3489(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22120 | Time 24.3147(24.7014) | Bit/dim 3.4540(3.4806) | Xent 0.0049(0.0044) | Loss 3.4564(3.4827) | Error 0.0011(0.0012) Steps 952(960.61) | Grad Norm 0.9142(1.0764) | Total Time 14.00(14.00)\n",
      "Iter 22130 | Time 24.1620(24.6437) | Bit/dim 3.5144(3.4836) | Xent 0.0008(0.0042) | Loss 3.5148(3.4857) | Error 0.0000(0.0013) Steps 958(962.25) | Grad Norm 0.6502(1.0688) | Total Time 14.00(14.00)\n",
      "Iter 22140 | Time 25.5508(24.7151) | Bit/dim 3.5144(3.4837) | Xent 0.0015(0.0043) | Loss 3.5152(3.4858) | Error 0.0011(0.0013) Steps 946(961.72) | Grad Norm 0.7073(1.0495) | Total Time 14.00(14.00)\n",
      "Iter 22150 | Time 25.0634(24.6807) | Bit/dim 3.4802(3.4823) | Xent 0.0004(0.0040) | Loss 3.4804(3.4843) | Error 0.0000(0.0012) Steps 976(961.70) | Grad Norm 0.4080(0.9964) | Total Time 14.00(14.00)\n",
      "Iter 22160 | Time 25.0433(24.6818) | Bit/dim 3.4726(3.4861) | Xent 0.0076(0.0038) | Loss 3.4764(3.4880) | Error 0.0033(0.0012) Steps 946(962.71) | Grad Norm 1.2581(0.9323) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 116.5737, Epoch Time 1490.4270(1478.6344), Bit/dim 3.5132(best: 3.5125), Xent 2.7715, Loss 4.8990, Error 0.3463(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22170 | Time 25.1688(24.7041) | Bit/dim 3.4740(3.4840) | Xent 0.0004(0.0038) | Loss 3.4742(3.4859) | Error 0.0000(0.0012) Steps 976(964.35) | Grad Norm 0.7047(0.9217) | Total Time 14.00(14.00)\n",
      "Iter 22180 | Time 24.7289(24.6882) | Bit/dim 3.5089(3.4839) | Xent 0.0027(0.0036) | Loss 3.5103(3.4857) | Error 0.0011(0.0010) Steps 970(965.98) | Grad Norm 1.4832(0.9195) | Total Time 14.00(14.00)\n",
      "Iter 22190 | Time 24.2175(24.7043) | Bit/dim 3.4800(3.4836) | Xent 0.0008(0.0036) | Loss 3.4804(3.4854) | Error 0.0000(0.0009) Steps 970(966.77) | Grad Norm 0.3728(0.9220) | Total Time 14.00(14.00)\n",
      "Iter 22200 | Time 25.3804(24.7011) | Bit/dim 3.4867(3.4844) | Xent 0.0014(0.0036) | Loss 3.4874(3.4863) | Error 0.0000(0.0009) Steps 970(966.95) | Grad Norm 0.5514(0.9329) | Total Time 14.00(14.00)\n",
      "Iter 22210 | Time 24.6444(24.7241) | Bit/dim 3.4578(3.4830) | Xent 0.0130(0.0036) | Loss 3.4643(3.4848) | Error 0.0022(0.0009) Steps 952(966.46) | Grad Norm 2.6836(0.9193) | Total Time 14.00(14.00)\n",
      "Iter 22220 | Time 24.2385(24.7025) | Bit/dim 3.5131(3.4839) | Xent 0.0012(0.0045) | Loss 3.5137(3.4861) | Error 0.0000(0.0011) Steps 952(967.23) | Grad Norm 1.0421(0.9530) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 115.9053, Epoch Time 1493.8606(1479.0912), Bit/dim 3.5151(best: 3.5125), Xent 2.7702, Loss 4.9002, Error 0.3416(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22230 | Time 24.5409(24.7161) | Bit/dim 3.4948(3.4834) | Xent 0.0025(0.0041) | Loss 3.4961(3.4854) | Error 0.0011(0.0011) Steps 958(966.48) | Grad Norm 0.6822(0.9821) | Total Time 14.00(14.00)\n",
      "Iter 22240 | Time 24.7941(24.7131) | Bit/dim 3.5021(3.4844) | Xent 0.0015(0.0039) | Loss 3.5029(3.4863) | Error 0.0011(0.0011) Steps 952(966.38) | Grad Norm 0.8011(0.9905) | Total Time 14.00(14.00)\n",
      "Iter 22250 | Time 25.1671(24.6644) | Bit/dim 3.4664(3.4822) | Xent 0.0013(0.0033) | Loss 3.4670(3.4839) | Error 0.0000(0.0009) Steps 952(965.17) | Grad Norm 0.4216(0.9388) | Total Time 14.00(14.00)\n",
      "Iter 22260 | Time 24.2733(24.6294) | Bit/dim 3.4868(3.4812) | Xent 0.0005(0.0033) | Loss 3.4870(3.4828) | Error 0.0000(0.0008) Steps 964(964.64) | Grad Norm 0.3825(0.9060) | Total Time 14.00(14.00)\n",
      "Iter 22270 | Time 24.9883(24.6573) | Bit/dim 3.4812(3.4836) | Xent 0.0007(0.0030) | Loss 3.4816(3.4851) | Error 0.0000(0.0007) Steps 970(964.04) | Grad Norm 0.4011(0.8105) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 115.5755, Epoch Time 1489.5069(1479.4037), Bit/dim 3.5122(best: 3.5125), Xent 2.7738, Loss 4.8991, Error 0.3458(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22280 | Time 24.1717(24.6304) | Bit/dim 3.5027(3.4864) | Xent 0.0014(0.0031) | Loss 3.5034(3.4879) | Error 0.0011(0.0009) Steps 940(962.71) | Grad Norm 0.7491(0.8272) | Total Time 14.00(14.00)\n",
      "Iter 22290 | Time 24.1490(24.5881) | Bit/dim 3.4958(3.4848) | Xent 0.0033(0.0033) | Loss 3.4974(3.4865) | Error 0.0011(0.0009) Steps 970(963.05) | Grad Norm 0.6084(0.8223) | Total Time 14.00(14.00)\n",
      "Iter 22300 | Time 23.7055(24.5752) | Bit/dim 3.4677(3.4828) | Xent 0.0033(0.0031) | Loss 3.4693(3.4844) | Error 0.0011(0.0009) Steps 958(962.68) | Grad Norm 0.9499(0.8019) | Total Time 14.00(14.00)\n",
      "Iter 22310 | Time 24.2740(24.5600) | Bit/dim 3.4937(3.4844) | Xent 0.0007(0.0034) | Loss 3.4940(3.4862) | Error 0.0000(0.0009) Steps 964(962.16) | Grad Norm 0.5580(0.7960) | Total Time 14.00(14.00)\n",
      "Iter 22320 | Time 25.1223(24.5857) | Bit/dim 3.4976(3.4830) | Xent 0.0057(0.0034) | Loss 3.5005(3.4847) | Error 0.0033(0.0010) Steps 952(961.89) | Grad Norm 1.4858(0.8307) | Total Time 14.00(14.00)\n",
      "Iter 22330 | Time 24.3981(24.5587) | Bit/dim 3.5031(3.4832) | Xent 0.0015(0.0034) | Loss 3.5038(3.4849) | Error 0.0011(0.0009) Steps 964(962.54) | Grad Norm 0.4329(0.7579) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 115.2264, Epoch Time 1482.6086(1479.4998), Bit/dim 3.5124(best: 3.5122), Xent 2.7803, Loss 4.9026, Error 0.3430(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22340 | Time 24.9032(24.5896) | Bit/dim 3.4891(3.4848) | Xent 0.0048(0.0032) | Loss 3.4915(3.4864) | Error 0.0011(0.0008) Steps 952(961.55) | Grad Norm 1.2067(0.7444) | Total Time 14.00(14.00)\n",
      "Iter 22350 | Time 24.2655(24.6566) | Bit/dim 3.4954(3.4822) | Xent 0.0009(0.0030) | Loss 3.4958(3.4837) | Error 0.0000(0.0008) Steps 964(963.15) | Grad Norm 0.4472(0.7403) | Total Time 14.00(14.00)\n",
      "Iter 22360 | Time 23.8748(24.6552) | Bit/dim 3.5135(3.4827) | Xent 0.0007(0.0030) | Loss 3.5138(3.4842) | Error 0.0000(0.0009) Steps 976(964.05) | Grad Norm 0.4879(0.8108) | Total Time 14.00(14.00)\n",
      "Iter 22370 | Time 24.3898(24.6371) | Bit/dim 3.4801(3.4831) | Xent 0.0003(0.0026) | Loss 3.4802(3.4844) | Error 0.0000(0.0007) Steps 958(963.11) | Grad Norm 0.3369(0.7802) | Total Time 14.00(14.00)\n",
      "Iter 22380 | Time 24.9056(24.6061) | Bit/dim 3.4970(3.4836) | Xent 0.0003(0.0023) | Loss 3.4972(3.4848) | Error 0.0000(0.0006) Steps 976(962.47) | Grad Norm 0.3905(0.7200) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 115.1158, Epoch Time 1489.5245(1479.8005), Bit/dim 3.5125(best: 3.5122), Xent 2.8521, Loss 4.9386, Error 0.3532(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22390 | Time 24.2485(24.6237) | Bit/dim 3.4558(3.4821) | Xent 0.0038(0.0023) | Loss 3.4577(3.4833) | Error 0.0022(0.0007) Steps 982(964.55) | Grad Norm 0.9647(0.7439) | Total Time 14.00(14.00)\n",
      "Iter 22400 | Time 25.0394(24.6704) | Bit/dim 3.4461(3.4812) | Xent 0.0005(0.0025) | Loss 3.4463(3.4825) | Error 0.0000(0.0007) Steps 952(963.60) | Grad Norm 0.5293(0.7945) | Total Time 14.00(14.00)\n",
      "Iter 22410 | Time 24.8548(24.7021) | Bit/dim 3.4754(3.4796) | Xent 0.0012(0.0032) | Loss 3.4760(3.4812) | Error 0.0000(0.0009) Steps 976(965.11) | Grad Norm 0.7467(0.9359) | Total Time 14.00(14.00)\n",
      "Iter 22420 | Time 24.9507(24.6862) | Bit/dim 3.4998(3.4809) | Xent 0.0019(0.0033) | Loss 3.5007(3.4826) | Error 0.0000(0.0009) Steps 964(965.44) | Grad Norm 0.7200(0.9469) | Total Time 14.00(14.00)\n",
      "Iter 22430 | Time 24.6752(24.6170) | Bit/dim 3.4558(3.4830) | Xent 0.0004(0.0036) | Loss 3.4560(3.4848) | Error 0.0000(0.0010) Steps 970(965.68) | Grad Norm 0.5030(0.9199) | Total Time 14.00(14.00)\n",
      "Iter 22440 | Time 24.4035(24.5460) | Bit/dim 3.4677(3.4852) | Xent 0.0040(0.0035) | Loss 3.4697(3.4869) | Error 0.0011(0.0010) Steps 970(963.86) | Grad Norm 1.0266(0.9533) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 115.7263, Epoch Time 1487.4045(1480.0287), Bit/dim 3.5143(best: 3.5122), Xent 2.7991, Loss 4.9139, Error 0.3412(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22450 | Time 24.6248(24.5765) | Bit/dim 3.4739(3.4839) | Xent 0.0010(0.0034) | Loss 3.4744(3.4856) | Error 0.0000(0.0009) Steps 964(963.59) | Grad Norm 0.8381(0.9382) | Total Time 14.00(14.00)\n",
      "Iter 22460 | Time 25.0484(24.6694) | Bit/dim 3.5187(3.4807) | Xent 0.0025(0.0033) | Loss 3.5200(3.4823) | Error 0.0011(0.0010) Steps 952(963.56) | Grad Norm 0.7357(0.9232) | Total Time 14.00(14.00)\n",
      "Iter 22470 | Time 25.1697(24.7587) | Bit/dim 3.5320(3.4835) | Xent 0.0004(0.0035) | Loss 3.5321(3.4852) | Error 0.0000(0.0010) Steps 964(963.73) | Grad Norm 0.4579(0.9385) | Total Time 14.00(14.00)\n",
      "Iter 22480 | Time 24.8755(24.7552) | Bit/dim 3.4882(3.4838) | Xent 0.0013(0.0033) | Loss 3.4888(3.4855) | Error 0.0000(0.0008) Steps 958(964.44) | Grad Norm 0.4474(0.8495) | Total Time 14.00(14.00)\n",
      "Iter 22490 | Time 24.6536(24.7961) | Bit/dim 3.4763(3.4846) | Xent 0.0007(0.0030) | Loss 3.4766(3.4861) | Error 0.0000(0.0007) Steps 976(964.12) | Grad Norm 0.4664(0.7896) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 116.7754, Epoch Time 1499.7716(1480.6210), Bit/dim 3.5120(best: 3.5122), Xent 2.7832, Loss 4.9036, Error 0.3471(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22500 | Time 24.9625(24.7598) | Bit/dim 3.4720(3.4848) | Xent 0.0011(0.0026) | Loss 3.4725(3.4861) | Error 0.0000(0.0007) Steps 958(963.27) | Grad Norm 0.5722(0.7587) | Total Time 14.00(14.00)\n",
      "Iter 22510 | Time 24.8138(24.7348) | Bit/dim 3.4994(3.4837) | Xent 0.0009(0.0025) | Loss 3.4999(3.4850) | Error 0.0000(0.0007) Steps 964(961.82) | Grad Norm 0.5472(0.7631) | Total Time 14.00(14.00)\n",
      "Iter 22520 | Time 25.0559(24.7589) | Bit/dim 3.4564(3.4797) | Xent 0.0038(0.0034) | Loss 3.4583(3.4814) | Error 0.0011(0.0008) Steps 964(961.61) | Grad Norm 1.5461(0.8375) | Total Time 14.00(14.00)\n",
      "Iter 22530 | Time 24.4931(24.8041) | Bit/dim 3.4720(3.4808) | Xent 0.0004(0.0030) | Loss 3.4722(3.4823) | Error 0.0000(0.0007) Steps 958(961.79) | Grad Norm 0.4467(0.8057) | Total Time 14.00(14.00)\n",
      "Iter 22540 | Time 24.9564(24.7650) | Bit/dim 3.4744(3.4842) | Xent 0.0110(0.0044) | Loss 3.4799(3.4864) | Error 0.0044(0.0012) Steps 958(960.90) | Grad Norm 1.7582(0.9732) | Total Time 14.00(14.00)\n",
      "Iter 22550 | Time 23.7682(24.7108) | Bit/dim 3.4887(3.4850) | Xent 0.0107(0.0052) | Loss 3.4941(3.4876) | Error 0.0022(0.0014) Steps 946(959.85) | Grad Norm 2.4012(1.1255) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 116.3838, Epoch Time 1495.6101(1481.0706), Bit/dim 3.5150(best: 3.5120), Xent 2.8365, Loss 4.9333, Error 0.3506(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22560 | Time 25.1428(24.7630) | Bit/dim 3.5056(3.4853) | Xent 0.0121(0.0051) | Loss 3.5116(3.4879) | Error 0.0033(0.0014) Steps 940(960.37) | Grad Norm 1.7075(1.1339) | Total Time 14.00(14.00)\n",
      "Iter 22570 | Time 24.9293(24.8352) | Bit/dim 3.4954(3.4849) | Xent 0.0050(0.0050) | Loss 3.4979(3.4874) | Error 0.0011(0.0013) Steps 970(962.65) | Grad Norm 1.5871(1.1437) | Total Time 14.00(14.00)\n",
      "Iter 22580 | Time 24.9427(24.8968) | Bit/dim 3.5393(3.4872) | Xent 0.0014(0.0051) | Loss 3.5400(3.4898) | Error 0.0000(0.0014) Steps 958(963.03) | Grad Norm 0.6720(1.1651) | Total Time 14.00(14.00)\n",
      "Iter 22590 | Time 25.2830(24.8634) | Bit/dim 3.5005(3.4860) | Xent 0.0007(0.0049) | Loss 3.5009(3.4884) | Error 0.0000(0.0013) Steps 964(964.30) | Grad Norm 0.3560(1.0459) | Total Time 14.00(14.00)\n",
      "Iter 22600 | Time 24.9902(24.8725) | Bit/dim 3.4795(3.4850) | Xent 0.0012(0.0043) | Loss 3.4801(3.4871) | Error 0.0011(0.0012) Steps 976(965.32) | Grad Norm 0.8672(0.9770) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 116.8368, Epoch Time 1504.7233(1481.7802), Bit/dim 3.5110(best: 3.5120), Xent 2.8116, Loss 4.9169, Error 0.3456(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22610 | Time 24.3291(24.8365) | Bit/dim 3.4862(3.4853) | Xent 0.0016(0.0036) | Loss 3.4869(3.4871) | Error 0.0000(0.0010) Steps 964(964.65) | Grad Norm 0.5536(0.8683) | Total Time 14.00(14.00)\n",
      "Iter 22620 | Time 24.6773(24.7480) | Bit/dim 3.4757(3.4829) | Xent 0.0010(0.0031) | Loss 3.4762(3.4845) | Error 0.0000(0.0008) Steps 958(964.74) | Grad Norm 0.6044(0.8239) | Total Time 14.00(14.00)\n",
      "Iter 22630 | Time 24.6481(24.7667) | Bit/dim 3.5108(3.4845) | Xent 0.0042(0.0035) | Loss 3.5129(3.4863) | Error 0.0011(0.0010) Steps 958(965.28) | Grad Norm 1.3274(0.9348) | Total Time 14.00(14.00)\n",
      "Iter 22640 | Time 24.1811(24.8088) | Bit/dim 3.4802(3.4840) | Xent 0.0020(0.0035) | Loss 3.4812(3.4858) | Error 0.0011(0.0011) Steps 970(965.14) | Grad Norm 0.6352(0.9572) | Total Time 14.00(14.00)\n",
      "Iter 22650 | Time 24.7223(24.7635) | Bit/dim 3.4822(3.4823) | Xent 0.0072(0.0035) | Loss 3.4858(3.4840) | Error 0.0033(0.0011) Steps 976(965.18) | Grad Norm 1.5852(0.9555) | Total Time 14.00(14.00)\n",
      "Iter 22660 | Time 24.5655(24.8447) | Bit/dim 3.4797(3.4825) | Xent 0.0004(0.0033) | Loss 3.4799(3.4841) | Error 0.0000(0.0010) Steps 958(964.87) | Grad Norm 0.4673(0.9888) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 116.4875, Epoch Time 1498.5760(1482.2841), Bit/dim 3.5136(best: 3.5110), Xent 2.7682, Loss 4.8977, Error 0.3425(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22670 | Time 24.4433(24.7616) | Bit/dim 3.4938(3.4817) | Xent 0.0061(0.0034) | Loss 3.4968(3.4834) | Error 0.0011(0.0011) Steps 958(963.19) | Grad Norm 1.5615(1.0200) | Total Time 14.00(14.00)\n",
      "Iter 22680 | Time 25.0463(24.7437) | Bit/dim 3.5112(3.4825) | Xent 0.0004(0.0041) | Loss 3.5114(3.4846) | Error 0.0000(0.0011) Steps 982(964.21) | Grad Norm 0.6554(1.0504) | Total Time 14.00(14.00)\n",
      "Iter 22690 | Time 24.2274(24.7705) | Bit/dim 3.4695(3.4834) | Xent 0.0004(0.0038) | Loss 3.4697(3.4853) | Error 0.0000(0.0011) Steps 964(964.80) | Grad Norm 0.5337(1.0301) | Total Time 14.00(14.00)\n",
      "Iter 22700 | Time 25.2252(24.7297) | Bit/dim 3.4714(3.4846) | Xent 0.0023(0.0033) | Loss 3.4725(3.4863) | Error 0.0011(0.0010) Steps 976(964.47) | Grad Norm 1.2021(0.9699) | Total Time 14.00(14.00)\n",
      "Iter 22710 | Time 25.0758(24.6637) | Bit/dim 3.4845(3.4836) | Xent 0.0025(0.0036) | Loss 3.4858(3.4854) | Error 0.0011(0.0011) Steps 958(963.36) | Grad Norm 0.7208(0.9345) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 115.9391, Epoch Time 1489.4509(1482.4991), Bit/dim 3.5132(best: 3.5110), Xent 2.8012, Loss 4.9138, Error 0.3416(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22720 | Time 24.6104(24.6151) | Bit/dim 3.4671(3.4817) | Xent 0.0016(0.0038) | Loss 3.4679(3.4836) | Error 0.0000(0.0011) Steps 952(962.03) | Grad Norm 0.9399(1.0093) | Total Time 14.00(14.00)\n",
      "Iter 22730 | Time 24.5329(24.5518) | Bit/dim 3.4524(3.4812) | Xent 0.0019(0.0034) | Loss 3.4534(3.4829) | Error 0.0011(0.0009) Steps 964(961.32) | Grad Norm 1.1984(0.9753) | Total Time 14.00(14.00)\n",
      "Iter 22740 | Time 24.9089(24.6091) | Bit/dim 3.4798(3.4843) | Xent 0.0037(0.0034) | Loss 3.4816(3.4860) | Error 0.0011(0.0009) Steps 976(962.87) | Grad Norm 1.4596(0.9698) | Total Time 14.00(14.00)\n",
      "Iter 22750 | Time 24.1805(24.6008) | Bit/dim 3.4413(3.4834) | Xent 0.0045(0.0029) | Loss 3.4436(3.4849) | Error 0.0011(0.0008) Steps 964(961.99) | Grad Norm 0.7709(0.8896) | Total Time 14.00(14.00)\n",
      "Iter 22760 | Time 24.8534(24.5947) | Bit/dim 3.4414(3.4834) | Xent 0.0011(0.0025) | Loss 3.4420(3.4846) | Error 0.0000(0.0007) Steps 976(961.92) | Grad Norm 0.4858(0.7959) | Total Time 14.00(14.00)\n",
      "Iter 22770 | Time 24.5276(24.6602) | Bit/dim 3.4712(3.4813) | Xent 0.0051(0.0024) | Loss 3.4737(3.4825) | Error 0.0022(0.0007) Steps 964(962.17) | Grad Norm 1.8936(0.8122) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 116.6811, Epoch Time 1487.5369(1482.6502), Bit/dim 3.5123(best: 3.5110), Xent 2.8280, Loss 4.9263, Error 0.3455(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22780 | Time 24.6429(24.6591) | Bit/dim 3.4843(3.4814) | Xent 0.0012(0.0033) | Loss 3.4849(3.4830) | Error 0.0000(0.0008) Steps 958(962.16) | Grad Norm 0.6933(0.9293) | Total Time 14.00(14.00)\n",
      "Iter 22790 | Time 24.4124(24.6424) | Bit/dim 3.4844(3.4836) | Xent 0.0005(0.0029) | Loss 3.4846(3.4851) | Error 0.0000(0.0008) Steps 952(962.48) | Grad Norm 0.4285(0.9292) | Total Time 14.00(14.00)\n",
      "Iter 22800 | Time 24.5822(24.6326) | Bit/dim 3.4895(3.4846) | Xent 0.0090(0.0036) | Loss 3.4939(3.4864) | Error 0.0022(0.0009) Steps 970(963.00) | Grad Norm 4.0474(1.1723) | Total Time 14.00(14.00)\n",
      "Iter 22810 | Time 24.3986(24.6231) | Bit/dim 3.4947(3.4850) | Xent 0.0169(0.0051) | Loss 3.5031(3.4875) | Error 0.0033(0.0014) Steps 964(963.45) | Grad Norm 1.4466(1.3705) | Total Time 14.00(14.00)\n",
      "Iter 22820 | Time 24.3607(24.6501) | Bit/dim 3.4480(3.4846) | Xent 0.0024(0.0053) | Loss 3.4492(3.4872) | Error 0.0011(0.0014) Steps 970(962.69) | Grad Norm 0.9094(1.3504) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 115.8669, Epoch Time 1489.2795(1482.8491), Bit/dim 3.5175(best: 3.5110), Xent 2.8162, Loss 4.9256, Error 0.3463(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22830 | Time 24.4229(24.6379) | Bit/dim 3.4847(3.4840) | Xent 0.0006(0.0055) | Loss 3.4850(3.4867) | Error 0.0000(0.0016) Steps 958(960.92) | Grad Norm 1.0355(1.4903) | Total Time 14.00(14.00)\n",
      "Iter 22840 | Time 24.4212(24.6254) | Bit/dim 3.4487(3.4827) | Xent 0.0017(0.0049) | Loss 3.4495(3.4851) | Error 0.0000(0.0014) Steps 970(961.61) | Grad Norm 0.9836(1.3735) | Total Time 14.00(14.00)\n",
      "Iter 22850 | Time 24.3976(24.6646) | Bit/dim 3.4691(3.4856) | Xent 0.0034(0.0048) | Loss 3.4707(3.4880) | Error 0.0011(0.0013) Steps 940(961.84) | Grad Norm 0.6829(1.2592) | Total Time 14.00(14.00)\n",
      "Iter 22860 | Time 24.7738(24.6954) | Bit/dim 3.4990(3.4862) | Xent 0.0017(0.0042) | Loss 3.4999(3.4883) | Error 0.0011(0.0012) Steps 964(961.94) | Grad Norm 0.7633(1.1846) | Total Time 14.00(14.00)\n",
      "Iter 22870 | Time 25.3217(24.6625) | Bit/dim 3.4772(3.4845) | Xent 0.0011(0.0038) | Loss 3.4777(3.4864) | Error 0.0000(0.0011) Steps 970(962.33) | Grad Norm 0.5938(1.0928) | Total Time 14.00(14.00)\n",
      "Iter 22880 | Time 24.5696(24.6783) | Bit/dim 3.5029(3.4824) | Xent 0.0005(0.0034) | Loss 3.5031(3.4841) | Error 0.0000(0.0010) Steps 964(962.64) | Grad Norm 0.3080(0.9656) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 116.5744, Epoch Time 1492.0639(1483.1255), Bit/dim 3.5111(best: 3.5110), Xent 2.7936, Loss 4.9079, Error 0.3443(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22890 | Time 24.5883(24.6722) | Bit/dim 3.5054(3.4842) | Xent 0.0005(0.0030) | Loss 3.5057(3.4857) | Error 0.0000(0.0008) Steps 952(963.17) | Grad Norm 0.4730(0.8766) | Total Time 14.00(14.00)\n",
      "Iter 22900 | Time 24.9536(24.7077) | Bit/dim 3.4965(3.4816) | Xent 0.0015(0.0027) | Loss 3.4972(3.4829) | Error 0.0000(0.0007) Steps 952(961.90) | Grad Norm 0.6324(0.8694) | Total Time 14.00(14.00)\n",
      "Iter 22910 | Time 24.8617(24.7817) | Bit/dim 3.4661(3.4797) | Xent 0.0003(0.0029) | Loss 3.4662(3.4811) | Error 0.0000(0.0007) Steps 976(962.88) | Grad Norm 0.2642(0.7833) | Total Time 14.00(14.00)\n",
      "Iter 22920 | Time 25.0520(24.7624) | Bit/dim 3.4870(3.4815) | Xent 0.0010(0.0027) | Loss 3.4875(3.4828) | Error 0.0000(0.0006) Steps 976(962.26) | Grad Norm 1.3141(0.7988) | Total Time 14.00(14.00)\n",
      "Iter 22930 | Time 24.5042(24.7812) | Bit/dim 3.5073(3.4820) | Xent 0.0049(0.0027) | Loss 3.5098(3.4833) | Error 0.0022(0.0007) Steps 964(963.24) | Grad Norm 1.5371(0.8266) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 116.0660, Epoch Time 1497.1839(1483.5473), Bit/dim 3.5118(best: 3.5110), Xent 2.7895, Loss 4.9065, Error 0.3431(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22940 | Time 24.7899(24.7280) | Bit/dim 3.4664(3.4825) | Xent 0.0005(0.0028) | Loss 3.4666(3.4839) | Error 0.0000(0.0007) Steps 952(962.13) | Grad Norm 0.4368(0.8673) | Total Time 14.00(14.00)\n",
      "Iter 22950 | Time 24.4033(24.6824) | Bit/dim 3.5057(3.4848) | Xent 0.0004(0.0025) | Loss 3.5059(3.4860) | Error 0.0000(0.0006) Steps 958(960.84) | Grad Norm 0.3284(0.7821) | Total Time 14.00(14.00)\n",
      "Iter 22960 | Time 24.6385(24.6089) | Bit/dim 3.4902(3.4841) | Xent 0.0005(0.0026) | Loss 3.4904(3.4854) | Error 0.0000(0.0007) Steps 964(960.25) | Grad Norm 0.4299(0.7577) | Total Time 14.00(14.00)\n",
      "Iter 22970 | Time 24.4904(24.6116) | Bit/dim 3.5118(3.4849) | Xent 0.0007(0.0027) | Loss 3.5121(3.4862) | Error 0.0000(0.0007) Steps 970(962.15) | Grad Norm 0.4507(0.7208) | Total Time 14.00(14.00)\n",
      "Iter 22980 | Time 24.6229(24.5866) | Bit/dim 3.4782(3.4814) | Xent 0.0042(0.0032) | Loss 3.4803(3.4830) | Error 0.0011(0.0008) Steps 970(962.26) | Grad Norm 0.9570(0.8406) | Total Time 14.00(14.00)\n",
      "Iter 22990 | Time 24.7295(24.6468) | Bit/dim 3.5090(3.4789) | Xent 0.0012(0.0033) | Loss 3.5096(3.4805) | Error 0.0000(0.0008) Steps 970(963.24) | Grad Norm 0.6415(0.9044) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 117.9432, Epoch Time 1488.0916(1483.6836), Bit/dim 3.5121(best: 3.5110), Xent 2.8313, Loss 4.9278, Error 0.3483(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23000 | Time 25.4061(24.7277) | Bit/dim 3.4730(3.4779) | Xent 0.0066(0.0037) | Loss 3.4763(3.4798) | Error 0.0011(0.0010) Steps 976(965.13) | Grad Norm 0.6847(0.9605) | Total Time 14.00(14.00)\n",
      "Iter 23010 | Time 24.5779(24.7940) | Bit/dim 3.4830(3.4790) | Xent 0.0021(0.0038) | Loss 3.4840(3.4809) | Error 0.0011(0.0010) Steps 970(963.96) | Grad Norm 0.8553(0.9346) | Total Time 14.00(14.00)\n",
      "Iter 23020 | Time 24.0991(24.7490) | Bit/dim 3.4582(3.4784) | Xent 0.0029(0.0034) | Loss 3.4597(3.4801) | Error 0.0011(0.0009) Steps 964(963.32) | Grad Norm 1.0978(0.9357) | Total Time 14.00(14.00)\n",
      "Iter 23030 | Time 24.4806(24.7314) | Bit/dim 3.4449(3.4789) | Xent 0.0005(0.0030) | Loss 3.4452(3.4804) | Error 0.0000(0.0008) Steps 958(963.47) | Grad Norm 0.4699(0.8468) | Total Time 14.00(14.00)\n",
      "Iter 23040 | Time 23.8086(24.6679) | Bit/dim 3.4820(3.4831) | Xent 0.0008(0.0030) | Loss 3.4823(3.4846) | Error 0.0000(0.0009) Steps 946(961.84) | Grad Norm 0.6091(0.8763) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 117.6140, Epoch Time 1497.6999(1484.1041), Bit/dim 3.5116(best: 3.5110), Xent 2.8232, Loss 4.9231, Error 0.3490(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23050 | Time 24.6978(24.6538) | Bit/dim 3.4757(3.4859) | Xent 0.0039(0.0032) | Loss 3.4777(3.4874) | Error 0.0011(0.0009) Steps 964(963.12) | Grad Norm 1.1176(0.9036) | Total Time 14.00(14.00)\n",
      "Iter 23060 | Time 24.3335(24.6518) | Bit/dim 3.4739(3.4827) | Xent 0.0059(0.0032) | Loss 3.4768(3.4843) | Error 0.0011(0.0009) Steps 946(962.70) | Grad Norm 0.8294(0.8729) | Total Time 14.00(14.00)\n",
      "Iter 23070 | Time 24.4919(24.7043) | Bit/dim 3.5053(3.4827) | Xent 0.0023(0.0030) | Loss 3.5065(3.4842) | Error 0.0011(0.0008) Steps 958(962.30) | Grad Norm 0.9671(0.8373) | Total Time 14.00(14.00)\n",
      "Iter 23080 | Time 24.4669(24.6735) | Bit/dim 3.5099(3.4809) | Xent 0.0018(0.0033) | Loss 3.5109(3.4826) | Error 0.0011(0.0009) Steps 940(961.57) | Grad Norm 1.0902(0.8559) | Total Time 14.00(14.00)\n",
      "Iter 23090 | Time 24.6254(24.6629) | Bit/dim 3.4933(3.4821) | Xent 0.0012(0.0033) | Loss 3.4939(3.4837) | Error 0.0000(0.0009) Steps 952(960.29) | Grad Norm 0.6798(0.9043) | Total Time 14.00(14.00)\n",
      "Iter 23100 | Time 24.4038(24.6313) | Bit/dim 3.4674(3.4812) | Xent 0.0036(0.0035) | Loss 3.4691(3.4829) | Error 0.0011(0.0009) Steps 952(959.94) | Grad Norm 0.8486(0.9457) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 116.9804, Epoch Time 1490.1494(1484.2855), Bit/dim 3.5120(best: 3.5110), Xent 2.8348, Loss 4.9294, Error 0.3473(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23110 | Time 24.7831(24.7554) | Bit/dim 3.4833(3.4821) | Xent 0.0009(0.0033) | Loss 3.4838(3.4838) | Error 0.0000(0.0009) Steps 952(961.67) | Grad Norm 1.0239(0.9505) | Total Time 14.00(14.00)\n",
      "Iter 23120 | Time 24.5203(24.7880) | Bit/dim 3.4986(3.4825) | Xent 0.0006(0.0030) | Loss 3.4989(3.4840) | Error 0.0000(0.0009) Steps 970(963.21) | Grad Norm 0.4795(0.9243) | Total Time 14.00(14.00)\n",
      "Iter 23130 | Time 25.1749(24.7576) | Bit/dim 3.4914(3.4812) | Xent 0.0015(0.0032) | Loss 3.4921(3.4828) | Error 0.0000(0.0008) Steps 982(963.59) | Grad Norm 0.7325(0.9141) | Total Time 14.00(14.00)\n",
      "Iter 23140 | Time 24.5575(24.7276) | Bit/dim 3.5044(3.4798) | Xent 0.0008(0.0028) | Loss 3.5048(3.4812) | Error 0.0000(0.0008) Steps 952(961.21) | Grad Norm 0.4211(0.8822) | Total Time 14.00(14.00)\n",
      "Iter 23150 | Time 24.6091(24.7459) | Bit/dim 3.4731(3.4801) | Xent 0.0025(0.0027) | Loss 3.4743(3.4814) | Error 0.0011(0.0008) Steps 970(961.73) | Grad Norm 0.4268(0.8235) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 117.2534, Epoch Time 1499.7805(1484.7503), Bit/dim 3.5103(best: 3.5110), Xent 2.8218, Loss 4.9212, Error 0.3464(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23160 | Time 25.1162(24.7300) | Bit/dim 3.5127(3.4828) | Xent 0.0008(0.0025) | Loss 3.5132(3.4840) | Error 0.0000(0.0008) Steps 958(962.09) | Grad Norm 0.3934(0.7991) | Total Time 14.00(14.00)\n",
      "Iter 23170 | Time 24.4644(24.7839) | Bit/dim 3.4848(3.4839) | Xent 0.0013(0.0028) | Loss 3.4855(3.4853) | Error 0.0000(0.0009) Steps 952(962.72) | Grad Norm 0.6899(0.8905) | Total Time 14.00(14.00)\n",
      "Iter 23180 | Time 24.5995(24.7422) | Bit/dim 3.4629(3.4817) | Xent 0.0060(0.0031) | Loss 3.4659(3.4833) | Error 0.0011(0.0011) Steps 964(962.62) | Grad Norm 1.7409(1.0188) | Total Time 14.00(14.00)\n",
      "Iter 23190 | Time 24.2540(24.8070) | Bit/dim 3.4900(3.4816) | Xent 0.0086(0.0035) | Loss 3.4943(3.4834) | Error 0.0022(0.0012) Steps 970(964.22) | Grad Norm 1.9266(1.0288) | Total Time 14.00(14.00)\n",
      "Iter 23200 | Time 24.9067(24.7820) | Bit/dim 3.4652(3.4837) | Xent 0.0130(0.0039) | Loss 3.4717(3.4856) | Error 0.0011(0.0012) Steps 964(963.91) | Grad Norm 0.8133(1.0575) | Total Time 14.00(14.00)\n",
      "Iter 23210 | Time 23.9802(24.6861) | Bit/dim 3.4245(3.4825) | Xent 0.0109(0.0043) | Loss 3.4299(3.4847) | Error 0.0022(0.0012) Steps 970(961.96) | Grad Norm 1.8332(1.1687) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 116.4263, Epoch Time 1495.7829(1485.0813), Bit/dim 3.5136(best: 3.5103), Xent 2.8223, Loss 4.9247, Error 0.3437(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23220 | Time 24.3362(24.5915) | Bit/dim 3.4855(3.4824) | Xent 0.0015(0.0039) | Loss 3.4862(3.4843) | Error 0.0000(0.0011) Steps 964(961.19) | Grad Norm 1.5010(1.1451) | Total Time 14.00(14.00)\n",
      "Iter 23230 | Time 24.0506(24.5931) | Bit/dim 3.4408(3.4804) | Xent 0.0047(0.0041) | Loss 3.4431(3.4825) | Error 0.0011(0.0011) Steps 958(961.87) | Grad Norm 0.8380(1.0924) | Total Time 14.00(14.00)\n",
      "Iter 23240 | Time 24.4921(24.6293) | Bit/dim 3.4795(3.4813) | Xent 0.0029(0.0037) | Loss 3.4810(3.4832) | Error 0.0011(0.0011) Steps 940(961.60) | Grad Norm 0.8028(1.0377) | Total Time 14.00(14.00)\n",
      "Iter 23250 | Time 24.7275(24.6346) | Bit/dim 3.4549(3.4818) | Xent 0.0013(0.0031) | Loss 3.4555(3.4833) | Error 0.0000(0.0008) Steps 976(964.11) | Grad Norm 0.8128(0.9270) | Total Time 14.00(14.00)\n",
      "Iter 23260 | Time 24.4815(24.6410) | Bit/dim 3.4952(3.4824) | Xent 0.0096(0.0038) | Loss 3.5000(3.4843) | Error 0.0011(0.0010) Steps 970(964.38) | Grad Norm 1.2806(1.0435) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 117.4462, Epoch Time 1489.3152(1485.2083), Bit/dim 3.5122(best: 3.5103), Xent 2.8632, Loss 4.9438, Error 0.3494(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23270 | Time 24.9764(24.6873) | Bit/dim 3.4804(3.4829) | Xent 0.0068(0.0037) | Loss 3.4838(3.4847) | Error 0.0033(0.0011) Steps 976(965.68) | Grad Norm 1.2829(1.0773) | Total Time 14.00(14.00)\n",
      "Iter 23280 | Time 24.8337(24.6462) | Bit/dim 3.4458(3.4832) | Xent 0.0009(0.0033) | Loss 3.4463(3.4849) | Error 0.0000(0.0009) Steps 964(965.55) | Grad Norm 0.6883(1.0556) | Total Time 14.00(14.00)\n",
      "Iter 23290 | Time 25.4964(24.6756) | Bit/dim 3.4744(3.4823) | Xent 0.0005(0.0032) | Loss 3.4747(3.4839) | Error 0.0000(0.0009) Steps 970(966.55) | Grad Norm 0.5820(1.0379) | Total Time 14.00(14.00)\n",
      "Iter 23300 | Time 25.0287(24.7491) | Bit/dim 3.5085(3.4841) | Xent 0.0143(0.0037) | Loss 3.5157(3.4860) | Error 0.0044(0.0010) Steps 970(966.24) | Grad Norm 2.3319(1.0360) | Total Time 14.00(14.00)\n",
      "Iter 23310 | Time 24.6840(24.7957) | Bit/dim 3.5072(3.4844) | Xent 0.0112(0.0038) | Loss 3.5128(3.4863) | Error 0.0033(0.0010) Steps 952(965.77) | Grad Norm 2.1189(1.0314) | Total Time 14.00(14.00)\n",
      "Iter 23320 | Time 24.5652(24.7966) | Bit/dim 3.4527(3.4806) | Xent 0.0097(0.0044) | Loss 3.4575(3.4828) | Error 0.0011(0.0011) Steps 964(965.15) | Grad Norm 1.5087(1.0424) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 115.6821, Epoch Time 1497.5604(1485.5789), Bit/dim 3.5128(best: 3.5103), Xent 2.8254, Loss 4.9255, Error 0.3447(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23330 | Time 24.9264(24.8232) | Bit/dim 3.4978(3.4813) | Xent 0.0017(0.0039) | Loss 3.4987(3.4832) | Error 0.0011(0.0011) Steps 970(964.75) | Grad Norm 0.7031(1.0053) | Total Time 14.00(14.00)\n",
      "Iter 23340 | Time 24.8403(24.8052) | Bit/dim 3.5368(3.4848) | Xent 0.0008(0.0035) | Loss 3.5372(3.4866) | Error 0.0000(0.0009) Steps 952(964.75) | Grad Norm 0.5135(0.9426) | Total Time 14.00(14.00)\n",
      "Iter 23350 | Time 25.0223(24.7810) | Bit/dim 3.4805(3.4843) | Xent 0.0031(0.0031) | Loss 3.4821(3.4858) | Error 0.0011(0.0008) Steps 970(964.89) | Grad Norm 1.9067(0.9267) | Total Time 14.00(14.00)\n",
      "Iter 23360 | Time 24.7666(24.8150) | Bit/dim 3.4490(3.4827) | Xent 0.0006(0.0031) | Loss 3.4493(3.4842) | Error 0.0000(0.0009) Steps 964(965.33) | Grad Norm 0.6421(0.9596) | Total Time 14.00(14.00)\n",
      "Iter 23370 | Time 24.2139(24.7762) | Bit/dim 3.3985(3.4792) | Xent 0.0049(0.0031) | Loss 3.4010(3.4808) | Error 0.0011(0.0008) Steps 958(964.30) | Grad Norm 0.6488(0.9116) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 116.1609, Epoch Time 1498.1695(1485.9566), Bit/dim 3.5096(best: 3.5103), Xent 2.8351, Loss 4.9271, Error 0.3462(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23380 | Time 24.8329(24.7782) | Bit/dim 3.4512(3.4777) | Xent 0.0011(0.0029) | Loss 3.4518(3.4792) | Error 0.0000(0.0008) Steps 958(964.14) | Grad Norm 0.4654(0.8624) | Total Time 14.00(14.00)\n",
      "Iter 23390 | Time 24.6360(24.7428) | Bit/dim 3.5162(3.4799) | Xent 0.0004(0.0029) | Loss 3.5164(3.4814) | Error 0.0000(0.0008) Steps 970(965.25) | Grad Norm 0.3979(0.8324) | Total Time 14.00(14.00)\n",
      "Iter 23400 | Time 24.5299(24.7516) | Bit/dim 3.4710(3.4783) | Xent 0.0010(0.0030) | Loss 3.4715(3.4798) | Error 0.0000(0.0009) Steps 952(964.96) | Grad Norm 0.3934(0.8106) | Total Time 14.00(14.00)\n",
      "Iter 23410 | Time 24.7208(24.7168) | Bit/dim 3.4833(3.4786) | Xent 0.0146(0.0034) | Loss 3.4906(3.4803) | Error 0.0044(0.0010) Steps 970(966.74) | Grad Norm 1.4291(0.8200) | Total Time 14.00(14.00)\n",
      "Iter 23420 | Time 24.4826(24.6859) | Bit/dim 3.4643(3.4778) | Xent 0.0005(0.0032) | Loss 3.4646(3.4794) | Error 0.0000(0.0009) Steps 964(966.09) | Grad Norm 0.5588(0.8623) | Total Time 14.00(14.00)\n",
      "Iter 23430 | Time 24.1039(24.6305) | Bit/dim 3.4970(3.4820) | Xent 0.0153(0.0038) | Loss 3.5047(3.4839) | Error 0.0022(0.0011) Steps 970(965.45) | Grad Norm 1.1907(0.9120) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 116.5071, Epoch Time 1489.2736(1486.0561), Bit/dim 3.5118(best: 3.5096), Xent 2.8332, Loss 4.9284, Error 0.3450(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23440 | Time 24.5414(24.5818) | Bit/dim 3.5263(3.4836) | Xent 0.0011(0.0032) | Loss 3.5269(3.4852) | Error 0.0000(0.0009) Steps 958(966.20) | Grad Norm 0.7112(0.8740) | Total Time 14.00(14.00)\n",
      "Iter 23450 | Time 24.1687(24.5850) | Bit/dim 3.4812(3.4802) | Xent 0.0077(0.0031) | Loss 3.4850(3.4818) | Error 0.0011(0.0009) Steps 964(965.16) | Grad Norm 1.2633(0.9399) | Total Time 14.00(14.00)\n",
      "Iter 23460 | Time 24.8442(24.6234) | Bit/dim 3.4876(3.4804) | Xent 0.0058(0.0047) | Loss 3.4904(3.4827) | Error 0.0011(0.0012) Steps 958(964.37) | Grad Norm 0.7664(1.0886) | Total Time 14.00(14.00)\n",
      "Iter 23470 | Time 24.4757(24.5559) | Bit/dim 3.4676(3.4812) | Xent 0.0043(0.0045) | Loss 3.4697(3.4835) | Error 0.0011(0.0012) Steps 958(964.17) | Grad Norm 0.9281(1.0886) | Total Time 14.00(14.00)\n",
      "Iter 23480 | Time 24.4786(24.5545) | Bit/dim 3.4902(3.4822) | Xent 0.0022(0.0046) | Loss 3.4913(3.4844) | Error 0.0011(0.0012) Steps 976(964.46) | Grad Norm 0.5236(1.0689) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 117.4836, Epoch Time 1487.4454(1486.0978), Bit/dim 3.5121(best: 3.5096), Xent 2.8037, Loss 4.9139, Error 0.3471(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23490 | Time 24.7987(24.6248) | Bit/dim 3.4698(3.4833) | Xent 0.0064(0.0046) | Loss 3.4730(3.4855) | Error 0.0022(0.0012) Steps 982(965.33) | Grad Norm 1.5907(1.0433) | Total Time 14.00(14.00)\n",
      "Iter 23500 | Time 25.4158(24.6542) | Bit/dim 3.5052(3.4823) | Xent 0.0041(0.0046) | Loss 3.5072(3.4846) | Error 0.0011(0.0013) Steps 976(964.41) | Grad Norm 0.7255(1.0606) | Total Time 14.00(14.00)\n",
      "Iter 23510 | Time 24.5413(24.6304) | Bit/dim 3.4887(3.4826) | Xent 0.0108(0.0048) | Loss 3.4941(3.4850) | Error 0.0022(0.0014) Steps 982(963.64) | Grad Norm 1.6106(1.0764) | Total Time 14.00(14.00)\n",
      "Iter 23520 | Time 24.3705(24.6931) | Bit/dim 3.4957(3.4808) | Xent 0.0037(0.0041) | Loss 3.4976(3.4828) | Error 0.0022(0.0012) Steps 976(965.11) | Grad Norm 0.7904(0.9807) | Total Time 14.00(14.00)\n",
      "Iter 23530 | Time 25.6929(24.7173) | Bit/dim 3.4651(3.4829) | Xent 0.0008(0.0033) | Loss 3.4654(3.4846) | Error 0.0000(0.0009) Steps 976(965.93) | Grad Norm 0.4157(0.8661) | Total Time 14.00(14.00)\n",
      "Iter 23540 | Time 24.7453(24.7552) | Bit/dim 3.4752(3.4829) | Xent 0.0016(0.0035) | Loss 3.4760(3.4846) | Error 0.0000(0.0010) Steps 970(967.45) | Grad Norm 0.9987(1.0430) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 115.2034, Epoch Time 1495.1547(1486.3695), Bit/dim 3.5113(best: 3.5096), Xent 2.7971, Loss 4.9098, Error 0.3471(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23550 | Time 24.7036(24.7947) | Bit/dim 3.5016(3.4848) | Xent 0.0034(0.0041) | Loss 3.5033(3.4868) | Error 0.0022(0.0013) Steps 970(965.06) | Grad Norm 1.5550(1.1252) | Total Time 14.00(14.00)\n",
      "Iter 23560 | Time 24.7659(24.8290) | Bit/dim 3.4626(3.4824) | Xent 0.0010(0.0034) | Loss 3.4631(3.4841) | Error 0.0000(0.0010) Steps 958(962.90) | Grad Norm 0.4027(0.9922) | Total Time 14.00(14.00)\n",
      "Iter 23570 | Time 25.1856(24.7518) | Bit/dim 3.4800(3.4820) | Xent 0.0017(0.0029) | Loss 3.4809(3.4834) | Error 0.0011(0.0009) Steps 964(962.87) | Grad Norm 0.9752(0.9062) | Total Time 14.00(14.00)\n",
      "Iter 23580 | Time 24.9388(24.7394) | Bit/dim 3.4910(3.4814) | Xent 0.0011(0.0027) | Loss 3.4915(3.4827) | Error 0.0000(0.0009) Steps 964(964.79) | Grad Norm 0.4913(0.8645) | Total Time 14.00(14.00)\n",
      "Iter 23590 | Time 24.9786(24.7243) | Bit/dim 3.4434(3.4807) | Xent 0.0012(0.0026) | Loss 3.4440(3.4820) | Error 0.0000(0.0008) Steps 952(963.00) | Grad Norm 0.4511(0.8368) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 116.7681, Epoch Time 1495.5597(1486.6452), Bit/dim 3.5096(best: 3.5096), Xent 2.8222, Loss 4.9207, Error 0.3452(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23600 | Time 24.6307(24.7416) | Bit/dim 3.4713(3.4813) | Xent 0.0010(0.0026) | Loss 3.4718(3.4826) | Error 0.0000(0.0007) Steps 964(964.81) | Grad Norm 0.4086(0.7950) | Total Time 14.00(14.00)\n",
      "Iter 23610 | Time 25.5078(24.7760) | Bit/dim 3.5000(3.4809) | Xent 0.0071(0.0026) | Loss 3.5036(3.4822) | Error 0.0022(0.0008) Steps 970(965.26) | Grad Norm 2.6348(0.8029) | Total Time 14.00(14.00)\n",
      "Iter 23620 | Time 24.1016(24.7457) | Bit/dim 3.4619(3.4809) | Xent 0.0004(0.0028) | Loss 3.4621(3.4823) | Error 0.0000(0.0008) Steps 958(965.32) | Grad Norm 0.4817(0.7972) | Total Time 14.00(14.00)\n",
      "Iter 23630 | Time 25.0426(24.7704) | Bit/dim 3.4969(3.4810) | Xent 0.0007(0.0031) | Loss 3.4973(3.4826) | Error 0.0000(0.0009) Steps 952(964.32) | Grad Norm 0.5102(0.8508) | Total Time 14.00(14.00)\n",
      "Iter 23640 | Time 24.7141(24.6935) | Bit/dim 3.4650(3.4817) | Xent 0.0030(0.0048) | Loss 3.4665(3.4841) | Error 0.0000(0.0010) Steps 976(964.36) | Grad Norm 1.0214(1.0108) | Total Time 14.00(14.00)\n",
      "Iter 23650 | Time 25.0032(24.7295) | Bit/dim 3.4748(3.4817) | Xent 0.0013(0.0047) | Loss 3.4755(3.4840) | Error 0.0000(0.0011) Steps 952(962.01) | Grad Norm 0.7379(1.0199) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 116.1143, Epoch Time 1495.6579(1486.9156), Bit/dim 3.5123(best: 3.5096), Xent 2.7917, Loss 4.9082, Error 0.3401(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23660 | Time 25.2448(24.7296) | Bit/dim 3.4931(3.4824) | Xent 0.0029(0.0042) | Loss 3.4945(3.4846) | Error 0.0011(0.0010) Steps 970(963.07) | Grad Norm 1.1631(0.9675) | Total Time 14.00(14.00)\n",
      "Iter 23670 | Time 24.6959(24.7819) | Bit/dim 3.4868(3.4828) | Xent 0.0111(0.0044) | Loss 3.4924(3.4849) | Error 0.0044(0.0011) Steps 976(964.42) | Grad Norm 1.9747(0.9741) | Total Time 14.00(14.00)\n",
      "Iter 23680 | Time 25.3507(24.7017) | Bit/dim 3.4629(3.4820) | Xent 0.0006(0.0042) | Loss 3.4632(3.4841) | Error 0.0000(0.0010) Steps 970(964.52) | Grad Norm 0.8316(1.0034) | Total Time 14.00(14.00)\n",
      "Iter 23690 | Time 24.7396(24.6642) | Bit/dim 3.4841(3.4862) | Xent 0.0037(0.0036) | Loss 3.4859(3.4880) | Error 0.0011(0.0009) Steps 970(963.44) | Grad Norm 1.2376(0.9513) | Total Time 14.00(14.00)\n",
      "Iter 23700 | Time 24.9911(24.6795) | Bit/dim 3.4575(3.4829) | Xent 0.0012(0.0036) | Loss 3.4581(3.4847) | Error 0.0000(0.0010) Steps 964(964.04) | Grad Norm 0.5372(0.9452) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 116.8023, Epoch Time 1491.8195(1487.0627), Bit/dim 3.5102(best: 3.5096), Xent 2.8393, Loss 4.9298, Error 0.3490(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23710 | Time 23.8518(24.6501) | Bit/dim 3.4469(3.4786) | Xent 0.0030(0.0036) | Loss 3.4484(3.4804) | Error 0.0011(0.0009) Steps 970(963.53) | Grad Norm 1.0542(0.9143) | Total Time 14.00(14.00)\n",
      "Iter 23720 | Time 25.0053(24.6481) | Bit/dim 3.4501(3.4786) | Xent 0.0018(0.0038) | Loss 3.4510(3.4805) | Error 0.0011(0.0009) Steps 982(963.45) | Grad Norm 1.7929(0.8984) | Total Time 14.00(14.00)\n",
      "Iter 23730 | Time 24.6504(24.6714) | Bit/dim 3.5070(3.4793) | Xent 0.0034(0.0035) | Loss 3.5087(3.4810) | Error 0.0022(0.0009) Steps 970(965.16) | Grad Norm 0.9727(0.8755) | Total Time 14.00(14.00)\n",
      "Iter 23740 | Time 24.8059(24.6228) | Bit/dim 3.4818(3.4802) | Xent 0.0109(0.0036) | Loss 3.4872(3.4819) | Error 0.0022(0.0010) Steps 970(965.90) | Grad Norm 3.5001(0.9474) | Total Time 14.00(14.00)\n",
      "Iter 23750 | Time 24.5214(24.6712) | Bit/dim 3.4956(3.4814) | Xent 0.0005(0.0033) | Loss 3.4958(3.4830) | Error 0.0000(0.0009) Steps 970(964.46) | Grad Norm 0.7391(0.9812) | Total Time 14.00(14.00)\n",
      "Iter 23760 | Time 24.3921(24.6559) | Bit/dim 3.4698(3.4828) | Xent 0.0018(0.0034) | Loss 3.4707(3.4845) | Error 0.0011(0.0009) Steps 964(963.94) | Grad Norm 1.2459(0.9925) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 115.7165, Epoch Time 1489.4611(1487.1347), Bit/dim 3.5105(best: 3.5096), Xent 2.8512, Loss 4.9361, Error 0.3486(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23770 | Time 24.3631(24.6462) | Bit/dim 3.4583(3.4819) | Xent 0.0007(0.0047) | Loss 3.4587(3.4843) | Error 0.0000(0.0012) Steps 964(963.96) | Grad Norm 0.5900(1.0454) | Total Time 14.00(14.00)\n",
      "Iter 23780 | Time 24.1595(24.6109) | Bit/dim 3.4401(3.4801) | Xent 0.0100(0.0046) | Loss 3.4451(3.4823) | Error 0.0022(0.0011) Steps 976(963.81) | Grad Norm 1.2401(1.0588) | Total Time 14.00(14.00)\n",
      "Iter 23790 | Time 24.6660(24.6160) | Bit/dim 3.4825(3.4801) | Xent 0.0010(0.0048) | Loss 3.4830(3.4825) | Error 0.0000(0.0012) Steps 952(962.21) | Grad Norm 1.0750(1.1006) | Total Time 14.00(14.00)\n",
      "Iter 23800 | Time 24.4192(24.5739) | Bit/dim 3.5061(3.4837) | Xent 0.0006(0.0043) | Loss 3.5064(3.4859) | Error 0.0000(0.0010) Steps 946(961.36) | Grad Norm 0.4273(1.0482) | Total Time 14.00(14.00)\n",
      "Iter 23810 | Time 24.6523(24.6322) | Bit/dim 3.4788(3.4819) | Xent 0.0011(0.0039) | Loss 3.4793(3.4838) | Error 0.0000(0.0010) Steps 964(961.25) | Grad Norm 0.5436(1.0048) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 116.7492, Epoch Time 1488.4301(1487.1735), Bit/dim 3.5101(best: 3.5096), Xent 2.8325, Loss 4.9263, Error 0.3455(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23820 | Time 24.5930(24.6520) | Bit/dim 3.4797(3.4815) | Xent 0.0009(0.0035) | Loss 3.4802(3.4832) | Error 0.0000(0.0009) Steps 970(962.49) | Grad Norm 0.6580(0.9557) | Total Time 14.00(14.00)\n",
      "Iter 23830 | Time 24.6653(24.6657) | Bit/dim 3.4798(3.4789) | Xent 0.0023(0.0031) | Loss 3.4809(3.4805) | Error 0.0011(0.0008) Steps 952(961.84) | Grad Norm 2.4044(0.9825) | Total Time 14.00(14.00)\n",
      "Iter 23840 | Time 24.6594(24.6629) | Bit/dim 3.4466(3.4790) | Xent 0.0017(0.0031) | Loss 3.4474(3.4805) | Error 0.0011(0.0009) Steps 958(961.55) | Grad Norm 1.0282(1.0049) | Total Time 14.00(14.00)\n",
      "Iter 23850 | Time 24.3713(24.7301) | Bit/dim 3.5289(3.4826) | Xent 0.0237(0.0039) | Loss 3.5408(3.4845) | Error 0.0044(0.0010) Steps 952(962.68) | Grad Norm 1.9050(1.0370) | Total Time 14.00(14.00)\n",
      "Iter 23860 | Time 24.8149(24.7796) | Bit/dim 3.4985(3.4823) | Xent 0.0014(0.0037) | Loss 3.4992(3.4841) | Error 0.0000(0.0010) Steps 964(963.08) | Grad Norm 0.7300(1.0169) | Total Time 14.00(14.00)\n",
      "Iter 23870 | Time 24.8240(24.7602) | Bit/dim 3.4835(3.4827) | Xent 0.0107(0.0037) | Loss 3.4889(3.4846) | Error 0.0022(0.0009) Steps 952(962.22) | Grad Norm 1.9595(1.0422) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 117.7263, Epoch Time 1499.0204(1487.5289), Bit/dim 3.5108(best: 3.5096), Xent 2.8142, Loss 4.9179, Error 0.3432(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23880 | Time 24.7730(24.7733) | Bit/dim 3.5027(3.4807) | Xent 0.0038(0.0033) | Loss 3.5046(3.4824) | Error 0.0011(0.0008) Steps 970(963.17) | Grad Norm 0.8281(0.9602) | Total Time 14.00(14.00)\n",
      "Iter 23890 | Time 24.8097(24.7401) | Bit/dim 3.5043(3.4834) | Xent 0.0021(0.0027) | Loss 3.5053(3.4848) | Error 0.0000(0.0006) Steps 988(965.32) | Grad Norm 0.6221(0.8440) | Total Time 14.00(14.00)\n",
      "Iter 23900 | Time 24.1973(24.6590) | Bit/dim 3.5149(3.4819) | Xent 0.0005(0.0025) | Loss 3.5151(3.4832) | Error 0.0000(0.0006) Steps 970(964.28) | Grad Norm 0.2644(0.7505) | Total Time 14.00(14.00)\n",
      "Iter 23910 | Time 24.4429(24.6386) | Bit/dim 3.4780(3.4813) | Xent 0.0009(0.0027) | Loss 3.4785(3.4826) | Error 0.0000(0.0006) Steps 964(963.85) | Grad Norm 0.5988(0.7675) | Total Time 14.00(14.00)\n",
      "Iter 23920 | Time 24.9308(24.6363) | Bit/dim 3.4526(3.4801) | Xent 0.0008(0.0025) | Loss 3.4530(3.4813) | Error 0.0000(0.0006) Steps 958(963.54) | Grad Norm 0.3449(0.7273) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 116.1325, Epoch Time 1491.0154(1487.6335), Bit/dim 3.5097(best: 3.5096), Xent 2.8916, Loss 4.9555, Error 0.3486(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23930 | Time 25.0273(24.6933) | Bit/dim 3.4533(3.4802) | Xent 0.0018(0.0024) | Loss 3.4542(3.4814) | Error 0.0011(0.0006) Steps 964(963.58) | Grad Norm 0.5224(0.7117) | Total Time 14.00(14.00)\n",
      "Iter 23940 | Time 24.5440(24.6282) | Bit/dim 3.4870(3.4803) | Xent 0.0005(0.0022) | Loss 3.4872(3.4814) | Error 0.0000(0.0006) Steps 964(964.06) | Grad Norm 0.3343(0.6962) | Total Time 14.00(14.00)\n",
      "Iter 23950 | Time 25.1841(24.6582) | Bit/dim 3.5009(3.4792) | Xent 0.0005(0.0023) | Loss 3.5011(3.4803) | Error 0.0000(0.0006) Steps 952(962.27) | Grad Norm 0.2626(0.6462) | Total Time 14.00(14.00)\n",
      "Iter 23960 | Time 24.2327(24.6567) | Bit/dim 3.4853(3.4766) | Xent 0.0041(0.0023) | Loss 3.4874(3.4778) | Error 0.0011(0.0005) Steps 964(962.73) | Grad Norm 1.0958(0.6523) | Total Time 14.00(14.00)\n",
      "Iter 23970 | Time 25.3788(24.6497) | Bit/dim 3.4509(3.4776) | Xent 0.0156(0.0028) | Loss 3.4587(3.4790) | Error 0.0044(0.0007) Steps 964(963.35) | Grad Norm 2.3818(0.7885) | Total Time 14.00(14.00)\n",
      "Iter 23980 | Time 25.0821(24.6776) | Bit/dim 3.4905(3.4809) | Xent 0.0003(0.0038) | Loss 3.4907(3.4828) | Error 0.0000(0.0010) Steps 982(964.59) | Grad Norm 0.4778(0.9165) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 116.5918, Epoch Time 1490.0396(1487.7057), Bit/dim 3.5112(best: 3.5096), Xent 2.9284, Loss 4.9755, Error 0.3454(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23990 | Time 24.6503(24.6551) | Bit/dim 3.4902(3.4810) | Xent 0.0013(0.0040) | Loss 3.4909(3.4830) | Error 0.0000(0.0011) Steps 964(964.73) | Grad Norm 0.8929(1.0209) | Total Time 14.00(14.00)\n",
      "Iter 24000 | Time 24.8581(24.6428) | Bit/dim 3.4780(3.4829) | Xent 0.0055(0.0044) | Loss 3.4808(3.4851) | Error 0.0022(0.0013) Steps 964(965.39) | Grad Norm 1.4258(1.1184) | Total Time 14.00(14.00)\n",
      "Iter 24010 | Time 24.2695(24.6471) | Bit/dim 3.4681(3.4798) | Xent 0.0107(0.0048) | Loss 3.4735(3.4822) | Error 0.0033(0.0014) Steps 964(964.56) | Grad Norm 2.5669(1.2014) | Total Time 14.00(14.00)\n",
      "Iter 24020 | Time 24.8368(24.6319) | Bit/dim 3.4904(3.4813) | Xent 0.0131(0.0053) | Loss 3.4969(3.4839) | Error 0.0022(0.0015) Steps 964(964.00) | Grad Norm 1.2181(1.3501) | Total Time 14.00(14.00)\n",
      "Iter 24030 | Time 24.5450(24.5840) | Bit/dim 3.4690(3.4823) | Xent 0.0035(0.0046) | Loss 3.4707(3.4846) | Error 0.0011(0.0013) Steps 970(963.57) | Grad Norm 1.1899(1.2754) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 115.6096, Epoch Time 1486.1995(1487.6605), Bit/dim 3.5108(best: 3.5096), Xent 2.9141, Loss 4.9679, Error 0.3520(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24040 | Time 24.1673(24.5642) | Bit/dim 3.4713(3.4808) | Xent 0.0091(0.0045) | Loss 3.4759(3.4831) | Error 0.0011(0.0013) Steps 970(963.58) | Grad Norm 1.1920(1.1887) | Total Time 14.00(14.00)\n",
      "Iter 24050 | Time 24.2991(24.4883) | Bit/dim 3.5342(3.4805) | Xent 0.0006(0.0043) | Loss 3.5345(3.4827) | Error 0.0000(0.0012) Steps 946(963.91) | Grad Norm 0.3842(1.0779) | Total Time 14.00(14.00)\n",
      "Iter 24060 | Time 24.9162(24.5504) | Bit/dim 3.4966(3.4802) | Xent 0.0077(0.0041) | Loss 3.5005(3.4822) | Error 0.0022(0.0012) Steps 964(965.03) | Grad Norm 2.8503(1.0752) | Total Time 14.00(14.00)\n",
      "Iter 24070 | Time 25.2547(24.6241) | Bit/dim 3.4580(3.4822) | Xent 0.0067(0.0036) | Loss 3.4614(3.4839) | Error 0.0022(0.0011) Steps 964(965.41) | Grad Norm 1.2175(0.9963) | Total Time 14.00(14.00)\n",
      "Iter 24080 | Time 25.2621(24.7117) | Bit/dim 3.4440(3.4823) | Xent 0.0064(0.0040) | Loss 3.4472(3.4843) | Error 0.0022(0.0012) Steps 946(965.26) | Grad Norm 1.5054(1.0270) | Total Time 14.00(14.00)\n",
      "Iter 24090 | Time 25.2329(24.7403) | Bit/dim 3.5032(3.4824) | Xent 0.0010(0.0040) | Loss 3.5038(3.4844) | Error 0.0000(0.0011) Steps 952(964.52) | Grad Norm 0.7558(1.0324) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 117.0822, Epoch Time 1492.9768(1487.8200), Bit/dim 3.5104(best: 3.5096), Xent 2.8917, Loss 4.9562, Error 0.3479(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24100 | Time 24.5192(24.7208) | Bit/dim 3.4688(3.4815) | Xent 0.0088(0.0036) | Loss 3.4732(3.4833) | Error 0.0011(0.0009) Steps 970(963.89) | Grad Norm 1.0437(0.9555) | Total Time 14.00(14.00)\n",
      "Iter 24110 | Time 24.1902(24.6779) | Bit/dim 3.4607(3.4817) | Xent 0.0028(0.0034) | Loss 3.4621(3.4834) | Error 0.0011(0.0009) Steps 958(963.69) | Grad Norm 1.5163(1.0140) | Total Time 14.00(14.00)\n",
      "Iter 24120 | Time 24.4291(24.6103) | Bit/dim 3.4851(3.4829) | Xent 0.0008(0.0031) | Loss 3.4856(3.4845) | Error 0.0000(0.0009) Steps 970(962.66) | Grad Norm 0.5507(0.9339) | Total Time 14.00(14.00)\n",
      "Iter 24130 | Time 24.5302(24.6164) | Bit/dim 3.4360(3.4818) | Xent 0.0051(0.0027) | Loss 3.4385(3.4831) | Error 0.0011(0.0007) Steps 964(962.52) | Grad Norm 1.2274(0.8510) | Total Time 14.00(14.00)\n",
      "Iter 24140 | Time 23.9635(24.6399) | Bit/dim 3.4917(3.4798) | Xent 0.0005(0.0026) | Loss 3.4920(3.4811) | Error 0.0000(0.0007) Steps 964(962.37) | Grad Norm 0.7252(0.8577) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 115.4547, Epoch Time 1487.1488(1487.7999), Bit/dim 3.5112(best: 3.5096), Xent 2.8788, Loss 4.9506, Error 0.3500(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24150 | Time 24.7459(24.6628) | Bit/dim 3.4960(3.4786) | Xent 0.0007(0.0025) | Loss 3.4963(3.4798) | Error 0.0000(0.0007) Steps 970(964.06) | Grad Norm 0.4078(0.8772) | Total Time 14.00(14.00)\n",
      "Iter 24160 | Time 24.3536(24.6468) | Bit/dim 3.4995(3.4810) | Xent 0.0007(0.0026) | Loss 3.4999(3.4824) | Error 0.0000(0.0008) Steps 976(963.96) | Grad Norm 0.6903(0.9007) | Total Time 14.00(14.00)\n",
      "Iter 24170 | Time 24.9888(24.6456) | Bit/dim 3.4610(3.4812) | Xent 0.0030(0.0026) | Loss 3.4624(3.4825) | Error 0.0011(0.0008) Steps 964(963.29) | Grad Norm 0.9108(0.9507) | Total Time 14.00(14.00)\n",
      "Iter 24180 | Time 24.5408(24.7056) | Bit/dim 3.4823(3.4800) | Xent 0.0041(0.0030) | Loss 3.4844(3.4815) | Error 0.0011(0.0009) Steps 958(964.71) | Grad Norm 1.1612(0.9788) | Total Time 14.00(14.00)\n",
      "Iter 24190 | Time 24.8600(24.7075) | Bit/dim 3.4788(3.4813) | Xent 0.0183(0.0038) | Loss 3.4880(3.4832) | Error 0.0078(0.0011) Steps 964(964.33) | Grad Norm 3.9264(1.0521) | Total Time 14.00(14.00)\n",
      "Iter 24200 | Time 24.9448(24.6527) | Bit/dim 3.4780(3.4804) | Xent 0.0005(0.0037) | Loss 3.4783(3.4823) | Error 0.0000(0.0011) Steps 970(963.41) | Grad Norm 0.5014(1.0824) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 116.7050, Epoch Time 1491.6028(1487.9139), Bit/dim 3.5110(best: 3.5096), Xent 2.8950, Loss 4.9585, Error 0.3490(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24210 | Time 24.7526(24.6869) | Bit/dim 3.4811(3.4816) | Xent 0.0158(0.0041) | Loss 3.4890(3.4836) | Error 0.0022(0.0011) Steps 958(964.22) | Grad Norm 1.3284(1.0694) | Total Time 14.00(14.00)\n",
      "Iter 24220 | Time 25.2263(24.6968) | Bit/dim 3.4704(3.4825) | Xent 0.0032(0.0042) | Loss 3.4720(3.4845) | Error 0.0022(0.0011) Steps 970(965.78) | Grad Norm 0.9185(1.0402) | Total Time 14.00(14.00)\n",
      "Iter 24230 | Time 24.5728(24.6965) | Bit/dim 3.4652(3.4827) | Xent 0.0031(0.0041) | Loss 3.4668(3.4848) | Error 0.0000(0.0011) Steps 970(965.54) | Grad Norm 1.1231(1.0845) | Total Time 14.00(14.00)\n",
      "Iter 24240 | Time 25.0096(24.6839) | Bit/dim 3.4798(3.4803) | Xent 0.0018(0.0049) | Loss 3.4807(3.4828) | Error 0.0011(0.0015) Steps 970(966.45) | Grad Norm 0.7149(1.1966) | Total Time 14.00(14.00)\n",
      "Iter 24250 | Time 24.6359(24.6459) | Bit/dim 3.4572(3.4799) | Xent 0.0010(0.0048) | Loss 3.4577(3.4823) | Error 0.0000(0.0014) Steps 958(965.50) | Grad Norm 0.5318(1.1967) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 116.9444, Epoch Time 1492.0080(1488.0368), Bit/dim 3.5108(best: 3.5096), Xent 2.8627, Loss 4.9421, Error 0.3424(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24260 | Time 24.9718(24.6360) | Bit/dim 3.4592(3.4798) | Xent 0.0015(0.0046) | Loss 3.4600(3.4821) | Error 0.0000(0.0013) Steps 970(965.60) | Grad Norm 0.4858(1.1189) | Total Time 14.00(14.00)\n",
      "Iter 24270 | Time 24.3885(24.6197) | Bit/dim 3.4692(3.4782) | Xent 0.0006(0.0041) | Loss 3.4694(3.4803) | Error 0.0000(0.0011) Steps 964(966.48) | Grad Norm 0.4339(1.0716) | Total Time 14.00(14.00)\n",
      "Iter 24280 | Time 24.3720(24.5812) | Bit/dim 3.4753(3.4789) | Xent 0.0095(0.0044) | Loss 3.4800(3.4811) | Error 0.0022(0.0013) Steps 970(965.07) | Grad Norm 1.3562(1.0539) | Total Time 14.00(14.00)\n",
      "Iter 24290 | Time 24.6889(24.5222) | Bit/dim 3.4929(3.4805) | Xent 0.0005(0.0040) | Loss 3.4932(3.4825) | Error 0.0000(0.0011) Steps 952(964.46) | Grad Norm 0.6991(1.0146) | Total Time 14.00(14.00)\n",
      "Iter 24300 | Time 24.7277(24.6086) | Bit/dim 3.4292(3.4812) | Xent 0.0042(0.0036) | Loss 3.4313(3.4830) | Error 0.0011(0.0010) Steps 982(965.26) | Grad Norm 0.9032(0.9372) | Total Time 14.00(14.00)\n",
      "Iter 24310 | Time 24.7093(24.6061) | Bit/dim 3.4619(3.4819) | Xent 0.0007(0.0036) | Loss 3.4622(3.4837) | Error 0.0000(0.0009) Steps 964(964.66) | Grad Norm 0.3866(0.8893) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 117.7297, Epoch Time 1487.9180(1488.0332), Bit/dim 3.5096(best: 3.5096), Xent 2.8540, Loss 4.9366, Error 0.3462(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24320 | Time 24.3334(24.6539) | Bit/dim 3.4816(3.4806) | Xent 0.0009(0.0035) | Loss 3.4820(3.4824) | Error 0.0000(0.0009) Steps 958(964.64) | Grad Norm 0.4513(0.8708) | Total Time 14.00(14.00)\n",
      "Iter 24330 | Time 24.7352(24.7403) | Bit/dim 3.4865(3.4809) | Xent 0.0025(0.0032) | Loss 3.4878(3.4825) | Error 0.0011(0.0009) Steps 970(964.61) | Grad Norm 0.5383(0.7918) | Total Time 14.00(14.00)\n",
      "Iter 24340 | Time 24.6739(24.7639) | Bit/dim 3.4875(3.4826) | Xent 0.0011(0.0029) | Loss 3.4881(3.4841) | Error 0.0000(0.0008) Steps 970(965.30) | Grad Norm 0.4342(0.7911) | Total Time 14.00(14.00)\n",
      "Iter 24350 | Time 24.1434(24.7303) | Bit/dim 3.4599(3.4807) | Xent 0.0051(0.0031) | Loss 3.4624(3.4822) | Error 0.0022(0.0009) Steps 970(965.67) | Grad Norm 1.8051(0.8914) | Total Time 14.00(14.00)\n",
      "Iter 24360 | Time 24.4588(24.7611) | Bit/dim 3.5004(3.4789) | Xent 0.0088(0.0030) | Loss 3.5048(3.4805) | Error 0.0022(0.0009) Steps 964(965.07) | Grad Norm 1.1299(0.8557) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 116.5665, Epoch Time 1500.3002(1488.4012), Bit/dim 3.5097(best: 3.5096), Xent 2.8678, Loss 4.9436, Error 0.3403(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24370 | Time 25.2736(24.7411) | Bit/dim 3.4485(3.4786) | Xent 0.0014(0.0029) | Loss 3.4491(3.4801) | Error 0.0000(0.0008) Steps 958(964.53) | Grad Norm 0.5382(0.8778) | Total Time 14.00(14.00)\n",
      "Iter 24380 | Time 23.7113(24.6569) | Bit/dim 3.4848(3.4815) | Xent 0.0013(0.0028) | Loss 3.4854(3.4829) | Error 0.0000(0.0007) Steps 958(963.37) | Grad Norm 0.5881(0.8687) | Total Time 14.00(14.00)\n",
      "Iter 24390 | Time 24.7551(24.6638) | Bit/dim 3.4641(3.4792) | Xent 0.0010(0.0034) | Loss 3.4646(3.4809) | Error 0.0000(0.0009) Steps 976(963.58) | Grad Norm 0.7917(0.8797) | Total Time 14.00(14.00)\n",
      "Iter 24400 | Time 25.6151(24.6813) | Bit/dim 3.4599(3.4766) | Xent 0.0023(0.0030) | Loss 3.4610(3.4781) | Error 0.0011(0.0008) Steps 940(963.25) | Grad Norm 0.5669(0.8246) | Total Time 14.00(14.00)\n",
      "Iter 24410 | Time 24.7127(24.7030) | Bit/dim 3.4738(3.4777) | Xent 0.0104(0.0027) | Loss 3.4790(3.4791) | Error 0.0011(0.0006) Steps 958(963.62) | Grad Norm 0.8777(0.7202) | Total Time 14.00(14.00)\n",
      "Iter 24420 | Time 23.6642(24.6877) | Bit/dim 3.4764(3.4791) | Xent 0.0006(0.0028) | Loss 3.4767(3.4805) | Error 0.0000(0.0007) Steps 952(963.51) | Grad Norm 0.2474(0.7122) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 115.8140, Epoch Time 1489.3469(1488.4296), Bit/dim 3.5086(best: 3.5096), Xent 2.8696, Loss 4.9434, Error 0.3476(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24430 | Time 24.3180(24.6390) | Bit/dim 3.4646(3.4790) | Xent 0.0024(0.0032) | Loss 3.4658(3.4806) | Error 0.0011(0.0007) Steps 952(964.37) | Grad Norm 1.0226(0.7685) | Total Time 14.00(14.00)\n",
      "Iter 24440 | Time 24.4418(24.6442) | Bit/dim 3.4926(3.4774) | Xent 0.0007(0.0031) | Loss 3.4930(3.4789) | Error 0.0000(0.0008) Steps 970(964.86) | Grad Norm 0.4378(0.7745) | Total Time 14.00(14.00)\n",
      "Iter 24450 | Time 24.5944(24.5649) | Bit/dim 3.4702(3.4771) | Xent 0.0004(0.0028) | Loss 3.4704(3.4786) | Error 0.0000(0.0007) Steps 958(963.87) | Grad Norm 0.3141(0.6988) | Total Time 14.00(14.00)\n",
      "Iter 24460 | Time 25.1898(24.5978) | Bit/dim 3.4849(3.4778) | Xent 0.0048(0.0029) | Loss 3.4872(3.4793) | Error 0.0011(0.0008) Steps 958(964.04) | Grad Norm 1.3222(0.7663) | Total Time 14.00(14.00)\n",
      "Iter 24470 | Time 24.8918(24.6144) | Bit/dim 3.4963(3.4773) | Xent 0.0014(0.0030) | Loss 3.4970(3.4788) | Error 0.0000(0.0008) Steps 970(964.70) | Grad Norm 0.6645(0.7860) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 115.3374, Epoch Time 1486.1533(1488.3613), Bit/dim 3.5093(best: 3.5086), Xent 2.9001, Loss 4.9593, Error 0.3503(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24480 | Time 23.9928(24.6244) | Bit/dim 3.4809(3.4775) | Xent 0.0080(0.0030) | Loss 3.4849(3.4790) | Error 0.0011(0.0009) Steps 964(964.39) | Grad Norm 0.5432(0.7714) | Total Time 14.00(14.00)\n",
      "Iter 24490 | Time 24.4458(24.5580) | Bit/dim 3.4586(3.4756) | Xent 0.0025(0.0033) | Loss 3.4599(3.4773) | Error 0.0000(0.0008) Steps 964(964.63) | Grad Norm 1.2465(0.8069) | Total Time 14.00(14.00)\n",
      "Iter 24500 | Time 24.0849(24.5408) | Bit/dim 3.4926(3.4776) | Xent 0.0004(0.0028) | Loss 3.4927(3.4790) | Error 0.0000(0.0006) Steps 970(964.45) | Grad Norm 0.2995(0.7370) | Total Time 14.00(14.00)\n",
      "Iter 24510 | Time 24.9318(24.5666) | Bit/dim 3.4534(3.4778) | Xent 0.0063(0.0030) | Loss 3.4565(3.4793) | Error 0.0011(0.0007) Steps 964(965.46) | Grad Norm 1.6070(0.9227) | Total Time 14.00(14.00)\n",
      "Iter 24520 | Time 24.9937(24.6406) | Bit/dim 3.4876(3.4795) | Xent 0.0048(0.0027) | Loss 3.4900(3.4809) | Error 0.0011(0.0006) Steps 970(965.15) | Grad Norm 1.7843(0.9458) | Total Time 14.00(14.00)\n",
      "Iter 24530 | Time 25.0981(24.7163) | Bit/dim 3.4608(3.4805) | Xent 0.0196(0.0042) | Loss 3.4706(3.4826) | Error 0.0056(0.0010) Steps 952(965.56) | Grad Norm 3.5023(1.1511) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 114.1839, Epoch Time 1487.6832(1488.3410), Bit/dim 3.5146(best: 3.5086), Xent 2.9301, Loss 4.9797, Error 0.3507(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24540 | Time 24.7730(24.6354) | Bit/dim 3.5024(3.4846) | Xent 0.0007(0.0060) | Loss 3.5028(3.4876) | Error 0.0000(0.0014) Steps 976(964.29) | Grad Norm 1.1639(1.4104) | Total Time 14.00(14.00)\n",
      "Iter 24550 | Time 24.1578(24.6029) | Bit/dim 3.4907(3.4860) | Xent 0.0049(0.0055) | Loss 3.4932(3.4887) | Error 0.0011(0.0013) Steps 958(963.70) | Grad Norm 1.1485(1.4151) | Total Time 14.00(14.00)\n",
      "Iter 24560 | Time 25.2577(24.5962) | Bit/dim 3.4754(3.4860) | Xent 0.0006(0.0050) | Loss 3.4757(3.4885) | Error 0.0000(0.0014) Steps 952(963.00) | Grad Norm 0.5354(1.3834) | Total Time 14.00(14.00)\n",
      "Iter 24570 | Time 24.7575(24.5445) | Bit/dim 3.4723(3.4827) | Xent 0.0018(0.0044) | Loss 3.4733(3.4849) | Error 0.0000(0.0011) Steps 970(963.06) | Grad Norm 0.7734(1.2600) | Total Time 14.00(14.00)\n",
      "Iter 24580 | Time 24.3392(24.6372) | Bit/dim 3.4749(3.4806) | Xent 0.0069(0.0040) | Loss 3.4783(3.4826) | Error 0.0022(0.0011) Steps 964(963.67) | Grad Norm 1.8384(1.1536) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 114.3581, Epoch Time 1482.2156(1488.1572), Bit/dim 3.5113(best: 3.5086), Xent 2.8553, Loss 4.9390, Error 0.3462(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24590 | Time 24.2835(24.6027) | Bit/dim 3.4689(3.4782) | Xent 0.0056(0.0042) | Loss 3.4717(3.4803) | Error 0.0033(0.0013) Steps 970(964.14) | Grad Norm 1.1374(1.2226) | Total Time 14.00(14.00)\n",
      "Iter 24600 | Time 24.2347(24.5502) | Bit/dim 3.4632(3.4795) | Xent 0.0006(0.0038) | Loss 3.4636(3.4814) | Error 0.0000(0.0012) Steps 970(964.08) | Grad Norm 0.7402(1.1653) | Total Time 14.00(14.00)\n",
      "Iter 24610 | Time 25.3732(24.5427) | Bit/dim 3.4475(3.4795) | Xent 0.0008(0.0037) | Loss 3.4479(3.4814) | Error 0.0000(0.0011) Steps 976(963.12) | Grad Norm 0.7612(1.1431) | Total Time 14.00(14.00)\n",
      "Iter 24620 | Time 25.1747(24.5567) | Bit/dim 3.4694(3.4769) | Xent 0.0042(0.0036) | Loss 3.4715(3.4787) | Error 0.0011(0.0010) Steps 964(964.55) | Grad Norm 0.5505(1.0485) | Total Time 14.00(14.00)\n",
      "Iter 24630 | Time 25.2997(24.5446) | Bit/dim 3.4663(3.4791) | Xent 0.0007(0.0033) | Loss 3.4666(3.4807) | Error 0.0000(0.0009) Steps 952(963.32) | Grad Norm 0.4123(0.9577) | Total Time 14.00(14.00)\n",
      "Iter 24640 | Time 24.2411(24.5287) | Bit/dim 3.4907(3.4800) | Xent 0.0013(0.0032) | Loss 3.4913(3.4816) | Error 0.0000(0.0009) Steps 964(963.95) | Grad Norm 0.5439(0.9577) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 114.4206, Epoch Time 1480.8007(1487.9365), Bit/dim 3.5079(best: 3.5086), Xent 2.8463, Loss 4.9311, Error 0.3446(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24650 | Time 25.2176(24.5583) | Bit/dim 3.4741(3.4800) | Xent 0.0011(0.0038) | Loss 3.4747(3.4819) | Error 0.0000(0.0010) Steps 940(962.97) | Grad Norm 0.4722(0.9319) | Total Time 14.00(14.00)\n",
      "Iter 24660 | Time 25.1169(24.5723) | Bit/dim 3.4635(3.4788) | Xent 0.0018(0.0040) | Loss 3.4644(3.4808) | Error 0.0011(0.0011) Steps 976(963.07) | Grad Norm 0.7093(1.0675) | Total Time 14.00(14.00)\n",
      "Iter 24670 | Time 23.2377(24.4809) | Bit/dim 3.4830(3.4814) | Xent 0.0042(0.0041) | Loss 3.4851(3.4834) | Error 0.0022(0.0012) Steps 952(963.10) | Grad Norm 1.3980(1.0830) | Total Time 14.00(14.00)\n",
      "Iter 24680 | Time 24.4501(24.5090) | Bit/dim 3.4825(3.4801) | Xent 0.0101(0.0046) | Loss 3.4875(3.4824) | Error 0.0022(0.0013) Steps 970(963.57) | Grad Norm 1.6468(1.1633) | Total Time 14.00(14.00)\n",
      "Iter 24690 | Time 25.0981(24.5403) | Bit/dim 3.4900(3.4823) | Xent 0.0080(0.0050) | Loss 3.4940(3.4848) | Error 0.0044(0.0014) Steps 964(961.02) | Grad Norm 2.2333(1.2061) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 114.0768, Epoch Time 1482.2739(1487.7666), Bit/dim 3.5093(best: 3.5079), Xent 2.8408, Loss 4.9297, Error 0.3439(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24700 | Time 24.2859(24.5331) | Bit/dim 3.4969(3.4805) | Xent 0.0035(0.0047) | Loss 3.4987(3.4828) | Error 0.0011(0.0013) Steps 952(960.76) | Grad Norm 1.5500(1.1814) | Total Time 14.00(14.00)\n",
      "Iter 24710 | Time 24.7639(24.5759) | Bit/dim 3.4905(3.4787) | Xent 0.0004(0.0043) | Loss 3.4907(3.4808) | Error 0.0000(0.0012) Steps 976(961.35) | Grad Norm 0.3862(1.1068) | Total Time 14.00(14.00)\n",
      "Iter 24720 | Time 24.8873(24.6591) | Bit/dim 3.4804(3.4802) | Xent 0.0004(0.0041) | Loss 3.4806(3.4822) | Error 0.0000(0.0011) Steps 946(958.30) | Grad Norm 0.4146(1.0169) | Total Time 14.00(14.00)\n",
      "Iter 24730 | Time 24.4730(24.6282) | Bit/dim 3.4810(3.4795) | Xent 0.0030(0.0037) | Loss 3.4825(3.4813) | Error 0.0011(0.0011) Steps 970(958.56) | Grad Norm 0.8264(0.9815) | Total Time 14.00(14.00)\n",
      "Iter 24740 | Time 25.4233(24.7084) | Bit/dim 3.4689(3.4795) | Xent 0.0006(0.0035) | Loss 3.4692(3.4812) | Error 0.0000(0.0010) Steps 952(958.66) | Grad Norm 0.3967(0.8605) | Total Time 14.00(14.00)\n",
      "Iter 24750 | Time 24.8348(24.6776) | Bit/dim 3.4811(3.4819) | Xent 0.0017(0.0032) | Loss 3.4819(3.4835) | Error 0.0000(0.0009) Steps 964(959.63) | Grad Norm 0.6449(0.8272) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 115.8667, Epoch Time 1493.2599(1487.9314), Bit/dim 3.5068(best: 3.5079), Xent 2.8370, Loss 4.9253, Error 0.3431(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24760 | Time 24.2231(24.5938) | Bit/dim 3.4427(3.4781) | Xent 0.0010(0.0031) | Loss 3.4432(3.4797) | Error 0.0000(0.0009) Steps 958(959.80) | Grad Norm 0.5568(0.8379) | Total Time 14.00(14.00)\n",
      "Iter 24770 | Time 24.8013(24.5561) | Bit/dim 3.4861(3.4785) | Xent 0.0027(0.0028) | Loss 3.4874(3.4799) | Error 0.0022(0.0009) Steps 958(960.17) | Grad Norm 0.7449(0.7920) | Total Time 14.00(14.00)\n",
      "Iter 24780 | Time 24.0755(24.5739) | Bit/dim 3.5055(3.4789) | Xent 0.0045(0.0026) | Loss 3.5077(3.4802) | Error 0.0022(0.0008) Steps 970(960.80) | Grad Norm 1.0910(0.7330) | Total Time 14.00(14.00)\n",
      "Iter 24790 | Time 24.8603(24.5584) | Bit/dim 3.4988(3.4799) | Xent 0.0008(0.0030) | Loss 3.4991(3.4814) | Error 0.0000(0.0008) Steps 970(962.19) | Grad Norm 0.4619(0.7691) | Total Time 14.00(14.00)\n",
      "Iter 24800 | Time 24.2969(24.5821) | Bit/dim 3.5130(3.4795) | Xent 0.0014(0.0026) | Loss 3.5137(3.4808) | Error 0.0011(0.0007) Steps 964(960.90) | Grad Norm 0.4014(0.7029) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 115.4777, Epoch Time 1483.5862(1487.8011), Bit/dim 3.5064(best: 3.5068), Xent 2.8715, Loss 4.9422, Error 0.3477(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24810 | Time 24.8245(24.6068) | Bit/dim 3.4691(3.4789) | Xent 0.0004(0.0024) | Loss 3.4693(3.4801) | Error 0.0000(0.0007) Steps 946(959.69) | Grad Norm 0.2425(0.6456) | Total Time 14.00(14.00)\n",
      "Iter 24820 | Time 23.6405(24.5502) | Bit/dim 3.4673(3.4807) | Xent 0.0114(0.0027) | Loss 3.4731(3.4820) | Error 0.0011(0.0007) Steps 970(960.38) | Grad Norm 0.7567(0.6488) | Total Time 14.00(14.00)\n",
      "Iter 24830 | Time 24.2575(24.5196) | Bit/dim 3.4726(3.4795) | Xent 0.0019(0.0030) | Loss 3.4735(3.4810) | Error 0.0000(0.0008) Steps 964(961.22) | Grad Norm 0.8706(0.7302) | Total Time 14.00(14.00)\n",
      "Iter 24840 | Time 24.9009(24.4660) | Bit/dim 3.4667(3.4782) | Xent 0.0004(0.0029) | Loss 3.4669(3.4797) | Error 0.0000(0.0007) Steps 946(961.75) | Grad Norm 0.3904(0.7539) | Total Time 14.00(14.00)\n",
      "Iter 24850 | Time 24.0788(24.4272) | Bit/dim 3.4717(3.4815) | Xent 0.0008(0.0032) | Loss 3.4721(3.4831) | Error 0.0000(0.0007) Steps 958(960.59) | Grad Norm 0.4650(0.7720) | Total Time 14.00(14.00)\n",
      "Iter 24860 | Time 24.0960(24.4024) | Bit/dim 3.4557(3.4768) | Xent 0.0016(0.0031) | Loss 3.4565(3.4784) | Error 0.0000(0.0007) Steps 958(959.47) | Grad Norm 0.8695(0.7717) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 115.7372, Epoch Time 1475.1387(1487.4212), Bit/dim 3.5074(best: 3.5064), Xent 2.8959, Loss 4.9554, Error 0.3488(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24870 | Time 24.1900(24.4145) | Bit/dim 3.5005(3.4783) | Xent 0.0130(0.0036) | Loss 3.5070(3.4801) | Error 0.0022(0.0009) Steps 964(961.01) | Grad Norm 1.4985(0.8988) | Total Time 14.00(14.00)\n",
      "Iter 24880 | Time 24.6525(24.4713) | Bit/dim 3.5087(3.4800) | Xent 0.0104(0.0036) | Loss 3.5139(3.4818) | Error 0.0022(0.0009) Steps 964(961.94) | Grad Norm 1.3581(0.9170) | Total Time 14.00(14.00)\n",
      "Iter 24890 | Time 24.9885(24.5160) | Bit/dim 3.4886(3.4779) | Xent 0.0042(0.0042) | Loss 3.4907(3.4800) | Error 0.0011(0.0011) Steps 958(961.28) | Grad Norm 0.8835(1.0009) | Total Time 14.00(14.00)\n",
      "Iter 24900 | Time 25.2799(24.5983) | Bit/dim 3.4924(3.4775) | Xent 0.0007(0.0045) | Loss 3.4927(3.4798) | Error 0.0000(0.0012) Steps 958(959.74) | Grad Norm 0.6138(1.0505) | Total Time 14.00(14.00)\n",
      "Iter 24910 | Time 24.9731(24.5744) | Bit/dim 3.4793(3.4782) | Xent 0.0044(0.0045) | Loss 3.4815(3.4804) | Error 0.0011(0.0012) Steps 958(958.49) | Grad Norm 0.7967(1.0469) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 114.9412, Epoch Time 1485.2213(1487.3552), Bit/dim 3.5102(best: 3.5064), Xent 2.8375, Loss 4.9289, Error 0.3422(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24920 | Time 24.3277(24.5382) | Bit/dim 3.4676(3.4815) | Xent 0.0087(0.0043) | Loss 3.4720(3.4836) | Error 0.0022(0.0011) Steps 952(957.82) | Grad Norm 1.5623(1.0702) | Total Time 14.00(14.00)\n",
      "Iter 24930 | Time 25.0132(24.6179) | Bit/dim 3.4896(3.4824) | Xent 0.0036(0.0043) | Loss 3.4913(3.4845) | Error 0.0011(0.0012) Steps 970(958.92) | Grad Norm 0.8551(1.0652) | Total Time 14.00(14.00)\n",
      "Iter 24940 | Time 24.6726(24.6542) | Bit/dim 3.4833(3.4817) | Xent 0.0017(0.0040) | Loss 3.4842(3.4837) | Error 0.0000(0.0011) Steps 940(960.34) | Grad Norm 0.9568(1.0522) | Total Time 14.00(14.00)\n",
      "Iter 24950 | Time 24.2763(24.5948) | Bit/dim 3.4674(3.4809) | Xent 0.0007(0.0040) | Loss 3.4677(3.4829) | Error 0.0000(0.0011) Steps 982(961.74) | Grad Norm 0.4981(1.0155) | Total Time 14.00(14.00)\n",
      "Iter 24960 | Time 24.0184(24.5306) | Bit/dim 3.4583(3.4797) | Xent 0.0042(0.0044) | Loss 3.4604(3.4819) | Error 0.0011(0.0011) Steps 958(962.30) | Grad Norm 0.7778(0.9877) | Total Time 14.00(14.00)\n",
      "Iter 24970 | Time 24.2415(24.5386) | Bit/dim 3.4552(3.4767) | Xent 0.0050(0.0040) | Loss 3.4577(3.4787) | Error 0.0011(0.0010) Steps 964(962.43) | Grad Norm 0.6871(0.9463) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 116.6011, Epoch Time 1486.2456(1487.3219), Bit/dim 3.5082(best: 3.5064), Xent 2.8256, Loss 4.9210, Error 0.3424(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24980 | Time 25.8370(24.6030) | Bit/dim 3.4871(3.4768) | Xent 0.0013(0.0038) | Loss 3.4877(3.4787) | Error 0.0000(0.0010) Steps 952(961.90) | Grad Norm 0.4700(0.9216) | Total Time 14.00(14.00)\n",
      "Iter 24990 | Time 24.8867(24.6320) | Bit/dim 3.4812(3.4747) | Xent 0.0061(0.0036) | Loss 3.4842(3.4765) | Error 0.0022(0.0009) Steps 952(961.29) | Grad Norm 2.3841(0.9505) | Total Time 14.00(14.00)\n",
      "Iter 25000 | Time 24.8913(24.6170) | Bit/dim 3.4997(3.4782) | Xent 0.0053(0.0038) | Loss 3.5023(3.4801) | Error 0.0011(0.0010) Steps 976(962.66) | Grad Norm 1.2674(1.0690) | Total Time 14.00(14.00)\n",
      "Iter 25010 | Time 24.1694(24.6421) | Bit/dim 3.4811(3.4795) | Xent 0.0035(0.0042) | Loss 3.4829(3.4816) | Error 0.0022(0.0011) Steps 946(961.37) | Grad Norm 1.0676(1.1127) | Total Time 14.00(14.00)\n",
      "Iter 25020 | Time 25.5661(24.7064) | Bit/dim 3.4559(3.4811) | Xent 0.0063(0.0046) | Loss 3.4591(3.4834) | Error 0.0022(0.0013) Steps 952(960.16) | Grad Norm 1.2405(1.1638) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 115.2023, Epoch Time 1492.8989(1487.4892), Bit/dim 3.5095(best: 3.5064), Xent 2.7980, Loss 4.9085, Error 0.3377(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25030 | Time 24.5598(24.6967) | Bit/dim 3.4814(3.4800) | Xent 0.0045(0.0043) | Loss 3.4836(3.4821) | Error 0.0022(0.0012) Steps 958(961.96) | Grad Norm 1.6925(1.1571) | Total Time 14.00(14.00)\n",
      "Iter 25040 | Time 24.7191(24.6770) | Bit/dim 3.4683(3.4796) | Xent 0.0014(0.0039) | Loss 3.4690(3.4816) | Error 0.0000(0.0011) Steps 958(961.17) | Grad Norm 0.6186(1.0659) | Total Time 14.00(14.00)\n",
      "Iter 25050 | Time 24.1694(24.5425) | Bit/dim 3.4845(3.4809) | Xent 0.0008(0.0036) | Loss 3.4849(3.4827) | Error 0.0000(0.0009) Steps 976(961.21) | Grad Norm 0.4357(0.9758) | Total Time 14.00(14.00)\n",
      "Iter 25060 | Time 25.1531(24.6155) | Bit/dim 3.4949(3.4800) | Xent 0.0005(0.0042) | Loss 3.4952(3.4821) | Error 0.0000(0.0011) Steps 952(962.79) | Grad Norm 0.9121(1.1040) | Total Time 14.00(14.00)\n",
      "Iter 25070 | Time 25.0325(24.6672) | Bit/dim 3.4839(3.4798) | Xent 0.0030(0.0050) | Loss 3.4854(3.4823) | Error 0.0011(0.0013) Steps 958(963.61) | Grad Norm 1.3065(1.1959) | Total Time 14.00(14.00)\n",
      "Iter 25080 | Time 24.2949(24.6524) | Bit/dim 3.4895(3.4799) | Xent 0.0108(0.0056) | Loss 3.4949(3.4827) | Error 0.0022(0.0015) Steps 970(962.31) | Grad Norm 1.0822(1.2500) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 114.9845, Epoch Time 1487.0530(1487.4761), Bit/dim 3.5109(best: 3.5064), Xent 2.8210, Loss 4.9214, Error 0.3479(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25090 | Time 24.5429(24.6026) | Bit/dim 3.4711(3.4777) | Xent 0.0037(0.0052) | Loss 3.4730(3.4803) | Error 0.0011(0.0014) Steps 964(960.17) | Grad Norm 0.8346(1.1848) | Total Time 14.00(14.00)\n",
      "Iter 25100 | Time 24.4448(24.5795) | Bit/dim 3.4598(3.4781) | Xent 0.0099(0.0048) | Loss 3.4647(3.4805) | Error 0.0022(0.0013) Steps 946(959.45) | Grad Norm 0.9340(1.0828) | Total Time 14.00(14.00)\n",
      "Iter 25110 | Time 25.6537(24.6003) | Bit/dim 3.5010(3.4789) | Xent 0.0074(0.0044) | Loss 3.5047(3.4811) | Error 0.0022(0.0012) Steps 982(960.63) | Grad Norm 1.8031(1.0929) | Total Time 14.00(14.00)\n",
      "Iter 25120 | Time 25.1410(24.6369) | Bit/dim 3.4743(3.4791) | Xent 0.0022(0.0038) | Loss 3.4753(3.4810) | Error 0.0011(0.0011) Steps 976(960.74) | Grad Norm 0.5990(1.0597) | Total Time 14.00(14.00)\n",
      "Iter 25130 | Time 25.3612(24.7063) | Bit/dim 3.4884(3.4795) | Xent 0.0009(0.0034) | Loss 3.4889(3.4812) | Error 0.0000(0.0010) Steps 958(960.70) | Grad Norm 0.4900(1.0222) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 116.5475, Epoch Time 1492.4851(1487.6264), Bit/dim 3.5084(best: 3.5064), Xent 2.7938, Loss 4.9053, Error 0.3406(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25140 | Time 24.5665(24.7209) | Bit/dim 3.4552(3.4803) | Xent 0.0016(0.0045) | Loss 3.4560(3.4826) | Error 0.0011(0.0012) Steps 958(959.19) | Grad Norm 0.9080(1.0390) | Total Time 14.00(14.00)\n",
      "Iter 25150 | Time 24.6002(24.7394) | Bit/dim 3.4582(3.4800) | Xent 0.0008(0.0044) | Loss 3.4586(3.4822) | Error 0.0000(0.0011) Steps 964(959.61) | Grad Norm 0.5401(0.9959) | Total Time 14.00(14.00)\n",
      "Iter 25160 | Time 24.8699(24.7501) | Bit/dim 3.4995(3.4809) | Xent 0.0039(0.0044) | Loss 3.5015(3.4830) | Error 0.0011(0.0012) Steps 958(959.38) | Grad Norm 0.9781(1.0632) | Total Time 14.00(14.00)\n",
      "Iter 25170 | Time 24.9590(24.7522) | Bit/dim 3.4738(3.4785) | Xent 0.0039(0.0040) | Loss 3.4758(3.4804) | Error 0.0011(0.0010) Steps 946(958.77) | Grad Norm 1.6838(1.0457) | Total Time 14.00(14.00)\n",
      "Iter 25180 | Time 24.3494(24.6861) | Bit/dim 3.4841(3.4803) | Xent 0.0003(0.0033) | Loss 3.4842(3.4820) | Error 0.0000(0.0008) Steps 964(959.53) | Grad Norm 0.3350(0.9404) | Total Time 14.00(14.00)\n",
      "Iter 25190 | Time 24.9485(24.6721) | Bit/dim 3.4861(3.4804) | Xent 0.0020(0.0032) | Loss 3.4871(3.4820) | Error 0.0011(0.0008) Steps 964(960.49) | Grad Norm 0.7121(0.9586) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 115.7423, Epoch Time 1490.6009(1487.7156), Bit/dim 3.5076(best: 3.5064), Xent 2.8165, Loss 4.9159, Error 0.3432(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25200 | Time 24.4169(24.6401) | Bit/dim 3.4726(3.4801) | Xent 0.0003(0.0030) | Loss 3.4728(3.4816) | Error 0.0000(0.0007) Steps 970(961.99) | Grad Norm 0.4522(0.8706) | Total Time 14.00(14.00)\n",
      "Iter 25210 | Time 25.2759(24.6470) | Bit/dim 3.4664(3.4797) | Xent 0.0003(0.0027) | Loss 3.4665(3.4810) | Error 0.0000(0.0007) Steps 958(961.56) | Grad Norm 0.3278(0.8309) | Total Time 14.00(14.00)\n",
      "Iter 25220 | Time 24.6312(24.7233) | Bit/dim 3.4665(3.4792) | Xent 0.0004(0.0026) | Loss 3.4667(3.4805) | Error 0.0000(0.0007) Steps 964(961.50) | Grad Norm 0.3020(0.7340) | Total Time 14.00(14.00)\n",
      "Iter 25230 | Time 24.6970(24.6716) | Bit/dim 3.4353(3.4764) | Xent 0.0013(0.0025) | Loss 3.4359(3.4777) | Error 0.0000(0.0006) Steps 946(961.29) | Grad Norm 1.1293(0.7156) | Total Time 14.00(14.00)\n",
      "Iter 25240 | Time 24.1555(24.6302) | Bit/dim 3.4830(3.4770) | Xent 0.0048(0.0030) | Loss 3.4854(3.4785) | Error 0.0022(0.0007) Steps 970(961.16) | Grad Norm 2.1710(0.8612) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 115.8051, Epoch Time 1487.1425(1487.6984), Bit/dim 3.5082(best: 3.5064), Xent 2.8443, Loss 4.9304, Error 0.3441(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25250 | Time 25.2048(24.6116) | Bit/dim 3.4880(3.4784) | Xent 0.0094(0.0029) | Loss 3.4927(3.4799) | Error 0.0022(0.0007) Steps 970(961.79) | Grad Norm 1.2162(0.8792) | Total Time 14.00(14.00)\n",
      "Iter 25260 | Time 24.2471(24.6231) | Bit/dim 3.4720(3.4807) | Xent 0.0113(0.0032) | Loss 3.4776(3.4823) | Error 0.0022(0.0009) Steps 958(960.45) | Grad Norm 1.4057(0.8802) | Total Time 14.00(14.00)\n",
      "Iter 25270 | Time 24.7536(24.6730) | Bit/dim 3.4664(3.4801) | Xent 0.0007(0.0031) | Loss 3.4668(3.4817) | Error 0.0000(0.0008) Steps 964(960.41) | Grad Norm 0.2578(0.8306) | Total Time 14.00(14.00)\n",
      "Iter 25280 | Time 25.0812(24.6225) | Bit/dim 3.5141(3.4805) | Xent 0.0055(0.0031) | Loss 3.5168(3.4821) | Error 0.0011(0.0008) Steps 940(958.98) | Grad Norm 1.0995(0.8511) | Total Time 14.00(14.00)\n",
      "Iter 25290 | Time 25.3160(24.6125) | Bit/dim 3.4529(3.4809) | Xent 0.0041(0.0040) | Loss 3.4549(3.4829) | Error 0.0011(0.0011) Steps 976(959.80) | Grad Norm 0.8634(0.9089) | Total Time 14.00(14.00)\n",
      "Iter 25300 | Time 25.5265(24.6495) | Bit/dim 3.4801(3.4773) | Xent 0.0045(0.0036) | Loss 3.4823(3.4791) | Error 0.0011(0.0010) Steps 940(959.96) | Grad Norm 1.4776(0.9049) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 115.9346, Epoch Time 1490.4205(1487.7801), Bit/dim 3.5080(best: 3.5064), Xent 2.8695, Loss 4.9427, Error 0.3461(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25310 | Time 24.4656(24.6791) | Bit/dim 3.4726(3.4771) | Xent 0.0118(0.0039) | Loss 3.4785(3.4791) | Error 0.0022(0.0009) Steps 976(962.03) | Grad Norm 1.2149(0.8722) | Total Time 14.00(14.00)\n",
      "Iter 25320 | Time 24.9968(24.7875) | Bit/dim 3.4534(3.4757) | Xent 0.0116(0.0040) | Loss 3.4592(3.4777) | Error 0.0022(0.0010) Steps 976(962.87) | Grad Norm 1.9298(0.8670) | Total Time 14.00(14.00)\n",
      "Iter 25330 | Time 24.3271(24.7853) | Bit/dim 3.4640(3.4776) | Xent 0.0011(0.0035) | Loss 3.4646(3.4793) | Error 0.0000(0.0009) Steps 958(962.25) | Grad Norm 0.6971(0.9015) | Total Time 14.00(14.00)\n",
      "Iter 25340 | Time 24.5696(24.7784) | Bit/dim 3.4812(3.4777) | Xent 0.0027(0.0033) | Loss 3.4826(3.4793) | Error 0.0011(0.0009) Steps 958(961.18) | Grad Norm 0.9616(0.8784) | Total Time 14.00(14.00)\n",
      "Iter 25350 | Time 24.8396(24.7717) | Bit/dim 3.4934(3.4795) | Xent 0.0030(0.0033) | Loss 3.4949(3.4812) | Error 0.0011(0.0009) Steps 964(960.39) | Grad Norm 0.9658(0.9297) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 115.5031, Epoch Time 1498.3238(1488.0964), Bit/dim 3.5066(best: 3.5064), Xent 2.9144, Loss 4.9638, Error 0.3480(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25360 | Time 24.8001(24.7036) | Bit/dim 3.4932(3.4800) | Xent 0.0005(0.0027) | Loss 3.4934(3.4814) | Error 0.0000(0.0007) Steps 976(960.17) | Grad Norm 0.3877(0.8488) | Total Time 14.00(14.00)\n",
      "Iter 25370 | Time 24.5582(24.6157) | Bit/dim 3.4885(3.4814) | Xent 0.0036(0.0028) | Loss 3.4903(3.4828) | Error 0.0033(0.0008) Steps 970(959.59) | Grad Norm 1.2604(0.8821) | Total Time 14.00(14.00)\n",
      "Iter 25380 | Time 24.4091(24.6086) | Bit/dim 3.4567(3.4770) | Xent 0.0020(0.0026) | Loss 3.4577(3.4783) | Error 0.0011(0.0009) Steps 952(959.97) | Grad Norm 0.5887(0.9227) | Total Time 14.00(14.00)\n",
      "Iter 25390 | Time 24.6825(24.5526) | Bit/dim 3.4898(3.4754) | Xent 0.0025(0.0032) | Loss 3.4910(3.4770) | Error 0.0011(0.0010) Steps 964(959.75) | Grad Norm 0.7841(0.9078) | Total Time 14.00(14.00)\n",
      "Iter 25400 | Time 23.8361(24.4710) | Bit/dim 3.4748(3.4777) | Xent 0.0007(0.0032) | Loss 3.4752(3.4793) | Error 0.0000(0.0010) Steps 964(960.24) | Grad Norm 0.7468(0.9526) | Total Time 14.00(14.00)\n",
      "Iter 25410 | Time 25.2066(24.5223) | Bit/dim 3.5057(3.4794) | Xent 0.0082(0.0036) | Loss 3.5098(3.4812) | Error 0.0022(0.0011) Steps 946(958.88) | Grad Norm 1.0697(1.0236) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 115.3923, Epoch Time 1478.1587(1487.7983), Bit/dim 3.5091(best: 3.5064), Xent 2.8755, Loss 4.9468, Error 0.3466(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25420 | Time 23.8973(24.5087) | Bit/dim 3.4523(3.4790) | Xent 0.0009(0.0034) | Loss 3.4527(3.4807) | Error 0.0000(0.0009) Steps 958(959.01) | Grad Norm 0.4533(0.9841) | Total Time 14.00(14.00)\n",
      "Iter 25430 | Time 24.8433(24.5272) | Bit/dim 3.4983(3.4798) | Xent 0.0007(0.0028) | Loss 3.4987(3.4812) | Error 0.0000(0.0008) Steps 946(959.94) | Grad Norm 0.8561(0.9654) | Total Time 14.00(14.00)\n",
      "Iter 25440 | Time 24.8693(24.5219) | Bit/dim 3.4672(3.4791) | Xent 0.0008(0.0024) | Loss 3.4676(3.4804) | Error 0.0000(0.0007) Steps 952(960.45) | Grad Norm 0.5563(0.8974) | Total Time 14.00(14.00)\n",
      "Iter 25450 | Time 24.1147(24.5580) | Bit/dim 3.5046(3.4802) | Xent 0.0017(0.0026) | Loss 3.5055(3.4815) | Error 0.0011(0.0007) Steps 964(962.03) | Grad Norm 1.1356(0.9462) | Total Time 14.00(14.00)\n",
      "Iter 25460 | Time 25.1842(24.5561) | Bit/dim 3.4672(3.4790) | Xent 0.0040(0.0029) | Loss 3.4692(3.4804) | Error 0.0022(0.0008) Steps 964(962.94) | Grad Norm 1.3968(0.9648) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 115.4165, Epoch Time 1482.9235(1487.6520), Bit/dim 3.5070(best: 3.5064), Xent 2.8511, Loss 4.9325, Error 0.3394(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25470 | Time 25.2815(24.5305) | Bit/dim 3.4833(3.4787) | Xent 0.0009(0.0028) | Loss 3.4837(3.4802) | Error 0.0000(0.0008) Steps 976(962.50) | Grad Norm 0.6081(0.9540) | Total Time 14.00(14.00)\n",
      "Iter 25480 | Time 24.1560(24.5397) | Bit/dim 3.4742(3.4785) | Xent 0.0031(0.0038) | Loss 3.4757(3.4804) | Error 0.0011(0.0009) Steps 964(962.30) | Grad Norm 0.9234(1.0259) | Total Time 14.00(14.00)\n",
      "Iter 25490 | Time 24.7896(24.4869) | Bit/dim 3.5039(3.4824) | Xent 0.0056(0.0049) | Loss 3.5067(3.4848) | Error 0.0022(0.0012) Steps 958(961.05) | Grad Norm 1.7760(1.2151) | Total Time 14.00(14.00)\n",
      "Iter 25500 | Time 24.7783(24.5224) | Bit/dim 3.4755(3.4810) | Xent 0.0007(0.0044) | Loss 3.4759(3.4832) | Error 0.0000(0.0011) Steps 964(960.40) | Grad Norm 0.8027(1.2630) | Total Time 14.00(14.00)\n",
      "Iter 25510 | Time 25.0326(24.5397) | Bit/dim 3.4765(3.4816) | Xent 0.0148(0.0044) | Loss 3.4838(3.4838) | Error 0.0011(0.0012) Steps 970(959.41) | Grad Norm 0.9281(1.2655) | Total Time 14.00(14.00)\n",
      "Iter 25520 | Time 24.6470(24.6033) | Bit/dim 3.4700(3.4786) | Xent 0.0066(0.0046) | Loss 3.4733(3.4808) | Error 0.0022(0.0012) Steps 964(960.26) | Grad Norm 1.4385(1.2767) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 115.2645, Epoch Time 1485.2838(1487.5810), Bit/dim 3.5084(best: 3.5064), Xent 2.8426, Loss 4.9297, Error 0.3410(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25530 | Time 24.6914(24.6057) | Bit/dim 3.4680(3.4781) | Xent 0.0018(0.0041) | Loss 3.4689(3.4801) | Error 0.0000(0.0011) Steps 964(957.94) | Grad Norm 1.0858(1.1811) | Total Time 14.00(14.00)\n",
      "Iter 25540 | Time 24.4092(24.6058) | Bit/dim 3.4847(3.4759) | Xent 0.0021(0.0034) | Loss 3.4858(3.4776) | Error 0.0011(0.0010) Steps 952(958.92) | Grad Norm 0.8895(1.0241) | Total Time 14.00(14.00)\n",
      "Iter 25550 | Time 24.6629(24.6698) | Bit/dim 3.4963(3.4758) | Xent 0.0025(0.0031) | Loss 3.4976(3.4774) | Error 0.0011(0.0009) Steps 946(957.33) | Grad Norm 0.7424(0.9108) | Total Time 14.00(14.00)\n",
      "Iter 25560 | Time 24.3567(24.6956) | Bit/dim 3.4781(3.4777) | Xent 0.0006(0.0026) | Loss 3.4784(3.4790) | Error 0.0000(0.0007) Steps 952(957.09) | Grad Norm 0.2966(0.8039) | Total Time 14.00(14.00)\n",
      "Iter 25570 | Time 23.8212(24.7129) | Bit/dim 3.5295(3.4776) | Xent 0.0006(0.0023) | Loss 3.5298(3.4788) | Error 0.0000(0.0006) Steps 940(956.67) | Grad Norm 0.3440(0.7490) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 115.0238, Epoch Time 1491.4583(1487.6973), Bit/dim 3.5056(best: 3.5064), Xent 2.9032, Loss 4.9572, Error 0.3455(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25580 | Time 24.2952(24.5895) | Bit/dim 3.4897(3.4794) | Xent 0.0056(0.0025) | Loss 3.4924(3.4806) | Error 0.0033(0.0007) Steps 952(956.26) | Grad Norm 1.4463(0.7553) | Total Time 14.00(14.00)\n",
      "Iter 25590 | Time 24.8936(24.5186) | Bit/dim 3.4730(3.4794) | Xent 0.0045(0.0028) | Loss 3.4752(3.4808) | Error 0.0011(0.0008) Steps 970(956.15) | Grad Norm 1.2951(0.7884) | Total Time 14.00(14.00)\n",
      "Iter 25600 | Time 23.9525(24.4777) | Bit/dim 3.4919(3.4786) | Xent 0.0004(0.0031) | Loss 3.4921(3.4802) | Error 0.0000(0.0008) Steps 952(956.91) | Grad Norm 0.3558(0.7908) | Total Time 14.00(14.00)\n",
      "Iter 25610 | Time 23.9021(24.5206) | Bit/dim 3.4530(3.4779) | Xent 0.0011(0.0029) | Loss 3.4536(3.4793) | Error 0.0000(0.0008) Steps 958(957.65) | Grad Norm 0.5226(0.7854) | Total Time 14.00(14.00)\n",
      "Iter 25620 | Time 25.2701(24.5715) | Bit/dim 3.4812(3.4766) | Xent 0.0056(0.0029) | Loss 3.4840(3.4780) | Error 0.0022(0.0007) Steps 970(958.75) | Grad Norm 3.0922(0.8704) | Total Time 14.00(14.00)\n",
      "Iter 25630 | Time 24.4833(24.5478) | Bit/dim 3.4723(3.4767) | Xent 0.0015(0.0031) | Loss 3.4731(3.4782) | Error 0.0000(0.0008) Steps 946(958.17) | Grad Norm 1.7553(1.0520) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 117.0625, Epoch Time 1480.9643(1487.4953), Bit/dim 3.5090(best: 3.5056), Xent 2.8966, Loss 4.9573, Error 0.3467(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25640 | Time 24.9463(24.4982) | Bit/dim 3.4762(3.4746) | Xent 0.0012(0.0030) | Loss 3.4768(3.4761) | Error 0.0000(0.0009) Steps 946(959.13) | Grad Norm 0.7090(1.0852) | Total Time 14.00(14.00)\n",
      "Iter 25650 | Time 24.2771(24.4926) | Bit/dim 3.4756(3.4745) | Xent 0.0063(0.0030) | Loss 3.4787(3.4760) | Error 0.0011(0.0008) Steps 958(959.68) | Grad Norm 1.0577(1.0665) | Total Time 14.00(14.00)\n",
      "Iter 25660 | Time 24.6666(24.5660) | Bit/dim 3.5125(3.4783) | Xent 0.0022(0.0036) | Loss 3.5136(3.4801) | Error 0.0011(0.0009) Steps 970(960.43) | Grad Norm 0.9294(1.0746) | Total Time 14.00(14.00)\n",
      "Iter 25670 | Time 24.9874(24.6362) | Bit/dim 3.4786(3.4794) | Xent 0.0131(0.0036) | Loss 3.4852(3.4812) | Error 0.0022(0.0009) Steps 952(961.22) | Grad Norm 1.0672(1.0378) | Total Time 14.00(14.00)\n",
      "Iter 25680 | Time 23.9493(24.5534) | Bit/dim 3.4596(3.4779) | Xent 0.0005(0.0034) | Loss 3.4599(3.4796) | Error 0.0000(0.0009) Steps 952(961.98) | Grad Norm 0.4687(1.0306) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 116.0990, Epoch Time 1485.6387(1487.4396), Bit/dim 3.5069(best: 3.5056), Xent 2.9081, Loss 4.9610, Error 0.3488(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25690 | Time 24.5880(24.5651) | Bit/dim 3.4624(3.4761) | Xent 0.0013(0.0030) | Loss 3.4630(3.4776) | Error 0.0000(0.0007) Steps 970(962.40) | Grad Norm 0.5008(0.9071) | Total Time 14.00(14.00)\n",
      "Iter 25700 | Time 24.1045(24.5450) | Bit/dim 3.4497(3.4772) | Xent 0.0067(0.0026) | Loss 3.4530(3.4785) | Error 0.0011(0.0006) Steps 952(961.07) | Grad Norm 0.6226(0.7642) | Total Time 14.00(14.00)\n",
      "Iter 25710 | Time 24.3994(24.5733) | Bit/dim 3.4868(3.4770) | Xent 0.0028(0.0024) | Loss 3.4882(3.4783) | Error 0.0011(0.0006) Steps 952(961.41) | Grad Norm 1.0851(0.8022) | Total Time 14.00(14.00)\n",
      "Iter 25720 | Time 24.9370(24.6097) | Bit/dim 3.4473(3.4763) | Xent 0.0007(0.0030) | Loss 3.4476(3.4778) | Error 0.0000(0.0008) Steps 952(960.84) | Grad Norm 0.6081(0.8673) | Total Time 14.00(14.00)\n",
      "Iter 25730 | Time 24.3327(24.6438) | Bit/dim 3.4794(3.4775) | Xent 0.0008(0.0032) | Loss 3.4797(3.4791) | Error 0.0000(0.0009) Steps 964(959.53) | Grad Norm 0.4966(0.8937) | Total Time 14.00(14.00)\n",
      "Iter 25740 | Time 24.3000(24.5816) | Bit/dim 3.4586(3.4780) | Xent 0.0063(0.0029) | Loss 3.4617(3.4794) | Error 0.0022(0.0008) Steps 964(959.23) | Grad Norm 1.7627(0.8895) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 116.8012, Epoch Time 1487.3493(1487.4369), Bit/dim 3.5070(best: 3.5056), Xent 2.9041, Loss 4.9590, Error 0.3466(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25750 | Time 25.4269(24.5078) | Bit/dim 3.4672(3.4766) | Xent 0.0004(0.0030) | Loss 3.4674(3.4781) | Error 0.0000(0.0008) Steps 970(959.65) | Grad Norm 0.3790(0.8586) | Total Time 14.00(14.00)\n",
      "Iter 25760 | Time 24.1753(24.5183) | Bit/dim 3.4654(3.4779) | Xent 0.0003(0.0031) | Loss 3.4656(3.4794) | Error 0.0000(0.0009) Steps 970(959.86) | Grad Norm 0.3999(0.8260) | Total Time 14.00(14.00)\n",
      "Iter 25770 | Time 23.9684(24.4851) | Bit/dim 3.4949(3.4811) | Xent 0.0062(0.0030) | Loss 3.4981(3.4826) | Error 0.0033(0.0009) Steps 964(961.25) | Grad Norm 2.3852(0.8536) | Total Time 14.00(14.00)\n",
      "Iter 25780 | Time 24.2288(24.5330) | Bit/dim 3.4660(3.4782) | Xent 0.0086(0.0036) | Loss 3.4704(3.4800) | Error 0.0011(0.0011) Steps 958(961.39) | Grad Norm 0.7164(0.9100) | Total Time 14.00(14.00)\n",
      "Iter 25790 | Time 24.4541(24.5975) | Bit/dim 3.4660(3.4781) | Xent 0.0005(0.0032) | Loss 3.4662(3.4797) | Error 0.0000(0.0009) Steps 964(961.80) | Grad Norm 0.3923(0.8630) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 116.5055, Epoch Time 1485.3641(1487.3747), Bit/dim 3.5067(best: 3.5056), Xent 2.8833, Loss 4.9484, Error 0.3462(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25800 | Time 24.9489(24.6335) | Bit/dim 3.4951(3.4769) | Xent 0.0078(0.0036) | Loss 3.4990(3.4787) | Error 0.0022(0.0011) Steps 952(960.75) | Grad Norm 2.1054(1.0157) | Total Time 14.00(14.00)\n",
      "Iter 25810 | Time 24.5559(24.5793) | Bit/dim 3.4703(3.4779) | Xent 0.0022(0.0036) | Loss 3.4714(3.4797) | Error 0.0011(0.0010) Steps 964(959.70) | Grad Norm 1.1193(0.9563) | Total Time 14.00(14.00)\n",
      "Iter 25820 | Time 24.5439(24.5761) | Bit/dim 3.4779(3.4790) | Xent 0.0020(0.0032) | Loss 3.4789(3.4806) | Error 0.0011(0.0009) Steps 946(959.60) | Grad Norm 0.5850(0.8745) | Total Time 14.00(14.00)\n",
      "Iter 25830 | Time 24.6841(24.5750) | Bit/dim 3.4879(3.4787) | Xent 0.0009(0.0030) | Loss 3.4884(3.4802) | Error 0.0000(0.0008) Steps 952(960.95) | Grad Norm 0.3474(0.8127) | Total Time 14.00(14.00)\n",
      "Iter 25840 | Time 23.7350(24.5386) | Bit/dim 3.4556(3.4767) | Xent 0.0003(0.0029) | Loss 3.4558(3.4781) | Error 0.0000(0.0008) Steps 958(961.30) | Grad Norm 0.4456(0.7979) | Total Time 14.00(14.00)\n",
      "Iter 25850 | Time 25.2382(24.5831) | Bit/dim 3.4519(3.4756) | Xent 0.0015(0.0027) | Loss 3.4527(3.4769) | Error 0.0000(0.0008) Steps 976(961.95) | Grad Norm 0.5174(0.7743) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 117.1371, Epoch Time 1486.2641(1487.3414), Bit/dim 3.5067(best: 3.5056), Xent 2.9340, Loss 4.9737, Error 0.3500(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25860 | Time 24.8354(24.6049) | Bit/dim 3.4364(3.4746) | Xent 0.0093(0.0031) | Loss 3.4410(3.4762) | Error 0.0022(0.0008) Steps 970(961.96) | Grad Norm 1.0269(0.7401) | Total Time 14.00(14.00)\n",
      "Iter 25870 | Time 24.5165(24.6056) | Bit/dim 3.4806(3.4724) | Xent 0.0012(0.0037) | Loss 3.4812(3.4742) | Error 0.0000(0.0010) Steps 946(962.08) | Grad Norm 0.5443(0.8065) | Total Time 14.00(14.00)\n",
      "Iter 25880 | Time 24.5418(24.5549) | Bit/dim 3.5062(3.4743) | Xent 0.0011(0.0034) | Loss 3.5068(3.4760) | Error 0.0000(0.0009) Steps 970(962.60) | Grad Norm 0.4435(0.8108) | Total Time 14.00(14.00)\n",
      "Iter 25890 | Time 24.6883(24.6203) | Bit/dim 3.4624(3.4742) | Xent 0.0012(0.0033) | Loss 3.4630(3.4759) | Error 0.0000(0.0009) Steps 952(961.32) | Grad Norm 0.3989(0.8985) | Total Time 14.00(14.00)\n",
      "Iter 25900 | Time 25.0819(24.6814) | Bit/dim 3.4926(3.4761) | Xent 0.0091(0.0037) | Loss 3.4972(3.4779) | Error 0.0011(0.0009) Steps 964(963.00) | Grad Norm 0.6888(0.9445) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 115.4721, Epoch Time 1490.0118(1487.4215), Bit/dim 3.5061(best: 3.5056), Xent 2.8700, Loss 4.9411, Error 0.3467(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25910 | Time 24.8220(24.6559) | Bit/dim 3.4653(3.4778) | Xent 0.0012(0.0036) | Loss 3.4659(3.4796) | Error 0.0000(0.0008) Steps 946(963.40) | Grad Norm 0.4593(0.8898) | Total Time 14.00(14.00)\n",
      "Iter 25920 | Time 24.4413(24.6038) | Bit/dim 3.5195(3.4807) | Xent 0.0008(0.0032) | Loss 3.5199(3.4823) | Error 0.0000(0.0008) Steps 952(961.05) | Grad Norm 0.6317(0.9012) | Total Time 14.00(14.00)\n",
      "Iter 25930 | Time 25.2216(24.6465) | Bit/dim 3.4802(3.4776) | Xent 0.0025(0.0031) | Loss 3.4815(3.4791) | Error 0.0011(0.0008) Steps 976(960.20) | Grad Norm 1.0222(0.8964) | Total Time 14.00(14.00)\n",
      "Iter 25940 | Time 25.6396(24.6731) | Bit/dim 3.4308(3.4760) | Xent 0.0017(0.0028) | Loss 3.4316(3.4774) | Error 0.0011(0.0008) Steps 946(958.86) | Grad Norm 1.2615(0.8882) | Total Time 14.00(14.00)\n",
      "Iter 25950 | Time 24.8437(24.6905) | Bit/dim 3.5091(3.4771) | Xent 0.0006(0.0026) | Loss 3.5094(3.4784) | Error 0.0000(0.0007) Steps 982(960.12) | Grad Norm 0.2812(0.8064) | Total Time 14.00(14.00)\n",
      "Iter 25960 | Time 24.8325(24.6892) | Bit/dim 3.4734(3.4775) | Xent 0.0036(0.0025) | Loss 3.4752(3.4787) | Error 0.0011(0.0007) Steps 952(960.74) | Grad Norm 1.5789(0.7773) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 115.4234, Epoch Time 1490.8684(1487.5249), Bit/dim 3.5047(best: 3.5056), Xent 2.8893, Loss 4.9494, Error 0.3456(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25970 | Time 24.9748(24.6456) | Bit/dim 3.4977(3.4769) | Xent 0.0033(0.0024) | Loss 3.4993(3.4781) | Error 0.0011(0.0007) Steps 958(961.66) | Grad Norm 1.6361(0.7574) | Total Time 14.00(14.00)\n",
      "Iter 25980 | Time 24.4849(24.5582) | Bit/dim 3.4532(3.4745) | Xent 0.0015(0.0027) | Loss 3.4540(3.4759) | Error 0.0011(0.0007) Steps 952(961.98) | Grad Norm 1.1045(0.7948) | Total Time 14.00(14.00)\n",
      "Iter 25990 | Time 24.7189(24.5090) | Bit/dim 3.4949(3.4784) | Xent 0.0060(0.0033) | Loss 3.4979(3.4801) | Error 0.0022(0.0009) Steps 952(962.00) | Grad Norm 1.2400(0.9662) | Total Time 14.00(14.00)\n",
      "Iter 26000 | Time 25.0590(24.5085) | Bit/dim 3.5090(3.4784) | Xent 0.0181(0.0036) | Loss 3.5180(3.4803) | Error 0.0022(0.0009) Steps 946(961.90) | Grad Norm 1.3253(1.0333) | Total Time 14.00(14.00)\n",
      "Iter 26010 | Time 24.2254(24.5491) | Bit/dim 3.4344(3.4762) | Xent 0.0012(0.0031) | Loss 3.4350(3.4778) | Error 0.0000(0.0008) Steps 964(963.23) | Grad Norm 0.7977(0.9631) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 115.8938, Epoch Time 1480.7053(1487.3203), Bit/dim 3.5054(best: 3.5047), Xent 2.8978, Loss 4.9543, Error 0.3468(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26020 | Time 24.5053(24.5489) | Bit/dim 3.4486(3.4790) | Xent 0.0006(0.0026) | Loss 3.4489(3.4803) | Error 0.0000(0.0007) Steps 970(963.39) | Grad Norm 0.6100(0.9130) | Total Time 14.00(14.00)\n",
      "Iter 26030 | Time 24.8441(24.5607) | Bit/dim 3.5141(3.4771) | Xent 0.0187(0.0039) | Loss 3.5234(3.4790) | Error 0.0022(0.0009) Steps 976(963.15) | Grad Norm 2.5941(0.9753) | Total Time 14.00(14.00)\n",
      "Iter 26040 | Time 25.2053(24.6122) | Bit/dim 3.4803(3.4801) | Xent 0.0097(0.0044) | Loss 3.4852(3.4823) | Error 0.0011(0.0009) Steps 946(961.87) | Grad Norm 0.9904(1.0048) | Total Time 14.00(14.00)\n",
      "Iter 26050 | Time 24.8532(24.7012) | Bit/dim 3.4910(3.4791) | Xent 0.0004(0.0045) | Loss 3.4912(3.4813) | Error 0.0000(0.0010) Steps 964(963.57) | Grad Norm 0.6324(1.0861) | Total Time 14.00(14.00)\n",
      "Iter 26060 | Time 24.3799(24.6429) | Bit/dim 3.4699(3.4783) | Xent 0.0011(0.0046) | Loss 3.4704(3.4806) | Error 0.0000(0.0010) Steps 952(962.76) | Grad Norm 0.8225(1.1759) | Total Time 14.00(14.00)\n",
      "Iter 26070 | Time 24.9572(24.6728) | Bit/dim 3.4857(3.4785) | Xent 0.0090(0.0056) | Loss 3.4903(3.4813) | Error 0.0033(0.0013) Steps 958(963.35) | Grad Norm 1.4389(1.3504) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 115.6341, Epoch Time 1491.5747(1487.4480), Bit/dim 3.5131(best: 3.5047), Xent 2.9168, Loss 4.9715, Error 0.3489(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26080 | Time 25.1640(24.6482) | Bit/dim 3.4533(3.4753) | Xent 0.0006(0.0053) | Loss 3.4536(3.4779) | Error 0.0000(0.0013) Steps 976(963.79) | Grad Norm 0.6452(1.3651) | Total Time 14.00(14.00)\n",
      "Iter 26090 | Time 25.2441(24.6854) | Bit/dim 3.5081(3.4784) | Xent 0.0132(0.0051) | Loss 3.5147(3.4810) | Error 0.0022(0.0013) Steps 964(963.71) | Grad Norm 1.5774(1.2982) | Total Time 14.00(14.00)\n",
      "Iter 26100 | Time 24.9783(24.6818) | Bit/dim 3.4736(3.4780) | Xent 0.0026(0.0047) | Loss 3.4749(3.4804) | Error 0.0011(0.0012) Steps 970(963.56) | Grad Norm 1.3598(1.2389) | Total Time 14.00(14.00)\n",
      "Iter 26110 | Time 25.4420(24.7092) | Bit/dim 3.4696(3.4808) | Xent 0.0017(0.0046) | Loss 3.4704(3.4830) | Error 0.0000(0.0012) Steps 988(963.67) | Grad Norm 0.6810(1.1394) | Total Time 14.00(14.00)\n",
      "Iter 26120 | Time 24.4350(24.7214) | Bit/dim 3.4568(3.4797) | Xent 0.0007(0.0049) | Loss 3.4572(3.4821) | Error 0.0000(0.0012) Steps 958(962.98) | Grad Norm 0.4967(1.1656) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 116.3085, Epoch Time 1497.3833(1487.7460), Bit/dim 3.5076(best: 3.5047), Xent 2.8342, Loss 4.9247, Error 0.3433(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26130 | Time 24.9833(24.8197) | Bit/dim 3.5317(3.4787) | Xent 0.0004(0.0045) | Loss 3.5319(3.4809) | Error 0.0000(0.0011) Steps 958(962.22) | Grad Norm 0.3099(1.0555) | Total Time 14.00(14.00)\n",
      "Iter 26140 | Time 24.9944(24.7877) | Bit/dim 3.4547(3.4770) | Xent 0.0116(0.0042) | Loss 3.4605(3.4791) | Error 0.0011(0.0010) Steps 964(962.60) | Grad Norm 0.4892(0.9568) | Total Time 14.00(14.00)\n",
      "Iter 26150 | Time 25.5624(24.7956) | Bit/dim 3.4838(3.4747) | Xent 0.0027(0.0034) | Loss 3.4852(3.4764) | Error 0.0011(0.0008) Steps 946(961.15) | Grad Norm 1.0051(0.8690) | Total Time 14.00(14.00)\n",
      "Iter 26160 | Time 24.7421(24.7442) | Bit/dim 3.4920(3.4756) | Xent 0.0033(0.0035) | Loss 3.4936(3.4774) | Error 0.0011(0.0009) Steps 958(961.58) | Grad Norm 0.7918(0.8818) | Total Time 14.00(14.00)\n",
      "Iter 26170 | Time 24.9197(24.6929) | Bit/dim 3.5020(3.4780) | Xent 0.0050(0.0036) | Loss 3.5045(3.4798) | Error 0.0022(0.0010) Steps 964(961.43) | Grad Norm 2.4250(0.9339) | Total Time 14.00(14.00)\n",
      "Iter 26180 | Time 24.2529(24.7718) | Bit/dim 3.5030(3.4793) | Xent 0.0022(0.0035) | Loss 3.5041(3.4811) | Error 0.0011(0.0010) Steps 970(961.37) | Grad Norm 0.7861(0.9662) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 116.7710, Epoch Time 1495.0947(1487.9665), Bit/dim 3.5060(best: 3.5047), Xent 2.8853, Loss 4.9486, Error 0.3459(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26190 | Time 24.6145(24.6731) | Bit/dim 3.4733(3.4791) | Xent 0.0010(0.0033) | Loss 3.4738(3.4808) | Error 0.0000(0.0009) Steps 970(962.38) | Grad Norm 0.3791(0.9288) | Total Time 14.00(14.00)\n",
      "Iter 26200 | Time 24.9523(24.6225) | Bit/dim 3.5004(3.4808) | Xent 0.0006(0.0027) | Loss 3.5007(3.4822) | Error 0.0000(0.0008) Steps 964(962.66) | Grad Norm 0.2649(0.8112) | Total Time 14.00(14.00)\n",
      "Iter 26210 | Time 24.2476(24.5801) | Bit/dim 3.4717(3.4788) | Xent 0.0015(0.0024) | Loss 3.4724(3.4800) | Error 0.0011(0.0007) Steps 964(960.57) | Grad Norm 1.4248(0.7572) | Total Time 14.00(14.00)\n",
      "Iter 26220 | Time 25.2861(24.5645) | Bit/dim 3.4323(3.4754) | Xent 0.0040(0.0024) | Loss 3.4343(3.4766) | Error 0.0011(0.0008) Steps 958(961.02) | Grad Norm 0.9404(0.8423) | Total Time 14.00(14.00)\n",
      "Iter 26230 | Time 24.7425(24.6276) | Bit/dim 3.4662(3.4755) | Xent 0.0030(0.0023) | Loss 3.4677(3.4767) | Error 0.0022(0.0008) Steps 970(960.33) | Grad Norm 1.5258(0.9110) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 116.7053, Epoch Time 1483.8183(1487.8420), Bit/dim 3.5064(best: 3.5047), Xent 2.9072, Loss 4.9600, Error 0.3471(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26240 | Time 24.6058(24.5621) | Bit/dim 3.4833(3.4788) | Xent 0.0053(0.0030) | Loss 3.4859(3.4803) | Error 0.0011(0.0008) Steps 952(960.19) | Grad Norm 1.4924(0.9533) | Total Time 14.00(14.00)\n",
      "Iter 26250 | Time 25.2519(24.6237) | Bit/dim 3.4739(3.4796) | Xent 0.0005(0.0034) | Loss 3.4742(3.4813) | Error 0.0000(0.0010) Steps 958(960.46) | Grad Norm 0.6773(0.9698) | Total Time 14.00(14.00)\n",
      "Iter 26260 | Time 24.7134(24.6159) | Bit/dim 3.4272(3.4768) | Xent 0.0053(0.0044) | Loss 3.4298(3.4790) | Error 0.0022(0.0012) Steps 970(961.83) | Grad Norm 1.7872(1.1084) | Total Time 14.00(14.00)\n",
      "Iter 26270 | Time 23.8462(24.5705) | Bit/dim 3.4621(3.4744) | Xent 0.0133(0.0050) | Loss 3.4688(3.4769) | Error 0.0022(0.0013) Steps 952(961.04) | Grad Norm 1.4384(1.1981) | Total Time 14.00(14.00)\n",
      "Iter 26280 | Time 24.7989(24.5440) | Bit/dim 3.4820(3.4756) | Xent 0.0022(0.0047) | Loss 3.4831(3.4780) | Error 0.0011(0.0012) Steps 958(959.65) | Grad Norm 0.8310(1.1689) | Total Time 14.00(14.00)\n",
      "Iter 26290 | Time 23.7559(24.5275) | Bit/dim 3.5044(3.4787) | Xent 0.0022(0.0045) | Loss 3.5056(3.4810) | Error 0.0011(0.0012) Steps 958(959.54) | Grad Norm 0.9601(1.0730) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 116.0972, Epoch Time 1483.2816(1487.7052), Bit/dim 3.5054(best: 3.5047), Xent 2.8434, Loss 4.9271, Error 0.3477(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26300 | Time 25.1171(24.4236) | Bit/dim 3.4676(3.4777) | Xent 0.0011(0.0039) | Loss 3.4682(3.4797) | Error 0.0000(0.0009) Steps 958(957.55) | Grad Norm 0.6241(0.9642) | Total Time 14.00(14.00)\n",
      "Iter 26310 | Time 24.7376(24.4004) | Bit/dim 3.4324(3.4772) | Xent 0.0078(0.0035) | Loss 3.4363(3.4790) | Error 0.0011(0.0009) Steps 940(956.67) | Grad Norm 2.7146(0.9108) | Total Time 14.00(14.00)\n",
      "Iter 26320 | Time 24.1873(24.4436) | Bit/dim 3.4738(3.4769) | Xent 0.0009(0.0033) | Loss 3.4742(3.4785) | Error 0.0000(0.0008) Steps 952(957.08) | Grad Norm 0.7117(0.9360) | Total Time 14.00(14.00)\n",
      "Iter 26330 | Time 24.5660(24.4573) | Bit/dim 3.4917(3.4767) | Xent 0.0032(0.0035) | Loss 3.4933(3.4784) | Error 0.0011(0.0009) Steps 964(958.82) | Grad Norm 0.7327(0.9500) | Total Time 14.00(14.00)\n",
      "Iter 26340 | Time 24.4290(24.5189) | Bit/dim 3.4379(3.4773) | Xent 0.0022(0.0039) | Loss 3.4390(3.4793) | Error 0.0011(0.0010) Steps 964(958.41) | Grad Norm 1.1616(1.0417) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 115.3752, Epoch Time 1479.6051(1487.4622), Bit/dim 3.5056(best: 3.5047), Xent 2.8987, Loss 4.9550, Error 0.3491(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26350 | Time 24.4015(24.5240) | Bit/dim 3.4666(3.4769) | Xent 0.0012(0.0037) | Loss 3.4672(3.4787) | Error 0.0000(0.0009) Steps 946(957.74) | Grad Norm 0.5267(1.0214) | Total Time 14.00(14.00)\n",
      "Iter 26360 | Time 24.6514(24.5606) | Bit/dim 3.4762(3.4770) | Xent 0.0079(0.0036) | Loss 3.4802(3.4788) | Error 0.0022(0.0009) Steps 970(957.01) | Grad Norm 3.5831(1.0801) | Total Time 14.00(14.00)\n",
      "Iter 26370 | Time 23.9935(24.6063) | Bit/dim 3.4865(3.4780) | Xent 0.0093(0.0041) | Loss 3.4911(3.4800) | Error 0.0022(0.0010) Steps 952(957.78) | Grad Norm 1.5258(1.0773) | Total Time 14.00(14.00)\n",
      "Iter 26380 | Time 24.5703(24.6480) | Bit/dim 3.4543(3.4771) | Xent 0.0008(0.0037) | Loss 3.4547(3.4789) | Error 0.0000(0.0010) Steps 946(957.36) | Grad Norm 0.5008(0.9980) | Total Time 14.00(14.00)\n",
      "Iter 26390 | Time 25.7264(24.5882) | Bit/dim 3.4924(3.4770) | Xent 0.0058(0.0035) | Loss 3.4953(3.4788) | Error 0.0011(0.0009) Steps 964(956.14) | Grad Norm 0.9990(1.0549) | Total Time 14.00(14.00)\n",
      "Iter 26400 | Time 24.5075(24.5723) | Bit/dim 3.4722(3.4786) | Xent 0.0013(0.0035) | Loss 3.4728(3.4804) | Error 0.0000(0.0010) Steps 952(956.16) | Grad Norm 0.5140(1.0587) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 115.9608, Epoch Time 1486.1340(1487.4224), Bit/dim 3.5065(best: 3.5047), Xent 2.9496, Loss 4.9813, Error 0.3502(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26410 | Time 23.7742(24.5135) | Bit/dim 3.4633(3.4763) | Xent 0.0078(0.0036) | Loss 3.4672(3.4781) | Error 0.0022(0.0010) Steps 946(955.48) | Grad Norm 1.3886(1.0274) | Total Time 14.00(14.00)\n",
      "Iter 26420 | Time 24.6215(24.5389) | Bit/dim 3.4901(3.4783) | Xent 0.0006(0.0034) | Loss 3.4904(3.4800) | Error 0.0000(0.0009) Steps 952(957.20) | Grad Norm 0.3074(0.9240) | Total Time 14.00(14.00)\n",
      "Iter 26430 | Time 24.4285(24.4720) | Bit/dim 3.4526(3.4790) | Xent 0.0116(0.0041) | Loss 3.4585(3.4810) | Error 0.0033(0.0011) Steps 940(956.95) | Grad Norm 1.8380(1.0341) | Total Time 14.00(14.00)\n",
      "Iter 26440 | Time 24.3697(24.5342) | Bit/dim 3.4824(3.4765) | Xent 0.0003(0.0037) | Loss 3.4826(3.4783) | Error 0.0000(0.0010) Steps 952(957.01) | Grad Norm 0.8284(1.1280) | Total Time 14.00(14.00)\n",
      "Iter 26450 | Time 24.0230(24.5046) | Bit/dim 3.4862(3.4782) | Xent 0.0006(0.0040) | Loss 3.4865(3.4802) | Error 0.0000(0.0011) Steps 946(956.81) | Grad Norm 0.7020(1.1100) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 114.7299, Epoch Time 1478.5609(1487.1565), Bit/dim 3.5106(best: 3.5047), Xent 2.8752, Loss 4.9482, Error 0.3446(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26460 | Time 23.9286(24.4395) | Bit/dim 3.4729(3.4799) | Xent 0.0005(0.0041) | Loss 3.4731(3.4820) | Error 0.0000(0.0012) Steps 964(957.95) | Grad Norm 0.5429(1.1138) | Total Time 14.00(14.00)\n",
      "Iter 26470 | Time 23.9234(24.3653) | Bit/dim 3.5134(3.4813) | Xent 0.0118(0.0044) | Loss 3.5193(3.4835) | Error 0.0011(0.0012) Steps 946(957.33) | Grad Norm 0.7129(1.0683) | Total Time 14.00(14.00)\n",
      "Iter 26480 | Time 24.3738(24.3456) | Bit/dim 3.4696(3.4807) | Xent 0.0006(0.0043) | Loss 3.4699(3.4828) | Error 0.0000(0.0011) Steps 952(957.27) | Grad Norm 0.6979(1.0500) | Total Time 14.00(14.00)\n",
      "Iter 26490 | Time 23.8866(24.3440) | Bit/dim 3.4698(3.4774) | Xent 0.0049(0.0041) | Loss 3.4723(3.4795) | Error 0.0011(0.0010) Steps 952(958.02) | Grad Norm 2.2409(1.0462) | Total Time 14.00(14.00)\n",
      "Iter 26500 | Time 24.6512(24.3444) | Bit/dim 3.4649(3.4782) | Xent 0.0019(0.0040) | Loss 3.4658(3.4801) | Error 0.0000(0.0009) Steps 952(957.36) | Grad Norm 0.6994(1.0471) | Total Time 14.00(14.00)\n",
      "Iter 26510 | Time 24.6344(24.3691) | Bit/dim 3.4707(3.4774) | Xent 0.0031(0.0039) | Loss 3.4722(3.4794) | Error 0.0000(0.0009) Steps 946(955.78) | Grad Norm 1.3597(1.0662) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 115.5032, Epoch Time 1470.1632(1486.6467), Bit/dim 3.5055(best: 3.5047), Xent 2.8686, Loss 4.9399, Error 0.3456(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26520 | Time 24.9431(24.3544) | Bit/dim 3.4902(3.4746) | Xent 0.0012(0.0035) | Loss 3.4908(3.4763) | Error 0.0000(0.0008) Steps 946(954.15) | Grad Norm 0.4032(0.9595) | Total Time 14.00(14.00)\n",
      "Iter 26530 | Time 24.1028(24.3059) | Bit/dim 3.4909(3.4783) | Xent 0.0053(0.0036) | Loss 3.4936(3.4801) | Error 0.0011(0.0008) Steps 946(954.79) | Grad Norm 1.0390(0.9138) | Total Time 14.00(14.00)\n",
      "Iter 26540 | Time 24.2007(24.3443) | Bit/dim 3.4750(3.4767) | Xent 0.0008(0.0040) | Loss 3.4754(3.4787) | Error 0.0000(0.0009) Steps 964(955.30) | Grad Norm 0.4461(0.9158) | Total Time 14.00(14.00)\n",
      "Iter 26550 | Time 24.0764(24.3376) | Bit/dim 3.5052(3.4750) | Xent 0.0014(0.0037) | Loss 3.5059(3.4769) | Error 0.0000(0.0008) Steps 952(954.72) | Grad Norm 0.6465(0.8838) | Total Time 14.00(14.00)\n",
      "Iter 26560 | Time 24.0583(24.2785) | Bit/dim 3.4745(3.4772) | Xent 0.0008(0.0035) | Loss 3.4750(3.4789) | Error 0.0000(0.0008) Steps 952(953.85) | Grad Norm 0.4161(0.8634) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 115.3353, Epoch Time 1470.7788(1486.1707), Bit/dim 3.5051(best: 3.5047), Xent 2.8793, Loss 4.9447, Error 0.3486(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26570 | Time 24.5106(24.3553) | Bit/dim 3.4926(3.4805) | Xent 0.0004(0.0031) | Loss 3.4928(3.4821) | Error 0.0000(0.0008) Steps 970(955.48) | Grad Norm 0.3139(0.8166) | Total Time 14.00(14.00)\n",
      "Iter 26580 | Time 24.3324(24.2910) | Bit/dim 3.4772(3.4792) | Xent 0.0005(0.0032) | Loss 3.4774(3.4807) | Error 0.0000(0.0008) Steps 970(955.25) | Grad Norm 0.4319(0.8239) | Total Time 14.00(14.00)\n",
      "Iter 26590 | Time 24.1875(24.2725) | Bit/dim 3.4698(3.4782) | Xent 0.0059(0.0035) | Loss 3.4728(3.4799) | Error 0.0022(0.0009) Steps 952(955.47) | Grad Norm 1.4979(0.8550) | Total Time 14.00(14.00)\n",
      "Iter 26600 | Time 24.4612(24.2760) | Bit/dim 3.4870(3.4775) | Xent 0.0019(0.0038) | Loss 3.4880(3.4794) | Error 0.0000(0.0009) Steps 970(955.97) | Grad Norm 0.6536(0.8253) | Total Time 14.00(14.00)\n",
      "Iter 26610 | Time 24.5484(24.3054) | Bit/dim 3.4928(3.4747) | Xent 0.0012(0.0041) | Loss 3.4934(3.4767) | Error 0.0011(0.0010) Steps 958(958.23) | Grad Norm 0.6091(0.8872) | Total Time 14.00(14.00)\n",
      "Iter 26620 | Time 24.6491(24.3096) | Bit/dim 3.4432(3.4748) | Xent 0.0056(0.0040) | Loss 3.4460(3.4768) | Error 0.0022(0.0010) Steps 964(958.67) | Grad Norm 1.4671(0.9055) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 115.5833, Epoch Time 1468.9250(1485.6533), Bit/dim 3.5061(best: 3.5047), Xent 2.9220, Loss 4.9672, Error 0.3508(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26630 | Time 25.0247(24.3936) | Bit/dim 3.4892(3.4779) | Xent 0.0048(0.0040) | Loss 3.4916(3.4799) | Error 0.0011(0.0010) Steps 946(957.47) | Grad Norm 1.4098(0.9911) | Total Time 14.00(14.00)\n",
      "Iter 26640 | Time 24.1868(24.4161) | Bit/dim 3.4753(3.4770) | Xent 0.0011(0.0035) | Loss 3.4758(3.4787) | Error 0.0000(0.0009) Steps 952(958.00) | Grad Norm 0.6365(1.0443) | Total Time 14.00(14.00)\n",
      "Iter 26650 | Time 25.1598(24.4628) | Bit/dim 3.5129(3.4804) | Xent 0.0012(0.0033) | Loss 3.5135(3.4821) | Error 0.0011(0.0009) Steps 970(958.25) | Grad Norm 0.8485(1.0756) | Total Time 14.00(14.00)\n",
      "Iter 26660 | Time 24.1642(24.4893) | Bit/dim 3.4451(3.4760) | Xent 0.0024(0.0028) | Loss 3.4463(3.4774) | Error 0.0000(0.0007) Steps 946(958.89) | Grad Norm 2.1907(1.0191) | Total Time 14.00(14.00)\n",
      "Iter 26670 | Time 23.9570(24.3746) | Bit/dim 3.4659(3.4752) | Xent 0.0022(0.0025) | Loss 3.4670(3.4765) | Error 0.0011(0.0007) Steps 958(958.84) | Grad Norm 0.6234(0.9181) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 115.3001, Epoch Time 1476.6241(1485.3825), Bit/dim 3.5058(best: 3.5047), Xent 2.8793, Loss 4.9454, Error 0.3436(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26680 | Time 24.2274(24.3039) | Bit/dim 3.4792(3.4741) | Xent 0.0080(0.0032) | Loss 3.4832(3.4757) | Error 0.0011(0.0009) Steps 952(957.26) | Grad Norm 1.2342(0.9912) | Total Time 14.00(14.00)\n",
      "Iter 26690 | Time 24.3316(24.2732) | Bit/dim 3.4413(3.4731) | Xent 0.0008(0.0030) | Loss 3.4416(3.4746) | Error 0.0000(0.0008) Steps 946(955.97) | Grad Norm 0.4025(0.9396) | Total Time 14.00(14.00)\n",
      "Iter 26700 | Time 24.2067(24.2654) | Bit/dim 3.4751(3.4765) | Xent 0.0088(0.0031) | Loss 3.4794(3.4781) | Error 0.0022(0.0009) Steps 958(955.27) | Grad Norm 0.9946(0.9565) | Total Time 14.00(14.00)\n",
      "Iter 26710 | Time 24.4782(24.2875) | Bit/dim 3.4888(3.4768) | Xent 0.0041(0.0031) | Loss 3.4909(3.4784) | Error 0.0022(0.0009) Steps 946(954.29) | Grad Norm 1.2228(0.9275) | Total Time 14.00(14.00)\n",
      "Iter 26720 | Time 24.8358(24.3048) | Bit/dim 3.4945(3.4775) | Xent 0.0005(0.0028) | Loss 3.4948(3.4789) | Error 0.0000(0.0008) Steps 976(954.97) | Grad Norm 0.5083(0.8859) | Total Time 14.00(14.00)\n",
      "Iter 26730 | Time 24.8509(24.3444) | Bit/dim 3.4608(3.4755) | Xent 0.0006(0.0029) | Loss 3.4611(3.4769) | Error 0.0000(0.0008) Steps 958(955.07) | Grad Norm 0.5386(0.8912) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 114.5545, Epoch Time 1469.0071(1484.8912), Bit/dim 3.5055(best: 3.5047), Xent 2.9109, Loss 4.9609, Error 0.3491(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26740 | Time 24.0427(24.3939) | Bit/dim 3.4595(3.4771) | Xent 0.0024(0.0024) | Loss 3.4607(3.4783) | Error 0.0011(0.0006) Steps 976(955.08) | Grad Norm 1.0485(0.8032) | Total Time 14.00(14.00)\n",
      "Iter 26750 | Time 24.6405(24.4049) | Bit/dim 3.4728(3.4779) | Xent 0.0007(0.0025) | Loss 3.4732(3.4792) | Error 0.0000(0.0007) Steps 940(955.26) | Grad Norm 0.3711(0.8116) | Total Time 14.00(14.00)\n",
      "Iter 26760 | Time 24.7938(24.3639) | Bit/dim 3.4620(3.4754) | Xent 0.0023(0.0021) | Loss 3.4631(3.4765) | Error 0.0011(0.0007) Steps 976(954.57) | Grad Norm 0.5218(0.7300) | Total Time 14.00(14.00)\n",
      "Iter 26770 | Time 24.9626(24.3790) | Bit/dim 3.4484(3.4750) | Xent 0.0056(0.0026) | Loss 3.4512(3.4763) | Error 0.0033(0.0008) Steps 964(954.49) | Grad Norm 1.3438(0.8285) | Total Time 14.00(14.00)\n",
      "Iter 26780 | Time 24.5530(24.3115) | Bit/dim 3.4407(3.4739) | Xent 0.0067(0.0031) | Loss 3.4441(3.4754) | Error 0.0011(0.0008) Steps 970(956.03) | Grad Norm 1.8069(0.8921) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 115.1265, Epoch Time 1471.4319(1484.4874), Bit/dim 3.5067(best: 3.5047), Xent 2.9486, Loss 4.9810, Error 0.3489(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26790 | Time 23.3858(24.2828) | Bit/dim 3.4917(3.4738) | Xent 0.0088(0.0036) | Loss 3.4961(3.4756) | Error 0.0011(0.0009) Steps 964(955.95) | Grad Norm 1.3906(0.9982) | Total Time 14.00(14.00)\n",
      "Iter 26800 | Time 24.6764(24.2732) | Bit/dim 3.4785(3.4730) | Xent 0.0004(0.0034) | Loss 3.4787(3.4747) | Error 0.0000(0.0008) Steps 964(956.24) | Grad Norm 0.6965(1.0086) | Total Time 14.00(14.00)\n",
      "Iter 26810 | Time 24.2192(24.2384) | Bit/dim 3.4778(3.4753) | Xent 0.0008(0.0033) | Loss 3.4781(3.4769) | Error 0.0000(0.0008) Steps 952(955.06) | Grad Norm 0.9928(0.9973) | Total Time 14.00(14.00)\n",
      "Iter 26820 | Time 25.3187(24.3613) | Bit/dim 3.4724(3.4747) | Xent 0.0028(0.0038) | Loss 3.4738(3.4766) | Error 0.0011(0.0008) Steps 970(956.94) | Grad Norm 0.6913(0.9328) | Total Time 14.00(14.00)\n",
      "Iter 26830 | Time 24.8425(24.4131) | Bit/dim 3.4482(3.4757) | Xent 0.0004(0.0037) | Loss 3.4484(3.4775) | Error 0.0000(0.0008) Steps 958(956.88) | Grad Norm 0.3408(0.8846) | Total Time 14.00(14.00)\n",
      "Iter 26840 | Time 24.3679(24.4983) | Bit/dim 3.4919(3.4771) | Xent 0.0032(0.0035) | Loss 3.4935(3.4789) | Error 0.0011(0.0008) Steps 958(957.70) | Grad Norm 1.6397(0.9090) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 115.4674, Epoch Time 1478.8376(1484.3179), Bit/dim 3.5046(best: 3.5047), Xent 2.8674, Loss 4.9383, Error 0.3416(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26850 | Time 24.7614(24.4761) | Bit/dim 3.4644(3.4772) | Xent 0.0080(0.0036) | Loss 3.4684(3.4790) | Error 0.0022(0.0008) Steps 952(957.75) | Grad Norm 1.2822(0.8468) | Total Time 14.00(14.00)\n",
      "Iter 26860 | Time 24.1257(24.4253) | Bit/dim 3.4757(3.4763) | Xent 0.0007(0.0039) | Loss 3.4760(3.4782) | Error 0.0000(0.0008) Steps 952(958.48) | Grad Norm 0.3611(0.7795) | Total Time 14.00(14.00)\n",
      "Iter 26870 | Time 24.7427(24.4391) | Bit/dim 3.4644(3.4761) | Xent 0.0118(0.0039) | Loss 3.4703(3.4781) | Error 0.0033(0.0009) Steps 946(958.51) | Grad Norm 2.5620(0.8983) | Total Time 14.00(14.00)\n",
      "Iter 26880 | Time 24.2492(24.4299) | Bit/dim 3.4874(3.4774) | Xent 0.0018(0.0045) | Loss 3.4882(3.4796) | Error 0.0000(0.0010) Steps 964(958.06) | Grad Norm 0.7873(1.0486) | Total Time 14.00(14.00)\n",
      "Iter 26890 | Time 24.5485(24.4420) | Bit/dim 3.4749(3.4779) | Xent 0.0027(0.0047) | Loss 3.4762(3.4802) | Error 0.0011(0.0013) Steps 964(957.19) | Grad Norm 1.3398(1.1170) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0489 | Time 115.5469, Epoch Time 1475.8612(1484.0642), Bit/dim 3.5062(best: 3.5046), Xent 2.8951, Loss 4.9537, Error 0.3448(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26900 | Time 24.1961(24.4397) | Bit/dim 3.4631(3.4767) | Xent 0.0012(0.0049) | Loss 3.4637(3.4791) | Error 0.0000(0.0011) Steps 964(957.34) | Grad Norm 0.7353(1.1439) | Total Time 14.00(14.00)\n",
      "Iter 26910 | Time 24.1995(24.5236) | Bit/dim 3.4680(3.4791) | Xent 0.0249(0.0052) | Loss 3.4805(3.4817) | Error 0.0056(0.0012) Steps 970(958.25) | Grad Norm 2.3061(1.1309) | Total Time 14.00(14.00)\n",
      "Iter 26920 | Time 24.8287(24.5481) | Bit/dim 3.4965(3.4782) | Xent 0.0106(0.0064) | Loss 3.5018(3.4814) | Error 0.0022(0.0015) Steps 976(959.62) | Grad Norm 1.8922(1.2728) | Total Time 14.00(14.00)\n",
      "Iter 26930 | Time 25.2409(24.6273) | Bit/dim 3.5019(3.4779) | Xent 0.0163(0.0068) | Loss 3.5101(3.4813) | Error 0.0056(0.0017) Steps 970(961.42) | Grad Norm 2.1791(1.3458) | Total Time 14.00(14.00)\n",
      "Iter 26940 | Time 25.0148(24.6648) | Bit/dim 3.4534(3.4778) | Xent 0.0023(0.0079) | Loss 3.4546(3.4818) | Error 0.0011(0.0020) Steps 976(961.45) | Grad Norm 1.6979(1.4598) | Total Time 14.00(14.00)\n",
      "Iter 26950 | Time 24.1905(24.5243) | Bit/dim 3.5123(3.4807) | Xent 0.0077(0.0083) | Loss 3.5161(3.4848) | Error 0.0011(0.0022) Steps 952(959.75) | Grad Norm 0.8714(1.4869) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0490 | Time 116.3396, Epoch Time 1488.1681(1484.1873), Bit/dim 3.5078(best: 3.5046), Xent 2.8307, Loss 4.9231, Error 0.3463(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26960 | Time 24.2027(24.4561) | Bit/dim 3.4647(3.4791) | Xent 0.0025(0.0075) | Loss 3.4660(3.4829) | Error 0.0011(0.0020) Steps 958(957.40) | Grad Norm 0.8071(1.4199) | Total Time 14.00(14.00)\n",
      "Iter 26970 | Time 24.0584(24.4168) | Bit/dim 3.4716(3.4782) | Xent 0.0056(0.0067) | Loss 3.4744(3.4815) | Error 0.0022(0.0018) Steps 946(957.11) | Grad Norm 1.6925(1.3585) | Total Time 14.00(14.00)\n",
      "Iter 26980 | Time 23.6138(24.3595) | Bit/dim 3.4837(3.4798) | Xent 0.0006(0.0060) | Loss 3.4840(3.4827) | Error 0.0000(0.0015) Steps 970(958.27) | Grad Norm 0.3407(1.2066) | Total Time 14.00(14.00)\n",
      "Iter 26990 | Time 24.4743(24.4357) | Bit/dim 3.4512(3.4789) | Xent 0.0102(0.0057) | Loss 3.4563(3.4818) | Error 0.0022(0.0015) Steps 970(958.87) | Grad Norm 1.9888(1.1647) | Total Time 14.00(14.00)\n",
      "Iter 27000 | Time 24.6732(24.3677) | Bit/dim 3.4592(3.4780) | Xent 0.0005(0.0048) | Loss 3.4595(3.4804) | Error 0.0000(0.0012) Steps 964(957.85) | Grad Norm 0.3760(1.0527) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0491 | Time 114.8442, Epoch Time 1468.8198(1483.7263), Bit/dim 3.5046(best: 3.5046), Xent 2.8627, Loss 4.9359, Error 0.3482(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27010 | Time 23.9817(24.3436) | Bit/dim 3.4220(3.4786) | Xent 0.0011(0.0049) | Loss 3.4226(3.4810) | Error 0.0000(0.0012) Steps 964(957.31) | Grad Norm 0.5083(1.0041) | Total Time 14.00(14.00)\n",
      "Iter 27020 | Time 24.3159(24.4614) | Bit/dim 3.4610(3.4767) | Xent 0.0008(0.0047) | Loss 3.4614(3.4791) | Error 0.0000(0.0011) Steps 964(958.83) | Grad Norm 0.3694(0.9422) | Total Time 14.00(14.00)\n",
      "Iter 27030 | Time 24.2878(24.4309) | Bit/dim 3.4384(3.4750) | Xent 0.0011(0.0044) | Loss 3.4390(3.4772) | Error 0.0000(0.0011) Steps 958(960.15) | Grad Norm 0.6450(0.9554) | Total Time 14.00(14.00)\n",
      "Iter 27040 | Time 24.8966(24.4698) | Bit/dim 3.4648(3.4756) | Xent 0.0008(0.0041) | Loss 3.4652(3.4777) | Error 0.0000(0.0010) Steps 958(959.74) | Grad Norm 0.6132(0.9646) | Total Time 14.00(14.00)\n",
      "Iter 27050 | Time 24.3690(24.4520) | Bit/dim 3.4665(3.4759) | Xent 0.0034(0.0034) | Loss 3.4682(3.4777) | Error 0.0011(0.0009) Steps 964(959.97) | Grad Norm 0.7666(0.8837) | Total Time 14.00(14.00)\n",
      "Iter 27060 | Time 25.5327(24.4972) | Bit/dim 3.4569(3.4770) | Xent 0.0010(0.0031) | Loss 3.4574(3.4785) | Error 0.0000(0.0007) Steps 958(960.20) | Grad Norm 0.3957(0.7817) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0492 | Time 117.3003, Epoch Time 1485.3670(1483.7755), Bit/dim 3.5025(best: 3.5046), Xent 2.8978, Loss 4.9515, Error 0.3481(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27070 | Time 24.2762(24.4936) | Bit/dim 3.4701(3.4800) | Xent 0.0173(0.0042) | Loss 3.4788(3.4821) | Error 0.0033(0.0009) Steps 964(958.86) | Grad Norm 1.4033(0.8376) | Total Time 14.00(14.00)\n",
      "Iter 27080 | Time 25.1063(24.5238) | Bit/dim 3.4768(3.4756) | Xent 0.0076(0.0052) | Loss 3.4806(3.4782) | Error 0.0011(0.0011) Steps 976(960.01) | Grad Norm 1.2584(1.0171) | Total Time 14.00(14.00)\n",
      "Iter 27090 | Time 24.0487(24.5377) | Bit/dim 3.4851(3.4775) | Xent 0.0068(0.0046) | Loss 3.4885(3.4797) | Error 0.0011(0.0010) Steps 958(960.28) | Grad Norm 2.4169(1.0526) | Total Time 14.00(14.00)\n",
      "Iter 27100 | Time 24.3547(24.5099) | Bit/dim 3.4473(3.4771) | Xent 0.0087(0.0045) | Loss 3.4517(3.4794) | Error 0.0011(0.0010) Steps 940(960.13) | Grad Norm 0.9736(1.1536) | Total Time 14.00(14.00)\n",
      "Iter 27110 | Time 24.6027(24.5225) | Bit/dim 3.4984(3.4765) | Xent 0.0034(0.0045) | Loss 3.5001(3.4788) | Error 0.0022(0.0011) Steps 952(960.60) | Grad Norm 1.2966(1.1543) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0493 | Time 115.4124, Epoch Time 1481.7434(1483.7146), Bit/dim 3.5052(best: 3.5025), Xent 2.8726, Loss 4.9415, Error 0.3509(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27120 | Time 24.6324(24.4507) | Bit/dim 3.4915(3.4761) | Xent 0.0082(0.0043) | Loss 3.4955(3.4782) | Error 0.0033(0.0011) Steps 946(959.86) | Grad Norm 1.1641(1.0574) | Total Time 14.00(14.00)\n",
      "Iter 27130 | Time 24.3011(24.4652) | Bit/dim 3.4892(3.4773) | Xent 0.0017(0.0040) | Loss 3.4900(3.4792) | Error 0.0011(0.0010) Steps 970(958.51) | Grad Norm 0.3890(0.9751) | Total Time 14.00(14.00)\n",
      "Iter 27140 | Time 23.5422(24.3705) | Bit/dim 3.4836(3.4796) | Xent 0.0012(0.0036) | Loss 3.4842(3.4814) | Error 0.0000(0.0009) Steps 970(959.43) | Grad Norm 0.4746(0.9151) | Total Time 14.00(14.00)\n",
      "Iter 27150 | Time 23.9118(24.3303) | Bit/dim 3.4752(3.4788) | Xent 0.0015(0.0032) | Loss 3.4760(3.4804) | Error 0.0000(0.0008) Steps 946(958.56) | Grad Norm 0.3737(0.8302) | Total Time 14.00(14.00)\n",
      "Iter 27160 | Time 23.7504(24.3268) | Bit/dim 3.4702(3.4757) | Xent 0.0073(0.0039) | Loss 3.4739(3.4776) | Error 0.0022(0.0010) Steps 964(957.93) | Grad Norm 1.3025(0.8934) | Total Time 14.00(14.00)\n",
      "Iter 27170 | Time 24.3990(24.2901) | Bit/dim 3.4535(3.4749) | Xent 0.0006(0.0034) | Loss 3.4538(3.4766) | Error 0.0000(0.0009) Steps 958(957.91) | Grad Norm 0.5349(0.8747) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0494 | Time 114.8559, Epoch Time 1467.4615(1483.2270), Bit/dim 3.5044(best: 3.5025), Xent 2.9009, Loss 4.9549, Error 0.3474(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27180 | Time 24.6828(24.3569) | Bit/dim 3.4912(3.4745) | Xent 0.0161(0.0036) | Loss 3.4993(3.4763) | Error 0.0033(0.0009) Steps 958(957.33) | Grad Norm 1.8400(0.8951) | Total Time 14.00(14.00)\n",
      "Iter 27190 | Time 24.5550(24.3966) | Bit/dim 3.4903(3.4757) | Xent 0.0050(0.0035) | Loss 3.4928(3.4774) | Error 0.0011(0.0010) Steps 970(958.12) | Grad Norm 1.1539(0.8957) | Total Time 14.00(14.00)\n",
      "Iter 27200 | Time 24.5510(24.4375) | Bit/dim 3.4667(3.4747) | Xent 0.0127(0.0035) | Loss 3.4730(3.4765) | Error 0.0022(0.0010) Steps 958(957.13) | Grad Norm 1.1517(0.8744) | Total Time 14.00(14.00)\n",
      "Iter 27210 | Time 25.0087(24.5078) | Bit/dim 3.4784(3.4735) | Xent 0.0017(0.0030) | Loss 3.4793(3.4750) | Error 0.0011(0.0008) Steps 994(958.72) | Grad Norm 0.6117(0.7974) | Total Time 14.00(14.00)\n",
      "Iter 27220 | Time 24.7419(24.5502) | Bit/dim 3.4645(3.4770) | Xent 0.0088(0.0030) | Loss 3.4689(3.4785) | Error 0.0033(0.0009) Steps 958(960.01) | Grad Norm 1.8985(0.8396) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0495 | Time 116.6301, Epoch Time 1488.6742(1483.3904), Bit/dim 3.5025(best: 3.5025), Xent 2.9070, Loss 4.9560, Error 0.3495(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27230 | Time 23.5430(24.5157) | Bit/dim 3.4454(3.4741) | Xent 0.0018(0.0027) | Loss 3.4463(3.4754) | Error 0.0011(0.0009) Steps 958(960.63) | Grad Norm 0.8998(0.8239) | Total Time 14.00(14.00)\n",
      "Iter 27240 | Time 24.4019(24.4896) | Bit/dim 3.4309(3.4735) | Xent 0.0040(0.0025) | Loss 3.4329(3.4747) | Error 0.0011(0.0008) Steps 940(959.11) | Grad Norm 1.2270(0.8257) | Total Time 14.00(14.00)\n",
      "Iter 27250 | Time 24.0524(24.4836) | Bit/dim 3.4937(3.4761) | Xent 0.0069(0.0030) | Loss 3.4972(3.4776) | Error 0.0022(0.0009) Steps 964(960.88) | Grad Norm 1.2456(0.9341) | Total Time 14.00(14.00)\n",
      "Iter 27260 | Time 24.9059(24.5406) | Bit/dim 3.4497(3.4751) | Xent 0.0011(0.0030) | Loss 3.4502(3.4766) | Error 0.0000(0.0008) Steps 964(959.92) | Grad Norm 0.6444(0.8982) | Total Time 14.00(14.00)\n",
      "Iter 27270 | Time 25.1129(24.5622) | Bit/dim 3.4808(3.4761) | Xent 0.0005(0.0031) | Loss 3.4810(3.4776) | Error 0.0000(0.0008) Steps 970(959.75) | Grad Norm 0.3688(0.8533) | Total Time 14.00(14.00)\n",
      "Iter 27280 | Time 23.9968(24.5914) | Bit/dim 3.5050(3.4758) | Xent 0.0015(0.0033) | Loss 3.5058(3.4775) | Error 0.0011(0.0009) Steps 964(958.58) | Grad Norm 0.5387(0.8550) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0496 | Time 114.9194, Epoch Time 1482.5441(1483.3650), Bit/dim 3.5036(best: 3.5025), Xent 2.9056, Loss 4.9565, Error 0.3476(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27290 | Time 25.0829(24.5559) | Bit/dim 3.4649(3.4772) | Xent 0.0185(0.0041) | Loss 3.4742(3.4793) | Error 0.0033(0.0011) Steps 964(959.61) | Grad Norm 1.7786(1.0174) | Total Time 14.00(14.00)\n",
      "Iter 27300 | Time 24.9382(24.5852) | Bit/dim 3.4616(3.4763) | Xent 0.0007(0.0040) | Loss 3.4619(3.4783) | Error 0.0000(0.0012) Steps 976(960.50) | Grad Norm 0.8017(1.0514) | Total Time 14.00(14.00)\n",
      "Iter 27310 | Time 24.4996(24.5159) | Bit/dim 3.4774(3.4757) | Xent 0.0055(0.0043) | Loss 3.4801(3.4778) | Error 0.0011(0.0012) Steps 952(959.87) | Grad Norm 1.1522(1.0688) | Total Time 14.00(14.00)\n",
      "Iter 27320 | Time 24.8770(24.6228) | Bit/dim 3.4657(3.4757) | Xent 0.0033(0.0042) | Loss 3.4674(3.4778) | Error 0.0011(0.0012) Steps 958(961.15) | Grad Norm 0.4570(1.0634) | Total Time 14.00(14.00)\n",
      "Iter 27330 | Time 24.5755(24.6243) | Bit/dim 3.4867(3.4768) | Xent 0.0035(0.0039) | Loss 3.4884(3.4788) | Error 0.0011(0.0011) Steps 946(961.47) | Grad Norm 0.8525(1.0197) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0497 | Time 115.0878, Epoch Time 1484.5482(1483.4005), Bit/dim 3.5065(best: 3.5025), Xent 2.9005, Loss 4.9567, Error 0.3439(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27340 | Time 23.9049(24.5272) | Bit/dim 3.4576(3.4755) | Xent 0.0008(0.0037) | Loss 3.4580(3.4774) | Error 0.0000(0.0011) Steps 940(960.98) | Grad Norm 0.7876(1.0735) | Total Time 14.00(14.00)\n",
      "Iter 27350 | Time 24.3941(24.4234) | Bit/dim 3.4528(3.4754) | Xent 0.0009(0.0034) | Loss 3.4532(3.4771) | Error 0.0000(0.0010) Steps 964(960.15) | Grad Norm 0.4110(1.0676) | Total Time 14.00(14.00)\n",
      "Iter 27360 | Time 24.4785(24.4214) | Bit/dim 3.4675(3.4755) | Xent 0.0058(0.0039) | Loss 3.4704(3.4774) | Error 0.0022(0.0011) Steps 958(960.84) | Grad Norm 1.1245(1.1238) | Total Time 14.00(14.00)\n",
      "Iter 27370 | Time 23.4926(24.4666) | Bit/dim 3.4423(3.4773) | Xent 0.0016(0.0036) | Loss 3.4431(3.4791) | Error 0.0000(0.0010) Steps 952(959.39) | Grad Norm 0.8558(1.1162) | Total Time 14.00(14.00)\n",
      "Iter 27380 | Time 24.7039(24.4543) | Bit/dim 3.4794(3.4767) | Xent 0.0102(0.0035) | Loss 3.4846(3.4785) | Error 0.0022(0.0010) Steps 958(958.53) | Grad Norm 1.5505(1.0624) | Total Time 14.00(14.00)\n",
      "Iter 27390 | Time 24.2717(24.4377) | Bit/dim 3.4617(3.4765) | Xent 0.0024(0.0040) | Loss 3.4629(3.4785) | Error 0.0011(0.0010) Steps 964(959.35) | Grad Norm 0.6512(1.0621) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0498 | Time 114.7340, Epoch Time 1473.3740(1483.0997), Bit/dim 3.5045(best: 3.5025), Xent 2.9057, Loss 4.9573, Error 0.3448(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27400 | Time 23.8906(24.4565) | Bit/dim 3.4963(3.4767) | Xent 0.0079(0.0040) | Loss 3.5002(3.4787) | Error 0.0011(0.0010) Steps 958(958.29) | Grad Norm 0.6676(1.0052) | Total Time 14.00(14.00)\n",
      "Iter 27410 | Time 24.5204(24.4509) | Bit/dim 3.4327(3.4744) | Xent 0.0110(0.0039) | Loss 3.4382(3.4763) | Error 0.0011(0.0009) Steps 970(959.58) | Grad Norm 0.6559(0.9117) | Total Time 14.00(14.00)\n",
      "Iter 27420 | Time 24.2334(24.4661) | Bit/dim 3.4763(3.4748) | Xent 0.0042(0.0040) | Loss 3.4784(3.4768) | Error 0.0011(0.0009) Steps 964(960.57) | Grad Norm 1.2871(0.9598) | Total Time 14.00(14.00)\n",
      "Iter 27430 | Time 24.7115(24.5192) | Bit/dim 3.4779(3.4769) | Xent 0.0013(0.0039) | Loss 3.4785(3.4789) | Error 0.0011(0.0010) Steps 964(960.65) | Grad Norm 0.6863(0.9803) | Total Time 14.00(14.00)\n",
      "Iter 27440 | Time 24.2564(24.5125) | Bit/dim 3.4713(3.4771) | Xent 0.0040(0.0041) | Loss 3.4733(3.4792) | Error 0.0011(0.0011) Steps 964(961.63) | Grad Norm 0.8286(1.0419) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0499 | Time 115.3766, Epoch Time 1482.7231(1483.0884), Bit/dim 3.5052(best: 3.5025), Xent 2.8958, Loss 4.9532, Error 0.3434(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27450 | Time 24.2680(24.5114) | Bit/dim 3.4977(3.4770) | Xent 0.0053(0.0037) | Loss 3.5004(3.4789) | Error 0.0011(0.0010) Steps 946(960.96) | Grad Norm 1.3187(1.0258) | Total Time 14.00(14.00)\n",
      "Iter 27460 | Time 23.9379(24.5036) | Bit/dim 3.4823(3.4755) | Xent 0.0010(0.0033) | Loss 3.4828(3.4772) | Error 0.0000(0.0009) Steps 958(962.09) | Grad Norm 0.9287(0.9488) | Total Time 14.00(14.00)\n",
      "Iter 27470 | Time 24.6172(24.5084) | Bit/dim 3.4820(3.4741) | Xent 0.0012(0.0037) | Loss 3.4826(3.4759) | Error 0.0000(0.0009) Steps 976(961.89) | Grad Norm 0.6279(0.9297) | Total Time 14.00(14.00)\n",
      "Iter 27480 | Time 24.6001(24.4767) | Bit/dim 3.4655(3.4750) | Xent 0.0008(0.0035) | Loss 3.4659(3.4767) | Error 0.0000(0.0009) Steps 964(961.81) | Grad Norm 0.5673(0.9392) | Total Time 14.00(14.00)\n",
      "Iter 27490 | Time 23.7830(24.4621) | Bit/dim 3.4869(3.4764) | Xent 0.0016(0.0034) | Loss 3.4877(3.4781) | Error 0.0000(0.0008) Steps 958(960.60) | Grad Norm 0.8207(0.8705) | Total Time 14.00(14.00)\n",
      "Iter 27500 | Time 24.0248(24.4562) | Bit/dim 3.4757(3.4746) | Xent 0.0007(0.0031) | Loss 3.4761(3.4761) | Error 0.0000(0.0007) Steps 940(959.97) | Grad Norm 0.2394(0.7505) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0500 | Time 116.4288, Epoch Time 1479.0557(1482.9674), Bit/dim 3.5024(best: 3.5025), Xent 2.9145, Loss 4.9597, Error 0.3505(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27510 | Time 23.9163(24.4323) | Bit/dim 3.4669(3.4759) | Xent 0.0007(0.0028) | Loss 3.4673(3.4773) | Error 0.0000(0.0007) Steps 958(959.84) | Grad Norm 0.5011(0.7908) | Total Time 14.00(14.00)\n",
      "Iter 27520 | Time 24.4146(24.4027) | Bit/dim 3.4632(3.4739) | Xent 0.0010(0.0031) | Loss 3.4637(3.4755) | Error 0.0000(0.0009) Steps 958(960.21) | Grad Norm 0.5087(0.8239) | Total Time 14.00(14.00)\n",
      "Iter 27530 | Time 23.2074(24.3250) | Bit/dim 3.4527(3.4733) | Xent 0.0003(0.0028) | Loss 3.4528(3.4747) | Error 0.0000(0.0008) Steps 958(959.91) | Grad Norm 0.3590(0.7987) | Total Time 14.00(14.00)\n",
      "Iter 27540 | Time 24.8308(24.3484) | Bit/dim 3.4612(3.4757) | Xent 0.0008(0.0027) | Loss 3.4617(3.4770) | Error 0.0000(0.0008) Steps 946(959.72) | Grad Norm 0.9770(0.8535) | Total Time 14.00(14.00)\n",
      "Iter 27550 | Time 23.8372(24.3330) | Bit/dim 3.4978(3.4741) | Xent 0.0013(0.0026) | Loss 3.4984(3.4754) | Error 0.0000(0.0007) Steps 946(959.15) | Grad Norm 0.9809(0.9260) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0501 | Time 116.6623, Epoch Time 1471.8123(1482.6328), Bit/dim 3.5042(best: 3.5024), Xent 2.8821, Loss 4.9452, Error 0.3457(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27560 | Time 24.7107(24.3308) | Bit/dim 3.4610(3.4742) | Xent 0.0037(0.0031) | Loss 3.4628(3.4757) | Error 0.0011(0.0008) Steps 976(959.09) | Grad Norm 0.8172(0.9427) | Total Time 14.00(14.00)\n",
      "Iter 27570 | Time 25.0835(24.4509) | Bit/dim 3.4660(3.4738) | Xent 0.0019(0.0031) | Loss 3.4669(3.4754) | Error 0.0011(0.0008) Steps 964(961.15) | Grad Norm 0.8504(0.9636) | Total Time 14.00(14.00)\n",
      "Iter 27580 | Time 24.2919(24.4555) | Bit/dim 3.4635(3.4761) | Xent 0.0195(0.0042) | Loss 3.4733(3.4782) | Error 0.0033(0.0010) Steps 970(960.70) | Grad Norm 1.2154(1.0507) | Total Time 14.00(14.00)\n",
      "Iter 27590 | Time 24.2726(24.4154) | Bit/dim 3.4989(3.4799) | Xent 0.0108(0.0047) | Loss 3.5043(3.4823) | Error 0.0033(0.0012) Steps 958(960.72) | Grad Norm 1.1410(1.0940) | Total Time 14.00(14.00)\n",
      "Iter 27600 | Time 24.9069(24.4759) | Bit/dim 3.4631(3.4785) | Xent 0.0149(0.0046) | Loss 3.4705(3.4808) | Error 0.0033(0.0011) Steps 958(959.37) | Grad Norm 1.3403(1.0840) | Total Time 14.00(14.00)\n",
      "Iter 27610 | Time 25.1696(24.5514) | Bit/dim 3.4776(3.4768) | Xent 0.0167(0.0044) | Loss 3.4859(3.4790) | Error 0.0044(0.0011) Steps 952(958.90) | Grad Norm 1.4682(1.0589) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0502 | Time 117.2769, Epoch Time 1486.0571(1482.7355), Bit/dim 3.5057(best: 3.5024), Xent 2.9237, Loss 4.9676, Error 0.3484(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27620 | Time 24.3522(24.5547) | Bit/dim 3.4661(3.4749) | Xent 0.0004(0.0036) | Loss 3.4663(3.4767) | Error 0.0000(0.0009) Steps 970(959.89) | Grad Norm 0.4734(0.9451) | Total Time 14.00(14.00)\n",
      "Iter 27630 | Time 24.6706(24.5428) | Bit/dim 3.4766(3.4750) | Xent 0.0027(0.0032) | Loss 3.4780(3.4766) | Error 0.0011(0.0008) Steps 946(960.14) | Grad Norm 1.3840(0.9073) | Total Time 14.00(14.00)\n",
      "Iter 27640 | Time 24.3165(24.5909) | Bit/dim 3.4796(3.4766) | Xent 0.0007(0.0027) | Loss 3.4800(3.4779) | Error 0.0000(0.0006) Steps 964(961.73) | Grad Norm 0.3444(0.8090) | Total Time 14.00(14.00)\n",
      "Iter 27650 | Time 24.6690(24.5381) | Bit/dim 3.4654(3.4760) | Xent 0.0006(0.0027) | Loss 3.4657(3.4773) | Error 0.0000(0.0006) Steps 964(961.94) | Grad Norm 0.5768(0.8326) | Total Time 14.00(14.00)\n",
      "Iter 27660 | Time 24.3075(24.4936) | Bit/dim 3.4692(3.4752) | Xent 0.0003(0.0026) | Loss 3.4694(3.4765) | Error 0.0000(0.0006) Steps 964(961.39) | Grad Norm 0.4338(0.8076) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0503 | Time 114.5475, Epoch Time 1480.8770(1482.6797), Bit/dim 3.5010(best: 3.5024), Xent 2.9266, Loss 4.9643, Error 0.3460(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27670 | Time 24.2579(24.4582) | Bit/dim 3.4908(3.4764) | Xent 0.0011(0.0027) | Loss 3.4913(3.4778) | Error 0.0000(0.0007) Steps 946(959.84) | Grad Norm 0.3906(0.8074) | Total Time 14.00(14.00)\n",
      "Iter 27680 | Time 24.1709(24.5191) | Bit/dim 3.4791(3.4772) | Xent 0.0031(0.0030) | Loss 3.4807(3.4787) | Error 0.0011(0.0008) Steps 952(960.26) | Grad Norm 0.8403(0.8229) | Total Time 14.00(14.00)\n",
      "Iter 27690 | Time 24.5055(24.4989) | Bit/dim 3.4859(3.4756) | Xent 0.0017(0.0029) | Loss 3.4868(3.4771) | Error 0.0000(0.0007) Steps 946(959.18) | Grad Norm 0.7540(0.8453) | Total Time 14.00(14.00)\n",
      "Iter 27700 | Time 24.6205(24.4840) | Bit/dim 3.4840(3.4749) | Xent 0.0023(0.0028) | Loss 3.4852(3.4763) | Error 0.0011(0.0007) Steps 946(959.87) | Grad Norm 1.5070(0.8841) | Total Time 14.00(14.00)\n",
      "Iter 27710 | Time 24.1901(24.4622) | Bit/dim 3.4590(3.4726) | Xent 0.0004(0.0027) | Loss 3.4592(3.4739) | Error 0.0000(0.0007) Steps 964(959.92) | Grad Norm 0.4540(0.8741) | Total Time 14.00(14.00)\n",
      "Iter 27720 | Time 23.8649(24.4798) | Bit/dim 3.4722(3.4750) | Xent 0.0007(0.0027) | Loss 3.4726(3.4764) | Error 0.0000(0.0007) Steps 976(961.19) | Grad Norm 0.5974(0.8746) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0504 | Time 114.5251, Epoch Time 1478.3731(1482.5505), Bit/dim 3.5037(best: 3.5010), Xent 2.9385, Loss 4.9730, Error 0.3433(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27730 | Time 24.6524(24.4881) | Bit/dim 3.4540(3.4738) | Xent 0.0018(0.0028) | Loss 3.4549(3.4752) | Error 0.0011(0.0008) Steps 964(961.05) | Grad Norm 0.7566(0.9495) | Total Time 14.00(14.00)\n",
      "Iter 27740 | Time 25.0902(24.5431) | Bit/dim 3.4703(3.4780) | Xent 0.0083(0.0037) | Loss 3.4745(3.4799) | Error 0.0011(0.0009) Steps 964(961.44) | Grad Norm 0.9464(0.9820) | Total Time 14.00(14.00)\n",
      "Iter 27750 | Time 24.0533(24.5344) | Bit/dim 3.4412(3.4770) | Xent 0.0044(0.0036) | Loss 3.4435(3.4788) | Error 0.0011(0.0009) Steps 970(960.66) | Grad Norm 0.9265(0.9828) | Total Time 14.00(14.00)\n",
      "Iter 27760 | Time 24.2408(24.4589) | Bit/dim 3.4612(3.4759) | Xent 0.0095(0.0038) | Loss 3.4660(3.4778) | Error 0.0022(0.0010) Steps 970(959.24) | Grad Norm 2.2320(1.0297) | Total Time 14.00(14.00)\n",
      "Iter 27770 | Time 24.3630(24.4253) | Bit/dim 3.4792(3.4728) | Xent 0.0087(0.0041) | Loss 3.4836(3.4748) | Error 0.0033(0.0011) Steps 940(957.46) | Grad Norm 1.3670(1.0644) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0505 | Time 114.9094, Epoch Time 1474.7759(1482.3173), Bit/dim 3.5043(best: 3.5010), Xent 2.8932, Loss 4.9509, Error 0.3421(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27780 | Time 23.5814(24.3412) | Bit/dim 3.4623(3.4718) | Xent 0.0017(0.0035) | Loss 3.4632(3.4735) | Error 0.0000(0.0010) Steps 964(958.47) | Grad Norm 0.7017(1.0305) | Total Time 14.00(14.00)\n",
      "Iter 27790 | Time 24.5668(24.3684) | Bit/dim 3.4383(3.4708) | Xent 0.0047(0.0038) | Loss 3.4407(3.4727) | Error 0.0011(0.0009) Steps 958(959.98) | Grad Norm 0.9354(0.9872) | Total Time 14.00(14.00)\n",
      "Iter 27800 | Time 24.4973(24.3770) | Bit/dim 3.4870(3.4717) | Xent 0.0096(0.0041) | Loss 3.4918(3.4737) | Error 0.0022(0.0010) Steps 970(958.11) | Grad Norm 1.2941(0.9820) | Total Time 14.00(14.00)\n",
      "Iter 27810 | Time 24.6849(24.3504) | Bit/dim 3.4566(3.4733) | Xent 0.0041(0.0035) | Loss 3.4587(3.4751) | Error 0.0011(0.0009) Steps 958(958.29) | Grad Norm 0.7881(0.9084) | Total Time 14.00(14.00)\n",
      "Iter 27820 | Time 24.1770(24.3116) | Bit/dim 3.4797(3.4739) | Xent 0.0004(0.0033) | Loss 3.4799(3.4755) | Error 0.0000(0.0008) Steps 946(957.66) | Grad Norm 0.3427(0.8437) | Total Time 14.00(14.00)\n",
      "Iter 27830 | Time 25.0254(24.3833) | Bit/dim 3.4772(3.4770) | Xent 0.0008(0.0030) | Loss 3.4775(3.4785) | Error 0.0000(0.0008) Steps 946(958.60) | Grad Norm 0.3392(0.8217) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0506 | Time 115.3496, Epoch Time 1473.2942(1482.0466), Bit/dim 3.5027(best: 3.5010), Xent 2.9214, Loss 4.9634, Error 0.3456(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27840 | Time 24.5555(24.4290) | Bit/dim 3.5139(3.4780) | Xent 0.0041(0.0029) | Loss 3.5160(3.4795) | Error 0.0011(0.0008) Steps 964(959.62) | Grad Norm 0.7364(0.8153) | Total Time 14.00(14.00)\n",
      "Iter 27850 | Time 24.6015(24.4024) | Bit/dim 3.4568(3.4779) | Xent 0.0038(0.0028) | Loss 3.4588(3.4793) | Error 0.0011(0.0007) Steps 952(960.34) | Grad Norm 0.7401(0.7674) | Total Time 14.00(14.00)\n",
      "Iter 27860 | Time 24.5183(24.3759) | Bit/dim 3.5023(3.4782) | Xent 0.0062(0.0031) | Loss 3.5054(3.4797) | Error 0.0022(0.0008) Steps 976(961.21) | Grad Norm 1.0528(0.7781) | Total Time 14.00(14.00)\n",
      "Iter 27870 | Time 24.9634(24.4989) | Bit/dim 3.4834(3.4787) | Xent 0.0065(0.0029) | Loss 3.4867(3.4802) | Error 0.0011(0.0007) Steps 976(961.29) | Grad Norm 1.8527(0.8478) | Total Time 14.00(14.00)\n",
      "Iter 27880 | Time 24.9333(24.5296) | Bit/dim 3.4732(3.4741) | Xent 0.0007(0.0028) | Loss 3.4735(3.4755) | Error 0.0000(0.0007) Steps 964(960.87) | Grad Norm 0.5287(0.8808) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0507 | Time 114.5246, Epoch Time 1482.5095(1482.0605), Bit/dim 3.5029(best: 3.5010), Xent 2.9464, Loss 4.9761, Error 0.3486(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27890 | Time 24.4901(24.5369) | Bit/dim 3.4546(3.4726) | Xent 0.0207(0.0039) | Loss 3.4650(3.4746) | Error 0.0033(0.0009) Steps 946(960.86) | Grad Norm 1.3137(0.9450) | Total Time 14.00(14.00)\n",
      "Iter 27900 | Time 25.0523(24.5879) | Bit/dim 3.4836(3.4767) | Xent 0.0039(0.0042) | Loss 3.4856(3.4788) | Error 0.0011(0.0010) Steps 964(960.41) | Grad Norm 1.4595(1.0924) | Total Time 14.00(14.00)\n",
      "Iter 27910 | Time 24.8065(24.5444) | Bit/dim 3.4591(3.4747) | Xent 0.0051(0.0041) | Loss 3.4617(3.4767) | Error 0.0011(0.0011) Steps 958(959.27) | Grad Norm 1.1607(1.0965) | Total Time 14.00(14.00)\n",
      "Iter 27920 | Time 24.1920(24.5280) | Bit/dim 3.4973(3.4752) | Xent 0.0003(0.0037) | Loss 3.4974(3.4771) | Error 0.0000(0.0010) Steps 946(959.08) | Grad Norm 0.6413(1.0510) | Total Time 14.00(14.00)\n",
      "Iter 27930 | Time 24.8419(24.5354) | Bit/dim 3.4756(3.4745) | Xent 0.0149(0.0042) | Loss 3.4831(3.4766) | Error 0.0022(0.0011) Steps 964(959.67) | Grad Norm 2.3293(1.1338) | Total Time 14.00(14.00)\n",
      "Iter 27940 | Time 24.2960(24.5261) | Bit/dim 3.4631(3.4746) | Xent 0.0014(0.0041) | Loss 3.4638(3.4767) | Error 0.0000(0.0011) Steps 952(958.63) | Grad Norm 1.1177(1.1746) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0508 | Time 116.2282, Epoch Time 1482.9571(1482.0874), Bit/dim 3.5050(best: 3.5010), Xent 2.9489, Loss 4.9794, Error 0.3411(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 27950 | Time 24.8056(24.5265) | Bit/dim 3.5240(3.4780) | Xent 0.0053(0.0045) | Loss 3.5267(3.4803) | Error 0.0022(0.0013) Steps 958(958.37) | Grad Norm 2.0634(1.3056) | Total Time 14.00(14.00)\n",
      "Iter 27960 | Time 25.5906(24.5862) | Bit/dim 3.4828(3.4781) | Xent 0.0030(0.0047) | Loss 3.4843(3.4805) | Error 0.0011(0.0013) Steps 970(958.97) | Grad Norm 1.3413(1.3194) | Total Time 14.00(14.00)\n",
      "Iter 27970 | Time 24.6786(24.5921) | Bit/dim 3.4584(3.4761) | Xent 0.0035(0.0046) | Loss 3.4602(3.4784) | Error 0.0011(0.0014) Steps 946(957.68) | Grad Norm 1.2279(1.3618) | Total Time 14.00(14.00)\n",
      "Iter 27980 | Time 24.6134(24.6221) | Bit/dim 3.4787(3.4776) | Xent 0.0008(0.0046) | Loss 3.4791(3.4799) | Error 0.0000(0.0015) Steps 958(958.07) | Grad Norm 0.7107(1.2912) | Total Time 14.00(14.00)\n",
      "Iter 27990 | Time 24.8198(24.5909) | Bit/dim 3.4331(3.4764) | Xent 0.0024(0.0041) | Loss 3.4342(3.4785) | Error 0.0011(0.0013) Steps 964(957.95) | Grad Norm 1.0526(1.1691) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0509 | Time 116.1987, Epoch Time 1487.8731(1482.2610), Bit/dim 3.5047(best: 3.5010), Xent 2.9202, Loss 4.9648, Error 0.3522(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28000 | Time 24.3577(24.6005) | Bit/dim 3.4880(3.4752) | Xent 0.0039(0.0043) | Loss 3.4900(3.4774) | Error 0.0011(0.0013) Steps 964(958.77) | Grad Norm 1.0076(1.1809) | Total Time 14.00(14.00)\n",
      "Iter 28010 | Time 24.9661(24.5831) | Bit/dim 3.4851(3.4748) | Xent 0.0011(0.0041) | Loss 3.4856(3.4768) | Error 0.0000(0.0011) Steps 952(960.08) | Grad Norm 0.7233(1.1202) | Total Time 14.00(14.00)\n",
      "Iter 28020 | Time 24.7858(24.5756) | Bit/dim 3.4404(3.4728) | Xent 0.0063(0.0036) | Loss 3.4435(3.4746) | Error 0.0022(0.0010) Steps 964(959.43) | Grad Norm 2.1654(1.1512) | Total Time 14.00(14.00)\n",
      "Iter 28030 | Time 24.8750(24.6151) | Bit/dim 3.4709(3.4736) | Xent 0.0017(0.0035) | Loss 3.4717(3.4753) | Error 0.0011(0.0009) Steps 958(961.11) | Grad Norm 0.6712(1.0623) | Total Time 14.00(14.00)\n",
      "Iter 28040 | Time 24.1502(24.7259) | Bit/dim 3.4838(3.4742) | Xent 0.0018(0.0034) | Loss 3.4847(3.4759) | Error 0.0000(0.0010) Steps 958(962.88) | Grad Norm 0.7234(1.0820) | Total Time 14.00(14.00)\n",
      "Iter 28050 | Time 24.9998(24.7597) | Bit/dim 3.5075(3.4755) | Xent 0.0010(0.0032) | Loss 3.5080(3.4771) | Error 0.0000(0.0009) Steps 964(964.88) | Grad Norm 0.5207(1.0279) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0510 | Time 116.0774, Epoch Time 1495.0213(1482.6438), Bit/dim 3.5023(best: 3.5010), Xent 2.9195, Loss 4.9620, Error 0.3492(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28060 | Time 25.4153(24.7416) | Bit/dim 3.5098(3.4741) | Xent 0.0011(0.0026) | Loss 3.5103(3.4754) | Error 0.0000(0.0007) Steps 970(964.24) | Grad Norm 0.5103(0.8968) | Total Time 14.00(14.00)\n",
      "Iter 28070 | Time 25.2822(24.7182) | Bit/dim 3.4354(3.4757) | Xent 0.0024(0.0029) | Loss 3.4366(3.4771) | Error 0.0011(0.0008) Steps 982(965.18) | Grad Norm 1.1539(0.9084) | Total Time 14.00(14.00)\n",
      "Iter 28080 | Time 24.5900(24.6580) | Bit/dim 3.4502(3.4733) | Xent 0.0004(0.0028) | Loss 3.4503(3.4747) | Error 0.0000(0.0008) Steps 970(963.67) | Grad Norm 0.2563(0.8779) | Total Time 14.00(14.00)\n",
      "Iter 28090 | Time 24.5875(24.6735) | Bit/dim 3.4521(3.4775) | Xent 0.0003(0.0026) | Loss 3.4523(3.4789) | Error 0.0000(0.0007) Steps 946(962.48) | Grad Norm 0.4273(0.8361) | Total Time 14.00(14.00)\n",
      "Iter 28100 | Time 24.7979(24.6245) | Bit/dim 3.4538(3.4747) | Xent 0.0008(0.0025) | Loss 3.4542(3.4760) | Error 0.0000(0.0007) Steps 958(962.31) | Grad Norm 0.5000(0.8357) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0511 | Time 115.8091, Epoch Time 1487.6249(1482.7932), Bit/dim 3.5033(best: 3.5010), Xent 2.9728, Loss 4.9897, Error 0.3497(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28110 | Time 24.8877(24.6392) | Bit/dim 3.4423(3.4724) | Xent 0.0003(0.0022) | Loss 3.4424(3.4735) | Error 0.0000(0.0007) Steps 958(962.19) | Grad Norm 0.4977(0.8512) | Total Time 14.00(14.00)\n",
      "Iter 28120 | Time 23.8185(24.5988) | Bit/dim 3.4845(3.4720) | Xent 0.0019(0.0023) | Loss 3.4855(3.4732) | Error 0.0000(0.0006) Steps 952(962.61) | Grad Norm 0.6806(0.8900) | Total Time 14.00(14.00)\n",
      "Iter 28130 | Time 24.0960(24.6193) | Bit/dim 3.4564(3.4723) | Xent 0.0028(0.0023) | Loss 3.4578(3.4734) | Error 0.0011(0.0006) Steps 952(962.11) | Grad Norm 0.6743(0.8390) | Total Time 14.00(14.00)\n",
      "Iter 28140 | Time 24.2675(24.6107) | Bit/dim 3.4703(3.4723) | Xent 0.0010(0.0021) | Loss 3.4707(3.4734) | Error 0.0000(0.0005) Steps 964(962.65) | Grad Norm 0.4121(0.8158) | Total Time 14.00(14.00)\n",
      "Iter 28150 | Time 25.0577(24.5631) | Bit/dim 3.4800(3.4737) | Xent 0.0072(0.0025) | Loss 3.4836(3.4749) | Error 0.0044(0.0007) Steps 976(962.72) | Grad Norm 1.3511(0.8428) | Total Time 14.00(14.00)\n",
      "Iter 28160 | Time 24.8495(24.6375) | Bit/dim 3.4763(3.4749) | Xent 0.0004(0.0025) | Loss 3.4765(3.4761) | Error 0.0000(0.0006) Steps 964(962.94) | Grad Norm 0.5980(0.8281) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0512 | Time 115.1936, Epoch Time 1487.0942(1482.9222), Bit/dim 3.5044(best: 3.5010), Xent 3.0128, Loss 5.0108, Error 0.3528(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28170 | Time 24.4285(24.5976) | Bit/dim 3.4745(3.4734) | Xent 0.0024(0.0029) | Loss 3.4757(3.4748) | Error 0.0000(0.0007) Steps 970(962.52) | Grad Norm 0.8350(0.9667) | Total Time 14.00(14.00)\n",
      "Iter 28180 | Time 24.1985(24.5723) | Bit/dim 3.4766(3.4755) | Xent 0.0198(0.0038) | Loss 3.4865(3.4774) | Error 0.0022(0.0009) Steps 964(962.05) | Grad Norm 1.5109(1.1064) | Total Time 14.00(14.00)\n",
      "Iter 28190 | Time 24.7778(24.5642) | Bit/dim 3.4715(3.4755) | Xent 0.0201(0.0042) | Loss 3.4816(3.4776) | Error 0.0033(0.0010) Steps 958(963.50) | Grad Norm 1.5765(1.1094) | Total Time 14.00(14.00)\n",
      "Iter 28200 | Time 24.6542(24.6041) | Bit/dim 3.4689(3.4762) | Xent 0.0104(0.0047) | Loss 3.4741(3.4786) | Error 0.0011(0.0011) Steps 964(963.53) | Grad Norm 1.0956(1.0693) | Total Time 14.00(14.00)\n",
      "Iter 28210 | Time 24.9320(24.6010) | Bit/dim 3.4801(3.4761) | Xent 0.0014(0.0045) | Loss 3.4808(3.4783) | Error 0.0011(0.0011) Steps 976(962.73) | Grad Norm 0.4735(1.0188) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0513 | Time 115.2936, Epoch Time 1486.3895(1483.0263), Bit/dim 3.5054(best: 3.5010), Xent 2.9784, Loss 4.9946, Error 0.3508(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28220 | Time 24.6953(24.6204) | Bit/dim 3.4970(3.4753) | Xent 0.0024(0.0050) | Loss 3.4983(3.4778) | Error 0.0022(0.0014) Steps 958(963.16) | Grad Norm 1.1057(1.0884) | Total Time 14.00(14.00)\n",
      "Iter 28230 | Time 24.6630(24.6319) | Bit/dim 3.4669(3.4730) | Xent 0.0027(0.0048) | Loss 3.4683(3.4753) | Error 0.0011(0.0013) Steps 946(963.37) | Grad Norm 0.7720(1.0830) | Total Time 14.00(14.00)\n",
      "Iter 28240 | Time 24.7833(24.6919) | Bit/dim 3.4604(3.4741) | Xent 0.0007(0.0046) | Loss 3.4608(3.4764) | Error 0.0000(0.0012) Steps 958(964.20) | Grad Norm 0.8806(1.0928) | Total Time 14.00(14.00)\n",
      "Iter 28250 | Time 24.3418(24.6750) | Bit/dim 3.4873(3.4764) | Xent 0.0044(0.0045) | Loss 3.4895(3.4786) | Error 0.0022(0.0013) Steps 958(963.36) | Grad Norm 1.3617(1.1355) | Total Time 14.00(14.00)\n",
      "Iter 28260 | Time 23.6921(24.6023) | Bit/dim 3.4708(3.4755) | Xent 0.0039(0.0042) | Loss 3.4727(3.4776) | Error 0.0011(0.0012) Steps 958(963.49) | Grad Norm 1.0400(1.0964) | Total Time 14.00(14.00)\n",
      "Iter 28270 | Time 24.3680(24.6071) | Bit/dim 3.4650(3.4760) | Xent 0.0006(0.0037) | Loss 3.4653(3.4778) | Error 0.0000(0.0010) Steps 970(963.09) | Grad Norm 0.4099(1.0209) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0514 | Time 115.7948, Epoch Time 1489.1631(1483.2104), Bit/dim 3.5025(best: 3.5010), Xent 2.9788, Loss 4.9919, Error 0.3499(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28280 | Time 24.1242(24.5498) | Bit/dim 3.4708(3.4763) | Xent 0.0014(0.0033) | Loss 3.4715(3.4779) | Error 0.0000(0.0009) Steps 952(961.82) | Grad Norm 0.4734(0.9335) | Total Time 14.00(14.00)\n",
      "Iter 28290 | Time 24.0639(24.4745) | Bit/dim 3.4968(3.4742) | Xent 0.0059(0.0033) | Loss 3.4998(3.4758) | Error 0.0022(0.0009) Steps 964(962.15) | Grad Norm 1.0407(0.8830) | Total Time 14.00(14.00)\n",
      "Iter 28300 | Time 24.5379(24.4768) | Bit/dim 3.4883(3.4732) | Xent 0.0020(0.0031) | Loss 3.4893(3.4747) | Error 0.0011(0.0009) Steps 970(962.63) | Grad Norm 0.6539(0.8177) | Total Time 14.00(14.00)\n",
      "Iter 28310 | Time 24.0008(24.4758) | Bit/dim 3.4954(3.4738) | Xent 0.0034(0.0029) | Loss 3.4971(3.4753) | Error 0.0022(0.0008) Steps 976(963.23) | Grad Norm 1.5767(0.7691) | Total Time 14.00(14.00)\n",
      "Iter 28320 | Time 24.1065(24.4707) | Bit/dim 3.4902(3.4742) | Xent 0.0029(0.0037) | Loss 3.4916(3.4761) | Error 0.0011(0.0009) Steps 970(964.08) | Grad Norm 1.6085(0.9158) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0515 | Time 115.7352, Epoch Time 1478.5922(1483.0718), Bit/dim 3.5046(best: 3.5010), Xent 2.9240, Loss 4.9666, Error 0.3451(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28330 | Time 24.4693(24.4709) | Bit/dim 3.4570(3.4738) | Xent 0.0020(0.0036) | Loss 3.4580(3.4756) | Error 0.0011(0.0009) Steps 988(963.24) | Grad Norm 0.6921(0.8915) | Total Time 14.00(14.00)\n",
      "Iter 28340 | Time 24.6827(24.4247) | Bit/dim 3.4934(3.4756) | Xent 0.0018(0.0043) | Loss 3.4943(3.4777) | Error 0.0011(0.0011) Steps 964(961.68) | Grad Norm 1.0353(0.9461) | Total Time 14.00(14.00)\n",
      "Iter 28350 | Time 24.2531(24.4129) | Bit/dim 3.4892(3.4734) | Xent 0.0058(0.0041) | Loss 3.4921(3.4754) | Error 0.0011(0.0011) Steps 946(960.60) | Grad Norm 1.4990(0.9440) | Total Time 14.00(14.00)\n",
      "Iter 28360 | Time 24.5384(24.4186) | Bit/dim 3.4924(3.4734) | Xent 0.0069(0.0039) | Loss 3.4959(3.4754) | Error 0.0022(0.0010) Steps 970(961.66) | Grad Norm 1.9736(0.9557) | Total Time 14.00(14.00)\n",
      "Iter 28370 | Time 24.7734(24.5296) | Bit/dim 3.4697(3.4741) | Xent 0.0072(0.0039) | Loss 3.4733(3.4760) | Error 0.0011(0.0010) Steps 952(962.11) | Grad Norm 1.8494(1.0162) | Total Time 14.00(14.00)\n",
      "Iter 28380 | Time 24.0382(24.5101) | Bit/dim 3.4750(3.4754) | Xent 0.0091(0.0044) | Loss 3.4796(3.4776) | Error 0.0011(0.0011) Steps 940(961.24) | Grad Norm 1.0282(1.1027) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0516 | Time 114.0550, Epoch Time 1477.9817(1482.9191), Bit/dim 3.5052(best: 3.5010), Xent 2.9342, Loss 4.9723, Error 0.3468(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28390 | Time 24.8170(24.5364) | Bit/dim 3.4887(3.4740) | Xent 0.0057(0.0045) | Loss 3.4915(3.4762) | Error 0.0022(0.0012) Steps 982(961.09) | Grad Norm 2.8284(1.1574) | Total Time 14.00(14.00)\n",
      "Iter 28400 | Time 24.2246(24.6065) | Bit/dim 3.4489(3.4740) | Xent 0.0009(0.0044) | Loss 3.4494(3.4762) | Error 0.0000(0.0011) Steps 976(961.52) | Grad Norm 0.8656(1.2255) | Total Time 14.00(14.00)\n",
      "Iter 28410 | Time 25.0137(24.5410) | Bit/dim 3.4623(3.4761) | Xent 0.0108(0.0048) | Loss 3.4677(3.4785) | Error 0.0011(0.0012) Steps 964(961.76) | Grad Norm 0.8586(1.2199) | Total Time 14.00(14.00)\n",
      "Iter 28420 | Time 25.0410(24.5873) | Bit/dim 3.4928(3.4748) | Xent 0.0114(0.0047) | Loss 3.4985(3.4772) | Error 0.0033(0.0012) Steps 970(960.83) | Grad Norm 2.6932(1.3585) | Total Time 14.00(14.00)\n",
      "Iter 28430 | Time 24.3769(24.6113) | Bit/dim 3.4663(3.4772) | Xent 0.0022(0.0043) | Loss 3.4674(3.4794) | Error 0.0011(0.0011) Steps 952(961.29) | Grad Norm 0.9875(1.3157) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0517 | Time 115.3115, Epoch Time 1488.3360(1483.0816), Bit/dim 3.5045(best: 3.5010), Xent 2.9559, Loss 4.9825, Error 0.3453(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28440 | Time 24.8575(24.6150) | Bit/dim 3.4451(3.4760) | Xent 0.0024(0.0040) | Loss 3.4463(3.4780) | Error 0.0000(0.0011) Steps 964(959.49) | Grad Norm 1.3009(1.2805) | Total Time 14.00(14.00)\n",
      "Iter 28450 | Time 24.2340(24.6334) | Bit/dim 3.4651(3.4775) | Xent 0.0008(0.0047) | Loss 3.4655(3.4798) | Error 0.0000(0.0012) Steps 976(960.88) | Grad Norm 1.4335(1.3477) | Total Time 14.00(14.00)\n",
      "Iter 28460 | Time 24.9354(24.6869) | Bit/dim 3.4807(3.4772) | Xent 0.0087(0.0044) | Loss 3.4851(3.4794) | Error 0.0022(0.0012) Steps 976(962.10) | Grad Norm 1.3388(1.2935) | Total Time 14.00(14.00)\n",
      "Iter 28470 | Time 23.9155(24.6617) | Bit/dim 3.4575(3.4767) | Xent 0.0009(0.0035) | Loss 3.4579(3.4784) | Error 0.0000(0.0009) Steps 964(962.69) | Grad Norm 0.6633(1.1094) | Total Time 14.00(14.00)\n",
      "Iter 28480 | Time 24.1941(24.6228) | Bit/dim 3.4523(3.4750) | Xent 0.0007(0.0035) | Loss 3.4526(3.4768) | Error 0.0000(0.0008) Steps 976(962.97) | Grad Norm 0.3781(0.9544) | Total Time 14.00(14.00)\n",
      "Iter 28490 | Time 25.1223(24.6222) | Bit/dim 3.4629(3.4746) | Xent 0.0029(0.0030) | Loss 3.4644(3.4761) | Error 0.0011(0.0007) Steps 958(963.34) | Grad Norm 0.6445(0.8693) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0518 | Time 116.5666, Epoch Time 1489.7461(1483.2816), Bit/dim 3.5018(best: 3.5010), Xent 2.9479, Loss 4.9757, Error 0.3502(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28500 | Time 24.5880(24.6369) | Bit/dim 3.4859(3.4749) | Xent 0.0014(0.0033) | Loss 3.4866(3.4765) | Error 0.0000(0.0008) Steps 958(962.63) | Grad Norm 0.6110(0.8663) | Total Time 14.00(14.00)\n",
      "Iter 28510 | Time 24.3402(24.5524) | Bit/dim 3.4766(3.4752) | Xent 0.0093(0.0039) | Loss 3.4813(3.4772) | Error 0.0033(0.0010) Steps 958(961.57) | Grad Norm 1.5791(0.9098) | Total Time 14.00(14.00)\n",
      "Iter 28520 | Time 24.0378(24.5150) | Bit/dim 3.4673(3.4737) | Xent 0.0014(0.0040) | Loss 3.4680(3.4757) | Error 0.0011(0.0010) Steps 958(959.83) | Grad Norm 0.9099(0.8980) | Total Time 14.00(14.00)\n",
      "Iter 28530 | Time 24.4275(24.5158) | Bit/dim 3.4917(3.4750) | Xent 0.0025(0.0032) | Loss 3.4929(3.4766) | Error 0.0011(0.0008) Steps 970(961.90) | Grad Norm 0.5063(0.7939) | Total Time 14.00(14.00)\n",
      "Iter 28540 | Time 24.5581(24.5565) | Bit/dim 3.4801(3.4732) | Xent 0.0005(0.0035) | Loss 3.4803(3.4749) | Error 0.0000(0.0009) Steps 970(961.48) | Grad Norm 0.4089(0.8416) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0519 | Time 116.9848, Epoch Time 1483.8786(1483.2995), Bit/dim 3.5033(best: 3.5010), Xent 2.9426, Loss 4.9746, Error 0.3490(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28550 | Time 23.4789(24.5166) | Bit/dim 3.4980(3.4762) | Xent 0.0024(0.0033) | Loss 3.4992(3.4779) | Error 0.0011(0.0009) Steps 970(962.79) | Grad Norm 0.8718(0.8676) | Total Time 14.00(14.00)\n",
      "Iter 28560 | Time 24.5826(24.5065) | Bit/dim 3.4888(3.4749) | Xent 0.0031(0.0030) | Loss 3.4903(3.4764) | Error 0.0022(0.0009) Steps 970(963.25) | Grad Norm 1.0101(0.8709) | Total Time 14.00(14.00)\n",
      "Iter 28570 | Time 24.7801(24.4738) | Bit/dim 3.4375(3.4741) | Xent 0.0005(0.0037) | Loss 3.4378(3.4760) | Error 0.0000(0.0010) Steps 958(962.95) | Grad Norm 0.6831(0.9193) | Total Time 14.00(14.00)\n",
      "Iter 28580 | Time 24.5963(24.4059) | Bit/dim 3.4361(3.4724) | Xent 0.0048(0.0031) | Loss 3.4385(3.4740) | Error 0.0022(0.0008) Steps 958(962.57) | Grad Norm 1.6164(0.8690) | Total Time 14.00(14.00)\n",
      "Iter 28590 | Time 24.4210(24.4648) | Bit/dim 3.4955(3.4719) | Xent 0.0093(0.0031) | Loss 3.5002(3.4734) | Error 0.0022(0.0009) Steps 970(961.77) | Grad Norm 1.2446(0.8307) | Total Time 14.00(14.00)\n",
      "Iter 28600 | Time 24.5670(24.4982) | Bit/dim 3.4746(3.4735) | Xent 0.0026(0.0027) | Loss 3.4759(3.4749) | Error 0.0011(0.0008) Steps 940(962.15) | Grad Norm 0.9760(0.8212) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0520 | Time 116.3845, Epoch Time 1479.1886(1483.1761), Bit/dim 3.5014(best: 3.5010), Xent 2.9785, Loss 4.9906, Error 0.3484(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28610 | Time 24.4972(24.4592) | Bit/dim 3.4793(3.4756) | Xent 0.0040(0.0030) | Loss 3.4813(3.4771) | Error 0.0011(0.0009) Steps 970(962.95) | Grad Norm 1.2673(0.8337) | Total Time 14.00(14.00)\n",
      "Iter 28620 | Time 24.6715(24.5271) | Bit/dim 3.4654(3.4753) | Xent 0.0054(0.0035) | Loss 3.4681(3.4770) | Error 0.0011(0.0010) Steps 958(963.16) | Grad Norm 2.3187(0.8980) | Total Time 14.00(14.00)\n",
      "Iter 28630 | Time 24.4571(24.5511) | Bit/dim 3.4899(3.4734) | Xent 0.0068(0.0043) | Loss 3.4933(3.4756) | Error 0.0022(0.0012) Steps 976(963.76) | Grad Norm 0.8939(1.0271) | Total Time 14.00(14.00)\n",
      "Iter 28640 | Time 25.0847(24.5702) | Bit/dim 3.4903(3.4739) | Xent 0.0191(0.0049) | Loss 3.4999(3.4763) | Error 0.0067(0.0014) Steps 952(964.33) | Grad Norm 3.3131(1.1672) | Total Time 14.00(14.00)\n",
      "Iter 28650 | Time 23.7750(24.6009) | Bit/dim 3.4460(3.4741) | Xent 0.0006(0.0047) | Loss 3.4463(3.4764) | Error 0.0000(0.0013) Steps 940(962.65) | Grad Norm 0.5089(1.1819) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0521 | Time 115.4286, Epoch Time 1484.1335(1483.2049), Bit/dim 3.5040(best: 3.5010), Xent 2.9275, Loss 4.9677, Error 0.3460(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28660 | Time 24.3470(24.5026) | Bit/dim 3.4658(3.4737) | Xent 0.0008(0.0044) | Loss 3.4662(3.4759) | Error 0.0000(0.0012) Steps 970(962.51) | Grad Norm 0.6794(1.0997) | Total Time 14.00(14.00)\n",
      "Iter 28670 | Time 24.9574(24.5299) | Bit/dim 3.4765(3.4734) | Xent 0.0081(0.0043) | Loss 3.4805(3.4755) | Error 0.0022(0.0012) Steps 946(961.50) | Grad Norm 1.3219(1.0990) | Total Time 14.00(14.00)\n",
      "Iter 28680 | Time 24.3442(24.5165) | Bit/dim 3.4662(3.4726) | Xent 0.0117(0.0048) | Loss 3.4720(3.4750) | Error 0.0022(0.0013) Steps 964(961.46) | Grad Norm 1.4108(1.1303) | Total Time 14.00(14.00)\n",
      "Iter 28690 | Time 25.2851(24.5069) | Bit/dim 3.4704(3.4759) | Xent 0.0115(0.0049) | Loss 3.4762(3.4783) | Error 0.0033(0.0013) Steps 934(960.50) | Grad Norm 1.3987(1.1100) | Total Time 14.00(14.00)\n",
      "Iter 28700 | Time 24.5223(24.5564) | Bit/dim 3.4856(3.4760) | Xent 0.0033(0.0053) | Loss 3.4872(3.4786) | Error 0.0022(0.0014) Steps 958(960.55) | Grad Norm 0.8759(1.2028) | Total Time 14.00(14.00)\n",
      "Iter 28710 | Time 24.7694(24.5533) | Bit/dim 3.4649(3.4762) | Xent 0.0065(0.0057) | Loss 3.4682(3.4791) | Error 0.0011(0.0015) Steps 958(961.69) | Grad Norm 1.1417(1.2592) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0522 | Time 117.2275, Epoch Time 1485.1001(1483.2617), Bit/dim 3.5059(best: 3.5010), Xent 2.9455, Loss 4.9786, Error 0.3481(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28720 | Time 23.9410(24.4878) | Bit/dim 3.4541(3.4762) | Xent 0.0074(0.0057) | Loss 3.4578(3.4790) | Error 0.0022(0.0015) Steps 964(961.65) | Grad Norm 2.2825(1.2656) | Total Time 14.00(14.00)\n",
      "Iter 28730 | Time 24.5398(24.4030) | Bit/dim 3.4690(3.4764) | Xent 0.0010(0.0049) | Loss 3.4695(3.4789) | Error 0.0000(0.0015) Steps 964(960.26) | Grad Norm 0.9030(1.2134) | Total Time 14.00(14.00)\n",
      "Iter 28740 | Time 23.9029(24.2558) | Bit/dim 3.4690(3.4739) | Xent 0.0006(0.0045) | Loss 3.4693(3.4761) | Error 0.0000(0.0012) Steps 964(959.85) | Grad Norm 0.6305(1.1402) | Total Time 14.00(14.00)\n",
      "Iter 28750 | Time 23.8468(24.2635) | Bit/dim 3.4967(3.4758) | Xent 0.0130(0.0045) | Loss 3.5032(3.4780) | Error 0.0022(0.0012) Steps 964(960.38) | Grad Norm 1.5939(1.0598) | Total Time 14.00(14.00)\n",
      "Iter 28760 | Time 24.5672(24.2444) | Bit/dim 3.4954(3.4762) | Xent 0.0138(0.0042) | Loss 3.5023(3.4783) | Error 0.0033(0.0011) Steps 958(960.23) | Grad Norm 2.0800(0.9948) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0523 | Time 116.2139, Epoch Time 1462.8412(1482.6491), Bit/dim 3.5023(best: 3.5010), Xent 2.9375, Loss 4.9711, Error 0.3506(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28770 | Time 24.4778(24.2365) | Bit/dim 3.4711(3.4757) | Xent 0.0007(0.0037) | Loss 3.4715(3.4776) | Error 0.0000(0.0010) Steps 970(960.07) | Grad Norm 0.7125(0.9788) | Total Time 14.00(14.00)\n",
      "Iter 28780 | Time 23.9458(24.2880) | Bit/dim 3.4748(3.4744) | Xent 0.0015(0.0035) | Loss 3.4756(3.4761) | Error 0.0011(0.0009) Steps 952(958.92) | Grad Norm 0.7746(0.9313) | Total Time 14.00(14.00)\n",
      "Iter 28790 | Time 24.7653(24.3699) | Bit/dim 3.4676(3.4738) | Xent 0.0044(0.0032) | Loss 3.4698(3.4755) | Error 0.0011(0.0008) Steps 958(959.30) | Grad Norm 1.5193(0.9197) | Total Time 14.00(14.00)\n",
      "Iter 28800 | Time 25.0001(24.4140) | Bit/dim 3.4262(3.4740) | Xent 0.0006(0.0033) | Loss 3.4265(3.4756) | Error 0.0000(0.0009) Steps 946(958.83) | Grad Norm 0.6116(0.9377) | Total Time 14.00(14.00)\n",
      "Iter 28810 | Time 25.0133(24.4997) | Bit/dim 3.4903(3.4738) | Xent 0.0066(0.0032) | Loss 3.4936(3.4755) | Error 0.0033(0.0009) Steps 958(958.96) | Grad Norm 2.3102(0.9588) | Total Time 14.00(14.00)\n",
      "Iter 28820 | Time 23.6492(24.4435) | Bit/dim 3.4448(3.4740) | Xent 0.0160(0.0035) | Loss 3.4528(3.4757) | Error 0.0022(0.0009) Steps 964(958.24) | Grad Norm 1.4508(0.9884) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0524 | Time 115.5364, Epoch Time 1481.1446(1482.6040), Bit/dim 3.5034(best: 3.5010), Xent 2.9560, Loss 4.9814, Error 0.3473(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28830 | Time 24.1257(24.4001) | Bit/dim 3.5467(3.4752) | Xent 0.0007(0.0032) | Loss 3.5471(3.4767) | Error 0.0000(0.0008) Steps 952(957.39) | Grad Norm 0.3887(0.9403) | Total Time 14.00(14.00)\n",
      "Iter 28840 | Time 24.1143(24.3810) | Bit/dim 3.4527(3.4765) | Xent 0.0008(0.0033) | Loss 3.4531(3.4781) | Error 0.0000(0.0008) Steps 970(957.34) | Grad Norm 0.6474(0.9661) | Total Time 14.00(14.00)\n",
      "Iter 28850 | Time 24.8348(24.4612) | Bit/dim 3.4781(3.4754) | Xent 0.0012(0.0038) | Loss 3.4787(3.4773) | Error 0.0000(0.0009) Steps 952(958.36) | Grad Norm 1.0195(1.0351) | Total Time 14.00(14.00)\n",
      "Iter 28860 | Time 24.4536(24.5387) | Bit/dim 3.4733(3.4748) | Xent 0.0038(0.0044) | Loss 3.4752(3.4770) | Error 0.0022(0.0011) Steps 970(959.80) | Grad Norm 1.0865(1.1672) | Total Time 14.00(14.00)\n",
      "Iter 28870 | Time 24.3024(24.5332) | Bit/dim 3.4600(3.4732) | Xent 0.0016(0.0040) | Loss 3.4608(3.4753) | Error 0.0011(0.0011) Steps 976(959.93) | Grad Norm 0.9673(1.1615) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0525 | Time 114.2956, Epoch Time 1477.8541(1482.4615), Bit/dim 3.5034(best: 3.5010), Xent 2.8938, Loss 4.9503, Error 0.3426(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28880 | Time 23.9058(24.4183) | Bit/dim 3.4532(3.4731) | Xent 0.0003(0.0037) | Loss 3.4534(3.4749) | Error 0.0000(0.0010) Steps 946(959.25) | Grad Norm 0.8279(1.2468) | Total Time 14.00(14.00)\n",
      "Iter 28890 | Time 24.4209(24.3873) | Bit/dim 3.5125(3.4757) | Xent 0.0016(0.0040) | Loss 3.5133(3.4777) | Error 0.0000(0.0012) Steps 970(959.07) | Grad Norm 1.1252(1.3672) | Total Time 14.00(14.00)\n",
      "Iter 28900 | Time 24.2400(24.4200) | Bit/dim 3.4941(3.4768) | Xent 0.0029(0.0037) | Loss 3.4956(3.4786) | Error 0.0011(0.0011) Steps 946(959.57) | Grad Norm 0.9471(1.3236) | Total Time 14.00(14.00)\n",
      "Iter 28910 | Time 24.5008(24.4185) | Bit/dim 3.4968(3.4776) | Xent 0.0003(0.0032) | Loss 3.4969(3.4792) | Error 0.0000(0.0009) Steps 958(960.04) | Grad Norm 0.5894(1.2447) | Total Time 14.00(14.00)\n",
      "Iter 28920 | Time 24.2327(24.4037) | Bit/dim 3.4595(3.4771) | Xent 0.0015(0.0032) | Loss 3.4602(3.4787) | Error 0.0011(0.0009) Steps 964(960.49) | Grad Norm 0.6566(1.1030) | Total Time 14.00(14.00)\n",
      "Iter 28930 | Time 24.4390(24.3583) | Bit/dim 3.4530(3.4744) | Xent 0.0077(0.0030) | Loss 3.4568(3.4759) | Error 0.0022(0.0008) Steps 970(958.48) | Grad Norm 1.6787(1.0347) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0526 | Time 114.6996, Epoch Time 1471.9845(1482.1472), Bit/dim 3.5016(best: 3.5010), Xent 2.9640, Loss 4.9836, Error 0.3496(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28940 | Time 24.7277(24.3535) | Bit/dim 3.4691(3.4770) | Xent 0.0038(0.0027) | Loss 3.4710(3.4784) | Error 0.0011(0.0008) Steps 940(956.23) | Grad Norm 1.3166(0.9717) | Total Time 14.00(14.00)\n",
      "Iter 28950 | Time 24.5828(24.3988) | Bit/dim 3.4621(3.4748) | Xent 0.0017(0.0026) | Loss 3.4630(3.4761) | Error 0.0011(0.0008) Steps 970(957.04) | Grad Norm 1.2196(0.9490) | Total Time 14.00(14.00)\n",
      "Iter 28960 | Time 24.2271(24.3770) | Bit/dim 3.5048(3.4735) | Xent 0.0090(0.0029) | Loss 3.5093(3.4749) | Error 0.0011(0.0007) Steps 952(957.15) | Grad Norm 0.4933(0.8425) | Total Time 14.00(14.00)\n",
      "Iter 28970 | Time 25.4417(24.4009) | Bit/dim 3.4408(3.4718) | Xent 0.0079(0.0030) | Loss 3.4447(3.4733) | Error 0.0011(0.0006) Steps 976(959.03) | Grad Norm 0.7306(0.7454) | Total Time 14.00(14.00)\n",
      "Iter 28980 | Time 24.8285(24.4684) | Bit/dim 3.4494(3.4724) | Xent 0.0009(0.0027) | Loss 3.4498(3.4738) | Error 0.0000(0.0006) Steps 976(959.48) | Grad Norm 0.3377(0.6964) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0527 | Time 115.5576, Epoch Time 1478.5655(1482.0397), Bit/dim 3.5003(best: 3.5010), Xent 2.9746, Loss 4.9876, Error 0.3490(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 28990 | Time 24.3770(24.4684) | Bit/dim 3.4519(3.4718) | Xent 0.0009(0.0028) | Loss 3.4524(3.4732) | Error 0.0000(0.0007) Steps 946(958.34) | Grad Norm 0.4693(0.6979) | Total Time 14.00(14.00)\n",
      "Iter 29000 | Time 24.5142(24.4827) | Bit/dim 3.4908(3.4724) | Xent 0.0009(0.0027) | Loss 3.4912(3.4738) | Error 0.0000(0.0006) Steps 940(957.88) | Grad Norm 0.4912(0.7074) | Total Time 14.00(14.00)\n",
      "Iter 29010 | Time 24.4264(24.4690) | Bit/dim 3.4833(3.4721) | Xent 0.0129(0.0030) | Loss 3.4897(3.4737) | Error 0.0011(0.0007) Steps 946(957.17) | Grad Norm 0.7042(0.8083) | Total Time 14.00(14.00)\n",
      "Iter 29020 | Time 24.2009(24.4624) | Bit/dim 3.4758(3.4723) | Xent 0.0072(0.0037) | Loss 3.4794(3.4741) | Error 0.0011(0.0008) Steps 970(958.11) | Grad Norm 0.8082(0.8918) | Total Time 14.00(14.00)\n",
      "Iter 29030 | Time 24.1682(24.4791) | Bit/dim 3.4818(3.4758) | Xent 0.0014(0.0034) | Loss 3.4825(3.4775) | Error 0.0000(0.0007) Steps 958(960.42) | Grad Norm 0.6490(0.8746) | Total Time 14.00(14.00)\n",
      "Iter 29040 | Time 23.8960(24.4706) | Bit/dim 3.4499(3.4732) | Xent 0.0113(0.0041) | Loss 3.4556(3.4753) | Error 0.0022(0.0010) Steps 970(960.59) | Grad Norm 0.9687(0.9168) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0528 | Time 116.0234, Epoch Time 1480.9413(1482.0068), Bit/dim 3.5015(best: 3.5003), Xent 2.9717, Loss 4.9873, Error 0.3481(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 29050 | Time 24.5481(24.4850) | Bit/dim 3.4705(3.4711) | Xent 0.0060(0.0042) | Loss 3.4735(3.4732) | Error 0.0022(0.0010) Steps 976(963.34) | Grad Norm 1.3878(0.9942) | Total Time 14.00(14.00)\n",
      "Iter 29060 | Time 23.6938(24.4471) | Bit/dim 3.4756(3.4749) | Xent 0.0162(0.0043) | Loss 3.4837(3.4770) | Error 0.0033(0.0011) Steps 964(963.49) | Grad Norm 2.0222(1.0338) | Total Time 14.00(14.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_drop_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_cifar10_bs900_drop_0_5_run3 --resume ../experiments_published/cnf_conditional_cifar10_bs900_drop_0_5_run3/current_checkpt.pth --seed 3 --lr 0.0001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --dropout_rate 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
