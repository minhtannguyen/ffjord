{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, eta=0.1, gamma=0.99, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume=None, rl_weight=1.0, rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_rlw_1_0_run1', scale=1.0, scale_fac=1.0, scale_std=6.0, seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1450732\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 0010 | Time 12.4615(30.4992) | Bit/dim 8.6904(8.9519) | Xent 2.2804(2.3001) | Loss 1119.6396(1132.6657) | Error 0.8000(0.8600) Steps 0(0.00) | Grad Norm 1131.0482(1431.5100) | Total Time 0.00(0.00)\n",
      "Iter 0020 | Time 12.7146(25.9028) | Bit/dim 8.4870(8.8629) | Xent 2.2260(2.2873) | Loss 1095.5132(1121.3882) | Error 0.7244(0.8323) Steps 0(0.00) | Grad Norm 470.6037(1238.4834) | Total Time 0.00(0.00)\n",
      "Iter 0030 | Time 13.1664(22.4963) | Bit/dim 8.3929(8.7512) | Xent 2.1745(2.2633) | Loss 1112.4894(1109.6703) | Error 0.7533(0.8087) Steps 0(0.00) | Grad Norm 477.1085(1017.5150) | Total Time 0.00(0.00)\n",
      "Iter 0040 | Time 13.0264(19.9463) | Bit/dim 8.1909(8.6231) | Xent 2.1139(2.2346) | Loss 1056.2534(1096.5079) | Error 0.7256(0.7910) Steps 0(0.00) | Grad Norm 288.0361(835.4779) | Total Time 0.00(0.00)\n",
      "Iter 0050 | Time 12.3645(18.0437) | Bit/dim 7.9732(8.4735) | Xent 2.1020(2.2021) | Loss 1013.4117(1080.0222) | Error 0.7056(0.7751) Steps 0(0.00) | Grad Norm 279.1727(694.2145) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 79.4867, Epoch Time 829.5281(829.5281), Bit/dim 7.7693(best: inf), Xent 2.0784, Loss 8.8085, Error 0.7006(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0060 | Time 12.9997(16.7710) | Bit/dim 7.6769(8.2911) | Xent 2.0796(2.1722) | Loss 979.1630(1114.7513) | Error 0.6989(0.7585) Steps 0(0.00) | Grad Norm 287.8819(585.8395) | Total Time 0.00(0.00)\n",
      "Iter 0070 | Time 13.6342(15.8151) | Bit/dim 7.3714(8.0803) | Xent 2.0586(2.1465) | Loss 976.1266(1078.9683) | Error 0.6767(0.7420) Steps 0(0.00) | Grad Norm 210.7428(495.3561) | Total Time 0.00(0.00)\n",
      "Iter 0080 | Time 13.2089(15.1363) | Bit/dim 7.1863(7.8635) | Xent 2.0713(2.1260) | Loss 952.1948(1044.4149) | Error 0.6656(0.7266) Steps 0(0.00) | Grad Norm 172.7406(413.9789) | Total Time 0.00(0.00)\n",
      "Iter 0090 | Time 12.9911(14.6690) | Bit/dim 7.0825(7.6688) | Xent 2.0850(2.1131) | Loss 947.5218(1015.5022) | Error 0.7222(0.7177) Steps 0(0.00) | Grad Norm 108.5610(340.8500) | Total Time 0.00(0.00)\n",
      "Iter 0100 | Time 14.3998(14.3671) | Bit/dim 7.0017(7.5061) | Xent 2.0628(2.1035) | Loss 944.3789(993.1370) | Error 0.6911(0.7125) Steps 0(0.00) | Grad Norm 175.4896(291.9488) | Total Time 0.00(0.00)\n",
      "Iter 0110 | Time 13.9033(14.2098) | Bit/dim 7.0036(7.3753) | Xent 2.0591(2.0948) | Loss 953.8782(976.7067) | Error 0.7289(0.7130) Steps 0(0.00) | Grad Norm 126.0230(246.5774) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 77.6592, Epoch Time 830.8994(829.5692), Bit/dim 6.9922(best: 7.7693), Xent 2.0583, Loss 8.0213, Error 0.6948(best: 0.7006)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0120 | Time 14.8360(14.3098) | Bit/dim 6.9409(7.2695) | Xent 2.0535(2.0853) | Loss 910.5272(1017.2237) | Error 0.7122(0.7116) Steps 0(0.00) | Grad Norm 90.8705(216.6992) | Total Time 0.00(0.00)\n",
      "Iter 0130 | Time 14.8153(14.3832) | Bit/dim 6.9193(7.1828) | Xent 2.0419(2.0746) | Loss 928.0721(990.8292) | Error 0.6856(0.7064) Steps 0(0.00) | Grad Norm 146.8542(191.7912) | Total Time 0.00(0.00)\n",
      "Iter 0140 | Time 16.9509(14.4598) | Bit/dim 6.8947(7.1069) | Xent 2.0488(2.0648) | Loss 917.7133(969.9937) | Error 0.6944(0.7025) Steps 0(0.00) | Grad Norm 443.5181(200.4860) | Total Time 0.00(0.00)\n",
      "Iter 0150 | Time 15.6658(14.5698) | Bit/dim 6.7857(7.0356) | Xent 2.0152(2.0565) | Loss 878.5733(951.1381) | Error 0.7044(0.6996) Steps 0(0.00) | Grad Norm 224.4832(255.4548) | Total Time 0.00(0.00)\n",
      "Iter 0160 | Time 15.2241(14.6542) | Bit/dim 6.7052(6.9609) | Xent 2.0387(2.0517) | Loss 912.4723(939.1028) | Error 0.7189(0.6980) Steps 0(0.00) | Grad Norm 1198.8711(391.8321) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 79.0875, Epoch Time 909.1561(831.9568), Bit/dim 6.6371(best: 6.9922), Xent 2.0226, Loss 7.6484, Error 0.6888(best: 0.6948)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0170 | Time 15.1055(14.7623) | Bit/dim 6.6049(6.8782) | Xent 2.0437(2.0521) | Loss 908.6235(990.2030) | Error 0.7144(0.7024) Steps 0(0.00) | Grad Norm 1987.1354(741.1942) | Total Time 0.00(0.00)\n",
      "Iter 0180 | Time 16.8132(15.0011) | Bit/dim 6.4563(6.7779) | Xent 2.2532(2.0573) | Loss 876.6907(961.0256) | Error 0.8133(0.7136) Steps 0(0.00) | Grad Norm 6227.6961(1226.9101) | Total Time 0.00(0.00)\n",
      "Iter 0190 | Time 13.5159(14.9654) | Bit/dim 6.2662(6.6630) | Xent 2.0537(2.0635) | Loss 853.7041(936.7958) | Error 0.7011(0.7199) Steps 0(0.00) | Grad Norm 3012.1134(1689.4894) | Total Time 0.00(0.00)\n",
      "Iter 0200 | Time 14.2100(15.0232) | Bit/dim 6.1004(6.5316) | Xent 2.0323(2.0640) | Loss 832.6703(913.2163) | Error 0.6822(0.7211) Steps 0(0.00) | Grad Norm 2097.6675(1943.6852) | Total Time 0.00(0.00)\n",
      "Iter 0210 | Time 14.8108(15.1862) | Bit/dim 5.9628(6.3969) | Xent 2.0590(2.0709) | Loss 831.7012(890.1886) | Error 0.7111(0.7258) Steps 0(0.00) | Grad Norm 1728.0678(2484.9560) | Total Time 0.00(0.00)\n",
      "Iter 0220 | Time 14.2238(15.0748) | Bit/dim 5.8177(6.2606) | Xent 2.0316(2.0625) | Loss 823.5174(869.9301) | Error 0.6778(0.7189) Steps 0(0.00) | Grad Norm 2260.2921(2494.1723) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 78.8394, Epoch Time 932.5257(834.9739), Bit/dim 5.8204(best: 6.6371), Xent 2.0253, Loss 6.8331, Error 0.6759(best: 0.6888)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0230 | Time 15.5100(15.1163) | Bit/dim 5.7976(6.1377) | Xent 2.0556(2.0520) | Loss 792.9816(903.6276) | Error 0.7233(0.7113) Steps 0(0.00) | Grad Norm 1553.9378(2201.6644) | Total Time 0.00(0.00)\n",
      "Iter 0240 | Time 15.3346(15.0231) | Bit/dim 5.7418(6.0301) | Xent 1.9837(2.0376) | Loss 812.4402(872.0512) | Error 0.6767(0.7045) Steps 0(0.00) | Grad Norm 1272.3405(2057.2348) | Total Time 0.00(0.00)\n",
      "Iter 0250 | Time 14.1470(14.8645) | Bit/dim 5.6764(5.9437) | Xent 1.9470(2.0231) | Loss 777.9117(850.7309) | Error 0.6456(0.6948) Steps 0(0.00) | Grad Norm 648.8393(1885.7391) | Total Time 0.00(0.00)\n",
      "Iter 0260 | Time 13.6236(14.7752) | Bit/dim 5.6718(5.8750) | Xent 2.0823(2.0351) | Loss 786.7686(837.1951) | Error 0.7700(0.7073) Steps 0(0.00) | Grad Norm 2829.0190(2407.1528) | Total Time 0.00(0.00)\n",
      "Iter 0270 | Time 13.7104(14.6862) | Bit/dim 5.6292(5.8161) | Xent 2.0335(2.0335) | Loss 733.2158(824.5327) | Error 0.7278(0.7074) Steps 0(0.00) | Grad Norm 1908.3775(2222.0706) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 79.3526, Epoch Time 900.8435(836.9500), Bit/dim 5.6152(best: 5.8204), Xent 1.9943, Loss 6.6124, Error 0.6636(best: 0.6759)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0280 | Time 14.4582(14.5197) | Bit/dim 5.5356(5.7578) | Xent 1.9833(2.0272) | Loss 791.7897(870.8742) | Error 0.6756(0.7043) Steps 0(0.00) | Grad Norm 546.9434(1969.3327) | Total Time 0.00(0.00)\n",
      "Iter 0290 | Time 14.0086(14.3034) | Bit/dim 5.5887(5.7147) | Xent 1.9498(2.0153) | Loss 786.0107(846.6010) | Error 0.6567(0.6961) Steps 0(0.00) | Grad Norm 842.0215(1703.0493) | Total Time 0.00(0.00)\n",
      "Iter 0300 | Time 13.5060(14.2240) | Bit/dim 5.5250(5.6756) | Xent 1.9263(1.9990) | Loss 765.2112(828.9362) | Error 0.6733(0.6869) Steps 0(0.00) | Grad Norm 1795.2881(1598.9236) | Total Time 0.00(0.00)\n",
      "Iter 0310 | Time 13.8353(14.2203) | Bit/dim 5.4885(5.6371) | Xent 1.9469(1.9873) | Loss 727.5876(814.3886) | Error 0.6567(0.6822) Steps 0(0.00) | Grad Norm 544.1314(1642.7911) | Total Time 0.00(0.00)\n",
      "Iter 0320 | Time 14.4370(14.3266) | Bit/dim 5.4900(5.6011) | Xent 1.9358(1.9743) | Loss 763.7435(801.5432) | Error 0.6811(0.6782) Steps 0(0.00) | Grad Norm 1135.5075(1519.3726) | Total Time 0.00(0.00)\n",
      "Iter 0330 | Time 15.0723(14.4693) | Bit/dim 5.5104(5.5734) | Xent 1.9202(1.9612) | Loss 772.8109(792.0723) | Error 0.6822(0.6727) Steps 0(0.00) | Grad Norm 2253.8401(1472.9118) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 79.4572, Epoch Time 882.2144(838.3079), Bit/dim 5.4977(best: 5.6152), Xent 1.9441, Loss 6.4698, Error 0.6826(best: 0.6636)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0340 | Time 15.2236(14.5126) | Bit/dim 5.4633(5.5481) | Xent 2.0204(1.9656) | Loss 779.9893(840.3130) | Error 0.7067(0.6784) Steps 0(0.00) | Grad Norm 1859.9512(1609.0230) | Total Time 0.00(0.00)\n",
      "Iter 0350 | Time 14.3008(14.5904) | Bit/dim 5.3701(5.5101) | Xent 1.9039(1.9649) | Loss 765.6796(820.7119) | Error 0.6444(0.6802) Steps 0(0.00) | Grad Norm 1315.5960(1898.8763) | Total Time 0.00(0.00)\n",
      "Iter 0360 | Time 14.7865(14.5696) | Bit/dim 5.3262(5.4733) | Xent 1.9552(1.9542) | Loss 741.0544(802.5359) | Error 0.6733(0.6777) Steps 0(0.00) | Grad Norm 1560.5561(1732.8361) | Total Time 0.00(0.00)\n",
      "Iter 0370 | Time 15.1706(14.7075) | Bit/dim 5.3273(5.4357) | Xent 1.8768(1.9413) | Loss 739.5658(788.9239) | Error 0.6556(0.6706) Steps 0(0.00) | Grad Norm 429.6583(1441.3823) | Total Time 0.00(0.00)\n",
      "Iter 0380 | Time 14.3023(14.8172) | Bit/dim 5.2924(5.3967) | Xent 1.9026(1.9332) | Loss 731.7829(778.2161) | Error 0.6678(0.6685) Steps 0(0.00) | Grad Norm 367.2487(1235.3572) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 82.1842, Epoch Time 917.6197(840.6873), Bit/dim 5.2536(best: 5.4977), Xent 1.8726, Loss 6.1899, Error 0.6401(best: 0.6636)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0390 | Time 16.3706(14.9800) | Bit/dim 5.2190(5.3676) | Xent 1.8888(1.9277) | Loss 751.0361(831.9951) | Error 0.6678(0.6677) Steps 0(0.00) | Grad Norm 2022.6565(1329.9462) | Total Time 0.00(0.00)\n",
      "Iter 0400 | Time 15.5037(15.0615) | Bit/dim 5.2698(5.3315) | Xent 1.8832(1.9141) | Loss 767.8967(808.6785) | Error 0.6522(0.6621) Steps 0(0.00) | Grad Norm 1359.5981(1329.2295) | Total Time 0.00(0.00)\n",
      "Iter 0410 | Time 15.1495(15.0390) | Bit/dim 5.3791(5.3170) | Xent 2.1091(1.9530) | Loss 752.4954(795.6598) | Error 0.7367(0.6800) Steps 0(0.00) | Grad Norm 3078.6794(1687.7832) | Total Time 0.00(0.00)\n",
      "Iter 0420 | Time 17.6420(15.1619) | Bit/dim 5.2281(5.2966) | Xent 1.9128(1.9654) | Loss 756.7731(783.9036) | Error 0.7000(0.6870) Steps 0(0.00) | Grad Norm 500.0589(1557.5976) | Total Time 0.00(0.00)\n",
      "Iter 0430 | Time 15.0117(15.1995) | Bit/dim 5.1946(5.2627) | Xent 1.9699(1.9610) | Loss 749.4848(770.0931) | Error 0.7044(0.6862) Steps 0(0.00) | Grad Norm 1568.0319(1399.5791) | Total Time 0.00(0.00)\n",
      "Iter 0440 | Time 15.8933(15.3290) | Bit/dim 5.1990(5.2312) | Xent 1.9249(1.9503) | Loss 733.8568(759.7713) | Error 0.6822(0.6822) Steps 0(0.00) | Grad Norm 1049.0294(1319.3147) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 82.4770, Epoch Time 945.7712(843.8398), Bit/dim 5.1086(best: 5.2536), Xent 1.8678, Loss 6.0425, Error 0.6360(best: 0.6401)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0450 | Time 16.0004(15.3016) | Bit/dim 5.1023(5.1984) | Xent 1.9386(1.9376) | Loss 701.0773(806.3135) | Error 0.6789(0.6754) Steps 0(0.00) | Grad Norm 1573.1702(1160.0733) | Total Time 0.00(0.00)\n",
      "Iter 0460 | Time 16.8829(15.5051) | Bit/dim 5.0587(5.1627) | Xent 1.8914(1.9212) | Loss 732.4976(785.5935) | Error 0.6722(0.6698) Steps 0(0.00) | Grad Norm 780.5136(1199.5557) | Total Time 0.00(0.00)\n",
      "Iter 0470 | Time 15.6906(15.6354) | Bit/dim 5.0379(5.1336) | Xent 1.8822(1.9098) | Loss 703.7000(769.1576) | Error 0.6633(0.6647) Steps 0(0.00) | Grad Norm 1317.1024(1250.3099) | Total Time 0.00(0.00)\n",
      "Iter 0480 | Time 16.6732(15.7385) | Bit/dim 4.9952(5.0999) | Xent 1.8663(1.9033) | Loss 726.2932(755.1275) | Error 0.6589(0.6653) Steps 0(0.00) | Grad Norm 1132.1086(1241.9824) | Total Time 0.00(0.00)\n",
      "Iter 0490 | Time 15.9978(15.8330) | Bit/dim 5.0230(5.0745) | Xent 1.9272(1.8956) | Loss 733.3157(746.0646) | Error 0.6889(0.6634) Steps 0(0.00) | Grad Norm 3396.3813(1405.1077) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 83.5603, Epoch Time 974.4875(847.7592), Bit/dim 4.9564(best: 5.1086), Xent 1.8642, Loss 5.8885, Error 0.6561(best: 0.6360)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0500 | Time 14.7843(15.8144) | Bit/dim 4.9324(5.0453) | Xent 1.9177(1.9156) | Loss 691.3301(794.4455) | Error 0.6633(0.6724) Steps 0(0.00) | Grad Norm 654.2769(1555.6522) | Total Time 0.00(0.00)\n",
      "Iter 0510 | Time 15.9375(15.8078) | Bit/dim 4.9261(5.0179) | Xent 1.8411(1.9088) | Loss 715.4644(772.5135) | Error 0.6611(0.6717) Steps 0(0.00) | Grad Norm 498.3529(1435.1938) | Total Time 0.00(0.00)\n",
      "Iter 0520 | Time 15.3837(15.9815) | Bit/dim 5.6933(5.0198) | Xent 2.7237(1.9308) | Loss 857.7256(761.8477) | Error 0.8300(0.6726) Steps 0(0.00) | Grad Norm 5417.7866(1675.3744) | Total Time 0.00(0.00)\n",
      "Iter 0530 | Time 15.4992(15.9754) | Bit/dim 5.1972(5.0885) | Xent 2.1144(1.9764) | Loss 721.6646(762.2329) | Error 0.7344(0.6889) Steps 0(0.00) | Grad Norm 1118.1396(1723.5076) | Total Time 0.00(0.00)\n",
      "Iter 0540 | Time 15.8165(16.0545) | Bit/dim 5.0100(5.0826) | Xent 1.9855(1.9862) | Loss 735.4111(752.4739) | Error 0.7244(0.6971) Steps 0(0.00) | Grad Norm 414.1191(1407.8105) | Total Time 0.00(0.00)\n",
      "Iter 0550 | Time 16.8896(16.1375) | Bit/dim 4.8845(5.0490) | Xent 2.0168(1.9843) | Loss 714.8724(742.9843) | Error 0.6978(0.6965) Steps 0(0.00) | Grad Norm 247.8532(1124.8711) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 82.1006, Epoch Time 987.7461(851.9588), Bit/dim 4.9097(best: 4.9564), Xent 1.9184, Loss 5.8689, Error 0.6621(best: 0.6360)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0560 | Time 14.9833(15.9795) | Bit/dim 4.8555(5.0057) | Xent 1.8893(1.9684) | Loss 693.9796(785.7928) | Error 0.6778(0.6918) Steps 0(0.00) | Grad Norm 304.0097(927.0612) | Total Time 0.00(0.00)\n",
      "Iter 0570 | Time 15.0275(15.8586) | Bit/dim 4.8454(4.9667) | Xent 1.9666(1.9595) | Loss 692.4276(761.7782) | Error 0.6867(0.6910) Steps 0(0.00) | Grad Norm 574.0938(890.2775) | Total Time 0.00(0.00)\n",
      "Iter 0580 | Time 16.1991(15.8684) | Bit/dim 4.8564(4.9298) | Xent 1.9032(1.9521) | Loss 699.4213(748.0628) | Error 0.6489(0.6861) Steps 0(0.00) | Grad Norm 478.2645(911.9307) | Total Time 0.00(0.00)\n",
      "Iter 0590 | Time 15.4236(15.9927) | Bit/dim 4.8125(4.8959) | Xent 1.8460(1.9382) | Loss 662.5625(733.9746) | Error 0.6700(0.6824) Steps 0(0.00) | Grad Norm 548.8791(945.4254) | Total Time 0.00(0.00)\n",
      "Iter 0600 | Time 16.8092(16.0369) | Bit/dim 4.8201(4.8666) | Xent 1.8189(1.9219) | Loss 682.5320(722.8620) | Error 0.6333(0.6756) Steps 0(0.00) | Grad Norm 1127.0473(950.7355) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 84.7704, Epoch Time 978.3923(855.7518), Bit/dim 4.7673(best: 4.9097), Xent 1.8114, Loss 5.6730, Error 0.6253(best: 0.6360)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0610 | Time 14.9293(16.0552) | Bit/dim 4.7680(4.8421) | Xent 1.8849(1.9071) | Loss 654.4509(777.8938) | Error 0.6611(0.6716) Steps 0(0.00) | Grad Norm 1011.6511(1034.3584) | Total Time 0.00(0.00)\n",
      "Iter 0620 | Time 16.3795(16.3089) | Bit/dim 4.7265(4.8169) | Xent 1.7646(1.8869) | Loss 694.4337(755.4670) | Error 0.6178(0.6656) Steps 0(0.00) | Grad Norm 1008.6329(1053.7062) | Total Time 0.00(0.00)\n",
      "Iter 0630 | Time 18.0619(16.4408) | Bit/dim 4.7292(4.7957) | Xent 1.7219(1.8601) | Loss 673.2491(735.9998) | Error 0.6111(0.6563) Steps 0(0.00) | Grad Norm 921.7933(984.8646) | Total Time 0.00(0.00)\n",
      "Iter 0640 | Time 16.9749(16.5729) | Bit/dim 5.1658(4.8124) | Xent 1.8720(1.8601) | Loss 756.3002(728.0543) | Error 0.6467(0.6556) Steps 0(0.00) | Grad Norm 2541.7200(1350.5322) | Total Time 0.00(0.00)\n",
      "Iter 0650 | Time 16.6457(16.4427) | Bit/dim 4.8009(4.8250) | Xent 1.9429(1.8704) | Loss 690.6653(721.7574) | Error 0.6844(0.6605) Steps 0(0.00) | Grad Norm 816.1047(1240.0342) | Total Time 0.00(0.00)\n",
      "Iter 0660 | Time 16.3878(16.4930) | Bit/dim 4.7178(4.8074) | Xent 1.9053(1.8737) | Loss 701.7669(714.8794) | Error 0.6900(0.6610) Steps 0(0.00) | Grad Norm 384.3539(1049.5621) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 86.7594, Epoch Time 1019.4438(860.6626), Bit/dim 4.7226(best: 4.7673), Xent 1.8026, Loss 5.6239, Error 0.6379(best: 0.6253)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0670 | Time 15.2046(16.4847) | Bit/dim 4.6873(4.7798) | Xent 1.7939(1.8584) | Loss 685.0646(757.7184) | Error 0.6322(0.6567) Steps 0(0.00) | Grad Norm 766.3437(924.7273) | Total Time 0.00(0.00)\n",
      "Iter 0680 | Time 16.5236(16.5904) | Bit/dim 4.6352(4.7509) | Xent 1.7642(1.8341) | Loss 672.9778(736.6317) | Error 0.6222(0.6496) Steps 0(0.00) | Grad Norm 728.3392(812.2287) | Total Time 0.00(0.00)\n",
      "Iter 0690 | Time 17.2497(16.7622) | Bit/dim 4.7216(4.7300) | Xent 1.8860(1.8187) | Loss 664.5461(720.9646) | Error 0.6600(0.6429) Steps 0(0.00) | Grad Norm 2175.6097(817.7988) | Total Time 0.00(0.00)\n",
      "Iter 0700 | Time 17.3544(16.7495) | Bit/dim 4.6566(4.7073) | Xent 1.7670(1.8068) | Loss 674.2991(708.3539) | Error 0.6522(0.6403) Steps 0(0.00) | Grad Norm 704.6454(901.4977) | Total Time 0.00(0.00)\n",
      "Iter 0710 | Time 16.8515(16.8943) | Bit/dim 4.6605(4.6970) | Xent 1.7162(1.8041) | Loss 691.1819(703.2784) | Error 0.5856(0.6402) Steps 0(0.00) | Grad Norm 1237.3739(1144.7088) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 87.2125, Epoch Time 1035.5190(865.9083), Bit/dim 4.6223(best: 4.7226), Xent 1.7164, Loss 5.4805, Error 0.6065(best: 0.6253)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0720 | Time 16.8923(16.9209) | Bit/dim 4.6139(4.6821) | Xent 1.7710(1.8033) | Loss 668.4809(759.9651) | Error 0.6367(0.6394) Steps 0(0.00) | Grad Norm 1787.2410(1184.1315) | Total Time 0.00(0.00)\n",
      "Iter 0730 | Time 16.0408(16.8376) | Bit/dim 4.6643(4.6672) | Xent 1.8056(1.7899) | Loss 643.7947(735.4004) | Error 0.6589(0.6359) Steps 0(0.00) | Grad Norm 2577.2873(1203.4448) | Total Time 0.00(0.00)\n",
      "Iter 0740 | Time 15.9181(17.1295) | Bit/dim 4.5866(4.6571) | Xent 1.7046(1.7788) | Loss 680.4643(720.7919) | Error 0.6144(0.6320) Steps 0(0.00) | Grad Norm 1020.5405(1245.3144) | Total Time 0.00(0.00)\n",
      "Iter 0750 | Time 16.2690(17.1536) | Bit/dim 4.5711(4.6367) | Xent 1.6524(1.7618) | Loss 659.4211(705.9325) | Error 0.5967(0.6255) Steps 0(0.00) | Grad Norm 250.7939(1099.2652) | Total Time 0.00(0.00)\n",
      "Iter 0760 | Time 16.1303(17.0622) | Bit/dim 4.5728(4.6230) | Xent 1.7001(1.7450) | Loss 688.7726(696.8509) | Error 0.5978(0.6197) Steps 0(0.00) | Grad Norm 852.7480(1114.5788) | Total Time 0.00(0.00)\n",
      "Iter 0770 | Time 17.1547(17.1166) | Bit/dim 4.5855(4.6071) | Xent 1.7104(1.7314) | Loss 674.1878(688.3384) | Error 0.6178(0.6142) Steps 0(0.00) | Grad Norm 1682.4572(1095.8294) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 89.8004, Epoch Time 1053.0961(871.5239), Bit/dim 4.5663(best: 4.6223), Xent 1.7052, Loss 5.4189, Error 0.6072(best: 0.6065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0780 | Time 17.9701(17.2666) | Bit/dim 4.6169(4.5960) | Xent 1.7326(1.7358) | Loss 645.4133(739.8229) | Error 0.6189(0.6160) Steps 0(0.00) | Grad Norm 1883.5929(1294.2465) | Total Time 0.00(0.00)\n",
      "Iter 0790 | Time 16.3331(17.1261) | Bit/dim 4.5275(4.5827) | Xent 1.6809(1.7304) | Loss 677.1990(721.3528) | Error 0.6156(0.6153) Steps 0(0.00) | Grad Norm 1284.8681(1336.7604) | Total Time 0.00(0.00)\n",
      "Iter 0800 | Time 18.0960(17.2123) | Bit/dim 4.5253(4.5690) | Xent 1.6611(1.7167) | Loss 654.9096(706.0244) | Error 0.5822(0.6101) Steps 0(0.00) | Grad Norm 372.1381(1224.1934) | Total Time 0.00(0.00)\n",
      "Iter 0810 | Time 17.4998(17.2850) | Bit/dim 4.5617(4.5669) | Xent 1.7785(1.7223) | Loss 668.7914(697.3498) | Error 0.6300(0.6128) Steps 0(0.00) | Grad Norm 1340.2717(1366.5990) | Total Time 0.00(0.00)\n",
      "Iter 0820 | Time 19.2799(17.2479) | Bit/dim 4.5469(4.5535) | Xent 1.6876(1.7198) | Loss 652.0721(686.7204) | Error 0.6033(0.6122) Steps 0(0.00) | Grad Norm 1100.7784(1275.2178) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 88.5070, Epoch Time 1058.7585(877.1410), Bit/dim 4.5487(best: 4.5663), Xent 1.6348, Loss 5.3661, Error 0.5724(best: 0.6065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0830 | Time 17.1093(17.2756) | Bit/dim 4.4718(4.5394) | Xent 1.6835(1.7128) | Loss 646.1967(746.5531) | Error 0.6156(0.6107) Steps 0(0.00) | Grad Norm 955.4942(1239.7173) | Total Time 0.00(0.00)\n",
      "Iter 0840 | Time 16.8549(17.3790) | Bit/dim 4.4849(4.5243) | Xent 1.7031(1.7029) | Loss 651.3997(722.8854) | Error 0.6033(0.6069) Steps 0(0.00) | Grad Norm 299.5401(1142.2680) | Total Time 0.00(0.00)\n",
      "Iter 0850 | Time 17.9115(17.2790) | Bit/dim 4.4604(4.5088) | Xent 1.6466(1.6880) | Loss 652.9744(705.4760) | Error 0.5856(0.6040) Steps 0(0.00) | Grad Norm 1110.9566(989.5211) | Total Time 0.00(0.00)\n",
      "Iter 0860 | Time 15.4486(17.1637) | Bit/dim 4.5347(4.5165) | Xent 1.6686(1.6952) | Loss 643.6068(693.8547) | Error 0.5989(0.6069) Steps 0(0.00) | Grad Norm 969.8772(1146.5922) | Total Time 0.00(0.00)\n",
      "Iter 0870 | Time 18.2043(17.3226) | Bit/dim 4.5090(4.5070) | Xent 1.7514(1.6982) | Loss 668.3624(688.0914) | Error 0.6322(0.6104) Steps 0(0.00) | Grad Norm 1629.8227(1176.2897) | Total Time 0.00(0.00)\n",
      "Iter 0880 | Time 19.1684(17.4617) | Bit/dim 4.4307(4.4910) | Xent 1.6095(1.6912) | Loss 652.8541(680.7113) | Error 0.5744(0.6082) Steps 0(0.00) | Grad Norm 686.3339(1174.3931) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 90.2272, Epoch Time 1064.4780(882.7611), Bit/dim 4.4353(best: 4.5487), Xent 1.5599, Loss 5.2152, Error 0.5562(best: 0.5724)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0890 | Time 17.4084(17.5260) | Bit/dim 4.4351(4.4778) | Xent 1.6359(1.6707) | Loss 648.6323(730.1380) | Error 0.5689(0.6015) Steps 0(0.00) | Grad Norm 862.0807(1096.5299) | Total Time 0.00(0.00)\n",
      "Iter 0900 | Time 17.5103(17.5814) | Bit/dim 4.4074(4.4599) | Xent 1.6383(1.6567) | Loss 628.6929(709.1310) | Error 0.5844(0.5961) Steps 0(0.00) | Grad Norm 1815.1983(1051.4500) | Total Time 0.00(0.00)\n",
      "Iter 0910 | Time 19.1722(17.7224) | Bit/dim 4.4115(4.4501) | Xent 1.6429(1.6539) | Loss 667.9098(697.6816) | Error 0.5856(0.5950) Steps 0(0.00) | Grad Norm 1308.2798(1064.5822) | Total Time 0.00(0.00)\n",
      "Iter 0920 | Time 17.6421(17.7485) | Bit/dim 4.3597(4.4311) | Xent 1.6327(1.6453) | Loss 617.6244(682.9223) | Error 0.5978(0.5921) Steps 0(0.00) | Grad Norm 867.7793(956.4860) | Total Time 0.00(0.00)\n",
      "Iter 0930 | Time 17.8338(17.7068) | Bit/dim 4.3629(4.4202) | Xent 1.6947(1.6484) | Loss 647.2821(675.1700) | Error 0.6144(0.5950) Steps 0(0.00) | Grad Norm 1460.5696(1047.2026) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 91.7114, Epoch Time 1087.1329(888.8922), Bit/dim 4.3670(best: 4.4353), Xent 1.6003, Loss 5.1672, Error 0.5842(best: 0.5562)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0940 | Time 19.0161(17.7368) | Bit/dim 4.3864(4.4069) | Xent 1.5484(1.6441) | Loss 648.6170(732.0427) | Error 0.5600(0.5915) Steps 0(0.00) | Grad Norm 426.3424(1015.0655) | Total Time 0.00(0.00)\n",
      "Iter 0950 | Time 18.3398(17.6208) | Bit/dim 4.3928(4.3953) | Xent 1.5503(1.6324) | Loss 664.5164(708.5580) | Error 0.5633(0.5862) Steps 0(0.00) | Grad Norm 1468.1921(1048.6998) | Total Time 0.00(0.00)\n",
      "Iter 0960 | Time 16.9862(17.5987) | Bit/dim 4.3819(4.3828) | Xent 1.6950(1.6247) | Loss 622.0990(688.8063) | Error 0.6200(0.5846) Steps 0(0.00) | Grad Norm 1787.4535(1027.1223) | Total Time 0.00(0.00)\n",
      "Iter 0970 | Time 17.1198(17.7180) | Bit/dim 4.3006(4.3719) | Xent 1.6316(1.6218) | Loss 640.8984(678.0618) | Error 0.5978(0.5836) Steps 0(0.00) | Grad Norm 508.5198(1024.5793) | Total Time 0.00(0.00)\n",
      "Iter 0980 | Time 17.0815(17.7329) | Bit/dim 4.3167(4.3573) | Xent 1.6160(1.6104) | Loss 635.2297(668.1062) | Error 0.5900(0.5811) Steps 0(0.00) | Grad Norm 485.0335(881.7385) | Total Time 0.00(0.00)\n",
      "Iter 0990 | Time 21.0852(17.8700) | Bit/dim 4.4089(4.3491) | Xent 1.6868(1.6101) | Loss 664.7314(661.2655) | Error 0.6233(0.5828) Steps 0(0.00) | Grad Norm 1876.5645(881.8044) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 94.0129, Epoch Time 1090.4266(894.9383), Bit/dim 4.3851(best: 4.3670), Xent 1.5333, Loss 5.1517, Error 0.5569(best: 0.5562)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1000 | Time 18.4182(17.9472) | Bit/dim 4.3501(4.3533) | Xent 1.5609(1.6150) | Loss 665.4724(717.6782) | Error 0.5900(0.5850) Steps 0(0.00) | Grad Norm 1255.3725(986.3879) | Total Time 0.00(0.00)\n",
      "Iter 1010 | Time 17.7698(17.9164) | Bit/dim 4.3415(4.3456) | Xent 1.5772(1.6106) | Loss 628.4724(697.2334) | Error 0.5811(0.5828) Steps 0(0.00) | Grad Norm 1039.7210(914.2651) | Total Time 0.00(0.00)\n",
      "Iter 1020 | Time 18.6956(17.9021) | Bit/dim 4.2719(4.3324) | Xent 1.5314(1.5967) | Loss 637.8751(681.6246) | Error 0.5533(0.5772) Steps 0(0.00) | Grad Norm 294.3211(825.5200) | Total Time 0.00(0.00)\n",
      "Iter 1030 | Time 17.5346(17.8479) | Bit/dim 4.3234(4.3238) | Xent 1.6575(1.5943) | Loss 637.2496(671.2987) | Error 0.6033(0.5780) Steps 0(0.00) | Grad Norm 1324.5838(923.0959) | Total Time 0.00(0.00)\n",
      "Iter 1040 | Time 16.5757(17.8073) | Bit/dim 4.2863(4.3145) | Xent 1.6425(1.6061) | Loss 622.1733(662.5117) | Error 0.5989(0.5829) Steps 0(0.00) | Grad Norm 694.1159(916.5871) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 91.6583, Epoch Time 1097.1131(901.0035), Bit/dim 4.2569(best: 4.3670), Xent 1.4772, Loss 4.9956, Error 0.5285(best: 0.5562)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1050 | Time 18.4791(18.0568) | Bit/dim 4.2663(4.3022) | Xent 1.5614(1.5947) | Loss 632.2091(717.2848) | Error 0.5689(0.5777) Steps 0(0.00) | Grad Norm 1426.0073(907.8455) | Total Time 0.00(0.00)\n",
      "Iter 1060 | Time 17.7368(18.2181) | Bit/dim 4.2585(4.2926) | Xent 1.5157(1.5847) | Loss 650.1760(696.2268) | Error 0.5489(0.5731) Steps 0(0.00) | Grad Norm 1342.7703(967.2883) | Total Time 0.00(0.00)\n",
      "Iter 1070 | Time 18.0372(18.1866) | Bit/dim 4.2126(4.2747) | Xent 1.5404(1.5716) | Loss 623.6423(678.6381) | Error 0.5567(0.5695) Steps 0(0.00) | Grad Norm 411.3714(844.8816) | Total Time 0.00(0.00)\n",
      "Iter 1080 | Time 19.4739(18.1207) | Bit/dim 4.2160(4.2612) | Xent 1.6183(1.5635) | Loss 639.3350(665.7529) | Error 0.5878(0.5674) Steps 0(0.00) | Grad Norm 1297.7781(797.0276) | Total Time 0.00(0.00)\n",
      "Iter 1090 | Time 19.2174(18.1049) | Bit/dim 4.2155(4.2634) | Xent 1.6028(1.5822) | Loss 640.6212(656.7826) | Error 0.5767(0.5732) Steps 0(0.00) | Grad Norm 586.6154(901.3934) | Total Time 0.00(0.00)\n",
      "Iter 1100 | Time 17.2023(18.1013) | Bit/dim 4.2235(4.2555) | Xent 1.5972(1.5790) | Loss 625.4080(649.0396) | Error 0.5789(0.5728) Steps 0(0.00) | Grad Norm 783.2348(862.8998) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 89.9070, Epoch Time 1108.8162(907.2379), Bit/dim 4.2257(best: 4.2569), Xent 1.4480, Loss 4.9497, Error 0.5202(best: 0.5285)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1110 | Time 17.9786(18.2308) | Bit/dim 4.2257(4.2435) | Xent 1.4918(1.5586) | Loss 619.7483(697.6346) | Error 0.5367(0.5651) Steps 0(0.00) | Grad Norm 454.3381(796.0463) | Total Time 0.00(0.00)\n",
      "Iter 1120 | Time 20.4812(18.1088) | Bit/dim 4.1819(4.2260) | Xent 1.4122(1.5369) | Loss 618.1519(677.3283) | Error 0.5044(0.5578) Steps 0(0.00) | Grad Norm 512.9584(696.6509) | Total Time 0.00(0.00)\n",
      "Iter 1130 | Time 20.1943(18.2213) | Bit/dim 4.1699(4.2135) | Xent 1.4798(1.5164) | Loss 607.9633(662.1709) | Error 0.5200(0.5500) Steps 0(0.00) | Grad Norm 651.0449(649.9848) | Total Time 0.00(0.00)\n",
      "Iter 1140 | Time 17.8487(18.1492) | Bit/dim 4.1767(4.2029) | Xent 1.4679(1.5066) | Loss 601.8393(651.1635) | Error 0.5478(0.5480) Steps 0(0.00) | Grad Norm 757.5011(667.2012) | Total Time 0.00(0.00)\n",
      "Iter 1150 | Time 17.3636(18.0254) | Bit/dim 4.1459(4.1902) | Xent 1.4422(1.4956) | Loss 619.4690(639.2582) | Error 0.5400(0.5437) Steps 0(0.00) | Grad Norm 1112.7735(654.0745) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 89.7242, Epoch Time 1102.0544(913.0824), Bit/dim 4.3221(best: 4.2257), Xent 1.5750, Loss 5.1096, Error 0.5662(best: 0.5202)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1160 | Time 18.0683(18.0506) | Bit/dim 4.3231(4.2116) | Xent 1.5767(1.5292) | Loss 638.1663(705.6642) | Error 0.5700(0.5545) Steps 0(0.00) | Grad Norm 749.1763(878.0252) | Total Time 0.00(0.00)\n",
      "Iter 1170 | Time 18.2387(18.0659) | Bit/dim 4.1657(4.2126) | Xent 1.4580(1.5232) | Loss 624.0589(684.8663) | Error 0.5444(0.5543) Steps 0(0.00) | Grad Norm 452.4220(818.4655) | Total Time 0.00(0.00)\n",
      "Iter 1180 | Time 16.7754(18.0430) | Bit/dim 4.1533(4.2017) | Xent 1.4088(1.5057) | Loss 580.8591(665.9893) | Error 0.5322(0.5491) Steps 0(0.00) | Grad Norm 426.4620(721.3056) | Total Time 0.00(0.00)\n",
      "Iter 1190 | Time 18.6034(17.9549) | Bit/dim 4.1457(4.1833) | Xent 1.6035(1.4878) | Loss 617.7972(650.7254) | Error 0.5833(0.5438) Steps 0(0.00) | Grad Norm 1240.1926(684.7303) | Total Time 0.00(0.00)\n",
      "Iter 1200 | Time 16.9615(17.8487) | Bit/dim 4.1335(4.1676) | Xent 1.4189(1.4787) | Loss 612.7139(641.7234) | Error 0.5278(0.5405) Steps 0(0.00) | Grad Norm 398.6808(702.4698) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 17.7147(17.8259) | Bit/dim 4.1142(4.1540) | Xent 1.4090(1.4756) | Loss 606.1974(632.6322) | Error 0.5011(0.5383) Steps 0(0.00) | Grad Norm 531.7241(702.1996) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 89.8336, Epoch Time 1089.1297(918.3638), Bit/dim 4.1253(best: 4.2257), Xent 1.4204, Loss 4.8355, Error 0.5167(best: 0.5202)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1220 | Time 16.9217(17.9587) | Bit/dim 4.1206(4.1454) | Xent 1.5010(1.4719) | Loss 618.1110(684.2772) | Error 0.5411(0.5355) Steps 0(0.00) | Grad Norm 723.6375(748.5409) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 17.6714(17.8936) | Bit/dim 4.1264(4.1422) | Xent 1.4593(1.4713) | Loss 590.7913(663.6073) | Error 0.5189(0.5336) Steps 0(0.00) | Grad Norm 605.9810(751.9950) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 18.0589(17.8633) | Bit/dim 4.1185(4.1341) | Xent 1.3802(1.4590) | Loss 607.2792(646.3010) | Error 0.4900(0.5298) Steps 0(0.00) | Grad Norm 754.8753(704.6607) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 20.6156(17.9227) | Bit/dim 4.0913(4.1276) | Xent 1.3316(1.4456) | Loss 619.1158(636.9897) | Error 0.4689(0.5265) Steps 0(0.00) | Grad Norm 294.1139(622.7884) | Total Time 0.00(0.00)\n",
      "Iter 1260 | Time 16.9800(17.8875) | Bit/dim 4.1051(4.1171) | Xent 1.3893(1.4326) | Loss 591.1760(627.2197) | Error 0.5011(0.5226) Steps 0(0.00) | Grad Norm 571.4460(572.4003) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 88.5367, Epoch Time 1093.1920(923.6086), Bit/dim 4.0934(best: 4.1253), Xent 1.3161, Loss 4.7514, Error 0.4822(best: 0.5167)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1270 | Time 20.2243(17.9561) | Bit/dim 4.0584(4.1098) | Xent 1.4231(1.4271) | Loss 625.4807(687.2737) | Error 0.5544(0.5203) Steps 0(0.00) | Grad Norm 613.6994(631.4366) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 16.9780(17.8456) | Bit/dim 4.0887(4.1019) | Xent 1.3927(1.4210) | Loss 583.7289(665.7434) | Error 0.5200(0.5178) Steps 0(0.00) | Grad Norm 305.4376(661.2676) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 19.4686(17.8171) | Bit/dim 4.0872(4.0979) | Xent 1.4228(1.4205) | Loss 618.0680(652.0279) | Error 0.5267(0.5173) Steps 0(0.00) | Grad Norm 685.5708(712.6448) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 16.3436(17.6679) | Bit/dim 4.0831(4.0896) | Xent 1.4205(1.4214) | Loss 597.0068(638.6075) | Error 0.5233(0.5194) Steps 0(0.00) | Grad Norm 485.9783(666.5289) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 19.1786(17.8529) | Bit/dim 4.0951(4.0863) | Xent 1.3967(1.4098) | Loss 635.4065(629.4141) | Error 0.5044(0.5152) Steps 0(0.00) | Grad Norm 869.9641(656.7231) | Total Time 0.00(0.00)\n",
      "Iter 1320 | Time 17.1546(17.8232) | Bit/dim 4.0612(4.0782) | Xent 1.3800(1.4025) | Loss 615.6801(620.9212) | Error 0.4956(0.5114) Steps 0(0.00) | Grad Norm 773.3337(609.9671) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 90.6794, Epoch Time 1085.7503(928.4729), Bit/dim 4.0711(best: 4.0934), Xent 1.3332, Loss 4.7377, Error 0.4825(best: 0.4822)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1330 | Time 17.0204(17.8173) | Bit/dim 4.0665(4.0752) | Xent 1.3591(1.3935) | Loss 612.5500(674.6491) | Error 0.4911(0.5065) Steps 0(0.00) | Grad Norm 1196.2040(692.1389) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 16.8471(17.8089) | Bit/dim 4.0511(4.0694) | Xent 1.3799(1.3857) | Loss 568.3694(653.8542) | Error 0.5156(0.5036) Steps 0(0.00) | Grad Norm 580.6995(713.7747) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 17.5450(17.7326) | Bit/dim 4.0533(4.0647) | Xent 1.3683(1.3817) | Loss 592.9430(640.3502) | Error 0.5067(0.5017) Steps 0(0.00) | Grad Norm 606.9874(737.8886) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 17.5246(17.7793) | Bit/dim 4.0636(4.0591) | Xent 1.3636(1.3782) | Loss 606.8519(630.8282) | Error 0.5033(0.5019) Steps 0(0.00) | Grad Norm 504.6264(694.6809) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 18.0790(17.7439) | Bit/dim 4.0063(4.0499) | Xent 1.3529(1.3727) | Loss 599.7519(622.8450) | Error 0.4878(0.5004) Steps 0(0.00) | Grad Norm 392.3542(646.1488) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 89.1022, Epoch Time 1082.4620(933.0926), Bit/dim 4.0275(best: 4.0711), Xent 1.3118, Loss 4.6834, Error 0.4812(best: 0.4822)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1380 | Time 18.4381(17.7487) | Bit/dim 4.0141(4.0448) | Xent 1.4428(1.3711) | Loss 614.5086(679.9296) | Error 0.5222(0.4986) Steps 0(0.00) | Grad Norm 1029.9788(693.1815) | Total Time 0.00(0.00)\n",
      "Iter 1390 | Time 18.0445(17.6590) | Bit/dim 4.0683(4.0416) | Xent 1.4202(1.3920) | Loss 619.3193(659.3709) | Error 0.5289(0.5045) Steps 0(0.00) | Grad Norm 739.6289(799.7973) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 17.0049(17.5976) | Bit/dim 4.0488(4.0405) | Xent 1.3309(1.3874) | Loss 600.4274(643.1697) | Error 0.5000(0.5015) Steps 0(0.00) | Grad Norm 576.7506(746.0847) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 18.1777(17.7623) | Bit/dim 4.0347(4.0378) | Xent 1.2955(1.3795) | Loss 591.9959(630.9352) | Error 0.4844(0.4995) Steps 0(0.00) | Grad Norm 414.4066(647.8405) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 17.4303(17.9502) | Bit/dim 4.0161(4.0342) | Xent 1.3339(1.3667) | Loss 610.8043(623.1959) | Error 0.4844(0.4971) Steps 0(0.00) | Grad Norm 755.0651(652.1766) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 19.4004(17.9214) | Bit/dim 3.9900(4.0331) | Xent 1.3354(1.3632) | Loss 601.1713(616.9631) | Error 0.5022(0.4957) Steps 0(0.00) | Grad Norm 259.0148(668.9747) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 89.0954, Epoch Time 1089.3079(937.7790), Bit/dim 4.0191(best: 4.0275), Xent 1.2527, Loss 4.6454, Error 0.4528(best: 0.4812)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1440 | Time 17.0765(17.9346) | Bit/dim 4.0177(4.0251) | Xent 1.2437(1.3498) | Loss 581.1960(664.5752) | Error 0.4533(0.4899) Steps 0(0.00) | Grad Norm 275.4466(601.3738) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 17.1461(17.8175) | Bit/dim 3.9960(4.0197) | Xent 1.2650(1.3353) | Loss 569.9095(644.3884) | Error 0.4622(0.4845) Steps 0(0.00) | Grad Norm 310.5667(561.7826) | Total Time 0.00(0.00)\n",
      "Iter 1460 | Time 17.3332(18.1210) | Bit/dim 3.9508(4.0120) | Xent 1.3784(1.3321) | Loss 580.1489(630.9705) | Error 0.5033(0.4836) Steps 0(0.00) | Grad Norm 1497.2156(600.8659) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 18.4960(18.0718) | Bit/dim 3.9945(4.0100) | Xent 1.3402(1.3341) | Loss 621.3974(624.0553) | Error 0.4711(0.4849) Steps 0(0.00) | Grad Norm 862.0435(653.4906) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 16.4074(17.9059) | Bit/dim 3.9929(4.0071) | Xent 1.3844(1.3341) | Loss 553.0476(614.5520) | Error 0.4978(0.4846) Steps 0(0.00) | Grad Norm 713.4049(646.4953) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 89.1452, Epoch Time 1095.9277(942.5235), Bit/dim 3.9964(best: 4.0191), Xent 1.2773, Loss 4.6351, Error 0.4623(best: 0.4528)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1490 | Time 17.8208(17.8761) | Bit/dim 3.9674(4.0021) | Xent 1.3217(1.3294) | Loss 595.5793(672.2677) | Error 0.4656(0.4817) Steps 0(0.00) | Grad Norm 682.1425(656.5091) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 17.5757(17.7528) | Bit/dim 3.9720(3.9977) | Xent 1.3215(1.3241) | Loss 580.4770(650.3763) | Error 0.4756(0.4796) Steps 0(0.00) | Grad Norm 566.9313(620.6902) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 17.9118(17.9051) | Bit/dim 3.9590(3.9900) | Xent 1.2741(1.3144) | Loss 592.5359(635.4922) | Error 0.4478(0.4750) Steps 0(0.00) | Grad Norm 298.5993(565.7072) | Total Time 0.00(0.00)\n",
      "Iter 1520 | Time 17.8903(17.8864) | Bit/dim 3.9781(3.9853) | Xent 1.3202(1.3071) | Loss 587.5430(622.8334) | Error 0.5000(0.4753) Steps 0(0.00) | Grad Norm 636.8237(549.3399) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 18.5088(17.8863) | Bit/dim 3.9881(3.9812) | Xent 1.2241(1.2963) | Loss 603.7140(613.6396) | Error 0.4500(0.4706) Steps 0(0.00) | Grad Norm 380.2600(567.2013) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 15.8266(17.8248) | Bit/dim 3.9833(3.9785) | Xent 1.3268(1.2936) | Loss 561.7943(604.9730) | Error 0.4567(0.4674) Steps 0(0.00) | Grad Norm 585.7695(545.6140) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 89.8813, Epoch Time 1086.7980(946.8517), Bit/dim 3.9593(best: 3.9964), Xent 1.2045, Loss 4.5616, Error 0.4387(best: 0.4528)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1550 | Time 19.9203(17.9308) | Bit/dim 3.9743(3.9770) | Xent 1.2584(1.2867) | Loss 594.1420(658.4006) | Error 0.4667(0.4646) Steps 0(0.00) | Grad Norm 616.6168(600.0248) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 17.5711(18.0244) | Bit/dim 3.9458(3.9725) | Xent 1.2424(1.2898) | Loss 563.5018(637.9516) | Error 0.4411(0.4657) Steps 0(0.00) | Grad Norm 694.4892(599.1832) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 17.8277(17.8819) | Bit/dim 3.9423(3.9696) | Xent 1.2370(1.2838) | Loss 585.7960(625.0213) | Error 0.4467(0.4626) Steps 0(0.00) | Grad Norm 650.4563(626.4041) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 17.8642(17.7942) | Bit/dim 3.9380(3.9656) | Xent 1.3049(1.2882) | Loss 584.7955(615.7726) | Error 0.4767(0.4655) Steps 0(0.00) | Grad Norm 463.6806(618.5751) | Total Time 0.00(0.00)\n",
      "Iter 1590 | Time 16.6322(17.6607) | Bit/dim 3.9866(3.9619) | Xent 1.2274(1.2809) | Loss 578.7457(606.2733) | Error 0.4544(0.4635) Steps 0(0.00) | Grad Norm 411.9136(568.2346) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 87.4888, Epoch Time 1081.4393(950.8893), Bit/dim 3.9492(best: 3.9593), Xent 1.1936, Loss 4.5460, Error 0.4344(best: 0.4387)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1600 | Time 16.8724(17.6350) | Bit/dim 3.9626(3.9596) | Xent 1.2444(1.2707) | Loss 571.3779(663.7128) | Error 0.4322(0.4592) Steps 0(0.00) | Grad Norm 745.7047(526.7167) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 17.1460(17.5400) | Bit/dim 3.9400(3.9548) | Xent 1.2466(1.2600) | Loss 550.1686(639.7183) | Error 0.4344(0.4552) Steps 0(0.00) | Grad Norm 496.8347(536.2162) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 18.3234(17.5078) | Bit/dim 3.9443(3.9518) | Xent 1.2785(1.2584) | Loss 580.8354(624.4862) | Error 0.4767(0.4569) Steps 0(0.00) | Grad Norm 742.2075(564.6354) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 15.8699(17.4951) | Bit/dim 3.9254(3.9496) | Xent 1.2975(1.2616) | Loss 569.5892(613.4828) | Error 0.4578(0.4566) Steps 0(0.00) | Grad Norm 757.4915(585.7629) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 17.3207(17.4451) | Bit/dim 3.9601(3.9486) | Xent 1.2361(1.2658) | Loss 569.3921(604.5456) | Error 0.4611(0.4571) Steps 0(0.00) | Grad Norm 484.7709(604.2888) | Total Time 0.00(0.00)\n",
      "Iter 1650 | Time 17.6271(17.5518) | Bit/dim 3.9342(3.9451) | Xent 1.2109(1.2661) | Loss 579.4701(598.4393) | Error 0.4356(0.4577) Steps 0(0.00) | Grad Norm 514.1893(626.6069) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 86.5198, Epoch Time 1064.3264(954.2925), Bit/dim 3.9499(best: 3.9492), Xent 1.2468, Loss 4.5732, Error 0.4478(best: 0.4344)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1660 | Time 17.1986(17.4912) | Bit/dim 3.9280(3.9456) | Xent 1.2655(1.2665) | Loss 575.0932(646.2834) | Error 0.4667(0.4570) Steps 0(0.00) | Grad Norm 654.9100(691.7769) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 17.3696(17.4728) | Bit/dim 3.9191(3.9449) | Xent 1.2040(1.2593) | Loss 575.8603(626.0909) | Error 0.4222(0.4534) Steps 0(0.00) | Grad Norm 597.4615(656.0140) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 21.4826(17.6484) | Bit/dim 3.9200(3.9417) | Xent 1.2434(1.2489) | Loss 561.8068(613.9083) | Error 0.4589(0.4478) Steps 0(0.00) | Grad Norm 585.2739(610.5954) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 17.8062(17.5376) | Bit/dim 3.9649(3.9410) | Xent 1.2231(1.2471) | Loss 590.1724(604.6513) | Error 0.4256(0.4461) Steps 0(0.00) | Grad Norm 527.0785(603.6957) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 17.4368(17.4285) | Bit/dim 3.9056(3.9348) | Xent 1.2080(1.2411) | Loss 560.7975(595.6756) | Error 0.4344(0.4448) Steps 0(0.00) | Grad Norm 259.8887(544.6851) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 86.9782, Epoch Time 1065.5019(957.6287), Bit/dim 3.9265(best: 3.9492), Xent 1.1557, Loss 4.5043, Error 0.4148(best: 0.4344)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1710 | Time 17.4190(17.3963) | Bit/dim 3.9168(3.9287) | Xent 1.1737(1.2313) | Loss 584.6082(652.8736) | Error 0.4256(0.4437) Steps 0(0.00) | Grad Norm 585.3521(545.7255) | Total Time 0.00(0.00)\n",
      "Iter 1720 | Time 15.8758(17.2763) | Bit/dim 3.9312(3.9273) | Xent 1.1999(1.2223) | Loss 576.0350(632.1488) | Error 0.4456(0.4411) Steps 0(0.00) | Grad Norm 340.3333(527.7458) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 17.4901(17.3650) | Bit/dim 3.9359(3.9256) | Xent 1.2221(1.2260) | Loss 591.5635(618.2937) | Error 0.4256(0.4408) Steps 0(0.00) | Grad Norm 1116.7217(596.6216) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 16.8374(17.3939) | Bit/dim 3.9707(3.9247) | Xent 1.2807(1.2372) | Loss 572.3790(608.3983) | Error 0.4522(0.4444) Steps 0(0.00) | Grad Norm 610.2838(643.0865) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 16.7002(17.5032) | Bit/dim 3.9499(3.9250) | Xent 1.2001(1.2424) | Loss 587.0932(601.0742) | Error 0.4256(0.4447) Steps 0(0.00) | Grad Norm 472.0703(681.0946) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 16.4988(17.5740) | Bit/dim 3.8969(3.9201) | Xent 1.2230(1.2373) | Loss 556.1656(594.5472) | Error 0.4511(0.4437) Steps 0(0.00) | Grad Norm 760.3440(650.1870) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 88.9436, Epoch Time 1067.7129(960.9313), Bit/dim 3.9057(best: 3.9265), Xent 1.1501, Loss 4.4807, Error 0.4088(best: 0.4148)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1770 | Time 17.5245(17.6379) | Bit/dim 3.8980(3.9179) | Xent 1.1308(1.2218) | Loss 565.5649(644.6955) | Error 0.3989(0.4377) Steps 0(0.00) | Grad Norm 321.3666(585.3426) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 15.7030(17.4720) | Bit/dim 3.9251(3.9163) | Xent 1.2370(1.2162) | Loss 566.9805(626.4803) | Error 0.4389(0.4363) Steps 0(0.00) | Grad Norm 448.0590(575.3628) | Total Time 0.00(0.00)\n",
      "Iter 1790 | Time 17.2979(17.5300) | Bit/dim 3.9042(3.9104) | Xent 1.2043(1.2071) | Loss 555.8284(610.6359) | Error 0.4311(0.4338) Steps 0(0.00) | Grad Norm 329.9903(570.8993) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 16.6356(17.4460) | Bit/dim 3.8996(3.9090) | Xent 1.1888(1.2028) | Loss 562.2378(600.9220) | Error 0.4300(0.4313) Steps 0(0.00) | Grad Norm 510.8651(573.9222) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 17.7195(17.3539) | Bit/dim 3.9067(3.9053) | Xent 1.1142(1.1982) | Loss 579.4114(590.5718) | Error 0.3911(0.4306) Steps 0(0.00) | Grad Norm 522.6987(568.5542) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 86.5390, Epoch Time 1066.3117(964.0927), Bit/dim 3.8962(best: 3.9057), Xent 1.1201, Loss 4.4562, Error 0.4027(best: 0.4088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1820 | Time 16.8699(17.5779) | Bit/dim 3.9088(3.9043) | Xent 1.1223(1.1868) | Loss 588.2616(648.2478) | Error 0.4044(0.4276) Steps 0(0.00) | Grad Norm 457.3769(546.5209) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 17.2019(17.4537) | Bit/dim 3.8536(3.9005) | Xent 1.2109(1.1832) | Loss 565.6576(627.7005) | Error 0.4289(0.4270) Steps 0(0.00) | Grad Norm 749.4540(545.1025) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 17.6826(17.4423) | Bit/dim 3.8643(3.8961) | Xent 1.2516(1.1838) | Loss 523.1426(611.2377) | Error 0.4411(0.4276) Steps 0(0.00) | Grad Norm 875.3327(565.6409) | Total Time 0.00(0.00)\n",
      "Iter 1850 | Time 16.7150(17.3109) | Bit/dim 3.8964(3.8989) | Xent 1.2297(1.1833) | Loss 585.5665(600.9500) | Error 0.4289(0.4282) Steps 0(0.00) | Grad Norm 1381.3640(613.2813) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 16.7438(17.1788) | Bit/dim 3.8641(3.8949) | Xent 1.1250(1.1814) | Loss 550.0441(591.4440) | Error 0.4011(0.4256) Steps 0(0.00) | Grad Norm 550.8093(628.2488) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 16.7553(17.1573) | Bit/dim 3.8952(3.8950) | Xent 1.1786(1.1808) | Loss 561.0651(586.6936) | Error 0.4200(0.4260) Steps 0(0.00) | Grad Norm 640.7218(617.1056) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 87.6331, Epoch Time 1047.6466(966.5993), Bit/dim 3.8866(best: 3.8962), Xent 1.1031, Loss 4.4381, Error 0.3987(best: 0.4027)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1880 | Time 17.4699(17.1881) | Bit/dim 3.9091(3.8934) | Xent 1.0917(1.1684) | Loss 564.8352(634.6089) | Error 0.3778(0.4192) Steps 0(0.00) | Grad Norm 493.8224(564.8834) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 16.3220(17.1672) | Bit/dim 3.8765(3.8913) | Xent 1.1003(1.1561) | Loss 546.3306(615.5604) | Error 0.3889(0.4140) Steps 0(0.00) | Grad Norm 538.6116(524.0782) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 16.8488(17.2097) | Bit/dim 3.8627(3.8895) | Xent 1.1965(1.1520) | Loss 544.2311(602.6903) | Error 0.4144(0.4128) Steps 0(0.00) | Grad Norm 762.0326(560.9937) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 16.8522(17.1027) | Bit/dim 3.8802(3.8871) | Xent 1.1533(1.1585) | Loss 582.5590(593.6933) | Error 0.4078(0.4155) Steps 0(0.00) | Grad Norm 472.3044(549.1066) | Total Time 0.00(0.00)\n",
      "Iter 1920 | Time 17.6225(17.1483) | Bit/dim 3.8908(3.8815) | Xent 1.1701(1.1535) | Loss 568.9518(586.6578) | Error 0.4211(0.4138) Steps 0(0.00) | Grad Norm 593.6716(561.1248) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 85.5612, Epoch Time 1050.3448(969.1117), Bit/dim 3.8714(best: 3.8866), Xent 1.0801, Loss 4.4114, Error 0.3852(best: 0.3987)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1930 | Time 18.0847(17.3774) | Bit/dim 3.8664(3.8817) | Xent 1.2037(1.1543) | Loss 571.2362(645.0833) | Error 0.4367(0.4151) Steps 0(0.00) | Grad Norm 475.2533(521.5530) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 18.0938(17.3783) | Bit/dim 3.8643(3.8760) | Xent 1.1424(1.1497) | Loss 549.5618(623.0422) | Error 0.3933(0.4132) Steps 0(0.00) | Grad Norm 573.8581(498.2005) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 19.1707(17.4193) | Bit/dim 3.9062(3.8776) | Xent 1.1380(1.1446) | Loss 584.9169(607.5131) | Error 0.4133(0.4114) Steps 0(0.00) | Grad Norm 1036.1366(527.4090) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 18.1382(17.4851) | Bit/dim 3.8545(3.8751) | Xent 1.1042(1.1354) | Loss 562.8391(595.6885) | Error 0.3989(0.4080) Steps 0(0.00) | Grad Norm 671.2653(535.0092) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 17.2462(17.3852) | Bit/dim 3.8687(3.8705) | Xent 1.1310(1.1304) | Loss 557.1368(586.6332) | Error 0.4078(0.4055) Steps 0(0.00) | Grad Norm 588.7299(517.7812) | Total Time 0.00(0.00)\n",
      "Iter 1980 | Time 16.2130(17.3164) | Bit/dim 3.8659(3.8711) | Xent 1.0974(1.1238) | Loss 567.6085(578.1020) | Error 0.4067(0.4030) Steps 0(0.00) | Grad Norm 428.7640(536.2717) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 86.4929, Epoch Time 1062.3988(971.9103), Bit/dim 3.8625(best: 3.8714), Xent 1.0582, Loss 4.3916, Error 0.3778(best: 0.3852)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1990 | Time 17.0385(17.1865) | Bit/dim 3.8702(3.8684) | Xent 1.0949(1.1167) | Loss 586.3535(627.6895) | Error 0.4000(0.4006) Steps 0(0.00) | Grad Norm 440.2607(522.2039) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 19.3214(17.3302) | Bit/dim 3.8550(3.8671) | Xent 1.1612(1.1081) | Loss 573.9421(611.5197) | Error 0.4233(0.3972) Steps 0(0.00) | Grad Norm 496.4391(499.9874) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 17.2019(17.3321) | Bit/dim 3.8772(3.8655) | Xent 1.1298(1.1082) | Loss 563.6152(598.4401) | Error 0.4167(0.3984) Steps 0(0.00) | Grad Norm 741.1264(512.8743) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 16.4586(17.4025) | Bit/dim 3.8800(3.8644) | Xent 1.1035(1.1058) | Loss 569.3524(588.7194) | Error 0.4200(0.3967) Steps 0(0.00) | Grad Norm 365.3698(574.8967) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 17.5660(17.4505) | Bit/dim 3.9301(3.8658) | Xent 1.0951(1.1118) | Loss 542.5607(582.0564) | Error 0.3944(0.3992) Steps 0(0.00) | Grad Norm 546.3604(640.2555) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 88.5247, Epoch Time 1067.1469(974.7674), Bit/dim 3.8636(best: 3.8625), Xent 1.0843, Loss 4.4057, Error 0.3864(best: 0.3778)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2040 | Time 18.3549(17.5637) | Bit/dim 3.8747(3.8655) | Xent 1.1148(1.1102) | Loss 565.9575(643.4596) | Error 0.3956(0.3981) Steps 0(0.00) | Grad Norm 566.1411(634.6409) | Total Time 0.00(0.00)\n",
      "Iter 2050 | Time 18.1206(17.4848) | Bit/dim 3.8695(3.8643) | Xent 1.0523(1.1037) | Loss 569.1541(621.2835) | Error 0.3711(0.3951) Steps 0(0.00) | Grad Norm 617.4657(629.7825) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 16.7857(17.5354) | Bit/dim 3.8488(3.8625) | Xent 1.0994(1.0982) | Loss 554.7962(607.1803) | Error 0.4178(0.3943) Steps 0(0.00) | Grad Norm 362.0765(568.7516) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 17.1127(17.5026) | Bit/dim 3.8342(3.8592) | Xent 1.0867(1.0857) | Loss 548.6695(593.7831) | Error 0.3978(0.3883) Steps 0(0.00) | Grad Norm 351.2996(548.3332) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 18.2671(17.6206) | Bit/dim 3.8586(3.8587) | Xent 1.0623(1.0812) | Loss 553.5695(586.0516) | Error 0.3789(0.3870) Steps 0(0.00) | Grad Norm 375.2138(526.3196) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 18.1081(17.6954) | Bit/dim 3.8070(3.8537) | Xent 1.2235(1.0889) | Loss 578.6058(580.9277) | Error 0.4133(0.3887) Steps 0(0.00) | Grad Norm 1275.6233(591.6972) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 88.3721, Epoch Time 1076.9471(977.8328), Bit/dim 3.8539(best: 3.8625), Xent 1.0904, Loss 4.3991, Error 0.3906(best: 0.3778)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2100 | Time 17.5036(17.5570) | Bit/dim 3.8533(3.8530) | Xent 1.0747(1.0959) | Loss 561.6887(631.4379) | Error 0.3933(0.3912) Steps 0(0.00) | Grad Norm 682.6070(639.7723) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 19.5708(17.6665) | Bit/dim 3.8404(3.8531) | Xent 1.1732(1.0974) | Loss 554.4020(610.7214) | Error 0.4100(0.3927) Steps 0(0.00) | Grad Norm 499.9022(600.7255) | Total Time 0.00(0.00)\n",
      "Iter 2120 | Time 17.1850(17.5519) | Bit/dim 3.8262(3.8491) | Xent 1.0574(1.0849) | Loss 568.6263(597.7218) | Error 0.3878(0.3908) Steps 0(0.00) | Grad Norm 305.8106(545.7347) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 16.5363(17.4026) | Bit/dim 3.8305(3.8469) | Xent 1.0615(1.0872) | Loss 549.5375(588.0921) | Error 0.3789(0.3904) Steps 0(0.00) | Grad Norm 525.4739(553.1582) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 17.2872(17.3662) | Bit/dim 3.8721(3.8458) | Xent 1.0890(1.0830) | Loss 543.4686(579.9674) | Error 0.4044(0.3890) Steps 0(0.00) | Grad Norm 370.6770(517.4762) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 87.5290, Epoch Time 1061.9976(980.3577), Bit/dim 3.8398(best: 3.8539), Xent 0.9925, Loss 4.3360, Error 0.3566(best: 0.3778)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2150 | Time 17.2136(17.3989) | Bit/dim 3.8319(3.8435) | Xent 1.0412(1.0728) | Loss 555.8198(638.8672) | Error 0.3656(0.3849) Steps 0(0.00) | Grad Norm 275.1624(481.4897) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 17.5035(17.4687) | Bit/dim 3.8540(3.8436) | Xent 1.0569(1.0676) | Loss 560.1609(620.0437) | Error 0.3867(0.3815) Steps 0(0.00) | Grad Norm 595.4013(468.8661) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 16.8030(17.4440) | Bit/dim 3.8249(3.8466) | Xent 1.0889(1.0679) | Loss 561.7606(604.0432) | Error 0.4000(0.3832) Steps 0(0.00) | Grad Norm 671.4720(534.0871) | Total Time 0.00(0.00)\n",
      "Iter 2180 | Time 17.4412(17.3885) | Bit/dim 3.8097(3.8444) | Xent 1.0640(1.0683) | Loss 558.4428(591.9559) | Error 0.3844(0.3834) Steps 0(0.00) | Grad Norm 325.8465(511.8844) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 17.9832(17.4678) | Bit/dim 3.8088(3.8408) | Xent 1.0660(1.0641) | Loss 573.6348(585.3107) | Error 0.3800(0.3818) Steps 0(0.00) | Grad Norm 433.8909(524.7560) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 17.5959(17.4470) | Bit/dim 3.8235(3.8385) | Xent 1.0133(1.0596) | Loss 547.7422(578.2118) | Error 0.3667(0.3807) Steps 0(0.00) | Grad Norm 363.2554(509.9672) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 87.3364, Epoch Time 1063.4989(982.8520), Bit/dim 3.8417(best: 3.8398), Xent 1.0265, Loss 4.3549, Error 0.3650(best: 0.3566)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2210 | Time 16.7672(17.3964) | Bit/dim 3.8353(3.8364) | Xent 1.0395(1.0535) | Loss 549.4202(623.8363) | Error 0.3656(0.3777) Steps 0(0.00) | Grad Norm 408.3125(520.5363) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 15.8578(17.4638) | Bit/dim 3.8337(3.8337) | Xent 1.1043(1.0548) | Loss 538.8918(605.2054) | Error 0.4144(0.3784) Steps 0(0.00) | Grad Norm 680.2793(553.6995) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 17.4136(17.3653) | Bit/dim 3.8297(3.8331) | Xent 1.0668(1.0477) | Loss 560.4875(593.3280) | Error 0.3711(0.3730) Steps 0(0.00) | Grad Norm 439.7349(519.0880) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 17.1511(17.2452) | Bit/dim 3.8196(3.8316) | Xent 1.0359(1.0445) | Loss 522.0934(580.0240) | Error 0.3522(0.3715) Steps 0(0.00) | Grad Norm 288.8026(483.6105) | Total Time 0.00(0.00)\n",
      "Iter 2250 | Time 16.6373(17.2158) | Bit/dim 3.8270(3.8325) | Xent 1.0897(1.0479) | Loss 565.5002(576.2447) | Error 0.3944(0.3731) Steps 0(0.00) | Grad Norm 604.2915(528.3664) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 86.1683, Epoch Time 1052.9102(984.9537), Bit/dim 3.8273(best: 3.8398), Xent 1.0017, Loss 4.3281, Error 0.3583(best: 0.3566)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2260 | Time 16.6386(17.1574) | Bit/dim 3.8240(3.8327) | Xent 1.0016(1.0410) | Loss 536.3129(632.2126) | Error 0.3511(0.3713) Steps 0(0.00) | Grad Norm 527.1478(552.2410) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 16.9235(17.3167) | Bit/dim 3.8241(3.8311) | Xent 1.0188(1.0328) | Loss 535.0869(611.5353) | Error 0.3511(0.3675) Steps 0(0.00) | Grad Norm 573.8950(551.1717) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 18.8818(17.4327) | Bit/dim 3.8197(3.8292) | Xent 0.9559(1.0267) | Loss 554.8016(595.9601) | Error 0.3411(0.3667) Steps 0(0.00) | Grad Norm 553.5936(523.3791) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 18.2772(17.5711) | Bit/dim 3.7830(3.8244) | Xent 1.0341(1.0274) | Loss 546.9447(585.2786) | Error 0.3700(0.3670) Steps 0(0.00) | Grad Norm 460.7841(538.8041) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 19.4088(17.5714) | Bit/dim 3.8298(3.8229) | Xent 1.0141(1.0457) | Loss 544.9809(578.1890) | Error 0.3667(0.3748) Steps 0(0.00) | Grad Norm 556.6761(622.7377) | Total Time 0.00(0.00)\n",
      "Iter 2310 | Time 18.9341(17.6396) | Bit/dim 3.8081(3.8218) | Xent 0.9775(1.0396) | Loss 562.6322(574.0136) | Error 0.3500(0.3729) Steps 0(0.00) | Grad Norm 278.3478(599.7245) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 85.5085, Epoch Time 1074.5604(987.6419), Bit/dim 3.8178(best: 3.8273), Xent 0.9942, Loss 4.3149, Error 0.3522(best: 0.3566)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2320 | Time 17.5834(17.6427) | Bit/dim 3.8281(3.8222) | Xent 0.9538(1.0385) | Loss 553.8207(623.4765) | Error 0.3333(0.3721) Steps 0(0.00) | Grad Norm 616.8797(588.7333) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 17.6702(17.5143) | Bit/dim 3.8036(3.8211) | Xent 1.0294(1.0271) | Loss 581.9503(604.6143) | Error 0.3589(0.3675) Steps 0(0.00) | Grad Norm 544.8771(551.8842) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 17.7312(17.4955) | Bit/dim 3.8153(3.8198) | Xent 0.9961(1.0221) | Loss 563.7990(592.4932) | Error 0.3389(0.3656) Steps 0(0.00) | Grad Norm 617.5284(552.1018) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 17.4047(17.4123) | Bit/dim 3.8172(3.8177) | Xent 1.0089(1.0231) | Loss 568.4294(583.1644) | Error 0.3678(0.3673) Steps 0(0.00) | Grad Norm 782.5874(563.3029) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 17.2841(17.4685) | Bit/dim 3.7848(3.8167) | Xent 1.0574(1.0178) | Loss 548.5170(576.6180) | Error 0.3789(0.3667) Steps 0(0.00) | Grad Norm 703.1364(589.2076) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 86.8646, Epoch Time 1059.8967(989.8095), Bit/dim 3.8183(best: 3.8178), Xent 1.0002, Loss 4.3184, Error 0.3527(best: 0.3522)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2370 | Time 18.4245(17.4592) | Bit/dim 3.8162(3.8164) | Xent 0.9377(1.0170) | Loss 565.1800(633.6814) | Error 0.3522(0.3679) Steps 0(0.00) | Grad Norm 703.7415(598.9386) | Total Time 0.00(0.00)\n",
      "Iter 2380 | Time 17.1450(17.3389) | Bit/dim 3.8450(3.8177) | Xent 0.9427(1.0012) | Loss 567.3818(612.1145) | Error 0.3544(0.3623) Steps 0(0.00) | Grad Norm 256.6883(545.7470) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 17.4668(17.3860) | Bit/dim 3.7787(3.8140) | Xent 1.0389(1.0045) | Loss 549.7269(598.1663) | Error 0.3678(0.3633) Steps 0(0.00) | Grad Norm 655.4959(541.8829) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 16.2411(17.3782) | Bit/dim 3.8044(3.8124) | Xent 1.0164(1.0086) | Loss 565.0537(586.3440) | Error 0.3611(0.3628) Steps 0(0.00) | Grad Norm 790.3675(545.8296) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 17.8361(17.3294) | Bit/dim 3.7955(3.8093) | Xent 1.0185(1.0094) | Loss 561.9508(575.7216) | Error 0.3656(0.3622) Steps 0(0.00) | Grad Norm 556.1603(566.1877) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 16.4569(17.3821) | Bit/dim 3.8015(3.8092) | Xent 0.9002(1.0035) | Loss 559.9646(571.4658) | Error 0.3189(0.3598) Steps 0(0.00) | Grad Norm 321.3932(571.9175) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 86.2581, Epoch Time 1057.4106(991.8376), Bit/dim 3.8144(best: 3.8178), Xent 0.9691, Loss 4.2990, Error 0.3444(best: 0.3522)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2430 | Time 24.3994(17.5981) | Bit/dim 3.7997(3.8097) | Xent 0.9344(1.0066) | Loss 572.6599(622.6256) | Error 0.3478(0.3617) Steps 0(0.00) | Grad Norm 433.0372(589.3395) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 19.6980(17.5776) | Bit/dim 3.8104(3.8081) | Xent 1.0477(1.0189) | Loss 564.2736(606.4704) | Error 0.3944(0.3667) Steps 0(0.00) | Grad Norm 733.4830(612.5643) | Total Time 0.00(0.00)\n",
      "Iter 2450 | Time 16.9605(17.4702) | Bit/dim 3.7995(3.8068) | Xent 1.0052(1.0180) | Loss 556.3723(593.5472) | Error 0.3622(0.3660) Steps 0(0.00) | Grad Norm 440.4804(589.7173) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 17.0591(17.4299) | Bit/dim 3.8238(3.8086) | Xent 0.9475(1.0135) | Loss 561.8168(584.9713) | Error 0.3456(0.3644) Steps 0(0.00) | Grad Norm 456.4550(577.8689) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 19.3274(17.4377) | Bit/dim 3.8131(3.8087) | Xent 0.9937(1.0088) | Loss 554.2338(575.4168) | Error 0.3644(0.3628) Steps 0(0.00) | Grad Norm 597.6495(578.0480) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 86.7843, Epoch Time 1065.9718(994.0616), Bit/dim 3.8118(best: 3.8144), Xent 0.9629, Loss 4.2932, Error 0.3403(best: 0.3444)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2480 | Time 16.6549(17.4968) | Bit/dim 3.7679(3.8077) | Xent 1.0120(1.0069) | Loss 517.1978(634.3058) | Error 0.3844(0.3623) Steps 0(0.00) | Grad Norm 453.1018(561.3429) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 17.3801(17.4885) | Bit/dim 3.8079(3.8053) | Xent 0.9904(0.9950) | Loss 559.0194(612.1435) | Error 0.3589(0.3572) Steps 0(0.00) | Grad Norm 560.8067(513.0416) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 16.9695(17.4871) | Bit/dim 3.7889(3.8047) | Xent 0.9735(0.9894) | Loss 549.8461(595.1883) | Error 0.3422(0.3553) Steps 0(0.00) | Grad Norm 705.9601(536.5998) | Total Time 0.00(0.00)\n",
      "Iter 2510 | Time 20.3953(17.6067) | Bit/dim 3.7948(3.8050) | Xent 0.9773(0.9783) | Loss 573.1191(584.6735) | Error 0.3344(0.3506) Steps 0(0.00) | Grad Norm 351.8955(504.3301) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 17.6851(17.5224) | Bit/dim 3.7973(3.8011) | Xent 1.0093(0.9755) | Loss 537.4059(574.1408) | Error 0.3522(0.3509) Steps 0(0.00) | Grad Norm 453.4053(493.8209) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 18.1732(17.4089) | Bit/dim 3.7692(3.7986) | Xent 0.9197(0.9708) | Loss 554.9695(568.0582) | Error 0.3300(0.3483) Steps 0(0.00) | Grad Norm 344.9159(487.0282) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 85.5760, Epoch Time 1065.9858(996.2193), Bit/dim 3.7929(best: 3.8118), Xent 0.9337, Loss 4.2597, Error 0.3272(best: 0.3403)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2540 | Time 17.8457(17.3058) | Bit/dim 3.8027(3.7980) | Xent 1.0040(0.9717) | Loss 530.3734(617.5790) | Error 0.3600(0.3482) Steps 0(0.00) | Grad Norm 868.2233(529.3452) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 18.3132(17.3514) | Bit/dim 3.7868(3.7991) | Xent 0.9319(0.9682) | Loss 567.2321(601.0463) | Error 0.3433(0.3478) Steps 0(0.00) | Grad Norm 351.9369(531.3740) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 16.1465(17.3874) | Bit/dim 3.8137(3.7948) | Xent 0.9105(0.9612) | Loss 549.1925(586.2306) | Error 0.3178(0.3433) Steps 0(0.00) | Grad Norm 445.8002(496.5783) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 17.7419(17.4535) | Bit/dim 3.8107(3.7939) | Xent 1.0138(0.9585) | Loss 541.8975(576.7329) | Error 0.3489(0.3416) Steps 0(0.00) | Grad Norm 557.2752(483.8743) | Total Time 0.00(0.00)\n",
      "Iter 2580 | Time 18.7824(17.3704) | Bit/dim 3.7854(3.7919) | Xent 0.9996(0.9622) | Loss 566.1603(571.0863) | Error 0.3600(0.3439) Steps 0(0.00) | Grad Norm 615.4052(499.2300) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 86.5837, Epoch Time 1064.4216(998.2654), Bit/dim 3.8061(best: 3.7929), Xent 0.9491, Loss 4.2807, Error 0.3364(best: 0.3272)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2590 | Time 19.2852(17.4768) | Bit/dim 3.7501(3.7882) | Xent 0.8870(0.9682) | Loss 545.7140(632.1198) | Error 0.3322(0.3469) Steps 0(0.00) | Grad Norm 740.2056(557.1909) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 17.0547(17.4804) | Bit/dim 3.7742(3.7897) | Xent 0.8757(0.9586) | Loss 520.8031(607.3166) | Error 0.3156(0.3431) Steps 0(0.00) | Grad Norm 276.7267(532.0409) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 17.6136(17.4826) | Bit/dim 3.8104(3.7902) | Xent 0.9362(0.9600) | Loss 567.6633(592.4895) | Error 0.3200(0.3438) Steps 0(0.00) | Grad Norm 675.0847(505.7377) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 17.6346(17.4106) | Bit/dim 3.7731(3.7887) | Xent 0.9689(0.9595) | Loss 543.8033(581.8999) | Error 0.3578(0.3437) Steps 0(0.00) | Grad Norm 499.1713(496.7007) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 16.7143(17.2832) | Bit/dim 3.7678(3.7904) | Xent 1.0233(0.9602) | Loss 548.0737(571.8426) | Error 0.3589(0.3449) Steps 0(0.00) | Grad Norm 336.0113(522.3603) | Total Time 0.00(0.00)\n",
      "Iter 2640 | Time 17.8597(17.4772) | Bit/dim 3.8197(3.7897) | Xent 0.9578(0.9560) | Loss 531.5487(564.1583) | Error 0.3544(0.3436) Steps 0(0.00) | Grad Norm 565.8212(512.5495) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 87.7405, Epoch Time 1063.5136(1000.2228), Bit/dim 3.7831(best: 3.7929), Xent 0.9259, Loss 4.2461, Error 0.3270(best: 0.3272)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2650 | Time 16.8988(17.3108) | Bit/dim 3.7441(3.7856) | Xent 0.9581(0.9502) | Loss 565.1549(612.8440) | Error 0.3567(0.3420) Steps 0(0.00) | Grad Norm 351.6340(500.7393) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 17.5974(17.4852) | Bit/dim 3.7716(3.7853) | Xent 0.9074(0.9423) | Loss 553.7620(596.0704) | Error 0.3189(0.3376) Steps 0(0.00) | Grad Norm 606.6520(491.5518) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 18.1430(17.5240) | Bit/dim 3.7942(3.7844) | Xent 0.9929(0.9385) | Loss 554.7175(583.5720) | Error 0.3467(0.3358) Steps 0(0.00) | Grad Norm 436.3121(482.3086) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 17.9738(17.5497) | Bit/dim 3.7865(3.7845) | Xent 0.9391(0.9332) | Loss 554.6113(574.9621) | Error 0.3256(0.3331) Steps 0(0.00) | Grad Norm 506.9303(450.9404) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 16.7237(17.4185) | Bit/dim 3.7407(3.7835) | Xent 0.9818(0.9439) | Loss 557.0744(568.7531) | Error 0.3478(0.3371) Steps 0(0.00) | Grad Norm 710.8202(519.1394) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 88.0708, Epoch Time 1066.4552(1002.2098), Bit/dim 3.7793(best: 3.7831), Xent 0.9181, Loss 4.2383, Error 0.3266(best: 0.3270)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2700 | Time 17.3136(17.5178) | Bit/dim 3.7903(3.7840) | Xent 0.9394(0.9429) | Loss 560.6043(631.1734) | Error 0.3478(0.3381) Steps 0(0.00) | Grad Norm 638.9905(521.2205) | Total Time 0.00(0.00)\n",
      "Iter 2710 | Time 17.4978(17.5010) | Bit/dim 3.7699(3.7837) | Xent 0.9474(0.9422) | Loss 553.8500(609.2635) | Error 0.3489(0.3393) Steps 0(0.00) | Grad Norm 813.1463(539.1266) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 16.5984(17.4894) | Bit/dim 3.7623(3.7845) | Xent 0.8595(0.9388) | Loss 553.0226(594.0493) | Error 0.2978(0.3347) Steps 0(0.00) | Grad Norm 306.1805(546.8396) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 16.3321(17.3706) | Bit/dim 3.7580(3.7801) | Xent 0.8805(0.9335) | Loss 540.4034(581.2260) | Error 0.3056(0.3328) Steps 0(0.00) | Grad Norm 519.9637(545.6983) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 17.8438(17.3737) | Bit/dim 3.7865(3.7782) | Xent 0.9511(0.9462) | Loss 542.1266(574.4091) | Error 0.3467(0.3388) Steps 0(0.00) | Grad Norm 289.1286(577.4100) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 16.1559(17.3142) | Bit/dim 3.8046(3.7781) | Xent 0.9526(0.9438) | Loss 523.5851(566.0132) | Error 0.3467(0.3371) Steps 0(0.00) | Grad Norm 420.4357(564.1748) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 87.5803, Epoch Time 1058.3270(1003.8933), Bit/dim 3.7749(best: 3.7793), Xent 0.9017, Loss 4.2257, Error 0.3196(best: 0.3266)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2760 | Time 16.1859(17.4281) | Bit/dim 3.7763(3.7752) | Xent 0.9705(0.9413) | Loss 557.2467(617.0887) | Error 0.3456(0.3361) Steps 0(0.00) | Grad Norm 693.6708(568.2430) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 16.8430(17.4093) | Bit/dim 3.7849(3.7759) | Xent 0.9887(0.9533) | Loss 550.2278(597.0298) | Error 0.3622(0.3395) Steps 0(0.00) | Grad Norm 673.8993(585.2436) | Total Time 0.00(0.00)\n",
      "Iter 2780 | Time 17.1752(17.3971) | Bit/dim 3.7785(3.7757) | Xent 0.8930(0.9440) | Loss 536.3743(584.9079) | Error 0.3111(0.3373) Steps 0(0.00) | Grad Norm 482.8991(564.4575) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 17.3379(17.2474) | Bit/dim 3.7728(3.7765) | Xent 0.9175(0.9398) | Loss 560.1133(576.7467) | Error 0.3144(0.3364) Steps 0(0.00) | Grad Norm 670.9175(563.2037) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 17.1686(17.2678) | Bit/dim 3.7656(3.7763) | Xent 0.8520(0.9321) | Loss 533.7247(570.1178) | Error 0.2933(0.3319) Steps 0(0.00) | Grad Norm 304.9995(540.9818) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 86.9064, Epoch Time 1056.0794(1005.4589), Bit/dim 3.7715(best: 3.7749), Xent 0.8866, Loss 4.2148, Error 0.3143(best: 0.3196)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2810 | Time 17.2073(17.2360) | Bit/dim 3.7901(3.7773) | Xent 0.9544(0.9288) | Loss 564.0602(630.2572) | Error 0.3367(0.3315) Steps 0(0.00) | Grad Norm 440.3767(498.1486) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 16.4807(17.2247) | Bit/dim 3.7635(3.7780) | Xent 0.9210(0.9259) | Loss 544.6210(606.6026) | Error 0.3367(0.3317) Steps 0(0.00) | Grad Norm 538.8569(515.1310) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 15.9691(17.1647) | Bit/dim 3.7488(3.7761) | Xent 0.8586(0.9212) | Loss 533.9268(589.7083) | Error 0.3011(0.3283) Steps 0(0.00) | Grad Norm 333.2590(495.3643) | Total Time 0.00(0.00)\n",
      "Iter 2840 | Time 16.9368(17.2758) | Bit/dim 3.7523(3.7732) | Xent 0.8639(0.9126) | Loss 545.5763(577.6672) | Error 0.2989(0.3243) Steps 0(0.00) | Grad Norm 408.5235(492.0433) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 15.7316(17.1578) | Bit/dim 3.7537(3.7723) | Xent 0.9659(0.9138) | Loss 546.8300(568.3432) | Error 0.3456(0.3256) Steps 0(0.00) | Grad Norm 634.6442(491.9301) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 17.8075(17.3379) | Bit/dim 3.7866(3.7703) | Xent 0.9258(0.9225) | Loss 563.0334(563.2423) | Error 0.3433(0.3295) Steps 0(0.00) | Grad Norm 413.3418(516.1027) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 87.6844, Epoch Time 1058.9337(1007.0632), Bit/dim 3.7757(best: 3.7715), Xent 0.8863, Loss 4.2189, Error 0.3161(best: 0.3143)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2870 | Time 17.5283(17.3373) | Bit/dim 3.7477(3.7694) | Xent 0.9658(0.9215) | Loss 558.8183(616.4470) | Error 0.3322(0.3284) Steps 0(0.00) | Grad Norm 1111.7193(538.1354) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 17.1390(17.3269) | Bit/dim 3.7431(3.7730) | Xent 0.9251(0.9225) | Loss 562.7485(598.8424) | Error 0.3378(0.3287) Steps 0(0.00) | Grad Norm 338.5602(564.2945) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 15.9310(17.3033) | Bit/dim 3.7487(3.7729) | Xent 0.8451(0.9152) | Loss 553.7668(586.4148) | Error 0.2922(0.3269) Steps 0(0.00) | Grad Norm 399.8617(523.4405) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 15.8200(17.2612) | Bit/dim 3.7610(3.7705) | Xent 0.9399(0.9128) | Loss 548.9400(575.6977) | Error 0.3144(0.3248) Steps 0(0.00) | Grad Norm 540.1135(502.9119) | Total Time 0.00(0.00)\n",
      "Iter 2910 | Time 17.0004(17.4435) | Bit/dim 3.7585(3.7677) | Xent 0.8981(0.9065) | Loss 555.1712(565.9859) | Error 0.3133(0.3237) Steps 0(0.00) | Grad Norm 748.4217(490.8093) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 88.3114, Epoch Time 1060.4271(1008.6641), Bit/dim 3.7597(best: 3.7715), Xent 0.8634, Loss 4.1913, Error 0.3086(best: 0.3143)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2920 | Time 20.8312(17.4911) | Bit/dim 3.7681(3.7673) | Xent 0.8906(0.9006) | Loss 548.8572(623.2035) | Error 0.3022(0.3209) Steps 0(0.00) | Grad Norm 584.2696(471.6451) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 17.7945(17.4292) | Bit/dim 3.7454(3.7651) | Xent 0.8941(0.9049) | Loss 539.5264(603.9609) | Error 0.3300(0.3228) Steps 0(0.00) | Grad Norm 520.8640(488.1670) | Total Time 0.00(0.00)\n",
      "Iter 2940 | Time 18.2765(17.3807) | Bit/dim 3.7616(3.7625) | Xent 0.8592(0.8929) | Loss 548.3670(587.7929) | Error 0.3056(0.3182) Steps 0(0.00) | Grad Norm 294.4846(460.8334) | Total Time 0.00(0.00)\n",
      "Iter 2950 | Time 16.0645(17.3563) | Bit/dim 3.7491(3.7614) | Xent 0.9650(0.8943) | Loss 514.2640(575.5063) | Error 0.3511(0.3182) Steps 0(0.00) | Grad Norm 505.6895(449.7941) | Total Time 0.00(0.00)\n",
      "Iter 2960 | Time 19.5664(17.4961) | Bit/dim 3.7342(3.7570) | Xent 0.8981(0.8907) | Loss 556.0286(566.5032) | Error 0.3144(0.3159) Steps 0(0.00) | Grad Norm 1031.8785(464.4481) | Total Time 0.00(0.00)\n",
      "Iter 2970 | Time 19.2037(17.5967) | Bit/dim 3.7627(3.7591) | Xent 0.9593(0.9008) | Loss 559.2702(561.3443) | Error 0.3511(0.3202) Steps 0(0.00) | Grad Norm 732.9484(489.5135) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 89.8125, Epoch Time 1073.8060(1010.6183), Bit/dim 3.7618(best: 3.7597), Xent 0.8861, Loss 4.2049, Error 0.3140(best: 0.3086)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2980 | Time 15.0770(17.5237) | Bit/dim 3.7418(3.7603) | Xent 0.9597(0.8950) | Loss 542.8436(613.4318) | Error 0.3489(0.3176) Steps 0(0.00) | Grad Norm 865.7556(498.0884) | Total Time 0.00(0.00)\n",
      "Iter 2990 | Time 17.9002(17.4802) | Bit/dim 3.7596(3.7606) | Xent 0.8170(0.8897) | Loss 544.9806(594.0038) | Error 0.2978(0.3167) Steps 0(0.00) | Grad Norm 569.3509(517.5845) | Total Time 0.00(0.00)\n",
      "Iter 3000 | Time 15.5240(17.3907) | Bit/dim 3.8058(3.7638) | Xent 0.8743(0.8877) | Loss 530.3981(579.4898) | Error 0.3156(0.3170) Steps 0(0.00) | Grad Norm 316.2835(520.4063) | Total Time 0.00(0.00)\n",
      "Iter 3010 | Time 17.9010(17.2377) | Bit/dim 3.7548(3.7586) | Xent 0.8722(0.8874) | Loss 558.9401(570.9916) | Error 0.2944(0.3169) Steps 0(0.00) | Grad Norm 431.5319(499.4092) | Total Time 0.00(0.00)\n",
      "Iter 3020 | Time 19.3019(17.1896) | Bit/dim 3.7462(3.7561) | Xent 0.9054(0.8855) | Loss 555.0124(563.8127) | Error 0.3156(0.3159) Steps 0(0.00) | Grad Norm 465.8582(473.2146) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 87.9930, Epoch Time 1046.9064(1011.7070), Bit/dim 3.7591(best: 3.7597), Xent 0.8579, Loss 4.1880, Error 0.3024(best: 0.3086)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3030 | Time 17.6289(17.0889) | Bit/dim 3.7590(3.7535) | Xent 0.9084(0.8883) | Loss 562.1143(620.9519) | Error 0.3356(0.3175) Steps 0(0.00) | Grad Norm 415.0672(482.9403) | Total Time 0.00(0.00)\n",
      "Iter 3040 | Time 17.7278(17.1377) | Bit/dim 3.7654(3.7534) | Xent 0.8153(0.8737) | Loss 543.7749(600.4066) | Error 0.2989(0.3123) Steps 0(0.00) | Grad Norm 553.7568(460.7330) | Total Time 0.00(0.00)\n",
      "Iter 3050 | Time 17.9751(17.1917) | Bit/dim 3.7629(3.7527) | Xent 0.7889(0.8728) | Loss 536.2864(584.5355) | Error 0.2922(0.3140) Steps 0(0.00) | Grad Norm 507.9445(479.5934) | Total Time 0.00(0.00)\n",
      "Iter 3060 | Time 19.6079(17.3349) | Bit/dim 3.7646(3.7529) | Xent 0.9570(0.8741) | Loss 579.9079(574.6920) | Error 0.3311(0.3131) Steps 0(0.00) | Grad Norm 657.1180(497.4257) | Total Time 0.00(0.00)\n",
      "Iter 3070 | Time 16.4913(17.2635) | Bit/dim 3.7794(3.7512) | Xent 0.9554(0.8810) | Loss 536.1678(565.2278) | Error 0.3344(0.3152) Steps 0(0.00) | Grad Norm 864.8431(525.1520) | Total Time 0.00(0.00)\n",
      "Iter 3080 | Time 18.2254(17.2823) | Bit/dim 3.7584(3.7510) | Xent 0.8539(0.8768) | Loss 541.8917(558.4794) | Error 0.3044(0.3139) Steps 0(0.00) | Grad Norm 308.8432(497.6973) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 89.7947, Epoch Time 1057.7330(1013.0878), Bit/dim 3.7491(best: 3.7591), Xent 0.8465, Loss 4.1723, Error 0.2985(best: 0.3024)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3090 | Time 18.0259(17.2675) | Bit/dim 3.7543(3.7525) | Xent 1.0170(0.8829) | Loss 561.9645(610.6889) | Error 0.3511(0.3150) Steps 0(0.00) | Grad Norm 702.6681(523.1963) | Total Time 0.00(0.00)\n",
      "Iter 3100 | Time 18.0053(17.3780) | Bit/dim 3.7198(3.7505) | Xent 0.8841(0.8905) | Loss 533.1348(592.6602) | Error 0.3100(0.3182) Steps 0(0.00) | Grad Norm 275.0784(514.2184) | Total Time 0.00(0.00)\n",
      "Iter 3110 | Time 16.2370(17.3397) | Bit/dim 3.7774(3.7493) | Xent 0.8806(0.8820) | Loss 551.8257(579.9265) | Error 0.3211(0.3157) Steps 0(0.00) | Grad Norm 340.0311(541.7125) | Total Time 0.00(0.00)\n",
      "Iter 3120 | Time 15.5314(17.3674) | Bit/dim 3.7260(3.7481) | Xent 0.9100(0.8875) | Loss 534.7762(570.2862) | Error 0.3278(0.3164) Steps 0(0.00) | Grad Norm 569.1571(537.1769) | Total Time 0.00(0.00)\n",
      "Iter 3130 | Time 17.7690(17.3382) | Bit/dim 3.7488(3.7478) | Xent 0.8624(0.8808) | Loss 536.5430(561.2337) | Error 0.3111(0.3148) Steps 0(0.00) | Grad Norm 490.4115(518.9426) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 86.8968, Epoch Time 1066.3352(1014.6852), Bit/dim 3.7464(best: 3.7491), Xent 0.8679, Loss 4.1803, Error 0.3044(best: 0.2985)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3140 | Time 17.0097(17.4188) | Bit/dim 3.7422(3.7447) | Xent 0.9478(0.8757) | Loss 559.7734(616.7936) | Error 0.3122(0.3120) Steps 0(0.00) | Grad Norm 777.9580(527.0637) | Total Time 0.00(0.00)\n",
      "Iter 3150 | Time 17.0986(17.5661) | Bit/dim 3.7397(3.7421) | Xent 0.8443(0.8737) | Loss 528.9269(597.4053) | Error 0.2989(0.3108) Steps 0(0.00) | Grad Norm 354.4870(492.7370) | Total Time 0.00(0.00)\n",
      "Iter 3160 | Time 16.9786(17.5043) | Bit/dim 3.7811(3.7452) | Xent 0.8918(0.8700) | Loss 556.0474(583.2507) | Error 0.3122(0.3094) Steps 0(0.00) | Grad Norm 832.8783(511.6559) | Total Time 0.00(0.00)\n",
      "Iter 3170 | Time 19.8360(17.4625) | Bit/dim 3.7307(3.7448) | Xent 0.9116(0.8742) | Loss 549.9031(573.3263) | Error 0.3333(0.3123) Steps 0(0.00) | Grad Norm 392.2245(526.6842) | Total Time 0.00(0.00)\n",
      "Iter 3180 | Time 16.8280(17.6948) | Bit/dim 3.7392(3.7452) | Xent 0.8544(0.8742) | Loss 549.6996(566.3891) | Error 0.3100(0.3121) Steps 0(0.00) | Grad Norm 364.5370(503.8857) | Total Time 0.00(0.00)\n",
      "Iter 3190 | Time 16.4474(17.4949) | Bit/dim 3.7637(3.7449) | Xent 0.8430(0.8706) | Loss 551.3329(558.1621) | Error 0.3056(0.3106) Steps 0(0.00) | Grad Norm 392.7482(488.1962) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 88.1673, Epoch Time 1069.3187(1016.3242), Bit/dim 3.7421(best: 3.7464), Xent 0.8543, Loss 4.1692, Error 0.3022(best: 0.2985)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3200 | Time 16.4553(17.2811) | Bit/dim 3.7374(3.7447) | Xent 0.8486(0.8628) | Loss 523.4377(609.0673) | Error 0.2978(0.3084) Steps 0(0.00) | Grad Norm 500.6987(491.7300) | Total Time 0.00(0.00)\n",
      "Iter 3210 | Time 17.9254(17.4325) | Bit/dim 3.7320(3.7414) | Xent 0.8197(0.8620) | Loss 542.7129(591.2346) | Error 0.3033(0.3085) Steps 0(0.00) | Grad Norm 490.8800(507.2567) | Total Time 0.00(0.00)\n",
      "Iter 3220 | Time 18.7068(17.6445) | Bit/dim 3.7603(3.7415) | Xent 0.8824(0.8581) | Loss 535.8206(578.3274) | Error 0.3178(0.3070) Steps 0(0.00) | Grad Norm 774.1164(506.5339) | Total Time 0.00(0.00)\n",
      "Iter 3230 | Time 17.5239(17.5726) | Bit/dim 3.7540(3.7434) | Xent 0.8838(0.8678) | Loss 551.2555(568.8308) | Error 0.3044(0.3100) Steps 0(0.00) | Grad Norm 509.3131(526.7834) | Total Time 0.00(0.00)\n",
      "Iter 3240 | Time 16.9865(17.4200) | Bit/dim 3.7373(3.7440) | Xent 0.9017(0.8747) | Loss 550.6146(562.1791) | Error 0.3300(0.3130) Steps 0(0.00) | Grad Norm 405.2475(508.9753) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 88.0691, Epoch Time 1061.5742(1017.6817), Bit/dim 3.7453(best: 3.7421), Xent 0.8401, Loss 4.1654, Error 0.2996(best: 0.2985)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3250 | Time 16.2880(17.3146) | Bit/dim 3.7677(3.7442) | Xent 0.8692(0.8694) | Loss 534.6148(619.2846) | Error 0.3056(0.3097) Steps 0(0.00) | Grad Norm 654.6794(498.8900) | Total Time 0.00(0.00)\n",
      "Iter 3260 | Time 16.6498(17.4074) | Bit/dim 3.7137(3.7415) | Xent 0.8073(0.8643) | Loss 513.4449(597.4361) | Error 0.2733(0.3064) Steps 0(0.00) | Grad Norm 484.3229(494.1854) | Total Time 0.00(0.00)\n",
      "Iter 3270 | Time 18.3074(17.4197) | Bit/dim 3.7288(3.7388) | Xent 0.8650(0.8569) | Loss 546.0601(582.9314) | Error 0.3189(0.3051) Steps 0(0.00) | Grad Norm 704.4239(485.9522) | Total Time 0.00(0.00)\n",
      "Iter 3280 | Time 17.8100(17.4961) | Bit/dim 3.7506(3.7417) | Xent 0.8101(0.8482) | Loss 534.5341(572.4822) | Error 0.2756(0.3012) Steps 0(0.00) | Grad Norm 618.2366(485.6388) | Total Time 0.00(0.00)\n",
      "Iter 3290 | Time 15.8805(17.3751) | Bit/dim 3.7187(3.7357) | Xent 0.9133(0.8521) | Loss 540.3234(563.2563) | Error 0.3267(0.3021) Steps 0(0.00) | Grad Norm 557.3791(511.0561) | Total Time 0.00(0.00)\n",
      "Iter 3300 | Time 17.8353(17.4524) | Bit/dim 3.7624(3.7397) | Xent 0.9249(0.8551) | Loss 546.4560(557.0796) | Error 0.3167(0.3040) Steps 0(0.00) | Grad Norm 647.0564(512.2671) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 88.9274, Epoch Time 1068.0205(1019.1918), Bit/dim 3.7350(best: 3.7421), Xent 0.8501, Loss 4.1600, Error 0.3025(best: 0.2985)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3310 | Time 16.0413(17.5199) | Bit/dim 3.7093(3.7373) | Xent 0.8375(0.8507) | Loss 521.6613(608.3420) | Error 0.2867(0.3029) Steps 0(0.00) | Grad Norm 332.6572(484.1142) | Total Time 0.00(0.00)\n",
      "Iter 3320 | Time 15.7961(17.5337) | Bit/dim 3.7342(3.7348) | Xent 0.8306(0.8401) | Loss 532.9916(589.8795) | Error 0.2789(0.2993) Steps 0(0.00) | Grad Norm 495.0977(460.9316) | Total Time 0.00(0.00)\n",
      "Iter 3330 | Time 16.9725(17.3515) | Bit/dim 3.7093(3.7317) | Xent 0.7859(0.8433) | Loss 553.1398(576.0428) | Error 0.3033(0.3004) Steps 0(0.00) | Grad Norm 500.3439(512.5423) | Total Time 0.00(0.00)\n",
      "Iter 3340 | Time 16.8065(17.4250) | Bit/dim 3.7567(3.7338) | Xent 0.7917(0.8495) | Loss 537.3697(566.3115) | Error 0.2733(0.3037) Steps 0(0.00) | Grad Norm 404.1058(509.2735) | Total Time 0.00(0.00)\n",
      "Iter 3350 | Time 17.4681(17.3465) | Bit/dim 3.7122(3.7382) | Xent 0.8742(0.8599) | Loss 536.8918(558.8761) | Error 0.3244(0.3059) Steps 0(0.00) | Grad Norm 421.8535(515.1152) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 88.6149, Epoch Time 1059.0154(1020.3866), Bit/dim 3.7289(best: 3.7350), Xent 0.8273, Loss 4.1425, Error 0.2954(best: 0.2985)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3360 | Time 17.6866(17.3002) | Bit/dim 3.7478(3.7365) | Xent 0.8232(0.8524) | Loss 538.3719(616.6667) | Error 0.3011(0.3028) Steps 0(0.00) | Grad Norm 367.0143(493.2631) | Total Time 0.00(0.00)\n",
      "Iter 3370 | Time 16.6914(17.3157) | Bit/dim 3.7285(3.7340) | Xent 0.8063(0.8392) | Loss 526.7349(595.1920) | Error 0.2878(0.2979) Steps 0(0.00) | Grad Norm 480.5843(462.2241) | Total Time 0.00(0.00)\n",
      "Iter 3380 | Time 17.5791(17.4574) | Bit/dim 3.7088(3.7284) | Xent 0.8530(0.8377) | Loss 525.6371(581.1104) | Error 0.3078(0.2977) Steps 0(0.00) | Grad Norm 679.8295(468.8841) | Total Time 0.00(0.00)\n",
      "Iter 3390 | Time 17.5473(17.3553) | Bit/dim 3.7434(3.7305) | Xent 0.8362(0.8414) | Loss 551.5988(570.0814) | Error 0.2956(0.2993) Steps 0(0.00) | Grad Norm 476.7712(502.7832) | Total Time 0.00(0.00)\n",
      "Iter 3400 | Time 16.9055(17.2448) | Bit/dim 3.7368(3.7332) | Xent 0.7889(0.8369) | Loss 528.0295(558.8508) | Error 0.2711(0.2985) Steps 0(0.00) | Grad Norm 406.0892(483.6667) | Total Time 0.00(0.00)\n",
      "Iter 3410 | Time 17.1162(17.0346) | Bit/dim 3.7309(3.7347) | Xent 0.8679(0.8381) | Loss 537.8641(552.5335) | Error 0.3056(0.2997) Steps 0(0.00) | Grad Norm 455.2414(465.3252) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 88.4049, Epoch Time 1050.1177(1021.2785), Bit/dim 3.7330(best: 3.7289), Xent 0.8180, Loss 4.1420, Error 0.2878(best: 0.2954)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3420 | Time 17.4909(17.2278) | Bit/dim 3.7350(3.7313) | Xent 0.8269(0.8331) | Loss 545.3947(605.6131) | Error 0.3022(0.2989) Steps 0(0.00) | Grad Norm 384.6919(436.7096) | Total Time 0.00(0.00)\n",
      "Iter 3430 | Time 16.4992(17.0964) | Bit/dim 3.6927(3.7311) | Xent 0.8005(0.8239) | Loss 526.8022(587.6757) | Error 0.2756(0.2938) Steps 0(0.00) | Grad Norm 257.8131(455.2771) | Total Time 0.00(0.00)\n",
      "Iter 3440 | Time 16.3553(17.0889) | Bit/dim 3.7375(3.7293) | Xent 0.8064(0.8212) | Loss 530.1326(572.0573) | Error 0.2856(0.2927) Steps 0(0.00) | Grad Norm 517.8486(449.5487) | Total Time 0.00(0.00)\n",
      "Iter 3450 | Time 16.9339(17.2397) | Bit/dim 3.7146(3.7268) | Xent 0.7795(0.8161) | Loss 534.8553(561.5910) | Error 0.2767(0.2905) Steps 0(0.00) | Grad Norm 316.7045(454.6903) | Total Time 0.00(0.00)\n",
      "Iter 3460 | Time 18.9718(17.4509) | Bit/dim 3.7494(3.7280) | Xent 0.7712(0.8152) | Loss 548.2153(555.1887) | Error 0.2733(0.2898) Steps 0(0.00) | Grad Norm 285.9159(444.8101) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 89.6663, Epoch Time 1068.6858(1022.7007), Bit/dim 3.7288(best: 3.7289), Xent 0.8240, Loss 4.1408, Error 0.2944(best: 0.2878)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3470 | Time 17.8007(17.4191) | Bit/dim 3.7096(3.7266) | Xent 0.8137(0.8099) | Loss 540.5593(614.4081) | Error 0.3022(0.2886) Steps 0(0.00) | Grad Norm 442.0717(456.6460) | Total Time 0.00(0.00)\n",
      "Iter 3480 | Time 16.9005(17.3622) | Bit/dim 3.6700(3.7270) | Xent 0.8617(0.8112) | Loss 526.2505(595.0360) | Error 0.2956(0.2888) Steps 0(0.00) | Grad Norm 545.0547(463.0501) | Total Time 0.00(0.00)\n",
      "Iter 3490 | Time 17.0703(17.3957) | Bit/dim 3.7257(3.7232) | Xent 0.7647(0.8157) | Loss 530.4484(578.2865) | Error 0.2744(0.2901) Steps 0(0.00) | Grad Norm 422.0103(493.8709) | Total Time 0.00(0.00)\n",
      "Iter 3500 | Time 16.6160(17.4244) | Bit/dim 3.6904(3.7219) | Xent 0.8029(0.8144) | Loss 532.4211(567.9026) | Error 0.2889(0.2910) Steps 0(0.00) | Grad Norm 406.6461(468.1811) | Total Time 0.00(0.00)\n",
      "Iter 3510 | Time 18.0214(17.4718) | Bit/dim 3.7451(3.7230) | Xent 0.7938(0.8134) | Loss 510.9497(560.1385) | Error 0.2811(0.2898) Steps 0(0.00) | Grad Norm 506.9291(483.6445) | Total Time 0.00(0.00)\n",
      "Iter 3520 | Time 17.8828(17.3711) | Bit/dim 3.7266(3.7242) | Xent 0.8480(0.8145) | Loss 536.4243(555.7112) | Error 0.2989(0.2901) Steps 0(0.00) | Grad Norm 606.4683(482.2524) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 88.7843, Epoch Time 1061.8039(1023.8738), Bit/dim 3.7231(best: 3.7288), Xent 0.8578, Loss 4.1520, Error 0.3076(best: 0.2878)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3530 | Time 17.3830(17.3491) | Bit/dim 3.7539(3.7239) | Xent 0.7836(0.8187) | Loss 543.0932(609.5347) | Error 0.2644(0.2914) Steps 0(0.00) | Grad Norm 318.0979(522.1458) | Total Time 0.00(0.00)\n",
      "Iter 3540 | Time 17.2124(17.4374) | Bit/dim 3.7690(3.7296) | Xent 0.7980(0.8116) | Loss 523.4442(591.4236) | Error 0.2811(0.2891) Steps 0(0.00) | Grad Norm 573.9866(530.4991) | Total Time 0.00(0.00)\n",
      "Iter 3550 | Time 16.8698(17.4365) | Bit/dim 3.7436(3.7280) | Xent 0.7620(0.8136) | Loss 527.4624(576.7274) | Error 0.2689(0.2902) Steps 0(0.00) | Grad Norm 375.9614(516.3853) | Total Time 0.00(0.00)\n",
      "Iter 3560 | Time 15.9623(17.3920) | Bit/dim 3.7126(3.7260) | Xent 0.9001(0.8190) | Loss 537.3378(566.0147) | Error 0.3344(0.2934) Steps 0(0.00) | Grad Norm 503.5053(521.7896) | Total Time 0.00(0.00)\n",
      "Iter 3570 | Time 18.6629(17.4932) | Bit/dim 3.7103(3.7231) | Xent 0.8517(0.8171) | Loss 551.1783(558.1204) | Error 0.3033(0.2918) Steps 0(0.00) | Grad Norm 424.1638(492.3792) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 87.7694, Epoch Time 1066.1930(1025.1434), Bit/dim 3.7198(best: 3.7231), Xent 0.8480, Loss 4.1438, Error 0.2989(best: 0.2878)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3580 | Time 16.9202(17.4007) | Bit/dim 3.7058(3.7214) | Xent 0.8152(0.8131) | Loss 530.6931(613.4341) | Error 0.2922(0.2900) Steps 0(0.00) | Grad Norm 512.0132(482.7149) | Total Time 0.00(0.00)\n",
      "Iter 3590 | Time 17.6594(17.3455) | Bit/dim 3.7390(3.7199) | Xent 0.7747(0.8102) | Loss 541.4460(592.9470) | Error 0.2744(0.2895) Steps 0(0.00) | Grad Norm 660.0473(483.3935) | Total Time 0.00(0.00)\n",
      "Iter 3600 | Time 19.0769(17.4567) | Bit/dim 3.7074(3.7196) | Xent 0.7768(0.8042) | Loss 541.9084(579.2633) | Error 0.2811(0.2885) Steps 0(0.00) | Grad Norm 400.6809(484.5520) | Total Time 0.00(0.00)\n",
      "Iter 3610 | Time 17.4928(17.5203) | Bit/dim 3.7726(3.7199) | Xent 0.7835(0.8085) | Loss 547.0505(569.6517) | Error 0.2789(0.2892) Steps 0(0.00) | Grad Norm 1006.5062(507.8302) | Total Time 0.00(0.00)\n",
      "Iter 3620 | Time 16.6003(17.4371) | Bit/dim 3.7344(3.7224) | Xent 0.8077(0.8091) | Loss 540.1997(561.8771) | Error 0.2956(0.2903) Steps 0(0.00) | Grad Norm 608.9142(496.6432) | Total Time 0.00(0.00)\n",
      "Iter 3630 | Time 16.0579(17.3191) | Bit/dim 3.7389(3.7234) | Xent 0.7931(0.8051) | Loss 528.2172(554.3359) | Error 0.2900(0.2892) Steps 0(0.00) | Grad Norm 298.3601(471.8354) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 89.7030, Epoch Time 1060.9816(1026.2185), Bit/dim 3.7195(best: 3.7198), Xent 0.8089, Loss 4.1239, Error 0.2844(best: 0.2878)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3640 | Time 17.2619(17.2908) | Bit/dim 3.7787(3.7250) | Xent 0.8275(0.8040) | Loss 546.1388(604.1152) | Error 0.2900(0.2876) Steps 0(0.00) | Grad Norm 711.6512(505.1018) | Total Time 0.00(0.00)\n",
      "Iter 3650 | Time 16.7067(17.3386) | Bit/dim 3.7180(3.7221) | Xent 0.8984(0.8069) | Loss 556.7884(587.1573) | Error 0.3211(0.2879) Steps 0(0.00) | Grad Norm 500.3413(530.5948) | Total Time 0.00(0.00)\n",
      "Iter 3660 | Time 18.0020(17.2569) | Bit/dim 3.7130(3.7278) | Xent 0.7879(0.8025) | Loss 551.8459(573.9619) | Error 0.2944(0.2870) Steps 0(0.00) | Grad Norm 346.1757(521.6662) | Total Time 0.00(0.00)\n",
      "Iter 3670 | Time 15.9255(17.2680) | Bit/dim 3.7054(3.7276) | Xent 0.7664(0.7942) | Loss 534.0994(563.9895) | Error 0.2856(0.2835) Steps 0(0.00) | Grad Norm 418.0234(489.1054) | Total Time 0.00(0.00)\n",
      "Iter 3680 | Time 19.0621(17.3051) | Bit/dim 3.7009(3.7209) | Xent 0.8022(0.7908) | Loss 535.3140(557.3043) | Error 0.2789(0.2827) Steps 0(0.00) | Grad Norm 361.1695(449.3580) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 90.9027, Epoch Time 1062.1357(1027.2960), Bit/dim 3.7169(best: 3.7195), Xent 0.7859, Loss 4.1099, Error 0.2783(best: 0.2844)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3690 | Time 16.8802(17.4453) | Bit/dim 3.7404(3.7213) | Xent 0.8274(0.7895) | Loss 539.1352(616.7175) | Error 0.2989(0.2817) Steps 0(0.00) | Grad Norm 522.7534(440.7803) | Total Time 0.00(0.00)\n",
      "Iter 3700 | Time 16.5332(17.3354) | Bit/dim 3.7058(3.7196) | Xent 0.7725(0.7846) | Loss 544.7891(594.9564) | Error 0.2656(0.2799) Steps 0(0.00) | Grad Norm 373.5285(432.8264) | Total Time 0.00(0.00)\n",
      "Iter 3710 | Time 16.1257(17.2771) | Bit/dim 3.7128(3.7172) | Xent 0.7855(0.7846) | Loss 504.6107(578.5611) | Error 0.2611(0.2804) Steps 0(0.00) | Grad Norm 417.2340(448.9872) | Total Time 0.00(0.00)\n",
      "Iter 3720 | Time 19.0766(17.4036) | Bit/dim 3.7445(3.7158) | Xent 0.8243(0.7829) | Loss 533.1758(567.4529) | Error 0.2989(0.2805) Steps 0(0.00) | Grad Norm 273.7769(433.6750) | Total Time 0.00(0.00)\n",
      "Iter 3730 | Time 17.6362(17.3502) | Bit/dim 3.6963(3.7154) | Xent 0.8831(0.7889) | Loss 537.0897(560.1667) | Error 0.3289(0.2828) Steps 0(0.00) | Grad Norm 768.8037(460.8304) | Total Time 0.00(0.00)\n",
      "Iter 3740 | Time 17.1594(17.3790) | Bit/dim 3.7022(3.7170) | Xent 0.7778(0.7899) | Loss 549.0656(554.8708) | Error 0.2756(0.2833) Steps 0(0.00) | Grad Norm 333.0297(441.6421) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 88.9974, Epoch Time 1061.0617(1028.3090), Bit/dim 3.7157(best: 3.7169), Xent 0.7882, Loss 4.1098, Error 0.2811(best: 0.2783)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3750 | Time 16.9061(17.3365) | Bit/dim 3.7261(3.7154) | Xent 0.7807(0.7941) | Loss 552.1127(606.3830) | Error 0.2778(0.2842) Steps 0(0.00) | Grad Norm 413.1318(488.0688) | Total Time 0.00(0.00)\n",
      "Iter 3760 | Time 17.3523(17.4266) | Bit/dim 3.7206(3.7144) | Xent 0.6983(0.7901) | Loss 560.0270(587.7990) | Error 0.2567(0.2826) Steps 0(0.00) | Grad Norm 613.6222(480.6722) | Total Time 0.00(0.00)\n",
      "Iter 3770 | Time 18.5277(17.3481) | Bit/dim 3.7380(3.7123) | Xent 0.8378(0.7812) | Loss 551.9340(572.9303) | Error 0.2878(0.2793) Steps 0(0.00) | Grad Norm 604.0025(456.7319) | Total Time 0.00(0.00)\n",
      "Iter 3780 | Time 17.3361(17.3915) | Bit/dim 3.7353(3.7152) | Xent 0.7089(0.7798) | Loss 538.2889(563.7147) | Error 0.2500(0.2783) Steps 0(0.00) | Grad Norm 380.1223(447.3772) | Total Time 0.00(0.00)\n",
      "Iter 3790 | Time 18.9718(17.4947) | Bit/dim 3.7057(3.7139) | Xent 0.8517(0.7764) | Loss 565.3964(557.3611) | Error 0.2856(0.2763) Steps 0(0.00) | Grad Norm 302.4756(416.5664) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 90.5097, Epoch Time 1069.1512(1029.5343), Bit/dim 3.7070(best: 3.7157), Xent 0.7810, Loss 4.0975, Error 0.2757(best: 0.2783)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3800 | Time 18.3234(17.5102) | Bit/dim 3.7163(3.7138) | Xent 0.8489(0.7769) | Loss 545.7871(620.8915) | Error 0.2956(0.2759) Steps 0(0.00) | Grad Norm 950.4132(449.6259) | Total Time 0.00(0.00)\n",
      "Iter 3810 | Time 16.7171(17.4897) | Bit/dim 3.7167(3.7136) | Xent 0.7815(0.7910) | Loss 512.7486(597.6190) | Error 0.2822(0.2812) Steps 0(0.00) | Grad Norm 335.8327(490.1601) | Total Time 0.00(0.00)\n",
      "Iter 3820 | Time 16.7579(17.6170) | Bit/dim 3.7327(3.7165) | Xent 0.8017(0.7933) | Loss 545.5308(583.8376) | Error 0.2844(0.2812) Steps 0(0.00) | Grad Norm 506.8491(483.7106) | Total Time 0.00(0.00)\n",
      "Iter 3830 | Time 16.2036(17.5503) | Bit/dim 3.7223(3.7169) | Xent 0.8182(0.7890) | Loss 524.0786(571.2873) | Error 0.2878(0.2809) Steps 0(0.00) | Grad Norm 375.4263(454.7176) | Total Time 0.00(0.00)\n",
      "Iter 3840 | Time 16.7693(17.4707) | Bit/dim 3.6902(3.7125) | Xent 0.7913(0.7831) | Loss 548.3800(562.1881) | Error 0.2822(0.2789) Steps 0(0.00) | Grad Norm 387.7305(440.2984) | Total Time 0.00(0.00)\n",
      "Iter 3850 | Time 16.7885(17.4691) | Bit/dim 3.7011(3.7083) | Xent 0.7446(0.7730) | Loss 511.5960(552.8279) | Error 0.2856(0.2778) Steps 0(0.00) | Grad Norm 412.9464(431.6586) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 88.7028, Epoch Time 1069.9233(1030.7459), Bit/dim 3.7152(best: 3.7070), Xent 0.7880, Loss 4.1092, Error 0.2780(best: 0.2757)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3860 | Time 18.2713(17.4381) | Bit/dim 3.7364(3.7096) | Xent 0.7617(0.7752) | Loss 524.9077(604.1716) | Error 0.2756(0.2781) Steps 0(0.00) | Grad Norm 415.4901(444.3770) | Total Time 0.00(0.00)\n",
      "Iter 3870 | Time 16.5564(17.4153) | Bit/dim 3.7199(3.7099) | Xent 0.7783(0.7677) | Loss 536.1053(585.7967) | Error 0.2889(0.2769) Steps 0(0.00) | Grad Norm 502.6364(441.0513) | Total Time 0.00(0.00)\n",
      "Iter 3880 | Time 16.1153(17.4540) | Bit/dim 3.6866(3.7046) | Xent 0.7347(0.7625) | Loss 526.1265(572.6330) | Error 0.2333(0.2737) Steps 0(0.00) | Grad Norm 470.9216(432.0068) | Total Time 0.00(0.00)\n",
      "Iter 3890 | Time 16.8997(17.4810) | Bit/dim 3.6938(3.7070) | Xent 0.7822(0.7600) | Loss 530.5238(562.7924) | Error 0.2778(0.2714) Steps 0(0.00) | Grad Norm 615.4243(429.6602) | Total Time 0.00(0.00)\n",
      "Iter 3900 | Time 16.6826(17.4936) | Bit/dim 3.6998(3.7047) | Xent 0.7604(0.7628) | Loss 533.1411(556.9635) | Error 0.2744(0.2711) Steps 0(0.00) | Grad Norm 553.8891(453.0657) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 90.6421, Epoch Time 1066.8106(1031.8279), Bit/dim 3.7059(best: 3.7070), Xent 0.7950, Loss 4.1034, Error 0.2795(best: 0.2757)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3910 | Time 17.3148(17.4133) | Bit/dim 3.7093(3.7039) | Xent 0.7524(0.7593) | Loss 529.5803(616.1107) | Error 0.2600(0.2708) Steps 0(0.00) | Grad Norm 483.1965(449.7468) | Total Time 0.00(0.00)\n",
      "Iter 3920 | Time 17.4416(17.4826) | Bit/dim 3.7222(3.7018) | Xent 0.7212(0.7538) | Loss 537.3299(592.9499) | Error 0.2567(0.2688) Steps 0(0.00) | Grad Norm 278.1948(453.6873) | Total Time 0.00(0.00)\n",
      "Iter 3930 | Time 18.0695(17.4810) | Bit/dim 3.7105(3.7030) | Xent 0.6773(0.7540) | Loss 529.6335(577.3265) | Error 0.2389(0.2698) Steps 0(0.00) | Grad Norm 334.6628(469.3688) | Total Time 0.00(0.00)\n",
      "Iter 3940 | Time 19.0435(17.5470) | Bit/dim 3.6754(3.6987) | Xent 0.7883(0.7552) | Loss 523.3342(564.6777) | Error 0.2700(0.2702) Steps 0(0.00) | Grad Norm 489.7048(490.0322) | Total Time 0.00(0.00)\n",
      "Iter 3950 | Time 16.6710(17.5153) | Bit/dim 3.7440(3.7027) | Xent 0.7531(0.7630) | Loss 544.9528(555.5251) | Error 0.2756(0.2714) Steps 0(0.00) | Grad Norm 496.6862(476.2110) | Total Time 0.00(0.00)\n",
      "Iter 3960 | Time 16.6716(17.5069) | Bit/dim 3.7261(3.7046) | Xent 0.7711(0.7701) | Loss 542.1342(552.0019) | Error 0.2833(0.2756) Steps 0(0.00) | Grad Norm 369.6366(469.4838) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 90.1475, Epoch Time 1072.8730(1033.0592), Bit/dim 3.7083(best: 3.7059), Xent 0.7647, Loss 4.0906, Error 0.2716(best: 0.2757)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3970 | Time 18.1017(17.4817) | Bit/dim 3.7031(3.7057) | Xent 0.7852(0.7637) | Loss 543.4830(604.9679) | Error 0.2900(0.2732) Steps 0(0.00) | Grad Norm 465.0965(470.5072) | Total Time 0.00(0.00)\n",
      "Iter 3980 | Time 15.6648(17.4394) | Bit/dim 3.7466(3.7085) | Xent 0.7146(0.7654) | Loss 497.4623(585.7540) | Error 0.2678(0.2751) Steps 0(0.00) | Grad Norm 451.3352(470.0951) | Total Time 0.00(0.00)\n",
      "Iter 3990 | Time 19.7426(17.4879) | Bit/dim 3.7064(3.7067) | Xent 0.7500(0.7550) | Loss 528.7293(571.8886) | Error 0.2644(0.2711) Steps 0(0.00) | Grad Norm 362.6239(442.1326) | Total Time 0.00(0.00)\n",
      "Iter 4000 | Time 19.0785(17.6980) | Bit/dim 3.6985(3.7057) | Xent 0.7636(0.7599) | Loss 555.4425(562.3331) | Error 0.2678(0.2719) Steps 0(0.00) | Grad Norm 656.6372(511.6253) | Total Time 0.00(0.00)\n",
      "Iter 4010 | Time 17.8002(17.7290) | Bit/dim 3.7190(3.7043) | Xent 0.8148(0.7552) | Loss 561.2732(554.5513) | Error 0.2856(0.2702) Steps 0(0.00) | Grad Norm 403.4488(483.9452) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 91.7323, Epoch Time 1080.9914(1034.4972), Bit/dim 3.7097(best: 3.7059), Xent 0.7523, Loss 4.0858, Error 0.2668(best: 0.2716)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4020 | Time 16.1074(17.5847) | Bit/dim 3.7100(3.7038) | Xent 0.7077(0.7515) | Loss 543.4604(613.9441) | Error 0.2422(0.2679) Steps 0(0.00) | Grad Norm 365.2030(463.3591) | Total Time 0.00(0.00)\n",
      "Iter 4030 | Time 18.1865(17.6034) | Bit/dim 3.7397(3.7051) | Xent 0.6800(0.7466) | Loss 552.1349(594.6564) | Error 0.2500(0.2676) Steps 0(0.00) | Grad Norm 426.5166(446.5786) | Total Time 0.00(0.00)\n",
      "Iter 4040 | Time 18.0804(17.5831) | Bit/dim 3.7107(3.7029) | Xent 0.7040(0.7427) | Loss 544.2830(578.2904) | Error 0.2622(0.2670) Steps 0(0.00) | Grad Norm 266.9116(436.0530) | Total Time 0.00(0.00)\n",
      "Iter 4050 | Time 16.7861(17.5425) | Bit/dim 3.6722(3.7033) | Xent 0.7907(0.7507) | Loss 525.1718(566.2788) | Error 0.2711(0.2695) Steps 0(0.00) | Grad Norm 679.0449(479.8014) | Total Time 0.00(0.00)\n",
      "Iter 4060 | Time 16.4352(17.5729) | Bit/dim 3.6987(3.7025) | Xent 0.7101(0.7536) | Loss 527.5109(558.9279) | Error 0.2633(0.2709) Steps 0(0.00) | Grad Norm 532.5309(469.0966) | Total Time 0.00(0.00)\n",
      "Iter 4070 | Time 19.7909(17.6588) | Bit/dim 3.7024(3.7012) | Xent 0.7262(0.7454) | Loss 550.4926(552.5837) | Error 0.2556(0.2680) Steps 0(0.00) | Grad Norm 326.2602(441.6389) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 91.9354, Epoch Time 1076.3840(1035.7538), Bit/dim 3.7018(best: 3.7059), Xent 0.7526, Loss 4.0781, Error 0.2694(best: 0.2668)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4080 | Time 15.8019(17.7153) | Bit/dim 3.6771(3.6991) | Xent 0.6987(0.7370) | Loss 501.4925(605.4701) | Error 0.2522(0.2630) Steps 0(0.00) | Grad Norm 200.4405(397.0268) | Total Time 0.00(0.00)\n",
      "Iter 4090 | Time 17.6937(17.7535) | Bit/dim 3.6716(3.6978) | Xent 0.6927(0.7311) | Loss 533.9702(585.8623) | Error 0.2556(0.2613) Steps 0(0.00) | Grad Norm 629.3958(404.9056) | Total Time 0.00(0.00)\n",
      "Iter 4100 | Time 16.3767(17.9075) | Bit/dim 3.7297(3.7027) | Xent 0.7112(0.7353) | Loss 518.7194(572.7336) | Error 0.2589(0.2628) Steps 0(0.00) | Grad Norm 645.5513(477.7572) | Total Time 0.00(0.00)\n",
      "Iter 4110 | Time 17.9741(18.0412) | Bit/dim 3.7071(3.7013) | Xent 0.7317(0.7356) | Loss 529.9730(562.5538) | Error 0.2589(0.2629) Steps 0(0.00) | Grad Norm 627.7004(473.5287) | Total Time 0.00(0.00)\n",
      "Iter 4120 | Time 16.9028(17.9343) | Bit/dim 3.6776(3.7017) | Xent 0.7936(0.7542) | Loss 520.0591(554.8659) | Error 0.2856(0.2685) Steps 0(0.00) | Grad Norm 573.4500(523.1798) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 92.1701, Epoch Time 1101.6836(1037.7317), Bit/dim 3.7013(best: 3.7018), Xent 0.7628, Loss 4.0827, Error 0.2692(best: 0.2668)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4130 | Time 19.4342(18.0728) | Bit/dim 3.7248(3.7034) | Xent 0.7935(0.7568) | Loss 555.7771(617.0493) | Error 0.2689(0.2682) Steps 0(0.00) | Grad Norm 417.0068(499.8112) | Total Time 0.00(0.00)\n",
      "Iter 4140 | Time 19.4309(17.9885) | Bit/dim 3.6781(3.7027) | Xent 0.7479(0.7520) | Loss 544.9929(593.1199) | Error 0.2589(0.2672) Steps 0(0.00) | Grad Norm 588.8746(475.5861) | Total Time 0.00(0.00)\n",
      "Iter 4150 | Time 17.3890(17.8231) | Bit/dim 3.7171(3.7029) | Xent 0.6701(0.7397) | Loss 529.1722(578.4290) | Error 0.2311(0.2620) Steps 0(0.00) | Grad Norm 317.5773(446.3884) | Total Time 0.00(0.00)\n",
      "Iter 4160 | Time 16.9560(17.6647) | Bit/dim 3.6983(3.7007) | Xent 0.8134(0.7373) | Loss 535.2797(566.0747) | Error 0.2856(0.2623) Steps 0(0.00) | Grad Norm 369.4940(430.2054) | Total Time 0.00(0.00)\n",
      "Iter 4170 | Time 19.3182(17.6408) | Bit/dim 3.7059(3.7000) | Xent 0.7600(0.7359) | Loss 543.9957(557.5941) | Error 0.2622(0.2617) Steps 0(0.00) | Grad Norm 430.1744(446.6765) | Total Time 0.00(0.00)\n",
      "Iter 4180 | Time 17.7184(17.5884) | Bit/dim 3.6772(3.6947) | Xent 0.7256(0.7320) | Loss 506.1504(549.5930) | Error 0.2700(0.2606) Steps 0(0.00) | Grad Norm 776.4511(431.9264) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 91.9263, Epoch Time 1076.6108(1038.8981), Bit/dim 3.6969(best: 3.7013), Xent 0.7782, Loss 4.0860, Error 0.2713(best: 0.2668)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4190 | Time 17.1356(17.5564) | Bit/dim 3.6804(3.6928) | Xent 0.8056(0.7341) | Loss 515.0712(598.9056) | Error 0.2878(0.2622) Steps 0(0.00) | Grad Norm 658.3236(455.0538) | Total Time 0.00(0.00)\n",
      "Iter 4200 | Time 17.9033(17.4875) | Bit/dim 3.6810(3.6935) | Xent 0.6966(0.7231) | Loss 531.8964(581.0722) | Error 0.2444(0.2584) Steps 0(0.00) | Grad Norm 302.9661(426.1185) | Total Time 0.00(0.00)\n",
      "Iter 4210 | Time 17.6837(17.5261) | Bit/dim 3.6952(3.6930) | Xent 0.7171(0.7273) | Loss 543.1271(569.6212) | Error 0.2589(0.2595) Steps 0(0.00) | Grad Norm 572.8624(429.0616) | Total Time 0.00(0.00)\n",
      "Iter 4220 | Time 16.4963(17.5213) | Bit/dim 3.6772(3.6939) | Xent 0.6933(0.7250) | Loss 519.8598(558.4370) | Error 0.2289(0.2575) Steps 0(0.00) | Grad Norm 506.1073(430.8965) | Total Time 0.00(0.00)\n",
      "Iter 4230 | Time 17.1967(17.6345) | Bit/dim 3.6903(3.6971) | Xent 0.7236(0.7221) | Loss 536.1710(551.4481) | Error 0.2656(0.2568) Steps 0(0.00) | Grad Norm 442.5890(444.6076) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 93.0807, Epoch Time 1078.8649(1040.0971), Bit/dim 3.7015(best: 3.6969), Xent 0.7852, Loss 4.0940, Error 0.2798(best: 0.2668)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4240 | Time 17.6200(17.6357) | Bit/dim 3.7125(3.6923) | Xent 0.7639(0.7228) | Loss 526.8624(609.8392) | Error 0.2611(0.2554) Steps 0(0.00) | Grad Norm 373.5982(449.4863) | Total Time 0.00(0.00)\n",
      "Iter 4250 | Time 17.3193(17.6584) | Bit/dim 3.7217(3.6951) | Xent 0.6455(0.7153) | Loss 530.1639(588.5286) | Error 0.2378(0.2541) Steps 0(0.00) | Grad Norm 209.0901(416.5713) | Total Time 0.00(0.00)\n",
      "Iter 4260 | Time 16.6977(17.4248) | Bit/dim 3.6815(3.6940) | Xent 0.7514(0.7116) | Loss 529.2214(571.9666) | Error 0.2833(0.2540) Steps 0(0.00) | Grad Norm 366.0871(376.9256) | Total Time 0.00(0.00)\n",
      "Iter 4270 | Time 17.7591(17.4390) | Bit/dim 3.7078(3.6948) | Xent 0.7635(0.7120) | Loss 526.6242(559.7598) | Error 0.2744(0.2551) Steps 0(0.00) | Grad Norm 395.7077(374.4324) | Total Time 0.00(0.00)\n",
      "Iter 4280 | Time 18.3596(17.5424) | Bit/dim 3.6813(3.6934) | Xent 0.7916(0.7057) | Loss 540.7987(552.5564) | Error 0.3000(0.2523) Steps 0(0.00) | Grad Norm 469.1108(365.3107) | Total Time 0.00(0.00)\n",
      "Iter 4290 | Time 17.4690(17.4985) | Bit/dim 3.6898(3.6926) | Xent 0.7075(0.7125) | Loss 517.9241(547.1558) | Error 0.2678(0.2544) Steps 0(0.00) | Grad Norm 318.0318(420.8549) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 90.8923, Epoch Time 1067.4629(1040.9180), Bit/dim 3.6913(best: 3.6969), Xent 0.7619, Loss 4.0722, Error 0.2670(best: 0.2668)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4300 | Time 16.6442(17.6198) | Bit/dim 3.6986(3.6906) | Xent 0.6136(0.7099) | Loss 490.2321(601.7805) | Error 0.2189(0.2527) Steps 0(0.00) | Grad Norm 302.0175(432.6266) | Total Time 0.00(0.00)\n",
      "Iter 4310 | Time 17.7869(17.6316) | Bit/dim 3.6571(3.6899) | Xent 0.6632(0.7133) | Loss 527.0417(584.2532) | Error 0.2367(0.2535) Steps 0(0.00) | Grad Norm 461.7643(458.5846) | Total Time 0.00(0.00)\n",
      "Iter 4320 | Time 18.0431(17.6603) | Bit/dim 3.7019(3.6936) | Xent 0.7380(0.7180) | Loss 531.8776(568.9534) | Error 0.2578(0.2548) Steps 0(0.00) | Grad Norm 392.7833(445.5320) | Total Time 0.00(0.00)\n",
      "Iter 4330 | Time 17.6935(17.5588) | Bit/dim 3.6721(3.6914) | Xent 0.7133(0.7087) | Loss 533.6735(557.1143) | Error 0.2611(0.2529) Steps 0(0.00) | Grad Norm 432.1792(410.4086) | Total Time 0.00(0.00)\n",
      "Iter 4340 | Time 17.1730(17.6174) | Bit/dim 3.6643(3.6927) | Xent 0.6942(0.7093) | Loss 527.1700(550.7447) | Error 0.2567(0.2536) Steps 0(0.00) | Grad Norm 444.3728(403.4099) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 89.9329, Epoch Time 1083.9857(1042.2101), Bit/dim 3.6952(best: 3.6913), Xent 0.7540, Loss 4.0722, Error 0.2615(best: 0.2668)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4350 | Time 18.3431(17.7144) | Bit/dim 3.6722(3.6898) | Xent 0.7015(0.7084) | Loss 519.1375(610.6941) | Error 0.2533(0.2547) Steps 0(0.00) | Grad Norm 377.7004(408.7846) | Total Time 0.00(0.00)\n",
      "Iter 4360 | Time 17.6462(17.7834) | Bit/dim 3.6818(3.6901) | Xent 0.7025(0.7078) | Loss 548.3336(590.6623) | Error 0.2622(0.2542) Steps 0(0.00) | Grad Norm 315.0308(411.0546) | Total Time 0.00(0.00)\n",
      "Iter 4370 | Time 17.3869(17.7786) | Bit/dim 3.7064(3.6910) | Xent 0.6822(0.7082) | Loss 515.4012(574.2032) | Error 0.2344(0.2535) Steps 0(0.00) | Grad Norm 440.2148(437.4058) | Total Time 0.00(0.00)\n",
      "Iter 4380 | Time 16.4042(17.8014) | Bit/dim 3.6792(3.6869) | Xent 0.7550(0.7127) | Loss 513.7125(562.3622) | Error 0.2733(0.2563) Steps 0(0.00) | Grad Norm 299.6957(444.4333) | Total Time 0.00(0.00)\n",
      "Iter 4390 | Time 17.6265(17.8411) | Bit/dim 3.7357(3.6868) | Xent 0.7186(0.7099) | Loss 536.9193(555.2316) | Error 0.2611(0.2542) Steps 0(0.00) | Grad Norm 494.7848(412.6132) | Total Time 0.00(0.00)\n",
      "Iter 4400 | Time 17.2091(17.7584) | Bit/dim 3.6532(3.6887) | Xent 0.7196(0.7110) | Loss 522.6404(548.7625) | Error 0.2611(0.2543) Steps 0(0.00) | Grad Norm 501.5762(432.5045) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 90.5962, Epoch Time 1087.5456(1043.5701), Bit/dim 3.6885(best: 3.6913), Xent 0.7543, Loss 4.0657, Error 0.2614(best: 0.2615)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4410 | Time 17.6757(17.7564) | Bit/dim 3.6987(3.6868) | Xent 0.6841(0.7085) | Loss 520.5437(601.7011) | Error 0.2544(0.2536) Steps 0(0.00) | Grad Norm 339.3683(452.5525) | Total Time 0.00(0.00)\n",
      "Iter 4420 | Time 19.9078(17.7698) | Bit/dim 3.6849(3.6905) | Xent 0.6236(0.7009) | Loss 538.9490(582.2329) | Error 0.2322(0.2503) Steps 0(0.00) | Grad Norm 308.3863(441.5388) | Total Time 0.00(0.00)\n",
      "Iter 4430 | Time 17.5924(17.9151) | Bit/dim 3.7077(3.6920) | Xent 0.7433(0.7035) | Loss 554.9157(570.5933) | Error 0.2567(0.2510) Steps 0(0.00) | Grad Norm 350.0635(449.6535) | Total Time 0.00(0.00)\n",
      "Iter 4440 | Time 17.1810(17.9937) | Bit/dim 3.6561(3.6890) | Xent 0.7238(0.7033) | Loss 548.9377(561.7140) | Error 0.2511(0.2507) Steps 0(0.00) | Grad Norm 539.1922(456.3233) | Total Time 0.00(0.00)\n",
      "Iter 4450 | Time 17.4252(17.8585) | Bit/dim 3.6763(3.6862) | Xent 0.6257(0.6941) | Loss 538.1778(550.7605) | Error 0.2333(0.2485) Steps 0(0.00) | Grad Norm 249.3158(426.0599) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 93.1449, Epoch Time 1094.4539(1045.0967), Bit/dim 3.6816(best: 3.6885), Xent 0.7435, Loss 4.0533, Error 0.2584(best: 0.2614)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4460 | Time 16.2659(17.8406) | Bit/dim 3.6919(3.6841) | Xent 0.6998(0.6937) | Loss 549.4998(609.6463) | Error 0.2578(0.2489) Steps 0(0.00) | Grad Norm 465.9819(432.0502) | Total Time 0.00(0.00)\n",
      "Iter 4470 | Time 18.1436(18.0924) | Bit/dim 3.6591(3.6807) | Xent 0.7060(0.6892) | Loss 527.6446(589.7359) | Error 0.2567(0.2471) Steps 0(0.00) | Grad Norm 286.5864(404.7034) | Total Time 0.00(0.00)\n",
      "Iter 4480 | Time 17.1910(18.1166) | Bit/dim 3.6701(3.6809) | Xent 0.7441(0.6877) | Loss 527.2776(574.8051) | Error 0.2511(0.2454) Steps 0(0.00) | Grad Norm 519.6528(406.3005) | Total Time 0.00(0.00)\n",
      "Iter 4490 | Time 18.1285(17.9768) | Bit/dim 3.6810(3.6812) | Xent 0.6817(0.6858) | Loss 535.9827(562.9374) | Error 0.2511(0.2451) Steps 0(0.00) | Grad Norm 529.9455(414.7584) | Total Time 0.00(0.00)\n",
      "Iter 4500 | Time 16.6807(17.9504) | Bit/dim 3.6797(3.6805) | Xent 0.6590(0.6892) | Loss 541.0614(553.5727) | Error 0.2256(0.2436) Steps 0(0.00) | Grad Norm 294.5542(409.3723) | Total Time 0.00(0.00)\n",
      "Iter 4510 | Time 17.6334(17.9618) | Bit/dim 3.6848(3.6833) | Xent 0.7358(0.6975) | Loss 527.0378(546.1958) | Error 0.2622(0.2480) Steps 0(0.00) | Grad Norm 675.2157(432.5302) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 90.5464, Epoch Time 1104.3674(1046.8748), Bit/dim 3.7057(best: 3.6816), Xent 0.8308, Loss 4.1210, Error 0.2898(best: 0.2584)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4520 | Time 17.0680(18.0294) | Bit/dim 3.6636(3.6866) | Xent 0.7380(0.7100) | Loss 531.6823(601.4478) | Error 0.2611(0.2514) Steps 0(0.00) | Grad Norm 380.4899(475.5592) | Total Time 0.00(0.00)\n",
      "Iter 4530 | Time 18.7097(17.9601) | Bit/dim 3.6759(3.6886) | Xent 0.7062(0.7046) | Loss 524.1990(582.7490) | Error 0.2511(0.2512) Steps 0(0.00) | Grad Norm 243.9333(444.6855) | Total Time 0.00(0.00)\n",
      "Iter 4540 | Time 17.1783(17.9755) | Bit/dim 3.7087(3.6859) | Xent 0.6942(0.6998) | Loss 525.7901(569.2879) | Error 0.2411(0.2491) Steps 0(0.00) | Grad Norm 305.7948(428.1027) | Total Time 0.00(0.00)\n",
      "Iter 4550 | Time 17.1408(18.0014) | Bit/dim 3.6687(3.6848) | Xent 0.7060(0.6930) | Loss 519.3156(559.2379) | Error 0.2489(0.2469) Steps 0(0.00) | Grad Norm 368.9068(401.7296) | Total Time 0.00(0.00)\n",
      "Iter 4560 | Time 16.9919(18.0255) | Bit/dim 3.6717(3.6849) | Xent 0.6614(0.6880) | Loss 498.4724(550.4418) | Error 0.2278(0.2446) Steps 0(0.00) | Grad Norm 384.4576(383.1028) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 91.9529, Epoch Time 1101.8215(1048.5232), Bit/dim 3.6907(best: 3.6816), Xent 0.7395, Loss 4.0605, Error 0.2618(best: 0.2584)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4570 | Time 18.0792(18.0451) | Bit/dim 3.6548(3.6862) | Xent 0.6216(0.6779) | Loss 532.5319(611.5183) | Error 0.2200(0.2429) Steps 0(0.00) | Grad Norm 449.9329(372.0976) | Total Time 0.00(0.00)\n",
      "Iter 4580 | Time 16.5721(18.0450) | Bit/dim 3.7130(3.6848) | Xent 0.6659(0.6802) | Loss 497.9380(589.3050) | Error 0.2311(0.2414) Steps 0(0.00) | Grad Norm 320.6573(381.5715) | Total Time 0.00(0.00)\n",
      "Iter 4590 | Time 17.5867(18.0993) | Bit/dim 3.6798(3.6788) | Xent 0.6632(0.6777) | Loss 531.9322(572.8533) | Error 0.2389(0.2420) Steps 0(0.00) | Grad Norm 610.7608(406.3712) | Total Time 0.00(0.00)\n",
      "Iter 4600 | Time 17.2955(18.1316) | Bit/dim 3.6780(3.6799) | Xent 0.6429(0.6757) | Loss 518.3947(560.9896) | Error 0.2311(0.2418) Steps 0(0.00) | Grad Norm 367.0593(416.7139) | Total Time 0.00(0.00)\n",
      "Iter 4610 | Time 17.1544(17.9656) | Bit/dim 3.6586(3.6772) | Xent 0.7114(0.6751) | Loss 540.4297(552.9776) | Error 0.2478(0.2411) Steps 0(0.00) | Grad Norm 404.1298(404.6041) | Total Time 0.00(0.00)\n",
      "Iter 4620 | Time 16.5010(17.9571) | Bit/dim 3.7123(3.6791) | Xent 0.7073(0.6777) | Loss 533.7844(546.5790) | Error 0.2667(0.2421) Steps 0(0.00) | Grad Norm 317.0192(406.2633) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 90.3896, Epoch Time 1099.2106(1050.0438), Bit/dim 3.6824(best: 3.6816), Xent 0.7301, Loss 4.0475, Error 0.2549(best: 0.2584)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4630 | Time 19.3801(18.0699) | Bit/dim 3.6875(3.6790) | Xent 0.6669(0.6725) | Loss 533.4120(599.3048) | Error 0.2300(0.2404) Steps 0(0.00) | Grad Norm 447.7351(419.9131) | Total Time 0.00(0.00)\n",
      "Iter 4640 | Time 17.2102(18.0921) | Bit/dim 3.6586(3.6775) | Xent 0.7285(0.6738) | Loss 528.5988(581.2792) | Error 0.2544(0.2410) Steps 0(0.00) | Grad Norm 630.1610(415.1936) | Total Time 0.00(0.00)\n",
      "Iter 4650 | Time 16.2774(17.9547) | Bit/dim 3.6575(3.6760) | Xent 0.6716(0.6764) | Loss 523.2287(567.0337) | Error 0.2411(0.2416) Steps 0(0.00) | Grad Norm 370.4513(419.8447) | Total Time 0.00(0.00)\n",
      "Iter 4660 | Time 18.3394(18.0164) | Bit/dim 3.7017(3.6760) | Xent 0.6803(0.6700) | Loss 558.3110(557.3152) | Error 0.2444(0.2404) Steps 0(0.00) | Grad Norm 485.6598(393.4906) | Total Time 0.00(0.00)\n",
      "Iter 4670 | Time 16.1306(17.7693) | Bit/dim 3.6661(3.6787) | Xent 0.6381(0.6698) | Loss 524.6240(548.9785) | Error 0.2178(0.2402) Steps 0(0.00) | Grad Norm 304.7316(400.4872) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 91.4744, Epoch Time 1090.4487(1051.2560), Bit/dim 3.6712(best: 3.6816), Xent 0.7233, Loss 4.0329, Error 0.2545(best: 0.2549)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4680 | Time 17.1199(17.7459) | Bit/dim 3.6959(3.6784) | Xent 0.6687(0.6748) | Loss 536.0224(612.5860) | Error 0.2556(0.2419) Steps 0(0.00) | Grad Norm 564.0421(416.6292) | Total Time 0.00(0.00)\n",
      "Iter 4690 | Time 17.4707(17.8338) | Bit/dim 3.6732(3.6779) | Xent 0.6194(0.6696) | Loss 505.9018(589.6076) | Error 0.2178(0.2401) Steps 0(0.00) | Grad Norm 331.8001(413.5455) | Total Time 0.00(0.00)\n",
      "Iter 4700 | Time 18.6588(17.9760) | Bit/dim 3.6631(3.6766) | Xent 0.6587(0.6709) | Loss 528.3118(573.3052) | Error 0.2244(0.2382) Steps 0(0.00) | Grad Norm 338.4684(409.2952) | Total Time 0.00(0.00)\n",
      "Iter 4710 | Time 20.4039(18.1195) | Bit/dim 3.6999(3.6778) | Xent 0.7236(0.6757) | Loss 553.5624(564.3328) | Error 0.2544(0.2397) Steps 0(0.00) | Grad Norm 484.1676(428.0263) | Total Time 0.00(0.00)\n",
      "Iter 4720 | Time 17.7289(18.0345) | Bit/dim 3.6577(3.6777) | Xent 0.6364(0.6688) | Loss 521.0720(553.3921) | Error 0.2244(0.2373) Steps 0(0.00) | Grad Norm 223.6950(401.7302) | Total Time 0.00(0.00)\n",
      "Iter 4730 | Time 19.9915(18.1165) | Bit/dim 3.6665(3.6755) | Xent 0.6595(0.6659) | Loss 542.6075(547.9239) | Error 0.2389(0.2372) Steps 0(0.00) | Grad Norm 549.3582(400.7763) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 92.8991, Epoch Time 1111.7696(1053.0714), Bit/dim 3.6740(best: 3.6712), Xent 0.7515, Loss 4.0497, Error 0.2596(best: 0.2545)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4740 | Time 19.6577(18.3325) | Bit/dim 3.7111(3.6775) | Xent 0.6614(0.6626) | Loss 553.2782(602.9719) | Error 0.2422(0.2362) Steps 0(0.00) | Grad Norm 378.0162(403.8783) | Total Time 0.00(0.00)\n",
      "Iter 4750 | Time 17.5541(18.3273) | Bit/dim 3.6509(3.6751) | Xent 0.6778(0.6605) | Loss 522.7833(584.2789) | Error 0.2356(0.2355) Steps 0(0.00) | Grad Norm 311.8400(393.0639) | Total Time 0.00(0.00)\n",
      "Iter 4760 | Time 18.4323(18.3578) | Bit/dim 3.6403(3.6735) | Xent 0.6331(0.6570) | Loss 501.1118(569.6127) | Error 0.2411(0.2337) Steps 0(0.00) | Grad Norm 427.4470(400.4563) | Total Time 0.00(0.00)\n",
      "Iter 4770 | Time 19.3929(18.2958) | Bit/dim 3.6290(3.6704) | Xent 0.6334(0.6709) | Loss 537.3053(558.7446) | Error 0.2267(0.2390) Steps 0(0.00) | Grad Norm 453.8443(448.8869) | Total Time 0.00(0.00)\n",
      "Iter 4780 | Time 16.1165(18.1906) | Bit/dim 3.7103(3.6739) | Xent 0.6830(0.6755) | Loss 512.3167(551.2890) | Error 0.2478(0.2402) Steps 0(0.00) | Grad Norm 328.8775(436.3010) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 91.7365, Epoch Time 1119.6678(1055.0693), Bit/dim 3.6887(best: 3.6712), Xent 0.7450, Loss 4.0612, Error 0.2625(best: 0.2545)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4790 | Time 20.2274(18.3375) | Bit/dim 3.6438(3.6737) | Xent 0.6554(0.6734) | Loss 555.3873(615.1946) | Error 0.2411(0.2409) Steps 0(0.00) | Grad Norm 496.7180(443.2076) | Total Time 0.00(0.00)\n",
      "Iter 4800 | Time 17.4793(18.3208) | Bit/dim 3.6947(3.6723) | Xent 0.5488(0.6637) | Loss 513.1890(591.5151) | Error 0.1889(0.2372) Steps 0(0.00) | Grad Norm 261.7925(416.3966) | Total Time 0.00(0.00)\n",
      "Iter 4810 | Time 17.4319(18.1564) | Bit/dim 3.6299(3.6735) | Xent 0.6534(0.6613) | Loss 517.4287(574.7513) | Error 0.2333(0.2366) Steps 0(0.00) | Grad Norm 322.3338(405.6543) | Total Time 0.00(0.00)\n",
      "Iter 4820 | Time 20.8826(18.2030) | Bit/dim 3.6645(3.6746) | Xent 0.7283(0.6662) | Loss 505.2409(562.9769) | Error 0.2689(0.2384) Steps 0(0.00) | Grad Norm 586.0567(431.1208) | Total Time 0.00(0.00)\n",
      "Iter 4830 | Time 19.4732(18.2906) | Bit/dim 3.6881(3.6742) | Xent 0.7029(0.6629) | Loss 522.3076(553.5108) | Error 0.2589(0.2380) Steps 0(0.00) | Grad Norm 604.3045(420.2217) | Total Time 0.00(0.00)\n",
      "Iter 4840 | Time 17.3107(18.1804) | Bit/dim 3.6942(3.6745) | Xent 0.6726(0.6640) | Loss 526.7753(545.7954) | Error 0.2422(0.2373) Steps 0(0.00) | Grad Norm 322.3055(416.6648) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 91.7080, Epoch Time 1110.2865(1056.7258), Bit/dim 3.6737(best: 3.6712), Xent 0.7109, Loss 4.0291, Error 0.2481(best: 0.2545)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4850 | Time 19.1937(18.2421) | Bit/dim 3.6851(3.6729) | Xent 0.6883(0.6636) | Loss 524.7565(595.4929) | Error 0.2356(0.2360) Steps 0(0.00) | Grad Norm 408.9279(434.1434) | Total Time 0.00(0.00)\n",
      "Iter 4860 | Time 17.0112(18.1787) | Bit/dim 3.6440(3.6705) | Xent 0.6421(0.6631) | Loss 523.3383(578.1971) | Error 0.2244(0.2376) Steps 0(0.00) | Grad Norm 325.8292(439.7373) | Total Time 0.00(0.00)\n",
      "Iter 4870 | Time 18.0446(18.1185) | Bit/dim 3.6591(3.6692) | Xent 0.6701(0.6638) | Loss 537.7589(566.0629) | Error 0.2300(0.2375) Steps 0(0.00) | Grad Norm 479.7002(425.7140) | Total Time 0.00(0.00)\n",
      "Iter 4880 | Time 17.0158(17.8767) | Bit/dim 3.6903(3.6690) | Xent 0.6476(0.6634) | Loss 519.4785(555.5364) | Error 0.2400(0.2381) Steps 0(0.00) | Grad Norm 273.1149(436.7638) | Total Time 0.00(0.00)\n",
      "Iter 4890 | Time 17.1385(17.9990) | Bit/dim 3.7368(3.6730) | Xent 0.6320(0.6614) | Loss 539.4516(549.4687) | Error 0.2200(0.2360) Steps 0(0.00) | Grad Norm 371.9812(424.1532) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 89.9832, Epoch Time 1099.7307(1058.0159), Bit/dim 3.6779(best: 3.6712), Xent 0.7429, Loss 4.0494, Error 0.2581(best: 0.2481)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4900 | Time 16.6402(18.1090) | Bit/dim 3.6279(3.6743) | Xent 0.6227(0.6584) | Loss 515.0243(609.4603) | Error 0.2178(0.2354) Steps 0(0.00) | Grad Norm 240.6119(403.4132) | Total Time 0.00(0.00)\n",
      "Iter 4910 | Time 16.7332(18.1671) | Bit/dim 3.6795(3.6715) | Xent 0.6660(0.6557) | Loss 516.3448(588.8299) | Error 0.2278(0.2352) Steps 0(0.00) | Grad Norm 443.4983(389.3528) | Total Time 0.00(0.00)\n",
      "Iter 4920 | Time 19.3940(18.0901) | Bit/dim 3.6877(3.6730) | Xent 0.6823(0.6537) | Loss 550.7579(573.7134) | Error 0.2244(0.2330) Steps 0(0.00) | Grad Norm 672.2780(418.2321) | Total Time 0.00(0.00)\n",
      "Iter 4930 | Time 17.6483(18.1073) | Bit/dim 3.7113(3.6765) | Xent 0.6840(0.6498) | Loss 517.1181(561.1422) | Error 0.2333(0.2320) Steps 0(0.00) | Grad Norm 610.9892(426.1741) | Total Time 0.00(0.00)\n",
      "Iter 4940 | Time 17.9046(18.1978) | Bit/dim 3.6420(3.6751) | Xent 0.5949(0.6526) | Loss 514.7646(552.4842) | Error 0.2211(0.2332) Steps 0(0.00) | Grad Norm 321.2113(420.6767) | Total Time 0.00(0.00)\n",
      "Iter 4950 | Time 18.8031(18.3473) | Bit/dim 3.6715(3.6721) | Xent 0.6588(0.6573) | Loss 537.0803(546.9234) | Error 0.2433(0.2354) Steps 0(0.00) | Grad Norm 340.9941(429.3140) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 91.1098, Epoch Time 1116.7531(1059.7780), Bit/dim 3.6690(best: 3.6712), Xent 0.7285, Loss 4.0333, Error 0.2552(best: 0.2481)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4960 | Time 19.6091(18.4151) | Bit/dim 3.6782(3.6709) | Xent 0.6167(0.6526) | Loss 535.1192(597.5689) | Error 0.2189(0.2337) Steps 0(0.00) | Grad Norm 404.8679(423.3302) | Total Time 0.00(0.00)\n",
      "Iter 4970 | Time 18.4008(18.4313) | Bit/dim 3.6930(3.6704) | Xent 0.6057(0.6521) | Loss 529.8411(578.0709) | Error 0.2133(0.2344) Steps 0(0.00) | Grad Norm 361.4183(423.6950) | Total Time 0.00(0.00)\n",
      "Iter 4980 | Time 21.9370(18.5009) | Bit/dim 3.6745(3.6712) | Xent 0.6304(0.6557) | Loss 540.0093(566.6949) | Error 0.2256(0.2356) Steps 0(0.00) | Grad Norm 557.0075(426.4301) | Total Time 0.00(0.00)\n",
      "Iter 4990 | Time 19.6285(18.3779) | Bit/dim 3.6484(3.6707) | Xent 0.6104(0.6564) | Loss 530.5181(555.8682) | Error 0.2144(0.2342) Steps 0(0.00) | Grad Norm 275.5551(419.2330) | Total Time 0.00(0.00)\n",
      "Iter 5000 | Time 17.6338(18.3243) | Bit/dim 3.6704(3.6699) | Xent 0.5899(0.6508) | Loss 530.6520(548.9470) | Error 0.2111(0.2313) Steps 0(0.00) | Grad Norm 295.3474(391.9481) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 92.4362, Epoch Time 1120.9964(1061.6146), Bit/dim 3.6773(best: 3.6690), Xent 0.7257, Loss 4.0402, Error 0.2502(best: 0.2481)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5010 | Time 17.5558(18.3080) | Bit/dim 3.6285(3.6706) | Xent 0.6779(0.6388) | Loss 504.2225(611.2397) | Error 0.2411(0.2280) Steps 0(0.00) | Grad Norm 453.4353(384.7382) | Total Time 0.00(0.00)\n",
      "Iter 5020 | Time 18.1688(18.2803) | Bit/dim 3.6487(3.6682) | Xent 0.6687(0.6359) | Loss 525.1412(588.7805) | Error 0.2356(0.2276) Steps 0(0.00) | Grad Norm 385.2986(416.1753) | Total Time 0.00(0.00)\n",
      "Iter 5030 | Time 21.1316(18.3664) | Bit/dim 3.6192(3.6681) | Xent 0.7387(0.6365) | Loss 514.7225(570.4350) | Error 0.2711(0.2284) Steps 0(0.00) | Grad Norm 365.0343(392.6901) | Total Time 0.00(0.00)\n",
      "Iter 5040 | Time 20.3784(18.3354) | Bit/dim 3.6476(3.6670) | Xent 0.6112(0.6327) | Loss 534.2095(558.4133) | Error 0.2111(0.2260) Steps 0(0.00) | Grad Norm 488.0270(396.6615) | Total Time 0.00(0.00)\n",
      "Iter 5050 | Time 20.3636(18.3701) | Bit/dim 3.6678(3.6665) | Xent 0.6501(0.6325) | Loss 523.9004(550.3589) | Error 0.2322(0.2257) Steps 0(0.00) | Grad Norm 455.0653(388.1130) | Total Time 0.00(0.00)\n",
      "Iter 5060 | Time 19.6539(18.6035) | Bit/dim 3.6399(3.6643) | Xent 0.6025(0.6331) | Loss 507.8721(543.7769) | Error 0.2189(0.2262) Steps 0(0.00) | Grad Norm 335.5440(394.8368) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 94.1038, Epoch Time 1128.6389(1063.6253), Bit/dim 3.6662(best: 3.6690), Xent 0.7125, Loss 4.0225, Error 0.2464(best: 0.2481)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5070 | Time 17.7947(18.4875) | Bit/dim 3.6925(3.6668) | Xent 0.6175(0.6279) | Loss 540.1389(597.0875) | Error 0.2111(0.2250) Steps 0(0.00) | Grad Norm 363.2968(382.5665) | Total Time 0.00(0.00)\n",
      "Iter 5080 | Time 18.9137(18.3760) | Bit/dim 3.6547(3.6653) | Xent 0.6497(0.6251) | Loss 524.5150(578.8613) | Error 0.2389(0.2245) Steps 0(0.00) | Grad Norm 393.0310(380.8940) | Total Time 0.00(0.00)\n",
      "Iter 5090 | Time 19.0641(18.3836) | Bit/dim 3.6711(3.6661) | Xent 0.6958(0.6298) | Loss 551.0758(564.8167) | Error 0.2567(0.2260) Steps 0(0.00) | Grad Norm 674.6730(413.8504) | Total Time 0.00(0.00)\n",
      "Iter 5100 | Time 18.8326(18.4569) | Bit/dim 3.6561(3.6623) | Xent 0.6495(0.6352) | Loss 526.2388(553.6747) | Error 0.2256(0.2268) Steps 0(0.00) | Grad Norm 419.8266(401.4993) | Total Time 0.00(0.00)\n",
      "Iter 5110 | Time 18.0106(18.4902) | Bit/dim 3.6943(3.6644) | Xent 0.6476(0.6319) | Loss 526.6089(546.9646) | Error 0.2456(0.2249) Steps 0(0.00) | Grad Norm 192.6162(388.4120) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 93.0729, Epoch Time 1123.1132(1065.4100), Bit/dim 3.6652(best: 3.6662), Xent 0.7433, Loss 4.0368, Error 0.2601(best: 0.2464)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5120 | Time 19.0454(18.4265) | Bit/dim 3.6833(3.6639) | Xent 0.5804(0.6268) | Loss 537.3879(607.2167) | Error 0.2067(0.2242) Steps 0(0.00) | Grad Norm 435.3739(380.9235) | Total Time 0.00(0.00)\n",
      "Iter 5130 | Time 17.3014(18.4066) | Bit/dim 3.6097(3.6648) | Xent 0.5905(0.6238) | Loss 519.6002(585.8838) | Error 0.2133(0.2227) Steps 0(0.00) | Grad Norm 331.6739(382.2926) | Total Time 0.00(0.00)\n",
      "Iter 5140 | Time 16.8920(18.3748) | Bit/dim 3.6630(3.6644) | Xent 0.6045(0.6220) | Loss 502.6429(570.3844) | Error 0.2156(0.2224) Steps 0(0.00) | Grad Norm 239.0898(377.5330) | Total Time 0.00(0.00)\n",
      "Iter 5150 | Time 19.5398(18.3501) | Bit/dim 3.6590(3.6656) | Xent 0.6079(0.6207) | Loss 537.9333(557.5487) | Error 0.2122(0.2218) Steps 0(0.00) | Grad Norm 330.7566(389.3863) | Total Time 0.00(0.00)\n",
      "Iter 5160 | Time 18.0933(18.3100) | Bit/dim 3.6646(3.6646) | Xent 0.5484(0.6196) | Loss 500.3025(548.6661) | Error 0.1911(0.2215) Steps 0(0.00) | Grad Norm 283.2950(390.2642) | Total Time 0.00(0.00)\n",
      "Iter 5170 | Time 17.8968(18.4518) | Bit/dim 3.6746(3.6634) | Xent 0.6823(0.6275) | Loss 534.2756(543.9289) | Error 0.2422(0.2242) Steps 0(0.00) | Grad Norm 642.0832(417.4899) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 91.8458, Epoch Time 1118.8631(1067.0135), Bit/dim 3.6710(best: 3.6652), Xent 0.7558, Loss 4.0489, Error 0.2679(best: 0.2464)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5180 | Time 18.5513(18.4818) | Bit/dim 3.6456(3.6622) | Xent 0.5490(0.6201) | Loss 522.7256(593.9802) | Error 0.2100(0.2226) Steps 0(0.00) | Grad Norm 220.6282(410.5501) | Total Time 0.00(0.00)\n",
      "Iter 5190 | Time 19.7140(18.5999) | Bit/dim 3.6860(3.6630) | Xent 0.6210(0.6184) | Loss 515.3367(575.1337) | Error 0.2200(0.2214) Steps 0(0.00) | Grad Norm 226.7697(382.5168) | Total Time 0.00(0.00)\n",
      "Iter 5200 | Time 17.8556(18.5188) | Bit/dim 3.6962(3.6642) | Xent 0.6031(0.6178) | Loss 509.3101(560.1859) | Error 0.2067(0.2214) Steps 0(0.00) | Grad Norm 438.1279(382.1884) | Total Time 0.00(0.00)\n",
      "Iter 5210 | Time 20.2080(18.7443) | Bit/dim 3.6853(3.6632) | Xent 0.6225(0.6179) | Loss 535.1954(551.9970) | Error 0.2089(0.2207) Steps 0(0.00) | Grad Norm 365.6218(370.2977) | Total Time 0.00(0.00)\n",
      "Iter 5220 | Time 17.4826(18.7739) | Bit/dim 3.6601(3.6621) | Xent 0.6396(0.6242) | Loss 521.1694(545.5408) | Error 0.2278(0.2224) Steps 0(0.00) | Grad Norm 410.9614(381.6515) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 93.0916, Epoch Time 1141.9374(1069.2613), Bit/dim 3.6613(best: 3.6652), Xent 0.7153, Loss 4.0190, Error 0.2468(best: 0.2464)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5230 | Time 16.9183(18.5242) | Bit/dim 3.6848(3.6643) | Xent 0.6100(0.6207) | Loss 500.8212(606.9778) | Error 0.2322(0.2219) Steps 0(0.00) | Grad Norm 423.0668(383.3437) | Total Time 0.00(0.00)\n",
      "Iter 5240 | Time 17.9267(18.5423) | Bit/dim 3.6860(3.6614) | Xent 0.5713(0.6138) | Loss 500.0494(585.4648) | Error 0.2100(0.2183) Steps 0(0.00) | Grad Norm 356.3829(394.3147) | Total Time 0.00(0.00)\n",
      "Iter 5250 | Time 17.8019(18.5092) | Bit/dim 3.6767(3.6617) | Xent 0.5788(0.6152) | Loss 522.3660(569.4148) | Error 0.2156(0.2202) Steps 0(0.00) | Grad Norm 378.8866(413.9699) | Total Time 0.00(0.00)\n",
      "Iter 5260 | Time 20.1867(18.5270) | Bit/dim 3.6589(3.6625) | Xent 0.5992(0.6201) | Loss 548.2353(558.4208) | Error 0.2011(0.2218) Steps 0(0.00) | Grad Norm 242.8877(411.6938) | Total Time 0.00(0.00)\n",
      "Iter 5270 | Time 17.9018(18.5202) | Bit/dim 3.6746(3.6607) | Xent 0.6618(0.6239) | Loss 514.7761(548.9137) | Error 0.2500(0.2239) Steps 0(0.00) | Grad Norm 367.0441(424.7150) | Total Time 0.00(0.00)\n",
      "Iter 5280 | Time 17.2545(18.5226) | Bit/dim 3.7074(3.6630) | Xent 0.5950(0.6236) | Loss 536.3938(542.5536) | Error 0.2167(0.2221) Steps 0(0.00) | Grad Norm 372.8343(421.0690) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 92.7753, Epoch Time 1126.2563(1070.9711), Bit/dim 3.6651(best: 3.6613), Xent 0.7023, Loss 4.0163, Error 0.2448(best: 0.2464)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5290 | Time 19.1395(18.4483) | Bit/dim 3.6420(3.6620) | Xent 0.5842(0.6155) | Loss 515.6140(594.2949) | Error 0.2189(0.2196) Steps 0(0.00) | Grad Norm 335.8149(395.9025) | Total Time 0.00(0.00)\n",
      "Iter 5300 | Time 17.6568(18.4799) | Bit/dim 3.6321(3.6608) | Xent 0.6854(0.6158) | Loss 509.9181(574.5354) | Error 0.2444(0.2208) Steps 0(0.00) | Grad Norm 715.0514(404.6403) | Total Time 0.00(0.00)\n",
      "Iter 5310 | Time 17.2379(18.5274) | Bit/dim 3.6645(3.6611) | Xent 0.5559(0.6155) | Loss 525.5468(561.3458) | Error 0.1967(0.2217) Steps 0(0.00) | Grad Norm 257.2351(414.1507) | Total Time 0.00(0.00)\n",
      "Iter 5320 | Time 20.6923(18.7296) | Bit/dim 3.6892(3.6641) | Xent 0.6699(0.6253) | Loss 542.1490(553.2998) | Error 0.2389(0.2242) Steps 0(0.00) | Grad Norm 903.8689(453.3762) | Total Time 0.00(0.00)\n",
      "Iter 5330 | Time 18.8816(18.9093) | Bit/dim 3.7032(3.6663) | Xent 0.5813(0.6239) | Loss 540.1608(547.6434) | Error 0.2067(0.2238) Steps 0(0.00) | Grad Norm 393.9551(447.6042) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 93.5023, Epoch Time 1148.4346(1073.2950), Bit/dim 3.6711(best: 3.6613), Xent 0.7231, Loss 4.0326, Error 0.2519(best: 0.2448)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5340 | Time 22.6028(19.0320) | Bit/dim 3.6754(3.6674) | Xent 0.5414(0.6169) | Loss 529.3651(609.3517) | Error 0.1978(0.2216) Steps 0(0.00) | Grad Norm 311.0738(421.2389) | Total Time 0.00(0.00)\n",
      "Iter 5350 | Time 17.5054(18.8490) | Bit/dim 3.6714(3.6668) | Xent 0.5891(0.6074) | Loss 541.3126(586.8794) | Error 0.2100(0.2188) Steps 0(0.00) | Grad Norm 376.7316(397.1142) | Total Time 0.00(0.00)\n",
      "Iter 5360 | Time 19.2834(18.8872) | Bit/dim 3.6583(3.6631) | Xent 0.6046(0.6036) | Loss 544.7567(570.7802) | Error 0.2189(0.2167) Steps 0(0.00) | Grad Norm 317.1719(389.9454) | Total Time 0.00(0.00)\n",
      "Iter 5370 | Time 17.8952(18.8435) | Bit/dim 3.6349(3.6619) | Xent 0.6062(0.6032) | Loss 517.8948(558.9111) | Error 0.2211(0.2161) Steps 0(0.00) | Grad Norm 425.5009(387.3682) | Total Time 0.00(0.00)\n",
      "Iter 5380 | Time 18.7433(18.7807) | Bit/dim 3.6454(3.6611) | Xent 0.6043(0.6005) | Loss 525.8066(549.6854) | Error 0.2033(0.2147) Steps 0(0.00) | Grad Norm 279.0101(370.1593) | Total Time 0.00(0.00)\n",
      "Iter 5390 | Time 18.5149(18.7216) | Bit/dim 3.6897(3.6600) | Xent 0.6752(0.6084) | Loss 544.2009(543.5882) | Error 0.2467(0.2176) Steps 0(0.00) | Grad Norm 542.8522(408.7396) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 93.5268, Epoch Time 1141.6827(1075.3466), Bit/dim 3.6627(best: 3.6613), Xent 0.7212, Loss 4.0233, Error 0.2484(best: 0.2448)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5400 | Time 19.4977(18.7751) | Bit/dim 3.6257(3.6583) | Xent 0.5412(0.6053) | Loss 544.2144(596.1057) | Error 0.2011(0.2171) Steps 0(0.00) | Grad Norm 421.1413(406.3577) | Total Time 0.00(0.00)\n",
      "Iter 5410 | Time 18.9167(18.8385) | Bit/dim 3.6543(3.6605) | Xent 0.5669(0.5987) | Loss 518.5432(577.6530) | Error 0.1989(0.2159) Steps 0(0.00) | Grad Norm 293.4079(378.5798) | Total Time 0.00(0.00)\n",
      "Iter 5420 | Time 19.3963(18.8225) | Bit/dim 3.6742(3.6596) | Xent 0.6211(0.5937) | Loss 536.1375(564.4275) | Error 0.2089(0.2124) Steps 0(0.00) | Grad Norm 404.9614(364.5268) | Total Time 0.00(0.00)\n",
      "Iter 5430 | Time 17.6459(18.5351) | Bit/dim 3.6702(3.6574) | Xent 0.6486(0.6005) | Loss 493.7317(553.6791) | Error 0.2322(0.2154) Steps 0(0.00) | Grad Norm 631.5111(380.6301) | Total Time 0.00(0.00)\n",
      "Iter 5440 | Time 17.9784(18.5209) | Bit/dim 3.6595(3.6570) | Xent 0.6222(0.6083) | Loss 537.0920(547.9661) | Error 0.2111(0.2175) Steps 0(0.00) | Grad Norm 519.1779(386.3062) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 91.3593, Epoch Time 1128.1994(1076.9322), Bit/dim 3.6633(best: 3.6613), Xent 0.7104, Loss 4.0185, Error 0.2488(best: 0.2448)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5450 | Time 18.3324(18.4861) | Bit/dim 3.6553(3.6602) | Xent 0.5805(0.6029) | Loss 524.6688(610.3712) | Error 0.2089(0.2143) Steps 0(0.00) | Grad Norm 430.1301(390.3888) | Total Time 0.00(0.00)\n",
      "Iter 5460 | Time 17.9018(18.4916) | Bit/dim 3.6441(3.6559) | Xent 0.5724(0.5943) | Loss 517.9624(585.8890) | Error 0.2144(0.2112) Steps 0(0.00) | Grad Norm 259.3937(371.6804) | Total Time 0.00(0.00)\n",
      "Iter 5470 | Time 18.0957(18.5266) | Bit/dim 3.6519(3.6565) | Xent 0.6105(0.5897) | Loss 536.6439(568.2674) | Error 0.2300(0.2100) Steps 0(0.00) | Grad Norm 498.8204(370.5455) | Total Time 0.00(0.00)\n",
      "Iter 5480 | Time 18.5108(18.5281) | Bit/dim 3.6668(3.6579) | Xent 0.6497(0.5966) | Loss 508.9791(555.7554) | Error 0.2133(0.2117) Steps 0(0.00) | Grad Norm 602.1921(417.4053) | Total Time 0.00(0.00)\n",
      "Iter 5490 | Time 18.7507(18.3828) | Bit/dim 3.6620(3.6598) | Xent 0.5968(0.6062) | Loss 540.5894(547.7081) | Error 0.2122(0.2163) Steps 0(0.00) | Grad Norm 291.6045(430.3416) | Total Time 0.00(0.00)\n",
      "Iter 5500 | Time 18.2882(18.4239) | Bit/dim 3.6638(3.6602) | Xent 0.6020(0.6048) | Loss 533.4327(542.6530) | Error 0.2133(0.2161) Steps 0(0.00) | Grad Norm 443.0164(405.2892) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 92.9658, Epoch Time 1127.3872(1078.4459), Bit/dim 3.6544(best: 3.6613), Xent 0.6868, Loss 3.9978, Error 0.2394(best: 0.2448)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5510 | Time 16.6182(18.3747) | Bit/dim 3.6682(3.6610) | Xent 0.5156(0.5955) | Loss 499.2320(594.5030) | Error 0.1978(0.2140) Steps 0(0.00) | Grad Norm 301.6336(394.6002) | Total Time 0.00(0.00)\n",
      "Iter 5520 | Time 18.2391(18.3410) | Bit/dim 3.6576(3.6607) | Xent 0.5701(0.6026) | Loss 526.6559(575.4065) | Error 0.1967(0.2154) Steps 0(0.00) | Grad Norm 198.8168(424.9628) | Total Time 0.00(0.00)\n",
      "Iter 5530 | Time 18.0790(18.6118) | Bit/dim 3.6667(3.6591) | Xent 0.5510(0.6012) | Loss 532.2998(562.3839) | Error 0.1867(0.2147) Steps 0(0.00) | Grad Norm 465.4485(415.5558) | Total Time 0.00(0.00)\n",
      "Iter 5540 | Time 18.2271(18.7119) | Bit/dim 3.6492(3.6591) | Xent 0.5908(0.5992) | Loss 534.6077(553.9385) | Error 0.2144(0.2136) Steps 0(0.00) | Grad Norm 605.0865(414.0916) | Total Time 0.00(0.00)\n",
      "Iter 5550 | Time 18.8548(18.7224) | Bit/dim 3.6821(3.6562) | Xent 0.5685(0.5966) | Loss 498.6217(543.9412) | Error 0.2111(0.2129) Steps 0(0.00) | Grad Norm 494.9327(429.2832) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 91.6413, Epoch Time 1141.6993(1080.3435), Bit/dim 3.6694(best: 3.6544), Xent 0.7148, Loss 4.0268, Error 0.2451(best: 0.2394)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5560 | Time 17.4773(18.7070) | Bit/dim 3.6703(3.6558) | Xent 0.5451(0.5930) | Loss 522.7033(607.2453) | Error 0.1922(0.2117) Steps 0(0.00) | Grad Norm 222.8308(409.7752) | Total Time 0.00(0.00)\n",
      "Iter 5570 | Time 19.3513(18.6896) | Bit/dim 3.6474(3.6540) | Xent 0.5147(0.5929) | Loss 536.2043(583.7280) | Error 0.1900(0.2121) Steps 0(0.00) | Grad Norm 371.2227(413.3971) | Total Time 0.00(0.00)\n",
      "Iter 5580 | Time 18.5809(18.8543) | Bit/dim 3.6404(3.6544) | Xent 0.5188(0.5924) | Loss 514.6686(566.9782) | Error 0.1856(0.2114) Steps 0(0.00) | Grad Norm 256.0148(399.4105) | Total Time 0.00(0.00)\n",
      "Iter 5590 | Time 16.8169(18.9812) | Bit/dim 3.6708(3.6559) | Xent 0.6499(0.5894) | Loss 499.5318(558.1352) | Error 0.2400(0.2105) Steps 0(0.00) | Grad Norm 393.7381(390.3210) | Total Time 0.00(0.00)\n",
      "Iter 5600 | Time 20.0762(19.0994) | Bit/dim 3.6532(3.6547) | Xent 0.6323(0.5936) | Loss 549.2040(550.4935) | Error 0.2356(0.2130) Steps 0(0.00) | Grad Norm 643.7824(418.0263) | Total Time 0.00(0.00)\n",
      "Iter 5610 | Time 18.2854(18.8803) | Bit/dim 3.6248(3.6550) | Xent 0.5621(0.5935) | Loss 492.9105(543.3185) | Error 0.2011(0.2117) Steps 0(0.00) | Grad Norm 334.6025(412.3687) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 92.6752, Epoch Time 1151.7750(1082.4864), Bit/dim 3.6581(best: 3.6544), Xent 0.7024, Loss 4.0093, Error 0.2435(best: 0.2394)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5620 | Time 18.9931(18.8476) | Bit/dim 3.6302(3.6562) | Xent 0.6190(0.5931) | Loss 540.4708(597.3766) | Error 0.2233(0.2107) Steps 0(0.00) | Grad Norm 815.2580(431.5425) | Total Time 0.00(0.00)\n",
      "Iter 5630 | Time 18.4562(18.8493) | Bit/dim 3.6488(3.6571) | Xent 0.5683(0.5971) | Loss 500.9453(577.3937) | Error 0.2011(0.2132) Steps 0(0.00) | Grad Norm 324.8702(430.7395) | Total Time 0.00(0.00)\n",
      "Iter 5640 | Time 18.2393(18.7619) | Bit/dim 3.6389(3.6544) | Xent 0.5148(0.5931) | Loss 531.3590(563.3961) | Error 0.1667(0.2108) Steps 0(0.00) | Grad Norm 328.0290(417.7119) | Total Time 0.00(0.00)\n",
      "Iter 5650 | Time 19.4486(18.7977) | Bit/dim 3.6428(3.6583) | Xent 0.5915(0.5949) | Loss 518.4598(554.7601) | Error 0.1922(0.2117) Steps 0(0.00) | Grad Norm 265.7082(418.0150) | Total Time 0.00(0.00)\n",
      "Iter 5660 | Time 19.1373(18.8300) | Bit/dim 3.6184(3.6562) | Xent 0.6717(0.5951) | Loss 536.1948(546.8869) | Error 0.2356(0.2118) Steps 0(0.00) | Grad Norm 482.5514(406.2772) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 92.4011, Epoch Time 1141.3730(1084.2530), Bit/dim 3.6581(best: 3.6544), Xent 0.7248, Loss 4.0205, Error 0.2520(best: 0.2394)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5670 | Time 20.5968(19.0525) | Bit/dim 3.6448(3.6542) | Xent 0.5201(0.5901) | Loss 536.8278(609.3974) | Error 0.1822(0.2108) Steps 0(0.00) | Grad Norm 271.8714(410.2129) | Total Time 0.00(0.00)\n",
      "Iter 5680 | Time 21.8487(19.1518) | Bit/dim 3.6551(3.6541) | Xent 0.5613(0.5770) | Loss 534.9733(586.5008) | Error 0.1978(0.2054) Steps 0(0.00) | Grad Norm 366.9545(386.8827) | Total Time 0.00(0.00)\n",
      "Iter 5690 | Time 18.9720(19.0262) | Bit/dim 3.6736(3.6544) | Xent 0.5553(0.5751) | Loss 531.4102(569.6951) | Error 0.1967(0.2044) Steps 0(0.00) | Grad Norm 410.5387(383.9306) | Total Time 0.00(0.00)\n",
      "Iter 5700 | Time 17.8087(18.9563) | Bit/dim 3.6657(3.6505) | Xent 0.5423(0.5708) | Loss 495.6123(555.5546) | Error 0.2000(0.2029) Steps 0(0.00) | Grad Norm 260.2427(375.7149) | Total Time 0.00(0.00)\n",
      "Iter 5710 | Time 17.1474(18.8193) | Bit/dim 3.6536(3.6534) | Xent 0.5535(0.5725) | Loss 517.8748(546.5664) | Error 0.1978(0.2033) Steps 0(0.00) | Grad Norm 415.9488(376.9280) | Total Time 0.00(0.00)\n",
      "Iter 5720 | Time 18.1158(18.7718) | Bit/dim 3.6712(3.6536) | Xent 0.5855(0.5732) | Loss 512.7370(540.9839) | Error 0.1978(0.2037) Steps 0(0.00) | Grad Norm 418.2073(381.0270) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 93.5359, Epoch Time 1154.3030(1086.3545), Bit/dim 3.6549(best: 3.6544), Xent 0.7051, Loss 4.0074, Error 0.2406(best: 0.2394)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5730 | Time 19.4463(18.7660) | Bit/dim 3.6423(3.6518) | Xent 0.5378(0.5686) | Loss 532.6521(593.2275) | Error 0.2000(0.2026) Steps 0(0.00) | Grad Norm 266.7929(372.1863) | Total Time 0.00(0.00)\n",
      "Iter 5740 | Time 18.8999(18.8526) | Bit/dim 3.6162(3.6482) | Xent 0.5361(0.5657) | Loss 493.6394(573.2143) | Error 0.2078(0.2014) Steps 0(0.00) | Grad Norm 379.1241(364.9577) | Total Time 0.00(0.00)\n",
      "Iter 5750 | Time 17.1409(18.8698) | Bit/dim 3.6679(3.6476) | Xent 0.6202(0.5779) | Loss 520.4153(560.7091) | Error 0.2367(0.2054) Steps 0(0.00) | Grad Norm 463.1427(403.4444) | Total Time 0.00(0.00)\n",
      "Iter 5760 | Time 19.1083(18.9719) | Bit/dim 3.6791(3.6523) | Xent 0.6136(0.5868) | Loss 520.7017(550.8339) | Error 0.2178(0.2086) Steps 0(0.00) | Grad Norm 509.0859(411.6055) | Total Time 0.00(0.00)\n",
      "Iter 5770 | Time 18.7602(19.1175) | Bit/dim 3.6567(3.6565) | Xent 0.5586(0.5871) | Loss 537.9097(545.9508) | Error 0.2011(0.2097) Steps 0(0.00) | Grad Norm 415.4037(409.6638) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 92.8237, Epoch Time 1156.1564(1088.4486), Bit/dim 3.6537(best: 3.6544), Xent 0.7329, Loss 4.0201, Error 0.2545(best: 0.2394)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5780 | Time 18.8755(18.8773) | Bit/dim 3.6634(3.6561) | Xent 0.5497(0.5852) | Loss 540.6897(607.4831) | Error 0.2000(0.2081) Steps 0(0.00) | Grad Norm 433.9510(407.0281) | Total Time 0.00(0.00)\n",
      "Iter 5790 | Time 19.1576(18.8062) | Bit/dim 3.6050(3.6534) | Xent 0.5353(0.5780) | Loss 523.2352(586.0956) | Error 0.1933(0.2053) Steps 0(0.00) | Grad Norm 252.5172(377.4403) | Total Time 0.00(0.00)\n",
      "Iter 5800 | Time 20.7880(18.7385) | Bit/dim 3.6517(3.6537) | Xent 0.5466(0.5676) | Loss 524.5242(567.6495) | Error 0.1967(0.2032) Steps 0(0.00) | Grad Norm 357.5035(369.8744) | Total Time 0.00(0.00)\n",
      "Iter 5810 | Time 19.5414(18.8600) | Bit/dim 3.6252(3.6524) | Xent 0.5858(0.5703) | Loss 505.3055(554.2534) | Error 0.2067(0.2047) Steps 0(0.00) | Grad Norm 313.7508(376.7812) | Total Time 0.00(0.00)\n",
      "Iter 5820 | Time 20.2496(18.9121) | Bit/dim 3.6361(3.6520) | Xent 0.5809(0.5686) | Loss 521.5592(545.3182) | Error 0.1978(0.2034) Steps 0(0.00) | Grad Norm 344.3901(356.0100) | Total Time 0.00(0.00)\n",
      "Iter 5830 | Time 18.6145(18.9338) | Bit/dim 3.6345(3.6501) | Xent 0.6292(0.5870) | Loss 524.2506(538.7944) | Error 0.2167(0.2102) Steps 0(0.00) | Grad Norm 466.2590(402.0117) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 94.2358, Epoch Time 1147.7781(1090.2285), Bit/dim 3.6533(best: 3.6537), Xent 0.6853, Loss 3.9959, Error 0.2333(best: 0.2394)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5840 | Time 17.4710(19.1478) | Bit/dim 3.6458(3.6516) | Xent 0.6163(0.5877) | Loss 524.5701(594.4925) | Error 0.2244(0.2110) Steps 0(0.00) | Grad Norm 392.3364(377.5291) | Total Time 0.00(0.00)\n",
      "Iter 5850 | Time 16.6695(19.0566) | Bit/dim 3.6663(3.6511) | Xent 0.5581(0.5777) | Loss 528.6033(575.9618) | Error 0.1900(0.2057) Steps 0(0.00) | Grad Norm 239.3835(341.1556) | Total Time 0.00(0.00)\n",
      "Iter 5860 | Time 18.1237(19.0885) | Bit/dim 3.6519(3.6481) | Xent 0.5992(0.5716) | Loss 518.9741(563.8018) | Error 0.2233(0.2035) Steps 0(0.00) | Grad Norm 702.5005(361.2287) | Total Time 0.00(0.00)\n",
      "Iter 5870 | Time 25.7238(19.2321) | Bit/dim 3.6395(3.6482) | Xent 0.5027(0.5677) | Loss 530.5282(552.8942) | Error 0.1856(0.2020) Steps 0(0.00) | Grad Norm 251.0050(362.2362) | Total Time 0.00(0.00)\n",
      "Iter 5880 | Time 18.5038(19.0369) | Bit/dim 3.6280(3.6483) | Xent 0.6299(0.5684) | Loss 523.1967(545.5649) | Error 0.2389(0.2021) Steps 0(0.00) | Grad Norm 492.7814(372.6806) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 94.8403, Epoch Time 1165.2537(1092.4792), Bit/dim 3.6534(best: 3.6533), Xent 0.6984, Loss 4.0026, Error 0.2400(best: 0.2333)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5890 | Time 17.5528(18.9487) | Bit/dim 3.6703(3.6528) | Xent 0.5427(0.5647) | Loss 509.8340(608.1319) | Error 0.1878(0.2016) Steps 0(0.00) | Grad Norm 316.9990(381.6125) | Total Time 0.00(0.00)\n",
      "Iter 5900 | Time 18.0050(18.9841) | Bit/dim 3.7047(3.6564) | Xent 0.6382(0.5632) | Loss 518.5347(586.0479) | Error 0.2356(0.2015) Steps 0(0.00) | Grad Norm 523.8830(380.5386) | Total Time 0.00(0.00)\n",
      "Iter 5910 | Time 19.2092(18.9402) | Bit/dim 3.6065(3.6533) | Xent 0.5532(0.5653) | Loss 496.3396(569.5502) | Error 0.2022(0.2013) Steps 0(0.00) | Grad Norm 271.7621(378.7725) | Total Time 0.00(0.00)\n",
      "Iter 5920 | Time 18.8717(18.9358) | Bit/dim 3.5993(3.6498) | Xent 0.5776(0.5657) | Loss 515.8439(557.0377) | Error 0.2322(0.2015) Steps 0(0.00) | Grad Norm 371.3821(413.1948) | Total Time 0.00(0.00)\n",
      "Iter 5930 | Time 17.9131(18.7540) | Bit/dim 3.6503(3.6464) | Xent 0.5633(0.5660) | Loss 537.8975(548.6003) | Error 0.2200(0.2018) Steps 0(0.00) | Grad Norm 440.6291(391.9951) | Total Time 0.00(0.00)\n",
      "Iter 5940 | Time 19.7558(18.7587) | Bit/dim 3.6284(3.6458) | Xent 0.5353(0.5638) | Loss 513.3448(542.5278) | Error 0.1933(0.2012) Steps 0(0.00) | Grad Norm 399.2200(388.3334) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 94.8622, Epoch Time 1142.5856(1093.9824), Bit/dim 3.6583(best: 3.6533), Xent 0.7362, Loss 4.0264, Error 0.2461(best: 0.2333)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5950 | Time 20.1852(18.6492) | Bit/dim 3.6658(3.6450) | Xent 0.4777(0.5533) | Loss 523.0308(594.9934) | Error 0.1667(0.1983) Steps 0(0.00) | Grad Norm 239.6247(376.2433) | Total Time 0.00(0.00)\n",
      "Iter 5960 | Time 18.7817(18.6601) | Bit/dim 3.6635(3.6451) | Xent 0.5850(0.5615) | Loss 533.4272(577.4413) | Error 0.2133(0.2016) Steps 0(0.00) | Grad Norm 291.1954(386.4398) | Total Time 0.00(0.00)\n",
      "Iter 5970 | Time 18.3078(18.6745) | Bit/dim 3.6224(3.6445) | Xent 0.5468(0.5546) | Loss 515.0021(562.5273) | Error 0.1856(0.1988) Steps 0(0.00) | Grad Norm 342.1950(370.6247) | Total Time 0.00(0.00)\n",
      "Iter 5980 | Time 18.0765(18.4970) | Bit/dim 3.6364(3.6426) | Xent 0.5157(0.5551) | Loss 520.8595(550.6389) | Error 0.1789(0.1978) Steps 0(0.00) | Grad Norm 291.8119(350.5727) | Total Time 0.00(0.00)\n",
      "Iter 5990 | Time 20.8785(18.6441) | Bit/dim 3.6414(3.6440) | Xent 0.5328(0.5552) | Loss 524.7732(543.3611) | Error 0.1778(0.1985) Steps 0(0.00) | Grad Norm 298.4300(334.9043) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 92.0523, Epoch Time 1127.7591(1094.9957), Bit/dim 3.6506(best: 3.6533), Xent 0.6870, Loss 3.9941, Error 0.2360(best: 0.2333)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6000 | Time 19.7079(18.6496) | Bit/dim 3.6563(3.6459) | Xent 0.6068(0.5594) | Loss 546.9957(604.5029) | Error 0.2156(0.1996) Steps 0(0.00) | Grad Norm 493.7706(375.1122) | Total Time 0.00(0.00)\n",
      "Iter 6010 | Time 19.3061(18.6927) | Bit/dim 3.6116(3.6422) | Xent 0.4961(0.5504) | Loss 505.2965(582.4402) | Error 0.1733(0.1959) Steps 0(0.00) | Grad Norm 361.5839(359.8873) | Total Time 0.00(0.00)\n",
      "Iter 6020 | Time 19.5135(18.7778) | Bit/dim 3.6517(3.6417) | Xent 0.5346(0.5458) | Loss 529.1565(566.6246) | Error 0.1878(0.1948) Steps 0(0.00) | Grad Norm 500.4155(368.7704) | Total Time 0.00(0.00)\n",
      "Iter 6030 | Time 21.8563(19.0164) | Bit/dim 3.6587(3.6412) | Xent 0.5956(0.5467) | Loss 504.0739(552.8211) | Error 0.1944(0.1944) Steps 0(0.00) | Grad Norm 529.7810(364.8142) | Total Time 0.00(0.00)\n",
      "Iter 6040 | Time 18.4049(18.9220) | Bit/dim 3.6581(3.6426) | Xent 0.5996(0.5491) | Loss 529.0908(545.0177) | Error 0.2144(0.1959) Steps 0(0.00) | Grad Norm 646.7140(363.9438) | Total Time 0.00(0.00)\n",
      "Iter 6050 | Time 19.8932(18.9499) | Bit/dim 3.6456(3.6433) | Xent 0.5085(0.5461) | Loss 530.9976(539.6673) | Error 0.1789(0.1942) Steps 0(0.00) | Grad Norm 226.6165(368.8668) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 93.8665, Epoch Time 1158.7368(1096.9079), Bit/dim 3.6606(best: 3.6506), Xent 0.7165, Loss 4.0189, Error 0.2407(best: 0.2333)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6060 | Time 18.2903(18.8506) | Bit/dim 3.6519(3.6445) | Xent 0.5034(0.5395) | Loss 520.1281(590.6876) | Error 0.1889(0.1921) Steps 0(0.00) | Grad Norm 241.3045(363.1874) | Total Time 0.00(0.00)\n",
      "Iter 6070 | Time 18.5607(18.9704) | Bit/dim 3.6302(3.6454) | Xent 0.4484(0.5398) | Loss 501.0206(571.3732) | Error 0.1678(0.1942) Steps 0(0.00) | Grad Norm 271.5234(372.5005) | Total Time 0.00(0.00)\n",
      "Iter 6080 | Time 17.7733(18.8542) | Bit/dim 3.6727(3.6448) | Xent 0.5761(0.5398) | Loss 522.4588(557.9990) | Error 0.2078(0.1930) Steps 0(0.00) | Grad Norm 258.0951(366.4206) | Total Time 0.00(0.00)\n",
      "Iter 6090 | Time 19.2571(18.9086) | Bit/dim 3.6511(3.6480) | Xent 0.6100(0.5470) | Loss 534.2422(548.7393) | Error 0.2211(0.1955) Steps 0(0.00) | Grad Norm 384.2190(393.3004) | Total Time 0.00(0.00)\n",
      "Iter 6100 | Time 18.7341(18.9341) | Bit/dim 3.6334(3.6459) | Xent 0.5197(0.5496) | Loss 504.8083(541.1225) | Error 0.1789(0.1977) Steps 0(0.00) | Grad Norm 289.8630(407.6525) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 92.5508, Epoch Time 1152.3189(1098.5703), Bit/dim 3.6560(best: 3.6506), Xent 0.6984, Loss 4.0052, Error 0.2366(best: 0.2333)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6110 | Time 18.6005(18.9942) | Bit/dim 3.6407(3.6430) | Xent 0.5160(0.5470) | Loss 525.5809(605.4755) | Error 0.1778(0.1964) Steps 0(0.00) | Grad Norm 382.4538(410.9406) | Total Time 0.00(0.00)\n",
      "Iter 6120 | Time 18.7496(18.9974) | Bit/dim 3.6793(3.6444) | Xent 0.6866(0.5535) | Loss 526.8961(584.3081) | Error 0.2300(0.1981) Steps 0(0.00) | Grad Norm 794.4513(440.2954) | Total Time 0.00(0.00)\n",
      "Iter 6130 | Time 18.0451(19.0443) | Bit/dim 3.6266(3.6438) | Xent 0.5844(0.5591) | Loss 528.5919(568.6409) | Error 0.2089(0.1998) Steps 0(0.00) | Grad Norm 471.0383(429.6481) | Total Time 0.00(0.00)\n",
      "Iter 6140 | Time 18.3994(19.1504) | Bit/dim 3.6530(3.6435) | Xent 0.5238(0.5540) | Loss 513.6856(557.2565) | Error 0.1800(0.1977) Steps 0(0.00) | Grad Norm 369.3610(409.9498) | Total Time 0.00(0.00)\n",
      "Iter 6150 | Time 19.4028(19.2043) | Bit/dim 3.6306(3.6421) | Xent 0.5757(0.5504) | Loss 520.3194(547.8435) | Error 0.2000(0.1969) Steps 0(0.00) | Grad Norm 349.6425(386.1293) | Total Time 0.00(0.00)\n",
      "Iter 6160 | Time 19.0126(19.2785) | Bit/dim 3.6034(3.6414) | Xent 0.5066(0.5443) | Loss 524.1643(541.7959) | Error 0.1789(0.1940) Steps 0(0.00) | Grad Norm 292.4285(356.4574) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 93.7538, Epoch Time 1170.1732(1100.7184), Bit/dim 3.6430(best: 3.6506), Xent 0.6564, Loss 3.9712, Error 0.2236(best: 0.2333)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6170 | Time 20.0456(19.2088) | Bit/dim 3.6504(3.6400) | Xent 0.5624(0.5437) | Loss 489.0614(595.5356) | Error 0.1944(0.1926) Steps 0(0.00) | Grad Norm 442.1038(361.6592) | Total Time 0.00(0.00)\n",
      "Iter 6180 | Time 19.3054(19.0531) | Bit/dim 3.6124(3.6399) | Xent 0.5213(0.5362) | Loss 513.1911(577.1055) | Error 0.2100(0.1912) Steps 0(0.00) | Grad Norm 234.2845(361.2966) | Total Time 0.00(0.00)\n",
      "Iter 6190 | Time 18.5287(18.9861) | Bit/dim 3.6224(3.6402) | Xent 0.5208(0.5320) | Loss 490.9964(559.5418) | Error 0.1733(0.1891) Steps 0(0.00) | Grad Norm 224.6685(371.2824) | Total Time 0.00(0.00)\n",
      "Iter 6200 | Time 19.3235(19.0524) | Bit/dim 3.6729(3.6435) | Xent 0.6451(0.5451) | Loss 539.8383(550.9207) | Error 0.2200(0.1932) Steps 0(0.00) | Grad Norm 670.3129(417.7283) | Total Time 0.00(0.00)\n",
      "Iter 6210 | Time 19.9225(19.2135) | Bit/dim 3.6454(3.6447) | Xent 0.5168(0.5553) | Loss 535.4884(545.2648) | Error 0.1800(0.1961) Steps 0(0.00) | Grad Norm 290.6408(426.0634) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 94.9375, Epoch Time 1158.9919(1102.4666), Bit/dim 3.6532(best: 3.6430), Xent 0.6730, Loss 3.9898, Error 0.2322(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6220 | Time 18.7417(19.1051) | Bit/dim 3.6695(3.6470) | Xent 0.5032(0.5545) | Loss 527.4065(609.3560) | Error 0.1867(0.1972) Steps 0(0.00) | Grad Norm 217.2773(409.2084) | Total Time 0.00(0.00)\n",
      "Iter 6230 | Time 20.0853(19.1604) | Bit/dim 3.6598(3.6459) | Xent 0.5135(0.5456) | Loss 522.6956(586.7358) | Error 0.1733(0.1947) Steps 0(0.00) | Grad Norm 255.4257(400.1341) | Total Time 0.00(0.00)\n",
      "Iter 6240 | Time 17.4557(19.1632) | Bit/dim 3.6618(3.6452) | Xent 0.5617(0.5404) | Loss 507.2620(569.5605) | Error 0.2178(0.1937) Steps 0(0.00) | Grad Norm 291.7819(384.0259) | Total Time 0.00(0.00)\n",
      "Iter 6250 | Time 20.0160(19.0499) | Bit/dim 3.6435(3.6459) | Xent 0.5083(0.5382) | Loss 514.6699(556.4292) | Error 0.1767(0.1930) Steps 0(0.00) | Grad Norm 340.4739(360.0491) | Total Time 0.00(0.00)\n",
      "Iter 6260 | Time 19.2426(19.1543) | Bit/dim 3.6477(3.6435) | Xent 0.5231(0.5348) | Loss 508.0115(547.0851) | Error 0.1900(0.1912) Steps 0(0.00) | Grad Norm 507.6680(374.3868) | Total Time 0.00(0.00)\n",
      "Iter 6270 | Time 21.2806(19.2902) | Bit/dim 3.6504(3.6416) | Xent 0.5792(0.5430) | Loss 516.3905(541.1100) | Error 0.2067(0.1937) Steps 0(0.00) | Grad Norm 354.6020(393.1291) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 94.5251, Epoch Time 1169.5044(1104.4777), Bit/dim 3.6454(best: 3.6430), Xent 0.6785, Loss 3.9847, Error 0.2337(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6280 | Time 20.7267(19.3193) | Bit/dim 3.6365(3.6410) | Xent 0.5480(0.5369) | Loss 532.5150(593.4243) | Error 0.1967(0.1918) Steps 0(0.00) | Grad Norm 320.2608(373.4628) | Total Time 0.00(0.00)\n",
      "Iter 6290 | Time 17.2522(19.1527) | Bit/dim 3.6493(3.6413) | Xent 0.4943(0.5355) | Loss 520.8958(576.1205) | Error 0.1822(0.1919) Steps 0(0.00) | Grad Norm 296.4805(388.6778) | Total Time 0.00(0.00)\n",
      "Iter 6300 | Time 17.8889(19.0664) | Bit/dim 3.6612(3.6406) | Xent 0.5397(0.5321) | Loss 535.4158(562.3254) | Error 0.1900(0.1908) Steps 0(0.00) | Grad Norm 611.0872(408.3369) | Total Time 0.00(0.00)\n",
      "Iter 6310 | Time 19.4565(18.9670) | Bit/dim 3.6263(3.6419) | Xent 0.5733(0.5428) | Loss 529.7979(551.5645) | Error 0.2078(0.1943) Steps 0(0.00) | Grad Norm 453.0492(432.1193) | Total Time 0.00(0.00)\n",
      "Iter 6320 | Time 19.1113(19.1920) | Bit/dim 3.6105(3.6412) | Xent 0.5785(0.5456) | Loss 515.6201(544.3390) | Error 0.2033(0.1952) Steps 0(0.00) | Grad Norm 455.4492(445.4992) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 94.0948, Epoch Time 1159.3768(1106.1247), Bit/dim 3.6424(best: 3.6430), Xent 0.6710, Loss 3.9779, Error 0.2283(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6330 | Time 18.2692(19.0672) | Bit/dim 3.6710(3.6426) | Xent 0.4776(0.5388) | Loss 525.3846(607.8505) | Error 0.1600(0.1930) Steps 0(0.00) | Grad Norm 261.0762(426.9394) | Total Time 0.00(0.00)\n",
      "Iter 6340 | Time 21.6678(19.1595) | Bit/dim 3.6332(3.6423) | Xent 0.5457(0.5311) | Loss 517.3050(585.0180) | Error 0.1933(0.1904) Steps 0(0.00) | Grad Norm 510.9031(409.2386) | Total Time 0.00(0.00)\n",
      "Iter 6350 | Time 18.0581(19.1143) | Bit/dim 3.6819(3.6436) | Xent 0.5022(0.5352) | Loss 509.5785(567.9418) | Error 0.1700(0.1904) Steps 0(0.00) | Grad Norm 336.2605(430.0544) | Total Time 0.00(0.00)\n",
      "Iter 6360 | Time 19.1379(19.1370) | Bit/dim 3.7001(3.6443) | Xent 0.5545(0.5320) | Loss 531.1547(555.9917) | Error 0.1944(0.1894) Steps 0(0.00) | Grad Norm 490.3504(419.6162) | Total Time 0.00(0.00)\n",
      "Iter 6370 | Time 18.2049(19.3601) | Bit/dim 3.5824(3.6439) | Xent 0.5546(0.5408) | Loss 516.3339(549.6525) | Error 0.1889(0.1911) Steps 0(0.00) | Grad Norm 278.3498(430.0952) | Total Time 0.00(0.00)\n",
      "Iter 6380 | Time 17.9784(19.3082) | Bit/dim 3.6264(3.6438) | Xent 0.5327(0.5360) | Loss 496.2015(543.3175) | Error 0.2056(0.1918) Steps 0(0.00) | Grad Norm 270.6919(395.0377) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 94.8240, Epoch Time 1173.3125(1108.1403), Bit/dim 3.6484(best: 3.6424), Xent 0.6740, Loss 3.9854, Error 0.2301(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6390 | Time 18.6474(19.1641) | Bit/dim 3.6279(3.6437) | Xent 0.4798(0.5327) | Loss 531.3589(597.1269) | Error 0.1711(0.1903) Steps 0(0.00) | Grad Norm 275.3345(408.9184) | Total Time 0.00(0.00)\n",
      "Iter 6400 | Time 19.4741(19.0568) | Bit/dim 3.6229(3.6439) | Xent 0.5011(0.5307) | Loss 495.4728(575.8470) | Error 0.1700(0.1898) Steps 0(0.00) | Grad Norm 393.0137(415.2953) | Total Time 0.00(0.00)\n",
      "Iter 6410 | Time 18.5505(18.9574) | Bit/dim 3.6579(3.6443) | Xent 0.5067(0.5229) | Loss 509.4505(559.9700) | Error 0.1833(0.1875) Steps 0(0.00) | Grad Norm 345.3355(384.2484) | Total Time 0.00(0.00)\n",
      "Iter 6420 | Time 20.1172(18.9054) | Bit/dim 3.6237(3.6417) | Xent 0.5342(0.5250) | Loss 520.7199(548.3926) | Error 0.1800(0.1874) Steps 0(0.00) | Grad Norm 356.1919(381.9159) | Total Time 0.00(0.00)\n",
      "Iter 6430 | Time 19.0050(19.1793) | Bit/dim 3.6435(3.6404) | Xent 0.5844(0.5318) | Loss 514.3923(540.8828) | Error 0.1967(0.1893) Steps 0(0.00) | Grad Norm 606.8107(402.9752) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 95.3788, Epoch Time 1156.5950(1109.5940), Bit/dim 3.6430(best: 3.6424), Xent 0.7007, Loss 3.9934, Error 0.2386(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6440 | Time 18.2934(19.0591) | Bit/dim 3.6517(3.6407) | Xent 0.5593(0.5401) | Loss 501.4751(606.1743) | Error 0.2100(0.1934) Steps 0(0.00) | Grad Norm 308.0864(400.1244) | Total Time 0.00(0.00)\n",
      "Iter 6450 | Time 18.6099(19.0549) | Bit/dim 3.6258(3.6400) | Xent 0.5453(0.5272) | Loss 520.8212(581.4589) | Error 0.1933(0.1877) Steps 0(0.00) | Grad Norm 362.6116(364.8075) | Total Time 0.00(0.00)\n",
      "Iter 6460 | Time 19.0550(19.0637) | Bit/dim 3.6172(3.6376) | Xent 0.4940(0.5185) | Loss 515.8619(565.8505) | Error 0.1756(0.1853) Steps 0(0.00) | Grad Norm 441.4011(370.1325) | Total Time 0.00(0.00)\n",
      "Iter 6470 | Time 19.3002(19.1635) | Bit/dim 3.6320(3.6365) | Xent 0.5372(0.5229) | Loss 513.1393(553.4704) | Error 0.1911(0.1867) Steps 0(0.00) | Grad Norm 487.9496(383.2577) | Total Time 0.00(0.00)\n",
      "Iter 6480 | Time 18.2933(19.1283) | Bit/dim 3.6200(3.6359) | Xent 0.5225(0.5233) | Loss 511.1249(544.0610) | Error 0.1900(0.1863) Steps 0(0.00) | Grad Norm 430.7850(381.9391) | Total Time 0.00(0.00)\n",
      "Iter 6490 | Time 18.2358(19.0288) | Bit/dim 3.6646(3.6367) | Xent 0.5209(0.5281) | Loss 504.4361(538.2466) | Error 0.1878(0.1888) Steps 0(0.00) | Grad Norm 346.4039(397.8415) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 95.3364, Epoch Time 1159.8204(1111.1007), Bit/dim 3.6401(best: 3.6424), Xent 0.6764, Loss 3.9783, Error 0.2303(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6500 | Time 19.9336(19.0620) | Bit/dim 3.6434(3.6349) | Xent 0.4724(0.5187) | Loss 521.6730(591.7979) | Error 0.1689(0.1860) Steps 0(0.00) | Grad Norm 299.9973(372.9570) | Total Time 0.00(0.00)\n",
      "Iter 6510 | Time 20.7595(19.2902) | Bit/dim 3.6390(3.6356) | Xent 0.4396(0.5154) | Loss 522.4525(573.3522) | Error 0.1700(0.1850) Steps 0(0.00) | Grad Norm 302.7372(370.9548) | Total Time 0.00(0.00)\n",
      "Iter 6520 | Time 19.1988(19.1948) | Bit/dim 3.6591(3.6384) | Xent 0.4714(0.5122) | Loss 514.3157(560.0321) | Error 0.1700(0.1835) Steps 0(0.00) | Grad Norm 423.3211(373.9275) | Total Time 0.00(0.00)\n",
      "Iter 6530 | Time 17.2628(19.0875) | Bit/dim 3.5887(3.6370) | Xent 0.5419(0.5163) | Loss 508.5198(549.8714) | Error 0.2011(0.1850) Steps 0(0.00) | Grad Norm 303.3748(380.1313) | Total Time 0.00(0.00)\n",
      "Iter 6540 | Time 19.5024(19.0661) | Bit/dim 3.6336(3.6375) | Xent 0.5665(0.5169) | Loss 544.0696(543.1779) | Error 0.2011(0.1859) Steps 0(0.00) | Grad Norm 490.3488(386.2122) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 93.8772, Epoch Time 1164.3954(1112.6996), Bit/dim 3.6377(best: 3.6401), Xent 0.6827, Loss 3.9791, Error 0.2278(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6550 | Time 19.4520(19.0496) | Bit/dim 3.6245(3.6382) | Xent 0.5860(0.5208) | Loss 516.8232(604.7961) | Error 0.1911(0.1861) Steps 0(0.00) | Grad Norm 584.4135(384.5488) | Total Time 0.00(0.00)\n",
      "Iter 6560 | Time 19.4786(19.0173) | Bit/dim 3.6810(3.6382) | Xent 0.6104(0.5288) | Loss 536.6169(582.6838) | Error 0.2200(0.1886) Steps 0(0.00) | Grad Norm 606.6409(431.4917) | Total Time 0.00(0.00)\n",
      "Iter 6570 | Time 16.7678(19.0621) | Bit/dim 3.6574(3.6388) | Xent 0.4960(0.5250) | Loss 506.5172(564.9432) | Error 0.1778(0.1871) Steps 0(0.00) | Grad Norm 328.9066(408.3359) | Total Time 0.00(0.00)\n",
      "Iter 6580 | Time 20.0884(19.2469) | Bit/dim 3.6509(3.6380) | Xent 0.5343(0.5211) | Loss 530.8548(554.3872) | Error 0.1989(0.1854) Steps 0(0.00) | Grad Norm 223.6045(377.8837) | Total Time 0.00(0.00)\n",
      "Iter 6590 | Time 20.1540(19.2951) | Bit/dim 3.6258(3.6360) | Xent 0.4595(0.5127) | Loss 525.9716(546.1622) | Error 0.1656(0.1828) Steps 0(0.00) | Grad Norm 277.3043(357.5352) | Total Time 0.00(0.00)\n",
      "Iter 6600 | Time 19.9442(19.3112) | Bit/dim 3.6482(3.6358) | Xent 0.5166(0.5138) | Loss 518.9268(539.5374) | Error 0.1833(0.1833) Steps 0(0.00) | Grad Norm 322.0171(371.9299) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 95.5406, Epoch Time 1174.7261(1114.5604), Bit/dim 3.6465(best: 3.6377), Xent 0.7640, Loss 4.0285, Error 0.2501(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6610 | Time 18.8308(19.3505) | Bit/dim 3.6513(3.6336) | Xent 0.5068(0.5163) | Loss 522.8837(593.9462) | Error 0.1867(0.1846) Steps 0(0.00) | Grad Norm 486.8604(402.3501) | Total Time 0.00(0.00)\n",
      "Iter 6620 | Time 18.3873(19.1879) | Bit/dim 3.6782(3.6348) | Xent 0.4990(0.5114) | Loss 523.6601(573.3172) | Error 0.1733(0.1819) Steps 0(0.00) | Grad Norm 565.4929(397.5234) | Total Time 0.00(0.00)\n",
      "Iter 6630 | Time 20.8292(19.2351) | Bit/dim 3.6236(3.6389) | Xent 0.5079(0.5151) | Loss 531.7187(562.1857) | Error 0.1722(0.1833) Steps 0(0.00) | Grad Norm 353.2134(404.4247) | Total Time 0.00(0.00)\n",
      "Iter 6640 | Time 18.9172(19.2079) | Bit/dim 3.6355(3.6398) | Xent 0.5528(0.5149) | Loss 520.6341(553.2884) | Error 0.1900(0.1829) Steps 0(0.00) | Grad Norm 303.5635(375.9609) | Total Time 0.00(0.00)\n",
      "Iter 6650 | Time 20.6403(19.3029) | Bit/dim 3.6533(3.6392) | Xent 0.5148(0.5131) | Loss 508.8676(544.4906) | Error 0.1856(0.1828) Steps 0(0.00) | Grad Norm 544.9858(385.8787) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 96.4471, Epoch Time 1172.9372(1116.3117), Bit/dim 3.6428(best: 3.6377), Xent 0.6886, Loss 3.9871, Error 0.2336(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6660 | Time 20.5427(19.2319) | Bit/dim 3.6122(3.6378) | Xent 0.4982(0.5149) | Loss 534.9884(608.2837) | Error 0.1833(0.1834) Steps 0(0.00) | Grad Norm 268.6002(374.7249) | Total Time 0.00(0.00)\n",
      "Iter 6670 | Time 19.4969(19.3423) | Bit/dim 3.6579(3.6403) | Xent 0.5308(0.5108) | Loss 519.9139(585.3577) | Error 0.1911(0.1819) Steps 0(0.00) | Grad Norm 603.3844(379.6214) | Total Time 0.00(0.00)\n",
      "Iter 6680 | Time 18.2717(19.3321) | Bit/dim 3.6371(3.6382) | Xent 0.5030(0.5069) | Loss 522.5450(568.3947) | Error 0.1844(0.1806) Steps 0(0.00) | Grad Norm 468.1438(385.6033) | Total Time 0.00(0.00)\n",
      "Iter 6690 | Time 19.2565(19.2115) | Bit/dim 3.6210(3.6342) | Xent 0.5069(0.5078) | Loss 515.6995(555.5956) | Error 0.1922(0.1822) Steps 0(0.00) | Grad Norm 480.7772(389.5670) | Total Time 0.00(0.00)\n",
      "Iter 6700 | Time 20.3889(19.1199) | Bit/dim 3.6758(3.6366) | Xent 0.4886(0.5080) | Loss 538.9774(546.1355) | Error 0.1744(0.1818) Steps 0(0.00) | Grad Norm 306.3471(391.3660) | Total Time 0.00(0.00)\n",
      "Iter 6710 | Time 19.5409(19.2649) | Bit/dim 3.6323(3.6345) | Xent 0.4886(0.5066) | Loss 507.1474(538.9575) | Error 0.1689(0.1814) Steps 0(0.00) | Grad Norm 381.5901(393.0529) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 96.9792, Epoch Time 1173.0891(1118.0150), Bit/dim 3.6415(best: 3.6377), Xent 0.7131, Loss 3.9980, Error 0.2332(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6720 | Time 19.4162(19.3794) | Bit/dim 3.6671(3.6347) | Xent 0.5756(0.5092) | Loss 520.4107(597.2516) | Error 0.1967(0.1817) Steps 0(0.00) | Grad Norm 428.6495(409.7294) | Total Time 0.00(0.00)\n",
      "Iter 6730 | Time 19.9733(19.4108) | Bit/dim 3.6043(3.6338) | Xent 0.5498(0.5029) | Loss 536.4011(579.1494) | Error 0.2011(0.1798) Steps 0(0.00) | Grad Norm 382.6372(379.7629) | Total Time 0.00(0.00)\n",
      "Iter 6740 | Time 20.4727(19.3752) | Bit/dim 3.6079(3.6315) | Xent 0.5663(0.5077) | Loss 520.9662(562.7676) | Error 0.2000(0.1821) Steps 0(0.00) | Grad Norm 349.5428(400.1896) | Total Time 0.00(0.00)\n",
      "Iter 6750 | Time 17.9823(19.2043) | Bit/dim 3.6166(3.6311) | Xent 0.4930(0.5107) | Loss 511.5863(551.7561) | Error 0.1856(0.1841) Steps 0(0.00) | Grad Norm 255.4081(400.4590) | Total Time 0.00(0.00)\n",
      "Iter 6760 | Time 19.4571(19.4214) | Bit/dim 3.6121(3.6318) | Xent 0.5263(0.5064) | Loss 530.0907(544.1786) | Error 0.1944(0.1819) Steps 0(0.00) | Grad Norm 373.8132(373.7190) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 94.5131, Epoch Time 1176.5486(1119.7710), Bit/dim 3.6439(best: 3.6377), Xent 0.7082, Loss 3.9980, Error 0.2334(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6770 | Time 19.0561(19.3244) | Bit/dim 3.6107(3.6328) | Xent 0.4824(0.5055) | Loss 535.2502(607.8092) | Error 0.1822(0.1809) Steps 0(0.00) | Grad Norm 275.1472(373.6741) | Total Time 0.00(0.00)\n",
      "Iter 6780 | Time 18.6123(19.4409) | Bit/dim 3.6195(3.6292) | Xent 0.5369(0.5002) | Loss 516.3477(583.9583) | Error 0.1967(0.1793) Steps 0(0.00) | Grad Norm 715.8100(364.3162) | Total Time 0.00(0.00)\n",
      "Iter 6790 | Time 18.5456(19.2420) | Bit/dim 3.6135(3.6307) | Xent 0.4726(0.4991) | Loss 515.6311(567.4111) | Error 0.1656(0.1785) Steps 0(0.00) | Grad Norm 389.4368(378.2563) | Total Time 0.00(0.00)\n",
      "Iter 6800 | Time 17.7573(19.2367) | Bit/dim 3.6174(3.6331) | Xent 0.4753(0.4996) | Loss 522.5222(556.1131) | Error 0.1733(0.1786) Steps 0(0.00) | Grad Norm 357.1042(380.6504) | Total Time 0.00(0.00)\n",
      "Iter 6810 | Time 19.4514(19.3859) | Bit/dim 3.6489(3.6334) | Xent 0.4657(0.4987) | Loss 533.9528(547.5639) | Error 0.1767(0.1792) Steps 0(0.00) | Grad Norm 205.9607(382.6414) | Total Time 0.00(0.00)\n",
      "Iter 6820 | Time 20.3273(19.2733) | Bit/dim 3.6163(3.6323) | Xent 0.4817(0.4964) | Loss 544.5715(538.2167) | Error 0.1878(0.1778) Steps 0(0.00) | Grad Norm 470.4699(375.9172) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 95.8433, Epoch Time 1177.3867(1121.4995), Bit/dim 3.6325(best: 3.6377), Xent 0.6593, Loss 3.9621, Error 0.2229(best: 0.2236)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6830 | Time 19.4304(19.3250) | Bit/dim 3.6188(3.6323) | Xent 0.4559(0.4858) | Loss 532.1136(593.0693) | Error 0.1633(0.1752) Steps 0(0.00) | Grad Norm 494.0741(366.6975) | Total Time 0.00(0.00)\n",
      "Iter 6840 | Time 19.4956(19.3576) | Bit/dim 3.6228(3.6297) | Xent 0.5040(0.4808) | Loss 521.2710(574.6900) | Error 0.1811(0.1730) Steps 0(0.00) | Grad Norm 325.2137(344.4403) | Total Time 0.00(0.00)\n",
      "Iter 6850 | Time 19.5694(19.2686) | Bit/dim 3.6186(3.6294) | Xent 0.5481(0.4869) | Loss 540.4604(559.7293) | Error 0.1900(0.1744) Steps 0(0.00) | Grad Norm 283.5193(345.5967) | Total Time 0.00(0.00)\n",
      "Iter 6860 | Time 19.2324(19.2298) | Bit/dim 3.6119(3.6297) | Xent 0.4700(0.4884) | Loss 508.2183(550.7483) | Error 0.1689(0.1751) Steps 0(0.00) | Grad Norm 306.1285(359.8447) | Total Time 0.00(0.00)\n",
      "Iter 6870 | Time 19.3920(19.2843) | Bit/dim 3.6392(3.6290) | Xent 0.4955(0.4932) | Loss 541.5040(543.5418) | Error 0.1811(0.1757) Steps 0(0.00) | Grad Norm 414.4373(369.0157) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 96.1209, Epoch Time 1171.9344(1123.0125), Bit/dim 3.6282(best: 3.6325), Xent 0.6705, Loss 3.9635, Error 0.2298(best: 0.2229)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6880 | Time 18.3531(19.1132) | Bit/dim 3.6241(3.6315) | Xent 0.4549(0.4951) | Loss 507.8866(605.8771) | Error 0.1589(0.1762) Steps 0(0.00) | Grad Norm 328.9318(376.8934) | Total Time 0.00(0.00)\n",
      "Iter 6890 | Time 18.6183(19.1930) | Bit/dim 3.6348(3.6317) | Xent 0.4789(0.4869) | Loss 528.8424(583.1130) | Error 0.1711(0.1731) Steps 0(0.00) | Grad Norm 418.0126(359.8564) | Total Time 0.00(0.00)\n",
      "Iter 6900 | Time 19.2085(19.2118) | Bit/dim 3.6340(3.6293) | Xent 0.4879(0.4895) | Loss 530.1104(566.6196) | Error 0.1811(0.1747) Steps 0(0.00) | Grad Norm 390.5297(364.1085) | Total Time 0.00(0.00)\n",
      "Iter 6910 | Time 18.3606(19.1347) | Bit/dim 3.6373(3.6309) | Xent 0.4229(0.4839) | Loss 503.8665(554.8969) | Error 0.1611(0.1738) Steps 0(0.00) | Grad Norm 303.5293(353.6414) | Total Time 0.00(0.00)\n",
      "Iter 6920 | Time 19.2969(19.1521) | Bit/dim 3.6335(3.6304) | Xent 0.5181(0.4807) | Loss 535.4569(545.0242) | Error 0.1922(0.1722) Steps 0(0.00) | Grad Norm 431.1223(334.6451) | Total Time 0.00(0.00)\n",
      "Iter 6930 | Time 20.0857(19.3418) | Bit/dim 3.6431(3.6299) | Xent 0.5226(0.4897) | Loss 525.9758(539.8665) | Error 0.1900(0.1761) Steps 0(0.00) | Grad Norm 402.6617(363.5856) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 96.1206, Epoch Time 1174.2397(1124.5493), Bit/dim 3.6328(best: 3.6282), Xent 0.7184, Loss 3.9920, Error 0.2377(best: 0.2229)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6940 | Time 20.2657(19.3520) | Bit/dim 3.6265(3.6287) | Xent 0.4715(0.4929) | Loss 533.9177(598.3941) | Error 0.1511(0.1770) Steps 0(0.00) | Grad Norm 444.7772(381.6266) | Total Time 0.00(0.00)\n",
      "Iter 6950 | Time 20.5582(19.2985) | Bit/dim 3.6807(3.6334) | Xent 0.6178(0.5018) | Loss 546.6475(578.1157) | Error 0.2144(0.1796) Steps 0(0.00) | Grad Norm 377.4296(393.0993) | Total Time 0.00(0.00)\n",
      "Iter 6960 | Time 19.1515(19.1260) | Bit/dim 3.6193(3.6343) | Xent 0.4968(0.5021) | Loss 534.1116(564.3349) | Error 0.1867(0.1798) Steps 0(0.00) | Grad Norm 285.6508(380.1252) | Total Time 0.00(0.00)\n",
      "Iter 6970 | Time 20.4130(19.2893) | Bit/dim 3.6403(3.6326) | Xent 0.5267(0.5016) | Loss 542.8416(553.6221) | Error 0.1956(0.1793) Steps 0(0.00) | Grad Norm 427.1058(384.0776) | Total Time 0.00(0.00)\n",
      "Iter 6980 | Time 18.7053(19.2532) | Bit/dim 3.6278(3.6335) | Xent 0.4903(0.4967) | Loss 494.4799(544.6247) | Error 0.1778(0.1772) Steps 0(0.00) | Grad Norm 348.9533(371.1526) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 95.4842, Epoch Time 1163.7387(1125.7250), Bit/dim 3.6306(best: 3.6282), Xent 0.6517, Loss 3.9564, Error 0.2202(best: 0.2229)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6990 | Time 20.1956(19.1314) | Bit/dim 3.6123(3.6263) | Xent 0.4602(0.4950) | Loss 520.6183(606.9901) | Error 0.1567(0.1773) Steps 0(0.00) | Grad Norm 326.3172(355.4679) | Total Time 0.00(0.00)\n",
      "Iter 7000 | Time 19.1024(19.4576) | Bit/dim 3.6312(3.6262) | Xent 0.4528(0.4869) | Loss 496.7165(584.6331) | Error 0.1722(0.1746) Steps 0(0.00) | Grad Norm 363.9578(362.9828) | Total Time 0.00(0.00)\n",
      "Iter 7010 | Time 19.2795(19.3798) | Bit/dim 3.6413(3.6290) | Xent 0.4660(0.4826) | Loss 525.0717(567.9458) | Error 0.1633(0.1727) Steps 0(0.00) | Grad Norm 310.9449(350.9401) | Total Time 0.00(0.00)\n",
      "Iter 7020 | Time 18.5751(19.4400) | Bit/dim 3.6303(3.6276) | Xent 0.4892(0.4780) | Loss 531.5007(554.2427) | Error 0.1678(0.1700) Steps 0(0.00) | Grad Norm 359.3796(330.4854) | Total Time 0.00(0.00)\n",
      "Iter 7030 | Time 20.4894(19.4468) | Bit/dim 3.5930(3.6264) | Xent 0.5334(0.4839) | Loss 533.9866(544.3738) | Error 0.1822(0.1724) Steps 0(0.00) | Grad Norm 419.8682(343.8082) | Total Time 0.00(0.00)\n",
      "Iter 7040 | Time 22.8763(19.5801) | Bit/dim 3.6313(3.6260) | Xent 0.5072(0.4843) | Loss 536.3459(537.8971) | Error 0.1811(0.1735) Steps 0(0.00) | Grad Norm 254.8748(346.9595) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 96.9919, Epoch Time 1198.1353(1127.8973), Bit/dim 3.6249(best: 3.6282), Xent 0.6679, Loss 3.9588, Error 0.2262(best: 0.2202)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7050 | Time 21.5088(19.5043) | Bit/dim 3.5934(3.6257) | Xent 0.4236(0.4816) | Loss 508.6882(594.7195) | Error 0.1589(0.1726) Steps 0(0.00) | Grad Norm 272.9219(354.4543) | Total Time 0.00(0.00)\n",
      "Iter 7060 | Time 19.8842(19.6263) | Bit/dim 3.6157(3.6272) | Xent 0.4963(0.4769) | Loss 524.7704(576.2775) | Error 0.1800(0.1705) Steps 0(0.00) | Grad Norm 277.4292(343.9688) | Total Time 0.00(0.00)\n",
      "Iter 7070 | Time 19.9238(19.3941) | Bit/dim 3.6354(3.6271) | Xent 0.4671(0.4797) | Loss 531.7519(561.8930) | Error 0.1733(0.1718) Steps 0(0.00) | Grad Norm 419.4821(360.3501) | Total Time 0.00(0.00)\n",
      "Iter 7080 | Time 20.8421(19.5262) | Bit/dim 3.6863(3.6302) | Xent 0.4765(0.4827) | Loss 534.4792(551.3694) | Error 0.1644(0.1726) Steps 0(0.00) | Grad Norm 270.8965(386.3697) | Total Time 0.00(0.00)\n",
      "Iter 7090 | Time 20.2405(19.7292) | Bit/dim 3.5971(3.6271) | Xent 0.4163(0.4763) | Loss 528.0432(544.3905) | Error 0.1444(0.1707) Steps 0(0.00) | Grad Norm 241.8296(357.1013) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 96.5138, Epoch Time 1193.1358(1129.8545), Bit/dim 3.6291(best: 3.6249), Xent 0.6717, Loss 3.9650, Error 0.2232(best: 0.2202)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7100 | Time 22.5237(19.8403) | Bit/dim 3.6511(3.6289) | Xent 0.4715(0.4728) | Loss 514.0360(611.8497) | Error 0.1833(0.1691) Steps 0(0.00) | Grad Norm 343.9849(359.7591) | Total Time 0.00(0.00)\n",
      "Iter 7110 | Time 17.7568(19.7562) | Bit/dim 3.6540(3.6273) | Xent 0.4620(0.4788) | Loss 518.1248(587.8783) | Error 0.1522(0.1691) Steps 0(0.00) | Grad Norm 286.3426(374.4106) | Total Time 0.00(0.00)\n",
      "Iter 7120 | Time 19.8426(19.6964) | Bit/dim 3.6393(3.6271) | Xent 0.4844(0.4755) | Loss 531.5150(569.0602) | Error 0.1767(0.1683) Steps 0(0.00) | Grad Norm 300.8608(356.5668) | Total Time 0.00(0.00)\n",
      "Iter 7130 | Time 18.9095(19.6465) | Bit/dim 3.6663(3.6256) | Xent 0.4615(0.4708) | Loss 516.4348(555.8692) | Error 0.1722(0.1671) Steps 0(0.00) | Grad Norm 272.1323(344.9098) | Total Time 0.00(0.00)\n",
      "Iter 7140 | Time 19.0355(19.6426) | Bit/dim 3.6197(3.6283) | Xent 0.5062(0.4775) | Loss 540.3149(548.6014) | Error 0.1667(0.1701) Steps 0(0.00) | Grad Norm 355.5801(368.7160) | Total Time 0.00(0.00)\n",
      "Iter 7150 | Time 19.7804(19.6871) | Bit/dim 3.6261(3.6282) | Xent 0.4523(0.4853) | Loss 540.7142(542.2532) | Error 0.1556(0.1729) Steps 0(0.00) | Grad Norm 208.0269(378.5356) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 97.3379, Epoch Time 1199.4112(1131.9412), Bit/dim 3.6311(best: 3.6249), Xent 0.6831, Loss 3.9727, Error 0.2281(best: 0.2202)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7160 | Time 20.8789(19.6091) | Bit/dim 3.6414(3.6292) | Xent 0.4937(0.4816) | Loss 548.1989(600.1117) | Error 0.1711(0.1710) Steps 0(0.00) | Grad Norm 428.4014(357.6316) | Total Time 0.00(0.00)\n",
      "Iter 7170 | Time 19.8723(19.6799) | Bit/dim 3.6497(3.6273) | Xent 0.4598(0.4760) | Loss 521.8768(579.7675) | Error 0.1600(0.1692) Steps 0(0.00) | Grad Norm 450.8910(349.1163) | Total Time 0.00(0.00)\n",
      "Iter 7180 | Time 18.9670(19.6505) | Bit/dim 3.6315(3.6274) | Xent 0.4798(0.4743) | Loss 526.5657(565.1017) | Error 0.1856(0.1695) Steps 0(0.00) | Grad Norm 393.2882(357.6062) | Total Time 0.00(0.00)\n",
      "Iter 7190 | Time 20.7563(19.6876) | Bit/dim 3.6466(3.6271) | Xent 0.4978(0.4746) | Loss 506.7193(553.0337) | Error 0.1811(0.1689) Steps 0(0.00) | Grad Norm 386.4057(362.1777) | Total Time 0.00(0.00)\n",
      "Iter 7200 | Time 19.9241(19.6521) | Bit/dim 3.6359(3.6234) | Xent 0.5216(0.4786) | Loss 533.5808(545.4199) | Error 0.1822(0.1698) Steps 0(0.00) | Grad Norm 345.2512(362.2241) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 96.2504, Epoch Time 1190.6259(1133.7017), Bit/dim 3.6269(best: 3.6249), Xent 0.6957, Loss 3.9748, Error 0.2360(best: 0.2202)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7210 | Time 20.6145(19.5508) | Bit/dim 3.6412(3.6252) | Xent 0.4363(0.4747) | Loss 522.6331(604.7781) | Error 0.1444(0.1685) Steps 0(0.00) | Grad Norm 380.7730(350.8227) | Total Time 0.00(0.00)\n",
      "Iter 7220 | Time 20.9240(19.6674) | Bit/dim 3.6070(3.6231) | Xent 0.5303(0.4738) | Loss 530.7259(583.1491) | Error 0.1833(0.1685) Steps 0(0.00) | Grad Norm 531.2290(376.5789) | Total Time 0.00(0.00)\n",
      "Iter 7230 | Time 19.1710(19.7363) | Bit/dim 3.6286(3.6239) | Xent 0.4730(0.4672) | Loss 507.3983(566.0496) | Error 0.1589(0.1656) Steps 0(0.00) | Grad Norm 391.6317(368.1807) | Total Time 0.00(0.00)\n",
      "Iter 7240 | Time 20.3787(19.7715) | Bit/dim 3.5903(3.6234) | Xent 0.4874(0.4653) | Loss 513.8799(552.4668) | Error 0.1700(0.1654) Steps 0(0.00) | Grad Norm 438.3616(360.2959) | Total Time 0.00(0.00)\n",
      "Iter 7250 | Time 21.2527(19.7631) | Bit/dim 3.6476(3.6246) | Xent 0.4674(0.4686) | Loss 526.2886(545.1636) | Error 0.1600(0.1672) Steps 0(0.00) | Grad Norm 258.6360(365.3626) | Total Time 0.00(0.00)\n",
      "Iter 7260 | Time 20.1546(19.8530) | Bit/dim 3.6182(3.6229) | Xent 0.4641(0.4713) | Loss 529.1730(538.6000) | Error 0.1722(0.1682) Steps 0(0.00) | Grad Norm 392.0631(351.7117) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 97.9509, Epoch Time 1209.4350(1135.9737), Bit/dim 3.6284(best: 3.6249), Xent 0.6643, Loss 3.9606, Error 0.2198(best: 0.2202)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7270 | Time 19.3825(19.7658) | Bit/dim 3.6356(3.6224) | Xent 0.4218(0.4680) | Loss 520.4420(592.7882) | Error 0.1589(0.1671) Steps 0(0.00) | Grad Norm 301.2033(349.5667) | Total Time 0.00(0.00)\n",
      "Iter 7280 | Time 19.8267(19.8502) | Bit/dim 3.6231(3.6224) | Xent 0.4432(0.4644) | Loss 526.6343(574.1238) | Error 0.1478(0.1664) Steps 0(0.00) | Grad Norm 159.5038(329.5186) | Total Time 0.00(0.00)\n",
      "Iter 7290 | Time 19.6430(19.6925) | Bit/dim 3.6136(3.6225) | Xent 0.4936(0.4629) | Loss 502.5951(558.5054) | Error 0.1711(0.1653) Steps 0(0.00) | Grad Norm 522.3790(336.5682) | Total Time 0.00(0.00)\n",
      "Iter 7300 | Time 18.5152(19.8010) | Bit/dim 3.6093(3.6232) | Xent 0.4882(0.4735) | Loss 505.7425(549.9442) | Error 0.1767(0.1691) Steps 0(0.00) | Grad Norm 361.1544(379.8589) | Total Time 0.00(0.00)\n",
      "Iter 7310 | Time 20.9067(19.8315) | Bit/dim 3.6143(3.6218) | Xent 0.5994(0.4782) | Loss 527.7769(542.7290) | Error 0.2100(0.1709) Steps 0(0.00) | Grad Norm 582.0438(388.7097) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 97.2035, Epoch Time 1202.3333(1137.9645), Bit/dim 3.6273(best: 3.6249), Xent 0.6658, Loss 3.9602, Error 0.2256(best: 0.2198)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7320 | Time 18.7125(19.7296) | Bit/dim 3.6412(3.6230) | Xent 0.3886(0.4699) | Loss 504.0033(602.4030) | Error 0.1289(0.1674) Steps 0(0.00) | Grad Norm 452.6240(379.8316) | Total Time 0.00(0.00)\n",
      "Iter 7330 | Time 18.7302(19.7847) | Bit/dim 3.6513(3.6227) | Xent 0.4387(0.4648) | Loss 513.1988(580.9722) | Error 0.1522(0.1665) Steps 0(0.00) | Grad Norm 261.1792(362.2405) | Total Time 0.00(0.00)\n",
      "Iter 7340 | Time 20.2591(19.8455) | Bit/dim 3.6198(3.6207) | Xent 0.4675(0.4629) | Loss 517.6983(563.9957) | Error 0.1722(0.1660) Steps 0(0.00) | Grad Norm 474.2109(362.4279) | Total Time 0.00(0.00)\n",
      "Iter 7350 | Time 18.6338(19.7155) | Bit/dim 3.5930(3.6211) | Xent 0.4561(0.4647) | Loss 509.9813(552.3734) | Error 0.1633(0.1666) Steps 0(0.00) | Grad Norm 314.6676(383.5028) | Total Time 0.00(0.00)\n",
      "Iter 7360 | Time 20.0986(19.6649) | Bit/dim 3.6691(3.6246) | Xent 0.5171(0.4651) | Loss 524.4303(544.7796) | Error 0.1844(0.1666) Steps 0(0.00) | Grad Norm 343.8478(369.0034) | Total Time 0.00(0.00)\n",
      "Iter 7370 | Time 19.7595(19.6422) | Bit/dim 3.6525(3.6252) | Xent 0.4314(0.4661) | Loss 510.3100(538.9974) | Error 0.1589(0.1667) Steps 0(0.00) | Grad Norm 290.9472(364.1425) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 98.1910, Epoch Time 1195.7463(1139.6980), Bit/dim 3.6193(best: 3.6249), Xent 0.6626, Loss 3.9505, Error 0.2225(best: 0.2198)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7380 | Time 20.4746(19.9494) | Bit/dim 3.6110(3.6241) | Xent 0.4024(0.4559) | Loss 520.6474(599.7782) | Error 0.1456(0.1626) Steps 0(0.00) | Grad Norm 558.3665(372.3391) | Total Time 0.00(0.00)\n",
      "Iter 7390 | Time 20.6768(19.8941) | Bit/dim 3.6251(3.6234) | Xent 0.4974(0.4570) | Loss 530.5740(579.2527) | Error 0.1844(0.1627) Steps 0(0.00) | Grad Norm 541.2515(370.3285) | Total Time 0.00(0.00)\n",
      "Iter 7400 | Time 21.1711(19.9546) | Bit/dim 3.6248(3.6242) | Xent 0.4782(0.4704) | Loss 510.3767(566.0822) | Error 0.1767(0.1672) Steps 0(0.00) | Grad Norm 263.0261(404.8509) | Total Time 0.00(0.00)\n",
      "Iter 7410 | Time 20.3105(19.8384) | Bit/dim 3.6229(3.6254) | Xent 0.4644(0.4767) | Loss 526.2883(553.0832) | Error 0.1544(0.1688) Steps 0(0.00) | Grad Norm 369.1328(391.5269) | Total Time 0.00(0.00)\n",
      "Iter 7420 | Time 19.0693(19.9028) | Bit/dim 3.6357(3.6281) | Xent 0.4445(0.4795) | Loss 515.3862(545.6867) | Error 0.1567(0.1700) Steps 0(0.00) | Grad Norm 292.5868(418.2474) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 99.5849, Epoch Time 1215.6783(1141.9774), Bit/dim 3.6265(best: 3.6193), Xent 0.6593, Loss 3.9562, Error 0.2213(best: 0.2198)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7430 | Time 21.4808(19.8993) | Bit/dim 3.6004(3.6261) | Xent 0.4196(0.4655) | Loss 519.5372(608.1366) | Error 0.1444(0.1650) Steps 0(0.00) | Grad Norm 336.2565(380.2711) | Total Time 0.00(0.00)\n",
      "Iter 7440 | Time 19.1851(19.7247) | Bit/dim 3.6363(3.6238) | Xent 0.4499(0.4566) | Loss 523.0342(583.4005) | Error 0.1500(0.1613) Steps 0(0.00) | Grad Norm 344.7201(356.8483) | Total Time 0.00(0.00)\n",
      "Iter 7450 | Time 18.1482(19.6596) | Bit/dim 3.6404(3.6274) | Xent 0.4399(0.4514) | Loss 504.1461(567.3352) | Error 0.1633(0.1599) Steps 0(0.00) | Grad Norm 198.3167(341.4042) | Total Time 0.00(0.00)\n",
      "Iter 7460 | Time 19.1911(19.6791) | Bit/dim 3.5840(3.6252) | Xent 0.4653(0.4547) | Loss 526.4081(555.9936) | Error 0.1622(0.1605) Steps 0(0.00) | Grad Norm 378.6602(355.1416) | Total Time 0.00(0.00)\n",
      "Iter 7470 | Time 19.5530(19.5501) | Bit/dim 3.6277(3.6226) | Xent 0.4227(0.4548) | Loss 528.9276(545.9155) | Error 0.1467(0.1618) Steps 0(0.00) | Grad Norm 423.8334(355.2527) | Total Time 0.00(0.00)\n",
      "Iter 7480 | Time 20.7484(19.7306) | Bit/dim 3.6072(3.6240) | Xent 0.4834(0.4571) | Loss 531.6627(539.6787) | Error 0.1611(0.1621) Steps 0(0.00) | Grad Norm 313.6766(362.8126) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 96.5804, Epoch Time 1195.3664(1143.5791), Bit/dim 3.6274(best: 3.6193), Xent 0.6651, Loss 3.9600, Error 0.2182(best: 0.2198)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7490 | Time 18.6691(19.7297) | Bit/dim 3.6419(3.6238) | Xent 0.4254(0.4512) | Loss 513.1652(595.3813) | Error 0.1544(0.1601) Steps 0(0.00) | Grad Norm 335.0871(362.4770) | Total Time 0.00(0.00)\n",
      "Iter 7500 | Time 19.8127(19.6723) | Bit/dim 3.5858(3.6217) | Xent 0.4229(0.4498) | Loss 506.4889(577.1263) | Error 0.1456(0.1600) Steps 0(0.00) | Grad Norm 286.9203(377.8003) | Total Time 0.00(0.00)\n",
      "Iter 7510 | Time 21.3308(19.9055) | Bit/dim 3.6227(3.6198) | Xent 0.4438(0.4454) | Loss 533.4566(562.0604) | Error 0.1500(0.1583) Steps 0(0.00) | Grad Norm 370.6523(376.5646) | Total Time 0.00(0.00)\n",
      "Iter 7520 | Time 20.8100(20.1237) | Bit/dim 3.6648(3.6220) | Xent 0.4710(0.4491) | Loss 533.2163(554.1204) | Error 0.1711(0.1595) Steps 0(0.00) | Grad Norm 624.2975(419.4390) | Total Time 0.00(0.00)\n",
      "Iter 7530 | Time 19.0677(20.1473) | Bit/dim 3.6205(3.6230) | Xent 0.4415(0.4497) | Loss 532.6564(547.5803) | Error 0.1522(0.1589) Steps 0(0.00) | Grad Norm 355.3307(411.2338) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 97.6354, Epoch Time 1222.8646(1145.9576), Bit/dim 3.6271(best: 3.6193), Xent 0.6865, Loss 3.9704, Error 0.2236(best: 0.2182)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7540 | Time 21.6642(20.1129) | Bit/dim 3.6150(3.6215) | Xent 0.4029(0.4456) | Loss 530.2915(614.4211) | Error 0.1300(0.1570) Steps 0(0.00) | Grad Norm 304.4924(377.1302) | Total Time 0.00(0.00)\n",
      "Iter 7550 | Time 19.4955(20.0761) | Bit/dim 3.5615(3.6195) | Xent 0.4348(0.4450) | Loss 508.6365(590.9028) | Error 0.1689(0.1576) Steps 0(0.00) | Grad Norm 406.2041(376.3978) | Total Time 0.00(0.00)\n",
      "Iter 7560 | Time 18.3249(19.9970) | Bit/dim 3.5951(3.6185) | Xent 0.3788(0.4385) | Loss 492.9344(572.5842) | Error 0.1422(0.1564) Steps 0(0.00) | Grad Norm 291.7238(369.7891) | Total Time 0.00(0.00)\n",
      "Iter 7570 | Time 20.0082(19.9684) | Bit/dim 3.6235(3.6188) | Xent 0.4572(0.4415) | Loss 538.6575(559.0395) | Error 0.1722(0.1573) Steps 0(0.00) | Grad Norm 477.9198(379.7594) | Total Time 0.00(0.00)\n",
      "Iter 7580 | Time 19.5676(20.1056) | Bit/dim 3.6182(3.6194) | Xent 0.4671(0.4417) | Loss 518.7293(549.3511) | Error 0.1589(0.1569) Steps 0(0.00) | Grad Norm 348.0557(373.0018) | Total Time 0.00(0.00)\n",
      "Iter 7590 | Time 20.0974(20.0607) | Bit/dim 3.6374(3.6191) | Xent 0.4387(0.4398) | Loss 541.5967(544.4629) | Error 0.1533(0.1568) Steps 0(0.00) | Grad Norm 241.1978(360.2493) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 99.5004, Epoch Time 1217.0500(1148.0904), Bit/dim 3.6197(best: 3.6193), Xent 0.6792, Loss 3.9593, Error 0.2232(best: 0.2182)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7600 | Time 19.4965(19.8734) | Bit/dim 3.5974(3.6162) | Xent 0.3993(0.4313) | Loss 501.7245(600.4694) | Error 0.1478(0.1552) Steps 0(0.00) | Grad Norm 230.0566(338.5057) | Total Time 0.00(0.00)\n",
      "Iter 7610 | Time 19.5049(19.9616) | Bit/dim 3.6099(3.6162) | Xent 0.4565(0.4308) | Loss 509.2521(578.7484) | Error 0.1678(0.1554) Steps 0(0.00) | Grad Norm 312.7523(343.7088) | Total Time 0.00(0.00)\n",
      "Iter 7620 | Time 19.1950(19.9007) | Bit/dim 3.6321(3.6189) | Xent 0.4645(0.4337) | Loss 528.6469(565.4091) | Error 0.1533(0.1543) Steps 0(0.00) | Grad Norm 389.0723(373.4204) | Total Time 0.00(0.00)\n",
      "Iter 7630 | Time 21.3518(19.8937) | Bit/dim 3.5906(3.6170) | Xent 0.4336(0.4381) | Loss 500.8652(554.4760) | Error 0.1544(0.1556) Steps 0(0.00) | Grad Norm 335.9376(385.9613) | Total Time 0.00(0.00)\n",
      "Iter 7640 | Time 19.9033(19.9729) | Bit/dim 3.6509(3.6174) | Xent 0.4336(0.4417) | Loss 535.7703(547.7581) | Error 0.1533(0.1576) Steps 0(0.00) | Grad Norm 280.3271(376.6593) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 95.9923, Epoch Time 1204.6255(1149.7864), Bit/dim 3.6244(best: 3.6193), Xent 0.6674, Loss 3.9581, Error 0.2239(best: 0.2182)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7650 | Time 19.3578(19.9273) | Bit/dim 3.6184(3.6186) | Xent 0.5000(0.4370) | Loss 518.9275(611.7078) | Error 0.1789(0.1559) Steps 0(0.00) | Grad Norm 447.3429(377.3809) | Total Time 0.00(0.00)\n",
      "Iter 7660 | Time 20.3528(19.9171) | Bit/dim 3.6286(3.6198) | Xent 0.4744(0.4411) | Loss 506.1231(587.1416) | Error 0.1756(0.1577) Steps 0(0.00) | Grad Norm 481.2847(387.6323) | Total Time 0.00(0.00)\n",
      "Iter 7670 | Time 19.2404(19.9973) | Bit/dim 3.6128(3.6208) | Xent 0.4335(0.4397) | Loss 524.6451(570.5947) | Error 0.1533(0.1569) Steps 0(0.00) | Grad Norm 210.0049(385.1723) | Total Time 0.00(0.00)\n",
      "Iter 7680 | Time 20.9852(20.0613) | Bit/dim 3.6736(3.6243) | Xent 0.4729(0.4457) | Loss 530.2751(558.2687) | Error 0.1744(0.1593) Steps 0(0.00) | Grad Norm 566.9114(392.2917) | Total Time 0.00(0.00)\n",
      "Iter 7690 | Time 20.6856(20.0425) | Bit/dim 3.6107(3.6198) | Xent 0.5041(0.4569) | Loss 498.9195(547.8962) | Error 0.1700(0.1625) Steps 0(0.00) | Grad Norm 300.2379(390.2536) | Total Time 0.00(0.00)\n",
      "Iter 7700 | Time 19.6238(20.0601) | Bit/dim 3.5959(3.6180) | Xent 0.4035(0.4551) | Loss 522.3224(541.4433) | Error 0.1478(0.1624) Steps 0(0.00) | Grad Norm 304.7276(377.7599) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 97.7729, Epoch Time 1222.0502(1151.9544), Bit/dim 3.6214(best: 3.6193), Xent 0.6840, Loss 3.9635, Error 0.2202(best: 0.2182)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7710 | Time 20.0841(20.1563) | Bit/dim 3.6081(3.6211) | Xent 0.4270(0.4465) | Loss 520.0588(599.5411) | Error 0.1556(0.1596) Steps 0(0.00) | Grad Norm 370.2575(376.6169) | Total Time 0.00(0.00)\n",
      "Iter 7720 | Time 19.4082(20.0863) | Bit/dim 3.6626(3.6201) | Xent 0.4026(0.4369) | Loss 527.3707(577.8879) | Error 0.1489(0.1563) Steps 0(0.00) | Grad Norm 399.6594(361.3787) | Total Time 0.00(0.00)\n",
      "Iter 7730 | Time 20.6023(20.1091) | Bit/dim 3.6106(3.6216) | Xent 0.4625(0.4395) | Loss 533.3440(563.7310) | Error 0.1656(0.1565) Steps 0(0.00) | Grad Norm 388.5610(382.0888) | Total Time 0.00(0.00)\n",
      "Iter 7740 | Time 19.2990(20.2406) | Bit/dim 3.6369(3.6222) | Xent 0.4289(0.4388) | Loss 510.7611(553.4035) | Error 0.1500(0.1563) Steps 0(0.00) | Grad Norm 344.3392(379.0359) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_rlw_1_0_run1 --seed 1 --lr 0.001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5 --scale_fac 1.0 --scale_std 6.0 --rl-weight 1.0\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
