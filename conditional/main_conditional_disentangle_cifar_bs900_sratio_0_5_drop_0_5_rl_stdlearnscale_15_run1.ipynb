{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, eta=0.1, gamma=0.99, gate='cnn2', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume=None, rl_weight=0.01, rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdlearnscale_15_run1', scale=1.0, scale_fac=1.0, scale_std=15.0, seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateII(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1450886\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 0010 | Time 12.2758(29.0690) | Bit/dim 8.6489(8.8177) | Xent 2.2786(2.2999) | Loss 20.4672(20.6656) | Error 0.7767(0.8622) Steps 0(0.00) | Grad Norm 21.3721(26.5013) | Total Time 0.00(0.00)\n",
      "Iter 0020 | Time 11.9711(24.6377) | Bit/dim 8.5927(8.7621) | Xent 2.2223(2.2871) | Loss 20.2958(20.5277) | Error 0.7444(0.8384) Steps 0(0.00) | Grad Norm 7.9353(23.0027) | Total Time 0.00(0.00)\n",
      "Iter 0030 | Time 12.6341(21.4790) | Bit/dim 8.3554(8.6671) | Xent 2.1901(2.2637) | Loss 20.0861(20.3243) | Error 0.7633(0.8163) Steps 0(0.00) | Grad Norm 9.1276(18.8562) | Total Time 0.00(0.00)\n",
      "Iter 0040 | Time 11.8081(19.0173) | Bit/dim 8.1425(8.5559) | Xent 2.1532(2.2355) | Loss 19.2385(20.0859) | Error 0.7544(0.7964) Steps 0(0.00) | Grad Norm 5.5218(15.6767) | Total Time 0.00(0.00)\n",
      "Iter 0050 | Time 12.1586(17.3004) | Bit/dim 7.9161(8.4239) | Xent 2.0934(2.2032) | Loss 18.5572(19.7978) | Error 0.7211(0.7772) Steps 0(0.00) | Grad Norm 5.7144(13.0679) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 74.9800, Epoch Time 798.0035(798.0035), Bit/dim 7.7768(best: inf), Xent 2.0748, Loss 8.8142, Error 0.7012(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0060 | Time 11.8007(16.0361) | Bit/dim 7.6593(8.2545) | Xent 2.0657(2.1708) | Loss 17.9767(19.9405) | Error 0.6933(0.7582) Steps 0(0.00) | Grad Norm 4.8434(10.9800) | Total Time 0.00(0.00)\n",
      "Iter 0070 | Time 12.9280(15.1168) | Bit/dim 7.3841(8.0589) | Xent 2.0806(2.1433) | Loss 17.8008(19.4096) | Error 0.7111(0.7423) Steps 0(0.00) | Grad Norm 4.0599(9.2896) | Total Time 0.00(0.00)\n",
      "Iter 0080 | Time 12.9834(14.4364) | Bit/dim 7.1907(7.8531) | Xent 2.0698(2.1233) | Loss 17.3441(18.8787) | Error 0.7211(0.7305) Steps 0(0.00) | Grad Norm 3.3166(7.8840) | Total Time 0.00(0.00)\n",
      "Iter 0090 | Time 12.4678(14.0124) | Bit/dim 7.0802(7.6620) | Xent 2.0673(2.1099) | Loss 17.1698(18.4085) | Error 0.7233(0.7220) Steps 0(0.00) | Grad Norm 3.6619(6.6084) | Total Time 0.00(0.00)\n",
      "Iter 0100 | Time 13.6031(13.7319) | Bit/dim 7.0471(7.5004) | Xent 2.0972(2.1030) | Loss 17.2035(18.0350) | Error 0.7200(0.7184) Steps 0(0.00) | Grad Norm 1.7844(5.5643) | Total Time 0.00(0.00)\n",
      "Iter 0110 | Time 13.2784(13.5122) | Bit/dim 6.9942(7.3694) | Xent 2.0362(2.0942) | Loss 17.1031(17.7401) | Error 0.6822(0.7135) Steps 0(0.00) | Grad Norm 1.8251(4.7118) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 75.7192, Epoch Time 793.4355(797.8665), Bit/dim 6.9835(best: 7.7768), Xent 2.0612, Loss 8.0141, Error 0.6906(best: 0.7012)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0120 | Time 12.9725(13.3033) | Bit/dim 6.9524(7.2623) | Xent 2.0385(2.0856) | Loss 16.6629(18.0077) | Error 0.6878(0.7112) Steps 0(0.00) | Grad Norm 3.5307(4.2004) | Total Time 0.00(0.00)\n",
      "Iter 0130 | Time 14.2982(13.2651) | Bit/dim 6.8991(7.1745) | Xent 2.0669(2.0755) | Loss 16.8214(17.6652) | Error 0.7089(0.7071) Steps 0(0.00) | Grad Norm 3.2866(4.0692) | Total Time 0.00(0.00)\n",
      "Iter 0140 | Time 13.0694(13.1822) | Bit/dim 6.8296(7.0956) | Xent 2.0326(2.0654) | Loss 16.4823(17.3779) | Error 0.7033(0.7035) Steps 0(0.00) | Grad Norm 5.0902(3.8144) | Total Time 0.00(0.00)\n",
      "Iter 0150 | Time 12.7705(13.1081) | Bit/dim 6.7747(7.0217) | Xent 2.0297(2.0556) | Loss 16.1820(17.1156) | Error 0.6800(0.6977) Steps 0(0.00) | Grad Norm 6.1629(4.6489) | Total Time 0.00(0.00)\n",
      "Iter 0160 | Time 14.1180(13.2085) | Bit/dim 6.6628(6.9417) | Xent 2.0229(2.0469) | Loss 16.3453(16.9126) | Error 0.6978(0.6964) Steps 0(0.00) | Grad Norm 16.9228(6.2373) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 78.8324, Epoch Time 817.1727(798.4457), Bit/dim 6.6170(best: 6.9835), Xent 2.1391, Loss 7.6865, Error 0.7759(best: 0.6906)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0170 | Time 13.9487(13.4012) | Bit/dim 6.5715(6.8538) | Xent 2.0917(2.0517) | Loss 16.2857(17.3162) | Error 0.7556(0.7033) Steps 0(0.00) | Grad Norm 65.0636(15.3155) | Total Time 0.00(0.00)\n",
      "Iter 0180 | Time 13.1230(13.5178) | Bit/dim 6.3465(6.7483) | Xent 2.0245(2.0420) | Loss 15.4605(16.9121) | Error 0.7011(0.6995) Steps 0(0.00) | Grad Norm 14.1192(18.5799) | Total Time 0.00(0.00)\n",
      "Iter 0190 | Time 13.9573(13.6786) | Bit/dim 6.1785(6.6220) | Xent 2.0061(2.0322) | Loss 15.2389(16.5312) | Error 0.7000(0.6971) Steps 0(0.00) | Grad Norm 49.1541(22.1590) | Total Time 0.00(0.00)\n",
      "Iter 0200 | Time 14.7728(13.8458) | Bit/dim 6.0127(6.4821) | Xent 2.0299(2.0441) | Loss 14.9218(16.1698) | Error 0.6956(0.7048) Steps 0(0.00) | Grad Norm 61.9632(35.9405) | Total Time 0.00(0.00)\n",
      "Iter 0210 | Time 14.0454(14.0240) | Bit/dim 5.8830(6.3389) | Xent 2.0138(2.0484) | Loss 14.7308(15.7973) | Error 0.6622(0.7112) Steps 0(0.00) | Grad Norm 44.2494(43.2083) | Total Time 0.00(0.00)\n",
      "Iter 0220 | Time 14.6094(14.0952) | Bit/dim 5.7781(6.2074) | Xent 2.0127(2.0424) | Loss 14.6291(15.4734) | Error 0.6956(0.7075) Steps 0(0.00) | Grad Norm 40.0265(43.8950) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 77.5380, Epoch Time 877.7235(800.8240), Bit/dim 5.7871(best: 6.6170), Xent 1.9881, Loss 6.7812, Error 0.6453(best: 0.6906)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0230 | Time 13.9050(14.1815) | Bit/dim 5.7490(6.0906) | Xent 1.9859(2.0303) | Loss 14.2528(15.6697) | Error 0.7011(0.6993) Steps 0(0.00) | Grad Norm 58.9170(41.9143) | Total Time 0.00(0.00)\n",
      "Iter 0240 | Time 16.7242(14.2393) | Bit/dim 5.6568(5.9884) | Xent 1.9286(2.0161) | Loss 14.2863(15.2684) | Error 0.6544(0.6911) Steps 0(0.00) | Grad Norm 34.5872(40.1048) | Total Time 0.00(0.00)\n",
      "Iter 0250 | Time 13.2055(14.0595) | Bit/dim 5.6707(5.9006) | Xent 1.9998(2.0059) | Loss 14.0951(14.9734) | Error 0.7011(0.6874) Steps 0(0.00) | Grad Norm 41.6457(37.3319) | Total Time 0.00(0.00)\n",
      "Iter 0260 | Time 13.8036(13.9918) | Bit/dim 5.6657(5.8381) | Xent 2.0248(2.0145) | Loss 14.1651(14.7933) | Error 0.7167(0.6950) Steps 0(0.00) | Grad Norm 50.0755(44.7528) | Total Time 0.00(0.00)\n",
      "Iter 0270 | Time 12.6470(13.8417) | Bit/dim 5.6431(5.7834) | Xent 2.0267(2.0144) | Loss 13.6442(14.6221) | Error 0.7189(0.7001) Steps 0(0.00) | Grad Norm 54.2914(43.4715) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 79.9432, Epoch Time 860.6587(802.6191), Bit/dim 5.6073(best: 5.7871), Xent 1.9864, Loss 6.6005, Error 0.7069(best: 0.6453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0280 | Time 14.9010(13.7738) | Bit/dim 5.5983(5.7382) | Xent 1.9997(2.0135) | Loss 14.2051(15.0230) | Error 0.6989(0.6985) Steps 0(0.00) | Grad Norm 13.9576(43.5852) | Total Time 0.00(0.00)\n",
      "Iter 0290 | Time 13.7197(13.7039) | Bit/dim 5.6124(5.6990) | Xent 1.9407(2.0062) | Loss 14.1462(14.7622) | Error 0.6456(0.6930) Steps 0(0.00) | Grad Norm 11.0148(42.4769) | Total Time 0.00(0.00)\n",
      "Iter 0300 | Time 13.5002(13.7076) | Bit/dim 5.5938(5.6575) | Xent 1.9276(1.9900) | Loss 13.9350(14.5427) | Error 0.6689(0.6839) Steps 0(0.00) | Grad Norm 29.4248(34.9625) | Total Time 0.00(0.00)\n",
      "Iter 0310 | Time 13.9867(13.6924) | Bit/dim 5.5303(5.6222) | Xent 1.9410(1.9775) | Loss 13.4795(14.3664) | Error 0.6289(0.6786) Steps 0(0.00) | Grad Norm 29.9554(35.5172) | Total Time 0.00(0.00)\n",
      "Iter 0320 | Time 13.7412(13.7751) | Bit/dim 5.4698(5.5949) | Xent 1.9850(1.9752) | Loss 13.7155(14.2251) | Error 0.7000(0.6804) Steps 0(0.00) | Grad Norm 42.0009(38.9890) | Total Time 0.00(0.00)\n",
      "Iter 0330 | Time 14.1747(13.8466) | Bit/dim 5.4842(5.5671) | Xent 1.9940(1.9818) | Loss 13.8789(14.1248) | Error 0.6989(0.6871) Steps 0(0.00) | Grad Norm 31.4163(40.6260) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 78.8895, Epoch Time 855.0718(804.1926), Bit/dim 5.4845(best: 5.6073), Xent 1.9789, Loss 6.4739, Error 0.6937(best: 0.6453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0340 | Time 13.8474(13.9335) | Bit/dim 5.4013(5.5377) | Xent 1.9351(1.9797) | Loss 13.6892(14.5430) | Error 0.6444(0.6865) Steps 0(0.00) | Grad Norm 9.2136(34.5797) | Total Time 0.00(0.00)\n",
      "Iter 0350 | Time 13.5822(13.9325) | Bit/dim 5.4309(5.5072) | Xent 1.9913(1.9714) | Loss 13.8049(14.3265) | Error 0.7278(0.6832) Steps 0(0.00) | Grad Norm 105.0787(35.9969) | Total Time 0.00(0.00)\n",
      "Iter 0360 | Time 13.8791(13.9151) | Bit/dim 5.3932(5.4758) | Xent 1.9056(1.9617) | Loss 13.4268(14.1193) | Error 0.6500(0.6780) Steps 0(0.00) | Grad Norm 37.5004(35.9386) | Total Time 0.00(0.00)\n",
      "Iter 0370 | Time 14.1689(13.9664) | Bit/dim 5.2983(5.4422) | Xent 1.9511(1.9529) | Loss 13.2906(13.9504) | Error 0.6889(0.6755) Steps 0(0.00) | Grad Norm 27.6316(32.8570) | Total Time 0.00(0.00)\n",
      "Iter 0380 | Time 13.8010(13.9879) | Bit/dim 5.2930(5.4070) | Xent 1.9645(1.9480) | Loss 13.2245(13.8126) | Error 0.6967(0.6741) Steps 0(0.00) | Grad Norm 34.1935(34.0638) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 81.0516, Epoch Time 873.9673(806.2859), Bit/dim 5.2478(best: 5.4845), Xent 1.9060, Loss 6.2008, Error 0.6396(best: 0.6453)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0390 | Time 15.1002(14.1291) | Bit/dim 5.2513(5.3632) | Xent 1.9397(1.9458) | Loss 13.4464(14.2521) | Error 0.6600(0.6750) Steps 0(0.00) | Grad Norm 26.1519(31.0232) | Total Time 0.00(0.00)\n",
      "Iter 0400 | Time 14.8187(14.2159) | Bit/dim 5.2345(5.3299) | Xent 1.9015(1.9385) | Loss 13.4813(14.0013) | Error 0.6556(0.6720) Steps 0(0.00) | Grad Norm 25.4907(28.8994) | Total Time 0.00(0.00)\n",
      "Iter 0410 | Time 14.6298(14.3372) | Bit/dim 5.1389(5.2951) | Xent 1.8913(1.9250) | Loss 12.8697(13.7993) | Error 0.6678(0.6695) Steps 0(0.00) | Grad Norm 26.8781(28.1951) | Total Time 0.00(0.00)\n",
      "Iter 0420 | Time 14.2101(14.3634) | Bit/dim 5.0979(5.2553) | Xent 1.9137(1.9174) | Loss 13.1453(13.6249) | Error 0.6567(0.6666) Steps 0(0.00) | Grad Norm 22.5715(25.9141) | Total Time 0.00(0.00)\n",
      "Iter 0430 | Time 14.7445(14.3652) | Bit/dim 5.1289(5.2285) | Xent 1.9730(1.9158) | Loss 13.2369(13.4806) | Error 0.7189(0.6670) Steps 0(0.00) | Grad Norm 52.9007(27.9081) | Total Time 0.00(0.00)\n",
      "Iter 0440 | Time 14.2159(14.4019) | Bit/dim 5.1111(5.1970) | Xent 1.9663(1.9231) | Loss 12.9984(13.3713) | Error 0.6922(0.6704) Steps 0(0.00) | Grad Norm 35.6278(30.3142) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 80.8227, Epoch Time 896.0718(808.9795), Bit/dim 5.0823(best: 5.2478), Xent 1.8592, Loss 6.0119, Error 0.6324(best: 0.6396)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0450 | Time 14.1195(14.3660) | Bit/dim 5.0674(5.1636) | Xent 1.9018(1.9092) | Loss 12.6575(13.7811) | Error 0.6522(0.6628) Steps 0(0.00) | Grad Norm 20.9781(27.1845) | Total Time 0.00(0.00)\n",
      "Iter 0460 | Time 15.9627(14.5788) | Bit/dim 5.0264(5.1312) | Xent 1.8834(1.8993) | Loss 13.0145(13.5635) | Error 0.6489(0.6583) Steps 0(0.00) | Grad Norm 41.6205(27.3108) | Total Time 0.00(0.00)\n",
      "Iter 0470 | Time 14.2289(14.6521) | Bit/dim 5.0011(5.1041) | Xent 1.8571(1.8987) | Loss 12.6205(13.3915) | Error 0.6478(0.6592) Steps 0(0.00) | Grad Norm 17.2393(28.4813) | Total Time 0.00(0.00)\n",
      "Iter 0480 | Time 16.9356(14.7013) | Bit/dim 4.9586(5.0751) | Xent 1.8703(1.8893) | Loss 12.8563(13.2278) | Error 0.6433(0.6572) Steps 0(0.00) | Grad Norm 22.0293(26.2941) | Total Time 0.00(0.00)\n",
      "Iter 0490 | Time 14.4212(14.8048) | Bit/dim 4.9580(5.0426) | Xent 1.8540(1.8816) | Loss 12.8430(13.1004) | Error 0.6511(0.6562) Steps 0(0.00) | Grad Norm 31.6114(25.4134) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 83.7299, Epoch Time 916.1654(812.1950), Bit/dim 4.9215(best: 5.0823), Xent 1.8584, Loss 5.8507, Error 0.6480(best: 0.6324)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0500 | Time 14.5219(14.7548) | Bit/dim 4.8699(5.0075) | Xent 1.8650(1.8772) | Loss 12.3942(13.5147) | Error 0.6667(0.6568) Steps 0(0.00) | Grad Norm 57.3255(28.0328) | Total Time 0.00(0.00)\n",
      "Iter 0510 | Time 14.6985(14.7551) | Bit/dim 4.9252(4.9966) | Xent 1.8814(1.9044) | Loss 12.8101(13.3392) | Error 0.6589(0.6680) Steps 0(0.00) | Grad Norm 20.7011(33.1882) | Total Time 0.00(0.00)\n",
      "Iter 0520 | Time 15.6447(14.9096) | Bit/dim 4.8246(4.9664) | Xent 1.8706(1.9043) | Loss 12.6719(13.1635) | Error 0.6789(0.6701) Steps 0(0.00) | Grad Norm 19.3614(29.2515) | Total Time 0.00(0.00)\n",
      "Iter 0530 | Time 14.3346(15.2051) | Bit/dim 4.8506(4.9377) | Xent 1.8440(1.8945) | Loss 12.2485(13.0126) | Error 0.6578(0.6661) Steps 0(0.00) | Grad Norm 7.4927(26.8340) | Total Time 0.00(0.00)\n",
      "Iter 0540 | Time 17.2065(15.2385) | Bit/dim 4.8402(4.9139) | Xent 1.8473(1.8829) | Loss 12.6185(12.8721) | Error 0.6533(0.6634) Steps 0(0.00) | Grad Norm 41.0205(28.1489) | Total Time 0.00(0.00)\n",
      "Iter 0550 | Time 15.0599(15.2657) | Bit/dim 4.8349(4.8944) | Xent 1.9069(1.8733) | Loss 12.5500(12.7679) | Error 0.6756(0.6581) Steps 0(0.00) | Grad Norm 47.7274(30.2776) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 82.9996, Epoch Time 943.2605(816.1270), Bit/dim 4.7860(best: 4.9215), Xent 1.7646, Loss 5.6683, Error 0.6032(best: 0.6324)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0560 | Time 16.4521(15.2968) | Bit/dim 4.7958(4.8644) | Xent 1.7879(1.8571) | Loss 12.2736(13.1893) | Error 0.6278(0.6536) Steps 0(0.00) | Grad Norm 17.9427(27.9409) | Total Time 0.00(0.00)\n",
      "Iter 0570 | Time 14.1408(15.3455) | Bit/dim 4.8048(4.8393) | Xent 1.8681(1.8419) | Loss 12.3230(12.9413) | Error 0.6444(0.6474) Steps 0(0.00) | Grad Norm 34.3758(27.0361) | Total Time 0.00(0.00)\n",
      "Iter 0580 | Time 15.4423(15.4074) | Bit/dim 4.7299(4.8140) | Xent 1.8002(1.8317) | Loss 12.2168(12.7881) | Error 0.6400(0.6463) Steps 0(0.00) | Grad Norm 24.8136(27.9117) | Total Time 0.00(0.00)\n",
      "Iter 0590 | Time 14.4800(15.5140) | Bit/dim 5.0847(4.8456) | Xent 2.0212(1.8671) | Loss 12.8321(12.7888) | Error 0.6867(0.6549) Steps 0(0.00) | Grad Norm 51.9257(33.7982) | Total Time 0.00(0.00)\n",
      "Iter 0600 | Time 16.1056(15.4063) | Bit/dim 4.8636(4.8582) | Xent 1.9208(1.8810) | Loss 12.5061(12.7473) | Error 0.6500(0.6612) Steps 0(0.00) | Grad Norm 24.6449(29.9577) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 84.7005, Epoch Time 952.1459(820.2076), Bit/dim 4.7613(best: 4.7860), Xent 1.8263, Loss 5.6744, Error 0.6389(best: 0.6032)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0610 | Time 14.4816(15.3477) | Bit/dim 4.7874(4.8382) | Xent 1.9165(1.8755) | Loss 12.0222(13.2496) | Error 0.6778(0.6599) Steps 0(0.00) | Grad Norm 14.4490(25.0540) | Total Time 0.00(0.00)\n",
      "Iter 0620 | Time 15.4993(15.4857) | Bit/dim 4.7493(4.8072) | Xent 1.8240(1.8636) | Loss 12.3227(12.9878) | Error 0.6411(0.6567) Steps 0(0.00) | Grad Norm 12.7965(21.1016) | Total Time 0.00(0.00)\n",
      "Iter 0630 | Time 16.2909(15.4906) | Bit/dim 4.6638(4.7749) | Xent 1.7682(1.8403) | Loss 11.9151(12.7444) | Error 0.6189(0.6477) Steps 0(0.00) | Grad Norm 20.1911(19.3115) | Total Time 0.00(0.00)\n",
      "Iter 0640 | Time 16.7065(15.7222) | Bit/dim 4.6940(4.7494) | Xent 1.7891(1.8151) | Loss 12.3328(12.5715) | Error 0.6256(0.6393) Steps 0(0.00) | Grad Norm 21.5573(20.1051) | Total Time 0.00(0.00)\n",
      "Iter 0650 | Time 16.5097(15.8757) | Bit/dim 4.6297(4.7246) | Xent 1.7151(1.7972) | Loss 11.8359(12.4267) | Error 0.6167(0.6344) Steps 0(0.00) | Grad Norm 18.8673(21.6936) | Total Time 0.00(0.00)\n",
      "Iter 0660 | Time 17.0726(15.9862) | Bit/dim 4.6550(4.7034) | Xent 1.7665(1.7897) | Loss 12.1647(12.3284) | Error 0.6089(0.6336) Steps 0(0.00) | Grad Norm 41.0018(23.4194) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 87.6196, Epoch Time 986.4795(825.1957), Bit/dim 4.6335(best: 4.7613), Xent 1.6717, Loss 5.4693, Error 0.5973(best: 0.6032)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0670 | Time 17.8194(16.1603) | Bit/dim 4.6035(4.6834) | Xent 1.7577(1.7804) | Loss 12.0399(12.7399) | Error 0.6089(0.6317) Steps 0(0.00) | Grad Norm 15.8662(24.0554) | Total Time 0.00(0.00)\n",
      "Iter 0680 | Time 16.5455(16.3379) | Bit/dim 4.6128(4.6654) | Xent 1.7300(1.7759) | Loss 11.9456(12.5396) | Error 0.6189(0.6299) Steps 0(0.00) | Grad Norm 30.4540(26.1648) | Total Time 0.00(0.00)\n",
      "Iter 0690 | Time 17.3004(16.3765) | Bit/dim 4.6119(4.6476) | Xent 1.6823(1.7548) | Loss 11.7104(12.3636) | Error 0.6056(0.6231) Steps 0(0.00) | Grad Norm 20.4356(23.3715) | Total Time 0.00(0.00)\n",
      "Iter 0700 | Time 19.2519(16.5127) | Bit/dim 4.5719(4.6292) | Xent 1.6606(1.7394) | Loss 11.7852(12.2157) | Error 0.6000(0.6181) Steps 0(0.00) | Grad Norm 25.3542(22.4644) | Total Time 0.00(0.00)\n",
      "Iter 0710 | Time 19.9798(16.6194) | Bit/dim 4.6158(4.6201) | Xent 1.7633(1.7485) | Loss 12.1826(12.1696) | Error 0.6244(0.6209) Steps 0(0.00) | Grad Norm 29.5889(23.9835) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 90.8837, Epoch Time 1029.2542(831.3175), Bit/dim 4.5676(best: 4.6335), Xent 1.6777, Loss 5.4064, Error 0.5875(best: 0.5973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0720 | Time 17.2598(16.6489) | Bit/dim 4.5590(4.6051) | Xent 1.7106(1.7398) | Loss 11.7570(12.6962) | Error 0.6067(0.6161) Steps 0(0.00) | Grad Norm 18.6612(23.7817) | Total Time 0.00(0.00)\n",
      "Iter 0730 | Time 16.3098(16.5475) | Bit/dim 4.5621(4.5904) | Xent 1.6625(1.7255) | Loss 11.4761(12.4342) | Error 0.5833(0.6113) Steps 0(0.00) | Grad Norm 15.6265(21.7715) | Total Time 0.00(0.00)\n",
      "Iter 0740 | Time 16.1525(16.7253) | Bit/dim 4.5269(4.5825) | Xent 1.7918(1.7258) | Loss 12.0078(12.2935) | Error 0.6400(0.6130) Steps 0(0.00) | Grad Norm 35.4973(24.5297) | Total Time 0.00(0.00)\n",
      "Iter 0750 | Time 15.2063(16.7674) | Bit/dim 4.5891(4.5793) | Xent 1.7209(1.7398) | Loss 11.8190(12.1797) | Error 0.6078(0.6178) Steps 0(0.00) | Grad Norm 22.8199(27.3499) | Total Time 0.00(0.00)\n",
      "Iter 0760 | Time 16.6923(16.8563) | Bit/dim 4.5297(4.5663) | Xent 1.6919(1.7388) | Loss 11.9564(12.0847) | Error 0.6078(0.6191) Steps 0(0.00) | Grad Norm 7.0681(23.2633) | Total Time 0.00(0.00)\n",
      "Iter 0770 | Time 17.3219(16.8735) | Bit/dim 4.4989(4.5502) | Xent 1.7187(1.7215) | Loss 11.7419(11.9702) | Error 0.6256(0.6129) Steps 0(0.00) | Grad Norm 14.3795(19.8564) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 90.8587, Epoch Time 1037.6414(837.5072), Bit/dim 4.4995(best: 4.5676), Xent 1.5968, Loss 5.2979, Error 0.5668(best: 0.5875)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0780 | Time 16.6108(16.9757) | Bit/dim 4.5122(4.5415) | Xent 1.7607(1.7170) | Loss 11.5208(12.4480) | Error 0.6167(0.6112) Steps 0(0.00) | Grad Norm 32.3858(22.4680) | Total Time 0.00(0.00)\n",
      "Iter 0790 | Time 16.9754(16.9436) | Bit/dim 4.5307(4.5317) | Xent 1.6531(1.7076) | Loss 11.9135(12.2600) | Error 0.5767(0.6074) Steps 0(0.00) | Grad Norm 22.8075(21.4465) | Total Time 0.00(0.00)\n",
      "Iter 0800 | Time 15.7588(16.8973) | Bit/dim 4.4476(4.5147) | Xent 1.6407(1.6924) | Loss 11.4616(12.0829) | Error 0.6033(0.6024) Steps 0(0.00) | Grad Norm 13.7934(19.4957) | Total Time 0.00(0.00)\n",
      "Iter 0810 | Time 18.0407(16.9561) | Bit/dim 4.4657(4.5010) | Xent 1.6906(1.6845) | Loss 11.5541(11.9585) | Error 0.6011(0.6007) Steps 0(0.00) | Grad Norm 30.2508(18.0672) | Total Time 0.00(0.00)\n",
      "Iter 0820 | Time 16.6881(16.8753) | Bit/dim 4.4465(4.4909) | Xent 1.7211(1.6896) | Loss 11.4626(11.8577) | Error 0.5967(0.6017) Steps 0(0.00) | Grad Norm 26.9239(20.7217) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 89.7682, Epoch Time 1042.3350(843.6520), Bit/dim 4.4468(best: 4.4995), Xent 1.5922, Loss 5.2429, Error 0.5708(best: 0.5668)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0830 | Time 16.8612(16.9378) | Bit/dim 4.4132(4.4784) | Xent 1.6833(1.6876) | Loss 11.4702(12.4393) | Error 0.5933(0.6014) Steps 0(0.00) | Grad Norm 9.8589(19.2442) | Total Time 0.00(0.00)\n",
      "Iter 0840 | Time 17.9398(17.0887) | Bit/dim 4.4193(4.4674) | Xent 1.6719(1.6738) | Loss 11.4344(12.1936) | Error 0.5889(0.5953) Steps 0(0.00) | Grad Norm 23.2771(17.2653) | Total Time 0.00(0.00)\n",
      "Iter 0850 | Time 16.7738(17.0591) | Bit/dim 4.4122(4.4539) | Xent 1.5933(1.6633) | Loss 11.4181(12.0076) | Error 0.5911(0.5920) Steps 0(0.00) | Grad Norm 3.4310(16.0931) | Total Time 0.00(0.00)\n",
      "Iter 0860 | Time 17.6034(17.1489) | Bit/dim 4.4255(4.4491) | Xent 1.7272(1.6750) | Loss 11.4646(11.8900) | Error 0.6289(0.5960) Steps 0(0.00) | Grad Norm 17.1316(18.2949) | Total Time 0.00(0.00)\n",
      "Iter 0870 | Time 16.0042(17.2712) | Bit/dim 4.4166(4.4408) | Xent 1.6012(1.6684) | Loss 11.5043(11.8236) | Error 0.5922(0.5955) Steps 0(0.00) | Grad Norm 15.5358(17.5985) | Total Time 0.00(0.00)\n",
      "Iter 0880 | Time 17.0153(17.2868) | Bit/dim 4.3882(4.4312) | Xent 1.6272(1.6618) | Loss 11.4464(11.7459) | Error 0.5944(0.5922) Steps 0(0.00) | Grad Norm 9.4892(16.9873) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 90.4860, Epoch Time 1060.7515(850.1650), Bit/dim 4.4025(best: 4.4468), Xent 1.5436, Loss 5.1743, Error 0.5467(best: 0.5668)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0890 | Time 16.9481(17.2415) | Bit/dim 4.3836(4.4219) | Xent 1.5932(1.6523) | Loss 11.3243(12.2179) | Error 0.5578(0.5897) Steps 0(0.00) | Grad Norm 9.7082(18.1149) | Total Time 0.00(0.00)\n",
      "Iter 0900 | Time 17.4344(17.3894) | Bit/dim 4.3629(4.4113) | Xent 1.6133(1.6507) | Loss 11.1827(12.0115) | Error 0.5822(0.5886) Steps 0(0.00) | Grad Norm 11.5791(18.8861) | Total Time 0.00(0.00)\n",
      "Iter 0910 | Time 19.6662(17.4801) | Bit/dim 4.3507(4.3957) | Xent 1.6195(1.6337) | Loss 11.4899(11.8540) | Error 0.5889(0.5839) Steps 0(0.00) | Grad Norm 23.2961(17.5819) | Total Time 0.00(0.00)\n",
      "Iter 0920 | Time 16.3200(17.3705) | Bit/dim 4.3315(4.3829) | Xent 1.6555(1.6255) | Loss 11.0325(11.6926) | Error 0.5878(0.5814) Steps 0(0.00) | Grad Norm 10.1698(17.1771) | Total Time 0.00(0.00)\n",
      "Iter 0930 | Time 17.4407(17.3930) | Bit/dim 4.3118(4.3692) | Xent 1.6223(1.6184) | Loss 11.2028(11.5894) | Error 0.5856(0.5799) Steps 0(0.00) | Grad Norm 6.5497(16.4900) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 91.4773, Epoch Time 1066.2466(856.6475), Bit/dim 4.3837(best: 4.4025), Xent 1.6090, Loss 5.1882, Error 0.5759(best: 0.5467)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0940 | Time 17.3336(17.3027) | Bit/dim 4.3371(4.3648) | Xent 1.7056(1.6230) | Loss 11.4370(12.1423) | Error 0.6056(0.5810) Steps 0(0.00) | Grad Norm 28.5772(18.7928) | Total Time 0.00(0.00)\n",
      "Iter 0950 | Time 18.1746(17.2549) | Bit/dim 4.2917(4.3539) | Xent 1.6036(1.6229) | Loss 11.4123(11.9154) | Error 0.5956(0.5807) Steps 0(0.00) | Grad Norm 16.1011(19.1825) | Total Time 0.00(0.00)\n",
      "Iter 0960 | Time 17.0408(17.1588) | Bit/dim 4.3283(4.3441) | Xent 1.6142(1.6147) | Loss 11.0248(11.7051) | Error 0.5922(0.5782) Steps 0(0.00) | Grad Norm 12.4141(19.0601) | Total Time 0.00(0.00)\n",
      "Iter 0970 | Time 16.8001(17.3003) | Bit/dim 4.2650(4.3323) | Xent 1.5750(1.6057) | Loss 11.1403(11.5818) | Error 0.5622(0.5768) Steps 0(0.00) | Grad Norm 11.7537(17.7389) | Total Time 0.00(0.00)\n",
      "Iter 0980 | Time 15.7807(17.2475) | Bit/dim 4.3313(4.3241) | Xent 1.6399(1.6034) | Loss 11.2808(11.4913) | Error 0.5989(0.5750) Steps 0(0.00) | Grad Norm 23.7515(19.2056) | Total Time 0.00(0.00)\n",
      "Iter 0990 | Time 17.0381(17.3311) | Bit/dim 4.2672(4.3140) | Xent 1.5776(1.6040) | Loss 11.2289(11.4137) | Error 0.5878(0.5768) Steps 0(0.00) | Grad Norm 11.1377(18.5750) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 90.3872, Epoch Time 1057.7967(862.6819), Bit/dim 4.2691(best: 4.3837), Xent 1.5040, Loss 5.0211, Error 0.5362(best: 0.5467)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1000 | Time 16.9162(17.2787) | Bit/dim 4.2500(4.3022) | Xent 1.5931(1.5897) | Loss 11.2989(11.9043) | Error 0.5611(0.5715) Steps 0(0.00) | Grad Norm 26.8283(18.6663) | Total Time 0.00(0.00)\n",
      "Iter 1010 | Time 16.9442(17.1863) | Bit/dim 4.2741(4.2906) | Xent 1.5078(1.5746) | Loss 10.9243(11.6725) | Error 0.5189(0.5648) Steps 0(0.00) | Grad Norm 21.4712(18.0620) | Total Time 0.00(0.00)\n",
      "Iter 1020 | Time 16.4021(17.2336) | Bit/dim 4.2368(4.2794) | Xent 1.4928(1.5721) | Loss 11.0443(11.5289) | Error 0.5356(0.5613) Steps 0(0.00) | Grad Norm 8.0908(18.0050) | Total Time 0.00(0.00)\n",
      "Iter 1030 | Time 17.5440(17.2569) | Bit/dim 4.2384(4.2702) | Xent 1.5189(1.5601) | Loss 10.9611(11.4095) | Error 0.5589(0.5586) Steps 0(0.00) | Grad Norm 18.3173(17.1841) | Total Time 0.00(0.00)\n",
      "Iter 1040 | Time 16.3236(17.2163) | Bit/dim 4.2473(4.2553) | Xent 1.5074(1.5532) | Loss 10.9097(11.2972) | Error 0.5300(0.5580) Steps 0(0.00) | Grad Norm 14.1656(15.2168) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 89.7207, Epoch Time 1055.0335(868.4525), Bit/dim 4.2241(best: 4.2691), Xent 1.4643, Loss 4.9563, Error 0.5281(best: 0.5362)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1050 | Time 18.2797(17.3690) | Bit/dim 4.1699(4.2473) | Xent 1.4735(1.5366) | Loss 10.8794(11.8117) | Error 0.5122(0.5521) Steps 0(0.00) | Grad Norm 23.8896(15.4031) | Total Time 0.00(0.00)\n",
      "Iter 1060 | Time 17.6558(17.3423) | Bit/dim 4.2228(4.2379) | Xent 1.4822(1.5228) | Loss 11.0885(11.5897) | Error 0.5233(0.5481) Steps 0(0.00) | Grad Norm 10.7662(15.1959) | Total Time 0.00(0.00)\n",
      "Iter 1070 | Time 20.0024(17.4360) | Bit/dim 4.2024(4.2375) | Xent 1.5919(1.5229) | Loss 11.0716(11.4439) | Error 0.5767(0.5485) Steps 0(0.00) | Grad Norm 13.2664(16.4437) | Total Time 0.00(0.00)\n",
      "Iter 1080 | Time 19.3190(17.4612) | Bit/dim 4.2141(4.2306) | Xent 1.5726(1.5396) | Loss 11.1722(11.3456) | Error 0.5778(0.5544) Steps 0(0.00) | Grad Norm 21.4730(17.7785) | Total Time 0.00(0.00)\n",
      "Iter 1090 | Time 18.1115(17.6246) | Bit/dim 4.1908(4.2274) | Xent 1.4905(1.5380) | Loss 11.0160(11.2449) | Error 0.5400(0.5545) Steps 0(0.00) | Grad Norm 11.8336(16.7950) | Total Time 0.00(0.00)\n",
      "Iter 1100 | Time 17.2768(17.4286) | Bit/dim 4.1760(4.2171) | Xent 1.4800(1.5299) | Loss 10.7750(11.1433) | Error 0.5267(0.5518) Steps 0(0.00) | Grad Norm 15.2821(14.9858) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 89.8605, Epoch Time 1071.9643(874.5578), Bit/dim 4.1864(best: 4.2241), Xent 1.4098, Loss 4.8913, Error 0.5089(best: 0.5281)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1110 | Time 19.6063(17.6908) | Bit/dim 4.2013(4.2082) | Xent 1.4691(1.5155) | Loss 10.7901(11.6002) | Error 0.5144(0.5442) Steps 0(0.00) | Grad Norm 17.7213(14.5086) | Total Time 0.00(0.00)\n",
      "Iter 1120 | Time 17.7001(17.6170) | Bit/dim 4.1698(4.2004) | Xent 1.4374(1.5044) | Loss 10.8002(11.4031) | Error 0.5356(0.5414) Steps 0(0.00) | Grad Norm 10.3198(15.6518) | Total Time 0.00(0.00)\n",
      "Iter 1130 | Time 16.8156(17.6002) | Bit/dim 4.1442(4.1846) | Xent 1.4708(1.4908) | Loss 10.6653(11.2259) | Error 0.5300(0.5376) Steps 0(0.00) | Grad Norm 12.6900(14.4712) | Total Time 0.00(0.00)\n",
      "Iter 1140 | Time 16.4735(17.5347) | Bit/dim 4.1173(4.1738) | Xent 1.4878(1.4815) | Loss 10.5562(11.0985) | Error 0.5278(0.5360) Steps 0(0.00) | Grad Norm 13.2429(14.4385) | Total Time 0.00(0.00)\n",
      "Iter 1150 | Time 17.1824(17.5377) | Bit/dim 4.1216(4.1662) | Xent 1.3979(1.4784) | Loss 10.7313(10.9800) | Error 0.4900(0.5358) Steps 0(0.00) | Grad Norm 11.7426(13.8021) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 89.8605, Epoch Time 1079.4174(880.7036), Bit/dim 4.1329(best: 4.1864), Xent 1.3520, Loss 4.8089, Error 0.4919(best: 0.5089)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1160 | Time 18.7392(17.7083) | Bit/dim 4.1479(4.1559) | Xent 1.3599(1.4638) | Loss 10.6884(11.5276) | Error 0.5044(0.5312) Steps 0(0.00) | Grad Norm 5.5471(12.3794) | Total Time 0.00(0.00)\n",
      "Iter 1170 | Time 17.5153(17.7117) | Bit/dim 4.1691(4.1568) | Xent 1.5020(1.4627) | Loss 10.9368(11.3416) | Error 0.5489(0.5296) Steps 0(0.00) | Grad Norm 19.0257(14.1045) | Total Time 0.00(0.00)\n",
      "Iter 1180 | Time 16.2869(17.5718) | Bit/dim 4.1120(4.1493) | Xent 1.3840(1.4581) | Loss 10.3054(11.1701) | Error 0.4922(0.5293) Steps 0(0.00) | Grad Norm 11.9641(14.2048) | Total Time 0.00(0.00)\n",
      "Iter 1190 | Time 18.6556(17.5654) | Bit/dim 4.1227(4.1417) | Xent 1.4385(1.4540) | Loss 10.6242(11.0340) | Error 0.5167(0.5271) Steps 0(0.00) | Grad Norm 19.0595(14.6073) | Total Time 0.00(0.00)\n",
      "Iter 1200 | Time 16.6269(17.5079) | Bit/dim 4.1172(4.1327) | Xent 1.4131(1.4468) | Loss 10.6633(10.9440) | Error 0.5156(0.5232) Steps 0(0.00) | Grad Norm 6.6253(13.8433) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 16.9519(17.3633) | Bit/dim 4.1003(4.1239) | Xent 1.4474(1.4386) | Loss 10.6493(10.8456) | Error 0.5144(0.5224) Steps 0(0.00) | Grad Norm 13.0713(13.5358) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 90.9137, Epoch Time 1069.5039(886.3676), Bit/dim 4.0949(best: 4.1329), Xent 1.3264, Loss 4.7581, Error 0.4850(best: 0.4919)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1220 | Time 16.9627(17.3840) | Bit/dim 4.0887(4.1150) | Xent 1.4212(1.4216) | Loss 10.7182(11.3121) | Error 0.5344(0.5170) Steps 0(0.00) | Grad Norm 6.0587(12.4406) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 18.9611(17.3313) | Bit/dim 4.1181(4.1111) | Xent 1.4173(1.4219) | Loss 10.4234(11.1080) | Error 0.5033(0.5147) Steps 0(0.00) | Grad Norm 17.6667(14.0882) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 17.1410(17.3270) | Bit/dim 4.0933(4.1101) | Xent 1.4528(1.4235) | Loss 10.6309(10.9538) | Error 0.5111(0.5139) Steps 0(0.00) | Grad Norm 17.5927(14.3062) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 18.6089(17.4111) | Bit/dim 4.0775(4.1036) | Xent 1.4205(1.4221) | Loss 10.7169(10.8667) | Error 0.5100(0.5132) Steps 0(0.00) | Grad Norm 6.2752(14.7082) | Total Time 0.00(0.00)\n",
      "Iter 1260 | Time 16.1937(17.3369) | Bit/dim 4.0770(4.0968) | Xent 1.4123(1.4144) | Loss 10.4064(10.7628) | Error 0.5033(0.5121) Steps 0(0.00) | Grad Norm 11.3167(13.0259) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 88.6849, Epoch Time 1061.6317(891.6256), Bit/dim 4.0641(best: 4.0949), Xent 1.3133, Loss 4.7208, Error 0.4769(best: 0.4850)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1270 | Time 19.1488(17.3944) | Bit/dim 4.0867(4.0921) | Xent 1.3216(1.3976) | Loss 10.6953(11.3250) | Error 0.4700(0.5059) Steps 0(0.00) | Grad Norm 15.8319(12.7739) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 16.3231(17.3985) | Bit/dim 4.0117(4.0834) | Xent 1.3400(1.3867) | Loss 10.0717(11.0997) | Error 0.4889(0.5022) Steps 0(0.00) | Grad Norm 17.7941(12.2718) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 17.4076(17.5401) | Bit/dim 4.0429(4.0777) | Xent 1.3408(1.3805) | Loss 10.5365(10.9599) | Error 0.5111(0.5020) Steps 0(0.00) | Grad Norm 11.9392(12.8130) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 16.5275(17.4566) | Bit/dim 4.0456(4.0702) | Xent 1.3944(1.3694) | Loss 10.4081(10.8136) | Error 0.5044(0.4976) Steps 0(0.00) | Grad Norm 24.1963(12.6701) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 17.5922(17.5700) | Bit/dim 4.0838(4.0693) | Xent 1.3610(1.3733) | Loss 10.7536(10.7391) | Error 0.4922(0.4985) Steps 0(0.00) | Grad Norm 8.2765(13.1913) | Total Time 0.00(0.00)\n",
      "Iter 1320 | Time 16.8625(17.4483) | Bit/dim 4.0356(4.0665) | Xent 1.4185(1.3739) | Loss 10.5674(10.6524) | Error 0.5122(0.4988) Steps 0(0.00) | Grad Norm 18.9502(13.0516) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 87.4085, Epoch Time 1071.0244(897.0075), Bit/dim 4.0614(best: 4.0641), Xent 1.3163, Loss 4.7196, Error 0.4709(best: 0.4769)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1330 | Time 19.8977(17.4739) | Bit/dim 3.9930(4.0602) | Xent 1.2229(1.3607) | Loss 10.3708(11.1308) | Error 0.4567(0.4937) Steps 0(0.00) | Grad Norm 6.0222(12.2766) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 15.9769(17.4422) | Bit/dim 4.0432(4.0628) | Xent 1.4089(1.3759) | Loss 10.2265(10.9701) | Error 0.5078(0.4987) Steps 0(0.00) | Grad Norm 8.3800(13.7843) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 16.9496(17.3803) | Bit/dim 4.0480(4.0607) | Xent 1.4087(1.3764) | Loss 10.4416(10.8518) | Error 0.5078(0.4996) Steps 0(0.00) | Grad Norm 12.3272(13.0337) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 17.8175(17.3724) | Bit/dim 4.0604(4.0554) | Xent 1.2578(1.3628) | Loss 10.4948(10.7396) | Error 0.4456(0.4933) Steps 0(0.00) | Grad Norm 10.3317(12.1931) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 18.5179(17.3000) | Bit/dim 4.0236(4.0509) | Xent 1.3482(1.3622) | Loss 10.5007(10.6666) | Error 0.4833(0.4931) Steps 0(0.00) | Grad Norm 15.6385(12.9171) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 89.1786, Epoch Time 1058.9396(901.8655), Bit/dim 4.0395(best: 4.0614), Xent 1.2491, Loss 4.6640, Error 0.4534(best: 0.4709)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1380 | Time 17.9961(17.2809) | Bit/dim 4.0219(4.0454) | Xent 1.3188(1.3550) | Loss 10.4935(11.1971) | Error 0.4767(0.4898) Steps 0(0.00) | Grad Norm 8.7744(12.9230) | Total Time 0.00(0.00)\n",
      "Iter 1390 | Time 17.8515(17.3608) | Bit/dim 4.0365(4.0395) | Xent 1.2807(1.3381) | Loss 10.4942(10.9708) | Error 0.4600(0.4845) Steps 0(0.00) | Grad Norm 15.0633(12.2118) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 16.1406(17.3389) | Bit/dim 4.0355(4.0342) | Xent 1.3845(1.3405) | Loss 10.4528(10.8132) | Error 0.5267(0.4856) Steps 0(0.00) | Grad Norm 16.0526(13.8951) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 17.8954(17.1549) | Bit/dim 3.9928(4.0297) | Xent 1.3105(1.3361) | Loss 10.2624(10.6785) | Error 0.4756(0.4844) Steps 0(0.00) | Grad Norm 6.5714(12.9601) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 18.3069(17.1855) | Bit/dim 4.0163(4.0285) | Xent 1.2658(1.3275) | Loss 10.5320(10.6044) | Error 0.4667(0.4806) Steps 0(0.00) | Grad Norm 6.9679(12.8505) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 18.8247(17.2737) | Bit/dim 3.9890(4.0215) | Xent 1.3098(1.3281) | Loss 10.4209(10.5359) | Error 0.4789(0.4815) Steps 0(0.00) | Grad Norm 12.2477(11.8198) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 87.6423, Epoch Time 1054.2590(906.4373), Bit/dim 4.0131(best: 4.0395), Xent 1.2562, Loss 4.6412, Error 0.4517(best: 0.4534)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1440 | Time 18.5272(17.2710) | Bit/dim 3.9835(4.0161) | Xent 1.2761(1.3247) | Loss 10.2567(10.9668) | Error 0.4533(0.4806) Steps 0(0.00) | Grad Norm 14.7378(12.3650) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 16.4917(17.1511) | Bit/dim 4.0409(4.0105) | Xent 1.2401(1.3104) | Loss 10.1079(10.7687) | Error 0.4444(0.4736) Steps 0(0.00) | Grad Norm 6.8289(11.3149) | Total Time 0.00(0.00)\n",
      "Iter 1460 | Time 16.6193(17.0402) | Bit/dim 3.9843(4.0057) | Xent 1.2883(1.3011) | Loss 10.1011(10.6327) | Error 0.4533(0.4692) Steps 0(0.00) | Grad Norm 9.7850(10.9552) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 18.1452(17.1839) | Bit/dim 3.9840(4.0002) | Xent 1.3299(1.2949) | Loss 10.5838(10.5560) | Error 0.4833(0.4676) Steps 0(0.00) | Grad Norm 6.4799(11.7948) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 15.4640(17.0681) | Bit/dim 4.0040(3.9999) | Xent 1.3691(1.2992) | Loss 9.9264(10.4772) | Error 0.4978(0.4708) Steps 0(0.00) | Grad Norm 20.5900(12.4063) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 87.4853, Epoch Time 1042.0582(910.5059), Bit/dim 3.9999(best: 4.0131), Xent 1.2063, Loss 4.6031, Error 0.4378(best: 0.4517)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1490 | Time 16.8219(17.0027) | Bit/dim 4.0085(3.9982) | Xent 1.3022(1.2979) | Loss 10.4008(11.0488) | Error 0.4700(0.4701) Steps 0(0.00) | Grad Norm 11.3245(12.6934) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 16.2915(17.0777) | Bit/dim 3.9618(3.9965) | Xent 1.4752(1.3042) | Loss 10.2720(10.8480) | Error 0.5489(0.4719) Steps 0(0.00) | Grad Norm 21.2830(13.0600) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 17.1208(17.2252) | Bit/dim 3.9850(3.9925) | Xent 1.3673(1.2974) | Loss 10.3421(10.7020) | Error 0.4744(0.4701) Steps 0(0.00) | Grad Norm 11.4792(12.7524) | Total Time 0.00(0.00)\n",
      "Iter 1520 | Time 18.4036(17.2073) | Bit/dim 3.9763(3.9888) | Xent 1.2030(1.2846) | Loss 10.1323(10.5688) | Error 0.4300(0.4651) Steps 0(0.00) | Grad Norm 4.2406(11.4996) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 17.4092(17.2603) | Bit/dim 3.9983(3.9899) | Xent 1.2634(1.2826) | Loss 10.3724(10.4898) | Error 0.4656(0.4647) Steps 0(0.00) | Grad Norm 11.6583(13.3215) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 15.8693(17.1201) | Bit/dim 4.0124(3.9852) | Xent 1.2993(1.2842) | Loss 10.0841(10.3992) | Error 0.4656(0.4661) Steps 0(0.00) | Grad Norm 7.1470(12.6612) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 87.2880, Epoch Time 1050.1575(914.6955), Bit/dim 3.9675(best: 3.9999), Xent 1.2200, Loss 4.5775, Error 0.4351(best: 0.4378)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1550 | Time 17.6025(17.3379) | Bit/dim 3.9726(3.9807) | Xent 1.2809(1.2677) | Loss 10.2466(10.8759) | Error 0.4633(0.4587) Steps 0(0.00) | Grad Norm 14.6552(12.2868) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 16.6871(17.1790) | Bit/dim 3.9897(3.9774) | Xent 1.2660(1.2580) | Loss 10.0564(10.6628) | Error 0.4400(0.4544) Steps 0(0.00) | Grad Norm 10.0760(11.9641) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 17.7348(17.1892) | Bit/dim 3.9159(3.9738) | Xent 1.2301(1.2635) | Loss 10.1349(10.5538) | Error 0.4278(0.4559) Steps 0(0.00) | Grad Norm 18.5387(12.5883) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 16.8088(17.0867) | Bit/dim 3.9713(3.9710) | Xent 1.3154(1.2623) | Loss 10.1819(10.4642) | Error 0.4756(0.4565) Steps 0(0.00) | Grad Norm 14.1420(13.5053) | Total Time 0.00(0.00)\n",
      "Iter 1590 | Time 16.7529(17.0314) | Bit/dim 3.9585(3.9688) | Xent 1.3134(1.2593) | Loss 10.1546(10.3762) | Error 0.4544(0.4545) Steps 0(0.00) | Grad Norm 13.2598(13.4397) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 86.9735, Epoch Time 1045.7506(918.6271), Bit/dim 3.9510(best: 3.9675), Xent 1.1678, Loss 4.5349, Error 0.4147(best: 0.4351)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1600 | Time 15.2334(16.8527) | Bit/dim 3.9721(3.9667) | Xent 1.2301(1.2527) | Loss 10.0086(10.9110) | Error 0.4400(0.4511) Steps 0(0.00) | Grad Norm 15.8219(13.1012) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 16.5339(16.8533) | Bit/dim 3.9601(3.9632) | Xent 1.2275(1.2465) | Loss 9.8401(10.6795) | Error 0.4211(0.4479) Steps 0(0.00) | Grad Norm 12.8314(13.4333) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 17.0411(16.9756) | Bit/dim 3.9329(3.9606) | Xent 1.2400(1.2400) | Loss 10.0484(10.5321) | Error 0.4756(0.4470) Steps 0(0.00) | Grad Norm 9.2325(12.9167) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 15.4370(16.8584) | Bit/dim 3.9378(3.9562) | Xent 1.2319(1.2311) | Loss 9.9784(10.4065) | Error 0.4311(0.4440) Steps 0(0.00) | Grad Norm 12.4239(11.8446) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 15.9263(16.7270) | Bit/dim 3.9420(3.9563) | Xent 1.2498(1.2276) | Loss 9.9948(10.3129) | Error 0.4656(0.4422) Steps 0(0.00) | Grad Norm 18.9990(12.0080) | Total Time 0.00(0.00)\n",
      "Iter 1650 | Time 17.0015(16.8435) | Bit/dim 3.9507(3.9515) | Xent 1.2376(1.2210) | Loss 10.1199(10.2455) | Error 0.4378(0.4396) Steps 0(0.00) | Grad Norm 7.5918(11.5676) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 87.1646, Epoch Time 1028.1960(921.9142), Bit/dim 3.9509(best: 3.9510), Xent 1.1312, Loss 4.5165, Error 0.4072(best: 0.4147)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1660 | Time 16.8269(16.7889) | Bit/dim 3.9423(3.9490) | Xent 1.1235(1.2131) | Loss 9.9535(10.6929) | Error 0.3933(0.4372) Steps 0(0.00) | Grad Norm 13.8287(11.6224) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 15.7003(16.6090) | Bit/dim 3.9202(3.9439) | Xent 1.1812(1.2002) | Loss 9.9537(10.4784) | Error 0.4278(0.4331) Steps 0(0.00) | Grad Norm 5.2792(11.0653) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 17.2971(16.8217) | Bit/dim 3.9556(3.9409) | Xent 1.2236(1.1993) | Loss 10.0112(10.3694) | Error 0.4333(0.4311) Steps 0(0.00) | Grad Norm 17.9753(11.1876) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 16.3650(16.7614) | Bit/dim 3.9111(3.9373) | Xent 1.2442(1.1984) | Loss 10.0729(10.2741) | Error 0.4556(0.4320) Steps 0(0.00) | Grad Norm 14.2042(11.0796) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 15.6425(16.7463) | Bit/dim 3.9050(3.9365) | Xent 1.0974(1.1959) | Loss 9.7067(10.1948) | Error 0.3900(0.4293) Steps 0(0.00) | Grad Norm 9.6815(10.7522) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 86.9569, Epoch Time 1023.4756(924.9610), Bit/dim 3.9426(best: 3.9509), Xent 1.1728, Loss 4.5290, Error 0.4206(best: 0.4072)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1710 | Time 17.5898(16.7444) | Bit/dim 3.9761(3.9362) | Xent 1.3188(1.2120) | Loss 10.3724(10.7608) | Error 0.4822(0.4356) Steps 0(0.00) | Grad Norm 18.7158(13.0514) | Total Time 0.00(0.00)\n",
      "Iter 1720 | Time 15.9021(16.7266) | Bit/dim 3.9200(3.9347) | Xent 1.1076(1.2039) | Loss 9.9018(10.5622) | Error 0.4033(0.4304) Steps 0(0.00) | Grad Norm 11.9108(12.3783) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 17.8420(16.7433) | Bit/dim 3.9095(3.9318) | Xent 1.1698(1.1991) | Loss 10.0962(10.4207) | Error 0.4233(0.4300) Steps 0(0.00) | Grad Norm 10.9007(12.2977) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 16.9792(16.8739) | Bit/dim 3.9287(3.9299) | Xent 1.1633(1.1918) | Loss 10.0121(10.3167) | Error 0.4222(0.4271) Steps 0(0.00) | Grad Norm 11.7644(11.9522) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 15.3681(16.7988) | Bit/dim 3.9280(3.9270) | Xent 1.0994(1.1806) | Loss 9.9335(10.2233) | Error 0.3978(0.4223) Steps 0(0.00) | Grad Norm 12.4731(11.2828) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 15.8090(16.7891) | Bit/dim 3.8979(3.9224) | Xent 1.1739(1.1783) | Loss 9.6982(10.1510) | Error 0.4189(0.4227) Steps 0(0.00) | Grad Norm 14.0995(11.9074) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 86.3330, Epoch Time 1029.0673(928.0842), Bit/dim 3.9053(best: 3.9426), Xent 1.1228, Loss 4.4667, Error 0.4044(best: 0.4072)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1770 | Time 16.4850(16.8316) | Bit/dim 3.8980(3.9190) | Xent 1.1267(1.1674) | Loss 9.8140(10.6102) | Error 0.3944(0.4188) Steps 0(0.00) | Grad Norm 12.2443(11.4649) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 16.0020(16.8421) | Bit/dim 3.9336(3.9175) | Xent 1.1369(1.1558) | Loss 9.9062(10.4293) | Error 0.3956(0.4141) Steps 0(0.00) | Grad Norm 5.5985(10.6069) | Total Time 0.00(0.00)\n",
      "Iter 1790 | Time 16.4721(16.8190) | Bit/dim 3.9282(3.9179) | Xent 1.1591(1.1530) | Loss 9.7993(10.2922) | Error 0.4022(0.4139) Steps 0(0.00) | Grad Norm 7.3228(11.4929) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 22.2995(17.0181) | Bit/dim 3.9170(3.9178) | Xent 1.1631(1.1474) | Loss 9.9797(10.2003) | Error 0.4167(0.4101) Steps 0(0.00) | Grad Norm 19.6749(11.5786) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 18.1840(16.8828) | Bit/dim 3.8713(3.9113) | Xent 1.2019(1.1472) | Loss 10.0651(10.0940) | Error 0.4300(0.4120) Steps 0(0.00) | Grad Norm 18.4859(11.5781) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 85.6236, Epoch Time 1031.9445(931.2000), Bit/dim 3.9126(best: 3.9053), Xent 1.1063, Loss 4.4657, Error 0.4001(best: 0.4044)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1820 | Time 16.3287(16.8151) | Bit/dim 3.9085(3.9090) | Xent 1.1459(1.1487) | Loss 10.1053(10.6398) | Error 0.3922(0.4109) Steps 0(0.00) | Grad Norm 12.1858(12.0401) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 15.6343(16.8416) | Bit/dim 3.9028(3.9082) | Xent 1.1798(1.1390) | Loss 9.8490(10.4425) | Error 0.4289(0.4078) Steps 0(0.00) | Grad Norm 23.3256(12.0278) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 15.7014(16.8195) | Bit/dim 3.9086(3.9073) | Xent 1.1611(1.1351) | Loss 9.4681(10.2823) | Error 0.4178(0.4077) Steps 0(0.00) | Grad Norm 5.9881(11.8734) | Total Time 0.00(0.00)\n",
      "Iter 1850 | Time 17.1132(16.8051) | Bit/dim 3.8694(3.9034) | Xent 1.1310(1.1342) | Loss 9.9704(10.1727) | Error 0.4100(0.4070) Steps 0(0.00) | Grad Norm 7.2497(11.5171) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 16.2933(16.6754) | Bit/dim 3.8731(3.8988) | Xent 1.0841(1.1338) | Loss 9.6778(10.0789) | Error 0.3967(0.4067) Steps 0(0.00) | Grad Norm 8.7383(10.8733) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 15.4535(16.6638) | Bit/dim 3.9349(3.8971) | Xent 1.0954(1.1243) | Loss 9.8466(10.0239) | Error 0.4022(0.4019) Steps 0(0.00) | Grad Norm 17.1284(10.8693) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 85.9293, Epoch Time 1021.8564(933.9197), Bit/dim 3.8914(best: 3.9053), Xent 1.1209, Loss 4.4518, Error 0.4059(best: 0.4001)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1880 | Time 17.5082(16.6739) | Bit/dim 3.8934(3.8940) | Xent 1.1165(1.1309) | Loss 9.8336(10.4797) | Error 0.4156(0.4039) Steps 0(0.00) | Grad Norm 8.0843(12.2429) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 15.4952(16.7099) | Bit/dim 3.8791(3.8897) | Xent 1.0384(1.1197) | Loss 9.5411(10.2899) | Error 0.3633(0.4007) Steps 0(0.00) | Grad Norm 7.8177(11.4304) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 15.9614(16.6598) | Bit/dim 3.8544(3.8893) | Xent 1.0933(1.1158) | Loss 9.4878(10.1660) | Error 0.3833(0.3970) Steps 0(0.00) | Grad Norm 13.5926(11.2624) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 16.1044(16.5216) | Bit/dim 3.8983(3.8891) | Xent 1.0785(1.1063) | Loss 9.9692(10.0742) | Error 0.3867(0.3952) Steps 0(0.00) | Grad Norm 12.4035(11.2678) | Total Time 0.00(0.00)\n",
      "Iter 1920 | Time 15.7630(16.5312) | Bit/dim 3.9090(3.8913) | Xent 1.1047(1.1098) | Loss 9.8146(10.0174) | Error 0.3933(0.3983) Steps 0(0.00) | Grad Norm 10.7010(11.5236) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 83.7653, Epoch Time 1010.6191(936.2207), Bit/dim 3.8762(best: 3.8914), Xent 1.0412, Loss 4.3967, Error 0.3687(best: 0.4001)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1930 | Time 17.3684(16.6288) | Bit/dim 3.9059(3.8909) | Xent 1.0823(1.1111) | Loss 9.8576(10.5666) | Error 0.3833(0.3983) Steps 0(0.00) | Grad Norm 7.4898(11.1961) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 16.5736(16.6378) | Bit/dim 3.8724(3.8882) | Xent 1.0718(1.1076) | Loss 9.6726(10.3593) | Error 0.4011(0.3968) Steps 0(0.00) | Grad Norm 9.5197(11.8025) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 16.3672(16.6933) | Bit/dim 3.8731(3.8866) | Xent 1.0778(1.0980) | Loss 9.8943(10.1991) | Error 0.3822(0.3923) Steps 0(0.00) | Grad Norm 10.1837(11.4173) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 17.8776(16.6624) | Bit/dim 3.8385(3.8815) | Xent 1.0903(1.0983) | Loss 9.7153(10.0838) | Error 0.3911(0.3913) Steps 0(0.00) | Grad Norm 11.5669(11.1216) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 16.7721(16.6976) | Bit/dim 3.8584(3.8766) | Xent 1.1150(1.0972) | Loss 9.7072(9.9898) | Error 0.3900(0.3930) Steps 0(0.00) | Grad Norm 7.6933(10.7620) | Total Time 0.00(0.00)\n",
      "Iter 1980 | Time 15.6947(16.6570) | Bit/dim 3.8509(3.8758) | Xent 1.0549(1.0927) | Loss 9.7902(9.9146) | Error 0.3611(0.3904) Steps 0(0.00) | Grad Norm 15.9591(11.0685) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 84.9042, Epoch Time 1024.3115(938.8634), Bit/dim 3.8622(best: 3.8762), Xent 1.0179, Loss 4.3711, Error 0.3654(best: 0.3687)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1990 | Time 17.2413(16.7393) | Bit/dim 3.8585(3.8713) | Xent 1.1611(1.0906) | Loss 10.0227(10.3791) | Error 0.4211(0.3906) Steps 0(0.00) | Grad Norm 22.5498(12.6305) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 18.8645(16.9098) | Bit/dim 3.8889(3.8756) | Xent 1.1310(1.0968) | Loss 9.9946(10.2500) | Error 0.4022(0.3926) Steps 0(0.00) | Grad Norm 15.6389(13.2821) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 15.3764(16.7446) | Bit/dim 3.9048(3.8760) | Xent 1.0677(1.0936) | Loss 9.6943(10.1221) | Error 0.3778(0.3913) Steps 0(0.00) | Grad Norm 10.4370(12.8988) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 16.6163(16.6483) | Bit/dim 3.8197(3.8738) | Xent 1.0625(1.1026) | Loss 9.6839(10.0328) | Error 0.3722(0.3936) Steps 0(0.00) | Grad Norm 12.6271(13.3494) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 18.0340(16.7717) | Bit/dim 3.8990(3.8737) | Xent 1.1152(1.1063) | Loss 9.6427(9.9717) | Error 0.4033(0.3940) Steps 0(0.00) | Grad Norm 5.9854(12.1034) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 87.2455, Epoch Time 1032.3968(941.6694), Bit/dim 3.8727(best: 3.8622), Xent 1.0018, Loss 4.3736, Error 0.3525(best: 0.3654)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2040 | Time 15.6382(16.8077) | Bit/dim 3.8841(3.8706) | Xent 1.0407(1.0973) | Loss 9.7778(10.5151) | Error 0.3578(0.3900) Steps 0(0.00) | Grad Norm 6.8001(11.4818) | Total Time 0.00(0.00)\n",
      "Iter 2050 | Time 15.7496(16.7790) | Bit/dim 3.8352(3.8657) | Xent 1.0532(1.0863) | Loss 9.7557(10.3014) | Error 0.3756(0.3876) Steps 0(0.00) | Grad Norm 8.7152(10.8546) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 16.8746(16.9234) | Bit/dim 3.8502(3.8648) | Xent 1.0771(1.0763) | Loss 9.7013(10.1675) | Error 0.3922(0.3846) Steps 0(0.00) | Grad Norm 9.5469(10.3378) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 16.7115(16.8098) | Bit/dim 3.8603(3.8615) | Xent 1.0450(1.0659) | Loss 9.6267(10.0356) | Error 0.3567(0.3803) Steps 0(0.00) | Grad Norm 10.2365(10.1893) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 16.5745(16.8915) | Bit/dim 3.8667(3.8605) | Xent 1.1343(1.0611) | Loss 9.7296(9.9535) | Error 0.4256(0.3794) Steps 0(0.00) | Grad Norm 7.0589(9.9972) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 18.1267(16.8104) | Bit/dim 3.8620(3.8578) | Xent 1.0154(1.0599) | Loss 9.8681(9.9066) | Error 0.3656(0.3803) Steps 0(0.00) | Grad Norm 5.7523(9.7930) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 87.0510, Epoch Time 1030.2912(944.3281), Bit/dim 3.8605(best: 3.8622), Xent 0.9883, Loss 4.3546, Error 0.3497(best: 0.3525)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2100 | Time 17.3942(16.8311) | Bit/dim 3.8723(3.8564) | Xent 1.0742(1.0557) | Loss 9.8005(10.3812) | Error 0.3789(0.3785) Steps 0(0.00) | Grad Norm 13.0554(9.7848) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 18.4704(16.9958) | Bit/dim 3.8393(3.8565) | Xent 1.0959(1.0584) | Loss 9.6460(10.1837) | Error 0.4078(0.3799) Steps 0(0.00) | Grad Norm 15.3290(10.4139) | Total Time 0.00(0.00)\n",
      "Iter 2120 | Time 16.5902(16.9185) | Bit/dim 3.8080(3.8557) | Xent 1.1491(1.0624) | Loss 9.8685(10.0705) | Error 0.4056(0.3809) Steps 0(0.00) | Grad Norm 23.3186(11.0842) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 15.8063(16.7607) | Bit/dim 3.8234(3.8550) | Xent 1.0781(1.0590) | Loss 9.5862(9.9727) | Error 0.3789(0.3790) Steps 0(0.00) | Grad Norm 14.2128(11.3600) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 15.8631(16.6442) | Bit/dim 3.8541(3.8534) | Xent 1.0607(1.0565) | Loss 9.5650(9.9018) | Error 0.3667(0.3777) Steps 0(0.00) | Grad Norm 7.6324(10.5931) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 84.6141, Epoch Time 1019.9585(946.5970), Bit/dim 3.8561(best: 3.8605), Xent 1.0460, Loss 4.3791, Error 0.3805(best: 0.3497)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2150 | Time 16.4235(16.6658) | Bit/dim 3.8669(3.8540) | Xent 1.1807(1.0714) | Loss 9.8525(10.4598) | Error 0.4256(0.3818) Steps 0(0.00) | Grad Norm 16.8314(10.8958) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 17.1260(16.6917) | Bit/dim 3.8560(3.8533) | Xent 1.0069(1.0638) | Loss 9.7212(10.2713) | Error 0.3811(0.3797) Steps 0(0.00) | Grad Norm 8.5949(10.5641) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 17.9842(16.6480) | Bit/dim 3.8356(3.8530) | Xent 1.0292(1.0550) | Loss 9.6629(10.1094) | Error 0.3656(0.3764) Steps 0(0.00) | Grad Norm 14.5933(10.1078) | Total Time 0.00(0.00)\n",
      "Iter 2180 | Time 16.3844(16.6817) | Bit/dim 3.8268(3.8499) | Xent 1.0577(1.0493) | Loss 9.6612(9.9872) | Error 0.3722(0.3746) Steps 0(0.00) | Grad Norm 11.9521(10.2819) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 17.0350(16.6532) | Bit/dim 3.8629(3.8481) | Xent 1.1449(1.0554) | Loss 9.9556(9.9344) | Error 0.4189(0.3774) Steps 0(0.00) | Grad Norm 10.4587(10.8204) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 16.5650(16.7838) | Bit/dim 3.8513(3.8457) | Xent 1.0264(1.0569) | Loss 9.5992(9.8730) | Error 0.3844(0.3791) Steps 0(0.00) | Grad Norm 9.8900(10.9539) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 85.7055, Epoch Time 1027.5729(949.0263), Bit/dim 3.8407(best: 3.8561), Xent 1.0001, Loss 4.3408, Error 0.3527(best: 0.3497)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2210 | Time 16.0327(16.5635) | Bit/dim 3.8410(3.8439) | Xent 1.0966(1.0485) | Loss 9.6177(10.2887) | Error 0.3789(0.3769) Steps 0(0.00) | Grad Norm 8.3302(10.5373) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 15.5468(16.5944) | Bit/dim 3.8591(3.8398) | Xent 1.0403(1.0360) | Loss 9.5217(10.1015) | Error 0.3611(0.3729) Steps 0(0.00) | Grad Norm 18.5794(10.6508) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 16.1194(16.5648) | Bit/dim 3.8488(3.8393) | Xent 1.0719(1.0354) | Loss 9.7008(9.9983) | Error 0.3756(0.3701) Steps 0(0.00) | Grad Norm 8.8944(10.6120) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 15.3304(16.5610) | Bit/dim 3.8164(3.8371) | Xent 1.0250(1.0302) | Loss 9.2722(9.8728) | Error 0.3644(0.3676) Steps 0(0.00) | Grad Norm 5.1759(10.6794) | Total Time 0.00(0.00)\n",
      "Iter 2250 | Time 16.4160(16.5017) | Bit/dim 3.8526(3.8351) | Xent 1.0727(1.0265) | Loss 9.7607(9.8301) | Error 0.3867(0.3666) Steps 0(0.00) | Grad Norm 6.4056(10.5097) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 84.9413, Epoch Time 1010.0842(950.8580), Bit/dim 3.8271(best: 3.8407), Xent 1.0051, Loss 4.3296, Error 0.3593(best: 0.3497)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2260 | Time 15.1996(16.4395) | Bit/dim 3.8274(3.8332) | Xent 0.9974(1.0313) | Loss 9.4648(10.3524) | Error 0.3622(0.3683) Steps 0(0.00) | Grad Norm 8.4141(10.5698) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 16.1459(16.4645) | Bit/dim 3.8165(3.8301) | Xent 0.8772(1.0195) | Loss 9.2893(10.1417) | Error 0.2967(0.3637) Steps 0(0.00) | Grad Norm 8.9103(9.9688) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 15.9728(16.4869) | Bit/dim 3.8521(3.8322) | Xent 1.0914(1.0433) | Loss 9.7274(10.0301) | Error 0.3822(0.3705) Steps 0(0.00) | Grad Norm 15.3724(12.3274) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 16.2211(16.5371) | Bit/dim 3.8471(3.8317) | Xent 1.0830(1.0520) | Loss 9.6685(9.9421) | Error 0.3844(0.3746) Steps 0(0.00) | Grad Norm 6.4191(11.3422) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 15.5541(16.5671) | Bit/dim 3.8038(3.8293) | Xent 1.0193(1.0424) | Loss 9.4560(9.8537) | Error 0.3933(0.3722) Steps 0(0.00) | Grad Norm 6.5079(10.4723) | Total Time 0.00(0.00)\n",
      "Iter 2310 | Time 16.1367(16.6253) | Bit/dim 3.8248(3.8262) | Xent 1.0783(1.0301) | Loss 9.8031(9.7952) | Error 0.3933(0.3674) Steps 0(0.00) | Grad Norm 9.2797(10.3579) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 84.5623, Epoch Time 1012.7659(952.7152), Bit/dim 3.8303(best: 3.8271), Xent 0.9723, Loss 4.3165, Error 0.3452(best: 0.3497)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2320 | Time 16.2882(16.7085) | Bit/dim 3.8392(3.8235) | Xent 0.9840(1.0181) | Loss 9.6425(10.2458) | Error 0.3544(0.3639) Steps 0(0.00) | Grad Norm 10.1679(10.4771) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 17.4080(16.7359) | Bit/dim 3.8020(3.8189) | Xent 1.0387(1.0085) | Loss 9.8593(10.0616) | Error 0.3822(0.3616) Steps 0(0.00) | Grad Norm 8.1702(10.1431) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 15.9832(16.6121) | Bit/dim 3.8035(3.8205) | Xent 1.0450(1.0065) | Loss 9.7693(9.9528) | Error 0.3622(0.3603) Steps 0(0.00) | Grad Norm 9.8565(10.2960) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 17.1133(16.6394) | Bit/dim 3.8531(3.8216) | Xent 1.0165(1.0107) | Loss 9.7842(9.8753) | Error 0.3567(0.3612) Steps 0(0.00) | Grad Norm 14.4136(10.5957) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 16.9575(16.6360) | Bit/dim 3.8087(3.8189) | Xent 1.0278(1.0138) | Loss 9.5948(9.8154) | Error 0.3578(0.3626) Steps 0(0.00) | Grad Norm 11.8912(10.1853) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 86.0118, Epoch Time 1018.8040(954.6979), Bit/dim 3.8232(best: 3.8271), Xent 0.9580, Loss 4.3022, Error 0.3374(best: 0.3452)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2370 | Time 17.8021(16.6270) | Bit/dim 3.8002(3.8193) | Xent 0.9573(1.0092) | Loss 9.6472(10.3485) | Error 0.3311(0.3592) Steps 0(0.00) | Grad Norm 9.7607(9.9062) | Total Time 0.00(0.00)\n",
      "Iter 2380 | Time 17.0098(16.5568) | Bit/dim 3.8194(3.8187) | Xent 0.9923(0.9971) | Loss 9.7086(10.1319) | Error 0.3578(0.3555) Steps 0(0.00) | Grad Norm 9.2061(9.7216) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 16.4596(16.4310) | Bit/dim 3.8225(3.8170) | Xent 1.0661(1.0009) | Loss 9.6038(9.9945) | Error 0.3744(0.3578) Steps 0(0.00) | Grad Norm 18.3111(11.4240) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 16.2850(16.4014) | Bit/dim 3.7960(3.8184) | Xent 0.9556(1.0026) | Loss 9.5612(9.8898) | Error 0.3367(0.3586) Steps 0(0.00) | Grad Norm 7.8853(11.7018) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 17.4850(16.3519) | Bit/dim 3.8018(3.8154) | Xent 1.0675(1.0048) | Loss 9.6496(9.7865) | Error 0.3867(0.3587) Steps 0(0.00) | Grad Norm 12.1914(11.2427) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 16.4305(16.4232) | Bit/dim 3.8117(3.8128) | Xent 1.0041(1.0108) | Loss 9.6870(9.7457) | Error 0.3633(0.3599) Steps 0(0.00) | Grad Norm 12.5816(11.4226) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 85.1946, Epoch Time 1002.8075(956.1412), Bit/dim 3.8084(best: 3.8232), Xent 0.9670, Loss 4.2919, Error 0.3400(best: 0.3374)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2430 | Time 16.9417(16.5129) | Bit/dim 3.7972(3.8118) | Xent 0.9498(0.9996) | Loss 9.6852(10.2185) | Error 0.3367(0.3562) Steps 0(0.00) | Grad Norm 6.2177(10.9716) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 18.1339(16.5795) | Bit/dim 3.7862(3.8096) | Xent 0.9902(0.9929) | Loss 9.5569(10.0471) | Error 0.3411(0.3555) Steps 0(0.00) | Grad Norm 15.5559(10.8093) | Total Time 0.00(0.00)\n",
      "Iter 2450 | Time 15.7623(16.5191) | Bit/dim 3.7676(3.8055) | Xent 1.0432(0.9945) | Loss 9.5671(9.9205) | Error 0.3656(0.3565) Steps 0(0.00) | Grad Norm 9.7415(10.5166) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 15.9480(16.4110) | Bit/dim 3.8203(3.8064) | Xent 0.9734(0.9881) | Loss 9.6526(9.8294) | Error 0.3422(0.3521) Steps 0(0.00) | Grad Norm 6.9388(9.7651) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 17.5257(16.4763) | Bit/dim 3.8040(3.8051) | Xent 1.0087(0.9867) | Loss 9.5663(9.7415) | Error 0.3656(0.3517) Steps 0(0.00) | Grad Norm 14.7602(9.6622) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 86.3827, Epoch Time 1015.8341(957.9320), Bit/dim 3.7991(best: 3.8084), Xent 0.9636, Loss 4.2809, Error 0.3403(best: 0.3374)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2480 | Time 14.8594(16.5351) | Bit/dim 3.8248(3.8069) | Xent 0.9984(0.9793) | Loss 9.2518(10.2848) | Error 0.3689(0.3494) Steps 0(0.00) | Grad Norm 11.0136(9.4996) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 15.7181(16.4510) | Bit/dim 3.8204(3.8072) | Xent 1.0659(0.9837) | Loss 9.6952(10.0915) | Error 0.3767(0.3505) Steps 0(0.00) | Grad Norm 18.6678(10.1595) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 16.1336(16.5062) | Bit/dim 3.8077(3.8053) | Xent 0.9667(0.9849) | Loss 9.5379(9.9377) | Error 0.3478(0.3526) Steps 0(0.00) | Grad Norm 19.0451(10.5809) | Total Time 0.00(0.00)\n",
      "Iter 2510 | Time 18.5415(16.5999) | Bit/dim 3.8338(3.8077) | Xent 0.9950(0.9857) | Loss 9.8672(9.8546) | Error 0.3333(0.3523) Steps 0(0.00) | Grad Norm 10.9557(10.7306) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 16.3083(16.5389) | Bit/dim 3.8140(3.8083) | Xent 1.0569(0.9939) | Loss 9.5593(9.7830) | Error 0.3811(0.3552) Steps 0(0.00) | Grad Norm 10.8996(11.5783) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 16.7029(16.6051) | Bit/dim 3.7164(3.8035) | Xent 1.1059(1.0050) | Loss 9.5701(9.7271) | Error 0.3756(0.3575) Steps 0(0.00) | Grad Norm 15.6966(11.7288) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 84.9909, Epoch Time 1015.4234(959.6567), Bit/dim 3.7993(best: 3.7991), Xent 0.9676, Loss 4.2832, Error 0.3395(best: 0.3374)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2540 | Time 17.4550(16.4699) | Bit/dim 3.8214(3.8040) | Xent 0.9692(0.9964) | Loss 9.3342(10.1835) | Error 0.3456(0.3562) Steps 0(0.00) | Grad Norm 8.7418(11.6707) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 17.4338(16.5718) | Bit/dim 3.8267(3.8059) | Xent 0.9236(0.9893) | Loss 9.6385(10.0188) | Error 0.3311(0.3554) Steps 0(0.00) | Grad Norm 11.4619(11.8401) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 17.3529(16.6068) | Bit/dim 3.8230(3.8017) | Xent 1.0068(0.9793) | Loss 9.5843(9.8638) | Error 0.3389(0.3509) Steps 0(0.00) | Grad Norm 12.8958(11.1031) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 16.1449(16.5714) | Bit/dim 3.8473(3.8010) | Xent 0.9698(0.9779) | Loss 9.4268(9.7748) | Error 0.3589(0.3499) Steps 0(0.00) | Grad Norm 13.6006(11.2813) | Total Time 0.00(0.00)\n",
      "Iter 2580 | Time 17.6797(16.5926) | Bit/dim 3.7945(3.7980) | Xent 1.0019(0.9871) | Loss 9.6998(9.7333) | Error 0.3456(0.3509) Steps 0(0.00) | Grad Norm 10.4968(11.5246) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 88.5292, Epoch Time 1019.9394(961.4652), Bit/dim 3.7955(best: 3.7991), Xent 1.0040, Loss 4.2974, Error 0.3584(best: 0.3374)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2590 | Time 18.4038(16.6824) | Bit/dim 3.7362(3.7922) | Xent 1.0069(0.9845) | Loss 9.4694(10.3058) | Error 0.3567(0.3510) Steps 0(0.00) | Grad Norm 6.2490(11.1875) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 16.3258(16.7311) | Bit/dim 3.7943(3.7921) | Xent 0.9335(0.9757) | Loss 9.2146(10.0638) | Error 0.3244(0.3483) Steps 0(0.00) | Grad Norm 6.8620(10.2335) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 16.6269(16.8262) | Bit/dim 3.7690(3.7903) | Xent 0.9226(0.9646) | Loss 9.5619(9.9093) | Error 0.3333(0.3451) Steps 0(0.00) | Grad Norm 4.5970(9.3949) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 15.2716(16.6611) | Bit/dim 3.8346(3.7904) | Xent 0.9413(0.9632) | Loss 9.4832(9.8097) | Error 0.3422(0.3455) Steps 0(0.00) | Grad Norm 15.3838(9.8134) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 15.3757(16.4409) | Bit/dim 3.7894(3.7911) | Xent 0.9381(0.9626) | Loss 9.4594(9.7162) | Error 0.3356(0.3441) Steps 0(0.00) | Grad Norm 11.2653(9.6995) | Total Time 0.00(0.00)\n",
      "Iter 2640 | Time 15.2167(16.3685) | Bit/dim 3.7378(3.7866) | Xent 0.9120(0.9578) | Loss 9.1711(9.6310) | Error 0.3378(0.3433) Steps 0(0.00) | Grad Norm 5.3753(9.4709) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 81.4635, Epoch Time 1006.2477(962.8087), Bit/dim 3.7870(best: 3.7955), Xent 0.9117, Loss 4.2428, Error 0.3186(best: 0.3374)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2650 | Time 16.4389(16.2410) | Bit/dim 3.7590(3.7870) | Xent 0.8971(0.9491) | Loss 9.5676(10.0822) | Error 0.3256(0.3404) Steps 0(0.00) | Grad Norm 7.2289(9.2936) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 17.3982(16.2433) | Bit/dim 3.7728(3.7880) | Xent 1.0144(0.9558) | Loss 9.5706(9.9327) | Error 0.3722(0.3428) Steps 0(0.00) | Grad Norm 15.9922(9.7919) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 16.3562(16.1820) | Bit/dim 3.7768(3.7862) | Xent 0.9394(0.9594) | Loss 9.5685(9.8194) | Error 0.3211(0.3427) Steps 0(0.00) | Grad Norm 8.0283(10.1592) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 16.0873(16.2889) | Bit/dim 3.7943(3.7843) | Xent 0.9297(0.9564) | Loss 9.5232(9.7279) | Error 0.3222(0.3405) Steps 0(0.00) | Grad Norm 9.2894(9.9856) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 16.2315(16.2527) | Bit/dim 3.7676(3.7829) | Xent 0.9852(0.9589) | Loss 9.6548(9.6708) | Error 0.3667(0.3428) Steps 0(0.00) | Grad Norm 12.4607(10.0907) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 84.0580, Epoch Time 991.5422(963.6707), Bit/dim 3.7825(best: 3.7870), Xent 0.9581, Loss 4.2616, Error 0.3366(best: 0.3186)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2700 | Time 15.0819(16.2545) | Bit/dim 3.7827(3.7848) | Xent 0.9385(0.9582) | Loss 9.4972(10.2613) | Error 0.3400(0.3437) Steps 0(0.00) | Grad Norm 10.2608(10.0055) | Total Time 0.00(0.00)\n",
      "Iter 2710 | Time 15.2945(16.1474) | Bit/dim 3.7692(3.7797) | Xent 0.9155(0.9524) | Loss 9.4820(10.0363) | Error 0.3322(0.3424) Steps 0(0.00) | Grad Norm 6.3064(9.4712) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 15.2830(16.1267) | Bit/dim 3.8104(3.7814) | Xent 0.9719(0.9474) | Loss 9.6040(9.8880) | Error 0.3356(0.3392) Steps 0(0.00) | Grad Norm 10.9935(9.3038) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 16.7055(16.1716) | Bit/dim 3.7659(3.7805) | Xent 0.9758(0.9522) | Loss 9.4014(9.7828) | Error 0.3500(0.3408) Steps 0(0.00) | Grad Norm 12.4530(9.6965) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 14.8475(16.2712) | Bit/dim 3.7715(3.7819) | Xent 0.9239(0.9491) | Loss 9.3869(9.7149) | Error 0.3211(0.3403) Steps 0(0.00) | Grad Norm 13.4844(9.9311) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 15.4634(16.1647) | Bit/dim 3.8051(3.7777) | Xent 0.9873(0.9474) | Loss 9.3524(9.6333) | Error 0.3467(0.3390) Steps 0(0.00) | Grad Norm 10.7486(10.0892) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 82.6625, Epoch Time 985.8329(964.3355), Bit/dim 3.7883(best: 3.7825), Xent 0.9543, Loss 4.2655, Error 0.3324(best: 0.3186)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2760 | Time 15.8329(16.1079) | Bit/dim 3.7657(3.7802) | Xent 0.8853(0.9409) | Loss 9.4424(10.0995) | Error 0.3222(0.3366) Steps 0(0.00) | Grad Norm 6.8047(11.0282) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 17.7122(16.1571) | Bit/dim 3.7815(3.7822) | Xent 0.9356(0.9458) | Loss 9.5171(9.9201) | Error 0.3333(0.3375) Steps 0(0.00) | Grad Norm 6.8057(11.0992) | Total Time 0.00(0.00)\n",
      "Iter 2780 | Time 15.6567(16.2051) | Bit/dim 3.7487(3.7812) | Xent 0.9240(0.9426) | Loss 9.2835(9.8122) | Error 0.3333(0.3379) Steps 0(0.00) | Grad Norm 7.1672(10.4242) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 16.4611(16.1752) | Bit/dim 3.7474(3.7792) | Xent 0.9828(0.9350) | Loss 9.5633(9.7277) | Error 0.3333(0.3336) Steps 0(0.00) | Grad Norm 4.7103(9.6442) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 15.3997(16.2010) | Bit/dim 3.7694(3.7740) | Xent 0.9444(0.9388) | Loss 9.2885(9.6589) | Error 0.3289(0.3352) Steps 0(0.00) | Grad Norm 8.5156(10.0064) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 79.9881, Epoch Time 984.3903(964.9372), Bit/dim 3.7720(best: 3.7825), Xent 0.8995, Loss 4.2217, Error 0.3120(best: 0.3186)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2810 | Time 17.2203(16.1862) | Bit/dim 3.7558(3.7751) | Xent 0.9646(0.9323) | Loss 9.6280(10.2061) | Error 0.3456(0.3330) Steps 0(0.00) | Grad Norm 17.0796(9.8795) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 15.6603(16.0999) | Bit/dim 3.7432(3.7715) | Xent 0.9094(0.9294) | Loss 9.2577(9.9773) | Error 0.3333(0.3325) Steps 0(0.00) | Grad Norm 8.9563(10.0182) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 14.5950(15.8654) | Bit/dim 3.7811(3.7730) | Xent 1.0226(0.9392) | Loss 9.4954(9.8324) | Error 0.3489(0.3363) Steps 0(0.00) | Grad Norm 20.3335(10.7796) | Total Time 0.00(0.00)\n",
      "Iter 2840 | Time 14.9587(15.8964) | Bit/dim 3.7732(3.7747) | Xent 0.9459(0.9474) | Loss 9.4861(9.7386) | Error 0.3211(0.3369) Steps 0(0.00) | Grad Norm 9.9726(11.3617) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 14.2790(15.8024) | Bit/dim 3.7942(3.7764) | Xent 0.9769(0.9437) | Loss 9.4868(9.6573) | Error 0.3367(0.3364) Steps 0(0.00) | Grad Norm 12.1490(11.0011) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 15.9476(15.9754) | Bit/dim 3.7437(3.7723) | Xent 0.9814(0.9417) | Loss 9.5231(9.5995) | Error 0.3567(0.3345) Steps 0(0.00) | Grad Norm 8.0764(10.6909) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 81.4603, Epoch Time 971.6801(965.1395), Bit/dim 3.7644(best: 3.7720), Xent 0.8975, Loss 4.2132, Error 0.3158(best: 0.3120)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2870 | Time 15.7906(16.0176) | Bit/dim 3.7370(3.7706) | Xent 0.9244(0.9265) | Loss 9.4834(10.0752) | Error 0.3156(0.3298) Steps 0(0.00) | Grad Norm 5.2781(9.8949) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 14.8779(16.0852) | Bit/dim 3.8126(3.7720) | Xent 0.9405(0.9276) | Loss 9.6605(9.9125) | Error 0.3389(0.3307) Steps 0(0.00) | Grad Norm 8.4591(9.7472) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 15.5799(16.0474) | Bit/dim 3.7270(3.7686) | Xent 0.8852(0.9251) | Loss 9.4077(9.7875) | Error 0.3022(0.3314) Steps 0(0.00) | Grad Norm 8.3836(9.2563) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 15.3017(15.9228) | Bit/dim 3.7620(3.7675) | Xent 1.0019(0.9291) | Loss 9.4583(9.6900) | Error 0.3689(0.3317) Steps 0(0.00) | Grad Norm 13.4616(10.0364) | Total Time 0.00(0.00)\n",
      "Iter 2910 | Time 15.6668(15.9074) | Bit/dim 3.7130(3.7663) | Xent 0.9357(0.9216) | Loss 9.3948(9.5928) | Error 0.3211(0.3290) Steps 0(0.00) | Grad Norm 6.2987(9.6117) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 80.5321, Epoch Time 971.0151(965.3157), Bit/dim 3.7677(best: 3.7644), Xent 0.9512, Loss 4.2433, Error 0.3370(best: 0.3120)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2920 | Time 16.4856(15.7983) | Bit/dim 3.7829(3.7669) | Xent 0.8621(0.9236) | Loss 9.4159(10.1148) | Error 0.3167(0.3293) Steps 0(0.00) | Grad Norm 7.7433(10.0119) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 15.4274(15.8051) | Bit/dim 3.7427(3.7656) | Xent 0.9051(0.9197) | Loss 9.2763(9.9355) | Error 0.3322(0.3278) Steps 0(0.00) | Grad Norm 9.7539(9.7404) | Total Time 0.00(0.00)\n",
      "Iter 2940 | Time 17.9871(15.9175) | Bit/dim 3.7509(3.7619) | Xent 0.8645(0.9079) | Loss 9.3764(9.7776) | Error 0.3144(0.3225) Steps 0(0.00) | Grad Norm 6.6495(9.3718) | Total Time 0.00(0.00)\n",
      "Iter 2950 | Time 15.4762(16.0179) | Bit/dim 3.7895(3.7627) | Xent 0.9206(0.9056) | Loss 9.2348(9.6640) | Error 0.3167(0.3199) Steps 0(0.00) | Grad Norm 7.4315(9.4583) | Total Time 0.00(0.00)\n",
      "Iter 2960 | Time 15.8501(16.0720) | Bit/dim 3.7621(3.7629) | Xent 0.9079(0.9096) | Loss 9.5608(9.5979) | Error 0.3256(0.3230) Steps 0(0.00) | Grad Norm 6.2004(9.1185) | Total Time 0.00(0.00)\n",
      "Iter 2970 | Time 17.2611(16.1469) | Bit/dim 3.7355(3.7613) | Xent 0.9278(0.9080) | Loss 9.5088(9.5352) | Error 0.3344(0.3234) Steps 0(0.00) | Grad Norm 7.5334(8.6907) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 81.7827, Epoch Time 986.1223(965.9399), Bit/dim 3.7581(best: 3.7644), Xent 0.8869, Loss 4.2015, Error 0.3127(best: 0.3120)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2980 | Time 15.5758(16.1719) | Bit/dim 3.7766(3.7598) | Xent 0.9135(0.9005) | Loss 9.4390(10.0196) | Error 0.3122(0.3215) Steps 0(0.00) | Grad Norm 4.2399(8.1641) | Total Time 0.00(0.00)\n",
      "Iter 2990 | Time 14.1196(15.9805) | Bit/dim 3.7673(3.7585) | Xent 0.9388(0.8982) | Loss 9.3910(9.8340) | Error 0.3511(0.3225) Steps 0(0.00) | Grad Norm 8.0642(8.3867) | Total Time 0.00(0.00)\n",
      "Iter 3000 | Time 15.1260(15.9276) | Bit/dim 3.7685(3.7556) | Xent 0.8557(0.8970) | Loss 9.1694(9.6923) | Error 0.3000(0.3220) Steps 0(0.00) | Grad Norm 6.3127(8.7937) | Total Time 0.00(0.00)\n",
      "Iter 3010 | Time 17.3062(15.9077) | Bit/dim 3.7649(3.7556) | Xent 0.8616(0.8946) | Loss 9.4934(9.6204) | Error 0.3022(0.3206) Steps 0(0.00) | Grad Norm 10.1267(9.3071) | Total Time 0.00(0.00)\n",
      "Iter 3020 | Time 17.2824(15.8787) | Bit/dim 3.7563(3.7548) | Xent 0.9037(0.8913) | Loss 9.4987(9.5578) | Error 0.3300(0.3193) Steps 0(0.00) | Grad Norm 10.7478(9.2987) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 81.7785, Epoch Time 968.5391(966.0179), Bit/dim 3.7491(best: 3.7581), Xent 0.8680, Loss 4.1831, Error 0.3060(best: 0.3120)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3030 | Time 16.2182(15.8326) | Bit/dim 3.7475(3.7523) | Xent 0.9218(0.8860) | Loss 9.5326(10.0874) | Error 0.3222(0.3172) Steps 0(0.00) | Grad Norm 9.7086(8.7696) | Total Time 0.00(0.00)\n",
      "Iter 3040 | Time 16.3955(15.7858) | Bit/dim 3.7552(3.7504) | Xent 0.9064(0.8866) | Loss 9.3878(9.8899) | Error 0.3444(0.3176) Steps 0(0.00) | Grad Norm 9.4678(9.1946) | Total Time 0.00(0.00)\n",
      "Iter 3050 | Time 16.1004(15.9469) | Bit/dim 3.7426(3.7491) | Xent 0.9242(0.8894) | Loss 9.3250(9.7443) | Error 0.3189(0.3182) Steps 0(0.00) | Grad Norm 6.9688(9.0234) | Total Time 0.00(0.00)\n",
      "Iter 3060 | Time 16.0137(16.1181) | Bit/dim 3.7603(3.7496) | Xent 1.0062(0.8882) | Loss 9.6935(9.6493) | Error 0.3444(0.3172) Steps 0(0.00) | Grad Norm 9.5870(9.4319) | Total Time 0.00(0.00)\n",
      "Iter 3070 | Time 16.5611(16.0560) | Bit/dim 3.7781(3.7500) | Xent 0.8926(0.8950) | Loss 9.3341(9.5697) | Error 0.3200(0.3189) Steps 0(0.00) | Grad Norm 6.1855(9.8566) | Total Time 0.00(0.00)\n",
      "Iter 3080 | Time 16.0170(16.0578) | Bit/dim 3.7601(3.7508) | Xent 0.9309(0.9019) | Loss 9.4140(9.5167) | Error 0.3422(0.3216) Steps 0(0.00) | Grad Norm 15.9933(9.7763) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 82.2734, Epoch Time 982.0219(966.4980), Bit/dim 3.7542(best: 3.7491), Xent 0.8845, Loss 4.1965, Error 0.3095(best: 0.3060)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3090 | Time 16.2607(16.1933) | Bit/dim 3.7499(3.7517) | Xent 0.8629(0.8973) | Loss 9.4117(10.0128) | Error 0.2989(0.3203) Steps 0(0.00) | Grad Norm 6.3413(9.5919) | Total Time 0.00(0.00)\n",
      "Iter 3100 | Time 16.7946(16.1187) | Bit/dim 3.7588(3.7533) | Xent 0.8758(0.8898) | Loss 9.3539(9.8333) | Error 0.3100(0.3175) Steps 0(0.00) | Grad Norm 7.7374(9.6638) | Total Time 0.00(0.00)\n",
      "Iter 3110 | Time 16.0016(15.9765) | Bit/dim 3.7203(3.7475) | Xent 0.9305(0.8895) | Loss 9.3949(9.6986) | Error 0.3278(0.3168) Steps 0(0.00) | Grad Norm 10.4784(9.7715) | Total Time 0.00(0.00)\n",
      "Iter 3120 | Time 14.9156(16.0775) | Bit/dim 3.7291(3.7484) | Xent 0.9296(0.8885) | Loss 9.2685(9.6088) | Error 0.3400(0.3159) Steps 0(0.00) | Grad Norm 8.8471(9.3939) | Total Time 0.00(0.00)\n",
      "Iter 3130 | Time 17.0366(15.9683) | Bit/dim 3.7533(3.7465) | Xent 0.9197(0.8864) | Loss 9.3696(9.5194) | Error 0.3333(0.3150) Steps 0(0.00) | Grad Norm 7.1096(9.1055) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 81.0994, Epoch Time 979.6531(966.8927), Bit/dim 3.7435(best: 3.7491), Xent 0.8722, Loss 4.1796, Error 0.3044(best: 0.3060)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3140 | Time 18.1775(16.0142) | Bit/dim 3.7483(3.7450) | Xent 0.8214(0.8840) | Loss 9.4340(10.0525) | Error 0.2767(0.3144) Steps 0(0.00) | Grad Norm 9.2524(9.3796) | Total Time 0.00(0.00)\n",
      "Iter 3150 | Time 17.3284(16.1756) | Bit/dim 3.7267(3.7436) | Xent 0.8956(0.8825) | Loss 9.2830(9.8613) | Error 0.3211(0.3146) Steps 0(0.00) | Grad Norm 8.5785(9.7755) | Total Time 0.00(0.00)\n",
      "Iter 3160 | Time 15.5831(16.1400) | Bit/dim 3.7340(3.7466) | Xent 0.8388(0.8797) | Loss 9.3495(9.7299) | Error 0.3056(0.3133) Steps 0(0.00) | Grad Norm 6.9147(10.0271) | Total Time 0.00(0.00)\n",
      "Iter 3170 | Time 16.5613(16.0127) | Bit/dim 3.7421(3.7432) | Xent 0.8714(0.8741) | Loss 9.3360(9.6211) | Error 0.3044(0.3119) Steps 0(0.00) | Grad Norm 9.1060(9.4858) | Total Time 0.00(0.00)\n",
      "Iter 3180 | Time 15.8704(16.0089) | Bit/dim 3.7170(3.7438) | Xent 0.9062(0.8797) | Loss 9.4398(9.5597) | Error 0.3311(0.3151) Steps 0(0.00) | Grad Norm 6.4268(9.6811) | Total Time 0.00(0.00)\n",
      "Iter 3190 | Time 15.7582(15.9739) | Bit/dim 3.7196(3.7440) | Xent 0.9252(0.8757) | Loss 9.5117(9.4892) | Error 0.3356(0.3127) Steps 0(0.00) | Grad Norm 7.8790(9.3183) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 82.1328, Epoch Time 980.6492(967.3054), Bit/dim 3.7468(best: 3.7435), Xent 0.8515, Loss 4.1726, Error 0.2973(best: 0.3044)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3200 | Time 16.5684(15.8843) | Bit/dim 3.7678(3.7431) | Xent 0.8245(0.8657) | Loss 9.2132(9.9629) | Error 0.2967(0.3095) Steps 0(0.00) | Grad Norm 9.1934(9.1455) | Total Time 0.00(0.00)\n",
      "Iter 3210 | Time 16.0559(16.0029) | Bit/dim 3.7636(3.7389) | Xent 0.9469(0.8677) | Loss 9.4392(9.7874) | Error 0.3478(0.3098) Steps 0(0.00) | Grad Norm 9.6214(9.4250) | Total Time 0.00(0.00)\n",
      "Iter 3220 | Time 16.5221(16.1229) | Bit/dim 3.7464(3.7359) | Xent 0.7787(0.8665) | Loss 9.1173(9.6580) | Error 0.2678(0.3082) Steps 0(0.00) | Grad Norm 7.8205(9.1316) | Total Time 0.00(0.00)\n",
      "Iter 3230 | Time 16.2880(16.1617) | Bit/dim 3.7630(3.7392) | Xent 0.9280(0.8667) | Loss 9.5407(9.5649) | Error 0.3267(0.3080) Steps 0(0.00) | Grad Norm 8.4902(8.9847) | Total Time 0.00(0.00)\n",
      "Iter 3240 | Time 16.4663(16.0943) | Bit/dim 3.7292(3.7390) | Xent 0.8703(0.8646) | Loss 9.3378(9.4959) | Error 0.2956(0.3087) Steps 0(0.00) | Grad Norm 7.2781(8.8908) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 81.8368, Epoch Time 981.4889(967.7309), Bit/dim 3.7384(best: 3.7435), Xent 0.8596, Loss 4.1682, Error 0.2995(best: 0.2973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3250 | Time 14.4011(15.8847) | Bit/dim 3.7543(3.7409) | Xent 1.0645(0.8765) | Loss 9.3898(10.0440) | Error 0.3733(0.3129) Steps 0(0.00) | Grad Norm 22.4913(10.3763) | Total Time 0.00(0.00)\n",
      "Iter 3260 | Time 15.9916(15.9481) | Bit/dim 3.7333(3.7507) | Xent 0.9334(0.8964) | Loss 9.1962(9.8884) | Error 0.3289(0.3203) Steps 0(0.00) | Grad Norm 12.5143(11.3288) | Total Time 0.00(0.00)\n",
      "Iter 3270 | Time 17.9050(16.1406) | Bit/dim 3.7640(3.7528) | Xent 0.8559(0.8936) | Loss 9.4097(9.7734) | Error 0.3022(0.3190) Steps 0(0.00) | Grad Norm 7.6732(10.8356) | Total Time 0.00(0.00)\n",
      "Iter 3280 | Time 17.0346(16.1692) | Bit/dim 3.7052(3.7499) | Xent 0.8865(0.8866) | Loss 9.1766(9.6533) | Error 0.3289(0.3183) Steps 0(0.00) | Grad Norm 9.8284(10.3353) | Total Time 0.00(0.00)\n",
      "Iter 3290 | Time 15.4273(16.1507) | Bit/dim 3.7477(3.7471) | Xent 0.8752(0.8838) | Loss 9.2783(9.5613) | Error 0.3167(0.3162) Steps 0(0.00) | Grad Norm 6.0346(9.7396) | Total Time 0.00(0.00)\n",
      "Iter 3300 | Time 15.5562(16.0797) | Bit/dim 3.7339(3.7424) | Xent 0.8006(0.8786) | Loss 9.2219(9.4746) | Error 0.2733(0.3135) Steps 0(0.00) | Grad Norm 7.1693(9.2867) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 81.6228, Epoch Time 984.5223(968.2346), Bit/dim 3.7320(best: 3.7384), Xent 0.8783, Loss 4.1711, Error 0.3035(best: 0.2973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3310 | Time 14.4211(16.0993) | Bit/dim 3.7426(3.7399) | Xent 0.8006(0.8674) | Loss 9.0854(9.9176) | Error 0.2933(0.3094) Steps 0(0.00) | Grad Norm 6.1336(8.7717) | Total Time 0.00(0.00)\n",
      "Iter 3320 | Time 15.5583(16.1088) | Bit/dim 3.7602(3.7368) | Xent 0.8471(0.8577) | Loss 9.2386(9.7437) | Error 0.3122(0.3062) Steps 0(0.00) | Grad Norm 8.1510(8.7446) | Total Time 0.00(0.00)\n",
      "Iter 3330 | Time 15.9478(16.0073) | Bit/dim 3.7522(3.7364) | Xent 0.9485(0.8596) | Loss 9.6243(9.6207) | Error 0.3411(0.3079) Steps 0(0.00) | Grad Norm 7.9864(8.6383) | Total Time 0.00(0.00)\n",
      "Iter 3340 | Time 15.3248(16.0939) | Bit/dim 3.7660(3.7355) | Xent 0.8168(0.8538) | Loss 9.2883(9.5225) | Error 0.2933(0.3059) Steps 0(0.00) | Grad Norm 13.1823(8.8476) | Total Time 0.00(0.00)\n",
      "Iter 3350 | Time 16.4072(16.1986) | Bit/dim 3.7348(3.7351) | Xent 0.8747(0.8610) | Loss 9.2894(9.4550) | Error 0.2956(0.3080) Steps 0(0.00) | Grad Norm 7.8187(9.4047) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 83.6147, Epoch Time 985.9007(968.7646), Bit/dim 3.7350(best: 3.7320), Xent 0.8455, Loss 4.1577, Error 0.2960(best: 0.2973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3360 | Time 15.6838(16.0337) | Bit/dim 3.7345(3.7348) | Xent 0.8142(0.8542) | Loss 9.2452(9.9926) | Error 0.2867(0.3051) Steps 0(0.00) | Grad Norm 7.1051(9.0880) | Total Time 0.00(0.00)\n",
      "Iter 3370 | Time 14.4613(15.8911) | Bit/dim 3.7195(3.7333) | Xent 0.8392(0.8521) | Loss 9.1187(9.7949) | Error 0.3078(0.3032) Steps 0(0.00) | Grad Norm 6.9096(8.6678) | Total Time 0.00(0.00)\n",
      "Iter 3380 | Time 15.9175(15.8741) | Bit/dim 3.7122(3.7339) | Xent 0.8817(0.8532) | Loss 9.1404(9.6730) | Error 0.3022(0.3045) Steps 0(0.00) | Grad Norm 7.3009(8.6478) | Total Time 0.00(0.00)\n",
      "Iter 3390 | Time 17.0689(15.9598) | Bit/dim 3.7464(3.7323) | Xent 0.8425(0.8467) | Loss 9.4023(9.5561) | Error 0.3100(0.3025) Steps 0(0.00) | Grad Norm 11.1590(8.9198) | Total Time 0.00(0.00)\n",
      "Iter 3400 | Time 16.3864(16.0542) | Bit/dim 3.7215(3.7286) | Xent 0.7631(0.8451) | Loss 9.0834(9.4529) | Error 0.2744(0.3025) Steps 0(0.00) | Grad Norm 7.7252(8.6714) | Total Time 0.00(0.00)\n",
      "Iter 3410 | Time 17.6225(16.1369) | Bit/dim 3.7234(3.7268) | Xent 0.8856(0.8508) | Loss 9.4297(9.4035) | Error 0.3267(0.3030) Steps 0(0.00) | Grad Norm 13.6613(8.4126) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 82.3111, Epoch Time 978.1612(969.0465), Bit/dim 3.7308(best: 3.7320), Xent 0.8778, Loss 4.1697, Error 0.3104(best: 0.2960)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3420 | Time 15.8610(15.9928) | Bit/dim 3.7164(3.7248) | Xent 0.7963(0.8582) | Loss 9.3086(9.9083) | Error 0.2956(0.3057) Steps 0(0.00) | Grad Norm 10.4966(9.1310) | Total Time 0.00(0.00)\n",
      "Iter 3430 | Time 15.8138(15.8637) | Bit/dim 3.7243(3.7284) | Xent 0.9229(0.8590) | Loss 9.3372(9.7481) | Error 0.3156(0.3045) Steps 0(0.00) | Grad Norm 20.5114(9.8487) | Total Time 0.00(0.00)\n",
      "Iter 3440 | Time 15.9446(15.9346) | Bit/dim 3.7093(3.7304) | Xent 0.8511(0.8553) | Loss 9.0695(9.6062) | Error 0.2833(0.3027) Steps 0(0.00) | Grad Norm 9.0171(9.5381) | Total Time 0.00(0.00)\n",
      "Iter 3450 | Time 16.0145(15.8893) | Bit/dim 3.7462(3.7315) | Xent 0.8126(0.8496) | Loss 9.1902(9.5077) | Error 0.2956(0.3006) Steps 0(0.00) | Grad Norm 8.6779(9.0731) | Total Time 0.00(0.00)\n",
      "Iter 3460 | Time 16.4370(15.9490) | Bit/dim 3.7156(3.7324) | Xent 0.8507(0.8465) | Loss 9.3307(9.4507) | Error 0.3022(0.3000) Steps 0(0.00) | Grad Norm 8.6022(9.5816) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 82.3974, Epoch Time 970.3069(969.0843), Bit/dim 3.7286(best: 3.7308), Xent 0.8577, Loss 4.1574, Error 0.3030(best: 0.2960)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3470 | Time 16.6436(15.9339) | Bit/dim 3.7554(3.7330) | Xent 0.8287(0.8478) | Loss 9.3093(10.0042) | Error 0.2956(0.3016) Steps 0(0.00) | Grad Norm 7.2845(9.7268) | Total Time 0.00(0.00)\n",
      "Iter 3480 | Time 15.2403(15.9820) | Bit/dim 3.7553(3.7336) | Xent 0.8450(0.8421) | Loss 9.2474(9.8196) | Error 0.2956(0.2982) Steps 0(0.00) | Grad Norm 9.5497(9.3578) | Total Time 0.00(0.00)\n",
      "Iter 3490 | Time 18.4378(15.9971) | Bit/dim 3.7597(3.7325) | Xent 0.8143(0.8404) | Loss 9.2881(9.6595) | Error 0.2800(0.2985) Steps 0(0.00) | Grad Norm 7.3717(9.2752) | Total Time 0.00(0.00)\n",
      "Iter 3500 | Time 15.6265(16.1142) | Bit/dim 3.7110(3.7261) | Xent 0.7744(0.8401) | Loss 9.1012(9.5506) | Error 0.2889(0.3001) Steps 0(0.00) | Grad Norm 5.0387(9.2075) | Total Time 0.00(0.00)\n",
      "Iter 3510 | Time 19.2264(16.3664) | Bit/dim 3.7181(3.7274) | Xent 0.8560(0.8352) | Loss 9.0569(9.4791) | Error 0.2933(0.2973) Steps 0(0.00) | Grad Norm 7.9084(8.6445) | Total Time 0.00(0.00)\n",
      "Iter 3520 | Time 15.7998(16.1625) | Bit/dim 3.7628(3.7234) | Xent 0.8447(0.8326) | Loss 9.2820(9.4234) | Error 0.3100(0.2968) Steps 0(0.00) | Grad Norm 9.0943(8.5215) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 83.6933, Epoch Time 990.6845(969.7323), Bit/dim 3.7295(best: 3.7286), Xent 0.8481, Loss 4.1536, Error 0.2983(best: 0.2960)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3530 | Time 14.0463(16.2417) | Bit/dim 3.7813(3.7204) | Xent 0.7545(0.8236) | Loss 9.2789(9.9129) | Error 0.2689(0.2944) Steps 0(0.00) | Grad Norm 5.4483(8.2273) | Total Time 0.00(0.00)\n",
      "Iter 3540 | Time 17.6057(16.3146) | Bit/dim 3.7010(3.7198) | Xent 0.8069(0.8241) | Loss 9.1112(9.7473) | Error 0.2989(0.2954) Steps 0(0.00) | Grad Norm 8.5405(8.6738) | Total Time 0.00(0.00)\n",
      "Iter 3550 | Time 17.5397(16.2419) | Bit/dim 3.6983(3.7184) | Xent 0.8096(0.8220) | Loss 9.1326(9.6031) | Error 0.2978(0.2953) Steps 0(0.00) | Grad Norm 5.4782(8.3505) | Total Time 0.00(0.00)\n",
      "Iter 3560 | Time 15.1112(16.1565) | Bit/dim 3.7067(3.7205) | Xent 0.8585(0.8204) | Loss 9.2742(9.5058) | Error 0.3011(0.2935) Steps 0(0.00) | Grad Norm 15.1350(8.5163) | Total Time 0.00(0.00)\n",
      "Iter 3570 | Time 17.9158(16.2960) | Bit/dim 3.7619(3.7216) | Xent 0.8948(0.8305) | Loss 9.5884(9.4437) | Error 0.3356(0.2981) Steps 0(0.00) | Grad Norm 9.7536(9.0328) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 85.1268, Epoch Time 1003.4627(970.7442), Bit/dim 3.7220(best: 3.7286), Xent 0.8759, Loss 4.1599, Error 0.3099(best: 0.2960)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3580 | Time 15.2831(16.2719) | Bit/dim 3.7242(3.7230) | Xent 0.7992(0.8314) | Loss 9.2073(9.9842) | Error 0.2778(0.2967) Steps 0(0.00) | Grad Norm 16.2283(9.6416) | Total Time 0.00(0.00)\n",
      "Iter 3590 | Time 16.5153(16.1291) | Bit/dim 3.6975(3.7208) | Xent 0.8220(0.8315) | Loss 9.2361(9.7783) | Error 0.2922(0.2964) Steps 0(0.00) | Grad Norm 4.9212(9.8140) | Total Time 0.00(0.00)\n",
      "Iter 3600 | Time 16.3236(16.0807) | Bit/dim 3.7027(3.7200) | Xent 0.7952(0.8271) | Loss 9.2418(9.6517) | Error 0.2711(0.2944) Steps 0(0.00) | Grad Norm 8.2076(9.4983) | Total Time 0.00(0.00)\n",
      "Iter 3610 | Time 16.8419(16.0364) | Bit/dim 3.7300(3.7229) | Xent 0.7623(0.8234) | Loss 9.2790(9.5598) | Error 0.2822(0.2945) Steps 0(0.00) | Grad Norm 6.7002(9.8770) | Total Time 0.00(0.00)\n",
      "Iter 3620 | Time 15.5741(15.9283) | Bit/dim 3.7268(3.7202) | Xent 0.8373(0.8253) | Loss 9.2754(9.4806) | Error 0.3144(0.2970) Steps 0(0.00) | Grad Norm 10.9612(9.2421) | Total Time 0.00(0.00)\n",
      "Iter 3630 | Time 15.1202(15.9119) | Bit/dim 3.7169(3.7178) | Xent 0.8540(0.8210) | Loss 9.2634(9.4032) | Error 0.2933(0.2941) Steps 0(0.00) | Grad Norm 9.7264(8.8157) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 83.0838, Epoch Time 966.9945(970.6317), Bit/dim 3.7079(best: 3.7220), Xent 0.8356, Loss 4.1257, Error 0.2935(best: 0.2960)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3640 | Time 14.8754(15.9567) | Bit/dim 3.7445(3.7178) | Xent 0.8477(0.8161) | Loss 9.2460(9.8554) | Error 0.3022(0.2931) Steps 0(0.00) | Grad Norm 11.4172(9.2016) | Total Time 0.00(0.00)\n",
      "Iter 3650 | Time 15.7841(16.1153) | Bit/dim 3.7380(3.7160) | Xent 0.8519(0.8226) | Loss 9.4129(9.6947) | Error 0.3022(0.2945) Steps 0(0.00) | Grad Norm 12.4021(9.9674) | Total Time 0.00(0.00)\n",
      "Iter 3660 | Time 17.2508(16.1198) | Bit/dim 3.6941(3.7168) | Xent 0.7695(0.8152) | Loss 9.2556(9.5593) | Error 0.2833(0.2928) Steps 0(0.00) | Grad Norm 9.9629(9.7004) | Total Time 0.00(0.00)\n",
      "Iter 3670 | Time 14.7968(16.0294) | Bit/dim 3.7179(3.7185) | Xent 0.9112(0.8148) | Loss 9.3619(9.4732) | Error 0.3244(0.2910) Steps 0(0.00) | Grad Norm 8.2103(9.7747) | Total Time 0.00(0.00)\n",
      "Iter 3680 | Time 16.4624(16.0874) | Bit/dim 3.6925(3.7183) | Xent 0.8236(0.8150) | Loss 9.2492(9.4201) | Error 0.2933(0.2906) Steps 0(0.00) | Grad Norm 7.8433(9.4172) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 83.5598, Epoch Time 988.3843(971.1643), Bit/dim 3.7125(best: 3.7079), Xent 0.8200, Loss 4.1226, Error 0.2888(best: 0.2935)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3690 | Time 15.3624(16.0940) | Bit/dim 3.7296(3.7200) | Xent 0.8557(0.8195) | Loss 9.3638(9.9759) | Error 0.3067(0.2921) Steps 0(0.00) | Grad Norm 11.0165(8.9245) | Total Time 0.00(0.00)\n",
      "Iter 3700 | Time 15.4379(16.0064) | Bit/dim 3.7230(3.7161) | Xent 0.8313(0.8168) | Loss 9.3766(9.7737) | Error 0.3056(0.2926) Steps 0(0.00) | Grad Norm 9.8139(8.9143) | Total Time 0.00(0.00)\n",
      "Iter 3710 | Time 15.0220(15.9619) | Bit/dim 3.7316(3.7193) | Xent 0.8614(0.8082) | Loss 9.0283(9.6203) | Error 0.3200(0.2897) Steps 0(0.00) | Grad Norm 7.0171(8.5846) | Total Time 0.00(0.00)\n",
      "Iter 3720 | Time 15.3428(16.0786) | Bit/dim 3.7280(3.7170) | Xent 0.7865(0.8075) | Loss 9.1903(9.5171) | Error 0.2822(0.2892) Steps 0(0.00) | Grad Norm 7.3563(9.0403) | Total Time 0.00(0.00)\n",
      "Iter 3730 | Time 15.8787(16.0438) | Bit/dim 3.6740(3.7155) | Xent 0.8387(0.8081) | Loss 9.1775(9.4460) | Error 0.2889(0.2893) Steps 0(0.00) | Grad Norm 10.8641(9.0797) | Total Time 0.00(0.00)\n",
      "Iter 3740 | Time 15.4436(15.9390) | Bit/dim 3.7296(3.7136) | Xent 0.8149(0.8082) | Loss 9.3934(9.3865) | Error 0.2944(0.2891) Steps 0(0.00) | Grad Norm 13.0822(9.0253) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 82.9187, Epoch Time 975.3904(971.2911), Bit/dim 3.7069(best: 3.7079), Xent 0.8179, Loss 4.1158, Error 0.2895(best: 0.2888)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3750 | Time 15.2354(15.7236) | Bit/dim 3.7007(3.7128) | Xent 0.7885(0.8033) | Loss 9.2504(9.8660) | Error 0.2778(0.2872) Steps 0(0.00) | Grad Norm 5.3312(8.2342) | Total Time 0.00(0.00)\n",
      "Iter 3760 | Time 17.8567(15.9280) | Bit/dim 3.7224(3.7112) | Xent 0.7953(0.7988) | Loss 9.5556(9.6906) | Error 0.2778(0.2851) Steps 0(0.00) | Grad Norm 9.6125(8.1649) | Total Time 0.00(0.00)\n",
      "Iter 3770 | Time 16.6896(15.8780) | Bit/dim 3.7408(3.7101) | Xent 0.8011(0.8052) | Loss 9.3560(9.5643) | Error 0.2789(0.2866) Steps 0(0.00) | Grad Norm 15.0955(8.6760) | Total Time 0.00(0.00)\n",
      "Iter 3780 | Time 16.9973(15.9480) | Bit/dim 3.6824(3.7096) | Xent 0.8105(0.8055) | Loss 9.1668(9.4687) | Error 0.2900(0.2892) Steps 0(0.00) | Grad Norm 8.9815(9.3888) | Total Time 0.00(0.00)\n",
      "Iter 3790 | Time 16.3398(16.0379) | Bit/dim 3.7262(3.7108) | Xent 0.7996(0.8091) | Loss 9.4110(9.4122) | Error 0.2800(0.2912) Steps 0(0.00) | Grad Norm 6.5812(9.5793) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 83.4016, Epoch Time 973.6622(971.3622), Bit/dim 3.7168(best: 3.7069), Xent 0.8263, Loss 4.1299, Error 0.2932(best: 0.2888)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3800 | Time 15.0448(15.9460) | Bit/dim 3.7128(3.7120) | Xent 0.8063(0.8054) | Loss 9.2522(9.9859) | Error 0.2833(0.2899) Steps 0(0.00) | Grad Norm 4.9710(9.0484) | Total Time 0.00(0.00)\n",
      "Iter 3810 | Time 15.2365(15.9004) | Bit/dim 3.7491(3.7108) | Xent 0.7469(0.8009) | Loss 9.0178(9.7552) | Error 0.2600(0.2879) Steps 0(0.00) | Grad Norm 7.7363(9.0094) | Total Time 0.00(0.00)\n",
      "Iter 3820 | Time 15.0771(15.9214) | Bit/dim 3.6765(3.7121) | Xent 0.8038(0.8042) | Loss 9.1645(9.6273) | Error 0.2967(0.2889) Steps 0(0.00) | Grad Norm 9.5193(9.0062) | Total Time 0.00(0.00)\n",
      "Iter 3830 | Time 15.4808(16.1046) | Bit/dim 3.7287(3.7115) | Xent 0.7885(0.7986) | Loss 9.1059(9.5081) | Error 0.2900(0.2867) Steps 0(0.00) | Grad Norm 9.0839(9.1585) | Total Time 0.00(0.00)\n",
      "Iter 3840 | Time 15.6858(15.9430) | Bit/dim 3.6828(3.7100) | Xent 0.8797(0.7986) | Loss 9.3678(9.4260) | Error 0.3144(0.2868) Steps 0(0.00) | Grad Norm 10.1260(9.2244) | Total Time 0.00(0.00)\n",
      "Iter 3850 | Time 15.2858(15.9211) | Bit/dim 3.7314(3.7089) | Xent 0.8109(0.7987) | Loss 9.0553(9.3486) | Error 0.3000(0.2864) Steps 0(0.00) | Grad Norm 9.2875(8.7098) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 85.3986, Epoch Time 979.0293(971.5923), Bit/dim 3.7125(best: 3.7069), Xent 0.8556, Loss 4.1403, Error 0.3053(best: 0.2888)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3860 | Time 16.7010(15.9050) | Bit/dim 3.7148(3.7090) | Xent 0.7809(0.8005) | Loss 9.1469(9.8366) | Error 0.2756(0.2873) Steps 0(0.00) | Grad Norm 10.3724(9.7727) | Total Time 0.00(0.00)\n",
      "Iter 3870 | Time 16.3346(15.8646) | Bit/dim 3.7105(3.7122) | Xent 0.8130(0.8011) | Loss 9.2329(9.6742) | Error 0.2900(0.2863) Steps 0(0.00) | Grad Norm 7.4316(10.1128) | Total Time 0.00(0.00)\n",
      "Iter 3880 | Time 16.7271(15.9378) | Bit/dim 3.6859(3.7087) | Xent 0.7422(0.7994) | Loss 9.0656(9.5516) | Error 0.2689(0.2865) Steps 0(0.00) | Grad Norm 10.0900(10.0459) | Total Time 0.00(0.00)\n",
      "Iter 3890 | Time 14.8813(15.9441) | Bit/dim 3.7307(3.7083) | Xent 0.8192(0.8011) | Loss 9.2267(9.4589) | Error 0.2667(0.2858) Steps 0(0.00) | Grad Norm 8.2410(9.8472) | Total Time 0.00(0.00)\n",
      "Iter 3900 | Time 15.1995(16.0928) | Bit/dim 3.7019(3.7071) | Xent 0.7114(0.7884) | Loss 9.0836(9.3889) | Error 0.2556(0.2820) Steps 0(0.00) | Grad Norm 5.5924(9.1042) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 85.2273, Epoch Time 982.4722(971.9187), Bit/dim 3.7137(best: 3.7069), Xent 0.8474, Loss 4.1374, Error 0.2984(best: 0.2888)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3910 | Time 15.9284(16.0281) | Bit/dim 3.6933(3.7049) | Xent 0.8178(0.7861) | Loss 9.1539(9.9652) | Error 0.2856(0.2807) Steps 0(0.00) | Grad Norm 8.0687(9.3061) | Total Time 0.00(0.00)\n",
      "Iter 3920 | Time 15.7560(16.1043) | Bit/dim 3.7091(3.7044) | Xent 0.8404(0.7907) | Loss 9.1758(9.7498) | Error 0.2922(0.2817) Steps 0(0.00) | Grad Norm 7.4665(9.0915) | Total Time 0.00(0.00)\n",
      "Iter 3930 | Time 16.7167(16.1829) | Bit/dim 3.7368(3.7048) | Xent 0.6861(0.7894) | Loss 9.1273(9.5934) | Error 0.2400(0.2816) Steps 0(0.00) | Grad Norm 6.6211(9.0935) | Total Time 0.00(0.00)\n",
      "Iter 3940 | Time 18.3075(16.2239) | Bit/dim 3.7015(3.7048) | Xent 0.7679(0.7827) | Loss 9.0998(9.4688) | Error 0.2867(0.2797) Steps 0(0.00) | Grad Norm 9.5746(9.0048) | Total Time 0.00(0.00)\n",
      "Iter 3950 | Time 16.7752(16.0731) | Bit/dim 3.7038(3.7056) | Xent 0.8056(0.7881) | Loss 9.3116(9.3761) | Error 0.2878(0.2814) Steps 0(0.00) | Grad Norm 18.8152(10.0654) | Total Time 0.00(0.00)\n",
      "Iter 3960 | Time 14.8358(16.0902) | Bit/dim 3.6954(3.7058) | Xent 0.7799(0.7862) | Loss 9.1897(9.3391) | Error 0.2767(0.2809) Steps 0(0.00) | Grad Norm 8.0638(9.4619) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 85.1103, Epoch Time 988.6362(972.4202), Bit/dim 3.7056(best: 3.7069), Xent 0.8118, Loss 4.1115, Error 0.2824(best: 0.2888)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3970 | Time 14.8381(16.0302) | Bit/dim 3.6918(3.7048) | Xent 0.7473(0.7798) | Loss 9.1828(9.8296) | Error 0.2589(0.2781) Steps 0(0.00) | Grad Norm 8.5915(8.7367) | Total Time 0.00(0.00)\n",
      "Iter 3980 | Time 15.1728(16.0048) | Bit/dim 3.7288(3.7054) | Xent 0.7538(0.7797) | Loss 8.7979(9.6482) | Error 0.2611(0.2775) Steps 0(0.00) | Grad Norm 8.8639(9.4461) | Total Time 0.00(0.00)\n",
      "Iter 3990 | Time 16.8777(15.9857) | Bit/dim 3.6772(3.7070) | Xent 0.7481(0.7757) | Loss 9.0979(9.5245) | Error 0.2789(0.2759) Steps 0(0.00) | Grad Norm 6.3497(9.1077) | Total Time 0.00(0.00)\n",
      "Iter 4000 | Time 16.0064(16.0148) | Bit/dim 3.6637(3.7027) | Xent 0.8235(0.7766) | Loss 9.2943(9.4280) | Error 0.2978(0.2771) Steps 0(0.00) | Grad Norm 12.6078(8.8983) | Total Time 0.00(0.00)\n",
      "Iter 4010 | Time 17.5827(16.0369) | Bit/dim 3.6814(3.7059) | Xent 0.7233(0.7798) | Loss 9.2746(9.3676) | Error 0.2478(0.2791) Steps 0(0.00) | Grad Norm 6.1315(9.1925) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 84.4479, Epoch Time 980.8908(972.6743), Bit/dim 3.6915(best: 3.7056), Xent 0.8368, Loss 4.1099, Error 0.2964(best: 0.2824)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4020 | Time 15.0168(16.0225) | Bit/dim 3.7179(3.7073) | Xent 0.7406(0.7752) | Loss 9.2192(9.9253) | Error 0.2778(0.2784) Steps 0(0.00) | Grad Norm 11.0730(8.7962) | Total Time 0.00(0.00)\n",
      "Iter 4030 | Time 16.7300(16.0736) | Bit/dim 3.7139(3.7057) | Xent 0.7398(0.7809) | Loss 9.3189(9.7479) | Error 0.2567(0.2804) Steps 0(0.00) | Grad Norm 6.3025(9.4706) | Total Time 0.00(0.00)\n",
      "Iter 4040 | Time 14.7226(15.9832) | Bit/dim 3.7174(3.7049) | Xent 0.7054(0.7771) | Loss 9.1662(9.5874) | Error 0.2567(0.2784) Steps 0(0.00) | Grad Norm 6.5109(8.9251) | Total Time 0.00(0.00)\n",
      "Iter 4050 | Time 16.8674(15.9153) | Bit/dim 3.6599(3.7026) | Xent 0.7582(0.7706) | Loss 9.0567(9.4529) | Error 0.2567(0.2740) Steps 0(0.00) | Grad Norm 6.3651(8.1607) | Total Time 0.00(0.00)\n",
      "Iter 4060 | Time 16.4088(16.0502) | Bit/dim 3.7041(3.7013) | Xent 0.8017(0.7673) | Loss 9.1483(9.3785) | Error 0.2900(0.2739) Steps 0(0.00) | Grad Norm 10.5929(7.8942) | Total Time 0.00(0.00)\n",
      "Iter 4070 | Time 15.3950(16.0372) | Bit/dim 3.6812(3.6970) | Xent 0.7521(0.7713) | Loss 9.2435(9.3129) | Error 0.2811(0.2760) Steps 0(0.00) | Grad Norm 5.4651(8.0189) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 85.5744, Epoch Time 982.6863(972.9747), Bit/dim 3.6990(best: 3.6915), Xent 0.8386, Loss 4.1183, Error 0.2937(best: 0.2824)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4080 | Time 15.7350(16.0587) | Bit/dim 3.7154(3.6952) | Xent 0.7119(0.7631) | Loss 8.8941(9.7933) | Error 0.2789(0.2720) Steps 0(0.00) | Grad Norm 7.6507(8.1467) | Total Time 0.00(0.00)\n",
      "Iter 4090 | Time 20.1043(16.1984) | Bit/dim 3.7107(3.6972) | Xent 0.7856(0.7666) | Loss 9.2681(9.6245) | Error 0.2867(0.2745) Steps 0(0.00) | Grad Norm 7.2338(7.9136) | Total Time 0.00(0.00)\n",
      "Iter 4100 | Time 15.2362(16.2604) | Bit/dim 3.6902(3.6952) | Xent 0.7128(0.7603) | Loss 8.9221(9.4897) | Error 0.2433(0.2707) Steps 0(0.00) | Grad Norm 7.5186(7.6270) | Total Time 0.00(0.00)\n",
      "Iter 4110 | Time 17.1354(16.2992) | Bit/dim 3.6900(3.6966) | Xent 0.7381(0.7525) | Loss 9.1119(9.3931) | Error 0.2622(0.2688) Steps 0(0.00) | Grad Norm 5.3548(7.9141) | Total Time 0.00(0.00)\n",
      "Iter 4120 | Time 16.5201(16.2741) | Bit/dim 3.6843(3.6955) | Xent 0.7351(0.7557) | Loss 8.9786(9.3136) | Error 0.2678(0.2699) Steps 0(0.00) | Grad Norm 8.2431(8.5389) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 85.2607, Epoch Time 1000.4637(973.7993), Bit/dim 3.7052(best: 3.6915), Xent 0.8210, Loss 4.1157, Error 0.2906(best: 0.2824)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4130 | Time 18.0471(16.3985) | Bit/dim 3.6622(3.6921) | Xent 0.8654(0.7659) | Loss 9.3311(9.8900) | Error 0.3144(0.2748) Steps 0(0.00) | Grad Norm 12.8529(9.0489) | Total Time 0.00(0.00)\n",
      "Iter 4140 | Time 18.5615(16.5592) | Bit/dim 3.6836(3.6938) | Xent 0.8753(0.7677) | Loss 9.3761(9.6823) | Error 0.3100(0.2743) Steps 0(0.00) | Grad Norm 15.4812(9.3900) | Total Time 0.00(0.00)\n",
      "Iter 4150 | Time 15.2994(16.4394) | Bit/dim 3.7275(3.7000) | Xent 0.7678(0.7675) | Loss 9.1784(9.5572) | Error 0.2789(0.2745) Steps 0(0.00) | Grad Norm 8.8348(9.5016) | Total Time 0.00(0.00)\n",
      "Iter 4160 | Time 14.8232(16.3230) | Bit/dim 3.7006(3.6989) | Xent 0.7612(0.7646) | Loss 9.1472(9.4463) | Error 0.2722(0.2728) Steps 0(0.00) | Grad Norm 8.2018(8.9462) | Total Time 0.00(0.00)\n",
      "Iter 4170 | Time 15.3453(16.2992) | Bit/dim 3.6703(3.6974) | Xent 0.7783(0.7615) | Loss 9.1458(9.3645) | Error 0.2678(0.2723) Steps 0(0.00) | Grad Norm 6.4608(8.3014) | Total Time 0.00(0.00)\n",
      "Iter 4180 | Time 15.9912(16.2274) | Bit/dim 3.7223(3.6937) | Xent 0.7670(0.7583) | Loss 8.9852(9.2830) | Error 0.2767(0.2728) Steps 0(0.00) | Grad Norm 6.0975(8.0811) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 85.5870, Epoch Time 1000.0824(974.5878), Bit/dim 3.6955(best: 3.6915), Xent 0.7820, Loss 4.0865, Error 0.2759(best: 0.2824)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4190 | Time 15.4408(16.1513) | Bit/dim 3.7225(3.6923) | Xent 0.6891(0.7482) | Loss 8.9095(9.7264) | Error 0.2367(0.2694) Steps 0(0.00) | Grad Norm 4.8622(7.5489) | Total Time 0.00(0.00)\n",
      "Iter 4200 | Time 16.3152(16.1050) | Bit/dim 3.7023(3.6908) | Xent 0.7464(0.7439) | Loss 9.1449(9.5607) | Error 0.2656(0.2685) Steps 0(0.00) | Grad Norm 6.3000(7.3089) | Total Time 0.00(0.00)\n",
      "Iter 4210 | Time 17.3019(16.1366) | Bit/dim 3.6933(3.6904) | Xent 0.6885(0.7390) | Loss 9.1547(9.4465) | Error 0.2356(0.2664) Steps 0(0.00) | Grad Norm 4.9253(7.3329) | Total Time 0.00(0.00)\n",
      "Iter 4220 | Time 15.7754(16.1608) | Bit/dim 3.7091(3.6903) | Xent 0.8402(0.7411) | Loss 9.1939(9.3524) | Error 0.2878(0.2664) Steps 0(0.00) | Grad Norm 13.8005(7.9821) | Total Time 0.00(0.00)\n",
      "Iter 4230 | Time 15.0116(16.1569) | Bit/dim 3.6991(3.6926) | Xent 0.7876(0.7507) | Loss 9.3022(9.2976) | Error 0.2700(0.2682) Steps 0(0.00) | Grad Norm 9.2358(8.2653) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 86.7223, Epoch Time 990.5697(975.0673), Bit/dim 3.7038(best: 3.6915), Xent 0.7889, Loss 4.0982, Error 0.2793(best: 0.2759)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4240 | Time 17.9914(16.2558) | Bit/dim 3.7295(3.6937) | Xent 0.7233(0.7495) | Loss 9.1185(9.8545) | Error 0.2600(0.2678) Steps 0(0.00) | Grad Norm 8.6038(8.4958) | Total Time 0.00(0.00)\n",
      "Iter 4250 | Time 17.2334(16.2737) | Bit/dim 3.6634(3.6920) | Xent 0.7886(0.7490) | Loss 9.1285(9.6504) | Error 0.2867(0.2679) Steps 0(0.00) | Grad Norm 8.7155(8.1307) | Total Time 0.00(0.00)\n",
      "Iter 4260 | Time 18.1436(16.3614) | Bit/dim 3.6978(3.6922) | Xent 0.7449(0.7465) | Loss 9.1267(9.4995) | Error 0.2567(0.2661) Steps 0(0.00) | Grad Norm 5.4345(7.7807) | Total Time 0.00(0.00)\n",
      "Iter 4270 | Time 16.2179(16.5501) | Bit/dim 3.7398(3.6927) | Xent 0.6892(0.7485) | Loss 9.0724(9.3907) | Error 0.2478(0.2674) Steps 0(0.00) | Grad Norm 10.4906(8.0568) | Total Time 0.00(0.00)\n",
      "Iter 4280 | Time 16.4651(16.4915) | Bit/dim 3.7361(3.6954) | Xent 0.7521(0.7452) | Loss 9.2996(9.3296) | Error 0.2756(0.2664) Steps 0(0.00) | Grad Norm 8.8405(8.3245) | Total Time 0.00(0.00)\n",
      "Iter 4290 | Time 15.8544(16.6017) | Bit/dim 3.6662(3.6913) | Xent 0.6581(0.7406) | Loss 8.9796(9.2695) | Error 0.2433(0.2661) Steps 0(0.00) | Grad Norm 5.5901(7.8184) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 84.8986, Epoch Time 1016.1275(976.2991), Bit/dim 3.6876(best: 3.6915), Xent 0.7698, Loss 4.0725, Error 0.2695(best: 0.2759)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4300 | Time 15.4289(16.5970) | Bit/dim 3.7036(3.6886) | Xent 0.6995(0.7319) | Loss 8.7544(9.7452) | Error 0.2578(0.2634) Steps 0(0.00) | Grad Norm 6.1074(7.7100) | Total Time 0.00(0.00)\n",
      "Iter 4310 | Time 17.7392(16.6484) | Bit/dim 3.6832(3.6887) | Xent 0.8166(0.7326) | Loss 9.2101(9.5865) | Error 0.2889(0.2624) Steps 0(0.00) | Grad Norm 12.5691(7.9896) | Total Time 0.00(0.00)\n",
      "Iter 4320 | Time 16.3192(16.6313) | Bit/dim 3.6991(3.6884) | Xent 0.7480(0.7398) | Loss 9.1147(9.4490) | Error 0.2667(0.2660) Steps 0(0.00) | Grad Norm 6.9109(8.4587) | Total Time 0.00(0.00)\n",
      "Iter 4330 | Time 16.4722(16.4821) | Bit/dim 3.7193(3.6904) | Xent 0.7242(0.7373) | Loss 9.1634(9.3444) | Error 0.2756(0.2673) Steps 0(0.00) | Grad Norm 7.7074(8.6264) | Total Time 0.00(0.00)\n",
      "Iter 4340 | Time 16.8457(16.5627) | Bit/dim 3.6767(3.6879) | Xent 0.7662(0.7454) | Loss 9.0831(9.2929) | Error 0.2733(0.2691) Steps 0(0.00) | Grad Norm 9.4635(9.4293) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 86.7772, Epoch Time 1017.8746(977.5463), Bit/dim 3.7021(best: 3.6876), Xent 0.8249, Loss 4.1146, Error 0.2928(best: 0.2695)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4350 | Time 17.0253(16.6819) | Bit/dim 3.6978(3.6925) | Xent 0.7593(0.7612) | Loss 9.0207(9.8958) | Error 0.2633(0.2739) Steps 0(0.00) | Grad Norm 12.7956(10.1518) | Total Time 0.00(0.00)\n",
      "Iter 4360 | Time 16.1714(16.5886) | Bit/dim 3.6481(3.6914) | Xent 0.7134(0.7561) | Loss 9.1670(9.6962) | Error 0.2578(0.2730) Steps 0(0.00) | Grad Norm 9.0765(9.7664) | Total Time 0.00(0.00)\n",
      "Iter 4370 | Time 15.4769(16.4063) | Bit/dim 3.6988(3.6950) | Xent 0.7376(0.7569) | Loss 8.8918(9.5387) | Error 0.2689(0.2730) Steps 0(0.00) | Grad Norm 8.4490(9.9510) | Total Time 0.00(0.00)\n",
      "Iter 4380 | Time 15.7803(16.4399) | Bit/dim 3.6937(3.6946) | Xent 0.6812(0.7475) | Loss 8.8179(9.4121) | Error 0.2400(0.2681) Steps 0(0.00) | Grad Norm 7.1453(9.4755) | Total Time 0.00(0.00)\n",
      "Iter 4390 | Time 17.5333(16.5654) | Bit/dim 3.7091(3.6955) | Xent 0.7869(0.7531) | Loss 9.1753(9.3504) | Error 0.2778(0.2687) Steps 0(0.00) | Grad Norm 7.5544(9.3604) | Total Time 0.00(0.00)\n",
      "Iter 4400 | Time 15.2643(16.3977) | Bit/dim 3.6803(3.6933) | Xent 0.7050(0.7493) | Loss 9.0336(9.2839) | Error 0.2489(0.2681) Steps 0(0.00) | Grad Norm 6.1479(9.0685) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 85.6445, Epoch Time 1001.1743(978.2552), Bit/dim 3.6793(best: 3.6876), Xent 0.7674, Loss 4.0630, Error 0.2692(best: 0.2695)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4410 | Time 17.3851(16.5681) | Bit/dim 3.6877(3.6934) | Xent 0.6860(0.7330) | Loss 8.9025(9.7715) | Error 0.2522(0.2620) Steps 0(0.00) | Grad Norm 5.7131(8.3492) | Total Time 0.00(0.00)\n",
      "Iter 4420 | Time 17.0546(16.6015) | Bit/dim 3.6166(3.6852) | Xent 0.7081(0.7292) | Loss 9.0332(9.5659) | Error 0.2544(0.2607) Steps 0(0.00) | Grad Norm 6.0337(8.2250) | Total Time 0.00(0.00)\n",
      "Iter 4430 | Time 18.1267(16.6856) | Bit/dim 3.6681(3.6862) | Xent 0.7432(0.7341) | Loss 9.3015(9.4645) | Error 0.2422(0.2606) Steps 0(0.00) | Grad Norm 10.2409(8.3851) | Total Time 0.00(0.00)\n",
      "Iter 4440 | Time 16.3972(16.6832) | Bit/dim 3.6439(3.6869) | Xent 0.6553(0.7380) | Loss 9.1114(9.3903) | Error 0.2311(0.2628) Steps 0(0.00) | Grad Norm 7.3962(8.8461) | Total Time 0.00(0.00)\n",
      "Iter 4450 | Time 16.5394(16.7788) | Bit/dim 3.6909(3.6845) | Xent 0.7038(0.7368) | Loss 9.1966(9.2872) | Error 0.2556(0.2633) Steps 0(0.00) | Grad Norm 8.6122(8.6174) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 88.3926, Epoch Time 1032.3793(979.8789), Bit/dim 3.6874(best: 3.6793), Xent 0.8003, Loss 4.0875, Error 0.2803(best: 0.2692)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4460 | Time 15.9601(16.8012) | Bit/dim 3.6751(3.6805) | Xent 0.6996(0.7379) | Loss 9.2197(9.8333) | Error 0.2456(0.2632) Steps 0(0.00) | Grad Norm 6.7464(8.3017) | Total Time 0.00(0.00)\n",
      "Iter 4470 | Time 16.4427(16.9323) | Bit/dim 3.6517(3.6778) | Xent 0.6853(0.7296) | Loss 9.0324(9.6448) | Error 0.2400(0.2605) Steps 0(0.00) | Grad Norm 4.2692(7.6304) | Total Time 0.00(0.00)\n",
      "Iter 4480 | Time 16.7295(16.7385) | Bit/dim 3.6894(3.6792) | Xent 0.7156(0.7317) | Loss 9.0149(9.5095) | Error 0.2611(0.2614) Steps 0(0.00) | Grad Norm 7.5167(8.1370) | Total Time 0.00(0.00)\n",
      "Iter 4490 | Time 15.6540(16.5935) | Bit/dim 3.7147(3.6816) | Xent 0.6959(0.7241) | Loss 9.1479(9.3968) | Error 0.2367(0.2588) Steps 0(0.00) | Grad Norm 4.2399(7.8102) | Total Time 0.00(0.00)\n",
      "Iter 4500 | Time 17.7325(16.4996) | Bit/dim 3.6608(3.6811) | Xent 0.7783(0.7260) | Loss 9.1401(9.3007) | Error 0.2722(0.2585) Steps 0(0.00) | Grad Norm 8.0203(7.9822) | Total Time 0.00(0.00)\n",
      "Iter 4510 | Time 16.1339(16.5431) | Bit/dim 3.7041(3.6832) | Xent 0.7393(0.7301) | Loss 9.1344(9.2303) | Error 0.2600(0.2604) Steps 0(0.00) | Grad Norm 11.5320(8.5494) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 84.7699, Epoch Time 1012.3280(980.8524), Bit/dim 3.6769(best: 3.6793), Xent 0.7980, Loss 4.0759, Error 0.2784(best: 0.2692)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4520 | Time 16.2698(16.7086) | Bit/dim 3.6943(3.6839) | Xent 0.7156(0.7253) | Loss 9.0542(9.7277) | Error 0.2500(0.2576) Steps 0(0.00) | Grad Norm 9.5041(8.8774) | Total Time 0.00(0.00)\n",
      "Iter 4530 | Time 17.5625(16.6655) | Bit/dim 3.6915(3.6842) | Xent 0.7380(0.7199) | Loss 9.0110(9.5545) | Error 0.2589(0.2559) Steps 0(0.00) | Grad Norm 11.0188(8.3325) | Total Time 0.00(0.00)\n",
      "Iter 4540 | Time 14.9098(16.6409) | Bit/dim 3.6923(3.6821) | Xent 0.6865(0.7182) | Loss 9.0188(9.4312) | Error 0.2500(0.2571) Steps 0(0.00) | Grad Norm 9.2361(8.3553) | Total Time 0.00(0.00)\n",
      "Iter 4550 | Time 15.4950(16.6386) | Bit/dim 3.6805(3.6825) | Xent 0.7822(0.7233) | Loss 9.0325(9.3517) | Error 0.2767(0.2586) Steps 0(0.00) | Grad Norm 13.8091(8.4311) | Total Time 0.00(0.00)\n",
      "Iter 4560 | Time 17.3363(16.7171) | Bit/dim 3.6692(3.6800) | Xent 0.7542(0.7290) | Loss 8.8124(9.2696) | Error 0.2678(0.2602) Steps 0(0.00) | Grad Norm 8.3309(8.6973) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 87.0297, Epoch Time 1027.0945(982.2396), Bit/dim 3.6815(best: 3.6769), Xent 0.7810, Loss 4.0720, Error 0.2748(best: 0.2692)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4570 | Time 15.2073(16.6714) | Bit/dim 3.6879(3.6807) | Xent 0.7140(0.7324) | Loss 9.1325(9.8560) | Error 0.2300(0.2605) Steps 0(0.00) | Grad Norm 6.1978(8.8622) | Total Time 0.00(0.00)\n",
      "Iter 4580 | Time 19.2192(16.7512) | Bit/dim 3.6855(3.6788) | Xent 0.7025(0.7230) | Loss 8.7418(9.6361) | Error 0.2578(0.2568) Steps 0(0.00) | Grad Norm 9.9819(8.7127) | Total Time 0.00(0.00)\n",
      "Iter 4590 | Time 17.3679(16.7978) | Bit/dim 3.6635(3.6814) | Xent 0.7163(0.7151) | Loss 9.1064(9.4909) | Error 0.2656(0.2547) Steps 0(0.00) | Grad Norm 5.3964(8.1887) | Total Time 0.00(0.00)\n",
      "Iter 4600 | Time 14.9147(16.7499) | Bit/dim 3.6702(3.6801) | Xent 0.7647(0.7197) | Loss 9.0542(9.3848) | Error 0.2944(0.2556) Steps 0(0.00) | Grad Norm 11.4496(8.5641) | Total Time 0.00(0.00)\n",
      "Iter 4610 | Time 16.0348(16.7516) | Bit/dim 3.6993(3.6796) | Xent 0.7521(0.7335) | Loss 9.1964(9.3269) | Error 0.2756(0.2597) Steps 0(0.00) | Grad Norm 10.0431(8.9302) | Total Time 0.00(0.00)\n",
      "Iter 4620 | Time 15.7593(16.6729) | Bit/dim 3.6800(3.6773) | Xent 0.7712(0.7245) | Loss 9.1012(9.2438) | Error 0.2567(0.2571) Steps 0(0.00) | Grad Norm 6.9146(8.0042) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 86.6160, Epoch Time 1022.6205(983.4511), Bit/dim 3.6771(best: 3.6769), Xent 0.7664, Loss 4.0603, Error 0.2691(best: 0.2692)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4630 | Time 16.4728(16.6681) | Bit/dim 3.6596(3.6775) | Xent 0.7080(0.7212) | Loss 9.0707(9.7393) | Error 0.2467(0.2553) Steps 0(0.00) | Grad Norm 7.2318(8.0641) | Total Time 0.00(0.00)\n",
      "Iter 4640 | Time 16.9651(16.7313) | Bit/dim 3.6629(3.6788) | Xent 0.7029(0.7213) | Loss 9.0846(9.5711) | Error 0.2544(0.2556) Steps 0(0.00) | Grad Norm 11.5196(8.4461) | Total Time 0.00(0.00)\n",
      "Iter 4650 | Time 16.0061(16.7957) | Bit/dim 3.6848(3.6808) | Xent 0.7142(0.7122) | Loss 9.0674(9.4307) | Error 0.2522(0.2525) Steps 0(0.00) | Grad Norm 5.9972(8.5303) | Total Time 0.00(0.00)\n",
      "Iter 4660 | Time 16.4743(16.7561) | Bit/dim 3.6749(3.6791) | Xent 0.7292(0.7114) | Loss 9.3933(9.3357) | Error 0.2522(0.2529) Steps 0(0.00) | Grad Norm 5.9718(8.4526) | Total Time 0.00(0.00)\n",
      "Iter 4670 | Time 16.2423(16.8364) | Bit/dim 3.6539(3.6770) | Xent 0.7365(0.7127) | Loss 9.0478(9.2559) | Error 0.2556(0.2542) Steps 0(0.00) | Grad Norm 9.7221(8.9184) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 87.7286, Epoch Time 1026.6050(984.7457), Bit/dim 3.6836(best: 3.6769), Xent 0.7547, Loss 4.0610, Error 0.2654(best: 0.2691)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4680 | Time 15.9169(16.8006) | Bit/dim 3.6778(3.6770) | Xent 0.7039(0.7064) | Loss 9.1449(9.8454) | Error 0.2567(0.2517) Steps 0(0.00) | Grad Norm 7.8676(8.4654) | Total Time 0.00(0.00)\n",
      "Iter 4690 | Time 17.9239(16.7900) | Bit/dim 3.6944(3.6747) | Xent 0.7119(0.7019) | Loss 8.9500(9.6177) | Error 0.2522(0.2499) Steps 0(0.00) | Grad Norm 6.1252(8.0671) | Total Time 0.00(0.00)\n",
      "Iter 4700 | Time 16.0852(16.8617) | Bit/dim 3.6612(3.6765) | Xent 0.7516(0.7001) | Loss 9.0608(9.4637) | Error 0.2733(0.2505) Steps 0(0.00) | Grad Norm 7.9235(8.2369) | Total Time 0.00(0.00)\n",
      "Iter 4710 | Time 18.5989(16.9546) | Bit/dim 3.6359(3.6762) | Xent 0.7165(0.7005) | Loss 9.1891(9.3737) | Error 0.2511(0.2509) Steps 0(0.00) | Grad Norm 6.6050(8.1772) | Total Time 0.00(0.00)\n",
      "Iter 4720 | Time 16.0253(16.9250) | Bit/dim 3.6527(3.6750) | Xent 0.6788(0.6984) | Loss 8.9527(9.2709) | Error 0.2389(0.2502) Steps 0(0.00) | Grad Norm 5.0224(7.9559) | Total Time 0.00(0.00)\n",
      "Iter 4730 | Time 15.9203(17.1756) | Bit/dim 3.6503(3.6704) | Xent 0.6816(0.7001) | Loss 9.0861(9.2240) | Error 0.2411(0.2507) Steps 0(0.00) | Grad Norm 7.2083(7.6442) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 86.9327, Epoch Time 1047.6233(986.6320), Bit/dim 3.6749(best: 3.6769), Xent 0.7671, Loss 4.0585, Error 0.2691(best: 0.2654)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4740 | Time 18.2603(17.2147) | Bit/dim 3.6954(3.6708) | Xent 0.7466(0.7023) | Loss 9.3045(9.7174) | Error 0.2600(0.2507) Steps 0(0.00) | Grad Norm 15.5003(8.5080) | Total Time 0.00(0.00)\n",
      "Iter 4750 | Time 15.4079(17.0377) | Bit/dim 3.6743(3.6727) | Xent 0.6699(0.6972) | Loss 8.9990(9.5481) | Error 0.2367(0.2494) Steps 0(0.00) | Grad Norm 9.4215(8.6029) | Total Time 0.00(0.00)\n",
      "Iter 4760 | Time 16.6591(17.0146) | Bit/dim 3.6690(3.6743) | Xent 0.7251(0.6951) | Loss 8.7951(9.4124) | Error 0.2700(0.2488) Steps 0(0.00) | Grad Norm 9.4173(8.4168) | Total Time 0.00(0.00)\n",
      "Iter 4770 | Time 18.7993(16.9217) | Bit/dim 3.6745(3.6739) | Xent 0.7455(0.6944) | Loss 9.2232(9.3051) | Error 0.2722(0.2490) Steps 0(0.00) | Grad Norm 10.8412(8.4021) | Total Time 0.00(0.00)\n",
      "Iter 4780 | Time 15.4733(16.7528) | Bit/dim 3.7023(3.6727) | Xent 0.6913(0.6939) | Loss 8.9109(9.2270) | Error 0.2422(0.2488) Steps 0(0.00) | Grad Norm 10.2693(8.2717) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 87.8599, Epoch Time 1027.7356(987.8651), Bit/dim 3.6685(best: 3.6749), Xent 0.7766, Loss 4.0568, Error 0.2718(best: 0.2654)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4790 | Time 17.7216(16.8671) | Bit/dim 3.6742(3.6717) | Xent 0.6440(0.6923) | Loss 9.2285(9.8223) | Error 0.2311(0.2485) Steps 0(0.00) | Grad Norm 7.2513(8.1318) | Total Time 0.00(0.00)\n",
      "Iter 4800 | Time 15.6091(16.8252) | Bit/dim 3.6383(3.6692) | Xent 0.7039(0.6891) | Loss 8.8165(9.6027) | Error 0.2600(0.2474) Steps 0(0.00) | Grad Norm 8.3289(7.9172) | Total Time 0.00(0.00)\n",
      "Iter 4810 | Time 19.5377(16.7884) | Bit/dim 3.6631(3.6729) | Xent 0.7346(0.7040) | Loss 9.0572(9.4756) | Error 0.2700(0.2518) Steps 0(0.00) | Grad Norm 9.6492(8.5477) | Total Time 0.00(0.00)\n",
      "Iter 4820 | Time 15.7582(16.7776) | Bit/dim 3.6891(3.6768) | Xent 0.6948(0.7010) | Loss 8.7832(9.3656) | Error 0.2489(0.2505) Steps 0(0.00) | Grad Norm 5.4911(8.3006) | Total Time 0.00(0.00)\n",
      "Iter 4830 | Time 18.2146(16.7443) | Bit/dim 3.6698(3.6754) | Xent 0.7537(0.6994) | Loss 9.0231(9.2720) | Error 0.2711(0.2506) Steps 0(0.00) | Grad Norm 13.2032(8.2571) | Total Time 0.00(0.00)\n",
      "Iter 4840 | Time 16.5381(16.7657) | Bit/dim 3.6788(3.6748) | Xent 0.7081(0.7007) | Loss 9.0001(9.2001) | Error 0.2689(0.2506) Steps 0(0.00) | Grad Norm 10.8976(8.6253) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 85.8060, Epoch Time 1024.1078(988.9524), Bit/dim 3.6700(best: 3.6685), Xent 0.7773, Loss 4.0587, Error 0.2748(best: 0.2654)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4850 | Time 15.0963(16.9220) | Bit/dim 3.6518(3.6741) | Xent 0.6446(0.6944) | Loss 8.6759(9.6657) | Error 0.2356(0.2495) Steps 0(0.00) | Grad Norm 5.6634(7.8461) | Total Time 0.00(0.00)\n",
      "Iter 4860 | Time 15.6127(16.8352) | Bit/dim 3.6303(3.6710) | Xent 0.6367(0.6860) | Loss 8.8680(9.4824) | Error 0.2300(0.2461) Steps 0(0.00) | Grad Norm 7.1960(7.7789) | Total Time 0.00(0.00)\n",
      "Iter 4870 | Time 16.3594(16.7672) | Bit/dim 3.6798(3.6717) | Xent 0.6813(0.6848) | Loss 9.1367(9.3786) | Error 0.2422(0.2456) Steps 0(0.00) | Grad Norm 9.0938(7.6381) | Total Time 0.00(0.00)\n",
      "Iter 4880 | Time 15.6676(16.6512) | Bit/dim 3.6887(3.6687) | Xent 0.7372(0.6845) | Loss 8.9884(9.2731) | Error 0.2567(0.2454) Steps 0(0.00) | Grad Norm 5.9244(7.4987) | Total Time 0.00(0.00)\n",
      "Iter 4890 | Time 16.7802(16.6549) | Bit/dim 3.7011(3.6712) | Xent 0.6709(0.6911) | Loss 9.1553(9.2271) | Error 0.2156(0.2458) Steps 0(0.00) | Grad Norm 5.8204(8.2323) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 84.8263, Epoch Time 1019.6673(989.8739), Bit/dim 3.6732(best: 3.6685), Xent 0.7742, Loss 4.0602, Error 0.2735(best: 0.2654)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4900 | Time 15.4899(16.5646) | Bit/dim 3.6923(3.6697) | Xent 0.7630(0.6982) | Loss 9.0815(9.7686) | Error 0.2722(0.2477) Steps 0(0.00) | Grad Norm 8.9619(8.3498) | Total Time 0.00(0.00)\n",
      "Iter 4910 | Time 17.2984(16.7850) | Bit/dim 3.6513(3.6689) | Xent 0.7293(0.6918) | Loss 8.9463(9.5825) | Error 0.2689(0.2458) Steps 0(0.00) | Grad Norm 16.0917(8.4593) | Total Time 0.00(0.00)\n",
      "Iter 4920 | Time 16.1647(16.7328) | Bit/dim 3.6796(3.6694) | Xent 0.6564(0.6946) | Loss 9.1075(9.4508) | Error 0.2389(0.2470) Steps 0(0.00) | Grad Norm 4.7982(8.6140) | Total Time 0.00(0.00)\n",
      "Iter 4930 | Time 16.5317(16.7089) | Bit/dim 3.6971(3.6707) | Xent 0.7429(0.6966) | Loss 9.0419(9.3400) | Error 0.2567(0.2481) Steps 0(0.00) | Grad Norm 10.0297(8.7351) | Total Time 0.00(0.00)\n",
      "Iter 4940 | Time 15.9864(16.6822) | Bit/dim 3.6748(3.6697) | Xent 0.7000(0.7035) | Loss 8.9215(9.2597) | Error 0.2489(0.2503) Steps 0(0.00) | Grad Norm 10.8855(8.9808) | Total Time 0.00(0.00)\n",
      "Iter 4950 | Time 18.6085(16.9046) | Bit/dim 3.7241(3.6714) | Xent 0.7086(0.7001) | Loss 9.3336(9.2121) | Error 0.2489(0.2489) Steps 0(0.00) | Grad Norm 15.4505(8.8938) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 87.1029, Epoch Time 1031.2213(991.1143), Bit/dim 3.6720(best: 3.6685), Xent 0.7391, Loss 4.0416, Error 0.2569(best: 0.2654)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4960 | Time 17.1649(16.8311) | Bit/dim 3.6445(3.6706) | Xent 0.6920(0.6946) | Loss 9.0429(9.6707) | Error 0.2522(0.2474) Steps 0(0.00) | Grad Norm 10.7441(9.3314) | Total Time 0.00(0.00)\n",
      "Iter 4970 | Time 16.6159(16.7125) | Bit/dim 3.6371(3.6717) | Xent 0.6400(0.6860) | Loss 8.9404(9.4857) | Error 0.2333(0.2449) Steps 0(0.00) | Grad Norm 6.4227(8.7585) | Total Time 0.00(0.00)\n",
      "Iter 4980 | Time 17.1082(16.6655) | Bit/dim 3.6401(3.6711) | Xent 0.7640(0.6932) | Loss 9.1761(9.3845) | Error 0.2789(0.2482) Steps 0(0.00) | Grad Norm 15.6016(9.2855) | Total Time 0.00(0.00)\n",
      "Iter 4990 | Time 18.2357(16.7695) | Bit/dim 3.6853(3.6742) | Xent 0.7026(0.6981) | Loss 9.0589(9.2943) | Error 0.2511(0.2505) Steps 0(0.00) | Grad Norm 8.8344(9.8681) | Total Time 0.00(0.00)\n",
      "Iter 5000 | Time 18.8565(17.0540) | Bit/dim 3.6922(3.6719) | Xent 0.7072(0.6882) | Loss 9.1819(9.2209) | Error 0.2500(0.2474) Steps 0(0.00) | Grad Norm 5.7019(8.8759) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 91.1293, Epoch Time 1039.9634(992.5797), Bit/dim 3.6654(best: 3.6685), Xent 0.7555, Loss 4.0431, Error 0.2639(best: 0.2569)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5010 | Time 16.6696(17.1855) | Bit/dim 3.6725(3.6679) | Xent 0.6314(0.6824) | Loss 8.7633(9.7841) | Error 0.2189(0.2443) Steps 0(0.00) | Grad Norm 9.0200(8.3511) | Total Time 0.00(0.00)\n",
      "Iter 5020 | Time 16.7169(17.1378) | Bit/dim 3.6687(3.6681) | Xent 0.6860(0.6742) | Loss 8.9874(9.5744) | Error 0.2478(0.2407) Steps 0(0.00) | Grad Norm 8.7605(8.3534) | Total Time 0.00(0.00)\n",
      "Iter 5030 | Time 17.1485(17.1385) | Bit/dim 3.6820(3.6662) | Xent 0.5636(0.6650) | Loss 8.7397(9.3822) | Error 0.2067(0.2376) Steps 0(0.00) | Grad Norm 6.6172(7.7871) | Total Time 0.00(0.00)\n",
      "Iter 5040 | Time 17.4847(17.2637) | Bit/dim 3.6623(3.6644) | Xent 0.7395(0.6690) | Loss 9.1189(9.2729) | Error 0.2567(0.2384) Steps 0(0.00) | Grad Norm 8.4218(7.5247) | Total Time 0.00(0.00)\n",
      "Iter 5050 | Time 17.7044(17.3218) | Bit/dim 3.6045(3.6626) | Xent 0.7133(0.6749) | Loss 8.8083(9.2015) | Error 0.2589(0.2406) Steps 0(0.00) | Grad Norm 6.5615(8.0627) | Total Time 0.00(0.00)\n",
      "Iter 5060 | Time 17.0244(17.2642) | Bit/dim 3.6774(3.6646) | Xent 0.6358(0.6797) | Loss 8.9157(9.1528) | Error 0.2422(0.2442) Steps 0(0.00) | Grad Norm 7.1624(7.8159) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 92.2413, Epoch Time 1061.3704(994.6435), Bit/dim 3.6675(best: 3.6654), Xent 0.7545, Loss 4.0447, Error 0.2618(best: 0.2569)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5070 | Time 17.0708(17.2992) | Bit/dim 3.6407(3.6629) | Xent 0.6721(0.6749) | Loss 9.1139(9.6505) | Error 0.2422(0.2425) Steps 0(0.00) | Grad Norm 7.0371(7.5764) | Total Time 0.00(0.00)\n",
      "Iter 5080 | Time 17.2107(17.3153) | Bit/dim 3.6481(3.6623) | Xent 0.7302(0.6674) | Loss 9.0186(9.4876) | Error 0.2511(0.2392) Steps 0(0.00) | Grad Norm 5.6534(7.3483) | Total Time 0.00(0.00)\n",
      "Iter 5090 | Time 18.3055(17.3975) | Bit/dim 3.6477(3.6638) | Xent 0.6677(0.6719) | Loss 9.1390(9.3616) | Error 0.2344(0.2411) Steps 0(0.00) | Grad Norm 9.5984(7.6758) | Total Time 0.00(0.00)\n",
      "Iter 5100 | Time 15.5123(17.2020) | Bit/dim 3.6633(3.6636) | Xent 0.6923(0.6701) | Loss 8.9568(9.2520) | Error 0.2511(0.2405) Steps 0(0.00) | Grad Norm 6.8409(7.3970) | Total Time 0.00(0.00)\n",
      "Iter 5110 | Time 18.8028(17.3136) | Bit/dim 3.6796(3.6656) | Xent 0.7643(0.6772) | Loss 9.1070(9.2017) | Error 0.2700(0.2423) Steps 0(0.00) | Grad Norm 7.8654(8.1554) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 91.5065, Epoch Time 1066.1343(996.7882), Bit/dim 3.6725(best: 3.6654), Xent 0.7550, Loss 4.0499, Error 0.2625(best: 0.2569)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5120 | Time 18.0776(17.3552) | Bit/dim 3.6780(3.6654) | Xent 0.6451(0.6764) | Loss 9.1500(9.7497) | Error 0.2356(0.2428) Steps 0(0.00) | Grad Norm 5.8969(7.8887) | Total Time 0.00(0.00)\n",
      "Iter 5130 | Time 17.9239(17.3647) | Bit/dim 3.6737(3.6681) | Xent 0.7083(0.6771) | Loss 9.0835(9.5588) | Error 0.2567(0.2431) Steps 0(0.00) | Grad Norm 10.0479(8.4074) | Total Time 0.00(0.00)\n",
      "Iter 5140 | Time 20.5764(17.5643) | Bit/dim 3.6655(3.6664) | Xent 0.7768(0.6872) | Loss 8.9793(9.4344) | Error 0.2667(0.2461) Steps 0(0.00) | Grad Norm 9.5351(8.5835) | Total Time 0.00(0.00)\n",
      "Iter 5150 | Time 19.0558(17.4457) | Bit/dim 3.7083(3.6700) | Xent 0.5999(0.6810) | Loss 9.1316(9.3119) | Error 0.2044(0.2432) Steps 0(0.00) | Grad Norm 8.7740(8.7670) | Total Time 0.00(0.00)\n",
      "Iter 5160 | Time 17.1803(17.3457) | Bit/dim 3.6725(3.6667) | Xent 0.6719(0.6760) | Loss 8.8160(9.2234) | Error 0.2467(0.2418) Steps 0(0.00) | Grad Norm 4.1679(8.2406) | Total Time 0.00(0.00)\n",
      "Iter 5170 | Time 18.0215(17.5482) | Bit/dim 3.6464(3.6626) | Xent 0.6903(0.6719) | Loss 9.0853(9.1637) | Error 0.2567(0.2413) Steps 0(0.00) | Grad Norm 11.5876(8.0258) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 91.5861, Epoch Time 1072.8121(999.0689), Bit/dim 3.6647(best: 3.6654), Xent 0.7548, Loss 4.0421, Error 0.2650(best: 0.2569)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5180 | Time 16.5896(17.3992) | Bit/dim 3.6548(3.6626) | Xent 0.7078(0.6705) | Loss 9.0192(9.6462) | Error 0.2533(0.2404) Steps 0(0.00) | Grad Norm 8.9047(7.8636) | Total Time 0.00(0.00)\n",
      "Iter 5190 | Time 17.5282(17.3521) | Bit/dim 3.6730(3.6638) | Xent 0.6017(0.6637) | Loss 8.8541(9.4656) | Error 0.2122(0.2389) Steps 0(0.00) | Grad Norm 9.5996(7.6944) | Total Time 0.00(0.00)\n",
      "Iter 5200 | Time 17.1642(17.2943) | Bit/dim 3.6477(3.6611) | Xent 0.6253(0.6568) | Loss 8.7933(9.3119) | Error 0.2300(0.2371) Steps 0(0.00) | Grad Norm 7.4921(7.1863) | Total Time 0.00(0.00)\n",
      "Iter 5210 | Time 17.3785(17.3332) | Bit/dim 3.6484(3.6590) | Xent 0.6340(0.6524) | Loss 9.0223(9.2265) | Error 0.2244(0.2354) Steps 0(0.00) | Grad Norm 7.1354(7.2436) | Total Time 0.00(0.00)\n",
      "Iter 5220 | Time 17.0010(17.4074) | Bit/dim 3.6506(3.6589) | Xent 0.6434(0.6615) | Loss 8.8943(9.1731) | Error 0.2211(0.2370) Steps 0(0.00) | Grad Norm 7.0846(7.4230) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 93.2572, Epoch Time 1061.9248(1000.9546), Bit/dim 3.6619(best: 3.6647), Xent 0.7468, Loss 4.0353, Error 0.2594(best: 0.2569)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5230 | Time 16.3575(17.3427) | Bit/dim 3.6468(3.6582) | Xent 0.6378(0.6630) | Loss 8.6375(9.7487) | Error 0.2278(0.2377) Steps 0(0.00) | Grad Norm 5.5638(7.6973) | Total Time 0.00(0.00)\n",
      "Iter 5240 | Time 15.9215(17.3714) | Bit/dim 3.6446(3.6562) | Xent 0.6285(0.6591) | Loss 8.6667(9.5473) | Error 0.2167(0.2363) Steps 0(0.00) | Grad Norm 6.9030(7.8107) | Total Time 0.00(0.00)\n",
      "Iter 5250 | Time 17.3393(17.5008) | Bit/dim 3.6628(3.6572) | Xent 0.6433(0.6641) | Loss 8.9662(9.4027) | Error 0.2389(0.2369) Steps 0(0.00) | Grad Norm 7.0153(8.2660) | Total Time 0.00(0.00)\n",
      "Iter 5260 | Time 18.6483(17.4712) | Bit/dim 3.6722(3.6602) | Xent 0.5949(0.6613) | Loss 9.1383(9.2986) | Error 0.2011(0.2355) Steps 0(0.00) | Grad Norm 8.0730(8.3668) | Total Time 0.00(0.00)\n",
      "Iter 5270 | Time 16.9144(17.5095) | Bit/dim 3.6775(3.6608) | Xent 0.6293(0.6642) | Loss 8.8613(9.2182) | Error 0.2311(0.2357) Steps 0(0.00) | Grad Norm 5.5261(8.2545) | Total Time 0.00(0.00)\n",
      "Iter 5280 | Time 16.6924(17.4010) | Bit/dim 3.6840(3.6605) | Xent 0.6508(0.6587) | Loss 9.0513(9.1455) | Error 0.2389(0.2339) Steps 0(0.00) | Grad Norm 7.5680(7.8205) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 92.4163, Epoch Time 1070.9259(1003.0537), Bit/dim 3.6600(best: 3.6619), Xent 0.7279, Loss 4.0239, Error 0.2525(best: 0.2569)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5290 | Time 18.0367(17.3776) | Bit/dim 3.6528(3.6600) | Xent 0.6347(0.6507) | Loss 8.8786(9.6220) | Error 0.2278(0.2315) Steps 0(0.00) | Grad Norm 8.5807(7.6112) | Total Time 0.00(0.00)\n",
      "Iter 5300 | Time 17.4479(17.3797) | Bit/dim 3.6644(3.6599) | Xent 0.6307(0.6474) | Loss 8.8138(9.4315) | Error 0.2111(0.2307) Steps 0(0.00) | Grad Norm 7.6432(7.6722) | Total Time 0.00(0.00)\n",
      "Iter 5310 | Time 17.1176(17.3659) | Bit/dim 3.6398(3.6602) | Xent 0.6493(0.6484) | Loss 8.9457(9.3097) | Error 0.2389(0.2317) Steps 0(0.00) | Grad Norm 10.1720(8.1538) | Total Time 0.00(0.00)\n",
      "Iter 5320 | Time 18.2514(17.4628) | Bit/dim 3.6163(3.6579) | Xent 0.6663(0.6481) | Loss 8.9879(9.2268) | Error 0.2478(0.2320) Steps 0(0.00) | Grad Norm 6.5419(7.8095) | Total Time 0.00(0.00)\n",
      "Iter 5330 | Time 17.8449(17.4523) | Bit/dim 3.6421(3.6586) | Xent 0.6190(0.6477) | Loss 8.9717(9.1701) | Error 0.2156(0.2309) Steps 0(0.00) | Grad Norm 6.6447(7.7428) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 92.9621, Epoch Time 1068.5058(1005.0173), Bit/dim 3.6553(best: 3.6600), Xent 0.7458, Loss 4.0282, Error 0.2592(best: 0.2525)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5340 | Time 16.9595(17.4014) | Bit/dim 3.6814(3.6607) | Xent 0.6393(0.6473) | Loss 9.0713(9.7599) | Error 0.2322(0.2312) Steps 0(0.00) | Grad Norm 8.1007(7.7670) | Total Time 0.00(0.00)\n",
      "Iter 5350 | Time 16.4720(17.3057) | Bit/dim 3.6747(3.6611) | Xent 0.7354(0.6481) | Loss 9.1637(9.5520) | Error 0.2644(0.2322) Steps 0(0.00) | Grad Norm 9.8801(8.0052) | Total Time 0.00(0.00)\n",
      "Iter 5360 | Time 18.5168(17.3589) | Bit/dim 3.6760(3.6633) | Xent 0.6603(0.6498) | Loss 9.1303(9.4106) | Error 0.2278(0.2324) Steps 0(0.00) | Grad Norm 6.9873(8.5094) | Total Time 0.00(0.00)\n",
      "Iter 5370 | Time 15.8748(17.4252) | Bit/dim 3.6534(3.6632) | Xent 0.6017(0.6474) | Loss 8.8727(9.2971) | Error 0.2044(0.2315) Steps 0(0.00) | Grad Norm 6.7244(7.9310) | Total Time 0.00(0.00)\n",
      "Iter 5380 | Time 16.9821(17.4688) | Bit/dim 3.6626(3.6624) | Xent 0.6829(0.6457) | Loss 8.9931(9.2104) | Error 0.2311(0.2301) Steps 0(0.00) | Grad Norm 6.6101(7.6854) | Total Time 0.00(0.00)\n",
      "Iter 5390 | Time 18.4640(17.5642) | Bit/dim 3.6297(3.6570) | Xent 0.5858(0.6477) | Loss 8.9958(9.1395) | Error 0.2144(0.2309) Steps 0(0.00) | Grad Norm 4.1780(7.6885) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 92.7300, Epoch Time 1073.8003(1007.0808), Bit/dim 3.6518(best: 3.6553), Xent 0.7268, Loss 4.0152, Error 0.2514(best: 0.2525)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5400 | Time 20.2718(17.4992) | Bit/dim 3.6268(3.6544) | Xent 0.6171(0.6414) | Loss 9.1075(9.6240) | Error 0.2222(0.2274) Steps 0(0.00) | Grad Norm 6.8939(7.6622) | Total Time 0.00(0.00)\n",
      "Iter 5410 | Time 17.3185(17.4559) | Bit/dim 3.6245(3.6543) | Xent 0.5888(0.6364) | Loss 8.8152(9.4463) | Error 0.2056(0.2258) Steps 0(0.00) | Grad Norm 8.5811(7.4155) | Total Time 0.00(0.00)\n",
      "Iter 5420 | Time 16.5161(17.4201) | Bit/dim 3.6607(3.6546) | Xent 0.6130(0.6422) | Loss 8.9347(9.3338) | Error 0.2222(0.2283) Steps 0(0.00) | Grad Norm 8.8902(8.0925) | Total Time 0.00(0.00)\n",
      "Iter 5430 | Time 16.7487(17.3528) | Bit/dim 3.6597(3.6548) | Xent 0.6915(0.6539) | Loss 8.6228(9.2451) | Error 0.2511(0.2344) Steps 0(0.00) | Grad Norm 9.1663(8.4003) | Total Time 0.00(0.00)\n",
      "Iter 5440 | Time 17.3952(17.3702) | Bit/dim 3.6608(3.6576) | Xent 0.5972(0.6509) | Loss 9.0352(9.1923) | Error 0.2167(0.2325) Steps 0(0.00) | Grad Norm 6.0396(8.2446) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 91.2113, Epoch Time 1060.5277(1008.6842), Bit/dim 3.6605(best: 3.6518), Xent 0.7389, Loss 4.0300, Error 0.2551(best: 0.2514)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5450 | Time 18.5888(17.4421) | Bit/dim 3.6752(3.6603) | Xent 0.7132(0.6464) | Loss 9.1621(9.7702) | Error 0.2444(0.2312) Steps 0(0.00) | Grad Norm 11.1602(8.2723) | Total Time 0.00(0.00)\n",
      "Iter 5460 | Time 18.0383(17.2570) | Bit/dim 3.6336(3.6599) | Xent 0.5818(0.6397) | Loss 8.9053(9.5435) | Error 0.1989(0.2282) Steps 0(0.00) | Grad Norm 7.6007(8.3239) | Total Time 0.00(0.00)\n",
      "Iter 5470 | Time 16.4983(17.3892) | Bit/dim 3.6650(3.6570) | Xent 0.6756(0.6348) | Loss 9.1293(9.3708) | Error 0.2444(0.2266) Steps 0(0.00) | Grad Norm 10.0073(7.8736) | Total Time 0.00(0.00)\n",
      "Iter 5480 | Time 16.7004(17.4335) | Bit/dim 3.6363(3.6570) | Xent 0.6046(0.6353) | Loss 8.6780(9.2503) | Error 0.2211(0.2279) Steps 0(0.00) | Grad Norm 6.5800(7.6679) | Total Time 0.00(0.00)\n",
      "Iter 5490 | Time 18.6232(17.3912) | Bit/dim 3.6746(3.6581) | Xent 0.7144(0.6465) | Loss 9.2343(9.1846) | Error 0.2567(0.2317) Steps 0(0.00) | Grad Norm 10.1721(8.2611) | Total Time 0.00(0.00)\n",
      "Iter 5500 | Time 16.7544(17.4045) | Bit/dim 3.6321(3.6593) | Xent 0.6494(0.6450) | Loss 9.0310(9.1458) | Error 0.2267(0.2313) Steps 0(0.00) | Grad Norm 9.0612(8.0231) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 93.9323, Epoch Time 1069.2669(1010.5017), Bit/dim 3.6602(best: 3.6518), Xent 0.7583, Loss 4.0394, Error 0.2624(best: 0.2514)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5510 | Time 16.2824(17.3886) | Bit/dim 3.6172(3.6598) | Xent 0.6625(0.6453) | Loss 8.6962(9.6430) | Error 0.2422(0.2311) Steps 0(0.00) | Grad Norm 5.9431(7.9857) | Total Time 0.00(0.00)\n",
      "Iter 5520 | Time 17.9287(17.4836) | Bit/dim 3.6271(3.6581) | Xent 0.6158(0.6383) | Loss 8.9500(9.4514) | Error 0.2200(0.2282) Steps 0(0.00) | Grad Norm 5.4882(7.8091) | Total Time 0.00(0.00)\n",
      "Iter 5530 | Time 17.0856(17.5561) | Bit/dim 3.6821(3.6568) | Xent 0.6121(0.6392) | Loss 9.0428(9.3273) | Error 0.2067(0.2273) Steps 0(0.00) | Grad Norm 5.8015(7.5862) | Total Time 0.00(0.00)\n",
      "Iter 5540 | Time 16.2152(17.5458) | Bit/dim 3.6809(3.6555) | Xent 0.5820(0.6423) | Loss 9.0568(9.2477) | Error 0.2000(0.2290) Steps 0(0.00) | Grad Norm 6.4321(7.9732) | Total Time 0.00(0.00)\n",
      "Iter 5550 | Time 16.1101(17.4253) | Bit/dim 3.6318(3.6554) | Xent 0.5861(0.6390) | Loss 8.6381(9.1516) | Error 0.2056(0.2288) Steps 0(0.00) | Grad Norm 4.9604(7.7150) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 91.8596, Epoch Time 1070.7588(1012.3094), Bit/dim 3.6595(best: 3.6518), Xent 0.7613, Loss 4.0402, Error 0.2620(best: 0.2514)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5560 | Time 17.6120(17.3254) | Bit/dim 3.6629(3.6566) | Xent 0.5773(0.6348) | Loss 8.8756(9.7363) | Error 0.1967(0.2263) Steps 0(0.00) | Grad Norm 6.9884(7.9148) | Total Time 0.00(0.00)\n",
      "Iter 5570 | Time 18.3262(17.2798) | Bit/dim 3.6894(3.6566) | Xent 0.6280(0.6389) | Loss 9.1436(9.5212) | Error 0.2267(0.2282) Steps 0(0.00) | Grad Norm 10.2553(8.1981) | Total Time 0.00(0.00)\n",
      "Iter 5580 | Time 16.8606(17.4323) | Bit/dim 3.6411(3.6547) | Xent 0.6337(0.6377) | Loss 8.8846(9.3607) | Error 0.2300(0.2287) Steps 0(0.00) | Grad Norm 4.4258(7.8010) | Total Time 0.00(0.00)\n",
      "Iter 5590 | Time 16.0929(17.2966) | Bit/dim 3.6696(3.6540) | Xent 0.7104(0.6374) | Loss 8.7979(9.2579) | Error 0.2567(0.2281) Steps 0(0.00) | Grad Norm 11.7388(7.6970) | Total Time 0.00(0.00)\n",
      "Iter 5600 | Time 17.6051(17.4543) | Bit/dim 3.6650(3.6539) | Xent 0.6706(0.6420) | Loss 9.2643(9.1941) | Error 0.2444(0.2304) Steps 0(0.00) | Grad Norm 8.4474(8.1249) | Total Time 0.00(0.00)\n",
      "Iter 5610 | Time 17.8801(17.5111) | Bit/dim 3.6431(3.6546) | Xent 0.6151(0.6365) | Loss 8.6280(9.1281) | Error 0.2144(0.2281) Steps 0(0.00) | Grad Norm 7.2181(7.9888) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 92.4039, Epoch Time 1070.8292(1014.0650), Bit/dim 3.6559(best: 3.6518), Xent 0.7648, Loss 4.0383, Error 0.2657(best: 0.2514)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5620 | Time 16.6498(17.4209) | Bit/dim 3.6725(3.6545) | Xent 0.6486(0.6371) | Loss 9.1719(9.6402) | Error 0.2378(0.2287) Steps 0(0.00) | Grad Norm 7.4195(8.2600) | Total Time 0.00(0.00)\n",
      "Iter 5630 | Time 18.8898(17.4336) | Bit/dim 3.6752(3.6557) | Xent 0.6022(0.6287) | Loss 8.7492(9.4405) | Error 0.1989(0.2250) Steps 0(0.00) | Grad Norm 4.6741(7.9604) | Total Time 0.00(0.00)\n",
      "Iter 5640 | Time 16.6470(17.3379) | Bit/dim 3.6625(3.6530) | Xent 0.6176(0.6229) | Loss 9.0249(9.2996) | Error 0.2122(0.2228) Steps 0(0.00) | Grad Norm 8.3123(7.8031) | Total Time 0.00(0.00)\n",
      "Iter 5650 | Time 21.4509(17.5361) | Bit/dim 3.6323(3.6517) | Xent 0.6515(0.6313) | Loss 8.9612(9.2253) | Error 0.2422(0.2259) Steps 0(0.00) | Grad Norm 7.5264(7.7540) | Total Time 0.00(0.00)\n",
      "Iter 5660 | Time 17.4001(17.5120) | Bit/dim 3.6646(3.6520) | Xent 0.5817(0.6321) | Loss 9.0650(9.1539) | Error 0.2078(0.2264) Steps 0(0.00) | Grad Norm 7.2412(7.7275) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 93.3063, Epoch Time 1069.8691(1015.7391), Bit/dim 3.6504(best: 3.6518), Xent 0.7581, Loss 4.0294, Error 0.2617(best: 0.2514)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5670 | Time 17.3513(17.5193) | Bit/dim 3.6640(3.6491) | Xent 0.6434(0.6297) | Loss 9.0740(9.7355) | Error 0.2333(0.2255) Steps 0(0.00) | Grad Norm 8.4323(7.5336) | Total Time 0.00(0.00)\n",
      "Iter 5680 | Time 16.6161(17.5002) | Bit/dim 3.6351(3.6465) | Xent 0.5827(0.6218) | Loss 8.9174(9.5100) | Error 0.2011(0.2223) Steps 0(0.00) | Grad Norm 5.0366(7.3781) | Total Time 0.00(0.00)\n",
      "Iter 5690 | Time 16.1043(17.4637) | Bit/dim 3.6532(3.6497) | Xent 0.6234(0.6181) | Loss 8.9933(9.3604) | Error 0.2156(0.2201) Steps 0(0.00) | Grad Norm 7.3003(7.4928) | Total Time 0.00(0.00)\n",
      "Iter 5700 | Time 17.8700(17.4956) | Bit/dim 3.7017(3.6515) | Xent 0.6507(0.6252) | Loss 8.7909(9.2455) | Error 0.2244(0.2217) Steps 0(0.00) | Grad Norm 11.8101(8.3840) | Total Time 0.00(0.00)\n",
      "Iter 5710 | Time 16.6820(17.4854) | Bit/dim 3.6289(3.6524) | Xent 0.6152(0.6223) | Loss 8.8487(9.1540) | Error 0.2189(0.2215) Steps 0(0.00) | Grad Norm 5.6844(8.0908) | Total Time 0.00(0.00)\n",
      "Iter 5720 | Time 16.6024(17.3652) | Bit/dim 3.6600(3.6541) | Xent 0.5748(0.6201) | Loss 8.7783(9.0992) | Error 0.1967(0.2208) Steps 0(0.00) | Grad Norm 4.5209(7.8081) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 94.2101, Epoch Time 1070.4924(1017.3817), Bit/dim 3.6587(best: 3.6504), Xent 0.7248, Loss 4.0211, Error 0.2476(best: 0.2514)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5730 | Time 17.2211(17.5617) | Bit/dim 3.6902(3.6537) | Xent 0.6195(0.6124) | Loss 9.1260(9.5891) | Error 0.2122(0.2177) Steps 0(0.00) | Grad Norm 7.5635(7.7112) | Total Time 0.00(0.00)\n",
      "Iter 5740 | Time 20.4619(17.5996) | Bit/dim 3.6130(3.6498) | Xent 0.6310(0.6159) | Loss 8.7107(9.4012) | Error 0.2289(0.2191) Steps 0(0.00) | Grad Norm 9.2308(7.9632) | Total Time 0.00(0.00)\n",
      "Iter 5750 | Time 16.4705(17.5819) | Bit/dim 3.6508(3.6507) | Xent 0.6254(0.6203) | Loss 8.9064(9.2853) | Error 0.2222(0.2205) Steps 0(0.00) | Grad Norm 7.8001(8.1351) | Total Time 0.00(0.00)\n",
      "Iter 5760 | Time 16.6722(17.4725) | Bit/dim 3.6538(3.6487) | Xent 0.5309(0.6142) | Loss 8.8121(9.1804) | Error 0.1789(0.2185) Steps 0(0.00) | Grad Norm 4.5641(7.5013) | Total Time 0.00(0.00)\n",
      "Iter 5770 | Time 17.9309(17.4964) | Bit/dim 3.6572(3.6455) | Xent 0.5977(0.6138) | Loss 9.1194(9.1203) | Error 0.2011(0.2191) Steps 0(0.00) | Grad Norm 8.7363(7.5062) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 95.0112, Epoch Time 1077.8771(1019.1966), Bit/dim 3.6564(best: 3.6504), Xent 0.7248, Loss 4.0188, Error 0.2483(best: 0.2476)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5780 | Time 20.2328(17.5122) | Bit/dim 3.6461(3.6517) | Xent 0.5776(0.6164) | Loss 9.1466(9.7251) | Error 0.2044(0.2195) Steps 0(0.00) | Grad Norm 5.9595(7.5100) | Total Time 0.00(0.00)\n",
      "Iter 5790 | Time 18.4849(17.7805) | Bit/dim 3.6479(3.6494) | Xent 0.6241(0.6137) | Loss 8.9797(9.5223) | Error 0.2311(0.2192) Steps 0(0.00) | Grad Norm 6.0897(7.6268) | Total Time 0.00(0.00)\n",
      "Iter 5800 | Time 18.1043(17.7367) | Bit/dim 3.6214(3.6495) | Xent 0.6380(0.6089) | Loss 8.9255(9.3475) | Error 0.2244(0.2171) Steps 0(0.00) | Grad Norm 7.9723(7.5260) | Total Time 0.00(0.00)\n",
      "Iter 5810 | Time 18.4642(17.7172) | Bit/dim 3.6464(3.6456) | Xent 0.6252(0.6007) | Loss 8.8083(9.2022) | Error 0.2133(0.2132) Steps 0(0.00) | Grad Norm 9.1377(7.6582) | Total Time 0.00(0.00)\n",
      "Iter 5820 | Time 17.7431(17.6584) | Bit/dim 3.6614(3.6479) | Xent 0.6681(0.6016) | Loss 9.0322(9.1251) | Error 0.2356(0.2134) Steps 0(0.00) | Grad Norm 9.0483(7.7324) | Total Time 0.00(0.00)\n",
      "Iter 5830 | Time 16.4720(17.4440) | Bit/dim 3.6505(3.6460) | Xent 0.6866(0.6048) | Loss 8.9786(9.0477) | Error 0.2367(0.2148) Steps 0(0.00) | Grad Norm 6.2913(7.2438) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 93.5843, Epoch Time 1083.4133(1021.1231), Bit/dim 3.6438(best: 3.6504), Xent 0.7174, Loss 4.0025, Error 0.2525(best: 0.2476)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5840 | Time 16.5675(17.6491) | Bit/dim 3.6855(3.6487) | Xent 0.6518(0.5984) | Loss 9.0475(9.5606) | Error 0.2522(0.2143) Steps 0(0.00) | Grad Norm 8.2650(7.1642) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdlearnscale_15_run1 --seed 1 --lr 0.001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5 --scale_fac 1.0 --gate cnn2 --scale_std 15.0\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
