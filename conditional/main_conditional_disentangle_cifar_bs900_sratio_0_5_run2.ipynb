{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.0, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_run2/current_checkpt.pth', rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_run2', seed=2, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1414198\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 13430 | Time 27.3337(27.4390) | Bit/dim 3.5914(3.5630) | Xent 0.0603(0.1017) | Loss 3.6215(3.6139) | Error 0.0222(0.0370) Steps 1102(1107.25) | Grad Norm 3.1126(4.2050) | Total Time 14.00(14.00)\n",
      "Iter 13440 | Time 27.4205(27.3034) | Bit/dim 3.5827(3.5615) | Xent 0.0306(0.0885) | Loss 3.5980(3.6057) | Error 0.0122(0.0321) Steps 1102(1105.93) | Grad Norm 1.1486(3.6692) | Total Time 14.00(14.00)\n",
      "Iter 13450 | Time 27.1059(27.2208) | Bit/dim 3.5416(3.5568) | Xent 0.0449(0.0762) | Loss 3.5641(3.5949) | Error 0.0133(0.0272) Steps 1090(1104.55) | Grad Norm 1.2547(3.1124) | Total Time 14.00(14.00)\n",
      "Iter 13460 | Time 26.5454(27.0717) | Bit/dim 3.5213(3.5544) | Xent 0.0352(0.0658) | Loss 3.5389(3.5873) | Error 0.0122(0.0231) Steps 1102(1104.16) | Grad Norm 0.9645(2.5924) | Total Time 14.00(14.00)\n",
      "Iter 13470 | Time 26.5920(26.9575) | Bit/dim 3.5419(3.5504) | Xent 0.0388(0.0577) | Loss 3.5613(3.5793) | Error 0.0167(0.0199) Steps 1090(1103.37) | Grad Norm 0.9903(2.1882) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0245 | Time 131.4441, Epoch Time 1642.4362(1571.2784), Bit/dim 3.5458(best: inf), Xent 1.7517, Loss 4.4216, Error 0.2727(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13480 | Time 26.4313(26.9559) | Bit/dim 3.5442(3.5493) | Xent 0.0375(0.0508) | Loss 3.5630(3.5747) | Error 0.0156(0.0170) Steps 1102(1105.01) | Grad Norm 0.9749(1.8784) | Total Time 14.00(14.00)\n",
      "Iter 13490 | Time 26.6763(26.9458) | Bit/dim 3.5714(3.5458) | Xent 0.0318(0.0457) | Loss 3.5873(3.5686) | Error 0.0100(0.0148) Steps 1120(1105.16) | Grad Norm 0.8705(1.6335) | Total Time 14.00(14.00)\n",
      "Iter 13500 | Time 26.9166(26.9298) | Bit/dim 3.5485(3.5429) | Xent 0.0258(0.0420) | Loss 3.5614(3.5639) | Error 0.0078(0.0134) Steps 1126(1104.40) | Grad Norm 0.9239(1.4598) | Total Time 14.00(14.00)\n",
      "Iter 13510 | Time 26.4481(26.9540) | Bit/dim 3.5641(3.5423) | Xent 0.0341(0.0391) | Loss 3.5812(3.5619) | Error 0.0111(0.0125) Steps 1084(1104.58) | Grad Norm 1.0428(1.3337) | Total Time 14.00(14.00)\n",
      "Iter 13520 | Time 26.6693(26.9298) | Bit/dim 3.5115(3.5406) | Xent 0.0242(0.0364) | Loss 3.5237(3.5588) | Error 0.0067(0.0114) Steps 1096(1103.43) | Grad Norm 0.7791(1.2014) | Total Time 14.00(14.00)\n",
      "Iter 13530 | Time 26.8821(26.9543) | Bit/dim 3.5194(3.5393) | Xent 0.0425(0.0351) | Loss 3.5406(3.5568) | Error 0.0144(0.0108) Steps 1102(1104.75) | Grad Norm 1.1221(1.1266) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0246 | Time 126.8062, Epoch Time 1627.7060(1572.9713), Bit/dim 3.5400(best: 3.5458), Xent 1.7846, Loss 4.4324, Error 0.2743(best: 0.2727)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13540 | Time 26.2740(26.9376) | Bit/dim 3.5474(3.5387) | Xent 0.0230(0.0328) | Loss 3.5589(3.5551) | Error 0.0056(0.0098) Steps 1108(1104.41) | Grad Norm 0.8281(1.0685) | Total Time 14.00(14.00)\n",
      "Iter 13550 | Time 27.1999(26.9222) | Bit/dim 3.5438(3.5351) | Xent 0.0281(0.0316) | Loss 3.5578(3.5509) | Error 0.0056(0.0091) Steps 1096(1103.31) | Grad Norm 0.9117(1.0285) | Total Time 14.00(14.00)\n",
      "Iter 13560 | Time 26.6240(26.8460) | Bit/dim 3.5387(3.5354) | Xent 0.0289(0.0311) | Loss 3.5531(3.5510) | Error 0.0089(0.0088) Steps 1126(1103.01) | Grad Norm 0.8772(1.0015) | Total Time 14.00(14.00)\n",
      "Iter 13570 | Time 27.3647(26.7871) | Bit/dim 3.5515(3.5357) | Xent 0.0242(0.0311) | Loss 3.5636(3.5512) | Error 0.0067(0.0088) Steps 1120(1101.35) | Grad Norm 0.8123(0.9734) | Total Time 14.00(14.00)\n",
      "Iter 13580 | Time 26.4338(26.8184) | Bit/dim 3.5279(3.5360) | Xent 0.0213(0.0296) | Loss 3.5385(3.5509) | Error 0.0044(0.0081) Steps 1096(1102.20) | Grad Norm 0.8077(0.9514) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0247 | Time 125.8767, Epoch Time 1618.1762(1574.3274), Bit/dim 3.5374(best: 3.5400), Xent 1.7954, Loss 4.4351, Error 0.2744(best: 0.2727)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13590 | Time 26.6234(26.8314) | Bit/dim 3.5293(3.5356) | Xent 0.0223(0.0288) | Loss 3.5404(3.5500) | Error 0.0067(0.0078) Steps 1090(1102.90) | Grad Norm 0.7107(0.9238) | Total Time 14.00(14.00)\n",
      "Iter 13600 | Time 26.5347(26.8149) | Bit/dim 3.5297(3.5348) | Xent 0.0178(0.0280) | Loss 3.5386(3.5488) | Error 0.0022(0.0075) Steps 1090(1101.83) | Grad Norm 0.6102(0.9102) | Total Time 14.00(14.00)\n",
      "Iter 13610 | Time 26.8497(26.8632) | Bit/dim 3.5348(3.5350) | Xent 0.0300(0.0282) | Loss 3.5498(3.5491) | Error 0.0100(0.0078) Steps 1114(1102.45) | Grad Norm 1.3448(0.9300) | Total Time 14.00(14.00)\n",
      "Iter 13620 | Time 27.1702(26.9301) | Bit/dim 3.5390(3.5362) | Xent 0.0332(0.0285) | Loss 3.5556(3.5505) | Error 0.0089(0.0079) Steps 1096(1100.07) | Grad Norm 1.0035(0.9248) | Total Time 14.00(14.00)\n",
      "Iter 13630 | Time 27.4126(26.9450) | Bit/dim 3.5527(3.5353) | Xent 0.0262(0.0280) | Loss 3.5659(3.5493) | Error 0.0089(0.0079) Steps 1108(1102.39) | Grad Norm 0.9329(0.9053) | Total Time 14.00(14.00)\n",
      "Iter 13640 | Time 26.8624(26.8858) | Bit/dim 3.5214(3.5314) | Xent 0.0318(0.0284) | Loss 3.5373(3.5456) | Error 0.0100(0.0079) Steps 1090(1101.93) | Grad Norm 0.8775(0.9023) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0248 | Time 126.2792, Epoch Time 1623.8163(1575.8121), Bit/dim 3.5371(best: 3.5374), Xent 1.8002, Loss 4.4373, Error 0.2730(best: 0.2727)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13650 | Time 27.3328(26.8596) | Bit/dim 3.5270(3.5308) | Xent 0.0241(0.0276) | Loss 3.5391(3.5446) | Error 0.0044(0.0074) Steps 1120(1103.69) | Grad Norm 0.8075(0.8966) | Total Time 14.00(14.00)\n",
      "Iter 13660 | Time 27.1103(26.8416) | Bit/dim 3.5288(3.5303) | Xent 0.0251(0.0268) | Loss 3.5414(3.5437) | Error 0.0078(0.0071) Steps 1108(1106.25) | Grad Norm 0.8721(0.8982) | Total Time 14.00(14.00)\n",
      "Iter 13670 | Time 26.8575(26.9486) | Bit/dim 3.5521(3.5349) | Xent 0.0239(0.0266) | Loss 3.5641(3.5482) | Error 0.0067(0.0072) Steps 1108(1106.56) | Grad Norm 0.8637(0.9028) | Total Time 14.00(14.00)\n",
      "Iter 13680 | Time 26.0990(26.9086) | Bit/dim 3.5438(3.5359) | Xent 0.0232(0.0265) | Loss 3.5554(3.5492) | Error 0.0067(0.0072) Steps 1096(1107.44) | Grad Norm 0.7428(0.8926) | Total Time 14.00(14.00)\n",
      "Iter 13690 | Time 26.8996(26.9308) | Bit/dim 3.4956(3.5297) | Xent 0.0199(0.0268) | Loss 3.5055(3.5431) | Error 0.0022(0.0074) Steps 1108(1106.27) | Grad Norm 0.7531(0.8879) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0249 | Time 127.2718, Epoch Time 1627.7421(1577.3700), Bit/dim 3.5348(best: 3.5371), Xent 1.8346, Loss 4.4521, Error 0.2773(best: 0.2727)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13700 | Time 27.4128(27.0147) | Bit/dim 3.5444(3.5306) | Xent 0.0294(0.0272) | Loss 3.5591(3.5442) | Error 0.0100(0.0072) Steps 1132(1108.23) | Grad Norm 0.9680(0.9106) | Total Time 14.00(14.00)\n",
      "Iter 13710 | Time 26.9587(27.0036) | Bit/dim 3.5249(3.5294) | Xent 0.0274(0.0275) | Loss 3.5386(3.5432) | Error 0.0067(0.0075) Steps 1126(1108.67) | Grad Norm 0.7385(0.9258) | Total Time 14.00(14.00)\n",
      "Iter 13720 | Time 27.5615(27.0716) | Bit/dim 3.5238(3.5304) | Xent 0.0270(0.0271) | Loss 3.5373(3.5440) | Error 0.0056(0.0070) Steps 1114(1108.61) | Grad Norm 0.9390(0.9033) | Total Time 14.00(14.00)\n",
      "Iter 13730 | Time 27.8776(27.0975) | Bit/dim 3.5448(3.5302) | Xent 0.0301(0.0265) | Loss 3.5598(3.5435) | Error 0.0089(0.0069) Steps 1102(1107.44) | Grad Norm 0.8617(0.9108) | Total Time 14.00(14.00)\n",
      "Iter 13740 | Time 27.0242(26.9998) | Bit/dim 3.5537(3.5310) | Xent 0.0329(0.0269) | Loss 3.5702(3.5444) | Error 0.0100(0.0075) Steps 1102(1107.14) | Grad Norm 0.9231(0.9204) | Total Time 14.00(14.00)\n",
      "Iter 13750 | Time 27.6741(26.9866) | Bit/dim 3.5544(3.5301) | Xent 0.0196(0.0260) | Loss 3.5642(3.5431) | Error 0.0067(0.0070) Steps 1108(1106.25) | Grad Norm 0.8489(0.9034) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0250 | Time 125.7267, Epoch Time 1631.0644(1578.9808), Bit/dim 3.5347(best: 3.5348), Xent 1.8260, Loss 4.4477, Error 0.2751(best: 0.2727)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13760 | Time 27.0743(26.9844) | Bit/dim 3.5412(3.5306) | Xent 0.0240(0.0249) | Loss 3.5532(3.5430) | Error 0.0056(0.0066) Steps 1108(1105.67) | Grad Norm 0.7005(0.8733) | Total Time 14.00(14.00)\n",
      "Iter 13770 | Time 27.0874(27.0571) | Bit/dim 3.5539(3.5297) | Xent 0.0188(0.0246) | Loss 3.5633(3.5420) | Error 0.0044(0.0065) Steps 1114(1107.22) | Grad Norm 0.7804(0.8587) | Total Time 14.00(14.00)\n",
      "Iter 13780 | Time 27.4224(27.1093) | Bit/dim 3.5496(3.5319) | Xent 0.0239(0.0250) | Loss 3.5615(3.5444) | Error 0.0078(0.0067) Steps 1102(1107.59) | Grad Norm 0.7264(0.8688) | Total Time 14.00(14.00)\n",
      "Iter 13790 | Time 27.6548(27.1357) | Bit/dim 3.5111(3.5298) | Xent 0.0375(0.0249) | Loss 3.5299(3.5422) | Error 0.0089(0.0064) Steps 1090(1107.14) | Grad Norm 1.1497(0.8672) | Total Time 14.00(14.00)\n",
      "Iter 13800 | Time 26.7992(27.1724) | Bit/dim 3.5163(3.5301) | Xent 0.0264(0.0251) | Loss 3.5295(3.5426) | Error 0.0100(0.0067) Steps 1102(1107.24) | Grad Norm 0.7804(0.8818) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 127.0725, Epoch Time 1638.7874(1580.7750), Bit/dim 3.5333(best: 3.5347), Xent 1.8391, Loss 4.4528, Error 0.2755(best: 0.2727)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13810 | Time 27.0624(27.1343) | Bit/dim 3.5190(3.5283) | Xent 0.0205(0.0247) | Loss 3.5293(3.5406) | Error 0.0078(0.0068) Steps 1102(1106.06) | Grad Norm 0.8098(0.8847) | Total Time 14.00(14.00)\n",
      "Iter 13820 | Time 26.5796(27.1868) | Bit/dim 3.5400(3.5307) | Xent 0.0230(0.0244) | Loss 3.5515(3.5429) | Error 0.0078(0.0067) Steps 1132(1107.03) | Grad Norm 0.8954(0.8785) | Total Time 14.00(14.00)\n",
      "Iter 13830 | Time 27.6259(27.2314) | Bit/dim 3.5464(3.5298) | Xent 0.0217(0.0242) | Loss 3.5572(3.5418) | Error 0.0044(0.0065) Steps 1120(1108.09) | Grad Norm 0.7698(0.8625) | Total Time 14.00(14.00)\n",
      "Iter 13840 | Time 27.1689(27.3549) | Bit/dim 3.5261(3.5288) | Xent 0.0253(0.0243) | Loss 3.5387(3.5410) | Error 0.0056(0.0064) Steps 1084(1106.67) | Grad Norm 0.8624(0.8694) | Total Time 14.00(14.00)\n",
      "Iter 13850 | Time 27.4861(27.3031) | Bit/dim 3.4842(3.5273) | Xent 0.0289(0.0247) | Loss 3.4986(3.5397) | Error 0.0100(0.0065) Steps 1102(1105.55) | Grad Norm 0.8874(0.8615) | Total Time 14.00(14.00)\n",
      "Iter 13860 | Time 27.3521(27.2599) | Bit/dim 3.5232(3.5270) | Xent 0.0318(0.0254) | Loss 3.5391(3.5397) | Error 0.0089(0.0068) Steps 1108(1106.47) | Grad Norm 1.0263(0.8808) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 126.5454, Epoch Time 1647.5758(1582.7790), Bit/dim 3.5325(best: 3.5333), Xent 1.8254, Loss 4.4452, Error 0.2752(best: 0.2727)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13870 | Time 26.8839(27.1993) | Bit/dim 3.5188(3.5275) | Xent 0.0204(0.0247) | Loss 3.5290(3.5398) | Error 0.0056(0.0064) Steps 1102(1106.83) | Grad Norm 0.6635(0.8458) | Total Time 14.00(14.00)\n",
      "Iter 13880 | Time 27.0685(27.2068) | Bit/dim 3.5137(3.5256) | Xent 0.0180(0.0243) | Loss 3.5227(3.5378) | Error 0.0033(0.0062) Steps 1096(1108.35) | Grad Norm 0.5802(0.8397) | Total Time 14.00(14.00)\n",
      "Iter 13890 | Time 25.9392(27.1200) | Bit/dim 3.5445(3.5268) | Xent 0.0172(0.0239) | Loss 3.5531(3.5387) | Error 0.0022(0.0062) Steps 1102(1109.51) | Grad Norm 0.8472(0.8474) | Total Time 14.00(14.00)\n",
      "Iter 13900 | Time 27.4107(27.0643) | Bit/dim 3.5363(3.5290) | Xent 0.0297(0.0243) | Loss 3.5512(3.5412) | Error 0.0067(0.0063) Steps 1126(1110.24) | Grad Norm 0.9502(0.8522) | Total Time 14.00(14.00)\n",
      "Iter 13910 | Time 28.0504(27.0793) | Bit/dim 3.5351(3.5274) | Xent 0.0202(0.0237) | Loss 3.5452(3.5393) | Error 0.0056(0.0062) Steps 1126(1110.01) | Grad Norm 0.7021(0.8380) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 126.2922, Epoch Time 1632.2110(1584.2620), Bit/dim 3.5318(best: 3.5325), Xent 1.8461, Loss 4.4548, Error 0.2733(best: 0.2727)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13920 | Time 26.4925(27.1094) | Bit/dim 3.5246(3.5276) | Xent 0.0159(0.0235) | Loss 3.5326(3.5394) | Error 0.0011(0.0060) Steps 1120(1107.59) | Grad Norm 0.6785(0.8415) | Total Time 14.00(14.00)\n",
      "Iter 13930 | Time 27.0623(27.1331) | Bit/dim 3.5083(3.5275) | Xent 0.0189(0.0231) | Loss 3.5177(3.5390) | Error 0.0056(0.0060) Steps 1090(1107.80) | Grad Norm 0.6752(0.8394) | Total Time 14.00(14.00)\n",
      "Iter 13940 | Time 27.4693(27.1743) | Bit/dim 3.5195(3.5264) | Xent 0.0168(0.0225) | Loss 3.5280(3.5377) | Error 0.0033(0.0058) Steps 1132(1108.79) | Grad Norm 0.6011(0.8086) | Total Time 14.00(14.00)\n",
      "Iter 13950 | Time 26.4200(27.1339) | Bit/dim 3.5049(3.5256) | Xent 0.0253(0.0235) | Loss 3.5176(3.5373) | Error 0.0067(0.0060) Steps 1096(1110.36) | Grad Norm 0.7530(0.8301) | Total Time 14.00(14.00)\n",
      "Iter 13960 | Time 26.3684(27.0806) | Bit/dim 3.5431(3.5270) | Xent 0.0241(0.0243) | Loss 3.5552(3.5391) | Error 0.0044(0.0064) Steps 1132(1111.94) | Grad Norm 0.8056(0.8407) | Total Time 14.00(14.00)\n",
      "Iter 13970 | Time 27.8643(27.1385) | Bit/dim 3.5273(3.5265) | Xent 0.0302(0.0247) | Loss 3.5424(3.5389) | Error 0.0067(0.0064) Steps 1108(1111.00) | Grad Norm 1.1016(0.8520) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 125.8637, Epoch Time 1637.2212(1585.8508), Bit/dim 3.5309(best: 3.5318), Xent 1.8646, Loss 4.4632, Error 0.2717(best: 0.2727)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13980 | Time 26.8260(27.1073) | Bit/dim 3.5229(3.5271) | Xent 0.0169(0.0234) | Loss 3.5313(3.5388) | Error 0.0033(0.0057) Steps 1114(1110.21) | Grad Norm 0.7233(0.8386) | Total Time 14.00(14.00)\n",
      "Iter 13990 | Time 27.7431(27.1290) | Bit/dim 3.5157(3.5258) | Xent 0.0239(0.0237) | Loss 3.5277(3.5377) | Error 0.0056(0.0058) Steps 1108(1109.19) | Grad Norm 0.7491(0.8550) | Total Time 14.00(14.00)\n",
      "Iter 14000 | Time 27.6512(27.1465) | Bit/dim 3.5156(3.5250) | Xent 0.0284(0.0242) | Loss 3.5298(3.5371) | Error 0.0078(0.0060) Steps 1120(1110.54) | Grad Norm 0.9216(0.8685) | Total Time 14.00(14.00)\n",
      "Iter 14010 | Time 27.2212(27.0749) | Bit/dim 3.5506(3.5277) | Xent 0.0262(0.0240) | Loss 3.5637(3.5397) | Error 0.0078(0.0060) Steps 1114(1109.11) | Grad Norm 0.8259(0.8696) | Total Time 14.00(14.00)\n",
      "Iter 14020 | Time 27.8131(27.1348) | Bit/dim 3.5426(3.5263) | Xent 0.0224(0.0239) | Loss 3.5538(3.5382) | Error 0.0056(0.0059) Steps 1120(1108.53) | Grad Norm 0.9519(0.8719) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 126.6491, Epoch Time 1635.7612(1587.3481), Bit/dim 3.5308(best: 3.5309), Xent 1.8496, Loss 4.4556, Error 0.2745(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14030 | Time 26.3757(27.1195) | Bit/dim 3.5227(3.5263) | Xent 0.0225(0.0236) | Loss 3.5340(3.5381) | Error 0.0067(0.0059) Steps 1114(1107.78) | Grad Norm 0.8741(0.8640) | Total Time 14.00(14.00)\n",
      "Iter 14040 | Time 27.0983(27.0702) | Bit/dim 3.5300(3.5272) | Xent 0.0177(0.0235) | Loss 3.5388(3.5389) | Error 0.0033(0.0060) Steps 1132(1109.22) | Grad Norm 0.7802(0.8549) | Total Time 14.00(14.00)\n",
      "Iter 14050 | Time 28.2038(27.0854) | Bit/dim 3.5586(3.5268) | Xent 0.0290(0.0234) | Loss 3.5731(3.5384) | Error 0.0100(0.0058) Steps 1108(1107.97) | Grad Norm 0.8892(0.8552) | Total Time 14.00(14.00)\n",
      "Iter 14060 | Time 27.5654(27.2066) | Bit/dim 3.5153(3.5262) | Xent 0.0306(0.0234) | Loss 3.5306(3.5378) | Error 0.0122(0.0061) Steps 1084(1106.22) | Grad Norm 1.0788(0.8795) | Total Time 14.00(14.00)\n",
      "Iter 14070 | Time 26.9463(27.1491) | Bit/dim 3.5506(3.5273) | Xent 0.0240(0.0230) | Loss 3.5626(3.5388) | Error 0.0044(0.0058) Steps 1126(1107.17) | Grad Norm 0.9451(0.8699) | Total Time 14.00(14.00)\n",
      "Iter 14080 | Time 26.7898(27.2458) | Bit/dim 3.4998(3.5251) | Xent 0.0181(0.0224) | Loss 3.5088(3.5363) | Error 0.0022(0.0054) Steps 1126(1109.19) | Grad Norm 0.8037(0.8595) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 126.7854, Epoch Time 1641.0617(1588.9595), Bit/dim 3.5319(best: 3.5308), Xent 1.8713, Loss 4.4675, Error 0.2765(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14090 | Time 27.6690(27.2530) | Bit/dim 3.5350(3.5259) | Xent 0.0297(0.0229) | Loss 3.5499(3.5373) | Error 0.0056(0.0056) Steps 1102(1110.01) | Grad Norm 0.8731(0.8532) | Total Time 14.00(14.00)\n",
      "Iter 14100 | Time 27.9621(27.2503) | Bit/dim 3.5101(3.5259) | Xent 0.0205(0.0232) | Loss 3.5204(3.5375) | Error 0.0067(0.0058) Steps 1108(1108.91) | Grad Norm 0.7910(0.8686) | Total Time 14.00(14.00)\n",
      "Iter 14110 | Time 26.6768(27.1884) | Bit/dim 3.5118(3.5273) | Xent 0.0185(0.0233) | Loss 3.5211(3.5389) | Error 0.0044(0.0058) Steps 1114(1112.27) | Grad Norm 0.6513(0.8610) | Total Time 14.00(14.00)\n",
      "Iter 14120 | Time 27.7647(27.2500) | Bit/dim 3.5215(3.5271) | Xent 0.0243(0.0234) | Loss 3.5337(3.5388) | Error 0.0078(0.0059) Steps 1114(1113.56) | Grad Norm 0.8694(0.8942) | Total Time 14.00(14.00)\n",
      "Iter 14130 | Time 27.2146(27.2551) | Bit/dim 3.4937(3.5226) | Xent 0.0247(0.0228) | Loss 3.5060(3.5340) | Error 0.0056(0.0055) Steps 1108(1113.68) | Grad Norm 1.2998(0.9071) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 127.3509, Epoch Time 1642.8716(1590.5769), Bit/dim 3.5305(best: 3.5308), Xent 1.8728, Loss 4.4669, Error 0.2760(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14140 | Time 27.2068(27.2193) | Bit/dim 3.5388(3.5252) | Xent 0.0252(0.0229) | Loss 3.5514(3.5367) | Error 0.0056(0.0055) Steps 1120(1112.47) | Grad Norm 1.2138(0.9236) | Total Time 14.00(14.00)\n",
      "Iter 14150 | Time 26.6927(27.1451) | Bit/dim 3.5093(3.5247) | Xent 0.0258(0.0224) | Loss 3.5222(3.5359) | Error 0.0089(0.0055) Steps 1108(1111.38) | Grad Norm 1.2318(0.9070) | Total Time 14.00(14.00)\n",
      "Iter 14160 | Time 26.9002(27.1477) | Bit/dim 3.5287(3.5263) | Xent 0.0232(0.0227) | Loss 3.5403(3.5376) | Error 0.0089(0.0057) Steps 1114(1111.73) | Grad Norm 1.1594(0.9109) | Total Time 14.00(14.00)\n",
      "Iter 14170 | Time 28.0738(27.1187) | Bit/dim 3.5623(3.5262) | Xent 0.0258(0.0235) | Loss 3.5752(3.5380) | Error 0.0078(0.0061) Steps 1144(1114.80) | Grad Norm 1.0093(0.9185) | Total Time 14.00(14.00)\n",
      "Iter 14180 | Time 28.4544(27.1652) | Bit/dim 3.5327(3.5237) | Xent 0.0223(0.0227) | Loss 3.5439(3.5351) | Error 0.0056(0.0057) Steps 1114(1115.77) | Grad Norm 0.7643(0.8799) | Total Time 14.00(14.00)\n",
      "Iter 14190 | Time 27.0757(27.1869) | Bit/dim 3.5465(3.5232) | Xent 0.0182(0.0222) | Loss 3.5556(3.5343) | Error 0.0022(0.0052) Steps 1108(1114.55) | Grad Norm 0.7439(0.8646) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 127.0408, Epoch Time 1636.9386(1591.9677), Bit/dim 3.5284(best: 3.5305), Xent 1.8723, Loss 4.4646, Error 0.2778(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14200 | Time 27.4746(27.2585) | Bit/dim 3.5000(3.5215) | Xent 0.0282(0.0225) | Loss 3.5141(3.5328) | Error 0.0056(0.0053) Steps 1108(1114.74) | Grad Norm 0.8255(0.8691) | Total Time 14.00(14.00)\n",
      "Iter 14210 | Time 26.6572(27.2588) | Bit/dim 3.4922(3.5212) | Xent 0.0255(0.0219) | Loss 3.5049(3.5321) | Error 0.0067(0.0049) Steps 1096(1113.85) | Grad Norm 1.0059(0.8540) | Total Time 14.00(14.00)\n",
      "Iter 14220 | Time 26.7038(27.1912) | Bit/dim 3.5270(3.5226) | Xent 0.0215(0.0218) | Loss 3.5378(3.5335) | Error 0.0056(0.0049) Steps 1114(1112.89) | Grad Norm 0.6900(0.8299) | Total Time 14.00(14.00)\n",
      "Iter 14230 | Time 27.7941(27.1982) | Bit/dim 3.5377(3.5242) | Xent 0.0175(0.0220) | Loss 3.5465(3.5352) | Error 0.0033(0.0052) Steps 1108(1113.61) | Grad Norm 0.6660(0.8307) | Total Time 14.00(14.00)\n",
      "Iter 14240 | Time 27.3129(27.1247) | Bit/dim 3.5517(3.5235) | Xent 0.0220(0.0224) | Loss 3.5627(3.5347) | Error 0.0044(0.0055) Steps 1132(1113.55) | Grad Norm 0.7579(0.8498) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 126.4486, Epoch Time 1640.2915(1593.4174), Bit/dim 3.5290(best: 3.5284), Xent 1.8915, Loss 4.4748, Error 0.2783(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14250 | Time 27.1109(27.1514) | Bit/dim 3.5041(3.5236) | Xent 0.0217(0.0225) | Loss 3.5150(3.5348) | Error 0.0033(0.0055) Steps 1126(1113.13) | Grad Norm 0.7088(0.8339) | Total Time 14.00(14.00)\n",
      "Iter 14260 | Time 26.6341(27.2066) | Bit/dim 3.5329(3.5244) | Xent 0.0231(0.0226) | Loss 3.5445(3.5356) | Error 0.0056(0.0055) Steps 1114(1114.71) | Grad Norm 0.8444(0.8571) | Total Time 14.00(14.00)\n",
      "Iter 14270 | Time 27.2047(27.1694) | Bit/dim 3.5029(3.5237) | Xent 0.0184(0.0222) | Loss 3.5120(3.5348) | Error 0.0011(0.0052) Steps 1114(1114.34) | Grad Norm 0.7293(0.8543) | Total Time 14.00(14.00)\n",
      "Iter 14280 | Time 27.5886(27.2189) | Bit/dim 3.5371(3.5247) | Xent 0.0231(0.0224) | Loss 3.5487(3.5359) | Error 0.0033(0.0052) Steps 1120(1115.86) | Grad Norm 0.8670(0.8725) | Total Time 14.00(14.00)\n",
      "Iter 14290 | Time 26.7146(27.1992) | Bit/dim 3.5100(3.5254) | Xent 0.0202(0.0226) | Loss 3.5201(3.5367) | Error 0.0044(0.0053) Steps 1102(1114.97) | Grad Norm 0.7930(0.8759) | Total Time 14.00(14.00)\n",
      "Iter 14300 | Time 27.5312(27.2132) | Bit/dim 3.5264(3.5240) | Xent 0.0168(0.0223) | Loss 3.5347(3.5352) | Error 0.0033(0.0053) Steps 1120(1113.52) | Grad Norm 0.7216(0.8765) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 126.8825, Epoch Time 1642.4783(1594.8893), Bit/dim 3.5293(best: 3.5284), Xent 1.9013, Loss 4.4799, Error 0.2766(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14310 | Time 26.5177(27.1964) | Bit/dim 3.5086(3.5243) | Xent 0.0199(0.0223) | Loss 3.5186(3.5355) | Error 0.0022(0.0053) Steps 1114(1113.39) | Grad Norm 0.5716(0.8610) | Total Time 14.00(14.00)\n",
      "Iter 14320 | Time 27.5270(27.1943) | Bit/dim 3.5406(3.5241) | Xent 0.0207(0.0223) | Loss 3.5510(3.5353) | Error 0.0056(0.0053) Steps 1132(1114.79) | Grad Norm 0.9031(0.8862) | Total Time 14.00(14.00)\n",
      "Iter 14330 | Time 26.7674(27.1896) | Bit/dim 3.5182(3.5256) | Xent 0.0183(0.0216) | Loss 3.5273(3.5364) | Error 0.0022(0.0049) Steps 1108(1114.40) | Grad Norm 0.6187(0.8622) | Total Time 14.00(14.00)\n",
      "Iter 14340 | Time 27.8748(27.2461) | Bit/dim 3.5205(3.5255) | Xent 0.0198(0.0212) | Loss 3.5304(3.5360) | Error 0.0033(0.0047) Steps 1084(1112.81) | Grad Norm 0.7507(0.8402) | Total Time 14.00(14.00)\n",
      "Iter 14350 | Time 26.7221(27.2092) | Bit/dim 3.5327(3.5229) | Xent 0.0214(0.0211) | Loss 3.5434(3.5335) | Error 0.0056(0.0048) Steps 1108(1112.36) | Grad Norm 0.8415(0.8370) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 127.0740, Epoch Time 1640.4041(1596.2547), Bit/dim 3.5275(best: 3.5284), Xent 1.9202, Loss 4.4875, Error 0.2828(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14360 | Time 27.2573(27.1519) | Bit/dim 3.5116(3.5232) | Xent 0.0229(0.0211) | Loss 3.5231(3.5338) | Error 0.0067(0.0047) Steps 1090(1112.16) | Grad Norm 1.0158(0.8506) | Total Time 14.00(14.00)\n",
      "Iter 14370 | Time 27.3483(27.1424) | Bit/dim 3.5086(3.5239) | Xent 0.0185(0.0208) | Loss 3.5179(3.5343) | Error 0.0022(0.0044) Steps 1096(1111.92) | Grad Norm 0.7215(0.8241) | Total Time 14.00(14.00)\n",
      "Iter 14380 | Time 26.9890(27.0978) | Bit/dim 3.5457(3.5270) | Xent 0.0224(0.0216) | Loss 3.5569(3.5378) | Error 0.0056(0.0048) Steps 1102(1111.84) | Grad Norm 0.9867(0.8794) | Total Time 14.00(14.00)\n",
      "Iter 14390 | Time 27.1168(27.1457) | Bit/dim 3.5194(3.5234) | Xent 0.0274(0.0222) | Loss 3.5332(3.5344) | Error 0.0067(0.0050) Steps 1096(1112.50) | Grad Norm 0.9945(0.8977) | Total Time 14.00(14.00)\n",
      "Iter 14400 | Time 27.0184(27.1928) | Bit/dim 3.4975(3.5217) | Xent 0.0193(0.0221) | Loss 3.5071(3.5327) | Error 0.0044(0.0051) Steps 1108(1113.70) | Grad Norm 0.6540(0.8967) | Total Time 14.00(14.00)\n",
      "Iter 14410 | Time 27.3078(27.1292) | Bit/dim 3.5357(3.5213) | Xent 0.0234(0.0224) | Loss 3.5474(3.5325) | Error 0.0044(0.0054) Steps 1114(1114.42) | Grad Norm 1.1631(0.9159) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 127.5531, Epoch Time 1636.7556(1597.4697), Bit/dim 3.5273(best: 3.5275), Xent 1.8912, Loss 4.4729, Error 0.2774(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14420 | Time 27.4457(27.1635) | Bit/dim 3.4963(3.5216) | Xent 0.0208(0.0218) | Loss 3.5067(3.5325) | Error 0.0044(0.0053) Steps 1102(1114.21) | Grad Norm 0.7479(0.8981) | Total Time 14.00(14.00)\n",
      "Iter 14430 | Time 27.7672(27.1744) | Bit/dim 3.5226(3.5224) | Xent 0.0202(0.0222) | Loss 3.5327(3.5335) | Error 0.0089(0.0055) Steps 1096(1112.34) | Grad Norm 0.6721(0.8900) | Total Time 14.00(14.00)\n",
      "Iter 14440 | Time 27.3399(27.2166) | Bit/dim 3.5343(3.5214) | Xent 0.0214(0.0223) | Loss 3.5450(3.5326) | Error 0.0056(0.0057) Steps 1114(1113.38) | Grad Norm 0.8397(0.8912) | Total Time 14.00(14.00)\n",
      "Iter 14450 | Time 27.1887(27.2471) | Bit/dim 3.5360(3.5245) | Xent 0.0327(0.0222) | Loss 3.5524(3.5356) | Error 0.0089(0.0054) Steps 1120(1113.35) | Grad Norm 0.9514(0.8722) | Total Time 14.00(14.00)\n",
      "Iter 14460 | Time 26.7643(27.1805) | Bit/dim 3.5286(3.5216) | Xent 0.0146(0.0218) | Loss 3.5359(3.5324) | Error 0.0033(0.0056) Steps 1120(1113.37) | Grad Norm 0.6881(0.8649) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 127.5001, Epoch Time 1640.2731(1598.7538), Bit/dim 3.5279(best: 3.5273), Xent 1.8931, Loss 4.4745, Error 0.2757(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14470 | Time 27.7912(27.1690) | Bit/dim 3.5398(3.5213) | Xent 0.0206(0.0216) | Loss 3.5501(3.5321) | Error 0.0067(0.0055) Steps 1114(1113.34) | Grad Norm 0.8765(0.8881) | Total Time 14.00(14.00)\n",
      "Iter 14480 | Time 26.5842(27.0871) | Bit/dim 3.5258(3.5201) | Xent 0.0236(0.0214) | Loss 3.5376(3.5308) | Error 0.0067(0.0052) Steps 1108(1111.30) | Grad Norm 1.0599(0.8851) | Total Time 14.00(14.00)\n",
      "Iter 14490 | Time 26.4995(27.1078) | Bit/dim 3.5144(3.5223) | Xent 0.0235(0.0210) | Loss 3.5261(3.5328) | Error 0.0056(0.0048) Steps 1102(1111.56) | Grad Norm 0.9621(0.9022) | Total Time 14.00(14.00)\n",
      "Iter 14500 | Time 27.1103(27.1037) | Bit/dim 3.5283(3.5247) | Xent 0.0193(0.0209) | Loss 3.5380(3.5351) | Error 0.0033(0.0048) Steps 1120(1113.20) | Grad Norm 0.8785(0.8972) | Total Time 14.00(14.00)\n",
      "Iter 14510 | Time 27.3078(27.1205) | Bit/dim 3.5297(3.5241) | Xent 0.0193(0.0204) | Loss 3.5394(3.5343) | Error 0.0044(0.0047) Steps 1108(1113.56) | Grad Norm 0.9515(0.8795) | Total Time 14.00(14.00)\n",
      "Iter 14520 | Time 27.5546(27.1373) | Bit/dim 3.5219(3.5212) | Xent 0.0357(0.0211) | Loss 3.5398(3.5317) | Error 0.0133(0.0049) Steps 1108(1113.77) | Grad Norm 1.6884(0.8927) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 125.8785, Epoch Time 1635.3526(1599.8518), Bit/dim 3.5258(best: 3.5273), Xent 1.9272, Loss 4.4894, Error 0.2780(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14530 | Time 26.4309(27.1121) | Bit/dim 3.5332(3.5214) | Xent 0.0221(0.0209) | Loss 3.5442(3.5318) | Error 0.0056(0.0050) Steps 1096(1112.45) | Grad Norm 0.6956(0.8728) | Total Time 14.00(14.00)\n",
      "Iter 14540 | Time 27.4606(27.2303) | Bit/dim 3.5036(3.5197) | Xent 0.0180(0.0209) | Loss 3.5126(3.5301) | Error 0.0044(0.0048) Steps 1126(1112.58) | Grad Norm 0.7104(0.8685) | Total Time 14.00(14.00)\n",
      "Iter 14550 | Time 27.5272(27.2590) | Bit/dim 3.5089(3.5184) | Xent 0.0140(0.0206) | Loss 3.5159(3.5287) | Error 0.0033(0.0047) Steps 1114(1112.92) | Grad Norm 0.7251(0.8827) | Total Time 14.00(14.00)\n",
      "Iter 14560 | Time 26.8559(27.2270) | Bit/dim 3.5135(3.5208) | Xent 0.0232(0.0208) | Loss 3.5251(3.5312) | Error 0.0056(0.0048) Steps 1108(1111.41) | Grad Norm 1.3864(0.9004) | Total Time 14.00(14.00)\n",
      "Iter 14570 | Time 27.2027(27.2310) | Bit/dim 3.5584(3.5239) | Xent 0.0200(0.0204) | Loss 3.5683(3.5340) | Error 0.0044(0.0048) Steps 1114(1112.15) | Grad Norm 0.9552(0.8925) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 126.5532, Epoch Time 1642.7702(1601.1393), Bit/dim 3.5256(best: 3.5258), Xent 1.9410, Loss 4.4961, Error 0.2799(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14580 | Time 27.3425(27.1879) | Bit/dim 3.5411(3.5230) | Xent 0.0159(0.0204) | Loss 3.5490(3.5332) | Error 0.0011(0.0047) Steps 1114(1111.81) | Grad Norm 0.6942(0.8909) | Total Time 14.00(14.00)\n",
      "Iter 14590 | Time 27.3315(27.1518) | Bit/dim 3.5311(3.5215) | Xent 0.0272(0.0206) | Loss 3.5447(3.5318) | Error 0.0067(0.0046) Steps 1132(1111.83) | Grad Norm 1.2084(0.8813) | Total Time 14.00(14.00)\n",
      "Iter 14600 | Time 27.5813(27.2152) | Bit/dim 3.5448(3.5237) | Xent 0.0166(0.0206) | Loss 3.5531(3.5340) | Error 0.0022(0.0045) Steps 1120(1112.06) | Grad Norm 1.0825(0.9149) | Total Time 14.00(14.00)\n",
      "Iter 14610 | Time 27.6662(27.2369) | Bit/dim 3.5190(3.5236) | Xent 0.0212(0.0209) | Loss 3.5296(3.5340) | Error 0.0033(0.0046) Steps 1150(1113.20) | Grad Norm 0.7739(0.9031) | Total Time 14.00(14.00)\n",
      "Iter 14620 | Time 27.8470(27.2645) | Bit/dim 3.5055(3.5190) | Xent 0.0253(0.0207) | Loss 3.5181(3.5294) | Error 0.0056(0.0047) Steps 1120(1112.32) | Grad Norm 0.9719(0.8865) | Total Time 14.00(14.00)\n",
      "Iter 14630 | Time 27.4617(27.2837) | Bit/dim 3.5391(3.5200) | Xent 0.0224(0.0205) | Loss 3.5504(3.5303) | Error 0.0033(0.0046) Steps 1108(1111.92) | Grad Norm 0.9814(0.8784) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 125.7428, Epoch Time 1643.3878(1602.4068), Bit/dim 3.5256(best: 3.5256), Xent 1.9255, Loss 4.4883, Error 0.2808(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14640 | Time 28.1995(27.2670) | Bit/dim 3.5402(3.5179) | Xent 0.0140(0.0203) | Loss 3.5472(3.5280) | Error 0.0044(0.0046) Steps 1144(1113.37) | Grad Norm 0.7020(0.8593) | Total Time 14.00(14.00)\n",
      "Iter 14650 | Time 26.7416(27.2150) | Bit/dim 3.5349(3.5201) | Xent 0.0225(0.0210) | Loss 3.5461(3.5306) | Error 0.0078(0.0049) Steps 1108(1113.87) | Grad Norm 0.8282(0.8690) | Total Time 14.00(14.00)\n",
      "Iter 14660 | Time 26.9586(27.1820) | Bit/dim 3.5429(3.5200) | Xent 0.0136(0.0208) | Loss 3.5497(3.5304) | Error 0.0011(0.0047) Steps 1102(1112.61) | Grad Norm 0.8169(0.8683) | Total Time 14.00(14.00)\n",
      "Iter 14670 | Time 26.6484(27.1773) | Bit/dim 3.5089(3.5195) | Xent 0.0198(0.0210) | Loss 3.5188(3.5300) | Error 0.0067(0.0049) Steps 1114(1112.89) | Grad Norm 0.8741(0.8787) | Total Time 14.00(14.00)\n",
      "Iter 14680 | Time 27.3556(27.2226) | Bit/dim 3.5319(3.5216) | Xent 0.0199(0.0211) | Loss 3.5419(3.5321) | Error 0.0056(0.0051) Steps 1126(1112.17) | Grad Norm 0.7584(0.9095) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0267 | Time 125.6544, Epoch Time 1638.5684(1603.4916), Bit/dim 3.5265(best: 3.5256), Xent 1.9116, Loss 4.4823, Error 0.2795(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14690 | Time 26.4981(27.1434) | Bit/dim 3.5351(3.5215) | Xent 0.0216(0.0207) | Loss 3.5459(3.5318) | Error 0.0067(0.0049) Steps 1120(1112.04) | Grad Norm 1.0428(0.9066) | Total Time 14.00(14.00)\n",
      "Iter 14700 | Time 26.6147(27.1388) | Bit/dim 3.4915(3.5183) | Xent 0.0169(0.0207) | Loss 3.5000(3.5287) | Error 0.0033(0.0050) Steps 1108(1111.10) | Grad Norm 0.8466(0.9011) | Total Time 14.00(14.00)\n",
      "Iter 14710 | Time 26.3919(27.1802) | Bit/dim 3.5349(3.5181) | Xent 0.0294(0.0221) | Loss 3.5496(3.5292) | Error 0.0078(0.0055) Steps 1120(1114.16) | Grad Norm 1.3921(0.9660) | Total Time 14.00(14.00)\n",
      "Iter 14720 | Time 27.2343(27.1148) | Bit/dim 3.5171(3.5191) | Xent 0.0185(0.0214) | Loss 3.5264(3.5298) | Error 0.0056(0.0053) Steps 1120(1113.67) | Grad Norm 0.9824(0.9425) | Total Time 14.00(14.00)\n",
      "Iter 14730 | Time 26.7642(27.0675) | Bit/dim 3.5311(3.5210) | Xent 0.0267(0.0213) | Loss 3.5445(3.5316) | Error 0.0089(0.0052) Steps 1108(1112.42) | Grad Norm 1.0851(0.9475) | Total Time 14.00(14.00)\n",
      "Iter 14740 | Time 27.7663(27.0718) | Bit/dim 3.5439(3.5222) | Xent 0.0186(0.0208) | Loss 3.5532(3.5326) | Error 0.0022(0.0048) Steps 1126(1112.10) | Grad Norm 0.7848(0.9171) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0268 | Time 127.6828, Epoch Time 1633.2710(1604.3850), Bit/dim 3.5254(best: 3.5256), Xent 1.9315, Loss 4.4912, Error 0.2809(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14750 | Time 27.3775(27.0982) | Bit/dim 3.5260(3.5202) | Xent 0.0164(0.0206) | Loss 3.5342(3.5305) | Error 0.0022(0.0048) Steps 1108(1113.01) | Grad Norm 0.6873(0.8978) | Total Time 14.00(14.00)\n",
      "Iter 14760 | Time 27.0768(27.0929) | Bit/dim 3.5541(3.5199) | Xent 0.0171(0.0194) | Loss 3.5627(3.5296) | Error 0.0022(0.0043) Steps 1108(1113.12) | Grad Norm 0.7942(0.8481) | Total Time 14.00(14.00)\n",
      "Iter 14770 | Time 27.5865(27.1523) | Bit/dim 3.5129(3.5227) | Xent 0.0193(0.0202) | Loss 3.5226(3.5328) | Error 0.0022(0.0046) Steps 1102(1114.52) | Grad Norm 0.7643(0.9040) | Total Time 14.00(14.00)\n",
      "Iter 14780 | Time 26.6162(27.1475) | Bit/dim 3.5302(3.5208) | Xent 0.0240(0.0205) | Loss 3.5422(3.5310) | Error 0.0056(0.0047) Steps 1120(1113.98) | Grad Norm 1.4114(0.9658) | Total Time 14.00(14.00)\n",
      "Iter 14790 | Time 27.1701(27.1437) | Bit/dim 3.5388(3.5208) | Xent 0.0215(0.0199) | Loss 3.5495(3.5308) | Error 0.0067(0.0045) Steps 1096(1113.06) | Grad Norm 1.0220(0.9881) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0269 | Time 125.9974, Epoch Time 1638.4643(1605.4074), Bit/dim 3.5245(best: 3.5254), Xent 1.9527, Loss 4.5009, Error 0.2800(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14800 | Time 26.8089(27.1363) | Bit/dim 3.5255(3.5209) | Xent 0.0208(0.0200) | Loss 3.5359(3.5309) | Error 0.0033(0.0043) Steps 1108(1112.49) | Grad Norm 0.8396(1.0136) | Total Time 14.00(14.00)\n",
      "Iter 14810 | Time 26.6954(27.1487) | Bit/dim 3.5273(3.5205) | Xent 0.0237(0.0204) | Loss 3.5391(3.5307) | Error 0.0078(0.0044) Steps 1126(1112.03) | Grad Norm 0.8832(0.9914) | Total Time 14.00(14.00)\n",
      "Iter 14820 | Time 26.8531(27.1299) | Bit/dim 3.4889(3.5186) | Xent 0.0181(0.0200) | Loss 3.4980(3.5286) | Error 0.0044(0.0042) Steps 1102(1111.77) | Grad Norm 0.7947(0.9689) | Total Time 14.00(14.00)\n",
      "Iter 14830 | Time 27.5260(27.1810) | Bit/dim 3.5076(3.5188) | Xent 0.0172(0.0201) | Loss 3.5162(3.5288) | Error 0.0033(0.0045) Steps 1108(1113.24) | Grad Norm 0.6863(0.9697) | Total Time 14.00(14.00)\n",
      "Iter 14840 | Time 27.6360(27.1748) | Bit/dim 3.5384(3.5207) | Xent 0.0180(0.0196) | Loss 3.5474(3.5305) | Error 0.0033(0.0044) Steps 1108(1112.06) | Grad Norm 0.8067(0.9299) | Total Time 14.00(14.00)\n",
      "Iter 14850 | Time 26.3629(27.1857) | Bit/dim 3.4972(3.5201) | Xent 0.0153(0.0205) | Loss 3.5049(3.5304) | Error 0.0022(0.0048) Steps 1096(1109.99) | Grad Norm 0.8562(0.9657) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0270 | Time 126.0546, Epoch Time 1638.8345(1606.4102), Bit/dim 3.5247(best: 3.5245), Xent 1.9538, Loss 4.5016, Error 0.2799(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14860 | Time 27.6437(27.1747) | Bit/dim 3.5112(3.5216) | Xent 0.0167(0.0201) | Loss 3.5195(3.5317) | Error 0.0011(0.0047) Steps 1114(1112.53) | Grad Norm 0.8120(0.9200) | Total Time 14.00(14.00)\n",
      "Iter 14870 | Time 26.2862(27.0882) | Bit/dim 3.5206(3.5212) | Xent 0.0156(0.0197) | Loss 3.5284(3.5311) | Error 0.0000(0.0044) Steps 1114(1112.74) | Grad Norm 0.6372(0.9113) | Total Time 14.00(14.00)\n",
      "Iter 14880 | Time 27.0177(27.1164) | Bit/dim 3.5440(3.5208) | Xent 0.0154(0.0198) | Loss 3.5517(3.5307) | Error 0.0033(0.0046) Steps 1132(1115.62) | Grad Norm 0.8839(0.8999) | Total Time 14.00(14.00)\n",
      "Iter 14890 | Time 27.0739(27.1401) | Bit/dim 3.4490(3.5145) | Xent 0.0263(0.0202) | Loss 3.4622(3.5246) | Error 0.0067(0.0047) Steps 1102(1113.85) | Grad Norm 1.1520(0.8979) | Total Time 14.00(14.00)\n",
      "Iter 14900 | Time 27.1824(27.1587) | Bit/dim 3.5629(3.5191) | Xent 0.0286(0.0205) | Loss 3.5772(3.5293) | Error 0.0089(0.0047) Steps 1114(1113.46) | Grad Norm 1.1297(0.9220) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0271 | Time 126.2953, Epoch Time 1638.1942(1607.3637), Bit/dim 3.5241(best: 3.5245), Xent 1.9752, Loss 4.5117, Error 0.2799(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14910 | Time 27.0269(27.1545) | Bit/dim 3.5565(3.5201) | Xent 0.0216(0.0204) | Loss 3.5673(3.5303) | Error 0.0056(0.0045) Steps 1120(1114.17) | Grad Norm 1.1043(0.9648) | Total Time 14.00(14.00)\n",
      "Iter 14920 | Time 27.4754(27.0911) | Bit/dim 3.5051(3.5198) | Xent 0.0217(0.0206) | Loss 3.5160(3.5301) | Error 0.0044(0.0046) Steps 1132(1113.34) | Grad Norm 0.8601(1.0150) | Total Time 14.00(14.00)\n",
      "Iter 14930 | Time 27.3000(27.1408) | Bit/dim 3.5334(3.5193) | Xent 0.0206(0.0206) | Loss 3.5437(3.5296) | Error 0.0044(0.0047) Steps 1114(1113.37) | Grad Norm 0.7479(1.0101) | Total Time 14.00(14.00)\n",
      "Iter 14940 | Time 27.6910(27.1967) | Bit/dim 3.5055(3.5192) | Xent 0.0155(0.0200) | Loss 3.5132(3.5293) | Error 0.0044(0.0046) Steps 1108(1112.11) | Grad Norm 0.7810(0.9607) | Total Time 14.00(14.00)\n",
      "Iter 14950 | Time 26.5564(27.2148) | Bit/dim 3.5297(3.5168) | Xent 0.0145(0.0210) | Loss 3.5370(3.5273) | Error 0.0011(0.0051) Steps 1114(1112.82) | Grad Norm 0.6787(0.9724) | Total Time 14.00(14.00)\n",
      "Iter 14960 | Time 27.1048(27.1963) | Bit/dim 3.5254(3.5195) | Xent 0.0214(0.0201) | Loss 3.5361(3.5296) | Error 0.0044(0.0046) Steps 1114(1114.07) | Grad Norm 0.7072(0.9235) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0272 | Time 125.8296, Epoch Time 1637.1261(1608.2566), Bit/dim 3.5232(best: 3.5241), Xent 1.9768, Loss 4.5116, Error 0.2821(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14970 | Time 27.1900(27.1608) | Bit/dim 3.5500(3.5214) | Xent 0.0160(0.0204) | Loss 3.5580(3.5316) | Error 0.0033(0.0047) Steps 1126(1115.82) | Grad Norm 0.7264(0.9204) | Total Time 14.00(14.00)\n",
      "Iter 14980 | Time 27.5400(27.1330) | Bit/dim 3.5073(3.5198) | Xent 0.0159(0.0206) | Loss 3.5153(3.5301) | Error 0.0044(0.0050) Steps 1132(1114.99) | Grad Norm 0.8797(0.9144) | Total Time 14.00(14.00)\n",
      "Iter 14990 | Time 27.5344(27.1061) | Bit/dim 3.5287(3.5196) | Xent 0.0210(0.0209) | Loss 3.5393(3.5300) | Error 0.0056(0.0051) Steps 1126(1114.72) | Grad Norm 1.1469(0.9552) | Total Time 14.00(14.00)\n",
      "Iter 15000 | Time 28.0621(27.1433) | Bit/dim 3.5167(3.5198) | Xent 0.0279(0.0213) | Loss 3.5306(3.5304) | Error 0.0078(0.0051) Steps 1114(1115.14) | Grad Norm 1.9655(1.0162) | Total Time 14.00(14.00)\n",
      "Iter 15010 | Time 27.0376(27.1302) | Bit/dim 3.5306(3.5180) | Xent 0.0217(0.0216) | Loss 3.5414(3.5288) | Error 0.0044(0.0054) Steps 1108(1113.58) | Grad Norm 1.1008(1.0128) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0273 | Time 127.2917, Epoch Time 1635.8136(1609.0833), Bit/dim 3.5235(best: 3.5232), Xent 1.9506, Loss 4.4988, Error 0.2785(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15020 | Time 27.6176(27.1453) | Bit/dim 3.5532(3.5188) | Xent 0.0234(0.0211) | Loss 3.5648(3.5294) | Error 0.0056(0.0052) Steps 1108(1112.54) | Grad Norm 0.9901(1.0057) | Total Time 14.00(14.00)\n",
      "Iter 15030 | Time 26.8684(27.1153) | Bit/dim 3.5196(3.5188) | Xent 0.0202(0.0206) | Loss 3.5297(3.5291) | Error 0.0033(0.0049) Steps 1108(1112.16) | Grad Norm 0.6594(0.9446) | Total Time 14.00(14.00)\n",
      "Iter 15040 | Time 27.2707(27.1089) | Bit/dim 3.5300(3.5164) | Xent 0.0176(0.0209) | Loss 3.5387(3.5268) | Error 0.0044(0.0049) Steps 1132(1113.99) | Grad Norm 0.8180(0.9705) | Total Time 14.00(14.00)\n",
      "Iter 15050 | Time 27.9133(27.1088) | Bit/dim 3.5186(3.5171) | Xent 0.0153(0.0209) | Loss 3.5262(3.5275) | Error 0.0011(0.0049) Steps 1114(1113.57) | Grad Norm 0.6273(0.9596) | Total Time 14.00(14.00)\n",
      "Iter 15060 | Time 26.7686(27.1563) | Bit/dim 3.5106(3.5182) | Xent 0.0146(0.0205) | Loss 3.5179(3.5285) | Error 0.0033(0.0048) Steps 1114(1113.03) | Grad Norm 0.8856(0.9396) | Total Time 14.00(14.00)\n",
      "Iter 15070 | Time 27.6394(27.1859) | Bit/dim 3.5304(3.5192) | Xent 0.0230(0.0205) | Loss 3.5420(3.5294) | Error 0.0067(0.0050) Steps 1096(1111.90) | Grad Norm 1.2963(0.9484) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0274 | Time 128.1596, Epoch Time 1640.2351(1610.0179), Bit/dim 3.5232(best: 3.5232), Xent 1.9736, Loss 4.5100, Error 0.2846(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15080 | Time 27.6401(27.1482) | Bit/dim 3.4812(3.5171) | Xent 0.0199(0.0204) | Loss 3.4911(3.5273) | Error 0.0044(0.0048) Steps 1084(1110.80) | Grad Norm 0.9936(0.9445) | Total Time 14.00(14.00)\n",
      "Iter 15090 | Time 26.5325(27.2094) | Bit/dim 3.5159(3.5182) | Xent 0.0267(0.0201) | Loss 3.5292(3.5282) | Error 0.0078(0.0045) Steps 1102(1112.20) | Grad Norm 1.0032(0.9481) | Total Time 14.00(14.00)\n",
      "Iter 15100 | Time 27.7461(27.2715) | Bit/dim 3.5139(3.5196) | Xent 0.0185(0.0202) | Loss 3.5232(3.5298) | Error 0.0044(0.0048) Steps 1138(1114.83) | Grad Norm 0.7854(0.9466) | Total Time 14.00(14.00)\n",
      "Iter 15110 | Time 26.5413(27.2182) | Bit/dim 3.5219(3.5184) | Xent 0.0211(0.0203) | Loss 3.5325(3.5285) | Error 0.0056(0.0050) Steps 1120(1114.73) | Grad Norm 1.2405(0.9521) | Total Time 14.00(14.00)\n",
      "Iter 15120 | Time 27.2038(27.1857) | Bit/dim 3.5065(3.5178) | Xent 0.0185(0.0199) | Loss 3.5157(3.5277) | Error 0.0044(0.0047) Steps 1126(1114.64) | Grad Norm 1.0273(0.9385) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0275 | Time 128.2326, Epoch Time 1643.0220(1611.0080), Bit/dim 3.5220(best: 3.5232), Xent 1.9844, Loss 4.5141, Error 0.2796(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15130 | Time 27.1675(27.1672) | Bit/dim 3.5223(3.5164) | Xent 0.0210(0.0202) | Loss 3.5328(3.5265) | Error 0.0033(0.0047) Steps 1114(1115.71) | Grad Norm 0.8982(0.9598) | Total Time 14.00(14.00)\n",
      "Iter 15140 | Time 27.3560(27.0391) | Bit/dim 3.5045(3.5167) | Xent 0.0168(0.0199) | Loss 3.5129(3.5267) | Error 0.0011(0.0044) Steps 1132(1113.77) | Grad Norm 0.6577(0.9444) | Total Time 14.00(14.00)\n",
      "Iter 15150 | Time 26.6878(27.0330) | Bit/dim 3.4919(3.5192) | Xent 0.0176(0.0196) | Loss 3.5007(3.5290) | Error 0.0056(0.0045) Steps 1108(1114.06) | Grad Norm 0.7646(0.9181) | Total Time 14.00(14.00)\n",
      "Iter 15160 | Time 26.1626(26.9727) | Bit/dim 3.5013(3.5182) | Xent 0.0169(0.0195) | Loss 3.5097(3.5280) | Error 0.0033(0.0046) Steps 1102(1113.03) | Grad Norm 0.7970(0.9336) | Total Time 14.00(14.00)\n",
      "Iter 15170 | Time 27.1945(27.0164) | Bit/dim 3.5210(3.5187) | Xent 0.0191(0.0196) | Loss 3.5306(3.5285) | Error 0.0033(0.0046) Steps 1120(1112.34) | Grad Norm 0.8522(0.9298) | Total Time 14.00(14.00)\n",
      "Iter 15180 | Time 27.1265(27.0609) | Bit/dim 3.5049(3.5175) | Xent 0.0188(0.0211) | Loss 3.5143(3.5280) | Error 0.0022(0.0049) Steps 1120(1112.40) | Grad Norm 1.0930(0.9808) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0276 | Time 127.3780, Epoch Time 1628.8842(1611.5443), Bit/dim 3.5230(best: 3.5220), Xent 1.9809, Loss 4.5134, Error 0.2721(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15190 | Time 26.8640(27.0429) | Bit/dim 3.5517(3.5185) | Xent 0.0233(0.0209) | Loss 3.5634(3.5289) | Error 0.0067(0.0051) Steps 1114(1112.03) | Grad Norm 0.8924(0.9891) | Total Time 14.00(14.00)\n",
      "Iter 15200 | Time 27.4165(27.1264) | Bit/dim 3.5014(3.5180) | Xent 0.0252(0.0214) | Loss 3.5140(3.5288) | Error 0.0067(0.0053) Steps 1108(1112.04) | Grad Norm 0.9530(1.0378) | Total Time 14.00(14.00)\n",
      "Iter 15210 | Time 27.6491(27.2167) | Bit/dim 3.5215(3.5178) | Xent 0.0157(0.0209) | Loss 3.5294(3.5283) | Error 0.0033(0.0050) Steps 1102(1111.69) | Grad Norm 0.9169(1.0384) | Total Time 14.00(14.00)\n",
      "Iter 15220 | Time 27.8233(27.2071) | Bit/dim 3.5381(3.5190) | Xent 0.0256(0.0216) | Loss 3.5509(3.5298) | Error 0.0044(0.0052) Steps 1126(1112.04) | Grad Norm 1.4453(1.0723) | Total Time 14.00(14.00)\n",
      "Iter 15230 | Time 27.1163(27.1866) | Bit/dim 3.5058(3.5174) | Xent 0.0225(0.0210) | Loss 3.5170(3.5279) | Error 0.0056(0.0049) Steps 1114(1112.10) | Grad Norm 0.9117(1.0363) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0277 | Time 126.2611, Epoch Time 1641.4795(1612.4423), Bit/dim 3.5217(best: 3.5220), Xent 1.9678, Loss 4.5056, Error 0.2809(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15240 | Time 27.7650(27.2179) | Bit/dim 3.5018(3.5178) | Xent 0.0129(0.0208) | Loss 3.5083(3.5282) | Error 0.0022(0.0047) Steps 1102(1112.25) | Grad Norm 0.6854(0.9998) | Total Time 14.00(14.00)\n",
      "Iter 15250 | Time 26.9117(27.2641) | Bit/dim 3.5349(3.5197) | Xent 0.0149(0.0197) | Loss 3.5423(3.5296) | Error 0.0033(0.0042) Steps 1108(1113.18) | Grad Norm 0.6365(0.9448) | Total Time 14.00(14.00)\n",
      "Iter 15260 | Time 26.9597(27.2510) | Bit/dim 3.5090(3.5192) | Xent 0.0261(0.0199) | Loss 3.5221(3.5292) | Error 0.0067(0.0043) Steps 1126(1112.87) | Grad Norm 1.0525(0.9322) | Total Time 14.00(14.00)\n",
      "Iter 15270 | Time 27.9078(27.2662) | Bit/dim 3.5622(3.5201) | Xent 0.0131(0.0193) | Loss 3.5687(3.5297) | Error 0.0022(0.0041) Steps 1120(1113.42) | Grad Norm 0.6380(0.8983) | Total Time 14.00(14.00)\n",
      "Iter 15280 | Time 27.2295(27.2581) | Bit/dim 3.5007(3.5166) | Xent 0.0250(0.0198) | Loss 3.5132(3.5265) | Error 0.0100(0.0044) Steps 1120(1112.97) | Grad Norm 1.0533(0.9016) | Total Time 14.00(14.00)\n",
      "Iter 15290 | Time 27.8591(27.2952) | Bit/dim 3.5367(3.5161) | Xent 0.0260(0.0204) | Loss 3.5497(3.5263) | Error 0.0078(0.0048) Steps 1108(1113.92) | Grad Norm 1.0243(0.9251) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0278 | Time 125.7665, Epoch Time 1646.0646(1613.4510), Bit/dim 3.5238(best: 3.5217), Xent 2.0120, Loss 4.5298, Error 0.2794(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15300 | Time 27.6913(27.2742) | Bit/dim 3.5206(3.5160) | Xent 0.0179(0.0202) | Loss 3.5296(3.5261) | Error 0.0033(0.0046) Steps 1114(1114.94) | Grad Norm 0.9837(0.9467) | Total Time 14.00(14.00)\n",
      "Iter 15310 | Time 27.0419(27.1838) | Bit/dim 3.5106(3.5153) | Xent 0.0188(0.0202) | Loss 3.5200(3.5254) | Error 0.0033(0.0046) Steps 1102(1113.07) | Grad Norm 1.0320(0.9447) | Total Time 14.00(14.00)\n",
      "Iter 15320 | Time 28.3681(27.2509) | Bit/dim 3.5169(3.5169) | Xent 0.0203(0.0201) | Loss 3.5270(3.5270) | Error 0.0033(0.0046) Steps 1120(1112.97) | Grad Norm 1.0198(0.9607) | Total Time 14.00(14.00)\n",
      "Iter 15330 | Time 26.8624(27.2242) | Bit/dim 3.4861(3.5167) | Xent 0.0173(0.0198) | Loss 3.4947(3.5266) | Error 0.0022(0.0045) Steps 1096(1112.22) | Grad Norm 1.0410(0.9504) | Total Time 14.00(14.00)\n",
      "Iter 15340 | Time 26.6991(27.1828) | Bit/dim 3.5354(3.5172) | Xent 0.0254(0.0197) | Loss 3.5481(3.5271) | Error 0.0067(0.0044) Steps 1126(1112.97) | Grad Norm 1.2257(0.9521) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0279 | Time 126.7918, Epoch Time 1638.2798(1614.1959), Bit/dim 3.5211(best: 3.5217), Xent 1.9753, Loss 4.5088, Error 0.2803(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15350 | Time 27.4786(27.1963) | Bit/dim 3.5194(3.5188) | Xent 0.0252(0.0202) | Loss 3.5321(3.5289) | Error 0.0067(0.0047) Steps 1096(1112.29) | Grad Norm 1.0339(0.9756) | Total Time 14.00(14.00)\n",
      "Iter 15360 | Time 28.0660(27.2848) | Bit/dim 3.5175(3.5181) | Xent 0.0290(0.0205) | Loss 3.5321(3.5283) | Error 0.0056(0.0050) Steps 1126(1112.89) | Grad Norm 1.0920(0.9997) | Total Time 14.00(14.00)\n",
      "Iter 15370 | Time 26.6283(27.2739) | Bit/dim 3.4973(3.5191) | Xent 0.0149(0.0201) | Loss 3.5048(3.5292) | Error 0.0022(0.0048) Steps 1108(1113.44) | Grad Norm 0.7467(0.9736) | Total Time 14.00(14.00)\n",
      "Iter 15380 | Time 26.6759(27.1231) | Bit/dim 3.5260(3.5166) | Xent 0.0180(0.0200) | Loss 3.5350(3.5266) | Error 0.0044(0.0048) Steps 1120(1112.72) | Grad Norm 0.9540(0.9924) | Total Time 14.00(14.00)\n",
      "Iter 15390 | Time 26.6811(27.0919) | Bit/dim 3.5065(3.5166) | Xent 0.0155(0.0198) | Loss 3.5143(3.5265) | Error 0.0033(0.0046) Steps 1108(1114.08) | Grad Norm 0.9136(1.0045) | Total Time 14.00(14.00)\n",
      "Iter 15400 | Time 27.0548(27.0557) | Bit/dim 3.5263(3.5168) | Xent 0.0165(0.0205) | Loss 3.5345(3.5270) | Error 0.0033(0.0048) Steps 1114(1112.25) | Grad Norm 0.7336(1.0153) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0280 | Time 126.9817, Epoch Time 1635.8097(1614.8443), Bit/dim 3.5224(best: 3.5211), Xent 1.9930, Loss 4.5189, Error 0.2781(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15410 | Time 27.4225(27.0728) | Bit/dim 3.5051(3.5151) | Xent 0.0169(0.0206) | Loss 3.5135(3.5253) | Error 0.0033(0.0047) Steps 1108(1111.61) | Grad Norm 1.1396(1.0349) | Total Time 14.00(14.00)\n",
      "Iter 15420 | Time 27.3434(27.1249) | Bit/dim 3.5411(3.5154) | Xent 0.0248(0.0209) | Loss 3.5535(3.5259) | Error 0.0067(0.0051) Steps 1114(1110.95) | Grad Norm 1.2038(1.0535) | Total Time 14.00(14.00)\n",
      "Iter 15430 | Time 27.2834(27.2181) | Bit/dim 3.5169(3.5132) | Xent 0.0141(0.0212) | Loss 3.5239(3.5237) | Error 0.0022(0.0053) Steps 1102(1110.15) | Grad Norm 0.7549(1.0895) | Total Time 14.00(14.00)\n",
      "Iter 15440 | Time 27.7541(27.3251) | Bit/dim 3.5311(3.5163) | Xent 0.0172(0.0205) | Loss 3.5397(3.5265) | Error 0.0067(0.0050) Steps 1114(1109.45) | Grad Norm 1.2295(1.0472) | Total Time 14.00(14.00)\n",
      "Iter 15450 | Time 27.1523(27.3430) | Bit/dim 3.5554(3.5176) | Xent 0.0154(0.0196) | Loss 3.5632(3.5274) | Error 0.0044(0.0046) Steps 1108(1109.99) | Grad Norm 0.7982(1.0109) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0281 | Time 127.1941, Epoch Time 1650.0768(1615.9013), Bit/dim 3.5215(best: 3.5211), Xent 2.0223, Loss 4.5326, Error 0.2811(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15460 | Time 26.5659(27.2124) | Bit/dim 3.5158(3.5181) | Xent 0.0203(0.0198) | Loss 3.5259(3.5280) | Error 0.0056(0.0047) Steps 1108(1111.01) | Grad Norm 0.9778(1.0529) | Total Time 14.00(14.00)\n",
      "Iter 15470 | Time 27.4290(27.1945) | Bit/dim 3.5234(3.5189) | Xent 0.0196(0.0199) | Loss 3.5332(3.5288) | Error 0.0033(0.0047) Steps 1102(1111.02) | Grad Norm 0.8594(1.0466) | Total Time 14.00(14.00)\n",
      "Iter 15480 | Time 27.5194(27.2562) | Bit/dim 3.5305(3.5181) | Xent 0.0176(0.0201) | Loss 3.5393(3.5282) | Error 0.0033(0.0048) Steps 1126(1113.31) | Grad Norm 1.3006(1.1116) | Total Time 14.00(14.00)\n",
      "Iter 15490 | Time 27.7050(27.2781) | Bit/dim 3.5189(3.5174) | Xent 0.0224(0.0206) | Loss 3.5301(3.5277) | Error 0.0044(0.0051) Steps 1114(1111.86) | Grad Norm 1.6338(1.1806) | Total Time 14.00(14.00)\n",
      "Iter 15500 | Time 27.1981(27.2461) | Bit/dim 3.5411(3.5173) | Xent 0.0130(0.0203) | Loss 3.5476(3.5275) | Error 0.0022(0.0051) Steps 1114(1111.66) | Grad Norm 1.2001(1.2237) | Total Time 14.00(14.00)\n",
      "Iter 15510 | Time 27.0023(27.2614) | Bit/dim 3.4983(3.5168) | Xent 0.0228(0.0205) | Loss 3.5097(3.5271) | Error 0.0044(0.0050) Steps 1108(1112.61) | Grad Norm 1.0766(1.2692) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0282 | Time 128.2466, Epoch Time 1642.5032(1616.6993), Bit/dim 3.5218(best: 3.5211), Xent 2.0298, Loss 4.5367, Error 0.2831(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15520 | Time 27.6169(27.2466) | Bit/dim 3.5171(3.5148) | Xent 0.0161(0.0201) | Loss 3.5252(3.5248) | Error 0.0033(0.0048) Steps 1108(1112.47) | Grad Norm 0.8225(1.2068) | Total Time 14.00(14.00)\n",
      "Iter 15530 | Time 26.8743(27.1478) | Bit/dim 3.5241(3.5133) | Xent 0.0223(0.0199) | Loss 3.5353(3.5233) | Error 0.0044(0.0047) Steps 1108(1111.55) | Grad Norm 1.0558(1.1604) | Total Time 14.00(14.00)\n",
      "Iter 15540 | Time 27.3684(27.2217) | Bit/dim 3.4874(3.5156) | Xent 0.0199(0.0199) | Loss 3.4973(3.5255) | Error 0.0044(0.0047) Steps 1108(1111.74) | Grad Norm 1.1214(1.1748) | Total Time 14.00(14.00)\n",
      "Iter 15550 | Time 27.6519(27.1829) | Bit/dim 3.5402(3.5158) | Xent 0.0228(0.0204) | Loss 3.5516(3.5260) | Error 0.0111(0.0048) Steps 1120(1111.22) | Grad Norm 1.1677(1.1591) | Total Time 14.00(14.00)\n",
      "Iter 15560 | Time 26.1575(27.1651) | Bit/dim 3.5262(3.5166) | Xent 0.0215(0.0200) | Loss 3.5369(3.5266) | Error 0.0078(0.0050) Steps 1108(1111.06) | Grad Norm 1.0319(1.1303) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0283 | Time 128.7923, Epoch Time 1638.6223(1617.3570), Bit/dim 3.5199(best: 3.5211), Xent 2.0096, Loss 4.5247, Error 0.2785(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15570 | Time 27.4476(27.1554) | Bit/dim 3.5259(3.5178) | Xent 0.0209(0.0199) | Loss 3.5363(3.5278) | Error 0.0044(0.0050) Steps 1144(1112.02) | Grad Norm 0.9281(1.0956) | Total Time 14.00(14.00)\n",
      "Iter 15580 | Time 27.3725(27.2076) | Bit/dim 3.5099(3.5169) | Xent 0.0229(0.0198) | Loss 3.5213(3.5268) | Error 0.0067(0.0051) Steps 1108(1113.04) | Grad Norm 1.3462(1.0699) | Total Time 14.00(14.00)\n",
      "Iter 15590 | Time 27.1563(27.2715) | Bit/dim 3.5322(3.5153) | Xent 0.0186(0.0194) | Loss 3.5414(3.5250) | Error 0.0044(0.0047) Steps 1114(1112.12) | Grad Norm 1.0265(1.0331) | Total Time 14.00(14.00)\n",
      "Iter 15600 | Time 27.4153(27.3220) | Bit/dim 3.5159(3.5160) | Xent 0.0196(0.0192) | Loss 3.5257(3.5256) | Error 0.0056(0.0047) Steps 1132(1112.50) | Grad Norm 0.9576(1.0066) | Total Time 14.00(14.00)\n",
      "Iter 15610 | Time 26.7208(27.3189) | Bit/dim 3.5046(3.5151) | Xent 0.0187(0.0195) | Loss 3.5139(3.5249) | Error 0.0044(0.0046) Steps 1108(1112.26) | Grad Norm 1.3116(1.0237) | Total Time 14.00(14.00)\n",
      "Iter 15620 | Time 27.6967(27.3449) | Bit/dim 3.5326(3.5152) | Xent 0.0153(0.0189) | Loss 3.5402(3.5247) | Error 0.0011(0.0042) Steps 1096(1112.06) | Grad Norm 0.7680(0.9838) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0284 | Time 128.0590, Epoch Time 1652.3571(1618.4070), Bit/dim 3.5206(best: 3.5199), Xent 2.0175, Loss 4.5293, Error 0.2820(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15630 | Time 27.5142(27.3003) | Bit/dim 3.5326(3.5159) | Xent 0.0213(0.0193) | Loss 3.5432(3.5255) | Error 0.0067(0.0046) Steps 1126(1112.30) | Grad Norm 0.9226(0.9896) | Total Time 14.00(14.00)\n",
      "Iter 15640 | Time 27.8944(27.3543) | Bit/dim 3.4943(3.5170) | Xent 0.0191(0.0188) | Loss 3.5039(3.5265) | Error 0.0033(0.0043) Steps 1114(1111.88) | Grad Norm 0.8168(0.9657) | Total Time 14.00(14.00)\n",
      "Iter 15650 | Time 26.8404(27.3417) | Bit/dim 3.4593(3.5156) | Xent 0.0190(0.0186) | Loss 3.4688(3.5249) | Error 0.0044(0.0042) Steps 1096(1110.79) | Grad Norm 0.9830(0.9690) | Total Time 14.00(14.00)\n",
      "Iter 15660 | Time 26.9749(27.3875) | Bit/dim 3.4942(3.5139) | Xent 0.0152(0.0190) | Loss 3.5018(3.5234) | Error 0.0022(0.0043) Steps 1114(1111.73) | Grad Norm 0.7329(0.9497) | Total Time 14.00(14.00)\n",
      "Iter 15670 | Time 27.6237(27.4042) | Bit/dim 3.5024(3.5125) | Xent 0.0185(0.0195) | Loss 3.5117(3.5222) | Error 0.0033(0.0046) Steps 1102(1112.34) | Grad Norm 0.9052(0.9676) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0285 | Time 127.2813, Epoch Time 1652.0956(1619.4177), Bit/dim 3.5191(best: 3.5199), Xent 2.0362, Loss 4.5372, Error 0.2818(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15680 | Time 26.9754(27.3564) | Bit/dim 3.5341(3.5132) | Xent 0.0208(0.0196) | Loss 3.5445(3.5230) | Error 0.0067(0.0047) Steps 1120(1112.41) | Grad Norm 0.8698(0.9545) | Total Time 14.00(14.00)\n",
      "Iter 15690 | Time 26.7923(27.3259) | Bit/dim 3.4878(3.5159) | Xent 0.0224(0.0193) | Loss 3.4990(3.5255) | Error 0.0056(0.0046) Steps 1108(1113.21) | Grad Norm 1.3800(0.9636) | Total Time 14.00(14.00)\n",
      "Iter 15700 | Time 27.6709(27.3852) | Bit/dim 3.5109(3.5162) | Xent 0.0149(0.0190) | Loss 3.5184(3.5257) | Error 0.0022(0.0045) Steps 1096(1113.79) | Grad Norm 0.7693(0.9679) | Total Time 14.00(14.00)\n",
      "Iter 15710 | Time 27.1700(27.3325) | Bit/dim 3.5281(3.5164) | Xent 0.0170(0.0188) | Loss 3.5366(3.5258) | Error 0.0022(0.0046) Steps 1108(1111.85) | Grad Norm 0.8994(0.9415) | Total Time 14.00(14.00)\n",
      "Iter 15720 | Time 27.4028(27.2853) | Bit/dim 3.5488(3.5149) | Xent 0.0147(0.0191) | Loss 3.5561(3.5244) | Error 0.0011(0.0046) Steps 1108(1111.74) | Grad Norm 0.6693(0.9802) | Total Time 14.00(14.00)\n",
      "Iter 15730 | Time 27.1657(27.1819) | Bit/dim 3.5031(3.5145) | Xent 0.0162(0.0193) | Loss 3.5112(3.5242) | Error 0.0033(0.0047) Steps 1102(1111.11) | Grad Norm 0.9025(0.9981) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0286 | Time 128.2933, Epoch Time 1641.9740(1620.0944), Bit/dim 3.5195(best: 3.5191), Xent 2.0572, Loss 4.5481, Error 0.2815(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15740 | Time 27.7298(27.1291) | Bit/dim 3.5490(3.5150) | Xent 0.0118(0.0196) | Loss 3.5549(3.5248) | Error 0.0011(0.0048) Steps 1108(1111.48) | Grad Norm 0.9287(1.0261) | Total Time 14.00(14.00)\n",
      "Iter 15750 | Time 26.8488(27.1945) | Bit/dim 3.5041(3.5137) | Xent 0.0159(0.0194) | Loss 3.5120(3.5234) | Error 0.0044(0.0045) Steps 1114(1111.57) | Grad Norm 1.2995(1.0446) | Total Time 14.00(14.00)\n",
      "Iter 15760 | Time 26.7170(27.1933) | Bit/dim 3.5043(3.5158) | Xent 0.0136(0.0191) | Loss 3.5110(3.5253) | Error 0.0011(0.0044) Steps 1102(1111.94) | Grad Norm 0.9844(1.0933) | Total Time 14.00(14.00)\n",
      "Iter 15770 | Time 27.9203(27.1907) | Bit/dim 3.5344(3.5161) | Xent 0.0177(0.0194) | Loss 3.5432(3.5258) | Error 0.0033(0.0045) Steps 1114(1111.24) | Grad Norm 1.2241(1.0988) | Total Time 14.00(14.00)\n",
      "Iter 15780 | Time 27.7243(27.2318) | Bit/dim 3.5209(3.5145) | Xent 0.0159(0.0205) | Loss 3.5288(3.5248) | Error 0.0011(0.0048) Steps 1126(1112.21) | Grad Norm 1.0763(1.1358) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0287 | Time 126.8949, Epoch Time 1641.9625(1620.7504), Bit/dim 3.5221(best: 3.5191), Xent 2.0450, Loss 4.5446, Error 0.2798(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15790 | Time 26.9950(27.2273) | Bit/dim 3.4918(3.5128) | Xent 0.0232(0.0204) | Loss 3.5034(3.5230) | Error 0.0089(0.0050) Steps 1108(1112.41) | Grad Norm 1.3253(1.1582) | Total Time 14.00(14.00)\n",
      "Iter 15800 | Time 27.4645(27.2245) | Bit/dim 3.5035(3.5136) | Xent 0.0233(0.0204) | Loss 3.5152(3.5238) | Error 0.0044(0.0051) Steps 1096(1112.77) | Grad Norm 0.8723(1.1190) | Total Time 14.00(14.00)\n",
      "Iter 15810 | Time 26.6374(27.2529) | Bit/dim 3.4760(3.5127) | Xent 0.0285(0.0197) | Loss 3.4902(3.5226) | Error 0.0100(0.0048) Steps 1108(1112.75) | Grad Norm 1.2542(1.0745) | Total Time 14.00(14.00)\n",
      "Iter 15820 | Time 27.5524(27.3186) | Bit/dim 3.5021(3.5126) | Xent 0.0243(0.0200) | Loss 3.5143(3.5226) | Error 0.0078(0.0048) Steps 1108(1112.61) | Grad Norm 1.5516(1.0746) | Total Time 14.00(14.00)\n",
      "Iter 15830 | Time 26.8313(27.2836) | Bit/dim 3.5305(3.5146) | Xent 0.0245(0.0202) | Loss 3.5427(3.5247) | Error 0.0089(0.0050) Steps 1126(1113.11) | Grad Norm 1.3801(1.1223) | Total Time 14.00(14.00)\n",
      "Iter 15840 | Time 27.0429(27.2170) | Bit/dim 3.5012(3.5142) | Xent 0.0169(0.0199) | Loss 3.5096(3.5242) | Error 0.0022(0.0049) Steps 1114(1113.23) | Grad Norm 1.3837(1.1143) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0288 | Time 127.2992, Epoch Time 1644.1187(1621.4515), Bit/dim 3.5205(best: 3.5191), Xent 2.0951, Loss 4.5680, Error 0.2849(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15850 | Time 26.8728(27.1217) | Bit/dim 3.5056(3.5149) | Xent 0.0205(0.0194) | Loss 3.5159(3.5246) | Error 0.0033(0.0047) Steps 1108(1112.77) | Grad Norm 1.1233(1.0829) | Total Time 14.00(14.00)\n",
      "Iter 15860 | Time 26.8377(27.1267) | Bit/dim 3.4977(3.5117) | Xent 0.0126(0.0191) | Loss 3.5040(3.5212) | Error 0.0011(0.0045) Steps 1096(1111.88) | Grad Norm 0.9684(1.0523) | Total Time 14.00(14.00)\n",
      "Iter 15870 | Time 26.6227(27.0814) | Bit/dim 3.5286(3.5133) | Xent 0.0247(0.0195) | Loss 3.5409(3.5231) | Error 0.0067(0.0046) Steps 1114(1113.03) | Grad Norm 1.1075(1.0373) | Total Time 14.00(14.00)\n",
      "Iter 15880 | Time 26.6170(27.0763) | Bit/dim 3.4962(3.5146) | Xent 0.0176(0.0193) | Loss 3.5050(3.5243) | Error 0.0033(0.0044) Steps 1120(1114.96) | Grad Norm 0.8413(1.0180) | Total Time 14.00(14.00)\n",
      "Iter 15890 | Time 26.9315(27.0869) | Bit/dim 3.4883(3.5128) | Xent 0.0223(0.0204) | Loss 3.4994(3.5230) | Error 0.0044(0.0048) Steps 1108(1112.93) | Grad Norm 1.0964(1.0363) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0289 | Time 126.9600, Epoch Time 1630.6569(1621.7276), Bit/dim 3.5188(best: 3.5191), Xent 2.0769, Loss 4.5573, Error 0.2824(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15900 | Time 26.5090(27.0465) | Bit/dim 3.4805(3.5135) | Xent 0.0199(0.0200) | Loss 3.4904(3.5235) | Error 0.0056(0.0045) Steps 1114(1113.52) | Grad Norm 1.9142(1.0748) | Total Time 14.00(14.00)\n",
      "Iter 15910 | Time 26.4236(27.0002) | Bit/dim 3.4799(3.5112) | Xent 0.0229(0.0198) | Loss 3.4914(3.5211) | Error 0.0067(0.0047) Steps 1114(1113.59) | Grad Norm 1.0776(1.0651) | Total Time 14.00(14.00)\n",
      "Iter 15920 | Time 27.4095(27.0688) | Bit/dim 3.4887(3.5116) | Xent 0.0124(0.0192) | Loss 3.4949(3.5213) | Error 0.0022(0.0044) Steps 1114(1113.22) | Grad Norm 0.8580(1.0613) | Total Time 14.00(14.00)\n",
      "Iter 15930 | Time 27.8545(27.1372) | Bit/dim 3.5385(3.5153) | Xent 0.0172(0.0189) | Loss 3.5471(3.5247) | Error 0.0056(0.0042) Steps 1138(1113.40) | Grad Norm 0.8086(1.0399) | Total Time 14.00(14.00)\n",
      "Iter 15940 | Time 27.5557(27.1237) | Bit/dim 3.5134(3.5162) | Xent 0.0207(0.0191) | Loss 3.5238(3.5258) | Error 0.0078(0.0042) Steps 1114(1112.96) | Grad Norm 1.1258(1.0322) | Total Time 14.00(14.00)\n",
      "Iter 15950 | Time 26.8361(27.0674) | Bit/dim 3.4986(3.5153) | Xent 0.0227(0.0190) | Loss 3.5100(3.5249) | Error 0.0067(0.0042) Steps 1120(1112.29) | Grad Norm 1.2589(1.0424) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0290 | Time 126.9264, Epoch Time 1634.2744(1622.1040), Bit/dim 3.5179(best: 3.5188), Xent 2.0586, Loss 4.5472, Error 0.2836(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15960 | Time 27.1561(27.0726) | Bit/dim 3.4991(3.5157) | Xent 0.0179(0.0196) | Loss 3.5081(3.5255) | Error 0.0033(0.0044) Steps 1138(1113.26) | Grad Norm 1.1263(1.0809) | Total Time 14.00(14.00)\n",
      "Iter 15970 | Time 26.5340(27.0777) | Bit/dim 3.5131(3.5135) | Xent 0.0151(0.0195) | Loss 3.5207(3.5233) | Error 0.0033(0.0046) Steps 1126(1113.18) | Grad Norm 1.1305(1.0711) | Total Time 14.00(14.00)\n",
      "Iter 15980 | Time 27.7629(27.0445) | Bit/dim 3.5029(3.5152) | Xent 0.0123(0.0198) | Loss 3.5090(3.5251) | Error 0.0011(0.0047) Steps 1114(1113.44) | Grad Norm 0.8850(1.0744) | Total Time 14.00(14.00)\n",
      "Iter 15990 | Time 26.2834(27.0524) | Bit/dim 3.5074(3.5151) | Xent 0.0242(0.0195) | Loss 3.5195(3.5248) | Error 0.0044(0.0045) Steps 1114(1113.55) | Grad Norm 1.6147(1.0857) | Total Time 14.00(14.00)\n",
      "Iter 16000 | Time 27.1072(27.1417) | Bit/dim 3.4995(3.5142) | Xent 0.0208(0.0196) | Loss 3.5099(3.5240) | Error 0.0044(0.0045) Steps 1114(1114.18) | Grad Norm 1.0308(1.0796) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0291 | Time 125.6693, Epoch Time 1634.4584(1622.4747), Bit/dim 3.5187(best: 3.5179), Xent 2.0760, Loss 4.5567, Error 0.2841(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16010 | Time 26.6764(27.0812) | Bit/dim 3.5204(3.5130) | Xent 0.0225(0.0197) | Loss 3.5317(3.5228) | Error 0.0067(0.0046) Steps 1108(1113.78) | Grad Norm 0.9957(1.0659) | Total Time 14.00(14.00)\n",
      "Iter 16020 | Time 27.8571(27.1591) | Bit/dim 3.4859(3.5105) | Xent 0.0199(0.0191) | Loss 3.4958(3.5200) | Error 0.0056(0.0043) Steps 1114(1111.60) | Grad Norm 1.0482(1.0310) | Total Time 14.00(14.00)\n",
      "Iter 16030 | Time 26.8172(27.2126) | Bit/dim 3.4699(3.5101) | Xent 0.0178(0.0189) | Loss 3.4788(3.5195) | Error 0.0033(0.0044) Steps 1102(1112.06) | Grad Norm 0.8172(1.0120) | Total Time 14.00(14.00)\n",
      "Iter 16040 | Time 27.1165(27.2735) | Bit/dim 3.5239(3.5133) | Xent 0.0218(0.0186) | Loss 3.5348(3.5226) | Error 0.0078(0.0044) Steps 1132(1112.87) | Grad Norm 1.3457(1.0139) | Total Time 14.00(14.00)\n",
      "Iter 16050 | Time 26.9159(27.1754) | Bit/dim 3.4961(3.5132) | Xent 0.0227(0.0192) | Loss 3.5075(3.5228) | Error 0.0056(0.0047) Steps 1102(1112.94) | Grad Norm 1.0779(1.0442) | Total Time 14.00(14.00)\n",
      "Iter 16060 | Time 27.6712(27.1601) | Bit/dim 3.4995(3.5147) | Xent 0.0193(0.0194) | Loss 3.5092(3.5244) | Error 0.0056(0.0048) Steps 1108(1112.10) | Grad Norm 1.0480(1.0903) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0292 | Time 126.8193, Epoch Time 1640.9258(1623.0282), Bit/dim 3.5193(best: 3.5179), Xent 2.0798, Loss 4.5592, Error 0.2836(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16070 | Time 27.3957(27.1365) | Bit/dim 3.5359(3.5153) | Xent 0.0163(0.0193) | Loss 3.5440(3.5250) | Error 0.0044(0.0047) Steps 1126(1112.52) | Grad Norm 0.8956(1.0871) | Total Time 14.00(14.00)\n",
      "Iter 16080 | Time 26.3093(27.0653) | Bit/dim 3.4951(3.5131) | Xent 0.0116(0.0189) | Loss 3.5009(3.5226) | Error 0.0000(0.0042) Steps 1108(1113.06) | Grad Norm 0.7913(1.0726) | Total Time 14.00(14.00)\n",
      "Iter 16090 | Time 27.7165(27.1234) | Bit/dim 3.4787(3.5137) | Xent 0.0152(0.0190) | Loss 3.4863(3.5232) | Error 0.0033(0.0043) Steps 1096(1111.56) | Grad Norm 0.8917(1.0530) | Total Time 14.00(14.00)\n",
      "Iter 16100 | Time 26.6003(27.0701) | Bit/dim 3.4936(3.5111) | Xent 0.0175(0.0190) | Loss 3.5024(3.5206) | Error 0.0044(0.0043) Steps 1108(1111.12) | Grad Norm 1.6300(1.0714) | Total Time 14.00(14.00)\n",
      "Iter 16110 | Time 26.0700(27.0534) | Bit/dim 3.5096(3.5130) | Xent 0.0161(0.0192) | Loss 3.5176(3.5227) | Error 0.0044(0.0048) Steps 1108(1110.76) | Grad Norm 1.1292(1.0883) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0293 | Time 126.6151, Epoch Time 1629.9240(1623.2351), Bit/dim 3.5186(best: 3.5179), Xent 2.0909, Loss 4.5640, Error 0.2779(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16120 | Time 26.5806(26.9725) | Bit/dim 3.5004(3.5131) | Xent 0.0342(0.0198) | Loss 3.5175(3.5230) | Error 0.0100(0.0049) Steps 1114(1111.65) | Grad Norm 1.4517(1.0923) | Total Time 14.00(14.00)\n",
      "Iter 16130 | Time 27.0757(27.0260) | Bit/dim 3.5136(3.5162) | Xent 0.0176(0.0198) | Loss 3.5224(3.5261) | Error 0.0033(0.0049) Steps 1096(1111.59) | Grad Norm 0.8324(1.1019) | Total Time 14.00(14.00)\n",
      "Iter 16140 | Time 27.0297(26.9988) | Bit/dim 3.5069(3.5155) | Xent 0.0209(0.0194) | Loss 3.5173(3.5252) | Error 0.0044(0.0049) Steps 1114(1110.70) | Grad Norm 1.2323(1.0880) | Total Time 14.00(14.00)\n",
      "Iter 16150 | Time 26.8771(27.0126) | Bit/dim 3.5323(3.5134) | Xent 0.0201(0.0204) | Loss 3.5423(3.5236) | Error 0.0022(0.0054) Steps 1102(1109.79) | Grad Norm 1.2609(1.1802) | Total Time 14.00(14.00)\n",
      "Iter 16160 | Time 27.1418(27.0052) | Bit/dim 3.4994(3.5132) | Xent 0.0148(0.0201) | Loss 3.5069(3.5232) | Error 0.0022(0.0050) Steps 1096(1109.13) | Grad Norm 0.8364(1.1651) | Total Time 14.00(14.00)\n",
      "Iter 16170 | Time 27.7627(27.0496) | Bit/dim 3.5385(3.5128) | Xent 0.0168(0.0199) | Loss 3.5469(3.5228) | Error 0.0044(0.0050) Steps 1126(1110.76) | Grad Norm 0.8807(1.1436) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0294 | Time 127.0745, Epoch Time 1632.1324(1623.5020), Bit/dim 3.5179(best: 3.5179), Xent 2.1052, Loss 4.5706, Error 0.2815(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16180 | Time 27.7488(27.1298) | Bit/dim 3.4868(3.5127) | Xent 0.0187(0.0194) | Loss 3.4961(3.5225) | Error 0.0044(0.0048) Steps 1126(1110.68) | Grad Norm 1.2325(1.1037) | Total Time 14.00(14.00)\n",
      "Iter 16190 | Time 26.6400(27.2267) | Bit/dim 3.4827(3.5142) | Xent 0.0236(0.0196) | Loss 3.4945(3.5240) | Error 0.0067(0.0048) Steps 1114(1111.39) | Grad Norm 1.2175(1.0950) | Total Time 14.00(14.00)\n",
      "Iter 16200 | Time 27.0736(27.1505) | Bit/dim 3.4995(3.5131) | Xent 0.0167(0.0196) | Loss 3.5078(3.5229) | Error 0.0033(0.0048) Steps 1114(1111.09) | Grad Norm 1.0551(1.0787) | Total Time 14.00(14.00)\n",
      "Iter 16210 | Time 26.8989(27.1849) | Bit/dim 3.5140(3.5151) | Xent 0.0189(0.0193) | Loss 3.5235(3.5247) | Error 0.0056(0.0047) Steps 1114(1111.84) | Grad Norm 1.0671(1.0551) | Total Time 14.00(14.00)\n",
      "Iter 16220 | Time 27.3123(27.1153) | Bit/dim 3.5484(3.5122) | Xent 0.0137(0.0193) | Loss 3.5553(3.5218) | Error 0.0033(0.0048) Steps 1120(1111.56) | Grad Norm 0.9245(1.0585) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0295 | Time 133.5653, Epoch Time 1647.8341(1624.2319), Bit/dim 3.5178(best: 3.5179), Xent 2.1259, Loss 4.5808, Error 0.2787(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16230 | Time 27.2717(27.1599) | Bit/dim 3.5282(3.5140) | Xent 0.0197(0.0190) | Loss 3.5380(3.5235) | Error 0.0067(0.0047) Steps 1114(1111.12) | Grad Norm 1.2838(1.0429) | Total Time 14.00(14.00)\n",
      "Iter 16240 | Time 26.6830(27.1753) | Bit/dim 3.4868(3.5135) | Xent 0.0153(0.0188) | Loss 3.4945(3.5230) | Error 0.0022(0.0045) Steps 1114(1111.37) | Grad Norm 0.9788(1.0677) | Total Time 14.00(14.00)\n",
      "Iter 16250 | Time 27.4165(27.1767) | Bit/dim 3.5259(3.5152) | Xent 0.0161(0.0191) | Loss 3.5340(3.5248) | Error 0.0022(0.0048) Steps 1108(1110.94) | Grad Norm 0.9262(1.0858) | Total Time 14.00(14.00)\n",
      "Iter 16260 | Time 27.6466(27.1503) | Bit/dim 3.5153(3.5161) | Xent 0.0195(0.0193) | Loss 3.5251(3.5258) | Error 0.0056(0.0049) Steps 1120(1110.50) | Grad Norm 1.4179(1.1502) | Total Time 14.00(14.00)\n",
      "Iter 16270 | Time 27.3306(27.1374) | Bit/dim 3.4888(3.5129) | Xent 0.0166(0.0191) | Loss 3.4971(3.5224) | Error 0.0000(0.0050) Steps 1120(1110.29) | Grad Norm 0.9451(1.1668) | Total Time 14.00(14.00)\n",
      "Iter 16280 | Time 26.6024(27.1696) | Bit/dim 3.5183(3.5108) | Xent 0.0231(0.0195) | Loss 3.5299(3.5205) | Error 0.0089(0.0051) Steps 1114(1112.23) | Grad Norm 1.2296(1.1231) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0296 | Time 126.8492, Epoch Time 1639.7986(1624.6989), Bit/dim 3.5176(best: 3.5178), Xent 2.1086, Loss 4.5719, Error 0.2811(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16290 | Time 26.2154(27.0357) | Bit/dim 3.4901(3.5101) | Xent 0.0177(0.0186) | Loss 3.4990(3.5194) | Error 0.0078(0.0047) Steps 1102(1111.60) | Grad Norm 1.1327(1.0854) | Total Time 14.00(14.00)\n",
      "Iter 16300 | Time 27.1787(26.9860) | Bit/dim 3.5221(3.5105) | Xent 0.0196(0.0185) | Loss 3.5319(3.5198) | Error 0.0033(0.0046) Steps 1120(1113.21) | Grad Norm 1.3506(1.0768) | Total Time 14.00(14.00)\n",
      "Iter 16310 | Time 27.3971(27.0929) | Bit/dim 3.5207(3.5117) | Xent 0.0167(0.0192) | Loss 3.5290(3.5213) | Error 0.0022(0.0048) Steps 1108(1112.59) | Grad Norm 1.4130(1.0966) | Total Time 14.00(14.00)\n",
      "Iter 16320 | Time 26.5613(27.0821) | Bit/dim 3.5361(3.5121) | Xent 0.0161(0.0191) | Loss 3.5441(3.5217) | Error 0.0044(0.0048) Steps 1114(1112.53) | Grad Norm 1.0910(1.0981) | Total Time 14.00(14.00)\n",
      "Iter 16330 | Time 26.8597(27.0522) | Bit/dim 3.5086(3.5118) | Xent 0.0173(0.0190) | Loss 3.5173(3.5213) | Error 0.0033(0.0047) Steps 1108(1113.40) | Grad Norm 1.4055(1.1174) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0297 | Time 124.9222, Epoch Time 1626.4973(1624.7529), Bit/dim 3.5176(best: 3.5176), Xent 2.1158, Loss 4.5755, Error 0.2828(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16340 | Time 26.0997(26.9792) | Bit/dim 3.4708(3.5116) | Xent 0.0155(0.0189) | Loss 3.4786(3.5210) | Error 0.0033(0.0046) Steps 1120(1112.84) | Grad Norm 1.0735(1.1036) | Total Time 14.00(14.00)\n",
      "Iter 16350 | Time 27.1362(26.9838) | Bit/dim 3.5346(3.5100) | Xent 0.0128(0.0187) | Loss 3.5410(3.5193) | Error 0.0033(0.0045) Steps 1102(1111.47) | Grad Norm 0.7589(1.0459) | Total Time 14.00(14.00)\n",
      "Iter 16360 | Time 26.3859(27.0023) | Bit/dim 3.5128(3.5105) | Xent 0.0176(0.0188) | Loss 3.5215(3.5199) | Error 0.0044(0.0043) Steps 1102(1110.24) | Grad Norm 1.6528(1.0543) | Total Time 14.00(14.00)\n",
      "Iter 16370 | Time 27.1701(27.0236) | Bit/dim 3.5171(3.5119) | Xent 0.0143(0.0190) | Loss 3.5242(3.5214) | Error 0.0033(0.0043) Steps 1102(1109.28) | Grad Norm 1.3911(1.1289) | Total Time 14.00(14.00)\n",
      "Iter 16380 | Time 27.2356(27.0757) | Bit/dim 3.4947(3.5127) | Xent 0.0177(0.0189) | Loss 3.5035(3.5222) | Error 0.0044(0.0042) Steps 1102(1108.99) | Grad Norm 0.8793(1.1320) | Total Time 14.00(14.00)\n",
      "Iter 16390 | Time 27.9576(27.2481) | Bit/dim 3.5285(3.5132) | Xent 0.0213(0.0192) | Loss 3.5392(3.5228) | Error 0.0056(0.0043) Steps 1120(1110.13) | Grad Norm 1.4514(1.1310) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0298 | Time 128.5309, Epoch Time 1640.9748(1625.2396), Bit/dim 3.5166(best: 3.5176), Xent 2.1086, Loss 4.5709, Error 0.2828(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16400 | Time 27.1038(27.1485) | Bit/dim 3.5041(3.5124) | Xent 0.0168(0.0188) | Loss 3.5125(3.5218) | Error 0.0022(0.0042) Steps 1108(1110.52) | Grad Norm 0.8177(1.1084) | Total Time 14.00(14.00)\n",
      "Iter 16410 | Time 26.6145(27.1861) | Bit/dim 3.4925(3.5116) | Xent 0.0232(0.0188) | Loss 3.5041(3.5210) | Error 0.0078(0.0045) Steps 1102(1110.33) | Grad Norm 0.9901(1.1175) | Total Time 14.00(14.00)\n",
      "Iter 16420 | Time 26.7740(27.1733) | Bit/dim 3.4917(3.5133) | Xent 0.0147(0.0188) | Loss 3.4990(3.5227) | Error 0.0022(0.0046) Steps 1102(1110.15) | Grad Norm 0.6751(1.1019) | Total Time 14.00(14.00)\n",
      "Iter 16430 | Time 27.5483(27.1593) | Bit/dim 3.5432(3.5128) | Xent 0.0126(0.0184) | Loss 3.5495(3.5220) | Error 0.0011(0.0044) Steps 1114(1109.69) | Grad Norm 0.8268(1.1060) | Total Time 14.00(14.00)\n",
      "Iter 16440 | Time 26.3923(27.1289) | Bit/dim 3.4961(3.5113) | Xent 0.0234(0.0193) | Loss 3.5078(3.5209) | Error 0.0067(0.0047) Steps 1096(1108.68) | Grad Norm 1.1421(1.1340) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0299 | Time 125.9175, Epoch Time 1632.5798(1625.4598), Bit/dim 3.5176(best: 3.5166), Xent 2.0922, Loss 4.5637, Error 0.2741(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16450 | Time 27.4588(27.0806) | Bit/dim 3.5061(3.5128) | Xent 0.0191(0.0188) | Loss 3.5156(3.5222) | Error 0.0044(0.0044) Steps 1126(1108.57) | Grad Norm 0.8650(1.1061) | Total Time 14.00(14.00)\n",
      "Iter 16460 | Time 27.1085(27.0913) | Bit/dim 3.5329(3.5135) | Xent 0.0226(0.0191) | Loss 3.5443(3.5231) | Error 0.0078(0.0046) Steps 1126(1109.51) | Grad Norm 1.1589(1.0973) | Total Time 14.00(14.00)\n",
      "Iter 16470 | Time 27.1167(27.1454) | Bit/dim 3.5142(3.5132) | Xent 0.0208(0.0193) | Loss 3.5246(3.5229) | Error 0.0022(0.0047) Steps 1114(1109.52) | Grad Norm 0.9971(1.1490) | Total Time 14.00(14.00)\n",
      "Iter 16480 | Time 26.4382(27.1401) | Bit/dim 3.4968(3.5111) | Xent 0.0186(0.0195) | Loss 3.5062(3.5209) | Error 0.0056(0.0047) Steps 1114(1109.90) | Grad Norm 1.0683(1.2022) | Total Time 14.00(14.00)\n",
      "Iter 16490 | Time 27.3196(27.1175) | Bit/dim 3.5691(3.5127) | Xent 0.0145(0.0192) | Loss 3.5763(3.5224) | Error 0.0044(0.0045) Steps 1132(1109.98) | Grad Norm 1.8583(1.2151) | Total Time 14.00(14.00)\n",
      "Iter 16500 | Time 27.2973(27.0483) | Bit/dim 3.4958(3.5104) | Xent 0.0221(0.0199) | Loss 3.5069(3.5204) | Error 0.0078(0.0050) Steps 1102(1109.13) | Grad Norm 1.0294(1.2049) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0300 | Time 125.3005, Epoch Time 1633.7233(1625.7077), Bit/dim 3.5175(best: 3.5166), Xent 2.1058, Loss 4.5704, Error 0.2824(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16510 | Time 26.9998(26.9868) | Bit/dim 3.5036(3.5129) | Xent 0.0158(0.0192) | Loss 3.5114(3.5226) | Error 0.0022(0.0048) Steps 1102(1109.64) | Grad Norm 0.9373(1.1746) | Total Time 14.00(14.00)\n",
      "Iter 16520 | Time 26.8381(26.9906) | Bit/dim 3.5018(3.5109) | Xent 0.0155(0.0190) | Loss 3.5096(3.5204) | Error 0.0033(0.0046) Steps 1114(1109.06) | Grad Norm 0.9033(1.1377) | Total Time 14.00(14.00)\n",
      "Iter 16530 | Time 27.7553(27.0045) | Bit/dim 3.5374(3.5106) | Xent 0.0201(0.0191) | Loss 3.5474(3.5201) | Error 0.0044(0.0047) Steps 1114(1108.74) | Grad Norm 1.1340(1.1655) | Total Time 14.00(14.00)\n",
      "Iter 16540 | Time 26.9459(27.0308) | Bit/dim 3.5170(3.5128) | Xent 0.0148(0.0195) | Loss 3.5244(3.5226) | Error 0.0033(0.0051) Steps 1120(1109.79) | Grad Norm 1.2086(1.2552) | Total Time 14.00(14.00)\n",
      "Iter 16550 | Time 26.3275(26.8996) | Bit/dim 3.5332(3.5120) | Xent 0.0172(0.0194) | Loss 3.5418(3.5217) | Error 0.0022(0.0048) Steps 1108(1109.74) | Grad Norm 1.7120(1.2764) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0301 | Time 126.2970, Epoch Time 1623.5186(1625.6420), Bit/dim 3.5170(best: 3.5166), Xent 2.1255, Loss 4.5798, Error 0.2819(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16560 | Time 27.1549(26.8689) | Bit/dim 3.5082(3.5095) | Xent 0.0174(0.0188) | Loss 3.5169(3.5189) | Error 0.0044(0.0046) Steps 1108(1109.03) | Grad Norm 0.9514(1.2058) | Total Time 14.00(14.00)\n",
      "Iter 16570 | Time 27.6904(26.9321) | Bit/dim 3.5200(3.5091) | Xent 0.0137(0.0191) | Loss 3.5268(3.5187) | Error 0.0022(0.0050) Steps 1108(1109.61) | Grad Norm 1.1821(1.2416) | Total Time 14.00(14.00)\n",
      "Iter 16580 | Time 27.0658(27.0602) | Bit/dim 3.4849(3.5119) | Xent 0.0213(0.0193) | Loss 3.4955(3.5216) | Error 0.0033(0.0051) Steps 1114(1110.56) | Grad Norm 1.8778(1.3004) | Total Time 14.00(14.00)\n",
      "Iter 16590 | Time 26.4904(27.0575) | Bit/dim 3.5245(3.5137) | Xent 0.0214(0.0193) | Loss 3.5352(3.5233) | Error 0.0067(0.0051) Steps 1096(1109.96) | Grad Norm 1.2460(1.2958) | Total Time 14.00(14.00)\n",
      "Iter 16600 | Time 27.0687(27.0893) | Bit/dim 3.4854(3.5114) | Xent 0.0172(0.0194) | Loss 3.4940(3.5211) | Error 0.0033(0.0050) Steps 1114(1110.64) | Grad Norm 1.0055(1.2416) | Total Time 14.00(14.00)\n",
      "Iter 16610 | Time 26.9182(27.0626) | Bit/dim 3.4881(3.5112) | Xent 0.0210(0.0193) | Loss 3.4986(3.5208) | Error 0.0078(0.0050) Steps 1102(1110.52) | Grad Norm 1.0007(1.2014) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0302 | Time 126.3502, Epoch Time 1635.5067(1625.9379), Bit/dim 3.5165(best: 3.5166), Xent 2.1163, Loss 4.5747, Error 0.2860(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16620 | Time 26.9488(27.0658) | Bit/dim 3.5237(3.5131) | Xent 0.0197(0.0196) | Loss 3.5336(3.5228) | Error 0.0044(0.0050) Steps 1102(1111.23) | Grad Norm 1.1103(1.2462) | Total Time 14.00(14.00)\n",
      "Iter 16630 | Time 26.8834(27.0256) | Bit/dim 3.4928(3.5096) | Xent 0.0154(0.0188) | Loss 3.5005(3.5190) | Error 0.0022(0.0045) Steps 1108(1109.77) | Grad Norm 0.8252(1.2023) | Total Time 14.00(14.00)\n",
      "Iter 16640 | Time 26.8732(26.9889) | Bit/dim 3.4991(3.5091) | Xent 0.0288(0.0188) | Loss 3.5135(3.5184) | Error 0.0089(0.0045) Steps 1108(1109.60) | Grad Norm 1.1804(1.1907) | Total Time 14.00(14.00)\n",
      "Iter 16650 | Time 26.4483(26.8828) | Bit/dim 3.5044(3.5091) | Xent 0.0135(0.0185) | Loss 3.5112(3.5183) | Error 0.0022(0.0044) Steps 1102(1108.24) | Grad Norm 1.3896(1.1636) | Total Time 14.00(14.00)\n",
      "Iter 16660 | Time 27.1511(26.8646) | Bit/dim 3.5148(3.5132) | Xent 0.0201(0.0183) | Loss 3.5248(3.5224) | Error 0.0078(0.0045) Steps 1108(1108.38) | Grad Norm 1.4145(1.1604) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0303 | Time 125.0852, Epoch Time 1620.1173(1625.7633), Bit/dim 3.5158(best: 3.5165), Xent 2.1601, Loss 4.5959, Error 0.2799(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16670 | Time 27.3714(26.8978) | Bit/dim 3.5321(3.5131) | Xent 0.0190(0.0188) | Loss 3.5416(3.5225) | Error 0.0044(0.0047) Steps 1108(1107.84) | Grad Norm 1.0451(1.1859) | Total Time 14.00(14.00)\n",
      "Iter 16680 | Time 26.9785(26.9445) | Bit/dim 3.5291(3.5134) | Xent 0.0193(0.0188) | Loss 3.5388(3.5227) | Error 0.0044(0.0048) Steps 1120(1108.01) | Grad Norm 1.1589(1.1953) | Total Time 14.00(14.00)\n",
      "Iter 16690 | Time 26.9715(26.9615) | Bit/dim 3.5247(3.5123) | Xent 0.0195(0.0186) | Loss 3.5345(3.5216) | Error 0.0033(0.0048) Steps 1114(1108.73) | Grad Norm 1.2320(1.1612) | Total Time 14.00(14.00)\n",
      "Iter 16700 | Time 26.8010(26.9245) | Bit/dim 3.5190(3.5090) | Xent 0.0219(0.0192) | Loss 3.5299(3.5186) | Error 0.0100(0.0050) Steps 1108(1107.54) | Grad Norm 1.3721(1.1532) | Total Time 14.00(14.00)\n",
      "Iter 16710 | Time 27.4077(26.9516) | Bit/dim 3.5128(3.5094) | Xent 0.0245(0.0188) | Loss 3.5250(3.5188) | Error 0.0067(0.0048) Steps 1114(1107.84) | Grad Norm 1.4893(1.1125) | Total Time 14.00(14.00)\n",
      "Iter 16720 | Time 27.4665(27.0161) | Bit/dim 3.5039(3.5099) | Xent 0.0190(0.0189) | Loss 3.5134(3.5193) | Error 0.0044(0.0048) Steps 1114(1108.60) | Grad Norm 1.0594(1.1084) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0304 | Time 126.2044, Epoch Time 1631.0091(1625.9207), Bit/dim 3.5155(best: 3.5158), Xent 2.1570, Loss 4.5940, Error 0.2816(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16730 | Time 27.5319(27.0544) | Bit/dim 3.5172(3.5094) | Xent 0.0177(0.0181) | Loss 3.5260(3.5184) | Error 0.0056(0.0045) Steps 1108(1108.96) | Grad Norm 1.2370(1.0813) | Total Time 14.00(14.00)\n",
      "Iter 16740 | Time 27.6263(27.0727) | Bit/dim 3.5030(3.5098) | Xent 0.0222(0.0178) | Loss 3.5140(3.5187) | Error 0.0044(0.0044) Steps 1108(1109.20) | Grad Norm 1.0321(1.1184) | Total Time 14.00(14.00)\n",
      "Iter 16750 | Time 26.5669(27.0432) | Bit/dim 3.5483(3.5102) | Xent 0.0178(0.0178) | Loss 3.5572(3.5191) | Error 0.0022(0.0044) Steps 1108(1109.27) | Grad Norm 1.3087(1.1351) | Total Time 14.00(14.00)\n",
      "Iter 16760 | Time 27.1368(26.9856) | Bit/dim 3.4936(3.5084) | Xent 0.0268(0.0189) | Loss 3.5071(3.5179) | Error 0.0089(0.0050) Steps 1108(1109.07) | Grad Norm 1.2609(1.1830) | Total Time 14.00(14.00)\n",
      "Iter 16770 | Time 28.0886(27.0248) | Bit/dim 3.5282(3.5103) | Xent 0.0188(0.0187) | Loss 3.5376(3.5196) | Error 0.0067(0.0047) Steps 1114(1109.55) | Grad Norm 1.0473(1.1718) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0305 | Time 127.3394, Epoch Time 1632.5905(1626.1208), Bit/dim 3.5136(best: 3.5155), Xent 2.1474, Loss 4.5873, Error 0.2857(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16780 | Time 27.0951(27.0788) | Bit/dim 3.4840(3.5092) | Xent 0.0147(0.0181) | Loss 3.4914(3.5183) | Error 0.0033(0.0044) Steps 1108(1109.43) | Grad Norm 0.8140(1.1014) | Total Time 14.00(14.00)\n",
      "Iter 16790 | Time 27.2335(27.0025) | Bit/dim 3.4975(3.5057) | Xent 0.0107(0.0178) | Loss 3.5029(3.5146) | Error 0.0011(0.0042) Steps 1120(1107.70) | Grad Norm 0.6435(1.0970) | Total Time 14.00(14.00)\n",
      "Iter 16800 | Time 26.8699(27.0264) | Bit/dim 3.4921(3.5081) | Xent 0.0147(0.0178) | Loss 3.4994(3.5170) | Error 0.0022(0.0041) Steps 1120(1109.77) | Grad Norm 0.8728(1.0763) | Total Time 14.00(14.00)\n",
      "Iter 16810 | Time 26.9150(27.1499) | Bit/dim 3.4868(3.5091) | Xent 0.0200(0.0178) | Loss 3.4968(3.5180) | Error 0.0022(0.0043) Steps 1108(1110.30) | Grad Norm 1.5756(1.1241) | Total Time 14.00(14.00)\n",
      "Iter 16820 | Time 27.0421(27.2312) | Bit/dim 3.5061(3.5106) | Xent 0.0270(0.0185) | Loss 3.5196(3.5199) | Error 0.0078(0.0044) Steps 1108(1111.87) | Grad Norm 1.3129(1.1906) | Total Time 14.00(14.00)\n",
      "Iter 16830 | Time 27.4894(27.2087) | Bit/dim 3.5129(3.5112) | Xent 0.0173(0.0194) | Loss 3.5215(3.5209) | Error 0.0044(0.0047) Steps 1120(1112.64) | Grad Norm 1.8614(1.2642) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0306 | Time 127.9116, Epoch Time 1642.4404(1626.6104), Bit/dim 3.5164(best: 3.5136), Xent 2.1683, Loss 4.6005, Error 0.2803(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16840 | Time 27.2553(27.1133) | Bit/dim 3.5073(3.5127) | Xent 0.0201(0.0188) | Loss 3.5174(3.5221) | Error 0.0022(0.0044) Steps 1108(1112.39) | Grad Norm 1.6456(1.2529) | Total Time 14.00(14.00)\n",
      "Iter 16850 | Time 26.4348(27.0728) | Bit/dim 3.5172(3.5109) | Xent 0.0173(0.0196) | Loss 3.5258(3.5206) | Error 0.0044(0.0048) Steps 1114(1112.11) | Grad Norm 1.0677(1.2856) | Total Time 14.00(14.00)\n",
      "Iter 16860 | Time 26.9185(26.9992) | Bit/dim 3.5280(3.5125) | Xent 0.0249(0.0196) | Loss 3.5405(3.5223) | Error 0.0067(0.0048) Steps 1108(1113.30) | Grad Norm 1.6465(1.2808) | Total Time 14.00(14.00)\n",
      "Iter 16870 | Time 26.6434(26.9586) | Bit/dim 3.5162(3.5115) | Xent 0.0154(0.0191) | Loss 3.5239(3.5211) | Error 0.0056(0.0048) Steps 1108(1112.68) | Grad Norm 1.1843(1.2520) | Total Time 14.00(14.00)\n",
      "Iter 16880 | Time 27.3530(26.9384) | Bit/dim 3.4944(3.5097) | Xent 0.0196(0.0187) | Loss 3.5041(3.5190) | Error 0.0044(0.0045) Steps 1120(1111.40) | Grad Norm 0.9817(1.2076) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0307 | Time 126.8690, Epoch Time 1620.4897(1626.4268), Bit/dim 3.5154(best: 3.5136), Xent 2.1958, Loss 4.6133, Error 0.2812(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16890 | Time 26.5396(26.8803) | Bit/dim 3.5189(3.5089) | Xent 0.0219(0.0184) | Loss 3.5299(3.5181) | Error 0.0056(0.0045) Steps 1102(1110.30) | Grad Norm 0.9248(1.1425) | Total Time 14.00(14.00)\n",
      "Iter 16900 | Time 26.8032(26.9151) | Bit/dim 3.5226(3.5106) | Xent 0.0180(0.0184) | Loss 3.5316(3.5198) | Error 0.0022(0.0047) Steps 1108(1109.71) | Grad Norm 1.1920(1.1359) | Total Time 14.00(14.00)\n",
      "Iter 16910 | Time 26.0876(26.9280) | Bit/dim 3.5269(3.5134) | Xent 0.0192(0.0185) | Loss 3.5365(3.5226) | Error 0.0044(0.0048) Steps 1108(1109.03) | Grad Norm 1.1804(1.1694) | Total Time 14.00(14.00)\n",
      "Iter 16920 | Time 26.9519(26.9185) | Bit/dim 3.4904(3.5093) | Xent 0.0243(0.0189) | Loss 3.5026(3.5188) | Error 0.0067(0.0050) Steps 1096(1109.71) | Grad Norm 1.2396(1.1789) | Total Time 14.00(14.00)\n",
      "Iter 16930 | Time 27.0151(26.8545) | Bit/dim 3.5483(3.5088) | Xent 0.0188(0.0185) | Loss 3.5577(3.5181) | Error 0.0044(0.0047) Steps 1114(1109.64) | Grad Norm 1.2178(1.1676) | Total Time 14.00(14.00)\n",
      "Iter 16940 | Time 27.4412(26.9251) | Bit/dim 3.5497(3.5099) | Xent 0.0147(0.0184) | Loss 3.5570(3.5191) | Error 0.0011(0.0047) Steps 1120(1109.44) | Grad Norm 1.0439(1.1743) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0308 | Time 127.1863, Epoch Time 1626.4327(1626.4269), Bit/dim 3.5156(best: 3.5136), Xent 2.1780, Loss 4.6046, Error 0.2822(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16950 | Time 26.9371(26.9873) | Bit/dim 3.5126(3.5097) | Xent 0.0242(0.0188) | Loss 3.5247(3.5191) | Error 0.0078(0.0047) Steps 1108(1110.63) | Grad Norm 1.4447(1.1644) | Total Time 14.00(14.00)\n",
      "Iter 16960 | Time 27.7723(27.0210) | Bit/dim 3.5238(3.5092) | Xent 0.0178(0.0191) | Loss 3.5327(3.5188) | Error 0.0067(0.0049) Steps 1096(1111.35) | Grad Norm 1.0961(1.2076) | Total Time 14.00(14.00)\n",
      "Iter 16970 | Time 26.5087(26.9870) | Bit/dim 3.5002(3.5118) | Xent 0.0175(0.0187) | Loss 3.5090(3.5212) | Error 0.0022(0.0046) Steps 1114(1112.61) | Grad Norm 1.4725(1.2178) | Total Time 14.00(14.00)\n",
      "Iter 16980 | Time 26.4850(26.9343) | Bit/dim 3.5281(3.5139) | Xent 0.0166(0.0186) | Loss 3.5364(3.5232) | Error 0.0033(0.0046) Steps 1108(1111.58) | Grad Norm 1.6001(1.2236) | Total Time 14.00(14.00)\n",
      "Iter 16990 | Time 27.0752(27.0031) | Bit/dim 3.5021(3.5097) | Xent 0.0208(0.0187) | Loss 3.5125(3.5191) | Error 0.0056(0.0045) Steps 1120(1111.77) | Grad Norm 1.1165(1.2283) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0309 | Time 127.0699, Epoch Time 1631.3404(1626.5743), Bit/dim 3.5149(best: 3.5136), Xent 2.1904, Loss 4.6101, Error 0.2801(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17000 | Time 26.8675(27.0453) | Bit/dim 3.5049(3.5115) | Xent 0.0217(0.0185) | Loss 3.5158(3.5208) | Error 0.0044(0.0043) Steps 1120(1111.76) | Grad Norm 1.8499(1.2670) | Total Time 14.00(14.00)\n",
      "Iter 17010 | Time 27.1568(27.0320) | Bit/dim 3.4789(3.5070) | Xent 0.0260(0.0189) | Loss 3.4919(3.5164) | Error 0.0100(0.0048) Steps 1120(1112.08) | Grad Norm 1.8585(1.3272) | Total Time 14.00(14.00)\n",
      "Iter 17020 | Time 26.2074(26.9504) | Bit/dim 3.5161(3.5072) | Xent 0.0144(0.0188) | Loss 3.5232(3.5166) | Error 0.0033(0.0049) Steps 1108(1112.27) | Grad Norm 1.0246(1.2920) | Total Time 14.00(14.00)\n",
      "Iter 17030 | Time 27.6677(26.9384) | Bit/dim 3.5325(3.5097) | Xent 0.0151(0.0186) | Loss 3.5400(3.5190) | Error 0.0033(0.0048) Steps 1138(1112.72) | Grad Norm 0.7347(1.2135) | Total Time 14.00(14.00)\n",
      "Iter 17040 | Time 26.6198(26.9637) | Bit/dim 3.5075(3.5093) | Xent 0.0266(0.0190) | Loss 3.5208(3.5188) | Error 0.0044(0.0049) Steps 1114(1113.39) | Grad Norm 1.3140(1.2213) | Total Time 14.00(14.00)\n",
      "Iter 17050 | Time 27.5155(27.0104) | Bit/dim 3.5219(3.5100) | Xent 0.0225(0.0189) | Loss 3.5332(3.5194) | Error 0.0067(0.0048) Steps 1126(1113.12) | Grad Norm 1.0842(1.2169) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0310 | Time 127.2126, Epoch Time 1629.7473(1626.6695), Bit/dim 3.5139(best: 3.5136), Xent 2.1892, Loss 4.6085, Error 0.2830(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17060 | Time 27.0590(27.0456) | Bit/dim 3.5233(3.5112) | Xent 0.0108(0.0178) | Loss 3.5287(3.5201) | Error 0.0022(0.0045) Steps 1120(1113.93) | Grad Norm 0.8035(1.1584) | Total Time 14.00(14.00)\n",
      "Iter 17070 | Time 27.0640(27.0464) | Bit/dim 3.5027(3.5094) | Xent 0.0236(0.0183) | Loss 3.5145(3.5185) | Error 0.0100(0.0048) Steps 1114(1112.87) | Grad Norm 1.4805(1.1516) | Total Time 14.00(14.00)\n",
      "Iter 17080 | Time 26.7086(27.1111) | Bit/dim 3.5070(3.5110) | Xent 0.0171(0.0180) | Loss 3.5156(3.5200) | Error 0.0022(0.0045) Steps 1102(1111.95) | Grad Norm 1.6720(1.1755) | Total Time 14.00(14.00)\n",
      "Iter 17090 | Time 27.2047(27.1055) | Bit/dim 3.4940(3.5090) | Xent 0.0183(0.0189) | Loss 3.5031(3.5184) | Error 0.0056(0.0051) Steps 1114(1113.13) | Grad Norm 1.6679(1.2778) | Total Time 14.00(14.00)\n",
      "Iter 17100 | Time 27.1134(27.0719) | Bit/dim 3.4958(3.5080) | Xent 0.0165(0.0188) | Loss 3.5041(3.5174) | Error 0.0033(0.0049) Steps 1114(1113.35) | Grad Norm 1.6722(1.3496) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0311 | Time 126.9601, Epoch Time 1635.1881(1626.9251), Bit/dim 3.5153(best: 3.5136), Xent 2.2112, Loss 4.6209, Error 0.2820(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17110 | Time 27.2330(27.0274) | Bit/dim 3.5095(3.5091) | Xent 0.0222(0.0192) | Loss 3.5206(3.5187) | Error 0.0044(0.0051) Steps 1114(1112.73) | Grad Norm 1.2887(1.3629) | Total Time 14.00(14.00)\n",
      "Iter 17120 | Time 27.2795(27.0762) | Bit/dim 3.4916(3.5086) | Xent 0.0252(0.0202) | Loss 3.5042(3.5187) | Error 0.0078(0.0055) Steps 1120(1112.96) | Grad Norm 1.1360(1.3906) | Total Time 14.00(14.00)\n",
      "Iter 17130 | Time 26.6886(27.0478) | Bit/dim 3.4784(3.5082) | Xent 0.0164(0.0195) | Loss 3.4866(3.5179) | Error 0.0044(0.0050) Steps 1120(1113.20) | Grad Norm 1.1232(1.3124) | Total Time 14.00(14.00)\n",
      "Iter 17140 | Time 26.7703(27.0575) | Bit/dim 3.5502(3.5114) | Xent 0.0146(0.0189) | Loss 3.5575(3.5209) | Error 0.0044(0.0049) Steps 1102(1113.46) | Grad Norm 1.2846(1.2700) | Total Time 14.00(14.00)\n",
      "Iter 17150 | Time 26.9970(27.0401) | Bit/dim 3.5088(3.5104) | Xent 0.0259(0.0188) | Loss 3.5218(3.5198) | Error 0.0089(0.0049) Steps 1132(1112.72) | Grad Norm 1.4130(1.2859) | Total Time 14.00(14.00)\n",
      "Iter 17160 | Time 27.0749(27.0860) | Bit/dim 3.5105(3.5097) | Xent 0.0170(0.0189) | Loss 3.5189(3.5191) | Error 0.0033(0.0050) Steps 1108(1112.85) | Grad Norm 1.3288(1.3310) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0312 | Time 127.4990, Epoch Time 1635.3430(1627.1776), Bit/dim 3.5143(best: 3.5136), Xent 2.1999, Loss 4.6143, Error 0.2846(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17170 | Time 27.0090(27.0575) | Bit/dim 3.4878(3.5088) | Xent 0.0198(0.0191) | Loss 3.4977(3.5183) | Error 0.0044(0.0052) Steps 1114(1111.89) | Grad Norm 1.1736(1.3253) | Total Time 14.00(14.00)\n",
      "Iter 17180 | Time 26.9634(27.0434) | Bit/dim 3.5146(3.5100) | Xent 0.0200(0.0190) | Loss 3.5246(3.5195) | Error 0.0044(0.0051) Steps 1120(1112.47) | Grad Norm 1.4648(1.2800) | Total Time 14.00(14.00)\n",
      "Iter 17190 | Time 26.8013(26.9853) | Bit/dim 3.4916(3.5100) | Xent 0.0286(0.0194) | Loss 3.5059(3.5198) | Error 0.0078(0.0052) Steps 1102(1112.07) | Grad Norm 1.3400(1.2819) | Total Time 14.00(14.00)\n",
      "Iter 17200 | Time 26.9083(27.0073) | Bit/dim 3.5131(3.5111) | Xent 0.0160(0.0194) | Loss 3.5212(3.5209) | Error 0.0056(0.0052) Steps 1114(1113.69) | Grad Norm 1.2163(1.2975) | Total Time 14.00(14.00)\n",
      "Iter 17210 | Time 27.2296(27.0720) | Bit/dim 3.4782(3.5101) | Xent 0.0229(0.0191) | Loss 3.4896(3.5196) | Error 0.0089(0.0053) Steps 1114(1113.66) | Grad Norm 1.7448(1.3641) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0313 | Time 127.3914, Epoch Time 1632.7869(1627.3459), Bit/dim 3.5150(best: 3.5136), Xent 2.2180, Loss 4.6240, Error 0.2861(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17220 | Time 26.5603(27.0831) | Bit/dim 3.5140(3.5100) | Xent 0.0189(0.0192) | Loss 3.5235(3.5196) | Error 0.0044(0.0055) Steps 1114(1113.17) | Grad Norm 1.1025(1.3163) | Total Time 14.00(14.00)\n",
      "Iter 17230 | Time 26.7526(27.0348) | Bit/dim 3.4884(3.5096) | Xent 0.0113(0.0187) | Loss 3.4941(3.5189) | Error 0.0011(0.0053) Steps 1114(1113.71) | Grad Norm 1.0052(1.2953) | Total Time 14.00(14.00)\n",
      "Iter 17240 | Time 26.7703(27.0625) | Bit/dim 3.5045(3.5092) | Xent 0.0246(0.0192) | Loss 3.5168(3.5189) | Error 0.0078(0.0055) Steps 1114(1114.15) | Grad Norm 1.6186(1.3246) | Total Time 14.00(14.00)\n",
      "Iter 17250 | Time 27.0740(27.0231) | Bit/dim 3.4908(3.5090) | Xent 0.0235(0.0195) | Loss 3.5026(3.5187) | Error 0.0067(0.0054) Steps 1126(1114.44) | Grad Norm 1.4246(1.3499) | Total Time 14.00(14.00)\n",
      "Iter 17260 | Time 27.3948(27.0517) | Bit/dim 3.5415(3.5109) | Xent 0.0137(0.0188) | Loss 3.5483(3.5203) | Error 0.0022(0.0049) Steps 1126(1114.57) | Grad Norm 1.0687(1.3247) | Total Time 14.00(14.00)\n",
      "Iter 17270 | Time 26.6918(27.0107) | Bit/dim 3.5062(3.5073) | Xent 0.0337(0.0195) | Loss 3.5231(3.5170) | Error 0.0111(0.0050) Steps 1114(1114.20) | Grad Norm 1.6346(1.3982) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0314 | Time 127.6062, Epoch Time 1630.5344(1627.4416), Bit/dim 3.5143(best: 3.5136), Xent 2.1951, Loss 4.6118, Error 0.2839(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17280 | Time 26.9397(26.9998) | Bit/dim 3.5340(3.5068) | Xent 0.0169(0.0196) | Loss 3.5425(3.5166) | Error 0.0067(0.0053) Steps 1120(1114.31) | Grad Norm 1.4961(1.4268) | Total Time 14.00(14.00)\n",
      "Iter 17290 | Time 27.8818(27.0613) | Bit/dim 3.5440(3.5078) | Xent 0.0290(0.0193) | Loss 3.5585(3.5175) | Error 0.0078(0.0052) Steps 1114(1115.43) | Grad Norm 2.0583(1.3878) | Total Time 14.00(14.00)\n",
      "Iter 17300 | Time 26.0793(27.0244) | Bit/dim 3.5017(3.5104) | Xent 0.0163(0.0191) | Loss 3.5098(3.5199) | Error 0.0033(0.0052) Steps 1108(1116.10) | Grad Norm 1.1353(1.3823) | Total Time 14.00(14.00)\n",
      "Iter 17310 | Time 26.8527(27.0625) | Bit/dim 3.4884(3.5086) | Xent 0.0186(0.0195) | Loss 3.4977(3.5183) | Error 0.0067(0.0056) Steps 1108(1115.08) | Grad Norm 1.2735(1.4104) | Total Time 14.00(14.00)\n",
      "Iter 17320 | Time 27.1910(27.0693) | Bit/dim 3.5094(3.5083) | Xent 0.0266(0.0198) | Loss 3.5227(3.5182) | Error 0.0089(0.0057) Steps 1096(1113.38) | Grad Norm 1.2117(1.3908) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0315 | Time 128.6293, Epoch Time 1635.1142(1627.6717), Bit/dim 3.5142(best: 3.5136), Xent 2.1717, Loss 4.6001, Error 0.2816(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17330 | Time 27.3568(27.0204) | Bit/dim 3.4914(3.5075) | Xent 0.0198(0.0200) | Loss 3.5013(3.5175) | Error 0.0056(0.0057) Steps 1108(1113.51) | Grad Norm 1.3658(1.3833) | Total Time 14.00(14.00)\n",
      "Iter 17340 | Time 26.5486(27.0341) | Bit/dim 3.4948(3.5090) | Xent 0.0195(0.0192) | Loss 3.5046(3.5186) | Error 0.0056(0.0053) Steps 1120(1114.06) | Grad Norm 1.2062(1.3035) | Total Time 14.00(14.00)\n",
      "Iter 17350 | Time 27.2616(27.0228) | Bit/dim 3.5129(3.5099) | Xent 0.0160(0.0188) | Loss 3.5209(3.5193) | Error 0.0011(0.0051) Steps 1108(1113.23) | Grad Norm 0.8745(1.2639) | Total Time 14.00(14.00)\n",
      "Iter 17360 | Time 27.6011(27.1002) | Bit/dim 3.5028(3.5107) | Xent 0.0115(0.0187) | Loss 3.5086(3.5200) | Error 0.0022(0.0051) Steps 1114(1113.60) | Grad Norm 0.7070(1.2059) | Total Time 14.00(14.00)\n",
      "Iter 17370 | Time 27.2025(27.1245) | Bit/dim 3.5361(3.5102) | Xent 0.0157(0.0188) | Loss 3.5440(3.5197) | Error 0.0033(0.0052) Steps 1120(1114.08) | Grad Norm 0.8193(1.2184) | Total Time 14.00(14.00)\n",
      "Iter 17380 | Time 27.5645(27.1836) | Bit/dim 3.5188(3.5076) | Xent 0.0249(0.0190) | Loss 3.5313(3.5171) | Error 0.0056(0.0051) Steps 1126(1114.63) | Grad Norm 1.6602(1.2574) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0316 | Time 129.1731, Epoch Time 1640.1744(1628.0468), Bit/dim 3.5155(best: 3.5136), Xent 2.1932, Loss 4.6121, Error 0.2801(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17390 | Time 27.0708(27.1203) | Bit/dim 3.5345(3.5094) | Xent 0.0169(0.0188) | Loss 3.5430(3.5188) | Error 0.0022(0.0047) Steps 1102(1112.65) | Grad Norm 1.1389(1.2425) | Total Time 14.00(14.00)\n",
      "Iter 17400 | Time 26.7835(27.1109) | Bit/dim 3.5069(3.5119) | Xent 0.0196(0.0190) | Loss 3.5167(3.5214) | Error 0.0078(0.0048) Steps 1120(1112.49) | Grad Norm 1.3096(1.2340) | Total Time 14.00(14.00)\n",
      "Iter 17410 | Time 26.3524(27.0867) | Bit/dim 3.5052(3.5104) | Xent 0.0162(0.0189) | Loss 3.5133(3.5198) | Error 0.0033(0.0050) Steps 1108(1113.36) | Grad Norm 1.2537(1.2107) | Total Time 14.00(14.00)\n",
      "Iter 17420 | Time 26.8924(27.1228) | Bit/dim 3.4945(3.5090) | Xent 0.0247(0.0188) | Loss 3.5069(3.5184) | Error 0.0089(0.0050) Steps 1114(1113.89) | Grad Norm 1.0452(1.1793) | Total Time 14.00(14.00)\n",
      "Iter 17430 | Time 26.8550(27.0644) | Bit/dim 3.5113(3.5075) | Xent 0.0160(0.0192) | Loss 3.5193(3.5171) | Error 0.0056(0.0052) Steps 1114(1113.89) | Grad Norm 0.8545(1.2014) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0317 | Time 128.5611, Epoch Time 1632.2825(1628.1739), Bit/dim 3.5128(best: 3.5136), Xent 2.2057, Loss 4.6156, Error 0.2794(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17440 | Time 27.0927(27.0213) | Bit/dim 3.5078(3.5062) | Xent 0.0116(0.0187) | Loss 3.5136(3.5156) | Error 0.0011(0.0049) Steps 1120(1113.33) | Grad Norm 0.7959(1.1628) | Total Time 14.00(14.00)\n",
      "Iter 17450 | Time 27.2897(27.0148) | Bit/dim 3.4979(3.5081) | Xent 0.0151(0.0186) | Loss 3.5055(3.5174) | Error 0.0056(0.0050) Steps 1108(1112.67) | Grad Norm 0.8972(1.1291) | Total Time 14.00(14.00)\n",
      "Iter 17460 | Time 27.4110(27.0688) | Bit/dim 3.5046(3.5095) | Xent 0.0101(0.0180) | Loss 3.5097(3.5185) | Error 0.0022(0.0049) Steps 1120(1113.87) | Grad Norm 0.7309(1.1434) | Total Time 14.00(14.00)\n",
      "Iter 17470 | Time 26.9114(27.1164) | Bit/dim 3.5047(3.5086) | Xent 0.0204(0.0183) | Loss 3.5148(3.5178) | Error 0.0056(0.0050) Steps 1120(1113.28) | Grad Norm 1.2950(1.1291) | Total Time 14.00(14.00)\n",
      "Iter 17480 | Time 27.4727(27.1421) | Bit/dim 3.5237(3.5079) | Xent 0.0214(0.0185) | Loss 3.5344(3.5171) | Error 0.0078(0.0050) Steps 1120(1113.11) | Grad Norm 1.2235(1.1494) | Total Time 14.00(14.00)\n",
      "Iter 17490 | Time 27.8726(27.1667) | Bit/dim 3.4778(3.5050) | Xent 0.0160(0.0193) | Loss 3.4858(3.5147) | Error 0.0044(0.0053) Steps 1108(1111.43) | Grad Norm 1.6106(1.2254) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0318 | Time 129.7524, Epoch Time 1642.5173(1628.6042), Bit/dim 3.5151(best: 3.5128), Xent 2.2242, Loss 4.6272, Error 0.2806(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17500 | Time 27.4241(27.1538) | Bit/dim 3.4771(3.5042) | Xent 0.0124(0.0180) | Loss 3.4833(3.5133) | Error 0.0022(0.0048) Steps 1132(1112.62) | Grad Norm 0.9659(1.1672) | Total Time 14.00(14.00)\n",
      "Iter 17510 | Time 26.9678(27.1454) | Bit/dim 3.5102(3.5071) | Xent 0.0133(0.0182) | Loss 3.5168(3.5162) | Error 0.0011(0.0048) Steps 1102(1112.40) | Grad Norm 0.6966(1.1474) | Total Time 14.00(14.00)\n",
      "Iter 17520 | Time 27.2267(27.1161) | Bit/dim 3.5139(3.5073) | Xent 0.0162(0.0180) | Loss 3.5220(3.5163) | Error 0.0011(0.0048) Steps 1108(1112.46) | Grad Norm 1.1638(1.1588) | Total Time 14.00(14.00)\n",
      "Iter 17530 | Time 27.1333(27.2174) | Bit/dim 3.5157(3.5099) | Xent 0.0175(0.0181) | Loss 3.5244(3.5189) | Error 0.0044(0.0048) Steps 1096(1112.97) | Grad Norm 1.0371(1.1680) | Total Time 14.00(14.00)\n",
      "Iter 17540 | Time 26.2319(27.1641) | Bit/dim 3.5062(3.5082) | Xent 0.0148(0.0183) | Loss 3.5135(3.5174) | Error 0.0033(0.0049) Steps 1102(1112.86) | Grad Norm 0.8320(1.1633) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0319 | Time 127.1162, Epoch Time 1637.7136(1628.8775), Bit/dim 3.5123(best: 3.5128), Xent 2.2456, Loss 4.6351, Error 0.2839(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17550 | Time 26.8751(27.0906) | Bit/dim 3.5091(3.5074) | Xent 0.0214(0.0183) | Loss 3.5198(3.5165) | Error 0.0078(0.0050) Steps 1120(1112.23) | Grad Norm 1.4469(1.1955) | Total Time 14.00(14.00)\n",
      "Iter 17560 | Time 26.4090(27.0382) | Bit/dim 3.5324(3.5075) | Xent 0.0194(0.0178) | Loss 3.5421(3.5164) | Error 0.0044(0.0048) Steps 1102(1112.74) | Grad Norm 1.2278(1.1788) | Total Time 14.00(14.00)\n",
      "Iter 17570 | Time 27.3235(27.1317) | Bit/dim 3.4927(3.5082) | Xent 0.0237(0.0175) | Loss 3.5046(3.5169) | Error 0.0033(0.0046) Steps 1120(1113.55) | Grad Norm 1.1061(1.1711) | Total Time 14.00(14.00)\n",
      "Iter 17580 | Time 27.1821(27.0824) | Bit/dim 3.4755(3.5069) | Xent 0.0209(0.0183) | Loss 3.4859(3.5160) | Error 0.0056(0.0048) Steps 1108(1113.87) | Grad Norm 1.2817(1.1985) | Total Time 14.00(14.00)\n",
      "Iter 17590 | Time 26.2663(27.0317) | Bit/dim 3.5322(3.5072) | Xent 0.0256(0.0184) | Loss 3.5450(3.5164) | Error 0.0078(0.0047) Steps 1114(1113.70) | Grad Norm 1.2979(1.2052) | Total Time 14.00(14.00)\n",
      "Iter 17600 | Time 26.3816(27.0383) | Bit/dim 3.4840(3.5078) | Xent 0.0279(0.0184) | Loss 3.4979(3.5170) | Error 0.0056(0.0044) Steps 1108(1112.57) | Grad Norm 1.4894(1.2123) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0320 | Time 128.6976, Epoch Time 1632.9043(1628.9983), Bit/dim 3.5133(best: 3.5123), Xent 2.2239, Loss 4.6252, Error 0.2807(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17610 | Time 27.2641(27.0031) | Bit/dim 3.5193(3.5091) | Xent 0.0175(0.0180) | Loss 3.5280(3.5181) | Error 0.0044(0.0044) Steps 1102(1113.88) | Grad Norm 0.9482(1.2173) | Total Time 14.00(14.00)\n",
      "Iter 17620 | Time 26.2954(27.0140) | Bit/dim 3.5050(3.5071) | Xent 0.0243(0.0180) | Loss 3.5172(3.5161) | Error 0.0111(0.0047) Steps 1102(1114.23) | Grad Norm 1.1713(1.1704) | Total Time 14.00(14.00)\n",
      "Iter 17630 | Time 27.9230(26.9793) | Bit/dim 3.5240(3.5073) | Xent 0.0139(0.0178) | Loss 3.5309(3.5162) | Error 0.0011(0.0048) Steps 1120(1114.66) | Grad Norm 1.3351(1.1828) | Total Time 14.00(14.00)\n",
      "Iter 17640 | Time 27.1722(26.9475) | Bit/dim 3.5378(3.5090) | Xent 0.0154(0.0179) | Loss 3.5455(3.5180) | Error 0.0044(0.0050) Steps 1108(1115.07) | Grad Norm 1.7240(1.2968) | Total Time 14.00(14.00)\n",
      "Iter 17650 | Time 26.8988(27.0049) | Bit/dim 3.5041(3.5064) | Xent 0.0208(0.0182) | Loss 3.5145(3.5155) | Error 0.0056(0.0050) Steps 1114(1116.64) | Grad Norm 2.5573(1.4382) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0321 | Time 128.3860, Epoch Time 1629.2130(1629.0047), Bit/dim 3.5139(best: 3.5123), Xent 2.2890, Loss 4.6584, Error 0.2858(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17660 | Time 26.2182(26.9424) | Bit/dim 3.4919(3.5067) | Xent 0.0149(0.0179) | Loss 3.4994(3.5156) | Error 0.0033(0.0049) Steps 1102(1115.84) | Grad Norm 1.6897(1.4497) | Total Time 14.00(14.00)\n",
      "Iter 17670 | Time 27.0412(26.9366) | Bit/dim 3.4963(3.5057) | Xent 0.0191(0.0179) | Loss 3.5059(3.5147) | Error 0.0033(0.0047) Steps 1120(1115.48) | Grad Norm 0.9799(1.4207) | Total Time 14.00(14.00)\n",
      "Iter 17680 | Time 26.7134(26.9842) | Bit/dim 3.4938(3.5051) | Xent 0.0158(0.0174) | Loss 3.5017(3.5138) | Error 0.0044(0.0045) Steps 1126(1116.67) | Grad Norm 1.1606(1.3382) | Total Time 14.00(14.00)\n",
      "Iter 17690 | Time 26.6130(26.9440) | Bit/dim 3.5094(3.5070) | Xent 0.0193(0.0180) | Loss 3.5190(3.5160) | Error 0.0033(0.0048) Steps 1102(1115.16) | Grad Norm 1.6257(1.3175) | Total Time 14.00(14.00)\n",
      "Iter 17700 | Time 27.1177(26.9283) | Bit/dim 3.5195(3.5066) | Xent 0.0179(0.0177) | Loss 3.5284(3.5155) | Error 0.0044(0.0047) Steps 1114(1113.62) | Grad Norm 1.6305(1.2815) | Total Time 14.00(14.00)\n",
      "Iter 17710 | Time 26.6488(26.8806) | Bit/dim 3.5105(3.5075) | Xent 0.0203(0.0180) | Loss 3.5206(3.5166) | Error 0.0044(0.0048) Steps 1102(1112.99) | Grad Norm 1.1315(1.2905) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0322 | Time 127.6570, Epoch Time 1623.5588(1628.8413), Bit/dim 3.5122(best: 3.5123), Xent 2.2492, Loss 4.6368, Error 0.2828(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17720 | Time 26.8056(26.9133) | Bit/dim 3.4823(3.5055) | Xent 0.0244(0.0172) | Loss 3.4945(3.5141) | Error 0.0078(0.0044) Steps 1114(1113.77) | Grad Norm 1.8219(1.2164) | Total Time 14.00(14.00)\n",
      "Iter 17730 | Time 27.3926(26.9501) | Bit/dim 3.4773(3.5058) | Xent 0.0223(0.0180) | Loss 3.4884(3.5148) | Error 0.0089(0.0047) Steps 1114(1113.51) | Grad Norm 1.1650(1.2508) | Total Time 14.00(14.00)\n",
      "Iter 17740 | Time 26.9133(27.0184) | Bit/dim 3.5545(3.5070) | Xent 0.0170(0.0179) | Loss 3.5630(3.5160) | Error 0.0033(0.0046) Steps 1126(1114.81) | Grad Norm 1.1617(1.2435) | Total Time 14.00(14.00)\n",
      "Iter 17750 | Time 26.8604(27.0031) | Bit/dim 3.5150(3.5063) | Xent 0.0203(0.0187) | Loss 3.5251(3.5157) | Error 0.0044(0.0050) Steps 1120(1114.02) | Grad Norm 1.6671(1.3082) | Total Time 14.00(14.00)\n",
      "Iter 17760 | Time 27.5543(26.9896) | Bit/dim 3.5489(3.5080) | Xent 0.0147(0.0189) | Loss 3.5562(3.5175) | Error 0.0022(0.0050) Steps 1114(1114.68) | Grad Norm 1.1304(1.3263) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0323 | Time 128.1919, Epoch Time 1632.3688(1628.9472), Bit/dim 3.5123(best: 3.5122), Xent 2.2636, Loss 4.6441, Error 0.2805(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17770 | Time 26.6294(26.9626) | Bit/dim 3.4932(3.5091) | Xent 0.0135(0.0185) | Loss 3.4999(3.5183) | Error 0.0011(0.0045) Steps 1102(1114.00) | Grad Norm 1.1926(1.2848) | Total Time 14.00(14.00)\n",
      "Iter 17780 | Time 27.2813(27.0132) | Bit/dim 3.5252(3.5075) | Xent 0.0096(0.0181) | Loss 3.5300(3.5165) | Error 0.0011(0.0045) Steps 1138(1114.66) | Grad Norm 0.8751(1.2428) | Total Time 14.00(14.00)\n",
      "Iter 17790 | Time 26.7350(27.0384) | Bit/dim 3.5070(3.5077) | Xent 0.0205(0.0183) | Loss 3.5172(3.5169) | Error 0.0067(0.0045) Steps 1114(1113.70) | Grad Norm 1.2309(1.2688) | Total Time 14.00(14.00)\n",
      "Iter 17800 | Time 27.2439(27.0587) | Bit/dim 3.5138(3.5070) | Xent 0.0129(0.0175) | Loss 3.5202(3.5158) | Error 0.0056(0.0044) Steps 1114(1113.24) | Grad Norm 1.0373(1.2294) | Total Time 14.00(14.00)\n",
      "Iter 17810 | Time 26.9229(27.0508) | Bit/dim 3.5177(3.5053) | Xent 0.0147(0.0179) | Loss 3.5250(3.5143) | Error 0.0033(0.0047) Steps 1120(1112.65) | Grad Norm 1.0823(1.2317) | Total Time 14.00(14.00)\n",
      "Iter 17820 | Time 26.8942(27.0370) | Bit/dim 3.5311(3.5068) | Xent 0.0167(0.0173) | Loss 3.5395(3.5154) | Error 0.0033(0.0044) Steps 1108(1112.47) | Grad Norm 1.0168(1.1794) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0324 | Time 127.1858, Epoch Time 1634.0454(1629.1001), Bit/dim 3.5114(best: 3.5122), Xent 2.2357, Loss 4.6293, Error 0.2802(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17830 | Time 26.9101(27.0063) | Bit/dim 3.5390(3.5095) | Xent 0.0158(0.0169) | Loss 3.5469(3.5179) | Error 0.0011(0.0041) Steps 1108(1111.96) | Grad Norm 0.9305(1.1591) | Total Time 14.00(14.00)\n",
      "Iter 17840 | Time 26.5247(27.0144) | Bit/dim 3.5377(3.5082) | Xent 0.0085(0.0164) | Loss 3.5420(3.5164) | Error 0.0000(0.0039) Steps 1108(1112.33) | Grad Norm 0.5991(1.1373) | Total Time 14.00(14.00)\n",
      "Iter 17850 | Time 27.7211(27.0811) | Bit/dim 3.4888(3.5094) | Xent 0.0266(0.0174) | Loss 3.5021(3.5181) | Error 0.0067(0.0046) Steps 1114(1112.04) | Grad Norm 2.0804(1.1876) | Total Time 14.00(14.00)\n",
      "Iter 17860 | Time 28.1225(27.1374) | Bit/dim 3.4957(3.5064) | Xent 0.0137(0.0177) | Loss 3.5026(3.5152) | Error 0.0022(0.0046) Steps 1102(1112.02) | Grad Norm 0.7610(1.2042) | Total Time 14.00(14.00)\n",
      "Iter 17870 | Time 27.2710(27.0715) | Bit/dim 3.4772(3.5037) | Xent 0.0158(0.0173) | Loss 3.4851(3.5123) | Error 0.0044(0.0046) Steps 1126(1113.93) | Grad Norm 0.9042(1.2349) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0325 | Time 127.6391, Epoch Time 1636.2465(1629.3145), Bit/dim 3.5131(best: 3.5114), Xent 2.2583, Loss 4.6422, Error 0.2852(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17880 | Time 26.9772(27.0843) | Bit/dim 3.5178(3.5048) | Xent 0.0160(0.0178) | Loss 3.5258(3.5137) | Error 0.0044(0.0047) Steps 1108(1113.66) | Grad Norm 1.1131(1.2531) | Total Time 14.00(14.00)\n",
      "Iter 17890 | Time 26.6026(27.0017) | Bit/dim 3.4813(3.5033) | Xent 0.0190(0.0175) | Loss 3.4908(3.5120) | Error 0.0067(0.0045) Steps 1096(1112.68) | Grad Norm 1.4820(1.2601) | Total Time 14.00(14.00)\n",
      "Iter 17900 | Time 26.5149(27.0016) | Bit/dim 3.4887(3.5053) | Xent 0.0162(0.0174) | Loss 3.4968(3.5140) | Error 0.0044(0.0043) Steps 1120(1113.14) | Grad Norm 1.3879(1.2861) | Total Time 14.00(14.00)\n",
      "Iter 17910 | Time 26.6671(26.9952) | Bit/dim 3.4844(3.5050) | Xent 0.0140(0.0180) | Loss 3.4914(3.5140) | Error 0.0033(0.0046) Steps 1126(1113.99) | Grad Norm 0.9545(1.2764) | Total Time 14.00(14.00)\n",
      "Iter 17920 | Time 26.9186(27.0298) | Bit/dim 3.5030(3.5069) | Xent 0.0146(0.0176) | Loss 3.5103(3.5157) | Error 0.0022(0.0043) Steps 1114(1114.20) | Grad Norm 0.9882(1.2656) | Total Time 14.00(14.00)\n",
      "Iter 17930 | Time 26.2130(26.9695) | Bit/dim 3.4970(3.5060) | Xent 0.0154(0.0183) | Loss 3.5047(3.5152) | Error 0.0033(0.0045) Steps 1108(1114.18) | Grad Norm 1.1844(1.2866) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0326 | Time 128.4121, Epoch Time 1628.1135(1629.2785), Bit/dim 3.5114(best: 3.5114), Xent 2.3216, Loss 4.6722, Error 0.2859(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17940 | Time 26.5729(26.9043) | Bit/dim 3.5123(3.5045) | Xent 0.0202(0.0185) | Loss 3.5224(3.5138) | Error 0.0056(0.0045) Steps 1114(1113.43) | Grad Norm 1.6798(1.2856) | Total Time 14.00(14.00)\n",
      "Iter 17950 | Time 26.3275(26.8469) | Bit/dim 3.4896(3.5036) | Xent 0.0199(0.0183) | Loss 3.4995(3.5127) | Error 0.0044(0.0046) Steps 1114(1113.12) | Grad Norm 1.4196(1.2917) | Total Time 14.00(14.00)\n",
      "Iter 17960 | Time 26.9203(26.8567) | Bit/dim 3.5138(3.5081) | Xent 0.0238(0.0181) | Loss 3.5257(3.5172) | Error 0.0078(0.0045) Steps 1114(1113.08) | Grad Norm 1.1814(1.2707) | Total Time 14.00(14.00)\n",
      "Iter 17970 | Time 27.4193(26.9627) | Bit/dim 3.5042(3.5086) | Xent 0.0153(0.0174) | Loss 3.5119(3.5173) | Error 0.0033(0.0042) Steps 1102(1111.84) | Grad Norm 0.9721(1.2369) | Total Time 14.00(14.00)\n",
      "Iter 17980 | Time 26.7439(26.9397) | Bit/dim 3.5199(3.5077) | Xent 0.0233(0.0175) | Loss 3.5316(3.5164) | Error 0.0089(0.0044) Steps 1108(1111.88) | Grad Norm 1.6591(1.2618) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0327 | Time 127.8693, Epoch Time 1624.7795(1629.1435), Bit/dim 3.5110(best: 3.5114), Xent 2.2793, Loss 4.6506, Error 0.2835(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17990 | Time 27.0875(26.9577) | Bit/dim 3.5095(3.5064) | Xent 0.0075(0.0171) | Loss 3.5133(3.5149) | Error 0.0011(0.0043) Steps 1114(1112.62) | Grad Norm 0.9004(1.2563) | Total Time 14.00(14.00)\n",
      "Iter 18000 | Time 27.0664(27.0251) | Bit/dim 3.5181(3.5044) | Xent 0.0191(0.0180) | Loss 3.5276(3.5134) | Error 0.0067(0.0047) Steps 1114(1112.66) | Grad Norm 1.6908(1.3346) | Total Time 14.00(14.00)\n",
      "Iter 18010 | Time 27.0001(26.9694) | Bit/dim 3.5102(3.5056) | Xent 0.0175(0.0189) | Loss 3.5189(3.5151) | Error 0.0033(0.0049) Steps 1108(1112.22) | Grad Norm 1.5247(1.3487) | Total Time 14.00(14.00)\n",
      "Iter 18020 | Time 26.2736(26.8625) | Bit/dim 3.4745(3.5048) | Xent 0.0134(0.0188) | Loss 3.4812(3.5142) | Error 0.0044(0.0050) Steps 1120(1111.64) | Grad Norm 1.0419(1.3338) | Total Time 14.00(14.00)\n",
      "Iter 18030 | Time 26.7942(26.7911) | Bit/dim 3.5568(3.5074) | Xent 0.0157(0.0195) | Loss 3.5646(3.5171) | Error 0.0022(0.0054) Steps 1108(1110.66) | Grad Norm 1.1385(1.3546) | Total Time 14.00(14.00)\n",
      "Iter 18040 | Time 26.6135(26.8115) | Bit/dim 3.4831(3.5071) | Xent 0.0210(0.0192) | Loss 3.4936(3.5167) | Error 0.0056(0.0053) Steps 1114(1111.59) | Grad Norm 1.3673(1.3650) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0328 | Time 128.2550, Epoch Time 1622.4994(1628.9442), Bit/dim 3.5135(best: 3.5110), Xent 2.2645, Loss 4.6457, Error 0.2812(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18050 | Time 26.6937(26.7728) | Bit/dim 3.5074(3.5068) | Xent 0.0212(0.0190) | Loss 3.5180(3.5163) | Error 0.0078(0.0051) Steps 1114(1110.99) | Grad Norm 1.4128(1.4321) | Total Time 14.00(14.00)\n",
      "Iter 18060 | Time 27.1537(26.7663) | Bit/dim 3.5490(3.5075) | Xent 0.0207(0.0191) | Loss 3.5594(3.5170) | Error 0.0100(0.0052) Steps 1114(1111.12) | Grad Norm 1.6769(1.4187) | Total Time 14.00(14.00)\n",
      "Iter 18070 | Time 27.0193(26.8005) | Bit/dim 3.4976(3.5093) | Xent 0.0240(0.0187) | Loss 3.5095(3.5186) | Error 0.0067(0.0051) Steps 1114(1111.70) | Grad Norm 1.3574(1.3561) | Total Time 14.00(14.00)\n",
      "Iter 18080 | Time 27.0094(26.8157) | Bit/dim 3.5165(3.5066) | Xent 0.0244(0.0194) | Loss 3.5287(3.5163) | Error 0.0067(0.0053) Steps 1114(1110.86) | Grad Norm 2.4456(1.4158) | Total Time 14.00(14.00)\n",
      "Iter 18090 | Time 26.4959(26.8195) | Bit/dim 3.5253(3.5072) | Xent 0.0225(0.0190) | Loss 3.5366(3.5167) | Error 0.0067(0.0050) Steps 1102(1110.79) | Grad Norm 1.3969(1.3863) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0329 | Time 127.2401, Epoch Time 1618.6686(1628.6359), Bit/dim 3.5129(best: 3.5110), Xent 2.2835, Loss 4.6547, Error 0.2806(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18100 | Time 26.7512(26.8005) | Bit/dim 3.5155(3.5079) | Xent 0.0199(0.0185) | Loss 3.5254(3.5171) | Error 0.0033(0.0046) Steps 1120(1111.31) | Grad Norm 1.2279(1.3337) | Total Time 14.00(14.00)\n",
      "Iter 18110 | Time 26.8118(26.8050) | Bit/dim 3.5036(3.5063) | Xent 0.0200(0.0184) | Loss 3.5136(3.5155) | Error 0.0056(0.0049) Steps 1114(1112.00) | Grad Norm 1.8997(1.3796) | Total Time 14.00(14.00)\n",
      "Iter 18120 | Time 27.6295(26.8874) | Bit/dim 3.5105(3.5062) | Xent 0.0202(0.0186) | Loss 3.5206(3.5155) | Error 0.0056(0.0048) Steps 1108(1111.91) | Grad Norm 1.7682(1.3944) | Total Time 14.00(14.00)\n",
      "Iter 18130 | Time 26.9180(26.8713) | Bit/dim 3.4869(3.5052) | Xent 0.0215(0.0183) | Loss 3.4976(3.5144) | Error 0.0078(0.0048) Steps 1102(1112.29) | Grad Norm 2.0918(1.4294) | Total Time 14.00(14.00)\n",
      "Iter 18140 | Time 26.5876(26.8552) | Bit/dim 3.5295(3.5072) | Xent 0.0122(0.0190) | Loss 3.5356(3.5167) | Error 0.0022(0.0054) Steps 1108(1112.69) | Grad Norm 0.8286(1.4356) | Total Time 14.00(14.00)\n",
      "Iter 18150 | Time 26.9307(26.8487) | Bit/dim 3.4915(3.5063) | Xent 0.0284(0.0190) | Loss 3.5057(3.5158) | Error 0.0078(0.0053) Steps 1096(1112.75) | Grad Norm 2.0321(1.4572) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0330 | Time 127.0762, Epoch Time 1622.8072(1628.4611), Bit/dim 3.5113(best: 3.5110), Xent 2.3002, Loss 4.6613, Error 0.2830(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18160 | Time 26.8293(26.8108) | Bit/dim 3.4725(3.5042) | Xent 0.0197(0.0186) | Loss 3.4823(3.5134) | Error 0.0067(0.0052) Steps 1114(1112.93) | Grad Norm 1.6183(1.4352) | Total Time 14.00(14.00)\n",
      "Iter 18170 | Time 27.0524(26.7667) | Bit/dim 3.5373(3.5039) | Xent 0.0139(0.0187) | Loss 3.5442(3.5132) | Error 0.0033(0.0052) Steps 1108(1111.46) | Grad Norm 1.4482(1.4203) | Total Time 14.00(14.00)\n",
      "Iter 18180 | Time 26.7416(26.8368) | Bit/dim 3.4685(3.5022) | Xent 0.0192(0.0182) | Loss 3.4781(3.5113) | Error 0.0044(0.0049) Steps 1108(1110.74) | Grad Norm 1.3054(1.3761) | Total Time 14.00(14.00)\n",
      "Iter 18190 | Time 25.9669(26.7790) | Bit/dim 3.5091(3.5038) | Xent 0.0149(0.0179) | Loss 3.5166(3.5127) | Error 0.0033(0.0047) Steps 1114(1109.73) | Grad Norm 0.9097(1.3030) | Total Time 14.00(14.00)\n",
      "Iter 18200 | Time 26.7452(26.8001) | Bit/dim 3.4830(3.5071) | Xent 0.0136(0.0179) | Loss 3.4899(3.5161) | Error 0.0022(0.0047) Steps 1102(1109.31) | Grad Norm 0.9480(1.2469) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0331 | Time 127.5504, Epoch Time 1618.2166(1628.1537), Bit/dim 3.5119(best: 3.5110), Xent 2.2931, Loss 4.6585, Error 0.2803(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18210 | Time 26.6043(26.8352) | Bit/dim 3.4880(3.5068) | Xent 0.0129(0.0177) | Loss 3.4944(3.5156) | Error 0.0022(0.0046) Steps 1108(1111.28) | Grad Norm 1.0171(1.2470) | Total Time 14.00(14.00)\n",
      "Iter 18220 | Time 27.0219(26.8481) | Bit/dim 3.5199(3.5071) | Xent 0.0210(0.0179) | Loss 3.5304(3.5161) | Error 0.0067(0.0046) Steps 1108(1111.03) | Grad Norm 1.8194(1.2590) | Total Time 14.00(14.00)\n",
      "Iter 18230 | Time 26.8988(26.8193) | Bit/dim 3.5137(3.5080) | Xent 0.0197(0.0176) | Loss 3.5235(3.5168) | Error 0.0044(0.0046) Steps 1126(1111.09) | Grad Norm 1.2199(1.3020) | Total Time 14.00(14.00)\n",
      "Iter 18240 | Time 27.3491(26.8402) | Bit/dim 3.5051(3.5052) | Xent 0.0201(0.0176) | Loss 3.5152(3.5140) | Error 0.0044(0.0046) Steps 1120(1110.97) | Grad Norm 1.6105(1.3088) | Total Time 14.00(14.00)\n",
      "Iter 18250 | Time 26.6295(26.8275) | Bit/dim 3.5115(3.5048) | Xent 0.0215(0.0175) | Loss 3.5223(3.5135) | Error 0.0067(0.0046) Steps 1132(1112.15) | Grad Norm 1.4175(1.2948) | Total Time 14.00(14.00)\n",
      "Iter 18260 | Time 26.9878(26.8679) | Bit/dim 3.4974(3.5063) | Xent 0.0239(0.0185) | Loss 3.5094(3.5155) | Error 0.0056(0.0050) Steps 1114(1112.03) | Grad Norm 1.4096(1.3435) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0332 | Time 127.1664, Epoch Time 1623.1944(1628.0049), Bit/dim 3.5107(best: 3.5110), Xent 2.3170, Loss 4.6692, Error 0.2859(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18270 | Time 26.5536(26.8472) | Bit/dim 3.5091(3.5070) | Xent 0.0184(0.0182) | Loss 3.5183(3.5161) | Error 0.0044(0.0046) Steps 1108(1110.82) | Grad Norm 1.2739(1.3955) | Total Time 14.00(14.00)\n",
      "Iter 18280 | Time 27.2917(26.8582) | Bit/dim 3.5048(3.5058) | Xent 0.0176(0.0182) | Loss 3.5136(3.5149) | Error 0.0078(0.0048) Steps 1108(1111.20) | Grad Norm 1.9308(1.4799) | Total Time 14.00(14.00)\n",
      "Iter 18290 | Time 26.4026(26.8034) | Bit/dim 3.5122(3.5075) | Xent 0.0260(0.0185) | Loss 3.5252(3.5168) | Error 0.0078(0.0047) Steps 1120(1110.67) | Grad Norm 1.6152(1.4855) | Total Time 14.00(14.00)\n",
      "Iter 18300 | Time 26.7406(26.7864) | Bit/dim 3.4992(3.5076) | Xent 0.0215(0.0185) | Loss 3.5099(3.5168) | Error 0.0067(0.0048) Steps 1108(1110.59) | Grad Norm 1.5407(1.4471) | Total Time 14.00(14.00)\n",
      "Iter 18310 | Time 27.3914(26.8627) | Bit/dim 3.5256(3.5053) | Xent 0.0168(0.0182) | Loss 3.5340(3.5145) | Error 0.0033(0.0048) Steps 1108(1110.21) | Grad Norm 1.2441(1.3997) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 126.8606, Epoch Time 1620.8130(1627.7892), Bit/dim 3.5105(best: 3.5107), Xent 2.3187, Loss 4.6698, Error 0.2847(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18320 | Time 25.8620(26.8364) | Bit/dim 3.4797(3.5041) | Xent 0.0265(0.0184) | Loss 3.4929(3.5133) | Error 0.0078(0.0048) Steps 1108(1109.71) | Grad Norm 2.1740(1.4014) | Total Time 14.00(14.00)\n",
      "Iter 18330 | Time 26.8674(26.8375) | Bit/dim 3.5147(3.5028) | Xent 0.0104(0.0178) | Loss 3.5199(3.5117) | Error 0.0022(0.0046) Steps 1108(1109.85) | Grad Norm 0.9822(1.4494) | Total Time 14.00(14.00)\n",
      "Iter 18340 | Time 26.4246(26.7969) | Bit/dim 3.5209(3.5043) | Xent 0.0245(0.0179) | Loss 3.5331(3.5132) | Error 0.0056(0.0047) Steps 1114(1110.01) | Grad Norm 1.8266(1.4836) | Total Time 14.00(14.00)\n",
      "Iter 18350 | Time 26.8686(26.8139) | Bit/dim 3.5029(3.5061) | Xent 0.0184(0.0179) | Loss 3.5121(3.5150) | Error 0.0044(0.0049) Steps 1114(1110.70) | Grad Norm 1.3487(1.5478) | Total Time 14.00(14.00)\n",
      "Iter 18360 | Time 27.0257(26.8558) | Bit/dim 3.4816(3.5066) | Xent 0.0178(0.0182) | Loss 3.4905(3.5157) | Error 0.0044(0.0050) Steps 1108(1110.86) | Grad Norm 1.2611(1.5081) | Total Time 14.00(14.00)\n",
      "Iter 18370 | Time 26.7230(26.8236) | Bit/dim 3.4980(3.5060) | Xent 0.0251(0.0183) | Loss 3.5106(3.5151) | Error 0.0089(0.0053) Steps 1102(1110.50) | Grad Norm 2.0255(1.5224) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 126.9732, Epoch Time 1618.4422(1627.5088), Bit/dim 3.5087(best: 3.5105), Xent 2.2761, Loss 4.6468, Error 0.2827(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18380 | Time 26.7563(26.8630) | Bit/dim 3.5013(3.5062) | Xent 0.0179(0.0183) | Loss 3.5103(3.5153) | Error 0.0067(0.0051) Steps 1108(1111.59) | Grad Norm 1.4786(1.5126) | Total Time 14.00(14.00)\n",
      "Iter 18390 | Time 26.9130(26.8961) | Bit/dim 3.4711(3.5047) | Xent 0.0267(0.0195) | Loss 3.4845(3.5144) | Error 0.0078(0.0058) Steps 1108(1111.30) | Grad Norm 1.9219(1.5915) | Total Time 14.00(14.00)\n",
      "Iter 18400 | Time 26.7727(26.9468) | Bit/dim 3.5056(3.5061) | Xent 0.0268(0.0200) | Loss 3.5190(3.5160) | Error 0.0100(0.0058) Steps 1120(1111.60) | Grad Norm 1.4288(1.5366) | Total Time 14.00(14.00)\n",
      "Iter 18410 | Time 27.0840(26.9066) | Bit/dim 3.5159(3.5065) | Xent 0.0183(0.0192) | Loss 3.5251(3.5161) | Error 0.0056(0.0053) Steps 1108(1111.28) | Grad Norm 1.5011(1.4545) | Total Time 14.00(14.00)\n",
      "Iter 18420 | Time 26.7171(26.9016) | Bit/dim 3.5138(3.5039) | Xent 0.0196(0.0189) | Loss 3.5236(3.5134) | Error 0.0044(0.0051) Steps 1114(1111.83) | Grad Norm 1.1023(1.4178) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 128.2760, Epoch Time 1629.8161(1627.5780), Bit/dim 3.5096(best: 3.5087), Xent 2.3140, Loss 4.6666, Error 0.2833(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18430 | Time 26.9919(26.9726) | Bit/dim 3.4914(3.5049) | Xent 0.0189(0.0189) | Loss 3.5009(3.5144) | Error 0.0056(0.0051) Steps 1120(1112.33) | Grad Norm 1.2795(1.3660) | Total Time 14.00(14.00)\n",
      "Iter 18440 | Time 27.6899(26.9510) | Bit/dim 3.4972(3.5036) | Xent 0.0222(0.0184) | Loss 3.5084(3.5128) | Error 0.0044(0.0049) Steps 1114(1111.64) | Grad Norm 1.0344(1.3132) | Total Time 14.00(14.00)\n",
      "Iter 18450 | Time 26.0349(26.8859) | Bit/dim 3.4910(3.5027) | Xent 0.0225(0.0184) | Loss 3.5023(3.5120) | Error 0.0067(0.0050) Steps 1114(1111.02) | Grad Norm 1.5881(1.3273) | Total Time 14.00(14.00)\n",
      "Iter 18460 | Time 26.0928(26.7817) | Bit/dim 3.5313(3.5058) | Xent 0.0131(0.0178) | Loss 3.5379(3.5147) | Error 0.0022(0.0048) Steps 1120(1110.30) | Grad Norm 1.2171(1.3253) | Total Time 14.00(14.00)\n",
      "Iter 18470 | Time 26.1466(26.7658) | Bit/dim 3.4827(3.5057) | Xent 0.0136(0.0176) | Loss 3.4895(3.5145) | Error 0.0022(0.0046) Steps 1108(1110.11) | Grad Norm 1.4748(1.3668) | Total Time 14.00(14.00)\n",
      "Iter 18480 | Time 26.8784(26.8721) | Bit/dim 3.4951(3.5055) | Xent 0.0226(0.0174) | Loss 3.5064(3.5142) | Error 0.0067(0.0045) Steps 1096(1109.70) | Grad Norm 1.9107(1.4477) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 127.8414, Epoch Time 1620.9301(1627.3786), Bit/dim 3.5106(best: 3.5087), Xent 2.3297, Loss 4.6754, Error 0.2844(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18490 | Time 26.6839(26.7975) | Bit/dim 3.4766(3.5049) | Xent 0.0213(0.0179) | Loss 3.4872(3.5138) | Error 0.0056(0.0047) Steps 1114(1108.65) | Grad Norm 1.2680(1.5307) | Total Time 14.00(14.00)\n",
      "Iter 18500 | Time 27.1890(26.7908) | Bit/dim 3.4996(3.5032) | Xent 0.0178(0.0177) | Loss 3.5085(3.5120) | Error 0.0033(0.0048) Steps 1114(1110.05) | Grad Norm 1.4336(1.4918) | Total Time 14.00(14.00)\n",
      "Iter 18510 | Time 27.1869(26.8983) | Bit/dim 3.4989(3.5042) | Xent 0.0218(0.0172) | Loss 3.5098(3.5128) | Error 0.0067(0.0047) Steps 1108(1109.52) | Grad Norm 1.2987(1.4429) | Total Time 14.00(14.00)\n",
      "Iter 18520 | Time 27.7008(26.9354) | Bit/dim 3.4998(3.5069) | Xent 0.0154(0.0173) | Loss 3.5075(3.5156) | Error 0.0033(0.0047) Steps 1120(1109.96) | Grad Norm 1.0153(1.3549) | Total Time 14.00(14.00)\n",
      "Iter 18530 | Time 26.6894(26.9522) | Bit/dim 3.5247(3.5053) | Xent 0.0180(0.0174) | Loss 3.5337(3.5140) | Error 0.0056(0.0045) Steps 1108(1110.37) | Grad Norm 1.0408(1.3024) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 127.4864, Epoch Time 1625.8416(1627.3324), Bit/dim 3.5102(best: 3.5087), Xent 2.3445, Loss 4.6824, Error 0.2797(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18540 | Time 26.4963(26.9436) | Bit/dim 3.5099(3.5047) | Xent 0.0225(0.0174) | Loss 3.5211(3.5133) | Error 0.0078(0.0048) Steps 1108(1110.72) | Grad Norm 1.5503(1.3017) | Total Time 14.00(14.00)\n",
      "Iter 18550 | Time 26.7618(26.9241) | Bit/dim 3.5253(3.5030) | Xent 0.0175(0.0172) | Loss 3.5340(3.5116) | Error 0.0044(0.0048) Steps 1120(1111.03) | Grad Norm 1.1744(1.2842) | Total Time 14.00(14.00)\n",
      "Iter 18560 | Time 27.0978(26.8772) | Bit/dim 3.5256(3.5020) | Xent 0.0103(0.0171) | Loss 3.5308(3.5106) | Error 0.0022(0.0047) Steps 1096(1111.57) | Grad Norm 0.9945(1.2789) | Total Time 14.00(14.00)\n",
      "Iter 18570 | Time 26.9146(26.8668) | Bit/dim 3.5182(3.5037) | Xent 0.0179(0.0172) | Loss 3.5271(3.5123) | Error 0.0056(0.0047) Steps 1114(1111.48) | Grad Norm 1.6270(1.2539) | Total Time 14.00(14.00)\n",
      "Iter 18580 | Time 27.2910(26.9197) | Bit/dim 3.5134(3.5049) | Xent 0.0162(0.0175) | Loss 3.5215(3.5137) | Error 0.0033(0.0046) Steps 1126(1110.86) | Grad Norm 1.7583(1.2835) | Total Time 14.00(14.00)\n",
      "Iter 18590 | Time 27.5013(26.9689) | Bit/dim 3.5191(3.5061) | Xent 0.0207(0.0175) | Loss 3.5294(3.5148) | Error 0.0056(0.0045) Steps 1114(1111.34) | Grad Norm 1.3427(1.2332) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 126.3888, Epoch Time 1624.8673(1627.2585), Bit/dim 3.5087(best: 3.5087), Xent 2.3535, Loss 4.6855, Error 0.2849(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18600 | Time 27.2244(26.9526) | Bit/dim 3.5057(3.5052) | Xent 0.0177(0.0172) | Loss 3.5145(3.5138) | Error 0.0056(0.0044) Steps 1114(1110.68) | Grad Norm 1.1770(1.2037) | Total Time 14.00(14.00)\n",
      "Iter 18610 | Time 27.6597(26.9540) | Bit/dim 3.5057(3.5024) | Xent 0.0197(0.0172) | Loss 3.5156(3.5110) | Error 0.0056(0.0042) Steps 1102(1110.67) | Grad Norm 1.4140(1.1821) | Total Time 14.00(14.00)\n",
      "Iter 18620 | Time 26.3099(26.9280) | Bit/dim 3.4914(3.5021) | Xent 0.0150(0.0176) | Loss 3.4989(3.5109) | Error 0.0033(0.0045) Steps 1108(1110.48) | Grad Norm 1.0058(1.2179) | Total Time 14.00(14.00)\n",
      "Iter 18630 | Time 27.0481(26.9099) | Bit/dim 3.5079(3.5039) | Xent 0.0195(0.0173) | Loss 3.5176(3.5126) | Error 0.0056(0.0045) Steps 1090(1110.14) | Grad Norm 1.1351(1.2080) | Total Time 14.00(14.00)\n",
      "Iter 18640 | Time 27.3795(26.8914) | Bit/dim 3.4937(3.5060) | Xent 0.0239(0.0172) | Loss 3.5056(3.5146) | Error 0.0033(0.0042) Steps 1114(1110.02) | Grad Norm 1.2898(1.2000) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 127.7528, Epoch Time 1625.7918(1627.2145), Bit/dim 3.5098(best: 3.5087), Xent 2.3379, Loss 4.6788, Error 0.2841(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18650 | Time 27.4270(26.9548) | Bit/dim 3.5195(3.5062) | Xent 0.0254(0.0175) | Loss 3.5322(3.5149) | Error 0.0056(0.0043) Steps 1126(1109.66) | Grad Norm 1.7950(1.2621) | Total Time 14.00(14.00)\n",
      "Iter 18660 | Time 27.0144(26.9352) | Bit/dim 3.5146(3.5055) | Xent 0.0180(0.0173) | Loss 3.5236(3.5141) | Error 0.0056(0.0043) Steps 1114(1111.09) | Grad Norm 1.7860(1.2911) | Total Time 14.00(14.00)\n",
      "Iter 18670 | Time 27.2709(26.9754) | Bit/dim 3.5192(3.5048) | Xent 0.0137(0.0175) | Loss 3.5260(3.5136) | Error 0.0033(0.0045) Steps 1114(1110.71) | Grad Norm 1.2161(1.2891) | Total Time 14.00(14.00)\n",
      "Iter 18680 | Time 27.2299(27.0058) | Bit/dim 3.5334(3.5042) | Xent 0.0166(0.0172) | Loss 3.5417(3.5128) | Error 0.0022(0.0044) Steps 1114(1111.03) | Grad Norm 1.1659(1.2412) | Total Time 14.00(14.00)\n",
      "Iter 18690 | Time 26.5169(26.9594) | Bit/dim 3.4980(3.5054) | Xent 0.0248(0.0174) | Loss 3.5104(3.5141) | Error 0.0056(0.0043) Steps 1114(1110.37) | Grad Norm 1.2339(1.2435) | Total Time 14.00(14.00)\n",
      "Iter 18700 | Time 26.1612(26.8845) | Bit/dim 3.5230(3.5046) | Xent 0.0169(0.0175) | Loss 3.5314(3.5133) | Error 0.0033(0.0043) Steps 1108(1110.70) | Grad Norm 1.3795(1.3591) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 127.8289, Epoch Time 1626.9905(1627.2078), Bit/dim 3.5107(best: 3.5087), Xent 2.4000, Loss 4.7107, Error 0.2862(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18710 | Time 26.8688(26.9141) | Bit/dim 3.4809(3.5042) | Xent 0.0155(0.0173) | Loss 3.4886(3.5128) | Error 0.0022(0.0042) Steps 1120(1111.16) | Grad Norm 1.0669(1.3469) | Total Time 14.00(14.00)\n",
      "Iter 18720 | Time 27.9865(26.9934) | Bit/dim 3.5166(3.5046) | Xent 0.0150(0.0176) | Loss 3.5242(3.5134) | Error 0.0044(0.0044) Steps 1096(1112.08) | Grad Norm 1.1100(1.3438) | Total Time 14.00(14.00)\n",
      "Iter 18730 | Time 27.5914(27.1194) | Bit/dim 3.4878(3.5049) | Xent 0.0223(0.0174) | Loss 3.4990(3.5135) | Error 0.0089(0.0046) Steps 1102(1111.90) | Grad Norm 1.6040(1.3529) | Total Time 14.00(14.00)\n",
      "Iter 18740 | Time 26.6491(27.1710) | Bit/dim 3.4867(3.5048) | Xent 0.0154(0.0177) | Loss 3.4944(3.5136) | Error 0.0044(0.0048) Steps 1114(1112.49) | Grad Norm 1.0115(1.3796) | Total Time 14.00(14.00)\n",
      "Iter 18750 | Time 26.8812(27.1906) | Bit/dim 3.5222(3.5051) | Xent 0.0170(0.0183) | Loss 3.5307(3.5142) | Error 0.0044(0.0050) Steps 1132(1113.11) | Grad Norm 1.5500(1.3669) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 127.6770, Epoch Time 1643.7731(1627.7047), Bit/dim 3.5096(best: 3.5087), Xent 2.3546, Loss 4.6869, Error 0.2826(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18760 | Time 27.0710(27.2120) | Bit/dim 3.4922(3.5034) | Xent 0.0173(0.0184) | Loss 3.5008(3.5126) | Error 0.0033(0.0049) Steps 1114(1112.72) | Grad Norm 1.2137(1.3336) | Total Time 14.00(14.00)\n",
      "Iter 18770 | Time 27.0778(27.0729) | Bit/dim 3.5201(3.5042) | Xent 0.0128(0.0180) | Loss 3.5265(3.5133) | Error 0.0022(0.0047) Steps 1120(1112.54) | Grad Norm 1.2651(1.3091) | Total Time 14.00(14.00)\n",
      "Iter 18780 | Time 26.5401(27.0520) | Bit/dim 3.5065(3.5041) | Xent 0.0250(0.0188) | Loss 3.5190(3.5135) | Error 0.0056(0.0050) Steps 1114(1112.61) | Grad Norm 1.6169(1.3617) | Total Time 14.00(14.00)\n",
      "Iter 18790 | Time 27.2339(27.0291) | Bit/dim 3.4989(3.5067) | Xent 0.0122(0.0186) | Loss 3.5050(3.5160) | Error 0.0022(0.0049) Steps 1108(1111.36) | Grad Norm 1.0599(1.3942) | Total Time 14.00(14.00)\n",
      "Iter 18800 | Time 27.0305(27.0856) | Bit/dim 3.5181(3.5051) | Xent 0.0169(0.0183) | Loss 3.5265(3.5143) | Error 0.0078(0.0048) Steps 1108(1111.64) | Grad Norm 1.6176(1.4866) | Total Time 14.00(14.00)\n",
      "Iter 18810 | Time 27.2022(27.0534) | Bit/dim 3.5087(3.5032) | Xent 0.0132(0.0184) | Loss 3.5153(3.5124) | Error 0.0022(0.0049) Steps 1120(1111.33) | Grad Norm 0.9140(1.4776) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 129.0790, Epoch Time 1632.2787(1627.8420), Bit/dim 3.5076(best: 3.5087), Xent 2.3530, Loss 4.6841, Error 0.2824(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18820 | Time 27.1497(27.0085) | Bit/dim 3.5301(3.5029) | Xent 0.0205(0.0188) | Loss 3.5404(3.5123) | Error 0.0078(0.0054) Steps 1114(1111.32) | Grad Norm 1.4487(1.4910) | Total Time 14.00(14.00)\n",
      "Iter 18830 | Time 27.7161(26.9819) | Bit/dim 3.5038(3.5014) | Xent 0.0165(0.0178) | Loss 3.5121(3.5103) | Error 0.0033(0.0048) Steps 1120(1111.42) | Grad Norm 1.3488(1.4569) | Total Time 14.00(14.00)\n",
      "Iter 18840 | Time 26.9542(26.9364) | Bit/dim 3.5312(3.5052) | Xent 0.0218(0.0175) | Loss 3.5421(3.5140) | Error 0.0078(0.0048) Steps 1114(1110.55) | Grad Norm 2.2884(1.4210) | Total Time 14.00(14.00)\n",
      "Iter 18850 | Time 26.8821(26.8619) | Bit/dim 3.5193(3.5073) | Xent 0.0171(0.0180) | Loss 3.5279(3.5163) | Error 0.0044(0.0049) Steps 1102(1109.97) | Grad Norm 1.2396(1.4257) | Total Time 14.00(14.00)\n",
      "Iter 18860 | Time 27.7163(26.8999) | Bit/dim 3.5133(3.5054) | Xent 0.0195(0.0180) | Loss 3.5231(3.5144) | Error 0.0056(0.0048) Steps 1114(1109.79) | Grad Norm 1.0625(1.4099) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 128.1630, Epoch Time 1624.5010(1627.7417), Bit/dim 3.5091(best: 3.5076), Xent 2.3771, Loss 4.6976, Error 0.2866(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18870 | Time 26.6645(26.9569) | Bit/dim 3.4823(3.5029) | Xent 0.0199(0.0180) | Loss 3.4923(3.5119) | Error 0.0067(0.0049) Steps 1114(1110.37) | Grad Norm 2.9081(1.4875) | Total Time 14.00(14.00)\n",
      "Iter 18880 | Time 26.6514(26.9480) | Bit/dim 3.4991(3.5040) | Xent 0.0128(0.0176) | Loss 3.5055(3.5129) | Error 0.0011(0.0046) Steps 1108(1111.06) | Grad Norm 1.0350(1.5127) | Total Time 14.00(14.00)\n",
      "Iter 18890 | Time 26.9496(27.0220) | Bit/dim 3.4671(3.5028) | Xent 0.0188(0.0171) | Loss 3.4765(3.5114) | Error 0.0067(0.0046) Steps 1114(1110.46) | Grad Norm 1.1509(1.4552) | Total Time 14.00(14.00)\n",
      "Iter 18900 | Time 27.8014(27.0187) | Bit/dim 3.4867(3.5032) | Xent 0.0187(0.0178) | Loss 3.4961(3.5121) | Error 0.0067(0.0049) Steps 1120(1110.08) | Grad Norm 2.1099(1.4511) | Total Time 14.00(14.00)\n",
      "Iter 18910 | Time 26.2024(27.0035) | Bit/dim 3.4787(3.5012) | Xent 0.0197(0.0174) | Loss 3.4886(3.5099) | Error 0.0078(0.0048) Steps 1102(1109.13) | Grad Norm 2.2292(1.4437) | Total Time 14.00(14.00)\n",
      "Iter 18920 | Time 26.7643(26.9838) | Bit/dim 3.5351(3.5043) | Xent 0.0171(0.0176) | Loss 3.5436(3.5131) | Error 0.0056(0.0048) Steps 1120(1109.09) | Grad Norm 1.0230(1.3903) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 127.6618, Epoch Time 1631.3645(1627.8504), Bit/dim 3.5089(best: 3.5076), Xent 2.3538, Loss 4.6858, Error 0.2789(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18930 | Time 27.0278(27.0217) | Bit/dim 3.4651(3.5039) | Xent 0.0222(0.0169) | Loss 3.4762(3.5123) | Error 0.0089(0.0044) Steps 1114(1109.47) | Grad Norm 1.3436(1.3655) | Total Time 14.00(14.00)\n",
      "Iter 18940 | Time 26.3816(26.9367) | Bit/dim 3.5092(3.5044) | Xent 0.0150(0.0167) | Loss 3.5167(3.5127) | Error 0.0056(0.0046) Steps 1114(1109.87) | Grad Norm 0.8775(1.3087) | Total Time 14.00(14.00)\n",
      "Iter 18950 | Time 26.6558(26.9148) | Bit/dim 3.4976(3.5033) | Xent 0.0157(0.0170) | Loss 3.5055(3.5117) | Error 0.0044(0.0046) Steps 1090(1108.63) | Grad Norm 1.5619(1.3181) | Total Time 14.00(14.00)\n",
      "Iter 18960 | Time 27.0355(26.9638) | Bit/dim 3.5014(3.5029) | Xent 0.0189(0.0176) | Loss 3.5108(3.5116) | Error 0.0056(0.0047) Steps 1108(1108.73) | Grad Norm 1.3256(1.3349) | Total Time 14.00(14.00)\n",
      "Iter 18970 | Time 27.5963(26.9778) | Bit/dim 3.4763(3.5031) | Xent 0.0207(0.0183) | Loss 3.4866(3.5122) | Error 0.0067(0.0051) Steps 1108(1108.61) | Grad Norm 1.4699(1.4139) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 127.3428, Epoch Time 1628.8141(1627.8793), Bit/dim 3.5091(best: 3.5076), Xent 2.3694, Loss 4.6938, Error 0.2805(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18980 | Time 27.3360(26.9933) | Bit/dim 3.5160(3.5036) | Xent 0.0126(0.0184) | Loss 3.5223(3.5128) | Error 0.0022(0.0051) Steps 1108(1107.86) | Grad Norm 1.3327(1.4243) | Total Time 14.00(14.00)\n",
      "Iter 18990 | Time 27.0721(26.9736) | Bit/dim 3.5097(3.5041) | Xent 0.0189(0.0183) | Loss 3.5191(3.5133) | Error 0.0022(0.0049) Steps 1114(1107.90) | Grad Norm 0.9112(1.4001) | Total Time 14.00(14.00)\n",
      "Iter 19000 | Time 27.0291(26.9679) | Bit/dim 3.5146(3.5015) | Xent 0.0173(0.0184) | Loss 3.5232(3.5107) | Error 0.0056(0.0050) Steps 1102(1106.68) | Grad Norm 1.9823(1.4397) | Total Time 14.00(14.00)\n",
      "Iter 19010 | Time 27.0129(26.8752) | Bit/dim 3.4996(3.5041) | Xent 0.0271(0.0181) | Loss 3.5131(3.5131) | Error 0.0089(0.0049) Steps 1114(1106.04) | Grad Norm 1.9193(1.4659) | Total Time 14.00(14.00)\n",
      "Iter 19020 | Time 26.9938(26.8933) | Bit/dim 3.5019(3.5016) | Xent 0.0202(0.0184) | Loss 3.5120(3.5107) | Error 0.0056(0.0051) Steps 1108(1106.33) | Grad Norm 1.4427(1.4711) | Total Time 14.00(14.00)\n",
      "Iter 19030 | Time 27.5234(26.8939) | Bit/dim 3.4906(3.5039) | Xent 0.0183(0.0180) | Loss 3.4997(3.5129) | Error 0.0044(0.0050) Steps 1102(1107.10) | Grad Norm 1.1775(1.4112) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 127.6261, Epoch Time 1623.2460(1627.7403), Bit/dim 3.5073(best: 3.5076), Xent 2.3694, Loss 4.6920, Error 0.2864(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19040 | Time 27.1614(26.9037) | Bit/dim 3.5057(3.5016) | Xent 0.0143(0.0174) | Loss 3.5129(3.5103) | Error 0.0033(0.0048) Steps 1102(1106.42) | Grad Norm 1.4562(1.3709) | Total Time 14.00(14.00)\n",
      "Iter 19050 | Time 27.2847(26.9285) | Bit/dim 3.5239(3.5029) | Xent 0.0161(0.0173) | Loss 3.5319(3.5116) | Error 0.0044(0.0045) Steps 1108(1107.44) | Grad Norm 1.4522(1.3160) | Total Time 14.00(14.00)\n",
      "Iter 19060 | Time 26.3773(26.8560) | Bit/dim 3.5116(3.5029) | Xent 0.0170(0.0170) | Loss 3.5201(3.5114) | Error 0.0044(0.0046) Steps 1108(1106.64) | Grad Norm 1.1167(1.2679) | Total Time 14.00(14.00)\n",
      "Iter 19070 | Time 27.0305(26.8921) | Bit/dim 3.5387(3.5048) | Xent 0.0159(0.0172) | Loss 3.5466(3.5133) | Error 0.0033(0.0047) Steps 1108(1107.01) | Grad Norm 1.0493(1.2758) | Total Time 14.00(14.00)\n",
      "Iter 19080 | Time 27.8470(26.9003) | Bit/dim 3.5086(3.5047) | Xent 0.0137(0.0175) | Loss 3.5154(3.5135) | Error 0.0022(0.0050) Steps 1114(1106.81) | Grad Norm 1.1546(1.3641) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 126.9821, Epoch Time 1623.5802(1627.6155), Bit/dim 3.5076(best: 3.5073), Xent 2.4022, Loss 4.7087, Error 0.2864(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19090 | Time 26.7941(26.8980) | Bit/dim 3.4766(3.5019) | Xent 0.0259(0.0179) | Loss 3.4895(3.5108) | Error 0.0089(0.0052) Steps 1084(1107.18) | Grad Norm 1.6292(1.3616) | Total Time 14.00(14.00)\n",
      "Iter 19100 | Time 27.2505(26.9181) | Bit/dim 3.5260(3.5041) | Xent 0.0169(0.0183) | Loss 3.5344(3.5132) | Error 0.0033(0.0054) Steps 1108(1107.07) | Grad Norm 1.1339(1.4373) | Total Time 14.00(14.00)\n",
      "Iter 19110 | Time 27.3760(26.8998) | Bit/dim 3.5089(3.5037) | Xent 0.0200(0.0178) | Loss 3.5189(3.5125) | Error 0.0067(0.0052) Steps 1090(1107.49) | Grad Norm 1.2679(1.4306) | Total Time 14.00(14.00)\n",
      "Iter 19120 | Time 26.6605(26.8893) | Bit/dim 3.4837(3.5043) | Xent 0.0190(0.0179) | Loss 3.4932(3.5133) | Error 0.0044(0.0052) Steps 1108(1107.46) | Grad Norm 1.5012(1.4259) | Total Time 14.00(14.00)\n",
      "Iter 19130 | Time 26.7139(26.9237) | Bit/dim 3.5229(3.5039) | Xent 0.0154(0.0175) | Loss 3.5305(3.5126) | Error 0.0067(0.0052) Steps 1114(1108.08) | Grad Norm 1.0632(1.4291) | Total Time 14.00(14.00)\n",
      "Iter 19140 | Time 26.3478(26.8946) | Bit/dim 3.4713(3.5030) | Xent 0.0097(0.0173) | Loss 3.4762(3.5117) | Error 0.0022(0.0049) Steps 1108(1106.67) | Grad Norm 1.1173(1.4124) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 126.3534, Epoch Time 1624.3658(1627.5180), Bit/dim 3.5085(best: 3.5073), Xent 2.3769, Loss 4.6970, Error 0.2862(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19150 | Time 26.5334(26.8459) | Bit/dim 3.5272(3.5047) | Xent 0.0214(0.0178) | Loss 3.5380(3.5136) | Error 0.0067(0.0052) Steps 1096(1105.25) | Grad Norm 1.6505(1.4474) | Total Time 14.00(14.00)\n",
      "Iter 19160 | Time 26.9244(26.8910) | Bit/dim 3.5082(3.5019) | Xent 0.0114(0.0173) | Loss 3.5140(3.5105) | Error 0.0022(0.0050) Steps 1108(1104.96) | Grad Norm 0.9414(1.4421) | Total Time 14.00(14.00)\n",
      "Iter 19170 | Time 27.1982(26.9202) | Bit/dim 3.4732(3.5015) | Xent 0.0226(0.0179) | Loss 3.4845(3.5104) | Error 0.0089(0.0052) Steps 1096(1105.36) | Grad Norm 1.5408(1.4326) | Total Time 14.00(14.00)\n",
      "Iter 19180 | Time 27.3240(26.9747) | Bit/dim 3.4966(3.5053) | Xent 0.0161(0.0177) | Loss 3.5047(3.5142) | Error 0.0033(0.0050) Steps 1090(1104.30) | Grad Norm 1.3970(1.4265) | Total Time 14.00(14.00)\n",
      "Iter 19190 | Time 27.7423(26.9582) | Bit/dim 3.4866(3.5023) | Xent 0.0211(0.0179) | Loss 3.4972(3.5113) | Error 0.0078(0.0052) Steps 1108(1104.23) | Grad Norm 1.2515(1.4376) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 128.7798, Epoch Time 1629.3231(1627.5722), Bit/dim 3.5088(best: 3.5073), Xent 2.4305, Loss 4.7240, Error 0.2823(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19200 | Time 26.6300(26.9113) | Bit/dim 3.4775(3.5006) | Xent 0.0236(0.0180) | Loss 3.4893(3.5096) | Error 0.0089(0.0052) Steps 1090(1104.33) | Grad Norm 1.2933(1.4316) | Total Time 14.00(14.00)\n",
      "Iter 19210 | Time 26.6951(26.8699) | Bit/dim 3.5487(3.5032) | Xent 0.0209(0.0171) | Loss 3.5592(3.5118) | Error 0.0033(0.0047) Steps 1120(1104.52) | Grad Norm 1.4326(1.3448) | Total Time 14.00(14.00)\n",
      "Iter 19220 | Time 27.1856(26.9376) | Bit/dim 3.5101(3.5021) | Xent 0.0189(0.0170) | Loss 3.5195(3.5107) | Error 0.0044(0.0044) Steps 1096(1103.50) | Grad Norm 1.1121(1.2642) | Total Time 14.00(14.00)\n",
      "Iter 19230 | Time 26.1344(26.8469) | Bit/dim 3.4780(3.4984) | Xent 0.0296(0.0171) | Loss 3.4928(3.5069) | Error 0.0100(0.0045) Steps 1090(1101.60) | Grad Norm 1.5669(1.2654) | Total Time 14.00(14.00)\n",
      "Iter 19240 | Time 26.7816(26.8851) | Bit/dim 3.4802(3.5014) | Xent 0.0209(0.0177) | Loss 3.4906(3.5103) | Error 0.0067(0.0048) Steps 1096(1102.50) | Grad Norm 1.3892(1.3207) | Total Time 14.00(14.00)\n",
      "Iter 19250 | Time 27.0966(26.9372) | Bit/dim 3.5220(3.5032) | Xent 0.0153(0.0174) | Loss 3.5296(3.5119) | Error 0.0033(0.0048) Steps 1108(1103.46) | Grad Norm 1.1520(1.3385) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 127.2900, Epoch Time 1623.9283(1627.4629), Bit/dim 3.5067(best: 3.5073), Xent 2.3846, Loss 4.6990, Error 0.2858(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19260 | Time 27.3346(26.9319) | Bit/dim 3.5185(3.5014) | Xent 0.0131(0.0168) | Loss 3.5251(3.5098) | Error 0.0022(0.0044) Steps 1108(1104.34) | Grad Norm 0.8054(1.2699) | Total Time 14.00(14.00)\n",
      "Iter 19270 | Time 27.2919(26.9262) | Bit/dim 3.5354(3.5035) | Xent 0.0112(0.0163) | Loss 3.5411(3.5117) | Error 0.0011(0.0043) Steps 1096(1104.84) | Grad Norm 1.0320(1.2181) | Total Time 14.00(14.00)\n",
      "Iter 19280 | Time 27.0147(27.0148) | Bit/dim 3.5215(3.5033) | Xent 0.0160(0.0166) | Loss 3.5295(3.5116) | Error 0.0044(0.0045) Steps 1108(1103.85) | Grad Norm 1.1354(1.2008) | Total Time 14.00(14.00)\n",
      "Iter 19290 | Time 26.5951(26.9267) | Bit/dim 3.5157(3.5033) | Xent 0.0098(0.0165) | Loss 3.5206(3.5116) | Error 0.0000(0.0044) Steps 1102(1104.81) | Grad Norm 0.8243(1.1810) | Total Time 14.00(14.00)\n",
      "Iter 19300 | Time 26.7324(26.9207) | Bit/dim 3.5036(3.5021) | Xent 0.0172(0.0163) | Loss 3.5122(3.5103) | Error 0.0044(0.0041) Steps 1102(1103.92) | Grad Norm 1.3720(1.1759) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 127.1792, Epoch Time 1627.6360(1627.4681), Bit/dim 3.5072(best: 3.5067), Xent 2.4139, Loss 4.7141, Error 0.2847(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19310 | Time 26.5551(26.9285) | Bit/dim 3.5157(3.5053) | Xent 0.0148(0.0163) | Loss 3.5231(3.5134) | Error 0.0044(0.0041) Steps 1120(1103.29) | Grad Norm 1.1270(1.1790) | Total Time 14.00(14.00)\n",
      "Iter 19320 | Time 26.9219(26.9191) | Bit/dim 3.4995(3.5047) | Xent 0.0133(0.0165) | Loss 3.5061(3.5130) | Error 0.0033(0.0043) Steps 1102(1103.56) | Grad Norm 0.9835(1.2081) | Total Time 14.00(14.00)\n",
      "Iter 19330 | Time 26.2969(26.8669) | Bit/dim 3.4813(3.5017) | Xent 0.0170(0.0169) | Loss 3.4898(3.5101) | Error 0.0056(0.0043) Steps 1102(1104.25) | Grad Norm 1.1642(1.2330) | Total Time 14.00(14.00)\n",
      "Iter 19340 | Time 26.5142(26.7912) | Bit/dim 3.5383(3.5041) | Xent 0.0170(0.0164) | Loss 3.5467(3.5123) | Error 0.0044(0.0044) Steps 1102(1103.79) | Grad Norm 1.5399(1.2466) | Total Time 14.00(14.00)\n",
      "Iter 19350 | Time 26.0037(26.8106) | Bit/dim 3.4732(3.5016) | Xent 0.0211(0.0166) | Loss 3.4838(3.5098) | Error 0.0056(0.0044) Steps 1102(1105.30) | Grad Norm 1.5819(1.2310) | Total Time 14.00(14.00)\n",
      "Iter 19360 | Time 26.4871(26.7585) | Bit/dim 3.5100(3.5015) | Xent 0.0242(0.0168) | Loss 3.5221(3.5098) | Error 0.0044(0.0043) Steps 1120(1106.86) | Grad Norm 1.5198(1.2391) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 128.6004, Epoch Time 1617.0549(1627.1557), Bit/dim 3.5062(best: 3.5067), Xent 2.3994, Loss 4.7059, Error 0.2880(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19370 | Time 26.7073(26.7090) | Bit/dim 3.5077(3.5022) | Xent 0.0148(0.0168) | Loss 3.5150(3.5106) | Error 0.0056(0.0045) Steps 1114(1106.07) | Grad Norm 1.4877(1.2724) | Total Time 14.00(14.00)\n",
      "Iter 19380 | Time 26.9201(26.7148) | Bit/dim 3.5262(3.5025) | Xent 0.0097(0.0168) | Loss 3.5311(3.5109) | Error 0.0011(0.0046) Steps 1114(1105.63) | Grad Norm 0.8760(1.2961) | Total Time 14.00(14.00)\n",
      "Iter 19390 | Time 27.2340(26.7596) | Bit/dim 3.5071(3.5013) | Xent 0.0182(0.0167) | Loss 3.5162(3.5096) | Error 0.0067(0.0046) Steps 1108(1105.27) | Grad Norm 1.6401(1.2853) | Total Time 14.00(14.00)\n",
      "Iter 19400 | Time 27.4306(26.7576) | Bit/dim 3.4790(3.5006) | Xent 0.0140(0.0170) | Loss 3.4860(3.5091) | Error 0.0033(0.0048) Steps 1120(1106.01) | Grad Norm 1.3842(1.2790) | Total Time 14.00(14.00)\n",
      "Iter 19410 | Time 26.6909(26.7252) | Bit/dim 3.4909(3.5022) | Xent 0.0283(0.0174) | Loss 3.5050(3.5109) | Error 0.0078(0.0048) Steps 1102(1105.86) | Grad Norm 1.9516(1.3326) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 127.9939, Epoch Time 1614.5942(1626.7788), Bit/dim 3.5080(best: 3.5062), Xent 2.4088, Loss 4.7124, Error 0.2873(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19420 | Time 26.3916(26.7281) | Bit/dim 3.4990(3.5017) | Xent 0.0206(0.0179) | Loss 3.5093(3.5106) | Error 0.0056(0.0049) Steps 1108(1106.63) | Grad Norm 1.3792(1.3392) | Total Time 14.00(14.00)\n",
      "Iter 19430 | Time 26.4499(26.7166) | Bit/dim 3.4969(3.5013) | Xent 0.0134(0.0177) | Loss 3.5036(3.5102) | Error 0.0022(0.0049) Steps 1090(1105.37) | Grad Norm 1.6092(1.3780) | Total Time 14.00(14.00)\n",
      "Iter 19440 | Time 26.9946(26.6915) | Bit/dim 3.5132(3.5051) | Xent 0.0080(0.0171) | Loss 3.5173(3.5137) | Error 0.0022(0.0047) Steps 1102(1105.37) | Grad Norm 0.8871(1.3536) | Total Time 14.00(14.00)\n",
      "Iter 19450 | Time 26.8805(26.7549) | Bit/dim 3.4827(3.5049) | Xent 0.0159(0.0170) | Loss 3.4906(3.5134) | Error 0.0056(0.0048) Steps 1102(1105.23) | Grad Norm 1.3202(1.3689) | Total Time 14.00(14.00)\n",
      "Iter 19460 | Time 27.3288(26.8423) | Bit/dim 3.4660(3.5001) | Xent 0.0131(0.0171) | Loss 3.4726(3.5086) | Error 0.0033(0.0049) Steps 1108(1104.19) | Grad Norm 1.3540(1.3749) | Total Time 14.00(14.00)\n",
      "Iter 19470 | Time 26.7739(26.8856) | Bit/dim 3.4614(3.5006) | Xent 0.0189(0.0166) | Loss 3.4708(3.5089) | Error 0.0078(0.0048) Steps 1102(1103.46) | Grad Norm 1.3781(1.3563) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 128.1819, Epoch Time 1623.2590(1626.6732), Bit/dim 3.5072(best: 3.5062), Xent 2.4227, Loss 4.7185, Error 0.2860(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19480 | Time 27.1268(26.9016) | Bit/dim 3.5445(3.4981) | Xent 0.0121(0.0166) | Loss 3.5506(3.5064) | Error 0.0022(0.0045) Steps 1126(1104.08) | Grad Norm 1.0038(1.3172) | Total Time 14.00(14.00)\n",
      "Iter 19490 | Time 26.1640(26.8332) | Bit/dim 3.5042(3.4991) | Xent 0.0091(0.0164) | Loss 3.5087(3.5074) | Error 0.0011(0.0044) Steps 1102(1103.65) | Grad Norm 0.9161(1.2946) | Total Time 14.00(14.00)\n",
      "Iter 19500 | Time 26.7349(26.7481) | Bit/dim 3.5132(3.4999) | Xent 0.0233(0.0166) | Loss 3.5249(3.5082) | Error 0.0067(0.0046) Steps 1102(1102.29) | Grad Norm 1.8475(1.3487) | Total Time 14.00(14.00)\n",
      "Iter 19510 | Time 26.5510(26.7197) | Bit/dim 3.4968(3.5002) | Xent 0.0245(0.0166) | Loss 3.5091(3.5085) | Error 0.0100(0.0044) Steps 1096(1102.69) | Grad Norm 2.0777(1.3788) | Total Time 14.00(14.00)\n",
      "Iter 19520 | Time 26.4320(26.6225) | Bit/dim 3.5083(3.5018) | Xent 0.0212(0.0174) | Loss 3.5189(3.5105) | Error 0.0067(0.0048) Steps 1102(1101.86) | Grad Norm 1.6028(1.3760) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 127.2798, Epoch Time 1609.2603(1626.1508), Bit/dim 3.5079(best: 3.5062), Xent 2.4198, Loss 4.7178, Error 0.2861(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19530 | Time 26.8202(26.6684) | Bit/dim 3.5018(3.5014) | Xent 0.0133(0.0182) | Loss 3.5084(3.5105) | Error 0.0022(0.0051) Steps 1108(1101.37) | Grad Norm 1.4981(1.4454) | Total Time 14.00(14.00)\n",
      "Iter 19540 | Time 26.9737(26.6572) | Bit/dim 3.4788(3.5005) | Xent 0.0133(0.0176) | Loss 3.4854(3.5094) | Error 0.0033(0.0048) Steps 1108(1100.60) | Grad Norm 0.9763(1.3985) | Total Time 14.00(14.00)\n",
      "Iter 19550 | Time 27.3518(26.7222) | Bit/dim 3.4892(3.5000) | Xent 0.0220(0.0181) | Loss 3.5003(3.5090) | Error 0.0056(0.0051) Steps 1102(1102.57) | Grad Norm 1.2142(1.3629) | Total Time 14.00(14.00)\n",
      "Iter 19560 | Time 26.6716(26.7644) | Bit/dim 3.5038(3.5004) | Xent 0.0124(0.0173) | Loss 3.5100(3.5090) | Error 0.0044(0.0048) Steps 1096(1102.23) | Grad Norm 0.9843(1.3032) | Total Time 14.00(14.00)\n",
      "Iter 19570 | Time 26.2880(26.7592) | Bit/dim 3.4841(3.5029) | Xent 0.0158(0.0170) | Loss 3.4920(3.5114) | Error 0.0044(0.0048) Steps 1090(1101.86) | Grad Norm 1.2854(1.3145) | Total Time 14.00(14.00)\n",
      "Iter 19580 | Time 26.8507(26.8184) | Bit/dim 3.4857(3.5027) | Xent 0.0072(0.0171) | Loss 3.4892(3.5113) | Error 0.0000(0.0047) Steps 1108(1102.57) | Grad Norm 0.5514(1.3493) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 126.6438, Epoch Time 1620.7660(1625.9893), Bit/dim 3.5074(best: 3.5062), Xent 2.4507, Loss 4.7327, Error 0.2864(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19590 | Time 27.6087(26.9091) | Bit/dim 3.4942(3.5034) | Xent 0.0099(0.0174) | Loss 3.4992(3.5121) | Error 0.0011(0.0051) Steps 1102(1102.07) | Grad Norm 1.0173(1.4913) | Total Time 14.00(14.00)\n",
      "Iter 19600 | Time 26.0778(26.8518) | Bit/dim 3.4871(3.4999) | Xent 0.0248(0.0174) | Loss 3.4995(3.5086) | Error 0.0089(0.0051) Steps 1108(1101.36) | Grad Norm 2.6874(1.5450) | Total Time 14.00(14.00)\n",
      "Iter 19610 | Time 26.8867(26.8583) | Bit/dim 3.5269(3.5017) | Xent 0.0161(0.0179) | Loss 3.5350(3.5107) | Error 0.0044(0.0050) Steps 1102(1102.75) | Grad Norm 1.3117(1.5298) | Total Time 14.00(14.00)\n",
      "Iter 19620 | Time 26.5193(26.8131) | Bit/dim 3.4712(3.5016) | Xent 0.0254(0.0181) | Loss 3.4840(3.5107) | Error 0.0100(0.0053) Steps 1084(1102.98) | Grad Norm 3.0696(1.5973) | Total Time 14.00(14.00)\n",
      "Iter 19630 | Time 27.0703(26.7957) | Bit/dim 3.4994(3.5037) | Xent 0.0269(0.0181) | Loss 3.5128(3.5127) | Error 0.0089(0.0054) Steps 1090(1103.04) | Grad Norm 2.7093(1.7168) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 127.8612, Epoch Time 1621.7607(1625.8624), Bit/dim 3.5073(best: 3.5062), Xent 2.3866, Loss 4.7006, Error 0.2797(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19640 | Time 26.8025(26.8403) | Bit/dim 3.5110(3.5053) | Xent 0.0194(0.0178) | Loss 3.5207(3.5142) | Error 0.0044(0.0053) Steps 1108(1103.41) | Grad Norm 1.7421(1.6536) | Total Time 14.00(14.00)\n",
      "Iter 19650 | Time 26.6055(26.8479) | Bit/dim 3.4980(3.5062) | Xent 0.0110(0.0173) | Loss 3.5035(3.5149) | Error 0.0022(0.0050) Steps 1102(1103.08) | Grad Norm 1.0960(1.5330) | Total Time 14.00(14.00)\n",
      "Iter 19660 | Time 27.3106(26.8338) | Bit/dim 3.5080(3.5039) | Xent 0.0163(0.0171) | Loss 3.5161(3.5125) | Error 0.0033(0.0048) Steps 1096(1102.88) | Grad Norm 1.2434(1.4754) | Total Time 14.00(14.00)\n",
      "Iter 19670 | Time 26.3316(26.7985) | Bit/dim 3.4945(3.5021) | Xent 0.0181(0.0171) | Loss 3.5035(3.5106) | Error 0.0056(0.0049) Steps 1084(1101.97) | Grad Norm 1.3699(1.4359) | Total Time 14.00(14.00)\n",
      "Iter 19680 | Time 26.5604(26.8214) | Bit/dim 3.4984(3.5003) | Xent 0.0214(0.0170) | Loss 3.5092(3.5088) | Error 0.0044(0.0047) Steps 1108(1102.46) | Grad Norm 1.4636(1.3836) | Total Time 14.00(14.00)\n",
      "Iter 19690 | Time 27.3710(26.7754) | Bit/dim 3.4893(3.5001) | Xent 0.0100(0.0167) | Loss 3.4943(3.5084) | Error 0.0011(0.0047) Steps 1108(1102.26) | Grad Norm 0.9772(1.3180) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 127.5348, Epoch Time 1619.7954(1625.6804), Bit/dim 3.5061(best: 3.5062), Xent 2.4514, Loss 4.7318, Error 0.2849(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19700 | Time 26.7241(26.7256) | Bit/dim 3.4993(3.5041) | Xent 0.0136(0.0169) | Loss 3.5061(3.5125) | Error 0.0033(0.0047) Steps 1090(1101.11) | Grad Norm 1.2399(1.2915) | Total Time 14.00(14.00)\n",
      "Iter 19710 | Time 25.6987(26.6799) | Bit/dim 3.5261(3.5031) | Xent 0.0165(0.0169) | Loss 3.5344(3.5116) | Error 0.0044(0.0047) Steps 1102(1101.36) | Grad Norm 1.0954(1.3106) | Total Time 14.00(14.00)\n",
      "Iter 19720 | Time 26.6602(26.7025) | Bit/dim 3.4977(3.5023) | Xent 0.0167(0.0170) | Loss 3.5060(3.5108) | Error 0.0033(0.0048) Steps 1096(1101.16) | Grad Norm 1.7895(1.3718) | Total Time 14.00(14.00)\n",
      "Iter 19730 | Time 27.3299(26.7314) | Bit/dim 3.5096(3.5029) | Xent 0.0180(0.0170) | Loss 3.5186(3.5114) | Error 0.0078(0.0050) Steps 1096(1102.48) | Grad Norm 1.4466(1.3591) | Total Time 14.00(14.00)\n",
      "Iter 19740 | Time 27.9464(26.7574) | Bit/dim 3.4770(3.5010) | Xent 0.0226(0.0176) | Loss 3.4882(3.5098) | Error 0.0056(0.0052) Steps 1102(1101.56) | Grad Norm 1.5493(1.3997) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 127.1896, Epoch Time 1614.8504(1625.3555), Bit/dim 3.5078(best: 3.5061), Xent 2.5027, Loss 4.7592, Error 0.2855(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19750 | Time 26.4806(26.7582) | Bit/dim 3.5090(3.5007) | Xent 0.0193(0.0184) | Loss 3.5186(3.5099) | Error 0.0044(0.0053) Steps 1102(1101.92) | Grad Norm 1.6240(1.4528) | Total Time 14.00(14.00)\n",
      "Iter 19760 | Time 26.8022(26.7205) | Bit/dim 3.5223(3.5024) | Xent 0.0133(0.0184) | Loss 3.5290(3.5116) | Error 0.0033(0.0051) Steps 1102(1100.84) | Grad Norm 1.3045(1.4680) | Total Time 14.00(14.00)\n",
      "Iter 19770 | Time 26.8715(26.7252) | Bit/dim 3.4977(3.5028) | Xent 0.0194(0.0180) | Loss 3.5074(3.5118) | Error 0.0033(0.0048) Steps 1108(1100.58) | Grad Norm 1.5877(1.5000) | Total Time 14.00(14.00)\n",
      "Iter 19780 | Time 26.7002(26.7463) | Bit/dim 3.5183(3.5023) | Xent 0.0141(0.0176) | Loss 3.5253(3.5112) | Error 0.0056(0.0048) Steps 1096(1100.91) | Grad Norm 1.2311(1.4687) | Total Time 14.00(14.00)\n",
      "Iter 19790 | Time 26.8670(26.7260) | Bit/dim 3.5064(3.5023) | Xent 0.0116(0.0166) | Loss 3.5122(3.5106) | Error 0.0033(0.0043) Steps 1090(1101.13) | Grad Norm 1.2001(1.3794) | Total Time 14.00(14.00)\n",
      "Iter 19800 | Time 26.9752(26.7300) | Bit/dim 3.4959(3.4987) | Xent 0.0136(0.0169) | Loss 3.5027(3.5072) | Error 0.0022(0.0044) Steps 1090(1101.32) | Grad Norm 1.4412(1.3918) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 127.8091, Epoch Time 1614.5205(1625.0305), Bit/dim 3.5068(best: 3.5061), Xent 2.4566, Loss 4.7351, Error 0.2872(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19810 | Time 26.8630(26.7116) | Bit/dim 3.5059(3.4999) | Xent 0.0210(0.0166) | Loss 3.5164(3.5082) | Error 0.0067(0.0042) Steps 1114(1101.68) | Grad Norm 1.7071(1.4046) | Total Time 14.00(14.00)\n",
      "Iter 19820 | Time 26.2508(26.7178) | Bit/dim 3.4865(3.5027) | Xent 0.0178(0.0167) | Loss 3.4954(3.5111) | Error 0.0044(0.0042) Steps 1090(1101.03) | Grad Norm 2.1907(1.4437) | Total Time 14.00(14.00)\n",
      "Iter 19830 | Time 26.1949(26.6839) | Bit/dim 3.4962(3.5020) | Xent 0.0172(0.0172) | Loss 3.5048(3.5106) | Error 0.0067(0.0047) Steps 1108(1101.96) | Grad Norm 1.3799(1.5360) | Total Time 14.00(14.00)\n",
      "Iter 19840 | Time 26.2944(26.6448) | Bit/dim 3.4775(3.4991) | Xent 0.0204(0.0173) | Loss 3.4877(3.5077) | Error 0.0044(0.0047) Steps 1108(1102.78) | Grad Norm 1.6852(1.5434) | Total Time 14.00(14.00)\n",
      "Iter 19850 | Time 26.5825(26.6820) | Bit/dim 3.5138(3.4991) | Xent 0.0136(0.0174) | Loss 3.5205(3.5078) | Error 0.0011(0.0046) Steps 1102(1102.95) | Grad Norm 1.7542(1.5174) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 127.2784, Epoch Time 1613.2556(1624.6772), Bit/dim 3.5062(best: 3.5061), Xent 2.4127, Loss 4.7125, Error 0.2846(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19860 | Time 25.9062(26.7084) | Bit/dim 3.5209(3.5005) | Xent 0.0208(0.0177) | Loss 3.5313(3.5093) | Error 0.0078(0.0048) Steps 1090(1102.88) | Grad Norm 1.9226(1.5081) | Total Time 14.00(14.00)\n",
      "Iter 19870 | Time 27.1194(26.7160) | Bit/dim 3.5058(3.5018) | Xent 0.0154(0.0172) | Loss 3.5135(3.5104) | Error 0.0033(0.0044) Steps 1102(1101.53) | Grad Norm 1.2476(1.4745) | Total Time 14.00(14.00)\n",
      "Iter 19880 | Time 26.8920(26.7595) | Bit/dim 3.5199(3.5037) | Xent 0.0180(0.0176) | Loss 3.5289(3.5125) | Error 0.0056(0.0048) Steps 1108(1100.41) | Grad Norm 2.0748(1.4952) | Total Time 14.00(14.00)\n",
      "Iter 19890 | Time 26.7634(26.8200) | Bit/dim 3.4931(3.5030) | Xent 0.0153(0.0173) | Loss 3.5007(3.5117) | Error 0.0022(0.0047) Steps 1102(1101.15) | Grad Norm 1.3903(1.4850) | Total Time 14.00(14.00)\n",
      "Iter 19900 | Time 25.9094(26.7418) | Bit/dim 3.5024(3.5007) | Xent 0.0183(0.0171) | Loss 3.5116(3.5093) | Error 0.0056(0.0046) Steps 1108(1100.36) | Grad Norm 1.7649(1.4470) | Total Time 14.00(14.00)\n",
      "Iter 19910 | Time 26.9188(26.7071) | Bit/dim 3.5183(3.4981) | Xent 0.0183(0.0177) | Loss 3.5274(3.5070) | Error 0.0056(0.0050) Steps 1108(1100.93) | Grad Norm 1.4331(1.4698) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 128.4719, Epoch Time 1617.4736(1624.4611), Bit/dim 3.5071(best: 3.5061), Xent 2.4487, Loss 4.7314, Error 0.2857(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19920 | Time 27.3201(26.8158) | Bit/dim 3.5037(3.4987) | Xent 0.0163(0.0176) | Loss 3.5118(3.5075) | Error 0.0044(0.0048) Steps 1090(1101.71) | Grad Norm 1.3207(1.4707) | Total Time 14.00(14.00)\n",
      "Iter 19930 | Time 26.7261(26.8185) | Bit/dim 3.5275(3.4988) | Xent 0.0246(0.0168) | Loss 3.5398(3.5072) | Error 0.0089(0.0045) Steps 1102(1100.77) | Grad Norm 1.4310(1.4300) | Total Time 14.00(14.00)\n",
      "Iter 19940 | Time 26.9120(26.8061) | Bit/dim 3.4781(3.5015) | Xent 0.0138(0.0174) | Loss 3.4850(3.5102) | Error 0.0044(0.0050) Steps 1090(1099.71) | Grad Norm 1.3083(1.4434) | Total Time 14.00(14.00)\n",
      "Iter 19950 | Time 27.3373(26.8068) | Bit/dim 3.5263(3.5026) | Xent 0.0197(0.0171) | Loss 3.5362(3.5112) | Error 0.0033(0.0045) Steps 1096(1099.83) | Grad Norm 1.3635(1.4138) | Total Time 14.00(14.00)\n",
      "Iter 19960 | Time 27.0472(26.8308) | Bit/dim 3.5017(3.4986) | Xent 0.0185(0.0177) | Loss 3.5110(3.5075) | Error 0.0033(0.0047) Steps 1108(1100.62) | Grad Norm 1.4871(1.4158) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 127.3191, Epoch Time 1622.9672(1624.4163), Bit/dim 3.5058(best: 3.5061), Xent 2.4190, Loss 4.7153, Error 0.2871(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19970 | Time 26.5090(26.7769) | Bit/dim 3.5164(3.5005) | Xent 0.0181(0.0172) | Loss 3.5254(3.5091) | Error 0.0044(0.0045) Steps 1102(1100.90) | Grad Norm 1.1189(1.3624) | Total Time 14.00(14.00)\n",
      "Iter 19980 | Time 26.6886(26.7409) | Bit/dim 3.4933(3.5020) | Xent 0.0157(0.0164) | Loss 3.5012(3.5102) | Error 0.0022(0.0040) Steps 1096(1101.83) | Grad Norm 0.9526(1.3157) | Total Time 14.00(14.00)\n",
      "Iter 19990 | Time 26.6571(26.7364) | Bit/dim 3.5110(3.4998) | Xent 0.0181(0.0166) | Loss 3.5200(3.5081) | Error 0.0056(0.0042) Steps 1102(1101.41) | Grad Norm 1.8713(1.3677) | Total Time 14.00(14.00)\n",
      "Iter 20000 | Time 26.5041(26.7728) | Bit/dim 3.5070(3.4999) | Xent 0.0145(0.0163) | Loss 3.5142(3.5081) | Error 0.0067(0.0044) Steps 1102(1100.99) | Grad Norm 1.3545(1.3934) | Total Time 14.00(14.00)\n",
      "Iter 20010 | Time 26.6881(26.7925) | Bit/dim 3.4968(3.5006) | Xent 0.0150(0.0165) | Loss 3.5043(3.5089) | Error 0.0056(0.0043) Steps 1114(1100.76) | Grad Norm 1.3918(1.3721) | Total Time 14.00(14.00)\n",
      "Iter 20020 | Time 27.1623(26.8424) | Bit/dim 3.5084(3.4997) | Xent 0.0153(0.0167) | Loss 3.5160(3.5080) | Error 0.0011(0.0043) Steps 1108(1101.72) | Grad Norm 1.2564(1.3603) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 126.9299, Epoch Time 1618.1525(1624.2284), Bit/dim 3.5056(best: 3.5058), Xent 2.4798, Loss 4.7455, Error 0.2849(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20030 | Time 27.2892(26.8697) | Bit/dim 3.4966(3.4971) | Xent 0.0093(0.0165) | Loss 3.5012(3.5054) | Error 0.0011(0.0043) Steps 1096(1102.33) | Grad Norm 0.7890(1.3685) | Total Time 14.00(14.00)\n",
      "Iter 20040 | Time 26.6207(26.8440) | Bit/dim 3.5077(3.4989) | Xent 0.0177(0.0168) | Loss 3.5165(3.5073) | Error 0.0033(0.0046) Steps 1096(1101.46) | Grad Norm 1.2553(1.3659) | Total Time 14.00(14.00)\n",
      "Iter 20050 | Time 27.0829(26.7993) | Bit/dim 3.5140(3.4977) | Xent 0.0165(0.0162) | Loss 3.5223(3.5058) | Error 0.0056(0.0045) Steps 1096(1099.76) | Grad Norm 1.2780(1.3462) | Total Time 14.00(14.00)\n",
      "Iter 20060 | Time 26.5762(26.7460) | Bit/dim 3.4978(3.5002) | Xent 0.0109(0.0161) | Loss 3.5033(3.5083) | Error 0.0033(0.0044) Steps 1102(1100.20) | Grad Norm 1.0998(1.3528) | Total Time 14.00(14.00)\n",
      "Iter 20070 | Time 26.9485(26.8028) | Bit/dim 3.4938(3.5005) | Xent 0.0118(0.0163) | Loss 3.4997(3.5086) | Error 0.0011(0.0044) Steps 1114(1100.19) | Grad Norm 1.0078(1.3676) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 127.5471, Epoch Time 1620.4092(1624.1138), Bit/dim 3.5061(best: 3.5056), Xent 2.4697, Loss 4.7410, Error 0.2852(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20080 | Time 26.6301(26.7296) | Bit/dim 3.5088(3.5019) | Xent 0.0135(0.0164) | Loss 3.5156(3.5101) | Error 0.0022(0.0044) Steps 1090(1099.30) | Grad Norm 1.1550(1.3889) | Total Time 14.00(14.00)\n",
      "Iter 20090 | Time 27.0715(26.7486) | Bit/dim 3.4952(3.5003) | Xent 0.0126(0.0169) | Loss 3.5015(3.5088) | Error 0.0033(0.0047) Steps 1084(1098.38) | Grad Norm 1.0222(1.4095) | Total Time 14.00(14.00)\n",
      "Iter 20100 | Time 26.1308(26.7236) | Bit/dim 3.4876(3.4989) | Xent 0.0213(0.0169) | Loss 3.4982(3.5073) | Error 0.0056(0.0046) Steps 1084(1098.12) | Grad Norm 1.5348(1.3800) | Total Time 14.00(14.00)\n",
      "Iter 20110 | Time 27.2215(26.7124) | Bit/dim 3.4845(3.4974) | Xent 0.0133(0.0168) | Loss 3.4912(3.5058) | Error 0.0033(0.0047) Steps 1102(1097.29) | Grad Norm 0.9951(1.3442) | Total Time 14.00(14.00)\n",
      "Iter 20120 | Time 26.8885(26.7553) | Bit/dim 3.5002(3.5008) | Xent 0.0170(0.0175) | Loss 3.5087(3.5095) | Error 0.0044(0.0051) Steps 1090(1098.00) | Grad Norm 1.9810(1.5062) | Total Time 14.00(14.00)\n",
      "Iter 20130 | Time 26.4176(26.7450) | Bit/dim 3.4975(3.5009) | Xent 0.0209(0.0177) | Loss 3.5079(3.5097) | Error 0.0056(0.0051) Steps 1084(1098.41) | Grad Norm 1.0981(1.5903) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 127.1451, Epoch Time 1615.6689(1623.8605), Bit/dim 3.5071(best: 3.5056), Xent 2.4780, Loss 4.7461, Error 0.2868(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20140 | Time 26.7137(26.7371) | Bit/dim 3.5120(3.5011) | Xent 0.0226(0.0173) | Loss 3.5233(3.5097) | Error 0.0089(0.0050) Steps 1090(1098.57) | Grad Norm 1.6783(1.6224) | Total Time 14.00(14.00)\n",
      "Iter 20150 | Time 27.0896(26.7766) | Bit/dim 3.5549(3.5034) | Xent 0.0079(0.0175) | Loss 3.5589(3.5122) | Error 0.0000(0.0048) Steps 1108(1098.90) | Grad Norm 0.9781(1.5534) | Total Time 14.00(14.00)\n",
      "Iter 20160 | Time 26.6795(26.7503) | Bit/dim 3.5023(3.5042) | Xent 0.0184(0.0175) | Loss 3.5115(3.5130) | Error 0.0056(0.0049) Steps 1114(1099.11) | Grad Norm 1.5719(1.5322) | Total Time 14.00(14.00)\n",
      "Iter 20170 | Time 25.7561(26.7396) | Bit/dim 3.4596(3.4969) | Xent 0.0176(0.0176) | Loss 3.4684(3.5057) | Error 0.0078(0.0048) Steps 1084(1099.24) | Grad Norm 1.5151(1.5167) | Total Time 14.00(14.00)\n",
      "Iter 20180 | Time 27.1694(26.6948) | Bit/dim 3.5272(3.4978) | Xent 0.0178(0.0175) | Loss 3.5360(3.5065) | Error 0.0044(0.0048) Steps 1084(1098.94) | Grad Norm 1.3650(1.4513) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 126.9859, Epoch Time 1614.4366(1623.5777), Bit/dim 3.5055(best: 3.5056), Xent 2.4811, Loss 4.7460, Error 0.2870(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20190 | Time 26.4826(26.6738) | Bit/dim 3.5124(3.5019) | Xent 0.0113(0.0173) | Loss 3.5181(3.5105) | Error 0.0022(0.0047) Steps 1108(1099.71) | Grad Norm 1.0371(1.4121) | Total Time 14.00(14.00)\n",
      "Iter 20200 | Time 26.8113(26.6174) | Bit/dim 3.5159(3.4995) | Xent 0.0159(0.0174) | Loss 3.5239(3.5082) | Error 0.0044(0.0046) Steps 1096(1099.07) | Grad Norm 1.2697(1.3870) | Total Time 14.00(14.00)\n",
      "Iter 20210 | Time 27.0876(26.5733) | Bit/dim 3.4637(3.4980) | Xent 0.0197(0.0172) | Loss 3.4736(3.5066) | Error 0.0067(0.0047) Steps 1102(1099.18) | Grad Norm 1.8473(1.4100) | Total Time 14.00(14.00)\n",
      "Iter 20220 | Time 26.4457(26.5562) | Bit/dim 3.5107(3.4970) | Xent 0.0190(0.0175) | Loss 3.5202(3.5057) | Error 0.0056(0.0047) Steps 1096(1100.22) | Grad Norm 1.9277(1.5385) | Total Time 14.00(14.00)\n",
      "Iter 20230 | Time 26.3410(26.5460) | Bit/dim 3.4894(3.4984) | Xent 0.0146(0.0176) | Loss 3.4967(3.5072) | Error 0.0022(0.0046) Steps 1090(1099.87) | Grad Norm 1.3266(1.5560) | Total Time 14.00(14.00)\n",
      "Iter 20240 | Time 26.7031(26.6108) | Bit/dim 3.5174(3.5017) | Xent 0.0125(0.0179) | Loss 3.5236(3.5107) | Error 0.0022(0.0048) Steps 1114(1100.32) | Grad Norm 1.7620(1.6199) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 127.0022, Epoch Time 1604.2841(1622.9989), Bit/dim 3.5064(best: 3.5055), Xent 2.4272, Loss 4.7200, Error 0.2839(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20250 | Time 26.4484(26.6227) | Bit/dim 3.4924(3.5015) | Xent 0.0198(0.0172) | Loss 3.5023(3.5101) | Error 0.0056(0.0046) Steps 1096(1100.38) | Grad Norm 1.1450(1.5371) | Total Time 14.00(14.00)\n",
      "Iter 20260 | Time 26.9780(26.6299) | Bit/dim 3.5036(3.4995) | Xent 0.0166(0.0172) | Loss 3.5119(3.5081) | Error 0.0033(0.0043) Steps 1108(1099.40) | Grad Norm 1.3320(1.4553) | Total Time 14.00(14.00)\n",
      "Iter 20270 | Time 27.0841(26.5925) | Bit/dim 3.4934(3.4975) | Xent 0.0169(0.0173) | Loss 3.5019(3.5061) | Error 0.0078(0.0048) Steps 1090(1099.19) | Grad Norm 2.0132(1.4164) | Total Time 14.00(14.00)\n",
      "Iter 20280 | Time 26.6965(26.6374) | Bit/dim 3.5124(3.4966) | Xent 0.0100(0.0171) | Loss 3.5174(3.5052) | Error 0.0011(0.0047) Steps 1120(1098.88) | Grad Norm 1.2866(1.3886) | Total Time 14.00(14.00)\n",
      "Iter 20290 | Time 26.0723(26.6573) | Bit/dim 3.4742(3.4971) | Xent 0.0135(0.0163) | Loss 3.4809(3.5052) | Error 0.0011(0.0042) Steps 1096(1098.48) | Grad Norm 1.0916(1.3771) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 127.7244, Epoch Time 1610.8520(1622.6345), Bit/dim 3.5054(best: 3.5055), Xent 2.4751, Loss 4.7430, Error 0.2847(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20300 | Time 26.6888(26.5978) | Bit/dim 3.4728(3.5006) | Xent 0.0171(0.0174) | Loss 3.4813(3.5093) | Error 0.0044(0.0049) Steps 1090(1097.71) | Grad Norm 1.1339(1.4764) | Total Time 14.00(14.00)\n",
      "Iter 20310 | Time 26.8223(26.6298) | Bit/dim 3.5214(3.5042) | Xent 0.0166(0.0172) | Loss 3.5297(3.5128) | Error 0.0022(0.0047) Steps 1114(1099.28) | Grad Norm 1.1008(1.4294) | Total Time 14.00(14.00)\n",
      "Iter 20320 | Time 26.9485(26.6394) | Bit/dim 3.4751(3.5010) | Xent 0.0171(0.0172) | Loss 3.4837(3.5096) | Error 0.0044(0.0047) Steps 1090(1099.10) | Grad Norm 1.8561(1.4385) | Total Time 14.00(14.00)\n",
      "Iter 20330 | Time 26.1115(26.5784) | Bit/dim 3.5110(3.5014) | Xent 0.0165(0.0174) | Loss 3.5192(3.5100) | Error 0.0022(0.0047) Steps 1090(1099.20) | Grad Norm 2.1942(1.5263) | Total Time 14.00(14.00)\n",
      "Iter 20340 | Time 26.3806(26.6007) | Bit/dim 3.4949(3.5010) | Xent 0.0131(0.0175) | Loss 3.5015(3.5098) | Error 0.0044(0.0047) Steps 1102(1099.09) | Grad Norm 1.1890(1.5826) | Total Time 14.00(14.00)\n",
      "Iter 20350 | Time 26.8101(26.5901) | Bit/dim 3.5023(3.4993) | Xent 0.0196(0.0170) | Loss 3.5121(3.5078) | Error 0.0089(0.0046) Steps 1108(1100.17) | Grad Norm 2.0378(1.5578) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 128.1604, Epoch Time 1608.0517(1622.1970), Bit/dim 3.5055(best: 3.5054), Xent 2.4889, Loss 4.7500, Error 0.2826(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20360 | Time 24.9996(26.6276) | Bit/dim 3.4608(3.5003) | Xent 0.0301(0.0174) | Loss 3.4758(3.5090) | Error 0.0089(0.0049) Steps 1096(1100.00) | Grad Norm 2.2804(1.5708) | Total Time 14.00(14.00)\n",
      "Iter 20370 | Time 26.7186(26.7062) | Bit/dim 3.5215(3.4981) | Xent 0.0188(0.0171) | Loss 3.5309(3.5067) | Error 0.0044(0.0049) Steps 1096(1098.97) | Grad Norm 2.0656(1.5862) | Total Time 14.00(14.00)\n",
      "Iter 20380 | Time 26.3446(26.6406) | Bit/dim 3.5080(3.5009) | Xent 0.0162(0.0176) | Loss 3.5161(3.5097) | Error 0.0044(0.0049) Steps 1108(1098.95) | Grad Norm 1.5166(1.5930) | Total Time 14.00(14.00)\n",
      "Iter 20390 | Time 27.1247(26.6236) | Bit/dim 3.5101(3.5001) | Xent 0.0242(0.0180) | Loss 3.5222(3.5092) | Error 0.0122(0.0052) Steps 1102(1098.46) | Grad Norm 2.0037(1.6497) | Total Time 14.00(14.00)\n",
      "Iter 20400 | Time 26.3874(26.6363) | Bit/dim 3.5096(3.5004) | Xent 0.0170(0.0175) | Loss 3.5181(3.5091) | Error 0.0078(0.0050) Steps 1120(1099.29) | Grad Norm 1.5343(1.6384) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 128.0715, Epoch Time 1612.4327(1621.9041), Bit/dim 3.5056(best: 3.5054), Xent 2.4724, Loss 4.7418, Error 0.2855(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20410 | Time 27.4190(26.6834) | Bit/dim 3.5093(3.5003) | Xent 0.0162(0.0173) | Loss 3.5173(3.5090) | Error 0.0056(0.0051) Steps 1102(1099.51) | Grad Norm 1.8432(1.6220) | Total Time 14.00(14.00)\n",
      "Iter 20420 | Time 26.9100(26.6975) | Bit/dim 3.5244(3.4993) | Xent 0.0146(0.0176) | Loss 3.5318(3.5081) | Error 0.0044(0.0050) Steps 1102(1099.55) | Grad Norm 1.1309(1.6489) | Total Time 14.00(14.00)\n",
      "Iter 20430 | Time 26.7915(26.6734) | Bit/dim 3.4883(3.4996) | Xent 0.0176(0.0178) | Loss 3.4971(3.5085) | Error 0.0022(0.0049) Steps 1102(1099.69) | Grad Norm 1.4597(1.6352) | Total Time 14.00(14.00)\n",
      "Iter 20440 | Time 26.2876(26.6146) | Bit/dim 3.4862(3.4977) | Xent 0.0103(0.0176) | Loss 3.4913(3.5065) | Error 0.0022(0.0049) Steps 1108(1100.13) | Grad Norm 0.8413(1.5249) | Total Time 14.00(14.00)\n",
      "Iter 20450 | Time 26.1494(26.5895) | Bit/dim 3.5127(3.4996) | Xent 0.0151(0.0172) | Loss 3.5202(3.5082) | Error 0.0067(0.0050) Steps 1096(1099.96) | Grad Norm 1.1989(1.5040) | Total Time 14.00(14.00)\n",
      "Iter 20460 | Time 26.8340(26.7119) | Bit/dim 3.4645(3.5004) | Xent 0.0283(0.0170) | Loss 3.4786(3.5089) | Error 0.0100(0.0051) Steps 1096(1100.14) | Grad Norm 1.8588(1.4694) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 128.1073, Epoch Time 1614.6636(1621.6869), Bit/dim 3.5039(best: 3.5054), Xent 2.4833, Loss 4.7456, Error 0.2857(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20470 | Time 26.2524(26.6121) | Bit/dim 3.5286(3.4987) | Xent 0.0117(0.0165) | Loss 3.5344(3.5069) | Error 0.0044(0.0050) Steps 1102(1099.81) | Grad Norm 1.3346(1.4234) | Total Time 14.00(14.00)\n",
      "Iter 20480 | Time 26.6907(26.6241) | Bit/dim 3.5207(3.5008) | Xent 0.0250(0.0170) | Loss 3.5332(3.5093) | Error 0.0122(0.0052) Steps 1090(1099.78) | Grad Norm 1.7442(1.4314) | Total Time 14.00(14.00)\n",
      "Iter 20490 | Time 26.4403(26.6565) | Bit/dim 3.5081(3.5015) | Xent 0.0311(0.0180) | Loss 3.5237(3.5105) | Error 0.0100(0.0053) Steps 1102(1099.74) | Grad Norm 2.4897(1.4740) | Total Time 14.00(14.00)\n",
      "Iter 20500 | Time 26.5915(26.6903) | Bit/dim 3.5105(3.5000) | Xent 0.0196(0.0178) | Loss 3.5203(3.5089) | Error 0.0044(0.0053) Steps 1108(1100.39) | Grad Norm 1.2767(1.5048) | Total Time 14.00(14.00)\n",
      "Iter 20510 | Time 25.7639(26.6828) | Bit/dim 3.4735(3.4977) | Xent 0.0144(0.0179) | Loss 3.4807(3.5067) | Error 0.0033(0.0053) Steps 1102(1099.50) | Grad Norm 1.0982(1.5103) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 128.6430, Epoch Time 1610.9932(1621.3661), Bit/dim 3.5048(best: 3.5039), Xent 2.5094, Loss 4.7595, Error 0.2856(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20520 | Time 27.0848(26.6739) | Bit/dim 3.4995(3.4974) | Xent 0.0150(0.0176) | Loss 3.5070(3.5062) | Error 0.0078(0.0052) Steps 1102(1099.51) | Grad Norm 1.7706(1.4859) | Total Time 14.00(14.00)\n",
      "Iter 20530 | Time 26.9046(26.7307) | Bit/dim 3.4800(3.4966) | Xent 0.0124(0.0168) | Loss 3.4862(3.5049) | Error 0.0033(0.0049) Steps 1096(1099.15) | Grad Norm 1.3924(1.4950) | Total Time 14.00(14.00)\n",
      "Iter 20540 | Time 27.1300(26.8062) | Bit/dim 3.4898(3.4983) | Xent 0.0123(0.0166) | Loss 3.4960(3.5066) | Error 0.0033(0.0048) Steps 1102(1098.47) | Grad Norm 0.9151(1.4558) | Total Time 14.00(14.00)\n",
      "Iter 20550 | Time 26.3204(26.7175) | Bit/dim 3.5152(3.4991) | Xent 0.0171(0.0168) | Loss 3.5238(3.5075) | Error 0.0044(0.0050) Steps 1102(1098.27) | Grad Norm 1.4057(1.4165) | Total Time 14.00(14.00)\n",
      "Iter 20560 | Time 26.7608(26.7244) | Bit/dim 3.4695(3.5007) | Xent 0.0158(0.0166) | Loss 3.4774(3.5090) | Error 0.0056(0.0050) Steps 1096(1098.26) | Grad Norm 1.1835(1.3409) | Total Time 14.00(14.00)\n",
      "Iter 20570 | Time 26.4394(26.6673) | Bit/dim 3.4739(3.5006) | Xent 0.0253(0.0171) | Loss 3.4866(3.5092) | Error 0.0100(0.0052) Steps 1102(1098.75) | Grad Norm 1.8692(1.3802) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 128.2396, Epoch Time 1616.2488(1621.2126), Bit/dim 3.5050(best: 3.5039), Xent 2.4602, Loss 4.7351, Error 0.2844(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20580 | Time 27.3282(26.6845) | Bit/dim 3.5069(3.4980) | Xent 0.0136(0.0167) | Loss 3.5137(3.5064) | Error 0.0022(0.0050) Steps 1120(1099.65) | Grad Norm 1.0356(1.3597) | Total Time 14.00(14.00)\n",
      "Iter 20590 | Time 26.7645(26.7507) | Bit/dim 3.4833(3.4991) | Xent 0.0154(0.0168) | Loss 3.4910(3.5075) | Error 0.0022(0.0051) Steps 1102(1100.51) | Grad Norm 1.1164(1.3788) | Total Time 14.00(14.00)\n",
      "Iter 20600 | Time 26.5027(26.7087) | Bit/dim 3.4946(3.5007) | Xent 0.0208(0.0171) | Loss 3.5050(3.5093) | Error 0.0056(0.0051) Steps 1102(1099.35) | Grad Norm 1.5029(1.4271) | Total Time 14.00(14.00)\n",
      "Iter 20610 | Time 26.8034(26.7021) | Bit/dim 3.5136(3.5013) | Xent 0.0212(0.0173) | Loss 3.5243(3.5099) | Error 0.0078(0.0052) Steps 1096(1099.66) | Grad Norm 2.0404(1.4557) | Total Time 14.00(14.00)\n",
      "Iter 20620 | Time 26.1714(26.6718) | Bit/dim 3.5081(3.5013) | Xent 0.0110(0.0173) | Loss 3.5136(3.5099) | Error 0.0022(0.0052) Steps 1102(1100.30) | Grad Norm 1.6778(1.4862) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 129.2572, Epoch Time 1615.9837(1621.0557), Bit/dim 3.5041(best: 3.5039), Xent 2.4862, Loss 4.7472, Error 0.2871(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20630 | Time 26.6866(26.6957) | Bit/dim 3.5242(3.4999) | Xent 0.0168(0.0168) | Loss 3.5326(3.5083) | Error 0.0044(0.0048) Steps 1102(1101.71) | Grad Norm 1.6018(1.5047) | Total Time 14.00(14.00)\n",
      "Iter 20640 | Time 26.4445(26.7015) | Bit/dim 3.4918(3.4989) | Xent 0.0197(0.0172) | Loss 3.5016(3.5075) | Error 0.0067(0.0048) Steps 1108(1102.41) | Grad Norm 1.4095(1.5274) | Total Time 14.00(14.00)\n",
      "Iter 20650 | Time 26.5783(26.7149) | Bit/dim 3.4952(3.5006) | Xent 0.0169(0.0173) | Loss 3.5036(3.5092) | Error 0.0067(0.0050) Steps 1102(1103.59) | Grad Norm 2.0373(1.5711) | Total Time 14.00(14.00)\n",
      "Iter 20660 | Time 27.2878(26.7359) | Bit/dim 3.5074(3.4982) | Xent 0.0213(0.0171) | Loss 3.5181(3.5068) | Error 0.0056(0.0050) Steps 1090(1102.01) | Grad Norm 2.1546(1.5625) | Total Time 14.00(14.00)\n",
      "Iter 20670 | Time 27.4480(26.7733) | Bit/dim 3.5122(3.5002) | Xent 0.0175(0.0170) | Loss 3.5210(3.5087) | Error 0.0056(0.0050) Steps 1120(1102.55) | Grad Norm 1.3804(1.4973) | Total Time 14.00(14.00)\n",
      "Iter 20680 | Time 27.5196(26.8112) | Bit/dim 3.5108(3.5003) | Xent 0.0172(0.0170) | Loss 3.5194(3.5088) | Error 0.0056(0.0050) Steps 1120(1103.14) | Grad Norm 1.6619(1.4450) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 128.6894, Epoch Time 1620.7997(1621.0480), Bit/dim 3.5053(best: 3.5039), Xent 2.5212, Loss 4.7659, Error 0.2838(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20690 | Time 27.5208(26.8546) | Bit/dim 3.5437(3.5004) | Xent 0.0160(0.0165) | Loss 3.5517(3.5086) | Error 0.0067(0.0049) Steps 1102(1101.56) | Grad Norm 1.8283(1.4083) | Total Time 14.00(14.00)\n",
      "Iter 20700 | Time 26.7279(26.8217) | Bit/dim 3.4918(3.4982) | Xent 0.0142(0.0171) | Loss 3.4989(3.5068) | Error 0.0044(0.0051) Steps 1096(1100.72) | Grad Norm 1.0382(1.4442) | Total Time 14.00(14.00)\n",
      "Iter 20710 | Time 26.6800(26.8287) | Bit/dim 3.5034(3.4991) | Xent 0.0203(0.0167) | Loss 3.5135(3.5075) | Error 0.0056(0.0050) Steps 1108(1101.71) | Grad Norm 1.4929(1.4326) | Total Time 14.00(14.00)\n",
      "Iter 20720 | Time 26.4871(26.7743) | Bit/dim 3.4607(3.4988) | Xent 0.0173(0.0173) | Loss 3.4693(3.5075) | Error 0.0056(0.0053) Steps 1108(1101.32) | Grad Norm 1.8633(1.4498) | Total Time 14.00(14.00)\n",
      "Iter 20730 | Time 27.6719(26.7966) | Bit/dim 3.5129(3.4992) | Xent 0.0162(0.0172) | Loss 3.5210(3.5078) | Error 0.0011(0.0051) Steps 1090(1099.86) | Grad Norm 1.1546(1.4043) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 128.1243, Epoch Time 1618.8855(1620.9831), Bit/dim 3.5035(best: 3.5039), Xent 2.5053, Loss 4.7562, Error 0.2866(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20740 | Time 26.6989(26.7557) | Bit/dim 3.4940(3.4997) | Xent 0.0171(0.0174) | Loss 3.5025(3.5083) | Error 0.0044(0.0050) Steps 1096(1099.56) | Grad Norm 1.8943(1.4450) | Total Time 14.00(14.00)\n",
      "Iter 20750 | Time 26.5199(26.6575) | Bit/dim 3.4643(3.4982) | Xent 0.0173(0.0172) | Loss 3.4729(3.5068) | Error 0.0056(0.0052) Steps 1114(1100.48) | Grad Norm 1.2509(1.4430) | Total Time 14.00(14.00)\n",
      "Iter 20760 | Time 26.9753(26.7182) | Bit/dim 3.5065(3.4995) | Xent 0.0090(0.0171) | Loss 3.5110(3.5081) | Error 0.0033(0.0050) Steps 1108(1100.50) | Grad Norm 0.9304(1.4365) | Total Time 14.00(14.00)\n",
      "Iter 20770 | Time 26.0385(26.6546) | Bit/dim 3.5088(3.4998) | Xent 0.0156(0.0169) | Loss 3.5166(3.5083) | Error 0.0044(0.0049) Steps 1096(1101.53) | Grad Norm 1.4278(1.4253) | Total Time 14.00(14.00)\n",
      "Iter 20780 | Time 26.3932(26.6693) | Bit/dim 3.5059(3.4981) | Xent 0.0117(0.0168) | Loss 3.5117(3.5065) | Error 0.0044(0.0048) Steps 1108(1102.32) | Grad Norm 0.9436(1.3893) | Total Time 14.00(14.00)\n",
      "Iter 20790 | Time 26.3630(26.6277) | Bit/dim 3.4758(3.4995) | Xent 0.0313(0.0169) | Loss 3.4915(3.5080) | Error 0.0122(0.0047) Steps 1114(1100.67) | Grad Norm 2.3975(1.3866) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 128.2939, Epoch Time 1609.6469(1620.6431), Bit/dim 3.5039(best: 3.5035), Xent 2.5089, Loss 4.7583, Error 0.2865(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20800 | Time 26.9839(26.6193) | Bit/dim 3.5089(3.5020) | Xent 0.0178(0.0169) | Loss 3.5178(3.5105) | Error 0.0067(0.0046) Steps 1108(1101.12) | Grad Norm 1.8298(1.3867) | Total Time 14.00(14.00)\n",
      "Iter 20810 | Time 26.4507(26.5945) | Bit/dim 3.5009(3.5014) | Xent 0.0117(0.0167) | Loss 3.5068(3.5098) | Error 0.0011(0.0046) Steps 1096(1100.91) | Grad Norm 1.2429(1.4260) | Total Time 14.00(14.00)\n",
      "Iter 20820 | Time 27.4395(26.6259) | Bit/dim 3.5074(3.5023) | Xent 0.0161(0.0166) | Loss 3.5155(3.5106) | Error 0.0044(0.0046) Steps 1090(1099.66) | Grad Norm 1.6304(1.4133) | Total Time 14.00(14.00)\n",
      "Iter 20830 | Time 26.6765(26.6833) | Bit/dim 3.5272(3.4990) | Xent 0.0146(0.0169) | Loss 3.5345(3.5075) | Error 0.0067(0.0049) Steps 1120(1101.83) | Grad Norm 1.5991(1.5098) | Total Time 14.00(14.00)\n",
      "Iter 20840 | Time 26.2773(26.6967) | Bit/dim 3.4908(3.4975) | Xent 0.0113(0.0165) | Loss 3.4965(3.5058) | Error 0.0011(0.0047) Steps 1090(1100.97) | Grad Norm 0.9140(1.4881) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 127.3530, Epoch Time 1612.5104(1620.3991), Bit/dim 3.5027(best: 3.5035), Xent 2.5038, Loss 4.7546, Error 0.2860(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20850 | Time 26.8857(26.7198) | Bit/dim 3.4837(3.4985) | Xent 0.0167(0.0163) | Loss 3.4921(3.5066) | Error 0.0044(0.0045) Steps 1096(1100.64) | Grad Norm 1.4122(1.4015) | Total Time 14.00(14.00)\n",
      "Iter 20860 | Time 26.3997(26.7038) | Bit/dim 3.5075(3.4987) | Xent 0.0108(0.0170) | Loss 3.5130(3.5072) | Error 0.0011(0.0049) Steps 1090(1099.59) | Grad Norm 1.0578(1.3942) | Total Time 14.00(14.00)\n",
      "Iter 20870 | Time 26.4235(26.6342) | Bit/dim 3.4895(3.4991) | Xent 0.0120(0.0162) | Loss 3.4955(3.5072) | Error 0.0033(0.0044) Steps 1114(1102.10) | Grad Norm 1.3191(1.3760) | Total Time 14.00(14.00)\n",
      "Iter 20880 | Time 26.4900(26.6314) | Bit/dim 3.4702(3.4990) | Xent 0.0126(0.0156) | Loss 3.4765(3.5068) | Error 0.0033(0.0042) Steps 1108(1101.85) | Grad Norm 0.7963(1.3120) | Total Time 14.00(14.00)\n",
      "Iter 20890 | Time 26.5062(26.6428) | Bit/dim 3.4766(3.4978) | Xent 0.0182(0.0154) | Loss 3.4858(3.5055) | Error 0.0067(0.0042) Steps 1090(1101.44) | Grad Norm 1.4386(1.3117) | Total Time 14.00(14.00)\n",
      "Iter 20900 | Time 26.7129(26.6585) | Bit/dim 3.5140(3.4973) | Xent 0.0136(0.0159) | Loss 3.5209(3.5052) | Error 0.0044(0.0044) Steps 1108(1103.17) | Grad Norm 1.0537(1.3229) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 128.6675, Epoch Time 1611.8407(1620.1423), Bit/dim 3.5029(best: 3.5027), Xent 2.5470, Loss 4.7763, Error 0.2861(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20910 | Time 26.4277(26.6147) | Bit/dim 3.5039(3.5001) | Xent 0.0201(0.0160) | Loss 3.5139(3.5081) | Error 0.0056(0.0045) Steps 1108(1102.92) | Grad Norm 1.6259(1.3190) | Total Time 14.00(14.00)\n",
      "Iter 20920 | Time 27.4376(26.6338) | Bit/dim 3.4766(3.4950) | Xent 0.0217(0.0165) | Loss 3.4875(3.5033) | Error 0.0056(0.0045) Steps 1102(1103.41) | Grad Norm 1.7331(1.3854) | Total Time 14.00(14.00)\n",
      "Iter 20930 | Time 26.8563(26.6737) | Bit/dim 3.4881(3.4973) | Xent 0.0197(0.0168) | Loss 3.4979(3.5057) | Error 0.0078(0.0049) Steps 1114(1104.43) | Grad Norm 1.4074(1.4132) | Total Time 14.00(14.00)\n",
      "Iter 20940 | Time 27.0478(26.7248) | Bit/dim 3.5173(3.4980) | Xent 0.0171(0.0173) | Loss 3.5258(3.5066) | Error 0.0044(0.0050) Steps 1096(1104.59) | Grad Norm 1.3129(1.4073) | Total Time 14.00(14.00)\n",
      "Iter 20950 | Time 26.4650(26.7416) | Bit/dim 3.4456(3.4992) | Xent 0.0132(0.0170) | Loss 3.4522(3.5077) | Error 0.0044(0.0048) Steps 1108(1104.07) | Grad Norm 1.2629(1.3820) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 129.3403, Epoch Time 1617.5974(1620.0660), Bit/dim 3.5038(best: 3.5027), Xent 2.5369, Loss 4.7722, Error 0.2885(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20960 | Time 26.5738(26.7820) | Bit/dim 3.5430(3.4982) | Xent 0.0178(0.0168) | Loss 3.5519(3.5066) | Error 0.0067(0.0049) Steps 1108(1104.91) | Grad Norm 1.6073(1.3982) | Total Time 14.00(14.00)\n",
      "Iter 20970 | Time 26.1175(26.7987) | Bit/dim 3.4677(3.4966) | Xent 0.0155(0.0164) | Loss 3.4754(3.5048) | Error 0.0044(0.0048) Steps 1090(1103.94) | Grad Norm 1.6920(1.4068) | Total Time 14.00(14.00)\n",
      "Iter 20980 | Time 26.4502(26.7780) | Bit/dim 3.4886(3.4969) | Xent 0.0161(0.0170) | Loss 3.4966(3.5054) | Error 0.0067(0.0050) Steps 1090(1102.78) | Grad Norm 2.5447(1.4944) | Total Time 14.00(14.00)\n",
      "Iter 20990 | Time 26.7820(26.8075) | Bit/dim 3.5154(3.4993) | Xent 0.0218(0.0180) | Loss 3.5263(3.5083) | Error 0.0078(0.0054) Steps 1096(1102.65) | Grad Norm 2.1567(1.6796) | Total Time 14.00(14.00)\n",
      "Iter 21000 | Time 27.3583(26.8034) | Bit/dim 3.4967(3.4982) | Xent 0.0131(0.0189) | Loss 3.5032(3.5077) | Error 0.0056(0.0056) Steps 1090(1102.47) | Grad Norm 1.3195(1.7609) | Total Time 14.00(14.00)\n",
      "Iter 21010 | Time 26.9024(26.7750) | Bit/dim 3.4700(3.4999) | Xent 0.0160(0.0180) | Loss 3.4780(3.5088) | Error 0.0056(0.0053) Steps 1120(1103.35) | Grad Norm 1.8036(1.7658) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 129.2592, Epoch Time 1620.7293(1620.0859), Bit/dim 3.5036(best: 3.5027), Xent 2.5132, Loss 4.7602, Error 0.2874(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21020 | Time 26.1969(26.7670) | Bit/dim 3.5152(3.5006) | Xent 0.0143(0.0181) | Loss 3.5224(3.5096) | Error 0.0022(0.0052) Steps 1096(1103.64) | Grad Norm 1.5098(1.7223) | Total Time 14.00(14.00)\n",
      "Iter 21030 | Time 27.0950(26.7782) | Bit/dim 3.5205(3.5005) | Xent 0.0146(0.0177) | Loss 3.5278(3.5094) | Error 0.0044(0.0051) Steps 1114(1103.24) | Grad Norm 2.1446(1.6728) | Total Time 14.00(14.00)\n",
      "Iter 21040 | Time 26.7451(26.8156) | Bit/dim 3.4849(3.5011) | Xent 0.0116(0.0177) | Loss 3.4907(3.5100) | Error 0.0022(0.0049) Steps 1096(1102.27) | Grad Norm 1.4850(1.6575) | Total Time 14.00(14.00)\n",
      "Iter 21050 | Time 26.5365(26.7448) | Bit/dim 3.4994(3.4985) | Xent 0.0137(0.0169) | Loss 3.5063(3.5069) | Error 0.0044(0.0046) Steps 1096(1103.11) | Grad Norm 1.0751(1.6234) | Total Time 14.00(14.00)\n",
      "Iter 21060 | Time 27.2907(26.8261) | Bit/dim 3.5143(3.4976) | Xent 0.0199(0.0166) | Loss 3.5242(3.5059) | Error 0.0056(0.0046) Steps 1108(1103.28) | Grad Norm 1.8340(1.5706) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 128.9124, Epoch Time 1623.5358(1620.1894), Bit/dim 3.5047(best: 3.5027), Xent 2.5273, Loss 4.7684, Error 0.2833(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21070 | Time 26.1645(26.8086) | Bit/dim 3.4749(3.4963) | Xent 0.0129(0.0170) | Loss 3.4813(3.5048) | Error 0.0033(0.0047) Steps 1096(1102.45) | Grad Norm 2.3810(1.6695) | Total Time 14.00(14.00)\n",
      "Iter 21080 | Time 26.4647(26.7499) | Bit/dim 3.4942(3.4976) | Xent 0.0185(0.0172) | Loss 3.5035(3.5062) | Error 0.0067(0.0049) Steps 1114(1103.21) | Grad Norm 1.0889(1.6063) | Total Time 14.00(14.00)\n",
      "Iter 21090 | Time 26.8773(26.7011) | Bit/dim 3.4876(3.4978) | Xent 0.0108(0.0168) | Loss 3.4930(3.5062) | Error 0.0022(0.0050) Steps 1102(1103.97) | Grad Norm 0.8340(1.5349) | Total Time 14.00(14.00)\n",
      "Iter 21100 | Time 26.6805(26.7002) | Bit/dim 3.4482(3.4974) | Xent 0.0188(0.0170) | Loss 3.4576(3.5059) | Error 0.0067(0.0050) Steps 1090(1103.46) | Grad Norm 1.7733(1.5260) | Total Time 14.00(14.00)\n",
      "Iter 21110 | Time 27.1736(26.6528) | Bit/dim 3.5012(3.4961) | Xent 0.0185(0.0168) | Loss 3.5104(3.5045) | Error 0.0056(0.0049) Steps 1096(1103.68) | Grad Norm 1.5247(1.4428) | Total Time 14.00(14.00)\n",
      "Iter 21120 | Time 27.5199(26.6898) | Bit/dim 3.4857(3.4970) | Xent 0.0180(0.0172) | Loss 3.4947(3.5056) | Error 0.0067(0.0049) Steps 1102(1103.80) | Grad Norm 1.3288(1.4063) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 129.1911, Epoch Time 1610.4806(1619.8981), Bit/dim 3.5038(best: 3.5027), Xent 2.5432, Loss 4.7755, Error 0.2876(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21130 | Time 26.9668(26.6912) | Bit/dim 3.5304(3.4983) | Xent 0.0148(0.0167) | Loss 3.5378(3.5066) | Error 0.0044(0.0048) Steps 1090(1103.83) | Grad Norm 1.2639(1.4032) | Total Time 14.00(14.00)\n",
      "Iter 21140 | Time 26.7499(26.6802) | Bit/dim 3.4986(3.4974) | Xent 0.0115(0.0162) | Loss 3.5043(3.5054) | Error 0.0033(0.0045) Steps 1108(1104.28) | Grad Norm 1.1431(1.3638) | Total Time 14.00(14.00)\n",
      "Iter 21150 | Time 26.0586(26.7027) | Bit/dim 3.5099(3.4973) | Xent 0.0196(0.0157) | Loss 3.5197(3.5052) | Error 0.0056(0.0042) Steps 1096(1104.10) | Grad Norm 1.6484(1.3185) | Total Time 14.00(14.00)\n",
      "Iter 21160 | Time 26.4584(26.6429) | Bit/dim 3.5211(3.4971) | Xent 0.0167(0.0155) | Loss 3.5294(3.5049) | Error 0.0033(0.0040) Steps 1126(1105.65) | Grad Norm 1.1290(1.2699) | Total Time 14.00(14.00)\n",
      "Iter 21170 | Time 26.2621(26.6149) | Bit/dim 3.5047(3.4969) | Xent 0.0168(0.0154) | Loss 3.5131(3.5046) | Error 0.0056(0.0041) Steps 1096(1105.50) | Grad Norm 0.9838(1.2317) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 129.1160, Epoch Time 1612.6446(1619.6805), Bit/dim 3.5027(best: 3.5027), Xent 2.5483, Loss 4.7769, Error 0.2842(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21180 | Time 27.0519(26.6648) | Bit/dim 3.5100(3.4965) | Xent 0.0156(0.0154) | Loss 3.5178(3.5042) | Error 0.0056(0.0040) Steps 1090(1104.61) | Grad Norm 1.5176(1.3110) | Total Time 14.00(14.00)\n",
      "Iter 21190 | Time 27.6125(26.7218) | Bit/dim 3.4900(3.4971) | Xent 0.0146(0.0155) | Loss 3.4973(3.5049) | Error 0.0044(0.0043) Steps 1108(1105.17) | Grad Norm 1.1579(1.3975) | Total Time 14.00(14.00)\n",
      "Iter 21200 | Time 26.3178(26.6808) | Bit/dim 3.5100(3.4969) | Xent 0.0162(0.0156) | Loss 3.5181(3.5047) | Error 0.0044(0.0043) Steps 1102(1104.36) | Grad Norm 1.1072(1.4048) | Total Time 14.00(14.00)\n",
      "Iter 21210 | Time 26.8452(26.6629) | Bit/dim 3.5373(3.4983) | Xent 0.0124(0.0157) | Loss 3.5435(3.5062) | Error 0.0022(0.0044) Steps 1108(1104.17) | Grad Norm 0.9414(1.3818) | Total Time 14.00(14.00)\n",
      "Iter 21220 | Time 26.6074(26.6529) | Bit/dim 3.5074(3.4999) | Xent 0.0197(0.0154) | Loss 3.5172(3.5076) | Error 0.0067(0.0043) Steps 1102(1105.21) | Grad Norm 1.5300(1.3316) | Total Time 14.00(14.00)\n",
      "Iter 21230 | Time 26.6815(26.5663) | Bit/dim 3.4884(3.4974) | Xent 0.0242(0.0164) | Loss 3.5005(3.5057) | Error 0.0089(0.0048) Steps 1096(1104.70) | Grad Norm 1.2557(1.4493) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 130.6351, Epoch Time 1612.9018(1619.4771), Bit/dim 3.5036(best: 3.5027), Xent 2.5650, Loss 4.7860, Error 0.2856(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21240 | Time 26.8412(26.5935) | Bit/dim 3.4625(3.4976) | Xent 0.0154(0.0166) | Loss 3.4702(3.5059) | Error 0.0044(0.0048) Steps 1096(1104.49) | Grad Norm 1.6619(1.4816) | Total Time 14.00(14.00)\n",
      "Iter 21250 | Time 25.9366(26.5467) | Bit/dim 3.4722(3.4984) | Xent 0.0112(0.0167) | Loss 3.4779(3.5068) | Error 0.0033(0.0049) Steps 1096(1103.04) | Grad Norm 0.9215(1.4918) | Total Time 14.00(14.00)\n",
      "Iter 21260 | Time 27.2044(26.5227) | Bit/dim 3.5030(3.4988) | Xent 0.0113(0.0162) | Loss 3.5087(3.5069) | Error 0.0033(0.0046) Steps 1108(1103.57) | Grad Norm 2.0796(1.5594) | Total Time 14.00(14.00)\n",
      "Iter 21270 | Time 26.8207(26.5698) | Bit/dim 3.5319(3.4973) | Xent 0.0198(0.0164) | Loss 3.5418(3.5055) | Error 0.0089(0.0048) Steps 1108(1103.38) | Grad Norm 2.8146(1.6086) | Total Time 14.00(14.00)\n",
      "Iter 21280 | Time 26.7794(26.6439) | Bit/dim 3.4998(3.4989) | Xent 0.0132(0.0167) | Loss 3.5064(3.5072) | Error 0.0044(0.0048) Steps 1090(1103.25) | Grad Norm 1.7754(1.6604) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 129.4540, Epoch Time 1611.0711(1619.2250), Bit/dim 3.5036(best: 3.5027), Xent 2.5717, Loss 4.7894, Error 0.2838(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21290 | Time 26.7792(26.6357) | Bit/dim 3.5081(3.4993) | Xent 0.0199(0.0168) | Loss 3.5181(3.5077) | Error 0.0078(0.0049) Steps 1096(1102.11) | Grad Norm 2.4883(1.6445) | Total Time 14.00(14.00)\n",
      "Iter 21300 | Time 26.9348(26.6882) | Bit/dim 3.5108(3.5000) | Xent 0.0185(0.0166) | Loss 3.5200(3.5083) | Error 0.0056(0.0050) Steps 1102(1103.21) | Grad Norm 1.9963(1.6145) | Total Time 14.00(14.00)\n",
      "Iter 21310 | Time 26.9079(26.7001) | Bit/dim 3.4991(3.4987) | Xent 0.0204(0.0172) | Loss 3.5093(3.5072) | Error 0.0067(0.0051) Steps 1096(1103.31) | Grad Norm 1.5429(1.6557) | Total Time 14.00(14.00)\n",
      "Iter 21320 | Time 26.5188(26.6374) | Bit/dim 3.4724(3.4972) | Xent 0.0149(0.0165) | Loss 3.4799(3.5054) | Error 0.0011(0.0045) Steps 1114(1104.87) | Grad Norm 1.1658(1.6048) | Total Time 14.00(14.00)\n",
      "Iter 21330 | Time 26.7256(26.6182) | Bit/dim 3.4779(3.4940) | Xent 0.0172(0.0163) | Loss 3.4865(3.5022) | Error 0.0067(0.0045) Steps 1114(1105.02) | Grad Norm 1.4263(1.5281) | Total Time 14.00(14.00)\n",
      "Iter 21340 | Time 27.1055(26.5996) | Bit/dim 3.5158(3.4975) | Xent 0.0166(0.0163) | Loss 3.5241(3.5057) | Error 0.0044(0.0047) Steps 1138(1106.06) | Grad Norm 1.1541(1.4775) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 130.7158, Epoch Time 1613.4235(1619.0509), Bit/dim 3.5042(best: 3.5027), Xent 2.5449, Loss 4.7767, Error 0.2855(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21350 | Time 26.7178(26.5476) | Bit/dim 3.4491(3.4970) | Xent 0.0168(0.0160) | Loss 3.4575(3.5050) | Error 0.0056(0.0045) Steps 1120(1104.87) | Grad Norm 1.7635(1.4685) | Total Time 14.00(14.00)\n",
      "Iter 21360 | Time 26.9866(26.5539) | Bit/dim 3.4865(3.4973) | Xent 0.0173(0.0163) | Loss 3.4952(3.5054) | Error 0.0033(0.0045) Steps 1108(1104.68) | Grad Norm 1.5334(1.4315) | Total Time 14.00(14.00)\n",
      "Iter 21370 | Time 26.5371(26.5333) | Bit/dim 3.5069(3.4955) | Xent 0.0256(0.0166) | Loss 3.5197(3.5038) | Error 0.0100(0.0050) Steps 1108(1104.18) | Grad Norm 2.1788(1.4397) | Total Time 14.00(14.00)\n",
      "Iter 21380 | Time 26.7375(26.6150) | Bit/dim 3.5294(3.4970) | Xent 0.0140(0.0174) | Loss 3.5364(3.5057) | Error 0.0056(0.0052) Steps 1120(1105.54) | Grad Norm 1.6874(1.4567) | Total Time 14.00(14.00)\n",
      "Iter 21390 | Time 26.0530(26.6078) | Bit/dim 3.5030(3.4999) | Xent 0.0154(0.0169) | Loss 3.5107(3.5084) | Error 0.0044(0.0049) Steps 1114(1106.41) | Grad Norm 1.2263(1.4321) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 129.4245, Epoch Time 1609.7155(1618.7709), Bit/dim 3.5004(best: 3.5027), Xent 2.5729, Loss 4.7868, Error 0.2874(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21400 | Time 27.4651(26.6385) | Bit/dim 3.5073(3.4980) | Xent 0.0149(0.0163) | Loss 3.5148(3.5062) | Error 0.0044(0.0046) Steps 1096(1105.21) | Grad Norm 1.2739(1.3757) | Total Time 14.00(14.00)\n",
      "Iter 21410 | Time 26.3096(26.6696) | Bit/dim 3.5064(3.4989) | Xent 0.0156(0.0156) | Loss 3.5142(3.5067) | Error 0.0056(0.0043) Steps 1102(1105.34) | Grad Norm 1.7339(1.3450) | Total Time 14.00(14.00)\n",
      "Iter 21420 | Time 26.5321(26.6211) | Bit/dim 3.4742(3.4970) | Xent 0.0152(0.0156) | Loss 3.4818(3.5048) | Error 0.0033(0.0044) Steps 1114(1104.76) | Grad Norm 0.9192(1.3461) | Total Time 14.00(14.00)\n",
      "Iter 21430 | Time 27.1304(26.6949) | Bit/dim 3.4789(3.4984) | Xent 0.0206(0.0160) | Loss 3.4892(3.5064) | Error 0.0078(0.0046) Steps 1114(1104.87) | Grad Norm 2.0424(1.4571) | Total Time 14.00(14.00)\n",
      "Iter 21440 | Time 26.5104(26.6630) | Bit/dim 3.4469(3.4967) | Xent 0.0147(0.0158) | Loss 3.4543(3.5046) | Error 0.0056(0.0048) Steps 1096(1103.96) | Grad Norm 1.6115(1.5566) | Total Time 14.00(14.00)\n",
      "Iter 21450 | Time 26.5985(26.5983) | Bit/dim 3.5328(3.4955) | Xent 0.0150(0.0156) | Loss 3.5403(3.5033) | Error 0.0022(0.0046) Steps 1102(1103.20) | Grad Norm 1.7513(1.5192) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 130.5409, Epoch Time 1613.4473(1618.6111), Bit/dim 3.5016(best: 3.5004), Xent 2.5858, Loss 4.7945, Error 0.2854(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21460 | Time 27.6368(26.7226) | Bit/dim 3.5118(3.4948) | Xent 0.0185(0.0154) | Loss 3.5211(3.5025) | Error 0.0056(0.0044) Steps 1102(1103.54) | Grad Norm 1.6008(1.4694) | Total Time 14.00(14.00)\n",
      "Iter 21470 | Time 26.9098(26.7861) | Bit/dim 3.4647(3.4943) | Xent 0.0184(0.0154) | Loss 3.4739(3.5021) | Error 0.0067(0.0044) Steps 1108(1104.25) | Grad Norm 1.9308(1.4673) | Total Time 14.00(14.00)\n",
      "Iter 21480 | Time 27.1169(26.7814) | Bit/dim 3.5024(3.4949) | Xent 0.0110(0.0155) | Loss 3.5078(3.5026) | Error 0.0022(0.0043) Steps 1096(1103.61) | Grad Norm 1.0247(1.4293) | Total Time 14.00(14.00)\n",
      "Iter 21490 | Time 26.5073(26.7437) | Bit/dim 3.4680(3.4955) | Xent 0.0130(0.0155) | Loss 3.4745(3.5032) | Error 0.0044(0.0043) Steps 1102(1103.53) | Grad Norm 1.0430(1.3978) | Total Time 14.00(14.00)\n",
      "Iter 21500 | Time 26.7509(26.7336) | Bit/dim 3.5215(3.4961) | Xent 0.0202(0.0160) | Loss 3.5316(3.5041) | Error 0.0067(0.0043) Steps 1114(1105.11) | Grad Norm 1.7879(1.3954) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 130.1077, Epoch Time 1620.6908(1618.6735), Bit/dim 3.5025(best: 3.5004), Xent 2.5433, Loss 4.7742, Error 0.2832(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21510 | Time 27.3479(26.6800) | Bit/dim 3.4876(3.4988) | Xent 0.0149(0.0160) | Loss 3.4951(3.5068) | Error 0.0022(0.0042) Steps 1102(1105.17) | Grad Norm 1.4441(1.3697) | Total Time 14.00(14.00)\n",
      "Iter 21520 | Time 26.5115(26.7078) | Bit/dim 3.4874(3.4973) | Xent 0.0209(0.0157) | Loss 3.4979(3.5052) | Error 0.0044(0.0041) Steps 1102(1104.78) | Grad Norm 1.7489(1.3703) | Total Time 14.00(14.00)\n",
      "Iter 21530 | Time 27.0649(26.7056) | Bit/dim 3.5232(3.4985) | Xent 0.0181(0.0155) | Loss 3.5323(3.5062) | Error 0.0067(0.0042) Steps 1102(1105.44) | Grad Norm 1.8960(1.3488) | Total Time 14.00(14.00)\n",
      "Iter 21540 | Time 26.6271(26.6955) | Bit/dim 3.5171(3.4983) | Xent 0.0130(0.0155) | Loss 3.5236(3.5061) | Error 0.0033(0.0040) Steps 1108(1105.52) | Grad Norm 1.3939(1.3905) | Total Time 14.00(14.00)\n",
      "Iter 21550 | Time 26.6610(26.7089) | Bit/dim 3.5021(3.4994) | Xent 0.0163(0.0160) | Loss 3.5102(3.5074) | Error 0.0044(0.0044) Steps 1102(1105.73) | Grad Norm 1.6745(1.5088) | Total Time 14.00(14.00)\n",
      "Iter 21560 | Time 26.6152(26.7413) | Bit/dim 3.4909(3.4956) | Xent 0.0119(0.0161) | Loss 3.4968(3.5037) | Error 0.0033(0.0046) Steps 1120(1106.70) | Grad Norm 1.3019(1.5739) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 130.6625, Epoch Time 1619.8024(1618.7074), Bit/dim 3.5022(best: 3.5004), Xent 2.5763, Loss 4.7903, Error 0.2845(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21570 | Time 26.7156(26.7604) | Bit/dim 3.5036(3.4975) | Xent 0.0104(0.0167) | Loss 3.5088(3.5058) | Error 0.0011(0.0048) Steps 1096(1105.71) | Grad Norm 0.9756(1.6233) | Total Time 14.00(14.00)\n",
      "Iter 21580 | Time 26.1817(26.6749) | Bit/dim 3.4918(3.4970) | Xent 0.0122(0.0164) | Loss 3.4979(3.5052) | Error 0.0033(0.0046) Steps 1102(1106.39) | Grad Norm 1.1808(1.5466) | Total Time 14.00(14.00)\n",
      "Iter 21590 | Time 27.2278(26.6778) | Bit/dim 3.5053(3.4965) | Xent 0.0201(0.0163) | Loss 3.5154(3.5046) | Error 0.0044(0.0045) Steps 1096(1106.16) | Grad Norm 1.5317(1.4804) | Total Time 14.00(14.00)\n",
      "Iter 21600 | Time 26.5944(26.6991) | Bit/dim 3.5194(3.4965) | Xent 0.0212(0.0169) | Loss 3.5300(3.5049) | Error 0.0078(0.0049) Steps 1102(1106.33) | Grad Norm 2.0006(1.5218) | Total Time 14.00(14.00)\n",
      "Iter 21610 | Time 27.3258(26.6818) | Bit/dim 3.4910(3.4946) | Xent 0.0211(0.0172) | Loss 3.5015(3.5032) | Error 0.0056(0.0049) Steps 1108(1105.07) | Grad Norm 2.1304(1.5355) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 130.4938, Epoch Time 1616.4046(1618.6383), Bit/dim 3.5039(best: 3.5004), Xent 2.5638, Loss 4.7858, Error 0.2852(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21620 | Time 27.1502(26.7599) | Bit/dim 3.4820(3.4967) | Xent 0.0137(0.0167) | Loss 3.4889(3.5050) | Error 0.0033(0.0047) Steps 1126(1106.83) | Grad Norm 0.9993(1.4763) | Total Time 14.00(14.00)\n",
      "Iter 21630 | Time 25.7878(26.6709) | Bit/dim 3.4766(3.4953) | Xent 0.0103(0.0157) | Loss 3.4817(3.5031) | Error 0.0033(0.0044) Steps 1108(1106.82) | Grad Norm 0.9232(1.3866) | Total Time 14.00(14.00)\n",
      "Iter 21640 | Time 27.2281(26.7831) | Bit/dim 3.4869(3.4997) | Xent 0.0185(0.0152) | Loss 3.4962(3.5073) | Error 0.0056(0.0041) Steps 1114(1106.34) | Grad Norm 1.1984(1.2963) | Total Time 14.00(14.00)\n",
      "Iter 21650 | Time 27.1224(26.7688) | Bit/dim 3.5362(3.5005) | Xent 0.0114(0.0156) | Loss 3.5418(3.5083) | Error 0.0011(0.0044) Steps 1102(1105.13) | Grad Norm 1.0361(1.3056) | Total Time 14.00(14.00)\n",
      "Iter 21660 | Time 26.1810(26.7123) | Bit/dim 3.4825(3.4967) | Xent 0.0293(0.0164) | Loss 3.4971(3.5049) | Error 0.0044(0.0045) Steps 1108(1104.94) | Grad Norm 1.7859(1.3383) | Total Time 14.00(14.00)\n",
      "Iter 21670 | Time 26.5341(26.7073) | Bit/dim 3.5158(3.4946) | Xent 0.0182(0.0164) | Loss 3.5249(3.5028) | Error 0.0067(0.0046) Steps 1108(1105.34) | Grad Norm 1.8658(1.3507) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 129.0027, Epoch Time 1617.0684(1618.5912), Bit/dim 3.5012(best: 3.5004), Xent 2.5932, Loss 4.7978, Error 0.2883(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21680 | Time 27.0151(26.7171) | Bit/dim 3.5208(3.4963) | Xent 0.0182(0.0166) | Loss 3.5299(3.5046) | Error 0.0056(0.0046) Steps 1102(1105.22) | Grad Norm 1.6623(1.4540) | Total Time 14.00(14.00)\n",
      "Iter 21690 | Time 27.0372(26.7658) | Bit/dim 3.4937(3.4957) | Xent 0.0131(0.0164) | Loss 3.5003(3.5039) | Error 0.0056(0.0046) Steps 1102(1105.31) | Grad Norm 1.4092(1.4876) | Total Time 14.00(14.00)\n",
      "Iter 21700 | Time 27.1802(26.8202) | Bit/dim 3.5400(3.4973) | Xent 0.0177(0.0168) | Loss 3.5488(3.5057) | Error 0.0056(0.0047) Steps 1120(1105.71) | Grad Norm 1.7237(1.5176) | Total Time 14.00(14.00)\n",
      "Iter 21710 | Time 26.3498(26.8232) | Bit/dim 3.4965(3.4967) | Xent 0.0163(0.0167) | Loss 3.5047(3.5051) | Error 0.0033(0.0046) Steps 1108(1106.50) | Grad Norm 1.2801(1.5266) | Total Time 14.00(14.00)\n",
      "Iter 21720 | Time 27.0490(26.7995) | Bit/dim 3.4949(3.4954) | Xent 0.0124(0.0169) | Loss 3.5012(3.5039) | Error 0.0033(0.0049) Steps 1108(1106.37) | Grad Norm 1.0959(1.4902) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 129.8039, Epoch Time 1624.0903(1618.7562), Bit/dim 3.5016(best: 3.5004), Xent 2.5902, Loss 4.7967, Error 0.2874(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21730 | Time 26.7080(26.7499) | Bit/dim 3.5040(3.4953) | Xent 0.0112(0.0163) | Loss 3.5096(3.5034) | Error 0.0033(0.0046) Steps 1108(1106.34) | Grad Norm 1.4442(1.4560) | Total Time 14.00(14.00)\n",
      "Iter 21740 | Time 27.0279(26.7780) | Bit/dim 3.4764(3.4946) | Xent 0.0181(0.0157) | Loss 3.4854(3.5025) | Error 0.0033(0.0042) Steps 1108(1106.39) | Grad Norm 1.3715(1.3953) | Total Time 14.00(14.00)\n",
      "Iter 21750 | Time 26.5817(26.7459) | Bit/dim 3.4556(3.4956) | Xent 0.0201(0.0158) | Loss 3.4657(3.5035) | Error 0.0044(0.0041) Steps 1114(1107.14) | Grad Norm 1.8744(1.4106) | Total Time 14.00(14.00)\n",
      "Iter 21760 | Time 26.8185(26.7205) | Bit/dim 3.5016(3.4968) | Xent 0.0223(0.0164) | Loss 3.5127(3.5050) | Error 0.0067(0.0044) Steps 1108(1107.29) | Grad Norm 1.9654(1.4562) | Total Time 14.00(14.00)\n",
      "Iter 21770 | Time 25.8917(26.6723) | Bit/dim 3.4542(3.4962) | Xent 0.0125(0.0163) | Loss 3.4605(3.5044) | Error 0.0044(0.0044) Steps 1108(1107.72) | Grad Norm 1.6177(1.4792) | Total Time 14.00(14.00)\n",
      "Iter 21780 | Time 26.7381(26.6040) | Bit/dim 3.4900(3.4958) | Xent 0.0162(0.0158) | Loss 3.4981(3.5037) | Error 0.0056(0.0043) Steps 1096(1106.69) | Grad Norm 1.1707(1.4575) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 129.7368, Epoch Time 1610.7624(1618.5164), Bit/dim 3.5012(best: 3.5004), Xent 2.5807, Loss 4.7916, Error 0.2880(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21790 | Time 27.1664(26.6888) | Bit/dim 3.5184(3.4952) | Xent 0.0117(0.0155) | Loss 3.5243(3.5030) | Error 0.0011(0.0041) Steps 1120(1106.74) | Grad Norm 1.5281(1.4580) | Total Time 14.00(14.00)\n",
      "Iter 21800 | Time 26.1261(26.7062) | Bit/dim 3.4777(3.4963) | Xent 0.0155(0.0150) | Loss 3.4854(3.5038) | Error 0.0044(0.0039) Steps 1102(1106.77) | Grad Norm 1.9232(1.4513) | Total Time 14.00(14.00)\n",
      "Iter 21810 | Time 26.8433(26.6821) | Bit/dim 3.4927(3.4958) | Xent 0.0163(0.0153) | Loss 3.5009(3.5034) | Error 0.0056(0.0042) Steps 1096(1106.14) | Grad Norm 1.7792(1.4608) | Total Time 14.00(14.00)\n",
      "Iter 21820 | Time 26.7190(26.6906) | Bit/dim 3.5034(3.4963) | Xent 0.0178(0.0155) | Loss 3.5123(3.5041) | Error 0.0056(0.0041) Steps 1114(1106.12) | Grad Norm 1.6258(1.5234) | Total Time 14.00(14.00)\n",
      "Iter 21830 | Time 26.9176(26.7306) | Bit/dim 3.5291(3.4971) | Xent 0.0101(0.0156) | Loss 3.5342(3.5049) | Error 0.0011(0.0042) Steps 1108(1105.97) | Grad Norm 0.7839(1.4789) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 129.3922, Epoch Time 1618.3928(1618.5127), Bit/dim 3.5021(best: 3.5004), Xent 2.5582, Loss 4.7812, Error 0.2863(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21840 | Time 26.5948(26.6563) | Bit/dim 3.4618(3.4949) | Xent 0.0126(0.0160) | Loss 3.4681(3.5029) | Error 0.0033(0.0044) Steps 1108(1105.59) | Grad Norm 0.9561(1.4543) | Total Time 14.00(14.00)\n",
      "Iter 21850 | Time 26.0026(26.6075) | Bit/dim 3.4750(3.4952) | Xent 0.0099(0.0156) | Loss 3.4799(3.5030) | Error 0.0022(0.0043) Steps 1102(1106.18) | Grad Norm 1.1073(1.3879) | Total Time 14.00(14.00)\n",
      "Iter 21860 | Time 26.1592(26.6530) | Bit/dim 3.5059(3.4964) | Xent 0.0254(0.0163) | Loss 3.5186(3.5045) | Error 0.0100(0.0047) Steps 1120(1106.06) | Grad Norm 1.4924(1.4295) | Total Time 14.00(14.00)\n",
      "Iter 21870 | Time 26.6728(26.6108) | Bit/dim 3.5030(3.4951) | Xent 0.0127(0.0158) | Loss 3.5094(3.5029) | Error 0.0022(0.0044) Steps 1096(1105.05) | Grad Norm 1.0853(1.4624) | Total Time 14.00(14.00)\n",
      "Iter 21880 | Time 26.0643(26.6104) | Bit/dim 3.4818(3.4958) | Xent 0.0131(0.0153) | Loss 3.4883(3.5035) | Error 0.0033(0.0042) Steps 1114(1106.65) | Grad Norm 0.9415(1.3802) | Total Time 14.00(14.00)\n",
      "Iter 21890 | Time 26.0357(26.5687) | Bit/dim 3.4882(3.4953) | Xent 0.0132(0.0157) | Loss 3.4948(3.5032) | Error 0.0056(0.0044) Steps 1096(1107.04) | Grad Norm 1.4629(1.3875) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 129.5408, Epoch Time 1608.3193(1618.2069), Bit/dim 3.5022(best: 3.5004), Xent 2.6083, Loss 4.8063, Error 0.2851(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21900 | Time 26.6319(26.6404) | Bit/dim 3.4899(3.4961) | Xent 0.0182(0.0156) | Loss 3.4990(3.5039) | Error 0.0067(0.0045) Steps 1102(1106.54) | Grad Norm 1.5912(1.3646) | Total Time 14.00(14.00)\n",
      "Iter 21910 | Time 26.5305(26.6819) | Bit/dim 3.4997(3.4960) | Xent 0.0200(0.0156) | Loss 3.5097(3.5038) | Error 0.0056(0.0045) Steps 1096(1107.31) | Grad Norm 1.2524(1.4057) | Total Time 14.00(14.00)\n",
      "Iter 21920 | Time 27.4019(26.7244) | Bit/dim 3.4835(3.4951) | Xent 0.0180(0.0150) | Loss 3.4925(3.5026) | Error 0.0044(0.0042) Steps 1120(1107.64) | Grad Norm 1.4181(1.3654) | Total Time 14.00(14.00)\n",
      "Iter 21930 | Time 26.9449(26.7350) | Bit/dim 3.5056(3.4960) | Xent 0.0117(0.0158) | Loss 3.5115(3.5039) | Error 0.0022(0.0043) Steps 1114(1108.27) | Grad Norm 1.6175(1.4322) | Total Time 14.00(14.00)\n",
      "Iter 21940 | Time 26.8395(26.7738) | Bit/dim 3.5154(3.4950) | Xent 0.0156(0.0159) | Loss 3.5232(3.5029) | Error 0.0033(0.0045) Steps 1108(1108.24) | Grad Norm 1.5245(1.4585) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 130.2223, Epoch Time 1623.6479(1618.3701), Bit/dim 3.5008(best: 3.5004), Xent 2.6013, Loss 4.8015, Error 0.2870(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21950 | Time 26.4405(26.7357) | Bit/dim 3.4794(3.4952) | Xent 0.0200(0.0163) | Loss 3.4894(3.5034) | Error 0.0067(0.0045) Steps 1102(1108.01) | Grad Norm 1.3139(1.4665) | Total Time 14.00(14.00)\n",
      "Iter 21960 | Time 26.4129(26.6555) | Bit/dim 3.4770(3.4951) | Xent 0.0129(0.0163) | Loss 3.4835(3.5032) | Error 0.0011(0.0047) Steps 1102(1108.72) | Grad Norm 1.0924(1.4605) | Total Time 14.00(14.00)\n",
      "Iter 21970 | Time 27.4580(26.6767) | Bit/dim 3.4837(3.4923) | Xent 0.0151(0.0169) | Loss 3.4913(3.5008) | Error 0.0044(0.0050) Steps 1096(1107.26) | Grad Norm 1.4467(1.6523) | Total Time 14.00(14.00)\n",
      "Iter 21980 | Time 26.5940(26.6711) | Bit/dim 3.5010(3.4948) | Xent 0.0129(0.0168) | Loss 3.5075(3.5032) | Error 0.0033(0.0049) Steps 1102(1106.17) | Grad Norm 1.2789(1.6947) | Total Time 14.00(14.00)\n",
      "Iter 21990 | Time 26.2854(26.6678) | Bit/dim 3.5330(3.4969) | Xent 0.0167(0.0177) | Loss 3.5414(3.5058) | Error 0.0056(0.0052) Steps 1102(1106.48) | Grad Norm 1.3969(1.6715) | Total Time 14.00(14.00)\n",
      "Iter 22000 | Time 26.6950(26.6394) | Bit/dim 3.5095(3.4969) | Xent 0.0214(0.0178) | Loss 3.5202(3.5058) | Error 0.0089(0.0054) Steps 1114(1106.06) | Grad Norm 2.0536(1.6477) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 129.5390, Epoch Time 1609.9794(1618.1184), Bit/dim 3.5012(best: 3.5004), Xent 2.6236, Loss 4.8131, Error 0.2866(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22010 | Time 26.8886(26.6895) | Bit/dim 3.4566(3.4961) | Xent 0.0114(0.0173) | Loss 3.4623(3.5048) | Error 0.0022(0.0052) Steps 1102(1106.55) | Grad Norm 1.4475(1.6349) | Total Time 14.00(14.00)\n",
      "Iter 22020 | Time 26.0907(26.7073) | Bit/dim 3.4969(3.4977) | Xent 0.0155(0.0177) | Loss 3.5046(3.5066) | Error 0.0044(0.0052) Steps 1114(1108.33) | Grad Norm 2.5215(1.7286) | Total Time 14.00(14.00)\n",
      "Iter 22030 | Time 26.3348(26.6998) | Bit/dim 3.4765(3.4985) | Xent 0.0214(0.0170) | Loss 3.4872(3.5069) | Error 0.0056(0.0048) Steps 1096(1107.26) | Grad Norm 1.9512(1.6943) | Total Time 14.00(14.00)\n",
      "Iter 22040 | Time 27.4491(26.6945) | Bit/dim 3.5069(3.4983) | Xent 0.0146(0.0173) | Loss 3.5142(3.5070) | Error 0.0044(0.0050) Steps 1120(1107.86) | Grad Norm 1.5035(1.7453) | Total Time 14.00(14.00)\n",
      "Iter 22050 | Time 26.2560(26.7036) | Bit/dim 3.5088(3.4967) | Xent 0.0127(0.0164) | Loss 3.5151(3.5049) | Error 0.0011(0.0046) Steps 1096(1108.35) | Grad Norm 1.0130(1.6943) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 129.4923, Epoch Time 1619.1911(1618.1506), Bit/dim 3.5019(best: 3.5004), Xent 2.6134, Loss 4.8087, Error 0.2874(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22060 | Time 26.5789(26.6949) | Bit/dim 3.4812(3.4936) | Xent 0.0101(0.0167) | Loss 3.4862(3.5019) | Error 0.0011(0.0047) Steps 1108(1107.78) | Grad Norm 1.1320(1.6594) | Total Time 14.00(14.00)\n",
      "Iter 22070 | Time 26.3394(26.7106) | Bit/dim 3.5069(3.4952) | Xent 0.0138(0.0165) | Loss 3.5138(3.5034) | Error 0.0033(0.0046) Steps 1108(1107.57) | Grad Norm 1.1930(1.5763) | Total Time 14.00(14.00)\n",
      "Iter 22080 | Time 26.8208(26.6649) | Bit/dim 3.4748(3.4946) | Xent 0.0300(0.0164) | Loss 3.4898(3.5028) | Error 0.0122(0.0046) Steps 1108(1106.43) | Grad Norm 2.2146(1.5259) | Total Time 14.00(14.00)\n",
      "Iter 22090 | Time 26.8412(26.6685) | Bit/dim 3.5087(3.4941) | Xent 0.0192(0.0172) | Loss 3.5184(3.5027) | Error 0.0067(0.0050) Steps 1126(1109.08) | Grad Norm 1.2089(1.5948) | Total Time 14.00(14.00)\n",
      "Iter 22100 | Time 26.6469(26.7141) | Bit/dim 3.5093(3.4967) | Xent 0.0160(0.0163) | Loss 3.5173(3.5048) | Error 0.0044(0.0047) Steps 1120(1109.91) | Grad Norm 1.3984(1.5951) | Total Time 14.00(14.00)\n",
      "Iter 22110 | Time 26.3255(26.6514) | Bit/dim 3.5086(3.4961) | Xent 0.0142(0.0160) | Loss 3.5157(3.5041) | Error 0.0033(0.0045) Steps 1108(1109.41) | Grad Norm 1.4704(1.5216) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 129.2437, Epoch Time 1612.3783(1617.9774), Bit/dim 3.5007(best: 3.5004), Xent 2.5869, Loss 4.7941, Error 0.2860(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22120 | Time 26.2905(26.6631) | Bit/dim 3.5092(3.4951) | Xent 0.0105(0.0161) | Loss 3.5145(3.5032) | Error 0.0011(0.0046) Steps 1108(1109.58) | Grad Norm 1.0912(1.4796) | Total Time 14.00(14.00)\n",
      "Iter 22130 | Time 26.5981(26.6383) | Bit/dim 3.5047(3.4951) | Xent 0.0119(0.0160) | Loss 3.5106(3.5031) | Error 0.0022(0.0047) Steps 1108(1109.02) | Grad Norm 0.9362(1.4872) | Total Time 14.00(14.00)\n",
      "Iter 22140 | Time 27.3252(26.6649) | Bit/dim 3.4985(3.4932) | Xent 0.0140(0.0158) | Loss 3.5055(3.5011) | Error 0.0022(0.0046) Steps 1114(1108.71) | Grad Norm 1.1132(1.4484) | Total Time 14.00(14.00)\n",
      "Iter 22150 | Time 27.1971(26.7333) | Bit/dim 3.5037(3.4937) | Xent 0.0229(0.0167) | Loss 3.5152(3.5020) | Error 0.0100(0.0050) Steps 1108(1106.46) | Grad Norm 2.2159(1.5057) | Total Time 14.00(14.00)\n",
      "Iter 22160 | Time 26.1599(26.8203) | Bit/dim 3.5020(3.4970) | Xent 0.0110(0.0162) | Loss 3.5075(3.5052) | Error 0.0011(0.0048) Steps 1108(1109.14) | Grad Norm 1.3373(1.4975) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 129.6847, Epoch Time 1619.8868(1618.0347), Bit/dim 3.5012(best: 3.5004), Xent 2.6286, Loss 4.8154, Error 0.2859(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22170 | Time 26.3375(26.7401) | Bit/dim 3.4927(3.4963) | Xent 0.0155(0.0158) | Loss 3.5005(3.5042) | Error 0.0044(0.0046) Steps 1114(1110.49) | Grad Norm 1.0197(1.4247) | Total Time 14.00(14.00)\n",
      "Iter 22180 | Time 25.7149(26.6894) | Bit/dim 3.4511(3.4955) | Xent 0.0119(0.0155) | Loss 3.4570(3.5032) | Error 0.0033(0.0045) Steps 1114(1110.18) | Grad Norm 1.9067(1.4464) | Total Time 14.00(14.00)\n",
      "Iter 22190 | Time 25.6964(26.6470) | Bit/dim 3.4865(3.4953) | Xent 0.0209(0.0156) | Loss 3.4970(3.5031) | Error 0.0044(0.0042) Steps 1114(1109.17) | Grad Norm 1.6656(1.4286) | Total Time 14.00(14.00)\n",
      "Iter 22200 | Time 27.0279(26.6990) | Bit/dim 3.4996(3.4954) | Xent 0.0116(0.0153) | Loss 3.5054(3.5031) | Error 0.0022(0.0040) Steps 1114(1108.73) | Grad Norm 1.1384(1.4262) | Total Time 14.00(14.00)\n",
      "Iter 22210 | Time 26.2260(26.6539) | Bit/dim 3.4967(3.4949) | Xent 0.0180(0.0161) | Loss 3.5057(3.5029) | Error 0.0044(0.0045) Steps 1096(1108.02) | Grad Norm 1.6493(1.4711) | Total Time 14.00(14.00)\n",
      "Iter 22220 | Time 26.4303(26.7042) | Bit/dim 3.5315(3.4958) | Xent 0.0161(0.0162) | Loss 3.5395(3.5039) | Error 0.0067(0.0045) Steps 1102(1107.19) | Grad Norm 1.3351(1.4915) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 129.8588, Epoch Time 1614.0786(1617.9160), Bit/dim 3.5018(best: 3.5004), Xent 2.5937, Loss 4.7986, Error 0.2837(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22230 | Time 26.3460(26.6695) | Bit/dim 3.4904(3.4995) | Xent 0.0162(0.0160) | Loss 3.4985(3.5075) | Error 0.0056(0.0044) Steps 1114(1106.94) | Grad Norm 1.0958(1.4377) | Total Time 14.00(14.00)\n",
      "Iter 22240 | Time 27.3605(26.7296) | Bit/dim 3.5101(3.4989) | Xent 0.0192(0.0162) | Loss 3.5197(3.5070) | Error 0.0067(0.0047) Steps 1108(1107.98) | Grad Norm 1.9461(1.4698) | Total Time 14.00(14.00)\n",
      "Iter 22250 | Time 26.5695(26.7396) | Bit/dim 3.5155(3.4970) | Xent 0.0131(0.0163) | Loss 3.5221(3.5051) | Error 0.0056(0.0050) Steps 1102(1107.37) | Grad Norm 1.2745(1.5081) | Total Time 14.00(14.00)\n",
      "Iter 22260 | Time 27.4182(26.7146) | Bit/dim 3.4495(3.4921) | Xent 0.0113(0.0159) | Loss 3.4551(3.5001) | Error 0.0022(0.0048) Steps 1102(1106.26) | Grad Norm 0.7736(1.4788) | Total Time 14.00(14.00)\n",
      "Iter 22270 | Time 26.5358(26.7973) | Bit/dim 3.4705(3.4938) | Xent 0.0218(0.0162) | Loss 3.4814(3.5019) | Error 0.0056(0.0047) Steps 1108(1107.43) | Grad Norm 1.4611(1.4235) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 128.8087, Epoch Time 1619.5490(1617.9650), Bit/dim 3.5006(best: 3.5004), Xent 2.6107, Loss 4.8059, Error 0.2896(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22280 | Time 26.3393(26.7512) | Bit/dim 3.5118(3.4975) | Xent 0.0116(0.0158) | Loss 3.5176(3.5054) | Error 0.0044(0.0045) Steps 1108(1106.19) | Grad Norm 1.1831(1.3615) | Total Time 14.00(14.00)\n",
      "Iter 22290 | Time 26.5377(26.7338) | Bit/dim 3.4748(3.4970) | Xent 0.0116(0.0158) | Loss 3.4806(3.5049) | Error 0.0033(0.0045) Steps 1108(1108.35) | Grad Norm 1.1561(1.3652) | Total Time 14.00(14.00)\n",
      "Iter 22300 | Time 26.7162(26.7196) | Bit/dim 3.5074(3.4961) | Xent 0.0254(0.0161) | Loss 3.5201(3.5041) | Error 0.0078(0.0046) Steps 1108(1108.26) | Grad Norm 2.0845(1.4190) | Total Time 14.00(14.00)\n",
      "Iter 22310 | Time 26.2186(26.6068) | Bit/dim 3.5254(3.4943) | Xent 0.0109(0.0167) | Loss 3.5308(3.5026) | Error 0.0022(0.0048) Steps 1120(1108.10) | Grad Norm 1.0852(1.5164) | Total Time 14.00(14.00)\n",
      "Iter 22320 | Time 26.9249(26.6243) | Bit/dim 3.4849(3.4947) | Xent 0.0168(0.0164) | Loss 3.4933(3.5029) | Error 0.0044(0.0047) Steps 1126(1108.46) | Grad Norm 1.6069(1.5179) | Total Time 14.00(14.00)\n",
      "Iter 22330 | Time 26.5777(26.5755) | Bit/dim 3.4780(3.4940) | Xent 0.0124(0.0165) | Loss 3.4842(3.5023) | Error 0.0044(0.0050) Steps 1114(1107.62) | Grad Norm 1.2294(1.5768) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 130.0182, Epoch Time 1608.0687(1617.6681), Bit/dim 3.5008(best: 3.5004), Xent 2.6404, Loss 4.8210, Error 0.2875(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22340 | Time 26.3166(26.5720) | Bit/dim 3.4782(3.4976) | Xent 0.0074(0.0167) | Loss 3.4819(3.5059) | Error 0.0011(0.0051) Steps 1108(1107.45) | Grad Norm 1.3496(1.6184) | Total Time 14.00(14.00)\n",
      "Iter 22350 | Time 26.8409(26.6455) | Bit/dim 3.4771(3.4977) | Xent 0.0266(0.0168) | Loss 3.4904(3.5061) | Error 0.0078(0.0050) Steps 1108(1107.87) | Grad Norm 2.8074(1.6919) | Total Time 14.00(14.00)\n",
      "Iter 22360 | Time 26.6315(26.6601) | Bit/dim 3.4789(3.4944) | Xent 0.0099(0.0165) | Loss 3.4838(3.5026) | Error 0.0022(0.0050) Steps 1120(1108.32) | Grad Norm 1.1664(1.6939) | Total Time 14.00(14.00)\n",
      "Iter 22370 | Time 26.1863(26.6877) | Bit/dim 3.4791(3.4941) | Xent 0.0198(0.0166) | Loss 3.4891(3.5024) | Error 0.0056(0.0050) Steps 1120(1109.73) | Grad Norm 1.6677(1.6581) | Total Time 14.00(14.00)\n",
      "Iter 22380 | Time 26.6000(26.6910) | Bit/dim 3.4929(3.4934) | Xent 0.0110(0.0165) | Loss 3.4984(3.5017) | Error 0.0033(0.0051) Steps 1114(1110.05) | Grad Norm 1.1369(1.5687) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 131.0965, Epoch Time 1619.1548(1617.7127), Bit/dim 3.5011(best: 3.5004), Xent 2.6491, Loss 4.8257, Error 0.2860(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22390 | Time 26.8155(26.7538) | Bit/dim 3.5066(3.4955) | Xent 0.0148(0.0164) | Loss 3.5141(3.5037) | Error 0.0044(0.0052) Steps 1114(1110.79) | Grad Norm 1.4476(1.5350) | Total Time 14.00(14.00)\n",
      "Iter 22400 | Time 27.1400(26.7568) | Bit/dim 3.4749(3.4947) | Xent 0.0205(0.0168) | Loss 3.4852(3.5031) | Error 0.0044(0.0053) Steps 1096(1109.77) | Grad Norm 2.0768(1.5577) | Total Time 14.00(14.00)\n",
      "Iter 22410 | Time 26.9889(26.8039) | Bit/dim 3.5107(3.4949) | Xent 0.0115(0.0166) | Loss 3.5164(3.5032) | Error 0.0044(0.0052) Steps 1102(1108.90) | Grad Norm 0.9237(1.5632) | Total Time 14.00(14.00)\n",
      "Iter 22420 | Time 27.0643(26.7851) | Bit/dim 3.5140(3.4976) | Xent 0.0177(0.0164) | Loss 3.5228(3.5058) | Error 0.0067(0.0051) Steps 1102(1109.85) | Grad Norm 1.7201(1.5163) | Total Time 14.00(14.00)\n",
      "Iter 22430 | Time 26.6646(26.7771) | Bit/dim 3.4753(3.4934) | Xent 0.0102(0.0162) | Loss 3.4804(3.5015) | Error 0.0022(0.0049) Steps 1096(1109.18) | Grad Norm 0.8627(1.4843) | Total Time 14.00(14.00)\n",
      "Iter 22440 | Time 26.7510(26.7796) | Bit/dim 3.5020(3.4939) | Xent 0.0196(0.0161) | Loss 3.5118(3.5019) | Error 0.0033(0.0047) Steps 1096(1107.88) | Grad Norm 1.5467(1.4577) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 130.2596, Epoch Time 1622.1562(1617.8460), Bit/dim 3.5008(best: 3.5004), Xent 2.6449, Loss 4.8232, Error 0.2883(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22450 | Time 26.3966(26.7317) | Bit/dim 3.5075(3.4923) | Xent 0.0202(0.0162) | Loss 3.5176(3.5004) | Error 0.0056(0.0049) Steps 1108(1107.83) | Grad Norm 2.0998(1.4419) | Total Time 14.00(14.00)\n",
      "Iter 22460 | Time 26.6718(26.7366) | Bit/dim 3.4794(3.4963) | Xent 0.0143(0.0157) | Loss 3.4865(3.5041) | Error 0.0044(0.0045) Steps 1096(1107.25) | Grad Norm 1.1457(1.4827) | Total Time 14.00(14.00)\n",
      "Iter 22470 | Time 26.5686(26.7382) | Bit/dim 3.5209(3.4959) | Xent 0.0113(0.0160) | Loss 3.5266(3.5038) | Error 0.0011(0.0045) Steps 1114(1107.63) | Grad Norm 1.2011(1.5185) | Total Time 14.00(14.00)\n",
      "Iter 22480 | Time 27.1447(26.6734) | Bit/dim 3.4975(3.4952) | Xent 0.0125(0.0155) | Loss 3.5037(3.5029) | Error 0.0033(0.0043) Steps 1096(1108.37) | Grad Norm 1.3876(1.4805) | Total Time 14.00(14.00)\n",
      "Iter 22490 | Time 26.5420(26.6620) | Bit/dim 3.4951(3.4953) | Xent 0.0211(0.0161) | Loss 3.5057(3.5034) | Error 0.0056(0.0046) Steps 1102(1108.94) | Grad Norm 1.6118(1.4767) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 129.3312, Epoch Time 1612.6257(1617.6894), Bit/dim 3.5022(best: 3.5004), Xent 2.6473, Loss 4.8259, Error 0.2878(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22500 | Time 26.6418(26.6387) | Bit/dim 3.4753(3.4942) | Xent 0.0158(0.0169) | Loss 3.4832(3.5026) | Error 0.0067(0.0048) Steps 1120(1108.59) | Grad Norm 1.4294(1.5069) | Total Time 14.00(14.00)\n",
      "Iter 22510 | Time 27.5057(26.7335) | Bit/dim 3.5152(3.4954) | Xent 0.0115(0.0163) | Loss 3.5209(3.5036) | Error 0.0022(0.0045) Steps 1120(1110.16) | Grad Norm 1.1786(1.4674) | Total Time 14.00(14.00)\n",
      "Iter 22520 | Time 26.8031(26.7474) | Bit/dim 3.5286(3.4958) | Xent 0.0175(0.0160) | Loss 3.5373(3.5038) | Error 0.0067(0.0046) Steps 1120(1110.47) | Grad Norm 1.3163(1.4391) | Total Time 14.00(14.00)\n",
      "Iter 22530 | Time 26.6416(26.7797) | Bit/dim 3.4708(3.4959) | Xent 0.0345(0.0168) | Loss 3.4881(3.5043) | Error 0.0133(0.0050) Steps 1108(1110.33) | Grad Norm 3.0205(1.5281) | Total Time 14.00(14.00)\n",
      "Iter 22540 | Time 26.3955(26.8146) | Bit/dim 3.4670(3.4945) | Xent 0.0177(0.0165) | Loss 3.4759(3.5027) | Error 0.0056(0.0048) Steps 1114(1110.45) | Grad Norm 1.3075(1.4959) | Total Time 14.00(14.00)\n",
      "Iter 22550 | Time 26.8741(26.8316) | Bit/dim 3.4744(3.4947) | Xent 0.0134(0.0164) | Loss 3.4810(3.5029) | Error 0.0022(0.0048) Steps 1096(1109.86) | Grad Norm 1.4362(1.5102) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 130.9036, Epoch Time 1625.2672(1617.9167), Bit/dim 3.5017(best: 3.5004), Xent 2.6755, Loss 4.8395, Error 0.2864(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22560 | Time 27.1683(26.7951) | Bit/dim 3.4743(3.4939) | Xent 0.0173(0.0172) | Loss 3.4830(3.5025) | Error 0.0056(0.0051) Steps 1114(1109.58) | Grad Norm 1.5310(1.6435) | Total Time 14.00(14.00)\n",
      "Iter 22570 | Time 26.6060(26.7921) | Bit/dim 3.4661(3.4922) | Xent 0.0201(0.0178) | Loss 3.4762(3.5011) | Error 0.0067(0.0054) Steps 1108(1109.76) | Grad Norm 1.5449(1.7739) | Total Time 14.00(14.00)\n",
      "Iter 22580 | Time 27.3180(26.8223) | Bit/dim 3.5026(3.4943) | Xent 0.0124(0.0171) | Loss 3.5088(3.5029) | Error 0.0033(0.0049) Steps 1120(1110.12) | Grad Norm 1.3564(1.6829) | Total Time 14.00(14.00)\n",
      "Iter 22590 | Time 26.9593(26.8416) | Bit/dim 3.4912(3.4960) | Xent 0.0213(0.0178) | Loss 3.5018(3.5049) | Error 0.0067(0.0050) Steps 1108(1111.01) | Grad Norm 2.0903(1.6708) | Total Time 14.00(14.00)\n",
      "Iter 22600 | Time 26.6455(26.7803) | Bit/dim 3.5170(3.4966) | Xent 0.0162(0.0181) | Loss 3.5251(3.5056) | Error 0.0067(0.0052) Steps 1108(1109.24) | Grad Norm 1.4204(1.7077) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 131.3847, Epoch Time 1619.9770(1617.9785), Bit/dim 3.5008(best: 3.5004), Xent 2.6524, Loss 4.8270, Error 0.2884(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22610 | Time 26.3296(26.6963) | Bit/dim 3.4800(3.4962) | Xent 0.0124(0.0178) | Loss 3.4862(3.5051) | Error 0.0033(0.0053) Steps 1120(1108.82) | Grad Norm 1.1688(1.6575) | Total Time 14.00(14.00)\n",
      "Iter 22620 | Time 26.9446(26.7639) | Bit/dim 3.4993(3.4947) | Xent 0.0191(0.0180) | Loss 3.5088(3.5037) | Error 0.0067(0.0053) Steps 1102(1109.14) | Grad Norm 2.1047(1.6221) | Total Time 14.00(14.00)\n",
      "Iter 22630 | Time 27.2936(26.7844) | Bit/dim 3.5246(3.4961) | Xent 0.0119(0.0172) | Loss 3.5305(3.5047) | Error 0.0022(0.0050) Steps 1108(1110.22) | Grad Norm 1.9549(1.6089) | Total Time 14.00(14.00)\n",
      "Iter 22640 | Time 26.9997(26.7838) | Bit/dim 3.4722(3.4946) | Xent 0.0242(0.0172) | Loss 3.4843(3.5032) | Error 0.0044(0.0052) Steps 1102(1109.94) | Grad Norm 1.5535(1.6240) | Total Time 14.00(14.00)\n",
      "Iter 22650 | Time 26.2208(26.7181) | Bit/dim 3.5041(3.4952) | Xent 0.0189(0.0166) | Loss 3.5136(3.5035) | Error 0.0056(0.0048) Steps 1102(1110.18) | Grad Norm 1.8351(1.6368) | Total Time 14.00(14.00)\n",
      "Iter 22660 | Time 26.1814(26.6662) | Bit/dim 3.4955(3.4963) | Xent 0.0168(0.0159) | Loss 3.5039(3.5042) | Error 0.0033(0.0044) Steps 1108(1109.93) | Grad Norm 1.6715(1.5580) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 132.6469, Epoch Time 1619.7412(1618.0314), Bit/dim 3.4982(best: 3.5004), Xent 2.6028, Loss 4.7996, Error 0.2860(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22670 | Time 26.6568(26.6746) | Bit/dim 3.5189(3.4954) | Xent 0.0177(0.0159) | Loss 3.5278(3.5033) | Error 0.0078(0.0046) Steps 1108(1110.84) | Grad Norm 1.5147(1.5339) | Total Time 14.00(14.00)\n",
      "Iter 22680 | Time 26.1287(26.6781) | Bit/dim 3.5219(3.4953) | Xent 0.0112(0.0155) | Loss 3.5275(3.5030) | Error 0.0033(0.0046) Steps 1102(1111.31) | Grad Norm 1.6979(1.5164) | Total Time 14.00(14.00)\n",
      "Iter 22690 | Time 26.1942(26.7038) | Bit/dim 3.5195(3.4956) | Xent 0.0168(0.0156) | Loss 3.5279(3.5034) | Error 0.0056(0.0046) Steps 1108(1109.98) | Grad Norm 1.7566(1.4791) | Total Time 14.00(14.00)\n",
      "Iter 22700 | Time 26.5555(26.6179) | Bit/dim 3.5050(3.4953) | Xent 0.0193(0.0164) | Loss 3.5147(3.5035) | Error 0.0056(0.0050) Steps 1108(1109.64) | Grad Norm 1.7376(1.5143) | Total Time 14.00(14.00)\n",
      "Iter 22710 | Time 26.5834(26.6124) | Bit/dim 3.5037(3.4953) | Xent 0.0181(0.0161) | Loss 3.5127(3.5033) | Error 0.0067(0.0049) Steps 1114(1109.43) | Grad Norm 2.1700(1.5125) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 131.8851, Epoch Time 1615.1450(1617.9448), Bit/dim 3.5021(best: 3.4982), Xent 2.6747, Loss 4.8395, Error 0.2858(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22720 | Time 26.8195(26.6104) | Bit/dim 3.4988(3.4941) | Xent 0.0108(0.0158) | Loss 3.5042(3.5020) | Error 0.0022(0.0047) Steps 1114(1109.57) | Grad Norm 1.8396(1.5489) | Total Time 14.00(14.00)\n",
      "Iter 22730 | Time 25.7689(26.5942) | Bit/dim 3.4588(3.4942) | Xent 0.0190(0.0158) | Loss 3.4683(3.5021) | Error 0.0033(0.0047) Steps 1114(1109.79) | Grad Norm 1.4880(1.5518) | Total Time 14.00(14.00)\n",
      "Iter 22740 | Time 26.8617(26.6073) | Bit/dim 3.5365(3.4956) | Xent 0.0155(0.0160) | Loss 3.5442(3.5036) | Error 0.0056(0.0048) Steps 1102(1109.49) | Grad Norm 1.9881(1.6070) | Total Time 14.00(14.00)\n",
      "Iter 22750 | Time 26.4822(26.6623) | Bit/dim 3.4693(3.4927) | Xent 0.0113(0.0158) | Loss 3.4749(3.5006) | Error 0.0011(0.0050) Steps 1108(1109.59) | Grad Norm 1.6277(1.6328) | Total Time 14.00(14.00)\n",
      "Iter 22760 | Time 27.2905(26.7153) | Bit/dim 3.5143(3.4960) | Xent 0.0137(0.0153) | Loss 3.5211(3.5036) | Error 0.0056(0.0047) Steps 1102(1108.11) | Grad Norm 1.3887(1.5833) | Total Time 14.00(14.00)\n",
      "Iter 22770 | Time 26.6802(26.6806) | Bit/dim 3.4697(3.4956) | Xent 0.0216(0.0154) | Loss 3.4805(3.5033) | Error 0.0078(0.0048) Steps 1096(1105.44) | Grad Norm 1.4634(1.5582) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 130.2767, Epoch Time 1615.0670(1617.8585), Bit/dim 3.4983(best: 3.4982), Xent 2.6358, Loss 4.8162, Error 0.2848(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22780 | Time 26.6707(26.6304) | Bit/dim 3.4876(3.4947) | Xent 0.0180(0.0159) | Loss 3.4966(3.5027) | Error 0.0056(0.0048) Steps 1102(1105.53) | Grad Norm 1.6096(1.5185) | Total Time 14.00(14.00)\n",
      "Iter 22790 | Time 27.0325(26.6871) | Bit/dim 3.5031(3.4941) | Xent 0.0136(0.0156) | Loss 3.5099(3.5019) | Error 0.0022(0.0045) Steps 1102(1106.49) | Grad Norm 1.6039(1.5461) | Total Time 14.00(14.00)\n",
      "Iter 22800 | Time 26.1608(26.7319) | Bit/dim 3.4623(3.4955) | Xent 0.0301(0.0160) | Loss 3.4774(3.5035) | Error 0.0133(0.0045) Steps 1102(1106.33) | Grad Norm 3.5840(1.6472) | Total Time 14.00(14.00)\n",
      "Iter 22810 | Time 26.5852(26.6757) | Bit/dim 3.5266(3.4939) | Xent 0.0156(0.0155) | Loss 3.5344(3.5016) | Error 0.0044(0.0044) Steps 1096(1106.39) | Grad Norm 1.7791(1.6898) | Total Time 14.00(14.00)\n",
      "Iter 22820 | Time 27.3026(26.6376) | Bit/dim 3.5019(3.4957) | Xent 0.0163(0.0160) | Loss 3.5101(3.5037) | Error 0.0033(0.0046) Steps 1102(1105.84) | Grad Norm 1.4424(1.6908) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 129.6392, Epoch Time 1613.5210(1617.7284), Bit/dim 3.5005(best: 3.4982), Xent 2.7036, Loss 4.8523, Error 0.2882(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22830 | Time 26.4044(26.5876) | Bit/dim 3.5093(3.4955) | Xent 0.0157(0.0159) | Loss 3.5171(3.5035) | Error 0.0056(0.0047) Steps 1102(1105.49) | Grad Norm 1.5959(1.6130) | Total Time 14.00(14.00)\n",
      "Iter 22840 | Time 26.1474(26.6091) | Bit/dim 3.4900(3.4950) | Xent 0.0104(0.0157) | Loss 3.4952(3.5029) | Error 0.0011(0.0046) Steps 1102(1106.11) | Grad Norm 1.2250(1.5475) | Total Time 14.00(14.00)\n",
      "Iter 22850 | Time 26.0548(26.5998) | Bit/dim 3.4976(3.4962) | Xent 0.0113(0.0153) | Loss 3.5032(3.5039) | Error 0.0033(0.0045) Steps 1108(1107.08) | Grad Norm 1.2016(1.5113) | Total Time 14.00(14.00)\n",
      "Iter 22860 | Time 26.8089(26.5922) | Bit/dim 3.5093(3.4923) | Xent 0.0163(0.0160) | Loss 3.5174(3.5003) | Error 0.0056(0.0048) Steps 1108(1107.52) | Grad Norm 1.6005(1.5428) | Total Time 14.00(14.00)\n",
      "Iter 22870 | Time 26.4983(26.6113) | Bit/dim 3.5052(3.4937) | Xent 0.0258(0.0169) | Loss 3.5181(3.5021) | Error 0.0111(0.0051) Steps 1102(1107.63) | Grad Norm 2.3741(1.6587) | Total Time 14.00(14.00)\n",
      "Iter 22880 | Time 26.5351(26.5262) | Bit/dim 3.5175(3.4945) | Xent 0.0203(0.0164) | Loss 3.5276(3.5027) | Error 0.0056(0.0049) Steps 1102(1108.14) | Grad Norm 1.4062(1.6170) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 129.5259, Epoch Time 1606.3153(1617.3860), Bit/dim 3.4989(best: 3.4982), Xent 2.6650, Loss 4.8314, Error 0.2870(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22890 | Time 26.6701(26.5117) | Bit/dim 3.4503(3.4935) | Xent 0.0207(0.0164) | Loss 3.4607(3.5017) | Error 0.0078(0.0048) Steps 1108(1107.65) | Grad Norm 2.3514(1.6657) | Total Time 14.00(14.00)\n",
      "Iter 22900 | Time 26.8087(26.5828) | Bit/dim 3.4993(3.4909) | Xent 0.0164(0.0166) | Loss 3.5075(3.4992) | Error 0.0056(0.0047) Steps 1114(1107.91) | Grad Norm 1.5546(1.6460) | Total Time 14.00(14.00)\n",
      "Iter 22910 | Time 26.3584(26.5675) | Bit/dim 3.4871(3.4917) | Xent 0.0190(0.0163) | Loss 3.4966(3.4999) | Error 0.0067(0.0046) Steps 1102(1107.94) | Grad Norm 1.5395(1.6099) | Total Time 14.00(14.00)\n",
      "Iter 22920 | Time 26.1595(26.5797) | Bit/dim 3.4833(3.4933) | Xent 0.0122(0.0166) | Loss 3.4894(3.5016) | Error 0.0022(0.0046) Steps 1108(1107.44) | Grad Norm 1.5191(1.6020) | Total Time 14.00(14.00)\n",
      "Iter 22930 | Time 27.6669(26.6454) | Bit/dim 3.4900(3.4941) | Xent 0.0158(0.0163) | Loss 3.4979(3.5023) | Error 0.0056(0.0048) Steps 1096(1106.25) | Grad Norm 1.4183(1.5362) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 130.1849, Epoch Time 1614.0062(1617.2846), Bit/dim 3.4992(best: 3.4982), Xent 2.6367, Loss 4.8175, Error 0.2811(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22940 | Time 26.0693(26.6422) | Bit/dim 3.4707(3.4955) | Xent 0.0166(0.0158) | Loss 3.4789(3.5034) | Error 0.0044(0.0045) Steps 1096(1105.57) | Grad Norm 1.7931(1.4877) | Total Time 14.00(14.00)\n",
      "Iter 22950 | Time 27.1261(26.6538) | Bit/dim 3.5334(3.4965) | Xent 0.0097(0.0155) | Loss 3.5383(3.5042) | Error 0.0022(0.0044) Steps 1126(1106.35) | Grad Norm 0.9288(1.4459) | Total Time 14.00(14.00)\n",
      "Iter 22960 | Time 26.5751(26.6197) | Bit/dim 3.4884(3.4938) | Xent 0.0221(0.0158) | Loss 3.4994(3.5017) | Error 0.0067(0.0045) Steps 1102(1106.13) | Grad Norm 1.4809(1.4649) | Total Time 14.00(14.00)\n",
      "Iter 22970 | Time 26.9176(26.6345) | Bit/dim 3.4831(3.4920) | Xent 0.0113(0.0159) | Loss 3.4887(3.5000) | Error 0.0033(0.0047) Steps 1114(1106.34) | Grad Norm 1.2489(1.4806) | Total Time 14.00(14.00)\n",
      "Iter 22980 | Time 25.9159(26.6614) | Bit/dim 3.5209(3.4939) | Xent 0.0166(0.0166) | Loss 3.5292(3.5022) | Error 0.0033(0.0050) Steps 1096(1107.15) | Grad Norm 1.6437(1.4957) | Total Time 14.00(14.00)\n",
      "Iter 22990 | Time 27.4236(26.6686) | Bit/dim 3.5225(3.4962) | Xent 0.0187(0.0172) | Loss 3.5319(3.5048) | Error 0.0089(0.0053) Steps 1108(1106.72) | Grad Norm 2.2849(1.6345) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 131.9638, Epoch Time 1615.8741(1617.2423), Bit/dim 3.5019(best: 3.4982), Xent 2.6856, Loss 4.8447, Error 0.2892(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23000 | Time 26.3607(26.6260) | Bit/dim 3.4738(3.4950) | Xent 0.0132(0.0167) | Loss 3.4804(3.5034) | Error 0.0056(0.0051) Steps 1108(1107.74) | Grad Norm 1.3590(1.6373) | Total Time 14.00(14.00)\n",
      "Iter 23010 | Time 26.3368(26.5791) | Bit/dim 3.5060(3.4944) | Xent 0.0180(0.0161) | Loss 3.5149(3.5024) | Error 0.0067(0.0048) Steps 1114(1107.93) | Grad Norm 1.2269(1.5961) | Total Time 14.00(14.00)\n",
      "Iter 23020 | Time 26.3192(26.5061) | Bit/dim 3.4944(3.4939) | Xent 0.0206(0.0158) | Loss 3.5047(3.5019) | Error 0.0033(0.0047) Steps 1090(1108.59) | Grad Norm 1.8066(1.5635) | Total Time 14.00(14.00)\n",
      "Iter 23030 | Time 26.8379(26.5158) | Bit/dim 3.4984(3.4941) | Xent 0.0208(0.0160) | Loss 3.5088(3.5022) | Error 0.0056(0.0048) Steps 1114(1109.63) | Grad Norm 1.8146(1.5707) | Total Time 14.00(14.00)\n",
      "Iter 23040 | Time 26.3861(26.4965) | Bit/dim 3.5103(3.4951) | Xent 0.0156(0.0157) | Loss 3.5181(3.5030) | Error 0.0044(0.0045) Steps 1096(1109.05) | Grad Norm 1.3538(1.5615) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 131.2446, Epoch Time 1604.9609(1616.8738), Bit/dim 3.4997(best: 3.4982), Xent 2.6789, Loss 4.8392, Error 0.2896(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23050 | Time 28.0979(26.6216) | Bit/dim 3.4955(3.4955) | Xent 0.0150(0.0152) | Loss 3.5030(3.5031) | Error 0.0044(0.0044) Steps 1102(1108.32) | Grad Norm 1.1850(1.4914) | Total Time 14.00(14.00)\n",
      "Iter 23060 | Time 27.0911(26.6484) | Bit/dim 3.5217(3.4983) | Xent 0.0169(0.0148) | Loss 3.5302(3.5057) | Error 0.0033(0.0041) Steps 1120(1107.92) | Grad Norm 1.8781(1.4334) | Total Time 14.00(14.00)\n",
      "Iter 23070 | Time 26.6228(26.6981) | Bit/dim 3.4900(3.4965) | Xent 0.0174(0.0144) | Loss 3.4987(3.5037) | Error 0.0033(0.0039) Steps 1114(1109.68) | Grad Norm 1.2202(1.3998) | Total Time 14.00(14.00)\n",
      "Iter 23080 | Time 26.8021(26.7073) | Bit/dim 3.5032(3.4945) | Xent 0.0186(0.0150) | Loss 3.5125(3.5020) | Error 0.0044(0.0043) Steps 1102(1108.28) | Grad Norm 1.7083(1.3927) | Total Time 14.00(14.00)\n",
      "Iter 23090 | Time 27.1188(26.7096) | Bit/dim 3.5156(3.4922) | Xent 0.0083(0.0155) | Loss 3.5198(3.5000) | Error 0.0000(0.0044) Steps 1114(1107.73) | Grad Norm 1.3673(1.5171) | Total Time 14.00(14.00)\n",
      "Iter 23100 | Time 26.7558(26.7698) | Bit/dim 3.4839(3.4916) | Xent 0.0172(0.0155) | Loss 3.4925(3.4994) | Error 0.0044(0.0043) Steps 1114(1108.79) | Grad Norm 1.6313(1.5130) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 130.2592, Epoch Time 1623.3418(1617.0679), Bit/dim 3.4997(best: 3.4982), Xent 2.6626, Loss 4.8310, Error 0.2873(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23110 | Time 26.3587(26.7611) | Bit/dim 3.5012(3.4926) | Xent 0.0219(0.0160) | Loss 3.5121(3.5006) | Error 0.0078(0.0046) Steps 1102(1108.52) | Grad Norm 1.6961(1.5075) | Total Time 14.00(14.00)\n",
      "Iter 23120 | Time 26.6473(26.7291) | Bit/dim 3.5087(3.4952) | Xent 0.0153(0.0160) | Loss 3.5164(3.5032) | Error 0.0067(0.0045) Steps 1114(1108.27) | Grad Norm 1.0616(1.4585) | Total Time 14.00(14.00)\n",
      "Iter 23130 | Time 27.5833(26.7964) | Bit/dim 3.5219(3.4939) | Xent 0.0131(0.0163) | Loss 3.5284(3.5021) | Error 0.0056(0.0047) Steps 1102(1107.69) | Grad Norm 1.5052(1.5329) | Total Time 14.00(14.00)\n",
      "Iter 23140 | Time 27.3694(26.7528) | Bit/dim 3.4834(3.4929) | Xent 0.0151(0.0162) | Loss 3.4910(3.5010) | Error 0.0011(0.0045) Steps 1102(1107.27) | Grad Norm 1.9453(1.5744) | Total Time 14.00(14.00)\n",
      "Iter 23150 | Time 27.2937(26.7130) | Bit/dim 3.5079(3.4927) | Xent 0.0155(0.0160) | Loss 3.5156(3.5007) | Error 0.0022(0.0045) Steps 1102(1107.26) | Grad Norm 1.1278(1.5462) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 129.9128, Epoch Time 1614.8976(1617.0028), Bit/dim 3.4999(best: 3.4982), Xent 2.6579, Loss 4.8288, Error 0.2902(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23160 | Time 26.2261(26.6586) | Bit/dim 3.4732(3.4943) | Xent 0.0078(0.0153) | Loss 3.4771(3.5020) | Error 0.0011(0.0042) Steps 1108(1106.70) | Grad Norm 0.8153(1.4676) | Total Time 14.00(14.00)\n",
      "Iter 23170 | Time 26.4096(26.6290) | Bit/dim 3.5101(3.4944) | Xent 0.0168(0.0155) | Loss 3.5185(3.5021) | Error 0.0044(0.0043) Steps 1114(1107.72) | Grad Norm 1.7570(1.4770) | Total Time 14.00(14.00)\n",
      "Iter 23180 | Time 26.6384(26.5675) | Bit/dim 3.4978(3.4928) | Xent 0.0120(0.0154) | Loss 3.5038(3.5005) | Error 0.0033(0.0043) Steps 1102(1106.43) | Grad Norm 1.8092(1.5080) | Total Time 14.00(14.00)\n",
      "Iter 23190 | Time 26.7658(26.5154) | Bit/dim 3.5231(3.4926) | Xent 0.0171(0.0158) | Loss 3.5317(3.5005) | Error 0.0044(0.0044) Steps 1096(1105.78) | Grad Norm 2.1163(1.5429) | Total Time 14.00(14.00)\n",
      "Iter 23200 | Time 26.5523(26.5465) | Bit/dim 3.4876(3.4926) | Xent 0.0112(0.0153) | Loss 3.4932(3.5003) | Error 0.0033(0.0042) Steps 1084(1103.65) | Grad Norm 1.1715(1.4966) | Total Time 14.00(14.00)\n",
      "Iter 23210 | Time 26.3049(26.5041) | Bit/dim 3.5174(3.4939) | Xent 0.0081(0.0157) | Loss 3.5215(3.5018) | Error 0.0011(0.0046) Steps 1096(1103.07) | Grad Norm 0.9253(1.5148) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 130.1198, Epoch Time 1604.5456(1616.6290), Bit/dim 3.5003(best: 3.4982), Xent 2.7013, Loss 4.8509, Error 0.2864(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23220 | Time 26.8936(26.5907) | Bit/dim 3.4687(3.4926) | Xent 0.0157(0.0159) | Loss 3.4766(3.5006) | Error 0.0056(0.0046) Steps 1108(1102.67) | Grad Norm 1.6763(1.5725) | Total Time 14.00(14.00)\n",
      "Iter 23230 | Time 26.5607(26.5399) | Bit/dim 3.4860(3.4916) | Xent 0.0110(0.0154) | Loss 3.4915(3.4992) | Error 0.0022(0.0045) Steps 1108(1103.87) | Grad Norm 1.2456(1.5125) | Total Time 14.00(14.00)\n",
      "Iter 23240 | Time 26.7001(26.5608) | Bit/dim 3.5273(3.4919) | Xent 0.0212(0.0154) | Loss 3.5379(3.4996) | Error 0.0056(0.0044) Steps 1096(1104.88) | Grad Norm 1.6658(1.4651) | Total Time 14.00(14.00)\n",
      "Iter 23250 | Time 26.1167(26.5540) | Bit/dim 3.5061(3.4938) | Xent 0.0182(0.0154) | Loss 3.5152(3.5015) | Error 0.0044(0.0045) Steps 1108(1105.32) | Grad Norm 1.3829(1.4198) | Total Time 14.00(14.00)\n",
      "Iter 23260 | Time 26.5138(26.5982) | Bit/dim 3.4894(3.4959) | Xent 0.0126(0.0158) | Loss 3.4957(3.5038) | Error 0.0011(0.0045) Steps 1120(1106.77) | Grad Norm 1.1939(1.4195) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 130.5067, Epoch Time 1612.8793(1616.5166), Bit/dim 3.4983(best: 3.4982), Xent 2.6883, Loss 4.8425, Error 0.2867(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23270 | Time 27.1568(26.5956) | Bit/dim 3.4760(3.4925) | Xent 0.0214(0.0160) | Loss 3.4867(3.5005) | Error 0.0078(0.0046) Steps 1090(1105.87) | Grad Norm 2.0433(1.4321) | Total Time 14.00(14.00)\n",
      "Iter 23280 | Time 26.6185(26.5799) | Bit/dim 3.4589(3.4933) | Xent 0.0171(0.0157) | Loss 3.4675(3.5012) | Error 0.0078(0.0045) Steps 1108(1105.39) | Grad Norm 1.7363(1.4703) | Total Time 14.00(14.00)\n",
      "Iter 23290 | Time 27.3371(26.5936) | Bit/dim 3.4995(3.4964) | Xent 0.0124(0.0155) | Loss 3.5057(3.5041) | Error 0.0033(0.0044) Steps 1108(1106.09) | Grad Norm 1.3530(1.4710) | Total Time 14.00(14.00)\n",
      "Iter 23300 | Time 26.9229(26.5638) | Bit/dim 3.4942(3.4952) | Xent 0.0137(0.0152) | Loss 3.5010(3.5028) | Error 0.0056(0.0044) Steps 1096(1107.41) | Grad Norm 1.5232(1.3978) | Total Time 14.00(14.00)\n",
      "Iter 23310 | Time 26.6152(26.6079) | Bit/dim 3.5025(3.4928) | Xent 0.0158(0.0153) | Loss 3.5104(3.5004) | Error 0.0056(0.0044) Steps 1108(1106.34) | Grad Norm 1.7422(1.4328) | Total Time 14.00(14.00)\n",
      "Iter 23320 | Time 26.5728(26.5850) | Bit/dim 3.5238(3.4920) | Xent 0.0123(0.0153) | Loss 3.5300(3.4997) | Error 0.0033(0.0044) Steps 1096(1106.20) | Grad Norm 1.3482(1.4627) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 130.7772, Epoch Time 1610.4321(1616.3340), Bit/dim 3.4990(best: 3.4982), Xent 2.6770, Loss 4.8375, Error 0.2888(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23330 | Time 26.8641(26.6176) | Bit/dim 3.5160(3.4955) | Xent 0.0138(0.0147) | Loss 3.5229(3.5028) | Error 0.0033(0.0040) Steps 1102(1105.36) | Grad Norm 1.3428(1.4087) | Total Time 14.00(14.00)\n",
      "Iter 23340 | Time 26.8075(26.7090) | Bit/dim 3.4979(3.4956) | Xent 0.0130(0.0146) | Loss 3.5044(3.5029) | Error 0.0033(0.0039) Steps 1108(1106.65) | Grad Norm 1.8498(1.3999) | Total Time 14.00(14.00)\n",
      "Iter 23350 | Time 26.3834(26.6516) | Bit/dim 3.4628(3.4946) | Xent 0.0118(0.0148) | Loss 3.4687(3.5020) | Error 0.0022(0.0039) Steps 1114(1108.19) | Grad Norm 1.0386(1.4713) | Total Time 14.00(14.00)\n",
      "Iter 23360 | Time 26.6221(26.6035) | Bit/dim 3.4885(3.4922) | Xent 0.0183(0.0150) | Loss 3.4976(3.4998) | Error 0.0078(0.0043) Steps 1096(1106.64) | Grad Norm 1.7890(1.4992) | Total Time 14.00(14.00)\n",
      "Iter 23370 | Time 27.1574(26.5937) | Bit/dim 3.5128(3.4917) | Xent 0.0180(0.0148) | Loss 3.5218(3.4991) | Error 0.0056(0.0042) Steps 1108(1106.28) | Grad Norm 1.5586(1.4810) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 132.4630, Epoch Time 1615.8270(1616.3188), Bit/dim 3.4984(best: 3.4982), Xent 2.7183, Loss 4.8575, Error 0.2908(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23380 | Time 26.9492(26.5635) | Bit/dim 3.5151(3.4898) | Xent 0.0100(0.0149) | Loss 3.5201(3.4972) | Error 0.0022(0.0043) Steps 1108(1105.97) | Grad Norm 1.0919(1.4828) | Total Time 14.00(14.00)\n",
      "Iter 23390 | Time 26.2889(26.5367) | Bit/dim 3.5208(3.4896) | Xent 0.0113(0.0142) | Loss 3.5264(3.4967) | Error 0.0044(0.0040) Steps 1102(1107.52) | Grad Norm 1.0486(1.4034) | Total Time 14.00(14.00)\n",
      "Iter 23400 | Time 25.8675(26.5197) | Bit/dim 3.4848(3.4906) | Xent 0.0111(0.0152) | Loss 3.4904(3.4982) | Error 0.0033(0.0041) Steps 1114(1107.23) | Grad Norm 1.2812(1.4193) | Total Time 14.00(14.00)\n",
      "Iter 23410 | Time 26.9928(26.5542) | Bit/dim 3.4618(3.4922) | Xent 0.0136(0.0146) | Loss 3.4686(3.4996) | Error 0.0056(0.0042) Steps 1108(1106.48) | Grad Norm 1.3754(1.3723) | Total Time 14.00(14.00)\n",
      "Iter 23420 | Time 26.3833(26.5489) | Bit/dim 3.4885(3.4905) | Xent 0.0113(0.0147) | Loss 3.4942(3.4978) | Error 0.0022(0.0042) Steps 1108(1106.66) | Grad Norm 0.9008(1.3128) | Total Time 14.00(14.00)\n",
      "Iter 23430 | Time 26.5412(26.5950) | Bit/dim 3.4976(3.4940) | Xent 0.0158(0.0155) | Loss 3.5055(3.5018) | Error 0.0044(0.0044) Steps 1114(1108.19) | Grad Norm 1.7056(1.4439) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 131.1571, Epoch Time 1609.0311(1616.1002), Bit/dim 3.4998(best: 3.4982), Xent 2.6969, Loss 4.8482, Error 0.2905(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23440 | Time 26.1227(26.5428) | Bit/dim 3.4920(3.4956) | Xent 0.0097(0.0152) | Loss 3.4968(3.5032) | Error 0.0022(0.0043) Steps 1114(1108.32) | Grad Norm 1.0222(1.4588) | Total Time 14.00(14.00)\n",
      "Iter 23450 | Time 27.2615(26.5460) | Bit/dim 3.4954(3.4948) | Xent 0.0112(0.0156) | Loss 3.5010(3.5026) | Error 0.0022(0.0045) Steps 1096(1107.89) | Grad Norm 1.0952(1.4918) | Total Time 14.00(14.00)\n",
      "Iter 23460 | Time 27.4776(26.7328) | Bit/dim 3.4815(3.4934) | Xent 0.0106(0.0161) | Loss 3.4868(3.5014) | Error 0.0033(0.0050) Steps 1108(1109.29) | Grad Norm 1.0450(1.5423) | Total Time 14.00(14.00)\n",
      "Iter 23470 | Time 26.6308(26.7938) | Bit/dim 3.4990(3.4934) | Xent 0.0237(0.0168) | Loss 3.5109(3.5018) | Error 0.0089(0.0054) Steps 1126(1111.21) | Grad Norm 2.3013(1.6072) | Total Time 14.00(14.00)\n",
      "Iter 23480 | Time 27.1718(26.8147) | Bit/dim 3.4991(3.4930) | Xent 0.0106(0.0171) | Loss 3.5044(3.5015) | Error 0.0033(0.0054) Steps 1120(1110.31) | Grad Norm 1.3534(1.7420) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 131.8735, Epoch Time 1622.9008(1616.3042), Bit/dim 3.4994(best: 3.4982), Xent 2.6818, Loss 4.8403, Error 0.2848(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23490 | Time 26.7150(26.7780) | Bit/dim 3.4940(3.4932) | Xent 0.0126(0.0165) | Loss 3.5003(3.5014) | Error 0.0022(0.0049) Steps 1108(1110.64) | Grad Norm 1.4553(1.6810) | Total Time 14.00(14.00)\n",
      "Iter 23500 | Time 26.7639(26.7440) | Bit/dim 3.5249(3.4937) | Xent 0.0141(0.0161) | Loss 3.5320(3.5018) | Error 0.0056(0.0051) Steps 1114(1111.06) | Grad Norm 1.8322(1.6123) | Total Time 14.00(14.00)\n",
      "Iter 23510 | Time 26.9779(26.8213) | Bit/dim 3.4880(3.4932) | Xent 0.0287(0.0164) | Loss 3.5023(3.5014) | Error 0.0100(0.0049) Steps 1108(1111.01) | Grad Norm 3.8072(1.7102) | Total Time 14.00(14.00)\n",
      "Iter 23520 | Time 26.9335(26.9080) | Bit/dim 3.4841(3.4925) | Xent 0.0154(0.0167) | Loss 3.4918(3.5008) | Error 0.0033(0.0049) Steps 1096(1109.70) | Grad Norm 2.0348(1.8658) | Total Time 14.00(14.00)\n",
      "Iter 23530 | Time 27.1378(26.8403) | Bit/dim 3.4975(3.4912) | Xent 0.0222(0.0172) | Loss 3.5086(3.4998) | Error 0.0056(0.0049) Steps 1108(1109.80) | Grad Norm 2.0849(1.8726) | Total Time 14.00(14.00)\n",
      "Iter 23540 | Time 26.9894(26.8836) | Bit/dim 3.4905(3.4945) | Xent 0.0144(0.0172) | Loss 3.4977(3.5031) | Error 0.0033(0.0047) Steps 1120(1111.22) | Grad Norm 1.6579(1.7819) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 131.3754, Epoch Time 1628.0615(1616.6569), Bit/dim 3.4989(best: 3.4982), Xent 2.7068, Loss 4.8523, Error 0.2885(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23550 | Time 26.3967(26.8394) | Bit/dim 3.4741(3.4941) | Xent 0.0175(0.0168) | Loss 3.4829(3.5025) | Error 0.0056(0.0046) Steps 1084(1109.17) | Grad Norm 1.6236(1.7108) | Total Time 14.00(14.00)\n",
      "Iter 23560 | Time 25.9348(26.8325) | Bit/dim 3.4881(3.4921) | Xent 0.0089(0.0169) | Loss 3.4926(3.5006) | Error 0.0011(0.0048) Steps 1108(1109.79) | Grad Norm 0.9292(1.6489) | Total Time 14.00(14.00)\n",
      "Iter 23570 | Time 26.2678(26.7849) | Bit/dim 3.4803(3.4907) | Xent 0.0135(0.0158) | Loss 3.4871(3.4986) | Error 0.0044(0.0046) Steps 1114(1110.09) | Grad Norm 1.2785(1.5360) | Total Time 14.00(14.00)\n",
      "Iter 23580 | Time 26.4518(26.8042) | Bit/dim 3.4814(3.4922) | Xent 0.0146(0.0152) | Loss 3.4887(3.4998) | Error 0.0022(0.0043) Steps 1108(1109.79) | Grad Norm 1.2799(1.4190) | Total Time 14.00(14.00)\n",
      "Iter 23590 | Time 26.9704(26.7722) | Bit/dim 3.5137(3.4948) | Xent 0.0109(0.0152) | Loss 3.5191(3.5024) | Error 0.0022(0.0044) Steps 1114(1108.91) | Grad Norm 1.6765(1.4102) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 130.8618, Epoch Time 1619.5966(1616.7451), Bit/dim 3.4981(best: 3.4982), Xent 2.7024, Loss 4.8493, Error 0.2875(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23600 | Time 26.8643(26.7868) | Bit/dim 3.4980(3.4925) | Xent 0.0165(0.0153) | Loss 3.5063(3.5002) | Error 0.0011(0.0045) Steps 1108(1110.43) | Grad Norm 1.1835(1.4140) | Total Time 14.00(14.00)\n",
      "Iter 23610 | Time 27.2823(26.7952) | Bit/dim 3.4775(3.4923) | Xent 0.0207(0.0156) | Loss 3.4878(3.5001) | Error 0.0078(0.0048) Steps 1108(1111.00) | Grad Norm 1.8574(1.4365) | Total Time 14.00(14.00)\n",
      "Iter 23620 | Time 27.2916(26.8197) | Bit/dim 3.5063(3.4951) | Xent 0.0130(0.0154) | Loss 3.5128(3.5028) | Error 0.0033(0.0046) Steps 1108(1111.01) | Grad Norm 1.2808(1.4373) | Total Time 14.00(14.00)\n",
      "Iter 23630 | Time 26.8997(26.9216) | Bit/dim 3.4910(3.4936) | Xent 0.0188(0.0159) | Loss 3.5004(3.5016) | Error 0.0078(0.0049) Steps 1096(1109.58) | Grad Norm 1.6229(1.5547) | Total Time 14.00(14.00)\n",
      "Iter 23640 | Time 26.8335(26.9391) | Bit/dim 3.4996(3.4925) | Xent 0.0126(0.0157) | Loss 3.5059(3.5004) | Error 0.0044(0.0048) Steps 1120(1112.11) | Grad Norm 1.5238(1.5473) | Total Time 14.00(14.00)\n",
      "Iter 23650 | Time 26.7209(26.8433) | Bit/dim 3.5010(3.4937) | Xent 0.0098(0.0155) | Loss 3.5059(3.5015) | Error 0.0022(0.0048) Steps 1126(1112.27) | Grad Norm 1.1987(1.5457) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 132.0847, Epoch Time 1630.0365(1617.1438), Bit/dim 3.4980(best: 3.4981), Xent 2.6836, Loss 4.8398, Error 0.2889(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23660 | Time 26.6251(26.8865) | Bit/dim 3.4969(3.4953) | Xent 0.0156(0.0155) | Loss 3.5047(3.5030) | Error 0.0044(0.0047) Steps 1126(1113.14) | Grad Norm 1.7869(1.5466) | Total Time 14.00(14.00)\n",
      "Iter 23670 | Time 26.8762(26.9604) | Bit/dim 3.5250(3.4964) | Xent 0.0170(0.0158) | Loss 3.5335(3.5043) | Error 0.0044(0.0046) Steps 1126(1113.62) | Grad Norm 1.3141(1.5408) | Total Time 14.00(14.00)\n",
      "Iter 23680 | Time 27.2317(26.9734) | Bit/dim 3.4836(3.4942) | Xent 0.0107(0.0150) | Loss 3.4890(3.5017) | Error 0.0022(0.0042) Steps 1108(1113.60) | Grad Norm 1.0572(1.4673) | Total Time 14.00(14.00)\n",
      "Iter 23690 | Time 26.5295(27.0058) | Bit/dim 3.5141(3.4947) | Xent 0.0074(0.0150) | Loss 3.5178(3.5022) | Error 0.0000(0.0040) Steps 1108(1113.54) | Grad Norm 1.0226(1.4486) | Total Time 14.00(14.00)\n",
      "Iter 23700 | Time 26.5556(26.9370) | Bit/dim 3.4853(3.4913) | Xent 0.0159(0.0154) | Loss 3.4932(3.4990) | Error 0.0067(0.0042) Steps 1114(1114.68) | Grad Norm 1.4845(1.4867) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 132.1515, Epoch Time 1635.5112(1617.6949), Bit/dim 3.4973(best: 3.4980), Xent 2.7125, Loss 4.8536, Error 0.2891(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23710 | Time 27.1414(26.9332) | Bit/dim 3.4859(3.4906) | Xent 0.0148(0.0158) | Loss 3.4933(3.4985) | Error 0.0056(0.0044) Steps 1114(1113.30) | Grad Norm 1.2030(1.5696) | Total Time 14.00(14.00)\n",
      "Iter 23720 | Time 27.1245(26.9685) | Bit/dim 3.4644(3.4883) | Xent 0.0126(0.0158) | Loss 3.4707(3.4962) | Error 0.0022(0.0045) Steps 1114(1114.18) | Grad Norm 1.4145(1.5614) | Total Time 14.00(14.00)\n",
      "Iter 23730 | Time 27.7140(27.0341) | Bit/dim 3.4639(3.4907) | Xent 0.0180(0.0155) | Loss 3.4728(3.4984) | Error 0.0067(0.0044) Steps 1126(1114.86) | Grad Norm 2.4028(1.5661) | Total Time 14.00(14.00)\n",
      "Iter 23740 | Time 26.8434(27.0061) | Bit/dim 3.5327(3.4919) | Xent 0.0184(0.0158) | Loss 3.5419(3.4998) | Error 0.0067(0.0048) Steps 1126(1115.74) | Grad Norm 1.7871(1.6513) | Total Time 14.00(14.00)\n",
      "Iter 23750 | Time 27.0559(27.0634) | Bit/dim 3.4686(3.4924) | Xent 0.0157(0.0156) | Loss 3.4764(3.5002) | Error 0.0056(0.0046) Steps 1114(1115.37) | Grad Norm 1.2303(1.6212) | Total Time 14.00(14.00)\n",
      "Iter 23760 | Time 26.9144(27.0291) | Bit/dim 3.4989(3.4925) | Xent 0.0134(0.0163) | Loss 3.5056(3.5007) | Error 0.0022(0.0049) Steps 1120(1116.51) | Grad Norm 1.3423(1.6183) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 131.8849, Epoch Time 1637.9813(1618.3035), Bit/dim 3.4996(best: 3.4973), Xent 2.6921, Loss 4.8456, Error 0.2842(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23770 | Time 26.3637(26.9532) | Bit/dim 3.4905(3.4922) | Xent 0.0130(0.0165) | Loss 3.4970(3.5004) | Error 0.0033(0.0048) Steps 1126(1116.79) | Grad Norm 1.5789(1.6027) | Total Time 14.00(14.00)\n",
      "Iter 23780 | Time 25.7620(26.8690) | Bit/dim 3.4874(3.4904) | Xent 0.0190(0.0161) | Loss 3.4969(3.4984) | Error 0.0067(0.0046) Steps 1102(1114.97) | Grad Norm 2.1415(1.5887) | Total Time 14.00(14.00)\n",
      "Iter 23790 | Time 26.4290(26.8439) | Bit/dim 3.4901(3.4900) | Xent 0.0214(0.0159) | Loss 3.5008(3.4979) | Error 0.0078(0.0046) Steps 1114(1113.39) | Grad Norm 1.5949(1.5354) | Total Time 14.00(14.00)\n",
      "Iter 23800 | Time 26.7384(26.8763) | Bit/dim 3.5198(3.4927) | Xent 0.0145(0.0161) | Loss 3.5270(3.5008) | Error 0.0044(0.0046) Steps 1126(1113.85) | Grad Norm 1.3148(1.5271) | Total Time 14.00(14.00)\n",
      "Iter 23810 | Time 26.8474(26.9044) | Bit/dim 3.4977(3.4930) | Xent 0.0089(0.0156) | Loss 3.5021(3.5008) | Error 0.0022(0.0044) Steps 1108(1114.43) | Grad Norm 1.0837(1.5010) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 130.2445, Epoch Time 1625.6209(1618.5230), Bit/dim 3.4979(best: 3.4973), Xent 2.7087, Loss 4.8523, Error 0.2864(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23820 | Time 26.3527(26.8984) | Bit/dim 3.4772(3.4922) | Xent 0.0124(0.0157) | Loss 3.4833(3.5000) | Error 0.0022(0.0043) Steps 1108(1115.05) | Grad Norm 1.5787(1.5417) | Total Time 14.00(14.00)\n",
      "Iter 23830 | Time 26.4491(26.8879) | Bit/dim 3.4829(3.4930) | Xent 0.0118(0.0158) | Loss 3.4888(3.5009) | Error 0.0022(0.0046) Steps 1108(1114.06) | Grad Norm 1.2793(1.5332) | Total Time 14.00(14.00)\n",
      "Iter 23840 | Time 26.5496(26.7953) | Bit/dim 3.4847(3.4926) | Xent 0.0124(0.0151) | Loss 3.4909(3.5001) | Error 0.0022(0.0042) Steps 1114(1114.03) | Grad Norm 1.1095(1.4318) | Total Time 14.00(14.00)\n",
      "Iter 23850 | Time 26.2726(26.6969) | Bit/dim 3.4798(3.4916) | Xent 0.0138(0.0154) | Loss 3.4867(3.4993) | Error 0.0044(0.0046) Steps 1126(1112.88) | Grad Norm 1.8845(1.5100) | Total Time 14.00(14.00)\n",
      "Iter 23860 | Time 26.8872(26.7159) | Bit/dim 3.4985(3.4948) | Xent 0.0115(0.0156) | Loss 3.5042(3.5027) | Error 0.0011(0.0046) Steps 1114(1113.80) | Grad Norm 1.3212(1.5092) | Total Time 14.00(14.00)\n",
      "Iter 23870 | Time 26.6974(26.6693) | Bit/dim 3.5230(3.4927) | Xent 0.0220(0.0160) | Loss 3.5340(3.5007) | Error 0.0089(0.0049) Steps 1114(1113.66) | Grad Norm 1.8345(1.5110) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 131.2341, Epoch Time 1612.9798(1618.3567), Bit/dim 3.4992(best: 3.4973), Xent 2.7340, Loss 4.8662, Error 0.2882(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23880 | Time 27.2458(26.7569) | Bit/dim 3.4634(3.4944) | Xent 0.0249(0.0160) | Loss 3.4759(3.5023) | Error 0.0100(0.0048) Steps 1114(1114.21) | Grad Norm 1.8387(1.4836) | Total Time 14.00(14.00)\n",
      "Iter 23890 | Time 26.5303(26.7621) | Bit/dim 3.5146(3.4968) | Xent 0.0131(0.0151) | Loss 3.5212(3.5043) | Error 0.0022(0.0044) Steps 1108(1115.63) | Grad Norm 1.2132(1.4260) | Total Time 14.00(14.00)\n",
      "Iter 23900 | Time 25.9468(26.7229) | Bit/dim 3.4988(3.4937) | Xent 0.0132(0.0150) | Loss 3.5054(3.5012) | Error 0.0033(0.0044) Steps 1120(1115.43) | Grad Norm 1.3283(1.4256) | Total Time 14.00(14.00)\n",
      "Iter 23910 | Time 26.9089(26.7597) | Bit/dim 3.4781(3.4919) | Xent 0.0260(0.0150) | Loss 3.4911(3.4994) | Error 0.0089(0.0043) Steps 1102(1115.02) | Grad Norm 2.2739(1.4186) | Total Time 14.00(14.00)\n",
      "Iter 23920 | Time 27.4551(26.8062) | Bit/dim 3.4747(3.4908) | Xent 0.0142(0.0152) | Loss 3.4818(3.4984) | Error 0.0033(0.0045) Steps 1090(1112.77) | Grad Norm 1.3250(1.4035) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 131.7626, Epoch Time 1626.3692(1618.5971), Bit/dim 3.4977(best: 3.4973), Xent 2.7120, Loss 4.8537, Error 0.2864(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23930 | Time 26.0356(26.8179) | Bit/dim 3.4513(3.4902) | Xent 0.0140(0.0153) | Loss 3.4584(3.4979) | Error 0.0044(0.0045) Steps 1108(1111.70) | Grad Norm 1.3943(1.4446) | Total Time 14.00(14.00)\n",
      "Iter 23940 | Time 26.8842(26.8811) | Bit/dim 3.4741(3.4910) | Xent 0.0191(0.0154) | Loss 3.4837(3.4987) | Error 0.0089(0.0047) Steps 1102(1110.69) | Grad Norm 1.2354(1.4301) | Total Time 14.00(14.00)\n",
      "Iter 23950 | Time 27.1710(26.8861) | Bit/dim 3.4911(3.4907) | Xent 0.0123(0.0149) | Loss 3.4973(3.4982) | Error 0.0011(0.0045) Steps 1120(1111.56) | Grad Norm 1.4398(1.4185) | Total Time 14.00(14.00)\n",
      "Iter 23960 | Time 26.7151(26.8834) | Bit/dim 3.4895(3.4899) | Xent 0.0209(0.0152) | Loss 3.5000(3.4975) | Error 0.0089(0.0047) Steps 1102(1111.34) | Grad Norm 1.6253(1.4959) | Total Time 14.00(14.00)\n",
      "Iter 23970 | Time 26.3102(26.7916) | Bit/dim 3.5001(3.4905) | Xent 0.0172(0.0154) | Loss 3.5087(3.4982) | Error 0.0056(0.0049) Steps 1108(1112.02) | Grad Norm 2.8416(1.7074) | Total Time 14.00(14.00)\n",
      "Iter 23980 | Time 26.5777(26.7326) | Bit/dim 3.4964(3.4919) | Xent 0.0161(0.0152) | Loss 3.5044(3.4995) | Error 0.0033(0.0048) Steps 1126(1112.86) | Grad Norm 1.9077(1.7869) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 130.0812, Epoch Time 1621.5194(1618.6847), Bit/dim 3.4987(best: 3.4973), Xent 2.7223, Loss 4.8599, Error 0.2867(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23990 | Time 27.0031(26.7463) | Bit/dim 3.5249(3.4930) | Xent 0.0113(0.0146) | Loss 3.5306(3.5003) | Error 0.0033(0.0046) Steps 1120(1113.28) | Grad Norm 1.1375(1.8344) | Total Time 14.00(14.00)\n",
      "Iter 24000 | Time 26.6903(26.6875) | Bit/dim 3.4893(3.4916) | Xent 0.0188(0.0151) | Loss 3.4987(3.4991) | Error 0.0033(0.0046) Steps 1114(1113.59) | Grad Norm 2.3334(1.9639) | Total Time 14.00(14.00)\n",
      "Iter 24010 | Time 26.3510(26.6454) | Bit/dim 3.5084(3.4893) | Xent 0.0082(0.0147) | Loss 3.5124(3.4966) | Error 0.0022(0.0045) Steps 1108(1113.64) | Grad Norm 1.0046(1.8354) | Total Time 14.00(14.00)\n",
      "Iter 24020 | Time 26.6095(26.6144) | Bit/dim 3.4566(3.4889) | Xent 0.0186(0.0152) | Loss 3.4659(3.4965) | Error 0.0033(0.0045) Steps 1120(1113.45) | Grad Norm 1.3362(1.7051) | Total Time 14.00(14.00)\n",
      "Iter 24030 | Time 26.1425(26.6013) | Bit/dim 3.4870(3.4909) | Xent 0.0147(0.0151) | Loss 3.4943(3.4985) | Error 0.0044(0.0045) Steps 1108(1113.17) | Grad Norm 1.4350(1.6092) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 131.6546, Epoch Time 1613.2403(1618.5214), Bit/dim 3.4976(best: 3.4973), Xent 2.7421, Loss 4.8687, Error 0.2879(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24040 | Time 26.4075(26.6277) | Bit/dim 3.5129(3.4932) | Xent 0.0157(0.0151) | Loss 3.5207(3.5007) | Error 0.0044(0.0044) Steps 1102(1113.85) | Grad Norm 1.7331(1.5606) | Total Time 14.00(14.00)\n",
      "Iter 24050 | Time 26.3953(26.6357) | Bit/dim 3.4852(3.4947) | Xent 0.0175(0.0150) | Loss 3.4940(3.5022) | Error 0.0056(0.0043) Steps 1120(1114.48) | Grad Norm 1.7661(1.5941) | Total Time 14.00(14.00)\n",
      "Iter 24060 | Time 26.7702(26.6283) | Bit/dim 3.5073(3.4952) | Xent 0.0156(0.0147) | Loss 3.5151(3.5025) | Error 0.0067(0.0043) Steps 1132(1115.03) | Grad Norm 1.9188(1.5347) | Total Time 14.00(14.00)\n",
      "Iter 24070 | Time 26.5108(26.6085) | Bit/dim 3.5146(3.4953) | Xent 0.0071(0.0149) | Loss 3.5182(3.5027) | Error 0.0011(0.0043) Steps 1114(1116.19) | Grad Norm 0.9770(1.4898) | Total Time 14.00(14.00)\n",
      "Iter 24080 | Time 27.1383(26.6589) | Bit/dim 3.4705(3.4944) | Xent 0.0136(0.0154) | Loss 3.4773(3.5021) | Error 0.0033(0.0045) Steps 1108(1116.40) | Grad Norm 1.4830(1.5085) | Total Time 14.00(14.00)\n",
      "Iter 24090 | Time 26.4680(26.6429) | Bit/dim 3.4900(3.4904) | Xent 0.0090(0.0160) | Loss 3.4945(3.4985) | Error 0.0011(0.0050) Steps 1120(1115.63) | Grad Norm 1.0258(1.5774) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 131.6123, Epoch Time 1614.7806(1618.4092), Bit/dim 3.4974(best: 3.4973), Xent 2.7316, Loss 4.8632, Error 0.2895(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24100 | Time 26.7326(26.5879) | Bit/dim 3.4699(3.4913) | Xent 0.0167(0.0161) | Loss 3.4782(3.4993) | Error 0.0067(0.0052) Steps 1114(1115.14) | Grad Norm 1.7170(1.5831) | Total Time 14.00(14.00)\n",
      "Iter 24110 | Time 27.0648(26.5968) | Bit/dim 3.5026(3.4927) | Xent 0.0130(0.0159) | Loss 3.5091(3.5007) | Error 0.0033(0.0050) Steps 1114(1115.24) | Grad Norm 1.1398(1.5251) | Total Time 14.00(14.00)\n",
      "Iter 24120 | Time 26.9569(26.6145) | Bit/dim 3.5101(3.4926) | Xent 0.0144(0.0155) | Loss 3.5173(3.5003) | Error 0.0044(0.0049) Steps 1114(1114.92) | Grad Norm 1.6437(1.4704) | Total Time 14.00(14.00)\n",
      "Iter 24130 | Time 26.3961(26.6185) | Bit/dim 3.4873(3.4905) | Xent 0.0253(0.0166) | Loss 3.4999(3.4987) | Error 0.0078(0.0053) Steps 1120(1116.07) | Grad Norm 1.8774(1.5795) | Total Time 14.00(14.00)\n",
      "Iter 24140 | Time 27.0406(26.6377) | Bit/dim 3.5272(3.4916) | Xent 0.0148(0.0159) | Loss 3.5347(3.4996) | Error 0.0033(0.0048) Steps 1120(1115.88) | Grad Norm 1.4906(1.5611) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 131.6142, Epoch Time 1614.8221(1618.3016), Bit/dim 3.4979(best: 3.4973), Xent 2.6824, Loss 4.8391, Error 0.2873(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24150 | Time 26.9287(26.7259) | Bit/dim 3.5010(3.4937) | Xent 0.0062(0.0156) | Loss 3.5041(3.5015) | Error 0.0011(0.0046) Steps 1120(1115.77) | Grad Norm 1.0841(1.4965) | Total Time 14.00(14.00)\n",
      "Iter 24160 | Time 26.6902(26.7203) | Bit/dim 3.4830(3.4910) | Xent 0.0148(0.0155) | Loss 3.4904(3.4987) | Error 0.0033(0.0045) Steps 1120(1114.93) | Grad Norm 1.0871(1.4891) | Total Time 14.00(14.00)\n",
      "Iter 24170 | Time 26.7933(26.7300) | Bit/dim 3.4794(3.4910) | Xent 0.0146(0.0158) | Loss 3.4868(3.4990) | Error 0.0033(0.0045) Steps 1108(1114.85) | Grad Norm 1.3179(1.5318) | Total Time 14.00(14.00)\n",
      "Iter 24180 | Time 26.4199(26.6845) | Bit/dim 3.4811(3.4915) | Xent 0.0148(0.0156) | Loss 3.4885(3.4992) | Error 0.0056(0.0046) Steps 1108(1113.81) | Grad Norm 1.2881(1.5219) | Total Time 14.00(14.00)\n",
      "Iter 24190 | Time 26.7720(26.7080) | Bit/dim 3.4867(3.4905) | Xent 0.0243(0.0159) | Loss 3.4988(3.4985) | Error 0.0100(0.0049) Steps 1090(1113.23) | Grad Norm 2.4653(1.5392) | Total Time 14.00(14.00)\n",
      "Iter 24200 | Time 27.1243(26.7571) | Bit/dim 3.5054(3.4913) | Xent 0.0085(0.0157) | Loss 3.5096(3.4991) | Error 0.0022(0.0046) Steps 1126(1113.12) | Grad Norm 0.9876(1.4853) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 130.2679, Epoch Time 1619.9434(1618.3508), Bit/dim 3.4972(best: 3.4973), Xent 2.7424, Loss 4.8684, Error 0.2890(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24210 | Time 27.2999(26.7507) | Bit/dim 3.4970(3.4915) | Xent 0.0125(0.0152) | Loss 3.5032(3.4991) | Error 0.0044(0.0045) Steps 1114(1113.65) | Grad Norm 1.1031(1.4479) | Total Time 14.00(14.00)\n",
      "Iter 24220 | Time 26.8440(26.7879) | Bit/dim 3.4846(3.4913) | Xent 0.0128(0.0158) | Loss 3.4910(3.4992) | Error 0.0033(0.0051) Steps 1120(1115.07) | Grad Norm 1.3194(1.5113) | Total Time 14.00(14.00)\n",
      "Iter 24230 | Time 26.8063(26.7793) | Bit/dim 3.5165(3.4931) | Xent 0.0109(0.0160) | Loss 3.5220(3.5011) | Error 0.0022(0.0049) Steps 1126(1114.65) | Grad Norm 1.0640(1.5237) | Total Time 14.00(14.00)\n",
      "Iter 24240 | Time 26.8601(26.7706) | Bit/dim 3.4947(3.4921) | Xent 0.0164(0.0152) | Loss 3.5029(3.4997) | Error 0.0078(0.0047) Steps 1132(1115.56) | Grad Norm 1.6599(1.4564) | Total Time 14.00(14.00)\n",
      "Iter 24250 | Time 26.9817(26.7532) | Bit/dim 3.4895(3.4915) | Xent 0.0191(0.0152) | Loss 3.4991(3.4990) | Error 0.0056(0.0047) Steps 1108(1113.76) | Grad Norm 1.5417(1.4649) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 131.9555, Epoch Time 1622.0060(1618.4605), Bit/dim 3.4975(best: 3.4972), Xent 2.7399, Loss 4.8675, Error 0.2872(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24260 | Time 26.3232(26.7477) | Bit/dim 3.4957(3.4918) | Xent 0.0108(0.0153) | Loss 3.5011(3.4994) | Error 0.0022(0.0047) Steps 1114(1114.31) | Grad Norm 1.1732(1.4488) | Total Time 14.00(14.00)\n",
      "Iter 24270 | Time 27.2826(26.7924) | Bit/dim 3.4805(3.4904) | Xent 0.0172(0.0154) | Loss 3.4891(3.4981) | Error 0.0033(0.0047) Steps 1126(1115.94) | Grad Norm 1.9502(1.5004) | Total Time 14.00(14.00)\n",
      "Iter 24280 | Time 26.6662(26.8241) | Bit/dim 3.4854(3.4903) | Xent 0.0106(0.0153) | Loss 3.4907(3.4980) | Error 0.0033(0.0047) Steps 1120(1116.14) | Grad Norm 0.8964(1.5122) | Total Time 14.00(14.00)\n",
      "Iter 24290 | Time 27.1937(26.8519) | Bit/dim 3.4905(3.4911) | Xent 0.0106(0.0154) | Loss 3.4958(3.4988) | Error 0.0022(0.0047) Steps 1114(1116.39) | Grad Norm 1.2877(1.5074) | Total Time 14.00(14.00)\n",
      "Iter 24300 | Time 27.1764(26.8508) | Bit/dim 3.5000(3.4921) | Xent 0.0246(0.0152) | Loss 3.5123(3.4997) | Error 0.0089(0.0045) Steps 1120(1116.60) | Grad Norm 2.1814(1.5479) | Total Time 14.00(14.00)\n",
      "Iter 24310 | Time 26.8499(26.8956) | Bit/dim 3.4861(3.4920) | Xent 0.0103(0.0142) | Loss 3.4912(3.4991) | Error 0.0022(0.0040) Steps 1114(1117.34) | Grad Norm 1.6256(1.4663) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 133.0012, Epoch Time 1630.2208(1618.8133), Bit/dim 3.4964(best: 3.4972), Xent 2.7024, Loss 4.8476, Error 0.2878(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24320 | Time 26.8641(26.9230) | Bit/dim 3.4919(3.4908) | Xent 0.0170(0.0149) | Loss 3.5003(3.4983) | Error 0.0044(0.0042) Steps 1108(1117.17) | Grad Norm 2.1622(1.6045) | Total Time 14.00(14.00)\n",
      "Iter 24330 | Time 26.4684(26.9201) | Bit/dim 3.5009(3.4929) | Xent 0.0187(0.0150) | Loss 3.5103(3.5004) | Error 0.0033(0.0043) Steps 1126(1116.98) | Grad Norm 2.9636(1.6970) | Total Time 14.00(14.00)\n",
      "Iter 24340 | Time 26.4691(26.9207) | Bit/dim 3.4651(3.4907) | Xent 0.0157(0.0151) | Loss 3.4730(3.4982) | Error 0.0056(0.0044) Steps 1114(1116.73) | Grad Norm 1.7116(1.7802) | Total Time 14.00(14.00)\n",
      "Iter 24350 | Time 27.2164(26.9587) | Bit/dim 3.4955(3.4927) | Xent 0.0160(0.0152) | Loss 3.5035(3.5003) | Error 0.0056(0.0046) Steps 1126(1117.94) | Grad Norm 1.5205(1.7666) | Total Time 14.00(14.00)\n",
      "Iter 24360 | Time 26.4837(26.9432) | Bit/dim 3.4987(3.4924) | Xent 0.0143(0.0153) | Loss 3.5058(3.5001) | Error 0.0056(0.0046) Steps 1114(1117.59) | Grad Norm 1.5825(1.7039) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 132.8455, Epoch Time 1632.7536(1619.2315), Bit/dim 3.4977(best: 3.4964), Xent 2.7357, Loss 4.8655, Error 0.2882(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24370 | Time 27.5566(26.9364) | Bit/dim 3.5360(3.4923) | Xent 0.0153(0.0159) | Loss 3.5436(3.5003) | Error 0.0056(0.0049) Steps 1120(1117.06) | Grad Norm 1.3532(1.6811) | Total Time 14.00(14.00)\n",
      "Iter 24380 | Time 27.3832(26.9305) | Bit/dim 3.5004(3.4910) | Xent 0.0227(0.0156) | Loss 3.5118(3.4988) | Error 0.0044(0.0047) Steps 1120(1116.80) | Grad Norm 1.7539(1.5895) | Total Time 14.00(14.00)\n",
      "Iter 24390 | Time 27.0264(26.9801) | Bit/dim 3.5164(3.4915) | Xent 0.0077(0.0154) | Loss 3.5202(3.4992) | Error 0.0011(0.0044) Steps 1120(1117.21) | Grad Norm 1.5229(1.6267) | Total Time 14.00(14.00)\n",
      "Iter 24400 | Time 27.2021(27.0115) | Bit/dim 3.4813(3.4909) | Xent 0.0205(0.0162) | Loss 3.4915(3.4990) | Error 0.0078(0.0050) Steps 1126(1117.05) | Grad Norm 2.0192(1.6879) | Total Time 14.00(14.00)\n",
      "Iter 24410 | Time 26.2379(26.9631) | Bit/dim 3.4772(3.4933) | Xent 0.0219(0.0169) | Loss 3.4882(3.5017) | Error 0.0033(0.0050) Steps 1120(1116.57) | Grad Norm 1.9540(1.8131) | Total Time 14.00(14.00)\n",
      "Iter 24420 | Time 26.2241(26.8290) | Bit/dim 3.4921(3.4905) | Xent 0.0220(0.0168) | Loss 3.5031(3.4989) | Error 0.0078(0.0050) Steps 1114(1116.17) | Grad Norm 2.6488(1.7841) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 131.5168, Epoch Time 1628.7325(1619.5165), Bit/dim 3.4969(best: 3.4964), Xent 2.7839, Loss 4.8889, Error 0.2879(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24430 | Time 27.3270(26.8587) | Bit/dim 3.5304(3.4907) | Xent 0.0273(0.0169) | Loss 3.5440(3.4991) | Error 0.0056(0.0049) Steps 1120(1116.91) | Grad Norm 1.9061(1.7853) | Total Time 14.00(14.00)\n",
      "Iter 24440 | Time 26.9987(26.8444) | Bit/dim 3.4828(3.4927) | Xent 0.0115(0.0169) | Loss 3.4885(3.5011) | Error 0.0033(0.0049) Steps 1138(1117.36) | Grad Norm 2.0382(1.7757) | Total Time 14.00(14.00)\n",
      "Iter 24450 | Time 26.4476(26.8093) | Bit/dim 3.4938(3.4936) | Xent 0.0351(0.0173) | Loss 3.5113(3.5023) | Error 0.0078(0.0051) Steps 1114(1116.71) | Grad Norm 2.3275(1.7411) | Total Time 14.00(14.00)\n",
      "Iter 24460 | Time 26.9161(26.8229) | Bit/dim 3.4749(3.4964) | Xent 0.0179(0.0170) | Loss 3.4838(3.5049) | Error 0.0044(0.0049) Steps 1108(1116.47) | Grad Norm 2.5695(1.8621) | Total Time 14.00(14.00)\n",
      "Iter 24470 | Time 27.3301(26.8240) | Bit/dim 3.4549(3.4924) | Xent 0.0427(0.0175) | Loss 3.4762(3.5012) | Error 0.0144(0.0051) Steps 1102(1116.93) | Grad Norm 4.5122(1.9815) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 131.1864, Epoch Time 1625.4073(1619.6932), Bit/dim 3.4974(best: 3.4964), Xent 2.7175, Loss 4.8561, Error 0.2832(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24480 | Time 26.6250(26.7948) | Bit/dim 3.5110(3.4923) | Xent 0.0154(0.0167) | Loss 3.5187(3.5007) | Error 0.0056(0.0048) Steps 1114(1117.19) | Grad Norm 1.4618(1.8931) | Total Time 14.00(14.00)\n",
      "Iter 24490 | Time 27.0688(26.7685) | Bit/dim 3.5226(3.4927) | Xent 0.0109(0.0167) | Loss 3.5280(3.5011) | Error 0.0022(0.0050) Steps 1114(1116.70) | Grad Norm 1.1046(1.7758) | Total Time 14.00(14.00)\n",
      "Iter 24500 | Time 26.8942(26.7984) | Bit/dim 3.4715(3.4909) | Xent 0.0149(0.0164) | Loss 3.4789(3.4991) | Error 0.0033(0.0047) Steps 1120(1117.20) | Grad Norm 1.8271(1.7330) | Total Time 14.00(14.00)\n",
      "Iter 24510 | Time 27.4944(26.7929) | Bit/dim 3.5085(3.4909) | Xent 0.0174(0.0166) | Loss 3.5172(3.4992) | Error 0.0033(0.0049) Steps 1120(1116.52) | Grad Norm 2.1774(1.7616) | Total Time 14.00(14.00)\n",
      "Iter 24520 | Time 26.8819(26.8823) | Bit/dim 3.5207(3.4914) | Xent 0.0147(0.0163) | Loss 3.5280(3.4996) | Error 0.0044(0.0049) Steps 1114(1116.17) | Grad Norm 2.4652(1.7860) | Total Time 14.00(14.00)\n",
      "Iter 24530 | Time 26.4762(26.8549) | Bit/dim 3.4568(3.4904) | Xent 0.0110(0.0162) | Loss 3.4623(3.4985) | Error 0.0022(0.0047) Steps 1114(1114.94) | Grad Norm 1.3076(1.7347) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 130.2852, Epoch Time 1623.1649(1619.7974), Bit/dim 3.4957(best: 3.4964), Xent 2.7622, Loss 4.8768, Error 0.2891(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24540 | Time 26.6522(26.8067) | Bit/dim 3.4848(3.4903) | Xent 0.0219(0.0160) | Loss 3.4958(3.4983) | Error 0.0078(0.0047) Steps 1132(1116.97) | Grad Norm 1.9206(1.7084) | Total Time 14.00(14.00)\n",
      "Iter 24550 | Time 27.3300(26.8387) | Bit/dim 3.4805(3.4907) | Xent 0.0148(0.0156) | Loss 3.4879(3.4985) | Error 0.0033(0.0046) Steps 1120(1116.65) | Grad Norm 1.2709(1.6125) | Total Time 14.00(14.00)\n",
      "Iter 24560 | Time 26.7037(26.8311) | Bit/dim 3.4953(3.4890) | Xent 0.0095(0.0148) | Loss 3.5000(3.4964) | Error 0.0011(0.0041) Steps 1108(1114.35) | Grad Norm 1.1695(1.5653) | Total Time 14.00(14.00)\n",
      "Iter 24570 | Time 25.7278(26.7914) | Bit/dim 3.4552(3.4911) | Xent 0.0106(0.0148) | Loss 3.4605(3.4986) | Error 0.0022(0.0042) Steps 1102(1113.72) | Grad Norm 1.1415(1.5107) | Total Time 14.00(14.00)\n",
      "Iter 24580 | Time 27.1902(26.7499) | Bit/dim 3.5116(3.4899) | Xent 0.0157(0.0147) | Loss 3.5194(3.4973) | Error 0.0044(0.0042) Steps 1126(1114.79) | Grad Norm 1.6099(1.4932) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 131.9880, Epoch Time 1620.8283(1619.8283), Bit/dim 3.4959(best: 3.4957), Xent 2.7335, Loss 4.8627, Error 0.2860(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24590 | Time 26.6281(26.7373) | Bit/dim 3.5043(3.4931) | Xent 0.0062(0.0143) | Loss 3.5074(3.5002) | Error 0.0011(0.0042) Steps 1108(1115.84) | Grad Norm 1.0278(1.5078) | Total Time 14.00(14.00)\n",
      "Iter 24600 | Time 27.3846(26.8067) | Bit/dim 3.4657(3.4886) | Xent 0.0189(0.0143) | Loss 3.4751(3.4958) | Error 0.0033(0.0040) Steps 1108(1115.21) | Grad Norm 1.2982(1.5931) | Total Time 14.00(14.00)\n",
      "Iter 24610 | Time 27.1023(26.9200) | Bit/dim 3.4885(3.4920) | Xent 0.0183(0.0148) | Loss 3.4976(3.4994) | Error 0.0056(0.0040) Steps 1120(1114.78) | Grad Norm 1.3264(1.5587) | Total Time 14.00(14.00)\n",
      "Iter 24620 | Time 26.4322(26.9250) | Bit/dim 3.4968(3.4924) | Xent 0.0116(0.0149) | Loss 3.5026(3.4999) | Error 0.0011(0.0042) Steps 1114(1115.36) | Grad Norm 0.8159(1.5225) | Total Time 14.00(14.00)\n",
      "Iter 24630 | Time 26.5440(26.8699) | Bit/dim 3.5062(3.4915) | Xent 0.0221(0.0148) | Loss 3.5172(3.4988) | Error 0.0067(0.0044) Steps 1114(1115.32) | Grad Norm 3.1155(1.5925) | Total Time 14.00(14.00)\n",
      "Iter 24640 | Time 27.1031(26.8448) | Bit/dim 3.5010(3.4912) | Xent 0.0170(0.0147) | Loss 3.5095(3.4986) | Error 0.0033(0.0044) Steps 1120(1115.12) | Grad Norm 1.5215(1.5812) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 131.4650, Epoch Time 1629.2871(1620.1121), Bit/dim 3.4958(best: 3.4957), Xent 2.7334, Loss 4.8625, Error 0.2878(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24650 | Time 26.9924(26.9295) | Bit/dim 3.5008(3.4905) | Xent 0.0236(0.0148) | Loss 3.5126(3.4979) | Error 0.0089(0.0044) Steps 1120(1114.66) | Grad Norm 2.6703(1.5379) | Total Time 14.00(14.00)\n",
      "Iter 24660 | Time 26.6120(26.8949) | Bit/dim 3.4853(3.4910) | Xent 0.0111(0.0146) | Loss 3.4909(3.4983) | Error 0.0044(0.0044) Steps 1108(1114.89) | Grad Norm 1.1920(1.5726) | Total Time 14.00(14.00)\n",
      "Iter 24670 | Time 27.0039(26.8420) | Bit/dim 3.4913(3.4913) | Xent 0.0286(0.0149) | Loss 3.5055(3.4987) | Error 0.0089(0.0045) Steps 1114(1115.28) | Grad Norm 1.7956(1.5818) | Total Time 14.00(14.00)\n",
      "Iter 24680 | Time 26.4801(26.8382) | Bit/dim 3.4786(3.4890) | Xent 0.0138(0.0150) | Loss 3.4855(3.4965) | Error 0.0033(0.0043) Steps 1120(1114.86) | Grad Norm 1.3410(1.5400) | Total Time 14.00(14.00)\n",
      "Iter 24690 | Time 26.5299(26.8458) | Bit/dim 3.5319(3.4916) | Xent 0.0105(0.0150) | Loss 3.5371(3.4991) | Error 0.0033(0.0045) Steps 1102(1115.02) | Grad Norm 1.9365(1.5996) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 132.6082, Epoch Time 1629.1290(1620.3826), Bit/dim 3.4973(best: 3.4957), Xent 2.7517, Loss 4.8731, Error 0.2882(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24700 | Time 27.3071(26.8635) | Bit/dim 3.4900(3.4921) | Xent 0.0131(0.0149) | Loss 3.4965(3.4996) | Error 0.0044(0.0045) Steps 1120(1114.74) | Grad Norm 1.6188(1.5624) | Total Time 14.00(14.00)\n",
      "Iter 24710 | Time 27.8127(26.9730) | Bit/dim 3.4929(3.4929) | Xent 0.0101(0.0156) | Loss 3.4980(3.5007) | Error 0.0022(0.0044) Steps 1126(1115.36) | Grad Norm 1.6492(1.6314) | Total Time 14.00(14.00)\n",
      "Iter 24720 | Time 26.6859(27.0007) | Bit/dim 3.4869(3.4909) | Xent 0.0130(0.0157) | Loss 3.4934(3.4988) | Error 0.0033(0.0044) Steps 1108(1114.50) | Grad Norm 1.2270(1.7164) | Total Time 14.00(14.00)\n",
      "Iter 24730 | Time 27.6744(26.9901) | Bit/dim 3.4928(3.4905) | Xent 0.0099(0.0159) | Loss 3.4977(3.4985) | Error 0.0022(0.0048) Steps 1126(1114.87) | Grad Norm 1.5409(1.7697) | Total Time 14.00(14.00)\n",
      "Iter 24740 | Time 26.8511(27.0700) | Bit/dim 3.4588(3.4893) | Xent 0.0164(0.0160) | Loss 3.4670(3.4973) | Error 0.0056(0.0049) Steps 1114(1114.46) | Grad Norm 1.5723(1.7277) | Total Time 14.00(14.00)\n",
      "Iter 24750 | Time 27.2948(27.0747) | Bit/dim 3.4967(3.4915) | Xent 0.0087(0.0155) | Loss 3.5010(3.4992) | Error 0.0022(0.0047) Steps 1120(1114.60) | Grad Norm 1.0181(1.6427) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 131.7450, Epoch Time 1640.7131(1620.9925), Bit/dim 3.4963(best: 3.4957), Xent 2.7877, Loss 4.8902, Error 0.2905(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24760 | Time 26.1996(27.0325) | Bit/dim 3.4807(3.4914) | Xent 0.0076(0.0157) | Loss 3.4845(3.4992) | Error 0.0000(0.0049) Steps 1114(1116.03) | Grad Norm 1.1875(1.6519) | Total Time 14.00(14.00)\n",
      "Iter 24770 | Time 27.1404(26.9908) | Bit/dim 3.5326(3.4904) | Xent 0.0088(0.0155) | Loss 3.5370(3.4981) | Error 0.0022(0.0047) Steps 1120(1116.66) | Grad Norm 1.3815(1.6559) | Total Time 14.00(14.00)\n",
      "Iter 24780 | Time 26.7414(26.9728) | Bit/dim 3.4817(3.4910) | Xent 0.0105(0.0156) | Loss 3.4869(3.4988) | Error 0.0033(0.0047) Steps 1114(1117.66) | Grad Norm 1.2722(1.7299) | Total Time 14.00(14.00)\n",
      "Iter 24790 | Time 26.8711(26.8967) | Bit/dim 3.5326(3.4922) | Xent 0.0158(0.0155) | Loss 3.5405(3.4999) | Error 0.0044(0.0047) Steps 1102(1116.14) | Grad Norm 1.7179(1.6680) | Total Time 14.00(14.00)\n",
      "Iter 24800 | Time 26.8082(26.8347) | Bit/dim 3.4948(3.4908) | Xent 0.0123(0.0161) | Loss 3.5010(3.4988) | Error 0.0022(0.0048) Steps 1108(1115.73) | Grad Norm 1.2848(1.7153) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 132.2843, Epoch Time 1622.8688(1621.0488), Bit/dim 3.4972(best: 3.4957), Xent 2.7567, Loss 4.8755, Error 0.2854(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24810 | Time 26.7246(26.7670) | Bit/dim 3.4759(3.4910) | Xent 0.0134(0.0156) | Loss 3.4825(3.4988) | Error 0.0022(0.0045) Steps 1114(1116.08) | Grad Norm 2.0522(1.7172) | Total Time 14.00(14.00)\n",
      "Iter 24820 | Time 26.2925(26.7863) | Bit/dim 3.4645(3.4902) | Xent 0.0127(0.0156) | Loss 3.4708(3.4980) | Error 0.0056(0.0048) Steps 1120(1116.11) | Grad Norm 1.1756(1.6828) | Total Time 14.00(14.00)\n",
      "Iter 24830 | Time 27.4744(26.7793) | Bit/dim 3.5167(3.4899) | Xent 0.0120(0.0149) | Loss 3.5227(3.4973) | Error 0.0033(0.0043) Steps 1120(1115.79) | Grad Norm 1.3348(1.5757) | Total Time 14.00(14.00)\n",
      "Iter 24840 | Time 26.6036(26.7932) | Bit/dim 3.4818(3.4898) | Xent 0.0222(0.0151) | Loss 3.4929(3.4974) | Error 0.0089(0.0046) Steps 1126(1114.29) | Grad Norm 1.4686(1.5390) | Total Time 14.00(14.00)\n",
      "Iter 24850 | Time 26.9090(26.8262) | Bit/dim 3.4775(3.4899) | Xent 0.0156(0.0155) | Loss 3.4853(3.4977) | Error 0.0033(0.0046) Steps 1132(1114.99) | Grad Norm 1.9159(1.5713) | Total Time 14.00(14.00)\n",
      "Iter 24860 | Time 26.8370(26.8361) | Bit/dim 3.5041(3.4924) | Xent 0.0269(0.0164) | Loss 3.5175(3.5006) | Error 0.0078(0.0049) Steps 1108(1113.77) | Grad Norm 2.3962(1.6872) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 130.2424, Epoch Time 1623.6531(1621.1269), Bit/dim 3.4969(best: 3.4957), Xent 2.7727, Loss 4.8833, Error 0.2881(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24870 | Time 26.7683(26.8008) | Bit/dim 3.4745(3.4918) | Xent 0.0173(0.0167) | Loss 3.4832(3.5002) | Error 0.0044(0.0049) Steps 1114(1113.91) | Grad Norm 2.6975(1.7710) | Total Time 14.00(14.00)\n",
      "Iter 24880 | Time 27.5657(26.9473) | Bit/dim 3.4738(3.4926) | Xent 0.0253(0.0171) | Loss 3.4865(3.5011) | Error 0.0067(0.0049) Steps 1126(1115.38) | Grad Norm 4.0355(1.9220) | Total Time 14.00(14.00)\n",
      "Iter 24890 | Time 26.4442(26.9080) | Bit/dim 3.4710(3.4890) | Xent 0.0252(0.0171) | Loss 3.4836(3.4976) | Error 0.0100(0.0049) Steps 1108(1115.72) | Grad Norm 2.0935(2.0010) | Total Time 14.00(14.00)\n",
      "Iter 24900 | Time 26.9286(26.9017) | Bit/dim 3.4863(3.4890) | Xent 0.0130(0.0160) | Loss 3.4928(3.4970) | Error 0.0033(0.0044) Steps 1108(1114.71) | Grad Norm 1.4592(1.9984) | Total Time 14.00(14.00)\n",
      "Iter 24910 | Time 27.2848(26.9842) | Bit/dim 3.5168(3.4928) | Xent 0.0219(0.0163) | Loss 3.5278(3.5010) | Error 0.0067(0.0048) Steps 1126(1114.45) | Grad Norm 1.8609(1.9308) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 131.7205, Epoch Time 1632.9980(1621.4831), Bit/dim 3.4955(best: 3.4957), Xent 2.7934, Loss 4.8922, Error 0.2904(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24920 | Time 26.4293(26.9453) | Bit/dim 3.4862(3.4921) | Xent 0.0172(0.0165) | Loss 3.4948(3.5004) | Error 0.0056(0.0048) Steps 1114(1114.49) | Grad Norm 1.6289(1.8489) | Total Time 14.00(14.00)\n",
      "Iter 24930 | Time 26.8456(26.9407) | Bit/dim 3.5024(3.4934) | Xent 0.0084(0.0154) | Loss 3.5066(3.5011) | Error 0.0011(0.0043) Steps 1114(1115.25) | Grad Norm 1.2946(1.7482) | Total Time 14.00(14.00)\n",
      "Iter 24940 | Time 26.8473(26.9517) | Bit/dim 3.4964(3.4949) | Xent 0.0073(0.0150) | Loss 3.5001(3.5024) | Error 0.0011(0.0043) Steps 1120(1115.10) | Grad Norm 0.7050(1.6568) | Total Time 14.00(14.00)\n",
      "Iter 24950 | Time 26.4977(26.8957) | Bit/dim 3.5240(3.4954) | Xent 0.0094(0.0153) | Loss 3.5286(3.5031) | Error 0.0011(0.0045) Steps 1108(1114.66) | Grad Norm 1.2286(1.6963) | Total Time 14.00(14.00)\n",
      "Iter 24960 | Time 26.3356(26.8438) | Bit/dim 3.4724(3.4926) | Xent 0.0119(0.0155) | Loss 3.4783(3.5003) | Error 0.0033(0.0046) Steps 1132(1116.19) | Grad Norm 1.6716(1.7431) | Total Time 14.00(14.00)\n",
      "Iter 24970 | Time 26.6741(26.7934) | Bit/dim 3.4545(3.4875) | Xent 0.0140(0.0158) | Loss 3.4615(3.4954) | Error 0.0056(0.0047) Steps 1120(1115.63) | Grad Norm 1.2380(1.7009) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 131.1796, Epoch Time 1623.5193(1621.5441), Bit/dim 3.4955(best: 3.4955), Xent 2.7931, Loss 4.8921, Error 0.2891(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24980 | Time 26.6234(26.7867) | Bit/dim 3.4491(3.4863) | Xent 0.0120(0.0164) | Loss 3.4551(3.4944) | Error 0.0022(0.0049) Steps 1108(1115.33) | Grad Norm 2.0490(1.7425) | Total Time 14.00(14.00)\n",
      "Iter 24990 | Time 26.7873(26.7857) | Bit/dim 3.5118(3.4871) | Xent 0.0087(0.0162) | Loss 3.5162(3.4952) | Error 0.0011(0.0048) Steps 1120(1115.57) | Grad Norm 0.8943(1.7003) | Total Time 14.00(14.00)\n",
      "Iter 25000 | Time 27.3982(26.7414) | Bit/dim 3.4681(3.4891) | Xent 0.0150(0.0152) | Loss 3.4756(3.4968) | Error 0.0044(0.0047) Steps 1108(1114.89) | Grad Norm 1.4400(1.6215) | Total Time 14.00(14.00)\n",
      "Iter 25010 | Time 26.2233(26.7153) | Bit/dim 3.4505(3.4893) | Xent 0.0171(0.0157) | Loss 3.4590(3.4971) | Error 0.0056(0.0051) Steps 1108(1113.96) | Grad Norm 2.2433(1.6526) | Total Time 14.00(14.00)\n",
      "Iter 25020 | Time 26.4996(26.7651) | Bit/dim 3.4700(3.4887) | Xent 0.0190(0.0167) | Loss 3.4795(3.4971) | Error 0.0078(0.0055) Steps 1102(1113.67) | Grad Norm 4.0134(1.7881) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 131.4770, Epoch Time 1621.2458(1621.5352), Bit/dim 3.4979(best: 3.4955), Xent 2.8193, Loss 4.9076, Error 0.2926(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25030 | Time 25.9574(26.7392) | Bit/dim 3.4910(3.4897) | Xent 0.0127(0.0168) | Loss 3.4974(3.4981) | Error 0.0022(0.0055) Steps 1114(1114.73) | Grad Norm 1.0009(1.7919) | Total Time 14.00(14.00)\n",
      "Iter 25040 | Time 26.8505(26.7064) | Bit/dim 3.4862(3.4896) | Xent 0.0264(0.0164) | Loss 3.4994(3.4978) | Error 0.0078(0.0053) Steps 1102(1114.68) | Grad Norm 2.1544(1.7692) | Total Time 14.00(14.00)\n",
      "Iter 25050 | Time 27.1332(26.8220) | Bit/dim 3.4938(3.4901) | Xent 0.0158(0.0157) | Loss 3.5017(3.4980) | Error 0.0078(0.0051) Steps 1108(1115.57) | Grad Norm 1.3026(1.6859) | Total Time 14.00(14.00)\n",
      "Iter 25060 | Time 26.9105(26.8563) | Bit/dim 3.5239(3.4907) | Xent 0.0079(0.0151) | Loss 3.5278(3.4983) | Error 0.0022(0.0048) Steps 1114(1115.89) | Grad Norm 0.7408(1.5913) | Total Time 14.00(14.00)\n",
      "Iter 25070 | Time 26.4168(26.8710) | Bit/dim 3.5009(3.4896) | Xent 0.0082(0.0154) | Loss 3.5050(3.4973) | Error 0.0033(0.0049) Steps 1108(1115.26) | Grad Norm 0.7867(1.5754) | Total Time 14.00(14.00)\n",
      "Iter 25080 | Time 26.6374(26.8367) | Bit/dim 3.5117(3.4926) | Xent 0.0181(0.0158) | Loss 3.5208(3.5005) | Error 0.0056(0.0049) Steps 1114(1115.26) | Grad Norm 1.9701(1.6061) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 132.8641, Epoch Time 1627.0646(1621.7011), Bit/dim 3.4966(best: 3.4955), Xent 2.7472, Loss 4.8702, Error 0.2866(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25090 | Time 27.5604(26.8495) | Bit/dim 3.5006(3.4917) | Xent 0.0197(0.0159) | Loss 3.5105(3.4997) | Error 0.0056(0.0049) Steps 1126(1114.32) | Grad Norm 2.3129(1.7073) | Total Time 14.00(14.00)\n",
      "Iter 25100 | Time 26.6008(26.9354) | Bit/dim 3.4967(3.4893) | Xent 0.0099(0.0154) | Loss 3.5016(3.4970) | Error 0.0022(0.0047) Steps 1132(1115.35) | Grad Norm 1.1506(1.7007) | Total Time 14.00(14.00)\n",
      "Iter 25110 | Time 27.4520(27.0316) | Bit/dim 3.4880(3.4887) | Xent 0.0206(0.0151) | Loss 3.4983(3.4962) | Error 0.0067(0.0046) Steps 1096(1115.74) | Grad Norm 1.9809(1.6677) | Total Time 14.00(14.00)\n",
      "Iter 25120 | Time 26.8186(27.0323) | Bit/dim 3.4871(3.4903) | Xent 0.0190(0.0152) | Loss 3.4966(3.4979) | Error 0.0056(0.0046) Steps 1102(1115.17) | Grad Norm 1.4441(1.6311) | Total Time 14.00(14.00)\n",
      "Iter 25130 | Time 26.1644(26.9564) | Bit/dim 3.4976(3.4906) | Xent 0.0246(0.0166) | Loss 3.5099(3.4989) | Error 0.0089(0.0051) Steps 1114(1115.36) | Grad Norm 1.8355(1.6815) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 132.6017, Epoch Time 1635.8806(1622.1265), Bit/dim 3.4977(best: 3.4955), Xent 2.7669, Loss 4.8811, Error 0.2875(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25140 | Time 26.7461(26.9125) | Bit/dim 3.5086(3.4943) | Xent 0.0121(0.0167) | Loss 3.5147(3.5027) | Error 0.0033(0.0050) Steps 1120(1114.86) | Grad Norm 1.6453(1.7516) | Total Time 14.00(14.00)\n",
      "Iter 25150 | Time 26.1306(26.8886) | Bit/dim 3.5232(3.4920) | Xent 0.0106(0.0165) | Loss 3.5285(3.5003) | Error 0.0022(0.0050) Steps 1114(1114.55) | Grad Norm 1.6656(1.7559) | Total Time 14.00(14.00)\n",
      "Iter 25160 | Time 27.2724(26.9073) | Bit/dim 3.5104(3.4915) | Xent 0.0172(0.0167) | Loss 3.5190(3.4998) | Error 0.0044(0.0052) Steps 1126(1114.28) | Grad Norm 1.7163(1.7354) | Total Time 14.00(14.00)\n",
      "Iter 25170 | Time 26.6658(26.9060) | Bit/dim 3.5244(3.4905) | Xent 0.0097(0.0170) | Loss 3.5293(3.4990) | Error 0.0011(0.0051) Steps 1126(1114.69) | Grad Norm 1.0983(1.7044) | Total Time 14.00(14.00)\n",
      "Iter 25180 | Time 27.2405(26.9212) | Bit/dim 3.4821(3.4910) | Xent 0.0127(0.0159) | Loss 3.4884(3.4990) | Error 0.0044(0.0047) Steps 1102(1115.26) | Grad Norm 1.4268(1.6777) | Total Time 14.00(14.00)\n",
      "Iter 25190 | Time 27.0771(26.9663) | Bit/dim 3.4935(3.4910) | Xent 0.0104(0.0157) | Loss 3.4987(3.4989) | Error 0.0022(0.0044) Steps 1120(1117.12) | Grad Norm 1.1219(1.5837) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 132.4766, Epoch Time 1632.4515(1622.4362), Bit/dim 3.4958(best: 3.4955), Xent 2.7588, Loss 4.8751, Error 0.2878(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25200 | Time 27.2012(27.0075) | Bit/dim 3.5121(3.4903) | Xent 0.0087(0.0151) | Loss 3.5165(3.4978) | Error 0.0011(0.0041) Steps 1114(1116.81) | Grad Norm 1.2198(1.5361) | Total Time 14.00(14.00)\n",
      "Iter 25210 | Time 26.4208(26.9327) | Bit/dim 3.4989(3.4907) | Xent 0.0082(0.0143) | Loss 3.5030(3.4978) | Error 0.0000(0.0038) Steps 1108(1114.61) | Grad Norm 1.2046(1.4766) | Total Time 14.00(14.00)\n",
      "Iter 25220 | Time 27.1853(26.9015) | Bit/dim 3.4989(3.4881) | Xent 0.0099(0.0139) | Loss 3.5039(3.4951) | Error 0.0033(0.0038) Steps 1108(1113.47) | Grad Norm 1.2296(1.4397) | Total Time 14.00(14.00)\n",
      "Iter 25230 | Time 26.6725(26.9053) | Bit/dim 3.4765(3.4869) | Xent 0.0119(0.0136) | Loss 3.4824(3.4937) | Error 0.0022(0.0037) Steps 1120(1113.31) | Grad Norm 1.2998(1.4153) | Total Time 14.00(14.00)\n",
      "Iter 25240 | Time 27.6124(27.0107) | Bit/dim 3.5020(3.4900) | Xent 0.0084(0.0134) | Loss 3.5062(3.4967) | Error 0.0011(0.0036) Steps 1120(1115.65) | Grad Norm 0.8743(1.4419) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 132.2321, Epoch Time 1634.6489(1622.8026), Bit/dim 3.4956(best: 3.4955), Xent 2.8165, Loss 4.9039, Error 0.2843(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25250 | Time 26.1252(26.9985) | Bit/dim 3.4692(3.4898) | Xent 0.0194(0.0139) | Loss 3.4789(3.4967) | Error 0.0044(0.0038) Steps 1132(1117.28) | Grad Norm 1.7993(1.4851) | Total Time 14.00(14.00)\n",
      "Iter 25260 | Time 27.0021(26.9679) | Bit/dim 3.4842(3.4898) | Xent 0.0126(0.0139) | Loss 3.4905(3.4967) | Error 0.0033(0.0039) Steps 1114(1117.73) | Grad Norm 1.2226(1.5054) | Total Time 14.00(14.00)\n",
      "Iter 25270 | Time 26.3366(26.9229) | Bit/dim 3.4766(3.4915) | Xent 0.0107(0.0147) | Loss 3.4819(3.4989) | Error 0.0000(0.0040) Steps 1120(1117.95) | Grad Norm 1.3321(1.6054) | Total Time 14.00(14.00)\n",
      "Iter 25280 | Time 25.6496(26.8333) | Bit/dim 3.4799(3.4896) | Xent 0.0186(0.0151) | Loss 3.4892(3.4972) | Error 0.0056(0.0043) Steps 1102(1117.33) | Grad Norm 1.8190(1.6418) | Total Time 14.00(14.00)\n",
      "Iter 25290 | Time 27.0690(26.8371) | Bit/dim 3.4891(3.4893) | Xent 0.0216(0.0154) | Loss 3.4999(3.4971) | Error 0.0067(0.0046) Steps 1126(1118.78) | Grad Norm 2.1342(1.6576) | Total Time 14.00(14.00)\n",
      "Iter 25300 | Time 26.2689(26.8853) | Bit/dim 3.5227(3.4901) | Xent 0.0175(0.0155) | Loss 3.5315(3.4979) | Error 0.0056(0.0048) Steps 1120(1118.06) | Grad Norm 1.6366(1.6418) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 132.5500, Epoch Time 1626.1615(1622.9034), Bit/dim 3.4958(best: 3.4955), Xent 2.8321, Loss 4.9118, Error 0.2889(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25310 | Time 26.2884(26.9377) | Bit/dim 3.4787(3.4879) | Xent 0.0099(0.0148) | Loss 3.4836(3.4953) | Error 0.0033(0.0045) Steps 1132(1119.56) | Grad Norm 1.1077(1.5828) | Total Time 14.00(14.00)\n",
      "Iter 25320 | Time 26.6546(26.9054) | Bit/dim 3.4940(3.4892) | Xent 0.0118(0.0143) | Loss 3.4999(3.4963) | Error 0.0022(0.0044) Steps 1132(1120.50) | Grad Norm 1.2319(1.5315) | Total Time 14.00(14.00)\n",
      "Iter 25330 | Time 27.8281(26.9705) | Bit/dim 3.4636(3.4861) | Xent 0.0210(0.0144) | Loss 3.4741(3.4933) | Error 0.0078(0.0042) Steps 1126(1119.88) | Grad Norm 1.8904(1.4807) | Total Time 14.00(14.00)\n",
      "Iter 25340 | Time 26.9241(26.9923) | Bit/dim 3.4728(3.4893) | Xent 0.0163(0.0143) | Loss 3.4809(3.4964) | Error 0.0067(0.0042) Steps 1126(1120.64) | Grad Norm 1.2812(1.4262) | Total Time 14.00(14.00)\n",
      "Iter 25350 | Time 27.0381(27.0024) | Bit/dim 3.4935(3.4914) | Xent 0.0158(0.0137) | Loss 3.5014(3.4983) | Error 0.0056(0.0039) Steps 1126(1120.88) | Grad Norm 1.3888(1.3626) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 133.8724, Epoch Time 1638.8648(1623.3822), Bit/dim 3.4933(best: 3.4955), Xent 2.7650, Loss 4.8758, Error 0.2882(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25360 | Time 27.1088(26.9640) | Bit/dim 3.4957(3.4918) | Xent 0.0116(0.0136) | Loss 3.5015(3.4985) | Error 0.0022(0.0036) Steps 1138(1121.75) | Grad Norm 1.0913(1.3618) | Total Time 14.00(14.00)\n",
      "Iter 25370 | Time 27.0911(26.9577) | Bit/dim 3.4889(3.4899) | Xent 0.0173(0.0148) | Loss 3.4976(3.4973) | Error 0.0056(0.0042) Steps 1120(1119.70) | Grad Norm 1.4277(1.4875) | Total Time 14.00(14.00)\n",
      "Iter 25380 | Time 27.3561(27.0603) | Bit/dim 3.4906(3.4892) | Xent 0.0117(0.0146) | Loss 3.4964(3.4965) | Error 0.0011(0.0041) Steps 1126(1121.58) | Grad Norm 1.2479(1.4619) | Total Time 14.00(14.00)\n",
      "Iter 25390 | Time 26.9444(27.0565) | Bit/dim 3.4766(3.4882) | Xent 0.0171(0.0150) | Loss 3.4851(3.4956) | Error 0.0033(0.0043) Steps 1114(1122.18) | Grad Norm 2.0138(1.5025) | Total Time 14.00(14.00)\n",
      "Iter 25400 | Time 26.8368(27.0887) | Bit/dim 3.4405(3.4897) | Xent 0.0224(0.0149) | Loss 3.4517(3.4971) | Error 0.0067(0.0044) Steps 1108(1121.80) | Grad Norm 2.1731(1.5128) | Total Time 14.00(14.00)\n",
      "Iter 25410 | Time 26.9253(27.0784) | Bit/dim 3.4503(3.4903) | Xent 0.0154(0.0149) | Loss 3.4580(3.4978) | Error 0.0056(0.0045) Steps 1126(1122.19) | Grad Norm 1.3291(1.5058) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 133.0141, Epoch Time 1639.9259(1623.8785), Bit/dim 3.4942(best: 3.4933), Xent 2.8042, Loss 4.8963, Error 0.2866(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25420 | Time 26.8205(27.0002) | Bit/dim 3.4876(3.4905) | Xent 0.0167(0.0149) | Loss 3.4960(3.4980) | Error 0.0033(0.0044) Steps 1126(1121.60) | Grad Norm 2.2199(1.5403) | Total Time 14.00(14.00)\n",
      "Iter 25430 | Time 26.7345(26.9456) | Bit/dim 3.4865(3.4923) | Xent 0.0160(0.0149) | Loss 3.4945(3.4998) | Error 0.0067(0.0045) Steps 1108(1120.74) | Grad Norm 2.5066(1.6275) | Total Time 14.00(14.00)\n",
      "Iter 25440 | Time 27.2743(26.9767) | Bit/dim 3.5075(3.4934) | Xent 0.0172(0.0151) | Loss 3.5161(3.5009) | Error 0.0056(0.0045) Steps 1120(1119.00) | Grad Norm 1.4242(1.6316) | Total Time 14.00(14.00)\n",
      "Iter 25450 | Time 27.3458(26.9127) | Bit/dim 3.4535(3.4920) | Xent 0.0098(0.0152) | Loss 3.4584(3.4996) | Error 0.0011(0.0045) Steps 1102(1117.12) | Grad Norm 1.1580(1.5872) | Total Time 14.00(14.00)\n",
      "Iter 25460 | Time 27.7462(26.9253) | Bit/dim 3.4483(3.4899) | Xent 0.0177(0.0153) | Loss 3.4572(3.4975) | Error 0.0078(0.0045) Steps 1102(1116.59) | Grad Norm 2.0277(1.5878) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 133.7460, Epoch Time 1630.0107(1624.0625), Bit/dim 3.4960(best: 3.4933), Xent 2.8127, Loss 4.9023, Error 0.2883(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25470 | Time 26.6015(26.9546) | Bit/dim 3.4996(3.4869) | Xent 0.0177(0.0153) | Loss 3.5084(3.4946) | Error 0.0067(0.0046) Steps 1120(1117.67) | Grad Norm 2.2780(1.5656) | Total Time 14.00(14.00)\n",
      "Iter 25480 | Time 27.5524(27.0004) | Bit/dim 3.4930(3.4882) | Xent 0.0115(0.0156) | Loss 3.4987(3.4961) | Error 0.0022(0.0046) Steps 1114(1118.43) | Grad Norm 1.7621(1.6024) | Total Time 14.00(14.00)\n",
      "Iter 25490 | Time 26.4350(27.0317) | Bit/dim 3.4731(3.4906) | Xent 0.0209(0.0158) | Loss 3.4836(3.4985) | Error 0.0044(0.0045) Steps 1108(1118.96) | Grad Norm 2.5961(1.6590) | Total Time 14.00(14.00)\n",
      "Iter 25500 | Time 26.3919(26.9556) | Bit/dim 3.4492(3.4893) | Xent 0.0167(0.0157) | Loss 3.4575(3.4972) | Error 0.0056(0.0046) Steps 1108(1118.81) | Grad Norm 1.9571(1.6297) | Total Time 14.00(14.00)\n",
      "Iter 25510 | Time 27.3089(26.9475) | Bit/dim 3.4821(3.4903) | Xent 0.0277(0.0166) | Loss 3.4959(3.4986) | Error 0.0089(0.0051) Steps 1114(1118.53) | Grad Norm 2.0939(1.6470) | Total Time 14.00(14.00)\n",
      "Iter 25520 | Time 27.7089(27.0372) | Bit/dim 3.4851(3.4878) | Xent 0.0231(0.0171) | Loss 3.4967(3.4964) | Error 0.0078(0.0051) Steps 1114(1118.91) | Grad Norm 1.6329(1.6394) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 134.1758, Epoch Time 1638.8339(1624.5056), Bit/dim 3.4959(best: 3.4933), Xent 2.8460, Loss 4.9189, Error 0.2908(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25530 | Time 26.9480(26.9570) | Bit/dim 3.5185(3.4882) | Xent 0.0146(0.0160) | Loss 3.5258(3.4962) | Error 0.0033(0.0047) Steps 1120(1118.07) | Grad Norm 1.4618(1.5570) | Total Time 14.00(14.00)\n",
      "Iter 25540 | Time 26.4848(27.0312) | Bit/dim 3.4626(3.4870) | Xent 0.0202(0.0156) | Loss 3.4727(3.4948) | Error 0.0067(0.0045) Steps 1126(1118.87) | Grad Norm 2.3042(1.5181) | Total Time 14.00(14.00)\n",
      "Iter 25550 | Time 26.1170(27.0237) | Bit/dim 3.4806(3.4873) | Xent 0.0188(0.0153) | Loss 3.4900(3.4950) | Error 0.0056(0.0043) Steps 1120(1117.94) | Grad Norm 1.7315(1.4882) | Total Time 14.00(14.00)\n",
      "Iter 25560 | Time 27.4280(27.0227) | Bit/dim 3.5293(3.4892) | Xent 0.0170(0.0158) | Loss 3.5378(3.4971) | Error 0.0044(0.0046) Steps 1120(1117.86) | Grad Norm 1.4773(1.5725) | Total Time 14.00(14.00)\n",
      "Iter 25570 | Time 26.8384(26.9691) | Bit/dim 3.4907(3.4900) | Xent 0.0122(0.0171) | Loss 3.4968(3.4985) | Error 0.0022(0.0051) Steps 1126(1118.48) | Grad Norm 1.3010(1.6496) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 134.8471, Epoch Time 1635.6724(1624.8406), Bit/dim 3.4966(best: 3.4933), Xent 2.8767, Loss 4.9350, Error 0.2905(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25580 | Time 27.1773(26.9459) | Bit/dim 3.4922(3.4883) | Xent 0.0126(0.0174) | Loss 3.4986(3.4971) | Error 0.0033(0.0052) Steps 1132(1118.24) | Grad Norm 1.8485(1.7028) | Total Time 14.00(14.00)\n",
      "Iter 25590 | Time 26.8543(26.9751) | Bit/dim 3.4628(3.4901) | Xent 0.0203(0.0168) | Loss 3.4729(3.4985) | Error 0.0067(0.0051) Steps 1114(1117.20) | Grad Norm 1.9727(1.6825) | Total Time 14.00(14.00)\n",
      "Iter 25600 | Time 27.3510(26.9745) | Bit/dim 3.4726(3.4896) | Xent 0.0168(0.0162) | Loss 3.4810(3.4977) | Error 0.0067(0.0048) Steps 1102(1117.45) | Grad Norm 1.4582(1.6419) | Total Time 14.00(14.00)\n",
      "Iter 25610 | Time 26.8731(27.0012) | Bit/dim 3.5048(3.4886) | Xent 0.0191(0.0160) | Loss 3.5143(3.4966) | Error 0.0078(0.0045) Steps 1126(1117.02) | Grad Norm 1.9445(1.6731) | Total Time 14.00(14.00)\n",
      "Iter 25620 | Time 27.4063(27.0266) | Bit/dim 3.4973(3.4890) | Xent 0.0250(0.0159) | Loss 3.5098(3.4970) | Error 0.0067(0.0045) Steps 1108(1117.49) | Grad Norm 2.3181(1.7685) | Total Time 14.00(14.00)\n",
      "Iter 25630 | Time 27.5045(27.0434) | Bit/dim 3.4983(3.4903) | Xent 0.0153(0.0161) | Loss 3.5060(3.4984) | Error 0.0033(0.0045) Steps 1126(1119.69) | Grad Norm 1.5507(1.7777) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 133.7432, Epoch Time 1638.3835(1625.2469), Bit/dim 3.4960(best: 3.4933), Xent 2.7801, Loss 4.8860, Error 0.2913(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25640 | Time 26.7490(27.0325) | Bit/dim 3.5032(3.4924) | Xent 0.0289(0.0163) | Loss 3.5176(3.5005) | Error 0.0122(0.0048) Steps 1120(1119.17) | Grad Norm 1.6794(1.7276) | Total Time 14.00(14.00)\n",
      "Iter 25650 | Time 26.0159(27.0079) | Bit/dim 3.4709(3.4904) | Xent 0.0204(0.0158) | Loss 3.4811(3.4982) | Error 0.0089(0.0046) Steps 1114(1120.73) | Grad Norm 2.0763(1.6716) | Total Time 14.00(14.00)\n",
      "Iter 25660 | Time 26.6880(26.9842) | Bit/dim 3.4291(3.4895) | Xent 0.0084(0.0154) | Loss 3.4333(3.4972) | Error 0.0022(0.0047) Steps 1126(1121.48) | Grad Norm 1.0349(1.6125) | Total Time 14.00(14.00)\n",
      "Iter 25670 | Time 27.4121(26.9590) | Bit/dim 3.4792(3.4863) | Xent 0.0226(0.0160) | Loss 3.4905(3.4944) | Error 0.0067(0.0050) Steps 1108(1120.67) | Grad Norm 2.0454(1.5950) | Total Time 14.00(14.00)\n",
      "Iter 25680 | Time 27.1870(26.9693) | Bit/dim 3.4477(3.4882) | Xent 0.0138(0.0156) | Loss 3.4545(3.4960) | Error 0.0033(0.0049) Steps 1138(1121.81) | Grad Norm 1.5214(1.5691) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 132.8440, Epoch Time 1633.0935(1625.4823), Bit/dim 3.4944(best: 3.4933), Xent 2.8053, Loss 4.8971, Error 0.2902(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25690 | Time 27.1233(26.9915) | Bit/dim 3.4986(3.4924) | Xent 0.0061(0.0148) | Loss 3.5017(3.4998) | Error 0.0011(0.0046) Steps 1132(1122.35) | Grad Norm 0.9786(1.5296) | Total Time 14.00(14.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_run2 --resume ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_run2/current_checkpt.pth --seed 2 --lr 0.0001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.5\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
