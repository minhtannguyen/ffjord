{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl_multiscale.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import torch.utils.data as data\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "plt.rcParams['figure.dpi'] = 300\n",
      "\n",
      "from PIL import Image\n",
      "import os.path\n",
      "import errno\n",
      "import codecs\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"colormnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--y_class\", type=int, default=10)\n",
      "parser.add_argument(\"--y_color\", type=int, default=10)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl_multiscale as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "class ColorMNIST(data.Dataset):\n",
      "    \"\"\"\n",
      "    ColorMNIST\n",
      "    \"\"\"\n",
      "    urls = [\n",
      "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
      "    ]\n",
      "    raw_folder = 'raw'\n",
      "    processed_folder = 'processed'\n",
      "    training_file = 'training.pt'\n",
      "    test_file = 'test.pt'\n",
      "\n",
      "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
      "        self.root = os.path.expanduser(root)\n",
      "        self.transform = transform\n",
      "        self.target_transform = target_transform\n",
      "        self.train = train  # training set or test set\n",
      "\n",
      "        if download:\n",
      "            self.download()\n",
      "\n",
      "        if not self._check_exists():\n",
      "            raise RuntimeError('Dataset not found.' +\n",
      "                               ' You can use download=True to download it')\n",
      "\n",
      "        if self.train:\n",
      "            self.train_data, self.train_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
      "            \n",
      "            self.train_data = np.tile(self.train_data[:, :, :, np.newaxis], 3)\n",
      "        else:\n",
      "            self.test_data, self.test_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "            \n",
      "            self.test_data = np.tile(self.test_data[:, :, :, np.newaxis], 3)\n",
      "        \n",
      "        self.pallette = [[31, 119, 180],\n",
      "                         [255, 127, 14],\n",
      "                         [44, 160, 44],\n",
      "                         [214, 39, 40],\n",
      "                         [148, 103, 189],\n",
      "                         [140, 86, 75],\n",
      "                         [227, 119, 194],\n",
      "                         [127, 127, 127],\n",
      "                         [188, 189, 34],\n",
      "                         [23, 190, 207]]\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            index (int): Index\n",
      "\n",
      "        Returns:\n",
      "            tuple: (image, target) where target is index of the target class.\n",
      "        \"\"\"\n",
      "        if self.train:\n",
      "            img, target = self.train_data[index].copy(), self.train_labels[index]\n",
      "        else:\n",
      "            img, target = self.test_data[index].copy(), self.test_labels[index]\n",
      "        \n",
      "        # doing this so that it is consistent with all other datasets\n",
      "        # to return a PIL Image\n",
      "        y_color_digit = np.random.randint(0, args.y_color)\n",
      "        c_digit = self.pallette[y_color_digit]\n",
      "        \n",
      "        img[:, :, 0] = img[:, :, 0] / 255 * c_digit[0]\n",
      "        img[:, :, 1] = img[:, :, 1] / 255 * c_digit[1]\n",
      "        img[:, :, 2] = img[:, :, 2] / 255 * c_digit[2]\n",
      "        \n",
      "        img = Image.fromarray(img)\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "\n",
      "        return img, [target,torch.from_numpy(np.array(y_color_digit))]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.train:\n",
      "            return len(self.train_data)\n",
      "        else:\n",
      "            return len(self.test_data)\n",
      "\n",
      "    def _check_exists(self):\n",
      "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
      "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "\n",
      "    def download(self):\n",
      "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
      "        from six.moves import urllib\n",
      "        import gzip\n",
      "\n",
      "        if self._check_exists():\n",
      "            return\n",
      "\n",
      "        # download files\n",
      "        try:\n",
      "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
      "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
      "        except OSError as e:\n",
      "            if e.errno == errno.EEXIST:\n",
      "                pass\n",
      "            else:\n",
      "                raise\n",
      "\n",
      "        for url in self.urls:\n",
      "            print('Downloading ' + url)\n",
      "            data = urllib.request.urlopen(url)\n",
      "            filename = url.rpartition('/')[2]\n",
      "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
      "            with open(file_path, 'wb') as f:\n",
      "                f.write(data.read())\n",
      "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
      "                    gzip.GzipFile(file_path) as zip_f:\n",
      "                out_f.write(zip_f.read())\n",
      "            os.unlink(file_path)\n",
      "\n",
      "        # process and save as torch files\n",
      "        print('Processing...')\n",
      "\n",
      "        training_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
      "        )\n",
      "        test_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
      "        )\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
      "            torch.save(training_set, f)\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
      "            torch.save(test_set, f)\n",
      "\n",
      "        print('Done!')\n",
      "\n",
      "    def __repr__(self):\n",
      "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
      "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
      "        tmp = 'train' if self.train is True else 'test'\n",
      "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
      "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
      "        tmp = '    Transforms (if any): '\n",
      "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        tmp = '    Target Transforms (if any): '\n",
      "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        return fmt_str\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"colormnist\":\n",
      "        im_dim = 3\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = ColorMNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = ColorMNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z_sup, z_unsup, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    z_sup = torch.cat(z_sup, 1)\n",
      "    z_unsup = torch.cat(z_unsup, 1)\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z_sup).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z_unsup).view(z_unsup.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        z_sup = model.module.dropout(z_sup)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z_sup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,\n",
      "            y_class = args.y_class)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            dim_unsup = np.prod(data_shape) - np.prod(fixed_z_sup.shape[1:])\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            \n",
      "            a_sup = fixed_z_sup.shape[1] // (2**(model.module.n_scale - 1))\n",
      "            a_unsup = fixed_z_unsup.shape[1] // (2**(model.module.n_scale - 1))\n",
      "            \n",
      "            fixed_z = []\n",
      "            start_sup = 0; start_unsup = 0\n",
      "            for ns in range(model.module.n_scale, 1, -1):\n",
      "                end_sup = start_sup + (2**(ns-2))*a_sup\n",
      "                end_unsup = start_unsup + (2**(ns-2))*a_unsup\n",
      "                \n",
      "                fixed_z.append(fixed_z_sup[:,start_sup:end_sup])\n",
      "                fixed_z.append(fixed_z_unsup[:,start_unsup:end_unsup])\n",
      "                \n",
      "                start_sup = end_sup; start_unsup = end_unsup\n",
      "            \n",
      "            end_sup = start_sup + a_sup\n",
      "            end_unsup = start_unsup + a_unsup\n",
      "            \n",
      "            fixed_z.append(fixed_z_sup[:,start_sup:end_sup])\n",
      "            fixed_z.append(fixed_z_unsup[:,start_unsup:end_unsup])\n",
      "            \n",
      "            # for i_z in range(len(fixed_z)): print(fixed_z[i_z].shape)\n",
      "            \n",
      "            fixed_z = torch.cat(fixed_z,1)\n",
      "            \n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            if args.data == \"colormnist\":\n",
      "                y = y[0]\n",
      "            \n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "            \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if args.data == \"colormnist\":\n",
      "                        y = y[0]\n",
      "                        \n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                    \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=False, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, eta=0.1, gamma=0.99, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run1/epoch_250_checkpt.pth', rl_weight=0.01, rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run1', scale=1.0, scale_fac=1.0, scale_std=6.0, seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5, y_class=10, y_color=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1450732\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 13760 | Time 18.6569(19.7735) | Bit/dim 3.5547(3.5574) | Xent 0.0295(0.0391) | Loss 8.8542(9.7652) | Error 0.0078(0.0122) Steps 790(787.64) | Grad Norm 2.0204(3.5651) | Total Time 0.00(0.00)\n",
      "Iter 13770 | Time 19.4538(19.6328) | Bit/dim 3.5493(3.5552) | Xent 0.0152(0.0342) | Loss 8.9565(9.5362) | Error 0.0044(0.0106) Steps 778(785.96) | Grad Norm 1.5590(3.1199) | Total Time 0.00(0.00)\n",
      "Iter 13780 | Time 19.9669(19.5579) | Bit/dim 3.5250(3.5509) | Xent 0.0085(0.0296) | Loss 8.7204(9.3631) | Error 0.0022(0.0090) Steps 790(786.17) | Grad Norm 1.3900(2.7268) | Total Time 0.00(0.00)\n",
      "Iter 13790 | Time 18.9868(19.5319) | Bit/dim 3.5203(3.5481) | Xent 0.0179(0.0260) | Loss 8.9068(9.2397) | Error 0.0067(0.0078) Steps 796(786.90) | Grad Norm 1.5412(2.3633) | Total Time 0.00(0.00)\n",
      "Iter 13800 | Time 19.2742(19.4832) | Bit/dim 3.5391(3.5451) | Xent 0.0140(0.0226) | Loss 8.8524(9.1413) | Error 0.0011(0.0067) Steps 784(787.79) | Grad Norm 1.2342(2.0603) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 95.4713, Epoch Time 1196.4506(1160.5555), Bit/dim 3.5592(best: inf), Xent 2.1897, Loss 4.6541, Error 0.3607(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13810 | Time 18.9006(19.4250) | Bit/dim 3.5184(3.5430) | Xent 0.0168(0.0200) | Loss 8.8156(9.8952) | Error 0.0033(0.0058) Steps 748(786.80) | Grad Norm 1.2943(1.8313) | Total Time 0.00(0.00)\n",
      "Iter 13820 | Time 18.8159(19.4196) | Bit/dim 3.5429(3.5408) | Xent 0.0130(0.0172) | Loss 8.8165(9.6197) | Error 0.0022(0.0048) Steps 772(785.89) | Grad Norm 1.7419(1.6741) | Total Time 0.00(0.00)\n",
      "Iter 13830 | Time 19.7508(19.4681) | Bit/dim 3.4979(3.5358) | Xent 0.0178(0.0159) | Loss 8.8357(9.4186) | Error 0.0033(0.0043) Steps 808(786.96) | Grad Norm 1.4162(1.5565) | Total Time 0.00(0.00)\n",
      "Iter 13840 | Time 18.8716(19.4137) | Bit/dim 3.5516(3.5357) | Xent 0.0090(0.0143) | Loss 8.9453(9.2680) | Error 0.0011(0.0038) Steps 790(786.22) | Grad Norm 1.2607(1.5056) | Total Time 0.00(0.00)\n",
      "Iter 13850 | Time 19.1154(19.4017) | Bit/dim 3.5268(3.5368) | Xent 0.0040(0.0135) | Loss 8.7835(9.1608) | Error 0.0011(0.0037) Steps 796(787.86) | Grad Norm 0.9292(1.5290) | Total Time 0.00(0.00)\n",
      "Iter 13860 | Time 19.6133(19.3972) | Bit/dim 3.5193(3.5364) | Xent 0.0197(0.0129) | Loss 8.8758(9.0911) | Error 0.0067(0.0035) Steps 766(786.76) | Grad Norm 1.6920(1.5249) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 90.0102, Epoch Time 1173.1367(1160.9329), Bit/dim 3.5567(best: 3.5592), Xent 2.2454, Loss 4.6794, Error 0.3605(best: 0.3607)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13870 | Time 19.1462(19.3467) | Bit/dim 3.5134(3.5345) | Xent 0.0067(0.0124) | Loss 8.7892(9.7251) | Error 0.0011(0.0032) Steps 760(785.44) | Grad Norm 0.8061(1.4516) | Total Time 0.00(0.00)\n",
      "Iter 13880 | Time 18.8229(19.4040) | Bit/dim 3.5516(3.5358) | Xent 0.0060(0.0113) | Loss 8.8723(9.5020) | Error 0.0011(0.0028) Steps 760(785.09) | Grad Norm 0.8786(1.3334) | Total Time 0.00(0.00)\n",
      "Iter 13890 | Time 18.9725(19.4216) | Bit/dim 3.5286(3.5345) | Xent 0.0074(0.0102) | Loss 8.7760(9.3245) | Error 0.0022(0.0025) Steps 808(786.25) | Grad Norm 1.8157(1.2967) | Total Time 0.00(0.00)\n",
      "Iter 13900 | Time 18.8658(19.3098) | Bit/dim 3.5636(3.5345) | Xent 0.0041(0.0100) | Loss 8.9937(9.1993) | Error 0.0011(0.0025) Steps 784(784.00) | Grad Norm 0.8886(1.2482) | Total Time 0.00(0.00)\n",
      "Iter 13910 | Time 20.2830(19.4245) | Bit/dim 3.5197(3.5338) | Xent 0.0069(0.0093) | Loss 8.8424(9.1005) | Error 0.0011(0.0023) Steps 814(784.61) | Grad Norm 0.6183(1.1905) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 90.4975, Epoch Time 1173.1850(1161.3005), Bit/dim 3.5564(best: 3.5567), Xent 2.3246, Loss 4.7187, Error 0.3641(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13920 | Time 19.5936(19.3906) | Bit/dim 3.5300(3.5342) | Xent 0.0061(0.0087) | Loss 8.8122(9.8448) | Error 0.0011(0.0021) Steps 772(783.46) | Grad Norm 1.2763(1.1224) | Total Time 0.00(0.00)\n",
      "Iter 13930 | Time 19.4428(19.4026) | Bit/dim 3.5779(3.5328) | Xent 0.0046(0.0088) | Loss 8.9901(9.5856) | Error 0.0000(0.0019) Steps 784(782.62) | Grad Norm 0.7263(1.1466) | Total Time 0.00(0.00)\n",
      "Iter 13940 | Time 18.9769(19.3324) | Bit/dim 3.5437(3.5302) | Xent 0.0042(0.0086) | Loss 8.9592(9.3971) | Error 0.0011(0.0021) Steps 802(787.53) | Grad Norm 0.7186(1.2633) | Total Time 0.00(0.00)\n",
      "Iter 13950 | Time 19.1040(19.3304) | Bit/dim 3.5096(3.5307) | Xent 0.0033(0.0081) | Loss 8.7008(9.2470) | Error 0.0000(0.0018) Steps 796(786.80) | Grad Norm 0.5010(1.1960) | Total Time 0.00(0.00)\n",
      "Iter 13960 | Time 20.0593(19.3994) | Bit/dim 3.5270(3.5306) | Xent 0.0064(0.0077) | Loss 8.7307(9.1354) | Error 0.0033(0.0018) Steps 742(784.29) | Grad Norm 0.7650(1.1916) | Total Time 0.00(0.00)\n",
      "Iter 13970 | Time 20.1489(19.3587) | Bit/dim 3.5782(3.5324) | Xent 0.0129(0.0081) | Loss 8.9403(9.0632) | Error 0.0033(0.0019) Steps 790(786.71) | Grad Norm 1.3954(1.2579) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 91.2397, Epoch Time 1172.1208(1161.6251), Bit/dim 3.5554(best: 3.5564), Xent 2.3576, Loss 4.7341, Error 0.3627(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13980 | Time 20.0219(19.4278) | Bit/dim 3.5026(3.5306) | Xent 0.0165(0.0085) | Loss 8.6880(9.7079) | Error 0.0056(0.0021) Steps 814(786.64) | Grad Norm 2.3640(1.2932) | Total Time 0.00(0.00)\n",
      "Iter 13990 | Time 18.5615(19.3620) | Bit/dim 3.5362(3.5339) | Xent 0.0034(0.0078) | Loss 8.8661(9.4962) | Error 0.0011(0.0019) Steps 772(785.65) | Grad Norm 0.6104(1.2043) | Total Time 0.00(0.00)\n",
      "Iter 14000 | Time 19.5014(19.2989) | Bit/dim 3.5321(3.5339) | Xent 0.0094(0.0080) | Loss 8.8205(9.3103) | Error 0.0033(0.0019) Steps 808(782.53) | Grad Norm 1.2887(1.1734) | Total Time 0.00(0.00)\n",
      "Iter 14010 | Time 19.0842(19.4428) | Bit/dim 3.5418(3.5316) | Xent 0.0057(0.0073) | Loss 8.7481(9.1859) | Error 0.0011(0.0017) Steps 760(780.60) | Grad Norm 1.0079(1.1439) | Total Time 0.00(0.00)\n",
      "Iter 14020 | Time 19.9810(19.4276) | Bit/dim 3.5318(3.5288) | Xent 0.0038(0.0071) | Loss 8.8740(9.0901) | Error 0.0000(0.0017) Steps 790(781.65) | Grad Norm 0.6689(1.1362) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 90.7244, Epoch Time 1177.4748(1162.1006), Bit/dim 3.5566(best: 3.5554), Xent 2.3866, Loss 4.7499, Error 0.3617(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14030 | Time 20.6313(19.5660) | Bit/dim 3.5135(3.5274) | Xent 0.0055(0.0066) | Loss 8.7705(9.8341) | Error 0.0011(0.0016) Steps 802(784.85) | Grad Norm 1.0743(1.0834) | Total Time 0.00(0.00)\n",
      "Iter 14040 | Time 18.2966(19.4645) | Bit/dim 3.5029(3.5256) | Xent 0.0075(0.0064) | Loss 8.7840(9.5622) | Error 0.0011(0.0015) Steps 760(784.28) | Grad Norm 1.9962(1.1356) | Total Time 0.00(0.00)\n",
      "Iter 14050 | Time 18.9192(19.4240) | Bit/dim 3.5118(3.5276) | Xent 0.0085(0.0065) | Loss 8.6337(9.3705) | Error 0.0033(0.0014) Steps 784(785.75) | Grad Norm 1.1718(1.1038) | Total Time 0.00(0.00)\n",
      "Iter 14060 | Time 18.9659(19.5468) | Bit/dim 3.5205(3.5271) | Xent 0.0079(0.0066) | Loss 8.8185(9.2248) | Error 0.0022(0.0016) Steps 784(786.83) | Grad Norm 1.2184(1.1400) | Total Time 0.00(0.00)\n",
      "Iter 14070 | Time 20.3203(19.4810) | Bit/dim 3.5438(3.5277) | Xent 0.0074(0.0066) | Loss 8.8295(9.1152) | Error 0.0033(0.0018) Steps 760(785.62) | Grad Norm 1.2310(1.0899) | Total Time 0.00(0.00)\n",
      "Iter 14080 | Time 20.2600(19.5353) | Bit/dim 3.5460(3.5299) | Xent 0.0072(0.0068) | Loss 8.9594(9.0523) | Error 0.0022(0.0019) Steps 832(788.76) | Grad Norm 1.5613(1.1389) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 93.1004, Epoch Time 1184.8474(1162.7830), Bit/dim 3.5562(best: 3.5554), Xent 2.4383, Loss 4.7754, Error 0.3631(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14090 | Time 19.1944(19.4972) | Bit/dim 3.5098(3.5289) | Xent 0.0052(0.0068) | Loss 8.8091(9.6894) | Error 0.0000(0.0019) Steps 778(785.96) | Grad Norm 1.3155(1.2302) | Total Time 0.00(0.00)\n",
      "Iter 14100 | Time 19.9063(19.4378) | Bit/dim 3.5051(3.5281) | Xent 0.0054(0.0063) | Loss 8.8270(9.4624) | Error 0.0011(0.0016) Steps 772(787.54) | Grad Norm 1.0213(1.1478) | Total Time 0.00(0.00)\n",
      "Iter 14110 | Time 19.6858(19.5206) | Bit/dim 3.5473(3.5277) | Xent 0.0068(0.0061) | Loss 8.9044(9.2939) | Error 0.0011(0.0015) Steps 772(785.05) | Grad Norm 0.9566(1.1323) | Total Time 0.00(0.00)\n",
      "Iter 14120 | Time 19.7675(19.5278) | Bit/dim 3.5712(3.5294) | Xent 0.0058(0.0054) | Loss 8.8848(9.1729) | Error 0.0011(0.0013) Steps 814(784.92) | Grad Norm 1.7362(1.0342) | Total Time 0.00(0.00)\n",
      "Iter 14130 | Time 19.6094(19.4588) | Bit/dim 3.4911(3.5305) | Xent 0.0029(0.0051) | Loss 8.8488(9.0999) | Error 0.0000(0.0011) Steps 814(788.34) | Grad Norm 0.7184(0.9932) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 93.2278, Epoch Time 1179.9587(1163.2982), Bit/dim 3.5551(best: 3.5554), Xent 2.4499, Loss 4.7801, Error 0.3628(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14140 | Time 18.6314(19.4060) | Bit/dim 3.5358(3.5291) | Xent 0.0063(0.0056) | Loss 8.8186(9.8454) | Error 0.0022(0.0015) Steps 784(787.78) | Grad Norm 0.9749(1.0022) | Total Time 0.00(0.00)\n",
      "Iter 14150 | Time 19.0548(19.3470) | Bit/dim 3.5486(3.5300) | Xent 0.0019(0.0053) | Loss 8.8174(9.5761) | Error 0.0000(0.0014) Steps 784(786.20) | Grad Norm 0.4023(0.9432) | Total Time 0.00(0.00)\n",
      "Iter 14160 | Time 18.7821(19.3982) | Bit/dim 3.5175(3.5287) | Xent 0.0056(0.0054) | Loss 8.7678(9.3782) | Error 0.0011(0.0014) Steps 760(784.90) | Grad Norm 1.1117(0.9598) | Total Time 0.00(0.00)\n",
      "Iter 14170 | Time 18.7045(19.3902) | Bit/dim 3.5094(3.5274) | Xent 0.0047(0.0056) | Loss 8.7601(9.2232) | Error 0.0000(0.0015) Steps 778(781.49) | Grad Norm 0.6899(1.0054) | Total Time 0.00(0.00)\n",
      "Iter 14180 | Time 21.4524(19.4340) | Bit/dim 3.5240(3.5266) | Xent 0.0049(0.0056) | Loss 8.8606(9.1209) | Error 0.0011(0.0015) Steps 826(783.73) | Grad Norm 1.3321(1.0252) | Total Time 0.00(0.00)\n",
      "Iter 14190 | Time 18.8041(19.5599) | Bit/dim 3.5769(3.5286) | Xent 0.0012(0.0059) | Loss 8.8670(9.0377) | Error 0.0000(0.0015) Steps 802(790.17) | Grad Norm 0.5004(1.1328) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 89.2441, Epoch Time 1176.9283(1163.7071), Bit/dim 3.5526(best: 3.5551), Xent 2.4410, Loss 4.7731, Error 0.3635(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14200 | Time 20.3356(19.4145) | Bit/dim 3.4967(3.5243) | Xent 0.0054(0.0058) | Loss 8.8146(9.6600) | Error 0.0011(0.0014) Steps 820(789.82) | Grad Norm 0.9124(1.1365) | Total Time 0.00(0.00)\n",
      "Iter 14210 | Time 19.0011(19.5532) | Bit/dim 3.5403(3.5254) | Xent 0.0043(0.0060) | Loss 8.8334(9.4477) | Error 0.0011(0.0014) Steps 790(789.84) | Grad Norm 1.5512(1.1458) | Total Time 0.00(0.00)\n",
      "Iter 14220 | Time 19.4454(19.5324) | Bit/dim 3.5495(3.5270) | Xent 0.0049(0.0055) | Loss 8.8943(9.2865) | Error 0.0011(0.0013) Steps 772(787.12) | Grad Norm 1.1167(1.0974) | Total Time 0.00(0.00)\n",
      "Iter 14230 | Time 19.4874(19.4919) | Bit/dim 3.5219(3.5273) | Xent 0.0054(0.0056) | Loss 8.8358(9.1620) | Error 0.0011(0.0014) Steps 784(786.57) | Grad Norm 1.2079(1.0844) | Total Time 0.00(0.00)\n",
      "Iter 14240 | Time 18.9153(19.5466) | Bit/dim 3.5075(3.5277) | Xent 0.0019(0.0052) | Loss 8.7334(9.0709) | Error 0.0000(0.0012) Steps 778(787.69) | Grad Norm 0.3830(0.9939) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 91.1259, Epoch Time 1180.2931(1164.2047), Bit/dim 3.5549(best: 3.5526), Xent 2.5070, Loss 4.8084, Error 0.3671(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14250 | Time 20.0784(19.5688) | Bit/dim 3.5104(3.5274) | Xent 0.0019(0.0050) | Loss 8.7237(9.8243) | Error 0.0000(0.0012) Steps 754(785.45) | Grad Norm 0.4413(0.9750) | Total Time 0.00(0.00)\n",
      "Iter 14260 | Time 19.6172(19.6333) | Bit/dim 3.5195(3.5280) | Xent 0.0031(0.0048) | Loss 8.7683(9.5593) | Error 0.0000(0.0011) Steps 778(785.88) | Grad Norm 0.6799(0.9382) | Total Time 0.00(0.00)\n",
      "Iter 14270 | Time 18.8339(19.5174) | Bit/dim 3.5269(3.5266) | Xent 0.0044(0.0055) | Loss 8.8724(9.3600) | Error 0.0011(0.0012) Steps 784(786.92) | Grad Norm 0.8786(1.0306) | Total Time 0.00(0.00)\n",
      "Iter 14280 | Time 20.2016(19.5308) | Bit/dim 3.5146(3.5258) | Xent 0.0047(0.0050) | Loss 8.6660(9.2159) | Error 0.0011(0.0012) Steps 808(792.16) | Grad Norm 1.0647(1.0203) | Total Time 0.00(0.00)\n",
      "Iter 14290 | Time 19.9999(19.6432) | Bit/dim 3.5356(3.5251) | Xent 0.0034(0.0048) | Loss 8.8583(9.1109) | Error 0.0000(0.0010) Steps 790(791.74) | Grad Norm 0.7666(0.9770) | Total Time 0.00(0.00)\n",
      "Iter 14300 | Time 19.2310(19.6410) | Bit/dim 3.5153(3.5263) | Xent 0.0030(0.0049) | Loss 8.8032(9.0356) | Error 0.0000(0.0012) Steps 784(793.19) | Grad Norm 0.5515(1.0027) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 92.3753, Epoch Time 1189.7811(1164.9720), Bit/dim 3.5547(best: 3.5526), Xent 2.5190, Loss 4.8142, Error 0.3621(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14310 | Time 20.1497(19.7111) | Bit/dim 3.5468(3.5276) | Xent 0.0030(0.0049) | Loss 8.8966(9.6842) | Error 0.0011(0.0012) Steps 820(792.78) | Grad Norm 0.6080(1.0236) | Total Time 0.00(0.00)\n",
      "Iter 14320 | Time 19.6955(19.6705) | Bit/dim 3.5163(3.5260) | Xent 0.0043(0.0053) | Loss 8.8033(9.4635) | Error 0.0011(0.0013) Steps 796(793.49) | Grad Norm 0.9776(1.0475) | Total Time 0.00(0.00)\n",
      "Iter 14330 | Time 20.0798(19.6660) | Bit/dim 3.5313(3.5271) | Xent 0.0051(0.0054) | Loss 8.8451(9.2950) | Error 0.0022(0.0014) Steps 802(791.46) | Grad Norm 1.5761(1.1227) | Total Time 0.00(0.00)\n",
      "Iter 14340 | Time 19.8616(19.6919) | Bit/dim 3.4931(3.5267) | Xent 0.0041(0.0055) | Loss 8.6768(9.1701) | Error 0.0011(0.0014) Steps 784(789.59) | Grad Norm 0.9807(1.1341) | Total Time 0.00(0.00)\n",
      "Iter 14350 | Time 19.7293(19.6481) | Bit/dim 3.5144(3.5257) | Xent 0.0031(0.0055) | Loss 8.8527(9.0766) | Error 0.0011(0.0015) Steps 826(787.62) | Grad Norm 1.2995(1.1604) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 91.4960, Epoch Time 1194.2056(1165.8490), Bit/dim 3.5542(best: 3.5526), Xent 2.5415, Loss 4.8250, Error 0.3650(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14360 | Time 19.6689(19.6910) | Bit/dim 3.5529(3.5233) | Xent 0.0095(0.0057) | Loss 8.9721(9.8082) | Error 0.0011(0.0014) Steps 760(785.62) | Grad Norm 0.8571(1.1860) | Total Time 0.00(0.00)\n",
      "Iter 14370 | Time 19.2894(19.6297) | Bit/dim 3.4770(3.5242) | Xent 0.0047(0.0053) | Loss 8.7759(9.5612) | Error 0.0022(0.0014) Steps 784(786.13) | Grad Norm 0.9017(1.1296) | Total Time 0.00(0.00)\n",
      "Iter 14380 | Time 20.5256(19.7124) | Bit/dim 3.5444(3.5239) | Xent 0.0073(0.0055) | Loss 8.9376(9.3688) | Error 0.0011(0.0014) Steps 784(783.24) | Grad Norm 0.8670(1.1111) | Total Time 0.00(0.00)\n",
      "Iter 14390 | Time 19.6677(19.6934) | Bit/dim 3.5401(3.5261) | Xent 0.0024(0.0054) | Loss 8.9685(9.2302) | Error 0.0000(0.0013) Steps 778(783.55) | Grad Norm 0.4542(1.0822) | Total Time 0.00(0.00)\n",
      "Iter 14400 | Time 19.3548(19.5443) | Bit/dim 3.5368(3.5265) | Xent 0.0059(0.0053) | Loss 8.8387(9.1243) | Error 0.0022(0.0013) Steps 796(783.49) | Grad Norm 1.2419(1.1469) | Total Time 0.00(0.00)\n",
      "Iter 14410 | Time 19.5097(19.5141) | Bit/dim 3.5174(3.5247) | Xent 0.0023(0.0051) | Loss 8.8512(9.0460) | Error 0.0000(0.0012) Steps 802(784.77) | Grad Norm 0.5334(1.0965) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 91.1908, Epoch Time 1183.0854(1166.3661), Bit/dim 3.5566(best: 3.5526), Xent 2.5739, Loss 4.8435, Error 0.3648(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14420 | Time 20.3261(19.4719) | Bit/dim 3.5327(3.5234) | Xent 0.0017(0.0046) | Loss 8.7755(9.6680) | Error 0.0000(0.0011) Steps 748(785.46) | Grad Norm 0.4446(1.0692) | Total Time 0.00(0.00)\n",
      "Iter 14430 | Time 20.9861(19.6349) | Bit/dim 3.5113(3.5233) | Xent 0.0032(0.0043) | Loss 8.7364(9.4428) | Error 0.0011(0.0011) Steps 766(784.68) | Grad Norm 1.0683(1.0600) | Total Time 0.00(0.00)\n",
      "Iter 14440 | Time 18.4791(19.5793) | Bit/dim 3.5199(3.5223) | Xent 0.0051(0.0047) | Loss 8.7087(9.2748) | Error 0.0011(0.0013) Steps 760(783.17) | Grad Norm 1.1758(1.1457) | Total Time 0.00(0.00)\n",
      "Iter 14450 | Time 19.2297(19.5265) | Bit/dim 3.5298(3.5240) | Xent 0.0013(0.0045) | Loss 8.9108(9.1612) | Error 0.0000(0.0012) Steps 796(782.22) | Grad Norm 0.4485(1.1268) | Total Time 0.00(0.00)\n",
      "Iter 14460 | Time 18.9017(19.5722) | Bit/dim 3.5024(3.5241) | Xent 0.0055(0.0048) | Loss 8.8562(9.0634) | Error 0.0011(0.0013) Steps 814(783.50) | Grad Norm 2.5293(1.1880) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 90.0863, Epoch Time 1182.0246(1166.8359), Bit/dim 3.5565(best: 3.5526), Xent 2.5834, Loss 4.8482, Error 0.3664(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14470 | Time 19.1775(19.5035) | Bit/dim 3.5035(3.5238) | Xent 0.0041(0.0044) | Loss 8.9213(9.8064) | Error 0.0011(0.0011) Steps 796(784.89) | Grad Norm 1.2610(1.1723) | Total Time 0.00(0.00)\n",
      "Iter 14480 | Time 19.6477(19.5976) | Bit/dim 3.5201(3.5228) | Xent 0.0020(0.0040) | Loss 8.8139(9.5380) | Error 0.0000(0.0010) Steps 790(786.32) | Grad Norm 0.6551(1.0695) | Total Time 0.00(0.00)\n",
      "Iter 14490 | Time 19.5599(19.6544) | Bit/dim 3.5156(3.5232) | Xent 0.0036(0.0040) | Loss 8.8212(9.3428) | Error 0.0000(0.0010) Steps 790(786.72) | Grad Norm 0.5539(1.0597) | Total Time 0.00(0.00)\n",
      "Iter 14500 | Time 19.7846(19.6676) | Bit/dim 3.5050(3.5233) | Xent 0.0047(0.0040) | Loss 8.7818(9.2032) | Error 0.0011(0.0009) Steps 778(786.07) | Grad Norm 1.4381(1.0342) | Total Time 0.00(0.00)\n",
      "Iter 14510 | Time 19.6270(19.6775) | Bit/dim 3.5072(3.5223) | Xent 0.0035(0.0043) | Loss 8.8295(9.1044) | Error 0.0011(0.0010) Steps 802(785.43) | Grad Norm 1.2315(1.0919) | Total Time 0.00(0.00)\n",
      "Iter 14520 | Time 19.8049(19.6130) | Bit/dim 3.5702(3.5245) | Xent 0.0058(0.0045) | Loss 8.9419(9.0368) | Error 0.0033(0.0011) Steps 808(785.65) | Grad Norm 1.3347(1.1392) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 89.4940, Epoch Time 1188.7555(1167.4935), Bit/dim 3.5534(best: 3.5526), Xent 2.6240, Loss 4.8654, Error 0.3667(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14530 | Time 19.4414(19.5791) | Bit/dim 3.5016(3.5236) | Xent 0.0090(0.0042) | Loss 8.6938(9.6808) | Error 0.0044(0.0011) Steps 790(784.93) | Grad Norm 2.3721(1.0850) | Total Time 0.00(0.00)\n",
      "Iter 14540 | Time 20.6514(19.6982) | Bit/dim 3.5316(3.5226) | Xent 0.0036(0.0041) | Loss 8.7723(9.4496) | Error 0.0011(0.0010) Steps 772(787.68) | Grad Norm 0.9096(1.0218) | Total Time 0.00(0.00)\n",
      "Iter 14550 | Time 19.6739(19.7055) | Bit/dim 3.5251(3.5231) | Xent 0.0105(0.0044) | Loss 8.7800(9.2813) | Error 0.0033(0.0010) Steps 772(787.73) | Grad Norm 1.6082(1.1104) | Total Time 0.00(0.00)\n",
      "Iter 14560 | Time 20.1994(19.7338) | Bit/dim 3.5196(3.5214) | Xent 0.0020(0.0046) | Loss 8.8046(9.1500) | Error 0.0000(0.0010) Steps 814(787.82) | Grad Norm 0.5131(1.1019) | Total Time 0.00(0.00)\n",
      "Iter 14570 | Time 19.9796(19.6795) | Bit/dim 3.5503(3.5256) | Xent 0.0057(0.0045) | Loss 8.9131(9.0728) | Error 0.0011(0.0011) Steps 778(787.42) | Grad Norm 1.1266(1.1174) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 92.1682, Epoch Time 1190.8980(1168.1956), Bit/dim 3.5565(best: 3.5526), Xent 2.6499, Loss 4.8814, Error 0.3701(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14580 | Time 18.5858(19.6680) | Bit/dim 3.5481(3.5258) | Xent 0.0037(0.0043) | Loss 8.7649(9.8184) | Error 0.0011(0.0011) Steps 754(784.83) | Grad Norm 0.9254(1.1005) | Total Time 0.00(0.00)\n",
      "Iter 14590 | Time 19.5602(19.6817) | Bit/dim 3.5203(3.5251) | Xent 0.0052(0.0044) | Loss 8.9210(9.5561) | Error 0.0011(0.0011) Steps 808(785.12) | Grad Norm 1.0705(1.1463) | Total Time 0.00(0.00)\n",
      "Iter 14600 | Time 19.8846(19.6309) | Bit/dim 3.4984(3.5239) | Xent 0.0014(0.0044) | Loss 8.8128(9.3564) | Error 0.0000(0.0011) Steps 820(785.63) | Grad Norm 0.5441(1.1708) | Total Time 0.00(0.00)\n",
      "Iter 14610 | Time 19.1313(19.7645) | Bit/dim 3.4991(3.5205) | Xent 0.0066(0.0043) | Loss 8.7684(9.2040) | Error 0.0011(0.0010) Steps 796(786.81) | Grad Norm 0.9381(1.1810) | Total Time 0.00(0.00)\n",
      "Iter 14620 | Time 19.6851(19.7471) | Bit/dim 3.5224(3.5241) | Xent 0.0137(0.0044) | Loss 8.8776(9.1128) | Error 0.0022(0.0010) Steps 814(788.85) | Grad Norm 1.1615(1.1458) | Total Time 0.00(0.00)\n",
      "Iter 14630 | Time 20.2405(19.8560) | Bit/dim 3.5025(3.5215) | Xent 0.0084(0.0045) | Loss 8.7088(9.0188) | Error 0.0033(0.0013) Steps 736(786.92) | Grad Norm 2.2468(1.1882) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 93.3090, Epoch Time 1201.7167(1169.2012), Bit/dim 3.5578(best: 3.5526), Xent 2.6331, Loss 4.8743, Error 0.3666(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14640 | Time 19.6193(19.7938) | Bit/dim 3.5586(3.5225) | Xent 0.0039(0.0050) | Loss 8.9614(9.6509) | Error 0.0011(0.0014) Steps 808(788.23) | Grad Norm 1.3806(1.3130) | Total Time 0.00(0.00)\n",
      "Iter 14650 | Time 19.8793(19.7855) | Bit/dim 3.4897(3.5195) | Xent 0.0032(0.0047) | Loss 8.6000(9.4229) | Error 0.0011(0.0013) Steps 796(788.58) | Grad Norm 0.7060(1.2144) | Total Time 0.00(0.00)\n",
      "Iter 14660 | Time 19.0818(19.8173) | Bit/dim 3.5204(3.5193) | Xent 0.0034(0.0044) | Loss 8.7709(9.2587) | Error 0.0011(0.0011) Steps 784(785.57) | Grad Norm 1.0232(1.1981) | Total Time 0.00(0.00)\n",
      "Iter 14670 | Time 20.0696(19.7324) | Bit/dim 3.5219(3.5198) | Xent 0.0012(0.0045) | Loss 8.8159(9.1368) | Error 0.0000(0.0011) Steps 778(784.90) | Grad Norm 0.4077(1.1313) | Total Time 0.00(0.00)\n",
      "Iter 14680 | Time 19.3832(19.7319) | Bit/dim 3.5628(3.5250) | Xent 0.0014(0.0049) | Loss 8.9036(9.0699) | Error 0.0000(0.0013) Steps 814(786.07) | Grad Norm 0.6661(1.2176) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0267 | Time 92.0350, Epoch Time 1196.9212(1170.0328), Bit/dim 3.5555(best: 3.5526), Xent 2.6542, Loss 4.8826, Error 0.3665(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14690 | Time 20.1096(19.8619) | Bit/dim 3.5356(3.5240) | Xent 0.0024(0.0049) | Loss 8.8207(9.8085) | Error 0.0011(0.0012) Steps 766(788.02) | Grad Norm 1.4235(1.2104) | Total Time 0.00(0.00)\n",
      "Iter 14700 | Time 21.2665(19.9057) | Bit/dim 3.5307(3.5243) | Xent 0.0026(0.0044) | Loss 8.8669(9.5456) | Error 0.0011(0.0010) Steps 808(786.30) | Grad Norm 0.9675(1.1375) | Total Time 0.00(0.00)\n",
      "Iter 14710 | Time 18.6284(19.9055) | Bit/dim 3.5300(3.5225) | Xent 0.0024(0.0051) | Loss 8.8307(9.3504) | Error 0.0000(0.0011) Steps 790(787.29) | Grad Norm 1.6888(1.4534) | Total Time 0.00(0.00)\n",
      "Iter 14720 | Time 19.0964(19.8506) | Bit/dim 3.5274(3.5215) | Xent 0.0023(0.0049) | Loss 8.7353(9.2080) | Error 0.0000(0.0011) Steps 784(789.04) | Grad Norm 0.7096(1.3627) | Total Time 0.00(0.00)\n",
      "Iter 14730 | Time 22.0881(19.8945) | Bit/dim 3.5204(3.5219) | Xent 0.0023(0.0047) | Loss 8.8035(9.0988) | Error 0.0011(0.0010) Steps 808(790.65) | Grad Norm 0.8746(1.3494) | Total Time 0.00(0.00)\n",
      "Iter 14740 | Time 20.0489(19.9971) | Bit/dim 3.5455(3.5247) | Xent 0.0017(0.0045) | Loss 8.7960(9.0245) | Error 0.0000(0.0009) Steps 808(790.24) | Grad Norm 0.6719(1.2220) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0268 | Time 90.3688, Epoch Time 1206.2675(1171.1199), Bit/dim 3.5549(best: 3.5526), Xent 2.6451, Loss 4.8774, Error 0.3633(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14750 | Time 19.2361(19.8770) | Bit/dim 3.5114(3.5238) | Xent 0.0030(0.0041) | Loss 8.7839(9.6598) | Error 0.0000(0.0008) Steps 778(790.90) | Grad Norm 0.9801(1.1135) | Total Time 0.00(0.00)\n",
      "Iter 14760 | Time 20.0112(19.9067) | Bit/dim 3.5108(3.5208) | Xent 0.0113(0.0050) | Loss 8.7809(9.4305) | Error 0.0033(0.0012) Steps 766(792.89) | Grad Norm 2.0998(1.2385) | Total Time 0.00(0.00)\n",
      "Iter 14770 | Time 19.3194(19.7824) | Bit/dim 3.5066(3.5234) | Xent 0.0095(0.0047) | Loss 8.7027(9.2735) | Error 0.0033(0.0012) Steps 778(789.46) | Grad Norm 1.3564(1.2720) | Total Time 0.00(0.00)\n",
      "Iter 14780 | Time 19.6007(19.7281) | Bit/dim 3.5288(3.5253) | Xent 0.0054(0.0043) | Loss 8.7322(9.1534) | Error 0.0011(0.0010) Steps 790(788.19) | Grad Norm 1.6332(1.1622) | Total Time 0.00(0.00)\n",
      "Iter 14790 | Time 19.7493(19.7655) | Bit/dim 3.5307(3.5241) | Xent 0.0064(0.0042) | Loss 8.7718(9.0571) | Error 0.0022(0.0012) Steps 796(786.08) | Grad Norm 1.4872(1.1716) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0269 | Time 89.7041, Epoch Time 1186.3668(1171.5773), Bit/dim 3.5541(best: 3.5526), Xent 2.6740, Loss 4.8911, Error 0.3661(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14800 | Time 20.5527(19.7029) | Bit/dim 3.4959(3.5228) | Xent 0.0187(0.0046) | Loss 8.7605(9.7977) | Error 0.0033(0.0012) Steps 802(789.90) | Grad Norm 2.1847(1.1758) | Total Time 0.00(0.00)\n",
      "Iter 14810 | Time 20.4562(19.7520) | Bit/dim 3.5412(3.5234) | Xent 0.0030(0.0040) | Loss 8.8537(9.5413) | Error 0.0000(0.0010) Steps 766(788.53) | Grad Norm 1.1553(1.1157) | Total Time 0.00(0.00)\n",
      "Iter 14820 | Time 18.9354(19.7634) | Bit/dim 3.4871(3.5211) | Xent 0.0040(0.0039) | Loss 8.6810(9.3463) | Error 0.0011(0.0009) Steps 790(790.55) | Grad Norm 0.9061(1.1026) | Total Time 0.00(0.00)\n",
      "Iter 14830 | Time 19.2318(19.6260) | Bit/dim 3.5284(3.5219) | Xent 0.0028(0.0043) | Loss 8.7535(9.1938) | Error 0.0000(0.0010) Steps 772(787.95) | Grad Norm 0.9108(1.2080) | Total Time 0.00(0.00)\n",
      "Iter 14840 | Time 19.8830(19.7334) | Bit/dim 3.4796(3.5227) | Xent 0.0096(0.0042) | Loss 8.8235(9.1085) | Error 0.0011(0.0009) Steps 784(788.96) | Grad Norm 2.3215(1.2236) | Total Time 0.00(0.00)\n",
      "Iter 14850 | Time 19.9902(19.6758) | Bit/dim 3.4962(3.5209) | Xent 0.0047(0.0046) | Loss 8.6697(9.0202) | Error 0.0011(0.0011) Steps 778(786.63) | Grad Norm 0.9977(1.2987) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0270 | Time 90.4803, Epoch Time 1191.6721(1172.1801), Bit/dim 3.5540(best: 3.5526), Xent 2.6840, Loss 4.8961, Error 0.3651(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14860 | Time 20.4690(19.6734) | Bit/dim 3.5131(3.5206) | Xent 0.0091(0.0047) | Loss 8.8922(9.6565) | Error 0.0022(0.0012) Steps 772(784.45) | Grad Norm 2.5508(1.3287) | Total Time 0.00(0.00)\n",
      "Iter 14870 | Time 18.2775(19.6056) | Bit/dim 3.5358(3.5225) | Xent 0.0015(0.0045) | Loss 8.7531(9.4294) | Error 0.0000(0.0011) Steps 778(785.51) | Grad Norm 0.5791(1.2350) | Total Time 0.00(0.00)\n",
      "Iter 14880 | Time 19.6355(19.6434) | Bit/dim 3.4930(3.5209) | Xent 0.0023(0.0044) | Loss 8.8063(9.2699) | Error 0.0000(0.0010) Steps 766(785.45) | Grad Norm 0.9972(1.2324) | Total Time 0.00(0.00)\n",
      "Iter 14890 | Time 19.3904(19.8182) | Bit/dim 3.5258(3.5202) | Xent 0.0046(0.0043) | Loss 8.8296(9.1475) | Error 0.0022(0.0010) Steps 802(787.37) | Grad Norm 1.1028(1.2243) | Total Time 0.00(0.00)\n",
      "Iter 14900 | Time 19.8658(19.7411) | Bit/dim 3.5055(3.5192) | Xent 0.0012(0.0041) | Loss 8.7968(9.0487) | Error 0.0000(0.0010) Steps 760(786.93) | Grad Norm 0.5406(1.1949) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0271 | Time 90.7250, Epoch Time 1191.3620(1172.7556), Bit/dim 3.5550(best: 3.5526), Xent 2.6994, Loss 4.9047, Error 0.3647(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14910 | Time 20.0354(19.7835) | Bit/dim 3.5258(3.5209) | Xent 0.0020(0.0038) | Loss 8.8101(9.7827) | Error 0.0011(0.0009) Steps 760(787.05) | Grad Norm 1.1215(1.1579) | Total Time 0.00(0.00)\n",
      "Iter 14920 | Time 20.4384(19.7291) | Bit/dim 3.5006(3.5228) | Xent 0.0015(0.0038) | Loss 8.7643(9.5256) | Error 0.0000(0.0009) Steps 844(788.48) | Grad Norm 0.4587(1.0889) | Total Time 0.00(0.00)\n",
      "Iter 14930 | Time 19.4631(19.7012) | Bit/dim 3.5312(3.5234) | Xent 0.0017(0.0037) | Loss 8.8539(9.3425) | Error 0.0000(0.0009) Steps 784(787.64) | Grad Norm 0.6097(1.0218) | Total Time 0.00(0.00)\n",
      "Iter 14940 | Time 20.0729(19.7268) | Bit/dim 3.5304(3.5208) | Xent 0.0015(0.0036) | Loss 8.8395(9.1946) | Error 0.0000(0.0009) Steps 802(785.73) | Grad Norm 0.5771(1.0529) | Total Time 0.00(0.00)\n",
      "Iter 14950 | Time 19.4040(19.6748) | Bit/dim 3.5069(3.5161) | Xent 0.0022(0.0035) | Loss 8.7050(9.0726) | Error 0.0000(0.0007) Steps 802(787.04) | Grad Norm 0.5960(1.0231) | Total Time 0.00(0.00)\n",
      "Iter 14960 | Time 20.0727(19.5536) | Bit/dim 3.5449(3.5179) | Xent 0.0032(0.0036) | Loss 8.7964(8.9954) | Error 0.0011(0.0009) Steps 790(786.64) | Grad Norm 1.0588(1.1494) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0272 | Time 91.8766, Epoch Time 1188.1088(1173.2162), Bit/dim 3.5523(best: 3.5526), Xent 2.7313, Loss 4.9180, Error 0.3671(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14970 | Time 19.6069(19.5759) | Bit/dim 3.5631(3.5193) | Xent 0.0069(0.0036) | Loss 8.8934(9.6190) | Error 0.0011(0.0008) Steps 802(788.53) | Grad Norm 1.5200(1.1489) | Total Time 0.00(0.00)\n",
      "Iter 14980 | Time 20.0456(19.5672) | Bit/dim 3.5347(3.5193) | Xent 0.0008(0.0036) | Loss 8.7841(9.3940) | Error 0.0000(0.0009) Steps 748(788.32) | Grad Norm 0.4757(1.0876) | Total Time 0.00(0.00)\n",
      "Iter 14990 | Time 20.5152(19.7037) | Bit/dim 3.5149(3.5183) | Xent 0.0011(0.0039) | Loss 8.8906(9.2313) | Error 0.0000(0.0009) Steps 778(785.74) | Grad Norm 0.4398(1.0469) | Total Time 0.00(0.00)\n",
      "Iter 15000 | Time 18.4996(19.5849) | Bit/dim 3.5610(3.5195) | Xent 0.0075(0.0042) | Loss 8.7745(9.1205) | Error 0.0011(0.0009) Steps 778(786.12) | Grad Norm 1.4559(1.1249) | Total Time 0.00(0.00)\n",
      "Iter 15010 | Time 20.7001(19.6590) | Bit/dim 3.5375(3.5205) | Xent 0.0022(0.0046) | Loss 8.9274(9.0473) | Error 0.0000(0.0011) Steps 784(789.28) | Grad Norm 0.7255(1.2954) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0273 | Time 91.2376, Epoch Time 1193.1351(1173.8137), Bit/dim 3.5548(best: 3.5523), Xent 2.7745, Loss 4.9421, Error 0.3699(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15020 | Time 19.2627(19.6799) | Bit/dim 3.5166(3.5209) | Xent 0.0011(0.0043) | Loss 8.7978(9.8050) | Error 0.0000(0.0010) Steps 778(788.86) | Grad Norm 0.4803(1.2734) | Total Time 0.00(0.00)\n",
      "Iter 15030 | Time 19.8993(19.6239) | Bit/dim 3.5206(3.5195) | Xent 0.0032(0.0042) | Loss 8.7229(9.5406) | Error 0.0011(0.0012) Steps 760(786.77) | Grad Norm 1.0623(1.2680) | Total Time 0.00(0.00)\n",
      "Iter 15040 | Time 20.2032(19.7202) | Bit/dim 3.5573(3.5207) | Xent 0.0009(0.0038) | Loss 8.8692(9.3555) | Error 0.0000(0.0011) Steps 796(785.99) | Grad Norm 0.3999(1.1997) | Total Time 0.00(0.00)\n",
      "Iter 15050 | Time 19.3105(19.6694) | Bit/dim 3.5252(3.5212) | Xent 0.0077(0.0042) | Loss 8.8768(9.2076) | Error 0.0022(0.0013) Steps 808(785.56) | Grad Norm 2.3955(1.2721) | Total Time 0.00(0.00)\n",
      "Iter 15060 | Time 20.0847(19.6559) | Bit/dim 3.5364(3.5194) | Xent 0.0025(0.0041) | Loss 8.8334(9.0936) | Error 0.0011(0.0013) Steps 772(784.05) | Grad Norm 1.1190(1.3236) | Total Time 0.00(0.00)\n",
      "Iter 15070 | Time 19.3816(19.7752) | Bit/dim 3.5439(3.5204) | Xent 0.0027(0.0041) | Loss 8.9363(9.0253) | Error 0.0011(0.0013) Steps 748(782.23) | Grad Norm 1.0108(1.2915) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0274 | Time 89.7143, Epoch Time 1190.1375(1174.3035), Bit/dim 3.5530(best: 3.5523), Xent 2.7293, Loss 4.9177, Error 0.3639(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15080 | Time 20.1370(19.6921) | Bit/dim 3.5108(3.5191) | Xent 0.0013(0.0037) | Loss 8.7351(9.6470) | Error 0.0000(0.0011) Steps 802(782.00) | Grad Norm 0.8986(1.2330) | Total Time 0.00(0.00)\n",
      "Iter 15090 | Time 20.1819(19.7485) | Bit/dim 3.5026(3.5161) | Xent 0.0071(0.0041) | Loss 8.7808(9.4098) | Error 0.0022(0.0011) Steps 796(782.45) | Grad Norm 2.2880(1.3006) | Total Time 0.00(0.00)\n",
      "Iter 15100 | Time 19.5302(19.7377) | Bit/dim 3.5318(3.5222) | Xent 0.0106(0.0041) | Loss 8.7823(9.2621) | Error 0.0033(0.0012) Steps 742(780.75) | Grad Norm 2.2600(1.2732) | Total Time 0.00(0.00)\n",
      "Iter 15110 | Time 18.5697(19.6034) | Bit/dim 3.5163(3.5204) | Xent 0.0023(0.0041) | Loss 8.7552(9.1361) | Error 0.0000(0.0011) Steps 754(780.80) | Grad Norm 0.6234(1.2188) | Total Time 0.00(0.00)\n",
      "Iter 15120 | Time 18.8795(19.7016) | Bit/dim 3.5010(3.5220) | Xent 0.0100(0.0043) | Loss 8.7760(9.0504) | Error 0.0022(0.0011) Steps 790(782.06) | Grad Norm 1.6195(1.2332) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0275 | Time 90.0025, Epoch Time 1186.8250(1174.6791), Bit/dim 3.5543(best: 3.5523), Xent 2.7670, Loss 4.9378, Error 0.3676(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15130 | Time 20.6873(19.6587) | Bit/dim 3.5152(3.5180) | Xent 0.0020(0.0043) | Loss 8.7716(9.7924) | Error 0.0000(0.0010) Steps 802(784.36) | Grad Norm 0.6993(1.2343) | Total Time 0.00(0.00)\n",
      "Iter 15140 | Time 18.9078(19.7211) | Bit/dim 3.5070(3.5172) | Xent 0.0121(0.0045) | Loss 8.7432(9.5246) | Error 0.0011(0.0009) Steps 742(784.89) | Grad Norm 0.8178(1.1744) | Total Time 0.00(0.00)\n",
      "Iter 15150 | Time 18.9619(19.6791) | Bit/dim 3.5175(3.5193) | Xent 0.0016(0.0041) | Loss 8.8322(9.3356) | Error 0.0000(0.0008) Steps 754(785.50) | Grad Norm 0.6987(1.1288) | Total Time 0.00(0.00)\n",
      "Iter 15160 | Time 21.0942(19.6769) | Bit/dim 3.5487(3.5211) | Xent 0.0016(0.0039) | Loss 8.8386(9.1925) | Error 0.0000(0.0009) Steps 772(785.26) | Grad Norm 0.6030(1.1464) | Total Time 0.00(0.00)\n",
      "Iter 15170 | Time 20.3093(19.6400) | Bit/dim 3.4944(3.5209) | Xent 0.0032(0.0041) | Loss 8.7250(9.0810) | Error 0.0011(0.0010) Steps 808(783.54) | Grad Norm 1.1193(1.1809) | Total Time 0.00(0.00)\n",
      "Iter 15180 | Time 19.4957(19.6475) | Bit/dim 3.5290(3.5175) | Xent 0.0090(0.0042) | Loss 8.7250(8.9942) | Error 0.0033(0.0011) Steps 796(785.07) | Grad Norm 2.3654(1.2459) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0276 | Time 92.1908, Epoch Time 1190.6711(1175.1589), Bit/dim 3.5527(best: 3.5523), Xent 2.7642, Loss 4.9347, Error 0.3672(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15190 | Time 19.8660(19.6889) | Bit/dim 3.5194(3.5177) | Xent 0.0061(0.0039) | Loss 8.9309(9.6437) | Error 0.0044(0.0011) Steps 808(784.93) | Grad Norm 2.4344(1.2437) | Total Time 0.00(0.00)\n",
      "Iter 15200 | Time 20.3027(19.6240) | Bit/dim 3.5515(3.5176) | Xent 0.0023(0.0036) | Loss 8.8974(9.4285) | Error 0.0000(0.0009) Steps 808(788.31) | Grad Norm 1.0119(1.2581) | Total Time 0.00(0.00)\n",
      "Iter 15210 | Time 19.9266(19.6383) | Bit/dim 3.4953(3.5171) | Xent 0.0055(0.0037) | Loss 8.7054(9.2542) | Error 0.0011(0.0010) Steps 802(789.14) | Grad Norm 2.2588(1.4320) | Total Time 0.00(0.00)\n",
      "Iter 15220 | Time 19.6370(19.7715) | Bit/dim 3.5096(3.5181) | Xent 0.0044(0.0039) | Loss 8.7990(9.1327) | Error 0.0011(0.0010) Steps 766(791.19) | Grad Norm 1.5794(1.4186) | Total Time 0.00(0.00)\n",
      "Iter 15230 | Time 19.0285(19.7261) | Bit/dim 3.5414(3.5190) | Xent 0.0040(0.0041) | Loss 8.8094(9.0462) | Error 0.0011(0.0011) Steps 784(787.65) | Grad Norm 1.9777(1.4077) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0277 | Time 94.3763, Epoch Time 1199.8380(1175.8992), Bit/dim 3.5507(best: 3.5523), Xent 2.7685, Loss 4.9350, Error 0.3645(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15240 | Time 18.8395(19.7816) | Bit/dim 3.4707(3.5199) | Xent 0.0073(0.0037) | Loss 8.6878(9.7887) | Error 0.0011(0.0010) Steps 790(786.39) | Grad Norm 1.7722(1.3915) | Total Time 0.00(0.00)\n",
      "Iter 15250 | Time 19.9935(19.8211) | Bit/dim 3.5233(3.5182) | Xent 0.0013(0.0033) | Loss 8.8186(9.5279) | Error 0.0000(0.0009) Steps 790(788.23) | Grad Norm 0.4722(1.3114) | Total Time 0.00(0.00)\n",
      "Iter 15260 | Time 20.7565(19.8817) | Bit/dim 3.5540(3.5186) | Xent 0.0010(0.0037) | Loss 8.7997(9.3337) | Error 0.0000(0.0010) Steps 808(789.27) | Grad Norm 0.5500(1.3268) | Total Time 0.00(0.00)\n",
      "Iter 15270 | Time 18.9797(19.8253) | Bit/dim 3.5248(3.5192) | Xent 0.0015(0.0035) | Loss 8.8093(9.1959) | Error 0.0000(0.0009) Steps 808(790.33) | Grad Norm 0.5793(1.3123) | Total Time 0.00(0.00)\n",
      "Iter 15280 | Time 20.2602(19.7712) | Bit/dim 3.5152(3.5200) | Xent 0.0009(0.0034) | Loss 8.8768(9.0957) | Error 0.0000(0.0009) Steps 832(789.72) | Grad Norm 0.9614(1.2888) | Total Time 0.00(0.00)\n",
      "Iter 15290 | Time 19.4450(19.8183) | Bit/dim 3.4911(3.5168) | Xent 0.0072(0.0034) | Loss 8.6242(9.0066) | Error 0.0022(0.0008) Steps 772(788.05) | Grad Norm 3.1243(1.3039) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0278 | Time 90.5660, Epoch Time 1197.5983(1176.5502), Bit/dim 3.5494(best: 3.5507), Xent 2.8071, Loss 4.9530, Error 0.3710(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15300 | Time 18.6047(19.6883) | Bit/dim 3.5171(3.5170) | Xent 0.0051(0.0042) | Loss 8.8055(9.6413) | Error 0.0011(0.0009) Steps 790(786.22) | Grad Norm 1.4620(1.3984) | Total Time 0.00(0.00)\n",
      "Iter 15310 | Time 21.4663(19.8169) | Bit/dim 3.4950(3.5184) | Xent 0.0066(0.0040) | Loss 8.6600(9.4167) | Error 0.0011(0.0009) Steps 784(782.81) | Grad Norm 1.6327(1.4642) | Total Time 0.00(0.00)\n",
      "Iter 15320 | Time 19.5885(19.7862) | Bit/dim 3.5274(3.5168) | Xent 0.0044(0.0045) | Loss 8.7276(9.2542) | Error 0.0011(0.0010) Steps 784(785.27) | Grad Norm 1.2474(1.4884) | Total Time 0.00(0.00)\n",
      "Iter 15330 | Time 19.2520(19.7131) | Bit/dim 3.5082(3.5167) | Xent 0.0023(0.0047) | Loss 8.8303(9.1401) | Error 0.0000(0.0011) Steps 790(787.47) | Grad Norm 0.9060(1.4596) | Total Time 0.00(0.00)\n",
      "Iter 15340 | Time 20.3648(19.8115) | Bit/dim 3.5319(3.5177) | Xent 0.0008(0.0045) | Loss 8.7284(9.0487) | Error 0.0000(0.0011) Steps 796(789.09) | Grad Norm 0.7569(1.4618) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0279 | Time 90.9965, Epoch Time 1195.5347(1177.1197), Bit/dim 3.5516(best: 3.5494), Xent 2.7917, Loss 4.9475, Error 0.3674(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15350 | Time 20.0142(19.8157) | Bit/dim 3.5361(3.5183) | Xent 0.0032(0.0042) | Loss 8.8398(9.7677) | Error 0.0011(0.0010) Steps 808(789.52) | Grad Norm 0.9949(1.3276) | Total Time 0.00(0.00)\n",
      "Iter 15360 | Time 21.4447(19.8831) | Bit/dim 3.5251(3.5174) | Xent 0.0036(0.0038) | Loss 8.8229(9.5120) | Error 0.0011(0.0009) Steps 760(788.40) | Grad Norm 2.1431(1.2673) | Total Time 0.00(0.00)\n",
      "Iter 15370 | Time 19.1054(19.8293) | Bit/dim 3.5312(3.5165) | Xent 0.0008(0.0038) | Loss 8.7837(9.3235) | Error 0.0000(0.0010) Steps 760(788.02) | Grad Norm 0.4742(1.2373) | Total Time 0.00(0.00)\n",
      "Iter 15380 | Time 19.5105(19.8035) | Bit/dim 3.4935(3.5150) | Xent 0.0015(0.0038) | Loss 8.8248(9.1859) | Error 0.0000(0.0010) Steps 814(787.46) | Grad Norm 0.4478(1.2274) | Total Time 0.00(0.00)\n",
      "Iter 15390 | Time 19.6522(19.8257) | Bit/dim 3.5194(3.5191) | Xent 0.0025(0.0036) | Loss 8.7846(9.0766) | Error 0.0000(0.0009) Steps 784(784.46) | Grad Norm 0.8415(1.2123) | Total Time 0.00(0.00)\n",
      "Iter 15400 | Time 19.1049(19.8139) | Bit/dim 3.5315(3.5173) | Xent 0.0046(0.0037) | Loss 8.8659(9.0003) | Error 0.0011(0.0009) Steps 784(783.53) | Grad Norm 1.4575(1.1906) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0280 | Time 90.1384, Epoch Time 1197.6898(1177.7368), Bit/dim 3.5558(best: 3.5494), Xent 2.7777, Loss 4.9446, Error 0.3651(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15410 | Time 20.7899(19.9039) | Bit/dim 3.5334(3.5183) | Xent 0.0072(0.0038) | Loss 8.8518(9.6090) | Error 0.0022(0.0010) Steps 796(785.88) | Grad Norm 2.2610(1.2266) | Total Time 0.00(0.00)\n",
      "Iter 15420 | Time 19.8672(19.7670) | Bit/dim 3.5437(3.5201) | Xent 0.0016(0.0034) | Loss 8.9089(9.3949) | Error 0.0000(0.0009) Steps 778(785.78) | Grad Norm 0.7485(1.1824) | Total Time 0.00(0.00)\n",
      "Iter 15430 | Time 19.5888(19.6641) | Bit/dim 3.5116(3.5199) | Xent 0.0008(0.0033) | Loss 8.7456(9.2226) | Error 0.0000(0.0009) Steps 814(783.40) | Grad Norm 0.5027(1.1940) | Total Time 0.00(0.00)\n",
      "Iter 15440 | Time 19.7967(19.7510) | Bit/dim 3.5076(3.5195) | Xent 0.0030(0.0034) | Loss 8.6388(9.1091) | Error 0.0011(0.0009) Steps 784(780.00) | Grad Norm 0.6650(1.1599) | Total Time 0.00(0.00)\n",
      "Iter 15450 | Time 19.5212(19.7043) | Bit/dim 3.5474(3.5164) | Xent 0.0068(0.0039) | Loss 8.9184(9.0192) | Error 0.0011(0.0009) Steps 790(781.82) | Grad Norm 3.0482(1.2597) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0281 | Time 90.6028, Epoch Time 1189.6203(1178.0933), Bit/dim 3.5538(best: 3.5494), Xent 2.7977, Loss 4.9526, Error 0.3669(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15460 | Time 19.7817(19.7505) | Bit/dim 3.5303(3.5160) | Xent 0.0022(0.0039) | Loss 8.8259(9.7710) | Error 0.0000(0.0009) Steps 796(785.22) | Grad Norm 0.6902(1.1664) | Total Time 0.00(0.00)\n",
      "Iter 15470 | Time 18.9987(19.6841) | Bit/dim 3.5470(3.5162) | Xent 0.0035(0.0045) | Loss 8.8077(9.5094) | Error 0.0011(0.0010) Steps 796(784.29) | Grad Norm 1.0134(1.1526) | Total Time 0.00(0.00)\n",
      "Iter 15480 | Time 19.9411(19.7578) | Bit/dim 3.5090(3.5149) | Xent 0.0024(0.0041) | Loss 8.7767(9.3296) | Error 0.0011(0.0009) Steps 784(787.42) | Grad Norm 1.5473(1.1295) | Total Time 0.00(0.00)\n",
      "Iter 15490 | Time 20.5533(19.8241) | Bit/dim 3.4771(3.5139) | Xent 0.0021(0.0042) | Loss 8.6768(9.1905) | Error 0.0011(0.0010) Steps 778(786.79) | Grad Norm 1.2753(1.1554) | Total Time 0.00(0.00)\n",
      "Iter 15500 | Time 18.9286(19.7866) | Bit/dim 3.5155(3.5156) | Xent 0.0038(0.0040) | Loss 8.7508(9.0917) | Error 0.0022(0.0011) Steps 784(788.14) | Grad Norm 1.2387(1.2118) | Total Time 0.00(0.00)\n",
      "Iter 15510 | Time 20.3759(19.7333) | Bit/dim 3.5326(3.5163) | Xent 0.0020(0.0040) | Loss 8.6885(9.0045) | Error 0.0000(0.0011) Steps 778(786.76) | Grad Norm 1.0686(1.2541) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0282 | Time 91.7965, Epoch Time 1196.7282(1178.6524), Bit/dim 3.5502(best: 3.5494), Xent 2.8286, Loss 4.9644, Error 0.3636(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15520 | Time 19.3438(19.8103) | Bit/dim 3.5405(3.5213) | Xent 0.0065(0.0041) | Loss 8.8428(9.6454) | Error 0.0011(0.0011) Steps 784(790.36) | Grad Norm 1.3512(1.3390) | Total Time 0.00(0.00)\n",
      "Iter 15530 | Time 20.2324(19.7614) | Bit/dim 3.5061(3.5186) | Xent 0.0037(0.0039) | Loss 8.8513(9.4220) | Error 0.0011(0.0011) Steps 832(790.43) | Grad Norm 1.8385(1.3770) | Total Time 0.00(0.00)\n",
      "Iter 15540 | Time 19.5268(19.8752) | Bit/dim 3.4837(3.5155) | Xent 0.0031(0.0039) | Loss 8.7145(9.2567) | Error 0.0000(0.0011) Steps 784(789.73) | Grad Norm 0.9776(1.3640) | Total Time 0.00(0.00)\n",
      "Iter 15550 | Time 19.2828(19.8027) | Bit/dim 3.4802(3.5147) | Xent 0.0039(0.0036) | Loss 8.7148(9.1277) | Error 0.0011(0.0009) Steps 760(787.40) | Grad Norm 2.1648(1.4311) | Total Time 0.00(0.00)\n",
      "Iter 15560 | Time 20.0697(19.7612) | Bit/dim 3.5197(3.5151) | Xent 0.0047(0.0042) | Loss 8.7712(9.0426) | Error 0.0022(0.0011) Steps 760(785.90) | Grad Norm 2.1483(1.4725) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0283 | Time 92.0359, Epoch Time 1200.4219(1179.3055), Bit/dim 3.5505(best: 3.5494), Xent 2.8177, Loss 4.9593, Error 0.3645(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15570 | Time 17.7848(19.7474) | Bit/dim 3.5355(3.5181) | Xent 0.0035(0.0040) | Loss 8.7870(9.7591) | Error 0.0000(0.0010) Steps 766(786.65) | Grad Norm 1.5042(1.4303) | Total Time 0.00(0.00)\n",
      "Iter 15580 | Time 20.6727(19.7757) | Bit/dim 3.4978(3.5193) | Xent 0.0043(0.0041) | Loss 8.7807(9.5108) | Error 0.0022(0.0011) Steps 820(788.08) | Grad Norm 1.1937(1.4105) | Total Time 0.00(0.00)\n",
      "Iter 15590 | Time 19.7140(19.8296) | Bit/dim 3.5176(3.5192) | Xent 0.0007(0.0035) | Loss 8.6944(9.3211) | Error 0.0000(0.0008) Steps 754(787.37) | Grad Norm 0.3883(1.2358) | Total Time 0.00(0.00)\n",
      "Iter 15600 | Time 19.0424(19.7398) | Bit/dim 3.5322(3.5180) | Xent 0.0075(0.0034) | Loss 8.7437(9.1779) | Error 0.0011(0.0008) Steps 784(788.33) | Grad Norm 2.6202(1.2173) | Total Time 0.00(0.00)\n",
      "Iter 15610 | Time 19.7395(19.8349) | Bit/dim 3.5005(3.5155) | Xent 0.0024(0.0041) | Loss 8.7381(9.0702) | Error 0.0011(0.0010) Steps 784(788.12) | Grad Norm 1.5392(1.3231) | Total Time 0.00(0.00)\n",
      "Iter 15620 | Time 19.6647(19.8492) | Bit/dim 3.4928(3.5143) | Xent 0.0023(0.0042) | Loss 8.7943(8.9947) | Error 0.0000(0.0010) Steps 790(788.75) | Grad Norm 0.8886(1.2793) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0284 | Time 89.7188, Epoch Time 1197.1310(1179.8402), Bit/dim 3.5463(best: 3.5494), Xent 2.8325, Loss 4.9626, Error 0.3692(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15630 | Time 19.8855(19.8360) | Bit/dim 3.5217(3.5144) | Xent 0.0059(0.0047) | Loss 8.8874(9.6072) | Error 0.0011(0.0011) Steps 748(788.38) | Grad Norm 1.8616(1.4103) | Total Time 0.00(0.00)\n",
      "Iter 15640 | Time 18.6811(19.8450) | Bit/dim 3.4835(3.5114) | Xent 0.0012(0.0049) | Loss 8.6730(9.3797) | Error 0.0000(0.0013) Steps 784(789.21) | Grad Norm 0.7888(1.5325) | Total Time 0.00(0.00)\n",
      "Iter 15650 | Time 19.4436(19.8288) | Bit/dim 3.5238(3.5140) | Xent 0.0007(0.0043) | Loss 8.6763(9.2204) | Error 0.0000(0.0011) Steps 754(788.93) | Grad Norm 0.9859(1.4321) | Total Time 0.00(0.00)\n",
      "Iter 15660 | Time 18.5846(19.7945) | Bit/dim 3.5173(3.5123) | Xent 0.0010(0.0039) | Loss 8.7238(9.0971) | Error 0.0000(0.0010) Steps 802(786.79) | Grad Norm 0.5438(1.4127) | Total Time 0.00(0.00)\n",
      "Iter 15670 | Time 19.4021(19.7419) | Bit/dim 3.5215(3.5160) | Xent 0.0029(0.0039) | Loss 8.7426(9.0220) | Error 0.0011(0.0011) Steps 796(786.55) | Grad Norm 0.8141(1.3890) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0285 | Time 91.8774, Epoch Time 1194.8879(1180.2917), Bit/dim 3.5488(best: 3.5463), Xent 2.8251, Loss 4.9613, Error 0.3646(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15680 | Time 20.6503(19.7818) | Bit/dim 3.4995(3.5177) | Xent 0.0023(0.0040) | Loss 8.8300(9.7588) | Error 0.0011(0.0011) Steps 838(788.51) | Grad Norm 1.0600(1.4416) | Total Time 0.00(0.00)\n",
      "Iter 15690 | Time 20.0975(19.7389) | Bit/dim 3.5196(3.5193) | Xent 0.0082(0.0049) | Loss 8.7716(9.4989) | Error 0.0033(0.0013) Steps 802(787.46) | Grad Norm 2.7220(1.6551) | Total Time 0.00(0.00)\n",
      "Iter 15700 | Time 19.6924(19.7756) | Bit/dim 3.5238(3.5189) | Xent 0.0055(0.0047) | Loss 8.8687(9.3102) | Error 0.0033(0.0013) Steps 814(787.39) | Grad Norm 2.1343(1.6345) | Total Time 0.00(0.00)\n",
      "Iter 15710 | Time 19.3387(19.7318) | Bit/dim 3.5188(3.5196) | Xent 0.0007(0.0048) | Loss 8.8192(9.1847) | Error 0.0000(0.0013) Steps 784(788.70) | Grad Norm 0.7576(1.6319) | Total Time 0.00(0.00)\n",
      "Iter 15720 | Time 19.6195(19.7545) | Bit/dim 3.4780(3.5176) | Xent 0.0006(0.0043) | Loss 8.7212(9.0858) | Error 0.0000(0.0012) Steps 760(784.97) | Grad Norm 0.6038(1.5782) | Total Time 0.00(0.00)\n",
      "Iter 15730 | Time 20.0431(19.8333) | Bit/dim 3.4887(3.5158) | Xent 0.0108(0.0042) | Loss 8.7850(9.0103) | Error 0.0022(0.0011) Steps 772(785.22) | Grad Norm 1.8763(1.5357) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0286 | Time 90.4931, Epoch Time 1197.7192(1180.8145), Bit/dim 3.5485(best: 3.5463), Xent 2.8528, Loss 4.9749, Error 0.3688(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15740 | Time 19.0596(19.8027) | Bit/dim 3.5198(3.5143) | Xent 0.0014(0.0039) | Loss 8.8291(9.6551) | Error 0.0000(0.0010) Steps 802(790.39) | Grad Norm 0.7602(1.3636) | Total Time 0.00(0.00)\n",
      "Iter 15750 | Time 19.4881(19.8814) | Bit/dim 3.5238(3.5127) | Xent 0.0044(0.0037) | Loss 8.8852(9.4262) | Error 0.0022(0.0009) Steps 772(786.67) | Grad Norm 1.3855(1.2078) | Total Time 0.00(0.00)\n",
      "Iter 15760 | Time 19.1383(19.8250) | Bit/dim 3.5583(3.5154) | Xent 0.0009(0.0038) | Loss 8.8308(9.2648) | Error 0.0000(0.0010) Steps 772(785.49) | Grad Norm 0.8114(1.2025) | Total Time 0.00(0.00)\n",
      "Iter 15770 | Time 20.1470(19.8416) | Bit/dim 3.4932(3.5148) | Xent 0.0037(0.0040) | Loss 8.7173(9.1355) | Error 0.0011(0.0011) Steps 832(788.38) | Grad Norm 0.9776(1.2289) | Total Time 0.00(0.00)\n",
      "Iter 15780 | Time 19.0241(19.7396) | Bit/dim 3.5336(3.5168) | Xent 0.0014(0.0046) | Loss 8.8362(9.0502) | Error 0.0000(0.0012) Steps 772(786.24) | Grad Norm 1.2992(1.4220) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0287 | Time 90.1163, Epoch Time 1193.8577(1181.2058), Bit/dim 3.5497(best: 3.5463), Xent 2.8756, Loss 4.9875, Error 0.3648(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15790 | Time 20.2707(19.7747) | Bit/dim 3.5189(3.5183) | Xent 0.0025(0.0045) | Loss 8.8315(9.8044) | Error 0.0000(0.0011) Steps 808(786.32) | Grad Norm 1.0879(1.4691) | Total Time 0.00(0.00)\n",
      "Iter 15800 | Time 19.0939(19.7651) | Bit/dim 3.5232(3.5168) | Xent 0.0058(0.0043) | Loss 8.9417(9.5443) | Error 0.0011(0.0010) Steps 796(788.91) | Grad Norm 2.0870(1.4692) | Total Time 0.00(0.00)\n",
      "Iter 15810 | Time 20.6559(19.7669) | Bit/dim 3.5266(3.5181) | Xent 0.0021(0.0042) | Loss 8.9007(9.3545) | Error 0.0011(0.0011) Steps 838(790.51) | Grad Norm 1.1486(1.5237) | Total Time 0.00(0.00)\n",
      "Iter 15820 | Time 20.0357(19.8287) | Bit/dim 3.5073(3.5164) | Xent 0.0033(0.0039) | Loss 8.7324(9.2028) | Error 0.0011(0.0011) Steps 784(791.01) | Grad Norm 1.0044(1.5326) | Total Time 0.00(0.00)\n",
      "Iter 15830 | Time 19.6187(19.7533) | Bit/dim 3.5233(3.5165) | Xent 0.0105(0.0041) | Loss 8.6894(9.0841) | Error 0.0022(0.0011) Steps 784(790.17) | Grad Norm 2.1407(1.5223) | Total Time 0.00(0.00)\n",
      "Iter 15840 | Time 19.1248(19.7371) | Bit/dim 3.5267(3.5148) | Xent 0.0009(0.0038) | Loss 8.7926(9.0070) | Error 0.0000(0.0010) Steps 802(792.44) | Grad Norm 0.4743(1.3732) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0288 | Time 92.3806, Epoch Time 1197.2424(1181.6869), Bit/dim 3.5517(best: 3.5463), Xent 2.8836, Loss 4.9935, Error 0.3728(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15850 | Time 19.5505(19.7378) | Bit/dim 3.5367(3.5184) | Xent 0.0028(0.0039) | Loss 8.8683(9.6358) | Error 0.0011(0.0010) Steps 772(789.00) | Grad Norm 1.2830(1.4278) | Total Time 0.00(0.00)\n",
      "Iter 15860 | Time 19.8815(19.7908) | Bit/dim 3.5310(3.5164) | Xent 0.0018(0.0041) | Loss 8.8279(9.4143) | Error 0.0000(0.0011) Steps 796(786.90) | Grad Norm 0.7567(1.4505) | Total Time 0.00(0.00)\n",
      "Iter 15870 | Time 19.8937(19.6715) | Bit/dim 3.5063(3.5160) | Xent 0.0081(0.0044) | Loss 8.7160(9.2478) | Error 0.0033(0.0012) Steps 796(786.03) | Grad Norm 2.9767(1.5265) | Total Time 0.00(0.00)\n",
      "Iter 15880 | Time 20.6622(19.6820) | Bit/dim 3.5027(3.5141) | Xent 0.0049(0.0044) | Loss 8.6804(9.1258) | Error 0.0011(0.0012) Steps 772(784.69) | Grad Norm 1.0298(1.4613) | Total Time 0.00(0.00)\n",
      "Iter 15890 | Time 19.9893(19.7375) | Bit/dim 3.5204(3.5134) | Xent 0.0023(0.0042) | Loss 8.6705(9.0305) | Error 0.0011(0.0011) Steps 796(783.10) | Grad Norm 1.3501(1.4604) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0289 | Time 91.4873, Epoch Time 1192.5226(1182.0120), Bit/dim 3.5505(best: 3.5463), Xent 2.8101, Loss 4.9556, Error 0.3655(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15900 | Time 19.5904(19.7169) | Bit/dim 3.5124(3.5145) | Xent 0.0008(0.0040) | Loss 8.7732(9.7348) | Error 0.0000(0.0011) Steps 778(782.66) | Grad Norm 0.7601(1.4458) | Total Time 0.00(0.00)\n",
      "Iter 15910 | Time 19.0052(19.6935) | Bit/dim 3.5441(3.5190) | Xent 0.0008(0.0038) | Loss 8.6722(9.4893) | Error 0.0000(0.0010) Steps 772(783.41) | Grad Norm 0.6055(1.4051) | Total Time 0.00(0.00)\n",
      "Iter 15920 | Time 20.4126(19.6967) | Bit/dim 3.5320(3.5180) | Xent 0.0014(0.0035) | Loss 8.8620(9.3088) | Error 0.0000(0.0010) Steps 766(784.48) | Grad Norm 1.3328(1.5068) | Total Time 0.00(0.00)\n",
      "Iter 15930 | Time 20.3082(19.8098) | Bit/dim 3.5369(3.5184) | Xent 0.0021(0.0039) | Loss 8.7999(9.1790) | Error 0.0000(0.0010) Steps 790(786.33) | Grad Norm 0.8642(1.5371) | Total Time 0.00(0.00)\n",
      "Iter 15940 | Time 19.4278(19.7227) | Bit/dim 3.5050(3.5176) | Xent 0.0109(0.0041) | Loss 8.8218(9.0747) | Error 0.0022(0.0011) Steps 790(785.22) | Grad Norm 1.8511(1.5545) | Total Time 0.00(0.00)\n",
      "Iter 15950 | Time 20.3204(19.6985) | Bit/dim 3.4732(3.5133) | Xent 0.0084(0.0040) | Loss 8.8219(8.9930) | Error 0.0033(0.0011) Steps 766(785.95) | Grad Norm 2.9587(1.5544) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0290 | Time 92.5595, Epoch Time 1193.7532(1182.3642), Bit/dim 3.5491(best: 3.5463), Xent 2.8368, Loss 4.9675, Error 0.3695(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15960 | Time 20.0247(19.7165) | Bit/dim 3.5019(3.5149) | Xent 0.0151(0.0042) | Loss 8.7973(9.6263) | Error 0.0044(0.0012) Steps 766(786.66) | Grad Norm 2.7777(1.5121) | Total Time 0.00(0.00)\n",
      "Iter 15970 | Time 18.7352(19.6809) | Bit/dim 3.5107(3.5144) | Xent 0.0018(0.0040) | Loss 8.8275(9.3995) | Error 0.0011(0.0011) Steps 802(787.17) | Grad Norm 1.7778(1.4428) | Total Time 0.00(0.00)\n",
      "Iter 15980 | Time 20.0274(19.7664) | Bit/dim 3.5412(3.5153) | Xent 0.0014(0.0038) | Loss 8.9011(9.2457) | Error 0.0000(0.0010) Steps 808(788.68) | Grad Norm 0.9190(1.4572) | Total Time 0.00(0.00)\n",
      "Iter 15990 | Time 19.7654(19.6512) | Bit/dim 3.4739(3.5141) | Xent 0.0011(0.0035) | Loss 8.6107(9.1135) | Error 0.0000(0.0009) Steps 820(790.00) | Grad Norm 0.9819(1.4204) | Total Time 0.00(0.00)\n",
      "Iter 16000 | Time 20.3159(19.7087) | Bit/dim 3.4966(3.5120) | Xent 0.0030(0.0032) | Loss 8.8073(9.0281) | Error 0.0022(0.0009) Steps 760(787.31) | Grad Norm 1.8802(1.3389) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0291 | Time 89.5721, Epoch Time 1195.1280(1182.7471), Bit/dim 3.5481(best: 3.5463), Xent 2.9064, Loss 5.0013, Error 0.3689(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16010 | Time 19.2184(19.7889) | Bit/dim 3.5375(3.5125) | Xent 0.0040(0.0035) | Loss 8.8631(9.7530) | Error 0.0011(0.0009) Steps 784(786.73) | Grad Norm 2.2439(1.3446) | Total Time 0.00(0.00)\n",
      "Iter 16020 | Time 20.1058(19.7246) | Bit/dim 3.5346(3.5122) | Xent 0.0029(0.0042) | Loss 8.8811(9.4883) | Error 0.0011(0.0009) Steps 826(785.08) | Grad Norm 1.7595(1.4082) | Total Time 0.00(0.00)\n",
      "Iter 16030 | Time 20.7176(19.7684) | Bit/dim 3.5381(3.5107) | Xent 0.0007(0.0040) | Loss 8.8880(9.2990) | Error 0.0000(0.0009) Steps 796(784.51) | Grad Norm 0.6622(1.4718) | Total Time 0.00(0.00)\n",
      "Iter 16040 | Time 19.9644(19.6887) | Bit/dim 3.5311(3.5112) | Xent 0.0012(0.0039) | Loss 8.9030(9.1561) | Error 0.0000(0.0009) Steps 802(782.22) | Grad Norm 0.6855(1.5218) | Total Time 0.00(0.00)\n",
      "Iter 16050 | Time 19.5933(19.6995) | Bit/dim 3.5020(3.5119) | Xent 0.0109(0.0038) | Loss 8.7931(9.0572) | Error 0.0044(0.0010) Steps 772(782.66) | Grad Norm 3.0186(1.5277) | Total Time 0.00(0.00)\n",
      "Iter 16060 | Time 20.5726(19.7239) | Bit/dim 3.5376(3.5156) | Xent 0.0027(0.0037) | Loss 8.7964(8.9896) | Error 0.0011(0.0009) Steps 790(783.48) | Grad Norm 1.5070(1.5081) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0292 | Time 91.5943, Epoch Time 1189.6500(1182.9542), Bit/dim 3.5485(best: 3.5463), Xent 2.9326, Loss 5.0148, Error 0.3719(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16070 | Time 20.0918(19.8256) | Bit/dim 3.5155(3.5124) | Xent 0.0007(0.0040) | Loss 8.7528(9.6010) | Error 0.0000(0.0010) Steps 796(785.48) | Grad Norm 0.6551(1.5379) | Total Time 0.00(0.00)\n",
      "Iter 16080 | Time 18.8686(19.7452) | Bit/dim 3.5005(3.5143) | Xent 0.0152(0.0044) | Loss 8.6488(9.3834) | Error 0.0044(0.0011) Steps 772(783.45) | Grad Norm 3.4338(1.5452) | Total Time 0.00(0.00)\n",
      "Iter 16090 | Time 19.6323(19.8005) | Bit/dim 3.4928(3.5148) | Xent 0.0011(0.0043) | Loss 8.7869(9.2296) | Error 0.0000(0.0012) Steps 772(783.51) | Grad Norm 0.7082(1.5686) | Total Time 0.00(0.00)\n",
      "Iter 16100 | Time 20.0433(19.7695) | Bit/dim 3.5216(3.5165) | Xent 0.0043(0.0042) | Loss 8.7340(9.1147) | Error 0.0011(0.0012) Steps 796(785.25) | Grad Norm 2.1645(1.5498) | Total Time 0.00(0.00)\n",
      "Iter 16110 | Time 19.0686(19.7506) | Bit/dim 3.5112(3.5129) | Xent 0.0050(0.0039) | Loss 8.7442(9.0138) | Error 0.0022(0.0012) Steps 754(785.39) | Grad Norm 2.4470(1.5705) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0293 | Time 93.1745, Epoch Time 1197.6672(1183.3956), Bit/dim 3.5471(best: 3.5463), Xent 2.8377, Loss 4.9660, Error 0.3677(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16120 | Time 19.1733(19.6416) | Bit/dim 3.5022(3.5138) | Xent 0.0033(0.0040) | Loss 8.6731(9.7497) | Error 0.0011(0.0012) Steps 784(785.83) | Grad Norm 2.3111(1.5360) | Total Time 0.00(0.00)\n",
      "Iter 16130 | Time 20.1949(19.5665) | Bit/dim 3.5244(3.5125) | Xent 0.0029(0.0045) | Loss 8.8259(9.4914) | Error 0.0011(0.0013) Steps 820(786.88) | Grad Norm 3.0188(1.6661) | Total Time 0.00(0.00)\n",
      "Iter 16140 | Time 20.0702(19.5663) | Bit/dim 3.5309(3.5136) | Xent 0.0091(0.0047) | Loss 8.8959(9.3059) | Error 0.0033(0.0013) Steps 784(783.20) | Grad Norm 2.4783(1.6640) | Total Time 0.00(0.00)\n",
      "Iter 16150 | Time 18.9869(19.4733) | Bit/dim 3.5331(3.5173) | Xent 0.0023(0.0045) | Loss 8.8212(9.1784) | Error 0.0011(0.0012) Steps 802(785.21) | Grad Norm 1.8587(1.6973) | Total Time 0.00(0.00)\n",
      "Iter 16160 | Time 19.9783(19.4287) | Bit/dim 3.4974(3.5123) | Xent 0.0020(0.0040) | Loss 8.7909(9.0673) | Error 0.0000(0.0010) Steps 796(785.26) | Grad Norm 1.0299(1.5320) | Total Time 0.00(0.00)\n",
      "Iter 16170 | Time 20.0066(19.5345) | Bit/dim 3.5255(3.5127) | Xent 0.0108(0.0044) | Loss 8.7957(8.9979) | Error 0.0022(0.0011) Steps 772(785.07) | Grad Norm 1.5086(1.6362) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0294 | Time 89.4336, Epoch Time 1174.9672(1183.1427), Bit/dim 3.5478(best: 3.5463), Xent 2.9146, Loss 5.0051, Error 0.3694(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16180 | Time 19.4142(19.4527) | Bit/dim 3.5105(3.5153) | Xent 0.0018(0.0042) | Loss 8.7915(9.6249) | Error 0.0000(0.0010) Steps 814(785.96) | Grad Norm 0.8486(1.5002) | Total Time 0.00(0.00)\n",
      "Iter 16190 | Time 20.0517(19.4808) | Bit/dim 3.5572(3.5167) | Xent 0.0014(0.0044) | Loss 8.8928(9.4063) | Error 0.0000(0.0011) Steps 796(785.72) | Grad Norm 1.2573(1.5772) | Total Time 0.00(0.00)\n",
      "Iter 16200 | Time 20.0009(19.4578) | Bit/dim 3.5247(3.5146) | Xent 0.0015(0.0041) | Loss 8.7302(9.2457) | Error 0.0000(0.0010) Steps 766(785.98) | Grad Norm 1.3452(1.4889) | Total Time 0.00(0.00)\n",
      "Iter 16210 | Time 19.6637(19.4258) | Bit/dim 3.5384(3.5117) | Xent 0.0099(0.0043) | Loss 8.8154(9.1120) | Error 0.0033(0.0011) Steps 790(786.04) | Grad Norm 3.8106(1.6586) | Total Time 0.00(0.00)\n",
      "Iter 16220 | Time 18.8348(19.4000) | Bit/dim 3.5085(3.5130) | Xent 0.0022(0.0042) | Loss 8.8275(9.0185) | Error 0.0011(0.0011) Steps 802(785.63) | Grad Norm 0.8542(1.6004) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0295 | Time 90.3993, Epoch Time 1174.0116(1182.8688), Bit/dim 3.5488(best: 3.5463), Xent 2.8969, Loss 4.9973, Error 0.3632(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16230 | Time 20.0401(19.4537) | Bit/dim 3.4942(3.5127) | Xent 0.0013(0.0043) | Loss 8.8249(9.7947) | Error 0.0000(0.0012) Steps 808(785.22) | Grad Norm 1.4991(1.6943) | Total Time 0.00(0.00)\n",
      "Iter 16240 | Time 18.6297(19.4597) | Bit/dim 3.5360(3.5134) | Xent 0.0070(0.0051) | Loss 8.8644(9.5279) | Error 0.0022(0.0014) Steps 778(786.80) | Grad Norm 3.8153(1.9693) | Total Time 0.00(0.00)\n",
      "Iter 16250 | Time 19.1362(19.4520) | Bit/dim 3.5216(3.5157) | Xent 0.0018(0.0052) | Loss 8.7340(9.3420) | Error 0.0000(0.0014) Steps 784(789.14) | Grad Norm 1.4051(2.0323) | Total Time 0.00(0.00)\n",
      "Iter 16260 | Time 18.3873(19.4297) | Bit/dim 3.4846(3.5137) | Xent 0.0053(0.0052) | Loss 8.6864(9.1903) | Error 0.0011(0.0013) Steps 754(785.81) | Grad Norm 1.4668(1.9290) | Total Time 0.00(0.00)\n",
      "Iter 16270 | Time 19.9572(19.4512) | Bit/dim 3.4384(3.5126) | Xent 0.0108(0.0056) | Loss 8.5849(9.0768) | Error 0.0033(0.0015) Steps 808(785.21) | Grad Norm 2.2320(1.9738) | Total Time 0.00(0.00)\n",
      "Iter 16280 | Time 20.3385(19.5706) | Bit/dim 3.5280(3.5153) | Xent 0.0141(0.0053) | Loss 8.8186(9.0051) | Error 0.0033(0.0015) Steps 790(785.45) | Grad Norm 3.3788(1.9627) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0296 | Time 89.4919, Epoch Time 1181.9607(1182.8416), Bit/dim 3.5492(best: 3.5463), Xent 2.9095, Loss 5.0039, Error 0.3743(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16290 | Time 19.1606(19.4408) | Bit/dim 3.5450(3.5154) | Xent 0.0039(0.0050) | Loss 8.7698(9.6183) | Error 0.0011(0.0014) Steps 778(785.26) | Grad Norm 1.5044(1.8403) | Total Time 0.00(0.00)\n",
      "Iter 16300 | Time 19.0155(19.5304) | Bit/dim 3.4973(3.5159) | Xent 0.0008(0.0044) | Loss 8.7331(9.3964) | Error 0.0000(0.0012) Steps 748(782.57) | Grad Norm 0.8114(1.6583) | Total Time 0.00(0.00)\n",
      "Iter 16310 | Time 19.1322(19.4465) | Bit/dim 3.5195(3.5155) | Xent 0.0100(0.0043) | Loss 8.7300(9.2330) | Error 0.0033(0.0012) Steps 766(780.55) | Grad Norm 2.5333(1.5728) | Total Time 0.00(0.00)\n",
      "Iter 16320 | Time 21.0840(19.4918) | Bit/dim 3.5026(3.5146) | Xent 0.0051(0.0041) | Loss 8.8777(9.1175) | Error 0.0011(0.0011) Steps 796(778.58) | Grad Norm 2.3274(1.5537) | Total Time 0.00(0.00)\n",
      "Iter 16330 | Time 18.7729(19.4312) | Bit/dim 3.5019(3.5134) | Xent 0.0027(0.0043) | Loss 8.7606(9.0171) | Error 0.0011(0.0011) Steps 784(778.20) | Grad Norm 1.2879(1.5495) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0297 | Time 91.5908, Epoch Time 1174.9108(1182.6036), Bit/dim 3.5465(best: 3.5463), Xent 2.8951, Loss 4.9940, Error 0.3678(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16340 | Time 19.6253(19.4651) | Bit/dim 3.4979(3.5127) | Xent 0.0017(0.0039) | Loss 8.6659(9.7506) | Error 0.0000(0.0011) Steps 778(780.06) | Grad Norm 0.9749(1.4379) | Total Time 0.00(0.00)\n",
      "Iter 16350 | Time 18.6835(19.3923) | Bit/dim 3.5434(3.5130) | Xent 0.0030(0.0037) | Loss 8.7351(9.4852) | Error 0.0000(0.0010) Steps 760(779.16) | Grad Norm 1.3677(1.4316) | Total Time 0.00(0.00)\n",
      "Iter 16360 | Time 20.6330(19.4793) | Bit/dim 3.5002(3.5115) | Xent 0.0008(0.0039) | Loss 8.6621(9.2960) | Error 0.0000(0.0011) Steps 826(783.16) | Grad Norm 1.2445(1.4864) | Total Time 0.00(0.00)\n",
      "Iter 16370 | Time 19.9254(19.5310) | Bit/dim 3.5458(3.5114) | Xent 0.0011(0.0041) | Loss 8.8368(9.1605) | Error 0.0000(0.0011) Steps 754(784.12) | Grad Norm 0.6586(1.4962) | Total Time 0.00(0.00)\n",
      "Iter 16380 | Time 20.6241(19.5899) | Bit/dim 3.5197(3.5137) | Xent 0.0048(0.0038) | Loss 8.8142(9.0623) | Error 0.0022(0.0010) Steps 814(786.20) | Grad Norm 1.7310(1.4389) | Total Time 0.00(0.00)\n",
      "Iter 16390 | Time 19.3772(19.6464) | Bit/dim 3.4930(3.5136) | Xent 0.0050(0.0042) | Loss 8.7151(8.9821) | Error 0.0022(0.0012) Steps 778(786.93) | Grad Norm 1.9942(1.5878) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0298 | Time 90.3710, Epoch Time 1187.6108(1182.7539), Bit/dim 3.5482(best: 3.5463), Xent 2.9120, Loss 5.0042, Error 0.3680(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16400 | Time 20.2295(19.7743) | Bit/dim 3.4833(3.5126) | Xent 0.0053(0.0037) | Loss 8.7548(9.6358) | Error 0.0022(0.0011) Steps 802(788.69) | Grad Norm 2.0801(1.5038) | Total Time 0.00(0.00)\n",
      "Iter 16410 | Time 20.0649(19.8374) | Bit/dim 3.5166(3.5147) | Xent 0.0008(0.0039) | Loss 8.7844(9.4206) | Error 0.0000(0.0010) Steps 844(794.48) | Grad Norm 0.7310(1.5419) | Total Time 0.00(0.00)\n",
      "Iter 16420 | Time 20.8126(19.8654) | Bit/dim 3.5282(3.5131) | Xent 0.0006(0.0036) | Loss 8.8573(9.2571) | Error 0.0000(0.0009) Steps 820(795.40) | Grad Norm 0.6494(1.4810) | Total Time 0.00(0.00)\n",
      "Iter 16430 | Time 19.7688(19.9255) | Bit/dim 3.4992(3.5155) | Xent 0.0039(0.0037) | Loss 8.7901(9.1465) | Error 0.0011(0.0009) Steps 784(797.13) | Grad Norm 1.3424(1.4480) | Total Time 0.00(0.00)\n",
      "Iter 16440 | Time 19.9706(19.9312) | Bit/dim 3.5590(3.5152) | Xent 0.0098(0.0041) | Loss 8.8980(9.0586) | Error 0.0022(0.0010) Steps 802(795.77) | Grad Norm 2.9700(1.5581) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0299 | Time 91.9574, Epoch Time 1211.4501(1183.6147), Bit/dim 3.5457(best: 3.5463), Xent 2.9375, Loss 5.0144, Error 0.3688(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16450 | Time 20.1749(19.9522) | Bit/dim 3.5387(3.5121) | Xent 0.0015(0.0046) | Loss 8.8584(9.7962) | Error 0.0000(0.0012) Steps 760(792.53) | Grad Norm 0.9660(1.6986) | Total Time 0.00(0.00)\n",
      "Iter 16460 | Time 20.7610(19.9702) | Bit/dim 3.5178(3.5134) | Xent 0.0087(0.0045) | Loss 8.8207(9.5389) | Error 0.0022(0.0011) Steps 784(790.58) | Grad Norm 1.3022(1.6845) | Total Time 0.00(0.00)\n",
      "Iter 16470 | Time 20.5191(20.0223) | Bit/dim 3.4968(3.5116) | Xent 0.0027(0.0041) | Loss 8.8247(9.3394) | Error 0.0011(0.0010) Steps 778(789.69) | Grad Norm 2.4778(1.6670) | Total Time 0.00(0.00)\n",
      "Iter 16480 | Time 20.5113(20.0126) | Bit/dim 3.5249(3.5144) | Xent 0.0031(0.0041) | Loss 8.7344(9.1963) | Error 0.0011(0.0011) Steps 808(788.96) | Grad Norm 0.7965(1.5668) | Total Time 0.00(0.00)\n",
      "Iter 16490 | Time 20.4924(20.0607) | Bit/dim 3.4847(3.5132) | Xent 0.0012(0.0043) | Loss 8.6973(9.0810) | Error 0.0000(0.0011) Steps 814(788.18) | Grad Norm 1.0325(1.5360) | Total Time 0.00(0.00)\n",
      "Iter 16500 | Time 19.4801(20.0011) | Bit/dim 3.4851(3.5113) | Xent 0.0087(0.0045) | Loss 8.7462(9.0030) | Error 0.0022(0.0011) Steps 784(791.53) | Grad Norm 3.5419(1.6696) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0300 | Time 93.3185, Epoch Time 1211.1849(1184.4418), Bit/dim 3.5458(best: 3.5457), Xent 2.9517, Loss 5.0216, Error 0.3721(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16510 | Time 20.2010(20.0168) | Bit/dim 3.5067(3.5113) | Xent 0.0046(0.0042) | Loss 8.7109(9.6484) | Error 0.0011(0.0011) Steps 790(793.28) | Grad Norm 3.4643(1.7366) | Total Time 0.00(0.00)\n",
      "Iter 16520 | Time 19.7683(20.0592) | Bit/dim 3.5239(3.5093) | Xent 0.0006(0.0041) | Loss 8.7734(9.4228) | Error 0.0000(0.0011) Steps 784(791.40) | Grad Norm 0.7707(1.7031) | Total Time 0.00(0.00)\n",
      "Iter 16530 | Time 18.9235(20.0624) | Bit/dim 3.5322(3.5114) | Xent 0.0042(0.0036) | Loss 8.7793(9.2511) | Error 0.0011(0.0009) Steps 790(788.90) | Grad Norm 1.5009(1.5945) | Total Time 0.00(0.00)\n",
      "Iter 16540 | Time 20.7343(20.0102) | Bit/dim 3.5042(3.5144) | Xent 0.0099(0.0035) | Loss 8.8283(9.1333) | Error 0.0022(0.0010) Steps 832(790.87) | Grad Norm 2.1110(1.5894) | Total Time 0.00(0.00)\n",
      "Iter 16550 | Time 20.2287(20.1248) | Bit/dim 3.4870(3.5136) | Xent 0.0053(0.0034) | Loss 8.8303(9.0426) | Error 0.0022(0.0010) Steps 802(790.84) | Grad Norm 3.2190(1.7722) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0301 | Time 91.2005, Epoch Time 1215.3920(1185.3704), Bit/dim 3.5485(best: 3.5457), Xent 2.9198, Loss 5.0084, Error 0.3664(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16560 | Time 20.3016(20.1455) | Bit/dim 3.4954(3.5141) | Xent 0.0078(0.0035) | Loss 8.6904(9.7772) | Error 0.0022(0.0010) Steps 784(789.94) | Grad Norm 3.4930(1.8163) | Total Time 0.00(0.00)\n",
      "Iter 16570 | Time 19.7714(20.1052) | Bit/dim 3.5057(3.5136) | Xent 0.0008(0.0037) | Loss 8.6568(9.5107) | Error 0.0000(0.0011) Steps 784(789.45) | Grad Norm 1.6591(1.9479) | Total Time 0.00(0.00)\n",
      "Iter 16580 | Time 19.9253(20.0212) | Bit/dim 3.5057(3.5137) | Xent 0.0038(0.0040) | Loss 8.6411(9.3141) | Error 0.0011(0.0012) Steps 808(790.42) | Grad Norm 2.4715(2.0068) | Total Time 0.00(0.00)\n",
      "Iter 16590 | Time 20.3396(20.1007) | Bit/dim 3.5232(3.5160) | Xent 0.0025(0.0042) | Loss 8.8616(9.1868) | Error 0.0011(0.0012) Steps 808(791.53) | Grad Norm 1.1907(1.9514) | Total Time 0.00(0.00)\n",
      "Iter 16600 | Time 19.9362(20.1221) | Bit/dim 3.5022(3.5163) | Xent 0.0014(0.0045) | Loss 8.7231(9.0819) | Error 0.0000(0.0013) Steps 820(794.93) | Grad Norm 1.1458(2.0856) | Total Time 0.00(0.00)\n",
      "Iter 16610 | Time 19.6080(20.1352) | Bit/dim 3.4932(3.5131) | Xent 0.0058(0.0043) | Loss 8.7024(8.9930) | Error 0.0033(0.0013) Steps 814(791.47) | Grad Norm 3.1939(1.9927) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0302 | Time 90.1354, Epoch Time 1213.1777(1186.2046), Bit/dim 3.5482(best: 3.5457), Xent 2.9231, Loss 5.0098, Error 0.3719(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16620 | Time 19.8958(20.0718) | Bit/dim 3.5044(3.5127) | Xent 0.0083(0.0043) | Loss 8.7456(9.6103) | Error 0.0011(0.0012) Steps 784(792.12) | Grad Norm 1.7311(1.8314) | Total Time 0.00(0.00)\n",
      "Iter 16630 | Time 19.1283(20.0512) | Bit/dim 3.5331(3.5143) | Xent 0.0010(0.0040) | Loss 8.6683(9.3882) | Error 0.0000(0.0011) Steps 784(788.31) | Grad Norm 0.9291(1.8484) | Total Time 0.00(0.00)\n",
      "Iter 16640 | Time 20.0274(20.0228) | Bit/dim 3.4985(3.5138) | Xent 0.0011(0.0040) | Loss 8.7625(9.2208) | Error 0.0000(0.0011) Steps 802(788.26) | Grad Norm 0.8910(1.7942) | Total Time 0.00(0.00)\n",
      "Iter 16650 | Time 19.6329(20.0837) | Bit/dim 3.5027(3.5125) | Xent 0.0021(0.0039) | Loss 8.7468(9.1073) | Error 0.0011(0.0010) Steps 796(791.11) | Grad Norm 1.3454(1.7361) | Total Time 0.00(0.00)\n",
      "Iter 16660 | Time 19.2827(20.0808) | Bit/dim 3.5309(3.5137) | Xent 0.0022(0.0037) | Loss 8.8198(9.0245) | Error 0.0000(0.0009) Steps 790(793.31) | Grad Norm 1.6126(1.6110) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0303 | Time 93.7931, Epoch Time 1211.9063(1186.9756), Bit/dim 3.5473(best: 3.5457), Xent 2.9386, Loss 5.0167, Error 0.3727(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16670 | Time 19.8022(20.1219) | Bit/dim 3.4801(3.5129) | Xent 0.0070(0.0038) | Loss 8.6178(9.7576) | Error 0.0033(0.0010) Steps 742(793.26) | Grad Norm 2.0776(1.6509) | Total Time 0.00(0.00)\n",
      "Iter 16680 | Time 20.1445(20.1328) | Bit/dim 3.4690(3.5125) | Xent 0.0017(0.0036) | Loss 8.7006(9.4959) | Error 0.0011(0.0010) Steps 796(793.97) | Grad Norm 1.3156(1.5731) | Total Time 0.00(0.00)\n",
      "Iter 16690 | Time 20.0633(20.1367) | Bit/dim 3.4743(3.5142) | Xent 0.0013(0.0039) | Loss 8.8172(9.3094) | Error 0.0000(0.0012) Steps 820(795.39) | Grad Norm 0.9194(1.5910) | Total Time 0.00(0.00)\n",
      "Iter 16700 | Time 20.3281(20.0963) | Bit/dim 3.5155(3.5151) | Xent 0.0037(0.0044) | Loss 8.7639(9.1682) | Error 0.0022(0.0012) Steps 814(794.99) | Grad Norm 2.6769(1.6584) | Total Time 0.00(0.00)\n",
      "Iter 16710 | Time 20.7801(20.1957) | Bit/dim 3.5267(3.5146) | Xent 0.0006(0.0040) | Loss 8.8460(9.0750) | Error 0.0000(0.0010) Steps 820(797.02) | Grad Norm 0.8003(1.5858) | Total Time 0.00(0.00)\n",
      "Iter 16720 | Time 19.6984(20.1724) | Bit/dim 3.4908(3.5147) | Xent 0.0010(0.0041) | Loss 8.6831(9.0000) | Error 0.0000(0.0010) Steps 784(797.11) | Grad Norm 1.0685(1.6330) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0304 | Time 91.5394, Epoch Time 1219.8641(1187.9623), Bit/dim 3.5513(best: 3.5457), Xent 2.9358, Loss 5.0191, Error 0.3664(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16730 | Time 21.0863(20.2605) | Bit/dim 3.5493(3.5159) | Xent 0.0013(0.0041) | Loss 8.9291(9.6324) | Error 0.0000(0.0011) Steps 814(797.25) | Grad Norm 0.8998(1.7381) | Total Time 0.00(0.00)\n",
      "Iter 16740 | Time 20.3446(20.2980) | Bit/dim 3.5287(3.5173) | Xent 0.0098(0.0041) | Loss 8.7335(9.4077) | Error 0.0022(0.0011) Steps 790(798.14) | Grad Norm 2.7163(1.7909) | Total Time 0.00(0.00)\n",
      "Iter 16750 | Time 20.9604(20.3476) | Bit/dim 3.5521(3.5173) | Xent 0.0018(0.0046) | Loss 8.8763(9.2473) | Error 0.0000(0.0012) Steps 796(797.00) | Grad Norm 0.9598(1.8390) | Total Time 0.00(0.00)\n",
      "Iter 16760 | Time 20.3380(20.4637) | Bit/dim 3.5260(3.5173) | Xent 0.0019(0.0046) | Loss 8.8625(9.1311) | Error 0.0011(0.0012) Steps 814(797.12) | Grad Norm 1.1051(1.9089) | Total Time 0.00(0.00)\n",
      "Iter 16770 | Time 20.6378(20.4048) | Bit/dim 3.5170(3.5130) | Xent 0.0056(0.0049) | Loss 8.8524(9.0321) | Error 0.0011(0.0012) Steps 832(798.45) | Grad Norm 1.8349(1.9257) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0305 | Time 92.7421, Epoch Time 1237.9379(1189.4615), Bit/dim 3.5496(best: 3.5457), Xent 2.9151, Loss 5.0071, Error 0.3680(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16780 | Time 19.6215(20.4135) | Bit/dim 3.5103(3.5167) | Xent 0.0023(0.0047) | Loss 8.7576(9.7814) | Error 0.0011(0.0012) Steps 766(800.65) | Grad Norm 1.4570(1.9257) | Total Time 0.00(0.00)\n",
      "Iter 16790 | Time 20.1765(20.4413) | Bit/dim 3.5293(3.5179) | Xent 0.0054(0.0041) | Loss 8.8865(9.5323) | Error 0.0011(0.0010) Steps 790(802.17) | Grad Norm 1.5472(1.7890) | Total Time 0.00(0.00)\n",
      "Iter 16800 | Time 19.6939(20.5198) | Bit/dim 3.4930(3.5149) | Xent 0.0055(0.0044) | Loss 8.7544(9.3377) | Error 0.0022(0.0011) Steps 808(800.62) | Grad Norm 3.1926(1.8570) | Total Time 0.00(0.00)\n",
      "Iter 16810 | Time 20.4795(20.4612) | Bit/dim 3.5211(3.5165) | Xent 0.0012(0.0043) | Loss 8.8394(9.1907) | Error 0.0000(0.0011) Steps 784(799.22) | Grad Norm 1.2070(1.9393) | Total Time 0.00(0.00)\n",
      "Iter 16820 | Time 20.6088(20.5506) | Bit/dim 3.5201(3.5157) | Xent 0.0055(0.0045) | Loss 8.7171(9.0821) | Error 0.0022(0.0012) Steps 796(799.41) | Grad Norm 2.8491(2.1388) | Total Time 0.00(0.00)\n",
      "Iter 16830 | Time 20.6825(20.5018) | Bit/dim 3.5113(3.5143) | Xent 0.0077(0.0046) | Loss 8.7582(9.0003) | Error 0.0022(0.0013) Steps 790(800.30) | Grad Norm 1.7842(2.0998) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0306 | Time 93.5551, Epoch Time 1238.2567(1190.9254), Bit/dim 3.5465(best: 3.5457), Xent 2.9321, Loss 5.0125, Error 0.3652(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16840 | Time 20.8510(20.6304) | Bit/dim 3.5106(3.5166) | Xent 0.0039(0.0044) | Loss 8.6931(9.6234) | Error 0.0011(0.0011) Steps 832(800.17) | Grad Norm 1.6408(1.9571) | Total Time 0.00(0.00)\n",
      "Iter 16850 | Time 19.9437(20.5306) | Bit/dim 3.4839(3.5162) | Xent 0.0013(0.0042) | Loss 8.7199(9.4035) | Error 0.0000(0.0011) Steps 784(800.71) | Grad Norm 0.8583(1.8459) | Total Time 0.00(0.00)\n",
      "Iter 16860 | Time 19.6198(20.4480) | Bit/dim 3.5391(3.5159) | Xent 0.0025(0.0042) | Loss 8.7195(9.2277) | Error 0.0011(0.0011) Steps 796(798.24) | Grad Norm 1.0119(1.7863) | Total Time 0.00(0.00)\n",
      "Iter 16870 | Time 20.5119(20.4718) | Bit/dim 3.4767(3.5118) | Xent 0.0093(0.0048) | Loss 8.5884(9.1011) | Error 0.0022(0.0012) Steps 796(799.76) | Grad Norm 2.1882(1.7485) | Total Time 0.00(0.00)\n",
      "Iter 16880 | Time 21.8528(20.5890) | Bit/dim 3.5289(3.5120) | Xent 0.0085(0.0046) | Loss 8.9817(9.0285) | Error 0.0044(0.0013) Steps 808(802.01) | Grad Norm 3.2336(1.7270) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0307 | Time 91.5228, Epoch Time 1238.0346(1192.3387), Bit/dim 3.5482(best: 3.5457), Xent 3.0031, Loss 5.0498, Error 0.3678(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16890 | Time 21.8507(20.6208) | Bit/dim 3.5165(3.5120) | Xent 0.0012(0.0047) | Loss 8.7139(9.7600) | Error 0.0000(0.0013) Steps 820(805.03) | Grad Norm 0.8573(1.7681) | Total Time 0.00(0.00)\n",
      "Iter 16900 | Time 21.9067(20.6433) | Bit/dim 3.5222(3.5125) | Xent 0.0051(0.0048) | Loss 8.8708(9.5061) | Error 0.0022(0.0014) Steps 808(803.96) | Grad Norm 3.7904(1.8978) | Total Time 0.00(0.00)\n",
      "Iter 16910 | Time 20.6740(20.6044) | Bit/dim 3.5171(3.5131) | Xent 0.0040(0.0049) | Loss 8.7904(9.3237) | Error 0.0022(0.0014) Steps 784(803.65) | Grad Norm 1.9058(1.9229) | Total Time 0.00(0.00)\n",
      "Iter 16920 | Time 20.2524(20.6326) | Bit/dim 3.5069(3.5119) | Xent 0.0034(0.0044) | Loss 8.7692(9.1836) | Error 0.0011(0.0012) Steps 814(802.86) | Grad Norm 1.7370(1.8571) | Total Time 0.00(0.00)\n",
      "Iter 16930 | Time 19.8718(20.4398) | Bit/dim 3.5471(3.5137) | Xent 0.0047(0.0045) | Loss 8.8286(9.0766) | Error 0.0022(0.0013) Steps 790(800.70) | Grad Norm 4.4149(2.0060) | Total Time 0.00(0.00)\n",
      "Iter 16940 | Time 20.4400(20.4868) | Bit/dim 3.4990(3.5101) | Xent 0.0221(0.0062) | Loss 8.7681(8.9854) | Error 0.0044(0.0016) Steps 802(797.97) | Grad Norm 3.0870(2.2059) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0308 | Time 91.6603, Epoch Time 1238.6471(1193.7279), Bit/dim 3.5484(best: 3.5457), Xent 3.0070, Loss 5.0519, Error 0.3693(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16950 | Time 20.4399(20.4464) | Bit/dim 3.5052(3.5115) | Xent 0.0013(0.0052) | Loss 8.6983(9.6262) | Error 0.0000(0.0013) Steps 790(800.17) | Grad Norm 1.2951(2.0331) | Total Time 0.00(0.00)\n",
      "Iter 16960 | Time 20.6795(20.5237) | Bit/dim 3.5202(3.5106) | Xent 0.0030(0.0050) | Loss 8.9018(9.3999) | Error 0.0011(0.0013) Steps 802(798.32) | Grad Norm 2.4511(1.9989) | Total Time 0.00(0.00)\n",
      "Iter 16970 | Time 20.2324(20.4050) | Bit/dim 3.5012(3.5094) | Xent 0.0022(0.0046) | Loss 8.8672(9.2273) | Error 0.0011(0.0012) Steps 826(797.69) | Grad Norm 1.9645(1.8707) | Total Time 0.00(0.00)\n",
      "Iter 16980 | Time 21.5519(20.4139) | Bit/dim 3.5170(3.5091) | Xent 0.0163(0.0051) | Loss 8.8887(9.1108) | Error 0.0022(0.0012) Steps 802(801.71) | Grad Norm 1.4789(1.8521) | Total Time 0.00(0.00)\n",
      "Iter 16990 | Time 19.7200(20.3591) | Bit/dim 3.5282(3.5126) | Xent 0.0071(0.0050) | Loss 8.7995(9.0299) | Error 0.0033(0.0012) Steps 778(802.86) | Grad Norm 1.9966(1.8298) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0309 | Time 93.3321, Epoch Time 1231.2397(1194.8533), Bit/dim 3.5433(best: 3.5457), Xent 2.9456, Loss 5.0161, Error 0.3691(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17000 | Time 19.9964(20.3910) | Bit/dim 3.4938(3.5116) | Xent 0.0131(0.0054) | Loss 8.6760(9.7589) | Error 0.0044(0.0013) Steps 820(802.06) | Grad Norm 2.8712(1.8270) | Total Time 0.00(0.00)\n",
      "Iter 17010 | Time 20.5024(20.3481) | Bit/dim 3.5021(3.5163) | Xent 0.0052(0.0048) | Loss 8.6398(9.4998) | Error 0.0022(0.0012) Steps 814(800.82) | Grad Norm 1.3076(1.6961) | Total Time 0.00(0.00)\n",
      "Iter 17020 | Time 19.8639(20.3130) | Bit/dim 3.4954(3.5152) | Xent 0.0016(0.0044) | Loss 8.7435(9.3053) | Error 0.0011(0.0011) Steps 796(803.11) | Grad Norm 0.8225(1.5943) | Total Time 0.00(0.00)\n",
      "Iter 17030 | Time 19.4612(20.2154) | Bit/dim 3.5346(3.5138) | Xent 0.0022(0.0043) | Loss 8.8384(9.1596) | Error 0.0011(0.0011) Steps 808(800.72) | Grad Norm 1.2555(1.5652) | Total Time 0.00(0.00)\n",
      "Iter 17040 | Time 22.0730(20.2926) | Bit/dim 3.4682(3.5099) | Xent 0.0008(0.0043) | Loss 8.7489(9.0548) | Error 0.0000(0.0012) Steps 790(801.12) | Grad Norm 1.1574(1.6991) | Total Time 0.00(0.00)\n",
      "Iter 17050 | Time 20.6901(20.2701) | Bit/dim 3.4933(3.5075) | Xent 0.0045(0.0042) | Loss 8.6356(8.9724) | Error 0.0022(0.0011) Steps 790(801.41) | Grad Norm 2.3362(1.7249) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0310 | Time 91.3848, Epoch Time 1220.5540(1195.6243), Bit/dim 3.5428(best: 3.5433), Xent 2.9398, Loss 5.0127, Error 0.3740(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17060 | Time 20.3665(20.3402) | Bit/dim 3.5044(3.5072) | Xent 0.0035(0.0041) | Loss 8.8492(9.5974) | Error 0.0011(0.0011) Steps 814(802.74) | Grad Norm 1.9688(1.8239) | Total Time 0.00(0.00)\n",
      "Iter 17070 | Time 19.7002(20.3053) | Bit/dim 3.4991(3.5057) | Xent 0.0007(0.0040) | Loss 8.7576(9.3832) | Error 0.0000(0.0010) Steps 802(801.97) | Grad Norm 0.7715(1.8102) | Total Time 0.00(0.00)\n",
      "Iter 17080 | Time 20.4824(20.3138) | Bit/dim 3.5504(3.5123) | Xent 0.0015(0.0041) | Loss 8.8873(9.2262) | Error 0.0000(0.0012) Steps 826(800.75) | Grad Norm 0.8470(1.7630) | Total Time 0.00(0.00)\n",
      "Iter 17090 | Time 19.8939(20.3461) | Bit/dim 3.5120(3.5116) | Xent 0.0009(0.0040) | Loss 8.8005(9.1146) | Error 0.0000(0.0011) Steps 802(800.35) | Grad Norm 0.6903(1.6637) | Total Time 0.00(0.00)\n",
      "Iter 17100 | Time 20.2006(20.3740) | Bit/dim 3.4958(3.5105) | Xent 0.0011(0.0039) | Loss 8.7761(9.0278) | Error 0.0000(0.0010) Steps 790(800.40) | Grad Norm 0.8460(1.5373) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0311 | Time 91.6499, Epoch Time 1230.8448(1196.6809), Bit/dim 3.5419(best: 3.5428), Xent 2.9400, Loss 5.0119, Error 0.3703(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17110 | Time 20.7167(20.3123) | Bit/dim 3.5027(3.5088) | Xent 0.0025(0.0036) | Loss 8.7557(9.7405) | Error 0.0000(0.0010) Steps 838(800.87) | Grad Norm 1.0719(1.5009) | Total Time 0.00(0.00)\n",
      "Iter 17120 | Time 20.6109(20.4203) | Bit/dim 3.4860(3.5092) | Xent 0.0009(0.0037) | Loss 8.7925(9.4965) | Error 0.0000(0.0009) Steps 814(800.24) | Grad Norm 0.7508(1.4426) | Total Time 0.00(0.00)\n",
      "Iter 17130 | Time 20.8456(20.4051) | Bit/dim 3.4931(3.5089) | Xent 0.0041(0.0033) | Loss 8.8369(9.3133) | Error 0.0022(0.0008) Steps 838(800.48) | Grad Norm 1.8265(1.4160) | Total Time 0.00(0.00)\n",
      "Iter 17140 | Time 20.2566(20.3991) | Bit/dim 3.5124(3.5071) | Xent 0.0033(0.0032) | Loss 8.8365(9.1708) | Error 0.0011(0.0008) Steps 808(799.20) | Grad Norm 1.6589(1.3653) | Total Time 0.00(0.00)\n",
      "Iter 17150 | Time 20.2605(20.3879) | Bit/dim 3.4779(3.5064) | Xent 0.0096(0.0032) | Loss 8.7547(9.0712) | Error 0.0022(0.0008) Steps 808(798.17) | Grad Norm 2.8136(1.3393) | Total Time 0.00(0.00)\n",
      "Iter 17160 | Time 20.7079(20.2974) | Bit/dim 3.5593(3.5083) | Xent 0.0014(0.0031) | Loss 8.8782(8.9982) | Error 0.0000(0.0008) Steps 784(796.63) | Grad Norm 0.9127(1.3616) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0312 | Time 94.5757, Epoch Time 1229.3621(1197.6614), Bit/dim 3.5430(best: 3.5419), Xent 3.0238, Loss 5.0549, Error 0.3735(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17170 | Time 19.6713(20.2820) | Bit/dim 3.4851(3.5075) | Xent 0.0010(0.0034) | Loss 8.7247(9.6239) | Error 0.0000(0.0007) Steps 790(794.44) | Grad Norm 0.8129(1.3331) | Total Time 0.00(0.00)\n",
      "Iter 17180 | Time 21.3588(20.3654) | Bit/dim 3.5240(3.5079) | Xent 0.0017(0.0031) | Loss 8.8400(9.4010) | Error 0.0000(0.0007) Steps 784(796.81) | Grad Norm 1.0103(1.3793) | Total Time 0.00(0.00)\n",
      "Iter 17190 | Time 20.3197(20.4296) | Bit/dim 3.5259(3.5077) | Xent 0.0009(0.0033) | Loss 8.7604(9.2359) | Error 0.0000(0.0008) Steps 778(797.25) | Grad Norm 0.7596(1.4308) | Total Time 0.00(0.00)\n",
      "Iter 17200 | Time 20.5705(20.4709) | Bit/dim 3.4719(3.5074) | Xent 0.0141(0.0038) | Loss 8.7298(9.1118) | Error 0.0022(0.0009) Steps 802(795.59) | Grad Norm 1.9026(1.4427) | Total Time 0.00(0.00)\n",
      "Iter 17210 | Time 19.7861(20.4282) | Bit/dim 3.5335(3.5067) | Xent 0.0011(0.0037) | Loss 8.7137(9.0213) | Error 0.0000(0.0009) Steps 814(796.08) | Grad Norm 0.6877(1.6352) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0313 | Time 91.9475, Epoch Time 1235.3147(1198.7910), Bit/dim 3.5461(best: 3.5419), Xent 2.9835, Loss 5.0379, Error 0.3676(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17220 | Time 20.7749(20.4343) | Bit/dim 3.5339(3.5106) | Xent 0.0015(0.0036) | Loss 8.7709(9.7552) | Error 0.0011(0.0010) Steps 784(794.96) | Grad Norm 1.5183(1.9370) | Total Time 0.00(0.00)\n",
      "Iter 17230 | Time 20.2208(20.4169) | Bit/dim 3.4944(3.5109) | Xent 0.0080(0.0035) | Loss 8.7755(9.4894) | Error 0.0033(0.0010) Steps 772(796.27) | Grad Norm 2.2819(1.8848) | Total Time 0.00(0.00)\n",
      "Iter 17240 | Time 19.6076(20.4118) | Bit/dim 3.4856(3.5090) | Xent 0.0021(0.0033) | Loss 8.6131(9.2975) | Error 0.0000(0.0009) Steps 772(797.11) | Grad Norm 1.0442(1.8335) | Total Time 0.00(0.00)\n",
      "Iter 17250 | Time 20.5830(20.5089) | Bit/dim 3.5344(3.5068) | Xent 0.0012(0.0033) | Loss 8.8019(9.1449) | Error 0.0000(0.0009) Steps 796(796.73) | Grad Norm 0.8107(1.7624) | Total Time 0.00(0.00)\n",
      "Iter 17260 | Time 20.0180(20.5206) | Bit/dim 3.5214(3.5101) | Xent 0.0008(0.0034) | Loss 8.8049(9.0519) | Error 0.0000(0.0009) Steps 802(797.61) | Grad Norm 0.5656(1.7116) | Total Time 0.00(0.00)\n",
      "Iter 17270 | Time 19.7328(20.5457) | Bit/dim 3.5128(3.5095) | Xent 0.0057(0.0032) | Loss 8.8227(8.9778) | Error 0.0022(0.0008) Steps 802(796.67) | Grad Norm 2.3644(1.6585) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0314 | Time 90.7381, Epoch Time 1237.2202(1199.9438), Bit/dim 3.5415(best: 3.5419), Xent 2.9837, Loss 5.0333, Error 0.3685(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17280 | Time 20.9894(20.4801) | Bit/dim 3.5303(3.5103) | Xent 0.0037(0.0036) | Loss 8.7911(9.6078) | Error 0.0011(0.0009) Steps 796(797.51) | Grad Norm 2.8283(1.8416) | Total Time 0.00(0.00)\n",
      "Iter 17290 | Time 19.8301(20.4484) | Bit/dim 3.5378(3.5094) | Xent 0.0009(0.0041) | Loss 8.8114(9.3915) | Error 0.0000(0.0010) Steps 790(798.25) | Grad Norm 0.7413(1.7484) | Total Time 0.00(0.00)\n",
      "Iter 17300 | Time 20.2828(20.4817) | Bit/dim 3.5379(3.5092) | Xent 0.0014(0.0040) | Loss 8.6467(9.2240) | Error 0.0000(0.0009) Steps 790(799.38) | Grad Norm 0.9865(1.5940) | Total Time 0.00(0.00)\n",
      "Iter 17310 | Time 20.2163(20.5301) | Bit/dim 3.5358(3.5098) | Xent 0.0017(0.0042) | Loss 8.8861(9.1128) | Error 0.0000(0.0010) Steps 814(803.32) | Grad Norm 1.2081(1.7522) | Total Time 0.00(0.00)\n",
      "Iter 17320 | Time 19.0784(20.4441) | Bit/dim 3.4969(3.5080) | Xent 0.0235(0.0057) | Loss 8.7552(9.0213) | Error 0.0056(0.0014) Steps 790(800.67) | Grad Norm 3.8085(2.1546) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0315 | Time 92.8925, Epoch Time 1235.2122(1201.0019), Bit/dim 3.5426(best: 3.5415), Xent 2.9631, Loss 5.0242, Error 0.3668(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17330 | Time 20.7666(20.4503) | Bit/dim 3.4548(3.5095) | Xent 0.0013(0.0054) | Loss 8.6771(9.7297) | Error 0.0000(0.0013) Steps 808(799.09) | Grad Norm 1.7394(2.3206) | Total Time 0.00(0.00)\n",
      "Iter 17340 | Time 20.1146(20.3418) | Bit/dim 3.5017(3.5109) | Xent 0.0116(0.0052) | Loss 8.7949(9.4863) | Error 0.0022(0.0013) Steps 802(799.42) | Grad Norm 3.3548(2.2801) | Total Time 0.00(0.00)\n",
      "Iter 17350 | Time 20.8927(20.4369) | Bit/dim 3.5208(3.5097) | Xent 0.0009(0.0046) | Loss 8.7594(9.2914) | Error 0.0000(0.0012) Steps 796(798.91) | Grad Norm 1.0837(2.0549) | Total Time 0.00(0.00)\n",
      "Iter 17360 | Time 20.3746(20.3922) | Bit/dim 3.4972(3.5098) | Xent 0.0009(0.0042) | Loss 8.6553(9.1486) | Error 0.0000(0.0010) Steps 826(800.08) | Grad Norm 0.6331(1.8362) | Total Time 0.00(0.00)\n",
      "Iter 17370 | Time 20.6483(20.3817) | Bit/dim 3.5319(3.5125) | Xent 0.0059(0.0042) | Loss 8.7083(9.0408) | Error 0.0011(0.0010) Steps 808(800.83) | Grad Norm 2.2560(1.8170) | Total Time 0.00(0.00)\n",
      "Iter 17380 | Time 20.0832(20.3806) | Bit/dim 3.5210(3.5101) | Xent 0.0027(0.0041) | Loss 8.8154(8.9613) | Error 0.0011(0.0011) Steps 814(799.39) | Grad Norm 2.0317(1.8726) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0316 | Time 91.0306, Epoch Time 1226.3717(1201.7630), Bit/dim 3.5411(best: 3.5415), Xent 2.9736, Loss 5.0279, Error 0.3710(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17390 | Time 20.1292(20.3664) | Bit/dim 3.5078(3.5071) | Xent 0.0009(0.0041) | Loss 8.7543(9.5541) | Error 0.0000(0.0011) Steps 796(797.99) | Grad Norm 1.3821(1.8318) | Total Time 0.00(0.00)\n",
      "Iter 17400 | Time 19.3654(20.3532) | Bit/dim 3.5145(3.5085) | Xent 0.0039(0.0043) | Loss 8.8594(9.3472) | Error 0.0022(0.0011) Steps 778(797.21) | Grad Norm 1.7709(1.7552) | Total Time 0.00(0.00)\n",
      "Iter 17410 | Time 20.1131(20.4458) | Bit/dim 3.4893(3.5067) | Xent 0.0027(0.0037) | Loss 8.6993(9.1742) | Error 0.0011(0.0009) Steps 790(794.94) | Grad Norm 1.8571(1.6096) | Total Time 0.00(0.00)\n",
      "Iter 17420 | Time 19.6414(20.3337) | Bit/dim 3.4923(3.5070) | Xent 0.0023(0.0034) | Loss 8.7743(9.0627) | Error 0.0011(0.0008) Steps 802(795.73) | Grad Norm 1.2077(1.5333) | Total Time 0.00(0.00)\n",
      "Iter 17430 | Time 21.4227(20.4260) | Bit/dim 3.5189(3.5095) | Xent 0.0019(0.0033) | Loss 8.7809(8.9976) | Error 0.0000(0.0008) Steps 766(798.24) | Grad Norm 1.2911(1.5175) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0317 | Time 90.9527, Epoch Time 1230.0487(1202.6115), Bit/dim 3.5426(best: 3.5411), Xent 2.9625, Loss 5.0239, Error 0.3676(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17440 | Time 20.1928(20.4132) | Bit/dim 3.4704(3.5111) | Xent 0.0009(0.0030) | Loss 8.7003(9.7449) | Error 0.0000(0.0008) Steps 808(801.16) | Grad Norm 1.1762(1.4421) | Total Time 0.00(0.00)\n",
      "Iter 17450 | Time 19.8043(20.3501) | Bit/dim 3.5225(3.5112) | Xent 0.0032(0.0030) | Loss 8.7942(9.4914) | Error 0.0011(0.0008) Steps 790(799.24) | Grad Norm 1.8718(1.5790) | Total Time 0.00(0.00)\n",
      "Iter 17460 | Time 19.7276(20.2673) | Bit/dim 3.5333(3.5100) | Xent 0.0065(0.0035) | Loss 8.8279(9.3041) | Error 0.0011(0.0010) Steps 808(799.12) | Grad Norm 2.1877(1.7946) | Total Time 0.00(0.00)\n",
      "Iter 17470 | Time 20.4044(20.3258) | Bit/dim 3.5089(3.5099) | Xent 0.0016(0.0041) | Loss 8.8193(9.1624) | Error 0.0000(0.0011) Steps 784(800.82) | Grad Norm 1.0726(1.8751) | Total Time 0.00(0.00)\n",
      "Iter 17480 | Time 19.0775(20.2953) | Bit/dim 3.5116(3.5111) | Xent 0.0037(0.0038) | Loss 8.8311(9.0522) | Error 0.0011(0.0010) Steps 814(799.78) | Grad Norm 1.3966(1.7402) | Total Time 0.00(0.00)\n",
      "Iter 17490 | Time 20.4754(20.3918) | Bit/dim 3.5158(3.5109) | Xent 0.0199(0.0045) | Loss 8.8577(8.9746) | Error 0.0022(0.0011) Steps 796(799.62) | Grad Norm 2.4568(1.7844) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0318 | Time 93.4268, Epoch Time 1228.3473(1203.3836), Bit/dim 3.5407(best: 3.5411), Xent 3.0112, Loss 5.0463, Error 0.3693(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17500 | Time 20.1691(20.2582) | Bit/dim 3.5260(3.5108) | Xent 0.0049(0.0042) | Loss 8.7689(9.5880) | Error 0.0011(0.0011) Steps 814(799.18) | Grad Norm 1.5206(1.8363) | Total Time 0.00(0.00)\n",
      "Iter 17510 | Time 21.4962(20.3426) | Bit/dim 3.5125(3.5102) | Xent 0.0041(0.0035) | Loss 8.6248(9.3644) | Error 0.0022(0.0010) Steps 778(799.40) | Grad Norm 2.0792(1.6778) | Total Time 0.00(0.00)\n",
      "Iter 17520 | Time 20.6097(20.3354) | Bit/dim 3.5073(3.5109) | Xent 0.0017(0.0035) | Loss 8.6958(9.2069) | Error 0.0000(0.0009) Steps 772(800.13) | Grad Norm 0.8432(1.5769) | Total Time 0.00(0.00)\n",
      "Iter 17530 | Time 20.8863(20.2563) | Bit/dim 3.4808(3.5085) | Xent 0.0058(0.0039) | Loss 8.7728(9.0883) | Error 0.0022(0.0010) Steps 790(800.43) | Grad Norm 3.3126(1.6307) | Total Time 0.00(0.00)\n",
      "Iter 17540 | Time 21.1582(20.2726) | Bit/dim 3.5047(3.5067) | Xent 0.0017(0.0038) | Loss 8.8080(9.0047) | Error 0.0000(0.0010) Steps 814(801.30) | Grad Norm 1.1620(1.6978) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0319 | Time 89.5777, Epoch Time 1218.9602(1203.8509), Bit/dim 3.5396(best: 3.5407), Xent 2.9807, Loss 5.0300, Error 0.3644(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17550 | Time 21.0024(20.3183) | Bit/dim 3.5341(3.5090) | Xent 0.0007(0.0040) | Loss 8.8410(9.7449) | Error 0.0000(0.0011) Steps 838(800.72) | Grad Norm 0.7839(1.7196) | Total Time 0.00(0.00)\n",
      "Iter 17560 | Time 19.2174(20.2845) | Bit/dim 3.5031(3.5084) | Xent 0.0006(0.0037) | Loss 8.7157(9.4943) | Error 0.0000(0.0011) Steps 760(800.08) | Grad Norm 0.7593(1.7105) | Total Time 0.00(0.00)\n",
      "Iter 17570 | Time 19.7191(20.1936) | Bit/dim 3.5188(3.5070) | Xent 0.0041(0.0035) | Loss 8.8550(9.3076) | Error 0.0011(0.0010) Steps 820(800.11) | Grad Norm 1.5714(1.6197) | Total Time 0.00(0.00)\n",
      "Iter 17580 | Time 20.1899(20.2242) | Bit/dim 3.5175(3.5066) | Xent 0.0022(0.0037) | Loss 8.8400(9.1645) | Error 0.0000(0.0011) Steps 802(801.36) | Grad Norm 1.4715(1.6449) | Total Time 0.00(0.00)\n",
      "Iter 17590 | Time 19.7518(20.2051) | Bit/dim 3.5040(3.5068) | Xent 0.0028(0.0039) | Loss 8.7801(9.0684) | Error 0.0011(0.0011) Steps 796(803.48) | Grad Norm 1.9676(1.7090) | Total Time 0.00(0.00)\n",
      "Iter 17600 | Time 20.5811(20.2241) | Bit/dim 3.5229(3.5076) | Xent 0.0058(0.0042) | Loss 8.8676(9.0054) | Error 0.0022(0.0013) Steps 790(802.81) | Grad Norm 2.5419(1.8557) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0320 | Time 92.1853, Epoch Time 1221.4430(1204.3787), Bit/dim 3.5452(best: 3.5396), Xent 3.0156, Loss 5.0530, Error 0.3690(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17610 | Time 20.3381(20.1762) | Bit/dim 3.4548(3.5087) | Xent 0.0064(0.0046) | Loss 8.7142(9.6227) | Error 0.0011(0.0015) Steps 844(800.95) | Grad Norm 1.4065(1.9556) | Total Time 0.00(0.00)\n",
      "Iter 17620 | Time 20.0562(20.2689) | Bit/dim 3.4747(3.5083) | Xent 0.0028(0.0042) | Loss 8.8240(9.3974) | Error 0.0011(0.0014) Steps 796(798.60) | Grad Norm 4.3298(1.9777) | Total Time 0.00(0.00)\n",
      "Iter 17630 | Time 20.8704(20.2855) | Bit/dim 3.5312(3.5093) | Xent 0.0073(0.0042) | Loss 8.7598(9.2329) | Error 0.0022(0.0013) Steps 820(799.98) | Grad Norm 2.5261(1.9340) | Total Time 0.00(0.00)\n",
      "Iter 17640 | Time 20.3045(20.2641) | Bit/dim 3.4878(3.5098) | Xent 0.0065(0.0040) | Loss 8.7031(9.1029) | Error 0.0022(0.0013) Steps 820(799.71) | Grad Norm 2.9895(1.8538) | Total Time 0.00(0.00)\n",
      "Iter 17650 | Time 20.1603(20.2393) | Bit/dim 3.5125(3.5066) | Xent 0.0009(0.0039) | Loss 8.8465(9.0110) | Error 0.0000(0.0012) Steps 796(799.23) | Grad Norm 1.4863(1.8152) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0321 | Time 92.7169, Epoch Time 1223.7900(1204.9610), Bit/dim 3.5427(best: 3.5396), Xent 2.9518, Loss 5.0186, Error 0.3626(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17660 | Time 20.8879(20.2746) | Bit/dim 3.5316(3.5078) | Xent 0.0016(0.0039) | Loss 8.8760(9.7458) | Error 0.0000(0.0012) Steps 790(799.17) | Grad Norm 1.6911(1.8471) | Total Time 0.00(0.00)\n",
      "Iter 17670 | Time 19.5296(20.3004) | Bit/dim 3.5059(3.5061) | Xent 0.0074(0.0038) | Loss 8.8816(9.4916) | Error 0.0011(0.0011) Steps 802(798.17) | Grad Norm 2.2801(1.8787) | Total Time 0.00(0.00)\n",
      "Iter 17680 | Time 20.8206(20.3266) | Bit/dim 3.4997(3.5068) | Xent 0.0065(0.0041) | Loss 8.7888(9.3017) | Error 0.0011(0.0010) Steps 808(798.54) | Grad Norm 2.1565(1.9275) | Total Time 0.00(0.00)\n",
      "Iter 17690 | Time 20.0518(20.3260) | Bit/dim 3.5247(3.5109) | Xent 0.0031(0.0043) | Loss 8.7992(9.1695) | Error 0.0011(0.0011) Steps 802(796.52) | Grad Norm 2.9468(2.0361) | Total Time 0.00(0.00)\n",
      "Iter 17700 | Time 20.1071(20.2841) | Bit/dim 3.5240(3.5107) | Xent 0.0108(0.0047) | Loss 8.7925(9.0653) | Error 0.0022(0.0012) Steps 814(799.78) | Grad Norm 2.0755(2.1053) | Total Time 0.00(0.00)\n",
      "Iter 17710 | Time 20.7673(20.3591) | Bit/dim 3.4940(3.5066) | Xent 0.0049(0.0045) | Loss 8.6679(8.9732) | Error 0.0011(0.0011) Steps 820(798.57) | Grad Norm 2.7491(2.1743) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0322 | Time 90.4740, Epoch Time 1227.3995(1205.6342), Bit/dim 3.5431(best: 3.5396), Xent 3.0021, Loss 5.0441, Error 0.3679(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17720 | Time 20.5093(20.3582) | Bit/dim 3.5025(3.5092) | Xent 0.0043(0.0042) | Loss 8.8007(9.6171) | Error 0.0022(0.0012) Steps 796(801.73) | Grad Norm 3.9395(2.1570) | Total Time 0.00(0.00)\n",
      "Iter 17730 | Time 20.3625(20.3981) | Bit/dim 3.5037(3.5083) | Xent 0.0017(0.0040) | Loss 8.6637(9.3981) | Error 0.0011(0.0011) Steps 808(802.29) | Grad Norm 1.7096(2.1832) | Total Time 0.00(0.00)\n",
      "Iter 17740 | Time 20.0772(20.4141) | Bit/dim 3.5323(3.5096) | Xent 0.0010(0.0038) | Loss 8.9036(9.2402) | Error 0.0000(0.0011) Steps 814(804.19) | Grad Norm 0.8081(2.0191) | Total Time 0.00(0.00)\n",
      "Iter 17750 | Time 20.4264(20.4538) | Bit/dim 3.4808(3.5063) | Xent 0.0096(0.0043) | Loss 8.7856(9.1115) | Error 0.0022(0.0011) Steps 784(803.15) | Grad Norm 3.3379(1.9192) | Total Time 0.00(0.00)\n",
      "Iter 17760 | Time 19.9449(20.3350) | Bit/dim 3.5275(3.5050) | Xent 0.0078(0.0039) | Loss 8.7739(9.0133) | Error 0.0011(0.0010) Steps 808(803.39) | Grad Norm 1.8139(1.6921) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0323 | Time 93.0653, Epoch Time 1231.8013(1206.4192), Bit/dim 3.5380(best: 3.5396), Xent 2.9725, Loss 5.0243, Error 0.3717(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17770 | Time 21.8735(20.4285) | Bit/dim 3.5104(3.5082) | Xent 0.0055(0.0036) | Loss 8.9208(9.7218) | Error 0.0022(0.0009) Steps 790(799.39) | Grad Norm 1.5872(1.5874) | Total Time 0.00(0.00)\n",
      "Iter 17780 | Time 21.1511(20.3994) | Bit/dim 3.5373(3.5076) | Xent 0.0035(0.0042) | Loss 8.9191(9.4727) | Error 0.0022(0.0011) Steps 826(800.26) | Grad Norm 2.0629(1.6701) | Total Time 0.00(0.00)\n",
      "Iter 17790 | Time 20.3763(20.4514) | Bit/dim 3.4817(3.5054) | Xent 0.0055(0.0041) | Loss 8.8209(9.2880) | Error 0.0022(0.0012) Steps 796(801.60) | Grad Norm 2.6523(1.7770) | Total Time 0.00(0.00)\n",
      "Iter 17800 | Time 20.4648(20.3495) | Bit/dim 3.5113(3.5058) | Xent 0.0005(0.0040) | Loss 8.8250(9.1526) | Error 0.0000(0.0011) Steps 820(803.05) | Grad Norm 0.6332(1.7565) | Total Time 0.00(0.00)\n",
      "Iter 17810 | Time 21.5014(20.3778) | Bit/dim 3.4847(3.5057) | Xent 0.0030(0.0039) | Loss 8.6652(9.0466) | Error 0.0011(0.0010) Steps 766(802.77) | Grad Norm 1.6865(1.7027) | Total Time 0.00(0.00)\n",
      "Iter 17820 | Time 19.8936(20.4079) | Bit/dim 3.5054(3.5057) | Xent 0.0062(0.0040) | Loss 8.7153(8.9669) | Error 0.0011(0.0010) Steps 814(801.88) | Grad Norm 1.7529(1.7899) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0324 | Time 91.9174, Epoch Time 1231.7412(1207.1788), Bit/dim 3.5411(best: 3.5380), Xent 2.9937, Loss 5.0379, Error 0.3718(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17830 | Time 21.0409(20.4083) | Bit/dim 3.5299(3.5056) | Xent 0.0008(0.0039) | Loss 8.9096(9.6021) | Error 0.0000(0.0009) Steps 778(801.02) | Grad Norm 0.5435(1.7093) | Total Time 0.00(0.00)\n",
      "Iter 17840 | Time 19.8118(20.3895) | Bit/dim 3.5264(3.5082) | Xent 0.0043(0.0041) | Loss 8.7509(9.3921) | Error 0.0011(0.0010) Steps 784(801.57) | Grad Norm 1.6300(1.6663) | Total Time 0.00(0.00)\n",
      "Iter 17850 | Time 20.9398(20.3419) | Bit/dim 3.5194(3.5089) | Xent 0.0025(0.0042) | Loss 8.8712(9.2332) | Error 0.0000(0.0010) Steps 814(798.83) | Grad Norm 1.5878(1.6782) | Total Time 0.00(0.00)\n",
      "Iter 17860 | Time 20.3632(20.3908) | Bit/dim 3.4510(3.5069) | Xent 0.0086(0.0041) | Loss 8.7068(9.0976) | Error 0.0022(0.0010) Steps 784(797.42) | Grad Norm 1.8759(1.7165) | Total Time 0.00(0.00)\n",
      "Iter 17870 | Time 20.1557(20.3032) | Bit/dim 3.5067(3.5078) | Xent 0.0019(0.0042) | Loss 8.8509(9.0122) | Error 0.0011(0.0011) Steps 826(797.73) | Grad Norm 1.4970(1.9743) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0325 | Time 94.0620, Epoch Time 1229.4941(1207.8483), Bit/dim 3.5410(best: 3.5380), Xent 3.0149, Loss 5.0484, Error 0.3638(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17880 | Time 20.8441(20.4056) | Bit/dim 3.4947(3.5091) | Xent 0.0033(0.0040) | Loss 8.7080(9.7470) | Error 0.0011(0.0011) Steps 796(797.98) | Grad Norm 2.6659(1.9166) | Total Time 0.00(0.00)\n",
      "Iter 17890 | Time 20.2249(20.3129) | Bit/dim 3.5209(3.5095) | Xent 0.0027(0.0043) | Loss 8.7726(9.4858) | Error 0.0011(0.0012) Steps 784(795.26) | Grad Norm 1.5984(1.9396) | Total Time 0.00(0.00)\n",
      "Iter 17900 | Time 19.5481(20.3820) | Bit/dim 3.5057(3.5067) | Xent 0.0033(0.0049) | Loss 8.7443(9.2931) | Error 0.0011(0.0013) Steps 796(796.48) | Grad Norm 1.0380(2.0861) | Total Time 0.00(0.00)\n",
      "Iter 17910 | Time 21.0744(20.3877) | Bit/dim 3.5365(3.5058) | Xent 0.0030(0.0046) | Loss 8.8119(9.1504) | Error 0.0011(0.0013) Steps 784(796.91) | Grad Norm 1.9139(2.0686) | Total Time 0.00(0.00)\n",
      "Iter 17920 | Time 20.4663(20.3538) | Bit/dim 3.5434(3.5076) | Xent 0.0074(0.0046) | Loss 8.7530(9.0518) | Error 0.0022(0.0014) Steps 784(797.14) | Grad Norm 1.6103(2.0754) | Total Time 0.00(0.00)\n",
      "Iter 17930 | Time 20.2918(20.3410) | Bit/dim 3.5557(3.5099) | Xent 0.0056(0.0046) | Loss 8.8888(8.9768) | Error 0.0022(0.0014) Steps 808(798.66) | Grad Norm 2.6456(2.1043) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0326 | Time 91.4893, Epoch Time 1227.9900(1208.4526), Bit/dim 3.5438(best: 3.5380), Xent 3.0869, Loss 5.0872, Error 0.3721(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17940 | Time 19.8052(20.3132) | Bit/dim 3.4734(3.5069) | Xent 0.0009(0.0043) | Loss 8.6552(9.5941) | Error 0.0000(0.0014) Steps 796(797.65) | Grad Norm 0.9908(2.0310) | Total Time 0.00(0.00)\n",
      "Iter 17950 | Time 20.0668(20.3129) | Bit/dim 3.4961(3.5069) | Xent 0.0009(0.0042) | Loss 8.6938(9.3710) | Error 0.0000(0.0013) Steps 808(799.98) | Grad Norm 0.9913(2.0214) | Total Time 0.00(0.00)\n",
      "Iter 17960 | Time 20.5897(20.3073) | Bit/dim 3.5448(3.5084) | Xent 0.0006(0.0037) | Loss 8.8187(9.2196) | Error 0.0000(0.0011) Steps 814(802.41) | Grad Norm 1.0494(1.8552) | Total Time 0.00(0.00)\n",
      "Iter 17970 | Time 20.0136(20.4164) | Bit/dim 3.5232(3.5092) | Xent 0.0007(0.0040) | Loss 8.8622(9.1086) | Error 0.0000(0.0012) Steps 790(801.67) | Grad Norm 0.6885(1.8937) | Total Time 0.00(0.00)\n",
      "Iter 17980 | Time 19.7183(20.3307) | Bit/dim 3.5249(3.5100) | Xent 0.0072(0.0043) | Loss 8.7106(9.0129) | Error 0.0011(0.0012) Steps 796(799.49) | Grad Norm 2.0365(1.9521) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0327 | Time 92.6697, Epoch Time 1230.3351(1209.1090), Bit/dim 3.5406(best: 3.5380), Xent 3.0086, Loss 5.0449, Error 0.3724(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17990 | Time 20.1584(20.3323) | Bit/dim 3.5249(3.5095) | Xent 0.0029(0.0041) | Loss 8.8952(9.7501) | Error 0.0000(0.0011) Steps 790(801.13) | Grad Norm 1.2187(1.8658) | Total Time 0.00(0.00)\n",
      "Iter 18000 | Time 20.5250(20.3403) | Bit/dim 3.5103(3.5083) | Xent 0.0016(0.0036) | Loss 8.6111(9.4834) | Error 0.0000(0.0010) Steps 754(799.58) | Grad Norm 0.7663(1.7833) | Total Time 0.00(0.00)\n",
      "Iter 18010 | Time 20.3123(20.4230) | Bit/dim 3.5054(3.5084) | Xent 0.0012(0.0033) | Loss 8.8394(9.2968) | Error 0.0000(0.0009) Steps 802(798.12) | Grad Norm 0.6566(1.6374) | Total Time 0.00(0.00)\n",
      "Iter 18020 | Time 20.7121(20.3507) | Bit/dim 3.4834(3.5081) | Xent 0.0050(0.0035) | Loss 8.7001(9.1579) | Error 0.0022(0.0009) Steps 796(795.84) | Grad Norm 2.0701(1.6042) | Total Time 0.00(0.00)\n",
      "Iter 18030 | Time 20.9245(20.3412) | Bit/dim 3.4817(3.5076) | Xent 0.0016(0.0031) | Loss 8.7436(9.0507) | Error 0.0000(0.0008) Steps 772(792.98) | Grad Norm 0.7761(1.4294) | Total Time 0.00(0.00)\n",
      "Iter 18040 | Time 20.1435(20.2647) | Bit/dim 3.5387(3.5085) | Xent 0.0043(0.0036) | Loss 8.8900(8.9778) | Error 0.0011(0.0009) Steps 808(793.28) | Grad Norm 2.6067(1.6590) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0328 | Time 91.4282, Epoch Time 1223.5583(1209.5425), Bit/dim 3.5420(best: 3.5380), Xent 3.0227, Loss 5.0534, Error 0.3685(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18050 | Time 21.9433(20.3734) | Bit/dim 3.5224(3.5098) | Xent 0.0107(0.0042) | Loss 8.8285(9.5863) | Error 0.0044(0.0011) Steps 760(793.26) | Grad Norm 4.7782(2.1160) | Total Time 0.00(0.00)\n",
      "Iter 18060 | Time 19.8377(20.3389) | Bit/dim 3.4968(3.5100) | Xent 0.0045(0.0047) | Loss 8.6031(9.3665) | Error 0.0033(0.0013) Steps 820(795.10) | Grad Norm 2.7802(2.2661) | Total Time 0.00(0.00)\n",
      "Iter 18070 | Time 19.6873(20.3721) | Bit/dim 3.5557(3.5103) | Xent 0.0025(0.0047) | Loss 8.8260(9.2037) | Error 0.0011(0.0013) Steps 802(794.79) | Grad Norm 1.6387(2.1547) | Total Time 0.00(0.00)\n",
      "Iter 18080 | Time 20.6331(20.3695) | Bit/dim 3.5049(3.5073) | Xent 0.0057(0.0050) | Loss 8.6924(9.0758) | Error 0.0011(0.0013) Steps 838(793.77) | Grad Norm 1.7248(2.2646) | Total Time 0.00(0.00)\n",
      "Iter 18090 | Time 20.9503(20.4453) | Bit/dim 3.5160(3.5088) | Xent 0.0038(0.0048) | Loss 8.8262(8.9941) | Error 0.0022(0.0013) Steps 832(796.59) | Grad Norm 1.7943(2.1768) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0329 | Time 90.2533, Epoch Time 1235.9347(1210.3343), Bit/dim 3.5395(best: 3.5380), Xent 2.9680, Loss 5.0235, Error 0.3669(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18100 | Time 19.9209(20.4620) | Bit/dim 3.4540(3.5060) | Xent 0.0061(0.0047) | Loss 8.6815(9.7350) | Error 0.0022(0.0013) Steps 778(795.27) | Grad Norm 2.0461(2.0882) | Total Time 0.00(0.00)\n",
      "Iter 18110 | Time 20.4110(20.4562) | Bit/dim 3.5006(3.5076) | Xent 0.0047(0.0044) | Loss 8.7791(9.4837) | Error 0.0022(0.0013) Steps 790(794.83) | Grad Norm 2.7915(2.0364) | Total Time 0.00(0.00)\n",
      "Iter 18120 | Time 19.5046(20.3029) | Bit/dim 3.5425(3.5092) | Xent 0.0016(0.0041) | Loss 8.7352(9.2948) | Error 0.0000(0.0011) Steps 790(791.79) | Grad Norm 1.0617(1.9390) | Total Time 0.00(0.00)\n",
      "Iter 18130 | Time 20.6138(20.2474) | Bit/dim 3.5040(3.5083) | Xent 0.0121(0.0050) | Loss 8.7720(9.1434) | Error 0.0022(0.0013) Steps 766(789.83) | Grad Norm 3.0887(2.0459) | Total Time 0.00(0.00)\n",
      "Iter 18140 | Time 20.6105(20.3333) | Bit/dim 3.5336(3.5080) | Xent 0.0008(0.0044) | Loss 8.8637(9.0531) | Error 0.0000(0.0012) Steps 808(793.29) | Grad Norm 0.8273(2.0416) | Total Time 0.00(0.00)\n",
      "Iter 18150 | Time 20.2793(20.3015) | Bit/dim 3.5100(3.5075) | Xent 0.0024(0.0044) | Loss 8.7352(8.9647) | Error 0.0011(0.0012) Steps 772(793.82) | Grad Norm 1.4000(2.0691) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0330 | Time 92.3908, Epoch Time 1222.0020(1210.6843), Bit/dim 3.5383(best: 3.5380), Xent 3.0132, Loss 5.0449, Error 0.3702(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18160 | Time 19.7777(20.3089) | Bit/dim 3.4924(3.5052) | Xent 0.0016(0.0039) | Loss 8.7175(9.5944) | Error 0.0011(0.0011) Steps 778(795.44) | Grad Norm 1.0762(1.8676) | Total Time 0.00(0.00)\n",
      "Iter 18170 | Time 20.1191(20.2928) | Bit/dim 3.4805(3.5047) | Xent 0.0198(0.0048) | Loss 8.6721(9.3754) | Error 0.0067(0.0014) Steps 772(796.54) | Grad Norm 6.0415(2.0298) | Total Time 0.00(0.00)\n",
      "Iter 18180 | Time 21.0605(20.3431) | Bit/dim 3.5300(3.5077) | Xent 0.0005(0.0042) | Loss 8.7829(9.2187) | Error 0.0000(0.0013) Steps 820(796.53) | Grad Norm 0.8641(2.0156) | Total Time 0.00(0.00)\n",
      "Iter 18190 | Time 19.6380(20.2403) | Bit/dim 3.4873(3.5067) | Xent 0.0038(0.0038) | Loss 8.6633(9.0925) | Error 0.0011(0.0012) Steps 772(794.91) | Grad Norm 1.6733(2.0411) | Total Time 0.00(0.00)\n",
      "Iter 18200 | Time 19.6692(20.2291) | Bit/dim 3.4845(3.5054) | Xent 0.0100(0.0038) | Loss 8.6913(8.9984) | Error 0.0033(0.0011) Steps 766(794.99) | Grad Norm 2.4662(1.9179) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0331 | Time 90.0418, Epoch Time 1221.4296(1211.0067), Bit/dim 3.5398(best: 3.5380), Xent 3.0355, Loss 5.0576, Error 0.3670(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18210 | Time 20.3921(20.2424) | Bit/dim 3.5360(3.5071) | Xent 0.0107(0.0039) | Loss 8.8764(9.7462) | Error 0.0011(0.0011) Steps 790(794.86) | Grad Norm 1.5281(1.8141) | Total Time 0.00(0.00)\n",
      "Iter 18220 | Time 20.2178(20.3088) | Bit/dim 3.4795(3.5055) | Xent 0.0006(0.0034) | Loss 8.6662(9.4780) | Error 0.0000(0.0009) Steps 808(794.31) | Grad Norm 0.6112(1.5907) | Total Time 0.00(0.00)\n",
      "Iter 18230 | Time 20.3331(20.2584) | Bit/dim 3.4811(3.5040) | Xent 0.0022(0.0035) | Loss 8.7883(9.2902) | Error 0.0011(0.0010) Steps 796(794.09) | Grad Norm 1.5453(1.7979) | Total Time 0.00(0.00)\n",
      "Iter 18240 | Time 20.4327(20.2725) | Bit/dim 3.5439(3.5060) | Xent 0.0012(0.0033) | Loss 8.7996(9.1528) | Error 0.0000(0.0009) Steps 790(792.55) | Grad Norm 0.9849(1.7887) | Total Time 0.00(0.00)\n",
      "Iter 18250 | Time 19.8153(20.2901) | Bit/dim 3.5006(3.5053) | Xent 0.0027(0.0035) | Loss 8.6976(9.0550) | Error 0.0011(0.0010) Steps 796(796.20) | Grad Norm 2.7568(1.7920) | Total Time 0.00(0.00)\n",
      "Iter 18260 | Time 19.2647(20.1662) | Bit/dim 3.4927(3.5048) | Xent 0.0021(0.0031) | Loss 8.8340(8.9852) | Error 0.0011(0.0009) Steps 772(794.61) | Grad Norm 1.5052(1.6717) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0332 | Time 93.8947, Epoch Time 1222.7346(1211.3585), Bit/dim 3.5368(best: 3.5380), Xent 3.0817, Loss 5.0776, Error 0.3739(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18270 | Time 20.2585(20.2221) | Bit/dim 3.5417(3.5019) | Xent 0.0022(0.0042) | Loss 8.8701(9.6068) | Error 0.0000(0.0012) Steps 796(795.92) | Grad Norm 1.5020(2.0801) | Total Time 0.00(0.00)\n",
      "Iter 18280 | Time 20.5398(20.2210) | Bit/dim 3.5415(3.5050) | Xent 0.0054(0.0045) | Loss 8.8364(9.3889) | Error 0.0033(0.0014) Steps 820(796.33) | Grad Norm 2.3819(2.1622) | Total Time 0.00(0.00)\n",
      "Iter 18290 | Time 20.5544(20.2997) | Bit/dim 3.5386(3.5047) | Xent 0.0060(0.0047) | Loss 8.9054(9.2269) | Error 0.0022(0.0013) Steps 808(798.89) | Grad Norm 2.0052(2.1200) | Total Time 0.00(0.00)\n",
      "Iter 18300 | Time 19.3642(20.3024) | Bit/dim 3.5180(3.5073) | Xent 0.0006(0.0042) | Loss 8.8001(9.1046) | Error 0.0000(0.0012) Steps 796(797.09) | Grad Norm 1.0612(2.0098) | Total Time 0.00(0.00)\n",
      "Iter 18310 | Time 20.2930(20.2994) | Bit/dim 3.5209(3.5057) | Xent 0.0043(0.0044) | Loss 8.8218(9.0042) | Error 0.0011(0.0013) Steps 796(795.50) | Grad Norm 1.9495(1.9636) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 90.2611, Epoch Time 1225.7831(1211.7912), Bit/dim 3.5377(best: 3.5368), Xent 3.0242, Loss 5.0498, Error 0.3719(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18320 | Time 19.4094(20.2694) | Bit/dim 3.4955(3.5077) | Xent 0.0055(0.0041) | Loss 8.6979(9.7323) | Error 0.0011(0.0012) Steps 802(794.85) | Grad Norm 2.6213(1.9448) | Total Time 0.00(0.00)\n",
      "Iter 18330 | Time 20.5591(20.3847) | Bit/dim 3.5167(3.5080) | Xent 0.0015(0.0037) | Loss 8.8102(9.4713) | Error 0.0011(0.0010) Steps 796(792.02) | Grad Norm 1.6929(1.7597) | Total Time 0.00(0.00)\n",
      "Iter 18340 | Time 19.9487(20.3029) | Bit/dim 3.4971(3.5064) | Xent 0.0034(0.0032) | Loss 8.7460(9.2851) | Error 0.0011(0.0009) Steps 802(794.26) | Grad Norm 1.5384(1.6186) | Total Time 0.00(0.00)\n",
      "Iter 18350 | Time 19.8434(20.3058) | Bit/dim 3.5017(3.5046) | Xent 0.0020(0.0030) | Loss 8.6659(9.1350) | Error 0.0011(0.0009) Steps 790(795.64) | Grad Norm 0.9356(1.5617) | Total Time 0.00(0.00)\n",
      "Iter 18360 | Time 19.6885(20.2339) | Bit/dim 3.4935(3.5031) | Xent 0.0165(0.0039) | Loss 8.7178(9.0269) | Error 0.0022(0.0010) Steps 820(797.47) | Grad Norm 2.7286(1.7930) | Total Time 0.00(0.00)\n",
      "Iter 18370 | Time 20.1596(20.2988) | Bit/dim 3.4852(3.5043) | Xent 0.0005(0.0036) | Loss 8.7755(8.9604) | Error 0.0000(0.0009) Steps 796(798.60) | Grad Norm 0.6707(1.8626) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 91.8673, Epoch Time 1225.4395(1212.2007), Bit/dim 3.5389(best: 3.5368), Xent 3.0855, Loss 5.0816, Error 0.3734(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18380 | Time 20.4076(20.2374) | Bit/dim 3.5058(3.5033) | Xent 0.0027(0.0039) | Loss 8.7452(9.5788) | Error 0.0000(0.0009) Steps 814(799.71) | Grad Norm 1.4249(1.9454) | Total Time 0.00(0.00)\n",
      "Iter 18390 | Time 21.3193(20.2991) | Bit/dim 3.4869(3.5046) | Xent 0.0028(0.0034) | Loss 8.6611(9.3611) | Error 0.0011(0.0008) Steps 778(797.16) | Grad Norm 2.1454(1.8333) | Total Time 0.00(0.00)\n",
      "Iter 18400 | Time 20.7874(20.3531) | Bit/dim 3.5231(3.5048) | Xent 0.0024(0.0037) | Loss 8.8682(9.2044) | Error 0.0011(0.0009) Steps 808(796.48) | Grad Norm 1.4065(1.7876) | Total Time 0.00(0.00)\n",
      "Iter 18410 | Time 20.4023(20.3365) | Bit/dim 3.5127(3.5036) | Xent 0.0019(0.0039) | Loss 8.8562(9.0795) | Error 0.0000(0.0010) Steps 820(797.71) | Grad Norm 1.2878(1.7390) | Total Time 0.00(0.00)\n",
      "Iter 18420 | Time 20.2276(20.2805) | Bit/dim 3.5084(3.5053) | Xent 0.0034(0.0043) | Loss 8.7262(8.9979) | Error 0.0011(0.0011) Steps 826(799.38) | Grad Norm 1.6415(1.8456) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 91.8439, Epoch Time 1225.0526(1212.5862), Bit/dim 3.5404(best: 3.5368), Xent 3.0598, Loss 5.0703, Error 0.3678(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18430 | Time 20.9469(20.3272) | Bit/dim 3.4758(3.5040) | Xent 0.0051(0.0041) | Loss 8.6434(9.7230) | Error 0.0011(0.0010) Steps 772(799.19) | Grad Norm 1.5998(1.7755) | Total Time 0.00(0.00)\n",
      "Iter 18440 | Time 20.2503(20.2241) | Bit/dim 3.5644(3.5056) | Xent 0.0006(0.0034) | Loss 8.8592(9.4659) | Error 0.0000(0.0008) Steps 784(797.57) | Grad Norm 0.8342(1.5878) | Total Time 0.00(0.00)\n",
      "Iter 18450 | Time 19.8948(20.1517) | Bit/dim 3.5057(3.5030) | Xent 0.0021(0.0031) | Loss 8.6784(9.2683) | Error 0.0000(0.0007) Steps 796(796.79) | Grad Norm 1.0440(1.5146) | Total Time 0.00(0.00)\n",
      "Iter 18460 | Time 20.2879(20.2565) | Bit/dim 3.5258(3.5043) | Xent 0.0011(0.0031) | Loss 8.7940(9.1352) | Error 0.0000(0.0007) Steps 778(796.21) | Grad Norm 0.8352(1.4741) | Total Time 0.00(0.00)\n",
      "Iter 18470 | Time 19.3782(20.2555) | Bit/dim 3.5161(3.5046) | Xent 0.0008(0.0030) | Loss 8.7722(9.0338) | Error 0.0000(0.0006) Steps 790(796.31) | Grad Norm 0.6856(1.3652) | Total Time 0.00(0.00)\n",
      "Iter 18480 | Time 20.0156(20.2875) | Bit/dim 3.4953(3.5039) | Xent 0.0014(0.0035) | Loss 8.7735(8.9638) | Error 0.0000(0.0008) Steps 778(795.06) | Grad Norm 1.0774(1.4761) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 90.6471, Epoch Time 1221.1017(1212.8417), Bit/dim 3.5362(best: 3.5368), Xent 3.0526, Loss 5.0625, Error 0.3704(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18490 | Time 20.6218(20.2371) | Bit/dim 3.5207(3.5062) | Xent 0.0018(0.0038) | Loss 8.7625(9.5943) | Error 0.0000(0.0010) Steps 784(792.03) | Grad Norm 1.5996(1.6789) | Total Time 0.00(0.00)\n",
      "Iter 18500 | Time 20.5738(20.2884) | Bit/dim 3.4949(3.5087) | Xent 0.0045(0.0040) | Loss 8.7799(9.3846) | Error 0.0011(0.0011) Steps 826(797.05) | Grad Norm 1.5586(1.9240) | Total Time 0.00(0.00)\n",
      "Iter 18510 | Time 20.1854(20.2804) | Bit/dim 3.5015(3.5086) | Xent 0.0014(0.0043) | Loss 8.7478(9.2287) | Error 0.0000(0.0012) Steps 790(796.60) | Grad Norm 1.1636(2.1151) | Total Time 0.00(0.00)\n",
      "Iter 18520 | Time 20.7837(20.2591) | Bit/dim 3.4844(3.5058) | Xent 0.0007(0.0040) | Loss 8.6584(9.0944) | Error 0.0000(0.0012) Steps 826(796.97) | Grad Norm 1.4910(2.1398) | Total Time 0.00(0.00)\n",
      "Iter 18530 | Time 20.4976(20.3933) | Bit/dim 3.4977(3.5024) | Xent 0.0013(0.0038) | Loss 8.7037(9.0010) | Error 0.0000(0.0012) Steps 754(798.19) | Grad Norm 1.3524(2.1519) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 92.5741, Epoch Time 1227.6893(1213.2871), Bit/dim 3.5367(best: 3.5362), Xent 3.0164, Loss 5.0449, Error 0.3672(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18540 | Time 20.8351(20.3924) | Bit/dim 3.5066(3.5026) | Xent 0.0016(0.0034) | Loss 8.7418(9.7168) | Error 0.0000(0.0010) Steps 772(793.17) | Grad Norm 1.5281(2.0350) | Total Time 0.00(0.00)\n",
      "Iter 18550 | Time 19.1523(20.2322) | Bit/dim 3.4922(3.5043) | Xent 0.0017(0.0031) | Loss 8.7353(9.4614) | Error 0.0011(0.0009) Steps 790(793.41) | Grad Norm 1.8789(1.9214) | Total Time 0.00(0.00)\n",
      "Iter 18560 | Time 20.7871(20.2247) | Bit/dim 3.5372(3.5059) | Xent 0.0010(0.0029) | Loss 8.8123(9.2817) | Error 0.0000(0.0008) Steps 820(793.40) | Grad Norm 0.9364(1.8722) | Total Time 0.00(0.00)\n",
      "Iter 18570 | Time 20.1464(20.2760) | Bit/dim 3.5406(3.5073) | Xent 0.0007(0.0027) | Loss 8.9433(9.1512) | Error 0.0000(0.0008) Steps 796(793.59) | Grad Norm 0.7351(1.7668) | Total Time 0.00(0.00)\n",
      "Iter 18580 | Time 20.4146(20.2409) | Bit/dim 3.5326(3.5062) | Xent 0.0016(0.0028) | Loss 8.8269(9.0420) | Error 0.0000(0.0008) Steps 778(792.68) | Grad Norm 0.8334(1.6697) | Total Time 0.00(0.00)\n",
      "Iter 18590 | Time 19.8911(20.3333) | Bit/dim 3.5080(3.5036) | Xent 0.0043(0.0028) | Loss 8.7641(8.9674) | Error 0.0011(0.0009) Steps 760(793.26) | Grad Norm 1.8380(1.6256) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 90.1159, Epoch Time 1222.4122(1213.5609), Bit/dim 3.5366(best: 3.5362), Xent 3.1421, Loss 5.1076, Error 0.3767(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18600 | Time 19.9314(20.2980) | Bit/dim 3.5164(3.5048) | Xent 0.0177(0.0037) | Loss 8.8828(9.5800) | Error 0.0033(0.0010) Steps 802(792.75) | Grad Norm 2.5134(1.6821) | Total Time 0.00(0.00)\n",
      "Iter 18610 | Time 19.2018(20.2858) | Bit/dim 3.5348(3.5055) | Xent 0.0030(0.0041) | Loss 8.7550(9.3656) | Error 0.0011(0.0010) Steps 772(791.57) | Grad Norm 2.2159(1.8694) | Total Time 0.00(0.00)\n",
      "Iter 18620 | Time 19.7584(20.2561) | Bit/dim 3.5293(3.5065) | Xent 0.0038(0.0043) | Loss 8.7872(9.2015) | Error 0.0011(0.0011) Steps 790(792.15) | Grad Norm 3.4015(1.9752) | Total Time 0.00(0.00)\n",
      "Iter 18630 | Time 22.0925(20.3959) | Bit/dim 3.4900(3.5052) | Xent 0.0084(0.0047) | Loss 8.6629(9.0891) | Error 0.0022(0.0012) Steps 802(793.72) | Grad Norm 3.6979(2.1570) | Total Time 0.00(0.00)\n",
      "Iter 18640 | Time 20.1239(20.3351) | Bit/dim 3.5372(3.5044) | Xent 0.0017(0.0048) | Loss 8.7988(9.0080) | Error 0.0000(0.0012) Steps 784(795.76) | Grad Norm 1.6233(2.1393) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 94.8065, Epoch Time 1228.3711(1214.0052), Bit/dim 3.5408(best: 3.5362), Xent 3.1074, Loss 5.0945, Error 0.3685(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18650 | Time 20.3469(20.3996) | Bit/dim 3.4750(3.5035) | Xent 0.0008(0.0044) | Loss 8.6532(9.7349) | Error 0.0000(0.0012) Steps 820(797.73) | Grad Norm 1.2362(2.0220) | Total Time 0.00(0.00)\n",
      "Iter 18660 | Time 19.8473(20.3778) | Bit/dim 3.5374(3.5056) | Xent 0.0008(0.0044) | Loss 8.7222(9.4749) | Error 0.0000(0.0012) Steps 796(798.87) | Grad Norm 0.8674(1.9424) | Total Time 0.00(0.00)\n",
      "Iter 18670 | Time 20.6057(20.4432) | Bit/dim 3.5026(3.5057) | Xent 0.0008(0.0042) | Loss 8.7449(9.2951) | Error 0.0000(0.0012) Steps 784(798.51) | Grad Norm 1.5464(2.0494) | Total Time 0.00(0.00)\n",
      "Iter 18680 | Time 20.4488(20.4280) | Bit/dim 3.5118(3.5043) | Xent 0.0057(0.0044) | Loss 8.8904(9.1568) | Error 0.0011(0.0012) Steps 796(798.12) | Grad Norm 1.4907(2.0795) | Total Time 0.00(0.00)\n",
      "Iter 18690 | Time 20.0197(20.3766) | Bit/dim 3.4808(3.5037) | Xent 0.0010(0.0046) | Loss 8.5779(9.0519) | Error 0.0000(0.0011) Steps 796(799.97) | Grad Norm 0.6668(1.9361) | Total Time 0.00(0.00)\n",
      "Iter 18700 | Time 20.6552(20.4274) | Bit/dim 3.5151(3.5042) | Xent 0.0092(0.0048) | Loss 8.8345(8.9756) | Error 0.0011(0.0011) Steps 814(802.66) | Grad Norm 1.8188(1.9494) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 91.7126, Epoch Time 1234.7446(1214.6274), Bit/dim 3.5357(best: 3.5362), Xent 3.0245, Loss 5.0480, Error 0.3686(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18710 | Time 20.6124(20.5564) | Bit/dim 3.5046(3.5040) | Xent 0.0006(0.0044) | Loss 8.7748(9.6197) | Error 0.0000(0.0011) Steps 832(803.98) | Grad Norm 0.7203(1.9658) | Total Time 0.00(0.00)\n",
      "Iter 18720 | Time 20.8358(20.5656) | Bit/dim 3.4776(3.5034) | Xent 0.0019(0.0039) | Loss 8.7426(9.3902) | Error 0.0011(0.0010) Steps 796(806.48) | Grad Norm 1.0167(1.8221) | Total Time 0.00(0.00)\n",
      "Iter 18730 | Time 20.3415(20.5150) | Bit/dim 3.5161(3.5040) | Xent 0.0076(0.0036) | Loss 8.5748(9.2188) | Error 0.0033(0.0009) Steps 748(801.66) | Grad Norm 3.6510(1.8204) | Total Time 0.00(0.00)\n",
      "Iter 18740 | Time 20.2724(20.4425) | Bit/dim 3.5368(3.5025) | Xent 0.0031(0.0039) | Loss 8.9404(9.0970) | Error 0.0011(0.0010) Steps 814(800.00) | Grad Norm 1.8580(1.7942) | Total Time 0.00(0.00)\n",
      "Iter 18750 | Time 20.0386(20.3881) | Bit/dim 3.4999(3.5037) | Xent 0.0036(0.0046) | Loss 8.6956(9.0072) | Error 0.0011(0.0011) Steps 784(798.65) | Grad Norm 2.6477(1.9287) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 94.6007, Epoch Time 1236.8096(1215.2928), Bit/dim 3.5378(best: 3.5357), Xent 3.0837, Loss 5.0797, Error 0.3685(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18760 | Time 19.8567(20.3478) | Bit/dim 3.5133(3.5064) | Xent 0.0029(0.0049) | Loss 8.7389(9.7434) | Error 0.0011(0.0013) Steps 808(800.19) | Grad Norm 2.2423(2.1434) | Total Time 0.00(0.00)\n",
      "Iter 18770 | Time 20.3075(20.3051) | Bit/dim 3.4760(3.5053) | Xent 0.0030(0.0046) | Loss 8.6722(9.4872) | Error 0.0011(0.0012) Steps 802(800.22) | Grad Norm 1.4137(1.9794) | Total Time 0.00(0.00)\n",
      "Iter 18780 | Time 19.4808(20.3139) | Bit/dim 3.4940(3.5036) | Xent 0.0030(0.0043) | Loss 8.7860(9.2918) | Error 0.0011(0.0011) Steps 796(798.47) | Grad Norm 3.3154(2.1241) | Total Time 0.00(0.00)\n",
      "Iter 18790 | Time 19.3781(20.2817) | Bit/dim 3.5160(3.5046) | Xent 0.0058(0.0043) | Loss 8.8185(9.1536) | Error 0.0011(0.0011) Steps 790(798.94) | Grad Norm 3.6994(2.1322) | Total Time 0.00(0.00)\n",
      "Iter 18800 | Time 20.6818(20.3397) | Bit/dim 3.5143(3.5057) | Xent 0.0022(0.0040) | Loss 8.8190(9.0584) | Error 0.0011(0.0011) Steps 790(797.89) | Grad Norm 1.2317(1.9935) | Total Time 0.00(0.00)\n",
      "Iter 18810 | Time 20.5077(20.3935) | Bit/dim 3.4974(3.5034) | Xent 0.0074(0.0039) | Loss 8.7083(8.9738) | Error 0.0011(0.0010) Steps 808(796.57) | Grad Norm 2.3462(1.8819) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 91.8006, Epoch Time 1226.6233(1215.6328), Bit/dim 3.5385(best: 3.5357), Xent 3.0702, Loss 5.0736, Error 0.3717(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18820 | Time 20.2185(20.4373) | Bit/dim 3.4520(3.5024) | Xent 0.0043(0.0034) | Loss 8.6769(9.5971) | Error 0.0011(0.0009) Steps 790(794.22) | Grad Norm 4.5968(1.8457) | Total Time 0.00(0.00)\n",
      "Iter 18830 | Time 19.8561(20.3214) | Bit/dim 3.5313(3.5050) | Xent 0.0032(0.0032) | Loss 8.8562(9.3774) | Error 0.0011(0.0010) Steps 820(795.39) | Grad Norm 1.5993(1.8634) | Total Time 0.00(0.00)\n",
      "Iter 18840 | Time 20.7597(20.3489) | Bit/dim 3.4788(3.5047) | Xent 0.0011(0.0035) | Loss 8.7013(9.2174) | Error 0.0000(0.0010) Steps 826(799.48) | Grad Norm 1.6438(2.0033) | Total Time 0.00(0.00)\n",
      "Iter 18850 | Time 20.3222(20.3399) | Bit/dim 3.5256(3.5057) | Xent 0.0032(0.0038) | Loss 8.8138(9.0935) | Error 0.0011(0.0011) Steps 802(798.75) | Grad Norm 2.1001(2.1037) | Total Time 0.00(0.00)\n",
      "Iter 18860 | Time 21.2372(20.3809) | Bit/dim 3.4953(3.5046) | Xent 0.0064(0.0040) | Loss 8.5281(8.9890) | Error 0.0033(0.0012) Steps 778(796.80) | Grad Norm 3.7038(2.1523) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 90.4851, Epoch Time 1226.7663(1215.9668), Bit/dim 3.5360(best: 3.5357), Xent 3.0782, Loss 5.0751, Error 0.3677(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18870 | Time 20.6078(20.3358) | Bit/dim 3.5196(3.5032) | Xent 0.0148(0.0038) | Loss 8.7681(9.7289) | Error 0.0022(0.0010) Steps 814(797.28) | Grad Norm 2.5861(1.9300) | Total Time 0.00(0.00)\n",
      "Iter 18880 | Time 21.0706(20.4370) | Bit/dim 3.4753(3.5032) | Xent 0.0007(0.0039) | Loss 8.5843(9.4699) | Error 0.0000(0.0011) Steps 802(796.55) | Grad Norm 0.9490(1.9132) | Total Time 0.00(0.00)\n",
      "Iter 18890 | Time 20.3399(20.4161) | Bit/dim 3.5119(3.5052) | Xent 0.0007(0.0034) | Loss 8.7884(9.2806) | Error 0.0000(0.0010) Steps 820(797.39) | Grad Norm 0.9064(1.7405) | Total Time 0.00(0.00)\n",
      "Iter 18900 | Time 21.1934(20.4294) | Bit/dim 3.4888(3.5032) | Xent 0.0009(0.0035) | Loss 8.6082(9.1416) | Error 0.0000(0.0009) Steps 778(797.63) | Grad Norm 1.3895(1.8743) | Total Time 0.00(0.00)\n",
      "Iter 18910 | Time 20.2804(20.4483) | Bit/dim 3.5058(3.5028) | Xent 0.0022(0.0036) | Loss 8.7626(9.0402) | Error 0.0011(0.0010) Steps 826(800.30) | Grad Norm 1.6711(1.8997) | Total Time 0.00(0.00)\n",
      "Iter 18920 | Time 20.1046(20.3198) | Bit/dim 3.5202(3.5029) | Xent 0.0009(0.0031) | Loss 8.8304(8.9686) | Error 0.0000(0.0009) Steps 820(801.31) | Grad Norm 0.9187(1.7222) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 92.4141, Epoch Time 1229.4531(1216.3714), Bit/dim 3.5352(best: 3.5357), Xent 3.1219, Loss 5.0962, Error 0.3705(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18930 | Time 20.1562(20.3275) | Bit/dim 3.5182(3.5010) | Xent 0.0054(0.0032) | Loss 8.7037(9.5744) | Error 0.0011(0.0009) Steps 802(802.14) | Grad Norm 1.1402(1.7236) | Total Time 0.00(0.00)\n",
      "Iter 18940 | Time 20.7050(20.4290) | Bit/dim 3.4920(3.5023) | Xent 0.0038(0.0034) | Loss 8.7333(9.3648) | Error 0.0022(0.0009) Steps 766(802.43) | Grad Norm 1.7221(1.7115) | Total Time 0.00(0.00)\n",
      "Iter 18950 | Time 19.4282(20.4407) | Bit/dim 3.5294(3.5043) | Xent 0.0027(0.0035) | Loss 8.8348(9.2117) | Error 0.0011(0.0009) Steps 814(802.99) | Grad Norm 1.5539(1.6939) | Total Time 0.00(0.00)\n",
      "Iter 18960 | Time 20.9625(20.4366) | Bit/dim 3.5056(3.5043) | Xent 0.0038(0.0038) | Loss 8.8370(9.0865) | Error 0.0011(0.0010) Steps 814(799.45) | Grad Norm 1.9271(1.8454) | Total Time 0.00(0.00)\n",
      "Iter 18970 | Time 20.8029(20.4500) | Bit/dim 3.5292(3.5036) | Xent 0.0086(0.0036) | Loss 8.8566(8.9899) | Error 0.0011(0.0009) Steps 796(797.98) | Grad Norm 1.1056(1.7760) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 91.7640, Epoch Time 1235.1526(1216.9348), Bit/dim 3.5346(best: 3.5352), Xent 3.1067, Loss 5.0879, Error 0.3704(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18980 | Time 20.9223(20.4423) | Bit/dim 3.4596(3.5018) | Xent 0.0021(0.0037) | Loss 8.7180(9.7088) | Error 0.0011(0.0009) Steps 814(799.01) | Grad Norm 1.9756(1.7366) | Total Time 0.00(0.00)\n",
      "Iter 18990 | Time 19.7337(20.4332) | Bit/dim 3.4664(3.5030) | Xent 0.0008(0.0035) | Loss 8.7325(9.4563) | Error 0.0000(0.0008) Steps 832(799.60) | Grad Norm 0.8418(1.6606) | Total Time 0.00(0.00)\n",
      "Iter 19000 | Time 20.0186(20.3582) | Bit/dim 3.5140(3.5041) | Xent 0.0043(0.0032) | Loss 8.7913(9.2805) | Error 0.0022(0.0009) Steps 826(801.28) | Grad Norm 3.4703(1.6832) | Total Time 0.00(0.00)\n",
      "Iter 19010 | Time 19.7388(20.4191) | Bit/dim 3.5252(3.5054) | Xent 0.0108(0.0033) | Loss 8.7257(9.1393) | Error 0.0011(0.0009) Steps 814(799.93) | Grad Norm 2.4445(1.7305) | Total Time 0.00(0.00)\n",
      "Iter 19020 | Time 19.2859(20.3129) | Bit/dim 3.5128(3.5031) | Xent 0.0108(0.0039) | Loss 8.7755(9.0265) | Error 0.0033(0.0011) Steps 802(799.00) | Grad Norm 3.5580(1.8871) | Total Time 0.00(0.00)\n",
      "Iter 19030 | Time 21.1552(20.3870) | Bit/dim 3.5265(3.5026) | Xent 0.0013(0.0042) | Loss 8.8241(8.9517) | Error 0.0000(0.0011) Steps 784(795.91) | Grad Norm 1.4338(1.9213) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 93.8076, Epoch Time 1230.3979(1217.3387), Bit/dim 3.5365(best: 3.5346), Xent 3.0733, Loss 5.0731, Error 0.3680(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19040 | Time 20.1317(20.3504) | Bit/dim 3.4969(3.5027) | Xent 0.0017(0.0037) | Loss 8.7397(9.5841) | Error 0.0000(0.0009) Steps 814(795.10) | Grad Norm 1.9001(1.9618) | Total Time 0.00(0.00)\n",
      "Iter 19050 | Time 20.5963(20.4049) | Bit/dim 3.5280(3.5032) | Xent 0.0160(0.0041) | Loss 8.7646(9.3657) | Error 0.0022(0.0010) Steps 790(796.24) | Grad Norm 2.7281(2.0358) | Total Time 0.00(0.00)\n",
      "Iter 19060 | Time 21.2873(20.3784) | Bit/dim 3.5109(3.5051) | Xent 0.0031(0.0038) | Loss 8.8183(9.2185) | Error 0.0011(0.0010) Steps 826(800.42) | Grad Norm 2.0842(2.0123) | Total Time 0.00(0.00)\n",
      "Iter 19070 | Time 20.7197(20.3880) | Bit/dim 3.4927(3.5069) | Xent 0.0005(0.0037) | Loss 8.7202(9.0978) | Error 0.0000(0.0010) Steps 808(799.78) | Grad Norm 0.8445(2.1199) | Total Time 0.00(0.00)\n",
      "Iter 19080 | Time 19.9444(20.4209) | Bit/dim 3.5167(3.5051) | Xent 0.0034(0.0033) | Loss 8.7599(9.0045) | Error 0.0011(0.0009) Steps 808(801.44) | Grad Norm 1.9534(2.0004) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 92.5837, Epoch Time 1232.6342(1217.7976), Bit/dim 3.5370(best: 3.5346), Xent 3.1136, Loss 5.0938, Error 0.3710(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19090 | Time 20.3491(20.5075) | Bit/dim 3.4968(3.5046) | Xent 0.0010(0.0031) | Loss 8.8288(9.7282) | Error 0.0000(0.0008) Steps 796(803.45) | Grad Norm 0.7554(1.8926) | Total Time 0.00(0.00)\n",
      "Iter 19100 | Time 20.3695(20.4760) | Bit/dim 3.4982(3.5025) | Xent 0.0015(0.0030) | Loss 8.7542(9.4566) | Error 0.0000(0.0007) Steps 814(803.12) | Grad Norm 0.7740(1.7604) | Total Time 0.00(0.00)\n",
      "Iter 19110 | Time 19.8491(20.4512) | Bit/dim 3.5027(3.5022) | Xent 0.0005(0.0033) | Loss 8.7278(9.2679) | Error 0.0000(0.0008) Steps 802(799.91) | Grad Norm 1.1873(1.8552) | Total Time 0.00(0.00)\n",
      "Iter 19120 | Time 20.3178(20.4121) | Bit/dim 3.4971(3.5021) | Xent 0.0090(0.0035) | Loss 8.7308(9.1311) | Error 0.0033(0.0010) Steps 790(797.41) | Grad Norm 4.2631(2.0764) | Total Time 0.00(0.00)\n",
      "Iter 19130 | Time 19.7166(20.3250) | Bit/dim 3.5208(3.5048) | Xent 0.0125(0.0039) | Loss 8.6705(9.0285) | Error 0.0022(0.0011) Steps 778(798.13) | Grad Norm 3.4850(2.1873) | Total Time 0.00(0.00)\n",
      "Iter 19140 | Time 19.9003(20.3608) | Bit/dim 3.5159(3.5048) | Xent 0.0015(0.0039) | Loss 8.6870(8.9612) | Error 0.0000(0.0010) Steps 796(797.14) | Grad Norm 0.9112(2.0025) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 91.5951, Epoch Time 1229.7686(1218.1567), Bit/dim 3.5328(best: 3.5346), Xent 3.1252, Loss 5.0954, Error 0.3677(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19150 | Time 20.8470(20.3686) | Bit/dim 3.5017(3.5017) | Xent 0.0027(0.0036) | Loss 8.7370(9.5575) | Error 0.0000(0.0009) Steps 832(799.87) | Grad Norm 2.0898(1.9318) | Total Time 0.00(0.00)\n",
      "Iter 19160 | Time 20.0528(20.4229) | Bit/dim 3.5100(3.5019) | Xent 0.0005(0.0040) | Loss 8.7395(9.3526) | Error 0.0000(0.0011) Steps 796(800.24) | Grad Norm 1.9045(2.2355) | Total Time 0.00(0.00)\n",
      "Iter 19170 | Time 21.0861(20.2986) | Bit/dim 3.4845(3.5045) | Xent 0.0037(0.0050) | Loss 8.6102(9.1987) | Error 0.0033(0.0013) Steps 820(799.97) | Grad Norm 2.4495(2.3829) | Total Time 0.00(0.00)\n",
      "Iter 19180 | Time 20.1216(20.4178) | Bit/dim 3.5051(3.5076) | Xent 0.0024(0.0050) | Loss 8.7537(9.0884) | Error 0.0011(0.0013) Steps 820(799.64) | Grad Norm 1.7307(2.2961) | Total Time 0.00(0.00)\n",
      "Iter 19190 | Time 20.2032(20.4308) | Bit/dim 3.5160(3.5069) | Xent 0.0012(0.0049) | Loss 8.7230(9.0049) | Error 0.0000(0.0012) Steps 766(799.33) | Grad Norm 1.0184(2.3118) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 93.3366, Epoch Time 1232.4192(1218.5846), Bit/dim 3.5353(best: 3.5328), Xent 3.1116, Loss 5.0911, Error 0.3720(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19200 | Time 20.5986(20.4177) | Bit/dim 3.5090(3.5048) | Xent 0.0006(0.0045) | Loss 8.7597(9.7121) | Error 0.0000(0.0012) Steps 802(799.06) | Grad Norm 0.7717(2.2022) | Total Time 0.00(0.00)\n",
      "Iter 19210 | Time 19.2393(20.4139) | Bit/dim 3.4748(3.5040) | Xent 0.0034(0.0050) | Loss 8.8091(9.4584) | Error 0.0022(0.0013) Steps 790(802.11) | Grad Norm 2.0305(2.4611) | Total Time 0.00(0.00)\n",
      "Iter 19220 | Time 19.9122(20.4757) | Bit/dim 3.5010(3.5065) | Xent 0.0124(0.0057) | Loss 8.7323(9.2886) | Error 0.0022(0.0015) Steps 784(801.69) | Grad Norm 3.1861(2.6428) | Total Time 0.00(0.00)\n",
      "Iter 19230 | Time 20.1954(20.4083) | Bit/dim 3.4894(3.5038) | Xent 0.0099(0.0054) | Loss 8.7168(9.1447) | Error 0.0011(0.0013) Steps 784(802.40) | Grad Norm 1.5621(2.4035) | Total Time 0.00(0.00)\n",
      "Iter 19240 | Time 20.6451(20.4483) | Bit/dim 3.4820(3.5041) | Xent 0.0116(0.0054) | Loss 8.6967(9.0388) | Error 0.0033(0.0013) Steps 790(800.09) | Grad Norm 2.8395(2.4979) | Total Time 0.00(0.00)\n",
      "Iter 19250 | Time 20.9166(20.3479) | Bit/dim 3.5269(3.5060) | Xent 0.0098(0.0048) | Loss 8.8260(8.9674) | Error 0.0022(0.0011) Steps 766(799.99) | Grad Norm 2.6178(2.2324) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 92.1964, Epoch Time 1231.2853(1218.9656), Bit/dim 3.5344(best: 3.5328), Xent 3.1095, Loss 5.0891, Error 0.3743(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19260 | Time 20.6256(20.3267) | Bit/dim 3.5128(3.5030) | Xent 0.0011(0.0050) | Loss 8.6935(9.5707) | Error 0.0000(0.0012) Steps 808(801.21) | Grad Norm 1.2152(2.3132) | Total Time 0.00(0.00)\n",
      "Iter 19270 | Time 20.2402(20.2668) | Bit/dim 3.4946(3.5043) | Xent 0.0012(0.0043) | Loss 8.6704(9.3488) | Error 0.0000(0.0011) Steps 790(799.18) | Grad Norm 1.4349(2.1732) | Total Time 0.00(0.00)\n",
      "Iter 19280 | Time 21.4710(20.2856) | Bit/dim 3.5239(3.5060) | Xent 0.0022(0.0039) | Loss 8.8551(9.1975) | Error 0.0011(0.0010) Steps 832(798.93) | Grad Norm 1.3619(1.9209) | Total Time 0.00(0.00)\n",
      "Iter 19290 | Time 21.2193(20.2903) | Bit/dim 3.5020(3.5050) | Xent 0.0095(0.0040) | Loss 8.8215(9.0759) | Error 0.0022(0.0009) Steps 820(801.69) | Grad Norm 2.8448(1.8667) | Total Time 0.00(0.00)\n",
      "Iter 19300 | Time 20.5179(20.2751) | Bit/dim 3.4970(3.5026) | Xent 0.0016(0.0038) | Loss 8.7349(8.9898) | Error 0.0000(0.0009) Steps 796(801.77) | Grad Norm 0.9028(1.7226) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 96.6113, Epoch Time 1228.5442(1219.2529), Bit/dim 3.5330(best: 3.5328), Xent 3.1060, Loss 5.0860, Error 0.3729(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19310 | Time 19.9067(20.2603) | Bit/dim 3.4711(3.5001) | Xent 0.0075(0.0041) | Loss 8.6607(9.7047) | Error 0.0022(0.0011) Steps 778(800.53) | Grad Norm 2.4727(1.8634) | Total Time 0.00(0.00)\n",
      "Iter 19320 | Time 20.7657(20.1728) | Bit/dim 3.5041(3.5018) | Xent 0.0015(0.0038) | Loss 8.7384(9.4523) | Error 0.0011(0.0010) Steps 808(797.86) | Grad Norm 1.8614(1.7950) | Total Time 0.00(0.00)\n",
      "Iter 19330 | Time 20.2184(20.2247) | Bit/dim 3.4901(3.5024) | Xent 0.0011(0.0038) | Loss 8.8472(9.2683) | Error 0.0000(0.0011) Steps 796(796.17) | Grad Norm 1.5398(1.9202) | Total Time 0.00(0.00)\n",
      "Iter 19340 | Time 19.1609(20.2202) | Bit/dim 3.5151(3.5035) | Xent 0.0006(0.0036) | Loss 8.8876(9.1427) | Error 0.0000(0.0010) Steps 802(797.45) | Grad Norm 0.7452(1.8623) | Total Time 0.00(0.00)\n",
      "Iter 19350 | Time 21.0106(20.3478) | Bit/dim 3.5363(3.5037) | Xent 0.0007(0.0036) | Loss 8.8109(9.0302) | Error 0.0000(0.0010) Steps 820(799.43) | Grad Norm 0.9759(1.7848) | Total Time 0.00(0.00)\n",
      "Iter 19360 | Time 20.5362(20.4050) | Bit/dim 3.4892(3.5028) | Xent 0.0008(0.0032) | Loss 8.7234(8.9528) | Error 0.0000(0.0010) Steps 772(797.84) | Grad Norm 0.7321(1.6787) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 90.9663, Epoch Time 1225.4118(1219.4377), Bit/dim 3.5366(best: 3.5328), Xent 3.1239, Loss 5.0986, Error 0.3742(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19370 | Time 20.3753(20.5465) | Bit/dim 3.4722(3.5002) | Xent 0.0026(0.0031) | Loss 8.7126(9.5729) | Error 0.0011(0.0009) Steps 784(797.94) | Grad Norm 1.4743(1.5829) | Total Time 0.00(0.00)\n",
      "Iter 19380 | Time 20.0819(20.4580) | Bit/dim 3.5096(3.4995) | Xent 0.0108(0.0034) | Loss 8.7855(9.3483) | Error 0.0022(0.0009) Steps 796(800.28) | Grad Norm 5.1186(1.6387) | Total Time 0.00(0.00)\n",
      "Iter 19390 | Time 21.0113(20.4697) | Bit/dim 3.4739(3.4973) | Xent 0.0050(0.0032) | Loss 8.5615(9.1809) | Error 0.0022(0.0010) Steps 790(797.67) | Grad Norm 2.6010(1.6595) | Total Time 0.00(0.00)\n",
      "Iter 19400 | Time 19.4047(20.3973) | Bit/dim 3.4995(3.4997) | Xent 0.0014(0.0034) | Loss 8.6582(9.0625) | Error 0.0000(0.0010) Steps 778(796.55) | Grad Norm 0.9939(1.7597) | Total Time 0.00(0.00)\n",
      "Iter 19410 | Time 20.0505(20.3058) | Bit/dim 3.5063(3.5005) | Xent 0.0024(0.0034) | Loss 8.7930(8.9728) | Error 0.0000(0.0010) Steps 814(797.08) | Grad Norm 1.4302(1.6379) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 89.7878, Epoch Time 1227.0730(1219.6668), Bit/dim 3.5354(best: 3.5328), Xent 3.1424, Loss 5.1066, Error 0.3736(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19420 | Time 20.1780(20.2872) | Bit/dim 3.5113(3.5047) | Xent 0.0012(0.0034) | Loss 8.7203(9.7007) | Error 0.0000(0.0009) Steps 790(797.11) | Grad Norm 0.6690(1.6024) | Total Time 0.00(0.00)\n",
      "Iter 19430 | Time 20.9611(20.4246) | Bit/dim 3.5083(3.5050) | Xent 0.0023(0.0033) | Loss 8.7830(9.4578) | Error 0.0011(0.0009) Steps 826(799.84) | Grad Norm 1.4199(1.6200) | Total Time 0.00(0.00)\n",
      "Iter 19440 | Time 19.9830(20.4597) | Bit/dim 3.5354(3.5052) | Xent 0.0011(0.0036) | Loss 8.7136(9.2736) | Error 0.0000(0.0009) Steps 814(801.30) | Grad Norm 0.7048(1.5687) | Total Time 0.00(0.00)\n",
      "Iter 19450 | Time 20.2365(20.4389) | Bit/dim 3.5250(3.5033) | Xent 0.0066(0.0034) | Loss 8.7295(9.1324) | Error 0.0011(0.0008) Steps 808(802.96) | Grad Norm 1.5342(1.5754) | Total Time 0.00(0.00)\n",
      "Iter 19460 | Time 19.2540(20.3918) | Bit/dim 3.5194(3.5041) | Xent 0.0009(0.0029) | Loss 8.7055(9.0265) | Error 0.0000(0.0008) Steps 790(801.31) | Grad Norm 0.7250(1.5170) | Total Time 0.00(0.00)\n",
      "Iter 19470 | Time 20.3246(20.3570) | Bit/dim 3.5029(3.5026) | Xent 0.0035(0.0034) | Loss 8.8103(8.9547) | Error 0.0011(0.0009) Steps 796(802.18) | Grad Norm 1.5006(1.4989) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 92.6030, Epoch Time 1232.6172(1220.0553), Bit/dim 3.5338(best: 3.5328), Xent 3.0928, Loss 5.0802, Error 0.3697(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19480 | Time 21.0346(20.3416) | Bit/dim 3.5317(3.4993) | Xent 0.0005(0.0034) | Loss 8.6963(9.5594) | Error 0.0000(0.0010) Steps 772(799.65) | Grad Norm 0.8045(1.5772) | Total Time 0.00(0.00)\n",
      "Iter 19490 | Time 20.4646(20.2739) | Bit/dim 3.5161(3.4995) | Xent 0.0027(0.0033) | Loss 8.8157(9.3378) | Error 0.0011(0.0009) Steps 808(799.46) | Grad Norm 1.6468(1.6116) | Total Time 0.00(0.00)\n",
      "Iter 19500 | Time 21.1416(20.3868) | Bit/dim 3.5169(3.5001) | Xent 0.0109(0.0034) | Loss 8.8262(9.1755) | Error 0.0022(0.0010) Steps 766(796.77) | Grad Norm 2.7291(1.6483) | Total Time 0.00(0.00)\n",
      "Iter 19510 | Time 19.4938(20.4263) | Bit/dim 3.4882(3.5014) | Xent 0.0006(0.0030) | Loss 8.6843(9.0654) | Error 0.0000(0.0008) Steps 796(796.27) | Grad Norm 1.0010(1.5758) | Total Time 0.00(0.00)\n",
      "Iter 19520 | Time 20.4901(20.5015) | Bit/dim 3.4963(3.5015) | Xent 0.0014(0.0029) | Loss 8.6604(8.9809) | Error 0.0000(0.0008) Steps 790(798.07) | Grad Norm 0.7621(1.5443) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 89.0497, Epoch Time 1232.2961(1220.4225), Bit/dim 3.5339(best: 3.5328), Xent 3.1581, Loss 5.1130, Error 0.3728(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19530 | Time 20.8163(20.4818) | Bit/dim 3.5312(3.5012) | Xent 0.0091(0.0034) | Loss 8.8250(9.6868) | Error 0.0022(0.0008) Steps 808(796.40) | Grad Norm 3.2339(1.6405) | Total Time 0.00(0.00)\n",
      "Iter 19540 | Time 20.4093(20.4946) | Bit/dim 3.5117(3.5007) | Xent 0.0014(0.0031) | Loss 8.8341(9.4339) | Error 0.0000(0.0007) Steps 820(796.11) | Grad Norm 1.6733(1.5782) | Total Time 0.00(0.00)\n",
      "Iter 19550 | Time 20.2701(20.4255) | Bit/dim 3.4968(3.4995) | Xent 0.0047(0.0029) | Loss 8.7029(9.2435) | Error 0.0011(0.0006) Steps 802(797.92) | Grad Norm 1.9143(1.4716) | Total Time 0.00(0.00)\n",
      "Iter 19560 | Time 20.9119(20.4041) | Bit/dim 3.5192(3.4992) | Xent 0.0009(0.0032) | Loss 8.6913(9.1067) | Error 0.0000(0.0007) Steps 754(796.89) | Grad Norm 1.1884(1.5875) | Total Time 0.00(0.00)\n",
      "Iter 19570 | Time 21.0565(20.3989) | Bit/dim 3.5168(3.5019) | Xent 0.0010(0.0030) | Loss 8.7649(8.9980) | Error 0.0000(0.0006) Steps 832(796.95) | Grad Norm 1.0787(1.5676) | Total Time 0.00(0.00)\n",
      "Iter 19580 | Time 21.2703(20.4371) | Bit/dim 3.5322(3.5029) | Xent 0.0047(0.0031) | Loss 8.7827(8.9300) | Error 0.0011(0.0007) Steps 784(794.67) | Grad Norm 1.2657(1.6045) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 93.5129, Epoch Time 1231.6123(1220.7582), Bit/dim 3.5337(best: 3.5328), Xent 3.1831, Loss 5.1253, Error 0.3770(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19590 | Time 19.3822(20.3609) | Bit/dim 3.5231(3.5051) | Xent 0.0091(0.0040) | Loss 8.7558(9.5337) | Error 0.0022(0.0009) Steps 796(798.58) | Grad Norm 2.1153(1.7370) | Total Time 0.00(0.00)\n",
      "Iter 19600 | Time 20.3700(20.3606) | Bit/dim 3.5136(3.5051) | Xent 0.0068(0.0043) | Loss 8.8390(9.3320) | Error 0.0022(0.0011) Steps 814(799.34) | Grad Norm 2.2889(1.9709) | Total Time 0.00(0.00)\n",
      "Iter 19610 | Time 19.9484(20.3556) | Bit/dim 3.4933(3.5050) | Xent 0.0011(0.0040) | Loss 8.6849(9.1784) | Error 0.0000(0.0009) Steps 778(799.34) | Grad Norm 0.9142(1.8557) | Total Time 0.00(0.00)\n",
      "Iter 19620 | Time 21.3101(20.4369) | Bit/dim 3.4998(3.5031) | Xent 0.0088(0.0039) | Loss 8.7365(9.0591) | Error 0.0011(0.0009) Steps 826(798.46) | Grad Norm 1.3996(1.8263) | Total Time 0.00(0.00)\n",
      "Iter 19630 | Time 19.6790(20.4844) | Bit/dim 3.5028(3.5011) | Xent 0.0039(0.0035) | Loss 8.7842(8.9761) | Error 0.0022(0.0009) Steps 796(798.95) | Grad Norm 2.0859(1.7536) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 91.3382, Epoch Time 1233.8872(1221.1521), Bit/dim 3.5340(best: 3.5328), Xent 3.1967, Loss 5.1324, Error 0.3707(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19640 | Time 21.1789(20.5739) | Bit/dim 3.4722(3.5030) | Xent 0.0012(0.0039) | Loss 8.6874(9.6977) | Error 0.0000(0.0010) Steps 796(798.82) | Grad Norm 1.3794(1.8841) | Total Time 0.00(0.00)\n",
      "Iter 19650 | Time 20.3361(20.5418) | Bit/dim 3.4940(3.5010) | Xent 0.0004(0.0039) | Loss 8.5867(9.4378) | Error 0.0000(0.0009) Steps 784(799.18) | Grad Norm 1.1309(1.8588) | Total Time 0.00(0.00)\n",
      "Iter 19660 | Time 20.4527(20.4520) | Bit/dim 3.5067(3.5010) | Xent 0.0026(0.0043) | Loss 8.6907(9.2630) | Error 0.0011(0.0011) Steps 790(800.27) | Grad Norm 1.9738(1.9943) | Total Time 0.00(0.00)\n",
      "Iter 19670 | Time 20.3215(20.5091) | Bit/dim 3.4904(3.5017) | Xent 0.0091(0.0047) | Loss 8.7046(9.1215) | Error 0.0011(0.0011) Steps 760(800.98) | Grad Norm 3.1342(2.0755) | Total Time 0.00(0.00)\n",
      "Iter 19680 | Time 19.9039(20.5045) | Bit/dim 3.5144(3.5020) | Xent 0.0014(0.0049) | Loss 8.6818(9.0245) | Error 0.0000(0.0012) Steps 796(801.79) | Grad Norm 1.5691(2.1107) | Total Time 0.00(0.00)\n",
      "Iter 19690 | Time 20.0889(20.4398) | Bit/dim 3.5299(3.5017) | Xent 0.0045(0.0049) | Loss 8.7108(8.9506) | Error 0.0022(0.0012) Steps 784(800.32) | Grad Norm 3.2069(2.2096) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 94.4769, Epoch Time 1236.3394(1221.6077), Bit/dim 3.5367(best: 3.5328), Xent 3.1486, Loss 5.1110, Error 0.3731(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19700 | Time 19.3912(20.4196) | Bit/dim 3.4844(3.5006) | Xent 0.0038(0.0048) | Loss 8.6415(9.5807) | Error 0.0011(0.0011) Steps 790(801.57) | Grad Norm 3.0801(2.2517) | Total Time 0.00(0.00)\n",
      "Iter 19710 | Time 20.6356(20.4437) | Bit/dim 3.5334(3.5000) | Xent 0.0145(0.0052) | Loss 8.7548(9.3549) | Error 0.0022(0.0012) Steps 778(798.48) | Grad Norm 1.9704(2.1858) | Total Time 0.00(0.00)\n",
      "Iter 19720 | Time 20.3138(20.4008) | Bit/dim 3.4845(3.5021) | Xent 0.0012(0.0047) | Loss 8.7587(9.1972) | Error 0.0000(0.0011) Steps 814(799.77) | Grad Norm 0.9099(1.9550) | Total Time 0.00(0.00)\n",
      "Iter 19730 | Time 21.5503(20.4884) | Bit/dim 3.4906(3.5004) | Xent 0.0043(0.0046) | Loss 8.7109(9.0802) | Error 0.0033(0.0012) Steps 826(801.60) | Grad Norm 2.1100(1.8627) | Total Time 0.00(0.00)\n",
      "Iter 19740 | Time 20.0897(20.4808) | Bit/dim 3.5107(3.5040) | Xent 0.0039(0.0039) | Loss 8.7242(8.9879) | Error 0.0011(0.0010) Steps 826(800.67) | Grad Norm 1.3942(1.6424) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 91.3938, Epoch Time 1232.9466(1221.9479), Bit/dim 3.5339(best: 3.5328), Xent 3.1543, Loss 5.1110, Error 0.3673(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19750 | Time 20.0828(20.4478) | Bit/dim 3.4828(3.5060) | Xent 0.0014(0.0034) | Loss 8.6951(9.7012) | Error 0.0000(0.0008) Steps 796(798.90) | Grad Norm 1.3168(1.4696) | Total Time 0.00(0.00)\n",
      "Iter 19760 | Time 21.2407(20.4551) | Bit/dim 3.5153(3.5026) | Xent 0.0076(0.0039) | Loss 8.7668(9.4461) | Error 0.0022(0.0010) Steps 820(801.23) | Grad Norm 2.8555(1.6332) | Total Time 0.00(0.00)\n",
      "Iter 19770 | Time 20.1567(20.4541) | Bit/dim 3.4991(3.5026) | Xent 0.0056(0.0042) | Loss 8.8152(9.2706) | Error 0.0011(0.0010) Steps 820(801.81) | Grad Norm 2.1669(1.6419) | Total Time 0.00(0.00)\n",
      "Iter 19780 | Time 19.9188(20.4383) | Bit/dim 3.5135(3.5033) | Xent 0.0012(0.0037) | Loss 8.6460(9.1307) | Error 0.0000(0.0009) Steps 808(800.56) | Grad Norm 1.5333(1.6239) | Total Time 0.00(0.00)\n",
      "Iter 19790 | Time 20.3457(20.3619) | Bit/dim 3.4696(3.5001) | Xent 0.0006(0.0036) | Loss 8.6751(9.0226) | Error 0.0000(0.0009) Steps 784(800.07) | Grad Norm 0.8310(1.6570) | Total Time 0.00(0.00)\n",
      "Iter 19800 | Time 20.6027(20.4458) | Bit/dim 3.5031(3.4994) | Xent 0.0012(0.0044) | Loss 8.7448(8.9574) | Error 0.0000(0.0010) Steps 802(799.70) | Grad Norm 1.0349(1.7420) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 91.4619, Epoch Time 1232.5253(1222.2652), Bit/dim 3.5376(best: 3.5328), Xent 3.1200, Loss 5.0976, Error 0.3663(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19810 | Time 20.5135(20.4093) | Bit/dim 3.4858(3.5006) | Xent 0.0026(0.0047) | Loss 8.6893(9.5609) | Error 0.0011(0.0011) Steps 778(800.16) | Grad Norm 2.2005(1.8681) | Total Time 0.00(0.00)\n",
      "Iter 19820 | Time 20.6109(20.4511) | Bit/dim 3.5074(3.5015) | Xent 0.0011(0.0041) | Loss 8.7270(9.3544) | Error 0.0000(0.0010) Steps 814(798.01) | Grad Norm 2.0328(1.9522) | Total Time 0.00(0.00)\n",
      "Iter 19830 | Time 19.7296(20.3737) | Bit/dim 3.4477(3.5005) | Xent 0.0012(0.0037) | Loss 8.6692(9.1897) | Error 0.0000(0.0010) Steps 808(799.80) | Grad Norm 1.1578(1.9486) | Total Time 0.00(0.00)\n",
      "Iter 19840 | Time 20.5346(20.4570) | Bit/dim 3.4566(3.5029) | Xent 0.0013(0.0032) | Loss 8.6884(9.0798) | Error 0.0000(0.0008) Steps 814(804.13) | Grad Norm 1.0343(1.6911) | Total Time 0.00(0.00)\n",
      "Iter 19850 | Time 20.9621(20.4994) | Bit/dim 3.4736(3.4996) | Xent 0.0013(0.0031) | Loss 8.6884(8.9852) | Error 0.0000(0.0008) Steps 820(802.36) | Grad Norm 0.8130(1.6129) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 92.9945, Epoch Time 1234.3178(1222.6268), Bit/dim 3.5365(best: 3.5328), Xent 3.1755, Loss 5.1242, Error 0.3736(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19860 | Time 21.3019(20.5192) | Bit/dim 3.5177(3.4985) | Xent 0.0008(0.0033) | Loss 8.8633(9.7038) | Error 0.0000(0.0009) Steps 820(804.68) | Grad Norm 0.8692(1.6618) | Total Time 0.00(0.00)\n",
      "Iter 19870 | Time 19.9523(20.5367) | Bit/dim 3.4829(3.4959) | Xent 0.0147(0.0039) | Loss 8.7287(9.4483) | Error 0.0033(0.0010) Steps 814(804.45) | Grad Norm 1.9848(1.7292) | Total Time 0.00(0.00)\n",
      "Iter 19880 | Time 20.8483(20.5030) | Bit/dim 3.5105(3.5002) | Xent 0.0014(0.0043) | Loss 8.6026(9.2677) | Error 0.0000(0.0010) Steps 790(803.43) | Grad Norm 1.1768(1.8585) | Total Time 0.00(0.00)\n",
      "Iter 19890 | Time 20.2439(20.4488) | Bit/dim 3.4968(3.4972) | Xent 0.0052(0.0043) | Loss 8.6551(9.1053) | Error 0.0011(0.0010) Steps 790(799.59) | Grad Norm 3.2614(1.9659) | Total Time 0.00(0.00)\n",
      "Iter 19900 | Time 20.0364(20.3589) | Bit/dim 3.5374(3.5024) | Xent 0.0008(0.0038) | Loss 8.7889(9.0213) | Error 0.0000(0.0010) Steps 784(798.23) | Grad Norm 0.6682(1.9204) | Total Time 0.00(0.00)\n",
      "Iter 19910 | Time 22.3151(20.5547) | Bit/dim 3.4934(3.5009) | Xent 0.0051(0.0035) | Loss 8.7810(8.9537) | Error 0.0022(0.0009) Steps 874(799.33) | Grad Norm 3.6563(1.9097) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 89.9739, Epoch Time 1236.6227(1223.0466), Bit/dim 3.5354(best: 3.5328), Xent 3.1469, Loss 5.1088, Error 0.3674(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19920 | Time 20.9327(20.4943) | Bit/dim 3.5091(3.4991) | Xent 0.0128(0.0039) | Loss 8.7290(9.5814) | Error 0.0033(0.0011) Steps 790(797.13) | Grad Norm 3.2726(1.9882) | Total Time 0.00(0.00)\n",
      "Iter 19930 | Time 20.5540(20.5414) | Bit/dim 3.4884(3.5006) | Xent 0.0033(0.0039) | Loss 8.7712(9.3653) | Error 0.0011(0.0011) Steps 760(795.62) | Grad Norm 2.5420(2.0824) | Total Time 0.00(0.00)\n",
      "Iter 19940 | Time 20.6529(20.4413) | Bit/dim 3.5142(3.5023) | Xent 0.0116(0.0042) | Loss 8.7882(9.2076) | Error 0.0011(0.0011) Steps 784(793.81) | Grad Norm 1.7962(2.0566) | Total Time 0.00(0.00)\n",
      "Iter 19950 | Time 19.5787(20.4667) | Bit/dim 3.4870(3.5023) | Xent 0.0032(0.0038) | Loss 8.5752(9.0878) | Error 0.0022(0.0011) Steps 778(796.79) | Grad Norm 2.7771(2.0579) | Total Time 0.00(0.00)\n",
      "Iter 19960 | Time 20.2447(20.4734) | Bit/dim 3.5214(3.5041) | Xent 0.0036(0.0036) | Loss 8.7135(8.9966) | Error 0.0011(0.0010) Steps 772(797.66) | Grad Norm 3.5374(2.0087) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 92.4320, Epoch Time 1232.1584(1223.3200), Bit/dim 3.5329(best: 3.5328), Xent 3.1353, Loss 5.1005, Error 0.3679(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19970 | Time 20.5319(20.4451) | Bit/dim 3.4918(3.5026) | Xent 0.0021(0.0034) | Loss 8.7132(9.7173) | Error 0.0000(0.0009) Steps 796(798.54) | Grad Norm 1.1204(2.0167) | Total Time 0.00(0.00)\n",
      "Iter 19980 | Time 20.0542(20.4135) | Bit/dim 3.4496(3.5011) | Xent 0.0090(0.0036) | Loss 8.6123(9.4541) | Error 0.0011(0.0010) Steps 814(798.58) | Grad Norm 2.1587(2.0625) | Total Time 0.00(0.00)\n",
      "Iter 19990 | Time 20.9370(20.4564) | Bit/dim 3.5260(3.5014) | Xent 0.0007(0.0034) | Loss 8.7906(9.2698) | Error 0.0000(0.0009) Steps 802(798.81) | Grad Norm 0.8625(1.9394) | Total Time 0.00(0.00)\n",
      "Iter 20000 | Time 20.6298(20.5195) | Bit/dim 3.5042(3.5001) | Xent 0.0067(0.0033) | Loss 8.7672(9.1325) | Error 0.0033(0.0009) Steps 772(800.78) | Grad Norm 2.8024(1.8985) | Total Time 0.00(0.00)\n",
      "Iter 20010 | Time 20.7112(20.4637) | Bit/dim 3.4999(3.5001) | Xent 0.0009(0.0029) | Loss 8.7759(9.0389) | Error 0.0000(0.0007) Steps 796(801.66) | Grad Norm 0.7147(1.6456) | Total Time 0.00(0.00)\n",
      "Iter 20020 | Time 20.1791(20.4577) | Bit/dim 3.5312(3.5013) | Xent 0.0021(0.0038) | Loss 8.8601(8.9634) | Error 0.0011(0.0010) Steps 796(797.44) | Grad Norm 0.9706(1.7774) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 91.6472, Epoch Time 1235.4099(1223.6827), Bit/dim 3.5335(best: 3.5328), Xent 3.1509, Loss 5.1089, Error 0.3713(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20030 | Time 20.5093(20.3565) | Bit/dim 3.5083(3.5026) | Xent 0.0095(0.0037) | Loss 8.6817(9.5905) | Error 0.0011(0.0009) Steps 778(795.49) | Grad Norm 1.6200(1.7331) | Total Time 0.00(0.00)\n",
      "Iter 20040 | Time 19.0709(20.3899) | Bit/dim 3.4666(3.5009) | Xent 0.0053(0.0039) | Loss 8.5525(9.3602) | Error 0.0011(0.0010) Steps 778(796.34) | Grad Norm 1.6981(1.8865) | Total Time 0.00(0.00)\n",
      "Iter 20050 | Time 20.8933(20.4129) | Bit/dim 3.4658(3.5007) | Xent 0.0059(0.0046) | Loss 8.7216(9.1904) | Error 0.0033(0.0013) Steps 796(796.51) | Grad Norm 3.5908(2.1805) | Total Time 0.00(0.00)\n",
      "Iter 20060 | Time 19.8650(20.4356) | Bit/dim 3.5242(3.5010) | Xent 0.0131(0.0051) | Loss 8.7012(9.0743) | Error 0.0044(0.0015) Steps 772(798.59) | Grad Norm 4.8976(2.4853) | Total Time 0.00(0.00)\n",
      "Iter 20070 | Time 21.1112(20.4123) | Bit/dim 3.4713(3.5017) | Xent 0.0086(0.0048) | Loss 8.7197(8.9948) | Error 0.0011(0.0013) Steps 808(800.37) | Grad Norm 2.3145(2.6991) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 92.8019, Epoch Time 1233.8626(1223.9881), Bit/dim 3.5350(best: 3.5328), Xent 3.2173, Loss 5.1437, Error 0.3766(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20080 | Time 20.3434(20.4695) | Bit/dim 3.5078(3.5011) | Xent 0.0046(0.0052) | Loss 8.7751(9.7527) | Error 0.0011(0.0013) Steps 826(802.99) | Grad Norm 2.7168(2.8239) | Total Time 0.00(0.00)\n",
      "Iter 20090 | Time 20.8524(20.4453) | Bit/dim 3.5117(3.5035) | Xent 0.0011(0.0050) | Loss 8.7006(9.4860) | Error 0.0000(0.0012) Steps 790(803.08) | Grad Norm 1.7009(2.6257) | Total Time 0.00(0.00)\n",
      "Iter 20100 | Time 20.1632(20.4889) | Bit/dim 3.4859(3.5039) | Xent 0.0021(0.0049) | Loss 8.7722(9.2962) | Error 0.0011(0.0014) Steps 808(801.75) | Grad Norm 2.3592(2.5381) | Total Time 0.00(0.00)\n",
      "Iter 20110 | Time 20.9304(20.4150) | Bit/dim 3.5344(3.5028) | Xent 0.0009(0.0051) | Loss 8.8651(9.1433) | Error 0.0000(0.0013) Steps 802(801.88) | Grad Norm 1.2205(2.4380) | Total Time 0.00(0.00)\n",
      "Iter 20120 | Time 19.3659(20.5136) | Bit/dim 3.5029(3.5039) | Xent 0.0025(0.0053) | Loss 8.6661(9.0468) | Error 0.0011(0.0013) Steps 808(805.24) | Grad Norm 2.6696(2.3352) | Total Time 0.00(0.00)\n",
      "Iter 20130 | Time 19.0489(20.3743) | Bit/dim 3.5121(3.5036) | Xent 0.0064(0.0050) | Loss 8.6570(8.9693) | Error 0.0011(0.0012) Steps 784(805.13) | Grad Norm 2.8432(2.3988) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 91.5622, Epoch Time 1229.6945(1224.1593), Bit/dim 3.5317(best: 3.5328), Xent 3.1299, Loss 5.0967, Error 0.3676(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20140 | Time 19.9774(20.4222) | Bit/dim 3.4622(3.5000) | Xent 0.0007(0.0050) | Loss 8.5882(9.5677) | Error 0.0000(0.0011) Steps 790(803.69) | Grad Norm 1.0436(2.2352) | Total Time 0.00(0.00)\n",
      "Iter 20150 | Time 19.5082(20.3745) | Bit/dim 3.5163(3.5011) | Xent 0.0018(0.0047) | Loss 8.7620(9.3487) | Error 0.0000(0.0011) Steps 790(802.90) | Grad Norm 1.3225(2.1638) | Total Time 0.00(0.00)\n",
      "Iter 20160 | Time 20.5232(20.4764) | Bit/dim 3.4938(3.5024) | Xent 0.0017(0.0049) | Loss 8.6996(9.1915) | Error 0.0011(0.0012) Steps 820(801.41) | Grad Norm 1.2543(2.2348) | Total Time 0.00(0.00)\n",
      "Iter 20170 | Time 20.4812(20.4233) | Bit/dim 3.4939(3.5048) | Xent 0.0062(0.0048) | Loss 8.7594(9.0781) | Error 0.0022(0.0012) Steps 826(800.59) | Grad Norm 2.6801(2.2532) | Total Time 0.00(0.00)\n",
      "Iter 20180 | Time 21.6788(20.6197) | Bit/dim 3.5043(3.5019) | Xent 0.0008(0.0049) | Loss 8.8417(8.9960) | Error 0.0000(0.0013) Steps 784(801.65) | Grad Norm 1.9310(2.3901) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 91.2060, Epoch Time 1242.3840(1224.7060), Bit/dim 3.5339(best: 3.5317), Xent 3.1362, Loss 5.1020, Error 0.3678(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20190 | Time 19.6337(20.5698) | Bit/dim 3.4971(3.5007) | Xent 0.0014(0.0051) | Loss 8.6469(9.7170) | Error 0.0000(0.0013) Steps 802(801.32) | Grad Norm 1.6741(2.4941) | Total Time 0.00(0.00)\n",
      "Iter 20200 | Time 20.6301(20.6563) | Bit/dim 3.5113(3.5001) | Xent 0.0138(0.0051) | Loss 8.8086(9.4536) | Error 0.0044(0.0013) Steps 814(799.38) | Grad Norm 6.0014(2.3455) | Total Time 0.00(0.00)\n",
      "Iter 20210 | Time 20.0278(20.5632) | Bit/dim 3.5452(3.5027) | Xent 0.0075(0.0052) | Loss 8.8949(9.2742) | Error 0.0022(0.0013) Steps 772(798.01) | Grad Norm 3.0776(2.3486) | Total Time 0.00(0.00)\n",
      "Iter 20220 | Time 20.5516(20.5393) | Bit/dim 3.5115(3.5022) | Xent 0.0038(0.0050) | Loss 8.7343(9.1371) | Error 0.0011(0.0013) Steps 808(799.28) | Grad Norm 1.9483(2.3440) | Total Time 0.00(0.00)\n",
      "Iter 20230 | Time 19.8947(20.4972) | Bit/dim 3.4910(3.5009) | Xent 0.0086(0.0046) | Loss 8.6846(9.0337) | Error 0.0033(0.0013) Steps 808(798.25) | Grad Norm 5.2879(2.2335) | Total Time 0.00(0.00)\n",
      "Iter 20240 | Time 21.0563(20.5001) | Bit/dim 3.5057(3.4998) | Xent 0.0062(0.0045) | Loss 8.7420(8.9482) | Error 0.0011(0.0012) Steps 802(797.08) | Grad Norm 1.8066(2.0923) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 93.3857, Epoch Time 1236.5507(1225.0614), Bit/dim 3.5311(best: 3.5317), Xent 3.1586, Loss 5.1104, Error 0.3730(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20250 | Time 21.0709(20.4899) | Bit/dim 3.4532(3.4992) | Xent 0.0006(0.0038) | Loss 8.6689(9.5661) | Error 0.0000(0.0010) Steps 796(796.47) | Grad Norm 0.7179(1.9170) | Total Time 0.00(0.00)\n",
      "Iter 20260 | Time 20.9815(20.5178) | Bit/dim 3.5072(3.5007) | Xent 0.0006(0.0034) | Loss 8.7968(9.3480) | Error 0.0000(0.0008) Steps 820(798.21) | Grad Norm 0.4243(1.6630) | Total Time 0.00(0.00)\n",
      "Iter 20270 | Time 20.5075(20.5654) | Bit/dim 3.4647(3.4989) | Xent 0.0016(0.0032) | Loss 8.6889(9.1894) | Error 0.0000(0.0007) Steps 790(798.16) | Grad Norm 1.5481(1.5909) | Total Time 0.00(0.00)\n",
      "Iter 20280 | Time 21.1829(20.4896) | Bit/dim 3.4991(3.4990) | Xent 0.0057(0.0034) | Loss 8.7582(9.0666) | Error 0.0022(0.0008) Steps 790(799.01) | Grad Norm 2.0418(1.7075) | Total Time 0.00(0.00)\n",
      "Iter 20290 | Time 20.5025(20.5445) | Bit/dim 3.5013(3.5007) | Xent 0.0005(0.0034) | Loss 8.7230(8.9868) | Error 0.0000(0.0009) Steps 784(797.46) | Grad Norm 0.9611(1.8697) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 90.5916, Epoch Time 1236.1059(1225.3927), Bit/dim 3.5344(best: 3.5311), Xent 3.1746, Loss 5.1217, Error 0.3709(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20300 | Time 20.3913(20.5108) | Bit/dim 3.4911(3.4984) | Xent 0.0005(0.0031) | Loss 8.7947(9.7052) | Error 0.0000(0.0007) Steps 754(797.61) | Grad Norm 0.9290(1.6698) | Total Time 0.00(0.00)\n",
      "Iter 20310 | Time 19.8825(20.5237) | Bit/dim 3.5035(3.5009) | Xent 0.0007(0.0031) | Loss 8.7073(9.4611) | Error 0.0000(0.0007) Steps 766(798.64) | Grad Norm 2.0173(1.7613) | Total Time 0.00(0.00)\n",
      "Iter 20320 | Time 20.1993(20.5275) | Bit/dim 3.5029(3.5019) | Xent 0.0030(0.0040) | Loss 8.7032(9.2758) | Error 0.0011(0.0011) Steps 778(799.59) | Grad Norm 2.1563(2.0729) | Total Time 0.00(0.00)\n",
      "Iter 20330 | Time 20.6394(20.5170) | Bit/dim 3.4929(3.5022) | Xent 0.0042(0.0040) | Loss 8.5003(9.1232) | Error 0.0022(0.0010) Steps 784(798.85) | Grad Norm 3.2809(2.0770) | Total Time 0.00(0.00)\n",
      "Iter 20340 | Time 19.8708(20.4238) | Bit/dim 3.4990(3.5027) | Xent 0.0005(0.0036) | Loss 8.7079(9.0271) | Error 0.0000(0.0010) Steps 760(799.34) | Grad Norm 0.9600(1.9278) | Total Time 0.00(0.00)\n",
      "Iter 20350 | Time 20.3744(20.3903) | Bit/dim 3.4772(3.5002) | Xent 0.0126(0.0039) | Loss 8.6658(8.9440) | Error 0.0033(0.0010) Steps 784(797.15) | Grad Norm 2.6499(1.8147) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 92.4990, Epoch Time 1232.9849(1225.6205), Bit/dim 3.5315(best: 3.5311), Xent 3.2088, Loss 5.1359, Error 0.3708(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20360 | Time 19.9129(20.4028) | Bit/dim 3.4738(3.4987) | Xent 0.0113(0.0043) | Loss 8.7226(9.5646) | Error 0.0022(0.0011) Steps 808(799.37) | Grad Norm 3.9074(2.0522) | Total Time 0.00(0.00)\n",
      "Iter 20370 | Time 19.8870(20.4851) | Bit/dim 3.5005(3.4975) | Xent 0.0051(0.0044) | Loss 8.7848(9.3461) | Error 0.0011(0.0011) Steps 784(798.53) | Grad Norm 2.9433(2.1167) | Total Time 0.00(0.00)\n",
      "Iter 20380 | Time 20.0808(20.4487) | Bit/dim 3.5282(3.4987) | Xent 0.0021(0.0040) | Loss 8.7503(9.1827) | Error 0.0011(0.0011) Steps 802(797.45) | Grad Norm 2.6319(2.1699) | Total Time 0.00(0.00)\n",
      "Iter 20390 | Time 20.5934(20.5103) | Bit/dim 3.5003(3.5006) | Xent 0.0021(0.0040) | Loss 8.7892(9.0725) | Error 0.0000(0.0011) Steps 784(798.47) | Grad Norm 1.3221(2.1093) | Total Time 0.00(0.00)\n",
      "Iter 20400 | Time 20.7927(20.4852) | Bit/dim 3.5168(3.5015) | Xent 0.0009(0.0036) | Loss 8.7781(8.9868) | Error 0.0000(0.0010) Steps 838(798.21) | Grad Norm 1.0795(2.0809) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 92.2341, Epoch Time 1236.1649(1225.9368), Bit/dim 3.5334(best: 3.5311), Xent 3.1257, Loss 5.0962, Error 0.3669(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20410 | Time 18.9698(20.4213) | Bit/dim 3.4934(3.5017) | Xent 0.0006(0.0033) | Loss 8.7859(9.7314) | Error 0.0000(0.0009) Steps 802(797.46) | Grad Norm 1.8791(2.1486) | Total Time 0.00(0.00)\n",
      "Iter 20420 | Time 19.6566(20.4071) | Bit/dim 3.4962(3.5020) | Xent 0.0037(0.0031) | Loss 8.6987(9.4723) | Error 0.0011(0.0009) Steps 796(795.70) | Grad Norm 2.9275(2.1488) | Total Time 0.00(0.00)\n",
      "Iter 20430 | Time 20.6344(20.4559) | Bit/dim 3.5013(3.5002) | Xent 0.0008(0.0031) | Loss 8.7509(9.2723) | Error 0.0000(0.0008) Steps 802(796.63) | Grad Norm 0.9761(2.0454) | Total Time 0.00(0.00)\n",
      "Iter 20440 | Time 20.5632(20.5409) | Bit/dim 3.5136(3.4982) | Xent 0.0014(0.0032) | Loss 8.6849(9.1292) | Error 0.0000(0.0009) Steps 820(799.98) | Grad Norm 1.3471(2.1440) | Total Time 0.00(0.00)\n",
      "Iter 20450 | Time 21.4061(20.5180) | Bit/dim 3.5129(3.5006) | Xent 0.0023(0.0031) | Loss 8.7694(9.0277) | Error 0.0011(0.0009) Steps 796(797.19) | Grad Norm 2.4388(2.0786) | Total Time 0.00(0.00)\n",
      "Iter 20460 | Time 19.6975(20.5376) | Bit/dim 3.5287(3.5028) | Xent 0.0009(0.0027) | Loss 8.8244(8.9610) | Error 0.0000(0.0008) Steps 802(799.05) | Grad Norm 1.5396(2.0134) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 91.0926, Epoch Time 1237.2481(1226.2761), Bit/dim 3.5321(best: 3.5311), Xent 3.2753, Loss 5.1697, Error 0.3760(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20470 | Time 21.8150(20.6278) | Bit/dim 3.5063(3.5044) | Xent 0.0041(0.0031) | Loss 8.6767(9.5874) | Error 0.0022(0.0009) Steps 820(800.54) | Grad Norm 4.6572(2.2997) | Total Time 0.00(0.00)\n",
      "Iter 20480 | Time 19.6484(20.5940) | Bit/dim 3.4801(3.5027) | Xent 0.0086(0.0040) | Loss 8.6973(9.3633) | Error 0.0033(0.0011) Steps 778(798.95) | Grad Norm 3.7367(2.2981) | Total Time 0.00(0.00)\n",
      "Iter 20490 | Time 20.9311(20.5852) | Bit/dim 3.4778(3.5009) | Xent 0.0005(0.0037) | Loss 8.7536(9.2023) | Error 0.0000(0.0011) Steps 778(799.15) | Grad Norm 0.9527(2.2862) | Total Time 0.00(0.00)\n",
      "Iter 20500 | Time 20.2187(20.6037) | Bit/dim 3.5007(3.4996) | Xent 0.0009(0.0032) | Loss 8.7235(9.0853) | Error 0.0000(0.0009) Steps 820(801.25) | Grad Norm 0.8615(2.1028) | Total Time 0.00(0.00)\n",
      "Iter 20510 | Time 20.4163(20.5641) | Bit/dim 3.5192(3.4987) | Xent 0.0052(0.0034) | Loss 8.7822(9.0041) | Error 0.0022(0.0011) Steps 784(800.52) | Grad Norm 2.6792(2.1305) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 92.4166, Epoch Time 1240.7760(1226.7111), Bit/dim 3.5309(best: 3.5311), Xent 3.1512, Loss 5.1065, Error 0.3667(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20520 | Time 20.1533(20.4871) | Bit/dim 3.4608(3.4980) | Xent 0.0021(0.0037) | Loss 8.6750(9.7354) | Error 0.0011(0.0012) Steps 814(800.06) | Grad Norm 1.6057(2.1138) | Total Time 0.00(0.00)\n",
      "Iter 20530 | Time 19.7985(20.4170) | Bit/dim 3.4857(3.5006) | Xent 0.0007(0.0038) | Loss 8.7503(9.4811) | Error 0.0000(0.0011) Steps 796(801.38) | Grad Norm 0.9193(2.1870) | Total Time 0.00(0.00)\n",
      "Iter 20540 | Time 20.9676(20.4458) | Bit/dim 3.4577(3.5001) | Xent 0.0045(0.0039) | Loss 8.6457(9.2854) | Error 0.0022(0.0011) Steps 826(801.97) | Grad Norm 3.9096(2.1818) | Total Time 0.00(0.00)\n",
      "Iter 20550 | Time 20.0921(20.5105) | Bit/dim 3.4752(3.5001) | Xent 0.0087(0.0040) | Loss 8.5656(9.1431) | Error 0.0011(0.0012) Steps 814(801.71) | Grad Norm 3.0379(2.1239) | Total Time 0.00(0.00)\n",
      "Iter 20560 | Time 21.2527(20.5455) | Bit/dim 3.5181(3.5026) | Xent 0.0027(0.0040) | Loss 8.7836(9.0353) | Error 0.0011(0.0011) Steps 832(803.90) | Grad Norm 3.1723(2.1247) | Total Time 0.00(0.00)\n",
      "Iter 20570 | Time 20.1376(20.5305) | Bit/dim 3.4553(3.4976) | Xent 0.0009(0.0045) | Loss 8.6648(8.9519) | Error 0.0000(0.0013) Steps 814(803.67) | Grad Norm 1.9584(2.3327) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 90.8762, Epoch Time 1235.5427(1226.9761), Bit/dim 3.5307(best: 3.5309), Xent 3.1419, Loss 5.1017, Error 0.3686(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20580 | Time 21.2079(20.5439) | Bit/dim 3.5103(3.4987) | Xent 0.0191(0.0054) | Loss 8.8318(9.5633) | Error 0.0044(0.0014) Steps 820(803.96) | Grad Norm 4.2079(2.7057) | Total Time 0.00(0.00)\n",
      "Iter 20590 | Time 20.9758(20.6282) | Bit/dim 3.4992(3.4972) | Xent 0.0282(0.0065) | Loss 8.8482(9.3496) | Error 0.0067(0.0017) Steps 796(802.28) | Grad Norm 6.5624(2.9696) | Total Time 0.00(0.00)\n",
      "Iter 20600 | Time 21.4224(20.5981) | Bit/dim 3.5088(3.4966) | Xent 0.0048(0.0056) | Loss 8.8234(9.1983) | Error 0.0011(0.0014) Steps 820(805.23) | Grad Norm 1.9907(2.7057) | Total Time 0.00(0.00)\n",
      "Iter 20610 | Time 19.9315(20.6044) | Bit/dim 3.5049(3.5008) | Xent 0.0009(0.0053) | Loss 8.7363(9.0906) | Error 0.0000(0.0013) Steps 814(803.83) | Grad Norm 0.8839(2.4510) | Total Time 0.00(0.00)\n",
      "Iter 20620 | Time 21.0246(20.4483) | Bit/dim 3.4905(3.5020) | Xent 0.0010(0.0052) | Loss 8.7019(8.9948) | Error 0.0000(0.0013) Steps 796(802.84) | Grad Norm 1.4561(2.5183) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 93.0597, Epoch Time 1240.3297(1227.3767), Bit/dim 3.5333(best: 3.5307), Xent 3.1619, Loss 5.1142, Error 0.3698(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20630 | Time 20.1265(20.5354) | Bit/dim 3.4996(3.5017) | Xent 0.0018(0.0049) | Loss 8.7224(9.7240) | Error 0.0011(0.0011) Steps 802(802.10) | Grad Norm 0.8809(2.4530) | Total Time 0.00(0.00)\n",
      "Iter 20640 | Time 20.7708(20.4453) | Bit/dim 3.4978(3.5000) | Xent 0.0007(0.0044) | Loss 8.7829(9.4688) | Error 0.0000(0.0010) Steps 820(802.68) | Grad Norm 0.7279(2.1981) | Total Time 0.00(0.00)\n",
      "Iter 20650 | Time 20.1640(20.5292) | Bit/dim 3.4645(3.5013) | Xent 0.0021(0.0043) | Loss 8.7032(9.2813) | Error 0.0000(0.0010) Steps 826(804.11) | Grad Norm 1.5596(2.2125) | Total Time 0.00(0.00)\n",
      "Iter 20660 | Time 19.8560(20.4740) | Bit/dim 3.5388(3.5036) | Xent 0.0094(0.0039) | Loss 8.6923(9.1356) | Error 0.0033(0.0010) Steps 784(803.79) | Grad Norm 2.7167(2.1065) | Total Time 0.00(0.00)\n",
      "Iter 20670 | Time 19.8460(20.5493) | Bit/dim 3.4893(3.5027) | Xent 0.0043(0.0037) | Loss 8.6376(9.0297) | Error 0.0011(0.0010) Steps 796(805.51) | Grad Norm 1.8292(1.9684) | Total Time 0.00(0.00)\n",
      "Iter 20680 | Time 20.4372(20.4834) | Bit/dim 3.4872(3.4994) | Xent 0.0011(0.0045) | Loss 8.6825(8.9509) | Error 0.0000(0.0011) Steps 796(801.40) | Grad Norm 1.4118(2.0180) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 91.1930, Epoch Time 1235.1550(1227.6100), Bit/dim 3.5298(best: 3.5307), Xent 3.2387, Loss 5.1492, Error 0.3726(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20690 | Time 20.7663(20.5663) | Bit/dim 3.5066(3.5017) | Xent 0.0018(0.0041) | Loss 8.8331(9.6039) | Error 0.0000(0.0010) Steps 796(801.21) | Grad Norm 1.6514(1.9337) | Total Time 0.00(0.00)\n",
      "Iter 20700 | Time 20.8877(20.4962) | Bit/dim 3.5198(3.5028) | Xent 0.0023(0.0043) | Loss 8.7982(9.3751) | Error 0.0011(0.0010) Steps 778(800.00) | Grad Norm 1.7382(1.8732) | Total Time 0.00(0.00)\n",
      "Iter 20710 | Time 21.2457(20.5289) | Bit/dim 3.4893(3.5017) | Xent 0.0073(0.0042) | Loss 8.7597(9.2027) | Error 0.0022(0.0010) Steps 808(799.99) | Grad Norm 1.7071(1.8372) | Total Time 0.00(0.00)\n",
      "Iter 20720 | Time 20.6511(20.5248) | Bit/dim 3.4839(3.4993) | Xent 0.0131(0.0045) | Loss 8.6762(9.0791) | Error 0.0033(0.0011) Steps 760(797.16) | Grad Norm 3.8757(2.1294) | Total Time 0.00(0.00)\n",
      "Iter 20730 | Time 20.4153(20.4560) | Bit/dim 3.4846(3.5001) | Xent 0.0007(0.0046) | Loss 8.6140(8.9883) | Error 0.0000(0.0011) Steps 772(798.47) | Grad Norm 0.9777(2.1136) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 92.8644, Epoch Time 1238.3988(1227.9337), Bit/dim 3.5364(best: 3.5298), Xent 3.1022, Loss 5.0875, Error 0.3682(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20740 | Time 20.7557(20.5011) | Bit/dim 3.4702(3.5002) | Xent 0.0022(0.0043) | Loss 8.7389(9.6995) | Error 0.0011(0.0011) Steps 778(798.28) | Grad Norm 2.0580(2.3051) | Total Time 0.00(0.00)\n",
      "Iter 20750 | Time 21.4191(20.5460) | Bit/dim 3.4757(3.5011) | Xent 0.0045(0.0048) | Loss 8.6732(9.4500) | Error 0.0022(0.0013) Steps 814(802.35) | Grad Norm 4.6388(2.4270) | Total Time 0.00(0.00)\n",
      "Iter 20760 | Time 20.1095(20.5880) | Bit/dim 3.4983(3.5005) | Xent 0.0006(0.0043) | Loss 8.6885(9.2648) | Error 0.0000(0.0012) Steps 784(799.62) | Grad Norm 1.6766(2.3598) | Total Time 0.00(0.00)\n",
      "Iter 20770 | Time 20.9981(20.5798) | Bit/dim 3.4413(3.4978) | Xent 0.0012(0.0044) | Loss 8.5816(9.1167) | Error 0.0000(0.0013) Steps 832(802.25) | Grad Norm 1.3058(2.3581) | Total Time 0.00(0.00)\n",
      "Iter 20780 | Time 20.7735(20.7724) | Bit/dim 3.4839(3.4980) | Xent 0.0015(0.0049) | Loss 8.6278(9.0119) | Error 0.0011(0.0014) Steps 808(804.77) | Grad Norm 2.1866(2.4637) | Total Time 0.00(0.00)\n",
      "Iter 20790 | Time 20.9225(20.7858) | Bit/dim 3.4938(3.4986) | Xent 0.0007(0.0045) | Loss 8.7090(8.9402) | Error 0.0000(0.0013) Steps 802(804.60) | Grad Norm 1.2131(2.3244) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 90.9563, Epoch Time 1251.2593(1228.6335), Bit/dim 3.5313(best: 3.5298), Xent 3.1648, Loss 5.1136, Error 0.3709(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20800 | Time 20.5621(20.7454) | Bit/dim 3.5083(3.4970) | Xent 0.0032(0.0040) | Loss 8.7838(9.5736) | Error 0.0011(0.0012) Steps 790(803.22) | Grad Norm 3.5544(2.1908) | Total Time 0.00(0.00)\n",
      "Iter 20810 | Time 20.0159(20.6760) | Bit/dim 3.5115(3.4963) | Xent 0.0013(0.0046) | Loss 8.7066(9.3483) | Error 0.0000(0.0011) Steps 790(799.41) | Grad Norm 1.9632(2.3299) | Total Time 0.00(0.00)\n",
      "Iter 20820 | Time 21.6883(20.6444) | Bit/dim 3.5153(3.4995) | Xent 0.0014(0.0040) | Loss 8.8605(9.1857) | Error 0.0000(0.0010) Steps 814(798.19) | Grad Norm 4.1956(2.2597) | Total Time 0.00(0.00)\n",
      "Iter 20830 | Time 20.0872(20.6316) | Bit/dim 3.4991(3.5008) | Xent 0.0011(0.0038) | Loss 8.7533(9.0686) | Error 0.0000(0.0009) Steps 790(797.99) | Grad Norm 1.2253(2.0795) | Total Time 0.00(0.00)\n",
      "Iter 20840 | Time 20.5038(20.6680) | Bit/dim 3.5138(3.5008) | Xent 0.0014(0.0038) | Loss 8.7504(8.9836) | Error 0.0011(0.0010) Steps 820(798.31) | Grad Norm 1.9906(2.1156) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 89.6610, Epoch Time 1241.5464(1229.0209), Bit/dim 3.5317(best: 3.5298), Xent 3.2557, Loss 5.1595, Error 0.3771(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20850 | Time 21.0223(20.6943) | Bit/dim 3.4638(3.4978) | Xent 0.0096(0.0042) | Loss 8.6628(9.6885) | Error 0.0044(0.0012) Steps 784(799.19) | Grad Norm 4.4028(2.2454) | Total Time 0.00(0.00)\n",
      "Iter 20860 | Time 21.0392(20.6857) | Bit/dim 3.5027(3.4996) | Xent 0.0019(0.0047) | Loss 8.7313(9.4388) | Error 0.0000(0.0012) Steps 838(800.37) | Grad Norm 1.8613(2.3139) | Total Time 0.00(0.00)\n",
      "Iter 20870 | Time 21.2343(20.7053) | Bit/dim 3.5062(3.4999) | Xent 0.0071(0.0045) | Loss 8.8002(9.2666) | Error 0.0022(0.0012) Steps 796(803.54) | Grad Norm 3.1605(2.2787) | Total Time 0.00(0.00)\n",
      "Iter 20880 | Time 20.7658(20.8168) | Bit/dim 3.5202(3.5000) | Xent 0.0009(0.0042) | Loss 8.8146(9.1211) | Error 0.0000(0.0010) Steps 790(802.95) | Grad Norm 1.1808(2.1099) | Total Time 0.00(0.00)\n",
      "Iter 20890 | Time 20.3739(20.7819) | Bit/dim 3.5135(3.4990) | Xent 0.0081(0.0039) | Loss 8.7567(9.0178) | Error 0.0022(0.0010) Steps 814(803.53) | Grad Norm 3.3975(2.0042) | Total Time 0.00(0.00)\n",
      "Iter 20900 | Time 20.5103(20.8208) | Bit/dim 3.5017(3.4975) | Xent 0.0094(0.0038) | Loss 8.7403(8.9320) | Error 0.0022(0.0010) Steps 802(804.29) | Grad Norm 5.5573(2.0618) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 93.9228, Epoch Time 1255.4718(1229.8144), Bit/dim 3.5282(best: 3.5298), Xent 3.1395, Loss 5.0980, Error 0.3691(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20910 | Time 19.8924(20.7045) | Bit/dim 3.5167(3.4991) | Xent 0.0016(0.0039) | Loss 8.7183(9.5860) | Error 0.0000(0.0010) Steps 790(803.22) | Grad Norm 1.3555(2.0659) | Total Time 0.00(0.00)\n",
      "Iter 20920 | Time 22.8647(20.7514) | Bit/dim 3.4881(3.4986) | Xent 0.0014(0.0036) | Loss 8.8162(9.3618) | Error 0.0000(0.0009) Steps 796(803.42) | Grad Norm 1.1592(2.0297) | Total Time 0.00(0.00)\n",
      "Iter 20930 | Time 21.3196(20.8160) | Bit/dim 3.5183(3.5003) | Xent 0.0055(0.0038) | Loss 8.7961(9.2028) | Error 0.0022(0.0010) Steps 838(806.31) | Grad Norm 3.0977(2.0210) | Total Time 0.00(0.00)\n",
      "Iter 20940 | Time 21.0052(20.7642) | Bit/dim 3.4941(3.4994) | Xent 0.0008(0.0035) | Loss 8.7279(9.0795) | Error 0.0000(0.0009) Steps 790(805.76) | Grad Norm 1.1481(2.0072) | Total Time 0.00(0.00)\n",
      "Iter 20950 | Time 21.4429(20.9446) | Bit/dim 3.4767(3.4974) | Xent 0.0185(0.0034) | Loss 8.7338(8.9821) | Error 0.0011(0.0008) Steps 814(805.17) | Grad Norm 1.5132(1.7902) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 90.5743, Epoch Time 1252.0815(1230.4824), Bit/dim 3.5269(best: 3.5282), Xent 3.2175, Loss 5.1357, Error 0.3683(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20960 | Time 19.8712(20.7609) | Bit/dim 3.4801(3.4980) | Xent 0.0146(0.0039) | Loss 8.5890(9.6755) | Error 0.0033(0.0010) Steps 802(804.65) | Grad Norm 3.2068(1.8107) | Total Time 0.00(0.00)\n",
      "Iter 20970 | Time 20.4697(20.7757) | Bit/dim 3.4828(3.4962) | Xent 0.0007(0.0041) | Loss 8.6242(9.4274) | Error 0.0000(0.0011) Steps 778(803.26) | Grad Norm 0.9590(1.9020) | Total Time 0.00(0.00)\n",
      "Iter 20980 | Time 20.3059(20.7042) | Bit/dim 3.5370(3.4997) | Xent 0.0007(0.0036) | Loss 8.7504(9.2490) | Error 0.0000(0.0009) Steps 796(802.56) | Grad Norm 0.5540(1.6872) | Total Time 0.00(0.00)\n",
      "Iter 20990 | Time 20.5889(20.7117) | Bit/dim 3.5142(3.5014) | Xent 0.0019(0.0038) | Loss 8.7330(9.1128) | Error 0.0000(0.0010) Steps 760(799.96) | Grad Norm 2.3408(2.0280) | Total Time 0.00(0.00)\n",
      "Iter 21000 | Time 20.2252(20.7510) | Bit/dim 3.4725(3.4983) | Xent 0.0058(0.0040) | Loss 8.6119(9.0046) | Error 0.0011(0.0011) Steps 820(802.20) | Grad Norm 2.1747(2.1399) | Total Time 0.00(0.00)\n",
      "Iter 21010 | Time 20.8721(20.8149) | Bit/dim 3.5039(3.4966) | Xent 0.0015(0.0042) | Loss 8.6677(8.9287) | Error 0.0000(0.0012) Steps 802(802.91) | Grad Norm 1.4682(2.2027) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 93.8663, Epoch Time 1250.8167(1231.0924), Bit/dim 3.5317(best: 3.5269), Xent 3.1877, Loss 5.1256, Error 0.3702(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21020 | Time 20.5136(20.7777) | Bit/dim 3.5125(3.4978) | Xent 0.0087(0.0042) | Loss 8.8437(9.5568) | Error 0.0011(0.0010) Steps 796(804.08) | Grad Norm 1.0537(2.0189) | Total Time 0.00(0.00)\n",
      "Iter 21030 | Time 21.9884(20.9664) | Bit/dim 3.4954(3.4978) | Xent 0.0025(0.0038) | Loss 8.7640(9.3409) | Error 0.0011(0.0009) Steps 790(804.68) | Grad Norm 1.7600(1.8748) | Total Time 0.00(0.00)\n",
      "Iter 21040 | Time 20.1031(20.9787) | Bit/dim 3.4995(3.4984) | Xent 0.0006(0.0034) | Loss 8.7923(9.1886) | Error 0.0000(0.0009) Steps 814(805.75) | Grad Norm 0.7974(1.7420) | Total Time 0.00(0.00)\n",
      "Iter 21050 | Time 22.2875(20.9539) | Bit/dim 3.4992(3.4961) | Xent 0.0018(0.0034) | Loss 8.6801(9.0538) | Error 0.0011(0.0009) Steps 844(808.13) | Grad Norm 2.2374(2.0086) | Total Time 0.00(0.00)\n",
      "Iter 21060 | Time 19.6050(20.8998) | Bit/dim 3.5119(3.4980) | Xent 0.0009(0.0034) | Loss 8.8266(8.9781) | Error 0.0000(0.0008) Steps 820(807.65) | Grad Norm 1.0124(1.8924) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 91.7415, Epoch Time 1261.4699(1232.0038), Bit/dim 3.5280(best: 3.5269), Xent 3.2199, Loss 5.1380, Error 0.3707(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21070 | Time 20.6393(20.9116) | Bit/dim 3.5003(3.4985) | Xent 0.0005(0.0033) | Loss 8.6881(9.7048) | Error 0.0000(0.0008) Steps 796(805.95) | Grad Norm 0.7426(1.8957) | Total Time 0.00(0.00)\n",
      "Iter 21080 | Time 21.2450(20.9948) | Bit/dim 3.4817(3.4974) | Xent 0.0037(0.0036) | Loss 8.8482(9.4560) | Error 0.0022(0.0009) Steps 820(805.69) | Grad Norm 3.7231(1.9130) | Total Time 0.00(0.00)\n",
      "Iter 21090 | Time 20.9903(21.0044) | Bit/dim 3.5059(3.4967) | Xent 0.0011(0.0036) | Loss 8.7246(9.2666) | Error 0.0000(0.0009) Steps 796(803.69) | Grad Norm 1.0589(1.8737) | Total Time 0.00(0.00)\n",
      "Iter 21100 | Time 21.9860(21.0979) | Bit/dim 3.5317(3.4996) | Xent 0.0004(0.0036) | Loss 8.7538(9.1337) | Error 0.0000(0.0009) Steps 790(803.02) | Grad Norm 0.8127(1.8882) | Total Time 0.00(0.00)\n",
      "Iter 21110 | Time 19.8576(21.0432) | Bit/dim 3.5196(3.5007) | Xent 0.0026(0.0033) | Loss 8.7481(9.0319) | Error 0.0011(0.0009) Steps 784(803.57) | Grad Norm 2.4294(1.8399) | Total Time 0.00(0.00)\n",
      "Iter 21120 | Time 21.6084(21.1037) | Bit/dim 3.4665(3.4972) | Xent 0.0013(0.0040) | Loss 8.7677(8.9625) | Error 0.0000(0.0010) Steps 808(804.15) | Grad Norm 1.3053(1.9133) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 91.4039, Epoch Time 1271.2175(1233.1802), Bit/dim 3.5291(best: 3.5269), Xent 3.2546, Loss 5.1564, Error 0.3721(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21130 | Time 21.3368(21.0201) | Bit/dim 3.5259(3.5005) | Xent 0.0012(0.0052) | Loss 8.6970(9.5634) | Error 0.0000(0.0013) Steps 796(801.97) | Grad Norm 0.8105(2.1125) | Total Time 0.00(0.00)\n",
      "Iter 21140 | Time 20.0162(21.1200) | Bit/dim 3.5152(3.5014) | Xent 0.0024(0.0054) | Loss 8.7071(9.3564) | Error 0.0011(0.0014) Steps 808(802.23) | Grad Norm 1.4845(2.3711) | Total Time 0.00(0.00)\n",
      "Iter 21150 | Time 21.3701(21.1526) | Bit/dim 3.4808(3.4999) | Xent 0.0027(0.0050) | Loss 8.7136(9.2025) | Error 0.0011(0.0014) Steps 838(804.27) | Grad Norm 1.7898(2.5107) | Total Time 0.00(0.00)\n",
      "Iter 21160 | Time 19.7433(21.0419) | Bit/dim 3.4670(3.4999) | Xent 0.0015(0.0054) | Loss 8.5079(9.0842) | Error 0.0011(0.0015) Steps 808(804.53) | Grad Norm 3.1589(2.7764) | Total Time 0.00(0.00)\n",
      "Iter 21170 | Time 20.3815(20.9282) | Bit/dim 3.5093(3.4995) | Xent 0.0035(0.0052) | Loss 8.7663(8.9931) | Error 0.0022(0.0016) Steps 814(802.66) | Grad Norm 3.8008(2.8644) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 92.8636, Epoch Time 1263.3291(1234.0846), Bit/dim 3.5352(best: 3.5269), Xent 3.1692, Loss 5.1198, Error 0.3664(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21180 | Time 21.0424(20.9630) | Bit/dim 3.4675(3.4956) | Xent 0.0009(0.0049) | Loss 8.5562(9.6804) | Error 0.0000(0.0016) Steps 778(802.33) | Grad Norm 1.1737(2.8214) | Total Time 0.00(0.00)\n",
      "Iter 21190 | Time 21.1526(20.9318) | Bit/dim 3.4834(3.4985) | Xent 0.0038(0.0045) | Loss 8.6470(9.4223) | Error 0.0011(0.0014) Steps 802(800.20) | Grad Norm 3.0853(2.6174) | Total Time 0.00(0.00)\n",
      "Iter 21200 | Time 21.1307(21.0400) | Bit/dim 3.4700(3.4972) | Xent 0.0004(0.0040) | Loss 8.6374(9.2381) | Error 0.0000(0.0012) Steps 838(800.30) | Grad Norm 1.2542(2.3608) | Total Time 0.00(0.00)\n",
      "Iter 21210 | Time 20.8331(20.9588) | Bit/dim 3.4403(3.4968) | Xent 0.0086(0.0040) | Loss 8.5293(9.1089) | Error 0.0033(0.0012) Steps 814(800.55) | Grad Norm 2.7024(2.2364) | Total Time 0.00(0.00)\n",
      "Iter 21220 | Time 21.2969(21.0433) | Bit/dim 3.5098(3.4984) | Xent 0.0070(0.0041) | Loss 8.8568(9.0169) | Error 0.0011(0.0012) Steps 826(804.70) | Grad Norm 1.3136(2.3543) | Total Time 0.00(0.00)\n",
      "Iter 21230 | Time 20.7253(21.0264) | Bit/dim 3.4718(3.4998) | Xent 0.0097(0.0041) | Loss 8.7367(8.9553) | Error 0.0033(0.0012) Steps 790(805.88) | Grad Norm 3.5809(2.3187) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 90.2562, Epoch Time 1263.7012(1234.9731), Bit/dim 3.5310(best: 3.5269), Xent 3.1885, Loss 5.1252, Error 0.3713(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21240 | Time 20.4940(21.0684) | Bit/dim 3.4872(3.4980) | Xent 0.0004(0.0042) | Loss 8.7102(9.5667) | Error 0.0000(0.0012) Steps 808(806.10) | Grad Norm 1.2768(2.1904) | Total Time 0.00(0.00)\n",
      "Iter 21250 | Time 21.4438(21.0413) | Bit/dim 3.4978(3.4955) | Xent 0.0019(0.0038) | Loss 8.7963(9.3548) | Error 0.0011(0.0011) Steps 844(807.46) | Grad Norm 1.6147(2.2794) | Total Time 0.00(0.00)\n",
      "Iter 21260 | Time 21.1818(21.0707) | Bit/dim 3.4760(3.4966) | Xent 0.0014(0.0042) | Loss 8.7494(9.1941) | Error 0.0000(0.0011) Steps 808(806.92) | Grad Norm 1.1814(2.2304) | Total Time 0.00(0.00)\n",
      "Iter 21270 | Time 21.3896(21.1105) | Bit/dim 3.4998(3.4992) | Xent 0.0059(0.0038) | Loss 8.7649(9.0845) | Error 0.0011(0.0010) Steps 784(806.03) | Grad Norm 1.9518(2.0403) | Total Time 0.00(0.00)\n",
      "Iter 21280 | Time 20.7288(20.9879) | Bit/dim 3.5196(3.5004) | Xent 0.0051(0.0040) | Loss 8.7793(8.9962) | Error 0.0011(0.0009) Steps 778(805.43) | Grad Norm 1.3097(1.8613) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 93.1937, Epoch Time 1268.5741(1235.9812), Bit/dim 3.5283(best: 3.5269), Xent 3.1675, Loss 5.1121, Error 0.3712(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21290 | Time 20.8550(21.0127) | Bit/dim 3.5082(3.4976) | Xent 0.0004(0.0041) | Loss 8.7796(9.7012) | Error 0.0000(0.0010) Steps 802(804.64) | Grad Norm 1.2731(1.8962) | Total Time 0.00(0.00)\n",
      "Iter 21300 | Time 21.7662(21.0514) | Bit/dim 3.5351(3.4984) | Xent 0.0006(0.0037) | Loss 8.8681(9.4481) | Error 0.0000(0.0009) Steps 784(806.56) | Grad Norm 1.1539(1.7996) | Total Time 0.00(0.00)\n",
      "Iter 21310 | Time 21.5029(21.1062) | Bit/dim 3.4837(3.4967) | Xent 0.0089(0.0039) | Loss 8.6758(9.2618) | Error 0.0011(0.0009) Steps 802(806.59) | Grad Norm 1.8877(1.8170) | Total Time 0.00(0.00)\n",
      "Iter 21320 | Time 21.3054(21.0888) | Bit/dim 3.5289(3.4959) | Xent 0.0038(0.0033) | Loss 8.8036(9.1194) | Error 0.0011(0.0007) Steps 790(805.64) | Grad Norm 2.9740(1.7490) | Total Time 0.00(0.00)\n",
      "Iter 21330 | Time 22.1980(21.2250) | Bit/dim 3.5025(3.4963) | Xent 0.0104(0.0038) | Loss 8.6664(9.0124) | Error 0.0033(0.0008) Steps 790(808.32) | Grad Norm 3.5164(1.8771) | Total Time 0.00(0.00)\n",
      "Iter 21340 | Time 21.4855(21.1142) | Bit/dim 3.5039(3.4967) | Xent 0.0013(0.0034) | Loss 8.7750(8.9384) | Error 0.0000(0.0008) Steps 814(807.15) | Grad Norm 1.3351(1.9090) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 89.9960, Epoch Time 1269.3252(1236.9815), Bit/dim 3.5282(best: 3.5269), Xent 3.1626, Loss 5.1095, Error 0.3701(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21350 | Time 20.7439(21.1828) | Bit/dim 3.4976(3.4970) | Xent 0.0004(0.0033) | Loss 8.7584(9.5545) | Error 0.0000(0.0007) Steps 808(806.48) | Grad Norm 1.3718(1.9124) | Total Time 0.00(0.00)\n",
      "Iter 21360 | Time 20.9909(21.1818) | Bit/dim 3.4728(3.4940) | Xent 0.0109(0.0045) | Loss 8.6910(9.3371) | Error 0.0011(0.0010) Steps 820(806.04) | Grad Norm 2.2563(2.3553) | Total Time 0.00(0.00)\n",
      "Iter 21370 | Time 22.1878(21.2871) | Bit/dim 3.4897(3.4947) | Xent 0.0028(0.0053) | Loss 8.7686(9.1858) | Error 0.0011(0.0013) Steps 796(805.84) | Grad Norm 3.0918(2.8586) | Total Time 0.00(0.00)\n",
      "Iter 21380 | Time 20.4829(21.3791) | Bit/dim 3.5199(3.4971) | Xent 0.0036(0.0055) | Loss 8.7248(9.0766) | Error 0.0011(0.0014) Steps 814(807.03) | Grad Norm 2.4818(2.8373) | Total Time 0.00(0.00)\n",
      "Iter 21390 | Time 21.3840(21.3115) | Bit/dim 3.5145(3.4986) | Xent 0.0150(0.0061) | Loss 8.7849(8.9865) | Error 0.0022(0.0014) Steps 820(805.55) | Grad Norm 2.9759(2.7707) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 91.5515, Epoch Time 1285.6646(1238.4420), Bit/dim 3.5359(best: 3.5269), Xent 3.2406, Loss 5.1562, Error 0.3756(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21400 | Time 21.1768(21.3045) | Bit/dim 3.4742(3.4993) | Xent 0.0014(0.0066) | Loss 8.7359(9.6826) | Error 0.0000(0.0017) Steps 820(807.64) | Grad Norm 2.6740(3.1075) | Total Time 0.00(0.00)\n",
      "Iter 21410 | Time 22.0199(21.3327) | Bit/dim 3.4887(3.4990) | Xent 0.0015(0.0078) | Loss 8.7017(9.4282) | Error 0.0000(0.0021) Steps 802(809.07) | Grad Norm 3.4343(3.6828) | Total Time 0.00(0.00)\n",
      "Iter 21420 | Time 21.1351(21.3184) | Bit/dim 3.4918(3.5029) | Xent 0.0033(0.0067) | Loss 8.7997(9.2568) | Error 0.0011(0.0019) Steps 802(810.06) | Grad Norm 2.0032(3.4414) | Total Time 0.00(0.00)\n",
      "Iter 21430 | Time 21.4262(21.3824) | Bit/dim 3.5147(3.5023) | Xent 0.0029(0.0063) | Loss 8.7819(9.1167) | Error 0.0011(0.0017) Steps 820(812.23) | Grad Norm 1.8052(3.1996) | Total Time 0.00(0.00)\n",
      "Iter 21440 | Time 21.1763(21.3724) | Bit/dim 3.5259(3.5014) | Xent 0.0038(0.0061) | Loss 8.8064(9.0170) | Error 0.0022(0.0017) Steps 796(811.99) | Grad Norm 2.3942(3.0351) | Total Time 0.00(0.00)\n",
      "Iter 21450 | Time 22.0736(21.3522) | Bit/dim 3.5267(3.5021) | Xent 0.0022(0.0056) | Loss 8.7689(8.9397) | Error 0.0000(0.0016) Steps 808(809.10) | Grad Norm 1.2385(2.8144) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 93.9913, Epoch Time 1284.4335(1239.8217), Bit/dim 3.5268(best: 3.5269), Xent 3.1295, Loss 5.0916, Error 0.3679(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21460 | Time 20.9608(21.3730) | Bit/dim 3.5122(3.5026) | Xent 0.0049(0.0047) | Loss 8.6907(9.5552) | Error 0.0011(0.0013) Steps 802(806.89) | Grad Norm 2.9170(2.4863) | Total Time 0.00(0.00)\n",
      "Iter 21470 | Time 22.5686(21.4503) | Bit/dim 3.4724(3.4993) | Xent 0.0009(0.0041) | Loss 8.6806(9.3387) | Error 0.0000(0.0011) Steps 826(808.75) | Grad Norm 1.7123(2.3872) | Total Time 0.00(0.00)\n",
      "Iter 21480 | Time 21.2149(21.4384) | Bit/dim 3.5202(3.5020) | Xent 0.0046(0.0044) | Loss 8.7584(9.1849) | Error 0.0011(0.0012) Steps 778(804.27) | Grad Norm 1.5447(2.4077) | Total Time 0.00(0.00)\n",
      "Iter 21490 | Time 21.6903(21.3873) | Bit/dim 3.4705(3.5002) | Xent 0.0008(0.0041) | Loss 8.6799(9.0665) | Error 0.0000(0.0011) Steps 814(806.18) | Grad Norm 1.1631(2.3193) | Total Time 0.00(0.00)\n",
      "Iter 21500 | Time 21.2853(21.4143) | Bit/dim 3.4912(3.4984) | Xent 0.0030(0.0042) | Loss 8.7035(8.9759) | Error 0.0022(0.0012) Steps 802(804.90) | Grad Norm 1.8841(2.3100) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 90.9550, Epoch Time 1286.5383(1241.2232), Bit/dim 3.5270(best: 3.5268), Xent 3.1480, Loss 5.1010, Error 0.3701(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21510 | Time 21.3859(21.3500) | Bit/dim 3.4799(3.4955) | Xent 0.0035(0.0038) | Loss 8.6122(9.6926) | Error 0.0011(0.0011) Steps 820(805.95) | Grad Norm 2.2266(2.0984) | Total Time 0.00(0.00)\n",
      "Iter 21520 | Time 20.8678(21.4249) | Bit/dim 3.5159(3.5001) | Xent 0.0089(0.0042) | Loss 8.6267(9.4442) | Error 0.0011(0.0011) Steps 796(805.15) | Grad Norm 1.0153(2.0028) | Total Time 0.00(0.00)\n",
      "Iter 21530 | Time 21.4717(21.3667) | Bit/dim 3.4983(3.4993) | Xent 0.0072(0.0039) | Loss 8.7938(9.2558) | Error 0.0011(0.0010) Steps 838(808.32) | Grad Norm 3.1793(1.9754) | Total Time 0.00(0.00)\n",
      "Iter 21540 | Time 22.3175(21.4234) | Bit/dim 3.4816(3.4965) | Xent 0.0041(0.0037) | Loss 8.6556(9.1153) | Error 0.0022(0.0009) Steps 802(806.35) | Grad Norm 4.8867(1.9890) | Total Time 0.00(0.00)\n",
      "Iter 21550 | Time 21.2067(21.3894) | Bit/dim 3.4864(3.4965) | Xent 0.0008(0.0038) | Loss 8.6842(9.0190) | Error 0.0000(0.0011) Steps 826(807.08) | Grad Norm 1.2811(2.0587) | Total Time 0.00(0.00)\n",
      "Iter 21560 | Time 21.6040(21.4394) | Bit/dim 3.5243(3.4970) | Xent 0.0006(0.0034) | Loss 8.8491(8.9453) | Error 0.0000(0.0010) Steps 856(809.16) | Grad Norm 0.7618(1.9005) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 90.7763, Epoch Time 1285.4359(1242.5496), Bit/dim 3.5297(best: 3.5268), Xent 3.1480, Loss 5.1037, Error 0.3670(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21570 | Time 21.5935(21.4317) | Bit/dim 3.5182(3.4971) | Xent 0.0048(0.0034) | Loss 8.7712(9.5605) | Error 0.0011(0.0010) Steps 826(810.35) | Grad Norm 1.9214(1.9119) | Total Time 0.00(0.00)\n",
      "Iter 21580 | Time 22.0689(21.4732) | Bit/dim 3.5095(3.4968) | Xent 0.0006(0.0035) | Loss 8.7328(9.3403) | Error 0.0000(0.0010) Steps 820(810.73) | Grad Norm 1.6166(1.9616) | Total Time 0.00(0.00)\n",
      "Iter 21590 | Time 21.9105(21.4528) | Bit/dim 3.5269(3.4965) | Xent 0.0009(0.0033) | Loss 8.5898(9.1774) | Error 0.0000(0.0010) Steps 850(811.56) | Grad Norm 1.4270(1.9439) | Total Time 0.00(0.00)\n",
      "Iter 21600 | Time 21.6277(21.4465) | Bit/dim 3.5100(3.4976) | Xent 0.0082(0.0032) | Loss 8.7354(9.0570) | Error 0.0011(0.0009) Steps 790(812.70) | Grad Norm 2.1124(1.8552) | Total Time 0.00(0.00)\n",
      "Iter 21610 | Time 21.4339(21.3946) | Bit/dim 3.5168(3.4980) | Xent 0.0007(0.0031) | Loss 8.8369(8.9672) | Error 0.0000(0.0009) Steps 808(811.67) | Grad Norm 0.5822(1.8142) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 91.8576, Epoch Time 1284.4563(1243.8068), Bit/dim 3.5253(best: 3.5268), Xent 3.1546, Loss 5.1026, Error 0.3684(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21620 | Time 20.8775(21.3486) | Bit/dim 3.5017(3.4975) | Xent 0.0090(0.0034) | Loss 8.7280(9.6849) | Error 0.0022(0.0010) Steps 784(810.38) | Grad Norm 2.5628(1.8758) | Total Time 0.00(0.00)\n",
      "Iter 21630 | Time 21.2515(21.3473) | Bit/dim 3.4840(3.4947) | Xent 0.0046(0.0034) | Loss 8.6713(9.4335) | Error 0.0011(0.0010) Steps 832(810.30) | Grad Norm 3.0571(1.9089) | Total Time 0.00(0.00)\n",
      "Iter 21640 | Time 21.5282(21.3873) | Bit/dim 3.4816(3.4956) | Xent 0.0029(0.0032) | Loss 8.6929(9.2603) | Error 0.0011(0.0009) Steps 820(810.65) | Grad Norm 0.9651(1.7784) | Total Time 0.00(0.00)\n",
      "Iter 21650 | Time 20.6428(21.2997) | Bit/dim 3.5083(3.4975) | Xent 0.0027(0.0032) | Loss 8.7512(9.1172) | Error 0.0011(0.0010) Steps 814(808.21) | Grad Norm 1.7854(1.8295) | Total Time 0.00(0.00)\n",
      "Iter 21660 | Time 22.9160(21.3395) | Bit/dim 3.5025(3.4994) | Xent 0.0090(0.0035) | Loss 8.8056(9.0192) | Error 0.0022(0.0010) Steps 820(808.85) | Grad Norm 3.1369(1.9114) | Total Time 0.00(0.00)\n",
      "Iter 21670 | Time 21.6332(21.3965) | Bit/dim 3.5264(3.4992) | Xent 0.0010(0.0040) | Loss 8.8931(8.9461) | Error 0.0000(0.0012) Steps 814(808.76) | Grad Norm 1.3199(2.2116) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 90.4238, Epoch Time 1282.8177(1244.9771), Bit/dim 3.5277(best: 3.5253), Xent 3.1576, Loss 5.1065, Error 0.3708(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21680 | Time 21.3321(21.4059) | Bit/dim 3.4873(3.4967) | Xent 0.0107(0.0040) | Loss 8.7018(9.5520) | Error 0.0022(0.0011) Steps 814(809.19) | Grad Norm 2.0835(2.1191) | Total Time 0.00(0.00)\n",
      "Iter 21690 | Time 22.1613(21.4610) | Bit/dim 3.4789(3.4957) | Xent 0.0038(0.0041) | Loss 8.6534(9.3205) | Error 0.0011(0.0011) Steps 802(807.38) | Grad Norm 3.1126(2.1489) | Total Time 0.00(0.00)\n",
      "Iter 21700 | Time 21.1455(21.4110) | Bit/dim 3.4973(3.4968) | Xent 0.0016(0.0038) | Loss 8.6132(9.1612) | Error 0.0011(0.0010) Steps 820(807.42) | Grad Norm 1.4620(1.9915) | Total Time 0.00(0.00)\n",
      "Iter 21710 | Time 21.4627(21.4556) | Bit/dim 3.5016(3.4976) | Xent 0.0009(0.0034) | Loss 8.6891(9.0473) | Error 0.0000(0.0010) Steps 796(808.39) | Grad Norm 0.8721(1.9366) | Total Time 0.00(0.00)\n",
      "Iter 21720 | Time 21.8237(21.4474) | Bit/dim 3.4744(3.4999) | Xent 0.0017(0.0034) | Loss 8.4955(8.9608) | Error 0.0011(0.0010) Steps 802(808.82) | Grad Norm 1.3461(2.2962) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 93.0231, Epoch Time 1290.9237(1246.3555), Bit/dim 3.5324(best: 3.5253), Xent 3.2218, Loss 5.1432, Error 0.3723(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21730 | Time 22.4283(21.4591) | Bit/dim 3.5007(3.5004) | Xent 0.0009(0.0033) | Loss 8.8227(9.6897) | Error 0.0000(0.0009) Steps 856(811.38) | Grad Norm 1.5183(2.2609) | Total Time 0.00(0.00)\n",
      "Iter 21740 | Time 21.6797(21.4675) | Bit/dim 3.4944(3.5015) | Xent 0.0017(0.0036) | Loss 8.6472(9.4417) | Error 0.0000(0.0010) Steps 802(808.71) | Grad Norm 1.2829(2.2179) | Total Time 0.00(0.00)\n",
      "Iter 21750 | Time 21.3412(21.6363) | Bit/dim 3.4988(3.4980) | Xent 0.0005(0.0034) | Loss 8.7190(9.2531) | Error 0.0000(0.0009) Steps 802(807.37) | Grad Norm 0.9237(2.1150) | Total Time 0.00(0.00)\n",
      "Iter 21760 | Time 21.5726(21.6128) | Bit/dim 3.5164(3.4996) | Xent 0.0028(0.0035) | Loss 8.7707(9.1229) | Error 0.0011(0.0010) Steps 826(810.59) | Grad Norm 3.5771(2.1924) | Total Time 0.00(0.00)\n",
      "Iter 21770 | Time 21.7840(21.6905) | Bit/dim 3.4877(3.4978) | Xent 0.0008(0.0032) | Loss 8.7198(9.0136) | Error 0.0000(0.0009) Steps 820(810.92) | Grad Norm 1.3928(2.2286) | Total Time 0.00(0.00)\n",
      "Iter 21780 | Time 21.2616(21.6899) | Bit/dim 3.4731(3.4983) | Xent 0.0006(0.0037) | Loss 8.7522(8.9421) | Error 0.0000(0.0009) Steps 808(807.48) | Grad Norm 0.9506(2.1756) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 91.5234, Epoch Time 1303.4199(1248.0674), Bit/dim 3.5315(best: 3.5253), Xent 3.2202, Loss 5.1416, Error 0.3666(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21790 | Time 20.6982(21.7082) | Bit/dim 3.5080(3.4985) | Xent 0.0080(0.0038) | Loss 8.8136(9.5650) | Error 0.0011(0.0009) Steps 790(806.67) | Grad Norm 2.1138(2.1675) | Total Time 0.00(0.00)\n",
      "Iter 21800 | Time 22.0040(21.6999) | Bit/dim 3.4961(3.4987) | Xent 0.0061(0.0040) | Loss 8.6700(9.3345) | Error 0.0011(0.0010) Steps 802(804.50) | Grad Norm 2.3125(2.3391) | Total Time 0.00(0.00)\n",
      "Iter 21810 | Time 22.2137(21.6624) | Bit/dim 3.5076(3.4993) | Xent 0.0116(0.0040) | Loss 8.8655(9.1806) | Error 0.0022(0.0011) Steps 814(806.23) | Grad Norm 2.1764(2.2405) | Total Time 0.00(0.00)\n",
      "Iter 21820 | Time 22.0345(21.5412) | Bit/dim 3.5001(3.4985) | Xent 0.0059(0.0051) | Loss 8.6578(9.0592) | Error 0.0033(0.0014) Steps 850(806.31) | Grad Norm 2.5546(2.3772) | Total Time 0.00(0.00)\n",
      "Iter 21830 | Time 21.1661(21.6065) | Bit/dim 3.4560(3.4991) | Xent 0.0047(0.0045) | Loss 8.6432(8.9777) | Error 0.0033(0.0013) Steps 802(808.39) | Grad Norm 3.0096(2.2264) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 88.9396, Epoch Time 1295.1835(1249.4809), Bit/dim 3.5268(best: 3.5253), Xent 3.1410, Loss 5.0974, Error 0.3682(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21840 | Time 22.0675(21.5791) | Bit/dim 3.4893(3.5000) | Xent 0.0008(0.0041) | Loss 8.8467(9.6803) | Error 0.0000(0.0012) Steps 814(809.38) | Grad Norm 0.7789(2.0983) | Total Time 0.00(0.00)\n",
      "Iter 21850 | Time 22.1609(21.5265) | Bit/dim 3.4979(3.4988) | Xent 0.0014(0.0032) | Loss 8.6079(9.4201) | Error 0.0000(0.0009) Steps 832(810.21) | Grad Norm 0.8152(1.7675) | Total Time 0.00(0.00)\n",
      "Iter 21860 | Time 21.2891(21.4323) | Bit/dim 3.4974(3.4965) | Xent 0.0030(0.0033) | Loss 8.7307(9.2322) | Error 0.0011(0.0010) Steps 790(808.95) | Grad Norm 1.5774(1.7459) | Total Time 0.00(0.00)\n",
      "Iter 21870 | Time 22.4277(21.5802) | Bit/dim 3.5011(3.4971) | Xent 0.0037(0.0032) | Loss 8.8322(9.1059) | Error 0.0011(0.0009) Steps 820(811.85) | Grad Norm 1.9361(1.7591) | Total Time 0.00(0.00)\n",
      "Iter 21880 | Time 20.4706(21.4186) | Bit/dim 3.5109(3.4987) | Xent 0.0030(0.0030) | Loss 8.6022(9.0024) | Error 0.0011(0.0009) Steps 796(809.83) | Grad Norm 4.6826(1.8296) | Total Time 0.00(0.00)\n",
      "Iter 21890 | Time 21.2099(21.4417) | Bit/dim 3.5105(3.4953) | Xent 0.0020(0.0033) | Loss 8.7758(8.9255) | Error 0.0011(0.0010) Steps 796(806.89) | Grad Norm 2.0573(1.8808) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 91.6696, Epoch Time 1284.1498(1250.5210), Bit/dim 3.5276(best: 3.5253), Xent 3.1596, Loss 5.1074, Error 0.3698(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21900 | Time 20.7274(21.4012) | Bit/dim 3.4974(3.4959) | Xent 0.0011(0.0026) | Loss 8.6362(9.5497) | Error 0.0000(0.0008) Steps 808(808.57) | Grad Norm 1.1332(1.6446) | Total Time 0.00(0.00)\n",
      "Iter 21910 | Time 21.4797(21.4261) | Bit/dim 3.5043(3.4921) | Xent 0.0024(0.0026) | Loss 8.7231(9.3267) | Error 0.0011(0.0007) Steps 802(807.63) | Grad Norm 2.5101(1.5865) | Total Time 0.00(0.00)\n",
      "Iter 21920 | Time 21.2099(21.4522) | Bit/dim 3.4925(3.4939) | Xent 0.0075(0.0028) | Loss 8.6894(9.1607) | Error 0.0033(0.0008) Steps 814(806.28) | Grad Norm 4.6484(1.8360) | Total Time 0.00(0.00)\n",
      "Iter 21930 | Time 21.5647(21.3893) | Bit/dim 3.4994(3.4955) | Xent 0.0003(0.0024) | Loss 8.8028(9.0467) | Error 0.0000(0.0007) Steps 784(805.93) | Grad Norm 1.5426(1.7990) | Total Time 0.00(0.00)\n",
      "Iter 21940 | Time 20.7297(21.4264) | Bit/dim 3.5122(3.4989) | Xent 0.0043(0.0024) | Loss 8.8049(8.9685) | Error 0.0011(0.0006) Steps 808(809.58) | Grad Norm 2.1936(1.7514) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 89.6276, Epoch Time 1284.1006(1251.5284), Bit/dim 3.5247(best: 3.5253), Xent 3.2736, Loss 5.1615, Error 0.3754(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21950 | Time 21.6477(21.4090) | Bit/dim 3.5055(3.4960) | Xent 0.0015(0.0023) | Loss 8.7888(9.6750) | Error 0.0011(0.0007) Steps 796(807.68) | Grad Norm 1.4441(1.7263) | Total Time 0.00(0.00)\n",
      "Iter 21960 | Time 21.4485(21.3312) | Bit/dim 3.4954(3.4930) | Xent 0.0061(0.0026) | Loss 8.7537(9.4221) | Error 0.0011(0.0007) Steps 790(807.17) | Grad Norm 1.9526(1.7322) | Total Time 0.00(0.00)\n",
      "Iter 21970 | Time 21.6413(21.3211) | Bit/dim 3.4722(3.4933) | Xent 0.0008(0.0026) | Loss 8.6381(9.2349) | Error 0.0000(0.0006) Steps 790(807.93) | Grad Norm 0.8084(1.6324) | Total Time 0.00(0.00)\n",
      "Iter 21980 | Time 21.9303(21.2920) | Bit/dim 3.4921(3.4943) | Xent 0.0026(0.0026) | Loss 8.7559(9.0962) | Error 0.0011(0.0007) Steps 808(809.37) | Grad Norm 1.1897(1.6559) | Total Time 0.00(0.00)\n",
      "Iter 21990 | Time 21.5645(21.3262) | Bit/dim 3.5333(3.4980) | Xent 0.0021(0.0026) | Loss 8.6606(8.9909) | Error 0.0011(0.0006) Steps 802(809.34) | Grad Norm 1.9504(1.6973) | Total Time 0.00(0.00)\n",
      "Iter 22000 | Time 21.0627(21.4265) | Bit/dim 3.5023(3.4966) | Xent 0.0011(0.0029) | Loss 8.7685(8.9183) | Error 0.0000(0.0007) Steps 808(808.39) | Grad Norm 1.0705(1.6745) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 90.1719, Epoch Time 1280.7713(1252.4057), Bit/dim 3.5290(best: 3.5247), Xent 3.2643, Loss 5.1611, Error 0.3724(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22010 | Time 22.3884(21.4610) | Bit/dim 3.4952(3.4941) | Xent 0.0017(0.0026) | Loss 8.7000(9.5191) | Error 0.0011(0.0007) Steps 850(807.03) | Grad Norm 1.2859(1.6606) | Total Time 0.00(0.00)\n",
      "Iter 22020 | Time 20.6756(21.4652) | Bit/dim 3.5026(3.4943) | Xent 0.0135(0.0035) | Loss 8.7338(9.3131) | Error 0.0033(0.0009) Steps 784(805.72) | Grad Norm 4.3698(1.9642) | Total Time 0.00(0.00)\n",
      "Iter 22030 | Time 20.9919(21.3655) | Bit/dim 3.5037(3.4942) | Xent 0.0010(0.0038) | Loss 8.8126(9.1546) | Error 0.0000(0.0010) Steps 814(808.10) | Grad Norm 1.9295(2.1628) | Total Time 0.00(0.00)\n",
      "Iter 22040 | Time 21.7711(21.4487) | Bit/dim 3.5010(3.4968) | Xent 0.0024(0.0038) | Loss 8.7332(9.0403) | Error 0.0011(0.0010) Steps 844(809.20) | Grad Norm 3.4231(2.2693) | Total Time 0.00(0.00)\n",
      "Iter 22050 | Time 21.2889(21.3545) | Bit/dim 3.4879(3.4957) | Xent 0.0021(0.0035) | Loss 8.6836(8.9528) | Error 0.0011(0.0009) Steps 814(808.69) | Grad Norm 1.6068(2.1706) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 91.8974, Epoch Time 1285.2409(1253.3907), Bit/dim 3.5303(best: 3.5247), Xent 3.2563, Loss 5.1584, Error 0.3729(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22060 | Time 20.4056(21.4199) | Bit/dim 3.4783(3.4963) | Xent 0.0105(0.0035) | Loss 8.7889(9.6743) | Error 0.0033(0.0009) Steps 760(808.82) | Grad Norm 3.0428(2.1413) | Total Time 0.00(0.00)\n",
      "Iter 22070 | Time 20.7214(21.3715) | Bit/dim 3.4633(3.4960) | Xent 0.0008(0.0034) | Loss 8.6227(9.4176) | Error 0.0000(0.0008) Steps 814(807.53) | Grad Norm 0.9681(2.1420) | Total Time 0.00(0.00)\n",
      "Iter 22080 | Time 21.7149(21.4099) | Bit/dim 3.4789(3.4988) | Xent 0.0005(0.0031) | Loss 8.6360(9.2412) | Error 0.0000(0.0007) Steps 826(804.05) | Grad Norm 2.2026(2.3670) | Total Time 0.00(0.00)\n",
      "Iter 22090 | Time 22.0531(21.3784) | Bit/dim 3.4802(3.4968) | Xent 0.0103(0.0032) | Loss 8.6433(9.0920) | Error 0.0022(0.0007) Steps 814(804.35) | Grad Norm 3.3206(2.4674) | Total Time 0.00(0.00)\n",
      "Iter 22100 | Time 21.4647(21.3583) | Bit/dim 3.4705(3.4940) | Xent 0.0006(0.0032) | Loss 8.5495(8.9911) | Error 0.0000(0.0008) Steps 814(808.12) | Grad Norm 1.2222(2.4505) | Total Time 0.00(0.00)\n",
      "Iter 22110 | Time 21.5253(21.3696) | Bit/dim 3.4958(3.4965) | Xent 0.0030(0.0036) | Loss 8.7290(8.9305) | Error 0.0011(0.0009) Steps 826(807.88) | Grad Norm 1.2141(2.3571) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 88.7328, Epoch Time 1280.3023(1254.1981), Bit/dim 3.5298(best: 3.5247), Xent 3.3304, Loss 5.1950, Error 0.3788(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22120 | Time 21.8418(21.4713) | Bit/dim 3.5026(3.4982) | Xent 0.0121(0.0045) | Loss 8.7690(9.5420) | Error 0.0033(0.0012) Steps 772(809.94) | Grad Norm 5.0130(2.6152) | Total Time 0.00(0.00)\n",
      "Iter 22130 | Time 21.8687(21.5308) | Bit/dim 3.5070(3.4997) | Xent 0.0014(0.0046) | Loss 8.7918(9.3332) | Error 0.0000(0.0013) Steps 808(810.78) | Grad Norm 2.1576(2.7741) | Total Time 0.00(0.00)\n",
      "Iter 22140 | Time 21.3586(21.5237) | Bit/dim 3.4914(3.5006) | Xent 0.0059(0.0048) | Loss 8.6351(9.1805) | Error 0.0011(0.0013) Steps 778(810.29) | Grad Norm 4.4907(2.8377) | Total Time 0.00(0.00)\n",
      "Iter 22150 | Time 20.5087(21.5345) | Bit/dim 3.5080(3.4990) | Xent 0.0019(0.0047) | Loss 8.6747(9.0608) | Error 0.0011(0.0013) Steps 814(808.48) | Grad Norm 2.4870(3.1670) | Total Time 0.00(0.00)\n",
      "Iter 22160 | Time 22.2615(21.4845) | Bit/dim 3.5314(3.4981) | Xent 0.0031(0.0049) | Loss 8.7323(8.9722) | Error 0.0011(0.0014) Steps 784(805.74) | Grad Norm 4.0788(3.2239) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 92.4900, Epoch Time 1298.0562(1255.5138), Bit/dim 3.5282(best: 3.5247), Xent 3.2383, Loss 5.1474, Error 0.3746(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22170 | Time 22.0049(21.5632) | Bit/dim 3.5028(3.4972) | Xent 0.0006(0.0041) | Loss 8.7474(9.6875) | Error 0.0000(0.0011) Steps 790(806.93) | Grad Norm 0.9324(2.9766) | Total Time 0.00(0.00)\n",
      "Iter 22180 | Time 21.9119(21.5810) | Bit/dim 3.4588(3.4942) | Xent 0.0012(0.0041) | Loss 8.7315(9.4243) | Error 0.0000(0.0011) Steps 820(811.34) | Grad Norm 1.1675(2.7685) | Total Time 0.00(0.00)\n",
      "Iter 22190 | Time 20.9331(21.5733) | Bit/dim 3.4859(3.4969) | Xent 0.0004(0.0037) | Loss 8.6928(9.2438) | Error 0.0000(0.0009) Steps 820(810.72) | Grad Norm 0.8607(2.5418) | Total Time 0.00(0.00)\n",
      "Iter 22200 | Time 20.9982(21.5105) | Bit/dim 3.4997(3.4979) | Xent 0.0013(0.0032) | Loss 8.6919(9.1100) | Error 0.0000(0.0008) Steps 802(811.34) | Grad Norm 0.9056(2.2491) | Total Time 0.00(0.00)\n",
      "Iter 22210 | Time 21.1711(21.4848) | Bit/dim 3.4854(3.4966) | Xent 0.0004(0.0029) | Loss 8.8303(9.0109) | Error 0.0000(0.0008) Steps 796(811.37) | Grad Norm 0.6549(2.0343) | Total Time 0.00(0.00)\n",
      "Iter 22220 | Time 21.4505(21.3760) | Bit/dim 3.4881(3.4954) | Xent 0.0132(0.0034) | Loss 8.7450(8.9330) | Error 0.0011(0.0009) Steps 802(812.36) | Grad Norm 1.5315(1.8962) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 90.4034, Epoch Time 1285.4023(1256.4105), Bit/dim 3.5251(best: 3.5247), Xent 3.3009, Loss 5.1756, Error 0.3805(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22230 | Time 21.1203(21.4170) | Bit/dim 3.4872(3.4956) | Xent 0.0022(0.0030) | Loss 8.6367(9.5605) | Error 0.0011(0.0008) Steps 778(810.22) | Grad Norm 2.9088(1.8113) | Total Time 0.00(0.00)\n",
      "Iter 22240 | Time 21.4459(21.3723) | Bit/dim 3.4735(3.4957) | Xent 0.0006(0.0031) | Loss 8.7540(9.3467) | Error 0.0000(0.0008) Steps 838(811.15) | Grad Norm 0.7849(1.8124) | Total Time 0.00(0.00)\n",
      "Iter 22250 | Time 21.9560(21.4416) | Bit/dim 3.4968(3.4948) | Xent 0.0018(0.0028) | Loss 8.7191(9.1765) | Error 0.0011(0.0007) Steps 832(812.42) | Grad Norm 1.2783(1.7348) | Total Time 0.00(0.00)\n",
      "Iter 22260 | Time 21.1627(21.3076) | Bit/dim 3.5121(3.4930) | Xent 0.0009(0.0029) | Loss 8.8086(9.0500) | Error 0.0000(0.0008) Steps 814(810.98) | Grad Norm 0.6975(1.7389) | Total Time 0.00(0.00)\n",
      "Iter 22270 | Time 21.4332(21.4378) | Bit/dim 3.4814(3.4932) | Xent 0.0013(0.0031) | Loss 8.6946(8.9710) | Error 0.0000(0.0007) Steps 850(810.99) | Grad Norm 0.8154(1.5749) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 90.6660, Epoch Time 1285.6642(1257.2881), Bit/dim 3.5277(best: 3.5247), Xent 3.2779, Loss 5.1667, Error 0.3776(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22280 | Time 21.4572(21.3925) | Bit/dim 3.4877(3.4938) | Xent 0.0074(0.0032) | Loss 8.7068(9.6866) | Error 0.0011(0.0007) Steps 802(808.29) | Grad Norm 1.8872(1.6078) | Total Time 0.00(0.00)\n",
      "Iter 22290 | Time 21.8711(21.5646) | Bit/dim 3.4876(3.4945) | Xent 0.0012(0.0029) | Loss 8.7245(9.4416) | Error 0.0000(0.0007) Steps 844(813.41) | Grad Norm 0.7690(1.5619) | Total Time 0.00(0.00)\n",
      "Iter 22300 | Time 20.2851(21.4778) | Bit/dim 3.4927(3.4938) | Xent 0.0019(0.0036) | Loss 8.7254(9.2588) | Error 0.0000(0.0008) Steps 796(813.64) | Grad Norm 2.3021(1.7093) | Total Time 0.00(0.00)\n",
      "Iter 22310 | Time 21.7037(21.4333) | Bit/dim 3.5073(3.4934) | Xent 0.0027(0.0032) | Loss 8.7311(9.1135) | Error 0.0011(0.0008) Steps 814(812.34) | Grad Norm 1.5451(1.6495) | Total Time 0.00(0.00)\n",
      "Iter 22320 | Time 21.4512(21.4987) | Bit/dim 3.5107(3.4940) | Xent 0.0115(0.0038) | Loss 8.6878(9.0166) | Error 0.0022(0.0008) Steps 784(814.51) | Grad Norm 1.9687(1.7497) | Total Time 0.00(0.00)\n",
      "Iter 22330 | Time 22.4461(21.4581) | Bit/dim 3.4906(3.4931) | Xent 0.0004(0.0043) | Loss 8.6419(8.9312) | Error 0.0000(0.0010) Steps 784(812.27) | Grad Norm 0.9057(1.8708) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 92.2931, Epoch Time 1291.3675(1258.3105), Bit/dim 3.5289(best: 3.5247), Xent 3.2477, Loss 5.1527, Error 0.3717(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22340 | Time 22.1882(21.4026) | Bit/dim 3.4582(3.4914) | Xent 0.0042(0.0040) | Loss 8.6724(9.5445) | Error 0.0033(0.0010) Steps 826(811.14) | Grad Norm 2.5892(1.9499) | Total Time 0.00(0.00)\n",
      "Iter 22350 | Time 21.7002(21.4756) | Bit/dim 3.4937(3.4935) | Xent 0.0004(0.0036) | Loss 8.6771(9.3233) | Error 0.0000(0.0009) Steps 814(809.81) | Grad Norm 0.7028(1.8261) | Total Time 0.00(0.00)\n",
      "Iter 22360 | Time 21.0658(21.3826) | Bit/dim 3.4955(3.4941) | Xent 0.0097(0.0038) | Loss 8.6685(9.1580) | Error 0.0011(0.0008) Steps 808(810.82) | Grad Norm 2.1868(1.8051) | Total Time 0.00(0.00)\n",
      "Iter 22370 | Time 21.3534(21.4580) | Bit/dim 3.4986(3.4930) | Xent 0.0008(0.0037) | Loss 8.8490(9.0435) | Error 0.0000(0.0009) Steps 802(809.95) | Grad Norm 1.1806(1.8910) | Total Time 0.00(0.00)\n",
      "Iter 22380 | Time 20.8035(21.4653) | Bit/dim 3.4930(3.4958) | Xent 0.0067(0.0037) | Loss 8.6623(8.9641) | Error 0.0033(0.0010) Steps 802(808.58) | Grad Norm 4.6091(1.9785) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 91.2248, Epoch Time 1285.2927(1259.1199), Bit/dim 3.5305(best: 3.5247), Xent 3.2539, Loss 5.1574, Error 0.3744(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22390 | Time 22.5420(21.4587) | Bit/dim 3.4739(3.4925) | Xent 0.0010(0.0035) | Loss 8.7212(9.6799) | Error 0.0000(0.0009) Steps 802(807.55) | Grad Norm 1.5352(1.8684) | Total Time 0.00(0.00)\n",
      "Iter 22400 | Time 21.0222(21.3311) | Bit/dim 3.5249(3.4983) | Xent 0.0172(0.0041) | Loss 8.7295(9.4380) | Error 0.0033(0.0010) Steps 778(805.70) | Grad Norm 1.9938(2.0539) | Total Time 0.00(0.00)\n",
      "Iter 22410 | Time 21.1945(21.3211) | Bit/dim 3.4917(3.4989) | Xent 0.0009(0.0038) | Loss 8.7510(9.2512) | Error 0.0000(0.0009) Steps 796(804.02) | Grad Norm 0.7921(1.9802) | Total Time 0.00(0.00)\n",
      "Iter 22420 | Time 21.0254(21.2271) | Bit/dim 3.5244(3.5000) | Xent 0.0196(0.0049) | Loss 8.8186(9.1140) | Error 0.0056(0.0013) Steps 796(803.20) | Grad Norm 5.1330(2.5407) | Total Time 0.00(0.00)\n",
      "Iter 22430 | Time 21.7261(21.2569) | Bit/dim 3.4889(3.4964) | Xent 0.0033(0.0061) | Loss 8.6351(9.0036) | Error 0.0011(0.0015) Steps 802(805.37) | Grad Norm 2.5035(2.8312) | Total Time 0.00(0.00)\n",
      "Iter 22440 | Time 21.3190(21.2997) | Bit/dim 3.5049(3.4972) | Xent 0.0006(0.0061) | Loss 8.7806(8.9383) | Error 0.0000(0.0014) Steps 808(809.25) | Grad Norm 1.1209(2.7114) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 90.1642, Epoch Time 1275.6626(1259.6162), Bit/dim 3.5284(best: 3.5247), Xent 3.2611, Loss 5.1590, Error 0.3775(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22450 | Time 22.4007(21.3608) | Bit/dim 3.4913(3.4942) | Xent 0.0013(0.0054) | Loss 8.7226(9.5510) | Error 0.0000(0.0012) Steps 796(808.22) | Grad Norm 4.2850(2.5455) | Total Time 0.00(0.00)\n",
      "Iter 22460 | Time 20.9043(21.3010) | Bit/dim 3.4979(3.4998) | Xent 0.0072(0.0049) | Loss 8.7845(9.3521) | Error 0.0022(0.0012) Steps 784(806.24) | Grad Norm 3.7838(2.4201) | Total Time 0.00(0.00)\n",
      "Iter 22470 | Time 21.9494(21.2490) | Bit/dim 3.4595(3.4964) | Xent 0.0008(0.0045) | Loss 8.6798(9.1816) | Error 0.0000(0.0010) Steps 820(806.04) | Grad Norm 1.0616(2.2215) | Total Time 0.00(0.00)\n",
      "Iter 22480 | Time 21.8409(21.2632) | Bit/dim 3.5290(3.4958) | Xent 0.0005(0.0037) | Loss 8.8427(9.0592) | Error 0.0000(0.0009) Steps 844(808.86) | Grad Norm 0.8451(2.0075) | Total Time 0.00(0.00)\n",
      "Iter 22490 | Time 21.3560(21.2390) | Bit/dim 3.5180(3.4968) | Xent 0.0007(0.0033) | Loss 8.7308(8.9637) | Error 0.0000(0.0008) Steps 826(811.01) | Grad Norm 0.9960(1.8184) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 91.8695, Epoch Time 1280.5083(1260.2430), Bit/dim 3.5244(best: 3.5247), Xent 3.2087, Loss 5.1288, Error 0.3707(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22500 | Time 21.3740(21.3716) | Bit/dim 3.4858(3.4949) | Xent 0.0010(0.0033) | Loss 8.7419(9.6762) | Error 0.0000(0.0008) Steps 790(808.02) | Grad Norm 0.8746(1.7358) | Total Time 0.00(0.00)\n",
      "Iter 22510 | Time 22.0363(21.3674) | Bit/dim 3.4718(3.4959) | Xent 0.0009(0.0030) | Loss 8.7190(9.4300) | Error 0.0000(0.0007) Steps 784(806.94) | Grad Norm 0.7226(1.6355) | Total Time 0.00(0.00)\n",
      "Iter 22520 | Time 21.0527(21.4182) | Bit/dim 3.4718(3.4956) | Xent 0.0016(0.0026) | Loss 8.6998(9.2385) | Error 0.0000(0.0006) Steps 826(810.63) | Grad Norm 1.7964(1.6555) | Total Time 0.00(0.00)\n",
      "Iter 22530 | Time 20.3959(21.3484) | Bit/dim 3.4908(3.4947) | Xent 0.0038(0.0025) | Loss 8.6157(9.0952) | Error 0.0011(0.0006) Steps 814(809.31) | Grad Norm 2.6475(1.5638) | Total Time 0.00(0.00)\n",
      "Iter 22540 | Time 21.2736(21.4610) | Bit/dim 3.4826(3.4936) | Xent 0.0018(0.0024) | Loss 8.7757(9.0032) | Error 0.0000(0.0006) Steps 814(813.23) | Grad Norm 1.2535(1.5256) | Total Time 0.00(0.00)\n",
      "Iter 22550 | Time 21.5914(21.3652) | Bit/dim 3.4853(3.4941) | Xent 0.0013(0.0027) | Loss 8.7053(8.9210) | Error 0.0000(0.0008) Steps 814(807.71) | Grad Norm 1.2666(1.7345) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 87.8475, Epoch Time 1281.8125(1260.8901), Bit/dim 3.5229(best: 3.5244), Xent 3.2510, Loss 5.1484, Error 0.3742(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22560 | Time 21.6988(21.4591) | Bit/dim 3.5000(3.4935) | Xent 0.0002(0.0026) | Loss 8.6560(9.5413) | Error 0.0000(0.0008) Steps 802(808.56) | Grad Norm 0.7972(1.7925) | Total Time 0.00(0.00)\n",
      "Iter 22570 | Time 20.6654(21.4110) | Bit/dim 3.4815(3.4945) | Xent 0.0005(0.0031) | Loss 8.7765(9.3311) | Error 0.0000(0.0008) Steps 814(808.58) | Grad Norm 0.8084(1.8588) | Total Time 0.00(0.00)\n",
      "Iter 22580 | Time 21.0068(21.4396) | Bit/dim 3.4800(3.4910) | Xent 0.0006(0.0027) | Loss 8.6596(9.1653) | Error 0.0000(0.0008) Steps 796(808.21) | Grad Norm 0.6817(1.6999) | Total Time 0.00(0.00)\n",
      "Iter 22590 | Time 22.0757(21.3991) | Bit/dim 3.4993(3.4944) | Xent 0.0025(0.0033) | Loss 8.8254(9.0536) | Error 0.0011(0.0010) Steps 796(806.42) | Grad Norm 1.0317(1.8537) | Total Time 0.00(0.00)\n",
      "Iter 22600 | Time 21.4336(21.4164) | Bit/dim 3.5072(3.4931) | Xent 0.0056(0.0035) | Loss 8.6111(8.9541) | Error 0.0011(0.0010) Steps 790(806.20) | Grad Norm 3.1448(1.9588) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 89.6596, Epoch Time 1286.9043(1261.6705), Bit/dim 3.5240(best: 3.5229), Xent 3.2678, Loss 5.1579, Error 0.3715(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22610 | Time 22.0713(21.4529) | Bit/dim 3.4852(3.4950) | Xent 0.0017(0.0032) | Loss 8.7129(9.6844) | Error 0.0011(0.0009) Steps 814(807.32) | Grad Norm 1.4463(1.8857) | Total Time 0.00(0.00)\n",
      "Iter 22620 | Time 22.0910(21.5386) | Bit/dim 3.4984(3.4947) | Xent 0.0004(0.0029) | Loss 8.8307(9.4347) | Error 0.0000(0.0008) Steps 820(807.39) | Grad Norm 0.8134(1.7766) | Total Time 0.00(0.00)\n",
      "Iter 22630 | Time 20.2738(21.4622) | Bit/dim 3.4819(3.4941) | Xent 0.0008(0.0026) | Loss 8.7303(9.2493) | Error 0.0000(0.0007) Steps 808(808.02) | Grad Norm 0.8389(1.6983) | Total Time 0.00(0.00)\n",
      "Iter 22640 | Time 21.9403(21.4800) | Bit/dim 3.4784(3.4940) | Xent 0.0015(0.0024) | Loss 8.7581(9.1113) | Error 0.0000(0.0007) Steps 832(809.53) | Grad Norm 1.1205(1.6002) | Total Time 0.00(0.00)\n",
      "Iter 22650 | Time 21.8334(21.4426) | Bit/dim 3.4906(3.4942) | Xent 0.0012(0.0028) | Loss 8.7281(9.0053) | Error 0.0000(0.0008) Steps 778(806.29) | Grad Norm 2.4746(1.8316) | Total Time 0.00(0.00)\n",
      "Iter 22660 | Time 22.6232(21.4414) | Bit/dim 3.5072(3.4969) | Xent 0.0014(0.0031) | Loss 8.6590(8.9314) | Error 0.0000(0.0009) Steps 802(808.41) | Grad Norm 1.5058(1.9770) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 93.4164, Epoch Time 1290.8033(1262.5445), Bit/dim 3.5273(best: 3.5229), Xent 3.2320, Loss 5.1433, Error 0.3709(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22670 | Time 20.4220(21.3654) | Bit/dim 3.4821(3.4987) | Xent 0.0013(0.0027) | Loss 8.7722(9.5593) | Error 0.0000(0.0008) Steps 820(810.10) | Grad Norm 1.1085(1.8461) | Total Time 0.00(0.00)\n",
      "Iter 22680 | Time 22.1672(21.3412) | Bit/dim 3.4775(3.4970) | Xent 0.0026(0.0024) | Loss 8.7006(9.3392) | Error 0.0011(0.0007) Steps 832(810.94) | Grad Norm 2.2053(1.7194) | Total Time 0.00(0.00)\n",
      "Iter 22690 | Time 21.5861(21.3764) | Bit/dim 3.4778(3.4947) | Xent 0.0083(0.0031) | Loss 8.7421(9.1644) | Error 0.0022(0.0008) Steps 820(808.19) | Grad Norm 3.2845(1.8253) | Total Time 0.00(0.00)\n",
      "Iter 22700 | Time 22.4690(21.3321) | Bit/dim 3.4676(3.4935) | Xent 0.0017(0.0028) | Loss 8.7783(9.0391) | Error 0.0011(0.0007) Steps 802(809.08) | Grad Norm 1.3026(1.7693) | Total Time 0.00(0.00)\n",
      "Iter 22710 | Time 21.6289(21.3097) | Bit/dim 3.5036(3.4953) | Xent 0.0009(0.0035) | Loss 8.7161(8.9675) | Error 0.0000(0.0008) Steps 778(809.01) | Grad Norm 1.8457(1.7527) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 90.7007, Epoch Time 1276.8794(1262.9745), Bit/dim 3.5247(best: 3.5229), Xent 3.2615, Loss 5.1554, Error 0.3750(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22720 | Time 21.6090(21.3299) | Bit/dim 3.4909(3.4961) | Xent 0.0008(0.0034) | Loss 8.7607(9.7128) | Error 0.0000(0.0008) Steps 790(808.73) | Grad Norm 0.8225(1.6513) | Total Time 0.00(0.00)\n",
      "Iter 22730 | Time 20.5247(21.3115) | Bit/dim 3.4830(3.4967) | Xent 0.0009(0.0038) | Loss 8.6971(9.4563) | Error 0.0000(0.0009) Steps 808(809.58) | Grad Norm 1.5861(1.8263) | Total Time 0.00(0.00)\n",
      "Iter 22740 | Time 21.8543(21.3514) | Bit/dim 3.4668(3.4930) | Xent 0.0021(0.0034) | Loss 8.6772(9.2624) | Error 0.0000(0.0008) Steps 802(809.97) | Grad Norm 1.9812(1.8260) | Total Time 0.00(0.00)\n",
      "Iter 22750 | Time 20.8396(21.4441) | Bit/dim 3.4671(3.4910) | Xent 0.0036(0.0029) | Loss 8.6888(9.1139) | Error 0.0011(0.0008) Steps 802(809.03) | Grad Norm 2.0485(1.7757) | Total Time 0.00(0.00)\n",
      "Iter 22760 | Time 21.8656(21.4710) | Bit/dim 3.4966(3.4936) | Xent 0.0009(0.0029) | Loss 8.7375(9.0083) | Error 0.0000(0.0008) Steps 778(807.54) | Grad Norm 1.1516(1.7767) | Total Time 0.00(0.00)\n",
      "Iter 22770 | Time 20.8499(21.5118) | Bit/dim 3.5034(3.4949) | Xent 0.0008(0.0026) | Loss 8.6844(8.9295) | Error 0.0000(0.0007) Steps 808(808.21) | Grad Norm 0.8591(1.6680) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 89.5931, Epoch Time 1289.5908(1263.7730), Bit/dim 3.5244(best: 3.5229), Xent 3.3063, Loss 5.1775, Error 0.3758(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22780 | Time 21.1704(21.5785) | Bit/dim 3.4851(3.4934) | Xent 0.0015(0.0026) | Loss 8.6480(9.5288) | Error 0.0011(0.0007) Steps 784(806.41) | Grad Norm 2.0077(1.7438) | Total Time 0.00(0.00)\n",
      "Iter 22790 | Time 22.6641(21.5408) | Bit/dim 3.5337(3.4931) | Xent 0.0010(0.0024) | Loss 8.7296(9.3161) | Error 0.0000(0.0007) Steps 784(806.31) | Grad Norm 0.8343(1.6779) | Total Time 0.00(0.00)\n",
      "Iter 22800 | Time 21.8887(21.4648) | Bit/dim 3.4849(3.4946) | Xent 0.0160(0.0030) | Loss 8.8414(9.1566) | Error 0.0022(0.0008) Steps 844(807.51) | Grad Norm 2.4128(1.8025) | Total Time 0.00(0.00)\n",
      "Iter 22810 | Time 21.6109(21.5965) | Bit/dim 3.4916(3.4933) | Xent 0.0035(0.0035) | Loss 8.7229(9.0336) | Error 0.0022(0.0010) Steps 790(805.63) | Grad Norm 2.1042(2.0490) | Total Time 0.00(0.00)\n",
      "Iter 22820 | Time 20.4811(21.4547) | Bit/dim 3.5112(3.4959) | Xent 0.0029(0.0036) | Loss 8.8827(8.9567) | Error 0.0011(0.0010) Steps 820(805.17) | Grad Norm 3.8904(2.3650) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 92.5473, Epoch Time 1292.8804(1264.6462), Bit/dim 3.5255(best: 3.5229), Xent 3.3248, Loss 5.1879, Error 0.3809(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22830 | Time 23.0609(21.4882) | Bit/dim 3.5022(3.4997) | Xent 0.0022(0.0043) | Loss 8.8294(9.6966) | Error 0.0011(0.0014) Steps 790(805.74) | Grad Norm 2.3082(2.6461) | Total Time 0.00(0.00)\n",
      "Iter 22840 | Time 21.2882(21.4088) | Bit/dim 3.4842(3.4999) | Xent 0.0004(0.0040) | Loss 8.7661(9.4445) | Error 0.0000(0.0012) Steps 808(805.33) | Grad Norm 0.9574(2.4920) | Total Time 0.00(0.00)\n",
      "Iter 22850 | Time 20.8970(21.4594) | Bit/dim 3.4825(3.4958) | Xent 0.0022(0.0037) | Loss 8.7574(9.2446) | Error 0.0011(0.0011) Steps 784(803.00) | Grad Norm 1.4708(2.2554) | Total Time 0.00(0.00)\n",
      "Iter 22860 | Time 20.9491(21.3668) | Bit/dim 3.4902(3.4957) | Xent 0.0010(0.0033) | Loss 8.7417(9.1036) | Error 0.0000(0.0009) Steps 808(803.45) | Grad Norm 0.8375(2.0141) | Total Time 0.00(0.00)\n",
      "Iter 22870 | Time 21.0956(21.3980) | Bit/dim 3.4979(3.4960) | Xent 0.0030(0.0035) | Loss 8.7986(9.0066) | Error 0.0011(0.0010) Steps 802(804.18) | Grad Norm 1.4330(2.0693) | Total Time 0.00(0.00)\n",
      "Iter 22880 | Time 21.5563(21.3827) | Bit/dim 3.5245(3.4935) | Xent 0.0082(0.0036) | Loss 8.8412(8.9312) | Error 0.0022(0.0010) Steps 832(807.00) | Grad Norm 2.0404(2.1333) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 91.4251, Epoch Time 1282.3480(1265.1773), Bit/dim 3.5253(best: 3.5229), Xent 3.2564, Loss 5.1535, Error 0.3714(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22890 | Time 21.6693(21.4111) | Bit/dim 3.4855(3.4923) | Xent 0.0047(0.0038) | Loss 8.6552(9.5587) | Error 0.0011(0.0009) Steps 790(808.62) | Grad Norm 1.5935(1.9451) | Total Time 0.00(0.00)\n",
      "Iter 22900 | Time 21.3681(21.3531) | Bit/dim 3.5574(3.4948) | Xent 0.0024(0.0034) | Loss 8.8851(9.3451) | Error 0.0011(0.0008) Steps 820(810.50) | Grad Norm 2.7637(1.9748) | Total Time 0.00(0.00)\n",
      "Iter 22910 | Time 21.6232(21.5074) | Bit/dim 3.5143(3.4940) | Xent 0.0071(0.0038) | Loss 8.7414(9.1814) | Error 0.0022(0.0010) Steps 832(812.28) | Grad Norm 3.4320(2.1841) | Total Time 0.00(0.00)\n",
      "Iter 22920 | Time 21.4390(21.4594) | Bit/dim 3.5050(3.4957) | Xent 0.0040(0.0041) | Loss 8.8137(9.0686) | Error 0.0011(0.0011) Steps 802(809.89) | Grad Norm 1.5306(2.1725) | Total Time 0.00(0.00)\n",
      "Iter 22930 | Time 20.8783(21.4173) | Bit/dim 3.5107(3.4950) | Xent 0.0022(0.0038) | Loss 8.6958(8.9715) | Error 0.0011(0.0010) Steps 790(809.08) | Grad Norm 3.2299(2.0792) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 90.2745, Epoch Time 1286.8982(1265.8289), Bit/dim 3.5251(best: 3.5229), Xent 3.3165, Loss 5.1833, Error 0.3758(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22940 | Time 21.3301(21.4364) | Bit/dim 3.4988(3.4962) | Xent 0.0034(0.0041) | Loss 8.7175(9.7023) | Error 0.0011(0.0010) Steps 814(809.71) | Grad Norm 3.9359(2.1927) | Total Time 0.00(0.00)\n",
      "Iter 22950 | Time 21.5351(21.5135) | Bit/dim 3.4646(3.4947) | Xent 0.0012(0.0044) | Loss 8.6059(9.4458) | Error 0.0000(0.0012) Steps 796(810.80) | Grad Norm 1.5387(2.3909) | Total Time 0.00(0.00)\n",
      "Iter 22960 | Time 22.4171(21.5019) | Bit/dim 3.4754(3.4950) | Xent 0.0123(0.0054) | Loss 8.6557(9.2609) | Error 0.0011(0.0013) Steps 820(811.53) | Grad Norm 2.9267(2.4908) | Total Time 0.00(0.00)\n",
      "Iter 22970 | Time 20.4284(21.5656) | Bit/dim 3.4876(3.4948) | Xent 0.0108(0.0051) | Loss 8.6428(9.1147) | Error 0.0022(0.0013) Steps 796(811.72) | Grad Norm 4.4497(2.5724) | Total Time 0.00(0.00)\n",
      "Iter 22980 | Time 21.0529(21.5539) | Bit/dim 3.5116(3.4953) | Xent 0.0069(0.0048) | Loss 8.8576(9.0183) | Error 0.0011(0.0012) Steps 814(814.37) | Grad Norm 1.8300(2.5664) | Total Time 0.00(0.00)\n",
      "Iter 22990 | Time 21.6294(21.5427) | Bit/dim 3.5179(3.4968) | Xent 0.0006(0.0058) | Loss 8.7470(8.9439) | Error 0.0000(0.0014) Steps 802(812.17) | Grad Norm 2.9616(3.1190) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 93.2584, Epoch Time 1298.0050(1266.7942), Bit/dim 3.5284(best: 3.5229), Xent 3.2406, Loss 5.1487, Error 0.3750(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23000 | Time 22.0956(21.4842) | Bit/dim 3.5036(3.4977) | Xent 0.0076(0.0061) | Loss 8.7397(9.5695) | Error 0.0011(0.0016) Steps 826(810.48) | Grad Norm 3.6124(3.1674) | Total Time 0.00(0.00)\n",
      "Iter 23010 | Time 22.2971(21.5007) | Bit/dim 3.5358(3.4988) | Xent 0.0027(0.0061) | Loss 8.7588(9.3524) | Error 0.0011(0.0015) Steps 814(808.55) | Grad Norm 2.2667(3.1390) | Total Time 0.00(0.00)\n",
      "Iter 23020 | Time 21.8581(21.4618) | Bit/dim 3.5381(3.5000) | Xent 0.0070(0.0052) | Loss 8.9089(9.1913) | Error 0.0011(0.0013) Steps 844(807.79) | Grad Norm 2.3999(2.9320) | Total Time 0.00(0.00)\n",
      "Iter 23030 | Time 21.7073(21.5470) | Bit/dim 3.5061(3.4984) | Xent 0.0124(0.0055) | Loss 8.7970(9.0700) | Error 0.0022(0.0013) Steps 784(811.58) | Grad Norm 3.7205(2.9088) | Total Time 0.00(0.00)\n",
      "Iter 23040 | Time 21.5405(21.4532) | Bit/dim 3.4964(3.4964) | Xent 0.0043(0.0048) | Loss 8.8060(8.9826) | Error 0.0011(0.0011) Steps 856(815.00) | Grad Norm 1.6275(2.5621) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 91.1432, Epoch Time 1285.9727(1267.3696), Bit/dim 3.5260(best: 3.5229), Xent 3.2834, Loss 5.1677, Error 0.3727(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23050 | Time 21.1470(21.4374) | Bit/dim 3.4670(3.4946) | Xent 0.0033(0.0041) | Loss 8.5958(9.6795) | Error 0.0022(0.0010) Steps 784(811.06) | Grad Norm 3.4594(2.3509) | Total Time 0.00(0.00)\n",
      "Iter 23060 | Time 20.2830(21.4000) | Bit/dim 3.4814(3.4935) | Xent 0.0003(0.0039) | Loss 8.7443(9.4245) | Error 0.0000(0.0011) Steps 796(809.17) | Grad Norm 0.8104(2.2123) | Total Time 0.00(0.00)\n",
      "Iter 23070 | Time 22.6335(21.4672) | Bit/dim 3.5208(3.4959) | Xent 0.0201(0.0053) | Loss 8.7856(9.2531) | Error 0.0033(0.0013) Steps 844(812.48) | Grad Norm 1.9388(2.5520) | Total Time 0.00(0.00)\n",
      "Iter 23080 | Time 20.8199(21.4616) | Bit/dim 3.5207(3.4969) | Xent 0.0104(0.0063) | Loss 8.8462(9.1159) | Error 0.0033(0.0015) Steps 808(811.47) | Grad Norm 3.7634(2.7921) | Total Time 0.00(0.00)\n",
      "Iter 23090 | Time 21.3071(21.4371) | Bit/dim 3.5068(3.4978) | Xent 0.0120(0.0054) | Loss 8.6648(9.0105) | Error 0.0044(0.0013) Steps 802(812.55) | Grad Norm 4.3780(2.5080) | Total Time 0.00(0.00)\n",
      "Iter 23100 | Time 21.8056(21.4816) | Bit/dim 3.4995(3.4963) | Xent 0.0128(0.0056) | Loss 8.7095(8.9250) | Error 0.0033(0.0014) Steps 826(814.19) | Grad Norm 5.2305(2.5335) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 89.1495, Epoch Time 1287.4195(1267.9711), Bit/dim 3.5239(best: 3.5229), Xent 3.2043, Loss 5.1260, Error 0.3719(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23110 | Time 22.1366(21.4641) | Bit/dim 3.4823(3.4923) | Xent 0.0013(0.0048) | Loss 8.7545(9.5585) | Error 0.0000(0.0012) Steps 796(815.30) | Grad Norm 0.8237(2.2562) | Total Time 0.00(0.00)\n",
      "Iter 23120 | Time 21.2699(21.4102) | Bit/dim 3.5087(3.4929) | Xent 0.0005(0.0043) | Loss 8.7219(9.3308) | Error 0.0000(0.0011) Steps 808(813.85) | Grad Norm 1.2961(2.3172) | Total Time 0.00(0.00)\n",
      "Iter 23130 | Time 21.6521(21.4318) | Bit/dim 3.4651(3.4943) | Xent 0.0141(0.0045) | Loss 8.6419(9.1689) | Error 0.0044(0.0012) Steps 802(812.82) | Grad Norm 4.1472(2.5549) | Total Time 0.00(0.00)\n",
      "Iter 23140 | Time 22.6999(21.4447) | Bit/dim 3.4300(3.4949) | Xent 0.0183(0.0048) | Loss 8.6629(9.0477) | Error 0.0033(0.0012) Steps 838(813.22) | Grad Norm 3.0125(2.4427) | Total Time 0.00(0.00)\n",
      "Iter 23150 | Time 21.2507(21.4409) | Bit/dim 3.5245(3.4942) | Xent 0.0014(0.0051) | Loss 8.8394(8.9658) | Error 0.0000(0.0013) Steps 796(813.67) | Grad Norm 1.6094(2.5310) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 92.2435, Epoch Time 1288.2688(1268.5800), Bit/dim 3.5242(best: 3.5229), Xent 3.2482, Loss 5.1483, Error 0.3673(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23160 | Time 21.7320(21.5045) | Bit/dim 3.5363(3.4939) | Xent 0.0035(0.0045) | Loss 8.8768(9.6928) | Error 0.0011(0.0012) Steps 826(815.14) | Grad Norm 2.4384(2.4335) | Total Time 0.00(0.00)\n",
      "Iter 23170 | Time 20.5390(21.3458) | Bit/dim 3.5170(3.4956) | Xent 0.0013(0.0043) | Loss 8.7280(9.4382) | Error 0.0011(0.0011) Steps 808(814.62) | Grad Norm 2.4392(2.4825) | Total Time 0.00(0.00)\n",
      "Iter 23180 | Time 20.7221(21.4612) | Bit/dim 3.5183(3.4937) | Xent 0.0008(0.0039) | Loss 8.7140(9.2431) | Error 0.0000(0.0010) Steps 826(813.59) | Grad Norm 1.4953(2.2951) | Total Time 0.00(0.00)\n",
      "Iter 23190 | Time 21.6381(21.4783) | Bit/dim 3.5207(3.4942) | Xent 0.0040(0.0033) | Loss 8.7782(9.1031) | Error 0.0022(0.0009) Steps 790(812.09) | Grad Norm 3.4058(2.0448) | Total Time 0.00(0.00)\n",
      "Iter 23200 | Time 21.2565(21.5331) | Bit/dim 3.4642(3.4954) | Xent 0.0006(0.0029) | Loss 8.6228(9.0000) | Error 0.0000(0.0007) Steps 796(810.67) | Grad Norm 0.7099(1.8285) | Total Time 0.00(0.00)\n",
      "Iter 23210 | Time 20.4807(21.4774) | Bit/dim 3.4857(3.4945) | Xent 0.0016(0.0030) | Loss 8.6681(8.9207) | Error 0.0011(0.0008) Steps 796(811.95) | Grad Norm 1.5886(1.8866) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 89.2763, Epoch Time 1287.3245(1269.1423), Bit/dim 3.5242(best: 3.5229), Xent 3.2986, Loss 5.1735, Error 0.3744(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23220 | Time 21.6860(21.5399) | Bit/dim 3.4849(3.4945) | Xent 0.0016(0.0032) | Loss 8.6931(9.5365) | Error 0.0011(0.0007) Steps 814(807.50) | Grad Norm 1.2624(1.9818) | Total Time 0.00(0.00)\n",
      "Iter 23230 | Time 21.5654(21.5130) | Bit/dim 3.4878(3.4923) | Xent 0.0045(0.0035) | Loss 8.7454(9.3173) | Error 0.0022(0.0009) Steps 820(809.30) | Grad Norm 2.1543(2.0039) | Total Time 0.00(0.00)\n",
      "Iter 23240 | Time 21.6172(21.5949) | Bit/dim 3.5085(3.4919) | Xent 0.0018(0.0032) | Loss 8.7212(9.1509) | Error 0.0000(0.0008) Steps 832(812.98) | Grad Norm 1.1090(2.0034) | Total Time 0.00(0.00)\n",
      "Iter 23250 | Time 21.5986(21.5047) | Bit/dim 3.5009(3.4954) | Xent 0.0027(0.0029) | Loss 8.8435(9.0425) | Error 0.0011(0.0008) Steps 838(814.32) | Grad Norm 1.0516(1.8886) | Total Time 0.00(0.00)\n",
      "Iter 23260 | Time 21.4074(21.5528) | Bit/dim 3.5091(3.4944) | Xent 0.0042(0.0026) | Loss 8.7385(8.9514) | Error 0.0011(0.0007) Steps 838(813.94) | Grad Norm 2.8178(1.8552) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 90.0613, Epoch Time 1294.4360(1269.9011), Bit/dim 3.5243(best: 3.5229), Xent 3.2980, Loss 5.1733, Error 0.3741(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23270 | Time 21.7150(21.5241) | Bit/dim 3.4940(3.4945) | Xent 0.0046(0.0028) | Loss 8.7234(9.6737) | Error 0.0011(0.0008) Steps 868(814.72) | Grad Norm 1.8363(1.9322) | Total Time 0.00(0.00)\n",
      "Iter 23280 | Time 21.6328(21.5151) | Bit/dim 3.4879(3.4915) | Xent 0.0182(0.0035) | Loss 8.7129(9.4112) | Error 0.0033(0.0010) Steps 796(811.85) | Grad Norm 3.7988(2.0600) | Total Time 0.00(0.00)\n",
      "Iter 23290 | Time 21.9177(21.5124) | Bit/dim 3.4712(3.4909) | Xent 0.0042(0.0034) | Loss 8.8023(9.2288) | Error 0.0011(0.0010) Steps 850(811.97) | Grad Norm 3.1322(2.1234) | Total Time 0.00(0.00)\n",
      "Iter 23300 | Time 22.1668(21.5591) | Bit/dim 3.4996(3.4944) | Xent 0.0005(0.0034) | Loss 8.7972(9.1084) | Error 0.0000(0.0009) Steps 832(812.52) | Grad Norm 0.8862(1.9821) | Total Time 0.00(0.00)\n",
      "Iter 23310 | Time 21.1900(21.4905) | Bit/dim 3.4947(3.4946) | Xent 0.0006(0.0035) | Loss 8.7073(9.0063) | Error 0.0000(0.0010) Steps 796(812.42) | Grad Norm 1.2013(2.1121) | Total Time 0.00(0.00)\n",
      "Iter 23320 | Time 21.1492(21.4853) | Bit/dim 3.4726(3.4943) | Xent 0.0053(0.0037) | Loss 8.6225(8.9300) | Error 0.0011(0.0010) Steps 796(811.62) | Grad Norm 1.9166(2.3220) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 93.0261, Epoch Time 1290.2935(1270.5129), Bit/dim 3.5253(best: 3.5229), Xent 3.3148, Loss 5.1828, Error 0.3692(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23330 | Time 21.4551(21.4929) | Bit/dim 3.5147(3.4953) | Xent 0.0063(0.0036) | Loss 8.6661(9.5448) | Error 0.0011(0.0010) Steps 796(812.56) | Grad Norm 1.8967(2.3104) | Total Time 0.00(0.00)\n",
      "Iter 23340 | Time 22.6529(21.4792) | Bit/dim 3.4810(3.4957) | Xent 0.0089(0.0043) | Loss 8.7316(9.3228) | Error 0.0022(0.0011) Steps 784(809.74) | Grad Norm 2.6893(2.6619) | Total Time 0.00(0.00)\n",
      "Iter 23350 | Time 20.4706(21.4088) | Bit/dim 3.5282(3.4967) | Xent 0.0072(0.0043) | Loss 8.8339(9.1616) | Error 0.0033(0.0012) Steps 826(810.26) | Grad Norm 6.0212(2.8487) | Total Time 0.00(0.00)\n",
      "Iter 23360 | Time 21.8847(21.3312) | Bit/dim 3.4908(3.4949) | Xent 0.0008(0.0041) | Loss 8.7957(9.0401) | Error 0.0000(0.0011) Steps 778(809.95) | Grad Norm 1.1187(2.7032) | Total Time 0.00(0.00)\n",
      "Iter 23370 | Time 20.8532(21.2930) | Bit/dim 3.5046(3.4929) | Xent 0.0128(0.0054) | Loss 8.6392(8.9551) | Error 0.0044(0.0015) Steps 832(809.31) | Grad Norm 4.0261(2.9714) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 89.6741, Epoch Time 1274.1709(1270.6226), Bit/dim 3.5300(best: 3.5229), Xent 3.2608, Loss 5.1604, Error 0.3673(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23380 | Time 21.7453(21.2721) | Bit/dim 3.5178(3.4969) | Xent 0.0050(0.0053) | Loss 8.7295(9.6995) | Error 0.0011(0.0014) Steps 784(808.80) | Grad Norm 2.4724(2.8192) | Total Time 0.00(0.00)\n",
      "Iter 23390 | Time 20.9513(21.2708) | Bit/dim 3.4892(3.4968) | Xent 0.0010(0.0049) | Loss 8.7507(9.4501) | Error 0.0000(0.0012) Steps 820(810.21) | Grad Norm 1.6877(2.6237) | Total Time 0.00(0.00)\n",
      "Iter 23400 | Time 21.2545(21.3056) | Bit/dim 3.4998(3.4966) | Xent 0.0055(0.0042) | Loss 8.6693(9.2509) | Error 0.0011(0.0011) Steps 802(811.26) | Grad Norm 2.8574(2.4158) | Total Time 0.00(0.00)\n",
      "Iter 23410 | Time 21.4282(21.3486) | Bit/dim 3.4833(3.4956) | Xent 0.0046(0.0044) | Loss 8.6920(9.1006) | Error 0.0011(0.0011) Steps 796(810.82) | Grad Norm 2.6889(2.2982) | Total Time 0.00(0.00)\n",
      "Iter 23420 | Time 21.9897(21.3564) | Bit/dim 3.4448(3.4934) | Xent 0.0020(0.0045) | Loss 8.7293(8.9976) | Error 0.0011(0.0011) Steps 802(812.92) | Grad Norm 1.7567(2.1382) | Total Time 0.00(0.00)\n",
      "Iter 23430 | Time 21.0024(21.3388) | Bit/dim 3.5015(3.4946) | Xent 0.0071(0.0045) | Loss 8.7582(8.9278) | Error 0.0033(0.0011) Steps 826(810.76) | Grad Norm 1.7800(2.0073) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 89.8389, Epoch Time 1283.4747(1271.0082), Bit/dim 3.5236(best: 3.5229), Xent 3.2574, Loss 5.1523, Error 0.3744(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23440 | Time 21.3504(21.3137) | Bit/dim 3.5564(3.4959) | Xent 0.0009(0.0043) | Loss 8.7648(9.5409) | Error 0.0000(0.0012) Steps 820(810.69) | Grad Norm 1.2484(2.1959) | Total Time 0.00(0.00)\n",
      "Iter 23450 | Time 20.8636(21.3609) | Bit/dim 3.4851(3.4946) | Xent 0.0020(0.0044) | Loss 8.6916(9.3141) | Error 0.0011(0.0012) Steps 832(811.10) | Grad Norm 1.1959(2.2630) | Total Time 0.00(0.00)\n",
      "Iter 23460 | Time 21.6960(21.3501) | Bit/dim 3.5079(3.4961) | Xent 0.0034(0.0036) | Loss 8.8273(9.1657) | Error 0.0011(0.0010) Steps 862(813.24) | Grad Norm 1.5873(2.0233) | Total Time 0.00(0.00)\n",
      "Iter 23470 | Time 22.4876(21.3463) | Bit/dim 3.4883(3.4950) | Xent 0.0042(0.0031) | Loss 8.7932(9.0511) | Error 0.0022(0.0009) Steps 796(811.94) | Grad Norm 3.3599(1.9959) | Total Time 0.00(0.00)\n",
      "Iter 23480 | Time 20.9011(21.2926) | Bit/dim 3.5200(3.4951) | Xent 0.0036(0.0029) | Loss 8.8063(8.9527) | Error 0.0011(0.0008) Steps 808(810.53) | Grad Norm 3.6639(1.9677) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 92.1735, Epoch Time 1278.9219(1271.2456), Bit/dim 3.5224(best: 3.5229), Xent 3.3139, Loss 5.1793, Error 0.3750(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23490 | Time 20.7810(21.2911) | Bit/dim 3.4794(3.4944) | Xent 0.0003(0.0032) | Loss 8.6320(9.6552) | Error 0.0000(0.0008) Steps 802(811.98) | Grad Norm 0.8736(1.9352) | Total Time 0.00(0.00)\n",
      "Iter 23500 | Time 21.3679(21.2797) | Bit/dim 3.4827(3.4943) | Xent 0.0010(0.0033) | Loss 8.7164(9.4078) | Error 0.0000(0.0009) Steps 802(812.88) | Grad Norm 1.4854(1.9383) | Total Time 0.00(0.00)\n",
      "Iter 23510 | Time 21.1697(21.2779) | Bit/dim 3.4814(3.4936) | Xent 0.0011(0.0036) | Loss 8.6639(9.2242) | Error 0.0000(0.0009) Steps 838(812.84) | Grad Norm 1.2409(1.8673) | Total Time 0.00(0.00)\n",
      "Iter 23520 | Time 21.1119(21.3613) | Bit/dim 3.4876(3.4929) | Xent 0.0011(0.0032) | Loss 8.7415(9.0930) | Error 0.0000(0.0008) Steps 796(812.72) | Grad Norm 0.9668(1.7143) | Total Time 0.00(0.00)\n",
      "Iter 23530 | Time 21.9620(21.3164) | Bit/dim 3.4837(3.4938) | Xent 0.0052(0.0033) | Loss 8.7548(8.9910) | Error 0.0011(0.0008) Steps 796(813.87) | Grad Norm 2.4334(1.8131) | Total Time 0.00(0.00)\n",
      "Iter 23540 | Time 22.8126(21.3473) | Bit/dim 3.5166(3.4945) | Xent 0.0011(0.0036) | Loss 8.7558(8.9248) | Error 0.0000(0.0009) Steps 778(812.35) | Grad Norm 1.0425(1.8786) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 89.4391, Epoch Time 1281.5159(1271.5537), Bit/dim 3.5231(best: 3.5224), Xent 3.2820, Loss 5.1641, Error 0.3765(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23550 | Time 22.4417(21.3718) | Bit/dim 3.5147(3.4935) | Xent 0.0048(0.0037) | Loss 8.7973(9.5348) | Error 0.0022(0.0010) Steps 838(812.29) | Grad Norm 3.8245(2.1578) | Total Time 0.00(0.00)\n",
      "Iter 23560 | Time 21.7290(21.3316) | Bit/dim 3.5306(3.4951) | Xent 0.0042(0.0040) | Loss 8.8037(9.3229) | Error 0.0011(0.0010) Steps 790(808.29) | Grad Norm 3.6875(2.2076) | Total Time 0.00(0.00)\n",
      "Iter 23570 | Time 21.4415(21.2690) | Bit/dim 3.5041(3.4949) | Xent 0.0044(0.0044) | Loss 8.7211(9.1551) | Error 0.0011(0.0010) Steps 808(806.18) | Grad Norm 2.9838(2.3370) | Total Time 0.00(0.00)\n",
      "Iter 23580 | Time 20.5642(21.2612) | Bit/dim 3.5151(3.4961) | Xent 0.0028(0.0056) | Loss 8.6827(9.0401) | Error 0.0011(0.0014) Steps 802(805.41) | Grad Norm 2.8427(2.6261) | Total Time 0.00(0.00)\n",
      "Iter 23590 | Time 20.8101(21.2816) | Bit/dim 3.4980(3.4948) | Xent 0.0015(0.0061) | Loss 8.8079(8.9606) | Error 0.0011(0.0015) Steps 814(806.67) | Grad Norm 2.3340(2.6428) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 92.5188, Epoch Time 1278.6872(1271.7677), Bit/dim 3.5264(best: 3.5224), Xent 3.2608, Loss 5.1568, Error 0.3698(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23600 | Time 21.1725(21.3379) | Bit/dim 3.4724(3.4951) | Xent 0.0004(0.0055) | Loss 8.6890(9.6895) | Error 0.0000(0.0013) Steps 784(809.26) | Grad Norm 0.8463(2.5094) | Total Time 0.00(0.00)\n",
      "Iter 23610 | Time 21.3408(21.3162) | Bit/dim 3.5062(3.4949) | Xent 0.0007(0.0052) | Loss 8.4931(9.4264) | Error 0.0000(0.0012) Steps 772(809.14) | Grad Norm 0.8414(2.2640) | Total Time 0.00(0.00)\n",
      "Iter 23620 | Time 20.6827(21.4155) | Bit/dim 3.4829(3.4937) | Xent 0.0011(0.0048) | Loss 8.7301(9.2368) | Error 0.0000(0.0011) Steps 814(806.16) | Grad Norm 1.1715(2.1898) | Total Time 0.00(0.00)\n",
      "Iter 23630 | Time 20.3013(21.3798) | Bit/dim 3.5609(3.4957) | Xent 0.0011(0.0042) | Loss 8.8088(9.1044) | Error 0.0000(0.0010) Steps 796(805.90) | Grad Norm 1.1119(2.2411) | Total Time 0.00(0.00)\n",
      "Iter 23640 | Time 22.2285(21.3523) | Bit/dim 3.4967(3.4964) | Xent 0.0021(0.0040) | Loss 8.7983(9.0174) | Error 0.0011(0.0009) Steps 820(808.57) | Grad Norm 2.2075(2.1679) | Total Time 0.00(0.00)\n",
      "Iter 23650 | Time 21.7127(21.4089) | Bit/dim 3.4955(3.4960) | Xent 0.0010(0.0038) | Loss 8.7270(8.9398) | Error 0.0000(0.0008) Steps 820(808.47) | Grad Norm 1.2713(2.0567) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 89.1607, Epoch Time 1285.5272(1272.1805), Bit/dim 3.5225(best: 3.5224), Xent 3.2530, Loss 5.1490, Error 0.3695(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23660 | Time 22.2531(21.4302) | Bit/dim 3.4767(3.4936) | Xent 0.0008(0.0036) | Loss 8.7194(9.5439) | Error 0.0000(0.0007) Steps 838(808.80) | Grad Norm 0.6248(1.9420) | Total Time 0.00(0.00)\n",
      "Iter 23670 | Time 21.3040(21.4633) | Bit/dim 3.4906(3.4914) | Xent 0.0013(0.0033) | Loss 8.7080(9.3262) | Error 0.0000(0.0006) Steps 820(810.39) | Grad Norm 1.4193(1.9076) | Total Time 0.00(0.00)\n",
      "Iter 23680 | Time 21.5269(21.4065) | Bit/dim 3.5259(3.4917) | Xent 0.0038(0.0038) | Loss 8.9072(9.1782) | Error 0.0022(0.0009) Steps 820(811.18) | Grad Norm 3.7969(2.2049) | Total Time 0.00(0.00)\n",
      "Iter 23690 | Time 21.2458(21.3857) | Bit/dim 3.4843(3.4961) | Xent 0.0012(0.0032) | Loss 8.7226(9.0721) | Error 0.0000(0.0007) Steps 796(811.17) | Grad Norm 1.3050(2.0399) | Total Time 0.00(0.00)\n",
      "Iter 23700 | Time 21.4176(21.4177) | Bit/dim 3.5009(3.4959) | Xent 0.0023(0.0028) | Loss 8.8172(8.9803) | Error 0.0011(0.0007) Steps 814(809.66) | Grad Norm 2.2982(2.0249) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 90.7929, Epoch Time 1287.6986(1272.6461), Bit/dim 3.5202(best: 3.5224), Xent 3.2343, Loss 5.1374, Error 0.3680(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23710 | Time 21.4687(21.4929) | Bit/dim 3.4734(3.4934) | Xent 0.0023(0.0028) | Loss 8.6296(9.6986) | Error 0.0011(0.0007) Steps 814(810.92) | Grad Norm 0.9876(2.0361) | Total Time 0.00(0.00)\n",
      "Iter 23720 | Time 21.4396(21.5553) | Bit/dim 3.5130(3.4930) | Xent 0.0066(0.0033) | Loss 8.6314(9.4422) | Error 0.0022(0.0008) Steps 832(810.43) | Grad Norm 2.0252(1.9242) | Total Time 0.00(0.00)\n",
      "Iter 23730 | Time 22.3547(21.6754) | Bit/dim 3.5346(3.4922) | Xent 0.0011(0.0029) | Loss 8.8056(9.2531) | Error 0.0000(0.0007) Steps 790(807.32) | Grad Norm 0.8128(1.8611) | Total Time 0.00(0.00)\n",
      "Iter 23740 | Time 21.7035(21.6606) | Bit/dim 3.5035(3.4953) | Xent 0.0004(0.0031) | Loss 8.6577(9.1159) | Error 0.0000(0.0008) Steps 808(806.34) | Grad Norm 1.2943(1.9505) | Total Time 0.00(0.00)\n",
      "Iter 23750 | Time 20.9924(21.5770) | Bit/dim 3.5169(3.4955) | Xent 0.0115(0.0032) | Loss 8.6577(9.0100) | Error 0.0022(0.0007) Steps 844(806.87) | Grad Norm 3.2211(1.9248) | Total Time 0.00(0.00)\n",
      "Iter 23760 | Time 21.7411(21.6399) | Bit/dim 3.4781(3.4933) | Xent 0.0078(0.0035) | Loss 8.7608(8.9373) | Error 0.0011(0.0009) Steps 826(809.40) | Grad Norm 2.0453(2.0530) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 93.0988, Epoch Time 1302.6593(1273.5465), Bit/dim 3.5236(best: 3.5202), Xent 3.3123, Loss 5.1797, Error 0.3767(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23770 | Time 21.6055(21.4923) | Bit/dim 3.4916(3.4929) | Xent 0.0023(0.0035) | Loss 8.7201(9.5635) | Error 0.0011(0.0009) Steps 820(809.97) | Grad Norm 2.3785(2.1077) | Total Time 0.00(0.00)\n",
      "Iter 23780 | Time 21.2283(21.4760) | Bit/dim 3.4827(3.4911) | Xent 0.0030(0.0034) | Loss 8.7148(9.3429) | Error 0.0022(0.0009) Steps 832(812.02) | Grad Norm 3.6071(2.3293) | Total Time 0.00(0.00)\n",
      "Iter 23790 | Time 20.6122(21.4179) | Bit/dim 3.4797(3.4906) | Xent 0.0017(0.0033) | Loss 8.6097(9.1795) | Error 0.0011(0.0009) Steps 814(809.78) | Grad Norm 2.2790(2.2284) | Total Time 0.00(0.00)\n",
      "Iter 23800 | Time 22.1274(21.3969) | Bit/dim 3.5154(3.4942) | Xent 0.0020(0.0044) | Loss 8.8555(9.0716) | Error 0.0011(0.0011) Steps 802(809.47) | Grad Norm 1.2360(2.2592) | Total Time 0.00(0.00)\n",
      "Iter 23810 | Time 21.7841(21.4929) | Bit/dim 3.5106(3.4936) | Xent 0.0026(0.0040) | Loss 8.8013(8.9727) | Error 0.0000(0.0010) Steps 796(807.15) | Grad Norm 1.5860(2.0549) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 90.9509, Epoch Time 1283.0049(1273.8302), Bit/dim 3.5217(best: 3.5202), Xent 3.3016, Loss 5.1726, Error 0.3682(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23820 | Time 21.6293(21.5096) | Bit/dim 3.4855(3.4947) | Xent 0.0024(0.0040) | Loss 8.6420(9.6975) | Error 0.0011(0.0010) Steps 838(807.69) | Grad Norm 2.1434(2.0657) | Total Time 0.00(0.00)\n",
      "Iter 23830 | Time 22.3989(21.5776) | Bit/dim 3.4917(3.4910) | Xent 0.0008(0.0035) | Loss 8.6484(9.4345) | Error 0.0000(0.0009) Steps 826(809.87) | Grad Norm 0.9705(1.9505) | Total Time 0.00(0.00)\n",
      "Iter 23840 | Time 21.0665(21.4896) | Bit/dim 3.4850(3.4916) | Xent 0.0005(0.0034) | Loss 8.7133(9.2467) | Error 0.0000(0.0008) Steps 778(808.42) | Grad Norm 1.4280(2.0285) | Total Time 0.00(0.00)\n",
      "Iter 23850 | Time 21.5675(21.5910) | Bit/dim 3.4885(3.4937) | Xent 0.0013(0.0032) | Loss 8.6220(9.1234) | Error 0.0000(0.0008) Steps 820(810.59) | Grad Norm 1.6779(2.1654) | Total Time 0.00(0.00)\n",
      "Iter 23860 | Time 21.5935(21.5567) | Bit/dim 3.5312(3.4945) | Xent 0.0046(0.0030) | Loss 8.9119(9.0253) | Error 0.0022(0.0008) Steps 814(810.72) | Grad Norm 3.7216(2.1881) | Total Time 0.00(0.00)\n",
      "Iter 23870 | Time 20.9177(21.4251) | Bit/dim 3.5123(3.4952) | Xent 0.0088(0.0038) | Loss 8.6904(8.9414) | Error 0.0022(0.0010) Steps 802(808.68) | Grad Norm 4.6120(2.4716) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 93.6672, Epoch Time 1292.8165(1274.3998), Bit/dim 3.5246(best: 3.5202), Xent 3.2374, Loss 5.1433, Error 0.3692(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23880 | Time 21.2275(21.4379) | Bit/dim 3.4816(3.4935) | Xent 0.0115(0.0039) | Loss 8.6563(9.5559) | Error 0.0022(0.0011) Steps 796(809.72) | Grad Norm 3.5135(2.4300) | Total Time 0.00(0.00)\n",
      "Iter 23890 | Time 20.8182(21.3855) | Bit/dim 3.4974(3.4933) | Xent 0.0010(0.0041) | Loss 8.7866(9.3373) | Error 0.0000(0.0011) Steps 790(808.58) | Grad Norm 1.4574(2.4239) | Total Time 0.00(0.00)\n",
      "Iter 23900 | Time 23.0288(21.4120) | Bit/dim 3.4803(3.4918) | Xent 0.0052(0.0040) | Loss 8.7475(9.1762) | Error 0.0022(0.0011) Steps 880(809.29) | Grad Norm 3.9347(2.3440) | Total Time 0.00(0.00)\n",
      "Iter 23910 | Time 22.0877(21.4460) | Bit/dim 3.5086(3.4932) | Xent 0.0007(0.0037) | Loss 8.8655(9.0625) | Error 0.0000(0.0011) Steps 832(808.90) | Grad Norm 1.4688(2.5256) | Total Time 0.00(0.00)\n",
      "Iter 23920 | Time 21.2084(21.3860) | Bit/dim 3.4718(3.4924) | Xent 0.0015(0.0033) | Loss 8.6064(8.9659) | Error 0.0000(0.0010) Steps 796(809.61) | Grad Norm 2.3167(2.3963) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 93.3597, Epoch Time 1285.3332(1274.7278), Bit/dim 3.5249(best: 3.5202), Xent 3.2624, Loss 5.1561, Error 0.3718(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23930 | Time 21.9053(21.4330) | Bit/dim 3.4690(3.4940) | Xent 0.0006(0.0039) | Loss 8.7479(9.7076) | Error 0.0000(0.0010) Steps 814(809.49) | Grad Norm 1.7434(2.4764) | Total Time 0.00(0.00)\n",
      "Iter 23940 | Time 21.2087(21.4579) | Bit/dim 3.4811(3.4916) | Xent 0.0013(0.0034) | Loss 8.6762(9.4432) | Error 0.0000(0.0010) Steps 820(810.40) | Grad Norm 0.9023(2.3024) | Total Time 0.00(0.00)\n",
      "Iter 23950 | Time 21.3896(21.4591) | Bit/dim 3.4867(3.4922) | Xent 0.0074(0.0036) | Loss 8.8564(9.2619) | Error 0.0011(0.0009) Steps 862(811.83) | Grad Norm 1.9690(2.1534) | Total Time 0.00(0.00)\n",
      "Iter 23960 | Time 20.9463(21.5413) | Bit/dim 3.4540(3.4914) | Xent 0.0036(0.0031) | Loss 8.5787(9.1147) | Error 0.0011(0.0007) Steps 796(810.83) | Grad Norm 2.3165(1.8699) | Total Time 0.00(0.00)\n",
      "Iter 23970 | Time 21.4477(21.4788) | Bit/dim 3.5215(3.4940) | Xent 0.0110(0.0032) | Loss 8.8036(9.0077) | Error 0.0022(0.0008) Steps 844(806.81) | Grad Norm 5.6797(1.9130) | Total Time 0.00(0.00)\n",
      "Iter 23980 | Time 21.2915(21.4790) | Bit/dim 3.4876(3.4941) | Xent 0.0005(0.0035) | Loss 8.7545(8.9347) | Error 0.0000(0.0008) Steps 796(803.74) | Grad Norm 0.9089(2.1262) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 91.1934, Epoch Time 1293.8607(1275.3018), Bit/dim 3.5246(best: 3.5202), Xent 3.2844, Loss 5.1668, Error 0.3657(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23990 | Time 22.9072(21.5404) | Bit/dim 3.5108(3.4948) | Xent 0.0255(0.0044) | Loss 8.8278(9.5373) | Error 0.0044(0.0010) Steps 808(807.64) | Grad Norm 5.2008(2.3187) | Total Time 0.00(0.00)\n",
      "Iter 24000 | Time 21.0864(21.4777) | Bit/dim 3.4938(3.4940) | Xent 0.0062(0.0040) | Loss 8.6779(9.3078) | Error 0.0011(0.0009) Steps 820(810.00) | Grad Norm 1.1586(2.1858) | Total Time 0.00(0.00)\n",
      "Iter 24010 | Time 20.5557(21.4271) | Bit/dim 3.5038(3.4922) | Xent 0.0006(0.0036) | Loss 8.7554(9.1546) | Error 0.0000(0.0009) Steps 796(809.28) | Grad Norm 0.8971(2.0672) | Total Time 0.00(0.00)\n",
      "Iter 24020 | Time 21.4140(21.4849) | Bit/dim 3.5377(3.4927) | Xent 0.0018(0.0039) | Loss 8.8389(9.0452) | Error 0.0011(0.0009) Steps 814(807.01) | Grad Norm 1.9145(2.1732) | Total Time 0.00(0.00)\n",
      "Iter 24030 | Time 21.1466(21.4654) | Bit/dim 3.4778(3.4934) | Xent 0.0132(0.0044) | Loss 8.7283(8.9636) | Error 0.0022(0.0011) Steps 802(807.34) | Grad Norm 4.0981(2.3501) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 89.6376, Epoch Time 1286.8110(1275.6471), Bit/dim 3.5234(best: 3.5202), Xent 3.3056, Loss 5.1762, Error 0.3746(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24040 | Time 22.1100(21.4643) | Bit/dim 3.4584(3.4939) | Xent 0.0070(0.0047) | Loss 8.5322(9.6814) | Error 0.0022(0.0013) Steps 826(807.92) | Grad Norm 3.4636(2.5275) | Total Time 0.00(0.00)\n",
      "Iter 24050 | Time 21.8650(21.4957) | Bit/dim 3.5044(3.4924) | Xent 0.0024(0.0045) | Loss 8.7526(9.4357) | Error 0.0011(0.0012) Steps 826(810.64) | Grad Norm 1.3734(2.6599) | Total Time 0.00(0.00)\n",
      "Iter 24060 | Time 21.1239(21.5075) | Bit/dim 3.5057(3.4921) | Xent 0.0043(0.0042) | Loss 8.6417(9.2382) | Error 0.0022(0.0013) Steps 772(807.33) | Grad Norm 3.8727(2.6543) | Total Time 0.00(0.00)\n",
      "Iter 24070 | Time 22.1792(21.4493) | Bit/dim 3.4852(3.4896) | Xent 0.0004(0.0044) | Loss 8.6665(9.0905) | Error 0.0000(0.0011) Steps 796(807.69) | Grad Norm 0.9716(2.5637) | Total Time 0.00(0.00)\n",
      "Iter 24080 | Time 22.2046(21.5658) | Bit/dim 3.5096(3.4929) | Xent 0.0050(0.0043) | Loss 8.7764(9.0005) | Error 0.0011(0.0011) Steps 814(809.25) | Grad Norm 1.5736(2.3538) | Total Time 0.00(0.00)\n",
      "Iter 24090 | Time 21.2454(21.5357) | Bit/dim 3.5446(3.4941) | Xent 0.0020(0.0039) | Loss 8.8474(8.9330) | Error 0.0000(0.0010) Steps 796(809.29) | Grad Norm 0.9037(2.0518) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 90.5990, Epoch Time 1292.3085(1276.1469), Bit/dim 3.5222(best: 3.5202), Xent 3.2703, Loss 5.1574, Error 0.3708(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24100 | Time 21.3635(21.5000) | Bit/dim 3.5065(3.4937) | Xent 0.0003(0.0032) | Loss 8.7859(9.5515) | Error 0.0000(0.0008) Steps 784(810.49) | Grad Norm 0.5944(1.7968) | Total Time 0.00(0.00)\n",
      "Iter 24110 | Time 21.6376(21.5786) | Bit/dim 3.4826(3.4914) | Xent 0.0007(0.0031) | Loss 8.6836(9.3213) | Error 0.0000(0.0008) Steps 850(810.62) | Grad Norm 1.0515(1.7499) | Total Time 0.00(0.00)\n",
      "Iter 24120 | Time 21.5571(21.4960) | Bit/dim 3.4830(3.4874) | Xent 0.0007(0.0035) | Loss 8.7066(9.1528) | Error 0.0000(0.0009) Steps 826(811.84) | Grad Norm 1.9114(2.0092) | Total Time 0.00(0.00)\n",
      "Iter 24130 | Time 21.7764(21.4735) | Bit/dim 3.5063(3.4884) | Xent 0.0016(0.0034) | Loss 8.6864(9.0274) | Error 0.0011(0.0009) Steps 802(811.05) | Grad Norm 1.2662(2.0430) | Total Time 0.00(0.00)\n",
      "Iter 24140 | Time 21.3200(21.5896) | Bit/dim 3.4722(3.4907) | Xent 0.0122(0.0043) | Loss 8.7061(8.9406) | Error 0.0044(0.0012) Steps 814(812.65) | Grad Norm 3.7908(2.4589) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 90.4654, Epoch Time 1291.6892(1276.6132), Bit/dim 3.5259(best: 3.5202), Xent 3.2754, Loss 5.1636, Error 0.3694(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24150 | Time 21.2617(21.4747) | Bit/dim 3.4810(3.4913) | Xent 0.0015(0.0043) | Loss 8.7162(9.6374) | Error 0.0000(0.0012) Steps 814(810.56) | Grad Norm 1.8744(2.4635) | Total Time 0.00(0.00)\n",
      "Iter 24160 | Time 21.4575(21.4613) | Bit/dim 3.5255(3.4942) | Xent 0.0004(0.0040) | Loss 8.8276(9.4039) | Error 0.0000(0.0011) Steps 826(812.65) | Grad Norm 0.6784(2.2877) | Total Time 0.00(0.00)\n",
      "Iter 24170 | Time 21.2932(21.5273) | Bit/dim 3.4940(3.4961) | Xent 0.0027(0.0039) | Loss 8.6500(9.2265) | Error 0.0011(0.0011) Steps 820(812.76) | Grad Norm 1.5621(2.3133) | Total Time 0.00(0.00)\n",
      "Iter 24180 | Time 20.5756(21.4835) | Bit/dim 3.4805(3.4951) | Xent 0.0013(0.0037) | Loss 8.7004(9.0895) | Error 0.0000(0.0011) Steps 772(808.90) | Grad Norm 1.8058(2.3226) | Total Time 0.00(0.00)\n",
      "Iter 24190 | Time 21.5105(21.4161) | Bit/dim 3.5131(3.4928) | Xent 0.0038(0.0033) | Loss 8.8054(8.9956) | Error 0.0022(0.0010) Steps 844(810.50) | Grad Norm 1.7905(2.2130) | Total Time 0.00(0.00)\n",
      "Iter 24200 | Time 21.2597(21.5524) | Bit/dim 3.4997(3.4924) | Xent 0.0121(0.0033) | Loss 8.7405(8.9231) | Error 0.0033(0.0010) Steps 826(810.59) | Grad Norm 1.8779(2.1266) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 91.7800, Epoch Time 1290.0580(1277.0165), Bit/dim 3.5232(best: 3.5202), Xent 3.2762, Loss 5.1613, Error 0.3708(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24210 | Time 21.3308(21.4860) | Bit/dim 3.4854(3.4938) | Xent 0.0011(0.0031) | Loss 8.7188(9.5393) | Error 0.0000(0.0009) Steps 814(812.15) | Grad Norm 1.9357(2.1146) | Total Time 0.00(0.00)\n",
      "Iter 24220 | Time 20.4002(21.5227) | Bit/dim 3.4658(3.4899) | Xent 0.0006(0.0031) | Loss 8.6715(9.3213) | Error 0.0000(0.0009) Steps 814(812.18) | Grad Norm 1.4036(2.1175) | Total Time 0.00(0.00)\n",
      "Iter 24230 | Time 21.2583(21.5324) | Bit/dim 3.5294(3.4925) | Xent 0.0007(0.0032) | Loss 8.8715(9.1601) | Error 0.0000(0.0009) Steps 814(811.92) | Grad Norm 0.9644(2.0429) | Total Time 0.00(0.00)\n",
      "Iter 24240 | Time 21.4157(21.4412) | Bit/dim 3.5037(3.4888) | Xent 0.0028(0.0035) | Loss 8.7763(9.0396) | Error 0.0011(0.0010) Steps 856(813.25) | Grad Norm 1.3417(2.1523) | Total Time 0.00(0.00)\n",
      "Iter 24250 | Time 21.1391(21.4125) | Bit/dim 3.4966(3.4920) | Xent 0.0085(0.0042) | Loss 8.7636(8.9611) | Error 0.0033(0.0011) Steps 826(814.70) | Grad Norm 2.5902(2.1253) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 93.0154, Epoch Time 1288.1427(1277.3503), Bit/dim 3.5249(best: 3.5202), Xent 3.3643, Loss 5.2071, Error 0.3730(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24260 | Time 21.2858(21.4207) | Bit/dim 3.4888(3.4939) | Xent 0.0088(0.0046) | Loss 8.6834(9.6918) | Error 0.0022(0.0012) Steps 814(814.57) | Grad Norm 5.7447(2.4859) | Total Time 0.00(0.00)\n",
      "Iter 24270 | Time 21.0432(21.3405) | Bit/dim 3.4954(3.4971) | Xent 0.0020(0.0041) | Loss 8.6895(9.4370) | Error 0.0000(0.0010) Steps 790(810.75) | Grad Norm 1.3035(2.3685) | Total Time 0.00(0.00)\n",
      "Iter 24280 | Time 21.3031(21.3597) | Bit/dim 3.4805(3.4962) | Xent 0.0109(0.0042) | Loss 8.6426(9.2562) | Error 0.0011(0.0010) Steps 784(811.05) | Grad Norm 2.0016(2.2497) | Total Time 0.00(0.00)\n",
      "Iter 24290 | Time 21.6671(21.3347) | Bit/dim 3.4909(3.4974) | Xent 0.0024(0.0044) | Loss 8.6670(9.1156) | Error 0.0011(0.0012) Steps 796(809.78) | Grad Norm 2.1283(2.4667) | Total Time 0.00(0.00)\n",
      "Iter 24300 | Time 20.5239(21.3242) | Bit/dim 3.4771(3.4954) | Xent 0.0065(0.0041) | Loss 8.5814(9.0043) | Error 0.0011(0.0011) Steps 784(808.23) | Grad Norm 2.1535(2.4059) | Total Time 0.00(0.00)\n",
      "Iter 24310 | Time 21.1693(21.2825) | Bit/dim 3.4526(3.4927) | Xent 0.0062(0.0044) | Loss 8.6976(8.9279) | Error 0.0011(0.0011) Steps 766(807.18) | Grad Norm 3.8965(2.3632) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 89.4905, Epoch Time 1275.8876(1277.3064), Bit/dim 3.5232(best: 3.5202), Xent 3.3265, Loss 5.1864, Error 0.3722(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24320 | Time 21.2419(21.3544) | Bit/dim 3.4850(3.4949) | Xent 0.0091(0.0048) | Loss 8.6932(9.5350) | Error 0.0011(0.0011) Steps 802(805.57) | Grad Norm 1.2950(2.3244) | Total Time 0.00(0.00)\n",
      "Iter 24330 | Time 21.8823(21.4153) | Bit/dim 3.5054(3.4937) | Xent 0.0029(0.0042) | Loss 8.7227(9.3249) | Error 0.0011(0.0010) Steps 826(808.70) | Grad Norm 2.6137(2.1299) | Total Time 0.00(0.00)\n",
      "Iter 24340 | Time 21.0683(21.4273) | Bit/dim 3.5134(3.4949) | Xent 0.0065(0.0037) | Loss 8.7208(9.1710) | Error 0.0011(0.0009) Steps 808(811.02) | Grad Norm 2.2934(2.0100) | Total Time 0.00(0.00)\n",
      "Iter 24350 | Time 21.1525(21.4700) | Bit/dim 3.4823(3.4936) | Xent 0.0039(0.0041) | Loss 8.7001(9.0530) | Error 0.0022(0.0011) Steps 814(811.46) | Grad Norm 3.0833(2.1524) | Total Time 0.00(0.00)\n",
      "Iter 24360 | Time 21.0312(21.5417) | Bit/dim 3.4859(3.4922) | Xent 0.0018(0.0046) | Loss 8.7503(8.9622) | Error 0.0000(0.0011) Steps 826(811.62) | Grad Norm 1.6348(2.1428) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 88.5427, Epoch Time 1287.9160(1277.6247), Bit/dim 3.5227(best: 3.5202), Xent 3.3436, Loss 5.1945, Error 0.3761(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24370 | Time 21.6932(21.3542) | Bit/dim 3.4646(3.4917) | Xent 0.0181(0.0049) | Loss 8.7533(9.6665) | Error 0.0033(0.0012) Steps 802(810.15) | Grad Norm 5.0760(2.4488) | Total Time 0.00(0.00)\n",
      "Iter 24380 | Time 22.5790(21.4303) | Bit/dim 3.5243(3.4950) | Xent 0.0107(0.0055) | Loss 8.7453(9.4205) | Error 0.0033(0.0015) Steps 820(807.05) | Grad Norm 4.5508(3.0630) | Total Time 0.00(0.00)\n",
      "Iter 24390 | Time 22.8278(21.5890) | Bit/dim 3.5176(3.4952) | Xent 0.0005(0.0058) | Loss 8.8035(9.2376) | Error 0.0000(0.0017) Steps 826(808.73) | Grad Norm 1.6524(3.3784) | Total Time 0.00(0.00)\n",
      "Iter 24400 | Time 21.7902(21.5974) | Bit/dim 3.4964(3.4936) | Xent 0.0078(0.0058) | Loss 8.6398(9.1008) | Error 0.0033(0.0018) Steps 754(806.05) | Grad Norm 4.3744(3.6352) | Total Time 0.00(0.00)\n",
      "Iter 24410 | Time 21.5022(21.5990) | Bit/dim 3.5101(3.4957) | Xent 0.0019(0.0051) | Loss 8.7386(9.0082) | Error 0.0000(0.0016) Steps 796(807.78) | Grad Norm 2.3153(3.4577) | Total Time 0.00(0.00)\n",
      "Iter 24420 | Time 22.0008(21.6272) | Bit/dim 3.4723(3.4969) | Xent 0.0080(0.0048) | Loss 8.5716(8.9349) | Error 0.0011(0.0015) Steps 772(808.45) | Grad Norm 4.1950(3.2301) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 89.7058, Epoch Time 1297.4302(1278.2189), Bit/dim 3.5212(best: 3.5202), Xent 3.2574, Loss 5.1499, Error 0.3703(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24430 | Time 21.4540(21.5059) | Bit/dim 3.5114(3.4976) | Xent 0.0080(0.0047) | Loss 8.8245(9.5604) | Error 0.0022(0.0013) Steps 784(810.09) | Grad Norm 2.3095(3.0396) | Total Time 0.00(0.00)\n",
      "Iter 24440 | Time 21.2938(21.4190) | Bit/dim 3.4851(3.4936) | Xent 0.0077(0.0050) | Loss 8.6244(9.3386) | Error 0.0022(0.0013) Steps 778(810.20) | Grad Norm 3.7904(2.9826) | Total Time 0.00(0.00)\n",
      "Iter 24450 | Time 20.8231(21.4333) | Bit/dim 3.4807(3.4914) | Xent 0.0007(0.0053) | Loss 8.6811(9.1719) | Error 0.0000(0.0013) Steps 796(810.41) | Grad Norm 1.9115(3.0325) | Total Time 0.00(0.00)\n",
      "Iter 24460 | Time 21.7309(21.4108) | Bit/dim 3.5006(3.4919) | Xent 0.0047(0.0047) | Loss 8.6476(9.0412) | Error 0.0022(0.0012) Steps 802(810.35) | Grad Norm 3.0078(3.0425) | Total Time 0.00(0.00)\n",
      "Iter 24470 | Time 22.3495(21.3487) | Bit/dim 3.5082(3.4942) | Xent 0.0092(0.0051) | Loss 8.6440(8.9573) | Error 0.0022(0.0014) Steps 802(809.19) | Grad Norm 4.4891(3.0209) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 93.0901, Epoch Time 1281.4721(1278.3165), Bit/dim 3.5231(best: 3.5202), Xent 3.2370, Loss 5.1416, Error 0.3670(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24480 | Time 21.5231(21.5022) | Bit/dim 3.5049(3.4951) | Xent 0.0055(0.0052) | Loss 8.6345(9.6657) | Error 0.0011(0.0014) Steps 802(810.26) | Grad Norm 2.4195(3.1437) | Total Time 0.00(0.00)\n",
      "Iter 24490 | Time 21.7708(21.4447) | Bit/dim 3.4733(3.4965) | Xent 0.0035(0.0045) | Loss 8.6719(9.4149) | Error 0.0011(0.0012) Steps 766(806.84) | Grad Norm 2.8342(3.2135) | Total Time 0.00(0.00)\n",
      "Iter 24500 | Time 21.2758(21.3540) | Bit/dim 3.4712(3.4943) | Xent 0.0034(0.0052) | Loss 8.6712(9.2311) | Error 0.0011(0.0014) Steps 820(804.45) | Grad Norm 2.1541(3.0689) | Total Time 0.00(0.00)\n",
      "Iter 24510 | Time 22.4179(21.4192) | Bit/dim 3.4837(3.4953) | Xent 0.0008(0.0045) | Loss 8.7490(9.0962) | Error 0.0000(0.0012) Steps 814(805.77) | Grad Norm 2.2448(2.8529) | Total Time 0.00(0.00)\n",
      "Iter 24520 | Time 21.0477(21.3769) | Bit/dim 3.5027(3.4932) | Xent 0.0012(0.0045) | Loss 8.5717(8.9870) | Error 0.0000(0.0011) Steps 820(806.95) | Grad Norm 1.1326(2.6791) | Total Time 0.00(0.00)\n",
      "Iter 24530 | Time 21.7921(21.3148) | Bit/dim 3.5004(3.4930) | Xent 0.0019(0.0041) | Loss 8.6231(8.9116) | Error 0.0011(0.0010) Steps 760(807.48) | Grad Norm 0.9692(2.3991) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 90.8909, Epoch Time 1281.9791(1278.4263), Bit/dim 3.5199(best: 3.5202), Xent 3.2856, Loss 5.1627, Error 0.3732(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24540 | Time 21.3799(21.4263) | Bit/dim 3.5087(3.4940) | Xent 0.0075(0.0040) | Loss 8.6635(9.5287) | Error 0.0011(0.0009) Steps 820(811.72) | Grad Norm 4.3761(2.3066) | Total Time 0.00(0.00)\n",
      "Iter 24550 | Time 21.4488(21.4031) | Bit/dim 3.4922(3.4914) | Xent 0.0056(0.0035) | Loss 8.8589(9.3132) | Error 0.0011(0.0008) Steps 832(809.95) | Grad Norm 1.6707(2.1073) | Total Time 0.00(0.00)\n",
      "Iter 24560 | Time 21.9487(21.3547) | Bit/dim 3.4748(3.4910) | Xent 0.0012(0.0034) | Loss 8.7007(9.1519) | Error 0.0000(0.0009) Steps 790(809.00) | Grad Norm 0.9626(2.0835) | Total Time 0.00(0.00)\n",
      "Iter 24570 | Time 21.5264(21.3493) | Bit/dim 3.5048(3.4905) | Xent 0.0182(0.0041) | Loss 8.6960(9.0358) | Error 0.0044(0.0011) Steps 826(807.50) | Grad Norm 4.5024(2.3119) | Total Time 0.00(0.00)\n",
      "Iter 24580 | Time 21.7228(21.4259) | Bit/dim 3.4981(3.4927) | Xent 0.0010(0.0034) | Loss 8.6717(8.9546) | Error 0.0000(0.0010) Steps 820(807.74) | Grad Norm 0.8516(2.1318) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 90.5967, Epoch Time 1286.3471(1278.6640), Bit/dim 3.5211(best: 3.5199), Xent 3.3681, Loss 5.2051, Error 0.3734(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24590 | Time 20.8726(21.4017) | Bit/dim 3.5107(3.4913) | Xent 0.0036(0.0033) | Loss 8.5585(9.6530) | Error 0.0022(0.0009) Steps 826(808.89) | Grad Norm 3.2893(2.1353) | Total Time 0.00(0.00)\n",
      "Iter 24600 | Time 21.8648(21.3985) | Bit/dim 3.4961(3.4931) | Xent 0.0006(0.0043) | Loss 8.7465(9.4111) | Error 0.0000(0.0011) Steps 832(808.17) | Grad Norm 1.0641(2.3501) | Total Time 0.00(0.00)\n",
      "Iter 24610 | Time 21.1281(21.4411) | Bit/dim 3.4918(3.4925) | Xent 0.0203(0.0045) | Loss 8.6175(9.2167) | Error 0.0044(0.0012) Steps 796(807.74) | Grad Norm 4.8487(2.3411) | Total Time 0.00(0.00)\n",
      "Iter 24620 | Time 21.9892(21.4131) | Bit/dim 3.5189(3.4934) | Xent 0.0011(0.0041) | Loss 8.7679(9.0913) | Error 0.0000(0.0011) Steps 820(808.30) | Grad Norm 1.3612(2.2955) | Total Time 0.00(0.00)\n",
      "Iter 24630 | Time 20.5040(21.3607) | Bit/dim 3.4869(3.4925) | Xent 0.0005(0.0040) | Loss 8.5445(8.9874) | Error 0.0000(0.0010) Steps 790(809.19) | Grad Norm 1.1725(2.1292) | Total Time 0.00(0.00)\n",
      "Iter 24640 | Time 21.2305(21.4792) | Bit/dim 3.4821(3.4901) | Xent 0.0020(0.0044) | Loss 8.6367(8.9104) | Error 0.0011(0.0010) Steps 790(809.58) | Grad Norm 1.6532(2.0270) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 90.9619, Epoch Time 1287.4953(1278.9289), Bit/dim 3.5220(best: 3.5199), Xent 3.2909, Loss 5.1674, Error 0.3702(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24650 | Time 21.6295(21.4201) | Bit/dim 3.4762(3.4898) | Xent 0.0088(0.0044) | Loss 8.6977(9.5347) | Error 0.0022(0.0010) Steps 826(813.86) | Grad Norm 1.8272(2.0045) | Total Time 0.00(0.00)\n",
      "Iter 24660 | Time 21.5559(21.3519) | Bit/dim 3.5107(3.4922) | Xent 0.0016(0.0044) | Loss 8.6556(9.3115) | Error 0.0011(0.0010) Steps 796(813.07) | Grad Norm 2.3455(2.3128) | Total Time 0.00(0.00)\n",
      "Iter 24670 | Time 21.6514(21.4467) | Bit/dim 3.4938(3.4911) | Xent 0.0003(0.0051) | Loss 8.7380(9.1525) | Error 0.0000(0.0012) Steps 844(815.01) | Grad Norm 1.4083(2.7733) | Total Time 0.00(0.00)\n",
      "Iter 24680 | Time 20.4507(21.3755) | Bit/dim 3.4864(3.4918) | Xent 0.0020(0.0047) | Loss 8.6400(9.0428) | Error 0.0000(0.0013) Steps 790(812.16) | Grad Norm 1.7953(2.9948) | Total Time 0.00(0.00)\n",
      "Iter 24690 | Time 20.6926(21.3445) | Bit/dim 3.5059(3.4942) | Xent 0.0009(0.0041) | Loss 8.7687(8.9592) | Error 0.0000(0.0012) Steps 802(807.58) | Grad Norm 1.0268(2.7323) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 93.2323, Epoch Time 1285.0286(1279.1119), Bit/dim 3.5194(best: 3.5199), Xent 3.3263, Loss 5.1825, Error 0.3731(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24700 | Time 21.7856(21.4602) | Bit/dim 3.4668(3.4928) | Xent 0.0016(0.0041) | Loss 8.7293(9.6433) | Error 0.0000(0.0012) Steps 772(806.37) | Grad Norm 2.1239(2.6804) | Total Time 0.00(0.00)\n",
      "Iter 24710 | Time 21.3185(21.4637) | Bit/dim 3.5014(3.4957) | Xent 0.0049(0.0041) | Loss 8.8240(9.4057) | Error 0.0011(0.0011) Steps 838(808.57) | Grad Norm 3.2155(2.5559) | Total Time 0.00(0.00)\n",
      "Iter 24720 | Time 20.8297(21.4581) | Bit/dim 3.4740(3.4920) | Xent 0.0008(0.0036) | Loss 8.8092(9.2278) | Error 0.0000(0.0009) Steps 826(810.78) | Grad Norm 1.3977(2.3414) | Total Time 0.00(0.00)\n",
      "Iter 24730 | Time 20.3802(21.4150) | Bit/dim 3.4848(3.4912) | Xent 0.0007(0.0031) | Loss 8.6484(9.0885) | Error 0.0000(0.0008) Steps 790(810.10) | Grad Norm 1.0072(2.1563) | Total Time 0.00(0.00)\n",
      "Iter 24740 | Time 21.7970(21.4778) | Bit/dim 3.4706(3.4901) | Xent 0.0007(0.0031) | Loss 8.6241(8.9795) | Error 0.0000(0.0008) Steps 826(811.86) | Grad Norm 1.2106(2.1336) | Total Time 0.00(0.00)\n",
      "Iter 24750 | Time 21.0239(21.4922) | Bit/dim 3.4866(3.4891) | Xent 0.0007(0.0029) | Loss 8.6348(8.8956) | Error 0.0000(0.0007) Steps 832(813.34) | Grad Norm 0.6734(1.8803) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 90.9254, Epoch Time 1290.6305(1279.4575), Bit/dim 3.5219(best: 3.5194), Xent 3.2782, Loss 5.1610, Error 0.3685(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24760 | Time 21.5899(21.5622) | Bit/dim 3.4620(3.4887) | Xent 0.0003(0.0025) | Loss 8.6839(9.5240) | Error 0.0000(0.0006) Steps 808(813.47) | Grad Norm 0.8620(1.7706) | Total Time 0.00(0.00)\n",
      "Iter 24770 | Time 21.2788(21.5761) | Bit/dim 3.5045(3.4884) | Xent 0.0013(0.0025) | Loss 8.6234(9.3068) | Error 0.0000(0.0006) Steps 826(812.86) | Grad Norm 1.6876(1.7261) | Total Time 0.00(0.00)\n",
      "Iter 24780 | Time 21.2675(21.4837) | Bit/dim 3.4846(3.4902) | Xent 0.0012(0.0027) | Loss 8.7511(9.1551) | Error 0.0000(0.0006) Steps 814(811.32) | Grad Norm 1.1059(1.6907) | Total Time 0.00(0.00)\n",
      "Iter 24790 | Time 21.9168(21.4455) | Bit/dim 3.4702(3.4906) | Xent 0.0007(0.0026) | Loss 8.7228(9.0387) | Error 0.0000(0.0006) Steps 802(812.76) | Grad Norm 0.6954(1.6374) | Total Time 0.00(0.00)\n",
      "Iter 24800 | Time 21.4512(21.5341) | Bit/dim 3.5017(3.4892) | Xent 0.0004(0.0023) | Loss 8.7335(8.9572) | Error 0.0000(0.0006) Steps 820(813.41) | Grad Norm 0.8749(1.5759) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 91.0755, Epoch Time 1291.7338(1279.8258), Bit/dim 3.5207(best: 3.5194), Xent 3.3326, Loss 5.1870, Error 0.3746(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24810 | Time 20.6114(21.4516) | Bit/dim 3.4852(3.4924) | Xent 0.0004(0.0022) | Loss 8.6666(9.6843) | Error 0.0000(0.0005) Steps 808(813.03) | Grad Norm 0.5771(1.4430) | Total Time 0.00(0.00)\n",
      "Iter 24820 | Time 22.0586(21.4505) | Bit/dim 3.4993(3.4937) | Xent 0.0034(0.0019) | Loss 8.6956(9.4273) | Error 0.0022(0.0005) Steps 838(814.59) | Grad Norm 2.0036(1.3434) | Total Time 0.00(0.00)\n",
      "Iter 24830 | Time 21.0681(21.4607) | Bit/dim 3.5099(3.4957) | Xent 0.0007(0.0024) | Loss 8.6994(9.2404) | Error 0.0000(0.0005) Steps 778(809.96) | Grad Norm 0.6061(1.4006) | Total Time 0.00(0.00)\n",
      "Iter 24840 | Time 21.0393(21.4772) | Bit/dim 3.5112(3.4928) | Xent 0.0006(0.0025) | Loss 8.7034(9.0974) | Error 0.0000(0.0005) Steps 808(811.12) | Grad Norm 0.6923(1.4076) | Total Time 0.00(0.00)\n",
      "Iter 24850 | Time 21.0845(21.4004) | Bit/dim 3.4818(3.4916) | Xent 0.0023(0.0025) | Loss 8.7889(8.9985) | Error 0.0011(0.0005) Steps 820(810.98) | Grad Norm 2.4021(1.5162) | Total Time 0.00(0.00)\n",
      "Iter 24860 | Time 21.7776(21.4717) | Bit/dim 3.4438(3.4895) | Xent 0.0045(0.0032) | Loss 8.5283(8.9090) | Error 0.0011(0.0007) Steps 814(811.31) | Grad Norm 4.2751(1.9635) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 92.5219, Epoch Time 1288.2654(1280.0789), Bit/dim 3.5248(best: 3.5194), Xent 3.3261, Loss 5.1878, Error 0.3710(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24870 | Time 21.6973(21.4680) | Bit/dim 3.5130(3.4899) | Xent 0.0029(0.0036) | Loss 8.8140(9.5280) | Error 0.0011(0.0008) Steps 868(812.29) | Grad Norm 1.9937(2.0298) | Total Time 0.00(0.00)\n",
      "Iter 24880 | Time 21.3610(21.4750) | Bit/dim 3.4705(3.4912) | Xent 0.0043(0.0035) | Loss 8.6580(9.3151) | Error 0.0022(0.0008) Steps 784(810.89) | Grad Norm 3.5106(2.1308) | Total Time 0.00(0.00)\n",
      "Iter 24890 | Time 22.5894(21.5062) | Bit/dim 3.4828(3.4915) | Xent 0.0021(0.0038) | Loss 8.6698(9.1612) | Error 0.0000(0.0009) Steps 790(811.69) | Grad Norm 3.3254(2.2918) | Total Time 0.00(0.00)\n",
      "Iter 24900 | Time 21.2333(21.5033) | Bit/dim 3.4806(3.4895) | Xent 0.0094(0.0040) | Loss 8.6973(9.0448) | Error 0.0033(0.0010) Steps 832(815.58) | Grad Norm 7.2188(2.3415) | Total Time 0.00(0.00)\n",
      "Iter 24910 | Time 20.6717(21.4107) | Bit/dim 3.4742(3.4903) | Xent 0.0097(0.0040) | Loss 8.6725(8.9551) | Error 0.0033(0.0009) Steps 796(813.87) | Grad Norm 3.7971(2.3431) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 91.2693, Epoch Time 1285.1270(1280.2304), Bit/dim 3.5238(best: 3.5194), Xent 3.3756, Loss 5.2116, Error 0.3757(best: 0.3605)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24920 | Time 22.1587(21.4936) | Bit/dim 3.5226(3.4938) | Xent 0.0021(0.0044) | Loss 8.6865(9.6975) | Error 0.0000(0.0011) Steps 814(815.84) | Grad Norm 1.6564(2.5395) | Total Time 0.00(0.00)\n",
      "Iter 24930 | Time 21.6321(21.5647) | Bit/dim 3.4780(3.4929) | Xent 0.0057(0.0038) | Loss 8.7168(9.4405) | Error 0.0011(0.0009) Steps 802(813.68) | Grad Norm 1.2886(2.3471) | Total Time 0.00(0.00)\n",
      "Iter 24940 | Time 22.4193(21.5072) | Bit/dim 3.4772(3.4901) | Xent 0.0078(0.0034) | Loss 8.6584(9.2389) | Error 0.0022(0.0008) Steps 778(810.84) | Grad Norm 5.3140(2.2060) | Total Time 0.00(0.00)\n",
      "Iter 24950 | Time 21.3194(21.3705) | Bit/dim 3.5097(3.4900) | Xent 0.0021(0.0036) | Loss 8.8158(9.0949) | Error 0.0011(0.0008) Steps 826(809.91) | Grad Norm 1.9523(2.0548) | Total Time 0.00(0.00)\n",
      "Iter 24960 | Time 22.8745(21.4560) | Bit/dim 3.5072(3.4914) | Xent 0.0074(0.0039) | Loss 8.6999(8.9862) | Error 0.0022(0.0008) Steps 796(807.61) | Grad Norm 3.2089(2.1391) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl_multiscale.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run1 --resume ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run1/epoch_250_checkpt.pth --seed 1 --lr 0.0001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5 --scale_fac 1.0 --scale_std 6.0\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
